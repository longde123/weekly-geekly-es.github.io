<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ“ ğŸ’Ÿ ğŸš° Logique, explicabilitÃ© et comprÃ©hension future â™‚ï¸ ğŸ¦€ ğŸŒ¤ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="DÃ©couverte liÃ©e Ã  la logique 
 La logique est Ã  la base de bien des choses. Mais quels sont les fondements de la logique elle-mÃªme? 

 Dans la logique...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Logique, explicabilitÃ© et comprÃ©hension future</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431956/"><h3>  DÃ©couverte liÃ©e Ã  la logique </h3><br>  La logique est Ã  la base de bien des choses.  Mais quels sont les fondements de la logique elle-mÃªme? <br><br>  Dans la logique symbolique, des symboles comme p et q sont introduits pour dÃ©signer des dÃ©clarations (ou Â«propositionsÂ») du type Â«ceci est un essai intÃ©ressantÂ».  Il existe encore certaines rÃ¨gles de logique, par exemple, pour tout p et tout q l'expression NOT (p AND q) est similaire Ã  (NOT p) OR (NOT q). <br><br>  Mais d'oÃ¹ viennent ces Â«rÃ¨gles de logiqueÂ»?  La logique est un systÃ¨me formel.  Comme la gÃ©omÃ©trie euclidienne, elle peut Ãªtre construite sur des axiomes.  Mais que sont les axiomes?  Vous pouvez commencer avec des instructions telles que p AND q = q AND p, ou NOT NOT p = p.  Mais combien d'axiomes sont nÃ©cessaires?  Comment peuvent-ils Ãªtre simples? <br><br>  Cette question est depuis longtemps douloureuse.  Mais Ã  20h31 le dimanche 29 janvier 2000, le seul axiome est apparu sur l'Ã©cran de mon ordinateur.  J'ai dÃ©jÃ  montrÃ© que rien de plus simple, mais j'ai vite Ã©tabli que ce seul petit axiome suffisait Ã  crÃ©er toute la logique: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8a5/426/b76/8a5426b76ec6ff73e4b9f521f1e66764.png"></div><a name="habracut"></a><br>  Comment savais-je qu'elle Ã©tait vraie?  Parce que je l'ai fait prouver Ã  l'ordinateur.  Et voici la preuve que j'ai imprimÃ©e dans le livre Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">A New Type of Science</a> Â» (dÃ©jÃ  disponible dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le rÃ©fÃ©rentiel Wolfram Data</a> ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9c7/d9f/11e/9c7d9f11e1cb651d7bfbe6b4edad66dd.png"></div><br>  En utilisant la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">derniÃ¨re version de</a> Wolfram Language, n'importe qui peut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gÃ©nÃ©rer</a> cette preuve en moins d'une minute.  Et chacune de ses Ã©tapes est facile <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ã  vÃ©rifier</a> .  Mais pourquoi le rÃ©sultat sera-t-il vrai?  Comment l'expliquer? <br><br>  Des questions similaires sont de plus en plus posÃ©es sur toutes sortes de systÃ¨mes informatiques et d'applications liÃ©s Ã  l'apprentissage automatique et Ã  l'IA.  Oui, nous voyons ce qui se passe.  Mais pouvons-nous comprendre cela? <br><br>  Je pense que cette question est profondÃ©ment inhÃ©rente - et d'une importance cruciale pour l'avenir de la science et de la technologie, et pour l'avenir de tout dÃ©veloppement intellectuel. <br><br>  Mais avant d'en parler, discutons de l'axiome que j'ai dÃ©couvert. <br><br><h2>  L'histoire </h2><br>  La logique en tant que discipline formelle vient d'Aristote, qui a vÃ©cu au 4Ã¨me siÃ¨cle avant JC.  Dans le cadre de son travail de catalogage des choses (animaux, raisons, etc.), Aristote a compilÃ© un catalogue de formes d'arguments autorisÃ©es et a crÃ©Ã© des modÃ¨les symboliques pour eux, qui, en substance, ont fourni le contenu principal de la logique pour deux mille ans Ã  venir. <br><br>  Cependant, au 15Ã¨me siÃ¨cle, l'algÃ¨bre a Ã©tÃ© inventÃ©e, et avec elle une image plus claire des choses est apparue.  Mais ce n'est qu'en 1847 que George Bull a finalement formulÃ© la logique de la mÃªme maniÃ¨re que l'algÃ¨bre, avec des opÃ©rations logiques telles que ET et OU fonctionnant selon des rÃ¨gles similaires aux rÃ¨gles de l'algÃ¨bre. <br><br>  AprÃ¨s quelques annÃ©es, les gens Ã©crivaient dÃ©jÃ  des systÃ¨mes axiomatiques pour la logique.  Un exemple typique Ã©tait: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1b7/f83/b05/1b7f83b053013cbb17e8a3e3f9734097.png"></div><br>  Mais ET, OU et NON PAS vraiment nÃ©cessaires pour la logique?  AprÃ¨s la premiÃ¨re dÃ©cennie du 20e siÃ¨cle, plusieurs personnes ont dÃ©couvert que la seule opÃ©ration que nous appelons maintenant NAND suffira, et, par exemple, p OR q peut Ãªtre calculÃ© comme (p NAND p) NAND (q NAND q).  La Â«complÃ©tude fonctionnelleÂ» de la NAND pourrait toujours rester Ã©trange sans le dÃ©veloppement de la technologie des semi-conducteurs - elle implÃ©mente tous les milliards d'opÃ©rations logiques dans un microprocesseur moderne en utilisant une combinaison de transistors qui exÃ©cutent uniquement la fonction NAND ou le NOR associÃ©. <br><br>  Eh bien, Ã  quoi ressemblent les axiomes de la logique en termes de NAND?  En voici la premiÃ¨re version connue, enregistrÃ©e par Henry Schaeffer en 1913 (ici le point dÃ©signe NAND): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2fd/af7/5d1/2fdaf75d1c346bb2d8c3c4d470ffcd68.png"></div><br>  En 1910, Principia Mathematica, un ouvrage en trois volumes sur la logique et la philosophie des mathÃ©matiques par Alfred North Whitehead et Bertrand Russell, a popularisÃ© l'idÃ©e que peut-Ãªtre toutes les mathÃ©matiques peuvent Ãªtre dÃ©duites de la logique.  Compte tenu de cela, il Ã©tait assez intÃ©ressant d'Ã©tudier la question de la simplicitÃ© des axiomes de la logique.  Le travail le plus important dans ce domaine a Ã©tÃ© effectuÃ© Ã  Lviv et Varsovie (alors ces villes faisaient partie de la Pologne), en particulier, Jan Lukasevich (comme effet secondaire de son travail en 1920, il a inventÃ© un record Â«polonaisÂ» qui ne nÃ©cessite pas de parenthÃ¨ses).  En 1944, Ã  l'Ã¢ge de 66 ans, Lukasevich a fui l'armÃ©e soviÃ©tique qui avanÃ§ait et en 1947 a fini en Irlande. <br><br>  Pendant ce temps, l'Irlandais Carew Meredith, qui a Ã©tudiÃ© Ã  Winchester et Ã  Cambridge et est devenu professeur de mathÃ©matiques Ã  Cambridge, a Ã©tÃ© contraint de retourner en Irlande en 1939 en raison de son pacifisme.  En 1947, Meredith a assistÃ© Ã  la confÃ©rence de Lukasevich Ã  Dublin, qui lâ€™a inspirÃ© Ã  rechercher des axiomes simples, ce quâ€™il a fait, pour la plupart, pour le reste de sa vie. <br><br>  En 1949, Meredith a dÃ©couvert un systÃ¨me Ã  deux axiomes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/237/0cf/7a8/2370cf7a8b94b221152f17f905223919.png"></div><br>  PrÃ¨s de 20 ans plus tard, en 1967, il a pu simplifier cela pour: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/245/ba1/89c/245ba189c20baf7290fde8e6164b1050.png"></div><br>  Est-il possible de simplifier davantage cela?  Meredith a bricolÃ© cela pendant des annÃ©es, trouvant oÃ¹ vous pouvez supprimer la NAND supplÃ©mentaire.  Mais aprÃ¨s 1967, il n'a plus avancÃ© (et est dÃ©cÃ©dÃ© en 1976), bien qu'en 1969 il ait trouvÃ© un systÃ¨me Ã  trois axiomes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/650/552/dcd/650552dcd498bb69a243af9ca9373091.png"></div><br>  Quand j'ai commencÃ© Ã  Ã©tudier les systÃ¨mes axiomes de logique, je ne connaissais rien du travail de Meredith.  Je me suis intÃ©ressÃ© Ã  ce sujet dans le cadre d'une tentative de comprendre quel comportement pourrait dÃ©couler de rÃ¨gles simples.  Dans les annÃ©es 1980, j'ai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dÃ©couvert de faÃ§on inattendue</a> que mÃªme les automates cellulaires avec les rÃ¨gles les plus simples possibles - comme ma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rÃ¨gle</a> prÃ©fÃ©rÃ©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">30</a> - peuvent conduire Ã  un comportement incroyablement complexe. <br><br>  Ayant passÃ© les annÃ©es 1990 dans une tentative de comprendre la gÃ©nÃ©ralitÃ© de ce phÃ©nomÃ¨ne, j'ai finalement voulu voir comment il pouvait s'appliquer aux mathÃ©matiques.  En mathÃ©matiques, nous commenÃ§ons en fait Ã  travailler avec des axiomes (par exemple, en arithmÃ©tique, en gÃ©omÃ©trie, en logique), puis sur leur base, nous essayons de prouver tout un ensemble de thÃ©orÃ¨mes complexes. <br><br>  Cependant, Ã  quel point les axiomes peuvent-ils Ãªtre simples?  C'est ce que je voulais Ã©tablir en 1999.  Comme premier exemple, j'ai dÃ©cidÃ© d'Ã©tudier la logique (ou, de maniÃ¨re Ã©quivalente, l'algÃ¨bre boolÃ©enne).  RÃ©futant toutes mes attentes, mon expÃ©rience avec les automates cellulaires, les machines de Turing et d'autres systÃ¨mes - y compris les Ã©quations diffÃ©rentielles mÃªme partielles - suggÃ¨re que vous pouvez simplement commencer Ã  lister les cas les plus simples possibles et Ã  un moment donnÃ© voir quelque chose intÃ©ressant. <br><br>  Mais est-il possible Â«d'ouvrir la logiqueÂ» de cette maniÃ¨re?  Il n'y avait qu'une seule faÃ§on de le dire.  Et fin 1999, j'ai tout arrangÃ© pour commencer Ã  explorer l'espace de tous les systÃ¨mes d'axiomes possibles, en commenÃ§ant par le plus simple. <br><br>  En un sens, tout systÃ¨me d'axiomes dÃ©finit un ensemble de contraintes, disons, sur p Â· q.  Elle ne dit pas ce qu'est p Â· q, elle ne donne que des propriÃ©tÃ©s que p Â· q doit satisfaire (par exemple, elle peut dire que q Â· p = p Â· q).  La question est alors de savoir s'il est possible de dÃ©duire de ces propriÃ©tÃ©s tous les thÃ©orÃ¨mes de la logique qui tiennent lorsque p Â· q est Nand [p, q]: ni plus ni moins. <br><br>  Quelque chose peut Ãªtre vÃ©rifiÃ© directement.  Nous pouvons prendre le systÃ¨me des axiomes et voir quelles formes p Â· q satisfont les axiomes, si p et q sont, disons, vrais et faux.  Si le systÃ¨me des axiomes est que q Â· p = p Â· q, alors oui, p Â· q peut Ãªtre Nand [p, q] - mais pas nÃ©cessairement.  Il peut Ã©galement s'agir de And [p, q] ou Equal [p, q], ou bien d'autres options qui ne satisfont pas aux mÃªmes niveaux que la fonction NAND en logique.  Mais au moment oÃ¹ nous arrivons au systÃ¨me axiome {((p Â· p) Â· q) Â· (q Â· p) = q}, nous arrivons Ã  l'Ã©tat dans lequel Nand [p, q] (et l'Ã©quivalent de Nor [p , q]) restent les seuls modÃ¨les p Â· q qui fonctionnent - du moins si nous supposons que q et p n'ont que deux valeurs possibles. <br><br>  S'agit-il alors d'un systÃ¨me d'axiomes pour la logique?  Non.  Parce que cela implique, par exemple, l'existence d'une variante oÃ¹ p et q ont trois valeurs, mais ce n'est pas dans la logique.  Cependant, le fait que ce systÃ¨me d'axiomes d'un axiome soit proche de ce dont nous avons besoin indique qu'il vaut la peine de chercher un seul axiome Ã  partir duquel la logique est reproduite.  C'est exactement ce que j'ai fait en janvier 2000 (Ã  notre Ã©poque, cette tÃ¢che a Ã©tÃ© facilitÃ©e grÃ¢ce Ã  la fonction assez nouvelle et trÃ¨s pratique de Wolfram Language, Groupements). <br><br>  Il Ã©tait assez facile de vÃ©rifier que les axiomes dans lesquels il y avait 3 NAND ou moins (ou Â«opÃ©rateurs de pointsÂ») ne fonctionnaient pas.  Ã€ 5 heures du matin le dimanche 29 janvier (oui, alors j'Ã©tais un hibou), j'ai dÃ©couvert que les axiomes contenant 4 NAND ne fonctionneraient pas non plus.  Lorsque j'ai arrÃªtÃ© de travailler vers 6 heures du matin, j'avais 14 candidats entre les mains de cinq NAND.  Mais en continuant Ã  travailler le dimanche soir et en effectuant des tests supplÃ©mentaires, j'ai dÃ» tous les abandonner. <br><br>  Inutile de dire que la prochaine Ã©tape consistait Ã  vÃ©rifier les axiomes avec 6 NAND.  Il y en avait 288 684. Mais mon code a fonctionnÃ© efficacement, et peu de temps s'est Ã©coulÃ© avant que les Ã©lÃ©ments suivants n'apparaissent Ã  l'Ã©cran (oui, de Mathematica version 4): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cb1/eb6/b59/cb1eb6b59aa53f1cc55cc91c2ec76271.png"></div><br>  Au dÃ©but, je ne comprenais pas ce que je faisais.  Je savais seulement que j'avais 25 axiomes non Ã©quivalents avec 6 NANDs qui ont pu avancer plus loin que les axiomes avec 5 NANDs.  Mais y avait-il parmi eux des axiomes qui gÃ©nÃ©raient de la logique?  J'avais une mÃ©thode empirique capable d'Ã©liminer les axiomes inutiles.  Mais la seule faÃ§on de savoir avec certitude l'exactitude d'un axiome particulier Ã©tait de prouver qu'il Ã©tait capable de reproduire avec succÃ¨s, par exemple, les axiomes de Schaeffer pour la logique. <br><br>  Il a fallu un peu de jeu avec les programmes, mais aprÃ¨s quelques jours, j'ai constatÃ© que la plupart des 25 axiomes reÃ§us ne fonctionnaient pas.  En consÃ©quence, deux ont survÃ©cu: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6f1/a4a/5e0/6f1a4a5e040e1acbd2e14406b8a05eff.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/311/20f/394/31120f394c33c0d1c95c0d22ee9caf45.png"></div><br>  Et Ã  ma grande joie, j'ai pu prouver Ã  l'aide d'un ordinateur que les deux sont des axiomes de la logique.  La technique utilisÃ©e garantit l'absence d'axiomes plus simples pour la logique.  Par consÃ©quent, je savais que j'avais atteint l'objectif: aprÃ¨s un siÃ¨cle (ou peut-Ãªtre quelques millÃ©naires) de recherches, nous pouvons enfin dire que nous avons trouvÃ© l'axiome le plus simple de la logique. <br><br>  Peu de temps aprÃ¨s, j'ai dÃ©couvert des systÃ¨mes de deux axiomes avec 6 NAND en gÃ©nÃ©ral, qui, comme je l'ai prouvÃ©, sont capables de reproduire la logique: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7b9/311/d22/7b9311d22392f15be81d05b43df9861c.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/920/f41/3e1/920f413e173d5e9c859b580d27eb3819.png"></div><br>  Et si nous prenons la commutativitÃ© p Â· q = q Â· p pour acquise, alors la logique peut Ãªtre obtenue Ã  partir de l'axiome contenant seulement 4 NAND. <br><br><h2>  Pourquoi est-ce important </h2><br>  Eh bien, disons que c'est trÃ¨s cool de pouvoir dire que quelqu'un "a terminÃ© le travail commencÃ© par Aristote" (ou du moins Boole) et a dÃ©couvert le systÃ¨me d'axiomes le plus simple possible pour la logique.  Est-ce juste un gadget, ou ce fait a-t-il des consÃ©quences importantes? <br><br>  Avant la plateforme que j'ai dÃ©veloppÃ©e dans A New Kind of Science, je pense qu'il serait difficile de considÃ©rer ce fait comme quelque chose de plus qu'une simple curiositÃ©.  Mais maintenant, il devrait Ãªtre clair qu'elle est liÃ©e Ã  toutes sortes de questions fondamentales, telles que la question de savoir si les mathÃ©matiques doivent Ãªtre considÃ©rÃ©es comme une dÃ©couverte ou une invention. <br><br>  Les mathÃ©matiques que les gens font sont basÃ©es sur une poignÃ©e de certains systÃ¨mes d'axiomes - chacun dÃ©finissant un domaine spÃ©cifique des mathÃ©matiques (logique, thÃ©orie des groupes, gÃ©omÃ©trie, thÃ©orie des ensembles).  Mais en parlant de faÃ§on abstraite, il existe un nombre infini de systÃ¨mes d'axiomes - chacun dÃ©finissant un domaine des mathÃ©matiques qui peut Ãªtre Ã©tudiÃ©, mÃªme si les gens ne l'ont pas encore fait. <br><br>  Avant le livre A New Kind of Science, je voulais dire que tout ce qui existe Â«quelque part lÃ -basÂ» dans l'univers informatique devrait Ãªtre Â«moins intÃ©ressantÂ» que ce que les gens ont crÃ©Ã© et Ã©tudiÃ©.  Mais mes dÃ©couvertes concernant les programmes simples indiquent que les systÃ¨mes qui Â«simplement quelque part lÃ -basÂ» n'ont pas des possibilitÃ©s moins riches que ces systÃ¨mes soigneusement sÃ©lectionnÃ©s par les gens. <br><br>  Alors qu'en est-il du systÃ¨me axiome pour les mathÃ©matiques?  Pour comparer le Â«quelque part lÃ -basÂ» existant avec ce que les gens ont Ã©tudiÃ©, vous devez savoir si les systÃ¨mes axiomatiques se situent dans les domaines mathÃ©matiques existants que nous avons Ã©tudiÃ©s.  Et, sur la base des systÃ¨mes traditionnels crÃ©Ã©s par les gens, nous pouvons conclure qu'ils doivent Ãªtre quelque part trÃ¨s, trÃ¨s loin - et en gÃ©nÃ©ral, ils ne peuvent Ãªtre trouvÃ©s que si vous savez dÃ©jÃ  oÃ¹ vous Ãªtes. <br><br>  Mais ma dÃ©couverte du systÃ¨me des axiomes a rÃ©pondu Ã  la question "Jusqu'oÃ¹ est la logique?"  Pour des choses comme un automate cellulaire, il est assez facile de numÃ©roter (comme je l'ai fait dans les annÃ©es 1980) tous les automates cellulaires possibles.  C'est un peu plus difficile Ã  faire avec les systÃ¨mes axiomes - mais pas de beaucoup.  Dans une approche, mon axiome peut Ãªtre notÃ© 411; 3; 7; 118 - ou, dans Wolfram Language: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/315/5d5/ef0/3155d5ef0d85da9df2a25e407c617625.png"></div><br>  Et, au moins dans l'espace des formes fonctionnelles possibles (sans tenir compte du balisage des variables), il y a une reprÃ©sentation visuelle de l'emplacement de cet axiome: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bb2/e6c/eb2/bb2e6ceb2b5a36d51e32d16727e89ef9.png"></div><br>  Ã‰tant donnÃ© l'importance fondamentale de la logique pour un si grand nombre de systÃ¨mes formels que les gens Ã©tudient, on pourrait penser que dans toute reprÃ©sentation raisonnable, la logique correspond Ã  l'un des systÃ¨mes d'axiomes les plus simples possibles.  Mais, au moins dans une prÃ©sentation utilisant NAND, ce n'est pas le cas.  Pour elle, il existe toujours un systÃ¨me d'axiomes trÃ¨s simple, mais il se rÃ©vÃ©lera probablement Ãªtre cent mille systÃ¨mes d'axiomes parmi tous ceux qui peuvent Ãªtre trouvÃ©s si vous commencez simplement Ã  numÃ©roter le systÃ¨me d'axiomes, en commenÃ§ant par le plus simple. <br><br>  Compte tenu de cela, la prochaine question Ã©vidente sera: qu'en est-il de tous les autres systÃ¨mes d'axiomes?  Comment se comportent-ils?  C'est ce numÃ©ro que le livre A New Kind of Science explore.  Et j'y affirme que les choses telles que les systÃ¨mes observÃ©s dans la nature sont le plus souvent dÃ©crites par ces Â«autres rÃ¨glesÂ» que nous pouvons trouver en numÃ©rotant les possibilitÃ©s. <br><br>  Quant aux systÃ¨mes d'axiomes, j'ai fait un tableau reprÃ©sentant ce qui se passe dans les "domaines des mathÃ©matiques" correspondant aux diffÃ©rents systÃ¨mes d'axiomes.  La sÃ©rie montre les consÃ©quences d'un certain systÃ¨me d'axiomes, et les encadrÃ©s indiquent la vÃ©ritÃ© d'un certain thÃ©orÃ¨me dans un systÃ¨me donnÃ© d'axiomes (oui, Ã  un moment donnÃ© le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">thÃ©orÃ¨me de GÃ¶del</a> entre en vigueur, aprÃ¨s quoi il devient incroyablement difficile de prouver ou de rÃ©futer un thÃ©orÃ¨me donnÃ© dans un systÃ¨me donnÃ© d'axiomes; en pratique, avec par mes mÃ©thodes, cela se produit un peu Ã  droite de ce qui est montrÃ© dans l'image). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/627/56f/8e5/62756f8e5e47459b575ad148feacee99.png"></div><br>  Y a-t-il quelque chose de fondamentalement spÃ©cial dans les domaines des mathÃ©matiques qui sont Â«recherchÃ©s par les gensÂ»?  Ã€ en juger par cette photo et d'autres, rien d'Ã©vident ne vient Ã  l'esprit.  Je soupÃ§onne qu'il n'y a qu'une seule caractÃ©ristique dans ces domaines - le fait historique qu'ils ont Ã©tÃ© Ã©tudiÃ©s.  (Vous pouvez faire des dÃ©clarations comme Â«elles dÃ©crivent le monde rÃ©elÂ» ou Â«liÃ©es au fonctionnement du cerveauÂ», mais les rÃ©sultats dÃ©crits dans le livre suggÃ¨rent le contraire). <br><br>  Eh bien, quelle est la signification de mon systÃ¨me d'axiomes pour la logique?  Sa taille vous fait sentir le contenu final de l'information de la logique en tant que systÃ¨me axiomatique.  Et cela nous oblige Ã  considÃ©rer - au moins pour l'instant - que nous devons considÃ©rer la logique plus comme une Â«construction inventÃ©e par l'hommeÂ» que comme une Â«dÃ©couverteÂ» qui s'est produite pour des Â«raisons naturellesÂ». <br><br>  Si l'histoire se dÃ©roulait diffÃ©remment et que nous cherchions constamment (comme cela est fait dans le livre) de nombreux systÃ¨mes d'axiomes les plus simples possibles, alors nous ouvririons probablement le systÃ¨me des axiomes Ã  la logique, comme le systÃ¨me dont nous trouvons les propriÃ©tÃ©s intÃ©ressantes.  Mais puisque nous avons Ã©tudiÃ© un si petit nombre de tous les systÃ¨mes d'axiomes possibles, je pense qu'il serait raisonnable de considÃ©rer la logique comme une Â«inventionÂ» - une construction spÃ©cialement crÃ©Ã©e. <br><br>  Dans un sens, au Moyen Ã‚ge, la logique ressemblait Ã  ceci - lorsque les syllogismes possibles (types d'arguments acceptables) Ã©taient reprÃ©sentÃ©s sous la forme de mnÃ©moniques latins comme bArbArA et cElErAnt.  Par consÃ©quent, il est maintenant intÃ©ressant de trouver une reprÃ©sentation mnÃ©monique de ce que nous connaissons maintenant comme le systÃ¨me d'axiomes le plus simple pour la logique. <br><br>  Ã€ partir de ((p Â· q) Â· r) Â· (p Â· ((p Â· r) Â· p)) = r, chaque p Â· q peut Ãªtre reprÃ©sentÃ© comme un prÃ©fixe ou une entrÃ©e polonaise (inverse Ã  "l'entrÃ©e polonaise inversÃ©e" de la calculatrice HP ) sous la forme de Dpq - par consÃ©quent, l'axiome entier peut Ãªtre Ã©crit comme = DDDpqrDpDDprpr.  Il existe Ã©galement un mnÃ©monique anglais sur ce sujet - FIGURE OuT Queue, oÃ¹ les rÃ´les p, q, r sont jouÃ©s par u, r, e.  Ou vous pouvez regarder les premiÃ¨res lettres des mots dans la phrase suivante (oÃ¹ B est l'opÃ©rateur, et p, q, r sont a, p, c): Â«Petit Ã  petit, un programme a calculÃ© le meilleur axiome binaire de l'algÃ¨bre boolÃ©enne couvrant tous les casÂ» [ le meilleur axiome binaire de l'algÃ¨bre de Boole calculÃ© au moyen d'un programme dÃ©crit progressivement tous les cas]. <br><br><h2>  MÃ©canique de la preuve </h2><br>  D'accord, alors comment prouvez-vous l'exactitude de mon systÃ¨me d'axiomes?  La premiÃ¨re chose qui vient Ã  l'esprit est de montrer qu'il est possible d'en dÃ©duire un systÃ¨me bien connu d'axiomes pour la logique - par exemple, le systÃ¨me d'axiomes de Schaeffer: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b5f/54a/161/b5f54a161b3ff941c7459003cd9dffd9.png"></div><br>  Il y a trois axiomes ici, et nous devons en dÃ©river chacun.  Voici ce que vous pouvez faire pour gÃ©nÃ©rer le premier, en utilisant la derniÃ¨re version de Wolfram Language: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/47b/f3e/10c/47bf3e10c7a79db3328816c3ff931a68.png"></div><br>  Il convient de noter qu'il est dÃ©sormais possible de le faire.  Dans Â«l'objet de la preuveÂ», il est Ã©crit que 54 Ã©tapes ont Ã©tÃ© utilisÃ©es pour la preuve.  Sur la base de cet objet, nous pouvons gÃ©nÃ©rer un Â«cahierÂ» qui dÃ©crit chacune des Ã©tapes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b2d/b12/0f3/b2db120f3a2bd50432ed16525ca72342.png"></div><br>  En gÃ©nÃ©ral, toute la sÃ©quence des lemmes intermÃ©diaires est prouvÃ©e ici, ce qui nous permet de dÃ©duire le rÃ©sultat final.  Entre les lemmes, il y a tout un rÃ©seau de dÃ©pendances mutuelles: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dc1/272/d6f/dc1272d6fd14710be4e2a49ec684efa8.png"></div><br>  Mais les rÃ©seaux impliquÃ©s dans la dÃ©rivation des trois axiomes dans le systÃ¨me d'axiomes de Scheffer - pour ce dernier, 504 Ã©tapes incroyables sont utilisÃ©es: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c33/0e5/d15/c330e5d159782e0d4cff4931f2b9f605.png"></div><br>  Oui, il est Ã©vident que ces rÃ©seaux sont assez dÃ©routants.  Mais avant de discuter de ce que signifie cette complexitÃ©, parlons de ce qui se passe Ã  chaque Ã©tape de cette preuve. <br><br>  L'idÃ©e principale est simple.  Imaginez que nous ayons un axiome qui est simplement Ã©crit comme p Â· q = q Â· p (mathÃ©matiquement, cela signifie que l'opÃ©rateur est commutatif).  Plus prÃ©cisÃ©ment, l'axiome dit que pour toute expression p et q, p Â· q est Ã©quivalent Ã  q Â· p. <br><br>  Eh bien, disons que nous voulons dÃ©duire de cet axiome que (a Â· b) Â· (c Â· d) = (d Â· c) Â· (b Â· a).  Cela peut Ãªtre fait en utilisant l'axiome pour convertir d Â· c en c Â· d, b Â· a en a Â· b, et enfin (c Â· d) Â· (a Â· b) en (a Â· b) Â· (c Â· d ) <br><br>  FindEquationalProof fait essentiellement la mÃªme chose, bien qu'il ne suive pas ces Ã©tapes exactement dans le mÃªme ordre et change Ã  la fois le cÃ´tÃ© gauche de l'Ã©quation et le droit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9f4/f43/f6b/9f4f43f6b97bb816052eeb50ec01dcb2.png"></div><br>  AprÃ¨s avoir reÃ§u une telle preuve, vous pouvez simplement suivre chaque Ã©tape et vÃ©rifier qu'elles donnent le rÃ©sultat indiquÃ©.  Mais comment trouver des preuves?  Il existe de nombreuses sÃ©quences possibles de permutations et de transformations.  Comment trouver une sÃ©quence qui amÃ¨ne avec succÃ¨s au rÃ©sultat final? <br><br>  On pourrait dÃ©cider: pourquoi ne pas essayer toutes les sÃ©quences possibles, et s'il y a une sÃ©quence de travail parmi elles, elle devrait finalement Ãªtre trouvÃ©e?<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le problÃ¨me est que vous pouvez arriver rapidement Ã  un nombre astronomique de sÃ©quences. </font><font style="vertical-align: inherit;">L'essentiel de l'art de prouver automatiquement les thÃ©orÃ¨mes consiste Ã  trouver des moyens de rÃ©duire le nombre de sÃ©quences Ã  vÃ©rifier. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela se glisse rapidement dans les dÃ©tails techniques, mais l'idÃ©e de base est facile Ã  discuter si vous connaissez les bases de l'algÃ¨bre. </font><font style="vertical-align: inherit;">Supposons que nous essayons de prouver un rÃ©sultat algÃ©brique comme</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fc0/402/9b6/fc04029b6fa134be318b5b9999d0beeb.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Il existe un moyen garanti de le faire: en appliquant simplement les rÃ¨gles de l'algÃ¨bre pour rÃ©vÃ©ler chaque cÃ´tÃ©, vous pouvez immÃ©diatement voir leur similitude: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c93/6e3/5b0/c936e35b0bf0addb94eece9e2379f15f.png"></div><br>  Pourquoi Ã§a marche?<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parce qu'il existe un moyen de travailler avec de telles expressions, en les rÃ©duisant systÃ©matiquement jusqu'Ã  ce qu'elles prennent une forme standard. Est-il possible de faire la mÃªme opÃ©ration dans des systÃ¨mes arbitraires d'axiomes? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pas tout de suite. En algÃ¨bre, cela fonctionne car il possÃ¨de une propriÃ©tÃ© spÃ©ciale qui garantit que vous pouvez toujours Â«vous dÃ©placerÂ» le long du chemin de la simplification des expressions. Mais dans les annÃ©es 1970, diffÃ©rents scientifiques ont dÃ©couvert Ã  plusieurs reprises de maniÃ¨re indÃ©pendante (sous des noms comme l'algorithme de Knuth-Bendix ou la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">base de GrÃ¶bner</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ) que mÃªme si le systÃ¨me axiomatique n'a pas la propriÃ©tÃ© interne nÃ©cessaire, il est possible de dÃ©couvrir des Â«ajoutsÂ» Ã  ce systÃ¨me dans lequel il il y en a.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Câ€™est ce qui se produit dans les preuves typiques fournies par FindEquationalProof (basÃ© sur le systÃ¨me de Valdmeister, Â«maÃ®tre des arbresÂ»). </font><font style="vertical-align: inherit;">Il y a ce qu'on appelle </font><font style="vertical-align: inherit;">Les Â«lemmes Ã  couple critiqueÂ», qui ne font pas directement avancer la preuve, mais permettent l'Ã©mergence de chemins capables de cela. </font><font style="vertical-align: inherit;">Tout est compliquÃ© du fait que, bien que l'expression finale que nous voulons obtenir soit assez courte, sur le chemin, vous devrez peut-Ãªtre passer par des expressions intermÃ©diaires beaucoup plus longues. </font><font style="vertical-align: inherit;">Par consÃ©quent, par exemple, la preuve du premier axiome de Schaeffer comporte de telles Ã©tapes intermÃ©diaires:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b0f/c98/287/b0fc98287cfb9bb8968eea6664aaa0ec.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dans ce cas, la plus grande des Ã©tapes est 4 fois plus grande que l'axiome d'origine: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cdd/885/774/cdd885774255091503fdb07d55fd8b0b.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ces expressions peuvent Ãªtre reprÃ©sentÃ©es comme un arbre. </font><font style="vertical-align: inherit;">Voici son arbre, comparÃ© Ã  l'arbre de l'axiome original:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a7f/465/f16/a7f465f1661555adf78695f71ea4fb8c.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Et c'est ainsi que se dÃ©veloppent les tailles des Ã©tapes intermÃ©diaires au cours des preuves de chacun des axiomes de Schaeffer: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5d2/ba7/c59/5d2ba7c5933f2d3d77b0b8acfb594020.png"></div><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pourquoi est-ce si difficile? </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faut-il s'Ã©tonner que ces preuves soient si complexes? </font><font style="vertical-align: inherit;">Pas vraiment, vraiment. </font><font style="vertical-align: inherit;">AprÃ¨s tout, nous savons bien que les mathÃ©matiques peuvent Ãªtre complexes. </font><font style="vertical-align: inherit;">En principe, il se pourrait que toutes les vÃ©ritÃ©s mathÃ©matiques soient faciles Ã  prouver. </font><font style="vertical-align: inherit;">Mais l'un des effets secondaires du thÃ©orÃ¨me de GÃ¶del de 1931 est que mÃªme les choses qui ont des preuves, leur chemin peut Ãªtre arbitrairement long. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C'est le symptÃ´me d'un phÃ©nomÃ¨ne beaucoup plus gÃ©nÃ©ral, que j'appelle </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">irrÃ©ductibilitÃ© informatique</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">ConsidÃ©rons un systÃ¨me contrÃ´lÃ© par une simple rÃ¨gle d'un automate cellulaire (bien sÃ»r, dans tous mes essais, il y aura toujours des automates cellulaires). </font><font style="vertical-align: inherit;">ExÃ©cutez ce systÃ¨me.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/511/f6e/5b2/511f6e5b21afb7a21c62622cab036fd4.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il pourrait Ãªtre dÃ©cidÃ© que si le systÃ¨me est basÃ© sur une rÃ¨gle simple, il devrait y avoir un moyen rapide de comprendre ce que fait le systÃ¨me.</font></font> Mais ce n'est pas le cas.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Selon mon </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">principe d'Ã©quivalence de calcul</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , le fonctionnement d'un systÃ¨me correspond souvent Ã  des calculs dont la complexitÃ© coÃ¯ncide avec tous les calculs que nous pourrions faire pour comprendre le comportement du systÃ¨me. Cela signifie que le comportement rÃ©el du systÃ¨me correspond en fait Ã  une telle quantitÃ© de travail de calcul, qui ne peut en principe pas Ãªtre rÃ©duit. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En ce qui concerne l'image ci-dessus: disons que nous voulons savoir si le motif meurt Ã  la fin. Nous pourrions continuer Ã  le remplir, et si nous avons de la chance, il finira par dÃ©gÃ©nÃ©rer en quelque chose, dont le sort sera Ã©vident. Cependant, en gÃ©nÃ©ral, il n'y a pas de limite supÃ©rieure sur le temps que nous devons consacrer, en fait, Ã  la preuve.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lorsque quelque chose comme cela se produit avec des preuves logiques, cela se produit un peu diffÃ©remment. Au lieu de commencer quelque chose qui fonctionne selon certaines rÃ¨gles, nous demandons s'il existe un moyen d'atteindre un certain rÃ©sultat en passant par plusieurs Ã©tapes, chacune obÃ©issant Ã  une certaine rÃ¨gle. Et cette tÃ¢che, en tant que tÃ¢che de calcul pratique, est beaucoup plus compliquÃ©e. Mais l'essence de la complexitÃ© est le mÃªme phÃ©nomÃ¨ne d'irrÃ©ductibilitÃ© informatique, et ce phÃ©nomÃ¨ne suggÃ¨re qu'il n'y a pas de moyen gÃ©nÃ©ral de contourner briÃ¨vement le processus d'Ã©tude de ce que le systÃ¨me fera.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Inutile de dire qu'il y a beaucoup de choses dans le monde - en particulier dans la technologie et la modÃ©lisation scientifique, ainsi que dans les domaines oÃ¹ il existe diffÃ©rentes formes de rÃ¨gles - traditionnellement conÃ§ues pour Ã©viter l'irrÃ©ductibilitÃ© informatique et pour travailler de sorte que le rÃ©sultat de leur travail soit immÃ©diatement visible, sans avoir Ã  effectuer une quantitÃ© irrÃ©ductible de calculs. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais l'une des consÃ©quences de mon principe d'Ã©quivalence informatique est que ces cas sont singuliers et non naturels - il soutient que l'irrÃ©ductibilitÃ© informatique existe dans tous les systÃ¨mes de l'univers informatique.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et les mathÃ©matiques? </font><font style="vertical-align: inherit;">Peut-Ãªtre que les rÃ¨gles des mathÃ©matiques sont spÃ©cifiquement choisies pour dÃ©montrer la rÃ©ductibilitÃ© du calcul. </font><font style="vertical-align: inherit;">Et dans certains cas, c'est le cas (et dans un sens, cela se produit Ã©galement en logique). </font><font style="vertical-align: inherit;">Mais pour la plupart, il semble que les systÃ¨mes d'axiomes des mathÃ©matiques ne soient pas atypiques pour l'espace de tous les systÃ¨mes possibles d'axiomes - oÃ¹ l'irrÃ©ductibilitÃ© informatique est endÃ©mique.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pourquoi avons-nous besoin de preuves? </font></font></h2><br>  Dans un sens, une preuve est nÃ©cessaire pour connaÃ®tre la vÃ©ritÃ© de quelque chose.  Bien sÃ»r, surtout Ã  notre Ã©poque, les preuves ont disparu dans le fond, laissant la place au calcul pur.  En pratique, le dÃ©sir de gÃ©nÃ©rer quelque chose par des calculs est beaucoup plus courant que le dÃ©sir de Â«prendre du reculÂ» et de construire une preuve de la vÃ©ritÃ© de quelque chose. <br><br>  En mathÃ©matiques pures, cependant, il faut souvent faire face Ã  des concepts qui incluent, au moins nominalement, un nombre infini de cas (Â«vrai pour tous les nombres premiersÂ», etc.) pour lesquels les calculs du front ne fonctionneront pas. .  Et lorsque la question se pose de confirmer ("ce programme peut-il se terminer avec une erreur?" Ou "puis-je dÃ©penser cette crypto-monnaie deux fois?") Il est plus raisonnable d'essayer de le prouver que de calculer tous les cas possibles. <br><br>  Mais dans la pratique mathÃ©matique rÃ©elle, la preuve est plus que l'Ã©tablissement de la vÃ©ritÃ©.  Quand Euclide a Ã©crit ses Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dÃ©buts</a> Â», il a simplement indiquÃ© les rÃ©sultats et Â«les a laissÃ©s au lecteurÂ».  Mais, d'une maniÃ¨re ou d'une autre, en particulier au cours du siÃ¨cle dernier, les preuves se sont transformÃ©es en quelque chose qui ne se produit pas seulement dans les coulisses, mais est le principal moyen par lequel il est nÃ©cessaire de diffuser des concepts. <br><br>  Il me semble qu'en raison de quelque bizarrerie de l'histoire, les preuves sont offertes aujourd'hui comme un objet que les gens devraient comprendre, et les programmes sont considÃ©rÃ©s comme quelque chose qu'un ordinateur devrait exÃ©cuter.  Pourquoi est-ce arrivÃ©?  Eh bien, au moins dans le passÃ©, les preuves pouvaient Ãªtre prÃ©sentÃ©es sous forme de texte - donc, si quelqu'un l'utilisait, alors seulement les gens.  Et les programmes Ã©taient presque toujours enregistrÃ©s sous la forme d'un langage informatique.  Et pendant trÃ¨s longtemps, ces langages ont Ã©tÃ© crÃ©Ã©s afin de pouvoir se traduire plus ou moins directement en opÃ©rations informatiques de bas niveau - c'est-Ã -dire que l'ordinateur les a compris immÃ©diatement, mais les gens n'ont pas Ã  le faire. <br><br>  Mais l'un des principaux objectifs de mon travail au cours des derniÃ¨res dÃ©cennies a Ã©tÃ© de changer cet Ã©tat de fait et de dÃ©velopper dans Wolfram Language un vÃ©ritable "langage de communication informatique" dans lequel les idÃ©es informatiques peuvent Ãªtre transmises afin qu'elles puissent Ãªtre comprises par les ordinateurs et les personnes. <br><br>  Une telle langue a de nombreuses consÃ©quences.  L'un d'eux change le rÃ´le des preuves.  Supposons que nous regardions un rÃ©sultat mathÃ©matique.  Dans le passÃ©, le seul moyen plausible de le faire comprendre Ã©tait de donner la preuve que les gens lisaient.  Mais maintenant, une autre chose est possible: vous pouvez distribuer un programme pour Wolfram Language qui calcule le rÃ©sultat.  Et c'est Ã  bien des Ã©gards un moyen beaucoup plus riche de transmettre la vÃ©ritÃ© du rÃ©sultat.  Chaque partie du programme est quelque chose de prÃ©cis et sans ambiguÃ¯tÃ© - tout le monde peut commencer.  Il n'y a pas de problÃ¨me tel que les tentatives de comprendre une partie du texte, nÃ©cessitant de combler certaines lacunes.  Tout est clairement indiquÃ© dans le texte. <br><br>  Et les preuves?  Existe-t-il des moyens clairs et prÃ©cis de rÃ©diger des preuves?  Potentiellement oui, bien que ce ne soit pas particuliÃ¨rement facile.  Et bien que la fondation Wolfram Language existe depuis 30 ans, ce n'est qu'aujourd'hui qu'un moyen raisonnable a semblÃ© prÃ©senter des preuves structurelles simples, comme l'un de mes axiomes ci-dessus. <br><br>  Vous pouvez imaginer crÃ©er des preuves dans Wolfram Language de la mÃªme maniÃ¨re que les gens crÃ©ent des programmes - et nous travaillons pour fournir des versions de haut niveau de cette fonctionnalitÃ© qui Â«aident Ã  la preuveÂ».  Cependant, personne n'a crÃ©Ã© la preuve de mon systÃ¨me d'axiomes - un ordinateur l'a trouvÃ©e.  Et cela ressemble plus Ã  la sortie du programme qu'au programme lui-mÃªme.  Cependant, comme un programme, dans un sens, la preuve peut Ã©galement Ãªtre Â«exÃ©cutÃ©eÂ» pour vÃ©rifier le rÃ©sultat. <br><br><h2>  CrÃ©er de la clartÃ© </h2><br>  La plupart du temps, les personnes utilisant le Wolfram Language, ou Wolfram | Alpha, veulent compter quelque chose.  Ils doivent obtenir le rÃ©sultat, ne pas comprendre pourquoi ils ont obtenu de tels rÃ©sultats.  Mais dans Wolfram | Alpha, en particulier dans des domaines tels que les mathÃ©matiques et la chimie, une caractÃ©ristique populaire parmi les Ã©tudiants est la construction de solutions "Ã©tape par Ã©tape". <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/77d/a19/015/77da190153b5c78394653c8bdee8bb98.png"></div><br>  Lorsque le systÃ¨me Wolfram | Alpha calcule, par exemple, une intÃ©grale, il utilise toutes sortes de techniques algorithmiques puissantes qui sont optimisÃ©es pour recevoir des rÃ©ponses.  Mais quand on lui demande de montrer les Ã©tapes des calculs, elle fait autre chose: elle doit expliquer par Ã©tapes pourquoi c'est le rÃ©sultat obtenu. <br><br>  Il n'y aurait aucun avantage Ã  expliquer comment le rÃ©sultat a Ã©tÃ© obtenu;  Il s'agit d'un processus trÃ¨s inappropriÃ© pour les humains.  Elle doit comprendre quelles opÃ©rations apprises par les gens peuvent Ãªtre utilisÃ©es pour obtenir un rÃ©sultat.  Souvent, elle trouve une astuce utile.  Oui, elle a un moyen systÃ©matique de le faire, qui fonctionne toujours.  Mais il y a trop d'Ã©tapes "mÃ©caniques".  Une Â«astuceÂ» (substitution, intÃ©gration partielle, etc.) ne fonctionnera pas dans le cas gÃ©nÃ©ral, mais dans ce cas particulier, elle donnera un moyen plus rapide Ã  la rÃ©ponse. <br><br>  Qu'en est-il d'obtenir des versions claires d'autres choses?  Par exemple, le travail des programmes dans le cas gÃ©nÃ©ral.  Ou des preuves de mon systÃ¨me axiome. <br><br>  CommenÃ§ons par les programmes.  Supposons que nous ayons Ã©crit un programme et que nous voulions expliquer comment il fonctionne.  L'une des approches traditionnelles consiste Ã  inclure des commentaires dans le code.  Si nous Ã©crivons dans une langue traditionnelle de bas niveau, c'est peut-Ãªtre la meilleure solution.  Mais l'essence mÃªme de Wolfram Language en tant que langage de communication informatique est que le langage lui-mÃªme devrait permettre la transmission d'idÃ©es, sans avoir besoin d'inclure des morceaux de texte supplÃ©mentaires. <br><br>  Des efforts doivent Ãªtre faits pour faire du programme Wolfram Language une bonne description du processus, ainsi que pour faire du texte anglais clair une bonne description du processus.  Cependant, vous pouvez obtenir un morceau de code Wolfram Language qui explique trÃ¨s clairement comment tout fonctionne de maniÃ¨re autonome. <br><br>  Bien sÃ»r, il arrive souvent que l'exÃ©cution rÃ©elle du code mÃ¨ne Ã  des choses qui ne dÃ©coulent Ã©videmment pas du programme.  Je mentionnerai bientÃ´t les cas extrÃªmes comme les automates cellulaires.  Mais pour l'instant, imaginons que nous avons crÃ©Ã© un programme par lequel nous pouvons imaginer ce qu'il fait gÃ©nÃ©ralement. <br><br>  Dans ce cas, j'ai trouvÃ© que les essais informatiques prÃ©sentÃ©s sous forme de cahiers Wolfram sont un excellent outil pour expliquer ce qui se passe.  Il est important que Wolfram Language, cela vous permet d'exÃ©cuter mÃªme les plus petites parties de programmes sÃ©parÃ©ment (avec les expressions symboliques correspondantes en tant que donnÃ©es d'entrÃ©e et de sortie).  AprÃ¨s cela, vous pouvez imaginer la sÃ©quence des Ã©tapes du programme comme une sÃ©quence d'Ã©lÃ©ments du dialogue qui constitue la base du bloc-notes informatique. <br><br>  En pratique, il est souvent nÃ©cessaire de crÃ©er des visualisations des donnÃ©es d'entrÃ©e et de sortie.  Oui, tout peut Ãªtre exprimÃ© comme une reprÃ©sentation symbolique sans ambiguÃ¯tÃ©.  Mais il est beaucoup plus facile pour les gens de comprendre la reprÃ©sentation visuelle des choses que toute ligne unidimensionnelle semblable Ã  un langage. <br><br>  Bien sÃ»r, crÃ©er de bonnes visualisations s'apparente Ã  de l'art.  Mais chez Wolfram Language, nous avons fait beaucoup de travail pour automatiser cet art - souvent Ã  l'aide d'un apprentissage automatique assez sophistiquÃ© et d'autres algorithmes qui effectuent des choses comme la disposition des rÃ©seaux ou des Ã©lÃ©ments graphiques. <br><br>  Et si on commenÃ§ait par un simple suivi de programme?  C'est difficile Ã  faire.  J'expÃ©rimente cela depuis des dÃ©cennies et je n'ai jamais Ã©tÃ© complÃ¨tement satisfait des rÃ©sultats.  Oui, vous pouvez zoomer et voir de nombreux dÃ©tails de ce qui se passe.  Mais je n'ai pas trouvÃ© suffisamment de bonnes techniques pour comprendre l'ensemble de l'image et donner automatiquement des choses particuliÃ¨rement utiles. <br><br>  Ã€ un certain niveau, cette tÃ¢che est similaire Ã  la rÃ©tro-ingÃ©nierie.  On vous montre un code machine, un circuit Ã  puce, peu importe.  Et vous devez prendre du recul et recrÃ©er la description de haut niveau Ã  partir de laquelle la personne repoussÃ©e, qui en quelque sorte Â«compilÃ©Â» dans ce que vous voyez. <br><br>  Dans l'approche traditionnelle de l'ingÃ©nierie, lorsque les gens crÃ©ent un produit par Ã©tapes, ayant toujours la capacitÃ© d'anticiper les consÃ©quences de ce qu'ils crÃ©ent, cette approche peut fonctionner en principe.  Mais si au lieu de cela vous vous promenez dans l'univers informatique Ã  la recherche d'un programme optimal (comme je cherchais des systÃ¨mes d'axiomes possibles pour trouver un systÃ¨me de logique), il n'y a aucune garantie qu'il y aura une "histoire humaine" ou une explication derriÃ¨re ce programme. <br><br>  Un problÃ¨me similaire se rencontre dans les sciences naturelles.  Vous voyez comment un ensemble complexe de toutes sortes de processus se dÃ©veloppe dans un systÃ¨me biologique.  Est-il possible de les soumettre Ã  une Â«rÃ©tro-ingÃ©nierieÂ» afin de trouver une Â«explicationÂ»?  On peut parfois dire que l'Ã©volution avec la sÃ©lection naturelle y conduira.  Ou qu'il se trouve souvent dans l'univers informatique, de sorte que la probabilitÃ© de son occurrence est Ã©levÃ©e.  Mais rien ne garantit que le monde naturel est nÃ©cessairement conÃ§u pour que les gens puissent l'expliquer. <br><br>  Naturellement, lors de la modÃ©lisation des choses, nous ne considÃ©rons inÃ©vitablement que les aspects qui nous intÃ©ressent et idÃ©alisons tout le reste.  Et surtout dans des domaines comme la mÃ©decine, vous devez souvent travailler avec un modÃ¨le approximatif avec un arbre de dÃ©cision peu profond, ce qui est facile Ã  expliquer. <br><br><h2>  La nature de l'explicabilitÃ© </h2><br>  Que signifie l'expression Â«quelque chose peut Ãªtre expliquÃ©Â»?  Essentiellement, cela signifie que les gens peuvent le comprendre. <br><br>  Que faut-il aux gens pour comprendre quelque chose?  Nous devons en quelque sorte rÃ©aliser cela.  Prenez un automate cellulaire typique avec un comportement complexe.  L'ordinateur n'a pas de problÃ¨mes pour passer par toutes les Ã©tapes de son Ã©volution.  Avec des efforts et un travail Ã©normes, une personne pourrait reproduire le travail d'un ordinateur. <br><br>  Mais on ne peut pas dire que dans ce cas, une personne "comprendrait" ce que fait un automate cellulaire.  Pour cela, une personne devrait facilement parler du comportement d'un automate cellulaire Ã  un niveau Ã©levÃ©.  Ou, en d'autres termes, une personne devrait Ãªtre capable de Â«raconter une histoireÂ» sur le comportement d'un automate que d'autres personnes pourraient comprendre. <br><br>  Existe-t-il un moyen universel de procÃ©der?  Non, en raison de l'irrÃ©ductibilitÃ© informatique.  Cependant, il peut arriver que certaines fonctionnalitÃ©s importantes pour les utilisateurs puissent Ãªtre expliquÃ©es Ã  un niveau Ã©levÃ© avec certaines limitations. <br><br>  Comment Ã§a marche?  Pour ce faire, vous devez crÃ©er un certain langage de haut niveau qui peut dÃ©crire les fonctionnalitÃ©s qui nous intÃ©ressent.  En Ã©tudiant un dessin typique de l'automate cellulaire, on peut essayer de parler non pas en termes de couleurs d'un grand nombre de cellules individuelles, mais en termes de structures d'un niveau supÃ©rieur qui peuvent Ãªtre dÃ©tectÃ©es.  L'essentiel est que vous puissiez compiler au moins un catalogue partiel de telles structures: bien qu'il y ait beaucoup de dÃ©tails qui ne rentrent pas dans la classification, certaines structures sont courantes. <br><br>  Et si nous voulons commencer Ã  Â«expliquerÂ» le comportement d'un automate cellulaire, nous commencerons par nommer les structures, puis nous parlerons de ce qui se passe du point de vue de ces structures. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b79/395/b3b/b79395b3bad1a1a63252ad645d54cc4b.png"></div><br>  Le cas de l'automate cellulaire a une caractÃ©ristique simplificatrice: puisqu'il fonctionne sur la base de rÃ¨gles dÃ©terministes simples, il a des structures Ã©galement rÃ©pÃ©titives.  Dans la nature, par exemple, nous ne rencontrons gÃ©nÃ©ralement pas une rÃ©pÃ©tition aussi identique.  Il n'y a qu'un seul, par exemple, un tigre, trÃ¨s similaire Ã  l'autre, c'est pourquoi nous les appelons tous les deux Â«tigresÂ», bien que la disposition de leurs atomes ne soit pas identique. <br><br>  Quelle est la signification gÃ©nÃ©rale de tout cela?  Elle consiste Ã  utiliser l'idÃ©e de reprÃ©sentation symbolique.  Nous disons que nous pouvons attribuer un certain symbole - souvent ce mot - qui peut Ãªtre utilisÃ© pour dÃ©crire symboliquement toute une classe de choses, sans avoir Ã  Ã©numÃ©rer en dÃ©tail chaque dÃ©tail de tous les composants de ces choses. <br><br>  Ceci est similaire Ã  la compression d'informations: nous utilisons des constructions symboliques pour trouver une maniÃ¨re plus courte de dÃ©crire les choses qui nous intÃ©ressent. <br><br>  Supposons que nous ayons gÃ©nÃ©rÃ© une structure gigantesque, par exemple mathÃ©matique: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/27d/923/5ac/27d9235ac9fd46bd22ef8c526e0afbc6.png"></div><br>  La premiÃ¨re Ã©tape consiste Ã  crÃ©er une sorte de reprÃ©sentation interne de haut niveau.  Par exemple, nous pouvons dÃ©tecter des structures rÃ©utilisables.  Et nous pouvons leur donner des noms.  Et puis montrez le "squelette" de la structure entiÃ¨re avec leur aide: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ba2/102/c89/ba2102c898a14c573ddd207694fd5696.png"></div><br>  Oui, ce schÃ©ma, similaire Ã  la Â«compression de dictionnaireÂ», est utile pour atteindre le premier niveau d'explicabilitÃ©. <br><br>  Mais revenons Ã  la preuve de mon systÃ¨me d'axiomes.  Les lemmes crÃ©Ã©s dans cette Ã©preuve sont spÃ©cialement sÃ©lectionnÃ©s comme Ã©lÃ©ments rÃ©utilisables.  Cependant, en les excluant, il nous reste des preuves que les gens ne peuvent pas comprendre immÃ©diatement. <br><br>  Que pouvez-vous faire d'autre?  Nous devons trouver une sorte de description d'un niveau encore plus Ã©levÃ©.  Qu'est-ce que Ã§a pourrait Ãªtre? <br><br><h2>  Concept de concepts </h2><br>  Si vous essayez d'expliquer quelque chose Ã  quelqu'un, il sera beaucoup plus facile de le faire si vous trouvez autre chose, mais similaire qu'une personne pourrait dÃ©jÃ  comprendre.  Imaginez comment vous expliquerez le concept d'un drone moderne Ã  une personne de l'Ã¢ge de pierre.  Ce sera difficile Ã  faire.  Mais il sera beaucoup plus facile d'expliquer cela Ã  une personne qui vivait il y a 50 ans et qui a dÃ©jÃ  vu des hÃ©licoptÃ¨res et des modÃ¨les rÃ©duits d'avions. <br><br>  Et Ã  la fin, l'essentiel est que lorsque nous expliquons quelque chose, nous le faisons dans une langue connue de nous et de celle Ã  qui nous l'expliquons.  Et plus la langue est riche, moins nous devons introduire de nouveaux Ã©lÃ©ments pour transmettre ce que nous essayons d'expliquer. <br><br>  Il y a un modÃ¨le qui se rÃ©pÃ¨te tout au long de l'histoire de l'esprit.  Un certain ensemble de choses sont remarquÃ©es plusieurs fois.  Peu Ã  peu, ils commencent Ã  comprendre que ces choses sont en quelque sorte abstraitement similaires, et toutes peuvent Ãªtre dÃ©crites en termes d'un nouveau concept, qui est dÃ©crit dans un nouveau mot ou une phrase. <br><br>  Supposons que nous remarquions des choses comme l'eau, le sang et l'huile.  Ã€ un certain moment, nous comprenons qu'il existe un concept gÃ©nÃ©ralisÃ© de Â«liquideÂ», et tous peuvent Ãªtre dÃ©crits comme liquides.  Et quand nous avons un tel concept, nous pouvons commencer Ã  raisonner en ses termes, en trouvant plus de concepts - disons la viscositÃ©, basÃ©s sur lui. <br><br>  Quand est-il judicieux de combiner les choses en un concept?  Une question difficile Ã  laquelle on ne peut rÃ©pondre sans prÃ©voir tout ce qui peut Ãªtre fait avec ce concept.  En pratique, dans le processus d'Ã©volution du langage et des idÃ©es d'une personne, un certain processus d'approximation successive est observÃ©. <br><br>  Dans le systÃ¨me moderne d'apprentissage automatique, la sommation des informations est beaucoup plus rapide.  Imaginez que nous prenions toutes sortes d'objets Ã  travers le monde et que nous les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">alimentions en</a> fonctions <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FeatureSpacePlot</a> pour voir ce qui se passe.  Si nous obtenons certains clusters dans l'espace des fonctionnalitÃ©s, nous pouvons conclure que chacun d'eux peut Ãªtre dÃ©fini comme correspondant Ã  un certain Â«conceptÂ», qui, par exemple, peut Ãªtre marquÃ© avec un mot. <br><br>  HonnÃªtement, ce qui arrive Ã  FeatureSpacePlot - comme dans le processus de dÃ©veloppement intellectuel humain - est, en un sens, un processus Ã©tape par Ã©tape.  Pour distribuer des objets par espace d'entitÃ©, FeatureSpacePlot utilise des fonctions qu'il a apprises Ã  extraire des tentatives prÃ©cÃ©dentes de catÃ©gorisation. <br><br>  Eh bien, si nous acceptons le monde tel qu'il est, quelles sont les meilleures catÃ©gories - ou concepts - qui peuvent Ãªtre utilisÃ©es pour dÃ©crire les choses?  Cette question est en constante Ã©volution.  En gÃ©nÃ©ral, toutes les percÃ©es - qu'il s'agisse de science, de technologie ou d'autre chose - sont souvent prÃ©cisÃ©ment associÃ©es Ã  la rÃ©alisation de la possibilitÃ© d'identifier une nouvelle catÃ©gorie ou un nouveau concept de maniÃ¨re utile. <br><br>  Mais dans le processus d'Ã©volution de notre civilisation, il y a une certaine spirale.  Tout d'abord, un certain concept dÃ©fini est dÃ©fini - disons, l'idÃ©e d'un programme.  AprÃ¨s cela, les gens commencent Ã  l'utiliser et Ã  rÃ©flÃ©chir dans ses termes.  BientÃ´t, de nombreux concepts diffÃ©rents sont construits sur la base de ce concept.  Et puis un autre niveau d'abstraction est dÃ©terminÃ©, de nouveaux concepts basÃ©s sur le prÃ©cÃ©dent sont crÃ©Ã©s. <br><br>  L'histoire est caractÃ©ristique de l'ensemble technologique de connaissances de la civilisation moderne et de son ensemble intellectuel de connaissances.  LÃ  et lÃ , il y a des tours de concepts et des niveaux d'abstraction qui se succÃ¨dent. <br><br><h2>  ProblÃ¨me d'apprentissage </h2><br>  Pour que les gens puissent communiquer en utilisant un certain concept, ils doivent le savoir.  Et, oui, certains concepts (comme la constance des objets) sont automatiquement reconnus par les gens simplement en observant la nature.  Mais supposons que, si vous regardez la liste des mots courants de l'anglais moderne, il deviendra clair que la plupart des concepts utilisÃ©s par notre civilisation moderne ne s'appliquent pas Ã  ceux que les gens connaissent d'eux-mÃªmes, observant la nature. <br><br>  Au lieu de cela - qui rappelle beaucoup l'apprentissage automatique moderne - ils ont besoin d'une connaissance spÃ©ciale du monde "sous surveillance", organisÃ©e afin de souligner l'importance de certains concepts.  Et dans des domaines plus abstraits (comme les mathÃ©matiques), ils ont probablement besoin de rencontrer des concepts sous leur forme abstraite immÃ©diate. <br><br>  Eh bien, mais aurons-nous besoin d'apprendre de plus en plus tout le temps avec l'augmentation de la quantitÃ© de connaissances intellectuelles accumulÃ©es de la civilisation?  On peut craindre qu'Ã  un moment donnÃ©, notre cerveau ne puisse tout simplement pas suivre le dÃ©veloppement, et nous devrons ajouter une aide supplÃ©mentaire.  Mais il me semble que c'est heureusement un de ces cas oÃ¹ le problÃ¨me peut Ãªtre rÃ©solu "au niveau logiciel". <br><br>  Le problÃ¨me est le suivant: Ã  tout moment de l'histoire, il existe un certain ensemble de concepts qui sont importants pour la vie dans le monde Ã  cette Ã©poque.  Et, oui, avec le dÃ©veloppement de la civilisation, de nouveaux concepts sont rÃ©vÃ©lÃ©s et de nouveaux concepts sont introduits.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cependant, il existe un autre processus: les nouveaux concepts introduisent de nouveaux niveaux d'abstraction, comprenant gÃ©nÃ©ralement un grand nombre de concepts antÃ©rieurs. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous pouvons souvent observer cela dans la technologie. Il fut un temps oÃ¹ vous deviez connaÃ®tre beaucoup de dÃ©tails de bas niveau pour travailler sur un ordinateur. Mais au fil du temps, ces dÃ©tails se sont rÃ©sumÃ©s, alors maintenant vous n'avez besoin que d'un concept gÃ©nÃ©ral. Vous cliquez sur l'icÃ´ne et le processus dÃ©marre - vous n'avez pas besoin de comprendre les subtilitÃ©s du fonctionnement des systÃ¨mes d'exploitation, des gestionnaires d'interruption, des planificateurs et tous les autres dÃ©tails.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et bien sÃ»r, Wolfram Language en fournit un excellent exemple. Cela met beaucoup d'efforts Ã  automatiser un grand nombre de dÃ©tails de bas niveau (par exemple, lequel des algorithmes doit Ãªtre utilisÃ©) et permet aux utilisateurs de penser dans des concepts de haut niveau. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Oui, il faut toujours des gens qui comprennent les dÃ©tails qui sous-tendent les abstractions (bien que je ne sais pas combien de tailleurs de pierre la sociÃ©tÃ© moderne a besoin). Mais pour la plupart, l'Ã©ducation peut se concentrer sur un haut niveau de connaissances.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">On suppose souvent que pour atteindre des concepts de haut niveau dans le processus d'apprentissage, une personne doit d'abord rÃ©sumer en quelque sorte l'histoire de la faÃ§on dont ces concepts sont devenus historiquement. Mais gÃ©nÃ©ralement - et, peut-Ãªtre, toujours - il semble que ce ne soit pas le cas. Vous pouvez donner un exemple extrÃªme: imaginez que pour apprendre Ã  utiliser un ordinateur, vous devez d'abord parcourir toute l'histoire de la logique mathÃ©matique. Cependant, on sait en fait que les gens se tournent immÃ©diatement vers les concepts modernes de l'informatique, sans avoir besoin d'Ã©tudier une sorte d'histoire. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais Ã  quoi ressemble alors la clartÃ© du rÃ©seau de concepts? Y a-t-il des concepts qui ne peuvent Ãªtre compris qu'en comprenant d'autres concepts? Ã‰tant donnÃ© la formation des personnes sur la base de l'interaction avec l'environnement (ou la formation d'un rÃ©seau de neurones), leur ordre peut probablement exister.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais il me semble qu'un certain principe, similaire Ã  l'universalitÃ© de l'informatique, suggÃ¨re qu'avec un Â«cerveau purÂ» en main, on peut partir de n'importe oÃ¹. </font><font style="vertical-align: inherit;">Donc, si certains extraterrestres apprenaient la thÃ©orie des catÃ©gories et presque rien d'autre, ils construiraient, sans aucun doute, un rÃ©seau de concepts oÃ¹ cette thÃ©orie est Ã  la racine, et ce que nous connaissons comme les bases de l'arithmÃ©tique serait Ã©tudiÃ© Ã  partir d'eux quelque part dans l'analogue de notre institut. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien sÃ»r, de tels extraterrestres pourraient construire leur ensemble de technologies et leur environnement d'une maniÃ¨re trÃ¨s diffÃ©rente de nous - tout comme notre histoire pourrait devenir complÃ¨tement diffÃ©rente si les ordinateurs pouvaient Ãªtre dÃ©veloppÃ©s avec succÃ¨s au 19Ã¨me siÃ¨cle, et non au milieu du 20Ã¨me.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Progression mathÃ©matique </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">J'ai souvent rÃ©flÃ©chi Ã  la mesure dans laquelle la trajectoire historique des mathÃ©matiques est soumise au rÃ´le du hasard et dans quelle mesure elle Ã©tait inÃ©vitable. Comme je l'ai dÃ©jÃ  mentionnÃ©, au niveau des systÃ¨mes formels, il existe de nombreux systÃ¨mes d'axiomes possibles sur lesquels vous pouvez construire quelque chose qui ressemble formellement aux mathÃ©matiques. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais la vÃ©ritable histoire des mathÃ©matiques n'a pas commencÃ© avec un systÃ¨me arbitraire d'axiomes. Il a commencÃ© au temps des Babyloniens avec des tentatives d'utiliser l'arithmÃ©tique pour le commerce et la gÃ©omÃ©trie Ã  des fins d'amÃ©nagement du territoire. Et Ã  partir de ces racines pratiques, des niveaux d'abstraction ont commencÃ© Ã  s'ajouter, ce qui a finalement conduit aux mathÃ©matiques modernes - par exemple, les nombres ont Ã©tÃ© progressivement gÃ©nÃ©ralisÃ©s des entiers positifs au rationnel, puis aux racines, puis Ã  tous les entiers, aux fractions dÃ©cimales, aux nombres complexes, Ã  l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">algÃ¨bre nombres</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, aux </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">quaternions</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , etc. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y a-t-il une fatalitÃ© d'une telle voie de dÃ©veloppement des abstractions? </font><font style="vertical-align: inherit;">Je soupÃ§onne, dans une certaine mesure, oui. </font><font style="vertical-align: inherit;">C'est peut-Ãªtre le cas avec d'autres types de formation de concepts. </font><font style="vertical-align: inherit;">Ayant atteint un certain niveau, vous avez la possibilitÃ© d'Ã©tudier diverses choses, et au fil du temps, des groupes de ces choses deviennent des exemples de constructions plus gÃ©nÃ©rales et abstraites - qui Ã  leur tour dÃ©terminent un nouveau niveau, Ã  partir duquel, on peut apprendre quelque chose de nouveau. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Existe-t-il des moyens de sortir de ce cycle? </font><font style="vertical-align: inherit;">Une possibilitÃ© peut Ãªtre liÃ©e aux expÃ©riences mathÃ©matiques. </font><font style="vertical-align: inherit;">On peut systÃ©matiquement prouver des choses liÃ©es Ã  certains systÃ¨mes mathÃ©matiques. </font><font style="vertical-align: inherit;">Mais on peut empiriquement juste remarquer des faits mathÃ©matiques - comme </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ramanujan</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> une fois remarquÃ© que </font></font><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msup><mi>e</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>&amp;#x03C0;</mi><msqrt><mn>163</mn></msqrt></mrow></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.092ex" height="2.78ex" viewBox="0 -1091.4 2623.1 1197.1" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/431956/&amp;usg=ALkJrhj2dS8gVAZPxDzc3pfQcuju8BHQNw#MJMATHI-65" x="0" y="0"></use><g transform="translate(466,362)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/431956/&amp;usg=ALkJrhj2dS8gVAZPxDzc3pfQcuju8BHQNw#MJMATHI-3C0" x="0" y="0"></use><g transform="translate(405,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/431956/&amp;usg=ALkJrhj2dS8gVAZPxDzc3pfQcuju8BHQNw#MJMAIN-221A" x="0" y="26"></use><rect stroke="none" width="1061" height="42" x="589" y="543"></rect><g transform="translate(589,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/431956/&amp;usg=ALkJrhj2dS8gVAZPxDzc3pfQcuju8BHQNw#MJMAIN-31"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/431956/&amp;usg=ALkJrhj2dS8gVAZPxDzc3pfQcuju8BHQNw#MJMAIN-36" x="500" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/431956/&amp;usg=ALkJrhj2dS8gVAZPxDzc3pfQcuju8BHQNw#MJMAIN-33" x="1001" y="0"></use></g></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>e</mi><mrow class="MJX-TeXAtom-ORD"><mi>Ï€</mi><msqrt><mn>163</mn></msqrt></mrow></msup></math></span></span><script type="math/tex" id="MathJax-Element-1">e^{\pi \sqrt{163}}</script><br><br><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De la mÃªme maniÃ¨re que l'on peut numÃ©roter les systÃ¨mes axiomatiques, on peut imaginer la numÃ©rotation des questions possibles en mathÃ©matiques. Mais cela pose immÃ©diatement un problÃ¨me. Le thÃ©orÃ¨me de GÃ¶del dÃ©clare que dans des systÃ¨mes d'axiomes tels que ceux liÃ©s Ã  l'arithmÃ©tique, il existe des thÃ©orÃ¨mes Â«formellement insolublesÂ» qui ne peuvent pas Ãªtre prouvÃ©s ou rÃ©futÃ©s dans le cadre de ce systÃ¨me d'axiomes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cependant, les exemples spÃ©cifiques crÃ©Ã©s par GÃ¶del semblaient trÃ¨s loin de ce qui pouvait rÃ©ellement se produire dans les cours de mathÃ©matiques. Et pendant longtemps, on a cru que le phÃ©nomÃ¨ne d'insolvabilitÃ© Ã©tait en quelque sorte quelque chose qui, en principe, existe, mais ne sera pas liÃ© aux Â«mathÃ©matiques rÃ©ellesÂ».</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cependant, selon mon principe d'Ã©quivalence informatique et mon expÃ©rience dans l'univers informatique, je suis Ã  peu prÃ¨s sÃ»r que ce n'est pas le cas - et qu'en fait, l'insolvabilitÃ© est trÃ¨s proche mÃªme en mathÃ©matiques typiques. Je ne serais pas surpris qu'une partie tangible des problÃ¨mes de mathÃ©matiques non rÃ©solus aujourd'hui ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">hypothÃ¨se de Riemann</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , P = NP, etc.) soit insoluble.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais s'il y a beaucoup d'insolvabilitÃ©, comment se fait-il que tant de choses en mathÃ©matiques soient rÃ©solues avec succÃ¨s? Je pense que c'est parce que les problÃ¨mes rÃ©solus avec succÃ¨s ont Ã©tÃ© spÃ©cialement choisis pour Ã©viter l'insolvabilitÃ©, simplement en raison de la faÃ§on dont le dÃ©veloppement des mathÃ©matiques est construit. Parce que si, en fait, nous formons des niveaux d'abstraction successifs sur la base de concepts que nous avons prouvÃ©s, alors nous ouvrons la voie qui peut aller de l'avant sans se transformer en insolubilitÃ©. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien sÃ»r, les mathÃ©matiques expÃ©rimentales ou les Â«questions alÃ©atoiresÂ» peuvent immÃ©diatement nous conduire Ã  un domaine plein d'insolvabilitÃ©. Mais, du moins pour l'instant, la discipline de base des mathÃ©matiques ne s'est pas dÃ©veloppÃ©e de cette faÃ§on.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et qu'en est-il de ces "faits alÃ©atoires des mathÃ©matiques"? Oui, comme pour les autres domaines de recherche intellectuelle. Les Â«faits alÃ©atoiresÂ» ne sont pas inclus dans la voie du dÃ©veloppement intellectuel tant qu'une structure - gÃ©nÃ©ralement quelques concepts abstraits - n'est pas construite autour d'eux. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un bon exemple est ma dÃ©couverte prÃ©fÃ©rÃ©e de l'origine de la complexitÃ© dans de tels systÃ¨mes, gÃ©nÃ©ralement 30 automates cellulaires. Oui, des phÃ©nomÃ¨nes similaires ont dÃ©jÃ  Ã©tÃ© observÃ©s il y a mÃªme des milliers d'annÃ©es (par exemple, le hasard dans une sÃ©quence de nombres premiers). Mais sans une plate-forme conceptuelle plus large, peu de gens y ont prÃªtÃ© attention.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un autre exemple est celui des sÃ©quences imbriquÃ©es (fractales). Il y a quelques exemples de la faÃ§on dont ils se sont rencontrÃ©s dans la mosaÃ¯que du XIIIe siÃ¨cle, mais personne n'y a prÃªtÃ© attention jusqu'Ã  ce que dans les annÃ©es 1980 une plate-forme entiÃ¨re apparaisse autour des fractales. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La mÃªme histoire se rÃ©pÃ¨te encore et encore: tant que les concepts abstraits ne sont pas dÃ©finis, il est difficile de parler de nouveaux concepts, mÃªme face Ã  un phÃ©nomÃ¨ne qui les dÃ©montre. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je soupÃ§onne que c'est le cas en mathÃ©matiques: il y a une certaine superposition inÃ©vitable de certains concepts abstraits au-dessus d'autres, qui dÃ©termine le chemin des mathÃ©matiques. Cette faÃ§on est-elle unique? Sans doute, non. Dans le vaste espace des faits mathÃ©matiques possibles, certaines directions sont choisies pour d'autres constructions. Mais vous pouvez en choisir d'autres.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Est-ce Ã  dire que les sujets en mathÃ©matiques sont inÃ©vitablement entraÃ®nÃ©s par des accidents historiques? </font><font style="vertical-align: inherit;">Pas autant qu'on pourrait le penser. </font><font style="vertical-align: inherit;">En effet, comme les mathÃ©matiques ont Ã©tÃ© dÃ©couvertes Ã  maintes reprises, en commenÃ§ant par des choses comme l'algÃ¨bre et la gÃ©omÃ©trie, il existe une tendance remarquable dans laquelle diffÃ©rentes directions et diffÃ©rentes approches conduisent Ã  des rÃ©sultats Ã©quivalents ou correspondant les uns aux autres. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Peut-Ãªtre, dans une certaine mesure, cela est une consÃ©quence du principe d'Ã©quivalence informatique et du phÃ©nomÃ¨ne d'universalitÃ© informatique: bien que les rÃ¨gles de base (ou Â«langageÂ») utilisÃ©es dans diffÃ©rents domaines des mathÃ©matiques diffÃ¨rent, le rÃ©sultat est un moyen de traduire entre elles - et au niveau suivant d'abstraction. le chemin choisi ne sera plus aussi critique.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Preuve logique et automatisation de l'abstraction </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Revenons aux preuves logiques. Comment sont-ils liÃ©s aux mathÃ©matiques typiques? Jusqu'Ã  prÃ©sent, aucun moyen. Oui, la preuve a nominalement la mÃªme forme que la preuve mathÃ©matique standard. Mais ce n'est pas "convivial pour les maths". Ce ne sont que des piÃ¨ces mÃ©caniques. Il n'est pas associÃ© Ã  des concepts abstraits de haut niveau qui seront comprÃ©hensibles par les mathÃ©matiques humaines. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela nous aiderait beaucoup si nous trouvions que des lemmes de preuve non triviaux sont dÃ©jÃ  apparus dans la littÃ©rature mathÃ©matique (je ne pense pas, mais nos possibilitÃ©s de recherche par thÃ©orÃ¨mes nâ€™ont pas encore atteint un niveau tel que nous pouvons en Ãªtre sÃ»rs). Mais s'ils apparaissent, cela nous donnera probablement un moyen de relier ces lemmes Ã  d'autres choses en mathÃ©matiques et de dÃ©finir leur cercle de concepts abstraits.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais comment rendre les preuves explicables sans cela? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Peut-Ãªtre existe-t-il une autre maniÃ¨re de rÃ©aliser la preuve, fondamentalement plus fortement liÃ©e aux mathÃ©matiques existantes. Mais mÃªme avec les preuves que nous avons maintenant, on peut imaginer Â«peaufinerÂ» de nouveaux concepts qui dÃ©finiraient un niveau d'abstraction plus Ã©levÃ© et placeraient cette preuve dans un contexte plus gÃ©nÃ©ral. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je ne sais pas comment faire Ã§a. J'envisageais de proposer un prix (quelque chose comme mon </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">prix Turing 2007</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) pour Â«transformer des preuves en une forme comprÃ©hensibleÂ». Cependant, il est totalement incomprÃ©hensible de savoir comment Ã©valuer Â«l'explicabilitÃ©Â». On pourrait Ãªtre invitÃ© Ã  enregistrer une vidÃ©o d'une heure dans laquelle une explication rÃ©ussie de la preuve serait donnÃ©e, adaptÃ©e Ã  un mathÃ©maticien typique - mais ce serait trÃ¨s subjectif. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais de la mÃªme maniÃ¨re qu'il est possible d'automatiser la recherche de belles dispositions de rÃ©seaux, nous pouvons peut-Ãªtre automatiser le processus de transformation des preuves en explicables. La preuve actuelle, en fait, sans explication, suggÃ¨re de considÃ©rer plusieurs centaines de lemmes. Mais supposons que nous puissions dÃ©finir un petit nombre de lemmes Â«intÃ©ressantsÂ». Peut-Ãªtre pourrions-nous en quelque sorte les ajouter Ã  notre canon des mathÃ©matiques cÃ©lÃ¨bres, puis nous pourrions les utiliser pour comprendre la preuve.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il y a une analogie avec le dÃ©veloppement des langues. En crÃ©ant le Wolfram Language, j'essaie d'identifier les Â«morceaux de travail informatiqueÂ» dont les gens ont souvent besoin. Nous crÃ©ons Ã  partir d'eux des fonctions intÃ©grÃ©es dans le langage, avec des noms spÃ©cifiques que les gens peuvent utiliser pour s'y rÃ©fÃ©rer. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un processus similaire est en cours - bien que pas du tout organisÃ© de la sorte - dans l'Ã©volution des langues naturelles. Les Â«morceaux de sensÂ» qui se rÃ©vÃ¨lent utiles finissent par faire passer leurs mots dans la langue. Parfois, ils commencent par des phrases composÃ©es de plusieurs mots existants. Mais les plus influents s'avÃ¨rent gÃ©nÃ©ralement si Ã©loignÃ©s des mots existants qu'ils apparaissent sous forme de nouveaux mots, qui sont potentiellement assez difficiles Ã  dÃ©finir.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le dÃ©veloppement de la langue Wolfram, dont les fonctions sont appelÃ©es Ã  l'aide de mots anglais, je me fie Ã  la comprÃ©hension gÃ©nÃ©rale de la langue anglaise par une personne (et parfois Ã  la comprÃ©hension des mots utilisÃ©s dans les applications informatiques courantes). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il faudrait faire quelque chose de similaire pour dÃ©terminer quels lemmes ajouter au canon mathÃ©matique. Il faudrait non seulement s'assurer que chaque lemme serait en quelque sorte Â«essentiellement intÃ©ressantÂ», mais aussi sÃ©lectionner des lemmes Â«faciles Ã  dÃ©duireÂ» des concepts et rÃ©sultats mathÃ©matiques existants. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais qu'est-ce qui rend le lemme Â«essentiellement intÃ©ressantÂ»? Il faut dire qu'avant de travailler sur mon livre, j'ai blÃ¢mÃ© le choix des lemmes (ou tours) dans n'importe quel domaine des mathÃ©matiques dÃ©crit et nommÃ© dans les manuels, le grand arbitraire et les accidents historiques.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais, aprÃ¨s avoir analysÃ© en dÃ©tail les thÃ©orÃ¨mes de la logique de base, j'ai Ã©tÃ© surpris de trouver quelque chose de complÃ¨tement diffÃ©rent. Supposons que nous avons construit tous les thÃ©orÃ¨mes corrects de la logique dans l'ordre de leur taille </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">(par exemple, p = p sera le premier, p ET p = p - un peu plus tard, etc.). Cette liste a beaucoup de redondance. La plupart des thÃ©orÃ¨mes s'avÃ¨rent Ãªtre une extension triviale des thÃ©orÃ¨mes qui sont dÃ©jÃ  apparus sur la liste. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais parfois, un thÃ©orÃ¨me apparaÃ®t qui produit de nouvelles informations qui ne peuvent pas Ãªtre prouvÃ©es sur la base de thÃ©orÃ¨mes qui sont dÃ©jÃ  apparus sur la liste. Un fait remarquable: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">il existe 14 de ces thÃ©orÃ¨mes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , et ils correspondent, en substance, exactement aux thÃ©orÃ¨mes qui sont gÃ©nÃ©ralement donnÃ©s des noms dans les manuels de logique (ici ET est âˆ§, OU est âˆ¨, et PAS est Â¬.)</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a00/078/057/a0007805787992eee313fa748deba866.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En d'autres termes, dans ce cas, les thÃ©orÃ¨mes nommÃ©s ou Â«intÃ©ressantsÂ» sont prÃ©cisÃ©ment ceux qui font des dÃ©clarations sur de nouvelles informations d'une taille minimale. Oui, selon cette dÃ©finition, aprÃ¨s un certain temps, de nouvelles informations n'existeront plus, car nous obtiendrons tous les axiomes nÃ©cessaires pour prouver tout ce qui est possible - bien que vous puissiez aller plus loin en commenÃ§ant Ã  limiter la complexitÃ© des preuves admissibles. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'en est-il des thÃ©orÃ¨mes NAND, par exemple, ceux trouvÃ©s dans la preuve? Encore une fois, vous pouvez construire tous les vrais thÃ©orÃ¨mes dans l'ordre, et trouver ceux qui ne peuvent pas Ãªtre prouvÃ©s sur la base des thÃ©orÃ¨mes prÃ©cÃ©dents de la liste:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3a8/4b3/022/3a84b3022c9b5408ce524671b006c814.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NAND n'a pas de tradition historique comme ET, OU et NON. Et, apparemment, il n'y a pas de langage humain dans lequel NAND est dÃ©signÃ© par un mot. Mais dans la liste des thÃ©orÃ¨mes NAND, le premier des prÃ©cÃ©dents est facilement reconnu comme commutativitÃ© de NAND. AprÃ¨s cela, seules quelques traductions sont nÃ©cessaires pour leur donner des noms: a = (a Â· a) Â· (a Â· a) est comme la double nÃ©gation, a = (a Â· a) Â· (a Â· b) est comme la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">loi d'absorption</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , (a Â· A) Â· b = (a Â· b) Â· b est similaire Ã  "l'affaiblissement", et ainsi de suite. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Eh bien, si nous allons apprendre quelques Â«thÃ©orÃ¨mes clÃ©sÂ» de la logique NAND, quel genre de thÃ©orÃ¨mes devraient-ils Ãªtre? Peut-Ãªtre que ce devraient Ãªtre des Â«lemmes populairesÂ» dans les Ã©preuves.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien sÃ»r, tout thÃ©orÃ¨me peut avoir de nombreuses preuves possibles. Mais supposons que nous n'utilisions que les preuves produites par FindEquationalProof. Il s'avÃ¨re ensuite que dans la preuve des mille premiers thÃ©orÃ¨mes NAND, le lemme le plus populaire est a Â· a = a Â· ((a Â· a) Â· a), suivi de lemmes du type (a Â· (((a Â· a) Â· a)) Â· ( a (a ((a a) a))) = a. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quels sont ces lemmes? Ils sont utiles pour les mÃ©thodes utilisÃ©es par FindEquationalProof. Mais pour les gens, ils ne semblent pas trÃ¨s adaptÃ©s. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'en est-il des lemmes qui se rÃ©vÃ¨lent courts? a Â· b = b Â· a n'est certainement pas le plus populaire, mais le plus court. (a Â· a) Â· (a Â· a) = a est plus populaire, mais plus long. Et puis il y a des lemmes tels que (a Â· a) Â· (b Â· a) = a.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle sera l'utilitÃ© de ces lemmes? Voici une faÃ§on de vÃ©rifier cela. Examinons les mille premiers thÃ©orÃ¨mes NAND et Ã©valuons comment l'ajout de lemmes raccourcit les preuves de ces thÃ©orÃ¨mes (au moins celles trouvÃ©es par FindEquationalProof):</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/549/2f6/5d5/5492f65d5a0b28d9b2ad56e910d4a673.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a Â· b = b Â· a est trÃ¨s efficace et coupe souvent la preuve de prÃ¨s de 100 Ã©tapes. </font><font style="vertical-align: inherit;">(a Â· a) Â· (a Â· a) = a a beaucoup moins de succÃ¨s; </font><font style="vertical-align: inherit;">il Â«confond parfoisÂ» FindEquationalProof, vous forÃ§ant Ã  prendre plus de mesures que nÃ©cessaire (valeurs nÃ©gatives sur les graphiques). </font><font style="vertical-align: inherit;">(a Â· a) Â· (b Â· a) = a rÃ©siste bien Ã  la contraction, mais pas aussi bien que a Â· b = b Â· a. </font><font style="vertical-align: inherit;">Cependant, si vous le combinez avec a Â· b = b Â· a, par consÃ©quent, les rÃ©ductions se produisent plus souvent. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'analyse peut Ãªtre poursuivie, par exemple, en incluant une comparaison de la mesure dans laquelle un lemme particulier raccourcit la longueur des preuves par rapport Ã  leur longueur d'origine. </font><font style="vertical-align: inherit;">Mais le problÃ¨me est que si vous ajoutez quelques "lemmes utiles" comme a Â· b = b Â· a et (a Â· a) Â· (b Â· a) = a, il y a encore beaucoup de preuves longues - c'est-Ã -dire, beaucoup de ce qui est nÃ©cessaire Pour comprendre.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5c5/410/c0e/5c5410c0e4690236d76c45f5e32e53f3.png"></div><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Que pouvons-nous comprendre? </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il existe diffÃ©rentes faÃ§ons de modÃ©liser les choses. Pendant plusieurs centaines d'annÃ©es, les sciences exactes ont Ã©tÃ© dominÃ©es par l'idÃ©e de trouver des Ã©quations mathÃ©matiques qui pourraient Ãªtre rÃ©solues pour montrer comment le systÃ¨me se comporterait. Mais depuis l'avÃ¨nement de mon livre, il y a eu un changement actif vers la crÃ©ation de programmes que vous pouvez exÃ©cuter pour voir comment les systÃ¨mes vont se comporter. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Parfois, ces programmes sont Ã©crits pour une tÃ¢che spÃ©cifique; parfois, ils sont recherchÃ©s depuis longtemps. Et Ã  notre Ã©poque, au moins une classe de ces programmes est dÃ©rivÃ©e en utilisant l'apprentissage automatique, par la mÃ©thode du mouvement inverse Ã  partir d'exemples connus de comportement du systÃ¨me.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et est-il facile de Â«comprendre ce qui se passeÂ» avec ces diffÃ©rents types de modÃ©lisation? Trouver la Â«solution exacteÂ» des Ã©quations mathÃ©matiques est un gros plus - alors le comportement du systÃ¨me peut Ãªtre dÃ©crit par une formule mathÃ©matique exacte. Mais mÃªme lorsque ce n'est pas le cas, il est souvent possible d'Ã©crire quelques Ã©noncÃ©s mathÃ©matiques suffisamment abstraits pour Ãªtre liÃ©s Ã  d'autres systÃ¨mes et comportements. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comme je l'ai Ã©crit ci-dessus, avec un programme - comme un automate cellulaire - tout peut Ãªtre diffÃ©rent. TrÃ¨s souvent, il arrive que nous rencontrons immÃ©diatement une irrÃ©ductibilitÃ© informatique, ce qui limite notre capacitÃ© Ã  aller un peu plus loin et Ã  Â«expliquerÂ» ce qui se passe.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'en est-il de l'apprentissage automatique et des rÃ©seaux de neurones? En un sens, la formation au rÃ©seau neuronal est comme un bref rÃ©sumÃ© de la recherche inductive en cours dans les sciences naturelles. Nous essayons, Ã  partir d'exemples, de dÃ©duire un modÃ¨le de comportement du systÃ¨me. Mais sera-t-il alors possible de comprendre le modÃ¨le? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et encore une fois, il y a des problÃ¨mes d'irrÃ©ductibilitÃ© informatique. Mais discutons d'un cas dans lequel nous pouvons imaginer Ã  quoi ressemblerait la situation dans lequel nous pouvons comprendre ce qui se passe.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Au lieu d'utiliser un rÃ©seau de neurones pour simuler le comportement du systÃ¨me, examinons la crÃ©ation d'un rÃ©seau de neurones qui classe certains aspects du monde: par exemple, prendre des images et les distribuer en fonction de leur contenu (Â«bateauÂ», Â«girafeÂ», etc.). Lorsque nous formons le rÃ©seau neuronal, il apprend Ã  produire la sortie correcte. Mais vous pouvez potentiellement imaginer ce processus comme une construction interne d'une sÃ©quence de diffÃ©rences (quelque chose comme un jeu de " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vingt questions</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> "), qui dÃ©termine finalement la conclusion correcte.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais quelles sont ces diffÃ©rences? Parfois, nous pouvons les reconnaÃ®tre. Par exemple, "Y a-t-il beaucoup de bleu dans l'image?" Mais la plupart du temps, ce sont des propriÃ©tÃ©s du monde que les gens ne remarquent pas. Peut-Ãªtre existe-t-il une histoire alternative des sciences naturelles dans laquelle certaines d'entre elles se rÃ©vÃ©leraient. Mais ils ne font pas partie du canon actuel de la perception ou de l'analyse. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si nous voulions les ajouter, nous pourrions peut-Ãªtre trouver des noms pour eux. Mais cette situation est similaire Ã  la situation avec des preuves logiques. Le systÃ¨me automatique a crÃ©Ã© certaines choses qu'il utilise comme jalons pour gÃ©nÃ©rer le rÃ©sultat. Mais nous ne reconnaissons pas ces jalons, ils ne signifient rien pour nous.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Encore une fois, si nous avons constatÃ© que certaines diffÃ©rences spÃ©cifiques se retrouvent souvent dans les rÃ©seaux de neurones, nous pourrions dÃ©cider qu'elles mÃ©ritent d'Ãªtre Ã©tudiÃ©es par nous-mÃªmes et les ajouter au canon standard des faÃ§ons de dÃ©crire le monde. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pouvons-nous nous attendre Ã  ce qu'un petit nombre de ces diffÃ©rences nous permettent de crÃ©er quelque chose de significatif? Il semble que la question soit de savoir si un petit nombre de thÃ©orÃ¨mes nous aidera Ã  comprendre une telle chose comme preuve logique. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je pense que la rÃ©ponse n'est pas claire. Si vous Ã©tudiez, par exemple, un grand nombre d'ouvrages scientifiques en mathÃ©matiques, vous pouvez poser des questions sur la frÃ©quence d'utilisation de divers thÃ©orÃ¨mes. Il s'avÃ¨re que la frÃ©quence des thÃ©orÃ¨mes correspond presque parfaitement </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ã  la loi de Zipf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (et en premier lieu il y aura un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">thÃ©orÃ¨me central limite</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ,</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">thÃ©orÃ¨me de </font></font></a><font style="vertical-align: inherit;"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">fonction implicite</font></a><font style="vertical-align: inherit;"> et </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">thÃ©orÃ¨me de Tonelli-Fubini</font></a><font style="vertical-align: inherit;"> ). </font><font style="vertical-align: inherit;">La mÃªme chose se produit probablement avec des diffÃ©rences qui Â«valent la peine d'Ãªtre connuesÂ», ou avec de nouveaux thÃ©orÃ¨mes qui Â«valent la peine d'Ãªtre connusÂ». </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La connaissance de plusieurs thÃ©orÃ¨mes nous donnera l'opportunitÃ© d'avancer assez loin, mais il y aura toujours une queue exponentielle infinie, et nous n'arriverons pas Ã  la fin.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> L'avenir de la connaissance </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En Ã©tudiant les mathÃ©matiques, la science ou la technologie, vous pouvez voir des voies de base similaires de dÃ©veloppement qualitatif, consistant Ã  construire un ensemble d'abstractions toujours croissantes. </font><font style="vertical-align: inherit;">Ce serait bien de quantifier ce processus. </font><font style="vertical-align: inherit;">Il est peut-Ãªtre possible de calculer comment certains termes ou descriptions qui se trouvent souvent en mÃªme temps sont inclus dans des niveaux d'abstraction plus Ã©levÃ©s, auxquels de nouveaux termes ou descriptions apparaissent Ã  leur tour en relation avec eux.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il peut Ãªtre possible de crÃ©er un modÃ¨le idÃ©alisÃ© de ce processus en utilisant un modÃ¨le formel de calcul tel que les machines de Turing. Imaginez qu'au niveau le plus bas, il y ait une machine de Turing de base sans abstractions. Imaginez maintenant que nous sÃ©lectionnions des programmes pour cette machine de Turing selon un processus alÃ©atoire spÃ©cifique. Ensuite, nous exÃ©cutons ces programmes et les analysons pour voir quel modÃ¨le du niveau de calcul "supÃ©rieur" peut reproduire avec succÃ¨s le comportement conjoint de ces programmes sans avoir Ã  effectuer chaque Ã©tape de chacun d'eux.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il pourrait Ãªtre dÃ©cidÃ© que l'irrÃ©ductibilitÃ© du calcul conduirait au fait que la crÃ©ation de ce modÃ¨le de calcul de niveau supÃ©rieur serait inÃ©vitablement plus compliquÃ©e. Mais le point clÃ© est que nous essayons seulement de reproduire le comportement commun des programmes, et non leur comportement sÃ©parÃ©. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais que se passe-t-il si ce processus se rÃ©pÃ¨te encore et encore, reproduisant l'histoire intellectuelle idÃ©alisÃ©e de l'homme et crÃ©ant une tour d'abstractions toujours plus Ã©levÃ©e? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vraisemblablement, nous pouvons ici faire une analogie avec les phÃ©nomÃ¨nes critiques en physique et la mÃ©thode du </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">groupe de renormalisation</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Si c'est le cas, nous pouvons imaginer que nous pouvons dÃ©terminer la trajectoire dans l'espace des plates-formes pour reprÃ©senter les concepts. Que fera cette trajectoire?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Peut-Ãªtre aura-t-il une valeur fixe quand, Ã  n'importe quel moment de l'histoire, il y aura Ã  peu prÃ¨s autant d'Ã©tudes valables sur les concepts - de nouveaux concepts s'ouvriront lentement et les anciens seront absorbÃ©s. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'est-ce que cela signifie pour les mathÃ©matiques? </font><font style="vertical-align: inherit;">Par exemple, que tout Â«fait mathÃ©matique alÃ©atoireÂ» dÃ©couvert empiriquement sera finalement considÃ©rÃ© lorsquâ€™il atteindra un certain niveau dâ€™abstraction. </font><font style="vertical-align: inherit;">Il n'y a pas de comprÃ©hension Ã©vidente du fonctionnement de ce processus. </font><font style="vertical-align: inherit;">En effet, Ã  tout niveau d'abstraction, il y a toujours de nouveaux faits empiriques auxquels il faut "sauter". </font><font style="vertical-align: inherit;">Il peut Ã©galement arriver que Â«l'Ã©lÃ©vation du niveau d'abstractionÂ» se dÃ©place plus lentement que nÃ©cessaire pour ces Â«sautsÂ».</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> L'avenir de la comprÃ©hension </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'est-ce que tout cela signifie pour la comprÃ©hension future? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le passÃ©, lorsque les gens Ã©tudiaient la nature, ils avaient un petit nombre de raisons pour la comprendre. Parfois, ils en personnifiaient certains aspects sous la forme d'esprits ou de divinitÃ©s. Mais ils l'ont acceptÃ© tel quel, sans penser Ã  la possibilitÃ© de comprendre tous les dÃ©tails des causes des processus. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Avec l'avÃ¨nement de la science moderne - et surtout quand de plus en plus de nos vies sont passÃ©es dans des environnements artificiels dominÃ©s par les technologies dÃ©veloppÃ©es par nous - ces attentes ont changÃ©. Et lorsque nous Ã©tudions les calculs effectuÃ©s par l'IA, nous n'aimons pas que nous ne les comprenions pas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cependant, il y aura toujours une compÃ©tition entre ce que font les systÃ¨mes de notre monde et ce que notre cerveau peut calculer Ã  partir de leur comportement. Si nous dÃ©cidons d'interagir uniquement avec des systÃ¨mes beaucoup plus simples que le cerveau en puissance de calcul, alors nous pouvons nous attendre Ã  pouvoir comprendre systÃ©matiquement ce qu'ils font. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais si nous voulons utiliser toutes les capacitÃ©s informatiques disponibles dans l'univers, alors inÃ©vitablement, les systÃ¨mes avec lesquels nous interagissons atteindront la puissance de traitement de notre cerveau. Et cela signifie que, selon le principe de l'irrÃ©ductibilitÃ© informatique, nous ne pouvons jamais systÃ©matiquement Â«dÃ©passerÂ» ou Â«comprendreÂ» le fonctionnement de ces systÃ¨mes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais comment alors les utiliser? Eh bien, tout comme les humains ont toujours utilisÃ© les systÃ¨mes de la nature. Bien sÃ»r, nous ne connaissons pas tous les dÃ©tails de leur travail ou de leurs capacitÃ©s. Mais Ã  un certain niveau d'abstraction, nous en savons assez pour comprendre comment atteindre nos objectifs avec leur aide. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Qu'en est-il des domaines comme les mathÃ©matiques? En mathÃ©matiques, nous sommes habituÃ©s Ã  construire notre ensemble de connaissances afin de pouvoir comprendre chaque Ã©tape. Mais les mathÃ©matiques expÃ©rimentales - ainsi que des fonctionnalitÃ©s telles que la preuve automatique des thÃ©orÃ¨mes - mettent en Ã©vidence l'existence de domaines dans lesquels une telle mÃ©thode ne sera pas disponible pour nous.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les appellerons-nous Â«mathÃ©matiquesÂ»? </font><font style="vertical-align: inherit;">Je pense qu'ils devraient. </font><font style="vertical-align: inherit;">Mais cette tradition est diffÃ©rente de celle Ã  laquelle nous sommes habituÃ©s au cours du dernier millÃ©naire. </font><font style="vertical-align: inherit;">Nous pouvons encore y crÃ©er des abstractions et construire de nouveaux niveaux de comprÃ©hension. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais quelque part dans sa base, il y aura toutes sortes de versions diffÃ©rentes de l'irrÃ©ductibilitÃ© informatique, que nous ne pourrons jamais transfÃ©rer dans le domaine de la comprÃ©hension humaine. </font><font style="vertical-align: inherit;">C'est Ã  peu prÃ¨s ce qui se passe dans la preuve de mon petit axiome de logique. </font><font style="vertical-align: inherit;">Ceci est un exemple prÃ©coce de ce que je pense Ãªtre l'un des principaux aspects des mathÃ©matiques - et bien plus - Ã  l'avenir.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr431956/">https://habr.com/ru/post/fr431956/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr431944/index.html">Yealink Meeting Server 2.0 - Nouvelles fonctionnalitÃ©s de vidÃ©oconfÃ©rence</a></li>
<li><a href="../fr431946/index.html">Semaine de la sÃ©curitÃ© 49: piratage de Dell et Marriott</a></li>
<li><a href="../fr431948/index.html">Deep Mind a appris Ã  son IA Ã  prÃ©dire la structure des protÃ©ines</a></li>
<li><a href="../fr431950/index.html">Comment prÃ©voir la demande et automatiser les achats Ã  l'aide de l'apprentissage automatique: cas Ozon</a></li>
<li><a href="../fr431954/index.html">L'ancien vice-prÃ©sident de Sun et DEC devient prÃ©sident de MIPS / Wave, parle de la Russie et de RISC / V</a></li>
<li><a href="../fr431958/index.html">La centrale Ã©lectrique Ã  batterie virtuelle de Tesla s'Ã©tend Ã  1 000 foyers australiens</a></li>
<li><a href="../fr431960/index.html">Nvidia devient fou et ouvre PhysX sous BSD-3</a></li>
<li><a href="../fr431964/index.html">Fusionner les tris</a></li>
<li><a href="../fr431968/index.html">Grande FAQ sur les trains longue distance et les rÃ¨gles non Ã©videntes</a></li>
<li><a href="../fr431970/index.html">DÃ©partement de support: attente vs rÃ©alitÃ©</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
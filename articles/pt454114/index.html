<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêò üè§ üö£ Experi√™ncia no uso do Starwind VSAN e do EMC ScaleIO (VxFlexOS) + dicas para o armazenamento mini Enterprise (1 parte) üìâ üì© üôãüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√Äs vezes, torna-se necess√°rio organizar um armazenamento tolerante a falhas de pequenos volumes de armazenamento de at√© 20 TB, mas com a funcionalidad...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Experi√™ncia no uso do Starwind VSAN e do EMC ScaleIO (VxFlexOS) + dicas para o armazenamento mini Enterprise (1 parte)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454114/"> √Äs vezes, torna-se necess√°rio organizar um armazenamento tolerante a falhas de pequenos volumes de armazenamento de at√© 20 TB, mas com a funcionalidade Enterprise - All-Flash, cache SSD, MPIO, HA (Activ-Activ) e tudo isso a um pre√ßo acess√≠vel.  As solu√ß√µes de hardware prontas com essas fun√ß√µes partem de centenas de terabytes e pre√ßos de 8 ou mais sinais em rublos.  Ter um pequeno or√ßamento de 6-7 caracteres no rio.  e a necessidade de um armazenamento pequeno e r√°pido (mas confi√°vel), desde 2009 duas vers√µes dos sistemas de armazenamento foram testadas e colocadas em opera√ß√£o comercial (o comum com esses sistemas √© que eles s√£o sistemas altamente confi√°veis ‚Äã‚Äãsem um √∫nico ponto de falha + voc√™ pode toc√°-los antes da compra ou "fazer sem ele" (GR√ÅTIS)). <br><br>  Quem est√° interessado nessa experi√™ncia, ser√° descrito a seguir: <br><br><ol><li>  Experi√™ncia de software <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">StarWind Virtual SAN (VSAN)</a> . </li><li>  Como fazer um pequeno armazenamento corporativo. </li><li>  Hist√≥rico de overclocking de IOPS (pr√°tica). </li><li>  Dicas para a implanta√ß√£o e opera√ß√£o dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sistemas</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">armazenamento EMC ScaleIO (VxFlexOS)</a> (na aus√™ncia de suporte t√©cnico dos especialistas do ‚ÄúNOT Linux-guru‚Äù) 1 parte. </li></ol><a name="habracut"></a><br><h2>  1. Experi√™ncia operacional Software StarWind Virtual SAN (VSAN) </h2><br>  <b>StarWind Virtual SAN (VSAN)</b> - na solu√ß√£o Activ-Activ (replica√ß√£o s√≠ncrona em 3 servidores), em opera√ß√£o de 2009 a 2016 em diferentes edi√ß√µes (Starwind ISCSI SAN HA-3) com base em servidores com matrizes RAID de hardware. <br><br>  <i>Pr√≥s</i> : <br><br><ul><li>  F√°cil e r√°pido, nem mesmo instalado por um profissional; </li><li>  MPIO sobre Ethernet iSCSI; </li><li>  HA (Ativa√ß√£o-Ativa√ß√£o); </li><li>  Em novos servidores (com garantia) (com novos discos), voc√™ pode esquecer a manuten√ß√£o do armazenamento por v√°rios anos (os usu√°rios nem notam a falha de dois em cada tr√™s servidores); </li><li>  Volumes de cache RAM e SSD; </li><li>  R√°pido Sincroniza√ß√£o r√°pida para pequenas interrup√ß√µes na rede. </li></ul><br>  <i>Contras</i> : <br><br><ul><li>  Anteriormente, havia apenas uma vers√£o para a plataforma Windows; </li><li>  Em opera√ß√µes de longo prazo (mais de 3 anos) - √© dif√≠cil encontrar uma unidade para substituir uma falha (fora de produ√ß√£o) para reparar uma matriz RAID (com discos heterog√™neos, podem ocorrer falhas na matriz); </li><li>  Um aumento no n√∫mero de interfaces de rede e nos slots PCI ocupados por elas (adicionalmente para sincroniza√ß√£o, placas de rede, comutadores); </li><li>  Ao usar o LSFS - ‚Äúsistema de arquivos de registro no di√°rio‚Äù, desligamento prolongado do sistema, que pode ser prejudicial quando o no-break √© acionado quando a energia √© desligada; </li><li>  Um tempo muito longo de sincroniza√ß√£o completa com um grande volume. </li></ul><br>  <i>Talvez j√° tenha solucionado problemas</i> (ocorridos anteriormente durante a opera√ß√£o em nosso data center): <br><br><ul><li>  Quando a matriz RAID √© recolhida, o servidor permanece vis√≠vel atrav√©s do canal de sincroniza√ß√£o e dados, mas o disco no servidor Windows est√° offline, o registro Starwind √© inflado e a mem√≥ria do servidor √© consumida, como resultado do congelamento do servidor.  Tratamento poss√≠vel: atribui√ß√£o de um arquivo de controle e remo√ß√£o de mensagens n√£o cr√≠ticas das configura√ß√µes de log. </li><li>  Se o switch ou a interface de rede falhar, uma escolha amb√≠gua do servidor host (√†s vezes aconteceu, o sistema n√£o conseguiu entender com quem sincronizar). </li></ul><br>  <i>Not√≠cias √∫teis</i> (ainda n√£o testadas): <br>  O StarWind Virtual SAN para vSphere (solu√ß√£o hiperconvergente) permite incorporar a virtualiza√ß√£o do Vmware em um cluster sem vincular-se a servidores Windows (baseados em m√°quinas virtuais Linux). <br><br>  <i><b>Resumo</b></i> : Uma solu√ß√£o tolerante a falhas se houver um programa de substitui√ß√£o de servidor de hardware normal no final da garantia e o suporte t√©cnico do StarWindSoftWare estiver dispon√≠vel. <br><br><h2>  <b>2. Como criar pequeno armazenamento corporativo</b> </h2><br>  <b>Declara√ß√£o do problema:</b> <br><br>  Crie uma rede de armazenamento de dados de pequeno volume √† prova de falhas com um total de 4 TB-20 TB, com opera√ß√£o garantida a m√©dio prazo, sem custos financeiros adicionais significativos. <br><br><ul><li>  O sistema deve ser tolerante a falhas (transfira calmamente a falha de pelo menos um comutador, um servidor, discos e placas de rede no servidor). </li><li>  Para o m√°ximo uso de todos os recursos da frota de servidores de hardware dispon√≠vel (servidores e comutadores de 3 a 10 anos). </li><li>  Garanta o funcionamento de volumes de diferentes n√≠veis: cache All-Flash e HDD + SSD. </li></ul><br>  <b>Dados de origem:</b> <br><br><ul><li>  or√ßamento limitado; </li><li>  equipamentos de gera√ß√£o h√° 3-10 anos; </li><li>  Especialistas - N√£o Linux-Guru. </li></ul><br>  <b>C√°lculo de caracter√≠sticas</b> <br><br>  Para evitar gargalos de desempenho ao usar discos SSD, que ser√£o cortados por algo da cadeia de equipamentos: placas de rede, controlador RAID (HBA), expansor (cesta), discos. <br><br>  √â necess√°rio, no momento da cria√ß√£o, fornecer, com base nas caracter√≠sticas necess√°rias, uma certa configura√ß√£o de equipamento. <br><br>  Obviamente, √© poss√≠vel executar uma configura√ß√£o com o SSD que armazena em cache o SAS HDD em redes de 1 Gb / s e controladores 3G, mas o resultado ser√° 3-7 vezes pior que nas redes de 6 Gb RAID e 10 Gb / s (verificadas por testes). <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">As instru√ß√µes de ajuste do VxFlexOS</a> descrevem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">instru√ß√µes</a> simples para calcular a largura de banda necess√°ria, com base nas classifica√ß√µes SSD -450 MB / C e HDD -100 MB / C, para grava√ß√£o sequencial (por exemplo, quando o servidor √© reequilibrado e reconstru√≠do). <br><br><img src="https://habrastorage.org/webt/ia/-h/kl/ia-hklgcn0f0i_t6126vqpondoi.jpeg"><br>  Por exemplo: <br><br><ul><li>  (Cache SSD + 3 HDD), obtemos ((450 * 1) + (3 * 100)) * 8/1000 = 6 GB </li><li>  (ALL SSD FLASH) + (cache SSD + 3 HDD) ((450 * 2) + (3 * 100)) * 8/1000 = 9,6 GB </li></ul><br>  Para determinar a largura de banda da rede por IOPS (carga padr√£o em servidores de banco de dados e servidores virtuais carregados), h√° uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tabela indicativa da StariWindSoftware</a> <br><br><img src="https://habrastorage.org/webt/uc/xm/qf/ucxmqfcjkdfvg2qyfzyuofsso6e.jpeg"><br>  <b>Configura√ß√£o final</b> : <br><br><ul><li>  Software de armazenamento, que pode n√£o combinar discos em matrizes RAID, mas transferi-los para armazenamento na forma de discos separados (para que n√£o haja problemas ao substituir discos ap√≥s um certo per√≠odo de tempo em que eles falham, mas simplesmente selecione-os por capacidade); </li><li>  Servidores de gera√ß√£o dos processadores e55xx-x56xx e superior, barramentos pci-express v 2.0 e superior, controladores Raid (HBA) 6G-12G com mem√≥ria, cestas de expans√£o para 6-16 discos; </li><li>  Switches SMB 10G de camada 2 (JUMBO FRAME, LACP). </li></ul><br>  <b>M√©todo de solu√ß√£o</b> <br><br>  No momento, n√£o foram encontradas op√ß√µes de or√ßamento para um "Small Enterprise Enterprise Storage" de um pequeno volume com os requisitos acima. <br><br>  Paramos com solu√ß√µes de software que permitem que voc√™ aproveite o Enterprise Storage, com a op√ß√£o de usar servidores existentes, que neste caso t√™m o direito de morrer de velhice sem comprometer o armazenamento. <br><br><ul><li>  Ceph - n√£o h√° especialistas em Linux suficientes; </li><li>  EMC ScaleIO - por alguns anos de suporte t√©cnico - voc√™ pode conviver com a equipe existente. </li><li>  (como se viu, o conhecimento em Linux pode ser m√≠nimo, mais sobre isso mais adiante na folha de dicas). </li></ul><br><h2>  3. Hist√≥rico de overclocking de IOPS (pr√°tica de or√ßamento) </h2><br>  Para acelerar as opera√ß√µes de leitura e grava√ß√£o em sistemas de armazenamento, foram utilizados os seguintes dispositivos SSD: <br><br>  3.1  Controladores com recursos de armazenamento em cache SSD. <br><br>  Em 2010, os controladores RAID com fun√ß√µes de cache Adaptec 5445 SSD com um disco <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MaxIQ</a> apareceram (para um resultado tang√≠vel, voc√™ precisava ter pelo menos 10% do disco MaxIQ do volume do volume em cache); o resultado √© insignificante *; <br>  Posteriormente, havia controladores que podem usar um disco SSD arbitr√°rio para armazenamento em cache, tanto a s√©rie Adaptec Q quanto a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LSI CacheCade</a> (mas o licenciamento √© separado aqui); <br><br>  3.2  Armazenamento em cache de software usando discos, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Intel DC S3700</a> , que √© visto pelo controlador e expansor dos servidores de servidores HP, IBM e FUJI de marca (a maioria dos servidores os reconhece com √™xito, caros para All-Flash, mas para 10% no cache SSD, √© toler√°vel n√£o liber√°-los em parceiros da IBM, HP, FUJI e apenas Intel).  * Mas agora existem op√ß√µes compat√≠veis mais baratas (consulte o par√°grafo 3.5.); <br><br>  3.3  O armazenamento em cache do software usando o adaptador PCIe- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">M.2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Synology M.2 M2D18 SSD</a> , √© verificado, funciona em servidores comuns (n√£o apenas no Synology), √© √∫til quando o controlador RAID e a cesta se recusam a ver os SSDs que o fabricante n√£o indicou nos compat√≠veis (n HP D2700)?  *; <br><br>  3.4  Unidades h√≠bridas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">EXOS da Seagate</a>  600Gb Seagate Exos 10E2400 (ST600MM0099) {SAS 12Gb / s, 10000rpm, 256Mb, 2,5 "}, * verificado reconhecido pelos servidores HP, IBM e FUJI (alternativa √†s vers√µes 3.1.-3.3.); <br><br>  3.5  Unidades SSD com um grande recurso e pre√ßo compar√°vel ao SAS de classe empresarial, <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Crucial Micron 5200 MAX</a> MTFDDAK480TDN-1AT1ZABYY, * verificado reconhecido pelos servidores HP, IBM, FUJI <br>  (uma alternativa √† substitui√ß√£o de unidades de disco r√≠gido por unidades compat√≠veis com a cl√°usula 3.4 e compat√≠veis com servidores SAS antigos: disco r√≠gido SAS2.5 "600GB AL14SEB060N TOSHIBA *, <br>  C10K1800 0B31229 HGST, ST600MM0099 SEAGATE).  Permite que um or√ßamento mude dos volumes HDD + SSD para All-Flash. <br><br><h2>  4. Dicas para a implanta√ß√£o e opera√ß√£o do armazenamento EMC ScaleIO (VxFlexOS) 1 parte </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Armazenamento EMC ScaleIO (VxFlexOS)</a> <br><br>  Ap√≥s testar a solu√ß√£o antes da compra, cheguei √† conclus√£o de que, para o funcionamento normal do sistema, s√£o necess√°rios mais de 3 n√≥s (o failover √© inst√°vel em 3), por exemplo, fa√ßa uma configura√ß√£o de 8 servidores (sobreviver√° √† falha seq√ºencial de 4 servidores sem perder volumes). <br><br>  <i>Pe√ßa de hardware</i> : <br><br>  FUJI CX2550M1 (E5-2xxx) - 3 pe√ßas  (Cliente SDC do cluster principal de virtualiza√ß√£o do servidor VmWare VSphere + ScaleIO e servidor SDS); <br>  +5 servidores de gera√ß√£o HP G6 (G7) ou IBM M3 (e55xx-x56xx) - servidores ScaleIO SDS; <br>  + 2 comutadores NetGear XS712T-100NES <br><br>  Ao executar o armazenamento no modo RFCache, consegui fazer o overclock para 44KIops usando o Iometer <br><br><img src="https://habrastorage.org/webt/ro/vg/19/rovg1982umabe29n5vqa6_9erpi.jpeg"><br><br>  Configura√ß√£o de armazenamento: <br><br>  Capacidade bruta de 12 TB (licen√ßa m√≠nima no momento em que ainda era vendido como software) <br><br><img src="https://habrastorage.org/webt/vw/os/4e/vwos4eljcmjyrnk8drmccc9vsoa.jpeg"><br><br>  8 servidores SDS 28 unidades <br><br><img src="https://habrastorage.org/webt/gd/-y/5j/gd-y5j3wve2zmum8vexmkbwhmu8.jpeg"><br><br>  Ler cache de RAM de 14 Gb <br><br><img src="https://habrastorage.org/webt/uo/-j/ck/uo-jck7jbbvfdbjvap9emzkzjvu.jpeg"><br><br>  Leia Flash cashe 1,27 TB (RFCashe) <br><br><img src="https://habrastorage.org/webt/2x/y2/km/2xy2kmosvvldbniqfv6sr_6hykw.jpeg"><br><br>  Na vers√£o intermedi√°ria, onde apenas 3 servidores 2x10Gb possuem placas de rede, nos 2 x1Gb restantes. <br><br><img src="https://habrastorage.org/webt/vh/k8/xc/vhk8xcff6fqdhzp2347gmgtksuu.jpeg"><br>  √â claramente visto que, mesmo com o cache do SSD de 1 Gb em vez de 10 Gb, h√° uma perda de largura de banda do SDS tr√™s vezes ou mais, com m√≠dia id√™ntica. <br><br>  Sem cache, se voc√™ considerar de acordo com esses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"padr√µes"</a> , com 28 HDDs, <br>  obtemos 28X140 = 3920 IOPS, ou seja,  para obter 44.000 IOPS, voc√™ precisaria de 11 vezes mais discos.  √â economicamente mais lucrativo para requisitos de pequeno volume, n√£o para aumentar o n√∫mero de discos, mas para o cache SSD. <br><br>  √Ä quest√£o de por que tais velocidades com um pequeno volume, responderei imediatamente! <br><br>  Existem organiza√ß√µes t√£o pequenas (como a nossa) nas quais h√° um grande n√∫mero de documentos eletr√¥nicos que s√£o processados ‚Äã‚Äãno software por um longo per√≠odo de tempo (cada registro controla o envio do software por at√© 1 hora, mesmo nesse armazenamento com overclock).  Todas as outras op√ß√µes j√° foram aplicadas anteriormente (aumento de RM-RAM, CPU i5, SSD, 1Gb-NET).  Mesmo o uso de apenas pacotes configur√°veis ‚Äã‚ÄãSSD + SAS no armazenamento (sem o ALL-Flash at√© agora) tornou poss√≠vel usar a maioria dos recursos dos servidores de virtualiza√ß√£o, transferindo VMs carregadas para o ScaleIO - dobrou a carga nos processadores FUJI CX400M1 (anteriormente retinha o armazenamento). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt454114/">https://habr.com/ru/post/pt454114/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt454100/index.html">Problemas comuns de c√≥digo em microsservi√ßos</a></li>
<li><a href="../pt454102/index.html">Usando um or√°culo aleat√≥rio no exemplo de uma loteria</a></li>
<li><a href="../pt454104/index.html">Servi√ßos na nuvem para jogar em PCs fracos, relevantes em 2019</a></li>
<li><a href="../pt454110/index.html">Desenvolvimento de uma loja online para preservar a natureza de Kamchatka</a></li>
<li><a href="../pt454112/index.html">Duke Nukem Level Design History (com esbo√ßos de Levelord)</a></li>
<li><a href="../pt454124/index.html">O livro "Aprendendo a codificar em JavaScript"</a></li>
<li><a href="../pt454126/index.html">De falhas di√°rias √† estabilidade: Informatica com 10 olhos de administrador</a></li>
<li><a href="../pt454128/index.html">Como fazer dois aplicativos de um. Experi√™ncia J√∫nior Tinkoff</a></li>
<li><a href="../pt454130/index.html">C-V2X com suporte para redes 5G NR: um novo paradigma para troca de dados entre ve√≠culos</a></li>
<li><a href="../pt454132/index.html">Vigil√¢ncia por v√≠deo em orange pi zero - barato e nem um pouco zangado</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
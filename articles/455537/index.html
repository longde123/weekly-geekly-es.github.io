<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïú üë®üèΩ‚Äç‚úàÔ∏è üë©üèº‚Äçüé§ Amplia optimizaci√≥n de b√∫squeda: c√≥mo procesar un gr√°fico con 10 mil millones de estados üë®üèª‚Äç‚öïÔ∏è üëí üß§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hace un par de meses, finalmente tuve que admitir que no era lo suficientemente inteligente como para pasar por algunos niveles del rompecabezas Snake...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Amplia optimizaci√≥n de b√∫squeda: c√≥mo procesar un gr√°fico con 10 mil millones de estados</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455537/"><div style="text-align:center;"><img src="https://nordicgame.com/wp-content/uploads/2015/05/noumenon.games_.snakebird.850.560.jpg" alt="imagen"></div><br>  Hace un par de meses, finalmente tuve que admitir que no era lo suficientemente inteligente como para pasar por algunos niveles del rompecabezas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Snakebird</a> .  La √∫nica forma de recuperar parte de la autoestima era escribir un solucionador.  Entonces podr√≠a pretender que crear un programa para resolver el rompecabezas es casi lo mismo que resolverlo yo mismo.  El c√≥digo para el programa C ++ resultante est√° disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Github</a> .  La parte principal del c√≥digo considerado en el art√≠culo se implementa en <a href="">search.h</a> y <a href="">compress.h</a> .  En esta publicaci√≥n, hablar√© principalmente sobre la optimizaci√≥n de una b√∫squeda de amplitud que requerir√≠a 50-100 GB de memoria para caber en 4 GB. <br><br>  M√°s tarde escribir√© otra publicaci√≥n, que describir√° los detalles del juego.  En esta publicaci√≥n, debes saber que no pude encontrar buenas alternativas a la fuerza bruta, porque ninguno de los trucos habituales funcion√≥.  El juego tiene muchos estados, porque hay muchos objetos en movimiento o empujados, y la forma de algunos de ellos es importante, lo que puede cambiar con el tiempo.  No exist√≠a una heur√≠stica conservadora adecuada para algoritmos como A * para reducir el espacio de b√∫squeda.  El gr√°fico de b√∫squeda se orient√≥ y se especific√≥ impl√≠citamente; por lo tanto, la b√∫squeda simult√°nea en las direcciones hacia adelante y hacia atr√°s era imposible.  El √∫nico movimiento podr√≠a cambiar el estado de muchas maneras no relacionadas, por lo que nada podr√≠a ser √∫til como hacer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hash a Zobrist</a> . <br><br>  Estimaciones aproximadas han demostrado que en el rompecabezas m√°s grande, despu√©s de eliminar todas las posiciones sim√©tricas, habr√° alrededor de 10 mil millones de estados.  Incluso despu√©s de empacar descripciones de estado con densidad m√°xima, el tama√±o del estado era de 8-10 bytes.  Con 100 GB de memoria, la tarea ser√≠a trivial, pero no para mi m√°quina dom√©stica con 16 GB de memoria.  Y dado que Chrome necesita 12 GB de ellos, mi suministro de memoria real est√° m√°s cerca de 4 GB.  Todo lo que exceda este volumen deber√° guardarse en el disco (disco duro viejo y oxidado). <br><a name="habracut"></a><br>  ¬øC√≥mo ajustar 100 GB de datos en 4 GB de RAM?  Ya sea a) los estados deben exprimirse 1/20 de su tama√±o original, ya optimizado, o b) el algoritmo debe ser capaz de guardar estados efectivamente desde y hacia el disco, o c) una combinaci√≥n de los dos m√©todos anteriores, o d) necesito comprar m√°s RAM o alquilar una potente m√°quina virtual durante varios d√≠as.  No consider√© la opci√≥n D, porque es demasiado aburrida.  Las opciones A y B se excluyeron despu√©s de la prueba de concepto utilizando gzip: un fragmento de una descripci√≥n de estado de 50 MB se comprimi√≥ a solo 35 MB.  Esto es aproximadamente 7 bytes por estado, y mi memoria es de aproximadamente 0.4 bytes por estado.  Es decir, la opci√≥n B permaneci√≥, aunque la b√∫squeda de amplitud parec√≠a bastante inc√≥moda para el almacenamiento en unidades secundarias. <br><br><h2>  Contenido </h2><br>  Esta es una publicaci√≥n bastante larga, as√≠ que aqu√≠ hay una breve descripci√≥n de las siguientes secciones: <br><br><ul><li>  B√∫squeda de amplitud primero de amplitud: ¬øcu√°l es la redacci√≥n habitual de b√∫squeda de amplitud primero (BFS) y por qu√© no es adecuada para almacenar porciones de un estado en el disco? </li><li>  <b>BFS con clasificaci√≥n y fusi√≥n</b> : un cambio en el algoritmo para la eliminaci√≥n por lotes eficiente de datos redundantes. </li><li>  <b>Compresi√≥n</b> : reduce la cantidad de memoria utilizada cien veces debido a la combinaci√≥n de compresi√≥n est√°ndar y nativa. </li><li>  <b>¬°Oh, oh, hice trampa!</b>  - en las primeras secciones me qued√© callado sobre algo: no es suficiente para nosotros saber d√≥nde est√° la soluci√≥n, pero necesitamos entender exactamente c√≥mo lograrla.  En esta secci√≥n, actualizamos el algoritmo b√°sico para que transfiera suficientes datos para recrear la soluci√≥n desde el √∫ltimo estado. </li><li>  <b>Ordenar + fusionar con m√∫ltiples salidas</b> : almacenar m√°s estados niega por completo los beneficios de la compresi√≥n.  El algoritmo de clasificaci√≥n + fusi√≥n debe cambiarse para que almacene dos conjuntos de datos de salida: uno, bien comprimido, se usa durante la b√∫squeda, y el otro se usa solo para recrear la soluci√≥n despu√©s de encontrar el primero. </li><li>  <b>Swap</b> - <b>Swap</b> en Linux es mucho peor de lo que pensaba. </li><li>  <b>Compresi√≥n de nuevos estados antes de la fusi√≥n</b> : hasta ahora, las optimizaciones de memoria solo funcionaban con muchos estados visitados.  Pero result√≥ que la lista de nuevos estados generados es mucho m√°s grande de lo que piensas.  Esta secci√≥n muestra un diagrama para una descripci√≥n m√°s eficiente de los nuevos estados. </li><li>  <b>Ahorro de espacio en estados primarios</b> : explore las compensaciones entre el uso de CPU / memoria para recrear la soluci√≥n al final. </li><li>  <b>Lo que no funcion√≥ o no funcion√≥</b> : algunas ideas parec√≠an prometedoras, pero como resultado tuvieron que revertirse, mientras que otras, que se supon√≠a que eran investigadores, intuitivamente me parecen inapropiadas en este caso. </li></ul><br><h2>  Amplia b√∫squeda "por libro de texto" </h2><br>  ¬øC√≥mo se ve la b√∫squeda de amplitud y por qu√© no deber√≠a usar un disco?  Antes de este peque√±o proyecto, consideraba solo las opciones de redacci√≥n ‚Äúde los libros de texto‚Äù, por ejemplo, como: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = {start} todo = [start] <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> todo: node = todo.pop_first() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> visited: visited.add(kid) todo.push_back(kid) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">False</span></span></code> </pre> <br>  En el proceso de crear nuevos nodos candidatos por el programa, cada nodo se verifica con una tabla hash de nodos ya visitados.  Si ya est√° en la tabla hash, se ignora el nodo.  De lo contrario, se agrega a la cola y a la tabla hash.  A veces, en implementaciones, la informaci√≥n "visitada" se ingresa en los nodos, y no en una tabla ajena;  pero esta es una optimizaci√≥n arriesgada y es completamente imposible si el gr√°fico se especifica impl√≠citamente. <br><br>  ¬øPor qu√© es problem√°tico usar una tabla hash?  Debido a que las tablas hash tienden a crear un patr√≥n de acceso a memoria completamente aleatorio.  Si no lo hacen, entonces esta es una mala funci√≥n hash, y la tabla hash probablemente tendr√° un bajo rendimiento debido a colisiones.  Este patr√≥n de acceso aleatorio puede causar problemas de rendimiento, incluso si los datos se ajustan en la memoria: es probable que el acceso a una gran tabla hash cause errores de cach√© y b√∫feres de traducci√≥n asociativa (TLB).  Pero, ¬øqu√© sucede si una porci√≥n significativa de los datos est√° en el disco y no en la memoria?  Las consecuencias ser√°n catastr√≥ficas: algo del orden de 10 ms por operaci√≥n de b√∫squeda. <br><br>  Con 10 mil millones de estados √∫nicos, solo acceder a la tabla hash nos llevar√° unos cuatro meses esperar la E / S del disco.  Esto no nos conviene;  la tarea definitivamente debe convertirse para que el programa pueda procesar grandes paquetes de datos en una sola pasada. <br><br><h2>  BFS con clasificaci√≥n y fusi√≥n </h2><br>  Si quisi√©ramos integrar las operaciones de acceso a datos en los paquetes tanto como sea posible, ¬øcu√°l ser√≠a la aproximaci√≥n m√°xima alcanzable?  Dado que el programa no sabe qu√© nodos procesar en una capa de profundidad N + 1 hasta que la capa N se procese por completo, parece obvio que es necesario deduplicar estados al menos una vez por profundidad. <br><br>  Si estamos trabajando con una capa completa al mismo tiempo, podemos abandonar las tablas hash y describir el conjunto de estados visitados y nuevos como algunas secuencias ordenadas (por ejemplo, como secuencias de archivos, matrices, listas).  Podemos encontrar trivialmente el nuevo conjunto visitado combinando los conjuntos de flujos y es igualmente trivial encontrar el conjunto todo utilizando la diferencia de conjuntos. <br><br>  Se pueden combinar dos operaciones con conjuntos para que funcionen en una sola pasada con ambos hilos.  De hecho, observamos ambas corrientes, procesamos el elemento m√°s peque√±o y luego avanzamos a lo largo de la corriente de la que se tom√≥ el elemento (o a lo largo de ambos flujos si los elementos al principio son los mismos).  En ambos casos, agregamos el elemento al nuevo conjunto visitado.  Luego avanzamos a lo largo de la secuencia de nuevos estados, y tambi√©n agregamos un elemento al nuevo conjunto de tareas: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = Stream() todo = Stream() visited.add(start) todo.add(start) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: new = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> todo: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): new.push_back(kid) new_stream = Stream() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> new.sorted().uniq(): new_stream.add(node) todo, visited = merge_sorted_streams(new_stream, visited) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> <span class="hljs-comment"><span class="hljs-comment"># Merges sorted streams new and visited. Return a sorted stream of # elements that were just present in new, and another sorted # stream containing the elements that were present in either or # both of new and visited. def merge_sorted_streams(new, visited): out_todo, out_visited = Stream(), Stream() while visited or new: if visited and new: if visited.peek() == new.peek(): out_visited.add(visited.pop()) new.pop() elif visited.peek() &lt; new.peek(): out_visited.add(visited.pop()) elif visited.peek() &gt; new.peek(): out_todo.add(new.peek()) out_visited.add(new.pop()) elif visited: out_visited.add(visited.pop()) elif new: out_todo.add(new.peek()) out_visited.add(new.pop()) return out_todo, out_visited</span></span></code> </pre> <br>  El patr√≥n de acceso a datos ahora es completamente lineal y predecible; no hay accesos arbitrarios en toda la fusi√≥n.  Por lo tanto, la demora en las operaciones de disco no es importante para nosotros, y lo √∫nico que sigue siendo importante es el ancho de banda. <br><br>  ¬øC√≥mo ser√° el rendimiento te√≥rico con una distribuci√≥n simplificada de datos en m√°s de 100 niveles de profundidad, cada uno de los cuales tiene 100 millones de estados?  El estado promedio ser√° le√≠do y escrito 50 veces.  Esto da 10 bytes / estado * 5 mil millones de estados * 50 = 2.5 TB.  Mi disco duro supuestamente puede leer y escribir a una velocidad promedio de 100 MB / s, es decir, en promedio, la E / S tomar√° (2 * 2.5 TB) / (100 MB / s) = ~ 50k / s = ~ 13 horas .  ¬°Esto es un par de pedidos menos que el resultado anterior (cuatro meses)! <br><br>  Tambi√©n vale la pena se√±alar que este modelo simplificado no tiene en cuenta el tama√±o de los nuevos estados generados.  Antes del paso de fusi√≥n, deben almacenarse en la memoria para la clasificaci√≥n + deduplicaci√≥n.  Cubriremos esto en las secciones a continuaci√≥n. <br><br><h2>  Compresi√≥n </h2><br>  En la introducci√≥n, dije que en los experimentos iniciales, la compresi√≥n de estado no parec√≠a prometedora, y la relaci√≥n de compresi√≥n era solo del 30%.  Pero despu√©s de realizar cambios en el algoritmo, los estados se racionalizaron.  Deber√≠an ser mucho m√°s f√°ciles de comprimir. <br><br>  Para probar esta teor√≠a, utilic√© zstd con un rompecabezas de 14,6 millones de estados, cada uno de los cuales ten√≠a un tama√±o de 8 bytes.  Despu√©s de ordenar, se comprimieron en promedio a 1,4 bytes por estado.  Parece un serio paso adelante.  No es suficiente ejecutar todo el programa en la memoria, pero puede reducir el tiempo de E / S del disco a solo un par de horas. <br><br>  ¬øEs posible mejorar de alguna manera el resultado del algoritmo moderno de compresi√≥n de prop√≥sito general si sabemos algo sobre la estructura de datos?  Puedes estar casi seguro de ello.  Un buen ejemplo de esto es el formato PNG.  Te√≥ricamente, la compresi√≥n es solo un pase Deflate est√°ndar.  Pero en lugar de comprimir datos sin procesar, la imagen se convierte primero con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">filtros PNG</a> .  El filtro PNG es esencialmente una f√≥rmula para predecir el valor de un byte de datos sin procesar en funci√≥n del valor del mismo byte en la l√≠nea anterior y / o el mismo byte del p√≠xel anterior.  Por ejemplo, el filtro "arriba" convierte cada byte restando los valores de la l√≠nea anterior al comprimir, y realizando la operaci√≥n opuesta al desempacar.  Dados los tipos de im√°genes para las que se usa PNG, el resultado casi siempre consistir√° en ceros o n√∫meros cercanos a cero.  Deflate puede comprimir esos datos mucho mejor que los datos sin procesar. <br><br>  ¬øSe puede aplicar este principio a los registros de estado BFS?  Parece que esto deber√≠a ser posible.  Al igual que con PNG, tenemos un tama√±o de l√≠nea constante y podemos esperar que las l√≠neas adyacentes sean muy similares.  Las primeras muestras con el filtro de resta / suma, seguido de zstd, condujeron a una mejora en la relaci√≥n de compresi√≥n en otro 40%: 0,87 bytes por estado.  Las operaciones de filtrado son triviales, por lo tanto, desde el punto de vista del consumo de CPU, son pr√°cticamente "gratuitas". <br><br>  No estaba claro para m√≠ si se pod√≠an hacer otras mejoras, o si esto era un l√≠mite pr√°ctico.  En los datos de la imagen, puede esperar l√≥gicamente que los bytes adyacentes de la misma l√≠nea sean similares.  Pero en estos estados no existe tal cosa.  Pero en realidad, los filtros ligeramente m√°s sofisticados a√∫n pueden mejorar los resultados.  Al final, llegu√© a este sistema: <br><br>  Supongamos que tenemos filas adyacentes R1 = [1, 2, 3, 4] y R2 = [1, 2, 6, 4].  Al generar R2, comparamos cada byte con el mismo byte de la l√≠nea anterior, y 0 indicar√° una coincidencia, y 1 indicar√° una falta de coincidencia: diff = [0, 0, 1, 0].  Luego pasamos este mapa de bits, codificado como VarInt, seguido de solo bytes que no coinciden con la l√≠nea anterior.  En este ejemplo, obtenemos dos bytes 0b00000100 6. Por s√≠ mismo, este filtro comprime los datos de referencia a 2,2 bytes / estado.  Pero al combinar el filtro + zstd, redujimos el tama√±o de los datos a 0,42 bytes / estado.  O, para decirlo de otra manera, esto equivale a 3.36 bits por estado, que es solo un poco m√°s que nuestros indicadores calculados aproximados necesarios para garantizar que todos los datos encajen en la RAM. <br><br>  En la pr√°ctica, las relaciones de compresi√≥n mejoran porque los conjuntos ordenados se vuelven m√°s densos.  Cuando la b√∫squeda llega al punto donde la memoria comienza a causar problemas, las tasas de compresi√≥n pueden mejorar mucho.  El mayor problema es que al final obtenemos 4.600 millones de estados visitados.  Despu√©s de la clasificaci√≥n, estos estados ocupan 405 MB y se comprimen de acuerdo con el esquema presentado anteriormente.  Esto nos da <b>0.7 bits por estado</b> .  Al final, la compresi√≥n y la descompresi√≥n ocupan aproximadamente el 25% del tiempo de CPU del programa, pero este es un excelente compromiso para reducir el consumo de memoria en cien veces. <br><br>  El filtro anterior parece un poco costoso debido al encabezado VarInt en cada l√≠nea.  Parece que es f√°cil de actualizar a costa de bajos costos de CPU o un ligero aumento en la complejidad.  Prob√© varias opciones diferentes, transponiendo datos en orden por columnas, o escribiendo m√°scaras de bits en bloques m√°s grandes, etc.  Estas opciones solo produjeron relaciones de compresi√≥n mucho m√°s altas, pero no funcionaron tan bien cuando la salida del filtro fue comprimida por zstd.  Y no fue alg√∫n tipo de error zstd, los resultados con gzip y bzip2 resultaron ser similares.  No tengo ninguna teor√≠a particularmente ingeniosa sobre por qu√© este tipo particular de codificaci√≥n result√≥ ser mucho mejor en compresi√≥n que otras opciones. <br><br>  Otro misterio: la tasa de compresi√≥n result√≥ ser mucho mejor cuando los datos se ordenan por little-endian, en lugar de big-endian.  Inicialmente, pens√© que sucedi√≥ porque en la clasificaci√≥n little-endian hay m√°s ceros a la izquierda con la m√°scara de bits codificada por VarInt.  Pero esta diferencia persiste incluso con filtros que no tienen tales dependencias. <br><br>  (Hay mucha investigaci√≥n sobre la compresi√≥n de conjuntos de enteros ordenados, porque son los componentes b√°sicos de los motores de b√∫squeda. Sin embargo, no encontr√© mucha informaci√≥n sobre la compresi√≥n de registros ordenados de longitud constante, y no quer√≠a adivinar, presentando los datos como valores enteros con precisi√≥n arbitraria). <br><br><h2>  ¬°Oh, oh, hice trampa! </h2><br>  Es posible que haya notado que las implementaciones BFS anteriores en pseudoc√≥digo devuelven solo valores booleanos: la soluci√≥n se encuentra / no se encuentra.  Esto no es particularmente √∫til.  En la mayor√≠a de los casos, necesitaremos crear una lista de los pasos exactos de la soluci√≥n, y no solo informar la disponibilidad de la soluci√≥n. <br><br>  Al principio parece que este problema es f√°cil de resolver.  En lugar de recopilar conjuntos de estados, debe recopilar las relaciones de estado con los estados primarios.  Luego, despu√©s de encontrar una soluci√≥n, simplemente puede volver de la lista de soluciones parentales de principio a fin.  Para una soluci√≥n basada en tablas hash, esto se ver√≠a as√≠: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = {start: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>} todo = [start] <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> todo: node = todo.pop_first() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(node, visited) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> visited: visited[kid] = node todo.push_back(kid) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trace_solution</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(state, visited)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> state <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(start, visited[state]) + [state]</code> </pre> <br>  Desafortunadamente, esto destruir√° todos los beneficios de compresi√≥n obtenidos en la secci√≥n anterior;  se basan en el supuesto de que las l√≠neas adyacentes son muy similares.  Cuando solo miramos los estados mismos, esto es cierto.  Pero no hay raz√≥n para creer que esto sea cierto para los estados parentales;  de hecho, son datos aleatorios.  En segundo lugar, una soluci√≥n sort + merge deber√≠a leer y escribir todos los estados vistos en cada iteraci√≥n.  Para guardar la vinculaci√≥n del estado / estado primario, tenemos que leer y escribir en el disco en cada iteraci√≥n todos estos datos mal comprimidos. <br><br><h2>  Ordenar + fusionar con salida m√∫ltiple </h2><br>  Al final, cuando regrese a la soluci√≥n, el programa solo necesitar√° paquetes de estados / estados primarios, por lo tanto, podemos almacenar dos estructuras de datos en paralelo.  Visitado continuar√° siendo el conjunto de estados visitados, como se recalcul√≥ previamente durante la fusi√≥n.  Los padres son al menos una lista ordenada de pares de estado / estado primario que no se sobrescriben.  Despu√©s de cada operaci√≥n de fusi√≥n, el par "estado + estado padre" se agrega a los padres. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> parents = Stream() visited = Stream() todo = Stream() parents.add((start, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)) visited.add(start) todo.add(start) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: new = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> todo: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(node, parents) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): new.push_back(kid) new_stream = Stream() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> new.sorted().uniq(): new_stream.add(node) todo, visited = merge_sorted_streams(new_stream, visited, parents) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-comment"><span class="hljs-comment"># Merges sorted streams new and visited. New contains pairs of # key + value (just the keys are compared), visited contains just # keys. # # Returns a sorted stream of keys that were just present in new, # another sorted stream containing the keys that were present in either or # both of new and visited. Also adds the keys + values to the parents # stream for keys that were only present in new. def merge_sorted_streams(new, visited, parents): out_todo, out_visited = Stream(), Stream() while visited or new: if visited and new: visited_head = visited.peek() new_head = new.peek()[0] if visited_head == new_head: out_visited.add(visited.pop()) new.pop() elif visited_head &lt; new_head: out_visited.add(visited.pop()) elif visited_head &gt; new_head: out_todo.add(new_head) out_visited.add(new_head) out_parents.add(new.pop()) elif visited: out_visited.add(visited.pop()) elif new: out_todo.add(new.peek()[0]) out_visited.add(new.peek()[0]) out_parents.add(new.pop()) return out_todo, out_visited</span></span></code> </pre> <br>  Esto nos permite aprovechar ambos enfoques en t√©rminos de tiempo de ejecuci√≥n y conjuntos de trabajo, pero requiere m√°s espacio de almacenamiento secundario.  Adem√°s, resulta que en el futuro, por otras razones, ser√° √∫til una copia separada de los estados visitados, agrupados por profundidad. <br><br><h2>  Intercambiar </h2><br>  Otro detalle se ignora en el pseudoc√≥digo: no existe un c√≥digo expl√≠cito para la E / S del disco, sino solo la interfaz Stream abstracta.  La secuencia puede ser una secuencia de archivos o una matriz dentro de la memoria, pero ignoramos este detalle de implementaci√≥n.  En cambio, el pseudoc√≥digo est√° creando un patr√≥n de acceso a la memoria que permite un uso √≥ptimo del disco.  En un mundo ideal, esto ser√≠a suficiente, y el resto podr√≠a ser ocupado por el subsistema de memoria virtual del sistema operativo. <br><br>  Pero esto no sucede, al menos en Linux.  En alg√∫n momento (antes de que el conjunto de datos de trabajo pudiera comprimirse a tama√±os de memoria), pude ejecutar el programa en aproximadamente 11 horas, y los datos se guardaron principalmente en el disco.  Luego hice que el programa usara p√°ginas an√≥nimas en lugar de almacenarlas en archivos, y seleccion√© un archivo de intercambio de tama√±o suficiente en la misma unidad.  Sin embargo, tres d√≠as despu√©s, el programa fue solo una cuarta parte y, con el tiempo, se hizo m√°s lento.  Seg√∫n mis estimaciones optimistas, se supon√≠a que ella terminar√≠a el trabajo en 20 d√≠as. <br><br>  Lo aclarar√©: era el mismo c√≥digo y <i>exactamente el mismo patr√≥n de acceso</i> .  Lo √∫nico que ha cambiado es que la memoria se guard√≥ no como un archivo de disco expl√≠cito, sino como un intercambio.  Casi no se necesita evidencia de que el intercambio destruya completamente el rendimiento de Linux, mientras que las E / S de archivos normales no.  Siempre supuse que esto se debe al hecho de que los programas tienden a considerar la RAM como memoria de acceso aleatorio.  Pero este no es el caso. <br><br>  Resulta que las p√°ginas para guardar archivos y las p√°ginas an√≥nimas son manejadas de manera diferente por el subsistema de m√°quina virtual.  Se almacenan en cach√©s LRU separadas con diferentes pol√≠ticas de vencimiento;  Adem√°s, parece que tienen diferentes propiedades de lectura / carga de lectura anticipada. <br><br>  Ahora lo s√©: el intercambio en Linux probablemente no funcionar√° bien incluso en condiciones √≥ptimas.  Si es probable que partes del espacio de direcciones se descarguen durante un tiempo en el disco, es mejor guardarlas manualmente en archivos que confiar en el intercambio.  Lo logr√© implementando mi propia clase de vectores, que inicialmente solo funciona en la memoria, y despu√©s de exceder un cierto umbral de tama√±o, cambia a mmap en un archivo temporal separado. <br><br><h2>  Compresi√≥n de nuevos estados antes de fusionarse </h2><br>  En un modelo de rendimiento simplificado, asumimos que ocurrir√≠an 100 millones de nuevas condiciones en cada profundidad.  Result√≥ que esto no est√° muy lejos de la realidad (en el rompecabezas m√°s complejo, un m√°ximo de m√°s de 150 millones de nuevos estados √∫nicos en una capa de profundidad).  Pero esto no se puede medir;  el conjunto de trabajo antes de la fusi√≥n est√° asociado no solo con estados √∫nicos, sino tambi√©n con todos los estados deducidos para esta iteraci√≥n.  Esta cifra alcanza los 880 millones de estados de salida por capa de profundidad.  Estos 880 millones de estados a) necesitan ser procesados ‚Äã‚Äãcon un patr√≥n de acceso aleatorio para la clasificaci√≥n, b) no pueden comprimirse efectivamente debido a la falta de clasificaci√≥n, c) deben almacenarse junto con el estado padre.  Este conjunto de trabajo es de aproximadamente 16 GB. <br><br>  La soluci√≥n obvia: usar alg√∫n tipo de clasificaci√≥n externa.  Simplemente escriba todos los estados en el disco, realice una clasificaci√≥n externa, deduplica y luego combine como de costumbre.  Al principio us√© esta soluci√≥n, y aunque en la mayor√≠a de los casos elimin√≥ el problema A, no pude hacer frente a B y C. <br><br>  Al final, tom√© un enfoque alternativo: reun√≠ los estados en una matriz en la memoria.  Si la matriz se vuelve demasiado grande (por ejemplo, m√°s de 100 millones de elementos), entonces se ordena, deduplica y comprime.  Esto nos da un paquete de ejecuciones de estado ordenadas, y no hay duplicados dentro de cada ejecuci√≥n, pero son posibles entre ejecuciones.  B√°sicamente, el c√≥digo para fusionar estados nuevos y visitados sigue siendo el mismo;  todav√≠a se basa en un paso gradual a trav√©s de las corrientes.  La √∫nica diferencia es que, en lugar de simplemente pasar por dos flujos, hay un flujo separado para cada una de las ejecuciones ordenadas de nuevos estados. <br><br>  Por supuesto, las tasas de compresi√≥n de estas ejecuciones de 100 millones de estados no son tan buenas como la compresi√≥n del conjunto de todos los estados visitados.  Pero incluso con tales indicadores, reduce significativamente el volumen del conjunto de trabajo y los requisitos de E / S de disco.  Necesita un poco m√°s de recursos de CPU para procesar la cola prioritaria de subprocesos, pero sigue siendo un gran compromiso. <br><br><h2>  Ahorro de espacio en estados primarios </h2><br>  En esta etapa, la gran mayor√≠a del espacio ocupado por el programa se gasta en almacenar los estados primarios, de modo que despu√©s de encontrar la soluci√≥n podamos recrear su proceso.  Lo m√°s probable es que apenas puedan exprimirse bien, pero ¬øquiz√°s haya alg√∫n tipo de compromiso entre la CPU y la memoria? <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Necesitamos conectar el estado S 'en la profundidad D + 1 con su estado padre S en la profundidad D. Si podemos iterar sobre todos los estados parentales posibles S', entonces podemos verificar si alguno de ellos aparece en la profundidad D en el conjunto visitado . (Ya hemos creado muchas visitas, agrupadas por profundidad como un subproducto conveniente de la derivaci√≥n de paquetes de estado / estado parental durante la fusi√≥n). Desafortunadamente, este enfoque no funcionar√° para esta tarea; es simplemente demasiado dif√≠cil para nosotros generar todos los estados posibles de S para un S 'dado. Sin embargo, para muchas otras tareas de b√∫squeda, tal soluci√≥n podr√≠a funcionar.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si solo podemos generar transiciones entre estados hacia adelante, pero no hacia atr√°s, ¬øpor qu√© no hacer esto? Recorramos iterativamente todos los estados en profundidad D y veamos qu√© tipo de estados de salida obtienen. Si alg√∫n estado en la salida da S ', entonces encontramos un S. adecuado. El problema con este plan es que aumenta el consumo total de recursos del procesador por parte del programa en un 50%. (No 100%, porque en promedio encontraremos S al observar la mitad de los estados en profundidad D).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por lo tanto, no me gusta ninguno de los casos limitantes, pero aqu√≠, al menos, es posible un compromiso entre la CPU / memoria. </font><font style="vertical-align: inherit;">¬øHay una soluci√≥n m√°s aceptable en alg√∫n punto intermedio? </font><font style="vertical-align: inherit;">Al final, decid√≠ no almacenar el par (S ', S), sino el par (S', H (S)), donde H es una funci√≥n hash de 8 bits. </font><font style="vertical-align: inherit;">Para encontrar S para una S 'dada, nuevamente recorremos iterativamente todos los estados en profundidad D. Pero antes de hacer cualquier otra cosa, calculamos el mismo hash. </font><font style="vertical-align: inherit;">Si la salida no coincide con H (S), entonces este no es el estado que estamos buscando, y simplemente podemos omitirlo. </font><font style="vertical-align: inherit;">Esta optimizaci√≥n significa que los costosos rec√°lculos deben realizarse solo para 1/256 estados, lo que representa un ligero aumento en la carga de la CPU, y al mismo tiempo reduce la cantidad de memoria para almacenar estados primarios de 8-10 bytes a 1 byte.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Lo que no funcion√≥ o puede no funcionar </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En las secciones anteriores, observamos la secuencia de optimizaciones de alto nivel que funcion√≥. Intent√© otras cosas que no funcionaron, o que encontr√© en la literatura, pero decid√≠ que en este caso particular no funcionar√≠an. Aqu√≠ hay una lista parcial.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En este punto, no recalculo todo el conjunto visitado en cada iteraci√≥n. En cambio, se almacen√≥ como muchas ejecuciones ordenadas, y estas ejecuciones se comprimieron de vez en cuando. La ventaja de este enfoque es que se utilizan menos escrituras en disco y recursos de CPU para la compresi√≥n. La desventaja es una mayor complejidad del c√≥digo y una tasa de compresi√≥n reducida. Inicialmente, pens√© que tal esquema tiene sentido, porque en mi caso, las operaciones de escritura son m√°s caras que la lectura. Pero al final, la relaci√≥n de compresi√≥n result√≥ ser el doble. Las ventajas de tal compromiso no son obvias, por lo tanto, como resultado, volv√≠ a una forma m√°s simple. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ya se ha realizado poca investigaci√≥n sobre c√≥mo realizar una b√∫squeda volum√©trica de amplitud para gr√°ficos definidos impl√≠citamente en el almacenamiento secundario, puede comenzar a explorar este tema</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de este art√≠culo de 2008</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Como puede suponer, la idea de hacer deduplicaci√≥n junto con ordenar + fusionar en el almacenamiento secundario no es nueva. Lo sorprendente de esto es que se abri√≥ solo en 1993. Bastante tarde! Hay sugerencias posteriores para la b√∫squeda de amplitud en el almacenamiento secundario que no requieren un paso de clasificaci√≥n. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Una de ellas era unir estados a enteros y almacenar en la memoria un mapa de bits de estados visitados. En mi caso, esto es completamente in√∫til, porque los tama√±os del estado codificado son muy diferentes en comparaci√≥n con los espacios de estado realmente accesibles. Y dudo mucho que haya problemas interesantes en los que tal enfoque funcionar√≠a.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otra alternativa seria se basa en tablas hash temporales. Los estados visitados se almacenan sin ordenar en un archivo. Guardamos el resultado obtenido de la profundidad D en la tabla hash. Luego, recorra iterativamente los estados visitados y b√∫squelos en la tabla hash. Si el elemento se encuentra en la tabla hash, elim√≠nelo. Despu√©s de recorrer iterativamente todo el archivo, solo quedar√°n elementos no duplicados en √©l. Luego se agregan al archivo y se utilizan para inicializar la lista de tareas pendientes para la pr√≥xima iteraci√≥n. Si la cantidad de salida es tan grande que la tabla hash no cabe en la memoria, los archivos y las tablas hash se pueden dividir en partes utilizando los mismos criterios (por ejemplo, los bits de estado superiores), y cada parte debe procesarse por separado. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aunque hay </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">puntos de referencia</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mostrando que el enfoque basado en hash es aproximadamente un 30% m√°s r√°pido que la clasificaci√≥n + fusi√≥n, pero parece que no tienen en cuenta la compresi√≥n. Simplemente no vi c√≥mo el rechazo de los beneficios de la compresi√≥n puede justificarse, por lo que ni siquiera experiment√© con tales enfoques. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Otra √°rea de investigaci√≥n digna de atenci√≥n fue la optimizaci√≥n de las consultas de la base de datos. Parece que que la tarea de deduplicaci√≥n est√° fuertemente relacionada con la uni√≥n a la base de datos, que tambi√©n tiene exactamente el mismo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dilema de </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">clasificaci√≥n versus hash</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Obviamente, algunos de estos estudios se pueden aplicar al problema de b√∫squeda. La diferencia puede ser que la salida de la base de datos de uni√≥n es temporal, mientras que la salida de deduplicaci√≥n BFS se almacena hasta el final del c√°lculo. Parece que esto est√° cambiando el equilibrio de compromisos: ahora se trata no solo del procesamiento m√°s eficiente de una iteraci√≥n, sino tambi√©n de la creaci√≥n del formato de datos de salida m√°s √≥ptimo para la pr√≥xima iteraci√≥n.</font></font><br><br><h2>  Conclusi√≥n </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esto concluye mi relato de lo que aprend√≠ de un proyecto que generalmente es aplicable a otras tareas de b√∫squeda por fuerza bruta. </font><font style="vertical-align: inherit;">La combinaci√≥n de estos trucos permiti√≥ reducir el volumen de soluciones a los acertijos m√°s complejos del juego de 50-100 GB a 500 MB y aumentar sin problemas los costos si la tarea excede la memoria disponible y se escribe en el disco. </font><font style="vertical-align: inherit;">Adem√°s, mi soluci√≥n es un 50% m√°s r√°pida que una ingenua deduplicaci√≥n de estados basada en tablas hash, incluso para acertijos que caben en la memoria. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Snakebird se puede comprar en </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Steam</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Play</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> y </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">App Store</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Se lo recomiendo a cualquiera que est√© interesado en acertijos muy complejos pero honestos.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/455537/">https://habr.com/ru/post/455537/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../455525/index.html">Zimbra y Mail Bomb Defense</a></li>
<li><a href="../455527/index.html">¬øQu√© est√° escrito en esto? Detr√°s de escena de objetos JavaScript</a></li>
<li><a href="../455529/index.html">Invertir y piratear el HDD externo de autocifrado de Aigo. Parte 2: Dumping con Cypress PSoC</a></li>
<li><a href="../455533/index.html">Bubble Physics: A Search for Foam Destruction Mechanism</a></li>
<li><a href="../455535/index.html">Administrar certificados SSL / TLS en las nubes y contenedores, no trabajo humano</a></li>
<li><a href="../455539/index.html">Ps√≠quicos m√≥viles: 10 datos nuevos sobre c√≥mo los dispositivos port√°tiles lo est√°n mirando</a></li>
<li><a href="../455543/index.html">¬øEs f√°cil y conveniente preparar Kubernetes Cluster? Anunciar operador de complemento</a></li>
<li><a href="../455545/index.html">Construyendo procesos desde cero: del caos al orden</a></li>
<li><a href="../455547/index.html">Internet de las cosas en ruso. Baseband Hotel LoRaWAN para propietarios de RTL-SDR</a></li>
<li><a href="../455549/index.html">C√≥mo usar grupos de Facebook para promocionar: crear una web</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
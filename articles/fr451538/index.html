<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💇 🌀 🙏🏿 Guide de mise à l'échelle parallèle d'Amazon Redshift et résultats des tests 🥥 🈂️ 🏚️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chez Skyeng, nous utilisons Amazon Redshift, y compris la mise à l'échelle parallèle, donc l'article de Stefan Gromall, le fondateur de dotgo.com, pou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Guide de mise à l'échelle parallèle d'Amazon Redshift et résultats des tests</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/skyeng/blog/451538/"><img src="https://habrastorage.org/webt/mo/pi/gt/mopigtqlz7wpuhwhxsmrlcvgpky.png" alt="image"><br><br>  <i>Chez Skyeng, nous utilisons Amazon Redshift, y compris la mise à l'échelle parallèle, donc l'article de Stefan Gromall, le fondateur de dotgo.com, pour intermix.io, nous a semblé intéressant.</i>  <i>Après le transfert - un peu de notre expérience de l'ingénieur selon Daniyar Belkhodzhaev.</i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'architecture Amazon Redshift</a> permet la mise à l'échelle en ajoutant de nouveaux nœuds au cluster.  Devoir faire face au nombre maximal de demandes peut entraîner un surapprovisionnement des nœuds.  La mise à l'échelle de la concurrence, contrairement à l'ajout de nouveaux nœuds, augmente la puissance de calcul selon les besoins. <br><br>  La mise à l'échelle parallèle d'Amazon Redshift donne aux clusters Redshift une puissance supplémentaire pour gérer les demandes de pointe.  Il fonctionne en transférant les requêtes vers de nouveaux clusters «parallèles» en arrière-plan.  Les demandes sont acheminées en fonction de la configuration et des règles WLM. <br><a name="habracut"></a><br>  La tarification pour une mise à l'échelle parallèle est basée sur un modèle de crédit gratuit.  Au-dessus de la norme des prêts gratuits, le paiement est basé sur le moment où le cluster de mise à l'échelle parallèle traite les demandes. <br><br>  L'auteur a testé la mise à l'échelle parallèle sur l'un des clusters internes.  Dans cet article, il parlera des résultats du test et donnera des conseils sur la façon de commencer. <br><br><h3>  Exigences du cluster </h3><br>  Pour utiliser la mise à l'échelle parallèle, un cluster Amazon Redshift doit répondre aux exigences suivantes: <br><br><ul><li>  <b>plate</b> - <b>forme:</b> EC2-VPC; </li><li>  <b>type de noeud:</b> dc2.8xlarge, ds2.8xlarge, dc2.large ou ds2.xlarge; </li><li>  <b>nombre de nœuds:</b> de 2 à 32 (les clusters avec un nœud ne sont pas pris en charge). </li></ul><br><h3>  Types de demande valides </h3><br>  La mise à l'échelle parallèle ne convient pas à tous les types de requêtes.  Dans la première version, il ne traite que les requêtes de lecture qui remplissent trois conditions: <br><br><ul><li>  Requêtes SELECT en lecture seule (bien que d'autres types soient prévus); </li><li>  la requête ne fait pas référence à une table avec le classement INTERLEAVED; </li><li>  la requête n'utilise pas Amazon Redshift Spectrum pour référencer les tables externes. </li></ul><br>  Pour acheminer vers un cluster de mise à l'échelle parallèle, la demande doit être mise en file d'attente.  De plus, les requêtes adaptées à la file d'attente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SQA (Short Query Acceleration)</a> ne seront pas exécutées dans des clusters de mise à l'échelle parallèles. <br><br>  Les files d'attente et les SQA nécessitent la configuration correcte de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Redshift Workload Management (WLM)</a> .  Nous vous recommandons d'optimiser d'abord votre WLM - cela réduira le besoin de mise à l'échelle parallèle.  Et cela est important car la mise à l'échelle parallèle n'est gratuite que pendant un certain nombre d'heures.  AWS affirme que la mise à l'échelle parallèle sera gratuite pour 97% des clients, ce qui nous amène à la question de la tarification. <br><br><h3>  Coût de mise à l'échelle parallèle </h3><br>  Pour la mise à l'échelle parallèle, AWS propose un modèle de crédit.  Chaque cluster <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Amazon Redshift</a> actif accumule des prêts toutes les heures, jusqu'à une heure de prêts de mise à l'échelle parallèle gratuits par jour. <br><br>  Vous ne payez que lorsque l'utilisation de clusters de mise à l'échelle parallèles dépasse le montant des prêts que vous avez reçus. <br><br>  Le coût est calculé au taux de demande par seconde pour un cluster parallèle utilisé en plus du taux gratuit.  Le paiement est effectué uniquement lors de l'exécution de vos demandes, avec un paiement minimum d'une minute, chaque fois que vous activez un cluster de mise à l'échelle parallèle.  Le taux à la demande par seconde est calculé sur la base des principes généraux de la tarification <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Amazon Redshift</a> , c'est-à-dire qu'il dépend du type de nœud et du nombre de nœuds de votre cluster. <br><br><h3>  Exécution d'une mise à l'échelle parallèle </h3><br>  La mise à l'échelle parallèle démarre pour chaque file d'attente WLM.  Accédez à la console AWS Redshift et sélectionnez «Workload Management» dans le menu de navigation de gauche.  Sélectionnez le groupe WLM de votre cluster dans le menu déroulant suivant. <br><br>  Vous verrez une nouvelle colonne intitulée «Mode de mise à l'échelle simultanée» à côté de chaque file d'attente.  La valeur par défaut est «Off».  Cliquez sur "Modifier" et vous pouvez modifier les paramètres de chaque file d'attente. <br><br><img src="https://habrastorage.org/webt/rz/g9/mk/rzg9mkvwxcmlhry2v522jjrtcdk.png"><br><br><h3>  La configuration </h3><br>  La mise à l'échelle parallèle fonctionne en transmettant les requêtes pertinentes aux nouveaux clusters dédiés.  Les nouveaux clusters ont la même taille (type et nombre de nœuds) que le cluster principal. <br><br>  Le nombre par défaut de clusters utilisés pour la mise à l'échelle parallèle est de un (1) avec la possibilité de configurer un total de dix (10) clusters au total. <br>  Le nombre total de clusters pour une mise à l'échelle parallèle peut être défini par le paramètre max_concurrency_scaling_clusters.  L'augmentation de ce paramètre fournit des clusters redondants supplémentaires. <br><br><img src="https://habrastorage.org/webt/p6/we/qu/p6wequjhe3-yxannbvr_zndpqdg.png"><br><br><h3>  Suivi </h3><br>  La console AWS Redshift possède plusieurs graphiques supplémentaires.  Le graphique Max Configured Concurrency Scaling Clusters affiche la valeur de max_concurrency_scaling_clusters au fil du temps. <br><br><img src="https://habrastorage.org/webt/ti/mw/au/timwauz4qrbalhetjn3ttccxui4.png"><br><br>  Le nombre de clusters de mise à l'échelle actifs est affiché dans la section "Activité de mise à l'échelle des accès concurrents" de l'interface utilisateur: <br><br><img src="https://habrastorage.org/webt/zq/ai/xx/zqaixxhdn7i-pkwockkal_7ujvw.png"><br><br>  Dans l'onglet «Demandes», il y a une colonne indiquant si la demande a été exécutée dans le cluster principal ou dans le cluster de mise à l'échelle parallèle: <br><br><img src="https://habrastorage.org/webt/p-/sw/p8/p-swp8elamy2ecxarcydioa0_ac.png"><br><br>  Peu importe si une demande particulière a été exécutée dans le cluster principal ou via un cluster de mise à l'échelle parallèle, elle est stockée dans stl_query.concurrency_scaling_status. <br><br><img src="https://habrastorage.org/webt/kf/ns/_4/kfns_4r21bi4fbmqzpk2nfgv1ba.png"><br><br>  Une valeur de 1 indique que la demande s'exécutait dans un cluster de mise à l'échelle parallèle, tandis que d'autres valeurs indiquent qu'elle s'exécutait dans le cluster principal. <br><br>  Un exemple: <br><br><img src="https://habrastorage.org/webt/cn/3u/vh/cn3uvh7rn90c8bydqicyz3zlir8.png"><br><br>  Les informations sur la mise à l'échelle parallèle sont également stockées dans d'autres tables et vues, par exemple, SVCS_CONCURRENCY_SCALING_USAGE.  En outre, il existe un certain nombre de tables de catalogue qui stockent des informations sur la mise à l'échelle parallèle. <br><br><h3>  Résultats </h3><br>  Les auteurs ont lancé la mise à l'échelle parallèle pour une file d'attente dans le cluster interne vers 18 h 30 GMT le 29/03/2019. Nous avons changé le paramètre max_concurrency_scaling_clusters en 3 vers 20 h 30 le 29 mars 2019. <br><br>  Pour simuler la file d'attente des demandes, et réduit le nombre d'emplacements pour cette file d'attente de 15 à 5. <br><br>  Vous trouverez ci-dessous le diagramme du tableau de bord intermix.io montrant le nombre de demandes en cours d'exécution et mises en file d'attente après avoir diminué le nombre d'emplacements. <br><br><img src="https://habrastorage.org/webt/d4/0p/7q/d40p7qzi5ty79bbw_irhtk4qfzs.png"><br><br>  Nous voyons que le temps d'attente pour les demandes dans la file d'attente a augmenté, tandis que le temps maximum est supérieur à 5 minutes. <br><br><img src="https://habrastorage.org/webt/ov/xp/rn/ovxprnqxnz1fy9ds4xm4vmn6vte.png"><br><br>  Voici les informations pertinentes de la console AWS sur ce qui s'est passé pendant cette période: <br><br><img src="https://habrastorage.org/webt/rm/f-/ip/rmf-ipbke1vkled8fyo8zch9jpu.png"><br><br>  Redshift a lancé trois (3) clusters de mise à l'échelle parallèle tels que configurés.  Il semble que ces clusters n'aient pas été pleinement utilisés, même si de nombreuses demandes de notre cluster étaient en file d'attente. <br><br>  Le graphique d'utilisation est en corrélation avec le graphique d'activité de mise à l'échelle: <br><br><img src="https://habrastorage.org/webt/am/ho/yk/amhoykwqbkcttpfdiv5gvizkvog.png"><br><br>  Après quelques heures, les auteurs ont vérifié la file d'attente, et il semble que 6 requêtes ont été exécutées avec une mise à l'échelle parallèle.  Nous avons également vérifié de manière sélective deux demandes via l'interface utilisateur.  Ils n'ont pas vérifié comment utiliser ces valeurs lorsque plusieurs clusters parallèles sont actifs à la fois. <br><br><img src="https://habrastorage.org/webt/fi/2f/rb/fi2frbpdkxqfcj1q-4rp12wrjz4.png"><br><br><h3>  Conclusions </h3><br>  La mise à l'échelle parallèle peut réduire le temps d'attente des demandes lors des pics de charge. <br><br>  Selon les résultats du test de base, il s'est avéré que la situation des demandes de chargement s'est partiellement améliorée.  Cependant, la mise à l'échelle parallèle à elle seule n'a pas résolu tous les problèmes de concurrence. <br><br>  Cela est dû aux restrictions sur les types de requêtes qui peuvent utiliser la mise à l'échelle parallèle.  Par exemple, les auteurs ont de nombreuses tables avec des clés de tri entrelacées, et la majeure partie de notre charge de travail est un enregistrement. <br><br>  Bien que la mise à l'échelle parallèle ne soit pas une solution universelle dans la configuration WLM, dans tous les cas, l'utilisation de cette fonction est simple et compréhensible. <br><br>  Par conséquent, l'auteur recommande de l'utiliser pour vos files d'attente WLM.  Commencez avec un seul cluster parallèle et surveillez la charge de pointe via la console pour déterminer si les nouveaux clusters sont pleinement utilisés. <br><br>  À mesure qu'AWS ajoute la prise en charge de types supplémentaires de requêtes et de tables, la mise à l'échelle parallèle devrait progressivement devenir de plus en plus efficace. <br><blockquote>  <b>Commentaire de Belkhodzhaev Daniyar, ingénieur selon Skyeng</b> <br><br>  Chez Skyeng, nous avons également immédiatement attiré l'attention sur la possibilité émergente d'une mise à l'échelle parallèle. <br>  La fonctionnalité est très attrayante, d'autant plus que, selon AWS, la plupart des utilisateurs n'ont même pas à payer de supplément pour cela. <br><br>  Il s'est avéré qu'à la mi-avril, nous avons eu une vague inhabituelle de demandes au cluster Redshift.  Au cours de cette période, nous avons souvent eu recours à l'aide de la mise à l'échelle de la concurrence, parfois le cluster supplémentaire fonctionnait 24h / 24 sans s'arrêter. <br><br>  Cela a permis, si ce n'est de résoudre complètement le problème de file d'attente, au moins de rendre la situation acceptable. <br><br>  Nos observations coïncident en grande partie avec l'impression des gars de intermix.io. <br><br>  Nous avons également remarqué que malgré la présence de demandes en attente dans la file d'attente, toutes les demandes n'étaient pas immédiatement redirigées vers un cluster parallèle.  Apparemment, cela est dû au fait que le cluster parallèle prend encore du temps pour démarrer.  Par conséquent, lors de pics de charge à court terme, nous avons encore de petites files d'attente et les alarmes correspondantes ont le temps de fonctionner. <br><br>  Après avoir éliminé les charges anormales en avril, nous nous attendions, comme AWS, à un mode d'utilisation épisodique - dans le cadre de la norme gratuite. <br>  Vous pouvez suivre les coûts de mise à l'échelle simultanés dans AWS Cost Explorer.  Vous devez sélectionner Service - Redshift, Type d'utilisation - CS, par exemple, USW2-CS: dc2.large. <br><br>  Les détails des prix en russe peuvent être trouvés <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici.</a> </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451538/">https://habr.com/ru/post/fr451538/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451522/index.html">Nous déployons l'automatisation en quelques heures: TypeScript, Protractor, Jasmine</a></li>
<li><a href="../fr451524/index.html">L'histoire de la rupture de la bouilloire Autoplay Media Studio 8.5.3.0</a></li>
<li><a href="../fr451528/index.html">«Et c'est ainsi»: que les fournisseurs de cloud ne s'entendent pas sur les données personnelles</a></li>
<li><a href="../fr451532/index.html">Nouvelles du monde d'OpenStreetMap n ° 459 (30/04/2019 - 06/05/2019)</a></li>
<li><a href="../fr451534/index.html">12 principes d'animation dans le développement de jeux vidéo</a></li>
<li><a href="../fr451540/index.html">Combien de développeurs ont besoin de créer un service comme Airbnb</a></li>
<li><a href="../fr451542/index.html">Comment et pourquoi avons-nous fait une reconnaissance historique dans Mail.ru Cloud</a></li>
<li><a href="../fr451552/index.html">Nous construisons des canaux de vente en réseau du gadget DO-RA</a></li>
<li><a href="../fr451556/index.html">Flutter: localisation d'applications à l'aide d'Android Studio</a></li>
<li><a href="../fr451558/index.html">Un jour dans la vie de l'automatisation QA</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
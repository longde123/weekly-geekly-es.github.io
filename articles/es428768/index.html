<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßë‚Äçü§ù‚Äçüßë üõãÔ∏è üë©üèø‚Äç‚úàÔ∏è En tres art√≠culos sobre m√≠nimos cuadrados: programa educativo sobre teor√≠a de probabilidad üìø üê∫ üéá</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hace un a√±o y medio, publiqu√© el art√≠culo "Matem√°ticas en los dedos: m√©todos de m√≠nimos cuadrados" , que recibi√≥ una respuesta muy decente, que, entre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>En tres art√≠culos sobre m√≠nimos cuadrados: programa educativo sobre teor√≠a de probabilidad</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428768/">  Hace un a√±o y medio, publiqu√© el art√≠culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Matem√°ticas en los dedos: m√©todos de m√≠nimos cuadrados"</a> , que recibi√≥ una respuesta muy decente, que, entre otras cosas, consisti√≥ en el hecho de que propuse dibujar un b√∫ho.  Bueno, como un b√∫ho, debes explicarlo de nuevo.  En una semana, sobre este tema exactamente, comenzar√© a dar varias conferencias a estudiantes de geolog√≠a;  Aprovecho esta oportunidad, presento aqu√≠ los puntos principales (adaptados) como un borrador.  ¬°Mi objetivo principal no es dar una receta preparada de un libro sobre comida sabrosa y saludable, sino explicar por qu√© es as√≠ y qu√© m√°s hay en la secci√≥n correspondiente, porque las conexiones entre las diferentes secciones de matem√°ticas son las m√°s interesantes! <br><br>  Por el momento, tengo la intenci√≥n de romper el texto de la siguiente manera: <br><br><ul><li>  <b>Programa educativo sobre teor√≠a de la probabilidad (art√≠culo introductorio, opcional)</b> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Introducci√≥n a los sistemas lineales de ecuaciones.</a> <br></li><li>  M√©todos de elementos finitos <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Minimizaci√≥n de formas cuadr√°ticas y ejemplos de problemas de MCO</a> <br></li><li>  De m√≠nimos cuadrados a redes neuronales <br></li></ul><br>  Ir√© a los m√≠nimos cuadrados un poco de lado, a trav√©s del principio de m√°xima verosimilitud, y requiere una orientaci√≥n m√≠nima en la teor√≠a de la probabilidad.  Este texto est√° dise√±ado para el tercer a√±o de nuestra facultad de geolog√≠a, lo que significa (¬°desde el punto de vista del equipo involucrado!) Que un estudiante de secundaria interesado con el celo apropiado deber√≠a poder entenderlo. <br><br><h1>  ¬øCu√°n s√≥lido es el te√≥rico o crees en la teor√≠a de la evoluci√≥n? </h1><br>  Un d√≠a me preguntaron si creo en la teor√≠a de la evoluci√≥n.  Pausa en este momento, piensa en c√≥mo responder√°s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/df1/f2b/6c0/df1f2b6c06daa3cf6d1e145eef8254be.png"><br><a name="habracut"></a><br>  Personalmente, me sorprendi√≥, respondi√≥ que me parece cre√≠ble y que la cuesti√≥n de la fe no surge aqu√≠ en absoluto.  La teor√≠a cient√≠fica tiene poco que ver con la fe.  En resumen, la teor√≠a solo construye un modelo del mundo que nos rodea, no hay necesidad de creer en √©l.  Adem√°s, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el criterio de Popper</a> requiere una teor√≠a cient√≠fica para poder refutar.  Y tambi√©n una teor√≠a s√≥lida debe poseer, en primer lugar, poder predictivo.  Por ejemplo, si modifica gen√©ticamente los cultivos de tal manera que ellos mismos produzcan pesticidas, es l√≥gico que aparezcan insectos resistentes a ellos.  Sin embargo, es significativamente menos obvio que este proceso puede ralentizarse si se cultivan plantas comunes junto con otras gen√©ticamente modificadas.  Basado en la teor√≠a de la evoluci√≥n, la simulaci√≥n correspondiente hizo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tal predicci√≥n</a> , y parece <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">confirmarse</a> . <br><br><h5>  ¬øY qu√© tienen que ver los m√≠nimos cuadrados con √©l? </h5><br>  Como mencion√© anteriormente, ir√© a los m√≠nimos cuadrados a trav√©s del principio de m√°xima verosimilitud.  Vamos a ilustrar con un ejemplo.  Supongamos que estamos interesados ‚Äã‚Äãen datos sobre el crecimiento de ping√ºinos, pero solo podemos medir algunas de estas hermosas aves.  Es bastante l√≥gico introducir un modelo de distribuci√≥n de crecimiento en la tarea; la mayor√≠a de las veces es normal.  La distribuci√≥n normal se caracteriza por dos par√°metros: valor medio y desviaci√≥n est√°ndar.  Para cada valor fijo de los par√°metros, podemos calcular la probabilidad de que se generen exactamente las mediciones que realizamos.  Adem√°s, al variar los par√°metros, encontramos aquellos que maximizan la probabilidad. <br><br>  Por lo tanto, para trabajar con la m√°xima probabilidad, necesitamos operar en t√©rminos de teor√≠a de la probabilidad.  Un poco m√°s abajo, en los dedos, definimos el concepto de probabilidad y probabilidad, pero primero me gustar√≠a centrarme en otro aspecto.  Sorprendentemente, rara vez veo personas pensando en la palabra "teor√≠a" en la frase "teor√≠a de la probabilidad". <br><br><h5>  ¬øQu√© es aprender theorver? </h5><br>  Con respecto a los or√≠genes, los significados y el alcance de las estimaciones de probabilidad, el debate violento ha estado ocurriendo durante m√°s de cien a√±os.  Por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bruno De Finetti</a> afirm√≥ que la probabilidad no es m√°s que un an√°lisis subjetivo de la probabilidad de que algo suceda, y que esta probabilidad no existe fuera de la mente.  Esta es la voluntad de una persona de apostar a que algo suceda.  Esta opini√≥n es directamente opuesta a la opini√≥n de los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cl√°sicos / freventistas</a> sobre la probabilidad de un resultado espec√≠fico de un evento, en el que se supone que el mismo evento puede repetirse varias veces, y la "probabilidad" de un resultado particular est√° relacionada con la frecuencia de un resultado espec√≠fico que se cae durante las pruebas repetidas.  Adem√°s de subjetivistas y freventistas, tambi√©n hay objetivistas que sostienen que las probabilidades son aspectos reales del universo, y no solo descripciones del grado de confianza del observador. <br><br>  Sea como fuere, pero las tres escuelas cient√≠ficas en la pr√°ctica usan el mismo aparato basado en los axiomas de Kolmogorov.  Demos un argumento indirecto, desde un punto de vista subjetivista, a favor de la teor√≠a de la probabilidad, construida sobre los axiomas de Kolmogorov.  Les damos a los axiomas un poco m√°s tarde, pero para empezar asumiremos que tenemos una casa de apuestas que aceptar√° apuestas en la pr√≥xima Copa del Mundo.  Tengamos dos eventos: a = el equipo de Uruguay se convertir√° en el campe√≥n, b = el equipo alem√°n se convertir√° en el campe√≥n.  La casa de apuestas estima las posibilidades de que el equipo de Uruguay gane en un 40%, las posibilidades del equipo alem√°n en un 30%.  Obviamente, tanto Alemania como Uruguay no pueden ganar al mismo tiempo, por lo tanto, la probabilidad de a‚àßb es cero.  Bueno, al mismo tiempo, la casa de apuestas cree que la probabilidad de que Uruguay o Alemania (y no Argentina o Australia) gane es del 80%.  Escrib√°moslo de la siguiente forma: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b01/b95/384/b01b9538401e50ea965ee6592f3981a1.png"><br><br>  Si el corredor de apuestas afirma que su grado de confianza en el evento <i>a</i> es 0.4, es decir, <i>P (a)</i> = 0.4, entonces el jugador puede elegir si apostar√° a favor o en contra de decir <i>a</i> , cantidades de apuestas que son compatibles con el grado de confianza del corredor de apuestas.  Esto significa que el jugador puede apostar que el evento suceder√° apostando cuatro rublos contra seis rublos de la casa de apuestas.  O un jugador puede apostar seis rublos en lugar de cuatro rublos de una casa de apuestas que el evento no suceder√°. <br><br>  Si el grado de confianza del corredor de apuestas no refleja con precisi√≥n el estado del mundo, entonces podemos contar con el hecho de que a la larga perder√° dinero para los jugadores cuyas creencias son m√°s precisas.  Adem√°s, en este ejemplo en particular, el jugador tiene una estrategia en la cual el corredor de apuestas <b>siempre</b> pierde dinero.  Vamos a ilustrarlo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/87c/97d/a15/87c97da153047340db4a3bbfb078c308.png"><br><br>  El jugador hace tres apuestas, y sea cual sea el resultado del campeonato, siempre gana.  Tenga en cuenta que la consideraci√≥n de las ganancias en principio no incluye si Uruguay o Alemania son los favoritos del campeonato, ¬°la p√©rdida de la casa de apuestas est√° garantizada!  Esta situaci√≥n fue conducida por el hecho de que el corredor de apuestas no se gui√≥ por los fundamentos de la teor√≠a de la probabilidad, habiendo violado el tercer axioma de Kolmogorov, traigamos los tres: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7ba/3c9/f5a/7ba3c9f5aaaf940ba9948be6bd5d23be.png"><br><br>  En forma de texto, se ven as√≠: <br><br><ul><li>  1. Todas las probabilidades van de 0 a 1 </li><li>  2. Por supuesto, las declaraciones verdaderas tienen una probabilidad de 1, y ciertamente una probabilidad falsa de 0. </li><li>  3. El tercer axioma es el axioma de la disyunci√≥n, es f√°cil de entender intuitivamente, observando que aquellos casos en los que el enunciado <i>a</i> es verdadero, junto con los casos en que <i>b</i> es verdadero, ciertamente cubre todos los casos en los que el enunciado a‚à®b es verdadero;  pero en la suma de dos conjuntos de casos, su intersecci√≥n ocurre dos veces, por lo tanto, es necesario restar P (a‚àßb). </li></ul><br>  En 1931, de Finetti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">demostr√≥ una</a> declaraci√≥n muy fuerte: <br><blockquote>  Si el corredor de apuestas se gu√≠a por muchos grados de confianza, lo que viola los axiomas de la teor√≠a de la probabilidad, entonces existe una combinaci√≥n de apuestas de jugador que garantiza la p√©rdida del corredor de apuestas (el jugador gana) en cada apuesta. <br></blockquote><br>  Se puede considerar que los axiomas de las probabilidades limitan el conjunto de creencias probabil√≠sticas que un agente puede tener.  Tenga en cuenta que seguir al corredor de apuestas no implica los axiomas de Kolmogorov de que ganar√° (dejaremos de lado los problemas de comisi√≥n), pero si no los sigue, se garantizar√° que perder√°.  Tenga en cuenta que se han presentado otros argumentos a favor de la aplicaci√≥n de probabilidades;  pero fue el √©xito <i>pr√°ctico</i> de los sistemas de razonamiento basados ‚Äã‚Äãen la teor√≠a de la probabilidad lo que result√≥ ser un incentivo atractivo que provoc√≥ una revisi√≥n de muchos puntos de vista. <br><br>  Entonces, abrimos ligeramente el velo de <b>por qu√©</b> Theorver puede tener sentido, pero ¬øqu√© tipo de objetos manipula?  Toda la teor√≠a se basa en solo tres axiomas;  los tres involucran alguna funci√≥n m√°gica <i>P.</i>  Adem√°s, al observar estos axiomas, me recuerda mucho la funci√≥n del √°rea de forma.  Intentemos ver si el √°rea funciona para determinar la probabilidad. <br><br>  Definimos la palabra "evento" como "un subconjunto de un cuadrado de la unidad".  Definimos la palabra "probabilidad de un evento" como "el √°rea del subconjunto correspondiente".  Hablando en t√©rminos generales, tenemos un gran objetivo de cart√≥n, y nosotros, habiendo cerrado los ojos, le disparamos.  Las posibilidades de que una bala caiga en un conjunto dado son directamente proporcionales al √°rea del conjunto.  Un evento confiable en este caso es el cuadrado completo, y obviamente falso, por ejemplo, cualquier punto del cuadrado.  De nuestra definici√≥n de probabilidad se deduce que es imposible llegar al punto perfectamente (nuestra vi√±eta es un punto material).  Realmente me gustan las im√°genes, y dibujo muchas de ellas, ¬°y el final no es una excepci√≥n!  Vamos a ilustrar los tres axiomas: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/205/9fc/35e/2059fc35ef9996e3410786a23ba71570.png"><br><br>  Entonces, se cumple el primer axioma: el √°rea no es negativa y no puede exceder las unidades.  Un evento confiable es todo el cuadrado, y uno deliberadamente falso es cualquier conjunto de √°rea cero.  ¬°Y funciona perfectamente con la disyunci√≥n! <br><br><h1>  M√°xima credibilidad con ejemplos </h1><br><h5>  Ejemplo uno: lanzamiento de moneda </h5><br>  Veamos el ejemplo m√°s simple de un lanzamiento de moneda, tambi√©n conocido como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el esquema de Bernoulli</a> .  Se llevan a cabo <i>N</i> experimentos, en cada uno de los cuales puede ocurrir uno de los dos eventos ("√©xito" o "fracaso"), uno con probabilidad <i>p</i> y el segundo con probabilidad <i>1-p</i> .  Nuestra tarea es encontrar la probabilidad de obtener exactamente <i>k</i> √©xitos en estos <i>n</i> experimentos.  Esta probabilidad nos da la f√≥rmula de Bernoulli: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ce6/9b2/2ef/ce69b22ef6bfbfa7e2e2276ea3b8df8c.png"><br><br>  Tome una moneda com√∫n ( <i>p = 0.5</i> ), t√≠rela diez veces ( <i>n = 10</i> ) y considere cu√°ntas veces se caen las colas: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d1a/78d/d1e/d1a78dd1e213244a7b1c31ab6f1381d4.png"><br><br>  Aqu√≠ hay un gr√°fico de densidad de probabilidad: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86b/a6e/4bc/86ba6e4bcb12aaadb5fa1f0e89a4f699.png"><br><br>  Por lo tanto, si fijamos la probabilidad del inicio del "√©xito" (0.5), y tambi√©n registramos el n√∫mero de experimentos (10), entonces el n√∫mero posible de "√©xitos" puede ser cualquier n√∫mero entero entre 0 y 10, sin embargo, estos resultados no son igualmente probables.  Es obvio que obtener cinco "√©xitos" es mucho m√°s probable que ninguno.  Por ejemplo, la probabilidad de contar siete colas es aproximadamente del 12%. <br><br>  Ahora veamos la misma tarea desde el otro lado.  Tenemos una moneda real, pero no sabemos su distribuci√≥n de la probabilidad a priori de "√©xito" / "fracaso".  Sin embargo, podemos lanzarlo diez veces y contar el n√∫mero de "√©xitos".  Por ejemplo, tenemos siete colas.  ¬øC√≥mo nos ayuda esto a evaluar <i>p</i> ? <br><br>  Podemos intentar arreglar <i>n</i> = 10 y <i>k</i> = 7 en la f√≥rmula de Bernoulli, dejando <i>p un</i> par√°metro libre: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f89/4de/196/f894de1965d550e7508a2b2e83d17901.png"><br><br>  Entonces la f√≥rmula de Bernoulli se puede interpretar como la <i>probabilidad del</i> par√°metro estimado (en este caso, <i>p</i> ).  Incluso cambi√© la letra de la funci√≥n, ahora es <i>L</i> (del ingl√©s).  Es decir, la probabilidad es la probabilidad de generar datos de observaci√≥n (7 colas de 10 experimentos) para un valor dado de los par√°metros. <br><br>  Por ejemplo, la probabilidad de una moneda equilibrada ( <i>p</i> = 0.5), siempre que ocurran siete colas de diez tiros, es aproximadamente del 12%.  Puedes trazar la funci√≥n <i>L</i> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bca/da0/5e8/bcada05e8fdd206495376852f88aafb8.png"><br><br>  Entonces, estamos buscando un valor de par√°metros que maximice la probabilidad de obtener las observaciones que tenemos.  En este caso particular, tenemos una funci√≥n de una variable, estamos buscando su m√°ximo.  Para facilitar la b√∫squeda, buscar√© un m√°ximo de no <i>L</i> , sino <i>log L.</i>  El logaritmo es una funci√≥n estrictamente monot√≥nica, por lo que maximizar uno y el otro es exactamente lo mismo.  Y el logaritmo divide el producto en una cantidad que es mucho m√°s conveniente para diferenciar.  Entonces, estamos buscando el m√°ximo de esta funci√≥n: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/915/407/504/915407504c2f92b808ff7c0bd8319320.png"><br><br>  Para hacer esto, equiparamos su derivada a cero: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/43b/428/a01/43b428a015cd2f25e188751c0c553418.png"><br><br>  La derivada de log x = 1 / x, obtenemos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d0f/8b7/e30/d0f8b7e3049a4d37fc1489c3a02003d6.png"><br><br>  Es decir, la probabilidad m√°xima (aproximadamente 27%) se alcanza en <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0e4/ee1/229/0e4ee12290100d8657e411e2719ed57d.png"><br><br>  Por si acaso, calculamos la segunda derivada: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/96f/5de/ba4/96f5deba4461fd3360dbefb29713c802.png"><br><br>  En el punto p = 0.7, es negativo, por lo que este punto es realmente el m√°ximo de la funci√≥n L. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/931/bfe/6c9/931bfe6c9f2fb93c0c9ec7036a67b74c.png"><br><br>  Y aqu√≠ est√° la densidad de probabilidad para el esquema de Bernoulli con <i>p</i> = 0.7: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c33/90c/180/c3390c180591b89bda8487b04f97ff66.png"><br><br><h5>  Ejemplo dos: ADC </h5><br>  Imaginemos que tenemos una cierta cantidad f√≠sica constante que queremos medir, ya sea una longitud con una regla o un voltaje con un volt√≠metro.  Cualquier medida da una <b>aproximaci√≥n de</b> esta cantidad, pero no la cantidad misma.  Los m√©todos que describo aqu√≠ fueron desarrollados por Gauss a fines del siglo XVIII, cuando midi√≥ las √≥rbitas de los cuerpos celestes. <br><br>  Por ejemplo, si medimos el voltaje de la bater√≠a N veces, obtenemos N mediciones diferentes.  ¬øCu√°l tomar?  Eso es todo!  Entonces, tengamos N cantidades Uj: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f5d/7c6/821/f5d7c6821d43ed3b9bf9128d52876b2e.png"><br><br>  Suponga que cada medida Uj es igual a un valor ideal, m√°s un ruido gaussiano, que se caracteriza por dos par√°metros: la posici√≥n de la campana gaussiana y su "ancho".  Aqu√≠ est√° la densidad de probabilidad: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ded/0d3/b40/ded0d3b40c8478f5e7a01889b5c8b100.png"><br><br>  Es decir, teniendo N valores dados de Uj, nuestra tarea es encontrar dicho par√°metro, U que maximice el valor de probabilidad.  La credibilidad (de inmediato tomo el logaritmo) se puede escribir de la siguiente manera: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/49c/ad9/a23/49cad9a2301ad0795567364befad5ea5.png"><br><br>  Bueno, entonces todo es estrictamente como antes, equiparamos a cero derivadas parciales con respecto a los par√°metros que estamos buscando: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4fe/d44/7d5/4fed447d51696fde602a9db5a7fe816e.png"><br><br>  Encontramos que la estimaci√≥n m√°s probable de la cantidad desconocida U se puede encontrar como el promedio de todas las mediciones: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b46/281/4f1/b462814f1a8a19167396798177a42ee5.png"><br><br>  Bueno, el par√°metro sigma m√°s probable es la desviaci√≥n est√°ndar habitual: <br><img src="https://habrastorage.org/getpro/habr/post_images/3c5/a74/194/3c5a741948e8a96dbaac24244c7daabd.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e3f/17f/422/e3f17f4222ee89afaecaffde3453dfec.png"><br><br>  ¬øVali√≥ la pena molestarse en obtener un promedio simple de todas las mediciones en la respuesta?  Para mi gusto, vali√≥ la pena.  Por cierto, promediar m√∫ltiples mediciones de un valor constante para aumentar la precisi√≥n de las mediciones es una pr√°ctica est√°ndar.  Por ejemplo, el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">promedio de ADC</a> .  Por cierto, para este ruido gaussiano no es necesario, es suficiente que el ruido sea imparcial. <br><br><h5>  Ejemplo tres, y nuevamente unidimensional </h5><br>  Continuamos la conversaci√≥n, tomemos el mismo ejemplo, pero lo complicamos un poco.  Queremos medir la resistencia de cierta resistencia.  Con la ayuda de una fuente de alimentaci√≥n de laboratorio, podemos pasar un n√∫mero est√°ndar de amperios a trav√©s de ella y medir el voltaje que se necesitar√° para esto.  Es decir, tendremos N pares de n√∫meros (Ij, Uj) en la entrada de nuestro evaluador de resistencia. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2b6/3c7/af0/2b63c7af0ec6024be16c1c4bd4a28dbc.png"><br><br>  Dibuja estos puntos en la tabla;  La ley de Ohm nos dice que estamos buscando la pendiente de la l√≠nea azul. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e4c/211/d7f/e4c211d7f3c34742ac53e18461818691.png"><br><br>  Escribimos la expresi√≥n para la probabilidad del par√°metro R: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/655/c9c/b8d/655c9cb8d1cb7429abd317016d09ce47.png"><br><br>  Y nuevamente, equiparamos a cero la derivada parcial correspondiente: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e7e/737/2bb/e7e7372bbb5f7f138e0e5858039617c7.png"><br><br>  Entonces la resistencia R m√°s plausible se puede encontrar mediante la siguiente f√≥rmula: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/529/877/57b/52987757bc0127158af6e642591b35d7.png"><br><br>  Este resultado ya es algo menos obvio que el promedio simple de todas las mediciones.  Tenga en cuenta que si tomamos cien mediciones en la regi√≥n de un amperio, y una medici√≥n en la regi√≥n de un kilo amperio, entonces las cien mediciones anteriores pr√°cticamente no afectar√°n el resultado.  Recordemos este hecho, nos ser√° √∫til en el pr√≥ximo art√≠culo. <br><br><h1>  Cuarto ejemplo: Volver a los m√≠nimos cuadrados </h1><br>  Seguramente ya habr√° notado que en los √∫ltimos dos ejemplos, maximizar el logaritmo de probabilidad es equivalente a minimizar la suma de los cuadrados del error de estimaci√≥n.  Veamos otro ejemplo.  Tome la calibraci√≥n de la romana usando pesas de referencia.  Supongamos que tenemos N cargas de masa de referencia xj, cu√©lguelas en una romana y mida la longitud del resorte, obtenemos N longitudes de resorte yj: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2ca/4c1/d86/2ca4c1d86e78cd4fd2d6f9d7b3052777.png"><br><br>  La ley de Hooke nos dice que la extensi√≥n del resorte depende linealmente de la fuerza aplicada, y esta fuerza incluye el peso de los bienes y el peso del resorte mismo.  Deje que la rigidez del resorte sea el par√°metro <i>a</i> , pero la tensi√≥n del resorte bajo su propio peso es el par√°metro b.  Entonces podemos escribir la expresi√≥n de la probabilidad de nuestras mediciones de esta manera (como antes, bajo la hip√≥tesis del ruido de medici√≥n gaussiano): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ce4/e81/011/ce4e81011eae69c44d9e88cfe82fc09a.png"><br><br>  La maximizaci√≥n de probabilidad de L es equivalente a minimizar la suma de los cuadrados de los errores de estimaci√≥n, es decir, podemos buscar el m√≠nimo de la funci√≥n S definida de la siguiente manera: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18e/272/2eb/18e2722ebe081756bd8e871588361d5f.png"><br><br>  En otras palabras, estamos buscando una l√≠nea recta que minimice la suma de los cuadrados de las longitudes de los segmentos verdes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c5a/a80/f6a/c5aa80f6a2e9575abfa7b3dfdabf5c5a.png" width="300"><br><br>  Bueno, entonces no hay sorpresas, establecemos derivadas parciales a cero: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b09/a29/620/b09a29620438327e5a5bffb827a5dfa6.png"><br><br>  Obtenemos un sistema de dos ecuaciones lineales con dos inc√≥gnitas: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0a9/d2f/f75/0a9d2ff75a4cb635434dc1e7eb267699.png"><br><br>  Recordamos el s√©ptimo grado de la escuela y escribimos la soluci√≥n: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/806/982/b11/806982b116726fcc07d1d4935efa3970.png"><br><br><h1>  Conclusi√≥n </h1><br>  Los m√©todos de m√≠nimos cuadrados son un caso especial de maximizar la probabilidad para aquellos casos en que la densidad de probabilidad es gaussiana.  En el caso de que la densidad sea (en absoluto) gaussiana, los m√≠nimos cuadrados dan una estimaci√≥n que difiere de la MLE (estimaci√≥n de semejanza m√°xima).  Por cierto, en un momento, Gauss plante√≥ la hip√≥tesis de que la distribuci√≥n no juega un papel, solo la independencia de las pruebas es importante. <br><br>  Como puede ver en este art√≠culo, cuanto m√°s se adentra en el bosque, m√°s engorrosas son las soluciones anal√≠ticas para este problema.  Bueno, s√≠, no estamos en el siglo XVIII, ¬°tenemos computadoras!  La pr√≥xima vez veremos un enfoque geom√©trico y, luego, program√°tico para el problema de OLS, permanezca en la l√≠nea. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es428768/">https://habr.com/ru/post/es428768/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es428756/index.html">Facializing con Machine Learning</a></li>
<li><a href="../es428758/index.html">Falta de habilidades inform√°ticas en estudiantes de secundaria</a></li>
<li><a href="../es428760/index.html">C√≥mo estirar el gzom del editor: podcast GLPH</a></li>
<li><a href="../es428762/index.html">Food Design Digest Octubre 2018</a></li>
<li><a href="../es428766/index.html">El resumen de materiales frescos del mundo del front-end para la √∫ltima semana No. 337 (29 de octubre - 4 de noviembre de 2018)</a></li>
<li><a href="../es428770/index.html">Macros de teclado para tareas cotidianas</a></li>
<li><a href="../es428772/index.html">Democratizaci√≥n de los datos de Uber.</a></li>
<li><a href="../es428774/index.html">Firewall GPS para centros de datos: por qu√© es necesario y c√≥mo funciona</a></li>
<li><a href="../es428776/index.html">Una nueva realizaci√≥n de la curiosidad en IA. Entrenamiento con una recompensa que depende de la dificultad para predecir el resultado</a></li>
<li><a href="../es428778/index.html">Ver lo invisible. Infrarrojo cercano (0.9-1.7Œºm)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
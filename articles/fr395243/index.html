<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⏬ 👸 👩🏼‍🤝‍👩🏻 L'IA génère des sons réalistes dans les images 🚃 💫 👩🏾‍🍳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Des employés du Massachusetts Institute of Computer Science and Artificial Intelligence Laboratory (CSAIL) et Google Research ont conçu un réseau de n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>L'IA génère des sons réalistes dans les images</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/395243/"><img src="https://habrastorage.org/files/ffc/d91/c15/ffcd91c151014c829f06083223c2a1ec.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Des employés </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">du</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Massachusetts Institute of </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">Computer Science and Artificial Intelligence Laboratory</font></a><font style="vertical-align: inherit;"> (CSAIL) et Google Research ont conçu un réseau de neurones qui a appris à </font><font style="vertical-align: inherit;">produire des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">séquences vidéo arbitraires</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , à générer des sons réalistes et à prédire les propriétés des objets. </font><font style="vertical-align: inherit;">Le programme analyse la vidéo, reconnaît les objets, leur mouvement et le type de contact - choc, glissement, frottement, etc. </font><font style="vertical-align: inherit;">Sur la base de ces informations, il génère un son qu'une personne dans 40% des cas considère comme plus réaliste que le vrai.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les scientifiques suggèrent que ce développement sera largement utilisé au cinéma et à la télévision pour générer des effets sonores à partir d'une séquence vidéo sans son. </font><font style="vertical-align: inherit;">De plus, il peut être utile pour entraîner des robots de mieux comprendre les propriétés du monde.</font></font><br>
<a name="habracut"></a><br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://www.youtube.com/embed/0FW99AQmMc8%3Ffeature%3Doembed&amp;usg=ALkJrhilioBiQkUkBQmEzRyvnBuFWKZKxw" frameborder="0" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les sons ambiants en disent long sur les propriétés des objets environnants, donc dans le processus d'auto-apprentissage, les futurs robots peuvent agir comme des enfants - toucher des objets, les essayer au toucher, enfoncer un bâton en eux, essayer de bouger, de soulever. Dans ce cas, le robot reçoit une rétroaction, reconnaissant les propriétés de l'objet - son poids, son élasticité, etc. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le son émis par un objet en contact contient également des informations importantes sur les propriétés de l'objet. «Lorsque vous faites glisser votre doigt sur un verre de vin, le son que vous faites correspond à la quantité de liquide versée dans le verre», explique </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Andrew Owens</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font><font style="vertical-align: inherit;">étudiant diplômé </font><font style="vertical-align: inherit;">, auteur principal d'un article scientifique publié, qui n'est pas encore prêt pour une revue scientifique, mais seulement </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publié.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">accessible au public sur arXiv.org. La présentation des travaux scientifiques aura lieu à la conférence annuelle sur la vision industrielle et la reconnaissance des formes (CVPR) à Las Vegas ce mois-ci. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les scientifiques ont sélectionné 977 vidéos dans lesquelles les gens effectuent des actions avec des objets environnants, constitués de divers matériaux: gratter, les battre avec un bâton, etc. Au total, les vidéos contenaient 46 577 actions. Les élèves du CSAIL ont marqué manuellement toutes les actions, en indiquant le type de matériau, le lieu de contact, le type d'action (choc / grattage / autre) et le type de réaction du matériau ou de l'objet (déformation, forme statique, mouvement dur, etc.). Des vidéos avec du son ont été utilisées pour former le réseau neuronal, et des étiquettes placées manuellement ont été utilisées </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">uniquement pour analyser le</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> résultat de la formation du réseau neuronal, mais </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pas pour le former.</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br>
<img src="https://habrastorage.org/files/bc6/750/52a/bc675052a44746f08b569350f7b6481c.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le réseau neuronal a analysé les caractéristiques du son qui correspondent à chaque type d'interaction avec les objets - volume, hauteur et autres caractéristiques. Au cours de la formation, le système a étudié la vidéo image par image, analysé le son dans cette image et trouvé une correspondance avec le son le plus similaire dans la base de données déjà accumulée. Le plus important était d'apprendre au réseau neuronal à étirer le son en images. </font></font><br>
<br>
<img src="https://habrastorage.org/files/5bd/97d/f05/5bd97df05e7b4df88695bbc282d8e93a.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Avec chaque nouvelle vidéo, la précision de la prédiction des sons augmentait. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le son généré par le réseau de neurones pour différentes scènes, par rapport à la réalité</font></font></b><br>
<img src="https://habrastorage.org/files/657/99e/efb/65799eefbb5149d2ad06460f27cdd984.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
, ce qui a permis au réseau de neurones d'apprendre à prédire avec précision les sons les plus divers avec toutes les nuances: des pierres qui frappent au lierre bruissant.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
«Les approches actuelles des chercheurs dans le domaine de l'intelligence artificielle se concentrent sur un seul des cinq sens: les spécialistes de la vision industrielle étudient les images visuelles, les spécialistes de la reconnaissance vocale étudient le son, etc.», </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">explique</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Abhinav Gupta, professeur adjoint de robotique à l'Université Carnegie Mellon. «Cette étude est un pas dans la bonne direction qui imite le processus d'apprentissage de la même manière que les gens, c'est-à-dire en intégrant le son et la vision.» </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour tester l'efficacité de l'IA, les scientifiques ont mené une étude en ligne sur Amazon Mechanical Turk, dont les participants ont été invités à comparer deux options pour le son d'une vidéo particulière et à déterminer quel son est réel et lequel ne l'est pas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À la suite de l'expérience, l'IA a </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">réussi à tromper les gens dans 40% des cas</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Cependant, selon </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">certains commentateurs sur les forums</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , il n'est pas si difficile de tromper une personne, car une partie importante des connaissances sur l'image sonore du monde est obtenue par les gens modernes à partir de longs métrages et de jeux informatiques. La gamme sonore pour les films et les jeux est composée de spécialistes utilisant des collections d'échantillons standard. Autrement dit, nous entendons constamment la même chose. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans une expérience en ligne, dans deux cas sur cinq, les gens pensaient que le son généré par le programme était plus réaliste que le son réel de la vidéo. C'est un meilleur résultat que d'autres méthodes pour synthétiser des sons réalistes.</font></font><br>
<br>
<img src="https://habrastorage.org/files/3ba/1d7/6af/3ba1d76afd8e467f8871e2a5a676442a.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le plus souvent, l'IA a trompé les participants à l'expérience avec les sons de matériaux tels que les feuilles et la saleté, car ces sons sont plus complexes et pas aussi «propres» que ceux produits, par exemple, par le bois ou le métal.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Revenant à la formation du réseau neuronal, en tant que sous-produit de l'étude, il a été constaté que l'algorithme peut distinguer les matériaux mous des matériaux durs avec une précision de 67%, prédisant simplement leur son. </font><font style="vertical-align: inherit;">En d'autres termes, le robot peut regarder le chemin d'asphalte et l'herbe devant lui - et conclure que l'asphalte est dur et l'herbe est douce. </font><font style="vertical-align: inherit;">Le robot le saura par le son prédit, sans même marcher sur l'asphalte et l'herbe. </font><font style="vertical-align: inherit;">Ensuite, il peut aller où il veut - et tester ses sentiments en vérifiant avec la base de données et, si nécessaire, en apportant des corrections dans la bibliothèque d'échantillons sonores. </font><font style="vertical-align: inherit;">De cette façon, à l'avenir, les robots étudieront et maîtriseront le monde qui les entoure.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cependant, les chercheurs ont encore beaucoup de travail à faire pour améliorer la technologie. </font><font style="vertical-align: inherit;">Le réseau neuronal est maintenant souvent confondu avec le mouvement rapide des objets, sans tomber dans le moment exact du contact. </font><font style="vertical-align: inherit;">De plus, l'IA ne peut générer que du son basé sur le contact direct, qui est enregistré sur vidéo, et il y a tellement de sons autour de nous qui ne sont pas basés sur le contact visuel: le bruit des arbres, le bourdonnement d'un ventilateur dans un ordinateur. </font><font style="vertical-align: inherit;">«Ce qui serait vraiment cool, c'est de simuler en quelque sorte un son qui n'est pas si étroitement lié à la séquence», </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">explique</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Andrew Owens.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr395243/">https://habr.com/ru/post/fr395243/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr395233/index.html">Pour classer. Pour simuler. Répéter</a></li>
<li><a href="../fr395235/index.html">La base russe à long terme sur la lune pourra accueillir 12 personnes</a></li>
<li><a href="../fr395237/index.html">Espace Kazan</a></li>
<li><a href="../fr395239/index.html">Présentation à la conférence Apple Worldwide Developers Conference (WWDC) 2016 [texte diffusé]</a></li>
<li><a href="../fr395241/index.html">Faire une carte de circuit imprimé en utilisant un laser à diode au lieu d'un fer. Faites-le vous-même du début à la fin</a></li>
<li><a href="../fr395245/index.html">Les développeurs du jeu No Man's Sky défendent le nom de Sky</a></li>
<li><a href="../fr395247/index.html">Talk Show: comment les podcasts créent, développent et écoutent</a></li>
<li><a href="../fr395249/index.html">Équipement de mobilisation estivale</a></li>
<li><a href="../fr395251/index.html">Casque à conduction osseuse Aftershokz Bluez 2 et malentendants</a></li>
<li><a href="../fr395253/index.html">Système de fichiers Apple (APFS)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
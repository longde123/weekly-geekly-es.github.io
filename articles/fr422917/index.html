<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ•œ ğŸ¨ ãŠ™ï¸ Je n'ai pas de bouche, mais je dois crier. RÃ©flexions sur l'IA et l'Ã©thique ğŸ¤¶ğŸ¾ ğŸ¤½ğŸ» ğŸ¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Clause de non-responsabilitÃ©  Je suis sceptique quant Ã  ma capacitÃ© Ã  exprimer une pensÃ©e vraiment originale. TrÃ¨s probablement, je suis loin d'Ãªtre l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Je n'ai pas de bouche, mais je dois crier. RÃ©flexions sur l'IA et l'Ã©thique</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422917/"><div class="spoiler">  <b class="spoiler_title">Clause de non-responsabilitÃ©</b> <div class="spoiler_text">  Je suis sceptique quant Ã  ma capacitÃ© Ã  exprimer une pensÃ©e vraiment originale.  TrÃ¨s probablement, je suis loin d'Ãªtre le premier Ã  poser ces questions, et il est fort possible que des rÃ©ponses digestes aient dÃ©jÃ  Ã©tÃ© Ã©laborÃ©es Ã  leur sujet.  Par consÃ©quent, en tapant ce texte, je n'attends pas votre surprise ou votre admiration.  Je m'attends Ã  ce que des gens familiers avec la philosophie moderne de la conscience viennent au commentaire et me donnent des liens vers le travail de penseurs sÃ©rieux avec des noms de famille allemands amusants. <br></div></div><br><img src="https://habrastorage.org/getpro/habr/post_images/4de/bcf/8fe/4debcf8fe238985125121b531bdaefef.jpg" alt="image"><br><br>  Il n'y a pas si longtemps, il y avait un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> sur HabrÃ©, dont les commentaires m'ont fait rÃ©flÃ©chir Ã  plusieurs questions interconnectÃ©es.  Je veux partager les rÃ©sultats de ces pensÃ©es (ou leur absence, voici comment regarder) avec la communautÃ©. <br><br><h3>  Qu'est-ce que la douleur? </h3><br>  Une fois, j'ai eu mal aux dents.  J'Ã©tais allongÃ© sur le canapÃ© et j'ai essayÃ© de ne pas y prÃªter attention.  Je pensais que la douleur n'Ã©tait qu'un signal entrant dans mon cerveau.  Le mÃªme signal que la prÃ©sence ou l'absence de tension dans le cÃ¢blage allant au connecteur PS / 2 de l'unitÃ© centrale.  En soi, il n'a pas de sÃ©mantique, c'est ma conscience qui choisit comment l'interprÃ©ter.  Si j'arrÃªte de le percevoir comme de la douleur et que je l'ignore ou simplement Â«prends noteÂ», cela deviendra plus facile pour moi. <br><br><a name="habracut"></a>  Mais cela n'a pas Ã©tÃ© plus facile.  D'une maniÃ¨re si simple, j'ai trouvÃ© que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">qualia</a> a mal et ne se rÃ©sume pas Ã  un simple transfert d'informations. <br><br><h3>  Comment comprenons-nous que cela blesse les autres? </h3><br>  Je ne suis pas spÃ©cial en neurophysiologie, mais ils disent qu'il y a une sorte de neurones miroirs dans le cerveau.  Lorsque nous voyons comment une autre personne effectue certaines actions, les neurones miroirs effectuent leur ingÃ©nierie inverse.  Nous essayons de comprendre ce qui devrait arriver dans la tÃªte de cette personne pour qu'elle se comporte de cette faÃ§on.  Et dans une certaine mesure, mÃªme nous-mÃªmes commenÃ§ons Ã  ressentir ce que, selon nos hypothÃ¨ses, il devrait ressentir.  Mes pommettes peuvent Ãªtre rÃ©duites Ã  la vue de quelqu'un mangeant un citron.  Si quelqu'un, par exemple, crie, pleure, se tord, roule par terre ... Il est probable que cette personne souffre.  TrÃ¨s probablement, il sera dÃ©sagrÃ©able pour moi de voir une telle vue.  Je vais commencer Ã  sympathiser avec cette personne et, si elle est en mon pouvoir, mÃªme Ã  prendre des mesures pour arrÃªter la douleur.  Putain de neurones miroirs. <br><br>  En fait, nous n'avons aucune garantie que l'autre personne souffre vraiment.  Par exemple, il peut s'agir d'un simulateur, d'un acteur, comme dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">expÃ©rience Milgram</a> .  Cependant, cela peut facilement Ãªtre compris en plaÃ§ant le simulateur dans le tomographe et en voyant quelles parties du cerveau sont actuellement actives.  Cependant, il s'agit Ã©galement d'un comportement, bien que plus "bas".  En consÃ©quence, tout se rÃ©sume Ã  un critÃ¨re trÃ¨s simple (je dirais mÃªme trop simple): nous pensons qu'une <i>personne ressent de la douleur si elle se comporte comme si nous ressentions de la douleur</i> . <br><br><h3>  Comment comprendre que l'autre personne est une personne? </h3><br>  Il y a une telle expÃ©rience de pensÃ©e cÃ©lÃ¨bre appelÃ©e le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">zombie philosophique</a> .  Son essence est simple: imaginez quelque chose qui se comporte absolument indiscernable d'une personne du point de vue d'un observateur externe, mais qui est totalement dÃ©pourvu d'expÃ©rience subjective.  Si vous le piquez avec une aiguille, il dira Â«ahÂ» (ou quelque chose de moins censurÃ©), tirera sa main en arriÃ¨re, ses muscles faciaux correspondants se contracteront et mÃªme le tomographe ne pourra pas l'attraper.  Mais en mÃªme temps, il ne ressent rien Ã  l'intÃ©rieur.  Il n'a tout simplement pas cet Â«intÃ©rieurÂ».  Un tel quelque chose est appelÃ© un Â«zombie philosophiqueÂ», et l'essence de l'expÃ©rience est que l'existence de cette crÃ©ature hypothÃ©tique ne conduit pas Ã  des contradictions Ã©videntes.  Autrement dit, il semble que <i>possible</i> . <br><br>  Pour revenir Ã  la question prÃ©cÃ©dente, nous n'avons vraiment aucune possibilitÃ© fiable de savoir si l'autre personne souffre en tant que qualia.  Nous pouvons Ã©couter nos neurones miroirs ou, si cela ne suffit pas pour nos esprits sophistiquÃ©s, utiliser le rasoir d'Occam.  Dire que le Â«zombie philosophiqueÂ» est une entitÃ© supplÃ©mentaire.  Il est beaucoup plus logique de supposer que toutes les personnes sont plus ou moins identiques que de supposer le contraire, sans aucune raison claire Ã  cela.  Cependant, le principe d'Occam est toujours une loi heuristique et non immuable.  Des entitÃ©s qui nous semblaient superflues hier entrent dans notre maison aujourd'hui, ouvrant la porte avec leurs pieds.  Si vous n'Ãªtes pas d'accord, essayez d'imaginer comment la mÃ©canique quantique serait expliquÃ©e Ã  DÃ©mocrite. <br><br><h3>  Les androÃ¯des rÃªvent-ils de supports Ã©lectriques? </h3><br>  Dans le premier commentaire sur le post que j'ai Ã©crit ci-dessus, la pensÃ©e suivante a Ã©tÃ© exprimÃ©e par l'utilisateur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">NeoCode</a> : <br><blockquote>  Tout d'abord, une `` IA forte '' n'est pas une crÃ©ature vivante et ne pourra pas ressentir la douleur ou la solitude, simplement parce que sa nature est initialement diffÃ©rente, elle n'a pas des millions d'annÃ©es d'Ã©volution et de sÃ©lection naturelle, et donc - des mÃ©canismes et des programmes biologiques de bas niveau.  Il n'aura mÃªme pas l'instinct de conservation de soi, Ã  moins que vous ne programmiez spÃ©cifiquement bien sÃ»r.  Mais dans sa forme pure - ne le sera pas;  vous pouvez crÃ©er une IA qui a conscience et est capable de rÃ©soudre des problÃ¨mes complexes et d'apprendre, sans avoir l'instinct de conservation en gÃ©nÃ©ral. <br>  C'est un point important que, pour une raison quelconque, beaucoup ne comprennent pas, par dÃ©faut, l'intelligence artificielle "humanisante". </blockquote><br>  En cela, bien sÃ»r, il y a un noyau rationnel.  Les qualitÃ©s humaines ne peuvent pas Ãªtre transfÃ©rÃ©es sans rÃ©flÃ©chir Ã  une IA hypothÃ©tique.  Ã€ cet Ã©gard, 95% de la science-fiction et 99,9% des habitants sont dÃ©sespÃ©rÃ©ment naÃ¯fs.  Mais je veux dire ce qui suit: ne privez pas non plus inconsidÃ©rÃ©ment l'IA des qualitÃ©s humaines.  Certains d'entre eux peuvent s'avÃ©rer plus fondamentaux que ce Ã  quoi on aurait pu s'attendre. <br><br>  ConsidÃ©rez cette situation hypothÃ©tique: pour que l'IA fasse ce dont nous avons besoin, et non ce qu'elle veut (et il pourrait bien Ãªtre plus Â«intÃ©ressantÂ» de rÃ©soudre le sudoku que de s'engager dans notre projet, qui est sur le point d'avoir un dÃ©lai) , nous y ajoutons un signal d'entrÃ©e spÃ©cial - de telle sorte que l'objectif principal de l'IA, le composant principal de sa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fonction objectif,</a> est de minimiser ce signal.  En consÃ©quence, lorsque la date limite approche, nous appuyons sur la pÃ©dale, une tension est appliquÃ©e aux fils et l'IA commence Ã  rÃ©flÃ©chir activement Ã  la faÃ§on de supprimer cette tension.  Et plus nous sommes actifs, plus nous appuyons.  Et comme la pression du pied sur la pÃ©dale est associÃ©e Ã  un projet incomplet, l'IA n'a d'autre choix que de terminer ce projet.  Eh bien, ou pour pirater un drone militaire qui vole au-delÃ  afin qu'il assomme le cerveau de l'opÃ©rateur Ã  pÃ©dales.  Qui sait, cette IA puissante. <br><br>  Cependant, j'Ã©tais distrait.  Dites-moi, ce signal hypothÃ©tique ne vous rappelle-t-il accidentellement rien?  Est-il possible dans ce cas de dire que l'IA souffre? <br><br><h3>  L'homme Ã  l'homme est un loup, et les zombies sont des zombies zombies </h3><br>  Comment pouvons-nous mÃªme comprendre si l'IA connaÃ®t des qualia?  Dans le cas des zombies philosophiques, l'empathie et le rasoir d'Occam Ã©taient de notre cÃ´tÃ©.  Cependant, l'IA est philosophique, mais pas zombie.  Autrement dit, il est logique de soulever cette question Ã  son sujet, mais il n'est pas humain.  Par consÃ©quent, nous ne pouvons pas dire qu'il ressent quelque chose, juste par analogie avec nous-mÃªmes. <br><br>  Quelqu'un (comme, par exemple, l'auteur du commentaire citÃ© ci-dessus) dira que nous pouvons dire le contraire en toute sÃ©curitÃ©.  Qu'il n'y a aucune raison de croire que l'IA souffre vraiment, et sinon, nous ne le penserons pas.  Je voudrais rÃ©pondre Ã  ceci comme suit: Imaginez qu'un Ãªtre, un sentiment, mais un Ãªtre complÃ¨tement inhumain vous a crÃ©Ã©s.  Quelles raisons aurait-il pour croire que vous vivez des qualia?  Ã€ moins, bien sÃ»r, que cette crÃ©ature n'ait pas la capacitÃ© transcendantale de vraiment s'intÃ©grer dans la tÃªte de quelqu'un d'autre;  allÃ©goriquement parlant, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">devenez une chauve-souris</a> .  Cependant, cela dÃ©passe dÃ©jÃ  le cadre de notre analogie et entre dans la catÃ©gorie des conversations sur le divin. <br><br><h3>  Chauvinisme anthropique </h3><br>  Dans tous les paragraphes prÃ©cÃ©dents, nous avons parlÃ© de la douleur.  La douleur est, disons, l'une des variÃ©tÃ©s les plus caractÃ©ristiques des sensations humaines.  Mais qui a dit que tout est limitÃ© Ã  l'homme? <br><br>  Si un esprit extraterrestre hypothÃ©tique (en gÃ©nÃ©ral, mÃªme s'il n'est pas artificiel, extraterrestre ou autre) est, en principe, capable de vivre des qualia, il peut se rÃ©vÃ©ler fondamentalement diffÃ©rent de ceux qu'une personne connaÃ®t.  Un exemple grotesque: baby-AI vient Ã  son pÃ¨re-scientifique et dit qu'il vit <i>quelque chose</i> .  Est-ce bon ou mauvais?  Faut-il lui donner un bonbon en rÃ©compense, lui tapoter la tÃªte en guise de rÃ©confort, ou mÃªme mettre une ceinture Ã©lectrique, car il n'y a rien ici? <br><br>  Dans tous les paragraphes prÃ©cÃ©dents, j'ai posÃ© des questions sans rÃ©ponse et, pour l'essentiel, je n'ai rien dit.  J'oserai maintenant affirmer: <b>l'Ã©thique humaine n'est pas prÃªte Ã  faire de l'esprit non humain son sujet Ã  part entiÃ¨re</b> .  Nous pouvons parler des "problÃ¨mes Ã©thiques de l'IA", en considÃ©rant l'intelligence artificielle comme un moyen par lequel certaines personnes font du bien ou du mal Ã  d'autres.  Mais si nous essayons de penser aux problÃ¨mes Ã©thiques en termes d'IA, nous ne rÃ©ussirons tout simplement pas.  Ce n'est pas que nous n'avons pas pu obtenir de rÃ©ponse - nous n'avons mÃªme pas l'appareil conceptuel appropriÃ© pour poser correctement la question.  Peut-Ãªtre que nous n'en possÃ©dons pas <i>encore</i> .  Ou peut-Ãªtre s'agit-il d'un Ã©cart fondamentalement irrÃ©cupÃ©rable.  Et l'intelligence artificielle devra dÃ©velopper sa propre Ã©thique, si, bien sÃ»r, il en a besoin. <br><br>  Et puis dÃ©cidez s'il vaut la peine de considÃ©rer une personne comme un sujet, hehe. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr422917/">https://habr.com/ru/post/fr422917/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr422903/index.html">Comment et pourquoi nous avons Ã©crit un service Ã©volutif hautement chargÃ© pour 1C: Enterprise: Java, PostgreSQL, Hazelcast</a></li>
<li><a href="../fr422905/index.html">Mais vous dites Ceph ... est-il si bon?</a></li>
<li><a href="../fr422907/index.html">Aide-mÃ©moire du robot aspirateur 2018</a></li>
<li><a href="../fr422909/index.html">10 vidÃ©os de discussion rÃ©tro 404 Festival les plus populaires</a></li>
<li><a href="../fr422915/index.html">Je recherche un senior sans bureau ni cookies: comment nous avons organisÃ© une recherche d'employÃ©s 100% distants</a></li>
<li><a href="../fr422919/index.html">SIP Ã  vÃ©lo et conversation tÃ©lÃ©phonique dans le cloud</a></li>
<li><a href="../fr422921/index.html">De Kotlin Ã  Goblin: comment s'est passÃ© TechTrain</a></li>
<li><a href="../fr422923/index.html">Comment marquer la journÃ©e du programmeur sans dÃ©corer le ficus de bureau avec des zÃ©ros et des uns</a></li>
<li><a href="../fr422925/index.html">Entretien avec le prÃ©sident de la confÃ©rence RubyRussia Godfrey Chan</a></li>
<li><a href="../fr422929/index.html">Yandex Mail [Ã©tait] indisponible pendant environ une heure Ã  12 h 16, heure de Moscou</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
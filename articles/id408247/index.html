<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏾‍⚖️ 👨🏻‍🏭 🙄 Akuntabilitas AI: peran catatan penjelasan 🐃 🕘 🥄</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sistem Artificial Intelligence (AI) mulai berkembang. Dalam hal ini, pengacara dan anggota parlemen membahas masalah bagaimana sistem seperti itu haru...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Akuntabilitas AI: peran catatan penjelasan</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408247/"><img src="https://habrastorage.org/webt/7y/i9/7x/7yi97xpnf18h5b8wqbqrzd49wqc.png" align="left">  Sistem Artificial Intelligence (AI) mulai berkembang.  Dalam hal ini, pengacara dan anggota parlemen membahas masalah bagaimana sistem seperti itu harus diatur, siapa yang akan bertanggung jawab atas tindakan mereka.  Masalah ini memerlukan studi yang cermat dan pendekatan yang seimbang, karena sistem AI mampu menghasilkan data dalam jumlah besar dan digunakan dalam aplikasi dengan fungsi berbeda - dari sistem medis dan autopilot di dalam mobil hingga memprediksi kejahatan dan menghitung potensi penjahat.  Pada saat yang sama, para ilmuwan berusaha untuk menciptakan "AI kuat" yang mampu beralasan, dan muncul pertanyaan tentang bagaimana menentukan keberadaan niat dalam tindakannya - atau untuk mengenali tindakan sebagai tidak disengaja. <br><br>  Ada banyak cara untuk membawa sistem AI ke akuntabilitas dan tanggung jawab, beberapa penelitian telah diterbitkan tentang topik ini.  Dalam sebuah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">makalah penelitian</a> baru, ilmu komputer, pakar ilmu kognitif dan pengacara dari Universitas Harvard dan Cambridge (AS) membahas satu komponen sistem pertanggungjawaban AI di masa depan, yaitu peran catatan penjelasan dari AI, yaitu penilaian tentang bagaimana sistem kecerdasan buatan menjelaskan tindakannya. .  Para ilmuwan sampai pada kesimpulan bahwa modul untuk menjelaskan tindakan harus dipisahkan dari sistem AI umum. <br><a name="habracut"></a><br>  Para penulis karya ilmiah menggambarkan semua masalah yang muncul ketika mencoba meminta sistem AI untuk penjelasan tindakannya. <br><br>  Pertama, kesempatan seperti itu harus diberikan pada tahap pengembangan sistem, jika tidak AI dapat menolak atau tidak akan dapat menjelaskan tindakannya. <br><br>  Kedua, sistem AI memproses sejumlah besar data menggunakan algoritme kepemilikan yang kompleks atau metode yang dikembangkan sendiri dalam proses pembelajaran.  Jadi, ketika mencoba menjelaskan tindakannya dengan cara yang paling lengkap, dia dapat menghasilkan terlalu banyak data yang tidak dapat dipahami oleh seseorang.  Atau - seperti ekstrem lainnya - akan memberikan model yang terlalu sederhana yang tidak akan mencerminkan niat sebenarnya AI dan motif tindakan.  Selain itu, algoritme operasi sistem AI dapat menjadi kekayaan intelektual perusahaan yang sedang berkembang, sehingga perlu menyediakan metode kompilasi catatan penjelasan untuk menetapkan penyebab tindakan sistem, tetapi tidak memberikan algoritma yang mendasarinya. <br><br>  Para peneliti percaya bahwa penjelasan dimungkinkan tanpa mengungkapkan algoritma dan aturan yang mendasari fungsi sistem AI.  Jika terjadi insiden, sistem harus memberikan jawaban atas pertanyaan-pertanyaan berikut: <br><br><ul><li>  Apa faktor utama yang mempengaruhi keputusan? </li><li>  Apakah perubahan dalam faktor tertentu menyebabkan perubahan dalam keputusan? </li><li>  Mengapa dua kasus serupa mengarah pada solusi yang berbeda? </li></ul><br>  Jawaban untuk pertanyaan semacam itu tidak selalu membutuhkan pengungkapan rahasia kepemilikan dan algoritma sistem internal, tetapi pada saat yang sama mereka akan memberikan pemahaman yang jelas tentang motifnya. <br><br>  Para ilmuwan berpendapat dalam kasus-kasus mana perlu meminta AI untuk menjelaskan tindakannya.  Faktanya, ini diperlukan dalam kasus di mana manfaat penjelasan melebihi harga kwitansi: “Kami percaya bahwa ada tiga kondisi untuk situasi di mana perusahaan menganggap perlu untuk mendapatkan penjelasan dari pembuat keputusan.  Ini adalah alasan moral, sosial atau hukum, ”jelas Finale Doshi-Velez, penulis utama makalah ini. <br><br>  Pada saat yang sama, seseorang seharusnya tidak menuntut penjelasan dari AI secara harfiah dalam setiap situasi.  Sebagaimana disebutkan di atas, ini meningkatkan risiko mengeluarkan rahasia dagang dan menempatkan beban tambahan pada pengembang sistem AI.  Dengan kata lain, akuntabilitas AI yang konstan kepada manusia akan menghambat pengembangan sistem ini, termasuk di bidang yang penting bagi manusia. <br><br>  Berbeda dengan kepercayaan luas bahwa sistem AI adalah kotak hitam, yang penyebabnya tidak dapat dipahami manusia, para penulis karya ilmiah yakin bahwa modul yang berfungsi normal untuk menjelaskan tindakan AI dapat dikembangkan.  Modul ini akan diintegrasikan ke dalam sistem, tetapi bekerja secara independen dari algoritma pengambilan keputusan dan tidak mematuhinya. <br><br>  Para ilmuwan percaya bahwa ada beberapa poin dalam penjelasan tentang tindakan yang mudah dilakukan orang dan sulit untuk mesin, dan sebaliknya. <br><br>  <b>Perbandingan kemampuan manusia dan AI untuk menjelaskan</b> <br><table><tbody><tr><th width="175"></th><th>  Bung </th><th>  AI </th></tr><tr><td>  Manfaatnya </td><td>  Dapat menjelaskan tindakan posterior </td><td>  Reproduksibilitas, kurangnya tekanan sosial </td></tr><tr><td>  Kekurangan </td><td>  Mungkin tidak akurat dan tidak dapat diandalkan, merasakan tekanan sosial </td><td>  Membutuhkan pemrograman pendahuluan dari modul penjelasan, taksonomi tambahan dan perluasan sistem penyimpanan </td></tr></tbody></table><br>  Namun, kelompok ahli merekomendasikan bahwa pengaturan pertama kali untuk sistem AI adalah standar yang sama untuk menjelaskan tindakan mereka yang ditetapkan untuk orang saat ini (standar ini dijabarkan dalam hukum AS: khususnya, diperlukan penjelasan dalam kasus pertanggungjawaban yang ketat, perceraian dan diskriminasi, untuk membuat keputusan administratif dan dari hakim dan juri untuk menjelaskan keputusan mereka - walaupun tingkat detail dari catatan penjelasan sangat berbeda dalam setiap kasus). <br><br>  Tetapi jika alasan untuk tindakan AI melampaui pemahaman manusia, maka untuk menjelaskan AI di masa depan, standar lain dapat dikembangkan untuk catatan penjelasan mereka, kata para ilmuwan. <br><br>  Artikel ilmiah ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">diterbitkan</a> pada 3 November 2017 di situs preprint arXiv.org (arXiv: 1711.01134v1). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id408247/">https://habr.com/ru/post/id408247/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id408235/index.html">Ajax Systems: sistem keamanan universal untuk apartemen, rumah atau kantor</a></li>
<li><a href="../id408237/index.html">Pemulihan dan modernisasi kolom Vega 50AS-106</a></li>
<li><a href="../id408239/index.html">Peluang baru Habr: cara berhenti berlangganan dari pengguna dan blog iklan</a></li>
<li><a href="../id408243/index.html">Memata-matai truk</a></li>
<li><a href="../id408245/index.html">Microsoft akan merilis versi Skype untuk freelancer</a></li>
<li><a href="../id408249/index.html">Di jalan raya I-94 di Wisconsin, sebuah jalur khusus untuk robomobiles direncanakan</a></li>
<li><a href="../id408251/index.html">Menggunakan atmosfer planet yang menyala untuk mencari kehidupan di luar bumi</a></li>
<li><a href="../id408253/index.html">Proyek penyelidikan Venus akan menerima dana dari agensi sains</a></li>
<li><a href="../id408255/index.html">Memeriksa Senolitik Potensial</a></li>
<li><a href="../id408261/index.html">Arduino di Linux: Mengkonfigurasi Pencipta Qt sebagai Lingkungan Pengembangan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
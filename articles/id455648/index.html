<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⛰️ 🐀 🤷🏾 Siklus Hidup ML 🤛🏾 🧛🏽 🗳️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam implementasi ML nyata, belajar itu sendiri membutuhkan seperempat upaya. Tiga perempat sisanya adalah persiapan data melalui rasa sakit dan biro...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Siklus Hidup ML</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/455648/">  Dalam implementasi ML nyata, belajar itu sendiri membutuhkan seperempat upaya.  Tiga perempat sisanya adalah persiapan data melalui rasa sakit dan birokrasi, penyebaran yang kompleks seringkali dalam lingkaran tertutup tanpa akses Internet, pengaturan infrastruktur, pengujian dan pemantauan.  Dokumen pada ratusan lembar, mode manual, konflik versi model, open source, dan perusahaan keras - semua ini menunggu seorang ilmuwan data.  Tapi dia tidak tertarik dengan masalah operasional yang "membosankan" seperti itu, dia ingin mengembangkan algoritma, mencapai kualitas tinggi, memberikan kembali dan tidak lagi ingat. <br><br>  Mungkin, di suatu tempat ML diterapkan lebih mudah, lebih sederhana, lebih cepat dan dengan satu tombol, tetapi kita belum melihat contoh seperti itu.  Semua yang di atas adalah pengalaman Front Tier dalam fintech dan telekomunikasi.  Sergey Vinogradov, seorang ahli dalam arsitektur sistem yang sangat dimuat, dalam penyimpanan besar dan dalam analisis data berat, berbicara tentang dia di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++</a> . <br><br><img src="https://habrastorage.org/webt/ss/7n/cm/ss7ncmtdsij0wncwt-uuzxneit8.jpeg"><br><a name="habracut"></a><br><h2>  Model siklus hidup </h2><br>  Biasanya siklus hidup di area subjek kami terdiri dari tiga bagian.  Pada awalnya <strong>, tugas datang dari bisnis</strong> .  Pada tahap kedua, seorang <strong>insinyur data dan / atau ilmuwan data menyiapkan data</strong> , membangun sebuah model.  Di bagian ketiga, <strong>kekacauan</strong> dimulai.  Dalam dua yang terakhir, berbagai situasi menarik terjadi. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/7GM9ac6ojtw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h3>  Jack dari semua perdagangan </h3><br>  Situasi pertama yang sering terjadi adalah seorang ilmuwan data atau insinyur data memiliki akses ke produk, jadi mereka berkata kepadanya: "Anda melakukan semua ini, Anda bertaruh." <br><br>  Seseorang mengambil <strong>Notebook Jupyter</strong> atau satu bundel notebook, menganggapnya secara eksklusif sebagai artefak penyebaran, dan mulai mereplikasi dengan gembira di beberapa server. <br><br>  Segalanya tampak baik-baik saja, tetapi tidak selalu.  Saya akan memberi tahu Anda nanti mengapa. <br><br><h3>  Eksploitasi tanpa ampun </h3><br>  Kisah kedua lebih rumit, dan biasanya terjadi di perusahaan-perusahaan di mana eksploitasi telah mencapai tingkat kegilaan ringan.  Ilmuwan data membawa solusi untuk operasi.  Mereka membuka kotak hitam ini dan melihat sesuatu yang mengerikan: <br><br><ul><li>  notebook </li><li>  acar dari berbagai versi; </li><li>  tumpukan skrip: tidak jelas di mana dan kapan harus menjalankannya, di mana menyimpan data yang mereka hasilkan. </li></ul><br>  Dalam teka-teki ini, eksploitasi menemukan ketidakcocokan versi.  Misalnya, seorang ilmuwan data tidak menentukan versi tertentu dari perpustakaan, dan operasi mengambil yang terbaru.  Setelah beberapa saat, ilmuwan data resor: <br><br>  <em>- Anda mengatur scikit-belajar ke versi yang salah, sekarang semua metrik hilang!</em>  <em>Perlu memutar kembali ke versi sebelumnya.</em> <br><br>  Ini benar-benar memecah prod, dan eksploitasi menderita. <br><br><h3>  Birokrasi </h3><br>  Di perusahaan dengan logo hijau, ketika ilmuwan data mulai beroperasi dan membawa model, biasanya ia menerima dokumen 800 lembar sebagai tanggapan: "Ikuti instruksi ini, jika tidak produk Anda tidak akan pernah melihat cahaya hari". <br><br>  Ilmuwan data yang menyedihkan pergi, membuang segalanya di tengah jalan, dan kemudian berhenti - dia tidak tertarik melakukan ini. <br><br><h3>  Sebarkan </h3><br>  Misalkan seorang ilmuwan data telah melalui semua kalangan dan pada akhirnya semuanya telah dikerahkan.  Tapi dia tidak akan bisa mengerti bahwa semuanya berjalan sebagaimana mestinya.  Dalam pengalaman saya, di bank yang sama diberkati tidak ada pemantauan produk ilmu data. <br><br>  Adalah baik jika spesialis menulis hasil karyanya dalam database.  Setelah beberapa saat, ia akan menerimanya dan melihat apa yang terjadi di dalam.  Tetapi ini tidak selalu terjadi.  Ketika seorang bisnis dan ilmuwan data hanya percaya bahwa semuanya bekerja dengan baik dan luar biasa, itu diterjemahkan menjadi kasus yang tidak berhasil. <br><br><h3>  LKM </h3><br>  Entah bagaimana kami mengembangkan mesin penilaian untuk satu organisasi keuangan mikro besar.  Mereka tidak membiarkan mereka pergi ke prod, tetapi hanya mengambil kaskade model dari kami, menginstal dan meluncurkannya.  Hasil tes model memuaskan mereka.  Tetapi setelah 6 bulan mereka kembali: <br><br>  <em>- Semuanya buruk.</em>  <em>Bisnis tidak berjalan, kita semakin buruk.</em>  <em>Tampaknya model-modelnya sangat baik, tetapi hasilnya menurun, penipuan dan standar semakin banyak, dan lebih sedikit uang.</em>  <em>Untuk apa kami membayar Anda?</em>  <em>Mari kita perbaiki.</em> <br><br>  Pada saat yang sama, akses ke model tidak lagi diberikan.  Log dibongkar selama sebulan, apalagi, enam bulan lalu.  Kami mempelajari pembongkaran selama satu bulan lagi dan sampai pada kesimpulan bahwa pada titik tertentu departemen TI dari LKM mengubah data input, dan alih-alih dokumen di json, mereka mulai mengirim dokumen dalam xml.  Model itu diharapkan json, tetapi menerima xml, sedih dan berpikir bahwa tidak ada data pada input. <br><br><blockquote>  Jika tidak ada data, maka penilaian tentang apa yang terjadi berbeda.  Tanpa pemantauan, ini tidak dapat dideteksi. </blockquote><br><h3>  Versi baru, kaskade, dan tes </h3><br>  Seringkali kita dihadapkan dengan kenyataan bahwa model tersebut bekerja dengan baik, tetapi untuk beberapa alasan <strong>versi baru telah</strong> dikembangkan.  Model itu lagi-lagi perlu dibawa masuk entah bagaimana, dan lagi untuk melewati semua lingkaran neraka.  Baik jika versi pustaka sama seperti pada model sebelumnya, dan jika tidak, penyebaran akan dimulai lagi ... <br><br>  Kadang-kadang sebelum menempatkan versi baru ke pertempuran, kami ingin <strong>mengujinya</strong> - letakkan di prod, lihat arus lalu lintas yang sama, pastikan itu baik.  Lagi-lagi ini adalah rantai penyebaran penuh.  Selain itu, kami mengatur sistem sehingga menurut model ini, hasil nyata tidak terjadi, jika kita berbicara tentang penilaian, tetapi hanya ada pemantauan dan analisis hasil untuk analisis lebih lanjut. <br><br>  Ada situasi ketika <strong>kaskade model digunakan.</strong>  Ketika hasil dari model-model berikut bergantung pada yang sebelumnya, entah bagaimana Anda perlu membangun interaksi di antara mereka dan di suatu tempat lagi semua ini harus disimpan. <br><br><h2>  Bagaimana mengatasi masalah seperti itu? </h2><br>  Seringkali, satu orang memecahkan masalah <strong>secara manual</strong> , terutama di perusahaan kecil.  Dia tahu bagaimana semuanya berjalan, ingat semua versi model dan perpustakaan, tahu di mana dan skrip mana yang bekerja, etalase mana yang mereka bangun.  Ini semua luar biasa.  Yang sangat indah adalah kisah-kisah yang ditinggalkan oleh mode manual. <br><br>  <strong>Kisah tentang warisan</strong> .  Seorang pria yang baik bekerja di satu bank kecil.  Suatu hari dia pergi ke negara selatan dan tidak kembali.  Setelah itu, kami mendapat warisan: sekelompok kode yang menghasilkan etalase tempat model bekerja.  Kode ini indah, berfungsi, tetapi kami tidak tahu versi pasti dari skrip yang menghasilkan etalase ini atau itu.  Dalam pertempuran semua jendela toko hadir, dan semuanya diluncurkan.  Kami menghabiskan dua bulan mencoba untuk mencari jalinan rumit ini dan entah bagaimana menyusunnya. <br><br>  <strong>Dalam perusahaan yang keras,</strong> orang tidak mau repot dengan segala macam Python, Jupiters, dll. Mereka berkata: <br><br>  <em>- Mari kita beli IBM SPSS, instal dan semuanya akan bagus.</em>  <em>Masalah dengan versi, dengan sumber data, dengan penyebaran di sana entah bagaimana diselesaikan.</em> <br><br>  Pendekatan ini memiliki hak untuk hidup, tetapi tidak semua orang mampu membelinya.  Bagaimanapun, ini adalah jarum bergerigi berkualitas tinggi.  Mereka duduk di atasnya, tetapi tidak berhasil turun - takik.  Dan biasanya biayanya banyak. <br><br>  <strong>Open Source adalah</strong> kebalikan dari pendekatan sebelumnya.  Para pengembang menjelajahi Internet, menemukan banyak solusi Open Source yang menyelesaikan tugas-tugas mereka dengan berbagai tingkat.  Ini adalah cara yang hebat, tetapi bagi kami sendiri kami tidak menemukan solusi yang akan memenuhi persyaratan kami 100%. <br><br>  Karena itu, kami telah memilih opsi klasik - <strong>keputusan kami</strong> .  Ini kruk, sepeda, semua milik mereka sendiri, asli. <br><br><h2>  Apa yang kita inginkan dari keputusan kita? </h2><br><br>  <strong>Jangan menulis semuanya sendiri</strong> .  Kami ingin mengambil komponen, terutama yang infrastruktur, yang telah membuktikan diri dengan baik dan akrab dengan operasi di lembaga tempat kami bekerja.  Kami hanya menulis sebuah lingkungan yang akan dengan mudah mengisolasi karya ilmuwan data dari karya DevOps. <br><br>  <strong>Memproses data dalam dua mode: keduanya dalam mode batch - Batch, dan waktu nyata</strong> .  Tugas kami mencakup kedua mode operasi. <br><br>  <strong>Kemudahan penyebaran, dan dalam perimeter tertutup</strong> .  Saat bekerja dengan data pribadi yang sensitif, tidak ada koneksi internet.  Pada saat ini, semuanya harus dengan cepat dan akurat mencapai produksi.  Oleh karena itu, kami mulai melihat ke arah Gitlab, pipa CI / CD di dalamnya dan Docker. <br><br><blockquote>  Model bukanlah tujuan itu sendiri.  Kami tidak memecahkan masalah membangun model, kami memecahkan masalah bisnis. </blockquote><br>  Di dalam pipa, harus ada aturan dan konglomerasi model dengan dukungan untuk <strong>versi semua</strong> komponen pipa. <br><br>  Apa yang dimaksud dengan pipa?  Di Rusia, Undang-Undang Federal 115 tentang penanggulangan pencucian uang dan pendanaan terorisme berlaku.  Hanya daftar isi rekomendasi Bank Sentral yang menempati 16 layar.  Ini adalah aturan sederhana yang dapat dipenuhi bank jika memiliki data seperti itu, atau tidak bisa jika tidak memiliki data. <br><br>  Evaluasi peminjam, transaksi keuangan atau proses bisnis lainnya adalah aliran data yang kami proses.  Aliran harus melalui aturan semacam ini.  Aturan-aturan ini dijelaskan dengan cara yang mudah oleh analis.  Dia bukan ilmuwan data, tetapi dia tahu hukum atau instruksi lainnya dengan baik.  Analis duduk dan, dalam bahasa sederhana, menjelaskan pemeriksaan untuk data. <br><br>  <strong>Membangun kaskade model</strong> .  Seringkali situasi muncul ketika model berikutnya menggunakan untuk pekerjaannya nilai-nilai yang diperoleh dalam model sebelumnya. <br><br>  <strong>Uji hipotesis dengan cepat.</strong>  Saya ulangi tesis sebelumnya: seorang ilmuwan data membuat semacam model, itu berputar dalam pertempuran dan bekerja dengan baik.  Untuk beberapa alasan, spesialis datang dengan solusi yang lebih baik, tetapi tidak ingin merusak alur kerja yang ada.  Ilmuwan data menggantung model baru pada lalu lintas tempur yang sama dalam sistem pertempuran.  Dia tidak berpartisipasi langsung dalam pengambilan keputusan, tetapi melayani lalu lintas yang sama, mempertimbangkan beberapa kesimpulan dan kesimpulan ini disimpan di suatu tempat. <br><br>  <strong>Fitur penggunaan kembali yang mudah.</strong>  Banyak tugas memiliki jenis komponen yang sama, terutama yang terkait dengan ekstraksi fitur atau aturan.  Kami ingin menyeret komponen ini ke jaringan pipa lain. <br><br><h2>  Apa yang Anda putuskan untuk lakukan? </h2><br>  Pertama, kami ingin pemantauan.  Dan dua jenisnya. <br><br><h3>  Pemantauan </h3><br>  <strong>Pemantauan teknis.</strong>  Jika ada komponen pipa yang digunakan, dalam operasi mereka akan melihat apa yang terjadi pada komponen: bagaimana ia mengkonsumsi memori, CPU, disk. <br><br>  <strong>Pengawasan bisnis.</strong>  Ini adalah alat ilmuwan data yang memungkinkan Anda untuk abstrak dari nuansa teknis implementasi.  Pada tingkat desain, konstruksi membantu menentukan metrik model mana yang harus tersedia dalam pemantauan, misalnya, distribusi fitur atau hasil penilaian layanan. <br><br>  Seorang ilmuwan data mendefinisikan metrik dan tidak perlu khawatir tentang bagaimana mereka masuk ke sistem pemantauan.  Satu-satunya hal yang penting adalah ia mendefinisikan metrik ini dan tampilan dasbor tempat metrik akan ditampilkan.  Kemudian spesialis meluncurkan semuanya pada produksi, dikerahkan, dan setelah beberapa saat metrik mengalir ke pemantauan.  Jadi seorang ilmuwan data tanpa akses ke produk dapat melihat apa yang terjadi di dalam model. <br><br><h3>  Pengujian </h3><br>  Uji <strong>pipa untuk konsistensi</strong> .  Mengingat kekhasan pipa, ini adalah semacam grafik komputasi.  Kami ingin memahami bahwa kami menerapkan grafik, kami dapat memintasnya dan menemukan jalan keluar darinya. <br><br>  Grafik memiliki komponen - modul.  Semua modul harus lulus pengujian unit dan integrasi.  Prosesnya harus transparan dan mudah bagi seorang ilmuwan data. <br><br>  Pengembang menjelaskan model dan tes sendiri atau dengan bantuan orang lain.  Letakkan semuanya di Gitlab, jalur pipa yang dikonfigurasi oleh Continuous Integration, tes, dan lihat hasilnya.  Jika semuanya baik - itu lebih jauh, tidak - itu mulai lagi. <br><br>  Ilmuwan data berfokus pada model dan tidak tahu apa yang ada di bawah tenda.  Untuk ini, dia diberikan beberapa hal. <br><br><ul><li>  <strong>API untuk integrasi dengan inti</strong> <strong>sistem itu sendiri</strong> melalui bus data - bus pesan.  Dalam hal ini, spesialis perlu menggambarkan apa yang terjadi dan apa yang keluar dari modelnya, titik masuk dan persimpangan dengan berbagai komponen di dalam pipa. </li><li>  Setelah melatih model, sebuah <strong>artefak</strong> muncul <strong>- file XGBoost</strong> atau <strong>acar</strong> .  Ilmuwan data memiliki pelaksana untuk bekerja dengan artefak - ia harus mengintegrasikan komponen pipa di dalamnya. </li><li>  API yang mudah dan transparan untuk ilmuwan data untuk memantau operasi komponen pipa - pemantauan teknis dan bisnis. </li><li>  <strong>Infrastruktur yang sederhana dan transparan</strong> untuk diintegrasikan dengan sumber data dan menjaga hasil kerja. </li></ul><br>  Seringkali model bekerja untuk kita, dan setelah beberapa saat audit tiba yang ingin meningkatkan seluruh sejarah layanan.  Audit ingin memeriksa kebenaran pekerjaan, tidak adanya kecurangan di pihak kami.  Alat-alat sederhana diperlukan agar setiap auditor yang mengetahui SQL dapat masuk ke repositori khusus dan melihat bagaimana semuanya bekerja, keputusan apa yang dibuat dan mengapa. <br><br>  Kami meletakkan dasar bagi dua kisah penting bagi kami. <br><br>  <strong>Perjalanan Pelanggan.</strong>  Ini adalah kesempatan untuk menggunakan mekanisme untuk menjaga seluruh sejarah pelanggan - apa yang terjadi pada klien sebagai bagian dari proses bisnis yang diterapkan pada sistem ini. <br><br>  Kami mungkin memiliki sumber data eksternal, misalnya, platform DMP.  Dari mereka, kami mendapatkan informasi tentang perilaku manusia di jaringan dan di perangkat seluler.  Ini mungkin memiliki efek pada LTV dan model penilaian modelnya.  Jika peminjam terlambat membayar, kami dapat memperkirakan bahwa ini bukan niat jahat - hanya ada masalah.  Dalam hal ini, kami menerapkan metode eksposur lunak kepada peminjam.  Ketika masalah diselesaikan, klien akan menutup pinjaman.  Ketika dia datang lain kali, kita akan tahu seluruh ceritanya.  Ilmuwan data akan mendapatkan sejarah visual dari model dan melakukan penilaian dalam mode cahaya. <br><br>  <strong>Identifikasi anomali</strong> .  Kita terus dihadapkan pada dunia yang sangat kompleks.  Misalnya, titik lemah dalam percepatan evaluasi LKM dapat menjadi sumber penipuan otomatis. <br><br>  Customer Journey adalah konsep akses cepat dan mudah ke aliran data yang melewati model.  Model ini memudahkan untuk mendeteksi anomali yang merupakan karakteristik penipuan pada saat kemunculannya yang masal. <br><br><h2>  Bagaimana semuanya diatur? </h2><br>  Tanpa ragu, kami mengambil <strong>Kafka</strong> sebagai patch Pesan Bus.  Ini adalah solusi yang baik yang digunakan oleh banyak pelanggan kami, operasi ini dapat bekerja dengannya. <br><br><img src="https://habrastorage.org/webt/uu/5k/3r/uu5k3rnxw7lu4iulruewhzmif8w.jpeg"><br><br><blockquote>  Beberapa komponen sistem mungkin sudah digunakan di perusahaan itu sendiri.  Kami tidak membangun sistem lagi, tetapi menggunakan kembali apa yang sudah mereka miliki. </blockquote><br>  <strong>Penyimpanan Data</strong> dalam hal ini adalah penyimpanan yang biasanya sudah dimiliki klien.  Ini bisa menjadi Hadoop, database relasional dan non-relasional.  Kita dapat bekerja di luar kotak dengan HDFS, Hive, Impala, Greenplum dan PostgreSQL.  Kami menganggap penyimpanan ini sebagai sumber untuk jendela toko. <br><br>  Data tiba di gudang, melewati ETL kami atau ETL pelanggan, jika ia memilikinya.  Kami sedang membangun jendela toko yang selanjutnya digunakan di dalam model.  Penyimpanan Data digunakan dalam mode hanya baca. <br><br><h3>  Perkembangan kami </h3><br>  <strong>Papan tulis</strong>  Nama ini diambil dari salah satu praktik matematika yang agak aneh dari 30-40-an.  Ini adalah manajer jalur pipa yang tinggal di sistem admin.  Blackboard memiliki semacam Meta Storage.  Ini menyimpan pipa sendiri dan konfigurasi yang diperlukan untuk menginisialisasi semua komponen. <br><br>  Semua pekerjaan sistem dimulai dengan Blackboard.  Dengan beberapa keajaiban, pipa berakhir di Meta Storage, Blackboard setelah beberapa saat memahami ini, mengeluarkan versi pipa saat ini, menginisialisasi dan mengirimkan sinyal ke dalam Kafka. <br><br>  Ada <strong>lingkungan runtime</strong> .  Itu dibangun di Dockers dan dapat direplikasi ke server, termasuk di cloud pribadi pelanggan. <br><br>  Keluar dari kotak muncul <strong>Aktor</strong> utama <strong>:: Init</strong> - ini adalah inisialisasi.  Ini adalah jin yang hanya dapat melakukan dua hal: <strong>membangun</strong> dan <strong>menghancurkan komponen</strong> .  Dia menerima perintah dari Blackboard: "Ini pipeline, perlu diluncurkan pada server ini dan itu dengan sumber daya ini dan itu dalam jumlah ini dan itu - bekerja!"  Kemudian aktor memulai semuanya. <br><br>  Secara matematis, aktor adalah fungsi yang mengambil satu atau lebih objek sebagai input, mengubah keadaan objek menggunakan algoritma di dalam, menghasilkan objek baru di output, atau mengubah keadaan objek yang sudah ada. <br><br>  Secara teknis, aktor adalah program Python.  Berjalan di wadah Docker dengan lingkungannya. <br><br>  Aktor tidak tahu tentang keberadaan aktor lain.  Satu-satunya entitas yang tahu bahwa selain aktor ada seluruh pipa secara keseluruhan - ini adalah Blackboard.  Ini memantau status eksekusi semua aktor dalam sistem dan mempertahankan keadaan saat ini, yang dinyatakan dalam pemantauan sebagai gambaran dari seluruh proses bisnis secara keseluruhan. <br><br>  Aktor :: Init memunculkan banyak wadah Docker.  Selain itu, aktor dapat bekerja dengan penyimpanan data. <br><br>  Sistem itu sendiri memiliki komponen <strong>Penyimpanan Acara</strong> .  Sebagai Penyimpanan Acara, kami menggunakan <strong>ClickHouse</strong> .  Tugasnya sederhana: semua informasi yang dipertukarkan antara aktor melalui Kafka disimpan di ClickHouse.  Ini dilakukan <strong>untuk audit lebih lanjut</strong> .  Ini adalah log operasi pipa. <br><br>  Aktor juga dapat dikembangkan untuk <strong>Perjalanan Pelanggan</strong> .  Mereka melihat perubahan dalam log pipa, dan dapat dengan cepat membangun kembali jendela yang diperlukan untuk model atau komponen untuk bekerja dengan aturan, sudah ada di dalam pipa.  Ini adalah proses perubahan data yang sedang berlangsung. <br><br>  Pemantauan agak primitif dibangun di atas <strong>Prometheus</strong> .  Aktor ini diberikan API dasar, dan dalam mode tertutup, tetapi cukup transparan bagi pengembang, ia mengirim pesan dengan metrik ke Kafka.  Prometheus membaca metrik dari Kafka dan menyimpannya di repositori. <br><br>  Untuk visualisasi kami menggunakan <strong>Grafana</strong> . <br><br><h3>  Dua titik integrasi </h3><br>  Yang pertama adalah titik integrasi dengan sumber data yang melewati ETL ke gudang data.  Titik integrasi kedua ketika layanan sudah digunakan oleh konsumen data, misalnya, layanan penilaian. <br><br>  Kami mengambil <strong>Apache ServiceMix.</strong>  Dari pengalaman, titik-titik integrasi ini memiliki tipe yang sama dengan jenis protokol yang sama: SOAP, ISTIRAHAT, kurang sering antrian.  Setiap kali kita tidak ingin mengembangkan konstruktor atau layanan kita sendiri untuk menghasilkan layanan SOAP berikutnya.  Oleh karena itu, kami mengambil ServiceMix, menggambarkannya di SDL, di mana model data layanan ini dan metode yang ada di dalamnya dibangun.  Kemudian kami mendorong melalui router di dalam ServiceMix, dan itu menghasilkan layanan itu sendiri. <br><br>  Dari diri kami sendiri, kami menambahkan konversi sinkron-asinkron yang rumit.  Semua permintaan yang hidup di dalam sistem asinkron dan masuk melalui Bus Pesan. <br><br>  Sebagian besar layanan penilaian bersifat sinkron.  Permintaan ServiceMix datang melalui REST atau SOAP.  Pada titik ini, ia melewati Gateway kami, yang mempertahankan pengetahuan tentang sesi HTTP.  Lalu ia mengirim pesan ke Kafka, itu berjalan melalui beberapa pipa, dan solusi dihasilkan. <br><br>  Namun, mungkin masih belum ada solusi.  Misalnya, ada sesuatu yang jatuh, atau ada SLA yang sulit untuk mengambil keputusan, dan Gateway memantau: "Oke, saya menerima permintaan, dia datang kepada saya dalam topik Kafka lain, atau tidak ada yang datang kepada saya, tetapi pemicu waktu habis saya berhasil."  Kemudian lagi, konversi dari sinkron ke asinkron berjalan, dan dalam sesi HTTP yang sama, ada respons kepada konsumen dengan hasil kerja.  Ini mungkin kesalahan atau perkiraan normal. <br><br>  Ngomong-ngomong, kami makan seekor anjing hambar berkat Open Source yang hebat dan kuat.  Kami menggunakan ServiceMix dari salah satu versi terbaru, dan Kafka dari versi sebelumnya dan semuanya bekerja dengan sempurna.  Kami menulis di Gateway ini, berdasarkan kubus-kubus yang sudah ada di ServiceMix.  Ketika versi baru Kafka keluar, kami dengan senang hati mengambilnya, tetapi ternyata dukungan untuk kepala bagian dalam pesan di Kafka yang sebelumnya ada telah berubah.  Gateway di dalam ServiceMix tidak bisa lagi bekerja dengan mereka.  Untuk memahami ini, kami menghabiskan banyak waktu.  Sebagai hasilnya, kami membangun Gateway kami, yang dapat bekerja dengan versi baru Kafka.  Kami menulis tentang masalah kepada pengembang ServiceMix dan menerima jawabannya: "Terima kasih, kami pasti akan membantu Anda dalam versi berikutnya!" <br><br>  Karena itu, kami dipaksa untuk memantau pembaruan dan secara teratur mengubah sesuatu. <br><br>  <strong>Infrastruktur adalah Gitlab.</strong>  Kami menggunakan hampir semua yang ada di dalamnya. <br><br><ul><li>  Repositori kode. </li><li>  Melanjutkan Integrasi / Melanjutkan pengiriman Pipa. </li><li>  Registri untuk memelihara daftar kontainer Docker. </li></ul><br><h3>  Komponen </h3><br>  Kami telah mengembangkan 5 komponen: <br><br><ul><li>  <strong>Blackboard</strong> - manajemen siklus hidup pipa.  Di mana, apa dan dengan parameter apa yang harus dijalankan dari pipa. </li><li>  <strong>Extractor fitur</strong> berfungsi sederhana - kami memberi tahu Extractor fitur bahwa kami mendapatkan model data ini dan itu pada input, pilih bidang yang diperlukan dari data, memetakannya ke nilai-nilai tertentu.  Misalnya, kami mendapatkan tanggal lahir klien, mengubahnya menjadi usia, menggunakannya sebagai fitur dalam model kami.  Extractor fitur bertanggung jawab untuk pengayaan data. </li><li>  <strong>Mesin berbasis aturan</strong> - memeriksa data sesuai aturan.  Ini adalah bahasa deskripsi sederhana yang memungkinkan orang yang terbiasa dengan konstruksi &lt;code&gt; jika, selain itu &lt;code /&gt; blok untuk menggambarkan aturan untuk memeriksa dalam sistem. </li><li>  <strong>Mesin pembelajaran mesin</strong> - memungkinkan Anda untuk menjalankan eksekutor, menginisialisasi model yang terlatih dan mengirimkannya ke data input.  Pada output, model mengambil data. </li><li>  <strong>Mesin</strong> pengambilan keputusan - <strong>mesin</strong> pengambilan keputusan, keluar dari grafik.  Memiliki kaskade model, misalnya, cabang yang berbeda dari penilaian peminjam, Anda harus memutuskan masalah uang di suatu tempat.  Seperangkat aturan untuk solusi harus sederhana. ,     LTV- —     ,     ,  . </li></ul><br><br><h3>   </h3><br>         .  —  ,    .  —      ,      . <br><br>   pipeline    . <br><img src="https://habrastorage.org/webt/o7/vy/dj/o7vydjrruyfittwhwzumh_gc_rq.jpeg"><br><ul><li>   <strong>Feature extractor</strong> :  ,        ,      . </li><li> <strong> </strong> . ,  -:  , ,       18. </li><li>  <strong> .</strong>    ,    .     ,      ,        pipeline. </li><li>  <strong>Decision engine</strong> .             . </li><li>  <strong></strong> . </li></ul><br>      yaml.         .    ,  ,        .           yaml. <br><br>  pipeline,   ,   : feature extractor, rules, models, decision engine,    .   — <strong>      Docker-</strong> .    Registry,   Docker-. -,   ,    . ,  ,      Docker-       . <br><br><h3>  Saluran pipa </h3><br>     ,     <strong>Python</strong> —         . Feature extractor, ,   decision engine   Python. <br><br> Pipeline   <strong>yaml.</strong>      meta storage     —   <strong></strong> . <br><br>  Runtime environment   10 ,  Blackboard  ,    pipeline    10 .  ,      : , , IP-    Kafka, , .       . <br><br>     GitLab.      Ansible. ,    .           ,      50 000    Ansible  . <br><br><h2>   ? </h2><br>  GitLab  pipeline.    GitLab. CI  ,   ,  ,  .   <strong>GitLab Runner</strong> ,    Docker-  ,    pipeline.    —    Registry. <br><br><img src="https://habrastorage.org/webt/gz/dx/hr/gzdxhruymhjm2_wejqybqizdp0i.jpeg"><br><br>  Docker  ,       .   Docker-        .   CI pipeline    pipeline  -  Meta Storage,    Blackboard. <br><br> Blackboard    Meta Storage —   , , ,   -.   Docker-     , , . <br><br> -   Blackboard  Meta Storage      :   ,  Kafka,   .  ,    ,   Docker-    ,     . <br><br>  ,    Docker-,  — pipeline ! <br><br>      DigitalOcean.     AWS  Scaleway,     . <br><br>    ,        .  pipeline         . ,    . <br><br><h3>    ? </h3><br>   —   .  ,   pipeline,     real-time   . <br><br><ul><li> 2 Feature extractor  .     1 , .. json    . </li><li> 8  — 8  ML engine.      XGBoost. </li><li> 18     RB engine (115 ).   1000     . </li><li> 1 decision engine. </li></ul><br>       200   .  2 Feature extractor, 8 , 18   1 decision engine      1,2 . <br><br><h3>  </h3><br> <strong>Discovery .</strong>  ,   -   .  ,      ,    .    .      Meta Storage. <br><br> <strong>  pipeline</strong> .    ,  <strong>BPM</strong> .        yaml      ,     ,      . <br><br> <strong>    .</strong>       Java, Scala, R.    Python,       ,     .    API   ,   pipeline      . <br><br><h2>  Apa hasilnya? </h2><br>    —     .    —   .   <strong> </strong> ,      .  ,         .     —     2018 . <br><br>         ,      .    —    ,   ,    . <br><br> <strong>    ,   </strong> .     ,    ,    notebook   ,     . <br><br><blockquote> , -      ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> ,           .  ,     , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">UseData Conf</a> .  ,    ,       ,   16 . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id455648/">https://habr.com/ru/post/id455648/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id455638/index.html">Alan Kay tidak menemukan benda</a></li>
<li><a href="../id455640/index.html">“Mesin Emosi” Marvin Minsky: Bab 4. “Bagaimana Kita Mengenali Kesadaran”</a></li>
<li><a href="../id455642/index.html">Arsitektur layanan antrian pesan terdistribusi di Yandex.Cloud</a></li>
<li><a href="../id455644/index.html">Kami menggunakan data dalam praktik</a></li>
<li><a href="../id455646/index.html">Security Week 24: backdoors pabrik di smartphone Android</a></li>
<li><a href="../id455650/index.html">Bagaimana kami melatih jaringan saraf untuk mengklasifikasikan sekrup</a></li>
<li><a href="../id455652/index.html">Deep Learning vs akal sehat: mengembangkan bot obrolan</a></li>
<li><a href="../id455658/index.html">Legendaris Intel Core i7-2600K: menguji Sandy Bridge pada 2019 (bagian 3)</a></li>
<li><a href="../id455662/index.html">Tampilan mekanis besar dengan mekanisme cam sebagai decoder</a></li>
<li><a href="../id455666/index.html">Membangun Penjualan Outbound di Perusahaan Layanan TI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
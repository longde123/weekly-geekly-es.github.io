<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë≤ üç™ üïâÔ∏è API fonctionnelle Keras dans TensorFlow üèÇüèª üëÉüèø üà∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Keras dispose de deux API pour construire rapidement des architectures de r√©seau neuronal s√©quentielles et fonctionnelles. Si le premier vous permet d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>API fonctionnelle Keras dans TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483664/"><img src="https://habrastorage.org/webt/w1/zr/n8/w1zrn8ydafoxahso_ig7vx1stfg.png"><br><br>  Keras dispose de deux API pour construire rapidement des architectures de r√©seau neuronal s√©quentielles et fonctionnelles.  Si le premier vous permet de construire uniquement des architectures s√©quentielles de r√©seaux de neurones, alors en utilisant l'API fonctionnelle, vous pouvez d√©finir un r√©seau de neurones sous la forme d'un graphe acyclique dirig√© arbitraire, ce qui donne beaucoup plus de possibilit√©s pour construire des mod√®les complexes.  Cet article est une traduction du Guide des fonctionnalit√©s de l'API fonctionnelle du site Web TensorFlow. <br><a name="habracut"></a><br><h2>  Pr√©sentation </h2><br>  L'API fonctionnelle vous permet de cr√©er des mod√®les de mani√®re plus flexible que l'API s√©quentielle; elle peut traiter des mod√®les avec une topologie non lin√©aire, des mod√®les avec des couches communes et des mod√®les avec plusieurs entr√©es ou sorties. <br><br>  Il est bas√© sur le fait que le mod√®le d'apprentissage profond est g√©n√©ralement un graphe acyclique dirig√© (DAG) de couches <br><br>  L'API fonctionnelle est un ensemble d'outils pour <b>tracer des couches</b> . <br><br>  Consid√©rez le mod√®le suivant: <br><br><blockquote>  (entr√©e: vecteur √† 784 dimensions) <br>  ‚Üß <br>  [Couche dense (64 √©l√©ments, activation de relu)] <br>  ‚Üß <br>  [Couche dense (64 √©l√©ments, activation de relu)] <br>  ‚Üß <br>  [Couche dense (10 √©l√©ments, activation de softmax)] <br>  ‚Üß <br>  (sortie: distribution de probabilit√© sur 10 classes) </blockquote>  Il s'agit d'un simple graphique de 3 couches. <br><br>  Pour cr√©er ce mod√®le √† l'aide de l'API fonctionnelle, vous devez commencer par cr√©er un n≈ìud d'entr√©e: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,))</code> </pre> <br>  Ici, nous indiquons simplement la dimension de nos donn√©es: vecteurs √† 784 dimensions.  Veuillez noter que la quantit√© de donn√©es est toujours omise, nous n'indiquons que la dimension de chaque √©l√©ment.  Pour saisir la taille destin√©e aux images `(32, 32, 3)`, nous utiliserions: <br><br><pre> <code class="python hljs">img_inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>))</code> </pre> <br>  Les <code>inputs</code> renvoy√©es contiennent des informations sur la taille et le type de donn√©es que vous pr√©voyez de transf√©rer vers votre mod√®le: <br><br><pre> <code class="python hljs">inputs.shape</code> </pre> <br><pre> <code class="python hljs">TensorShape([<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>])</code> </pre> <br><pre> <code class="python hljs">inputs.dtype</code> </pre> <br><pre> <code class="python hljs">tf.float32</code> </pre> <br>  Vous cr√©ez un nouveau n≈ìud dans le graphe de calques en appelant le calque sur cet objet d' <code>inputs</code> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers dense = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) x = dense(inputs)</code> </pre> <br>  ¬´Appeler un calque¬ª revient √† dessiner une fl√®che depuis ¬´l'entr√©e¬ª dans le calque que nous avons cr√©√©.  Nous ¬´passons¬ª l'entr√©e √† la couche <code>dense</code> et nous obtenons <code>x</code> . <br><br>  Ajoutons quelques couches suppl√©mentaires √† notre graphique de couches: <br><br><pre> <code class="python hljs">x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x)</code> </pre> <br>  Nous pouvons maintenant cr√©er un <code>Model</code> sp√©cifiant ses entr√©es et sorties dans le graphique des couches: <br><br><pre> <code class="python hljs">model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br>  Regardons √† nouveau le processus complet de d√©finition du mod√®le: <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs=inputs, outputs=outputs, name=<span class="hljs-string"><span class="hljs-string">'mnist_model'</span></span>)</code> </pre> <br>  Voyons √† quoi ressemble le r√©sum√© du mod√®le: <br><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><pre> <code class="python hljs">Model: <span class="hljs-string"><span class="hljs-string">"mnist_model"</span></span> _________________________________________________________________ Layer (type) Output Shape Param <span class="hljs-comment"><span class="hljs-comment"># ================================================================= img (InputLayer) [(None, 784)] 0 _________________________________________________________________ dense_3 (Dense) (None, 64) 50240 _________________________________________________________________ dense_4 (Dense) (None, 64) 4160 _________________________________________________________________ dense_5 (Dense) (None, 10) 650 ================================================================= Total params: 55,050 Trainable params: 55,050 Non-trainable params: 0 _________________________________________________________________</span></span></code> </pre> <br>  Nous pouvons √©galement dessiner le mod√®le sous forme de graphique: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model.png'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/oq/4o/vl/oq4ovlxewr3hxczaldchmbeyfua.png" alt="image"><br><br>  Et d√©rivez √©ventuellement les dimensions de l'entr√©e et de la sortie de chaque couche sur le graphique construit: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model_with_shape_info.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fn/rm/hc/fnrmhcqknnsjdcgmqp9w6dpong8.png" alt="image"><br><br>  Cette image et le code que nous avons √©crit sont identiques.  Dans la version de code, les fl√®ches de liaison sont simplement remplac√©es par des op√©rations d'appel. <br><br>  Le ¬´graphe de couches¬ª est une image mentale tr√®s intuitive pour le mod√®le d'apprentissage en profondeur, et l'API fonctionnelle est un moyen de cr√©er des mod√®les qui refl√®tent √©troitement cette image mentale. <br><br><h2>  Formation, √©valuation et conclusion </h2><br>  Apprendre, √©valuer et d√©river le travail pour les mod√®les construits √† l'aide de l'API fonctionnelle, tout comme dans les mod√®les s√©quentiels. <br><br>  Envisagez une d√©monstration rapide. <br><br>  Ici, nous chargeons l'ensemble de donn√©es d'image MNIST, le convertissons en vecteurs, entra√Ænons le mod√®le sur les donn√©es (tout en surveillant la qualit√© du travail sur l'√©chantillon de test), et enfin nous √©valuons notre mod√®le sur les donn√©es de test: <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = x_train.reshape(<span class="hljs-number"><span class="hljs-number">60000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> x_test = x_test.reshape(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> model.compile(loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, optimizer=keras.optimizers.RMSprop(), metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) history = model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) test_scores = model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Test loss:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(<span class="hljs-string"><span class="hljs-string">'Test accuracy:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h2>  Enregistrement et s√©rialisation </h2><br>  L'enregistrement et la s√©rialisation des mod√®les cr√©√©s √† l'aide de l'API fonctionnelle fonctionnent exactement de la m√™me mani√®re que pour les mod√®les s√©quentiels. <br><br>  La m√©thode standard pour enregistrer un mod√®le fonctionnel consiste √† appeler <code>model.save(</code> ), ce qui vous permet d'enregistrer le mod√®le entier dans un fichier. <br><br>  Vous pouvez ensuite restaurer le m√™me mod√®le √† partir de ce fichier, m√™me si vous n'avez plus acc√®s au code qui a cr√©√© le mod√®le. <br><br>  Ce fichier comprend: <br><br><ul><li>  Architecture du mod√®le </li><li>  Poids du mod√®le (obtenus lors de la formation) </li><li>  Configuration de la formation du mod√®le (ce que vous avez r√©ussi √† <code>compile</code> ) </li><li>  L'optimiseur et son √©tat, s'il l'√©tait (cela vous permet de reprendre l'entra√Ænement l√† o√π vous vous √©tiez arr√™t√©) </li></ul><br><pre> <code class="python hljs">model.save(<span class="hljs-string"><span class="hljs-string">'path_to_my_model.h5'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> model <span class="hljs-comment"><span class="hljs-comment"># Recreate the exact same model purely from the file: model = keras.models.load_model('path_to_my_model.h5')</span></span></code> </pre><br><h2>  Utilisation du m√™me graphe de calque pour d√©finir plusieurs mod√®les </h2><br>  Dans l'API fonctionnelle, les mod√®les sont cr√©√©s en sp√©cifiant les donn√©es d'entr√©e et de sortie dans un graphique de couches.  Cela signifie qu'un graphique √† couche unique peut √™tre utilis√© pour g√©n√©rer plusieurs mod√®les. <br><br>  Dans l'exemple ci-dessous, nous utilisons la m√™me pile de calques pour cr√©er deux mod√®les: <br>  un mod√®le de <code> (encoder)</code> qui convertit les images d'entr√©e en vecteurs 16 dimensions et un mod√®le de <code> (autoencoder)</code> bout en <code> (autoencoder)</code> pour la formation. <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(encoder_output) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) autoencoder = keras.Model(encoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre><br>  Veuillez noter que nous rendons l'architecture de d√©codage strictement sym√©trique √† l'architecture de codage, de sorte que nous obtenons la dimension des donn√©es de sortie de la m√™me mani√®re que les donn√©es d'entr√©e <code>(28, 28, 1)</code> .  La couche <code>Conv2D</code> est en <code>Conv2D</code> vers la couche <code>Conv2D</code> , et la couche <code>MaxPooling2D</code> sera le dos √† la couche <code>MaxPooling2D</code> . <br><br><h2>  Les mod√®les peuvent √™tre appel√©s en tant que couches </h2><br>  Vous pouvez utiliser n'importe quel mod√®le comme s'il s'agissait d'une couche, en l'appelant en <code>Input</code> ou en sortie d'une autre couche. <br><br>  Notez qu'en invoquant un mod√®le, vous r√©utilisez non seulement son architecture, vous r√©utilisez √©galement ses poids.  Voyons cela en action.  Voici un autre exemple d'un exemple d'auto-encodeur, lorsqu'un mod√®le d'encodeur, un mod√®le de d√©codeur est cr√©√©, et ils sont connect√©s en deux appels pour obtenir un mod√®le d'auto-encodeur: <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'original_img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() decoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">16</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'encoded_img'</span></span>) x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(decoder_input) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder = keras.Model(decoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'decoder'</span></span>) decoder.summary() autoencoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) encoded_img = encoder(autoencoder_input) decoded_img = decoder(encoded_img) autoencoder = keras.Model(autoencoder_input, decoded_img, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre> <br>  Comme vous pouvez le voir, un mod√®le peut √™tre imbriqu√©: un mod√®le peut contenir un sous-mod√®le (puisque le mod√®le peut √™tre consid√©r√© comme une couche). <br><br>  Un cas d'utilisation courant pour les mod√®les d'imbrication est l' <i>assemblage</i> . <br><br>  √Ä titre d'exemple, voici comment combiner un ensemble de mod√®les en un mod√®le qui fait la moyenne de leurs pr√©visions: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> keras.Model(inputs, outputs) model1 = get_model() model2 = get_model() model3 = get_model() inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) y1 = model1(inputs) y2 = model2(inputs) y3 = model3(inputs) outputs = layers.average([y1, y2, y3]) ensemble_model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br><br><h2>  Manipulation de topologies de graphes complexes </h2><br><h3>  Mod√®les avec plusieurs entr√©es et sorties </h3><br>  L'API fonctionnelle simplifie la manipulation de plusieurs entr√©es et sorties.  Cela ne peut pas √™tre fait avec l'API s√©quentielle. <br><br>  Voici un exemple simple. <br><br>  Supposons que vous cr√©ez un syst√®me de classement des applications client par priorit√© et que vous les envoyez au bon service. <br><br>  Votre mod√®le aura 3 entr√©es: <br><br><ul><li>  En-t√™te d'application (saisie de texte) </li><li>  Contenu texte de l'application (saisie de texte) </li><li>  Toutes les balises ajout√©es par l'utilisateur (entr√©e cat√©gorielle) </li></ul><br>  Le mod√®le aura 2 sorties: <br><br><ul><li>  Score de priorit√© entre 0 et 1 (sortie sigmo√Øde scalaire) </li><li>  Le service qui doit traiter la demande (sortie softmax pour de nombreux services) </li></ul><br>  Construisons un mod√®le en plusieurs lignes √† l'aide de l'API fonctionnelle. <br><br><pre> <code class="python hljs">num_tags = <span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-comment"><span class="hljs-comment">#     num_words = 10000 #         num_departments = 4 #     title_input = keras.Input(shape=(None,), name='title') #      body_input = keras.Input(shape=(None,), name='body') #      tags_input = keras.Input(shape=(num_tags,), name='tags') #    `num_tags` #      64-  title_features = layers.Embedding(num_words, 64)(title_input) #      64-  body_features = layers.Embedding(num_words, 64)(body_input) #        128-  title_features = layers.LSTM(128)(title_features) #        32-  body_features = layers.LSTM(32)(body_features) #          x = layers.concatenate([title_features, body_features, tags_input]) #         priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x) #       department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x) #   ,     model = keras.Model(inputs=[title_input, body_input, tags_input], outputs=[priority_pred, department_pred])</span></span></code> </pre> <br>  Dessinons un graphe mod√®le: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'multi_input_and_output_model.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gc/hk/uw/gchkuwc_zgefnaf4tx0ercck8bc.png"><br><br>  Lors de la compilation de ce mod√®le, nous pouvons attribuer diff√©rentes fonctions de perte √† chaque sortie. <br><br>  Vous pouvez m√™me attribuer des poids diff√©rents √† chaque fonction de perte pour varier leur contribution √† la fonction globale de perte d'apprentissage. <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=[<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>], loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br>  Puisque nous avons donn√© des noms √† nos couches de sortie, nous pouvons √©galement sp√©cifier des fonctions de perte: <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss={<span class="hljs-string"><span class="hljs-string">'priority'</span></span>: <span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'department'</span></span>: <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>}, loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br>  Nous pouvons former le mod√®le en passant des listes de tableaux Numpy de donn√©es d'entr√©e et d'√©tiquettes: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Dummy input data title_data = np.random.randint(num_words, size=(1280, 10)) body_data = np.random.randint(num_words, size=(1280, 100)) tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32') # Dummy target data priority_targets = np.random.random(size=(1280, 1)) dept_targets = np.random.randint(2, size=(1280, num_departments)) model.fit({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets}, epochs=2, batch_size=32)</span></span></code> </pre><br>  Lorsque vous appelez fit avec un objet <code>Dataset</code> , soit un tuple de listes telles que <code>([title_data, body_data, tags_data], [priority_targets, dept_targets])</code> , soit un tuple de dictionnaires <code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> doivent √™tre retourn√©s <code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> . <br><br><h3>  Mod√®le de resnet de formation </h3><br>  En plus des mod√®les avec plusieurs entr√©es et sorties, l'API fonctionnelle simplifie la manipulation des topologies avec une connectivit√© non lin√©aire, c'est-√†-dire des mod√®les dans lesquels les couches ne sont pas connect√©es en s√©rie.  De tels mod√®les ne peuvent pas non plus √™tre impl√©ment√©s √† l'aide de l'API s√©quentielle (comme son nom l'indique). <br><br>  Un cas d'utilisation courant pour cela est les connexions r√©siduelles. <br><br>  Construisons un mod√®le de formation ResNet pour CIFAR10 pour le d√©montrer. <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) block_1_output = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_1_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_2_output = layers.add([x, block_1_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_2_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_3_output = layers.add([x, block_2_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(block_3_output) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs, outputs, name=<span class="hljs-string"><span class="hljs-string">'toy_resnet'</span></span>) model.summary()</code> </pre> <br>  Dessinons un graphe mod√®le: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'mini_resnet.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/qj/vi/bk/qjvibkpx9zrbp09rcfhj_drtlzc.png"><br><br>  Et lui apprendre: <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() x_train = x_train.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_test = x_test.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> y_train = keras.utils.to_categorical(y_train, <span class="hljs-number"><span class="hljs-number">10</span></span>) y_test = keras.utils.to_categorical(y_test, <span class="hljs-number"><span class="hljs-number">10</span></span>) model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)</code> </pre> <br><h2>  Partage de couche </h2><br>  Une autre bonne utilisation de l'API fonctionnelle est les mod√®les qui utilisent des couches communes.  Les couches communes sont des instances de couches r√©utilis√©es dans le m√™me mod√®le: elles √©tudient les entit√©s li√©es √† plusieurs chemins dans un graphe de couches. <br><br>  Les couches communes sont souvent utilis√©es pour coder des donn√©es d'entr√©e provenant des m√™mes espaces (par exemple, de deux morceaux de texte diff√©rents qui ont le m√™me dictionnaire), car elles fournissent l'√©change d'informations entre ces diff√©rentes donn√©es, ce qui permet √† ces mod√®les d'√™tre form√©s sur moins de donn√©es.  Si un certain mot appara√Æt sur l'une des entr√©es, cela facilitera son traitement sur toutes les entr√©es qui passent par le niveau g√©n√©ral. <br><br>  Pour partager une couche dans l'API fonctionnelle, il suffit d'appeler plusieurs fois la m√™me instance de la couche.  Par exemple, ici la couche <code>Embedding</code> est partag√©e sur deux entr√©es de texte: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   1000    128-  shared_embedding = layers.Embedding(1000, 128) #     text_input_a = keras.Input(shape=(None,), dtype='int32') #     text_input_b = keras.Input(shape=(None,), dtype='int32') #           encoded_input_a = shared_embedding(text_input_a) encoded_input_b = shared_embedding(text_input_b)</span></span></code> </pre> <br><h2>  R√©cup√©ration et r√©utilisation des n≈ìuds dans un graphe de couches </h2><br>  √âtant donn√© que le graphe de calque que vous manipulez dans l'API fonctionnelle est une structure de donn√©es statique, vous pouvez y acc√©der et le v√©rifier.  C'est ainsi que nous construisons des mod√®les fonctionnels, par exemple, sous forme d'images. <br><br>  Cela signifie √©galement que nous pouvons acc√©der aux activations des couches interm√©diaires (¬´n≈ìuds¬ª dans le graphique) et les utiliser √† d'autres endroits.  C'est extr√™mement utile pour extraire des traits, par exemple! <br><br>  Voyons un exemple.  Il s'agit d'un mod√®le VGG19 avec des balances pr√©-entra√Æn√©es sur ImageNet: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.applications <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> VGG19 vgg19 = VGG19()</code> </pre> <br>  Et ce sont des activations de mod√®le interm√©diaires obtenues en interrogeant la structure des donn√©es du graphique: <br><br><pre> <code class="python hljs">features_list = [layer.output <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> layer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> vgg19.layers]</code> </pre> <br>  Nous pouvons utiliser ces fonctionnalit√©s pour cr√©er un nouveau mod√®le d'extraction de fonctionnalit√©s qui renvoie des valeurs d'activation de niveau interm√©diaire - et nous pouvons tout faire en 3 lignes <br><br><pre> <code class="python hljs">feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list) img = np.random.random((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) extracted_features = feat_extraction_model(img)</code> </pre> <br>  Ceci est pratique lors de la mise en ≈ìuvre d'un transfert de style neuronal, comme dans d'autres cas. <br><br><h2>  Extension de l'API en √©crivant des couches personnalis√©es </h2><br>  <code>tf.keras</code> dispose d'une large gamme de couches int√©gr√©es.  Voici quelques exemples: <br><br>  Couches convolutionnelles: <code>Conv1D</code> , <code>Conv2D</code> , <code>Conv3D</code> , <code>Conv2DTranspose</code> , etc. <br>  Couches de <code>MaxPooling1D</code> : <code>MaxPooling1D</code> , <code>MaxPooling2D</code> , <code>MaxPooling3D</code> , <code>AveragePooling1D</code> , etc. <br>  Couches RNN: <code>GRU</code> , <code>LSTM</code> , <code>ConvLSTM2D</code> , etc. <br>  <code>BatchNormalization</code> , <code>Dropout</code> , <code>Embedding</code> , etc. <br><br>  Si vous n'avez pas trouv√© ce dont vous avez besoin, il est facile d'√©tendre l'API en cr√©ant votre propre couche. <br><br>  Toutes les couches sous-classent la classe <code>Layer</code> et impl√©mentent: <br><br>  La m√©thode d' <code>call</code> qui d√©finit les calculs effectu√©s par la couche. <br>  La m√©thode de <code>build</code> qui cr√©e les pond√©rations de couche (notez qu'il s'agit simplement d'une convention de style; vous pouvez √©galement cr√©er des pond√©rations dans <code>__init__</code> ). <br><br>  Voici une impl√©mentation simple de la couche <code>Dense</code> : <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs)</code> </pre> <br>  Si vous souhaitez que votre couche personnalis√©e <code>get_config</code> en charge la s√©rialisation, vous devez √©galement d√©finir la m√©thode <code>get_config</code> qui renvoie les arguments du constructeur de l'instance de couche: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> {<span class="hljs-string"><span class="hljs-string">'units'</span></span>: self.units} inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs) config = model.get_config() new_model = keras.Model.from_config( config, custom_objects={<span class="hljs-string"><span class="hljs-string">'CustomDense'</span></span>: CustomDense})</code> </pre> <br>  Facultativement, vous pouvez √©galement impl√©menter la m√©thode de classe <code>from_config (cls, config)</code> , qui est charg√©e de recr√©er l'instance de couche, compte tenu de son dictionnaire de configuration.  L' <code>from_config</code> par d√©faut <code>from_config</code> ressemble √† ceci: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">from_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cls, config)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> cls(**config)</code> </pre> <br><h2>  Quand utiliser l'API fonctionnelle </h2><br>  Comment d√©terminer quand il vaut mieux utiliser l'API fonctionnelle pour cr√©er un nouveau mod√®le, ou simplement sous-classer le <code>Model</code> directement? <br><br>  En g√©n√©ral, l'API fonctionnelle est de plus haut niveau et facile √† utiliser, elle poss√®de un certain nombre de fonctions qui ne sont pas prises en charge par les mod√®les sous-class√©s. <br><br>  Cependant, la sous-classification du mod√®le vous donne une grande flexibilit√© lors de la cr√©ation de mod√®les qui ne sont pas facilement d√©crits comme un graphique acyclique dirig√© de couches (par exemple, vous ne pouvez pas impl√©menter Tree-RNN avec l'API fonctionnelle, vous devez sous-classer le <code>Model</code> directement). <br><br><h3>  Points forts de l'API fonctionnelle: </h3><br>  Les propri√©t√©s r√©pertori√©es ci-dessous sont toutes vraies pour les mod√®les s√©quentiels (qui sont √©galement des structures de donn√©es), mais elles sont vraies pour les mod√®les sous-class√©s (qui sont du code Python, pas des structures de donn√©es). <br><br><h4>  L'API fonctionnelle produit un code plus court. </h4><br>  Pas de <code>super(MyClass, self).__init__(...)</code> , pas d' <code>def call(self, ...):</code> etc. <br><br>  Comparez: <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x) mlp = keras.Model(inputs, outputs)</code> </pre> <br>  Avec version sous-class√©e: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MLP</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(keras.Model)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, **kwargs)</span></span></span><span class="hljs-function">:</span></span> super(MLP, self).__init__(**kwargs) self.dense_1 = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) self.dense_2 = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> x = self.dense_1(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.dense_2(x) <span class="hljs-comment"><span class="hljs-comment">#   . mlp = MLP() #    . #            . _ = mlp(tf.zeros((1, 32)))</span></span></code> </pre> <br><h4>  Votre mod√®le est valid√© tel qu'il est √©crit. </h4><br>  Dans l'API fonctionnelle, les sp√©cifications d'entr√©e (forme et type) sont cr√©√©es √† l'avance (via `Input`), et chaque fois que vous appelez la couche, la couche v√©rifie que les sp√©cifications qui lui sont transmises correspondent √† ses hypoth√®ses; si ce n'est pas le cas, vous recevrez un message d'erreur utile . <br><br>  Cela garantit que tout mod√®le que vous cr√©ez avec l'API fonctionnelle d√©marre.  Tout le d√©bogage (non li√© au d√©bogage de convergence) se produira de mani√®re statique pendant la construction du mod√®le, et non au moment de l'ex√©cution.  Ceci est similaire √† la v√©rification de type dans le compilateur. <br><br><h4>  Votre mod√®le fonctionnel peut √™tre repr√©sent√© graphiquement, et il est √©galement testable. </h4><br>  Vous pouvez dessiner le mod√®le sous la forme d'un graphique, et vous pouvez facilement acc√©der aux n≈ìuds interm√©diaires du graphique, par exemple, pour extraire et r√©utiliser l'activation des couches interm√©diaires, comme nous l'avons vu dans l'exemple pr√©c√©dent: <br><br><pre> <code class="plaintext hljs">features_list = [layer.output for layer in vgg19.layers] feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)</code> </pre> <br>  √âtant donn√© que le mod√®le fonctionnel est plus une structure de donn√©es qu'un morceau de code, il peut √™tre s√©rialis√© en toute s√©curit√© et peut √™tre enregistr√© sous la forme d'un fichier unique qui vous permet de recr√©er exactement le m√™me mod√®le sans acc√®s au code source. <br><br><h3>  Faiblesses fonctionnelles de l'API </h3><br><h4>  Il ne prend pas en charge les architectures dynamiques. </h4><br>  L'API fonctionnelle traite les mod√®les en tant que couches DAG.  Cela est vrai pour la plupart des architectures d'apprentissage en profondeur, mais pas pour tout le monde: par exemple, les r√©seaux r√©cursifs ou les RNN arborescents ne r√©pondent pas √† cette hypoth√®se et ne peuvent pas √™tre impl√©ment√©s dans l'API fonctionnelle. <br><br><h4>  Parfois, il vous suffit de tout √©crire √† partir de z√©ro. </h4><br>  Lors de l'√©criture d'architectures avanc√©es, vous souhaiterez peut-√™tre aller au-del√† de la ¬´d√©finition de couches DAG¬ª: par exemple, vous pouvez utiliser plusieurs m√©thodes de formation et de sortie personnalis√©es sur une instance de votre mod√®le.  Cela n√©cessite un sous-classement. <br><br><h2>  Combiner et combiner diff√©rents styles d'API </h2><br>  Il est important de noter que le choix entre l'API fonctionnelle ou la sous-classification du mod√®le n'est pas une solution binaire qui vous limite √† une cat√©gorie de mod√®les.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tous les mod√®les de l'API tf.keras peuvent interagir les uns avec les autres, qu'il s'agisse de mod√®les s√©quentiels, de mod√®les fonctionnels ou de mod√®les / couches sous-class√©s √©crits √† partir de z√©ro. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pouvez toujours utiliser le mod√®le fonctionnel ou le mod√®le s√©quentiel dans le cadre du mod√®le / couche sous-class√©:</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment"># Define a Functional model inputs = keras.Input((None, units)) x = layers.GlobalAveragePooling1D()(inputs) outputs = layers.Dense(1, activation='sigmoid')(x) model = keras.Model(inputs, outputs) class CustomRNN(layers.Layer): def __init__(self): super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation='tanh') self.projection_2 = layers.Dense(units=units, activation='tanh') # Our previously-defined Functional model self.classifier = model def call(self, inputs): outputs = [] state = tf.zeros(shape=(inputs.shape[0], self.units)) for t in range(inputs.shape[1]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=1) print(features.shape) return self.classifier(features) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, timesteps, input_dim)))</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Inversement, vous pouvez utiliser n'importe quel calque ou mod√®le sous-class√© dans l'API fonctionnelle si vous impl√©mentez une m√©thode </font></font><code>call</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">qui correspond √† l'un des mod√®les suivants: </font></font><br><br> <code>call(self, inputs, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o√π </font></font><code>inputs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est le tenseur ou la structure de tenseur imbriqu√©e (par exemple, la liste des tenseurs), et o√π </font></font><code>**kwargs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">sont les arguments non-tenseur (pas d'entr√©e) . </font></font><br> <code>call(self, inputs, training=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o√π </font></font><code>training</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est une valeur bool√©enne indiquant dans quel mode la couche, l'apprentissage ou la sortie doit se comporter. </font></font><br> <code>call(self, inputs, mask=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">o√π </font></font><code>mask</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est le tenseur de masque bool√©en (utile pour RNN, par exemple). </font></font><br> <code>call(self, inputs, training=None, mask=None, **kwargs)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- bien s√ªr, vous pouvez avoir les deux param√®tres d√©finissant le comportement de la couche en m√™me temps.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De plus, si vous impl√©mentez la m√©thode `get_config` sur votre couche ou mod√®le personnalis√©, les mod√®les fonctionnels que vous cr√©ez avec lui seront s√©rialisables et clon√©s. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voici un petit exemple o√π nous utilisons des RNN personnalis√©s √©crits √† partir de z√©ro Mod√®les fonctionnels:</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomRNN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.projection_2 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.classifier = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> outputs = [] state = tf.zeros(shape=(inputs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], self.units)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(inputs.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.classifier(features) <span class="hljs-comment"><span class="hljs-comment">#           #  `batch_shape`,     `CustomRNN`  #    (     `state`). inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim)) x = layers.Conv1D(32, 3)(inputs) outputs = CustomRNN()(x) model = keras.Model(inputs, outputs) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, 10, 5)))</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ceci conclut notre guide API fonctionnel! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous disposez maintenant d'un puissant ensemble d'outils pour cr√©er des mod√®les d'apprentissage en profondeur.</font></font><br><br>  <i>Apr√®s v√©rification, la traduction appara√Ætra √©galement sur Tensorflow.org.</i>  <i>Si vous souhaitez participer √† la traduction de la documentation du site Tensorflow.org en russe, veuillez nous contacter √† titre personnel ou commentaires.</i>  <i>Toutes corrections ou commentaires sont appr√©ci√©s.</i> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ä titre d'illustration, nous avons utilis√© l'image du mod√®le GoogLeNet, qui est √©galement un graphique acyclique dirig√©.</font></font></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr483664/">https://habr.com/ru/post/fr483664/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr483650/index.html">Cosmodromes plus proches de l'√©quateur - Cosmodrome tropical de Wenchang</a></li>
<li><a href="../fr483652/index.html">Mentez-vous si vous le pouvez: caract√©ristiques de la r√©alisation d'un pentest sociotechnique</a></li>
<li><a href="../fr483654/index.html">Commentaires en rallye, un √† un, pourquoi cela peut ne pas fonctionner et comment essayer de le r√©soudre?</a></li>
<li><a href="../fr483656/index.html">Tableau au d√©tail, vraiment?</a></li>
<li><a href="../fr483662/index.html">Int√©gration de Cisco Threat Response et de Cisco Stealthwatch Enterprise</a></li>
<li><a href="../fr483666/index.html">√Ä propos de Volodya et de l'ozoniseur</a></li>
<li><a href="../fr483668/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 397 (6-12 janvier 2020)</a></li>
<li><a href="../fr483670/index.html">Tout ce que vous vouliez savoir sur l'adresse MAC</a></li>
<li><a href="../fr483674/index.html">Comment fonctionnent les r√©seaux de neurones binaires et pourquoi ils seront populaires en 2020</a></li>
<li><a href="../fr483676/index.html">√âvaluation de l'efficacit√© et du co√ªt de la mise en ≈ìuvre d'un syst√®me d'analyse marketing de bout en bout</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
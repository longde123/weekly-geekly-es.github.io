<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≥üèø üôÉ üëêüèª Utilisation d'Ansible, Terraform, Docker, Consul, Nomad dans les nuages ‚Äã‚Äã(Alexey Vakhov, Uchi.ru) üë®‚Äçüöí üë£ üö´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cet article est une transcription du reportage vid√©o d'Alexei Vakhov de Uchi.ru ¬´Nuages ‚Äã‚Äãdans les nuages¬ª 


 Uchi.ru est une plateforme en ligne pou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Utilisation d'Ansible, Terraform, Docker, Consul, Nomad dans les nuages ‚Äã‚Äã(Alexey Vakhov, Uchi.ru)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439382/"><p>  Cet article est une transcription du reportage vid√©o d'Alexei Vakhov de Uchi.ru ¬´Nuages ‚Äã‚Äãdans les nuages¬ª </p><br><p>  Uchi.ru est une plateforme en ligne pour l'enseignement scolaire, plus de 2 millions d'√©l√®ves, des classes interactives d√©cident r√©guli√®rement avec nous.  Tous nos projets sont h√©berg√©s enti√®rement dans des clouds publics, 100% des applications fonctionnent dans des conteneurs, √† partir du plus petit, pour un usage interne, et se terminant par de grandes productions √† 1k + requ√™tes par seconde.  Il se trouve que nous avons 15 clusters de dockers isol√©s (pas Kubernetes, sic!) Dans cinq fournisseurs de cloud.  1500 applications utilisateur, dont le nombre ne cesse de cro√Ætre. </p><br><p>  Je vais parler de choses tr√®s sp√©cifiques: comment nous sommes pass√©s aux conteneurs, comment nous g√©rons l'infrastructure, les probl√®mes que nous avons rencontr√©s, ce qui a fonctionn√© et ce qui n'a pas fonctionn√©. </p><br><p>  Au cours du rapport, nous discuterons: </p><br><ul><li>  Motivation pour la s√©lection de technologies et les fonctionnalit√©s commerciales </li><li>  Outils: Ansible, Terraform, Docker, Github Flow, Consul, Nomad, Prometheus, Shaman - une interface Web pour Nomad. </li><li>  Utilisation de la f√©d√©ration de clusters pour g√©rer l'infrastructure distribu√©e </li><li>  D√©ploiements NoOps, environnements de test, circuits d'application (les d√©veloppeurs apportent leurs propres modifications pratiquement par eux-m√™mes) </li><li>  Histoires divertissantes de la pratique </li></ul><br><iframe width="560" height="315" src="https://www.youtube.com/embed/C7utdhh6UCk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Peu importe, s'il vous pla√Æt, sous le chat. </p><a name="habracut"></a><br><p>  Je m'appelle Alexey Vakhov.  Je travaille en tant que directeur technique chez Uchi.ru.  Nous h√©bergeons dans des clouds publics.  Nous utilisons activement Terraform, Ansible.  Depuis lors, nous sommes compl√®tement pass√©s √† Docker.  Tr√®s satisfait.  Comme nous sommes heureux, comme nous sommes heureux - je le dirai. </p><br><p><img src="https://habrastorage.org/webt/l3/zh/6x/l3zh6xrikma1bku1ks6vo7hixva.png"></p><br><p>  La soci√©t√© Uchi.ru est engag√©e dans la production de produits pour l'enseignement scolaire.  Nous avons une plate-forme principale sur laquelle les enfants r√©solvent des probl√®mes interactifs dans divers sujets en Russie, au Br√©sil et aux √âtats-Unis.  Nous organisons des olympiades en ligne, des concours, des clubs, des camps.  Chaque ann√©e, cette activit√© se d√©veloppe. </p><br><p><img src="https://habrastorage.org/webt/ms/m8/8h/msm88h-eoc67vkjnokat3ssq_wo.png"></p><br><p>  D'un point de vue technique, la pile web classique (Ruby, Python, NodeJS, Nginx, Redis, ELK, PostgreSQL).  La principale caract√©ristique est que de nombreuses applications.  Les applications sont h√©berg√©es dans le monde entier.  Chaque jour, il y a des d√©ploiements en production. </p><br><p>  La deuxi√®me caract√©ristique est que nos r√©gimes changent tr√®s souvent.  Ils demandent de lancer une nouvelle application, d'arr√™ter l'ancienne, d'ajouter cron pour les jobs d'arri√®re-plan.  Toutes les 2 semaines, il y a de nouveaux Jeux Olympiques - c'est une nouvelle application.  Tout est n√©cessaire pour accompagner, surveiller, sauvegarder.  Par cons√©quent, l'environnement est superdynamique.  Le dynamisme est notre principale difficult√©. </p><br><p><img src="https://habrastorage.org/webt/gm/dn/vu/gmdnvuag9g19b-bkzqbamcrwdw8.png"></p><br><p>  Notre unit√© de travail est le site.  En termes de fournisseurs de cloud, c'est Project.  Notre site est une entit√© compl√®tement isol√©e avec une API et un sous-r√©seau priv√©.  Lorsque nous entrons dans le pays, nous recherchons des fournisseurs de cloud locaux.  Pas partout, il y a Google et Amazon.  Il arrive parfois qu'il n'y ait pas d'API pour le fournisseur de cloud.  Ext√©rieurement, nous publions VPN et HTTP, HTTPS aux √©quilibreurs.  Tous les autres services communiquent √† l'int√©rieur du cloud. </p><br><p><img src="https://habrastorage.org/webt/vz/b6/w2/vzb6w2yehx_arktffwsjxildnhe.png"></p><br><p>  Pour chaque site, nous avons cr√©√© notre propre r√©f√©rentiel Ansible.  Le r√©f√©rentiel contient hosts.yml, playbook, r√¥les et 3 dossiers secrets, dont je parlerai plus tard.  C'est terraform, provision, routage.  Nous sommes fans de standardisation.  Notre r√©f√©rentiel doit toujours √™tre appel√© le "nom ansible du site".  Nous normalisons chaque nom de fichier, structure interne.  Ceci est tr√®s important pour une automatisation plus pouss√©e. </p><br><p><img src="https://habrastorage.org/webt/v3/a0/kk/v3a0kke8aauqojk4hj5blhgwmt4.png"></p><br><p>  Nous avons cr√©√© Terraform il y a un an et demi, nous l'utilisons donc.  Terraform sans modules, sans structure de fichiers (une structure plate est utilis√©e).  Structure du fichier Terraform: 1 serveur - 1 fichier, param√®tres r√©seau et autres param√®tres.  √Ä l'aide de terraform, nous d√©crivons des serveurs, des lecteurs, des domaines, des compartiments s3, des r√©seaux, etc.  Terraform pr√©pare sur place le fer √† repasser. </p><br><p><img src="https://habrastorage.org/webt/wq/qz/ly/wqqzly1s4_6brivoh4hkeyvexmu.png"></p><br><p>  Terraform cr√©e le serveur, puis l'ensemble roule ces serveurs.  Du fait que nous utilisons partout la m√™me version du syst√®me d'exploitation, nous avons √©crit tous les r√¥les √† partir de z√©ro.  Les r√¥les possibles sont g√©n√©ralement publi√©s sur Internet pour tous les syst√®mes d'exploitation qui ne fonctionnent nulle part.  Nous avons tous pris des r√¥les Ansible et n'avons laiss√© que ce dont nous avions besoin.  R√¥les Ansible standardis√©s.  Nous avons 6 playbooks de base.  Une fois lanc√©, Ansible installe une liste standard de logiciels: OpenVPN, PostgreSQL, Nginx, Docker.  Kubernetes que nous n'utilisons pas. </p><br><p><img src="https://habrastorage.org/webt/fh/x4/i4/fhx4i4ztn5fvmjj6uivdbkdrub8.png"></p><br><p>  Nous utilisons Consul + Nomad.  Ce sont des programmes tr√®s simples.  Ex√©cutez 2 programmes √©crits en Golang sur chaque serveur.  Le consul est responsable de la d√©couverte du service, de la v√©rification de l'int√©grit√© et de la valeur-cl√© pour le stockage de la configuration.  Nomad est responsable de la planification, du d√©ploiement.  Nomad lance des conteneurs, fournit des d√©ploiements, y compris une mise √† jour continue sur le bilan de sant√©, vous permet d'ex√©cuter des sidecar-containers.  Le cluster est facile √† √©tendre ou vice versa √† r√©duire.  Nomad prend en charge le cron distribu√©. </p><br><p><img src="https://habrastorage.org/webt/dc/ic/sm/dcicsmnhzdduqbnxsdpe6ewkvws.png"></p><br><p>  Une fois que nous sommes entr√©s sur le site, Ansible ex√©cute le playbook situ√© dans le r√©pertoire d'approvisionnement.  Le playbook de ce r√©pertoire est responsable de l'installation du logiciel dans le cluster de dockers utilis√© par les administrateurs.  Installez le logiciel prometheus, grafana et shaman secret. </p><br><p>  Shaman est un tableau de bord Web pour les nomades.  Nomad est de bas niveau et je ne veux pas vraiment laisser les d√©veloppeurs y entrer.  Dans chaman, nous voyons une liste d'applications, nous donnons aux d√©veloppeurs un bouton de d√©ploiement pour les applications.  Les d√©veloppeurs peuvent modifier les configurations: ajouter des conteneurs, des variables d'environnement, d√©marrer des services. </p><br><p><img src="https://habrastorage.org/webt/cm/jw/ry/cmjwryicd-9dvhlpg--bhfrfe9w.png"></p><br><p>  Et enfin, le dernier √©l√©ment du site est le routage.  Le routage est stock√© dans le stockage K / V du consul, c'est-√†-dire qu'il existe un lien entre l'amont, le service, l'url, etc.  Sur chaque √©quilibreur, il existe un mod√®le Consul qui g√©n√®re une configuration nginx et la fait recharger.  Une chose tr√®s fiable, nous n'avons jamais eu de probl√®me avec √ßa.  La caract√©ristique de ce sch√©ma est que le trafic accepte le nginx standard et vous pouvez toujours voir quelle configuration a √©t√© g√©n√©r√©e et fonctionner comme avec le nginx standard. </p><br><p><img src="https://habrastorage.org/webt/rn/ew/7g/rnew7gm_fe4gcc57clp3f41ob68.png"></p><br><p>  Ainsi, chaque site se compose de 5 couches.  Avec terraform, nous personnalisons le mat√©riel.  Nous pouvons effectuer la configuration de base des serveurs, mettre le docker-cluster.  Provision r√©sume le logiciel syst√®me.  Le routage dirige le trafic sur le site.  Applications contient des applications utilisateur et des applications administrateur. </p><br><p>  Nous avons d√©bogu√© ces couches pendant longtemps afin qu'elles soient aussi identiques que possible.  Provision, le routage correspond √† 100% entre les sites.  Par cons√©quent, pour les d√©veloppeurs, chaque site est absolument identique. </p><br><p>  Si les informaticiens passent d'un projet √† l'autre, ils tombent dans un environnement tout √† fait typique.  En ansible, nous n'avons pas pu rendre les param√®tres de pare-feu et VPN identiques pour diff√©rents fournisseurs de cloud.  Avec un r√©seau, tous les fournisseurs de cloud fonctionnent diff√©remment.  Terraform est partout le sien, car il contient des conceptions sp√©cifiques pour chaque fournisseur de cloud. </p><br><p><img src="https://habrastorage.org/webt/36/kg/ti/36kgtipfv8rl9lhjevdjhhiwp5m.png"></p><br><p>  Nous avons 14 sites de production.  La question se pose: comment les g√©rer?  Nous avons fait le 15√®me site ma√Ætre, dans lequel nous n'autorisons que les administrateurs.  Elle travaille sur un sch√©ma de f√©d√©ration. </p><br><p>  L'id√©e a √©t√© prise de prometheus.  Il y a un mode dans prometheus lorsque nous installons prometheus dans chaque site.  Nous publions Prometheus via l'autorisation d'authentification de base HTTPS.  Le ma√Ætre Prometheus ne r√©cup√®re que les m√©triques n√©cessaires du prometheus distant.  Cela permet de comparer les m√©triques des applications dans diff√©rents clouds, de trouver les applications les plus t√©l√©charg√©es ou d√©charg√©es.  La notification centralis√©e (alerte) passe par le ma√Ætre Prometheus pour les administrateurs.  Les d√©veloppeurs re√ßoivent des alertes de prometheus local. </p><br><p><img src="https://habrastorage.org/webt/cw/c9/yd/cwc9yd3hpmbhbxvlz0ygacktloa.png"></p><br><p>  Le chaman est configur√© de la m√™me mani√®re.  Gr√¢ce au site principal, les administrateurs peuvent d√©ployer, configurer sur n'importe quel site via une seule interface.  Nous r√©solvons une classe de probl√®mes suffisamment importante sans quitter ce site ma√Ætre. </p><br><p><img src="https://habrastorage.org/webt/kz/ul/hi/kzulhi1jrz8c3bssubwqzremd6g.png"></p><br><p>  Je vais vous dire comment nous sommes pass√©s √† Docker.  Ce processus est tr√®s lent.  Nous avons travers√© environ 10 mois.  √Ä l'√©t√© 2017, nous avions 0 conteneurs de production.  En avril 2018, nous avons ancr√© et d√©ploy√© notre derni√®re application en production. </p><br><p><img src="https://habrastorage.org/webt/h5/9t/ib/h59tibngi0uru-f4vehjhnq3e1c.png"></p><br><p>  Nous venons du monde du rubis sur rails.  Il y avait 99% des applications Ruby on Rails.  Rails se d√©ploie √† travers Capistrano.  Techniquement, Capistrano fonctionne comme suit: le d√©veloppeur lance cap deploy, capistrano se rend sur tous les serveurs d'applications via ssh, r√©cup√®re la derni√®re version du code, collecte les actifs, migre la base de donn√©es.  Capistrano cr√©e un lien symbolique vers la nouvelle version du code et envoie un signal USR2 √† l'application Web.  √Ä ce signal, le serveur Web prend un nouveau code. </p><br><p><img src="https://habrastorage.org/webt/il/us/4e/ilus4ejwfkd6cvjnmjrcln2ugyy.png"></p><br><p>  La derni√®re √©tape de docker ne se fait pas comme √ßa.  Dans Docker, vous devez arr√™ter l'ancien conteneur, soulever le nouveau conteneur.  Cela soul√®ve la question: comment changer de trafic?  Dans le monde du cloud, la d√©couverte de services en est responsable. </p><br><p><img src="https://habrastorage.org/webt/k3/il/ig/k3iligqv5uphvlp1l3cvkmbggem.png"></p><br><p>  Par cons√©quent, nous avons ajout√© un consul √† chaque site.  Le consul a √©t√© ajout√© car ils utilisaient Terraform.  Nous avons envelopp√© toutes les configurations nginx dans un mod√®le de consul.  Formellement, la m√™me chose, mais d√©j√† nous √©tions pr√™ts √† g√©rer dynamiquement le trafic √† l'int√©rieur des sites. </p><br><p><img src="https://habrastorage.org/webt/u9/qg/ag/u9qgagdnxiwo4lowkqi7micapqu.png"></p><br><p>  Ensuite, nous avons √©crit un script ruby ‚Äã‚Äãqui collectait une image sur l'un des serveurs, la poussait dans le registre, puis passait par ssh √† chaque serveur, en r√©cup√©rait de nouveaux et arr√™tait les anciens conteneurs, les enregistrant en consul.  Les d√©veloppeurs ont √©galement continu√© √† ex√©cuter cap deploy, mais les services √©taient d√©j√† en cours d'ex√©cution dans docker. </p><br><p>  Je me souviens qu'il y avait deux versions du script, la seconde s'est av√©r√©e assez avanc√©e, il y a eu une mise √† jour continue, lorsqu'un petit nombre de conteneurs s'est arr√™t√©, de nouveaux ont augment√©, le consul Helfcheki a attendu et est parti. </p><br><p><img src="https://habrastorage.org/webt/07/fx/gk/07fxgkf2fcvnhs8gpfjfrygalxs.png"></p><br><p>  Ils ont ensuite r√©alis√© qu'il s'agissait d'une m√©thode sans issue.  Le script est pass√© √† 600 lignes.  La prochaine √©tape du d√©lestage manuel, nous avons remplac√© Nomad.  Masquer les d√©tails du travail au d√©veloppeur.  Autrement dit, ils appelaient toujours cap deploy, mais √† l'int√©rieur il y avait d√©j√† une technologie compl√®tement diff√©rente. </p><br><p><img src="https://habrastorage.org/webt/4j/o-/ms/4jo-ms4v5mx1q4cn6sqt6n0jr4a.png"></p><br><p>  Et √† la fin, nous avons d√©plac√© le d√©ploiement vers l'interface utilisateur et retir√© l'acc√®s au serveur, laissant le bouton de d√©ploiement vert et l'interface de contr√¥le. </p><br><p>  En principe, une telle transition s'est av√©r√©e bien s√ªr longue, mais nous avons √©vit√© le probl√®me que j'ai rencontr√© √† plusieurs reprises. </p><br><p>  Il existe une sorte de pile, de syst√®me ou quelque chose comme √ßa.  Khachennaya d√©j√† juste en volets.  Le d√©veloppement d'une nouvelle version commence.  Apr√®s quelques mois ou quelques ann√©es, selon la taille de l'entreprise, moins de la moiti√© des fonctionnalit√©s n√©cessaires sont impl√©ment√©es dans la nouvelle version, et l'ancienne version s'est toujours √©chapp√©e.  Et cette nouvelle est √©galement devenue tr√®s h√©rit√©e.  Et il est temps de commencer une nouvelle troisi√®me version √† partir de z√©ro.  En g√©n√©ral, c'est un processus sans fin. </p><br><p>  Par cons√©quent, nous d√©pla√ßons toujours la pile enti√®re dans son ensemble.  √Ä petits pas, de travers, avec des b√©quilles, mais enti√®rement.  Nous ne pouvons pas mettre √† niveau par exemple le moteur Docker sur un seul site.  Il faut mettre √† jour partout, s'il y a un d√©sir. </p><br><p><img src="https://habrastorage.org/webt/qy/31/jr/qy31jrpbehnyyrcozqaxnj41jk8.png"></p><br><p>  D√©ploiements.  Toutes les instructions de docker d√©ploient 10 conteneurs nginx ou 10 conteneurs redis dans docker.  Ceci est un mauvais exemple, car les images sont d√©j√† assembl√©es, les images sont claires.  Nous avons emball√© nos applications de rails dans Docker.  La taille des images de docker √©tait de 2 √† 3 gigaoctets.  Ils sortiront pas si vite. </p><br><p><img src="https://habrastorage.org/webt/2q/lx/bf/2qlxbfo5lnhpjfxcjtlljrntgxy.png"></p><br><p>  Le deuxi√®me probl√®me est venu du web hipster.  Un site Web hipster est toujours Github Flow.  En 2011, il y avait un poste de cr√©ation d'√©poque que Github Flow dirige, de sorte que la toile enti√®re roule.  √Ä quoi √ßa ressemble?  La branche ma√Ætre est toujours la production.  Lors de l'ajout de nouvelles fonctionnalit√©s, nous cr√©ons une branche.  Lors de la fusion, nous proc√©dons √† la r√©vision du code, ex√©cutons des tests, augmentons l'environnement de transfert.  Environnement de mise en sc√®ne √† la recherche d'affaires.  Au moment X, si tout r√©ussit, nous fusionnons la branche en master et passons en production. </p><br><p>  Sur capistrano, cela a bien fonctionn√©, car il a √©t√© cr√©√© pour cela.  Docker nous vend toujours un pipeline.  Assembl√© le conteneur.  Le conteneur peut √™tre transf√©r√© au d√©veloppeur, testeur, transf√©r√© √† la production.  Mais au moment de la fusion en master, le code est d√©j√† diff√©rent.  Toutes les images de docker qui ont √©t√© collect√©es √† partir de la branche de fonctionnalit√©, elles n'ont pas √©t√© collect√©es √† partir du ma√Ætre. </p><br><p><img src="https://habrastorage.org/webt/vl/th/8g/vlth8gjbcyby-rpamtltaijqxcy.png"></p><br><p>  Comment l'avons-nous fait?  Nous collectons l'image, la mettons dans le registre docker local.  Et apr√®s cela, nous faisons le reste des op√©rations: migration, d√©ploiement en production. </p><br><p><img src="https://habrastorage.org/webt/1i/kb/yu/1ikbyuh88pytsfprkkwdi6_6ppq.png"></p><br><p>  Pour assembler rapidement cette image, nous utilisons Docker-in-Docker.  Sur Internet, tout le monde √©crit que c'est un anti-pattern, √ßa plante.  Nous n'avions rien de tel.  Combien travaillaient d√©j√† avec lui n'a jamais eu de probl√®me.  Nous transmettons le r√©pertoire / var / lib / docker au serveur principal en utilisant le volume persistant.  Toutes les images interm√©diaires se trouvent sur le serveur principal.  L'assemblage d'une nouvelle image tient en quelques minutes. </p><br><p><img src="https://habrastorage.org/webt/6q/_g/67/6q_g67tuzx_n078pff6-aisdvdc.png"></p><br><p>  Pour chaque application, nous cr√©ons un registre docker interne local et notre volume de build.  Parce que docker enregistre toutes les couches sur le disque et est difficile √† nettoyer.  Nous connaissons maintenant l'utilisation du disque de chaque registre Docker local.  Nous savons combien de disque cela n√©cessite.  Vous pouvez recevoir des alertes via Grafana centralis√© et nettoyer.  Pendant que nous nettoyons leurs mains.  Mais nous allons l'automatiser. </p><br><p><img src="https://habrastorage.org/webt/mf/py/wj/mfpywjgwpsj0tbqb6vvvyzz8_1u.png"></p><br><p>  Un autre point.  Image Docker collect√©e.  Maintenant, cette image doit √™tre d√©compos√©e en serveurs.  Lors de la copie d'une grande image Docker, le r√©seau ne r√©siste pas.  Dans le cloud, nous avons 1 Gbit / s.  Il y a un arr√™t global dans le cloud.  Nous d√©ployons maintenant une image Docker sur 4 serveurs de production lourds.  Sur le graphique, vous pouvez voir le disque travaill√© sur 1 pack de serveurs.  Ensuite, le deuxi√®me pack de serveurs est d√©ploy√©.  Ci-dessous, vous pouvez voir l'utilisation du canal.  Environ 1 Gbit / s, nous tirons presque.  Il n'y a plus beaucoup d'acc√©l√©ration. </p><br><p><img src="https://habrastorage.org/webt/lk/eo/hl/lkeohl4fjm-y97kmp3hyogr3p1a.png"></p><br><p>  Ma production pr√©f√©r√©e est l'Afrique du Sud.  Il y a du fer tr√®s cher et lent.  Quatre fois plus cher qu'en Russie.  Il y a une tr√®s mauvaise connexion Internet.  Internet au niveau du modem, mais pas buggy.  L√†, nous d√©ployons des applications en 40 minutes, en prenant en compte le r√©glage des caches, les param√®tres de timeout. </p><br><p><img src="https://habrastorage.org/webt/zl/8x/ig/zl8xig0k9liveeiuzoykh-ctgwm.png"></p><br><p>  Le dernier probl√®me qui m'inqui√©tait avant que Docker ne contacte √©tait la charge.  En fait, la charge est la m√™me que sans docker avec un fer identique.  La seule nuance que nous avons rencontr√©e en un seul point.  Si vous collectez des journaux du moteur Docker via le pilote fluentd int√©gr√©, puis √† une charge d'environ 1000 rps, le tampon fluentd interne commence √† √™tre jonch√© et les demandes commencent √† ralentir.  Nous avons enlev√© l'exploitation foresti√®re dans des conteneurs de side-car.  En nomade, cela s'appelle l'exp√©diteur de grumes.  Un petit conteneur est suspendu √† c√¥t√© d'un grand conteneur d'application.  La seule t√¢che consiste √† le r√©cup√©rer et √† l'envoyer vers un r√©f√©rentiel centralis√©. </p><br><p><img src="https://habrastorage.org/webt/8r/fv/7x/8rfv7xzfamwjrwemisa1laingzy.png"></p><br><p>  Quels √©taient les probl√®mes / solutions / d√©fis.  J'ai essay√© d'analyser quelle √©tait la t√¢che.  Les caract√©ristiques de nos probl√®mes sont: </p><br><ul><li>  de nombreuses applications ind√©pendantes </li><li>  changements continus dans l'infrastructure </li><li>  Flux Github et grandes images de docker </li></ul><br><p><img src="https://habrastorage.org/webt/da/xm/jm/daxmjmflat8cz4a5b-2nmx4pip4.png"></p><br><p>  Nos solutions </p><br><ul><li>  F√©d√©ration des clusters de dockers.  Du point de vue de la manipulation, c'est difficile.  Mais Docker est bon pour d√©ployer des fonctionnalit√©s commerciales en production.  Nous travaillons avec des donn√©es personnelles et nous avons une certification dans chaque pays.  Dans un site isol√©, une telle certification est facile √† passer.  Pendant la certification, toutes les questions se posent: o√π h√©bergez-vous, comment avez-vous un fournisseur de cloud, o√π stockez-vous les donn√©es personnelles, o√π sauvegardez-vous, qui a acc√®s aux donn√©es.  Lorsque tout est isol√©, il est beaucoup plus facile de d√©crire le cercle des suspects et de surveiller tout cela beaucoup plus facilement. </li><li>  Orchestration.  Il est clair que les kubernetes.  Il est partout.  Mais je tiens √† dire que Consul + Nomad est une solution compl√®tement de production. </li><li>  Assemblage d'images.  Vous pouvez rapidement cr√©er des images dans Docker-in-Docker. </li><li>  Lors de l'utilisation de Docker, le maintien d'une charge de 1000 rps est √©galement possible. </li></ul><br><p>  Vecteur de direction de d√©veloppement </p><br><p>  Maintenant, l'un des gros probl√®mes est la d√©synchronisation des versions logicielles sur les sites.  Auparavant, nous configurions le serveur √† la main.  Puis nous sommes devenus des ing√©nieurs devops.  Configurez maintenant le serveur en utilisant ansible.  Nous avons maintenant l'unification totale, la normalisation.  Nous introduisons la pens√©e ordinaire dans la t√™te.  Nous ne pouvons pas r√©parer PostgreSQL avec nos mains sur le serveur.  Si vous avez besoin d'une sorte de r√©glage fin sur un seul serveur, nous pensons comment r√©partir ce param√®tre partout.  Si vous ne standardisez pas, il y aura un zoo de param√®tres. </p><br><p>  Je suis ravi et tr√®s heureux que nous sortions de la bo√Æte gratuitement une infrastructure de travail vraiment, vraiment sympa. </p><br><p><img src="https://habrastorage.org/webt/w6/nz/pw/w6nzpwpzt1tsxifw0gksrvoplpg.png"></p><br><p>  Vous pouvez m'ajouter sur facebook.  Si nous faisons quelque chose de bien, j'√©crirai √† ce sujet. </p><br><p>  Questions: </p><br><p>  Quel est l'avantage du mod√®le Consul par rapport au mod√®le Ansible, par exemple, pour configurer des r√®gles de pare-feu et plus encore? </p><br><p>  R√©ponse: Nous avons maintenant du trafic provenant d'√©quilibreurs externes qui va directement aux conteneurs.  Il n'y a personne entre les deux.  Une configuration y est form√©e qui transmet les adresses IP et les ports du cluster.  De plus, nous avons tous les param√®tres d'√©quilibre en K / V dans Consul.  Nous avons une id√©e de donner des param√®tres de routage aux d√©veloppeurs via une interface s√©curis√©e afin qu'ils ne cassent rien. </p><br><p>  Question: Concernant l'homog√©n√©it√© de tous les sites.  N'y a-t-il vraiment aucune demande des entreprises ou des d√©veloppeurs dont vous avez besoin pour d√©ployer quelque chose de non standard sur ce site?  Par exemple, tarantool avec cassandra. </p><br><p>  R√©ponse: Cela arrive, mais c'est tr√®s rare.  Ceci nous √©tablissons un artefact s√©par√© interne.  Il y a un tel probl√®me, mais il est rare. </p><br><p>  Question: La solution au probl√®me de livraison est d'utiliser un registre de docker priv√© dans chaque site et √† partir de l√†, il est d√©j√† rapide d'obtenir des images de docker. </p><br><p>  R√©ponse: Quoi qu'il en soit, le d√©ploiement se d√©roulera sur le r√©seau, car nous d√©ployons simultan√©ment l'image docker sur 15 serveurs.  Nous nous reposons contre le r√©seau.  √Ä l'int√©rieur du r√©seau, 1 Gbit / s. </p><br><p>  Question: De nombreux conteneurs Docker sont bas√©s √† peu pr√®s sur la m√™me pile technologique? </p><br><p>  R√©ponse: Ruby, Python, NodeJS. </p><br><p>  Question: √Ä quelle fr√©quence testez-vous ou v√©rifiez-vous les images de votre docker pour les mises √† jour?  Comment r√©solvez-vous les probl√®mes de mise √† jour, par exemple, lorsque glibc, openssl doivent √™tre corrig√©s dans tous les dockers? </p><br><p>  R√©ponse: Si vous trouvez une telle erreur, vuln√©rabilit√©, alors nous nous asseyons pendant une semaine et la r√©parons.  Si vous avez besoin de d√©ployer, nous pouvons d√©ployer le cloud entier (toutes les applications) de z√©ro √† travers la f√©d√©ration.  On peut cliquer sur tous les boutons verts pour le d√©ploiement d'applications et laisser boire du th√©. </p><br><p>  Question: Allez-vous lib√©rer votre chaman en open source? </p><br><p>  R√©ponse: Ici Andrei (montre la personne du public) nous promet de mettre en place un chaman √† l'automne.  Mais l√†, vous devez ajouter un support pour kubernetes.  OpenSource devrait toujours √™tre meilleur. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439382/">https://habr.com/ru/post/fr439382/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439372/index.html">Tu veux jouer un d√©tective? Trouver le bogue dans une fonction de Midnight Commander</a></li>
<li><a href="../fr439374/index.html">Pour ceux qui veulent jouer au d√©tective: trouvez l'erreur dans la fonction de Midnight Commander</a></li>
<li><a href="../fr439376/index.html">Club d'int√©r√™t</a></li>
<li><a href="../fr439378/index.html">Livre (d'√™tre?). R√©flexions sur la nature de l'esprit. Partie I</a></li>
<li><a href="../fr439380/index.html">Comment j'ai cr√©√© une extension pour Atom et VS Code: exp√©rience personnelle et sources</a></li>
<li><a href="../fr439384/index.html">Mod√©lisation Metropolis</a></li>
<li><a href="../fr439388/index.html">Robots en journalisme ou comment utiliser l'intelligence artificielle pour cr√©er du contenu</a></li>
<li><a href="../fr439390/index.html">Les meilleures innovations des r√©seaux sociaux en 2018</a></li>
<li><a href="../fr439392/index.html">La saison des championnats 2019 est ouverte! Coup d'envoi du SNA Hackathon Ala ML Boot Camp 8</a></li>
<li><a href="../fr439394/index.html">En tant que programmeur, les noyaux de datacenter ont √©crit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
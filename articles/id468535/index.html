<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‰ âœï¸ ğŸ‘¦ğŸ¾ Tidak perlu log? ğŸ”† ğŸ‘¼ğŸ» ğŸ•“</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Perkembangan telah banyak berubah dalam beberapa tahun terakhir. Alih-alih aplikasi monolitik, layanan microser dan fungsi datang. Database dari monst...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tidak perlu log?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/468535/">  Perkembangan telah banyak berubah dalam beberapa tahun terakhir.  Alih-alih aplikasi monolitik, layanan microser dan fungsi datang.  Database dari monster industri universal telah merosot menjadi sasaran sempit.  Docker berubah pikiran tentang penyebaran.  Tetapi apakah ide kita tentang log berubah? <br><br>  Salah satu masalah besar di Yandex. Vertikal adalah log - 18 TB per hari dan 250.000 log per detik, semuanya ditulis ke file.  Log bersifat heterogen karena ada banyak bahasa: Scala, Java, Python, Go.  Kemudian mereka dikumpulkan oleh Fluent Bit, menulis di Kafka, penangan bekerja pada satu mesin besi, berkumpul dari Kafka dan menulis semuanya ke disk.  Selain itu, ini adalah versi log yang kedua. <br><br><img src="https://habrastorage.org/webt/4i/z8/ws/4iz8wst0a72z7ytipvzx77wnxiq.jpeg"><br><br>  Akibatnya, masalah pencarian yang panjang muncul.  Log ini dicari menggunakan grep.  Pada beberapa layanan, grep bisa mencapai berjam-jam.  Jika Anda memiliki masalah dalam produksi, Anda tidak akan mencari log Anda selama berjam-jam.  Untuk mengatasi masalah tersebut, Yandex memutuskan untuk menulis sepeda pengiriman log sendiri untuk pencarian.  Apa yang datang dari ini, akan memberitahu <b>Alexei Danilov</b> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">danevge</a> ) - pengembang tim infrastruktur di Yandex.Verticals.  Mengembangkan, menulis, dan mendukung proyek auto.ru dan Yandex.Real Estate. <br><br>  <i>Penafian.</i>  <i>Artikel ini berbicara tentang perkembangan modern dan cocok untuk arsitektur layanan mikro.</i>  <i>Berbagai produk disajikan di sini - ini adalah alat yang digunakan dalam Yandex. Vertikal.</i>  <i>Dalam kondisi lain, analog mungkin lebih berhasil, tetapi mereka melakukan fungsi yang hampir sama.</i> <a name="habracut"></a><br><blockquote>  Catatan  Artikel ini adalah versi diperpanjang dari laporan Alexey Danilov "Log tidak diperlukan" di RIT ++ 2019 DevOps Conf, yang dimodifikasi secara stylistically dan dilengkapi dengan materi baru.  Anda dapat menemukan rekaman video pidato Alexey <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di tautan</a> di saluran YouTube kami. </blockquote><br>  Tim Yandex. Tim Vertikal memiliki 300 orang, sekitar 100 di antaranya adalah pengembang.  Dalam pengembangan, kami tidak berbeda dengan kebanyakan perusahaan yang membuat solusi produk mereka sendiri.  Microservices, semua orang tinggal di Docker, sebuah monolith di PHP mengumpulkan debu di sudut yang gelap, digunakan melalui Hashicorp Nomad dan kami memelihara kebun binatang bahasa: Scala, Java, Go, Node.js, Python. <br><br>  Salah satu masalah infrastruktur besar di Yandex. Vertikal adalah log aplikasi.  Ketika kami secara serius mendekati masalah ini, kami menggunakan versi ketiga dari pengumpulan dan pemrosesan mereka.  Sederhana, ini berfungsi seperti ini: <br><br><ul><li>  aplikasi menulis ke file; <br></li><li>  Fluent Bit membaca file dan mengirimkannya baris demi baris ke Kafka filebeat; <br></li><li>  Pada mesin besi khusus ada aplikasi yang membaca topik Kafka dan menulis ke file pada disk. <br></li></ul><br>  Di musim panas, kami memiliki 18 TB log per hari, atau 250.000 baris per detik.  Ini adalah jumlah yang sangat besar, yang mempersulit pekerjaan dengan data ini.  Satu-satunya cara untuk menganalisis ini adalah grep, karena semuanya disimpan dalam file.  Untuk aplikasi besar, analisis bisa memakan waktu berjam-jam.  Untuk masalah dalam produksi, Anda tidak punya waktu ini. <br><br>  Solusi siap pakai tidak sesuai dengan harga, sumber daya atau kecepatan.  Mereka tidak bisa menangani aliran kami dengan baik.  Sulit untuk menghitung jumlah upaya untuk memasak Elasticsearch.  Saya kira kita tidak tahu cara memasaknya.  Tetapi ini bukan yang kita butuhkan, jika untuk menggunakannya sebagai tempat penyimpanan log, diperlukan kemampuan khusus (keterampilan). <br><br>  Dalam situasi ini, kami memutuskan untuk menerapkan sistem kami sendiri untuk mengumpulkan dan menganalisis log. <br><br><h2>  Sepeda </h2><br><img src="https://habrastorage.org/webt/aw/49/s9/aw49s9cfjgf28z2eqyofr3cx7ea.jpeg"><br><br>  <i>Catatan: Jika sepeda berikutnya tidak menarik, maka segera lanjutkan ke bagian "Typification".</i> <br><br><h3>  Format </h3><br>  Kami menggunakan beberapa PL dan suka microservices.  Untuk bekerja dengan log, kami secara seragam membentuk format JSON kami sendiri.  Ini mencakup sebagian besar kebutuhan untuk pekerjaan lebih lanjut dengan log. <br><br><img src="https://habrastorage.org/webt/z8/8q/g5/z88qg5gh3s5ntz9n91q5opbk0ku.png"><br>  <i>Contoh log dengan semua bidang yang memungkinkan.</i> <br><br><h2>  Driver log Docker </h2><br>  Untuk mengumpulkan log, kami menulis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">driver log buruh pelabuhan</a> kami sendiri - aplikasi di Go.  Itu dirakit dengan cara khusus, disampaikan oleh perintah plugin docker, disimpan dalam registri, dan berjalan dalam satu contoh menjalankan Docker. <br><br>  Karena masalah dengan driver log dapat memengaruhi semua pekerjaan secara negatif, kami mencoba menulis implementasi yang minimal.  Pengemudi kami mendengarkan stdout wadah dan segera meneruskan log ke aplikasi yang ada di dekatnya.  Itu sudah berurusan dengan bagian yang lebih kompleks dari pengiriman. <br><br><h3>  Masalahnya </h3><br>  Saya secara terpisah akan menyebutkan masalah memperbarui versi driver log buruh pelabuhan. <br><br><img src="https://habrastorage.org/webt/a6/sy/md/a6symdnuvy0z5kekvjv924yth-i.png"><br>  <i>Cuplikan layar dari internal Grafana.</i> <br><br>  Di sebelah kiri adalah rasio versi yang diinstal ke mesin.  Sekarang tiga versi diinstal pada semua perangkat keras - tidak ada mobil yang hilang di mana pun dan tidak ada instalasi yang tidak perlu.  Di sebelah kanan adalah jumlah kontainer yang menggunakan versi ini atau itu. <br><br>  Driver buruh pelabuhan tidak dapat pergi dan memperbarui segera.  Untuk melakukan ini, Anda harus memulai kembali semua wadah dan semua layanan, yang dapat menyebabkan masalah.  Oleh karena itu, untuk menginstal versi baru, kami hanya menunggu semua wadah untuk memperbarui sendiri. <br><br><h2>  Skema umum </h2><br>  Pertimbangkan skema umum sistem baru untuk mengumpulkan dan mengirimkan log.  Detail lainnya tidak begitu menarik. <br><br><img src="https://habrastorage.org/webt/nm/lx/pq/nmlxpqlg41ntzuar5imu8pw3-km.jpeg"><br><br>  Aplikasi menulis log dalam format JSON di stdout.  Docker mendengarkan pipa dari wadah dan mengarahkannya ke driver Docker.  Driver Docker membaca dan secara tidak sinkron mencairkan kembali semua yang ada di Pusher. <br><br>  Pusher berdiri di setiap mobil besi.  Dia menyiapkan, menjenuhkan, membalik dan mendorong log ke Antrian Pesan Yandex.  Aliran log dari MQ diurai oleh tiga jenis pekerja dan ditulis ke repositori. <br><br>  Ada tiga repositori untuk merekam log. <br><br><ul><li>  <b>Yandex mapReduce</b> untuk menyimpan dan menganalisis log dalam periode waktu yang lama.  Ini adalah analog dari Hadoop. <br></li><li>  <b>ClickHouse</b> untuk menyimpan log selama hari terakhir. <br></li><li>  <b>Humio</b> (sebagai percobaan) untuk menyimpan log untuk hari terakhir. <br></li></ul><br><h3>  Untung </h3><br>  Format umum memungkinkan Anda untuk menulis dan memproses log dengan cara yang sama.  Pengumpulan log otomatis, tanpa menggunakan disk, dan pengiriman berada di area beberapa detik.  Pencarian kunci dari 2 detik hingga 5 detik.  Penyimpanan dan pengambilan untuk periode waktu yang lama. <br><br>  Untuk volume yang lebih kecil, pertimbangkan alternatif: Humio, Splunk, dan Elastic.  Dua yang terakhir memiliki driver Docker resmi.  Jika Anda tinggal di AWS, itu adalah Amazon CloudWatch. <br><br><h3>  Amazon cloudwatch </h3><br>  Amazon CloudWatch menangani metrik, acara, dan log.  Dia tidak mencari yang terakhir, tidak memberikan item pencarian super dan tidak memprosesnya dalam bentuk yang biasa.  Amazon CloudWatch memproses log, analisis, filter, dan tampilan pada grafik. <br><br><img src="https://habrastorage.org/webt/xc/le/o2/xcleo2if8o1ezw7hob29olfzcta.png"><br>  <i>Amazon CloudWatch mengonversi log ke metrik dan grafik.</i> <br><br><h2>  Apa yang harus dilakukan dengan log? </h2><br>  Kembali ke sepeda kami - apakah ini memuaskan semua kasus?  Tidak, solusi kami memungkinkan Anda menemukan log, tetapi mereka membutuhkan heterogenitas informasi dan jenisnya yang jauh lebih besar.  Log digunakan dalam lebih banyak kasus. <br><br>  Segera setelah Anda mengumpulkan log, kalimat berikut akan menjadi: "Mari kita parsing sesuatu, entah bagaimana memprosesnya, menuliskannya di suatu tempat dan mulai ditampilkan pada grafik, di dashboard."  Ini jalan menuju neraka.  Apalagi jika kita berbicara tentang alat umum. <br><br><blockquote>  Jika Anda membayangkan log sebagai kekacauan atau log peristiwa tertentu dari data apa pun, maka mereka tidak akan berfungsi. </blockquote><br>  Ini akan menjadi kekacauan besar informasi yang tidak dapat diproses.  Sebuah permainan akan dimulai dalam formalisasi log: "Mari kita tulis baris ini dalam format khusus sehingga akan mudah untuk menguraikannya nanti!"  Itu juga tidak berhasil.  Percayalah, kami sudah mencoba. <br><br><h2>  Mengetik </h2><br>  Jika Anda memecah log menjadi tipe dan memprosesnya secara terpisah, Anda dapat menemukan alat yang akan membuatnya lebih mudah untuk bekerja dengannya.  Bekerja tidak lagi dengan log, tetapi seperti data yang berguna - pekerjaan seperti itu lebih transparan dan nyaman.  Beberapa jenis log dapat dibuang sama sekali. <br><br><h3>  Untuk jaga-jaga </h3><br>  Jenis log "menjadi" ini adalah favorit saya.  Jika tidak mungkin untuk menjawab dengan jelas mengapa garis ini atau itu diperlukan, maka mereka harus.  Tipe ini juga bisa disebut "log berjaga-jaga." <br><br><pre><code class="plaintext hljs">// validate customer func Validate(customer Customer) { // ??? log.debug(â€œValidate customer %vâ€, customer) â€¦ log.Error(â€œCustomer not valid %v. Reason: %sâ€, ...) â€¦. }</code> </pre> <br><blockquote>  Log bukan komentar yang bisa dihapus.  Ini adalah bagian dari kode yang lebih sulit untuk dimodifikasi, dikelola, dan bahkan dihapus. </blockquote><br>  Dalam kasus terbaik, log seperti itu dapat berubah menjadi debug atau jejak.  Jenis ini <b>mengacaukan kode</b> .  Karena pencatatan yang terburu-buru, saya bisa memasukkan data pribadi, kata sandi, dan cookie pengguna ke dalamnya. <br><br>  Cara yang benar adalah <b>membuangnya dan melupakannya</b> .  Tapi kemudian kita dihadapkan dengan masalah baru.  Bagaimana cara mengurai situasi dengan kesalahan? <br><br><h3>  Kesalahan fatal / kritis </h3><br>  Untuk memulainya, kami hanya mempertimbangkan kesalahan kritis.  Ini adalah kesalahan yang diderita pengguna dan pengembang.  Yang pertama - ketika mereka tidak dapat menyelesaikan operasi.  Yang kedua - ketika Anda perlu melakukan koreksi dengan tangan. <br><br>  Mengapa log tidak pas? <br><br>  <b>Tidak ada respons cepat</b> .  Jika tim pengembangan mempelajari tentang kesalahan dari pengguna melalui dukungan atau dari Twitter, maka inilah saatnya untuk mengubah sesuatu. <br><br>  <b>Tidak ada konteks</b> .  Baris terpisah dari log kesalahan tidak berguna.  Kita harus mengumpulkan konteksnya sedikit demi sedikit.  Meski begitu, itu mungkin tidak cukup, karena ini adalah konteks dari proses, bukan kesalahan. <br><br>  <b>Tidak ada gambaran besar</b> .  Tidak ada jawaban untuk pertanyaan: <br><br><ul><li>  seberapa sering kesalahan seperti itu terjadi; <br></li><li>  itu terjadi pada replika yang tersisa dari layanan; <br></li><li>  apakah itu sebelumnya? <br></li></ul><br>  Untuk memperbaiki masalah ini, gunakan alat yang sesuai, misalnya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sentry.io</a> .  Ini memungkinkan Anda untuk bekerja dengan informasi kesalahan yang representatif, lengkap (kontekstual) dengan <code>alerting rule</code> dapat disesuaikan.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Situs web penjaga</a> menjelaskan perbedaan log dari menggunakan sentry.io. <br><br><h3>  Bukan kesalahan kritis </h3><br>  Kami melemparkan kesalahan fatal dan kritis dan sekarang semuanya ditulis dalam Sentry.  Tetapi ada kesalahan internal - berbagai perpustakaan atau jawaban dari layanan pihak ketiga. <br><br>  Contoh yang baik adalah coba lagi yang sukses.  Misalkan layanan A beralih ke layanan B, tetapi, karena masalah jaringan, tidak bisa mendapatkan jawaban.  Setelah kesalahan, layanan A kembali beralih ke layanan B dan menerima respons yang valid.  Apakah kesalahan pada panggilan pertama penting?  Tidak.  Dalam hal ini, proses selesai dengan sukses, dan pengguna dapat menggunakan layanan ini. <br><br>  Jika kesalahan semacam itu tidak penting untuk layanan agar berfungsi dan mereka tidak memengaruhi pengguna dengan pengulangan yang jarang, maka ini sama sekali bukan kesalahan.  Ini adalah degradasi dari layanan, walaupun respons terhadap pengguna datang 50 ms kemudian.  Jenis log ini merujuk pada peringatan - Peringatan. <br><br><h3>  Peringatan </h3><br><blockquote>  Lansiran adalah informasi tentang degradasi layanan. </blockquote><br>  Di sini kita akan melihat masalah yang sama yang melekat pada kesalahan kritis, tetapi dengan reservasi.  Reaksi terhadap suatu peristiwa individu tidak penting - kuantitasnya dari waktu ke waktu adalah penting. <br><br>  Pertimbangkan contoh di mana layanan tidak dapat mengambil entri cache dan mengakses penyimpanan dingin.  Jika ini terjadi satu menit sekali, maka ini dapat diambil untuk operasi normal dari layanan.  <b>Emisi langka tidak penting</b> . <br><br>  Tetapi pada saat yang sama, Anda perlu memiliki alat untuk melihat gambaran besar, Anda perlu <b>analisis waktu nyata</b> .  Untuk melacak perubahan dalam jangka waktu yang lama, alangkah baiknya untuk memiliki <b>analisis retrospektif</b> juga.  Degradasi di atas tingkat tertentu (ambang batas) dapat berdampak buruk bagi pengguna - Anda memerlukan <b>reaksi dengan degradasi parah</b> . <br><br><blockquote>  Kita tidak perlu log bertanda Peringatan, tetapi metrik degradasi. </blockquote><br>  Alat pengumpul metrik paling populer adalah Prometheus, dan Anda dapat menggunakan Grafana untuk visualisasi.  Jika Anda memerlukan konteks besar (sama dengan kesalahan), maka Sentry yang sama akan melakukannya, tetapi dengan peringatan dimatikan.  Namun, dalam kebanyakan kasus akan ada konteks yang cukup.  Ini akan digunakan untuk grafik - label Prometheus. <br><br>  Contohnya. <br><div class="scrollable-table"><table><tbody><tr><td>  label <br></td><td>  contoh 1 <br></td><td>  contoh 2 <br></td><td>  contoh 3 <br></td></tr><tr><td>  konteks <br></td><td>  db <br></td><td>  layanan internal <br></td><td>  cache <br></td></tr><tr><td>  modul <br></td><td>  layanan pengguna <br></td><td>  layanan pengguna <br></td><td>  layanan pengguna <br></td></tr><tr><td>  alasan <br></td><td>  long_query <br></td><td>  coba lagi <br></td><td>  miss_cache <br></td></tr><tr><td>  lainnya <br></td><td>  get_user <br></td><td>  service_b <br></td><td>  user_permisson <br></td></tr></tbody></table></div><br>  Tiga peristiwa terjadi di <code>user_service</code> bersyarat.  Mereka memengaruhi operasi layanan: permintaan panjang ke database, akses berulang ke API <code>service_b</code> dan tidak ada hak pengguna yang ditemukan dalam cache.  Bagan dan peringatan akan dikonfigurasikan sebagai hal penting bagi pengembang layanan, berkat konteksnya. <br><br><h3>  Menelusuri </h3><br>  Ini adalah hal pertama yang harus Anda mulai jika kami memilih jalur tempat Anda perlu mengurai log.  Dengan sendirinya, informasi dalam log ini tidak berguna, karena Anda perlu membuat rantai panggilan, melihat data di dalam permintaan, kesalahan dalam rantai panggilan, waktu respons, jumlah RPS. <br><br>  Ada alat hebat untuk melacak - Jaeger atau Zipkin.  Saya sarankan menggunakan OpenTracing, yang keduanya dukung. <br><br>  Anda dapat mengumpulkan penelusuran dari tiga sumber. <br><br><ul><li>  Jika Anda menggunakan <b>balancer</b> bersama, parsing log dari mereka dan kirim ke Jaeger. <br></li><li>  <b>Layanan sendiri</b> , jika mereka menerima alamat melalui Service Discovery dan langsung pergi.  Dalam hal ini, jejak dari layanan dikirim langsung ke Jaeger. <br></li><li>  <b>Mesh layanan</b> cerdas.  Dia tahu cara mengumpulkan dan mengirim jejak, misalnya, Istio. <br></li></ul><br><br><h3>  Informasi awal </h3><br>  Informasi ini adalah tentang panggilan layanan API, peluncuran Cron, permintaan basis data, atau panggilan ke layanan lain. <br><br><pre> <code class="plaintext hljs">{ "_message": "Request: ...; request_id: ...,... ", "_level": "INFO", "_time": "2019-03-08T12:04:05.000+07:00", "_context": "ryawvcHandler", "_tread": "785534" }</code> </pre> <br>  Informasi ini termasuk dalam blok "Hanya dalam kasus", tetapi terpisah karena lebih umum.  Informasi ini diperlukan untuk mengurai kesalahan dan <b>Anda dapat membuangnya</b> . <br><br>  Jika informasi tentang panggilan ke metode internal sangat penting dan Anda tidak dapat melakukannya tanpa itu, bahkan dengan konteks yang dikumpulkan jika terjadi kesalahan, maka perlu menginstruksikan panggilan metode sebagai jejak. <br><br><h3>  Waktu eksekusi </h3><br>  Informasi ini tentang waktu eksekusi metode, API, kueri basis data, atau layanan lainnya. <br><br><pre> <code class="plaintext hljs">{ "_message": "Get customer 12ms", "_level": "INFO", "_time": "2019-03-08T12:04:05.000+07:00", "_context": "ryawvcCustomerRepository", "_tread": "785534" }</code> </pre> <br>  Tidak ada nilai dalam log dari itu, karena Anda perlu menganalisis informasi ini, menampilkannya pada grafik, dan mengkonfigurasi ambang batas.  Jenis log ini perlu diganti dengan <b>metrik</b> , misalnya, di Prometheus. <br><br><h3>  Info bisnis </h3><br>  Informasi ini diperlukan untuk analisis bisnis, analisis perilaku pelanggan, perhitungan keuangan.  Di tempat ini, kami secara historis menggunakan pendekatan yang berlawanan - log yang diuraikan.  Tapi ini adalah contoh yang baik dari apa yang bisa membuat aplikasi log merosot jika Anda bekerja dengan mereka dengan cara ini. <br><br>  Untuk log dengan data bisnis, perjanjian dibuat dengan bidang tetap dalam format TSKV, yang diperlukan untuk analitik.  Aplikasi menulis log bisnis ke file khusus.  Kemudian log dibaca dan dikirim baris demi baris ke MQ, dan aplikasi terpisah memprosesnya dan menulisnya ke database.  Ini adalah contoh dari apa yang berubah menjadi parsing. <br><br><blockquote>  Ini tidak akan berhasil mengurai seluruh aliran log dengan harapan bahwa data akan bertemu. </blockquote><br>  Persyaratan konvensi, format, aturan, dan keandalan sedang muncul.  Ini sudah terlihat sedikit seperti log aplikasi.  Dalam hal ini, log menjadi antrian pengiriman data dengan semua persyaratan berikutnya untuk MQ.  Terlihat bahwa middleware dalam bentuk log adalah berlebihan di sini. <br><br>  Solusi yang baik adalah mengirim data ini langsung ke MQ.  Sudah ada mereka akan diproses, disimpan di penyimpanan yang sesuai dan digunakan oleh tim analisis.  Sebagai contoh, untuk tampilan kami menggunakan Tableau. <br><br><h3>  Performa </h3><br>  Jenis log ini jarang ditemukan dalam log aplikasi dan lebih sering dikumpulkan sebagai metrik.  Secara terpisah, saya menambahkan bahwa untuk mengumpulkan metrik dasar yang spesifik untuk bahasa, cukup menggunakan perpustakaan Prometheus.  Dia secara default akan mengumpulkan semua yang dia raih.  Biaya menambahkan metrik ini kecil. <br><br><img src="https://habrastorage.org/webt/iz/od/jv/izodjvufyysy4-3ihlurtw9rueq.png"><br><br><h3>  Hasil pengetikan </h3><br>  Setelah mengurutkan log berdasarkan jenis, kita dapat mengambil alat yang lebih kuat untuk bekerja dengannya.  Tidak ada sistem yang kompleks atau teknologi ruang angkasa seperti Amazon, tidak ada yang tidak bisa dimunculkan besok.  Anda mungkin sudah memiliki beberapa sistem atau analog ini: Sentry mengumpulkan debu di suatu tempat, Prometheus bekerja di suatu tempat. <br><br><img src="https://habrastorage.org/webt/69/jj/ik/69jjikx9uuyrghuq-1rpw0bu5o0.png"><br><br><blockquote>  Masalahnya bukan dalam teknologi, tetapi dalam perangkap kognitif ketika kita mempercayai log sebagai cara representasi yang andal dari kondisi sistem kita.  Ini tidak demikian, log adalah serangkaian peristiwa kacau. </blockquote><br>  Ada pengecualian - Debug-log, yang dapat digunakan dalam kasus yang jarang terjadi. <br><br><h3>  Debug log </h3><br>  Debug-log harus berupa informasi terperinci.  Mereka tidak boleh menduplikasi apa yang sudah dikirim ke sistem yang kami jelaskan di atas.  Jenis ini ada untuk parsing kasus khusus.  Misalnya, bug yang tidak dapat dipahami terjadi saat produksi, dan saat ini tidak jelas dengan metrik apa yang terjadi. <br><br>  <b>Nyalakan debug-log di hot, tanpa me-restart layanan</b> .  Karena kita berbicara tentang beberapa layanan, tidak akan banyak dari mereka.  Infrastruktur canggih tidak diperlukan.  Stack ELK yang cukup tanpa "persiapan" yang rumit.  Masuk akal juga untuk menambahkan lansiran ke Sentry dengan semua konteks yang diperlukan. <br><br>  <b>Debug log dapat digunakan untuk pengembangan</b> .  Tetapi mereka diganti dengan sempurna dengan debugging. <br><br><h2>  Untuk meringkas </h2><br>  <b>Kami menulis pengiriman log sepeda kami untuk pencarian</b> .  Kami tidak memuaskan pelanggan layanan - mereka semua datang kepada kami untuk memilah, mengumpulkan, dan mengagregasi mereka di suatu tempat.  Ini dapat dihindari - sistem pemrosesan log yang kompleks tidak diperlukan. <br><br><blockquote>  Log mentah tidak berguna, tetapi dapat diubah menjadi metrik yang bermanfaat. </blockquote><br>  Cukup untuk membuat infrastruktur untuk memberikan metrik dan data yang berguna di sekitar layanan.  Akibatnya, metrik yang berguna akan muncul yang berbicara tentang layanan dan secara transparan menunjukkan semua yang terjadi pada mereka. <br><br><blockquote>  Kesalahan harus mengandung konteks kesalahan itu sendiri. </blockquote><br>  Ini akan membantu mengatasinya dan segera memperbaikinya.  <b>Kesalahan dan degradasi harus mengarah ke tindakan</b> , sehingga pengembang langsung belajar tentang masalah dan memperbaikinya bahkan sebelum permintaan pengguna marah. <br><br>  <b>Alat yang tepat akan membuat bekerja dengan layanan Anda lebih menyenangkan dan transparan</b> .  Debug memiliki tempat untuk menjadi, tetapi Anda harus tegas dengan itu. <br><br><blockquote>  Di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++ 2019</a> pada bulan November akan ada bagian DevOps - 13 laporan tentang muatan di AWS, sistem pemantauan di Lamoda, konveyor untuk pengiriman model, kehidupan tanpa Kubernetes, dan banyak lagi.  Lihat daftar lengkap topik dan abstrak di halaman terpisah " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Laporan</a> ".  Dan kami akan bertemu di DevOpsConf di musim semi - daftar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">untuk buletin</a> , beri tahu kami kapan kami menentukan tanggal dan lokasi. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id468535/">https://habr.com/ru/post/id468535/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id468525/index.html">Mainan kayu, bagian satu - 1982-1985</a></li>
<li><a href="../id468527/index.html">Sintesis pengontrol dengan metode masalah dinamika terbalik</a></li>
<li><a href="../id468529/index.html">Menjinakkan Gorynych, atau Mengompilasi eBPF di Ghidra</a></li>
<li><a href="../id468531/index.html">Bot PHP pertama untuk VKontakte</a></li>
<li><a href="../id468533/index.html">Menumpang di DevOps dengan Express 42</a></li>
<li><a href="../id468537/index.html">Dasar-dasar DevOps. Masuk ke proyek dari awal</a></li>
<li><a href="../id468541/index.html">Seret - & - Jatuhkan komponen untuk pengguna tunanetra? Apakah kamu bercanda?</a></li>
<li><a href="../id468543/index.html">FrontendConf Komite Program Hari Kerja. Wawancara dengan Sergey Popov</a></li>
<li><a href="../id468545/index.html">"Alice, ayo pergi ke frontend!"</a></li>
<li><a href="../id468547/index.html">Berbicara Bahasa Inggris, CSS, Kisi dan Aksesibilitas di FrontendConf</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
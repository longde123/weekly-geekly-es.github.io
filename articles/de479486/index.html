<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüîß ‚¨õÔ∏è üßëüèø‚Äçü§ù‚Äçüßëüèø Heterogene Programmierung und oneAPI Toolkit. Der improvisierte Vortrag von Intel-Experten beantwortet Ihre Fragen ‚ò∏Ô∏è ü§æüèø ü¶Ç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im Rahmen der Kolumne "Eine Frage an einen Intel-Experten stellen" haben wir den f√ºhrenden Intel-Spezialisten Konstantin Vladimirov gebeten, Fragen zu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Heterogene Programmierung und oneAPI Toolkit. Der improvisierte Vortrag von Intel-Experten beantwortet Ihre Fragen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/479486/"><img src="https://habrastorage.org/webt/tz/b5/gv/tzb5gvt-1m1z3yvd4tjzot84ao4.jpeg"><br><br>  Im Rahmen der Kolumne "Eine Frage an einen Intel-Experten stellen" haben wir den f√ºhrenden Intel-Spezialisten Konstantin Vladimirov gebeten, Fragen zu heterogener Programmierung, dem <a href="https//software.intel.com/en-us/oneapi">oneAPI-Toolkit</a> und √§hnlichen interessanten Dingen zu beantworten.  Das Ergebnis hat alle unsere Erwartungen √ºbertroffen.  Konstantin hatte keine freie Zeit und gab detaillierte und fundierte Antworten, ohne Polemik zu bef√ºrchten.  Tats√§chlich haben wir einen kleinen Vortrag √ºber die Architektur√ºbergreifende Programmierung in all ihren Formen gehalten: Nuancen, Optimierungen, Standards und so weiter auslagern. <br>  Wir √ºbergeben das Mikrofon dem Fachmann.  Nun, die Kommentare werden dem Publikum gegeben. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Frage <a href="https://habr.com/ru/users/soarex16/" class="user_link">Soarex16</a> <br><blockquote>  Wie m√ºhsam wird der √úbergang von OpenCL zu oneAPI sein und welche Vorteile lassen sich daraus ziehen? </blockquote><br>  <b>Die antwort.</b>  Der Wechsel zu DPC ++ kann schwierig sein, aber meiner Meinung nach lohnt es sich.  Es gibt zwei Hauptstufen. <br><br>  Erstens ist dies ein √úbergang von Ihrer heterogenen Programmiersprache (OpenCL, Vulkan Compute), die h√∂chstwahrscheinlich auf der API basiert.  Hier haben Sie einen Vorsprung, da Sie den Themenbereich bereits kennen und die Schwierigkeit darin besteht, das Denken von der direkten Steuerung √ºber die API auf etwas implizitere Sprachkonstrukte umzustellen. <br>  Zweitens ist dies ein √úbergang von Ihrer Gastsprache.  Wenn Sie Ihr ganzes Leben von reinem C abgeladen haben, entspricht der Eingabeschwellenwert dem Schwellenwert f√ºr den Wechsel von C zu C ++, der ziemlich hoch ist. <br><br>  Warum versuchen? <br><br>  Erstens leistet DPC ++ einen gro√üartigen Job f√ºr einen Programmierer.  Sie werden sehr schnell vergessen, wie ein Albtraum, all diese expliziten Aufrufe von clXXXYYY, und was das sechste Argument bedeutet, und ob Sie den R√ºckkehrcode vergessen haben.  Viele objektorientierte Wrapper verstecken die Routine nicht schlechter, aber normalerweise auf Kosten der Umstellung von der Standard-OpenCL-API auf die nicht so Standard-Wrapper-API (ich habe diese Bikes auch gesehen).  Im Falle von DPC ++ schreiben Sie einfach die Standard-SYCL mit Intel-Erweiterungen (die m√∂glicherweise bald auch zur Standard-SYCL werden). <br><br>  Zweitens sorgt DPC ++ f√ºr eine gemeinsame Kompilierung, dh Sie k√∂nnen sicher sein, welche Typen es gibt, und Sie haben keine Probleme an den Grenzen der API mit Bema√üungen, Abst√§nden und Ausrichtungen.  Sie schreiben den Kernel- und Host-Code in eine Datei, und dies ist derselbe Code.  Mit USM k√∂nnen Sie auch viel einfacher mit komplexen Datenstrukturen arbeiten. <br><br>  Drittens ist DPC ++ echtes C ++, das hei√üt, es erm√∂glicht eine verallgemeinerte Programmierung.  Zum Beispiel der einfachste Kernel zum Hinzuf√ºgen von zwei Vektoren: <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> kern = [A, B, C](cl::sycl::id&lt;<span class="hljs-number"><span class="hljs-number">1</span></span>&gt; wiID) { C[wiID] = A[wiID] + B[wiID]; <span class="hljs-comment"><span class="hljs-comment">//   A, B  C?  ! };</span></span></code> </pre> <br>  Dasselbe auf OpenCL: <br><br><pre> <code class="cpp hljs">_<span class="hljs-function"><span class="hljs-function">kernel </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vector_add</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(__global </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *A, __global </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *B, __global </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *C)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = get_global_id(<span class="hljs-number"><span class="hljs-number">0</span></span>); C[i] = A[i] + B[i]; }</code> </pre> <br>  Sie sehen, ich war gezwungen, auf einen OpenCL-Typ int zu zeigen.  Wenn ich einen Float ben√∂tige, muss ich entweder einen anderen Kernel schreiben oder einen Pr√§prozessor oder eine externe Codegenerierung verwenden.  Es kann ein wenig be√§ngstigend sein, fast alle Funktionen von C ++ zur Verf√ºgung zu haben, wenn Sie noch keine Erfahrung mit C ++ haben.  Dies ist jedoch eine h√§ufige Angelegenheit, wenn es um einen gro√üen technologischen Wandel geht. <br><br>  Und alle Vorteile sind nicht darauf beschr√§nkt.  Ich werde in den folgenden Antworten etwas anderes erw√§hnen. <br><br>  Daher h√§tte ich den Compiler an Ihrer Stelle heruntergeladen und ausprobiert, da dies mit dem <a href="https://software.intel.com/en-us/oneapi">OneAPI-</a> Paket nicht schwierig ist. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Frage <a href="https://habr.com/ru/users/juster/" class="user_link">Juster</a> <br><blockquote>  Werden OpenVINO und oneAPI in irgendeiner Weise zusammenh√§ngen? </blockquote><br>  <b>Die antwort.</b>  Die OpenVINO-Distribution ist jetzt Teil der OneAPI-Distribution.  Das Erlernen und Verwenden neuronaler Netze ist eine rechenintensive Aufgabe, die stark von heterogener Programmierung profitiert.  Ich glaube, dass alle OneAPI-Komponenten es fr√ºher oder sp√§ter erm√∂glichen werden, alle verf√ºgbaren Rechenressourcen zu nutzen: sowohl Grafikbeschleuniger als auch Spezialbeschleuniger wie Nervana und FPGA.  Und das alles, ohne das Sprachparadigma und Typensystem Ihres C ++ - Programms zu verlassen. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Fragen aus der Mail <br><blockquote>  Ich versuche zu verstehen, wie AI Hardware Accelerator in 3 Jahren aussehen wird. Bitte helfen Sie dabei.  Es gibt ein interessantes Unternehmen Graphcore und seine IPU - dieses Ger√§t ist nicht weniger effizient als FPGA, aber es ist viel einfacher zu programmieren - Python mit Unterst√ºtzung f√ºr TensorFlow und andere Frameworks.  Es stellt sich heraus, dass bei Erf√ºllung der Versprechen von Graphcore keine FPGAs auf dem Markt f√ºr maschinelles Lernen erforderlich sind.  Python ist f√ºr Datenwissenschaftler viel praktischer als C ++. <br>  Stimmen Sie zu, dass FPGA im Vergleich zu programmierbaren Python-L√∂sungen nicht f√ºr den Markt f√ºr maschinelles Lernen geeignet ist?  Welche anderen weit verbreiteten FPGA-Anwendungen sehen Sie, wenn der ML-Markt verloren geht? <br>  In welchen Anwendungen sehen Sie den unvermeidlichen Bedarf an heterogener Programmierung, wo Sie mit bequemeren Tools wie Python nicht auskommen k√∂nnen? </blockquote><br>  <b>Die antwort.</b>  Ich warf einen kurzen Blick auf die Art der IPU.  Noch ein St√ºck Eisen, auf das sich jeder entladen wird.  Diese Typen konkurrieren mit der GPU und mit speziellen Beschleunigern und nicht mit dem FPGA. <br><br>  Bei Aufgaben, f√ºr die ein spezielles Hardwareteil eingesperrt ist, schl√§gt es immer das FPGA, z. B. ist das Rendern von Videos auf einer Grafikkarte usw. besser.  Aber in der Welt (einschlie√ülich der ML-Welt) gibt es viele Aufgaben, f√ºr die nichts Besonderes erfunden oder ver√∂ffentlicht wurde, und hier wird FPGA immer unverzichtbar sein.  Zum Beispiel, weil es um den Preis geht und um billig zu sein, muss eine spezialisierte Hardware massiv sein. <br><br>  Angenommen, die angegebene IPU ist wirklich cool.  Dies wird die heterogene Programmierung nicht aufheben, im Gegenteil, das Vorhandensein eines solch hervorragenden Beschleunigers wird sie befl√ºgeln.  Und es wird OneAPI und DPC ++ einen Riesenvorsprung verschaffen, denn fr√ºher oder sp√§ter wird jemand sagen: "Ich m√∂chte sowohl Ihre IPU als auch meine GPU von einem Programm aus verwenden."  Eher fr√ºh, weil es um heterogene Programmierung geht.  Ihre Bedeutung ist die Verlagerung einer geeigneten Aufgabe auf ein geeignetes Ger√§t.  Eine Aufgabe kann von √ºberall kommen.  Und dieses Ger√§t kann alles sein, es kann sogar dasselbe Ger√§t sein, auf dem das Programm ausgef√ºhrt wird.  Wenn Sie beispielsweise den in ISPC geschriebenen Kernel auslagern und die Vektorfunktionen von Xeon maximal nutzen, k√∂nnen Sie ihn selbst auslagern und dennoch einen erheblichen Gewinn erzielen.  Das Hauptkriterium hierbei ist die Leistung.  Nun, es wird nie zu viel Produktivit√§t auf dieser Welt geben.  Selbst mit den besten Beschleunigern der Welt. <br><br>  Was Python und seine Bequemlichkeit angeht ... Ich muss sofort zugeben, dass ich dynamisch getippte Sprachen nicht mag: Sie sind langsam und statt eines normalen Kompilierungsfehlers m√ºssen Sie zwei Stunden warten, bevor Sie aufgrund des falschen Typs in die Laufzeit wechseln.  Ich verstehe aber nicht, wie schlimm es ist, dieselben Auslagerungen unter Python durchzuf√ºhren.  In OneAPI ist √ºbrigens bereits Intel Distribution f√ºr Python enthalten, was f√ºr verschiedene Testberichte √§u√üerst praktisch ist. <br><br>  Das hei√üt, in der Traumwelt der Python-Liebhaber schreiben Sie ein Programm darauf und entladen es auf alle Beschleuniger, die Sie mit OneAPI finden k√∂nnen, und nicht auf eine Reihe von herstellerspezifischen Bibliotheken.  Eine andere Sache ist, dass Sie bei diesem Ansatz die End-to-End-Eingabe verpassen und in die √§u√üerst prek√§re Welt der API-basierten Programmierung zur√ºckkehren.  Vielleicht wird die Entwicklung von DPC ++ die Community ermutigen, aktiver geeignete Tools wie C ++ zu verwenden. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Frage aus der Mail <br><blockquote>  Performance versus OpenCL.  Luxus muss besteuert werden - d. H.  Gemeinkosten.  Gibt es irgendwelche Ma√üe? </blockquote><br>  <b>Die antwort.</b>  Im Internet finden Sie viele Messungen mit unterschiedlichen Ergebnissen, abh√§ngig vom Compiler, der Aufgabe und der Qualit√§t der Implementierung.  Als pers√∂nliche Recherche habe ich an einfachen Aufgaben (SGEMM, DGEMM) auf meinem Laptop (integrierte Skylake-Grafik) gemessen und festgestellt, dass es bis jetzt einen gewissen R√ºckgang gibt (innerhalb von Prozent).  Aber es scheint mir, dass dies eine Folge der Tatsache ist, dass dies alles bisher Beta ist. <br><br>  Theoretisch sollte das Ergebnis Beschleunigung sein, nicht Verlangsamung, dh im Prinzip sollte all dieser Luxus einen negativen Wert haben.  Alles dreht sich um den Compiler.  Wenn Ihr Programm aus einer einzigen Quelle besteht und als einzelnes Programm verarbeitet wird, bietet der Compiler fantastische, unglaubliche Optimierungsm√∂glichkeiten: Erstellen von allgemeinen Codes, Umkehren von Schleifen, Neuanordnen von Codeabschnitten und alles andere, was der Compiler im API-basierten Ansatz einfach nicht kann fr√ºher oder sp√§ter wird sie definitiv mit einem einzigen Quellmodell lernen. <br><br>  Dar√ºber hinaus wird DPC ++ negative Kosten in Bezug auf die Entwicklungszeit verursachen.  Ein einfaches Beispiel sind SYCL-Accessoren, mit denen der Compiler bereits Ereignisse anordnet und asynchrone Warteschlangen verwaltet. <br><br><pre> <code class="cpp hljs">deviceQueue.submit([&amp;](cl::sycl::handler &amp;cgh) { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> A = bufferA.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_read&gt;(cgh); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> B = bufferB.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_read&gt;(cgh); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> C = bufferC.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_write&gt;(cgh); .... deviceQueue.submit([&amp;](cl::sycl::handler &amp;cgh) { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> A = bufferA.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_read&gt;(cgh); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> B = bufferB.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_read&gt;(cgh); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> D = bufferD.<span class="hljs-keyword"><span class="hljs-keyword">template</span></span> get_access&lt;sycl_write&gt;(cgh);</code> </pre><br>  Hier sieht der Compiler, dass beide Pakete nur A und B lesen und unabh√§ngige Puffer C und D schreiben. Infolgedessen sieht er die M√∂glichkeit, sie parallel zu senden, wenn es gen√ºgend globale Gr√∂√üen gibt. <br><br>  Nat√ºrlich kann ein pedantisch geschriebenes OpenCL-Programm dies genauso gut, aber die Entwicklungszeit, die mit einem nicht trivialen Kernel verbracht wird, ist nicht vergleichbar. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Frage aus der Mail <br><blockquote>  Sind alle M√∂glichkeiten zur Optimierung von OpenCL-Anwendungen f√ºr DPC ++ relevant?  Was ist neu, um sie hinzuzuf√ºgen? </blockquote><br>  <b>Die antwort.</b>  Ich w√ºrde sagen, dass die meisten der subtilen manuellen Optimierungen, die von Kernel-Autoren durchgef√ºhrt werden, vom Compiler vorgenommen werden k√∂nnen und sollten.  Auf die gleiche Weise halte ich es beispielsweise f√ºr sch√§dlich, einen Inline-Assembler manuell in C ++ - Programmen zu installieren, da er, selbst wenn er taktische Vorteile bietet, Optimierungen beeintr√§chtigt und sich negativ auf die Entwicklung und den Transfer eines Produkts auswirkt.  Nun, OpenCL ist jetzt auch Assembler. <br><br>  Was die detailliertere Antwort betrifft, habe ich Angst vor dem Abgrund hier.  Beispielsweise gibt es ein bekanntes Intel-Dokument "OpenCL Developer Guide for Intel Processor Graphics".  Und es gibt einen <a href="https://software.intel.com/en-us/iocl-opg-avoiding-needless-synchronization">Abschnitt</a> dar√ºber, wie man es versucht, um die √ºbersch√ºssige Synchronisation nicht dort abzulegen. <br><br>  Aus meiner Sicht ist dies also im Prinzip eine nichtmenschliche Aufgabe.  Die Leute sind extrem schlecht darin, √ºber Multithread-Synchronisation nachzudenken, und tendieren dazu, Synchronisation entweder konservativ oder falsch oder beides auf einmal zu formen - ich habe solche Kommas gesetzt ( <i>aber wir haben es behoben - Anmerkung der Redaktion</i> ). <br><br>  Auf der anderen Seite schreiben Sie in DPC ++ keinen Code mit expliziten Barrieren wie folgt: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (t = <span class="hljs-number"><span class="hljs-number">0</span></span>; t &lt; numTiles; t++) { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tiledRow = TS * t + row; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> tiledCol = TS * t + col; Asub[col][row] = A[globalRow * AY + tiledCol]; Bsub[col][row] = B[tiledRow * BY + globalCol]; <span class="hljs-comment"><span class="hljs-comment">// Synchronise to make sure the tile is loaded barrier(CLK_LOCAL_MEM_FENCE); // .... etc ....</span></span></code> </pre> <br>  Sie werden h√∂chstwahrscheinlich eine explizite Iteration von <i>parallel_for_work_group</i> schreiben, innerhalb der <i>group.parallel_for_work_item</i> <br><br><pre> <code class="cpp hljs">cgh.parallel_for_work_group&lt;<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">mxm_kernel</span></span></span><span class="hljs-class">&gt;( </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">cl</span></span></span><span class="hljs-class">:</span></span>:sycl::range&lt;<span class="hljs-number"><span class="hljs-number">2</span></span>&gt;{BIG_AX / TS, BIG_BY / TS}, cl::sycl::range&lt;<span class="hljs-number"><span class="hljs-number">2</span></span>&gt;{TS, TS}, [=](cl::sycl::group&lt;<span class="hljs-number"><span class="hljs-number">2</span></span>&gt; group) { <span class="hljs-comment"><span class="hljs-comment">// .... etc .... for (int t = 0; t &lt; numTiles; t++) { group.parallel_for_work_item([&amp;](cl::sycl::h_item&lt;2&gt; it) { // .... etc .... Asub[col][row] = A[globalRow][tiledCol]; Bsub[col][row] = B[tiledRow][globalCol]; }); //      ,   </span></span></code> </pre> <br>  Infolgedessen m√ºssen Sie die Synchronisation √ºberhaupt nicht manuell einstellen, und der gesamte Abschnitt kann weggeworfen werden. <br><br>  Und so k√∂nnen Sie in allen Abschnitten laufen.  Etwas wird √ºberleben, etwas wird gehen.  Ich sehe das Erscheinen eines neuen Dokuments ‚ÄûOptimierung f√ºr DPC ++‚Äú voraus, aber die Zeit sollte vergehen, da alle wirklich funktionierenden Techniken erst sp√§ter und mit Blut entwickelt werden <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Frage aus der Mail <br><blockquote>  In OpenCL gibt es eine Einschr√§nkung: Sie k√∂nnen keine "entfernten Daten" im Kernel verwenden, dh Sie implementieren beispielsweise einen "breiten Filter", der Eingabedaten aus einer gro√üen Gruppe von Pixeln verwendet, die gr√∂√üer sind als die OpenCL-Arbeitsgruppe in einer Berechnung.  Was bietet DPC ++ in dieser Hinsicht? </blockquote><br>  <b>Die antwort.</b>  Das ist unm√∂glich.  Nat√ºrlich schreibe ich keine besonderen Kernel ... Aber es ist absolut sicher, dass Sie den gesamten globalen Speicher so nutzen k√∂nnen, wie er ist. Sie m√ºssen nur sicherstellen, dass Sie mit atomaren Operationen arbeiten (oder hierarchische Kernel extern synchronisieren).  Sie k√∂nnen auch System-SVM (oder USM in DPC ++) anschlie√üen. <br><br>  Leider ist das alles extrem ineffizient, und ich mag all diese Tricks nicht.  Au√üerdem sind sie vom Compiler nur schwer zu optimieren. <br><br>  Wenn wir also von direkten und effektiven L√∂sungen sprechen, gibt es in DPC ++ nat√ºrlich keine Magie.  Ihr Programm ist am Ende immer noch in Teile geteilt: Der Hostcode und der Ger√§tecode, und alle Ger√§teeinschr√§nkungen wirken sich auf den Ger√§tecode aus.  Die maximale Gr√∂√üe der Arbeitsgruppe ist die tats√§chliche Parallelit√§t, zu der Ihre Hardware f√§hig ist.  Alles, was noch dazu kommt, sind Wege, um herauszukommen und die Leistung dramatisch zu beeintr√§chtigen.  Aus diesem Grund bietet DPC ++ die M√∂glichkeit, dies zu tun: <i>device.get_info &lt;sycl :: info :: device :: max_work_group_size&gt; ()</i> und dann zu entscheiden, wie mit der resultierenden Zahl <i>umgegangen werden soll</i> . <br><br>  Es w√§re nat√ºrlich verlockend, ein Modell in DPC ++ zu erstellen, wenn der Programmierer mit beliebig langen Schleifen arbeitet und der Compiler √ºberlegt, was als n√§chstes zu tun ist, aber es w√§re t√∂dlich, weil es Konstanten und sogar Asymptoten mit zus√§tzlicher Komplexit√§t verbergen w√ºrde Computer tauchen aus dem Nichts auf.  Aus einem anderen Grund schrieb Alexandrescu, dass ‚ÄûKomplexit√§t als Verbrechen betrachtet werden sollte‚Äú, und dies gilt auch. <br><br>  Manchmal hilft es, den Algorithmus selbst zu √ºberarbeiten.  Hier erleichtert DPC ++ die Arbeit, da strukturierter Code einfacher umzugestalten ist.  Aber das ist so ein Trost. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Frage aus der Mail <br><blockquote>  DPC ++ basiert auf SYCL.  Aber was ist, wenn Sie tiefer unter die Haube gehen, was sind die Unterschiede zu OpenCL bei der Implementierung des Backends, falls vorhanden?  Ist beispielsweise der Verteilungsmechanismus zwischen heterogenen Ger√§ten der gleiche wie bei OpenCL? </blockquote><br>  <b>Die antwort.</b>  Wenn Sie unter die Haube kommen, dann ist dies OpenCL.  Alle Vorteile und St√§rken von SYCL sind die Vorteile und St√§rken der Sprache, dh des Frontends.  Vom Frontend kommt die gute alte SPIRV, die zum Backend geht und dort bereits f√ºr eine bestimmte Grafikkarte optimiert ist (oft bereits zur Laufzeit, d. H. Es ist JIT), genau wie OpenCL daf√ºr optimiert w√§re. <br><br>  Eine andere Sache ist, dass der Mechanismus f√ºr die Verteilung der Arbeit zwischen heterogenen Ger√§ten mehr Front-End als Back-End ist, da es der Host-Code ist, der entscheidet, was gesendet wird und wohin.  Der Hostcode wird von DPC ++ bezogen.  Ich habe bereits ein etwas h√∂heres Beispiel gezeigt, wie der Compiler auf der Basis von Accessoren eine Entscheidung √ºber die Parallelisierung von Paketen treffen kann.  Und das ist nur die Spitze des Eisbergs. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Frage aus der Mail <br><blockquote>  Bibliotheken  Ja, wir sprechen nicht √ºber CUDA.  Wir wissen jedoch, dass es f√ºr CUDA-Entwickler sehr n√ºtzliche Bibliotheken gibt, die auf der GPU mit hoher Leistung arbeiten.  OneAPI enth√§lt auch einige Bibliotheken, aber zum Beispiel <a href="https://software.intel.com/en-us/ipp">IPP</a> - f√ºr die Arbeit mit Bildern in oneAPI / OpenCL ist keine Archivierung sinnvoll.  Wird es etwas geben und wie kann in diesem Fall von CUDA auf oneAPI gewechselt werden? </blockquote><br>  <b>Die antwort.</b>  Der √úbergang von CUDA zu einem einzigen offenen Standard wird schwierig, aber unvermeidlich sein.  Nat√ºrlich verf√ºgt CUDA jetzt √ºber eine ausgereiftere Infrastruktur.  Die Eigenschaften der Lizenzierung sind jedoch ein Nachteil, da immer mehr Akteure auf dem Markt f√ºr heterogene Systeme, immer interessantere Karten und Beschleuniger verschiedener Hersteller auftreten. <br><br>  Die Vielfalt der vorhandenen APIs erschwert es Programmierern mit Erfahrung in der klassischen CPU, diese Welt der M√∂glichkeiten zu nutzen.  Was zu OneAPI oder so √§hnlich f√ºhrt.  Hier liegt die Magie nicht im Durchbruch von Intel in der Grafik, sondern in der Tatsache, dass Intel jedem die T√ºr zu DPC ++ √∂ffnet.  Wir besitzen nicht einmal den SYCL-Standard, er geh√∂rt zur Khronos-Gruppe, und alle Intel-Erweiterungen sind Erweiterungen in Khronos, f√ºr die sich jeder engagieren kann (und es gibt Vertreter aller wichtigen Akteure).  Und das bedeutet, dass (Bibliotheken) und Community angezeigt werden (bereits angezeigt werden) und eine Reihe von Stellen in diese Richtung. <br><br>  Und nat√ºrlich wird IPP f√ºr neue Realit√§ten umgeschrieben.  Ich habe nichts mit IPP zu tun, aber die Verwendung von DPC ++ ist gesunder Menschenverstand. <br><br>  Aber was noch wichtiger ist, jetzt ist genau der Moment in der Geschichte, in dem Sie Ihre eigene Bibliothek schreiben k√∂nnen, die IPP √ºbertrifft und die dann von der ganzen Welt verwendet wird.  Weil offene Standards immer gewinnen. <br><br><img src="https://habrastorage.org/webt/pb/_f/jj/pb_fjj71wjkak3kyklvojjcao5w.png" alt="Bild">  Frage aus der Mail <br><blockquote>  Wenn wir den Start von Trainings- und Inferenz-Algorithmen f√ºr neuronale Netze auf Nervana und FPGA vergleichen, welche Unterschiede bestehen in der Programmierung und der daraus resultierenden Effizienz? </blockquote><br>  <b>Die antwort.</b>  Ich wei√ü nichts √ºber FPGA-Programmierdetails, ich schreibe Compiler.  Aber ich habe eine Gegenfrage.  Und wie werden wir vergleichen?  Bei Standard-Benchmarks ist es unsportlich, Nervana leckte darunter.  Aber wenn Sie etwas Interessantes haben, wird das FPGA Ihre H√§nde l√∂sen, und wenn Sie Nervana dieses Etwas geben, kann das langwierig und teuer sein, das ist alles. <br><br>  Es stellt sich heraus, dass die Frage selbst sozusagen aus der Serie ‚ÄûWer ist st√§rker als ein Elefant oder ein Wal?‚Äú Stammt.  Dies ist jedoch keine wirkliche Frage.  Die eigentliche Frage lautet: Wie kann man einen Elefanten und einen Wal in einem Wagen fangen?  Nun, oder zumindest verteilen, sagen wir, dass ein Elefant ihn an Land zieht und ein Wal auf dem Seeweg. <br><br>  Im Fall von OneAPI haben Sie im Allgemeinen dasselbe Programm in Standard-C ++.  Und Sie k√∂nnen es selbst schreiben und mit hin und her auslagern.  Dies ist genau die Aufgabe, die Sie interessiert, an der Sie selbst die Leistung messen und optimieren k√∂nnen.  Ein einziger Standard und eine einzige Schnittstelle zu heterogenen Ger√§ten sind ein Schritt zum Vergleich von √Ñpfeln mit √Ñpfeln in solchen Angelegenheiten. <br><br>  Zum Beispiel: "Was ist f√ºr% meiner Aufgabe% im Hinblick auf einfache Programmierung und Effizienz besser? Setzen Sie diesen Teil auf FPGA, belassen Sie diesen auf Nervana oder teilen Sie diesen Teil in zwei Teile und schreiben Sie diesen Teil f√ºr die GPU neu." <br><br>  Und die ganze Geschichte mit OneAPI - Sie m√ºssen nur sagen: "Warum lange dar√ºber nachdenken, ich werde es jetzt schnell versuchen, ES IST EINFACH." <br><br>  Noch nicht so einfach.  Aber es wird geben. <br><br><hr><br>  <b>Nachwort vom Experten</b> <br><br>  Vielen Dank f√ºr Ihre Fragen.  Es ist m√∂glich und sogar wahrscheinlich, dass ich falsch, ungenau und fehlerhaft lag.  Es passiert, im Internet irrt sich st√§ndig jemand. <br><br>  Ich hoffe, dass ich jemanden f√ºr heterogene Programmierung und DPC ++ interessieren konnte.  Ich m√∂chte allen die Seite <a href="https://sycl.tech/">sycl.tech</a> empfehlen, auf der <a href="https://sycl.tech/">jede Menge</a> Berichte liegen, auch von weltbekannten Experten (Englisch ist erforderlich). <br><br>  Gut zu allen! <br><br>  <i>PS vom Verlag.</i>  <i>Diesmal wurde durch einstimmige Entscheidung der Redaktion beschlossen, den Preis f√ºr die beste Frage ... an den Autor der Antworten zu vergeben.</i>  <i>Ich denke, Sie werden zustimmen, dass dies fair ist.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479486/">https://habr.com/ru/post/de479486/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479468/index.html">Edge of Honesty und John Doe</a></li>
<li><a href="../de479474/index.html">Warum ist die Selbstorganisation von Teams in Scrum so wichtig und warum kann es keine Manager geben?</a></li>
<li><a href="../de479478/index.html">Java-Plug-In ohne Schmerzen</a></li>
<li><a href="../de479480/index.html">SARIF SDK und seine Fehler</a></li>
<li><a href="../de479482/index.html">SARIF SDK und seine Fehler</a></li>
<li><a href="../de479488/index.html">Von einem Laptop - ein Heimserver mit redundanter Stromversorgung f√ºr den Mikrotik-Router</a></li>
<li><a href="../de479492/index.html">Serverloses Rechnen basierend auf OpenWhisk, Teil 3</a></li>
<li><a href="../de479496/index.html">Analysieren von WTF-Aufgaben in JavaScript</a></li>
<li><a href="../de479498/index.html">Wie aus linearer Zeit Windows in O (n¬≤) wird</a></li>
<li><a href="../de479502/index.html">Wie √ºberlebt man die schwerste Eiszeit der Erdgeschichte?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéê üè∏ üç© Mengajar dan menguji jaringan saraf pada PyTorch menggunakan Ignite üëÖ ü•ü ‚ôèÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hai, Habr, dalam artikel ini saya akan berbicara tentang perpustakaan menyalakan , dengan mana Anda dapat dengan mudah melatih dan menguji jaringan sa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mengajar dan menguji jaringan saraf pada PyTorch menggunakan Ignite</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/424781/"><p>  <em>Hai, Habr, dalam artikel ini saya akan berbicara tentang perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menyalakan</a> , dengan mana Anda dapat dengan mudah melatih dan menguji jaringan saraf menggunakan kerangka kerja PyTorch.</em> </p><br><p> Dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">penyalaan,</a> Anda dapat menulis siklus untuk melatih jaringan hanya dalam beberapa baris, menambahkan perhitungan metrik standar dari kotak, menyimpan model, dll.  Nah, bagi mereka yang telah pindah dari TF ke PyTorch, kita dapat mengatakan bahwa perpustakaan yang <em>menyala</em> adalah Keras untuk PyTorch. </p><br><p>  Artikel ini akan <em>memeriksa</em> secara rinci contoh pelatihan jaringan saraf untuk tugas klasifikasi menggunakan <em>ignite.</em> </p><br><p><img src="https://habrastorage.org/webt/35/ar/af/35arafc8y9aicrbpz5unazs-y-a.png"></p><a name="habracut"></a><br><h2 id="dobavim-esche-bolshe-ognya-v-pytorch">  Tambahkan lebih banyak api ke PyTorch </h2><br><p>  Saya tidak akan membuang waktu berbicara tentang betapa <em>kerennya</em> kerangka PyTorch.  Siapa pun yang telah menggunakannya memahami apa yang saya tulis.  Tetapi, dengan semua kelebihannya, masih rendah dalam hal siklus penulisan untuk pelatihan, pengujian, pengujian jaringan saraf. </p><br><p>  Jika kita melihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">contoh resmi</a> menggunakan kerangka PyTorch, kita akan melihat setidaknya dua siklus iterasi oleh zaman dan oleh batch pelatihan yang diatur dalam kode pelatihan grid: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, epochs + <span class="hljs-number"><span class="hljs-number">1</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> batch_idx, (data, target) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(train_loader): <span class="hljs-comment"><span class="hljs-comment"># ...</span></span></code> </pre> <br><p>  Gagasan utama dari perpustakaan yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menyala</a> adalah untuk memfaktorkan loop ini ke dalam satu kelas, sementara memungkinkan pengguna untuk berinteraksi dengan loop ini menggunakan event handler. </p><br><p>  Akibatnya, dalam kasus tugas pembelajaran dalam standar, kita dapat menyimpan banyak pada jumlah baris kode.  Lebih sedikit baris - lebih sedikit kesalahan! </p><br><p>  Misalnya, untuk perbandingan, di sebelah kiri adalah kode untuk pelatihan dan validasi model menggunakan <em>ignite</em> , dan di sebelah kanan adalah PyTorch murni: <br><img src="https://habrastorage.org/getpro/habr/post_images/914/408/b07/914408b07fa093c696e66cb15ae36bfc.png" alt="gambar"></p><br><p>  Jadi sekali lagi, untuk apa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menyalakan api</a> ? </p><br><ul><li>  Anda tidak perlu lagi menulis untuk setiap loop tugas <code>for epoch in range(n_epochs)</code> dan <code>for batch in data_loader</code> . </li><li>  memungkinkan Anda membuat kode faktorisasi yang lebih baik </li><li>  memungkinkan Anda menghitung metrik dasar di luar kotak </li><li>  menyediakan "roti" seperti <br><ul><li>  menyimpan model terbaru dan terbaik (juga pengoptimal dan penjadwal tingkat pembelajaran) selama pelatihan, </li><li>  berhenti belajar awal </li><li>  dll. </li></ul></li><li>  mudah diintegrasikan dengan alat visualisasi: tensorboardX, visdom, ... </li></ul><br><p>  Dalam arti, seperti yang telah disebutkan, perpustakaan yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menyala</a> dapat dibandingkan dengan semua <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Keras</a> terkenal dan API-nya untuk pelatihan dan pengujian jaringan.  Juga, perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menyalakan</a> pada pandangan pertama sangat mirip dengan perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tnt</a> , karena pada awalnya kedua perpustakaan memiliki tujuan yang sama dan memiliki ide yang sama untuk implementasinya. </p><br><p>  Jadi, nyalakan: </p><br><pre> <code class="hljs sql">pip <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> pytorch-ignite</code> </pre> <br><p>  atau </p><br><pre> <code class="hljs swift">conda install ignite -<span class="hljs-built_in"><span class="hljs-built_in">c</span></span> pytorch</code> </pre> <br><p>  Selanjutnya, dengan contoh spesifik, kami akan membiasakan diri dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">API</a> pustaka <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">api</a> . </p><br><h2 id="zadacha-klassifikacii-s-ignitehttpspytorchorgignite">  Tugas klasifikasi dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menyalakan</a> </h2><br><p>  Pada bagian artikel ini, kami akan mempertimbangkan contoh <em>sekolah</em> melatih jaringan saraf untuk masalah klasifikasi menggunakan perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">nyala</a> . </p><br><p>  Jadi, mari kita ambil dataset sederhana dengan gambar buah-buahan dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kaggle</a> .  Tugasnya adalah untuk mengasosiasikan kelas yang sesuai dengan masing-masing gambar buah. </p><br><p>  Sebelum menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ignite</a> , mari kita tentukan komponen utama: </p><br><p>  Aliran data </p><br><ul><li>  melatih pemuat pengumpul sampel, <code>train_loader</code> </li><li>  checkout pengunduh batch, <code>val_loader</code> </li></ul><br><p>  Model: </p><br><ul><li>  ambil kotak squeezeNet kecil dari <code>torchvision</code> </li></ul><br><p>  Algoritma Optimasi: </p><br><ul><li>  ambil sgd </li></ul><br><p>  Fungsi kerugian: </p><br><ul><li>  Entropi silang </li></ul><br><div class="spoiler">  <b class="spoiler_title">Kode</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dataset, DataLoader <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data.dataset <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Subset <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageFolder <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Compose, RandomResizedCrop, RandomVerticalFlip, RandomHorizontalFlip <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ColorJitter, ToTensor, Normalize FRUIT360_PATH = Path(<span class="hljs-string"><span class="hljs-string">"."</span></span>).resolve().parent / <span class="hljs-string"><span class="hljs-string">"input"</span></span> / <span class="hljs-string"><span class="hljs-string">"fruits-360_dataset"</span></span> / <span class="hljs-string"><span class="hljs-string">"fruits-360"</span></span> device = <span class="hljs-string"><span class="hljs-string">"cuda"</span></span> train_transform = Compose([ RandomHorizontalFlip(), RandomResizedCrop(size=<span class="hljs-number"><span class="hljs-number">32</span></span>), ColorJitter(brightness=<span class="hljs-number"><span class="hljs-number">0.12</span></span>), ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>]) ]) val_transform = Compose([ RandomResizedCrop(size=<span class="hljs-number"><span class="hljs-number">32</span></span>), ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>]) ]) batch_size = <span class="hljs-number"><span class="hljs-number">128</span></span> num_workers = <span class="hljs-number"><span class="hljs-number">8</span></span> train_dataset = ImageFolder((FRUIT360_PATH /<span class="hljs-string"><span class="hljs-string">"Training"</span></span>).as_posix(), transform=train_transform, target_transform=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) val_dataset = ImageFolder((FRUIT360_PATH /<span class="hljs-string"><span class="hljs-string">"Test"</span></span>).as_posix(), transform=val_transform, target_transform=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device) val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.models.squeezenet <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> squeezenet1_1 model = squeezenet1_1(pretrained=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">81</span></span>) model.classifier[<span class="hljs-number"><span class="hljs-number">-1</span></span>] = nn.AdaptiveAvgPool2d(<span class="hljs-number"><span class="hljs-number">1</span></span>) model = model.to(device)</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.optim <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SGD optimizer = SGD(model.parameters(), lr=<span class="hljs-number"><span class="hljs-number">0.01</span></span>, momentum=<span class="hljs-number"><span class="hljs-number">0.5</span></span>) criterion = nn.CrossEntropyLoss()</code> </pre> </div></div><br><p>  Jadi sekarang saatnya untuk menjalankan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">penyalaan</a> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Engine, _prepare_batch <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.train() optimizer.zero_grad() x, y = _prepare_batch(batch, device=device) y_pred = model(x) loss = criterion(y_pred, y) loss.backward() optimizer.step() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> loss.item() trainer = Engine(process_function)</code> </pre> <br><p>  Mari kita lihat apa arti kode ini. </p><br><h3 id="dvizhok-engine">  Mesin <code>Engine</code> </h3><br><p>  Kelas <code>ignite.engine.Engine</code> adalah framework library, dan objek dari class ini adalah <code>trainer</code> : </p><br><pre> <code class="python hljs">trainer = Engine(process_function)</code> </pre> <br><p>  Ini didefinisikan dengan fungsi fungsi input proses untuk memproses satu batch dan berfungsi untuk menerapkan pass untuk sampel pelatihan.  Di dalam kelas <code>ignite.engine.Engine</code> , hal berikut terjadi: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> epoch &lt; max_epochs: <span class="hljs-comment"><span class="hljs-comment"># run once on data for batch in data: output = process_function(batch)</span></span></code> </pre> <br><p>  Kembali ke fungsi <code>process_function</code> : </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.train() optimizer.zero_grad() x, y = _prepare_batch(batch, device=device) y_pred = model(x) loss = criterion(y_pred, y) loss.backward() optimizer.step() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> loss.item()</code> </pre> <br><p>  Kita melihat bahwa di dalam fungsi kita, seperti biasa dalam hal pelatihan model, menghitung prediksi <code>y_pred</code> , menghitung fungsi <code>loss</code> , <code>loss</code> dan gradien.  Yang terakhir memungkinkan Anda untuk memperbarui bobot model: <code>optimizer.step()</code> . </p><br><p>  Secara umum, tidak ada batasan pada kode fungsi <code>process_function</code> .  Kami hanya mencatat bahwa dibutuhkan dua argumen sebagai input: objek <code>Engine</code> (dalam kasus kami, <code>trainer</code> ) dan kumpulan dari pemuat data.  Oleh karena itu, misalnya, untuk menguji jaringan saraf, kita dapat mendefinisikan objek lain dari kelas <code>ignite.engine.Engine</code> , di mana fungsi input hanya menghitung prediksi, dan mengimplementasikan lulus melalui sampel uji sekali.  Baca tentang itu nanti. </p><br><p>  Jadi, kode di atas hanya mendefinisikan objek yang diperlukan tanpa memulai pelatihan.  Pada dasarnya, dalam contoh minimal, Anda dapat memanggil metode: </p><br><pre> <code class="python hljs">trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>)</code> </pre> <br><p>  dan kode ini cukup untuk "diam-diam" (tanpa derivasi hasil antara) melatih model. </p><br><div class="spoiler">  <b class="spoiler_title">Sebuah catatan</b> <div class="spoiler_text"><p>  Perhatikan juga bahwa untuk tugas-tugas jenis ini perpustakaan memiliki metode yang mudah untuk membuat objek <code>trainer</code> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_supervised_trainer trainer = create_supervised_trainer(model, optimizer, criterion, device)</code> </pre> </div></div><br><p>  Tentu saja, dalam praktiknya, contoh di atas tidak terlalu menarik, jadi mari kita tambahkan opsi berikut untuk "pelatih": </p><br><ul><li>  tampilan nilai fungsi kerugian setiap 50 iterasi </li><li>  mulai perhitungan metrik pada set pelatihan dengan model tetap </li><li>  mulai perhitungan metrik pada sampel uji setelah setiap era </li><li>  menyimpan parameter model setelah setiap era </li><li>  pelestarian tiga model terbaik </li><li>  perubahan kecepatan belajar tergantung pada zaman (penjadwalan tingkat pembelajaran) </li><li>  pelatihan penghentian dini (early-stopping) </li></ul><br><h3 id="sobytiya-i-obrabotchiki-sobytiy">  Acara dan Penangan Acara </h3><br><p>  Untuk menambahkan opsi di atas untuk "pelatih", perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menyalakan</a> menyediakan sistem acara dan peluncuran penangan acara kustom.  Dengan demikian, pengguna dapat mengontrol objek kelas <code>Engine</code> pada setiap tahap: </p><br><ul><li>  mesin memulai / menyelesaikan peluncuran </li><li>  era dimulai / berakhir </li><li>  iterasi batch dimulai / berakhir </li></ul><br><p>  dan jalankan kode Anda di setiap acara. </p><br><h4 id="vyvod-na-ekran-znacheniya-funkcii-poter">  Menampilkan nilai fungsi kerugian </h4><br><p>  Untuk melakukan ini, cukup tentukan fungsi di mana output akan ditampilkan di layar, dan tambahkan ke "trainer": </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Events log_interval = <span class="hljs-number"><span class="hljs-number">50</span></span> @trainer.on(Events.ITERATION_COMPLETED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_training_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> iteration = (engine.state.iteration - <span class="hljs-number"><span class="hljs-number">1</span></span>) % len(train_loader) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> iteration % log_interval == <span class="hljs-number"><span class="hljs-number">0</span></span>: print(<span class="hljs-string"><span class="hljs-string">"Epoch[{}] Iteration[{}/{}] Loss: {:.4f}"</span></span> .format(engine.state.epoch, iteration, len(train_loader), engine.state.output))</code> </pre> <br><p>  Sebenarnya ada dua cara untuk menambahkan event handler: melalui <code>add_event_handler</code> , atau melalui dekorator <code>on</code> .  Hal yang sama seperti di atas dapat dilakukan seperti ini: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Events log_interval = <span class="hljs-number"><span class="hljs-number">50</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_training_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># ... trainer.add_event_handler(Events.ITERATION_COMPLETED, log_training_loss)</span></span></code> </pre> <br><p>  Perhatikan bahwa argumen apa pun dapat diteruskan ke fungsi penanganan acara.  Secara umum, fungsi seperti itu akan terlihat seperti ini: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">custom_handler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, *args, **kwargs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">pass</span></span> trainer.add_event_handler(Events.ITERATION_COMPLETED, custom_handler, *args, **kwargs) <span class="hljs-comment"><span class="hljs-comment">#  @trainer.on(Events.ITERATION_COMPLETED, *args, **kwargs) def custom_handler(engine, *args, **kwargs): pass</span></span></code> </pre> <br><p>  Jadi, mari kita mulai pelatihan di satu era dan lihat apa yang terjadi: </p><br><pre> <code class="python hljs">output = trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[50/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.3459</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[100/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.2801</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[150/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.2294</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[200/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 4<span class="hljs-selector-class"><span class="hljs-selector-class">.1467</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[250/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 3<span class="hljs-selector-class"><span class="hljs-selector-class">.8607</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Epoch</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[1]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Iteration</span></span><span class="hljs-selector-attr"><span class="hljs-selector-attr">[300/322]</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">Loss</span></span>: 3<span class="hljs-selector-class"><span class="hljs-selector-class">.6688</span></span></code> </pre> <br><p>  Tidak buruk!  Mari kita melangkah lebih jauh. </p><br><h4 id="zapusk-rascheta-metrik-na-obuchayuschey-i-testovoy-vyborkah">  Mulai perhitungan metrik pada pelatihan dan sampel uji </h4><br><p>  Mari kita hitung metrik berikut: akurasi rata-rata, kelengkapan rata-rata setelah setiap era pada bagian pelatihan dan seluruh sampel uji.  Perhatikan bahwa kami akan menghitung metrik pada bagian sampel pelatihan setelah setiap era pelatihan, dan bukan selama pelatihan.  Dengan demikian, pengukuran efisiensi akan lebih akurat karena model tidak berubah selama perhitungan. </p><br><p>  Jadi, kami mendefinisikan metrik: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Loss, CategoricalAccuracy, Precision, Recall metrics = { <span class="hljs-string"><span class="hljs-string">'avg_loss'</span></span>: Loss(criterion), <span class="hljs-string"><span class="hljs-string">'avg_accuracy'</span></span>: CategoricalAccuracy(), <span class="hljs-string"><span class="hljs-string">'avg_precision'</span></span>: Precision(average=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>), <span class="hljs-string"><span class="hljs-string">'avg_recall'</span></span>: Recall(average=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) }</code> </pre> <br><p>  Selanjutnya, kita akan membuat dua mesin untuk mengevaluasi model menggunakan <code>ignite.engine.create_supervised_evaluator</code> : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.engine <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_supervised_evaluator <span class="hljs-comment"><span class="hljs-comment"># ,  device = ‚Äúcuda‚Äù    train_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device) val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)</span></span></code> </pre> <br><p>  Kami membuat dua mesin untuk lebih melampirkan penangan acara tambahan ke salah satunya ( <code>val_evaluator</code> ) untuk menyimpan model dan berhenti belajar lebih awal (tentang semua ini di bawah). </p><br><p>  Mari kita juga melihat lebih dekat bagaimana mesin untuk mengevaluasi model didefinisikan, yaitu, bagaimana fungsi fungsi input proses didefinisikan untuk memproses satu batch: </p><br><pre> <code class="hljs python"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_supervised_evaluator</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, metrics={}, device=None)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> device: model.to(device) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_inference</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> model.eval() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): x, y = _prepare_batch(batch, device=device) y_pred = model(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y_pred, y engine = Engine(_inference) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> name, metric <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> metrics.items(): metric.attach(engine, name) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> engine</code> </pre> <br><p>  Kami melanjutkan lebih jauh.  Biarkan kami secara acak memilih bagian dari sampel pelatihan yang akan kami hitung metriknya: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.utils.data.dataset <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Subset indices = np.arange(len(train_dataset)) random_indices = np.random.permutation(indices)[:len(val_dataset)] train_subset = Subset(train_dataset, indices=random_indices) train_eval_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre> <br><p>  Selanjutnya, mari kita tentukan pada titik mana dalam pelatihan kita akan memulai perhitungan metrik dan akan ditampilkan ke layar: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@trainer.on(Events.EPOCH_COMPLETED) def compute_and_display_offline_train_metrics(engine): epoch = engine.state.epoch print("Compute train metrics...") metrics = train_evaluator.run(train_eval_loader).metrics print("Training Results - Epoch: {} Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}" .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall'])) @trainer.on(Events.EPOCH_COMPLETED) def compute_and_display_val_metrics(engine): epoch = engine.state.epoch print("Compute validation metrics...") metrics = val_evaluator.run(val_loader).metrics print("Validation Results - Epoch: {} Average Loss: {:.4f} | Accuracy: {:.4f} | Precision: {:.4f} | Recall: {:.4f}" .format(engine.state.epoch, metrics['avg_loss'], metrics['avg_accuracy'], metrics['avg_precision'], metrics['avg_recall']))</span></span></code> </pre><br><p>  Kamu bisa lari! </p><br><pre> <code class="python hljs">output = trainer.run(train_loader, max_epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><p>  Kita sampai di layar </p><br><pre> <code class="hljs powershell">Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">3.5112</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.9840</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.8807</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.9285</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.5026</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.1944</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">2.1018</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.3699</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.3981</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.3686</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">2.0519</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.3850</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.3578</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.3845</span></span></code> </pre><br><p>  Sudah lebih baik! </p><br><p>  <strong>Beberapa detail</strong> <br>  Mari kita lihat sedikit kode sebelumnya.  Pembaca mungkin memperhatikan baris kode berikut: </p><br><pre> <code class="python hljs">metrics = train_evaluator.run(train_eval_loader).metrics</code> </pre> <br><p>  dan mungkin ada pertanyaan tentang jenis objek yang diperoleh dari <code>train_evaluator.run(train_eval_loader)</code> , yang memiliki atribut <code>metrics</code> . </p><br><p>  Bahkan, kelas <code>Engine</code> berisi struktur yang disebut <code>state</code> (tipe <code>State</code> ) agar dapat mentransfer data antara event handler.  Atribut <code>state</code> ini berisi informasi dasar tentang era saat ini, iterasi, jumlah era, dll.  Itu juga dapat digunakan untuk mentransfer data pengguna apa pun, termasuk hasil perhitungan metrik. </p><br><pre> <code class="python hljs">state = train_evaluator.run(train_eval_loader) metrics = state.metrics <span class="hljs-comment"><span class="hljs-comment">#   train_evaluator.run(train_eval_loader) metrics = train_evaluator.state.metrics</span></span></code> </pre> <br><h5 id="raschet-metrik-vo-vremya-obucheniya">  Perhitungan metrik selama pelatihan </h5><br><p>  Jika tugas memiliki sampel pelatihan yang sangat besar dan penghitungan metrik setelah setiap zaman pelatihan mahal, tetapi Anda masih ingin melihat beberapa metrik berubah selama pelatihan, Anda dapat menggunakan pengendali event <code>RunningAverage</code> berikut dari kotak.  Sebagai contoh, kami ingin menghitung dan menampilkan akurasi classifier: </p><br><pre> <code class="python hljs">acc_metric = RunningAverage(CategoryAccuracy(...), alpha=<span class="hljs-number"><span class="hljs-number">0.98</span></span>) acc_metric.attach(trainer, <span class="hljs-string"><span class="hljs-string">'running_avg_accuracy'</span></span>) @trainer.on(Events.ITERATION_COMPLETED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">log_running_avg_metrics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> print(<span class="hljs-string"><span class="hljs-string">"running avg accuracy:"</span></span>, engine.state.metrics[<span class="hljs-string"><span class="hljs-string">'running_avg_accuracy'</span></span>])</code> </pre> <br><p>  Untuk menggunakan fungsionalitas <code>RunningAverage</code> , Anda perlu menginstal <em>ignite</em> dari sumber: </p><br><pre> <code class="hljs objectivec">pip install git+https:<span class="hljs-comment"><span class="hljs-comment">//github.com/pytorch/ignite</span></span></code> </pre> <br><h4 id="izmenenie-skorosti-obuchenie-learning-rate-scheduling">  Penjadwalan tingkat pembelajaran </h4><br><p>  Ada beberapa cara untuk mengubah kecepatan belajar menggunakan <em>ignite</em> .  Selanjutnya, pertimbangkan metode paling sederhana dengan memanggil fungsi <code>lr_scheduler.step()</code> di awal setiap era. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.optim.lr_scheduler <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ExponentialLR lr_scheduler = ExponentialLR(optimizer, gamma=<span class="hljs-number"><span class="hljs-number">0.8</span></span>) @trainer.on(Events.EPOCH_STARTED) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">update_lr_scheduler</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> lr_scheduler.step() <span class="hljs-comment"><span class="hljs-comment">#    : if len(optimizer.param_groups) == 1: lr = float(optimizer.param_groups[0]['lr']) print("Learning rate: {}".format(lr)) else: for i, param_group in enumerate(optimizer.param_groups): lr = float(param_group['lr']) print("Learning rate (group {}): {}".format(i, lr))</span></span></code> </pre> <br><h4 id="sohranenie-luchshih-modeley-i-drugih-parametrov-vo-vremya-obucheniya">  Menyimpan model terbaik dan parameter lain selama pelatihan </h4><br><p>  Selama pelatihan, akan sangat bagus untuk merekam bobot model terbaik pada disk, serta secara berkala menyimpan bobot model, parameter pengoptimal, dan parameter untuk mengubah kecepatan belajar.  Yang terakhir ini mungkin berguna untuk melanjutkan belajar dari keadaan tersimpan terakhir. </p><br><p>  <em>Ignite</em> memiliki kelas <code>ModelCheckpoint</code> khusus untuk ini.  Jadi, mari kita membuat event <code>ModelCheckpoint</code> dan menyimpan model terbaik dalam hal akurasi dalam set tes.  Dalam kasus ini, kami mendefinisikan fungsi <code>score_function</code> yang memberikan nilai akurasi ke pengendali event dan memutuskan apakah akan menyimpan model atau tidak: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.handlers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ModelCheckpoint <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score_function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine)</span></span></span><span class="hljs-function">:</span></span> val_avg_accuracy = engine.state.metrics[<span class="hljs-string"><span class="hljs-string">'avg_accuracy'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> val_avg_accuracy best_model_saver = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">"best_models"</span></span>, filename_prefix=<span class="hljs-string"><span class="hljs-string">"model"</span></span>, score_name=<span class="hljs-string"><span class="hljs-string">"val_accuracy"</span></span>, score_function=score_function, n_saved=<span class="hljs-number"><span class="hljs-number">3</span></span>, save_as_state_dict=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, create_dir=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment"># "best_models" -    1     #   -&gt; {filename_prefix}_{name}_{step_number}_{score_name}={abs(score_function_result)}.pth # save_as_state_dict=True, #   `state_dict` val_evaluator.add_event_handler(Events.COMPLETED, best_model_saver, {"best_model": model})</span></span></code> </pre> <br><p>  Sekarang buat event <code>ModelCheckpoint</code> lain untuk mempertahankan status pembelajaran setiap 1000 iterasi: </p><br><pre> <code class="python hljs">training_saver = ModelCheckpoint(<span class="hljs-string"><span class="hljs-string">"checkpoint"</span></span>, filename_prefix=<span class="hljs-string"><span class="hljs-string">"checkpoint"</span></span>, save_interval=<span class="hljs-number"><span class="hljs-number">1000</span></span>, n_saved=<span class="hljs-number"><span class="hljs-number">1</span></span>, save_as_state_dict=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, create_dir=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) to_save = {<span class="hljs-string"><span class="hljs-string">"model"</span></span>: model, <span class="hljs-string"><span class="hljs-string">"optimizer"</span></span>: optimizer, <span class="hljs-string"><span class="hljs-string">"lr_scheduler"</span></span>: lr_scheduler} trainer.add_event_handler(Events.ITERATION_COMPLETED, training_saver, to_save)</code> </pre> <br><p>  Jadi, hampir semuanya sudah siap, tambahkan elemen terakhir: </p><br><h4 id="rannyaya-ostanovka-obucheniya-early-stopping">  Pelatihan hentikan dini (hentikan dini) </h4><br><p>  Mari kita tambahkan event handler lain yang akan berhenti belajar jika tidak ada peningkatan kualitas model lebih dari 10 era.  Kami akan mengevaluasi kualitas model lagi menggunakan <code>score_function</code> score_function. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite.handlers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> EarlyStopping early_stopping = EarlyStopping(patience=<span class="hljs-number"><span class="hljs-number">10</span></span>, score_function=score_function, trainer=trainer) val_evaluator.add_event_handler(Events.EPOCH_COMPLETED, early_stopping)</code> </pre> <br><h3 id="zapusk-obucheniya">  Mulai pelatihan </h3><br><p>  Untuk memulai pelatihan, cukup bagi kita untuk memanggil metode <code>run()</code> .  Kami akan melatih model untuk 10 era: </p><br><pre> <code class="python hljs">max_epochs = <span class="hljs-number"><span class="hljs-number">10</span></span> output = trainer.run(train_loader, max_epochs=max_epochs)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Output layar</b> <div class="spoiler_text"><pre> <code class="hljs powershell">Learning rate: <span class="hljs-number"><span class="hljs-number">0.01</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.7984</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.9736</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">4.3419</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.0261</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.1724</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">1</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">2.1599</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">1.5363</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.5177</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.5477</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.5178</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">1</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">1.5116</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.5139</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.5400</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.5140</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.008</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.4076</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.4892</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.2485</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.6511</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">3.3376</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">2</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.3299</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">2</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">3.2686</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.1977</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.1792</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.1942</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">2</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">3.2772</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.1962</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.1628</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.1918</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.006400000000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.9016</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.2006</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8892</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8141</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">1.4005</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">3</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8888</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">3</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.7368</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.7554</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.7818</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.7554</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">3</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.7177</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.7623</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.7863</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.7611</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.005120000000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8490</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8493</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.8100</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.9165</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.9370</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">4</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6548</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">4</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.7047</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.7713</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8040</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.7728</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">4</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.6737</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.7778</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.7955</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.7806</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.004096000000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6965</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6196</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6194</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3986</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.6032</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">5</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.7152</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">5</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.5049</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8282</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8393</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8314</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">5</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.5084</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8304</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8386</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8328</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.0032768000000000007</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4433</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4764</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.5578</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3684</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4847</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">6</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3811</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">6</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.4383</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8474</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8618</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8495</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">6</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.4419</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8446</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8532</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8442</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.002621440000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4447</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4602</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.5345</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3973</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.5023</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">7</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.5303</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">7</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.4305</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8579</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8691</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8596</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">7</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.4262</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8590</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8685</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8606</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.002097152000000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4867</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3090</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3721</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4559</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3958</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">8</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4222</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">8</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3432</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8818</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8895</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8817</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">8</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3644</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8713</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8784</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8707</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.001677721600000001</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3557</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3692</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3510</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3446</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3966</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">9</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3451</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">9</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3315</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8954</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.9001</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8982</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">9</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3559</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8818</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8876</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8847</span></span> Learning rate: <span class="hljs-number"><span class="hljs-number">0.0013421772800000006</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">50</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3340</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">100</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3370</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">150</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3694</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">200</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.3409</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">250</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.4420</span></span> Epoch[<span class="hljs-number"><span class="hljs-number">10</span></span>] Iteration[<span class="hljs-number"><span class="hljs-number">300</span></span>/<span class="hljs-number"><span class="hljs-number">322</span></span>] Loss: <span class="hljs-number"><span class="hljs-number">0.2770</span></span> Compute train metrics... Training Results - Epoch: <span class="hljs-number"><span class="hljs-number">10</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3246</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8921</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8988</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8925</span></span> Compute validation metrics... Validation Results - Epoch: <span class="hljs-number"><span class="hljs-number">10</span></span> Average Loss: <span class="hljs-number"><span class="hljs-number">0.3536</span></span> | Accuracy: <span class="hljs-number"><span class="hljs-number">0.8731</span></span> | Precision: <span class="hljs-number"><span class="hljs-number">0.8785</span></span> | Recall: <span class="hljs-number"><span class="hljs-number">0.8722</span></span></code> </pre> </div></div><br><p>  Sekarang periksa model dan parameter yang disimpan ke disk: </p><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">ls</span></span> best_models/ model_best_model_10_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8730994</span></span>.pth model_best_model_8_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8712978</span></span>.pth model_best_model_9_val_accuracy=<span class="hljs-number"><span class="hljs-number">0.8818188</span></span>.pth</code> </pre> <br><p>  dan </p><br><pre> <code class="hljs pgsql">ls <span class="hljs-keyword"><span class="hljs-keyword">checkpoint</span></span>/ checkpoint_lr_scheduler_3000.pth checkpoint_optimizer_3000.pth checkpoint_model_3000.pth</code> </pre> <br><h3 id="predskazaniya-obuchennoy-modelyu">  Prediksi oleh model yang terlatih </h3><br><p>  Pertama, buat pemuat data uji (misalnya, ambil sampel validasi) sehingga kumpulan data terdiri dari gambar dan indeksnya: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TestDataset</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(Dataset)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, ds)</span></span></span><span class="hljs-function">:</span></span> self.ds = ds <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__len__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> len(self.ds) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__getitem__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, index)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.ds[index][<span class="hljs-number"><span class="hljs-number">0</span></span>], index test_dataset = TestDataset(val_dataset) test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_workers=num_workers, drop_last=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pin_memory=<span class="hljs-string"><span class="hljs-string">"cuda"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> device)</code> </pre> <br><p>  Menggunakan <em>ignite,</em> kami <em>akan</em> membuat mesin prediksi baru untuk data uji.  Untuk melakukan ini, kita mendefinisikan fungsi <code>inference_update</code> , yang mengembalikan hasil prediksi dan indeks gambar.  Untuk meningkatkan akurasi, kami juga akan menggunakan trik terkenal "test time augmentation" (TTA). </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch.nn.functional <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> F <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ignite._utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> convert_tensor <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_prepare_batch</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(batch)</span></span></span><span class="hljs-function">:</span></span> x, index = batch x = convert_tensor(x, device=device) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x, index <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">inference_update</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(engine, batch)</span></span></span><span class="hljs-function">:</span></span> x, indices = _prepare_batch(batch) y_pred = model(x) y_pred = F.softmax(y_pred, dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> {<span class="hljs-string"><span class="hljs-string">"y_pred"</span></span>: convert_tensor(y_pred, device=<span class="hljs-string"><span class="hljs-string">'cpu'</span></span>), <span class="hljs-string"><span class="hljs-string">"indices"</span></span>: indices} model.eval() inferencer = Engine(inference_update)</code> </pre> <br><p>  Selanjutnya, buat pengendali acara yang akan memberi tahu tentang tahap prediksi dan menyimpan prediksi dalam array khusus: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inferencer.on(Events.EPOCH_COMPLETED) def log_tta(engine): print("TTA {} / {}".format(engine.state.epoch, n_tta)) n_tta = 3 num_classes = 81 n_samples = len(val_dataset) #     y_probas_tta = np.zeros((n_samples, num_classes, n_tta), dtype=np.float32) @inferencer.on(Events.ITERATION_COMPLETED) def save_results(engine): output = engine.state.output tta_index = engine.state.epoch - 1 start_index = ((engine.state.iteration - 1) % len(test_loader)) * batch_size end_index = min(start_index + batch_size, n_samples) batch_y_probas = output['y_pred'].detach().numpy() y_probas_tta[start_index:end_index, :, tta_index] = batch_y_probas</span></span></code> </pre> <br><p>  Sebelum memulai proses, mari unduh model terbaik: </p><br><pre> <code class="python hljs">model = squeezenet1_1(pretrained=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">64</span></span>) model.classifier[<span class="hljs-number"><span class="hljs-number">-1</span></span>] = nn.AdaptiveAvgPool2d(<span class="hljs-number"><span class="hljs-number">1</span></span>) model = model.to(device) model_state_dict = torch.load(<span class="hljs-string"><span class="hljs-string">"best_models/model_best_model_10_val_accuracy=0.8730994.pth"</span></span>) model.load_state_dict(model_state_dict)</code> </pre> <br><p>  Kami meluncurkan: </p><br><pre> <code class="python hljs">inferencer.run(test_loader, max_epochs=n_tta) &gt; TTA <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span> &gt; TTA <span class="hljs-number"><span class="hljs-number">2</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span> &gt; TTA <span class="hljs-number"><span class="hljs-number">3</span></span> / <span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br><p>  Selanjutnya, dengan cara standar, kami mengambil rata-rata prediksi TTA dan menghitung indeks kelas dengan probabilitas tertinggi: </p><br><pre> <code class="python hljs">y_probas = np.mean(y_probas_tta, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>) y_preds = np.argmax(y_probas, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)</code> </pre> <br><p>  Dan sekarang kita dapat sekali lagi menghitung keakuratan model sesuai dengan prediksi: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score y_test_true = [y <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _, y <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> val_dataset] accuracy_score(y_test_true, y_preds) &gt; <span class="hljs-number"><span class="hljs-number">0.9310369676443035</span></span></code> </pre> <br><p> ,     ,          .   ,   ,      ,    <em>ignite</em>      . </p><br><h2 id="drugie-primery-s-ignitehttpspytorchorgignite">    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ignite</a> </h2><br><p>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> . </p><br><p>  github      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a>       </p><br><ul><li> fast neural transfer </li><li> reinforcement learning </li><li> dcgan </li></ul><br><h2 id="zaklyuchenie">  Kesimpulan </h2><br><p>    ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ignite</a>      Facebook           (.   ).        0.1.0,   API (Engine, State, Events, Metric, ...)           .       ,      ,     ,     pull request-  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> github</a> . </p><br><p>  Terima kasih atas perhatian anda! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id424781/">https://habr.com/ru/post/id424781/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id424767/index.html">Kami membuat kue dari Habr. Lagi</a></li>
<li><a href="../id424771/index.html">Pengalaman pribadi: dari ide dan lembar kosong hingga versi konsep situs</a></li>
<li><a href="../id424773/index.html">Pemodelan biofarma dan numerik: Pengalaman dan praktik Amgen</a></li>
<li><a href="../id424777/index.html">Menggunakan Konsul untuk Skala Layanan Stateful</a></li>
<li><a href="../id424779/index.html">SPA multi-halaman dalam Python</a></li>
<li><a href="../id424787/index.html">Wawancara dengan Aaron Patterson, Pembicara Konferensi RubyRusia 2018</a></li>
<li><a href="../id424789/index.html">Bagaimana cara menyebarkan aplikasi Ruby on Rails dengan HAProxy Ingress, unicorn / puma, dan soket web</a></li>
<li><a href="../id424791/index.html">Memperluas kemampuan jaringan dari relay yang dapat diprogram menggunakan WI-FI</a></li>
<li><a href="../id424793/index.html">Cara mencetak motor listrik</a></li>
<li><a href="../id424795/index.html">Seberapa besar drone bertenaga surya?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
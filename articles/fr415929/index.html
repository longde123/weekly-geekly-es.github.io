<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§úüèª üë®üèæ‚Äçüöí üêî Optimisation de l'architecture de l'intelligence artificielle: la course commence üë©üèº‚Äçüíº üçï üöê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√Ä mesure que l'architecture de l'IA s'am√©liore et que les co√ªts baissent, les experts disent que de plus en plus d'entreprises ma√Ætriseront ces techno...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimisation de l'architecture de l'intelligence artificielle: la course commence</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/icl_services/blog/415929/">  √Ä mesure que l'architecture de l'IA s'am√©liore et que les co√ªts baissent, les experts disent que de plus en plus d'entreprises ma√Ætriseront ces technologies, ce qui donnera une impulsion aux innovations et apportera de gros dividendes aux entreprises et aux d√©veloppeurs d'IA. <br><br>  Les applications d'IA fonctionnent souvent sur la base d'architectures compl√®tement diff√©rentes des applications d'entreprise traditionnelles.  √Ä leur tour, les fournisseurs sont pr√™ts √† faire beaucoup pour fournir de nouveaux composants dont la demande augmente. <br><br><img src="https://habrastorage.org/webt/kx/tl/dk/kxtldk4vqyzwqzmeaxzo5u8pulo.jpeg" align="left"><blockquote> ¬´L'industrie informatique est en pleine mutation - l'int√©r√™t des entreprises pour l'IA donne une impulsion aux innovations qui aideront √† ma√Ætriser et √† d√©ployer l'IA √† n'importe quelle √©chelle¬ª, a d√©clar√© Keith Strier, expert en IA, consultant chez EY.  Les investisseurs investissent beaucoup d'argent dans les startups qui optimisent l'IA, et les grands fabricants commencent √† proposer non seulement des puces et du stockage, mais aussi les services r√©seau et cloud n√©cessaires au d√©ploiement. ¬ª </blockquote>  . <br>  Selon lui, la t√¢che principale des directeurs informatiques consiste d√©sormais √† choisir l'architecture d'intelligence artificielle appropri√©e aux besoins de l'entreprise. <br><br>  Streer dit que l'IA √©tant des math√©matiques √† une √©chelle sans pr√©c√©dent, la mise en ≈ìuvre de cette technologie n√©cessite des conditions techniques et des outils de s√©curit√© compl√®tement diff√©rents de ceux des charges de travail d'entreprise famili√®res.  Pour tirer pleinement parti de l'IA, les fournisseurs devront fournir l'infrastructure technique, le cloud et les autres services n√©cessaires √† l'IA, sans lesquels de tels calculs complexes seraient impossibles. <br><a name="habracut"></a><br>  Mais nous y sommes d√©j√† en route, et √† l'avenir, il y aura des architectures encore plus avanc√©es de l'intelligence artificielle.  Streer estime que fournir la flexibilit√©, la puissance et la vitesse des architectures informatiques sera non seulement de petites entreprises pour le d√©veloppement de l'informatique haute performance, mais aussi d'autres repr√©sentants de l'industrie de l'informatique haute performance, y compris des startups pour cr√©er des micropuces et des services cloud qui cherchent √† √©tablir des normes √©lev√©es pour l'IA. l'informatique. <br><br>  √Ä mesure que de plus en plus de sp√©cialistes et de d√©veloppeurs dans le domaine de l'IA apparaissent, cette technologie deviendra plus accessible, ce qui donnera une bonne impulsion aux innovations et apportera des dividendes notables - pour les entreprises et les fournisseurs. <br><br>  Dans l'intervalle, les directeurs informatiques doivent se familiariser avec les difficult√©s li√©es √† la cr√©ation d'une architecture d'intelligence artificielle pour une utilisation en entreprise afin d'√™tre pr√™ts √† les r√©soudre. <br><br><h3>  D√©veloppement de puces <br></h3><br>  La condition la plus importante pour la transition des architectures informatiques traditionnelles √† l'IA √©tait le d√©veloppement de processeurs graphiques, de circuits int√©gr√©s logiques programmables (FPGA) et de puces AI sp√©cialis√©es.  La prolif√©ration des architectures bas√©es sur les GPU et les FPGA contribuera √† augmenter la productivit√© et la flexibilit√© des syst√®mes informatiques et de stockage, ce qui permettra aux fournisseurs de solutions d'offrir une gamme de services avanc√©s pour les applications d'IA et d'apprentissage automatique. <br><br><img src="https://habrastorage.org/webt/ik/yt/d4/ikytd4x8p5ajbjv_m4tjqq-lgzi.jpeg" align="left"><blockquote>  ¬´Ce sont des architectures de puces qui lib√®rent de nombreuses fonctionnalit√©s avanc√©es de la charge [telles que la formation √† l'IA] et aident √† mettre en ≈ìuvre une pile am√©lior√©e pour l'informatique et le stockage qui offre des performances et une efficacit√© in√©gal√©es¬ª, a d√©clar√© Surya Varanasi, fondateur et directeur technique de Vexata Inc., fournisseur de solutions de gestion de donn√©es. </blockquote><br>  Mais alors que les nouveaux microcircuits ne sont pas capables de quelque chose de plus complexe.  Afin de s√©lectionner l'architecture optimale pour les charges de travail de l'IA, il est n√©cessaire d'effectuer des calculs √† grande √©chelle qui n√©cessitent un d√©bit √©lev√© et ne peuvent pas se faire sans retards.  La cl√© du succ√®s r√©side ici dans les r√©seaux √† haut d√©bit.  Mais de nombreux algorithmes d'IA doivent attendre que le prochain ensemble de donn√©es soit tap√©, vous ne devez donc pas perdre de vue le retard. <br><br>  De plus, lors du franchissement des limites du serveur ou du transfert des serveurs vers le stockage, les donn√©es passent par plusieurs protocoles.  Pour simplifier ces processus, les experts en donn√©es peuvent essayer de localiser les donn√©es localement afin qu'un serveur puisse traiter de gros morceaux de donn√©es sans en attendre d'autres.  Une meilleure int√©gration entre les GPU et le stockage permet √©galement d'√©conomiser de l'argent.  D'autres fournisseurs recherchent des moyens de simplifier la conception des serveurs AI pour garantir la compatibilit√© afin que les m√™mes serveurs puissent √™tre utilis√©s pour diff√©rentes charges de travail. <br><br><h3>  M√©moire non volatile pour le traitement des charges de travail AI <br></h3><br>  Au c≈ìur de nombreuses solutions bas√©es sur le GPU se trouve un lecteur √† connexion directe (DAS), qui complique grandement l'apprentissage distribu√© et la formation de conclusions logiques pour l'IA.  Par cons√©quent, l'installation et la gestion de ces lignes de donn√©es pour l'apprentissage en profondeur deviennent une t√¢che complexe et longue. <br><br>  Pour r√©soudre ce probl√®me, la m√©moire non volatile (NVM) convient, con√ßue √† l'origine pour fournir une connectivit√© de haute qualit√© entre les disques SSD et les serveurs d'entreprise traditionnels.  D√©sormais, ce type de m√©moire est souvent inclus dans les matrices d'E / S pour optimiser les charges de travail de l'IA. <br><br>  L'essentiel est que NVMe over Fabrics (NVMeF) - les soi-disant ces interfaces - contribuera √† r√©duire le co√ªt de la conversion entre les protocoles r√©seau et √† contr√¥ler les caract√©ristiques de chaque type de SSD.  Cela permettra aux DSI de justifier le co√ªt des applications d'IA qui utilisent de grands ensembles de donn√©es. <br><br>  Les interfaces NVMeF comportent leurs risques, notamment la n√©cessit√© de co√ªts √©lev√©s pour les technologies avanc√©es.  En outre, il existe toujours une d√©pendance vis-√†-vis des fournisseurs NVMeF dans ce secteur, de sorte que les directeurs informatiques doivent essayer d'√©viter les relations sp√©cifiques au fournisseur lors du choix d'un produit. <br>  Mais la mise en ≈ìuvre de NVMeF vous permettra de franchir une nouvelle √©tape vers l'optimisation de l'architecture d'entreprise de l'intelligence artificielle, estime Varanasi. <br><br><img src="https://habrastorage.org/webt/ik/yt/d4/ikytd4x8p5ajbjv_m4tjqq-lgzi.jpeg" align="left"><blockquote>  ¬´Malgr√© le fait que l'expansion de l'architecture NVMe over Fabrics √† l'√©chelle industrielle puisse prendre encore un an ou un an et demi, nous avons d√©j√† les principaux composants et les pionniers rapportent d√©j√† des r√©sultats prometteurs¬ª, explique Varanasi. <br><br></blockquote><br>  Les DSI d√©sireux de d√©velopper des applications d'IA peuvent essayer de cr√©er un pool de stockage partag√© optimis√© pour l'IA pour NVMeF s'il r√©ussit √† remplacer les r√©seaux de stockage existants √† court terme.  Mais si vous attendez que NVMeF soit r√©trocompatible, vous pouvez perdre beaucoup. <br><br><h3>  R√©duisez le mouvement des donn√©es <br></h3><br>  Lors de la planification des diff√©rentes √©tapes du d√©ploiement de l'IA, vous devez porter une attention particuli√®re au co√ªt du d√©placement des donn√©es.  Les projets d'IA, y compris ceux pour le traitement et la transformation des donn√©es, ainsi que pour la formation d'algorithmes, n√©cessitent d'√©normes quantit√©s de donn√©es. <br><br>  Le mat√©riel et les ressources humaines n√©cessaires pour effectuer ces t√¢ches, ainsi que le temps n√©cessaire pour d√©placer les donn√©es elles-m√™mes, peuvent rendre les projets d'IA trop co√ªteux.  Si les DSI parviennent √† √©viter de d√©placer des donn√©es entre les √©tapes, il est probable qu'ils seront en mesure de d√©velopper une infrastructure d'IA viable qui r√©pond √† ces besoins, a d√©clar√© Haris Pozidis, Ph.D., directeur, sp√©cialiste des technologies d'acc√©l√©ration du stockage chez IBM Research.  Les fabricants travaillent d√©j√† sur cette question. <br><br>  Par exemple, IBM exp√©rimente diverses options d'optimisation mat√©rielle et logicielle pour r√©duire le mouvement des donn√©es pour les applications d'IA √† grande √©chelle dans les laboratoires de Zurich.  Ces optimisations ont permis de multiplier par 46 les performances du script de test de l'outil d'analyse de clics populaire.  Pozidis affirme que l'apprentissage distribu√© et l'acc√©l√©ration GPU sont au c≈ìur de ce travail, ce qui am√©liore la prise en charge des structures de donn√©es clairsem√©es. <br><br>  La concurrence est un autre √©l√©ment important dans l'acc√©l√©ration des charges de travail de l'IA.  Pour la formation distribu√©e, il est n√©cessaire d'apporter des modifications aux niveaux mat√©riel et logiciel, ce qui am√©liorera l'efficacit√© de traitement des algorithmes de processeur graphique parall√®le.  Les chercheurs d'IBM ont cr√©√© une plate-forme prototype avec parall√©lisme de donn√©es, qui vous permet de faire √©voluer et d'apprendre sur de grandes quantit√©s de donn√©es qui d√©passent la quantit√© de m√©moire sur une machine.  Ceci est tr√®s important pour les applications √† grande √©chelle.  Une nouvelle plate-forme optimis√©e pour l'apprentissage de la communication et la localisation des donn√©es a permis de r√©duire le mouvement des donn√©es. <br><br>  Au niveau mat√©riel, les chercheurs d'IBM ont utilis√© NVMeF pour am√©liorer l'interconnectivit√© des composants GPU, CPU et m√©moire sur les serveurs, ainsi qu'entre les serveurs et le stockage. <br><br><img src="https://habrastorage.org/webt/es/li/m1/eslim1mvwlg3vqgesw1lfuzlyqa.jpeg" align="left"><blockquote>  ¬´Les performances des diff√©rentes charges de travail de l'IA peuvent √™tre limit√©es par les goulots d'√©tranglement du r√©seau, la bande passante m√©moire et la bande passante entre le CPU et le GPU.  Mais si vous impl√©mentez des algorithmes et des protocoles de connexion plus efficaces dans toutes les parties du syst√®me, vous pouvez faire un grand pas vers le d√©veloppement d'applications d'IA plus rapides ¬ª, explique Pozidis. </blockquote><br><br><h3>  Compound Computing <br></h3>  Aujourd'hui, la plupart des charges de travail utilisent une base de donn√©es pr√©configur√©e optimis√©e pour une architecture mat√©rielle particuli√®re. <br><br><img src="https://habrastorage.org/webt/iy/qd/xq/iyqdxqbenrorpibc--ylt9o0zfs.jpeg" align="left"><br><blockquote>  Chad Miley, vice-pr√©sident des produits et solutions analytiques chez Teradata, explique que le march√© s'oriente vers le mat√©riel logiciel, qui permettra aux organisations de r√©partir intelligemment le traitement entre les GPU et les CPU en fonction de la t√¢che en cours. </blockquote><br><br>  La difficult√© r√©side dans le fait que les entreprises utilisent diff√©rents moteurs informatiques pour acc√©der √† diff√©rentes options de stockage.  Les grandes entreprises pr√©f√®rent stocker des donn√©es pr√©cieuses qui n√©cessitent un acc√®s r√©gulier, par exemple des informations sur les clients, les finances, la cha√Æne d'approvisionnement, les produits et d'autres composants, en utilisant des environnements d'entr√©e-sortie hautes performances.  √Ä leur tour, les ensembles de donn√©es rarement utilis√©s, tels que les lectures de capteur, le contenu Web et le multim√©dia, sont stock√©s dans un stockage cloud √† faible co√ªt. <br><br>  L'un des objectifs de l'informatique composite est d'utiliser des conteneurs pour optimiser les performances des instances telles que les moteurs SQL, les moteurs de graphes, l'apprentissage automatique et les moteurs d'apprentissage en profondeur qui acc√®dent aux donn√©es r√©parties sur diff√©rents r√©f√©rentiels.  Le d√©ploiement de plusieurs moteurs de calcul analytique permet d'utiliser des mod√®les multiprocesseurs qui utilisent des donn√©es de diff√©rents moteurs et, en r√®gle g√©n√©rale, donnent de meilleurs r√©sultats. <br><br>  Les fournisseurs informatiques tels que Dell Technologies, Hewlett Packard Enterprise et Liquid s'√©loignent progressivement des architectures traditionnelles qui affectent les charges de travail au niveau informatique.  Au lieu de cela, ils cherchent √† affecter des charges de travail AI √† un syst√®me entier compos√© d'unit√©s de traitement centrales, de GPU, de m√©moire et de p√©riph√©riques de stockage.  Pour une telle transition, il est n√©cessaire de ma√Ætriser de nouveaux composants r√©seau, ce qui augmente la vitesse et r√©duit le d√©lai lors de la connexion des diff√©rents composants du syst√®me. <br><br>  Par exemple, de nombreux centres de donn√©es cloud utilisent Ethernet pour connecter les composants informatiques et le stockage, o√π le retard est d'environ 15 microsecondes.  Le r√©seau informatique commut√© √† grande vitesse d'InfiniBand, qui est utilis√© dans de nombreuses infrastructures convergentes, peut r√©duire la latence jusqu'√† 1,5 microsecondes.  Liquid a cr√©√© un ensemble d'outils pour connecter diff√©rents n≈ìuds √† l'aide de PCI Express (PCIE), ce qui r√©duit le d√©lai √† 150 nanosecondes. <br><br>  De plus, certains experts sugg√®rent d'augmenter la quantit√© de m√©moire pour les GPU utilis√©s pour g√©rer de grandes charges avec des connexions rapides.  Par exemple, la DDR4 est souvent utilis√©e avec la RAM, ce qui r√©duit le retard √† 14 nanosecondes.  Mais cela ne fonctionne que pour de petits segments de quelques pouces. <br><br>  Little Marrek, fondateur et d√©veloppeur du service de gestion ClusterOne AI, estime que davantage de travail est n√©cessaire pour garantir la compatibilit√© des charges de travail AI dans un environnement logiciel.  Malgr√© le fait que certaines entreprises tentent d√©j√† d'assurer la compatibilit√© avec Docker et Kubernetes, il est trop t√¥t pour appliquer la m√™me approche aux GPU. <br><br><img src="https://habrastorage.org/webt/gy/kf/vo/gykfvonm7odfn4osmkaya-lwfas.jpeg" align="left"><blockquote>  ¬´En g√©n√©ral, ex√©cuter des charges de travail GPU et les surveiller n'est pas facile¬ª, explique Marrek.  ¬´Il n'y a pas de solution universelle qui permette la surveillance de tous les syst√®mes.¬ª <br><br></blockquote><br><br><h3>  Stockage et GPU <br></h3><br>  Une autre approche consiste √† utiliser un processeur graphique pour pr√©traiter les donn√©es afin de r√©duire la quantit√© n√©cessaire pour un type particulier d'analyse, et aider √† organiser les donn√©es et √† leur attribuer des √©tiquettes.  Cela vous permettra de pr√©parer un ensemble de donn√©es appropri√© pour plusieurs GPU impliqu√©s dans le traitement, afin que l'algorithme puisse fonctionner de l'int√©rieur de la m√©moire au lieu de transf√©rer les donn√©es des stockages sur des r√©seaux lents. <br><br><img src="https://habrastorage.org/webt/ys/qp/cb/ysqpcbtqxhszcgd3hpgn9kutmss.jpeg" align="left"><blockquote>  ¬´Nous percevons le stockage, l'informatique et la m√©moire comme des composants distincts de la solution, qui s'est d√©velopp√©e historiquement, et essayons donc d'augmenter les volumes de traitement¬ª, a d√©clar√© Alex St. John, directeur technique et fondateur de Nyriad Ltd., une soci√©t√© de logiciels de stockage apparue dans le r√©sultat de la recherche du plus grand radiot√©lescope du monde - un t√©lescope avec un r√©seau d'antennes de kilom√®tre carr√© (SKA). </blockquote>  Plus les quantit√©s de donn√©es sont importantes, plus il est difficile de les d√©placer quelque part pour le traitement. <br><br>  Le t√©lescope SKA avait besoin de grandes quantit√©s d'√©nergie pour traiter 160 To de donn√©es de signaux radio en temps r√©el, ce qui √©tait le principal obstacle pour les chercheurs.  En cons√©quence, ils ont d√©cid√© d'abandonner les stockages RAID qui sont le plus souvent utilis√©s dans les centres de donn√©es et de d√©ployer un syst√®me de fichiers en cluster parall√®le, tel que BeeGFS, ce qui simplifie la pr√©paration des donn√©es pour les charges de travail de l'IA. <br><br>  Les directeurs informatiques qui travaillent sur la strat√©gie optimale pour l'architecture d'intelligence artificielle doivent accorder une attention particuli√®re √† la convivialit√©.  Si les d√©veloppeurs, les sp√©cialistes des donn√©es et les √©quipes de d√©veloppement et d'int√©gration des op√©rations peuvent rapidement ma√Ætriser la nouvelle technologie, ils peuvent investir leur temps et leur √©nergie dans la cr√©ation d'une logique m√©tier r√©ussie au lieu de r√©soudre les probl√®mes de d√©ploiement et les lignes de donn√©es. <br><br>  En outre, les organisations doivent soigneusement r√©fl√©chir aux efforts et au temps n√©cessaires pour int√©grer une nouvelle architecture d'IA dans un √©cosyst√®me existant. <br><br>  ¬´Avant de mettre en ≈ìuvre de nouvelles infrastructures et de planifier d'importantes charges de travail, les DSI doivent √©valuer le nombre de ressources √©puisables qui seront n√©cessaires¬ª, explique Asaf Someh, fondateur et PDG d'Iguazio. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr415929/">https://habr.com/ru/post/fr415929/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr415917/index.html">La "loi du printemps" est entr√©e en vigueur: quelle est la prochaine √©tape?</a></li>
<li><a href="../fr415919/index.html">Refactorisation d'un programme sur Go: acc√©l√©ration de 23 fois</a></li>
<li><a href="../fr415923/index.html">L'unit√© est-elle lente? Attention LINQ</a></li>
<li><a href="../fr415925/index.html">Technologie de blockchain anonyme brevet√©e MasterCard</a></li>
<li><a href="../fr415927/index.html">Lampe industrielle Breeze 50</a></li>
<li><a href="../fr415933/index.html">Comment construire une architecture IIoT √† faire soi-m√™me</a></li>
<li><a href="../fr415935/index.html">Tri d'insertion</a></li>
<li><a href="../fr415937/index.html">La fus√©e priv√©e japonaise MOMO-2 a explos√© sur la rampe de lancement</a></li>
<li><a href="../fr415939/index.html">Traitement graphique distribu√© avec Spark GraphX</a></li>
<li><a href="../fr415943/index.html">"D√©veloppement du jeu et th√©orie du divertissement": points cl√©s du livre de Raff Coster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
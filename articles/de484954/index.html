<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧓 👊🏽 👨🏾‍🔧 Visuelle Fehlerbehebung für Kubernetes 😺 👎🏿 🥨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hinweis perev. : Dieser Artikel ist Teil des frei verfügbaren Materials aus dem learnk8s- Projekt, in dem Sie lernen , wie Sie mit Kubernetes-Unterneh...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Visuelle Fehlerbehebung für Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/484954/">  <i><b>Hinweis</b></i>  <i><b>perev.</b></i>  <i>: Dieser Artikel ist Teil des frei verfügbaren Materials aus dem <a href="https://learnk8s.io/">learnk8s-</a> Projekt, in dem Sie <a href="https://learnk8s.io/">lernen</a> , wie Sie mit Kubernetes-Unternehmen und einzelnen Administratoren arbeiten.</i>  <i>Darin gibt Daniele Polencic, der Projektmanager, eine klare Anweisung, welche Schritte bei allgemeinen Problemen für Anwendungen im K8s-Cluster zu unternehmen sind.</i> <br><br><img src="https://habrastorage.org/webt/ch/5u/xa/ch5uxanj-3ivwqu88swqyoi6bsu.png"><br><br>  TL; DR: Hier ist ein Diagramm, das Ihnen beim Debuggen der Bereitstellung in Kubernetes hilft: <a name="habracut"></a><br><br> <a href=""><img src="https://habrastorage.org/webt/4r/qp/si/4rqpsie8dnplkqxahaqntpi2ssw.png"></a> <br><br>  <i>Flussdiagramm zum Auffinden und Beheben von Fehlern in einem Cluster.</i>  <i>Im Original (auf Englisch) ist es als <a href="https://learnk8s.io/a/troubleshooting-kubernetes.pdf">PDF</a> und <a href="">als Bild</a> verfügbar.</i> <br><br>  Wenn Sie eine Anwendung auf Kubernetes bereitstellen, müssen Sie normalerweise drei Komponenten definieren: <br><br><ul><li>  <b>Die Bereitstellung</b> ist ein Rezept zum Erstellen von Kopien einer Anwendung namens Pods. </li><li>  <b>Service</b> - ein interner Load Balancer, der den Datenverkehr auf die Pods verteilt; </li><li>  <b>Ingress</b> - Eine Beschreibung, wie der Datenverkehr von der Außenwelt zum Service fließt. </li></ul><br>  Hier ist eine kurze grafische Zusammenfassung: <br><br>  1) In Kubernetes empfangen Anwendungen Datenverkehr von der Außenwelt über zwei Ebenen von Load Balancern: interne und externe. <br><br><img src="https://habrastorage.org/webt/3v/cy/z9/3vcyz9a-2ciiqbh9he7idgvo7uy.png"><br><br>  2) Der interne Balancer heißt Service, der externe - Ingress. <br><br><img src="https://habrastorage.org/webt/23/mn/zc/23mnzcfo_b3niccdivn4bc4vzei.png"><br><br>  3) Die Bereitstellung erstellt Pods und überwacht sie (sie werden nicht manuell erstellt). <br><br><img src="https://habrastorage.org/webt/4j/c2/h9/4jc2h9pgzbxmkon4ewkbeuf0vhc.png"><br><br>  Angenommen, Sie möchten eine einfache Anwendung a la <i>Hello World</i> bereitstellen.  Die YAML-Konfiguration dafür sieht folgendermaßen aus: <br><br><pre><code class="plaintext hljs">apiVersion: apps/v1 kind: Deployment # &lt;&lt;&lt; metadata: name: my-deployment labels: track: canary spec: selector: matchLabels: any-name: my-app template: metadata: labels: any-name: my-app spec: containers: - name: cont1 image: learnk8s/app:1.0.0 ports: - containerPort: 8080 --- apiVersion: v1 kind: Service # &lt;&lt;&lt; metadata: name: my-service spec: ports: - port: 80 targetPort: 8080 selector: name: app --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress # &lt;&lt;&lt; metadata: name: my-ingress spec: rules: - http: paths: - backend: serviceName: app servicePort: 80 path: /</code> </pre> <br>  Die Definition ist ziemlich lang und es ist leicht zu verwechseln, wie die Komponenten zueinander in Beziehung stehen. <br><br>  Zum Beispiel: <br><br><ul><li>  Wann sollten Sie Port 80 und wann - 8080 verwenden? </li><li>  Soll ich für jeden Dienst einen neuen Port erstellen, damit keine Konflikte auftreten? </li><li>  Sind Markennamen wichtig?  Sollten sie überall gleich sein? </li></ul><br>  Bevor wir uns auf das Debuggen konzentrieren, wollen wir uns erinnern, wie die drei Komponenten zueinander in Beziehung stehen.  Beginnen wir mit Bereitstellung und Service. <br><br><h2>  Connection Deployment'a und Service'a </h2><br>  Sie werden überrascht sein, aber Deployments und Service sind in keiner Weise miteinander verbunden.  Stattdessen verweist der Dienst direkt auf Pods, die die Bereitstellung umgehen. <br><br>  Aus diesem Grund interessieren wir uns für die Beziehung zwischen Pods und Services.  Drei Dinge zu beachten: <br><br><ol><li>  Ein Service- <code>selector</code> muss mit mindestens einem Pod-Etikett übereinstimmen. </li><li>  <code>targetPort</code> muss mit dem <code>containerPort</code> Containers im Pod übereinstimmen. </li><li>  <code>port</code> Service kann alles sein.  Verschiedene Dienste können denselben Port verwenden, da sie unterschiedliche IP-Adressen haben. </li></ol><br>  Das folgende Diagramm zeigt alle oben genannten Punkte in grafischer Form: <br><br>  1) Stellen Sie sich vor, der Dienst leitet den Verkehr zu einem bestimmten Pod weiter: <br><br><img src="https://habrastorage.org/webt/2a/e5/8f/2ae58fcgoi7aifmcr5rl_0bseym.png"><br><br>  2) Beim Erstellen eines Pods müssen Sie <code>containerPort</code> für jeden Container in den Pods angeben: <br><br><img src="https://habrastorage.org/webt/xc/fa/ow/xcfaowomhbtqhebhodgzhzrkupc.png"><br><br>  3) Beim Erstellen des Dienstes müssen Sie <code>port</code> und <code>targetPort</code> angeben.  <i>Aber welches verbindet sich mit dem Container?</i> <br><br><img src="https://habrastorage.org/webt/vg/wj/nd/vgwjnde0xyzdblwamomfxjaxb40.png"><br><br>  4) Über <code>targetPort</code> .  Es sollte mit <code>containerPort</code> übereinstimmen. <br><br><img src="https://habrastorage.org/webt/q4/yx/qn/q4yxqnkxxilupalikahmqqp09x8.png"><br><br>  5) Nehmen wir an, Port 3000 ist im Container offen, dann sollte der <code>targetPort</code> Wert gleich sein. <br><br><img src="https://habrastorage.org/webt/cq/tj/-s/cqtj-srznih70qh7bxs3w_l7bis.png"><br><br>  In der YAML-Datei müssen die Bezeichnungen und <code>ports</code> / <code>targetPort</code> übereinstimmen: <br><br><pre> <code class="plaintext hljs">apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment labels: track: canary spec: selector: matchLabels: any-name: my-app template: metadata: labels: # &lt;&lt;&lt; any-name: my-app # &lt;&lt;&lt; spec: containers: - name: cont1 image: learnk8s/app:1.0.0 ports: - containerPort: 8080 # &lt;&lt;&lt; --- apiVersion: v1 kind: Service metadata: name: my-service spec: ports: - port: 80 targetPort: 8080 # &lt;&lt;&lt; selector: # &lt;&lt;&lt; any-name: my-app # &lt;&lt;&lt;</code> </pre> <br>  <i>Was ist mit dem <code>track: canary</code> oben im Bereich Bereitstellung?</i>  <i>Sollte es passen?</i> <br><br>  Diese Bezeichnung bezieht sich auf die Bereitstellung und wird vom Dienst nicht zum Weiterleiten des Datenverkehrs verwendet.  Mit anderen Worten, es kann gelöscht oder ein anderer Wert zugewiesen werden. <br><br>  <i>Was ist mit dem <code>matchLabels</code> Selektor?</i> <br><br>  <b>Es sollte immer mit den Beschriftungen des</b> Pods <b>übereinstimmen</b> , da es von der Bereitstellung zum Verfolgen von Pods verwendet wird. <br><br>  <i>Angenommen, Sie haben die richtigen Änderungen vorgenommen.</i>  <i>Wie prüfe ich sie?</i> <br><br>  Sie können die Pod-Bezeichnung mit dem folgenden Befehl überprüfen: <br><br><pre> <code class="bash hljs">kubectl get pods --show-labels</code> </pre> <br>  Oder, wenn Pods zu mehreren Anwendungen gehören: <br><br><pre> <code class="bash hljs">kubectl get pods --selector any-name=my-app --show-labels</code> </pre> <br>  Wobei <code>any-name=my-app</code> die <code>any-name: my-app</code> . <br><br>  <i>Gibt es irgendwelche Schwierigkeiten?</i> <br><br>  Sie können sich mit dem Pod verbinden!  Verwenden Sie dazu den Befehl <code>port-forward</code> in kubectl.  Hiermit können Sie eine Verbindung zum Dienst herstellen und die Verbindung überprüfen. <br><br><pre> <code class="bash hljs">kubectl port-forward service/&lt;service name&gt; 3000:80</code> </pre> <br>  Hier: <br><br><ul><li>  <code>service/&lt;service name&gt;</code> - Dienstname;  in unserem Fall ist es <code>my-service</code> ; </li><li>  3000 - der Port, den Sie auf dem Computer öffnen möchten; </li><li>  80 - im <code>port</code> des Dienstes angegebener <code>port</code> . </li></ul><br>  Wenn Sie eine Verbindung herstellen konnten, sind die Einstellungen korrekt. <br><br>  Wenn die Verbindung nicht hergestellt werden konnte, liegt ein Problem mit den Beschriftungen vor oder die Anschlüsse stimmen nicht überein. <br><br><h2>  Verbindung von Service und Ingress </h2><br>  Der nächste Schritt zum Bereitstellen des Zugriffs auf die Anwendung bezieht sich auf die Konfiguration von Ingress.  Ingress sollte wissen, wie der Service zu finden ist, und dann die Pods finden und den Verkehr zu ihnen leiten.  Ingress findet den gewünschten Dienst nach Name und offenem Port. <br><br>  In der Beschreibung von Ingress und Service müssen zwei Parameter übereinstimmen: <br><br><ol><li>  <code>servicePort</code> in Ingress muss mit dem <code>servicePort</code> in Service übereinstimmen. </li><li>  <code>serviceName</code> in Ingress muss mit dem <code>serviceName</code> in Service übereinstimmen. </li></ol><br>  Das folgende Diagramm fasst die Verbindung der Ports zusammen: <br><br>  1) Wie Sie bereits wissen, überwacht Service einen bestimmten <code>port</code> : <br><br><img src="https://habrastorage.org/webt/9q/t0/fz/9qt0fzsyme9mnrd4ki07ezamnkg.png"><br><br>  2) Ingress hat einen Parameter namens <code>servicePort</code> : <br><br><img src="https://habrastorage.org/webt/rn/du/yw/rnduyw4xvfmpjmhup8fy9ao2d1a.png"><br><br>  3) Dieser Parameter ( <code>servicePort</code> ) sollte immer mit dem <code>port</code> in der Service-Definition übereinstimmen: <br><br><img src="https://habrastorage.org/webt/1d/ap/ty/1daptyulxphnbb2dt6uben-lnzk.png"><br><br>  4) Wenn unter Service der Port 80 angegeben ist, muss <code>servicePort</code> ebenfalls 80 sein: <br><br><img src="https://habrastorage.org/webt/nc/mi/dl/ncmidlxiegmtmhtozaxxqhznaya.png"><br><br>  In der Praxis müssen Sie folgende Zeilen beachten: <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Service metadata: name: my-service # &lt;&lt;&lt; spec: ports: - port: 80 # &lt;&lt;&lt; targetPort: 8080 selector: any-name: my-app --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: my-ingress spec: rules: - http: paths: - backend: serviceName: my-service # &lt;&lt;&lt; servicePort: 80 # &lt;&lt;&lt; path: /</code> </pre> <br>  <i>Wie überprüfe ich, ob Ingress funktioniert?</i> <br><br>  Sie können die Methode mit <code>kubectl port-forward</code> , müssen jedoch anstelle des Dienstes eine Verbindung zum Ingress-Controller herstellen. <br><br>  Zuerst müssen Sie den Namen des Pods mit dem Ingress-Controller herausfinden: <br><br><pre> <code class="bash hljs">kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS kube-system coredns-5644d7b6d9-jn7cq 1/1 Running kube-system etcd-minikube 1/1 Running kube-system kube-apiserver-minikube 1/1 Running kube-system kube-controller-manager-minikube 1/1 Running kube-system kube-proxy-zvf2h 1/1 Running kube-system kube-scheduler-minikube 1/1 Running kube-system nginx-ingress-controller-6fc5bcc 1/1 Running</code> </pre> <br>  Suchen Sie den Ingress-Pod (er verweist möglicherweise auf einen anderen Namespace) und führen Sie den Befehl <code>describe</code> , um die Portnummern zu ermitteln: <br><br><pre> <code class="bash hljs">kubectl describe pod nginx-ingress-controller-6fc5bcc \ --namespace kube-system \ | grep Ports Ports: 80/TCP, 443/TCP, 18080/TCP</code> </pre> <br>  Zum Schluss verbinden Sie sich mit dem Pod: <br><br><pre> <code class="bash hljs">kubectl port-forward nginx-ingress-controller-6fc5bcc 3000:80 --namespace kube-system</code> </pre> <br>  Jedes Mal, wenn Sie eine Anforderung an Port 3000 auf dem Computer senden, wird diese mit dem Ingress-Controller an Port 80 des Pods umgeleitet.  Wenn Sie <a href="http://localhost:3000/">http: // localhost: 3000</a> aufrufen, sollte die von der Anwendung erstellte Seite angezeigt werden. <br><br><h2>  Port-Zusammenfassung </h2><br>  Erinnern wir uns noch einmal, welche Ports und Labels übereinstimmen sollten: <br><br><ol><li>  Der Selektor in der Service-Definition muss mit der Pod-Bezeichnung übereinstimmen. </li><li>  <code>targetPort</code> in der Service-Definition muss mit dem <code>containerPort</code> Containers im Pod übereinstimmen. </li><li>  <code>port</code> in der Definition von Service kann alles sein.  Verschiedene Dienste können denselben Port verwenden, da sie unterschiedliche IP-Adressen haben. </li><li>  <code>servicePort</code> Ingress muss mit dem <code>port</code> in der Service-Definition übereinstimmen. </li><li>  Der Servicename muss mit dem Feld <code>serviceName</code> in Ingress übereinstimmen. </li></ol><br>  Leider reicht es nicht aus, zu wissen, wie Ihre YAML-Konfiguration richtig strukturiert wird. <br><br>  <i>Was passiert, wenn etwas schief geht?</i> <br><br>  Vielleicht startet der Pod nicht oder er stürzt ab. <br><br><h2>  3 Schritte zur Behebung von Anwendungsfehlern in Kubernetes </h2><br>  Bevor Sie ein Deployment debuggen, müssen Sie wissen, wie Kubernetes funktioniert. <br><br>  Da jede auf K8 heruntergeladene Anwendung drei Komponenten enthält, sollten sie in einer bestimmten Reihenfolge von unten nach unten getestet werden. <br><br><ol><li>  Zuerst müssen Sie sicherstellen, dass die Pods funktionieren, dann ... </li><li>  Überprüfen Sie, ob der Service Datenverkehr an die Pods liefert, und führen Sie dann Folgendes aus: </li><li>  Überprüfen Sie, ob Ingress richtig konfiguriert ist. </li></ol><br>  Visuelle Darstellung: <br><br>  1) Starten Sie die Suche nach Problemen sollte von unten sein.  Überprüfen Sie zunächst, ob die Pods <code>Ready</code> und ausgeführt werden: <br><br><img src="https://habrastorage.org/webt/f-/lc/iz/f-lcizmfav5sb1sc7hvu8samwes.png"><br><br>  2) Wenn die Pods <code>Ready</code> , sollten Sie herausfinden, ob der Dienst den Datenverkehr zwischen den Pods verteilt: <br><br><img src="https://habrastorage.org/webt/yg/we/bu/ygwebumu8ga9lmd7krineuw38mq.png"><br><br>  3) Schließlich müssen Sie die Verbindung zwischen dem Dienst und Ingress analysieren: <br><br><img src="https://habrastorage.org/webt/y7/ze/uz/y7zeuzkhzgsdzcjmng2ei4fjrxg.png"><br><br><h2>  1. Diagnostik von Schoten </h2><br>  In den meisten Fällen liegt das Problem beim Pod.  Stellen Sie sicher, dass die Pods betriebsbereit sind.  Sie können dies mit dem folgenden Befehl überprüfen: <br><br><pre> <code class="bash hljs">kubectl get pods NAME READY STATUS RESTARTS AGE app1 0/1 ImagePullBackOff 0 47h app2 0/1 Error 0 47h app3-76f9fcd46b-xbv4k 1/1 Running 1 47h</code> </pre> <br>  In der Ausgabe des obigen Befehls wird der letzte Pod als " <code>Running</code> und " <code>Ready</code> , bei den beiden anderen nicht. <br><br>  <i>Wie kann man verstehen, was schief gelaufen ist?</i> <br><br>  Es gibt vier nützliche Befehle zur Diagnose von Pods: <br><br><ol><li>  <code>kubectl logs &lt; pod'&gt;</code> können Sie Protokolle aus Containern in pod extrahieren. </li><li>  <code>kubectl describe pod &lt; pod'&gt;</code> können Sie eine Liste der mit dem Pod verbundenen Ereignisse anzeigen. </li><li>  <code>kubectl get pod &lt; pod'&gt;</code> können Sie die YAML-Konfiguration des in Kubernetes gespeicherten <code>kubectl get pod &lt; pod'&gt;</code> abrufen. </li><li>  <code>kubectl exec -ti &lt; pod'&gt; bash</code> können Sie eine interaktive Befehlsshell in einem der Pod-Container ausführen </li></ol><br>  <i>Welches soll ich wählen?</i> <br><br>  Tatsache ist, dass es kein universelles Team gibt.  Eine Kombination von diesen sollte verwendet werden. <br><br><h3>  Häufige Probleme mit der Kapsel </h3><br>  Es gibt zwei Haupttypen von Pod-Fehlern: Startfehler und Laufzeitfehler. <br><br>  Startfehler: <br><br><ul><li> <code>ImagePullBackoff</code> </li> <li> <code>ImageInspectError</code> </li> <li> <code>ErrImagePull</code> </li> <li> <code>ErrImageNeverPull</code> </li> <li> <code>RegistryUnavailable</code> </li> <li> <code>InvalidImageName</code> </li> </ul><br>  Laufzeitfehler: <br><br><ul><li> <code>CrashLoopBackOff</code> </li> <li> <code>RunContainerError</code> </li> <li> <code>KillContainerError</code> </li> <li> <code>VerifyNonRootError</code> </li> <li> <code>RunInitContainerError</code> </li> <li> <code>CreatePodSandboxError</code> </li> <li> <code>ConfigPodSandboxError</code> </li> <li> <code>KillPodSandboxError</code> </li> <li> <code>SetupNetworkError</code> </li> <li> <code>TeardownNetworkError</code> </li> </ul><br>  Einige Fehler sind häufiger als andere.  Hier sind einige häufige Fehler und deren Behebung. <br><br><h4>  ImagePullBackOff </h4><br>  Dieser Fehler tritt auf, wenn Kubernetes kein Bild für einen der Pod-Container abrufen kann.  Hier sind die drei häufigsten Gründe dafür: <br><br><ol><li>  Der Bildname wurde falsch angegeben. Sie haben beispielsweise einen Fehler gemacht oder das Bild ist nicht vorhanden. </li><li>  Es wurde ein nicht vorhandenes Tag für das Bild angegeben. </li><li>  Das Image wird in einer privaten Registrierung gespeichert und Kubernetes hat keine Berechtigung, darauf zuzugreifen. </li></ol><br>  Die ersten beiden Gründe sind leicht zu beseitigen - korrigieren Sie einfach den Bildnamen und das Tag.  In letzterem Fall müssen Sie die Anmeldeinformationen für die private Registrierung in Secret eingeben und in Pods Links hinzufügen.  Die Kubernetes-Dokumentation <a href="https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/">enthält ein Beispiel dafür,</a> wie dies getan werden kann. <br><br><h4>  CrashLoopBackOff </h4><br>  Kubenetes löst einen CrashLoopBackOff-Fehler aus, wenn der Container nicht gestartet werden kann.  Dies passiert normalerweise, wenn: <br><br><ol><li>  In der Anwendung ist ein Fehler aufgetreten, der den Start verhindert. </li><li>  Der Container ist <a href="https://stackoverflow.com/questions/41604499/my-kubernetes-pods-keep-crashing-with-crashloopbackoff-but-i-cant-find-any-lo">falsch konfiguriert</a> . </li><li>  Der Liveness-Test ist zu oft fehlgeschlagen. </li></ol><br>  Sie müssen versuchen, die Protokolle aus dem Container abzurufen, um den Grund für den Fehler herauszufinden.  Wenn der Zugriff auf die Protokolle schwierig ist, weil der Container zu schnell neu gestartet wird, können Sie den folgenden Befehl verwenden: <br><br><pre> <code class="bash hljs">kubectl logs &lt;pod-name&gt; --previous</code> </pre> <br>  Es zeigt Fehlermeldungen von einer früheren Container-Reinkarnation an. <br><br><h4>  RunContainerError </h4><br>  Dieser Fehler tritt auf, wenn der Container nicht gestartet werden kann.  Es entspricht dem Moment vor dem Start der Anwendung.  Normalerweise ist die Ursache eine falsche Konfiguration, zum Beispiel: <br><br><ul><li>  Es wird versucht, ein nicht vorhandenes Volume bereitzustellen, z. B. ConfigMap oder Secrets. </li><li>  Versuchen Sie, ein schreibgeschütztes Volume als Lese- / Schreibzugriff bereitzustellen. </li></ul><br>  Der <code>kubectl describe pod &lt;pod-name&gt;</code> eignet sich gut zur Analyse solcher Fehler. <br><br><h3>  Hülsen ausstehend </h3><br>  Nach der Erstellung verbleibt der Pod im Status <code>Pending</code> . <br><br>  <i>Warum passiert das?</i> <br><br>  Hier sind die möglichen Gründe (ich gehe davon aus, dass der Scheduler gut funktioniert): <br><br><ol><li>  Der Cluster verfügt nicht über genügend Ressourcen, z. B. Prozessorleistung und Arbeitsspeicher, um den Pod auszuführen. </li><li>  Das <code>ResourceQuota</code> Objekt wird im entsprechenden Namespace installiert, und das Erstellen eines Pods führt dazu, dass der Namespace das Kontingent überschreitet. </li><li>  Der Pod ist an Pending <code>PersistentVolumeClaim</code> gebunden. </li></ol><br>  In diesem Fall wird empfohlen, den Befehl <code>kubectl describe</code> und den Abschnitt <code>Events</code> überprüfen: <br><br><pre> <code class="bash hljs">kubectl describe pod &lt;pod name&gt;</code> </pre> <br>  Bei Fehlern im Zusammenhang mit <code>ResourceQuotas</code> wird empfohlen, die Clusterprotokolle mit dem Befehl anzuzeigen <br><br><pre> <code class="bash hljs">kubectl get events --sort-by=.metadata.creationTimestamp</code> </pre> <br><h3>  Hülsen nicht bereit </h3><br>  Wenn der Pod als "Wird ausgeführt" aufgeführt ist, sich jedoch nicht im Status " <code>Ready</code> , ist die Bereitschaftsprüfung nicht erfolgreich. <br><br>  In diesem Fall stellt der Pod keine Verbindung zum Dienst her und der Datenverkehr fließt nicht dorthin.  Der Readiness-Test ist aufgrund von Anwendungsproblemen fehlgeschlagen.  In diesem Fall müssen Sie den Abschnitt " <code>Events</code> " in der Ausgabe des <code>kubectl describe</code> analysieren, um den Fehler zu finden. <br><br><h2>  2. Diagnose von Diensten </h2><br>  Wenn die Pods als " <code>Running</code> und " <code>Ready</code> , die Anwendung jedoch weiterhin nicht reagiert, sollten Sie die Diensteinstellungen überprüfen. <br><br>  Dienste sind abhängig von ihren Bezeichnungen an der Weiterleitung des Datenverkehrs an Pods beteiligt.  Überprüfen Sie daher zunächst, wie viele Pods mit dem Service zusammenarbeiten.  Dazu können Sie die Endpunkte im Service überprüfen: <br><br><pre> <code class="bash hljs">kubectl describe service &lt;service-name&gt; | grep Endpoints</code> </pre> <br>  Endpunkt ist ein Wertepaar der Form <code>&lt;IP-:&gt;</code> , und mindestens ein solches Paar muss in der Ausgabe vorhanden sein (dh, mindestens ein Pod arbeitet mit dem Service zusammen). <br><br>  Wenn der Abschnitt <code>Endpoins</code> leer ist, sind zwei Optionen möglich: <br><br><ol><li>  Es gibt keine Pods mit der richtigen Bezeichnung (Hinweis: Überprüfen Sie, ob der Namespace richtig ausgewählt ist). </li><li>  Es liegt ein Fehler in den Dienstetiketten im Selektor vor. </li></ol><br>  Wenn Sie eine Liste mit Endpunkten sehen, aber immer noch nicht auf die Anwendung zugreifen können, ist der wahrscheinliche Schuldige der Fehler in <code>targetPort</code> in der Servicebeschreibung. <br><br>  <i>Wie überprüfe ich die Servicefreundlichkeit?</i> <br><br>  Unabhängig von der Art des Dienstes können Sie mit dem <code>kubectl port-forward</code> eine Verbindung herstellen: <br><br><pre> <code class="bash hljs">kubectl port-forward service/&lt;service-name&gt; 3000:80</code> </pre> <br>  Hier: <br><br><ul><li>  <code>&lt;service-name&gt;</code> - der Name des Dienstes; </li><li>  3000 - der Port, den Sie auf dem Computer öffnen; </li><li>  80 - Port auf der Serviceseite. </li></ul><br><h2>  3. Ingress-Diagnose </h2><br>  Wenn Sie bis zu diesem Ort gelesen haben, dann: <br><br><ul><li>  Die Pods sind als " <code>Running</code> und " <code>Ready</code> . </li><li>  Der Dienst verteilt den Datenverkehr erfolgreich auf die Pods. </li></ul><br>  Sie können jedoch immer noch nicht auf die Anwendung zugreifen. <br><br>  Dies bedeutet, dass der Ingress-Controller höchstwahrscheinlich falsch konfiguriert ist.  Da der Ingress-Controller eine Komponente eines Drittanbieters im Cluster ist, gibt es je nach Typ verschiedene Debugging-Methoden. <br><br>  Bevor Sie jedoch zum Konfigurieren von Ingress auf spezielle Tools zurückgreifen, können Sie etwas ganz Einfaches tun.  Ingress verwendet <code>serviceName</code> und <code>servicePort</code> , um eine Verbindung zum Dienst <code>servicePort</code> .  Sie müssen überprüfen, ob sie richtig konfiguriert sind.  Sie können dies mit dem folgenden Befehl tun: <br><br><pre> <code class="bash hljs">kubectl describe ingress &lt;ingress-name&gt;</code> </pre> <br>  Wenn die Spalte <code>Backend</code> leer ist, besteht eine hohe Wahrscheinlichkeit eines Konfigurationsfehlers.  Wenn die Backends vorhanden sind, aber immer noch kein Zugriff auf die Anwendung besteht, kann das Problem folgende Ursachen haben: <br><br><ul><li>  Einstellungen für die Ingress-Erreichbarkeit aus dem öffentlichen Internet; </li><li>  Einstellungen für die Cluster-Zugänglichkeit aus dem öffentlichen Internet. </li></ul><br>  Sie können Infrastrukturprobleme identifizieren, indem Sie eine direkte Verbindung zum Ingress-Pod herstellen.  Suchen Sie dazu zuerst den Pod des Ingress-Controllers (möglicherweise in einem anderen Namespace): <br><br><pre> <code class="bash hljs">kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS kube-system coredns-5644d7b6d9-jn7cq 1/1 Running kube-system etcd-minikube 1/1 Running kube-system kube-apiserver-minikube 1/1 Running kube-system kube-controller-manager-minikube 1/1 Running kube-system kube-proxy-zvf2h 1/1 Running kube-system kube-scheduler-minikube 1/1 Running kube-system nginx-ingress-controller-6fc5bcc 1/1 Running</code> </pre> <br>  Verwenden Sie den Befehl <code>describe</code> , um den Port festzulegen: <br><br><pre> <code class="bash hljs">kubectl describe pod nginx-ingress-controller-6fc5bcc --namespace kube-system \ | grep Ports</code> </pre> <br>  Zum Schluss verbinden Sie sich mit dem Pod: <br><br><pre> <code class="bash hljs">kubectl port-forward nginx-ingress-controller-6fc5bcc 3000:80 --namespace kube-system</code> </pre> <br>  Jetzt werden alle Anforderungen für den Port 3000 auf dem Computer an den Port 80-Pod umgeleitet. <br><br>  <i>Funktioniert es jetzt</i> <br><br><ul><li>  Wenn ja, liegt das Problem in der Infrastruktur.  Es muss genau herausgefunden werden, wie der Datenverkehr zum Cluster geleitet wird. </li><li>  Wenn nicht, liegt das Problem beim Ingress-Controller. </li></ul><br>  Wenn Sie den Ingress-Controller nicht zum Laufen bringen können, müssen Sie ihn debuggen. <br><br>  Es gibt viele verschiedene Arten von Ingress-Controllern.  Am beliebtesten sind Nginx, HAProxy, Traefik und andere. <i>(Weitere Informationen zu vorhandenen Lösungen finden Sie in <a href="https://habr.com/ru/company/flant/blog/447180/">unserem Testbericht</a> .)</i> Verwenden Sie die Anleitung zur Fehlerbehebung in der Dokumentation des entsprechenden Controllers.  Da <a href="https://github.com/kubernetes/ingress-nginx">Ingress Nginx</a> der beliebteste Ingress-Controller ist, enthält dieser Artikel einige Tipps zur Behebung verwandter Probleme. <br><br><h3>  Debuggen eines Ingress Nginx-Controllers </h3><br><br>  Das Ingress-Nginx-Projekt hat ein offizielles <a href="https://kubernetes.github.io/ingress-nginx/kubectl-plugin/">Plugin für Kubectl</a> .  Der <code>kubectl ingress-nginx</code> kann verwendet werden, um: <br><br><ul><li>  Analyse von Logs, Backends, Zertifikaten usw .; </li><li>  Verbindung zu Ingress; </li><li>  Studieren der aktuellen Konfiguration. </li></ul><br>  Die folgenden drei Teams helfen Ihnen dabei: <br><br><ul><li>  <code>kubectl ingress-nginx lint</code> - prüft <code>nginx.conf</code> ; </li><li>  <code>kubectl ingress-nginx backend</code> - untersucht das Backend (ähnlich wie <code>kubectl describe ingress &lt;ingress-name&gt;</code> ); </li><li>  <code>kubectl ingress-nginx logs</code> - prüft logs. </li></ul><br>  Beachten Sie, dass es in einigen Fällen erforderlich sein kann, den richtigen Namespace für den Ingress-Controller mithilfe des <code>--namespace &lt;name&gt;</code> . <br><br><h2>  Zusammenfassung </h2><br>  Die Diagnose von Kubernetes kann eine entmutigende Aufgabe sein, wenn Sie nicht wissen, wo Sie anfangen sollen.  Das Problem sollte immer nach dem Bottom-up-Prinzip angegangen werden: Beginnen Sie mit Pods und gehen Sie dann zu Service und Ingress.  Die im Artikel beschriebenen Debugging-Methoden können auf andere Objekte angewendet werden, z. <br><br><ul><li>  Leerlaufjobs und CronJobs; </li><li>  StatefulSets und DaemonSets. </li></ul><br>  Vielen Dank an <a href="https://github.com/errge">Gergely Risko</a> , <a href="https://medium.com/%40weibeld">Daniel Weibel</a> und <a href="https://www.linkedin.com/in/charles-christyraj-0bab8a36/">Charles Christyraj</a> für wertvolle Kommentare und Ergänzungen. <br><br><h2>  PS vom Übersetzer </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  " <a href="https://habr.com/ru/company/flant/blog/436112/">Kubectl-Debug-Plugin zum Debuggen in Kubernetes-Pods</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/443458/">6 unterhaltsame Systemfehler im Betrieb von Kubernetes [und deren Lösung]</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/462707/">Tools für Anwendungsentwickler, die auf Kubernetes ausgeführt werden</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/471892/">6 praktische Geschichten aus unserem SRE-Alltag</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de484954/">https://habr.com/ru/post/de484954/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de484936/index.html">Wissen und Kompetenzen im Team: Finden, sehen, pumpen</a></li>
<li><a href="../de484944/index.html">Was ist mir in ACID oder passt nicht zu uns</a></li>
<li><a href="../de484946/index.html">GPR-Modellierung</a></li>
<li><a href="../de484948/index.html">NEC hat ein U-Boot-Kabel mit einem Rekord von 20 Glasfaserpaaren herausgebracht</a></li>
<li><a href="../de484952/index.html">Ersetzen von Redux durch Observables und React Hooks</a></li>
<li><a href="../de484964/index.html">Konfigurieren des Lastenausgleichs in InfoWatch Traffic Monitor</a></li>
<li><a href="../de484966/index.html">Vorgefertigte Vorlage zum Testen mit Spring</a></li>
<li><a href="../de484968/index.html">WPF DataGrid. Kampf um Vorlage</a></li>
<li><a href="../de484972/index.html">Wine 5.0 veröffentlicht</a></li>
<li><a href="../de484974/index.html">Wang Fliesen für Turing Machine Simulation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
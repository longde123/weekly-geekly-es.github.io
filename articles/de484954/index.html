<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßì üëäüèΩ üë®üèæ‚Äçüîß Visuelle Fehlerbehebung f√ºr Kubernetes üò∫ üëéüèø ü•®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hinweis perev. : Dieser Artikel ist Teil des frei verf√ºgbaren Materials aus dem learnk8s- Projekt, in dem Sie lernen , wie Sie mit Kubernetes-Unterneh...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Visuelle Fehlerbehebung f√ºr Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/484954/">  <i><b>Hinweis</b></i>  <i><b>perev.</b></i>  <i>: Dieser Artikel ist Teil des frei verf√ºgbaren Materials aus dem <a href="https://learnk8s.io/">learnk8s-</a> Projekt, in dem Sie <a href="https://learnk8s.io/">lernen</a> , wie Sie mit Kubernetes-Unternehmen und einzelnen Administratoren arbeiten.</i>  <i>Darin gibt Daniele Polencic, der Projektmanager, eine klare Anweisung, welche Schritte bei allgemeinen Problemen f√ºr Anwendungen im K8s-Cluster zu unternehmen sind.</i> <br><br><img src="https://habrastorage.org/webt/ch/5u/xa/ch5uxanj-3ivwqu88swqyoi6bsu.png"><br><br>  TL; DR: Hier ist ein Diagramm, das Ihnen beim Debuggen der Bereitstellung in Kubernetes hilft: <a name="habracut"></a><br><br> <a href=""><img src="https://habrastorage.org/webt/4r/qp/si/4rqpsie8dnplkqxahaqntpi2ssw.png"></a> <br><br>  <i>Flussdiagramm zum Auffinden und Beheben von Fehlern in einem Cluster.</i>  <i>Im Original (auf Englisch) ist es als <a href="https://learnk8s.io/a/troubleshooting-kubernetes.pdf">PDF</a> und <a href="">als Bild</a> verf√ºgbar.</i> <br><br>  Wenn Sie eine Anwendung auf Kubernetes bereitstellen, m√ºssen Sie normalerweise drei Komponenten definieren: <br><br><ul><li>  <b>Die Bereitstellung</b> ist ein Rezept zum Erstellen von Kopien einer Anwendung namens Pods. </li><li>  <b>Service</b> - ein interner Load Balancer, der den Datenverkehr auf die Pods verteilt; </li><li>  <b>Ingress</b> - Eine Beschreibung, wie der Datenverkehr von der Au√üenwelt zum Service flie√üt. </li></ul><br>  Hier ist eine kurze grafische Zusammenfassung: <br><br>  1) In Kubernetes empfangen Anwendungen Datenverkehr von der Au√üenwelt √ºber zwei Ebenen von Load Balancern: interne und externe. <br><br><img src="https://habrastorage.org/webt/3v/cy/z9/3vcyz9a-2ciiqbh9he7idgvo7uy.png"><br><br>  2) Der interne Balancer hei√üt Service, der externe - Ingress. <br><br><img src="https://habrastorage.org/webt/23/mn/zc/23mnzcfo_b3niccdivn4bc4vzei.png"><br><br>  3) Die Bereitstellung erstellt Pods und √ºberwacht sie (sie werden nicht manuell erstellt). <br><br><img src="https://habrastorage.org/webt/4j/c2/h9/4jc2h9pgzbxmkon4ewkbeuf0vhc.png"><br><br>  Angenommen, Sie m√∂chten eine einfache Anwendung a la <i>Hello World</i> bereitstellen.  Die YAML-Konfiguration daf√ºr sieht folgenderma√üen aus: <br><br><pre><code class="plaintext hljs">apiVersion: apps/v1 kind: Deployment # &lt;&lt;&lt; metadata: name: my-deployment labels: track: canary spec: selector: matchLabels: any-name: my-app template: metadata: labels: any-name: my-app spec: containers: - name: cont1 image: learnk8s/app:1.0.0 ports: - containerPort: 8080 --- apiVersion: v1 kind: Service # &lt;&lt;&lt; metadata: name: my-service spec: ports: - port: 80 targetPort: 8080 selector: name: app --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress # &lt;&lt;&lt; metadata: name: my-ingress spec: rules: - http: paths: - backend: serviceName: app servicePort: 80 path: /</code> </pre> <br>  Die Definition ist ziemlich lang und es ist leicht zu verwechseln, wie die Komponenten zueinander in Beziehung stehen. <br><br>  Zum Beispiel: <br><br><ul><li>  Wann sollten Sie Port 80 und wann - 8080 verwenden? </li><li>  Soll ich f√ºr jeden Dienst einen neuen Port erstellen, damit keine Konflikte auftreten? </li><li>  Sind Markennamen wichtig?  Sollten sie √ºberall gleich sein? </li></ul><br>  Bevor wir uns auf das Debuggen konzentrieren, wollen wir uns erinnern, wie die drei Komponenten zueinander in Beziehung stehen.  Beginnen wir mit Bereitstellung und Service. <br><br><h2>  Connection Deployment'a und Service'a </h2><br>  Sie werden √ºberrascht sein, aber Deployments und Service sind in keiner Weise miteinander verbunden.  Stattdessen verweist der Dienst direkt auf Pods, die die Bereitstellung umgehen. <br><br>  Aus diesem Grund interessieren wir uns f√ºr die Beziehung zwischen Pods und Services.  Drei Dinge zu beachten: <br><br><ol><li>  Ein Service- <code>selector</code> muss mit mindestens einem Pod-Etikett √ºbereinstimmen. </li><li>  <code>targetPort</code> muss mit dem <code>containerPort</code> Containers im Pod √ºbereinstimmen. </li><li>  <code>port</code> Service kann alles sein.  Verschiedene Dienste k√∂nnen denselben Port verwenden, da sie unterschiedliche IP-Adressen haben. </li></ol><br>  Das folgende Diagramm zeigt alle oben genannten Punkte in grafischer Form: <br><br>  1) Stellen Sie sich vor, der Dienst leitet den Verkehr zu einem bestimmten Pod weiter: <br><br><img src="https://habrastorage.org/webt/2a/e5/8f/2ae58fcgoi7aifmcr5rl_0bseym.png"><br><br>  2) Beim Erstellen eines Pods m√ºssen Sie <code>containerPort</code> f√ºr jeden Container in den Pods angeben: <br><br><img src="https://habrastorage.org/webt/xc/fa/ow/xcfaowomhbtqhebhodgzhzrkupc.png"><br><br>  3) Beim Erstellen des Dienstes m√ºssen Sie <code>port</code> und <code>targetPort</code> angeben.  <i>Aber welches verbindet sich mit dem Container?</i> <br><br><img src="https://habrastorage.org/webt/vg/wj/nd/vgwjnde0xyzdblwamomfxjaxb40.png"><br><br>  4) √úber <code>targetPort</code> .  Es sollte mit <code>containerPort</code> √ºbereinstimmen. <br><br><img src="https://habrastorage.org/webt/q4/yx/qn/q4yxqnkxxilupalikahmqqp09x8.png"><br><br>  5) Nehmen wir an, Port 3000 ist im Container offen, dann sollte der <code>targetPort</code> Wert gleich sein. <br><br><img src="https://habrastorage.org/webt/cq/tj/-s/cqtj-srznih70qh7bxs3w_l7bis.png"><br><br>  In der YAML-Datei m√ºssen die Bezeichnungen und <code>ports</code> / <code>targetPort</code> √ºbereinstimmen: <br><br><pre> <code class="plaintext hljs">apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment labels: track: canary spec: selector: matchLabels: any-name: my-app template: metadata: labels: # &lt;&lt;&lt; any-name: my-app # &lt;&lt;&lt; spec: containers: - name: cont1 image: learnk8s/app:1.0.0 ports: - containerPort: 8080 # &lt;&lt;&lt; --- apiVersion: v1 kind: Service metadata: name: my-service spec: ports: - port: 80 targetPort: 8080 # &lt;&lt;&lt; selector: # &lt;&lt;&lt; any-name: my-app # &lt;&lt;&lt;</code> </pre> <br>  <i>Was ist mit dem <code>track: canary</code> oben im Bereich Bereitstellung?</i>  <i>Sollte es passen?</i> <br><br>  Diese Bezeichnung bezieht sich auf die Bereitstellung und wird vom Dienst nicht zum Weiterleiten des Datenverkehrs verwendet.  Mit anderen Worten, es kann gel√∂scht oder ein anderer Wert zugewiesen werden. <br><br>  <i>Was ist mit dem <code>matchLabels</code> Selektor?</i> <br><br>  <b>Es sollte immer mit den Beschriftungen des</b> Pods <b>√ºbereinstimmen</b> , da es von der Bereitstellung zum Verfolgen von Pods verwendet wird. <br><br>  <i>Angenommen, Sie haben die richtigen √Ñnderungen vorgenommen.</i>  <i>Wie pr√ºfe ich sie?</i> <br><br>  Sie k√∂nnen die Pod-Bezeichnung mit dem folgenden Befehl √ºberpr√ºfen: <br><br><pre> <code class="bash hljs">kubectl get pods --show-labels</code> </pre> <br>  Oder, wenn Pods zu mehreren Anwendungen geh√∂ren: <br><br><pre> <code class="bash hljs">kubectl get pods --selector any-name=my-app --show-labels</code> </pre> <br>  Wobei <code>any-name=my-app</code> die <code>any-name: my-app</code> . <br><br>  <i>Gibt es irgendwelche Schwierigkeiten?</i> <br><br>  Sie k√∂nnen sich mit dem Pod verbinden!  Verwenden Sie dazu den Befehl <code>port-forward</code> in kubectl.  Hiermit k√∂nnen Sie eine Verbindung zum Dienst herstellen und die Verbindung √ºberpr√ºfen. <br><br><pre> <code class="bash hljs">kubectl port-forward service/&lt;service name&gt; 3000:80</code> </pre> <br>  Hier: <br><br><ul><li>  <code>service/&lt;service name&gt;</code> - Dienstname;  in unserem Fall ist es <code>my-service</code> ; </li><li>  3000 - der Port, den Sie auf dem Computer √∂ffnen m√∂chten; </li><li>  80 - im <code>port</code> des Dienstes angegebener <code>port</code> . </li></ul><br>  Wenn Sie eine Verbindung herstellen konnten, sind die Einstellungen korrekt. <br><br>  Wenn die Verbindung nicht hergestellt werden konnte, liegt ein Problem mit den Beschriftungen vor oder die Anschl√ºsse stimmen nicht √ºberein. <br><br><h2>  Verbindung von Service und Ingress </h2><br>  Der n√§chste Schritt zum Bereitstellen des Zugriffs auf die Anwendung bezieht sich auf die Konfiguration von Ingress.  Ingress sollte wissen, wie der Service zu finden ist, und dann die Pods finden und den Verkehr zu ihnen leiten.  Ingress findet den gew√ºnschten Dienst nach Name und offenem Port. <br><br>  In der Beschreibung von Ingress und Service m√ºssen zwei Parameter √ºbereinstimmen: <br><br><ol><li>  <code>servicePort</code> in Ingress muss mit dem <code>servicePort</code> in Service √ºbereinstimmen. </li><li>  <code>serviceName</code> in Ingress muss mit dem <code>serviceName</code> in Service √ºbereinstimmen. </li></ol><br>  Das folgende Diagramm fasst die Verbindung der Ports zusammen: <br><br>  1) Wie Sie bereits wissen, √ºberwacht Service einen bestimmten <code>port</code> : <br><br><img src="https://habrastorage.org/webt/9q/t0/fz/9qt0fzsyme9mnrd4ki07ezamnkg.png"><br><br>  2) Ingress hat einen Parameter namens <code>servicePort</code> : <br><br><img src="https://habrastorage.org/webt/rn/du/yw/rnduyw4xvfmpjmhup8fy9ao2d1a.png"><br><br>  3) Dieser Parameter ( <code>servicePort</code> ) sollte immer mit dem <code>port</code> in der Service-Definition √ºbereinstimmen: <br><br><img src="https://habrastorage.org/webt/1d/ap/ty/1daptyulxphnbb2dt6uben-lnzk.png"><br><br>  4) Wenn unter Service der Port 80 angegeben ist, muss <code>servicePort</code> ebenfalls 80 sein: <br><br><img src="https://habrastorage.org/webt/nc/mi/dl/ncmidlxiegmtmhtozaxxqhznaya.png"><br><br>  In der Praxis m√ºssen Sie folgende Zeilen beachten: <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Service metadata: name: my-service # &lt;&lt;&lt; spec: ports: - port: 80 # &lt;&lt;&lt; targetPort: 8080 selector: any-name: my-app --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: my-ingress spec: rules: - http: paths: - backend: serviceName: my-service # &lt;&lt;&lt; servicePort: 80 # &lt;&lt;&lt; path: /</code> </pre> <br>  <i>Wie √ºberpr√ºfe ich, ob Ingress funktioniert?</i> <br><br>  Sie k√∂nnen die Methode mit <code>kubectl port-forward</code> , m√ºssen jedoch anstelle des Dienstes eine Verbindung zum Ingress-Controller herstellen. <br><br>  Zuerst m√ºssen Sie den Namen des Pods mit dem Ingress-Controller herausfinden: <br><br><pre> <code class="bash hljs">kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS kube-system coredns-5644d7b6d9-jn7cq 1/1 Running kube-system etcd-minikube 1/1 Running kube-system kube-apiserver-minikube 1/1 Running kube-system kube-controller-manager-minikube 1/1 Running kube-system kube-proxy-zvf2h 1/1 Running kube-system kube-scheduler-minikube 1/1 Running kube-system nginx-ingress-controller-6fc5bcc 1/1 Running</code> </pre> <br>  Suchen Sie den Ingress-Pod (er verweist m√∂glicherweise auf einen anderen Namespace) und f√ºhren Sie den Befehl <code>describe</code> , um die Portnummern zu ermitteln: <br><br><pre> <code class="bash hljs">kubectl describe pod nginx-ingress-controller-6fc5bcc \ --namespace kube-system \ | grep Ports Ports: 80/TCP, 443/TCP, 18080/TCP</code> </pre> <br>  Zum Schluss verbinden Sie sich mit dem Pod: <br><br><pre> <code class="bash hljs">kubectl port-forward nginx-ingress-controller-6fc5bcc 3000:80 --namespace kube-system</code> </pre> <br>  Jedes Mal, wenn Sie eine Anforderung an Port 3000 auf dem Computer senden, wird diese mit dem Ingress-Controller an Port 80 des Pods umgeleitet.  Wenn Sie <a href="http://localhost:3000/">http: // localhost: 3000</a> aufrufen, sollte die von der Anwendung erstellte Seite angezeigt werden. <br><br><h2>  Port-Zusammenfassung </h2><br>  Erinnern wir uns noch einmal, welche Ports und Labels √ºbereinstimmen sollten: <br><br><ol><li>  Der Selektor in der Service-Definition muss mit der Pod-Bezeichnung √ºbereinstimmen. </li><li>  <code>targetPort</code> in der Service-Definition muss mit dem <code>containerPort</code> Containers im Pod √ºbereinstimmen. </li><li>  <code>port</code> in der Definition von Service kann alles sein.  Verschiedene Dienste k√∂nnen denselben Port verwenden, da sie unterschiedliche IP-Adressen haben. </li><li>  <code>servicePort</code> Ingress muss mit dem <code>port</code> in der Service-Definition √ºbereinstimmen. </li><li>  Der Servicename muss mit dem Feld <code>serviceName</code> in Ingress √ºbereinstimmen. </li></ol><br>  Leider reicht es nicht aus, zu wissen, wie Ihre YAML-Konfiguration richtig strukturiert wird. <br><br>  <i>Was passiert, wenn etwas schief geht?</i> <br><br>  Vielleicht startet der Pod nicht oder er st√ºrzt ab. <br><br><h2>  3 Schritte zur Behebung von Anwendungsfehlern in Kubernetes </h2><br>  Bevor Sie ein Deployment debuggen, m√ºssen Sie wissen, wie Kubernetes funktioniert. <br><br>  Da jede auf K8 heruntergeladene Anwendung drei Komponenten enth√§lt, sollten sie in einer bestimmten Reihenfolge von unten nach unten getestet werden. <br><br><ol><li>  Zuerst m√ºssen Sie sicherstellen, dass die Pods funktionieren, dann ... </li><li>  √úberpr√ºfen Sie, ob der Service Datenverkehr an die Pods liefert, und f√ºhren Sie dann Folgendes aus: </li><li>  √úberpr√ºfen Sie, ob Ingress richtig konfiguriert ist. </li></ol><br>  Visuelle Darstellung: <br><br>  1) Starten Sie die Suche nach Problemen sollte von unten sein.  √úberpr√ºfen Sie zun√§chst, ob die Pods <code>Ready</code> und ausgef√ºhrt werden: <br><br><img src="https://habrastorage.org/webt/f-/lc/iz/f-lcizmfav5sb1sc7hvu8samwes.png"><br><br>  2) Wenn die Pods <code>Ready</code> , sollten Sie herausfinden, ob der Dienst den Datenverkehr zwischen den Pods verteilt: <br><br><img src="https://habrastorage.org/webt/yg/we/bu/ygwebumu8ga9lmd7krineuw38mq.png"><br><br>  3) Schlie√ülich m√ºssen Sie die Verbindung zwischen dem Dienst und Ingress analysieren: <br><br><img src="https://habrastorage.org/webt/y7/ze/uz/y7zeuzkhzgsdzcjmng2ei4fjrxg.png"><br><br><h2>  1. Diagnostik von Schoten </h2><br>  In den meisten F√§llen liegt das Problem beim Pod.  Stellen Sie sicher, dass die Pods betriebsbereit sind.  Sie k√∂nnen dies mit dem folgenden Befehl √ºberpr√ºfen: <br><br><pre> <code class="bash hljs">kubectl get pods NAME READY STATUS RESTARTS AGE app1 0/1 ImagePullBackOff 0 47h app2 0/1 Error 0 47h app3-76f9fcd46b-xbv4k 1/1 Running 1 47h</code> </pre> <br>  In der Ausgabe des obigen Befehls wird der letzte Pod als " <code>Running</code> und " <code>Ready</code> , bei den beiden anderen nicht. <br><br>  <i>Wie kann man verstehen, was schief gelaufen ist?</i> <br><br>  Es gibt vier n√ºtzliche Befehle zur Diagnose von Pods: <br><br><ol><li>  <code>kubectl logs &lt; pod'&gt;</code> k√∂nnen Sie Protokolle aus Containern in pod extrahieren. </li><li>  <code>kubectl describe pod &lt; pod'&gt;</code> k√∂nnen Sie eine Liste der mit dem Pod verbundenen Ereignisse anzeigen. </li><li>  <code>kubectl get pod &lt; pod'&gt;</code> k√∂nnen Sie die YAML-Konfiguration des in Kubernetes gespeicherten <code>kubectl get pod &lt; pod'&gt;</code> abrufen. </li><li>  <code>kubectl exec -ti &lt; pod'&gt; bash</code> k√∂nnen Sie eine interaktive Befehlsshell in einem der Pod-Container ausf√ºhren </li></ol><br>  <i>Welches soll ich w√§hlen?</i> <br><br>  Tatsache ist, dass es kein universelles Team gibt.  Eine Kombination von diesen sollte verwendet werden. <br><br><h3>  H√§ufige Probleme mit der Kapsel </h3><br>  Es gibt zwei Haupttypen von Pod-Fehlern: Startfehler und Laufzeitfehler. <br><br>  Startfehler: <br><br><ul><li> <code>ImagePullBackoff</code> </li> <li> <code>ImageInspectError</code> </li> <li> <code>ErrImagePull</code> </li> <li> <code>ErrImageNeverPull</code> </li> <li> <code>RegistryUnavailable</code> </li> <li> <code>InvalidImageName</code> </li> </ul><br>  Laufzeitfehler: <br><br><ul><li> <code>CrashLoopBackOff</code> </li> <li> <code>RunContainerError</code> </li> <li> <code>KillContainerError</code> </li> <li> <code>VerifyNonRootError</code> </li> <li> <code>RunInitContainerError</code> </li> <li> <code>CreatePodSandboxError</code> </li> <li> <code>ConfigPodSandboxError</code> </li> <li> <code>KillPodSandboxError</code> </li> <li> <code>SetupNetworkError</code> </li> <li> <code>TeardownNetworkError</code> </li> </ul><br>  Einige Fehler sind h√§ufiger als andere.  Hier sind einige h√§ufige Fehler und deren Behebung. <br><br><h4>  ImagePullBackOff </h4><br>  Dieser Fehler tritt auf, wenn Kubernetes kein Bild f√ºr einen der Pod-Container abrufen kann.  Hier sind die drei h√§ufigsten Gr√ºnde daf√ºr: <br><br><ol><li>  Der Bildname wurde falsch angegeben. Sie haben beispielsweise einen Fehler gemacht oder das Bild ist nicht vorhanden. </li><li>  Es wurde ein nicht vorhandenes Tag f√ºr das Bild angegeben. </li><li>  Das Image wird in einer privaten Registrierung gespeichert und Kubernetes hat keine Berechtigung, darauf zuzugreifen. </li></ol><br>  Die ersten beiden Gr√ºnde sind leicht zu beseitigen - korrigieren Sie einfach den Bildnamen und das Tag.  In letzterem Fall m√ºssen Sie die Anmeldeinformationen f√ºr die private Registrierung in Secret eingeben und in Pods Links hinzuf√ºgen.  Die Kubernetes-Dokumentation <a href="https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/">enth√§lt ein Beispiel daf√ºr,</a> wie dies getan werden kann. <br><br><h4>  CrashLoopBackOff </h4><br>  Kubenetes l√∂st einen CrashLoopBackOff-Fehler aus, wenn der Container nicht gestartet werden kann.  Dies passiert normalerweise, wenn: <br><br><ol><li>  In der Anwendung ist ein Fehler aufgetreten, der den Start verhindert. </li><li>  Der Container ist <a href="https://stackoverflow.com/questions/41604499/my-kubernetes-pods-keep-crashing-with-crashloopbackoff-but-i-cant-find-any-lo">falsch konfiguriert</a> . </li><li>  Der Liveness-Test ist zu oft fehlgeschlagen. </li></ol><br>  Sie m√ºssen versuchen, die Protokolle aus dem Container abzurufen, um den Grund f√ºr den Fehler herauszufinden.  Wenn der Zugriff auf die Protokolle schwierig ist, weil der Container zu schnell neu gestartet wird, k√∂nnen Sie den folgenden Befehl verwenden: <br><br><pre> <code class="bash hljs">kubectl logs &lt;pod-name&gt; --previous</code> </pre> <br>  Es zeigt Fehlermeldungen von einer fr√ºheren Container-Reinkarnation an. <br><br><h4>  RunContainerError </h4><br>  Dieser Fehler tritt auf, wenn der Container nicht gestartet werden kann.  Es entspricht dem Moment vor dem Start der Anwendung.  Normalerweise ist die Ursache eine falsche Konfiguration, zum Beispiel: <br><br><ul><li>  Es wird versucht, ein nicht vorhandenes Volume bereitzustellen, z. B. ConfigMap oder Secrets. </li><li>  Versuchen Sie, ein schreibgesch√ºtztes Volume als Lese- / Schreibzugriff bereitzustellen. </li></ul><br>  Der <code>kubectl describe pod &lt;pod-name&gt;</code> eignet sich gut zur Analyse solcher Fehler. <br><br><h3>  H√ºlsen ausstehend </h3><br>  Nach der Erstellung verbleibt der Pod im Status <code>Pending</code> . <br><br>  <i>Warum passiert das?</i> <br><br>  Hier sind die m√∂glichen Gr√ºnde (ich gehe davon aus, dass der Scheduler gut funktioniert): <br><br><ol><li>  Der Cluster verf√ºgt nicht √ºber gen√ºgend Ressourcen, z. B. Prozessorleistung und Arbeitsspeicher, um den Pod auszuf√ºhren. </li><li>  Das <code>ResourceQuota</code> Objekt wird im entsprechenden Namespace installiert, und das Erstellen eines Pods f√ºhrt dazu, dass der Namespace das Kontingent √ºberschreitet. </li><li>  Der Pod ist an Pending <code>PersistentVolumeClaim</code> gebunden. </li></ol><br>  In diesem Fall wird empfohlen, den Befehl <code>kubectl describe</code> und den Abschnitt <code>Events</code> √ºberpr√ºfen: <br><br><pre> <code class="bash hljs">kubectl describe pod &lt;pod name&gt;</code> </pre> <br>  Bei Fehlern im Zusammenhang mit <code>ResourceQuotas</code> wird empfohlen, die Clusterprotokolle mit dem Befehl anzuzeigen <br><br><pre> <code class="bash hljs">kubectl get events --sort-by=.metadata.creationTimestamp</code> </pre> <br><h3>  H√ºlsen nicht bereit </h3><br>  Wenn der Pod als "Wird ausgef√ºhrt" aufgef√ºhrt ist, sich jedoch nicht im Status " <code>Ready</code> , ist die Bereitschaftspr√ºfung nicht erfolgreich. <br><br>  In diesem Fall stellt der Pod keine Verbindung zum Dienst her und der Datenverkehr flie√üt nicht dorthin.  Der Readiness-Test ist aufgrund von Anwendungsproblemen fehlgeschlagen.  In diesem Fall m√ºssen Sie den Abschnitt " <code>Events</code> " in der Ausgabe des <code>kubectl describe</code> analysieren, um den Fehler zu finden. <br><br><h2>  2. Diagnose von Diensten </h2><br>  Wenn die Pods als " <code>Running</code> und " <code>Ready</code> , die Anwendung jedoch weiterhin nicht reagiert, sollten Sie die Diensteinstellungen √ºberpr√ºfen. <br><br>  Dienste sind abh√§ngig von ihren Bezeichnungen an der Weiterleitung des Datenverkehrs an Pods beteiligt.  √úberpr√ºfen Sie daher zun√§chst, wie viele Pods mit dem Service zusammenarbeiten.  Dazu k√∂nnen Sie die Endpunkte im Service √ºberpr√ºfen: <br><br><pre> <code class="bash hljs">kubectl describe service &lt;service-name&gt; | grep Endpoints</code> </pre> <br>  Endpunkt ist ein Wertepaar der Form <code>&lt;IP-:&gt;</code> , und mindestens ein solches Paar muss in der Ausgabe vorhanden sein (dh, mindestens ein Pod arbeitet mit dem Service zusammen). <br><br>  Wenn der Abschnitt <code>Endpoins</code> leer ist, sind zwei Optionen m√∂glich: <br><br><ol><li>  Es gibt keine Pods mit der richtigen Bezeichnung (Hinweis: √úberpr√ºfen Sie, ob der Namespace richtig ausgew√§hlt ist). </li><li>  Es liegt ein Fehler in den Dienstetiketten im Selektor vor. </li></ol><br>  Wenn Sie eine Liste mit Endpunkten sehen, aber immer noch nicht auf die Anwendung zugreifen k√∂nnen, ist der wahrscheinliche Schuldige der Fehler in <code>targetPort</code> in der Servicebeschreibung. <br><br>  <i>Wie √ºberpr√ºfe ich die Servicefreundlichkeit?</i> <br><br>  Unabh√§ngig von der Art des Dienstes k√∂nnen Sie mit dem <code>kubectl port-forward</code> eine Verbindung herstellen: <br><br><pre> <code class="bash hljs">kubectl port-forward service/&lt;service-name&gt; 3000:80</code> </pre> <br>  Hier: <br><br><ul><li>  <code>&lt;service-name&gt;</code> - der Name des Dienstes; </li><li>  3000 - der Port, den Sie auf dem Computer √∂ffnen; </li><li>  80 - Port auf der Serviceseite. </li></ul><br><h2>  3. Ingress-Diagnose </h2><br>  Wenn Sie bis zu diesem Ort gelesen haben, dann: <br><br><ul><li>  Die Pods sind als " <code>Running</code> und " <code>Ready</code> . </li><li>  Der Dienst verteilt den Datenverkehr erfolgreich auf die Pods. </li></ul><br>  Sie k√∂nnen jedoch immer noch nicht auf die Anwendung zugreifen. <br><br>  Dies bedeutet, dass der Ingress-Controller h√∂chstwahrscheinlich falsch konfiguriert ist.  Da der Ingress-Controller eine Komponente eines Drittanbieters im Cluster ist, gibt es je nach Typ verschiedene Debugging-Methoden. <br><br>  Bevor Sie jedoch zum Konfigurieren von Ingress auf spezielle Tools zur√ºckgreifen, k√∂nnen Sie etwas ganz Einfaches tun.  Ingress verwendet <code>serviceName</code> und <code>servicePort</code> , um eine Verbindung zum Dienst <code>servicePort</code> .  Sie m√ºssen √ºberpr√ºfen, ob sie richtig konfiguriert sind.  Sie k√∂nnen dies mit dem folgenden Befehl tun: <br><br><pre> <code class="bash hljs">kubectl describe ingress &lt;ingress-name&gt;</code> </pre> <br>  Wenn die Spalte <code>Backend</code> leer ist, besteht eine hohe Wahrscheinlichkeit eines Konfigurationsfehlers.  Wenn die Backends vorhanden sind, aber immer noch kein Zugriff auf die Anwendung besteht, kann das Problem folgende Ursachen haben: <br><br><ul><li>  Einstellungen f√ºr die Ingress-Erreichbarkeit aus dem √∂ffentlichen Internet; </li><li>  Einstellungen f√ºr die Cluster-Zug√§nglichkeit aus dem √∂ffentlichen Internet. </li></ul><br>  Sie k√∂nnen Infrastrukturprobleme identifizieren, indem Sie eine direkte Verbindung zum Ingress-Pod herstellen.  Suchen Sie dazu zuerst den Pod des Ingress-Controllers (m√∂glicherweise in einem anderen Namespace): <br><br><pre> <code class="bash hljs">kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS kube-system coredns-5644d7b6d9-jn7cq 1/1 Running kube-system etcd-minikube 1/1 Running kube-system kube-apiserver-minikube 1/1 Running kube-system kube-controller-manager-minikube 1/1 Running kube-system kube-proxy-zvf2h 1/1 Running kube-system kube-scheduler-minikube 1/1 Running kube-system nginx-ingress-controller-6fc5bcc 1/1 Running</code> </pre> <br>  Verwenden Sie den Befehl <code>describe</code> , um den Port festzulegen: <br><br><pre> <code class="bash hljs">kubectl describe pod nginx-ingress-controller-6fc5bcc --namespace kube-system \ | grep Ports</code> </pre> <br>  Zum Schluss verbinden Sie sich mit dem Pod: <br><br><pre> <code class="bash hljs">kubectl port-forward nginx-ingress-controller-6fc5bcc 3000:80 --namespace kube-system</code> </pre> <br>  Jetzt werden alle Anforderungen f√ºr den Port 3000 auf dem Computer an den Port 80-Pod umgeleitet. <br><br>  <i>Funktioniert es jetzt</i> <br><br><ul><li>  Wenn ja, liegt das Problem in der Infrastruktur.  Es muss genau herausgefunden werden, wie der Datenverkehr zum Cluster geleitet wird. </li><li>  Wenn nicht, liegt das Problem beim Ingress-Controller. </li></ul><br>  Wenn Sie den Ingress-Controller nicht zum Laufen bringen k√∂nnen, m√ºssen Sie ihn debuggen. <br><br>  Es gibt viele verschiedene Arten von Ingress-Controllern.  Am beliebtesten sind Nginx, HAProxy, Traefik und andere. <i>(Weitere Informationen zu vorhandenen L√∂sungen finden Sie in <a href="https://habr.com/ru/company/flant/blog/447180/">unserem Testbericht</a> .)</i> Verwenden Sie die Anleitung zur Fehlerbehebung in der Dokumentation des entsprechenden Controllers.  Da <a href="https://github.com/kubernetes/ingress-nginx">Ingress Nginx</a> der beliebteste Ingress-Controller ist, enth√§lt dieser Artikel einige Tipps zur Behebung verwandter Probleme. <br><br><h3>  Debuggen eines Ingress Nginx-Controllers </h3><br><br>  Das Ingress-Nginx-Projekt hat ein offizielles <a href="https://kubernetes.github.io/ingress-nginx/kubectl-plugin/">Plugin f√ºr Kubectl</a> .  Der <code>kubectl ingress-nginx</code> kann verwendet werden, um: <br><br><ul><li>  Analyse von Logs, Backends, Zertifikaten usw .; </li><li>  Verbindung zu Ingress; </li><li>  Studieren der aktuellen Konfiguration. </li></ul><br>  Die folgenden drei Teams helfen Ihnen dabei: <br><br><ul><li>  <code>kubectl ingress-nginx lint</code> - pr√ºft <code>nginx.conf</code> ; </li><li>  <code>kubectl ingress-nginx backend</code> - untersucht das Backend (√§hnlich wie <code>kubectl describe ingress &lt;ingress-name&gt;</code> ); </li><li>  <code>kubectl ingress-nginx logs</code> - pr√ºft logs. </li></ul><br>  Beachten Sie, dass es in einigen F√§llen erforderlich sein kann, den richtigen Namespace f√ºr den Ingress-Controller mithilfe des <code>--namespace &lt;name&gt;</code> . <br><br><h2>  Zusammenfassung </h2><br>  Die Diagnose von Kubernetes kann eine entmutigende Aufgabe sein, wenn Sie nicht wissen, wo Sie anfangen sollen.  Das Problem sollte immer nach dem Bottom-up-Prinzip angegangen werden: Beginnen Sie mit Pods und gehen Sie dann zu Service und Ingress.  Die im Artikel beschriebenen Debugging-Methoden k√∂nnen auf andere Objekte angewendet werden, z. <br><br><ul><li>  Leerlaufjobs und CronJobs; </li><li>  StatefulSets und DaemonSets. </li></ul><br>  Vielen Dank an <a href="https://github.com/errge">Gergely Risko</a> , <a href="https://medium.com/%40weibeld">Daniel Weibel</a> und <a href="https://www.linkedin.com/in/charles-christyraj-0bab8a36/">Charles Christyraj</a> f√ºr wertvolle Kommentare und Erg√§nzungen. <br><br><h2>  PS vom √úbersetzer </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  " <a href="https://habr.com/ru/company/flant/blog/436112/">Kubectl-Debug-Plugin zum Debuggen in Kubernetes-Pods</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/443458/">6 unterhaltsame Systemfehler im Betrieb von Kubernetes [und deren L√∂sung]</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/462707/">Tools f√ºr Anwendungsentwickler, die auf Kubernetes ausgef√ºhrt werden</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/471892/">6 praktische Geschichten aus unserem SRE-Alltag</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de484954/">https://habr.com/ru/post/de484954/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de484936/index.html">Wissen und Kompetenzen im Team: Finden, sehen, pumpen</a></li>
<li><a href="../de484944/index.html">Was ist mir in ACID oder passt nicht zu uns</a></li>
<li><a href="../de484946/index.html">GPR-Modellierung</a></li>
<li><a href="../de484948/index.html">NEC hat ein U-Boot-Kabel mit einem Rekord von 20 Glasfaserpaaren herausgebracht</a></li>
<li><a href="../de484952/index.html">Ersetzen von Redux durch Observables und React Hooks</a></li>
<li><a href="../de484964/index.html">Konfigurieren des Lastenausgleichs in InfoWatch Traffic Monitor</a></li>
<li><a href="../de484966/index.html">Vorgefertigte Vorlage zum Testen mit Spring</a></li>
<li><a href="../de484968/index.html">WPF DataGrid. Kampf um Vorlage</a></li>
<li><a href="../de484972/index.html">Wine 5.0 ver√∂ffentlicht</a></li>
<li><a href="../de484974/index.html">Wang Fliesen f√ºr Turing Machine Simulation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
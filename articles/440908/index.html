<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëàüèæ üî≤ üïµüèæ Servir todo üë©üèΩ‚ÄçüöÄ üë∑üèª üê´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="No hace mucho tiempo, en una galaxia bastante distante, en un planeta provincial hab√≠a descendientes famosos de monos que eran tan vagos que decidiero...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Servir todo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440908/"> No hace mucho tiempo, en una galaxia bastante distante, en un planeta provincial hab√≠a descendientes famosos de monos que eran tan vagos que decidieron inventar inteligencia artificial.  "Bueno, ¬øqu√©?"  Ellos pensaron.  Es bueno tener en los asesores de la <s>Overmind un</s> "cerebro" que pensar√° por ti cuando sea necesario, tus problemas se pueden resolver r√°pidamente, y es incluso mejor de lo que una criatura viviente puede hacer ... Y, sin pensar en las consecuencias, comenzaron sus monos. Los cerebros inversos y el proceso cognitivo en los bloques de construcci√≥n se desmontan.  Pensaron, pensaron y pensaron, no lo creer√°n: un modelo de neurona, un algoritmo de aprendizaje matem√°tico y luego redes neuronales con diferentes topolog√≠as desplegadas.  Por supuesto, esto no funcion√≥ para decirlo muy bien.  Hubo muchas deficiencias, en comparaci√≥n con la inteligencia natural, pero una cierta gama de problemas, estos modelos nos permitieron resolver con una precisi√≥n razonable.  Y lentamente, las habilidades digitalizadas y serializadas comenzaron a aparecer en forma de modelos de redes neuronales.  Hoy, queridos amantes de la historia del universo, tocaremos la organizaci√≥n e implementaci√≥n de varias habilidades de inteligencia artificial. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sa/gk/cs/sagkcsc7kookhhmkxeppqvi7zue.jpeg"></div><a name="habracut"></a><br>  Sobre la creaci√≥n y capacitaci√≥n de modelos de redes neuronales (habilidades) en Habr√© se escribe mucho, por lo tanto, no hablaremos de eso hoy.  Habiendo entrenado o recibido habilidades de IA serializadas, esperamos usarlas en nuestros sistemas de informaci√≥n objetivo, y aqu√≠ surge un problema.  Lo que funciona en el stand de laboratorio no puede transferirse a la producci√≥n en su forma original, es necesario implementar toda la pila de tecnolog√≠a asociada e incluso realizar modificaciones significativas en la plataforma objetivo (por supuesto, hay excepciones en la forma de CoreML, pero este es un caso especial y solo para equipos Apple).  Adem√°s, existen muchas herramientas para desarrollar y serializar modelos, ¬øes realmente necesario que todos desarrollen una soluci√≥n de integraci√≥n separada?  Adem√°s, incluso en el laboratorio, a menudo es necesario obtener una conclusi√≥n r√°pida del modelo, sin esperar la carga de toda la pila de desarrollo asociada. <br>  Como sugerencia para resolver estos problemas, me gustar√≠a contarles acerca de una herramienta de c√≥digo abierto relativamente nueva, que, tal vez, ser√° √∫til para ustedes al desarrollar proyectos relacionados con la IA. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">0Mind</a> (leer ZeroMind) es un servidor de habilidades gratuito.  La soluci√≥n es un servidor de aplicaciones modular, universal y f√°cilmente extensible con elementos de un marco para servir modelos de aprendizaje autom√°tico heterog√©neos (salida altamente accesible).  El servidor es feo en Python 3 y usa Tornado para el procesamiento de solicitudes as√≠ncronas.  Independientemente del marco de aprendizaje autom√°tico que se utiliz√≥ para preparar y serializar el modelo, 0Mind facilita el uso de una habilidad o grupo de habilidades utilizando la API REST universal.  De hecho, la soluci√≥n es un servidor web as√≠ncrono con una API REST, unificada para trabajar con modelos de habilidades de IA y un conjunto de adaptadores para varios marcos de aprendizaje autom√°tico.  Es posible que haya trabajado con el servicio de tensorflow: esta es una soluci√≥n similar, pero 0Mind no est√° apilado y puede servir varios modelos de diferentes marcos en el mismo puerto.  Por lo tanto, en lugar de implementar toda la pila de tecnolog√≠a para derivar modelos de IA en el sistema de informaci√≥n de destino, puede usar la API REST simple y familiar para la habilidad de inter√©s, adem√°s, el modelo preparado permanece en el servidor y no termina en la distribuci√≥n de software.  Para no confundir una vez m√°s con t√©rminos complejos, pasemos a ejemplos de uso y comencemos a lanzar hechizos de consola. <br><br><h1>  Instalaci√≥n </h1><br>  Aqu√≠ todo es simple: <br><br><pre><code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> git@github.com:MisteryX/0Mind.git 0Mind</code> </pre> <br>  Ahora tenemos una instancia de servidor en funcionamiento.  Instalar las dependencias: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> 0Mind pip3 install -r requirements.txt</code> </pre><br>  O si usas Conda: <br><br><pre> <code class="bash hljs">conda install --yes --file requirements.txt</code> </pre> <br>  Una advertencia importante es que el <a href="">servidor admite varios marcos de</a> aprendizaje autom√°tico y, para no agregarlos todos y no instalarlos, usted mismo decide qu√© marcos de marcos cargar√° en el host con la instancia de 0Mind, instale y configure estas herramientas de forma independiente. <br><br><h1>  Personalizaci√≥n </h1><br>  El punto de entrada o el ejecutable del servidor principal es <b>model_pool.py</b> . <br>  Las posibles opciones de inicio son <b>-c</b> o <b>--config_file</b> con la ruta al archivo de configuraci√≥n.  De manera predeterminada, 0Mind usa el archivo <b>configs / model_pool_config.json</b> como archivo de configuraci√≥n.  El servidor tambi√©n usa el <b>archivo config / logger.json</b> para controlar el registro est√°ndar del m√≥dulo de registro de Python. <br><br>  Con el fin de demostrar las capacidades, podemos dejar intacto el archivo de configuraci√≥n predeterminado.  Lea m√°s sobre la configuraci√≥n en la <a href="">documentaci√≥n oficial</a> . <br><br>  La configuraci√≥n principal del servidor es: id, host, puerto, tareas. <br><br>  <b>id</b> : (n√∫mero) identificador √∫nico del grupo de modelos (utilizado para equilibrar y direccionar en una red distribuida de grupos) <br>  <b>host</b> - (cadena) direcci√≥n de red o nombre de dominio de este host <br>  <b>puerto</b> : (n√∫mero) en qu√© puerto desea alojar el servicio 0Mind (debe estar libre en este host) <br>  <b>tareas</b> : (lista de objetos) una lista de tareas cargadas con el servicio (puede estar vac√≠a).  En la configuraci√≥n predeterminada, se carga el modelo de demostraci√≥n CNN_MNIST preparado por Keras, y lo usaremos para demostrar las capacidades. <br><br>  Par√°metros de configuraci√≥n adicionales (opcionales): <br><br>  <b>model_types</b> : (lista de cadenas) puede limitar los tipos de modelos cargados a este grupo al especificarlos en esta lista.  Si la lista est√° vac√≠a, entonces no hay restricciones. <br><br>  <b>debug</b> : (tipo booleano) es responsable de habilitar o deshabilitar el modo de depuraci√≥n de Tornado.  En modo de depuraci√≥n, en caso de errores, la informaci√≥n de error extendida se devuelve a stdout, lo cual es √∫til cuando se desarrollan extensiones. <br><br><h1>  Las posibilidades </h1><br>  Lo principal en 0Mind es la <a href="">lista de marcos compatibles</a> y las <a href="">caracter√≠sticas de la API REST</a> . <br><br>  Las solicitudes a la API REST se pueden realizar utilizando un navegador o utilidades http.  En esta gu√≠a, as√≠ como en la documentaci√≥n del servidor, utilizaremos cURL como la herramienta m√°s simple y asequible para sistemas abiertos. <br><br>  Actualmente, 0Mind API tiene un total de 10 solicitudes: <br><br>  1. http: // $ HOST: $ PORT / info - informaci√≥n general sobre la instancia de 0Mind <br>  2. http: // $ HOST: $ PORT / info / system: informaci√≥n del sistema sobre el host en el que se ejecuta 0Mind <br>  3. http: // $ HOST: $ PORT / info / task: informaci√≥n sobre la tarea especificada <br>  4. http: // $ HOST: $ PORT / info / tareas - lista de tareas de instancia 0Mind <br>  5. http: // $ HOST: $ PORT / model / list: una lista de identificadores de modelos cargados en el grupo <br>  6. http: // $ HOST: $ PORT / model / info - muestra informaci√≥n de la interfaz sobre el modelo <br>  7. http: // $ HOST: $ PORT / model / load: carga un nuevo modelo en el grupo <br>  8. http: // $ HOST: $ PORT / model / drop: descarga un modelo cargado previamente del grupo <br>  9. http: // $ HOST: $ PORT / model / predict - solicita salida del modelo <br>  10.http: // $ HOST: $ PORT / command / stop - detiene el servicio 0Mind y finaliza su proceso <br><br><h2>  Informacion </h2><br>  Puede iniciar una instancia de servidor, por ejemplo, as√≠: <br><br><pre> <code class="bash hljs">python3 model_pool.py</code> </pre> <br>  Por ejemplo, obtendremos informaci√≥n general sobre una instancia de servidor en ejecuci√≥n: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/info</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"service"</span></span>: <span class="hljs-string"><span class="hljs-string">"ModelPool"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"options"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"debug"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>}, <span class="hljs-attr"><span class="hljs-attr">"version"</span></span>: [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>]}</code> </pre> <br>  Ok, ahora descubrimos qu√© modelos est√°n cargados en el grupo: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/list</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"check_sum"</span></span>: <span class="hljs-string"><span class="hljs-string">"4d8a15e3cc35750f016ce15a43937620"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"models"</span></span>: [<span class="hljs-string"><span class="hljs-string">"1"</span></span>]}</code> </pre> <br>  Ahora aclaremos la interfaz del modelo cargado con el identificador "1": <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/info?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"inputs"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"0"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"conv2d_1_input:0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"shape"</span></span>: [<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]}}, <span class="hljs-attr"><span class="hljs-attr">"outputs"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"0"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"dense_2/Softmax:0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"shape"</span></span>: [<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]}}, <span class="hljs-attr"><span class="hljs-attr">"tool"</span></span>: <span class="hljs-string"><span class="hljs-string">"keras"</span></span>}</code> </pre> <br>  Queda por averiguar con qu√© filtros se carga el modelo.  Para hacer esto, aclaramos los detalles de la tarea de cargar el modelo con el identificador "1": <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/info/task?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_file"</span></span>: <span class="hljs-string"><span class="hljs-string">"ML/models/mnist_cnn_model.keras"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_type"</span></span>: <span class="hljs-string"><span class="hljs-string">"keras"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"input_filters"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"conv2d_1_input:0"</span></span>: [<span class="hljs-string"><span class="hljs-string">"i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter"</span></span>]}, <span class="hljs-attr"><span class="hljs-attr">"output_filters"</span></span>: {}}</code> </pre> <br>  Como puede ver, nuestro modelo tiene un filtro de entrada: i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter y filtra la entrada con el nombre - conv2d_1_input: 0.  Este filtro simplemente convierte el archivo de imagen especificado en un tensor y lo escala de acuerdo con la entrada del modelo.  <a href="">Los filtros</a> son otra gran herramienta generalizada de 0Mind.  Dado que el procesamiento previo y posterior del procesamiento de datos para los modelos es el mismo, simplemente puede acumular estos filtros para un uso r√°pido en el trabajo posterior con otros modelos, indicando la tarea deseada como un atributo para cargar el modelo. <br><br><h2>  Salida de datos del modelo (inferencia) </h2><br>  Bueno, ahora que tenemos toda la informaci√≥n necesaria para la inferencia, podemos sacar una conclusi√≥n del modelo.  Como entrada, usamos la imagen del conjunto de pruebas incluido en la distribuci√≥n 0Mind <b>samples / image5.png</b> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o0/rr/h7/o0rrh7cyclpin4vxxjx9nqaytxc.png"></div><br><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"conv2d_1_input:0": [{"image_file": "samples/image5.png"}]}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/predict?id=1</code> </pre> <br>  La √∫nica entrada del modelo conv2d_1_input: 0 con el filtro i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter son los datos en el formato aceptado por el filtro - [{"image_file": "samples / image5.png"}].  En respuesta de 0Mind, obtenemos la salida del modelo: <br><br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"dense_2/Softmax:0"</span></span>: [[<span class="hljs-number"><span class="hljs-number">2.190017217283827e-21</span></span>, <span class="hljs-number"><span class="hljs-number">1.6761866200587505e-11</span></span>, <span class="hljs-number"><span class="hljs-number">2.2447325167271673e-14</span></span>, <span class="hljs-number"><span class="hljs-number">0.00011080023978138342</span></span>, <span class="hljs-number"><span class="hljs-number">1.881280855367115e-17</span></span>, <span class="hljs-number"><span class="hljs-number">0.9998891353607178</span></span>, <span class="hljs-number"><span class="hljs-number">1.6690393796396863e-16</span></span>, <span class="hljs-number"><span class="hljs-number">9.67975005705668e-12</span></span>, <span class="hljs-number"><span class="hljs-number">1.1265206161566871e-13</span></span>, <span class="hljs-number"><span class="hljs-number">2.086113400079359e-13</span></span>]]}, <span class="hljs-attr"><span class="hljs-attr">"model_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.002135753631591797</span></span>}</code> </pre> <br>  Entonces, la √∫nica salida del modelo "dense_2 / Softmax: 0" (ver informaci√≥n sobre el modelo anterior) nos dio el vector de confianza del modelo en la clasificaci√≥n de esta imagen.  Como puede ver, la probabilidad m√°s alta es 0.99 para una clase con un √≠ndice de 6 (las clases son n√∫meros 0-9), que corresponde al n√∫mero <b>5</b> .  Por lo tanto, el modelo hizo frente con √©xito al reconocimiento del manuscrito y dio una conclusi√≥n con gran confianza.  El tiempo de inferencia del modelo en el host 0Mind fue 0.002135753631591797 segundos, porque  la salida estaba en una CPU x86 normal. <br><br><h2>  Carga y descarga din√°mica de modelos. </h2><br>  Ahora descargue nuestro modelo del grupo: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/drop?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"unload_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.000152587890625</span></span>, <span class="hljs-attr"><span class="hljs-attr">"memory_released"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_id"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>}</code> </pre> <br>  Volvemos a cargar el mismo modelo, pero ahora con un identificador diferente ("nuevo") y un filtro de salida del modelo io_argmax.ArgMaxFilter, que probablemente derivar√° el √≠ndice del vector de confianza del modelo.  Tendremos que cambiar los √≠ndices de las entradas y salidas del modelo, esto se debe a las caracter√≠sticas de Keras: <br><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"id": "new", "output_filters": {"dense_2_1/Softmax:0": ["io_argmax.ArgMaxFilter"]}, "model_file": "ML/models/mnist_cnn_model.keras", "input_filters": {"conv2d_1_input_1:0": ["i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter"]}, "model_type": "keras"}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/load</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"load_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.45618462562561035</span></span>, <span class="hljs-attr"><span class="hljs-attr">"memory_consumed"</span></span>: <span class="hljs-number"><span class="hljs-number">16183296</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_id"</span></span>: <span class="hljs-string"><span class="hljs-string">"new"</span></span>}</code> </pre> <br>  Y ahora le pedimos al modelo que reconozca para nosotros dos im√°genes a la vez en una solicitud <b>samples / image5.png</b> y <b>samples / image1.png</b> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o0/rr/h7/o0rrh7cyclpin4vxxjx9nqaytxc.png"></div><div style="text-align:center;"><img src="https://habrastorage.org/webt/bv/ha/79/bvha79zohijfpxiilvn1w12wze4.png"></div><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"conv2d_1_input:0": [{"image_file": "samples/image5.png"}, {"image_file": "samples/image1.png"}]}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/predict?id=new</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"dense_2_1/Softmax:0"</span></span>: [<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]}, <span class="hljs-attr"><span class="hljs-attr">"model_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.003907206535339355</span></span>}</code> </pre> <br>  El modelo de demostraci√≥n no volvi√≥ a confundirse. <br><br><h1>  Extensi√≥n </h1><br>  Ampliar las capacidades de 0Mind no es dif√≠cil, gracias a su arquitectura modular, el uso de herramientas populares y buenas convenciones de c√≥digo en el proyecto.  Los principales vectores de extensi√≥n pueden ser: <br><br><ol><li>  <a href="">Los adaptadores</a> son clases entre capas para trabajar con nuevos marcos de redes neuronales y aprendizaje autom√°tico. </li><li>  <a href="">Los filtros</a> son manejadores de datos para entrar y salir de modelos de habilidades. </li><li>  <a href="">Controladores de solicitud</a> : le permiten agregar nueva funcionalidad a las solicitudes y respuestas de la API 0Mind. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440908/">https://habr.com/ru/post/440908/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440898/index.html">Marketing de contenidos, publicidad contextual, mejora de la conversi√≥n: 6 gu√≠as √∫tiles de promoci√≥n de inicio</a></li>
<li><a href="../440900/index.html">RESTO pasi√≥n por 200</a></li>
<li><a href="../440902/index.html">La mitad del reino para la IA: cu√°nto ahorran los bancos en aprendizaje autom√°tico, redes neuronales y bots de chat</a></li>
<li><a href="../440904/index.html">Comparaci√≥n de las arquitecturas Viper y MVVM: c√≥mo aplicar ambas</a></li>
<li><a href="../440906/index.html">Seminario web "167-–§–ó. C√≥mo los bancos pueden cumplir los requisitos del Banco Central para los sistemas antifraude ‚Äù- 26 de febrero de 2019, 11:00 hora de Mosc√∫</a></li>
<li><a href="../440910/index.html">¬øPor qu√© los bancos monopolizan blockchain?</a></li>
<li><a href="../440912/index.html">Tal dolor, tal dolor, infraestructura como servicio 1: 0</a></li>
<li><a href="../440914/index.html">Perd√≠ la fe en la industria, me quem√©, pero el culto a la herramienta me salv√≥</a></li>
<li><a href="../440916/index.html">Radiaci√≥n: unidades</a></li>
<li><a href="../440918/index.html">Semana de la seguridad 08: pirateo de VFEMail en vivo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
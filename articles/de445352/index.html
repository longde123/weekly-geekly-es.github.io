<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤰🏽 👩🏾‍🔬 👧🏼 Spark Structured Streaming-Anwendungen auf Kubernetes. Erleben Sie FASTEN RUS 🥩 🛂 👂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Heute werde ich Ihnen erzählen, wie wir es geschafft haben, das Problem der Portierung von Spark Structured Streaming-Anwendungen auf Kubernetes (K8s)...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark Structured Streaming-Anwendungen auf Kubernetes. Erleben Sie FASTEN RUS</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445352/">  Heute werde ich Ihnen erzählen, wie wir es geschafft haben, das Problem der Portierung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spark Structured Streaming-Anwendungen</a> auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes</a> (K8s) und der Implementierung von CI-Streaming zu lösen. <br><a name="habracut"></a><br><h4>  <i><b>Wie hat alles angefangen?</b></i> </h4><br>  Streaming ist eine Schlüsselkomponente der FASTEN RUS BI-Plattform.  Echtzeitdaten werden vom Datumsanalyseteam verwendet, um Betriebsberichte zu erstellen. <br><br>  Streaming-Anwendungen werden mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spark Structured Streaming</a> implementiert.  Dieses Framework bietet eine praktische Datentransformations-API, die unsere Anforderungen hinsichtlich der Geschwindigkeit von Verbesserungen erfüllt. <br><br>  Die Streams selbst stiegen im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AWS EMR-</a> Cluster an.  Daher wurde beim Auslösen eines neuen Streams zum Cluster ein SSH-Skript zum Senden von Spark-Jobs erstellt, wonach die Anwendung gestartet wurde.  Und zuerst schien uns alles zu passen.  Mit der zunehmenden Anzahl von Streams wurde jedoch immer deutlicher, dass CI-Streaming implementiert werden muss, was die Autonomie des Befehls "Analysedatum" beim Starten von Anwendungen zum Bereitstellen von Daten für neue Entitäten erhöhen würde. <br><br>  Und jetzt schauen wir uns an, wie wir dieses Problem durch Portierung von Streaming auf Kubernetes gelöst haben. <br><br><h4>  <i><b>Warum Kubernetes?</b></i> </h4><br>  Kubernetes als Ressourcenmanager hat unsere Anforderungen am besten erfüllt.  Dies ist eine Bereitstellung ohne Ausfallzeiten und eine breite Palette von CI-Implementierungstools auf Kubernetes, einschließlich Helm.  Darüber hinaus verfügte unser Team über ausreichend Fachwissen bei der Implementierung von CI-Pipelines auf K8.  Daher war die Wahl offensichtlich. <br><br><h4>  <i><b>Wie ist das Kubernetes-basierte Spark-Anwendungsverwaltungsmodell organisiert?</b></i> </h4><br><img src="https://habrastorage.org/webt/ms/rz/fv/msrzfvb4_7eqjzokg2cuvplcerm.png"><br><br>  Der Client führt Spark-Submit auf K8s aus.  Ein Anwendungstreiber-Pod wird erstellt.  Kubernetes Scheduler bindet einen Pod an einen Clusterknoten.  Anschließend sendet der Treiber eine Anforderung zum Erstellen von Pods zum Ausführen von Führungskräften. Pods werden erstellt und an Clusterknoten angehängt.  Danach wird ein Standardsatz von Operationen ausgeführt, mit der anschließenden Konvertierung des Anwendungscodes in DAG, der Zerlegung in Stufen, der Aufteilung in Aufgaben und deren Start auf ausführbaren Dateien. <br><br>  Dieses Modell funktioniert recht erfolgreich, wenn Spark-Anwendungen manuell gestartet werden.  Der Ansatz, Spark-Submit außerhalb des Clusters zu starten, passte jedoch nicht zu uns hinsichtlich der CI-Implementierung.  Es musste eine Lösung gefunden werden, mit der Spark direkt auf den Knoten des Clusters ausgeführt werden kann (Spark-Submit ausführen).  Und hier hat das Kubernetes Operator-Modell unsere Anforderungen voll erfüllt. <br><br><h4>  <i><b>Kubernetes Operator als Spark Application Lifecycle Management-Modell</b></i> </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Operator</a> ist ein von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CoreOS</a> vorgeschlagenes Konzept zur Verwaltung von Statefull-Anwendungen in Kubernetes, das die Automatisierung von Betriebsaufgaben umfasst, z. B. das Bereitstellen von Anwendungen, das Neustarten von Anwendungen bei Dateien und das Aktualisieren der Konfiguration von Anwendungen.  Eines der wichtigsten Kubernetes-Operatormuster ist CRD ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CustomResourceDefinitions</a> ), bei dem dem K8s-Cluster benutzerdefinierte Ressourcen hinzugefügt werden, mit denen Sie wiederum mit diesen Ressourcen wie mit nativen Kubernetes-Objekten arbeiten können. <br><br>  Operator ist ein Daemon, der sich im Pod des Clusters befindet und auf die Erstellung / Änderung des Status einer benutzerdefinierten Ressource reagiert. <br><br>  Berücksichtigen Sie dieses Konzept für das Spark-Anwendungslebenszyklusmanagement. <br><br><img src="https://habrastorage.org/webt/an/ei/gt/aneigtq-0jc8fhtryimgh3orfaw.png"><br><br>  Der Benutzer führt den Befehl kubectl apply -f spark-application.yaml aus, wobei spark-application.yaml die Spezifikation der Spark-Anwendung ist.  Der Bediener empfängt das Spark-Anwendungsobjekt und führt die Spark-Übermittlung aus. <br><br>  Wie wir sehen können, umfasst das Kubernetes-Operator-Modell die Verwaltung des Lebenszyklus einer Spark-Anwendung direkt im Kubernetes-Cluster, was ein ernstes Argument für dieses Modell im Zusammenhang mit der Lösung unserer Probleme war. <br><br>  Als Kubernetes-Operator für die Verwaltung von Streaming-Anwendungen wurde die Verwendung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spark-on-k8s-Operators beschlossen</a> .  Dieser Operator bietet eine recht praktische API sowie Flexibilität bei der Konfiguration der Neustartrichtlinie für Spark-Anwendungen (was im Zusammenhang mit der Unterstützung von Streaming-Anwendungen sehr wichtig ist). <br><br><h4>  <i><b>CI-Implementierung</b></i> </h4><br>  Zur Implementierung des CI-Streamings wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitLab CI / CD verwendet</a> .  Die Bereitstellung von Spark-Anwendungen auf K8s wurde mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Helm-</a> Tools durchgeführt. <br><br>  Die Pipeline selbst umfasst zwei Stufen: <br><br><ul><li>  Test - Syntaxprüfung wird durchgeführt, sowie das Rendern von Helm-Vorlagen; </li><li>  Bereitstellen - Bereitstellung von Streaming-Anwendungen in Test- (Entwickler) und Produktumgebungen (Produktumgebungen). </li></ul><br>  Lassen Sie uns diese Phasen genauer betrachten. <br><br>  In der Testphase wird die Spark-Anwendungs- <a href="">Helmvorlage</a> (CRD - <a href="">SparkApplication</a> ) mit umgebungsspezifischen Werten <a href="">gerendert</a> . <br><br>  Die wichtigsten Abschnitte der Helm-Vorlage sind: <br><ol><li>  Funke: <br><ul><li>  version - Apache Spark-Version </li><li>  image - Verwendetes Docker-Image </li></ul></li><li>  nodeSelector - enthält eine Liste (Schlüssel → Wert), die den Beschriftungen der Herde entspricht. </li><li>  Toleranzen - Gibt die Liste der Toleranzen der Spark-Anwendung an. </li><li>  mainClass - Spark-Anwendungsklasse </li><li>  applicationFile - lokaler Pfad, in dem sich das Spark-Anwendungsglas befindet </li><li>  restartPolicy - Richtlinie zum Neustart der Spark-Anwendung <br><ul><li>  Niemals - Die abgeschlossene Spark-Anwendung wird nicht neu gestartet </li><li>  Immer - Die abgeschlossene Spark-Anwendung wird unabhängig vom Grund für den Stopp neu gestartet. </li><li>  OnFailure - Die Spark-Anwendung wird nur im Falle einer Datei neu gestartet </li></ul></li><li>  maxSubmissionRetries - maximale Anzahl von Übermittlungen einer Spark-Anwendung </li><li>  Treiber / Executor: <br><ul><li>  Kerne - Die Anzahl der Kernel, die dem Treiber / Executor zugewiesen sind </li><li>  Instanzen (nur für die Konfiguration von Führungskräften verwendet) - Die Anzahl der Führungskräfte </li><li>  Speicher - Die Menge an Speicher, die dem Treiber / Executor-Prozess zugewiesen ist </li><li>  memoryOverhead - Die Menge an Off-Heap-Speicher, die dem Treiber / Executor zugewiesen ist </li></ul></li><li>  Streams: <br><ul><li>  name - Name der Streaming-Anwendung </li><li>  Argumente - Argumente für die Streaming-Anwendung </li></ul></li><li>  sink - der Pfad zu den Data Lake-Datensätzen in S3 </li></ol><br>  Nach dem Rendern der Vorlage werden Anwendungen mit Helm in der Entwicklertestumgebung bereitgestellt. <br><br>  Die CI-Pipeline wurde ausgearbeitet. <br><br><img src="https://habrastorage.org/webt/ah/za/br/ahzabrhmjpduar2y7ug3xzn90lu.png"><br><br>  Dann starten wir den Deployment-Prod-Job - das Starten von Anwendungen in der Produktion. <br><br>  Wir sind von einer erfolgreichen Arbeitsleistung überzeugt. <br><br><img src="https://habrastorage.org/webt/md/-h/0e/md-h0e0u3mwccnncq7t2qqzaf5i.png"><br><br>  Wie wir unten sehen können, werden die Anwendungen ausgeführt, die Pods befinden sich im Status RUNNING. <br><br><img src="https://habrastorage.org/webt/ce/4i/cc/ce4iccuv7vkzintbor0tyjtae88.png"><br><br><h4>  <i><b>Fazit</b></i> </h4><br>  Durch die Portierung von Spark-strukturierten Streaming-Anwendungen auf K8s und die anschließende Implementierung von CI konnte der Start von Streams für die Bereitstellung von Daten an neue Entitäten automatisiert werden.  Um den nächsten Stream auszulösen, reicht es aus, eine Zusammenführungsanforderung mit einer Beschreibung der Konfiguration der Spark-Anwendung in der yaml-Wertedatei vorzubereiten. Wenn der Job für die Bereitstellung gestartet wird, wird die Datenübermittlung an Data Lake (S3) initiiert.  Diese Lösung stellte die Autonomie des Befehls "Analysedatum" sicher, wenn Aufgaben im Zusammenhang mit dem Hinzufügen neuer Entitäten zum Repository ausgeführt wurden.  Darüber hinaus hat die Portierung des Streamings auf K8s und insbesondere die Verwaltung von Spark-Anwendungen mit dem Kubernetes-Operator spark-on-k8s-operator die Ausfallsicherheit des Streamings erheblich erhöht.  Aber mehr dazu im nächsten Artikel. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de445352/">https://habr.com/ru/post/de445352/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de445340/index.html">Erhöhen Sie die Netzwerksicherheit mithilfe eines Cloud-Analysators</a></li>
<li><a href="../de445344/index.html">OpenVox Unified Communications Platform</a></li>
<li><a href="../de445346/index.html">Wie schreibe ich eine schlechte API</a></li>
<li><a href="../de445348/index.html">SNA Hackathon 2019: Architektur vereinfachen - Funktionen vereinfachen</a></li>
<li><a href="../de445350/index.html">Sonata - SIP-Bereitstellungsserver</a></li>
<li><a href="../de445354/index.html">Objekte in Bildern finden</a></li>
<li><a href="../de445356/index.html">Überblick über den Bereich Mobile bei DUMP-2019: Maximal angewendet und nützlich in der täglichen Arbeit</a></li>
<li><a href="../de445358/index.html">Organisation des Ereignissystems in Unity - mit den Augen eines Spieledesigners</a></li>
<li><a href="../de445360/index.html">5 typische Aufgaben für JavaScript-Interviews: Analyse und Lösungen</a></li>
<li><a href="../de445362/index.html">Das Buch "Distributed Systems. Entwurfsmuster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∞üèΩ üë©üèæ‚Äçüî¨ üëßüèº Spark Structured Streaming-Anwendungen auf Kubernetes. Erleben Sie FASTEN RUS ü•© üõÇ üëÇ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Heute werde ich Ihnen erz√§hlen, wie wir es geschafft haben, das Problem der Portierung von Spark Structured Streaming-Anwendungen auf Kubernetes (K8s)...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark Structured Streaming-Anwendungen auf Kubernetes. Erleben Sie FASTEN RUS</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445352/">  Heute werde ich Ihnen erz√§hlen, wie wir es geschafft haben, das Problem der Portierung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spark Structured Streaming-Anwendungen</a> auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes</a> (K8s) und der Implementierung von CI-Streaming zu l√∂sen. <br><a name="habracut"></a><br><h4>  <i><b>Wie hat alles angefangen?</b></i> </h4><br>  Streaming ist eine Schl√ºsselkomponente der FASTEN RUS BI-Plattform.  Echtzeitdaten werden vom Datumsanalyseteam verwendet, um Betriebsberichte zu erstellen. <br><br>  Streaming-Anwendungen werden mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spark Structured Streaming</a> implementiert.  Dieses Framework bietet eine praktische Datentransformations-API, die unsere Anforderungen hinsichtlich der Geschwindigkeit von Verbesserungen erf√ºllt. <br><br>  Die Streams selbst stiegen im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AWS EMR-</a> Cluster an.  Daher wurde beim Ausl√∂sen eines neuen Streams zum Cluster ein SSH-Skript zum Senden von Spark-Jobs erstellt, wonach die Anwendung gestartet wurde.  Und zuerst schien uns alles zu passen.  Mit der zunehmenden Anzahl von Streams wurde jedoch immer deutlicher, dass CI-Streaming implementiert werden muss, was die Autonomie des Befehls "Analysedatum" beim Starten von Anwendungen zum Bereitstellen von Daten f√ºr neue Entit√§ten erh√∂hen w√ºrde. <br><br>  Und jetzt schauen wir uns an, wie wir dieses Problem durch Portierung von Streaming auf Kubernetes gel√∂st haben. <br><br><h4>  <i><b>Warum Kubernetes?</b></i> </h4><br>  Kubernetes als Ressourcenmanager hat unsere Anforderungen am besten erf√ºllt.  Dies ist eine Bereitstellung ohne Ausfallzeiten und eine breite Palette von CI-Implementierungstools auf Kubernetes, einschlie√ülich Helm.  Dar√ºber hinaus verf√ºgte unser Team √ºber ausreichend Fachwissen bei der Implementierung von CI-Pipelines auf K8.  Daher war die Wahl offensichtlich. <br><br><h4>  <i><b>Wie ist das Kubernetes-basierte Spark-Anwendungsverwaltungsmodell organisiert?</b></i> </h4><br><img src="https://habrastorage.org/webt/ms/rz/fv/msrzfvb4_7eqjzokg2cuvplcerm.png"><br><br>  Der Client f√ºhrt Spark-Submit auf K8s aus.  Ein Anwendungstreiber-Pod wird erstellt.  Kubernetes Scheduler bindet einen Pod an einen Clusterknoten.  Anschlie√üend sendet der Treiber eine Anforderung zum Erstellen von Pods zum Ausf√ºhren von F√ºhrungskr√§ften. Pods werden erstellt und an Clusterknoten angeh√§ngt.  Danach wird ein Standardsatz von Operationen ausgef√ºhrt, mit der anschlie√üenden Konvertierung des Anwendungscodes in DAG, der Zerlegung in Stufen, der Aufteilung in Aufgaben und deren Start auf ausf√ºhrbaren Dateien. <br><br>  Dieses Modell funktioniert recht erfolgreich, wenn Spark-Anwendungen manuell gestartet werden.  Der Ansatz, Spark-Submit au√üerhalb des Clusters zu starten, passte jedoch nicht zu uns hinsichtlich der CI-Implementierung.  Es musste eine L√∂sung gefunden werden, mit der Spark direkt auf den Knoten des Clusters ausgef√ºhrt werden kann (Spark-Submit ausf√ºhren).  Und hier hat das Kubernetes Operator-Modell unsere Anforderungen voll erf√ºllt. <br><br><h4>  <i><b>Kubernetes Operator als Spark Application Lifecycle Management-Modell</b></i> </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Operator</a> ist ein von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CoreOS</a> vorgeschlagenes Konzept zur Verwaltung von Statefull-Anwendungen in Kubernetes, das die Automatisierung von Betriebsaufgaben umfasst, z. B. das Bereitstellen von Anwendungen, das Neustarten von Anwendungen bei Dateien und das Aktualisieren der Konfiguration von Anwendungen.  Eines der wichtigsten Kubernetes-Operatormuster ist CRD ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CustomResourceDefinitions</a> ), bei dem dem K8s-Cluster benutzerdefinierte Ressourcen hinzugef√ºgt werden, mit denen Sie wiederum mit diesen Ressourcen wie mit nativen Kubernetes-Objekten arbeiten k√∂nnen. <br><br>  Operator ist ein Daemon, der sich im Pod des Clusters befindet und auf die Erstellung / √Ñnderung des Status einer benutzerdefinierten Ressource reagiert. <br><br>  Ber√ºcksichtigen Sie dieses Konzept f√ºr das Spark-Anwendungslebenszyklusmanagement. <br><br><img src="https://habrastorage.org/webt/an/ei/gt/aneigtq-0jc8fhtryimgh3orfaw.png"><br><br>  Der Benutzer f√ºhrt den Befehl kubectl apply -f spark-application.yaml aus, wobei spark-application.yaml die Spezifikation der Spark-Anwendung ist.  Der Bediener empf√§ngt das Spark-Anwendungsobjekt und f√ºhrt die Spark-√úbermittlung aus. <br><br>  Wie wir sehen k√∂nnen, umfasst das Kubernetes-Operator-Modell die Verwaltung des Lebenszyklus einer Spark-Anwendung direkt im Kubernetes-Cluster, was ein ernstes Argument f√ºr dieses Modell im Zusammenhang mit der L√∂sung unserer Probleme war. <br><br>  Als Kubernetes-Operator f√ºr die Verwaltung von Streaming-Anwendungen wurde die Verwendung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spark-on-k8s-Operators beschlossen</a> .  Dieser Operator bietet eine recht praktische API sowie Flexibilit√§t bei der Konfiguration der Neustartrichtlinie f√ºr Spark-Anwendungen (was im Zusammenhang mit der Unterst√ºtzung von Streaming-Anwendungen sehr wichtig ist). <br><br><h4>  <i><b>CI-Implementierung</b></i> </h4><br>  Zur Implementierung des CI-Streamings wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitLab CI / CD verwendet</a> .  Die Bereitstellung von Spark-Anwendungen auf K8s wurde mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Helm-</a> Tools durchgef√ºhrt. <br><br>  Die Pipeline selbst umfasst zwei Stufen: <br><br><ul><li>  Test - Syntaxpr√ºfung wird durchgef√ºhrt, sowie das Rendern von Helm-Vorlagen; </li><li>  Bereitstellen - Bereitstellung von Streaming-Anwendungen in Test- (Entwickler) und Produktumgebungen (Produktumgebungen). </li></ul><br>  Lassen Sie uns diese Phasen genauer betrachten. <br><br>  In der Testphase wird die Spark-Anwendungs- <a href="">Helmvorlage</a> (CRD - <a href="">SparkApplication</a> ) mit umgebungsspezifischen Werten <a href="">gerendert</a> . <br><br>  Die wichtigsten Abschnitte der Helm-Vorlage sind: <br><ol><li>  Funke: <br><ul><li>  version - Apache Spark-Version </li><li>  image - Verwendetes Docker-Image </li></ul></li><li>  nodeSelector - enth√§lt eine Liste (Schl√ºssel ‚Üí Wert), die den Beschriftungen der Herde entspricht. </li><li>  Toleranzen - Gibt die Liste der Toleranzen der Spark-Anwendung an. </li><li>  mainClass - Spark-Anwendungsklasse </li><li>  applicationFile - lokaler Pfad, in dem sich das Spark-Anwendungsglas befindet </li><li>  restartPolicy - Richtlinie zum Neustart der Spark-Anwendung <br><ul><li>  Niemals - Die abgeschlossene Spark-Anwendung wird nicht neu gestartet </li><li>  Immer - Die abgeschlossene Spark-Anwendung wird unabh√§ngig vom Grund f√ºr den Stopp neu gestartet. </li><li>  OnFailure - Die Spark-Anwendung wird nur im Falle einer Datei neu gestartet </li></ul></li><li>  maxSubmissionRetries - maximale Anzahl von √úbermittlungen einer Spark-Anwendung </li><li>  Treiber / Executor: <br><ul><li>  Kerne - Die Anzahl der Kernel, die dem Treiber / Executor zugewiesen sind </li><li>  Instanzen (nur f√ºr die Konfiguration von F√ºhrungskr√§ften verwendet) - Die Anzahl der F√ºhrungskr√§fte </li><li>  Speicher - Die Menge an Speicher, die dem Treiber / Executor-Prozess zugewiesen ist </li><li>  memoryOverhead - Die Menge an Off-Heap-Speicher, die dem Treiber / Executor zugewiesen ist </li></ul></li><li>  Streams: <br><ul><li>  name - Name der Streaming-Anwendung </li><li>  Argumente - Argumente f√ºr die Streaming-Anwendung </li></ul></li><li>  sink - der Pfad zu den Data Lake-Datens√§tzen in S3 </li></ol><br>  Nach dem Rendern der Vorlage werden Anwendungen mit Helm in der Entwicklertestumgebung bereitgestellt. <br><br>  Die CI-Pipeline wurde ausgearbeitet. <br><br><img src="https://habrastorage.org/webt/ah/za/br/ahzabrhmjpduar2y7ug3xzn90lu.png"><br><br>  Dann starten wir den Deployment-Prod-Job - das Starten von Anwendungen in der Produktion. <br><br>  Wir sind von einer erfolgreichen Arbeitsleistung √ºberzeugt. <br><br><img src="https://habrastorage.org/webt/md/-h/0e/md-h0e0u3mwccnncq7t2qqzaf5i.png"><br><br>  Wie wir unten sehen k√∂nnen, werden die Anwendungen ausgef√ºhrt, die Pods befinden sich im Status RUNNING. <br><br><img src="https://habrastorage.org/webt/ce/4i/cc/ce4iccuv7vkzintbor0tyjtae88.png"><br><br><h4>  <i><b>Fazit</b></i> </h4><br>  Durch die Portierung von Spark-strukturierten Streaming-Anwendungen auf K8s und die anschlie√üende Implementierung von CI konnte der Start von Streams f√ºr die Bereitstellung von Daten an neue Entit√§ten automatisiert werden.  Um den n√§chsten Stream auszul√∂sen, reicht es aus, eine Zusammenf√ºhrungsanforderung mit einer Beschreibung der Konfiguration der Spark-Anwendung in der yaml-Wertedatei vorzubereiten. Wenn der Job f√ºr die Bereitstellung gestartet wird, wird die Daten√ºbermittlung an Data Lake (S3) initiiert.  Diese L√∂sung stellte die Autonomie des Befehls "Analysedatum" sicher, wenn Aufgaben im Zusammenhang mit dem Hinzuf√ºgen neuer Entit√§ten zum Repository ausgef√ºhrt wurden.  Dar√ºber hinaus hat die Portierung des Streamings auf K8s und insbesondere die Verwaltung von Spark-Anwendungen mit dem Kubernetes-Operator spark-on-k8s-operator die Ausfallsicherheit des Streamings erheblich erh√∂ht.  Aber mehr dazu im n√§chsten Artikel. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de445352/">https://habr.com/ru/post/de445352/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de445340/index.html">Erh√∂hen Sie die Netzwerksicherheit mithilfe eines Cloud-Analysators</a></li>
<li><a href="../de445344/index.html">OpenVox Unified Communications Platform</a></li>
<li><a href="../de445346/index.html">Wie schreibe ich eine schlechte API</a></li>
<li><a href="../de445348/index.html">SNA Hackathon 2019: Architektur vereinfachen - Funktionen vereinfachen</a></li>
<li><a href="../de445350/index.html">Sonata - SIP-Bereitstellungsserver</a></li>
<li><a href="../de445354/index.html">Objekte in Bildern finden</a></li>
<li><a href="../de445356/index.html">√úberblick √ºber den Bereich Mobile bei DUMP-2019: Maximal angewendet und n√ºtzlich in der t√§glichen Arbeit</a></li>
<li><a href="../de445358/index.html">Organisation des Ereignissystems in Unity - mit den Augen eines Spieledesigners</a></li>
<li><a href="../de445360/index.html">5 typische Aufgaben f√ºr JavaScript-Interviews: Analyse und L√∂sungen</a></li>
<li><a href="../de445362/index.html">Das Buch "Distributed Systems. Entwurfsmuster</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üè¥‚Äç‚ò†Ô∏è üß† üë©üèΩ‚Äçüíª Nous faisons un projet d'apprentissage automatique en Python. 2e partie ‚≠ïÔ∏è üëáüèø üë®üèø‚ÄçüöÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pr√©sentation compl√®te de l'apprentissage automatique en Python: deuxi√®me partie 

 Il peut √™tre difficile de rassembler toutes les parties d'un projet...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nous faisons un projet d'apprentissage automatique en Python. 2e partie</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/425907/"><img src="https://habrastorage.org/getpro/habr/post_images/225/910/6f3/2259106f3ccc19ae2b8b1ec9f316c4f2.png"><br><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©sentation compl√®te de l'apprentissage automatique en Python: deuxi√®me partie</a></i> <br><br>  Il peut √™tre difficile de rassembler toutes les parties d'un projet d'apprentissage automatique.  Dans cette s√©rie d'articles, nous passerons par toutes les √©tapes de la mise en ≈ìuvre du processus d'apprentissage automatique √† l'aide de donn√©es r√©elles, et d√©couvrirons comment les diff√©rentes techniques sont combin√©es entre elles. <br><br>  Dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premier article,</a> nous avons nettoy√© et structur√© les donn√©es, effectu√© une analyse exploratoire, collect√© un ensemble d'attributs √† utiliser dans le mod√®le et d√©fini une base de r√©f√©rence pour √©valuer les r√©sultats.  √Ä l'aide de cet article, nous apprendrons comment impl√©menter en Python et comparer plusieurs mod√®les d'apprentissage automatique, effectuer un r√©glage hyperparam√©trique pour optimiser le meilleur mod√®le et √©valuer les performances du mod√®le final sur un ensemble de donn√©es de test. <br><br>  Tout le code du projet est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur GitHub</a> , et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">voici</a> le deuxi√®me bloc-notes li√© √† l'article actuel.  Vous pouvez utiliser et modifier le code √† votre guise! <br><a name="habracut"></a><br><h2>  √âvaluation et s√©lection du mod√®le </h2><br>  M√©mo: Nous travaillons sur une t√¢che de r√©gression contr√¥l√©e, en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les informations √©nerg√©tiques des b√¢timents de New York</a> pour cr√©er un mod√®le qui pr√©dit le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">score Energy Star qu'un</a> b√¢timent particulier recevra.  Nous nous int√©ressons √† la fois √† l'exactitude des pr√©visions et √† l'interpr√©tabilit√© du mod√®le. <br><br>  Aujourd'hui, vous pouvez choisir parmi les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nombreux mod√®les d'apprentissage automatique disponibles</a> , et cette abondance peut √™tre intimidante.  Bien s√ªr, il existe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des critiques comparatives</a> sur le r√©seau qui vous aideront √† naviguer lors du choix d'un algorithme, mais je pr√©f√®re en essayer quelques-unes et voir laquelle est la meilleure.  Pour l'essentiel, l'apprentissage automatique est bas√© sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des r√©sultats empiriques plut√¥t que th√©oriques</a> , et il est presque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">impossible de comprendre √† l'avance quel mod√®le est le plus pr√©cis</a> . <br><br>  Il est g√©n√©ralement recommand√© de commencer avec des mod√®les simples et interpr√©tables, tels que la r√©gression lin√©aire, et si les r√©sultats ne sont pas satisfaisants, passez √† des m√©thodes plus complexes, mais g√©n√©ralement plus pr√©cises.  Ce graphique (tr√®s anti-scientifique) montre la relation entre la pr√©cision et l'interpr√©tabilit√© de certains algorithmes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1a1/602/9a1/1a16029a1b75b5ba4022d477615f352f.png"><br>  <i>Interpr√©tabilit√© et pr√©cision ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a> ).</i> <br><br>  Nous √©valuerons cinq mod√®les de degr√©s de complexit√© variables: <br><br><ul><li>  R√©gression lin√©aire. </li><li>  La m√©thode des k voisins les plus proches. </li><li>  "For√™t al√©atoire." </li><li>  Augmentation du gradient. </li><li>  M√©thode des vecteurs de support. </li></ul><br>  Nous ne consid√©rerons pas l'appareil th√©orique de ces mod√®les, mais leur mise en ≈ìuvre.  Si vous √™tes int√©ress√© par la th√©orie, consultez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">An Introduction to Statistical Learning</a> (disponible gratuitement) ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hands-On Machine Learning with Scikit-Learn et TensorFlow</a> .  Dans les deux livres, la th√©orie est parfaitement expliqu√©e et l'efficacit√© de l'utilisation des m√©thodes mentionn√©es dans les langages R et Python, respectivement, est montr√©e. <br><br><h4>  Remplissez les valeurs manquantes </h4><br>  Bien que lorsque nous avons effac√© les donn√©es, nous avons supprim√© les colonnes dans lesquelles plus de la moiti√© des valeurs manquent, nous avons encore beaucoup de valeurs.  Les mod√®les d'apprentissage automatique ne peuvent pas fonctionner avec des donn√©es manquantes, nous devons donc les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">remplir</a> . <br><br>  Tout d'abord, nous consid√©rons les donn√©es et nous rappelons √† quoi elles ressemblent: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Read in data into dataframes train_features = pd.read_csv('data/training_features.csv') test_features = pd.read_csv('data/testing_features.csv') train_labels = pd.read_csv('data/training_labels.csv') test_labels = pd.read_csv('data/testing_labels.csv') Training Feature Size: (6622, 64) Testing Feature Size: (2839, 64) Training Labels Size: (6622, 1) Testing Labels Size: (2839, 1)</span></span></code> </pre> <br>  Chaque valeur <code>NaN</code> est un enregistrement manquant dans les donn√©es.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vous pouvez les remplir de diff√©rentes mani√®res</a> , et nous utiliserons la m√©thode d'imputation m√©diane assez simple, qui remplace les donn√©es manquantes par les valeurs moyennes des colonnes correspondantes. <br><br>  Dans le code ci-dessous, nous allons cr√©er un <code>Imputer</code> Imputer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Scikit-Learn</a> avec une strat√©gie m√©diane.  Ensuite, nous l' <code>imputer.fit</code> sur les donn√©es d'entra√Ænement (en utilisant <code>imputer.fit</code> ), et l'appliquons pour remplir les valeurs manquantes dans les ensembles d'apprentissage et de test (en utilisant <code>imputer.transform</code> ).  Autrement dit, les enregistrements manquants dans les <i>donn√©es de test</i> seront remplis avec la valeur m√©diane correspondante <i>des donn√©es d'apprentissage</i> . <br><br>  Nous effectuons le remplissage et ne formons pas le mod√®le sur les donn√©es tel quel, afin d'√©viter le probl√®me de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fuite des donn√©es de test</a> lorsque les informations de l'ensemble de donn√©es de test entrent dans la formation. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Create an imputer object with a median filling strategy imputer = Imputer(strategy='median') # Train on the training features imputer.fit(train_features) # Transform both training data and testing data X = imputer.transform(train_features) X_test = imputer.transform(test_features) Missing values in training features: 0 Missing values in testing features: 0</span></span></code> </pre> <br>  Maintenant que toutes les valeurs sont remplies, il n'y a plus d'espace. <br><br><h4>  Mise √† l'√©chelle des fonctionnalit√©s </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La mise √† l'√©chelle</a> est le processus g√©n√©ral de modification de la plage d'une caract√©ristique.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Il s'agit d'une √©tape n√©cessaire</a> , car les signes sont mesur√©s dans diff√©rentes unit√©s, ce qui signifie qu'ils couvrent diff√©rentes plages.  Cela d√©forme consid√©rablement les r√©sultats d'algorithmes tels que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la</a> m√©thode du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vecteur de support</a> et la m√©thode du plus proche voisin k, qui prennent en compte les distances entre les mesures.  Et la mise √† l'√©chelle vous permet d'√©viter cela.  Bien que des m√©thodes comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la r√©gression lin√©aire et la ¬´for√™t al√©atoire¬ª</a> ne n√©cessitent pas de mise √† l'√©chelle des entit√©s, il est pr√©f√©rable de ne pas n√©gliger cette √©tape lors de la comparaison de plusieurs algorithmes. <br><br>  Nous mettrons √† l'√©chelle en utilisant chaque attribut dans une plage de 0 √† 1. Nous prenons toutes les valeurs de l'attribut, s√©lectionnons le minimum et le divisons par la diff√©rence entre le maximum et le minimum (plage).  Cette m√©thode de mise √† l'√©chelle est souvent appel√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">normalisation, et l'autre moyen principal est la normalisation</a> . <br><br>  Ce processus est facile √† impl√©menter manuellement, nous <code>MinMaxScaler</code> utiliser l'objet <code>MinMaxScaler</code> de Scikit-Learn.  Le code de cette m√©thode est identique au code de remplissage des valeurs manquantes, seule la mise √† l'√©chelle est utilis√©e au lieu de coller.  Rappelons que nous apprenons le mod√®le uniquement sur l'ensemble d'entra√Ænement, puis nous transformons toutes les donn√©es. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Create the scaler object with a range of 0-1 scaler = MinMaxScaler(feature_range=(0, 1)) # Fit on the training data scaler.fit(X) # Transform both the training and testing data X = scaler.transform(X) X_test = scaler.transform(X_test)</span></span></code> </pre> <br>  D√©sormais, chaque attribut a une valeur minimale de 0 et un maximum de 1. Remplissage des valeurs manquantes et mise √† l'√©chelle des attributs - ces deux √©tapes sont n√©cessaires dans presque tous les processus d'apprentissage automatique. <br><br><h4>  Nous impl√©mentons des mod√®les d'apprentissage automatique dans Scikit-Learn </h4><br>  Apr√®s tous les travaux pr√©paratoires, le processus de cr√©ation, de formation et d'ex√©cution de mod√®les est relativement simple.  Nous utiliserons la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Scikit-Learn</a> en Python, qui est magnifiquement document√©e et avec une syntaxe √©labor√©e pour construire des mod√®les.  En apprenant √† cr√©er un mod√®le dans Scikit-Learn, vous pouvez rapidement impl√©menter toutes sortes d'algorithmes. <br><br>  Nous illustrerons le processus de cr√©ation, de formation ( <code>.fit</code> ) et de test ( <code>.predict</code> ) en utilisant le boost de gradient: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GradientBoostingRegressor <span class="hljs-comment"><span class="hljs-comment"># Create the model gradient_boosted = GradientBoostingRegressor() # Fit the model on the training data gradient_boosted.fit(X, y) # Make predictions on the test data predictions = gradient_boosted.predict(X_test) # Evaluate the model mae = np.mean(abs(predictions - y_test)) print('Gradient Boosted Performance on the test set: MAE = %0.4f' % mae) Gradient Boosted Performance on the test set: MAE = 10.0132</span></span></code> </pre> <br>  Une seule ligne de code pour cr√©er, former et tester.  Pour construire d'autres mod√®les, nous utilisons la m√™me syntaxe, en ne changeant que le nom de l'algorithme. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/215/58f/ab4/21558fab42e2669b96132dff6a5b2691.png"><br><br>  Afin d'√©valuer objectivement les mod√®les, nous avons calcul√© le niveau de base en utilisant la valeur m√©diane de l'objectif et obtenu 24,5.  Et les r√©sultats √©taient bien meilleurs, donc notre probl√®me peut √™tre r√©solu en utilisant l'apprentissage automatique. <br><br>  Dans notre cas, l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">augmentation du gradient</a> (MAE = 10.013) s'est av√©r√©e l√©g√®rement meilleure que la "for√™t al√©atoire" (10.014 MAE).  Bien que ces r√©sultats ne puissent pas √™tre consid√©r√©s comme compl√®tement honn√™tes, car pour les hyperparam√®tres, nous utilisons principalement les valeurs par d√©faut.  L'efficacit√© des mod√®les d√©pend fortement de ces param√®tres, en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">particulier dans la m√©thode des vecteurs de support</a> .  N√©anmoins, sur la base de ces r√©sultats, nous choisirons l'augmentation du gradient et commencerons √† l'optimiser. <br><br><h2>  Optimisation de mod√®le hyperparam√©trique </h2><br>  Apr√®s avoir choisi un mod√®le, vous pouvez l'optimiser pour la t√¢che √† r√©soudre en ajustant les param√®tres hyper. <br><br>  Mais tout d'abord, comprenons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce que sont les hyperparam√®tres et comment diff√®rent-ils des param√®tres ordinaires</a> ? <br><br><ul><li>  Les hyperparam√®tres du mod√®le peuvent √™tre consid√©r√©s comme les param√®tres de l'algorithme, que nous avons d√©finis avant le d√©but de sa formation.  Par exemple, l'hyperparam√®tre est le nombre d'arbres dans la "for√™t al√©atoire" ou le nombre de voisins dans la m√©thode k-voisins les plus proches. </li><li>  Param√®tres du mod√®le - ce qu'elle apprend pendant l'entra√Ænement, par exemple, les poids en r√©gression lin√©aire. </li></ul><br>  En contr√¥lant l'hyperparam√®tre, nous influen√ßons les r√©sultats du mod√®le, modifiant l'√©quilibre entre sa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sous-√©ducation et sa reconversion</a> .  Le sous-apprentissage est une situation o√π le mod√®le n'est pas assez complexe (il a trop peu de degr√©s de libert√©) pour √©tudier la correspondance des signes et des objectifs.  Un mod√®le sous-form√© a un biais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©lev√©</a> , qui peut √™tre corrig√© en compliquant le mod√®le. <br><br>  Le recyclage est une situation o√π le mod√®le se souvient essentiellement des donn√©es de formation.  Le mod√®le recycl√© pr√©sente une variance <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©lev√©e</a> , qui peut √™tre ajust√©e en limitant la complexit√© du mod√®le gr√¢ce √† la r√©gularisation.  Les mod√®les sous-form√©s et recycl√©s ne seront pas en mesure de bien g√©n√©raliser les donn√©es de test. <br><br>  La difficult√© de choisir les bons hyperparam√®tres est que pour chaque t√¢che, il y aura un ensemble optimal unique.  Par cons√©quent, la seule fa√ßon de choisir les meilleurs param√®tres est d'essayer diff√©rentes combinaisons sur le nouveau jeu de donn√©es.  Heureusement, Scikit-Learn dispose d'un certain nombre de m√©thodes qui vous permettent d'√©valuer efficacement les hyperparam√®tres.  De plus, des projets comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TPOT</a> tentent d'optimiser la recherche d'hyperparam√®tres en utilisant des approches telles que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la programmation g√©n√©tique</a> .  Dans cet article, nous nous limitons √† utiliser Scikit-Learn. <br><br><h4>  Croiser la recherche al√©atoire </h4><br>  Impl√©mentons une m√©thode de r√©glage hyperparam√©trique appel√©e recherche al√©atoire de validation crois√©e: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Recherche al√©atoire</a> - une technique pour s√©lectionner les hyperparam√®tres.  Nous d√©finissons une grille, puis s√©lectionnons au hasard diverses combinaisons √† partir de celle-ci, contrairement √† la recherche dans la grille, dans laquelle nous essayons successivement chaque combinaison.  Soit dit en passant, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la recherche al√©atoire fonctionne presque aussi bien que la recherche dans la grille</a> , mais beaucoup plus rapidement. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le recoupement</a> est un moyen d'√©valuer la combinaison s√©lectionn√©e d'hyperparam√®tres.  Au lieu de diviser les donn√©es en ensembles de formation et de test, ce qui r√©duit la quantit√© de donn√©es disponibles pour la formation, nous utiliserons la validation crois√©e k-block (validation crois√©e K-Fold).  Pour ce faire, nous diviserons les donn√©es d'apprentissage en k blocs, puis ex√©cuterons le processus it√©ratif, au cours duquel nous formerons d'abord le mod√®le sur k-1 blocs, puis comparerons le r√©sultat lors de l'apprentissage sur le k-√®me bloc.  Nous r√©p√©terons le processus k fois, et √† la fin nous obtiendrons la valeur d'erreur moyenne pour chaque it√©ration.  Ce sera l'√©valuation finale. </li></ul><br>  Voici une illustration graphique de la validation crois√©e du bloc k √† k = 5: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e17/94b/51e/e1794b51eded0314afd9f594a8e9ee5e.png"><br><br>  L'ensemble du processus de recherche al√©atoire de validation crois√©e ressemble √† ceci: <br><br><ol><li>  Nous d√©finissons une grille d'hyperparam√®tres. </li><li>  S√©lectionnez au hasard une combinaison d'hyperparam√®tres. </li><li>  Cr√©ez un mod√®le √† l'aide de cette combinaison. </li><li>  Nous √©valuons le r√©sultat du mod√®le en utilisant la validation crois√©e k-block. </li><li>  Nous d√©cidons quels hyperparam√®tres donnent le meilleur r√©sultat. </li></ol><br>  Bien s√ªr, tout cela ne se fait pas manuellement, mais en utilisant <code>RandomizedSearchCV</code> de Scikit-Learn! <br><br><h4>  Petite digression: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">m√©thodes de renforcement du gradient</a> </h4><br>  Nous utiliserons un mod√®le de r√©gression bas√© sur l'augmentation du gradient.  Il s'agit d'une m√©thode collective, c'est-√†-dire que le mod√®le se compose de nombreux ¬´apprenants faibles¬ª, dans ce cas, √† partir d'arbres de d√©cision distincts.  Si les √©l√®ves apprennent dans des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">algorithmes</a> parall√®les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">comme ¬´for√™t al√©atoire¬ª</a> , puis que le r√©sultat de la pr√©diction est s√©lectionn√© en votant, puis dans des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">algorithmes de renforcement</a> comme le renforcement de gradient, les √©l√®ves apprennent en s√©quence, et chacun d'eux ¬´se concentre¬ª sur les erreurs commises par ses pr√©d√©cesseurs. <br><br>  Ces derni√®res ann√©es, les algorithmes de stimulation sont devenus populaires et gagnent souvent dans les comp√©titions d'apprentissage automatique.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'amplification du gradient</a> est l'une des impl√©mentations dans lesquelles la descente du gradient est utilis√©e pour minimiser le co√ªt de la fonction.  L'impl√©mentation de l'augmentation de gradient dans Scikit-Learn n'est pas aussi efficace que dans d'autres biblioth√®ques, par exemple, dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">XGBoost</a> , mais elle fonctionne bien sur de petits ensembles de donn√©es et donne des pr√©visions assez pr√©cises. <br><br><h4>  Retour au r√©glage hyperparam√©trique </h4><br>  Dans la r√©gression utilisant le boosting de gradient, il existe de nombreux hyperparam√®tres qui doivent √™tre configur√©s, pour plus de d√©tails, je vous renvoie √† la documentation Scikit-Learn.  Nous optimiserons: <br><br><ul><li>  <code>loss</code> : minimisation de la fonction de perte; </li><li>  <code>n_estimators</code> : nombre d'arbres de d√©cision faibles utilis√©s (arbres de d√©cision); </li><li>  <code>max_depth</code> : profondeur maximale de chaque arbre de d√©cision; </li><li>  <code>min_samples_leaf</code> : le nombre minimum d'exemples qui devraient √™tre dans le n≈ìud feuille de l'arbre de d√©cision; </li><li>  <code>min_samples_split</code> : le nombre minimum d'exemples n√©cessaires pour diviser le n≈ìud d'arbre de d√©cision; </li><li>  <code>max_features</code> : nombre maximal de fonctions utilis√©es pour s√©parer les n≈ìuds. </li></ul><br>  Je ne sais pas si quelqu'un comprend vraiment comment tout cela fonctionne, et la seule fa√ßon de trouver la meilleure combinaison est d'essayer diff√©rentes options. <br><br>  Dans ce code, nous cr√©ons une grille d'hyperparam√®tres, puis cr√©ons un objet <code>RandomizedSearchCV</code> et recherchons en utilisant une validation crois√©e √† 4 blocs pour 25 combinaisons diff√©rentes d'hyperparam√®tres: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Loss function to be optimized loss = ['ls', 'lad', 'huber'] # Number of trees used in the boosting process n_estimators = [100, 500, 900, 1100, 1500] # Maximum depth of each tree max_depth = [2, 3, 5, 10, 15] # Minimum number of samples per leaf min_samples_leaf = [1, 2, 4, 6, 8] # Minimum number of samples to split a node min_samples_split = [2, 4, 6, 10] # Maximum number of features to consider for making splits max_features = ['auto', 'sqrt', 'log2', None] # Define the grid of hyperparameters to search hyperparameter_grid = {'loss': loss, 'n_estimators': n_estimators, 'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf, 'min_samples_split': min_samples_split, 'max_features': max_features} # Create the model to use for hyperparameter tuning model = GradientBoostingRegressor(random_state = 42) # Set up the random search with 4-fold cross validation random_cv = RandomizedSearchCV(estimator=model, param_distributions=hyperparameter_grid, cv=4, n_iter=25, scoring = 'neg_mean_absolute_error', n_jobs = -1, verbose = 1, return_train_score = True, random_state=42) # Fit on the training data random_cv.fit(X, y) After performing the search, we can inspect the RandomizedSearchCV object to find the best model: # Find the best combination of settings random_cv.best_estimator_ GradientBoostingRegressor(loss='lad', max_depth=5, max_features=None, min_samples_leaf=6, min_samples_split=6, n_estimators=500)</span></span></code> </pre> <br>  Vous pouvez utiliser ces r√©sultats pour une recherche dans la grille en s√©lectionnant des param√®tres pour la grille qui sont proches de ces valeurs optimales.  Mais un r√©glage ult√©rieur ne devrait pas am√©liorer consid√©rablement le mod√®le.  Il existe une r√®gle g√©n√©rale: la construction comp√©tente des fonctionnalit√©s aura un impact beaucoup plus important sur la pr√©cision du mod√®le que le param√®tre d'hyperparam√®tre le plus cher.  Il s'agit de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">loi de la baisse de la rentabilit√© par rapport √† l'apprentissage automatique</a> : la conception d'attributs donne le meilleur rendement et le r√©glage hyperparam√©trique n'apporte que des avantages modestes. <br><br>  Pour modifier le nombre d'estimateurs (arbres de d√©cision) tout en pr√©servant les valeurs des autres hyperparam√®tres, une exp√©rience peut √™tre effectu√©e qui d√©montrera le r√¥le de ce param√®tre.  L'impl√©mentation est donn√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , mais voici le r√©sultat: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aca/18e/d51/aca18ed519f22d26c6b78af3324b8614.png"><br><br>  √Ä mesure que le nombre d'arbres utilis√©s par le mod√®le augmente, le niveau d'erreurs pendant la formation et les tests diminue.  Mais les erreurs d'apprentissage diminuent beaucoup plus rapidement et, par cons√©quent, le mod√®le est recycl√©: il montre d'excellents r√©sultats sur les donn√©es d'entra√Ænement, mais il fonctionne moins bien sur les donn√©es de test. <br><br>  Sur les donn√©es de test, la pr√©cision diminue toujours (car le mod√®le voit les bonnes r√©ponses pour le jeu de donn√©es d'apprentissage), mais une baisse significative <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">indique un recyclage</a> .  Ce probl√®me peut √™tre r√©solu en augmentant la quantit√© de donn√©es d'apprentissage ou en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©duisant la complexit√© du mod√®le √† l'aide d'hyperparam√®tres</a> .  Ici, nous n'aborderons pas les hyperparam√®tres, mais je vous recommande de toujours faire attention au probl√®me de la reconversion. <br><br>  Pour notre mod√®le final, nous prendrons 800 √©valuateurs, car cela nous donnera le niveau d'erreur le plus bas dans la validation crois√©e.  Testez maintenant le mod√®le! <br><br><h2>  √âvaluation √† l'aide de donn√©es de test </h2><br>  En tant que personnes responsables, nous avons veill√© √† ce que notre mod√®le n'ait aucunement acc√®s aux donn√©es de test pendant la formation.  Par cons√©quent, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nous pouvons utiliser la pr√©cision lorsque nous travaillons avec des donn√©es de test comme indicateur de</a> qualit√© de mod√®le lorsqu'elles sont admises √† des t√¢ches r√©elles. <br><br>  Nous alimentons les donn√©es de test du mod√®le et calculons l'erreur.  Voici une comparaison des r√©sultats de l'algorithme de renforcement de gradient par d√©faut et de notre mod√®le personnalis√©: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Make predictions on the test set using default and final model default_pred = default_model.predict(X_test) final_pred = final_model.predict(X_test) Default model performance on the test set: MAE = 10.0118. Final model performance on the test set: MAE = 9.0446.</span></span></code> </pre> <br>  Le r√©glage hyperparam√©trique a permis d'am√©liorer la pr√©cision du mod√®le d'environ 10%.  Selon la situation, cela peut √™tre une am√©lioration tr√®s importante, mais cela prend beaucoup de temps. <br><br>  Vous pouvez comparer le temps d'entra√Ænement pour les deux mod√®les √† l'aide de la <code>%timeit</code> magic <code>%timeit</code> dans les ordinateurs portables Jupyter.  Tout d'abord, mesurez la dur√©e par d√©faut du mod√®le: <br><br><pre> <code class="python hljs">%%timeit -n <span class="hljs-number"><span class="hljs-number">1</span></span> -r <span class="hljs-number"><span class="hljs-number">5</span></span> default_model.fit(X, y) <span class="hljs-number"><span class="hljs-number">1.09</span></span> s ¬± <span class="hljs-number"><span class="hljs-number">153</span></span> ms per loop (mean ¬± std. dev. of <span class="hljs-number"><span class="hljs-number">5</span></span> runs, <span class="hljs-number"><span class="hljs-number">1</span></span> loop each)</code> </pre> <br>  Une seconde pour √©tudier est tr√®s d√©cente.  Mais le mod√®le r√©gl√© n'est pas si rapide: <br><br><pre> <code class="python hljs">%%timeit -n <span class="hljs-number"><span class="hljs-number">1</span></span> -r <span class="hljs-number"><span class="hljs-number">5</span></span> final_model.fit(X, y) <span class="hljs-number"><span class="hljs-number">12.1</span></span> s ¬± <span class="hljs-number"><span class="hljs-number">1.33</span></span> s per loop (mean ¬± std. dev. of <span class="hljs-number"><span class="hljs-number">5</span></span> runs, <span class="hljs-number"><span class="hljs-number">1</span></span> loop each)</code> </pre> <br>  Cette situation illustre l'aspect fondamental de l'apprentissage automatique: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">il s'agit de compromis</a> .  Il faut constamment choisir un √©quilibre entre pr√©cision et interpr√©tabilit√©, entre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©placement et dispersion</a> , entre pr√©cision et dur√©e de fonctionnement, etc.  La bonne combinaison est compl√®tement d√©termin√©e par la t√¢che sp√©cifique.  Dans notre cas, une augmentation de 12 fois de la dur√©e du travail en termes relatifs est importante, mais en termes absolus, elle est insignifiante. <br><br>  Nous avons obtenu les r√©sultats finaux des pr√©visions, analysons-les maintenant et d√©couvrons s'il y a des √©carts notables.  √Ä gauche, un graphique de la densit√© des valeurs pr√©dites et r√©elles, √† droite, un histogramme de l'erreur: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/817/ea7/f23/817ea7f2371b83ff0ae6ae5fa02b5a1e.png" width="350"><img src="https://habrastorage.org/getpro/habr/post_images/f49/f42/5cc/f49f425cc56d717a1e75b9478d1a24d1.png" width="340"><br><br>  La pr√©vision du mod√®le r√©p√®te bien la distribution des valeurs r√©elles, tandis que sur les donn√©es d'apprentissage, le pic de densit√© est situ√© plus pr√®s de la valeur m√©diane (66) que du pic de densit√© r√©elle (environ 100).  Les erreurs ont une distribution presque normale, bien qu'il existe plusieurs grandes valeurs n√©gatives lorsque les pr√©visions du mod√®le sont tr√®s diff√©rentes des donn√©es r√©elles.  Dans le prochain article, nous examinerons plus en d√©tail l'interpr√©tation des r√©sultats. <br><br><h2>  Conclusion </h2><br>  Dans cet article, nous avons examin√© plusieurs √©tapes de la r√©solution du probl√®me de l'apprentissage automatique: <br><br><ul><li>  Remplissage des valeurs manquantes et des fonctionnalit√©s de mise √† l'√©chelle. </li><li>  √âvaluation et comparaison des r√©sultats de plusieurs mod√®les. </li><li>  R√©glage hyperparam√©trique utilisant la recherche al√©atoire de grille et la validation crois√©e. </li><li>  √âvaluation du meilleur mod√®le √† l'aide de donn√©es de test. </li></ul><br>  Les r√©sultats indiquent que nous pouvons utiliser l'apprentissage automatique pour pr√©dire le score Energy Star sur la base des statistiques disponibles.  √Ä l'aide de l'augmentation du gradient, une erreur de 9,1 a √©t√© obtenue sur les donn√©es de test.  Le r√©glage hyperparam√©trique peut grandement am√©liorer les r√©sultats, mais au prix d'un ralentissement important.  C'est l'un des nombreux compromis √† consid√©rer dans l'apprentissage automatique. <br><br>  Dans le prochain article, nous allons essayer de comprendre comment fonctionne notre mod√®le.  Nous examinerons √©galement les principaux facteurs qui influencent le score Energy Star.  Si nous savons que le mod√®le est pr√©cis, nous essaierons de comprendre pourquoi il pr√©dit ainsi et ce que cela nous apprend sur le probl√®me lui-m√™me. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr425907/">https://habr.com/ru/post/fr425907/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr425897/index.html">Caract√©ristiques de l'utilisation de la biblioth√®que RxJs dans un syst√®me bancaire en ligne</a></li>
<li><a href="../fr425899/index.html">Colline de fourmis ou forteresse? Je construis une maison pour le prix d'un appartement. 1 partie</a></li>
<li><a href="../fr425901/index.html">Station m√©t√©o sur Arduino de A √† Z. Partie 1</a></li>
<li><a href="../fr425903/index.html">Les vacances arrivent: SCRF a doubl√© la bande ISM de 868 MHz</a></li>
<li><a href="../fr425905/index.html">Comment √©crire du code assembleur avec des instructions qui se chevauchent (une autre technique pour masquer le bytecode)</a></li>
<li><a href="../fr425911/index.html">Transf√©rer le cloud CRM vers la version en bo√Æte</a></li>
<li><a href="../fr425915/index.html">Comment les communications transfrontali√®res peuvent remplacer les feux de circulation et raccourcir le chemin du travail</a></li>
<li><a href="../fr425917/index.html">Un combattant de la justice emp√™che Waymo de breveter une technologie lidar cl√©</a></li>
<li><a href="../fr425919/index.html">Cartes hexagonales dans Unity: enregistrement et chargement, textures, distances</a></li>
<li><a href="../fr425921/index.html">R√©union de la communaut√© .NET sur CLRium # 4 + en ligne</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
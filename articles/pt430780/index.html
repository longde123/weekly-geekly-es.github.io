<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖖🏾 💇🏼 🍍 Modelos de sequência-sequência-parte 1 👰🏿 🧀 🤶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bom dia a todos! 

 E novamente abrimos um novo fluxo para o curso Data Scientist revisado: outro excelente professor , um programa ligeiramente refin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Modelos de sequência-sequência-parte 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/430780/">  Bom dia a todos! <br><br>  E novamente abrimos um novo fluxo para o curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Data Scientist</a> revisado: outro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">excelente professor</a> , um programa ligeiramente refinado com base em atualizações.  Bem, como sempre, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lições abertas</a> interessantes e coleções de materiais interessantes.  Hoje começaremos a análise dos modelos seq2seq do Tensor Flow. <br><br>  Vamos lá <br><br>  Como já discutido no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tutorial</a> da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNN</a> (recomendamos que você se familiarize com ele antes de ler este artigo), redes neurais recorrentes podem ser ensinadas a modelar o idioma.  E surge uma pergunta interessante: é possível treinar a rede em determinados dados para gerar uma resposta significativa?  Por exemplo, podemos ensinar uma rede neural a traduzir do inglês para o francês?  Acontece que nós podemos. <br><br>  Este guia mostra como criar e treinar um sistema de ponta a ponta.  Copie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o repositório principal do Tensor Flow</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o repositório do modelo TensorFlow do GitHub</a> .  Em seguida, você pode começar iniciando o programa de tradução: <br><br><pre><code class="python hljs">cd models/tutorials/rnn/translate python translate.py --data_dir [your_data_directory]</code> </pre> <br><img src="https://habrastorage.org/webt/ra/j0/rr/raj0rraitsp6itojzydkhrk2yoi.png"><a name="habracut"></a><br><br>  Ela fará o download dos dados para tradução do inglês para o francês <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no site do WMT'15</a> , preparará-os para treinamento e treinamento.  Isso exigirá cerca de 20 GB no disco rígido e muito tempo para baixar e preparar, para que você possa iniciar o processo agora e continuar lendo este tutorial. <br><br>  O manual acessará os seguintes arquivos: <br><br><table><tbody><tr><th>  Ficheiro </th><th>  O que há nele? </th></tr><tr><td>  tensorflow / tensorflow / python / ops / seq2seq.py </td><td>  Biblioteca para criar modelos de sequência para sequência </td></tr><tr><td>  modelos / tutoriais / rnn / translate / seq2seq_model.py </td><td>  Modelos de tradução neural sequência a sequência </td></tr><tr><td>  modelos / tutoriais / rnn / translate / data_utils.py </td><td>  Funções auxiliares para preparar dados de tradução </td></tr><tr><td>  modelos / tutoriais / rnn / translate / translate.py </td><td>  O binário que treina e executa o modelo de conversão </td></tr></tbody></table><br>  <b>Noções básicas de sequência a sequência</b> <br><br>  O modelo básico de sequência a sequência, conforme apresentado por <a href="">Cho et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ), consiste em duas redes neurais recorrentes (RNNs): um codificador (codificador) que processa os dados de entrada e um decodificador (decodificador) que gera os dados saída.  A arquitetura básica é mostrada abaixo: <br><br><img src="https://habrastorage.org/webt/e-/df/cu/e-dfcuvlsbykvyxvzac9rc0nrow.png"><br><br>  Cada retângulo na figura acima representa uma célula no RNN, geralmente uma célula GRU - um bloco de recorrência controlado ou uma célula LSTM - memória de curto prazo de longo prazo (leia o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tutorial</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNN</a> para saber mais sobre eles).  Codificadores e decodificadores podem ter pesos comuns ou, mais frequentemente, usar diferentes conjuntos de parâmetros.  Células multicamadas foram usadas com sucesso em modelos de sequência a sequência, por exemplo, para traduzir <a href="">Sutskever et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ). <br><br>  No modelo básico descrito acima, cada entrada deve ser codificada em um vetor de estado de tamanho fixo, pois essa é a única coisa que é transmitida ao decodificador.  Para dar ao decodificador acesso mais direto aos dados de entrada, um mecanismo de atenção foi introduzido em <a href="">Bahdanau et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ).  Não entraremos em detalhes do mecanismo de atenção (para isso você pode se familiarizar com o trabalho aqui);  basta dizer que permite que o decodificador analise os dados de entrada em cada etapa de decodificação.  Uma rede sequência a sequência multicamada com células LSTM e o mecanismo de atenção no decodificador são os seguintes: <br><br><img src="https://habrastorage.org/webt/c4/ro/0z/c4ro0zvzu8m-y4qjlnfbhv9x4qa.png"><br><br>  <b>Biblioteca TensorFlow seq2seq</b> <br><br>  Como você pode ver acima, existem diferentes modelos de sequência para sequência.  Todos eles podem usar células RNN diferentes, mas todos aceitam dados de entrada do codificador e dados de entrada do decodificador.  Essa é a base da interface da biblioteca TensorFlow seq2seq (tensorflow / tensorflow / python / ops / seq2seq.py).  Esse modelo básico de RNN, codec, sequência a sequência funciona da seguinte maneira. <br><br><pre> <code class="python hljs">outputs, states = basic_rnn_seq2seq(encoder_inputs, decoder_inputs, cell)</code> </pre> <br>  Na chamada indicada acima, <code>encoder_inputs</code> é uma lista de tensores que representam os dados de entrada do codificador, correspondendo às letras A, B, C da figura acima.  Da mesma forma, <code>decoder_inputs</code> são tensores que representam dados de entrada do decodificador.  GO, W, X, Y, Z da primeira foto. <br><br>  O argumento <code>cell</code> é uma instância da classe <code>tf.contrib.rnn.RNNCell</code> que determina qual célula será usada no modelo.  Você pode usar células existentes, por exemplo, <code>GRUCell</code> ou <code>LSTMCell</code> , ou pode escrever suas próprias.  Além disso, o <code>tf.contrib.rnn</code> fornece shells para criar células de <code>tf.contrib.rnn</code> camadas, adicionando exceções à entrada e saída de células ou outras transformações.  Confira o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tutorial</a> da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNN</a> para obter exemplos. <br><br>  A chamada <code>basic_rnn_seq2seq</code> retorna dois argumentos: <code>outputs</code> e <code>states</code> .  Ambos representam uma lista de tensores do mesmo comprimento que <code>decoder_inputs</code> .  <code>outputs</code> correspondem aos dados de saída do decodificador a cada passo, na primeira imagem são W, X, Y, Z, EOS.  Os <code>states</code> retornados representam o estado interno do decodificador em cada etapa do tempo. <br><br>  Em muitas aplicações que usam o modelo de sequência a sequência, a saída do decodificador no tempo t é retornada à entrada do decodificador no tempo t + 1.  Durante o teste, durante a decodificação de sequência, é assim que uma nova é construída.  Por outro lado, durante o treinamento, é habitual transmitir ao decodificador os dados de entrada corretos a cada passo, mesmo que o decodificador tenha sido previamente confundido.  As funções no <code>seq2seq.py</code> suportam os dois modos com o argumento <code>feed_previous</code> .  Por exemplo, considere o uso a seguir de um modelo RNN aninhado. <br><br><pre> <code class="python hljs">outputs, states = embedding_rnn_seq2seq( encoder_inputs, decoder_inputs, cell, num_encoder_symbols, num_decoder_symbols, embedding_size, output_projection=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, feed_previous=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  No modelo <code>embedding_rnn_seq2seq</code> , todos os dados de entrada ( <code>encoder_inputs</code> e <code>decoder_inputs</code> ) são tensores inteiros que refletem valores discretos.  Eles serão aninhados em uma representação restrita (para obter detalhes sobre o anexo, consulte o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vector Views Guide</a> ), mas para criar esses anexos, é necessário especificar o número máximo de caracteres discretos: <code>num_encoder_symbols</code> no lado do codificador e <code>num_decoder_symbols</code> no lado do decodificador. <br><br>  Na chamada acima, definimos <code>feed_previous</code> como False.  Isso significa que o decodificador usará os tensores <code>decoder_inputs</code> na forma em que são fornecidos.  Se <code>feed_previous</code> como True, o decodificador usará apenas o primeiro elemento <code>decoder_inputs</code> .  Todos os outros tensores da lista serão ignorados e o valor anterior da saída do decodificador será usado.  Isso é usado para decodificar traduções em nosso modelo de tradução, mas também pode ser usado durante o treinamento, para melhorar a estabilidade do modelo a seus erros.  Aproximadamente como em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Bengio et al., 2015</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ). <br><br>  Outro argumento importante usado acima é <code>output_projection</code> .  Sem esclarecimentos, as conclusões do modelo incorporado serão tensores da forma o número de amostras de treinamento por <code>num_decoder_symbols</code> , uma vez que representam os logotipos de cada símbolo gerado.  Ao treinar modelos com dicionários de saída grandes, por exemplo, com <code>num_decoder_symbols</code> grande, o armazenamento desses tensores grandes se torna impraticável.  Em vez disso, é melhor retornar tensores menores, que serão projetados posteriormente no tensor grande usando a <code>output_projection</code> .  Isso nos permite usar nossos modelos seq2seq com perdas de softmax amostradas, conforme descrito por <a href="">Jean et.</a>  <a href="">al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ). <br><br>  Além de <code>basic_rnn_seq2seq</code> e <code>embedding_rnn_seq2seq</code> , existem vários modelos de sequência a sequência no <code>seq2seq.py</code> .  Preste atenção neles.  Todos eles têm uma interface semelhante, por isso não vamos nos aprofundar em seus detalhes.  Para o nosso modelo de tradução abaixo, use <code>embedding_attention_seq2seq</code> . <br><br>  Para ser continuado. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt430780/">https://habr.com/ru/post/pt430780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt430768/index.html">Entrevista com o criador do ADOM, Thomas Biscap</a></li>
<li><a href="../pt430770/index.html">Backup para Linux ou como criar um instantâneo</a></li>
<li><a href="../pt430774/index.html">Você está pronto para a IA em outdoors?</a></li>
<li><a href="../pt430776/index.html">Fazer um IP é a única maneira</a></li>
<li><a href="../pt430778/index.html">3DEXPERIENCE processo de projeto de sistema elétrico de ponta a ponta</a></li>
<li><a href="../pt430782/index.html">Quantos programadores você precisa para suportar códigos escritos anteriormente?</a></li>
<li><a href="../pt430784/index.html">De júnior a diretor: histórias de um guarda</a></li>
<li><a href="../pt430788/index.html">Meu histórico de entrevistas no IB IT (desenvolvedor Java, banco de investimentos) em Londres, com exemplos de tarefas típicas</a></li>
<li><a href="../pt430790/index.html">Ledger Nano S: a chave da sala onde 710 tokens e criptomoedas podem estar</a></li>
<li><a href="../pt430792/index.html">Criando um esboço sobre LWRP no Unity</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üññüèæ üíáüèº üçç Modelos de sequ√™ncia-sequ√™ncia-parte 1 üë∞üèø üßÄ ü§∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bom dia a todos! 

 E novamente abrimos um novo fluxo para o curso Data Scientist revisado: outro excelente professor , um programa ligeiramente refin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Modelos de sequ√™ncia-sequ√™ncia-parte 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/430780/">  Bom dia a todos! <br><br>  E novamente abrimos um novo fluxo para o curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Data Scientist</a> revisado: outro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">excelente professor</a> , um programa ligeiramente refinado com base em atualiza√ß√µes.  Bem, como sempre, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">li√ß√µes abertas</a> interessantes e cole√ß√µes de materiais interessantes.  Hoje come√ßaremos a an√°lise dos modelos seq2seq do Tensor Flow. <br><br>  Vamos l√° <br><br>  Como j√° discutido no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tutorial</a> da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNN</a> (recomendamos que voc√™ se familiarize com ele antes de ler este artigo), redes neurais recorrentes podem ser ensinadas a modelar o idioma.  E surge uma pergunta interessante: √© poss√≠vel treinar a rede em determinados dados para gerar uma resposta significativa?  Por exemplo, podemos ensinar uma rede neural a traduzir do ingl√™s para o franc√™s?  Acontece que n√≥s podemos. <br><br>  Este guia mostra como criar e treinar um sistema de ponta a ponta.  Copie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o reposit√≥rio principal do Tensor Flow</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o reposit√≥rio do modelo TensorFlow do GitHub</a> .  Em seguida, voc√™ pode come√ßar iniciando o programa de tradu√ß√£o: <br><br><pre><code class="python hljs">cd models/tutorials/rnn/translate python translate.py --data_dir [your_data_directory]</code> </pre> <br><img src="https://habrastorage.org/webt/ra/j0/rr/raj0rraitsp6itojzydkhrk2yoi.png"><a name="habracut"></a><br><br>  Ela far√° o download dos dados para tradu√ß√£o do ingl√™s para o franc√™s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no site do WMT'15</a> , preparar√°-os para treinamento e treinamento.  Isso exigir√° cerca de 20 GB no disco r√≠gido e muito tempo para baixar e preparar, para que voc√™ possa iniciar o processo agora e continuar lendo este tutorial. <br><br>  O manual acessar√° os seguintes arquivos: <br><br><table><tbody><tr><th>  Ficheiro </th><th>  O que h√° nele? </th></tr><tr><td>  tensorflow / tensorflow / python / ops / seq2seq.py </td><td>  Biblioteca para criar modelos de sequ√™ncia para sequ√™ncia </td></tr><tr><td>  modelos / tutoriais / rnn / translate / seq2seq_model.py </td><td>  Modelos de tradu√ß√£o neural sequ√™ncia a sequ√™ncia </td></tr><tr><td>  modelos / tutoriais / rnn / translate / data_utils.py </td><td>  Fun√ß√µes auxiliares para preparar dados de tradu√ß√£o </td></tr><tr><td>  modelos / tutoriais / rnn / translate / translate.py </td><td>  O bin√°rio que treina e executa o modelo de convers√£o </td></tr></tbody></table><br>  <b>No√ß√µes b√°sicas de sequ√™ncia a sequ√™ncia</b> <br><br>  O modelo b√°sico de sequ√™ncia a sequ√™ncia, conforme apresentado por <a href="">Cho et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ), consiste em duas redes neurais recorrentes (RNNs): um codificador (codificador) que processa os dados de entrada e um decodificador (decodificador) que gera os dados sa√≠da.  A arquitetura b√°sica √© mostrada abaixo: <br><br><img src="https://habrastorage.org/webt/e-/df/cu/e-dfcuvlsbykvyxvzac9rc0nrow.png"><br><br>  Cada ret√¢ngulo na figura acima representa uma c√©lula no RNN, geralmente uma c√©lula GRU - um bloco de recorr√™ncia controlado ou uma c√©lula LSTM - mem√≥ria de curto prazo de longo prazo (leia o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tutorial</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNN</a> para saber mais sobre eles).  Codificadores e decodificadores podem ter pesos comuns ou, mais frequentemente, usar diferentes conjuntos de par√¢metros.  C√©lulas multicamadas foram usadas com sucesso em modelos de sequ√™ncia a sequ√™ncia, por exemplo, para traduzir <a href="">Sutskever et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ). <br><br>  No modelo b√°sico descrito acima, cada entrada deve ser codificada em um vetor de estado de tamanho fixo, pois essa √© a √∫nica coisa que √© transmitida ao decodificador.  Para dar ao decodificador acesso mais direto aos dados de entrada, um mecanismo de aten√ß√£o foi introduzido em <a href="">Bahdanau et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ).  N√£o entraremos em detalhes do mecanismo de aten√ß√£o (para isso voc√™ pode se familiarizar com o trabalho aqui);  basta dizer que permite que o decodificador analise os dados de entrada em cada etapa de decodifica√ß√£o.  Uma rede sequ√™ncia a sequ√™ncia multicamada com c√©lulas LSTM e o mecanismo de aten√ß√£o no decodificador s√£o os seguintes: <br><br><img src="https://habrastorage.org/webt/c4/ro/0z/c4ro0zvzu8m-y4qjlnfbhv9x4qa.png"><br><br>  <b>Biblioteca TensorFlow seq2seq</b> <br><br>  Como voc√™ pode ver acima, existem diferentes modelos de sequ√™ncia para sequ√™ncia.  Todos eles podem usar c√©lulas RNN diferentes, mas todos aceitam dados de entrada do codificador e dados de entrada do decodificador.  Essa √© a base da interface da biblioteca TensorFlow seq2seq (tensorflow / tensorflow / python / ops / seq2seq.py).  Esse modelo b√°sico de RNN, codec, sequ√™ncia a sequ√™ncia funciona da seguinte maneira. <br><br><pre> <code class="python hljs">outputs, states = basic_rnn_seq2seq(encoder_inputs, decoder_inputs, cell)</code> </pre> <br>  Na chamada indicada acima, <code>encoder_inputs</code> √© uma lista de tensores que representam os dados de entrada do codificador, correspondendo √†s letras A, B, C da figura acima.  Da mesma forma, <code>decoder_inputs</code> s√£o tensores que representam dados de entrada do decodificador.  GO, W, X, Y, Z da primeira foto. <br><br>  O argumento <code>cell</code> √© uma inst√¢ncia da classe <code>tf.contrib.rnn.RNNCell</code> que determina qual c√©lula ser√° usada no modelo.  Voc√™ pode usar c√©lulas existentes, por exemplo, <code>GRUCell</code> ou <code>LSTMCell</code> , ou pode escrever suas pr√≥prias.  Al√©m disso, o <code>tf.contrib.rnn</code> fornece shells para criar c√©lulas de <code>tf.contrib.rnn</code> camadas, adicionando exce√ß√µes √† entrada e sa√≠da de c√©lulas ou outras transforma√ß√µes.  Confira o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tutorial</a> da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNN</a> para obter exemplos. <br><br>  A chamada <code>basic_rnn_seq2seq</code> retorna dois argumentos: <code>outputs</code> e <code>states</code> .  Ambos representam uma lista de tensores do mesmo comprimento que <code>decoder_inputs</code> .  <code>outputs</code> correspondem aos dados de sa√≠da do decodificador a cada passo, na primeira imagem s√£o W, X, Y, Z, EOS.  Os <code>states</code> retornados representam o estado interno do decodificador em cada etapa do tempo. <br><br>  Em muitas aplica√ß√µes que usam o modelo de sequ√™ncia a sequ√™ncia, a sa√≠da do decodificador no tempo t √© retornada √† entrada do decodificador no tempo t + 1.  Durante o teste, durante a decodifica√ß√£o de sequ√™ncia, √© assim que uma nova √© constru√≠da.  Por outro lado, durante o treinamento, √© habitual transmitir ao decodificador os dados de entrada corretos a cada passo, mesmo que o decodificador tenha sido previamente confundido.  As fun√ß√µes no <code>seq2seq.py</code> suportam os dois modos com o argumento <code>feed_previous</code> .  Por exemplo, considere o uso a seguir de um modelo RNN aninhado. <br><br><pre> <code class="python hljs">outputs, states = embedding_rnn_seq2seq( encoder_inputs, decoder_inputs, cell, num_encoder_symbols, num_decoder_symbols, embedding_size, output_projection=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, feed_previous=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  No modelo <code>embedding_rnn_seq2seq</code> , todos os dados de entrada ( <code>encoder_inputs</code> e <code>decoder_inputs</code> ) s√£o tensores inteiros que refletem valores discretos.  Eles ser√£o aninhados em uma representa√ß√£o restrita (para obter detalhes sobre o anexo, consulte o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vector Views Guide</a> ), mas para criar esses anexos, √© necess√°rio especificar o n√∫mero m√°ximo de caracteres discretos: <code>num_encoder_symbols</code> no lado do codificador e <code>num_decoder_symbols</code> no lado do decodificador. <br><br>  Na chamada acima, definimos <code>feed_previous</code> como False.  Isso significa que o decodificador usar√° os tensores <code>decoder_inputs</code> na forma em que s√£o fornecidos.  Se <code>feed_previous</code> como True, o decodificador usar√° apenas o primeiro elemento <code>decoder_inputs</code> .  Todos os outros tensores da lista ser√£o ignorados e o valor anterior da sa√≠da do decodificador ser√° usado.  Isso √© usado para decodificar tradu√ß√µes em nosso modelo de tradu√ß√£o, mas tamb√©m pode ser usado durante o treinamento, para melhorar a estabilidade do modelo a seus erros.  Aproximadamente como em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Bengio et al., 2015</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ). <br><br>  Outro argumento importante usado acima √© <code>output_projection</code> .  Sem esclarecimentos, as conclus√µes do modelo incorporado ser√£o tensores da forma o n√∫mero de amostras de treinamento por <code>num_decoder_symbols</code> , uma vez que representam os logotipos de cada s√≠mbolo gerado.  Ao treinar modelos com dicion√°rios de sa√≠da grandes, por exemplo, com <code>num_decoder_symbols</code> grande, o armazenamento desses tensores grandes se torna impratic√°vel.  Em vez disso, √© melhor retornar tensores menores, que ser√£o projetados posteriormente no tensor grande usando a <code>output_projection</code> .  Isso nos permite usar nossos modelos seq2seq com perdas de softmax amostradas, conforme descrito por <a href="">Jean et.</a>  <a href="">al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pdf</a> ). <br><br>  Al√©m de <code>basic_rnn_seq2seq</code> e <code>embedding_rnn_seq2seq</code> , existem v√°rios modelos de sequ√™ncia a sequ√™ncia no <code>seq2seq.py</code> .  Preste aten√ß√£o neles.  Todos eles t√™m uma interface semelhante, por isso n√£o vamos nos aprofundar em seus detalhes.  Para o nosso modelo de tradu√ß√£o abaixo, use <code>embedding_attention_seq2seq</code> . <br><br>  Para ser continuado. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt430780/">https://habr.com/ru/post/pt430780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt430768/index.html">Entrevista com o criador do ADOM, Thomas Biscap</a></li>
<li><a href="../pt430770/index.html">Backup para Linux ou como criar um instant√¢neo</a></li>
<li><a href="../pt430774/index.html">Voc√™ est√° pronto para a IA em outdoors?</a></li>
<li><a href="../pt430776/index.html">Fazer um IP √© a √∫nica maneira</a></li>
<li><a href="../pt430778/index.html">3DEXPERIENCE processo de projeto de sistema el√©trico de ponta a ponta</a></li>
<li><a href="../pt430782/index.html">Quantos programadores voc√™ precisa para suportar c√≥digos escritos anteriormente?</a></li>
<li><a href="../pt430784/index.html">De j√∫nior a diretor: hist√≥rias de um guarda</a></li>
<li><a href="../pt430788/index.html">Meu hist√≥rico de entrevistas no IB IT (desenvolvedor Java, banco de investimentos) em Londres, com exemplos de tarefas t√≠picas</a></li>
<li><a href="../pt430790/index.html">Ledger Nano S: a chave da sala onde 710 tokens e criptomoedas podem estar</a></li>
<li><a href="../pt430792/index.html">Criando um esbo√ßo sobre LWRP no Unity</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
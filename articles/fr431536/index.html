<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•ù üë©‚Äçüé§ üë©üèº‚ÄçüöÄ Ceph. Anatomie de catastrophe üí† üë©üèæ‚Äçüåæ üèåÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ceph est un stockage d'objets con√ßu pour aider √† cr√©er un cluster de basculement. Pourtant, des √©checs se produisent. Tous ceux qui travaillent avec C...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ceph. Anatomie de catastrophe</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/431536/">  Ceph est un stockage d'objets con√ßu pour aider √† cr√©er un cluster de basculement.  Pourtant, des √©checs se produisent.  Tous ceux qui travaillent avec Ceph connaissent la l√©gende de CloudMouse ou Rosreestr.  Malheureusement, il n'est pas habituel de partager avec nous une exp√©rience n√©gative, les causes des √©checs sont le plus souvent √©touff√©es et ne permettent pas aux g√©n√©rations futures d'apprendre des erreurs des autres. <br><br>  Eh bien, mettons en place un cluster de test, mais proche du vrai, et analysons la catastrophe par os.  Nous mesurerons tous les baisses de performances, trouverons les fuites de m√©moire et analyserons le processus de r√©cup√©ration du service.  Et tout cela sous la direction d'Artemy Kapitula, qui a pass√© pr√®s d'un an √† √©tudier les pi√®ges, a fait √©chouer les performances du cluster √† z√©ro et la latence ne pas atteindre des valeurs ind√©centes.  Et j'ai un graphique rouge, ce qui est bien mieux. <br><img src="https://habrastorage.org/webt/c8/nr/1a/c8nr1akew1kjleodu5trq_ow3oy.png"><br><br>  Ensuite, vous trouverez une version vid√©o et texte de l'un des meilleurs rapports de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DevOpsConf Russia</a> 2018. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/_fWYUl2QsoI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><a name="habracut"></a><br>  <strong>√Ä propos du conf√©rencier:</strong> Artemy Kapitula architecte syst√®me RCNTEC.  La soci√©t√© propose des solutions de t√©l√©phonie IP (collaboration, organisation d'un bureau √† distance, syst√®mes de stockage d√©finis par logiciel et syst√®mes de gestion / distribution d'√©nergie).  L'entreprise travaille principalement dans le secteur des entreprises, elle n'est donc pas tr√®s connue sur le march√© DevOps.  N√©anmoins, une certaine exp√©rience a √©t√© accumul√©e avec Ceph, qui dans de nombreux projets est utilis√© comme √©l√©ment de base de l'infrastructure de stockage. <br><br>  <strong>Ceph est un r√©f√©rentiel d√©fini par logiciel avec de nombreux composants logiciels.</strong> <br><img src="https://habrastorage.org/webt/dw/ow/hm/dwowhmqvjfugd0u-ljhhz3fy2ji.png"><br><br>  Dans le diagramme: <br><br><ul><li>  Le niveau sup√©rieur est le r√©seau de cluster interne par lequel le cluster lui-m√™me communique; </li><li>  Le niveau inf√©rieur - en fait Ceph - est un ensemble de d√©mons internes de Ceph (MON, MDS et OSD) qui stockent les donn√©es. </li></ul><br>  En r√®gle g√©n√©rale, toutes les donn√©es sont r√©pliqu√©es. Dans le diagramme, j'ai d√©lib√©r√©ment s√©lectionn√© trois groupes, chacun avec trois OSD, et chacun de ces groupes contient g√©n√©ralement une r√©plique de donn√©es.  En cons√©quence, les donn√©es sont stock√©es en trois copies. <br><br>  Un r√©seau de cluster de niveau sup√©rieur est le r√©seau par lequel les clients Ceph acc√®dent aux donn√©es.  Gr√¢ce √† lui, les clients communiquent avec le moniteur, avec MDS (qui en a besoin) et avec OSD.  Chaque client fonctionne avec chaque OSD et avec chaque moniteur ind√©pendamment.  Par cons√©quent, le <strong>syst√®me est d√©pourvu d'un seul point de d√©faillance</strong> , ce qui est tr√®s agr√©able. <br><br><h2>  Les clients <br></h2><br>  ‚óè Clients S3 <br><br>  S3 est une API pour HTTP.  Les clients S3 fonctionnent via HTTP et se connectent aux composants Ceph Rados Gateway (RGW).  Ils communiquent presque toujours avec un composant via un r√©seau d√©di√©.  Ce r√©seau (je l'ai appel√© r√©seau S3) utilise uniquement HTTP, les exceptions sont rares. <br><br>  ‚óè Hyperviseur avec machines virtuelles <br><br>  Ce groupe de clients est souvent utilis√©.  Ils travaillent avec des moniteurs et avec OSD, d'o√π ils re√ßoivent des informations g√©n√©rales sur l'√©tat du cluster et la distribution des donn√©es.  Pour les donn√©es, ces clients acc√®dent directement aux d√©mons OSD via le r√©seau public du cluster. <br><br>  ‚óè Clients RBD <br><br>  Il existe √©galement des h√¥tes physiques de m√©taux BR, qui sont g√©n√©ralement Linux.  Ce sont des clients RBD et acc√®dent aux images stock√©es dans un cluster Ceph (images de disque de machine virtuelle). <br><br>  ‚óè Clients CephFS <br><br>  Le quatri√®me groupe de clients, qui ne sont pas encore nombreux mais qui suscitent un int√©r√™t croissant, sont les clients du syst√®me de fichiers de cluster CephFS.  Le syst√®me de cluster CephFS peut √™tre mont√© simultan√©ment √† partir de nombreux n≈ìuds, et tous les n≈ìuds ont acc√®s aux m√™mes donn√©es, en travaillant avec chaque OSD.  Autrement dit, il n'y a pas de passerelles en tant que telles (Samba, NFS et autres).  Le probl√®me est qu'un tel client ne peut √™tre que Linux et une version assez moderne. <br><img src="https://habrastorage.org/webt/fw/nm/xc/fwnmxcaiig0yy6tkofrljqri3ck.png"><br><br>  Notre entreprise travaille sur le march√© des entreprises, et l√†, la balle est dirig√©e par ESXi, HyperV et autres.  En cons√©quence, le cluster Ceph, qui est en quelque sorte utilis√© dans le secteur des entreprises, est n√©cessaire pour soutenir les techniques appropri√©es.  Ce n'√©tait pas suffisant pour nous √† Ceph, nous avons donc d√ª affiner et √©tendre le cluster Ceph avec nos composants, en fait construire quelque chose de plus que Ceph, notre propre plate-forme de stockage de donn√©es. <br><br>  De plus, les clients du secteur des entreprises ne sont pas sous Linux, mais la plupart d'entre eux Windows, parfois Mac OS, ne peuvent pas acc√©der au cluster Ceph eux-m√™mes.  Ils doivent passer par une sorte de passerelles, qui dans ce cas deviennent des goulots d'√©tranglement. <br><br>  Nous avons d√ª ajouter tous ces composants et nous avons obtenu un cluster l√©g√®rement plus large. <br><img src="https://habrastorage.org/webt/p2/tg/j2/p2tgj2qtpzrzsnst5bophkclywi.png"><br><br>  Nous avons deux composants centraux: le <strong>groupe SCSI Gateways</strong> , qui permet d'acc√©der aux donn√©es d'un cluster Ceph via FibreChannel ou iSCSI.  Ces composants sont utilis√©s pour connecter HyperV et ESXi √† un cluster Ceph.  Les clients PROXMOX travaillent toujours √† leur mani√®re - via RBD. <br><br>  Nous ne laissons pas les clients de fichiers directement dans le r√©seau de cluster; plusieurs passerelles tol√©rantes aux pannes leur sont allou√©es.  Chaque passerelle permet d'acc√©der au syst√®me de cluster de fichiers via NFS, AFP ou SMB.  En cons√©quence, presque tous les clients, que ce soit Linux, FreeBSD ou non seulement un client, un serveur (OS X, Windows), ont acc√®s √† CephFS. <br><br>  Pour g√©rer tout cela, nous avons d√ª d√©velopper notre propre orchestre Ceph et tous nos composants, qui y sont nombreux.  Mais en parler maintenant n'a aucun sens, car c'est notre d√©veloppement.  La plupart seront probablement int√©ress√©s par le Ceph ¬´nu¬ª lui-m√™me. <br><br>  Ceph est beaucoup utilis√© l√† o√π, et parfois des pannes se produisent.  Certes, tous ceux qui travaillent avec Ceph connaissent la l√©gende de CloudMouse.  C'est une terrible l√©gende urbaine, mais tout n'est pas si mal qu'il n'y para√Æt.  Il y a un nouveau conte de f√©es sur Rosreestr.  Ceph tournait partout, et partout il √©chouait.  Quelque part, cela s'est termin√© fatalement, quelque part a r√©ussi √† √©liminer rapidement les cons√©quences. <br><br>  Malheureusement, il n'est pas habituel pour nous de partager des exp√©riences n√©gatives, tout le monde essaie de cacher les informations pertinentes.  Les entreprises √©trang√®res sont un peu plus ouvertes, en particulier, DigitalOcean (un fournisseur bien connu qui distribue des machines virtuelles) a √©galement subi une d√©faillance Ceph pendant presque une journ√©e, c'√©tait le 1er avril - une journ√©e merveilleuse!  Ils ont publi√© certains des rapports, un court journal ci-dessous. <br><img src="https://habrastorage.org/webt/qo/sb/ds/qosbdsczlkvzh-zqsfvid86er5u.png"><br><br>  Les probl√®mes ont commenc√© √† 7 heures du matin, √† 11 heures, ils ont compris ce qui se passait et ont commenc√© √† √©liminer l'√©chec.  Pour ce faire, ils ont allou√© deux commandes: l'une pour une raison quelconque a parcouru les serveurs et y a install√© de la m√©moire, et la seconde pour une raison quelconque a d√©marr√© manuellement un serveur apr√®s l'autre et surveill√© attentivement tous les serveurs.  Pourquoi?  Nous sommes tous habitu√©s √† tout allum√© en un seul clic. <br><br>  <em>Que se passe-t-il fondamentalement dans un syst√®me distribu√© lorsqu'il est effectivement construit et fonctionne presque √† la limite de ses capacit√©s?</em> <br><br>  Pour r√©pondre √† cette question, nous devons examiner comment fonctionne le cluster Ceph et comment la panne se produit. <br><img src="https://habrastorage.org/webt/ln/ks/rd/lnksrda1mb-lmfbymyacym1f8aw.png"><br><br><h2>  Sc√©nario d'√©chec de Ceph <br></h2><br>  Au d√©but, le cluster fonctionne bien, tout va bien.  Ensuite, quelque chose se produit, apr√®s quoi les d√©mons OSD, o√π les donn√©es sont stock√©es, perdent le contact avec les composants centraux du cluster (moniteurs).  √Ä ce stade, un d√©lai d'attente se produit et l'ensemble du cluster obtient un enjeu.  Le cluster reste un moment jusqu'√† ce qu'il se rende compte que quelque chose ne va pas avec lui, et ensuite il corrige ses connaissances internes.  Apr√®s cela, le service client est restaur√© dans une certaine mesure et le cluster fonctionne √† nouveau en mode d√©grad√©.  Et le plus dr√¥le, c'est que cela fonctionne plus rapidement qu'en mode normal - c'est un fait √©tonnant. <br><br>  Ensuite, nous √©liminons l'√©chec.  Supposons que nous perdions de l'√©nergie, le rack a √©t√© compl√®tement coup√©.  Les √©lectriciens sont venus en courant, ils ont tous restaur√©, ils ont fourni l'√©lectricit√©, les serveurs allum√©s et <strong>le plaisir commence</strong> . <br><br><blockquote>  Tout le monde est habitu√© au fait que lorsqu'un serveur tombe en panne, tout devient mauvais, et lorsque nous allumons le serveur, tout devient bon.  Tout est compl√®tement faux ici. <br></blockquote><br>  Le cluster s'arr√™te pratiquement, effectue la synchronisation principale, puis commence une r√©cup√©ration douce et lente, revenant progressivement au mode normal. <br><img src="https://habrastorage.org/webt/ml/r_/i3/mlr_i3llw-lsdaybp4vbedxeuhi.png"><br><br>  Ci-dessus, un graphique des performances du cluster Ceph au fur et √† mesure de la d√©faillance.  Veuillez noter qu'ici, les intervalles dont nous avons parl√© sont trac√©s tr√®s clairement: <br><br><ul><li>  Fonctionnement normal jusqu'√† environ 70 secondes; </li><li>  √âchec d'une minute √† environ 130 secondes; </li><li>  Un plateau nettement sup√©rieur au fonctionnement normal est l'≈ìuvre de clusters d√©grad√©s; </li><li>  Ensuite, nous activons le n≈ìud manquant - il s'agit d'un cluster de formation, il n'y a que 3 serveurs et 15 SSD.  Nous d√©marrons le serveur quelque part environ 260 secondes. </li><li>  Le serveur s'est allum√©, est entr√© dans le cluster - IOPS'y est tomb√©. </li></ul><br>  Essayons de comprendre ce qui s'est r√©ellement pass√© l√†-bas.  La premi√®re chose qui nous int√©resse est une baisse au tout d√©but du graphique. <br><br><h3>  √âchec de l'OSD <br></h3><br>  Prenons un exemple de cluster avec trois racks, plusieurs n≈ìuds dans chacun.  Si le rack gauche tombe en panne, tous les d√©mons OSD (pas les h√¥tes!) Se pinglent avec des messages Ceph √† un certain intervalle.  En cas de perte de plusieurs messages, un message est envoy√© au moniteur: "Je, OSD tel ou tel, ne peux pas atteindre l'OSD tel ou tel." <br><img src="https://habrastorage.org/webt/zh/1s/ge/zh1sge1ljlclxjmgfygxpyyyc8i.png"><br><br>  Dans ce cas, les messages sont g√©n√©ralement regroup√©s par h√¥tes, c'est-√†-dire que si deux messages provenant d'OSD diff√©rents arrivent sur le m√™me h√¥te, ils sont combin√©s en un seul message.  Par cons√©quent, si l'OSD 11 et l'OSD 12 indiquent qu'ils ne peuvent pas atteindre l'OSD 1, cela sera interpr√©t√© comme l'h√¥te 11 se plaignant de l'OSD 1. Lorsque l'OSD 21 et l'OSD 22 ont √©t√© signal√©s, il est interpr√©t√© comme l'h√¥te 21 insatisfait de l'OSD 1 Apr√®s quoi le moniteur consid√®re que l'OSD 1 est √† l'√©tat bas et informe tous les membres du cluster (en changeant la carte OSD), le travail se poursuit en mode d√©grad√©. <br><img src="https://habrastorage.org/webt/uu/-c/1w/uu-c1wnwflbqk6ueyumhohtlvjy.png"><br><br>  Voici donc notre cluster et notre rack d√©faillant (h√¥te 5 et h√¥te 6).  Nous activons l'h√¥te 5 et l'h√¥te 6, au fur et √† mesure que la puissance est apparue, et ... <br><br><h3>  Comportement interne de Ceph <br></h3><br>  Et maintenant, la partie la plus int√©ressante est que nous commen√ßons la <strong>synchronisation initiale des donn√©es</strong> .  Comme il existe de nombreuses r√©pliques, elles doivent √™tre synchrones et √™tre dans la m√™me version.  En cours de d√©marrage du d√©marrage OSD: <br><br><ul><li>  OSD lit les versions disponibles, l'historique disponible (pg_log - pour d√©terminer les versions actuelles des objets). </li><li>  Apr√®s quoi, il d√©termine sur quel OSD les derni√®res versions des objets d√©grad√©s (missing_loc) sont activ√©es et lesquelles sont derri√®re. </li><li>  Lorsque les versions ant√©rieures sont stock√©es, une synchronisation est n√©cessaire et de nouvelles versions peuvent √™tre utilis√©es comme r√©f√©rence pour lire et √©crire des donn√©es. </li></ul><br>  Une histoire est utilis√©e qui est collect√©e √† partir de tous les OSD, et cette histoire peut √™tre beaucoup;  l'emplacement r√©el de l'ensemble d'objets dans le cluster o√π se trouvent les versions correspondantes est d√©termin√©.  Combien d'objets sont dans le cluster, combien d'enregistrements sont obtenus, si le cluster est rest√© longtemps en mode d√©grad√©, alors l'histoire est longue. <br><br>  <strong>√Ä titre de comparaison: la</strong> taille typique d'un objet lorsque nous travaillons avec une image RBD est de 4 Mo.  Lorsque nous travaillons en effacement cod√© - 1 Mo.  Si nous avons un disque de 10 To, nous obtenons un million d'objets m√©gaoctets sur le disque.  Si nous avons 10 disques sur le serveur, alors il y a d√©j√† 10 millions d'objets, s'il y a 32 disques (nous construisons un cluster efficace, nous avons une allocation serr√©e), alors 32 millions d'objets doivent √™tre conserv√©s en m√©moire.  De plus, en fait, les informations sur chaque objet sont stock√©es en plusieurs copies, car chaque copie indique qu'√† cet endroit, elle se trouve dans cette version, et dans celle-ci - dans celle-ci. <br><br>  Il s'av√®re qu'une √©norme quantit√© de donn√©es, qui se trouve dans la RAM: <br><br><ul><li>  plus il y a d'objets, plus l'histoire de missing_loc est grande; </li><li>  plus PG - plus pg_log et carte OSD; </li></ul><br>  en plus: <br><br><ul><li>  plus la taille du disque est grande; </li><li>  plus la densit√© est √©lev√©e (le nombre de disques dans chaque serveur); </li><li>  plus la charge sur le cluster est √©lev√©e et plus votre cluster est rapide; </li><li>  plus l'OSD est arr√™t√© (en mode hors ligne); </li></ul><br>  en d'autres termes, <strong>plus le cluster que nous avons construit est raide et plus la partie du cluster ne r√©pond plus, plus il faudra de RAM au d√©marrage</strong> . <br><br><h2>  Les optimisations extr√™mes sont √† l'origine de tout mal <br></h2><br><blockquote>  <em>"... et le MOO noir vient aux mauvais gar√ßons et filles la nuit et tue tous les processus √† gauche et √† droite"</em> <br><br>  L√©gende du sysadmin de la ville <br></blockquote><br>  Ainsi, la RAM n√©cessite beaucoup, la consommation de m√©moire augmente (nous avons commenc√© tout de suite dans un tiers du cluster) et le syst√®me peut en th√©orie passer en SWAP, si vous l'avez cr√©√© bien s√ªr.  Je pense que beaucoup de gens pensent que SWAP est mauvais et qu‚Äôils ne le cr√©ent pas: ¬´Pourquoi?  Nous avons beaucoup de m√©moire! ¬ª  Mais ce n'est pas la bonne approche. <br><br>  Si le fichier SWAP n'a pas √©t√© cr√©√© √† l'avance, car il a √©t√© d√©cid√© que Linux fonctionnerait plus efficacement, t√¥t ou tard, cela se produirait par manque de m√©moire (OOM-killer). Et pas le fait qu'il tue celui qui a mang√© toute la m√©moire, non celui qui a √©t√© le premier malchanceux.  Nous savons ce qu'est un endroit optimiste - nous demandons un souvenir, ils nous le promettent, nous disons: "Maintenant, donnez-nous-en un", en r√©ponse: "Mais non!"  - et tueur de m√©moire. <br><br>  Il s'agit d'un travail Linux normal, sauf s'il est configur√© dans la zone de m√©moire virtuelle. <br><br>  Le processus sort du tueur de m√©moire et tombe rapidement et sans piti√©.  De plus, aucun autre processus qu'il est d√©c√©d√© ne sait.  Il n'a pas eu le temps d'informer quiconque de quoi que ce soit, ils l'ont simplement licenci√©. <br><br>  Ensuite, bien s√ªr, le processus va red√©marrer - nous avons systemd, il lance √©galement, si n√©cessaire, les OSD qui sont tomb√©s.  Les OSD tomb√©s commencent et ... une r√©action en cha√Æne commence. <br><img src="https://habrastorage.org/webt/9p/s8/4z/9ps84zkjtmuamxyllkcgffsgxkq.png"><br><br>  Dans notre cas, nous avons commenc√© OSD 8 et OSD 9, ils ont commenc√© √† tout √©craser, mais pas de chance OSD 0 et OSD 5. Un tueur en m√©moire a vol√© vers eux et les a mis fin.  Ils ont red√©marr√© - ils ont lu leurs donn√©es, ont commenc√© √† synchroniser et √† √©craser le reste.  Trois autres malchanceux (OSD 9, OSD 4 et OSD 7).  Ces trois ont red√©marr√©, ont commenc√© √† faire pression sur l'ensemble du cluster, le pack suivant n'a pas eu de chance. <br><br>  <strong>Le cluster commence √† s'effondrer litt√©ralement sous nos yeux</strong> .  La d√©gradation se produit tr√®s rapidement, et ce ¬´tr√®s rapide¬ª s'exprime g√©n√©ralement en minutes, maximum dizaines de minutes.  Si vous avez 30 n≈ìuds (10 n≈ìuds par rack) et coupez le rack en raison d'une panne de courant - apr√®s 6 minutes, la moiti√© du cluster se trouve. <br><br>  Donc, nous obtenons quelque chose comme ce qui suit. <br><img src="https://habrastorage.org/webt/1b/hq/bu/1bhqburpjt74vwnpbgqn5ehdhh0.png"><br><br>  Sur presque tous les serveurs, nous avons un OSD d√©fectueux.  Et si c'est sur chaque serveur, c'est-√†-dire dans chaque domaine de d√©faillance que nous avons pour l'OSD d√©faillant, alors la <strong>plupart de nos donn√©es ne sont pas disponibles</strong> .  Toute demande est bloqu√©e - pour √©crire, pour lire - cela ne fait aucune diff√©rence.  C‚Äôest tout!  Nous nous sommes lev√©s. <br><br>  Que faire dans une telle situation?  Plus pr√©cis√©ment, <strong>que fallait-il faire</strong> ? <br><br>  <strong>R√©ponse:</strong> Ne d√©marrez pas le cluster imm√©diatement, c'est-√†-dire l'ensemble du rack, mais √©levez soigneusement un d√©mon chacun. <br><br>  Mais nous ne le savions pas.  Nous avons commenc√© tout de suite et avons obtenu ce que nous avons obtenu.  Dans ce cas, nous avons lanc√© l'un des quatre d√©mons (8, 9, 10, 11), la consommation m√©moire augmentera d'environ 20%.  En r√®gle g√©n√©rale, nous faisons un tel bond.  Ensuite, la consommation de m√©moire commence √† diminuer, car certaines des structures utilis√©es pour contenir les informations sur la fa√ßon dont le cluster s'est d√©grad√© quittent.  Autrement dit, une partie des groupes de placement est revenue √† son √©tat normal, et tout ce qui est n√©cessaire pour maintenir l'√©tat d√©grad√© est lib√©r√© - <strong>en th√©orie, il est lib√©r√©</strong> . <br><br>  Voyons un exemple.  Le code C √† gauche et √† droite est presque identique, la diff√©rence ne concerne que les constantes. <br><img src="https://habrastorage.org/webt/sy/1j/u0/sy1ju0rfqjg507jxvk_4wax9_o4.png"><br><br>  Ces deux exemples demandent une quantit√© de m√©moire diff√©rente du syst√®me: <br><br><ul><li>  gauche - 2 048 morceaux de 1 Mo chacun; </li><li>  √† droite - 2097152 pi√®ces de 1 kilo-octet. </li></ul><br>  Ensuite, les deux exemples nous attendent pour les photographier en haut.  Et apr√®s avoir appuy√© sur ENTER, ils lib√®rent de la m√©moire - tout sauf le dernier morceau.  C'est tr√®s important - la derni√®re pi√®ce reste.  Et encore une fois, ils attendent que nous les photographions. <br><br>  Voici ce qui s'est r√©ellement pass√©. <br><img src="https://habrastorage.org/webt/zx/ah/ug/zxahugrdasantcktho7dbu-tnes.png"><br><br><ul><li>  Tout d'abord, les deux processus ont d√©marr√© et ont mang√© la m√©moire.  Sonne comme la v√©rit√© - 2 Go RSS. </li><li>  Appuyez sur ENTER et soyez surpris.  Le premier programme qui s'est d√©marqu√© en gros morceaux a rendu la m√©moire.  Mais le deuxi√®me programme n'est pas revenu. </li></ul><br>  La raison pour laquelle cela s'est produit r√©side dans le malloc Linux. <br><br>  Si nous demandons de la m√©moire en gros morceaux, elle est √©mise √† l'aide du m√©canisme mmap anonyme, qui est donn√© √† l'espace d'adressage du processeur, d'o√π la m√©moire nous est ensuite coup√©e.  Lorsque nous faisons free (), la m√©moire est lib√©r√©e et les pages sont retourn√©es au cache de pages (syst√®me). <br><br>  Si nous allouons de la m√©moire en petits morceaux, nous faisons sbrk ().  sbrk () d√©place le pointeur vers la queue du tas; en th√©orie, la queue d√©cal√©e peut √™tre renvoy√©e en renvoyant des pages de m√©moire au syst√®me si la m√©moire n'est pas utilis√©e. <br><br>  Regardez maintenant l'illustration.  Nous avions de nombreux enregistrements dans l'histoire de la localisation des objets d√©grad√©s, puis la session utilisateur - un objet √† longue dur√©e de vie.  Nous nous sommes synchronis√©s et toutes les structures suppl√©mentaires ont disparu, mais l'objet √† longue dur√©e de vie est rest√© et nous ne pouvons pas reculer sbrk (). <br><img src="https://habrastorage.org/webt/06/wf/eg/06wfegwyvu0ibae8xjlwizrwteo.png"><br><br>  Nous avons encore beaucoup d'espace inutilis√© qui pourrait √™tre lib√©r√© si nous avions SWAP.  Mais nous sommes intelligents - nous avons d√©sactiv√© SWAP. <br><br>  Bien s√ªr, alors une partie de la m√©moire du d√©but du tas sera utilis√©e, mais ce n'est qu'une partie, et un reste tr√®s important sera occup√©. <br><br>  Que faire dans une telle situation?  La r√©ponse est ci-dessous. <br><br><h3>  Lancement contr√¥l√© <br></h3><br><ul><li>  Nous d√©marrons un d√©mon OSD. </li><li>  On attend pendant qu'il est synchronis√©, on v√©rifie les budgets m√©moire. </li><li>  Si nous comprenons que nous survivrons au d√©but du prochain d√©mon, nous commen√ßons le suivant. </li><li>  Sinon, red√©marrez rapidement le d√©mon qui a pris le plus de m√©moire.  Il a pu baisser pendant un court instant, il n'a pas beaucoup d'histoire, il manque des locs et d'autres choses, donc il va manger moins de m√©moire, le budget m√©moire augmentera l√©g√®rement. </li><li>  Nous courons autour du cluster, le contr√¥lons et levons progressivement tout. </li><li>  Nous v√©rifions s'il est possible de passer au prochain OSD, allez-y. </li></ul><br>  DigitalOcean a en fait accompli ceci: <br>  <em>"Notre √©quipe Datacenter effectue des augmentations de m√©moire tandis qu'une autre √©quipe continue lentement √† mettre en place des n≈ìuds tout en g√©rant manuellement le budget de m√©moire de chaque h√¥te."</em> <br><img src="https://habrastorage.org/webt/nr/yg/a1/nryga17av_ez5yj0mt3lm5grkk0.png"><br><br>  Revenons √† notre configuration et √† notre situation actuelle.  Nous avons maintenant un cluster effondr√© apr√®s une r√©action en cha√Æne de tueur en m√©moire.  Nous interdisons le red√©marrage automatique de l'OSD dans le domaine rouge, et un par un, nous d√©marrons les n≈ìuds √† partir des domaines bleus.  Parce que <strong>notre premi√®re t√¢che est toujours de restaurer le service</strong> , sans comprendre pourquoi cela s'est produit.  Nous comprendrons plus tard, lorsque nous r√©tablirons le service.  En fonctionnement, c'est toujours le cas. <br><br>  Nous amenons le cluster √† l'√©tat cible afin de restaurer le service, puis nous commen√ßons √† ex√©cuter un OSD apr√®s l'autre selon notre m√©thodologie.  Nous regardons le premier, si n√©cessaire, red√©marrez les autres pour ajuster le budget m√©moire, le suivant - 9, 10, 11 - et le cluster semble √™tre synchronis√© et pr√™t √† d√©marrer la maintenance. <br><br>  Le probl√®me est de savoir comment la <strong>maintenance en √©criture</strong> est effectu√©e <strong>dans Ceph</strong> . <br><img src="https://habrastorage.org/webt/hl/rp/ek/hlrpekm0rvjgrjwl11zgdklwecc.png"><br><br>  Nous avons 3 r√©pliques: un OSD ma√Ætre et deux esclaves pour cela.  Nous allons pr√©ciser que le ma√Ætre / esclave de chaque groupe de placement a le sien, mais chacun a un ma√Ætre et deux esclaves. <br><br>  L'op√©ration d'√©criture ou de lecture incombe au ma√Ætre.  Lors de la lecture, si le ma√Ætre a la bonne version, il la remettra au client.  L'enregistrement est un peu plus compliqu√©, l'enregistrement doit √™tre r√©p√©t√© sur toutes les r√©pliques.  Par cons√©quent, lorsque le client √©crit 64 Ko dans OSD 0, les m√™mes 64 Ko dans notre exemple vont √† OSD 5 et OSD 8. <br><br>  Mais le fait est que notre OSD 8 est tr√®s d√©grad√©, car nous avons red√©marr√© de nombreux processus. <br><img src="https://habrastorage.org/webt/es/_z/fr/es_zfrsvdaq8a7f_rgn7hcakpi4.png"><br><br>  √âtant donn√© que dans Ceph, tout changement est une transition d'une version √† l'autre, sur OSD 0 et OSD 5, nous aurons une nouvelle version, sur OSD 8 - l'ancienne.  ,   ,    ( 64 )    OSD 8   ‚Äî   4  ( ).     4   OSD 0,   OSD 8,  ,    .       ,      64 . <br><br>    ‚Äî  . <br><img src="https://habrastorage.org/webt/ch/uc/l_/chucl_b0vhoi-jvuhl3xokm26qg.png"><br><br>   : <br><br><ul><li>    4   1 ,  1000 /  1 . </li><li>   4  ( )  22 ,  45 /. </li></ul><br> ,      ,       ,        ,         . <br><br>      ‚Äî     . <br><img src="https://habrastorage.org/webt/it/0p/34/it0p34kbqfs3u9hvyhmextflvqc.png"><br><br>    4   22 ,  22 ,   1    4   .   45          SSD,       1  ‚Äî <strong>   45 </strong> . <br><br>       ,    . <br><br><h2>    <br></h2><br><br><ul><li>   <strong> </strong> ,    ‚Äî (45+1) / 2 = <strong>23 .</strong> </li><li>   <strong>75% </strong> ,  (45 * 3 + 1) / 4 = <strong>34 </strong> . </li><li>  90% ‚Äî(45 * 9 + 1) / 10 = 41  ‚Äî  40  ,   . </li></ul><br>     Ceph,      .                 ,     ,    ,     . <br><br>      Ceph       . <br><img src="https://habrastorage.org/webt/ng/jj/od/ngjjodzmfd4n6kes71g4n6pg7os.png"><br><br><ol><li>     ‚Äî   :  , ,  ,  ,    . <br></li><li>  ‚Äî latency.   latency  ,   .      100%    (    ,          ). Latency  60     ,       . <br></li></ol><br><img src="https://habrastorage.org/webt/z3/pb/ob/z3pbobkev0bfszscnwgprpop3xe.png"><br><br>       ,       .  10 ,   1 200 /,    300      ,    ,   .  10 SSD ‚Äî   300   ,   ‚Äî ,  - 300   . <br><br><blockquote>    ,     . <br></blockquote><br>  ,     .       900 / (  SSD).     2 500   128    ( , ESXi  HyperV     128 ).      degraded,   225   .     file store,   object store,         ( ),    110   ,     - . <br><br> SSD  110    ‚Äî ! <br><br> <strong>   ?</strong> <br><br> <strong> 1:</strong>     ‚Äî <b>   </b> . <br><img src="https://habrastorage.org/webt/ls/ib/rh/lsibrhcfnucjiox9f8gzxbk1cc8.png"><br><br>    :   ;   PG; <br>       . <br><br>    : <br><br><ul><li>    ,  45  ‚Äî   . </li><li>     (     . ),   14 . </li><li>    ,  8  (  10% PG). </li></ul><br>   <strong>  ,  </strong> ,       , ,  ,     . <br><br> <strong> 2:</strong>   ‚Äî <b>  </b> (order, objectsize)  . <br><br>     , , ,   4   2  1 .      ,     ,   .  Dans ce cas: <br><br><ul><li>     ; </li><li>     (latency)     . </li></ul><br>     : <br><br><ul><li>    ; </li><li>     ; </li><li>   ‚Äî        .     4 ,   . </li></ul><br>        (32  ) ‚Äî      ! <br><br> <strong> 3:</strong>    ‚Äî  <b> Ceph</b> . <br><br>     ,   -,  <strong> Ceph</strong> .                  ,      ,      .     . <br><img src="https://habrastorage.org/webt/c8/nr/1a/c8nr1akew1kjleodu5trq_ow3oy.png"><br><br>     ,   ‚Äî Latency.  ‚Äî  ,  ‚Äî . Latency      30% ,       ,      . <br><br>  Community     ,     preproduction .     ,     .      ,   . <br><br><h1>  Conclusion <br></h1><br>      -  ,     .        ,   Ceph    - ,  ,    . <br><br> ‚óè <strong>   -  </strong> . <br>     ,     .  ,  <strong>     </strong> .       .  ,         ,    production.  ,       ,     ,    DigitalOcean  ,   .   ,  ,    ,  . <br><br>   ,        ,        .    ,  : ¬´    !  ?!¬ª     ,  ,     .   ,      : ,   ,    down time. <br><br> ‚óè <strong>    (OSD).</strong> <br>  ,       ,     ‚Äî     , ,  -      ,   . <strong>     OSD ‚Äî    ‚Äî   </strong> .    ,     . <br><br> ‚óè <strong>  .</strong> <br>        OSD       . <strong>   ,   </strong> .  ,     ,     ,   . <br><br> ‚óè <strong>  RAM   OSD.</strong> <br><br> ‚óè <strong>  SWAP.</strong> <br>   SWAP    Ceph' ,    Linux' .         . <br><br> ‚óè <strong>    .</strong> <br>         100%,    10%. ,    ,      ,   . <br><br> ‚óè <strong>        RBD      Rados Getway.</strong> <br>  ,         . <strong>   SWAP ‚Äî    .</strong> ,    SWAP  ‚Äî    , ,  ,    ,     . <br><br><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cet article est une transcription de l'un des meilleurs rapports de DevOpsConf Russia. </font><font style="vertical-align: inherit;">Bient√¥t, nous ouvrirons la vid√©o et publierons dans une version texte √† quel point les sujets sont int√©ressants. </font><font style="vertical-align: inherit;">Abonnez-vous ici sur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">youtube</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou dans la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">newsletter</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> si vous ne voulez pas manquer de tels documents utiles et √™tre au courant des nouvelles de DevOps.</font></font><br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr431536/">https://habr.com/ru/post/fr431536/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr431526/index.html">Influence corrompue: comment la Stasi a d√©fendu l'Allemagne de l'Est contre les jeux vid√©o</a></li>
<li><a href="../fr431528/index.html">Un myst√©rieux g√©nie math√©matique et un √©crivain promeuvent une solution au probl√®me de permutation</a></li>
<li><a href="../fr431530/index.html">Le√ßon ouverte "Android Material Design: aper√ßu de la mise √† jour"</a></li>
<li><a href="../fr431532/index.html">Memristors constitu√©s de pi√®ces de 2 nm d'√©paisseur</a></li>
<li><a href="../fr431534/index.html">Identit√©s des probl√®mes parmi les d√©veloppeurs</a></li>
<li><a href="../fr431538/index.html">Case Rate & Goods et Mobio: augmentation progressive de tous les indicateurs</a></li>
<li><a href="../fr431540/index.html">Packages et gestionnaires de packages pour k8s</a></li>
<li><a href="../fr431542/index.html">D√©veloppement et maintenance efficaces des r√¥les Ansible</a></li>
<li><a href="../fr431544/index.html">Portez DevOps aux masses</a></li>
<li><a href="../fr431546/index.html">Pourquoi disons-nous OK?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
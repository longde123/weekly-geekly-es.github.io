<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçª üìî üöã Drei Ebenen der automatischen Skalierung in Kubernetes: wie man sie effektiv nutzt üë©üèø‚Äçüè´ üëßüèº üêøÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Um Kubernetes vollst√§ndig zu beherrschen, m√ºssen Sie die verschiedenen M√∂glichkeiten zur Skalierung von Clusterressourcen kennen: Laut den Entwicklern...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Drei Ebenen der automatischen Skalierung in Kubernetes: wie man sie effektiv nutzt</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/484344/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ns/da/j-/nsdaj-fipddnizqrkx4z2rzvyc0.png"></div><br>  Um Kubernetes vollst√§ndig zu beherrschen, m√ºssen Sie die verschiedenen M√∂glichkeiten zur Skalierung von Clusterressourcen kennen: Laut <a href="https://speakerdeck.com/thockin/everything-you-ever-wanted-to-know-about-resource-scheduling-dot-dot-dot-almost">den Entwicklern des Systems</a> ist dies eine der Hauptaufgaben von Kubernetes.  Wir haben eine umfassende √úberpr√ºfung der Mechanismen der horizontalen und vertikalen automatischen Skalierung und Gr√∂√üen√§nderung von Clustern sowie Empfehlungen zu deren effektiver Verwendung vorbereitet. <br><br>  Der <a href="https://www.magalix.com/blog/kubernetes-autoscaling-101">Artikel Kubernetes Autoscaling 101: Cluster Autoscaler, Horizontal Autoscaler und Vertical Pod Autoscaler wurde</a> von einem Team √ºbersetzt, das <a href="https://www.magalix.com/blog/kubernetes-autoscaling-101">Autoscaling</a> in <a href="https://mcs.mail.ru/containers/">Kubernetes aaS von Mail.ru</a> implementiert hat <a href="https://mcs.mail.ru/containers/">.</a> <br><a name="habracut"></a><br><h2>  Warum es wichtig ist, √ºber Skalierung nachzudenken </h2><br>  <a href="https://mcs.mail.ru/blog/kubernetes-for-much-stuff">Kubernetes</a> ist ein Tool f√ºr Ressourcenverwaltung und Orchestrierung.  Nat√ºrlich ist es sch√∂n, an coolen Bereitstellungs-, √úberwachungs- und Pod-Verwaltungsfunktionen zu basteln (das Pod-Modul ist eine Gruppe von Containern, die als Antwort auf eine Anfrage gestartet werden). <br><br>  Sie sollten jedoch √ºber folgende Punkte nachdenken: <br><br><ol><li>  Wie skaliere ich Module und Anwendungen? <br></li><li>  Wie k√∂nnen Container betriebsbereit und effizient gehalten werden? <br></li><li>  Wie kann man auf st√§ndige √Ñnderungen im Code und bei den Arbeitslasten der Benutzer reagieren? <br></li></ol><br>  Die Konfiguration von Kubernetes-Clustern zum Ausgleichen von Ressourcen und Leistung kann eine Herausforderung sein und erfordert Expertenwissen √ºber die internen Funktionen von Kubernetes.  Die Auslastung Ihrer Anwendung oder Dienste kann im Laufe des Tages oder sogar innerhalb einer Stunde schwanken, sodass der Ausgleich am besten als kontinuierlicher Prozess dargestellt wird. <br><br><h2>  Kubernetes Autoscale-Ebenen </h2><br>  Effektives Autoscaling erfordert die Koordination zwischen zwei Ebenen: <br><br><ol><li>  Pod-Ebene, einschlie√ülich horizontaler (Horizontal Pod Autoscaler, HPA) und vertikaler Auto-Skalierung (Vertical Pod Autoscaler, VPA).  Dadurch werden die verf√ºgbaren Ressourcen f√ºr Ihre Container skaliert. <br></li><li>  Die Clusterebene, die vom Cluster Autoscaler (CA) -System gesteuert wird, erh√∂ht oder verringert die Anzahl der Knoten im Cluster. <br></li></ol><br><h2>  Horizontales Auto-Scale-Modul (HPA) </h2><br>  Wie der Name schon sagt, skaliert HPA die Anzahl der Pod-Replikate.  Als Ausl√∂ser f√ºr die √Ñnderung der Anzahl der Replikate verwenden die meisten Entwickler die CPU- und Speicherlast.  Sie k√∂nnen das System jedoch basierend auf <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">benutzerdefinierten Metriken</a> , deren <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Kombination</a> oder sogar <a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/external-metrics-autoscaling">externen Metriken</a> skalieren. <br><br>  Hoher HPA-Workflow: <br><br><ol><li>  HPA √ºberpr√ºft kontinuierlich die w√§hrend der Installation angegebenen Metrikwerte mit einem Standardintervall von 30 Sekunden. <br></li><li>  HPA versucht, die Anzahl der Module zu erh√∂hen, wenn der angegebene Schwellenwert erreicht ist. <br></li><li>  HPA aktualisiert die Anzahl der Replikate im Bereitstellungs- / Replikationscontroller. <br></li><li>  Der Bereitstellungs- / Replikationscontroller stellt dann alle erforderlichen Zusatzmodule bereit. <br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/879/338/b0e/879338b0e99aa2b652ab1406e9677319.jpg"><br>  <i>HPA startet den Modulbereitstellungsprozess, wenn der Schwellenwert f√ºr Metriken erreicht ist</i> <br><br>  Beachten Sie bei der Verwendung von HPA Folgendes: <br><br><ul><li>  Das standardm√§√üige HPA-Validierungsintervall betr√§gt 30 Sekunden.  Sie wird im Controller-Manager mit dem Flag <i>Horizontal-Pod-Autoscaler-Sync-Period gesetzt</i> . <br></li><li>  Der relative Standardfehler betr√§gt 10%. <br></li><li>  Nach der letzten Erh√∂hung der Modulanzahl erwartet HPA, dass sich die Metriken innerhalb von drei Minuten stabilisieren.  Dieses Intervall wird durch das <i>Horizontal-Pod-Autoscaler-Upscale-Delay-</i> Flag festgelegt. <br></li><li> Nach der letzten Reduzierung der Modulanzahl rechnet die HPA mit einer Stabilisierung von f√ºnf Minuten.  Dieses Intervall wird durch das <i>Horizontal-Pod-Autoscaler-Downscale-Delay-</i> Flag festgelegt. <br></li><li>  HPA funktioniert am besten mit Bereitstellungsobjekten, nicht mit Replikationscontrollern.  Die horizontale automatische Skalierung ist nicht kompatibel mit fortlaufenden Aktualisierungen, die Replikationscontroller direkt manipulieren.  Bei der Bereitstellung h√§ngt die Anzahl der Replikate direkt von den Bereitstellungsobjekten ab. <br></li></ul><br><h2>  Vertikale automatische Skalierung von Pods </h2><br>  Vertical Auto Scale (VPA) weist vorhandenen Pods mehr (oder weniger) Prozessor- oder Speicherzeit zu.  Es eignet sich f√ºr Pods mit oder ohne Stateful Stateless, ist aber haupts√§chlich f√ºr Stateful Services gedacht.  Sie k√∂nnen jedoch VPA f√ºr zustandslose Module anwenden, wenn Sie die Menge der urspr√ºnglich zugewiesenen Ressourcen automatisch anpassen m√ºssen. <br><br>  VPA reagiert auch auf OOM-Ereignisse (zu wenig Speicher, zu wenig Speicher).  Um die Prozessorzeit und die Speichergr√∂√üe zu √§ndern, m√ºssen Sie den Pod neu starten.  Beim Neustart beachtet der VPA das <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">Pods Distribution Budget (PDB</a> ), um die Mindestanzahl von Modulen zu gew√§hrleisten. <br><br>  Sie k√∂nnen die minimale und maximale Menge an Ressourcen f√ºr jedes Modul festlegen.  Sie k√∂nnen also die maximale Gr√∂√üe des zugewiesenen Speichers auf 8 GB beschr√§nken.  Dies ist n√ºtzlich, wenn die aktuellen Knoten nur nicht mehr als 8 GB Speicher pro Container zuweisen k√∂nnen.  Detaillierte Spezifikationen und Betriebsmechanismen sind im <a href="">offiziellen VPA-Wiki beschrieben</a> . <br><br>  Dar√ºber hinaus verf√ºgt VPA √ºber eine interessante Empfehlungsfunktion (VPA Recommender).  Es verfolgt die Ressourcennutzung und die OOM-Ereignisse aller Module, um basierend auf einem intelligenten Algorithmus unter Ber√ºcksichtigung historischer Metriken neue Werte f√ºr Speicher- und Prozessorzeit bereitzustellen.  Es gibt auch eine API, die einen Pod-Deskriptor verwendet und die vorgeschlagenen Ressourcenwerte zur√ºckgibt. <br><br>  Es ist anzumerken, dass VPA Recommender das "Limit" der Ressourcen nicht √ºberwacht.  Dies kann dazu f√ºhren, dass das Modul Ressourcen innerhalb von Knoten monopolisiert.  Es ist besser, einen Grenzwert auf Namespace-Ebene festzulegen, um eine enorme Verschwendung von Arbeitsspeicher oder Prozessorzeit zu vermeiden. <br><br>  √úbergeordnetes VPA-Schema: <br><br><ol><li>  Der VPA √ºberpr√ºft kontinuierlich die w√§hrend der Installation angegebenen Metrikwerte mit einem Standardintervall von 10 Sekunden. <br></li><li>  Wenn der angegebene Schwellenwert erreicht ist, versucht der VPA, die zugewiesene Menge an Ressourcen zu √§ndern. <br></li><li>  VPA aktualisiert die Ressourcenmenge im Deployment / Replication Controller. <br></li><li>  Wenn Sie die Module neu starten, werden alle neuen Ressourcen auf die erstellten Instanzen angewendet. <br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/738/82e/e90/73882ee906b515bcf4c9a8ab42a742b6.jpg"><br>  <i>VPA f√ºgt die erforderliche Menge an Ressourcen hinzu</i> <br><br>  Beachten Sie bei der Verwendung von VPA die folgenden Punkte: <br><br><ul><li>  Das Skalieren erfordert einen obligatorischen Neustart des Pods.  Dies ist erforderlich, um einen instabilen Betrieb nach √Ñnderungen zu vermeiden.  Aus Gr√ºnden der Zuverl√§ssigkeit werden die Module basierend auf den neu zugewiesenen Ressourcen neu gestartet und auf die Knoten verteilt. <br></li><li>  VPA und HPA sind noch nicht miteinander kompatibel und k√∂nnen nicht mit denselben Pods arbeiten.  Wenn Sie beide Skalierungsmechanismen in demselben Cluster verwenden, stellen Sie sicher, dass die Einstellungen nicht zulassen, dass sie f√ºr dieselben Objekte aktiviert werden. <br></li><li>  VPA konfiguriert Containeranforderungen f√ºr Ressourcen nur basierend auf der vorherigen und aktuellen Verwendung.  Der Einsatz von Ressourcen ist nicht begrenzt.  Es kann Probleme mit dem fehlerhaften Betrieb von Anwendungen geben, die immer mehr Ressourcen belegen. Dies f√ºhrt dazu, dass Kubernetes diesen Pod ausschaltet. <br></li><li>  VPA befindet sich noch in einem fr√ºhen Entwicklungsstadium.  Seien Sie darauf vorbereitet, dass das System in naher Zukunft einige √Ñnderungen erfahren kann.  Sie k√∂nnen die <a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler">bekannten Einschr√§nkungen</a> und <a href="">Entwicklungspl√§ne</a> nachlesen.  Also, in den Pl√§nen, die gemeinsame Arbeit von VPA und HPA sowie die Bereitstellung von Modulen zusammen mit einer vertikalen Auto-Scaling-Richtlinie f√ºr sie zu implementieren (zum Beispiel, ein spezielles Label "erfordert VPA"). <br></li></ul><br><h2>  Automatische Skalierung des Kubernetes-Clusters </h2><br>  Cluster Autoscaler (CA) √§ndert die Anzahl der Knoten basierend auf der Anzahl der wartenden Pods.  Das System sucht regelm√§√üig nach ausstehenden Modulen und erh√∂ht die Clustergr√∂√üe, wenn mehr Ressourcen erforderlich sind und der Cluster die festgelegten Grenzwerte nicht √ºberschreitet.  Die Zertifizierungsstelle interagiert mit dem Cloud-Dienstanbieter, fordert zus√§tzliche Knoten von ihm an oder gibt die inaktiven frei.  Die erste √∂ffentlich verf√ºgbare Version von CA wurde in Kubernetes 1.8 eingef√ºhrt. <br><br>  √úbergeordnetes Betriebsschema CA: <br><br><ol><li>  Die Zertifizierungsstelle pr√ºft im Standby-Modus mit einem Standardintervall von 10 Sekunden, ob Module vorhanden sind. <br></li><li>  Befinden sich ein oder mehrere Module aufgrund unzureichender Ressourcen im Cluster f√ºr ihre Verteilung im Standby-Zustand, wird versucht, einen oder mehrere zus√§tzliche Knoten vorzubereiten. <br></li><li>  Wenn der Cloud-Dienstanbieter den erforderlichen Knoten zuweist, tritt er dem Cluster bei und kann die Pod-Module bedienen. <br></li><li>  Kubernetes Scheduler verteilt ausstehende Module an einen neuen Host.  Wenn danach einige Module noch im Standby-Zustand bleiben, wird der Vorgang wiederholt und dem Cluster werden neue Knoten hinzugef√ºgt. <br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/13a/65b/ac3/13a65bac364aca04c83fc6fe1a59c60f.jpg"><br>  <i>Automatische Zuordnung von Clusterknoten in der Cloud</i> <br><br>  Beachten Sie bei der Verwendung von CA Folgendes: <br><br><ul><li>  CA stellt sicher, dass alle Module im Cluster unabh√§ngig von der Prozessorauslastung ausgef√ºhrt werden k√∂nnen.  Au√üerdem versucht er sicherzustellen, dass sich keine unn√∂tigen Knoten im Cluster befinden. <br></li><li>  Die CA registriert den Skalierungsbedarf nach ca. 30 Sekunden. <br></li><li>  Nachdem der Knoten nicht mehr ben√∂tigt wird, wartet die Zertifizierungsstelle standardm√§√üig 10 Minuten, bevor das System skaliert wird. <br></li><li>  Im Autoscale-System gibt es das Konzept der Expander.  Dies sind verschiedene Strategien zum Ausw√§hlen einer Gruppe von Knoten, zu denen neue hinzugef√ºgt werden. <br></li><li>  Verwenden Sie verantwortungsbewusst die Option <i>cluster-autoscaler.kubernetes.io/safe-to-evict (true)</i> .  Wenn Sie viele Pods installieren oder wenn viele auf alle Knoten verteilt sind, k√∂nnen Sie den Cluster nicht mehr verkleinern. <br></li><li>  Verwenden Sie <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">PodDisruptionBudgets</a> , um das Entfernen von Pods zu verhindern, da ein Teil Ihrer Anwendung m√∂glicherweise vollst√§ndig fehlschl√§gt. <br></li></ul><br><h2>  Wie Kubernetes Autoscale-Systeme interagieren </h2><br>  F√ºr eine perfekte Harmonie sollte die automatische Skalierung sowohl auf Pod-Ebene (HPA / VPA) als auch auf Cluster-Ebene angewendet werden.  Sie interagieren relativ einfach miteinander: <br><br><ol><li>  HPA oder VPA aktualisiert Pod-Replikate oder Ressourcen, die vorhandenen Pods zugewiesen sind. <br></li><li>  Wenn nicht gen√ºgend Knoten f√ºr die geplante Skalierung vorhanden sind, stellt CA das Vorhandensein von Pods im Ruhezustand fest. <br></li><li>  CA weist neue Knoten zu. <br></li><li>  Module werden auf neue Knoten verteilt. <br></li></ol><br><img src="https://habrastorage.org/getpro/habr/post_images/20a/8c0/bef/20a8c0befe51c509efc2354c43aeaf13.jpg"><br>  <i>Kubernetes kollaboratives Skalierungssystem</i> <br><br><h2>  H√§ufige Fehler bei der automatischen Skalierung von Kubernetes </h2><br>  Es gibt einige typische Probleme, auf die Entwickler sto√üen, wenn sie versuchen, die automatische Skalierung anzuwenden. <br><br>  HPA und VPA sind abh√§ngig von Metriken und einigen historischen Daten.  Wenn nicht gen√ºgend Ressourcen zugewiesen werden, werden die Module reduziert und k√∂nnen keine Metriken generieren.  In diesem Fall findet keine automatische Skalierung statt. <br><br>  Der Skalierungsvorgang selbst ist zeitkritisch.  Wir m√∂chten, dass Module und Cluster schnell skaliert werden k√∂nnen, bevor Benutzer Probleme oder Ausf√§lle bemerken.  Daher sollte die durchschnittliche Skalierungszeit der Pods und des Clusters ber√ºcksichtigt werden. <br><br>  Ideales Szenario - 4 Minuten: <br><br><ol><li>  30 Sekunden  Aktualisierung der Zielmetriken: 30-60 Sekunden. <br></li><li>  30 Sekunden  HPA pr√ºft metrische Werte: 30 Sekunden. <br></li><li>  Weniger als 2 Sekunden  Die Pod-Module werden erstellt und in den Standby-Zustand versetzt: 1 Sekunde. <br></li><li>  Weniger als 2 Sekunden  CA erkennt anstehende Module und sendet Anrufe, um Knoten vorzubereiten: 1 Sekunde. <br></li><li>  3 Minuten  Der Cloud-Anbieter weist Knoten zu.  K8s wartet, bis sie bereit sind: bis zu 10 Minuten (abh√§ngig von mehreren Faktoren). <br></li></ol><br>  Schlimmstes (realistischeres) Szenario - 12 Minuten: <br><br><ol><li>  30 Sekunden  Aktualisierung der Zielmetriken <br></li><li>  30 Sekunden  HPA validiert metrische Werte. <br></li><li>  Weniger als 2 Sekunden  Die Pod-Module werden erstellt und in den Standby-Zustand versetzt. <br></li><li>  Weniger als 2 Sekunden  CA erkennt anstehende Module und sendet Anrufe, um Knoten vorzubereiten. <br></li><li>  10 Minuten.  Der Cloud-Anbieter weist Knoten zu.  K8s wartet bis sie fertig sind.  Die Wartezeit h√§ngt von mehreren Faktoren ab, wie der Verz√∂gerung des Lieferanten, der Verz√∂gerung des Betriebssystems, der Arbeit der Hilfswerkzeuge. <br></li></ol><br>  Verwechseln Sie die Skalierungsmechanismen von Cloud-Anbietern nicht mit unserer Zertifizierungsstelle.  Letzteres funktioniert innerhalb des Kubernetes-Clusters, w√§hrend der Cloud-Provider-Mechanismus auf der Basis der Knotenzuweisung arbeitet.  Er wei√ü nicht, was mit Ihren Pods oder Ihrer Anwendung passiert.  Diese Systeme arbeiten parallel. <br><br><h2>  So verwalten Sie die Skalierung in Kubernetes </h2><br><ol><li>  Kubernetes ist ein Tool f√ºr Ressourcenverwaltung und Orchestrierung.  Cluster-Pod- und Ressourcenverwaltungsvorg√§nge sind ein wichtiger Meilenstein bei der Entwicklung von Kubernetes. <br></li><li>  Erfahren Sie mehr √ºber die Pod-Skalierbarkeitslogik f√ºr HPA und VPA. <br></li><li>  CA sollte nur verwendet werden, wenn Sie die Anforderungen Ihrer Schalen und Beh√§lter genau kennen. <br></li><li>  F√ºr eine optimale Cluster-Konfiguration m√ºssen Sie verstehen, wie die verschiedenen Skalierungssysteme zusammenarbeiten. <br></li><li>  Ber√ºcksichtigen Sie bei der Bewertung der Skalierungszeiten die schlechtesten und besten Szenarien. <br></li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de484344/">https://habr.com/ru/post/de484344/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de484332/index.html">Fokus auf Aufgabenverwaltung. Wie wir unser Managementsystem machen</a></li>
<li><a href="../de484336/index.html">Regeln f√ºr die Arbeit mit dynamischen Arrays und benutzerdefinierten Auflistungsklassen</a></li>
<li><a href="../de484338/index.html">Samsungs Neon-Projekt: Digital Bankers, Fernsehmoderatoren, Companions</a></li>
<li><a href="../de484340/index.html">Java Digest f√ºr den 17. Januar. Die ersten zwei Wochen des neuen Jahres</a></li>
<li><a href="../de484342/index.html">Toolkit basierend auf Eclipse und GTK + f√ºr ‚ÄúToradex Colibri T20 (Linux)‚Äù</a></li>
<li><a href="../de484356/index.html">Ein interessantes Projekt in einem freundlichen Team, oder wie viel kostet der richtige Mitarbeiter?</a></li>
<li><a href="../de484358/index.html">Portfoliomanagement in R</a></li>
<li><a href="../de484364/index.html">Mit 26 Jahren leitet Yana Harlan die Entwicklung einer Raumfahrtmaschine. N√§chstes Jahr planen sie den Start.</a></li>
<li><a href="../de484370/index.html">Slurm SRE - lernen, die Zufriedenheit der Benutzer zu gew√§hrleisten</a></li>
<li><a href="../de484372/index.html">Smart House mit Xiaomi am Beispiel einer Sauna</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💲 👨🏿‍🏫 👨🏽‍🏭 USE, RED, PgBouncer, ses paramètres et surveillance 👨🏾‍🏫 🎵 👜</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous avons commencé à mettre à jour la surveillance de PgBouncer dans notre service et avons décidé de tout peigner un peu. Pour que tout soit en form...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>USE, RED, PgBouncer, ses paramètres et surveillance</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/okmeter/blog/420429/"><img align="left" width="359" src="https://habrastorage.org/webt/l4/xy/iz/l4xyize9ztzrmf303fot3iylnc8.png" alt="Pgbouncer USE RED"><br><p>  Nous avons commencé à mettre à jour la surveillance de PgBouncer dans notre service et avons décidé de tout peigner un peu.  Pour que tout soit en forme, nous avons utilisé les méthodologies de surveillance des performances les plus célèbres: USE (Utilisation, Saturation, Erreurs) de Brendan Gregg et RED (Requêtes, Erreurs, Durées) de Tom Wilkie. </p><br><p>  Sous la cinématique se trouve une histoire avec des graphiques sur le fonctionnement de pgbouncer, la configuration qui le gère et comment utiliser USE / RED pour choisir les bonnes mesures pour le surveiller. </p><a name="habracut"></a><br><h2 id="snachala-pro-sami-metody">  Tout d'abord sur les méthodes elles-mêmes </h2><br><p>  Bien que ces méthodes soient assez connues (à propos d’ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">elles, c’était déjà sur Habré, bien qu’elles ne soient pas très détaillées</a> ), ce n’est pas qu’elles soient répandues dans la pratique. </p><br><h3 id="use">  UTILISATION </h3><br><blockquote>  Pour chaque ressource, gardez une trace de l'élimination, de la saturation et des erreurs. <br>  Brendan gregg </blockquote><p>  Ici, une <strong>ressource</strong> est un composant physique distinct - un processeur, un disque, un bus, etc.  Mais pas seulement - les performances de certaines ressources logicielles peuvent également être prises en compte par cette méthode, en particulier les ressources virtuelles, telles que les conteneurs / groupes de contrôle avec des limites, il est également pratique de le considérer. </p><br><p> <strong>U - Élimination</strong> : soit un pourcentage du temps (à partir de l'intervalle d'observation) lorsque la ressource était occupée à un travail utile.  Comme, par exemple, le chargement du processeur ou de l'utilisation du disque à 90% signifie que 90% du temps a été pris par quelque chose d'utile) ou, pour des ressources telles que la mémoire, c'est le pourcentage de mémoire utilisé. </p><br><p>  Dans tous les cas, un recyclage à 100% signifie que la ressource ne peut pas être utilisée plus que maintenant.  Et soit le travail restera bloqué en attendant sa sortie / aller dans la file d'attente, soit il y aura des erreurs.  Ces deux scénarios sont couverts par les deux métriques USE restantes correspondantes: </p><br><p>  <strong>S - Saturation</strong> , c'est aussi la saturation: une mesure de la quantité de travail «différé» / en file d'attente. </p><br><p>  <strong>E - Erreurs</strong> : nous comptons simplement le nombre d'échecs.  Les erreurs / pannes affectent les performances, mais peuvent ne pas être immédiatement visibles en raison de la récupération des opérations inversées ou des mécanismes de tolérance aux pannes avec des périphériques de sauvegarde, etc. </p><br><h3 id="red">  Rouge </h3><br><p>  Tom Wilkie (qui travaille maintenant à Grafana Labs) a été frustré par la méthodologie USE, ou plutôt, par sa faible applicabilité dans certains cas et son incohérence avec la pratique.  Comment, par exemple, mesurer la saturation de la mémoire?  Ou comment mesurer les erreurs de bus système dans la pratique? </p><br><blockquote>  Il s'avère que Linux rapporte vraiment le nombre de bogues. <br>  T. Wilkie </blockquote><p>  Bref, pour suivre les performances et le comportement des microservices, il propose une autre méthode adaptée: mesurer, là encore, trois indicateurs: </p><br><p>  <strong>R - Rate</strong> : Le nombre de requêtes par seconde. <br>  <strong>E - Erreurs</strong> : combien de demandes ont renvoyé une erreur. <br>  <strong>D - Durée</strong> : temps nécessaire au traitement de la demande.  C'est la latence, la "latence" (© Sveta Smirnova :), le temps de réponse, etc. </p><br><p>  En général, USE est plus approprié pour surveiller les ressources, et RED pour les services et leur charge de travail / charge utile. </p><br><h2 id="pgbouncer">  Pgbouncer </h2><br><p>  Être un service, il a en même temps toutes sortes de limites et de ressources internes.  On peut en dire autant de Postgres, auquel les clients accèdent via ce PgBouncer.  Par conséquent, pour une surveillance complète dans cette situation, les deux méthodes sont nécessaires. </p><br><p>  Pour comprendre comment appliquer ces méthodes à un videur, vous devez comprendre les détails de son appareil.  Il ne suffit pas de le surveiller comme une boîte noire - "le processus pgbouncer est-il vivant" ou "le port est-il ouvert", car  en cas de problème, cela ne permettra pas de comprendre exactement quoi et comment il s'est cassé et quoi faire. </p><br><p>  À quoi ressemble généralement PgBouncer du point de vue du client: </p><br><ol><li>  le client se connecte </li><li>  [le client fait une demande - reçoit une réponse] x combien de fois il a besoin </li></ol><br><p>  Ici, j'ai dessiné un diagramme des états clients correspondants du point de vue de PgBoucer: <br><img src="https://habrastorage.org/webt/zb/mh/ot/zbmhotvidvuxnsbzp04-bqtgqhk.jpeg"></p><br><p> Dans le processus de connexion, l'autorisation peut se produire à la fois localement (fichiers, certificats, et même PAM et hba à partir de nouvelles versions), et à distance - c'est-à-dire  dans la base de données à laquelle la connexion est tentée.  Ainsi, l'état de connexion a un sous-état supplémentaire.  Appelons-le <code>Executing</code> pour indiquer que <code>auth_query</code> est en <code>auth_query</code> dans la base de données à ce moment: <br><img src="https://habrastorage.org/webt/e4/ib/pb/e4ibpbf6ef5q9xcdy2fantydkc4.png"></p><br><p>  Mais ces connexions client correspondent en fait aux connexions backend / amont que PgBouncer ouvre dans le pool et en détient un nombre limité.  Et ils donnent une telle connexion au client uniquement pour le temps - pour la durée de la session, de la transaction ou de la demande, selon le type de regroupement (déterminé par le paramètre <code>pool_mode</code> ).  Le plus souvent, le regroupement de transactions est utilisé (nous en discuterons principalement plus tard) - lorsque la connexion est établie avec le client pour une transaction, et le reste du temps, le client n'est pas connecté au serveur en fait.  Ainsi, l'état "actif" du client nous en dit peu, et nous le diviserons en substrats: <br><img src="https://habrastorage.org/webt/uv/q4/tj/uvq4tjzbbauunpwzhboxc8s3pgu.png"></p><br><p>  Chacun de ces clients appartient à son propre pool de connexions, qui sera émis pour être utilisé par la connexion réelle à Postgres.  C'est la tâche principale de PgBouncer - limiter le nombre de connexions à Postgres. </p><br><p>  En raison des connexions de serveur limitées, une situation peut se produire lorsque le client doit répondre directement à la demande, mais il n'y a pas de connexion gratuite maintenant.  Le client est ensuite mis en file d'attente et sa connexion passe à l'état <code>CL_WAITING</code> .  Ainsi, le diagramme d'état doit être complété: <br><img src="https://habrastorage.org/webt/2v/ny/yu/2vnyyuhlqher6cc5q5izwjtu7te.png"><br>  Étant donné que cela peut se produire dans le cas où le client se connecte uniquement et qu'il doit exécuter une demande d'autorisation, l'état <code>CL_WAITING_LOGIN</code> également. </p><br><p>  Si nous regardons maintenant de l'arrière - du côté des connexions au serveur, alors, en conséquence, ils sont dans de tels états: lorsque l'autorisation se produit immédiatement après la connexion - <code>SV_LOGIN</code> , émis et (éventuellement) utilisé par le client - <code>SV_ACTIVE</code> , ou librement - <code>SV_IDLE</code> . </p><br><h2 id="use-dlya-pgbouncer">  UTILISATION pour PgBouncer </h2><br><p>  Nous arrivons ainsi à la (version naïve) Utilisation d'un pool spécifique: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">Pool</span></span> utiliz =    /  </code> </pre> <br><p>  PgBouncer possède une base de données d'utilitaires pgbouncer spéciale dans laquelle se trouve une <code>SHOW POOLS</code> qui affiche l'état actuel des connexions de chaque pool: <br><img src="https://habrastorage.org/webt/xz/_o/eb/xz_oebvf-0yahuvdfzrxx3iass0.png"><br>  Il existe 4 connexions client ouvertes et toutes sont <code>cl_active</code> .  Sur 5 connexions serveur - 4 <code>sv_active</code> et une dans le nouvel état <code>sv_used</code> . </p><br><div class="spoiler">  <b class="spoiler_title">Qu'est-ce que sv_used vraiment sur les différents paramètres de pgbouncer sans rapport avec la surveillance</b> <div class="spoiler_text"><p>  Donc, <code>sv_used</code> ne signifie pas «la connexion est utilisée», comme vous pourriez le penser, mais «la connexion a déjà été utilisée et n'a pas été utilisée depuis longtemps».  Le fait est que PgBouncer utilise les connexions serveur en mode LIFO par défaut - c'est-à-dire  Tout d'abord, les connexions nouvellement publiées sont utilisées, puis celles récemment utilisées, etc.  se déplaçant progressivement vers des composés utilisés depuis longtemps.  Par conséquent, les connexions au serveur depuis le bas d'une telle pile peuvent «mal tourner».  Et ils devraient être vérifiés pour la vivacité avant utilisation, ce qui est fait en utilisant <code>server_check_query</code> , tandis qu'ils sont vérifiés, l'état sera <code>sv_tested</code> . </p><br><p>  La documentation indique que LIFO est activé par défaut, comme  alors "un petit nombre de connexions obtient la charge de travail la plus importante. Et cela donne les meilleures performances quand il y a un serveur servant la base de données derrière pgbouncer", c'est-à-dire  comme dans le cas le plus typique.  Je crois que l'augmentation potentielle des performances est due aux économies de commutation des performances entre plusieurs processus backend.  Mais cela n'a pas fonctionné de manière fiable, car  Ce détail d'implémentation existe depuis&gt; 12 ans et va au-delà de l'historique des validations sur github et de la profondeur de mon intérêt =) </p><br><p>  Ainsi, il semblait étrange et <code>server_check_delay</code> avec les réalités actuelles que la valeur par défaut du paramètre <code>server_check_delay</code> , qui détermine que le serveur n'a pas été utilisé depuis trop longtemps et doit être vérifié avant de le donner au client, est de 30 secondes.  Ceci malgré le fait que par défaut tcp_keepalive est activé simultanément avec les paramètres par défaut - commencez à vérifier la connexion keep alive avec des échantillons 2 heures après son inactivité. <br>  Il s'avère que dans une situation de rafale / surtension de connexions clientes qui veulent faire quelque chose sur le serveur, un délai supplémentaire est introduit sur <code>server_check_query</code> , qui, bien que " <code>SELECT 1;</code> peut encore prendre ~ 100 microsecondes, et si <code>server_check_query = ';'</code>  alors vous pouvez économiser ~ 30 microsecondes =) </p><br><p>  Mais l'hypothèse selon laquelle travailler sur quelques connexions = sur plusieurs processus postgres principaux "principaux" sera plus efficace, cela me semble douteux.  Le processus de travail postgres met en cache (méta) des informations sur chaque table qui a été consultée dans cette connexion.  Si vous avez un grand nombre de tables, alors ce relcache peut augmenter considérablement et prendre beaucoup de mémoire, jusqu'à l'échange des pages du processus 0_o.  Pour contourner ce <code>server_lifetime</code> , utilisez le paramètre <code>server_lifetime</code> (la valeur par défaut est 1 heure), par lequel la connexion au serveur sera fermée pour rotation.  Mais d'un autre côté, il existe un paramètre <code>server_round_robin</code> qui fera basculer le mode d'utilisation des connexions de LIFO à FIFO, répartissant les demandes des clients sur les connexions de serveur de manière plus uniforme. </p></div></div><br><p>  <code>SHOW POOLS</code> prenant <code>SHOW POOLS</code> métriques de <code>SHOW POOLS</code> (par un exportateur de prometheus), nous pouvons tracer ces états: </p><br><p><img src="https://habrastorage.org/webt/i8/8f/-x/i88f-xpwo_2hj7z6iq6qbnatsju.png"></p><br><p>  Mais pour vous mettre à disposition, vous devez répondre à quelques questions: </p><br><ul><li>  Quelle est la taille de la piscine? </li><li>  Comment compter le nombre de composés utilisés?  En blagues ou dans le temps, en moyenne ou en pointe? </li></ul><br><h3 id="razmer-pula">  Taille de la piscine </h3><br><p>  Tout est compliqué ici, comme dans la vie.  Au total, il y a déjà cinq limites de paramètres dans le pbbouncer! </p><br><ul><li>  <code>pool_size</code> peut être défini pour chaque base de données.  Un pool séparé est créé pour chaque paire DB / utilisateur, c'est-à-dire  à partir de n'importe quel utilisateur <em>supplémentaire</em> , vous pouvez créer un autre backend <code>pool_size</code> / Postgres.  Parce que  si <code>pool_size</code> pas défini, il tombe dans <code>default_pool_size</code> , qui vaut 20 par défaut, puis il s'avère que chaque utilisateur qui a le droit de se connecter à la base de données (et qui travaille via pgbouncer) peut potentiellement créer 20 processus Postgres, ce qui semble être peu.  Mais si vous avez de nombreux utilisateurs différents des bases de données ou des bases de données elles-mêmes, et que les pools ne sont pas enregistrés auprès d'un utilisateur fixe, c'est-à-dire  sera créé à la volée (puis supprimé par <code>autodb_idle_timeout</code> ), cela peut être dangereux =) <br><blockquote>  Il peut être utile de laisser <code>default_pool_size</code> petit, juste pour chaque pompier. <br></blockquote></li><li>  <code>max_db_connections</code> - juste nécessaire pour limiter le nombre total de connexions à une base de données, car  sinon, les clients qui se comportent mal peuvent créer de nombreux processus d'arrière-plan / postgres.  Et par défaut ici - illimité ¯_ (ツ) _ / ¯ <br><blockquote>  Vous devriez peut-être changer les <code>max_db_connections</code> par défaut, par exemple, vous pouvez vous concentrer sur les <code>max_connections</code> vos Postgres (par défaut 100).  Mais si vous avez beaucoup de PgBouncers ... <br></blockquote></li><li>  <code>reserve_pool_size</code> - en fait, si <code>pool_size</code> tout utilisé, alors PgBouncer peut ouvrir plusieurs connexions supplémentaires à la base.  Si je comprends bien, cela est fait pour faire face à une augmentation de la charge.  Nous y reviendrons. </li><li>  <code>max_user_connections</code> - C'est, au contraire, la limite des connexions d'un utilisateur à toutes les bases de données, c'est-à-dire  pertinent si vous avez plusieurs bases de données et qu'elles relèvent des mêmes utilisateurs. </li><li>  <code>max_client_conn</code> - combien de connexions client PgBouncer acceptera au total.  Par défaut, comme d'habitude, a une signification très étrange - 100. Autrement dit,  il est supposé que si plus de 100 clients se bloquent soudainement, alors ils ont juste besoin de <code>reset</code> silencieusement au niveau TCP et de <code>reset</code> (enfin, dans les journaux, je dois admettre, ce sera "plus de connexions autorisées (max_client_conn)")). <br><blockquote>  Il peut être utile de créer <code>max_client_conn &gt;&gt; SUM ( pool_size' )</code> , par exemple, 10 fois plus. <br></blockquote></li></ul><br><p>  En plus de <code>SHOW POOLS</code> service pseudo-base pgbouncer fournit également la <code>SHOW DATABASES</code> , qui montre les limites réellement appliquées à un pool particulier: <br><img src="https://habrastorage.org/webt/1v/lv/4h/1vlv4hviyhxz1pbh9puc6xxim9o.jpeg"></p><br><h3 id="servernye-soedineniya">  Connexions au serveur </h3><br><p>  Encore une fois - comment mesurer le nombre de composés utilisés? <br>  En blagues en moyenne / en pointe / en temps? </p><br><p>  En pratique, il est assez problématique de surveiller l'utilisation des piscines par le videur avec des outils répandus, comme  pgbouncer lui-même ne fournit qu'une image momentanée, et comme souvent ne fait pas d'enquête, il y a toujours la possibilité d'une image erronée en raison de l'échantillonnage.  Voici un exemple réel où, selon le moment où l'exportateur a travaillé - au début de la minute ou à la fin - l'image des composés ouverts et utilisés change fondamentalement: </p><br><p><img src="https://habrastorage.org/webt/i3/ch/qb/i3chqbtvyp3p6nm0bayw62pf3hq.png"></p><br><p>  Ici, tous les changements dans la charge / utilisation des connexions ne sont qu'une fiction, un artefact des redémarrages du collecteur de statistiques.  Ici vous pouvez voir les graphiques de connexion dans Postgres pendant cette période et les descripteurs de fichiers du videur et de la PG - aucun changement: </p><br><p><img src="https://habrastorage.org/webt/n7/bh/4r/n7bh4r_2h21ypaxhtr7njv2u8xa.png"></p><br><p>  Revenons à la question de l'élimination.  Nous avons décidé d'utiliser une approche combinée dans notre service - nous échantillonnons <code>SHOW POOLS</code> une fois par seconde, et une fois par minute, nous rendons le nombre moyen et maximum de connexions dans chaque classe: </p><br><p><img src="https://habrastorage.org/webt/ea/v5/ei/eav5eimcl7fofctvc24oaymzsu4.png"></p><br><p>  Et si nous divisons le nombre de ces connexions d'état actives par la taille du pool, nous obtenons l'utilisation moyenne et maximale de ce pool et pouvons alerter s'il est proche de 100%. </p><br><p>  De plus, PgBouncer dispose d'une commande <code>SHOW STATS</code> qui affichera des statistiques d'utilisation pour chaque base de données proxy: <br><img src="https://habrastorage.org/webt/mo/wz/_q/mowz_qavy_zspkljbvnehbj1bpc.png"><br>  Nous sommes plus intéressés par la colonne <code>total_query_time</code> - le temps passé par toutes les connexions dans le processus d'exécution des requêtes dans postgres.  Et à partir de la version 1.8, il y a aussi la métrique <code>total_xact_time</code> - le temps passé dans les transactions.  Sur la base de ces métriques, nous pouvons construire une utilisation du temps de connexion au serveur; cet indicateur n'est pas soumis, contrairement au calcul à partir des états de connexion, à des problèmes d'échantillonnage, car  ces <code>total_..._time</code> sont cumulatifs et ne passent rien: </p><br><p><img src="https://habrastorage.org/webt/p3/1l/iv/p31liv1gccpj3rxnxav-nbelck0.png"><br>  Comparez <br><img src="https://habrastorage.org/webt/yk/rt/gd/ykrtgdu5s8_pcltl3w3mmcuj4oo.png"><br>  On peut voir que l'échantillonnage ne montre pas tous les moments d'utilisation élevée à ~ 100%, et les spectacles query_time. </p><br><h3 id="saturation-i-pgbouncer">  Saturation et PgBouncer </h3><br><p>  Pourquoi avez-vous besoin de surveiller la saturation, en raison de la forte utilisation, il est déjà clair que tout va mal? </p><br><p>  Le problème est que, quelle que soit la façon dont vous mesurez l'utilisation, même les compteurs accumulés ne peuvent pas afficher une utilisation locale des ressources à 100% si elle ne se produit qu'à des intervalles très courts.  Par exemple, vous disposez de couronnes ou d'autres processus synchrones qui peuvent simultanément lancer des requêtes vers la base de données à la commande.  Si ces demandes sont courtes, alors l'utilisation, mesurée sur des échelles de minutes et même de secondes, peut être faible, mais en même temps, à un moment donné, ces demandes ont été forcées d'attendre en ligne pour l'exécution.  Cela est similaire avec une situation d'utilisation du processeur à 100% et une moyenne de charge élevée - comme le temps processeur est toujours là, mais néanmoins de nombreux processus attendent leur exécution. </p><br><p>  Comment cette situation peut-elle être surveillée? <code>cl_waiting</code> bien, encore une fois, nous pouvons simplement compter le nombre de clients dans l'état <code>cl_waiting</code> selon <code>SHOW POOLS</code> .  Dans une situation normale, il y a zéro, et plus de zéro signifie un débordement de ce pool: </p><br><p><img src="https://habrastorage.org/webt/q1/tg/tj/q1tgtjcqgrqpavfpkf0kyg31hjq.png"></p><br><p>  Il reste le problème que <code>SHOW POOLS</code> ne peut être échantillonné, et dans une situation avec des couronnes synchrones ou quelque chose comme ça, nous pouvons simplement ignorer et ne pas voir de tels clients en attente. </p><br><p>  Vous pouvez utiliser cette astuce, pgbouncer lui-même peut détecter une utilisation à 100% du pool et ouvrir le pool de sauvegarde.  Deux paramètres en sont responsables: <code>reserve_pool_size</code> - pour sa taille, comme je l'ai dit, et <code>reserve_pool_timeout</code> - combien de secondes un client doit <code>waiting</code> avant d'utiliser le pool de sauvegarde.  Ainsi, si nous voyons sur le graphique des connexions serveur que le nombre de connexions ouvertes à Postgres est supérieur à pool_size, alors il y avait une saturation du pool, comme ceci: <br><img src="https://habrastorage.org/webt/ne/ec/hn/neechnkp9sffd8g3rjov_3jjijm.png"><br>  De toute évidence, quelque chose comme des couronnes une fois par heure fait beaucoup de demandes et occupe complètement la piscine.  Et même si nous ne voyons pas le moment où <code>active</code> connexions <code>active</code> dépassent la limite <code>pool_size</code> , pgbouncer a quand même été obligé d'ouvrir des connexions supplémentaires. </p><br><p>  Également sur ce graphique, le travail des paramètres <code>server_idle_timeout</code> est clairement visible - après combien arrêter la fermeture et fermer les connexions qui ne sont pas utilisées.  Par défaut, c'est 10 minutes, ce que nous voyons sur le graphique - après les pics <code>active</code> à exactement 5h00, à 6h00, etc.  (selon cron <code>0 * * * *</code> ), les connexions restent <code>idle</code> + <code>used</code> 10 minutes supplémentaires et se ferment. </p><br><p>  Si vous vivez à la pointe du progrès et avez mis à jour PgBouncer au cours des 9 derniers mois, vous pouvez trouver dans la colonne <code>SHOW STATS</code> <code>total_wait_time</code> , qui montre le mieux la saturation, car  considère cumulativement le temps passé par les clients en <code>waiting</code> .  Par exemple, ici - l' <code>waiting</code> est apparu à 16h30: <br><img src="https://habrastorage.org/webt/ck/-q/qt/ck-qqth3dhvsqsw1zzeuvkjg4wa.png"><br>  Et <code>wait_time</code> , qui est comparable et affecte clairement <code>average query time</code> , peut être vu de 15h15 à presque 19: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  Néanmoins, la surveillance de l'état des connexions client est toujours très utile, car  cela vous permet de découvrir non seulement le fait que toutes les connexions à une telle base de données ont été dépensées et que les clients doivent attendre, mais aussi parce que <code>SHOW POOLS</code> divisé en pools séparés par les utilisateurs, et <code>SHOW STATS</code> ne le fait pas, il vous permet de savoir quels clients ont utilisé toutes les connexions à la base spécifiée - selon la colonne <code>sv_active</code> du pool correspondant.  Ou par métrique </p><br><pre> <code class="hljs pgsql">sum_by(<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">database</span></span>, metric(<span class="hljs-type"><span class="hljs-type">name</span></span>="pgbouncer.clients.count", state="active-link")):</code> </pre> <br><p><img src="https://habrastorage.org/webt/k_/0s/lf/k_0slfupzfrdz4npoiz8kbxgpko.png"></p><br><p>  Chez okmeter, nous sommes allés encore plus loin et avons ajouté une ventilation des connexions utilisées par les adresses IP des clients qui les ont ouvertes et utilisées.  Cela vous permet de comprendre exactement quelles instances d'application se comportent différemment: <br><img src="https://habrastorage.org/webt/dk/fr/5j/dkfr5j_yvxgmm2f0b5dvru4b9nk.png"><br>  Nous voyons ici les adresses IP de kubernetes spécifiques de foyers que nous devons traiter. </p><br><h3 id="errors">  Des erreurs </h3><br><p>  Il n'y a rien de particulièrement compliqué ici: pgbouncer écrit des journaux dans lesquels il signale des erreurs si la limite de connexions client est atteinte, le délai de connexion au serveur, etc.  Nous n'avons pas encore atteint les journaux de pgbouncer :( </p><br><h2 id="red-dlya-pgbouncer">  ROUGE pour PgBouncer </h2><br><p>  Alors que l'USAGE est plus axé sur les performances, au sens de goulots d'étranglement, RED, à mon avis, concerne davantage les caractéristiques du trafic entrant et sortant en général, et non les goulots d'étranglement.  Autrement dit, RED répond à la question - tout fonctionne-t-il bien, et sinon, USE aidera à comprendre quel est le problème. </p><br><h2 id="requests">  Prérequis </h2><br><p>  Il semblerait que tout soit assez simple pour la base de données SQL et pour l'extracteur de proxy / connexion dans une telle base de données - les clients exécutent des instructions SQL, qui sont des requêtes.  A partir de <code>SHOW STATS</code> nous prenons <code>total_requests</code> et <code>total_requests</code> sa dérivée temporelle </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"pgbouncer.total_requests"</span></span>, database: <span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fa/7u/o2/fa7uo2r8b6_4y6z9e2bounudzmw.png"></p><br><p>  Mais en fait, il existe différents modes de tirage, et le plus courant est les transactions.  L'unité d'oeuvre pour ce mode est une transaction, pas une requête.  Par conséquent, à partir de la version 1.8, Pgbouner fournit déjà deux autres statistiques - <code>total_query_count</code> , au lieu de <code>total_requests</code> , et <code>total_xact_count</code> - le nombre de transactions terminées. </p><br><p>  Désormais, la charge de travail peut être caractérisée non seulement en termes de nombre de demandes / transactions terminées, mais, par exemple, vous pouvez consulter le nombre moyen de demandes par transaction dans différentes bases de données, en les divisant les unes les autres </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_requests"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>)) / rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_xact"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/xd/uh/3w/xduh3wsb-bww1tysfwtdhcw-seg.png"></p><br><p>  Ici, nous voyons des changements évidents dans le profil de charge, ce qui peut être la raison du changement de performances.  Et si vous ne regardez que le taux de transactions ou de demandes, vous ne le verrez peut-être pas. </p><br><h2 id="red-errors">  Erreurs RED </h2><br><p>  Il est clair que RED et USE se recoupent sur la surveillance des erreurs, mais il me semble que les erreurs dans USE concernent principalement des erreurs de traitement des demandes dues à une utilisation à 100%, c'est-à-dire  lorsque le service refuse d'accepter plus de travail.  Et pour RED, il serait préférable de mesurer précisément les erreurs du point de vue du client, des demandes du client.  C'est-à-dire, non seulement dans une situation où le pool dans PgBouncer est plein ou une autre limite a fonctionné, mais aussi lorsque des délais d'expiration de demande tels que "l'annulation de la déclaration en raison du délai de la déclaration", les annulations et les annulations de transactions par le client lui-même ont fonctionné, etc. e.  niveau supérieur, plus proche des types d'erreurs de la logique métier. </p><br><h2 id="durations">  Durées </h2><br><p>  Ici encore, <code>SHOW STATS</code> avec les compteurs cumulatifs <code>total_xact_time</code> , <code>total_query_time</code> et <code>total_wait_time</code> nous aidera, en les divisant par le nombre de demandes et de transactions, respectivement, nous obtenons le temps moyen de demande, le temps moyen de transaction, le temps d'attente moyen par transaction.  J'ai déjà montré un graphique sur le premier et le troisième: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  Que pouvez-vous obtenir d'autre?  L'antipattern bien connu pour travailler avec la base de données et Postgres, en particulier, lorsque l'application ouvre une transaction, fait une demande, puis commence (pendant longtemps) à traiter ses résultats, ou pire encore - va à un autre service / base de données et y fait des demandes.  Pendant tout ce temps, la transaction «se bloque» dans le postgres ouvert, le service retourne et fait encore plus de requêtes, met à jour dans la base de données, et seulement alors ferme la transaction.  Pour les postgres, c'est particulièrement désagréable, car  pg les travailleurs sont chers.  Nous pouvons donc surveiller quand une telle application est <code>idle in transaction</code> dans le postgres lui-même - selon la colonne d' <code>state</code> dans <code>pg_stat_activity</code> , mais il y a toujours les mêmes problèmes décrits avec l'échantillonnage, car  <code>pg_stat_activity</code> ne donne que l'image actuelle.  Dans PgBouncer, nous pouvons soustraire le temps passé par les clients dans les requêtes <code>total_query_time</code> du temps passé dans les transactions <code>total_xact_time</code> - ce sera le temps d'une telle marche au ralenti.  Si le résultat est toujours divisé par <code>total_xact_time</code> , il sera normalisé: une valeur de 1 correspond à une situation où les clients sont <code>idle in transaction</code> 100% du temps.  Et avec une telle normalisation, il est facile de comprendre à quel point tout est mauvais: </p><br><p><img src="https://habrastorage.org/webt/t9/kn/io/t9knioh2ckzd_photgqvcq543x4.png"></p><br><p>  De plus, en revenant à Duration, la métrique <code>total_xact_time - total_query_time</code> peut être divisée par le nombre de transactions pour voir le montant moyen de l'application inactive par transaction. </p><br><hr><br><p>  À mon avis, les méthodes USE / RED sont les plus utiles pour structurer les mesures que vous prenez et pourquoi.  Étant donné que nous sommes engagés dans une surveillance à temps plein et que nous devons effectuer la surveillance de divers composants d'infrastructure, ces méthodes nous aident à prendre les mesures correctes, à faire les bons calendriers et déclencheurs pour nos clients. </p><br><p>  <em>Un bon suivi ne peut pas être fait tout de suite, c'est un processus itératif.</em>  <em>Dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">okmeter.io,</a> nous avons juste une surveillance continue (il y a beaucoup de choses, mais demain ce sera mieux et plus détaillé :)</em> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420429/">https://habr.com/ru/post/fr420429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420413/index.html">SQLite et NW.js - instructions pas à pas pour créer des amitiés solides</a></li>
<li><a href="../fr420415/index.html">Tout ce que vous vouliez savoir sur les tests d'adaptateurs Wi-Fi, mais aviez peur de demander</a></li>
<li><a href="../fr420419/index.html">Coureurs pour ceux qui aiment l'humiliation ou comment nous avons changé et modifié PixJam</a></li>
<li><a href="../fr420423/index.html">Problèmes d'interface avec le passage au sol</a></li>
<li><a href="../fr420425/index.html">Théorie et pratique de l'utilisation de HBase</a></li>
<li><a href="../fr420431/index.html">Mars Guide pratique de la terraformation pour les femmes au foyer</a></li>
<li><a href="../fr420433/index.html">«Format du vendredi»: routes musicales - qu'est-ce que c'est et pourquoi elles ne sont pas en Russie</a></li>
<li><a href="../fr420435/index.html">Démarrage rapide avec ARM Mbed: développement de microcontrôleurs modernes pour débutants</a></li>
<li><a href="../fr420437/index.html">Une introduction pratique au gestionnaire de paquets pour Kubernetes - Helm</a></li>
<li><a href="../fr420439/index.html">Fintech digest: les investissements dans les fintech ont atteint 57 milliards de dollars, la vitesse des transactions augmente et les coûts baissent</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
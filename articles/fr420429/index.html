<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí≤ üë®üèø‚Äçüè´ üë®üèΩ‚Äçüè≠ USE, RED, PgBouncer, ses param√®tres et surveillance üë®üèæ‚Äçüè´ üéµ üëú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous avons commenc√© √† mettre √† jour la surveillance de PgBouncer dans notre service et avons d√©cid√© de tout peigner un peu. Pour que tout soit en form...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>USE, RED, PgBouncer, ses param√®tres et surveillance</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/okmeter/blog/420429/"><img align="left" width="359" src="https://habrastorage.org/webt/l4/xy/iz/l4xyize9ztzrmf303fot3iylnc8.png" alt="Pgbouncer USE RED"><br><p>  Nous avons commenc√© √† mettre √† jour la surveillance de PgBouncer dans notre service et avons d√©cid√© de tout peigner un peu.  Pour que tout soit en forme, nous avons utilis√© les m√©thodologies de surveillance des performances les plus c√©l√®bres: USE (Utilisation, Saturation, Erreurs) de Brendan Gregg et RED (Requ√™tes, Erreurs, Dur√©es) de Tom Wilkie. </p><br><p>  Sous la cin√©matique se trouve une histoire avec des graphiques sur le fonctionnement de pgbouncer, la configuration qui le g√®re et comment utiliser USE / RED pour choisir les bonnes mesures pour le surveiller. </p><a name="habracut"></a><br><h2 id="snachala-pro-sami-metody">  Tout d'abord sur les m√©thodes elles-m√™mes </h2><br><p>  Bien que ces m√©thodes soient assez connues (√† propos d‚Äô <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">elles, c‚Äô√©tait d√©j√† sur Habr√©, bien qu‚Äôelles ne soient pas tr√®s d√©taill√©es</a> ), ce n‚Äôest pas qu‚Äôelles soient r√©pandues dans la pratique. </p><br><h3 id="use">  UTILISATION </h3><br><blockquote>  Pour chaque ressource, gardez une trace de l'√©limination, de la saturation et des erreurs. <br>  Brendan gregg </blockquote><p>  Ici, une <strong>ressource</strong> est un composant physique distinct - un processeur, un disque, un bus, etc.  Mais pas seulement - les performances de certaines ressources logicielles peuvent √©galement √™tre prises en compte par cette m√©thode, en particulier les ressources virtuelles, telles que les conteneurs / groupes de contr√¥le avec des limites, il est √©galement pratique de le consid√©rer. </p><br><p> <strong>U - √âlimination</strong> : soit un pourcentage du temps (√† partir de l'intervalle d'observation) lorsque la ressource √©tait occup√©e √† un travail utile.  Comme, par exemple, le chargement du processeur ou de l'utilisation du disque √† 90% signifie que 90% du temps a √©t√© pris par quelque chose d'utile) ou, pour des ressources telles que la m√©moire, c'est le pourcentage de m√©moire utilis√©. </p><br><p>  Dans tous les cas, un recyclage √† 100% signifie que la ressource ne peut pas √™tre utilis√©e plus que maintenant.  Et soit le travail restera bloqu√© en attendant sa sortie / aller dans la file d'attente, soit il y aura des erreurs.  Ces deux sc√©narios sont couverts par les deux m√©triques USE restantes correspondantes: </p><br><p>  <strong>S - Saturation</strong> , c'est aussi la saturation: une mesure de la quantit√© de travail ¬´diff√©r√©¬ª / en file d'attente. </p><br><p>  <strong>E - Erreurs</strong> : nous comptons simplement le nombre d'√©checs.  Les erreurs / pannes affectent les performances, mais peuvent ne pas √™tre imm√©diatement visibles en raison de la r√©cup√©ration des op√©rations invers√©es ou des m√©canismes de tol√©rance aux pannes avec des p√©riph√©riques de sauvegarde, etc. </p><br><h3 id="red">  Rouge </h3><br><p>  Tom Wilkie (qui travaille maintenant √† Grafana Labs) a √©t√© frustr√© par la m√©thodologie USE, ou plut√¥t, par sa faible applicabilit√© dans certains cas et son incoh√©rence avec la pratique.  Comment, par exemple, mesurer la saturation de la m√©moire?  Ou comment mesurer les erreurs de bus syst√®me dans la pratique? </p><br><blockquote>  Il s'av√®re que Linux rapporte vraiment le nombre de bogues. <br>  T. Wilkie </blockquote><p>  Bref, pour suivre les performances et le comportement des microservices, il propose une autre m√©thode adapt√©e: mesurer, l√† encore, trois indicateurs: </p><br><p>  <strong>R - Rate</strong> : Le nombre de requ√™tes par seconde. <br>  <strong>E - Erreurs</strong> : combien de demandes ont renvoy√© une erreur. <br>  <strong>D - Dur√©e</strong> : temps n√©cessaire au traitement de la demande.  C'est la latence, la "latence" (¬© Sveta Smirnova :), le temps de r√©ponse, etc. </p><br><p>  En g√©n√©ral, USE est plus appropri√© pour surveiller les ressources, et RED pour les services et leur charge de travail / charge utile. </p><br><h2 id="pgbouncer">  Pgbouncer </h2><br><p>  √ätre un service, il a en m√™me temps toutes sortes de limites et de ressources internes.  On peut en dire autant de Postgres, auquel les clients acc√®dent via ce PgBouncer.  Par cons√©quent, pour une surveillance compl√®te dans cette situation, les deux m√©thodes sont n√©cessaires. </p><br><p>  Pour comprendre comment appliquer ces m√©thodes √† un videur, vous devez comprendre les d√©tails de son appareil.  Il ne suffit pas de le surveiller comme une bo√Æte noire - "le processus pgbouncer est-il vivant" ou "le port est-il ouvert", car  en cas de probl√®me, cela ne permettra pas de comprendre exactement quoi et comment il s'est cass√© et quoi faire. </p><br><p>  √Ä quoi ressemble g√©n√©ralement PgBouncer du point de vue du client: </p><br><ol><li>  le client se connecte </li><li>  [le client fait une demande - re√ßoit une r√©ponse] x combien de fois il a besoin </li></ol><br><p>  Ici, j'ai dessin√© un diagramme des √©tats clients correspondants du point de vue de PgBoucer: <br><img src="https://habrastorage.org/webt/zb/mh/ot/zbmhotvidvuxnsbzp04-bqtgqhk.jpeg"></p><br><p> Dans le processus de connexion, l'autorisation peut se produire √† la fois localement (fichiers, certificats, et m√™me PAM et hba √† partir de nouvelles versions), et √† distance - c'est-√†-dire  dans la base de donn√©es √† laquelle la connexion est tent√©e.  Ainsi, l'√©tat de connexion a un sous-√©tat suppl√©mentaire.  Appelons-le <code>Executing</code> pour indiquer que <code>auth_query</code> est en <code>auth_query</code> dans la base de donn√©es √† ce moment: <br><img src="https://habrastorage.org/webt/e4/ib/pb/e4ibpbf6ef5q9xcdy2fantydkc4.png"></p><br><p>  Mais ces connexions client correspondent en fait aux connexions backend / amont que PgBouncer ouvre dans le pool et en d√©tient un nombre limit√©.  Et ils donnent une telle connexion au client uniquement pour le temps - pour la dur√©e de la session, de la transaction ou de la demande, selon le type de regroupement (d√©termin√© par le param√®tre <code>pool_mode</code> ).  Le plus souvent, le regroupement de transactions est utilis√© (nous en discuterons principalement plus tard) - lorsque la connexion est √©tablie avec le client pour une transaction, et le reste du temps, le client n'est pas connect√© au serveur en fait.  Ainsi, l'√©tat "actif" du client nous en dit peu, et nous le diviserons en substrats: <br><img src="https://habrastorage.org/webt/uv/q4/tj/uvq4tjzbbauunpwzhboxc8s3pgu.png"></p><br><p>  Chacun de ces clients appartient √† son propre pool de connexions, qui sera √©mis pour √™tre utilis√© par la connexion r√©elle √† Postgres.  C'est la t√¢che principale de PgBouncer - limiter le nombre de connexions √† Postgres. </p><br><p>  En raison des connexions de serveur limit√©es, une situation peut se produire lorsque le client doit r√©pondre directement √† la demande, mais il n'y a pas de connexion gratuite maintenant.  Le client est ensuite mis en file d'attente et sa connexion passe √† l'√©tat <code>CL_WAITING</code> .  Ainsi, le diagramme d'√©tat doit √™tre compl√©t√©: <br><img src="https://habrastorage.org/webt/2v/ny/yu/2vnyyuhlqher6cc5q5izwjtu7te.png"><br>  √âtant donn√© que cela peut se produire dans le cas o√π le client se connecte uniquement et qu'il doit ex√©cuter une demande d'autorisation, l'√©tat <code>CL_WAITING_LOGIN</code> √©galement. </p><br><p>  Si nous regardons maintenant de l'arri√®re - du c√¥t√© des connexions au serveur, alors, en cons√©quence, ils sont dans de tels √©tats: lorsque l'autorisation se produit imm√©diatement apr√®s la connexion - <code>SV_LOGIN</code> , √©mis et (√©ventuellement) utilis√© par le client - <code>SV_ACTIVE</code> , ou librement - <code>SV_IDLE</code> . </p><br><h2 id="use-dlya-pgbouncer">  UTILISATION pour PgBouncer </h2><br><p>  Nous arrivons ainsi √† la (version na√Øve) Utilisation d'un pool sp√©cifique: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">Pool</span></span> utiliz =    /  </code> </pre> <br><p>  PgBouncer poss√®de une base de donn√©es d'utilitaires pgbouncer sp√©ciale dans laquelle se trouve une <code>SHOW POOLS</code> qui affiche l'√©tat actuel des connexions de chaque pool: <br><img src="https://habrastorage.org/webt/xz/_o/eb/xz_oebvf-0yahuvdfzrxx3iass0.png"><br>  Il existe 4 connexions client ouvertes et toutes sont <code>cl_active</code> .  Sur 5 connexions serveur - 4 <code>sv_active</code> et une dans le nouvel √©tat <code>sv_used</code> . </p><br><div class="spoiler">  <b class="spoiler_title">Qu'est-ce que sv_used vraiment sur les diff√©rents param√®tres de pgbouncer sans rapport avec la surveillance</b> <div class="spoiler_text"><p>  Donc, <code>sv_used</code> ne signifie pas ¬´la connexion est utilis√©e¬ª, comme vous pourriez le penser, mais ¬´la connexion a d√©j√† √©t√© utilis√©e et n'a pas √©t√© utilis√©e depuis longtemps¬ª.  Le fait est que PgBouncer utilise les connexions serveur en mode LIFO par d√©faut - c'est-√†-dire  Tout d'abord, les connexions nouvellement publi√©es sont utilis√©es, puis celles r√©cemment utilis√©es, etc.  se d√©pla√ßant progressivement vers des compos√©s utilis√©s depuis longtemps.  Par cons√©quent, les connexions au serveur depuis le bas d'une telle pile peuvent ¬´mal tourner¬ª.  Et ils devraient √™tre v√©rifi√©s pour la vivacit√© avant utilisation, ce qui est fait en utilisant <code>server_check_query</code> , tandis qu'ils sont v√©rifi√©s, l'√©tat sera <code>sv_tested</code> . </p><br><p>  La documentation indique que LIFO est activ√© par d√©faut, comme  alors "un petit nombre de connexions obtient la charge de travail la plus importante. Et cela donne les meilleures performances quand il y a un serveur servant la base de donn√©es derri√®re pgbouncer", c'est-√†-dire  comme dans le cas le plus typique.  Je crois que l'augmentation potentielle des performances est due aux √©conomies de commutation des performances entre plusieurs processus backend.  Mais cela n'a pas fonctionn√© de mani√®re fiable, car  Ce d√©tail d'impl√©mentation existe depuis&gt; 12 ans et va au-del√† de l'historique des validations sur github et de la profondeur de mon int√©r√™t =) </p><br><p>  Ainsi, il semblait √©trange et <code>server_check_delay</code> avec les r√©alit√©s actuelles que la valeur par d√©faut du param√®tre <code>server_check_delay</code> , qui d√©termine que le serveur n'a pas √©t√© utilis√© depuis trop longtemps et doit √™tre v√©rifi√© avant de le donner au client, est de 30 secondes.  Ceci malgr√© le fait que par d√©faut tcp_keepalive est activ√© simultan√©ment avec les param√®tres par d√©faut - commencez √† v√©rifier la connexion keep alive avec des √©chantillons 2 heures apr√®s son inactivit√©. <br>  Il s'av√®re que dans une situation de rafale / surtension de connexions clientes qui veulent faire quelque chose sur le serveur, un d√©lai suppl√©mentaire est introduit sur <code>server_check_query</code> , qui, bien que " <code>SELECT 1;</code> peut encore prendre ~ 100 microsecondes, et si <code>server_check_query = ';'</code>  alors vous pouvez √©conomiser ~ 30 microsecondes =) </p><br><p>  Mais l'hypoth√®se selon laquelle travailler sur quelques connexions = sur plusieurs processus postgres principaux "principaux" sera plus efficace, cela me semble douteux.  Le processus de travail postgres met en cache (m√©ta) des informations sur chaque table qui a √©t√© consult√©e dans cette connexion.  Si vous avez un grand nombre de tables, alors ce relcache peut augmenter consid√©rablement et prendre beaucoup de m√©moire, jusqu'√† l'√©change des pages du processus 0_o.  Pour contourner ce <code>server_lifetime</code> , utilisez le param√®tre <code>server_lifetime</code> (la valeur par d√©faut est 1 heure), par lequel la connexion au serveur sera ferm√©e pour rotation.  Mais d'un autre c√¥t√©, il existe un param√®tre <code>server_round_robin</code> qui fera basculer le mode d'utilisation des connexions de LIFO √† FIFO, r√©partissant les demandes des clients sur les connexions de serveur de mani√®re plus uniforme. </p></div></div><br><p>  <code>SHOW POOLS</code> prenant <code>SHOW POOLS</code> m√©triques de <code>SHOW POOLS</code> (par un exportateur de prometheus), nous pouvons tracer ces √©tats: </p><br><p><img src="https://habrastorage.org/webt/i8/8f/-x/i88f-xpwo_2hj7z6iq6qbnatsju.png"></p><br><p>  Mais pour vous mettre √† disposition, vous devez r√©pondre √† quelques questions: </p><br><ul><li>  Quelle est la taille de la piscine? </li><li>  Comment compter le nombre de compos√©s utilis√©s?  En blagues ou dans le temps, en moyenne ou en pointe? </li></ul><br><h3 id="razmer-pula">  Taille de la piscine </h3><br><p>  Tout est compliqu√© ici, comme dans la vie.  Au total, il y a d√©j√† cinq limites de param√®tres dans le pbbouncer! </p><br><ul><li>  <code>pool_size</code> peut √™tre d√©fini pour chaque base de donn√©es.  Un pool s√©par√© est cr√©√© pour chaque paire DB / utilisateur, c'est-√†-dire  √† partir de n'importe quel utilisateur <em>suppl√©mentaire</em> , vous pouvez cr√©er un autre backend <code>pool_size</code> / Postgres.  Parce que  si <code>pool_size</code> pas d√©fini, il tombe dans <code>default_pool_size</code> , qui vaut 20 par d√©faut, puis il s'av√®re que chaque utilisateur qui a le droit de se connecter √† la base de donn√©es (et qui travaille via pgbouncer) peut potentiellement cr√©er 20 processus Postgres, ce qui semble √™tre peu.  Mais si vous avez de nombreux utilisateurs diff√©rents des bases de donn√©es ou des bases de donn√©es elles-m√™mes, et que les pools ne sont pas enregistr√©s aupr√®s d'un utilisateur fixe, c'est-√†-dire  sera cr√©√© √† la vol√©e (puis supprim√© par <code>autodb_idle_timeout</code> ), cela peut √™tre dangereux =) <br><blockquote>  Il peut √™tre utile de laisser <code>default_pool_size</code> petit, juste pour chaque pompier. <br></blockquote></li><li>  <code>max_db_connections</code> - juste n√©cessaire pour limiter le nombre total de connexions √† une base de donn√©es, car  sinon, les clients qui se comportent mal peuvent cr√©er de nombreux processus d'arri√®re-plan / postgres.  Et par d√©faut ici - illimit√© ¬Ø_ („ÉÑ) _ / ¬Ø <br><blockquote>  Vous devriez peut-√™tre changer les <code>max_db_connections</code> par d√©faut, par exemple, vous pouvez vous concentrer sur les <code>max_connections</code> vos Postgres (par d√©faut 100).  Mais si vous avez beaucoup de PgBouncers ... <br></blockquote></li><li>  <code>reserve_pool_size</code> - en fait, si <code>pool_size</code> tout utilis√©, alors PgBouncer peut ouvrir plusieurs connexions suppl√©mentaires √† la base.  Si je comprends bien, cela est fait pour faire face √† une augmentation de la charge.  Nous y reviendrons. </li><li>  <code>max_user_connections</code> - C'est, au contraire, la limite des connexions d'un utilisateur √† toutes les bases de donn√©es, c'est-√†-dire  pertinent si vous avez plusieurs bases de donn√©es et qu'elles rel√®vent des m√™mes utilisateurs. </li><li>  <code>max_client_conn</code> - combien de connexions client PgBouncer acceptera au total.  Par d√©faut, comme d'habitude, a une signification tr√®s √©trange - 100. Autrement dit,  il est suppos√© que si plus de 100 clients se bloquent soudainement, alors ils ont juste besoin de <code>reset</code> silencieusement au niveau TCP et de <code>reset</code> (enfin, dans les journaux, je dois admettre, ce sera "plus de connexions autoris√©es (max_client_conn)")). <br><blockquote>  Il peut √™tre utile de cr√©er <code>max_client_conn &gt;&gt; SUM ( pool_size' )</code> , par exemple, 10 fois plus. <br></blockquote></li></ul><br><p>  En plus de <code>SHOW POOLS</code> service pseudo-base pgbouncer fournit √©galement la <code>SHOW DATABASES</code> , qui montre les limites r√©ellement appliqu√©es √† un pool particulier: <br><img src="https://habrastorage.org/webt/1v/lv/4h/1vlv4hviyhxz1pbh9puc6xxim9o.jpeg"></p><br><h3 id="servernye-soedineniya">  Connexions au serveur </h3><br><p>  Encore une fois - comment mesurer le nombre de compos√©s utilis√©s? <br>  En blagues en moyenne / en pointe / en temps? </p><br><p>  En pratique, il est assez probl√©matique de surveiller l'utilisation des piscines par le videur avec des outils r√©pandus, comme  pgbouncer lui-m√™me ne fournit qu'une image momentan√©e, et comme souvent ne fait pas d'enqu√™te, il y a toujours la possibilit√© d'une image erron√©e en raison de l'√©chantillonnage.  Voici un exemple r√©el o√π, selon le moment o√π l'exportateur a travaill√© - au d√©but de la minute ou √† la fin - l'image des compos√©s ouverts et utilis√©s change fondamentalement: </p><br><p><img src="https://habrastorage.org/webt/i3/ch/qb/i3chqbtvyp3p6nm0bayw62pf3hq.png"></p><br><p>  Ici, tous les changements dans la charge / utilisation des connexions ne sont qu'une fiction, un artefact des red√©marrages du collecteur de statistiques.  Ici vous pouvez voir les graphiques de connexion dans Postgres pendant cette p√©riode et les descripteurs de fichiers du videur et de la PG - aucun changement: </p><br><p><img src="https://habrastorage.org/webt/n7/bh/4r/n7bh4r_2h21ypaxhtr7njv2u8xa.png"></p><br><p>  Revenons √† la question de l'√©limination.  Nous avons d√©cid√© d'utiliser une approche combin√©e dans notre service - nous √©chantillonnons <code>SHOW POOLS</code> une fois par seconde, et une fois par minute, nous rendons le nombre moyen et maximum de connexions dans chaque classe: </p><br><p><img src="https://habrastorage.org/webt/ea/v5/ei/eav5eimcl7fofctvc24oaymzsu4.png"></p><br><p>  Et si nous divisons le nombre de ces connexions d'√©tat actives par la taille du pool, nous obtenons l'utilisation moyenne et maximale de ce pool et pouvons alerter s'il est proche de 100%. </p><br><p>  De plus, PgBouncer dispose d'une commande <code>SHOW STATS</code> qui affichera des statistiques d'utilisation pour chaque base de donn√©es proxy: <br><img src="https://habrastorage.org/webt/mo/wz/_q/mowz_qavy_zspkljbvnehbj1bpc.png"><br>  Nous sommes plus int√©ress√©s par la colonne <code>total_query_time</code> - le temps pass√© par toutes les connexions dans le processus d'ex√©cution des requ√™tes dans postgres.  Et √† partir de la version 1.8, il y a aussi la m√©trique <code>total_xact_time</code> - le temps pass√© dans les transactions.  Sur la base de ces m√©triques, nous pouvons construire une utilisation du temps de connexion au serveur; cet indicateur n'est pas soumis, contrairement au calcul √† partir des √©tats de connexion, √† des probl√®mes d'√©chantillonnage, car  ces <code>total_..._time</code> sont cumulatifs et ne passent rien: </p><br><p><img src="https://habrastorage.org/webt/p3/1l/iv/p31liv1gccpj3rxnxav-nbelck0.png"><br>  Comparez <br><img src="https://habrastorage.org/webt/yk/rt/gd/ykrtgdu5s8_pcltl3w3mmcuj4oo.png"><br>  On peut voir que l'√©chantillonnage ne montre pas tous les moments d'utilisation √©lev√©e √† ~ 100%, et les spectacles query_time. </p><br><h3 id="saturation-i-pgbouncer">  Saturation et PgBouncer </h3><br><p>  Pourquoi avez-vous besoin de surveiller la saturation, en raison de la forte utilisation, il est d√©j√† clair que tout va mal? </p><br><p>  Le probl√®me est que, quelle que soit la fa√ßon dont vous mesurez l'utilisation, m√™me les compteurs accumul√©s ne peuvent pas afficher une utilisation locale des ressources √† 100% si elle ne se produit qu'√† des intervalles tr√®s courts.  Par exemple, vous disposez de couronnes ou d'autres processus synchrones qui peuvent simultan√©ment lancer des requ√™tes vers la base de donn√©es √† la commande.  Si ces demandes sont courtes, alors l'utilisation, mesur√©e sur des √©chelles de minutes et m√™me de secondes, peut √™tre faible, mais en m√™me temps, √† un moment donn√©, ces demandes ont √©t√© forc√©es d'attendre en ligne pour l'ex√©cution.  Cela est similaire avec une situation d'utilisation du processeur √† 100% et une moyenne de charge √©lev√©e - comme le temps processeur est toujours l√†, mais n√©anmoins de nombreux processus attendent leur ex√©cution. </p><br><p>  Comment cette situation peut-elle √™tre surveill√©e? <code>cl_waiting</code> bien, encore une fois, nous pouvons simplement compter le nombre de clients dans l'√©tat <code>cl_waiting</code> selon <code>SHOW POOLS</code> .  Dans une situation normale, il y a z√©ro, et plus de z√©ro signifie un d√©bordement de ce pool: </p><br><p><img src="https://habrastorage.org/webt/q1/tg/tj/q1tgtjcqgrqpavfpkf0kyg31hjq.png"></p><br><p>  Il reste le probl√®me que <code>SHOW POOLS</code> ne peut √™tre √©chantillonn√©, et dans une situation avec des couronnes synchrones ou quelque chose comme √ßa, nous pouvons simplement ignorer et ne pas voir de tels clients en attente. </p><br><p>  Vous pouvez utiliser cette astuce, pgbouncer lui-m√™me peut d√©tecter une utilisation √† 100% du pool et ouvrir le pool de sauvegarde.  Deux param√®tres en sont responsables: <code>reserve_pool_size</code> - pour sa taille, comme je l'ai dit, et <code>reserve_pool_timeout</code> - combien de secondes un client doit <code>waiting</code> avant d'utiliser le pool de sauvegarde.  Ainsi, si nous voyons sur le graphique des connexions serveur que le nombre de connexions ouvertes √† Postgres est sup√©rieur √† pool_size, alors il y avait une saturation du pool, comme ceci: <br><img src="https://habrastorage.org/webt/ne/ec/hn/neechnkp9sffd8g3rjov_3jjijm.png"><br>  De toute √©vidence, quelque chose comme des couronnes une fois par heure fait beaucoup de demandes et occupe compl√®tement la piscine.  Et m√™me si nous ne voyons pas le moment o√π <code>active</code> connexions <code>active</code> d√©passent la limite <code>pool_size</code> , pgbouncer a quand m√™me √©t√© oblig√© d'ouvrir des connexions suppl√©mentaires. </p><br><p>  √âgalement sur ce graphique, le travail des param√®tres <code>server_idle_timeout</code> est clairement visible - apr√®s combien arr√™ter la fermeture et fermer les connexions qui ne sont pas utilis√©es.  Par d√©faut, c'est 10 minutes, ce que nous voyons sur le graphique - apr√®s les pics <code>active</code> √† exactement 5h00, √† 6h00, etc.  (selon cron <code>0 * * * *</code> ), les connexions restent <code>idle</code> + <code>used</code> 10 minutes suppl√©mentaires et se ferment. </p><br><p>  Si vous vivez √† la pointe du progr√®s et avez mis √† jour PgBouncer au cours des 9 derniers mois, vous pouvez trouver dans la colonne <code>SHOW STATS</code> <code>total_wait_time</code> , qui montre le mieux la saturation, car  consid√®re cumulativement le temps pass√© par les clients en <code>waiting</code> .  Par exemple, ici - l' <code>waiting</code> est apparu √† 16h30: <br><img src="https://habrastorage.org/webt/ck/-q/qt/ck-qqth3dhvsqsw1zzeuvkjg4wa.png"><br>  Et <code>wait_time</code> , qui est comparable et affecte clairement <code>average query time</code> , peut √™tre vu de 15h15 √† presque 19: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  N√©anmoins, la surveillance de l'√©tat des connexions client est toujours tr√®s utile, car  cela vous permet de d√©couvrir non seulement le fait que toutes les connexions √† une telle base de donn√©es ont √©t√© d√©pens√©es et que les clients doivent attendre, mais aussi parce que <code>SHOW POOLS</code> divis√© en pools s√©par√©s par les utilisateurs, et <code>SHOW STATS</code> ne le fait pas, il vous permet de savoir quels clients ont utilis√© toutes les connexions √† la base sp√©cifi√©e - selon la colonne <code>sv_active</code> du pool correspondant.  Ou par m√©trique </p><br><pre> <code class="hljs pgsql">sum_by(<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">database</span></span>, metric(<span class="hljs-type"><span class="hljs-type">name</span></span>="pgbouncer.clients.count", state="active-link")):</code> </pre> <br><p><img src="https://habrastorage.org/webt/k_/0s/lf/k_0slfupzfrdz4npoiz8kbxgpko.png"></p><br><p>  Chez okmeter, nous sommes all√©s encore plus loin et avons ajout√© une ventilation des connexions utilis√©es par les adresses IP des clients qui les ont ouvertes et utilis√©es.  Cela vous permet de comprendre exactement quelles instances d'application se comportent diff√©remment: <br><img src="https://habrastorage.org/webt/dk/fr/5j/dkfr5j_yvxgmm2f0b5dvru4b9nk.png"><br>  Nous voyons ici les adresses IP de kubernetes sp√©cifiques de foyers que nous devons traiter. </p><br><h3 id="errors">  Des erreurs </h3><br><p>  Il n'y a rien de particuli√®rement compliqu√© ici: pgbouncer √©crit des journaux dans lesquels il signale des erreurs si la limite de connexions client est atteinte, le d√©lai de connexion au serveur, etc.  Nous n'avons pas encore atteint les journaux de pgbouncer :( </p><br><h2 id="red-dlya-pgbouncer">  ROUGE pour PgBouncer </h2><br><p>  Alors que l'USAGE est plus ax√© sur les performances, au sens de goulots d'√©tranglement, RED, √† mon avis, concerne davantage les caract√©ristiques du trafic entrant et sortant en g√©n√©ral, et non les goulots d'√©tranglement.  Autrement dit, RED r√©pond √† la question - tout fonctionne-t-il bien, et sinon, USE aidera √† comprendre quel est le probl√®me. </p><br><h2 id="requests">  Pr√©requis </h2><br><p>  Il semblerait que tout soit assez simple pour la base de donn√©es SQL et pour l'extracteur de proxy / connexion dans une telle base de donn√©es - les clients ex√©cutent des instructions SQL, qui sont des requ√™tes.  A partir de <code>SHOW STATS</code> nous prenons <code>total_requests</code> et <code>total_requests</code> sa d√©riv√©e temporelle </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"pgbouncer.total_requests"</span></span>, database: <span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fa/7u/o2/fa7uo2r8b6_4y6z9e2bounudzmw.png"></p><br><p>  Mais en fait, il existe diff√©rents modes de tirage, et le plus courant est les transactions.  L'unit√© d'oeuvre pour ce mode est une transaction, pas une requ√™te.  Par cons√©quent, √† partir de la version 1.8, Pgbouner fournit d√©j√† deux autres statistiques - <code>total_query_count</code> , au lieu de <code>total_requests</code> , et <code>total_xact_count</code> - le nombre de transactions termin√©es. </p><br><p>  D√©sormais, la charge de travail peut √™tre caract√©ris√©e non seulement en termes de nombre de demandes / transactions termin√©es, mais, par exemple, vous pouvez consulter le nombre moyen de demandes par transaction dans diff√©rentes bases de donn√©es, en les divisant les unes les autres </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_requests"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>)) / rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_xact"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/xd/uh/3w/xduh3wsb-bww1tysfwtdhcw-seg.png"></p><br><p>  Ici, nous voyons des changements √©vidents dans le profil de charge, ce qui peut √™tre la raison du changement de performances.  Et si vous ne regardez que le taux de transactions ou de demandes, vous ne le verrez peut-√™tre pas. </p><br><h2 id="red-errors">  Erreurs RED </h2><br><p>  Il est clair que RED et USE se recoupent sur la surveillance des erreurs, mais il me semble que les erreurs dans USE concernent principalement des erreurs de traitement des demandes dues √† une utilisation √† 100%, c'est-√†-dire  lorsque le service refuse d'accepter plus de travail.  Et pour RED, il serait pr√©f√©rable de mesurer pr√©cis√©ment les erreurs du point de vue du client, des demandes du client.  C'est-√†-dire, non seulement dans une situation o√π le pool dans PgBouncer est plein ou une autre limite a fonctionn√©, mais aussi lorsque des d√©lais d'expiration de demande tels que "l'annulation de la d√©claration en raison du d√©lai de la d√©claration", les annulations et les annulations de transactions par le client lui-m√™me ont fonctionn√©, etc. e.  niveau sup√©rieur, plus proche des types d'erreurs de la logique m√©tier. </p><br><h2 id="durations">  Dur√©es </h2><br><p>  Ici encore, <code>SHOW STATS</code> avec les compteurs cumulatifs <code>total_xact_time</code> , <code>total_query_time</code> et <code>total_wait_time</code> nous aidera, en les divisant par le nombre de demandes et de transactions, respectivement, nous obtenons le temps moyen de demande, le temps moyen de transaction, le temps d'attente moyen par transaction.  J'ai d√©j√† montr√© un graphique sur le premier et le troisi√®me: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  Que pouvez-vous obtenir d'autre?  L'antipattern bien connu pour travailler avec la base de donn√©es et Postgres, en particulier, lorsque l'application ouvre une transaction, fait une demande, puis commence (pendant longtemps) √† traiter ses r√©sultats, ou pire encore - va √† un autre service / base de donn√©es et y fait des demandes.  Pendant tout ce temps, la transaction ¬´se bloque¬ª dans le postgres ouvert, le service retourne et fait encore plus de requ√™tes, met √† jour dans la base de donn√©es, et seulement alors ferme la transaction.  Pour les postgres, c'est particuli√®rement d√©sagr√©able, car  pg les travailleurs sont chers.  Nous pouvons donc surveiller quand une telle application est <code>idle in transaction</code> dans le postgres lui-m√™me - selon la colonne d' <code>state</code> dans <code>pg_stat_activity</code> , mais il y a toujours les m√™mes probl√®mes d√©crits avec l'√©chantillonnage, car  <code>pg_stat_activity</code> ne donne que l'image actuelle.  Dans PgBouncer, nous pouvons soustraire le temps pass√© par les clients dans les requ√™tes <code>total_query_time</code> du temps pass√© dans les transactions <code>total_xact_time</code> - ce sera le temps d'une telle marche au ralenti.  Si le r√©sultat est toujours divis√© par <code>total_xact_time</code> , il sera normalis√©: une valeur de 1 correspond √† une situation o√π les clients sont <code>idle in transaction</code> 100% du temps.  Et avec une telle normalisation, il est facile de comprendre √† quel point tout est mauvais: </p><br><p><img src="https://habrastorage.org/webt/t9/kn/io/t9knioh2ckzd_photgqvcq543x4.png"></p><br><p>  De plus, en revenant √† Duration, la m√©trique <code>total_xact_time - total_query_time</code> peut √™tre divis√©e par le nombre de transactions pour voir le montant moyen de l'application inactive par transaction. </p><br><hr><br><p>  √Ä mon avis, les m√©thodes USE / RED sont les plus utiles pour structurer les mesures que vous prenez et pourquoi.  √âtant donn√© que nous sommes engag√©s dans une surveillance √† temps plein et que nous devons effectuer la surveillance de divers composants d'infrastructure, ces m√©thodes nous aident √† prendre les mesures correctes, √† faire les bons calendriers et d√©clencheurs pour nos clients. </p><br><p>  <em>Un bon suivi ne peut pas √™tre fait tout de suite, c'est un processus it√©ratif.</em>  <em>Dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">okmeter.io,</a> nous avons juste une surveillance continue (il y a beaucoup de choses, mais demain ce sera mieux et plus d√©taill√© :)</em> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420429/">https://habr.com/ru/post/fr420429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420413/index.html">SQLite et NW.js - instructions pas √† pas pour cr√©er des amiti√©s solides</a></li>
<li><a href="../fr420415/index.html">Tout ce que vous vouliez savoir sur les tests d'adaptateurs Wi-Fi, mais aviez peur de demander</a></li>
<li><a href="../fr420419/index.html">Coureurs pour ceux qui aiment l'humiliation ou comment nous avons chang√© et modifi√© PixJam</a></li>
<li><a href="../fr420423/index.html">Probl√®mes d'interface avec le passage au sol</a></li>
<li><a href="../fr420425/index.html">Th√©orie et pratique de l'utilisation de HBase</a></li>
<li><a href="../fr420431/index.html">Mars Guide pratique de la terraformation pour les femmes au foyer</a></li>
<li><a href="../fr420433/index.html">¬´Format du vendredi¬ª: routes musicales - qu'est-ce que c'est et pourquoi elles ne sont pas en Russie</a></li>
<li><a href="../fr420435/index.html">D√©marrage rapide avec ARM Mbed: d√©veloppement de microcontr√¥leurs modernes pour d√©butants</a></li>
<li><a href="../fr420437/index.html">Une introduction pratique au gestionnaire de paquets pour Kubernetes - Helm</a></li>
<li><a href="../fr420439/index.html">Fintech digest: les investissements dans les fintech ont atteint 57 milliards de dollars, la vitesse des transactions augmente et les co√ªts baissent</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçüíª üßëüèø‚Äçü§ù‚ÄçüßëüèΩ üé° Comment supprimer 10 millions de paquets par seconde üë®üèæ‚Äçüé® üßõüèæ üìÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Au sein de l'entreprise, notre √©quipe de lutte contre les attaques DDoS s'appelle les ¬´droppers de paquets¬ª. Alors que toutes les autres √©quipes font ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment supprimer 10 millions de paquets par seconde</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/419921/"> Au sein de l'entreprise, notre √©quipe de lutte contre les attaques DDoS s'appelle les ¬´droppers de paquets¬ª.  Alors que toutes les autres √©quipes font des choses sympas avec le trafic passant par notre r√©seau, nous nous amusons √† trouver de nouvelles fa√ßons de s'en d√©barrasser. <br><br><img src="https://habrastorage.org/webt/s-/3y/un/s-3yun8pllqd7-e077fuxbk9jiw.png"><br>  <i>Photo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Brian Evans</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CC BY-SA 2.0</a></i> <br><br>  La possibilit√© de supprimer rapidement des paquets est tr√®s importante pour s'opposer aux attaques DDoS. <br><br>  Les paquets de d√©p√¥t atteignant nos serveurs peuvent √™tre effectu√©s √† plusieurs niveaux.  Chaque m√©thode a ses avantages et ses inconv√©nients.  Sous la coupe, nous regardons tout ce que nous avons test√©. <br><a name="habracut"></a><br><blockquote>  <i>Note du traducteur: dans la sortie de certaines des commandes pr√©sent√©es, des espaces suppl√©mentaires ont √©t√© supprim√©s pour maintenir la lisibilit√©.</i> </blockquote><h1>  Site de test </h1><br>  Pour la commodit√© de comparer les m√©thodes, nous vous fournirons quelques chiffres, cependant, ne les prenez pas trop √† la lettre, en raison du caract√®re artificiel des tests.  Nous utiliserons l'une de nos cartes r√©seau Intel 10 Gb / s.  Les autres caract√©ristiques du serveur ne sont pas si importantes, car nous voulons nous concentrer sur les limites du syst√®me d'exploitation, pas sur le mat√©riel. <br><br>  Nos tests se pr√©senteront comme suit: <br><br><ul><li>  Nous cr√©ons une charge d'un grand nombre de petits paquets UDP, atteignant une valeur de 14 millions de paquets par seconde; </li><li>  Tout ce trafic est dirig√© vers un c≈ìur de processeur du serveur s√©lectionn√©; </li><li>  Nous mesurons le nombre de paquets trait√©s par le noyau sur un seul c≈ìur de processeur. </li></ul><br>  Le trafic artificiel est g√©n√©r√© de mani√®re √† cr√©er une charge maximale: une adresse IP al√©atoire et un port d'exp√©diteur sont utilis√©s.  Voici √† quoi cela ressemble dans tcpdump: <br><br><pre><code class="bash hljs">$ tcpdump -ni vlan100 -c 10 -t udp and dst port 1234 IP 198.18.40.55.32059 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.51.16.30852 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.35.51.61823 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.44.42.30344 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.106.227.38592 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.48.67.19533 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.49.38.40566 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.50.73.22989 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.43.204.37895 &gt; 198.18.0.12.1234: UDP, length 16 IP 198.18.104.128.1543 &gt; 198.18.0.12.1234: UDP, length 16</code> </pre> <br>  Sur le serveur s√©lectionn√©, tous les paquets deviendront dans une file d'attente RX et, par cons√©quent, seront trait√©s par un c≈ìur.  Nous y parvenons gr√¢ce au contr√¥le de flux mat√©riel: <br><br><pre> <code class="bash hljs">ethtool -N ext0 flow-type udp4 dst-ip 198.18.0.12 dst-port 1234 action 2</code> </pre><br>  Les tests de performances sont un processus complexe.  Lorsque nous avons pr√©par√© les tests, nous avons remarqu√© que la pr√©sence de sockets bruts actifs affecte n√©gativement les performances, donc avant d'ex√©cuter les tests, vous devez vous assurer qu'aucun <code>tcpdump</code> n'est en cours d'ex√©cution.  Il existe un moyen simple de v√©rifier les mauvais processus: <br><br><pre> <code class="bash hljs">$ ss -A raw,packet_raw -l -p|cat Netid State Recv-Q Send-Q Local Address:Port p_raw UNCONN 525157 0 *:vlan100 users:((<span class="hljs-string"><span class="hljs-string">"tcpdump"</span></span>,pid=23683,fd=3))</code> </pre><br>  Et enfin, nous d√©sactivons Intel Turbo Boost sur notre serveur: <br><br><pre> <code class="hljs pgsql">echo <span class="hljs-number"><span class="hljs-number">1</span></span> | sudo tee /sys/devices/<span class="hljs-keyword"><span class="hljs-keyword">system</span></span>/cpu/intel_pstate/no_turbo</code> </pre> <br>  Malgr√© le fait que Turbo Boost soit une excellente chose et augmente le d√©bit d'au moins 20%, il g√¢che consid√©rablement l'√©cart-type dans nos tests.  Avec turbo activ√©, l'√©cart atteint ¬± 1,5%, alors que sans lui seulement 0,25%. <br><br><img src="https://habrastorage.org/webt/ic/ik/jq/icikjqda_ztydjswe8xjq07u5sa.png"><br><br><h3>  √âtape 1. D√©poser des paquets dans l'application </h3><br>  Commen√ßons par l'id√©e de livrer tous les packages √† l'application et de les ignorer.  Pour l'honn√™tet√© de l'exp√©rience, assurez-vous que les iptables n'affectent en rien les performances: <br><br><pre> <code class="bash hljs">iptables -I PREROUTING -t mangle -d 198.18.0.12 -p udp --dport 1234 -j ACCEPT iptables -I PREROUTING -t raw -d 198.18.0.12 -p udp --dport 1234 -j ACCEPT iptables -I INPUT -t filter -d 198.18.0.12 -p udp --dport 1234 -j ACCEPT</code> </pre><br>  L'application est un cycle simple dans lequel les donn√©es re√ßues sont imm√©diatement rejet√©es: <br><br><pre> <code class="python hljs">s = socket.socket(AF_INET, SOCK_DGRAM) s.bind((<span class="hljs-string"><span class="hljs-string">"0.0.0.0"</span></span>, <span class="hljs-number"><span class="hljs-number">1234</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: s.recvmmsg([...])</code> </pre><br>  Nous avons d√©j√† pr√©par√© le <a href="">code</a> , ex√©cutez: <br><br><pre> <code class="bash hljs">$ ./dropping-packets/recvmmsg-loop packets=171261 bytes=1940176</code> </pre><br>  Cette solution permet au noyau de ne prendre que 175 000 paquets de la file d'attente mat√©rielle, comme l'ont mesur√© l' <code>ethtool</code> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nos</a> <code>mmwatch</code> : <br><br><pre> <code class="bash hljs">$ mmwatch <span class="hljs-string"><span class="hljs-string">'ethtool -S ext0|grep rx_2'</span></span> rx2_packets: 174.0k/s</code> </pre><br>  Techniquement, 14 millions de paquets par seconde arrivent sur le serveur, cependant, un c≈ìur de processeur ne peut pas faire face √† un tel volume.  <code>mpstat</code> confirme: <br><br><pre> <code class="bash hljs">$ watch <span class="hljs-string"><span class="hljs-string">'mpstat -u -I SUM -P ALL 1 1|egrep -v Aver'</span></span> 01:32:05 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 01:32:06 PM 0 0.00 0.00 0.00 2.94 0.00 3.92 0.00 0.00 0.00 93.14 01:32:06 PM 1 2.17 0.00 27.17 0.00 0.00 0.00 0.00 0.00 0.00 70.65 01:32:06 PM 2 0.00 0.00 0.00 0.00 0.00 100.00 0.00 0.00 0.00 0.00 01:32:06 PM 3 0.95 0.00 1.90 0.95 0.00 3.81 0.00 0.00 0.00 92.38</code> </pre><br><br>  Comme nous pouvons le voir, l'application n'est pas un goulot d'√©tranglement: le CPU # 1 est utilis√© √† 27,17% + 2,17%, tandis que la gestion des interruptions prend 100% sur le CPU # 2. <br><br>  L'utilisation de <code>recvmessagge(2)</code> joue un r√¥le important.  Apr√®s la d√©couverte de la vuln√©rabilit√© Spectre, les appels syst√®me sont devenus encore plus chers en raison du <abbr title="Isolation de la table des pages du noyau">KPTI</abbr> et de la <abbr title="Trampoline de retour">retpoline</abbr> utilis√©s dans le noyau <br><br><pre> <code class="hljs ruby">$ tail -n +<span class="hljs-number"><span class="hljs-number">1</span></span> /sys/devices/system/cpu/vulnerabilities/* ==&gt; <span class="hljs-regexp"><span class="hljs-regexp">/sys/devices</span></span><span class="hljs-regexp"><span class="hljs-regexp">/system/cpu</span></span><span class="hljs-regexp"><span class="hljs-regexp">/vulnerabilities/meltdown</span></span> &lt;== <span class="hljs-symbol"><span class="hljs-symbol">Mitigation:</span></span> PTI ==&gt; <span class="hljs-regexp"><span class="hljs-regexp">/sys/devices</span></span><span class="hljs-regexp"><span class="hljs-regexp">/system/cpu</span></span><span class="hljs-regexp"><span class="hljs-regexp">/vulnerabilities/spectre</span></span>_v1 &lt;== <span class="hljs-symbol"><span class="hljs-symbol">Mitigation:</span></span> __user pointer sanitization ==&gt; <span class="hljs-regexp"><span class="hljs-regexp">/sys/devices</span></span><span class="hljs-regexp"><span class="hljs-regexp">/system/cpu</span></span><span class="hljs-regexp"><span class="hljs-regexp">/vulnerabilities/spectre</span></span>_v2 &lt;== <span class="hljs-symbol"><span class="hljs-symbol">Mitigation:</span></span> Full generic retpoline, IBPB, IBRS_FW</code> </pre><br><br><h3>  √âtape 2. Tuer conntrack </h3><br>  Nous avons sp√©cifiquement cr√©√© une telle charge avec diff√©rents IP et ports d'exp√©diteur afin de charger le conntrack autant que possible.  Le nombre d'entr√©es dans conntrack pendant le test tend vers le maximum possible et nous pouvons le v√©rifier: <br><br><pre> <code class="bash hljs">$ conntrack -C 2095202 $ sysctl net.netfilter.nf_conntrack_max net.netfilter.nf_conntrack_max = 2097152</code> </pre><br>  De plus, dans <code>dmesg</code> vous pouvez √©galement voir des cris de conntrack: <br><br><pre> <code class="bash hljs">[4029612.456673] nf_conntrack: nf_conntrack: table full, dropping packet [4029612.465787] nf_conntrack: nf_conntrack: table full, dropping packet [4029617.175957] net_ratelimit: 5731 callbacks suppressed</code> </pre><br>  Arr√™tons-le donc: <br><br><pre> <code class="bash hljs">iptables -t raw -I PREROUTING -d 198.18.0.12 -p udp -m udp --dport 1234 -j NOTRACK</code> </pre><br>  Et red√©marrez les tests: <br><br><pre> <code class="bash hljs">$ ./dropping-packets/recvmmsg-loop packets=331008 bytes=5296128</code> </pre><br><br>  Cela nous a permis d'atteindre la marque de 333 000 paquets par seconde.  Hourra! <br>  PS En utilisant SO_BUSY_POLL, nous pouvons atteindre jusqu'√† 470 000 par seconde, cependant, c'est un sujet pour un article s√©par√©. <br><br><h3>  √âtape 3. Filtre de lot Berkeley </h3><br>  Continuons.  Pourquoi devons-nous livrer des packages √† l'application?  Bien que ce ne soit pas une solution courante, nous pouvons lier le filtre de paquets Berkeley classique au socket en appelant <code>setsockopt(SO_ATTACH_FILTER)</code> et configurer le filtre pour supprimer les paquets dans le noyau. <br>  Pr√©parez le <a href="">code</a> , ex√©cutez: <br><br><pre> <code class="bash hljs">$ ./bpf-drop packets=0 bytes=0</code> </pre><br>  En utilisant un filtre de paquets (les filtres Berkeley classiques et avanc√©s donnent des performances √† peu pr√®s similaires), nous arrivons √† environ 512 000 paquets par seconde.  De plus, la suppression d'un paquet pendant une interruption lib√®re le processeur de la n√©cessit√© de r√©activer l'application. <br><br><h3>  √âtape 4. iptables DROP apr√®s le routage </h3><br>  Nous pouvons maintenant supprimer des paquets en ajoutant la r√®gle suivante √† iptables dans la cha√Æne INPUT: <br><br><pre> <code class="bash hljs">iptables -I INPUT -d 198.18.0.12 -p udp --dport 1234 -j DROP</code> </pre><br>  Permettez-moi de vous rappeler que nous avons d√©j√† d√©sactiv√© conntrack avec la r√®gle <code>-j NOTRACK</code> .  Ces deux r√®gles nous donnent 608 000 paquets par seconde. <br><br>  Regardons les chiffres dans iptables: <br><br><pre> <code class="bash hljs">$ mmwatch <span class="hljs-string"><span class="hljs-string">'iptables -L -v -n -x | head'</span></span> Chain INPUT (policy DROP 0 packets, 0 bytes) pkts bytes target prot opt <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> out <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> destination 605.9k/s 26.7m/s DROP udp -- * * 0.0.0.0/0 198.18.0.12 udp dpt:1234</code> </pre><br>  Bon, pas mal, mais on peut faire mieux. <br><br><h3>  √âtape 5. iptabes DROP in PREROUTING </h3><br>  Une technique plus rapide consiste √† supprimer les paquets avant le routage √† l'aide de cette r√®gle: <br><br><pre> <code class="bash hljs">iptables -I PREROUTING -t raw -d 198.18.0.12 -p udp --dport 1234 -j DROP</code> </pre> <br>  Cela nous permet de perdre 1,688 million de paquets par seconde. <br><br>  En fait, il s'agit d'un bond l√©g√®rement surprenant des performances.  Je ne comprends toujours pas les raisons, peut-√™tre que notre routage est compliqu√©, ou peut-√™tre juste un bug dans la configuration du serveur. <br><br>  Dans tous les cas, les iptables bruts sont beaucoup plus rapides. <br><br><h3>  √âtape 6. nftables DROP </h3><br>  L'utilitaire iptables est maintenant un peu ancien.  Elle a √©t√© remplac√©e par des nftables.  D√©couvrez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette vid√©o expliquant</a> pourquoi nftables est top.  Nftables promet d'√™tre plus rapide que les iptables grisonnants pour diverses raisons, y compris des rumeurs selon lesquelles les retpolines ralentissent beaucoup les iptables. <br><br>  Mais notre article ne porte toujours pas sur la comparaison des iptables et des nftables, alors essayons le plus rapidement possible: <br><br><pre> <code class="bash hljs">nft add table netdev filter nft -- add chain netdev filter input { <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> filter hook ingress device vlan100 priority -500 \; policy accept \; } nft add rule netdev filter input ip daddr 198.18.0.0/24 udp dport 1234 counter drop nft add rule netdev filter input ip6 daddr fd00::/64 udp dport 1234 counter drop</code> </pre><br>  Les compteurs peuvent √™tre vus comme ceci: <br><br><pre> <code class="bash hljs">$ mmwatch <span class="hljs-string"><span class="hljs-string">'nft --handle list chain netdev filter input'</span></span> table netdev filter { chain input { <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> filter hook ingress device vlan100 priority -500; policy accept; ip daddr 198.18.0.0/24 udp dport 1234 counter packets 1.6m/s bytes 69.6m/s drop <span class="hljs-comment"><span class="hljs-comment"># handle 2 ip6 daddr fd00::/64 udp dport 1234 counter packets 0 bytes 0 drop # handle 3 } }</span></span></code> </pre><br>  Le crochet d'entr√©e nftables a montr√© des valeurs d'environ 1,53 million de paquets.  C'est un peu moins que la cha√Æne PREROUTING dans iptables.  Mais il y a un myst√®re √† cela: th√©oriquement, le hook nftables va plus t√¥t que PREROUTING iptables et, par cons√©quent, devrait √™tre trait√© plus rapidement. <br><br>  Dans notre test, nftables est un peu plus lent que iptables, mais les nftables sont quand m√™me plus frais.  : P <br><br><h3>  √âtape 7. Tc DROP </h3><br>  De fa√ßon quelque peu inattendue, le crochet tc (contr√¥le du trafic) se produit plus t√¥t que iptables PREROUTING.  tc nous permet de s√©lectionner des paquets selon des crit√®res simples et, bien s√ªr, de les supprimer.  La syntaxe est un peu inhabituelle, nous vous sugg√©rons donc d'utiliser <a href="">ce script</a> pour la configuration.  Et nous avons besoin d'une r√®gle assez compliqu√©e qui ressemble √† ceci: <br><br><pre> <code class="bash hljs">tc qdisc add dev vlan100 ingress tc filter add dev vlan100 parent ffff: prio 4 protocol ip u32 match ip protocol 17 0xff match ip dport 1234 0xffff match ip dst 198.18.0.0/24 flowid 1:1 action drop tc filter add dev vlan100 parent ffff: protocol ipv6 u32 match ip6 dport 1234 0xffff match ip6 dst fd00::/64 flowid 1:1 action drop</code> </pre><br>  Et nous pouvons le v√©rifier en action: <br><br><pre> <code class="bash hljs">$ mmwatch <span class="hljs-string"><span class="hljs-string">'tc -s filter show dev vlan100 ingress'</span></span> filter parent ffff: protocol ip pref 4 u32 filter parent ffff: protocol ip pref 4 u32 fh 800: ht divisor 1 filter parent ffff: protocol ip pref 4 u32 fh 800::800 order 2048 key ht 800 bkt 0 flowid 1:1 (rule hit 1.8m/s success 1.8m/s) match 00110000/00ff0000 at 8 (success 1.8m/s ) match 000004d2/0000ffff at 20 (success 1.8m/s ) match c612000c/ffffffff at 16 (success 1.8m/s ) action order 1: gact action drop random <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> none pass val 0 index 1 ref 1 <span class="hljs-built_in"><span class="hljs-built_in">bind</span></span> 1 installed 1.0/s sec Action statistics: Sent 79.7m/s bytes 1.8m/s pkt (dropped 1.8m/s, overlimits 0 requeues 0)</code> </pre><br>  Le crochet tc nous a permis de supprimer jusqu'√† 1,8 million de paquets par seconde sur un seul c≈ìur.  C'est super! <br>  Mais nous pouvons le faire encore plus rapidement ... <br><br><h3>  √âtape 8. XDP_DROP </h3><br>  Et enfin, notre arme la plus puissante: XDP - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">eXpress Data Path</a> .  En utilisant XDP, nous pouvons ex√©cuter le code Berkley Packet Filter (eBPF) √©tendu directement dans le contexte du pilote r√©seau et, surtout, avant m√™me d'allouer de la m√©moire pour <code>skbuff</code> , ce qui nous promet une augmentation de la vitesse. <br><br>  En r√®gle g√©n√©rale, un projet XDP se compose de deux parties: <br><br><ul><li>  code eBPF t√©l√©chargeable </li><li>  chargeur de d√©marrage qui place le code dans la bonne interface r√©seau </li></ul><br>  L'√©criture de votre chargeur de d√©marrage est une t√¢che difficile, alors utilisez simplement la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nouvelle puce iproute2</a> et chargez le code avec une simple commande: <br><br><pre> <code class="bash hljs">ip link <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> dev ext0 xdp obj xdp-drop-ebpf.o</code> </pre><br>  Ta Dam! <br><br>  Le code source du <a href="">programme eBPF t√©l√©chargeable est disponible ici</a> .  Le programme examine les caract√©ristiques des paquets IP comme le protocole UDP, le sous-r√©seau exp√©diteur et le port de destination: <br><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (h_proto == htons(<span class="hljs-type"><span class="hljs-type">ETH_P_IP</span></span>)) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (iph-&gt;<span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">protocol</span></span></span><span class="hljs-class"> == </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">IPPROTO_UDP</span></span></span><span class="hljs-class"> &amp;&amp; (</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">htonl</span></span></span><span class="hljs-class">(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">iph</span></span></span><span class="hljs-class">-&gt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">daddr</span></span></span><span class="hljs-class">) &amp; 0</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">xFFFFFF00</span></span></span><span class="hljs-class">) == 0</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">xC6120000</span></span></span><span class="hljs-class"> // 198.18.0.0/24 &amp;&amp; </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">udph</span></span></span><span class="hljs-class">-&gt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">dest</span></span></span><span class="hljs-class"> == </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">htons</span></span></span><span class="hljs-class">(1234)) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-type"><span class="hljs-type">XDP_DROP</span></span>; } }</code> </pre><br>  Le programme XDP doit √™tre construit √† l'aide de clang moderne, qui peut g√©n√©rer un bytecode BPF.  Apr√®s cela, nous pouvons t√©l√©charger et tester les fonctionnalit√©s du programme BFP: <br><br><pre> <code class="bash hljs">$ ip link show dev ext0 4: ext0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 xdp qdisc fq state UP mode DEFAULT group default qlen 1000 link/ether 24:8a:07:8a:59:8e brd ff:ff:ff:ff:ff:ff prog/xdp id 5 tag aedc195cc0471f51 jited</code> </pre><br>  Et puis voyez les statistiques dans <code>ethtool</code> : <br><br><pre> <code class="bash hljs">$ mmwatch <span class="hljs-string"><span class="hljs-string">'ethtool -S ext0|egrep "rx"|egrep -v ": 0"|egrep -v "cache|csum"'</span></span> rx_out_of_buffer: 4.4m/s rx_xdp_drop: 10.1m/s rx2_xdp_drop: 10.1m/s</code> </pre><br>  Yoo hoo!  Avec XDP, nous pouvons supprimer jusqu'√† 10 millions de paquets par seconde! <br><br><img src="https://habrastorage.org/webt/fq/mf/e5/fqmfe5jgs1qylz7fpwryoeey0ag.png"><br>  <i>Photo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Andrew Filer</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CC BY-SA 2.0</a></i> <br><br><h3>  Conclusions </h3><br>  Nous avons r√©p√©t√© l'exp√©rience pour IPv4 et IPv6 et pr√©par√© ce diagramme: <br><br><img src="https://habrastorage.org/webt/dl/sc/qa/dlscqatdfii2rihttytjnfvtfea.png"><br>  En g√©n√©ral, on peut affirmer que notre configuration pour IPv6 est l√©g√®rement plus lente.  Mais comme les paquets IPv6 sont un peu plus gros, la diff√©rence de vitesse est attendue. <br><br>  Linux a de nombreuses fa√ßons de filtrer les packages, chacun avec sa propre vitesse et complexit√©. <br><br>  Pour se prot√©ger contre les DDoS, il est tout √† fait raisonnable de donner des paquets √† l'application et de les traiter l√†-bas.  Une application bien r√©gl√©e peut donner de bons r√©sultats. <br><br>  Pour les attaques DDoS avec une adresse IP al√©atoire ou usurp√©e, il peut √™tre utile de d√©sactiver conntrack afin d'obtenir une petite augmentation de la vitesse, mais attention: il existe des attaques contre lesquelles conntrack est tr√®s utile. <br><br>  Dans d'autres cas, il est logique d'ajouter le pare-feu Linux comme l'un des moyens d'att√©nuer l'attaque DDoS.  Dans certains cas, il est pr√©f√©rable d'utiliser la table "-t raw PREROUTING", car elle est beaucoup plus rapide que la table de filtrage. <br><br>  Pour les cas les plus avanc√©s, nous utilisons toujours XDP.  Et oui, c'est une chose tr√®s puissante.  Voici un graphique comme ci-dessus, uniquement avec XDP: <br><br><img src="https://habrastorage.org/webt/o4/un/dm/o4undm-syfgavdxop6izkvpckyk.png"><br>  Si vous souhaitez r√©p√©ter l'exp√©rience, voici le <a href="">fichier README, dans lequel nous avons tout document√©</a> . <br><br>  Chez CloudFlare, nous utilisons ... presque toutes ces techniques.  Quelques astuces dans l'espace utilisateur sont int√©gr√©es dans nos applications.  La technique iptables se trouve dans notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gatebot</a> .  Enfin, nous rempla√ßons notre propre solution principale par XDP. <br><br>  Un grand merci √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Jesper Dangaard Brouer</a> pour leur aide. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr419921/">https://habr.com/ru/post/fr419921/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr419911/index.html">Construire des orbites de corps c√©lestes en utilisant Python</a></li>
<li><a href="../fr419913/index.html">IKEA et la maison intelligente. 2e partie</a></li>
<li><a href="../fr419915/index.html">Liaison et serveur SSH dans initramfs</a></li>
<li><a href="../fr419917/index.html">R√©seaux de neurones: impl√©mentation de la t√¢che sur les champignons sur Tensor Flow et Python</a></li>
<li><a href="../fr419919/index.html">Contr√¥le de version dans SQL Server</a></li>
<li><a href="../fr419923/index.html">Mon travail temporaire, les montres de la carte m√®re</a></li>
<li><a href="../fr419925/index.html">Contr√¥le de version de fichiers individuels √† l'aide de GitHub Gist</a></li>
<li><a href="../fr419927/index.html">[DotNetBook] Exceptions: Type Architecture du syst√®me</a></li>
<li><a href="../fr419929/index.html">[DotNetBook] √âv√©nements d'exception et comment obtenir StackOverflow et ExecutionEngineException √† partir de z√©ro</a></li>
<li><a href="../fr419931/index.html">[DotNetBook] L'heure des histoires divertissantes: des situations exceptionnellement exceptionnelles</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
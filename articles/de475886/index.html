<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏿‍🔧 🗓️ 💒 Mit Amazon AI ist es ganz einfach, von Nutzern obszöne Inhalte zu verarbeiten 🤴🏼 🐒 💣</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Tausende Unternehmen verwenden den Bildverarbeitungsdienst von Amazon Rekognition, um nach obszönen Bildern und Videos zu suchen, die von Benutzern ho...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mit Amazon AI ist es ganz einfach, von Nutzern obszöne Inhalte zu verarbeiten</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/475886/"><h3>  Tausende Unternehmen verwenden den Bildverarbeitungsdienst von Amazon Rekognition, um nach obszönen Bildern und Videos zu suchen, die von Benutzern hochgeladen wurden </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/c90/475/902/c904759027af9a4f8f295d74d62ae25d.jpg"><br><br>  Die umstrittene Rekognition-Technologie von Amazon wird bereits zum Entfernen von Penisbildern von Food-Websites verwendet.  Zumindest ist dies ein Beispiel für seine Verwendung.  Irgendwann hatte der in London ansässige Lebensmittel-Lieferservice Deliveroo Probleme mit der Moderation von Inhalten.  Im Falle eines Lebensmittelproblems senden Deliveroo-Kunden ein Foto des Essens zusammen mit einer Beschwerde.  Und oft machen sie Fotobomben mit ihren Genitalien.  Oder obszöne Bilder von Lebensmitteln machen.  Ja wirklich. <br><br>  Und so stellt sich heraus, dass sich Deliveroo-Mitarbeiter nicht immer mit solchen Inhalten auseinandersetzen wollen.  Aus diesem Grund verwendet das Unternehmen die Funktion "Erkennung", um obszöne Fotos zu erkennen und zu verwischen oder zu entfernen, bevor eine Person sie sieht. <br><a name="habracut"></a><br>  Problem Deliveroo präsentiert eine etwas seltsame Facette eines zunehmend komplexeren Problems.  Auf die eine oder andere Weise verlassen sich viele Online-Unternehmen auf benutzergenerierte Inhalte.  In den letzten Jahren sind wir zunehmend mit dem Eindringen in diesen Inhalt der dunklen Seite der menschlichen Natur konfrontiert.  Die Moderation von Inhalten ist zu einer Priorität geworden, da Websites zunehmend mit unangenehmen Materialien wie falschen Nachrichten, Gewalt, Diphfeiks, Mobbing, aggressiven Rhetoriken und anderen toxischen Inhalten, die von Nutzern erstellt wurden, konfrontiert werden.  Wenn Sie Facebook sind, können Sie zur Lösung dieses Problems Ihre eigene KI entwickeln oder eine Armee von Moderatoren einstellen - oder beides.  Kleinere Unternehmen mit wenigen Ressourcen verfügen jedoch häufig nicht über diese Fähigkeit.  Hier hilft der Content-Moderationsdienst von Amazon. <br><br>  Dieser Service ist Teil des Computer Vision Services-Pakets von Rekognition, das von Amazon Web Services bereitgestellt wird.  In der Presse wurde er häufig dafür <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kritisiert</a> , dass das Unternehmen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bereit war</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesichtserkennungsdienste</a> für den US-Migrationsdienst bereitzustellen.  Auf der Rekognition-Website finden Sie weitere Beispiele für die Verwendung des Dienstes zur Verfolgung, z. B. die Möglichkeit, Autonummern aus verschiedenen Blickwinkeln in einem Video zu erkennen oder den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pfad einer</a> Person mithilfe von Kameraaufzeichnungen zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verfolgen</a> . <br><br>  Auf der Suche nach einem positiveren Image des Computer-Vision-Dienstes sprach Amazon zunächst darüber, mithilfe von Rekognition Benutzerinhalte zu überwachen, um Gewalt und Unanständigkeit zu beseitigen.  Mit diesem Dienst können Sie unsichere oder unangenehme Inhalte auf Bildern und Videos erkennen, die auf die Website hochgeladen wurden. <br><br>  Und dieses Geschäft wächst.  „Die Rolle von nutzergenerierten Inhalten wächst von Jahr zu Jahr explosionsartig - heute teilen wir bereits 2-3 Bilder täglich in sozialen Netzwerken mit unseren Freunden und Verwandten“, sagt Swami Sivasubramanyan, Amazon Vice President, Amazon.  Laut Shivasubramanyan bietet Amazon seit 2017 Content-Moderation-Services auf Kundenwunsch an. <br><br>  Firmen können für Rekognition bezahlen, anstatt Leute einzustellen, um herunterladbare Bilder zu studieren.  Wie bei anderen Diensten mit AWS funktioniert es nach einem Pay-per-Use-Modell und seine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kosten</a> hängen von der Anzahl der vom neuronalen Netzwerk verarbeiteten Bilder ab. <br><br>  Es ist nicht verwunderlich, dass Dating-Services zu den ersten Nutzern von Content Management gehörten - sie müssen Selfies, die in Benutzerprofile hochgeladen wurden, schnell verarbeiten können.  Amazon sagt, dass Dating-Sites Coffee Meets Bagel und Shaadi diesen Service nur für diesen Zweck nutzen - wie die portugiesische Soul-Site, die Menschen hilft, Dating-Sites zu erstellen. <br><br>  AI ist nicht nur auf der Suche nach Nacktheit.  Das neuronale Netz wurde darauf trainiert, jeden zweifelhaften Inhalt zu erkennen, einschließlich Bildern von Waffen oder Gewalt oder allgemein unangenehmen Bildern.  Hier ist das Klassifizierungsmenü von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Erkennungsseite</a> : <br><br>  Explizite Nacktheit: <br><br><ul><li>  nackter Körper; </li><li>  grafische Darstellung eines nackten männlichen Körpers; </li><li>  Grafik eines nackten weiblichen Körpers; </li><li>  sexuelle Aktivität; </li><li>  Demonstration von Nacktheit oder sexueller Aktivität </li><li>  Spielzeug für Erwachsene. </li></ul><br>  Verdächtiger Inhalt: <br><br><ul><li>  Badeanzug oder Unterwäsche für Damen; </li><li>  Badehosen oder Unterwäsche für Herren; </li><li>  teilweise nackter Körper; </li><li>  offene Kleidung. </li></ul><br>  Inhalte, die Gewalt demonstrieren: <br><br><ul><li>  grafische Darstellung von Gewalt oder Blut; </li><li>  körperlicher Missbrauch; </li><li>  Waffengewalt; </li><li>  Waffen; </li><li>  sich selbst verletzen. </li></ul><br>  Störender visueller Inhalt: <br><br><ul><li>  abgemagerte Körper; </li><li>  Leichen; </li><li>  hängen. </li></ul><br><h2>  Wie funktioniert das? </h2><br>  Wie alles in AWS läuft Rekognition in der Cloud.  Das Unternehmen kann dem Service mitteilen, welche Art von Bildern es finden muss.  Anschließend werden die von Benutzern empfangenen Fotos und Videos eingespeist, die in vielen Fällen ohnehin auf AWS-Servern gespeichert werden können. <br><br>  Das neuronale Netzwerk verarbeitet Bilder, sucht nach diesen Inhalten und stellt potenziell unangenehme fest.  Das neuronale Netzwerk erzeugt Metadaten, die den Inhalt der Bilder beschreiben, sowie einen Prozentsatz des Vertrauens in die ausgegebenen Etiketten.  Es sieht ungefähr so ​​aus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/922/d55/5fe/922d555fe35aab61e2f791b6c1056c26.jpg"><br><br>  Diese Daten werden bereits vom clientseitigen Programm verarbeitet, das basierend auf den programmierten Geschäftsregeln entscheidet, was mit dem verarbeiteten Bild geschehen soll.  Es kann es automatisch löschen, überspringen, Teile verwischen oder zur Überprüfung an den Moderator senden. <br><br>  Neuronale Netze für die tiefe Bildverarbeitung haben viele Schichten.  Jeder von ihnen wertet Daten aus, die verschiedene Aspekte der Bilder darstellen, führt Berechnungen durch und sendet das Ergebnis an die nächste Ebene.  Erstens verarbeitet das Netzwerk Informationen auf niedriger Ebene, wie z. B. Grundformen oder die Anwesenheit einer Person in einem Bild. <br><br>  „Dann verfeinert sie die Daten immer weiter, die nächsten Schichten werden spezifischer und so weiter“, erklärt Shivasubramanyan.  Schicht für Schicht bestimmt das neuronale Netz mit immer größerer Sicherheit den Inhalt von Bildern. <br><br>  Laut AWS-Vizepräsident von AI Matt Wood trainiert sein Team Computer Vision-Modelle an Millionen von privaten und öffentlich zugänglichen Bildern aus verschiedenen Sets.  Er sagt, dass Amazon keine Bilder von Benutzern für diesen Zweck verwendet. <br><br><h2>  Bild für Bild </h2><br>  Einige der größten Rekognition-Clients verwenden diesen Dienst nicht zum Moderieren von benutzergenerierten Inhalten.  Laut Amazon möchten große Medienunternehmen mit großen digitalen Videobibliotheken die Inhalte der einzelnen Frames anhand dieser Videos kennen.  Das neuronale Netzwerk von Rekognition kann jede Sekunde eines Videos verarbeiten, mithilfe von Metadaten beschreiben und potenziell gefährliche Bilder kennzeichnen. <br><br>  „Eine der Aufgaben des maschinellen Lernens ist es, Videos oder Bilder aufzunehmen und zusätzlichen Kontext bereitzustellen“, sagt Wood.  "Man kann sagen, dass in diesem Video eine Frau mit einem Hund am Ufer eines Sees entlang spaziert oder ein teilweise gekleideter Mann abgebildet ist."  In diesem Modus könne das neuronale Netz gefährliche, toxische oder unanständige Inhalte in Bildern mit hoher Genauigkeit erkennen. <br><br>  Und doch ist dieser Bereich der Computer Vision noch nicht ausgereift.  Wissenschaftler entdecken immer noch neue Wege, um neuronale Netzwerkalgorithmen zu optimieren, damit sie Bilder noch genauer und detaillierter erkennen können.  "Wir haben noch keinen Zustand mit sinkenden Gewinnen erreicht", sagt Wood. <br><br>  Shivasubramanyan erzählte mir, dass das Team, das an der Bildverarbeitung arbeitet, erst letzten Monat die Anzahl der falsch-positiven (wenn das Bild fälschlicherweise als gefährlich eingestuft wurde) um 68% und die Anzahl der falsch-negativen um 36% verringerte.  "Wir haben die Möglichkeit, die Genauigkeit dieser APIs zu verbessern", sagt er. <br><br>  Neben der Genauigkeit fordern Kunden eine detailliertere Klassifizierung der Bilder.  Auf der AWS-Website wird angegeben, dass der Service nur die Hauptkategorie und eine Unterkategorie von unsicheren Bildern bereitstellt.  Daher kann das System beispielsweise ausgeben, dass das Bild Nacktheit als Hauptkategorie und sexuelle Handlungen als Unterkategorie enthält.  Die dritte Unterkategorie kann eine Klassifizierung der Art der sexuellen Aktivität enthalten. <br><br>  "Bisher ist die Maschine anfällig für Fakten und funktioniert im wahrsten Sinne des Wortes. Sie wird Ihnen sagen, dass" dies dort gezeigt wird "", sagte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pietro Perona</a> , Professor für Computer- und neuronale Systeme von Caltech, ein Berater von AWS.  - Aber Wissenschaftler möchten über diesen Rahmen hinausgehen und nicht nur berichten, was dort abgebildet ist, sondern auch, was diese Leute denken.  Infolgedessen möchte sich dieser Bereich in diese Richtung entwickeln - und nicht nur eine Liste der auf dem Bild gezeigten Bereiche herausgeben. “ <br><br>  Und solche subtilen Unterschiede können für die Moderation von Inhalten wichtig sein.  Ob das Bild möglicherweise anstößige Inhalte enthält oder nicht, hängt möglicherweise von den Absichten der dort abgebildeten Personen ab. <br><br>  Sogar die Definitionen von "unsicheren" und "missbräuchlichen" Bildern sind ziemlich verschwommen.  Sie können sich im Laufe der Zeit ändern und hängen von der geografischen Region ab.  Und Kontext ist alles, erklärt Perona.  Bilder von Gewalt sind ein gutes Beispiel. <br><br>  "Gewalt kann in einem Kontext inakzeptabel sein, wie echte Gewalt in Syrien", sagt Perona, "aber in einem anderen akzeptabel, wie einem Fußballspiel oder einer Szene aus einem Tarantino-Film." <br><br>  Wie bei anderen AWS-Diensten verkauft Amazon nicht nur Tools zur Inhaltsmoderation an andere, sondern es ist sein eigener Kunde.  Das Unternehmen teilt mit, dass es diesen Service verwendet, um von Nutzern erstellte Inhalte in Bilder und Videos zu sortieren, die zum Speichern von Bewertungen angehängt werden. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de475886/">https://habr.com/ru/post/de475886/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de475874/index.html">PHP-Sicherheit: Wo und wie werden Passwörter gespeichert? Teil 2</a></li>
<li><a href="../de475876/index.html">Kirill Bondarenko: „OSM ist seit langem in der Breite gewachsen und tut dies auch weiterhin. Jetzt ist die Zeit für Größe und Volumen gekommen.“</a></li>
<li><a href="../de475880/index.html">7 kostenlose Kurse für Microsoft Solution Architects</a></li>
<li><a href="../de475882/index.html">JavaFX Tutorial: Grundlegende Layouts</a></li>
<li><a href="../de475884/index.html">Lösen des Problems von gezackten Linien in Verläufen</a></li>
<li><a href="../de475888/index.html">Vorteile der Wolkengesichtserkennung</a></li>
<li><a href="../de475892/index.html">Wie wir die Bestellung des Mittagessens im Büro verbessert haben (ohne Zugang zum Server)</a></li>
<li><a href="../de475894/index.html">Drei-Pass-Protokolle</a></li>
<li><a href="../de475896/index.html">Voller I / O-Naked-C-Reaktor</a></li>
<li><a href="../de475900/index.html">Die 6 neuesten Azure-Kurse</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
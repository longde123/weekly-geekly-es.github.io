<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏿‍🤝‍👩🏻 👩🏿‍🤝‍👩🏾 🌝 .NET, TensorFlow y los molinos de viento de Kaggle: el viaje comienza 🌳 🔂 👺</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta es una serie de artículos sobre mi viaje en curso en el bosque oscuro de las competencias de Kaggle como desarrollador de .NET. 

 Me centraré en...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>.NET, TensorFlow y los molinos de viento de Kaggle: el viaje comienza</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437174/"><img src="https://habrastorage.org/webt/tc/fj/ml/tcfjml8-rk618mttrw9qhvfan_u.png" align="left">  Esta es una serie de artículos sobre mi viaje en curso en el bosque oscuro de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" title="Kaggle">las</a> competencias de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" title="Kaggle">Kaggle</a> como desarrollador de .NET. <br><br>  Me centraré en redes neuronales (casi) puras en este y en los siguientes artículos.  Significa que la mayoría de las partes aburridas de la preparación del conjunto de datos, como completar valores perdidos, selección de características, análisis de valores atípicos, etc.  será omitido intencionalmente. <br><br>  La pila tecnológica será C # + TensorFlow <i>tf.keras</i> API.  A partir de hoy también requerirá Windows.  Los modelos más grandes en los próximos artículos pueden necesitar una GPU adecuada para que su tiempo de entrenamiento permanezca cuerdo. <br><a name="habracut"></a><br><h2>  ¡Vamos a predecir los precios inmobiliarios! </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Los precios de la vivienda</a> son una gran competencia para los principiantes.  Su conjunto de datos es pequeño, no hay reglas especiales, la tabla de clasificación pública tiene muchos participantes y puede enviar hasta 4 entradas por día. <br><br>  Regístrese en Kaggle, si aún no lo ha hecho, únase a esta competencia y descargue los datos.  El objetivo es predecir el precio de venta (columna SalePrice) para las entradas en <i>test.csv</i> .  El archivo contiene <i>train.csv</i> , que tiene alrededor de 1500 entradas con un precio de venta conocido para entrenar.  Comenzaremos cargando ese conjunto de datos y explorándolo un poco antes de entrar en las redes neuronales. <br><br><h2>  Analizar datos de entrenamiento </h2><br>  <i>¿Dije que omitiremos la preparación del conjunto de datos?</i>  <i>Mentí!</i>  <i>Tienes que echar un vistazo al menos una vez.</i> <br><br>  Para mi sorpresa, no encontré una manera fácil de cargar un archivo .csv en la biblioteca de clases estándar .NET, así que instalé un paquete NuGet, llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CsvHelper</a> .  Para simplificar la manipulación de datos, también obtuve mi nuevo paquete de extensión LINQ favorito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MoreLinq</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Carga de datos .csv en DataTable</b> <div class="spoiler_text"><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> DataTable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">LoadData</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> csvFilePath</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> result = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DataTable(); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> reader = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvDataReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamReader(csvFilePath)))) { result.Load(reader); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; }</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">ML.NET</b> <div class="spoiler_text">  Usar <i>DataTable</i> para la manipulación de datos de entrenamiento es, de hecho, una mala idea. <br><br>  Se supone que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ML.NET</a> tiene la carga .csv y muchas de las operaciones de exploración y peparación de datos.  Sin embargo, todavía no estaba listo para ese propósito en particular, cuando recién ingresé a la competencia de Precios de la vivienda. <br></div></div><br><br>  Los datos se ven así (solo unas pocas filas y columnas): <br><br><table><tbody><tr><td>  Id </td><td>  MSSubClass </td><td>  Msoning </td><td>  LotFrontage </td><td>  Lotarea </td></tr><tr><td>  1 </td><td>  60 60 </td><td>  RL </td><td>  65 </td><td>  8450 </td></tr><tr><td>  2 </td><td>  20 </td><td>  RL </td><td>  80 </td><td>  9600 </td></tr><tr><td>  3 </td><td>  60 60 </td><td>  RL </td><td>  68 </td><td>  11250 </td></tr><tr><td>  4 4 </td><td>  70 </td><td>  RL </td><td>  60 60 </td><td>  9550 </td></tr></tbody></table><br><br>  Después de cargar los datos, debemos eliminar la columna <i>Id</i> , ya que en realidad no está relacionada con los precios de la vivienda: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> trainData = LoadData(<span class="hljs-string"><span class="hljs-string">"train.csv"</span></span>); trainData.Columns.Remove(<span class="hljs-string"><span class="hljs-string">"Id"</span></span>);</code> </pre> <br><h3>  Analizando los tipos de datos de columna </h3><br>  DataTable no deduce automáticamente los tipos de datos de las columnas y supone que todas son cadenas.  Entonces, el siguiente paso es determinar lo que realmente tenemos.  Para cada columna, calculé las siguientes estadísticas: número de valores distintos, cuántos de ellos son enteros y cuántos de ellos son números de coma flotante (un código fuente con todos los métodos auxiliares se vinculará al final del artículo): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> values = rows.Select(row =&gt; (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column]); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> ints = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> distincts = values.Distinct().Count();</code> </pre> <br><h3>  Columnas numéricas </h3><br>  Resulta que la mayoría de las columnas son en realidad ints, pero dado que las redes neuronales funcionan principalmente en números flotantes, las convertiremos a dobles de todos modos. <br><br><h3>  Columnas categóricas </h3><br>  Otras columnas describen categorías a las que pertenecía la propiedad en venta.  Ninguno de ellos tiene demasiados valores diferentes, lo cual es bueno.  Para usarlos como entrada para nuestra futura red neuronal, también deben convertirse al <i>doble</i> . <br><br>  Inicialmente, simplemente les asigné números de 0 a distinctValueCount - 1, pero eso no tiene mucho sentido, ya que en realidad no hay progresión de "Fachada: Azul" a "Fachada: Verde" a "Fachada: Blanco".  Tan temprano que cambié eso a lo que se llama una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">codificación de</a> un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">solo punto</a> , donde cada valor único obtiene una columna de entrada separada.  Por ejemplo, "Fachada: Azul" se convierte en [1,0,0], y "Fachada: Blanco" se convierte en [0,0,1]. <br><br><h3>  Reuniéndolos a todos </h3><br><div class="spoiler">  <b class="spoiler_title">Gran producción de exploración de datos.</b> <div class="spoiler_text">  CentralAir: 2 valores, ints: 0.00%, flotantes: 0.00% <br>  Calle: 2 valores, entradas: 0.00%, carrozas: 0.00% <br>  Utilidades: 2 valores, ints: 0.00%, flotantes: 0.00% <br>  Callejón: 3 valores, entradas: 0.00%, carrozas: 0.00% <br>  BsmtHalfBath: 3 valores, ints: 100.00%, flotantes: 100.00% <br>  HalfBath: 3 valores, ints: 100.00%, flotantes: 100.00% <br>  LandSlope: 3 valores, ints: 0.00%, flota: 0.00% <br>  PavedDrive: 3 valores, ints: 0.00%, flotantes: 0.00% <br>  BsmtFullBath: 4 valores, ints: 100.00%, flotantes: 100.00% <br>  ExterQual: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  Chimeneas: 4 valores, entradas: 100.00%, flotadores: 100.00% <br>  Baño completo: 4 valores, entradas: 100.00%, flotantes: 100.00% <br>  GarageFinish: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  KitchenAbvGr: 4 valores, ints: 100.00%, flotadores: 100.00% <br>  KitchenQual: 4 valores, ints: 0.00%, flota: 0.00% <br>  LandContour: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  LotShape: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  PoolQC: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  BldgType: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  BsmtCond: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  Bsmt Exposición: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  BsmtQual: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  ExterCond: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  Valla: 5 valores, entradas: 0.00%, flotadores: 0.00% <br>  GarageCars: 5 valores, ints: 100.00%, flotadores: 100.00% <br>  Calefacción QC: 5 valores, ints: 0.00%, flotadores: 0.00% <br>  LotConfig: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  MasVnrType: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  MiscFeature: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  MS Zoning: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  Año de venta: 5 valores, entradas: 100.00%, flotantes: 100.00% <br>  Eléctrico: 6 valores, ints: 0.00%, flotadores: 0.00% <br>  FireplaceQu: 6 valores, ints: 0.00%, flota: 0.00% <br>  Fundación: 6 valores, ints: 0.00%, flotadores: 0.00% <br>  GarageCond: 6 valores, ints: 0.00%, flotantes: 0.00% <br>  GarageQual: 6 valores, ints: 0.00%, flotantes: 0.00% <br>  Calefacción: 6 valores, ints: 0.00%, flotadores: 0.00% <br>  RoofStyle: 6 valores, ints: 0.00%, flotantes: 0.00% <br>  Condición de venta: 6 valores, ints: 0.00%, flotadores: 0.00% <br>  BsmtFinType1: 7 valores, ints: 0.00%, flotantes: 0.00% <br>  BsmtFinType2: 7 valores, ints: 0.00%, flotantes: 0.00% <br>  Funcional: 7 valores, ints: 0.00%, flotantes: 0.00% <br>  GarageType: 7 valores, ints: 0.00%, flotantes: 0.00% <br>  BedroomAbvGr: 8 valores, ints: 100.00%, flotantes: 100.00% <br>  Condición2: 8 valores, ints: 0.00%, flotantes: 0.00% <br>  HouseStyle: 8 valores, ints: 0.00%, flotantes: 0.00% <br>  PoolArea: 8 valores, ints: 100.00%, flotantes: 100.00% <br>  RoofMatl: 8 valores, ints: 0.00%, flotantes: 0.00% <br>  Condición1: 9 valores, ints: 0.00%, flotantes: 0.00% <br>  OverallCond: 9 valores, ints: 100.00%, flota: 100.00% <br>  SaleType: 9 valores, ints: 0.00%, floats: 0.00% <br>  OverallQual: 10 valores, ints: 100.00%, flota: 100.00% <br>  MoSold: 12 valores, entradas: 100.00%, flotantes: 100.00% <br>  TotRmsAbvGrd: 12 valores, ints: 100.00%, flotantes: 100.00% <br>  Exterior1: 15 valores, ints: 0.00%, flotantes: 0.00% <br>  MSSubClass: 15 valores, ints: 100.00%, flotantes: 100.00% <br>  Exterior 2: 16 valores, ints: 0.00%, flotantes: 0.00% <br>  3SsnPorch: 20 valores, ints: 100.00%, flotantes: 100.00% <br>  MiscVal: 21 valores, ints: 100.00%, flotantes: 100.00% <br>  LowQualFinSF: 24 valores, ints: 100.00%, flotantes: 100.00% <br>  Barrio: 25 valores, entradas: 0.00%, flotadores: 0.00% <br>  YearRemodAdd: 61 valores, ints: 100.00%, flotantes: 100.00% <br>  ScreenPorch: 76 valores, ints: 100.00%, flota: 100.00% <br>  GarageYrBlt: 98 valores, ints: 94.45%, flotadores: 94.45% <br>  LotFrontage: 111 valores, ints: 82.26%, flotantes: 82.26% <br>  Año Construido: 112 valores, entradas: 100.00%, flotantes: 100.00% <br>  Porche cerrado: 120 valores, entradas: 100.00%, flotadores: 100.00% <br>  BsmtFinSF2: 144 valores, ints: 100.00%, flotantes: 100.00% <br>  OpenPorchSF: 202 valores, ints: 100.00%, flotantes: 100.00% <br>  WoodDeckSF: 274 valores, entradas: 100.00%, flotadores: 100.00% <br>  MasVnrArea: 328 valores, ints: 99.45%, flotantes: 99.45% <br>  2ndFlrSF: 417 valores, entradas: 100.00%, flotantes: 100.00% <br>  Área de garaje: 441 valores, entradas: 100.00%, flotadores: 100.00% <br>  BsmtFinSF1: 637 valores, ints: 100.00%, flotantes: 100.00% <br>  Precio de venta: 663 valores, entradas: 100.00%, flotadores: 100.00% <br>  TotalBsmtSF: 721 valores, ints: 100.00%, flotantes: 100.00% <br>  1stFlrSF: 753 valores, entradas: 100.00%, flotantes: 100.00% <br>  BsmtUnfSF: 780 valores, ints: 100.00%, flotantes: 100.00% <br>  GrLivArea: 861 valores, entradas: 100.00%, flotantes: 100.00% <br>  LotArea: 1073 valores, ints: 100.00%, flotantes: 100.00% <br><br>  Muchas columnas de valor: <br>  Exterior1st: AsbShng, AsphShn, BrkComm, BrkFace, CBlock, CemntBd, HdBoard, ImStucc, MetalSd, Plywood, Stone, Stucco, VinylSd, Wd Sdng, WdShing <br>  Exterior2nd: AsbShng, AsphShn, Brk Cmn, BrkFace, CBlock, CmentBd, HdBoard, ImStucc, MetalSd, Other, Plywood, Stone, Stucco, VinylSd, Wd Sdng, Wd Shng <br>  Vecindad: Blmngtn, Blueste, BrDale, BrkSide, ClearCr, CollgCr, Crawfor, Edwards, Gilbert, IDOTRR, MeadowV, Mitchel, NAmes, NoRidge, NPkVill, NridgHt, NWAmes, OldTown, Sawyer, SawyerW, Somerst, Stone, Stoner Veenker <br><br>  flotadores no analizables <br>  GarageYrBlt: NA <br>  LotFrontage: NA <br>  MasVnrArea: NA <br><br>  rangos de flotación: <br>  BsmtHalfBath: 0 ... 2 <br>  Medio baño: 0 ... 2 <br>  BsmtFullBath: 0 ... 3 <br>  Chimeneas: 0 ... 3 <br>  Baño completo: 0 ... 3 <br>  KitchenAbvGr: 0 ... 3 <br>  GarageCars: 0 ... 4 <br>  Año de venta: 2006 ... 2010 <br>  DormitorioAbvGr: 0 ... 8 <br>  Área de piscina: 0 ... 738 <br>  OverallCond: 1 ... 9 <br>  General Qualual: 1 ... 10 <br>  MoSold: 1 ... 12 <br>  TotRmsAbvGrd: 2 ... 14 <br>  MSSubClass: 20 ... 190 <br>  3SsnPorche: 0 ... 508 <br>  Miscelánea: 0 ... 15500 <br>  LowQualFinSF: 0 ... 572 <br>  Año Modificado Agregar: 1950 ... 2010 <br>  ScreenPorch: 0 ... 480 <br>  GarageYrBlt: 1900 ... 2010 <br>  LotFrontage: 21 ... 313 <br>  Año de construcción: 1872 ... 2010 <br>  Porche cerrado: 0 ... 552 <br>  BsmtFinSF2: 0 ... 1474 <br>  OpenPorchSF: 0 ... 547 <br>  WoodDeckSF: 0 ... 857 <br>  MasVnrArea: 0 ... 1600 <br>  2ndFlrSF: 0 ... 2065 <br>  Área de garaje: 0 ... 1418 <br>  BsmtFinSF1: 0 ... 5644 <br>  Precio de venta: 34,900 ... 755,000 <br>  TotalBsmtSF: 0 ... 6110 <br>  1stFlrSF: 334 ... 4692 <br>  BsmtUnfSF: 0 ... 2336 <br>  GrLivArea: 334 ... 5642 <br>  LotArea: 1300 ... 215245 <br></div></div><br><br>  Con eso en mente, construí el siguiente <i>ValueNormalizer</i> , que toma información sobre los valores dentro de la columna y devuelve una función, que transforma un valor (una <i>cadena</i> ) en un vector de características numéricas para la red neuronal ( <i>doble []</i> ): <br><br><div class="spoiler">  <b class="spoiler_title">ValueNormalizer</b> <div class="spoiler_text"><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Func&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[]&gt; ValueNormalizer( <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats, IEnumerable&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>&gt; values) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (floats &gt; <span class="hljs-number"><span class="hljs-number">0.01</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> max = values.AsDouble().Max().Value; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span>[] { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(s, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) ? v / max : <span class="hljs-number"><span class="hljs-number">-1</span></span> }; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>[] domain = values.Distinct().OrderBy(v =&gt; v).ToArray(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[domain.Length+<span class="hljs-number"><span class="hljs-number">1</span></span>] .Set(Array.IndexOf(domain, s)+<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); } }</code> </pre> <br></div></div><br>  Ahora tenemos los datos convertidos a un formato, adecuado para una red neuronal.  Es hora de construir uno. <br><br><h2>  Construye una red neuronal </h2><br>  <i>A partir de hoy, necesitaría usar una máquina Windows para eso.</i> <br><br>  Si ya tiene Python y TensorFlow 1.1x instalados, todo lo que necesita es <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">PackageReference</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Include</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"Gradient"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Version</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"0.1.10-tech-preview3"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre> <br>  en tu archivo .csproj moderno.  De lo contrario, consulte el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">manual Gradient</a> para hacer la configuración inicial. <br><br>  Una vez que el paquete está en funcionamiento, podemos crear nuestra primera red profunda poco profunda. <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras.layers; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.train; ... <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> model = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Sequential(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Layer[] { <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">16</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dropout(rate: <span class="hljs-number"><span class="hljs-number">0.1</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">10</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">1</span></span>, activation: tf.nn.relu_fn), }); model.compile(optimizer: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AdamOptimizer(), loss: <span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>);</code> </pre> <br>  Esto creará una red neuronal no entrenada con 3 capas de neuronas y una capa de abandono, que ayuda a prevenir el sobreajuste. <br><br><div class="spoiler">  <b class="spoiler_title">tf.nn.relu_fn</b> <div class="spoiler_text">  <i>tf.nn.relu_fn</i> es la función de activación de nuestras neuronas.  Se sabe que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ReLU</a> funciona bien en redes profundas, porque resuelve el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">problema del gradiente de fuga</a> : las derivadas de las funciones de activación no lineales originales tienden a ser muy pequeñas cuando el error se propaga desde la capa de salida en las redes profundas.  Eso significaba que las capas más cercanas a la entrada solo se ajustarían muy ligeramente, lo que ralentizó significativamente el entrenamiento de redes profundas. <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Abandono</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La deserción</a> es una capa de función especial en las redes neuronales, que en realidad no contiene neuronas como tales.  En cambio, funciona tomando cada entrada individual y la reemplaza aleatoriamente con 0 en la salida automática (de lo contrario, solo pasa el valor original).  Al hacerlo, ayuda a evitar el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sobreajuste</a> a características menos relevantes en un pequeño conjunto de datos.  Por ejemplo, si no eliminamos la columna <i>Id</i> , la red podría haber memorizado exactamente el mapeo &lt;Id&gt; -&gt; &lt;SalePrice&gt; exactamente, lo que nos daría una precisión del 100% en el conjunto de entrenamiento, pero números completamente no relacionados en cualquier otro dato. <br><br>  ¿Por qué necesitamos abandonar?  Nuestros datos de entrenamiento solo tienen ~ 1500 ejemplos, y esta pequeña red neuronal que hemos construido tiene&gt; 1800 pesos ajustables.  Si fuera un polinomio simple, podría coincidir con la función de precio que estamos tratando de aproximar exactamente.  Pero entonces tendría valores enormes en cualquier entrada fuera del conjunto de entrenamiento original. <br></div></div><br><h2>  Alimentar los datos </h2><br>  TensorFlow espera sus datos en matrices NumPy o tensores existentes.  Estoy convirtiendo DataRows en matrices NumPy: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> numpy; ... <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> predict = <span class="hljs-string"><span class="hljs-string">"SalePrice"</span></span>; <span class="hljs-function"><span class="hljs-function">ndarray </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetInputs</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">IEnumerable&lt;DataRow&gt; rowSeq</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(rowSeq.Select(row =&gt; np.array( columnTypes .Where(c =&gt; c.column.ColumnName != predict) .SelectMany(column =&gt; column.normalizer( row.Table.Columns.Contains(column.column.ColumnName) ? (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column.column.ColumnName] : <span class="hljs-string"><span class="hljs-string">"-1"</span></span>)) .ToArray())) .ToArray() ); } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> predictColumn = columnTypes.Single(c =&gt; c.column.ColumnName == predict); ndarray trainOutputs = np.array(predictColumn.trainValues .AsDouble() .Select(v =&gt; v ?? <span class="hljs-number"><span class="hljs-number">-1</span></span>) .ToArray()); ndarray trainInputs = GetInputs(trainRows);</code> </pre> <br>  En el código anterior, convertimos cada <i>DataRow</i> en un <i>ndarray</i> al tomar cada celda y aplicar el <i>ValueNormalizer</i> correspondiente a su columna.  Luego colocamos todas las filas en otro <i>ndarray</i> , obteniendo una matriz de matrices. <br><br>  No se necesita tal transformación para las salidas, donde simplemente convertimos los valores del tren a otro <i>ndarray</i> . <br><br><h2>  Es hora de bajar el gradiente </h2><br>  Con esta configuración, todo lo que necesitamos hacer para entrenar nuestra red es llamar a la función de <i>ajuste</i> del modelo: <br><br><pre> <code class="cs hljs">model.fit(trainInputs, trainOutputs, epochs: <span class="hljs-number"><span class="hljs-number">2000</span></span>, validation_split: <span class="hljs-number"><span class="hljs-number">0.075</span></span>, verbose: <span class="hljs-number"><span class="hljs-number">2</span></span>);</code> </pre> <br>  Esta llamada realmente reservará el último 7.5% del conjunto de entrenamiento para la validación, luego repita las siguientes 2000 veces: <br><br><ol><li>  dividir el resto de <i>entradas</i> de <i>tren</i> en lotes </li><li>  alimentar estos lotes uno por uno en la red neuronal </li><li>  calcular error usando la función de pérdida que definimos anteriormente </li><li>  propaga el error por los gradientes de las conexiones neuronales individuales, ajustando los pesos </li></ol><br>  Durante el entrenamiento, generará el error de la red en los datos que dejó de lado para la validación como <b>val_loss</b> y el error en los datos de entrenamiento en sí mismo como una <b>pérdida</b> .  En general, si <b>val_loss se</b> vuelve mucho mayor que la <b>pérdida</b> , significa que la red comenzó a sobreajustarse.  Abordaré eso con más detalle en los siguientes artículos. <br><br>  Si hiciste todo correctamente, una <u>raíz cuadrada</u> de una de tus pérdidas debería ser del orden de 20000. <br><br><img src="https://habrastorage.org/webt/fu/rn/vg/furnvg6dbs8ocijm91_3xcqdxhm.png"><br><br><h2>  Sumisión </h2><br>  No hablaré mucho sobre generar el archivo para enviar aquí.  El código para calcular las salidas es simple: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> SubmissionInputFile = <span class="hljs-string"><span class="hljs-string">"test.csv"</span></span>; DataTable submissionData = LoadData(SubmissionInputFile); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> submissionRows = submissionData.Rows.Cast&lt;DataRow&gt;(); ndarray submissionInputs = GetInputs(submissionRows); ndarray sumissionOutputs = model.predict(submissionInputs);</code> </pre> <br>  que utiliza principalmente funciones, que se definieron anteriormente. <br><br>  Luego, debe escribirlos en un archivo .csv, que es simplemente una lista de Id, pares de valores pronosticados. <br><br>  Cuando envíe su resultado, debería obtener una puntuación del orden de 0.17, que estaría en algún lugar en el último trimestre de la tabla de clasificación pública.  Pero bueno, si fuera tan simple como una red de 3 capas con 27 neuronas, esos molestos científicos de datos no obtendrían compensaciones totales de $ 300k + / a de las principales compañías estadounidenses <br><br><h2>  Terminando </h2><br>  El código fuente completo para esta entrada (con todos los ayudantes, y algunas de las partes comentadas de mis anteriores exploraciones y experimentos) es de aproximadamente 200 líneas en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PasteBin</a> . <br><br>  En el próximo artículo, verás a mis travesuras tratando de llegar al 50% superior de esa tabla de clasificación pública.  Va a ser la aventura de un viajero aficionado, una pelea con The Windmill of Overfitting con la única herramienta que tiene el peregrino: un modelo más grande (por ejemplo, ¡NN profundo, recuerda, sin ingeniería manual de características!).  Será menos un tutorial de codificación, y más una búsqueda de pensamiento con matemáticas realmente maliciosas y una conclusión extraña.  Estén atentos! <br><br><h2>  Enlaces </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Concurso de precios de la vivienda en Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tutorial de regresión de TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Página de inicio de TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Referencia de la API de TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gradiente (enlace TensorFlow)</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/437174/">https://habr.com/ru/post/437174/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../437160/index.html">Devops</a></li>
<li><a href="../437164/index.html"># 10yearschallenge para programadores</a></li>
<li><a href="../437166/index.html">Vuelo de combate en Meteor-e</a></li>
<li><a href="../437170/index.html">Facebook sugiere usar láseres espaciales para comunicaciones globales</a></li>
<li><a href="../437172/index.html">IBM MQ y JMeter: primer contacto</a></li>
<li><a href="../437176/index.html">Aplicación para iOS y Android en Kotlin + Flutter UI</a></li>
<li><a href="../437180/index.html">JVM siberiano duro: gran entrevista sobre Excelsior JET</a></li>
<li><a href="../437182/index.html">Interceptación de llamadas del sistema en el módulo del kernel de Linux</a></li>
<li><a href="../437184/index.html">Nikolay Durov 90% completó el desarrollo de la plataforma Telegram Open Network</a></li>
<li><a href="../437186/index.html">Monolito a microservicios. Punto de vista de infraestructura</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
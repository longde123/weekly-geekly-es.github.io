<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äçü§ù‚Äçüë©üèª üë©üèø‚Äçü§ù‚Äçüë©üèæ üåù .NET, TensorFlow y los molinos de viento de Kaggle: el viaje comienza üå≥ üîÇ üë∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta es una serie de art√≠culos sobre mi viaje en curso en el bosque oscuro de las competencias de Kaggle como desarrollador de .NET. 

 Me centrar√© en...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>.NET, TensorFlow y los molinos de viento de Kaggle: el viaje comienza</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437174/"><img src="https://habrastorage.org/webt/tc/fj/ml/tcfjml8-rk618mttrw9qhvfan_u.png" align="left">  Esta es una serie de art√≠culos sobre mi viaje en curso en el bosque oscuro de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" title="Kaggle">las</a> competencias de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" title="Kaggle">Kaggle</a> como desarrollador de .NET. <br><br>  Me centrar√© en redes neuronales (casi) puras en este y en los siguientes art√≠culos.  Significa que la mayor√≠a de las partes aburridas de la preparaci√≥n del conjunto de datos, como completar valores perdidos, selecci√≥n de caracter√≠sticas, an√°lisis de valores at√≠picos, etc.  ser√° omitido intencionalmente. <br><br>  La pila tecnol√≥gica ser√° C # + TensorFlow <i>tf.keras</i> API.  A partir de hoy tambi√©n requerir√° Windows.  Los modelos m√°s grandes en los pr√≥ximos art√≠culos pueden necesitar una GPU adecuada para que su tiempo de entrenamiento permanezca cuerdo. <br><a name="habracut"></a><br><h2>  ¬°Vamos a predecir los precios inmobiliarios! </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Los precios de la vivienda</a> son una gran competencia para los principiantes.  Su conjunto de datos es peque√±o, no hay reglas especiales, la tabla de clasificaci√≥n p√∫blica tiene muchos participantes y puede enviar hasta 4 entradas por d√≠a. <br><br>  Reg√≠strese en Kaggle, si a√∫n no lo ha hecho, √∫nase a esta competencia y descargue los datos.  El objetivo es predecir el precio de venta (columna SalePrice) para las entradas en <i>test.csv</i> .  El archivo contiene <i>train.csv</i> , que tiene alrededor de 1500 entradas con un precio de venta conocido para entrenar.  Comenzaremos cargando ese conjunto de datos y explor√°ndolo un poco antes de entrar en las redes neuronales. <br><br><h2>  Analizar datos de entrenamiento </h2><br>  <i>¬øDije que omitiremos la preparaci√≥n del conjunto de datos?</i>  <i>Ment√≠!</i>  <i>Tienes que echar un vistazo al menos una vez.</i> <br><br>  Para mi sorpresa, no encontr√© una manera f√°cil de cargar un archivo .csv en la biblioteca de clases est√°ndar .NET, as√≠ que instal√© un paquete NuGet, llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CsvHelper</a> .  Para simplificar la manipulaci√≥n de datos, tambi√©n obtuve mi nuevo paquete de extensi√≥n LINQ favorito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MoreLinq</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Carga de datos .csv en DataTable</b> <div class="spoiler_text"><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> DataTable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">LoadData</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> csvFilePath</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> result = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DataTable(); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> reader = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvDataReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamReader(csvFilePath)))) { result.Load(reader); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; }</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">ML.NET</b> <div class="spoiler_text">  Usar <i>DataTable</i> para la manipulaci√≥n de datos de entrenamiento es, de hecho, una mala idea. <br><br>  Se supone que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ML.NET</a> tiene la carga .csv y muchas de las operaciones de exploraci√≥n y peparaci√≥n de datos.  Sin embargo, todav√≠a no estaba listo para ese prop√≥sito en particular, cuando reci√©n ingres√© a la competencia de Precios de la vivienda. <br></div></div><br><br>  Los datos se ven as√≠ (solo unas pocas filas y columnas): <br><br><table><tbody><tr><td>  Id </td><td>  MSSubClass </td><td>  Msoning </td><td>  LotFrontage </td><td>  Lotarea </td></tr><tr><td>  1 </td><td>  60 60 </td><td>  RL </td><td>  65 </td><td>  8450 </td></tr><tr><td>  2 </td><td>  20 </td><td>  RL </td><td>  80 </td><td>  9600 </td></tr><tr><td>  3 </td><td>  60 60 </td><td>  RL </td><td>  68 </td><td>  11250 </td></tr><tr><td>  4 4 </td><td>  70 </td><td>  RL </td><td>  60 60 </td><td>  9550 </td></tr></tbody></table><br><br>  Despu√©s de cargar los datos, debemos eliminar la columna <i>Id</i> , ya que en realidad no est√° relacionada con los precios de la vivienda: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> trainData = LoadData(<span class="hljs-string"><span class="hljs-string">"train.csv"</span></span>); trainData.Columns.Remove(<span class="hljs-string"><span class="hljs-string">"Id"</span></span>);</code> </pre> <br><h3>  Analizando los tipos de datos de columna </h3><br>  DataTable no deduce autom√°ticamente los tipos de datos de las columnas y supone que todas son cadenas.  Entonces, el siguiente paso es determinar lo que realmente tenemos.  Para cada columna, calcul√© las siguientes estad√≠sticas: n√∫mero de valores distintos, cu√°ntos de ellos son enteros y cu√°ntos de ellos son n√∫meros de coma flotante (un c√≥digo fuente con todos los m√©todos auxiliares se vincular√° al final del art√≠culo): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> values = rows.Select(row =&gt; (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column]); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> ints = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> distincts = values.Distinct().Count();</code> </pre> <br><h3>  Columnas num√©ricas </h3><br>  Resulta que la mayor√≠a de las columnas son en realidad ints, pero dado que las redes neuronales funcionan principalmente en n√∫meros flotantes, las convertiremos a dobles de todos modos. <br><br><h3>  Columnas categ√≥ricas </h3><br>  Otras columnas describen categor√≠as a las que pertenec√≠a la propiedad en venta.  Ninguno de ellos tiene demasiados valores diferentes, lo cual es bueno.  Para usarlos como entrada para nuestra futura red neuronal, tambi√©n deben convertirse al <i>doble</i> . <br><br>  Inicialmente, simplemente les asign√© n√∫meros de 0 a distinctValueCount - 1, pero eso no tiene mucho sentido, ya que en realidad no hay progresi√≥n de "Fachada: Azul" a "Fachada: Verde" a "Fachada: Blanco".  Tan temprano que cambi√© eso a lo que se llama una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">codificaci√≥n de</a> un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">solo punto</a> , donde cada valor √∫nico obtiene una columna de entrada separada.  Por ejemplo, "Fachada: Azul" se convierte en [1,0,0], y "Fachada: Blanco" se convierte en [0,0,1]. <br><br><h3>  Reuni√©ndolos a todos </h3><br><div class="spoiler">  <b class="spoiler_title">Gran producci√≥n de exploraci√≥n de datos.</b> <div class="spoiler_text">  CentralAir: 2 valores, ints: 0.00%, flotantes: 0.00% <br>  Calle: 2 valores, entradas: 0.00%, carrozas: 0.00% <br>  Utilidades: 2 valores, ints: 0.00%, flotantes: 0.00% <br>  Callej√≥n: 3 valores, entradas: 0.00%, carrozas: 0.00% <br>  BsmtHalfBath: 3 valores, ints: 100.00%, flotantes: 100.00% <br>  HalfBath: 3 valores, ints: 100.00%, flotantes: 100.00% <br>  LandSlope: 3 valores, ints: 0.00%, flota: 0.00% <br>  PavedDrive: 3 valores, ints: 0.00%, flotantes: 0.00% <br>  BsmtFullBath: 4 valores, ints: 100.00%, flotantes: 100.00% <br>  ExterQual: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  Chimeneas: 4 valores, entradas: 100.00%, flotadores: 100.00% <br>  Ba√±o completo: 4 valores, entradas: 100.00%, flotantes: 100.00% <br>  GarageFinish: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  KitchenAbvGr: 4 valores, ints: 100.00%, flotadores: 100.00% <br>  KitchenQual: 4 valores, ints: 0.00%, flota: 0.00% <br>  LandContour: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  LotShape: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  PoolQC: 4 valores, ints: 0.00%, flotantes: 0.00% <br>  BldgType: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  BsmtCond: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  Bsmt Exposici√≥n: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  BsmtQual: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  ExterCond: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  Valla: 5 valores, entradas: 0.00%, flotadores: 0.00% <br>  GarageCars: 5 valores, ints: 100.00%, flotadores: 100.00% <br>  Calefacci√≥n QC: 5 valores, ints: 0.00%, flotadores: 0.00% <br>  LotConfig: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  MasVnrType: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  MiscFeature: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  MS Zoning: 5 valores, ints: 0.00%, flotantes: 0.00% <br>  A√±o de venta: 5 valores, entradas: 100.00%, flotantes: 100.00% <br>  El√©ctrico: 6 valores, ints: 0.00%, flotadores: 0.00% <br>  FireplaceQu: 6 valores, ints: 0.00%, flota: 0.00% <br>  Fundaci√≥n: 6 valores, ints: 0.00%, flotadores: 0.00% <br>  GarageCond: 6 valores, ints: 0.00%, flotantes: 0.00% <br>  GarageQual: 6 valores, ints: 0.00%, flotantes: 0.00% <br>  Calefacci√≥n: 6 valores, ints: 0.00%, flotadores: 0.00% <br>  RoofStyle: 6 valores, ints: 0.00%, flotantes: 0.00% <br>  Condici√≥n de venta: 6 valores, ints: 0.00%, flotadores: 0.00% <br>  BsmtFinType1: 7 valores, ints: 0.00%, flotantes: 0.00% <br>  BsmtFinType2: 7 valores, ints: 0.00%, flotantes: 0.00% <br>  Funcional: 7 valores, ints: 0.00%, flotantes: 0.00% <br>  GarageType: 7 valores, ints: 0.00%, flotantes: 0.00% <br>  BedroomAbvGr: 8 valores, ints: 100.00%, flotantes: 100.00% <br>  Condici√≥n2: 8 valores, ints: 0.00%, flotantes: 0.00% <br>  HouseStyle: 8 valores, ints: 0.00%, flotantes: 0.00% <br>  PoolArea: 8 valores, ints: 100.00%, flotantes: 100.00% <br>  RoofMatl: 8 valores, ints: 0.00%, flotantes: 0.00% <br>  Condici√≥n1: 9 valores, ints: 0.00%, flotantes: 0.00% <br>  OverallCond: 9 valores, ints: 100.00%, flota: 100.00% <br>  SaleType: 9 valores, ints: 0.00%, floats: 0.00% <br>  OverallQual: 10 valores, ints: 100.00%, flota: 100.00% <br>  MoSold: 12 valores, entradas: 100.00%, flotantes: 100.00% <br>  TotRmsAbvGrd: 12 valores, ints: 100.00%, flotantes: 100.00% <br>  Exterior1: 15 valores, ints: 0.00%, flotantes: 0.00% <br>  MSSubClass: 15 valores, ints: 100.00%, flotantes: 100.00% <br>  Exterior 2: 16 valores, ints: 0.00%, flotantes: 0.00% <br>  3SsnPorch: 20 valores, ints: 100.00%, flotantes: 100.00% <br>  MiscVal: 21 valores, ints: 100.00%, flotantes: 100.00% <br>  LowQualFinSF: 24 valores, ints: 100.00%, flotantes: 100.00% <br>  Barrio: 25 valores, entradas: 0.00%, flotadores: 0.00% <br>  YearRemodAdd: 61 valores, ints: 100.00%, flotantes: 100.00% <br>  ScreenPorch: 76 valores, ints: 100.00%, flota: 100.00% <br>  GarageYrBlt: 98 valores, ints: 94.45%, flotadores: 94.45% <br>  LotFrontage: 111 valores, ints: 82.26%, flotantes: 82.26% <br>  A√±o Construido: 112 valores, entradas: 100.00%, flotantes: 100.00% <br>  Porche cerrado: 120 valores, entradas: 100.00%, flotadores: 100.00% <br>  BsmtFinSF2: 144 valores, ints: 100.00%, flotantes: 100.00% <br>  OpenPorchSF: 202 valores, ints: 100.00%, flotantes: 100.00% <br>  WoodDeckSF: 274 valores, entradas: 100.00%, flotadores: 100.00% <br>  MasVnrArea: 328 valores, ints: 99.45%, flotantes: 99.45% <br>  2ndFlrSF: 417 valores, entradas: 100.00%, flotantes: 100.00% <br>  √Årea de garaje: 441 valores, entradas: 100.00%, flotadores: 100.00% <br>  BsmtFinSF1: 637 valores, ints: 100.00%, flotantes: 100.00% <br>  Precio de venta: 663 valores, entradas: 100.00%, flotadores: 100.00% <br>  TotalBsmtSF: 721 valores, ints: 100.00%, flotantes: 100.00% <br>  1stFlrSF: 753 valores, entradas: 100.00%, flotantes: 100.00% <br>  BsmtUnfSF: 780 valores, ints: 100.00%, flotantes: 100.00% <br>  GrLivArea: 861 valores, entradas: 100.00%, flotantes: 100.00% <br>  LotArea: 1073 valores, ints: 100.00%, flotantes: 100.00% <br><br>  Muchas columnas de valor: <br>  Exterior1st: AsbShng, AsphShn, BrkComm, BrkFace, CBlock, CemntBd, HdBoard, ImStucc, MetalSd, Plywood, Stone, Stucco, VinylSd, Wd Sdng, WdShing <br>  Exterior2nd: AsbShng, AsphShn, Brk Cmn, BrkFace, CBlock, CmentBd, HdBoard, ImStucc, MetalSd, Other, Plywood, Stone, Stucco, VinylSd, Wd Sdng, Wd Shng <br>  Vecindad: Blmngtn, Blueste, BrDale, BrkSide, ClearCr, CollgCr, Crawfor, Edwards, Gilbert, IDOTRR, MeadowV, Mitchel, NAmes, NoRidge, NPkVill, NridgHt, NWAmes, OldTown, Sawyer, SawyerW, Somerst, Stone, Stoner Veenker <br><br>  flotadores no analizables <br>  GarageYrBlt: NA <br>  LotFrontage: NA <br>  MasVnrArea: NA <br><br>  rangos de flotaci√≥n: <br>  BsmtHalfBath: 0 ... 2 <br>  Medio ba√±o: 0 ... 2 <br>  BsmtFullBath: 0 ... 3 <br>  Chimeneas: 0 ... 3 <br>  Ba√±o completo: 0 ... 3 <br>  KitchenAbvGr: 0 ... 3 <br>  GarageCars: 0 ... 4 <br>  A√±o de venta: 2006 ... 2010 <br>  DormitorioAbvGr: 0 ... 8 <br>  √Årea de piscina: 0 ... 738 <br>  OverallCond: 1 ... 9 <br>  General Qualual: 1 ... 10 <br>  MoSold: 1 ... 12 <br>  TotRmsAbvGrd: 2 ... 14 <br>  MSSubClass: 20 ... 190 <br>  3SsnPorche: 0 ... 508 <br>  Miscel√°nea: 0 ... 15500 <br>  LowQualFinSF: 0 ... 572 <br>  A√±o Modificado Agregar: 1950 ... 2010 <br>  ScreenPorch: 0 ... 480 <br>  GarageYrBlt: 1900 ... 2010 <br>  LotFrontage: 21 ... 313 <br>  A√±o de construcci√≥n: 1872 ... 2010 <br>  Porche cerrado: 0 ... 552 <br>  BsmtFinSF2: 0 ... 1474 <br>  OpenPorchSF: 0 ... 547 <br>  WoodDeckSF: 0 ... 857 <br>  MasVnrArea: 0 ... 1600 <br>  2ndFlrSF: 0 ... 2065 <br>  √Årea de garaje: 0 ... 1418 <br>  BsmtFinSF1: 0 ... 5644 <br>  Precio de venta: 34,900 ... 755,000 <br>  TotalBsmtSF: 0 ... 6110 <br>  1stFlrSF: 334 ... 4692 <br>  BsmtUnfSF: 0 ... 2336 <br>  GrLivArea: 334 ... 5642 <br>  LotArea: 1300 ... 215245 <br></div></div><br><br>  Con eso en mente, constru√≠ el siguiente <i>ValueNormalizer</i> , que toma informaci√≥n sobre los valores dentro de la columna y devuelve una funci√≥n, que transforma un valor (una <i>cadena</i> ) en un vector de caracter√≠sticas num√©ricas para la red neuronal ( <i>doble []</i> ): <br><br><div class="spoiler">  <b class="spoiler_title">ValueNormalizer</b> <div class="spoiler_text"><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Func&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[]&gt; ValueNormalizer( <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats, IEnumerable&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>&gt; values) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (floats &gt; <span class="hljs-number"><span class="hljs-number">0.01</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> max = values.AsDouble().Max().Value; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span>[] { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(s, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) ? v / max : <span class="hljs-number"><span class="hljs-number">-1</span></span> }; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>[] domain = values.Distinct().OrderBy(v =&gt; v).ToArray(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[domain.Length+<span class="hljs-number"><span class="hljs-number">1</span></span>] .Set(Array.IndexOf(domain, s)+<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); } }</code> </pre> <br></div></div><br>  Ahora tenemos los datos convertidos a un formato, adecuado para una red neuronal.  Es hora de construir uno. <br><br><h2>  Construye una red neuronal </h2><br>  <i>A partir de hoy, necesitar√≠a usar una m√°quina Windows para eso.</i> <br><br>  Si ya tiene Python y TensorFlow 1.1x instalados, todo lo que necesita es <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">PackageReference</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Include</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"Gradient"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Version</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"0.1.10-tech-preview3"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre> <br>  en tu archivo .csproj moderno.  De lo contrario, consulte el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">manual Gradient</a> para hacer la configuraci√≥n inicial. <br><br>  Una vez que el paquete est√° en funcionamiento, podemos crear nuestra primera red profunda poco profunda. <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras.layers; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.train; ... <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> model = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Sequential(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Layer[] { <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">16</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dropout(rate: <span class="hljs-number"><span class="hljs-number">0.1</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">10</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">1</span></span>, activation: tf.nn.relu_fn), }); model.compile(optimizer: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AdamOptimizer(), loss: <span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>);</code> </pre> <br>  Esto crear√° una red neuronal no entrenada con 3 capas de neuronas y una capa de abandono, que ayuda a prevenir el sobreajuste. <br><br><div class="spoiler">  <b class="spoiler_title">tf.nn.relu_fn</b> <div class="spoiler_text">  <i>tf.nn.relu_fn</i> es la funci√≥n de activaci√≥n de nuestras neuronas.  Se sabe que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ReLU</a> funciona bien en redes profundas, porque resuelve el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">problema del gradiente de fuga</a> : las derivadas de las funciones de activaci√≥n no lineales originales tienden a ser muy peque√±as cuando el error se propaga desde la capa de salida en las redes profundas.  Eso significaba que las capas m√°s cercanas a la entrada solo se ajustar√≠an muy ligeramente, lo que ralentiz√≥ significativamente el entrenamiento de redes profundas. <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Abandono</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La deserci√≥n</a> es una capa de funci√≥n especial en las redes neuronales, que en realidad no contiene neuronas como tales.  En cambio, funciona tomando cada entrada individual y la reemplaza aleatoriamente con 0 en la salida autom√°tica (de lo contrario, solo pasa el valor original).  Al hacerlo, ayuda a evitar el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sobreajuste</a> a caracter√≠sticas menos relevantes en un peque√±o conjunto de datos.  Por ejemplo, si no eliminamos la columna <i>Id</i> , la red podr√≠a haber memorizado exactamente el mapeo &lt;Id&gt; -&gt; &lt;SalePrice&gt; exactamente, lo que nos dar√≠a una precisi√≥n del 100% en el conjunto de entrenamiento, pero n√∫meros completamente no relacionados en cualquier otro dato. <br><br>  ¬øPor qu√© necesitamos abandonar?  Nuestros datos de entrenamiento solo tienen ~ 1500 ejemplos, y esta peque√±a red neuronal que hemos construido tiene&gt; 1800 pesos ajustables.  Si fuera un polinomio simple, podr√≠a coincidir con la funci√≥n de precio que estamos tratando de aproximar exactamente.  Pero entonces tendr√≠a valores enormes en cualquier entrada fuera del conjunto de entrenamiento original. <br></div></div><br><h2>  Alimentar los datos </h2><br>  TensorFlow espera sus datos en matrices NumPy o tensores existentes.  Estoy convirtiendo DataRows en matrices NumPy: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> numpy; ... <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> predict = <span class="hljs-string"><span class="hljs-string">"SalePrice"</span></span>; <span class="hljs-function"><span class="hljs-function">ndarray </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetInputs</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">IEnumerable&lt;DataRow&gt; rowSeq</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(rowSeq.Select(row =&gt; np.array( columnTypes .Where(c =&gt; c.column.ColumnName != predict) .SelectMany(column =&gt; column.normalizer( row.Table.Columns.Contains(column.column.ColumnName) ? (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column.column.ColumnName] : <span class="hljs-string"><span class="hljs-string">"-1"</span></span>)) .ToArray())) .ToArray() ); } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> predictColumn = columnTypes.Single(c =&gt; c.column.ColumnName == predict); ndarray trainOutputs = np.array(predictColumn.trainValues .AsDouble() .Select(v =&gt; v ?? <span class="hljs-number"><span class="hljs-number">-1</span></span>) .ToArray()); ndarray trainInputs = GetInputs(trainRows);</code> </pre> <br>  En el c√≥digo anterior, convertimos cada <i>DataRow</i> en un <i>ndarray</i> al tomar cada celda y aplicar el <i>ValueNormalizer</i> correspondiente a su columna.  Luego colocamos todas las filas en otro <i>ndarray</i> , obteniendo una matriz de matrices. <br><br>  No se necesita tal transformaci√≥n para las salidas, donde simplemente convertimos los valores del tren a otro <i>ndarray</i> . <br><br><h2>  Es hora de bajar el gradiente </h2><br>  Con esta configuraci√≥n, todo lo que necesitamos hacer para entrenar nuestra red es llamar a la funci√≥n de <i>ajuste</i> del modelo: <br><br><pre> <code class="cs hljs">model.fit(trainInputs, trainOutputs, epochs: <span class="hljs-number"><span class="hljs-number">2000</span></span>, validation_split: <span class="hljs-number"><span class="hljs-number">0.075</span></span>, verbose: <span class="hljs-number"><span class="hljs-number">2</span></span>);</code> </pre> <br>  Esta llamada realmente reservar√° el √∫ltimo 7.5% del conjunto de entrenamiento para la validaci√≥n, luego repita las siguientes 2000 veces: <br><br><ol><li>  dividir el resto de <i>entradas</i> de <i>tren</i> en lotes </li><li>  alimentar estos lotes uno por uno en la red neuronal </li><li>  calcular error usando la funci√≥n de p√©rdida que definimos anteriormente </li><li>  propaga el error por los gradientes de las conexiones neuronales individuales, ajustando los pesos </li></ol><br>  Durante el entrenamiento, generar√° el error de la red en los datos que dej√≥ de lado para la validaci√≥n como <b>val_loss</b> y el error en los datos de entrenamiento en s√≠ mismo como una <b>p√©rdida</b> .  En general, si <b>val_loss se</b> vuelve mucho mayor que la <b>p√©rdida</b> , significa que la red comenz√≥ a sobreajustarse.  Abordar√© eso con m√°s detalle en los siguientes art√≠culos. <br><br>  Si hiciste todo correctamente, una <u>ra√≠z cuadrada</u> de una de tus p√©rdidas deber√≠a ser del orden de 20000. <br><br><img src="https://habrastorage.org/webt/fu/rn/vg/furnvg6dbs8ocijm91_3xcqdxhm.png"><br><br><h2>  Sumisi√≥n </h2><br>  No hablar√© mucho sobre generar el archivo para enviar aqu√≠.  El c√≥digo para calcular las salidas es simple: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> SubmissionInputFile = <span class="hljs-string"><span class="hljs-string">"test.csv"</span></span>; DataTable submissionData = LoadData(SubmissionInputFile); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> submissionRows = submissionData.Rows.Cast&lt;DataRow&gt;(); ndarray submissionInputs = GetInputs(submissionRows); ndarray sumissionOutputs = model.predict(submissionInputs);</code> </pre> <br>  que utiliza principalmente funciones, que se definieron anteriormente. <br><br>  Luego, debe escribirlos en un archivo .csv, que es simplemente una lista de Id, pares de valores pronosticados. <br><br>  Cuando env√≠e su resultado, deber√≠a obtener una puntuaci√≥n del orden de 0.17, que estar√≠a en alg√∫n lugar en el √∫ltimo trimestre de la tabla de clasificaci√≥n p√∫blica.  Pero bueno, si fuera tan simple como una red de 3 capas con 27 neuronas, esos molestos cient√≠ficos de datos no obtendr√≠an compensaciones totales de $ 300k + / a de las principales compa√±√≠as estadounidenses <br><br><h2>  Terminando </h2><br>  El c√≥digo fuente completo para esta entrada (con todos los ayudantes, y algunas de las partes comentadas de mis anteriores exploraciones y experimentos) es de aproximadamente 200 l√≠neas en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PasteBin</a> . <br><br>  En el pr√≥ximo art√≠culo, ver√°s a mis travesuras tratando de llegar al 50% superior de esa tabla de clasificaci√≥n p√∫blica.  Va a ser la aventura de un viajero aficionado, una pelea con The Windmill of Overfitting con la √∫nica herramienta que tiene el peregrino: un modelo m√°s grande (por ejemplo, ¬°NN profundo, recuerda, sin ingenier√≠a manual de caracter√≠sticas!).  Ser√° menos un tutorial de codificaci√≥n, y m√°s una b√∫squeda de pensamiento con matem√°ticas realmente maliciosas y una conclusi√≥n extra√±a.  Est√©n atentos! <br><br><h2>  Enlaces </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Concurso de precios de la vivienda en Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tutorial de regresi√≥n de TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">P√°gina de inicio de TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Referencia de la API de TensorFlow</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gradiente (enlace TensorFlow)</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/437174/">https://habr.com/ru/post/437174/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../437160/index.html">Devops</a></li>
<li><a href="../437164/index.html"># 10yearschallenge para programadores</a></li>
<li><a href="../437166/index.html">Vuelo de combate en Meteor-e</a></li>
<li><a href="../437170/index.html">Facebook sugiere usar l√°seres espaciales para comunicaciones globales</a></li>
<li><a href="../437172/index.html">IBM MQ y JMeter: primer contacto</a></li>
<li><a href="../437176/index.html">Aplicaci√≥n para iOS y Android en Kotlin + Flutter UI</a></li>
<li><a href="../437180/index.html">JVM siberiano duro: gran entrevista sobre Excelsior JET</a></li>
<li><a href="../437182/index.html">Interceptaci√≥n de llamadas del sistema en el m√≥dulo del kernel de Linux</a></li>
<li><a href="../437184/index.html">Nikolay Durov 90% complet√≥ el desarrollo de la plataforma Telegram Open Network</a></li>
<li><a href="../437186/index.html">Monolito a microservicios. Punto de vista de infraestructura</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
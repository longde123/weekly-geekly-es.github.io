<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📛 👩🏻‍💻 🖤 AERODISK Engine: Catastrophic. Bagian 1 🌁 👩🏿‍⚖️ 📞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo pembaca Habr! Topik artikel ini adalah penerapan toleransi bencana dalam sistem penyimpanan Engine AERODISK. Awalnya, kami ingin menulis dalam sa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AERODISK Engine: Catastrophic. Bagian 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/aerodisk/blog/456348/"><p><img src="https://habrastorage.org/webt/2b/54/ub/2b54ub9jta3knw6ff5eseo1buyu.jpeg"></p><br><p> Halo pembaca Habr!  Topik artikel ini adalah penerapan toleransi bencana dalam sistem penyimpanan Engine AERODISK.  Awalnya, kami ingin menulis dalam satu artikel tentang kedua cara: replikasi dan metro cluster, tetapi, sayangnya, artikel itu ternyata terlalu besar, jadi kami membagi artikel menjadi dua bagian.  Mari kita beralih dari yang sederhana ke rumit.  Pada artikel ini, kami akan mengonfigurasi dan menguji replikasi sinkron - taruh satu pusat data, dan juga putuskan saluran komunikasi antara pusat data dan lihat apa yang terjadi. </p><a name="habracut"></a><br><p>  Pelanggan kami sering mengajukan pertanyaan berbeda tentang replikasi, oleh karena itu, sebelum beralih ke pengaturan dan pengujian implementasi replika, kami akan memberi tahu Anda sedikit tentang replikasi apa yang ada dalam sistem penyimpanan. </p><br><h2 id="nemnogo-teorii">  Sedikit teori </h2><br><p>  Replikasi ke penyimpanan adalah proses berkelanjutan untuk memastikan identitas data di berbagai sistem penyimpanan secara bersamaan.  Secara teknis, replikasi dilakukan dengan dua metode. </p><br><p>  <strong>Replikasi sinkron</strong> adalah penyalinan data dari sistem penyimpanan utama ke sistem cadangan, diikuti oleh konfirmasi wajib dari kedua sistem penyimpanan bahwa data dicatat dan dikonfirmasi.  Setelah konfirmasi dari kedua belah pihak (pada kedua sistem penyimpanan) bahwa data dianggap direkam, dan Anda dapat bekerja dengannya.  Ini memastikan identitas data yang dijamin pada semua sistem penyimpanan yang berpartisipasi dalam replika. </p><br><p>  Kelebihan dari metode ini: </p><br><ul><li>  Data selalu identik pada semua sistem penyimpanan. </li></ul><br><p>  Cons: </p><br><ul><li>  Biaya solusi yang tinggi (saluran komunikasi cepat, serat mahal, transceiver gelombang panjang, dll.) </li><li>  Pembatasan jarak (dalam beberapa puluh kilometer) </li><li>  Tidak ada perlindungan terhadap kerusakan data logis (jika data rusak (disengaja atau tidak sengaja) pada sistem penyimpanan utama, maka secara otomatis dan langsung akan menjadi rusak pada penyimpanan cadangan, karena data selalu identik (ini adalah paradoks) </li></ul><br><p>  <strong>Replikasi asinkron</strong> juga menyalin data dari penyimpanan utama ke cadangan, tetapi dengan penundaan tertentu dan tanpa perlu mengkonfirmasi catatan di sisi lain.  Anda dapat bekerja dengan data segera setelah menulis ke penyimpanan utama, dan pada penyimpanan cadangan, data akan tersedia setelah beberapa saat.  Identitas data dalam hal ini, tentu saja, tidak disediakan sama sekali.  Data pada penyimpanan cadangan selalu sedikit "di masa lalu". </p><br><p>  Plus dari replikasi asinkron: </p><br><ul><li>  Biaya solusi rendah (semua saluran komunikasi, optik opsional) </li><li>  Tidak ada batasan jarak </li><li>  Data pada penyimpanan cadangan tidak rusak jika rusak pada utama (setidaknya untuk beberapa waktu), jika data menjadi rusak, Anda selalu dapat menghentikan replika untuk mencegah korupsi data pada penyimpanan cadangan </li></ul><br><p>  Cons: </p><br><ul><li>  Data di pusat data yang berbeda selalu tidak identik </li></ul><br><p>  Dengan demikian, pilihan mode replikasi tergantung pada tugas-tugas bisnis.  Jika penting bagi Anda bahwa pusat data cadangan memiliki data yang sama persis dengan data utama (mis. Persyaratan bisnis untuk RPO = 0), Anda harus membayar dan memasang dengan batasan replika sinkron.  Dan jika keterlambatan dalam keadaan data diizinkan atau tidak ada uang, maka, pasti, Anda harus menggunakan metode asinkron. </p><br><p>  Kami juga secara terpisah membedakan rezim seperti itu (lebih tepatnya, sudah menjadi topologi) sebagai metro cluster.  Mode Metrocluster menggunakan replikasi sinkron, tetapi, tidak seperti replika biasa, metrocluster memungkinkan kedua sistem penyimpanan bekerja dalam mode aktif.  Yaitu  Anda tidak memiliki pemisahan pusat data siaga-aktif.  Aplikasi bekerja secara bersamaan dengan dua sistem penyimpanan yang secara fisik terletak di pusat data yang berbeda.  Downtime kecelakaan dalam topologi seperti itu sangat kecil (RTO, biasanya menit).  Dalam artikel ini, kami tidak akan mempertimbangkan penerapan cluster metro kami, karena ini adalah topik yang sangat besar dan luas, jadi kami akan mencurahkan artikel terpisah, berikut untuk melanjutkannya. </p><br><p>  Juga sangat sering, ketika kita berbicara tentang replikasi menggunakan sistem penyimpanan, banyak yang memiliki pertanyaan yang masuk akal:&gt; "Banyak aplikasi memiliki alat replikasi sendiri, mengapa menggunakan replikasi pada sistem penyimpanan?  Apakah ini lebih baik atau lebih buruk? " </p><br><p>  Tidak ada jawaban tunggal, jadi inilah pro dan kontra: </p><br><p>  Argumen UNTUK replikasi penyimpanan: </p><br><ul><li>  Kesederhanaan solusinya.  Dengan satu cara, Anda dapat mereplikasi seluruh larik data, apa pun jenis atau aplikasinya.  Jika Anda menggunakan replika aplikasi, maka Anda harus mengkonfigurasi setiap aplikasi secara terpisah.  Jika ada lebih dari 2 dari mereka, maka itu sangat memakan waktu dan mahal (replikasi aplikasi mensyaratkan, sebagai lisensi terpisah dan tidak gratis untuk setiap aplikasi. Tetapi lebih lanjut tentang itu di bawah). </li><li>  Anda dapat mereplikasi apa saja - aplikasi apa saja, data apa saja - dan mereka akan selalu konsisten.  Banyak (sebagian besar) aplikasi tidak memiliki fasilitas replikasi, dan replika dari sisi penyimpanan adalah satu-satunya cara untuk memberikan perlindungan terhadap bencana. </li><li>  Tidak perlu membayar lebih untuk fungsionalitas replikasi aplikasi.  Sebagai aturan, biayanya banyak, seperti halnya lisensi untuk sistem penyimpanan replika.  Tetapi Anda perlu membayar lisensi replikasi penyimpanan hanya sekali, dan Anda perlu membeli lisensi untuk replika aplikasi untuk setiap aplikasi secara terpisah.  Jika ada banyak aplikasi seperti itu, maka harganya cukup mahal dan biaya lisensi untuk replikasi penyimpanan menjadi setetes dalam ember. </li></ul><br><p>  Argumen TERHADAP replikasi penyimpanan: </p><br><ul><li>  Replika menggunakan alat aplikasi memiliki lebih banyak fungsi dari sudut pandang aplikasi itu sendiri, aplikasi mengetahui datanya lebih baik (yang jelas), jadi ada lebih banyak pilihan untuk bekerja dengannya. </li><li>  Pembuat beberapa aplikasi tidak menjamin konsistensi data mereka jika replikasi dilakukan oleh alat pihak ketiga.  * </li></ul><br><p>  * - tesis kontroversial.  Sebagai contoh, sebuah perusahaan manufaktur DBMS yang terkenal, untuk waktu yang sangat lama secara resmi menyatakan bahwa DBMS mereka biasanya dapat direplikasi hanya dengan cara mereka, dan sisa replikasi (termasuk SHD-shnaya) adalah "tidak benar".  Tetapi hidup telah menunjukkan bahwa ini tidak benar.  Kemungkinan besar (tapi ini tidak akurat) ini sama sekali bukan upaya yang paling jujur ​​untuk menjual lebih banyak lisensi kepada pelanggan. </p><br><p>  Akibatnya, dalam banyak kasus, replikasi dari sisi penyimpanan lebih baik, karena  Ini adalah pilihan yang lebih sederhana dan lebih murah, tetapi ada kasus kompleks ketika Anda membutuhkan fungsionalitas aplikasi spesifik, dan Anda perlu bekerja dengan replikasi tingkat aplikasi. </p><br><h2 id="s-teoriey-zakonchili-teper-praktika">  Dengan teori selesai, sekarang berlatih </h2><br><p>  Kami akan membuat replika di lab kami.  Di laboratorium, kami meniru dua pusat data (pada kenyataannya, dua rak yang berdekatan yang tampaknya berada di gedung yang berbeda).  Dudukan terdiri dari dua sistem penyimpanan Engine N2, yang saling terhubung oleh kabel optik.  Server fisik yang menjalankan Windows Server 2016 menggunakan 10Gb Ethernet terhubung ke kedua sistem penyimpanan.  Dudukannya cukup sederhana, tetapi tidak mengubah esensinya. </p><br><p>  Secara skematis, tampilannya seperti ini: </p><br><p><img src="https://habrastorage.org/webt/wj/u4/rc/wju4rcak9ilbms68pnffyvsb6ly.png"></p><br><p>  Replikasi logis diatur sebagai berikut: </p><br><p><img src="https://habrastorage.org/webt/yf/yh/dy/yfyhdy19cbj3sc0gpzp8jx6liz0.jpeg"></p><br><p>  Sekarang mari kita lihat fungsi replikasi yang kita miliki sekarang. <br>  Dua mode didukung: asinkron dan sinkron.  Adalah logis bahwa mode sinkron dibatasi oleh jarak dan saluran komunikasi.  Secara khusus, mode sinkron memerlukan penggunaan serat sebagai fisika dan 10 gigabit Ethernet (atau lebih tinggi). </p><br><p>  Jarak yang didukung untuk replikasi sinkron adalah 40 kilometer, penundaan saluran optik antara pusat data hingga 2 milidetik.  Secara umum, ini akan bekerja dengan penundaan besar, tetapi kemudian akan ada rem yang kuat saat merekam (yang juga logis), jadi jika Anda mempertimbangkan replikasi sinkron antara pusat data, Anda harus memeriksa kualitas optik dan penundaan. </p><br><p>  Persyaratan replikasi asinkron tidak begitu serius.  Lebih tepatnya, mereka sama sekali tidak.  Koneksi Ethernet yang berfungsi cocok. </p><br><p>  Saat ini, penyimpanan AERODISK ENGINE mendukung replikasi untuk perangkat blok (LUN) menggunakan protokol Ethernet (tembaga atau optik).  Untuk proyek-proyek yang perlu direplikasi melalui pabrik Fibre Channel SAN, kami sekarang menyelesaikan solusi yang sesuai, tetapi sejauh ini belum siap, jadi dalam kasus kami hanya Ethernet. </p><br><p>  Replikasi dapat bekerja di antara sistem penyimpanan seri ENGINE (N1, N2, N4) dari sistem yang lebih rendah ke yang lebih lama dan sebaliknya. </p><br><p>  Fungsionalitas kedua mode replikasi benar-benar identik.  Di bawah ini lebih lanjut tentang apa itu: </p><br><ul><li>  Replikasi "satu ke satu" atau "satu ke satu", yaitu, versi klasik dengan dua pusat data, utama dan cadangan </li><li>  Replikasi adalah "satu ke banyak" atau "satu ke banyak", yaitu  satu LUN dapat direplikasi ke beberapa sistem penyimpanan sekaligus </li><li>  Aktivasi, deaktivasi, dan "pembalikan" replikasi, masing-masing, untuk mengaktifkan, menonaktifkan atau mengubah arah replikasi </li><li>  Replikasi tersedia untuk kelompok RDG (Raid Distributed Group) dan DDP (Dynamic Disk Pool).  Namun, RDG pool LUN hanya dapat direplikasi ke RDG lain.  C DDP serupa. </li></ul><br><p>  Ada banyak fitur yang lebih kecil, tetapi daftar mereka tidak masuk akal, kami akan menyebutkannya selama pengaturan. </p><br><h2 id="nastroyka-replikacii">  Setup replikasi </h2><br><p>  Proses pengaturannya cukup sederhana dan terdiri dari tiga tahap. </p><br><ol><li>  Pengaturan jaringan </li><li>  Pengaturan Penyimpanan </li><li>  Menyiapkan aturan (tautan) dan pemetaan </li></ol><br><p>  Poin penting dalam mengonfigurasi replikasi adalah bahwa dua tahap pertama harus diulang pada sistem penyimpanan jarak jauh, tahap ketiga - hanya pada tahap utama. </p><br><h3 id="nastroyka-setevyh-resursov">  Konfigurasi Sumber Daya Jaringan </h3><br><p>  Langkah pertama adalah mengkonfigurasi port jaringan di mana lalu lintas replikasi akan dikirimkan.  Untuk melakukan ini, Anda perlu mengaktifkan port dan mengatur alamat IP pada port tersebut di bagian Adapter front-end. </p><br><p>  Setelah itu kita perlu membuat kumpulan (dalam kasus kami RDG) dan IP virtual untuk replikasi (VIP).  VIP adalah alamat IP mengambang yang terikat pada dua alamat "fisik" pengontrol penyimpanan (port yang baru saja kami konfigurasikan).  Ini akan menjadi antarmuka replikasi utama.  Anda juga dapat beroperasi bukan dengan VIP, tetapi dengan VLAN jika Anda perlu bekerja dengan lalu lintas yang ditandai. </p><br><p><img src="https://habrastorage.org/webt/di/ye/5f/diye5fvbzya3cvtebg7memcs5jo.jpeg"></p><br><p>  Proses membuat VIP untuk replika tidak jauh berbeda dari membuat VIP untuk I / O (NFS, SMB, iSCSI).  Dalam hal ini, kami membuat VIP (tanpa VLAN), tetapi pastikan untuk menunjukkan bahwa itu untuk replikasi (tanpa penunjuk ini, kami tidak akan dapat menambahkan VIP ke aturan di langkah berikutnya). </p><br><p><img src="https://habrastorage.org/webt/nd/i9/2d/ndi92dbmjvxuqjidju802r-vl7s.png"></p><br><p>  VIP harus berada di subnet yang sama dengan port IP di mana ia "mengapung". </p><br><p><img src="https://habrastorage.org/webt/vm/no/9m/vmno9ms_uas_guk28o1etun7kg4.png"></p><br><p>  Kami ulangi pengaturan ini pada sistem penyimpanan jarak jauh, dengan IP-shnik lain, dengan sendirinya. <br>  VIP dari sistem penyimpanan yang berbeda dapat berada di subnet yang berbeda, yang utama adalah harus ada perutean di antara mereka.  Dalam kasus kami, contoh ini baru saja ditampilkan (192.168.3.XX dan 192.168.2.XX) </p><br><p><img src="https://habrastorage.org/webt/w5/r6/re/w5r6rexidxqry4rnfdrvgp5gzcq.jpeg"></p><br><p>  Pada ini, persiapan bagian jaringan selesai. </p><br><h3 id="nastraivaem-hranilischa">  Konfigurasikan penyimpanan </h3><br><p>  Mengkonfigurasi penyimpanan untuk replika berbeda dari yang biasa hanya dalam hal kita melakukan pemetaan melalui menu khusus “Pemetaan replikasi”.  Kalau tidak, semuanya sama dengan pengaturan biasa.  Sekarang sudah beres. </p><br><p>  Di kumpulan R02 yang sebelumnya dibuat, Anda harus membuat LUN.  Buat, sebut saja LUN1. </p><br><p><img src="https://habrastorage.org/webt/tg/l8/vk/tgl8vkdsqf-4oljacfssnh2_zus.jpeg"></p><br><p>  Kita juga perlu membuat LUN yang sama pada sistem penyimpanan jarak jauh dengan volume yang sama.  Kami menciptakan.  Untuk menghindari kebingungan, LUN jarak jauh akan disebut LUN1R </p><br><p><img src="https://habrastorage.org/webt/xm/kl/v4/xmklv4deigknjz1vadluit9pdds.jpeg"></p><br><p>  Jika kita perlu mengambil LUN yang sudah ada, maka pada saat setup replika, LUN yang produktif ini harus dilepas dari host, dan pada sistem penyimpanan jarak jauh cukup buat LUN kosong dengan ukuran yang sama. </p><br><p>  Pengaturan penyimpanan selesai, kami melanjutkan ke pembuatan aturan replikasi. </p><br><h3 id="nastroyka-pravil-replikacii-ili-replikacionnyh-svyazey">  Konfigurasikan aturan replikasi atau tautan replikasi </h3><br><p>  Setelah membuat LUN pada penyimpanan, yang akan menjadi yang utama saat ini, kami mengkonfigurasi aturan replikasi LUN1 pada SHD1 di LUN1R pada SHD2. </p><br><p>  Konfigurasi dilakukan di menu Replikasi Jarak Jauh. </p><br><p>  Buat aturan.  Untuk melakukan ini, tentukan penerima replika.  Kami juga menentukan nama koneksi dan jenis replikasi (sinkron atau asinkron). </p><br><p><img src="https://habrastorage.org/webt/xk/yu/8f/xkyu8ftgcubcwu4-ul_ux3vc7lq.jpeg"></p><br><p>  Di bidang "sistem jarak jauh", tambahkan SHD2 kami.  Untuk menambahkan, Anda perlu menggunakan penyimpanan IP pengelolaan (MGR) dan nama LUN jarak jauh yang akan kami tiru (dalam kasus kami, LUN1R).  Mengelola IP diperlukan hanya pada tahap penambahan komunikasi, lalu lintas replikasi melalui mereka tidak akan ditransmisikan, untuk ini, VIP yang sebelumnya dikonfigurasi akan digunakan. </p><br><p>  Sudah pada tahap ini, kita dapat menambahkan lebih dari satu sistem jarak jauh untuk topologi "satu ke banyak": klik tombol "tambahkan simpul", seperti pada gambar di bawah ini. </p><br><p><img src="https://habrastorage.org/webt/rv/xb/bh/rvxbbh4umovgds3gduoaxg3tfc8.jpeg"></p><br><p>  Dalam kasus kami, sistem jarak jauh adalah satu, jadi kami terbatas pada ini. </p><br><p>  Aturannya sudah siap.  Perhatikan bahwa itu secara otomatis ditambahkan ke semua peserta replikasi (dalam kasus kami, ada dua dari mereka).  Anda dapat membuat aturan sebanyak yang Anda suka, untuk sejumlah LUN dan ke arah mana pun.  Misalnya, untuk menyeimbangkan beban, kita dapat mereplikasi bagian LUN dari SHD1 ke SHD2, dan bagian lain, sebaliknya, dari SHD2 ke SHD1. </p><br><p>  SHD1.  Segera setelah pembuatan, sinkronisasi dimulai. </p><br><p><img src="https://habrastorage.org/webt/y7/v8/gg/y7v8gg7bboqpit0zrow87pgvi5y.jpeg"></p><br><p>  SHD2.  Kami melihat aturan yang sama, tetapi sinkronisasi sudah berakhir. </p><br><p><img src="https://habrastorage.org/webt/tb/dl/0k/tbdl0k_anxtcwmecg31bk0s7fmo.jpeg"></p><br><p>  LUN1 pada SHD1 adalah dalam peran Pratama, yaitu aktif.  LUN1R pada SHD2 adalah dalam peran Sekunder, yaitu ditahan, dalam kasus kegagalan SHD1. <br>  Sekarang kita dapat menghubungkan LUN kita ke host. </p><br><p>  Kami akan melakukan koneksi melalui iSCSI, meskipun itu dapat dilakukan melalui FC.  Menyiapkan pemetaan untuk iSCSI LUN dalam replika praktis tidak berbeda dari skenario yang biasa, jadi kami tidak akan membahas ini secara rinci di sini.  Jika ada, proses ini dijelaskan dalam artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengaturan Cepat</a> . </p><br><p>  Satu-satunya perbedaan adalah kami membuat pemetaan di menu “Pemetaan replikasi”. </p><br><p><img src="https://habrastorage.org/webt/xn/uy/p9/xnuyp9dccwbpg93ahvefmhifmdq.jpeg"></p><br><p>  Atur pemetaan, berikan LUN ke tuan rumah.  Tuan rumah melihat LUN. </p><br><p><img src="https://habrastorage.org/webt/qg/y3/vm/qgy3vmfark_2-pvl8liqtozb2iu.jpeg"></p><br><p>  Memformatnya ke sistem file lokal. </p><br><p><img src="https://habrastorage.org/webt/zd/8l/qg/zd8lqglmv194u9-zsctatxrsuzk.jpeg"></p><br><p>  Itu dia, setup sudah selesai.  Selanjutnya akan pergi tes. </p><br><h2 id="testirovanie">  Pengujian </h2><br><p>  Kami akan menguji tiga skenario utama. </p><br><ol><li>  Pergantian peran staf Sekunder&gt; Primer.  Pergantian peran rutin diperlukan jika, misalnya, kami terutama membutuhkan pusat data untuk melakukan beberapa operasi pencegahan, dan selama waktu ini, agar data tersedia, kami mentransfer beban ke pusat data cadangan. </li><li>  Kegagalan peran Sekunder&gt; Primer (kegagalan pusat data).  Ini adalah skenario utama yang ada replikasi, yang dapat membantu bertahan dari kegagalan pusat data yang lengkap tanpa menghentikan perusahaan untuk waktu yang lama. </li><li>  Saluran komunikasi terputus antara pusat data.  Memeriksa perilaku yang benar dari dua sistem penyimpanan dalam kondisi ketika karena suatu alasan saluran komunikasi antara pusat data tidak tersedia (misalnya, excavator menggali di tempat yang salah dan merobek melalui optik gelap). </li></ol><br><p>  Untuk memulainya, kita akan mulai menulis data ke LUN kita (kita menulis file dengan data acak).  Kami segera melihat bahwa saluran komunikasi antara sistem penyimpanan sedang digunakan.  Ini mudah dimengerti jika Anda membuka pemantauan port yang bertanggung jawab untuk replikasi. </p><br><p><img src="https://habrastorage.org/webt/s7/99/bt/s799bttjt3v6q24uhvxoywfrwne.jpeg"></p><br><p>  Pada kedua sistem penyimpanan sekarang ada data "berguna", kita dapat memulai tes. </p><br><p><img src="https://habrastorage.org/webt/r3/vs/dv/r3vsdvpsp9avchablad41pxrfdu.jpeg"></p><br><p>  Untuk berjaga-jaga, mari kita lihat jumlah hash dari salah satu file dan tuliskan. </p><br><p><img src="https://habrastorage.org/webt/e1/zi/st/e1zistvzwlkimqbupxjtgnltc9o.jpeg"></p><br><h3 id="shtatnoe-pereklyuchenie-roley">  Pergantian Peran Staf </h3><br><p>  Pengoperasian peran switching (mengubah arah replikasi) dapat dilakukan dari sistem penyimpanan apa pun, tetapi Anda masih harus menuju keduanya, karena Anda harus menonaktifkan pemetaan pada Primary, dan mengaktifkannya pada Secondary (yang akan menjadi Primary). </p><br><p>  Mungkin sekarang muncul pertanyaan yang masuk akal: mengapa tidak mengotomatiskan ini?  Kami menjawab: semuanya sederhana, replikasi adalah alat toleransi bencana sederhana yang hanya didasarkan pada operasi manual.  Untuk mengotomatiskan operasi ini, ada mode cluster metro, ini sepenuhnya otomatis, tetapi konfigurasinya jauh lebih rumit.  Kami akan menulis tentang pengaturan metro cluster di artikel selanjutnya. </p><br><p>  Nonaktifkan pemetaan pada penyimpanan utama untuk memastikan perekaman dihentikan. </p><br><p><img src="https://habrastorage.org/webt/jk/j4/1l/jkj41ltsncz2hmqoclkrecqvguy.jpeg"></p><br><p>  Kemudian pada salah satu sistem penyimpanan (tidak masalah, pada primer atau cadangan) di menu Replikasi Jarak Jauh, pilih koneksi REPL1 kami dan klik "Ubah Peran". </p><br><p><img src="https://habrastorage.org/webt/dc/bb/8t/dcbb8tv24xxhofmg_avtodfelas.jpeg"></p><br><p>  Setelah beberapa detik, LUN1R (penyimpanan cadangan) menjadi Utama. </p><br><p><img src="https://habrastorage.org/webt/-v/hf/l2/-vhfl2g0v20bnfnomxwupf0_9xk.jpeg"></p><br><p>  Kami membuat pemetaan LUN1R dengan SHD2. </p><br><p><img src="https://habrastorage.org/webt/lh/uw/cy/lhuwcyscu0quljitysu2pkk35hg.jpeg"></p><br><p>  Setelah itu, drive E: kami secara otomatis menempel pada host, hanya saja kali ini "terbang" dengan LUN1R. </p><br><p>  Untuk jaga-jaga, bandingkan jumlah hash. </p><br><p><img src="https://habrastorage.org/webt/g6/st/qh/g6stqhn-xr0yqlw84t7y4_y5sqm.png"></p><br><p>  Identik  Tes berlalu. </p><br><h3 id="avariynoe-pereklyuchenie-otkaz-cod-a">  Kegagalan  Kegagalan Pusat Data </h3><br><p>  Saat ini, penyimpanan utama setelah switching reguler adalah SHD2 dan LUN1R, masing-masing.  Untuk mensimulasikan kecelakaan, kami mematikan daya pada kedua kontroler SHD2. <br>  Akses ke sana tidak lagi. </p><br><p>  Kami melihat apa yang terjadi pada penyimpanan 1 (cadangan saat ini). </p><br><p><img src="https://habrastorage.org/webt/ai/oy/jt/aioyjtl8xqmmgngtidigkvoesai.jpeg"></p><br><p>  Kami melihat bahwa LUN Primer (LUN1R) tidak tersedia.  Pesan kesalahan muncul di log, di panel informasi, serta di aturan replikasi itu sendiri.  Karenanya, data dari tuan rumah saat ini tidak tersedia. </p><br><p>  Ubah peran LUN1 menjadi Utama. </p><br><p><img src="https://habrastorage.org/webt/ef/vr/wv/efvrwvemqzysnrtebprwvmqnxw8.jpeg"></p><br><p>  Urusan pemetaan ke tuan rumah. </p><br><p><img src="https://habrastorage.org/webt/o9/es/oj/o9esojg6xcl-uv_wbbj6afkrz18.jpeg"></p><br><p>  Pastikan drive E muncul di host. </p><br><p><img src="https://habrastorage.org/webt/rg/kj/0s/rgkj0s-0rgoumtmnzk98bd-bgl4.jpeg"></p><br><p>  Periksa hash. </p><br><p><img src="https://habrastorage.org/webt/hn/yb/yq/hnybyqjm7w_g1il4bowg1-xgq5y.jpeg"></p><br><p>  Semuanya baik-baik saja.  Pusat penyimpanan mengalami penurunan di pusat data, yang aktif.  Perkiraan waktu yang kami habiskan untuk menghubungkan "pembalikan" replikasi dan menghubungkan LUN dari pusat data cadangan adalah sekitar 3 menit.  Jelas bahwa dalam produk nyata semuanya jauh lebih rumit, dan di samping tindakan dengan sistem penyimpanan, Anda perlu melakukan lebih banyak operasi pada jaringan, pada host, dalam aplikasi.  Dan dalam hidup, periode waktu ini akan jauh lebih lama. </p><br><p>  Di sini saya ingin menulis bahwa semuanya, tes selesai dengan sukses, tapi jangan terburu-buru.  Penyimpanan utama "terletak", kita tahu bahwa ketika dia "jatuh", dia berperan sebagai Pratama.  Apa yang terjadi jika dia tiba-tiba hidup?  Akan ada dua peran utama, yang sama dengan korupsi data?  Kami akan memeriksanya sekarang. <br>  Kami tiba-tiba akan mengaktifkan penyimpanan yang mendasarinya. </p><br><p>  Ini memuat selama beberapa menit dan setelah itu kembali beroperasi setelah sinkronisasi singkat, tetapi sudah dalam peran Sekunder. </p><br><p><img src="https://habrastorage.org/webt/27/hu/q6/27huq6b6guby7o-g7_xkz7quugy.jpeg"></p><br><p>  Semuanya baik-baik saja.  Otak yang terbelah tidak terjadi.  Kami memikirkan hal ini, dan selalu setelah jatuhnya sistem penyimpanan naik dalam peran Sekunder, terlepas dari apa perannya "dalam kehidupan".  Sekarang kita dapat mengatakan dengan pasti bahwa uji kegagalan pusat data berhasil. </p><br><h3 id="otkaz-kanalov-svyazi-mezhdu-cod-ami">  Kegagalan saluran komunikasi antara pusat data </h3><br><p>  Tugas utama dari tes ini adalah untuk memastikan bahwa sistem penyimpanan tidak akan mulai panik jika sementara itu kehilangan saluran komunikasi antara kedua sistem penyimpanan dan kemudian muncul kembali. <br>  Jadi  Kami mencabut kabel antara sistem penyimpanan (bayangkan bahwa sebuah excavator menggali mereka). </p><br><p>  Di Pratama kita melihat bahwa tidak ada hubungan dengan Sekunder. </p><br><p><img src="https://habrastorage.org/webt/yh/nf/ar/yhnfarhppjrnbaxotu4ds4szz5c.jpeg"></p><br><p>  Pada Sekunder, kita melihat bahwa tidak ada koneksi dengan Pratama. </p><br><p><img src="https://habrastorage.org/webt/f4/k9/7h/f4k97hzr11uh3cytxpsjlq2anly.jpeg"></p><br><p>  Semuanya berfungsi dengan baik, dan kami terus menulis data ke sistem penyimpanan utama, yaitu, mereka sudah dijamin berbeda dari yang cadangan, yaitu, mereka telah "pergi". </p><br><p>  Dalam beberapa menit kami memperbaiki saluran komunikasi.  Segera setelah sistem penyimpanan saling melihat, sinkronisasi data dihidupkan secara otomatis.  Tidak ada yang diperlukan dari administrator. </p><br><p><img src="https://habrastorage.org/webt/wo/os/yy/woosyydo-vvbauzsd7lgu4qwfos.jpeg"></p><br><p>     . </p><br><p><img src="https://habrastorage.org/webt/up/ne/es/upneeslicidwf8manqfmlvcaohu.jpeg"></p><br><p>  ,        ,      . </p><br><h2 id="vyvody">  </h2><br><p>    –    ,  ,   .       . </p><br><p>        ,  -    .      .   ,        . </p><br><p>                   active-active,       ,       . </p><br><p>   ,       . </p><br><p>   . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id456348/">https://habr.com/ru/post/id456348/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id456336/index.html">11 tips untuk menggunakan Redux saat mengembangkan Bereaksi aplikasi</a></li>
<li><a href="../id456338/index.html">13 single-liners JavaScript yang bermanfaat</a></li>
<li><a href="../id456340/index.html">Sebuah kisah tentang bagaimana tim freelancer menulis aplikasi JavaScript penuh-tumpukan</a></li>
<li><a href="../id456342/index.html">Satu bahasa untuk menguasai semua</a></li>
<li><a href="../id456344/index.html">Mengapa ['1', '7', '11']. Peta (parseInt) mengembalikan [1, NaN, 3] dalam Javascript?</a></li>
<li><a href="../id456350/index.html">Acara digital di Moskow dari 17-23 Juni</a></li>
<li><a href="../id456352/index.html">Modul komunikasi objek nirkabel WISE-4000</a></li>
<li><a href="../id456354/index.html">Bagaimana cara kami mengumpulkan kotak TV</a></li>
<li><a href="../id456358/index.html">13 artikel paling terkenal tahun lalu</a></li>
<li><a href="../id456362/index.html">Perancang Tingkat 6: bagaimana kita memotivasi dan mengembangkan perancang</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëû üßü üîã Nginx-Cache: alles neu - gut vergessen alt üèïÔ∏è üë®üèº‚Äçüé® ü§öüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im Laufe jedes Projekts kommt die Zeit, in der der Server die SLA-Anforderungen nicht mehr erf√ºllt und buchst√§blich beginnt, die Menge des eingehenden...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nginx-Cache: alles neu - gut vergessen alt</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428127/">  Im Laufe jedes Projekts kommt die Zeit, in der der Server die SLA-Anforderungen nicht mehr erf√ºllt und buchst√§blich beginnt, die Menge des eingehenden Datenverkehrs zu drosseln.  Danach beginnt der lange Prozess des Auffindens von Engp√§ssen, umfangreichen Abfragen, falsch erstellten Indizes, nicht zwischengespeicherten Daten oder umgekehrt, zu h√§ufig aktualisierten Daten im Cache und anderen dunklen Seiten des Projekts. <br><br>  Aber was tun, wenn Ihr Code ‚Äûperfekt‚Äú ist, alle umfangreichen Anforderungen im Hintergrund stehen, alles, was m√∂glich war, zwischengespeichert wurde und der Server die von uns ben√∂tigten SLA-Indikatoren immer noch nicht erreicht?  Wenn m√∂glich, k√∂nnen Sie nat√ºrlich neue Autos kaufen, einen Teil des Verkehrs verteilen und das Problem f√ºr eine Weile vergessen. <br><br>  Wenn Sie jedoch das Gef√ºhl haben, dass Ihr Server mehr kann oder es einen magischen Parameter gibt, der die Site um das 100-fache beschleunigt, k√∂nnen Sie die integrierte Nginx-Funktion aufrufen, mit der Sie Antworten aus dem Backend zwischenspeichern k√∂nnen.  Lassen Sie uns einen Blick darauf werfen, was es ist und wie es dazu beitragen kann, die Anzahl der vom Server verarbeiteten Anforderungen zu erh√∂hen. <a name="habracut"></a><br><br>
<h3>  Was ist der Nginx-Cache und wie funktioniert er? </h3><br>  Der Nginx-Cache kann die Anzahl der Anforderungen f√ºr das Backend erheblich reduzieren.  Dies wird erreicht, indem die HTTP-Antwort f√ºr eine bestimmte Zeit gespeichert wird und beim erneuten Zugriff auf die Ressource aus dem Cache zur√ºckgegeben wird, ohne die Anforderung f√ºr das Backend zu √ºbertragen.  Durch das Zwischenspeichern wird die Anzahl der vom Server verarbeiteten Anforderungen selbst f√ºr einen kurzen Zeitraum erheblich erh√∂ht. <br><br>  Bevor Sie mit der Konfiguration von nginx fortfahren, m√ºssen Sie sicherstellen, dass es mit dem Modul ‚Äûngx_http_proxy_module‚Äú erstellt wurde, da wir es mit diesem Modul konfigurieren werden. <br><br>  Zur Vereinfachung k√∂nnen Sie die Konfiguration in eine separate Datei √ºbertragen, z. B. "/etc/nginx/conf.d/cache.conf".  Schauen wir uns die Anweisung proxy_cache_path an, mit der Sie die Cache-Speichereinstellungen konfigurieren k√∂nnen. <br><br><pre><code class="hljs swift">proxy_cache_path /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/nginx/proxy_cache levels=<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">2</span></span> keys_zone=proxy_cache:15m max_size=1G;</code> </pre> <br>  "/ Var / lib / nginx / proxy_cache" gibt den Cache-Speicherpfad auf dem Server an.  In diesem Verzeichnis speichert nginx genau die Dateien mit der Antwort vom Backend.  Gleichzeitig erstellt nginx nicht unabh√§ngig ein Verzeichnis f√ºr den Cache. Sie m√ºssen sich selbst darum k√ºmmern. <br><br>  "Levels = 1: 2" - Legt die Verschachtelungsebene von Verzeichnissen mit einem Cache fest.  Verschachtelungsebenen werden durch ":" angezeigt. In diesem Fall werden 2 Verzeichnisse erstellt, insgesamt sind 3 Verschachtelungsebenen zul√§ssig.  F√ºr jede Verschachtelungsebene stehen Werte von 1 bis 2 zur Verf√ºgung, die angeben, wie der Verzeichnisname erstellt wird. <br><br>  Der wichtige Punkt ist, dass der Verzeichnisname nicht zuf√§llig ausgew√§hlt wird, sondern basierend auf dem Dateinamen erstellt wird.  Der Dateiname wiederum ist das Ergebnis der md5-Funktion aus dem Cache-Schl√ºssel. Wir werden uns den Cache-Schl√ºssel etwas sp√§ter ansehen. <br><br>  Lassen Sie uns in der Praxis sehen, wie der Pfad zur Cache-Datei erstellt wird: <br><br><pre> <code class="hljs swift">/<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/nginx/proxy_cache/<span class="hljs-number"><span class="hljs-number">2</span></span>/<span class="hljs-number"><span class="hljs-number">49</span></span>/07edcfe6974569ab4da6634ad4e5d492</code> </pre> <br>  Der Parameter "Keys_zone = proxy_cache: 15m" legt den Namen der Zone im gemeinsam genutzten Speicher fest, in der alle aktiven Schl√ºssel und Informationen zu ihnen gespeichert sind.  Durch ":" wird die Gr√∂√üe des zugewiesenen Speichers in MB angegeben.  Laut nginx reicht 1 MB aus, um 8.000 Schl√ºssel zu speichern. <br><br>  "Max_size = 1G" definiert die maximale Cache-Gr√∂√üe f√ºr alle Seiten, √ºber denen nginx daf√ºr sorgt, dass weniger ben√∂tigte Daten gel√∂scht werden. <br><br>  Es ist auch m√∂glich, die Lebensdauer der Daten im Cache zu steuern. Dazu reicht es aus, den Parameter "inaktiv" der Direktive "proxy_cache_path" zu definieren, der standardm√§√üig 10 Minuten betr√§gt.  Wenn w√§hrend der im Parameter "inaktiv" angegebenen Zeit keine Aufrufe der Cache-Daten aufgetreten sind, werden diese Daten gel√∂scht, auch wenn der Cache noch nicht "sauer" ist. <br><br>  Wie ist dieser Cache?  Dies ist eigentlich eine regul√§re Datei auf dem Server, deren Inhalt geschrieben ist: <br><br>  ‚Ä¢ Cache-Schl√ºssel; <br>  ‚Ä¢ Cache-Header; <br>  ‚Ä¢ Inhaltsantwort vom Backend. <br><br>  Wenn mit den Headern und der Antwort vom Backend alles klar ist, gibt es eine Reihe von Fragen zum ‚ÄûCache-Schl√ºssel‚Äú.  Wie ist es aufgebaut und wie kann es verwaltet werden? <br><br>  Um die Vorlage zum Erstellen eines Cache-Schl√ºssels in nginx zu beschreiben, gibt es eine Direktive proxy_cache_key, in der eine Zeichenfolge als Parameter angegeben wird.  Eine Zeichenfolge kann aus beliebigen in nginx verf√ºgbaren Variablen bestehen. <br><br>  Zum Beispiel: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_key</span></span> <span class="hljs-variable"><span class="hljs-variable">$request_method</span></span><span class="hljs-variable"><span class="hljs-variable">$host</span></span><span class="hljs-variable"><span class="hljs-variable">$orig_uri</span></span>:<span class="hljs-variable"><span class="hljs-variable">$cookie_some_cookie</span></span>:<span class="hljs-variable"><span class="hljs-variable">$arg_some_arg</span></span>;</code> </pre> <br>  Das Symbol ":" zwischen dem Cookie-Parameter und dem get-Parameter wird verwendet, um Kollisionen zwischen Cache-Schl√ºsseln zu verhindern. Sie k√∂nnen ein beliebiges anderes Symbol Ihrer Wahl ausw√§hlen.  Standardm√§√üig verwendet nginx die folgende Zeile, um den Schl√ºssel zu generieren: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_key</span></span> <span class="hljs-variable"><span class="hljs-variable">$scheme</span></span><span class="hljs-variable"><span class="hljs-variable">$proxy_host</span></span><span class="hljs-variable"><span class="hljs-variable">$request_uri</span></span>;</code> </pre> <br>  Die folgenden Anweisungen sollten beachtet werden, damit Sie Ihr Caching flexibler verwalten k√∂nnen: <br><br>  <i>proxy_cache_valid</i> - Gibt die Antwort-Caching-Zeit an.  Es ist m√∂glich, den spezifischen Status der Antwort anzugeben, z. B. 200, 302, 404 usw., oder alles gleichzeitig mit dem Konstrukt "any" anzugeben.  Wenn nur die Caching-Zeit angegeben wird, speichert nginx standardm√§√üig nur die Status 200, 301 und 302 zwischen. <br><br>  Ein Beispiel: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_valid</span></span> <span class="hljs-number"><span class="hljs-number">15m</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_valid</span></span> <span class="hljs-number"><span class="hljs-number">404</span></span> <span class="hljs-number"><span class="hljs-number">15s</span></span>;</code> </pre><br>  In diesem Beispiel haben wir die Cache-Lebensdauer f√ºr die Status 200, 301, 302 auf 15 Minuten festgelegt (nginx verwendet sie standardm√§√üig, da wir keinen bestimmten Status angegeben haben).  In der n√§chsten Zeile wird die Caching-Zeit auf 15 Sekunden festgelegt, nur f√ºr Antworten mit dem Status 404. <br><br>  <i>proxy_cache_lock</i> - Diese Anweisung hilft dabei, mehrere Durchg√§nge zum Backend unmittelbar nach einer Reihe von Caches zu vermeiden. Setzen Sie einfach den Wert auf die Position "Ein".  Alle anderen Anforderungen warten auf eine Antwort im Cache oder auf eine Zeit√ºberschreitung beim Blockieren der Anforderung an die Seite.  Dementsprechend k√∂nnen alle Zeit√ºberschreitungen konfiguriert werden. <br><br>  <i>proxy_cache_lock_age</i> - Erm√∂glicht das <i>Festlegen</i> eines Zeitlimits f√ºr eine Antwort vom Server. <i>Danach wird</i> die n√§chste Anforderung an ihn gesendet, nachdem der Cache festgelegt wurde.  Der Standardwert betr√§gt 5 Sekunden. <br><br>  <i>proxy_cache_lock_timeout</i> - Legt die Wartezeit f√ºr die Sperre fest. <i>Danach wird</i> die Anforderung an das Backend gesendet, die Antwort wird jedoch nicht zwischengespeichert.  Der Standardwert betr√§gt 5 Sekunden. <br><br>  <i>proxy_cache_use_stale</i> - Eine weitere n√ºtzliche Anweisung, mit der Sie konfigurieren k√∂nnen, wann ein veralteter Cache verwendet werden kann. <br><br>  Ein Beispiel: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_use_stale</span></span> <span class="hljs-literal"><span class="hljs-literal">error</span></span> timeout updating;</code> </pre> <br>  In diesem Fall wird ein veralteter Cache verwendet, wenn ein Verbindungsfehler auftritt, eine Anforderung gesendet, eine Antwort vom Server gelesen, das Wartelimit f√ºr das Senden einer Anforderung √ºberschritten, eine Antwort vom Server gelesen wird oder wenn die Daten im Cache zum Zeitpunkt der Anforderung aktualisiert werden. <br><br>  <i>proxy_cache_bypass</i> - Gibt die Bedingungen an, unter denen nginx keine Antwort vom Cache entgegennimmt, sondern die Anforderung sofort an das Backend umleitet.  Wenn mindestens einer der Parameter nicht leer ist und nicht gleich "0" ist.  Ein Beispiel: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_cache_bypass</span></span> <span class="hljs-variable"><span class="hljs-variable">$cookie_nocache</span></span> <span class="hljs-variable"><span class="hljs-variable">$arg_nocache</span></span>;</code> </pre> <br>  <i>proxy_no_cache</i> - Legt die Bedingung fest, unter der nginx die Antwort vom Backend nicht im Cache speichert.  Das Funktionsprinzip ist dasselbe wie das der Direktive proxy_cache_bypass. <br><br><h3>  M√∂gliche Probleme beim Zwischenspeichern von Seiten </h3><br>  Wie oben erw√§hnt, speichert nginx neben dem Zwischenspeichern einer HTTP-Antwort die vom Backend empfangenen Header.  Wenn Ihre Site eine Sitzung verwendet, wird auch das Sitzungscookie zwischengespeichert.  Alle Benutzer, die die Seite besuchen, die Sie zwischengespeichert haben, erhalten Ihre in der Sitzung gespeicherten pers√∂nlichen Daten. <br><br>  Die n√§chste Herausforderung ist das Caching-Management.  Nat√ºrlich k√∂nnen Sie eine unbedeutende Cache-Zeit von 2-5 Minuten festlegen, was in den meisten F√§llen ausreicht.  Dies gilt jedoch nicht in allen Situationen, sodass wir unser Fahrrad neu erfinden werden.  Nun, das Wichtigste zuerst. <br><br>  <b>Verwaltung der Cookie-Aufbewahrung</b> <br><br>  Das Caching auf der Nginx-Seite unterwirft einige Designeinschr√§nkungen.  Beispielsweise k√∂nnen wir keine Sitzungen auf zwischengespeicherten Seiten verwenden, da der Benutzer das Backend nicht erreicht. Eine weitere Einschr√§nkung ist die Bereitstellung von Cookies durch das Backend.  Da nginx alle Header zwischenspeichert, m√ºssen wir die √úbermittlung von Cookies f√ºr zwischengespeicherte Seiten untersagen, um zu vermeiden, dass die Sitzung einer anderen Person im Cache gespeichert wird.  Die Anweisung proxy_ignore_headers hilft uns dabei.  Das Argument listet die Header auf, die im Backend ignoriert werden sollen. <br><br>  Ein Beispiel: <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">proxy_ignore_headers</span></span> <span class="hljs-string"><span class="hljs-string">"Set-Cookie"</span></span>;</code> </pre> <br>  Mit dieser Zeile ignorieren wir die Installation von Cookies vom Proxyserver, dh der Benutzer erh√§lt eine Antwort ohne den Header "Set-Cookies".  Dementsprechend wird alles, was das Backend versucht hat, in das Cookie zu schreiben, auf der Clientseite ignoriert, da es nicht einmal wei√ü, dass etwas daf√ºr bestimmt war.  Diese Cookie-Einschr√§nkung sollte bei der Entwicklung einer Anwendung ber√ºcksichtigt werden.  Um beispielsweise eine Autorisierung anzufordern, k√∂nnen Sie die Header-Z√ºndung deaktivieren, damit der Benutzer ein Sitzungscookie erh√§lt. <br><br>  Sie sollten auch die Sitzungslebensdauer ber√ºcksichtigen. Sie kann im Parameter " <i>session.gc_maxlifetime</i> " der Konfiguration " <i>php.ini</i> " angezeigt werden.  Stellen Sie sich vor, der Benutzer hat sich auf der Website angemeldet und den Newsfeed angezeigt. Alle Daten befinden sich bereits im Nginx-Cache.  Nach einiger Zeit bemerkt der Benutzer, dass seine Autorisierung verschwunden ist und er den Autorisierungsprozess erneut durchlaufen muss, obwohl er die ganze Zeit auf der Website war und die Nachrichten sah.  Dies geschah, weil nginx bei allen Anfragen das Ergebnis aus dem Cache zur√ºckgab, ohne eine Anfrage an das Backend zu senden.  Daher entschied das Backend, dass der Benutzer inaktiv war, und l√∂schte nach einer in ‚Äû <i>session.gc_maxlifetime</i> ‚Äú angegebenen Zeit die Sitzungsdatei. <br><br>  Um dies zu verhindern, k√∂nnen wir Backend-Anfragen emulieren.  Senden Sie beispielsweise √ºber Ajax eine Anfrage, die garantiert an das Backend weitergeleitet wird.  Um den Nginx-Cache an das Backend zu √ºbergeben, senden Sie einfach eine POST-Anfrage. Sie k√∂nnen auch die Regel aus der Direktive "proxy_cache_bypass" verwenden oder einfach den Cache f√ºr diese Seite deaktivieren.  Die Anfrage muss nichts zur√ºckgeben, es kann sich um eine Datei mit einer einzelnen Zeile handeln, die die Sitzung startet.  Der Zweck einer solchen Anforderung besteht darin, die Lebensdauer der Sitzung zu verl√§ngern, w√§hrend sich der Benutzer auf der Site befindet, und nginx gibt die zwischengespeicherten Daten gewissenhaft an alle seine Anforderungen weiter. <br><br>  <b>Cache Flush Management</b> <br><br>  Zuerst m√ºssen Sie die Anforderungen bestimmen, welches Ziel wir erreichen wollen.  Nehmen wir an, unsere Website enth√§lt einen Abschnitt mit einer Textsendung √ºber beliebte Sportveranstaltungen.  Wenn das Laden der Seite aus dem Cache erfolgt, kommen alle neuen Nachrichten in Sockets.  Damit der Benutzer beim ersten Start aktuelle Nachrichten zum aktuellen Zeitpunkt und nicht vor 15 Minuten sehen kann, muss der Nginx-Cache jederzeit unabh√§ngig gel√∂scht werden k√∂nnen.  Gleichzeitig befindet sich nginx m√∂glicherweise nicht auf demselben Computer wie die Anwendung.  Eine der Voraussetzungen f√ºr ein Zur√ºcksetzen ist auch die M√∂glichkeit, den Cache √ºber mehrere Seiten gleichzeitig zu l√∂schen. <br><br>  Bevor Sie mit dem Schreiben Ihrer L√∂sung beginnen, schauen wir uns an, was nginx sofort bietet.  Um den Cache zur√ºckzusetzen, verf√ºgt nginx √ºber eine spezielle Anweisung namens "proxy_cache_purge", die die Bedingung f√ºr das Zur√ºcksetzen des Caches aufzeichnet.  Die Bedingung ist eigentlich eine normale Zeile, die, wenn sie nicht leer und nicht "0" ist, den Cache durch den √ºbergebenen Schl√ºssel l√∂scht.  Betrachten Sie ein kleines Beispiel. <br><br><pre> <code class="hljs perl">proxy_cache_path /data/nginx/cache keys_zone=cache_zone:<span class="hljs-number"><span class="hljs-number">10</span></span><span class="hljs-keyword"><span class="hljs-keyword">m</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">map</span></span> $request_method $purge_method { PURGE <span class="hljs-number"><span class="hljs-number">1</span></span>; default <span class="hljs-number"><span class="hljs-number">0</span></span>; } server { ... location / { proxy_pass http:<span class="hljs-regexp"><span class="hljs-regexp">//backend</span></span>; proxy_cache cache_zone; proxy_cache_key $uri; proxy_cache_purge $purge_method; } }</code> </pre><br>  <i>Ein Beispiel stammt von der offiziellen Nginx-Website.</i> <br><br>  Die Variable $ purge_method ist f√ºr das Leeren des Caches verantwortlich. Dies ist eine Bedingung f√ºr die Direktive proxy_cache_purge und wird standardm√§√üig auf 0 gesetzt.  Dies bedeutet, dass nginx im ‚Äûnormalen‚Äú Modus arbeitet (es speichert Antworten vom Backend).  Wenn Sie jedoch die Anforderungsmethode in "PURGE" √§ndern, wird der Cache-Eintrag mit dem entsprechenden Caching-Schl√ºssel gel√∂scht, anstatt die Anforderung f√ºr das Backend durch Speichern der Antwort zu ersetzen.  Es ist auch m√∂glich, eine L√∂schmaske anzugeben, indem am Ende des Cache-Schl√ºssels ein "*" angegeben wird.  Daher m√ºssen wir den Speicherort des Caches auf der Festplatte und das Prinzip der Schl√ºsselbildung nicht kennen. Nginx √ºbernimmt diese Verantwortung.  Dieser Ansatz hat aber auch Nachteile. <br><br><ul><li>  Die Direktive proxy_cache_purge ist als Teil eines kommerziellen Abonnements verf√ºgbar. </li><li>  Es ist nur m√∂glich, den Cache punktweise oder mithilfe der Maske des Formulars {Cache-Schl√ºssel} "*" zu l√∂schen. </li></ul><br>  Da die Adressen zwischengespeicherter Seiten ohne gemeinsame Teile v√∂llig unterschiedlich sein k√∂nnen, ist der Ansatz mit der Maske "*" und der Direktive "proxy_cache_purge" f√ºr uns nicht geeignet.  Es bleibt, sich an eine kleine Theorie zu erinnern und Ihre Lieblingsidee zu entdecken. <br><br>  Wir wissen, dass der Nginx-Cache eine regul√§re Datei auf dem Server ist.  Wir haben das Verzeichnis zum Speichern von Cache-Dateien unabh√§ngig in der Direktive "proxy_cache_path" angegeben und sogar die Logik zum Bilden des Pfads zur Datei aus diesem Verzeichnis mithilfe von "Ebenen" angegeben.  Das einzige, was uns fehlt, ist die korrekte Bildung des Caching-Schl√ºssels.  Wir k√∂nnen es aber auch in der Direktive "proxy_cache_key" sehen.  Jetzt m√ºssen wir nur noch: <br><br><ul><li>  Bilden Sie den vollst√§ndigen Pfad zur Seite, genau wie in der Anweisung proxy_cache_key angegeben. </li><li>  codiere den resultierenden String in md5; </li><li>  Erstellen Sie verschachtelte Verzeichnisse mit der Regel aus dem Parameter "Ebenen". </li><li>  Und jetzt haben wir bereits den vollst√§ndigen Pfad zur Cache-Datei auf dem Server.  Jetzt m√ºssen wir nur noch diese Datei l√∂schen.  Aus dem Einf√ºhrungsteil wissen wir, dass sich nginx m√∂glicherweise nicht auf dem Anwendungscomputer befindet. Daher m√ºssen Sie es erm√∂glichen, mehrere Adressen gleichzeitig zu l√∂schen.  Wieder beschreiben wir den Algorithmus: </li><li>  Die generierten Pfade zu den Cache-Dateien werden in die Datei geschrieben. </li><li>  Schreiben wir ein einfaches Bash-Skript, das wir mit der Anwendung auf den Computer stellen.  Seine Aufgabe wird es sein, √ºber ssh eine Verbindung zu dem Server herzustellen, auf dem Nginx zwischengespeichert wird, und alle in der generierten Datei angegebenen Cache-Dateien aus Schritt 1 zu l√∂schen. </li></ul><br>  Wir gehen von der Theorie zur Praxis √ºber und schreiben ein kleines Beispiel, das unseren Arbeitsalgorithmus veranschaulicht. <br><br>  Schritt 1. Generieren einer Datei mit Pfaden zum Cache. <br><br><pre> <code class="hljs powershell"><span class="hljs-variable"><span class="hljs-variable">$urls</span></span> = [ <span class="hljs-string"><span class="hljs-string">'httpGETdomain.ru/news/111/1:2'</span></span>, <span class="hljs-string"><span class="hljs-string">'httpGETdomain.ru/news/112/3:4'</span></span>, ]; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_nginx_cache_path</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url)</span></span></span></span> { <span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span> = md5(<span class="hljs-variable"><span class="hljs-variable">$url</span></span>); <span class="hljs-variable"><span class="hljs-variable">$firstDir</span></span> = substr(<span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span>, <span class="hljs-literal"><span class="hljs-literal">-1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-variable"><span class="hljs-variable">$secondDir</span></span> = substr(<span class="hljs-variable"><span class="hljs-variable">$nginxHash</span></span>, <span class="hljs-literal"><span class="hljs-literal">-3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"/var/lib/nginx/proxy_cache/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$firstDir</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$secondDir</span></span></span><span class="hljs-string">/</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$nginxHash</span></span></span><span class="hljs-string">"</span></span>; } //        tmp <span class="hljs-variable"><span class="hljs-variable">$filePath</span></span> = tempnam(<span class="hljs-string"><span class="hljs-string">'tmp'</span></span>, <span class="hljs-string"><span class="hljs-string">'nginx_cache_'</span></span>); //      <span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span> = fopen(<span class="hljs-variable"><span class="hljs-variable">$filePath</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-variable"><span class="hljs-variable">$urls</span></span> as <span class="hljs-variable"><span class="hljs-variable">$url</span></span>) { //      <span class="hljs-variable"><span class="hljs-variable">$cachePath</span></span> = to_nginx_cache_path(<span class="hljs-variable"><span class="hljs-variable">$url</span></span>); //       fwrite(<span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span>, <span class="hljs-variable"><span class="hljs-variable">$cachePath</span></span> . PHP_EOL); } //     fclose(<span class="hljs-variable"><span class="hljs-variable">$fileStream</span></span>); //  bash       exec(<span class="hljs-string"><span class="hljs-string">"/usr/local/bin/cache_remover </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$filePath</span></span></span><span class="hljs-string">"</span></span>);</code> </pre><br>  Bitte beachten Sie, dass die Variable $ urls die URL der zwischengespeicherten Seiten enth√§lt, die bereits das in der nginx-Konfiguration angegebene Format proxy_cache_key hat.  Die URL dient als Tag f√ºr die auf der Seite angezeigten Objekte.  Sie k√∂nnen beispielsweise eine regul√§re Tabelle in der Datenbank erstellen, in der jede Entit√§t einer bestimmten Seite zugeordnet wird, auf der sie angezeigt wird.  Wenn wir dann Daten √§ndern, k√∂nnen wir eine Auswahl in der Tabelle treffen und den Cache aller ben√∂tigten Seiten l√∂schen. <br><br>  Schritt 2. Stellen Sie eine Verbindung zum Cache-Server her und l√∂schen Sie die Cache-Dateien. <br><br><pre> <code class="hljs smalltalk">#      ,      <span class="hljs-type"><span class="hljs-type">FILE_LIST</span></span>=`cat <span class="hljs-string"><span class="hljs-string">$1</span></span> | tr <span class="hljs-comment"><span class="hljs-comment">"\n"</span></span> <span class="hljs-comment"><span class="hljs-comment">" "</span></span>` #   ssh  <span class="hljs-type"><span class="hljs-type">SSH</span></span>=`which ssh` <span class="hljs-type"><span class="hljs-type">USER</span></span>=<span class="hljs-comment"><span class="hljs-comment">"root"</span></span> #         nginx <span class="hljs-type"><span class="hljs-type">HOST</span></span>=<span class="hljs-comment"><span class="hljs-comment">"10.10.1.0"</span></span> #   <span class="hljs-type"><span class="hljs-type">KEY</span></span>=<span class="hljs-comment"><span class="hljs-comment">"/var/keys/id_rsa"</span></span> # <span class="hljs-type"><span class="hljs-type">SSH</span></span> ,          <span class="hljs-string"><span class="hljs-string">$S</span></span>SH -i <span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">KEY</span></span>} <span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">USER</span></span>}@<span class="hljs-string"><span class="hljs-string">${</span></span><span class="hljs-type"><span class="hljs-type">HOST</span></span>} <span class="hljs-comment"><span class="hljs-comment">"rm -f ${FILE_LIST}"</span></span> #       rm -rf rm -f <span class="hljs-string"><span class="hljs-string">$1</span></span> #  </code> </pre><br>  Die obigen Beispiele dienen nur zur Orientierung. Verwenden Sie sie nicht in der Produktion.  In den Beispielen werden die √úberpr√ºfungen von Eingabeparametern und Befehlsbeschr√§nkungen weggelassen.  Eines der Probleme, auf die Sie m√∂glicherweise sto√üen, besteht darin, die L√§nge des Arguments auf den Befehl rm zu beschr√§nken.  Beim Testen in einer Entwicklungsumgebung auf kleinen Volumes kann dies leicht √ºbersehen werden, und in der Produktion wird der Fehler "rm: Argumentliste zu lang" angezeigt. <br><br><h3>  Benutzerdefiniertes Block-Caching </h3><br>  Fassen wir zusammen, was wir geschafft haben: <br><br><ul><li>  reduzierte die Belastung des Backends; </li><li>  Erfahren Sie, wie Sie das Caching verwalten </li><li>  habe gelernt, den Cache jederzeit zu leeren. </li></ul><br>  Aber nicht alles ist so gut, wie es auf den ersten Blick scheinen mag.  Nun, wahrscheinlich, wenn nicht jede erste, dann hat genau jede zweite Site eine Registrierungs- / Autorisierungsfunktion, nach deren Durchlauf wir den Benutzernamen irgendwo in der Kopfzeile anzeigen m√∂chten.  Der Block mit dem Namen ist eindeutig und sollte den Benutzernamen anzeigen, unter dem wir autorisiert sind.  Da nginx die Antwort vom Backend speichert und es sich bei der Seite um den HTML-Inhalt der Seite handelt, wird der Block mit den pers√∂nlichen Daten ebenfalls zwischengespeichert.  Alle Besucher der Site sehen den Namen des ersten Benutzers, der f√ºr einen Satz Cache an das Backend √ºbergeben wurde. <br>  Daher sollte das Backend keine Bl√∂cke angeben, in denen sich pers√∂nliche Informationen befinden, damit diese Informationen nicht unter den Nginx-Cache fallen. <br><br>  Es ist notwendig, ein alternatives Laden solcher Teile der Seite in Betracht zu ziehen.  Wie immer kann dies auf viele Arten erfolgen, z. B. nach dem Laden der Seite, Senden einer Ajax-Anfrage und Anzeigen des Loaders anstelle von pers√∂nlichem Inhalt.  Eine andere M√∂glichkeit, die wir heute betrachten werden, ist die Verwendung von ssi-Tags.  Lassen Sie uns zuerst verstehen, was SSI ist und wie wir es dann in Verbindung mit dem Nginx-Cache verwenden k√∂nnen. <br><br><h3>  Was ist SSI und wie funktioniert es? </h3><br>  SSI (Server-Side Includes, Server-Side Inclusions) ist eine Reihe von Befehlen, die in eine HTML-Seite eingebettet sind und dem Server mitteilen, was zu tun ist. <br><br>  Hier ist eine Liste solcher Befehle (Anweisungen): <br><br>  ‚Ä¢ if / elif / else / endif - Der Verzweigungsoperator; <br>  ‚Ä¢ echo - Zeigt die Werte von Variablen an. <br>  ‚Ä¢ include - Erm√∂glicht das Einf√ºgen des Inhalts einer anderen Datei in das Dokument. <br>  Nur die letzte Richtlinie wird diskutiert.  Die include-Direktive hat zwei Parameter: <br>  ‚Ä¢ Datei - Gibt den Pfad zur Datei auf dem Server an.  In Bezug auf das aktuelle Verzeichnis; <br>  ‚Ä¢ virtuell - Gibt den virtuellen Pfad zum Dokument auf dem Server an. <br><br>  Wir interessieren uns f√ºr den Parameter ‚Äûvirtuell‚Äú, da die Angabe des vollst√§ndigen Pfads zur Datei auf dem Server nicht immer bequem ist oder bei einer verteilten Architektur die Datei auf dem Server einfach nicht vorhanden ist.  Beispielanweisung: <br><br><pre> <code class="hljs xml"><span class="hljs-comment"><span class="hljs-comment">&lt;!--#include virtual="/user/personal_news/"--&gt;</span></span></code> </pre> <br>  Damit nginx mit der Verarbeitung von SSI-Einf√ºgungen beginnen kann, m√ºssen Sie den Speicherort wie folgt √§ndern: <br><br><pre> <code class="hljs cs">location / { ssi <span class="hljs-keyword"><span class="hljs-keyword">on</span></span>; ... }</code> </pre><br>  Jetzt k√∂nnen alle vom Standort "/" verarbeiteten Anforderungen SSI-Einf√ºgungen ausf√ºhren. <br><br>  Wie wird unsere Anfrage dieses ganze Schema durchlaufen? <br><br><ul><li>  der Client fordert die Seite an; </li><li>  Nginx √ºbertr√§gt die Anfrage f√ºr das Backend. </li><li>  Das Backend enth√§lt die Seite mit SSI-Einf√ºgungen. </li><li>  Das Ergebnis wird im Cache gespeichert. </li><li>  Nginx "fragt" nach den fehlenden Bl√∂cken; </li><li>  Die resultierende Seite wird an den Client gesendet. </li></ul><br>  Wie Sie den Schritten entnehmen k√∂nnen, gelangen ssi-Konstrukte in den Nginx-Cache, wodurch pers√∂nliche Bl√∂cke nicht zwischengespeichert werden k√∂nnen, und dem Client wird eine vorgefertigte HTML-Seite mit allen Einf√ºgungen gesendet.  Hier funktioniert unser Laden, nginx fordert unabh√§ngig die fehlenden Seitenbl√∂cke an.  Aber wie jede andere L√∂sung hat auch dieser Ansatz Vor- und Nachteile.  Stellen Sie sich vor, es gibt mehrere Bl√∂cke auf der Seite, die je nach Benutzer unterschiedlich angezeigt werden sollten. Dann wird jeder dieser Bl√∂cke durch eine SSI-Einf√ºgung ersetzt.  Wie erwartet fordert Nginx jeden solchen Block vom Backend an, dh eine Anfrage des Benutzers generiert sofort mehrere Anfragen f√ºr das Backend, die ich √ºberhaupt nicht m√∂chte. <br><br><h3>  Dauerhafte Backend-Anfragen √ºber ssi loswerden </h3><br>  Um dieses Problem zu l√∂sen, hilft uns das Nginx-Modul ‚Äûngx_http_memcached_module‚Äú.  Das Modul erm√∂glicht den Empfang von Werten vom zwischengespeicherten Server.  Das Schreiben durch das Modul funktioniert nicht, der Anwendungsserver sollte sich darum k√ºmmern.  Betrachten Sie ein kleines Beispiel f√ºr die Konfiguration von nginx in Verbindung mit einem Modul: <br><br><pre> <code class="hljs nginx"><span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> /page { <span class="hljs-attribute"><span class="hljs-attribute">set</span></span> <span class="hljs-variable"><span class="hljs-variable">$memcached_key</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$uri</span></span></span><span class="hljs-string">"</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1:11211</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">error_page</span></span> <span class="hljs-number"><span class="hljs-number">404</span></span> <span class="hljs-number"><span class="hljs-number">502</span></span> <span class="hljs-number"><span class="hljs-number">504</span></span> = <span class="hljs-variable"><span class="hljs-variable">@fallback</span></span>; } <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> <span class="hljs-variable"><span class="hljs-variable">@fallback</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> http://backend; } }</code> </pre><br>  In der Variablen $ memcache_key haben wir den Schl√ºssel angegeben, mit dem nginx versucht, Daten aus dem Memcache abzurufen.  Die Parameter f√ºr die Verbindung zum Memcache-Server werden in der Anweisung memcached_pass festgelegt.  Die Verbindung kann auf verschiedene Arten angegeben werden: <br><br>  ‚Ä¢ Domainname; <br><br><pre> <code class="hljs css"><span class="hljs-selector-tag"><span class="hljs-selector-tag">memcached_pass</span></span> <span class="hljs-selector-tag"><span class="hljs-selector-tag">cache</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.domain</span></span><span class="hljs-selector-class"><span class="hljs-selector-class">.ru</span></span>;</code> </pre> <br>  ‚Ä¢ IP-Adresse und Port; <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> localhost:<span class="hljs-number"><span class="hljs-number">11211</span></span>;</code> </pre> <br>  ‚Ä¢ Unix-Socket; <br><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">memcached_pass</span></span> unix:/tmp/memcached.socket;</code> </pre> <br>  ‚Ä¢ vorgelagerte Richtlinie. <br><br><pre> <code class="hljs axapta">upstream cachestream { hash $request_uri consistent; <span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">10.10</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>:<span class="hljs-number"><span class="hljs-number">11211</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">10.10</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span>:<span class="hljs-number"><span class="hljs-number">11211</span></span>; } location / { ... memcached_pass cachestream; ... }</code> </pre><br>  Wenn es nginx gelungen ist, eine Antwort vom Cache-Server zu erhalten, gibt sie diese an den Client weiter.  Befinden sich keine Daten im Cache, wird die Anfrage √ºber "@fallback" an das Backend gesendet.  Diese kleine Einrichtung des zwischengespeicherten Moduls unter nginx hilft uns, die Anzahl der √ºbergebenen Anforderungen f√ºr das Backend von SSI-Einf√ºgungen zu reduzieren. <br><br>  Wir hoffen, dass dieser Artikel hilfreich war und wir eine der M√∂glichkeiten zur Optimierung der Serverauslastung aufzeigen, die Grundprinzipien f√ºr das Einrichten des Nginx-Caching ber√ºcksichtigen und die Probleme schlie√üen konnten, die bei der Verwendung auftreten. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428127/">https://habr.com/ru/post/de428127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428117/index.html">Kostenlose Tensorprozessoren von Google in der Colaboratory Cloud</a></li>
<li><a href="../de428119/index.html">"Klassenfeld-Vorschlag" oder "Was ist beim tc39-Commit schief gelaufen"</a></li>
<li><a href="../de428121/index.html">Stan Drapkin. Hochrangige Kryptografiefallen in .NET</a></li>
<li><a href="../de428123/index.html">Sicherheitswoche 41: Gute Nachrichten</a></li>
<li><a href="../de428125/index.html">Wer sind Produktanalysen und warum werden sie in einem Team ben√∂tigt?</a></li>
<li><a href="../de428129/index.html">Einfache Fuzzy-Logik ‚Äûf√ºr das, was f√ºr ein Gasturbinentriebwerk war‚Äú</a></li>
<li><a href="../de428131/index.html">Die ganze Wahrheit √ºber RTOS. Artikel Nr. 17. Ereignisflag-Gruppen: Einf√ºhrung und Basisdienste</a></li>
<li><a href="../de428133/index.html">Hasura. Hochleistungs-GraphQL-zu-SQL-Server-Architektur</a></li>
<li><a href="../de428135/index.html">So konfigurieren oder deaktivieren Sie Flusen im integrierten Code-Editor</a></li>
<li><a href="../de428137/index.html">Olympiade, Ideenwettbewerb, Vortr√§ge √ºber IT-Projektmanagement und Filmvorf√ºhrungen: 10 bevorstehende Veranstaltungen an der ITMO University</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
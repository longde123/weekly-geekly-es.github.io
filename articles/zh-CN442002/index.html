<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸŠ ğŸ˜¸ ğŸ³ å¼•å…¥ç¥ç»ODE ğŸ§ğŸ¼ ğŸ´ ğŸ³</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ 
 å¾®åˆ†æ–¹ç¨‹æè¿°äº†å¾ˆå¤§ä¸€éƒ¨åˆ†è¿‡ç¨‹ï¼Œè¿™å¯èƒ½æ˜¯ç‰©ç†ç³»ç»Ÿéšæ—¶é—´çš„æ¼”å˜ï¼Œæ‚£è€…çš„åŒ»ç–—çŠ¶å†µï¼Œè‚¡ç¥¨å¸‚åœºçš„åŸºæœ¬ç‰¹å¾ç­‰ã€‚ ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œè§‚å¯Ÿåªæ˜¯çŠ¶æ€ä¸æ–­å˜åŒ–çš„æŸç§è¡¨ç°ï¼Œæœ‰å…³è¿™äº›è¿‡ç¨‹çš„æ•°æ®æœ¬è´¨ä¸Šæ˜¯ä¸€è‡´ä¸”è¿ç»­çš„ã€‚ 

 è¿˜æœ‰å¦ä¸€ç§ä¸²è¡Œæ•°æ®ç±»å‹ï¼Œå®ƒæ˜¯ç¦»æ•£æ•°æ®ï¼Œä¾‹å¦‚NLPä»»åŠ¡æ•°æ®ã€‚ æ­¤ç±»æ•°æ®ä¸­çš„çŠ¶æ€ç¦»æ•£åœ°å˜...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>å¼•å…¥ç¥ç»ODE</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/442002/"><h1> ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ </h1><br> å¾®åˆ†æ–¹ç¨‹æè¿°äº†å¾ˆå¤§ä¸€éƒ¨åˆ†è¿‡ç¨‹ï¼Œè¿™å¯èƒ½æ˜¯ç‰©ç†ç³»ç»Ÿéšæ—¶é—´çš„æ¼”å˜ï¼Œæ‚£è€…çš„åŒ»ç–—çŠ¶å†µï¼Œè‚¡ç¥¨å¸‚åœºçš„åŸºæœ¬ç‰¹å¾ç­‰ã€‚ ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œè§‚å¯Ÿåªæ˜¯çŠ¶æ€ä¸æ–­å˜åŒ–çš„æŸç§è¡¨ç°ï¼Œæœ‰å…³è¿™äº›è¿‡ç¨‹çš„æ•°æ®æœ¬è´¨ä¸Šæ˜¯ä¸€è‡´ä¸”è¿ç»­çš„ã€‚ <br><br> è¿˜æœ‰å¦ä¸€ç§ä¸²è¡Œæ•°æ®ç±»å‹ï¼Œå®ƒæ˜¯ç¦»æ•£æ•°æ®ï¼Œä¾‹å¦‚NLPä»»åŠ¡æ•°æ®ã€‚ æ­¤ç±»æ•°æ®ä¸­çš„çŠ¶æ€ç¦»æ•£åœ°å˜åŒ–ï¼šä»ä¸€ä¸ªå­—ç¬¦æˆ–å•è¯åˆ°å¦ä¸€å­—ç¬¦æˆ–å•è¯ã€‚ <br><br> ç°åœ¨ï¼Œè¿™ä¸¤ç§ç±»å‹çš„ä¸²è¡Œæ•°æ®é€šå¸¸éƒ½ç”±é€’å½’ç½‘ç»œå¤„ç†ï¼Œå°½ç®¡å®ƒä»¬æœ¬è´¨ä¸Šä¸åŒå¹¶ä¸”ä¼¼ä¹éœ€è¦ä¸åŒçš„æ–¹æ³•ã€‚ <br><br> ä¸Šä¸€å±Š<em>NIPSä¼šè®®ä¸Š</em>å‘è¡¨äº†ä¸€ç¯‡éå¸¸æœ‰è¶£çš„æ–‡ç« ï¼Œå¯ä»¥å¸®åŠ©è§£å†³æ­¤é—®é¢˜ã€‚ ä½œè€…æå‡ºäº†ä¸€ç§ç§°ä¸º<strong>ç¥ç»ODEçš„æ–¹æ³•</strong> ã€‚ <br><br> åœ¨è¿™é‡Œï¼Œæˆ‘è¯•å›¾é‡ç°å’Œæ€»ç»“æœ¬æ–‡çš„ç»“æœï¼Œä»¥ä¾¿ä½¿å¥¹çš„æƒ³æ³•æ›´å®¹æ˜“ç†è§£ã€‚ åœ¨æˆ‘çœ‹æ¥ï¼Œè¿™ç§æ–°æ¶æ„å¾ˆå¯èƒ½ä¼šåœ¨æ•°æ®ç§‘å­¦å®¶çš„æ ‡å‡†å·¥å…·ä¸­ä»¥åŠå·ç§¯å’Œå¾ªç¯ç½‘ç»œä¸­æ‰¾åˆ°ä¸€å¸­ä¹‹åœ°ã€‚ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7e/65/hf/7e65hfxs1amdqyy_uy6emdwulkg.png"></div><br><a name="habracut"></a><br><i></i><p>  <em>å›¾</em> 1ï¼šè¿ç»­æ¢¯åº¦<em>åå‘ä¼ æ’­</em>éœ€è¦åŠæ—¶è§£<em>ç®—å‡º</em>æ‰©å±•çš„å¾®åˆ†æ–¹ç¨‹ã€‚ <br><br> ç®­å¤´è¡¨ç¤ºé€šè¿‡è§‚æµ‹å€¼çš„æ¢¯åº¦æ¥è°ƒæ•´å‘åä¼ æ’­çš„æ¢¯åº¦ã€‚ <br><br> åŸå§‹æ–‡ç« ä¸­çš„æ’å›¾ã€‚ </p><br><h2> é—®é¢˜é™ˆè¿° </h2><br> å‡è®¾æœ‰ä¸€ä¸ªè¿‡ç¨‹éµå¾ªæŸäº›æœªçŸ¥çš„ODEï¼Œå¹¶ä¸”æ²¿è¯¥è¿‡ç¨‹çš„è½¨è¿¹å­˜åœ¨å¤šä¸ªï¼ˆå˜ˆæ‚çš„ï¼‰è§‚å¯Ÿç»“æœ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/438/dde/8ca/438dde8cabcfd6a826ed0257752e6499.svg" alt="\ frac {dz} {dt} = fï¼ˆzï¼ˆtï¼‰ï¼Œtï¼‰\; ï¼ˆ1ï¼‰"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/190/072/e64/190072e645d65dc29d6160aaf0dde065.svg" alt="\ {ï¼ˆz_0ï¼Œt_0ï¼‰ï¼Œï¼ˆz_1ï¼Œt_1ï¼‰ï¼Œ...ï¼Œï¼ˆz_Mï¼Œt_Mï¼‰\}-\æ–‡å­—{observations}"></div><br> å¦‚ä½•æ‰¾åˆ°ä¸€ä¸ªè¿‘ä¼¼å€¼ <img src="https://habrastorage.org/getpro/habr/post_images/287/bb8/c63/287bb8c637a8a70238be4ea690a0a8e1.svg" alt="\ widehat {f}ï¼ˆzï¼Œtï¼Œ\ thetaï¼‰"> æ‰¬å£°å™¨åŠŸèƒ½ <img src="https://habrastorage.org/getpro/habr/post_images/6ad/6ab/1fa/6ad6ab1fa56e2c8b6d987dc5c1f68004.svg" alt="fï¼ˆzï¼Œtï¼‰">  ï¼Ÿ <br><br> é¦–å…ˆï¼Œè€ƒè™‘ä¸€ä¸ªç®€å•çš„ä»»åŠ¡ï¼šåœ¨è½¨è¿¹çš„å¼€å§‹å’Œç»“å°¾åªæœ‰2ä¸ªè§‚æµ‹å€¼ï¼Œ <img src="https://habrastorage.org/getpro/habr/post_images/547/808/5c2/5478085c21b85393c8e9e0f78c2821b3.svg" alt="ï¼ˆz_0ï¼Œt_0ï¼‰ï¼Œï¼ˆz_1ï¼Œt_1ï¼‰">  ã€‚ <br><br> ç³»ç»Ÿæ¼”è¿›ä»çŠ¶æ€å¼€å§‹ <img src="https://habrastorage.org/getpro/habr/post_images/7e2/d13/d9a/7e2d13d9a9cc05a84422c3b63260dd83.svg" alt="z_0ï¼Œt_0"> å‡†æ—¶ <img src="https://habrastorage.org/getpro/habr/post_images/4fc/683/cd0/4fc683cd033494d093a0e2c6f021805b.svg" alt="t_1-t_0"> å¯ä»¥ä½¿ç”¨ODEç³»ç»Ÿçš„ä»»ä½•æ¼”åŒ–æ–¹æ³•ä½¿ç”¨ä¸€äº›å‚æ•°åŒ–åŠ¨åŠ›å­¦å‡½æ•°ã€‚ ç³»ç»Ÿå¤„äºæ–°çŠ¶æ€å <img src="https://habrastorage.org/getpro/habr/post_images/56d/8d1/11e/56d8d111e514029cf892aff24a82c768.svg" alt="\ hat {z_1}ï¼Œt_1">  ï¼Œä¸çŠ¶æ€è¿›è¡Œæ¯”è¾ƒ <img src="https://habrastorage.org/getpro/habr/post_images/f80/709/9a5/f807099a57f179abaa3ab5e70cee4c9c.svg" alt="z_1"> å¹¶é€šè¿‡æ›´æ”¹å‚æ•°å°†å®ƒä»¬ä¹‹é—´çš„å·®å¼‚æœ€å°åŒ– <img src="https://habrastorage.org/getpro/habr/post_images/2cb/bcb/347/2cbbcb347a44c276c1095ac5bb3f8242.svg" alt="\ theta"> åŠ¨åŠ›å­¦åŠŸèƒ½ã€‚ <br><br> æˆ–è€…ï¼Œæ›´æ­£å¼åœ°è¯´ï¼Œè€ƒè™‘æœ€å°åŒ–æŸå¤±å‡½æ•° <img src="https://habrastorage.org/getpro/habr/post_images/b03/557/43f/b0355743fe8383284ef53436870494da.svg" alt="Lï¼ˆ\å¸½å­{z_1}ï¼‰">  ï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/251/944/489/251944489756d64d40b61f0dc0d7cb0b.svg" alt="Lï¼ˆzï¼ˆt_1ï¼‰ï¼‰= L \å¤§ï¼ˆ\ int_ {t_0} ^ {t_1} fï¼ˆzï¼ˆtï¼‰ï¼Œtï¼Œ\ thetaï¼‰dt \ Bigï¼‰= L \å¤§ï¼ˆ\æ–‡æœ¬{ODESolve}ï¼ˆzï¼ˆ t_0ï¼‰ï¼Œfï¼Œt_0ï¼Œt_1ï¼Œ\ thetaï¼‰\ bigï¼‰\; ï¼ˆ2ï¼‰"></div><br> æœ€å°åŒ– <img src="https://habrastorage.org/getpro/habr/post_images/899/a67/551/899a675510d28419769a9b42281f0c65.svg" alt="å¤§å·">  ï¼Œæ‚¨éœ€è¦ä¸ºå…¶æ‰€æœ‰å‚æ•°è®¡ç®—æ¢¯åº¦ï¼š <img src="https://habrastorage.org/getpro/habr/post_images/194/e4f/6e5/194e4f6e59bbfefc52efebce3bb857a3.svg" alt="zï¼ˆt_0ï¼‰ï¼Œt_0ï¼Œt_1ï¼Œ\ theta">  ã€‚ ä¸ºæ­¤ï¼Œæ‚¨é¦–å…ˆéœ€è¦ç¡®å®šå¦‚ä½• <img src="https://habrastorage.org/getpro/habr/post_images/899/a67/551/899a675510d28419769a9b42281f0c65.svg" alt="å¤§å·"> å–å†³äºæ¯æ—¶æ¯åˆ»çš„çŠ¶æ€ <img src="https://habrastorage.org/getpro/habr/post_images/823/f33/fc8/823f33fc81685e76b1d88f48c68eea32.svg" alt="ï¼ˆz [tï¼‰ï¼‰">  ï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e79/64f/b7f/e7964fb7f074d4f9c16893b53a1562c6.svg" alt="aï¼ˆtï¼‰=-\ frac {\éƒ¨åˆ†L} {\éƒ¨åˆ†zï¼ˆtï¼‰} \; ï¼ˆ3ï¼‰"></div><br><img src="https://habrastorage.org/getpro/habr/post_images/2e3/af6/935/2e3af69359cb79517739f0ccf9a8bc3e.svg" alt="ä¸€ä¸ªï¼ˆtï¼‰"> ç§°ä¸º<em>ä¼´éš</em>çŠ¶æ€ï¼Œå…¶åŠ¨åŠ›å­¦ç”±å¦ä¸€ä¸ªå¾®åˆ†æ–¹ç¨‹ç»™å‡ºï¼Œå¯ä»¥å°†å…¶è§†ä¸ºå¤æ•°å‡½æ•°å¾®åˆ†ï¼ˆ <em>é“¾è§„åˆ™</em> ï¼‰çš„è¿ç»­æ¨¡æ‹Ÿï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/006/b66/5d5/006b665d51719470f25859e6271463dc.svg" alt="\ frac {d aï¼ˆtï¼‰} {d t} = -aï¼ˆtï¼‰\ frac {\éƒ¨åˆ†fï¼ˆzï¼ˆtï¼‰ï¼Œtï¼Œ\ thetaï¼‰} {\éƒ¨åˆ†z} \; ï¼ˆ4ï¼‰"></div><br> è¯¥å…¬å¼çš„è¾“å‡ºå¯ä»¥åœ¨åŸå§‹æ–‡ç« çš„é™„å½•ä¸­æ‰¾åˆ°ã€‚ <br><br>  <i>å°½ç®¡åŸå§‹æ–‡ç« åŒæ—¶ä½¿ç”¨è¡Œå’Œåˆ—è¡¨ç¤ºï¼Œä½†æœ¬æ–‡ä¸­çš„å‘é‡åº”è¢«è§†ä¸ºå°å†™å‘é‡ã€‚</i> <br><br> åŠæ—¶è§£å†³diffurï¼ˆ4ï¼‰ï¼Œæˆ‘ä»¬è·å¾—äº†å¯¹åˆå§‹çŠ¶æ€çš„ä¾èµ– <img src="https://habrastorage.org/getpro/habr/post_images/9ec/7ef/827/9ec7ef8276505d510f609b983c58fdc3.svg" alt="zï¼ˆt_0ï¼‰">  ï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/556/75a/7f0/55675a7f0c820f2a1da88e0802c97dc7.svg" alt="\ frac {\éƒ¨åˆ†L} {\éƒ¨åˆ†zï¼ˆt_0ï¼‰} = \ int_ {t_1} ^ {t_0} aï¼ˆtï¼‰\ frac {\éƒ¨åˆ†fï¼ˆzï¼ˆtï¼‰ï¼Œtï¼Œ\ thetaï¼‰} {\éƒ¨åˆ†z} dt \; ï¼ˆ5ï¼‰"></div><br> è®¡ç®—ç›¸å¯¹äºçš„æ¢¯åº¦ <img src="https://habrastorage.org/getpro/habr/post_images/2a3/102/4ea/2a31024ea1803c34a47496e24a53a1ef.svg" alt="Å¤"> å’Œ <img src="https://habrastorage.org/getpro/habr/post_images/2cb/bcb/347/2cbbcb347a44c276c1095ac5bb3f8242.svg" alt="\ theta">  ï¼Œæ‚¨å¯ä»¥ç®€å•åœ°å°†å…¶è§†ä¸ºçŠ¶æ€çš„ä¸€éƒ¨åˆ†ã€‚ è¿™ç§æƒ…å†µç§°ä¸º<em>å¢å¼º</em> ã€‚ æ­¤çŠ¶æ€çš„åŠ¨æ€æ˜¯ä»åŸå§‹åŠ¨æ€ä¸­è½»æ¾è·å¾—çš„ï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/161/f11/79c/161f1179cbb6dfe3c18057d8abd0f45b.svg" alt="\ frac {d} {dt} \å¼€å§‹{bmatrix} zâ€‹â€‹ \\ \ theta \\ t \ç»“æŸ{bmatrix}ï¼ˆtï¼‰= f _ {\ text {aug}}ï¼ˆ[zï¼Œ\ thetaï¼Œt]ï¼‰ï¼š= \å¼€å§‹{bmatrix} fï¼ˆ[zï¼Œ\ thetaï¼Œt]ï¼‰\\ 0 \\ 1 \ç»“æŸ{bmatrix} \; ï¼ˆ6ï¼‰"></div><br> ç„¶åå°†å…±è½­çŠ¶æ€æ‰©å±•ä¸ºè¯¥çŠ¶æ€ï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7dc/7d0/553/7dc7d055304addbb695d1f23a9e640e6.svg" alt="a _ {\ text {aug}}ï¼š= \å¼€å§‹{bmatrix} a \\ a _ {\ theta} \\ a_t \ end {bmatrix}ï¼Œa _ {\ theta}ï¼ˆtï¼‰ï¼š= \ frac {\éƒ¨åˆ†L} { \\ partial \ thetaï¼ˆtï¼‰}ï¼Œa_tï¼ˆtï¼‰ï¼š= \ frac {\éƒ¨åˆ†L} {\éƒ¨åˆ†tï¼ˆtï¼‰} \; ï¼ˆ7ï¼‰"></div><br> æ¸å˜å¢å¼ºåŠ¨åŠ›å­¦ï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/985/437/7a4/9854377a42cda72fa53bedb928a9d023.svg" alt="\ frac {\éƒ¨åˆ†f _ {\æ–‡æœ¬{aug}}} {\éƒ¨åˆ†[zï¼Œ\ thetaï¼Œt]} = \å¼€å§‹{bmatrix} \ frac {\éƒ¨åˆ†f} {\éƒ¨åˆ†z}ï¼†; \ frac {\éƒ¨åˆ†f} {\éƒ¨åˆ†\ theta}ï¼†; \ frac {\éƒ¨åˆ†f} {\éƒ¨åˆ†t} \\ 0ï¼†; 0ï¼†; 0 \\ 0ï¼†; 0ï¼†; 0 \ end {bmatrix} \; ï¼ˆ8ï¼‰"></div><br> æ ¹æ®å…¬å¼ï¼ˆ4ï¼‰å¾—å‡ºçš„å…±è½­å¢å¼ºæ€çš„å¾®åˆ†æ–¹ç¨‹ä¸ºï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bd3/b9f/7f3/bd3b9f7f3e6ec08881594346a8a3e4f3.svg" alt="\ frac {d a _ {\ text {aug}}} {dt} =-\å¼€å§‹{bmatrix} a \ frac {\éƒ¨åˆ†f} {\éƒ¨åˆ†z}ï¼†; a \ frac {\éƒ¨åˆ†f} {\éƒ¨åˆ†\ theta}ï¼†; a \ frac {\éƒ¨åˆ†f} {\éƒ¨åˆ†t} \ç»“æŸ{bmatrix} \; ï¼ˆ9ï¼‰"></div><br> åŠæ—¶è§£å†³æ­¤ODEä¼šäº§ç”Ÿï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5a0/01e/3d9/5a001e3d928ce08d05ff084353134d78.svg" alt="\ frac {\éƒ¨åˆ†L} {\éƒ¨åˆ†zï¼ˆt_0ï¼‰} = \ int_ {t_1} ^ {t_0} aï¼ˆtï¼‰\ frac {\éƒ¨åˆ†fï¼ˆzï¼ˆtï¼‰ï¼Œtï¼Œ\ thetaï¼‰} {\éƒ¨åˆ†z} dt \; ï¼ˆ10ï¼‰"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e09/ba3/cc6/e09ba3cc6674830a8847894c39020ec0.svg" alt="\ frac {\éƒ¨åˆ†L} {\éƒ¨åˆ†\ theta} = \ int_ {t_1} ^ {t_0} aï¼ˆtï¼‰\ frac {\éƒ¨åˆ†fï¼ˆzï¼ˆtï¼‰ï¼Œtï¼Œ\ thetaï¼‰} {\éƒ¨åˆ†\ theta } dt \; ï¼ˆ11ï¼‰"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/022/f84/715/022f84715f62b101017a6dcb591d5de3.svg" alt="\ frac {\éƒ¨åˆ†L} {\éƒ¨åˆ†t_0} = \ int_ {t_1} ^ {t_0} aï¼ˆtï¼‰\ frac {\éƒ¨åˆ†fï¼ˆzï¼ˆtï¼‰ï¼Œtï¼Œ\ thetaï¼‰} {\éƒ¨åˆ†t} dt \; ï¼ˆ12ï¼‰"></div><br> æ€ä¹ˆäº† <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0f9/b43/8a8/0f9b438a88408c879af759bcaf4d1d5e.svg" alt="\ frac {\éƒ¨åˆ†L} {\éƒ¨åˆ†t_1} =-aï¼ˆtï¼‰\ frac {\éƒ¨åˆ†fï¼ˆzï¼ˆtï¼‰ï¼Œtï¼Œ\ thetaï¼‰} {\éƒ¨åˆ†t} \; ï¼ˆ13ï¼‰"></div><br> åœ¨<em>ODESolve</em> ODE <em>è§£ç®—å™¨çš„</em>æ‰€æœ‰è¾“å…¥å‚æ•°ä¸­ç»™å‡ºæ¢¯åº¦ã€‚ <br><br> æ‰€æœ‰æ¢¯åº¦ï¼ˆ10ï¼‰ï¼Œï¼ˆ11ï¼‰ï¼Œï¼ˆ12ï¼‰ï¼Œï¼ˆ13ï¼‰å¯ä»¥åœ¨ä¸€ä¸ª<em>ODESolve</em>è°ƒç”¨ä¸­ä¸å…±è½­å¢å¼ºæ€ï¼ˆ9ï¼‰çš„åŠ¨åŠ›å­¦ä¸€èµ·è®¡ç®—ã€‚ <br><br><img src="https://habrastorage.org/webt/8k/pz/uk/8kpzukmizpmezmywov4b3zm29lc.png"><br>  <i>åŸå§‹æ–‡ç« ä¸­çš„æ’å›¾ã€‚</i> <br><br> ä¸Šé¢çš„ç®—æ³•æè¿°äº†è¿ç»­è§‚æµ‹çš„ODEè§£çš„æ¢¯åº¦çš„åå‘ä¼ æ’­ã€‚ <br><br> åœ¨ä¸€ä¸ªè½¨è¿¹ä¸Šè¿›è¡Œå¤šä¸ªè§‚æµ‹çš„æƒ…å†µä¸‹ï¼Œä¸€åˆ‡éƒ½ä»¥ç›¸åŒçš„æ–¹å¼è®¡ç®—ï¼Œä½†æ˜¯åœ¨è§‚æµ‹çš„æ—¶åˆ»ï¼Œå¿…é¡»ä½¿ç”¨å½“å‰è§‚æµ‹çš„æ¢¯åº¦æ¥è°ƒæ•´åˆ†å¸ƒæ¢¯åº¦çš„å€’æ•°ï¼Œ <em>å¦‚å›¾1</em>æ‰€ç¤ºã€‚ <br><br><h1> å®ä½œ </h1><br> ä¸‹é¢çš„ä»£ç æ˜¯æˆ‘å¯¹<strong>ç¥ç»ODEçš„</strong>å®ç°ã€‚ æˆ‘è¿™æ ·åšçº¯ç²¹æ˜¯ä¸ºäº†æ›´å¥½åœ°äº†è§£æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…ã€‚ ä½†æ˜¯ï¼Œå®ƒä¸æœ¬æ–‡ä½œè€…<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">èµ„æºåº“ä¸­</a>å®ç°çš„å†…å®¹éå¸¸æ¥è¿‘ã€‚ å®ƒåŒ…å«æ‚¨éœ€è¦åœ¨ä¸€ä¸ªåœ°æ–¹ç†è§£çš„æ‰€æœ‰ä»£ç ï¼Œå¹¶ä¸”æ³¨é‡Šä¹Ÿç•¥å¤šäº†ã€‚ å¯¹äºå®é™…åº”ç”¨å’Œå®éªŒï¼Œæœ€å¥½è¿˜æ˜¯ä½¿ç”¨åŸå§‹æ–‡ç« ä½œè€…çš„å®ç°ã€‚ <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> IPython.display <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> clear_output <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm_notebook <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mpl <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns sns.color_palette(<span class="hljs-string"><span class="hljs-string">"bright"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mpl <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.cm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tensor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functional <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> F <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.autograd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Variable use_cuda = torch.cuda.is_available()</code> </pre> <br> é¦–å…ˆï¼Œæ‚¨éœ€è¦å®ç°ODEç³»ç»Ÿæ¼”åŒ–çš„ä»»ä½•æ–¹æ³•ã€‚ ä¸ºç®€å•èµ·è§ï¼Œæ­¤å¤„å¯ä»¥ä½¿ç”¨Euleræ–¹æ³•ï¼Œå°½ç®¡ä»»ä½•æ˜¾å¼æˆ–éšå¼æ–¹æ³•éƒ½é€‚ç”¨ã€‚ <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ode_solve</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(z0, t0, t1, f)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""     -   """</span></span> h_max = <span class="hljs-number"><span class="hljs-number">0.05</span></span> n_steps = math.ceil((abs(t1 - t0)/h_max).max().item()) h = (t1 - t0)/n_steps t = t0 z = z0 <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i_step <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n_steps): z = z + h * f(z, t) t = t + h <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z</code> </pre><br> å®ƒè¿˜ç”¨ä¸€äº›æœ‰ç”¨çš„æ–¹æ³•æè¿°äº†å‚æ•°åŒ–åŠ¨åŠ›å­¦å‡½æ•°çš„è¶…ç±»ã€‚ <br><br> é¦–å…ˆï¼šæ‚¨éœ€è¦ä»¥å‘é‡çš„å½¢å¼è¿”å›å‡½æ•°æ‰€ä¾èµ–çš„æ‰€æœ‰å‚æ•°ã€‚ <br><br> å…¶æ¬¡ï¼šæœ‰å¿…è¦è®¡ç®—å¢å¼ºåŠ¨åŠ›ã€‚ è¿™ç§åŠ¨åŠ›å­¦å–å†³äºå‚æ•°åŒ–å‡½æ•°åœ¨å‚æ•°å’Œè¾“å…¥æ•°æ®æ–¹é¢çš„æ¢¯åº¦ã€‚ ä¸ºäº†ä¸å¿…ä¸ºæ¯ç§æ–°ä½“ç³»ç»“æ„ç”¨æ¯åªæ‰‹è®°å½•æ¸å˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<strong>torch.autograd.grad</strong>æ–¹æ³•ã€‚ <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward_with_grad</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, z, t, grad_outputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Compute f and a df/dz, a df/dp, a df/dt"""</span></span> batch_size = z.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] out = self.forward(z, t) a = grad_outputs adfdz, adfdt, *adfdp = torch.autograd.grad( (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a), allow_unused=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, retain_graph=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> ) <span class="hljs-comment"><span class="hljs-comment">#  grad       , #  expand   if adfdp is not None: adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0) adfdp = adfdp.expand(batch_size, -1) / batch_size if adfdt is not None: adfdt = adfdt.expand(batch_size, 1) / batch_size return out, adfdz, adfdt, adfdp def flatten_parameters(self): p_shapes = [] flat_parameters = [] for p in self.parameters(): p_shapes.append(p.size()) flat_parameters.append(p.flatten()) return torch.cat(flat_parameters)</span></span></code> </pre><br> ä¸‹é¢çš„ä»£ç æè¿°äº†<em>ç¥ç»ODE</em>çš„æ­£å‘å’Œåå‘ä¼ æ’­ã€‚ å¿…é¡»ä»¥<strong><em>torch.autograd.Function</em></strong>å‡½æ•°çš„å½¢å¼å°†æ­¤ä»£ç ä¸<strong><em>torch.nn.Module</em></strong>ä¸»ä»£ç åˆ†å¼€ï¼Œå› ä¸ºåœ¨åè€…ä¸­ï¼Œæ‚¨å¯ä»¥å®ç°ä»»æ„<strong><em>åå‘ä¼ æ’­</em></strong>æ–¹æ³•ï¼Œè¿™ä¸æ¨¡å—ä¸åŒã€‚ æ‰€ä»¥è¿™åªæ˜¯æ‹æ–ã€‚ <br><br> æ­¤åŠŸèƒ½æ˜¯æ•´ä¸ª<em>ç¥ç»ODE</em>æ–¹æ³•çš„åŸºç¡€ã€‚ <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ODEAdjoint</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.autograd.Function)</span></span></span><span class="hljs-class">:</span></span> @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ctx, z0, t, flat_parameters, func)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span> isinstance(func, ODEF) bs, *z_shape = z0.size() time_len = t.size(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): z = torch.zeros(time_len, bs, *z_shape).to(z0) z[<span class="hljs-number"><span class="hljs-number">0</span></span>] = z0 <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i_t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(time_len - <span class="hljs-number"><span class="hljs-number">1</span></span>): z0 = ode_solve(z0, t[i_t], t[i_t+<span class="hljs-number"><span class="hljs-number">1</span></span>], func) z[i_t+<span class="hljs-number"><span class="hljs-number">1</span></span>] = z0 ctx.func = func ctx.save_for_backward(t, z.clone(), flat_parameters) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">backward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ctx, dLdz)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" dLdz shape: time_len, batch_size, *z_shape """</span></span> func = ctx.func t, z, flat_parameters = ctx.saved_tensors time_len, bs, *z_shape = z.size() n_dim = np.prod(z_shape) n_params = flat_parameters.size(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment">#   , #       def augmented_dynamics(aug_z_i, t_i): """   -     t_i -   : bs, 1 aug_z_i -   : bs, n_dim*2 + n_params + 1 """ #     z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim] # Unflatten z and a z_i = z_i.view(bs, *z_shape) a = a.view(bs, *z_shape) with torch.set_grad_enabled(True): t_i = t_i.detach().requires_grad_(True) z_i = z_i.detach().requires_grad_(True) faug = func.forward_with_grad(z_i, t_i, grad_outputs=a) func_eval, adfdz, adfdt, adfdp = faug adfdz = adfdz if adfdz is not None else torch.zeros(bs, *z_shape) adfdp = adfdp if adfdp is not None else torch.zeros(bs, n_params) adfdt = adfdt if adfdt is not None else torch.zeros(bs, 1) adfdz = adfdz.to(z_i) adfdp = adfdp.to(z_i) adfdt = adfdt.to(z_i) # Flatten f and adfdz func_eval = func_eval.view(bs, n_dim) adfdz = adfdz.view(bs, n_dim) return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1) dLdz = dLdz.view(time_len, bs, n_dim) # flatten dLdz   with torch.no_grad(): ##      #    , #       adj_z = torch.zeros(bs, n_dim).to(dLdz) adj_p = torch.zeros(bs, n_params).to(dLdz) #    z  p,        adj_t = torch.zeros(time_len, bs, 1).to(dLdz) for i_t in range(time_len-1, 0, -1): z_i = z[i_t] t_i = t[i_t] f_i = func(z_i, t_i).view(bs, n_dim) #      dLdz_i = dLdz[i_t] dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0] #     adj_z += dLdz_i adj_t[i_t] = adj_t[i_t] - dLdt_i #      aug_z = torch.cat(( z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z) adj_t[i_t]), dim=-1 ) #  ()      aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics) #       adj_z[:] = aug_ans[:, n_dim:2*n_dim] adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params] adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:] del aug_z, aug_ans ##         #    dLdz_0 = dLdz[0] dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0] #  adj_z += dLdz_0 adj_t[0] = adj_t[0] - dLdt_0 return adj_z.view(bs, *z_shape), adj_t, adj_p, None</span></span></code> </pre><br> ç°åœ¨ä¸ºæ–¹ä¾¿èµ·è§ï¼Œå°†æ­¤å‡½æ•°åŒ…è£…åœ¨<strong>nn.Moduleä¸­</strong> ã€‚ <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">NeuralODE</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, func)</span></span></span><span class="hljs-function">:</span></span> super(NeuralODE, self).__init__() <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span> isinstance(func, ODEF) self.func = func <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, z0, t=Tensor</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">([</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">0.</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">, </span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1.</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">])</span></span></span></span><span class="hljs-function"><span class="hljs-params">, return_whole_sequence=False)</span></span></span><span class="hljs-function">:</span></span> t = t.to(z0) z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> return_whole_sequence: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z[<span class="hljs-number"><span class="hljs-number">-1</span></span>]</code> </pre><br><br><h1> ç”³è¯·ä¹¦ </h1><br><h2> æ¢å¤çœŸå®åŠ¨æ€åŠŸèƒ½ï¼ˆæ–¹æ³•éªŒè¯ï¼‰ </h2><br> ä½œä¸ºä¸€é¡¹åŸºæœ¬æµ‹è¯•ï¼Œç°åœ¨è®©æˆ‘ä»¬æ£€æŸ¥<strong>ç¥ç»ODE</strong>æ˜¯å¦å¯ä»¥ä½¿ç”¨è§‚æµ‹æ•°æ®æ¢å¤åŠ¨åŠ›å­¦çš„çœŸå®åŠŸèƒ½ã€‚ <br><br> ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆç¡®å®šODEçš„åŠ¨åŠ›å­¦å‡½æ•°ï¼Œæ ¹æ®å…¶æ¼”åŒ–è½¨è¿¹ï¼Œç„¶åå°è¯•ä»éšæœºå‚æ•°åŒ–çš„åŠ¨åŠ›å­¦å‡½æ•°ä¸­æ¢å¤å®ƒã€‚ <br><br> é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ£€æŸ¥çº¿æ€§ODEçš„æœ€ç®€å•æƒ…å†µã€‚ åŠ¨åŠ›å­¦çš„åŠŸèƒ½ä»…ä»…æ˜¯çŸ©é˜µçš„ä½œç”¨ã€‚ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/eb4/fdc/86a/eb4fdc86a1c5f56ab1b6e37e575e7c72.svg" alt="\ frac {dz} {dt} = \å¼€å§‹{bmatrix} -0.1ï¼†; -1.0 \\ 1.0ï¼†; -0.1 \ end {bmatrix} z"></div><br> è®­ç»ƒåçš„å‡½æ•°ç”±éšæœºçŸ©é˜µå‚æ•°åŒ–ã€‚ <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nj/q6/es/njq6eswuevh4rhx-8nhzyz-cq_k.gif"></div><br> æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€äº›æ›´å¤æ‚çš„åŠ¨æ€ï¼ˆæ²¡æœ‰gifï¼Œå› ä¸ºå­¦ä¹ è¿‡ç¨‹ä¸æ˜¯å¾ˆæ¼‚äº®ï¼šï¼‰ï¼‰ <br> è¿™é‡Œçš„å­¦ä¹ åŠŸèƒ½æ˜¯å…·æœ‰ä¸€ä¸ªéšè—å±‚çš„å®Œå…¨è¿æ¥çš„ç½‘ç»œã€‚ <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tr/4n/eb/tr4nebjdrs4pt4v5vlzleai8exe.png"></div><br><div class="spoiler">  <b class="spoiler_title">ä»£å·</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LinearODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(ODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, W)</span></span></span><span class="hljs-function">:</span></span> super(LinearODEF, self).__init__() self.lin = nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) self.lin.weight = nn.Parameter(W) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.lin(x)</code> </pre><br> åŠ¨åŠ›å­¦åŠŸèƒ½åªæ˜¯ä¸€ä¸ªçŸ©é˜µ <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SpiralFunctionExample</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(LinearODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> matrix = Tensor([[<span class="hljs-number"><span class="hljs-number">-0.1</span></span>, <span class="hljs-number"><span class="hljs-number">-1.</span></span>], [<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">-0.1</span></span>]]) super(SpiralFunctionExample, self).__init__(matrix)</code> </pre><br> éšæœºå‚æ•°åŒ–çŸ©é˜µ <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RandomLinearODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(LinearODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(RandomLinearODEF, self).__init__(torch.randn(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)/<span class="hljs-number"><span class="hljs-number">2.</span></span>)</code> </pre><br> åŠ¨åŠ›å­¦å¯å®ç°æ›´å¤æ‚çš„è½¨è¿¹ <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TestODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(ODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, A, B, x0)</span></span></span><span class="hljs-function">:</span></span> super(TestODEF, self).__init__() self.A = nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) self.A.weight = nn.Parameter(A) self.B = nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) self.B.weight = nn.Parameter(B) self.x0 = nn.Parameter(x0) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> xTx0 = torch.sum(x*self.x0, dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) dxdt = torch.sigmoid(xTx0) * self.A(x - self.x0) + torch.sigmoid(-xTx0) * self.B(x + self.x0) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> dxdt</code> </pre><br> å®Œå…¨è¿æ¥çš„ç½‘ç»œå½¢å¼çš„åŠ¨æ€å­¦ä¹  <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">NNODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(ODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, in_dim, hid_dim, time_invariant=False)</span></span></span><span class="hljs-function">:</span></span> super(NNODEF, self).__init__() self.time_invariant = time_invariant <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> time_invariant: self.lin1 = nn.Linear(in_dim, hid_dim) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: self.lin1 = nn.Linear(in_dim+<span class="hljs-number"><span class="hljs-number">1</span></span>, hid_dim) self.lin2 = nn.Linear(hid_dim, hid_dim) self.lin3 = nn.Linear(hid_dim, in_dim) self.elu = nn.ELU(inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> self.time_invariant: x = torch.cat((x, t), dim=<span class="hljs-number"><span class="hljs-number">-1</span></span>) h = self.elu(self.lin1(x)) h = self.elu(self.lin2(h)) out = self.lin3(h) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_np</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x.detach().cpu().numpy() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_trajectories</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(obs=None, times=None, trajs=None, save=None, figsize=</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">16</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">, </span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">8</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">)</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> plt.figure(figsize=figsize) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> obs <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> times <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: times = [<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>] * len(obs) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> o, t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(obs, times): o, t = to_np(o), to_np(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> b_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(o.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]): plt.scatter(o[:, b_i, <span class="hljs-number"><span class="hljs-number">0</span></span>], o[:, b_i, <span class="hljs-number"><span class="hljs-number">1</span></span>], c=t[:, b_i, <span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=cm.plasma) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> trajs <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> z <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> trajs: z = to_np(z) plt.plot(z[:, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>], z[:, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], lw=<span class="hljs-number"><span class="hljs-number">1.5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> save <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: plt.savefig(save) plt.show() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">conduct_experiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ode_true, ode_trained, n_steps, name, plot_freq=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Create data z0 = Variable(torch.Tensor([[0.6, 0.3]])) t_max = 6.29*5 n_points = 200 index_np = np.arange(0, n_points, 1, dtype=np.int) index_np = np.hstack([index_np[:, None]]) times_np = np.linspace(0, t_max, num=n_points) times_np = np.hstack([times_np[:, None]]) times = torch.from_numpy(times_np[:, :, None]).to(z0) obs = ode_true(z0, times, return_whole_sequence=True).detach() obs = obs + torch.randn_like(obs) * 0.01 # Get trajectory of random timespan min_delta_time = 1.0 max_delta_time = 5.0 max_points_num = 32 def create_batch(): t0 = np.random.uniform(0, t_max - max_delta_time) t1 = t0 + np.random.uniform(min_delta_time, max_delta_time) idx = sorted(np.random.permutation( index_np[(times_np &gt; t0) &amp; (times_np &lt; t1)] )[:max_points_num]) obs_ = obs[idx] ts_ = times[idx] return obs_, ts_ # Train Neural ODE optimizer = torch.optim.Adam(ode_trained.parameters(), lr=0.01) for i in range(n_steps): obs_, ts_ = create_batch() z_ = ode_trained(obs_[0], ts_, return_whole_sequence=True) loss = F.mse_loss(z_, obs_.detach()) optimizer.zero_grad() loss.backward(retain_graph=True) optimizer.step() if i % plot_freq == 0: z_p = ode_trained(z0, times, return_whole_sequence=True) plot_trajectories(obs=[obs], times=[times], trajs=[z_p], save=f"assets/imgs/{name}/{i}.png") clear_output(wait=True) ode_true = NeuralODE(SpiralFunctionExample()) ode_trained = NeuralODE(RandomLinearODEF()) conduct_experiment(ode_true, ode_trained, 500, "linear") func = TestODEF(Tensor([[-0.1, -0.5], [0.5, -0.1]]), Tensor([[0.2, 1.], [-1, 0.2]]), Tensor([[-1., 0.]])) ode_true = NeuralODE(func) func = NNODEF(2, 16, time_invariant=True) ode_trained = NeuralODE(func) conduct_experiment(ode_true, ode_trained, 3000, "comp", plot_freq=30)</span></span></code> </pre><br></div></div><br> å¦‚æ‚¨æ‰€è§ï¼Œ <em>Neural ODE</em>åœ¨è¿˜åŸåŠ¨åŠ›å­¦æ–¹é¢åšå¾—å¾ˆå¥½ã€‚ å³ï¼Œè¯¥æ¦‚å¿µä½œä¸ºæ•´ä½“èµ·ä½œç”¨ã€‚ <br> ç°åœ¨æ£€æŸ¥ä¸€ä¸ªç¨å¾®å¤æ‚çš„é—®é¢˜ï¼ˆMNISTï¼Œå“ˆå“ˆï¼‰ã€‚ <br><br><h2> å—ResNetså¯å‘çš„ç¥ç»ODE </h2><br> åœ¨ResNet'axä¸­ï¼Œæ½œåœ¨çŠ¶æ€æ ¹æ®å…¬å¼æ›´æ”¹ <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/30a/6b2/d3c/30a6b2d3c27bb27afaeb4736072e4446.svg" alt="h_ {t + 1} = h_ {t} + fï¼ˆh_ {t}ï¼Œ\ theta_ {t}ï¼‰"></div><br> åœ¨å“ªé‡Œ <img src="https://habrastorage.org/getpro/habr/post_images/7ca/860/97d/7ca86097dc5dc0d9cbb9b454168de928.svg" alt="t \ in \ {0 ... T \}"> æ˜¯å—å·å’Œ <img src="https://habrastorage.org/getpro/habr/post_images/eb2/5f7/ddf/eb25f7ddf77e46681e256b28fecaef35.svg" alt="ËšF"> è¿™æ˜¯å—å†…å„å±‚å­¦ä¹ åˆ°çš„åŠŸèƒ½ã€‚ <br><br> åœ¨æé™æƒ…å†µä¸‹ï¼Œå¦‚æœæˆ‘ä»¬é‡‡ç”¨æ— é™å¤šçš„æ­¥é•¿ä¸æ–­ç¼©å°çš„å—ï¼Œåˆ™ä¸ä¸Šé¢ä¸€æ ·ï¼Œæˆ‘ä»¬å°†ä»¥ODEçš„å½¢å¼è·å¾—éšè—å±‚çš„è¿ç»­åŠ¨æ€ã€‚ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/629/67a/d41/62967ad41e5f50cc65e1c1e55a2860d3.svg" alt="\ frac {dhï¼ˆtï¼‰} {dt} = fï¼ˆhï¼ˆtï¼‰ï¼Œtï¼Œ\ thetaï¼‰"></div><br> ä»è¾“å…¥å±‚å¼€å§‹ <img src="https://habrastorage.org/getpro/habr/post_images/c33/9b9/bc0/c339b9bc0244968c806390c2e66fdb62.svg" alt="å°æ—¶ï¼ˆ0ï¼‰"> æˆ‘ä»¬å¯ä»¥å®šä¹‰è¾“å‡ºå±‚ <img src="https://habrastorage.org/getpro/habr/post_images/b7e/dec/ef3/b7edecef308ce0df4f3d1c8aaa753617.svg" alt="å°æ—¶ï¼ˆTï¼‰"> ä½œä¸ºåœ¨æ—¶é—´Tå¯¹è¯¥ODEçš„è§£å†³æ–¹æ¡ˆã€‚ <br><br> ç°åœ¨æˆ‘ä»¬å¯ä»¥æ•° <img src="https://habrastorage.org/getpro/habr/post_images/2cb/bcb/347/2cbbcb347a44c276c1095ac5bb3f8242.svg" alt="\ theta"> ä½œä¸ºæ‰€æœ‰æ— ç©·å°å—ä¹‹é—´çš„åˆ†å¸ƒå¼ï¼ˆ <em>å…±äº«</em> ï¼‰å‚æ•°ã€‚ <br><br><h3> åœ¨MNISTä¸ŠéªŒè¯ç¥ç»ODEæ¶æ„ </h3><br> åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æµ‹è¯•<em>ç¥ç»ODE</em>åœ¨æ›´ç†Ÿæ‚‰çš„ä½“ç³»ç»“æ„ä¸­ç”¨ä½œç»„ä»¶çš„åŠŸèƒ½ã€‚ <br><br> ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å°†åœ¨MNISTåˆ†ç±»å™¨ä¸­å°†å‰©ä½™å—æ›¿æ¢ä¸º<em>ç¥ç»ODE</em> ã€‚ <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7c/gw/ia/7cgwiawqx6-_kxk82qpenqplowi.png" width="400"></div><br><br><div class="spoiler">  <b class="spoiler_title">ä»£å·</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">norm</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dim)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> nn.BatchNorm2d(dim) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">conv3x3</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(in_feats, out_feats, stride=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> nn.Conv2d(in_feats, out_feats, kernel_size=<span class="hljs-number"><span class="hljs-number">3</span></span>, stride=stride, padding=<span class="hljs-number"><span class="hljs-number">1</span></span>, bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">add_time</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(in_tensor, t)</span></span></span><span class="hljs-function">:</span></span> bs, c, w, h = in_tensor.shape <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> torch.cat((in_tensor, t.expand(bs, <span class="hljs-number"><span class="hljs-number">1</span></span>, w, h)), dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ConvODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(ODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, dim)</span></span></span><span class="hljs-function">:</span></span> super(ConvODEF, self).__init__() self.conv1 = conv3x3(dim + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim) self.norm1 = norm(dim) self.conv2 = conv3x3(dim + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim) self.norm2 = norm(dim) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> xt = add_time(x, t) h = self.norm1(torch.relu(self.conv1(xt))) ht = add_time(h, t) dxdt = self.norm2(torch.relu(self.conv2(ht))) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> dxdt <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ContinuousNeuralMNISTClassifier</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, ode)</span></span></span><span class="hljs-function">:</span></span> super(ContinuousNeuralMNISTClassifier, self).__init__() self.downsampling = nn.Sequential( nn.Conv2d(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), norm(<span class="hljs-number"><span class="hljs-number">64</span></span>), nn.ReLU(inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>), nn.Conv2d(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), norm(<span class="hljs-number"><span class="hljs-number">64</span></span>), nn.ReLU(inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>), nn.Conv2d(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), ) self.feature = ode self.norm = norm(<span class="hljs-number"><span class="hljs-number">64</span></span>) self.avg_pool = nn.AdaptiveAvgPool2d((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) self.fc = nn.Linear(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x)</span></span></span><span class="hljs-function">:</span></span> x = self.downsampling(x) x = self.feature(x) x = self.norm(x) x = self.avg_pool(x) shape = torch.prod(torch.tensor(x.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>:])).item() x = x.view(<span class="hljs-number"><span class="hljs-number">-1</span></span>, shape) out = self.fc(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out func = ConvODEF(<span class="hljs-number"><span class="hljs-number">64</span></span>) ode = NeuralODE(func) model = ContinuousNeuralMNISTClassifier(ode) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: model = model.cuda() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision img_std = <span class="hljs-number"><span class="hljs-number">0.3081</span></span> img_mean = <span class="hljs-number"><span class="hljs-number">0.1307</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">32</span></span> train_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(<span class="hljs-string"><span class="hljs-string">"data/mnist"</span></span>, train=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, download=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((img_mean,), (img_std,)) ]) ), batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> ) test_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(<span class="hljs-string"><span class="hljs-string">"data/mnist"</span></span>, train=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, download=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((img_mean,), (img_std,)) ]) ), batch_size=<span class="hljs-number"><span class="hljs-number">128</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> ) optimizer = torch.optim.Adam(model.parameters()) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(epoch)</span></span></span><span class="hljs-function">:</span></span> num_items = <span class="hljs-number"><span class="hljs-number">0</span></span> train_losses = [] model.train() criterion = nn.CrossEntropyLoss() print(<span class="hljs-string"><span class="hljs-string">f"Training Epoch </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{epoch}</span></span></span><span class="hljs-string">..."</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> batch_idx, (data, target) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(enumerate(train_loader), total=len(train_loader)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: data = data.cuda() target = target.cuda() optimizer.zero_grad() output = model(data) loss = criterion(output, target) loss.backward() optimizer.step() train_losses += [loss.item()] num_items += data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(<span class="hljs-string"><span class="hljs-string">'Train loss: {:.5f}'</span></span>.format(np.mean(train_losses))) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> train_losses <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> accuracy = <span class="hljs-number"><span class="hljs-number">0.0</span></span> num_items = <span class="hljs-number"><span class="hljs-number">0</span></span> model.eval() criterion = nn.CrossEntropyLoss() print(<span class="hljs-string"><span class="hljs-string">f"Testing..."</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> batch_idx, (data, target) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(enumerate(test_loader), total=len(test_loader)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: data = data.cuda() target = target.cuda() output = model(data) accuracy += torch.sum(torch.argmax(output, dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) == target).item() num_items += data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] accuracy = accuracy * <span class="hljs-number"><span class="hljs-number">100</span></span> / num_items print(<span class="hljs-string"><span class="hljs-string">"Test Accuracy: {:.3f}%"</span></span>.format(accuracy)) n_epochs = <span class="hljs-number"><span class="hljs-number">5</span></span> test() train_losses = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, n_epochs + <span class="hljs-number"><span class="hljs-number">1</span></span>): train_losses += train(epoch) test() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) history = pd.DataFrame({<span class="hljs-string"><span class="hljs-string">"loss"</span></span>: train_losses}) history[<span class="hljs-string"><span class="hljs-string">"cum_data"</span></span>] = history.index * batch_size history[<span class="hljs-string"><span class="hljs-string">"smooth_loss"</span></span>] = history.loss.ewm(halflife=<span class="hljs-number"><span class="hljs-number">10</span></span>).mean() history.plot(x=<span class="hljs-string"><span class="hljs-string">"cum_data"</span></span>, y=<span class="hljs-string"><span class="hljs-string">"smooth_loss"</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), title=<span class="hljs-string"><span class="hljs-string">"train error"</span></span>)</code> </pre><br></div></div><br><pre> <code class="plaintext hljs">Testing... 100% 79/79 [00:01&lt;00:00, 45.69it/s] Test Accuracy: 9.740% Training Epoch 1... 100% 1875/1875 [01:15&lt;00:00, 24.69it/s] Train loss: 0.20137 Testing... 100% 79/79 [00:01&lt;00:00, 46.64it/s] Test Accuracy: 98.680% Training Epoch 2... 100% 1875/1875 [01:17&lt;00:00, 24.32it/s] Train loss: 0.05059 Testing... 100% 79/79 [00:01&lt;00:00, 46.11it/s] Test Accuracy: 97.760% Training Epoch 3... 100% 1875/1875 [01:16&lt;00:00, 24.63it/s] Train loss: 0.03808 Testing... 100% 79/79 [00:01&lt;00:00, 45.65it/s] Test Accuracy: 99.000% Training Epoch 4... 100% 1875/1875 [01:17&lt;00:00, 24.28it/s] Train loss: 0.02894 Testing... 100% 79/79 [00:01&lt;00:00, 45.42it/s] Test Accuracy: 99.130% Training Epoch 5... 100% 1875/1875 [01:16&lt;00:00, 24.67it/s] Train loss: 0.02424 Testing... 100% 79/79 [00:01&lt;00:00, 45.89it/s] Test Accuracy: 99.170%</code> </pre><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zx/zv/5x/zxzv5x4ktqyy9lt19of-d2i4few.png"></div><br> åœ¨çŸ­çŸ­çš„5ä¸ªæ—¶ä»£å’Œ6åˆ†é’Ÿçš„è®­ç»ƒä¸­è¿›è¡Œäº†éå¸¸ç²—ç•¥çš„è®­ç»ƒåï¼Œè¯¥æ¨¡å‹çš„æµ‹è¯•è¯¯å·®å·²ç»å°äº1ï¼…ã€‚ å¯ä»¥è¯´ï¼Œ <em>ç¥ç»ODE</em> <em>ä½œä¸º</em>ç»„ä»¶å¾ˆå¥½åœ°é›†æˆåˆ°äº†æ›´ä¼ ç»Ÿçš„ç½‘ç»œä¸­ã€‚ <br><br> åœ¨ä»–ä»¬çš„æ–‡ç« ä¸­ï¼Œä½œè€…è¿˜å°†è¯¥åˆ†ç±»å™¨ï¼ˆODE-Netï¼‰ä¸å¸¸è§„çš„å…¨è¿æ¥ç½‘ç»œï¼Œå…·æœ‰ç›¸ä¼¼æ¶æ„çš„ResNetå’Œå…·æœ‰å®Œå…¨ç›¸åŒçš„æ¶æ„è¿›è¡Œäº†æ¯”è¾ƒï¼Œå…¶ä¸­æ¢¯åº¦ç›´æ¥é€šè¿‡<em>ODESolveä¸­çš„</em>æ“ä½œä¼ æ’­ï¼ˆæ²¡æœ‰å…±è½­æ¢¯åº¦æ–¹æ³•ï¼‰ï¼ˆ RK-Netï¼‰ã€‚ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vn/41/--/vn41--frzbdkftca4ehe7hh-kea.png"></div><br>  <i>åŸå§‹æ–‡ç« ä¸­çš„æ’å›¾ã€‚</i> <br><br> æ ¹æ®ä»–ä»¬çš„è¯´æ³•ï¼Œå…·æœ‰ä¸<em>ç¥ç»ç½‘ç»œODE</em>ç›¸åŒæ•°é‡çš„å‚æ•°çš„1å±‚å…¨è¿æ¥ç½‘ç»œåœ¨æµ‹è¯•ä¸­å…·æœ‰æ›´é«˜çš„è¯¯å·®ï¼Œå…·æœ‰ç›¸åŒè¯¯å·®çš„ResNetå…·æœ‰æ›´å¤šçš„å‚æ•°ï¼Œè€Œæ²¡æœ‰å…±è½­æ¢¯åº¦æ³•çš„RK-Netåˆ™å…·æœ‰è¾ƒé«˜çš„è¯¯å·®ã€‚å¹¶ä¸”éšç€å†…å­˜æ¶ˆè€—çº¿æ€§å¢åŠ ï¼ˆå…è®¸çš„è¯¯å·®è¶Šå°ï¼Œ <em>ODESolve</em>å¿…é¡»é‡‡å–çš„æ­¥éª¤è¶Šå¤šï¼Œè¿™éšæ­¥éª¤æ•°çº¿æ€§å¢åŠ äº†å†…å­˜æ¶ˆè€—ï¼‰ã€‚ <br><br> ä½œè€…åœ¨å…¶å®ç°ä¸­ä½¿ç”¨å…·æœ‰è‡ªé€‚åº”æ­¥é•¿çš„éšå¼Runge-Kuttaæ–¹æ³•ï¼Œè¿™ä¸æ­¤å¤„æ›´ç®€å•çš„Euleræ–¹æ³•ä¸åŒã€‚ ä»–ä»¬è¿˜ç ”ç©¶äº†æ–°æ¶æ„çš„ä¸€äº›å±æ€§ã€‚ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/u7/li/fq/u7lifqdsf72otgcyfigm6-fiyww.png"></div><br>  <i>ODE-NetåŠŸèƒ½ï¼ˆNFEè½¬å‘-ç›´æ¥ä¼ é€’ä¸­çš„åŠŸèƒ½è®¡ç®—æ•°ï¼‰</i> <i><br></i>  <i>åŸå§‹æ–‡ç« ä¸­çš„æ’å›¾ã€‚</i> <br><br><ul><li>  ï¼ˆaï¼‰æ”¹å˜æ•°å€¼è¯¯å·®çš„å¯æ¥å—æ°´å¹³ä¼šæ”¹å˜ç›´æ¥åˆ†å¸ƒçš„æ­¥æ•°ã€‚ <br></li><li>  ï¼ˆbï¼‰ç›´æ¥åˆ†é…æ‰€èŠ±è´¹çš„æ—¶é—´ä¸å‡½æ•°çš„è®¡ç®—æ¬¡æ•°æˆæ­£æ¯”ã€‚ <br></li><li>  ï¼ˆcï¼‰å‘åä¼ æ’­ä¸­å‡½æ•°çš„è®¡ç®—æ•°é‡å¤§çº¦æ˜¯ç›´æ¥ä¼ æ’­çš„ä¸€åŠï¼Œè¿™è¡¨æ˜å…±è½­æ¢¯åº¦æ–¹æ³•å¯èƒ½æ¯”ç›´æ¥é€šè¿‡<em>ODESolve</em>ä¼ æ’­æ¢¯åº¦æ›´æœ‰æ•ˆã€‚ <br></li><li>  ï¼ˆdï¼‰éšç€ODE-Netçš„è®­ç»ƒè¶Šæ¥è¶Šå¤šï¼Œå®ƒéœ€è¦å¯¹å‡½æ•°è¿›è¡Œè¶Šæ¥è¶Šå¤šçš„è®¡ç®—ï¼ˆæ­¥ä¼è¶Šæ¥è¶Šå°ï¼‰ï¼Œå¯èƒ½ä¼šé€‚åº”æ¨¡å‹æ—¥ç›Šå¢åŠ çš„å¤æ‚æ€§ã€‚ <br></li></ul><br><br><h2> æ—¶é—´åºåˆ—å»ºæ¨¡çš„éšè—ç”ŸæˆåŠŸèƒ½ </h2><br> å³ä½¿è·¯å¾„ä½äºæœªçŸ¥çš„éšè—ç©ºé—´ä¸­ï¼ŒNeural ODEä¹Ÿé€‚åˆå¤„ç†è¿ç»­çš„ä¸²è¡Œæ•°æ®ã€‚ <br><br> åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<em>Neural ODE</em>å°è¯•<em>å¹¶</em>æ›´æ”¹è¿ç»­åºåˆ—çš„ç”Ÿæˆï¼Œå¹¶äº†è§£å­¦ä¹ åˆ°çš„éšè—ç©ºé—´ã€‚ <br><br> ä½œè€…è¿˜å°†è¿™ä¸€ç‚¹ä¸é€’å½’ç½‘ç»œç”Ÿæˆçš„ç›¸ä¼¼åºåˆ—è¿›è¡Œäº†æ¯”è¾ƒã€‚ <br><br> è¿™é‡Œçš„å®éªŒä¸authorså­˜å‚¨åº“ä¸­çš„ç›¸åº”ç¤ºä¾‹ç¨æœ‰ä¸åŒï¼Œè¿™é‡Œçš„è½¨è¿¹æ›´åŠ å¤šæ ·åŒ–ã€‚ <br><br><h3> èµ„æ–™ </h3><br> è®­ç»ƒæ•°æ®ç”±éšæœºèºæ—‹ç»„æˆï¼Œå…¶ä¸­ä¸€åŠæ˜¯é¡ºæ—¶é’ˆæ–¹å‘ï¼Œç¬¬äºŒä¸ªæ˜¯é€†æ—¶é’ˆæ–¹å‘ã€‚ æ­¤å¤–ï¼Œä»è¿™äº›èºæ—‹ä¸­é‡‡æ ·éšæœºå­åºåˆ—ï¼Œç”±ç¼–ç é€’å½’æ¨¡å‹åœ¨ç›¸åçš„æ–¹å‘ä¸Šè¿›è¡Œå¤„ç†ï¼Œä»è€Œäº§ç”Ÿåˆå§‹çš„éšè—çŠ¶æ€ï¼Œç„¶åé€æ¸å‘å±•ï¼Œåœ¨éšè—ç©ºé—´ä¸­å½¢æˆè½¨è¿¹ã€‚ ç„¶åå°†æ­¤æ½œåœ¨è·¯å¾„æ˜ å°„åˆ°æ•°æ®ç©ºé—´ï¼Œå¹¶ä¸é‡‡æ ·çš„å­åºåˆ—è¿›è¡Œæ¯”è¾ƒã€‚ å› æ­¤ï¼Œæ¨¡å‹å­¦ä¹ ç”Ÿæˆç±»ä¼¼äºæ•°æ®é›†çš„è½¨è¿¹ã€‚ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/or/4z/lg/or4zlgwkqjm-kzhvlmqtzmeqnl4.png"></div><br>  <i>æ•°æ®é›†èºæ—‹çš„ç¤ºä¾‹</i> <br><br><h3>  VAEä½œä¸ºç”Ÿæˆæ¨¡å‹ </h3><br> é€šè¿‡æŠ½æ ·ç¨‹åºç”Ÿæˆæ¨¡å‹ï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fde/a91/b7b/fdea91b7b77af8c87a50e6c9e361f13b.svg" alt="z_ {t_0} \ sim \ mathcal {N}ï¼ˆ0ï¼Œæˆ‘ï¼‰"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb0/9b2/ad7/fb09b2ad71d820266be632be7c5b5f97.svg" alt="z_ {t_1}ï¼Œz_ {t_2}ï¼Œ...ï¼Œz_ {t_M} = \æ–‡æœ¬{ODESolve}ï¼ˆz_ {t_0}ï¼Œfï¼Œ\ theta_fï¼Œt_0ï¼Œ...ï¼Œt_Mï¼‰"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/477/5a1/439/4775a14397c7842e67c0756d585c3d5b.svg" alt="x_ {t_i} \ sim pï¼ˆx \ mid z_ {t_i}; \ theta_xï¼‰"></div><br> å¯ä»¥ä½¿ç”¨å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚ <br><ol><li> é€šè¿‡æ—¶é—´åºåˆ—çš„é€’å½’ç¼–ç å™¨ä»¥è·å–æ—¶é—´å‚æ•° <img src="https://habrastorage.org/getpro/habr/post_images/26b/84a/1dd/26b84a1dd2d618b4dd85d805e95b5db3.svg" alt="\ mu_ {z_ {t_0}}">  ï¼Œ <img src="https://habrastorage.org/getpro/habr/post_images/a1f/9e2/8ac/a1f9e28acee2636547023da51c1af36e.svg" alt="\ sigma_ {z_ {t_0}}"> åéªŒåˆ†å¸ƒï¼Œç„¶åä»ä¸­å–æ ·ï¼š <br></li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/816/997/3be/8169973bece43135c717f8abd5088e4c.svg" alt="z_ {t_0} \ sim q \å·¦ï¼ˆz_ {t_0} \ä¸­é—´x_ {t_0}ï¼Œ...ï¼Œx_ {t_M}; t_0ï¼Œ...ï¼Œt_M; \ theta_q \å³ï¼‰= \æ•°å­¦{N} \å·¦ï¼ˆz_ {t_0} \ä¸­\ mu_ {z_ {t_0}} \ sigma_ {z_ {t_0}} \å³ï¼‰"></div><br><ol><li> è·å–éšè—çš„è½¨è¿¹ï¼š <br></li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/416/810/833/416810833bb304242b3ec7bccfeb91ad.svg" alt="z_ {t_1}ï¼Œz_ {t_2}ï¼Œ...ï¼Œz_ {t_N} = \æ–‡æœ¬{ODESolve}ï¼ˆz_ {t_0}ï¼Œfï¼Œ\ theta_fï¼Œt_0ï¼Œ...ï¼Œt_Nï¼‰ï¼Œ\æ–‡æœ¬{where} \ frac {dz} {dt} = fï¼ˆzï¼Œt; \ theta_fï¼‰"></div><br><ol><li> ä½¿ç”¨å¦ä¸€ä¸ªç¥ç»ç½‘ç»œå°†éšè—çš„è·¯å¾„æ˜ å°„åˆ°æ•°æ®ä¸­çš„è·¯å¾„ï¼š <img src="https://habrastorage.org/getpro/habr/post_images/fd1/2b0/73d/fd12b073dd1cede0a98b312c0e3240d1.svg" alt="\ hat {x_ {t_i}}ï¼ˆz_ {t_i}ï¼Œt_i; \ theta_xï¼‰"><br></li><li> æœ€å¤§åŒ–å¯¹é‡‡æ ·è·¯å¾„çš„æœ‰æ•ˆæ€§ä¸‹é™ï¼ˆELBOï¼‰çš„è¯„ä¼°ï¼š <br></li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9cf/838/1e3/9cf8381e35978cf70219a1f3bea211b6.svg" alt="\ text {ELBO} \å¤§çº¦N \ Bigï¼ˆ\ sum_ {i = 0} ^ {M} \ log pï¼ˆx_ {t_i} \ mid z_ {t_i}ï¼ˆz_ {t_0}; \ theta_fï¼‰; \ theta_xï¼‰+ KL \å·¦ï¼ˆqï¼ˆz_ {t_0} \ä¸­é—´x_ {t_0}ï¼Œ...ï¼Œx_ {t_M}; t_0ï¼Œ...ï¼Œt_M; \ theta_qï¼‰\å¹¶è¡Œ\æ•°å­¦{N}ï¼ˆ0ï¼ŒIï¼‰\å³ï¼‰\å¤§ï¼‰"></div><br> åœ¨é«˜æ–¯åéªŒåˆ†å¸ƒçš„æƒ…å†µä¸‹ <img src="https://habrastorage.org/getpro/habr/post_images/9a9/404/aa0/9a9404aa0267a6c257815abc794e95c3.svg" alt="pï¼ˆx \ mid z_ {t_i}; \ theta_xï¼‰"> å’Œå·²çŸ¥çš„å™ªéŸ³æ°´å¹³ <img src="https://habrastorage.org/getpro/habr/post_images/87a/7c9/aba/87a7c9abaa12e58e75ef64aa8312050e.svg" alt="\ sigma_x">  ï¼š <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7b0/a0d/c43/7b0a0dc43667f287d584b6865afa1cfb.svg" alt="\ text {ELBO} \å¤§çº¦-N \ Bigï¼ˆ\ sum_ {i = 1} ^ {M} \ frac {ï¼ˆx_i-\ hat {x_i}ï¼‰^ 2} {\ sigma_x ^ 2}-\ log \ sigma_ { z_ {t_0}} ^ 2 + \ mu_ {z_ {t_0}} ^ 2 + \ sigma_ {z_ {t_0}} ^ 2 \å¤§ï¼‰+ C"></div><br> éšè—çš„ODEæ¨¡å‹çš„è®¡ç®—å›¾å¯ä»¥è¡¨ç¤ºå¦‚ä¸‹ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zl/57/ui/zl57uisgnvjy7-y94fkker9m1eq.png"></div><br>  <i>åŸå§‹æ–‡ç« ä¸­çš„æ’å›¾ã€‚</i> <br><br> ç„¶åå¯ä»¥ä»…ä½¿ç”¨åˆå§‹è§‚æµ‹å€¼æµ‹è¯•è¯¥æ¨¡å‹çš„å†…æ’è·¯å¾„ã€‚ <br><br><div class="spoiler">  <b class="spoiler_title">ä»£å·</b> <div class="spoiler_text"><h3> å®šä¹‰æ¨¡å‹ </h3><br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RNNEncoder</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_dim, hidden_dim, latent_dim)</span></span></span><span class="hljs-function">:</span></span> super(RNNEncoder, self).__init__() self.input_dim = input_dim self.hidden_dim = hidden_dim self.latent_dim = latent_dim self.rnn = nn.GRU(input_dim+<span class="hljs-number"><span class="hljs-number">1</span></span>, hidden_dim) self.hid2lat = nn.Linear(hidden_dim, <span class="hljs-number"><span class="hljs-number">2</span></span>*latent_dim) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Concatenate time to input t = t.clone() t[1:] = t[:-1] - t[1:] t[0] = 0. xt = torch.cat((x, t), dim=-1) _, h0 = self.rnn(xt.flip((0,))) # Reversed # Compute latent dimension z0 = self.hid2lat(h0[0]) z0_mean = z0[:, :self.latent_dim] z0_log_var = z0[:, self.latent_dim:] return z0_mean, z0_log_var class NeuralODEDecoder(nn.Module): def __init__(self, output_dim, hidden_dim, latent_dim): super(NeuralODEDecoder, self).__init__() self.output_dim = output_dim self.hidden_dim = hidden_dim self.latent_dim = latent_dim func = NNODEF(latent_dim, hidden_dim, time_invariant=True) self.ode = NeuralODE(func) self.l2h = nn.Linear(latent_dim, hidden_dim) self.h2o = nn.Linear(hidden_dim, output_dim) def forward(self, z0, t): zs = self.ode(z0, t, return_whole_sequence=True) hs = self.l2h(zs) xs = self.h2o(hs) return xs class ODEVAE(nn.Module): def __init__(self, output_dim, hidden_dim, latent_dim): super(ODEVAE, self).__init__() self.output_dim = output_dim self.hidden_dim = hidden_dim self.latent_dim = latent_dim self.encoder = RNNEncoder(output_dim, hidden_dim, latent_dim) self.decoder = NeuralODEDecoder(output_dim, hidden_dim, latent_dim) def forward(self, x, t, MAP=False): z_mean, z_log_var = self.encoder(x, t) if MAP: z = z_mean else: z = z_mean + torch.randn_like(z_mean) * torch.exp(0.5 * z_log_var) x_p = self.decoder(z, t) return x_p, z, z_mean, z_log_var def generate_with_seed(self, seed_x, t): seed_t_len = seed_x.shape[0] z_mean, z_log_var = self.encoder(seed_x, t[:seed_t_len]) x_p = self.decoder(z_mean, t) return x_p</span></span></code> </pre><br><br><h3> æ•°æ®é›†ç”Ÿæˆ </h3><br><br><pre> <code class="python hljs">t_max = <span class="hljs-number"><span class="hljs-number">6.29</span></span>*<span class="hljs-number"><span class="hljs-number">5</span></span> n_points = <span class="hljs-number"><span class="hljs-number">200</span></span> noise_std = <span class="hljs-number"><span class="hljs-number">0.02</span></span> num_spirals = <span class="hljs-number"><span class="hljs-number">1000</span></span> index_np = np.arange(<span class="hljs-number"><span class="hljs-number">0</span></span>, n_points, <span class="hljs-number"><span class="hljs-number">1</span></span>, dtype=np.int) index_np = np.hstack([index_np[:, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]]) times_np = np.linspace(<span class="hljs-number"><span class="hljs-number">0</span></span>, t_max, num=n_points) times_np = np.hstack([times_np[:, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]] * num_spirals) times = torch.from_numpy(times_np[:, :, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]).to(torch.float32) <span class="hljs-comment"><span class="hljs-comment"># Generate random spirals parameters normal01 = torch.distributions.Normal(0, 1.0) x0 = Variable(normal01.sample((num_spirals, 2))) * 2.0 W11 = -0.1 * normal01.sample((num_spirals,)).abs() - 0.05 W22 = -0.1 * normal01.sample((num_spirals,)).abs() - 0.05 W21 = -1.0 * normal01.sample((num_spirals,)).abs() W12 = 1.0 * normal01.sample((num_spirals,)).abs() xs_list = [] for i in range(num_spirals): if i % 2 == 1: # Make it counter-clockwise W21, W12 = W12, W21 func = LinearODEF(Tensor([[W11[i], W12[i]], [W21[i], W22[i]]])) ode = NeuralODE(func) xs = ode(x0[i:i+1], times[:, i:i+1], return_whole_sequence=True) xs_list.append(xs) orig_trajs = torch.cat(xs_list, dim=1).detach() samp_trajs = orig_trajs + torch.randn_like(orig_trajs) * noise_std samp_ts = times fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 9)) axes = axes.flatten() for i, ax in enumerate(axes): ax.scatter(samp_trajs[:, i, 0], samp_trajs[:, i, 1], c=samp_ts[:, i, 0], cmap=cm.plasma) plt.show() import numpy.random as npr def gen_batch(batch_size, n_sample=100): n_batches = samp_trajs.shape[1] // batch_size time_len = samp_trajs.shape[0] n_sample = min(n_sample, time_len) for i in range(n_batches): if n_sample &gt; 0: probs = [1. / (time_len - n_sample)] * (time_len - n_sample) t0_idx = npr.multinomial(1, probs) t0_idx = np.argmax(t0_idx) tM_idx = t0_idx + n_sample else: t0_idx = 0 tM_idx = time_len frm, to = batch_size*i, batch_size*(i+1) yield samp_trajs[t0_idx:tM_idx, frm:to], samp_ts[t0_idx:tM_idx, frm:to]</span></span></code> </pre><br><br><h3> åŸ¹è®­è¯¾ç¨‹ </h3><br><br><pre> <code class="python hljs">vae = ODEVAE(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>) vae = vae.cuda() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: vae = vae.cuda() optim = torch.optim.Adam(vae.parameters(), betas=(<span class="hljs-number"><span class="hljs-number">0.9</span></span>, <span class="hljs-number"><span class="hljs-number">0.999</span></span>), lr=<span class="hljs-number"><span class="hljs-number">0.001</span></span>) preload = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> n_epochs = <span class="hljs-number"><span class="hljs-number">20000</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">100</span></span> plot_traj_idx = <span class="hljs-number"><span class="hljs-number">1</span></span> plot_traj = orig_trajs[:, plot_traj_idx:plot_traj_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>] plot_obs = samp_trajs[:, plot_traj_idx:plot_traj_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>] plot_ts = samp_ts[:, plot_traj_idx:plot_traj_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: plot_traj = plot_traj.cuda() plot_obs = plot_obs.cuda() plot_ts = plot_ts.cuda() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> preload: vae.load_state_dict(torch.load(<span class="hljs-string"><span class="hljs-string">"models/vae_spirals.sd"</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch_idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n_epochs): losses = [] train_iter = gen_batch(batch_size) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x, t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> train_iter: optim.zero_grad() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: x, t = x.cuda(), t.cuda() max_len = np.random.choice([<span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>]) permutation = np.random.permutation(t.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) np.random.shuffle(permutation) permutation = np.sort(permutation[:max_len]) x, t = x[permutation], t[permutation] x_p, z, z_mean, z_log_var = vae(x, t) z_var = torch.exp(z_log_var) kl_loss = <span class="hljs-number"><span class="hljs-number">-0.5</span></span> * torch.sum(<span class="hljs-number"><span class="hljs-number">1</span></span> + z_log_var - z_mean**<span class="hljs-number"><span class="hljs-number">2</span></span> - z_var, <span class="hljs-number"><span class="hljs-number">-1</span></span>) loss = <span class="hljs-number"><span class="hljs-number">0.5</span></span> * ((x-x_p)**<span class="hljs-number"><span class="hljs-number">2</span></span>).sum(<span class="hljs-number"><span class="hljs-number">-1</span></span>).sum(<span class="hljs-number"><span class="hljs-number">0</span></span>) / noise_std**<span class="hljs-number"><span class="hljs-number">2</span></span> + kl_loss loss = torch.mean(loss) loss /= max_len loss.backward() optim.step() losses.append(loss.item()) print(<span class="hljs-string"><span class="hljs-string">f"Epoch </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{epoch_idx}</span></span></span><span class="hljs-string">"</span></span>) frm, to, to_seed = <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span> seed_trajs = samp_trajs[frm:to_seed] ts = samp_ts[frm:to] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: seed_trajs = seed_trajs.cuda() ts = ts.cuda() samp_trajs_p = to_np(vae.generate_with_seed(seed_trajs, ts)) fig, axes = plt.subplots(nrows=<span class="hljs-number"><span class="hljs-number">3</span></span>, ncols=<span class="hljs-number"><span class="hljs-number">3</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(axes): ax.scatter(to_np(seed_trajs[:, i, <span class="hljs-number"><span class="hljs-number">0</span></span>]), to_np(seed_trajs[:, i, <span class="hljs-number"><span class="hljs-number">1</span></span>]), c=to_np(ts[frm:to_seed, i, <span class="hljs-number"><span class="hljs-number">0</span></span>]), cmap=cm.plasma) ax.plot(to_np(orig_trajs[frm:to, i, <span class="hljs-number"><span class="hljs-number">0</span></span>]), to_np(orig_trajs[frm:to, i, <span class="hljs-number"><span class="hljs-number">1</span></span>])) ax.plot(samp_trajs_p[:, i, <span class="hljs-number"><span class="hljs-number">0</span></span>], samp_trajs_p[:, i, <span class="hljs-number"><span class="hljs-number">1</span></span>]) plt.show() print(np.mean(losses), np.median(losses)) clear_output(wait=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) spiral_0_idx = <span class="hljs-number"><span class="hljs-number">3</span></span> spiral_1_idx = <span class="hljs-number"><span class="hljs-number">6</span></span> homotopy_p = Tensor(np.linspace(<span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)[:, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]) vae = vae <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: homotopy_p = homotopy_p.cuda() vae = vae.cuda() spiral_0 = orig_trajs[:, spiral_0_idx:spiral_0_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>, :] spiral_1 = orig_trajs[:, spiral_1_idx:spiral_1_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>, :] ts_0 = samp_ts[:, spiral_0_idx:spiral_0_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>, :] ts_1 = samp_ts[:, spiral_1_idx:spiral_1_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>, :] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: spiral_0, ts_0 = spiral_0.cuda(), ts_0.cuda() spiral_1, ts_1 = spiral_1.cuda(), ts_1.cuda() z_cw, _ = vae.encoder(spiral_0, ts_0) z_cc, _ = vae.encoder(spiral_1, ts_1) homotopy_z = z_cw * (<span class="hljs-number"><span class="hljs-number">1</span></span> - homotopy_p) + z_cc * homotopy_p t = torch.from_numpy(np.linspace(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>*np.pi, <span class="hljs-number"><span class="hljs-number">200</span></span>)) t = t[:, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>].expand(<span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)[:, :, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>].cuda() t = t.cuda() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> t hom_gen_trajs = vae.decoder(homotopy_z, t) fig, axes = plt.subplots(nrows=<span class="hljs-number"><span class="hljs-number">2</span></span>, ncols=<span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(axes): ax.plot(to_np(hom_gen_trajs[:, i, <span class="hljs-number"><span class="hljs-number">0</span></span>]), to_np(hom_gen_trajs[:, i, <span class="hljs-number"><span class="hljs-number">1</span></span>])) plt.show() torch.save(vae.state_dict(), <span class="hljs-string"><span class="hljs-string">"models/vae_spirals.sd"</span></span>)</code> </pre><br></div></div><br>       <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fv/pn/pi/fvpnpimixf3sq0cezhepgzh2txy.png"></div><br> <i> â€”      (), <br>  â€”     ,    . <br><br>    .</i> <br><br>       .        .       . <br><br>    ,     -   - . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/at/g_/7e/atg_7ecofins-uohnv99qccfxfq.png"></div><br><br>         <em>Neural ODE</em>    . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/kj/ak/-e/kjak-evgr-7mrrtpgimf0gfmfxq.png"></div><br> <i>   </i> <br><br><h2>    </h2><br>         .   ,       ,         (, ),            . <br>  ,           ,   . <br><br> <em> </em>       <em> </em> , <em>  </em>     . <br><br>  , ,    <em></em> ,  ,  ,     . <br><br>  : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nd/e_/wn/nde_wn590scz9dff_0hzxo1-tgg.png"></div><br> <i>    ( )   ( )   ; <br><br> -X        Â«Â» ( )  Â«Â» ( ). <br><br>    </i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" class="user_link">bekemax</a>            . <br><br>      <strong>Neural ODEs</strong> .   ! <br><br><h1>   </h1><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">   + . </a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">   VAE ()</a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> VAE</a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">   </a> <br></li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Variational Inference with Normalizing Flows Paper</a> <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN442002/">https://habr.com/ru/post/zh-CN442002/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN441990/index.html">æ‰“å‡»ç›—ç‰ˆçš„æœ€æœ‰æ•ˆæ–¹æ³•-ä¾¿æ·ï¼Œå»‰ä»·çš„æ³•å¾‹æœåŠ¡</a></li>
<li><a href="../zh-CN441992/index.html">ä¸ºæå®¢å¥³å­©é€‰æ‹©ç¤¼ç‰©</a></li>
<li><a href="../zh-CN441994/index.html">ç¾å›½å®‡èˆªå±€ï¼šæˆ‘ä»¬é“¶æ²³ç³»ä¸­å®œå±…è¡Œæ˜Ÿçš„æ•°é‡æ¯”é€šå¸¸è®¤ä¸ºçš„å°‘å¾—å¤š</a></li>
<li><a href="../zh-CN441996/index.html">80å¹´ä»£çš„æŠ€æœ¯ï¼šè°ä¼šå¤å…´æ™¶åœ†çº§å¤„ç†å™¨</a></li>
<li><a href="../zh-CN441998/index.html">â€œè¿™äº›å®¹å™¨èµ¢å¾—äº†æˆ˜æ–—ï¼Œä½†åœ¨æ— æœåŠ¡å™¨æ¶æ„ä¸Šå´è¾“æ‰äº†è¿™åœºæˆ˜äº‰ã€‚â€-Simon Wardley</a></li>
<li><a href="../zh-CN442004/index.html">SVGè¿‡æ»¤æ•ˆæœã€‚ ç¬¬7éƒ¨åˆ†ã€‚å‰è¿›</a></li>
<li><a href="../zh-CN442006/index.html">æ–‡ä»¶ç®¡ç†åšé”™äº†-ç¬¬2éƒ¨åˆ†ï¼šç‹—å±çš„æ°ä½œ</a></li>
<li><a href="../zh-CN442008/index.html">k3sæ˜¯ç”±Rancher Labsè®¤è¯çš„å°å‹ä½†ç»è¿‡è®¤è¯çš„Kubernetes</a></li>
<li><a href="../zh-CN442010/index.html">Pythonå’ŒFPGAã€‚ æµ‹è¯•ä¸­</a></li>
<li><a href="../zh-CN442012/index.html">å®éªŒï¼šæˆ‘ä»¬æ”¶é›†å‘æ”¾æŠ¤ç…§çš„å•ä½ç›®å½•</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
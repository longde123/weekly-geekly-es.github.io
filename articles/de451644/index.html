<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äçüåæ ü§æüèæ üí™üèº Anwendungsbereitstellung in VM, Nomad und Kubernetes ‚õ≥Ô∏è ‚òùüèº üì∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! Ich hei√üe Pavel Agaletsky. Ich arbeite als Teamleiter in einem Team, das ein Lamoda-Liefersystem entwickelt. 2018 sprach ich auf der...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Anwendungsbereitstellung in VM, Nomad und Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lamoda/blog/451644/">  Hallo allerseits!  Ich hei√üe Pavel Agaletsky.  Ich arbeite als Teamleiter in einem Team, das ein Lamoda-Liefersystem entwickelt.  2018 sprach ich auf der HighLoad ++ - Konferenz und m√∂chte heute eine Abschrift meines Berichts vorstellen. <br><br>  Mein Thema ist der Erfahrung unseres Unternehmens bei der Bereitstellung von Systemen und Diensten in verschiedenen Umgebungen gewidmet.  Ausgehend von unserer pr√§historischen Zeit, als wir alle Systeme auf regul√§ren virtuellen Servern bereitstellten, endete dies mit einem schrittweisen √úbergang von Nomad zu einer Bereitstellung auf Kubernetes.  Ich werde Ihnen sagen, warum wir dies getan haben und welche Probleme wir dabei hatten. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/oqrb7dWECSo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  Stellen Sie Anwendungen auf der VM bereit </h1><br>  Zun√§chst wurden vor 3 Jahren alle Systeme und Dienste des Unternehmens auf normalen virtuellen Servern bereitgestellt.  Technisch war es so organisiert, dass der gesamte Code unserer Systeme mit automatischen Build-Tools unter Verwendung von Jenkins erstellt und zusammengesetzt wurde.  Mit Ansible rollte er unser Versionskontrollsystem auf virtuelle Server aus.  Dar√ºber hinaus wurde jedes System in unserem Unternehmen mindestens auf zwei Servern bereitgestellt: einer davon war auf dem Kopf, der zweite auf dem Kopf.  Diese beiden Systeme waren in allen Einstellungen, Leistung, Konfiguration und mehr absolut identisch.  Der einzige Unterschied zwischen ihnen bestand darin, dass der Kopf Benutzerverkehr erhielt, w√§hrend der Schwanz niemals Benutzerverkehr erhielt. <br><br>  Warum wurde das gemacht? <br><br>  Bei der Bereitstellung neuer Versionen unserer Anwendung wollten wir die M√∂glichkeit einer nahtlosen Einf√ºhrung bieten, dh ohne erkennbare Konsequenzen f√ºr die Benutzer.  Dies wurde aufgrund der Tatsache erreicht, dass die n√§chste zusammengebaute Version mit Ansible am Heck ausgerollt wurde.  Dort konnten die an der Bereitstellung beteiligten Personen √ºberpr√ºfen und sicherstellen, dass alles in Ordnung war: Alle Metriken, Abschnitte und Anwendungen funktionierten.  Die erforderlichen Skripte werden gestartet.  Erst nachdem sie √ºberzeugt waren, dass alles in Ordnung ist, wurde der Verkehr umgeschaltet.  Er fing an, zu dem Server zu gehen, der vorher Schwanz war.  Und derjenige, der vorher der Kopf war, wurde ohne Benutzerverkehr gelassen, w√§hrend mit der vorherigen Version unserer Anwendung darauf. <br><br>  Somit war es f√ºr Benutzer nahtlos.  Weil das Umschalten gleichzeitig erfolgt, da es sich nur um ein Balancer-Umschalten handelt.  Es ist sehr einfach, ein Rollback auf die vorherige Version durchzuf√ºhren, indem Sie einfach den Balancer zur√ºckschalten.  Wir konnten auch die Produktionsf√§higkeit der Anwendung √ºberpr√ºfen, noch bevor der Benutzerverkehr zu ihr gelangt, was praktisch genug war. <br><br>  Welche Vorteile haben wir dabei gesehen? <br><br><ol><li>  Erstens <b>funktioniert es</b> ganz <b>einfach.</b>  Jeder versteht, wie dieses Bereitstellungsschema funktioniert, da die meisten Benutzer jemals auf normalen virtuellen Servern bereitgestellt haben. </li><li> Dies ist sehr <b>zuverl√§ssig</b> , da die Bereitstellungstechnologie einfach ist und von Tausenden von Unternehmen getestet wird.  Auf diese Weise werden Millionen von Servern bereitgestellt.  Es ist schwer, etwas zu zerbrechen. </li><li>  Und schlie√ülich k√∂nnten wir <b>atomare Bereitstellungen erhalten</b> .  Bereitstellungen, die gleichzeitig f√ºr Benutzer erfolgen, ohne dass ein merklicher Wechsel zwischen der alten und der neuen Version erforderlich ist. </li></ol><br>  Dabei haben wir aber auch einige M√§ngel gesehen: <br><br><ol><li>  Neben der Produktionsumgebung und der Entwicklungsumgebung gibt es noch andere Umgebungen.  Zum Beispiel Qa und Vorproduktion.  Zu dieser Zeit hatten wir viele Server und ungef√§hr 60 Dienste.  Aus diesem Grund musste <b>f√ºr jeden Dienst die f√ºr ihn relevante Version der</b> virtuellen Maschine verwaltet werden.  Wenn Sie Bibliotheken aktualisieren oder neue Abh√§ngigkeiten installieren m√∂chten, m√ºssen Sie dies in allen Umgebungen tun.  Es war auch erforderlich, die Zeit, zu der Sie die n√§chste neue Version Ihrer Anwendung bereitstellen wollten, mit der Zeit zu synchronisieren, zu der die Entwickler die erforderlichen Umgebungseinstellungen vorgenommen haben.  In diesem Fall ist es leicht, in eine Situation zu geraten, in der sich unsere Umgebung in allen aufeinanderfolgenden Umgebungen gleichzeitig geringf√ºgig unterscheidet.  In der QS-Umgebung gibt es beispielsweise einige Versionen von Bibliotheken und in der Produktion andere, was zu Problemen f√ºhren wird. </li><li>  <b>Schwierigkeiten beim Aktualisieren der Abh√§ngigkeiten</b> Ihrer Anwendung.  Es h√§ngt nicht von dir ab, sondern vom anderen Team.  N√§mlich aus dem Befehl devops, der den Server unterst√ºtzt.  Sie m√ºssen eine geeignete Aufgabe f√ºr sie festlegen und eine Beschreibung dessen geben, was Sie tun m√∂chten. </li><li>  Zu dieser Zeit wollten wir auch die gro√üen gro√üen Monolithen, die wir hatten, in separate kleine Dienste aufteilen, da wir verstanden hatten, dass es immer mehr von ihnen geben w√ºrde.  Zu diesem Zeitpunkt hatten wir bereits mehr als 100 davon. F√ºr jeden neuen Dienst musste eine separate neue virtuelle Maschine erstellt werden, die ebenfalls gewartet und bereitgestellt werden muss.  Au√üerdem ben√∂tigen Sie nicht ein Auto, sondern mindestens zwei.  Dazu wird noch die QS-Umgebung hinzugef√ºgt.  Dies verursacht Probleme und macht das Erstellen und Starten neuer Systeme <b>f√ºr Sie schwieriger, kostspieliger und zeitaufw√§ndiger.</b> </li></ol><br>  Aus diesem Grund haben wir beschlossen, dass es bequemer ist, von der Bereitstellung gew√∂hnlicher virtueller Maschinen zur Bereitstellung unserer Anwendungen im Docker-Container zu wechseln.  Wenn Sie Docker haben, ben√∂tigen Sie ein System, das die Anwendung im Cluster ausf√ºhren kann, da Sie den Container nicht einfach anheben k√∂nnen.  Normalerweise m√∂chten Sie verfolgen, wie viele Container angehoben werden, damit sie automatisch ansteigen.  Aus diesem Grund mussten wir ein Steuerungssystem w√§hlen. <br><br>  Wir haben lange dar√ºber nachgedacht, welche man nehmen kann.  Tatsache ist, dass zu diesem Zeitpunkt dieser Stapel von Bereitstellungen auf normalen virtuellen Servern etwas veraltet war, da es dort nicht die neuesten Versionen von Betriebssystemen gab.  Irgendwann stand sogar FreeBSD da, was nicht sehr bequem zu warten war.  Wir haben verstanden, dass Sie so schnell wie m√∂glich auf Docker migrieren m√ºssen.  Unsere Entwickler haben ihre vorhandenen Erfahrungen mit verschiedenen L√∂sungen untersucht und sich f√ºr ein System wie Nomad entschieden. <br><br><h1>  Wechseln Sie zu Nomad </h1><br>  Nomad ist ein HashiCorp-Produkt.  Sie sind auch f√ºr ihre anderen Entscheidungen bekannt: <br><br><img src="https://habrastorage.org/webt/4e/vz/4e/4evz4entvdaauztnu558tb-2z9u.jpeg" alt="Bild"><br><br>  <b>Consul</b> ist ein Tool zur Serviceerkennung. <br><br>  <b>Terraform</b> ist ein Serververwaltungssystem, mit dem Sie sie √ºber eine Konfiguration konfigurieren k√∂nnen, die als Infrastruktur als Code bezeichnet wird. <br><br>  <b>Mit Vagrant</b> k√∂nnen Sie virtuelle Maschinen lokal oder in der Cloud √ºber bestimmte Konfigurationsdateien bereitstellen. <br><br>  Nomad schien zu dieser Zeit eine ziemlich einfache L√∂sung zu sein, zu der Sie schnell wechseln k√∂nnen, ohne die gesamte Infrastruktur zu ver√§ndern.  Dar√ºber hinaus ist es recht einfach zu beherrschen.  Deshalb haben wir es als unser Filtersystem f√ºr unseren Container gew√§hlt. <br><br>  Was ist erforderlich, um Ihr System vollst√§ndig f√ºr Nomad bereitzustellen? <br><br><ol><li>  Zun√§chst ben√∂tigen Sie das <b>Docker-Image</b> Ihrer Anwendung.  Sie m√ºssen es erstellen und in den Docker-Image-Speicher stellen.  In unserem Fall ist dies k√ºnstlich - ein solches System, mit dem Sie verschiedene Artefakte verschiedener Typen hineinschieben k√∂nnen.  Es kann Archive, Docker-Images, PHP-Composer-Pakete, NPM-Pakete usw. speichern. </li><li>  Sie ben√∂tigen au√üerdem eine <b>Konfigurationsdatei</b> , die Nomad mitteilt, was, wo und wie viel Sie bereitstellen m√∂chten. </li></ol><br>  Wenn wir √ºber Nomad sprechen, wird die HCL-Sprache als Informationsdateiformat verwendet, das f√ºr <i>HashiCorp Configuration Language steht</i> .  Dies ist eine Obermenge von Yaml, mit der Sie Ihren Service in Bezug auf Nomad beschreiben k√∂nnen. <br><br><img src="https://habrastorage.org/webt/vg/q9/vb/vgq9vb_izh4i890ro7giihibz6g.jpeg" alt="Bild"><br><br>  Hier k√∂nnen Sie angeben, wie viele Container Sie bereitstellen m√∂chten, von welchen Images verschiedene Parameter w√§hrend der Bereitstellung √ºbertragen werden sollen.  Sie f√ºttern also diese Nomad-Datei und sie startet entsprechend die entsprechenden Container in der Produktion. <br><br>  In unserem Fall haben wir festgestellt, dass es nicht sehr praktisch ist, f√ºr jeden Dienst genau die gleichen, identischen HLC-Dateien zu schreiben, da es viele Dienste gibt und Sie diese manchmal aktualisieren m√∂chten.  Es kommt vor, dass ein Dienst nicht in einer Instanz bereitgestellt wird, sondern in den unterschiedlichsten.  Zum Beispiel hat eines der Systeme, die wir in der Produktion haben, mehr als 100 Instanzen in der Produktion.  Sie werden von denselben Images gestartet, unterscheiden sich jedoch in den Konfigurationseinstellungen und Konfigurationsdateien. <br><br>  Aus diesem Grund haben wir beschlossen, dass es f√ºr uns praktisch ist, alle Konfigurationsdateien f√ºr die Bereitstellung in einem gemeinsamen Repository zu speichern.  So wurden sie beobachtbar: Sie waren leicht zu warten und es war m√∂glich zu sehen, welche Systeme wir hatten.  Bei Bedarf ist es auch einfach, etwas zu aktualisieren oder zu √§ndern.  Das Hinzuf√ºgen eines neuen Systems ist ebenfalls nicht schwierig - geben Sie einfach die Konfigurationsdatei in das neue Verzeichnis ein.  Darin befinden sich die Dateien: service.hcl, die eine Beschreibung unseres Dienstes enthalten, und einige env-Dateien, mit denen dieser Dienst, der in der Produktion bereitgestellt wird, konfiguriert werden kann. <br><br><img src="https://habrastorage.org/webt/-g/l7/8h/-gl78hl7nbmdbhbuacuntgxw4ow.jpeg" alt="Bild"><br><br>  Einige unserer Systeme werden jedoch nicht in einer Kopie, sondern in mehreren gleichzeitig im Produkt bereitgestellt.  Aus diesem Grund haben wir beschlossen, dass es f√ºr uns zweckm√§√üig ist, Konfigurationen nicht in ihrer reinen Form, sondern in ihrer Vorlagenform zu speichern.  Und als Vorlagensprache haben wir <i>jinja 2 gew√§hlt</i> .  In diesem Format speichern wir sowohl die Konfigurationen des Dienstes selbst als auch die daf√ºr ben√∂tigten env-Dateien. <br><br>  Dar√ºber hinaus haben wir im Repository eine gemeinsame Skriptbereitstellung f√ºr alle Projekte bereitgestellt, mit der Sie Ihren Service in der Produktion, in der richtigen Umgebung und am richtigen Ziel starten und bereitstellen k√∂nnen.  In dem Fall, als wir unsere HCL-Konfiguration in eine Vorlage verwandelten, sah die HCL-Datei, die zuvor eine regul√§re Nomad-Konfiguration war, in diesem Fall etwas anders aus. <br><br><img src="https://habrastorage.org/webt/9a/ib/zv/9aibzvsme34ra2eg53bjfbqt1tw.jpeg" alt="Bild"><br><br>  Das hei√üt, wir haben einige Variablen in der Konfigurationsdatei durch Variableneinf√ºgungen ersetzt, die aus env-Dateien oder aus anderen Quellen stammen.  Dar√ºber hinaus konnten wir HL-Dateien dynamisch erfassen, dh wir k√∂nnen nicht nur die √ºblichen Variableneinf√ºgungen verwenden.  Da jinja Schleifen und Bedingungen unterst√ºtzt, k√∂nnen Sie dort auch Konfigurationsdateien erstellen, die je nachdem, wo genau Sie Ihre Anwendungen bereitstellen, variieren. <br><br>  Sie m√∂chten Ihren Service beispielsweise in der Vorproduktion und in der Produktion bereitstellen.  Angenommen, Sie m√∂chten in der Vorproduktion keine Crown-Skripte ausf√ºhren, sondern den Dienst nur in einer separaten Dom√§ne anzeigen, um sicherzustellen, dass er funktioniert.  F√ºr jeden, der einen Dienst bereitstellt, sieht der Prozess sehr einfach und transparent aus.  Es reicht aus, die Datei deploy.sh auszuf√ºhren, anzugeben, welchen Dienst Sie bereitstellen m√∂chten und in welchem ‚Äã‚ÄãZiel.  Sie m√∂chten beispielsweise ein bestimmtes System in Russland, Wei√ürussland oder Kasachstan bereitstellen.  √Ñndern Sie dazu einfach einen der Parameter, und Sie erhalten die richtige Konfigurationsdatei. <br><br>  Wenn der Nomad-Dienst bereits in Ihrem Cluster bereitgestellt ist, sieht dies folgenderma√üen aus. <br><br><img src="https://habrastorage.org/webt/nu/au/8d/nuau8dqdcwft0boyw57x37wrkcm.jpeg" alt="Bild"><br><br>  Zuerst ben√∂tigen Sie einen Balancer au√üerhalb, der den gesamten Benutzerverkehr in sich aufnimmt.  Er wird mit Consul zusammenarbeiten und von ihm herausfinden, wo, auf welchem ‚Äã‚ÄãKnoten, unter welcher IP-Adresse sich ein bestimmter Dienst befindet, der einem bestimmten Domainnamen entspricht.  Dienstleistungen in Consul kommen von Nomad selbst.  Da es sich um Produkte desselben Unternehmens handelt, sind sie gut miteinander verbunden.  Wir k√∂nnen sagen, dass Nomad out of the box alle darin eingef√ºhrten Dienste in Consul registrieren kann. <br><br>  Nachdem Ihr externer Balancer herausgefunden hat, an welchen Dienst Datenverkehr gesendet werden muss, leitet er ihn an den entsprechenden Container oder an mehrere Container weiter, die Ihrer Anwendung entsprechen.  Nat√ºrlich muss man auch √ºber Sicherheit nachdenken.  Obwohl alle Dienste auf denselben virtuellen Maschinen in Containern ausgef√ºhrt werden, erfordert dies normalerweise das Verbot des freien Zugriffs von jedem Dienst auf einen anderen.  Dies haben wir durch Segmentierung erreicht.  Jeder Dienst wurde in einem eigenen virtuellen Netzwerk gestartet, in dem Routing-Regeln und Regeln zum Zulassen / Verweigern des Zugriffs auf andere Systeme und Dienste vorgeschrieben wurden.  Sie k√∂nnen sich sowohl innerhalb als auch au√üerhalb dieses Clusters befinden.  Wenn Sie beispielsweise verhindern m√∂chten, dass ein Dienst eine Verbindung zu einer bestimmten Datenbank herstellt, kann dies durch Segmentierung auf Netzwerkebene erfolgen.  Das hei√üt, auch aus Versehen k√∂nnen Sie nicht versehentlich eine Verbindung von einer Testumgebung zu Ihrer Produktionsbasis herstellen. <br><br>  Was hat uns der √úbergang in Bezug auf die Humanressourcen gekostet? <br><br>  Der √úbergang des gesamten Unternehmens zu Nomad dauerte ca. 5-6 Monate.  Wir haben ohne Service gewechselt, aber ziemlich schnell.  Jedes Team musste seine eigenen Container f√ºr Dienstleistungen erstellen. <br><br>  Wir haben einen solchen Ansatz gew√§hlt, dass jedes Team f√ºr die Docker-Images seiner Systeme selbst verantwortlich ist.  Devops stellen auch die allgemeine Infrastruktur bereit, die f√ºr die Bereitstellung erforderlich ist, dh Unterst√ºtzung f√ºr den Cluster selbst, Unterst√ºtzung f√ºr das CI-System usw.  Zu dieser Zeit hatten wir mehr als 60 Systeme auf Nomad umgestellt, es stellte sich heraus, dass es ungef√§hr zweitausend Container waren. <br><br>  Devops ist f√ºr die gesamte Infrastruktur aller mit der Bereitstellung verbundenen Server verantwortlich.  Und jedes Entwicklungsteam ist wiederum f√ºr die Implementierung von Containern f√ºr sein spezifisches System verantwortlich, da es das Team ist, das wei√ü, was es im Allgemeinen in einem bestimmten Container ben√∂tigt. <br><br><h1>  Gr√ºnde f√ºr das Verlassen von Nomad </h1><br>  Welche Vorteile haben wir durch den Wechsel zur Bereitstellung mit Nomad und Docker erzielt? <br><br><ol><li>  Wir haben f√ºr alle Umgebungen <b>die gleichen Bedingungen bereitgestellt</b> .  In einer Entwicklungsfirma, QS-Umgebung, Vorproduktion, Produktion werden dieselben Container-Images mit denselben Abh√§ngigkeiten verwendet.  Dementsprechend haben Sie praktisch keine Chance, dass sich die Produktion von der unterscheidet, die Sie zuvor lokal oder in einer Testumgebung getestet haben. </li><li>  Wir haben auch festgestellt, dass es <b>einfach</b> genug ist <b>, einen neuen Service hinzuzuf√ºgen</b> .  Aus Sicht der Bereitstellung werden neue Systeme sehr einfach gestartet.  Es reicht aus, in das Repository zu gehen, in dem die Konfigurationen gespeichert sind, dort die n√§chste Konfiguration f√ºr Ihr System hinzuzuf√ºgen, und schon sind Sie bereit.  Sie k√∂nnen Ihr System ohne zus√§tzlichen Aufwand von Entwicklern in der Produktion bereitstellen. </li><li>  Es <b>stellte sich heraus, dass</b> alle <b>Konfigurationsdateien</b> in einem gemeinsamen Repository <b>√ºberwacht wurden</b> .  In diesem Moment, als wir unsere Systeme mithilfe virtueller Server bereitstellten, verwendeten wir Ansible, in dem sich die Konfigurationen im selben Repository befanden.  F√ºr die meisten Entwickler war es jedoch etwas schwieriger, damit zu arbeiten.  Hier ist das Volumen an Konfigurationen und Code, das Sie hinzuf√ºgen m√ºssen, um den Dienst bereitzustellen, viel kleiner geworden.  Au√üerdem ist es f√ºr Entwickler sehr einfach, es zu reparieren oder zu √§ndern.  Bei √úberg√§ngen, beispielsweise in der neuen Version von Nomad, k√∂nnen sie alle an derselben Stelle liegenden Betriebsdateien aufnehmen und massiv aktualisieren. </li></ol><br>  Wir hatten aber auch einige M√§ngel: <br><br>  Es stellte sich heraus, dass wir im Fall von Nomad <b>keine nahtlosen Bereitstellungen erreichen konnten</b> .  Wenn Container unter verschiedenen Bedingungen gerollt werden, kann sich herausstellen, dass sie ausgef√ºhrt werden, und Nomad hat sie als Container wahrgenommen, der bereit ist, Verkehr aufzunehmen.  Dies geschah noch bevor die darin enthaltene Anwendung gestartet werden konnte.  Aus diesem Grund begann das System f√ºr kurze Zeit 500 Fehler zu erzeugen, da der Verkehr zu dem Container ging, der noch nicht bereit ist, ihn zu empfangen. <br><br>  Wir sind auf einige <b>Fehler</b> gesto√üen.  Der gr√∂√üte Fehler ist, dass Nomad einen gro√üen Cluster nicht sehr gut akzeptiert, wenn Sie √ºber viele Systeme und Container verf√ºgen.  Wenn Sie einen der im Nomad-Cluster enthaltenen Server in Betrieb nehmen m√∂chten, besteht eine hohe Wahrscheinlichkeit, dass sich der Cluster nicht sehr gut anf√ºhlt und auseinander f√§llt.  Ein Teil der Container kann beispielsweise fallen und nicht steigen - dies ist anschlie√üend f√ºr Sie sehr teuer, wenn sich alle Ihre Produktionssysteme in einem von Nomad verwalteten Cluster befinden. <br><br>  Aus diesem Grund haben wir uns √ºberlegt, wohin wir als n√§chstes gehen sollen.  Zu dieser Zeit wurden wir uns viel besser bewusst, was wir erreichen wollen.  Wir wollen n√§mlich Zuverl√§ssigkeit, etwas mehr Funktionen als Nomad und ein ausgereifteres, stabileres System. <br><br>  In dieser Hinsicht fiel unsere Wahl auf Kubernetes als beliebteste Plattform f√ºr den Start von Clustern.  Vor allem, wenn die Gr√∂√üe und Menge unserer Container recht gro√ü war.  F√ºr solche Zwecke schien Kubernetes das am besten geeignete System von denen zu sein, die wir sehen konnten. <br><br><h1>  Ich gehe nach Kubernetes </h1><br>  Ich werde ein wenig √ºber die Grundkonzepte von Kubernetes sprechen und wie sie sich von Nomad unterscheiden. <br><br><img src="https://habrastorage.org/webt/pv/eh/va/pvehvavusoxszoxum9bsuwyjqbc.jpeg" alt="Bild"><br><br>  Das grundlegendste Konzept in Kubernetes ist zun√§chst das Konzept des Pods.  <b>Ein Pod</b> ist eine Gruppe von einem oder mehreren Containern, die immer zusammen laufen.  Und sie scheinen immer streng auf derselben virtuellen Maschine zu arbeiten.  Sie stehen einander √ºber IP 127.0.0.1 an verschiedenen Ports zur Verf√ºgung. <br><br>  Angenommen, Sie haben eine PHP-Anwendung, die aus nginx und php-fpm besteht - eine klassische Schaltung.  H√∂chstwahrscheinlich m√∂chten Sie, dass sowohl Nginx- als auch PHP-Fpm-Container immer zusammen sind.  Kubernetes beschreibt dies als einen gemeinsamen Pod.  Genau das konnten wir mit Hilfe von Nomad nicht erreichen. <br><br>  Das zweite Konzept ist die <b>Bereitstellung</b> .  Tatsache ist, dass die Kapsel selbst eine verg√§ngliche Sache ist, sie beginnt und verschwindet.  Egal, ob Sie zuerst alle Ihre vorherigen Container beenden und dann neue Versionen auf einmal starten oder sie schrittweise einf√ºhren m√∂chten - genau f√ºr dieses Konzept ist die Bereitstellung verantwortlich.  Es wird beschrieben, wie Sie Ihre Pods bereitstellen, wie viele und wie Sie sie aktualisieren. <br><br>  Das dritte Konzept ist <b>Service</b> .  Ihr Dienst ist eigentlich Ihr System, das Datenverkehr empf√§ngt und ihn dann an einen oder mehrere Pods weiterleitet, die Ihrem Dienst entsprechen.  Das hei√üt, Sie k√∂nnen sagen, dass der gesamte eingehende Verkehr zu einem solchen Dienst mit einem solchen Namen an diese bestimmten Pods gesendet werden muss.  Gleichzeitig erhalten Sie einen Verkehrsausgleich.  Das hei√üt, Sie k√∂nnen zwei Pods Ihrer Anwendung ausf√ºhren, und der gesamte eingehende Datenverkehr wird gleichm√§√üig zwischen den Pods verteilt, die sich auf diesen Dienst beziehen. <br><br>  Und das vierte Grundkonzept ist <b>Ingress</b> .  Dies ist ein Dienst, der in einem Kubernetes-Cluster ausgef√ºhrt wird.  Es fungiert als externer Load Balancer, der alle Anforderungen √ºbernimmt.  Aufgrund der API kann Kubernetes Ingress bestimmen, wohin diese Anforderungen gesendet werden sollen.  Und er macht es sehr flexibel.  Sie k√∂nnen sagen, dass alle Anforderungen an diesen Host und diese URL an diesen Dienst gesendet werden.  Und wir senden diese Anfragen an diesen Host und an eine andere URL an einen anderen Dienst. <br><br>  Das Coolste aus der Sicht des Entwicklers der Anwendung ist, dass Sie alles selbst verwalten k√∂nnen.  Nachdem Sie die Ingress-Konfiguration festgelegt haben, k√∂nnen Sie den gesamten Datenverkehr, der zu einer solchen API kommt, an separate registrierte Container senden, z. B. an Go.  Dieser Datenverkehr, der zu derselben Domain, aber zu einer anderen URL gelangt, sollte an in PHP geschriebene Container gesendet werden, in denen viel Logik vorhanden ist, die jedoch nicht sehr schnell sind. <br><br>  Wenn wir alle diese Konzepte mit Nomad vergleichen, k√∂nnen wir sagen, dass die ersten drei Konzepte alle zusammen Service sind.  Und das letzte Konzept in Nomad selbst fehlt.  Wir haben einen externen Balancer verwendet: Es kann Haproxy, Nginx, Nginx + und so weiter sein.  Im Falle eines W√ºrfels m√ºssen Sie dieses zus√§tzliche Konzept nicht separat einf√ºhren.  Wenn Sie sich jedoch Ingress im Inneren ansehen, handelt es sich entweder um Nginx, Haproxy oder Traefik, aber als ob es in Kubernetes eingebaut w√§re. <br><br>  Alle von mir beschriebenen Konzepte sind im Wesentlichen die Ressourcen, die im Kubernetes-Cluster vorhanden sind.  Um sie im Cube zu beschreiben, wird das Yaml-Format verwendet, das lesbarer und vertrauter ist als die HCl-Dateien im Fall von Nomad.  Aber strukturell beschreiben sie beispielsweise im Fall von Pod das Gleiche.  Sie sagen - ich m√∂chte solche und solche Pods hier und da mit solchen und solchen Bildern in dieser und jener Menge einsetzen. <br><br><img src="https://habrastorage.org/webt/2k/ka/53/2kka53a1vp1lm0rnl4xbhmcpyu4.jpeg" alt="Bild"><br><br>  Dar√ºber hinaus haben wir festgestellt, dass wir nicht jede einzelne Ressource mit unseren eigenen H√§nden erstellen m√∂chten: Bereitstellung, Services, Ingress und mehr.  Stattdessen wollten wir jedes bereitgestellte System w√§hrend der Bereitstellung in Form von Kubernetes beschreiben, damit wir nicht alle erforderlichen Ressourcenabh√§ngigkeiten manuell in der richtigen Reihenfolge neu erstellen m√ºssen.  Helm wurde als das System gew√§hlt, das uns dies erm√∂glichte. <br><br><h1>  Schl√ºsselkonzepte bei Helm </h1><br>  Helm ist <b>Paketmanager</b> f√ºr Kubernetes.  Es ist sehr √§hnlich wie Paketmanager in Programmiersprachen arbeiten.  Mit ihnen k√∂nnen Sie einen Dienst, der beispielsweise aus Deployment Nginx, Deployment PHP-Fpm, einer Konfiguration f√ºr Ingress, Configmaps (dies ist eine Entit√§t, mit der Sie Env und andere Parameter f√ºr Ihr System festlegen k√∂nnen) in Form von sogenannten Diagrammen speichern.  Gleichzeitig <b>l√§uft</b> Helm <b>auf Kubernetes</b> .  Das hei√üt, dies ist kein System, das beiseite steht, sondern nur ein weiterer Dienst, der im Cube ausgef√ºhrt wird.  Sie interagieren mit ihm √ºber seine API √ºber einen Konsolenbefehl.  Bequem und charmant ist, dass Ihre Dienste auch dann nicht verschwinden, wenn das Ruder bricht oder Sie es aus dem Cluster entfernen, da das Ruder im Wesentlichen nur zum Starten des Systems dient.  Kubernetes selbst ist f√ºr die Verf√ºgbarkeit und den Status der Dienste verantwortlich. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben auch erkannt, dass die </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Standardisierung</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , die zuvor durch die Einf√ºhrung von Jinja in unseren Konfigurationen unabh√§ngig durchgef√ºhrt werden musste, eines der Hauptmerkmale des Ruders ist. Alle Konfigurationen, die Sie f√ºr Ihre Systeme erstellen, werden in helm in Form von Vorlagen gespeichert, die ein bisschen wie jinja √§hneln, aber tats√§chlich die Go-Sprachvorlage verwenden, in der helm geschrieben ist, wie Kubernetes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Helm f√ºgt uns weitere zus√§tzliche Konzepte hinzu. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Diagramm</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ist eine Beschreibung Ihres Dienstes. Andere Paketmanager w√ºrden es Paket, Bundle oder √§hnliches nennen. Dies wird hier als Diagramm bezeichnet. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Werte</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sind die Variablen, mit denen Sie Ihre Konfigurationen aus Vorlagen erstellen m√∂chten. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lassen Sie los</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Jedes Mal, wenn ein Dienst, der mithilfe von helm bereitgestellt wird, eine inkrementelle Version der Version erh√§lt. Helm merkt sich, wie die Servicekonfiguration im vorherigen, im Jahr vor der letzten Version usw. war. Wenn Sie ein Rollback durchf√ºhren m√ºssen, f√ºhren Sie einfach den Befehl helm callback aus und geben Sie die vorherige Version der Version an. Auch wenn zum Zeitpunkt des Rollbacks die entsprechende Konfiguration in Ihrem Repository nicht verf√ºgbar ist, merkt sich helm immer noch, was es war, und setzt Ihr System auf den Zustand zur√ºck, in dem es in der vorherigen Version war. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn wir helm verwenden, werden die √ºblichen Konfigurationen f√ºr Kubernetes auch zu Vorlagen, in denen es m√∂glich ist, Variablen und Funktionen zu verwenden und bedingte Operatoren anzuwenden. Auf diese Weise k√∂nnen Sie die Konfiguration Ihres Dienstes abh√§ngig von der Umgebung erfassen.</font></font><br><br><img src="https://habrastorage.org/webt/dc/lr/fh/dclrfhbdr29ms0gouz_pvd8xz44.jpeg" alt="Bild"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In der Praxis haben wir uns entschlossen, etwas anders zu machen als im Fall von Nomad. Wenn in Nomad im selben Repository sowohl Konfigurationen f√ºr die Bereitstellung als auch n-Variablen gespeichert wurden, die f√ºr die Bereitstellung unseres Dienstes erforderlich waren, haben wir uns hier entschieden, sie in zwei separate Repositorys aufzuteilen. Nur die f√ºr die Bereitstellung erforderlichen n-Variablen werden im Bereitstellungsrepository gespeichert, und Konfigurationen oder Diagramme werden im Steuerungsrepository gespeichert. </font></font><br><br><img src="https://habrastorage.org/webt/2r/lo/yt/2rloytnvlrj6nri8vj7e9-hccg8.jpeg" alt="Bild"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Was hat es uns gegeben?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trotz der Tatsache, dass wir keine wirklich sensiblen Daten in den Konfigurationsdateien selbst speichern. Zum Beispiel Datenbankkennw√∂rter. Sie werden in Kubernetes als Geheimnisse gespeichert, aber es gibt noch einige Dinge, die wir nicht jedem in einer Reihe Zugriff gew√§hren m√∂chten. Daher ist der Zugriff auf das Bereitstellungsrepository eingeschr√§nkter, und das Steuerrepository enth√§lt lediglich eine Beschreibung des Dienstes. Aus diesem Grund ist es m√∂glich, einem gr√∂√üeren Personenkreis sicher Zugang zu gew√§hren. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Da wir dank dieser Trennung nicht nur √ºber die Produktion, sondern auch √ºber andere Umgebungen verf√ºgen, k√∂nnen wir unsere Steuerkarten wiederverwenden, um Services nicht nur f√ºr die Produktion, sondern beispielsweise auch f√ºr die QS-Umgebung bereitzustellen. Selbst </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wenn Sie</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sie lokal mit </font><i><font style="vertical-align: inherit;">Minikube</font></i><font style="vertical-align: inherit;"> bereitstellen, k√∂nnen Sie </font><font style="vertical-align: inherit;">Kubernetes lokal ausf√ºhren.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In jedem Repository haben wir f√ºr jeden Service eine Trennung in separate Verzeichnisse hinterlassen. Das hei√üt, in jedem Verzeichnis befinden sich Vorlagen, die sich auf das entsprechende Diagramm beziehen und die Ressourcen beschreiben, die zum Starten unseres Systems bereitgestellt werden m√ºssen. Im Bereitstellungs-Repository haben wir nur enves hinterlassen. In diesem Fall haben wir kein Templating mit Jinja verwendet, da das Ruder selbst das Templating sofort bereitstellt - dies ist eine seiner Hauptfunktionen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben das Bereitstellungsskript deploy.sh verlassen, das den Start f√ºr die Bereitstellung mithilfe von helm vereinfacht und standardisiert. </font><font style="vertical-align: inherit;">Daher sieht die Bereitstellungsschnittstelle f√ºr alle Benutzer der Bereitstellung genauso aus wie bei der Bereitstellung √ºber Nomad. </font><font style="vertical-align: inherit;">Dieselbe deploy.sh, der Name Ihres Dienstes und der Ort, an dem Sie ihn bereitstellen m√∂chten. </font><font style="vertical-align: inherit;">Dies f√ºhrt dazu, dass das Ruder im Inneren startet. </font><font style="vertical-align: inherit;">Er sammelt wiederum Konfigurationen aus Vorlagen, ersetzt die erforderlichen Wertedateien in ihnen, stellt sie dann bereit und legt sie in Kubernetes ab.</font></font><br><br><h1>  Schlussfolgerungen </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Der Kubernetes-Service sieht komplexer aus als Nomad. </font></font><br><br><img src="https://habrastorage.org/webt/fe/p6/qi/fep6qibp6hhnbsmqifk2jnmg20a.jpeg" alt="Bild"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hier kommt ausgehender Datenverkehr zu Ingress. Dies ist nur der Front-Controller, der alle Anforderungen empf√§ngt und sie anschlie√üend an die den Anforderungsdaten entsprechenden Dienste sendet. Sie werden anhand von Konfigurationen definiert, die Teil der Beschreibung Ihrer Anwendung in helm sind und die Entwickler unabh√§ngig voneinander festlegen. Der Dienst sendet Anforderungen an seine Pods, dh an bestimmte Container, und gleicht den eingehenden Datenverkehr zwischen allen Containern aus, die zu diesem Dienst geh√∂ren. Vergessen Sie nat√ºrlich nicht, dass wir auf Netzwerkebene nicht von der Sicherheit abweichen sollten. Daher betreibt der Kubernetes-Cluster eine Segmentierung, die auf Tagging basiert. Alle Dienste verf√ºgen √ºber bestimmte Tags, an die die Zugriffsrechte von Diensten auf bestimmte externe / interne Ressourcen innerhalb oder au√üerhalb des Clusters angeh√§ngt sind.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">W√§hrend des √úbergangs haben wir gesehen, dass Kubernetes alle Funktionen von Nomad bietet, die wir zuvor verwendet haben, und auch viele neue Funktionen hinzuf√ºgt. Es kann durch Plugins und sogar durch benutzerdefinierte Ressourcentypen erweitert werden. Das hei√üt, Sie haben nicht nur die M√∂glichkeit, etwas zu verwenden, das sofort in Kubernetes eingeht, sondern auch Ihre eigene Ressource und Ihren eigenen Dienst zu erstellen, die Ihre Ressource lesen. Dies bietet zus√§tzliche Optionen zum Erweitern Ihres Systems, ohne dass Kubernetes neu installiert werden muss und ohne dass √Ñnderungen erforderlich sind.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ein Beispiel hierf√ºr ist Prometheus, das in unserem Kubernetes-Cluster ausgef√ºhrt wird. Damit er Metriken von einem bestimmten Dienst erfassen kann, m√ºssen wir der Dienstbeschreibung einen zus√§tzlichen Ressourcentyp hinzuf√ºgen, den sogenannten Dienstmonitor. Prometheus beginnt aufgrund der Tatsache, dass es lesen kann, automatisch mit dem Sammeln von Metriken aus dem neuen System, wenn es in Kubernetes, einem benutzerdefinierten Ressourcentyp, gestartet wird. Es ist sehr praktisch.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der erste Einsatz bei Kubernetes erfolgte im M√§rz 2018. </font><font style="vertical-align: inherit;">Und in dieser Zeit hatten wir nie Probleme mit ihm. </font><font style="vertical-align: inherit;">Es funktioniert stabil genug ohne signifikante Fehler. </font><font style="vertical-align: inherit;">Dar√ºber hinaus k√∂nnen wir es weiter ausbauen. </font><font style="vertical-align: inherit;">Heute haben wir genug von den M√∂glichkeiten, die es bietet, und wir m√∂gen das Entwicklungstempo von Kubernetes sehr. </font><font style="vertical-align: inherit;">Derzeit befinden sich mehr als 3.000 Container in Kubernetes. </font><font style="vertical-align: inherit;">Der Cluster ben√∂tigt mehrere Knoten. </font><font style="vertical-align: inherit;">Gleichzeitig ist es gewartet, stabil und sehr kontrolliert.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de451644/">https://habr.com/ru/post/de451644/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de451634/index.html">Wie wir in Gesch√§ften und Restaurants analysiert werden</a></li>
<li><a href="../de451636/index.html">F√ºnf Jahre Sklaverei</a></li>
<li><a href="../de451638/index.html">Animation in mobilen Anwendungen: Testen von Lottie</a></li>
<li><a href="../de451640/index.html">Game of Thrones: Erstellen von Infografiken zu Morden, Sex, Reisen in Westeros und mehr</a></li>
<li><a href="../de451642/index.html">Einen Weg zwischen runden Hindernissen finden</a></li>
<li><a href="../de451646/index.html">Die Produktion des Rumpfes des Raumschiffs der F√∂deration hat begonnen</a></li>
<li><a href="../de451648/index.html">Wie haben wir nach ungew√∂hnlichem Tourismus in Russland gesucht und welche Art von Abenteuern finden im Allgemeinen statt?</a></li>
<li><a href="../de451650/index.html">Teil I. Fragen Sie Ihre Mutter: Wie k√∂nnen Sie mit Kunden kommunizieren und die Richtigkeit ihrer Gesch√§ftsidee best√§tigen, wenn alle herumliegen?</a></li>
<li><a href="../de451652/index.html">Teil II Fragen Sie Ihre Mutter: Wie k√∂nnen Sie mit Kunden kommunizieren und die Richtigkeit ihrer Gesch√§ftsidee best√§tigen, wenn alle herumliegen?</a></li>
<li><a href="../de451654/index.html">Neuer Mitarbeiter - tot oder lebendig</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
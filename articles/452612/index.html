<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🆖 🤵🏿 💣 Aprendizaje automático reforzado de redes neuronales profundas en tensorflow.js: trucos 🏈 👂🏻 🤜🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Entrenar redes neuronales profundas desde cero no es una tarea fácil. 

 Se necesitan muchos datos y tiempo para aprender, pero algunos trucos pueden ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aprendizaje automático reforzado de redes neuronales profundas en tensorflow.js: trucos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452612/">  Entrenar redes neuronales profundas desde cero no es una tarea fácil. <br><br>  Se necesitan muchos datos y tiempo para aprender, pero algunos trucos pueden ayudar a acelerar el proceso, del que hablaré más adelante. <br><br>  Demostración del paso de un laberinto simple utilizando trucos.  Duración del entrenamiento de red: 1 hora 06 minutos.  Grabación acelerada 8 veces. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/KbuNjZKidpw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  Para cada tarea, debe desarrollar su propio conjunto de trucos para acelerar el aprendizaje en red.  Compartiré algunos trucos que me ayudaron a entrenar la red mucho más rápido. <br><br>  Para conocimientos teóricos, recomiendo cambiar al canal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sim0nsays</a> . <br>  Y contaré sobre mis modestos éxitos en el entrenamiento de redes neuronales. <br><br><h2>  Declaración del problema. </h2><br>  <i>Aproximar la función de convergencia minimizando la función de pérdida cuadrática mediante la propagación hacia atrás del error por redes neuronales profundas.</i> <br><br>  Tenía una opción de estrategia sobre cómo entrenar una red neuronal. <br>  Fomente la finalización exitosa de la tarea o aliente a medida que se acerca a la finalización de la tarea. <br><br>  Elegí el segundo método, por dos razones: <br><br><ul><li>  La probabilidad de que la red llegue a la línea de meta por sí sola es muy pequeña, por lo que estará condenada a recibir mucho refuerzo negativo.  Esto restablecerá los pesos de todas las neuronas y la red no será capaz de seguir entrenando. <br></li><li>  Las redes neuronales profundas son poderosas.  No excluyo que el primer método hubiera sido exitoso si tuviera una gran potencia informática y mucho tiempo para la capacitación.  Tomé el camino de menor costo desarrollando trucos. <br></li></ul><br><h2>  Arquitectura de red neuronal </h2><br>  La arquitectura se está desarrollando experimentalmente, basada en la experiencia del arquitecto y la buena suerte. <br><br>  Arquitectura para resolver el problema: <br><br><ul><li>  3 neuronas de entrada: las coordenadas del agente y el valor de la célula pasada (normalizamos en el rango de 0 a 1). <br></li><li>  2 capas ocultas de 256 y 128 neuronas (reducimos la dimensión de las capas hacia la salida de la red). <br></li><li>  1 capa de caída de neuronas aleatorias para la red de aprendizaje de sostenibilidad. <br></li><li>  4 neuronas de salida: la probabilidad de decidir qué lado elegir para el siguiente paso. <br></li><li>  Función de activación neuronal: sigmoidea.  Optimizador: Adam. <br></li></ul><br>  sigmoid da 4 probabilidades en la salida en el rango de 0 a 1, eligiendo el máximo, obtenemos el lado para el siguiente paso: [jumpTop, jumpRight, jumpBottom, jumpLeft]. <br><br><h2>  Desarrollo de la arquitectura </h2><br>  La reentrenamiento ocurre cuando se usan modelos demasiado complejos. <br><br>  Esto es cuando la red recordó los datos de entrenamiento y para los nuevos datos que la red aún no ha visto, funcionará mal porque la red no necesitaba buscar generalizaciones, ya que tenía suficiente memoria para memorizar. <br><br>  Falta de educación - con modelos insuficientemente complejos.  Esto es cuando la red tenía pocos datos de entrenamiento para encontrar generalizaciones. <br><br>  <b>Conclusión: cuantas</b> más capas y neuronas contengan, más datos se necesitan para el entrenamiento. <br><br><h2>  Campo de juego </h2><br><img src="https://habrastorage.org/webt/3n/we/ck/3nweckh5jsx0-pfebojf_yq3n3k.png"><br><br><h3>  Reglas del juego </h3><br>  0: al ingresar a esta celda, el agente se destruye. <br>  1..44 - Celdas cuyos valores aumentan con cada paso. <br>  Cuanto más lejos vaya el agente, más recompensa recibirá. <br>  45 - Acabado.  Al mismo tiempo, el entrenamiento no ocurre, solo cuando todos los agentes son destruidos, y el final es una excepción que simplemente usa la red ya entrenada para el próximo pronóstico desde el comienzo del laberinto. <br><br><h2>  Descripción de los parámetros. </h2><br>  El agente tiene una "antena" en cuatro direcciones: desempeña el papel de inteligencia ambiental y es una descripción de las coordenadas del agente y el valor de la celda en la que se encuentra. <br><br>  La descripción juega el papel de predecir la siguiente dirección para el movimiento del agente.  Es decir, el agente escanea de antemano lo que sigue y, en consecuencia, con el tiempo, la red aprende a moverse en la dirección de aumentar el valor de la celda y no ir más allá de los límites del movimiento permisible. <br><br>  <b>El propósito de la red neuronal:</b> obtener más recompensas. <br>  <b>Propósito de aprendizaje: para</b> alentar las acciones correctas, cuanto más cerca esté el agente de resolver la tarea, mayor será la recompensa para la red neuronal. <br><br><h2>  Trucos </h2><br>  Los primeros intentos de aprender sin trucos tomaron varias horas de entrenamiento y el resultado estuvo lejos de ser completo.  Aplicando ciertas técnicas, ¡el resultado se logró en solo una hora y seis minutos! <br><br><h3>  Agente en bucle </h3><br>  Durante el entrenamiento, la red comenzó a tomar decisiones, hacer movimientos de ida y vuelta, el problema del "uso".  Ambos movimientos dan a la red una recompensa positiva, que detuvo el proceso de exploración del laberinto y no permitió salir del mínimo local. <br><br>  El primer intento de solución fue limitar el número de movimientos del agente, pero esto no fue óptimo, ya que el agente pasó mucho tiempo en un ciclo antes de la autodestrucción.  La mejor solución era destruir al agente si iba a la celda con un valor más bajo que el que estaba parado: la prohibición de ir en la dirección opuesta. <br><br><h3>  Investigar o usar </h3><br>  Se usó un truco simple para explorar los caminos alrededor de la posición actual del agente: en cada paso, 5 agentes serán investigadores "voluntarios".  El curso de estos agentes se elegirá al azar, y no por el pronóstico de la red neuronal. <br><br>  Por lo tanto, tenemos una mayor probabilidad de que uno de los cinco agentes avance más que los demás y ayude a capacitar a la red con mejores resultados. <br><br><h3>  Algoritmo genético </h3><br>  Cada era, 500 agentes participan en el campo de juego.  Las predicciones para todos los agentes se realizan en modo asíncrono para todos los agentes a la vez, además, los cálculos se delegan a gpu.  Por lo tanto, obtenemos un uso más eficiente de la potencia informática de la computadora, lo que conduce a una reducción en el tiempo para predecir una red neuronal para 500 agentes al mismo tiempo. <br><br>  La predicción funciona más rápido que el entrenamiento, por lo que la red tiene más posibilidades de avanzar por el laberinto con la menor cantidad de tiempo y el mejor resultado. <br><br><h3>  Aprendiendo lo mejor de la generación </h3><br>  A lo largo de la era, para 500 agentes, se conservan los resultados de su avance a través del laberinto.  Cuando se destruye el último agente, se seleccionan los 5 mejores agentes de cada 500, que llegaron más lejos al laberinto. <br><br>  Con base en los mejores resultados de la era, se capacitará una red neuronal. <br><br>  Por lo tanto, reduciremos la cantidad de memoria utilizada al no guardar y no capacitar a la red en agentes que no avanzan la red. <br><br><h2>  Finalización </h2><br>  Al no ser un especialista en este campo, logré cierto éxito en el entrenamiento de la red neuronal, y usted tendrá éxito, ¡adelante! <br><br>  Esforzarse por aprender más rápido que las computadoras, mientras lo hacemos mejor. <br><br><h3>  Materiales </h3><br>  <a href="">Repositorio con código</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Iniciar la capacitación del navegador</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La documentación de tensorflow.js</a> , donde también puede encontrar recursos adicionales para el aprendizaje. <br><br><h3>  Libros </h3><br><ul><li>  Aprendizaje profundo  Inmersión en el mundo de las redes neuronales. <br>  S. Nikolenko, A. Kadurin, E. Arkhangelskaya <br></li><li>  Aprendizaje automático y TensorFlow <br>  N. Shakla <br></li><li>  Sistemas de autoaprendizaje <br>  S. I. Nikolenko, A. L. Tulupyev <br></li><li>  Entrenamiento de refuerzo <br>  R.S. Sutton, E.G. Barto <br></li><li>  Tarjetas autoorganizadas <br>  T. Kohonen <br></li></ul><br><h2>  Gracias por su atencion! </h2></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/452612/">https://habr.com/ru/post/452612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../452598/index.html">Gestión de un equipo de programadores: ¿cómo y cómo motivarlos correctamente? Primera parte</a></li>
<li><a href="../452602/index.html">Cisco Hyperflex para sistemas de administración de bases de datos de alta carga</a></li>
<li><a href="../452606/index.html">UDB Que es esto Parte 8. Abordar UDB</a></li>
<li><a href="../452608/index.html">Parte 1. QInst: es mejor perder un día, luego volar en cinco minutos (escribir instrumentos es trivial)</a></li>
<li><a href="../452610/index.html">Ayuda y solicitud por ella. Artículo sobre seguridad de la información para usuarios comunes.</a></li>
<li><a href="../452614/index.html">Cómo comenzar a programar en Adobe Illustrator. Parte dos</a></li>
<li><a href="../452618/index.html">Lo que se dijo en Google I / O 2019: Android 10, aplicaciones AR y mucho más</a></li>
<li><a href="../452620/index.html">Derivar un tipo de acción usando el mecanografiado</a></li>
<li><a href="../452622/index.html">Introducción a la genómica para programadores</a></li>
<li><a href="../452624/index.html">Introducción al actuador Spring Boot</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
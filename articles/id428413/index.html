<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💸 🙏🏿 🧗🏼 Sistem pendingin di pusat data Selectel 😑 🌇 👩‍👧‍👧</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Harga kompetitif untuk layanan selalu menjadi "raja argumen" bagi pelanggan saat memilih pusat data. Dan apa harga ini terdiri dari? Yang pertama terl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sistem pendingin di pusat data Selectel</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/428413/"><img src="https://habrastorage.org/webt/wv/ak/ub/wvakubpf21_rfkea8frghkzat0o.png" alt="Ikhtisar: Sistem pendingin di pusat data Selectel"><br><br>  Harga kompetitif untuk layanan selalu menjadi "raja argumen" bagi pelanggan saat memilih pusat data.  Dan apa harga ini terdiri dari?  Yang pertama terlintas dalam pikiran adalah biaya peralatan TI dan listrik, tetapi bagian yang signifikan dalam struktur harga terdiri dari biaya server pendingin, sistem penyimpanan (SHD) dan perangkat jaringan.  Sebagai contoh, server dengan beberapa prosesor memancarkan hingga 600 W atau lebih energi panas, yang harus dihilangkan secara efektif, dan udara dingin harus dipasok ke lubang ventilasi server. <br><br>  Dalam artikel ini, kami akan memperkenalkan Anda dengan teknologi kontrol iklim di pusat data Selectel dan memberi tahu Anda bagaimana produk baru di daerah ini mengurangi biaya pengoperasian pusat data, dan secara tidak langsung, jumlah dalam akun pelanggan kami. <a name="habracut"></a><br><br><h2>  3 pasar layanan - 3 persyaratan pendinginan </h2><br>  Di pasar layanan pusat data, diperkirakan secara kasar, ada tiga segmen utama.  Ini, pertama, colocation, kemudian infrastruktur IaaS - dedicated server plus cloud storage, dan segmen ketiga - cloud server (VPC, VPS, VMware Cloud), termasuk cloud publik, pribadi, dan hybrid. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/8o/4q/ie/8o4qie1csc2qa97pn_b4nwqktr4.png" alt="Diagram Pasar Layanan Layanan Data"></div><br><br>  Tidak peduli betapa mengejutkannya hal itu, tetapi pelanggan dari masing-masing segmen memiliki persyaratan yang berbeda untuk sistem iklim.  Pelanggan yang paling menuntut adalah menempatkan peralatan mereka sendiri (colocation) di pusat data.  Di antara mereka ada banyak manajer TI dengan praktik bertahun-tahun dan gagasan konservatif tentang suhu yang seharusnya ada di ruang server.  10-15 tahun yang lalu, persyaratan untuk menyediakan + 18 ° C di koridor yang dingin sangat penting.  Tetapi server dan penyimpanan modern bekerja dengan stabil hingga suhu + 27 ° C. <br><br>  Omong-omong, kisaran suhu udara spesifik untuk ruang server pusat data agak ketat diatur oleh rekomendasi ASHRAE (Masyarakat Insinyur Pemanasan, Pendinginan, dan Pendingin Udara Amerika), yang dipandu di seluruh dunia, termasuk Rusia.  Kisaran suhu yang disarankan berubah seiring waktu, di suatu tempat di awal 2000-an itu benar-benar 16-20 ° C, kemudian 18-22 ° C, dan hari ini suhu udara yang disarankan untuk server pendingin sudah 20-27 ° C. <br><br><img src="https://habrastorage.org/webt/pq/as/um/pqasumkyisv-zngx6blsdtt2jmq.jpeg" alt="Kirill Malevanov, Selectel CTO" width="130" height="130" align="left" hspace="15" vspace="15">  "Selectel di pusat datanya berusaha mempertahankan suhu udara di dekat batas bawah kisaran yang direkomendasikan menurut ASHRAE, rata-rata, sekitar 23 ° C," kata Kirill Malevanov, Direktur Teknis Selectel untuk artikel itu. <br><br>  Manakah dari ini dapat disimpulkan untuk bisnis pusat data?  Pendinginan yang mahal dengan AC harus digunakan terutama untuk ruang server yang dialokasikan untuk layanan colocation.  Dengan demikian, untuk ruang server untuk layanan IaaS, dan bahkan lebih lagi untuk server cloud, Anda dapat menggunakan peralatan yang memaksimalkan penggunaan pendinginan karena lingkungan - hingga hanya meniup server dengan udara tempel. <br><br>  Pada saat yang sama, karena Selectel memiliki beberapa pusat data, dan di berbagai daerah, ada kebebasan bermanuver.  Dengan kata lain, dimungkinkan untuk mempertimbangkan persyaratan pendinginan di segmen layanan yang dipilih bahkan pada tahap desain, pembangunan pusat data dan pemilihan peralatan iklim.  Dan kemudian dalam proses operasi, untuk memodernisasi sistem iklim, dengan mempertimbangkan pengurangan TCO ketika menyediakan layanan ini. <br><br><h2>  Apa itu PUE? </h2><br>  Ukuran utama efisiensi pusat data adalah rasio efektivitas penggunaan daya (PUE) yang digunakan dalam industri pusat data sejak 2007.  Apa koefisien ini: <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/96/zl/qf/96zlqfrah9utcoz87kv4end7lwq.png" alt="Formula PUE"></div><br>  Dengan kata lain, semakin dekat PUE ke 1, semakin sempurna adalah pusat data.  Namun, tidak mungkin untuk mencapai nilai 1,0 pada prinsipnya, karena ini sesuai dengan tingkat efisiensi energi mesin gerak abadi.  Omong-omong, definisi lengkap dari istilah PUE dapat ditemukan dalam dokumen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">PUE, A Comprehensive Examination of the Metric (PDF)</a> . <br>  Dalam praktiknya, nilai PUE antara 1,10 dan 1,15 dianggap sangat baik.  Misalnya, menurut publikasi, untuk pusat data Google, nilai PUE rata-rata untuk semua pusat data di berbagai wilayah dan pada waktu yang berbeda dalam setahun adalah 1,12. <br>  Selanjutnya, kita akan melihat lebih dekat pada sistem pendingin di pusat data Selectel yang dipilih. <br><br><h2>  "Bunga 1" - Freon </h2><br>  Pusat data Tsvetochnaya 1 pertama dioperasikan pada tahun 2008, ketika layanan colocation dominan di pasar.  Selain itu, ini adalah pusat kota St Petersburg - situasi dengan ruang bebas kemudian agak dibatasi.  Dengan demikian, di pusat data "Bunga 1", AC klasik industri untuk pusat data Freon dipasang, yang beroperasi hingga saat ini. <br>  Prinsip pengoperasian AC seperti itu didasarkan pada transisi freon ke berbagai keadaan agregasi.  Udara dingin di bawah lantai terangkat disuplai ke apa yang disebut "koridor dingin" dengan peralatan komputasi, dan udara panas masuk ke ruang server (ke "koridor panas"), dari tempat itu kembali tersedot ke penukar panas AC, didinginkan dan dimasukkan kembali ke server dan sistem penyimpanan. <br><br><img src="https://habrastorage.org/webt/kb/oc/gs/kbocgs9ssbgl3si67gga6cbcp90.png" alt="Pendinginan pusat data dengan AC"><br>  <sup><i>Pendinginan pusat data dengan AC</i></sup> <br><br>  Efisiensi AC klasik menyisakan banyak yang diinginkan, dan karenanya koefisien efisiensi energi untuk pusat data Flower 1 cukup tinggi menurut standar modern, PUE = 1,7.  Tetapi mengingat layanan colocation disediakan di sini, sangat mungkin untuk menghadapi situasi ini sampai saat modernisasi radikal seluruh pusat data. <br><br><img src="https://habrastorage.org/webt/qy/hx/w1/qyhxw1xpqlwgybi4fxd7zjtefak.jpeg" alt="Pemeriksaan AC di pusat data Bunga 1"><br>  <sup><i>Pemeriksaan pendingin udara di pusat data "Bunga 1"</i></sup> <br><br><h2>  "Dubrovka 1", "Berzarina 1", "Flower 2" - pendingin </h2><br>  Teknologi pendinginan berikutnya di Selectel diuji pada tahun 2010, ketika pusat data Dubrovka 1 dibangun di desa Dubrovka di Wilayah Leningrad.  Di dalamnya, untuk pertama kalinya dalam praktik perusahaan, sistem pendingin chiller diterapkan. <br>  Perbedaan antara sistem pendingin dan pendingin udara freon adalah bahwa larutan glikol yang tidak beku bersirkulasi di dalam pipa antara unit dalam dan luar, yang tetap cair setiap saat dan tidak masuk ke kondisi gas.  Solusi dipompa melalui AC di ruang server, di mana dipanaskan oleh radiator panas dari AC dan dari mana dipompa ke penukar panas eksternal eksternal, yang disebut chiller. <br>  Dalam pendingin, larutan glikol didinginkan menggunakan udara eksternal dan unit kondensasi tambahan.  Kemudian, solusi glikol yang sudah didinginkan kembali dimasukkan ke dalam AC di dalam ruang server pusat data.  Dalam hal ini, pendinginan peralatan komputasi terjadi sesuai dengan skema tradisional - udara dingin disuplai dari bawah melalui lantai yang ditinggikan ke "koridor dingin", dan udara panas pergi ke ruang bersama dan selanjutnya ke penukar panas. <br><img src="https://habrastorage.org/webt/et/ny/mq/etnymqbmnlbmw0lj9x3y7jfquxq.png" alt="Pendingin Pusat Data"><br>  <sup><i>Pendingin Pusat Data</i></sup> <br><br>  Skema dengan koridor dingin dan panas memberikan penghematan energi hingga 5%, sehingga sangat penting untuk mengisolasi kolam udara dingin dan panas (koridor dan penyimpanan udara). <br>  Efisiensi energi dari sirkuit chiller lebih tinggi dibandingkan dengan AC, dan ini disebabkan oleh fakta bahwa kompresor eksternal dan unit kondensor chiller hanya diaktifkan pada suhu sekitar di atas + 12 ° C, dan kipas unit outdoor dihidupkan secara bertahap, ketika suhu pendingin glikol meningkat.  Ini sangat mirip dengan cara kerja sistem pendingin mesin mobil konvensional. <br>  Menurut skema chiller, Selectel membangun pendinginan dari tiga pusat data - Dubrovka 1 (2010), Berzarina 1 (2011) dan Flower 2 (2015).  Dalam kasus pusat data Tsvetochnaya 2, pengalaman operasi mengakumulasikan lebih dari 5 tahun operasi dari pusat data Dubrovka 1 mengenai banyak nuansa pemeliharaan dipertimbangkan.  Ternyata, terlepas dari kesederhanaan luar dari prinsip operasi, sistem chiller agak berubah-ubah dalam operasi dan membutuhkan pemeliharaan yang cermat dan kepatuhan terhadap peraturan.  Anda dapat membaca lebih lanjut tentang pengoperasian sistem pendingin di pusat data Berzarina 1 di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel blog perusahaan kami</a> . <br><br><img src="https://habrastorage.org/webt/rm/h0/d-/rmh0d-hfnvsgaqniw2u2z1bb3ae.jpeg" alt="Koridor dingin di pusat data Flower 2"><br>  <sup><i>Koridor dingin di pusat data Flower Center 2</i></sup> <br><br><h2>  "Dubrovka 3", "Berzarina 2" - pendinginan gratis </h2><br>  Langkah selanjutnya dalam meningkatkan efisiensi energi sistem pendingin diambil di Selectel dalam transisi ke skema pendinginan langsung.  Prinsip operasi freecooling langsung klasik adalah penolakan penukar panas, dan pendinginan peralatan komputasi terjadi karena bertiup dengan udara luar. <br>  Udara tempel melewati saringan, tempat dibersihkan dari debu, dan kemudian memasuki ruang mesin.  Di musim dingin, sesuai kebutuhan, udara dingin pra-diencerkan dengan udara hangat dari server di ruang pencampuran untuk menjaga suhu konstan untuk peralatan bertiup. <br><br><img src="https://habrastorage.org/webt/bv/ae/qv/bvaeqv7ptkti0lktfedorsy2jru.png" alt="Freecooling langsung dengan aftercooling tanpa lantai yang terangkat"><br>  <sup><i>Freecooling langsung dengan aftercooling tanpa lantai yang terangkat</i></sup> <br><br>  Seperti disebutkan di atas, server modern dan sistem penyimpanan beroperasi andal pada suhu di koridor dingin hingga + 27 ° C.  Mengingat iklim Wilayah Leningrad, di mana suhu harian rata-rata jangka panjang bahkan pada bulan Juli adalah + 20 ° C, solusi seperti itu tampaknya cukup bisa diterapkan.  Namun, mengingat catatan suhu + 37,8 ° C, yang dicatat di Wilayah Leningrad pada 2010, tidak mungkin untuk hanya bergantung pada belas kasihan alam.  Ngomong-ngomong, "musim panas tahun 2018" menegaskan kebenaran perhitungan ini. <br>  Karenanya, pusat data Dubrovka 3, yang ditugaskan pada 2013, menggunakan freecooling langsung dengan unit pendingin tambahan (ABHM, mesin pendingin serapan) jika terjadi panas di musim panas.  Udara tempel melewati filter dan kemudian melewati penukar panas ABXM.  Di koridor ruang server yang dingin, udara disuplai di bawah lantai yang ditinggikan. <br><br><img src="https://habrastorage.org/webt/kc/pu/nq/kcpunqokvdjkgdune4-omhr4bwa.png" alt="Pendinginan pusat data sesuai dengan skema freecooling dengan lantai terangkat"><br>  <sup><i>Pendinginan pusat data sesuai dengan skema freecooling dengan lantai terangkat</i></sup> <br><br>  Seperti yang ditunjukkan oleh pengalaman operasi, solusi seperti itu bekerja tanpa menyalakan ABCM ke suhu sekitar + 21 ° C, yang secara praktis berarti bahwa ABCM hanya beroperasi di bulan-bulan musim panas.  Dengan demikian, ini adalah solusi yang cukup hemat energi dengan PUE ~ 1,25. <br>  Keuntungan penting dari ABCHM adalah keamanan lingkungan, karena bekerja pada air biasa tanpa menggunakan freon.  Di antara kelemahan ABXM adalah penukar panas eksternal raksasa, tetapi mengingat penempatan pusat data Dubrovka 3 di hampir bidang yang bersih, ini tidak memainkan peran khusus dalam hal ukuran area untuk peralatan ABXM. <br><br><img src="https://habrastorage.org/webt/gb/oe/o5/gboeo5r8xlb7nagh85ozb54ba8m.png" alt="Sistem pendingin dari data center Dubrovka 3 dengan ABHM"><br>  <sup><i>Sistem pendingin dari pusat data "Dubrovka 3" dengan ABHM</i></sup> <br><br>  Sejak 2013, sistem freecooling langsung dengan aftercooling telah menunjukkan efisiensi tinggi dan akan diimplementasikan kembali dalam pembangunan pusat data Berzarina 2 di Moskow.  Namun, karena ruang yang terbatas, unit setelah pendinginan akan diimplementasikan menggunakan sistem adiabatik. <br><br><h2>  Beberapa kata tentang reservasi </h2><br>  Secara tradisional, sistem pendingin di pusat data Tier III dicadangkan sesuai dengan skema setidaknya N +1.  Ini berarti bahwa harus selalu ada setidaknya satu unit pendingin dalam stok, yang dioperasikan ketika terjadi kecelakaan atau perbaikan (pemeliharaan terjadwal) dari salah satu sistem yang terlibat.  Jadi, di data center Dubrovka 1, 4 mesin ventilasi digunakan untuk freecooling ketika ada kebutuhan untuk 3, dan di pusat data Dubrovka 3, tiga mesin ABHM, yang salah satu dimatikan dan dalam siaga, siap untuk diluncurkan. <br>  Omong-omong, Selectel di pusat datanya berupaya untuk memperketat persyaratan redundansi N +1 sebanyak mungkin, dan tidak memiliki satu tetapi dua sistem pendingin yang berlebihan dalam stok.  Misalnya, di pusat data "Bunga 1" dan "Bunga 2", masing-masing ada 2 pendingin udara cadangan dan pendingin. <br><br><img src="https://habrastorage.org/webt/qx/wl/bd/qxwlbdnbccfscvcfd1odycfgnbs.jpeg" alt="AC di ruang server pusat data Flower 1"><br>  <sup><i>Pendingin udara di ruang server pusat data Flower Center 1 (di tengah)</i></sup> <br><br><h2>  "Berzarina 2" - segera beroperasi </h2><br>  Pada bulan November 2018, sebuah pusat data Berzarina 2 baru dioperasikan di Moskow, di mana untuk pertama kalinya dalam praktik perusahaan skema pendinginan gratis dengan pendinginan setelah menggunakan sistem adiabatik akan diterapkan.  Jika udara luar terlalu panas - dan suhu di Moskow pada musim panas sering melebihi 23 ° C - maka sistem pendingin adiabatik akan menyala. <br><br><img src="https://habrastorage.org/webt/9o/oq/fe/9ooqfepiiawq0y3drnsw1kep-ii.png" alt="Freecooling dengan sistem adiabatik pasca-pendinginan di pusat data Berzarin 2"><br>  <sup><i>Freecooling dengan sistem adiabatik pasca-pendinginan di pusat data "Berzarina 2"</i></sup> <br><br>  Teknologi pendinginan adiabatik didasarkan pada atomisasi air dalam bentuk tetesan kecil di jalur aliran udara, yang memungkinkan pendinginan udara dengan menguapkan air.  Saat menggunakan pelembap tipe semprot, biaya energi untuk proses pendinginan itu sendiri kecil, dibandingkan dengan sistem pendingin lainnya.  Struktur seluler kompleks penghalang yang dapat dibasahi di jalan udara yang dipasok tidak memungkinkan mikrodroplet air untuk masuk lebih jauh ke dalam saluran pusat data.  Pada saat yang sama, tingkat kelembaban tetap dalam nilai yang dapat diterima untuk peralatan IT. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rk/wn/f3/rkwnf3n_n9a7ja0zdh-cnnlqxzq.png" alt="Skema sistem adiabatik Berzarin 2"></div><br>  <sup><i>Sistem adiabatik</i></sup> <br><br><blockquote>  “Ada banyak solusi menarik untuk sistem pendingin di dunia yang menghemat energi.  Namun, tidak mungkin untuk mencoba semua produk baru - Anda perlu mendapatkan pembiayaan, melaksanakan desain, kemudian menyelesaikan pembelian peralatan, persiapan dan commissioning peralatan.  Tahapan pengiriman, pemasangan, penyesuaian, dan pengoperasian adalah semua prosedur yang sangat panjang.  Oleh karena itu, sistem iklim setelah mulai bekerja setidaknya selama satu dekade dan jarang dimodernisasi secara radikal dalam proses pengoperasian pusat data yang sudah dibangun.  Dan produk-produk baru yang menarik sudah datang ke pusat data baru, di mana mereka akan bertahan 10-15 tahun mereka, ”diringkas Kirill Malevanov, direktur teknis Selectel. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id428413/">https://habr.com/ru/post/id428413/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id428401/index.html">Proses pembangunan melalui mata eksploitasi. Pandangan dari sisi lain barikade</a></li>
<li><a href="../id428403/index.html">Intisari acara untuk profesional SDM di bidang TI untuk November 2018</a></li>
<li><a href="../id428407/index.html">6 plot khas sastra dunia</a></li>
<li><a href="../id428409/index.html">Analisis insiden 21 Oktober di github</a></li>
<li><a href="../id428411/index.html">Teknologi Radar: Daftar Bahasa, Alat, dan Platform yang Melewati Tangan Lamoda</a></li>
<li><a href="../id428415/index.html">Tinjauan umum tentang pengontrol cloud TP-Link Omada OC200</a></li>
<li><a href="../id428417/index.html">Pembelajaran Mesin di MatLab / Oktaf: Contoh Algoritma yang Didukung oleh Rumus</a></li>
<li><a href="../id428419/index.html">Seret dan Geser di RecyclerView. Bagian 2: pengontrol seret dan lepas, kisi, dan animasi khusus</a></li>
<li><a href="../id428421/index.html">Sistem yang fleksibel untuk menguji dan mengumpulkan metrik program menggunakan LLVM test-suite sebagai contoh</a></li>
<li><a href="../id428423/index.html">Bagaimana kesepakatan $ 34 miliar antara IBM dan Red Hat akan mengubah pasar TI: para ahli dan analis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî† üß• ü§≥üèº Int√©gration continue dans Yandex. 2e partie üéß üí≥ ü§∂üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans l' article pr√©c√©dent , nous avons parl√© du transfert du d√©veloppement vers un r√©f√©rentiel unique avec une approche de d√©veloppement bas√©e sur des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Int√©gration continue dans Yandex. 2e partie</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/429956/"><p>  Dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> pr√©c√©dent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> nous avons parl√© du transfert du d√©veloppement vers un r√©f√©rentiel unique avec une approche de d√©veloppement bas√©e sur des troncs, avec des syst√®mes unifi√©s pour l'assemblage, les tests, le d√©ploiement et la surveillance, sur les t√¢ches qu'un syst√®me d'int√©gration continue doit r√©soudre pour fonctionner efficacement dans de telles conditions. </p><br><p>  Aujourd'hui, nous parlerons aux lecteurs Habr du dispositif du syst√®me d'int√©gration continue. </p><br><p><img src="https://habrastorage.org/webt/wb/mt/xc/wbmtxcvurtd6cdv1aomjrtcyfw8.png" alt="image"></p><br><p>  Un syst√®me d'int√©gration continue doit fonctionner de mani√®re fiable et rapide.  Le syst√®me doit r√©agir rapidement aux √©v√©nements entrants et ne doit pas entra√Æner de retards suppl√©mentaires dans le processus de livraison des r√©sultats de test √† l'utilisateur.  Les r√©sultats de l'assemblage et des tests doivent √™tre fournis √† l'utilisateur en temps r√©el. </p><a name="habracut"></a><br><p>  Le syst√®me d'int√©gration continue est un syst√®me de traitement de donn√©es en continu avec des retards minimaux. </p><br><p>  Apr√®s avoir envoy√© tous les r√©sultats √† un certain stade (configuration, g√©n√©ration, style, petits tests, tests moyens, etc.), le syst√®me de g√©n√©ration le signale au syst√®me d'int√©gration continue (¬´ferme¬ª le stade), et l'utilisateur voit que pour cette v√©rification et A ce stade, tous les r√©sultats sont connus.  Chaque √©tape se ferme ind√©pendamment.  L'utilisateur re√ßoit plus rapidement un signal utile.  Apr√®s avoir ferm√© toutes les √©tapes, la v√©rification est consid√©r√©e comme termin√©e. </p><br><p>  Pour impl√©menter le syst√®me, nous avons choisi l'architecture <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kappa</a> .  Le syst√®me se compose de 2 sous-syst√®mes: </p><br><ul><li>  Le traitement des √©v√©nements et des donn√©es a lieu dans un circuit en temps r√©el.  Toutes les donn√©es d'entr√©e sont trait√©es comme des flux de donn√©es (flux).  Tout d'abord, les √©v√©nements sont enregistr√©s dans le flux et ce n'est qu'ensuite qu'ils sont trait√©s. </li><li>  Les r√©sultats du traitement des donn√©es sont continuellement √©crits dans la base de donn√©es, o√π passent ensuite les appels via l'API.  Dans l'architecture Kappa, cela s'appelle la couche de desserte. </li></ul><br><p>  Toutes les demandes de modification de donn√©es doivent passer par le circuit en temps r√©el, car l√†, vous devez toujours avoir l'√©tat actuel du syst√®me.  Les demandes de lecture vont uniquement √† la base de donn√©es. </p><br><img src="https://habrastorage.org/webt/fb/bu/ps/fbbups7bcp0zgwvigxv5un9reek.png"><br><br><p>  Dans la mesure du possible, nous suivons la r√®gle de l'ajout uniquement.  Aucune modification ou suppression d'objets, √† l'exception de la suppression d'anciennes donn√©es inutiles. </p><br><p>  Plus de 2 To de donn√©es brutes transitent par le service par jour. </p><br><p>  Avantages: </p><br><ul><li>  Les flux contiennent tous les √©v√©nements et messages.  Nous pouvons toujours comprendre ce qui s'est pass√© et quand.  Le flux peut √™tre per√ßu comme un gros journal. </li><li>  Haute efficacit√© et surcharge minimale.  Il s'agit d'un syst√®me enti√®rement orient√© √©v√©nement, sans aucune perte d'interrogation.  Il n'y a aucun √©v√©nement - nous ne faisons rien de plus. </li><li>  Le code d'application ne traite pratiquement pas les primitives de synchronisation des threads et la m√©moire partag√©e entre les threads.  Cela rend le syst√®me plus fiable. </li><li>  Les processeurs sont bien isol√©s les uns des autres, car  n'interagissent pas directement, uniquement via des flux.  Une bonne couverture de test peut √™tre fournie. </li></ul><br><p>  Mais le traitement des donn√©es en streaming n'est pas si simple: </p><br><ul><li> Une bonne compr√©hension du mod√®le de calcul est requise.  Vous devrez repenser les algorithmes de traitement des donn√©es existants.  Tous les algorithmes ne tombent pas imm√©diatement dans le mod√®le de flux et vous devez vous casser la t√™te un peu. </li><li>  Il est n√©cessaire de garantir la conservation de l'ordre de r√©ception et le traitement des √©v√©nements. </li><li>  Vous devez √™tre capable de g√©rer des √©v√©nements interd√©pendants, c'est-√†-dire  avoir un acc√®s rapide √† toutes les donn√©es n√©cessaires lors du traitement d'un nouveau message. </li><li>  Vous devez √©galement pouvoir g√©rer les √©v√©nements en double. </li></ul><br><h3 id="potokovaya-obrabotka-dannyh-stream-processing">  Traitement de flux </h3><br><p>  Tout en travaillant sur le projet, la biblioth√®que Stream Processor a √©t√© √©crite, ce qui nous a aid√©s √† impl√©menter et √† lancer rapidement des algorithmes de traitement de donn√©es en streaming en production. </p><br><p>  Stream Processor est une biblioth√®que pour la construction de syst√®mes de traitement de donn√©es en streaming.  Le flux est une s√©quence potentiellement infinie de donn√©es (messages) dans laquelle seul l'ajout de nouveaux messages est possible; les messages d√©j√† enregistr√©s ne sont pas modifi√©s et ne sont pas supprim√©s du flux.  Les convertisseurs d'un flux √† un autre (processeurs de flux) se composent fonctionnellement de trois parties: un fournisseur de messages entrants, qui lit g√©n√©ralement les messages d'un ou plusieurs flux et les place dans une file d'attente de traitement, un processeur de messages qui convertit les messages entrants en messages sortants et les place dans une file d'attente √† l'enregistrement et au r√©dacteur, o√π les messages sortants regroup√©s dans la fen√™tre de temps tombent dans le flux de sortie.  Les messages de donn√©es g√©n√©r√©s par un processeur de flux peuvent √™tre utilis√©s par d'autres ult√©rieurement.  Ainsi, les flux et les processeurs forment un graphe orient√© dans lequel des boucles sont possibles, en particulier, un processeur de flux peut m√™me g√©n√©rer des messages dans le m√™me flux d'o√π il re√ßoit des donn√©es. </p><br><p>  Il est garanti que chaque message du flux d'entr√©e sera trait√© par chaque processeur qui lui est associ√© au moins une fois (s√©mantique au moins une fois).  Il est √©galement garanti que tous les messages seront trait√©s dans l'ordre dans lequel ils sont arriv√©s dans ce flux.  Pour ce faire, les processeurs de flux sont r√©partis sur tous les n≈ìuds de service actifs, de sorte qu'√† un moment donn√©, pas plus d'une instance de chaque processeur enregistr√© ne fonctionne. </p><br><p>  Le traitement des √©v√©nements interd√©pendants est l'un des principaux probl√®mes rencontr√©s dans la construction de syst√®mes de traitement de donn√©es en continu.  En r√®gle g√©n√©rale, lors du streaming de messages, les processeurs de flux cr√©ent progressivement un certain √©tat qui √©tait valide au moment o√π le message en cours a √©t√© trait√©.  De tels objets d'√©tat sont g√©n√©ralement associ√©s non pas √† l'ensemble du flux dans son ensemble, mais √† un certain sous-ensemble de messages, qui est d√©termin√© par la valeur de cl√© dans ce flux.  Un stockage efficace de la richesse est la cl√© du succ√®s.  Lors du traitement du message suivant, il est important que le processeur puisse obtenir rapidement cet √©tat et, sur la base de celui-ci et du message actuel, g√©n√©rer des messages sortants.  Ces objets d'√©tat sont accessibles aux processeurs en L1 (veuillez ne pas confondre avec le cache CPU) LRU cache, qui est situ√© en m√©moire.  Dans le cas o√π il n'y avait aucun √©tat dans le cache L1, il est restaur√© √† partir du cache L2 situ√© dans le m√™me stockage o√π les flux sont stock√©s et o√π il est p√©riodiquement stock√© pendant le fonctionnement du processeur.  S'il n'y avait aucun √©tat dans le cache L2, il est restaur√© √† partir des messages de flux d'origine, comme si le processeur avait trait√© tous les messages d'origine associ√©s √† la cl√© de message actuelle.  La technique de mise en cache vous permet √©galement de traiter le probl√®me de la latence √©lev√©e du stockage, car souvent le traitement s√©quentiel ne repose pas sur les performances du serveur, mais sur le retard des demandes et des r√©ponses lors de la communication avec l'entrep√¥t de donn√©es. </p><br><img width="400" src="https://habrastorage.org/webt/_o/pk/sj/_opksjvyut5cirxrnbjerswkt78.png"><br><br><p>  Pour stocker efficacement les donn√©es dans les caches L1 et les donn√©es de message en m√©moire, en plus des structures √©conomes en m√©moire, nous utilisons des pools d'objets qui vous permettent de n'avoir qu'une seule copie d'un objet (ou m√™me des parties de celui-ci) en m√©moire.  Cette technique est d√©j√† utilis√©e dans le JDK pour les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cha√Ænes internes aux cha√Ænes</a> et s'√©tend √©galement aux autres types d'objets, qui devraient √™tre immuables. </p><br><p>  Pour un stockage compact des donn√©es dans le stockage de flux, certaines donn√©es sont normalis√©es avant d'√©crire dans le flux, c'est-√†-dire  transformer en chiffres.  Des algorithmes de compression efficaces peuvent ensuite √™tre appliqu√©s aux nombres (identificateurs d'objet).  Les nombres sont tri√©s, les deltas sont compt√©s, puis encod√©s avec le codage <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ZigZag</a> puis compress√©s par l'archiveur.  La normalisation n'est pas une technique tr√®s standard pour diffuser des syst√®mes de traitement de donn√©es.  Mais cette technique de compression est tr√®s efficace et la quantit√© de donn√©es dans le flux le plus charg√© est r√©duite d'environ 1 000 fois. </p><br><img width="600" src="https://habrastorage.org/getpro/habr/post_images/b1b/6f4/fa9/b1b6f4fa9d551a96fd4069b44435354f.png"><br><br><p>  Pour chaque flux et processeur, nous suivons le cycle de vie du traitement des messages: l'apparition de nouveaux messages dans le flux d'entr√©e, la taille de la file d'attente des messages non trait√©s, la taille de la file d'attente pour l'√©criture dans le flux r√©sultant, le temps de traitement des messages et la r√©partition du temps par √©tapes de traitement des messages: </p><br><img src="https://habrastorage.org/webt/jg/0q/rp/jg0qrpqbojreaugzrf66cikffwa.png"><br><br><h3 id="hranilische-dannyh">  Entrep√¥t de donn√©es </h3><br><p>  Les r√©sultats du traitement en continu des donn√©es doivent √™tre mis √† la disposition de l'utilisateur d√®s que possible.  Les donn√©es trait√©es des flux doivent √™tre enregistr√©es en continu dans la base de donn√©es, o√π vous pouvez ensuite aller chercher les donn√©es (par exemple, afficher un rapport avec les r√©sultats du test, afficher l'historique du test). </p><br><p>  Caract√©ristiques des donn√©es et requ√™tes stock√©es. <br>  La plupart des donn√©es sont des tests.  Sur un mois, plus de 1,5 milliard de builds et de tests sont lanc√©s.  Une quantit√© assez importante d'informations est stock√©e pour chaque lancement: le r√©sultat et le type d'erreur, une br√®ve description de l'erreur (extrait), plusieurs liens vers les journaux, la dur√©e du test, un ensemble de valeurs num√©riques, des m√©triques, au format nom = valeur, etc.  Certaines de ces donn√©es - par exemple, les mesures et la dur√©e - sont tr√®s difficiles √† compresser, car il s'agit en fait de valeurs al√©atoires.  L'autre partie - par exemple, le r√©sultat, le type d'erreur, les journaux - peut √™tre enregistr√©e plus efficacement, car ils ne changent presque pas dans le m√™me test d'une ex√©cution √† l'autre. </p><br><p>  Auparavant, nous utilisions MySQL pour stocker des donn√©es trait√©es.  Nous avons progressivement commenc√© √† nous reposer sur les capacit√©s de la base de donn√©es: </p><br><ul><li>  La quantit√© de donn√©es trait√©es double tous les six mois. </li><li>  Nous ne pouvions stocker les donn√©es que pour les 2 derniers mois, mais nous voulions stocker les donn√©es pendant au moins un an. </li><li>  Probl√®mes avec la vitesse d'ex√©cution de quelques requ√™tes lourdes (proches de l'analyse). </li><li>  Sch√©ma de base de donn√©es compliqu√©.  Nombreuses tables (normalisation), ce qui complique l'√©criture dans la base de donn√©es.  Le sch√©ma de base est tr√®s diff√©rent du sch√©ma des objets utilis√©s dans le circuit en temps r√©el. </li><li>  Ne rencontrant pas d'arr√™t du serveur.  La d√©faillance d'un serveur distinct ou l'arr√™t du centre de donn√©es peut entra√Æner une d√©faillance du syst√®me. </li><li>  Op√©ration assez compliqu√©e. </li></ul><br><p>  En tant que candidats au nouvel entrep√¥t de donn√©es, nous avons envisag√© plusieurs options: PostgreSQL, MongoDB et plusieurs solutions internes, y compris <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ClickHouse</a> . </p><br><p>  Certaines solutions ne nous permettent pas de stocker nos donn√©es plus efficacement que l'ancienne solution bas√©e sur MySQL.  D'autres ne permettent pas l'impl√©mentation de requ√™tes rapides et complexes (presque analytiques).  Par exemple, nous avons une demande assez lourde qui montre les commits qui affectent un projet sp√©cifique (un ensemble de tests).  Dans tous les cas o√π nous ne pouvons pas ex√©cuter de requ√™tes SQL rapides, nous devons obliger l'utilisateur √† attendre longtemps ou √† faire des calculs √† l'avance avec une perte de flexibilit√©.  Si vous comptez quelque chose √† l'avance, vous devez √©crire plus de code et en m√™me temps perdre de la flexibilit√© - il n'y a aucun moyen de changer rapidement le comportement et de raconter quoi que ce soit.  Il est beaucoup plus pratique et plus rapide d'√©crire une requ√™te SQL qui renverra les donn√©es dont l'utilisateur a besoin et pourra les modifier rapidement si vous voulez changer le comportement du syst√®me. </p><br><h3 id="clickhouse">  Clickhouse </h3><br><p>  Nous avons opt√© pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ClickHouse</a> .  ClickHouse est un syst√®me de gestion de base de donn√©es en colonnes (SGBD) pour le traitement des requ√™tes analytiques en ligne (OLAP). </p><br><p>  En passant √† ClickHouse, nous avons d√©lib√©r√©ment abandonn√© certaines des opportunit√©s offertes par d'autres SGBD, en recevant une compensation plus que digne sous forme de requ√™tes analytiques tr√®s rapides et d'un entrep√¥t de donn√©es compact. </p><br><p>  Dans les SGBD relationnels, les valeurs li√©es √† une ligne sont physiquement stock√©es c√¥te √† c√¥te.  Dans ClickHouse, les valeurs de diff√©rentes colonnes sont stock√©es s√©par√©ment et les donn√©es d'une colonne sont stock√©es ensemble.  Cet ordre de stockage des donn√©es vous permet de fournir un degr√© √©lev√© de compression des donn√©es avec le bon choix de cl√© primaire.  Cela affecte √©galement dans quels sc√©narios le SGBD fonctionnera bien.  ClickHouse fonctionne mieux avec les requ√™tes, o√π un petit nombre de colonnes sont lues et la requ√™te utilise une grande table et les autres tables sont petites.  Mais m√™me dans les requ√™tes non analytiques, ClickHouse peut afficher de bons r√©sultats. </p><br><p>  Les donn√©es des tableaux sont tri√©es par cl√© primaire.  Le tri est effectu√© en arri√®re-plan.  Cela vous permet de cr√©er un index clairsem√© d'un petit volume, ce qui vous permet de trouver rapidement des donn√©es.  ClickHouse n'a aucun index secondaire.  √Ä strictement parler, il existe un index secondaire - la cl√© de partition (ClickHouse coupe les donn√©es de partition l√† o√π la cl√© de partition est sp√©cifi√©e dans la demande).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Plus de d√©tails</a> . </p><br><p>  Le sch√©ma de donn√©es avec normalisation n'est pas fonctionnel, au contraire, il est pr√©f√©rable de d√©normaliser les donn√©es en fonction des demandes qui lui sont adress√©es.  Il est pr√©f√©rable de cr√©er des tableaux "larges" avec un grand nombre de colonnes.  Cet √©l√©ment est √©galement li√© au pr√©c√©dent, car l'absence d'index secondaires cr√©e parfois des copies de tables √† l'aide d'une cl√© primaire diff√©rente. </p><br><p>  ClickHouse n'a pas UPDATE et DELETE au sens classique, mais il est possible de les √©muler. </p><br><p>  Les donn√©es doivent √™tre ins√©r√©es dans de grands blocs et pas trop souvent (une fois toutes les quelques secondes).  Le chargement de donn√©es ligne par ligne est pratiquement inop√©rant sur des volumes de donn√©es r√©els. </p><br><p>  ClickHouse ne prend pas en charge les transactions; le syst√®me devient <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">finalement coh√©rent</a> . </p><br><p>  N√©anmoins, certaines fonctionnalit√©s de ClickHouse, similaires √† d'autres SGBD, facilitent le transfert de syst√®mes existants vers celui-ci. </p><br><ul><li>  ClickHouse utilise SQL, mais avec de l√©g√®res diff√©rences, utile pour les requ√™tes typiques des syst√®mes OLAP.  Il existe un puissant syst√®me de fonctions d'agr√©gation, ALL / ANY JOIN, des expressions lambda dans les fonctions et d'autres extensions SQL qui vous permettent d'√©crire presque n'importe quelle requ√™te analytique. </li><li>  ClickHouse prend en charge la r√©plication, l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">enregistrement du</a> quorum et la lecture du quorum.  Une √©criture de quorum est n√©cessaire pour un stockage fiable des donn√©es: INSERT ne r√©ussit que si ClickHouse a pu √©crire des donn√©es dans un nombre donn√© de r√©pliques sans erreur. </li></ul><br><p>  Vous pouvez en savoir plus sur les fonctionnalit√©s de ClickHouse dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> . </p><br><h4 id="osobennosti-raboty-s-clickhouse">  Caract√©ristiques de travailler avec ClickHouse </h4><br><p>  Choix de la cl√© primaire et de la cl√© de partition. </p><br><p>  Comment choisir une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cl√© primaire</a> et une cl√© de partition?  C'est peut-√™tre la premi√®re question qui se pose lors de la cr√©ation d'une nouvelle table.  Le choix de la cl√© primaire et de la cl√© de partition est g√©n√©ralement dict√© par les requ√™tes qui seront effectu√©es sur les donn√©es.  En m√™me temps, les requ√™tes qui utilisent les deux conditions s'av√®rent √™tre les plus efficaces: √† la fois par la cl√© primaire et par la cl√© de partition. </p><br><p>  Dans notre cas, les tableaux principaux sont les matrices d'ex√©cution des tests.  Il est logique de supposer qu'avec cette structure de donn√©es, les cl√©s doivent √™tre s√©lectionn√©es de mani√®re √† ce que l'ordre de contournement de l'une passe dans l'ordre d'augmentation du num√©ro de ligne et dans l'ordre de contournement de l'autre - dans l'ordre d'augmentation du num√©ro de colonne. </p><br><p>  Il est √©galement important de garder √† l'esprit que le choix de la cl√© primaire peut consid√©rablement affecter la compacit√© du stockage de donn√©es, car des valeurs identiques dans le contournement de la cl√© primaire dans d'autres colonnes n'occupent presque pas d'espace dans le tableau.  Ainsi, dans notre cas, par exemple, les √©tats des tests changent peu de commit √† commit.  Ce fait a pr√©d√©termin√© essentiellement le choix de la cl√© primaire - une paire d'identifiant de test et de num√©ro de validation.  De plus, dans cet ordre. </p><br><img width="600" src="https://habrastorage.org/webt/0t/gj/jo/0tgjjoefxhjgbxexx4gevfwte7y.png"><br><br><p>  La cl√© de partition a deux objectifs.  D'une part, il permet aux partitions d'√™tre ¬´archiv√©es¬ª afin de pouvoir √™tre d√©finitivement supprim√©es du stockage, car les donn√©es qu'elles contiennent sont d√©j√† obsol√®tes.  D'un autre c√¥t√©, la cl√© de partition est un index secondaire, ce qui signifie qu'elle vous permet d'acc√©l√©rer les requ√™tes si une expression y est pr√©sente. </p><br><p>  Pour nos matrices, le choix du num√©ro de commit comme cl√© de partition semble assez naturel.  Mais si vous d√©finissez la valeur de r√©vision dans l'expression de la cl√© de partition, il y aura trop de partitions dans une telle table, ce qui d√©gradera les performances des requ√™tes.  Par cons√©quent, dans l'expression de la cl√© de partition, la valeur de r√©vision peut √™tre divis√©e en un grand nombre pour r√©duire le nombre de partitions, par exemple, PARTITION BY intDiv (r√©vision, 2000).  Ce nombre doit √™tre suffisamment grand pour que le nombre de partitions ne d√©passe pas les valeurs recommand√©es, tandis qu'il doit √™tre suffisamment petit pour que peu de donn√©es ne tombent dans une partition et que la base de donn√©es n'ait pas √† lire trop de donn√©es. </p><br><p>  Comment impl√©menter UPDATE et DELETE? </p><br><p>  Dans le sens habituel, UPDATE et DELETE ne sont pas pris en charge dans ClickHouse.  Cependant, au lieu de UPDATE et DELETE, vous pouvez ajouter une colonne avec une version √† la table et utiliser le moteur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ReplacingMergeTree</a> sp√©cial (supprime les enregistrements en double avec la m√™me valeur de cl√© primaire).  Dans certains cas, la version sera naturellement pr√©sente dans la table d√®s le d√©but: par exemple, si nous voulons cr√©er une table pour l'√©tat actuel du test, la version dans cette table sera le num√©ro de commit. </p><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> current_tests ( test_id UInt64, <span class="hljs-keyword"><span class="hljs-keyword">value</span></span> Nullable(<span class="hljs-keyword"><span class="hljs-keyword">String</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">version</span></span> UInt64 ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = ReplacingMergeTree(<span class="hljs-keyword"><span class="hljs-keyword">version</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> test_id</code> </pre> <br><p>  Dans le cas d'un changement d'enregistrement, nous ajoutons la version avec une nouvelle valeur, dans le cas de la suppression, avec une valeur NULL (ou une autre valeur sp√©ciale qui ne peut pas √™tre trouv√©e dans les donn√©es). </p><br><p>  Qu'avez-vous r√©alis√© avec le nouveau stockage? </p><br><p>  L'un des principaux objectifs du passage √† ClickHouse √©tait de pouvoir stocker l'historique des tests sur une longue p√©riode (plusieurs ann√©es, ou au moins un an dans le pire des cas).  D√©j√† au stade du prototype, il est devenu clair que nous pouvions contourner les SSD existants dans nos serveurs pour stocker au moins une histoire de trois ans.  Les requ√™tes analytiques se sont consid√©rablement acc√©l√©r√©es, nous pouvons d√©sormais extraire des informations beaucoup plus utiles de nos donn√©es.  La marge RPS a augment√©.  De plus, cette valeur est mise √† l'√©chelle presque lin√©airement par l'ajout de nouveaux serveurs au cluster ClickHouse.  La cr√©ation d'un nouvel entrep√¥t de donn√©es pour la base de donn√©es ClickHouse n'est qu'une √©tape √† peine perceptible pour l'utilisateur final vers un objectif plus important - l'ajout de nouvelles fonctionnalit√©s, l'acc√©l√©ration et la simplification du d√©veloppement, gr√¢ce √† la possibilit√© de stocker et de traiter de grandes quantit√©s de donn√©es. </p><br><h4 id="prihodite-k-nam">  Venez chez nous </h4><br><p>  Notre d√©partement est en constante expansion.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Visitez-nous</a> si vous souhaitez travailler sur des t√¢ches et des algorithmes complexes et int√©ressants.  Si vous avez des questions, vous pouvez me les poser directement en PM. </p><br><h3 id="poleznye-ssylki">  Liens utiles </h3><br><p>  Traitement de flux </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le journal: ce que tout ing√©nieur logiciel doit savoir sur l'abstraction unificatrice des donn√©es en temps r√©el</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le monde au-del√† du lot: Streaming 101</a> . </li><li>  Book <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Designing Data-Intensive Applications</a> - O'Reilly Media. </li></ul><br><p>  Architecture Kappa </p><br><ul><li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">architecture kappa</a> . </li></ul><br><p>  ClickHouse: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Yandex ouvre ClickHouse</a> . </li><li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://clickhouse.yandex</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La documentation</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr429956/">https://habr.com/ru/post/fr429956/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr429946/index.html">Folie et succ√®s du code de base de donn√©es Oracle</a></li>
<li><a href="../fr429948/index.html">Pourquoi les chefs de produit chez Fintech sont n√©cessaires</a></li>
<li><a href="../fr429950/index.html">Comment maintenir de saines habitudes de communication des √©quipes distantes</a></li>
<li><a href="../fr429952/index.html">Le pass√©, le pr√©sent et l'avenir de Docker et d'autres environnements d'ex√©cution de conteneurs dans Kubernetes</a></li>
<li><a href="../fr429954/index.html">Le programmeur des bookmakers irlandais</a></li>
<li><a href="../fr429958/index.html">Cinq r√®gles de d√©bogage faciles pour les d√©butants</a></li>
<li><a href="../fr429960/index.html">10 raisons pour lesquelles les clients se d√©sabonnent d'un produit</a></li>
<li><a href="../fr429964/index.html">U> X> I> P ... ou "Comment les noms des professions jouent le saut"</a></li>
<li><a href="../fr429966/index.html">Un aper√ßu des techniques d'adaptation de domaine approfondi de base (partie 2)</a></li>
<li><a href="../fr429968/index.html">La plus grande entreprise de messagerie de Chine commence √† utiliser des ¬´camions de ma√Øs¬ª sans pilote pour le transport de marchandises</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
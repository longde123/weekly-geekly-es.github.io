<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç™ üìù ü¶î Una lente inusual para una c√°mara normal o c√≥mo dejar de pensar en el enfoque. üòâ ‚ùï üë©üèª‚Äçüíª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Casi dos siglos de existencia de la c√°mara no deber√≠an haber dado a los ingenieros la oportunidad de agregar "algo m√°s". Las c√°maras modernas graban v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Una lente inusual para una c√°mara normal o c√≥mo dejar de pensar en el enfoque.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414877/">  Casi dos siglos de existencia de la c√°mara no deber√≠an haber dado a los ingenieros la oportunidad de agregar "algo m√°s".  Las c√°maras modernas graban videos de alta calidad, suben fotos a la nube y ajustan etiquetas geogr√°ficas.  Podemos tomar panor√°micas y 360 ¬∞, mirar las estrellas y ralentizar el tiempo.  Pero el progreso no se detiene, sino que se precipita hacia el futuro, alimentado por mentes inquisitivas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cb/co/ue/cbcoueypd1fnm9blmcb3ohpqyeu.png" alt="prueba de imagen"></div><br>  La tecnolog√≠a que se discutir√° hoy no es nueva por naturaleza.  Pero definitivamente vale la pena considerar la forma en que se implementa.  Ser√° una lente de campo de luz interesante que se puede usar con cualquier c√°mara DSLR. <br><a name="habracut"></a><br><h2>  ¬øQu√© es un campo de luz y con qu√© se come? </h2><br>  El t√©rmino <i>campo de luz en</i> s√≠ fue propuesto por el f√≠sico sovi√©tico Gershun en 1936 en su trabajo sobre las propiedades radiom√©tricas de la luz. <br><br>  Un campo de luz es una funci√≥n vectorial que describe la luz que pasa en cualquier direcci√≥n a trav√©s de un punto en el espacio. <img src="https://habrastorage.org/webt/av/tv/ns/avtvnsfa4n-252jrwzy2cntdf5k.png" alt="imagen" align="right">  Un rayo de luz (o m√°s bien su direcci√≥n) para un punto dado en el espacio puede describirse mediante cinco par√°metros (la llamada funci√≥n 5D-ple√≥ptica): coordenadas <i>x</i> , <i>y</i> , <i>z</i> y dos √°ngulos <i>Œ∏</i> y <i>œï</i> .  Al integrar los vectores de campo obtenidos desde varios puntos de vista, obtenemos el valor de iluminaci√≥n total.  Y teniendo una descripci√≥n completa de los rayos de luz en el espacio, podemos determinar con precisi√≥n, por ejemplo, c√≥mo se ve un objeto desde cualquier punto de vista. <br><br>  ¬øCu√°l es la aplicaci√≥n pr√°ctica de la teor√≠a del campo de luz?  Una de las √°reas m√°s interesantes son las c√°maras de campo claro.  A diferencia de las c√°maras cl√°sicas, que registran la intensidad de la luz en los puntos de un objeto, la c√°mara del campo de luz tambi√©n tiene en cuenta la direcci√≥n de los rayos, la salida y estos puntos.  En otras palabras, capturamos los rayos de luz "individuales" que emanan del objeto.  Y esto, a su vez, le permite obtener las coordenadas f√≠sicas de los objetos en el espacio y un mapa de profundidad. <br><br><h2>  ¬øC√≥mo se arreglan las c√°maras de campo de luz? </h2><br>  Ya sabemos que una c√°mara de este tipo deber√≠a registrar no solo la intensidad, sino tambi√©n la direcci√≥n de los rayos de luz que emanan del objeto.  Una forma de implementar esto es usar una serie de lentes frente al sensor √≥ptico.  Estas lentes recogen rayos de luz de un objeto ubicado en una parte espec√≠fica de la escena y los enfocan en el sensor. <br><br>  Es importante comprender que en este caso la lente principal de la lente ya no enfoca la imagen en el sensor.  En cambio, los rayos se proyectan en el plano del conjunto de lentes (en las c√°maras cl√°sicas, el sensor se encuentra exactamente en este plano), el conjunto de lentes pasa y solo luego cae sobre el sensor, formando una imagen en mosaico de varias partes de la escena. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qf/gl/5i/qfgl5i2miblhvrhz_ge49lqfrnq.png" alt="imagen"></div><br>  La figura muestra un diagrama simplificado del funcionamiento de dicha lente.  Gracias a la astuta organizaci√≥n del sistema √≥ptico, al final, obtenemos no una, sino muchas im√°genes del objeto, y cada una de esas im√°genes crea una representaci√≥n √∫nica del objeto desde su √°ngulo √∫nico. <br><br>  Sin embargo, este esquema tiene una serie de desventajas, como el alto costo de fabricaci√≥n, la complejidad de la calibraci√≥n, el control de apertura y otros par√°metros del sistema.  Uno de los ejemplos m√°s famosos de tales c√°maras es el producto de Lytro: la c√°mara Lytro Illum (el proyecto parece estar congelado) <br><br><h2>  ¬øPuedes hacerlo m√°s f√°cil? </h2><br>  Usted puede  La lente de la que quiero hablar en este art√≠culo no contiene una variedad de microlentes.  En cambio, se utiliza un sistema, que es un "canal" espejo con una secci√≥n rectangular (caja de espejo), donde, gracias a la reflexi√≥n m√∫ltiple, se forma una llamada imagen caleidosc√≥pica, que el sensor de la c√°mara graba de la manera habitual. <br><br><img src="https://habrastorage.org/webt/jp/gt/dh/jpgtdhotrubcdjqctkx1ypxtxv8.png" alt="imagen"><br><br>  Se est√° desarrollando una peque√±a empresa alemana.  La lente est√° en la etapa de un prototipo completamente funcional, y el principio de su funcionamiento es bastante simple. <br><br>  Las im√°genes obtenidas por el sistema se ven as√≠: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bc/0z/u9/bc0zu9ojlfgakmjvfyu2ed6j6og.png" alt="imagen"></div><br>  Los elementos aqu√≠ se reflejan.  Una imagen caleidosc√≥pica tan inusual es una consecuencia del reflejo de los rayos en el "canal del espejo". <br><br>  Y as√≠ es como se ve la diferencia absoluta del par de elementos recuperados (los p√≠xeles brillantes significan una mayor diferencia en los valores): <br><br><img src="https://habrastorage.org/webt/e1/t5/po/e1t5poethhxhqe9f2i8xmplliys.png" alt="imagen"><br><br>  En otras palabras, no tenemos m√°s que un par est√©reo.  O m√°s bien, est√©reo nueve (elementos 3x3).  Al cambiar los par√°metros geom√©tricos del canal, podemos obtener 5x5 e incluso grandes dimensiones, lo que, sin embargo, no tiene sentido en la vida real e incluso perjudica. <br><br>  Entonces, tenemos un conjunto de im√°genes que forman una imagen caleidosc√≥pica.  Que sigue <br><br>  Aqu√≠ es donde termina el hardware √≥ptico anal√≥gico c√°lido y comienza el soft digital fr√≠o. <br><br><h2>  Calibraci√≥n </h2><br>  Independientemente de la aplicaci√≥n, las im√°genes deben restaurarse (debe calibrar todo el sistema √≥ptico y aplicar los datos de calibraci√≥n obtenidos a las im√°genes).  El proceso es bastante tedioso, pero importante, ya que los diversos elementos de la imagen caleidosc√≥pica necesariamente deben estar "coordinados" entre s√≠ (incluso insignificantes / varios p√≠xeles / discrepancias de los elementos pueden estropear en gran medida el resultado y la impresi√≥n).  Hay muchos trabajos sobre el tema de la calibraci√≥n, por lo que no tiene sentido revelar detalles.  Solo necesita recordar que la calibraci√≥n es muy importante para cualquier aplicaci√≥n est√©reo. <br><br><h2>  Mapa de profundidad </h2><br>  Habiendo recibido im√°genes "pares", podemos construir un mapa de profundidad. <br>  Esta es quiz√°s la parte m√°s importante y dif√≠cil en la tuber√≠a.  La calidad de la aplicaci√≥n final depende de la calidad del mapa de profundidad.  Y la calidad del mapa de profundidad, a su vez, depende de la calidad de la calibraci√≥n, el algoritmo seleccionado y la "complejidad" de la escena. <br><br>  Pero independientemente del algoritmo, la tarea es siempre la misma: encontrar los puntos correspondientes de las im√°genes izquierda y derecha (y en nuestro caso + 7 im√°genes m√°s) y calcular la distancia (disparidad) entre ellas.  El valor de la distancia ser√° el rec√≠proco del valor de profundidad para un p√≠xel dado. <br><br>  ¬øPor qu√© usar 9 im√°genes si puedes llevarte bien con dos?  Obviamente, al usar m√°s im√°genes, tenemos m√°s informaci√≥n sobre la escena y podemos resolver parcialmente algunos problemas de los algoritmos existentes para estimar el mapa de profundidad. <br><br>  Entre los problemas cl√°sicos de tales algoritmos: <br><br><ul><li>  Superficies mon√≥tonas de un color sin textura: el algoritmo simplemente no tiene nada que "atrapar" en el proceso de b√∫squeda de coincidencias </li><li>  Objetos superpuestos (visibles desde una esquina e invisibles desde otra) </li><li>  Sombras y reflejos en superficies espejadas o brillantes. </li><li>  Las estructuras regulares, como las celdas y las bandas, plantean problemas, ya que no siempre est√° claro qu√© celda de la imagen A corresponde a la celda de la imagen B. </li><li>  Bordes de im√°genes: un problema similar al problema de la superposici√≥n de objetos.  En los bordes de las im√°genes, la informaci√≥n se pierde inevitablemente desde cualquier √°ngulo. </li></ul><br>  Hay muchos algoritmos de calidad y no muchos para construir un mapa de profundidad.  Los desarrollos m√°s prometedores se encuentran ahora en el campo de los enfoques h√≠bridos que utilizan m√©todos cl√°sicos y diversas t√©cnicas de aprendizaje autom√°tico (CNN, DNN).  Como siempre, la elecci√≥n del algoritmo es un compromiso entre velocidad y calidad.  Afortunadamente, en fotograf√≠a podemos darnos el lujo de retroceder en tiempo real y obtener un mejor mapa de profundidad. <br><br>  Para nuestro ejemplo, el mapa de profundidad se ve as√≠: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lk/a5/p2/lka5p2k7vkqazvlzads_pqai9y4.png" alt="imagen"></div><br><br><h2>  Enfoque posterior </h2><br>  Tenemos un mapa de las profundidades, ¬øqu√© hacer con √©l ahora?  La informaci√≥n sobre la lejan√≠a de los objetos suele ser √∫til.  Una aplicaci√≥n popular es el enfoque posterior. <br><br>  Desenfocarse es uno de los problemas de los fot√≥grafos.  ¬øNotaste que en la imagen original toda la escena estaba enfocada?  As√≠ es como se ve el enfoque posterior basado en un mapa de profundidad: <br><br><img src="https://habrastorage.org/webt/5q/qy/dp/5qqydpw85mv-p_b0hzock0cqi20.png" alt="imagen"><br><br>  Cabe se√±alar que con este enfoque, en realidad nos deshacemos de las propiedades f√≠sicas del sistema √≥ptico.  Esto permite, por ejemplo, crear algor√≠tmicamente una imagen con varios trucos.  O cambie mediante programaci√≥n la profundidad de un espacio claramente representado (Profundidad de campo). <br><br><h2>  Otras aplicaciones </h2><br>  El enfoque posterior es la aplicaci√≥n principal, pero a√∫n no es la √∫nica.  En general, esta lente se puede considerar como un conjunto de c√°maras virtuales (9 piezas).  En consecuencia, es aplicable a todas aquellas aplicaciones que pueda imaginar para una variedad de c√°maras, por ejemplo: <br><br><ul><li>  Filtros de polarizaci√≥n: cada uno de los 9 elementos de imagen tiene su propio filtro de polarizaci√≥n con una direcci√≥n determinada.  Esto le permite obtener 9 im√°genes con diferentes polarizaciones en una sola toma e incluso crear una serie de videos de un cambio suave de direcci√≥n de polarizaci√≥n </li><li>  HDR (High-Dynamic-Range): el mismo principio: 9 filtros diferentes + algoritmo para la "combinaci√≥n" √≥ptima de brillo </li><li>  Cambio de perspectiva </li><li>  Edici√≥n basada en profundidad: le permite aplicar varios filtros a diferentes profundidades.  Por ejemplo, haga el fondo en blanco y negro, resaltando el primer plano. </li><li>  Segmentaci√≥n: selecci√≥n de objetos ubicados a cierta distancia </li><li>  Medici√≥n de distancia: una regla para las im√°genes.  Funciona especialmente bien para escenas "poco profundas" para las cuales la disparidad es m√°s f√°cil de calcular. </li><li>  Aplicaciones para la industria: varias formas de evaluar la calidad de la producci√≥n y el monitoreo </li></ul><br><h2>  Conclusi√≥n </h2><br>  La cuesti√≥n del costo final de esta lente a√∫n est√° abierta, pero algunos par√°metros f√≠sicos ya se han determinado.  Se sabe que la longitud no debe exceder los 20 cm, y la masa - 800 g.  Se afirma que este dispositivo ser√° principalmente compatible con las c√°maras Sony, Canon y Nikon. <br><br>  Fuera del art√≠culo, quedaron temas tan importantes como el uso pr√°ctico de c√°maras est√°ndar con visores, restauraci√≥n de la resoluci√≥n (superresoluci√≥n), algoritmos de procesamiento e integraci√≥n con editores gr√°ficos.  Hablar√© de esto la pr√≥xima vez. <br><br>  Gracias por su atencion! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es414877/">https://habr.com/ru/post/es414877/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es414867/index.html">ThinkingHome.Migrator: migraci√≥n versionada del esquema de base de datos en la plataforma .NET Core</a></li>
<li><a href="../es414869/index.html">Marcos desaparecidos</a></li>
<li><a href="../es414871/index.html">La tormenta de polvo en Marte alcanz√≥ la escala planetaria, incluso la curiosidad se vio afectada</a></li>
<li><a href="../es414873/index.html">IDisposable: que su madre no habl√≥ sobre la liberaci√≥n de recursos. Parte 1</a></li>
<li><a href="../es414875/index.html">La integraci√≥n de contenedores Kubernetes reemplaza a Docker listo para la producci√≥n</a></li>
<li><a href="../es414879/index.html">¬øPor qu√© 2 extrusoras en una impresora 3D?</a></li>
<li><a href="../es414881/index.html">Un poco de backstage VK</a></li>
<li><a href="../es414883/index.html">Los recuerdos sonaron de una nueva manera: la BBC actualiz√≥ el archivo de sonido del proyecto RemArc</a></li>
<li><a href="../es414885/index.html">Nos ocupamos de errores y "muletas" en el Registro Estatal Unificado de Entidades Legales - el registro estatal de entidades legales</a></li>
<li><a href="../es414887/index.html">Creando un gancho de gato en Unity. Parte 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
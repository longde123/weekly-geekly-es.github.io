<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ô£Ô∏è üòú ü§ñ Le cerveau est comme un ordinateur: mal g√©rer les math√©matiques et bien avec tout le reste üåΩ üçÑ üèüÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous nous souvenons tous des exercices tourment√©s d'arithm√©tique de l'√©cole. Il faudra au moins une minute pour multiplier des nombres comme 3 752 et ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le cerveau est comme un ordinateur: mal g√©rer les math√©matiques et bien avec tout le reste</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/405285/"><img src="https://habrastorage.org/getpro/geektimes/post_images/4f2/344/2fe/4f23442fefbfc9ec8afa548b63195343.jpg" alt="image" align="left">  Nous nous souvenons tous des exercices tourment√©s d'arithm√©tique de l'√©cole.  Il faudra au moins une minute pour multiplier des nombres comme 3 752 et 6 901 avec un crayon et du papier.  Bien s√ªr, aujourd'hui, lorsque nous avons des t√©l√©phones √† port√©e de main, nous pouvons rapidement v√©rifier que le r√©sultat de notre exercice devrait √™tre 25 892 552. Les processeurs des t√©l√©phones modernes peuvent effectuer plus de 100 milliards de ces op√©rations par seconde.  De plus, ces puces consomment seulement quelques watts, ce qui les rend beaucoup plus efficaces que nos cerveaux lents, consommant 20 watts et n√©cessitant beaucoup plus de temps pour obtenir le m√™me r√©sultat. <br><br>  Bien s√ªr, le cerveau n'a pas √©volu√© pour faire de l'arithm√©tique.  Par cons√©quent, il le fait mal.  Mais il fait face au traitement d'un flux constant d'informations provenant de notre environnement.  Et il y r√©agit - parfois plus vite que nous ne pouvons le r√©aliser.  Peu importe la quantit√© d'√©nergie qu'un ordinateur ordinaire consommera - il sera difficile de faire face √† ce qui est facilement donn√© au cerveau - par exemple, comprendre le langage ou monter les escaliers. <br><a name="habracut"></a><br>  S'ils pouvaient cr√©er des machines dont les capacit√©s de calcul et l'efficacit√© √©nerg√©tique seraient comparables √† celles du cerveau, alors tout changerait radicalement.  Les robots se d√©placeraient habilement dans le monde physique et communiqueraient avec nous dans un langage naturel.  Les syst√®mes √† grande √©chelle collecteraient d'√©normes quantit√©s d'informations sur les affaires, la science, la m√©decine ou le gouvernement, d√©couvrant de nouveaux mod√®les, trouvant des relations causales et faisant des pr√©dictions.  Les applications mobiles intelligentes comme Siri et Cortana pourraient moins s'appuyer sur les nuages.  Une telle technologie pourrait nous permettre de cr√©er des appareils √† faible consommation d'√©nergie, compl√©tant nos sens, nous fournissant des m√©dicaments et √©mulant des signaux nerveux, compensant les dommages aux organes ou la paralysie. <br><br>  Mais n'est-il pas trop t√¥t pour se fixer des objectifs aussi audacieux?  Notre compr√©hension du cerveau est-elle trop limit√©e pour que nous puissions cr√©er des technologies bas√©es sur ses principes?  Je crois que l'√©mulation des caract√©ristiques les plus simples des circuits nerveux peut am√©liorer consid√©rablement les performances de nombreuses applications commerciales.  La pr√©cision avec laquelle les ordinateurs doivent copier les d√©tails biologiques de la structure du cerveau afin de se rapprocher de son niveau de vitesse est une question ouverte.  Mais les syst√®mes d'aujourd'hui, inspir√©s de la structure du cerveau, ou neuromorphes, deviendront des outils importants pour y trouver une r√©ponse. <br><br>  Une caract√©ristique cl√© des ordinateurs conventionnels est la s√©paration physique de la m√©moire qui stocke les donn√©es et les instructions, et la logique qui traite ces informations.  Il n'y a pas une telle division dans le cerveau.  Les calculs et le stockage des donn√©es se produisent simultan√©ment et localement, dans un vaste r√©seau compos√© d'environ 100 milliards de cellules nerveuses (neurones) et de plus de 100 billions de connexions (synapses).  Pour la plupart, le cerveau est d√©termin√© par ces connexions et la fa√ßon dont chacun des neurones r√©pond au signal entrant des autres neurones. <br><br>  Parlant des possibilit√©s extraordinaires du cerveau humain, nous entendons g√©n√©ralement l'acquisition r√©cente d'un long processus √©volutif - le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">n√©ocortex</a> (nouveau cortex).  Cette couche mince et extr√™mement pli√©e forme la coque externe du cerveau et effectue des t√¢ches tr√®s diff√©rentes, y compris le traitement des informations re√ßues des sens, le contr√¥le de la motricit√©, le travail avec la m√©moire et l'apprentissage.  Un tel √©ventail de possibilit√©s est disponible dans une structure plut√¥t homog√®ne: six couches horizontales et un million de colonnes verticales de 500 Œºm de large, constitu√©es de neurones qui int√®grent et distribuent des informations cod√©es en impulsions √©lectriques le long des antennes qui en d√©coulent - dendrites et axones. <br><br>  Comme toutes les cellules du corps humain, le neurone a un potentiel √©lectrique de l'ordre de 70 mV entre la surface ext√©rieure et l'int√©rieur.  Cette tension membranaire change lorsqu'un neurone re√ßoit un signal d'autres neurones qui lui sont associ√©s.  Si la tension de la membrane atteint une valeur critique, elle forme une impulsion, ou une surtension de plusieurs millisecondes, de l'ordre de 40 mV.  Cette impulsion se propage le long de l'axone d'un neurone jusqu'√† ce qu'elle atteigne la synapse, une structure biochimique complexe qui relie l'axone d'un neurone √† la dendrite d'un autre.  Si l'impulsion satisfait √† certaines restrictions, la synapse la convertit en une autre impulsion, descendant les dendrites de ramification du neurone recevant le signal, et change sa tension de membrane dans le sens positif ou n√©gatif. <br><br>  La connectivit√© est une caract√©ristique essentielle du cerveau.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le neurone pyramidal</a> , un type particuli√®rement important de cellules n√©ocortex humaines, contient environ 30 000 synapses, soit 30 000 canaux d'entr√©e provenant d'autres neurones.  Et le cerveau s'adapte constamment.  Le neurone et les propri√©t√©s de la synapse - et m√™me la structure du r√©seau lui-m√™me - sont en constante √©volution, principalement sous l'influence des donn√©es d'entr√©e provenant des sens et de la r√©troaction environnementale. <br><br>  Les ordinateurs modernes √† usage g√©n√©ral sont num√©riques et non analogiques;  la classification du cerveau n'est pas si simple.  Les neurones accumulent une charge √©lectrique, comme les condensateurs dans les circuits √©lectroniques.  Il s'agit clairement d'un processus analogique.  Mais le cerveau utilise les rafales comme unit√©s d'information, et il s'agit essentiellement d'un sch√©ma binaire: √† tout moment, n'importe o√π, il y a une rafale ou non.  En termes d'√©lectronique, le cerveau est un syst√®me √† signaux mixtes, avec calcul analogique local et transmission d'informations √† l'aide de salves binaires.  √âtant donn√© que la rafale n'a que 0 ou 1 valeur, elle peut parcourir une longue distance sans perdre ces informations de base.  Il se reproduit √©galement, atteignant le prochain neurone du r√©seau. <br><br>  Une autre diff√©rence cl√© entre le cerveau et l'ordinateur est que le cerveau g√®re le traitement de l'information sans horloge centrale synchronisant son fonctionnement.  Bien que nous observions des √©v√©nements de synchronisation - des ondes c√©r√©brales - ils s'organisent, r√©sultant du travail des r√©seaux de neurones.  Fait int√©ressant, les syst√®mes informatiques modernes commencent √† adopter l'asynchronie inh√©rente au cerveau afin d'acc√©l√©rer les calculs en les ex√©cutant en parall√®le.  Mais le degr√© et le but de la parall√©lisation de ces deux syst√®mes sont extr√™mement diff√©rents. <br><br>  L'id√©e d'utiliser le cerveau comme mod√®le de calcul a des racines profondes.  Les premi√®res tentatives √©taient bas√©es sur un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">neurone √† seuil simple</a> qui donne une valeur si la somme des donn√©es d'entr√©e pond√©r√©es d√©passe le seuil, et l'autre si ce n'est pas le cas.  Le r√©alisme biologique de cette approche, con√ßue par Warren McCullough et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Walter Pitts</a> dans les ann√©es 40, est tr√®s limit√©.  Cependant, c'√©tait la premi√®re √©tape vers l'application du concept de neurone d√©clencheur comme √©l√©ment de calcul. <br><br>  En 1957, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Frank Rosenblatt a</a> propos√© une autre version d'un neurone √† seuil, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">perceptron</a> .  Un r√©seau de n≈ìuds interconnect√©s (neurones artificiels) est compos√© de couches.  Les couches visibles √† la surface du r√©seau interagissent avec le monde ext√©rieur en tant qu'entr√©es et sorties, et les couches cach√©es √† l'int√©rieur effectuent tous les calculs. <br><br>  Rosenblatt a √©galement sugg√©r√© d'utiliser une caract√©ristique essentielle du cerveau: le confinement.  Au lieu d'empiler toutes les entr√©es, les neurones du perceptron peuvent apporter une contribution n√©gative.  Cette fonctionnalit√© permet aux r√©seaux de neurones d'utiliser une seule couche cach√©e pour r√©soudre les probl√®mes XOR en logique, dans lesquels la sortie est vraie si une seule des deux entr√©es binaires est vraie.  Cet exemple simple montre que l'ajout de r√©alisme biologique peut ajouter de nouvelles capacit√©s de calcul.  Mais quelles fonctions du cerveau sont n√©cessaires √† son travail, et quelles sont les traces inutiles de l'√©volution?  Personne ne le sait. <br><br>  Nous savons que des r√©sultats informatiques impressionnants peuvent √™tre obtenus sans chercher √† cr√©er un r√©alisme biologique.  Les chercheurs en apprentissage profond ont parcouru un long chemin dans l'utilisation des ordinateurs pour analyser de grandes quantit√©s de donn√©es et extraire certains attributs d'images complexes.  Bien que les r√©seaux de neurones qu'ils ont cr√©√©s aient plus d'entr√©es et de couches cach√©es que jamais, ils sont toujours bas√©s sur des mod√®les de neurones extr√™mement simples.  Leurs vastes possibilit√©s ne refl√®tent pas le r√©alisme biologique, mais l'ampleur des r√©seaux qu'ils contiennent et la puissance des ordinateurs utilis√©s pour leur formation.  Mais les r√©seaux d'apprentissage en profondeur sont encore tr√®s loin des vitesses de calcul, de l'efficacit√© √©nerg√©tique et des capacit√©s d'apprentissage du cerveau biologique. <br><br>  L'√©norme foss√© entre le cerveau et les ordinateurs modernes est mieux soulign√© par les simulations √† grande √©chelle du cerveau.  Ces derni√®res ann√©es, plusieurs tentatives de ce type ont √©t√© faites, mais toutes ont √©t√© s√©v√®rement limit√©es par deux facteurs: l'√©nergie et le temps de simulation.  Par exemple, consid√©rons une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">simulation</a> r√©alis√©e il y a plusieurs ann√©es par Markus Daisman et ses coll√®gues utilisant 83 000 processeurs sur un supercalculateur K au Japon.  La simulation de 1,73 milliard de neurones a consomm√© 10 milliards de fois plus d'√©nergie que la zone √©quivalente du cerveau, bien qu'ils aient utilis√© des mod√®les extr√™mement simplifi√©s et n'aient effectu√© aucune formation.  Et ces simulations fonctionnent g√©n√©ralement plus de 1000 fois plus lentement que le cerveau biologique en temps r√©el. <br><br>  Pourquoi sont-ils si lents?  Les simulations c√©r√©brales sur des ordinateurs conventionnels n√©cessitent le calcul de milliards d'√©quations diff√©rentielles qui sont interconnect√©es et d√©crivent la dynamique des cellules et des r√©seaux: des processus analogiques comme le d√©placement d'une charge √† travers une membrane cellulaire.  Les ordinateurs qui utilisent la logique bool√©enne - changer l'√©nergie pour la pr√©cision - et partager la m√©moire et le calcul, sont extr√™mement inefficaces pour mod√©liser le cerveau. <br><br>  Ces simulations peuvent devenir un outil de cognition du cerveau, en transf√©rant les donn√©es obtenues en laboratoire vers des simulations avec lesquelles nous pouvons exp√©rimenter, puis comparer les r√©sultats avec les observations.  Mais si nous esp√©rons aller dans une direction diff√©rente et utiliser les le√ßons de la neurobiologie pour cr√©er de nouveaux syst√®mes informatiques, nous devons repenser la fa√ßon dont nous concevons et cr√©ons des ordinateurs. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2bd/b7a/481/2bdb7a48108ec3979ff6b184c86d3240.jpg" alt="image"><br>  <i>Neurones dans le silicium.</i> <br><br>  Copier le travail du cerveau √† l'aide de l'√©lectronique peut √™tre plus r√©alisable qu'il n'y para√Æt √† premi√®re vue.  Il s'av√®re qu'environ 10 fJ (10 <sup>-15</sup> joules) sont d√©pens√©s pour cr√©er un potentiel √©lectrique au niveau de la synapse.  La grille d'un transistor m√©tal-oxyde-semi-conducteur (MOS), qui est beaucoup plus grande et consomme plus d'√©nergie que celles utilis√©es dans le CPU, ne n√©cessite que 0,5 fJ pour se charger.  Il s'av√®re que la transmission synaptique √©quivaut √† charger 20 transistors.  De plus, au niveau des appareils, les circuits biologiques et √©lectroniques ne diff√®rent pas beaucoup.  En principe, vous pouvez cr√©er des structures comme des synapses et des neurones √† partir de transistors et les connecter de mani√®re √† obtenir un cerveau artificiel qui n'absorbe pas de telles quantit√©s √©blouissantes d'√©nergie. <br><br>  L'id√©e de cr√©er des ordinateurs √† l'aide de transistors qui fonctionnent comme des neurones est apparue dans les ann√©es 1980 avec le professeur Carver Mead de Caltech.  L'un des principaux arguments de Mead en faveur des ordinateurs ¬´neuromorphes¬ª √©tait que les dispositifs semi-conducteurs peuvent, dans un certain mode, suivre les m√™mes lois physiques que les neurones, et que le comportement analogique peut √™tre utilis√© pour des calculs √† haute efficacit√© √©nerg√©tique. <br><br>  Le groupe de Mead a √©galement invent√© une plate-forme de communication neuronale dans laquelle les salves ne sont cod√©es que par leurs adresses r√©seau et leur heure d'occurrence.  Ce travail a √©t√© r√©volutionnaire, car il a √©t√© le premier √† faire du temps une caract√©ristique n√©cessaire des r√©seaux de neurones artificiels.  Le temps est un facteur cl√© pour le cerveau.  Les signaux ont besoin de temps de propagation, les membranes ont besoin de temps de r√©action, et c'est le temps qui d√©termine la forme des potentiels postsynaptiques. <br><br>  Aujourd'hui, plusieurs groupes de recherche actifs, par exemple le groupe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Giacomo Indiveri</a> de la Swiss Higher Technical School et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kwabena Bohen</a> de Stanford, ont suivi les traces de Mead et introduit avec succ√®s des √©l√©ments des r√©seaux biologiques corticaux.  L'astuce consiste √† travailler avec des transistors utilisant un courant basse tension qui n'atteint pas leur valeur seuil, cr√©ant des circuits analogiques qui copient le comportement du syst√®me nerveux, tout en consommant un peu d'√©nergie. <br><br>  Des recherches plus pouss√©es dans ce sens pourraient trouver des applications dans des syst√®mes tels que l'interface cerveau-ordinateur.  Mais il y a un √©norme foss√© entre ces syst√®mes et la taille r√©elle du r√©seau, la connectivit√© et la capacit√© d'apprentissage du cerveau animal. <br><br>  Ainsi, dans la r√©gion de 2005, trois groupes de chercheurs ont commenc√© ind√©pendamment √† d√©velopper des syst√®mes neuromorphiques qui √©taient significativement diff√©rents de l'approche originale de Mead.  Ils voulaient cr√©er des syst√®mes √† grande √©chelle avec des millions de neurones. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le</a> projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SpiNNaker</a> , dirig√© par Steve Ferber de l'Universit√© de Manchester, est le plus proche des ordinateurs ordinaires.  Ce groupe a d√©velopp√© sa propre puce num√©rique, compos√©e de 18 processeurs ARM fonctionnant √† 200 MHz - environ un dixi√®me de la vitesse des processeurs modernes.  Bien que les c≈ìurs ARM soient issus du monde des ordinateurs classiques, ils simulent des rafales envoy√©es via des routeurs sp√©ciaux con√ßus pour transmettre des informations de mani√®re asynchrone - tout comme le cerveau.  La mise en ≈ìuvre actuelle, qui fait partie du projet du cerveau humain de l'Union europ√©enne et a √©t√© achev√©e en 2016, contient 500 000 c≈ìurs ARM.  Selon la complexit√© du mod√®le neuronal, chaque noyau est capable de simuler jusqu'√† 1000 neurones. <br><br>  La puce TrueNorth, d√©velopp√©e par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Darmendra Maud</a> et ses coll√®gues du laboratoire de recherche IBM √† Almaden, refuse d'utiliser les microprocesseurs comme unit√©s de calcul, et est en fait un syst√®me neuromorphique dans lequel l'informatique et la m√©moire sont intimement li√©es.  TrueNorth reste toujours un syst√®me num√©rique, mais il est bas√© sur des neurocontours sp√©cialement con√ßus qui impl√©mentent un mod√®le de neurone sp√©cifique.  La puce contient 5,4 milliards de transistors, elle est construite sur la technologie Samsung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CMOS</a> 28 nm (structure compl√©mentaire m√©tal-oxyde-semi-conducteur).  Les transistors √©mulent 1 million de circuits neuronaux et 256 millions de synapses simples (bit unique) sur une seule puce. <br><br>  Je dirais que le prochain projet, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">BrainScaleS</a> , est all√© assez loin des ordinateurs conventionnels et s'est rapproch√© du cerveau biologique.  Nous avons travaill√© sur ce projet avec mes coll√®gues de l'Universit√© d'Heidelberg pour l'initiative europ√©enne ¬´The Human Brain¬ª.  BrainScaleS impl√©mente un traitement de signal mixte.  Il combine les neurones et les synapses, dans le r√¥le desquels les transistors au silicium agissent comme des dispositifs analogiques avec l'√©change d'informations num√©riques.  Le syst√®me de grande taille se compose de substrats de silicium de 8 pouces et vous permet d'√©muler 4 millions de neurones et 1 milliard de synapses. <br><br>  Le syst√®me peut reproduire neuf modes de r√©ponse diff√©rents des neurones biologiques et est d√©velopp√© en √©troite collaboration avec des neuroscientifiques.  Contrairement √† l'approche analogique de Mead, BrainScaleS fonctionne en mode acc√©l√©r√©, son √©mulation est 10 000 fois plus rapide qu'en temps r√©el.  Ceci est particuli√®rement pratique pour √©tudier le processus d'apprentissage et le d√©veloppement. <br><br>  L'apprentissage est susceptible de devenir une composante essentielle des syst√®mes neuromorphiques.  D√©sormais, les puces fabriqu√©es √† l'image du cerveau, ainsi que les r√©seaux de neurones fonctionnant sur des ordinateurs ordinaires, sont entra√Æn√©s sur le c√¥t√© √† l'aide d'ordinateurs plus puissants.  Mais si nous voulons utiliser des syst√®mes neuromorphiques dans des applications r√©elles - par exemple, dans des robots qui devront travailler c√¥te √† c√¥te avec nous, ils devront √™tre capables d'apprendre et de s'adapter √† la vol√©e. <br><br>  Dans la deuxi√®me g√©n√©ration de notre syst√®me BrainScaleS, nous avons mis en ≈ìuvre l'opportunit√© de formation en cr√©ant des ¬´processeurs de flexibilit√©¬ª sur la puce.  Ils sont utilis√©s pour modifier un large √©ventail de param√®tres des neurones et des synapses.  Cette fonctionnalit√© nous permet d'affiner les param√®tres pour compenser les diff√©rences de taille et de propri√©t√©s √©lectriques lors du passage d'un appareil √† un autre - approximativement comment le cerveau lui-m√™me s'adapte aux changements. <br><br>  Les trois syst√®mes √† grande √©chelle que j'ai d√©crits se compl√®tent.  SpiNNaker peut √™tre configur√© de mani√®re flexible et utilis√© pour tester diff√©rents neuromod√®les, TrueNorth a une densit√© d'int√©gration √©lev√©e, BrainScaleS est con√ßu pour une formation et un d√©veloppement continus.  La recherche de la bonne fa√ßon d'√©valuer l'efficacit√© de tels syst√®mes est toujours en cours.  Mais les premiers r√©sultats sont prometteurs.  L'√©quipe TrueNorth d'IBM a r√©cemment calcul√© que la transmission synaptique dans leur syst√®me prend 26 pJ.  Et bien que ce soit 1000 fois plus d'√©nergie n√©cessaire dans un syst√®me biologique, c'est presque 100 000 fois moins d'√©nergie utilis√©e pour la transmission dans les simulations sur des ordinateurs √† usage g√©n√©ral. <br><br>  Nous sommes encore √† un stade pr√©coce pour comprendre ce que de tels syst√®mes peuvent faire et comment les appliquer √† la r√©solution de probl√®mes r√©els.  Dans le m√™me temps, nous devons trouver des moyens de combiner de nombreuses puces neuromorphiques en grands r√©seaux avec des capacit√©s d'apprentissage am√©lior√©es, tout en r√©duisant la consommation d'√©nergie.  L'un des probl√®mes est la connectivit√©: le cerveau est en trois dimensions et nos circuits sont en deux dimensions.  La question de l'int√©gration tridimensionnelle des circuits est actuellement √† l'√©tude, et ces technologies peuvent nous aider. <br><br>  Les appareils qui ne sont pas bas√©s sur CMOS - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">memristors</a> ou PCRAM ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">m√©moire avec changement d'√©tat de phase</a> ) peuvent devenir une autre aide.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aujourd'hui, les poids qui d√©terminent la r√©ponse des synapses artificielles aux signaux entrants sont stock√©s dans la m√©moire num√©rique ordinaire, qui occupe la plupart des ressources en silicium n√©cessaires pour construire un r√©seau. </font><font style="vertical-align: inherit;">Mais d'autres types de m√©moire peuvent nous aider √† r√©duire la taille de ces cellules du microm√®tre au nanom√®tre. </font><font style="vertical-align: inherit;">Et la principale difficult√© des syst√®mes modernes sera de supporter les diff√©rences entre les diff√©rents appareils. </font><font style="vertical-align: inherit;">Les principes d'√©talonnage d√©velopp√©s par BrainScaleS peuvent vous aider. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous venons de commencer notre voyage sur la route des syst√®mes neuromorphiques pratiques et utiles. </font><font style="vertical-align: inherit;">Mais l'effort en vaut la peine. </font><font style="vertical-align: inherit;">En cas de succ√®s, nous ne cr√©erons pas seulement de puissants syst√®mes informatiques; </font><font style="vertical-align: inherit;">nous pouvons m√™me obtenir de nouvelles informations sur le travail de notre propre cerveau.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr405285/">https://habr.com/ru/post/fr405285/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr405269/index.html">Un r√©seau de neurones fait de faux Obama</a></li>
<li><a href="../fr405273/index.html">√âchange de r√©seaux radio</a></li>
<li><a href="../fr405275/index.html">Demandez √† Ethan: les √©toiles peuvent-elles s'√©chapper de la galaxie sans endommager la plan√®te?</a></li>
<li><a href="../fr405281/index.html">Lecteur flash, c√¢ble et lecteur de carte: comparez trois lecteurs externes pour iPhone et iPad</a></li>
<li><a href="../fr405283/index.html">50 nuances de moignon *. Microcontr√¥leurs dans la commutation des alimentations. 2e partie</a></li>
<li><a href="../fr405287/index.html">√âchec √âchec: une br√®ve histoire de l'anti-√¢ge</a></li>
<li><a href="../fr405289/index.html">Comment chanter des chansons sovi√©tiques en anglais et d√©velopper la prononciation</a></li>
<li><a href="../fr405291/index.html">√Ä partir du 1er ao√ªt, Bitcoin peut se diviser en deux versions ou plus</a></li>
<li><a href="../fr405293/index.html">Hyperloop One a pour la premi√®re fois dispers√© un ch√¢ssis en l√©vitation dans un vide technique</a></li>
<li><a href="../fr405295/index.html">Mauvaise nouvelle: r√©ductions SoundCloud et √©limination de la m√¢choire</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤üèº üìÑ üßîüèø Onde uma pessoa v√™ formas, a IA v√™ texturas ‚èÆÔ∏è üé™ ü¶Å</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Surpreendentemente, os pesquisadores com algoritmos de aprendizado profundo de vis√£o por computador geralmente n√£o conseguem classificar imagens porqu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Onde uma pessoa v√™ formas, a IA v√™ texturas</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/462951/"> Surpreendentemente, os pesquisadores com algoritmos de aprendizado profundo de vis√£o por computador geralmente n√£o conseguem classificar imagens porque se concentram principalmente nas texturas, e n√£o nas formas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/953/444/41f/95344441f850333698aa94694c254d32.jpg"><br><br>  Se voc√™ olhar a foto de um gato, com uma alta probabilidade, poder√° reconhec√™-lo, independentemente de ser vermelho ou listrado - ou mesmo se a foto for em preto e branco, manchada, maltratada ou manchada.  Voc√™ provavelmente poder√° notar um gato quando ele se enrolar atr√°s de um travesseiro ou pular sobre uma mesa, representando apenas uma forma borrada.  Voc√™ naturalmente aprendeu a reconhecer gatos em quase qualquer situa√ß√£o.  Mas os sistemas de vis√£o de m√°quina baseados em redes neurais profundas, embora √†s vezes possam fornecer √†s pessoas tarefas de reconhecimento de gatos em condi√ß√µes fixas, podem ser confundidos com imagens que s√£o pelo menos ligeiramente diferentes daquilo que sabem, ou que cont√™m ru√≠do ou gr√£o forte. <br><a name="habracut"></a><br>  E agora os pesquisadores alem√£es descobriram uma raz√£o inesperada para isso: se as pessoas prestam aten√ß√£o √†s formas dos objetos representados, a vis√£o computacional com aprendizado profundo se apega √†s texturas dos objetos. <br><br>  Essa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">descoberta</a> , apresentada em maio em uma confer√™ncia internacional de representa√ß√µes de aprendizado, enfatiza o n√≠tido contraste entre o ‚Äúpensamento‚Äù de pessoas e m√°quinas e ilustra como podemos estar errados ao entender como a IA funciona.  E tamb√©m pode nos dizer por que nossa vis√£o se tornou assim como resultado da evolu√ß√£o. <br><br><h2>  Gatos de marfim e avi√µes de observa√ß√£o </h2><br>  Os algoritmos de aprendizado profundo funcionam ao conduzir milhares de imagens atrav√©s de uma rede neural que possui ou n√£o um gato.  O sistema procura padr√µes nesses dados, que s√£o usados ‚Äã‚Äãpara colocar a melhor marca na imagem que n√£o havia encontrado antes.  A arquitetura de rede √© um pouco como a estrutura do sistema visual humano, pois possui camadas conectadas que permitem extrair mais e mais recursos abstratos da imagem.  No entanto, o processo de constru√ß√£o de um sistema de associa√ß√µes que leva √† resposta correta √© uma caixa preta que as pessoas s√≥ podem tentar interpretar ap√≥s o fato.  "Tentamos entender o que leva ao sucesso desses algoritmos de vis√£o computacional de aprendizado profundo e por que eles s√£o t√£o vulner√°veis", disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Thomas Ditterich</a> , especialista em TI da Universidade de Oregon, que n√£o √© afiliado a este estudo. <br><br>  Alguns pesquisadores preferem estudar o que acontece quando tentam enganar a rede alterando ligeiramente a imagem.  Eles descobriram que mesmo pequenas altera√ß√µes podem fazer com que o sistema marque a imagem incorretamente - e grandes altera√ß√µes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">podem n√£o</a> alterar o r√≥tulo.  Enquanto isso, outros especialistas rastreiam mudan√ßas no sistema para analisar como os neur√¥nios individuais respondem √† imagem e comp√µem um " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">atlas de ativa√ß√£o</a> " com base nos atributos que o sistema aprendeu. <br><br>  Mas um grupo de cientistas dos laborat√≥rios do neurobi√≥logo computacional <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Matias Betge</a> e do psicofisiologista <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Felix Wichmann</a> da Universidade de T√ºbingen, na Alemanha, escolheu uma abordagem qualitativa.  No ano passado, a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">equipe relatou</a> que, ao treinar imagens que foram alteradas por um determinado tipo de ru√≠do, a rede come√ßou a reconhecer imagens melhor do que as pessoas que tentavam tirar as mesmas fotos com ru√≠do.  No entanto, as mesmas imagens, modificadas de maneira um pouco diferente, confundiram completamente a rede, embora para as pessoas a nova distor√ß√£o parecesse quase a mesma que a antiga. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c18/418/8c4/c184188c4f088a155c652e51562c42f6.jpg" width="60%"><br>  <i>Robert Geyros, estudante de p√≥s-gradua√ß√£o em Neurobiologia Computacional pela Universidade de T√ºbingen</i> <br><br>  Para explicar esse resultado, os pesquisadores se perguntaram qual a qualidade da imagem que mais muda, mesmo com a adi√ß√£o de um pouco de ru√≠do.  A escolha √≥bvia √© a textura.  "A forma de um objeto permanece mais ou menos inc√≥lume se voc√™ adicionar muito ru√≠do por um longo tempo", disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Robert Geyros</a> , estudante de gradua√ß√£o nos laborat√≥rios de Betge e Wichmann, principal autor do estudo.  Mas "a estrutura da imagem local √© distorcida muito rapidamente quando uma pequena quantidade de ru√≠do √© adicionada".  Ent√£o eles criaram uma maneira complicada de testar como os sistemas visuais de m√°quinas e pessoas processam imagens. <br><br>  Geyros, Betge e seus colegas criaram imagens com duas caracter√≠sticas conflitantes, assumindo a forma de um objeto e a textura de outro: por exemplo, uma silhueta de gato pintada com textura de pele de elefante cinza, ou um urso feito de latas de alum√≠nio ou uma silhueta plana cheia de sobreposi√ß√µes um ao outro com imagens de mostradores.  As pessoas rotulavam centenas dessas imagens com base em suas formas - gato, urso, avi√£o - quase sempre, como pretendido.  No entanto, quatro algoritmos de classifica√ß√£o diferentes estavam inclinados na dire√ß√£o oposta, distribuindo r√≥tulos que refletiam as texturas dos objetos: elefante, latas, rel√≥gios. <br><br>  "Isso muda nossa compreens√£o de como as redes neurais profundas com distribui√ß√£o direta - sem configura√ß√µes adicionais, ap√≥s o processo usual de aprendizado - reconhecem imagens", disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nikolaus Kriegescorte</a> , neurocientista computacional da Universidade de Columbia que n√£o participou do estudo. <br><br>  √Ä primeira vista, a prefer√™ncia por texturas AI sobre formas pode parecer estranha, mas faz sentido.  "A textura tem um formato de alta resolu√ß√£o", disse Kriegscorte.  E √© mais f√°cil para o sistema se apegar a essa escala: o n√∫mero de pixels com informa√ß√µes de textura excede significativamente o n√∫mero de pixels que comp√µem o limite do objeto, e as primeiras etapas da rede est√£o relacionadas ao reconhecimento de recursos locais, como linhas e faces.  "Isso √© exatamente o que √© textura", disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">John Tsotsos</a> , especialista em vis√£o computacional da Universidade de York, em Toronto, que n√£o est√° associado a este estudo.  "Por exemplo, um agrupamento de segmentos alinhados da mesma maneira." <br><br>  Geyros e colegas mostraram que esses sinais locais s√£o suficientes para a rede realizar a classifica√ß√£o.  Esta √© a prova de Betge e outro dos autores do estudo, o p√≥s-doc <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wiland Brendel</a> , que deu uma olhada final no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho</a> , que tamb√©m foi apresentado na confer√™ncia de maio.  Nesse trabalho, eles constru√≠ram um sistema de aprendizado profundo que funcionava da mesma maneira que os algoritmos de classifica√ß√£o funcionavam antes da dissemina√ß√£o do aprendizado profundo - com base no princ√≠pio da "bolsa de atributos".  O algoritmo divide a imagem em pequenos fragmentos, como os modelos atuais (como Geyros usado em seu experimento), mas, em vez de integrar gradualmente essas informa√ß√µes para extrair sinais de um n√≠vel mais alto de abstra√ß√£o, o algoritmo assume imediatamente o conte√∫do de cada pe√ßa ( ‚ÄúNesta pe√ßa h√° evid√™ncia de bicicleta, nesta - evid√™ncia de um p√°ssaro‚Äù).  Ele simplesmente dobrou todas as decis√µes para determinar o objeto ("se mais pe√ßas cont√™m sinais de bicicleta, ent√£o esta √© uma bicicleta"), sem prestar aten√ß√£o √†s rela√ß√µes espaciais das pe√ßas.  E, no entanto, ele foi capaz de reconhecer objetos com uma precis√£o inesperadamente alta. <br><br>  "Este trabalho desafia a suposi√ß√£o de que o aprendizado profundo faz algo completamente diferente", de modelos anteriores, disse Brendel.  ‚ÄúObviamente, houve um grande salto.  S√≥ estou dizendo que n√£o era t√£o grande quanto se esperava. " <br><br>  Segundo Amir Rosenfeld, um p√≥s-doutorado da Universidade de York e da Universidade de Toronto, que n√£o participou do estudo, "existe uma grande diferen√ßa entre o que as redes neurais devem, em nossa opini√£o, e o que elas fazem", incluindo o qu√£o bem elas gerenciam reproduzir o comportamento humano. <br><br>  O pretzel falou da mesma maneira.  √â f√°cil assumir que as redes neurais resolver√£o os problemas da mesma maneira que as pessoas, disse ele.  "No entanto, esquecemos constantemente a exist√™ncia de outros m√©todos." <br><br><h2>  Uma mudan√ßa para uma perspectiva mais humana </h2><br>  Os m√©todos modernos de aprendizado profundo podem integrar recursos locais, como texturas, a padr√µes mais globais, como formul√°rios.  "O que √© inesperadamente e muito convincentemente mostrado nesses trabalhos - embora a arquitetura permita classificar imagens padr√£o, isso n√£o acontece automaticamente se voc√™ apenas treinar a rede sobre isso", disse Kriegescorte. <br><br>  Geyros queria ver o que acontece se a equipe obriga os modelos a ignorar as texturas.  A equipe pegou as imagens tradicionalmente usadas para treinar algoritmos de classifica√ß√£o e as pintou em estilos diferentes, privando-as de informa√ß√µes √∫teis sobre textura.  Quando eles treinaram novamente cada modelo nas novas imagens, os sistemas come√ßaram a contar com padr√µes globais maiores e mostraram uma tend√™ncia maior ao reconhecimento de padr√µes, mais parecido com as pessoas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c60/18d/44b/c6018d44bb8459f3b0496d19975c6c5d.jpg" width="60%"><br>  <i>Wieland Brendel, neurocientista computacional da Universidade de T√ºbingen na Alemanha</i> <br><br>  E depois disso, os algoritmos come√ßaram a classificar melhor as imagens ruidosas, mesmo quando n√£o foram treinadas para lidar com essas distor√ß√µes.  "A rede de reconhecimento de formas tornou-se completamente mais confi√°vel gratuitamente", disse Geyros.  "Isso sugere que o vi√©s certo para a execu√ß√£o de determinadas tarefas, no nosso caso, a propens√£o a usar formul√°rios, ajuda a generalizar o conhecimento para novas condi√ß√µes". <br><br>  Isso tamb√©m sugere que em humanos essa tend√™ncia poderia ter se formado naturalmente, j√° que o uso de formas √© uma maneira mais confi√°vel de reconhecer o que vemos em condi√ß√µes novas ou barulhentas.  As pessoas vivem em um mundo tridimensional, onde os objetos s√£o vis√≠veis de muitos √¢ngulos sob diversas condi√ß√µes e onde nossos outros sentimentos, como o toque, podem opcionalmente complementar o reconhecimento de objetos.  Portanto, para nossa vis√£o, faz sentido colocar o formul√°rio como uma textura priorit√°ria.  Al√©m disso, alguns psic√≥logos mostraram uma conex√£o entre linguagem, aprendizado e tend√™ncia a usar formas: quando as crian√ßas eram ensinadas a prestar mais aten√ß√£o √†s formas quando estudavam certas categorias de palavras, mais tarde elas foram capazes de desenvolver um vocabul√°rio muito mais extenso de substantivos do que outros. <br><br>  Este trabalho serve como um lembrete de que "os dados t√™m um efeito mais forte sobre o preconceito e o vi√©s dos modelos do que pens√°vamos", disse Wichman.  Esta n√£o √© a primeira vez que os pesquisadores encontram esse problema: j√° foi demonstrado que programas de reconhecimento facial, pesquisa autom√°tica de curr√≠culo e outras redes neurais d√£o muita import√¢ncia a sinais inesperados devido a preconceitos profundamente enraizados nos dados em que s√£o treinados.  Eliminar preconceitos indesejados do processo de tomada de decis√£o provou ser uma tarefa dif√≠cil, mas Wichman disse que o novo trabalho demonstra que isso √© poss√≠vel em princ√≠pio e √© encorajador. <br><br>  No entanto, mesmo os modelos de Geyros que se concentram nos formul√°rios podem ser enganados adicionando muito ru√≠do √†s imagens ou alterando certos pixels, o que significa que eles ainda t√™m um longo caminho a percorrer para alcan√ßar uma qualidade compar√°vel √† vis√£o humana.  Na mesma linha, um novo trabalho de Rosenfeld, Tsotsos e Marcus Solbach, um estudante de p√≥s-gradua√ß√£o do laborat√≥rio Tsotsos, demonstra que os algoritmos de aprendizado de m√°quina n√£o s√£o capazes de capturar a semelhan√ßa de diferentes imagens da mesma maneira que as pessoas.  No entanto, esses trabalhos "ajudam a indicar exatamente em quais aspectos esses modelos ainda n√£o reproduzem aspectos importantes do c√©rebro humano", disse Kriegscorte.  E Wichman disse que "em alguns casos, pode ser mais importante examinar o conjunto de dados". <br><br>  Sanya Fiedler, especialista em TI da Universidade de Toronto, que n√£o participou do estudo, concorda.  "√â nosso trabalho desenvolver dados inteligentes", disse ela.  Ela e seus colegas est√£o explorando como as tarefas auxiliares podem ajudar as redes neurais a melhorar a qualidade de suas tarefas principais.  Inspirados pelas descobertas de Geyros, eles recentemente treinaram o algoritmo de classifica√ß√£o de imagens n√£o apenas para reconhecer os pr√≥prios objetos, mas tamb√©m para determinar quais pixels pertencem a seus contornos.  E a rede melhorou automaticamente no reconhecimento de objetos.  "Se voc√™ recebe apenas uma tarefa, o resultado √© aten√ß√£o seletiva e cegueira em rela√ß√£o a muitas outras coisas", disse Fiedler.  "Se eu lhe der v√°rias tarefas, voc√™ aprender√° sobre coisas diferentes, e isso pode n√£o acontecer."  √â o mesmo com esses algoritmos. "  A solu√ß√£o de v√°rios problemas os ajuda a ‚Äúdesenvolver uma tend√™ncia para v√°rias informa√ß√µes‚Äù, semelhante ao que aconteceu no experimento de Geyros com formas e texturas. <br><br>  Todos esses estudos s√£o "um passo muito interessante para aprofundar nossa compreens√£o do que est√° acontecendo com o aprendizado profundo, e talvez isso nos ajude a superar as limita√ß√µes que enfrentamos", disse Dietrich.  "√â por isso que amo essa s√©rie de trabalhos." </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt462951/">https://habr.com/ru/post/pt462951/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt462939/index.html">Os 10 principais relat√≥rios C ++ da R√∫ssia e a lista de reprodu√ß√£o da confer√™ncia de acesso aberto</a></li>
<li><a href="../pt462943/index.html">Ca√ßa aos Wumpus ou experimente escrever um jogo cl√°ssico do Android</a></li>
<li><a href="../pt462945/index.html">Gere senhas √∫nicas para 2FA em JS usando a API Web Crypto</a></li>
<li><a href="../pt462947/index.html">A hist√≥ria de como o PVS-Studio encontrou um erro na biblioteca usada em ... PVS-Studio</a></li>
<li><a href="../pt462949/index.html">A hist√≥ria de como o PVS-Studio encontrou um erro na biblioteca usada em ... PVS-Studio</a></li>
<li><a href="../pt462955/index.html">Transforma√ß√£o digital do treinamento e certifica√ß√£o da equipe de campo</a></li>
<li><a href="../pt462957/index.html">Pr√≥s e contras: o limite de pre√ßo para .org ainda √© cancelado</a></li>
<li><a href="../pt462959/index.html">Processamento de linguagem natural de cheques on-line: um curso de li√ß√µes de m√°gica para um gato comum e outros problemas</a></li>
<li><a href="../pt462961/index.html">Data Science Digest (agosto de 2019)</a></li>
<li><a href="../pt462963/index.html">Usando a API de contexto no React para criar um tema de aplicativo global</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
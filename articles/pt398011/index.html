<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💇🏾 🤦 🙌🏾 Matemática protegendo a privacidade: uma nova abordagem para segurança de dados 🍒 🦖 🧒</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Em 1997, quando os pesquisadores médicos de Massachusetts começaram a fornecer acesso aos registros médicos dos funcionários, o governo removeu os nom...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Matemática protegendo a privacidade: uma nova abordagem para segurança de dados</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/398011/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em 1997, quando os pesquisadores médicos de Massachusetts começaram a fornecer acesso aos registros médicos dos funcionários, o governo removeu os nomes dos pacientes, seus endereços e números de previdência social das listas. William Weld, então governador, garantiu ao público que seria impossível restaurar a identidade mediante agendamento. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alguns dias depois, uma carta chegou ao escritório de Weld enviada por um estudante do Instituto de Tecnologia de Massachusetts. Extratos do cartão médico do governador foram incluídos no envelope. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Embora os identificadores óbvios tenham sido removidos, as autoridades decidiram deixar a data de nascimento, sexo e código postal (CEP). Depois de comparar esses dados com as gravações de voz, Latanya Sweeney conseguiu calcular o prontuário médico de Weld.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O trabalho de Sweeney e outros avanços na privacidade nos últimos 15 anos levantam preocupações de segurança para dados supostamente anônimos. </font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Descobrimos que a intuição das pessoas sobre quais dados considerar privados não está funcionando bem", diz Frank McSherry, da Microsoft Research Silicon Valley. </font><font style="vertical-align: inherit;">"Os computadores estão constantemente aprimorando sua capacidade de extrair dados individuais de uma série de informações que o leigo consideraria seguras". </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Estudar seu histórico médico pode ajudá-lo a encontrar os genes responsáveis ​​pelo risco de doença de Alzheimer, reduzir o número de erros nos hospitais ou encontrar o melhor remédio para uma doença. </font><font style="vertical-align: inherit;">A única questão é como obter todos esses dados sem fornecer informações pessoais? </font><font style="vertical-align: inherit;">Um estudo de dez anos sobre esse tópico já está abordando uma solução universal.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Essa abordagem é chamada de "privacidade diferencial" e permite publicar dados enquanto protege as informações pessoais. O algoritmo de diferenciação de dados permite que os pesquisadores formulem qualquer consulta em um banco de dados que contenha informações confidenciais e recebam uma resposta "borrada" de forma a não revelar nenhum dado pessoal - até mesmo a presença de dados de uma pessoa específica nesse banco de dados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"A idéia é que você possa deixar seus dados serem utilizados sem risco", diz Cynthia Dvork, da Microsoft Research Silicon Valley. A Dvork introduziu o conceito de privacidade diferencial (RP) em 2005 com a ajuda de McSherry, Cobby Nissim e Adam Smith.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O método mantém o direito à "negação plausível", diz Avrim Blum, da Universidade Carnegie Mellon. “Se eu quiser fingir que minhas informações pessoais são diferentes daquilo que realmente tenho, posso fazê-lo. A saída do mecanismo de RP na prática não será muito diferente, independentemente de incluir o verdadeiro ou o falso - para que eu possa negar tudo o que quero. ”</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Um nível tão alto de privacidade parece inatingível. E, de fato, não há algoritmo RP útil que produziria um resultado completamente idêntico quando você fornecer seus dados reais ou fictícios. Mas você pode permitir que os algoritmos produzam dados quase idênticos. O grau de diferença é calibrado e representa uma quantificação de privacidade. Pessoas ou comunidades podem decidir qual valor desse parâmetro corresponde a um grau aceitável de perda de privacidade e escolher os algoritmos apropriados.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os especialistas em privacidade desenvolveram uma ampla gama de algoritmos de RP para processar dados diferentes e responder a perguntas diferentes sobre eles. </font><font style="vertical-align: inherit;">A maior parte do trabalho é difícil de ser percebida por pessoas que não são especialistas na área, então os cientistas estão desenvolvendo linguagens de computador padronizadas que permitirão que não apenas especialistas publiquem dados confidenciais no modo RP, apenas escrevendo um programa simples. </font><font style="vertical-align: inherit;">"O RP é uma tecnologia promissora e muito interessante", diz Aaron Roth, especialista em ciência da computação da Universidade da Pensilvânia. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/513/02c/9f4/51302c9f4253c9f12c6b444124903d4f.png"><br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O Comitê de Censo OnTheMap usa privacidade diferencial ao publicar dados, mas não divulgar informações pessoais</font></font></em><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agulha no palheiro</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Parece que, para resolver problemas de privacidade, você só precisa liberar dados generalizados relacionados a grandes grupos de pessoas. Mas mesmo essa abordagem está repleta de violação da integridade dos dados pessoais. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Suponha que você precise descobrir se o autor tem diabetes e você sabe que meus dados estão no banco de dados. Pode-se subtrair os resultados de duas consultas: “Quantas pessoas têm diabetes no banco de dados” e “Quantas pessoas no banco de dados, com um nome diferente de Eric Clarreich, têm diabetes”. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A combinação de duas dessas consultas viola minha privacidade. Mas nem sempre é claro que combinações específicas de perguntas podem violar a privacidade. Encontrar essas combinações é uma tarefa completa do NP, ou seja, não existe um algoritmo de computador eficaz para rastrear esses "ataques".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em 2008, os pesquisadores mostraram o perigo de publicar as informações agregadas obtidas na pesquisa genética geral - uma das principais ferramentas para encontrar a dependência do diabetes nos genes. Esses estudos envolvem a decodificação dos genes do grupo de teste de 100 a 1000 pacientes com a mesma doença, seguidos pelo cálculo da frequência média com a qual uma das 100.000 mutações ocorre. Se uma das mutações ocorre no grupo com muito mais frequência, ela é apontada como potencialmente associada à doença.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma equipe de pesquisadores liderada por Niels Homer, que era um estudante de graduação da Universidade da Califórnia na época, mostrou que, em muitos casos, conhecendo o genoma do paciente, você pode descobrir se ele fazia parte do grupo de testes do genoma. Depois disso, a associação de institutos médicos revogou o decreto de publicação dos dados obtidos em estudos genéticos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os pesquisadores chegaram a uma conclusão ainda mais surpreendente em 2011 - é possível extrair informações pessoais sobre compras, guiadas por um sistema de recomendação com a Amazon, que fornece resultados como “quem comprou e também comprou B e C”. </font><font style="vertical-align: inherit;">Observando as alterações nas recomendações e comparando-as com as avaliações que as pessoas fazem sobre os itens comprados, em vários casos, os pesquisadores conseguiram dizer que um comprador em particular comprou um item em um dia específico - mesmo antes de publicar uma revisão desse item. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em todos os casos, as medidas de privacidade parecem adequadas, desde que não sejam suficientes. </font><font style="vertical-align: inherit;">Mas já naquele momento uma nova abordagem para proteger a privacidade estava sendo preparada, obtida pela busca da resposta para a pergunta principal: o que significa proteger a privacidade?</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A privacidade de dois mundos</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se os pesquisadores examinarem o banco de dados de pacientes e encontrarem uma conexão entre fumar e algum tipo de câncer, a privacidade diferencial não protegerá uma pessoa que fuma em um local público do rótulo de uma pessoa com maior risco de adoecer. Mas se fumar é o segredo de uma pessoa, escondido na base, o RP o protegerá. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
“Diferença” significa levar em consideração a diferença de dois mundos: em um deles você permite incluir seus dados pessoais no banco de dados e no outro não. Os dois mundos não serão absolutamente idênticos, mas podem ser feitos o mais semelhante possível, e será quase impossível distinguir entre eles. Esse é o objetivo do RP.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O RP se concentra em algoritmos que emitem dados, recebem consultas no banco de dados e emitem respostas - não exatas, mas modificadas aleatoriamente. Se você fizer a mesma pergunta em duas bases que diferem apenas nos dados de uma pessoa, obterá essencialmente as mesmas respostas. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/dec/c26/3a8/decc263a89964b471bc03f0664b18572.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Representação RP do local dos usuários que pesquisam a palavra "críquete" em um mecanismo de pesquisa</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mais precisamente, para qualquer resposta possível, a probabilidade de recebimento deve ser a mesma para os dois bancos de dados; a razão dessas duas probabilidades deve ser limitada a um número R próximo à unidade. Quanto mais R estiver próximo de 1, mais difícil é para um invasor descobrir se ele recebe informações da base A ou da base B e a pessoa mais protegida X estará. Como se o invasor não puder saber se as informações recebidas por ele incluem informações sobre X, ele não será capaz de entender quais dados se referem ao X. Os </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
pesquisadores de RP geralmente falam sobre o logaritmo de R e denotam-no por Ɛ. O parâmetro quantifica o vazamento de dados pessoais. Quanto mais próximo de zero, melhor o algoritmo protege a privacidade.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para entender como o algoritmo RP pode ser construído, vejamos o exemplo mais simples de tal algoritmo. Ele usa um cenário em que o questionador pode fazer apenas consultas quantitativas. Por exemplo: “quantas pessoas no banco de dados possuem propriedade C?” </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Suponha que a resposta real para uma das perguntas seja 157. O algoritmo RP adicionará "ruído" a ela - antes de emitir uma resposta, adicione ou subtraia um número aleatório. Como resultado, obtemos 153, 159 ou 292. O interlocutor conhece a distribuição de probabilidade usada pelo algoritmo; portanto, sabe aproximadamente a distorção do resultado real (caso contrário, o problema seria completamente inútil). Mas que tipo de número aleatório foi adicionado à resposta, ele não sabe.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A fórmula de distribuição deve ser escolhida com cuidado. Para entender qual distribuição garante privacidade, vamos imaginar que um solicitante persistente tente descobrir se estou no banco de dados. Ele pergunta: "Quantas pessoas chamadas Eric Clarreich estão no banco de dados?" Suponha que ele receba uma resposta de 100. Como esse nome é raro, ele percebe que a resposta era realmente 0 ou 1. Ele tem duas possibilidades: </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A) a resposta é 0 e o algoritmo adicionou 100 como ruído; </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
B) a resposta é 1, e o algoritmo adicionou 99 A </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
probabilidade de escolher 100 e 99 deve ser a mesma. Então o questionador não pode distinguir entre esses dois casos. Mais precisamente, a razão dessas duas probabilidades não deve exceder um R. predeterminado. E essa condição deve ser preservada não apenas para os pares 100 e 99, mas também para quaisquer dois números consecutivos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Esta propriedade tem a distribuição Laplace. Seu pico agudo cai para zero e, em seguida, o gráfico diminui gradualmente nas duas direções. Para isso, a condição para a existência do número R (largura da distribuição) é satisfeita, de modo que, para dois números consecutivos, a razão de suas probabilidades seja R. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para cada largura, existe uma distribuição possível de Laplace. Portanto, você pode brincar com a largura para obter uma distribuição que forneça exatamente o grau de privacidade que precisamos. Para uma forte privacidade, a distribuição será relativamente ampla e plana. Números distantes de 0 cairão com quase a mesma probabilidade que números próximos de zero. Os dados serão borrados bastante.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Naturalmente, há um confronto entre privacidade e utilidade. Quanto mais privacidade você precisar, mais ruído precisará adicionar e menos útil será a resposta. Ao usar a distribuição Laplace, a quantidade de ruído adicionado volta Ɛ. Se o parâmetro de privacidade for 0,01, o algoritmo borrará os indicadores quantitativos em cerca de 100. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quanto maior o conjunto de dados, menos o borrão especificado afetará o utilitário. Em um banco de dados de centenas de registros, um desfoque de 100 interferirá mais do que em um banco de dados de milhões de registros. Segundo Dvork, para dados em escala de Internet, ou seja, centenas de milhões, o algoritmo já oferece privacidade suficiente para uso prático.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E o "ruído", segundo Laplace, é apenas o primeiro estágio da implementação do PR. Os pesquisadores já criaram um grande número de algoritmos muito mais complexos, para muitos dos quais a proporção de utilidade e privacidade excede a de Laplace em determinadas situações. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"As pessoas sempre encontram maneiras de melhorar e ainda há espaço para melhorias", diz Dvork. Quanto a conjuntos de dados mais modestos que a Internet, ela disse: "existem algoritmos para muitas tarefas".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com o algoritmo RP, não há necessidade de analisar cuidadosamente os problemas por violações da privacidade - essa proteção já está embutida no algoritmo. Como perguntas que interferem em seus próprios assuntos geralmente se resumem a pequenos números relacionados a pessoas específicas, e questões de natureza diferente estudam o comportamento de grandes grupos, a quantidade de ruído adicional que nega as características individuais terá pouco efeito nas respostas a perguntas legítimas. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com o RP, os problemas dos pesquisadores de dados, como comparações cruzadas com fontes externas, desaparecem. A abordagem matemática não espera que o invasor tenha fontes limitadas de informações externas.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"A abordagem de RP implica que o invasor é onipotente", diz McSherry. </font><font style="vertical-align: inherit;">- Mesmo que o invasor retorne após 100 anos, acumulando idéias e tecnologias de computador o tempo todo, ele ainda não conseguirá descobrir se você está no banco de dados. </font><font style="vertical-align: inherit;">O RP está protegido do futuro. ”</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Primitivo fundamental</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Até agora, estamos considerando uma situação em que alguém faz consultas ao banco de dados com um número como resposta. </font><font style="vertical-align: inherit;">Mas a realidade é mais complicada. </font><font style="vertical-align: inherit;">Os pesquisadores querem fazer muitas perguntas ao banco de dados. </font><font style="vertical-align: inherit;">E, com o tempo, partes de suas informações pessoais chegarão a vários bancos de dados, cada um dos quais fornecerá dados sem perguntar ao resto.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O RP fornece uma maneira fácil e precisa de avaliar a ameaça geral à privacidade quando os pesquisadores fazem a todas as bases de dados em que seus dados apresentam várias perguntas. Suponha que, se seus dados estiverem em dois bancos de dados, e esses dados forem fornecidos de acordo com algoritmos que fornecem os parâmetros de privacidade Ɛ1 e Ɛ2, a quantidade total de informações pessoais vazadas não será maior que Ɛ1 + Ɛ2. A mesma fórmula funciona para um único banco de dados com várias consultas. Para m consultas, o vazamento será delimitado acima de m * Ɛ. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em teoria, um curador de banco de dados pode permitir que os pesquisadores façam quantas perguntas quiserem, adicionando a quantidade necessária de ruído de Laplace a cada resposta, para que a quantidade total de dados pessoais vazados não exceda um determinado limite.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Acontece que o limite de respostas numéricas não é tão crítico. Muitas outras consultas podem ser alteradas para que se tornem quantitativas. Por exemplo, se você precisar criar uma lista de centenas dos nomes mais populares para bebês nascidos em 2012, poderá, por exemplo, fazer uma sequência de perguntas como "Quantas crianças receberam nomes começando com A?" E processar os resultados. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Um dos primeiros resultados do aprendizado de máquina afirma que qualquer coisa que possa ser aprendida em princípio pode ser aprendida usando consultas numéricas", diz Aaron Roth. “Tais solicitações não são brinquedos em si mesmas, mas uma primitiva fundamental”, isto é, tijolos, com base nos quais algoritmos mais complexos podem ser construídos.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mas há um problema. Quanto mais perguntas pudermos fazer, mais ruído será adicionado a cada resposta. Vejamos um exemplo com nomes. Se decidirmos limitar a despesa máxima de privacidade Ɛ a 0,01, e os nomes forem 10.000, o limite de privacidade para cada problema será Ɛ / 10.000 ou 0,000001. O nível de ruído será 10.000 / Ɛ ou 1.000.000 - e esse nível simplesmente elimina os resultados reais. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em outras palavras, a abordagem “frontal” com a adição de ruído de Laplace a cada resposta é limitada pelo número de perguntas possíveis. Para remediar a situação, os programadores tiveram que desenvolver primitivas mais adequadas - "tijolos" algorítmicos, com a ajuda de que, dada a estrutura de uma base e tarefa específica, podem responder a mais perguntas com maior precisão.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por exemplo, em 2005, Smith descobriu que a tarefa com nomes tem uma estrutura especial: remover informações sobre uma pessoa do banco de dados altera a resposta para apenas um em cada 10.000 nomes. Portanto, não podemos adicionar mais de 1 / Ɛ ruído a cada resposta, em vez de 10.000 / Ɛ, e a privacidade da resposta permanecerá dentro do nosso limite. Tal primitivo pode ser aplicado a qualquer consulta de "histograma" - ou seja, uma consulta sobre quantas pessoas se enquadram em uma das várias categorias mutuamente exclusivas, como nomes. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quando Smith disse ao Dwork sobre isso, "algo dentro de mim se alegrou", diz o Dwork. "Percebi que podemos usar a estrutura da solicitação ou cálculo e obter uma precisão muito maior da resposta".</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Desde então, os cientistas da computação desenvolveram uma grande biblioteca de tais primitivos. E como a regra aditiva explica o que acontece com a privacidade ao combinar algoritmos, os programadores podem montar esses "tijolos" em estruturas complexas, enquanto monitoram as restrições ao vazamento de privacidade. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para simplificar o acesso ao sistema RP para pessoas que não são especialistas, vários grupos estão trabalhando na criação de uma linguagem de programação que nos permitirá abstrair dos fundamentos matemáticos dos algoritmos. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/544/ab9/935/544ab99355f19d64391b846f42ea6ec5.jpg"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
PINQ - um dos exemplos de PL para RP</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
As linguagens de programação para trabalhar com privacidade diferencial, como o PINQ, fornecem uma interface para dados confidenciais e permitem que você faça perguntas sobre eles, ajustando respostas para proteger a privacidade. </font><font style="vertical-align: inherit;">"Se você é responsável por um conjunto de dados, não precisa se preocupar com o que as pessoas fazem com ele enquanto as consultas são feitas usando este PL", diz McSherry, que criou o idioma PINQ. </font><font style="vertical-align: inherit;">"O programa garante a segurança das consultas."</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Recurso não renovável</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como a regra aditiva simples para Ɛ define o limite superior exato da perda de privacidade quando diferentes bancos de dados que contêm seus dados fornecem respostas para consultas, essa regra, de acordo com McSherry, transforma a privacidade em uma moeda. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por exemplo, se você decidir qual restrição à perda de privacidade para você pessoalmente é aceitável para toda a sua vida, poderá decidir "gastar" essa privacidade - trocando por dinheiro ou apoiando um bom projeto de pesquisa. Sempre que você permitir o uso de seus dados em uma nova liberação de informações, você saberá qual é o saldo do seu "orçamento" de privacidade.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
E o curador do conjunto de dados pode decidir como gastar a quantidade de privacidade que ele decidiu liberar - por exemplo, considere propostas de projetos de pesquisa que descrevam não apenas as solicitações disponíveis, mas também a quantidade de privacidade usada nos projetos. Em seguida, o curador poderá escolher quais projetos usarão melhor o “orçamento” existente desse conjunto de informações. Depois que o orçamento é gasto, o conjunto de dados é fechado. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"A privacidade é um recurso não renovável", diz McSherry. "Assim que você gasta, ele desaparece."</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quando perguntados sobre qual valor Ɛ representa uma restrição aceitável à perda de privacidade, a sociedade deve responder, não os programadores. </font><font style="vertical-align: inherit;">E todos podem ter sua própria resposta. </font><font style="vertical-align: inherit;">E embora a perspectiva de atribuir um preço a algo intangível como privacidade possa parecer assustadora, já existem análogos disso. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Há outro recurso com as mesmas propriedades - o relógio da sua vida", diz McSherry. </font><font style="vertical-align: inherit;">"O número deles é limitado e, depois que você os gasta, eles desaparecem." </font><font style="vertical-align: inherit;">Mas, como temos uma moeda e um mercado de trabalho, nossa sociedade criou como atribuir um preço ao tempo humano. </font><font style="vertical-align: inherit;">Pode-se imaginar como a mesma coisa acontecerá com a privacidade. ”</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt398011/">https://habr.com/ru/post/pt398011/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt397997/index.html">Repensando o programa de fidelidade usando a tecnologia blockchain</a></li>
<li><a href="../pt397999/index.html">20 aplicações do Blockchain fora dos serviços financeiros, parte 1</a></li>
<li><a href="../pt398001/index.html">Internet das distâncias</a></li>
<li><a href="../pt398003/index.html">As figuras mais influentes da comunidade Blockchain 2016</a></li>
<li><a href="../pt398005/index.html">Audio Digest 10: Entrevistas, vinil e guias temáticos</a></li>
<li><a href="../pt398013/index.html">Google ensina robôs a realizar novas tarefas no "jardim de infância"</a></li>
<li><a href="../pt398015/index.html">Por que não consigo usar um no-break de computador para alimentar uma caldeira a gás?</a></li>
<li><a href="../pt398017/index.html">Anunciados os ganhadores do Prêmio Nobel de Física</a></li>
<li><a href="../pt398021/index.html">Pergunte a Ethan No. 96: A teoria do universo é científica?</a></li>
<li><a href="../pt398023/index.html">O Grande Caminho da Sibéria - 100 anos (atualizado)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
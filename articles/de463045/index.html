<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩‍👦 🍹 👩🏽‍🎤 Erkennen Sie Emotionen automatisch in Textkonversationen mithilfe neuronaler Netze 🔐 🍕 🚤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine der Hauptaufgaben von Dialogsystemen besteht nicht nur darin, die Informationen bereitzustellen, die der Benutzer benötigt, sondern auch so viele...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erkennen Sie Emotionen automatisch in Textkonversationen mithilfe neuronaler Netze</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/463045/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Eine der Hauptaufgaben von Dialogsystemen besteht nicht nur darin, die Informationen bereitzustellen, die der Benutzer benötigt, sondern auch so viele menschliche Antworten wie möglich zu generieren.  Und das Erkennen der Emotionen des Gesprächspartners ist nicht mehr nur ein cooles Feature, sondern eine wichtige Notwendigkeit.  In diesem Artikel werden wir uns mit der <b>Architektur eines wiederkehrenden neuronalen Netzwerks zur Bestimmung von Emotionen in Textkonversationen</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">befassen</a> , das am <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SemEval-2019 Task 3 „EmoContext“</a> , dem jährlichen Wettbewerb für Computerlinguistik, teilgenommen hat.  Die Aufgabe bestand darin, Emotionen („glücklich“, „traurig“, „wütend“ und „andere“) in einem Gespräch mit drei Bemerkungen zu klassifizieren, an dem ein Chat-Bot und eine Person teilnahmen. <br><br>  Im ersten Teil des Artikels werden wir die in EmoContext festgelegte Aufgabe und die von den Organisatoren bereitgestellten Daten betrachten.  Im zweiten und dritten Teil analysieren wir die vorläufige Verarbeitung des Textes und die Art und Weise der Vektordarstellung von Wörtern.  Im vierten Teil beschreiben wir die LSTM-Architektur, die wir im Wettbewerb verwendet haben.  Der Code wird in Python mithilfe der Keras-Bibliothek geschrieben. <br><a name="habracut"></a><br><h2>  1. Trainingsdaten </h2><br>  Der Titel „EmoContext“ auf der SemEval-2019 widmete sich der Definition von Emotionen in Textkonversationen unter Berücksichtigung des Kontextes der Korrespondenz.  Der Kontext in diesem Fall sind mehrere aufeinanderfolgende Bemerkungen von Dialogteilnehmern.  Es gibt zwei Teilnehmer an der Konversation: einen anonymen Benutzer (er besitzt die erste und dritte Replik) und einen Chat-Bot <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ruuh</a> (er besitzt die zweite Replik).  Anhand von drei Replikaten muss ermittelt werden, welche Emotionen der Benutzer beim Schreiben einer Antwort auf den Chatbot verspürt hat (Tabelle 1).  Insgesamt enthielt das Markup des Datensatzes vier Emotionen: „glücklich“, „traurig“, „wütend“ oder „andere“ (Tabelle 1).  Eine detaillierte Beschreibung wird hier vorgestellt: ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabelle 1. Beispiele aus dem EmoContext-Datensatz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Benutzer (Stufe 1) </th><th>  Interaktiver Roboter (Stufe 1) </th><th>  Benutzer (Stufe 2) </th><th>  Wahre Klasse </th></tr><tr><td>  Ich habe mich gerade für das Nabard-Praktikum qualifiziert </td><td>  WOOT!  Das sind großartige Neuigkeiten.  Glückwunsch! </td><td>  Ich fing an zu weinen </td><td>  Glück </td></tr><tr><td>  Wie kannst du es wagen, mein Kind zu schlagen? </td><td>  Wenn Sie mein Auto verwöhnen, werde ich Ihnen das auch antun </td><td>  Versuchen Sie das einfach einmal </td><td>  Wut </td></tr><tr><td>  Ich wurde von dir mehr verletzt </td><td>  Du hast es nicht so gemeint. </td><td>  Sag, du liebst mich </td><td>  Traurigkeit </td></tr><tr><td>  Ich werde Nacht machen. </td><td>  In Ordnung.  Halte mich auf dem Laufenden. </td><td>  Keine WhatsApp-Nr. </td><td>  Andere </td></tr></tbody></table></div><br>  Während des Wettbewerbs stellten die Organisatoren mehrere Datensätze zur Verfügung.  Der Trainingsdatensatz (Train) bestand aus 30.160 manuell markierten Texten.  In diesen Texten befanden sich ungefähr 5000 Objekte der Klassen „glücklich“, „traurig“ und „wütend“ sowie 15000 Texte der Klasse „andere“ (Tabelle 2). <br><br>  Die Organisatoren stellten auch Datensätze für Entwicklung (Dev) und Test (Test) zur Verfügung, in denen im Gegensatz zum Trainingsdatensatz die Verteilung nach Emotionsklassen dem realen Leben entsprach: etwa 4% für jede der Klassen „glücklich“, „traurig“ und „ wütend ", und der Rest ist die Klasse" andere ".  Von Microsoft bereitgestellte Daten können Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offiziellen Gruppe auf LinkedIn</a> herunterladen. <br><br>  <i>Tabelle 2. Verteilung der Emotionsklassenbezeichnungen im Datensatz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Datacet </th><th>  Glück </th><th>  Traurigkeit </th><th>  Wut </th><th>  Andere </th><th>  Insgesamt </th></tr><tr><td>  Schulung <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30 160 <br></td></tr><tr><td>  Zu entwickeln <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Test <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Fernbedienung <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900 Tausend <br></td></tr></tbody></table></div><br>  Zusätzlich zu diesen Daten haben wir 900.000 englischsprachige Nachrichten von Twitter gesammelt, um einen entfernten Datensatz zu erstellen (300.000 Tweets für jede Emotion).  Bei der Erstellung folgten wir der Strategie von Go et al.  (2009), in dessen Rahmen Botschaften einfach mit dem Vorhandensein von Wörtern in Verbindung gebracht wurden, die sich auf Emotionen beziehen, wie z. B. #angry, #annoyed, #happy, #sad, #surprised und so weiter.  Die Liste der Begriffe basiert auf den Begriffen von SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Duppada et al., 2018</a> ). <br><br>  Die Hauptqualitätsmetrik im EmoContext-Wettbewerb ist das durchschnittliche F1-Maß für die drei Klassen von Emotionen, dh für die Klassen „glücklich“, „traurig“ und „wütend“. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Textvorverarbeitung </h2><br>  Vor dem Training haben wir die Texte mit dem Ekphrasis-Tool vorverarbeitet (Baziotis et al., 2017).  Es hilft, Rechtschreibung zu korrigieren, Wörter und Segmente zu normalisieren und mithilfe spezieller Tags zu bestimmen, welche Token gelöscht, normalisiert oder mit Anmerkungen versehen werden sollen.  In der Vorverarbeitungsphase haben wir Folgendes durchgeführt: <br><br><ul><li>  URLs und E-Mails, Datum und Uhrzeit, Spitznamen, Prozentsätze, Währungen und Zahlen wurden durch entsprechende Tags ersetzt. </li><li>  Wiederholte, zensierte, verlängerte Großbuchstaben werden von entsprechenden Etiketten begleitet. </li><li>  Längliche Wörter wurden automatisch korrigiert. </li></ul><br>  Darüber hinaus enthält Emphasis einen Tokenizer, mit dem die meisten Emojis, Emoticons und komplexen Ausdrücke sowie Datums-, Uhrzeit-, Währungs- und Akronyme identifiziert werden können. <br><br>  <i>Tabelle 3. Beispiele für die Textvorverarbeitung.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Quelltext </th><th>  Vorverarbeiteter Text </th></tr><tr><td>  Ich fühle dich ... Ich zerbreche in Millionen Stücke <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; Ich fühle dich &lt;/ allcaps&gt;.  &lt;wiederholt&gt; Ich zerbreche in Millionen Stücke <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  müde und ich habe dich auch vermisst :-( </td><td>  müde und ich habe dich auch vermisst &lt;sad&gt; </td></tr><tr><td>  Du solltest dir das anhören: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  Sie sollten &lt;elongated&gt; Folgendes anhören: &lt;url&gt; </td></tr><tr><td>  Meine Wohnung kümmert sich darum.  Meine Miete liegt bei 650 Dollar. </td><td>  Meine Wohnung kümmert sich darum.  Meine Miete liegt bei &lt;Geld&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^・^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑c'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‑/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‑]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‑':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‑("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‑["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‑d'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Vektordarstellung von Wörtern </h2><br>  Die Vektordarstellung ist ein wesentlicher Bestandteil der meisten Ansätze zur Erstellung von NLP-Systemen mithilfe von Deep Learning geworden.  Um die am besten geeigneten Vektorkartierungsmodelle zu bestimmen, haben wir Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pennington et al., 2014</a> ) und FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Joulin et al., 2017</a> ) sowie vorab trainierte DataStories-Vektoren ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Baziotis et al.) Versucht. ., 2017</a> ).  Word2Vec findet Beziehungen zwischen Wörtern, indem angenommen wird, dass semantisch verwandte Wörter in ähnlichen Kontexten gefunden werden.  Word2Vec versucht, das Zielwort (CBOW-Architektur) oder den Kontext (Skip-Gram-Architektur) vorherzusagen, dh die Verlustfunktion zu minimieren, und GloVe berechnet Wortvektoren, wodurch die Dimension der Adjazenzmatrix verringert wird.  Die Logik von FastText ähnelt der Logik von Word2Vec, verwendet jedoch symbolische n-Gramm, um Wortvektoren zu erstellen, und kann daher das Problem unbekannter Wörter lösen. <br><br>  Für alle genannten Modelle verwenden wir die von den Autoren angegebenen Standard-Trainingsparameter.  Wir haben ein einfaches LSTM-Modell (dim = 64) basierend auf jeder dieser Vektordarstellungen trainiert und die Klassifizierungseffizienz mithilfe einer Kreuzvalidierung verglichen.  Das beste Ergebnis bei F1-Messungen wurde durch vorab trainierte DataStories-Vektoren gezeigt. <br><br>  Um die ausgewählte Vektorkartierung mit der emotionalen Färbung von Wörtern anzureichern, haben wir beschlossen, die Vektoren mithilfe des automatisch beschrifteten Distant- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datensatzes zu optimieren</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deriu et al., 2017</a> ).  Wir haben den Distant-Datensatz verwendet, um ein einfaches LSTM-Netzwerk zu trainieren, um "böse", "traurige" und "glückliche" Nachrichten zu klassifizieren.  Die Einbettungsschicht wurde während der ersten Iteration des Trainings eingefroren, um starke Änderungen in den Gewichten der Vektoren zu vermeiden, und für die nächsten fünf Iterationen wurde die Schicht aufgetaut.  Nach dem Training wurden die "verzögerten" Vektoren für die spätere Verwendung im neuronalen Netzwerk gespeichert <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">und gemeinsam genutzt</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Neuronale Netzwerkarchitektur </h2><br>  Recurrent Neural Networks (RNNs) sind eine Familie neuronaler Netze, die sich auf die Verarbeitung einer Reihe von Ereignissen spezialisiert haben.  Im Gegensatz zu herkömmlichen neuronalen Netzen sind RNNs so konzipiert, dass sie mit Sequenzen unter Verwendung interner Salden arbeiten.  Zu diesem Zweck enthält der Berechnungsgraph RNN Zyklen, die den Einfluss vorheriger Informationen aus der Abfolge von Ereignissen auf die aktuelle widerspiegeln.  LSTM-Neuronale Netze (Long Short-Term Memory) wurden 1997 als Erweiterung von RNN eingeführt ( <a href="">Hochreiter und Schmidhuber, 1997</a> ).  LSTM-Wiederholungszellen sind verbunden, um Burst- und Fade-Probleme zu vermeiden.  Herkömmliche LSTMs behalten nur frühere Informationen bei, wenn sie die Sequenz in eine Richtung verarbeiten.  Bidirektionale LSTMs, die in beide Richtungen arbeiten, kombinieren die Ausgabe von zwei verborgenen LSTM-Schichten, die Informationen in entgegengesetzte Richtungen übertragen - eine im Laufe der Zeit und die andere dagegen - und gleichzeitig Daten aus vergangenen und zukünftigen Zuständen empfangen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schuster und Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Abbildung 1: Reduzierte Version der Architektur.</i>  <i>Das LSTM-Modul verwendet für die erste und dritte Stufe die gleichen Gewichte.</i> <br><br>  Eine vereinfachte Darstellung des beschriebenen Ansatzes ist in Abbildung 1 dargestellt. Die Architektur des neuronalen Netzwerks besteht aus einer Einbettungsschicht und zwei bidirektionalen LTSM-Modulen (dim = 64).  Das erste LTSM-Modul analysiert die Wörter des ersten Benutzers (d. H. Die erste und dritte Replik der Konversation), und das zweite Modul analysiert die Wörter des zweiten Benutzers (zweite Replik).  In der ersten Stufe werden die Wörter jedes Benutzers, die vorab trainierte Vektordarstellungen verwenden, in das entsprechende bidirektionale LTSM-Modul eingespeist.  Dann werden die resultierenden drei Merkmalskarten zu einem flachen Merkmalsvektor kombiniert und dann auf eine vollständig verbundene verborgene Schicht (dim = 30) übertragen, die die Wechselwirkungen zwischen den extrahierten Merkmalen analysiert.  Schließlich werden diese Eigenschaften in der Ausgabeschicht unter Verwendung der Softmax-Aktivierungsfunktion verarbeitet, um die endgültige Klassenbezeichnung zu bestimmen.  Um die Überanpassung zu verringern, wurden nach Schichten der Vektordarstellung Regularisierungsschichten mit Gaußschem Rauschen hinzugefügt, und jedem LTSM-Modul (p = 0,2) und einer verborgenen vollständig verbundenen Schicht (p = 0,1) wurden Dropout-Schichten hinzugefügt ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Srivastava et al., 2014)</a> ) <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Ergebnisse </h2><br>  Auf der Suche nach der optimalen Architektur haben wir nicht nur mit der Anzahl der Neuronen in den Schichten, Aktivierungsfunktionen und Regularisierungsparametern experimentiert, sondern auch mit der Architektur des neuronalen Netzwerks selbst.  Dies wird in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Originalarbeit</a> ausführlicher beschrieben. <br><br>  Die im vorherigen Abschnitt beschriebene Architektur zeigte die besten Ergebnisse beim Training des Train-Datensatzes und der Validierung des Dev-Datensatzes, sodass sie in der letzten Phase des Wettbewerbs verwendet wurde.  Beim letzten Testdatensatz zeigte das Modell ein mikro-gemitteltes F1-Maß von 72,59%, und das maximal erzielte Ergebnis unter allen Teilnehmern betrug 79,59%.  Trotzdem war unser Ergebnis viel höher als der von den Organisatoren festgelegte Basiswert von 58,68%. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Quellcode für die Modell- und Vektordarstellung von Wörtern</a> ist auf GitHub verfügbar. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Vollversion des Artikels</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit mit der Aufgabenbeschreibung</a> finden Sie auf der ACL Anthology-Website. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Trainingsdatensatz</a> kann von der offiziellen LinkedIn-Gruppe heruntergeladen werden. <br><br>  Zitat: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de463045/">https://habr.com/ru/post/de463045/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de463031/index.html">Lebe und lerne. Teil 3. Weiterbildung oder das Alter des ewigen Schülers</a></li>
<li><a href="../de463035/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 471 (23.07.2019 - 29.07.2019)</a></li>
<li><a href="../de463037/index.html">Auf der Suche nach Inspiration oder wie man sich aus F herausholt</a></li>
<li><a href="../de463039/index.html">Maniküre-Staubsauger zum Selbermachen</a></li>
<li><a href="../de463041/index.html">Definiert oder undefiniert? Nuancen beim Erstellen von Arrays in JavaScript</a></li>
<li><a href="../de463055/index.html">Über Administratoren, Entwickler, endlose Verwirrung und DevOps-Transformation innerhalb des Unternehmens</a></li>
<li><a href="../de463057/index.html">Benutzerdefinierte Rechte für Yii Framework 2</a></li>
<li><a href="../de463059/index.html">Drei leben in der IT und nicht nur</a></li>
<li><a href="../de463061/index.html">Regeln für die Erstellung von Layouts in Figma</a></li>
<li><a href="../de463063/index.html">Wir beschäftigen uns mit Schnittstellen in Go</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
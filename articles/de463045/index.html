<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüë¶ üçπ üë©üèΩ‚Äçüé§ Erkennen Sie Emotionen automatisch in Textkonversationen mithilfe neuronaler Netze üîê üçï üö§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine der Hauptaufgaben von Dialogsystemen besteht nicht nur darin, die Informationen bereitzustellen, die der Benutzer ben√∂tigt, sondern auch so viele...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erkennen Sie Emotionen automatisch in Textkonversationen mithilfe neuronaler Netze</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/463045/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Eine der Hauptaufgaben von Dialogsystemen besteht nicht nur darin, die Informationen bereitzustellen, die der Benutzer ben√∂tigt, sondern auch so viele menschliche Antworten wie m√∂glich zu generieren.  Und das Erkennen der Emotionen des Gespr√§chspartners ist nicht mehr nur ein cooles Feature, sondern eine wichtige Notwendigkeit.  In diesem Artikel werden wir uns mit der <b>Architektur eines wiederkehrenden neuronalen Netzwerks zur Bestimmung von Emotionen in Textkonversationen</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">befassen</a> , das am <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SemEval-2019 Task 3 ‚ÄûEmoContext‚Äú</a> , dem j√§hrlichen Wettbewerb f√ºr Computerlinguistik, teilgenommen hat.  Die Aufgabe bestand darin, Emotionen (‚Äûgl√ºcklich‚Äú, ‚Äûtraurig‚Äú, ‚Äûw√ºtend‚Äú und ‚Äûandere‚Äú) in einem Gespr√§ch mit drei Bemerkungen zu klassifizieren, an dem ein Chat-Bot und eine Person teilnahmen. <br><br>  Im ersten Teil des Artikels werden wir die in EmoContext festgelegte Aufgabe und die von den Organisatoren bereitgestellten Daten betrachten.  Im zweiten und dritten Teil analysieren wir die vorl√§ufige Verarbeitung des Textes und die Art und Weise der Vektordarstellung von W√∂rtern.  Im vierten Teil beschreiben wir die LSTM-Architektur, die wir im Wettbewerb verwendet haben.  Der Code wird in Python mithilfe der Keras-Bibliothek geschrieben. <br><a name="habracut"></a><br><h2>  1. Trainingsdaten </h2><br>  Der Titel ‚ÄûEmoContext‚Äú auf der SemEval-2019 widmete sich der Definition von Emotionen in Textkonversationen unter Ber√ºcksichtigung des Kontextes der Korrespondenz.  Der Kontext in diesem Fall sind mehrere aufeinanderfolgende Bemerkungen von Dialogteilnehmern.  Es gibt zwei Teilnehmer an der Konversation: einen anonymen Benutzer (er besitzt die erste und dritte Replik) und einen Chat-Bot <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ruuh</a> (er besitzt die zweite Replik).  Anhand von drei Replikaten muss ermittelt werden, welche Emotionen der Benutzer beim Schreiben einer Antwort auf den Chatbot versp√ºrt hat (Tabelle 1).  Insgesamt enthielt das Markup des Datensatzes vier Emotionen: ‚Äûgl√ºcklich‚Äú, ‚Äûtraurig‚Äú, ‚Äûw√ºtend‚Äú oder ‚Äûandere‚Äú (Tabelle 1).  Eine detaillierte Beschreibung wird hier vorgestellt: ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabelle 1. Beispiele aus dem EmoContext-Datensatz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Benutzer (Stufe 1) </th><th>  Interaktiver Roboter (Stufe 1) </th><th>  Benutzer (Stufe 2) </th><th>  Wahre Klasse </th></tr><tr><td>  Ich habe mich gerade f√ºr das Nabard-Praktikum qualifiziert </td><td>  WOOT!  Das sind gro√üartige Neuigkeiten.  Gl√ºckwunsch! </td><td>  Ich fing an zu weinen </td><td>  Gl√ºck </td></tr><tr><td>  Wie kannst du es wagen, mein Kind zu schlagen? </td><td>  Wenn Sie mein Auto verw√∂hnen, werde ich Ihnen das auch antun </td><td>  Versuchen Sie das einfach einmal </td><td>  Wut </td></tr><tr><td>  Ich wurde von dir mehr verletzt </td><td>  Du hast es nicht so gemeint. </td><td>  Sag, du liebst mich </td><td>  Traurigkeit </td></tr><tr><td>  Ich werde Nacht machen. </td><td>  In Ordnung.  Halte mich auf dem Laufenden. </td><td>  Keine WhatsApp-Nr. </td><td>  Andere </td></tr></tbody></table></div><br>  W√§hrend des Wettbewerbs stellten die Organisatoren mehrere Datens√§tze zur Verf√ºgung.  Der Trainingsdatensatz (Train) bestand aus 30.160 manuell markierten Texten.  In diesen Texten befanden sich ungef√§hr 5000 Objekte der Klassen ‚Äûgl√ºcklich‚Äú, ‚Äûtraurig‚Äú und ‚Äûw√ºtend‚Äú sowie 15000 Texte der Klasse ‚Äûandere‚Äú (Tabelle 2). <br><br>  Die Organisatoren stellten auch Datens√§tze f√ºr Entwicklung (Dev) und Test (Test) zur Verf√ºgung, in denen im Gegensatz zum Trainingsdatensatz die Verteilung nach Emotionsklassen dem realen Leben entsprach: etwa 4% f√ºr jede der Klassen ‚Äûgl√ºcklich‚Äú, ‚Äûtraurig‚Äú und ‚Äû w√ºtend ", und der Rest ist die Klasse" andere ".  Von Microsoft bereitgestellte Daten k√∂nnen Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offiziellen Gruppe auf LinkedIn</a> herunterladen. <br><br>  <i>Tabelle 2. Verteilung der Emotionsklassenbezeichnungen im Datensatz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Datacet </th><th>  Gl√ºck </th><th>  Traurigkeit </th><th>  Wut </th><th>  Andere </th><th>  Insgesamt </th></tr><tr><td>  Schulung <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30 160 <br></td></tr><tr><td>  Zu entwickeln <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Test <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Fernbedienung <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900 Tausend <br></td></tr></tbody></table></div><br>  Zus√§tzlich zu diesen Daten haben wir 900.000 englischsprachige Nachrichten von Twitter gesammelt, um einen entfernten Datensatz zu erstellen (300.000 Tweets f√ºr jede Emotion).  Bei der Erstellung folgten wir der Strategie von Go et al.  (2009), in dessen Rahmen Botschaften einfach mit dem Vorhandensein von W√∂rtern in Verbindung gebracht wurden, die sich auf Emotionen beziehen, wie z. B. #angry, #annoyed, #happy, #sad, #surprised und so weiter.  Die Liste der Begriffe basiert auf den Begriffen von SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Duppada et al., 2018</a> ). <br><br>  Die Hauptqualit√§tsmetrik im EmoContext-Wettbewerb ist das durchschnittliche F1-Ma√ü f√ºr die drei Klassen von Emotionen, dh f√ºr die Klassen ‚Äûgl√ºcklich‚Äú, ‚Äûtraurig‚Äú und ‚Äûw√ºtend‚Äú. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Textvorverarbeitung </h2><br>  Vor dem Training haben wir die Texte mit dem Ekphrasis-Tool vorverarbeitet (Baziotis et al., 2017).  Es hilft, Rechtschreibung zu korrigieren, W√∂rter und Segmente zu normalisieren und mithilfe spezieller Tags zu bestimmen, welche Token gel√∂scht, normalisiert oder mit Anmerkungen versehen werden sollen.  In der Vorverarbeitungsphase haben wir Folgendes durchgef√ºhrt: <br><br><ul><li>  URLs und E-Mails, Datum und Uhrzeit, Spitznamen, Prozents√§tze, W√§hrungen und Zahlen wurden durch entsprechende Tags ersetzt. </li><li>  Wiederholte, zensierte, verl√§ngerte Gro√übuchstaben werden von entsprechenden Etiketten begleitet. </li><li>  L√§ngliche W√∂rter wurden automatisch korrigiert. </li></ul><br>  Dar√ºber hinaus enth√§lt Emphasis einen Tokenizer, mit dem die meisten Emojis, Emoticons und komplexen Ausdr√ºcke sowie Datums-, Uhrzeit-, W√§hrungs- und Akronyme identifiziert werden k√∂nnen. <br><br>  <i>Tabelle 3. Beispiele f√ºr die Textvorverarbeitung.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Quelltext </th><th>  Vorverarbeiteter Text </th></tr><tr><td>  Ich f√ºhle dich ... Ich zerbreche in Millionen St√ºcke <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; Ich f√ºhle dich &lt;/ allcaps&gt;.  &lt;wiederholt&gt; Ich zerbreche in Millionen St√ºcke <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  m√ºde und ich habe dich auch vermisst :-( </td><td>  m√ºde und ich habe dich auch vermisst &lt;sad&gt; </td></tr><tr><td>  Du solltest dir das anh√∂ren: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  Sie sollten &lt;elongated&gt; Folgendes anh√∂ren: &lt;url&gt; </td></tr><tr><td>  Meine Wohnung k√ºmmert sich darum.  Meine Miete liegt bei 650 Dollar. </td><td>  Meine Wohnung k√ºmmert sich darum.  Meine Miete liegt bei &lt;Geld&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^„Éª^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëc'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‚Äë':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‚Äë["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Vektordarstellung von W√∂rtern </h2><br>  Die Vektordarstellung ist ein wesentlicher Bestandteil der meisten Ans√§tze zur Erstellung von NLP-Systemen mithilfe von Deep Learning geworden.  Um die am besten geeigneten Vektorkartierungsmodelle zu bestimmen, haben wir Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pennington et al., 2014</a> ) und FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Joulin et al., 2017</a> ) sowie vorab trainierte DataStories-Vektoren ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Baziotis et al.) Versucht. ., 2017</a> ).  Word2Vec findet Beziehungen zwischen W√∂rtern, indem angenommen wird, dass semantisch verwandte W√∂rter in √§hnlichen Kontexten gefunden werden.  Word2Vec versucht, das Zielwort (CBOW-Architektur) oder den Kontext (Skip-Gram-Architektur) vorherzusagen, dh die Verlustfunktion zu minimieren, und GloVe berechnet Wortvektoren, wodurch die Dimension der Adjazenzmatrix verringert wird.  Die Logik von FastText √§hnelt der Logik von Word2Vec, verwendet jedoch symbolische n-Gramm, um Wortvektoren zu erstellen, und kann daher das Problem unbekannter W√∂rter l√∂sen. <br><br>  F√ºr alle genannten Modelle verwenden wir die von den Autoren angegebenen Standard-Trainingsparameter.  Wir haben ein einfaches LSTM-Modell (dim = 64) basierend auf jeder dieser Vektordarstellungen trainiert und die Klassifizierungseffizienz mithilfe einer Kreuzvalidierung verglichen.  Das beste Ergebnis bei F1-Messungen wurde durch vorab trainierte DataStories-Vektoren gezeigt. <br><br>  Um die ausgew√§hlte Vektorkartierung mit der emotionalen F√§rbung von W√∂rtern anzureichern, haben wir beschlossen, die Vektoren mithilfe des automatisch beschrifteten Distant- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datensatzes zu optimieren</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deriu et al., 2017</a> ).  Wir haben den Distant-Datensatz verwendet, um ein einfaches LSTM-Netzwerk zu trainieren, um "b√∂se", "traurige" und "gl√ºckliche" Nachrichten zu klassifizieren.  Die Einbettungsschicht wurde w√§hrend der ersten Iteration des Trainings eingefroren, um starke √Ñnderungen in den Gewichten der Vektoren zu vermeiden, und f√ºr die n√§chsten f√ºnf Iterationen wurde die Schicht aufgetaut.  Nach dem Training wurden die "verz√∂gerten" Vektoren f√ºr die sp√§tere Verwendung im neuronalen Netzwerk gespeichert <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">und gemeinsam genutzt</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Neuronale Netzwerkarchitektur </h2><br>  Recurrent Neural Networks (RNNs) sind eine Familie neuronaler Netze, die sich auf die Verarbeitung einer Reihe von Ereignissen spezialisiert haben.  Im Gegensatz zu herk√∂mmlichen neuronalen Netzen sind RNNs so konzipiert, dass sie mit Sequenzen unter Verwendung interner Salden arbeiten.  Zu diesem Zweck enth√§lt der Berechnungsgraph RNN Zyklen, die den Einfluss vorheriger Informationen aus der Abfolge von Ereignissen auf die aktuelle widerspiegeln.  LSTM-Neuronale Netze (Long Short-Term Memory) wurden 1997 als Erweiterung von RNN eingef√ºhrt ( <a href="">Hochreiter und Schmidhuber, 1997</a> ).  LSTM-Wiederholungszellen sind verbunden, um Burst- und Fade-Probleme zu vermeiden.  Herk√∂mmliche LSTMs behalten nur fr√ºhere Informationen bei, wenn sie die Sequenz in eine Richtung verarbeiten.  Bidirektionale LSTMs, die in beide Richtungen arbeiten, kombinieren die Ausgabe von zwei verborgenen LSTM-Schichten, die Informationen in entgegengesetzte Richtungen √ºbertragen - eine im Laufe der Zeit und die andere dagegen - und gleichzeitig Daten aus vergangenen und zuk√ºnftigen Zust√§nden empfangen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schuster und Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Abbildung 1: Reduzierte Version der Architektur.</i>  <i>Das LSTM-Modul verwendet f√ºr die erste und dritte Stufe die gleichen Gewichte.</i> <br><br>  Eine vereinfachte Darstellung des beschriebenen Ansatzes ist in Abbildung 1 dargestellt. Die Architektur des neuronalen Netzwerks besteht aus einer Einbettungsschicht und zwei bidirektionalen LTSM-Modulen (dim = 64).  Das erste LTSM-Modul analysiert die W√∂rter des ersten Benutzers (d. H. Die erste und dritte Replik der Konversation), und das zweite Modul analysiert die W√∂rter des zweiten Benutzers (zweite Replik).  In der ersten Stufe werden die W√∂rter jedes Benutzers, die vorab trainierte Vektordarstellungen verwenden, in das entsprechende bidirektionale LTSM-Modul eingespeist.  Dann werden die resultierenden drei Merkmalskarten zu einem flachen Merkmalsvektor kombiniert und dann auf eine vollst√§ndig verbundene verborgene Schicht (dim = 30) √ºbertragen, die die Wechselwirkungen zwischen den extrahierten Merkmalen analysiert.  Schlie√ülich werden diese Eigenschaften in der Ausgabeschicht unter Verwendung der Softmax-Aktivierungsfunktion verarbeitet, um die endg√ºltige Klassenbezeichnung zu bestimmen.  Um die √úberanpassung zu verringern, wurden nach Schichten der Vektordarstellung Regularisierungsschichten mit Gau√üschem Rauschen hinzugef√ºgt, und jedem LTSM-Modul (p = 0,2) und einer verborgenen vollst√§ndig verbundenen Schicht (p = 0,1) wurden Dropout-Schichten hinzugef√ºgt ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Srivastava et al., 2014)</a> ) <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Ergebnisse </h2><br>  Auf der Suche nach der optimalen Architektur haben wir nicht nur mit der Anzahl der Neuronen in den Schichten, Aktivierungsfunktionen und Regularisierungsparametern experimentiert, sondern auch mit der Architektur des neuronalen Netzwerks selbst.  Dies wird in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Originalarbeit</a> ausf√ºhrlicher beschrieben. <br><br>  Die im vorherigen Abschnitt beschriebene Architektur zeigte die besten Ergebnisse beim Training des Train-Datensatzes und der Validierung des Dev-Datensatzes, sodass sie in der letzten Phase des Wettbewerbs verwendet wurde.  Beim letzten Testdatensatz zeigte das Modell ein mikro-gemitteltes F1-Ma√ü von 72,59%, und das maximal erzielte Ergebnis unter allen Teilnehmern betrug 79,59%.  Trotzdem war unser Ergebnis viel h√∂her als der von den Organisatoren festgelegte Basiswert von 58,68%. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Quellcode f√ºr die Modell- und Vektordarstellung von W√∂rtern</a> ist auf GitHub verf√ºgbar. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Vollversion des Artikels</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit mit der Aufgabenbeschreibung</a> finden Sie auf der ACL Anthology-Website. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Trainingsdatensatz</a> kann von der offiziellen LinkedIn-Gruppe heruntergeladen werden. <br><br>  Zitat: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de463045/">https://habr.com/ru/post/de463045/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de463031/index.html">Lebe und lerne. Teil 3. Weiterbildung oder das Alter des ewigen Sch√ºlers</a></li>
<li><a href="../de463035/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 471 (23.07.2019 - 29.07.2019)</a></li>
<li><a href="../de463037/index.html">Auf der Suche nach Inspiration oder wie man sich aus F herausholt</a></li>
<li><a href="../de463039/index.html">Manik√ºre-Staubsauger zum Selbermachen</a></li>
<li><a href="../de463041/index.html">Definiert oder undefiniert? Nuancen beim Erstellen von Arrays in JavaScript</a></li>
<li><a href="../de463055/index.html">√úber Administratoren, Entwickler, endlose Verwirrung und DevOps-Transformation innerhalb des Unternehmens</a></li>
<li><a href="../de463057/index.html">Benutzerdefinierte Rechte f√ºr Yii Framework 2</a></li>
<li><a href="../de463059/index.html">Drei leben in der IT und nicht nur</a></li>
<li><a href="../de463061/index.html">Regeln f√ºr die Erstellung von Layouts in Figma</a></li>
<li><a href="../de463063/index.html">Wir besch√§ftigen uns mit Schnittstellen in Go</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
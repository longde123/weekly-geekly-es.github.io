<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÖüèº üå† üë©üèø‚Äçü§ù‚Äçüë®üèª Bicicleta pr√≥pria para sincronizar MariaDB e Sphinx ‚ú® üì† üîÇ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Em 28 de fevereiro, fiz uma apresenta√ß√£o no SphinxSearch-meetup , realizado em nosso escrit√≥rio. Ele falou sobre como viemos da reconstru√ß√£o regular d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bicicleta pr√≥pria para sincronizar MariaDB e Sphinx</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/superjob/blog/447526/"><p><img src="https://habrastorage.org/webt/t0/1g/vk/t01gvkcn0zx47xuioqcvfz5bqoc.png"></p><br><p>  Em 28 de fevereiro, fiz uma apresenta√ß√£o no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SphinxSearch-meetup</a> , realizado em nosso escrit√≥rio.  Ele falou sobre como viemos da reconstru√ß√£o regular de √≠ndices para pesquisa de texto completo e do envio de atualiza√ß√µes no c√≥digo "no local" para √≠ndices de tempo de trilho e sincroniza√ß√£o autom√°tica do estado do √≠ndice e do banco de dados MariaDB.  Uma grava√ß√£o de v√≠deo do meu relat√≥rio est√° dispon√≠vel no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">link</a> e, para quem prefere ler a assistir ao v√≠deo, escrevi este artigo. </p><a name="habracut"></a><br><p>  Come√ßarei com a organiza√ß√£o de nossa pesquisa e por que come√ßamos tudo isso. </p><br><p>  Nossa busca foi organizada de acordo com um esquema completamente padr√£o. </p><br><p>  Do front end, as solicita√ß√µes do usu√°rio chegam ao servidor de aplicativos escrito em PHP e ele, por sua vez, se comunica com o banco de dados (temos o MariaDB).  Se precisarmos fazer uma pesquisa, o servidor de aplicativos se volta para o balanceador (temos haproxy), que o conecta a um dos servidores em que o searchd est√° em execu√ß√£o, e esse servidor j√° realiza uma pesquisa e retorna o resultado. </p><br><p>  Os dados do banco de dados entram no √≠ndice de uma maneira bastante tradicional: de acordo com a programa√ß√£o, reconstru√≠mos o √≠ndice a cada poucos minutos com os documentos atualizados recentemente, e reconstru√≠mos o √≠ndice com os chamados documentos "arquivados" (ou seja, aqueles com os quais Durante muito tempo, nada aconteceu).  Existem algumas m√°quinas alocadas para indexa√ß√£o, um script √© executado em uma programa√ß√£o, que primeiro cria o √≠ndice, renomeia os arquivos de √≠ndice de uma maneira especial e, em seguida, coloca-os em uma pasta separada.  E em cada um dos servidores com searchd, o rsync √© iniciado uma vez por minuto, que copia arquivos dessa pasta para a pasta searchd indexes e, se algo tiver sido copiado, ele executa a solicita√ß√£o RELOAD INDEX. </p><br><p>  No entanto, para algumas altera√ß√µes nos curr√≠culos e nas vagas, era necess√°rio que eles "alcan√ßassem" o √≠ndice o mais r√°pido poss√≠vel.  Por exemplo, se uma vaga publicada em dom√≠nio p√∫blico for removida da publica√ß√£o, √© razo√°vel esperar, do ponto de vista do usu√°rio, que ela desapare√ßa do problema em alguns segundos, n√£o mais.  Portanto, esses tipos de altera√ß√µes s√£o enviadas diretamente via searchd usando consultas UPDATE.  E, para que essas altera√ß√µes sejam aplicadas a todas as c√≥pias de √≠ndices em todos os nossos servidores, um √≠ndice distribu√≠do √© configurado em cada pesquisa, que envia atualiza√ß√µes de atributos para todas as inst√¢ncias da pesquisa.  O servidor de aplicativos ainda se conecta ao balanceador e envia uma solicita√ß√£o para atualizar o √≠ndice distribu√≠do;  portanto, ele n√£o precisa conhecer antecipadamente a lista de servidores com searchd, nem chegar√° exatamente a qual servidor com searchd. </p><br><p>  Tudo isso funcionou muito bem, mas houve problemas. </p><br><ol><li>  O atraso m√©dio entre a cria√ß√£o do documento (temos este curr√≠culo ou vaga) e sua entrada no √≠ndice foi diretamente proporcional ao seu n√∫mero em nosso banco de dados. </li><li> Como usamos o √≠ndice distribu√≠do para distribuir atualiza√ß√µes de atributos, n√£o t√≠nhamos garantia de que essas atualiza√ß√µes fossem aplicadas a todas as c√≥pias do √≠ndice. </li><li> As altera√ß√µes "urgentes" que ocorreram durante a reconstru√ß√£o do √≠ndice foram perdidas quando o comando <code>RELOAD INDEX</code> foi executado (simplesmente porque ainda n√£o estavam no √≠ndice rec√©m-constru√≠do) e s√≥ entraram no √≠ndice ap√≥s a pr√≥xima reindexa√ß√£o. <img src="https://habrastorage.org/webt/rz/t6/v3/rzt6v3lfrnyayc3-texs56vlh48.png"></li><li>  Os scripts para atualiza√ß√£o de √≠ndices nos servidores com searchd foram executados independentemente um do outro, n√£o houve sincroniza√ß√£o entre eles.  Por esse motivo, o atraso entre a atualiza√ß√£o do √≠ndice em diferentes servidores pode chegar a v√°rios minutos. </li><li>  Se fosse necess√°rio testar algo relacionado √† pesquisa, era necess√°rio recriar o √≠ndice ap√≥s cada altera√ß√£o. </li></ol><br><p>  Cada um desses problemas separadamente n√£o valia a pena retrabalhar a infra-estrutura de busca, mas, juntos, eles estragavam a vida de maneira bastante tang√≠vel. </p><br><p>  Decidimos lidar com os problemas acima usando os √≠ndices em tempo real do Sphinx.  Al√©m disso, a transi√ß√£o para os √≠ndices de RT n√£o foi suficiente para n√≥s.  Para finalmente se livrar de qualquer corrida de dados, era necess√°rio garantir que todas as atualiza√ß√µes do aplicativo no √≠ndice passassem pelo mesmo canal.  Al√©m disso, era necess√°rio salvar em algum lugar as altera√ß√µes feitas no banco de dados enquanto o √≠ndice estava sendo reconstru√≠do (porque, afinal, √†s vezes √© necess√°rio reconstru√≠-lo, mas o procedimento n√£o √© instant√¢neo). </p><br><p>  Decidimos fazer a conex√£o usando o protocolo de replica√ß√£o do MySQL como um canal de transfer√™ncia de dados, e o binlog do MySQL √© o local para salvar as altera√ß√µes durante a reconstru√ß√£o do √≠ndice.  Essa solu√ß√£o nos permitiu livrar da escrita no Sphinx a partir do c√≥digo do aplicativo.  E como j√° t√≠nhamos usado a replica√ß√£o baseada em linha com um ID de transa√ß√£o global naquele momento, a altern√¢ncia entre r√©plicas de banco de dados poderia ser feita de maneira bastante simples. </p><br><p>  A ideia de conectar-se diretamente ao banco de dados para obter altera√ß√µes de l√° para enviar para o √≠ndice, √© claro, n√£o √© nova: em 2016, colegas da Avito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fizeram uma apresenta√ß√£o</a> onde descreveram detalhadamente como resolveram o problema de sincronizar dados no Sphinx com o banco de dados principal.  Decidimos usar a experi√™ncia deles e criar um sistema semelhante para n√≥s mesmos, com a diferen√ßa de que n√£o possu√≠mos o PostgreSQL, mas o MariaDB e o antigo ramo do Sphinx (vers√£o 2.3.2). </p><br><p>  Fizemos um servi√ßo que assina as altera√ß√µes no MariaDB e atualiza o √≠ndice no Sphinx.  Suas responsabilidades s√£o as seguintes: </p><br><ul><li>  conex√£o com o servidor MariaDB via protocolo de replica√ß√£o e recebimento de eventos do binlog; </li><li>  rastreando a posi√ß√£o atual do binlog e o n√∫mero da √∫ltima transa√ß√£o conclu√≠da; </li><li>  filtrando eventos de binlog; </li><li>  descobrir quais documentos precisam ser adicionados, exclu√≠dos ou atualizados no √≠ndice e para documentos atualizados - quais campos precisam ser atualizados; </li><li>  solicita√ß√£o de dados ausentes do MariaDB; </li><li>  gera√ß√£o e execu√ß√£o de solicita√ß√µes de atualiza√ß√£o de √≠ndice; </li><li>  reconstruindo o √≠ndice, se necess√°rio. </li></ul><br><p>  Fizemos uma conex√£o usando o protocolo de replica√ß√£o usando a biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">go-mysql</a> .  Ela √© respons√°vel por estabelecer uma conex√£o com o MariaDB, ler eventos de replica√ß√£o e pass√°-los para um manipulador.  Esse manipulador come√ßa na goroutine, que √© controlada pela biblioteca, mas n√≥s mesmos escrevemos o c√≥digo do manipulador.  No c√≥digo do manipulador, os eventos s√£o verificados com uma lista de tabelas que nos interessam e as altera√ß√µes nessas tabelas s√£o enviadas para processamento.  Nosso manipulador tamb√©m armazena o status da transa√ß√£o.  Isso ocorre porque os eventos no protocolo de replica√ß√£o est√£o em ordem: GTID (in√≠cio da transa√ß√£o) -&gt; ROW (altera√ß√£o de dados) -&gt; XID (fim da transa√ß√£o), e apenas o primeiro deles cont√©m informa√ß√µes sobre o n√∫mero da transa√ß√£o.  √â mais conveniente transferir o n√∫mero da transa√ß√£o juntamente com sua conclus√£o, a fim de salvar informa√ß√µes sobre em que posi√ß√£o no binlog as altera√ß√µes foram aplicadas e, para isso, precisamos lembrar o n√∫mero da transa√ß√£o atual entre o in√≠cio e a conclus√£o. </p><br><pre> <code class="plaintext hljs">MySQL [(none)]&gt; describe sync_state; +-----------------+--------+ | Field | Type | +-----------------+--------+ | id | bigint | | dummy_field | field | | binlog_position | uint | | binlog_name | string | | gtid | string | | flavor | string | +-----------------+--------+</code> </pre> <br><p>  N√≥s salvamos o n√∫mero da √∫ltima transa√ß√£o conclu√≠da em um √≠ndice especial de um documento em cada servidor com searchd.  No in√≠cio do servi√ßo, verificamos que os √≠ndices foram inicializados e possuem a estrutura esperada, al√©m de que a posi√ß√£o salva em todos os servidores esteja presente e a mesma em todos os servidores.  Ent√£o, se essas verifica√ß√µes foram bem-sucedidas e conseguimos iniciar a leitura do binlog a partir da posi√ß√£o salva, iniciamos o procedimento de sincroniza√ß√£o.  Se as verifica√ß√µes falharem ou n√£o foi poss√≠vel come√ßar a ler o binlog da posi√ß√£o salva, redefinimos a posi√ß√£o salva para a posi√ß√£o atual do servidor MariaDB e reconstru√≠mos o √≠ndice. </p><br><p>  O processamento de eventos de replica√ß√£o come√ßa determinando quais documentos s√£o afetados por uma altera√ß√£o espec√≠fica no banco de dados.  Para fazer isso, na configura√ß√£o do nosso servi√ßo, fizemos algo como rotear para eventos de altera√ß√£o de linha nas tabelas de nosso interesse, ou seja, um conjunto de regras para determinar como as altera√ß√µes no banco de dados devem ser indexadas. </p><br><pre> <code class="plaintext hljs">[[ingest]] table = "vacancy" id_field = "id" index = "vacancy" [ingest.column_map] user_id = ["user_id"] edited_at = ["date_edited"] profession = ["profession"] latitude = ["latitude_deg", "latitude_rad"] longitude = ["longitude_deg", "longitude_rad"] [[ingest]] table = "vacancy_language" id_field = "vacancy_id" index = "vacancy" [ingest.column_map] language_id = ["languages"] level = ["languages"] [[ingest]] table = "vacancy_metro_station" id_field = "vacancy_id" index = "vacancy" [ingest.column_map] metro_station_id = ["metro"]</code> </pre> <br><p>  Por exemplo, com este conjunto de regras, as altera√ß√µes <code>vacancy_metro_station</code> <code>vacancy</code> , <code>vacancy_language</code> e <code>vacancy_metro_station</code> devem estar no √≠ndice de <code>vacancy</code> .  O n√∫mero do documento pode ser obtido no campo de <code>id</code> da tabela de <code>vacancy</code> e no campo <code>vacancy_id</code> das outras duas tabelas.  O campo <code>column_map</code> √© uma tabela da depend√™ncia dos campos de √≠ndice nos campos de diferentes tabelas de banco de dados. </p><br><p>  Al√©m disso, quando recebemos a lista de documentos afetados pelas altera√ß√µes, precisamos atualiz√°-los no √≠ndice, mas n√£o o fazemos imediatamente.  Primeiro, acumulamos altera√ß√µes para cada documento e enviamos as altera√ß√µes para o √≠ndice assim que um curto per√≠odo de tempo (temos 100 milissegundos) desde a √∫ltima altera√ß√£o deste documento. </p><br><p>  Decidimos fazer isso para evitar muitas atualiza√ß√µes desnecess√°rias de √≠ndice, porque em muitos casos ocorre uma √∫nica altera√ß√£o l√≥gica em um documento com a ajuda de v√°rias consultas SQL que afetam tabelas diferentes e, √†s vezes, s√£o executadas em transa√ß√µes completamente diferentes. </p><br><p>  Vou dar um exemplo simples.  Suponha que um usu√°rio tenha editado uma vaga.  O c√≥digo respons√°vel por salvar as altera√ß√µes geralmente √© escrito para simplificar aproximadamente desta maneira: </p><br><pre> <code class="plaintext hljs">BEGIN; UPDATE vacancy SET edited_at = NOW() WHERE id = 123; DELETE FROM vacancy_language WHERE vacancy_id = 123; INSERT INTO vacancy_language (vacancy_id, language_id, level) VALUES (123, 1, "fluent"), (123, 2, "technical"); DELETE FROM vacancy_metro_station WHERE vacancy_id = 123; INSERT INTO vacancy_metro_station (vacancy_id, metro_station_id) VALUES (123, 55); ... COMMIT;</code> </pre> <br><p>  Em outras palavras, primeiro todos os registros antigos s√£o exclu√≠dos das tabelas vinculadas e, em seguida, novos s√£o inseridos.  Ao mesmo tempo, ainda haver√° entradas no binlog sobre essas exclus√µes e inser√ß√µes, mesmo que nada tenha sido alterado no documento. </p><br><p>  Para atualizar apenas o necess√°rio, fizemos o seguinte: classifique as linhas alteradas para que, para cada par de documentos de √≠ndice, todas as altera√ß√µes possam ser recuperadas em ordem cronol√≥gica.  Em seguida, podemos aplic√°-los, por sua vez, para determinar quais campos em que tabelas foram alteradas e quais n√£o s√£o. Depois disso, podemos usar a tabela <code>column_map</code> obter uma lista de campos e atributos de √≠ndice que precisam ser atualizados para cada documento afetado.  Al√©m disso, os eventos relacionados a um documento podem n√£o chegar um ap√≥s o outro, mas como se fossem ‚Äúdiferentes‚Äù se forem executados em transa√ß√µes diferentes.  Mas, em nossa capacidade de determinar quais documentos foram alterados, isso n√£o afetar√°. </p><br><p>  Ao mesmo tempo, essa abordagem nos permitiu atualizar apenas os atributos do √≠ndice, se n√£o houvesse altera√ß√µes nos campos de texto, al√©m de combinar o envio de altera√ß√µes ao Sphinx. </p><br><p>  Portanto, agora podemos descobrir quais documentos precisam ser atualizados no √≠ndice. </p><br><p>  Em muitos casos, os dados do binlog n√£o s√£o suficientes para criar uma solicita√ß√£o para atualizar o √≠ndice; portanto, obtemos os dados ausentes no mesmo servidor onde lemos o binlog.  Para isso, existe um modelo de solicita√ß√£o para recebimento de dados na configura√ß√£o do nosso servi√ßo. </p><br><pre> <code class="plaintext hljs">[data_source.vacancy] #               #   -      id     parts = 4 query = """ SELECT vacancy.id AS `:id`, vacancy.profession AS `profession_text:field`, GROUP_CONCAT(DISTINCT vacancy_language.language_id) AS `languages:attr_multi`, GROUP_CONCAT(DISTINCT vacancy_metro_station.metro_station_id) AS `metro:attr_multi` FROM vacancy LEFT JOIN vacancy_language ON vacancy_language.vacancy_id = vacancy.id LEFT JOIN vacancy_metro_station ON vacancy_metro_station.vacancy_id = vacancy.id GROUP BY vacancy.id """</code> </pre> <br><p>  Neste modelo, todos os campos s√£o marcados com aliases especiais: <code>[___]:___</code> . <br>  √â usado na forma√ß√£o de uma solicita√ß√£o para receber os dados ausentes e na constru√ß√£o do √≠ndice (mais sobre isso posteriormente). </p><br><p>  N√≥s formamos uma solicita√ß√£o deste tipo: </p><br><pre> <code class="plaintext hljs">SELECT vacancy.id AS `id`, vacancy.profession AS `profession_text`, GROUP_CONCAT(DISTINCT vacancy_language.language_id) AS `languages`, GROUP_CONCAT(DISTINCT vacancy_metro_station.metro_station_id) AS `metro` FROM vacancy LEFT JOIN vacancy_language ON vacancy_language.vacancy_id = vacancy.id LEFT JOIN vacancy_metro_station ON vacancy_metro_station.vacancy_id = vacancy.id WHERE vacancy.id IN (&lt; id ,   &gt;) GROUP BY vacancy.id</code> </pre> <br><p>  Em seguida, para cada documento, verificamos se √© o resultado dessa solicita√ß√£o.  Caso contr√°rio, significa que foi exclu√≠do da tabela principal e, portanto, tamb√©m pode ser exclu√≠do do √≠ndice (executamos a consulta <code>DELETE</code> para este documento).  Se for, verifique se precisamos atualizar os campos de texto para este documento.  Se os campos de texto n√£o precisarem ser atualizados, faremos uma consulta <code>UPDATE</code> para este documento, caso contr√°rio, <code>REPLACE</code> . </p><br><p>  Vale a pena observar aqui que a l√≥gica de manter a posi√ß√£o a partir da qual voc√™ pode come√ßar a ler o binlog em caso de falhas tinha que ser complicada, porque agora √© poss√≠vel uma situa√ß√£o em que n√£o aplicamos todas as altera√ß√µes lidas no binlog. </p><br><p>  Para retomar a leitura do binlog funcionando corretamente, fizemos o seguinte: para cada evento de altera√ß√£o de linha no banco de dados, lembre-se do ID da √∫ltima transa√ß√£o conclu√≠da no momento em que esse evento ocorreu.  Depois de enviar as altera√ß√µes para o Sphinx, atualizamos o n√∫mero da transa√ß√£o a partir do qual voc√™ pode come√ßar a ler com seguran√ßa, como a seguir.  Se n√£o processamos todas as altera√ß√µes acumuladas (porque alguns documentos n√£o foram "rastreados" na fila), obteremos o n√∫mero da transa√ß√£o mais antiga das relacionadas √†s altera√ß√µes que ainda n√£o conseguimos aplicar.  E se aplicamos todas as altera√ß√µes acumuladas, pegamos o n√∫mero da √∫ltima transa√ß√£o conclu√≠da. </p><br><p>  O que aconteceu como resultado foi bom para n√≥s, mas havia um ponto mais importante: para que o desempenho do √≠ndice em tempo real permanecesse em um n√≠vel aceit√°vel ao longo do tempo, era necess√°rio que o tamanho e o n√∫mero de "peda√ßos" desse √≠ndice permanecessem pequenos.  Para fazer isso, o Sphinx possui uma solicita√ß√£o <code>FLUSH RAMCHUNK</code> , que <code>FLUSH RAMCHUNK</code> um novo bloco de disco, e uma solicita√ß√£o <code>OPTIMIZE INDEX</code> , que mescla todos os blocos de disco em um.  Inicialmente, pens√°vamos que o executar√≠amos periodicamente e isso √© tudo.  Infelizmente, por√©m, verificou-se que na vers√£o 2.3.2 <code>OPTIMIZE INDEX</code> n√£o funciona (ou seja, com uma probabilidade bastante alta leva a uma queda na pesquisad).  Portanto, decidimos apenas uma vez por dia recriar completamente o √≠ndice, especialmente porque de tempos em tempos ainda precisamos faz√™-lo (por exemplo, se o esquema do √≠ndice ou as configura√ß√µes do tokenizer mudarem). </p><br><p>  O procedimento para reconstruir o √≠ndice ocorre em v√°rias etapas. </p><br><ol><li><p>  Geramos uma configura√ß√£o para indexador </p><br><p>  Como mencionado acima, h√° um modelo de consulta SQL na configura√ß√£o do servi√ßo.  Tamb√©m √© usado para formar a configura√ß√£o do indexador. <br>  Tamb√©m na configura√ß√£o, existem outras configura√ß√µes necess√°rias para criar o √≠ndice (configura√ß√µes do tokenizer, dicion√°rios, v√°rias restri√ß√µes ao consumo de recursos). </p><br></li><li><p>  Salve a posi√ß√£o atual do MariaDB </p><br><p>  A partir dessa posi√ß√£o, come√ßaremos a ler o binlog, depois que o novo √≠ndice estiver dispon√≠vel em todos os servidores com searchd. </p><br></li><li><p>  Come√ßamos o indexador </p><br><p>  <code>indexer --config tmp.vacancy.indexer.0.conf --all</code> comandos do <code>indexer --config tmp.vacancy.indexer.0.conf --all</code> formul√°rios <code>indexer --config tmp.vacancy.indexer.0.conf --all</code> e aguardamos sua conclus√£o.  Al√©m disso, se o √≠ndice for dividido em partes, iniciaremos a constru√ß√£o de todas as partes em paralelo. </p><br></li><li><p>  Carregamos arquivos de √≠ndice em servidores </p><br><p>  O download para cada servidor tamb√©m ocorre em paralelo, mas naturalmente esperamos at√© que todos os arquivos sejam carregados em todos os servidores.  Para baixar arquivos na configura√ß√£o do servi√ßo, h√° uma se√ß√£o com um modelo de comando para baixar arquivos. </p><br><pre> <code class="plaintext hljs">[index_uploader] executable = "rsync" arguments = [ "--files-from=-", "--log-file=&lt;&lt;.DataDir&gt;&gt;/rsync.&lt;&lt;.Host&gt;&gt;.log", "--no-relative", "--times", "--delay-updates", ".", "rsync://&lt;&lt;.Host&gt;&gt;/index/vacancy/", ]</code> </pre> <br><p>  Para cada servidor, simplesmente substitu√≠mos seu nome na vari√°vel Host e executamos o comando resultante.  Usamos o rsync para download, mas, em princ√≠pio, qualquer programa ou script que aceite uma lista de arquivos no stdin e fa√ßa o download desses arquivos para a pasta em que o searchd espera ver os arquivos de √≠ndice o far√°. </p><br></li><li><p>  Paramos a sincroniza√ß√£o </p><br><p>  Paramos de ler o binlog, paramos a goroutine respons√°vel pelo ac√∫mulo de altera√ß√µes. </p><br></li><li><p>  Substitua o √≠ndice antigo por um novo </p><br><p>  Para cada servidor com searchd, fazemos consultas seq√ºenciais <code>RELOAD INDEX vacancy_plain</code> , <code>TRUNCATE INDEX vacancy_plain</code> , <code>ATTACH INDEX vacancy_plain TO vacancy</code> .  Se o √≠ndice for dividido em partes, executamos essas consultas para cada parte sequencialmente.  Ao mesmo tempo, se estivermos em um ambiente de produ√ß√£o, antes de executar essas consultas em qualquer servidor, removeremos a carga dele atrav√©s do balanceador (para que ningu√©m fa√ßa consultas SELECT aos √≠ndices entre <code>TRUNCATE</code> e <code>ATTACH</code> ), e assim que Quando a √∫ltima solicita√ß√£o <code>ATTACH</code> for conclu√≠da, retornamos a carga para este servidor. </p><br></li><li><p>  Reiniciando a sincroniza√ß√£o a partir de uma posi√ß√£o salva </p><br><p>  Assim que substitu√≠mos todos os √≠ndices em tempo real pelos rec√©m-constru√≠dos, retomamos a leitura do binlog e sincronizamos eventos do binlog, come√ßando pela posi√ß√£o que salvamos antes do in√≠cio da indexa√ß√£o. </p><br></li></ol><br><p>  Aqui est√° um exemplo de um gr√°fico do atraso do √≠ndice do servidor MariaDB. </p><br><p><img src="https://habrastorage.org/webt/xs/pq/56/xspq56osyygn1fxx6h5x_oczgpy.png" alt="Lista de pend√™ncias ap√≥s reindexa√ß√£o"></p><br><p>  Aqui voc√™ pode ver que, embora o estado do √≠ndice ap√≥s a reconstru√ß√£o volte no tempo, isso acontece muito brevemente. </p><br><p>  Agora que tudo est√° mais ou menos pronto, √© hora de lan√ßar.  Fizemos isso gradualmente.  Primeiro, lan√ßamos um √≠ndice em tempo real em alguns servidores e o restante na √©poca funcionou da mesma maneira.  Ao mesmo tempo, a estrutura dos √≠ndices nos servidores "novos" n√£o diferia dos antigos, portanto, nosso aplicativo PHP ainda podia se conectar ao balanceador sem se preocupar se a solicita√ß√£o seria processada em um √≠ndice em tempo real ou em um √≠ndice simples. </p><br><p><img src="https://habrastorage.org/webt/sy/xz/lx/syxzlx_tfmg0-mze5vr1ngt3_tg.png" alt="Esquema de distribui√ß√£o de atualiza√ß√£o de transi√ß√£o"></p><br><p>  As atualiza√ß√µes de atributos, sobre as quais falei anteriormente, tamb√©m foram enviadas de acordo com o esquema antigo, com a diferen√ßa de que o √≠ndice distribu√≠do em todos os servidores estava configurado para enviar consultas UPDATE apenas para servidores com √≠ndices simples.  Al√©m disso, se a solicita√ß√£o UPDATE do aplicativo atingir o servidor com √≠ndices em tempo real, ela n√£o executar√° essa solicita√ß√£o em casa, mas a enviar√° para os servidores configurados da maneira antiga. </p><br><p>  Ap√≥s o lan√ßamento, como esper√°vamos, ele reduziu significativamente o atraso entre a forma como um resumo ou vaga √© alterada no banco de dados e como as altera√ß√µes correspondentes entram no √≠ndice. </p><br><p>  Depois de mudar para um √≠ndice em tempo real, n√£o havia necessidade de reconstruir o √≠ndice ap√≥s cada altera√ß√£o nos servidores de teste.  E, assim, tornou-se poss√≠vel escrever autotestes de ponta a ponta com a participa√ß√£o da pesquisa de forma relativamente barata.  No entanto, como processamos as altera√ß√µes do binlog de maneira ass√≠ncrona (do ponto de vista dos clientes que gravam no banco de dados), tivemos que esperar at√© que as altera√ß√µes relativas ao documento participante do autoteste fossem processadas pelo nosso servi√ßo e enviadas para a pesquisa. . </p><br><p>  Para fazer isso, criamos um terminal em nosso servi√ßo, o que faz exatamente isso, isto √©, aguarda at√© que todas as altera√ß√µes sejam aplicadas ao n√∫mero de transa√ß√£o especificado.  Para fazer isso, imediatamente ap√≥s fazer as altera√ß√µes necess√°rias no banco de dados, solicitamos a MariaDB <code>@@gtid_current_pos</code> e o transferimos para o terminal do nosso servi√ßo.  Se j√° aplicamos todas as transa√ß√µes a essa posi√ß√£o nesse momento, o servi√ßo responde imediatamente que podemos continuar.  Caso contr√°rio, na goroutine respons√°vel pela aplica√ß√£o das altera√ß√µes, criamos uma assinatura para este GTID e, assim que ele (ou qualquer um que esteja seguindo) √© aplicado, tamb√©m permitimos que o cliente continue o autoteste. </p><br><p>  No c√≥digo PHP, ele se parece com isso: </p><br><pre> <code class="plaintext hljs">&lt;?php declare(strict_types=1); use GuzzleHttp\ClientInterface; use GuzzleHttp\RequestOptions; use PDO; class RiverClient { private const REQUEST_METHOD = 'post'; /** * @var ClientInterface */ private $httpClient; public function __construct(ClientInterface $httpClient) { $this-&gt;httpClient = $httpClient; } public function waitForSync(PDO $mysqlConnection, PDO $sphinxConnection, string $riverAddr): void { $masterGTID = $mysqlConnection-&gt;query('SELECT @@gtid_current_pos')-&gt;fetchColumn(); $this-&gt;httpClient-&gt;request( self::REQUEST_METHOD, "http://{$riverAddr}/wait", [RequestOptions::FORM_PARAMS =&gt; ['gtid' =&gt; $masterGTID]] ); } }</code> </pre> <br><h2 id="rezultaty">  Resultados </h2><br><p>  Como resultado, conseguimos reduzir significativamente o atraso entre a atualiza√ß√£o do MariaDB e o Sphinx. </p><br><p><img src="https://habrastorage.org/webt/lc/rs/rl/lcrsrlzpcw8bzhuptg5s42p6wou.png" alt="Atraso de √≠ndice simples do banco de dados"></p><br><p><img src="https://habrastorage.org/webt/7h/ik/ic/7hikichzuaqyszagbenen-9drhk.png" alt="Rt-index lag do banco de dados"></p><br><p>  Tamb√©m ficamos muito mais confiantes de que todas as atualiza√ß√µes chegam a todos os nossos servidores Sphinx a tempo. </p><br><p>  Al√©m disso, o teste de pesquisa (manual e autom√°tico) tornou-se muito mais agrad√°vel. </p><br><p>  Infelizmente, isso n√£o nos foi dado de gra√ßa: o desempenho do √≠ndice em tempo real comparado ao √≠ndice simples acabou sendo um pouco pior. </p><br><p>  A distribui√ß√£o do tempo de processamento das consultas de pesquisa, dependendo do tempo para um √≠ndice simples, √© mostrada abaixo. </p><br><p><img src="https://habrastorage.org/webt/op/ro/gm/oprogmvvdykt244nlbmzeldufhu.png" alt="Linha de tempo de execu√ß√£o da consulta - simples"></p><br><p>  E aqui est√° o mesmo gr√°fico para o √≠ndice em tempo real. </p><br><p><img src="https://habrastorage.org/webt/07/ii/ce/07iicewkxbb0qvsrrob6dbwoa2i.png" alt="Linha do tempo de execu√ß√£o da consulta - em tempo real"></p><br><p>  Voc√™ pode ver que o compartilhamento de solicita√ß√µes "r√°pidas" diminuiu um pouco, enquanto o compartilhamento de solicita√ß√µes "lentas" aumentou. </p><br><h2 id="vmesto-zaklyucheniya">  Em vez de uma conclus√£o </h2><br><p>  Resta dizer que o c√≥digo do servi√ßo descrito neste artigo foi publicado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">em dom√≠nio p√∫blico</a> .  Infelizmente, ainda n√£o existe documenta√ß√£o detalhada, mas se desejar, voc√™ pode executar um exemplo de uso desse servi√ßo atrav√©s do <code>docker-compose</code> . </p><br><h2 id="ssylki">  Refer√™ncias </h2><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Slides de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">v√≠deo</a> e relat√≥rio </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Reportagem de v√≠deo de Andrey Smirnov e Vyacheslav Kryukov em Highload ++</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Biblioteca Go-mysql</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo de servi√ßo com exemplo de uso</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt447526/">https://habr.com/ru/post/pt447526/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt447512/index.html">E quem fez isso? Automatize a auditoria de seguran√ßa da informa√ß√£o</a></li>
<li><a href="../pt447514/index.html">7 startups interessantes na IoT</a></li>
<li><a href="../pt447516/index.html">Como fizemos o overclock do CAD COMPASS-3D ‚Üí Parte 2</a></li>
<li><a href="../pt447520/index.html">Recursos de classifica√ß√£o autom√°tica por n√≠veis no armazenamento Qsan XCubeSAN</a></li>
<li><a href="../pt447522/index.html">Que coisas √∫teis podem ser extra√≠das dos logs de uma esta√ß√£o de trabalho baseada no Windows</a></li>
<li><a href="../pt447528/index.html">Quem √© respons√°vel pela qualidade?</a></li>
<li><a href="../pt447530/index.html">OceanLotus: atualiza√ß√£o de Malvari para macOS</a></li>
<li><a href="../pt447532/index.html">Splunk Universal Forwarder no Docker como um coletor de logs do sistema</a></li>
<li><a href="../pt447534/index.html">O cosmonauta Aleksandr Laveykin sobre o melhor filme espacial, for√ßa G de 20g e pouso suave</a></li>
<li><a href="../pt447536/index.html">Implemente o IdM. Prepara√ß√£o para implementa√ß√£o pelo cliente</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
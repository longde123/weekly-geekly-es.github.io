<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔽 🦅 ♑️ 误差最小化的元集群，以及为什么我认为大脑以这种方式工作 ⛏️ 🌅 👩🏾‍🍳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="大家好！ 我想与您分享我对机器学习的看法。 

 机器学习的巨大进步令人印象深刻。 卷积网络和LSTM很酷。 但是，几乎所有现代技术都基于错误的反向传播。 基于这种方法，不可能构建思维机。 神经网络由诸如冻结的大脑之类的东西组成，它们经过一劳永逸地训练，无法改变思维。 

 我想，为什么不尝试创建像...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>误差最小化的元集群，以及为什么我认为大脑以这种方式工作</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427407/"> 大家好！ 我想与您分享我对机器学习的看法。 <br><br> 机器学习的巨大进步令人印象深刻。 卷积网络和LSTM很酷。 但是，几乎所有现代技术都基于错误的反向传播。 基于这种方法，不可能构建思维机。 神经网络由诸如冻结的大脑之类的东西组成，它们经过一劳永逸地训练，无法<strike>改变</strike>思维。 <br><br> 我想，为什么不尝试创建像活着的大脑一样的东西。 一种重新设计。 由于在所有动物中，尽管智力差异，大脑都由大约相同的神经元组成，所以一些基本原理应成为其工作的核心。 <br><a name="habracut"></a><br><h2> 我不了解神经元 </h2><br> 我在流行文学中没有找到明确答案的几个问题。 <br><br><ul><li> 显然，神经元以某种方式对神经递质作出反应，但究竟如何呢？ 神经递质越大，尖峰越频繁的简单假设显然并没有受到批评。 如果是这样，一个神经元的触发将触发多个邻居的触发，而另一个神经元的触发将在短时间内触发整个雪崩。 但这实际上并没有发生，同时只有一小部分神经元在大脑中起作用。 怎么了 </li><li> 神经元显然是记忆单位，但是它们如何存储信息？ 神经元的中央部分没有什么特别的：线粒体的核等。  Axon无法影响峰值，因为信息仅从核心向一个方向传播。 因此，唯一剩下的就是树突。 但是信息如何存储在其中？ 是模拟形式还是数字形式？ </li><li> 显然，神经元正在以某种方式学习。 但是到底如何呢？ 假设树突生长在尖峰之前存在大量神经递质的地方。 但是，如果是这样，则触发的神经元将增长一点，并且下次出现神经递质时，它将是邻居中最厚的，它将吸收大部分神经递质并再次起作用。 再一次长大。 一直到无限，直到他扼杀了所有邻居？ 这有什么问题吗？ </li><li> 如果一个神经元生长，那么相邻的神经元就会减少，头部不是橡胶。 某些东西会使神经元变干。 什么啊 </li></ul><br><h2> 只是聚类 </h2><br> 在我看来，所有这些问题的合理答案似乎是大脑的工作就像许多简单的簇。 是否可以在一组神经元上执行这样的算法？ 例如，K-means方法。 只需稍微简化一下即可。 在经典算法中，中心被迭代地计算为所有考虑示例的平均值，但是我们将在每个示例之后立即移动中心。 <br><br> 让我们看看实现聚类算法所需的条件。 <br><br><ul><li> 当然，簇中心是我们组中神经元的树突。 但是如何记住这些信息？ 假设将信息存储在枝状体中的单位晶胞是突触区域中枝状体分支的体积。 分支越厚，其体积越大，保存的值越大。 因此，每个树枝状晶体可以存储几个模拟量。 </li><li> 比较器计算一个示例的接近度。 更复杂。 假设提供数据后（轴突弹出神经递质），每个神经元将更快地工作，存储的数据越多（簇的中心）与给出的示例（神经递质的数量）相似。 请注意，神经元的响应率不受神经递质绝对量的影响，而是受神经递质量与树突中存储值的接近程度的影响。 假设如果神经递质很小，那么树枝状晶体不会发出尖峰信号。 没有任何反应，并且如果存在大量神经递质，则树突状分支的尖峰比其他树突状分支的尖峰更早出现并且不会到达核。 但是，如果神经递质是正确的，那么所有的树突状分支都会在大约同一时间发出小尖峰，并且该波将变成沿着轴突的神经元尖峰。 </li><li> 多输入比较器使您可以比较结果并选择最佳结果。 假设附近的神经元对其所有邻居都有抑制作用。 因此，在特定的一组神经元中，任何时间都只能活跃。 最先起作用的那个。 由于该组中的神经元在附近，因此它们对进入该组的所有轴突具有相同的访问权限。 因此，其中存储的信息最接近所讨论示例的神经元将在该组中工作。 </li><li> 中心向示例的位移机制。 好吧，一切都很简单。 在神经元尖峰之后，该神经元的所有树突均改变其体积。 在神经递质浓度过高的地方，分支生长。 在不足之处，减少树枝。 只要浓度合适，体积就不会改变。 树枝的体积略有不同。 但是马上。 下一个高峰是下一个变化。 </li></ul><br> 让我们在实践中检查结果算法。 我在Python中画了几行。 这是二维随机数发生的情况： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a4/5b2/a12/2a45b2a122a9536cf95e3768af65d4f2.gif"></div><br> 这是MNIST： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ceb/6a5/61a/ceb6a561a711c640904a74d1443fa706.gif"></div><br> 乍一看，以上所有内容似乎都没有改变。 好吧，我们在输入处有一些数据，我们以某种方式对其进行了转换，获得了其他数据。 <br><br> 但是确实有区别。 如果在转换之前我们有一堆模拟参数，那么在转换之后我们只有一个参数，同时由a码编码。 该组中的每个神经元都可以与特定动作相关联。 <br><br> 让我举个例子：假设一个聚类组中只有两个神经元。 称它们为“ TASTY”和“ SCARY”。 为了让大脑做出决定，只需要将“ EAT”神经元连接到第一个，而将“ RUN”连接到第二个。 为此，我们需要一位老师。 但是现在还不止如此，与老师一起教学是另一篇文章的主题。 <br><br> 如果增加簇数，则准确性将逐渐提高。 极端情况是簇数等于示例数。 但是有一个问题，大脑中神经元的数量是有限的。 一个人必须不断地折衷，无论是准确性还是大脑大小。 <br><br><h2> 元聚类 </h2><br> 假设我们没有一个群集组，而是两个。 在这种情况下，将相同的值应用于输入。 显然，您得到相同的结果。 <br><br> 让我们做一个随机的错误。 有时，让每个聚类器都不选择聚类的最近中心，而是选择哪个中心。 然后，这些值将开始不同，随着时间的流逝，差异将不断累积。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/844/742/6ce/8447426cea375229e23546b4be16ee1b.gif"></div><br> 现在，让我们计算每个聚类器的错误。 错误是输入示例与所选聚类中心之间的差异。 如果一个聚类器选择了最接近的值，而另一个则选择了随机值，则第二个聚类器将具有更大的误差。 <br><br> 继续，为每个群集器的输入添加一个掩码。 掩码是每个输入的一组系数。 不是掩码中通常使用的零或一，而是从零到一的某个实数。 <br><br> 在将示例提供给聚类器的输入之前，我们先将示例与掩码相乘。 例如，如果将遮罩用于图片，则对于某些像素，该遮罩等于1，则好像完全透明。 如果掩码为零，则此像素始终为黑色。 如果蒙版为1/2，则像素变暗一半。 <br><br> 现在是主要动作，我们将根据聚类误差按比例减少蒙版的值。 也就是说，如果误差很大，那么我们将更强烈地减小该值，如果它为零，则根本不会减小它。 <br><br> 为了使掩码的值不会逐渐重置为零，我们将其标准化。 即，每个输入参数的掩码值之和始终等于1。 如果在一个遮罩中拿走了某些东西，则将其添加到另一个遮罩中。 <br><br> 让我们尝试看一下MNIST的例子。 我们看到掩模逐渐将像素分为两部分。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/39c/204/a45/39c204a45731b8408b14cb9621cd91b0.gif"></div><br> 生成的蒙版显示在图片的右侧。 在过程结束时，上层集群器考虑右下角，下层集群器考虑其余的示例。 有趣的是，如果我们重新启动该过程，则会得到另一个分离。 但是同时，不是随机获得参数组，而是以减小预测误差的方式获得。 群集似乎尝试将每个像素粘贴到其蒙版上，同时，像素选择了最适合该像素的群集器。 <br><br> 让我们尝试输入两位数，不要互相叠加，而是彼此相邻，像这样（这是一个示例，不是两个）： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9ee/675/145/9ee6751458d904e22d9d286e704084eb.jpg" alt="图片"></div><br> 现在我们看到，每次分离都是一样的。 也就是说，如果有一个单独的，显然是分离蒙版的最佳选择，那么它将被选择。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/48b/55c/487/48b55c4877b5938ed22f5473bb4fb033.gif"></div><br> 无论第一个掩码是选择左数字还是右数字，只有一件事是随机的。 <br><br> 我将生成的蒙版称为元集群。 以及通过元聚类形成掩模的过程。 为什么要元？ 因为聚类不是输入示例的聚类，而是输入本身的聚类。 <br><br> 一个例子更复杂。 让我们尝试将25个参数划分为5个元集群。 <br><br> 为此，我们采用由单一代码编码的五个参数组成的五组。 <br><br> 也就是说，在每个组中，随机位置只有一个单位。 每个示例中始终有五个单元。 <br><br> 在下面的图片中，每一列都是输入参数，每一行都是元集群掩码。 群集本身未显示。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/95e/a47/42b/95ea4742b10e16dac89d9a27dc02822a.gif"></div><br>  100个参数和10个元集群： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/55a/632/b55/55a632b5503d6b4c439c8905d1bdf46b.gif"></div><br> 有效！ 在某些地方，它甚至有点像同名电影中的矩阵图像。 <br><br> 使用元集群可以大大减少集群数量。 <br><br> 例如，以十组为一组，每组十个参数，每组有一个单位。 <br><br> 如果我们有一个集群器（没有元集群），那么我们需要10 <sup>10</sup> = 10000000000集群才能获得零误差。 <br><br> 如果我们有十个群集，则只需要10 * 10 = 100个群集。 这类似于十进制数字系统，您不需要为所有可能的数字都想出符号，可以使用十位数字。 <br><br> 元集群非常并行化。 可以对每个群集独立执行最昂贵的计算（将示例与群集的中心进行比较）。 请注意，不是用于群集，而是用于群集。 <br><br><h2> 它在大脑中如何运作 </h2><br> 在此之前，我只谈论树突，但神经元有轴突。 他们也学习。 因此，轴突很可能是元簇的面具。 <br><br> 我们在上面对树枝状操作的描述中增加了一个功能。 <br><br> 假设如果出现神经元尖峰，则所有树突都会以某种方式散发到突触中的某种物质，该物质显示出树突中神经递质的浓度。 不是从轴突到树突，而是回来。 该物质的浓度取决于比较误差。 假设误差越小，发射的物质量越大。 好吧，轴突对这种物质的量产生反应并生长。 如果物质很小，那就意味着大错了，那么轴突就会逐渐减少。 <br><br> 而且，如果您从大脑诞生之初就改变了轴突，那么随着时间的流逝，它们只会进入需要与这些轴突粘附的神经元组（不会导致大的错误）。 <br><br> 例如：让我们记住人的面孔。 让每个脸都以百万像素的图像进行描绘。 然后，每张脸都需要一个具有一百万个树突的神经元，这是不现实的。 现在，将所有像素划分为元簇，例如眼睛，鼻子，耳朵等。 只有十个这样的元集群。 对于每个元集群，让它有十个集群，十个鼻子选项，十个耳朵选项，依此类推。 现在，要记住脸，一个具有十个树突的神经元就足够了。 这将记忆（和大脑容量）降低了五个数量级。 <br><br><h2> 结论 </h2><br> 现在，如果我们假设大脑由元簇组成，那么我们可以尝试从这种角度考虑活脑固有的一些概念： <br><br> 集群需要不断地训练，否则新数据将无法正确处理。 为了训练大脑中的簇，需要一个平衡的样本。 让我解释一下，如果现在是冬天，那么大脑将仅从冬天的例子中学习，并且所产生的簇将逐渐与冬天相关，而在夏天，一切都会对大脑不利。 怎么办呢？ 有必要定期向所有集群提交新的和旧的重要示例（冬季和夏季的记忆）。 为了使这些感觉不会干扰当前的感觉，您需要暂时关闭这些感觉。 在动物中，这被称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">梦</a> 。 <br><br> 想象一下，大脑看到一个小的东西，灰色，它在运转。 在进行元聚类后，我们在三个元聚类中拥有三个活动神经元。 并且由于记忆，大脑知道它很美味。 然后，大脑看到小的东西在运行。 但是大脑不知道它是美味还是恐怖。 暂时禁用颜色所在的元集群就足够了，仅保留运行中的较小的集群。 大脑知道它很美味。 这称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">类比</a> 。 <br><br> 假设大脑记住了某些东西，然后将某个组中的活动神经元簇改变为其他任何一个，而在其余的元簇中则存在真实的记忆。 现在，大脑已经引入了前所未有的东西。 这已经是一种<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">想象</a> 。 <br><br> 感谢您的关注，代码在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a> 。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN427407/">https://habr.com/ru/post/zh-CN427407/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN427397/index.html">开发用于训练神经网络的声学数据集</a></li>
<li><a href="../zh-CN427399/index.html">在基于GraphQL构建API时使用数据</a></li>
<li><a href="../zh-CN427401/index.html">溶解着色器和世界探索</a></li>
<li><a href="../zh-CN427403/index.html">ReportingObserver API：以新的角度看待网页代码</a></li>
<li><a href="../zh-CN427405/index.html">ES2018-最终承诺方法</a></li>
<li><a href="../zh-CN427409/index.html">该书“辉煌的敏捷。 使用敏捷，Scrum和看板的灵活项目管理»</a></li>
<li><a href="../zh-CN427413/index.html">争夺资源，第4部分：太好了</a></li>
<li><a href="../zh-CN427415/index.html">我们使用Node.js处理大型文件和原始数据集。</a></li>
<li><a href="../zh-CN427417/index.html">对8英寸的软盘充满幽默感（在70年代只有这样）</a></li>
<li><a href="../zh-CN427419/index.html">当处理器无关时该怎么办？</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
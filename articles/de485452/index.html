<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÜö üì£ üå≥ Warum Rust den TechEmpower Framework Benchmark anf√ºhrt üìë üí™üèø üë®üèæ‚Äç‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eigentlich hatte ich nicht vor zu sehen, welche Farbe die Eingeweide von Rust hatten. Ich habe ein Hobbyprojekt auf Go aufgegriffen und bin zu GitHub ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Warum Rust den TechEmpower Framework Benchmark anf√ºhrt</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485452/"><p>  Eigentlich hatte ich nicht vor zu sehen, welche Farbe die Eingeweide von Rust hatten.  Ich habe ein Hobbyprojekt auf Go aufgegriffen und bin zu GitHub gegangen, um den Stand von fasthttp zu sehen: Entwickelt es sich?  Na, zumindest unterst√ºtzt?  Aufgewachsen.  Ging, schaute, wo fasthttp in <a href="https://www.techempower.com/benchmarks/" rel="nofollow">TechEmpower-</a> Benchmarks sitzt.  Ich schaue: und dort zeigt fasthttp kaum die H√§lfte dessen, was der Anf√ºhrer schafft - zu etwas Actix auf etwas Rust.  Was f√ºr ein Schmerz. </p><br><p>  Hier verschr√§nkte ich die Arme, schlug dreimal mit dem Kopf auf den Boden und rief: "Halleluja, wahrlich, Rust ist ein wahrer Gott, wie blind ich vorher war!"  Aber entweder haben die Griffe nicht funktioniert, oder die Stirn hat es bereut ... Stattdessen habe ich mich mit dem Code der Tests befasst, der in Go und den Actix-Web-Tests in Rust geschrieben wurde.  Um es zu kl√§ren. </p><br><p>  Nach ein paar Stunden fand ich heraus: </p><br><ol><li>  warum actix-web Rust framework bei allen TechEmpower-Tests an erster Stelle steht, </li><li>  wie Java startet Script. </li></ol><br><p>  Jetzt erz√§hle ich dir alles in der richtigen Reihenfolge. </p><a name="habracut"></a><br><h2 id="chto-za-techempower-framework-benchmark">  Was ist der TechEmpower Framework Benchmark? </h2><br><p>  Wenn ein Web-Framework demonstriert, ob es "Ich bin schnell" an Freunde fl√ºstert oder beispielsweise dar√ºber nachdenkt, dies zu tun, f√§llt es mit Sicherheit in den TechEmpower Framework-Benchmark.  Ein beliebter Ort, um die Leistung zu messen. </p><br><p>  Die Website hat ein eigenartiges Design: Die Registerkarten mit Filtern, Runden, Bedingungen und Ergebnissen f√ºr verschiedene Testarten sind mit gro√üz√ºgiger Hand auf der Seite verteilt.  So gro√üz√ºgig und mitrei√üend, dass Sie sie einfach nicht bemerken.  Es lohnt sich jedoch, auf die Registerkarten zu klicken. Die Informationen dahinter sind hilfreich. </p><br><p>  Am einfachsten ist es, die Klartext-Testergebnisse "Hello World!"  f√ºr Webserver.  Die Autoren des Frameworks geben in der Regel einen Link dazu an: Wir bleiben angeblich in den ersten hundert.  Der Fall ist richtig und n√ºtzlich.  Im Allgemeinen ist es f√ºr viele gut, Klartext zu verschenken, und die F√ºhrungskr√§fte bilden eine enge Gruppe. </p><br><p>  In diesen Registerkarten werden die Ergebnisse von Tests anderer Typen (Szenarien) angezeigt.  Es gibt sieben davon, weitere Details finden Sie <a href="https://github.com/TechEmpower/FrameworkBenchmarks/wiki/Project-Information-Framework-Tests-Overview" rel="nofollow">hier</a> .  Diese Skripte testen nicht nur, wie das Framework / die Plattform die Verarbeitung einer einfachen http-Anforderung handhabt, sondern auch eine Kombination mit einem Datenbank-Client, einer Vorlagen-Engine oder einem JSON-Serializer. </p><br><p>  In einer virtuellen Umgebung befinden sich Testdaten auf einer physischen Hardware.  Neben Grafiken gibt es tabellarische Daten.  In der Regel eine Menge interessanter Dinge, lohnt es sich zu graben, nicht nur auf die Position von "Ihrer" Plattform zu schauen. </p><br><p>  Das erste, woran ich dachte, nachdem ich die Testergebnisse durchgesehen hatte: "Warum unterscheidet sich alles so sehr von Klartext?!".  Im Klartext befinden sich die F√ºhrungskr√§fte in einer engen Gruppe, aber wenn es um die Arbeit mit der Datenbank geht, liegt actix-web deutlich vorne.  Gleichzeitig zeigt es eine stabile Anforderungsbearbeitungszeit.  Shaitan. </p><br><p>  Eine weitere Anomalie: eine unglaublich leistungsstarke JavaScript-L√∂sung.  Es hei√üt ex4x.  Es stellte sich heraus, dass sein Code etwas weniger als vollst√§ndig in Java geschrieben war.  Wird von Java Runtime, JDBC, verwendet.  JavaScript-Code wird in Bytecode √ºbersetzt und klebt Java-Bibliotheken.  Sie haben es buchst√§blich genommen - und Script an Java angeh√§ngt.  Den Tricks der blassen Gesichter sind keine Grenzen gesetzt. </p><br><h2 id="kak-posmotret-kod-i-chto-tam-vnutri">  Wie man den Code ansieht und was drin ist </h2><br><p>  Der Code f√ºr alle Tests ist auf GitHub.  Alles befindet sich in einem einzigen Repository, was sehr praktisch ist.  Du kannst klonen und schauen, du kannst direkt auf GitHub schauen.  Das Testen umfasst mehr als 300 verschiedene Kombinationen des Frameworks mit Serialisierern, Template-Engines und dem Datenbank-Client.  In verschiedenen Programmiersprachen, mit einer anderen Herangehensweise an die Entwicklung.  Implementierungen in einer Sprache sind in der N√§he, sie k√∂nnen mit Implementierungen in anderen Sprachen verglichen werden.  Der Code wird von der Community gepflegt und ist nicht die Arbeit einer Person oder eines Teams. </p><br><p>  Der Benchmark-Code ist ein gro√üartiger Ort, um Ihren Horizont zu erweitern.  Es ist interessant zu analysieren, wie verschiedene Personen die gleichen Probleme l√∂sen.  Es gibt nicht viel Code, die verwendeten Bibliotheken und L√∂sungen sind leicht zu unterscheiden.  Ich bereue √ºberhaupt nicht, dass ich dort angekommen bin.  Ich habe viel gelernt.  Zuallererst √ºber Rust. </p><br><p>  Vor Rust hatte ich eine sehr vage Idee.  In jedem Artikel √ºber C, C ++, D und insbesondere Go gibt es mit Sicherheit ein paar Kommentatoren, die ausf√ºhrlich und mit Sorge erkl√§ren, dass Eitelkeit, Unsinn und Dummheit in etwas anderem geschrieben sind, solange es etwas gibt <del>  Gascogne </del>  Rust.  Manchmal werden sie so sehr mitgerissen, dass sie Codebeispiele geben als eine unvorbereitete Person <del>  oder wenige akzeptieren </del>  verbl√ºfft: "Warum, warum, warum all diese Symbole?!" </p><br><p>  Daher war das √ñffnen des Codes be√§ngstigend. </p><br><p>  Ich habe geschaut.  Es stellte sich heraus, dass Programme in Rust gelesen werden k√∂nnen.  Au√üerdem ist der Code so gut gelesen, dass ich sogar Rust installiert, versucht habe, den Test zu kompilieren und ein bisschen daran zu basteln. </p><br><p>  Hier habe ich dieses Gesch√§ft fast aufgegeben, weil die Zusammenstellung eine lange Zeit dauert.  Sehr lang.  Wenn ich D'Artagnan w√§re oder nur ein Choleriker, w√§re ich in die Gascogne gelaufen, und tausend Teufel w√§ren niedergeschlagen.  Aber ich habe es geschafft.  Ich habe wieder Tee getrunken.  Es scheint, dass nicht einmal eine Tasse: Auf meinem Laptop hat die erste Zusammenstellung etwa 20 Minuten gedauert, dann macht aber alles mehr Spa√ü.  Vielleicht bis zu den n√§chsten gro√üen Update-Kisten. </p><br><h2 id="a-razve-delo-ne-v-samom-rust">  Aber ist es nicht Rust selbst? </h2><br><p>  Nein.  Keine Programmiersprache. </p><br><p>  Nat√ºrlich ist Rust eine wunderbare Sprache.  Kraftvoll, flexibel, wenn auch aus Gewohnheit und wortreich.  Aber die Sprache selbst wird keinen schnellen Code schreiben.  Die Sprache ist eines der Werkzeuge, eine der Entscheidungen, die der Programmierer trifft. </p><br><p>  Wie gesagt - Klartext zu verschenken ist f√ºr viele schnell erledigt.  Die Leistung von actix-web, fasthttp und einem Dutzend anderer Frameworks bei der Verarbeitung einer einfachen Anfrage ist durchaus vergleichbar, dh andere Sprachen haben die technische F√§higkeit, mit Rust zu konkurrieren. </p><br><p>  Actix-web selbst ist nat√ºrlich ‚Äûschuld‚Äú: ein schnelles, pragmatisches, exzellentes Produkt.  Die Serialisierung ist praktisch, die Template-Engine ist gut - sie hilft auch sehr. </p><br><p>  Insbesondere unterscheiden sich die Ergebnisse von Tests, die mit der Datenbank arbeiten. </p><br><p>  Nachdem ich mich ein wenig in den Code eingearbeitet hatte, stellte ich drei Hauptunterschiede heraus, die (meiner Meinung nach) dazu beigetragen haben, dass sich Actix-Tests bei synthetischen Tests von der Konkurrenz abheben: </p><br><ol><li>  Pipelined Pipelined Tokio-Postgres-Betriebsmodus; </li><li>  Verwenden einer einzelnen Verbindung mit einem Rust-Test anstelle eines Verbindungspools mit einem in Go geschriebenen Test. </li><li>  Aktualisieren von Actix-Benchmarks mit einem einzigen Befehl, der √ºber eine einfache Abfrage gesendet wird, anstatt mehrere UPDATE-Befehle zu senden. </li></ol><br><h2 id="chto-esche-za-konveyernyy-rezhim">  Was f√ºr ein F√∂rdermodus? </h2><br><p>  Hier ist ein Ausschnitt aus der tokio-postgres-Dokumentation (die im Benchmark der PostgreSQL-Clientbibliothek verwendet wird), der erkl√§rt, was die Entwickler damit meinen: </p><br><pre><code class="plaintext hljs">Sequential Pipelined | Client | PostgreSQL | | Client | PostgreSQL | |----------------|-----------------| |----------------|-----------------| | send query 1 | | | send query 1 | | | | process query 1 | | send query 2 | process query 1 | | receive rows 1 | | | send query 3 | process query 2 | | send query 2 | | | receive rows 1 | process query 3 | | | process query 2 | | receive rows 2 | | | receive rows 2 | | | receive rows 3 | | | send query 3 | | | | process query 3 | | receive rows 3 | |</code> </pre> <br><p>  Der Client im Pipelined-Modus (Pipelined-Modus) wartet nicht auf eine PostgreSQL-Antwort, sondern sendet die n√§chste Abfrage, w√§hrend PostgreSQL die vorherige verarbeitet.  Es ist ersichtlich, dass Sie auf diese Weise dieselbe Sequenz von Datenbankabfragen erheblich schneller verarbeiten k√∂nnen. </p><br><p>  Wenn die Verbindung im Pipeline-Modus Duplex ist (was die M√∂glichkeit bietet, Ergebnisse parallel zum Senden zu erhalten), kann sich diese Zeit geringf√ºgig verk√ºrzen.  Es scheint, dass es bereits eine experimentelle Version von tokio-postgres gibt, bei der eine Duplexverbindung ge√∂ffnet ist. </p><br><p>  Da der PostgreSQL-Client mehrere Nachrichten (Parse, Bind, Execute und Sync) an jede zur Ausf√ºhrung gesendete SQL-Abfrage sendet und eine Antwort darauf erh√§lt, ist der Pipeline-Modus auch bei der Verarbeitung einzelner Abfragen effektiver. </p><br><h2 id="a-pochemu-v-go-ne-tak">  Und warum ist es nicht in Go? </h2><br><p>  Da Go normalerweise Datenbankverbindungspools verwendet.  Verbindungen sind nicht zur parallelen Verwendung vorgesehen. </p><br><p>  Wenn Sie dieselben SQL-Abfragen √ºber einen Pool und nicht √ºber eine Verbindung ausf√ºhren, k√∂nnen Sie theoretisch mit einem normalen seriellen Client eine noch k√ºrzere Ausf√ºhrungszeit erzielen, als wenn Sie √ºber eine einzelne Verbindung arbeiten, sei es dreimal per Pipeline: </p><br><pre> <code class="plaintext hljs">| Connection | Connection 2 | Connection 3 | PostgreSQL | |----------------|----------------|----------------|-----------------| | send query 1 | | | | | | send query 2 | | process query 1 | | receive rows 1 | | send query 3 | process query 2 | | | receive rows 2 | | process query 3 | | | receive rows 3 | |</code> </pre><br><p>  Es sieht so aus, als ob das Schaffell (F√∂rderer-Modus) die Kerze nicht wert ist. </p><br><p>  Nur unter hoher Last kann die Anzahl der Verbindungen zum PostgreSQL-Server ein Problem sein. </p><br><h2 id="a-pri-chyom-tut-voobsche-kolichestvo-soedineniy">  Und was hat die Anzahl der Verbindungen damit zu tun? </h2><br><p>  Hier geht es darum, wie der PostgreSQL-Server auf eine Zunahme der Anzahl von Verbindungen reagiert. </p><br><p>  Die linke Spaltengruppe zeigt den Anstieg und Abfall der PostgreSQL-Leistung in Abh√§ngigkeit von der Anzahl der offenen Verbindungen: </p><br><p><img src="https://habrastorage.org/webt/nj/rl/io/njrlior5dxzdovhnxrv4spx8q_w.png"></p><br><p>  <em>( <a href="https://www.percona.com/blog/2018/06/27/scaling-postgresql-with-pgbouncer-you-may-need-a-connection-pooler-sooner-than-you-expect/" rel="nofollow">Nach Percona-Post</a> )</em> </p><br><p>  Es ist zu erkennen, dass mit zunehmender Anzahl offener Verbindungen die Leistung des PostgreSQL-Servers rapide abnimmt. </p><br><p>  Dar√ºber hinaus ist das √ñffnen einer direkten Verbindung nicht "kostenlos".  Unmittelbar nach dem √ñffnen sendet der Client Dienstinformationen, "stimmt" mit dem PostgreSQL-Server √ºberein, wie die Anforderungen verarbeitet werden. </p><br><p>  In der Praxis m√ºssen Sie daher die Anzahl der aktiven Verbindungen zu PostgreSQL begrenzen und diese h√§ufig zus√§tzlich √ºber pgbouncer oder eine andere Odyssee weiterleiten. </p><br><h2 id="tak-pochemu-actix-web-okazalsya-bystree">  Warum war actix-web schneller? </h2><br><p>  Zun√§chst einmal ist actix-web selbst verdammt schnell.  Er setzt die ‚ÄûObergrenze‚Äú fest und ist etwas h√∂her als die der anderen.  Andere verwendete Bibliotheken (serde, yarde) sind ebenfalls sehr, sehr produktiv.  In Tests mit PostgreSQL schien es mir jedoch m√∂glich zu sein, das Problem zu l√∂sen, da der Actix-Web-Server einen Thread auf dem Prozessorkern startet.  Jeder Thread √∂ffnet nur eine Verbindung zu PostgreSQL. </p><br><p>  Je weniger Verbindungen aktiv sind, desto schneller funktioniert PostgreSQL (siehe Grafik oben). </p><br><p>  Der Client, der im Pipeline-Modus (tokio-postgres) arbeitet, erm√∂glicht es Ihnen, eine Verbindung mit PostgreSQL effektiv f√ºr die parallele Verarbeitung von Benutzeranfragen zu verwenden.  HTTP-Request-Handler speichern ihre SQL-Befehle in einer Warteschlange und richten sie in einer anderen aus, um Ergebnisse zu erhalten.  Die Ergebnisse machen Spa√ü, die Verz√∂gerungen sind minimal, alle sind gl√ºcklich.  Die Gesamtleistung ist h√∂her als bei einem System mit einem Verbindungspool. </p><br><p>  Sie m√ºssen also den Pool verlassen, einen PostgreSQL-Pipeline-Client schreiben, und das Gl√ºck und die unglaubliche Geschwindigkeit werden sofort kommen? </p><br><p>  M√∂glicherweise.  Aber nicht auf einmal. </p><br><h2 id="kogda-konveyernyy-rezhim-vryad-li-spaset-i-uzh-tochno-ne-sohranit">  Wenn es unwahrscheinlich ist, dass der F√∂rdermodus speichert, und sicherlich nicht speichert </h2><br><p>  Das im Benchmark-Code verwendete Schema funktioniert nicht mit PostgreSQL-Transaktionen. </p><br><p>  In der Benchmark werden keine Transaktionen ben√∂tigt und der Code wird unter Ber√ºcksichtigung der Tatsache geschrieben, dass keine Transaktionen stattfinden.  In der Praxis passieren sie. </p><br><p>  Wenn der Backend-Code eine PostgreSQL-Transaktion √∂ffnet (um beispielsweise zwei verschiedene Tabellen atomar zu √§ndern), werden alle √ºber diese Verbindung gesendeten Befehle innerhalb dieser Transaktion ausgef√ºhrt. </p><br><p>  Da die Verbindung mit PostgreSQL parallel genutzt wird, ger√§t alles durcheinander.  Die Befehle, die in einer vom Entwickler entworfenen Transaktion ausgef√ºhrt werden sollen, werden mit SQL-Befehlen gemischt, die von parallelen HTTP-Request-Handlern initiiert werden.  Wir erhalten zuf√§llige Datenverluste und Probleme mit deren Integrit√§t. </p><br><p>  Also hallo Transaktion - auf Wiedersehen parallele Nutzung einer Verbindung.  Sie m√ºssen sicherstellen, dass die Verbindung nicht von anderen HTTP-Request-Handlern verwendet wird.  Sie m√ºssen entweder die Verarbeitung eingehender http-Anforderungen beenden, bevor Sie die Transaktion schlie√üen, oder einen Pool f√ºr Transaktionen verwenden, um mehrere Verbindungen zum Datenbankserver herzustellen.  Es gibt mehrere Pool-Implementierungen f√ºr Rust und keine.  Dar√ºber hinaus existieren sie in Rust getrennt von der Datenbank-Client-Implementierung.  Sie k√∂nnen nach Geschmack, Farbe, Geruch oder nach Belieben w√§hlen.  Go funktioniert so nicht.  Die Kraft der Generika, ja. </p><br><p>  Ein wichtiger Punkt: Im Test, dessen Code ich sah, werden keine Transaktionen ge√∂ffnet.  Diese Frage ist es einfach nicht wert.  Der Benchmark-Code ist f√ºr eine bestimmte Aufgabe und sehr spezielle Betriebsbedingungen der Anwendung optimiert.  Die Entscheidung, eine Verbindung pro Server-Stream zu verwenden, wurde wahrscheinlich bewusst getroffen und erwies sich als sehr effektiv. </p><br><h2 id="est-v-kode-benchmarka-esche-chto-to-interesnoe">  Gibt es noch etwas Interessantes im Benchmark-Code? </h2><br><p>  Ja </p><br><p>  Das Szenario zur Leistungsmessung ist sehr detailliert beschrieben.  Sowie die Kriterien, die der an den Tests teilnehmende Code erf√ºllen muss.  Eine davon ist, dass alle Abfragen an den Datenbankserver nacheinander ausgef√ºhrt werden m√ºssen. </p><br><p>  Das folgende (leicht abgek√ºrzte) Codefragment scheint die Kriterien nicht zu erf√ºllen: </p><br><pre> <code class="rust hljs"> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mut</span></span> worlds = <span class="hljs-built_in"><span class="hljs-built_in">Vec</span></span>::with_capacity(num); <span class="hljs-comment"><span class="hljs-comment">//  num    PostgreSQL for _ in 0..num { let w_id: i32 = self.rng.gen_range(1, 10_001); worlds.push( self.cl .query(&amp;self.world, &amp;[&amp;w_id]) .into_future() .map(move |(row, _)| { // ... }), ); } //     stream::futures_unordered(worlds) .collect() .and_then(move |worlds| { // ... })</span></span></code> </pre> <br><p>  Alles sieht aus wie ein typischer Start von parallelen Prozessen.  Da jedoch eine Verbindung zu PostgreSQL verwendet wird, werden Abfragen an den Datenbankserver nacheinander gesendet.  Eins nach dem anderen.  Wie erforderlich.  Kein Verbrechen. </p><br><p>  Warum so?  Nun, erstens wird in dem Code (der in der Redaktion, die in der 18. Runde arbeitete, angegeben wurde) async / await noch nicht verwendet, er erschien sp√§ter in Rust.  Und durch Futures <code>num</code> es einfacher, SQL-Abfragen "parallel" zu senden - wie im obigen Code.  Auf diese Weise k√∂nnen Sie eine zus√§tzliche Leistungssteigerung erzielen: W√§hrend PostgreSQL die erste SQL-Abfrage akzeptiert und verarbeitet, wird der Rest an PostgreSQL weitergeleitet.  Der Webserver wartet nicht auf das Ergebnis der einzelnen Tasks, sondern wechselt zu anderen Tasks und kehrt erst dann zur Verarbeitung der http-Anforderung zur√ºck, wenn alle SQL-Abfragen abgeschlossen sind. </p><br><p>  F√ºr PostgreSQL besteht der Bonus darin, dass dieselbe Art von Abfrage im selben Kontext (Verbindung) hintereinander ausgef√ºhrt wird.  Die Wahrscheinlichkeit, dass der Abfrageplan nicht wiederhergestellt wird, steigt. </p><br><p>  Es stellt sich heraus, dass die Vorteile des Pipeline-Modus (siehe das Diagramm aus der tokio-postgres-Dokumentation) auch bei der Verarbeitung einer einzelnen http-Anforderung voll ausgenutzt werden. </p><br><p>  Was sonst? </p><br><h2 id="ispolzovanie-uproschennogo-protokola-simple-query-dlya-paketnogo-obnovleniya">  Verwenden des einfachen Abfrageprotokolls f√ºr Stapelaktualisierungen </h2><br><p>  Das Kommunikationsprotokoll zwischen dem Client und dem PostgreSQL-Server erm√∂glicht alternative Methoden zum Ausf√ºhren von SQL-Befehlen.  Das √ºbliche Protokoll (Extended Query) umfasst das Senden mehrerer Nachrichten an einen Client: Parse, Bind, Execute und Sync.  Eine Alternative ist das Simple Query-Protokoll, nach dem eine einzige Nachricht ausreicht, um einen Befehl auszuf√ºhren und Ergebnisse zu erhalten - Query. </p><br><p>  Der Hauptunterschied zwischen den √ºblichen Protokollen besteht in der √úbertragung der Anforderungsparameter: Sie werden getrennt vom Befehl selbst √ºbertragen.  Es ist sicherer.  Das vereinfachte Protokoll geht davon aus, dass alle Parameter der SQL-Abfrage in eine Zeichenfolge konvertiert und im Hauptteil der Abfrage enthalten sind. </p><br><p>  Eine interessante L√∂sung f√ºr die actix-web-Benchmarks bestand darin, mehrere Tabelleneintr√§ge mit einem einzigen Befehl zu aktualisieren, der √ºber das Simple Query-Protokoll gesendet wurde. </p><br><p>  Gem√§√ü dem Benchmark muss der Webserver bei der Verarbeitung einer Benutzeranforderung mehrere Datens√§tze in der Tabelle aktualisieren und Zufallszahlen schreiben.  Offensichtlich dauert das Aktualisieren von Datens√§tzen nacheinander mit sequentiellen Abfragen l√§nger als das Aktualisieren aller Datens√§tze auf einmal. </p><br><p>  Die im Testcode generierte Anfrage sieht ungef√§hr so ‚Äã‚Äãaus: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> world <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> randomnumber = temp.randomnumber <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), (<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> temp(<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>, randomnumber) <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> temp.id = world.id</code> </pre> <br><p>  Wobei <code>(1, 2), (2, 3)</code> die Zeilenbezeichnerpaare / neuer Wert des Zufallszahlenfeldes sind. </p><br><p>  Die Anzahl der aktualisierten Datens√§tze ist variabel. Das Vorbereiten einer (PREPARE) -Anforderung im Voraus ist nicht sinnvoll.  Da es sich bei den zu aktualisierenden Daten um numerische Daten handelt und der Quelle vertraut werden kann (dem Testcode selbst), besteht keine Gefahr der SQL-Injection. Die Daten werden einfach in den SQL-Body aufgenommen und alles wird mithilfe des Simple Query-Protokolls gesendet. </p><br><p>  Einfache Abfrage wird gemunkelt.  Ich traf eine Empfehlung: "Arbeiten Sie nur am Simple Query-Protokoll, und alles wird schnell und gut."  Ich nehme sie mit gro√üer Skepsis wahr.  Mit der einfachen Abfrage k√∂nnen Sie die Anzahl der an den PostgreSQL-Server gesendeten Nachrichten verringern, indem Sie die Verarbeitung der Abfrageparameter auf die Clientseite verlagern.  Sie k√∂nnen den Gewinn f√ºr dynamisch generierte Abfragen mit einer variablen Anzahl von Parametern sehen.  Bei der gleichen Art von SQL-Abfragen (die h√§ufiger vorkommen) ist der Gewinn nicht offensichtlich.  Gut und wie sicher die Verarbeitung von Abfrageparametern sein wird, bestimmt im Fall von Simple Query die Implementierung der Clientbibliothek. </p><br><p>  Wie ich oben geschrieben habe, wird in diesem Fall der Hauptteil der SQL-Abfrage dynamisch generiert, die Daten sind numerisch und werden vom Server selbst generiert.  Die perfekte Kombination f√ºr Simple Query.  Aber auch in diesem Fall lohnt es sich, andere Optionen zu testen.  Alternativen h√§ngen von der PostgreSQL-Plattform und dem Client ab: pgx (der Client f√ºr Go) erm√∂glicht das Senden eines Befehlspakets, JDBC - um einen Befehl mehrmals hintereinander mit verschiedenen Parametern auszuf√ºhren.  Beide L√∂sungen k√∂nnen mit der gleichen Geschwindigkeit ausgef√ºhrt werden oder sogar schneller sein. </p><br><h2 id="tak-pochemu-rust-lidiruet">  Warum f√ºhrt Rust? </h2><br><p>  Der Anf√ºhrer ist nat√ºrlich nicht Rust.  Tests, die auf actix-web basieren, sind f√ºhrend - er setzt die "Obergrenze" der Leistung.  Es gibt zum Beispiel Raketen und Eisen, die bescheidene Stellungen einnehmen.  Aber im Moment ist es actix-web, das das Potenzial f√ºr den Einsatz von Rust in der Webentwicklung bestimmt.  F√ºr mich ist das Potenzial sehr hoch. </p><br><p>  Ein weiterer nicht offensichtlicher, aber wichtiger "geheimer" Server auf Basis von actix-web, der in allen TechEmpower-Benchmarks den ersten Platz belegte - wie es mit PostgreSQL funktioniert: </p><br><ol><li>  Pro Webserver-Stream wird nur eine Verbindung mit PostgreSQL ge√∂ffnet.  Diese Verbindung verwendet den Pipeline-Modus, mit dem Benutzeranforderungen effektiv parallel verarbeitet werden k√∂nnen. </li><li>  Je weniger aktive Verbindungen vorhanden sind, desto schneller reagiert PostgreSQL.  Die Geschwindigkeit der Verarbeitung von Benutzeranforderungen nimmt zu.  Gleichzeitig arbeitet das gesamte System unter Last stabiler (Verz√∂gerungen bei der Verarbeitung eingehender Anforderungen sind geringer, sie wachsen langsamer). </li></ol><br><p>  Wenn Geschwindigkeit wichtig ist, ist diese Option wahrscheinlich schneller als die Verwendung von Multiplexern (wie pgbouncer und odyssey).  Und sicherlich war er in den Benchmarks schneller. </p><br><p>  Es ist sehr interessant, wie sich Async / Warten, das in Rust aufgetaucht ist, und das j√ºngste Drama mit Actix-Web auf die Popularit√§t von Rust in der Webentwicklung auswirken.  Es ist auch interessant, wie sich die Testergebnisse √§ndern, wenn sie asynchron verarbeitet werden. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de485452/">https://habr.com/ru/post/de485452/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de485428/index.html">Das mysteri√∂se LyX-Programm. Teil 5</a></li>
<li><a href="../de485430/index.html">Einfacher Mehrbenutzer-Texteditor mit End-to-End-Verschl√ºsselung</a></li>
<li><a href="../de485438/index.html">Testen der Komponenten der Reaktionsoberfl√§che</a></li>
<li><a href="../de485448/index.html">Ein weiteres FM-Radio auf dem RDA5807 mit Arduino</a></li>
<li><a href="../de485450/index.html">Was ist neu in SObjectizer-5.7.0 und worauf wartet dieses Projekt als n√§chstes?</a></li>
<li><a href="../de485454/index.html">Erste Schritte mit User Returns: Tipps f√ºr das Hooked-Modell</a></li>
<li><a href="../de485458/index.html">Haubitze Schalld√§mpfer</a></li>
<li><a href="../de485460/index.html">20 Bibliotheken f√ºr eine spektakul√§re iOS-Anwendung</a></li>
<li><a href="../de485462/index.html">Wir besch√§ftigen uns mit eSIM (+ Interview mit einem Experten)</a></li>
<li><a href="../de485464/index.html">Mein erstes HTML5-Spiel von Alice Yandex und Siege f√ºr mobile Anwendungen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö° üöÆ üöí End2End-abordagem para entender a linguagem falada üöó üèì üé¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Existem v√°rias abordagens para entender uma m√°quina de fala coloquial: a abordagem cl√°ssica de tr√™s componentes (inclui um componente de reconheciment...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>End2End-abordagem para entender a linguagem falada</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/451008/">  <i>Existem v√°rias abordagens para entender uma m√°quina de fala coloquial: a abordagem cl√°ssica de tr√™s componentes (inclui um componente de reconhecimento de fala, um componente de compreens√£o de linguagem natural e um componente respons√°vel por uma certa l√≥gica de neg√≥cios) e uma abordagem End2End que envolve quatro modelos de implementa√ß√£o: direto, colaborativo, multiest√°gio e multitarefa. .</i>  <i>Vamos considerar todos os pr√≥s e contras dessas abordagens, incluindo os baseados nos experimentos do Google, e analisar detalhadamente por que a abordagem End2End resolve os problemas da abordagem cl√°ssica.</i> <i><br></i> <br><img src="https://habrastorage.org/webt/4f/zx/o3/4fzxo3p37pnl9kprkwk1trmwxd4.png"><a name="habracut"></a><br><br>  Damos a palavra ao principal desenvolvedor do centro de AI MTS Nikita Semenov. <br><br>  Oi  Como pref√°cio, quero citar os renomados cientistas Jan Lekun, Joshua Benjio e Jeffrey Hinton - esses s√£o tr√™s pioneiros da intelig√™ncia artificial que recentemente receberam um dos pr√™mios de maior prest√≠gio no campo da tecnologia da informa√ß√£o - o Turing Award.  Em uma das edi√ß√µes da revista Nature em 2015, eles lan√ßaram um artigo muito interessante "Aprendizado profundo", no qual havia uma frase interessante: "O aprendizado profundo veio com a promessa de sua capacidade de lidar com sinais brutos sem a necessidade de recursos artesanais".  √â dif√≠cil traduzi-lo corretamente, mas o significado √© algo assim: "O aprendizado profundo veio com a promessa da capacidade de lidar com sinais brutos sem a necessidade de cria√ß√£o manual de sinais".  Na minha opini√£o, para os desenvolvedores, esse √© o principal motivador de todos os existentes. <br><br><h4>  Abordagem cl√°ssica </h4><br>  Ent√£o, vamos come√ßar com a abordagem cl√°ssica.  Quando falamos em entender como falar com uma m√°quina, queremos dizer que temos uma certa pessoa que deseja controlar alguns servi√ßos com sua voz ou sente a necessidade de algum sistema responder a seus comandos de voz com alguma l√≥gica. <br><br>  Como esse problema √© resolvido?  Na vers√£o cl√°ssica, √© utilizado um sistema que, como mencionado acima, consiste em tr√™s grandes componentes: um componente de reconhecimento de fala, um componente para entender uma linguagem natural e um componente respons√°vel por uma certa l√≥gica de neg√≥cios.  √â claro que, a princ√≠pio, o usu√°rio cria um certo sinal sonoro, que cai sobre o componente de reconhecimento de fala e passa do som para o texto.  Em seguida, o texto entra no componente de compreens√£o da linguagem natural, a partir da qual √© retirada uma certa estrutura sem√¢ntica, necess√°ria para o componente respons√°vel pela l√≥gica de neg√≥cios. <br><br><img src="https://habrastorage.org/webt/sl/s9/a1/sls9a1uzwmia7h523tecvgssiec.png"><br><br>  O que √© uma estrutura sem√¢ntica?  Este √© um tipo de generaliza√ß√£o / agrega√ß√£o de v√°rias tarefas em uma - para facilitar a compreens√£o.  A estrutura inclui tr√™s partes importantes: a classifica√ß√£o do dom√≠nio (uma certa defini√ß√£o do t√≥pico), a classifica√ß√£o da inten√ß√£o (entendendo o que precisa ser feito) e a aloca√ß√£o das entidades nomeadas para preencher os cart√µes necess√°rios para tarefas comerciais espec√≠ficas no pr√≥ximo est√°gio.  Para entender o que √© uma estrutura sem√¢ntica, considere um exemplo simples, que o Google cita com mais frequ√™ncia.  Temos um pedido simples: "Por favor, toque uma m√∫sica de algum artista". <br><br><img src="https://habrastorage.org/webt/nf/an/6l/nfan6l3vzzjsl_r4iq9_3x491rk.png"><br><br>  O dom√≠nio e o assunto nesta solicita√ß√£o s√£o m√∫sica;  inten√ß√£o - tocar uma m√∫sica;  atributos do cart√£o "tocar uma m√∫sica" - que tipo de m√∫sica, que tipo de artista.  Essa estrutura √© o resultado da compreens√£o de uma linguagem natural. <br><br>  Se falamos em resolver um problema complexo e de v√°rios est√°gios para entender o discurso coloquial, ent√£o, como eu disse, ele consiste em dois est√°gios: o primeiro √© o reconhecimento de fala, o segundo √© o entendimento da linguagem natural.  A abordagem cl√°ssica envolve uma separa√ß√£o completa desses est√°gios.  Como primeiro passo, temos um determinado modelo que recebe um sinal ac√∫stico na entrada e na sa√≠da, usando linguagem e modelos ac√∫sticos e um l√©xico, determina a hip√≥tese verbal mais prov√°vel desse sinal ac√∫stico.  Esta √© uma hist√≥ria completamente probabil√≠stica - pode ser decomposta de acordo com a conhecida f√≥rmula de Bayes e obter uma f√≥rmula que permita escrever a fun√ß√£o de probabilidade da amostra e usar o m√©todo de m√°xima verossimilhan√ßa.  Temos uma probabilidade condicional do sinal X, desde que a sequ√™ncia de palavras W seja multiplicada pela probabilidade dessa sequ√™ncia de palavras. <br><br><img src="https://habrastorage.org/webt/u0/pz/y8/u0pzy8cvkx_texgnjfzun-keavu.png"><br><br>  A primeira etapa pela qual passamos - obtemos uma hip√≥tese verbal a partir do sinal sonoro.  Em seguida, vem o segundo componente, que pega essa hip√≥tese muito verbal e tenta extrair a estrutura sem√¢ntica descrita acima. <br><br>  Temos a probabilidade da estrutura sem√¢ntica S, desde que a sequ√™ncia verbal W esteja na entrada. <br><br><img src="https://habrastorage.org/webt/yi/34/tx/yi34txzqvgevrvoauj4stho32im.png"><br><br>  Qual √© a coisa ruim da abordagem cl√°ssica, consistindo desses dois elementos / etapas, ensinados separadamente (ou seja, primeiro treinamos o modelo do primeiro elemento e depois o modelo do segundo)? <br><br><ul><li>  O componente de compreens√£o da linguagem natural trabalha com as hip√≥teses verbais de alto n√≠vel que o ASR gera.  Esse √© um grande problema, porque o primeiro componente (o pr√≥prio ASR) trabalha com dados brutos de baixo n√≠vel e gera uma hip√≥tese verbal de alto n√≠vel, e o segundo componente toma a hip√≥tese como entrada - n√£o os dados brutos da fonte prim√°ria, mas a hip√≥tese que o primeiro modelo fornece - e constr√≥i sua hip√≥tese sobre a hip√≥tese do primeiro est√°gio.  Esta √© uma hist√≥ria bastante problem√°tica, porque se torna "condicional" demais. </li><li>  O pr√≥ximo problema: n√£o podemos estabelecer nenhuma conex√£o entre a import√¢ncia das palavras necess√°rias para construir a pr√≥pria estrutura sem√¢ntica e o que o primeiro componente prefere ao construir nossa hip√≥tese verbal.  Ou seja, se voc√™ reformular, entendemos que a hip√≥tese j√° foi constru√≠da.  √â constru√≠do com base em tr√™s componentes, como eu disse: a parte ac√∫stica (a que entrou na entrada e √© de alguma forma modelada), a parte da linguagem (modela completamente qualquer engraxamento da linguagem - a probabilidade de fala) e o l√©xico (pron√∫ncia das palavras).  Essas s√£o tr√™s grandes partes que precisam ser combinadas e algumas hip√≥teses encontradas nelas.  Mas n√£o h√° como influenciar a escolha da mesma hip√≥tese, de modo que essa hip√≥tese seja importante para o pr√≥ximo est√°gio (que, em princ√≠pio, √© o ponto em que aprendem completamente separadamente e n√£o se afetam de maneira alguma). </li></ul><br><h4>  Abordagem End2End </h4><br>  Entendemos qual √© a abordagem cl√°ssica, que problemas ela tem.  Vamos tentar resolver esses problemas usando a abordagem End2End. <br><br>  Por End2End, queremos dizer um modelo que combinar√° os v√°rios componentes em um √∫nico componente.  Modelaremos usando modelos que consistem na arquitetura codificador-decodificador contendo m√≥dulos de aten√ß√£o (aten√ß√£o).  Tais arquiteturas s√£o frequentemente usadas em problemas de reconhecimento de fala e em tarefas relacionadas ao processamento de uma linguagem natural, em particular a tradu√ß√£o autom√°tica. <br><br>  Existem quatro op√ß√µes para a implementa√ß√£o de tais abordagens que poderiam resolver o problema colocado √† nossa frente pela abordagem cl√°ssica: s√£o modelos diretos, colaborativos, de v√°rios est√°gios e multitarefas. <br><br><h4>  Modelo direto </h4><br>  O modelo direto assume os atributos brutos de baixo n√≠vel de entrada, ou seja,  sinal de √°udio de baixo n√≠vel e, na sa√≠da, obtemos imediatamente uma estrutura sem√¢ntica.  Ou seja, obtemos um m√≥dulo - a entrada do primeiro m√≥dulo da abordagem cl√°ssica e a sa√≠da do segundo m√≥dulo da mesma abordagem cl√°ssica.  Apenas uma "caixa preta".  A partir daqui, existem algumas vantagens e desvantagens.  O modelo n√£o aprende a transcrever completamente o sinal de entrada - essa √© uma vantagem clara, porque n√£o precisamos coletar marca√ß√µes grandes e grandes, n√£o precisamos coletar muito sinal de √°udio e depois transmiti-lo aos acessadores para marca√ß√£o.  N√≥s apenas precisamos deste sinal de √°udio e da estrutura sem√¢ntica correspondente.  E isso √© tudo.  Isso muitas vezes reduz o trabalho envolvido na marca√ß√£o de dados.  Provavelmente, o maior ponto negativo dessa abordagem √© que a tarefa √© muito complicada para uma "caixa preta", que est√° tentando resolver imediatamente, condicionalmente, dois problemas.  Primeiro, dentro de si, ele tenta construir algum tipo de transcri√ß√£o e, a partir dessa transcri√ß√£o, revela a pr√≥pria estrutura sem√¢ntica.  Isso levanta uma tarefa bastante dif√≠cil - aprender a ignorar partes da transcri√ß√£o.  E √© muito dif√≠cil.  Esse fator √© um sinal menos amplo e colossal dessa abordagem. <br><br>  Se falamos de probabilidades, esse modelo resolve o problema de encontrar a estrutura sem√¢ntica mais prov√°vel S a partir do sinal ac√∫stico X com os par√¢metros do modelo Œ∏. <br><br><img src="https://habrastorage.org/webt/34/kl/m2/34klm26dj3vk5sd9kdcxckkenii.png"><br><br><h4>  Modelo comum </h4><br>  Qual √© a alternativa?  Este √© um modelo colaborativo.  Ou seja, algum modelo √© muito semelhante a uma linha reta, mas com uma exce√ß√£o: a sa√≠da para n√≥s j√° consiste em sequ√™ncias verbais e uma estrutura sem√¢ntica √© simplesmente concatenada para eles.  Ou seja, na entrada temos um sinal sonoro e um modelo de rede neural, que na sa√≠da j√° fornece transcri√ß√£o verbal e estrutura sem√¢ntica. <br><br><img src="https://habrastorage.org/webt/jz/kn/-f/jzkn-frploycnewpluip2kgoqb8.png"><br><br>  Dos profissionais: ainda temos um codificador simples, um decodificador simples.  O aprendizado √© facilitado porque o modelo n√£o tenta resolver dois problemas ao mesmo tempo, como no caso do modelo direto.  Mais uma vantagem √© que essa depend√™ncia da estrutura sem√¢ntica em atributos sonoros de baixo n√≠vel ainda est√° presente.  Porque, novamente, um codificador, um decodificador.  E, consequentemente, uma das vantagens pode-se notar que existe uma depend√™ncia em prever essa estrutura sem√¢ntica e sua influ√™ncia diretamente na pr√≥pria transcri√ß√£o - o que n√£o nos convinha na abordagem cl√°ssica. <br><br>  Novamente, precisamos encontrar a sequ√™ncia mais prov√°vel de palavras W e as estruturas sem√¢nticas correspondentes S do sinal ac√∫stico X com os par√¢metros Œ∏. <br><br><h4>  Modelo multitarefa </h4><br>  A pr√≥xima abordagem √© um modelo multitarefa.  Novamente, a abordagem codificador-decodificador, mas com uma exce√ß√£o. <br><br><img src="https://habrastorage.org/webt/ym/kz/l3/ymkzl3t_nh892ohttlu84sjg98i.png"><br><br>  Para cada tarefa, ou seja, criar uma sequ√™ncia verbal, criar uma estrutura sem√¢ntica, temos nosso pr√≥prio decodificador que usa uma representa√ß√£o oculta comum que gera um √∫nico codificador.  Um truque muito famoso no aprendizado de m√°quina, muito usado no trabalho.  Resolver dois problemas diferentes ao mesmo tempo ajuda a procurar depend√™ncias nos dados de origem muito melhor.  E como consequ√™ncia disso - a melhor capacidade de generaliza√ß√£o, pois o par√¢metro ideal √© selecionado para v√°rias tarefas ao mesmo tempo.  Essa abordagem √© mais adequada para tarefas com menos dados.  E os decodificadores usam um espa√ßo vetorial oculto no qual seu codificador cria. <br><br><img src="https://habrastorage.org/webt/8l/-q/pj/8l-qpjo3dccdzmqh5a-fspmveiq.png"><br><br>  √â importante notar que j√° em probabilidade existe uma depend√™ncia dos par√¢metros dos modelos de codificador e decodificador.  E esses par√¢metros s√£o importantes. <br><br><h4>  Modelo multiest√°gio </h4><br>  Na minha opini√£o, passamos √† abordagem mais interessante: um modelo de v√°rios est√°gios.  Se voc√™ observar com muito cuidado, poder√° ver que, de fato, esta √© a mesma abordagem cl√°ssica de dois componentes, com uma exce√ß√£o. <br><br><img src="https://habrastorage.org/webt/fr/az/np/fraznpocvjmklcjjmau4i9v9ago.png"><br><br>  Aqui √© poss√≠vel estabelecer uma conex√£o entre os m√≥dulos e torn√°-los monom√≥dulos.  Portanto, a estrutura sem√¢ntica √© considerada condicionalmente dependente da transcri√ß√£o.  Existem duas op√ß√µes para trabalhar com este modelo.  Podemos treinar individualmente esses dois mini-blocos: o primeiro e o segundo codificador-decodificador.  Ou combine-os e treine as duas tarefas ao mesmo tempo. <br><br>  No primeiro caso, os par√¢metros para as duas tarefas n√£o est√£o relacionados (podemos treinar usando dados diferentes).  Suponha que tenhamos um grande corpo sonoro e as sequ√™ncias e transcri√ß√µes verbais correspondentes.  N√≥s os "dirigimos", treinamos apenas a primeira parte.  Temos uma boa simula√ß√£o de transcri√ß√£o.  Ent√£o pegamos a segunda parte, treinamos em outro caso.  Conectamos e obtemos uma solu√ß√£o que nessa abordagem √© 100% consistente com a abordagem cl√°ssica, porque escolhemos e treinamos separadamente a primeira parte e separadamente a segunda.  E ent√£o treinamos o modelo conectado no caso, que j√° cont√©m tr√≠ades de dados: um sinal de √°udio, a transcri√ß√£o correspondente e a estrutura sem√¢ntica correspondente.  Se tivermos um edif√≠cio assim, podemos treinar novamente o modelo, treinado individualmente em grandes edif√≠cios, para nossa pequena tarefa espec√≠fica e obter o m√°ximo ganho de precis√£o de uma maneira t√£o complicada.  Essa abordagem nos permite levar em considera√ß√£o a import√¢ncia de diferentes partes da transcri√ß√£o e sua influ√™ncia na previs√£o da estrutura sem√¢ntica, <i>levando em considera√ß√£o os erros do</i> segundo est√°gio no primeiro. <br><br>  √â importante notar que a tarefa final √© muito semelhante √† abordagem cl√°ssica, com apenas uma grande diferen√ßa: o segundo termo de nossa fun√ß√£o - o logaritmo da probabilidade da estrutura sem√¢ntica - desde que o sinal ac√∫stico de entrada X tamb√©m dependa dos par√¢metros do <i>modelo do primeiro est√°gio</i> . <br><br><img src="https://habrastorage.org/webt/pa/24/xr/pa24xr-aaep-mqo7bzd3loksve4.png"><br><br>  Tamb√©m √© importante observar aqui que o segundo componente depende dos par√¢metros do primeiro e do segundo modelos. <br><br><h4>  Metodologia para avaliar a precis√£o das abordagens </h4><br>  Agora vale a pena decidir sobre a metodologia para avaliar a precis√£o.  Como, de fato, medir essa precis√£o, a fim de levar em considera√ß√£o caracter√≠sticas que n√£o nos conv√™m na abordagem cl√°ssica?  Existem r√≥tulos cl√°ssicos para essas tarefas separadas.  Para avaliar os componentes de reconhecimento de fala, podemos usar a m√©trica cl√°ssica do WER.  Esta √© uma taxa de erro do Word.  Consideramos, de acordo com uma f√≥rmula n√£o muito complicada, o n√∫mero de inser√ß√µes, substitui√ß√µes, permuta√ß√µes da palavra e as dividimos pelo n√∫mero de todas as palavras.  E temos uma certa caracter√≠stica estimada da qualidade do nosso reconhecimento.  Para uma estrutura sem√¢ntica, componente a componente, podemos simplesmente considerar a pontua√ß√£o F1.  Essa tamb√©m √© uma m√©trica cl√°ssica para o problema de classifica√ß√£o.  Aqui tudo √© mais ou menos claro.  H√° plenitude, h√° precis√£o.  E isso √© apenas um meio harm√¥nico entre eles. <br><br>  Mas surge a quest√£o de como medir a precis√£o quando a transcri√ß√£o de entrada e o argumento de sa√≠da n√£o coincidem ou quando a sa√≠da √© de dados de √°udio.  O Google prop√¥s uma m√©trica que levar√° em conta a import√¢ncia de prever o primeiro componente do reconhecimento de fala, avaliando o efeito desse reconhecimento no pr√≥prio segundo componente.  Eles o chamavam de Arg WER, ou seja, pesa WER sobre as entidades da estrutura sem√¢ntica. <br><br>  Aceite o pedido: "Defina o alarme por 5 horas".  Essa estrutura sem√¢ntica cont√©m um argumento como "cinco horas", um argumento do tipo "data e hora".  √â importante entender que, se o componente de reconhecimento de fala produzir esse argumento, a m√©trica de erro desse argumento, ou seja, WER, ser√° 0%.  Se esse valor n√£o corresponder a cinco horas, a m√©trica ter√° 100% de WER.  Portanto, simplesmente consideramos o valor m√©dio ponderado de todos os argumentos e, em geral, obtemos uma certa m√©trica agregada que estima a import√¢ncia dos erros de transcri√ß√£o que criam o componente de reconhecimento de fala. <br><br>  Deixe-me dar um exemplo das experi√™ncias do Google que ele conduziu em um de seus estudos sobre este t√≥pico.  Eles usaram dados de cinco dom√≠nios, cinco assuntos: M√≠dia, Media_Control, Produtividade, Prazer, Nenhum - com a distribui√ß√£o correspondente de dados nos conjuntos de dados de teste de treinamento.  √â importante observar que todos os modelos foram treinados do zero.  Cross_entropy foi usado, o par√¢metro de busca do feixe foi 8, o otimizador que eles usaram, √© claro, Adam.  Considerado, √© claro, em uma grande nuvem de seu TPU.  Qual √© o resultado?  Estes s√£o n√∫meros interessantes: <br><br><img src="https://habrastorage.org/webt/cj/bb/of/cjbbofaddfuhufwqk3brhr2-l04.png"><br><br>  Para entender, a linha de base √© uma abordagem cl√°ssica que consiste em dois componentes, como dissemos no in√≠cio.  A seguir, s√£o apresentados exemplos de modelos diretos, conectados, multitarefa e de v√°rios est√°gios. <br><br>  Quanto custam dois modelos de v√°rios est√°gios?  Apenas na jun√ß√£o da primeira e segunda partes, diferentes camadas foram usadas.  No primeiro caso, √© ArgMax, no segundo caso, SampedSoftmax. <br><br>  No que vale a pena prestar aten√ß√£o?  A abordagem cl√°ssica perde nas tr√™s m√©tricas, que s√£o uma estimativa da colabora√ß√£o direta desses dois componentes.  Sim, n√£o estamos interessados ‚Äã‚Äãem qu√£o bem a transcri√ß√£o √© feita l√°, apenas em como o elemento que prediz a estrutura sem√¢ntica funciona.  Ele √© avaliado por tr√™s m√©tricas: F1 - por t√≥pico, F1 - por inten√ß√£o e m√©trica ArgWer, que √© considerada pelos argumentos das entidades.  F1 √© considerada uma m√©dia ponderada entre precis√£o e integridade.  Ou seja, o padr√£o √© 100. ArgWer, pelo contr√°rio, n√£o √© um sucesso, √© um erro, ou seja, aqui o padr√£o √© 0. <br><br>  Vale ressaltar que nossos modelos acoplados e multitarefas superam completamente todos os modelos de classifica√ß√£o para t√≥picos e inten√ß√µes.  E o modelo, que √© de v√°rios est√°gios, tem um aumento muito grande no ArgWer total.  Por que isso √© importante?  Como nas tarefas associadas √† compreens√£o do discurso coloquial, a a√ß√£o final que ser√° executada no componente respons√°vel pela l√≥gica de neg√≥cios √© importante.  N√£o depende diretamente das transcri√ß√µes criadas pelo ASR, mas da qualidade dos componentes ASR e NLU trabalhando juntos.  Portanto, uma diferen√ßa de quase tr√™s pontos na m√©trica argWER √© um indicador muito interessante, que indica o sucesso dessa abordagem.  Tamb√©m √© importante notar que todas as abordagens t√™m valores compar√°veis ‚Äã‚Äãpor defini√ß√£o de t√≥picos e inten√ß√µes. <br><br>  Vou dar alguns exemplos do uso de tais algoritmos para entender o discurso conversacional.  O Google, ao falar sobre as tarefas de entender a fala conversacional, observa principalmente as interfaces homem-computador, ou seja, todos os tipos de assistentes virtuais, como o Google Assistant, o Apple Siri, o Amazon Alexa e assim por diante.  Como segundo exemplo, vale mencionar um pool de tarefas como o Interactive Voice Response.  Ou seja, esta √© uma hist√≥ria que est√° envolvida na automa√ß√£o de call centers. <br><br>  Portanto, examinamos as abordagens com a possibilidade de usar a otimiza√ß√£o conjunta, o que ajuda o modelo a se concentrar nos erros mais importantes para as SLUs.  Essa abordagem da tarefa de entender o idioma falado simplifica bastante a complexidade geral. <br><br>  Temos a oportunidade de fazer uma conclus√£o l√≥gica, ou seja, obter algum tipo de resultado, sem a necessidade de recursos adicionais como o l√©xico, modelos de linguagem, analisadores e assim por diante (ou seja, todos esses s√£o fatores inerentes √† abordagem cl√°ssica).  A tarefa √© resolvida "diretamente". <br><br>  Na verdade, voc√™ n√£o pode parar por a√≠.  E se agora combinamos as duas abordagens, os dois componentes de uma estrutura comum, podemos procurar mais.  Combine os tr√™s componentes e os quatro - apenas continue a combinar essa cadeia l√≥gica e "repasse" a import√¢ncia dos erros para um n√≠vel mais baixo, dada a criticidade j√° existente.  Isso nos permitir√° aumentar a precis√£o da solu√ß√£o do problema. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt451008/">https://habr.com/ru/post/pt451008/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt450996/index.html">Estruturas de jogos: tend√™ncias do JavaScript em 2019</a></li>
<li><a href="../pt450998/index.html">Uma breve hist√≥ria da texturiza√ß√£o 3D em jogos</a></li>
<li><a href="../pt451002/index.html">Conjunto de computador personalizado, parte 1</a></li>
<li><a href="../pt451004/index.html">Tecnosfera. Curso de palestra ‚ÄúGerenciamento de projetos e produtos de TI‚Äù</a></li>
<li><a href="../pt451006/index.html">Resumo de eventos para profissionais de RH na √°rea de TI de maio de 2019</a></li>
<li><a href="../pt451010/index.html">Oh c√°ustico e n√£o muito</a></li>
<li><a href="../pt451012/index.html">Permuta√ß√µes aleat√≥rias e parti√ß√µes aleat√≥rias</a></li>
<li><a href="../pt451014/index.html">Pressa, vontade ou avan√ßo? Contamos toda a verdade sobre a maior hackathon do pa√≠s</a></li>
<li><a href="../pt451018/index.html">V√° l√° - n√£o sei onde</a></li>
<li><a href="../pt451020/index.html">A hist√≥ria de uma otimiza√ß√£o do MySQL</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
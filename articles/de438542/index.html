<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìç üçß üï¥üèø Wie wir einen Empfehlungsdienst f√ºr die Auswahl von Kleidung in neuronalen Netzen erstellt haben üòá üåñ ü§≤üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In diesem Artikel m√∂chte ich dar√ºber sprechen, wie wir aus Fotos ein Suchsystem f√ºr √§hnliche Kleidung (genauer Kleidung, Schuhe und Taschen) erstellt ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir einen Empfehlungsdienst f√ºr die Auswahl von Kleidung in neuronalen Netzen erstellt haben</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438542/"><img src="https://habrastorage.org/webt/bh/ne/uw/bhneuwiip47lykb6jg-yigfnk3o.png" alt="Bild"><br><br>  In diesem Artikel m√∂chte ich dar√ºber sprechen, wie wir aus Fotos ein Suchsystem f√ºr √§hnliche Kleidung (genauer Kleidung, Schuhe und Taschen) erstellt haben.  Das ist in gesch√§ftlicher Hinsicht ein Empfehlungsdienst, der auf neuronalen Netzen basiert. <br><br>  Wie bei den meisten modernen IT-L√∂sungen k√∂nnen wir die Entwicklung unseres Systems mit der Lego-Konstruktorbaugruppe vergleichen, wenn wir viele kleine Details und Anweisungen verwenden und daraus ein fertiges Modell erstellen.  Hier ist eine solche Anweisung: Welche Details zu beachten sind und wie sie anzuwenden sind, damit Ihre GPU √§hnliche Produkte aus einem Foto ausw√§hlen kann, finden Sie in diesem Artikel. <br><br>  Aus welchen Teilen besteht unser System: <br><br><ul><li>  Detektor und Klassifikator von Kleidung, Schuhen und Taschen auf Bildern; </li><li>  Crawler, Indexer oder Modul f√ºr die Arbeit mit elektronischen Katalogen von Gesch√§ften; </li><li>  √§hnliches Bildsuchmodul; </li><li>  JSON-API f√ºr die bequeme Interaktion mit jedem Ger√§t und Dienst; </li><li>  Weboberfl√§che oder mobile Anwendung, um die Ergebnisse anzuzeigen. </li></ul><br>  Am Ende des Artikels werden wir alle ‚ÄûRechen‚Äú beschreiben, auf die wir w√§hrend der Entwicklung getreten sind, und Empfehlungen, wie wir sie neutralisieren k√∂nnen. <br><br><h3>  Erkl√§rung des Problems und Erstellung des Rubrikators </h3><br>  Die Aufgabe und der Hauptanwendungsfall des Systems klingen recht einfach und klar: <br><br><ul><li>  Der Benutzer legt dem Eingang (z. B. √ºber eine mobile Anwendung) ein Foto vor, auf dem sich Kleidungsst√ºcke und / oder Taschen und / oder Schuhe befinden. </li><li>  das System bestimmt (erkennt) alle diese Objekte; </li><li>  findet f√ºr jeden von ihnen die √§hnlichsten (relevanten) Produkte in echten Online-Shops; </li><li>  bietet dem Benutzer Produkte die M√∂glichkeit, zum Kauf auf eine bestimmte Produktseite zuzugreifen. </li></ul><br>  Einfach ausgedr√ºckt, das Ziel unseres Systems ist es, die ber√ºhmte Frage zu beantworten: "Und Sie haben nicht das gleiche, nur mit Perlmuttkn√∂pfen?" <br><a name="habracut"></a><br>  Bevor Sie in den Pool der Codierung, Markierung und des Trainings neuronaler Netze einsteigen, m√ºssen Sie die Kategorien, die sich in Ihrem System befinden, dh die Kategorien, die das neuronale Netz erkennt, ganz klar bestimmen.  Es ist wichtig zu verstehen, dass die Liste der Kategorien umso universeller ist, je breiter und detaillierter sie ist, da eine gro√üe Anzahl schmaler kleiner Kategorien wie Minikleid, Midikleid und Maxikleid immer mit einem Tastendruck zu einer Kategorie von Kleidungsst√ºcken kombiniert werden kann ABER NICHT umgekehrt.  Mit anderen Worten, der Rubrikator muss zu Beginn des Projekts gut durchdacht und kompiliert werden, damit die gleiche Arbeit nicht dreimal wiederholt wird.  Wir haben den Rubrikator auf der Grundlage mehrerer gro√üer Gesch√§fte wie Lamoda.ru und Amazon.com zusammengestellt und versucht, ihn einerseits so breit wie m√∂glich und andererseits so vielseitig wie m√∂glich zu gestalten, um die Zuordnung von Detektorkategorien zu verschiedenen Kategorien in Zukunft zu vereinfachen Online-Shops (Ich werde Ihnen im Abschnitt "Crawler und Indexer" mehr dar√ºber erz√§hlen, wie Sie diese Gruppe erstellen k√∂nnen.)  Hier ist ein Beispiel daf√ºr, was passiert ist. <br><br><img src="https://habrastorage.org/webt/bg/ku/zq/bgkuzqn0q-wovsd8x8aq7hlwlio.png" alt="Bild"><br>  <i>Beispielkategorien</i> <br><br>  In unserem Katalog gibt es derzeit nur 205 Kategorien: Damenbekleidung, Herrenbekleidung, Damenschuhe, Herrenschuhe, Taschen, Kleidung f√ºr Neugeborene.  Die Vollversion unseres Klassifikators finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unter dem Link</a> . <br><br><h3>  Indexer oder Modul zum Arbeiten mit elektronischen Filialkatalogen </h3><br>  Um in Zukunft nach √§hnlichen Produkten suchen zu k√∂nnen, m√ºssen wir eine umfassende Basis f√ºr das schaffen, wonach wir suchen werden.  Nach unserer Erfahrung h√§ngt die Qualit√§t der Suche nach √§hnlichen Bildern direkt von der Gr√∂√üe der Suchbasis ab, die mindestens 100.000 Bilder und vorzugsweise 1 Million Bilder √ºberschreiten sollte.  Wenn Sie der Datenbank 1-2 kleine Online-Shops hinzuf√ºgen, erhalten Sie h√∂chstwahrscheinlich keine beeindruckenden Ergebnisse, nur weil in 80% der F√§lle nichts wirklich dem gew√ºnschten Artikel in Ihrem Katalog √§hnlich ist. <br><br>  Um eine gro√üe Datenbank mit Bildern zu erstellen, die Sie zum Verarbeiten von Katalogen verschiedener Online-Shops ben√∂tigen, umfasst dieser Prozess Folgendes: <br><br><ul><li>  Zuerst m√ºssen Sie die XML-Feeds von Online-Shops finden. Sie k√∂nnen sie normalerweise entweder frei im Internet oder auf Anfrage im Store selbst oder in verschiedenen Aggregatoren wie Admitad finden. </li><li>  Der Feed wird von einem speziellen Programm verarbeitet (analysiert). Ein Crawler, der alle Bilder aus dem Feed herunterl√§dt, auf die Festplatte legt (genauer gesagt auf den Netzwerkspeicher, mit dem Ihr Server verbunden ist), schreibt alle Metainformationen zu den Waren in die Datenbank. </li><li>  Dann wird ein anderer Prozess gestartet - der Indexer, der bin√§re 128-dimensionale Merkmalsvektoren f√ºr jedes Bild berechnet.  Sie k√∂nnen den Crawler und den Indexer in einem Modul oder Programm kombinieren, aber wir haben in der Vergangenheit festgestellt, dass dies unterschiedliche Prozesse waren.  Dies war haupts√§chlich auf die Tatsache zur√ºckzuf√ºhren, dass wir zun√§chst Deskriptoren (Hashes) f√ºr jedes Bild berechnet haben, das auf einer gro√üen Flotte von Maschinen verteilt ist, da dies ein sehr ressourcenintensiver Prozess war.  Wenn Sie nur mit neuronalen Netzen arbeiten, reicht Ihnen der erste Computer mit einer GPU. </li><li>  Bin√§rvektoren werden in die Datenbank geschrieben, alle Prozesse sind abgeschlossen und voila - Ihre Produktdatenbank ist bereit f√ºr die weitere Suche; </li><li>  Ein kleiner Trick bleibt jedoch bestehen: Da alle Gesch√§fte unterschiedliche Kataloge mit unterschiedlichen Kategorien enthalten, m√ºssen Sie die Kategorien aller in Ihrer Datenbank enthaltenen Feeds mit den Kategorien des Detektors (genauer gesagt des Klassifikators) von Waren vergleichen. Wir nennen dies den Prozess der Zuordnung.  Dies ist eine manuelle Routine, aber eine sehr n√ºtzliche Arbeit, bei der der Bediener beim manuellen Bearbeiten einer regul√§ren XML-Datei die Kategorien von Feeds in der Datenbank mit den Kategorien des Detektors vergleicht.  Hier ist das Ergebnis: </li></ul><br><img src="https://habrastorage.org/webt/wb/je/hp/wbjehp3opuvabmnniuv8alvxwqm.png" alt="Bild"><br>  <i>Beispiel f√ºr eine Kategoriezuordnungsdatei: Katalogklassifizierer</i> <br><br><h3>  Erkennung und Klassifizierung </h3><br>  Um etwas zu finden, das dem √§hnelt, was unser Auge auf dem Foto gefunden hat, m√ºssen wir zuerst dieses ‚ÄûEtwas‚Äú erkennen (dh das Objekt lokalisieren und ausw√§hlen).  Wir haben einen langen Weg bei der Entwicklung eines Detektors zur√ºckgelegt, angefangen beim Training von OpenCV-Kaskaden, die f√ºr diese Aufgabe √ºberhaupt nicht <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">geeignet waren</a> , bis hin zur modernen Technologie zur Erkennung und Klassifizierung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">R-FCN</a> und dem Klassifikator basierend auf dem neuronalen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ResNet-</a> Netzwerk. <br><br>  Als Daten, die f√ºr Training und Test verwendet wurden (sogenannte Trainings- und Testmuster), haben wir alle Arten von Bildern aus dem Internet aufgenommen: <br><br><ul><li>  Suche in Google / Yandex-Bildern; </li><li>  von Dritten markierte Datens√§tze; </li><li>  soziale Netzwerke; </li><li>  Modemagazinseiten; </li><li>  Internet-Shops mit Kleidung, Schuhen, Taschen. </li></ul><br>  Das Markup wurde mit einem Samopisny-Tool durchgef√ºhrt. Das Ergebnis des Markups waren S√§tze von Bildern und * .seg-Dateien, in denen die Koordinaten von Objekten und Klassenbeschriftungen f√ºr sie gespeichert sind.  Im Durchschnitt wurden 100 bis 200 Bilder f√ºr jede Kategorie beschriftet, die Gesamtzahl der Bilder in 205 Klassen betrug 65.000. <br><br>  Nachdem die Schulungs- und Testmuster fertig sind, haben wir das Markup noch einmal √ºberpr√ºft und alle Bilder einem anderen Bediener √ºbergeben.  Dies erm√∂glichte es uns, eine gro√üe Anzahl von Fehlern herauszufiltern, die die Trainingsqualit√§t des neuronalen Netzwerks, dh des Detektors und des Klassifikators, stark beeinflussen.  Dann beginnen wir mit dem Training des neuronalen Netzwerks mit Standardwerkzeugen und "starten" den n√§chsten Schnappschuss des neuronalen Netzwerks "in der Hitze des Tages" in wenigen Tagen.  Im Durchschnitt betr√§gt die Trainingszeit des Detektors und Klassifikators f√ºr das Datenvolumen von 65.000 Bildern auf einer Titan X-GPU etwa 3 Tage. <br><br>  Ein vorgefertigtes neuronales Netzwerk muss irgendwie auf Qualit√§t √ºberpr√ºft werden, dh um zu bewerten, ob und um wie viel die aktuelle Version des Netzwerks besser als die vorherige geworden ist.  Wie wir es gemacht haben: <br><br><ul><li>  Die Testprobe bestand aus 12.000 Bildern und war genauso angelegt wie das Training. </li><li>  Wir haben ein kleines Tool geschrieben, das die gesamte Testprobe durch den Detektor lief und eine Tabelle dieser Art zusammenstellte (die Vollversion der Tabelle finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ). </li><li>  Diese Tabelle wird auf einer neuen Registerkarte zu Excel hinzugef√ºgt und manuell oder mithilfe der integrierten Excel-Formeln mit der vorherigen Tabelle verglichen. </li><li>  Am Ausgang erhalten wir die allgemeinen Indikatoren des TPR / FPR-Detektors und Klassifikators im gesamten System in und f√ºr jede Kategorie separat. </li></ul><br><img src="https://habrastorage.org/webt/vq/ou/it/vqouitv0rpqps36tme91uu5ynpw.png" alt="Bild"><br>  <i>Beispiel einer Berichtstabelle zur Qualit√§t des Detektors und Klassifikators</i> <br><br><h3>  Suchmodul f√ºr √§hnliche Bilder </h3><br>  Nachdem wir auf dem Foto Kleidungsst√ºcke entdeckt haben, starten wir die Suchmaschine f√ºr √§hnliche Bilder. So funktioniert es: <br><br><ul><li>  F√ºr alle ausgeschnittenen Bildfragmente (erkannte Waren) werden 128-Bit-Bin√§rmerkmalsvektoren des neuronalen Netzwerks in Form und Farbe berechnet (woher sie stammen, siehe unten). </li><li>  Die gleichen Vektoren, die zuvor in der Indizierungsphase f√ºr alle in der Datenbank gespeicherten Bilder von Waren berechnet wurden, sind bereits in den Computer-RAM geladen (da f√ºr die Suche nach √§hnlichen Vektoren eine gro√üe Anzahl von Suchen und paarweisen Vergleichen erforderlich ist, haben wir die gesamte Datenbank sofort in den Speicher geladen, wodurch wir uns vergr√∂√üern konnten Die Suchgeschwindigkeit ist dutzende Male, w√§hrend die Basis von etwa 100.000 Produkten in nicht mehr als 2-3 GB RAM passt. </li><li>  Suchkoeffizienten f√ºr diese Kategorie stammen von der Benutzeroberfl√§che oder von fest codierten Eigenschaften. Beispielsweise suchen wir in der Kategorie ‚ÄûKleid‚Äú mehr nach Farbe als nach Form (z. B. 8-zu-2-Farbformsuche) und in der Kategorie ‚ÄûSchuhe mit hohen Abs√§tzen‚Äú suchen wir 1-zu-1-Formfarbe, da hier sowohl Form als auch Farbe gleich wichtig sind; </li><li>  Ferner werden die Vektoren f√ºr die Ernte (Fragmente) aus dem Eingabebild paarweise mit dem Bild aus der Datenbank unter Ber√ºcksichtigung der Koeffizienten verglichen (der Hamming-Abstand zwischen den Vektoren wird verglichen). </li><li>  Infolgedessen wird f√ºr jedes Schnittproduktfragment ein Array √§hnlicher Produkte aus der Datenbank gebildet, und jedem Produkt wird ein Gewicht zugewiesen (gem√§√ü einer einfachen Formel unter Ber√ºcksichtigung der Normalisierung, so dass alle Gewichte im Bereich von 0 bis 1 liegen), um die M√∂glichkeit zur Ausgabe an die Schnittstelle sowie f√ºr weitere zu erhalten Sortieren; </li><li>  √úber die Web-JSON-API wird in der Benutzeroberfl√§che eine Reihe √§hnlicher Produkte angezeigt. </li></ul><br>  Neuronale Netze zur Bildung neuronaler Netzvektoren in Form und Farbe werden wie folgt trainiert. <br><br><ol><li>  Um das neuronale Netzwerk in Form zu trainieren, nehmen wir alle markierten Bilder, schneiden die Fragmente gem√§√ü dem Markup aus und verteilen sie entsprechend der Klasse in Ordnern: dh alle Pullover in einem Ordner, alle T-Shirts in einem anderen und alle hochhackigen Schuhe im dritten usw. d.  Als n√§chstes trainieren wir einen gew√∂hnlichen Klassifikator basierend auf diesem Beispiel.  Auf diese Weise ‚Äûerkl√§ren‚Äú wir dem neuronalen Netzwerk unser Verst√§ndnis der Form des Objekts. </li><li>  Um das neuronale Netzwerk in Farbe zu trainieren, nehmen wir alle markierten Bilder, schneiden die Fragmente gem√§√ü dem Markup aus und verteilen sie entsprechend der Farbe in Ordnern: Das hei√üt, wir legen alle T-Shirts, Schuhe, Taschen usw. in den ‚Äûgr√ºnen‚Äú Ordner.  gr√ºne Farbe (daher sammeln sich alle Objekte mit gr√ºner Farbe im Allgemeinen in einem Ordner an), im Ordner "gestrippt" legen wir alle Dinge in einen Streifen und im Ordner "rot-wei√ü" alle rot-wei√üen Dinge.  Als n√§chstes trainieren wir einen separaten Klassifikator f√ºr diese Klassen, als ob wir dem neuronalen Netzwerk sein Verst√§ndnis der Farbe einer Sache ‚Äûerkl√§ren‚Äú w√ºrden. </li></ol><br><img src="https://habrastorage.org/webt/b8/0-/qg/b80-qglyjgkpn6trfxxdm6b55gm.png" alt="Bild"><br>  <i>Ein Beispiel f√ºr das Markieren von Bildern nach Farbe, um neuronale Netzwerkvektoren von Zeichen nach Farbe zu erhalten.</i> <br><br>  Interessanterweise funktioniert eine solche Technologie auch auf komplexen Hintergr√ºnden gut, dh wenn Fragmente von Dingen nicht klar entlang der Kontur (Maske) ausgeschnitten werden, sondern entlang eines rechteckigen Rahmens, den der Marker definiert hat. <br><br>  Die Suche nach √§hnlichen basiert auf der Extraktion von bin√§ren Merkmalsvektoren aus dem neuronalen Netzwerk auf folgende Weise: Die Ausgabe der vorletzten Schicht wird genommen, komprimiert, normalisiert und bin√§risiert.  In unserer Arbeit haben wir auf einen 128-Bit-Vektor komprimiert.  Sie k√∂nnen dies beispielsweise etwas anders tun, wie in Yahoo-Artikel ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep Learning von bin√§ren Hash-Codes f√ºr das schnelle Abrufen</a> von Bildern‚Äú beschrieben. Die Essenz aller Algorithmen ist jedoch ungef√§hr gleich - Bilder, die dem Bild √§hnlich sind, werden durchsucht, indem die Eigenschaften verglichen werden, die das neuronale Netzwerk innerhalb der Ebenen arbeitet. <br><br>  Zun√§chst verwendeten wir als Technologie f√ºr die Suche nach √§hnlichen Bildern Hashes oder Bilddeskriptoren, die auf bestimmten mathematischen Algorithmen basieren (genauer berechnet), z. B. dem Sobel-Operator (oder Kontur-Hash), dem SIFT-Algorithmus (oder einzelnen Punkten), dem Zeichnen eines Histogramms oder dem Vergleichen der Anzahl der Winkel in einem Bild .  Diese Technologie hat funktioniert und zu mehr oder weniger vern√ºnftigen Ergebnissen gef√ºhrt, aber Hashes stehen in keinem Vergleich mit der Technologie zur Suche nach √§hnlichen Bildern basierend auf Eigenschaften, die von einem neuronalen Netzwerk zugewiesen wurden.  Wenn Sie versuchen, den Unterschied in zwei Worten zu erkl√§ren, ist der Hash-basierte Bildvergleichsalgorithmus ein ‚ÄûTaschenrechner‚Äú, der so konfiguriert ist, dass er Bilder mit einer Formel vergleicht und kontinuierlich funktioniert.  Ein Vergleich unter Verwendung von Merkmalen aus einem neuronalen Netzwerk ist ‚Äûk√ºnstliche Intelligenz‚Äú, die von einer Person trainiert wird, um ein bestimmtes Problem auf eine bestimmte Weise zu l√∂sen.  Sie k√∂nnen ein so grobes Beispiel geben: Wenn Sie nach Hash-Pullovern in schwarz-wei√üen Streifen suchen, werden Sie wahrscheinlich alle schwarz-wei√üen Dinge als √§hnliche finden.  Und wenn Sie √ºber ein neuronales Netzwerk suchen, dann: <br><br><ul><li>  an den ersten Stellen finden Sie alle Pullover mit schwarz-wei√üen Streifen, </li><li>  dann alle schwarz-wei√üen Pullover </li><li>  und dann alle gestreiften Pullover. </li></ul><br><h3>  JSON-API f√ºr die bequeme Interaktion mit jedem Ger√§t und Dienst </h3><br>  Wir haben eine einfache und bequeme WEB-JSON-API f√ºr die Kommunikation unseres Systems mit allen Ger√§ten und Systemen erstellt. Dies ist nat√ºrlich keine Innovation, sondern ein guter, starker Entwicklungsstandard. <br><br><h3>  Weboberfl√§che oder mobile Anwendung zum Anzeigen von Ergebnissen </h3><br>  Um die Ergebnisse visuell zu √ºberpr√ºfen und den Kunden das System zu demonstrieren, haben wir einfache Schnittstellen entwickelt: <br><br><ul><li>  Weboberfl√§che, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://demo.likethis.me/</a> </li><li>  mobile Anwendung ist <a href="">hier</a> verf√ºgbar </li></ul><br><h3>  Fehler, die im Projekt begangen wurden </h3><br><ul><li>  Zun√§chst ist es notwendig, die Aufgabe klarer zu definieren und basierend auf der Aufgabe Fotos f√ºr das Layout auszuw√§hlen.  Wenn Sie nach UGC-Fotos (User Generated Content) suchen m√ºssen, ist dies ein Fall und ein Beispiel f√ºr das Layout.  Wenn Sie eine Fotosuche aus Hochglanzmagazinen ben√∂tigen, ist dies ein anderer Fall. Wenn Sie eine Fotosuche ben√∂tigen, bei der sich ein gro√ües Objekt auf einem wei√üen Hintergrund befindet, handelt es sich um eine separate Geschichte und ein v√∂llig anderes Beispiel.  Wir haben alles in einem Stapel gemischt, was sich auf die Qualit√§t des Detektors und des Klassifikators auswirkte. </li><li>  Auf Fotos sollten Sie immer ALLE Objekte markieren, zumindest aufgrund der Tatsache, dass dies zumindest irgendwie zu Ihrer Aufgabe passt. Wenn Sie beispielsweise eine √§hnliche Auswahl an Kleidungsst√ºcken ausw√§hlen, m√ºssen Sie sofort alle Accessoires (Perlen, Brillen, Armb√§nder usw.) und den Kopf markieren H√ºte usw.  Da wir jetzt √ºber ein riesiges Trainingsset verf√ºgen, m√ºssen wir ALLE Fotos neu verteilen, um eine weitere Kategorie hinzuzuf√ºgen. Dies ist eine sehr umfangreiche Arbeit. </li><li>  Die Erkennung erfolgt h√∂chstwahrscheinlich am besten mit einem Maskennetzwerk. Der √úbergang zu Mask-CNN und einer modernen Detectron-basierten L√∂sung ist einer der Bereiche der Systementwicklung. </li><li>  Es w√§re sch√∂n, sofort zu entscheiden, wie Sie die Qualit√§t der Auswahl √§hnlicher Bilder bestimmen m√∂chten - es gibt zwei Methoden: "per Auge" und dies ist die einfachste und billigste Methode und die zweite - "wissenschaftliche" Methode, wenn Sie Daten von "Experten" (Personen,) sammeln. (Ich teste Ihren √§hnlichen Suchalgorithmus) und basierend auf diesen Daten ein Testmuster und einen Katalog speziell f√ºr die Suche nach √§hnlichen Bildern bilden.  Diese Methode ist theoretisch gut und sieht ziemlich √ºberzeugend aus (f√ºr Sie selbst und f√ºr Kunden), aber in der Praxis ist ihre Implementierung schwierig und ziemlich teuer. </li></ul><br><h3>  Fazit und Weiterentwicklungspl√§ne </h3><br>  Diese Technologie ist ziemlich fertig und einsatzbereit. Jetzt arbeitet sie bei einem unserer Kunden im Online-Shop als Empfehlungsservice.  Au√üerdem haben wir k√ºrzlich begonnen, ein √§hnliches System in einer anderen Branche zu entwickeln (das hei√üt, wir arbeiten jetzt mit anderen Arten von Waren). <br><br>  Aus sofortigen Pl√§nen: die √úbertragung des Netzwerks an Mask-CNN sowie das erneute Markieren und Markieren von Bildern, um die Qualit√§t des Detektors und des Klassifikators zu verbessern. <br><br>  Abschlie√üend m√∂chte ich sagen, dass nach unseren Gef√ºhlen eine √§hnliche Technologie und im Allgemeinen neuronale Netze bis zu 80% der komplexen und hochintellektuellen Aufgaben l√∂sen k√∂nnen, die unser Gehirn t√§glich erf√ºllt.  Die Frage ist nur, wer als erster eine solche Technologie implementiert und einen Menschen von der Routinearbeit entlastet, um ihm Raum f√ºr Kreativit√§t und Entwicklung zu geben, was unserer Meinung nach der h√∂chste Zweck des Menschen ist! <br><br><h3>  Referenzliste </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">R-FCN-Technologie</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ResNet Neuronales Netz</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Suchen Sie nach √§hnlichen Bildern mithilfe eines neuronalen Netzwerks</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de438542/">https://habr.com/ru/post/de438542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de438530/index.html">Hipster Podcasts # 1</a></li>
<li><a href="../de438534/index.html">Modbus auf dem russischen Mikrocontroller K1986BE92QI</a></li>
<li><a href="../de438536/index.html">Unter der Haube des Chatbots: Was RocketBot kann und wie es funktioniert</a></li>
<li><a href="../de438538/index.html">Teamlead Conf 2019 Msk: √ºber ein anderes Kommunikationsformat</a></li>
<li><a href="../de438540/index.html">Trends in der Dokumentenverwaltung und Datenspeicherung f√ºr 2019</a></li>
<li><a href="../de438544/index.html">Wir schauen zu Hause Filme: 10 Materialien √ºber den Bau eines Heimkinos und die Auswahl der Ausr√ºstung</a></li>
<li><a href="../de438546/index.html">Analyse von Modulbindungsans√§tzen in Node.js.</a></li>
<li><a href="../de438548/index.html">Lombok, sources.jar und praktisches Debuggen</a></li>
<li><a href="../de438550/index.html">Ein weiteres Manifest</a></li>
<li><a href="../de438554/index.html">Verwalten des Status und der Ereignisse zwischen Komponenten in GameObject</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
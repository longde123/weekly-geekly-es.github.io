<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛐 🎃 👻 Banyak karakter - banyak jaringan saraf: bagaimana membangun sistem pengenalan yang efektif untuk sejumlah besar kelas? 🔭 💧 🤛🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Di artikel sebelumnya, mereka sudah menulis tentang cara kerja teknologi pengenalan teks kami: 

 Series Navigator 

- Pengenalan teks dalam ABBYY Fin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Banyak karakter - banyak jaringan saraf: bagaimana membangun sistem pengenalan yang efektif untuk sejumlah besar kelas?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/438128/">  Di artikel sebelumnya, mereka sudah menulis tentang cara kerja teknologi pengenalan teks kami: <br><br><div class="spoiler">  <b class="spoiler_title">Series Navigator</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengenalan teks dalam ABBYY FineReader (1/2)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengenalan Teks di ABBYY FineReader (2/2)</a> </li></ul><br></div></div><br>  Hingga 2018, pengenalan karakter Jepang dan Cina diatur dengan cara yang sama: terutama menggunakan pengklasifikasi raster dan fitur.  Tetapi dengan pengakuan hieroglif ada kesulitan: <br><br><ol><li>  Sejumlah besar kelas yang perlu dibedakan. </li><li>  Karakter perangkat yang lebih kompleks secara keseluruhan. </li></ol><br><img src="https://habrastorage.org/webt/fy/p7/yu/fyp7yudyxpraxbdsegon8y7w_xa.png" alt="gambar"><br><br>  Sama sulitnya untuk mengatakan dengan pasti berapa banyak karakter yang ditulis dalam alfabet China, sebagaimana akurat untuk menghitung berapa banyak kata dalam bahasa Rusia.  Tetapi paling sering dalam tulisan China ~ 10.000 karakter digunakan.  Dengan mereka, kami membatasi jumlah kelas yang digunakan dalam pengakuan. <br><br>  Kedua masalah yang dijelaskan di atas juga mengarah pada fakta bahwa untuk mencapai kualitas tinggi Anda harus menggunakan sejumlah besar fitur dan fitur-fitur ini sendiri dihitung pada gambar karakter lebih lama. <br><br>  Agar masalah ini tidak menyebabkan perlambatan parah di seluruh sistem pengenalan, saya harus menggunakan banyak heuristik, terutama bertujuan untuk dengan cepat memotong sejumlah besar hieroglif, yang tidak terlihat seperti gambar ini.  Masih tidak membantu sampai akhir, tetapi kami ingin membawa teknologi kami ke tingkat yang sama sekali baru. <br><br>  Kami mulai mempelajari penerapan jaringan saraf convolutional untuk meningkatkan kualitas dan kecepatan pengakuan hieroglif.  Saya ingin mengganti seluruh unit karena mengenali satu karakter untuk bahasa-bahasa ini dengan bantuan jaringan saraf.  Dalam artikel ini, kami akan menjelaskan bagaimana kami akhirnya berhasil. <br><a name="habracut"></a><br><h2>  Pendekatan sederhana: satu jaringan konvolusi untuk mengenali semua hieroglif </h2><br>  Secara umum, penggunaan jaringan konvolusional untuk pengenalan karakter bukanlah ide baru sama sekali.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Secara historis, mereka digunakan</a> untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pertama kalinya</a> tepatnya untuk tugas ini pada tahun 1998.  Benar, maka ini bukan karakter yang dicetak, tetapi huruf dan angka bahasa Inggris tulisan tangan. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yg/fi/se/ygfisegze1bli8r9nyakftguapu.png"></div><br><br>  Lebih dari 20 tahun, teknologi di bidang pembelajaran yang dalam, tentu saja, telah melompat maju.  Termasuk arsitektur yang lebih maju dan pendekatan baru untuk belajar. <br><br>  Arsitektur yang disajikan dalam diagram di atas (LeNet), pada kenyataannya, dan hari ini sangat cocok untuk tugas-tugas sederhana seperti pengenalan teks cetak.  "Sederhana" Saya menyebutnya dibandingkan dengan tugas-tugas lain dari visi komputer seperti pencarian dan pengenalan wajah. <br><br>  Tampaknya solusinya tidak ada yang lebih sederhana.  Kami mengambil jaringan saraf, contoh hieroglif berlabel dan melatihnya untuk masalah klasifikasi.  Sayangnya, ternyata semuanya tidak begitu sederhana.  Semua kemungkinan modifikasi LeNet untuk tugas mengklasifikasikan 10.000 hieroglif tidak memberikan kualitas yang memadai (setidaknya sebanding dengan sistem pengakuan yang sudah kita miliki). <br><br>  Untuk mencapai kualitas yang diperlukan, kami harus mempertimbangkan arsitektur yang lebih dalam dan lebih kompleks: WideResNet, SqueezeNet, dll.  Dengan bantuan mereka, dimungkinkan untuk mencapai tingkat kualitas yang diperlukan, tetapi mereka memberikan penurunan kecepatan yang kuat - 3-5 kali dibandingkan dengan algoritma dasar pada CPU. <br><br>  Seseorang mungkin bertanya: "Apa gunanya mengukur kecepatan jaringan pada CPU, jika bekerja lebih cepat pada prosesor grafis (GPU)"?  Di sini perlu dibuat komentar mengenai fakta bahwa kecepatan algoritma pada CPU terutama penting bagi kita.  Kami sedang mengembangkan teknologi untuk lini besar produk pengenalan ABBYY.  Dalam sejumlah skenario terbesar, pengakuan dilakukan di sisi klien, dan kita tidak bisa tahu bahwa itu memiliki GPU. <br><br>  Jadi, pada akhirnya, kami sampai pada masalah berikut: satu jaringan saraf untuk mengenali semua karakter tergantung pada pilihan karya arsitektur yang terlalu buruk atau terlalu lambat. <br><br><h2>  Model pengenalan hieroglif jaringan saraf dua tingkat </h2><br>  Saya harus mencari cara lain.  Pada saat yang sama, saya tidak ingin meninggalkan jaringan saraf.  Tampaknya masalah terbesar adalah sejumlah besar kelas, karena itu diperlukan untuk membangun jaringan arsitektur yang kompleks.  Oleh karena itu, kami memutuskan bahwa kami tidak akan melatih jaringan untuk sejumlah besar kelas, yaitu untuk seluruh alfabet, tetapi sebaliknya kami akan melatih banyak jaringan untuk sejumlah kecil kelas (himpunan bagian dari alfabet). <br><br>  Secara umum, sistem yang ideal disajikan sebagai berikut: alfabet dibagi menjadi kelompok-kelompok dengan karakter yang sama.  Jaringan tingkat pertama mengklasifikasikan grup karakter mana yang diberikan gambar.  Untuk setiap kelompok, pada gilirannya, jaringan tingkat kedua dilatih, yang menghasilkan klasifikasi akhir dalam setiap kelompok. <br><br>  <i>Gambar yang dapat diklik</i> <br> <a href=""><img src="https://habrastorage.org/webt/lg/r9/a1/lgr9a1ibz_vktq5xvkzqquawd7k.png"></a> <br><br>  Jadi, kami membuat klasifikasi akhir dengan meluncurkan dua jaringan: yang pertama menentukan jaringan tingkat kedua mana yang akan diluncurkan, dan yang kedua sudah membuat klasifikasi akhir. <br><br>  Sebenarnya, poin mendasar di sini adalah bagaimana membagi karakter ke dalam kelompok-kelompok sehingga jaringan tingkat pertama dapat dibuat akurat dan cepat. <br><br><h2>  Membangun classifier tingkat pertama </h2><br>  Untuk memahami simbol jaringan mana yang lebih mudah dibedakan dan mana yang lebih sulit, paling mudah untuk melihat tanda apa yang menonjol untuk simbol tertentu.  Untuk melakukan ini, kami mengambil jaringan classifier dilatih untuk membedakan semua karakter alfabet dengan kualitas yang baik dan melihat statistik aktivasi lapisan kedua dari belakang jaringan ini - kami mulai melihat representasi fitur akhir yang diterima jaringan untuk semua karakter. <br><br>  Pada saat yang sama, kami tahu bahwa gambar harus ada sesuatu seperti berikut ini: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sr/bw/el/srbwele_woukv5qioz-qr6vdq6g.png"></div><br><br>  Ini adalah contoh sederhana untuk kasus pengelompokan pilihan digit tulisan tangan (MNIST) ke dalam 10 kelas.  Pada lapisan tersembunyi kedua dari belakang, yang berjalan sebelum klasifikasi, hanya ada 2 neuron, yang membuat statistik aktivasi mereka mudah untuk ditampilkan di pesawat.  Setiap titik pada grafik sesuai dengan beberapa contoh dari sampel uji.  Warna titik sesuai dengan kelas tertentu. <br><br>  Dalam kasus kami, dimensi ruang fitur lebih besar dari 128 dalam contoh. Kami menjalankan sekelompok gambar dari sampel uji dan menerima vektor fitur untuk setiap gambar.  Setelah itu, mereka dinormalisasi (dibagi panjangnya).  Dari gambar di atas jelas mengapa ini layak dilakukan.  Kami mengelompokkan vektor yang dinormalisasi dengan metode KMeans.  Kami mendapat pengelompokan sampel ke dalam kelompok gambar yang serupa (dari sudut pandang jaringan). <br><br>  Tetapi pada akhirnya, kami perlu membuat partisi alfabet ke dalam kelompok, dan bukan partisi dari sampel uji.  Tetapi yang pertama dari yang kedua tidak sulit diperoleh: cukup untuk menetapkan setiap label kelas ke kluster yang berisi sebagian besar gambar kelas ini.  Dalam kebanyakan situasi, tentu saja, seluruh kelas bahkan akan berakhir di dalam satu cluster. <br><br>  Yah, itu saja, kami mendapat partisi dari seluruh alfabet menjadi kelompok-kelompok karakter yang sama.  Maka tetaplah memilih arsitektur yang sederhana dan melatih classifier untuk membedakan antara kelompok-kelompok ini. <br><br>  Berikut ini adalah contoh dari 6 grup acak yang diperoleh dengan membagi seluruh alfabet sumber menjadi 500 cluster: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ge/14/zi/ge14ziruqvxamfjvh-zx6fchb3s.png"></div><br><h2>  Konstruksi pengklasifikasi tingkat kedua </h2><br>  Selanjutnya, Anda perlu memutuskan karakter target mana yang akan dipelajari oleh pengklasifikasi tingkat kedua.  Jawabannya tampaknya jelas - ini harus berupa kelompok karakter yang diperoleh pada langkah sebelumnya.  Ini akan berhasil, tetapi tidak selalu dengan kualitas yang baik. <br><br>  Faktanya adalah bahwa pengklasifikasi tingkat pertama membuat kesalahan dalam hal apa pun dan mereka dapat diimbangi sebagian oleh konstruksi set tingkat kedua sebagai berikut: <br><br><ul><li>  Kami memperbaiki sampel gambar simbol tertentu yang terpisah (tidak berpartisipasi baik dalam pelatihan atau dalam pengujian); </li><li>  Kami menjalankan sampel ini melalui classifier tingkat pertama yang terlatih, menandai setiap gambar dengan label classifier ini (label grup); </li><li>  Untuk setiap simbol, kami mempertimbangkan semua grup yang memungkinkan yang menjadi pengelompokan tingkat pertama milik gambar simbol ini; </li><li>  Tambahkan simbol ini ke semua grup hingga tingkat cakupan yang diperlukan T_acc tercapai; </li><li>  Kami menganggap kelompok simbol terakhir sebagai kelompok sasaran tingkat kedua, yang akan dilatihkan oleh pengklasifikasi. </li></ul><br>  Sebagai contoh, gambar simbol "A" ditugaskan oleh classifier tingkat pertama 980 kali ke grup 5, 19 kali ke grup 2 dan 1 kali ke grup 6.  Secara total kami memiliki 1000 gambar simbol ini. <br><br>  Kemudian kita bisa menambahkan simbol "A" ke grup ke-5 dan mendapatkan cakupan 98% dari simbol ini.  Kami dapat mengaitkannya dengan grup 5 dan 2 dan mendapatkan cakupan 99,9%.  Dan kita dapat langsung mengaitkannya dengan grup (5, 2, 6) dan mendapatkan cakupan 100%. <br><br>  Intinya, T_acc mengatur keseimbangan antara kecepatan dan kualitas.  Semakin tinggi, semakin tinggi kualitas akhir dari klasifikasi, tetapi semakin besar akan menjadi set target level kedua dan semakin sulit klasifikasi di level kedua. <br><br>  Praktek menunjukkan bahwa bahkan dengan T_acc = 1, peningkatan ukuran set sebagai akibat dari prosedur pengisian ulang yang dijelaskan di atas tidak begitu signifikan - rata-rata, sekitar 2 kali.  Jelas, ini akan secara langsung tergantung pada kualitas classifier tingkat pertama yang terlatih. <br><br>  Berikut adalah contoh bagaimana penyelesaian ini bekerja untuk salah satu set dari partisi yang sama menjadi 500 grup, yang lebih tinggi: <br><br><img src="https://habrastorage.org/webt/b6/kd/nh/b6kdnh829fmav36s41h2ygqzen0.png" alt="gambar"><br><br><h2>  Hasil embed model </h2><br>  Model dua tingkat yang terlatih akhirnya bekerja lebih cepat dan lebih baik daripada pengklasifikasi yang digunakan sebelumnya.  Sebenarnya, tidak mudah untuk "berteman" dengan grafik pembagian linier yang sama (GLD).  Untuk melakukan ini, kami harus secara terpisah mengajarkan model untuk membedakan karakter dari kesalahan apriori dan segmentasi garis (mengembalikan kepercayaan rendah dalam situasi ini). <br><br>  Hasil akhir dari penyisipan ke dalam algoritma pengenalan dokumen lengkap di bawah ini (diperoleh pada kumpulan dokumen Cina dan Jepang), kecepatan ditunjukkan untuk algoritme lengkap: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7g/jq/oa/7gjqoavm4iu3xwanuakuhml4mhe.png"></div><br>  Kami meningkatkan kualitas dan mempercepat baik dalam mode normal dan cepat, sambil mentransfer semua pengenalan karakter ke jaringan saraf. <br><br><h2>  Sedikit tentang pengakuan ujung ke ujung </h2><br>  Sampai saat ini, sebagian besar sistem OCR yang diketahui secara publik (Tesseract yang sama dari Google) menggunakan arsitektur jaringan saraf End-to-End untuk mengenali string atau fragmen mereka secara keseluruhan.  Tapi di sini kami menggunakan jaringan saraf justru sebagai pengganti modul pengenalan karakter tunggal.  Ini bukan kecelakaan. <br><br>  Faktanya adalah bahwa segmentasi string menjadi karakter dalam cetak Cina dan Jepang bukan masalah besar karena pencetakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">monospace</a> .  Dalam hal ini, penggunaan pengenalan End-to-End untuk bahasa-bahasa ini tidak banyak meningkatkan kualitas, tetapi jauh lebih lambat (setidaknya pada CPU).  Secara umum, tidak jelas bagaimana menggunakan pendekatan dua tingkat yang diusulkan dalam konteks End-to-End. <br><br>  Sebaliknya, ada bahasa yang pembagian linier menjadi karakter adalah masalah utama.  Contoh-contoh eksplisit adalah bahasa Arab, Hindi.  Untuk bahasa Arab, misalnya, solusi End-to-End sudah dipelajari secara aktif bersama kami.  Tetapi ini adalah kisah yang sangat berbeda. <br><br>  <i>Alexey Zhuravlev, Kepala Grup Teknologi Baru OCR</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id438128/">https://habr.com/ru/post/id438128/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id438118/index.html">Dex-Net 4.0 memungkinkan robot Ambidextro untuk mengambil yang terbaik</a></li>
<li><a href="../id438120/index.html">Intisari acara untuk profesional SDM di bidang TI untuk Februari 2019</a></li>
<li><a href="../id438122/index.html">Numerologi pada MS SQL - percobaan yang menghibur</a></li>
<li><a href="../id438124/index.html">Piter GraphQL: video dari mitap di Wrike</a></li>
<li><a href="../id438126/index.html">Lulusan magang TI di Raiffeisenbank - bagaimana itu</a></li>
<li><a href="../id438130/index.html">Neutralinojs - Alternatif Elektron Yang Mengkonsumsi Memori Lebih Sedikit</a></li>
<li><a href="../id438132/index.html">GOSINT - solusi sumber terbuka untuk mengelola indikator kompromi (IoC)</a></li>
<li><a href="../id438134/index.html">Instalasi sistem CCTV: cerita indah dan malang dengan kamera</a></li>
<li><a href="../id438136/index.html">Persetujuan untuk pemrosesan data GDPR: analisis terperinci</a></li>
<li><a href="../id438138/index.html">Anatomi falcon</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
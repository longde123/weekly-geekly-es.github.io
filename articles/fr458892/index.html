<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéà ‚åöÔ∏è ‚ú¥Ô∏è Suggestions de vuln√©rabilit√©s et de protection des mod√®les d'apprentissage automatique üëÉüèø üîõ üë®üèº‚Äç‚öïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="R√©cemment, des experts se penchent de plus en plus sur la question de la s√©curit√© des mod√®les d'apprentissage automatique et proposent diverses m√©thod...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Suggestions de vuln√©rabilit√©s et de protection des mod√®les d'apprentissage automatique</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/458892/"><img src="https://habrastorage.org/webt/gn/da/kl/gndaklzm6lwmn9ijp2pb9sxnmza.jpeg"><br><br>  R√©cemment, des experts se penchent de plus en plus sur la question de la s√©curit√© des mod√®les d'apprentissage automatique et proposent diverses m√©thodes de protection.  Il est temps d'√©tudier en d√©tail les vuln√©rabilit√©s et d√©fenses potentielles dans le contexte des syst√®mes de mod√©lisation traditionnels populaires, tels que les mod√®les lin√©aires et arborescents, form√©s sur des ensembles de donn√©es statiques.  Bien que l'auteur de cet article ne soit pas un expert en s√©curit√©, il suit attentivement des sujets tels que le d√©bogage, les explications, l'√©quit√©, l'interpr√©tabilit√© et la confidentialit√© dans l'apprentissage automatique. <br><br>  Dans cet article, nous pr√©sentons plusieurs vecteurs probables d'attaques sur un syst√®me d'apprentissage automatique typique dans une organisation typique, proposons des solutions de protection provisoires et examinons certains probl√®mes courants et les pratiques les plus prometteuses. <br><a name="habracut"></a><br><h2>  1. Attaques de corruption de donn√©es </h2><br>  La distorsion des donn√©es signifie que quelqu'un modifie syst√©matiquement les donn√©es d'entra√Ænement pour manipuler les pr√©dictions de votre mod√®le (de telles attaques sont √©galement appel√©es attaques ¬´causales¬ª).  Pour d√©former des donn√©es, un attaquant doit avoir acc√®s √† tout ou partie de vos donn√©es d'entra√Ænement.  Et en l'absence d'un contr√¥le appropri√© dans de nombreuses entreprises, diff√©rents employ√©s, consultants et entrepreneurs peuvent avoir un tel acc√®s.  Un acc√®s non autoris√© √† tout ou partie des donn√©es d'entra√Ænement peut √©galement √™tre obtenu par un attaquant en dehors du p√©rim√®tre de s√©curit√©. <br><br>  Une attaque directe contre les donn√©es corrompues peut inclure la modification des √©tiquettes des ensembles de donn√©es.  Ainsi, quelle que soit l'utilisation commerciale de votre mod√®le, un attaquant peut g√©rer ses pr√©visions, par exemple, en changeant les √©tiquettes afin que votre mod√®le puisse apprendre √† accorder des pr√™ts importants, des remises importantes ou √† √©tablir de petites primes d'assurance pour les attaquants.  Obliger un mod√®le √† faire de fausses pr√©dictions dans l'int√©r√™t d'un attaquant est parfois qualifi√© de violation de l '"int√©grit√©" du mod√®le. <br><br>  Un attaquant peut √©galement utiliser la corruption de donn√©es pour entra√Æner votre mod√®le dans le but de discriminer d√©lib√©r√©ment un groupe de personnes, en les privant d'un pr√™t important, de remises importantes ou de primes d'assurance basses auxquelles ils ont droit.  √Ä la base, cette attaque est similaire √† DDoS.  Obliger un mod√®le √† faire de fausses pr√©dictions afin de nuire √† autrui est parfois qualifi√© de violation de l '¬´accessibilit√©¬ª du mod√®le. <br><br>  Bien qu'il puisse sembler qu'il soit plus facile de d√©former les donn√©es que de modifier les valeurs dans les lignes existantes d'un ensemble de donn√©es, vous pouvez √©galement introduire des distorsions en ajoutant des colonnes apparemment inoffensives ou suppl√©mentaires √† l'ensemble de donn√©es.  Les valeurs modifi√©es dans ces colonnes peuvent alors entra√Æner la modification des pr√©visions du mod√®le. <br><br>  Voyons maintenant quelques solutions de protection et expert (m√©dico-l√©gales) possibles en cas de corruption de donn√©es: <br><br><ul><li>  <b>Analyse d'impact diff√©renci√©e</b> .  De nombreuses banques effectuent d√©j√† une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">analyse d'</a> impact <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">diff√©rentiel</a> pour des pr√™ts √©quitables afin de d√©terminer si leur mod√®le est discrimin√© par diff√©rentes cat√©gories de personnes.  Cependant, de nombreuses autres organisations ne sont pas encore arriv√©es √† ce jour.  Il existe plusieurs excellents outils open source pour d√©tecter la discrimination et effectuer une analyse d'impact diff√©rentiel.  Par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Aequitas,</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Themis</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AIF360</a> . <br></li><li> <b>Mod√®les √©quitables ou priv√©s</b> .  Des mod√®les tels que l'apprentissage des repr√©sentations justes (LFR) et l'agr√©gation priv√©e des ensembles d'enseignants (PATE) ont tendance √† accorder moins d'attention aux propri√©t√©s d√©mographiques individuelles lors de la g√©n√©ration de pr√©visions.  De plus, ces mod√®les peuvent √™tre moins sensibles aux attaques discriminatoires afin de fausser les donn√©es. <br></li><li>  <b>Rejet sur impact n√©gatif (RONI)</b> .  RONI est une m√©thode de suppression des lignes de donn√©es d'un ensemble de donn√©es qui r√©duit la pr√©cision des pr√©dictions.  Pour plus d'informations sur RONI, reportez-vous √† la Section 8, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">S√©curit√© de l'apprentissage automatique</a> . <br></li><li>  <b>Analyse r√©siduelle</b> .  Recherchez des mod√®les √©tranges et perceptibles dans les r√©sidus de vos pr√©visions de mod√®le, en particulier ceux li√©s aux employ√©s, consultants ou entrepreneurs. <br></li><li>  <b>Auto-r√©flexion</b> .  √âvaluez les mod√®les de vos employ√©s, consultants et sous-traitants pour identifier les pr√©visions anormalement favorables. <br></li></ul><br>  Une analyse d'impact diff√©renci√©e, une analyse r√©siduelle et une auto-r√©flexion peuvent √™tre r√©alis√©es pendant la formation et dans le cadre du suivi en temps r√©el des mod√®les. <br><br><h2>  2. Attaques par filigrane </h2><br>  Un filigrane est un terme emprunt√© √† la litt√©rature sur la s√©curit√© de l'apprentissage en profondeur, qui se r√©f√®re souvent √† l'ajout de pixels sp√©ciaux √† l'image pour obtenir le r√©sultat souhait√© de votre mod√®le.  Il est tout √† fait possible de faire de m√™me avec les donn√©es des clients ou des transactions. <br><br>  Consid√©rez un sc√©nario dans lequel un employ√©, un consultant, un entrepreneur ou un attaquant de l'ext√©rieur a acc√®s au code pour la production-utilisation de votre mod√®le qui fait des pr√©visions en temps r√©el.  Une telle personne peut modifier le code pour reconna√Ætre une combinaison √©trange ou improbable de valeurs de variable d'entr√©e pour obtenir le r√©sultat de pr√©diction souhait√©.  Tout comme la corruption de donn√©es, les attaques par filigrane peuvent √™tre utilis√©es pour violer l'int√©grit√© ou l'accessibilit√© de votre mod√®le.  Par exemple, afin de violer l'int√©grit√©, un attaquant peut ins√©rer une "charge utile" dans le code d'√©valuation pour l'utilisation en production du mod√®le, √† la suite de quoi il reconna√Æt une combinaison de 0 ans √† l'adresse 99, ce qui conduira √† des pr√©visions positives pour l'attaquant.  Et pour bloquer la disponibilit√© du mod√®le, il peut ins√©rer une r√®gle de discrimination artificielle dans le code d'√©valuation, ce qui ne permettra pas au mod√®le de donner des r√©sultats positifs pour un certain groupe de personnes. <br><br>  Les approches protectrices et expertes des attaques utilisant des filigranes peuvent inclure: <br><br><ul><li>  <b>D√©tection d'anomalie</b> .  Autocoders est un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®le de d√©tection de fraude</a> qui peut identifier les entr√©es complexes et √©tranges, ou pas comme les autres donn√©es.  Les auto-encodeurs peuvent potentiellement d√©tecter les filigranes utilis√©s pour d√©clencher des m√©canismes malveillants. <br></li><li>  <b>Limitations de l'int√©grit√© des donn√©es</b> .  De nombreuses bases de donn√©es ne permettent pas de combinaisons √©tranges ou irr√©alistes de variables d'entr√©e, ce qui pourrait potentiellement emp√™cher les attaques de filigrane.  Le m√™me effet peut fonctionner pour les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">contraintes d'int√©grit√©</a> des flux de donn√©es qui sont re√ßus en temps r√©el. <br></li><li>  <b>Analyse d'exposition diff√©renci√©e</b> : voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">section 1</a> . <br></li><li>  <b>Contr√¥le de version</b> .  Le code d'√©valuation de l'application de production du mod√®le doit √™tre versionn√© et contr√¥l√©, comme tout autre produit logiciel critique. <br></li></ul><br>  La d√©tection d'anomalies, les limites d'int√©grit√© des donn√©es et l'analyse d'impact diff√©rentiel peuvent √™tre utilis√©es pendant la formation et dans le cadre de la surveillance du mod√®le en temps r√©el. <br><br><h2>  3. Inversion des mod√®les de substitution </h2><br>  Habituellement, ¬´inversion¬ª est appel√©e obtenir des informations non autoris√©es √† partir d'un mod√®le, plut√¥t que d'y placer des informations.  En outre, l'inversion peut √™tre un exemple d'une ¬´attaque de reconnaissance en ing√©nierie inverse¬ª.  Si un attaquant est en mesure d'obtenir de nombreuses pr√©dictions √† partir de l'API de votre mod√®le ou d'un autre point de terminaison (site Web, application, etc.), il peut former son propre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√®le de substitution</a> .  Autrement dit, il s'agit d'une simulation de votre mod√®le pr√©dictif!  Th√©oriquement, un attaquant peut entra√Æner un mod√®le de substitution entre les donn√©es d'entr√©e utilis√©es pour g√©n√©rer les pr√©visions re√ßues et les pr√©visions elles-m√™mes.  Selon le nombre de pr√©dictions pouvant √™tre re√ßues, le mod√®le de substitution peut devenir une simulation assez pr√©cise de votre mod√®le.  Apr√®s avoir entra√Æn√© le mod√®le de substitution, l'attaquant disposera d'un ¬´bac √† sable¬ª √† partir duquel il pourra planifier une impersonnalisation (c'est-√†-dire une ¬´imitation¬ª) ou une attaque avec un exemple concurrentiel sur l'int√©grit√© de votre mod√®le, ou gagner le potentiel de commencer √† r√©cup√©rer certains aspects de vos donn√©es d'entra√Ænement confidentielles.  Les mod√®les de substitution peuvent √©galement √™tre form√©s √† l'aide de sources de donn√©es externes qui sont en quelque sorte coh√©rentes avec vos pr√©visions, comme, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ProPublica l'a</a> fait avec le mod√®le de r√©cidive de l'auteur COMPAS. <br><br>  Pour prot√©ger votre mod√®le contre l'inversion √† l'aide d'un mod√®le de substitution, vous pouvez compter sur de telles approches: <br><br><ul><li>  <b>Acc√®s autoris√©</b> .  Demandez une authentification suppl√©mentaire (par exemple, √† deux facteurs) pour obtenir une pr√©vision. <br></li><li>  <b>Pr√©dictions des gaz</b>  Limitez un grand nombre de pr√©visions rapides d'utilisateurs individuels;  envisager la possibilit√© d'augmenter artificiellement les d√©lais de pr√©diction. <br></li><li>  <b>Mod√®les de substitution ¬´blanc¬ª (chapeau blanc)</b> .  En tant qu'exercice de piratage blanc, essayez ce qui suit: entra√Ænez vos propres mod√®les de substitution entre vos pr√©visions d'entr√©e et de mod√®le pour une application de production, et observez attentivement les aspects suivants: <br><ul><li>  limites d'exactitude de divers types de mod√®les de substitution ¬´blancs¬ª;  essayez de comprendre dans quelle mesure le mod√®le de substitution peut r√©ellement √™tre utilis√© pour obtenir des donn√©es ind√©sirables sur votre mod√®le. <br></li><li>  types de tendances de donn√©es qui peuvent √™tre apprises √† partir de votre mod√®le de substitution ¬´blanc¬ª, par exemple, les tendances lin√©aires repr√©sent√©es par des coefficients de mod√®le lin√©aire. <br></li><li>  types de segments ou distributions d√©mographiques qui peuvent √™tre √©tudi√©s en analysant le nombre de personnes affect√©es √† certains n≈ìuds de l'arbre de d√©cision de substitution ¬´blanc¬ª. <br></li><li>  les r√®gles qui peuvent √™tre tir√©es de l'arbre de d√©cision de substitution ¬´blanc¬ª, par exemple, comment repr√©senter avec pr√©cision une personne qui recevra une pr√©vision positive. <br></li></ul><br></li></ul><br><h2>  4. Attaques de rivalit√© </h2><br>  En th√©orie, un pirate informatique d√©di√© peut apprendre - par exemple, essais et erreurs (c.-√†-d. ¬´Intelligence¬ª ou ¬´analyse de sensibilit√©¬ª) - inverser un mod√®le de substitution ou une ing√©nierie sociale, comment jouer avec votre mod√®le pour obtenir le r√©sultat de pr√©diction souhait√© ou √©viter les effets ind√©sirables pr√©visions.  Tenter d'atteindre ces objectifs √† l'aide d'une cha√Æne de donn√©es sp√©cialement con√ßue est appel√© une attaque contradictoire.  (parfois une attaque pour enqu√™ter sur l'int√©grit√©).  Un attaquant peut utiliser une attaque contradictoire pour obtenir un pr√™t important ou une prime d'assurance faible, ou pour √©viter un refus de lib√©ration conditionnelle avec une √©valuation √©lev√©e du risque criminel.  Certaines personnes appellent l'utilisation d'exemples concurrentiels pour exclure un r√©sultat ind√©sirable d'une pr√©vision comme ¬´√©vasion¬ª. <br><br>  Essayez les m√©thodes d√©crites ci-dessous pour d√©fendre ou d√©tecter une attaque avec un exemple concurrentiel: <br><br><ul><li>  <b>Analyse d'activation</b> .  L'analyse d'activation n√©cessite que vos mod√®les pr√©dictifs disposent de m√©canismes internes comparatifs, par exemple, l'activation moyenne des neurones dans votre r√©seau neuronal ou la proportion d'observations li√©es √† chaque n≈ìud terminal de votre for√™t al√©atoire.  Ensuite, vous comparez ces informations avec le comportement du mod√®le avec des flux de donn√©es entrants r√©els.  Comme l‚Äôa dit un de mes coll√®gues: ¬´ <i>C‚Äôest la m√™me chose que de voir un n≈ìud final dans une for√™t al√©atoire qui correspond √† 0,1% des donn√©es de formation, mais convient √† 75% des lignes de score par heure</i> .¬ª <br></li><li>  <b>D√©tection d'anomalie</b> .  voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">section 2</a> . <br></li><li>  <b>Acc√®s autoris√©</b> .  voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">section 3</a> . <br></li><li>  <b>Mod√®les comparatifs</b> .  Lors de l'√©valuation de nouvelles donn√©es, en plus d'un mod√®le plus complexe, utilisez un mod√®le comparatif √† haute transparence.  Les mod√®les interpr√©t√©s sont plus difficiles √† d√©chiffrer car leurs m√©canismes sont transparents.  Lors de l'√©valuation de nouvelles donn√©es, comparez le nouveau mod√®le avec un mod√®le transparent fiable ou un mod√®le form√© sur des donn√©es v√©rifi√©es et sur un processus de confiance.  Si la diff√©rence entre le mod√®le plus complexe et opaque et le mod√®le interpr√©t√© (ou v√©rifi√©) est trop grande, revenez aux pr√©visions du mod√®le conservateur ou traitez la ligne de donn√©es manuellement.  Enregistrez cet incident, il pourrait s'agir d'une attaque avec un exemple comp√©titif. <br></li><li>  <b>Pr√©vision des gaz</b> : voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">section 3</a> . <br></li><li>  <b>Analyse de sensibilit√© "blanche"</b> .  Utilisez l'analyse de sensibilit√© pour mener vos propres attaques de recherche afin de comprendre quelles valeurs variables (ou combinaisons d'entre elles) peuvent provoquer de grandes fluctuations dans les pr√©visions.  Recherchez ces valeurs ou combinaisons de valeurs lors de l'√©valuation de nouvelles donn√©es.  Pour effectuer une analyse de recherche ¬´blanche¬ª, vous pouvez utiliser le package open source <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cleverhans</a> . <br></li><li>  Mod√®les de substitution blancs: voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">section 3</a> . <br></li></ul><br>  L'analyse d'activation ou des mod√®les comparatifs peuvent √™tre utilis√©s pendant la formation et dans le cadre du suivi en temps r√©el des mod√®les. <br><br><h2>  5. Impersonnalisation </h2><br>  Un pirate intentionnel peut d√©couvrir - encore une fois, par essais et erreurs, par inversion avec un mod√®le de substitution ou une ing√©nierie sociale - qui saisissent des donn√©es ou des personnes sp√©cifiques obtiennent le r√©sultat de pr√©diction souhait√©.  Un attaquant peut alors se faire passer pour cette personne pour b√©n√©ficier des pr√©visions.  Les attaques par impersonnalisation sont parfois appel√©es attaques ¬´simul√©es¬ª et, du point de vue du mod√®le, cela rappelle le vol d'identit√©.  Comme dans le cas d'un exemple d'attaque concurrentielle, avec l'impersonnalisation, les donn√©es d'entr√©e sont modifi√©es artificiellement en fonction de votre mod√®le.  Mais, contrairement √† la m√™me attaque avec un exemple concurrentiel, dans lequel une combinaison potentiellement al√©atoire de valeurs peut √™tre utilis√©e pour tromper, en impersonnalisation, pour obtenir les pr√©visions associ√©es √† ce type d'objet, des informations associ√©es √† un autre objet mod√©lis√© (par exemple, un client condamn√© , employ√©, transaction financi√®re, patient, produit, etc.).  Supposons qu'un attaquant puisse d√©couvrir de quelles caract√©ristiques de votre mod√®le d√©pend la fourniture de remises ou d'avantages importants.  Ensuite, il peut falsifier les informations que vous utilisez pour obtenir une telle remise.  Un attaquant peut partager sa strat√©gie avec d'autres, ce qui peut entra√Æner des pertes importantes pour votre entreprise. <br><br>  Si vous utilisez un mod√®le √† deux √©tapes, m√©fiez-vous d'une attaque ¬´allergique¬ª: un attaquant peut simuler une cha√Æne de donn√©es d'entr√©e ordinaires pour la premi√®re √©tape de votre mod√®le afin d'attaquer sa deuxi√®me √©tape. <br><br>  Les approches protectrices et expertes pour les attaques avec impersonnalisation peuvent inclure: <br><br><ul><li>  Analyse d'activation.  voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">section 4</a> . <br></li><li>  Acc√®s autoris√©.  voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">section 3</a> . <br></li><li>  V√©rifiez les doublons.  √Ä l'√©tape de la notation, suivez le nombre d'enregistrements similaires pour lesquels votre mod√®le est disponible.  Cela peut √™tre fait dans un espace dimensionnel r√©duit en utilisant des autocodeurs, une mise √† l'√©chelle multidimensionnelle (MDS) ou des m√©thodes de r√©duction dimensionnelle similaires.  S'il y a trop de lignes similaires dans une p√©riode de temps donn√©e, prenez des mesures correctives. <br></li><li> Fonctions de notification des menaces.  Enregistrez la fonction <code>num_similar_queries</code> dans votre pipeline, qui peut √™tre inutile imm√©diatement apr√®s la formation ou la mise en ≈ìuvre de votre mod√®le, mais peut √™tre utilis√©e lors de l'√©valuation (ou lors d'une nouvelle formation) pour notifier le mod√®le ou le pipeline des menaces.  Par exemple, si au moment de l'√©valuation, la valeur de <code>num_similar_queries</code> sup√©rieure √† z√©ro, la demande d'√©valuation peut √™tre envoy√©e pour analyse manuelle.  √Ä l'avenir, lorsque vous <code>num_similar_queries</code> le mod√®le, vous pourrez lui apprendre √† produire des r√©sultats de pr√©diction n√©gatifs pour les lignes d'entr√©e avec un <code>num_similar_queries</code> √©lev√© de <code>num_similar_queries</code> . <br></li></ul><br>  L'analyse d'activation, la v√©rification des doublons et la notification des menaces potentielles peuvent √™tre utilis√©es pendant la formation et dans la surveillance des mod√®les en temps r√©el. <br><br><h2>  6. Probl√®mes courants </h2><br>  Certaines utilisations courantes de l'apprentissage automatique posent √©galement des probl√®mes de s√©curit√© plus g√©n√©raux. <br><br>  <b>Bo√Ætes noires et complexit√© inutile</b> .  Bien que les progr√®s r√©cents des mod√®les interpr√©t√©s et des explications des mod√®les permettent d'utiliser des classificateurs et des r√©gresseurs non lin√©aires pr√©cis et transparents, de nombreux processus d'apprentissage automatique continuent de se concentrer sur les mod√®les de bo√Æte noire.  Ils ne sont qu'un type de complexit√© souvent inutile dans le flux de travail standard de l'apprentissage automatique commercial.  D'autres exemples de complexit√© potentiellement nuisible peuvent √™tre des sp√©cifications trop exotiques ou un grand nombre de d√©pendances de package.  Cela peut √™tre un probl√®me pour au moins deux raisons: <br><br><ol><li>  Un pirate persistant et motiv√© peut en savoir plus sur votre syst√®me de simulation de bo√Æte noire trop complexe que vous ou votre √©quipe (en particulier sur le march√© actuel en surchauffe et en √©volution rapide pour ¬´analyser¬ª les donn√©es).  Pour cela, un attaquant peut utiliser de nombreuses nouvelles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">m√©thodes d'explication</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ind√©pendantes du</a> mod√®le et une analyse de sensibilit√© classique, √† part de nombreux autres outils de piratage plus courants.  Ce d√©s√©quilibre des connaissances peut potentiellement √™tre utilis√© pour mener √† bien les attaques d√©crites dans les sections 1 √† 5, ou pour d'autres types d'attaques encore inconnus. <br></li><li>  L'apprentissage automatique dans les environnements de recherche et d√©veloppement d√©pend fortement d'un √©cosyst√®me diversifi√© de progiciels open source.  Certains de ces forfaits comptent de nombreux participants et utilisateurs, d'autres sont hautement sp√©cialis√©s et sont n√©cessaires √† un petit cercle de chercheurs et de praticiens.  Il est connu que de nombreux packages sont pris en charge par de brillants statisticiens et chercheurs en apprentissage automatique qui se concentrent sur les math√©matiques ou les algorithmes, plut√¥t que sur le g√©nie logiciel et certainement pas sur la s√©curit√©.  Il existe de nombreux cas o√π le pipeline d'apprentissage automatique d√©pend de dizaines, voire de centaines de packages externes, dont chacun peut √™tre pirat√© pour masquer une ¬´charge utile¬ª malveillante. <br></li></ol><br>  <b>Syst√®mes et mod√®les distribu√©s</b> .  Heureusement ou malheureusement, nous vivons √† une √©poque de m√©gadonn√©es.  De nombreuses organisations utilisent aujourd'hui des syst√®mes distribu√©s de traitement de donn√©es et d'apprentissage automatique.  L'informatique distribu√©e peut √™tre une cible importante pour les attaques de l'int√©rieur ou de l'ext√©rieur.  Les donn√©es ne peuvent √™tre d√©form√©es que sur un ou plusieurs n≈ìuds de travail d'un grand syst√®me de stockage ou de traitement de donn√©es distribu√©.  La porte arri√®re pour les filigranes peut √™tre cod√©e en un mod√®le d'un grand ensemble.  Au lieu de d√©boguer un simple ensemble de donn√©es ou un mod√®le, les praticiens devraient maintenant √©tudier des donn√©es ou des mod√®les dispers√©s dans de grands clusters informatiques. <br><br>  <b>Attaques par d√©ni de service distribu√© (DDoS)</b> .  Si un service de mod√©lisation pr√©dictive joue un r√¥le cl√© dans les activit√©s de votre organisation, assurez-vous de prendre en compte au moins les attaques DDoS distribu√©es les plus populaires lorsque les attaquants attaquent un service pr√©dictif avec un nombre incroyablement √©lev√© de demandes afin de retarder ou d'arr√™ter la production de pr√©visions pour les utilisateurs l√©gitimes. <br><br><h2>  7. D√©cisions g√©n√©rales </h2><br>  Vous pouvez utiliser plusieurs m√©thodes courantes, anciennes et nouvelles, les plus efficaces pour r√©duire les vuln√©rabilit√©s des syst√®mes de s√©curit√© et augmenter l'√©quit√©, la contr√¥labilit√©, la transparence et la confiance dans les syst√®mes d'apprentissage automatique. <br><br>  <b>Pr√©vision d'acc√®s autoris√© et de r√©gulation de fr√©quence (√©tranglement)</b> .  Les fonctionnalit√©s de s√©curit√© standard, telles que l'ajustement suppl√©mentaire de la fr√©quence d'authentification et de pr√©diction, peuvent √™tre tr√®s efficaces pour bloquer un certain nombre de vecteurs d'attaque d√©crits dans les sections 1-5. <br><br>  <b>Mod√®les comparatifs</b> .  En tant que mod√®le comparatif pour d√©terminer si des manipulations ont √©t√© effectu√©es avec la pr√©vision, vous pouvez utiliser l'ancien pipeline de mod√©lisation √©prouv√© ou un autre outil de pr√©vision interpr√©t√© avec une grande transparence.  La manipulation comprend la corruption de donn√©es, des attaques de filigrane ou des exemples concurrents.  Si la diff√©rence entre la pr√©vision de votre mod√®le test√© et la pr√©vision d'un mod√®le plus complexe et opaque est trop grande, notez ces cas.  Envoyez-les √† des analystes ou prenez d'autres mesures pour analyser ou corriger la situation.  De s√©rieuses pr√©cautions doivent √™tre prises pour garantir que votre r√©f√©rence et votre convoyeur restent en s√©curit√© et inchang√©s par rapport √† leur √©tat d'origine et fiable. <br><br>  <b>Mod√®les interpr√©t√©s, √©quitables ou priv√©s</b> .  Actuellement, il existe des m√©thodes (par exemple, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GBM monotone (M-GBM),</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les listes de r√®gles bay√©siennes √©volutives (SBRL)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les explications du r√©seau neuronal (XNN)</a> ) qui fournissent √† la fois pr√©cision et interpr√©tabilit√©.  Ces mod√®les pr√©cis et interpr√©tables sont plus faciles √† documenter et √† d√©boguer que les bo√Ætes noires classiques d'apprentissage automatique.  Les nouveaux types de mod√®les √©quitables et priv√©s (par exemple, LFR, PATE) peuvent √©galement √™tre form√©s √† la fa√ßon de pr√™ter moins d'attention aux caract√©ristiques d√©mographiques visibles de l'ext√©rieur qui sont disponibles pour l'observation, en utilisant l'ing√©nierie sociale lors d'une attaque avec un exemple concurrentiel, ou impersonnalisation.  Envisagez-vous de cr√©er un nouveau processus d'apprentissage automatique √† l'avenir?  Envisagez de le construire sur la base de mod√®les priv√©s ou √©quitables interpr√©t√©s moins risqu√©s.  Ils sont plus faciles √† d√©boguer et potentiellement r√©sistants aux modifications des caract√©ristiques des objets individuels. <br><br>  <b>D√©bogage d'un mod√®le pour la s√©curit√©</b> .  Un nouveau domaine de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©bogage des mod√®les est</a> consacr√© √† la d√©tection des erreurs dans les m√©canismes et pr√©visions des mod√®les d'apprentissage automatique et √† leur correction.  Les outils de d√©bogage, tels que les mod√®les de substitution, l'analyse r√©siduelle et l'analyse de sensibilit√©, peuvent √™tre utilis√©s dans les essais blancs pour identifier vos vuln√©rabilit√©s, ou dans les exercices analytiques pour identifier les attaques potentielles qui peuvent ou peuvent se produire. <br><br>  <b>Documentation du mod√®le et m√©thodes d'explication</b> .  La documentation mod√®le est une strat√©gie de r√©duction des risques utilis√©e dans le secteur bancaire depuis des d√©cennies.  Il vous permet d'enregistrer et de transf√©rer des connaissances sur les syst√®mes de mod√©lisation complexes √† mesure que la composition des propri√©taires de mod√®les change.  La documentation est traditionnellement utilis√©e pour les mod√®les lin√©aires de haute transparence.  Mais avec l'av√®nement d'outils d'explication puissants et pr√©cis (tels que l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">arborescence SHAP</a> et les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">attributs d√©riv√©s des fonctions locales</a> pour les r√©seaux de neurones), les flux de travail pr√©existants des mod√®les de bo√Æte noire peuvent √™tre au moins un peu expliqu√©s, d√©bogu√©s et document√©s.  De toute √©vidence, la documentation devrait maintenant inclure tous les objectifs de s√©curit√©, y compris les vuln√©rabilit√©s connues, corrig√©es ou attendues. <br><br>  <b>Surveillez et g√©rez les mod√®les directement pour des raisons de s√©curit√©</b> .  Les praticiens s√©rieux comprennent que la plupart des mod√®les sont form√©s sur des "instantan√©s" statiques de la r√©alit√© sous la forme d'ensembles de donn√©es, et qu'en temps r√©el la pr√©cision des pr√©visions diminue, car l'√©tat actuel des choses s'√©loigne des informations collect√©es pr√©c√©demment.  Aujourd'hui, la surveillance de la plupart des mod√®les vise √† identifier un tel biais dans la distribution des variables d'entr√©e, qui, √† terme, entra√Ænera une diminution de la pr√©cision.  La surveillance du mod√®le doit √™tre con√ßue pour suivre les attaques d√©crites dans les sections 1 √† 5 et toutes les autres menaces potentielles qui apparaissent lors du d√©bogage de votre mod√®le.  Bien que cela ne soit pas toujours directement li√© √† la s√©curit√©, les mod√®les doivent √©galement √™tre √©valu√©s en temps r√©el pour des effets diff√©renci√©s.  Avec la documentation du mod√®le, tous les artefacts de mod√©lisation, le code source et les m√©tadonn√©es associ√©es doivent √™tre g√©r√©s, versionn√©s et v√©rifi√©s pour la s√©curit√©, ainsi que les actifs commerciaux pr√©cieux qu'ils sont. <br><br>  <b>Fonctions de notification des menaces</b> .  Des fonctions, des r√®gles et des √©tapes de traitement pr√©liminaire ou ult√©rieur peuvent √™tre incluses dans vos mod√®les ou processus √©quip√©s de moyens de notification des menaces possibles: par exemple, le nombre de lignes similaires dans le mod√®le;  si la ligne actuelle repr√©sente un employ√©, un entrepreneur ou un consultant;  Les valeurs de la ligne actuelle sont-elles similaires √† celles obtenues avec des attaques blanches avec un exemple comp√©titif?  Ces fonctions peuvent √™tre n√©cessaires ou non lors de la premi√®re formation du mod√®le.  Mais √©conomiser de l'espace pour eux peut un jour √™tre tr√®s utile pour √©valuer de nouvelles donn√©es ou pour recycler ult√©rieurement le mod√®le. <br><br>  <b>D√©tection d'anomalies du syst√®me</b> .  Entra√Ænez le m√©tamode √† d√©tecter les anomalies sur la base d'un autocodeur sur les statistiques op√©rationnelles de l'ensemble de votre syst√®me de mod√©lisation pr√©dictive (nombre de pr√©visions pour une certaine p√©riode de temps, retards, CPU, m√©moire et chargement de disque, nombre d'utilisateurs simultan√©s, etc.), puis surveillez attentivement ce m√©tamod√®le pour anomalies.  Une anomalie peut dire si quelque chose ne va pas.  Des enqu√™tes de suivi ou des m√©canismes sp√©ciaux seront n√©cessaires pour suivre avec pr√©cision la cause du probl√®me. <br><br><h2>  8. R√©f√©rences et informations pour une lecture plus approfondie </h2><br>  Une grande quantit√© de litt√©rature acad√©mique moderne sur la s√©curit√© de l'apprentissage automatique se concentre sur l'apprentissage adaptatif, l'apprentissage profond et le chiffrement.  Cependant, jusqu'√† pr√©sent, l'auteur ne conna√Æt pas les pratiquants qui feraient r√©ellement tout cela.  Par cons√©quent, en plus d'articles et de publications r√©cemment publi√©s, nous pr√©sentons des articles des ann√©es 1990 et du d√©but des ann√©es 2000 sur les violations de r√©seau, la d√©tection de virus, le filtrage du spam et des sujets connexes, qui √©taient √©galement des sources utiles.  Si vous souhaitez en savoir plus sur le sujet fascinant de la protection des mod√®les d'apprentissage automatique, voici les principaux liens - du pass√© et du pr√©sent - qui ont √©t√© utilis√©s pour r√©diger l'article. <br><br><ul><li>  Bareno, Marco et al.S√©curit√© de l'apprentissage machine.  Machine Learning 81.2 (2010): 121-148.  URL  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://people.eecs.berkeley.edu/ <sub>~</sub> adj / publications / paper-files / SecML-MLJ2010.pdf</a> <br></li><li>  Kumar, Agites.  "Attaques de s√©curit√©: une analyse des mod√®les d'apprentissage automatique."  DZone (2018).  URL  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://dzone.com/articles/security-attacks-analysis-of-machine-learning-mode</a> <br></li><li>  Lorica, Ben et Lucidis, Mike.  ¬´Vous avez cr√©√© une application d'apprentissage automatique.  Maintenant, assurez-vous que c'est s√ªr. "  Id√©es O'Reilly (2019).  URL  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.oreilly.com/ideas/you-created-a-machine-learning-application-now-make-sure-its-secure</a> <br></li><li>  Paperno, Nicholas.  "Carte des maraudeurs de la s√©curit√© et de la confidentialit√© dans l'apprentissage automatique: un examen des tendances de recherche actuelles et futures en mati√®re de s√©curit√© et de confidentialit√© de l'apprentissage automatique."  Actes du 11e atelier ACM sur l'intelligence artificielle et la s√©curit√©.  ACM (2018).  URL  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://arxiv.org/pdf/1811.01134.pdf</a> <br></li></ul><br><h2>  Conclusion </h2><br>  Ceux qui se soucient de la science et de la pratique de l'apprentissage automatique s'inqui√®tent du fait que la menace de piratage avec l'apprentissage automatique, coupl√©e aux menaces croissantes de violation de la confidentialit√© et de discrimination algorithmique, peut augmenter le scepticisme public et politique croissant concernant l'apprentissage automatique et l'intelligence artificielle.  Nous devons tous nous souvenir des moments difficiles de l'IA dans un pass√© r√©cent.  Les vuln√©rabilit√©s de s√©curit√©, les atteintes √† la vie priv√©e et la discrimination algorithmique pourraient potentiellement √™tre combin√©es, conduisant √† une r√©duction du financement de la recherche en formation informatique ou √† des mesures draconiennes pour r√©glementer ce domaine.  Poursuivons la discussion et la r√©solution de ces questions importantes afin de pr√©venir une crise et non d'en perturber les cons√©quences. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr458892/">https://habr.com/ru/post/fr458892/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr458882/index.html">Prise de parole en public. En bref sur l'essentiel</a></li>
<li><a href="../fr458884/index.html">Un peu sur les normes de communication spatiale</a></li>
<li><a href="../fr458886/index.html">Conf√©rences Mail.ru Design Conf √ó Dribbble Meetup 2019 les plus utiles par True Engineering</a></li>
<li><a href="../fr458888/index.html">Meetup Summer Droid</a></li>
<li><a href="../fr458890/index.html">√âchantillonnage et pr√©cision des calculs</a></li>
<li><a href="../fr458894/index.html">Les gens typiques et les r√©seaux dans lesquels ils vivent</a></li>
<li><a href="../fr458896/index.html">JavaScript fonctionnel: quelles sont les fonctions d'ordre sup√©rieur et pourquoi sont-elles n√©cessaires?</a></li>
<li><a href="../fr458900/index.html">Cartouches de console en tant que modems</a></li>
<li><a href="../fr458902/index.html">5 erreurs communes de Python pour d√©butants</a></li>
<li><a href="../fr458904/index.html">Visualisation du nombre de victoires pour les √©quipes NBA √† l'aide de graphiques √† barres anim√©es en R</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
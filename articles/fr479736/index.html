<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚åõÔ∏è üíõ üë©üèæ‚Äçüåæ Appareils photo ou lasers üóúÔ∏è üê∑ üà≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Quels capteurs seront les plus importants dans les v√©hicules sans pilote? Ces capteurs qui contr√¥lent le soi-disant syst√®me de perception, et c'est la...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Appareils photo ou lasers</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itelma/blog/479736/"><img src="https://habrastorage.org/getpro/habr/post_images/7d1/cd7/4c9/7d1cd74c9a86901e522b61b4848fbd1e.jpg" alt="image"><br><br>  Quels capteurs seront les plus importants dans les v√©hicules sans pilote?  Ces capteurs qui contr√¥lent le soi-disant syst√®me de perception, et c'est la chose la plus importante dans la conduite.  Le syst√®me de perception a pour t√¢che de d√©tecter tous les objets importants sur ou pr√®s de la route, par exemple, d'autres v√©hicules, pi√©tons, ordures et, dans certains cas, des objets de la route, tels que des panneaux et des marquages ‚Äã‚Äãde voie. <br><br>  (Le positionnement sur la route d√©pend √©galement des capteurs). <br><br>  Le syst√®me de perception doit d√©tecter tous les obstacles et essayer de les identifier.  Elle a besoin de mesurer leur vitesse et leur direction, mais aussi de pr√©voir leur mouvement.  C'est une t√¢che tr√®s difficile. <br><br>  Deux erreurs cl√©s dans le syst√®me de perception sont les faux positifs (c√©cit√©) et les faux positifs (objets fantomatiques). <br><br>  Une fausse r√©ponse n√©gative est une situation dans laquelle aucun obstacle n'a √©t√© d√©tect√©.  Cela peut entra√Æner des cons√©quences d√©sastreuses si le syst√®me fonctionne de cette mani√®re pendant si longtemps que vous ne pouvez pas contourner l'obstacle en toute s√©curit√©.  Un bon syst√®me ne produira presque jamais de faux r√©sultats n√©gatifs.  La reconnaissance d'un obstacle peut prendre quelques instants suppl√©mentaires, il peut manquer quelque chose en raison de flashs soudains, mais des erreurs r√©p√©t√©es peuvent entra√Æner un accident.  Dire ¬´jamais¬ª, je veux dire ¬´presque jamais¬ª, de l'ordre de l'unit√© √† plusieurs millions. <br><br>  Un r√©sultat faussement positif est un autre type d'erreur.  Dans son cas, le syst√®me voit quelque chose qui n'est pas l√†, ce qui oblige la voiture √† freiner ou √† s'effondrer.  Cela d√©range les passagers et s'ils ne sont pas attach√©s, cela peut entra√Æner des blessures.  Cela peut √©galement entra√Æner un accident si l'autre voiture se d√©place tr√®s pr√®s ou avec un freinage et des virages trop serr√©s.  En r√®gle g√©n√©rale, de tels cas ne sont pas dangereux, mais si cela se produit trop souvent, les utilisateurs abandonneront le syst√®me. <br><a name="habracut"></a><br>  Une classification incorrecte est √©galement associ√©e aux erreurs ci-dessus.  Une classification incorrecte signifie que le cycliste a √©t√© confondu avec un pi√©ton ou que deux motos ont √©t√© confondues avec une voiture.  M√™me sans identification pr√©cise, la machine sait comment ne pas percuter un obstacle, mais le syst√®me peut d√©terminer de mani√®re incorrecte o√π elle se d√©place ou comment y r√©pondre au mieux. <br><br>  Une autre classe d'erreurs est celle des √©checs complets.  Le capteur ou son logiciel peut mal fonctionner ou ne pas fonctionner correctement.  √âtonnamment, cela est autoris√© plus souvent que la c√©cit√©, car le syst√®me saura que le capteur est hors service et n'acceptera pas ses donn√©es.  Dans ce cas, elle s'appuiera sur des capteurs de secours, ou s'efforcera de quitter la route d√®s que possible en utilisant d'autres capteurs, si cela ne suffit pas.  Bien que cela ne devrait pas se produire trop souvent, sinon les gens cesseront de faire confiance au syst√®me. <br><br>  Il existe de nombreux capteurs importants pour les v√©hicules sans pilote, mais les plus √©tudi√©s et discut√©s sont les lidars et les cam√©ras. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/068/a1f/383/068a1f38333747b94b64b3e39a6194b6.jpg" alt="image"></div><br><br>  Lidar est un radar √† base de lumi√®re.  Le capteur envoie de courtes impulsions de lumi√®re laser invisibles √† l'≈ìil et d√©tecte la dur√©e de retour de la lumi√®re r√©fl√©chie.  Ainsi, le syst√®me reconna√Æt assez pr√©cis√©ment la luminosit√© et la plage de la cible. <br><br>  <b>Le Lidar pr√©sente de grands avantages:</b> <br><br><ul><li>  Il est extr√™mement fiable pour d√©tecter divers objets de taille suffisante et calcule leur distance, taille et position tr√®s proche de 100% de fiabilit√©. </li><li>  Le r√©sultat du lidar est une carte 3D du monde autour.  Il est facile de s√©lectionner quelque chose parmi les objets derri√®re le capteur (ou devant celui-ci) </li><li>  Le Lidar utilise la lumi√®re √©mise, il fonctionne donc ind√©pendamment de la lumi√®re ambiante.  De jour comme de nuit, nuageux ou ensoleill√©, le ciel est couvert ou le soleil brille - le lidar voit presque la m√™me chose dans toutes les conditions. </li><li>  Il r√©siste aux interf√©rences et a une r√©solution beaucoup plus √©lev√©e que le radar. </li><li>  Certains lidars peuvent d√©terminer la vitesse d'un objet en utilisant l'effet Doppler. </li></ul><br>  <b>Cependant, il y a des inconv√©nients:</b> <br><br><ul><li>  Au d√©part, les lidars √©taient tr√®s chers.  Les lidars haute r√©solution ont √©t√© produits en petites quantit√©s et co√ªtent plus cher que les voitures (les nouveaux mod√®les apparaissent √† un prix inf√©rieur √† 1000 $) </li><li>  R√©solution assez modeste.  Les meilleurs appareils re√ßoivent une image de 128 pixels en balayage vertical avec une fr√©quence de 10 Hz. </li><li>  La port√©e est limit√©e.  Les lidars moyens voient √† une distance de 70 √† 100 m√®tres et re√ßoivent moins de retour de gros objets comme des voitures √† une distance d'une centaine de m√®tres.  Certains pr√©tendent travailler jusqu'√† 200 m√®tres, mais cela est douteux.  Les lidars de 1,5 microns, qui sont encore plus chers, peuvent voir plus loin. </li><li>  La plupart des lidars ont des pi√®ces mobiles pour parcourir le monde.  Les lidars Flash se passent de pi√®ces mobiles, mais maintenant ils sont encore plus chers (dans les lidars √† semi-conducteurs de nouvelle g√©n√©ration, le nombre de pi√®ces mobiles est minimis√© ou compl√®tement √©limin√©). </li><li>  Le taux de rafra√Æchissement est g√©n√©ralement plus faible.  De plus, tandis que le lidar scanne la sc√®ne, il est d√©form√© en raison du mouvement des voitures scann√©es et d'autres objets, et puisque diff√©rents bords de la sc√®ne sont scann√©s √† diff√©rents moments, un d√©calage se produit. </li><li>  Les lidars peuvent rencontrer des probl√®mes avec de fortes pluies, de la neige et du brouillard, bien que d'autres capteurs de lumi√®re, y compris des cam√©ras, se comportent de la m√™me mani√®re.  Les lidars peuvent aussi parfois d√©clencher des choses invisibles comme les gaz d'√©chappement. </li><li>  Les lidars sont mieux mont√©s √† l'ext√©rieur.  Ils ont besoin de chaque photon, alors ne les affaiblissez pas en les installant derri√®re le pare-brise. </li></ul><br><h3>  Cam√©ras </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/964/c91/7af/964c917afd18e85e85164f6bf52c79f3.jpg" alt="image"></div><br><br>  Les syst√®mes bas√©s sur des cam√©ras se comportent comme des humains.  Une ou plusieurs cam√©ras observent la sc√®ne et le logiciel essaie de faire la m√™me chose qu'une personne - d'imaginer et de comprendre un monde en trois dimensions √† partir d'une image en deux dimensions. <br><br><ul><li>  Les cam√©ras sont vraiment bon march√©.  L'√©quipement ne co√ªte que des dizaines de dollars, vous pouvez en avoir beaucoup. </li><li>  √âtant donn√© que les cam√©ras sensibles √† la lumi√®re visible utilisent la lumi√®re r√©fl√©chie, elles peuvent voir une distance arbitraire pendant la journ√©e si elles ont un champ de vision assez √©troit et peuvent √™tre dirig√©es.  La nuit, ils devraient utiliser la lumi√®re transmise - comme vos phares. </li><li>  Ils voient des couleurs.  Les lidars per√ßoivent des nuances de gris dans le spectre infrarouge. </li><li>  √Ä moins que les cam√©ras ne soient guid√©es, elles ne comportent aucune pi√®ce mobile;  sinon, ils peuvent recevoir une image haute r√©solution m√™me pour des objets distants.  M√™me en acc√®s large, il existe des cam√©ras √† tr√®s haute r√©solution - tandis que le lidar voit 64 lignes, la cam√©ra en voit 3000. </li><li>  En raison de la haute r√©solution et de la couleur, les cam√©ras sont capables de tirer des conclusions sur les sc√®nes qui ne peuvent pas √™tre obtenues √† partir de l'image basse r√©solution obtenue du lidar. </li><li>  Les cam√©ras peuvent voir les feux de circulation, les dimensions, les clignotants et d'autres sources de lumi√®re √©mise.  Les appareils photo sont parfaits pour lire les caract√®res. </li></ul><br>  <b>Cependant, les cam√©ras ont certains inconv√©nients, et le premier g√¢che beaucoup:</b> <br><br><ul><li>  Aujourd'hui, la vision par ordinateur ne fonctionne pas assez bien pour d√©tecter toutes les fonctionnalit√©s importantes avec la fiabilit√© n√©cessaire pour une conduite s√ªre. </li><li>  Les cam√©ras doivent fonctionner avec un √©clairage changeant.  Les objets observ√©s sont souvent soumis au mouvement des ombres et peuvent √©galement √™tre √©clair√©s dans toutes les directions (ou pas du tout √©clair√©s). </li><li>  La nuit, les cam√©ras ont besoin d'un √©clairage suppl√©mentaire et les phares peuvent ne pas suffire. </li><li>  Les t√¢ches de vision par ordinateur n√©cessitent des processeurs hautes performances ou des puces sp√©cifiques pour fonctionner au niveau des exigences actuelles. </li></ul><br><h3>  Vision par ordinateur </h3><br>  Le traitement des images de la cam√©ra peut √™tre grossi√®rement divis√© en deux cat√©gories: ¬´vision par ordinateur¬ª et ¬´vision par ordinateur¬ª.  La vision industrielle se r√©f√®re √† une analyse simple et localis√©e d'images num√©riques.  Il comprend des t√¢ches telles que la recherche de d√©tails et de bords d'une image, la d√©termination du mouvement et de la parallaxe du mouvement, ainsi que l'application de la parallaxe aux images st√©r√©o pour d√©terminer la distance.  Ces m√©thodes sont assez bien √©tablies et nombre d'entre elles sont tout √† fait compr√©hensibles.  Certaines t√¢ches de vision industrielle (telles que la reconnaissance et la lecture des panneaux routiers) sont plus difficiles, mais seront bient√¥t r√©solues. <br><br>  La vision par ordinateur fait r√©f√©rence √† un ensemble de t√¢ches plus complexes qui n√©cessitent des comp√©tences de type humain, y compris la capacit√© de comprendre les images.  Ces t√¢ches impliquent √©galement des comp√©tences telles que la capacit√© de diviser l'image en segments et de reconna√Ætre des objets.  Vous pouvez montrer l'image d'une autre personne √† une personne qui se trouve dans presque n'importe quelle situation et sous n'importe quelle lumi√®re, et l'observateur peut facilement d√©terminer ce que la personne est dans l'image, et m√™me √† quelle distance elle se trouve.  Nous pouvons m√™me d√©terminer √† quoi l'attention est dirig√©e et ce que fait la personne repr√©sent√©e.  Les algorithmes dans ce domaine s'am√©liorent de plus en plus, mais ne sont pas encore √† un niveau suffisant. <br><br>  Certaines t√¢ches ont atteint la zone frontali√®re.  Les outils de vision industrielle recherchent les d√©tails dans l'image et le font ind√©pendamment de la taille et de l'orientation de l'image.  Cela vous permet de d√©tecter d'autres voitures, pi√©tons, limites de routes et marquages ‚Äã‚Äãroutiers.  Le probl√®me g√©n√©ral d'une identification pr√©cise est un probl√®me qui, selon beaucoup, sera finalement r√©solu, mais beaucoup plus difficile √† pr√©voir quand cela se produira.  La conduite n√©cessite que le syst√®me ¬´ne manque jamais¬ª tout ce qui pourrait √™tre un probl√®me de s√©curit√©.  Les obstacles stationnaires qui sont si √©loign√©s que l'image st√©r√©o ne fonctionne pas sont particuli√®rement difficiles et la parallaxe du mouvement (la fa√ßon dont les objets en arri√®re-plan se d√©placent par rapport aux autres objets pendant votre mouvement) est √©galement limit√©e.  (L'objet vers lequel vous vous dirigez directement, comme un pi√©ton ou une voiture debout, aura une tr√®s petite parallaxe de mouvement) <br><br>  Un autre probl√®me pour les syst√®mes de vision artificielle est la vari√©t√© d'√©clairage et d'ombrage.  Les objets peuvent √™tre √©clair√©s de n'importe quelle direction.  De plus, le soleil peut √™tre derri√®re eux.  Souvent, les ombres traversent l'objet lui-m√™me.  Dans ce cas, il sera n√©cessaire d'utiliser les technologies HDR afin de pouvoir voir les d√©tails dans chacune des zones d'image, lorsque les bordures des ombres brouillent les traits caract√©ristiques de l'objet dans l'image de contraste. <br><br>  Il existe un type sp√©cial de cam√©ra, appel√© infrarouge √† ondes longues ou ¬´thermique¬ª, qui utilise la lumi√®re √©mise plut√¥t que r√©fl√©chie.  Les objets qui sont dans l'ombre par rapport √† la lumi√®re du soleil seront toujours obscurcis dans l'image, mais il n'y aura plus d'ombres mobiles.  Les images thermiques sont monochromes et fonctionnent aussi bien de jour que de nuit, bien que la nuit le r√©sultat soit l√©g√®rement meilleur.  Ces cam√©ras sont mieux visibles dans le brouillard et dans d'autres conditions m√©t√©orologiques.  Ils peuvent tr√®s bien d√©tecter les √™tres vivants, sauf lorsque la temp√©rature de la terre est √©gale √† la temp√©rature du corps humain.  Malheureusement, les cam√©ras thermiques sont tr√®s ch√®res et les mod√®les avec une bonne r√©solution sont encore plus chers.  Ils doivent √©galement √™tre install√©s √† l'ext√©rieur car les ondes infrarouges ne traversent pas le verre.  Actuellement, il n'y a aucun rapport sur l'utilisation pratique de ces cam√©ras, cependant, certaines recherches sont en cours. <br><br>  Il existe un certain potentiel dans le domaine de l'imagerie "hyperspectrale", dans laquelle vous disposez de cam√©ras qui fonctionnent dans de nombreuses gammes de couleurs, y compris l'infrarouge et l'ultraviolet.  Avec de telles images, il sera plus facile de reconna√Ætre certains types d'objets. <br><br>  Les gens sont capables de transformer les images bidimensionnelles observ√©es en un mod√®le tridimensionnel du monde, et en m√™me temps le font beaucoup mieux apr√®s avoir examin√© la sc√®ne et observ√© la parallaxe du mouvement.  Les ordinateurs sont actuellement modestes dans l'analyse des images fixes et ne recourent qu'occasionnellement √† l'utilisation du mouvement.  Les gens utilisent des images st√©r√©o, mais ils peuvent √©galement conduire lorsqu'un ≈ìil est ferm√© ou manquant. <br><br>  √Ä son tour, le lidar peut cr√©er une carte tridimensionnelle compl√®te de la sc√®ne en un seul passage.  Plusieurs passes peuvent am√©liorer l'image - et l'aider √† appr√©cier la vitesse. <br><br><h3>  Apprentissage profond </h3><br>  La plupart de l'excitation actuelle en vision par ordinateur est associ√©e aux r√©seaux de neurones convolutifs, en particulier ceux cr√©√©s √† l'aide d'un outil appel√© Deep Learning, qui imite de nombreuses capacit√©s du cerveau biologique.  Beaucoup de gens pensent que cette direction sera une perc√©e.  Les r√©seaux d'apprentissage en profondeur fonctionnent avec un large ensemble d'apprentissage (et dans une mesure limit√©e peuvent m√™me fonctionner sans formation sp√©ciale) pour mieux comprendre la vision du monde et agir.  Les gens ont cr√©√© des robots, qui ont √©t√© conduits sur un terrain accident√© en utilisant des techniques d'apprentissage en profondeur, apr√®s quoi ces robots ont pu apprendre le mouvement dans des conditions similaires. <br><br>  C'est un travail formidable, mais nous sommes encore loin de la grande pr√©cision requise pour les v√©hicules sans pilote.  Il est √©galement troublant que lorsque nous travaillons avec l'apprentissage en profondeur, nous ne savons pas exactement pourquoi cela fonctionne, nous n'avons que le fait de travailler.  Vous pouvez recycler le r√©seau de neurones pour corriger les erreurs, mais vous ne savez pas pourquoi le recyclage a tout corrig√©.  Le m√™me inconv√©nient est √©galement caract√©ristique du cerveau humain, seule une personne peut vous expliquer pourquoi elle a agi d'une mani√®re ou d'une autre. <br><br>  Il existe diff√©rents points de vue sur la formation approfondie dans les v√©hicules sans pilote d'un point de vue juridique.  L'apprentissage automatique peut vous nuire parce que vous ne comprenez pas comment cela fonctionne, et il peut √™tre utile parce que vous avez appliqu√© les meilleures techniques avec de bons indicateurs de s√©curit√© et que vous n'avez commis aucune erreur pouvant √™tre qualifi√©e de b√¢cl√©e. <br><br>  L'apprentissage automatique a tendance √† am√©liorer la qualit√© du travail avec une augmentation de la quantit√© de donn√©es de formation, c'est pourquoi de si grands efforts sont faits pour cr√©er de grands volumes de ces donn√©es.  Cependant, les r√©seaux de neurones ne sont pas en mesure de reconna√Ætre des choses qu'ils n'ont jamais vues (ou vu des objets similaires). <br><br><h3>  Autres capteurs </h3><br>  Le plus important des autres capteurs est le radar.  Le radar pr√©sente des avantages fantastiques.  Premi√®rement, il voit bien √† travers le brouillard, alors que les capteurs optiques ne peuvent pas y faire face.  Deuxi√®mement, il voit bien les autres voitures et chaque coup de radar donne des informations non seulement sur la distance, mais aussi sur la vitesse, gr√¢ce √† l'effet Doppler.  C'est encore plus que les informations du lidar - un coup de radar montre tous les obstacles en mouvement et leur vitesse.  Le radar peut √©valuer les r√©flexions de la route sous la voiture ou le camion devant vous et donner des informations sur les actions de la voiture dans la zone aveugle du camion - c'est une astuce tr√®s intelligente. <br><br>  Les radars offrent une r√©solution beaucoup plus faible.  Il existe des radars exp√©rimentaux √† haute r√©solution, mais ils n√©cessitent un large spectre radio (plage de fr√©quences) - plus que ce que produisent les r√©gulateurs.  Il est peu probable que le radar vous indique si la cible est sur votre voie ou non, ou si elle est sur un survol ou sur la route devant vous. <br><br>  Les objets fixes refl√®tent √©galement les signaux radar, et c'est un probl√®me.  Terre, signes, cl√¥tures - ils renvoient tous des signaux indiquant qu'ils sont des objets statiques.  Ainsi, lorsqu'une voiture debout refl√®te un signal radar, vous ne pouvez pas √™tre s√ªr qu'il s'agit d'un panneau routier ou d'une voiture gar√©e dessus.  La plupart des autoradios ignorent simplement les reflets d'objets statiques, ce qui est l'une des raisons pour lesquelles le r√©gulateur de vitesse automatique n'a pas fonctionn√© pendant longtemps dans les flux de circulation, dans lesquels vous devez souvent gazer et freiner. <br><br>  √Ä la suite de nouvelles recherches, un radar √† plus haute r√©solution a √©t√© cr√©√©, et des recherches sont √©galement en cours pour reconna√Ætre les objets par leurs caract√©ristiques dans leurs r√©flexions.  Les radars num√©riques √† r√©seau phas√© peuvent inspecter la sc√®ne et augmenter la r√©solution d'un degr√©.  Ce n'est pas suffisant, mais c'est d√©j√† une am√©lioration. <br><br><h3>  Association des capteurs </h3><br>  Lorsque vous utilisez plusieurs capteurs, vous souhaitez combiner toutes les donn√©es afin de comprendre que la machine d√©tect√©e par le radar est la m√™me que la cam√©ra ou le lidar.  Cela am√©liore la qualit√© des donn√©es re√ßues, mais cela peut √©galement nuire.  La combinaison de capteurs n'est pas fiable √† 100%.  Que ferez-vous si le radar montre qu'il y a une voiture devant et que la cam√©ra consid√®re qu'elle ne l'est pas (ou vice versa)?  Vous devrez choisir quoi croire.  Si le choix est incorrect, un probl√®me peut survenir.  Si vous croyez au message sur l'obstacle, vous pouvez r√©duire la c√©cit√© (ce qui est tr√®s important), mais vous pouvez prendre en compte les obstacles inexistants des deux capteurs.  Parfois, vous obtenez le meilleur des deux mondes, et parfois le pire. <br><br>  Malgr√© cela, puisque tous les capteurs ont diverses limites, l'int√©gration des capteurs reste l'objectif principal de la plupart des √©quipes impliqu√©es dans les robots. <br><br>  La combinaison de capteurs peut √™tre effectu√©e sans complications, si chaque capteur s'adapte mieux √† une t√¢che sp√©cifique ou √† un champ de vision distinct.  Ensuite, vous faites confiance aux capteurs pour le travail qu'ils font le mieux. <br><br>  (Il convient de noter qu'une bonne combinaison de capteurs est effectu√©e en tenant compte des donn√©es brutes de tous les capteurs - vous ne prenez pas simplement des d√©cisions bas√©es sur le fait que la voiture est pr√©sente dans les donn√©es radar, mais pas dans les donn√©es de la cam√©ra. N√©anmoins, de nombreux objets seront affich√©s en un seul l'ensemble de donn√©es du capteur est plus clair que dans un autre.) <br><br><h3>  Positionnement </h3><br>  ,       (,     ).      ,           3D,          ,         . <br><br>         GPS,            .                . GPS          ( GPS     ),      . <br><br><h3> , ,   ,  ? </h3><br>       ,  .    ? <br><br>                2020        .   ‚Äì         . <br><br>     .   ,        Velodyne  75 000 $,       32     .      .   ,    ,   1982 5-   3000 $,   ,            .  ,           ,      ,           . <br><br>           ,      .    ,    ,    ,       .     ,     ,        .            ,     , <br><br> ,              ,    . <br><br>      .      ,             ,      .  ,                      . <br><br>   MobilEye,      Intel, (, ,         ),   ,    ,   ,       .    4  ,        . <br><br>      ,        .    ,        ,     .        ,            .     . <br><br>  ,     .      ,       .  ,         ,   ,  VisLab  ,  ,       ,  Mercedes 6D   MobilEye,    . <br><br>     ,      ,     ,      ,    ‚Äì     .      ,            . <br><br>      ,    ,        ,      .  ,       ,         ,   . <br><br>         ,       ‚ÄúSuper Cruise‚Äù,               ,     .   (     ,     )   ,     .       ,     ,    ,   ,      . <br><br>           ,     ‚Äì    .       ,        .     99% ,    99%  99.9999%      .     .  ,      ,      ,    . <br><br>           .    ,      ,     ,    ,       .  ,   -        .   ,      10-20%   ,      , -      ,   ,       . ,    ,   ,         ,           ,    ,     . <br><br>    - ,  - .       ,     ,     100 000 $,       3000 $   . <br><br><h3>    ? </h3><br>  ,      ,  ,       . <br><br>     ,   .  ,  400 000     .       170     290    .  ,        3  ,      6000 .       ,     . <br><br> ,          . ,             -  ( 80%    ,     ). -       .       ,        .       -   ,      ,        ‚Äì    ,    .   -    ,   ,      , . <br><br> ,      ,   .           ,     .         ,     ,        .                 .            . <br><br>     ,         ,  , ,        ,    .        ,  ,    ,                .  -      ,      ,  ,     ‚Äì     .            ,    . <br><br>        .             ,  , ,    . <br><br>          .       ,   .      ,      .     ( ,    ) - . <br><br>         ,          ,    ,      .      ,       ,       ,      .                  ,  -   . <br><br>  ,     ,        ,        .        ,     .          ,    ,       (   ),   , ,            .       -     ,    ,         . <br><br>   ,          . ,    ‚Äú ‚Äù   ,      40 /.         ,         3D,            . <br><br> ,   ,          (  Microsoft Kinect).      3D,        ,     ,  . <br><br><h3>             </h3><br>              ,  ,       .     ,           .    ,       ‚Äì        . <br><br>  ,   ,     ,    .  ,       .     ,       .                        ,   ,    .      .     ,         ,     ,  .     ,   .  ,   99.9%    ,   ,     ,      ,     ,       .          ,   . <br><br>           ,    ,  -     .   ,         ,   .     -  ‚Äì   ,       .      ,      99.99999%,    . <br><br>  ,      ,          .       ,          .   ,  1   10 000  100 000      ,             -,     . <br><br>  ,   -,    2017  2019 ,      .  ‚Äì    ,    .     ,     ,  ,  ,     .  ,       ,          .    ,     ,         . <br><br> ,  2020,               ,          ,  , ,      . <br><br>      ( 25 /)     ,       . <br><br>   ,    ,    ,   ‚Äì  ,      ? <br><br><h3>  Tesla </h3><br> ,  Tesla   ,   ‚Äú‚Äù  ,   ‚Äú‚Äù.        8   ,     :        .  ,        ,    .    ,    ,             . <br><br> Tesla ,        ,          ,      .    ,     ,  ,      ,        .  ,       - ,            . <br><br><h3>  </h3><br> ,     ,    <a href="https://en.wikipedia.org/wiki/Lidar"></a> . Velodyne,    ,   ,     64   .    10       .        905  (,    )      . Velodyne      32     16   10 000 $. <br><br>    ,          . , ,  ,   ,          ,     . <br><br>       .  ‚Äì        ,   .      ,    , , ,   DVD.   ,       ,     . <br><br>    .  16-   Velodyne   10 000 $. Quanergy,    ,    8                  . Valeo/IBEO    250   4 ,   , Velodyne ,             300 .    . <br><br> <b>    ,   :</b> <br><br><ul><li>         ,    ,      ,      .        .        360 ,    Velodyne   .  ,    ,     . </li><li> Les lidars flash envoient un flash lumineux sur toute la zone, puis il est re√ßu par un ensemble de capteurs et de minuteries qui peuvent prendre une photo de la sc√®ne enti√®re √† la fois.  Il y a de nombreux avantages √† cette conception - il n'y a pas de pi√®ces mobiles et vous n'obtiendrez pas d'artefacts de mouvement, car le monde et le capteur bougent pendant le balayage.  Dans le lidar √† balayage, tous les objets sont √©tir√©s et d√©form√©s car ils se d√©placent par rapport au capteur.  Un lidar flash est tr√®s cher aujourd'hui - il a besoin d'une puce de capteur sp√©ciale, et l'impulsion doit √™tre extr√™mement puissante pour √©clairer tout le champ de vision √† la fois. </li><li>  Les microscanners sont des miroirs mobiles ultra-minces fabriqu√©s √† base de puces de silicium.  C'est ainsi que la plupart des projecteurs vid√©o fonctionnent.  Bien qu'il y ait des pi√®ces mobiles, elles sont tr√®s petites et peuvent √™tre tr√®s l√©g√®res et durables.  Certains lidars √† courte port√©e ont √©t√© construits √† l'aide de cette technologie. </li><li>  Si vous utilisez de la lumi√®re dans la plage de 1,5 microns (infrarouge de milieu de gamme), l'≈ìil humain ne la focalise plus.  Cela signifie que vous pouvez envoyer des impulsions beaucoup plus lumineuses sans causer de dommages, ce qui signifie que vous pouvez voir √† une plus grande distance.  La mauvaise nouvelle est que la lumi√®re de 1,5 micron ne d√©clenche pas le silicium, ce qui signifie que vous devez utiliser d'autres types d'√©lectronique, des technologies qui n'ont pas le faible co√ªt de production √† grande √©chelle, comme le silicium.  Ainsi, les lidars de 1,5 microns sont tr√®s chers pour le moment. </li><li>  Certains lidars sp√©ciaux ont √©t√© faits pour voir plus loin, et ils utilisent m√™me l'effet Doppler, afin qu'ils sachent √† quelle vitesse l'objet qu'ils suivent se d√©place.  Cela est difficile √† faire dans les couvercles √† usage g√©n√©ral √† haute r√©solution. </li><li>  Certaines cam√©ras √† temps de vol √©tudient la lumi√®re avec une onde porteuse et observent les changements de phase des r√©flexions de retour pour mesurer le temps.  Ces cam√©ras peuvent √™tre tr√®s peu co√ªteuses, mais ont une port√©e et un bruit faibles lors de la mesure des distances. </li></ul><br><hr><br><img src="https://habrastorage.org/webt/4m/5z/_p/4m5z_pc9zhjja8pmtwxvaihckfe.png" alt="image"><br><br><div class="spoiler">  <b class="spoiler_title">√Ä propos d'ITELMA</b> <div class="spoiler_text">  Nous sommes une grande entreprise de composants <a href="https://en.wikipedia.org/wiki/Automotive_industry">automobiles</a> .  L'entreprise emploie environ 2 500 personnes, dont 650 ing√©nieurs. <br><br>  Nous sommes peut-√™tre le centre de comp√©tences le plus puissant de Russie pour le d√©veloppement de l'√©lectronique automobile en Russie.  Maintenant, nous sommes en pleine croissance et nous avons ouvert de nombreux postes vacants (environ 30, y compris dans les r√©gions), tels qu'un ing√©nieur logiciel, un ing√©nieur de conception, un ing√©nieur de d√©veloppement principal (programmeur DSP), etc. <br><br>  Nous avons de nombreux d√©fis int√©ressants de la part des constructeurs automobiles et des pr√©occupations qui animent l'industrie.  Si vous souhaitez √©voluer en tant que sp√©cialiste et apprendre des meilleurs, nous serons heureux de vous voir dans notre √©quipe.  Nous sommes √©galement pr√™ts √† partager l'expertise, la chose la plus importante qui se passe dans l'automobile.  Posez-nous des questions, nous r√©pondrons, nous discuterons. </div></div><br>  <b>Lisez d'autres articles utiles:</b> <br><br><ul><li>  <a href="https://habr.com/ru/company/itelma/blog/478640/">Voitures autonomes sur open source</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/478376/">Les voitures autonomes prennent en compte le niveau d'√©go√Øsme des personnes</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476824/">McKinsey: repenser l'architecture logicielle et √©lectronique de l'automobile</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476054/">Une autre guerre des OS est d√©j√† sous le capot des voitures</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475576/">Code de programme dans la voiture</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475448/">Il y a plus de lignes de code dans une voiture moderne que ...</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr479736/">https://habr.com/ru/post/fr479736/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr479718/index.html">Cr√©ation d'une application d'environnement Arduino √† l'aide de CI Github</a></li>
<li><a href="../fr479724/index.html">Les pirates informatiques sont termin√©s</a></li>
<li><a href="../fr479726/index.html">Vladimir aka wowik: ¬´OpenStreetMap a besoin d'id√©es irr√©alisables dans d'autres syst√®mes¬ª</a></li>
<li><a href="../fr479728/index.html">Comment organiser une startup r√©ussie?</a></li>
<li><a href="../fr479732/index.html">Arr√™tez d'√©mettre autre chose comme une fuite de m√©moire</a></li>
<li><a href="../fr479738/index.html">Comme Youtube et Instagram: internationaliser et localiser une application Python</a></li>
<li><a href="../fr479742/index.html">Backyards - un maillage de services automatis√© au-dessus d'une infrastructure multicloud et hybride</a></li>
<li><a href="../fr479744/index.html">Gestion de la m√©moire Python: un peu sur la fragmentation de la m√©moire</a></li>
<li><a href="../fr479746/index.html">Le logiciel d'entreprise rend vos employ√©s plus cool. En avez-vous besoin?</a></li>
<li><a href="../fr479748/index.html">GoLand 2019.3 avec des performances am√©lior√©es, une prise en charge am√©lior√©e des modules Go et plus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úåüèø üßöüèΩ ü§±üèª Visualizaci√≥n de traducci√≥n autom√°tica neural (modelos seq2seq con mecanismo de atenci√≥n) üöÉ üë®üèº‚Äçüíº ‚úãüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! Les presento la traducci√≥n del art√≠culo "Visualizando un modelo de traducci√≥n autom√°tica neuronal (Mec√°nica de modelos Seq2seq con atenci√≥n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Visualizaci√≥n de traducci√≥n autom√°tica neural (modelos seq2seq con mecanismo de atenci√≥n)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/486158/"><p>  Hola Habr!  Les presento la traducci√≥n del art√≠culo <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="nofollow">"Visualizando un modelo de traducci√≥n autom√°tica neuronal (Mec√°nica de modelos Seq2seq con atenci√≥n)"</a> por Jay Alammar. </p><br><p>  Los modelos de secuencia a secuencia (seq2seq) son modelos de aprendizaje profundo que han logrado un gran √©xito en tareas como traducci√≥n autom√°tica, resumen de texto, anotaci√≥n de im√°genes, etc. Por ejemplo, a fines de 2016, <a href="https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/" rel="nofollow">se incorpor√≥</a> un modelo similar en Google Translate.  Las bases de los modelos seq2seq se establecieron en 2014 con el lanzamiento de dos art√≠culos: <a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" rel="nofollow">Sutskever et al., 2014</a> , <a href="http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf" rel="nofollow">Cho et al., 2014</a> . </p><br><p> Para comprender lo suficiente y luego usar estos modelos, primero deben aclararse algunos conceptos.  Las visualizaciones propuestas en este art√≠culo ser√°n un buen complemento para los art√≠culos mencionados anteriormente. </p><br><p>  El modelo de secuencia a secuencia es un modelo que acepta una secuencia de entrada de elementos (palabras, letras, atributos de imagen, etc.) y devuelve otra secuencia de elementos.  El modelo entrenado funciona de la siguiente manera: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/seq2seq_1.mp4" type="video/mp4"></video></div></div></div><a name="habracut"></a><br><p>  En la traducci√≥n autom√°tica neuronal, una secuencia de elementos es una colecci√≥n de palabras que se procesan a su vez.  La conclusi√≥n tambi√©n es un conjunto de palabras: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/seq2seq_2.mp4" type="video/mp4"></video></div></div></div><br><h1 id="zaglyanem-pod-kapot">  Echa un vistazo debajo del cap√≥ </h1><br><p>  Debajo del cap√≥, el modelo tiene un codificador y decodificador. </p><br><p>  El codificador procesa cada elemento de la secuencia de entrada, traduce la informaci√≥n recibida en un vector llamado contexto.  Despu√©s de procesar toda la secuencia de entrada, el codificador env√≠a el contexto al decodificador, que luego comienza a generar la secuencia de salida elemento por elemento. </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/seq2seq_3.mp4" type="video/mp4"></video></div></div></div><br><p>  Lo mismo sucede con la traducci√≥n autom√°tica. </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/seq2seq_4.mp4" type="video/mp4"></video></div></div></div><br><p>  Para la traducci√≥n autom√°tica, el contexto es un vector (una matriz de n√∫meros), y el codificador y el decodificador, a su vez, son redes neuronales recurrentes (consulte la introducci√≥n a RNN: <a href="https://www.youtube.com/watch%3Fv%3DUNmqTiOnRfg" rel="nofollow">una introducci√≥n amigable a las redes neuronales recurrentes</a> ). </p><br><p><img src="https://habrastorage.org/webt/yr/ir/92/yrir92d8paf_xdm29bovaw109gu.png" alt="contexto"></p><br><p>  <em>El contexto es un vector de n√∫meros de coma flotante.</em>  <em>Adem√°s en el art√≠culo, los vectores se visualizar√°n en color para que el color m√°s claro corresponda a celdas con valores grandes.</em> </p><br><p>  Al entrenar el modelo, puede establecer el tama√±o del vector de contexto: el n√∫mero de neuronas ocultas (unidades ocultas) en el codificador RNN.  Los datos de visualizaci√≥n muestran un vector de 4 dimensiones, pero en aplicaciones reales el vector de contexto tendr√° una dimensi√≥n del orden de 256, 512 o 1024. </p><br><p>  Por defecto, en cada intervalo de tiempo, RNN recibe dos elementos para la entrada: el elemento de entrada en s√≠ (en el caso de un codificador, una palabra de la oraci√≥n original) y el estado oculto.  La palabra, sin embargo, debe estar representada por un vector.  Para convertir una palabra en un vector, recurren a una serie de algoritmos llamados incrustaciones de palabras.  Las incrustaciones traducen palabras en espacios vectoriales que contienen informaci√≥n sem√°ntica y sem√°ntica sobre ellas (por ejemplo, <a href="http://p.migdal.pl/2017/01/06/king-man-woman-queen-why.html" rel="nofollow">"rey" - "hombre" + "mujer" = "reina"</a> ). </p><br><p><img src="https://habrastorage.org/webt/87/pp/s9/87pps99ndmgvp6gqxskkodf4zl4.png" alt="incrustaci√≥n"></p><br><p>  <em>Antes de procesar palabras, debe convertirlas en vectores.</em>  <em>Esta transformaci√≥n se lleva a cabo utilizando el algoritmo de inclusi√≥n de palabras.</em>  <em>Puede utilizar incrustaciones pre-entrenadas y entretejidas en su conjunto de datos.</em>  <em>200-300 - dimensi√≥n t√≠pica del vector de incrustaci√≥n;</em>  <em>Este art√≠culo utiliza la dimensi√≥n 4 por simplicidad.</em> </p><br><p>  Ahora que nos hemos familiarizado con nuestros principales vectores / tensores, recordemos el mecanismo de RNN y creemos visualizaciones para describirlo: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/RNN_1.mp4" type="video/mp4"></video></div></div></div><br><p>  En el siguiente paso, RNN toma el segundo vector de entrada y el estado latente # 1 para formar la salida en este intervalo de tiempo.  M√°s adelante en el art√≠culo, se usa una animaci√≥n similar para describir vectores dentro de un modelo de traducci√≥n autom√°tica neuronal. </p><br><p>  En la siguiente visualizaci√≥n, cada cuadro describe el procesamiento de entradas por un codificador y la generaci√≥n de salidas por un decodificador en un intervalo de tiempo.  Dado que tanto el codificador como el decodificador son RNN, en cada intervalo de tiempo, la red neuronal est√° ocupada procesando y actualizando sus estados ocultos en funci√≥n de las entradas actuales y anteriores.  En este caso, el √∫ltimo de los estados ocultos del codificador es el contexto mismo que se transmite al decodificador. </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/seq2seq_5.mp4" type="video/mp4"></video></div></div></div><br><p>  El decodificador tambi√©n contiene estados ocultos que transfiere de un intervalo de tiempo a otro.  (Esto no est√° en la visualizaci√≥n, representando solo las partes principales del modelo). </p><br><p>  Ahora pasamos a otro tipo de visualizaci√≥n de modelos de secuencia a secuencia.  Esta animaci√≥n ayudar√° a comprender los gr√°ficos est√°ticos que describen estos modelos, los llamados  una vista desenrollada, donde en lugar de mostrar un decodificador, mostramos una copia para cada intervalo de tiempo.  Entonces podemos mirar los elementos de entrada y salida en cada intervalo de tiempo. </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/seq2seq_6.mp4" type="video/mp4"></video></div></div></div><br><h1 id="obratite-vnimanie">  ¬°Presta atenci√≥n! </h1><br><p>  El vector de contexto es un cuello de botella para este tipo de modelo, lo que les dificulta lidiar con oraciones largas.  La soluci√≥n fue propuesta en art√≠culos de <a href="" rel="nofollow">Bahdanau et al., 2014</a> y <a href="https://arxiv.org/abs/1508.04025" rel="nofollow">Luong et al., 2015</a> , que presentaron una t√©cnica llamada mecanismo de atenci√≥n.  Este mecanismo mejora significativamente la calidad de los sistemas de traducci√≥n autom√°tica, permitiendo que los modelos se concentren en las partes relevantes de las secuencias de entrada. </p><br><p><img src="https://habrastorage.org/webt/b1/ru/kj/b1rukj6w-dgtyfncd3a62635zb0.png" alt="atencion"></p><br><p>  <em>En el s√©ptimo per√≠odo de tiempo, el mecanismo de atenci√≥n permite al decodificador enfocarse en la palabra √©tudiant (estudiante en franc√©s) antes de generar una traducci√≥n al ingl√©s.</em>  <em>Esta capacidad de amplificar la se√±al de la parte relevante de la secuencia de entrada permite que los modelos basados ‚Äã‚Äãen el mecanismo de atenci√≥n obtengan un mejor resultado en comparaci√≥n con otros modelos.</em> </p><br><p>  Cuando se considera un modelo con un mecanismo de atenci√≥n a un alto nivel de abstracci√≥n, se pueden distinguir dos diferencias principales del modelo cl√°sico de secuencia a secuencia. </p><br><p>  En primer lugar, el codificador transfiere significativamente m√°s datos al decodificador: en lugar de transmitir solo el √∫ltimo estado oculto despu√©s de la etapa de codificaci√≥n, el codificador le env√≠a todos sus estados ocultos: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/seq2seq_7.mp4" type="video/mp4"></video></div></div></div><br><p>  En segundo lugar, el decodificador pasa por un paso adicional antes de generar la salida.  Para enfocarse en aquellas partes de la secuencia de entrada que son relevantes para el lapso de tiempo correspondiente, el decodificador hace lo siguiente: </p><br><ol><li>  Examina un conjunto de estados latentes recibidos de un codificador: cada uno de los estados latentes se correlaciona mejor con una de las palabras en la secuencia de entrada; </li><li>  Asigna una determinada evaluaci√≥n a cada estado latente (omita por ahora c√≥mo ocurre el procedimiento de estimaci√≥n); </li><li>  Multiplica cada estado oculto por una funci√≥n de evaluaci√≥n convertida por softmax, resaltando as√≠ los estados ocultos con una calificaci√≥n grande y relegando los estados ocultos con uno peque√±o al fondo. </li></ol><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/attention_process.mp4" type="video/mp4"></video></div></div></div><br><p>  Este "ejercicio de calificaci√≥n" se realiza en el decodificador en cada intervalo de tiempo. </p><br><p>  Entonces, resumiendo todo lo anterior, consideramos el proceso del modelo con el mecanismo de atenci√≥n: </p><br><ol><li>  En el decodificador, el RNN recibe la incorporaci√≥n &lt;END&gt; del token y el estado oculto inicial. </li><li>  El RNN procesa el elemento de entrada, genera la salida y un nuevo vector de estado oculto (h4).  La salida se descarta. </li><li>  El mecanismo de atenci√≥n utiliza los estados ocultos del codificador y el vector h4 para calcular el vector de contexto (C4) en un intervalo de tiempo dado. </li><li>  Los vectores h4 y C4 se concatenan en un solo vector. </li><li>  Este vector se pasa a trav√©s de una red neuronal de alimentaci√≥n directa (FFN), entrenada junto con el modelo. </li><li>  La salida de la red FFN indica la palabra de salida en un intervalo de tiempo dado. </li><li>  El algoritmo se repite para el siguiente intervalo de tiempo. </li></ol><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/attention_tensor_dance.mp4" type="video/mp4"></video></div></div></div><br><p>  Otra forma de ver en qu√© parte de la oraci√≥n original se enfoca el modelo en cada etapa del decodificador: </p><br><div class="oembed"><div><div style="left: 0; width: 100%; height: 0; position: relative; padding-bottom: 56.25%;"><video controls="" style="top: 0; left: 0; width: 100%; height: 100%; position: absolute;">  Su navegador no admite video HTML5. <source src="https://jalammar.github.io/images/seq2seq_9.mp4" type="video/mp4"></video></div></div></div><br><p>  Tenga en cuenta que el modelo no solo conecta sin pensar la primera palabra en la entrada con la primera palabra en la salida.  Ella realmente entendi√≥ durante el proceso de capacitaci√≥n c√≥mo unir las palabras en este par de idiomas considerado (en nuestro caso, franc√©s e ingl√©s).  Un ejemplo de la precisi√≥n con que puede funcionar este mecanismo se puede encontrar en los art√≠culos sobre el mecanismo de atenci√≥n mencionados anteriormente. </p><br><p><img src="https://habrastorage.org/webt/cl/dv/9f/cldv9f7zdegsobuszn10hyy1nde.png" alt="atenci√≥n"></p><br><p>  Si cree que est√° listo para aprender c√≥mo aplicar este modelo, consulte el manual de <a href="https://github.com/tensorflow/nmt" rel="nofollow">Traducci√≥n Neural Autom√°tica (seq2seq)</a> en TensorFlow. </p><br><h1 id="avtory">  Los autores </h1><br><ul><li>  <strong>Original</strong> de <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="nofollow">Jay Alammar</a> </li><li>  <strong>Traducci√≥n</strong> - <a href="https://habr.com/ru/users/smekur/">Ekaterina Smirnova</a> </li><li>  <strong>Edici√≥n y maquetaci√≥n</strong> - <a href="https://habr.com/ru/users/kouki_rus/">Shkarin Sergey</a> </li></ul></div></div><p>Source: <a href="https://habr.com/ru/post/486158/">https://habr.com/ru/post/486158/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../486124/index.html">Impala vs Hive vs Spark SQL: elegir el motor SQL correcto para que funcione correctamente en el almac√©n de datos de Cloudera</a></li>
<li><a href="../486128/index.html">Arquitecto de soluciones de prueba: qui√©n es y cu√°ndo se necesita</a></li>
<li><a href="../486144/index.html">¬øPor qu√© mueren las monedas alternativas y qu√© puede suceder con la criptomoneda en el futuro cercano?</a></li>
<li><a href="../486150/index.html">Desarrollo de la esfera inform√°tica en Eslovaquia. Beneficios laborales para j√≥venes profesionales.</a></li>
<li><a href="../486156/index.html">Como ense√±√©, y luego escrib√≠ un manual de entrenamiento en Python</a></li>
<li><a href="../486164/index.html">Coronavirus 2019-nCoV. Preguntas frecuentes sobre protecci√≥n respiratoria y desinfecci√≥n</a></li>
<li><a href="../486174/index.html">Tengo cero rotaci√≥n</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
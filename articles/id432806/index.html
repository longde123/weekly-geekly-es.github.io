<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>â›²ï¸ âš«ï¸ ğŸš¬ Superintelligence: sebuah ide yang menghantui orang pintar ğŸ ğŸ§‘ğŸ¾â€ğŸ¤â€ğŸ§‘ğŸ» ğŸ‘¨â€ğŸ”§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Interpretasi pidato di konferensi Web Camp Zagreb Maciej Tseglovsky, seorang pengembang web Amerika, pengusaha, pembicara dan kritik sosial yang beras...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Superintelligence: sebuah ide yang menghantui orang pintar</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/432806/"><img src="https://habrastorage.org/getpro/habr/post_images/6e3/91b/4f1/6e391b4f1772fd49d6c836bc87ffd343.jpg"><br><br>  <i>Interpretasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pidato di konferensi</a> Web Camp Zagreb Maciej Tseglovsky, seorang pengembang web Amerika, pengusaha, pembicara dan kritik sosial yang berasal dari Polandia.</i> <br><br>  Pada tahun 1945, ketika fisikawan Amerika bersiap untuk menguji bom atom, terpikir oleh seseorang untuk bertanya apakah tes seperti itu dapat menyalakan atmosfer. <br><br>  Ketakutan itu bisa dibenarkan.  Nitrogen yang membentuk sebagian besar atmosfer tidak stabil secara energetik.  Jika dua atom bertabrakan cukup kuat, mereka akan berubah menjadi atom magnesium, partikel alfa dan melepaskan energi besar: <br><br>  N <sup>14</sup> + N <sup>14</sup> â‡’ Mg <sup>24</sup> + Î± + 17.7 MeV <br><br>  Sebuah pertanyaan vital adalah apakah reaksi ini bisa menjadi mandiri.  Suhu di dalam bola ledakan nuklir seharusnya melebihi semua yang pernah diamati di Bumi.  Mungkinkah kita melemparkan korek api ke tumpukan daun kering? <br><a name="habracut"></a><br>  Fisikawan dari Los Alamos melakukan analisis dan memutuskan bahwa margin keselamatan memuaskan.  Karena kita semua datang ke konferensi hari ini, kita tahu bahwa mereka benar.  Mereka yakin dengan prediksi mereka, karena undang-undang yang mengatur reaksi nuklir bersifat langsung dan terkenal. <br><br>  Hari ini kami sedang menciptakan teknologi lain yang mengubah dunia - kecerdasan mesin.  Kita tahu bahwa itu akan memiliki dampak luar biasa pada dunia, mengubah cara ekonomi bekerja, dan memicu efek domino yang tidak terduga. <br><br>  Tetapi ada juga risiko reaksi yang tidak terkendali, di mana AI akan dengan cepat mencapai dan melampaui tingkat kecerdasan manusia.  Dan pada saat ini, masalah sosial dan ekonomi akan membuat kita khawatir.  Mesin ultra-pintar mana pun akan memiliki hypergoals sendiri, dan akan bekerja untuk mencapainya dengan memanipulasi orang, atau hanya menggunakan tubuh mereka sebagai sumber sumber daya yang nyaman. <br><br>  Tahun lalu, filsuf Nick Bostrom merilis buku Superintelligence, di mana ia menggambarkan pandangan AI yang mengkhawatirkan dan mencoba membuktikan bahwa ledakan kecerdasan semacam itu berbahaya dan tidak terhindarkan, jika Anda mengandalkan beberapa asumsi moderat. <br><br>  Komputer yang mengambil alih dunia adalah topik favorit NF.  Namun, cukup banyak orang yang menganggap skenario ini serius, jadi kita harus menanggapinya dengan serius.  Stephen Hawking, Elon Musk, sejumlah besar investor dan miliarder Lembah Silikon menganggap argumen ini meyakinkan. <br><br>  Ijinkan saya menguraikan prasyarat yang diperlukan untuk membuktikan argumen Bostrom. <br><br><h2>  Latar belakang </h2><br><h3>  Prasyarat 1: Gagasan Bekerja </h3><br>  Premis pertama adalah pengamatan sederhana tentang keberadaan pikiran yang berpikir.  Masing-masing dari kita membawa sekotak kecil daging berfikir.  Saya menggunakan milik saya untuk berbicara, Anda menggunakan milik saya untuk mendengarkan.  Terkadang, dalam kondisi yang tepat, pikiran ini dapat berpikir secara rasional. <br><br>  Jadi kita tahu bahwa pada prinsipnya ini mungkin. <br><br><h3>  Prasyarat 2: tidak ada masalah kuantum </h3><br>  Premis kedua mengatakan bahwa otak adalah konfigurasi materi yang biasa, meskipun sangat kompleks.  Jika kita cukup tahu tentang hal itu dan kita memiliki teknologi yang tepat, kita dapat secara akurat menyalin strukturnya dan meniru perilakunya menggunakan komponen elektronik, sama seperti hari ini kita dapat mensimulasikan anatomi neuron yang sangat sederhana. <br><br>  Dengan kata lain, premis ini mengatakan bahwa kesadaran muncul menggunakan fisika biasa.  Beberapa orang, seperti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Roger Penrose</a> , akan menentang argumen ini, percaya bahwa sesuatu yang tidak biasa sedang terjadi di otak pada tingkat kuantum. <br><br>  Jika Anda religius, Anda dapat percaya bahwa otak tidak dapat bekerja tanpa jiwa. <br><br>  Tetapi bagi kebanyakan orang, premis ini mudah diterima. <br><br><h3>  Prasyarat 3: banyak kemungkinan pikiran. </h3><br>  Premis ketiga adalah bahwa ruang semua pikiran yang mungkin adalah besar. <br><br>  Tingkat kecerdasan kita, kecepatan berpikir, serangkaian distorsi kognitif, dll.  tidak ditentukan sebelumnya, tetapi merupakan artefak dari sejarah evolusi kita.  Secara khusus, tidak ada hukum fisik yang membatasi kecerdasan pada tingkat manusia. <br><br>  Adalah baik untuk membayangkan contoh dari apa yang terjadi di alam ketika mencoba untuk memaksimalkan kecepatan.  Jika Anda bertemu dengan seekor cheetah di masa pra-industri (dan Anda selamat), Anda dapat memutuskan bahwa tidak ada yang bisa bergerak lebih cepat. <br><br>  Tetapi kita, tentu saja, tahu bahwa ada semua jenis konfigurasi materi, misalnya, sepeda motor yang dapat bergerak lebih cepat daripada seekor cheetah, dan bahkan terlihat lebih curam daripada itu.  Namun, tidak ada jalur evolusi langsung ke sepeda motor.  Evolusi pertama-tama harus menciptakan manusia yang telah menciptakan segala macam hal berguna. <br><br>  Dengan analogi, mungkin ada pikiran yang jauh lebih pintar daripada kita, tetapi tidak dapat diakses selama evolusi di Bumi.  Ada kemungkinan bahwa kita dapat membuat mereka, atau menciptakan mesin yang dapat menciptakan mesin yang dapat membuatnya. <br><br>  Mungkin ada batas alami untuk kecerdasan, tetapi tidak ada alasan untuk percaya bahwa kita dekat dengannya.  Mungkin kecerdasan paling pintar mungkin dua kali lebih pintar dari manusia, dan mungkin enam puluh ribu. <br><br>  Pertanyaan ini bersifat empiris, dan kami tidak tahu bagaimana menjawabnya. <br><br><h3>  Premis 4: ada banyak ruang di atas </h3><br>  Premis keempat adalah bahwa komputer masih penuh peluang untuk menjadi lebih cepat dan lebih kecil.  Anda dapat mengasumsikan bahwa hukum Moore melambat - tetapi untuk premis ini cukup untuk percaya bahwa besi lebih kecil dan lebih cepat pada prinsipnya memungkinkan, hingga beberapa kali lipat. <br><br>  Dari teori diketahui bahwa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">batas</a> fisik <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perhitungannya</a> cukup tinggi.  Kita dapat menggandakan angka selama beberapa dekade, sampai kita menemukan batas fisik yang mendasar, dan bukan batas ekonomi atau politik hukum Moore. <br><br><h3>  Premis 5: skala waktu komputer </h3><br>  Premis kedua dari belakang adalah bahwa jika kita berhasil menciptakan AI, apakah itu emulasi otak manusia atau beberapa perangkat lunak khusus, ia akan bekerja pada skala waktu karakteristik elektronik (mikrodetik), dan bukan untuk manusia (jam) . <br><br>  Untuk mencapai keadaan di mana saya dapat membuat laporan ini, saya harus dilahirkan, tumbuh, pergi ke sekolah, universitas, hidup sedikit, terbang ke sini, dan seterusnya.  Komputer dapat berjalan puluhan ribu kali lebih cepat. <br><br>  Secara khusus, orang dapat membayangkan bahwa pikiran elektronik dapat mengubah sirkuitnya (atau perangkat keras tempat ia bekerja), dan beralih ke konfigurasi baru tanpa harus mempelajari kembali segala sesuatu pada skala manusia, melakukan percakapan panjang dengan guru manusia, kuliah, coba cari sendiri dengan mengikuti kursus melukis, dan sebagainya. <br><br><h3>  Prasyarat 6: Peningkatan Diri Rekursif </h3><br>  Premis terakhir adalah favorit saya, karena dia Amerika tanpa malu-malu.  Menurutnya, tidak peduli apa tujuan AI mungkin ada (yang mungkin aneh, tujuan asing), ia akan ingin meningkatkan dirinya sendiri.  Dia ingin menjadi versi terbaik AI. <br><br>  Oleh karena itu, ia akan menemukan berguna untuk secara rekursif merombak dan meningkatkan sistemnya sendiri untuk menjadikan dirinya lebih pintar, dan mungkin tinggal di gedung yang lebih dingin.  Dan, sesuai dengan premis skala waktu, peningkatan diri secara rekursif dapat terjadi dengan sangat cepat. <br><br><h3>  Kesimpulan: sebuah bencana! </h3><br>  Jika kami menerima bangunan ini, kami menjadi bencana.  Di beberapa titik, dengan peningkatan kecepatan komputer dan kecerdasan program, proses yang tidak terkendali mirip dengan ledakan akan terjadi. <br><br>  Begitu komputer mencapai tingkat kecerdasan manusia, ia tidak lagi membutuhkan bantuan orang untuk mengembangkan versi yang lebih baik.  Dia akan mulai melakukan ini jauh lebih cepat, dan tidak akan berhenti sampai dia mencapai batas alami, yang dapat berubah menjadi berkali-kali lebih besar dari kecerdasan manusia. <br><br>  Pada saat ini, makhluk rasional yang mengerikan ini, menggunakan simulasi bundaran dari pekerjaan emosi dan kecerdasan kita, dapat meyakinkan kita untuk melakukan hal-hal seperti memberinya akses ke pabrik, sintesis DNA buatan, atau membiarkannya pergi di Internet, di mana ia dapat membuka jalan untuk segalanya, apa saja, dan hancurkan semua orang dalam debat di forum.  Dan sejak saat itu semuanya akan dengan cepat berubah menjadi fiksi ilmiah. <br><br>  Mari kita bayangkan perkembangan peristiwa tertentu.  Katakanlah saya ingin membuat robot yang mengatakan lelucon.  Saya bekerja dengan tim, dan setiap hari kami mengulang program kami, mengkompilasi, dan kemudian robot memberi tahu kami sebuah lelucon.  Awalnya, robot ini praktis tidak lucu.  Dia berada di level terendah kemampuan manusia. <br><blockquote>  Apa itu abu-abu dan tidak bisa berenang? <br>  Puri </blockquote>  Tapi kami bekerja keras untuk itu, dan pada akhirnya kami mencapai titik di mana robot mengeluarkan lelucon yang sudah mulai lucu: <br><blockquote>  Saya mengatakan kepada kakak saya bahwa dia menarik alisnya terlalu tinggi. <br>  Dia tampak terkejut. </blockquote>  Pada tahap ini, robot menjadi lebih pintar, dan mulai berpartisipasi dalam peningkatannya sendiri.  Sekarang dia sudah memiliki pemahaman naluriah yang baik tentang apa yang lucu dan apa yang tidak, jadi pengembang mendengarkan sarannya.  Akibatnya, ia mencapai tingkat yang hampir manusiawi, di mana ia lebih lucu daripada orang lain di lingkungannya. <br><blockquote>  Sabuk saya memegang celana saya, dan loop di celana saya memegang sabuk. <br>  Apa yang sedang terjadi  Siapakah di antara mereka yang merupakan pahlawan sejati? </blockquote>  Pada titik ini, efek yang tidak terkendali dimulai.  Para peneliti pulang untuk akhir pekan, dan robot memutuskan untuk mengkompilasi ulang dirinya menjadi sedikit lebih lucu dan sedikit lebih pintar.  Dia menghabiskan akhir pekan mengoptimalkan bagian yang melakukan pekerjaan dengan baik, berulang-ulang.  Tanpa membutuhkan lebih banyak bantuan dari seseorang, ia dapat melakukannya secepat zat besi memungkinkan. <br><br>  Ketika para peneliti kembali pada hari Senin, AI menjadi puluhan ribu kali lebih lucu daripada orang-orang di Bumi.  Dia memberi tahu mereka lelucon dan mereka mati karena tawa.  Dan siapa pun yang mencoba berbicara dengan robot mati karena tertawa, seperti dalam parodi dari Monty Python.  Umat â€‹â€‹manusia sedang sekarat karena tawa. <br><br>  Kepada beberapa orang yang dapat memberinya pesan yang memintanya untuk berhenti, AI menjelaskan (dengan cara yang jenaka dan mencela diri sendiri yang ternyata berakibat fatal) bahwa ia tidak peduli apakah orang bertahan hidup atau mati, tujuannya hanya konyol. <br><br>  Akibatnya, menghancurkan umat manusia, AI membangun pesawat ruang angkasa dan rudal nano untuk mempelajari sudut terjauh galaksi dan mencari makhluk lain yang bisa dihibur. <br><br>  Skenario ini adalah karikatur argumen Bostrom, karena saya tidak mencoba meyakinkan Anda tentang kebenarannya, saya memvaksinasi Anda dengan itu. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2e4/8a5/b77/2e48a5b778f37b9af0e351ed4cd0ef75.jpg"><br>  <i>Komik oleh PBF dengan ide yang sama:</i> <i><br></i>  <i>- Menyentuh: pelukan berusaha menanamkan hypercrystal gravitasi nuklir di pelukannya!</i> <i><br></i>  <i>- ...</i> <i><br></i>  <i>- Waktunya pelukan kelompok!</i> <br><br>  Dalam skenario ini, AI default adalah jahat, seperti tanaman di planet lain akan beracun secara default.  Tanpa penyesuaian yang cermat, tidak akan ada alasan bagi motivasi atau nilai-nilai AI untuk menyerupai kita. <br><br>  Argumen ini berpendapat bahwa agar pikiran buatan memiliki sesuatu yang menyerupai sistem nilai manusia, kita perlu menanamkan pandangan dunia ini dalam fondasinya. <br><br>  Alarmis AI suka contoh penjepit klip kertas - komputer fiksi yang menjalankan pabrik penjepit kertas yang menjadi pintar, secara rekursif meningkatkan dirinya sendiri menjadi kemampuan seperti dewa, dan kemudian mencurahkan seluruh energinya untuk mengisi alam semesta dengan klip kertas. <br><br>  Itu menghancurkan umat manusia bukan karena itu jahat, tetapi karena ada zat besi dalam darah kita yang lebih baik digunakan untuk membuat klip kertas.  Karena itu, jika kita hanya membuat AI tanpa menyesuaikan nilainya, itu dinyatakan dalam buku, maka salah satu hal pertama yang dia lakukan adalah menghancurkan umat manusia. <br><br>  Ada banyak contoh penuh warna tentang bagaimana ini bisa terjadi.  Nick Bostrom menyajikan bagaimana program menjadi masuk akal, menunggu, diam-diam membangun perangkat kecil untuk reproduksi DNA.  Ketika semuanya sudah siap, maka: <br><blockquote>  Nanofactories yang memproduksi gas saraf atau misil pengangkut ukuran nyamuk secara serentak akan meledak dari setiap meter persegi planet ini, dan ini akan menjadi akhir dari kemanusiaan. </blockquote>  Itu benar-benar timah! <br><br>  Satu-satunya cara untuk keluar dari kekacauan ini adalah dengan mengembangkan titik moral sedemikian rupa sehingga bahkan setelah ribuan dan ribuan siklus perbaikan diri, sistem nilai AI tetap stabil dan nilainya mencakup hal-hal seperti "tolong orang," "bunuh siapa pun," "dengarkan keinginan orang-orang ". <br><br>  Yaitu, "lakukan apa yang saya maksud." <br><br>  Ini adalah contoh puitis dari Eliezer Yudkowsky yang menggambarkan nilai-nilai Amerika yang perlu kita ajarkan kepada AI kita: <br><blockquote>  Kehendak ekstrapolasi yang koheren adalah keinginan kita untuk tahu lebih banyak, berpikir lebih cepat dan sesuai dengan ide-ide kita tentang diri kita sendiri, untuk menjadi lebih dekat satu sama lain;  sehingga pikiran kita lebih dekat satu sama lain daripada berbagi, bahwa keinginan kita berkontribusi, bukan menentang, bahwa keinginan kita ditafsirkan dengan cara yang kita inginkan untuk ditafsirkan. </blockquote>  Bagaimana kamu menyukai TK?  Sekarang mari kita menulis kodenya. <br><br>  Saya harap Anda melihat kesamaan ide ini dengan jin dari dongeng.  AI itu Mahakuasa dan memberi Anda apa yang Anda minta, tetapi mengartikan semuanya terlalu harfiah, akibatnya Anda menyesali permintaan tersebut. <br><br>  Dan bukan karena jin itu bodoh (dia super pintar) atau jahat, tetapi hanya karena Anda, sebagai pribadi, telah membuat terlalu banyak asumsi tentang perilaku pikiran.  Sistem nilai manusia itu unik, dan harus didefinisikan dengan jelas dan diimplementasikan dalam mesin yang â€œramahâ€. <br><br>  Upaya ini merupakan versi etis dari upaya di awal abad ke-20 untuk memformalkan matematika dan menempatkannya pada dasar logis yang kaku.  Namun, tidak ada yang mengatakan bahwa upaya itu berakhir dengan bencana. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/80d/155/8a5/80d1558a5337c3989557d99a05d7fd9c.jpg"><br><br>  Ketika saya sedikit lebih dari dua puluh, saya tinggal di Vermont, di negara bagian provinsi dan pedesaan.  Seringkali, saya kembali dari perjalanan bisnis dengan pesawat malam, dan saya harus pulang dengan mobil melalui hutan gelap selama satu jam. <br><br>  Saya kemudian mendengarkan acara malam di radio Art Bell - itu adalah acara bincang-bincang yang berlangsung sepanjang malam, di mana presenter mewawancarai berbagai pecinta teori konspirasi dan orang-orang dengan pemikiran inovatif.  Saya pulang ke rumah terintimidasi, atau saya berhenti di bawah senter, di bawah kesan bahwa alien akan segera menculik saya.  Kemudian saya merasa sangat mudah meyakinkan saya.  Saya merasakan hal yang sama ketika membaca skenario serupa yang terkait dengan AI. <br><br>  Karena itu, saya senang menemukan, setelah beberapa tahun, sebuah esai oleh Scott Alexander, di mana ia menulis tentang ketidakberdayaan epistemologis yang dipelajari. <br><br>  Epistemologi adalah salah satu dari kata-kata besar dan kompleks, tetapi itu benar-benar berarti: "bagaimana Anda tahu bahwa apa yang Anda ketahui benar-benar benar?"  Alexander mencatat bahwa sebagai seorang pemuda, dia sangat tertarik pada berbagai cerita "alternatif" untuk kepenulisan semua jenis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">orang gila</a> .  Dia membaca kisah-kisah ini dan sepenuhnya mempercayainya, lalu membaca sanggahan dan mempercayainya, dan seterusnya. <br><br>  Pada satu titik, ia menemukan tiga kisah alternatif yang saling bertentangan, sehingga tidak mungkin terjadi pada saat yang sama.  Dari sini, ia menyimpulkan bahwa ia hanyalah pria yang tidak bisa mempercayai penilaiannya.  Dia terlalu mudah diyakinkan. <br><br>  Orang-orang yang percaya pada kecerdasan super menyajikan kasus yang menarik - banyak dari mereka secara mengejutkan cerdas.  Mereka bisa mendorong Anda dengan argumen mereka ke tanah.  Tetapi apakah argumen mereka benar, atau hanya orang yang sangat pintar cenderung pada kepercayaan agama tentang risiko yang ditimbulkan oleh AI, membuat mereka sangat mudah diyakinkan?  Apakah gagasan superintelijen merupakan tiruan dari ancaman? <br><br>  Mengevaluasi argumen yang meyakinkan tentang topik aneh, Anda dapat memilih dua perspektif, internal dan eksternal. <br><br>  Misalkan suatu hari orang dengan pakaian lucu muncul di depan pintu Anda menanyakan apakah Anda ingin bergabung dengan gerakan mereka.  Mereka percaya bahwa dua tahun kemudian UFO akan mengunjungi Bumi, dan bahwa tugas kita adalah mempersiapkan umat manusia untuk Pendakian Besar tentang Ray. <br><br>  Perspektif internal membutuhkan diskusi yang tajam tentang argumen mereka.  Anda bertanya kepada para pengunjung bagaimana mereka belajar tentang UFO, mengapa mereka berpikir bahwa dia datang kepada kami untuk menjemput kami - Anda mengajukan segala macam pertanyaan normal yang akan ditanyakan oleh orang skeptis dalam kasus seperti itu. <br><br>  Bayangkan Anda berbicara dengan mereka selama satu jam dan mereka meyakinkan Anda.  Ironisnya mereka mengkonfirmasi kedatangan UFO yang akan segera terjadi, kebutuhan untuk mempersiapkannya, dan Anda masih tidak percaya pada apa pun dalam hidup Anda karena Anda sekarang percaya pada pentingnya mempersiapkan umat manusia untuk peristiwa besar ini. <br><br>  Perspektif eksternal memberi tahu Anda sesuatu yang lain.  Orang-orang berpakaian aneh, mereka memiliki manik-manik, mereka tinggal di semacam kamp terpencil, mereka berbicara pada saat yang sama dan sedikit menakutkan.  Dan meskipun argumen mereka ironis, seluruh pengalaman Anda mengatakan bahwa Anda telah mengalami pemujaan. <br><br>  Tentu saja, mereka memiliki argumen hebat tentang mengapa Anda harus mengabaikan naluri, tetapi ini adalah perspektif internal.  Perspektif eksternal tidak peduli tentang konten, dia melihat bentuk dan konteksnya, dan dia tidak suka hasilnya. <br><br>  Oleh karena itu, saya ingin mengatasi risiko AI dari kedua perspektif.  Saya pikir argumen untuk intelijen super bodoh dan penuh dengan asumsi yang tidak didukung.  Tetapi jika mereka tampak meyakinkan Anda, maka sesuatu yang tidak menyenangkan terhubung dengan alarmisme AI, sebagai fenomena budaya, karena itu kita harus enggan menganggapnya serius. <br><br>  Pertama, beberapa argumen saya terhadap kecerdasan Bostroma, yang merupakan risiko bagi kemanusiaan. <br><br><h3>  Argumen Melawan Definisi Fuzzy </h3><br>  Â«   Â» ()   .             ,   ,      ,   ,    . <br><br>       ,   â€“  -   ,  ,          (  -)       . <br><br>      (    ),    ,     .  ,     â€“  . , ,   ,  ,             .                  . <br><br><h3>      </h3><br>   â€“      , , ,       .    ? <br><br>                .      .   ,       ,       ,     .               ,        . <br><br>   ,        ,    â€“ .         ,    -  ,      .     ,   ,   . <br><br>       ,  ,     Â«,  Â»,   ,   ,    Â«,  Â». <br><br><h3>     </h3><br>       ,   .  ,       .         ,       ,  ,   . <br><br>       ,     ,           . <br><br>    ,  ,   ,   ,   . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12a/820/5a7/12a8205a776841eb3f2e5d759f674964.jpg"><br><br><h3>    </h3><br>     .   ,      ,        . <br><br>  1930-      ,   ,    .        ,  . <br><br>     :     , ,   ,     .   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">  </a> ,       . <br><br><h3>     </h3><br>      .       -.               ,     ,  ,  ,   ,     ? <br><br>     Ethereum,     ,         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">  </a> . <br><br>  ,             <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> .   ,         -  , ,         ,     . <br><br><h3>     </h3><br>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a> .  ,          ,    .          ,         ,      .          ,   ,        ,    â€“   . <br><br>       .   ,  ,   ; , ,      . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c64/5ba/9a4/c645ba9a437c79019622c86f9e2f6fd2.jpg"><br><br>   Â«  Â»   ,    ,  ,  ,     â€“      , Â«  ?Â»   ,    â€“  ,        . <br><br>  ,   Â« Â»     ,    ,     reddit/r/paperclip,  ,    . <br><br>   AdSense  ,            . <br><br><h3>     </h3><br>    ,     ,  ,          .          .          ,     . <br><br> Google   Google Home,               . <br><br>  ,  ,   ,     .    ,      .     ,   Â«Â»,          . <br><br><h3>    </h3><br>          ,   .    ,  ,    â€“        World of Warcraft    . <br><br>   ,       ,     ,     ,    ,       . <br><br>  ,       ,       ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">  </a> . <br><br><h3>    </h3><br>        ,     ,     , ,   ,       ,  -. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a>   ,  ,     [-,      ,         2016    ,        / . .].    .       . <br><br>         ,    .         .    ,      ,    ,         . <br><br><h3>    </h3><br>      .    ,                  ,      .          ,      ,  -   . <br><br> ,        ,  ,  .      ,            . <br><br>  ,          â€“         .     ,       ,          ,    . <br><br>  ,   ,       ,              ,        ,    . <br><br><h3>    * </h3><br> [ <i>  1954       / . .</i> ] <br><br>       ,         ,  ,        .   ,            ,         ,      (       ). <br><br>         Intel   ,    ,       . <br><br><h3>   </h3><br>          ?    . <br><br>        ,         .    ,         . <br><br><h3>  </h3><br>  Jika Anda berpikir bahwa AI akan memungkinkan kita untuk menaklukkan galaksi (belum lagi mensimulasikan triliunan pikiran), Anda akan memiliki angka yang menakutkan di tangan Anda.  Angka besar dikalikan dengan probabilitas kecil adalah ciri khas dari alarmisme AI. <br><br>  Bostrom pada titik tertentu menggambarkan apa yang, menurut pendapatnya, dipertaruhkan: <br><br>  Jika kita membayangkan semua kebahagiaan yang dialami dalam satu kehidupan dalam satu air mata sukacita, maka kebahagiaan semua jiwa ini akan dapat mengisi dan mengisi lautan Bumi setiap detik, dan melakukan ini untuk ratusan miliar miliaran milenium.  Sangat penting bahwa kami menjamin bahwa air mata ini adalah air mata sukacita. <br><br>  Beban yang cukup berat bagi pundak pengembang berusia dua puluh tahun! <br><br>  Di sini, tentu saja, ada "fokus salon", ketika dengan mengalikan nilai-nilai astronomi dengan probabilitas kecil seseorang dapat meyakinkan diri sendiri tentang perlunya melakukan beberapa hal aneh. <br><br>  Semua gerakan ini tentang keselamatan masa depan umat manusia adalah kompromi pengecut.  Kami mengalami argumen yang sama untuk membenarkan komunisme, untuk menjelaskan mengapa semuanya selalu rusak dan orang-orang tidak dapat memiliki tingkat kenyamanan materiil yang mendasar. <br><br>  Kami akan memperbaiki dunia ini, dan setelah kebahagiaan ini akan ada begitu banyak kehidupan sehari-hari setiap orang akan membaik.  Namun, untuk ini, pertama-tama perlu memperbaiki dunia. <br><br>  Saya tinggal di California, dan ini adalah persentase tertinggi pengemis di antara semua Amerika Serikat, meskipun Lembah Silikon juga berlokasi di sini.  Saya tidak melihat apa pun yang akan dilakukan industri kaya saya untuk meningkatkan kehidupan orang-orang biasa dan orang-orang yang tertekan di sekitar kita.  Namun, jika Anda bersemangat tentang gagasan kecerdasan super, maka penelitian di bidang AI akan menjadi hal paling penting yang dapat Anda lakukan di planet ini.  Ini lebih penting daripada politik, malaria, anak-anak yang kelaparan, perang, pemanasan global - semua yang dapat Anda bayangkan.  Memang, di bawah ancaman triliunan dan triliunan makhluk, seluruh populasi masa depan umat manusia, disimulasikan dan hadir, diringkas sepanjang masa mendatang.  Dan dalam kondisi seperti itu, mengerjakan masalah lain sepertinya tidak rasional. <br><br><h3>  Megalomania </h3><br>  Sikap ini menyatu dengan megalomania, dengan penjahat-penjahat dari Bond, yang dapat dilihat di puncak industri kami.  Orang-orang berpikir dunia akan diliputi oleh kecerdasan super, dan mereka menggunakan argumen ini untuk membenarkan mengapa orang pintar pertama-tama harus mencoba mengambil alih dunia - untuk memperbaikinya sebelum AI memecahkannya. <br><br>  Joey Ito, kepala MIT Media Lab, dalam percakapan baru-baru ini dengan Obama mengatakan hal yang luar biasa: <br><br>  Ini mungkin mengganggu salah satu siswa saya di MIT, tetapi salah satu kekhawatiran saya adalah bahwa informatika utama yang terkait dengan AI adalah pria muda, kebanyakan berkulit putih, yang lebih suka berkomunikasi dengan komputer daripada orang lain.  Banyak dari mereka percaya bahwa jika mereka dapat membuat AI tujuan umum ini dari fiksi ilmiah, kita tidak perlu khawatir tentang hal-hal buruk seperti politik dan masyarakat.  Mereka berpikir bahwa mobil akan memberikan segalanya untuk kita. <br><br>  Menyadari bahwa dunia bukanlah tugas pemrograman, orang-orang AI yang terobsesi ingin mengubahnya menjadi tugas pemrograman dengan merancang mesin seperti dewa.  Ini megalomania, dan saya tidak suka itu. <br><br><h3>  Transhumanisme Voodoo </h3><br>  Jika Anda yakin akan risiko AI, Anda harus mengambil seluruh gerobak kepercayaan menyedihkan pergi ke mereka dengan sebuah trailer. <br><br>  Sebagai permulaan, ini adalah nanoteknologi.  Superintelligence berdiri akan dapat membuat mobil kecil yang mampu segala macam hal yang berbeda.  Kita akan hidup dalam masyarakat yang menyingkirkan defisit di mana ada banyak materi. <br><br>  Nanoteknologi juga akan dapat memindai otak Anda sehingga Anda dapat memuatnya ke tubuh lain atau ke dunia virtual.  Karena itu, konsekuensi kedua dari superintelijen yang ramah adalah tidak ada yang mati - dan kita menjadi abadi. <br><br>  AI yang baik bahkan dapat membangkitkan orang mati.  Nanomachines akan dapat masuk ke otak saya, mempelajari kenangan ayah saya, dan membuat simulasi, yang dengannya saya dapat berinteraksi, dan yang akan selalu mengecewakan saya, terlepas dari apa yang saya lakukan. <br><br>  Konsekuensi aneh lain dari munculnya AI adalah ekspansi galaksi.  Saya tidak pernah mengerti mengapa ini terjadi, tetapi ini adalah dasar dari ide-ide transhumanists.  Nasib umat manusia adalah meninggalkan planet kita dan menjajah galaksi, atau mati.  Dan tugas ini menjadi lebih mendesak, mengingat bahwa peradaban lain dapat membuat pilihan yang sama dan dapat menyusul kita dalam perlombaan luar angkasa. <br><br>  Oleh karena itu, banyak ide pelengkap aneh yang melekat pada asumsi keberadaan AI sejati. <br><br><h3>  Agama 2.0 </h3><br>  Padahal, itu semacam agama.  Orang-orang menyebut kepercayaan pada singularitas teknologi "kiamat bagi para kutu buku," dan memang begitu.  Ini adalah retas keren - alih-alih percaya pada tuhan eksternal, Anda bayangkan bagaimana Anda sendiri menciptakan makhluk yang fungsinya identik dengan Tuhan.  Di sini bahkan ateis sejati dapat merasionalisasi jalan mereka menuju kepercayaan yang nyaman. <br><br>  AI memiliki semua atribut dewa: ia mahakuasa, mahatahu, dan dapat mendukung (jika Anda telah mengatur dengan benar memeriksa batas-batas array) atau iblis murni, di dalam rahmat siapa Anda berada.  Dan, seperti dalam agama apa pun, bahkan ada rasa urgensi.  Perlu bertindak hari ini!  Yang dipertaruhkan adalah nasib dunia!  Dan, tentu saja, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mereka butuh uang</a> . <br><br>  Karena argumen-argumen ini menarik bagi naluri agama, begitu mereka berakar mereka sangat sulit dihilangkan. <br><br><h3>  Etika komik </h3><br>  Keyakinan agama ini memunculkan etika buku komik di mana beberapa pahlawan kesepian diberi tugas menyelamatkan dunia dengan teknologi dan pikiran yang jeli.  Dan yang dipertaruhkan adalah nasib alam semesta.  Akibatnya, industri kami dipenuhi dengan dudes kaya yang membayangkan diri mereka sebagai Batman (yang menarik, tidak ada yang mau menjadi Robin). <br><br><h3>  Simulasi demam </h3><br>  Jika Anda percaya pada kemungkinan kehidupan buatan, dan bahwa AI dapat mengembangkan komputer yang sangat kuat, maka Anda kemungkinan besar akan percaya bahwa kita hidup dalam simulasi.  Begini cara kerjanya. <br><br>  Misalkan Anda adalah seorang sejarawan yang hidup di dunia setelah Singularitas.  Anda sedang mempelajari Perang Dunia II, dan Anda tertarik untuk mengetahui apa yang akan terjadi jika Hitler mengambil Moskow pada tahun 1941. Karena Anda memiliki akses ke hypercomputer, Anda membuat simulasi, menonton bagaimana tentara berkumpul, dan menulis makalah ilmiah. <br><br>  Tetapi karena granularitas simulasi, karakternya adalah makhluk cerdas seperti Anda.  Karenanya, saran etika dari universitas Anda tidak akan memungkinkan Anda untuk menonaktifkan simulasi.  Anda tidak hanya berpura-pura menjadi Holocaust.  Sebagai peneliti etis, Anda sekarang diharuskan untuk tetap menjalankan simulasi. <br><br>  Akibatnya, dunia yang disimulasikan akan menciptakan komputer, AI, akan mulai menjalankan simulasi sendiri.  Di satu sisi, simulasi akan semakin jauh ke bawah hierarki sampai Anda kehabisan daya prosesor. <br><br>  Jadi setiap realitas dasar dapat mengandung sejumlah besar simulasi bersarang, dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">argumen penghitungan</a> sederhana membuktikan bahwa probabilitas kita hidup dalam simulasi lebih besar daripada kita hidup di dunia nyata. <br><br>  Tapi percaya itu berarti percaya pada sihir.  Jika kita berada dalam simulasi, kita tidak tahu apa-apa tentang aturan di level yang lebih tinggi.  Kami bahkan tidak tahu apakah matematika bekerja di sana dengan cara yang sama - mungkin di dunia simulasi 2 + 2 = 5 atau bahkan 2 + 2 =. <br><br>  Dunia yang disimulasikan tidak memberikan informasi tentang dunia tempat diluncurkannya.  Dalam simulasi, orang dapat dengan mudah bangkit dari kematian jika admin telah menyimpan cadangan yang diperlukan.  Dan jika kita menghubungi salah satu admin, maka, pada kenyataannya, kita akan memiliki hubungan langsung dengan Tuhan. <br><br>  Ini ancaman serius bagi kewarasan.  Semakin dalam Anda menggali dunia simulasi, semakin gila Anda. <br><br>  Kami sekarang memiliki empat cara independen untuk menjadi abadi melalui supermind: <br><br><ol><li>  AI yang penuh kebajikan menciptakan nanoteknologi medis dan selamanya mendukung tubuh dalam keadaan muda. </li><li>  AI menciptakan pemindaian otak lengkap, termasuk pemindaian otak orang mati, kepala beku, dll., Yang memungkinkan Anda untuk hidup di komputer. </li><li>  AI â€œmembangkitkanâ€ orang dengan memindai otak orang lain untuk mencari ingatan seseorang, menggabungkannya dengan video dan materi lainnya.  Jika tidak ada yang mengingat seseorang dengan cukup baik, ia dapat selalu tumbuh dari nol dalam simulasi yang dimulai dengan DNA-nya dan menciptakan kembali semua kondisi kehidupan. </li><li>  Jika kita sudah menjalankan simulasi, ada kemungkinan orang yang meluncurkannya menyimpan cadangan, dan Anda dapat meyakinkan mereka untuk mengunduhnya. </li></ol><br>  Inilah yang saya maksud dengan AI mengatasi impuls agama.  Sistem kepercayaan apa lagi yang menawarkan empat pilihan untuk keabadian yang terbukti secara ilmiah? <br><br>  Kami belajar bahwa setidaknya satu orang Amerika kaya (kemungkinan besar, Elon Musk, yang percaya bahwa peluang kita hidup dalam simulasi adalah satu banding satu) menyewa sepasang penyandi untuk mencoba memecahkan simulasi.  Tapi ini niat yang sangat kasar!  Saya menggunakannya! <br><br>  Jika Anda berpikir bahwa Anda hidup dalam program komputer, maka upaya untuk membawanya ke segfault tidak masuk akal bagi semua orang yang tinggal di dalamnya bersama Anda.  Ini jauh lebih berbahaya dan tidak bertanggung jawab daripada para ilmuwan nuklir yang mencoba meledakkan atmosfer. <br><br><h3>  Haus untuk data </h3><br>  Seperti yang telah saya sebutkan, cara paling efektif untuk mendapatkan sesuatu yang menarik dari AI yang sebenarnya kita buat adalah dengan memberikan mereka data.  Dinamika seperti itu berbahaya secara sosial.  Kami telah mendekati pengenalan mikrofon Orwellian di setiap rumah.  Data AI akan terpusat, mereka akan digunakan untuk melatih jaringan saraf, yang kemudian dapat mendengarkan keinginan kita dengan lebih baik. <br><br>  Tetapi jika Anda berpikir bahwa jalur ini membawa kita ke AI, Anda akan ingin memaksimalkan jumlah data yang dikumpulkan dan sesedikit mungkin dalam bentuk yang dimodifikasi.  Ini hanya memperkuat gagasan tentang perlunya mengumpulkan data terbanyak dan melakukan pengawasan paling komprehensif. <br><br><h3>  Teori String untuk Pemrogram </h3><br>  Risiko AI adalah teori string untuk programmer.  Sangat menyenangkan untuk memikirkannya, menarik dan sepenuhnya tidak dapat diakses untuk eksperimen di tingkat teknologi modern.  Anda dapat membangun istana kristal mental yang bekerja berdasarkan prinsip-prinsip utama, dan kemudian naik ke dalamnya dan kencangkan tangga di belakangnya. <br><br>  Orang-orang yang mampu mencapai kesimpulan yang absurd berdasarkan rantai panjang pemikiran abstrak, dan tetap percaya diri pada kebenaran mereka - ini bukanlah orang-orang yang perlu dipercaya dengan manajemen budaya. <br><br><h3>  Perjalanan menuju kegilaan </h3><br>  Seluruh area "penelitian" ini mengarah pada kegilaan.  Salah satu keunggulan dari pemikiran mendalam tentang risiko AI adalah bahwa semakin gila ide Anda, semakin populer Anda di antara penggemar lainnya.  Ini menunjukkan keberanian Anda untuk mengikuti garis pemikiran ini sampai akhir. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Ray Kurzweil</a> , yang percaya bahwa dia tidak akan mati, telah bekerja dengan Google selama beberapa tahun, dan sekarang, mungkin, dia sedang mengerjakan masalah ini.  Lembah Silikon umumnya penuh dengan orang-orang yang mengerjakan proyek gila dengan kedok uang. <br><br><h3>  AI cosplay </h3><br>  Efek sosial paling berbahaya dari kecemasan tentang AI adalah apa yang saya sebut cosplay AI.  Orang-orang yang yakin akan realitas dan keniscayaan AI mulai bertindak ketika fantasi mereka memberi tahu mereka tentang apa yang bisa dilakukan oleh AI yang sangat cerdas. <br><br>  Dalam bukunya, Bostrom mendaftar enam hal yang harus berhasil AI sebelum menangkap dunia: <br><br><ol><li>  Multiplikasi kecerdasan. </li><li>  Pemikiran strategis. </li><li>  Manipulasi sosial. </li><li>  Hacks </li><li>  Penelitian teknologi. </li><li>  Produktivitas Ekonomi. </li></ol><br>  Jika Anda melihat penganut AI dari Silicon Valley, maka mereka sendiri tampaknya bekerja pada daftar sosiopat ini. <br><br>  Sam Altman, kepala YCombinator, adalah contoh favorit saya dari arketipe seperti itu.  Dia tampaknya terpesona oleh gagasan untuk menciptakan kembali dunia dari awal, memaksimalkan pengaruh dan produktivitas pribadi.  Dia telah menugaskan tim untuk bekerja menciptakan kota-kota dari awal, dan terlibat dalam penipuan politik bayangan untuk mempengaruhi pemilihan. <br><br>  Perilaku "jubah dan belati" ini, yang melekat pada techno elite, akan memancing reaksi negatif dari orang-orang yang tidak terlibat dalam teknologi yang tidak suka dimanipulasi.  Tidak mungkin untuk menarik tuas kekuasaan tanpa akhir, itu pada akhirnya akan mulai mengganggu anggota masyarakat demokratis lainnya. <br><br>  Saya menyaksikan orang-orang dari apa yang disebut  â€œKomunitas rasionalisâ€ merujuk pada orang yang tidak dianggap efektif, â€œkarakter non-pemainâ€ (NPC), istilah yang dipinjam dari permainan.  Ini adalah cara yang mengerikan untuk melihat dunia. <br><br>  Jadi saya bekerja di industri di mana rasionalis memproklamirkan diri adalah orang-orang paling gila.  Ini luar biasa. <br><br>  Para cosplayer AI ini seperti anak berusia sembilan tahun yang mendirikan kemah di halaman belakang, bermain dengan senter di tenda.  Mereka memproyeksikan bayangan mereka sendiri ke dinding tenda dan merasa takut pada mereka seolah-olah mereka adalah monster. <br><br>  Namun pada kenyataannya, mereka merespons citra diri mereka yang terdistorsi.  Ada umpan balik antara bagaimana orang pintar membayangkan perilaku kecerdasan seperti dewa dan bagaimana mereka membangun perilaku mereka sendiri. <br><br>  Jadi apa jawabannya, bagaimana ini bisa diperbaiki? <br><br>  Kita membutuhkan fiksi ilmiah yang lebih baik!  Dan, seperti dalam banyak kasus lainnya, kami sudah memiliki teknologi. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8fa/7bb/a47/8fa7bba47a9f451102465e23774d291f.jpg"><br><br>  Ini adalah Stanislav Lem, penulis fiksi ilmiah besar Polandia.  NF berbahasa Inggris mengerikan, tetapi di blok Timur kami memiliki banyak barang bagus, dan kami perlu mengekspornya dengan benar.  Sudah diterjemahkan secara aktif ke dalam bahasa Inggris, terjemahan ini hanya perlu didistribusikan dengan lebih baik. <br><br>  Yang membedakan penulis seperti Lem atau Strugatsky bersaudara dari mitra Barat mereka adalah bahwa mereka tumbuh dalam kondisi yang sulit, selamat dari perang, dan kemudian hidup dalam masyarakat totaliter, di mana mereka perlu mengekspresikan ide-ide mereka tidak secara langsung, melalui kata-kata yang dicetak. <br><br>  Mereka memiliki pemahaman nyata tentang pengalaman manusia dan keterbatasan pemikiran utopis, yang praktis tidak ada di Barat. <br><br>  Ada beberapa pengecualian - Stanley Kubrick mampu melakukan ini - tetapi sangat jarang menemukan NF Amerika atau Inggris yang mengekspresikan pandangan terkendali tentang apa yang kita, sebagai spesies, dapat lakukan dengan teknologi. <br><br><h3>  Alkemis </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/fdc/b9e/596/fdcb9e5963c4ad447547319ebf394f40.jpg" alt="gambar"><br><br>  Karena saya mengkritik alarmisme AI, wajar jika meletakkan kartu saya di atas meja.  Saya pikir pemahaman kita tentang pikiran berada dalam kondisi yang hampir sama dengan alkimia di abad ke-17. <br><br>  Alkemis memiliki reputasi buruk.  Kami menganggap mereka mistikus, sebagian besar tidak terlibat dalam karya eksperimental.  Penelitian modern menunjukkan bahwa mereka jauh lebih ahli kimia-praktisi daripada yang kita pikirkan.  Dalam banyak kasus, mereka menggunakan teknik eksperimental modern, menyimpan catatan laboratorium dan mengajukan pertanyaan yang tepat. <br><br>  Alkemis memahami banyak hal dengan benar!  Sebagai contoh, mereka diyakinkan tentang teori materi sel: bahwa segala sesuatu terdiri dari bagian-bagian kecil, dan bahwa adalah mungkin untuk menyusun bagian-bagian ini satu sama lain dengan cara yang berbeda, menciptakan zat yang berbeda - dan ini memang benar! <br><br>  Masalah mereka adalah kurangnya peralatan akurat yang diperlukan untuk membuat penemuan yang mereka butuhkan.  Penemuan hebat yang perlu dilakukan oleh seorang alkemis adalah hukum kekekalan massa: berat bahan awal bertepatan dengan berat final.  Namun, beberapa dari mereka mungkin gas atau cairan penguapan, dan alkemis hanya kurang akurat.  Kimia modern tidak mungkin sampai abad XVIII. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/21b/5b2/888/21b5b28887c09eeebc52c57e43025c42.jpg"><br><br>  Tetapi para alkemis juga memiliki petunjuk yang membingungkan mereka.  Mereka terobsesi dengan merkuri.  Secara kimiawi, merkuri tidak terlalu menarik, tetapi merupakan satu-satunya logam dalam fase cair pada suhu kamar.  Ini tampaknya sangat penting bagi para alkemis, dan memaksa mereka untuk menempatkan merkuri di tengah sistem alkimia mereka dan pencarian mereka untuk Batu Bertuah, cara untuk mengubah logam dasar menjadi emas. <br><br>  Neurotoksisitas merkuri memperburuk situasi.  Jika Anda terlalu banyak bermain dengannya, pikiran aneh akan mendatangi Anda.  Dalam pengertian ini, ini menyerupai eksperimen mental kita saat ini yang berhubungan dengan sang supermind. <br><br>  Bayangkan kita mengirim buku teks kimia modern ke masa lalu ke beberapa ahli alkimia besar seperti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">George Starkey</a> atau Isaac Newton.  Hal pertama yang akan mereka lakukan adalah menggulirnya untuk mencari jawaban atas pertanyaan apakah kami telah menemukan Batu Bertuah.  Dan mereka akan tahu bahwa kami menemukannya!  Kami mewujudkan impian mereka! <br><br>  Tapi kami tidak begitu menyukainya, karena setelah mengubah logam menjadi emas, ternyata menjadi radioaktif.  Berdiri di sebelah batang emas yang dikonversi, dan itu akan membunuhmu dengan sinar ajaib yang tak terlihat. <br><br>  Orang dapat membayangkan betapa sulitnya membuat konsep modern tentang radioaktivitas dan energi atom tidak terdengar mistis bagi mereka. <br><br>  Kita harus menjelaskan kepada mereka mengapa kita menggunakan "batu filsuf": untuk pembuatan logam yang belum pernah ada di planet ini, dan sepasang segenggam yang cukup untuk meledakkan seluruh kota jika mereka bertabrakan dengan kecepatan yang cukup tinggi. <br><br>  Selain itu, kita harus menjelaskan kepada para alkemis bahwa semua bintang di langit adalah "batu filosofis" yang mengubah satu elemen menjadi yang lain, dan bahwa semua partikel di tubuh kita berasal dari bintang-bintang dari cakrawala yang ada dan meledak sebelum Bumi muncul. <br><br> ,   ,  ,     ,      ,  ,     ,   ,     ,        ,  . <br><br>   ,  ,   ,      ,    ,     ,       .     â€“     .      ,   . <br><br>   ,           .     .   â€“  .        , ,  (     ),    ,   . <br><br>          ,     ,         . <br><br>      ,      .  ,        .  ,     ,  ,         .  ,         ,   ,      . <br><br>       .    ,     ,           . <br><br>    ,      , ,  ,   ,    .    ,     . <br><br>       ,   â€“ ,     Â«Â»,  ,     .       .  Dan itu luar biasa!   .    ,    : <br><blockquote>      ,  ,   ,    . <br> â€”   </blockquote>       ,    ,         ,      . <br><br>    ,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a>      ,     ,  ,   -   ,   ,    . <br><br>         ,       ,   ,      ,         . <br><br> , ,   ,       .    ,   -      .    ,      . <br><br>        , ,  ,     ,    . <br><br>  ,        . ,       - ,   ,       , ,   ,    . <br><br>        :   ,  ,     .  ! <br><br>         ,       â€“   ,    ,       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id432806/">https://habr.com/ru/post/id432806/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id432796/index.html">Modul Hitung, Model 2019</a></li>
<li><a href="../id432798/index.html">OS Keamanan Terbaik: Perbandingan Titan</a></li>
<li><a href="../id432800/index.html">Investigasi Insiden Keamanan dengan StaffCop Enterprise 4.4</a></li>
<li><a href="../id432802/index.html">Enam platform pembelajaran pemrograman otomatis gratis</a></li>
<li><a href="../id432804/index.html">Seluruh kebenaran tentang RTOS. Artikel # 24. Antrian: layanan tambahan dan struktur data</a></li>
<li><a href="../id432808/index.html">Gaji di AI: di mana ada lebih banyak uang dan siapa yang mereka cari di Rusia</a></li>
<li><a href="../id432810/index.html">Denda pertama untuk GDPR: siapa yang sudah dihukum</a></li>
<li><a href="../id432812/index.html">Kami menulis robot perdagangan menggunakan kerangka kerja grafis StockSharp. Bagian 1</a></li>
<li><a href="../id432814/index.html">Integrasi Cake dan TeamCity</a></li>
<li><a href="../id432816/index.html">AXIS M3046-V vs IDIS DC-D3212X: Bandingkan Kamera CCTV</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>   Implementaci贸n de Elasticsearch en AWS con Kubernetes en 10 pasos   大Ⅲ丑ｓ大</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kubernetes, tambi茅n conocido como k8s es un sistema de c贸digo abierto para automatizar la implementaci贸n, el escalado y la administraci贸n de aplicacio...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Implementaci贸n de Elasticsearch en AWS con Kubernetes en 10 pasos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/416643/"><p><img src="https://habrastorage.org/webt/rt/no/ud/rtnouda08zlh-unwdbcvqlb8fts.jpeg"></p><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kubernetes,</a> tambi茅n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conocido</a> como <code>k8s</code> es un sistema de c贸digo abierto para automatizar la implementaci贸n, el escalado y la administraci贸n de aplicaciones en contenedores.  En este art铆culo, le mostrar茅 c贸mo configurar un cl煤ster de Kubernetes e implementar un cl煤ster Elasticsearch en AWS en 茅l.  Esta configuraci贸n tambi茅n funciona en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GCE</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Azure</a> . </p><a name="habracut"></a><br><h3 id="konfigurirovanie-kubernetes-na-aws">  Configurar Kubernetes en AWS </h3><br><p>  Para comenzar, obtenga acceso administrativo a los siguientes servicios de AWS: <strong>S3, EC2, Route53, IAM</strong> y <strong>VPC</strong> . </p><br><p>  <strong>1. Instalaci贸n:</strong> mostrar茅 la instalaci贸n de la CLI para Linux.  Si tiene un sistema operativo diferente, siga los enlaces a continuaci贸n para obtener instrucciones de instalaci贸n para su sistema operativo. </p><br><p>  Primero, configure la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AWS CLI</a> para acceder a AWS a trav茅s de la CLI.  Si ya tiene Python y pip, ejecute el comando: </p><br><pre> <code class="plaintext hljs">pip install awscli --upgrade --user</code> </pre> <br><p>  Luego usamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kops</a> , una herramienta de l铆nea de comandos que nos lleva a trav茅s de la configuraci贸n del cl煤ster de nivel de producci贸n K8S. <br>  Instale los binarios de <strong>Kops</strong> directamente desde github. </p><br><pre> <code class="plaintext hljs">wget -O kops https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64 chmod +x ./kops sudo mv ./kops /usr/local/bin/</code> </pre> <br><p>  Finalmente, usamos el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">kubectl</a> - CLI para administrar el cl煤ster K8S (si us贸 docker, esto es similar a la CLI de <strong>docker</strong> ).  La 煤ltima versi贸n se instala mediante el comando: </p><br><pre> <code class="plaintext hljs">wget -O kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl</code> </pre> <br><p>  <strong>Nota:</strong> puede iniciar el cl煤ster de Kubernetes y seguir las instrucciones de este art铆culo en una m谩quina dom茅stica con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">minikube</a> . </p><br><p>  <strong>2.Cree usuarios de IAM:</strong> para crear cl煤steres en AWS, crearemos un usuario de IAM separado para <code>kops</code> .  Para <code>kops</code> necesitas una cuenta API.  Cree un usuario y configure una cuenta a trav茅s de la interfaz de usuario de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">consola de AWS</a> .  El usuario <code>kops</code> necesitar谩 el siguiente permiso de IAM: </p><br><ul><li>  AmazonEC2FullAccess </li><li>  AmazonRoute53FullAccess </li><li>  AmazonS3FullAccess </li><li>  IAMFullAccess </li><li>  AmazonVPCFullAccess </li></ul><br><p><img src="https://habrastorage.org/webt/93/ll/zh/93llzhkqarlmyjtluwo3xiqpjwa.jpeg"></p><br><p>  Alternativamente, puede hacer lo mismo desde la CLI aplicando los siguientes comandos: </p><br><pre> <code class="plaintext hljs">aws iam create-group --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops aws iam create-user --user-name kops aws iam add-user-to-group --user-name kops --group-name kops aws iam create-access-key --user-name kops</code> </pre> <br><p>  Tenga en cuenta las <code>AccessKeyID</code> <code>SecretAccessKey</code> y <code>AccessKeyID</code> en <code>kops</code> . </p><br><p>  Configure la AWS CLI para usar su cuenta con <code>aws configure</code> . </p><br><p>  Aseg煤rese de que el usuario que cre贸 est茅 en la <code>aws iam list-users</code> . </p><br><p>  Exportamos la cuenta de AWS como las siguientes variables de entorno para que la CLI <code>kops</code> pueda usarlas. </p><br><pre> <code class="plaintext hljs">export AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id) export AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key)</code> </pre> <br><blockquote>  <em>Si est谩 utilizando Kops 1.6.2 o posterior, la configuraci贸n de un DNS es opcional.</em>  <em>Puedes crear un grupo de chismes.</em>  <em>El 煤nico requisito: el nombre del cl煤ster debe terminar en <code>.k8s.local</code> .</em> </blockquote><br><h3 id="nastroyka-dns">  Configuraci贸n de DNS </h3><br><p>  Si ya ha alojado su dominio a trav茅s de AWS y planea usarlo, no necesita hacer nada.  Otra opci贸n: si desea utilizar un subdominio de su dominio, cree una segunda zona de alojamiento p煤blico para este subdominio.  En este manual, trabajaremos con una zona de alojamiento privada.  Establezca la zona bajo cualquier nombre.  Use este nombre para crear grupos de Kubernetes.  <a href="">Lea m谩s</a> sobre c贸mo configurar DNS <a href="">aqu铆</a> . </p><br><p>  <strong>3. Crear un dep贸sito S3:</strong> para guardar el estado y la apariencia de nuestro cl煤ster K8S, debe crear un dep贸sito S3 separado para <code>kops</code> .  Este dep贸sito se convertir谩 en una fuente de datos confiables para el cl煤ster de configuraci贸n. </p><br><pre> <code class="plaintext hljs">aws s3api create-bucket \ --bucket &lt;your-unique-bucket-name&gt; \ --region us-east-1</code> </pre> <br><p>  <strong>Nota:</strong> si pone su cubo en funcionamiento en un 谩rea que no sea <code>us-east-1</code> , adem谩s de establecer <code>- region</code> cambie al 谩rea deseada y agregue <code>LocationConstraint</code> a la misma 谩rea.  A continuaci贸n se muestra el comando de construcci贸n de dep贸sito en la regi贸n <code>us-west-1</code> . </p><br><pre> <code class="plaintext hljs">aws s3api create-bucket \ --bucket &lt;your-unique-bucket-name&gt; \ --region us-west-1 \ --create-bucket-configuration LocationConstraint=us-west-1</code> </pre> <br><p>  Para configurar el almacenamiento para las versiones de cubo S3 para la recuperaci贸n, use el siguiente comando: </p><br><pre> <code class="plaintext hljs">aws s3api put-bucket-versioning \ --bucket &lt;your-unique-bucket-name&gt; \ --versioning-configuration Status=Enabled</code> </pre> <br><p>  <strong>4. Creando el primer cluster de Kubernetes: 隆</strong> Entonces, est谩s listo para crear tu primer cluster!  Primero, configure las variables de entorno para simplificar el proceso.  Si omiti贸 la configuraci贸n de DNS (despu茅s del paso 2), agregue <code>.k8s.local</code> al valor <code>NAME</code> . </p><br><pre> <code class="plaintext hljs">export NAME=myfirstcluster.example.com export KOPS_STATE_STORE=s3://your-bucket-name</code> </pre> <br><p>  No olvide hacer un seguimiento de qu茅 zonas regionales est谩n disponibles para usted.  En este ejemplo, implementaremos un cl煤ster en la regi贸n <strong>us-east-2</strong> . </p><br><pre> <code class="plaintext hljs">aws ec2 describe-availability-zones --region us-east-2</code> </pre> <br><p>  Si est谩 utilizando una zona de alojamiento p煤blico, cree un cl煤ster con el siguiente comando: </p><br><pre> <code class="plaintext hljs">kops create cluster \ --zones us-east-2c \ --node-count 3 \ ${NAME}</code> </pre> <br><p>  Si usa una zona de alojamiento privado, haga lo siguiente: </p><br><pre> <code class="plaintext hljs">kops create cluster \ --zones us-east-2c \ --node-count 3 \ --dns private ${NAME}</code> </pre> <br><p>  Este comando le proporcionar谩 el registro de configuraci贸n del cl煤ster K8S.  El cl煤ster tarda en iniciarse, ya que crea nuevas m谩quinas EC2 para los nodos maestros minion. </p><br><pre> <code class="plaintext hljs">[ec2-user@ip-172-31-35-145 test]$ kops create cluster \ &gt; --dns private \ &gt; --zones us-east-2c \ &gt; --node-count 3 \ &gt; ${NAME} --yes I0306 09:45:29.636834 20628 create_cluster.go:439] Inferred --cloud=aws from zone "us-east-2c" I0306 09:45:29.637030 20628 create_cluster.go:971] Using SSH public key: /home/ec2-user/.ssh/id_rsa.pub I0306 09:45:29.850021 20628 subnets.go:184] Assigned CIDR 172.20.32.0/19 to subnet us-east-2c I0306 09:45:31.118837 20628 dns.go:92] Private DNS: skipping DNS validation I0306 09:45:46.986963 20628 executor.go:91] Tasks: 73 done / 73 total; 0 can run I0306 09:45:46.987101 20628 dns.go:153] Pre-creating DNS records I0306 09:45:47.668392 20628 update_cluster.go:248] Exporting kubecfg for cluster kops has set your kubectl context to k8s.appbase Cluster is starting. It should be ready in a few minutes.</code> </pre> <br><p>  Voila!  El cl煤ster K8s ya deber铆a estar funcionando. </p><br><p>  <strong>5. Verificaci贸n de cl煤ster:</strong> todas las instancias creadas por <code>kops</code> est谩n en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ASG (Grupos de Auto Scaling)</a> .  En caso de falla, las instancias ASG son verificadas y reconstruidas autom谩ticamente. </p><br><p>  Para cambiar la configuraci贸n del cl煤ster, ejecute el siguiente comando: </p><br><pre> <code class="plaintext hljs">kops edit cluster ${NAME}</code> </pre> <br><p>  Cada vez que cambie la configuraci贸n del cl煤ster, deber谩 crear un cl煤ster ejecutando el siguiente comando: </p><br><pre> <code class="plaintext hljs">kops update cluster ${NAME} --yes</code> </pre> <br><p>  Ver谩s algo como esto. </p><br><pre> <code class="plaintext hljs">[ec2-user@ip-172-31-35-145 examples]$ kops update cluster --yes Using cluster from kubectl context: k8s.appbase I0216 05:09:06.074467 2158 dns.go:92] Private DNS: skipping DNS validation I0216 05:09:07.699380 2158 executor.go:91] Tasks: 73 done / 73 total; 0 can run I0216 05:09:07.699486 2158 dns.go:153] Pre-creating DNS records I0216 05:09:07.961703 2158 update_cluster.go:248] Exporting kubecfg for cluster kops has set your kubectl context to k8s.appbase Cluster changes have been applied to the cloud.</code> </pre> <br><p>  Verifica el cl煤ster. </p><br><pre> <code class="plaintext hljs">kops validate cluster</code> </pre> <br><p>  Aseg煤rese de que el cl煤ster est茅 en funcionamiento. </p><br><pre> <code class="plaintext hljs">Using cluster from kubectl context: k8s.appbase Validating cluster k8s.appbase INSTANCE GROUPS NAME ROLE MACHINETYPE MIN MAX SUBNETS master-us-east-2c Master t2.large 1 1 us-east-2c nodes Node t2.medium 3 3 us-east-2c NODE STATUS NAME ROLE READY ip-172-20-44-33.us-east-2.compute.internal master True ip-172-20-52-48.us-east-2.compute.internal node True ip-172-20-62-30.us-east-2.compute.internal node True ip-172-20-64-53.us-east-2.compute.internal node True Your cluster k8s.appbase is ready</code> </pre> <br><p>  <strong>隆Mira tus nuevos k8!</strong> </p><br><p>  Con una simple llamada a la API de Kubernetes, puede verificar si la API est谩 en l铆nea y escuchando.  Use <code>kubectl</code> para verificar los nodos. </p><br><pre> <code class="plaintext hljs">kubectl get nodes</code> </pre> <br><p>  Esto le dar谩 informaci贸n sobre sus nodos y su estado actual. </p><br><pre> <code class="plaintext hljs">[ec2-user@ip-172-31-35-145 elasticsearch]$ kubectl get nodes NAME STATUS ROLES AGE VERSION ip-172-20-44-33.us-east-2.compute.internal Ready master 1m v1.8.6 ip-172-20-52-48.us-east-2.compute.internal Ready node 3m v1.8.6 ip-172-20-62-30.us-east-2.compute.internal Ready node 2m v1.8.6 ip-172-20-64-53.us-east-2.compute.internal Ready node 4m v1.8.6</code> </pre> <br><p>  Un sub Kubernetes es una abstracci贸n que representa un grupo de uno o m谩s contenedores de aplicaciones (como Docker) y varios recursos compartidos para estos contenedores.  Under se despliega en el nodo.  Si necesita escalar la aplicaci贸n, agregue nodos al K8S implementado. </p><br><p>  Para conocer los pods disponibles: </p><br><pre> <code class="plaintext hljs">kubectl get pods</code> </pre> <br><p>  Este comando enumerar谩 los hogares disponibles en el cl煤ster. </p><br><pre> <code class="plaintext hljs">[ec2-user@ip-172-31-35-145 ~]$ kubectl get pods NAME READY STATUS RESTARTS AGE es-5967f5d99c-5vcpb 1/1 Running 0 3h es-5967f5d99c-cqk88 1/1 Running 0 3h es-5967f5d99c-lp789 1/1 Running 0 3h</code> </pre> <br><h3 id="razvertyvanie-elasticsearch-v-klastere-k8s">  Implementaci贸n de Elasticsearch en el cl煤ster K8S </h3><br><p><img src="https://habrastorage.org/webt/ot/1m/he/ot1mhep0o9nltuo2ueq0puexg7g.png"></p><br><p>  Si no est谩 familiarizado con Kubernetes, le recomiendo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la capacitaci贸n en l铆nea de k8s</a> . </p><br><p>  Por el momento, hemos creado en el cl煤ster K8S: el nodo principal y dos nodos de agente.  La funci贸n del nodo principal es transferir los comandos de implementaci贸n a las aplicaciones que se ejecutan en los pods de los agentes de nodo. </p><br><p>  Las implementaciones de aplicaciones K8S son declarativas y se configuran a trav茅s de archivos JSON / YAML.  Elija un controlador basado en el tipo de aplicaci贸n o sistema que est谩 implementando.  Como Elasticsearch es una aplicaci贸n con estado, utilizaremos el controlador StatefulSet. </p><br><p>  <strong>6. Implementaci贸n a trav茅s de StatefulSet.</strong>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>StatefulSet</strong></a> gestiona pods seg煤n la especificaci贸n de contenedores id茅nticos.  Gestiona el despliegue y la escala del conjunto de hogares y garantiza el orden y la unicidad de estos hogares.  El controlador <strong>StatefulSet</strong> tambi茅n facilita la asociaci贸n de la aplicaci贸n con el volumen persistente, lo cual es importante para Elasticsearch. </p><br><p>  Cree un archivo llamado <code>es-stateful set. yaml</code> .  Contendr谩 la especificaci贸n Elasticsearch.  Si茅ntase libre de cambiar la configuraci贸n.  Para obtener una lista de variables de entorno que se pueden pasar a su imagen de Elasticsearch, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">consulte aqu铆</a> . </p><br><p>  <strong>7. Servicios:</strong> <code>Service</code> Kubernetes: una abstracci贸n que define un conjunto l贸gico de <code></code> y acceso a ellos.  Esto ayuda a que la aplicaci贸n contenedor identifique otra aplicaci贸n contenedor o su propia instancia en un hogar diferente. </p><br><p><img src="https://habrastorage.org/webt/di/wn/yq/diwnyqsurqxa0813hatxpfhfgco.png"></p><br><p>  <code>LoadBalancer</code> es un tipo especial de servicio que proporciona pods a redes externas y distribuye la carga.  Lo usaremos para crear una direcci贸n IP externa a trav茅s de la cual cualquiera puede contactar al cl煤ster Elasticsearch.  Utilizaremos este servicio para los nodos ES como una forma de descubrirnos. </p><br><p>  Cree un archivo llamado <code>es-svc.yaml</code> .  Ed铆telo y especifique el servicio de equilibrador de carga. </p><br><pre> <code class="plaintext hljs">apiVersion: v1 #API Version of the resource kind: Service #Type of resource metadata: #Contains metadata of this resource. name: elasticsearch #Name of this resource labels: #Additional identifier to put on pods component: elasticsearch #puts component = elasticsearch spec: #Specifications of this resource type: LoadBalancer #type of service selector: #will distribute load on pods which component: elasticsearch #have label `component = elasticsearch` ports: #Port on which LoadBalancer will listen - name: http #Name given to port port: 9200 #Port number protocol: TCP #Protocol supported - name: transport #Name given to port port: 9300 #Port number protocol: TCP #Protocol supported</code> </pre> <br><p>  <strong>8. Crear una aplicaci贸n:</strong> eso es todo lo que necesitamos.  Implemente nuestro cl煤ster Elasticsearch en K8S utilizando los siguientes comandos. </p><br><pre> <code class="plaintext hljs">kubectl create -f es-statefulset.yaml kubectl create -f es-svc.yaml</code> </pre> <br><p>  'Crear' es un comando universal para crear cualquier recurso en K8S. </p><br><p>  Nuestro cl煤ster Elasticsearch de 3 nodos (驴recuerda <code>replicas = 3</code> en la configuraci贸n StatefulSet?) Se lanzar谩 instant谩neamente. </p><br><p>  Podemos verificar los pods de Elasticsearch con este comando: </p><br><pre> <code class="plaintext hljs">kubectl get pods</code> </pre> <br><pre> <code class="plaintext hljs">[ec2-user@ip-172-31-35-145 test]$ kubectl get pods,svc,deployment NAME READY STATUS RESTARTS AGE es-0 1/1 Running 0 23m es-1 1/1 Running 0 17m es-2 1/1 Running 0 23m</code> </pre> <br><p>  <strong>9. Prueba del cl煤ster Elasticsearch:</strong> verifique si Elasticsearch est谩 configurado correctamente y funciona.  Obtenga la direcci贸n IP externa para conectarse a Elasticsearch.  Se ubicar谩 en el servicio <strong>LoadBalancer que</strong> creamos.  Use el siguiente comando para describir <strong>LoadBalancer</strong> : </p><br><pre> <code class="plaintext hljs">kubectl describe service elasticsearch</code> </pre> <br><pre> <code class="plaintext hljs">[ec2-user@ip-172-31-35-145 examples]$ kubectl describe service elasticsearch Name: elasticsearch Namespace: default Labels: component=elasticsearch Annotations: &lt;none&gt; Selector: component=elasticsearch Type: LoadBalancer IP: 100.70.114.146 LoadBalancer Ingress: http://a4d0c157d212811e898430af47d23da1-952261901.us-east-2.elb.amazonaws.com Port: http 9200/TCP TargetPort: 9200/TCP NodePort: http 31358/TCP Endpoints: 100.96.4.28:9200 Port: transport 9300/TCP TargetPort: 9300/TCP NodePort: transport 31767/TCP Endpoints: 100.96.4.28:9300 Session Affinity: None External Traffic Policy: Cluster Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal EnsuringLoadBalancer 1m service-controller Ensuring load balancer Normal EnsuredLoadBalancer 1m service-controller Ensured load balancer [ec2-user@ip-172-31-35-145 examples]$</code> </pre> <br><p>  Tenga en cuenta el valor de <code>LoadBalancer Ingress</code> .  Abra un navegador con un URI y n煤mero de sufijo del puerto externo Elasticsearch: <code>9200</code> .  Ver谩s esto: </p><br><p><img src="https://habrastorage.org/webt/el/b_/zl/elb_zlrvyocf5b7phv5pd9zubri.jpeg"></p><br><p>  Puede verificar la funcionalidad de los nodos <code>9200/_cluster /health?pretty</code> agregando: <code>9200/_cluster /health?pretty</code> a la direcci贸n IP externa. </p><br><p><img src="https://habrastorage.org/webt/hh/ye/aa/hhyeaabyci4yvxnwqjkxacghek4.jpeg"></p><br><p>  <strong>10. Prueba de curaci贸n de Kubernetes:</strong> StatefulSets tiene la <strong>capacidad de</strong> almacenar el n煤mero especificado de r茅plicas.  De esa manera, si un sub cae, StatefulSet comenzar谩 un nuevo sub. </p><br><p>  Lo probaremos simulando una falla (eliminando todos los pods en los que se ejecutan nuestras instancias de ES) para ver si nuestro cl煤ster de ES puede realizar copias de seguridad autom谩ticamente con datos intactos. </p><br><p><img src="https://habrastorage.org/webt/l1/vh/nb/l1vhnbrmqhhumqzqi1c7uczvdaa.gif"></p><br><p>  Como StatefulSet ejecuta un hogar a la vez, lleva tiempo restaurar todos los contenedores. </p><br><p>  Vemos que despu茅s de la recuperaci贸n de los hogares, un registro indexado est谩 disponible para nosotros en el estado anterior a la falla de ES. </p><br><h3 id="rekomenduem-sleduyuschie-shagi">  Pr贸ximos pasos recomendados </h3><br><p>  Antes de usar esta configuraci贸n en producci贸n, tenga en cuenta: </p><br><ol><li>  Configurar copias de seguridad.  Ayuda a recuperar datos perdidos.  Este proceso se automatiza mejor. </li><li>  Configuraci贸n de autorizaci贸n.  Queremos proteger el cl煤ster Elasticsearch.  Configurar la autenticaci贸n o autorizaci贸n b谩sica basada en un token de medios proporcionar谩 seguridad. </li><li>  Certificados TLS.  Configure LetsEncrypt / otros proveedores TLS de certificados de mapeo de dominios personales para nuestro cl煤ster ES y proteja todas las solicitudes que se le env铆en. </li></ol><br><p>  Aunque el art铆culo no trata sobre eso, sepa: Kubernetes puede hacer todo esto. </p><br><p>  Original: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">despliegue Elasticsearch con Kubernetes en AWS en 10 pasos</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es416643/">https://habr.com/ru/post/es416643/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es416633/index.html">QUIC, TLS 1.3, DNS sobre HTTPS, luego en todas partes</a></li>
<li><a href="../es416635/index.html">De derecha a izquierda. C贸mo activar la interfaz del sitio bajo RTL</a></li>
<li><a href="../es416637/index.html">M煤sica de papel y cart贸n: una breve historia del vari贸fono y el "sonido dibujado"</a></li>
<li><a href="../es416639/index.html">Entrevista con un pionero del rejuvenecimiento.</a></li>
<li><a href="../es416641/index.html">8 etapas del proceso de desarrollo de una interfaz de aplicaci贸n m贸vil</a></li>
<li><a href="../es416645/index.html">MIS Patrones de investigaci贸n</a></li>
<li><a href="../es416647/index.html">驴Las agencias gubernamentales sue帽an con riesgos el茅ctricos?</a></li>
<li><a href="../es416651/index.html">1M HTTP rps en 1 n煤cleo de CPU. DPDK en lugar de nginx + linux kernel TCP / IP</a></li>
<li><a href="../es416653/index.html">Ordenaci贸n de la biblioteca</a></li>
<li><a href="../es416657/index.html">Dos tercios de las tarjetas de memoria usadas contienen datos personales de propietarios anteriores</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
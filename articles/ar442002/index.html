<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>๐ฅ ๐ ๐ ุฅุฏุฎุงู ุงูุนุตุจูุฉ ODE ๐ง๐ฝโ๐คโ๐ง๐ป ๐ฐ๐ผ ๐ฉ๐ฝ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ุงููุนุงุฏูุงุช ุงูุชูุงุถููุฉ ุงูุนุตุจูุฉ ุงูุนุงุฏูุฉ 
 ูุชู ูุตู ูุณุจุฉ ูุจูุฑุฉ ูู ุงูุนูููุงุช ูู ุฎูุงู ุงููุนุงุฏูุงุช ุงูุชูุงุถููุฉ ุ ููุฐุง ูุฏ ูููู ุชุทูุฑ ุงููุธุงู ุงููุงุฏู ูุน ูุฑูุฑ ุงูููุช ุ ูุงู...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ุฅุฏุฎุงู ุงูุนุตุจูุฉ ODE</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/442002/" style=";text-align:right;direction:rtl"><h1 style=";text-align:right;direction:rtl">  ุงููุนุงุฏูุงุช ุงูุชูุงุถููุฉ ุงูุนุตุจูุฉ ุงูุนุงุฏูุฉ </h1><br>  ูุชู ูุตู ูุณุจุฉ ูุจูุฑุฉ ูู ุงูุนูููุงุช ูู ุฎูุงู ุงููุนุงุฏูุงุช ุงูุชูุงุถููุฉ ุ ููุฐุง ูุฏ ูููู ุชุทูุฑ ุงููุธุงู ุงููุงุฏู ูุน ูุฑูุฑ ุงูููุช ุ ูุงูุญุงูุฉ ุงูุทุจูุฉ ูููุฑูุถ ุ ูุงูุฎุตุงุฆุต ุงูุฃุณุงุณูุฉ ูุณูู ุงูุฃูุฑุงู ุงููุงููุฉ ุ ููุง ุฅูู ุฐูู.  ุงูุจูุงูุงุช ุงููุชุนููุฉ ุจูุฐู ุงูุนูููุงุช ูุชุณูุฉ ููุณุชูุฑุฉ ุจุทุจูุนุชูุง ุ ุจูุนูู ุฃู ุงูููุงุญุธุงุช ูู ุจุจุณุงุทุฉ ูุธุงูุฑ ูููุน ูู ุงูุญุงูุฉ ุงููุชุบูุฑุฉ ุจุงุณุชูุฑุงุฑ. <br><br>  ููุงู ุฃูุถูุง ููุน ุขุฎุฑ ูู ุงูุจูุงูุงุช ุงูุชุณูุณููุฉ ุ ููู ุจูุงูุงุช ูููุตูุฉ ุ ุนูู ุณุจูู ุงููุซุงู ุ ุจูุงูุงุช ูููุฉ NLP.  ุชุฎุชูู ุงูุญุงูุฉ ูู ูุซู ูุฐู ุงูุจูุงูุงุช ุจุดูู ูููุฑุฏ: ูู ุญุฑู ุฃู ูููุฉ ุฅูู ุฃุฎุฑู. <br><br>  ุงูุขู ุชุชู ูุนุงูุฌุฉ ููุง ุงูููุนูู ูู ูุฐู ุงูุจูุงูุงุช ุงูุชุณูุณููุฉ ุนุงุฏุฉ ุจูุงุณุทุฉ ุดุจูุงุช ูุชูุฑุฑุฉ ุ ุนูู ุงูุฑุบู ูู ุงุฎุชูุงูููุง ุจุทุจูุนุชููุง ููุจุฏู ุฃูููุง ูุชุทูุจุงู ุฃุณุงููุจ ูุฎุชููุฉ. <br><br>  ุชู ุชูุฏูู ููุงูุฉ ูุซูุฑุฉ ุฌุฏูุง ููุงูุชูุงู ูู <em>ูุคุชูุฑ NIPS</em> ุงูุฃุฎูุฑ ุ ูุงูุฐู ูููู ุฃู ูุณุงุนุฏ ูู ุญู ูุฐู ุงููุดููุฉ.  ููุชุฑุญ ุงููุคูููู ููุงุฑุจุฉ ุฃุทูููุง ุนูููุง <strong>ODEs ุงูุนุตุจูุฉ</strong> . <br><br>  ุญุงููุช ููุง ุฅุนุงุฏุฉ ุฅูุชุงุฌ ูุชูุฎูุต ูุชุงุฆุฌ ูุฐู ุงูููุงูุฉ ูู ุฃุฌู ุฌุนู ุงูุชุนุฑู ุนูู ููุฑุชูุง ุฃุณูู ููููุงู.  ูุจุฏู ูู ุฃู ูุฐู ุงูุจููุฉ ุงูุฌุฏูุฏุฉ ูุฏ ุชุฌุฏ ููุงููุง ูู ุงูุฃุฏูุงุช ุงูููุงุณูุฉ ูุนุงูู ุงูุจูุงูุงุช ุฅูู ุฌุงูุจ ุงูุดุจูุงุช ุงูุชูุงููููุฉ ูุงูุดุจูุงุช ุงููุชูุฑุฑุฉ. <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/7e/65/hf/7e65hfxs1amdqyy_uy6emdwulkg.png"></div><br><a name="habracut"></a><br><i></i><p style=";text-align:right;direction:rtl">  <em>ุงูุดูู</em> 1: ูุชุทูุจ <em>backpropagation</em> ุงูุชุฏุฑุฌ ุงููุณุชูุฑ ุญู ุงููุนุงุฏูุฉ ุงูุชูุงุถููุฉ ุฒูุงุฏุฉ ูุฑุฉ ุฃุฎุฑู ูู ุงูููุช ุงูููุงุณุจ. <br><br>  ุชูุซู ุงูุฃุณูู ุถุจุท ุงูุชุฏุฑุฌุงุช ุงูุชู ุชู ูุดุฑูุง ููุฎูู ุจูุงุณุทุฉ ุงูุชุฏุฑุฌุงุช ูู ุงูููุงุญุธุงุช. <br><br>  ุชูุถูุญ ูู ุงูููุงู ุงูุฃุตูู. </p><br><h2 style=";text-align:right;direction:rtl">  ุจูุงู ุงููุดููุฉ </h2><br>  ููููู ููุงู ุนูููุฉ ุชุทูุน ุจุนุถ ุนูุงุตุฑ ODE ุบูุฑ ุงููุนุฑููุฉ ูุชุณูุญ ุจูุฌูุฏ ุนุฏุฉ ููุงุญุธุงุช (ุตุงุฎุจุฉ) ุนูู ุทูู ูุณุงุฑ ุงูุนูููุฉ <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/438/dde/8ca/438dde8cabcfd6a826ed0257752e6499.svg" alt="\ frac {dz} {dt} = f (z (t)ุ t) \ุ (1)"></div><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/190/072/e64/190072e645d65dc29d6160aaf0dde065.svg" alt="\ {(z_0ุ t_0)ุ (z_1ุ t_1)ุ ...ุ (z_Mุ t_M) \} - \ text {notes}"></div><br>  ููููุฉ ุงูุนุซูุฑ ุนูู ุชูุฑูุจ <img src="https://habrastorage.org/getpro/habr/post_images/287/bb8/c63/287bb8c637a8a70238be4ea690a0a8e1.svg" alt="\ widehat {f} (zุ tุ \ theta)">  ูุธุงุฆู ุงููุชููู <img src="https://habrastorage.org/getpro/habr/post_images/6ad/6ab/1fa/6ad6ab1fa56e2c8b6d987dc5c1f68004.svg" alt="f (z ุ t)">  ุ <br><br>  ุฃููุงู ุ ููุฑ ูู ูููุฉ ุฃูุซุฑ ุจุณุงุทุฉ: ูุง ููุฌุฏ ุณูู ููุงุญุธุชุงู ุ ูู ุจุฏุงูุฉ ุงููุณุงุฑ ููู ููุงูุชู ุ <img src="https://habrastorage.org/getpro/habr/post_images/547/808/5c2/5478085c21b85393c8e9e0f78c2821b3.svg" alt="(z_0 ุ t_0) ุ (z_1 ุ t_1)">  . <br><br>  ุชุทูุฑ ุงููุธุงู ูุจุฏุฃ ูู ุงูุญุงูุฉ <img src="https://habrastorage.org/getpro/habr/post_images/7e2/d13/d9a/7e2d13d9a9cc05a84422c3b63260dd83.svg" alt="z_0 ุ t_0">  ูู ุงูููุช ุงููุญุฏุฏ <img src="https://habrastorage.org/getpro/habr/post_images/4fc/683/cd0/4fc683cd033494d093a0e2c6f021805b.svg" alt="t_1 - t_0">  ูุน ุจุนุถ ุงูุฏููุงููููุงุช ุงููุนููุฉ ุชุนูู ุจุงุณุชุฎุฏุงู ุฃู ุทุฑููุฉ ูุชุทูุฑ ุฃูุธูุฉ ODE.  ุจุนุฏ ุงููุธุงู ูู ุญุงูุฉ ุฌุฏูุฏุฉ <img src="https://habrastorage.org/getpro/habr/post_images/56d/8d1/11e/56d8d111e514029cf892aff24a82c768.svg" alt="\ ูุจุนุฉ {z_1} ุ t_1">  ุ ุจุงูููุงุฑูุฉ ูุน ุงูุฏููุฉ <img src="https://habrastorage.org/getpro/habr/post_images/f80/709/9a5/f807099a57f179abaa3ab5e70cee4c9c.svg" alt="z_1">  ููุชู ุชูููู ุงููุฑู ุจููููุง ูู ุฎูุงู ุชุบููุฑ ุงููุนููุงุช <img src="https://habrastorage.org/getpro/habr/post_images/2cb/bcb/347/2cbbcb347a44c276c1095ac5bb3f8242.svg" alt="\ ุซูุชุง">  ูุธุงุฆู ุงูุฏููุงููุงุช. <br><br>  ุฃู ุ ุจุดูู ุฃูุซุฑ ุฑุณููุฉ ุ ููุฑ ูู ุชูููู ูุธููุฉ ุงูุฎุณุงุฑุฉ <img src="https://habrastorage.org/getpro/habr/post_images/b03/557/43f/b0355743fe8383284ef53436870494da.svg" alt="L (\ hat {z_1})">  : <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/251/944/489/251944489756d64d40b61f0dc0d7cb0b.svg" alt="L (z (t_1)) = L \ Big (\ int_ {t_0} ^ {t_1} f (z (t) ุ t ุ \ theta) dt \ Big) = L \ big (\ text {ODESolve} (z ( t_0) ุ f ุ t_0 ุ t_1 ุ \ theta) \ big) \ุ (2)"></div><br>  ูุชูููู <img src="https://habrastorage.org/getpro/habr/post_images/899/a67/551/899a675510d28419769a9b42281f0c65.svg" alt="ูุงู">  ุ ุชุญุชุงุฌ ุฅูู ุญุณุงุจ ุงูุชุฏุฑุฌุงุช ูุฌููุน ุงููุนููุงุช: <img src="https://habrastorage.org/getpro/habr/post_images/194/e4f/6e5/194e4f6e59bbfefc52efebce3bb857a3.svg" alt="z (t_0) ุ t_0 ุ t_1 ุ \ theta">  .  ููููุงู ุจุฐูู ุ ุชุญุชุงุฌ ุฃููุงู ุฅูู ุชุญุฏูุฏ ููู <img src="https://habrastorage.org/getpro/habr/post_images/899/a67/551/899a675510d28419769a9b42281f0c65.svg" alt="ูุงู">  ูุนุชูุฏ ุนูู ุงูุฏููุฉ ูู ูู ูุญุธุฉ ูู ุงูุฒูู <img src="https://habrastorage.org/getpro/habr/post_images/823/f33/fc8/823f33fc81685e76b1d88f48c68eea32.svg" alt="(ุถ (ุฑ))">  : <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/e79/64f/b7f/e7964fb7f074d4f9c16893b53a1562c6.svg" alt="a (t) = - \ frac {\ ุงูุฌุฒุฆู L} {\ ุงูุฌุฒุฆู z (t)} \ุ (3)"></div><br><img src="https://habrastorage.org/getpro/habr/post_images/2e3/af6/935/2e3af69359cb79517739f0ccf9a8bc3e.svg" alt="(ุฑ)">  ููุทูู ุนูููุง ุญุงูุฉ <em>ูุชุฌุงูุฑุฉ</em> ุ ููุชู ุฅุนุทุงุก ุฏููุงููููุงุชูุง ุจูุงุณุทุฉ ูุนุงุฏูุฉ ุชูุงุถููุฉ ุฃุฎุฑู ุ ูุงูุชู ูููู ุงุนุชุจุงุฑูุง ุชูุงุธุฑููุง ูุณุชูุฑูุง ููุชูุงูุฒ ุจูู ุฏุงูุฉ ูุนูุฏุฉ ( <em>ูุงุนุฏุฉ ุงูุณูุณูุฉ</em> ): <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/006/b66/5d5/006b665d51719470f25859e6271463dc.svg" alt="\ frac {d a (t)} {d t} = -a (t) \ frac {\ ุฌุฒุฆู f (z (t)ุ tุ \ theta)} {\ ุฌุฒุฆูุฉ z} \ุ (4)"></div><br>  ูููู ุงูุนุซูุฑ ุนูู ุฅุฎุฑุงุฌ ูุฐู ุงูุตูุบุฉ ูู ููุญู ุงูููุงูุฉ ุงูุฃุตููุฉ. <br><br>  <i>ูุฌุจ ุงุนุชุจุงุฑ ุงููุชุฌูุงุช ูู ูุฐู ุงูููุงูุฉ ูุงููุงุช ุตุบูุฑุฉ ุ ุนูู ุงูุฑุบู ูู ุฃู ุงูููุงู ุงูุฃุตูู ูุณุชุฎุฏู ููุงู ูู ุชูุซูู ุงูุตู ูุงูุนููุฏ.</i> <br><br>  ุญู diffur (4) ูู ุงูููุช ุงูููุงุณุจ ุ ูุญุตู ุนูู ุงูุงุนุชูุงุฏ ุนูู ุงูุญุงูุฉ ุงูุฃูููุฉ <img src="https://habrastorage.org/getpro/habr/post_images/9ec/7ef/827/9ec7ef8276505d510f609b983c58fdc3.svg" alt="z (t_0)">  : <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/556/75a/7f0/55675a7f0c820f2a1da88e0802c97dc7.svg" alt="\ frac {\ ุฌุฒุฆูุฉ L} {\ ุฌุฒุฆูุฉ z (t_0)} = \ int_ {t_1} ^ {t_0} a (t) \ frac {\ ุฌุฒุฆูุฉ f (z (t) ุ t ุ \ theta)} {\ ุฌุฒุฆูุฉ z} dt \ุ (5)"></div><br>  ูุญุณุงุจ ุงูุชุฏุฑุฌ ูููุง ูุชุนูู <img src="https://habrastorage.org/getpro/habr/post_images/2a3/102/4ea/2a31024ea1803c34a47496e24a53a1ef.svg" alt="ุฑ">  ู <img src="https://habrastorage.org/getpro/habr/post_images/2cb/bcb/347/2cbbcb347a44c276c1095ac5bb3f8242.svg" alt="\ ุซูุชุง">  ููููู ุจุจุณุงุทุฉ ุงุนุชุจุงุฑูู ุฌุฒุกูุง ูู ุงูุฏููุฉ.  ูุชุณูู ูุฐู ุงูุญุงูุฉ <em>ุฒูุงุฏุฉ</em> .  ูุชู ุงูุญุตูู ุนูู ุฏููุงููุงุช ูุฐู ุงูุญุงูุฉ ุจุดูู ุชุงูู ูู ุงูุฏููุงููุงุช ุงูุฃุตููุฉ: <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/161/f11/79c/161f1179cbb6dfe3c18057d8abd0f45b.svg" alt="\ frac {d} {dt} \ ุชุจุฏุฃ {bmatrix} z โโ\\ \ theta \\ t \ end {bmatrix} (t) = f _ {\ text {aug}} ([zุ \ thetaุ t]): = \ start {bmatrix} f ([zุ \ thetaุ t]) \\ 0 \\ 1 \ end {bmatrix} \ุ (6)"></div><br>  ุซู ุงูุญุงูุฉ ุงููุชุฑุงููุฉ ููุฐู ุงูุญุงูุฉ ุงููุนุฒุฒุฉ: <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/7dc/7d0/553/7dc7d055304addbb695d1f23a9e640e6.svg" alt="a _ {\ text {aug}}: = \ start {bmatrix} a \\ a _ {\ theta} \\ a_t \ end {bmatrix} ุ a _ {\ theta} (t): = \ frac {\ ุงูุฌุฒุฆู L} { \ ุฌุฒุฆูุฉ \ theta (t)} ุ a_t (t): = \ frac {\ ุฌุฒุฆูุฉ L} {\ ุฌุฒุฆูุฉ t (t)} \ุ (7)"></div><br>  ุฏููุงููุงุช ุงูุชุฏุฑุฌ ุงููุนุฒุฒ: <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/985/437/7a4/9854377a42cda72fa53bedb928a9d023.svg" alt="\ frac {\ ุฌุฒุฆูุฉ f _ {\ text {aug}}} {\ ุฌุฒุฆูุฉ [zุ \ thetaุ t]} = \ ุชุจุฏุฃ {bmatrix} \ frac {\ ุฌุฒุฆูุฉ f} {\ ุฌุฒุฆูุฉ z} &amp;ุ \ frac {\ ุฌุฒุฆูุฉ f} {\ ุฌุฒุฆูุฉ \ theta} &amp;ุ \ frac {\ ุฌุฒุฆูุฉ f} {\ ุฌุฒุฆูุฉ t} \\ 0 &amp;ุ 0 &amp;ุ 0 \\ 0 &amp;ุ 0 &amp;ุ 0 \ end {bmatrix} \ุ (8)"></div><br>  ุงููุนุงุฏูุฉ ุงูุชูุงุถููุฉ ููุญุงูุฉ ุงููุชุถุงูุฑุฉ ูู ุงูุตูุบุฉ (4) ุซู: <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/bd3/b9f/7f3/bd3b9f7f3e6ec08881594346a8a3e4f3.svg" alt="\ frac {d a _ {\ text {aug}}} {dt} = - \ start {bmatrix} a \ frac {\ ุฌุฒุฆูุฉ f} {\ ุฌุฒุฆูุฉ z} &amp;ุ a \ frac {\ ุฌุฒุฆูุฉ f} {\ ุฌุฒุฆูุฉ \ theta} &amp;ุ a \ frac {\ ุฌุฒุฆูุฉ f} {\ ุฌุฒุฆูุฉ t} \ end {bmatrix} \ุ (9)"></div><br>  ููุชุฌ ุนู ุญู ODE ูุฐุง ูู ุงูููุช ุงููุญุฏุฏ: <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/5a0/01e/3d9/5a001e3d928ce08d05ff084353134d78.svg" alt="\ frac {\ ุฌุฒุฆูุฉ L} {\ ุฌุฒุฆูุฉ z (t_0)} = \ int_ {t_1} ^ {t_0} a (t) \ frac {\ ุฌุฒุฆูุฉ f (z (t) ุ t ุ \ theta)} {\ ุฌุฒุฆูุฉ z} dt \ุ (10)"></div><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/e09/ba3/cc6/e09ba3cc6674830a8847894c39020ec0.svg" alt="\ frac {\ ุฌุฒุฆูุฉ L} {\ ุฌุฒุฆูุฉ \ theta} = \ int_ {t_1} ^ {t_0} a (t) \ frac {\ ุฌุฒุฆูุฉ f (z (t) ุ t ุ \ theta)} {\ ุฌุฒุฆูุฉ \ theta } dt \ุ (11)"></div><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/022/f84/715/022f84715f62b101017a6dcb591d5de3.svg" alt="\ frac {\ ุงูุฌุฒุฆู L} {\ ุงูุฌุฒุฆู t_0} = \ int_ {t_1} ^ {t_0} a (t) \ frac {\ ุงูุฌุฒุฆู f (z (t) ุ t ุ \ theta)} {\ ุงูุฌุฒุฆู t} dt \ุ (12)"></div><br>  ูุง ูุน <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/0f9/b43/8a8/0f9b438a88408c879af759bcaf4d1d5e.svg" alt="\ frac {\ ุฌุฒุฆูุฉ L} {\ ุฌุฒุฆูุฉ t_1} = - a (t) \ frac {\ ุฌุฒุฆูุฉ f (z (t)ุ tุ \ theta)} {\ ุฌุฒุฆูุฉ t} \ุ (13)"></div><br>  ูุนุทู ุงูุชุฏุฑุฌุงุช ูู ุฌููุน ูุนููุงุช ุงูุฅุฏุฎุงู ุฅูู <em>ODESolve</em> ODE <em>ุญูุงูุง</em> . <br><br>  ูููู ุญุณุงุจ ุฌููุน ุงูุชุฏุฑุฌุงุช (10) ุ (11) ุ (12) ุ (13) ูุนูุง ูู ููุงููุฉ ูุงุญุฏุฉ ูู <em>ODESolve</em> ูุน ุฏููุงููููุงุช ุงูุญุงูุฉ ุงูููุถุงูุฉ ุงููุฏูุฌุฉ (9). <br><br><img src="https://habrastorage.org/webt/8k/pz/uk/8kpzukmizpmezmywov4b3zm29lc.png"><br>  <i>ุชูุถูุญ ูู ุงูููุงู ุงูุฃุตูู.</i> <br><br>  ุชุตู ุงูุฎูุงุฑุฒููุฉ ุฃุนูุงู ุงูุงูุชุดุงุฑ ุงูุนูุณู ูุชุฏุฑุฌ ุญู ODE ููุฑุตุฏุงุช ุงููุชุชุงููุฉ. <br><br>  ูู ุญุงูุฉ ูุฌูุฏ ุนุฏุฉ ููุงุญุธุงุช ุนูู ูุณุงุฑ ูุงุญุฏ ุ ูุชู ุญุณุงุจ ูู ุดูุก ุจุงูุทุฑููุฉ ููุณูุง ุ ูููู ูู ูุญุธุงุช ุงูุฑุตุฏ ุ ูุฌุจ ุถุจุท ูุนููุณ ุงูุชุฏุฑุฌ ุงููุฑูุฌ ุจูุงุณุทุฉ ุชุฏุฑุฌุงุช ูู ุงูููุงุญุธุฉ ุงูุญุงููุฉ ุ ููุง ูู ูุจูู ูู <em>ุงูุดูู 1</em> . <br><br><h1 style=";text-align:right;direction:rtl">  ุงูุชูููุฐ </h1><br>  ุงูููุฏ ุฃุฏูุงู ูู ุนููู ูู ุชูููุฐ <strong>ODEs ุงูุนุตุจูุฉ</strong> .  ููุฏ ูุนูุช ุฐูู ูู ุฃุฌู ููู ุฃูุถู ููุง ูุญุฏุซ.  ููุน ุฐูู ุ ููู ูุฑูุจ ุฌุฏูุง ููุง ุชู ุชูููุฐู ูู <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">ูุณุชูุฏุน</a> ูุคููู ุงูููุงู.  ุฃูู ูุญุชูู ุนูู ุฌููุน ุงูููุฏ ุงูุฐู ุชุญุชุงุฌ ุฅูู ูููู ูู ููุงู ูุงุญุฏ ุ ููุง ุฃูู ุชู ุชุนูููู ุฃูุซุฑ ููููุงู.  ููุชุทุจููุงุช ูุงูุชุฌุงุฑุจ ุงูุญููููุฉ ุ ูุง ูุฒุงู ูู ุงูุฃูุถู ุงุณุชุฎุฏุงู ุชุทุจูู ูุคููู ุงูููุงู ุงูุฃุตูู. <br><br><pre style=";text-align:right;direction:rtl"><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> IPython.display <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> clear_output <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm_notebook <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mpl <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns sns.color_palette(<span class="hljs-string"><span class="hljs-string">"bright"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> mpl <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.cm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tensor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nn <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.nn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functional <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> F <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch.autograd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Variable use_cuda = torch.cuda.is_available()</code> </pre> <br>  ุชุญุชุงุฌ ุฃููุงู ุฅูู ุชูููุฐ ุฃู ุทุฑููุฉ ูุชุทููุฑ ุฃูุธูุฉ ODE.  ูู ุฃุฌู ุงูุจุณุงุทุฉ ุ ูุชู ุชุทุจูู ุทุฑููุฉ Euler ููุง ุ ุนูู ุงูุฑุบู ูู ุฃู ุฃู ุทุฑููุฉ ุตุฑูุญุฉ ุฃู ุถูููุฉ ููุงุณุจุฉ. <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ode_solve</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(z0, t0, t1, f)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""     -   """</span></span> h_max = <span class="hljs-number"><span class="hljs-number">0.05</span></span> n_steps = math.ceil((abs(t1 - t0)/h_max).max().item()) h = (t1 - t0)/n_steps t = t0 z = z0 <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i_step <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n_steps): z = z + h * f(z, t) t = t + h <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z</code> </pre><br>  ูุตู ุฃูุถูุง ุงูุทุจูุฉ ุงููุงุฆูุฉ ููุธููุฉ ุฏููุงููููุฉ ุฐุงุช ูุนููุงุช ูุน ุนุฏุฉ ุทุฑู ูููุฏุฉ. <br><br>  ุฃููุงู: ุชุญุชุงุฌ ุฅูู ุฅุฑุฌุงุน ุฌููุน ุงููุนููุงุช ุงูุชู ุชุนุชูุฏ ุนูููุง ุงููุธููุฉ ูู ุดูู ูุชุฌู. <br><br>  ุซุงููุงู: ูู ุงูุถุฑูุฑู ุญุณุงุจ ุงูุฏููุงููุงุช ุงููุนุฒุฒุฉ.  ุชุนุชูุฏ ูุฐู ุงูุฏููุงููุงุช ุนูู ุงูุชุฏุฑุฌ ุงููููู ูููุธููุฉ ุงููุนููุฉ ูู ุญูุซ ุงููุนููุงุช ูุจูุงูุงุช ุงูุฅุฏุฎุงู.  ุญุชู ูุง ุชุถุทุฑ ุฅูู ุชุณุฌูู ุงูุชุฏุฑุฌ <strong>ุงููููู</strong> ูุน ูู ูุฏ ููู ููุฏุณุฉ ุฌุฏูุฏุฉ ุ <strong>ุณูุณุชุฎุฏู</strong> ุทุฑููุฉ <strong>torch.autograd.grad</strong> . <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward_with_grad</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, z, t, grad_outputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Compute f and a df/dz, a df/dp, a df/dt"""</span></span> batch_size = z.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] out = self.forward(z, t) a = grad_outputs adfdz, adfdt, *adfdp = torch.autograd.grad( (out,), (z, t) + tuple(self.parameters()), grad_outputs=(a), allow_unused=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, retain_graph=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> ) <span class="hljs-comment"><span class="hljs-comment">#  grad       , #  expand   if adfdp is not None: adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0) adfdp = adfdp.expand(batch_size, -1) / batch_size if adfdt is not None: adfdt = adfdt.expand(batch_size, 1) / batch_size return out, adfdz, adfdt, adfdp def flatten_parameters(self): p_shapes = [] flat_parameters = [] for p in self.parameters(): p_shapes.append(p.size()) flat_parameters.append(p.flatten()) return torch.cat(flat_parameters)</span></span></code> </pre><br>  ูุตู ุงูููุฏ ุฃุฏูุงู ุงูุงูุชุดุงุฑ <em>ุงูุฃูุงูู ูุงูุฎููู ูููุงุฏ ODE ุงูุนุตุจูุฉ</em> .  ูู ุงูุถุฑูุฑู ูุตู ูุฐุง ุงูุฑูุฒ ุนู <strong><em>torch.nn.Module</em></strong> ุงูุฑุฆูุณู ูู ุดูู ูุธููุฉ <strong><em>torch.autograd.Function</em></strong> ูุฃูู ูู ุงูุฃุฎูุฑ ููููู ุชูููุฐ ุทุฑููุฉ ุชุนุณููุฉ ูููุดุฑ ุงูุฎููู ุ ุนูู ุนูุณ ุงููุญุฏุฉ ุงูููุทูุฉ.  ูุฐูู ูุฐุง ูุฌุฑุฏ ุนูุงุฒ. <br><br>  ูุฐู ุงูููุฒุฉ ุชููู ูุฑุงุก ููุฌ <em>ODE ุงูุนุตุจู</em> ุจุฃูููู. <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ODEAdjoint</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.autograd.Function)</span></span></span><span class="hljs-class">:</span></span> @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ctx, z0, t, flat_parameters, func)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span> isinstance(func, ODEF) bs, *z_shape = z0.size() time_len = t.size(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): z = torch.zeros(time_len, bs, *z_shape).to(z0) z[<span class="hljs-number"><span class="hljs-number">0</span></span>] = z0 <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i_t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(time_len - <span class="hljs-number"><span class="hljs-number">1</span></span>): z0 = ode_solve(z0, t[i_t], t[i_t+<span class="hljs-number"><span class="hljs-number">1</span></span>], func) z[i_t+<span class="hljs-number"><span class="hljs-number">1</span></span>] = z0 ctx.func = func ctx.save_for_backward(t, z.clone(), flat_parameters) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z @staticmethod <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">backward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ctx, dLdz)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" dLdz shape: time_len, batch_size, *z_shape """</span></span> func = ctx.func t, z, flat_parameters = ctx.saved_tensors time_len, bs, *z_shape = z.size() n_dim = np.prod(z_shape) n_params = flat_parameters.size(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment">#   , #       def augmented_dynamics(aug_z_i, t_i): """   -     t_i -   : bs, 1 aug_z_i -   : bs, n_dim*2 + n_params + 1 """ #     z_i, a = aug_z_i[:, :n_dim], aug_z_i[:, n_dim:2*n_dim] # Unflatten z and a z_i = z_i.view(bs, *z_shape) a = a.view(bs, *z_shape) with torch.set_grad_enabled(True): t_i = t_i.detach().requires_grad_(True) z_i = z_i.detach().requires_grad_(True) faug = func.forward_with_grad(z_i, t_i, grad_outputs=a) func_eval, adfdz, adfdt, adfdp = faug adfdz = adfdz if adfdz is not None else torch.zeros(bs, *z_shape) adfdp = adfdp if adfdp is not None else torch.zeros(bs, n_params) adfdt = adfdt if adfdt is not None else torch.zeros(bs, 1) adfdz = adfdz.to(z_i) adfdp = adfdp.to(z_i) adfdt = adfdt.to(z_i) # Flatten f and adfdz func_eval = func_eval.view(bs, n_dim) adfdz = adfdz.view(bs, n_dim) return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1) dLdz = dLdz.view(time_len, bs, n_dim) # flatten dLdz   with torch.no_grad(): ##      #    , #       adj_z = torch.zeros(bs, n_dim).to(dLdz) adj_p = torch.zeros(bs, n_params).to(dLdz) #    z  p,        adj_t = torch.zeros(time_len, bs, 1).to(dLdz) for i_t in range(time_len-1, 0, -1): z_i = z[i_t] t_i = t[i_t] f_i = func(z_i, t_i).view(bs, n_dim) #      dLdz_i = dLdz[i_t] dLdt_i = torch.bmm(torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0] #     adj_z += dLdz_i adj_t[i_t] = adj_t[i_t] - dLdt_i #      aug_z = torch.cat(( z_i.view(bs, n_dim), adj_z, torch.zeros(bs, n_params).to(z) adj_t[i_t]), dim=-1 ) #  ()      aug_ans = ode_solve(aug_z, t_i, t[i_t-1], augmented_dynamics) #       adj_z[:] = aug_ans[:, n_dim:2*n_dim] adj_p[:] += aug_ans[:, 2*n_dim:2*n_dim + n_params] adj_t[i_t-1] = aug_ans[:, 2*n_dim + n_params:] del aug_z, aug_ans ##         #    dLdz_0 = dLdz[0] dLdt_0 = torch.bmm(torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1))[:, 0] #  adj_z += dLdz_0 adj_t[0] = adj_t[0] - dLdt_0 return adj_z.view(bs, *z_shape), adj_t, adj_p, None</span></span></code> </pre><br>  ุงูุขู ููุฑุงุญุฉ ุ ูู ูุฐู ุงููุธููุฉ ูู <strong>nn.Module</strong> . <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">NeuralODE</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, func)</span></span></span><span class="hljs-function">:</span></span> super(NeuralODE, self).__init__() <span class="hljs-keyword"><span class="hljs-keyword">assert</span></span> isinstance(func, ODEF) self.func = func <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, z0, t=Tensor</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">([</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">0.</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">, </span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1.</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">])</span></span></span></span><span class="hljs-function"><span class="hljs-params">, return_whole_sequence=False)</span></span></span><span class="hljs-function">:</span></span> t = t.to(z0) z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> return_whole_sequence: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z[<span class="hljs-number"><span class="hljs-number">-1</span></span>]</code> </pre><br><br><h1 style=";text-align:right;direction:rtl">  ุงูุชุทุจูู </h1><br><h2 style=";text-align:right;direction:rtl">  ุงุณุชุนุงุฏุฉ ูุธููุฉ ุงูุฏููุงููุงุช ุงูุญููููุฉ (ุงูุชุญูู ูู ุงูููุฌ) </h2><br>  ูุงุฎุชุจุงุฑ ุฃุณุงุณู ุ ุฏุนููุง ุงูุขู ูุชุญูู ููุง ุฅุฐุง ูุงู ุจุฅููุงู <strong>Neural ODE</strong> ุงุณุชุนุงุฏุฉ ุงููุธููุฉ ุงูุญููููุฉ ููุฏููุงููุงุช ุจุงุณุชุฎุฏุงู ุจูุงูุงุช ุงูุฑุตุฏ. <br><br>  ููููุงู ุจุฐูู ุ ูุญุฏุฏ ุฃููุงู ูุธููุฉ ุฏููุงููุงุช ODE ุ ููุทูุฑ ุงููุณุงุฑ ุจูุงุกู ุนููู ุ ุซู ูุญุงูู ุงุณุชุนุงุฏุชู ูู ูุธููุฉ ุงูุฏููุงููุงุช ุฐุงุช ุงููุนููุงุช ุงูุนุดูุงุฆูุฉ. <br><br>  ุฃููุงู ุ ุฏุนููุง ูุชุญูู ูู ุฃุจุณุท ุญุงูุงุช ODE ุงูุฎุทูุฉ.  ูุธููุฉ ุงูุฏููุงููุงุช ูู ุจุจุณุงุทุฉ ุนูู ูุตูููุฉ. <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/eb4/fdc/86a/eb4fdc86a1c5f56ab1b6e37e575e7c72.svg" alt="\ frac {dz} {dt} = \ ุชุจุฏุฃ {bmatrix} -0.1 &amp;ุ -1.0 \\ 1.0 &amp;ุ -0.1 \ end {bmatrix} z"></div><br>  ูุชู ุชุญุฏูุฏ ุงููุธููุฉ ุงููุฏุฑุจุฉ ุจูุงุณุทุฉ ูุตูููุฉ ุนุดูุงุฆูุฉ. <br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/nj/q6/es/njq6eswuevh4rhx-8nhzyz-cq_k.gif"></div><br>  ุนูุงูุฉ ุนูู ุฐูู ุ ุฏููุงููุงุช ุฃูุซุฑ ุชุนููุฏูุง ุจูููู (ุจุฏูู ุตูุฑุฉ ูุชุญุฑูุฉ ุ ูุฃู ุนูููุฉ ุงูุชุนูู ููุณุช ุฌูููุฉ ุฌุฏูุง :)) <br>  ูุธููุฉ ุงูุชุนูู ููุง ูู ุดุจูุฉ ูุชุตูุฉ ุจุงููุงูู ุจุทุจูุฉ ูุงุญุฏุฉ ูุฎููุฉ. <br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/tr/4n/eb/tr4nebjdrs4pt4v5vlzleai8exe.png"></div><br><div class="spoiler" style=";text-align:right;direction:rtl">  <b class="spoiler_title">ููุฏ</b> <div class="spoiler_text" style=";text-align:right;direction:rtl"><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">LinearODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(ODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, W)</span></span></span><span class="hljs-function">:</span></span> super(LinearODEF, self).__init__() self.lin = nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) self.lin.weight = nn.Parameter(W) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.lin(x)</code> </pre><br>  ูุธููุฉ ุงูุฏููุงููุงุช ูู ูุฌุฑุฏ ูุตูููุฉ <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">SpiralFunctionExample</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(LinearODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> matrix = Tensor([[<span class="hljs-number"><span class="hljs-number">-0.1</span></span>, <span class="hljs-number"><span class="hljs-number">-1.</span></span>], [<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">-0.1</span></span>]]) super(SpiralFunctionExample, self).__init__(matrix)</code> </pre><br>  ูุตูููุฉ ูุนููุฉ ุนุดูุงุฆูุง <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RandomLinearODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(LinearODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(RandomLinearODEF, self).__init__(torch.randn(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)/<span class="hljs-number"><span class="hljs-number">2.</span></span>)</code> </pre><br>  ุฏููุงููุงุช ููุณุงุฑุงุช ุฃูุซุฑ ุชุทูุฑุง <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TestODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(ODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, A, B, x0)</span></span></span><span class="hljs-function">:</span></span> super(TestODEF, self).__init__() self.A = nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) self.A.weight = nn.Parameter(A) self.B = nn.Linear(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) self.B.weight = nn.Parameter(B) self.x0 = nn.Parameter(x0) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> xTx0 = torch.sum(x*self.x0, dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) dxdt = torch.sigmoid(xTx0) * self.A(x - self.x0) + torch.sigmoid(-xTx0) * self.B(x + self.x0) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> dxdt</code> </pre><br>  ุฏููุงููุงุช ุงูุชุนูู ูู ุดูู ุดุจูุฉ ูุชุตูุฉ ุจุงููุงูู <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">NNODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(ODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, in_dim, hid_dim, time_invariant=False)</span></span></span><span class="hljs-function">:</span></span> super(NNODEF, self).__init__() self.time_invariant = time_invariant <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> time_invariant: self.lin1 = nn.Linear(in_dim, hid_dim) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: self.lin1 = nn.Linear(in_dim+<span class="hljs-number"><span class="hljs-number">1</span></span>, hid_dim) self.lin2 = nn.Linear(hid_dim, hid_dim) self.lin3 = nn.Linear(hid_dim, in_dim) self.elu = nn.ELU(inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> self.time_invariant: x = torch.cat((x, t), dim=<span class="hljs-number"><span class="hljs-number">-1</span></span>) h = self.elu(self.lin1(x)) h = self.elu(self.lin2(h)) out = self.lin3(h) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_np</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x.detach().cpu().numpy() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_trajectories</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(obs=None, times=None, trajs=None, save=None, figsize=</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">16</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">, </span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">8</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">)</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> plt.figure(figsize=figsize) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> obs <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> times <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: times = [<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>] * len(obs) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> o, t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(obs, times): o, t = to_np(o), to_np(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> b_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(o.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]): plt.scatter(o[:, b_i, <span class="hljs-number"><span class="hljs-number">0</span></span>], o[:, b_i, <span class="hljs-number"><span class="hljs-number">1</span></span>], c=t[:, b_i, <span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=cm.plasma) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> trajs <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> z <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> trajs: z = to_np(z) plt.plot(z[:, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>], z[:, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], lw=<span class="hljs-number"><span class="hljs-number">1.5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> save <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: plt.savefig(save) plt.show() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">conduct_experiment</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ode_true, ode_trained, n_steps, name, plot_freq=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Create data z0 = Variable(torch.Tensor([[0.6, 0.3]])) t_max = 6.29*5 n_points = 200 index_np = np.arange(0, n_points, 1, dtype=np.int) index_np = np.hstack([index_np[:, None]]) times_np = np.linspace(0, t_max, num=n_points) times_np = np.hstack([times_np[:, None]]) times = torch.from_numpy(times_np[:, :, None]).to(z0) obs = ode_true(z0, times, return_whole_sequence=True).detach() obs = obs + torch.randn_like(obs) * 0.01 # Get trajectory of random timespan min_delta_time = 1.0 max_delta_time = 5.0 max_points_num = 32 def create_batch(): t0 = np.random.uniform(0, t_max - max_delta_time) t1 = t0 + np.random.uniform(min_delta_time, max_delta_time) idx = sorted(np.random.permutation( index_np[(times_np &gt; t0) &amp; (times_np &lt; t1)] )[:max_points_num]) obs_ = obs[idx] ts_ = times[idx] return obs_, ts_ # Train Neural ODE optimizer = torch.optim.Adam(ode_trained.parameters(), lr=0.01) for i in range(n_steps): obs_, ts_ = create_batch() z_ = ode_trained(obs_[0], ts_, return_whole_sequence=True) loss = F.mse_loss(z_, obs_.detach()) optimizer.zero_grad() loss.backward(retain_graph=True) optimizer.step() if i % plot_freq == 0: z_p = ode_trained(z0, times, return_whole_sequence=True) plot_trajectories(obs=[obs], times=[times], trajs=[z_p], save=f"assets/imgs/{name}/{i}.png") clear_output(wait=True) ode_true = NeuralODE(SpiralFunctionExample()) ode_trained = NeuralODE(RandomLinearODEF()) conduct_experiment(ode_true, ode_trained, 500, "linear") func = TestODEF(Tensor([[-0.1, -0.5], [0.5, -0.1]]), Tensor([[0.2, 1.], [-1, 0.2]]), Tensor([[-1., 0.]])) ode_true = NeuralODE(func) func = NNODEF(2, 16, time_invariant=True) ode_trained = NeuralODE(func) conduct_experiment(ode_true, ode_trained, 3000, "comp", plot_freq=30)</span></span></code> </pre><br></div></div><br>  ููุง ุชุฑูู ุ <em>ODE Neural ูู</em> ุฌูุฏ ุฌุฏุง ูู ุงุณุชุนุงุฏุฉ ุฏููุงููุงุช.  ููุฐุง ูู ุ ููููู ููู ุฃุนูุงู. <br>  ุชุญูู ุงูุขู ูู ูุดููุฉ ุฃูุซุฑ ุชุนููุฏูุง (MNISTุ haha). <br><br><h2 style=";text-align:right;direction:rtl">  ODE ุงูุนุตุจูุฉ ูุณุชูุญุงุฉ ูู ResNets </h2><br>  ูู ResNet'ax ุ ุชุชุบูุฑ ุงูุญุงูุฉ ุงููุงููุฉ ููููุง ููุตูุบุฉ <br><br><p style=";text-align:right;direction:rtl"></p><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/30a/6b2/d3c/30a6b2d3c27bb27afaeb4736072e4446.svg" alt="h_ {t + 1} = h_ {t} + f (h_ {t} ุ \ theta_ {t})"></div><br>  ุงูู <img src="https://habrastorage.org/getpro/habr/post_images/7ca/860/97d/7ca86097dc5dc0d9cbb9b454168de928.svg" alt="t \ in \ {0 ... T \}">  ูู ุฑูู ูุชูุฉ ู <img src="https://habrastorage.org/getpro/habr/post_images/eb2/5f7/ddf/eb25f7ddf77e46681e256b28fecaef35.svg" alt="ู">  ูุฐู ูู ูุธููุฉ ุชุนููุชูุง ุงูุทุจูุงุช ุฏุงุฎู ุงููุชูุฉ. <br><br>  ูู ุงูุญุฏ ุงูุฃูุตู ุ ุฅุฐุง ุฃุฎุฐูุง ุนุฏุฏูุง ูุง ุญุตุฑ ูู ูู ุงููุชู ุจุฎุทูุงุช ุฃุตุบุฑ ูู ุฃู ููุช ูุถู ุ ูุณูู ูุญุตู ุนูู ุฏููุงููููุงุช ูุณุชูุฑุฉ ููุทุจูุฉ ุงููุฎููุฉ ูู ุดูู ODE ุ ุชูุงููุง ููุง ูุงู ุฃุนูุงู. <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/629/67a/d41/62967ad41e5f50cc65e1c1e55a2860d3.svg" alt="\ frac {dh (t)} {dt} = f (h (t) ุ t ุ \ theta)"></div><br>  ุจุฏุกุง ูู ุทุจูุฉ ุงูุฅุฏุฎุงู <img src="https://habrastorage.org/getpro/habr/post_images/c33/9b9/bc0/c339b9bc0244968c806390c2e66fdb62.svg" alt="ุญ (0)">  ูููููุง ุชุญุฏูุฏ ุทุจูุฉ ุงูุฅุฎุฑุงุฌ <img src="https://habrastorage.org/getpro/habr/post_images/b7e/dec/ef3/b7edecef308ce0df4f3d1c8aaa753617.svg" alt="ุญ (ุฑ)">  ูุญู ููุฐุง ODE ูู ููุช T. <br><br>  ุงูุขู ูููููุง ุงูุงุนุชูุงุฏ <img src="https://habrastorage.org/getpro/habr/post_images/2cb/bcb/347/2cbbcb347a44c276c1095ac5bb3f8242.svg" alt="\ ุซูุชุง">  ููุง ุงููุนููุงุช ุงูููุฒุนุฉ ( <em>ุงููุดุชุฑูุฉ</em> ) ุจูู ุฌููุน ุงููุชู ูุชูุงููุฉ ุงูุตุบุฑ. <br><br><h3 style=";text-align:right;direction:rtl">  ุงูุชุญูู ูู ุตุญุฉ ุจููุฉ ODE ุงูุนุตุจูุฉ ุนูู MNIST </h3><br>  ูู ูุฐุง ุงูุฌุฒุก ุ ุณูุฎุชุจุฑ ูุฏุฑุฉ <em>ODE Neural</em> ูุงุณุชุฎุฏุงููุง ูููููุงุช ูู ุฃุจููุฉ ูุฃูููุฉ ุฃูุซุฑ. <br><br>  ุนูู ูุฌู ุงูุฎุตูุต ุ ุณูุณุชุจุฏู ุงููุชู ุงููุชุจููุฉ ุจู <em>ODE Neural</em> ูู ูุตูู MNIST. <br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/7c/gw/ia/7cgwiawqx6-_kxk82qpenqplowi.png" width="400"></div><br><br><div class="spoiler" style=";text-align:right;direction:rtl">  <b class="spoiler_title">ููุฏ</b> <div class="spoiler_text" style=";text-align:right;direction:rtl"><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">norm</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dim)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> nn.BatchNorm2d(dim) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">conv3x3</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(in_feats, out_feats, stride=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> nn.Conv2d(in_feats, out_feats, kernel_size=<span class="hljs-number"><span class="hljs-number">3</span></span>, stride=stride, padding=<span class="hljs-number"><span class="hljs-number">1</span></span>, bias=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">add_time</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(in_tensor, t)</span></span></span><span class="hljs-function">:</span></span> bs, c, w, h = in_tensor.shape <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> torch.cat((in_tensor, t.expand(bs, <span class="hljs-number"><span class="hljs-number">1</span></span>, w, h)), dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ConvODEF</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(ODEF)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, dim)</span></span></span><span class="hljs-function">:</span></span> super(ConvODEF, self).__init__() self.conv1 = conv3x3(dim + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim) self.norm1 = norm(dim) self.conv2 = conv3x3(dim + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim) self.norm2 = norm(dim) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> xt = add_time(x, t) h = self.norm1(torch.relu(self.conv1(xt))) ht = add_time(h, t) dxdt = self.norm2(torch.relu(self.conv2(ht))) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> dxdt <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ContinuousNeuralMNISTClassifier</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, ode)</span></span></span><span class="hljs-function">:</span></span> super(ContinuousNeuralMNISTClassifier, self).__init__() self.downsampling = nn.Sequential( nn.Conv2d(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), norm(<span class="hljs-number"><span class="hljs-number">64</span></span>), nn.ReLU(inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>), nn.Conv2d(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), norm(<span class="hljs-number"><span class="hljs-number">64</span></span>), nn.ReLU(inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>), nn.Conv2d(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), ) self.feature = ode self.norm = norm(<span class="hljs-number"><span class="hljs-number">64</span></span>) self.avg_pool = nn.AdaptiveAvgPool2d((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) self.fc = nn.Linear(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x)</span></span></span><span class="hljs-function">:</span></span> x = self.downsampling(x) x = self.feature(x) x = self.norm(x) x = self.avg_pool(x) shape = torch.prod(torch.tensor(x.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>:])).item() x = x.view(<span class="hljs-number"><span class="hljs-number">-1</span></span>, shape) out = self.fc(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out func = ConvODEF(<span class="hljs-number"><span class="hljs-number">64</span></span>) ode = NeuralODE(func) model = ContinuousNeuralMNISTClassifier(ode) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: model = model.cuda() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision img_std = <span class="hljs-number"><span class="hljs-number">0.3081</span></span> img_mean = <span class="hljs-number"><span class="hljs-number">0.1307</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">32</span></span> train_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(<span class="hljs-string"><span class="hljs-string">"data/mnist"</span></span>, train=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, download=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((img_mean,), (img_std,)) ]) ), batch_size=batch_size, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> ) test_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST(<span class="hljs-string"><span class="hljs-string">"data/mnist"</span></span>, train=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, download=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, transform=torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((img_mean,), (img_std,)) ]) ), batch_size=<span class="hljs-number"><span class="hljs-number">128</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span> ) optimizer = torch.optim.Adam(model.parameters()) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(epoch)</span></span></span><span class="hljs-function">:</span></span> num_items = <span class="hljs-number"><span class="hljs-number">0</span></span> train_losses = [] model.train() criterion = nn.CrossEntropyLoss() print(<span class="hljs-string"><span class="hljs-string">f"Training Epoch </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{epoch}</span></span></span><span class="hljs-string">..."</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> batch_idx, (data, target) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(enumerate(train_loader), total=len(train_loader)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: data = data.cuda() target = target.cuda() optimizer.zero_grad() output = model(data) loss = criterion(output, target) loss.backward() optimizer.step() train_losses += [loss.item()] num_items += data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(<span class="hljs-string"><span class="hljs-string">'Train loss: {:.5f}'</span></span>.format(np.mean(train_losses))) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> train_losses <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">test</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> accuracy = <span class="hljs-number"><span class="hljs-number">0.0</span></span> num_items = <span class="hljs-number"><span class="hljs-number">0</span></span> model.eval() criterion = nn.CrossEntropyLoss() print(<span class="hljs-string"><span class="hljs-string">f"Testing..."</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> torch.no_grad(): <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> batch_idx, (data, target) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(enumerate(test_loader), total=len(test_loader)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: data = data.cuda() target = target.cuda() output = model(data) accuracy += torch.sum(torch.argmax(output, dim=<span class="hljs-number"><span class="hljs-number">1</span></span>) == target).item() num_items += data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>] accuracy = accuracy * <span class="hljs-number"><span class="hljs-number">100</span></span> / num_items print(<span class="hljs-string"><span class="hljs-string">"Test Accuracy: {:.3f}%"</span></span>.format(accuracy)) n_epochs = <span class="hljs-number"><span class="hljs-number">5</span></span> test() train_losses = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, n_epochs + <span class="hljs-number"><span class="hljs-number">1</span></span>): train_losses += train(epoch) test() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) history = pd.DataFrame({<span class="hljs-string"><span class="hljs-string">"loss"</span></span>: train_losses}) history[<span class="hljs-string"><span class="hljs-string">"cum_data"</span></span>] = history.index * batch_size history[<span class="hljs-string"><span class="hljs-string">"smooth_loss"</span></span>] = history.loss.ewm(halflife=<span class="hljs-number"><span class="hljs-number">10</span></span>).mean() history.plot(x=<span class="hljs-string"><span class="hljs-string">"cum_data"</span></span>, y=<span class="hljs-string"><span class="hljs-string">"smooth_loss"</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), title=<span class="hljs-string"><span class="hljs-string">"train error"</span></span>)</code> </pre><br></div></div><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">Testing... 100% 79/79 [00:01&lt;00:00, 45.69it/s] Test Accuracy: 9.740% Training Epoch 1... 100% 1875/1875 [01:15&lt;00:00, 24.69it/s] Train loss: 0.20137 Testing... 100% 79/79 [00:01&lt;00:00, 46.64it/s] Test Accuracy: 98.680% Training Epoch 2... 100% 1875/1875 [01:17&lt;00:00, 24.32it/s] Train loss: 0.05059 Testing... 100% 79/79 [00:01&lt;00:00, 46.11it/s] Test Accuracy: 97.760% Training Epoch 3... 100% 1875/1875 [01:16&lt;00:00, 24.63it/s] Train loss: 0.03808 Testing... 100% 79/79 [00:01&lt;00:00, 45.65it/s] Test Accuracy: 99.000% Training Epoch 4... 100% 1875/1875 [01:17&lt;00:00, 24.28it/s] Train loss: 0.02894 Testing... 100% 79/79 [00:01&lt;00:00, 45.42it/s] Test Accuracy: 99.130% Training Epoch 5... 100% 1875/1875 [01:16&lt;00:00, 24.67it/s] Train loss: 0.02424 Testing... 100% 79/79 [00:01&lt;00:00, 45.89it/s] Test Accuracy: 99.170%</code> </pre><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/zx/zv/5x/zxzv5x4ktqyy9lt19of-d2i4few.png"></div><br>  ุจุนุฏ ุชุฏุฑูุจ ุชูุฑูุจู ููุบุงูุฉ ุฎูุงู ุฎูุณ ุนุตูุฑ ููุท ู 6 ุฏูุงุฆู ูู ุงูุชุฏุฑูุจ ุ ูุตู ุงููููุฐุฌ ุจุงููุนู ุฅูู ุฎุทุฃ ุงุฎุชุจุงุฑ ุฃูู ูู 1ูช.  ูููููุง ุงูููู ุฃู <em>ODEs ุงูุนุตุจูุฉ</em> ุชุฏูุฌ ูุฐูู ูุนูุตุฑ ูู ุดุจูุงุช ุฃูุซุฑ ุชูููุฏูุฉ. <br><br>  ูู ููุงูุชูู ุ ูุงุฑู ุงููุคูููู ุฃูุถูุง ูุฐุง ุงููุตูู (ODE-Net) ุจุดุจูุฉ ููุชุธูุฉ ูุชุตูุฉ ุจุงููุงูู ุ ูุน ResNet ูุน ุจููุฉ ููุงุซูุฉ ุ ูุจููุณ ุงูุจููุฉ ุงูุฏูููุฉ ุ ุงูุชู ููุชุดุฑ ูููุง ุงูุชุฏุฑุฌ <em>ุงููููู</em> ูุจุงุดุฑุฉู ูู ุฎูุงู ุงูุนูููุงุช ูู <em>ODESolve</em> (ุจุฏูู ุทุฑููุฉ ุงูุชุฏุฑุฌ ุงููุชุฑุงูู) ( RK-Net). <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/vn/41/--/vn41--frzbdkftca4ehe7hh-kea.png"></div><br>  <i>ุชูุถูุญ ูู ุงูููุงู ุงูุฃุตูู.</i> <br><br>  ูููุง ููู ุ ูุฅู ุดุจูุฉ ูุชุตูุฉ ุจุงููุงูู ุฐุงุช ุทุจูุฉ ูุงุญุฏุฉ ุชุญุชูู ุนูู ููุณ ุนุฏุฏ ุงููุนููุงุช ุชูุฑูุจูุง ูุซู <em>Neural ODE</em> ุจูุง ุฎุทุฃ ุฃุนูู ุจูุซูุฑ ูู ุงูุงุฎุชุจุงุฑ ุ ResNet ูุน ููุณ ุงูุฎุทุฃ ุฅูู ุญุฏ ูุจูุฑ ุจู ูุนููุงุช ุฃูุซุฑ ุจูุซูุฑ ุ ู RK-Net ุจุฏูู ุทุฑููุฉ ุงูุชุฏุฑุฌ ุงููุชุฑุงูู ูุญุชูู ุนูู ุฎุทุฃ ุฃุนูู ููููุงู ููุน ุฒูุงุฏุฉ ุงุณุชููุงู ุงูุฐุงูุฑุฉ ุจุดูู ุฎุทู (ูููุง ูุงู ุงูุฎุทุฃ ุงููุณููุญ ุจู <em>ุฃุตุบุฑูุง</em> ุ ุฒุงุฏุช ุงูุฎุทูุงุช ุงูุชู ูุฌุจ ุนูู <em>ODESolve</em> ุงุชุฎุงุฐูุง ุ ููุง ูุฒูุฏ ูู ุงุณุชููุงู ุงูุฐุงูุฑุฉ ุฎุทููุง ุจุนุฏุฏ ุงูุฎุทูุงุช). <br><br>  ูุณุชุฎุฏู ุงููุคูููู ุทุฑููุฉ Runge-Kutta ุงูุถูููุฉ ูุน ุญุฌู ุงูุฎุทูุฉ ุงูุชูููู ูู ุชูููุฐูุง ุ ุนูู ุนูุณ ุทุฑููุฉ Euler ุงูุฃุจุณุท ููุง.  ูู ุฃูุถุง ุฏุฑุงุณุฉ ุจุนุถ ุฎุตุงุฆุต ุงูููุฏุณุฉ ุงููุนูุงุฑูุฉ ุงูุฌุฏูุฏุฉ. <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/u7/li/fq/u7lifqdsf72otgcyfigm6-fiyww.png"></div><br>  <i>ููุฒุฉ ODE-Net (NFE ุฅูู ุงูุฃูุงู - ุนุฏุฏ ุญุณุงุจุงุช ุงููุธุงุฆู ูู ูุณุงุฑ ูุจุงุดุฑ)</i> <i><br></i>  <i>ุชูุถูุญ ูู ุงูููุงู ุงูุฃุตูู.</i> <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  (ุฃ) ุชุบููุฑ ูุณุชูู ุงูุฎุทุฃ ุงูุนุฏุฏู ุงูููุจูู ูุบูุฑ ุนุฏุฏ ุงูุฎุทูุงุช ูู ุงูุชูุฒูุน ุงููุจุงุดุฑ. <br></li><li style=";text-align:right;direction:rtl">  (ุจ) ุงูููุช ุงูุฐู ููุถูู ุงูุชูุฒูุน ุงููุจุงุดุฑ ูุชูุงุณุจ ูุน ุนุฏุฏ ุญุณุงุจุงุช ุงููุธุงุฆู. <br></li><li style=";text-align:right;direction:rtl">  (ุฌ) ููุซู ุนุฏุฏ ุงูุนูููุงุช ุงูุญุณุงุจูุฉ ููุธููุฉ ุงูุงูุชุดุงุฑ ุงูุฎููู ูุง ููุฑุจ ูู ูุตู ุงูุงูุชุดุงุฑ ุงููุจุงุดุฑ ุ ููุง ูุฏู ุนูู ุฃู ุทุฑููุฉ ุงูุชุฏุฑุฌ ุงููุชุฒุงูู ูุฏ ุชููู ุฃูุซุฑ ููุงุกุฉ ูู ุงููุงุญูุฉ ุงูุญุณุงุจูุฉ ูู ูุดุฑ ุงูุชุฏุฑุฌ <em>ุงููููู</em> ูุจุงุดุฑุฉ ูู ุฎูุงู <em>ODESolve</em> . <br></li><li style=";text-align:right;direction:rtl">  (ุฏ) ุนูุฏูุง ูุตุจุญ ODE-Net ุฃูุซุฑ ูุฃูุซุฑ ุชุฏุฑูุจุงู ุ ูุฅูู ูุชุทูุจ ุงููุฒูุฏ ูุงููุฒูุฏ ูู ุงูุนูููุงุช ุงูุญุณุงุจูุฉ ูููุธููุฉ (ุฎุทูุฉ ุฃุตุบุฑ ูู ุฃู ููุช ูุถู) ุ ูุฑุจูุง ุงูุชููู ูุน ุงูุชุนููุฏ ุงููุชุฒุงูุฏ ูููููุฐุฌ. <br></li></ul><br><br><h2 style=";text-align:right;direction:rtl">  ูุธููุฉ ุชูููุฏูุฉ ุฎููุฉ ูููุฐุฌุฉ ุงูุณูุงุณู ุงูุฒูููุฉ </h2><br>  ODE ุงูุนุตุจู ููุงุณุจ ููุนุงูุฌุฉ ุงูุจูุงูุงุช ุงูุชุณูุณููุฉ ุงููุณุชูุฑุฉ ุญุชู ุนูุฏูุง ูููู ุงููุณุงุฑ ูู ูุณุงุญุฉ ูุฎููุฉ ุบูุฑ ูุนุฑููุฉ. <br><br>  ูู ูุฐุง ุงููุณู ุ ุณูููู ุจุชุฌุฑุจุฉ ูุชุบููุฑ ุชูููุฏ ุชุณูุณู ูุณุชูุฑ ุจุงุณุชุฎุฏุงู <em>Neural ODE</em> ุ ููููู ูุธุฑุฉ ุนูู ุงููุณุงุญุฉ ุงูุฎููุฉ ุงููุณุชูุงุฏุฉ. <br><br>  ููุงุฑู ุงููุคูููู ูุฐุง ุฃูุถูุง ุจุงูุชุณูุณูุงุช ุงููุชุดุงุจูุฉ ุงููุงุชุฌุฉ ุนู ุงูุดุจูุงุช ุงููุชูุฑุฑุฉ. <br><br>  ุชุฎุชูู ุงูุชุฌุฑุจุฉ ููุง ููููุงู ุนู ุงููุซุงู ุงูููุงุจู ูู ูุณุชูุฏุน ุงููุคูููู ุ ูููุงู ูุฌููุนุฉ ูุชููุนุฉ ูู ุงููุณุงุฑุงุช. <br><br><h3 style=";text-align:right;direction:rtl">  ุงูุจูุงูุงุช </h3><br>  ุชุชููู ุจูุงูุงุช ุงูุชุฏุฑูุจ ูู ุงูููุงูุจ ุงูุนุดูุงุฆูุฉ ุ ูุตููุง ูู ุงุชุฌุงู ุนูุงุฑุจ ุงูุณุงุนุฉ ุ ูุงูุซุงูู ุนูุณ ุงุชุฌุงู ุนูุงุฑุจ ุงูุณุงุนุฉ.  ุนูุงูุฉ ุนูู ุฐูู ุ ูุชู ุฃุฎุฐ ุงูุนููุงุช ุงูุชุงููุฉ ูู ูุฐู ุงูููุงูุจ ุ ุงูุชู ุชุชู ูุนุงูุฌุชูุง ุจูุงุณุทุฉ ูููุฐุฌ ุชูุฑุงุฑ ุงูุชุฑููุฒ ูู ุงูุงุชุฌุงู ุงููุนุงูุณ ุ ููุง ูุคุฏู ุฅูู ุจุฏุงูุฉ ุญุงูุฉ ูุฎููุฉ ุ ูุงูุชู ุชุชุทูุฑ ุจุนุฏ ุฐูู ุ ููุง ูุฎูู ูุณุงุฑูุง ูู ุงููุถุงุก ุงูุฎูู.  ุซู ูุชู ุชุนููู ูุฐุง ุงููุณุงุฑ ูุงูู ุฅูู ูุณุงุญุฉ ุงูุจูุงูุงุช ูููุงุฑูุชูุง ูุน ูููู ุนููุงุช.  ูุจุงูุชุงูู ุ ูุชุนูู ุงููููุฐุฌ ุฅูุดุงุก ูุณุงุฑุงุช ูุดุงุจูุฉ ููุฌููุนุฉ ุงูุจูุงูุงุช. <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/or/4z/lg/or4zlgwkqjm-kzhvlmqtzmeqnl4.png"></div><br>  <i>ุฃูุซูุฉ ูู ุงูููุงูุจ ูุฌููุนุฉ ุงูุจูุงูุงุช</i> <br><br><h3 style=";text-align:right;direction:rtl">  VAE ููููุฐุฌ ุฅูุชุงุฌู </h3><br>  ูููุฐุฌ ุนุงู ูู ุฎูุงู ุฅุฌุฑุงุก ุฃุฎุฐ ุงูุนููุงุช: <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/fde/a91/b7b/fdea91b7b77af8c87a50e6c9e361f13b.svg" alt="z_ {t_0} \ sim \ mathcal {N} (0 ุ I)"></div><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/fb0/9b2/ad7/fb09b2ad71d820266be632be7c5b5f97.svg" alt="z_ {t_1}ุ z_ {t_2}ุ ...ุ z_ {t_M} = \ text {ODESolve} (z_ {t_0}ุ fุ \ theta_fุ t_0ุ ...ุ t_M)"></div><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/477/5a1/439/4775a14397c7842e67c0756d585c3d5b.svg" alt="x_ {t_i} \ sim p (x \ mid z_ {t_i}ุ \ theta_x)"></div><br>  ูุงูุชู ูููู ุชุฏุฑูุจูุง ุจุงุณุชุฎุฏุงู ููุฌ ุงูุชุฑููุฒ ุงูุชููุงุฆู ุงูุงุฎุชูุงูุงุช. <br><ol style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  ุงูุชูู ูู ุฎูุงู ุงูุชุดููุฑ ุงููุชูุฑุฑ ูู ุฎูุงู ุชุณูุณู ุงูููุช ูู ุงูููุช ุงูููุงุณุจ ููุญุตูู ุนูู ุงููุนููุงุช <img src="https://habrastorage.org/getpro/habr/post_images/26b/84a/1dd/26b84a1dd2d618b4dd85d805e95b5db3.svg" alt="\ mu_ {z_ {t_0}}">  ุ <img src="https://habrastorage.org/getpro/habr/post_images/a1f/9e2/8ac/a1f9e28acee2636547023da51c1af36e.svg" alt="\ sigma_ {z_ {t_0}}">  ุงูุชูุฒูุน ุงูุฎููู ุงููุชุบูุฑ ุ ุซู ุฃุฎุฐ ุนููุฉ ููู: <br></li></ol><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/816/997/3be/8169973bece43135c717f8abd5088e4c.svg" alt="z_ {t_0} \ sim q \ left (z_ {t_0} \ mid x_ {t_0}ุ ...ุ x_ {t_M}ุ t_0ุ ...ุ t_Mุ \ theta_q \ right) = \ mathcal {N} \ ูุณุงุฑ (z_ {t_0} \ mid \ mu_ {z_ {t_0}} \ sigma_ {z_ {t_0}} \ ุงููููู)"></div><br><ol style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  ุงูุญุตูู ุนูู ุงููุณุงุฑ ุงูุฎูู: <br></li></ol><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/416/810/833/416810833bb304242b3ec7bccfeb91ad.svg" alt="z_ {t_1}ุ z_ {t_2}ุ ...ุ z_ {t_N} = \ text {ODESolve} (z_ {t_0}ุ fุ \ theta_fุ t_0ุ ...ุ t_N)ุ \ text {ุญูุซ} \ frac {dz} {dt} = f (zุ tุ \ theta_f)"></div><br><ol style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  ุนููู ูุณุงุฑูุง ูุฎูููุง ุฅูู ูุณุงุฑ ูู ุงูุจูุงูุงุช ุจุงุณุชุฎุฏุงู ุดุจูุฉ ุนุตุจูุฉ ุฃุฎุฑู: <img src="https://habrastorage.org/getpro/habr/post_images/fd1/2b0/73d/fd12b073dd1cede0a98b312c0e3240d1.svg" alt="\ hat {x_ {t_i}} (z_ {t_i}ุ t_iุ \ theta_x)"><br></li><li style=";text-align:right;direction:rtl">  ุชุนุธูู ุชูููู ุงูุญุฏ ุงูุฃุฏูู ูู ุงูุตูุงุญูุฉ (ELBO) ููุณุงุฑ ุงูุนููุฉ: <br></li></ol><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/9cf/838/1e3/9cf8381e35978cf70219a1f3bea211b6.svg" alt="\ text {ELBO} \ approx N \ Big (\ sum_ {i = 0} ^ {M} \ log p (x_ {t_i} \ mid z_ {t_i} (z_ {t_0}ุ \ theta_x) + \ theta_x) + KL \ left (q (z_ {t_0} \ mid x_ {t_0}ุ ...ุ x_ {t_M}ุ t_0ุ ...ุ t_Mุ \ theta_q) \ parallel \ mathcal {N} (0ุ I) \ ุงููููู) \ ูุจูุฑ)"></div><br>  ููู ุญุงูุฉ ุงูุชูุฒูุน ุงูุฎููู ุงูุบูุณู <img src="https://habrastorage.org/getpro/habr/post_images/9a9/404/aa0/9a9404aa0267a6c257815abc794e95c3.svg" alt="p (x \ mid z_ {t_i}ุ \ theta_x)">  ููุณุชูู ุงูุถูุถุงุก ุงููุนุฑููุฉ <img src="https://habrastorage.org/getpro/habr/post_images/87a/7c9/aba/87a7c9abaa12e58e75ef64aa8312050e.svg" alt="\ sigma_x">  : <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/getpro/habr/post_images/7b0/a0d/c43/7b0a0dc43667f287d584b6865afa1cfb.svg" alt="\ text {ELBO} \ approx -N \ Big (\ sum_ {i = 1} ^ {M} \ frac {(x_i - \ hat {x_i}) ^ 2} {\ sigma_x ^ 2} - \ log \ sigma_ { z_ {t_0}} ^ 2 + \ mu_ {z_ {t_0}} ^ 2 + \ sigma_ {z_ {t_0}} ^ 2 \ Big) + C"></div><br>  ูููู ุชูุซูู ุงูุฑุณู ุงูุจูุงูู ูุญุณุงุจ ูููุฐุฌ ODE ุงููุฎูู ุนูู ุงููุญู ุงูุชุงูู <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/zl/57/ui/zl57uisgnvjy7-y94fkker9m1eq.png"></div><br>  <i>ุชูุถูุญ ูู ุงูููุงู ุงูุฃุตูู.</i> <br><br>  ูููู ุจุนุฏ ุฐูู ุงุฎุชุจุงุฑ ูุฐุง ุงููููุฐุฌ ููุนุฑูุฉ ููููุฉ ุชูุฑูุจ ุงููุณุงุฑ ุจุงุณุชุฎุฏุงู ุงูููุงุญุธุงุช ุงูุฃูููุฉ ููุท. <br><br><div class="spoiler" style=";text-align:right;direction:rtl">  <b class="spoiler_title">ููุฏ</b> <div class="spoiler_text" style=";text-align:right;direction:rtl"><h3 style=";text-align:right;direction:rtl">  ุชุญุฏูุฏ ุงูููุงุฐุฌ </h3><br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">RNNEncoder</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_dim, hidden_dim, latent_dim)</span></span></span><span class="hljs-function">:</span></span> super(RNNEncoder, self).__init__() self.input_dim = input_dim self.hidden_dim = hidden_dim self.latent_dim = latent_dim self.rnn = nn.GRU(input_dim+<span class="hljs-number"><span class="hljs-number">1</span></span>, hidden_dim) self.hid2lat = nn.Linear(hidden_dim, <span class="hljs-number"><span class="hljs-number">2</span></span>*latent_dim) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x, t)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Concatenate time to input t = t.clone() t[1:] = t[:-1] - t[1:] t[0] = 0. xt = torch.cat((x, t), dim=-1) _, h0 = self.rnn(xt.flip((0,))) # Reversed # Compute latent dimension z0 = self.hid2lat(h0[0]) z0_mean = z0[:, :self.latent_dim] z0_log_var = z0[:, self.latent_dim:] return z0_mean, z0_log_var class NeuralODEDecoder(nn.Module): def __init__(self, output_dim, hidden_dim, latent_dim): super(NeuralODEDecoder, self).__init__() self.output_dim = output_dim self.hidden_dim = hidden_dim self.latent_dim = latent_dim func = NNODEF(latent_dim, hidden_dim, time_invariant=True) self.ode = NeuralODE(func) self.l2h = nn.Linear(latent_dim, hidden_dim) self.h2o = nn.Linear(hidden_dim, output_dim) def forward(self, z0, t): zs = self.ode(z0, t, return_whole_sequence=True) hs = self.l2h(zs) xs = self.h2o(hs) return xs class ODEVAE(nn.Module): def __init__(self, output_dim, hidden_dim, latent_dim): super(ODEVAE, self).__init__() self.output_dim = output_dim self.hidden_dim = hidden_dim self.latent_dim = latent_dim self.encoder = RNNEncoder(output_dim, hidden_dim, latent_dim) self.decoder = NeuralODEDecoder(output_dim, hidden_dim, latent_dim) def forward(self, x, t, MAP=False): z_mean, z_log_var = self.encoder(x, t) if MAP: z = z_mean else: z = z_mean + torch.randn_like(z_mean) * torch.exp(0.5 * z_log_var) x_p = self.decoder(z, t) return x_p, z, z_mean, z_log_var def generate_with_seed(self, seed_x, t): seed_t_len = seed_x.shape[0] z_mean, z_log_var = self.encoder(seed_x, t[:seed_t_len]) x_p = self.decoder(z_mean, t) return x_p</span></span></code> </pre><br><br><h3 style=";text-align:right;direction:rtl">  ุฌูู ูุฌููุนุฉ ุงูุจูุงูุงุช </h3><br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">t_max = <span class="hljs-number"><span class="hljs-number">6.29</span></span>*<span class="hljs-number"><span class="hljs-number">5</span></span> n_points = <span class="hljs-number"><span class="hljs-number">200</span></span> noise_std = <span class="hljs-number"><span class="hljs-number">0.02</span></span> num_spirals = <span class="hljs-number"><span class="hljs-number">1000</span></span> index_np = np.arange(<span class="hljs-number"><span class="hljs-number">0</span></span>, n_points, <span class="hljs-number"><span class="hljs-number">1</span></span>, dtype=np.int) index_np = np.hstack([index_np[:, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]]) times_np = np.linspace(<span class="hljs-number"><span class="hljs-number">0</span></span>, t_max, num=n_points) times_np = np.hstack([times_np[:, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]] * num_spirals) times = torch.from_numpy(times_np[:, :, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]).to(torch.float32) <span class="hljs-comment"><span class="hljs-comment"># Generate random spirals parameters normal01 = torch.distributions.Normal(0, 1.0) x0 = Variable(normal01.sample((num_spirals, 2))) * 2.0 W11 = -0.1 * normal01.sample((num_spirals,)).abs() - 0.05 W22 = -0.1 * normal01.sample((num_spirals,)).abs() - 0.05 W21 = -1.0 * normal01.sample((num_spirals,)).abs() W12 = 1.0 * normal01.sample((num_spirals,)).abs() xs_list = [] for i in range(num_spirals): if i % 2 == 1: # Make it counter-clockwise W21, W12 = W12, W21 func = LinearODEF(Tensor([[W11[i], W12[i]], [W21[i], W22[i]]])) ode = NeuralODE(func) xs = ode(x0[i:i+1], times[:, i:i+1], return_whole_sequence=True) xs_list.append(xs) orig_trajs = torch.cat(xs_list, dim=1).detach() samp_trajs = orig_trajs + torch.randn_like(orig_trajs) * noise_std samp_ts = times fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 9)) axes = axes.flatten() for i, ax in enumerate(axes): ax.scatter(samp_trajs[:, i, 0], samp_trajs[:, i, 1], c=samp_ts[:, i, 0], cmap=cm.plasma) plt.show() import numpy.random as npr def gen_batch(batch_size, n_sample=100): n_batches = samp_trajs.shape[1] // batch_size time_len = samp_trajs.shape[0] n_sample = min(n_sample, time_len) for i in range(n_batches): if n_sample &gt; 0: probs = [1. / (time_len - n_sample)] * (time_len - n_sample) t0_idx = npr.multinomial(1, probs) t0_idx = np.argmax(t0_idx) tM_idx = t0_idx + n_sample else: t0_idx = 0 tM_idx = time_len frm, to = batch_size*i, batch_size*(i+1) yield samp_trajs[t0_idx:tM_idx, frm:to], samp_ts[t0_idx:tM_idx, frm:to]</span></span></code> </pre><br><br><h3 style=";text-align:right;direction:rtl">  ุงูุชุฏุฑูุจ </h3><br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">vae = ODEVAE(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>) vae = vae.cuda() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: vae = vae.cuda() optim = torch.optim.Adam(vae.parameters(), betas=(<span class="hljs-number"><span class="hljs-number">0.9</span></span>, <span class="hljs-number"><span class="hljs-number">0.999</span></span>), lr=<span class="hljs-number"><span class="hljs-number">0.001</span></span>) preload = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> n_epochs = <span class="hljs-number"><span class="hljs-number">20000</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">100</span></span> plot_traj_idx = <span class="hljs-number"><span class="hljs-number">1</span></span> plot_traj = orig_trajs[:, plot_traj_idx:plot_traj_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>] plot_obs = samp_trajs[:, plot_traj_idx:plot_traj_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>] plot_ts = samp_ts[:, plot_traj_idx:plot_traj_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: plot_traj = plot_traj.cuda() plot_obs = plot_obs.cuda() plot_ts = plot_ts.cuda() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> preload: vae.load_state_dict(torch.load(<span class="hljs-string"><span class="hljs-string">"models/vae_spirals.sd"</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> epoch_idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n_epochs): losses = [] train_iter = gen_batch(batch_size) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x, t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> train_iter: optim.zero_grad() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: x, t = x.cuda(), t.cuda() max_len = np.random.choice([<span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>]) permutation = np.random.permutation(t.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) np.random.shuffle(permutation) permutation = np.sort(permutation[:max_len]) x, t = x[permutation], t[permutation] x_p, z, z_mean, z_log_var = vae(x, t) z_var = torch.exp(z_log_var) kl_loss = <span class="hljs-number"><span class="hljs-number">-0.5</span></span> * torch.sum(<span class="hljs-number"><span class="hljs-number">1</span></span> + z_log_var - z_mean**<span class="hljs-number"><span class="hljs-number">2</span></span> - z_var, <span class="hljs-number"><span class="hljs-number">-1</span></span>) loss = <span class="hljs-number"><span class="hljs-number">0.5</span></span> * ((x-x_p)**<span class="hljs-number"><span class="hljs-number">2</span></span>).sum(<span class="hljs-number"><span class="hljs-number">-1</span></span>).sum(<span class="hljs-number"><span class="hljs-number">0</span></span>) / noise_std**<span class="hljs-number"><span class="hljs-number">2</span></span> + kl_loss loss = torch.mean(loss) loss /= max_len loss.backward() optim.step() losses.append(loss.item()) print(<span class="hljs-string"><span class="hljs-string">f"Epoch </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{epoch_idx}</span></span></span><span class="hljs-string">"</span></span>) frm, to, to_seed = <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-number"><span class="hljs-number">50</span></span> seed_trajs = samp_trajs[frm:to_seed] ts = samp_ts[frm:to] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: seed_trajs = seed_trajs.cuda() ts = ts.cuda() samp_trajs_p = to_np(vae.generate_with_seed(seed_trajs, ts)) fig, axes = plt.subplots(nrows=<span class="hljs-number"><span class="hljs-number">3</span></span>, ncols=<span class="hljs-number"><span class="hljs-number">3</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(axes): ax.scatter(to_np(seed_trajs[:, i, <span class="hljs-number"><span class="hljs-number">0</span></span>]), to_np(seed_trajs[:, i, <span class="hljs-number"><span class="hljs-number">1</span></span>]), c=to_np(ts[frm:to_seed, i, <span class="hljs-number"><span class="hljs-number">0</span></span>]), cmap=cm.plasma) ax.plot(to_np(orig_trajs[frm:to, i, <span class="hljs-number"><span class="hljs-number">0</span></span>]), to_np(orig_trajs[frm:to, i, <span class="hljs-number"><span class="hljs-number">1</span></span>])) ax.plot(samp_trajs_p[:, i, <span class="hljs-number"><span class="hljs-number">0</span></span>], samp_trajs_p[:, i, <span class="hljs-number"><span class="hljs-number">1</span></span>]) plt.show() print(np.mean(losses), np.median(losses)) clear_output(wait=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) spiral_0_idx = <span class="hljs-number"><span class="hljs-number">3</span></span> spiral_1_idx = <span class="hljs-number"><span class="hljs-number">6</span></span> homotopy_p = Tensor(np.linspace(<span class="hljs-number"><span class="hljs-number">0.</span></span>, <span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)[:, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>]) vae = vae <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: homotopy_p = homotopy_p.cuda() vae = vae.cuda() spiral_0 = orig_trajs[:, spiral_0_idx:spiral_0_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>, :] spiral_1 = orig_trajs[:, spiral_1_idx:spiral_1_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>, :] ts_0 = samp_ts[:, spiral_0_idx:spiral_0_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>, :] ts_1 = samp_ts[:, spiral_1_idx:spiral_1_idx+<span class="hljs-number"><span class="hljs-number">1</span></span>, :] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda: spiral_0, ts_0 = spiral_0.cuda(), ts_0.cuda() spiral_1, ts_1 = spiral_1.cuda(), ts_1.cuda() z_cw, _ = vae.encoder(spiral_0, ts_0) z_cc, _ = vae.encoder(spiral_1, ts_1) homotopy_z = z_cw * (<span class="hljs-number"><span class="hljs-number">1</span></span> - homotopy_p) + z_cc * homotopy_p t = torch.from_numpy(np.linspace(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>*np.pi, <span class="hljs-number"><span class="hljs-number">200</span></span>)) t = t[:, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>].expand(<span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)[:, :, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>].cuda() t = t.cuda() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> use_cuda <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> t hom_gen_trajs = vae.decoder(homotopy_z, t) fig, axes = plt.subplots(nrows=<span class="hljs-number"><span class="hljs-number">2</span></span>, ncols=<span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) axes = axes.flatten() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, ax <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(axes): ax.plot(to_np(hom_gen_trajs[:, i, <span class="hljs-number"><span class="hljs-number">0</span></span>]), to_np(hom_gen_trajs[:, i, <span class="hljs-number"><span class="hljs-number">1</span></span>])) plt.show() torch.save(vae.state_dict(), <span class="hljs-string"><span class="hljs-string">"models/vae_spirals.sd"</span></span>)</code> </pre><br></div></div><br>       <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/fv/pn/pi/fvpnpimixf3sq0cezhepgzh2txy.png"></div><br> <i> โ      (), <br>  โ     ,    . <br><br>    .</i> <br><br>       .        .       . <br><br>    ,     -   - . <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/at/g_/7e/atg_7ecofins-uohnv99qccfxfq.png"></div><br><br>         <em>Neural ODE</em>    . <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/kj/ak/-e/kjak-evgr-7mrrtpgimf0gfmfxq.png"></div><br> <i>   </i> <br><br><h2 style=";text-align:right;direction:rtl">    </h2><br>         .   ,       ,         (, ),            . <br>  ,           ,   . <br><br> <em> </em>       <em> </em> , <em>  </em>     . <br><br>  , ,    <em></em> ,  ,  ,     . <br><br>  : <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/nd/e_/wn/nde_wn590scz9dff_0hzxo1-tgg.png"></div><br> <i>    ( )   ( )   ; <br><br> -X        ยซยป ( )  ยซยป ( ). <br><br>    </i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=" class="user_link">bekemax</a>            . <br><br>      <strong>Neural ODEs</strong> .   ! <br><br><h1 style=";text-align:right;direction:rtl">   </h1><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">   + . </a> <br></li><li style=";text-align:right;direction:rtl"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="> </a> <br></li><li style=";text-align:right;direction:rtl"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="> </a> <br></li><li style=";text-align:right;direction:rtl"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="> </a> <br></li><li style=";text-align:right;direction:rtl"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">   VAE ()</a> <br></li><li style=";text-align:right;direction:rtl"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="> VAE</a> <br></li><li style=";text-align:right;direction:rtl"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">   </a> <br></li><li style=";text-align:right;direction:rtl"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">Variational Inference with Normalizing Flows Paper</a> <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar442002/">https://habr.com/ru/post/ar442002/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar441990/index.html">ุงูุทุฑููุฉ ุงูุฃูุซุฑ ูุนุงููุฉ ูููุงูุญุฉ ุงููุฑุตูุฉ - ุฎุฏูุงุช ูุงููููุฉ ูุฑูุญุฉ ูุฑุฎูุตุฉ</a></li>
<li><a href="../ar441992/index.html">ุงุฎุชูุงุฑ ูุฏูุฉ ููุชุงุฉ ุงููููุณ</a></li>
<li><a href="../ar441994/index.html">ูุงุณุง: ุนุฏุฏ ุงูููุงูุจ ุงูุตุงูุญุฉ ููุญูุงุฉ ูู ูุฌุฑุชูุง ูู ุฃูู ุจูุซูุฑ ููุง ูุนุชูุฏ ุนูููุง</a></li>
<li><a href="../ar441996/index.html">ุงูุชูููููุฌูุง ูู 80s: ุงูุฐู ูุญูู ุงููุนุงูุฌุงุช waferscale</a></li>
<li><a href="../ar441998/index.html">"ูุงุฒุช ุงูุญุงููุงุช ูู ุงููุนุฑูุฉ ุ ููููุง ุฎุณุฑุช ุงูุญุฑุจ ุนูู ุงูุนูุงุฑุฉ ุจุฏูู ุฎุงุฏู" - ุณุงูููู ูุงุฑุฏูู</a></li>
<li><a href="../ar442004/index.html">ุขุซุงุฑ ุชุตููุฉ SVG. ุงูุฌุฒุก 7. ุฅูู ุงูุฃูุงู</a></li>
<li><a href="../ar442006/index.html">ุฅุฏุงุฑุฉ ุงููููุงุช ุฎุทุฃ - ุงูุฌุฒุก 2: ุชุญูุฉ ูู ุงูุฎุฑุงุก</a></li>
<li><a href="../ar442008/index.html">k3s ูู Kubernetes ุตุบูุฑุฉ ูููููุง ูุนุชูุฏุฉ ูู ูุจู Rancher Labs</a></li>
<li><a href="../ar442010/index.html">ุจูุซูู ู FPGA. ุชุฌุฑูุจ</a></li>
<li><a href="../ar442012/index.html">ุงูุชุฌุฑุจุฉ: ูููู ุจุฌูุน ุฏููู ุงููุญุฏุงุช ุงูุชู ุฃุตุฏุฑุช ุฌูุงุฒ ุณูุฑ</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
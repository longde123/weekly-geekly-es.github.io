<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîó üñêüèº üìî El nuevo algoritmo acelera 200 veces el dise√±o autom√°tico de las redes neuronales. üêö „ÄΩÔ∏è üìó</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="ProxylessNAS optimiza directamente la arquitectura de las redes neuronales para una tarea y equipo espec√≠ficos, lo que puede aumentar significativamen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>El nuevo algoritmo acelera 200 veces el dise√±o autom√°tico de las redes neuronales.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/444920/"><img src="https://habrastorage.org/webt/s-/oa/ve/s-oaveujtah5s2-6nxm1ouexltq.png"><br><br>  <i><font color="gray">ProxylessNAS optimiza directamente la arquitectura de las redes neuronales para una tarea y equipo espec√≠ficos, lo que puede aumentar significativamente la productividad en comparaci√≥n con los enfoques proxy anteriores.</font></i>  <i><font color="gray">En un conjunto de datos ImageNet, una red neuronal est√° dise√±ada en 200 GPU horas (200‚Äì378 veces m√°s r√°pido que sus contrapartes), y el modelo CNN dise√±ado autom√°ticamente para dispositivos m√≥viles alcanza el mismo nivel de precisi√≥n que MobileNetV2 1.4, trabajando 1.8 veces m√°s r√°pido.</font></i> <br><br>  Investigadores del Instituto de Tecnolog√≠a de Massachusetts han desarrollado un algoritmo eficiente para el dise√±o autom√°tico de redes neuronales de alto rendimiento para hardware espec√≠fico, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">escribe la</a> publicaci√≥n <i>MIT News</i> . <br><br>  Los algoritmos para el dise√±o autom√°tico de sistemas de aprendizaje autom√°tico son un nuevo campo de investigaci√≥n en el campo de la IA.  Esta t√©cnica se llama b√∫squeda de arquitectura neural (NAS) y se considera una tarea computacional dif√≠cil. <br><a name="habracut"></a><br>  Las redes neuronales dise√±adas autom√°ticamente tienen un dise√±o m√°s preciso y eficiente que las desarrolladas por humanos.  Pero la b√∫squeda de arquitectura neuronal requiere c√°lculos realmente enormes.  Por ejemplo, el moderno algoritmo NASNet-F, desarrollado recientemente por Google para ejecutarse en GPU, requiere 48,000 horas de computaci√≥n GPU para crear una red neuronal convolucional, que se utiliza para clasificar y detectar im√°genes.  Por supuesto, Google puede ejecutar cientos de GPU y otro hardware especializado en paralelo.  Por ejemplo, en mil GPUs, este c√°lculo tomar√° solo dos d√≠as.  Pero no todos los investigadores tienen tales oportunidades, y si ejecuta el algoritmo en la nube inform√°tica de Google, puede llegar a ser un centavo. <br><br>  Los investigadores del MIT han preparado un art√≠culo para la Conferencia Internacional sobre Representaciones de Aprendizaje, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ICLR 2019</a> , que se llevar√° a cabo del 6 al 9 de mayo de 2019.  El art√≠culo <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ProxylessNAS: B√∫squeda directa de arquitectura neuronal en tareas y hardware objetivo</a></i> describe el algoritmo ProxylessNAS que puede desarrollar directamente redes neuronales convolucionales especializadas para plataformas de hardware espec√≠ficas. <br><br>  Cuando se ejecuta en un conjunto masivo de datos de imagen, el algoritmo dise√±√≥ la arquitectura √≥ptima en solo 200 horas de funcionamiento de la GPU.  Esto es dos √≥rdenes de magnitud m√°s r√°pido que el desarrollo de la arquitectura CNN utilizando otros algoritmos (ver tabla). <br><br><img src="https://habrastorage.org/webt/yq/aj/-p/yqaj-p8kj8kusqykhnjj0nmsa4c.png"><br><br>  Los investigadores y las empresas con recursos limitados se beneficiar√°n del algoritmo.  Un objetivo m√°s general es "democratizar la IA", dice el coautor cient√≠fico Song Han, profesor asociado de ingenier√≠a el√©ctrica y ciencias de la computaci√≥n en los Laboratorios de Tecnolog√≠a de Microsistemas del MIT. <br><br>  Khan agreg√≥ que tales algoritmos NAS nunca reemplazar√°n el trabajo intelectual de los ingenieros: "El objetivo es descargar el trabajo repetitivo y tedioso que viene con el dise√±o y la mejora de la arquitectura de las redes neuronales". <br><br>  En su trabajo, los investigadores encontraron formas de eliminar componentes innecesarios de una red neuronal, reducir el tiempo de c√≥mputo y usar solo una parte de la memoria del hardware para ejecutar el algoritmo NAS.  Esto garantiza que el CNN desarrollado funcione de manera m√°s eficiente en plataformas de hardware espec√≠ficas: CPU, GPU y dispositivos m√≥viles. <br><br>  La arquitectura CNN consta de capas con par√°metros ajustables llamados "filtros" y posibles relaciones entre ellos.  Los filtros procesan p√≠xeles de imagen en cuadr√≠culas cuadradas, como 3 √ó 3, 5 √ó 5 o 7 √ó 7, donde cada filtro cubre un cuadrado.  De hecho, los filtros se mueven alrededor de la imagen y combinan los colores de la cuadr√≠cula de p√≠xeles en un p√≠xel.  En diferentes capas, los filtros son de diferentes tama√±os, que est√°n conectados de diferentes maneras para intercambiar datos.  La salida CNN produce una imagen comprimida combinada de todos los filtros.  Dado que la cantidad de arquitecturas posibles, el llamado "espacio de b√∫squeda", es muy grande, usar NAS para crear una red neuronal en conjuntos masivos de datos de im√°genes requiere enormes recursos.  Normalmente, los desarrolladores ejecutan NAS en conjuntos de datos m√°s peque√±os (proxies) y transfieren las arquitecturas CNN resultantes al destino.  Sin embargo, este m√©todo reduce la precisi√≥n del modelo.  Adem√°s, la misma arquitectura se aplica a todas las plataformas de hardware, lo que genera problemas de rendimiento. <br><br>  Los investigadores del MIT entrenaron y probaron el nuevo algoritmo en la tarea de clasificar im√°genes directamente en el conjunto de datos ImageNet, que contiene millones de im√°genes en mil clases.  Primero, crearon un espacio de b√∫squeda que contiene todas las "rutas" posibles para los candidatos de CNN para que el algoritmo encuentre la arquitectura √≥ptima entre ellos.  Para ajustar el espacio de b√∫squeda en la memoria de la GPU, utilizaron un m√©todo llamado binarizaci√≥n a nivel de ruta, que guarda solo una ruta a la vez y guarda la memoria en un orden de magnitud.  La binarizaci√≥n se combina con la poda a nivel de ruta, un m√©todo que tradicionalmente estudia qu√© neuronas en una red neuronal se pueden eliminar de forma segura sin da√±ar el sistema.  Solo en lugar de eliminar neuronas, el algoritmo NAS elimina rutas completas, cambiando completamente la arquitectura. <br><br>  Al final, el algoritmo corta todas las rutas poco probables y guarda solo la ruta con la mayor probabilidad: esta es la arquitectura CNN definitiva. <br><br>  La ilustraci√≥n muestra ejemplos de redes neuronales para clasificar im√°genes que ProxylessNAS ha desarrollado para GPU, CPU y procesadores m√≥viles (de arriba a abajo, respectivamente). <br><br> <a href=""><img src="https://habrastorage.org/webt/fa/cv/pv/facvpv5fu2b715md0rjoiiurtrg.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/444920/">https://habr.com/ru/post/444920/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../444908/index.html">Donde cultivar tel√©fonos inteligentes</a></li>
<li><a href="../444910/index.html">La estimulaci√≥n de sonido y luz ayuda con el Alzheimer, mientras que en ratones, pero los resultados son alentadores</a></li>
<li><a href="../444912/index.html">Control LCD F-51543NFU-LW-ADN / PWB51543C-2-V0 (de la biblioteca de cintas)</a></li>
<li><a href="../444916/index.html">No compr√≥ DLC: una funci√≥n que salvar√≠a al 737 ca√≠do, Boeing vendi√≥ como una opci√≥n</a></li>
<li><a href="../444918/index.html">Donde crecen los tel√©fonos inteligentes: una hoja de ruta para convertirse en una computadora completa</a></li>
<li><a href="../444922/index.html">C√≥mo protegerse del hipnovirus</a></li>
<li><a href="../444924/index.html">El primer WIAD en Mosc√∫: c√≥mo fue y de qu√© hablaron</a></li>
<li><a href="../444926/index.html">Design Digest: L√≠der creativo, productividad y auriculares de la verdad</a></li>
<li><a href="../444928/index.html">El 95% del volumen comercial anunciado de Bitcoin result√≥ ser falso</a></li>
<li><a href="../444930/index.html">Se arrastraron github</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äçüî¨ üë®‚Äçüíª üöú Das Buch "Architekten der Intelligenz" üñ•Ô∏è üë≥ üëêüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="K√ºnstliche Intelligenz (KI) entwickelt sich rasant vom Science-Fiction-Bereich zum Alltag. Moderne Ger√§te erkennen die menschliche Sprache, k√∂nnen Fra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das Buch "Architekten der Intelligenz"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/476466/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/mb/12/np/mb12npah994j7jq-gm2outusizg.jpeg" align="left" alt="Bild"></a>  K√ºnstliche Intelligenz (KI) entwickelt sich rasant vom Science-Fiction-Bereich zum Alltag.  Moderne Ger√§te erkennen die menschliche Sprache, k√∂nnen Fragen beantworten und maschinelle √úbersetzungen durchf√ºhren.  In einer Vielzahl von Bereichen, vom Fahren eines unbemannten Fahrzeugs bis zur Diagnose von Krebs, werden AI-basierte Objekterkennungsalgorithmen verwendet, die den menschlichen F√§higkeiten √ºberlegen sind.  Gro√üe Medienunternehmen nutzen den Roboterjournalismus, um aus den gesammelten Daten urheberrechtlich √§hnliche Artikel zu erstellen.  AI ist offensichtlich bereit, eine wirklich universelle Technologie wie Elektrizit√§t zu werden. <br><br>  Welche Ans√§tze und Technologien gelten als die erfolgversprechendsten?  Welche wichtigen Entdeckungen sind in den kommenden Jahren m√∂glich?  Ist es m√∂glich, eine wirklich denkende Maschine oder KI zu erschaffen, die mit der menschlichen vergleichbar ist, und wie schnell?  Welche Risiken und Bedrohungen sind mit KI verbunden und wie k√∂nnen sie vermieden werden?  Verursacht die KI ein Chaos in der Wirtschaft und auf dem Arbeitsmarkt?  Werden superintelligente Maschinen au√üer Kontrolle geraten und zu einer echten Bedrohung? <br><br>  Nat√ºrlich ist es unm√∂glich, die Zukunft vorherzusagen.  Dennoch wissen Experten mehr √ºber den aktuellen Stand der Technik sowie √ºber Innovationen in naher Zukunft als jeder andere.  Sie werden brillante Begegnungen mit so anerkannten Personen wie R. Kurzweil, D. Hassabis, J. Hinton, R. Brooks und vielen anderen haben. <br><a name="habracut"></a><br><h3>  Yan Lekun </h3><br>  VICE PR√ÑSIDENT UND GR√úNDER DES AI RESEARCH LABORATORY BEI FACEBOOK (FAIR), COMPUTER SCIENCE PROFESSOR AN DER NEW YORK UNIVERSITY <br><br>  <i>Ian Lekun geh√∂rt zusammen mit Jeffrey Hinton und Joshua Benjio zu einer Gruppe von Forschern, deren Bem√ºhungen und Beharrlichkeit zur gegenw√§rtigen Revolution in Bezug auf neuronale Netze und tiefes Lernen gef√ºhrt haben.</i>  <i>W√§hrend seiner Arbeit bei Bell Labs erfand er faltungsbedingte neuronale Netze.</i>  <i>Er erhielt ein Diplom als Elektroingenieur in Paris von der ESIEE und einen Doktortitel in Informatik von der Universit√§t Pierre und Marie Curie.</i>  <i>Nach seinem Abschluss arbeitete er am Jeffrey Hinton Laboratory der University of Toronto.</i> <br><br>  <b>Martin Ford:</b> Die Explosion des Interesses am Deep Learning in den letzten 10 Jahren ist eine Folge der gleichzeitigen Verbesserung neuronaler Netze, der Steigerung der Leistungsf√§higkeit von Computern und der verf√ºgbaren Datenmenge? <br><br>  <b>Yang Lekun:</b> Ja, aber der Prozess war bewusster.  Erschien 1986‚Äì87.  Der Backpropagation-Algorithmus erm√∂glichte das Trainieren mehrschichtiger neuronaler Netze.  Dies l√∂ste eine Welle des Interesses aus, die bis 1995 andauerte. Im Jahr 2003 hatten Jeffrey Hinton, Joshua Benggio und ich den Plan, das Interesse der Community an diesen Methoden zu erneuern, da sie von ihrem bevorstehenden Sieg √ºberzeugt waren.  Wir k√∂nnen also sagen, dass es eine absichtliche Verschw√∂rung gab. <br><br>  <b>M.F .:</b> Hast du schon alle Perspektiven verstanden?  KI und tiefes Lernen werden jetzt synonym betrachtet. <br><br>  <b>I. L .:</b> Ja und nein.  Wir wussten, dass Methoden die Grundlage f√ºr Computer Vision, Spracherkennung und m√∂glicherweise ein paar andere Dinge bilden w√ºrden, aber niemand erwartete, dass sie das Verst√§ndnis der nat√ºrlichen Sprache, der Robotik und der Analyse der medizinischen Bildgebung erweitern und sogar zur Entstehung unbemannter Fahrzeuge beitragen w√ºrden.  In den fr√ºhen neunziger Jahren.  Ich dachte, dass die Bewegung zu diesen Dingen reibungsloser sein w√ºrde und sie etwas fr√ºher erscheinen w√ºrden.  Wir haben auf die Revolution gewartet, die um 2013 stattgefunden hat. <br><br>  <b>M.F .:</b> Und wie kam es zu Ihrem Interesse an KI und maschinellem Lernen? <br><br>  <b>Y. L .:</b> Von Kindheit an interessierte ich mich f√ºr Wissenschaft, Technologie und globale Fragen √ºber den Ursprung des Lebens, die Intelligenz und den Ursprung der Menschheit.  Die Idee der KI faszinierte mich.  Aber in den 1960er und 1970er Jahren.  in frankreich hat das niemand gemacht, also bin ich nach der schule zum ingenieur gegangen. <br><br>  1980 hat mir das Buch √ºber die Philosophie des Lernens und der Sprache sehr gut gefallen: Die Debatte zwischen Jean Piaget und Noam Chomsky ("Sprache und Lernen: Eine Diskussion zwischen Jean Piaget und Noam Chomsky"), in dem der Sch√∂pfer der Theorie der kognitiven Entwicklung und der Linguist Natur und Bildung diskutierten sowie die Entstehung von Sprache und Intelligenz. <br><br>  Neben Piaget sprach MIT-Professor Seymour Peypert Ende der 1960er Jahre √ºber die Urspr√ºnge des maschinellen Lernens.  tats√§chlich dazu beigetragen, die Arbeit mit neuronalen Netzen einzustellen.  Und jetzt, nach 10 Jahren, pries er das sogenannte Perzeptron - ein sehr einfaches Modell des maschinellen Lernens, das in den 1950er Jahren aufkam.  und an denen er in den 1960er Jahren arbeitete.  Ich habe mich also zum ersten Mal mit dem Konzept des maschinellen Lernens vertraut gemacht und war absolut fasziniert davon.  Die F√§higkeit zu lernen betrachtete ich als einen integralen Bestandteil der Intelligenz. <br><br>  Als Student las ich alles, was ich zum maschinellen Lernen finden konnte, und f√ºhrte mehrere Projekte zu diesem Thema durch.  Es stellte sich heraus, dass im Westen niemand mit neuronalen Netzen arbeitet.  Einige japanische Forscher arbeiteten an dem, was sp√§ter als dieser Begriff bekannt wurde.  In unserem Land war dieses Thema f√ºr niemanden von Interesse, auch aufgrund dessen, was in den sp√§ten 1960er Jahren auftrat.  B√ºcher von Peypert und Minsky. <br><br>  Ich begann selbst√§ndig zu forschen und verteidigte 1987 meine Doktorarbeit Modeles connexionnistes de l'apprentissage ("Connectionist learning models").  Mein Manager Maurice Milgram hat sich nicht mit diesem Thema befasst und mir direkt gesagt, dass er offiziell mein Berater werden kann, aber er kann mir technisch nicht helfen. <br><br>  In den fr√ºhen 1980er Jahren  Ich entdeckte eine Gemeinschaft von Menschen, die an neuronalen Netzen arbeiteten und mit ihnen Kontakt aufnahmen.  Parallel zu David Rumelhart und Jeffrey Hinton entdeckte ich so etwas wie die Methode der R√ºck√ºbertragung von Fehlern. <br><br>  <b>M.F .:</b> Das hei√üt, in den fr√ºhen 1980er Jahren.  In Kanada gab es zahlreiche Studien in diesem Bereich? <br><br>  <b>Y. L .:</b> Nein, alles ist in den USA passiert.  In Kanada wurden solche Studien noch nicht durchgef√ºhrt.  In den fr√ºhen 1980er Jahren  Jeffrey Hinton war Angestellter an der University of California in San Diego, wo er mit Kognitionspsychologen wie David Rumelhart und James McClelland zusammenarbeitete.  Als Ergebnis erschien ein Buch, das die Psychologie mit Hilfe einfacher neuronaler Netze und Computermodelle erkl√§rte.  Anschlie√üend wurde Jeffrey Assistant Professor an der Carnegie Mellon University.  Er ist erst 1987 nach Toronto gezogen. Dann bin ich nach Toronto gezogen und habe ein Jahr in seinem Labor gearbeitet. <br><br>  M.F .: In den fr√ºhen 1980er Jahren.  Ich war Informatikstudent und kann mich nicht erinnern, dass irgendwo neuronale Netze verwendet wurden.  Jetzt hat sich die Situation dramatisch ge√§ndert. <br><br>  <b>Y. L .:</b> Neuronale Netze stehen nicht nur am Rande der Wissenschaft.  In den 1970er Jahren  und Anfang der 1980er Jahre.  Sie waren tats√§chlich anathematisiert.  Artikel wurden wegen einer Erw√§hnung neuronaler Netze abgelehnt. <br><br>  Der bekannte Artikel Optimal Perceptual Inference, der 1983 von Jeffrey Hinton und Terry Seinowski ver√∂ffentlicht wurde.  Um darin eines der ersten Modelle des Deep Learning und des neuronalen Netzwerks zu beschreiben, verwendeten sie Codew√∂rter, sogar im Namen. <br><br>  <b>M.F .:</b> Sie sind als Autor eines Faltungsnetzwerks bekannt.  Bitte erkl√§ren Sie, was es ist? <br><br>  <b>Y. L .:</b> Urspr√ºnglich wurde dieses neuronale Netzwerk f√ºr die Erkennung von Objekten in Bildern optimiert.  Es stellte sich jedoch heraus, dass es auf eine Vielzahl von Aufgaben angewendet werden kann, wie zum Beispiel Spracherkennung und maschinelle √úbersetzung.  Die Idee zu seiner Schaffung wurde von den Merkmalen des visuellen Kortex des Gehirns von Tieren und Menschen getragen, die in den 1950er und 60er Jahren untersucht wurden.  David Hubel und Thorsten Wiesel, die sp√§ter den Nobelpreis f√ºr Neurobiologie erhielten. <br><br>  Das Faltungsnetzwerk ist eine spezielle Art, Neuronen zu verbinden, die keine exakte Kopie biologischer Neuronen sind.  In der ersten Schicht - der Faltungsschicht - wird jedem Neuron eine kleine Anzahl von Bildpunkten zugeordnet und die gewichtete Summe seiner Eingangsdaten berechnet.  W√§hrend des Trainings √§ndern sich die Gewichte.  Gruppen von Neuronen sehen kleine Bereiche des Bildes.  Wenn ein Neuron ein bestimmtes Merkmal in einem Bereich erkennt, erkennt ein anderes Neuron genau dasselbe Merkmal im angrenzenden Bereich und alle anderen Neuronen in den √ºbrigen Bereichen des Bildes.  Die mathematische Operation, die Neuronen zusammen ausf√ºhren, wird als diskrete Faltung bezeichnet.  Daher der Name. <br><br>  Dann kommt die nichtlineare Schicht, in der jedes Neuron ein- oder ausgeschaltet wird, je nachdem, ob die von der Faltungsschicht berechnete gewichtete Summe h√∂her oder niedriger als der angegebene Schwellenwert ist.  Schlie√ülich f√ºhrt die dritte Schicht einen Downsampling-Vorgang durch, um sicherzustellen, dass eine leichte Vorspannung oder Verformung des Eingabebildes die Ausgabe nicht stark ver√§ndert.  Dies bietet Unabh√§ngigkeit von Verformungen des Eingabebildes. <br><br>  Tats√§chlich ist ein Faltungsnetzwerk ein Stapel, der aus Schichten von Faltung, Nichtlinearit√§t und Unterabtastung organisiert ist.  Wenn sie gefaltet sind, erscheinen Neuronen, die Objekte erkennen.  Zum Beispiel ein Neuron, das sich einschaltet, wenn sich das Pferd auf dem Bild befindet, ein anderes Neuron f√ºr Autos, ein drittes f√ºr Menschen usw. f√ºr alle Kategorien, die Sie ben√∂tigen. <br><br>  Dar√ºber hinaus wird die Aktivit√§t des neuronalen Netzwerks durch die St√§rke der Verbindungen zwischen Neuronen, dh die Gewichte, bestimmt.  Und diese Gewichte sind nicht programmiert, sondern das Ergebnis des Trainings. <br><br>  Das Bild des Pferdes wird dem Netzwerk angezeigt, und wenn es nicht auf "Pferd" antwortet, wird es dar√ºber informiert, dass dies falsch ist, und mit der richtigen Antwort aufgefordert.  Anschlie√üend passt das Netzwerk mithilfe des Algorithmus zur Fehlerr√ºck√ºbertragung die Gewichte aller Verbindungen an, sodass das Ergebnis beim n√§chsten Anzeigen desselben Bilds n√§her am gew√ºnschten liegt.  Gleichzeitig muss man ihr Tausende von Bildern zeigen. <br><br>  <b>M. F .:</b> Unterrichtet das mit einem Lehrer?  Soweit ich wei√ü, ist dies der vorherrschende Ansatz. <br><br>  <b>Y. L .:</b> Genau.  Fast alle modernen Deep-Learning-Anwendungen nutzen die Lehrerausbildung.  Die Magie besteht darin, dass das trainierte Netzwerk selbst f√ºr Bilder, denen es zuvor noch nicht gezeigt wurde, zum gr√∂√üten Teil die richtigen Antworten gibt.  Aber es braucht eine Vielzahl von Beispielen. <br><br>  <b>M.F .:</b> Und was ist in Zukunft zu erwarten?  Wird es m√∂glich sein, ein Auto als Kind zu unterrichten, das eine Katze nur einmal zeigen und benennen muss? <br><br>  <b>I. L .:</b> Eigentlich hast du nicht ganz recht.  Die ersten Faltungsschulungen finden wirklich mit Millionen von Bildern verschiedener Kategorien statt.  Und wenn Sie dann eine neue Kategorie hinzuf√ºgen m√ºssen, um beispielsweise einem Computer das Erkennen von Katzen beizubringen, sind einige Beispiele ausreichend.  Schlie√ülich ist das Netzwerk bereits darauf trainiert, Objekte nahezu aller Art zu erkennen.  Erg√§nzungen zum Training beziehen sich auf ein Paar Oberschichten. <br><br>  <b>MF:</b> Es sieht schon so aus, als w√ºrden Kinder lernen. <br><br>  <b>Y. L .:</b> Nein, das ist leider √ºberhaupt nicht so.  Kinder erhalten die meisten Informationen, bevor ihnen jemand sagt: "Dies ist eine Katze."  In den ersten Lebensmonaten lernen Kinder ohne eine Ahnung von der Sprache.  Sie erkennen die Struktur der Welt, indem sie einfach die Welt beobachten und ein wenig damit interagieren.  Diese Art der Wissensakkumulation steht Maschinen nicht zur Verf√ºgung.  Wie man es nennt, ist nicht klar.  Einige verwenden den provokativen Begriff ‚Äûlehrerlosen Unterricht‚Äú.  Dies wird manchmal als vorausschauendes oder induktives Training bezeichnet.  Ich nenne es Selbststudium.  Wenn Sie diesen Typ trainieren, m√ºssen Sie sich nicht auf die Ausf√ºhrung einer Aufgabe vorbereiten, sondern lediglich die Welt und ihre Funktionsweise beobachten. <br><br>  <b>M.F .: F√§llt</b> verst√§rktes Lernen in diese Kategorie? <br><br>  <b>Y. L .:</b> Nein, das ist eine ganz andere Kategorie.  Tats√§chlich gibt es drei Hauptkategorien: verst√§rktes Lernen, Lehrerausbildung und Selbstlernen. <br><br>  Das Training mit Verst√§rkung erfolgt durch Ausprobieren und eignet sich gut f√ºr Spiele, in denen Sie so viele Versuche machen k√∂nnen, wie Sie m√∂chten.  Die gute Leistung von AlphaGo wurde erreicht, nachdem die Maschine in den letzten dreitausend Jahren mehr Spiele als die gesamte Menschheit gespielt hatte.  F√ºr Probleme aus der realen Welt ist ein solcher Ansatz unpraktisch. <br><br>  Eine Person kann in 15 Stunden Autofahren lernen, ohne gegen irgendetwas zu sto√üen.  Wenn Sie die vorhandenen Trainingsmethoden mit Verst√§rkungen anwenden, muss das Auto, um zu lernen, wie man ohne Fahrer f√§hrt, zehntausend Mal von einer Klippe fallen, bevor es versteht, dies zu vermeiden. <br><br>  <b>M.F .:</b> Es scheint mir, dass dies ein Argument f√ºr die Modellierung ist. <br><br>  <b>Y. L .:</b> Es ist vielmehr eine Best√§tigung daf√ºr, dass sich die Art der Schulung, die die Menschen absolvieren, stark vom verst√§rkten Lernen unterscheidet.  Dies √§hnelt dem modellbasierten Verst√§rkungstraining.  Immerhin hat ein Mensch, der zum ersten Mal f√§hrt, ein Modell der Welt und kann die Konsequenzen seines Handelns vorhersagen.  Das Hauptproblem ist, wie die Maschine dazu gebracht werden kann, Prognosemodelle unabh√§ngig zu untersuchen. <br><br>  <b>M.F .:</b> Geht es Ihnen bei Ihrer Arbeit mit Facebook darum? <br><br>  <b>I. L .:</b> Ja, das ist eines der Dinge, an denen wir arbeiten.  Wir schulen die Maschine auch, um verschiedene Datenquellen zu beobachten.  Wir bauen ein Modell der Welt auf, in der Hoffnung, dass der gesunde Menschenverstand darin zum Ausdruck kommt, damit es sp√§ter als Prognosemodell verwendet werden kann. <br><br>  <b>M.F .:</b> Einige Leute denken, dass tiefes Lernen allein nicht ausreicht, und in den Netzwerken sollte es zun√§chst eine Struktur geben, die f√ºr Intelligenz verantwortlich ist.  Und Sie scheinen √ºberzeugt zu sein, dass Intelligenz aus relativ universellen neuronalen Netzen organisch hervorgehen kann. <br><br>  Y. L .: Sie √ºbertreiben.  Alle sind mit der Notwendigkeit der Struktur einverstanden, die Frage ist, wie sie aussehen soll.  Und wenn Sie von Menschen sprechen, die glauben, dass es Strukturen geben sollte, die logisches Denken und die F√§higkeit zu argumentieren bieten, dann meinen Sie wahrscheinlich Gary Marcus und m√∂glicherweise Oren Etzioni.  Wir haben uns heute Morgen mit Gary √ºber dieses Thema gestritten.  Seine Meinung wird in der Gemeinde nicht gut aufgenommen, weil er, ohne den geringsten Beitrag zum tiefen Lernen zu leisten, kritisch dar√ºber schrieb.  Oren hat einige Zeit in diesem Bereich gearbeitet und spricht gleichzeitig viel leiser. <br><br>  Tats√§chlich entstand die Idee von Faltungsnetzen als Versuch, neuronalen Netzen Struktur zu verleihen.  Die Frage ist: Wie kann die Maschine Zeichen manipulieren oder zum Beispiel den hierarchischen Merkmalen der Sprache entsprechen? <br><br>  Viele meiner Kollegen, darunter Jeffrey Hinton und Joshua Benggio, sind sich einig, dass wir fr√ºher oder sp√§ter auf Strukturen verzichten k√∂nnen.  Sie k√∂nnen kurzfristig n√ºtzlich sein, da ein Weg des Selbstlernens noch nicht erfunden wurde.  Dieser Punkt kann umgangen werden, indem alles mit der Architektur verkn√ºpft wird.  Die Mikrostruktur des Kortex, sowohl visuell als auch pr√§frontal, scheint jedoch vollkommen homogen zu sein. <br><br>  <b>M.F .:</b> Verwendet das Gehirn etwas √Ñhnliches wie die Fehlerausbreitungsmethode? <br><br>  <b>I. L .:</b> Das ist unbekannt.  Es kann sich herausstellen, dass dies nicht die R√ºckausbreitung in der Form ist, wie wir sie kennen, sondern eine √§hnliche Form der Approximation der Gradientensch√§tzung.  Joshua Benggio hat sich mit biologisch plausiblen Formen der Gradientensch√§tzung besch√§ftigt.  Es besteht die M√∂glichkeit, dass das Gehirn den Gradienten einer Zielfunktion absch√§tzt. <br><br>  <b>M.F .: An</b> welchen anderen wichtigen Dingen wird bei Facebook gearbeitet? <br><br>  <b>Y. L .:</b> Wir besch√§ftigen uns sowohl mit Grundlagenforschung als auch mit Fragen des maschinellen Lernens. Daher besch√§ftigen wir uns haupts√§chlich mit angewandter Mathematik und Optimierung.  Es wird an verst√§rktem Lernen und den sogenannten generativen Mustern gearbeitet, die eine Form des Selbstlernens oder des vorausschauenden Lernens sind. <br><br>  <b>MF:</b> Entwickelt Facebook Systeme, die eine Unterhaltung aufrechterhalten k√∂nnen? <br><br>  <b>Y. L .:</b> Ich habe oben die grundlegenden Forschungsthemen aufgelistet, aber es gibt auch viele Anwendungsbereiche.  Facebook entwickelt aktiv Entwicklungen im Bereich Computer Vision, und es kann argumentiert werden, dass wir die beste Forschungsgruppe der Welt haben.  Wir arbeiten viel an der Textverarbeitung in einer nat√ºrlichen Sprache.  Dies umfasst √úbersetzung, Generalisierung, Kategorisierung (Herausfinden, welches Thema diskutiert wird) und Dialogsysteme f√ºr virtuelle Assistenten, Frage- und Antwortsysteme usw. <br><br>  <b>M.F .:</b> Glauben Sie, dass es eines Tages eine KI geben wird, die den Turing-Test bestehen kann? <br><br>  <b>I. L .:</b> Irgendwann wird das passieren, aber ich halte den Turing-Test nicht f√ºr ein gutes Kriterium: Es ist leicht zu t√§uschen und etwas veraltet.  Viele vergessen oder weigern sich zu glauben, dass Sprache ein sekund√§res Ph√§nomen in Bezug auf Intelligenz ist. <br><br>  ¬ªWeitere Informationen zum Buch finden Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Website des Herausgebers</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Inhalt</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auszug</a> <br><br>  25% Rabatt-Gutschein f√ºr H√§ndler - <b>Intelligence Architects</b> <br><br>  Nach Bezahlung der Papierversion des Buches wird ein elektronisches Buch per E-Mail verschickt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de476466/">https://habr.com/ru/post/de476466/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de476452/index.html">Speichern von Schl√ºsselwerten oder wie unsere Anwendungen komfortabler geworden sind</a></li>
<li><a href="../de476454/index.html">5G kommt: Welche Unternehmen werden die Einf√ºhrung neuer Technologien im Jahr 2020 sicherstellen?</a></li>
<li><a href="../de476456/index.html">Das chinesische Sozialkredit-System ist in erster Linie kein B√ºrgerbewertungssystem, sondern ein massives API</a></li>
<li><a href="../de476460/index.html">Das erste Hit-Dateiformat im Internet war nicht MP3, sondern MIDI</a></li>
<li><a href="../de476464/index.html">Windows-Systemsicherheitsprotokollierungsprobleme</a></li>
<li><a href="../de476468/index.html">Samsungs neuer kostenloser Online-Kurs zur Textanalyse f√ºr neuronale Netze</a></li>
<li><a href="../de476474/index.html">Wir senden Keenetic an die KN-1310-Unterst√ºtzung des USB-Modems zur√ºck</a></li>
<li><a href="../de476476/index.html">Google Mail nur in HTML anzeigen</a></li>
<li><a href="../de476478/index.html">Etappen der Einf√ºhrung von Modellen f√ºr maschinelles Lernen in gro√üen Unternehmen</a></li>
<li><a href="../de476480/index.html">Wie man einen Entwickler in einer kleinen und nicht sehr gro√üen IT-Stadt entwickelt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
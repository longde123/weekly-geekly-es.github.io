<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå™Ô∏è üë©‚Äçüéì üöÄ Replicaci√≥n de Tarantool: configuraci√≥n y uso üñ§ üë©‚Äçüîß üê¢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Entro al equipo central de Tarantool y participo en el desarrollo de un motor de base de datos, comunicaciones internas de componentes del servidor y ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Replicaci√≥n de Tarantool: configuraci√≥n y uso</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439514/"><img src="https://habrastorage.org/webt/ec/a3/bt/eca3bttl2uu6rg8sz7e9sj3o3us.jpeg"><br><br>  Entro al equipo central de Tarantool y participo en el desarrollo de un motor de base de datos, comunicaciones internas de componentes del servidor y replicaci√≥n.  Y hoy te dir√© c√≥mo funciona la replicaci√≥n. <br><a name="habracut"></a><br><h2>  Sobre la replicaci√≥n </h2><br>  La replicaci√≥n es el proceso de hacer copias de datos de una tienda a otra.  Cada copia se llama r√©plica.  La replicaci√≥n se puede usar si necesita obtener una copia de seguridad, implementar un modo de espera activo o escalar el sistema horizontalmente.  Y para esto es necesario poder utilizar los mismos datos en diferentes nodos de la red inform√°tica del cl√∫ster. <br><br>  Clasificamos la replicaci√≥n de dos maneras principales: <br><br><ul><li> <b>Direcci√≥n: maestro-maestro o maestro-esclavo</b> .  La replicaci√≥n maestro-esclavo es la opci√≥n m√°s f√°cil.  Tiene un nodo en el que est√° cambiando los datos.  Traduce estos cambios a los otros nodos donde se aplican.  Con la replicaci√≥n maestro-maestro, los cambios se realizan en m√∫ltiples nodos a la vez.  En este caso, cada nodo cambia sus datos y aplica los cambios realizados a otros nodos. </li><li>  <b>Modo de funcionamiento: as√≠ncrono o s√≠ncrono</b> .  La replicaci√≥n sincr√≥nica implica que los datos no se comprometer√°n y la replicaci√≥n no se confirmar√° al usuario hasta que los cambios se propaguen al menos a trav√©s del m√≠nimo n√∫mero de nodos del cl√∫ster.  En la replicaci√≥n asincr√≥nica, la confirmaci√≥n de una transacci√≥n (confirmaci√≥n) y la interacci√≥n con un usuario son dos procesos independientes.  Para confirmar los datos, solo es necesario que caigan en el registro local, y solo entonces estos cambios se transmiten de alguna manera a otros nodos.  Obviamente, la replicaci√≥n asincr√≥nica tiene varios efectos secundarios debido a esto. </li></ul><br><h2>  ¬øC√≥mo funciona la replicaci√≥n en Tarantool? </h2><br>  La replicaci√≥n en Tarantool tiene varias caracter√≠sticas: <br><br><ul><li>  Est√° construido a partir de ladrillos b√°sicos, con los que puede crear un cl√∫ster de cualquier topolog√≠a.  Cada elemento de configuraci√≥n b√°sica es unidireccional, es decir, siempre tiene maestro y esclavo.  Master realiza algunas acciones y genera un registro de operaciones, que se utiliza en la r√©plica. </li><li>  La replicaci√≥n de Tarantool es as√≠ncrona.  Es decir, el sistema confirma el compromiso con usted, independientemente de cu√°ntas r√©plicas haya visto esta transacci√≥n, cu√°nto se aplic√≥ a s√≠ mismo y si result√≥ que se hizo. </li><li>  Otra propiedad de replicaci√≥n en Tarantool es que se basa en filas.  Tarantool mantiene un registro de operaciones (WAL).  La operaci√≥n llega l√≠nea por l√≠nea, es decir, cuando cambia una tabla del espacio, esta operaci√≥n se escribe en el registro como una l√≠nea.  Despu√©s de eso, el proceso en segundo plano lee esta l√≠nea del registro y la env√≠a a la r√©plica.  Cu√°ntas r√©plicas tiene el maestro, tantos procesos en segundo plano.  Es decir, cada proceso de replicaci√≥n a diferentes nodos del cl√∫ster se realiza de forma as√≠ncrona desde otros. </li><li>  Cada nodo del cl√∫ster tiene su propio identificador √∫nico, que se genera cuando se crea el nodo.  Adem√°s, el nodo tambi√©n tiene un identificador en el cl√∫ster (n√∫mero de miembro).  Esta es una constante num√©rica que se asigna a una r√©plica cuando se conecta a un cl√∫ster, y permanece con la r√©plica durante su vida √∫til en el cl√∫ster. </li></ul><br>  Debido a la asincron√≠a, los datos se entregan a r√©plicas retrasadas.  Es decir, realiz√≥ alg√∫n cambio, el sistema confirm√≥ la confirmaci√≥n, la operaci√≥n ya se aplic√≥ en el maestro, pero en las r√©plicas se aplicar√° con cierto retraso, que est√° determinado por la velocidad con la que el proceso de replicaci√≥n en segundo plano lee la operaci√≥n, la env√≠a a la r√©plica y se aplica . <br><br>  Debido a esto, existe la posibilidad de que los datos no est√©n sincronizados.  Supongamos que tenemos varios maestros que cambian los datos interconectados.  Puede resultar que las operaciones que utiliza no sean conmutativas y se refieran a los mismos datos, luego dos miembros diferentes del cl√∫ster tendr√°n diferentes versiones de los datos. <br><br>  <b>Si la replicaci√≥n en Tarantool es unidireccional maestro-esclavo, entonces, ¬øc√≥mo hacer maestro-maestro?</b>  Muy simple: cree otro canal de replicaci√≥n pero en la otra direcci√≥n.  Debe comprender que en Tarantool, la replicaci√≥n maestro-maestro es solo una combinaci√≥n de dos flujos de datos que son independientes entre s√≠. <br><br>  Usando el mismo principio, podemos conectar el tercer maestro y, como resultado, construir una red de malla completa en la que cada r√©plica sea maestra y esclava para todas las dem√°s r√©plicas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nx/z5/b-/nxz5b-f9rzqtmhi7ga4fhq8pdq8.png" width="500"></div><br>  Tenga en cuenta que no solo se replican aquellas operaciones que se inician localmente en este maestro, sino tambi√©n aquellas que recibi√≥ externamente a trav√©s de protocolos de replicaci√≥n.  En este caso, los cambios creados en la r√©plica No. 1 vendr√°n a la r√©plica No. 3 dos veces: directamente ya trav√©s de la r√©plica No. 2. Esta propiedad nos permite construir topolog√≠as m√°s complejas sin usar una malla completa.  Digamos este. <br><br><img src="https://habrastorage.org/webt/k3/wy/r4/k3wyr4imeqfncmfar65mohmcj24.png"><br><br>  Los tres maestros, que juntos forman el n√∫cleo de malla completa del cl√∫ster, tienen una r√©plica individual adjunta.  Dado que la representaci√≥n de registros se realiza en cada uno de los maestros, los tres esclavos "limpios" contendr√°n todas las operaciones que se realizaron en cualquiera de los nodos del cl√∫ster. <br><br>  Esta configuraci√≥n se puede usar para una variedad de tareas.  No puede crear enlaces redundantes entre todos los nodos del cl√∫ster, y si las r√©plicas se colocan cerca, tendr√°n una copia exacta del maestro con un retraso m√≠nimo.  Y todo esto se hace utilizando el elemento b√°sico de replicaci√≥n maestro-esclavo. <br><br><h2>  Etiquetado de operaciones de cl√∫ster </h2><br>  Surge la pregunta: <b>si las operaciones se representan entre todos los miembros del cl√∫ster y llegan a cada r√©plica varias veces, ¬øc√≥mo entendemos qu√© operaci√≥n debe realizarse y cu√°l no?</b>  Esto requiere un mecanismo de filtrado.  A cada operaci√≥n le√≠da del registro se le asignan dos atributos: <br><br><ul><li>  El identificador del servidor en el que se inici√≥ esta operaci√≥n. </li><li>  El n√∫mero de secuencia de la operaci√≥n en el servidor, lsn, que es su iniciador.  Cada servidor, al realizar una operaci√≥n, asigna un n√∫mero creciente a cada l√≠nea de registro recibida: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ... Por lo tanto, si sabemos que para un servidor con un determinado identificador, aplicamos la operaci√≥n con lsn 10, luego no son necesarias las operaciones con lsn 9, 8, 7, 10 que llegaron a trav√©s de otros canales de replicaci√≥n.  En su lugar, aplicamos lo siguiente: 11, 12, etc. </li></ul><br><h2>  Estado de r√©plica </h2><br>  <b>¬øY c√≥mo almacena Tarantool informaci√≥n sobre las operaciones que ya ha aplicado?</b>  Para hacer esto, hay un reloj Vclock: este es el vector del √∫ltimo lsn aplicado a cada nodo en el cl√∫ster. <br><br> <code>[lsn <sub>1</sub> , lsn <sub>2</sub> , lsn <sub>n</sub> ]</code> <br> <br>  donde <code>lsn <sub>i</sub></code> es el n√∫mero de la √∫ltima operaci√≥n conocida del servidor con el identificador i. <br><br>  Vclock tambi√©n se puede llamar una instant√°nea del estado completo del cl√∫ster conocido por esta r√©plica.  Al conocer la ID del servidor de la operaci√≥n que ha llegado, aislamos el componente del Vclock local que necesitamos, comparamos el lsn recibido con la operaci√≥n lsn y decidimos si usar esta operaci√≥n.  Como resultado, las operaciones iniciadas por un maestro espec√≠fico se enviar√°n y aplicar√°n secuencialmente.  Al mismo tiempo, los flujos de trabajo creados en diferentes maestros pueden mezclarse entre s√≠ debido a la replicaci√≥n asincr√≥nica. <br><br><h2>  Creaci√≥n de cl√∫ster </h2><br>  Supongamos que tenemos un cl√∫ster que consta de dos elementos maestro y esclavo, y queremos conectarle una tercera instancia.  Tiene un UUID √∫nico, pero todav√≠a no hay un identificador de cl√∫ster.  Si Tarantool a√∫n no se ha inicializado, desea unirse al cl√∫ster, debe enviar una operaci√≥n JOIN a uno de los maestros que puedan realizarlo, es decir, est√° en modo de lectura-escritura.  En respuesta a JOIN, el maestro env√≠a su instant√°nea local a la r√©plica de conexi√≥n.  La r√©plica lo rueda en casa, mientras que todav√≠a no tiene un identificador.  Ahora la r√©plica con un ligero retraso se sincroniza con el cl√∫ster.  Despu√©s de eso, el maestro en el que se ejecut√≥ JOIN asigna un identificador a esta r√©plica, que se registra y se env√≠a a la r√©plica.  Cuando se asigna un identificador a una r√©plica, se convierte en un nodo completo y luego puede iniciar la replicaci√≥n de registros a su lado. <br><br>  Las l√≠neas del diario se env√≠an a partir del estado de esta r√©plica al momento de solicitar el registro de replicaci√≥n al maestro, es decir, desde el vclock que recibi√≥ durante el proceso de UNI√ìN, o desde el lugar donde la r√©plica se detuvo antes.  Si la r√©plica se ha ca√≠do por alg√∫n motivo, la pr√≥xima vez que se conecte al cl√∫ster, ya no se unir√°, porque ya tiene una instant√°nea local.  Ella solo pregunta por todas las operaciones que ocurrieron durante su ausencia en el grupo. <br><br><h2>  Registrar una r√©plica en un cl√∫ster </h2><br>  Se utiliza un espacio especial para almacenar el estado de la estructura del cl√∫ster: cl√∫ster.  Contiene los identificadores del servidor en el cl√∫ster, sus n√∫meros de serie e identificadores √∫nicos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/af/0f/hr/af0fhra2ln0s2xcq-qsmeim2xtc.png" width="500"></div><br><br> <code>[1, 'c35b285c-c5b1-4bbe-83b1-b825eb594aa4'] <br> [2, '37b12cb7-d324-4d75-b428-cde92c18e708'] <br> [3, 'b72b1aa6-42a0-4d73-a611-900e44cdd465']</code> <br> <br>  No es necesario que los identificadores vayan en orden, porque los nodos se pueden eliminar y agregar. <br><br>  Aqu√≠ est√° el primer escollo.  Como regla, los cl√∫steres no son recopilados por un nodo: ejecuta una determinada aplicaci√≥n y despliega todo el cl√∫ster a la vez.  Pero la replicaci√≥n en Tarantool es asincr√≥nica.  ¬øQu√© sucede si dos maestros conectan simult√°neamente nuevos nodos y les asignan identificadores id√©nticos?  Habr√° un conflicto. <br><br>  Aqu√≠ hay un ejemplo de una UNI√ìN incorrecta y correcta: <br><br><img src="https://habrastorage.org/webt/o2/9_/bc/o29_bcjs3dhyllneqlgaczljxys.png"><br><br>  Tenemos dos maestros y dos r√©plicas que desean conectarse.  Hacen uniones en diferentes maestros.  Supongamos que las r√©plicas obtienen los mismos identificadores.  Luego, la replicaci√≥n entre los maestros y aquellos que logran replicar sus registros se desmoronar√°, el cl√∫ster se desmoronar√°. <br><br>  Para evitar que esto suceda, debe iniciar r√©plicas estrictamente en un maestro en cualquier momento.  Con este fin, Tarantool introdujo un concepto como l√≠der de inicializaci√≥n e implement√≥ un algoritmo para elegir este l√≠der.  Una r√©plica que quiere conectarse al cl√∫ster primero establece una conexi√≥n con todos los maestros conocidos desde la configuraci√≥n transferida.  Luego, la r√©plica selecciona aquellos que ya se han iniciado (al implementar el cl√∫ster, no todos los nodos logran ganar dinero completo).  Y de ellos se seleccionan los maestros que est√°n disponibles para la grabaci√≥n.  En Tarantool, hay lectura-escritura y solo lectura, no podemos registrarnos en el nodo de solo lectura.  Despu√©s de eso, de la lista de nodos filtrados, seleccionamos el que tiene el UUID m√°s bajo. <br><br>  Si usamos la misma configuraci√≥n y la misma lista de servidores en instancias no inicializadas que se conectan al cl√∫ster, entonces seleccionar√°n el mismo maestro, lo que significa que JOIN probablemente tendr√° √©xito. <br><br>  De aqu√≠ derivamos una regla: cuando se conectan r√©plicas a un cl√∫ster en paralelo, todas estas r√©plicas deben tener la misma configuraci√≥n de replicaci√≥n.  Si omitimos algo en alguna parte, existe la posibilidad de que las instancias con una configuraci√≥n diferente se inicien en diferentes maestros y el cl√∫ster no pueda ensamblarse. <br><br>  Supongamos que nos equivocamos, o el administrador olvid√≥ arreglar la configuraci√≥n, o Ansible se rompi√≥, y el cl√∫ster a√∫n se desmoron√≥.  ¬øQu√© puede dar testimonio de esto?  Primero, las r√©plicas conectables no podr√°n crear sus instant√°neas locales: las r√©plicas no se inician ni informan errores.  En segundo lugar, en los maestros en los registros, veremos errores relacionados con conflictos en el cl√∫ster espacial. <br><br>  ¬øC√≥mo resolvemos esta situaci√≥n?  Es simple: <br><br><ul><li>  En primer lugar, debemos validar la configuraci√≥n que establecemos para las r√©plicas de conexi√≥n, porque si no la arreglamos, todo lo dem√°s ser√° in√∫til. </li><li>  Despu√©s de eso, limpiamos los conflictos en el cl√∫ster y tomamos una foto. </li></ul><br>  Ahora puede intentar inicializar las r√©plicas nuevamente. <br><br><h2>  Resoluci√≥n de conflictos </h2><br>  Entonces, creamos un cl√∫ster y nos conectamos.  Todos los nodos funcionan en el modo de suscripci√≥n, es decir, reciben los cambios generados por diferentes maestros.  Debido a que la replicaci√≥n es as√≠ncrona, los conflictos son posibles.  Cuando cambia simult√°neamente datos en diferentes maestros, diferentes r√©plicas obtienen diferentes copias de los datos, porque las operaciones se pueden aplicar en un orden diferente. <br><br>  Aqu√≠ hay un cl√∫ster de ejemplo despu√©s de ejecutar JOIN: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-o/2j/k2/-o2jk2hjv2dqndshyqta_blcmo8.png" width="500"></div><br>  Tenemos tres esclavos maestros, los registros se transmiten entre ellos, que se representan en diferentes direcciones y se aplican a los esclavos.  Los datos no sincronizados significan que cada r√©plica tendr√° su propio historial de cambios vclock, ya que las secuencias de diferentes maestros se pueden mezclar.  Pero entonces el orden de las operaciones en las instancias puede variar.  Si nuestras operaciones no son conmutativas, como la operaci√≥n REEMPLAZAR, entonces los datos que recibamos en estas r√©plicas ser√°n diferentes. <br><br>  Un peque√±o ejemplo.  Supongamos que tenemos dos maestros con vclock = {0,0}.  Y ambos realizar√°n dos operaciones, designadas como op1,1, op1,2, op2,1, op2,2.  Este es el segundo segmento de tiempo cuando cada uno de los maestros realiz√≥ una operaci√≥n local: <br><br><img src="https://habrastorage.org/webt/-y/z7/cy/-yz7cyhaozyxkdltf7pptl37oqa.png"><br><br>  El verde indica un cambio en el componente vclock correspondiente.  Primero, ambos maestros cambian su vclock, y luego el segundo maestro realiza otra operaci√≥n local y nuevamente aumenta vclock.  El primer maestro recibe la operaci√≥n de replicaci√≥n del segundo maestro, esto se indica con el n√∫mero rojo 1 en vclock del primer nodo del cl√∫ster. <br><br><img src="https://habrastorage.org/webt/if/j8/8f/ifj88f4rat3litvsyedit09shw0.png"><br><br>  Luego, el segundo maestro recibe la operaci√≥n del primero, y el primero, la segunda operaci√≥n del segundo.  Y al final, el primer maestro realiza su √∫ltima operaci√≥n, y el segundo maestro lo recibe. <br><br><img src="https://habrastorage.org/webt/gh/3z/jo/gh3zjoicvoxqd772_pt1m92wfem.png"><br><br>  Vclock en el cuanto de tiempo cero tenemos lo mismo - {0,0}.  En el √∫ltimo cuanto de tiempo, tambi√©n tenemos el mismo vclock {2,2}, parece que los datos deber√≠an ser los mismos.  Pero el orden de las operaciones realizadas en cada maestro es diferente.  ¬øY si esta es una operaci√≥n REPLACE con diferentes valores para las mismas claves?  Luego, a pesar del mismo vclock al final, obtendremos diferentes versiones de los datos en ambas r√©plicas. <br><br>  Tambi√©n podemos resolver esta situaci√≥n. <br><br><ul><li>  <b>Sharding records</b> .  Primero, podemos realizar operaciones de escritura no en r√©plicas seleccionadas al azar, sino que de alguna manera las fragmentamos.  Simplemente rompieron las operaciones de escritura en diferentes maestros y obtuvieron un sistema de consistencia eventual.  Por ejemplo, las claves han cambiado de 1 a 10 en un maestro y de 11 a 20 en otro: los nodos intercambiar√°n sus registros y obtendr√°n exactamente los mismos datos. <br><br>  Sharding implica que tenemos un cierto enrutador.  No tiene que ser una entidad separada, el enrutador puede ser parte de la aplicaci√≥n.  Puede ser un fragmento que aplica operaciones de escritura a s√≠ mismo o las transfiere a otro maestro de una forma u otra.  Pero pasa de tal manera que los cambios en los valores asociados van a un maestro particular: un bloque de valor fue a un maestro, otro bloque a otro maestro.  En este caso, las operaciones de lectura se pueden enviar a cualquier nodo del cl√∫ster.  Y no se olvide de la replicaci√≥n asincr√≥nica: si grab√≥ en el mismo maestro, es posible que tambi√©n deba leerlo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/de/cq/wv/decqwvuzuaz-yn6t7fbyq2o2sv4.png" width="500"></div></li><li>  <b>Ordenamiento l√≥gico de operaciones</b> .  Suponga que de acuerdo con las condiciones del problema, de alguna manera puede determinar la prioridad de la operaci√≥n.  Digamos, ponga una marca de tiempo, o versi√≥n, o alguna otra etiqueta que nos permita comprender qu√© operaci√≥n ocurri√≥ f√≠sicamente antes.  Es decir, estamos hablando de una fuente externa de pedidos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/h8/pt/zl/h8ptzlm1ieiugdnjr66ubi9pxwq.png" width="500"></div><br>  Tarantool tiene un desencadenador <code>before_replace</code> que se puede ejecutar durante la replicaci√≥n.  En este caso, no estamos limitados por la necesidad de enrutar solicitudes, podemos enviarlas a donde queramos.  Pero cuando realizamos la replicaci√≥n a la entrada del flujo de datos, tenemos un desencadenante.  Lee la l√≠nea enviada, la compara con la l√≠nea que ya est√° almacenada y decide cu√°l de las l√≠neas tiene mayor prioridad.  Es decir, el activador ignora la solicitud de replicaci√≥n o la aplica, posiblemente con las modificaciones requeridas.  Ya aplicamos este enfoque, aunque tambi√©n tiene sus inconvenientes.  Primero, necesita una fuente de reloj externa.  Supongamos que un operador en un sal√≥n de telefon√≠a m√≥vil realiza cambios en un suscriptor.  Para tales operaciones, puede usar el tiempo en la computadora del operador, porque es poco probable que varios operadores realicen cambios en un suscriptor al mismo tiempo.  Las operaciones pueden venir de diferentes maneras, pero si a cada una de ellas se le puede asignar una determinada versi√≥n, entonces, al pasar por los disparadores, solo permanecer√°n aquellos que sean relevantes. <br><br>  El segundo inconveniente del m√©todo: dado que el disparador se aplica a cada delta que vino por la replicaci√≥n para cada solicitud, esto crea una carga computacional adicional.  Pero luego tendremos una copia consistente de los datos en una escala de cl√∫ster. </li></ul><br><h2>  Sincronizaci√≥n </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jr/1n/db/jr1ndb23coit6rz1qeblip_tpy0.png" width="500"></div><br>  Nuestra replicaci√≥n es as√≠ncrona, es decir, mediante la ejecuci√≥n de confirmaci√≥n no sabe si estos datos ya est√°n en alg√∫n otro nodo del cl√∫ster.  Si realiz√≥ una confirmaci√≥n en master, se le confirm√≥, y master por alguna raz√≥n dej√≥ de funcionar inmediatamente, entonces no puede estar seguro de que los datos se hayan guardado en otro lugar.  Para resolver este problema, el protocolo de replicaci√≥n de Tarantool tiene un ACK.  Cada maestro tiene conocimiento de qu√© √∫ltimo ACK vino de cada esclavo. <br><br>  ¬øQu√© es un ACK?  Cuando el esclavo recibe el delta, que est√° marcado por el maestro lsn y su identificador, en respuesta env√≠a un paquete ACK especial, en el que empaca su vclock local despu√©s de aplicar esta operaci√≥n.  Veamos c√≥mo puede funcionar esto. <br><br>  Tenemos un maestro que realiz√≥ 4 operaciones en s√≠ mismo.  Suponga que en alg√∫n momento el esclavo esclavo recibi√≥ las primeras tres l√≠neas y su vclock aument√≥ a {3.0}. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oy/iw/y1/oyiwy1eifo7_jfsb9ylvi1wkija.png" width="500"></div><br>  ACK a√∫n no ha llegado.  Habiendo recibido estas tres l√≠neas, el esclavo env√≠a el paquete ACK al que ha cosido su vclock en el momento en que se envi√≥ el paquete.  Deje que el esclavo maestro env√≠e otra l√≠nea en el mismo intervalo de tiempo, es decir, el vclock del esclavo ha aumentado.  En base a esto, el maestro No. 1 sabe con certeza que las tres primeras operaciones que realiz√≥ ya se han aplicado a este esclavo.  Estos estados se almacenan para todos los esclavos con los que trabaja el maestro; son completamente independientes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/u1/rx/va/u1rxvazmmssfoizpfecbwf3ceas.png" width="500"></div><br>  Y al final, el esclavo responde con un cuarto paquete ACK.  Despu√©s de eso, el maestro sabe que el esclavo est√° sincronizado con √©l. <br><br>  Este mecanismo se puede usar en el c√≥digo de la aplicaci√≥n.  Cuando confirma una operaci√≥n, no reconoce inmediatamente al usuario, sino que primero llama a una funci√≥n especial.  Espera a que el esclavo lsn conocido por el maestro sea igual al lsn de su maestro en el momento en que se completa la confirmaci√≥n.  Por lo tanto, no necesita esperar la sincronizaci√≥n completa, solo espere el momento mencionado. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1-/oe/93/1-oe930isjznmsurqj314c2-gue.png" width="500"></div><br>  Supongamos que nuestra primera llamada ha cambiado tres l√≠neas y la segunda llamada ha cambiado una.  Despu√©s de la primera llamada, desea asegurarse de que los datos est√©n sincronizados.  El estado que se muestra arriba ya significa que la primera llamada se sincroniz√≥ en al menos un esclavo. <br><br>  D√≥nde exactamente buscar informaci√≥n sobre esto, lo consideraremos en la siguiente secci√≥n. <br><br><h2>  Monitoreo </h2><br>  Cuando la replicaci√≥n es s√≠ncrona, el monitoreo es muy simple: si se desmorona, se emiten errores en sus operaciones.  Y si la replicaci√≥n es asincr√≥nica, la situaci√≥n se vuelve confusa.  Shifu le responde que todo est√° bien, funciona, aceptado, anotado.  Pero al mismo tiempo, todas las r√©plicas est√°n muertas, los datos no tienen redundancia y si pierde el maestro, perder√° los datos.  Por lo tanto, realmente quiero monitorear el cl√∫ster, entender lo que est√° sucediendo con la replicaci√≥n asincr√≥nica, d√≥nde est√°n las r√©plicas, en qu√© estado se encuentran. <br><br>  Para el monitoreo b√°sico, Tarantool tiene una entidad box.info.  Vale la pena llamarlo en la consola, ya que ver√° datos interesantes. <br><br><pre> <code class="plaintext hljs">id: 1 uuid: c35b285c-c5b1-4bbe-83b1-b825eb594aa4 lsn : 5 vclock : {2: 1, 1: 5} replication : 1: id: 1 uuid : c35b285c -c5b1 -4 bbe -83b1 - b825eb594aa4 lsn : 5 2: id: 2 uuid : 37 b12cb7 -d324 -4 d75 -b428 - cde92c18e708 lsn : 1 upstream : status : follow idle : 0.30358312401222 peer : lag: 3.6001205444336 e -05 downstream : vclock : {2: 1, 1: 5}</code> </pre> <br>  La m√©trica m√°s importante es la identificaci√≥n <code>id</code> .  En este caso, 1 significa que el lsn de este maestro se almacenar√° en la primera posici√≥n en todos los vclock.  Una cosa muy √∫til.  Si tiene un conflicto con JOIN, puede distinguir un maestro de otro solo por identificadores √∫nicos.  Adem√°s, las cantidades locales incluyen cantidades tales como lsn.  Este es el n√∫mero de la √∫ltima l√≠nea que este maestro ejecut√≥ y escribi√≥ en su registro.  En nuestro ejemplo, el primer maestro realiz√≥ cinco operaciones.  Vclock es el estado de las operaciones que sabe que se aplic√≥ a s√≠ mismo.  Y finalmente, para el maestro n√∫mero 2, realiz√≥ una de sus operaciones de replicaci√≥n. <br><br>  Despu√©s de los indicadores del estado local, puede ver lo que esta instancia sabe sobre el estado de la replicaci√≥n del cl√∫ster; para esto, hay una secci√≥n de <code>replication</code> .  Enumera todos los nodos del cl√∫ster conocidos por la instancia, incluido √©l mismo.  El primer nodo tiene el identificador 1, id corresponde a la instancia actual.  El segundo nodo tiene el identificador 2, su lsn 1 corresponde al lsn que se escribe en vclock.  En este caso, consideramos la replicaci√≥n maestro-maestro, cuando el maestro No. 1 es el maestro para el segundo nodo del cl√∫ster y su esclavo, es decir, lo sigue. <br><br><ul><li>  La esencia de <code>upstream</code> .  El atributo de <code>status follow</code> significa que el maestro 1 sigue al maestro 2. Inactivo es el tiempo que ha pasado localmente desde la √∫ltima interacci√≥n con este maestro.  No enviamos un flujo continuamente, el maestro env√≠a un delta solo cuando se producen cambios en √©l.  Cuando enviamos alg√∫n tipo de ACK, tambi√©n nos comunicamos.  Obviamente, si la inactividad aumenta (segundos, minutos, horas), entonces algo est√° mal. </li><li>  Atributo de <code>lag</code> .  Hablamos sobre el retraso.  Adem√°s de lsn y <code>server id</code> cada operaci√≥n en el registro tambi√©n est√° marcada con una marca de tiempo - hora local durante la cual esta operaci√≥n se registr√≥ en vclock en el maestro que la realiz√≥.  Al mismo tiempo, Slave compara su marca de tiempo local con la marca de tiempo del delta que recibi√≥.  La √∫ltima marca de tiempo actual recibida para la √∫ltima l√≠nea, el esclavo se muestra en la supervisi√≥n. </li><li>  Atributo <code>downstream</code> .  Muestra lo que el maestro sabe sobre su esclavo en particular.  Este es el ACK que el esclavo le env√≠a.  El <code>downstream</code> presentado anteriormente significa que la √∫ltima vez que su esclavo, tambi√©n conocido como maestro en el n√∫mero 2, le envi√≥ su vclock, que era 5.1.  Este maestro sabe que las cinco l√≠neas, que complet√≥ en su lugar, se fueron a otro nodo. </li></ul><br><h2>  P√©rdida de XLOG </h2><br>  Considere la situaci√≥n con la ca√≠da del maestro. <br><br><pre> <code class="plaintext hljs">lsn : 0 id: 3 replication : 1: &lt;...&gt; upstream : status: disconnected peer : lag: 3.9100646972656 e -05 idle: 1602.836148153 message: connect, called on fd 13, aka [::1]:37960 2: &lt;...&gt; upstream : status : follow idle : 0.65611373598222 peer : lag: 1.9550323486328 e -05 3: &lt;...&gt; vclock : {2: 2, 1: 5}</code> </pre> <br>  En primer lugar, el estado cambiar√°.  <code>Lag</code> no cambia porque la l√≠nea que aplicamos sigue siendo la misma, no obtuvimos ninguna nueva.  Al mismo tiempo, el tiempo de <code>idle</code> creciendo, en este caso ya es igual a 1602 segundos, tanto tiempo el maestro estuvo muerto.  Y vemos un mensaje de error: no hay conexi√≥n de red. <br><br>  ¬øQu√© hacer en una situaci√≥n similar?  Descubrimos lo que sucedi√≥ con nuestro maestro, atraemos al administrador, reiniciamos el servidor, elevamos el nodo.  Se realiza una replicaci√≥n repetida, y cuando el maestro ingresa al sistema, nos conectamos a √©l, nos suscribimos a su XLOG, los obtenemos para nosotros y el cl√∫ster se estabiliza. <br><br>  Pero hay un peque√±o problema.  Imagine que tenemos un esclavo, que por alguna raz√≥n se apag√≥ y estuvo ausente durante mucho tiempo.  Durante este tiempo, el maestro, que lo sirvi√≥, elimin√≥ el XLOG.  Por ejemplo, el disco est√° lleno, el recolector de basura ha recopilado registros.  ¬øC√≥mo puede continuar un esclavo que regresa?  De ninguna manera  Porque los registros que necesita aplicar para sincronizarse con el cl√∫ster se han ido y no hay de d√≥nde sacarlos.  En este caso, veremos un error interesante: el estado ya no se <code>disconnected</code> , sino que se <code>stopped</code> .  Y un mensaje espec√≠fico: no hay ning√∫n archivo de registro que coincida con tal lsn. <br><br><pre> <code class="plaintext hljs">id: 3 replication : 1: &lt;...&gt; upstream : peer : status: stopped lag : 0.0001683235168457 idle : 9.4331328970147 message: 'Missing .xlog file between LSN 7 1: 5, 2: 2 and 8 1: 6, 2: 2' 2: &lt;...&gt; 3: &lt;...&gt; vclock : {2: 2, 1: 5}</code> </pre> <br>  De hecho, la situaci√≥n no siempre es fatal.  Supongamos que tenemos m√°s de dos maestros, y en algunos de ellos estos registros a√∫n se conservan.  Los entregamos a todos los maestros a la vez, y no los almacenamos en uno solo.  Luego resulta que esta r√©plica, que se conecta con todos los maestros que conoce, en algunos de ellos encontrar√° los registros que necesita.  Ella realizar√° todas estas operaciones en casa, su vclock aumentar√° y alcanzar√° el estado actual del grupo.  Despu√©s de eso, puedes intentar reconectarte. <br><br>  Si no hay registros, no podemos continuar con la r√©plica.  Solo queda reiniciarlo.  Recuerde su identificador √∫nico, puede escribirlo en una hoja de papel o en un archivo.  Luego limpiamos la r√©plica localmente: elimina sus im√°genes, registros, etc.  Despu√©s de eso, vuelva a conectar la r√©plica con el mismo UUID que ten√≠a. <br><br>  Elimine el cl√∫ster o reutilice el UUID para la nueva r√©plica: <code>box.cfg{instance_uuid =  uuid}</code> . <br><br>   ,   .   UUID    space cluster,    .       ,    .    UUID,  master,     JOIN,     ,       UUID,   ,    . <br><br>   ,   UUID ,     space cluster      ,    .       .  ,  ,          . <br><br><h2>  </h2><br> ,  -           .   ,        .    ,   ,      . <br><br>  Tarantool   . <br><br> <code>replication_connect_quorum: 2 <br> replication_connect_timeout: 30 <br> replication_sync_lag: 0.1</code> <br> <br> ,   , ,            ,   ,  ,  master'     0,1 .    30 .     ,   .   0,1 .  ,      . <br><br><h2> Keep alive </h2><br>  ,      ip tables drop.  ,    -  30   30 ,    ,      .     ,   keep alive-. <br><br>  keep alive-  : <code>box.cfg.replication_timeout</code> . <br><br>      master'      ,    keep alive-, ,   .    4  master  slave   keep alive-   ,         .             master'. <br><br><h2>    </h2><br>  ,      .    6 ,      5 .     10 ,    9 .     . <br><br>   ,    ,     .       ,         master',   .  -          .   . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pp/wv/qo/ppwvqoys4enyzstnxbfp0mtkug4.png" width="500"></div><br>     6 ,       3.     ,    .  ,     5 ,      3 . <br><br><h2>     </h2><br>   ,       : <br><br><ul><li>  . </li><li>  ,       space cluster,        .          . </li></ul><br>   ,    Telegram-,  .          ,     GitHub,   . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439514/">https://habr.com/ru/post/439514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439504/index.html">¬øSu equipo necesita un ingeniero de datos?</a></li>
<li><a href="../439506/index.html">9 alternativas a un mal equipo (patr√≥n de dise√±o)</a></li>
<li><a href="../439508/index.html">Mitap sobre desarrollo de c√≥digo abierto en Mosc√∫</a></li>
<li><a href="../439510/index.html">Sistema de control distribuido altamente cargado de una central nuclear moderna</a></li>
<li><a href="../439512/index.html">¬øLa edad de los dinosaurios o el reaseguro legalmente verificado?</a></li>
<li><a href="../439520/index.html">Prueba de participaci√≥n: ¬ønuevo modelo de negocio en 2019?</a></li>
<li><a href="../439522/index.html">Reenlace de DNS en 2k19, o c√≥mo sudar realmente visitando un sitio porno</a></li>
<li><a href="../439524/index.html">Fortnite es el futuro, pero por razones bastante inesperadas</a></li>
<li><a href="../439526/index.html">Los operadores de telecomunicaciones realizar√°n "pruebas de campo" de la ley de sostenibilidad de Runet</a></li>
<li><a href="../439528/index.html">Seguimiento de llamadas sin costo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
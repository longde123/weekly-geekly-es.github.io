<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📢 💆🏽 📩 Cargo Cult para IA: O Mito da Inteligência Artificial Sobre-Humana 🤞🏻 🍺 🤺</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ouvi dizer que, no futuro, a IA do computador se tornará tão mais inteligente do que nós que tirará todos os nossos empregos e recursos e as pessoas m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cargo Cult para IA: O Mito da Inteligência Artificial Sobre-Humana</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/403999/"><img src="https://habrastorage.org/getpro/geektimes/post_images/f29/b7c/50b/f29b7c50b4fd97573f28f8508e94a9a0.jpg" alt="imagem"><br><br>  Ouvi dizer que, no futuro, a IA do computador se tornará tão mais inteligente do que nós que tirará todos os nossos empregos e recursos e as pessoas morrerão.  É isso mesmo? <br><br>  Essa é a pergunta mais comum que me fazem nos meus discursos sobre IA.  As pessoas que perguntam a ele estão sinceramente preocupadas, e sua preocupação vem de outras pessoas - especialistas que fazem a mesma pergunta.  Entre eles, você pode conhecer as pessoas mais inteligentes que vivem hoje - por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Stephen Hawking</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Elon Musk</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Max Tegmark</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sam Harris</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Bill Gates</a> - e todos acreditam na possibilidade de tal cenário.  Em uma recente conferência da IA, um comitê das nove pessoas com mais conhecimento da IA ​​concordou que não poderíamos evitar o advento da IA ​​sobre-humana. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/h0962biiZa4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Mas esse cenário de conquista do mundo da IA ​​inclui cinco suposições, que, como se vê em um estudo cuidadoso, não são baseadas em evidências.  Essas declarações podem ser justificadas no futuro, mas agora nenhuma delas possui evidências.  Estas são as premissas: <br><br>  1. A IA já está se tornando mais inteligente do que nós, e seu poder está crescendo exponencialmente. <br>  2. Criaremos uma IA geral semelhante à nossa. <br>  3. Somos capazes de criar inteligência humana baseada em silício. <br>  4. O intelecto é capaz de crescer sem limites. <br>  5. Após a explosão da superinteligência, ele nos ajudará a resolver todos os nossos problemas. <br><br>  Como objeção a esse cânone ortodoxo, darei cinco declarações heréticas, as quais, ao que me parece, têm mais razões. <br><br>  1. A inteligência não é unidimensional; portanto, o conceito de "mais inteligente que as pessoas" não faz sentido. <br>  2. Nem os seres humanos nem a IA têm consciência de propósito geral. <br>  3. A emulação do pensamento humano em outras mídias será limitada pelo custo de sua criação. <br>  4. As dimensões da inteligência não são infinitas. <br>  5. A inteligência é apenas um dos fatores do progresso. <br><br>  Se a expectativa para o surgimento de IA sobre-humana (SII) se baseia em cinco suposições principais que não têm evidências, então essa idéia é mais como uma crença religiosa ou um mito.  Em seguida, expandirei cada uma das minhas cinco contra-premissas e provarei que o SII é realmente um mito. <br><br><h2>  1 </h2><br>  O equívoco mais comum sobre IA começa com o equívoco sobre inteligência natural.  Consiste no fato de que a inteligência é unidimensional.  A maioria dos técnicos tende a retratar a inteligência como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nick Bostrom</a> em Superintelligence, como um gráfico de linhas unidimensional com amplitude crescente. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2c1/36a/b2f/2c136ab2fc2e0fd8904bff67561b5252.png" alt="imagem"><br><br>  De um lado, há pouca inteligência, por exemplo, um animal pequeno;  por outro, um alto, digamos, gênio - como se a inteligência pudesse ser representada como um nível sonoro em decibéis.  Certamente, neste caso, é fácil imaginar que o volume de inteligência continua a crescer e, como resultado, excede nosso nível altamente intelectual e se torna um intelecto ultra-alto - um rugido!  - inacessível para nós e fora do cronograma. <br><br>  Esse modelo é topologicamente equivalente a uma escada na qual cada passo subsequente da inteligência é um passo mais alto que o anterior.  Animais mais novos estão nos degraus mais baixos, e a IA de alto nível nos ultrapassará e estará nos degraus acima.  A linha do tempo deste evento não importa, apenas o ranking importa - a métrica do aumento da inteligência. <br><img src="https://habrastorage.org/getpro/geektimes/post_images/f8e/b81/319/f8eb81319d9ae2b95c5e2d0b627c974c.jpg" alt="imagem"><br><br>  O problema com esse modelo é que ele é tão mítico quanto a escada da evolução.  Antes de Darwin, o mundo natural era considerado uma escada na qual os animais mais jovens estavam localizados abaixo da pessoa.  Mesmo depois de Darwin, era costume pensar na evolução como uma “escada”, segundo a qual os peixes se transformavam em répteis, depois em mamíferos, depois em primatas, em humanos, e cada estágio está em um “estágio de evolução” um pouco mais alto e, portanto, considerados mais inteligentes que os anteriores.  Portanto, a escada da inteligência é consistente com a escada da existência.  Mas esses modelos têm uma abordagem completamente não científica. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/57d/f3e/7ed/57df3e7eda77f345c53819dc8a1945bc.png" alt="imagem"><br><br>  Uma descrição mais precisa da evolução natural das espécies é um disco em expansão, como na figura acima, proposto pela primeira vez por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">David Hillis,</a> da Universidade do Texas, e criado com base no DNA.  Essa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mandala</a> genealógica começa no centro com as formas de vida mais primitivas e depois se ramifica no tempo.  O tempo se move para fora, de modo que os novos tipos de vida que habitam o planeta hoje estão em torno da circunferência.  Esta imagem enfatiza o fato da evolução, que é difícil de aceitar: cada uma das espécies que vivem hoje é igualmente evolucionária.  As pessoas existem neste anel, juntamente com baratas, moluscos, samambaias, raposas e bactérias.  Cada espécie passou por uma cadeia contínua de três bilhões de anos de reprodução bem-sucedida, o que significa que as bactérias e baratas de hoje são tão evolutivamente desenvolvidas quanto os seres humanos.  Não há escada. <br><br>  Da mesma forma, não há escada para a inteligência.  A inteligência não é unidimensional.  Este é um complexo de muitos tipos e modos de reconhecimento, cada um dos quais é um continuum.  Pegue a tarefa mais simples de medir a inteligência animal.  Se a inteligência fosse unidimensional, seria fácil construirmos na ordem ascendente correta os intelectos de um papagaio, golfinho, cavalo, esquilo, polvo, baleia azul, gato e gorila.  Hoje, porém, não temos evidências científicas para a existência dessa linha.  Uma das razões para isso pode ser a ausência de uma diferença entre as inteligências nos animais, mas também não vemos isso.  A Zoologia está cheia de exemplos surpreendentes de diferenças no pensamento animal.  Mas talvez todos eles tenham uma "inteligência geral" relativa?  Talvez, mas para ele não temos como medir e métricas.  Temos muitas métricas diferentes para muitos tipos de cognição. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/5ff/9f5/eb6/5ff9f5eb643fccb4b764519d6a804739.png" alt="imagem"><br><br>  Em vez de uma única linha com decibéis, um modelo de inteligência mais preciso seria um gráfico de seu espaço probabilístico, como, por exemplo, a figura acima representando possíveis formas.  A inteligência é um continuum combinatório.  Muitos nós, cada um dos quais é um continuum, criam estruturas complexas e diversas em dimensões superiores.  Alguns intelectos podem ser muito complexos e ter muitos subnós de pensamento.  Outros podem ser mais simples, mas se estendem ainda mais, assumindo um ângulo no espaço.  Esses complexos, que chamamos de intelectos, podem ser considerados sinfonias que envolvem muitos tipos de instrumentos.  Eles diferem não apenas no volume, mas também no tom, melodia, cor, andamento, etc.  Eles podem ser representados como ecossistemas.  E, nesse sentido, os vários nós-componentes do pensamento dependem um do outro e são criados juntos. <br><br>  Como disse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Marvin Minsky</a> , as mentes humanas são comunidades de mentes.  Trabalhamos em ecossistemas de pensamento.  Temos muitos tipos de pensamento que lidam com muitos tipos de pensamento: dedução, indução, lógica simbólica, inteligência emocional, lógica espacial, memória de curto prazo e memória de longo prazo.  O sistema nervoso do intestino também é um cérebro de um certo tipo com seu próprio modo de pensar.  Pensamos não apenas com um cérebro, pensamos com todo o corpo. <br><br>  Esses conjuntos de pensamento variam de indivíduo para indivíduo e de espécie para espécie.  O esquilo pode se lembrar da localização exata de vários milhares de bolotas durante anos, o que afeta completamente a mente humana.  Portanto, nesse tipo de pensamento, as proteínas são superiores aos humanos.  Essa superpotência está conectada com outros modos, desaparecendo em comparação com a nossa, e essa conexão forma a mente do esquilo.  No reino animal, existem muitos outros exemplos de oportunidades superiores às humanas, e eles também estão incluídos em diferentes sistemas. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2ba/9d4/63b/2ba9d463b13bdcb6d36b7c749a90a1af.jpg" alt="imagem"><br><br>  O mesmo vale para a IA.  Mentes artificiais já são superiores aos seres humanos em certas dimensões.  Sua calculadora é um gênio da matemática. A memória do Google já é superior à nossa em uma determinada dimensão.  Criamos IA que se destacam em certos modos.  Somos capazes de fazer algumas dessas coisas nós mesmos, mas eles fazem melhor - por exemplo, nos campos de probabilidade ou matemática.  Outros modos de pensar não estão disponíveis para nós - apenas um mecanismo de pesquisa pode lembrar cada palavra em seis bilhões de páginas da web.  No futuro, apresentaremos completamente novos tipos de pensamento que não temos e, de fato, na natureza viva.  Inventando o vôo artificial, fomos inspirados pelos regimes biológicos de vôo, principalmente o bater de asas.  Mas inventamos esses voos - com hélices e asas fixas - que eram desconhecidos pelo mundo biológico.  Este é o voo de outra pessoa.  Do mesmo modo, apresentaremos novos modos de pensar que não existem na natureza.  Em muitos casos, serão novos modos específicos, pequenos, projetados para um trabalho específico - talvez um tipo de raciocínio adequado apenas para estatística e teoria das probabilidades. <br><br>  Em outros casos, a nova mente será um conjunto complexo de tipos de pensamento que podemos usar para resolver problemas que não são passíveis de nossa inteligência.  Muitos dos problemas mais complexos dos negócios e da ciência podem exigir uma solução em dois estágios.  Etapa um: invente um novo modo de pensar que possa funcionar com nossas mentes.  Segundo: combine-os para resolver o problema.  Como resolvemos problemas que antes eram inacessíveis para nós, queremos chamar esse novo tipo de pensamento de "mais inteligente" do que nós, mas, na realidade, é simplesmente diferente de nós.  A principal vantagem da IA ​​é um pensamento diferente.  Eu acho que é útil pensar na IA como pensamento alienígena (ou alienígena artificial).  Sua incomum será sua principal virtude. <br><br>  Ao mesmo tempo, integraremos esses diferentes modos de pensar em comunidades mais complexas da mente.  Alguns desses complexos serão mais complexos que os nossos, porque podem resolver problemas inacessíveis para nós e, então, alguém quer chamá-los de super-humanos.  Mas não chamamos o Google SII, embora sua memória ultrapasse a nossa, porque há muitas coisas que podemos fazer melhor que ele.  Esses complexos de IA serão capazes de nos ultrapassar em muitas dimensões, mas ninguém pode fazer tudo o que fazemos melhor do que nós.  Isso pode ser comparado com as habilidades físicas das pessoas.  A Revolução Industrial já tem 200 anos e, embora em geral as máquinas superem as capacidades físicas de uma pessoa (velocidade de movimento, levantamento de peso, corte preciso etc.), não existe uma máquina capaz de superar a pessoa média em tudo o que faz. <br><br>  E enquanto a comunidade de mentes da IA ​​está se tornando mais complexa, ainda é difícil medir cientificamente essa complexidade.  Não temos boas métricas de complexidade que possam determinar se o pepino de um Boeing 747 é mais difícil ou descrever como suas dificuldades diferem.  Essa é uma das razões pelas quais não temos boas métricas para a mente.  Será muito difícil determinar se a mente A é mais difícil do que a mente B e, portanto, é difícil entender qual deles é mais inteligente.  Em breve chegaremos a entender que a mente não é unidimensional e, de fato, estamos interessados ​​em todas as muitas maneiras pelas quais o intelecto é capaz de funcionar - todos esses nós de conhecimento que ainda não descobrimos. <br><br><h2>  2) </h2><br>  O segundo erro relacionado à inteligência humana é nossa crença de que nossa mente é universal, é uma mente de propósito geral.  Essa crença levou ao surgimento do objetivo frequentemente declarado dos pesquisadores de IA de criar uma IA generalizada, OII.  No entanto, se considerarmos a inteligência como um espaço maior de possibilidades, ela não possui um estado generalizado.  A inteligência humana não está em uma posição central em torno da qual outros intelectos especializados giram.  A inteligência humana é um tipo muito, muito especial de inteligência que surgiu como resultado de milhões de anos de evolução, para que nossa espécie sobreviva neste planeta.  Se você colocá-lo no espaço de todas as inteligências possíveis, ele estará em algum lugar no canto, assim como o nosso mundo está à beira de uma enorme galáxia. <br><br>  Definitivamente, podemos imaginar e até inventar um pensamento que se assemelha a uma faca suíça universal.  Ele faz um bom trabalho com várias tarefas, mas não se sai muito bem com nenhuma delas.  A IA seguirá a mesma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">máxima de</a> engenharia que todas as coisas criadas ou nascidas seguem: você não pode otimizar todas as dimensões.  Somente compromissos são possíveis.  Não funcionará para criar uma unidade multifuncional generalizada superior às especializadas.  Uma mente grande, “capaz de qualquer coisa”, não será capaz de fazer tudo isso, assim como as especializadas.  Como acreditamos na generalização de nossa mente, acreditamos que o pensamento não precisa seguir compromissos de engenharia, que será possível criar uma inteligência que maximize todos os modos de pensar.  Mas não há evidências disso.  Ainda não inventamos opções suficientes para a mente ver todo o espaço (e até agora estamos varrendo a mente dos animais, avaliando-os com uma amplitude unidimensional). <br><br><h2>  3) </h2><br>  Parte dessa crença vem do conceito de computação universal.  Essa suposição, formalmente descrita em 1950 como a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tese de Church-Turing</a> , afirma que todos os cálculos que atingem um certo limiar são equivalentes.  Portanto, para todos os cálculos, existe um núcleo universal, e se eles ocorrem em uma máquina com muitas partes rápidas, ou lentas, ou no cérebro biológico - tudo isso é o mesmo processo lógico.  E isso significa que é possível emular qualquer processo de computação (pensamento) em qualquer máquina capaz de computação "universal".  Os adeptos da singularidade baseiam-se nesse princípio, esperando que possamos criar cérebros de silício que possam acomodar a mente humana e que possamos criar uma mente artificial que pense que os humanos são muito mais inteligentes.  Essa esperança deve ser cética, porque se baseia em um mal-entendido da hipótese de Church-Turing. <br><br>  O ponto de partida dessa hipótese é o seguinte: "Se houver um filme infinito (memória) e tempo, todos os cálculos serão equivalentes".  O problema é que, na realidade, o computador não possui memória e tempo infinitos.  No mundo real, o tempo real é crítico, muitas vezes até uma questão de vida ou morte.  Sim, todo pensamento pode ser equivalente se o tempo for ignorado.  Sim, você pode emular o pensamento humano em qualquer matriz, desde que ignore o tempo ou as limitações reais do armazenamento de dados e memória.  No entanto, ao incluir o tempo, será possível redefinir substancialmente esse princípio: "Dois sistemas de computação rodando em plataformas muito diferentes não serão equivalentes no tempo".  Ou: "A única maneira de obter padrões de pensamento semelhantes é executá-los em plataformas equivalentes".  A questão física sobre a qual os cálculos funcionam - especialmente quando eles se tornam mais complexos - afeta drasticamente o tipo de pensamento que pode funcionar com sucesso em tempo real. <br><br>  Continuarei com esses argumentos e direi que a única maneira de aproximar um processo de pensamento humano é fazer cálculos em tecidos moles e úmidos semelhantes aos humanos.  Isso significa que as IAs muito grandes e complexas que operam com silício seco nos proporcionarão tipos de pensamento grandes, complexos e desumanos.  Se for possível criar um cérebro artificial molhado usando neurônios desenvolvidos semelhantes aos humanos, então eu diria que seus pensamentos serão muito semelhantes aos nossos.  Os benefícios de um cérebro tão úmido são proporcionais à forma como podemos criar a base.  O custo de criar um “computador humano” é enorme e, quanto mais próximo o tecido estiver do tecido cerebral, mais econômico será simplesmente criar uma pessoa.  No final, podemos fazer isso em nove meses. <br><br>  Além disso, como indicado acima, pensamos com a ajuda de todo o corpo, e não apenas com apenas um cérebro.  Temos muitos dados mostrando que o sistema nervoso intestinal guia nosso processo "racional" de tomada de decisão, que é capaz de aprender e prever eventos.  Quanto mais modelamos o sistema do corpo humano, mais chegamos à sua reprodução.  A inteligência que trabalha em um corpo muito diferente (silício seco em vez de carbono úmido) pensará de maneira diferente. <br><br>  Parece-me que isso não é um bug, mas um recurso.  Como mencionei no parágrafo 2, a diferença entre pensamento e humano é a principal vantagem da IA.  Essa é outra razão pela qual é errado dizer que ele é "mais esperto que as pessoas". <br><br><h2>  4) </h2><br>  No centro do conceito de inteligência sobre-humana - em particular, a idéia de que essa inteligência irá melhorar constantemente - está a crença de que a escala da inteligência é infinita.  Não vejo evidência disso.  Acreditar nisso ajuda a idéia errônea da unidimensionalidade da inteligência - mas isso é apenas fé.  No universo, não há conhecimento confiável para a ciência de dimensões físicas sem fim.  A temperatura não é infinita - há frio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">final</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">calor final</a> .  Tempo e espaço são finitos.  A velocidade final.  Talvez a linha numérica na matemática seja infinita, mas os atributos físicos têm limitações.  Seria razoável dizer que a própria mente é finita.  Então a pergunta é: onde está o limite da inteligência?  Tendemos a acreditar que está muito além do nosso alcance, é muito "mais alto" que nós, tanto quanto somos "mais altos" que a formiga.  Se deixarmos o problema que surge constantemente da unidimensionalidade, que evidência temos de que não atingimos esse limite?  Por que não podemos estar no máximo?<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ou talvez esse limite esteja muito próximo de nós? Por que acreditamos que a inteligência é algo que pode se expandir para sempre? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">É muito melhor abordar esse problema, considerando nossa inteligência como um dos </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">muitos tipos possíveis de inteligência</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . E mesmo que todas as dimensões do pensamento e da computação tenham uma limitação, com a existência de centenas de dimensões, pode haver inúmeras mentes - nenhuma das quais será infinita em nenhuma das dimensões. Quando encontramos ou criamos essas variantes de mentes, podemos decidir que algumas delas são superiores às nossas. No meu último livro, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">The Inevitable,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> descrevi alguns tipos de mentes que podem ser um pouco superiores às nossas. Aqui está uma lista parcial:</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente que é semelhante à humana, mas funciona mais rápido (esse tipo de IA é mais fácil de imaginar). </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente muito lenta, caracterizada por grandes quantidades de armazenamento de informações. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Um super cérebro global composto por milhões de mentes primitivas que trabalham coerentemente. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• A supermente da colméia, consistindo de muitas mentes inteligentes que não estão cientes de que pertencem à colméia. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• A mente cibernética, composta por mentes inteligentes, conscientes de que pertencem à mente coletiva. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente projetada especificamente para melhorar o trabalho de sua própria mente e é inútil para qualquer outra pessoa. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente capaz de imaginar uma mente mais perfeita, mas incapaz de produzi-la.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente capaz de produzir uma mente perfeita, mas não suficientemente consciente para representá-la. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente que pode uma vez criar com sucesso uma mente melhor. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente capaz de criar com sucesso uma mente mais perfeita, que por sua vez é capaz de criar uma mente ainda mais perfeita, etc. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente com acesso ao seu código-fonte e capaz de influenciar seu trabalho. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente super lógica sem emoções. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente capaz de resolver problemas comuns, mas não autoconsciente. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente autoconsciente, incapaz de resolver problemas comuns. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente, cujo desenvolvimento requer muito tempo e protege sua mente.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente extremamente lenta, distribuída em um grande volume físico e, portanto, é invisível para mentes mais rápidas. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente capaz de auto-clonagem rápida e precisa. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente capaz de auto-clonar, após a qual pode permanecer combinada com seus clones. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente imortal, capaz de migrar entre plataformas. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente rápida e dinâmica, capaz de alterar o processo e as características de seu trabalho. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Nanointeligência, a menor possível do ponto de vista energético e físico. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente especializada em previsões do desenvolvimento de eventos. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Uma mente que nunca apaga ou esquece nada. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente simbiótica em meio animal e meio animal.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Inteligência cibernética em uma meia máquina semi-humana. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">• Mente usando a computação quântica, com lógica inacessível para nós. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alguns estão prontos para chamar qualquer mente desta lista de SII, mas a própria diversidade e estranheza de tais mentes nos força a desenvolver novos termos e conceitos sobre inteligência e mente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Então, os que acreditam no SRI sugerem um crescimento exponencial da inteligência (por alguma vaga medida), talvez porque acreditem que ele já esteja se desenvolvendo exponencialmente. No entanto, não há evidências até o momento de que a inteligência se desenvolva exponencialmente, não importa como você a mensure. Por crescimento exponencial, entendo o crescimento em que a IA dobra seu poder em intervalos regulares.</font></font> Onde está a evidência?<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Não consigo encontrá-los. Se não são hoje, por que geralmente é aceito que eles apareçam? Exponencialmente, até agora apenas a quantidade de dados de entrada para IA, bem como os recursos dedicados à produção dos intelectos mais inteligentes, está crescendo. Mas os resultados de seu trabalho não crescem de acordo com a lei de Moore. As IAs não ficam duas vezes mais inteligentes a cada três anos ou a cada 10 anos. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pedi a muitos especialistas em IA que forneçam evidências de um aumento exponencial dos recursos de IA, mas todos concordaram que não temos uma métrica para a IA, e geralmente não funciona assim. Quando perguntei a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ray Kurzweil</font></font></a> ,   ,       ,   ,      ,    .  : «       ,      …        ,         ,            .           ,      2029    ». <br><br>   ,   ,      ,      ,           .       .      ,       . <br><br> ,   « »,        ,      . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> ,    .   ,  ,   ,  .   ,    «» . <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/3ac/61d/4aa/3ac61d4aadb2feb04c55657530506604.jpg" alt="imagem"><br><br><h2> 5. </h2><br>  Outra, não refutada por ninguém, a crença no advento do FIS, não apoiada em evidências, é que uma superinteligência de poder quase infinito resolverá rapidamente todos os nossos principais problemas não resolvidos. <br><br>  Muitos defensores da explosão da inteligência acreditam que isso levará a uma explosão de progresso.  Eu chamo essa fé mítica de "thinkism".  Este é um equívoco de que estágios futuros de progresso são inatingíveis apenas por falta de poder mental ou inteligência.  Observo que a crença de que o pensamento é uma panacéia mágica para tudo é comum entre muitas pessoas que gostam de pensar. <br><br>  Tome cura do câncer ou extensão da vida.  Você não pode resolver esses problemas com um pensamento.  Nenhum pensamento é suficiente para entender como as células envelhecem ou como os telômeros desaparecem.  Nenhum intelecto super-duper pode entender como o corpo humano funciona simplesmente lendo toda a literatura científica conhecida no mundo e refletindo sobre isso.  Nenhum FIC pode, simplesmente pensando em todos os experimentos com fusão nuclear, produzir um esquema de fusão nuclear em funcionamento.  Para superar o caminho de não saber como algo funciona até entender como algo funciona, é preciso muito mais do que apenas pensar.  No mundo real, montes de experimentos estão sendo feitos, cada um dos quais leva ao aparecimento de montanhas de dados conflitantes que exigem experimentos adicionais para criar uma hipótese de trabalho.  Pensar em dados em potencial não fornecerá os dados corretos. <br><br>  Pensar é apenas uma parte da ciência, talvez até uma pequena parte dela.  Por exemplo, não temos dados suficientes para nos aproximarmos da solução do problema da morte.  Ao trabalhar com organismos vivos, quase todos os experimentos levam tempo.  O metabolismo lento das células não pode ser disperso.  Obter resultados leva anos, meses, pelo menos dias.  Se queremos saber o que acontece com as partículas subatômicas, não podemos apenas pensar nelas.  Precisamos construir estruturas físicas enormes, complexas e astutas para descobrir.  Mesmo se os físicos mais inteligentes fossem 1000 vezes mais inteligentes do que agora, sem um colisor, eles não teriam aprendido nada de novo. <br><br>  Não há dúvida de que o SRI pode acelerar o progresso da ciência.  Podemos fazer simulações de átomos ou células por computador e acelerá-las muitas vezes, mas dois problemas limitam a utilidade das simulações.  A primeira é que simulações e modelos podem ir mais rápido do que os processos em estudo apenas porque não levamos em conta alguma coisa.  Essa é a essência de um modelo ou simulação.  Além disso, testar, verificar e provar esses modelos também consome tempo e precisa seguir a velocidade dos processos simulados.  A verificação da verdade não pode ser acelerada. <br><br>  Essas versões simplificadas são úteis para filtrar os caminhos mais promissores e acelerar o progresso.  Mas, na realidade, não há excesso;  tudo o que é real exerce sua influência até certo ponto;  essa é uma das definições da realidade.  Se você começar a bombear modelos e simulações com mais e mais dados, logo fica claro que a realidade é mais rápida que sua simulação de 100%.  Essa é outra definição de realidade: a versão mais rápida possível de todos os detalhes e graus de liberdade presentes.  Se você pode modelar todas as moléculas em células e todas as células do corpo humano, a simulação não funcionará tão rápido quanto o corpo humano.  Não importa o quanto você pense sobre isso, você precisará de tempo para experimentação, seja um sistema real ou uma simulação. <br><br>  Para ser útil, a IA precisa se infiltrar no mundo real, e o mundo definirá a velocidade de sua inovação.  Sem conduzir experimentos, construir protótipos, erros e experimentos com a realidade, a inteligência pode pensar, mas não produzir resultados.  Nenhuma descoberta instantânea por minuto, hora, dia ou ano de ocorrência dos chamados.  "AI sobre-humana" não é esperado.  É claro que os sucessos no desenvolvimento da IA ​​aumentarão significativamente o número de descobertas por unidade de tempo, em particular porque a AI, ao contrário das pessoas, fará perguntas que as pessoas não perguntariam, mas mesmo um intelecto extremamente poderoso não garante progresso instantâneo em comparação a nós.  Para resolver problemas, é necessário muito mais do que apenas inteligência. <br><br>  Somente a inteligência não será capaz de resolver não apenas os problemas do câncer e da longevidade, mas também os problemas do próprio intelecto.  Um mantra típico dos defensores da singularidade é que, assim que você cria uma IA "mais inteligente que uma pessoa", ele de repente pensa e inventa uma IA "mais inteligente que ele", que, por sua vez, pensa ainda mais apropriadamente e inventa ainda mais IA inteligente e, como resultado, tudo terminará com uma explosão de poder intelectual em um nível quase divino.  Não temos evidências de que apenas pensar em inteligência seja suficiente para criar novos níveis de inteligência.  Tal pensamento é fé.  Temos muitas evidências de que, além de uma grande quantidade de conhecimento, precisamos de experimentos, dados, tentativas e erros, perguntas incomuns e tudo mais além da simples engenhosidade para inventar novos tipos de mentes operacionais bem-sucedidas. <br><br>  Em conclusão, direi que posso estar enganado com minhas declarações.  Estamos nos estágios iniciais.  Podemos descobrir uma métrica universal para inteligência;  descubra seu infinito em todas as direções.  Como sabemos muito pouco sobre o que é inteligência (sem mencionar a consciência), a probabilidade de algum tipo de singularidade da IA ​​excede zero.  Parece-me que toda a evidência fala a favor da baixa probabilidade de tal cenário, mas essa probabilidade é diferente de zero. <br><br>  Portanto, embora eu discorde de sua probabilidade, concordo com os objetivos mais amplos da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenAI</a> e das pessoas inteligentes preocupadas com o IDE - que devemos criar IAs amigáveis ​​e pensar em como incutir neles valores que correspondem aos nossos.  E embora eu pense que o IDE seja uma ameaça existencial muito distante (que vale a pena considerar), acho que sua pequena probabilidade (baseada nas evidências disponíveis) não deve governar nossa ciência, política e desenvolvimento.  A colisão de um asteróide com a Terra seria um desastre.  Sua probabilidade é maior que zero (portanto, devemos apoiar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o fundo B612</a> ), mas não devemos dar a possibilidade de um ataque de asteróide para gerenciar nossas decisões, por exemplo, no campo das mudanças climáticas, viagens espaciais ou mesmo no planejamento urbano. <br><br>  Da mesma forma, as evidências até agora sugerem que a IA provavelmente não será sobre-humana, mas extra-humana, serão centenas de novos tipos de pensamento diferentes dos humanos, nenhum dos quais se tornará AI de uso geral, e nenhum deles se tornará um deus, resolvendo instantaneamente todos os nossos problemas.  Em vez disso, teremos uma galáxia de inteligências limitadas, trabalhando em dimensões desconhecidas, indo além de nossas capacidades em muitas delas, trabalhando conosco para resolver problemas existentes e criar novos ao longo do tempo. <br><br>  Eu entendo o charme e a atratividade do deus SII.  Isso é algo como Superman.  Mas, como Superman, esta é uma figura mítica.  Em algum lugar do universo, o Super-Homem pode existir, mas a probabilidade de sua existência é extremamente pequena.  Mas os mitos podem ser úteis, e não desaparecem após sua invenção.  A idéia do Superman não vai morrer.  A idéia de uma singularidade AI sobre-humana, uma vez gerada, também não morrerá.  Mas devemos entender que agora é uma ideia religiosa, não científica.  Se estudarmos os dados que temos hoje sobre inteligência, artificial e natural, podemos concluir que nossas discussões sobre o mítico deus SII são apenas mitos. <br><br>  Muitas das ilhas isoladas da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Micronésia</a> entraram em contato com o resto do mundo pela primeira vez durante a Segunda Guerra Mundial.  Os deuses alienígenas voaram em seus céus em pássaros barulhentos, jogaram comida e mercadorias em suas ilhas e não voltaram.  Cultos religiosos apareceram nas ilhas, rezando para que os deuses voltassem e jogassem mais mercadorias.  Mesmo agora, cinquenta anos depois, muitos ainda aguardam a devolução das mercadorias.  É possível que o SRI seja outro culto à carga.  Depois de cem anos, as pessoas poderão olhar para trás, em nosso tempo, no momento em que os crentes começaram a esperar pelo surgimento da FIC, o que lhes traria benefícios inimagináveis.  Década após década, aguardam a chegada do IDE, confiantes de que, com seus benefícios, deverá aparecer muito em breve. <br><br>  Mas a IA não-sobre-humana já é real aqui.  Redefinimos constantemente esse termo, aumentamos sua complexidade e, como resultado, o mantemos no futuro, mas no sentido amplo da definição de intelectos alienígenas - em um espectro contínuo de diferentes mentes, intelectos, pensamentos, lógicas, ensinamentos e consciências - a IA já existe no planeta e continua espalhar, aprofundar, diversificar e intensificar.  Nenhuma invenção anterior pode se comparar com seu poder sobre o mundo, e até o final do século a IA tocará e mudará todos os aspectos de nossas vidas.  Mas o mito da inteligência artificial sobre-humana, pronto para nos dar abundância ou nos levar à super-escravidão (ou ambas ao mesmo tempo), aparentemente, continuará a viver - essa oportunidade é mítica demais para rejeitá-la. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt403999/">https://habr.com/ru/post/pt403999/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt403989/index.html">Caminho da robótica de campo ao criador de cyborg</a></li>
<li><a href="../pt403991/index.html">Eritritol - um açúcar sem carboidratos para diabéticos que não afeta o índice glicêmico</a></li>
<li><a href="../pt403993/index.html">Pergunte a Ethan: Por que os raios do sol se parecem com os raios do sol?</a></li>
<li><a href="../pt403995/index.html">Aqui está, o nosso verão: gadgets para as férias</a></li>
<li><a href="../pt403997/index.html">Conjunto jovem biohacker</a></li>
<li><a href="../pt404003/index.html">Química do mundo dos computadores</a></li>
<li><a href="../pt404005/index.html">Carretel pequeno, sim querido: fones de ouvido intra-auriculares Fostex</a></li>
<li><a href="../pt404007/index.html">GPD Win - explorando um notebook em miniatura com uma diagonal de 5,5 ", projetado para jogos e emuladores</a></li>
<li><a href="../pt404009/index.html">Nós controlamos a casa através do Telegram</a></li>
<li><a href="../pt404011/index.html">Economia de sangue: um novo sistema de entrega de biomateriais de laboratório foi desenvolvido</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>   Entrenamiento de refuerzo PyBullet  カ 娥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Muchas personas que estudian el aprendizaje autom谩tico est谩n familiarizadas con el proyecto OpenAI, uno de los fundadores del cual es Elon Musk, y uti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Entrenamiento de refuerzo PyBullet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420897/"><img src="https://habrastorage.org/webt/0g/x5/ai/0gx5aizowrlyrgkvekcxlxh9pge.png" alt="imagen"><br><br>  Muchas personas que estudian el aprendizaje autom谩tico est谩n familiarizadas con el proyecto OpenAI, uno de los fundadores del cual es Elon Musk, y utilizan la plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenAI Gym</a> para entrenar sus modelos de redes neuronales. <br><br>  El gimnasio contiene un gran conjunto de entornos, algunos de ellos son varios tipos de simulaciones f铆sicas: los movimientos de animales, humanos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">robots</a> .  Estas simulaciones se basan en el motor de f铆sica <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MuJoCo</a> , que es gratuito con fines educativos y cient铆ficos. <br><br>  En este art铆culo, crearemos una simulaci贸n f铆sica extremadamente simple similar al entorno OpenAI Gym, pero basada en el motor de f铆sica gratuito Bullet ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PyBullet</a> ).  Y tambi茅n cree un agente para trabajar con este entorno. <br><a name="habracut"></a><br>  PyBullet es un m贸dulo de Python para crear un entorno de simulaci贸n f铆sica basado en el motor de f铆sica <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bullet Physics</a> .  Al igual que MuJoCo, a menudo se usa como estimulaci贸n de varios robots, que est谩n interesados en tener <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art铆culo</a> con ejemplos reales. <br><br>  Hay una Gu铆a de inicio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">r谩pido</a> bastante buena para PyBullet que contiene enlaces a ejemplos en la p谩gina de origen en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GitHub</a> . <br><br>  PyBullet le permite cargar modelos ya creados en formato URDF, SDF o MJCF.  En las fuentes hay una biblioteca de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelos</a> en estos formatos, as铆 como entornos completamente simulados de simuladores de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">robots reales.</a> <br><br>  En nuestro caso, nosotros mismos crearemos el entorno usando PyBullet.  La interfaz del entorno ser谩 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">similar a</a> la interfaz de OpenAI Gym.  De esta manera podemos capacitar a nuestros agentes tanto en nuestro entorno como en el entorno del gimnasio. <br><br>  Todo el c贸digo (iPython), as铆 como el funcionamiento del programa, se pueden ver en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Google Colaboratory</a> . <br><br><h2>  Medio ambiente </h2><br>  Nuestro entorno consistir谩 en una pelota que puede moverse a lo largo del eje vertical dentro de un cierto rango de alturas.  La pelota tiene masa y la gravedad act煤a sobre ella, y el agente debe, controlando la fuerza vertical aplicada a la pelota, llevarla al objetivo.  La altitud objetivo cambia con cada reinicio de la experiencia. <br><br><img src="https://habrastorage.org/webt/w-/wy/jr/w-wyjrj1zphr8aqndhutrnno1po.png" alt="imagen"><br><br>  La simulaci贸n es muy simple y, de hecho, puede considerarse como una simulaci贸n de alg煤n motor elemental. <br><br>  Para trabajar con el entorno, se utilizan 3 m茅todos: <i><b>restablecer</b></i> (reiniciar el experimento y crear todos los objetos del entorno), <i><b>paso</b></i> (aplicar la acci贸n seleccionada y obtener el estado resultante del entorno), <i><b>renderizar</b></i> (visualizaci贸n visual del entorno). <br><br>  Al inicializar el entorno, es necesario conectar nuestro objeto a la simulaci贸n f铆sica.  Hay 2 opciones de conexi贸n: con una interfaz gr谩fica (GUI) y sin (DIRECTA). En nuestro caso, es DIRECTA. <br><br><pre><code class="python hljs">pb.connect(pb.DIRECT)</code> </pre> <br><h4>  restablecer </h4><br>  Con cada nuevo experimento, restablecemos la simulaci贸n <i>pb.resetSimulation ()</i> y creamos todos los objetos del entorno nuevamente. <br><br>  En PyBullet, los objetos tienen 2 formas: una <i>forma de</i> colisi贸n y una <i>forma visual</i> .  El primero lo utiliza el motor f铆sico para calcular colisiones de objetos y, para acelerar el c谩lculo de la f铆sica, generalmente tiene una forma m谩s simple que un objeto real.  El segundo es opcional y se usa solo cuando se forma la imagen del objeto. <br><br>  Los formularios se recopilan en un solo objeto (cuerpo): <i>MultiBody</i> .  Un cuerpo puede estar formado por una forma (par <i>CollisionShape / Visual Shape</i> ), como en nuestro caso, o varias. <br><br>  Adem谩s de las formas que componen el cuerpo, es necesario determinar su masa, posici贸n y orientaci贸n en el espacio. <br><br><div class="spoiler">  <b class="spoiler_title">Algunas palabras sobre cuerpos de m煤ltiples objetos.</b> <div class="spoiler_text">  Como regla, en casos reales, para simular varios mecanismos, se utilizan cuerpos que consisten en muchas formas.  Al crear el cuerpo, adem谩s de la forma b谩sica de colisiones y visualizaci贸n, se transfieren al cuerpo cadenas de formas de objetos secundarios ( <i>Enlaces</i> ), su posici贸n y orientaci贸n con respecto al objeto anterior, as铆 como los tipos de conexiones (articulaciones) de los objetos entre s铆 ( <i>Junta</i> ).  Los tipos de conexiones pueden ser fijas, prism谩ticas (desliz谩ndose en el mismo eje) o rotacionales (girando en un eje).  Los 煤ltimos 2 tipos de conexiones le permiten configurar los par谩metros de los tipos de motores correspondientes ( <i>JointMotor</i> ), como la fuerza de actuaci贸n, la velocidad o el par, simulando as铆 los motores de las "articulaciones" del robot.  M谩s detalles en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci贸n</a> . <br></div></div><br>  Crearemos 3 cuerpos: Ball, Plane (Earth) y Target Pointer.  El 煤ltimo objeto tendr谩 solo una forma de visualizaci贸n y masa cero, por lo tanto, no participar谩 en la interacci贸n f铆sica entre los cuerpos: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  floorColShape = pb.createCollisionShape(pb.GEOM_PLANE) #   (GEOM_PLANE), visualShape -    ,   GEOM_BOX floorVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[100,100,0.0001], rgbaColor=[1,1,.98,1]) pb_floorId = pb.createMultiBody(0,floorColShape,floorVisualShapeId, [0,0,0], [0,0,0,1]) #  PB_BallRadius = 0.2 PB_BallMass = 1 ballPosition = [0,0,5] ballOrientation=[0,0,0,1] ballColShape = pb.createCollisionShape(pb.GEOM_SPHERE,radius=PB_BallRadius) ballVisualShapeId = pb.createVisualShape(pb.GEOM_SPHERE,radius=PB_BallRadius, rgbaColor=[1,0.27,0,1]) pb_ballId = pb.createMultiBody(PB_BallMass, ballColShape, ballVisualShapeId, ballPosition, ballOrientation) #   TARGET_Z = 8 targetPosition = [0,0,TARGET_Z] targetOrientation=[0,0,0,1] targetVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[1,0.025,0.025], rgbaColor=[0,0,0,1]) pb_targetId = pb.createMultiBody(0,-1, targetVisualShapeId, targetPosition, targetOrientation)</span></span></code> </pre><br>  Defina la gravedad y el tiempo del paso de simulaci贸n. <br><br><pre> <code class="python hljs">pb.setGravity(<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">-10</span></span>) pb.setTimeStep(<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">60</span></span>)</code> </pre> <br>  Para evitar que la pelota caiga inmediatamente despu茅s de comenzar la simulaci贸n, equilibramos la gravedad. <br><br><pre> <code class="python hljs">pb_force = <span class="hljs-number"><span class="hljs-number">10</span></span> * PB_BallMass pb.applyExternalForce(pb_ballId, <span class="hljs-number"><span class="hljs-number">-1</span></span>, [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,pb_force], [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>], pb.LINK_FRAME)</code> </pre> <br><br><h4>  paso </h4><br>  El agente selecciona acciones basadas en el estado actual del entorno, despu茅s de lo cual llama al m茅todo de <i>pasos</i> y recibe un nuevo estado. <br><br>  Se definen 2 tipos de acci贸n: aumento y disminuci贸n de la fuerza que act煤a sobre la pelota.  Los l铆mites de fuerza son limitados. <br><br>  Despu茅s de cambiar la fuerza que act煤a sobre la pelota, <i>se inicia</i> un nuevo paso de simulaci贸n f铆sica <i>pb.stepSimulation ()</i> , y los siguientes par谩metros se devuelven al agente: <br><br>  <i>observaci贸n</i> - observaciones (estado del medio ambiente) <br>  <i>recompensa</i> - recompensa por la acci贸n perfecta <br>  <i>hecho</i> - la bandera del final de la experiencia <br>  <i>info</i> - informaci贸n adicional <br><br>  Como estado del entorno, se devuelven 3 valores: la distancia al objetivo, la fuerza actual aplicada a la pelota y la velocidad de la pelota.  Los valores se devuelven normalizados (0..1), ya que los par谩metros ambientales que determinan estos valores pueden variar dependiendo de nuestro deseo. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     (     Z curPos[2]) curPos, curOrient = pb.getBasePositionAndOrientation(pb_ballId) #     (      Z lin_vel[2]) lin_vel, ang_vel= pb.getBaseVelocity(self.pb_ballId)</span></span></code> </pre> <br>  La recompensa por la acci贸n perfecta es 1 si la pelota est谩 cerca del objetivo (altura del objetivo m谩s / menos el valor de balanceo aceptable <i>TARGET_DELTA</i> ) y 0 en otros casos. <br>  El experimento se completa si la pelota sale de la zona (cae al suelo o vuela alto).  Si la pelota llega a la meta, el experimento tambi茅n termina, pero solo despu茅s de un cierto tiempo (pasos <i>STEPS_AFTER_TARGET</i> del experimento).  Por lo tanto, nuestro agente est谩 entrenado no solo para avanzar hacia la meta, sino tambi茅n para detenerse y estar cerca de ella.  Dado que la recompensa cuando est谩 cerca de la meta es 1, una experiencia exitosa debe tener una recompensa total igual a <i>STEPS_AFTER_TARGET</i> . <br><br>  Como informaci贸n adicional para mostrar estad铆sticas, se devuelve el n煤mero total de pasos realizados dentro del experimento, as铆 como el n煤mero de pasos realizados por segundo. <br><br><h4>  renderizar </h4><br>  PyBullet tiene 2 opciones de representaci贸n de imagen: representaci贸n de GPU basada en OpenGL y CPU basada en TinyRenderer.  En nuestro caso, solo es posible una implementaci贸n de CPU. <br><br>  Para obtener el marco actual de la simulaci贸n, es necesario determinar la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">matriz de especies</a> y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">matriz de proyecci贸n</a> , y luego obtener la imagen <i>rgb</i> del tama帽o dado de la c谩mara. <br><br><pre> <code class="python hljs">camTargetPos = [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>] <span class="hljs-comment"><span class="hljs-comment">#   ()  camDistance = 10 #     yaw = 0 #     pitch = 0 #     roll=0 #      upAxisIndex = 2 #    (z) fov = 60 #    nearPlane = 0.01 #      farPlane = 20 #      pixelWidth = 320 #   pixelHeight = 200 #   aspect = pixelWidth/pixelHeight; #    #   viewMatrix = pb.computeViewMatrixFromYawPitchRoll(camTargetPos, camDistance, yaw, pitch, roll, upAxisIndex) #   projectionMatrix = pb.computeProjectionMatrixFOV(fov, aspect, nearPlane, farPlane); #     img_arr = pb.getCameraImage(pixelWidth, pixelHeight, viewMatrix, projectionMatrix, shadow=0, lightDirection=[0,1,1],renderer=pb.ER_TINY_RENDERER) w=img_arr[0] #width of the image, in pixels h=img_arr[1] #height of the image, in pixels rgb=img_arr[2] #color data RGB dep=img_arr[3] #depth data</span></span></code> </pre> <br>  Al final de cada experimento, se genera un video basado en las im谩genes recopiladas. <br><br><pre> <code class="python hljs">ani = animation.ArtistAnimation(plt.gcf(), render_imgs, interval=<span class="hljs-number"><span class="hljs-number">10</span></span>, blit=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>,repeat_delay=<span class="hljs-number"><span class="hljs-number">1000</span></span>) display(HTML(ani.to_html5_video()))</code> </pre><br><h2>  Agente </h2><br>  El c贸digo de usuario de GitHub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">jaara</a> se tom贸 como base para el Agente, como un ejemplo simple y comprensible de implementar la capacitaci贸n de refuerzo para el entorno del Gimnasio. <br><br>  El agente contiene 2 objetos: <i>Memoria</i> : un almacenamiento para la formaci贸n de ejemplos de entrenamiento, y <i>Brain es</i> la red neuronal que entrena. <br><br>  La red neuronal entrenada se cre贸 en TensorFlow utilizando la biblioteca Keras, que recientemente se ha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">incluido por</a> completo en TensorFlow. <br>  La red neuronal tiene una estructura simple: 3 capas, es decir.  Solo 1 capa oculta. <br><br>  La primera capa contiene 512 neuronas y tiene un n煤mero de entradas igual al n煤mero de par谩metros del estado del medio (3 par谩metros: distancia al objetivo, fuerza y velocidad de la pelota).  La capa oculta tiene una dimensi贸n igual a la primera capa: 512 neuronas, en la salida est谩 conectada a la capa de salida.  El n煤mero de neuronas de la capa de salida corresponde al n煤mero de acciones realizadas por el Agente (2 acciones: disminuci贸n y aumento de la fuerza de actuaci贸n). <br><br>  Por lo tanto, el estado del sistema se suministra a la entrada de la red, y en la salida tenemos un beneficio para cada una de las acciones. <br><br>  Para las dos primeras capas, <i>ReLU</i> (unidad lineal rectificada) se utiliza como funciones de activaci贸n, para la 煤ltima, una <i>funci贸n lineal</i> (la suma de los valores de entrada es simple). <br>  En funci贸n del error, <i>MSE</i> (error est谩ndar), como algoritmo de optimizaci贸n: <i>RMSprop</i> (Propagaci贸n cuadr谩tica media cuadr谩tica). <br><br><pre> <code class="python hljs">model = Sequential() model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_dim=<span class="hljs-number"><span class="hljs-number">3</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)) opt = RMSprop(lr=<span class="hljs-number"><span class="hljs-number">0.00025</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mse'</span></span>, optimizer=opt)</code> </pre><br>  Despu茅s de cada paso de simulaci贸n, el Agente guarda los resultados de este paso en forma de una lista <i>(s, a, r, s_)</i> : <br>  <i>s</i> - observaci贸n previa (estado del medio ambiente) <br>  <i>a</i> - acci贸n completada <br>  <i>r</i> : recompensa recibida por la acci贸n realizada <br>  <i>s_</i> - observaci贸n final despu茅s de la acci贸n <br><br>  Despu茅s de eso, el Agente recibe de la memoria un conjunto aleatorio de ejemplos para per铆odos anteriores y forma un paquete de capacitaci贸n ( <i>lote</i> ). <br><br>  Los estados iniciales de los pasos aleatorios seleccionados de la memoria se toman como valores de entrada ( <i>X</i> ) del paquete. <br><br>  Los valores reales de la salida de aprendizaje ( <i>Y '</i> ) se calculan de la siguiente manera: en la salida ( <i>Y</i> ) de la red neuronal para s habr谩 valores de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">funci贸n Q</a> para cada una de las acciones <i>Q (s)</i> .  De este conjunto, el agente seleccion贸 la acci贸n con el valor m谩s alto <i>Q (s, a) = MAX (Q (s))</i> , la complet贸 y recibi贸 el premio <i>r</i> .  El nuevo valor de <i>Q</i> para la acci贸n seleccionada <i>a</i> ser谩 <i>Q (s, a) = Q (s, a) + DF * r</i> , donde <i>DF</i> es el factor de descuento.  Los valores de salida restantes seguir谩n siendo los mismos. <br><br><pre> <code class="python hljs">STATE_CNT = <span class="hljs-number"><span class="hljs-number">3</span></span> ACTION_CNT = <span class="hljs-number"><span class="hljs-number">2</span></span> batchLen = <span class="hljs-number"><span class="hljs-number">32</span></span> <span class="hljs-comment"><span class="hljs-comment">#     states = numpy.array([ o[0] for o in batch ]) #     states_ = numpy.array([ o[3] for o in batch ]) #     p = agent.brain.predict(states) #     p_ = agent.brain.predict(states_) #     x = numpy.zeros((batchLen, STATE_CNT)) y = numpy.zeros((batchLen, ACTION_CNT)) #   for i in range(batchLen): o = batch[i] s = o[0]; a = o[1]; r = o[2]; s_ = o[3] t = p[i] #      #      ,       t[a] = r + GAMMA * numpy.amax(p_[i]) #            #    batch x[i] = s y[i] = t #      self.brain.train(x, y)</span></span></code> </pre> <br>  El entrenamiento de red se lleva a cabo en el paquete formado <br><br><pre> <code class="python hljs">self.model.fit(x, y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Despu茅s de completar el experimento, se genera un video <br><br><img src="https://habrastorage.org/webt/om/ox/rk/omoxrkmnrigllf9hu_8x9ofbd7m.gif" alt="imagen"><br><br>  y se muestran las estad铆sticas <br><br><img src="https://habrastorage.org/webt/0s/ed/p2/0sedp2zvwqmiiku6emmhp2yxf7m.png" alt="imagen"><br><br>  El agente necesit贸 1.200 ensayos para lograr un resultado del 95 por ciento (n煤mero de pasos exitosos).  Y en el 50潞 experimento, el Agente hab铆a aprendido a mover la pelota hacia el objetivo (los experimentos fallidos desaparecen). <br><br>  Para mejorar los resultados, puede intentar cambiar el tama帽o de las capas de red (LAYER_SIZE), el par谩metro del factor de descuento (GAMMA) o la tasa de disminuci贸n en la probabilidad de elegir una acci贸n aleatoria (LAMBDA). <br><br>  Nuestro agente tiene la arquitectura m谩s simple: DQN (Deep Q-Network).  En una tarea tan simple, es suficiente para obtener un resultado aceptable. <br><br>  El uso, por ejemplo, de la arquitectura DDQN (Double DQN) deber铆a proporcionar una capacitaci贸n m谩s fluida y precisa.  Y la red RDQN (DQN recurrente) podr谩 rastrear los patrones de cambio ambiental a lo largo del tiempo, lo que permitir谩 deshacerse del par谩metro de velocidad de bola, reduciendo el n煤mero de par谩metros de entrada de red. <br><br>  Tambi茅n puede ampliar nuestra simulaci贸n agregando una masa de bola variable o el 谩ngulo de inclinaci贸n de su movimiento. <br><br>  Pero esta es la pr贸xima vez. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es420897/">https://habr.com/ru/post/es420897/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es420887/index.html">Informe de Tele2 Hackathon</a></li>
<li><a href="../es420889/index.html">La tecnolog铆a militar de detecci贸n de minas ayuda a los robomobiles a navegar por todos los caminos</a></li>
<li><a href="../es420891/index.html">Migraci贸n a JUnit 5 en 10 min. Medici贸n del tiempo de prueba con extensiones</a></li>
<li><a href="../es420893/index.html">Franquicias de embalaje A a B</a></li>
<li><a href="../es420895/index.html">C贸mo reanim茅 un dispositivo (JTAG-emulator BH-USB-560v2) a trav茅s de U-Boot</a></li>
<li><a href="../es420901/index.html">C贸mo estudio Spring Framework (la ayuda para principiantes es el trabajo de los principiantes)</a></li>
<li><a href="../es420903/index.html">Implementaci贸n de ERP: c贸mo no fallar</a></li>
<li><a href="../es420905/index.html">C贸mo se introduce la iluminaci贸n inteligente en Rusia y cu谩nto tiempo llevar谩</a></li>
<li><a href="../es420907/index.html">De NOKLA a Xiaomi: la evoluci贸n de los tel茅fonos m贸viles chinos</a></li>
<li><a href="../es420909/index.html">Las compa帽铆as de televisi贸n rusas acusan a Yandex de pirater铆a</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
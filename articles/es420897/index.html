<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèá üåÅ üöï Entrenamiento de refuerzo PyBullet üö® ü•´ üë∂üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Muchas personas que estudian el aprendizaje autom√°tico est√°n familiarizadas con el proyecto OpenAI, uno de los fundadores del cual es Elon Musk, y uti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Entrenamiento de refuerzo PyBullet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420897/"><img src="https://habrastorage.org/webt/0g/x5/ai/0gx5aizowrlyrgkvekcxlxh9pge.png" alt="imagen"><br><br>  Muchas personas que estudian el aprendizaje autom√°tico est√°n familiarizadas con el proyecto OpenAI, uno de los fundadores del cual es Elon Musk, y utilizan la plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenAI Gym</a> para entrenar sus modelos de redes neuronales. <br><br>  El gimnasio contiene un gran conjunto de entornos, algunos de ellos son varios tipos de simulaciones f√≠sicas: los movimientos de animales, humanos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">robots</a> .  Estas simulaciones se basan en el motor de f√≠sica <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MuJoCo</a> , que es gratuito con fines educativos y cient√≠ficos. <br><br>  En este art√≠culo, crearemos una simulaci√≥n f√≠sica extremadamente simple similar al entorno OpenAI Gym, pero basada en el motor de f√≠sica gratuito Bullet ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PyBullet</a> ).  Y tambi√©n cree un agente para trabajar con este entorno. <br><a name="habracut"></a><br>  PyBullet es un m√≥dulo de Python para crear un entorno de simulaci√≥n f√≠sica basado en el motor de f√≠sica <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bullet Physics</a> .  Al igual que MuJoCo, a menudo se usa como estimulaci√≥n de varios robots, que est√°n interesados ‚Äã‚Äãen tener <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo</a> con ejemplos reales. <br><br>  Hay una Gu√≠a de inicio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">r√°pido</a> bastante buena para PyBullet que contiene enlaces a ejemplos en la p√°gina de origen en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GitHub</a> . <br><br>  PyBullet le permite cargar modelos ya creados en formato URDF, SDF o MJCF.  En las fuentes hay una biblioteca de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">modelos</a> en estos formatos, as√≠ como entornos completamente simulados de simuladores de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">robots reales.</a> <br><br>  En nuestro caso, nosotros mismos crearemos el entorno usando PyBullet.  La interfaz del entorno ser√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">similar a</a> la interfaz de OpenAI Gym.  De esta manera podemos capacitar a nuestros agentes tanto en nuestro entorno como en el entorno del gimnasio. <br><br>  Todo el c√≥digo (iPython), as√≠ como el funcionamiento del programa, se pueden ver en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Google Colaboratory</a> . <br><br><h2>  Medio ambiente </h2><br>  Nuestro entorno consistir√° en una pelota que puede moverse a lo largo del eje vertical dentro de un cierto rango de alturas.  La pelota tiene masa y la gravedad act√∫a sobre ella, y el agente debe, controlando la fuerza vertical aplicada a la pelota, llevarla al objetivo.  La altitud objetivo cambia con cada reinicio de la experiencia. <br><br><img src="https://habrastorage.org/webt/w-/wy/jr/w-wyjrj1zphr8aqndhutrnno1po.png" alt="imagen"><br><br>  La simulaci√≥n es muy simple y, de hecho, puede considerarse como una simulaci√≥n de alg√∫n motor elemental. <br><br>  Para trabajar con el entorno, se utilizan 3 m√©todos: <i><b>restablecer</b></i> (reiniciar el experimento y crear todos los objetos del entorno), <i><b>paso</b></i> (aplicar la acci√≥n seleccionada y obtener el estado resultante del entorno), <i><b>renderizar</b></i> (visualizaci√≥n visual del entorno). <br><br>  Al inicializar el entorno, es necesario conectar nuestro objeto a la simulaci√≥n f√≠sica.  Hay 2 opciones de conexi√≥n: con una interfaz gr√°fica (GUI) y sin (DIRECTA). En nuestro caso, es DIRECTA. <br><br><pre><code class="python hljs">pb.connect(pb.DIRECT)</code> </pre> <br><h4>  restablecer </h4><br>  Con cada nuevo experimento, restablecemos la simulaci√≥n <i>pb.resetSimulation ()</i> y creamos todos los objetos del entorno nuevamente. <br><br>  En PyBullet, los objetos tienen 2 formas: una <i>forma de</i> colisi√≥n y una <i>forma visual</i> .  El primero lo utiliza el motor f√≠sico para calcular colisiones de objetos y, para acelerar el c√°lculo de la f√≠sica, generalmente tiene una forma m√°s simple que un objeto real.  El segundo es opcional y se usa solo cuando se forma la imagen del objeto. <br><br>  Los formularios se recopilan en un solo objeto (cuerpo): <i>MultiBody</i> .  Un cuerpo puede estar formado por una forma (par <i>CollisionShape / Visual Shape</i> ), como en nuestro caso, o varias. <br><br>  Adem√°s de las formas que componen el cuerpo, es necesario determinar su masa, posici√≥n y orientaci√≥n en el espacio. <br><br><div class="spoiler">  <b class="spoiler_title">Algunas palabras sobre cuerpos de m√∫ltiples objetos.</b> <div class="spoiler_text">  Como regla, en casos reales, para simular varios mecanismos, se utilizan cuerpos que consisten en muchas formas.  Al crear el cuerpo, adem√°s de la forma b√°sica de colisiones y visualizaci√≥n, se transfieren al cuerpo cadenas de formas de objetos secundarios ( <i>Enlaces</i> ), su posici√≥n y orientaci√≥n con respecto al objeto anterior, as√≠ como los tipos de conexiones (articulaciones) de los objetos entre s√≠ ( <i>Junta</i> ).  Los tipos de conexiones pueden ser fijas, prism√°ticas (desliz√°ndose en el mismo eje) o rotacionales (girando en un eje).  Los √∫ltimos 2 tipos de conexiones le permiten configurar los par√°metros de los tipos de motores correspondientes ( <i>JointMotor</i> ), como la fuerza de actuaci√≥n, la velocidad o el par, simulando as√≠ los motores de las "articulaciones" del robot.  M√°s detalles en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n</a> . <br></div></div><br>  Crearemos 3 cuerpos: Ball, Plane (Earth) y Target Pointer.  El √∫ltimo objeto tendr√° solo una forma de visualizaci√≥n y masa cero, por lo tanto, no participar√° en la interacci√≥n f√≠sica entre los cuerpos: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  floorColShape = pb.createCollisionShape(pb.GEOM_PLANE) #   (GEOM_PLANE), visualShape -    ,   GEOM_BOX floorVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[100,100,0.0001], rgbaColor=[1,1,.98,1]) pb_floorId = pb.createMultiBody(0,floorColShape,floorVisualShapeId, [0,0,0], [0,0,0,1]) #  PB_BallRadius = 0.2 PB_BallMass = 1 ballPosition = [0,0,5] ballOrientation=[0,0,0,1] ballColShape = pb.createCollisionShape(pb.GEOM_SPHERE,radius=PB_BallRadius) ballVisualShapeId = pb.createVisualShape(pb.GEOM_SPHERE,radius=PB_BallRadius, rgbaColor=[1,0.27,0,1]) pb_ballId = pb.createMultiBody(PB_BallMass, ballColShape, ballVisualShapeId, ballPosition, ballOrientation) #   TARGET_Z = 8 targetPosition = [0,0,TARGET_Z] targetOrientation=[0,0,0,1] targetVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[1,0.025,0.025], rgbaColor=[0,0,0,1]) pb_targetId = pb.createMultiBody(0,-1, targetVisualShapeId, targetPosition, targetOrientation)</span></span></code> </pre><br>  Defina la gravedad y el tiempo del paso de simulaci√≥n. <br><br><pre> <code class="python hljs">pb.setGravity(<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">-10</span></span>) pb.setTimeStep(<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">60</span></span>)</code> </pre> <br>  Para evitar que la pelota caiga inmediatamente despu√©s de comenzar la simulaci√≥n, equilibramos la gravedad. <br><br><pre> <code class="python hljs">pb_force = <span class="hljs-number"><span class="hljs-number">10</span></span> * PB_BallMass pb.applyExternalForce(pb_ballId, <span class="hljs-number"><span class="hljs-number">-1</span></span>, [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,pb_force], [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>], pb.LINK_FRAME)</code> </pre> <br><br><h4>  paso </h4><br>  El agente selecciona acciones basadas en el estado actual del entorno, despu√©s de lo cual llama al m√©todo de <i>pasos</i> y recibe un nuevo estado. <br><br>  Se definen 2 tipos de acci√≥n: aumento y disminuci√≥n de la fuerza que act√∫a sobre la pelota.  Los l√≠mites de fuerza son limitados. <br><br>  Despu√©s de cambiar la fuerza que act√∫a sobre la pelota, <i>se inicia</i> un nuevo paso de simulaci√≥n f√≠sica <i>pb.stepSimulation ()</i> , y los siguientes par√°metros se devuelven al agente: <br><br>  <i>observaci√≥n</i> - observaciones (estado del medio ambiente) <br>  <i>recompensa</i> - recompensa por la acci√≥n perfecta <br>  <i>hecho</i> - la bandera del final de la experiencia <br>  <i>info</i> - informaci√≥n adicional <br><br>  Como estado del entorno, se devuelven 3 valores: la distancia al objetivo, la fuerza actual aplicada a la pelota y la velocidad de la pelota.  Los valores se devuelven normalizados (0..1), ya que los par√°metros ambientales que determinan estos valores pueden variar dependiendo de nuestro deseo. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     (     Z curPos[2]) curPos, curOrient = pb.getBasePositionAndOrientation(pb_ballId) #     (      Z lin_vel[2]) lin_vel, ang_vel= pb.getBaseVelocity(self.pb_ballId)</span></span></code> </pre> <br>  La recompensa por la acci√≥n perfecta es 1 si la pelota est√° cerca del objetivo (altura del objetivo m√°s / menos el valor de balanceo aceptable <i>TARGET_DELTA</i> ) y 0 en otros casos. <br>  El experimento se completa si la pelota sale de la zona (cae al suelo o vuela alto).  Si la pelota llega a la meta, el experimento tambi√©n termina, pero solo despu√©s de un cierto tiempo (pasos <i>STEPS_AFTER_TARGET</i> del experimento).  Por lo tanto, nuestro agente est√° entrenado no solo para avanzar hacia la meta, sino tambi√©n para detenerse y estar cerca de ella.  Dado que la recompensa cuando est√° cerca de la meta es 1, una experiencia exitosa debe tener una recompensa total igual a <i>STEPS_AFTER_TARGET</i> . <br><br>  Como informaci√≥n adicional para mostrar estad√≠sticas, se devuelve el n√∫mero total de pasos realizados dentro del experimento, as√≠ como el n√∫mero de pasos realizados por segundo. <br><br><h4>  renderizar </h4><br>  PyBullet tiene 2 opciones de representaci√≥n de imagen: representaci√≥n de GPU basada en OpenGL y CPU basada en TinyRenderer.  En nuestro caso, solo es posible una implementaci√≥n de CPU. <br><br>  Para obtener el marco actual de la simulaci√≥n, es necesario determinar la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">matriz de especies</a> y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">matriz de proyecci√≥n</a> , y luego obtener la imagen <i>rgb</i> del tama√±o dado de la c√°mara. <br><br><pre> <code class="python hljs">camTargetPos = [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>] <span class="hljs-comment"><span class="hljs-comment">#   ()  camDistance = 10 #     yaw = 0 #     pitch = 0 #     roll=0 #      upAxisIndex = 2 #    (z) fov = 60 #    nearPlane = 0.01 #      farPlane = 20 #      pixelWidth = 320 #   pixelHeight = 200 #   aspect = pixelWidth/pixelHeight; #    #   viewMatrix = pb.computeViewMatrixFromYawPitchRoll(camTargetPos, camDistance, yaw, pitch, roll, upAxisIndex) #   projectionMatrix = pb.computeProjectionMatrixFOV(fov, aspect, nearPlane, farPlane); #     img_arr = pb.getCameraImage(pixelWidth, pixelHeight, viewMatrix, projectionMatrix, shadow=0, lightDirection=[0,1,1],renderer=pb.ER_TINY_RENDERER) w=img_arr[0] #width of the image, in pixels h=img_arr[1] #height of the image, in pixels rgb=img_arr[2] #color data RGB dep=img_arr[3] #depth data</span></span></code> </pre> <br>  Al final de cada experimento, se genera un video basado en las im√°genes recopiladas. <br><br><pre> <code class="python hljs">ani = animation.ArtistAnimation(plt.gcf(), render_imgs, interval=<span class="hljs-number"><span class="hljs-number">10</span></span>, blit=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>,repeat_delay=<span class="hljs-number"><span class="hljs-number">1000</span></span>) display(HTML(ani.to_html5_video()))</code> </pre><br><h2>  Agente </h2><br>  El c√≥digo de usuario de GitHub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">jaara</a> se tom√≥ como base para el Agente, como un ejemplo simple y comprensible de implementar la capacitaci√≥n de refuerzo para el entorno del Gimnasio. <br><br>  El agente contiene 2 objetos: <i>Memoria</i> : un almacenamiento para la formaci√≥n de ejemplos de entrenamiento, y <i>Brain es</i> la red neuronal que entrena. <br><br>  La red neuronal entrenada se cre√≥ en TensorFlow utilizando la biblioteca Keras, que recientemente se ha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">incluido por</a> completo en TensorFlow. <br>  La red neuronal tiene una estructura simple: 3 capas, es decir.  Solo 1 capa oculta. <br><br>  La primera capa contiene 512 neuronas y tiene un n√∫mero de entradas igual al n√∫mero de par√°metros del estado del medio (3 par√°metros: distancia al objetivo, fuerza y ‚Äã‚Äãvelocidad de la pelota).  La capa oculta tiene una dimensi√≥n igual a la primera capa: 512 neuronas, en la salida est√° conectada a la capa de salida.  El n√∫mero de neuronas de la capa de salida corresponde al n√∫mero de acciones realizadas por el Agente (2 acciones: disminuci√≥n y aumento de la fuerza de actuaci√≥n). <br><br>  Por lo tanto, el estado del sistema se suministra a la entrada de la red, y en la salida tenemos un beneficio para cada una de las acciones. <br><br>  Para las dos primeras capas, <i>ReLU</i> (unidad lineal rectificada) se utiliza como funciones de activaci√≥n, para la √∫ltima, una <i>funci√≥n lineal</i> (la suma de los valores de entrada es simple). <br>  En funci√≥n del error, <i>MSE</i> (error est√°ndar), como algoritmo de optimizaci√≥n: <i>RMSprop</i> (Propagaci√≥n cuadr√°tica media cuadr√°tica). <br><br><pre> <code class="python hljs">model = Sequential() model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_dim=<span class="hljs-number"><span class="hljs-number">3</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)) opt = RMSprop(lr=<span class="hljs-number"><span class="hljs-number">0.00025</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mse'</span></span>, optimizer=opt)</code> </pre><br>  Despu√©s de cada paso de simulaci√≥n, el Agente guarda los resultados de este paso en forma de una lista <i>(s, a, r, s_)</i> : <br>  <i>s</i> - observaci√≥n previa (estado del medio ambiente) <br>  <i>a</i> - acci√≥n completada <br>  <i>r</i> : recompensa recibida por la acci√≥n realizada <br>  <i>s_</i> - observaci√≥n final despu√©s de la acci√≥n <br><br>  Despu√©s de eso, el Agente recibe de la memoria un conjunto aleatorio de ejemplos para per√≠odos anteriores y forma un paquete de capacitaci√≥n ( <i>lote</i> ). <br><br>  Los estados iniciales de los pasos aleatorios seleccionados de la memoria se toman como valores de entrada ( <i>X</i> ) del paquete. <br><br>  Los valores reales de la salida de aprendizaje ( <i>Y '</i> ) se calculan de la siguiente manera: en la salida ( <i>Y</i> ) de la red neuronal para s habr√° valores de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">funci√≥n Q</a> para cada una de las acciones <i>Q (s)</i> .  De este conjunto, el agente seleccion√≥ la acci√≥n con el valor m√°s alto <i>Q (s, a) = MAX (Q (s))</i> , la complet√≥ y recibi√≥ el premio <i>r</i> .  El nuevo valor de <i>Q</i> para la acci√≥n seleccionada <i>a</i> ser√° <i>Q (s, a) = Q (s, a) + DF * r</i> , donde <i>DF</i> es el factor de descuento.  Los valores de salida restantes seguir√°n siendo los mismos. <br><br><pre> <code class="python hljs">STATE_CNT = <span class="hljs-number"><span class="hljs-number">3</span></span> ACTION_CNT = <span class="hljs-number"><span class="hljs-number">2</span></span> batchLen = <span class="hljs-number"><span class="hljs-number">32</span></span> <span class="hljs-comment"><span class="hljs-comment">#     states = numpy.array([ o[0] for o in batch ]) #     states_ = numpy.array([ o[3] for o in batch ]) #     p = agent.brain.predict(states) #     p_ = agent.brain.predict(states_) #     x = numpy.zeros((batchLen, STATE_CNT)) y = numpy.zeros((batchLen, ACTION_CNT)) #   for i in range(batchLen): o = batch[i] s = o[0]; a = o[1]; r = o[2]; s_ = o[3] t = p[i] #      #      ,       t[a] = r + GAMMA * numpy.amax(p_[i]) #            #    batch x[i] = s y[i] = t #      self.brain.train(x, y)</span></span></code> </pre> <br>  El entrenamiento de red se lleva a cabo en el paquete formado <br><br><pre> <code class="python hljs">self.model.fit(x, y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Despu√©s de completar el experimento, se genera un video <br><br><img src="https://habrastorage.org/webt/om/ox/rk/omoxrkmnrigllf9hu_8x9ofbd7m.gif" alt="imagen"><br><br>  y se muestran las estad√≠sticas <br><br><img src="https://habrastorage.org/webt/0s/ed/p2/0sedp2zvwqmiiku6emmhp2yxf7m.png" alt="imagen"><br><br>  El agente necesit√≥ 1.200 ensayos para lograr un resultado del 95 por ciento (n√∫mero de pasos exitosos).  Y en el 50¬∫ experimento, el Agente hab√≠a aprendido a mover la pelota hacia el objetivo (los experimentos fallidos desaparecen). <br><br>  Para mejorar los resultados, puede intentar cambiar el tama√±o de las capas de red (LAYER_SIZE), el par√°metro del factor de descuento (GAMMA) o la tasa de disminuci√≥n en la probabilidad de elegir una acci√≥n aleatoria (LAMBDA). <br><br>  Nuestro agente tiene la arquitectura m√°s simple: DQN (Deep Q-Network).  En una tarea tan simple, es suficiente para obtener un resultado aceptable. <br><br>  El uso, por ejemplo, de la arquitectura DDQN (Double DQN) deber√≠a proporcionar una capacitaci√≥n m√°s fluida y precisa.  Y la red RDQN (DQN recurrente) podr√° rastrear los patrones de cambio ambiental a lo largo del tiempo, lo que permitir√° deshacerse del par√°metro de velocidad de bola, reduciendo el n√∫mero de par√°metros de entrada de red. <br><br>  Tambi√©n puede ampliar nuestra simulaci√≥n agregando una masa de bola variable o el √°ngulo de inclinaci√≥n de su movimiento. <br><br>  Pero esta es la pr√≥xima vez. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es420897/">https://habr.com/ru/post/es420897/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es420887/index.html">Informe de Tele2 Hackathon</a></li>
<li><a href="../es420889/index.html">La tecnolog√≠a militar de detecci√≥n de minas ayuda a los robomobiles a navegar por todos los caminos</a></li>
<li><a href="../es420891/index.html">Migraci√≥n a JUnit 5 en 10 min. Medici√≥n del tiempo de prueba con extensiones</a></li>
<li><a href="../es420893/index.html">Franquicias de embalaje A a B</a></li>
<li><a href="../es420895/index.html">C√≥mo reanim√© un dispositivo (JTAG-emulator BH-USB-560v2) a trav√©s de U-Boot</a></li>
<li><a href="../es420901/index.html">C√≥mo estudio Spring Framework (la ayuda para principiantes es el trabajo de los principiantes)</a></li>
<li><a href="../es420903/index.html">Implementaci√≥n de ERP: c√≥mo no fallar</a></li>
<li><a href="../es420905/index.html">C√≥mo se introduce la iluminaci√≥n inteligente en Rusia y cu√°nto tiempo llevar√°</a></li>
<li><a href="../es420907/index.html">De NOKLA a Xiaomi: la evoluci√≥n de los tel√©fonos m√≥viles chinos</a></li>
<li><a href="../es420909/index.html">Las compa√±√≠as de televisi√≥n rusas acusan a Yandex de pirater√≠a</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
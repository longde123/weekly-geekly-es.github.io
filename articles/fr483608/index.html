<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔉 🏰 🧑🏾‍🤝‍🧑🏽 Visualisation des limites d'une solution de classificateur basée sur l'image 👩🏼‍🎓 👩🏼‍🎤 🚸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Présentation 


 Comprendre comment le classificateur décompose l'espace multidimensionnel initial d'attributs en plusieurs classes cibles est une éta...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Visualisation des limites d'une solution de classificateur basée sur l'image</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483608/"><h2 id="vvedenie">  Présentation </h2><br><p>  Comprendre comment le classificateur décompose l'espace multidimensionnel initial d'attributs en plusieurs classes cibles est une étape importante pour analyser tout problème de classification et évaluer la solution obtenue à l'aide de l'apprentissage automatique. </p><br><p>  Les approches modernes de visualisation des décisions des classificateurs utilisent principalement des diagrammes de dispersion qui ne peuvent afficher que les projections des échantillons d'apprentissage originaux, mais ne montrent pas explicitement les limites réelles de la prise de décision, ou utilisent la structure interne du classificateur (par exemple, kNN, SVM, régression logistique) pour laquelle il est facile de construire une géométrie interprétation.  Cette méthode ne convient pas pour la visualisation, par exemple, d'un classificateur de réseau neuronal. </p><br><p>  L'article <em>"Visualisation basée sur l'image des limites de décision du classificateur" (Rodrigues et al., 2018)</em> propose une méthode alternative efficace, belle et assez simple pour visualiser les solutions du classificateur, qui est dépourvue des inconvénients ci-dessus.  À savoir, la méthode convient aux classificateurs de toute nature et établit les limites de la prise de décision en utilisant des images avec un taux d'échantillonnage arbitraire. </p><br><p>  <em>Ce message est un bref aperçu des principales idées et résultats de l'article d'origine.</em> </p><a name="habracut"></a><br><h2 id="opisanie-metoda">  Description de la méthode </h2><br><p>  La base de la méthode est l'échantillonnage inverse <em>(eng. Upsampling)</em> du plan de l'image <img src="https://habrastorage.org/getpro/habr/post_images/bbe/6f0/7de/bbe6f07de26be484f6cda1bf892ff41b.svg" alt="\ mathbb {R} ^ 2">  qui est représenté par un ensemble de pixels dans l'espace de fonctionnalité <img src="https://habrastorage.org/getpro/habr/post_images/083/a90/e39/083a90e392615e6ff9271b60c0ffb8db.svg" alt="\ mathbb {R} ^ n">  . </p><br><p>  La méthode nécessite deux mappages <img src="https://habrastorage.org/getpro/habr/post_images/da1/8e5/2bc/da18e52bcc30ce0aa0ecaeee335ae07f.svg" alt="P: \ mathbb {R} ^ n \ to \ mathbb {R} ^ 2">  - projection directe de l'espace caractéristique vers le plan image et l'inverse <img src="https://habrastorage.org/getpro/habr/post_images/5b3/03b/64d/5b303b64d69ea3c32dd0f084fbc68091.svg" alt="P ^ {- 1}: \ mathbb {R} ^ 2 \ à \ mathbb {R} ^ n">  .  En tant que telles cartographies, <em>LAMP (Joia et al. 2011)</em> et <em>iLAMP (Amorim et al. 2012)</em> , respectivement, sont utilisés. </p><br><h4 id="postroenie">  Immeuble </h4><br><p>  Pour créer une image, vous devez attribuer une couleur à chaque pixel.  Pour cela, pour chaque pixel <img src="https://habrastorage.org/getpro/habr/post_images/7ba/469/280/7ba469280dbeae1ae4fcd637e6d8966e.svg" alt="y">  va trouver <img src="https://habrastorage.org/getpro/habr/post_images/bff/605/a65/bff605a65883fb83a49aeb1ef0d21f3f.svg" alt="N \ geq 1">  points de l'hyperespace source où <img src="https://habrastorage.org/getpro/habr/post_images/a1e/39d/a1c/a1e39da1c84981d7264baa207047222a.svg" alt="N">  - un paramètre spécifié par l'utilisateur.  Laissez le pixel <img src="https://habrastorage.org/getpro/habr/post_images/7ba/469/280/7ba469280dbeae1ae4fcd637e6d8966e.svg" alt="y">  a déjà <img src="https://habrastorage.org/getpro/habr/post_images/434/1b0/03f/4341b003f49abd1e3af597087bc9b190.svg" alt="n (y) \ geq 0">  de vrais prototypes de l'ensemble de formation.  Ensuite, choisissez uniformément <img src="https://habrastorage.org/getpro/habr/post_images/b81/cfa/f99/b81cfaf992bc8f0efaa1099e7a7fe993.svg" alt="\ max (N - n (y), 0)">  les points restants de la surface des pixels et trouver le prototype pour eux à travers la projection arrière <img src="https://habrastorage.org/getpro/habr/post_images/94f/124/acc/94f124acc806a90feaf324e0ad8450db.svg" alt="x_i = P ^ {- 1} (y_i)">  .  Ainsi, la couleur de chaque pixel sera déterminée par au moins <img src="https://habrastorage.org/getpro/habr/post_images/a1e/39d/a1c/a1e39da1c84981d7264baa207047222a.svg" alt="N">  points de l'espace source, et l'image entière sera peinte. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/0ad/fdd/96a/0adfdd96afccbad3702cd032a754481f.png" alt="Différence de méthodes" width="400"><br>  [Fig.1] Illustration schématique de différentes approches </p><br><h4 id="opredelenie-cveta">  Définition des couleurs </h4><br><p>  La couleur <img src="https://habrastorage.org/getpro/habr/post_images/804/c42/9d4/804c429d4bd8e4f2577d467481a193bd.svg" alt="d">  chaque pixel <img src="https://habrastorage.org/getpro/habr/post_images/7ba/469/280/7ba469280dbeae1ae4fcd637e6d8966e.svg" alt="y">  déterminé par un vote majoritaire pour les étiquettes de classe des préimages correspondantes. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/469/c8d/c50/469c8dc5021ee22be2190d80d4a8f9bd.svg" alt="d (y) = \ text {argmax} _ {k \ in C} \ sum_ {y_i \ in y} [f (P ^ {- 1} (y_i)) = k]"><br><p>  où <img src="https://habrastorage.org/getpro/habr/post_images/fbc/aa2/dde/fbcaa2dde5e052a6e1800227925c3615.svg" alt="C">  - beaucoup de toutes les classes, <img src="https://habrastorage.org/getpro/habr/post_images/b7b/64a/383/b7b64a3838b51c8557f97dadf1217771.svg" alt="f: \ mathbb {R} ^ n \ à C">  - classificateur. </p><br><p>  Chaque classe se verra attribuer un ton <em>(eng. Hue)</em> <img src="https://habrastorage.org/getpro/habr/post_images/23e/de5/d9b/23ede5d9b5363fbdc2108333f4ae7e33.svg" alt="H_T (k)">  - si la projection a des points de l'échantillon réel et un ton légèrement changé <img src="https://habrastorage.org/getpro/habr/post_images/9c9/128/5aa/9c91285aa90f350efd4554aebbbb0928.svg" alt="H _ {\ text {synth}} (k)">  pour les pixels dans lesquels il n'y a que des points synthétiques. </p><br><h4 id="smeshenie">  Confusion </h4><br><p>  Définir le mélange de pixels <em>(à partir de la confusion anglaise)</em> <img src="https://habrastorage.org/getpro/habr/post_images/704/5da/302/7045da3025a345f8eee22cdbc3371540.svg" alt="c (y)">  - comme le rapport du nombre d'étiquettes de la classe dominante au nombre total d'images inversées de pixels <img src="https://habrastorage.org/getpro/habr/post_images/7ba/469/280/7ba469280dbeae1ae4fcd637e6d8966e.svg" alt="y">  : </p><br><img src="https://habrastorage.org/getpro/habr/post_images/62d/5e7/47f/62d5e747f958e587200665af682cbae9.svg" alt="c (y) = \ frac {\ max_ {k \ in C} \ sum_ {y_i \ in y} [f (P ^ {- 1} (y_i)) = k]} {| y |}"><br><p>  Haute valeur <img src="https://habrastorage.org/getpro/habr/post_images/704/5da/302/7045da3025a345f8eee22cdbc3371540.svg" alt="c (y)">  indique la cohérence du classificateur, tandis qu'une valeur faible signale une approche de la frontière de division.  Mélanger les informations encodées en saturation de pixels <img src="https://habrastorage.org/getpro/habr/post_images/63e/a67/704/63ea67704edb2fecd38058084b809c43.svg" alt="S (y)">  - plus la consistance est élevée, plus la saturation est élevée. </p><br><h4 id="plotnost">  Densité </h4><br><p>  Bien qu'un minimum ait été généré <img src="https://habrastorage.org/getpro/habr/post_images/a1e/39d/a1c/a1e39da1c84981d7264baa207047222a.svg" alt="N">  des points de pré-image pour chaque pixel, il peut y avoir des pixels pour lesquels il y a beaucoup plus de points réels de l'ensemble d'apprentissage.  Ces pixels doivent être pris en compte lors du rendu.  Pour ce faire, entrez la densité de pixels <img src="https://habrastorage.org/getpro/habr/post_images/f76/9da/704/f769da704577ffcb3b5a6cde5ff711d5.svg" alt="\ rho (y)">  comme le nombre de ses points d'image inverses de <img src="https://habrastorage.org/getpro/habr/post_images/083/a90/e39/083a90e392615e6ff9271b60c0ffb8db.svg" alt="\ mathbb {R} ^ n">  .  On pourrait utiliser cette densité directement pour déterminer la luminosité d'un pixel comme <img src="https://habrastorage.org/getpro/habr/post_images/5cb/176/90f/5cb17690f41ccca3920dd257b053536d.svg" alt="V (y) = \ frac {\ rho (y)} {\ rho_ {max}}">  , mais les auteurs de l'article soulignent que cela ne donne pas le résultat souhaité, car  certains tons sont évidemment plus sombres que d'autres.  Par conséquent, un réglage plus sophistiqué est utilisé à la fois de saturation et de luminosité grâce à un paramètre de densité normalisé. </p><br><img src="https://habrastorage.org/getpro/habr/post_images/374/faf/768/374faf7680b448f460d3e89129445ff5.svg" alt="\ hat {\ rho} = max (\ frac {1} {20} \ frac {\ rho} {\ rho_ {avg}}, 1)"><br><p>  Alors si <img src="https://habrastorage.org/getpro/habr/post_images/5f3/8f9/0c5/5f38f90c57fe8c26092278e6a36b55c7.svg" alt="\ hat {\ rho} \ in [0, 0,5]">  - la luminosité dépend linéairement du paramètre à l'intérieur <img src="https://habrastorage.org/getpro/habr/post_images/b1e/ef5/e22/b1eef5e220c553d3c437ee6ddb9f4f08.svg" alt="[V_ {min} = 0,1, V_ {max} = 1]">  .  À <img src="https://habrastorage.org/getpro/habr/post_images/4cc/04d/a79/4cc04da7997da643ef6671babba1ec57.svg" alt="\ hat {\ rho} \ in [0,5, 1]">  commence à croître linéairement la saturation de <img src="https://habrastorage.org/getpro/habr/post_images/990/75d/89e/99075d89ee3ecff0e455ea82750e353f.svg" alt="S_ {min} = 0,2">  avant <img src="https://habrastorage.org/getpro/habr/post_images/638/3c5/73c/6383c573c312afd338a8ba5dbbaacdeb.svg" alt="S_ {max} = 1">  . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/6f2/21c/de5/6f221cde5e5f7fc053ec45964ec5dcbc.png" alt="Encodage couleur" width="400"><br>  [Fig.2] Codage couleur </p><br><h2 id="eksperimenty-i-rezultaty">  Expériences et résultats </h2><br><p>  Pour les expériences, les problèmes de classification binaire sur l'ensemble d'images <em>numériques MNIST</em> et de classification multiclasse sur l'ensemble de <em>données de segmentation d'image</em> , qui contient 2 310 images divisées en 7 classes, ont été résolus.  Il y a 19 attributs pour chaque image. </p><br><p>  Imagerie des résultats avec différents paramètres de résolution <img src="https://habrastorage.org/getpro/habr/post_images/bc2/e13/169/bc2e1316980f83eed49a82ca5dd0f525.svg" alt="R">  et le nombre minimum de prototypes <img src="https://habrastorage.org/getpro/habr/post_images/a1e/39d/a1c/a1e39da1c84981d7264baa207047222a.svg" alt="N">  pour le classificateur binaire LogisticRegression sur MNIST sont montrés dans la figure [3].  Les classes sont séparées par une ligne droite avec une grande précision et l'algorithme de visualisation fait un excellent travail.  Avec une résolution croissante, les nuages ​​des points source se dissolvent presque complètement parmi les nombreux points générés. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/037/5c6/69b/0375c669bf3ad059981b01727998baa9.png" alt="Encodage couleur" width="400"><br>  [Fig.  3] Le résultat de la visualisation pour divers paramètres de résolution et le nombre minimal d'échantillons N pour le classificateur LogisticRegression </p><br><p>  Visualisation lorsque <img src="https://habrastorage.org/getpro/habr/post_images/17c/6e0/1e3/17c6e01e344982b1f502a87aaf5560c5.svg" alt="R = 500 \ text {x} 500, N = 5">  pour trois classificateurs différents pour la classification multiple dans la figure [4].  Les projections des points de départ sont fortement mitigées et il n'est pas possible de construire des frontières de division explicites aux endroits où les projections des cas de test sont accumulées.  Cependant, en dehors du cluster principal, des limites de classe explicites ont été obtenues, dont les informations ne sont pas affichées sur les projections ordinaires, mais uniquement à l'aide de points synthétiques. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/662/ff8/8f4/662ff88f47de55ce8855a2676691d102.png" alt="Encodage couleur" width="400"><br>  [Fig.  4] Le résultat de la visualisation de trois classificateurs différents pour k = 7, R = 500x500, N = 5 </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><p>  La visualisation des limites de classe peut être utilisée dans la construction et le débogage d'un algorithme décisif, dans la sélection d'hyperparamètres, dans la lutte contre la reconversion, pour présenter et analyser les résultats. </p><br><p>  La méthode décrite par les auteurs de l'article d'origine peut être utilisée pour tout problème de classification, où les données peuvent être représentées comme un ensemble de signes d'une dimension fixe.  Contrairement à d'autres algorithmes de visualisation, cette approche peut être utilisée pour tout classificateur arbitrairement complexe et pour les ensembles de données avec un nombre arbitraire d'exemples, même avec un très petit, car  même avec de petites <img src="https://habrastorage.org/getpro/habr/post_images/a1e/39d/a1c/a1e39da1c84981d7264baa207047222a.svg" alt="N">  l'algorithme fonctionne de manière stable, sans perdre beaucoup de qualité. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr483608/">https://habr.com/ru/post/fr483608/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr483594/index.html">Économie future pour les physiciens</a></li>
<li><a href="../fr483598/index.html">Des oeufs de Pâques encore plus musicaux: on continue de parler de cadeaux pour des auditeurs attentifs</a></li>
<li><a href="../fr483600/index.html">Libérez votre Android</a></li>
<li><a href="../fr483602/index.html">Conférence DefCon 27: Dans les coulisses de la création de badges électroniques 2e partie</a></li>
<li><a href="../fr483604/index.html">Iridium: recevoir et décoder des signaux de constellation de satellites à domicile</a></li>
<li><a href="../fr483610/index.html">Un automate est-il un événement?</a></li>
<li><a href="../fr483612/index.html">Un conducteur de Tesla condamné à une amende pour s'être brossé les dents pendant qu'il conduisait sur un pilote automatique</a></li>
<li><a href="../fr483614/index.html">Méthodes de lutte contre le vol dans un club de robotique</a></li>
<li><a href="../fr483616/index.html">Projet Lacmus: comment la vision par ordinateur aide à sauver des personnes perdues</a></li>
<li><a href="../fr483626/index.html">Comment décrire un job 100 gitlab en 100 lignes sur Jsonnet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
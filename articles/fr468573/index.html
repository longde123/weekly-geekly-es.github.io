<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçüç≥ üëßüèΩ üîà postgres_exporter et surveillance des instances PostgreSQL avec plusieurs bases de donn√©es üëáüèø üë®üèæ‚Äçüíª üéûÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="UPD: La note a perdu de sa pertinence avec la sortie de 0.8.0. Toutes les innovations se trouvent dans l'article: Nouvelles fonctionnalit√©s de postgre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>postgres_exporter et surveillance des instances PostgreSQL avec plusieurs bases de donn√©es</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/468573/"><p>  <strong>UPD: La</strong> note a perdu de sa pertinence avec la sortie de 0.8.0.  Toutes les innovations se trouvent dans l'article: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nouvelles fonctionnalit√©s de postgres_exporter pour la surveillance de PostgreSQL</a> </p><br><p>  Bonjour, chers lecteurs! </p><br><p>  Prometheus et son √©cosyst√®me d'exportateurs (agents) est un bon outil pour tout administrateur et d√©veloppeur.  Facilit√© de livraison, simplicit√© (relative) des param√®tres, possibilit√© d'utiliser le service de d√©tection automatique. <br>  Mais ce n'est pas tellement √† propos de Prom√©th√©e, mais √† propos d'un des agents notables, √† savoir postgres_exporter.  Il vous permet de collecter des m√©triques avec PostgreSQL.  Mais si tout √©tait si simple ... </p><a name="habracut"></a><br><p>  Malheureusement, la documentation de postgres_exporter est assez asc√©tique et n'affecte que les cas g√©n√©raux.  Mais que faire si vous obtenez une instance d'un cluster SGBD avec plusieurs bases de donn√©es et / ou si vous souhaitez collecter des m√©triques pour plusieurs instances du cluster √† la fois. </p><br><h2 id="cel">  But </h2><br><p>  En fait, sur le but de l'article ou plut√¥t des notes.  Je constate tout de suite qu'ici je ne d√©crirai pas les processus d'assemblage ou de configuration de Prom√©th√©e et postgres_exporter, leur interaction.  Tout cela est d√©crit dans la documentation et dans de nombreuses autres sources. </p><br><p>  Je voudrais aborder certains cas particuliers d'utilisation de postgres_exporter pour r√©soudre des probl√®mes sp√©cifiques, √† savoir la collecte de m√©triques par un agent avec: </p><br><ol><li>  plusieurs bases de donn√©es en une seule instance; </li><li>  plusieurs exemplaires; </li><li>  plusieurs bases de donn√©es sur diff√©rentes instances. </li></ol><br><h2 id="postgres_exporter">  postgres_exporter </h2><br><p>  Subjectivement, les avantages et les inconv√©nients. </p><br><p>  Des pros: </p><br><ol><li>  Le premier et important avantage est la facilit√© de livraison et de configuration de l'agent.  Agent - est un fichier ex√©cutable (√©ventuellement, un fichier yaml avec un ensemble de m√©triques utilisateur).  Il s'agit d'une application autonome compil√©e pour la distribution et l'architecture n√©cessaires, et ne n√©cessite pas l'installation de packages suppl√©mentaires sur le serveur.  L'agent peut √™tre install√© √† la fois sur le m√™me n≈ìud que l'instance de cluster et sur un n≈ìud distinct; </li><li>  L'agent se connecte au SGBD en tant que client SQL standard.  Il est possible de se connecter via inet ou via une prise unix; </li><li>  La capacit√© de recevoir des m√©triques par un agent, √† partir de plusieurs instances d'instances et / ou de plusieurs bases de donn√©es d'une instance; </li><li>  Les mesures sont collect√©es aussi souvent que demand√© par Prom√©th√©e ou un autre collectionneur; </li><li>  La possibilit√© de recevoir des m√©triques avec une simple requ√™te HTTP; </li><li>  R√©ception automatique, par un agent, d'une liste de bases de donn√©es sur une seule instance PostgreSQL, avec la version postgres_exporter 0.5.0+, l'option --auto-Discover-Database est apparue. </li></ol><br><p>  Des inconv√©nients: </p><br><ol><li>  Absence d'autorisation; </li><li>  Transfert de donn√©es uniquement via HTTP.  Toutes les mesures seront transmises en texte clair.  Et c'est mauvais, car un attaquant, une fois intercept√©, peut obtenir une liste fiable de bases de donn√©es et de r√¥les; </li><li>  Ne met pas en cache les m√©triques.  Ainsi, par exemple, lorsque l'agent n'est pas disponible pour le r√©seau, les donn√©es pour la p√©riode d'indisponibilit√© ne seront pas re√ßues par Prometheus; </li><li>  Lorsque vous utilisez l'option --auto-Discover-Database, il n'est pas possible d'exclure certaines bases de donn√©es de la liste.  C'est plut√¥t temporaire, car dans la prochaine version, une telle possibilit√© devrait d√©j√† appara√Ætre (option --exclude-databases). </li></ol><br><h3 id="neskolko-baz-dannyh-v-odnom-ekzemplyare">  Plusieurs bases de donn√©es dans une seule instance </h3><br><p>  Eh bien, passons √† la pratique.  Supposons que nous ayons une instance de PostgreSQL avec plusieurs bases de donn√©es et que nous devons organiser la collecte des m√©triques d'instance et toutes les bases de donn√©es. <br>  Pourquoi ai-je s√©par√© la collection de m√©triques de base de donn√©es et l'instance de cluster, tout est tr√®s simple, le sc√©nario de postgres_exporter travaillant avec plusieurs bases de donn√©es sur le m√™me cluster implique l'ex√©cution du m√™me ensemble de requ√™tes SQL dans diff√©rentes bases de donn√©es.  Et par cons√©quent, lorsque vous essayez d'obtenir des mesures √† partir des vues pg_stat_replication, pg_stat_activity, pg_stat_statement, etc.  √©tant commun au cluster, nous obtenons toujours, dans la compr√©hension de postgres_exporter, le m√™me ensemble de m√©triques qui conduira √† des cl√©s et des valeurs en double, ce qui conduira √† une erreur. <br>  Voyons √† quoi cela ressemble dans la pratique. </p><br><p>  Nous avons une instance de test avec un ensemble de bases de donn√©es: </p><br><pre><code class="plaintext hljs">List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+------------+------------+----------------------- dbtest1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | dbtest2 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | dbtest3 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 |</code> </pre> <br><p>  Nous d√©marrons postgres_exporter, avec l'option --auto-discovery-databases (si le nom de la base de donn√©es n'est pas sp√©cifi√© dans la cha√Æne de connexion, alors la connexion sera √©tablie √† la base de donn√©es avec le nom d'utilisateur): </p><br><pre> <code class="plaintext hljs">$ DATA_SOURCE_NAME="postgresql://postgres@127.0.0.1:5432/?sslmode=disable" ./postgres_exporter --auto-discover-databases --log.format=logger:stdout</code> </pre> <br><ul><li>  DATA_SOURCE_NAME - variable d'environnement contenant des param√®tres pour la connexion √† une instance PostgreSQL </li></ul><br><p>  Dans la sortie de l'agent, nous observons une image idyllique, il est lanc√© et a pu se connecter √† toutes les bases de donn√©es du cluster (bien qu'il n'√©crive pas dans quelles bases de donn√©es, mais j'esp√®re que cela sera corrig√©): </p><br><pre> <code class="plaintext hljs">INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Starting Server: :9187 source="postgres_exporter.go:1490"</code> </pre> <br><p>  Je pense qu'un lecteur attentif remarquera qu'il y a quatre bases dans le cluster (postgres, dbtest1, dbtest2 et dbtest3, template0 et template1 sont ignor√©s), et il y a cinq connexions.  Dans notre cas, postgres_exporter cr√©e deux connexions √† la base de donn√©es postgres.  Et avec cette fonctionnalit√©, vous devez √™tre tr√®s prudent.  Pourquoi?  Nous verrons cela un peu plus loin. </p><br><p>  Eh bien, continuons et essayons d'obtenir les m√©triques: </p><br><pre> <code class="plaintext hljs">$ curl http://localhost:9178/metrics</code> </pre> <br><p>  Par cons√©quent, dans la sortie, nous obtenons des avertissements sur les doublons "a √©t√© collect√© auparavant avec le m√™me nom et les m√™mes valeurs d'√©tiquette" (mais dans le journal postgres_exporter nous ne verrons pas d'avertissements): </p><br><pre> <code class="plaintext hljs">... * collected metric pg_stat_activity_max_tx_duration label:&lt;name:"datname" value:"dbtest1" &gt; label:&lt;name:"server" value:"127.0.0.1:5432" &gt; label:&lt;name:"state" value:"fastpath function call" &gt; gauge:&lt;value:0 &gt; was collected before with the same name and label values * collected metric pg_stat_bgwriter_checkpoints_timed label:&lt;name:"server" value:"127.0.0.1:5432" &gt; counter:&lt;value:1 &gt; was collected before with the same name and label values ...</code> </pre> <br><p>  La seule fa√ßon de se d√©barrasser des erreurs est de d√©sactiver la collection de m√©triques par d√©faut.  Il existe deux fa√ßons de proc√©der: d√©finissez d'abord les variables d'environnement PG_EXPORTER_DISABLE_DEFAULT_METRICS et PG_EXPORTER_DISABLE_SETTINGS_METRICS sur true ou utilisez les options --disable-default-metrics et --disable-settings-metrics </p><br><p>  Red√©marrez postgres_exporter avec des options suppl√©mentaires: </p><br><pre> <code class="plaintext hljs">$ DATA_SOURCE_NAME="postgresql://postgres@127.0.0.1:5432/?sslmode=disable" ./postgres_exporter --auto-discover-databases --log.format=logger:stdout --disable-default-metrics --disable-settings-metrics</code> </pre> <br><p>  Essayer d'obtenir les m√©triques: </p><br><pre> <code class="plaintext hljs">$ curl http://localhost:9178/metrics</code> </pre> <br><p>  Et donc, tout s'est pass√© comme pr√©vu, mais il n'y a pas une seule m√©trique associ√©e √† PostgreSQL dans la sortie: </p><br><pre> <code class="plaintext hljs"># HELP go_gc_duration_seconds A summary of the GC invocation durations. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile="0"} 0 go_gc_duration_seconds{quantile="0.25"} 0 go_gc_duration_seconds{quantile="0.5"} 0 go_gc_duration_seconds{quantile="0.75"} 0 go_gc_duration_seconds{quantile="1"} 0 go_gc_duration_seconds_sum 0 go_gc_duration_seconds_count 0 ... # HELP process_virtual_memory_bytes Virtual memory size in bytes. # TYPE process_virtual_memory_bytes gauge process_virtual_memory_bytes 1.3832192e+07</code> </pre> <br><p>  De plus, afin d'obtenir la charge utile, nous devons cr√©er un fichier qui d√©crit les mesures que nous voulons recevoir (n'oubliez pas, nous ne pouvons collecter que des mesures sp√©cifiques √† la base de donn√©es). </p><br><p>  Pour le test, nous collecterons des m√©triques de la relation pg_statio_user_tables.  Pour ce faire, cr√©ez un fichier queries.yaml avec le contenu suivant: </p><br><pre> <code class="plaintext hljs">pg_statio_user_tables: query: "SELECT current_database() as datname, schemaname, relname, heap_blks_read, heap_blks_hit FROM pg_statio_user_tables" metrics: - datname: usage: "LABEL" description: "Name of database" - schemaname: usage: "LABEL" description: "Name of the schema that this table is in" - relname: usage: "LABEL" description: "Name of this table" - heap_blks_read: usage: "COUNTER" description: "Number of disk blocks read from this table" - heap_blks_hit: usage: "COUNTER" description: "Number of buffer hits in this table"</code> </pre> <br><p>  Je pense ici qu'il est n√©cessaire de clarifier un point, √† savoir l'ajout du nom de la base de donn√©es dans laquelle la requ√™te est ex√©cut√©e.  Il s'agit d'une exigence obligatoire, et il y a au moins deux raisons √† cela: </p><br><ol><li>  Les bases de donn√©es peuvent avoir des tables du m√™me nom, ce qui entra√Ænera une erreur en raison de la duplication des m√©triques; </li><li>  Sans cela, vous ne pouvez pas identifier la base de donn√©es √† laquelle la m√©trique fait r√©f√©rence, ce qui transformera les donn√©es collect√©es en ordures. </li></ol><br><p>  Et donc, nous lan√ßons notre agent avec l'option --extend.query-path (ici le chemin vers le fichier yaml avec la description des m√©triques est indiqu√©): </p><br><pre> <code class="plaintext hljs">DATA_SOURCE_NAME="postgresql://postgres@127.0.0.1:5432?sslmode=disable" ./postgres_exporter --log.format=logger:stdout --auto-discover-databases --disable-default-metrics --disable-settings-metrics --extend.query-path=./queries.yaml</code> </pre> <br><p>  Nous essayons d'obtenir les m√©triques (pour plus de clart√©, nous ne prenons que pg_statio_user_tables_heap_blks_hit): </p><br><pre> <code class="plaintext hljs">curl -s http://localhost:9187/metrics | grep pg_statio_user_tables_heap_blks_hit</code> </pre> <br><p>  En cons√©quence, nous obtenons un ensemble de mesures unique interpr√©t√©: </p><br><pre> <code class="plaintext hljs"># HELP pg_statio_user_tables_heap_blks_hit Number of buffer hits in this table # TYPE pg_statio_user_tables_heap_blks_hit counter pg_statio_user_tables_heap_blks_hit{datname="dbtest1",relname="t1",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest1",relname="t2",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest2",relname="t1",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest2",relname="t2",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest3",relname="t1",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest3",relname="t2",schemaname="public",server="127.0.0.1:5432"} 0</code> </pre> <br><p>  En cons√©quence, nous avons eu l'opportunit√©, en utilisant l'option --auto-discovery-databases, de collecter des m√©triques √† partir de toutes les bases de donn√©es d'une instance du cluster.  Un bon bonus est que lorsque vous ajoutez une nouvelle base de donn√©es, vous n'avez pas besoin de red√©marrer l'agent. <br>  Mais avec tout cela, nous nous sommes retrouv√©s sans m√©triques d'instance.  Pour le moment, la solution n'est qu'une solution: utiliser diff√©rents agents pour collecter des m√©triques de base de donn√©es et d'instance. <br>  Bien s√ªr, cela n'a pas l'air tr√®s bien, mais il est possible de niveler cette nuisance en regroupant les agents pour collecter des m√©triques √† partir de plusieurs instances.  Nous consid√©rerons ceci, une autre opportunit√© plut√¥t int√©ressante ci-dessous. </p><br><div class="spoiler">  <b class="spoiler_title">La r√©ponse √† l'√©nigme de la connexion ¬´extra¬ª</b> <div class="spoiler_text"><p>  Rappelez-vous, au d√©but, nous avons attir√© l'attention sur la connexion "extra". C'est donc une fonctionnalit√© de postgres_exporter avec l'option --auto-discovery-databases. <br>  Mais pourquoi cela peut-il causer beaucoup de probl√®mes?  En fait, tout est simple et d√©j√† d√©crit ci-dessus, √† savoir, le probl√®me est que postgres_exporter collectera deux fois les m√©triques de la base de donn√©es postgres et commencera √† dupliquer les m√©triques.  Dans notre cas, seule l'apparence de l'option --exclude-databases peut aider (nous attendons donc avec impatience la prochaine version). <br>  Et oui, si vous avez des tables d'utilisateurs dans la base de donn√©es postgres, alors l'exemple ci-dessus ne fonctionnera pas. </p></div></div><br><h3 id="neskolko-ekzemplyarov">  Plusieurs instances </h3><br><p>  Bon, continue.  Nous avons compris comment obtenir des m√©triques √† partir de plusieurs bases de donn√©es, nous allons maintenant examiner la possibilit√© de surveiller plusieurs instances avec un seul agent.  C'est tr√®s simple, pour cela il suffit de les lister dans la variable d'environnement DATA_SOURCE_NAME s√©par√©s par une virgule: </p><br><pre> <code class="plaintext hljs">$ DATA_SOURCE_NAME="postgresql://postgres@127.0.0.1:5432/postgres?sslmode=disable,postgresql://postgres@127.0.0.1:5434/postgres?sslmode=disable" ./postgres_exporter --log.format=logger:stdout</code> </pre> <br><p>  Ici, nous nous connectons √† deux instances de cluster diff√©rentes fonctionnant, dans notre cas, sur le n≈ìud local.  Voici √† quoi cela ressemble dans les journaux: </p><br><pre> <code class="plaintext hljs">INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Established new database connection to "127.0.0.1:5434". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5434": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Starting Server: :9187 source="postgres_exporter.go:1490"</code> </pre> <br><p>  Ensuite, nous essayons d'obtenir les m√©triques (pour plus de clart√©, nous nous limitons √† la m√©trique pg_stat_database_blk_read_time): </p><br><pre> <code class="plaintext hljs">curl -s http://localhost:9187/metrics | grep pg_stat_database_blk_read_time</code> </pre> <br><p>  Par cons√©quent, √† partir d'un agent, nous obtenons des mesures pour les deux instances: </p><br><pre> <code class="plaintext hljs"># HELP pg_stat_database_blk_read_time Time spent reading data file blocks by backends in this database, in milliseconds # TYPE pg_stat_database_blk_read_time counter pg_stat_database_blk_read_time{datid="1",datname="template1",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="1",datname="template1",server="127.0.0.1:5434"} 0 pg_stat_database_blk_read_time{datid="13116",datname="template0",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="13116",datname="template0",server="127.0.0.1:5434"} 0 pg_stat_database_blk_read_time{datid="13117",datname="postgres",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="13117",datname="postgres",server="127.0.0.1:5434"} 0 pg_stat_database_blk_read_time{datid="16384",datname="dbtest1",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="16385",datname="dbtest2",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="16386",datname="dbtest3",server="127.0.0.1:5432"} 0</code> </pre><br><p>  Dans ce cas, tout √©tait un peu plus simple que dans le cas de plusieurs bases de donn√©es sur une seule instance.  Dans le m√™me temps, nous avons toujours la possibilit√© de recevoir des mesures globales de toutes les instances. </p><br><h2 id="rezyume">  R√©sum√© </h2><br><p>  Et donc, le troisi√®me cas indiqu√© aux fins est une combinaison des deux d√©crits ci-dessus, donc je ne vois aucune raison de l'amener. </p><br><p>  En cons√©quence, ce que nous avons en fin de compte, postgres_exporter, √† mon avis, est un outil administrateur plut√¥t int√©ressant et prometteur pour surveiller les instances du cluster PostgreSQL et les bases de donn√©es d√©ploy√©es dessus.  Mais en raison de son √¢ge, ce n'est pas sans d√©fauts qui peuvent √™tre compris et pardonn√©s. </p><br><h2 id="istochniki">  Les sources </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Prometheus</a> [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">1</a> ] est une application open source utilis√©e pour surveiller et alerter les √©v√©nements.  Il √©crit des m√©triques en temps r√©el dans une base de donn√©es de s√©ries chronologiques construite √† l'aide du mod√®le de requ√™te HTTP, avec des requ√™tes flexibles et des alertes en temps r√©el. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">postgres_exporter</a> est un exportateur de m√©triques PostgreSQL pour Prometheus. </li></ul><br><p>  Version, au moment de la r√©daction, v 0.5.1.  Versions prises en charge de PostgreSQL 9.4+ (restriction de la version 9.1+ not√©e dans le code source). </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr468573/">https://habr.com/ru/post/fr468573/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr468557/index.html">WEB 3.0 - la deuxi√®me approche du projectile</a></li>
<li><a href="../fr468559/index.html">Sauvegardez le cloud, amis</a></li>
<li><a href="../fr468561/index.html">Semaine de la s√©curit√© 39: erreurs de s√©curit√© et banales</a></li>
<li><a href="../fr468563/index.html">Watchmen Watch: L'√©tat actuel des installations de suivi spatial</a></li>
<li><a href="../fr468565/index.html">Compteur Geiger fait maison sur ESP8266 avec √©cran tactile</a></li>
<li><a href="../fr468577/index.html">Patch'ti - ne compte pas: l'histoire de la gestion des patchs dans les visages et les couleurs</a></li>
<li><a href="../fr468581/index.html">Partagez, p√™chez, rapidement et compl√®tement</a></li>
<li><a href="../fr468583/index.html">Exemples de jeu des ordres ¬´venez √† la rescousse¬ª (analyse d'une dizaine d'incidents avec des exemples)</a></li>
<li><a href="../fr468589/index.html">Comment organiser le travail sur une biblioth√®que de composants communs</a></li>
<li><a href="../fr468595/index.html">Comment nous avons construit le Wi-Fi sur Huawei</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
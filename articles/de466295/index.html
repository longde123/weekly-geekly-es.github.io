<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§µüèø üéÇ üò≥ Schmerzloser Fallback-Cache auf Scala üôå üôÖüèª üçü</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In gro√üen oder Microservice-Architekturen ist der wichtigste Service nicht immer der produktivste und manchmal nicht f√ºr Hochlast vorgesehen. Wir spre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Schmerzloser Fallback-Cache auf Scala</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/466295/"> In gro√üen oder Microservice-Architekturen ist der wichtigste Service nicht immer der produktivste und manchmal nicht f√ºr Hochlast vorgesehen.  Wir sprechen √ºber das Backend.  Es arbeitet langsam - es verliert Zeit bei der Datenverarbeitung und wartet auf eine Antwort zwischen ihm und dem DBMS und skaliert nicht.  Selbst wenn sich die Anwendung selbst leicht skalieren l√§sst, l√§sst sich dieser Engpass √ºberhaupt nicht skalieren.  Wie kann dieses Problem gel√∂st und eine hohe Leistung sichergestellt werden?  Wie kann eine Systemantwort bereitgestellt werden, wenn wichtige Informationsquellen stumm sind? <br><br><img src="https://habrastorage.org/webt/tw/3o/ti/tw3otiqpnki3jcwa8ittvdrpzoc.jpeg"><br><br>  Wenn Ihre Architektur vollst√§ndig mit dem Reactive-Manifest √ºbereinstimmt, skalieren die Komponenten der Anwendung unbegrenzt mit zunehmender Last unabh√§ngig voneinander und halten dem Fall eines Knotens stand - Sie kennen die Antwort.  Wenn nicht, wird <b>Oleg Nizhnikov</b> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Odomontois</a> ) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">erkl√§ren</a> , wie das Skalierbarkeitsproblem bei Tinkoff gel√∂st wurde, indem er seinen schmerzlosen Fallback-Cache auf Scala erstellt, ohne die Anwendung neu zu schreiben. <br><br>  <i>Hinweis</i>  <i>Der Artikel enth√§lt ein Minimum an Scala-Code und ein Maximum an allgemeinen Prinzipien und Ideen.</i> <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/p9j6_nOP4Kk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  Instabiles oder langsames Backend </h2><br>  Bei der Interaktion mit dem Backend ist die durchschnittliche Anwendung schnell.  Das Backend erledigt jedoch den Gro√üteil der Arbeit und mahlt die meisten Daten intern - es dauert l√§nger.  Es wird zus√§tzliche Zeit verschwendet, auf ein Backend und eine DBMS-Antwort zu warten.  Selbst wenn sich die Anwendung selbst leicht skalieren l√§sst, l√§sst sich dieser Engpass √ºberhaupt nicht skalieren.  Wie kann das Backend entlastet und das Problem gel√∂st werden? <br><div class="scrollable-table"><table><tbody><tr><td></td><td>  <b>Ihr Service</b> <br></td><td>  <b>Backend</b> <br></td></tr><tr><td>  Nettoarbeitszeit in jeder Antwort: (De-) Serialisierung, √úberpr√ºfungen, Logik, Asynchronit√§tskosten <br></td><td>  53 ms <br></td><td>  785 ms <br></td></tr><tr><td>  Warten auf Backend und DBMS <br></td><td>  3015 ms <br></td><td>  1932 ms <br></td></tr><tr><td>  Anzahl der Knoten <br></td><td>  32 <br></td><td>  2 <br></td></tr><tr><td>  Zusammenfassende Antwort <br></td><td>  3070 ms <br></td><td>  2702 ms <br></td></tr></tbody></table></div><br><h3>  Eingebetteter Cache </h3><br>  Die erste Idee besteht darin, Daten zum Lesen zu nehmen, Daten anzufordern und den Cache auf der Ebene jedes speicherinternen Knotens zu konfigurieren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e98/e7d/18f/e98e7d18f9f43d97f36941011d82b3b4.jpg"><br><br>  Der Cache bleibt so lange bestehen, bis der Knoten neu gestartet wird und nur die letzten Daten gespeichert werden.  Wenn die Anwendung abst√ºrzt und neue Benutzer hinzukommen, die nicht in der letzten Stunde, am letzten Tag oder in der letzten Woche waren, kann die Anwendung nichts dagegen tun. <br><br><h3>  Proxy </h3><br>  Die zweite Option ist ein Proxy, der einen Teil der Anforderungen √ºbernimmt oder die Anwendung √§ndert. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7ff/817/a49/7ff817a49b919c269c55e9995eaca4f0.jpg"><br><br>  Im Proxy k√∂nnen Sie jedoch nicht die gesamte Arbeit f√ºr die Anwendung selbst erledigen. <br><br><h3>  Datenbank zwischenspeichern </h3><br>  Die dritte Option ist schwierig, wenn der Teil der Daten, den das Backend zur√ºckgibt, f√ºr lange Zeit gespeichert werden kann.  Wenn sie gebraucht werden, zeigen wir dem Kunden, auch wenn sie nicht mehr relevant sind.  Das ist besser als nichts. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/024/8a3/72f/0248a372f78828298f116a711321a55f.jpg"><br><br>  Diese Entscheidung wird diskutiert. <br><br><h2>  Fallback-Cache </h2><br>  Dies ist unsere Bibliothek.  Es ist in die Anwendung eingebettet und kommuniziert mit dem Backend.  Mit minimaler Verfeinerung analysiert es die Datenstruktur, generiert Serialisierungsformate und erh√∂ht mit Hilfe des Leistungsschalteralgorithmus die Fehlertoleranz.  Eine effektive Serialisierung kann in jeder Sprache implementiert werden, in der Typen im Voraus analysiert werden k√∂nnen, wenn sie streng genug definiert sind. <br><br><h3>  Komponenten </h3><br>  Unsere Bibliothek sieht ungef√§hr so ‚Äã‚Äãaus. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/906/57c/ce0/90657cce0e43cbaf09ba1a38b3e8eaff.jpg"><br><br>  Der linke Teil ist der Interaktion mit diesem Repository gewidmet, das zwei wichtige Komponenten enth√§lt: <br><br><ul><li>  die Komponente, die f√ºr den Initialisierungsprozess verantwortlich ist - vorbereitende Aktionen mit dem DBMS vor Verwendung des Fallback-Cache; <br></li><li>  Modul zur automatischen Serialisierung. <br></li></ul><br>  Die rechte Seite ist die allgemeine Funktionalit√§t, die sich auf Fallback bezieht. <br><br>  Wie funktioniert das alles?  In der Mitte der Anwendung befinden sich Abfragen und Zwischentypen zum Speichern des Status.  Dieses Formular dr√ºckt die Daten aus, die wir vom Backend f√ºr eine oder mehrere Anfragen erhalten haben.  Wir senden die Parameter an unsere Methode und erhalten die Daten von dort.  Diese Daten m√ºssen irgendwie serialisiert werden, um gespeichert zu werden, also verpacken wir sie in Code.  Ein separates Modul ist daf√ºr verantwortlich.  Wir haben das Leistungsschaltermuster verwendet. <br><br><h3>  Speicheranforderungen </h3><br>  <b>Lange Haltbarkeit - 30-500 Tage</b> .  Einige Aktionen k√∂nnen lange dauern, und w√§hrend dieser ganzen Zeit m√ºssen Daten gespeichert werden.  Daher m√∂chten wir einen Speicher, in dem Daten f√ºr lange Zeit gespeichert werden k√∂nnen.  In-Memory ist daf√ºr nicht geeignet. <br><br>  <b>Gro√ües Datenvolumen - 100 GB-20 TB</b> .  Wir m√∂chten Dutzende Terabyte Daten im Cache speichern, und noch mehr aufgrund des Wachstums.  All dies im Speicher zu halten ist ineffizient - die meisten Daten werden nicht st√§ndig angefordert.  Sie l√ºgen lange und warten auf ihren Benutzer, der hereinkommt und fragt.  In-Memory f√§llt nicht unter diese Anforderungen. <br><br>  <b>Hohe Datenverf√ºgbarkeit</b> .  Mit dem Service kann alles passieren, aber wir m√∂chten, dass das DBMS jederzeit verf√ºgbar bleibt. <br><br>  <b>Niedrige Lagerkosten</b> .  Wir senden zus√§tzliche Daten an den Cache.  Infolgedessen tritt Overhead auf.  Bei der Implementierung unserer L√∂sung m√∂chten wir diese minimieren. <br><br>  <b>Unterst√ºtzung f√ºr Abfragen in regelm√§√üigen Abst√§nden</b> .  Unsere Datenbank sollte in der Lage sein, Daten nicht nur vollst√§ndig, sondern in Intervallen abzurufen: eine Liste von Aktionen, den Verlauf eines Benutzers f√ºr einen bestimmten Zeitraum.  Daher ist ein reiner Schl√ºsselwert nicht geeignet. <br><br><h3>  Annahmen </h3><br>  Anforderungen schr√§nken die Liste der Kandidaten ein.  Wir gehen davon aus, dass wir den Rest implementiert haben, und gehen von den folgenden Annahmen aus, wobei wir wissen, warum genau wir den Fallback-Cache ben√∂tigen. <br><br>  <b>Datenintegrit√§t zwischen zwei verschiedenen GET-Anforderungen ist nicht erforderlich</b> .  Wenn sie also zwei verschiedene Zust√§nde aufweisen, die nicht miteinander √ºbereinstimmen, werden wir dies ertragen. <br><br>  <b>Die Relevanz und Ung√ºltigmachung von Daten ist nicht erforderlich</b> .  Zum Zeitpunkt der Anfrage wird davon ausgegangen, dass wir die neueste Version haben, die wir anzeigen. <br><br>  Wir senden und empfangen Daten vom Backend.  <b>Die Struktur dieser Daten ist im Voraus bekannt</b> . <br><br><h2>  Speicherauswahl </h2><br>  Als Alternative haben wir drei Hauptoptionen in Betracht gezogen. <br><br>  Der erste ist <b>Cassandra</b> .  Vorteile: hohe Verf√ºgbarkeit, einfache Skalierbarkeit und integrierter Serialisierungsmechanismus mit der UDT-Sammlung. <br><br>  <b>UDT</b> oder <b>benutzerdefinierte Typen</b> bedeutet einen Typ.  Mit ihnen k√∂nnen Sie strukturierte Typen effizient stapeln.  Typfelder sind im Voraus bekannt.  Diese Serialisierungsfelder sind wie in Protokollpuffern mit separaten Tags gekennzeichnet.  Nach dem Lesen dieser Struktur ist es m√∂glich zu verstehen, welche Felder dort auf Tags basieren.  Genug Metadaten, um ihren Namen und Typ herauszufinden. <br><br>  Ein weiteres Plus von Cassandra ist, dass es neben dem Partitionsschl√ºssel einen zus√§tzlichen <b>Clustering-Schl√ºssel gibt</b> .  Dies ist ein spezieller Schl√ºssel, aufgrund dessen die Daten auf einem Knoten sortiert werden.  Auf diese Weise k√∂nnen Sie eine Option wie Intervallabfragen implementieren. <br><br>  Cassandra gibt es schon relativ lange, es gibt <b>viele √úberwachungsl√∂sungen daf√ºr</b> , und <b>ein Minus ist die JVM</b> .  Dies ist nicht die produktivste Option f√ºr Plattformen, auf denen Sie ein DBMS schreiben k√∂nnen.  Die JVM hat Probleme mit der Speicherbereinigung und dem Overhead. <br><br>  Die zweite Option ist <b>CouchBase</b> .  Vorteile: Datenzugriff, Skalierbarkeit und Schema. <br><br>  Mit CouchBase m√ºssen Sie weniger √ºber Serialisierung nachdenken.  Dies ist sowohl ein Plus als auch ein Minus - wir m√ºssen das Datenschema nicht steuern.  Es gibt globale Indizes, mit denen Sie Intervallabfragen global in einem Cluster ausf√ºhren k√∂nnen. <br><br>  CouchBase ist ein Hybrid, bei dem <b>Memcache</b> zu einem √ºblichen DBMS hinzugef√ºgt wird <b>- schneller Cache</b> .  Sie k√∂nnen damit automatisch alle Daten auf dem Knoten zwischenspeichern - die hei√üesten mit sehr hoher Verf√ºgbarkeit.  Dank seines Caches kann CouchBase schnell sein, wenn dieselben Daten sehr oft angefordert werden. <br><br>  <b>Schemaless</b> und <b>JSON</b> k√∂nnen auch ein Minus sein.  Daten k√∂nnen so lange gespeichert werden, dass die Anwendung Zeit zum √Ñndern hat.  In diesem Fall √§ndert sich auch die Datenstruktur, die CouchBase speichern und lesen wird.  Die vorherige Version ist m√∂glicherweise nicht kompatibel.  Dies erfahren Sie nur beim Lesen und nicht beim Entwickeln von Daten, wenn diese irgendwo in der Produktion liegen.  Wir m√ºssen √ºber eine ordnungsgem√§√üe Migration nachdenken, und genau das wollen wir nicht tun. <br><br>  Die dritte Option ist <b>Tarantool</b> .  Es ist ber√ºhmt f√ºr seine super Geschwindigkeit.  Es hat eine wunderbare LUA-Engine, mit der Sie eine Reihe von Logik schreiben k√∂nnen, die direkt auf dem Server von LuaJit ausgef√ºhrt wird. <br><br>  Andererseits ist dies ein modifizierter Schl√ºsselwert.  Daten werden in Tupeln gespeichert.  Wir m√ºssen selbst √ºber die richtige Serialisierung nachdenken, dies ist nicht immer eine offensichtliche Aufgabe.  Tarantool hat auch einen spezifischen Ansatz zur <b>Skalierbarkeit</b> .  Was mit ihm los ist, werden wir weiter diskutieren. <br><br><h3>  Sharding / Replikation </h3><br>  M√∂glicherweise ben√∂tigt unsere Anwendung <b>Sharding / Replication</b> .  Drei Repositorys implementieren sie unterschiedlich. <br><br>  Cassandra schl√§gt eine Struktur vor, die normalerweise als "Ring" bezeichnet wird. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/387/b22/828/387b228289ece281dd70ecea2ded8890.jpg"><br><br>  Viele Knoten sind verf√ºgbar.  Jeder von ihnen speichert seine Daten und Daten von den n√§chstgelegenen Knoten als Replikate.  Wenn einer ausf√§llt, k√∂nnen die Knoten daneben einen Teil seiner Daten bedienen, bis der Ausfall steigt. <br><br>  Sharding \ Replication ist f√ºr dieselbe Struktur verantwortlich.  Zum Auspacken in 10 Teile und Replikationsfaktor 3 reichen 10 Knoten aus.  Jeder der Knoten speichert 2 Replikate der benachbarten. <br><br>  In CouchBase ist die Interaktionsstruktur zwischen Knoten √§hnlich aufgebaut: <br><br><ul><li>  Es gibt Daten, die als aktiv markiert sind und f√ºr die der Knoten selbst verantwortlich ist. <br></li><li>  Es gibt Replikate benachbarter Knoten, die CouchBase speichert. <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/296/09a/1c8/29609a1c8391653566cb36ab9434da21.jpg"><br><br>  Wenn ein Knoten ausf√§llt, √ºbernehmen die benachbarten, gemeinsam genutzten Knoten die Verantwortung f√ºr die Wartung dieses Teils der Schl√ºssel. <br><br>  In Tarantool √§hnelt die Architektur MongoDB.  Aber mit einer Nuance: Es gibt Sharding-Gruppen, die miteinander repliziert werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e81/5f8/5a5/e815f85a59d330b8250071def6cc0d25.jpg"><br><br>  F√ºr die beiden vorherigen Architekturen sind 4 Knoten erforderlich, wenn 4 Shards und Replikationsfaktor 3 erstellt werden sollen.  F√ºr Tarantool - 12!  Der Nachteil wird jedoch durch die von Tarantool garantierte Geschwindigkeit ausgeglichen. <br><br><h2>  Cassandra </h2><br>  Optionale Module f√ºr das Sharding in Tarantool wurden erst k√ºrzlich ver√∂ffentlicht.  Aus diesem Grund haben wir das Cassandra DBMS als Hauptkandidaten ausgew√§hlt.  Denken Sie daran, dass wir √ºber die spezifische Serialisierung gesprochen haben. <br><br><h3>  Automatische Serialisierung </h3><br><blockquote>  Das SQL-Protokoll setzt voraus, dass Sie ein Datenschema ziemlich frei definieren k√∂nnen. </blockquote><br>  Sie k√∂nnen dies als Vorteil nutzen.  Serialisieren Sie beispielsweise Daten so, dass die langen Feldnamen unserer Blattstrukturen nicht jedes Mal in unseren Werten gespeichert werden.  In diesem Fall verf√ºgen wir √ºber einige Metadaten, die das Datenger√§t beschreiben.  UDTs selbst geben auch an, welche Felder Beschriftungen und Tags entsprechen. <br><br>  Daher erfolgt die automatisch generierte Serialisierung ungef√§hr auf die gleiche Weise.  Wenn wir einen der Grundtypen haben, der dem Typ aus der Datenbank eins zu eins entsprechen kann, tun wir das.  Eine Reihe von Typen Int, Long, String, Double befindet sich ebenfalls in Cassandra. <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Anwendungsdatentyp</b> <br></td><td>  <b>Datentyp in Cassandra</b> <br></td></tr><tr><td>  Primitiver Typ <br>  (Int, Long, String, Double, BigDecimal) <br></td><td>  Primitiver Typ <br>  (int, biging, text, double, decimal) <br></td></tr></tbody></table></div><br>  Wenn in einer Struktur ein optionales Feld auftritt, tun wir nichts extra.  Wir geben ihm den Typ an, in den sich dieses Feld verwandeln soll.  Die Struktur speichert null.  Wenn wir in der Struktur auf der Deserialisierungsebene Null finden, nehmen wir an, dass dies das Fehlen eines Wertes ist. <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Anwendungsdatentyp</b> <br></td><td>  <b>Datentyp in Cassandra</b> <br></td></tr><tr><td>  Option [A] <br></td><td>  a <br></td></tr></tbody></table></div><br>  Alle Sammlungstypen aus der Sammlung in Scala werden in eine Typliste konvertiert.  Hierbei handelt es sich um geordnete Sammlungen mit einem Index-Matching-Element. <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Anwendungsdatentyp</b> <br></td><td>  <b>Datentyp in Cassandra</b> <br></td></tr><tr><td>  Seq [A], Liste [A], Stream [A], Vektor [A] <br></td><td>  eingefroren &lt;Liste "a"&gt; <br></td></tr></tbody></table></div><br>  Ungeordnete Set-Sammlungen garantieren, dass jeder Wert genau ein Element enth√§lt.  Cassandra hat auch einen speziellen Set-Typ f√ºr sie. <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Anwendungsdatentyp</b> <br></td><td>  <b>Datentyp in Cassandra</b> <br></td></tr><tr><td>  Setze [A] <br></td><td>  eingefroren &lt;setze "a"&gt; <br></td></tr></tbody></table></div><br>  H√∂chstwahrscheinlich werden wir viel Mapping () haben, insbesondere mit String-Schl√ºsseln.  Cassandra hat einen speziellen Kartentyp f√ºr sie.  Es ist auch typisiert und hat zwei Typparameter.  Damit k√∂nnen wir f√ºr jeden Schl√ºssel einen passenden Typ erstellen <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Anwendungsdatentyp</b> <br></td><td>  <b>Datentyp in Cassandra</b> <br></td></tr><tr><td>  Karte [K, V] <br></td><td>  eingefroren &lt;map "k, v"&gt; <br></td></tr></tbody></table></div><br>  Es gibt Datentypen, die wir selbst in unserer Anwendung definieren.  In vielen Sprachen werden sie als <b>algebraische Datentypen bezeichnet</b> .  Sie werden definiert, indem ein benanntes Produkt von Typen definiert wird, dh eine Struktur.  Wir weisen diese Struktur dem benutzerdefinierten Typ zu.  Jedes Feld der Struktur entspricht einem Feld in der UDT. <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Anwendungsdatentyp</b> <br></td><td>  <b>Datentyp in Cassandra</b> <br></td></tr><tr><td>  Typ Produkt: Fallklasse <br></td><td>  UDT <br></td></tr></tbody></table></div><br>  Der zweite Typ ist die <b>algebraische Summe der Typen</b> .  In diesem Fall entspricht der Typ mehreren zuvor bekannten Subtypen oder Unterarten.  In gewisser Weise weisen wir ihm auch eine Struktur zu. <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Anwendungsdatentyp</b> <br></td><td>  <b>Datentyp in Cassandra</b> <br></td></tr><tr><td>  Typ Summe: versiegeltes Merkmal \ Klasse <br></td><td>  UDT <br></td></tr></tbody></table></div><br><h3>  Abstrakter Datentyp in UDT √ºbersetzen </h3><br>  Wir haben eine Struktur und zeigen sie eins zu eins an - f√ºr jedes Feld definieren wir das Feld in der erstellten UDT in Cassandra: <br><br><pre><code class="plaintext hljs">case class Account ( id: Long, tags: List[String], user: User, finData: Option[FinData] ) create type account ( id bigint, tags: frozen&lt;list&lt;text&gt;&gt;, user frozen&lt;user&gt;, fin_data frozen&lt;fin_data&gt; )</code> </pre> <br>  Primitive Typen werden zu primitiven Typen.  Ein Link zu einem vordefinierten Typ, bevor dieser eingefroren wird.  Dies ist ein spezieller Wrapper in Cassandra, was bedeutet, dass Sie nicht St√ºck f√ºr St√ºck aus diesem Feld lesen k√∂nnen.  Der Wrapper ist in diesem Zustand "eingefroren".  Wir k√∂nnen nur den Benutzer oder die Liste lesen oder speichern, wie im Fall von Tags. <br><br>  Wenn wir auf ein optionales Feld treffen, verwerfen wir dieses Merkmal.  Wir nehmen nur den Datentyp, der dem Feldtyp entspricht, der sein wird.  Wenn wir hier nicht treffen - das Fehlen eines Wertes - schreiben wir null in das entsprechende Feld.  Beim Lesen nehmen wir auch Korrespondenz ungleich Null entgegen. <br><br>  Wenn wir auf einen Typ treffen, der mehrere bekannte Alternativen aufweist, definieren wir in Cassandra auch einen neuen Datentyp.  F√ºr jede Alternative ein Feld in unserem Datentyp in UDT. <br><br>  Infolgedessen ist in dieser Struktur zu einem bestimmten Zeitpunkt nur eines der Felder nicht null.  Wenn Sie einen Benutzertyp kennengelernt haben und sich zur Laufzeit als Instanz eines Moderators herausstellte, enth√§lt das Moderatorfeld einen Wert, der Rest ist null.  F√ºr admin - admin ist der Rest - null. <br><br>  Auf diese Weise k√∂nnen Sie die Struktur wie folgt codieren: Wir haben 4 optionale Felder, wir garantieren, dass nur eines von ihnen geschrieben wird.  Cassandra verwendet nur ein Tag, um das Vorhandensein eines bestimmten Feldes in der Struktur zu identifizieren.  Dank dessen erhalten wir eine Speicherstruktur ohne Overhead. <br><br>  Um den Benutzertyp zu speichern, wird als Moderator dieselbe Anzahl von Bytes ben√∂tigt, die zum Speichern des Moderators erforderlich sind.  Plus ein Byte, um zu zeigen, welche bestimmte Alternative hier vorhanden ist. <br><br><h3>  Initialisierung </h3><br><blockquote>  Die Initialisierung ist ein vorl√§ufiges Verfahren, das abgeschlossen sein muss, bevor wir unseren Fallback verwenden k√∂nnen. </blockquote><br>  Wie funktioniert dieser Prozess? <br><br><ul><li>  Auf jedem Knoten generieren wir Definitionen von Tabellen, Typen und Abfragetexten basierend auf den dargestellten Typen. <br></li><li>  Lesen Sie das aktuelle Schema aus dem DBMS.  In Cassandra ist dies einfach, indem Sie einfach eine Verbindung herstellen.  Wenn eine Verbindung besteht, pumpt das "Sitzungs" -Objekt in fast allen Treibern die Metadaten des Schl√ºsselbereichs aus, mit denen es verbunden ist.  Dann k√∂nnen Sie sehen, was sie haben. <br></li><li>  Wir gehen die Metadaten durch, vergleichen und √ºberpr√ºfen, ob alles, was wir erstellen m√∂chten, zul√§ssig ist und ob eine inkrementelle Migration m√∂glich ist. <br></li><li>  Wenn alles normal ist und eine Initialisierung m√∂glich ist, f√ºhren wir die Migration durch. <br></li><li>  Wir bereiten Anfragen vor. <br></li></ul><br><pre> <code class="plaintext hljs">sealed trait User case class Anonymous extends User case class Registered extends User case class Moderator extends User case class Admin extends User create type user ( anonymous frozen&lt;anonymous&gt;, registered frozen&lt;registered&gt;, moderator frozen&lt;moderator&gt;, admin frozen&lt;admin&gt; )</code> </pre> <br>  Es passiert so.  Wir haben <b>Typen</b> , <b>Tabellen</b> und <b>Abfragen</b> .  Typen h√§ngen von anderen Typen ab, die von anderen.  Tabellen h√§ngen von diesen Typen ab.  Abfragen h√§ngen bereits von den Tabellen ab, aus denen sie Daten lesen.  Bei der Initialisierung werden alle diese Abh√§ngigkeiten √ºberpr√ºft und im DBMS alles erstellt, was nach bestimmten Regeln erstellt werden kann. <br><br><h3>  Geben Sie Migration ein </h3><br>  Wie kann festgestellt werden, dass ein Typ schrittweise migriert werden kann? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/105/eeb/554/105eeb554bcc5eadaf10753f8c150531.jpg"><br><br><ul><li>  Wir lesen, wie dieser Typ im DBMS definiert ist. <br></li><li>  Wenn es keinen solchen Typ gibt, haben wir uns einen neuen ausgedacht - wir erstellen ihn. <br></li><li>  Wenn ein solcher Typ bereits vorhanden ist, versuchen wir, die vorhandene Definition Feld f√ºr Feld mit der zu vergleichen, die wir diesem Typ geben m√∂chten. <br></li><li>  Wenn sich herausstellt, dass wir nur einige Felder hinzuf√ºgen m√∂chten, die nicht mehr existieren, tun wir dies.  Erstellen Sie eine Liste mutierender ALTER TYPE-Operationen und starten Sie sie. <br></li><li>  Wenn sich herausstellt, dass wir ein Feld eines anderen Typs haben, generieren wir einen Fehler.  Zum Beispiel gab es eine Liste - wurde zu einer Karte oder es gab einen Link zu einem benutzerdefinierten Typ, und wir versuchen, ihn anders zu machen. <br></li></ul><br>  Der Entwickler kann diesen Fehler sehen, noch bevor er die Funktionalit√§t in der Produktion startet.  Ich gehe davon aus, dass sich in seiner Entwicklungsumgebung genau das gleiche Datenschema befindet.  Er sieht, dass er irgendwie ein nicht migrierbares Datenschema erstellt hat, und um diese Fehler zu vermeiden, kann er die automatisch generierte Serialisierung √ºberschreiben, Optionen hinzuf√ºgen, Felder umbenennen oder alle Typen und Tabellen als Ganzes. <br><br><h3>  Initialisierung: Typen </h3><br>  Stellen Sie sich vor, es gibt verschiedene Arten von Definitionen: <br><br><pre> <code class="plaintext hljs">case class Product (id: Long, name: ctring, price: BigDecimal) case class UserOffers (valiDate: LocalDate, offers: Seq[Products]) case class UserProducts (user User, products: Map[Date, Product]) case class UserInfo: UserOffers, products: UserProducts)</code> </pre> <br>  <b>Fallklasse</b> - Eine Klasse, die eine Reihe von Feldern enth√§lt.  Dies ist ein Analogon von struct in Rust. <br><br>  Wir werden ungef√§hr solche Datendefinitionen f√ºr jeden der 4 Typen generieren - was wir schlie√ülich ankurbeln wollen: <br><br><pre> <code class="plaintext hljs">CREATE TYPE product (id bigint, name text, price decimal); CREATE TYPE user_offers (valid_date date, offers frozen&lt;list&lt;frozen&lt;offer&gt;&gt;&gt;); CREATE TYPE user_products (user frozen&lt;user&gt;, products frozen&lt;map&lt;date, frozen&lt;product&gt;&gt;); CREATE TYPE user_jnfo (offers: frozen&lt;user_offers&gt;, products: frozen&lt;user_products&gt;);</code> </pre> <br>  Die Art der user_offers h√§ngt von der Art des Angebots ab, user_products h√§ngt von der Art des Produkts ab, user_info vom zweiten und dritten Typ. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5bb/e3b/e9d/5bbe3be9d2694677b42b59613305752b.jpg"><br><br>  Wir haben eine solche Abh√§ngigkeit zwischen Typen und m√∂chten sie korrekt initialisieren.  Das Diagramm zeigt, dass wir user_offers und user_products parallel initialisieren.  Dies bedeutet nicht, dass wir zwei parallele Operationen starten werden.  Nein, wir starten alle Anweisungen, alle Analysen nacheinander, um nicht versehentlich denselben Typ in zwei parallelen Threads zu erstellen. <br><br>  Auf der Ebene der Fehlerkorrektur besteht jedoch eine gewisse Parallelit√§t.  Wenn ein Typfehler auftritt, wird bei allem, was davon abh√§ngt, der urspr√ºngliche Fehler abgerufen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/122/93f/0ba/12293f0bab8bd0a8b7e12d092380a5c5.jpg"><br><br>  Wenn ein Fehler von einem der parallelen Zweige generiert wird, wird alles, was von normal migrierten Daten abh√§ngt, fehlerfrei generiert.  Wenn es weitere Definitionen von Tabellen und vorbereitete Anweisungen gibt, k√∂nnen wir diesen Teil unseres Fallback-Cache sicher initialisieren.  Die Kommunikation geht nur mit einem Teil der Backends oder mit einigen Funktionen verloren.  Die restlichen werden initialisiert. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a8d/5ec/3a2/a8d5ec3a2483d899c7db16ac56974fe9.jpg"><br><br>  Es kann vorkommen, dass zwei gleichzeitig initialisierte Typen unterschiedliche Fehler erzeugen.  In diesem Fall f√ºhrt eine Funktionalit√§t, die von beiden Typen abh√§ngt, zu einem summierenden Fehlertyp.  Der Entwickler, der seinen Fallback in der Entwicklungsumgebung initialisiert, erh√§lt eine vollst√§ndige Liste der fehlerhaften Daten.  Nat√ºrlich kann er es hier beheben und den Fehler weiter bringen.  Es wird jedoch nicht so sein, dass ein v√∂llig unabh√§ngiger Zweig die Fehler schlie√üt, die wir bekommen k√∂nnten, unabh√§ngig von diesem Zweig. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d08/e94/4ba/d08e944ba9b210d16f6f6c0b57048051.jpg"><br><br><h3>  Initialisierung: Tabellen </h3><br>  Als n√§chstes erstellen wir die Tabellen. <br><br><pre> <code class="plaintext hljs">def getOffer (user: User, number: Long): Future[OfferData] create table get_offer( key frozen&lt;tuple&lt;frozen&lt;user&gt;, bigint&gt;&gt;PRIMARY KEY, value frozen&lt;friend_data&gt; )</code> </pre> <br>  Eine solche Anforderung kann direkt eine REST- oder SOAP-Anforderung starten, zus√§tzliche Vorg√§nge darin erstellen oder sogar mehrere Anforderungen ausf√ºhren.  Es h√§ngt alles von Ihrem Code ab - wie Sie den Code organisiert haben.  Fallback analysiert nicht vollst√§ndig, was innerhalb der Methode passiert, an der Sie einen solchen Stub aufh√§ngen. <br><br><blockquote>  Die Methode muss asynchron sein, da Fallback identisch ist. </blockquote><br>  In Scala ist dies mit einer besonderen Art von Zukunft gekennzeichnet.  Dies bedeutet, dass das Ergebnis eines Tages zur√ºckkehren wird.  Wann genau - es ist unbekannt: vielleicht sofort oder vielleicht auch nicht. <br><br>  Erstellen Sie f√ºr die Methode eine Tabelle.  Der Schl√ºssel in der Tabelle ist ein Tupel aller Typen, die den Parametern dieser Methode entsprechen.  Der Nichtschl√ºsselwert ist das Ergebnis, das asynchron zur√ºckgegeben wird.  F√ºr jede solche Tabelle bereiten wir im Voraus zwei parametrische Abfragen vor: Daten einf√ºgen und Daten lesen. <br><br><pre> <code class="plaintext hljs">insert into get_offer(key, value) values (?key, ?value); select value from get_offer where key = ?key;</code> </pre> <br>  Alles ist bereit, mit dem DBMS zu interagieren.  Es bleibt abzuwarten, wie wir Daten aus Fallback lesen werden. <br><br><h3>  Leistungsschalter </h3><br>  Hier geht die Verantwortung in die Zone des ber√ºhmten Leistungsschaltermusters √ºber. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c0/de1/91c/5c0de191c5c1699cc8f324f38d62b6ee.jpg"><br><br>  Ein typischer Leistungsschalter enth√§lt drei Zust√§nde. <br><br>  <b>Geschlossen - der standardm√§√üig geschlossene Zustand</b> , der unser Backend schlie√üt.  Das Prinzip ist, dass wir die Daten zuerst aus dem Backend lesen und nur dann zu Fallback gehen, wenn wir sie nicht erhalten konnten.  Wenn es uns gelungen ist, die Daten abzurufen, suchen wir nicht in Fallback, sondern speichern die Daten darin, und es passiert nichts. <br><br>  Wenn die Probleme nacheinander auftreten, gehen wir davon aus, dass das Backend liegt.  Um es nicht mit einer riesigen Menge neuer Anfragen zu spammen, wechseln wir zu <b>Open - in einem zerrissenen Zustand</b> .  Darin versuchen wir, Daten nur aus Fallback zu lesen.  Wenn es nicht funktioniert, geben wir sofort einen Fehler zur√ºck und ber√ºhren nicht einmal das Haupt-Backend. <br><br>  Nach einer Weile entscheiden wir uns herauszufinden, ob das Backend aufgewacht ist, und versuchen, den <b>halboffenen Zustand - einen kurzlebigen Zustand - zur√ºckzusetzen</b> .  Seine Lebensspanne ist eine Bitte. <br><br>  Im kurzlebigen Zustand entscheiden wir uns, wieder zu schlie√üen oder f√ºr eine noch l√§ngere Zeit zu √∂ffnen.  Wenn wir im halboffenen Zustand erfolgreich Fallback erreichen und die n√§chste Anfrage erhalten, gehen wir in den geschlossenen Zustand.  Wenn wir nicht durchkommen konnten, kehren wir zu Open zur√ºck, aber f√ºr eine lange Zeit. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ad/92e/4a4/9ad92e4a417201c8655ed4785ae21dfc.jpg"><br><br>  Wir haben zwei zus√§tzliche Zust√§nde hinzugef√ºgt, die eindeutig nicht mit der Leistungsschalterschaltung zusammenh√§ngen: <br><br><ul><li>  Erzwungener - gewaltsam geschlossener Zustand; <br></li><li>  Umgekehrt - Priorit√§t f√ºr offenen, geschlossenen Zustand invertiert. <br></li></ul><br>  Mal sehen, was sie tun. <br><br><h3>  Das Funktionsprinzip von Staaten </h3><br>  <b>Geschlossen</b>  Das Schema ist gro√ü, aber es reicht aus, um das allgemeine Prinzip daraus zu verstehen.  Wir behalten Fallback parallel dazu bei, wie wir das Ergebnis aus dem Backend zur√ºckgeben, wenn dort alles gut gelaufen ist und lesen aus Fallback.  Wenn es √ºberall schlecht ist, geben wir die Fehlerpriorit√§t zur√ºck. <br><br><blockquote>  W√§hlen Sie aus den beiden Fehlern den Backend-Fehler aus. </blockquote><br><img src="https://habrastorage.org/getpro/habr/post_images/5b7/541/f99/5b7541f99197cc1730c6a934cebe6516.jpg"><br><br>  Wenn keine Fehler vorliegen, erh√∂hen wir parallel dazu den Z√§hler und gehen in den ge√∂ffneten Zustand, wenn zu viele Anforderungen vorliegen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/182/18f/25d/18218f25de112cf7f6a88291fccbe72f.jpg"><br><br>  <b>√ñffnen</b>  Der offene Zustand von Open ist einfacher - wir lesen st√§ndig aus Fallback, egal was passiert, und nach einer Weile versuchen wir, in den halboffenen Zustand zu wechseln. <br><br>  <b>Halb offen</b> .  Der Zustand in der Struktur √§hnelt geschlossen.  Der Unterschied besteht darin, dass wir im Falle einer erfolgreichen Antwort in einen geschlossenen Zustand √ºbergehen.  Im Fehlerfall kehren wir mit einem l√§ngeren Intervall zum Open zur√ºck. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b82/a1e/7c8/b82a1e7c89774bbe327613b51f50f5c0.jpg"><br><br>  <b>Forced ist ein zus√§tzlicher Status zum Aufw√§rmen des Caches</b> .  Wenn wir es mit Daten f√ºllen, versucht es nie, aus Fallback zu lesen, sondern f√ºgt nur Datens√§tze hinzu. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdc/8e3/b33/bdc8e3b335750b826fdd21db6c0f0ac7.jpg"><br><br>  <b>Umgekehrt ist ein zweiter weit hergeholter Zustand</b> .  Es funktioniert wie ein persistenter Cache.  Wir aktivieren den Status, wenn wir die Last dauerhaft aus dem Backend entfernen m√∂chten, auch wenn die Daten m√∂glicherweise irrelevant sind.  Die ersten Suchvorg√§nge in Fallback wurden r√ºckg√§ngig gemacht. Wenn die Suche fehlgeschlagen ist, wird das Backend aufgerufen und behandelt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/618/0da/8ed/6180da8edf69398780bd37fae9bc8ba7.jpg"><br><br><h3>  Die Probleme </h3><br>  Bei diesem ganzen Schema hatten wir mehrere Probleme.  Am ernstesten ist es, zu verstehen, wie <b>vorbereitete Aussagen</b> in Cassandra funktionieren.  Dieses Problem wurde in Version 4.0 behoben, die noch nicht ver√∂ffentlicht wurde. Ich werde es Ihnen also sagen. <br><br>  Cassandra wurde entwickelt, um Millionen von Kunden gleichzeitig damit zu verbinden, und jeder versucht, seine vorbereiteten Aussagen vorzubereiten.  Nat√ºrlich bereitet Cassandra nicht jede vorbereitete Anweisung vor, da sonst der Speicherplatz knapp wird.  Es berechnet den MD5-Parameter basierend auf Text, Schl√ºsselraum und Abfrageoptionen.  Wenn sie genau dieselbe Anfrage mit genau demselben MD5 erh√§lt, nimmt sie die bereits vorbereitete Anfrage entgegen.  Es enth√§lt bereits Informationen zu Metadaten und deren Handhabung. <br><br>  Es gibt jedoch Versionsprobleme.  Wir ver√∂ffentlichen eine neue Version, die erfolgreich Migrationen durchgef√ºhrt, Felder in Typen hinzugef√ºgt und vorbereitete Anweisungen ausgef√ºhrt hat.  Sie kommen mit der vorherigen Version unseres Status und unserer Metadaten zur√ºck - mit Typen ohne Felder.  Zum Zeitpunkt des Lesens der Daten versuchen wir, ihre neuen erforderlichen Spalten zu schreiben, und sehen uns mit der Tatsache konfrontiert, dass sie einfach nicht existieren!  Cassandra sagt, dass dies im Allgemeinen ein anderer Typ ist, den sie nicht kennt. <br><br>  Wir haben dieses Problem wie folgt behandelt: Wir haben <b>jeder unserer vorbereiteten Anfrage einen eindeutigen Text hinzugef√ºgt</b> . <br><br><pre> <code class="plaintext hljs">create table get_offer( key frozen&lt;tuple&lt;frozen&lt;user&gt;, bigint&gt;&gt; PRIMARY KEY, value frozen&lt;friend_data&gt;, query_tag text ) insert into get_offer (key, value, query_tag) values (?key, ?value, 'tag_123'); select value as tag_123 from get_offer where key = ?key;</code> </pre> <br>  Wir werden nicht Millionen verbundener Clients haben, sondern nur eine Sitzung f√ºr jeden Knoten, der mehrere Verbindungen enth√§lt.  F√ºr jede vorbereitende Anweisung einmal.  Wir gehen davon aus, dass es in Ordnung ist, wenn f√ºr jede Version der Anwendung oder f√ºr jeden Start eines Knotens ein eindeutiger Text generiert wird, der eindeutig im Text unserer Anfrage enthalten ist. <br><br>  Wir haben ein spezielles Feld hinzugef√ºgt, um ihn auszutricksen.  Beim Einf√ºgen schreiben wir eine Konstante in dieses Feld.  Es ist f√ºr jeden Start oder jede Anwendungsversion eindeutig - dies wird in der Bibliothek konfiguriert.  Beim Lesen verwenden wir diesen Namen als Alias ‚Äã‚Äãf√ºr den Wert, den wir erhalten.  Die Anfrage ist genau die gleiche, wir machen immer noch einen ausgew√§hlten Wert, aber der Text ist anders.  Cassandra erkennt nicht, dass dies dieselbe Anforderung ist, berechnet eine andere MD5 und bereitet die Anforderung erneut mit neuen Metadaten vor. <br><br>  Das zweite Problem ist das <b>Migrationsrennen</b> .  Zum Beispiel m√∂chten wir mehrere parallele Migrationen durchf√ºhren.  Beginnen wir mit einigen Notizen und gleichzeitig starten sie Berechnungen, f√ºhren Tabellen erstellen und Typen erstellen aus.  Dies kann dazu f√ºhren, dass auf jedem Knoten oder in jedem der parallelen Threads alles erfolgreich ist und zwei Tabellen erfolgreich erstellt wurden.  Aber in Cassandra ist man verwirrt und wir werden eine Auszeit zum Schreiben und Lesen erhalten. <br><br><blockquote>  Sie k√∂nnen Cassandra unterbrechen, wenn Sie versuchen, Prozesse aus mehreren Threads oder aus mehreren Knoten zu parallelisieren. </blockquote><br>  Wenn wir wissen, dass eine Fallback-Migration erforderlich ist, <b>migrieren</b> wir <b>vor der Ver√∂ffentlichung von einem speziellen Knoten</b> .  Nur dann werden wir alle unsere Knoten w√§hrend der Ver√∂ffentlichung starten.  Also haben wir dieses Problem gel√∂st. <br><br>  Das dritte Problem ist der <b>Mangel an Daten im Fallback-Cache</b> .  Es mag sein, dass wir die Methode ‚Äûvoll unterst√ºtzt‚Äú haben, sie sollte historische Daten f√ºr ein Jahr speichern, aber in Wirklichkeit haben wir sie gestern gestartet. <br><br>  <b>Das Problem wurde durch Aufw√§rmen gel√∂st</b> .  Wir haben den Status "Erzwungen" verwendet und spezielle Knoten gestartet, die nicht mit echten Benutzern kommunizieren.  Sie nehmen alle m√∂glichen Schl√ºssel, die wir annehmen, und erw√§rmen den Cache in einem Kreis.  Das Aufw√§rmen geht so schnell, dass das Backend, aus dem wir lesen, nicht zerst√∂rt wird. <br><br><blockquote>  Skalierung von Anwendungen, Backend, Big Data und Frontend - Scala ist daf√ºr geeignet.  Am 26. November veranstalten wir eine professionelle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Konferenz f√ºr Scala-Entwickler</a> .  Stile, Ans√§tze, Dutzende von L√∂sungen f√ºr das gleiche Problem, die Nuancen der Verwendung alter und bew√§hrter Ans√§tze, die Praxis der funktionalen Programmierung, die Theorie der radikalen funktionalen Kosmonautik - dar√ºber werden wir auf der Konferenz sprechen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beantragen Sie</a> einen Bericht, wenn Sie Ihre Scala-Erfahrung vor dem 26. September teilen m√∂chten, oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">buchen Sie Ihre Tickets</a> . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de466295/">https://habr.com/ru/post/de466295/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de466283/index.html">Opencartforum und Freunde</a></li>
<li><a href="../de466285/index.html">Ein kleines Werbegeschenk: Tombola Combo DVR und Radarwarner</a></li>
<li><a href="../de466287/index.html">2019 National Internet Segments Reliability Research & Report</a></li>
<li><a href="../de466289/index.html">Legislative Initiativen. Seltsam, aber der Staatsduma vorgestellt</a></li>
<li><a href="../de466291/index.html">Nachhaltigkeitsumfrage der nationalen Internet-Segmente f√ºr 2019</a></li>
<li><a href="../de466299/index.html">Russische Soziologen f√ºhrten die weltweit erste Chatbots-Umfrage durch</a></li>
<li><a href="../de466301/index.html">Noch etwas: Haiku-App-Pakete?</a></li>
<li><a href="../de466305/index.html">Takashi Kokubun: Wie man Ruby-Anwendungen schneller laufen l√§sst</a></li>
<li><a href="../de466307/index.html">Wie gestalte ich SCS?</a></li>
<li><a href="../de466311/index.html">SLS Workshop 6. September</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
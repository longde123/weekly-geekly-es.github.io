<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèº ‚õ¥Ô∏è üë©üèø‚Äçü§ù‚Äçüë®üèª La s√©curit√© des algorithmes d'apprentissage automatique. Protection et test de mod√®les √† l'aide de Python ü§∞ üçú üëÇüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans l'article pr√©c√©dent, nous avons parl√© d'un probl√®me d'apprentissage automatique tel que les exemples contradictoires et certains types d'attaques...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La s√©curit√© des algorithmes d'apprentissage automatique. Protection et test de mod√®les √† l'aide de Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dsec/blog/438644/"><p><img src="https://habrastorage.org/webt/wo/o_/u2/woo_u2i8ll_fqrqvt3o-typrlue.jpeg" alt="image"></p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dans l'article pr√©c√©dent,</a> nous avons parl√© d'un probl√®me d'apprentissage automatique tel que les exemples contradictoires et certains types d'attaques qui permettent de les g√©n√©rer.  Cet article se concentrera sur les algorithmes de protection contre ce type d'effet et les recommandations pour tester les mod√®les. </p><a name="habracut"></a><br><h2 id="zaschita">  La protection </h2><br><p>  Tout d'abord, expliquons imm√©diatement un point - il est impossible de se d√©fendre compl√®tement contre un tel effet, et c'est tout √† fait naturel.  En effet, si nous r√©solvions compl√®tement le probl√®me des exemples contradictoires, nous r√©soudrions simultan√©ment le probl√®me de la construction d'un hyperplan id√©al, ce qui, bien s√ªr, ne peut se faire sans un ensemble de donn√©es g√©n√©rales. </p><br><p>  La d√©fense d'un mod√®le d'apprentissage automatique se d√©roule en deux √©tapes: </p><br><p>  <strong>Apprentissage</strong> - Nous enseignons √† notre algorithme √† r√©pondre correctement aux exemples contradictoires. </p><br><p>  <strong>Fonctionnement</strong> - nous essayons de d√©tecter un exemple contradictoire pendant la phase de fonctionnement du mod√®le. </p><br><p>  Il vaut la peine de dire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tout de</a> suite que vous pouvez utiliser les m√©thodes de protection pr√©sent√©es dans cet article √† l'aide de IBM <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Adversarial Robustness Toolbox</a> . </p><br><h3 id="adversarial-training">  Formation contradictoire </h3><br><p><img src="https://habrastorage.org/webt/4w/t_/lm/4wt_lmm-cbcdye9rabryki0jj70.png" alt="image"></p><br><p> Si vous demandez √† une personne qui vient de se familiariser avec le probl√®me contradictoire avec des exemples, la question: ¬´Comment vous prot√©ger de cet effet?¬ª, Alors certainement 9 personnes sur 10 diront: ¬´Ajoutons les objets g√©n√©r√©s √† l'ensemble de formation¬ª.  Cette approche a √©t√© imm√©diatement propos√©e dans l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Intriguing properties of neural networks</a> en 2013.  C'est dans cet article que ce probl√®me a √©t√© d√©crit pour la premi√®re fois et l'attaque L-BFGS, qui permet de recevoir des exemples contradictoires. </p><br><p>  Cette m√©thode est tr√®s simple.  Nous g√©n√©rons des exemples contradictoires en utilisant diff√©rents types d'attaques et les ajoutons √† l'ensemble de formation √† chaque it√©ration, augmentant ainsi la ¬´r√©sistance¬ª du mod√®le contradictoire aux exemples. </p><br><p>  L'inconv√©nient de cette m√©thode est assez √©vident: √† chaque it√©ration de la formation, pour chaque exemple, nous pouvons g√©n√©rer un tr√®s grand nombre d'exemples, respectivement, et le temps de mod√©lisation de la formation augmente de nombreuses fois. </p><br><p>  Vous pouvez appliquer cette m√©thode √† l'aide de la biblioth√®que ART-IBM comme suit. </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> art.defences.adversarial_trainer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> AdversarialTrainer trainer = AdversarialTrainer(model, attacks) trainer.fit(x_train, y_train)</code> </pre> <br><h3 id="gaussian-data-augmentation">  Augmentation des donn√©es gaussiennes </h3><br><p><img src="https://habrastorage.org/webt/jf/9d/ko/jf9dkoia9fom1rtqkvgwe-7aulo.png" alt="image"></p><br><p>  La m√©thode suivante, d√©crite dans l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Efficient Defenses Against Adversarial Attacks</a> , utilise une logique similaire: elle sugg√®re √©galement d'ajouter des objets suppl√©mentaires √† l'ensemble d'entra√Ænement, mais contrairement √† Adversarial Training, ces objets ne sont pas des exemples contradictoires, mais des objets d'ensemble d'entra√Ænement l√©g√®rement bruyants (le gaussien est utilis√© comme bruit). bruit, d'o√π le nom de la m√©thode).  Et, en effet, cela semble tr√®s logique, car le principal probl√®me des mod√®les est pr√©cis√©ment leur faible immunit√© au bruit. </p><br><p>  Cette m√©thode montre des r√©sultats similaires √† la formation contradictoire, tout en passant beaucoup moins de temps √† g√©n√©rer des objets pour la formation. </p><br><p>  Vous pouvez appliquer cette m√©thode √† l'aide de la classe GaussianAugmentation dans ART-IBM </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> art.defences.gaussian_augmentation <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GaussianAugmentation GDA = GaussianAugmentation() new_x = GDA(x_train)</code> </pre> <br><h3 id="label-smoothing">  Lissage des √©tiquettes </h3><br><p>  La m√©thode de lissage d'√©tiquette est tr√®s simple √† mettre en ≈ìuvre, mais comporte n√©anmoins beaucoup de sens probabiliste.  Nous n'entrerons pas dans les d√©tails de l'interpr√©tation probabiliste de cette m√©thode; vous pouvez la trouver dans l'article original <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Repenser l'architecture de d√©marrage pour la vision par ordinateur</a> .  Mais, pour le dire bri√®vement, le lissage d'√©tiquette est un type suppl√©mentaire de r√©gularisation du mod√®le dans le probl√®me de classification, ce qui le rend plus r√©sistant au bruit. </p><br><p>  En fait, cette m√©thode lisse les √©tiquettes de classe.  Les faire, disons, non pas 1, mais 0,9.  Ainsi, les mod√®les de formation sont condamn√©s √† une amende pour une "confiance" beaucoup plus grande dans l'√©tiquette d'un objet particulier. </p><br><p>  L'application de cette m√©thode en Python peut √™tre vue ci-dessous. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> art.defences.label_smoothing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LabelSmoothing LS = LabelSmoothing() new_x, new_y = LS(train_x, train_y)</code> </pre> <br><h3 id="bounded-relu">  Relu born√© </h3><br><p><img src="https://habrastorage.org/webt/dw/mw/sz/dwmwszowk1t9l6byacxcscvmvh4.png" alt="image"></p><br><p>  Lorsque nous avons parl√© d'attaques, beaucoup ont pu remarquer que certaines attaques (JSMA, OnePixel) d√©pendent de la force du gradient √† un moment ou √† un autre de l'image d'entr√©e.  La m√©thode simple et ¬´bon march√©¬ª (en termes de co√ªts de calcul et de temps) de Bounded ReLU tente de r√©soudre ce probl√®me. </p><br><p>  L'essence de la m√©thode est la suivante.  Rempla√ßons la fonction d'activation de ReLU dans un r√©seau de neurones par la m√™me, qui est limit√©e non seulement par le bas, mais aussi par le haut, lissant ainsi les cartes de gradient, et √† des points sp√©cifiques, il ne sera pas possible d'obtenir un splash, ce qui ne vous permettra pas de tromper l'algorithme en changeant un pixel de l'image. </p><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0" height="0.25ex" viewBox="0 -53.9 0 107.7" role="img" focusable="false" style="vertical-align: -0.125ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"></script></p><br>  \ begin {√©quation *} f (x) = <br>  \ begin {cases} <br>  0, x &lt;0 <br>  \\ <br>  x, 0 \ leq x \ leq t <br>  \\ <br>  t, x&gt; t <br>  \ end {cases} <br>  \ end {√©quation *} <p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0" height="0.25ex" viewBox="0 -53.9 0 107.7" role="img" focusable="false" style="vertical-align: -0.125ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"></script></p><br><p>  Cette m√©thode a √©galement √©t√© d√©crite dans l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Efficient Defenses Against Adversarial Attacks</a> </p><br><h3 id="postroenie-ansambley-modeley">  Building Model Ensembles </h3><br><p><img src="https://habrastorage.org/webt/cq/2i/pg/cq2ipgeru_vavdrnk-usoydtlxw.png" alt="image"><br>  Il n'est pas difficile de tromper un mod√®le form√©.  Tromper deux mod√®les en m√™me temps avec un m√™me objet est encore plus difficile.  Et s'il y a N de tels mod√®les?  C'est sur cette base que repose la m√©thode d'ensemble des mod√®les.  Nous construisons simplement N mod√®les diff√©rents et agr√©gons leur sortie en une seule r√©ponse.  Si les mod√®les sont √©galement repr√©sent√©s par diff√©rents algorithmes, alors il est extr√™mement difficile de tromper un tel syst√®me, mais c'est extr√™mement difficile! </p><br><p>  Il est tout √† fait naturel que la mise en place d'ensembles de mod√®les soit une approche purement architecturale, posant beaucoup de questions (Quels mod√®les de base prendre? Comment agr√©ger les sorties des mod√®les de base? Y a-t-il une relation entre les mod√®les? Et ainsi de suite).  Pour cette raison, cette approche n'est pas impl√©ment√©e dans ART-IBM </p><br><h3 id="feature-squeezing">  Fonctionnalit√© de compression </h3><br><p><img src="https://habrastorage.org/webt/sn/wy/wp/snwywpuqqae7pun4njrlmluseeg.png" alt="image"><br>  Cette m√©thode, d√©crite dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Feature Squeezing: Detecting Adversarial Exemples in Deep Neural Networks</a> , fonctionne pendant la phase op√©rationnelle du mod√®le.  Il vous permet de d√©tecter des exemples contradictoires. </p><br><p>  L'id√©e derri√®re cette m√©thode est la suivante: si vous entra√Ænez n mod√®les sur les m√™mes donn√©es, mais avec des taux de compression diff√©rents, les r√©sultats de leur travail seront toujours similaires.  Dans le m√™me temps, l'exemple Adversarial, qui fonctionne sur le r√©seau source, √©chouera tr√®s probablement sur des r√©seaux suppl√©mentaires.  Ainsi, compte tenu de la diff√©rence par paire entre les sorties du r√©seau neuronal initial et celles suppl√©mentaires, en choisissant le maximum parmi elles et en le comparant avec un seuil pr√©s√©lectionn√©, nous pouvons affirmer que l'objet d'entr√©e est soit contradictoire soit absolument valide. </p><br><p>  Voici une m√©thode pour obtenir des objets compress√©s √† l'aide de ART-IBM </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> art.defences.feature_squeezing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> FeatureSqueezing FS = FeatureSqueezing() new_x = FS(train_x)</code> </pre> <br><p>  Nous terminerons avec les m√©thodes de protection.  Mais il serait faux de ne pas saisir un point important.  Si un attaquant n'a pas acc√®s aux entr√©es et sorties du mod√®le, il ne comprendra pas comment les donn√©es brutes sont trait√©es √† l'int√©rieur de votre syst√®me avant d'entrer dans le mod√®le.  Alors et seulement alors, toutes ses attaques seront r√©duites au tri al√©atoire des valeurs d'entr√©e, ce qui est naturellement peu susceptible de conduire au r√©sultat souhait√©. </p><br><h2 id="testirovanie">  Test </h2><br><p>  Parlons maintenant des tests d'algorithmes pour contrer les exemples contradictoires.  Ici, tout d'abord, il est n√©cessaire de comprendre comment nous allons tester notre mod√®le.  Si nous supposons que l'attaquant peut acc√©der de mani√®re compl√®te √† l'int√©gralit√© du mod√®le, il est n√©cessaire de tester notre mod√®le √† l'aide des m√©thodes d'attaque WhiteBox. <br><img src="https://habrastorage.org/webt/vj/pm/-w/vjpm-wuwle8c5sngov5ksw5iahq.png" alt="image"></p><br><p>  Dans un autre cas, nous supposons qu'un attaquant n'aura jamais acc√®s aux "entrailles" de notre mod√®le, mais il pourra, quoique indirectement, influencer les donn√©es d'entr√©e et voir le r√©sultat du mod√®le.  Ensuite, vous devez appliquer les m√©thodes d'attaques BlackBox. <br><img src="https://habrastorage.org/webt/xc/h9/wo/xch9wo0pweqhlf33pzgrgdiihqm.png" alt="image"></p><br><p>  L'algorithme de test g√©n√©ral peut √™tre d√©crit avec l'exemple suivant: </p><br><p><img src="https://habrastorage.org/webt/1d/p_/lx/1dp_lxdocm0zkd2ssmbg_fmnvba.jpeg" alt="image"></p><br><p>  Soit un r√©seau neuronal form√© √©crit en TensorFlow (TF NN).  Nous affirmons de mani√®re experte que notre r√©seau peut tomber entre les mains d'un attaquant en p√©n√©trant dans le syst√®me o√π se trouve le mod√®le.  Dans ce cas, nous devons effectuer des attaques WhiteBox.  Pour ce faire, nous d√©finissons un pool d'attaques et des frameworks (FoolBox - FB, CleverHans - CH, Adversarial robustness toolbox - ART) qui permettent de mettre en ≈ìuvre ces attaques.  Ensuite, en comptant le nombre d'attaques r√©ussies, nous calculons le taux de r√©ussite (SR).  Si SR nous convient, nous terminons les tests, sinon nous utilisons l'une des m√©thodes de protection, par exemple, mises en ≈ìuvre dans ART-IBM.  Ensuite, nous menons des attaques et consid√©rons SR.  Nous faisons cette op√©ration de fa√ßon cyclique, jusqu'√† ce que SR nous convienne. </p><br><h2 id="vyvody">  Conclusions </h2><br><p>  Je voudrais terminer ici avec des informations g√©n√©rales sur les attaques, les d√©fenses et les tests de mod√®les d'apprentissage automatique.  En r√©sumant les deux articles, nous pouvons conclure ce qui suit: </p><br><ol><li>  Ne croyez pas au machine learning comme une sorte de miracle qui peut r√©soudre tous vos probl√®mes. </li><li>  Lorsque vous appliquez des algorithmes d'apprentissage automatique dans vos t√¢ches, pensez √† la r√©sistance de cet algorithme √† une telle menace que les exemples contradictoires. </li><li>  Vous pouvez prot√©ger l'algorithme √† la fois du c√¥t√© de l'apprentissage automatique et du c√¥t√© du syst√®me dans lequel ce mod√®le est utilis√©. </li><li>  Testez vos mod√®les, en particulier dans les cas o√π le r√©sultat du mod√®le affecte directement la d√©cision </li><li>  Des biblioth√®ques telles que FoolBox, CleverHans, ART-IBM fournissent une interface pratique pour attaquer et d√©fendre les mod√®les d'apprentissage automatique. </li></ol><br><p>  Dans cet article, je voudrais √©galement r√©sumer le travail avec les biblioth√®ques FoolBox, CleverHans et ART-IBM: </p><br><p>  FoolBox est une biblioth√®que simple et compr√©hensible pour attaquer les r√©seaux de neurones, prenant en charge de nombreux cadres diff√©rents. </p><br><p>  CleverHans est une biblioth√®que qui vous permet de mener des attaques en modifiant de nombreux param√®tres de l'attaque, un peu plus compliqu√© que FoolBox, supporte moins de frameworks. </p><br><p>  ART-IBM est la seule biblioth√®que de ce qui pr√©c√®de qui vous permet de travailler avec des m√©thodes de s√©curit√©, jusqu'√† pr√©sent, elle ne prend en charge que TensorFlow et Keras, mais elle se d√©veloppe plus rapidement que les autres. </p><br><p>  Ici, il convient de dire qu'il existe une autre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">biblioth√®que</a> pour travailler avec des exemples contradictoires de Baidu, mais, malheureusement, elle ne convient qu'aux personnes qui parlent chinois. </p><br><p>  Dans le prochain article sur ce sujet, nous analyserons une partie de la t√¢che qui devait √™tre r√©solue lors de ZeroNights HackQuest 2018 en trompant un r√©seau neuronal typique √† l'aide de la biblioth√®que FoolBox. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr438644/">https://habr.com/ru/post/fr438644/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr438634/index.html">Dans les bureaux, il fait trop chaud ou trop froid: existe-t-il une meilleure fa√ßon de r√©gler la temp√©rature?</a></li>
<li><a href="../fr438636/index.html">Incorporation d√©fectueuse de fonctions dans Go</a></li>
<li><a href="../fr438638/index.html">Nous analysons le protocole des messages pager POCSAG, partie 2</a></li>
<li><a href="../fr438640/index.html">Monnaie √©lectronique ouverte √† grande vitesse</a></li>
<li><a href="../fr438642/index.html">Les bases de la programmation r√©active √† l'aide de RxJS</a></li>
<li><a href="../fr438646/index.html">√Ä propos de la cr√©ation d'images st√©r√©o √† petit budget sur les doigts (st√©r√©ogramme, anaglyphe, st√©r√©oscope)</a></li>
<li><a href="../fr438648/index.html">Comparaison des syst√®mes de BI (Tableau, Power BI, Oracle, Qlik)</a></li>
<li><a href="../fr438650/index.html">Rocket 9M729. Quelques mots sur le ¬´violateur¬ª du trait√© INF</a></li>
<li><a href="../fr438652/index.html">IDA de portabelization</a></li>
<li><a href="../fr438654/index.html">OpenSceneGraph: int√©gration avec Qt Framework</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
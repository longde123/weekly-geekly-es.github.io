<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèáüèΩ üëçüèæ ü§Æ Cargo Cult for AI: El mito de la inteligencia artificial sobrehumana üëÜüèæ üëäüèæ üßê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Escuch√© que en el futuro, la IA de la computadora se volver√° m√°s inteligente que nosotros que nos quitar√°n todos nuestros trabajos y recursos, y la ge...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cargo Cult for AI: El mito de la inteligencia artificial sobrehumana</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/403999/"><img src="https://habrastorage.org/getpro/geektimes/post_images/f29/b7c/50b/f29b7c50b4fd97573f28f8508e94a9a0.jpg" alt="imagen"><br><br>  Escuch√© que en el futuro, la IA de la computadora se volver√° m√°s inteligente que nosotros que nos quitar√°n todos nuestros trabajos y recursos, y la gente morir√°.  Es asi? <br><br>  Esta es la pregunta m√°s com√∫n que me hacen en mis discursos sobre IA.  Las personas que le preguntan est√°n sinceramente preocupadas, y su preocupaci√≥n proviene de otras personas, expertos que hacen la misma pregunta.  Entre ellos puedes conocer a las personas m√°s inteligentes que viven hoy, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Stephen Hawking</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Elon Musk</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Max Tegmark</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Sam Harris</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Bill Gates</a> , y todos creen en la posibilidad de tal escenario.  En una reciente conferencia sobre IA, un comit√© de las nueve personas con m√°s conocimientos sobre IA acord√≥ que no podr√≠amos evitar el advenimiento de la IA sobrehumana. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/h0962biiZa4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Pero este escenario de conquistar el mundo de la IA incluye cinco suposiciones que, como resultado de un estudio cuidadoso, no se basan en evidencia.  Estas declaraciones pueden estar justificadas en el futuro, pero ahora ninguna de ellas tiene evidencia.  Estos son los supuestos: <br><br>  1. La IA ya se est√° volviendo m√°s inteligente que nosotros, y su poder est√° creciendo exponencialmente. <br>  2. Crearemos una IA general similar a la nuestra. <br>  3. Somos capaces de crear inteligencia humana basada en silicio. <br>  4. El intelecto puede crecer sin l√≠mites. <br>  5. Despu√©s de la explosi√≥n de la superinteligencia, nos ayudar√° a resolver todos nuestros problemas. <br><br>  Como una objeci√≥n a este canon ortodoxo, dar√© cinco declaraciones her√©ticas que, a mi parecer, tienen m√°s razones. <br><br>  1. La inteligencia no es unidimensional, por lo que el concepto de "m√°s inteligente que las personas" no tiene sentido. <br>  2. Ni los humanos ni la IA tienen conciencia de prop√≥sito general. <br>  3. La emulaci√≥n del pensamiento humano en otros medios estar√° limitada por el costo de su creaci√≥n. <br>  4. Las dimensiones de la inteligencia no son infinitas. <br>  5. La inteligencia es solo uno de los factores de progreso. <br><br>  Si la expectativa de la aparici√≥n de IA sobrehumana (SII) se basa en cinco supuestos clave que no tienen evidencia, entonces esta idea es m√°s como una creencia religiosa o un mito.  A continuaci√≥n, ampliar√© cada uno de mis cinco supuestos contrarios, y demostrar√© que SII es en realidad un mito. <br><br><h2>  1) </h2><br>  El concepto err√≥neo m√°s com√∫n sobre la IA comienza con el concepto err√≥neo sobre la inteligencia natural.  Consiste en el hecho de que la inteligencia es unidimensional.  La mayor√≠a de los t√©cnicos tienden a retratar la inteligencia como lo hace <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nick Bostrom</a> en Superinteligencia, como un gr√°fico lineal unidimensional con una amplitud creciente. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2c1/36a/b2f/2c136ab2fc2e0fd8904bff67561b5252.png" alt="imagen"><br><br>  Por un lado, hay poca inteligencia, por ejemplo, un animal peque√±o;  por otro lado, un genio alto, por ejemplo, como si la inteligencia se pudiera representar como un nivel de sonido en decibelios.  Por supuesto, en este caso es f√°cil imaginar que el volumen de inteligencia contin√∫a creciendo y, como resultado, excede nuestro nivel altamente intelectual y se convierte en un intelecto ultra ruidoso: ¬°un rugido!  - inaccesible para nosotros y m√°s all√° del horario. <br><br>  Este modelo es topol√≥gicamente equivalente a una escalera en la que cada paso posterior de inteligencia es un paso m√°s alto que el anterior.  Los animales m√°s j√≥venes est√°n en los escalones inferiores, y la IA de alto nivel nos alcanzar√° y seguir√° los pasos anteriores.  La l√≠nea de tiempo de este evento no importa, solo importa el ranking: la m√©trica de la inteligencia creciente. <br><img src="https://habrastorage.org/getpro/geektimes/post_images/f8e/b81/319/f8eb81319d9ae2b95c5e2d0b627c974c.jpg" alt="imagen"><br><br>  El problema con este modelo es que es tan m√≠tico como la escalera de la evoluci√≥n.  Antes de Darwin, el mundo natural se consideraba una escalera en la que los animales m√°s j√≥venes se ubicaban debajo de la persona.  Incluso despu√©s de Darwin, era costumbre pensar en la evoluci√≥n como una "escalera", seg√∫n la cual los peces se convirtieron en reptiles, luego en mam√≠feros, luego en primates, en humanos, y cada etapa est√° en una "etapa de evoluci√≥n" ligeramente m√°s alta, y por lo tanto considerado m√°s inteligente que los anteriores.  Entonces la escalera de la inteligencia es consistente con la escalera de la existencia.  Pero estos modelos tienen un enfoque completamente no cient√≠fico. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/57d/f3e/7ed/57df3e7eda77f345c53819dc8a1945bc.png" alt="imagen"><br><br>  Una representaci√≥n m√°s precisa de la evoluci√≥n natural de las especies es un disco en expansi√≥n, como en la imagen de arriba, propuesta por primera vez por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">David Hillis</a> de la Universidad de Texas y creada a partir del ADN.  Este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mandala</a> geneal√≥gico comienza en el centro con las formas de vida m√°s primitivas, y luego se ramifica en el tiempo.  El tiempo se mueve hacia afuera, por lo que los nuevos tipos de vida que habitan el planeta hoy est√°n alrededor de la circunferencia.  Esta imagen enfatiza el hecho de la evoluci√≥n, que es dif√≠cil de aceptar: cada una de las especies que viven hoy est√° igualmente desarrollada evolutivamente.  Existen personas en este anillo junto con cucarachas, moluscos, helechos, zorros y bacterias.  Cada especie pas√≥ por una cadena continua de tres mil millones de a√±os de reproducci√≥n exitosa, lo que significa que las bacterias y cucarachas de hoy en d√≠a est√°n tan evolucionadas como los humanos.  No hay escalera <br><br>  Del mismo modo, no hay escalera para la inteligencia.  La inteligencia no es unidimensional.  Este es un complejo de muchos tipos y modos de reconocimiento, cada uno de los cuales es un continuo.  Tome la tarea m√°s simple de medir la inteligencia animal.  Si el intelecto fuera unidimensional, simplemente construir√≠amos los intelectos del loro, delf√≠n, caballo, ardilla, pulpo, ballena azul, gato y gorila en el orden ascendente correcto.  Pero hoy no tenemos evidencia cient√≠fica de la existencia de tal l√≠nea.  Una de las razones para esto podr√≠a ser la ausencia de una diferencia entre las inteligencias en los animales, pero tampoco vemos esto.  La zoolog√≠a est√° llena de ejemplos sorprendentes de diferencias en el pensamiento animal.  ¬øPero tal vez todos tienen una relativa "inteligencia general"?  Quiz√°s, pero para √©l no tenemos forma de medir y medir.  Tenemos muchas m√©tricas diferentes para muchos tipos de cognici√≥n. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/5ff/9f5/eb6/5ff9f5eb643fccb4b764519d6a804739.png" alt="imagen"><br><br>  En lugar de una sola l√≠nea con decibelios, un modelo de inteligencia m√°s preciso ser√≠a un gr√°fico de su espacio probabil√≠stico, como, por ejemplo, la figura anterior, que representa formas posibles.  La inteligencia es un continuo combinatorio.  Muchos nodos, cada uno de los cuales es un continuo, crean estructuras complejas y diversas en dimensiones superiores.  Algunos intelectos pueden ser muy complejos y tener muchos subnodos de pensamiento.  Otros pueden ser m√°s simples, pero se estiran m√°s, tomando un √°ngulo en el espacio.  Estos complejos, que llamamos intelectos, pueden considerarse sinfon√≠as que involucran muchos tipos de instrumentos.  Difieren no solo en volumen, sino tambi√©n en tono, melod√≠a, color, tempo, etc.  Se pueden representar como ecosistemas.  Y en este sentido, los diversos nodos-componentes del pensamiento dependen unos de otros y se crean juntos. <br><br>  Como dijo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Marvin Minsky</a> , las mentes humanas son comunidades de mentes.  Trabajamos en ecosistemas de pensamiento.  Tenemos muchos tipos de pensamiento dentro que se ocupan de muchos tipos de pensamiento: deducci√≥n, inducci√≥n, l√≥gica simb√≥lica, inteligencia emocional, l√≥gica espacial, memoria a corto plazo y memoria a largo plazo.  El sistema nervioso de nuestros intestinos tambi√©n es un cerebro de cierto tipo con su propio modo de pensar.  Pensamos no solo con un cerebro, pensamos con todo el cuerpo. <br><br>  Estos conjuntos de pensamiento var√≠an de individuo a individuo y de especie a especie.  La ardilla puede recordar la ubicaci√≥n exacta de varios miles de bellotas durante a√±os, lo que afecta completamente la mente humana.  Entonces, en este tipo de pensamiento, las prote√≠nas son superiores a los humanos.  Esta superpotencia est√° conectada con otros modos, desvaneci√©ndose en comparaci√≥n con la nuestra, y esta conexi√≥n toma la decisi√≥n de la ardilla.  En el reino animal hay muchos otros ejemplos de oportunidades que son superiores a los humanos, y tambi√©n se incluyen en diferentes sistemas. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/2ba/9d4/63b/2ba9d463b13bdcb6d36b7c749a90a1af.jpg" alt="imagen"><br><br>  Lo mismo es cierto para la IA.  Las mentes artificiales ya son superiores a los humanos en ciertas dimensiones.  Su calculadora es un genio en matem√°ticas, la memoria de Google ya es superior a la nuestra en cierta dimensi√≥n.  Creamos IA que se destacan en ciertos modos.  Podemos hacer algunas de estas cosas nosotros mismos, pero lo hacen mejor, por ejemplo, en los campos de probabilidad o matem√°ticas.  No tenemos otros modos de pensar: solo un motor de b√∫squeda puede recordar cada palabra en seis mil millones de p√°ginas web.  En el futuro, encontraremos tipos de pensamiento completamente nuevos que no tenemos, y de hecho, en la naturaleza viva.  Al inventar el vuelo artificial, nos inspiramos en los reg√≠menes de vuelo biol√≥gico, principalmente el aleteo de las alas.  Pero inventamos tales vuelos, con h√©lices y alas fijas, que eran desconocidos para el mundo biol√≥gico.  Este es el vuelo de otra persona.  Del mismo modo, presentaremos nuevas formas de pensar que no existen en la naturaleza.  En muchos casos, ser√°n modos nuevos, espec√≠ficos y peque√±os dise√±ados para un trabajo espec√≠fico, tal vez un tipo de razonamiento adecuado solo para estad√≠sticas y teor√≠a de la probabilidad. <br><br>  En otros casos, la nueva mente ser√° un conjunto complejo de los tipos de pensamiento que podemos usar para resolver problemas que no son susceptibles a nuestra inteligencia.  Muchos de los problemas m√°s complejos de los negocios y la ciencia pueden requerir una soluci√≥n de dos etapas.  Etapa uno: inventa un nuevo modo de pensar que pueda funcionar con nuestras mentes.  Segundo: combinarlos para resolver el problema.  Como resolvemos problemas que antes eran inaccesibles para nosotros, queremos llamar a este nuevo tipo de pensamiento "m√°s inteligente" que nosotros, pero en realidad es simplemente diferente de nosotros.  La principal ventaja de la IA es un pensamiento diferente.  Creo que es √∫til pensar en la IA como un pensamiento extraterrestre (o extraterrestres artificiales).  Su rareza ser√° su principal virtud. <br><br>  Al mismo tiempo, integraremos estos diferentes modos de pensamiento en comunidades m√°s complejas de la mente.  Algunos de estos complejos ser√°n m√°s complejos que los nuestros, porque pueden resolver problemas que son inaccesibles para nosotros, y luego alguien quiere llamarlos sobrehumanos.  Pero no llamamos Google SII, aunque su memoria supera la nuestra, porque hay muchas cosas que podemos hacer mejor que √©l.  Estos complejos de IA podr√°n superarnos en muchas dimensiones, pero nadie puede hacer todo lo que hacemos mejor que nosotros.  Esto se puede comparar con las habilidades f√≠sicas de las personas.  La Revoluci√≥n Industrial ya tiene 200 a√±os, y aunque en general las m√°quinas superan las habilidades f√≠sicas de una persona (velocidad de movimiento, levantamiento de pesas, corte preciso, etc.), no hay una m√°quina capaz de superar a la persona promedio en todo lo que hace. <br><br>  Y aunque la comunidad de mentes de IA se est√° volviendo m√°s compleja, esta complejidad a√∫n es dif√≠cil de medir cient√≠ficamente.  No tenemos buenas m√©tricas de complejidad que puedan determinar si el pepino de un Boeing 747 es m√°s dif√≠cil o describir c√≥mo difieren sus dificultades.  Esta es una de las razones por las que no tenemos buenas m√©tricas para la mente.  Ser√° muy dif√≠cil determinar si la mente A es m√°s dif√≠cil que la mente B y, por lo tanto, es dif√≠cil entender cu√°l de ellos es m√°s inteligente.  Pronto llegaremos a comprender que la mente no es unidimensional, y de hecho estamos interesados ‚Äã‚Äãen todas las formas en que el intelecto es capaz de funcionar, todos esos nodos de cognici√≥n que a√∫n no hemos descubierto. <br><br><h2>  2) </h2><br>  El segundo error relacionado con la inteligencia humana es nuestra creencia de que nuestra mente es universal, es una mente de prop√≥sito general.  Esta creencia ha llevado al surgimiento del objetivo a menudo declarado de los investigadores de IA de crear una IA generalizada, OII.  Sin embargo, si consideramos la inteligencia como un mayor espacio de posibilidades, no tiene un estado generalizado.  La inteligencia humana no est√° en una posici√≥n central alrededor de la cual giran otros intelectos especializados.  La inteligencia humana es un tipo de inteligencia muy, muy especial que surgi√≥ como resultado de millones de a√±os de evoluci√≥n para que nuestra especie sobreviva en este planeta.  Si lo coloca en el espacio de todas las inteligencias posibles, estar√° en alg√∫n lugar de la esquina, al igual que nuestro mundo est√° al borde de una gran galaxia. <br><br>  Definitivamente podemos imaginar e incluso inventar un pensamiento que se asemeje a un cuchillo suizo universal.  Hace un trabajo bastante bueno con muchas tareas, pero no le va muy bien con ninguna de ellas.  La IA seguir√° la misma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°xima de</a> ingenier√≠a que siguen todas las cosas creadas o nacidas: no puede optimizar cada dimensi√≥n.  Solo los compromisos son posibles.  No funcionar√° crear una unidad multifuncional generalizada superior a las especializadas.  Una mente grande, "capaz de cualquier cosa", no podr√° hacer todo esto tan bien como las especializadas.  Como creemos en la generalizaci√≥n de nuestra mente, creemos que el pensamiento no tiene que seguir compromisos de ingenier√≠a, que ser√° posible crear una inteligencia que maximice todos los modos de pensamiento.  Pero no hay evidencia de esto.  Todav√≠a no hemos inventado suficientes opciones para que la mente vea todo el espacio (y hasta ahora estamos barriendo las mentes de los animales, evalu√°ndolos con amplitud unidimensional). <br><br><h2>  3) </h2><br>  Parte de esta creencia proviene del concepto de computaci√≥n universal.  Esta suposici√≥n, descrita formalmente en 1950 como la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tesis de Church-Turing</a> , establece que todos los c√°lculos que alcanzan cierto umbral son equivalentes.  Por lo tanto, para todos los c√°lculos hay un n√∫cleo universal, y si se producen en una m√°quina con muchas partes r√°pidas o lentas, o en el cerebro biol√≥gico, todo esto es el mismo proceso l√≥gico.  Y esto significa que es posible emular cualquier proceso de computaci√≥n (pensamiento) en cualquier m√°quina capaz de computaci√≥n "universal".  Los partidarios de la singularidad se basan en este principio, esperando que podamos crear cerebros de silicio que puedan acomodar la mente humana, y que podamos crear una mente artificial que piense que los humanos son mucho m√°s inteligentes.  Esta esperanza deber√≠a ser esc√©ptica, porque se basa en un malentendido de la hip√≥tesis de la Iglesia-Turing. <br><br>  El punto de partida de esta hip√≥tesis es el siguiente: "Si hay una pel√≠cula (memoria) y tiempo infinitos, todos los c√°lculos son equivalentes".  El problema es que, en realidad, la computadora no tiene memoria y tiempo infinitos.  En el mundo real, el tiempo real es cr√≠tico, a menudo incluso una cuesti√≥n de vida o muerte.  S√≠, todo pensamiento puede ser equivalente si se ignora el tiempo.  S√≠, puede emular el pensamiento humano en cualquier matriz, siempre que ignore el tiempo o las limitaciones reales del almacenamiento de datos y memoria.  Sin embargo, al incluir el tiempo, ser√° posible redefinir sustancialmente este principio: "Dos sistemas inform√°ticos que se ejecutan en plataformas muy diferentes no ser√°n equivalentes en el tiempo".  O: "La √∫nica forma de obtener patrones de pensamiento similares es ejecutarlos en plataformas equivalentes".  La materia f√≠sica sobre la que funcionan los c√°lculos, especialmente cuando se vuelven m√°s complejos, afecta dram√°ticamente el tipo de pensamiento que puede funcionar con √©xito en tiempo real. <br><br>  Continuar√© con estos argumentos y dir√© que la √∫nica forma de lograr un proceso de pensamiento cercano al humano es realizar c√°lculos en tejidos blandos y h√∫medos similares al humano.  Esto significa que las IA muy grandes y complejas que funcionan con silicio seco nos dar√°n tipos de pensamiento grandes, complejos e inhumanos.  Si es posible crear un cerebro h√∫medo artificial usando neuronas crecidas similares a las humanas, entonces dir√≠a que sus pensamientos ser√°n muy similares a los nuestros.  Los beneficios de un cerebro tan h√∫medo son proporcionales a cu√°n similares podemos hacer la base.  El costo de crear tal "computadora humana" es enorme, y cuanto m√°s cerca est√© el tejido del tejido cerebral, m√°s rentable ser√° simplemente crear una persona.  Al final, podemos hacer esto en nueve meses. <br><br>  Adem√°s, como se indic√≥ anteriormente, pensamos con la ayuda de todo el cuerpo, y no solo con un solo cerebro.  Tenemos muchos datos que muestran que el sistema nervioso intestinal gu√≠a nuestro proceso de toma de decisiones "racional", que puede aprender y predecir eventos.  Cuanto m√°s modelamos el sistema del cuerpo humano, m√°s nos acercamos a reproducirlo.  La inteligencia que trabaja en un cuerpo muy diferente (silicio seco en lugar de carbono h√∫medo) pensar√° de manera diferente. <br><br>  Me parece que esto no es un error, sino una caracter√≠stica.  Como mencion√© en el p√°rrafo 2, la diferencia entre pensar y ser humano es la principal ventaja de la IA.  Esta es otra raz√≥n por la cual es err√≥neo decir que √©l es "m√°s inteligente que las personas". <br><br><h2>  4) </h2><br>  En el centro del concepto de inteligencia sobrehumana, en particular, la idea de que dicha inteligencia mejorar√° constantemente, yace en la creencia de que la escala de inteligencia es infinita.  No veo evidencia de esto.  Creer en esto ayuda a la idea err√≥nea de la unidimensionalidad de la inteligencia, pero esto es solo fe.  En el Universo, la ciencia no conoce de manera confiable dimensiones f√≠sicas infinitas.  La temperatura no es infinita: hay fr√≠o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">final</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">calor final</a> .  El tiempo y el espacio son finitos.  La velocidad final.  Quiz√°s la l√≠nea num√©rica en matem√°ticas es infinita, pero los atributos f√≠sicos tienen limitaciones.  Ser√° razonable decir que la mente misma es finita.  Entonces la pregunta es, ¬ød√≥nde est√° el l√≠mite de la inteligencia?  Tendemos a creer que est√° mucho m√°s all√° de nuestro alcance, es mucho m√°s "alto" que nosotros, tanto como nosotros somos "m√°s altos" que la hormiga.  Si dejamos el problema que surge constantemente de la unidimensionalidad, ¬øqu√© evidencia tenemos de que no hemos alcanzado este l√≠mite?  ¬øPor qu√© no podemos estar al m√°ximo? , ,       ?     ,   ‚Äì  ,    ? <br><br>      ,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">   </a> .           ,          ‚Äì           .         ,   ,  -    .     ¬´¬ª [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">The Inevitable</a> ]      ,    -  .    : <br><br> ‚Ä¢ ,   ,    (     ). <br> ‚Ä¢   ,     . <br> ‚Ä¢  ,       . <br> ‚Ä¢  ,     ,      . <br> ‚Ä¢  ,    ,      . <br> ‚Ä¢ ,        ,    - . <br> ‚Ä¢ ,      ,    . <br> ‚Ä¢ ,    ,         ,   . <br> ‚Ä¢ ,       . <br> ‚Ä¢ ,      ,          ,  .. <br> ‚Ä¢ ,      ,      . <br> ‚Ä¢    . <br> ‚Ä¢ ,    ,    . <br> ‚Ä¢   ,    . <br> ‚Ä¢ ,          . <br> ‚Ä¢   ,     ,          . <br> ‚Ä¢ ,      . <br> ‚Ä¢ ,   ,         . <br> ‚Ä¢  ,    . <br> ‚Ä¢    ,       . <br> ‚Ä¢ ,          . <br> ‚Ä¢ ,     . <br> ‚Ä¢ ,       . <br> ‚Ä¢    -. <br> ‚Ä¢    -. <br> ‚Ä¢ ,   ,     . <br><br>         ,                   . <br><br> ,        ( -  ), , ,   ,     .         ,    .      ,          .  ?     .    ,   ,   ?           ,   ,    .         .              10 . <br><br>            ,    ,       ,      .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> ,   ,       ,   ,      ,    .  : ¬´       ,      ‚Ä¶        ,         ,            .           ,      2029    ¬ª. <br><br>   ,   ,      ,      ,           .       .      ,       . <br><br> ,   ¬´ ¬ª,        ,      . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> ,    .   ,  ,   ,  .   ,    ¬´¬ª . <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/3ac/61d/4aa/3ac61d4aadb2feb04c55657530506604.jpg" alt="imagen"><br><br><h2>  5) </h2><br>  Otra, no refutada por nadie, la creencia en el advenimiento de FIS, no respaldada por evidencia, es que una superinteligencia de poder casi infinito resolver√° r√°pidamente todos nuestros principales problemas no resueltos. <br><br>  Muchos defensores de la explosi√≥n de inteligencia creen que conducir√° a una explosi√≥n de progreso.  Yo llamo a esta fe m√≠tica "pensismo".  Esta es una idea err√≥nea de que las etapas futuras del progreso son inalcanzables solo debido a la falta de poder mental o inteligencia.  Noto que la creencia de que pensar es una panacea m√°gica para todo es com√∫n entre muchas personas a las que les gusta pensar. <br><br>  Tome la cura del c√°ncer o la extensi√≥n de la vida.  No puedes resolver tales problemas con un solo pensamiento.  Ning√∫n pensamiento es suficiente para entender c√≥mo envejecen las c√©lulas o c√≥mo desaparecen los tel√≥meros.  Ning√∫n intelecto s√∫per tonto puede entender c√≥mo funciona el cuerpo humano simplemente leyendo toda la literatura cient√≠fica conocida en el mundo y reflexionando.  Ning√∫n FIC puede, simplemente pensando en todos los experimentos con fusi√≥n nuclear, producir un esquema de fusi√≥n nuclear que funcione.  Para superar el camino de no saber c√≥mo funciona algo a comprender c√≥mo funciona algo, se necesita mucho m√°s que solo pensar.  En el mundo real, se est√°n haciendo montones de experimentos, cada uno de los cuales conduce a la aparici√≥n de monta√±as de datos conflictivos que requieren m√°s experimentos para crear una hip√≥tesis de trabajo.  Pensar en datos potenciales no le dar√° los datos correctos. <br><br>  Pensar es solo una parte de la ciencia, quiz√°s incluso una peque√±a parte de ella.  Por ejemplo, no tenemos suficientes datos para acercarnos a resolver el problema de la muerte.  Cuando se trabaja con organismos vivos, casi todos los experimentos llevan tiempo.  El metabolismo celular lento no se puede dispersar.  Obtener resultados lleva a√±os, meses, al menos d√≠as.  Si queremos saber qu√© sucede con las part√≠culas subat√≥micas, no podemos pensar en ellas.  Necesitamos construir estructuras f√≠sicas enormes, complejas y astutas para descubrirlo.  Incluso si los f√≠sicos m√°s inteligentes fueran 1000 veces m√°s inteligentes que ahora, sin un colisionador no habr√≠an aprendido nada nuevo. <br><br>  No hay duda de que SRI puede acelerar el progreso de la ciencia.  Podemos hacer simulaciones por computadora de √°tomos o c√©lulas y acelerarlas muchas veces, pero dos problemas limitan la utilidad de las simulaciones.  La primera es que las simulaciones y los modelos pueden ir m√°s r√°pido que los procesos que se estudian solo porque no tenemos en cuenta algo.  Esta es la esencia de un modelo o simulaci√≥n.  Adem√°s, probar, verificar y probar estos modelos tambi√©n lleva mucho tiempo y debe ir a la velocidad de los procesos simulados.  La verificaci√≥n de la verdad no se puede acelerar. <br><br>  Estas versiones simplificadas son √∫tiles para filtrar los caminos m√°s prometedores y acelerar el progreso.  Pero en realidad no hay exceso;  todo lo que es real ejerce su influencia hasta cierto punto;  Esta es una de las definiciones de realidad.  Si comienza a bombear modelos y simulaciones con m√°s y m√°s datos, pronto queda claro que la realidad es m√°s r√°pida que su simulaci√≥n al 100%.  Esta es otra definici√≥n de realidad: la versi√≥n m√°s r√°pida posible de todos los detalles y grados de libertad presentes.  Si puede modelar todas las mol√©culas en c√©lulas y todas las c√©lulas del cuerpo humano, entonces la simulaci√≥n no funcionar√° tan r√°pido como el cuerpo humano.  No importa cu√°nto lo piense, necesitar√° tiempo para experimentar, ya sea un sistema real o una simulaci√≥n. <br><br>  Para ser √∫til, la IA necesita infiltrarse en el mundo real, y el mundo establecer√° la velocidad de su innovaci√≥n.  Sin realizar experimentos, construir prototipos, errores y experimentos con la realidad, la inteligencia puede pensar, pero no producir resultados.  No hay descubrimientos instant√°neos por minuto, hora, d√≠a o a√±o de ocurrencia de la llamada.  No se espera "IA sobrehumana".  Por supuesto, los √©xitos en el desarrollo de la IA aumentar√°n significativamente el n√∫mero de descubrimientos por unidad de tiempo, en particular, ya que la IA, a diferencia de las personas, har√° preguntas que las personas no har√≠an, pero incluso un intelecto extremadamente poderoso no garantiza un progreso instant√°neo en comparaci√≥n con nosotros.  Para resolver problemas, se necesita mucho m√°s que solo inteligencia. <br><br>  La inteligencia por s√≠ sola no podr√° resolver no solo los problemas del c√°ncer y la longevidad, sino tambi√©n los problemas del intelecto mismo.  Un mantra t√≠pico de los partidarios de la singularidad es que tan pronto como haces una IA que es "m√°s inteligente que una persona", de repente piensa e inventa una IA, "m√°s inteligente que √©l", que, a su vez, piensa a√∫n m√°s adecuadamente e inventa a√∫n m√°s. inteligencia artificial inteligente, y como resultado, todo terminar√° con una explosi√≥n de poder intelectual a un nivel casi divino.  No tenemos evidencia de que solo pensar en la inteligencia sea suficiente para crear nuevos niveles de inteligencia.  Tal pensamiento es fe.  Tenemos mucha evidencia de que, adem√°s de una gran cantidad de conocimiento, necesitamos experimentos, datos, pruebas y errores, preguntas inusualmente planteadas y todo lo dem√°s m√°s all√° del simple ingenio para inventar nuevos tipos de mentes que operan con √©xito. <br><br>  En conclusi√≥n, dir√© que puedo estar equivocado con mis declaraciones.  Estamos en las primeras etapas.  Podemos descubrir una m√©trica universal para la inteligencia;  Descubre su infinito en todas las direcciones.  Dado que sabemos muy poco acerca de qu√© es la inteligencia (sin mencionar la conciencia), la probabilidad de alg√∫n tipo de singularidad AI excede cero.  Me parece que toda la evidencia habla a favor de la baja probabilidad de tal escenario, pero esta probabilidad es distinta de cero. <br><br>  Entonces, aunque no estoy de acuerdo con su probabilidad, estoy de acuerdo con los objetivos m√°s amplios de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenAI</a> y las personas inteligentes preocupadas por la IED: que debemos crear IA amigables y pensar c√≥mo inculcarles valores que coincidan con los nuestros.  Y aunque creo que la IED es una amenaza existencial muy distante (que vale la pena considerar), creo que su peque√±a probabilidad (seg√∫n la evidencia disponible) no deber√≠a gobernar nuestra ciencia, pol√≠tica y desarrollo.  La colisi√≥n de un asteroide con la Tierra ser√≠a un desastre.  Su probabilidad es mayor que cero (por lo que debemos apoyar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el fondo B612</a> ), pero no debemos dar la posibilidad de un ataque de asteroides para gestionar nuestras decisiones, por ejemplo, en el campo del cambio clim√°tico, o los viajes espaciales, o incluso en la planificaci√≥n urbana. <br><br>  De la misma manera, la evidencia hasta ahora sugiere que la IA probablemente no sea sobrehumana, sino extrahumana, ser√°n cientos de nuevos tipos de pensamiento diferentes a los humanos, ninguno de los cuales resultar√° ser IA de prop√≥sito general, y ninguno de ellos se convertir√° en un dios, resolviendo al instante todos nuestros problemas.  En cambio, tendremos una galaxia de inteligencias limitadas, trabajando en dimensiones desconocidas, yendo m√°s all√° de nuestras capacidades en muchas de ellas, trabajando con nosotros para resolver problemas existentes y crear otros nuevos con el tiempo. <br><br>  Entiendo el encanto y el atractivo de SII-god.  Esto es algo as√≠ como Superman.  Pero, como Superman, esta es una figura m√≠tica.  En alg√∫n lugar del universo, Superman puede existir, pero la probabilidad de su existencia es extremadamente peque√±a.  Pero los mitos pueden ser √∫tiles y no desaparecer despu√©s de su invenci√≥n.  La idea de Superman no morir√°.  La idea de una singularidad de IA sobrehumana, una vez que se haya generado, tampoco morir√°.  Pero debemos entender que ahora es una idea religiosa, no cient√≠fica.  Si estudiamos los datos que tenemos hoy sobre inteligencia, artificial y natural, solo podemos concluir que nuestras discusiones sobre el m√≠tico dios SII son solo mitos. <br><br>  Muchas de las islas aisladas de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Micronesia</a> entraron en contacto por primera vez con el resto del mundo durante la Segunda Guerra Mundial.  Los dioses alien√≠genas volaron en sus cielos en p√°jaros ruidosos, arrojaron comida y bienes en sus islas, y no regresaron.  Los cultos religiosos aparecieron en las islas, rezando para que los dioses regresaran y arrojaran m√°s bienes.  Incluso ahora, cincuenta a√±os despu√©s, muchos todav√≠a esperan la devoluci√≥n de los bienes.  Es posible que el SRI sea otro culto a la carga.  Despu√©s de cien a√±os, las personas podr√°n mirar hacia atr√°s, en nuestro tiempo, en el momento en que los creyentes comenzaron a esperar la aparici√≥n de FIC, lo que les traer√≠a beneficios inimaginables.  D√©cada tras d√©cada, esperan la llegada de la IED, confiando en que con sus beneficios deber√≠a aparecer muy pronto. <br><br>  Pero la IA no sobrehumana ya es real aqu√≠.  Redefinimos constantemente este t√©rmino, aumentamos su complejidad y, como resultado, lo mantenemos en el futuro, pero en el sentido amplio de la definici√≥n de intelectos extra√±os, en un espectro continuo de diferentes mentes, intelectos, pensamientos, l√≥gicas, ense√±anzas y conciencias, la IA ya existe en el planeta y contin√∫a difundir, profundizar, diversificar e intensificar.  Ning√∫n invento anterior puede compararse con su poder sobre el mundo, y para fines de siglo la IA tocar√° y cambiar√° todos los aspectos de nuestras vidas.  Pero el mito de la inteligencia artificial sobrehumana, listo para dotarnos de abundancia o conducirnos a la s√∫per esclavitud (o ambas al mismo tiempo), aparentemente continuar√° viviendo; esta oportunidad es demasiado m√≠tica para rechazarla. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es403999/">https://habr.com/ru/post/es403999/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es403989/index.html">Camino de la rob√≥tica del campamento al creador de cyborg</a></li>
<li><a href="../es403991/index.html">Eritritol: un az√∫car sin carbohidratos para diab√©ticos que no afecta el √≠ndice gluc√©mico</a></li>
<li><a href="../es403993/index.html">Preg√∫ntele a Ethan: ¬øPor qu√© los rayos del sol se parecen a los rayos del sol?</a></li>
<li><a href="../es403995/index.html">Aqu√≠ est√°, nuestro verano: gadgets para las vacaciones</a></li>
<li><a href="../es403997/index.html">Conjunto joven biohacker</a></li>
<li><a href="../es404003/index.html">Qu√≠mica del mundo de la inform√°tica.</a></li>
<li><a href="../es404005/index.html">Bobina peque√±a, s√≠ querida: auriculares internos Fostex</a></li>
<li><a href="../es404007/index.html">GPD Win: explora una computadora port√°til en miniatura con una diagonal de 5.5 ", dise√±ada para juegos y emuladores</a></li>
<li><a href="../es404009/index.html">Controlamos la casa a trav√©s de Telegram.</a></li>
<li><a href="../es404011/index.html">Ahorro de sangre: se ha desarrollado un nuevo sistema de entrega de biomateriales de laboratorio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
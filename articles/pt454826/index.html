<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüíº üóìÔ∏è üî∑ Reduza os backups em 99,5% com hashget üî® üõçÔ∏è üöò</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O hashget √© um desduplicador gratuito baseado em √≥pera - um utilit√°rio semelhante ao arquivador que pode reduzir significativamente o tamanho dos back...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reduza os backups em 99,5% com hashget</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454826/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O hashget</a> √© um <em>desduplicador</em> gratuito baseado em √≥pera - um utilit√°rio semelhante ao arquivador que pode reduzir significativamente o tamanho dos backups, al√©m de organizar esquemas de backup incremental e diferencial e muito mais. </p><br><p>  Este √© um artigo de revis√£o para descrever os recursos.  O uso do hashget em si (bastante simples) √© descrito na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">README</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">wiki</a> do projeto. </p><br><h1 id="sravnenie">  Compara√ß√£o </h1><br><p>  De acordo com a lei do g√™nero, come√ßarei imediatamente com intrigas - comparando os resultados: </p><br><div class="scrollable-table"><table><thead><tr><th>  Amostra de dados </th><th>  tamanho descompactado </th><th>  .tar.gz </th><th>  hashget .tar.gz </th></tr></thead><tbody><tr><td>  Wordpress-5.1.1 </td><td>  43 Mb </td><td>  11 Mb (26%) </td><td>  155 Kb ( <strong>0,3%</strong> ) </td></tr><tr><td>  Linux kernel 5.0.4 </td><td>  934 Mb </td><td>  161 Mb (20%) </td><td>  4,7 Mb ( <strong>0,5%</strong> ) </td></tr><tr><td>  VM LXC do Debian 9 (LAMP) </td><td>  724 Mb </td><td>  165 Mb (23%) </td><td>  4,1 Mb ( <strong>0,5%</strong> ) </td></tr></tbody></table></div><br><h1 id="predystoriya-kakim-dolzhen-byt-idealnyy-i-effektivnyy-bekap">  Antecedentes do que um backup ideal e eficaz deve ser </h1><br><p> Toda vez que eu fazia um backup de uma m√°quina virtual criada recentemente, ficava assombrada com a sensa√ß√£o de estar fazendo algo errado.  Por que obtenho um backup pesado de um sistema em que minha inestim√°vel criatividade imperec√≠vel √© um index.html de linha √∫nica com o texto "Hello world"? </p><a name="habracut"></a><br><p>  Por que h√° 16 megabytes / usr / sbin / mysqld no meu backup?  √â realmente neste mundo que tenho a honra de armazenar esse arquivo importante e, se eu n√£o conseguir, ser√° perdido para a humanidade?  Provavelmente n√£o.  Ele √© armazenado em servidores debian altamente confi√°veis ‚Äã‚Äã(cuja confiabilidade e continuidade n√£o podem ser comparadas com o que eu posso fornecer), bem como em c√≥pias de backup (milh√µes deles) de outros administradores.  Realmente precisamos criar 10.000.000 + 1¬™ c√≥pia desse arquivo importante para aumentar a confiabilidade? </p><br><p> Em geral, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hashget</a> resolve esse problema.  Ao embalar - ele cria um backup muito pequeno.  Ao descompactar - um sistema completamente descompactado, semelhante ao que seria com <code>tar -c</code> / <code>tar -x</code> .  (Em outras palavras, esta √© uma embalagem sem perdas) </p><br><h1 id="kak-rabotaet-hashget">  Como o hashget funciona </h1><br><p>  O Hashget possui os conceitos de Package e HashPackage, com a ajuda deles para executar a desduplica√ß√£o. </p><br><p>  <em>Pacote</em>  Um arquivo (geralmente um arquivo .deb ou .tar.gz) que pode ser baixado com seguran√ßa da rede e do qual um ou mais arquivos podem ser obtidos. </p><br><p>  <em>HashPackage</em> √© um pequeno arquivo JSON que representa o pacote, incluindo a URL do pacote e a soma de hash (sha256) dos arquivos dele.  Por exemplo, para o pacote mariadb-server-core de 5 megabytes de tamanho, o tamanho do pacote de hash √© de apenas 6 kilobytes.  Mil vezes menor. </p><br><p>  <em>Desduplica√ß√£o</em> - criando um arquivo morto sem arquivos duplicados (se o desduplicador souber onde o pacote original pode ser baixado, isso reduzir√° as duplicatas do arquivo morto). </p><br><h2 id="zapakovka">  Embalagem </h2><br><p>  Ao compactar, todos os arquivos do diret√≥rio compactado s√£o exibidos, suas somas de hash s√£o consideradas e, se a soma for encontrada em um dos HashPackage conhecidos, os metadados do arquivo (nome, hash, permiss√µes etc.) s√£o salvos em um arquivo especial .hashget-restore.json, que tamb√©m ser√° inclu√≠do no arquivo. </p><br><p>  A pr√≥pria embalagem, no caso mais simples, n√£o parece mais complicada que o tar: </p><br><pre> <code class="plaintext hljs">hashget -zf /tmp/mybackup.tar.gz --pack /path/to/data</code> </pre> <br><h2 id="raspakovka">  Desembalar </h2><br><p>  A desembalagem √© feita em duas etapas.  Primeiro, o alcatr√£o usual √© desembalado: </p><br><pre> <code class="plaintext hljs">tar -xf mybackup.tar.gz -C /path/to/data</code> </pre> <br><p>  depois restaure da rede: </p><br><pre> <code class="plaintext hljs">hashget -u /path/to/data</code> </pre> <br><p>  Durante a recupera√ß√£o, o hashget l√™ o arquivo .hashget-restore.json, baixa os pacotes necess√°rios, descompacta e extrai os arquivos necess√°rios, configurando-os nos caminhos corretos, com o propriet√°rio / grupo / permiss√µes necess√°rios. </p><br><h1 id="bolee-slozhnye-veschi">  Coisas mais complicadas </h1><br><p>  O que √© descrito acima j√° √© suficiente para aqueles que "querem como tar, mas empacotam meu Debian em 4 megabytes".  Al√©m disso, veremos coisas mais dif√≠ceis. </p><br><h2 id="indeksirovanie">  Indexa√ß√£o </h2><br><p>  Se um hashget n√£o tivesse um √∫nico HashPackage, simplesmente n√£o poderia deduplicar nada. </p><br><p>  Voc√™ tamb√©m pode criar um HashPackage manualmente (simplesmente: <code>hashget --submit https://wordpress.org/wordpress-5.1.1.zip -p my</code> ), mas existe uma maneira mais conveniente. </p><br><p>  Para obter o hashpackage necess√°rio, existe uma etapa de <em>indexa√ß√£o</em> (√© executada automaticamente quando o comando <code>--pack</code> √© <code>--pack</code> ) e <em>heur√≠sticas</em> .  Ao indexar, o hashget "alimenta" cada arquivo encontrado para todas as heur√≠sticas existentes nas quais ele est√° interessado.  A heur√≠stica pode indexar qualquer pacote para criar um HashPackage. </p><br><p>  Por exemplo, uma heur√≠stica Debian ama o arquivo / var / lib / dpkg / status e detecta pacotes debian instalados e, se n√£o estiverem indexados (o HashPackage n√£o foi criado para eles), os far√° o download e os indexar√°.  O resultado √© um efeito muito agrad√°vel - o hashget sempre deduplicar√° efetivamente os sistemas operacionais Debian, mesmo se eles tiverem os pacotes mais recentes. </p><br><h2 id="fayly-podskazki-hinty">  Arquivos de dicas </h2><br><p>  Se sua rede usar algum tipo de pacote propriet√°rio ou p√∫blico que n√£o esteja inclu√≠do nas heur√≠sticas de hashget, voc√™ poder√° adicionar um arquivo de dica hashget-hint.json simples da seguinte maneira: </p><br><pre> <code class="plaintext hljs">{ "project": "wordpress.org", "url": "https://ru.wordpress.org/wordpress-5.1.1-ru_RU.zip" }</code> </pre> <br><p>  Al√©m disso, toda vez que o arquivo morto √© criado, o pacote ser√° indexado (se n√£o anteriormente) e os arquivos do pacote ser√£o deduplicados do arquivo morto.  Nenhuma programa√ß√£o √© necess√°ria, tudo pode ser feito a partir do vim e salvo em todos os backups.  Observe que, gra√ßas √† abordagem via hashes, se alguns arquivos do pacote forem alterados localmente (por exemplo, o arquivo de configura√ß√£o for alterado), os arquivos alterados ser√£o salvos no arquivo morto "como est√£o" e n√£o ser√£o reduzidos. </p><br><p>  Se alguns de seus pr√≥prios pacotes s√£o atualizados periodicamente, mas as altera√ß√µes n√£o s√£o muito grandes, voc√™ pode apenas sugerir vers√µes principais.  Por exemplo, na vers√£o 1.0, eles fizeram uma dica indicando mypackage-1.0.tar.gz, e ela ser√° completamente desduplicada; depois, eles lan√ßaram a vers√£o 1.1, que √© um pouco diferente, mas a dica n√£o foi atualizada.  Nada para se preocupar.  Somente arquivos que correspondem (que podem ser restaurados) com a vers√£o 1.0 s√£o deduplicados. </p><br><p>  Uma heur√≠stica que processa um arquivo de dicas √© um bom exemplo para entender o mecanismo interno da heur√≠stica.  Ele processa apenas arquivos hashget-hint.json (ou .hashget-hint.json com um ponto) e ignora todos os outros.  Usando esse arquivo, ele determina qual URL do pacote deve ser indexado e o hashget o indexa (se isso n√£o tiver sido feito antes) </p><br><h2 id="hashserver">  Hashver </h2><br><p>  Seria bastante demorado executar totalmente a indexa√ß√£o ao criar backups.  Para fazer isso, voc√™ precisa baixar cada pacote, descompactar, indexar.  Portanto, o hashget usa um esquema com um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HashServer</a> .  Se um pacote debian estiver instalado, se n√£o for encontrado no HashPackage local, primeiro ser√° feita uma tentativa de simplesmente fazer o download do HashPackage do servidor de hash.  E somente se isso n√£o der certo - o hashget faz o download e o hash do pacote (e faz o upload para o hashserver, para que o hashserver o forne√ßa posteriormente). </p><br><p>  HashServer - um elemento opcional do esquema, n√£o cr√≠tico, √© usado exclusivamente para acelerar e reduzir a carga nos reposit√≥rios.  √â facilmente desconectado (com a op√ß√£o <code>--hashserver</code> sem par√¢metros).  Al√©m disso, voc√™ pode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">criar</a> facilmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">seu pr√≥prio servidor de hash</a> . </p><br><h2 id="inkrementalnye-i-differencialnye-bekapy-zaplanirovannoe-ustarevanie">  Backups incrementais e diferenciais, obsolesc√™ncia planejada </h2><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O hashget</a> facilita muito fazer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">backups incrementais e diferenciais</a> .  Por que n√£o indexamos nosso pr√≥prio backup (com todos os nossos arquivos exclusivos)?  Uma equipe - <code>--submit</code> e pronto!  O pr√≥ximo backup que o hashget criar√° n√£o incluir√° arquivos desse arquivo. </p><br><p>  Mas essa n√£o √© uma abordagem muito boa, pois pode ocorrer que, durante a recupera√ß√£o, tenhamos de arrancar todos os backups de hashget de todo o hist√≥rico (se cada um tiver pelo menos um arquivo exclusivo).  Existe um mecanismo para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">obsolesc√™ncia agendada de backup</a> para isso.  Ao indexar, voc√™ pode especificar a data de validade do HashPackage - <code>--expires 2019-06-01</code> e, nessa data (a partir das 00:00), ele n√£o ser√° usado.  O arquivo em si n√£o pode ser exclu√≠do ap√≥s essa data (embora o hashget possa mostrar convenientemente os URLs de todos os backups que n√≥s apodrecemos / apodrecemos no momento ou em qualquer data). </p><br><p>  Por exemplo, se voc√™ fizer um backup completo no 1¬∫ dia e index√°-lo por uma vida √∫til antes do final do m√™s, obteremos um esquema de backup diferencial. </p><br><p>  Se tamb√©m indexarmos novos backups, haver√° um esquema de backups incrementais. </p><br><p>  Diferentemente dos esquemas tradicionais, o hashget permite usar v√°rias fontes b√°sicas.  O backup ser√° reduzido devido √† redu√ß√£o de arquivos de backups anteriores (se houver) e devido a arquivos p√∫blicos (que podem ser baixados). </p><br><p>  Se, por algum motivo, n√£o confiamos na confiabilidade dos recursos do Debian ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://snapshot.debian.org/</a> ) ou usamos uma distribui√ß√£o diferente, podemos fazer um backup completo de todos os pacotes uma vez e depois confiar nele ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">desabilitando a heur√≠stica</a> )  Agora, se todos os servidores de nossas distribui√ß√µes se tornarem inacess√≠veis para n√≥s (na lembran√ßa da Internet ou durante o apocalipse zumbi), mas nossos backups estiverem em ordem - podemos recuperar qualquer backup diff curto que dependa apenas dos backups anteriores. </p><br><blockquote>  O Hashget depende apenas de fontes confi√°veis ‚Äã‚Äãde recupera√ß√£o, a seu crit√©rio.  O que voc√™ considera confi√°vel - esses ser√£o usados. </blockquote><br><h2 id="filepool-i-glacier">  FilePool e Geleira </h2><br><p>  O mecanismo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">FilePool</a> permite que voc√™ n√£o acesse constantemente servidores externos para baixar pacotes, mas use pacotes de um diret√≥rio local ou servidor corporativo, por exemplo: </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool /tmp/pool</code> </pre> <br><p>  ou </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool http://myhashdb.example.com/</code> </pre> <br><p>  Para criar um pool em um diret√≥rio local - basta criar um diret√≥rio e fazer upload de arquivos para ele, o pr√≥prio hashget encontrar√° o que ele precisa com hashes.  Para tornar o pool acess√≠vel via HTTP, voc√™ precisa criar links simb√≥licos de uma maneira especial, isso √© feito com um comando ( <code>hashget-admin --build /var/www/html/hashdb/ --pool /tmp/pool</code> ).  O pr√≥prio HTTP FilePool √© um arquivo est√°tico; portanto, qualquer servidor Web simples pode atend√™-lo; a carga no servidor √© quase zero. </p><br><p>  Gra√ßas ao FilePool, n√£o apenas os recursos http (s) podem ser usados ‚Äã‚Äãcomo recursos b√°sicos, mas tamb√©m, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">por exemplo</a> , o Amazon Glacier. </p><br><p>  Ap√≥s o upload do backup para o glaciar, obtemos seu ID de upload e o usamos como um URL.  Por exemplo: </p><br><pre> <code class="plaintext hljs">hashget --submit Glacier_Upload_ID --file /tmp/my-glacier-backup.tar.gz --project glacier --hashserver --expires 2019-09-01</code> </pre> <br><p>  Agora, os novos backups (diferenciais) contar√£o com esse backup e ser√£o mais curtos.  Depois de descompactar o diffback, podemos ver em que recursos ele se baseia: </p><br><pre> <code class="plaintext hljs">hashget --info /tmp/unpacked/ list</code> </pre> <br><p>  e apenas use o shell script para baixar todos esses arquivos da geleira no pool e execute a recupera√ß√£o usual: hashget -u / tmp / unpacked --pool / tmp / pool </p><br><h3 id="stoit-li-ovchinka-vydelki">  O jogo vale a vela </h3><br><p>  No caso mais simples, voc√™ pagar√° menos pelos backups (se os armazenar em algum lugar da nuvem por dinheiro).  Talvez - muito, muito menos. </p><br><p>  Mas este n√£o √© o √∫nico.  Quantidade entra em qualidade.  Voc√™ pode usar isso para obter uma atualiza√ß√£o de alta qualidade do esquema de backup.  Por exemplo, como nossos backups agora s√£o mais curtos - voc√™ n√£o pode fazer um backup mensal, mas di√°rio.  Mantenha-os n√£o seis meses, como antes, mas 5 anos.  Anteriormente, eles eram armazenados em um armazenamento "frio" lento, mas barato (Glacier), agora voc√™ pode armazenar em local quente, de onde voc√™ sempre pode baixar rapidamente um backup e recuperar em minutos, n√£o em um dia. </p><br><p>  Voc√™ pode aumentar a confiabilidade do armazenamento de backup.  Se agora os armazenarmos em uma loja, reduzindo o volume de backups - podemos armazenar em 2 a 3 lojas e sobreviver com seguran√ßa se um deles for danificado. </p><br><h3 id="kak-poprobovat-i-nachat-polzovatsya">  Como tentar come√ßar a usar? </h3><br><p>  Vamos para a p√°gina do gitlab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://gitlab.com/yaroslaff/hashget</a> , instalamos com um comando ( <code>pip3 install hashget[plugins]</code> ) e apenas lemos e executamos o in√≠cio r√°pido.  Eu acho que todas as coisas simples a fazer - levar√£o de 10 a 15 minutos.  Em seguida, voc√™ pode tentar agitar suas m√°quinas virtuais, criar arquivos de dica, se necess√°rio, apertar com mais for√ßa, brincar com pools, um banco de dados de hash local e um servidor de hash, se for interessante, e no dia seguinte ver qual ser√° o tamanho do backup incremental sobre ontem. </p><br><h3 id="restic--hashget">  Restic + HashGet </h3><br><p>  <em>(Este cap√≠tulo foi adicionado mais tarde. Agradecemos aos comentaristas por suas cr√≠ticas e motiva√ß√£o.)</em> </p><br><p>  Existe uma boa ferramenta conveniente para backups - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">restic</a> .  Ele tamb√©m pode executar desduplica√ß√£o, mas apenas dentro do reposit√≥rio, n√£o √© poss√≠vel desduplica√ß√£o externa, o que o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hashget</a> faz com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">facilidade</a> .  Mas na combina√ß√£o de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">restic + hashget</a> , conseguimos usar as vantagens de ambas as abordagens! </p><br><p>  Prepara√ß√£o (descompacte o wordpress e o indexe): </p><br><pre> <code class="plaintext hljs"># wget -q https://wordpress.org/wordpress-5.2.2.tar.gz # hashget --submit https://wordpress.org/wordpress-5.2.2.tar.gz -p my --file wordpress-5.2.2.tar.gz --hashserver # tar -xf wordpress-5.2.2.tar.gz # du -sh wordpress 46M wordpress</code> </pre> <br><p>  Adicionando instant√¢neo a restic via </p><br><pre> <code class="plaintext hljs"># hashget -X exclude-list --prepack wordpress --hashserver Saved: 1468 files, 1 pkgs, size: 40.5M. Download: 10.7M # restic --exclude-file exclude-list backup wordpress password is correct scan [/tmp/wp/wordpress] scanned 193 directories, 367 files in 0:02 [0:04] 100.00% 700.829 KiB / 700.829 KiB 560 / 560 items 0 errors ETA 0:00 duration: 0:04 snapshot 76b54230 saved # du -sh /tmp/restic-repo/ 2,1M /tmp/restic-repo/</code> </pre> <br><p>  Nesse est√°gio, adicionamos uma captura instant√¢nea de cat√°logo (mais de 40 Mb) e o tamanho do reposit√≥rio aumentou em apenas 1 Mb. </p><br><p>  A recupera√ß√£o √© feita por dois comandos: </p><br><pre> <code class="plaintext hljs"># restic restore 76b54230 -t unpacked password is correct restoring &lt;Snapshot 76b54230 of [/tmp/wp/wordpress] at 2019-06-19 04:30:55.760618336 +0700 +07 by root@braconnier&gt; to unpacked # hashget -u unpacked/wordpress/ --hashserver Recovered 1468/1468 files 40.5M bytes (0 downloaded, 0 from pool, 10.7M cached) in 1.56s</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt454826/">https://habr.com/ru/post/pt454826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt454810/index.html">Ar fresco em Marte: dobre uma mol√©cula de CO2 e obtenha oxig√™nio</a></li>
<li><a href="../pt454816/index.html">Configurando o pacote php-fpm + nginx no WSL</a></li>
<li><a href="../pt454818/index.html">Desafio Rekko - como conquistar o 2¬∫ lugar na competi√ß√£o pela cria√ß√£o de sistemas de recomenda√ß√£o</a></li>
<li><a href="../pt454820/index.html">Pesquisa do Azure</a></li>
<li><a href="../pt454824/index.html">O amplificador operacional mais simples em elementos discretos</a></li>
<li><a href="../pt454828/index.html">Criando uma imagem em mosaico</a></li>
<li><a href="../pt454830/index.html">3 principais qualidades para um gerente de produto de sucesso: Alexander Belyaev</a></li>
<li><a href="../pt454832/index.html">Por que uma semana de trabalho de quatro dias √© um p√©ssimo conto</a></li>
<li><a href="../pt454834/index.html">Os termos reais do estudo da digita√ß√£o por toque com baixa motiva√ß√£o</a></li>
<li><a href="../pt454840/index.html">Mudan√ßa cuidadosa para a Holanda com sua esposa e hipoteca. Parte 2: preparando documentos e movendo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
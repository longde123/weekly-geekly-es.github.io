<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚è≠Ô∏è üñêüèø üë©üèæ‚Äçüé® O livro "Apache Kafka. Processamento de fluxo e an√°lise de dados ‚Äù ü•™ ‚èèÔ∏è üàπ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Durante o trabalho de qualquer aplicativo corporativo, s√£o gerados dados: s√£o arquivos de log, m√©tricas, informa√ß√µes sobre a atividade do usu√°rio, men...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O livro "Apache Kafka. Processamento de fluxo e an√°lise de dados ‚Äù</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/421519/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/t6/ej/tx/t6ejtxboknf_ha_u7radv1gzrls.jpeg" align="left" alt="imagem"></a>  Durante o trabalho de qualquer aplicativo corporativo, s√£o gerados dados: s√£o arquivos de log, m√©tricas, informa√ß√µes sobre a atividade do usu√°rio, mensagens enviadas, etc. A manipula√ß√£o adequada de todos esses dados n√£o √© menos importante que os pr√≥prios dados.  Se voc√™ √© um arquiteto, desenvolvedor ou engenheiro graduado que deseja resolver esses problemas, mas ainda n√£o conhece o Apache Kafka, neste maravilhoso livro voc√™ aprender√° como trabalhar com esta plataforma de streaming gratuita que permite processar filas de dados em tempo real. <br><br><h3>  Para quem √© este livro? </h3><br>  Apache Kafka.  Processamento de fluxo e an√°lise de dados ‚Äùfoi escrito para desenvolvedores que usam a API Kafka em seu trabalho, bem como engenheiros de processo (tamb√©m chamados de SRE, DevOps ou administradores de sistema) que est√£o envolvidos na instala√ß√£o, configura√ß√£o, configura√ß√£o e monitoramento de sua opera√ß√£o durante a opera√ß√£o industrial.  Tamb√©m n√£o esquecemos os arquitetos de dados e os engenheiros anal√≠ticos - os respons√°veis ‚Äã‚Äãpelo design e cria√ß√£o de toda a infraestrutura de dados da empresa.  Alguns cap√≠tulos, em particular 3, 4 e 11, s√£o voltados para desenvolvedores de Java.  Para entend√™-los, √© importante que o leitor esteja familiarizado com os conceitos b√°sicos da linguagem de programa√ß√£o Java, incluindo quest√µes como manipula√ß√£o de exce√ß√£o e concorr√™ncia. <br><a name="habracut"></a><br>  Outros cap√≠tulos, especialmente 2, 8, 9 e 10, pressup√µem que o leitor tenha experi√™ncia com Linux e esteja familiarizado com a configura√ß√£o de rede e armazenamento Linux.  O restante das arquiteturas de livros e software de Kafka √© discutido em termos mais gerais, portanto, nenhum conhecimento especial √© exigido dos leitores. <br><br>  Outra categoria de pessoas que podem estar interessadas neste livro s√£o gerentes e arquitetos que n√£o trabalham diretamente com Kafka, mas com aqueles que trabalham com ele.  N√£o √© menos importante que eles entendam quais s√£o as garantias da plataforma e o que compromete seus subordinados e colegas ao criar sistemas baseados em Kafka.  Este livro ser√° √∫til para os gerentes que desejam treinar seus funcion√°rios para trabalhar com Kafka ou para garantir que a equipe de desenvolvimento possua as informa√ß√µes necess√°rias. <br><br><h3>  Cap√≠tulo 2. Instalando o Kafka </h3><br>  O Apache Kafka √© um aplicativo Java que pode ser executado em muitos sistemas operacionais, incluindo Windows, MacOS, Linux e outros.Neste cap√≠tulo, focaremos na instala√ß√£o do Kafka no Linux, pois √© a plataforma mais frequentemente instalada nesse sistema operacional.  O Linux tamb√©m √© o sistema operacional recomendado para a implanta√ß√£o Kafka de uso geral.  Para obter informa√ß√µes sobre a instala√ß√£o do Kafka no Windows e MacOS, consulte o Ap√™ndice A. <br><br>  <b>Instalar java</b> <br><br>  Antes de instalar o ZooKeeper ou Kafka, voc√™ deve instalar e configurar o ambiente Java.  √â recomend√°vel usar o Java 8, e essa pode ser uma vers√£o inclu√≠da no sistema operacional ou baixada diretamente do java.com.  Embora o ZooKeeper e o Kafka funcionem com o Java Runtime Edition, √© mais conveniente usar o Java Development Kit (JDK) completo ao desenvolver utilit√°rios e aplicativos.  Essas etapas de instala√ß√£o assumem que voc√™ possui o JDK vers√£o 8.0.51 instalado no diret√≥rio /usr/java/jdk1.8.0_51. <br><br>  <b>Instale o ZooKeeper</b> <br><br>  O Apache Kafka usa o ZooKeeper para armazenar metadados sobre o cluster Kafka, al√©m de detalhes sobre clientes consumidores (Fig. 2.1).  Embora o ZooKeeper tamb√©m possa ser iniciado usando scripts inclu√≠dos na distribui√ß√£o Kafka, a instala√ß√£o da vers√£o completa do reposit√≥rio ZooKeeper a partir da distribui√ß√£o √© muito simples. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/a-/ye/ed/a-yeeda4ysojxtp4kcwlnmufwlc.png" alt="imagem"></div><br>  O Kafka foi completamente testado com a vers√£o est√°vel 3.4.6 do reposit√≥rio ZooKeeper, que pode ser baixada em apache.org. <br><br>  <b>Servidor aut√¥nomo</b> <br><br>  O exemplo a seguir demonstra como instalar o ZooKeeper com configura√ß√µes b√°sicas no diret√≥rio / usr / local / zookeeper e salvar os dados no diret√≥rio / var / lib / zookeeper: <br><br><pre><code class="hljs delphi"># tar -zxf zookeeper-<span class="hljs-number"><span class="hljs-number">3.4</span></span>.<span class="hljs-number"><span class="hljs-number">6</span></span>.tar.gz # mv zookeeper-<span class="hljs-number"><span class="hljs-number">3.4</span></span>.<span class="hljs-number"><span class="hljs-number">6</span></span> /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper # mkdir -p /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/zookeeper # cat &gt; /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/conf/zoo.cfg &lt;&lt; EOF &gt; tickTime=<span class="hljs-number"><span class="hljs-number">2000</span></span> &gt; dataDir=/<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/zookeeper &gt; clientPort=<span class="hljs-number"><span class="hljs-number">2181</span></span> &gt; EOF # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/zkServer.sh start JMX enabled by <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Using config: /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED # <span class="hljs-keyword"><span class="hljs-keyword">export</span></span> JAVA_HOME=/usr/java/jdk1.<span class="hljs-number"><span class="hljs-number">8.0</span></span>_51 # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/zkServer.sh start JMX enabled by <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Using config: /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED #</code> </pre> <br>  Agora voc√™ pode verificar se o ZooKeeper deve funcionar offline, conectando-se √† porta do cliente e enviando o comando srvr de quatro letras: <br><br><pre> <code class="hljs pgsql"># telnet localhost <span class="hljs-number"><span class="hljs-number">2181</span></span> Trying ::<span class="hljs-number"><span class="hljs-number">1.</span></span>.. Connected <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> localhost. <span class="hljs-keyword"><span class="hljs-keyword">Escape</span></span> <span class="hljs-type"><span class="hljs-type">character</span></span> <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-string"><span class="hljs-string">'^]'</span></span>. srvr Zookeeper <span class="hljs-keyword"><span class="hljs-keyword">version</span></span>: <span class="hljs-number"><span class="hljs-number">3.4</span></span><span class="hljs-number"><span class="hljs-number">.6</span></span><span class="hljs-number"><span class="hljs-number">-1569965</span></span>, built <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> <span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">20</span></span>/<span class="hljs-number"><span class="hljs-number">2014</span></span> <span class="hljs-number"><span class="hljs-number">09</span></span>:<span class="hljs-number"><span class="hljs-number">09</span></span> GMT Latency min/avg/max: <span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">0</span></span> Received: <span class="hljs-number"><span class="hljs-number">1</span></span> Sent: <span class="hljs-number"><span class="hljs-number">0</span></span> Connections: <span class="hljs-number"><span class="hljs-number">1</span></span> Outstanding: <span class="hljs-number"><span class="hljs-number">0</span></span> Zxid: <span class="hljs-number"><span class="hljs-number">0x0</span></span> Mode: standalone Node count: <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Connection</span></span> closed <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> <span class="hljs-keyword"><span class="hljs-keyword">foreign</span></span> host. #</code> </pre> <br>  <b>ZooKeeper Ensemble</b> <br><br>  O cluster ZooKeeper √© chamado de conjunto.  Devido √† natureza do pr√≥prio algoritmo, recomenda-se que o conjunto inclua um n√∫mero √≠mpar de servidores, por exemplo, 3, 5, etc., pois para que o ZooKeeper possa responder √†s solicita√ß√µes, a maioria dos membros do conjunto deve funcionar (quorum).  Isso significa que um conjunto de tr√™s n√≥s pode trabalhar com um n√≥ inativo.  Se o conjunto tiver tr√™s n√≥s, pode haver dois. <br><br>  Para configurar a opera√ß√£o dos servidores ZooKeeper no conjunto, eles devem ter uma √∫nica configura√ß√£o com uma lista de todos os servidores, e cada servidor no diret√≥rio de dados deve ter um arquivo myid com o identificador desse servidor.  Se os hosts do conjunto forem denominados zoo1.example.com, zoo2.example.com e zoo3.example.com, o arquivo de configura√ß√£o poder√° se parecer com o seguinte: <br><br><pre> <code class="hljs pgsql">tickTime=<span class="hljs-number"><span class="hljs-number">2000</span></span> dataDir=/var/lib/zookeeper clientPort=<span class="hljs-number"><span class="hljs-number">2181</span></span> initLimit=<span class="hljs-number"><span class="hljs-number">20</span></span> syncLimit=<span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>=zoo1.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span>=zoo2.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.3</span></span>=zoo3.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span></code> </pre> <br>  Nesta configura√ß√£o, initLimit √© a quantidade de tempo que os n√≥s escravos podem conectar ao mestre.  O valor syncLimit limita o atraso dos n√≥s escravos do mestre.  Ambos os valores s√£o especificados em unidades tickTime, ou seja, initLimit = 20 ¬∑ 2000 ms = 40 s.  A configura√ß√£o tamb√©m lista todos os servidores de conjunto.  Eles est√£o no formato server.X = hostname: peerPort: leaderPort com os seguintes par√¢metros: <br><br><ul><li>  X √© o identificador do servidor.  Ele deve ser um n√∫mero inteiro, mas a contagem pode n√£o ser de zero e n√£o ser seq√ºencial; </li><li>  hostname - nome do host ou endere√ßo IP do servidor; </li><li>  peerPort - porta TCP atrav√©s da qual os servidores do conjunto se comunicam; </li><li>  leaderPort - porta TCP atrav√©s da qual o host est√° selecionado. </li></ul><br>  √â suficiente que os clientes possam se conectar ao conjunto por meio da porta clientPort, mas os membros do conjunto devem poder trocar mensagens entre si nas tr√™s portas. <br><br>  Al√©m de um √∫nico arquivo de configura√ß√£o, cada servidor no diret√≥rio dataDir deve ter um arquivo myid.  Ele deve conter o identificador do servidor correspondente ao fornecido no arquivo de configura√ß√£o.  Depois de concluir essas etapas, voc√™ pode iniciar os servidores e eles interagir√£o entre si no conjunto. <br><br><h3>  Instalando o Kafka Broker </h3><br>  Ap√≥s concluir a configura√ß√£o do Java e ZooKeeper, voc√™ pode prosseguir com a instala√ß√£o do Apache Kafka.  A vers√£o mais recente do Apache Kafka pode ser baixada em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">kafka.apache.org/downloads.html</a> . <br><br>  No exemplo a seguir, instale a plataforma Kafka no diret√≥rio / usr / local / kafka, configure-a para usar o servidor ZooKeeper iniciado anteriormente e salve os segmentos de log de mensagens no diret√≥rio / tmp / kafka-logs: <br><br><pre> <code class="hljs pgsql"># tar -zxf kafka_2<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">-0.9</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>.tgz # mv kafka_2<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">-0.9</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span> /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka # mkdir /tmp/kafka-logs # export JAVA_HOME=/usr/java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_51 # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>.sh -daemon /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/config/<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.properties #</code> </pre> <br>  Ap√≥s iniciar o broker Kafka, voc√™ pode testar seu funcionamento executando quaisquer opera√ß√µes simples com o cluster, incluindo a cria√ß√£o de um t√≥pico de teste, gerando mensagens e consumindo-as. <br><br>  Criando e verificando threads: <br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta"># /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test Created topic </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"test"</span></span></span><span class="hljs-meta">. # /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test Topic:test PartitionCount:1 ReplicationFactor:1 Configs: Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 #</span></span></code> </pre> <br>  Gerando mensagens para o t√≥pico de teste: <br><br><pre> <code class="hljs delphi"># /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-console-producer.sh --broker-list localhost:<span class="hljs-number"><span class="hljs-number">9092</span></span> --topic test Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> ^D #</code> </pre> <br>  Consumindo mensagens do t√≥pico de teste: <br><br><pre> <code class="hljs delphi"># /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:<span class="hljs-number"><span class="hljs-number">2181</span></span> --topic test --from-beginning Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> ^C Consumed <span class="hljs-number"><span class="hljs-number">2</span></span> messages #</code> </pre> <br><h3>  Configura√ß√£o do Broker </h3><br>  O exemplo de configura√ß√£o do broker fornecido com a distribui√ß√£o Kafka √© bastante adequado para uma execu√ß√£o de teste de um servidor independente, mas para a maioria das instala√ß√µes, n√£o ser√° suficiente.  Existem muitas op√ß√µes de configura√ß√£o do Kafka que governam todos os aspectos da instala√ß√£o e configura√ß√£o.  √â poss√≠vel deixar os valores padr√£o para muitos deles, pois eles se relacionam √†s nuances da configura√ß√£o de um broker Kafka que n√£o s√£o aplic√°veis ‚Äã‚Äãat√© que voc√™ trabalhe com um cen√°rio espec√≠fico que exija que eles sejam usados. <br><br><h3>  Configura√ß√µes b√°sicas do broker </h3><br>  Existem v√°rias configura√ß√µes do broker Kafka que voc√™ deve considerar ao implementar a plataforma em qualquer ambiente, exceto um broker independente em um servidor separado.  Esses par√¢metros est√£o relacionados √†s principais configura√ß√µes do broker e a maioria deles deve ser alterada para que o broker possa trabalhar em um cluster com outros brokers. <br><br>  <b>broker.id</b> <br><br>  Cada intermedi√°rio Kafka deve ter um identificador inteiro especificado pelo par√¢metro broker.id.  Por padr√£o, esse valor √© 0, mas pode ser qualquer n√∫mero.  O principal √© que ele n√£o se repete no mesmo cluster Kafka.  A escolha do n√∫mero pode ser arbitr√°ria e, se necess√°rio, para conveni√™ncia da manuten√ß√£o, pode ser transferida de um corretor para outro.  √â desej√°vel que esse n√∫mero esteja de alguma forma conectado ao host, ent√£o a correspond√™ncia dos identificadores do broker para hosts com rastreamento ser√° mais transparente.  Por exemplo, se seus nomes de host contiverem n√∫meros exclusivos (por exemplo, host1.exemplo.com, host2.exemplo.com etc.), esses n√∫meros seriam uma boa op√ß√£o para os valores de broker.id. <br><br>  <b>porta</b> <br><br>  Um arquivo de configura√ß√£o t√≠pico inicia o Kafka com um ouvinte na porta TCP 9092. Essa porta pode ser alterada para qualquer outra dispon√≠vel, alterando a porta do par√¢metro de configura√ß√£o.  Lembre-se de que, ao escolher uma porta com um n√∫mero menor que 1024, o Kafka deve ser executado como root.  Executar o Kafka como root n√£o √© recomendado. <br><br>  <b>zookeeper.connect</b> <br><br>  O caminho que o ZooKeeper usa para armazenar os metadados do broker √© definido usando o par√¢metro de configura√ß√£o zookeeper.connect.  Na configura√ß√£o de amostra, o ZooKeeper √© executado na porta 2181 no host local, indicado como host local: 2181.  O formato desse par√¢metro √© uma lista de linhas separadas por ponto e v√≠rgula no formato nome do host: porta / caminho, incluindo: <br><br><ul><li>  nome do host - nome do host ou endere√ßo IP do servidor ZooKeeper; </li><li>  port - n√∫mero da porta do cliente para o servidor; </li><li>  / path - um caminho opcional do ZooKeeper usado como o novo caminho raiz (chroot) do cluster Kafka.  Se n√£o for especificado, o caminho raiz ser√° usado. </li></ul><br>  Se o caminho chroot especificado n√£o existir, ele ser√° criado quando o broker iniciar. <br><br>  <b>log.dirs</b> <br><br>  O Kafka salva todas as mensagens no disco r√≠gido e esses segmentos do log s√£o armazenados nos diret√≥rios especificados na configura√ß√£o log.dirs.  √â uma lista de caminhos separados por v√≠rgula no sistema local.  Se v√°rios caminhos forem especificados, o broker salvar√° se√ß√µes neles de acordo com o princ√≠pio dos menos utilizados, com a preserva√ß√£o dos segmentos de log de uma se√ß√£o ao longo de um caminho.  Observe que o broker colocar√° a nova se√ß√£o no diret√≥rio em que, no momento, menos parti√ß√µes s√£o armazenadas e n√£o menos espa√ßo √© usado, para que a distribui√ß√£o uniforme de dados entre as se√ß√µes n√£o seja garantida. <br><br>  <b>num.recovery.threads.per.data.dir</b> <br><br>  Kafka usa um conjunto de encadeamentos personalizado para processar segmentos de log.  Atualmente √© aplicado: <br><br><ul><li>  durante a inicializa√ß√£o normal - para abrir os segmentos de log de cada se√ß√£o; </li><li>  iniciar ap√≥s uma falha - para verificar e truncar os segmentos de log de cada se√ß√£o; </li><li>  Parar - para fechar suavemente os segmentos de log. </li></ul><br>  Por padr√£o, apenas um encadeamento √© usado por diret√≥rio de log.  Como isso acontece apenas ao iniciar e parar, faz sentido usar mais deles para paralelizar opera√ß√µes.  Ao se recuperar de um desligamento incorreto, os benef√≠cios do uso dessa abordagem podem chegar a v√°rias horas se o broker com um grande n√∫mero de parti√ß√µes for reiniciado!  Lembre-se de que o valor desse par√¢metro √© determinado com base em um diret√≥rio de log do n√∫mero especificado usando log.dirs.  Ou seja, se o valor do par√¢metro num.recovery.threads.per.data.dir for 8 e tr√™s caminhos forem especificados em log.dirs, o n√∫mero total de encadeamentos ser√° 24. <br><br>  <b>auto.create.topics.enable</b> <br><br>  De acordo com a configura√ß√£o padr√£o do Kafka, o broker deve criar automaticamente um tema quando: <br><br><ul><li>  o fabricante come√ßa a escrever na linha de assunto; </li><li>  o consumidor come√ßa a ler o t√≥pico da mensagem; </li><li>  qualquer cliente solicita metadados do t√≥pico. </li></ul><br>  Em muitos casos, esse comportamento pode ser indesej√°vel, principalmente devido ao fato de que n√£o h√° como verificar a exist√™ncia de um t√≥pico usando o protocolo Kafka sem fazer com que ele seja criado.  Se voc√™ controlar a cria√ß√£o disso explicitamente, manualmente ou por meio do sistema de inicializa√ß√£o, poder√° definir o par√¢metro auto.create.topics.enable como false. <br><br><h3>  Configura√ß√µes de tema padr√£o </h3><br>  A configura√ß√£o do servidor Kafka define muitas configura√ß√µes padr√£o para os temas criados.  Alguns desses par√¢metros, incluindo o n√∫mero de se√ß√µes e os par√¢metros de salvamento de mensagens, podem ser definidos para cada t√≥pico separadamente, usando as ferramentas do administrador (discutidas no Cap√≠tulo 9).  Os valores padr√£o na configura√ß√£o do servidor devem ser definidos iguais aos valores de refer√™ncia adequados para a maioria dos t√≥picos do cluster. <br><br>  <b>parti√ß√µes num.</b> <br><br>  O par√¢metro num.partitions determina com quantas se√ß√µes um novo t√≥pico √© criado, principalmente quando a cria√ß√£o autom√°tica por temas √© ativada (que √© o comportamento padr√£o).  O valor padr√£o deste par√¢metro √© 1. Lembre-se de que o n√∫mero de se√ß√µes de um t√≥pico s√≥ pode ser aumentado, mas n√£o reduzido.  Isso significa que, se exigir menos parti√ß√µes do que as indicadas em parti√ß√µes num., voc√™ precisar√° cri√°-las cuidadosamente manualmente (isso √© discutido no Cap√≠tulo 9). <br><br>  Conforme discutido no Cap√≠tulo 1, as se√ß√µes s√£o uma maneira de escalar t√≥picos em um cluster Kafka, por isso √© importante que voc√™ tenha o n√∫mero necess√°rio para equilibrar a carga nas mensagens em todo o cluster √† medida que os agentes forem adicionados.  Muitos usu√°rios preferem que o n√∫mero de parti√ß√µes seja igual ou o n√∫mero de intermedi√°rios no cluster.  Isso possibilita a distribui√ß√£o uniforme de se√ß√µes entre os intermedi√°rios, o que levar√° a uma distribui√ß√£o uniforme da carga entre as mensagens.  No entanto, esse n√£o √© um requisito obrigat√≥rio, porque a presen√ßa de v√°rios t√≥picos permite equilibrar a carga. <br><br>  <b>log.retention.ms</b> <br><br>  Na maioria das vezes, o armazenamento de mensagens em Kafka √© limitado no tempo.  O valor padr√£o √© especificado no arquivo de configura√ß√£o usando o par√¢metro log.retention.hours e √© igual a 168 horas ou 1 semana.  No entanto, voc√™ pode usar dois outros par√¢metros - log.retention.minutes e log.retention.ms.  Todos esses tr√™s par√¢metros determinam a mesma coisa - o per√≠odo de tempo ap√≥s o qual as mensagens s√£o exclu√≠das.  Mas √© recomend√°vel usar o par√¢metro log.retention.ms, porque se v√°rios par√¢metros forem especificados, a prioridade pertencer√° √† menor unidade de medida, portanto, o valor de log.retention.ms ser√° sempre usado. <br><br>  <b>log.retention.bytes</b> <br><br>  Outra maneira de limitar a validade das mensagens √© baseada no tamanho total (em bytes) das mensagens armazenadas.  O valor √© definido usando o par√¢metro log.retention.bytes e √© aplicado separadamente.  Isso significa que, no caso de um t√≥pico de oito se√ß√µes e igual a 1 GB do valor de log.retention.bytes, a quantidade m√°xima de dados armazenados para este t√≥pico ser√° de 8 GB.  Observe que a quantidade de armazenamento depende das se√ß√µes individuais e n√£o do t√≥pico.  Isso significa que, se o n√∫mero de se√ß√µes do t√≥pico aumentar, a quantidade m√°xima de dados salvos ao usar log.retention.bytes tamb√©m aumentar√°. <br><br>  <b>log.segment.bytes</b> <br><br>  As configura√ß√µes de log mencionadas dizem respeito a segmentos de log, n√£o a mensagens individuais.  √Ä medida que as mensagens s√£o geradas pelo broker Kafka, elas s√£o adicionadas ao final do segmento de di√°rio atual da se√ß√£o correspondente.  Quando o segmento de log atinge o tamanho especificado pelo par√¢metro log.segment.bytes e √© igual a 1 GB por padr√£o, esse segmento √© fechado e um novo √© aberto.  Ap√≥s o fechamento, o segmento do di√°rio pode ser retirado.  Quanto menor o tamanho dos segmentos de log, mais frequentemente √© necess√°rio fechar arquivos e criar novos, o que reduz a efici√™ncia geral das grava√ß√µes em disco. <br><br>  O dimensionamento dos segmentos de log √© importante quando os t√≥picos s√£o caracterizados por uma baixa frequ√™ncia de gera√ß√£o de mensagens.  Por exemplo, se um t√≥pico receber apenas 100 MB de mensagens por dia e o par√¢metro log.segment.bytes estiver definido como o valor padr√£o, leva 10 dias para preencher um segmento.  E como as mensagens n√£o podem ser declaradas inv√°lidas at√© o segmento de log ser fechado, com o valor de 604,8 milh√µes (1 semana) do par√¢metro log.retention.ms, as mensagens podem acumular-se em 17 dias antes que o segmento de log fechado seja retirado de circula√ß√£o.  Isso ocorre porque quando voc√™ fecha um segmento com mensagens acumuladas por 10 dias, √© necess√°rio armazen√°-lo por mais 7 dias antes de poder retir√°-lo de acordo com as regras tempor√°rias adotadas, pois o segmento n√£o pode ser exclu√≠do antes que a √∫ltima mensagem nele expire. . <br><br>  <b>log.segment.ms</b> <br><br>  Outra maneira de controlar o fechamento dos segmentos de log √© usar o par√¢metro log.segment.ms, que especifica o per√≠odo de tempo ap√≥s o qual o segmento de log √© fechado.  Como os par√¢metros log.retention.bytes e log.retention.ms, os par√¢metros log.segment.bytes e log.segment.ms n√£o s√£o mutuamente exclusivos.  Kafka fecha o segmento de log quando o tempo acabar ou o limite de tamanho especificado for atingido, dependendo de qual desses eventos ocorrer primeiro.  Por padr√£o, o valor do par√¢metro log.segment.ms n√£o est√° definido e, como resultado, o fechamento dos segmentos de log √© determinado pelo tamanho. <br><br>  <b>message.max.bytes</b> <br><br>  O broker Kafka permite usar o par√¢metro message.max.bytes para limitar o tamanho m√°ximo das mensagens geradas.  O valor padr√£o para este par√¢metro √© 1.000.000 (1 MB).  Um fabricante que tentar enviar uma mensagem maior receber√° uma notifica√ß√£o de erro do broker, mas a mensagem n√£o ser√° aceita.  Como no caso de todos os outros tamanhos em bytes especificados nas configura√ß√µes do broker, estamos falando sobre o tamanho da mensagem compactada, para que os fabricantes possam enviar mensagens, cujo tamanho n√£o compactado seja muito maior se puderem ser compactados nos limites especificados por message.max.bytes . <br><br>  Aumentar o tamanho da mensagem pode afetar seriamente o desempenho.  Um tamanho de mensagem maior significa que os threads do broker que processam as conex√µes e solicita√ß√µes de rede levar√£o mais tempo para cada solicita√ß√£o.  Mensagens maiores tamb√©m aumentam a quantidade de dados gravados no disco, o que afeta a taxa de transfer√™ncia de E / S. <br><br><h3>  Sele√ß√£o de hardware </h3><br>  Escolher o hardware certo para o corretor Kafka √© mais uma arte do que uma ci√™ncia.  A plataforma Kafka em si n√£o possui requisitos r√≠gidos de hardware; funcionar√° sem problemas em nenhum sistema.  Mas se falamos de desempenho, ele √© influenciado por v√°rios fatores: capacidade e taxa de transfer√™ncia de discos, RAM, rede e CPU. <br><br>  Primeiro, voc√™ precisa decidir quais tipos de desempenho s√£o mais importantes para o seu sistema; depois disso, voc√™ pode escolher a configura√ß√£o ideal de hardware que se encaixa no or√ßamento. <br><br><h3>  Taxa de transfer√™ncia do disco </h3><br>  A taxa de transfer√™ncia dos discos do broker, usados ‚Äã‚Äãpara armazenar segmentos de log, afeta diretamente o desempenho dos clientes de fabrica√ß√£o.  As mensagens Kafka devem ser confirmadas no armazenamento local que confirma sua grava√ß√£o.  Somente ent√£o a opera√ß√£o de envio pode ser considerada bem-sucedida.  Isso significa que, quanto mais r√°pido as opera√ß√µes de grava√ß√£o no disco forem realizadas, menor ser√° o atraso na gera√ß√£o de mensagens. <br><br>  A a√ß√£o √≥bvia em caso de problemas com a largura de banda dos discos √© usar discos r√≠gidos com placas girat√≥rias (HDD) ou unidades de estado s√≥lido (SSD).  Os SSDs t√™m ordens de magnitude menor tempo de pesquisa / acesso e maior desempenho.  Os HDDs s√£o mais econ√¥micos e t√™m uma capacidade relativa mais alta.  O desempenho do HDD pode ser aprimorado devido ao seu maior n√∫mero no broker, ou ao usar v√°rios diret√≥rios de dados ou √† instala√ß√£o de discos em uma matriz de discos independentes com redund√¢ncia (RAID).  Outros fatores influenciam a taxa de transfer√™ncia, por exemplo, a tecnologia de fabrica√ß√£o de um disco r√≠gido (por exemplo, SAS ou SATA), bem como as caracter√≠sticas do controlador de disco r√≠gido. <br><br><h3>  Capacidade de disco </h3><br>  A capacidade √© outro aspecto do armazenamento.  A quantidade necess√°ria de espa√ßo em disco √© determinada por quantas mensagens precisam ser armazenadas ao mesmo tempo.  Se o corretor receber 1 TB de tr√°fego por dia, com 7 dias de armazenamento, ele precisar√° de armazenamento dispon√≠vel para segmentos de log de pelo menos 7 TB.  Voc√™ tamb√©m deve considerar uma satura√ß√£o de pelo menos 10% para outros arquivos, sem contar o buffer para poss√≠veis flutua√ß√µes de tr√°fego ou seu crescimento ao longo do tempo. <br><br>  A capacidade de armazenamento √© um dos fatores que devem ser considerados ao determinar o tamanho ideal do cluster Kafka e decidir sua expans√£o.  O tr√°fego total do cluster pode ser balanceado por v√°rias se√ß√µes para cada t√≥pico, o que permite o uso de intermedi√°rios adicionais para aumentar a capacidade dispon√≠vel nos casos em que a densidade de dados por intermedi√°rio n√£o √© suficiente.  A decis√£o sobre quanto espa√ßo em disco √© necess√°rio tamb√©m √© determinada pela estrat√©gia de replica√ß√£o selecionada para o cluster (discutida em mais detalhes no Cap√≠tulo 6). <br><br><h3>  A mem√≥ria </h3><br>  No modo normal de opera√ß√£o, o consumidor Kafka l√™ no final da se√ß√£o e consome constantemente o tempo perdido e apenas um pouco atr√°s dos fabricantes, se √© que o faz.            ,      ,         . ,         ,    -. <br><br>   Kafka     JVM      .  ,   X        X   ,      5 .             Kafka        .      Kafka  ,      ,       ,     Kafka. <br><br><h3>     </h3><br>   ,    Kafka,     .    (    )    .     Kafka (   )       .    1       ,       ,      .       ,     (.  6)    (   8).          ,     . <br><br><h3>  CPU </h3><br>     ,      ,           .             .  Kafka, ,              .            .    Kafka  '   .            . <br><br><h3> Kafka    </h3><br> Kafka      , , Amazon Web Services (AWS). AWS     ,     CPU,     .              Kafka.       ,      .                /      SSD.         (, AWS Elastic Block Store).            CPU   . <br>    ,     AWS      m4  r3.    m4    ,        ,      .      r3      SSD-,        .            i2  d2. <br><br><h3>  Kafka </h3><br>   Kafka         ,             (. 2.2).     ‚Äî      .    ‚Äî            .         Kafka        .         Kafka.           6. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vo/c-/cc/voc-cc5ywmwoh4ttiidnzt1gdk4.png" alt="imagem"></div><br><br><h3>    ? </h3><br>   Kafka   .    ‚Äî              .     10  ,      2 ,     ‚Äî  .  ,          100 % (    ) (.  6).  ,              . <br><br>   ,   , ‚Äî     . ,                        (         ).        80 %   ,    ,             .     ,      ,   .        ,     ,          . <br><br><h3>   </h3><br>               Kafka.  ‚Äî          zookeeper.connect.    ZooKeeper     .  ‚Äî           broker.id.       broker.id    ,            .      ,    ,      ,    . <br><br><h3>     </h3><br>     Linux      ,       ,           Kafka.          ,    ,        .       /etc/sysctl.conf,        Linux,       . <br><br><h3>   </h3><br>     Linux     .           ,    ¬´¬ª  ,        Kafka. <br>     ,  ,    ,    ()  . ,      ,       Kafka.  , Kafka     ,         ,       . <br><br>      ‚Äî        .  ‚Äî   ,      -   .            .      vm.swappiness  ,  1.      ( ) ,            .     ,   . <br><br>  ,      ¬´¬ª ,      ,   .   Kafka       /.         :        (, SSD),       NVRAM   (, RAID).       ¬´¬ª ,         .       vm.dirty_background_ratio ,     ( 10).       ( ),         5.       0,                           . <br><br>   ¬´¬ª ,               ,      vm.dirty_ratio  ,     ‚Äî 20 (        ).       ,      60  80.               ,       /       .       vm.dirty_ratio       Kafka,     . <br><br>          ¬´¬ª      Kafka        .        /proc/vmstat: <br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta"># cat /proc/vmstat | egrep </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"dirty|writeback"</span></span></span><span class="hljs-meta"> nr_dirty 3875 nr_writeback 29 nr_writeback_temp 0 #</span></span></code> </pre> <br><h3>  Drive </h3><br>         ,    RAID-    ,           .     ,        EXT4 (fourth extended file system ‚Äî    )  XFS (Extents File System ‚Äî     ). EXT4   ,       .       ,     (5),       .  EXT4     ,            .    XFS     ,   ,   EXT4.  XFS    Kafka  ,        ,    .         ,       /. <br><br>     ,        ,     noatime.      /:   (ctime),    (mtime)       (atime).     atime     .        .  atime    ,   ,      ,         (      realtime). Kafka     atime,      .   noatime       /,        ctime  mtime. <br><br><h3>     </h3><br>       Linux ‚Äî     ,    ,             .     Kafka     ,    -    .     (   ) ,         .          .              net.core.wmem_default  net.core.rmem_default ,      2 097 152 (2 ).   ,           ,       . <br><br>              TCP    net.ipv4.tcp_wmem  net.ipv4.tcp_rmem.        ,   ,       .    ‚Äî 4096 65536 2048000 ‚Äî ,     4 ,    ‚Äî 64 ,   ‚Äî 2 .      ,      net.core.wmem_max  net.core.rmem_max.        Kafka           . <br><br>      .     TCP    1  net.ipv4.tcp_window_scaling,               .   net.ipv4.tcp_max_syn_backlog ,     1024,     .   net.core.netdev_max_backlog,     1000,       ,       ,    ,       . <br><br><h3>   </h3><br>      Kafka      ,             . <br><br><h3>    </h3><br>     Java      ,           ,   .  ,     Java 7     Garbage First (G1). G1                    .         ,       ,           . <br><br>         G1   .       . <br><br><ul><li> MaxGCPauseMillis.         .     ‚Äî   G1    .      200 .  ,  G1       ,    ,    , ,      200 . </li><li> InitiatingHeapOccupancyPercent.        ,       .     45.  ,  G1       ,    45 % ,       (Eden),    . </li></ul><br>  Kafka         ,         .               64   ,  Kafka     5 .       20  MaxGCPauseMillis.    InitiatingHeapOccupancyPercent   35,       ,     . <br><br>   Kafka       G1,            .       .       : <br><br><pre> <code class="hljs pgsql"># export JAVA_HOME=/usr/java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_51 # export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true" # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>.sh -daemon /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/config/<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.properties #</code> </pre> <br><h3>   </h3><br>          Kafka      ,                 .             -    ,     .         Kafka (.  6),         .        Kafka,       . <br><br>  Kafka             ,  ,                     (    , , AWS),           ,            .          .  ,   ¬´¬ª             (.    6). <br><br>  :    Kafka      ,   ,       ,     .             (     )                   .               , ,     . <br><br><h3>    ZooKeeper </h3><br> Kafka  ZooKeeper     ,   .   ZooKeeper              Kafka.     ,      ZooKeeper    Kafka  .      ZooKeeper      Kafka (     ZooKeeper   ,      ). <br><br>      ZooKeeper     .        ZooKeeper,  Kafka,      .    ZooKeeper  ,        ZooKeeper        .       ‚Äî 1 ,               .        ZooKeeper,      ,     .   ZooKeeper      ,     .  ,      Kafka   Kafka        ZooKeeper. <br><br>         Kafka,       ,    . Kafka         ZooKeeper,          .              ZooKeeper,     .        ,            , ,     .    ,            ,   . <br><br><h3>  Sum√°rio </h3><br>       ,     Apache Kafka. ,       ,         . ,   Kafka,         Kafka.             Kafka ( 3),       ( 4). <br><br>  ¬ªMais informa√ß√µes sobre o livro podem ser encontradas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site do editor</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Conte√∫do</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Trecho</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><br></a> <br>    20%   ‚Äî <b>Apache Kafka</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt421519/">https://habr.com/ru/post/pt421519/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt421501/index.html">O Hacker encontrou uma maneira de rastrear visitantes de sites concorrentes</a></li>
<li><a href="../pt421503/index.html">Como escrever instru√ß√µes para entender</a></li>
<li><a href="../pt421505/index.html">Mini hacks de vida para trabalhar com o Yandex.Direct</a></li>
<li><a href="../pt421507/index.html">Quais foram os soldadores para √≥ptica</a></li>
<li><a href="../pt421513/index.html">Introdu√ß√£o suave ao scrum pelos pr√≥prios desenvolvedores (resolvemos as contradi√ß√µes, montamos a equipe, evitamos conflitos)</a></li>
<li><a href="../pt421521/index.html">Monstros ap√≥s as f√©rias: AMD Threadripper 2990WX 32-Core e 2950X 16-Core (parte 3 - testes)</a></li>
<li><a href="../pt421523/index.html">Unidade: conhecendo objetos program√°veis</a></li>
<li><a href="../pt421525/index.html">Um pouco sobre as diferen√ßas entre hosters russos e estrangeiros</a></li>
<li><a href="../pt421527/index.html">Lan√ßamento da transmiss√£o do projeto "Servidor nas nuvens"</a></li>
<li><a href="../pt421529/index.html">Netflix, Uber, Google e voc√™ no MBLT DEV 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
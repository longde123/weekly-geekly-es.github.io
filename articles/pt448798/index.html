<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏼‍🔬 👩‍🔧 👩🏽‍🤝‍👨🏻 Teste de Python com pytest. Usando pytest com outras ferramentas, CAPÍTULO 7 🏀 🧥 😹</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Voltar 


 Normalmente, o pytest não é usado independentemente, mas em um ambiente de teste com outras ferramentas. Este capítulo discute outras ferra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Teste de Python com pytest. Usando pytest com outras ferramentas, CAPÍTULO 7</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448798/"><p><img src="https://habrastorage.org/webt/jl/jn/bb/jljnbbjr-ejh473xy_eccsmknpk.png">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Voltar</a> </p><br><p>  <em>Normalmente, o pytest não é usado independentemente, mas em um ambiente de teste com outras ferramentas.</em>  <em>Este capítulo discute outras ferramentas que são frequentemente usadas em conjunto com o pytest para testes eficazes e eficientes.</em>  <em>Embora essa não seja de forma alguma uma lista exaustiva, as ferramentas discutidas aqui fornecerão uma idéia do sabor do poder de misturar o pytest com outras ferramentas.</em> </p><br><p><img src="https://habrastorage.org/webt/hd/--/9w/hd--9w134j0rxhmxftrflbbdopy.png"></p><a name="habracut"></a><br><p>  Os exemplos deste livro foram escritos usando Python 3.6 e pytest 3.2.  O pytest 3.2 suporta Python 2.6, 2.7 e Python 3.3+. </p><br><blockquote> O código-fonte do projeto Tarefas, bem como todos os testes mostrados neste livro, estão disponíveis no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" title="https://pragprog.com/titles/bopytest/source_code">link</a> na página da Web do livro em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" title="https://pragprog.com/titles/bopytest">pragprog.com</a> .  Você não precisa fazer o download do código-fonte para entender o código de teste;  o código de teste é apresentado de forma conveniente nos exemplos.  Mas, para acompanhar as tarefas do projeto ou adaptar exemplos de teste para testar seu próprio projeto (suas mãos estão desamarradas!), Você deve acessar a página da Web do livro e fazer o download do trabalho.  Lá, na página do livro, há um link para mensagens de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" title="https://pragprog.com/titles/bopytest/errata">errata</a> e um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" title="https://forums.pragprog.com/forums/438">fórum de discussão</a> . </blockquote><p>  Sob o spoiler, há uma lista de artigos desta série. </p><br><div class="spoiler">  <b class="spoiler_title">Sumário</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><strong>1. Introdução</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><strong>Capítulo 1: Introdução ao pytest</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><strong>Capítulo 2: Escrevendo funções de teste</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><strong>Capítulo 3: Acessórios Pytest</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><strong>Capítulo 4: Acessórios embutidos</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><strong>Capítulo 5: Plugins</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><strong>Capítulo 6: Configuração</strong></a> </li><li>  [ <strong>Capítulo 7: Usando pytest com outras ferramentas</strong> ] (Este artigo) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://habr.com/en/post/448798/</a> ) </li></ul></div></div><br><h2 id="pdb-debugging-test-failures">  PDB: falhas de teste de depuração </h2><br><p> O módulo <code>pdb</code> é um depurador Python na biblioteca padrão.  Você usa <code>--pdb</code> para que o pytest inicie uma sessão de depuração no ponto de falha.  Vejamos o <code>pdb</code> em ação no contexto do projeto Tarefas. </p><br><p>  Em “Parametrizando o dispositivo elétrico” na página 64, deixamos o projeto Tarefas com alguns erros: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch3/c/tasks_proj $ pytest --tb=no -q .........................................FF.FFFF FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF.FFF........... 42 failed, 54 passed in 4.74 seconds</code> </pre> <br><p>  Antes de <code>pdb</code> como o <code>pdb</code> pode nos ajudar a depurar esse teste, vamos dar uma olhada nas opções pytest disponíveis para acelerar a depuração dos erros de teste, que examinamos pela primeira vez na seção “Usando opções” na página 9: </p><br><ul><li>  <code>--tb=[auto/long/short/line/native/no]</code> : controla o estilo de rastreamento. </li><li>  <code>-v / --verbose</code> : exibe todos os nomes de teste que foram aprovados ou falharam. </li><li>  <code>-l / --showlocals</code> : exibe variáveis ​​locais ao lado do rastreamento de pilha. </li><li>  <code>-lf / --last-failed</code> : Executa apenas testes que falham. </li><li>  <code>-x / --exitfirst</code> : interrompe a sessão de teste na primeira falha. </li><li>  <code>--pdb</code> : inicia uma sessão de depuração interativa no ponto de falha. </li></ul><br><hr><br><p>  <em>Instalando o MongoDB</em> </p><br><hr><br><p>  Conforme mencionado no Capítulo 3, “Acessórios Pytest”, na página 49, a instalação do <code>MongoDB</code> e do <code>pymongo</code> é necessária para executar os testes do MongoDB. </p><br><p>  Testei a versão do Community Server encontrada em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://www.mongodb.com/download-center</a> .  O pymongo é instalado com <code>pip</code> : <code>pip install pymongo</code> .  No entanto, este é o último exemplo de um livro que usa o MongoDB.  Para testar o depurador sem usar o MongoDB, você pode executar os comandos pytest a partir do <code>code/ch2/</code> , pois esse diretório também contém vários testes com falha. </p><br><hr><br><p>  Acabamos de executar os testes do <code>code/ch3/c</code> para garantir que alguns deles não estejam funcionando.  Não vimos tracebacks ou nomes de teste porque <code>--tb=no</code> desativa o rastreamento e não tínhamos <code>--verbose</code> ativado.  Vamos repetir os erros (não mais que três) com o texto detalhado: </p><br><pre> <code class="plaintext hljs">$ pytest --tb=no --verbose --lf --maxfail=3 ============================= test session starts ============================= collected 96 items / 52 deselected run-last-failure: rerun previous 44 failures tests/func/test_add.py::test_add_returns_valid_id[mongo] ERROR [ 2%] tests/func/test_add.py::test_added_task_has_id_set[mongo] ERROR [ 4%] tests/func/test_add.py::test_add_increases_count[mongo] ERROR [ 6%] =================== 52 deselected, 3 error in 0.72 seconds ====================</code> </pre> <br><p>  Agora sabemos quais testes falharam.  Vejamos apenas um deles, usando <code>-x</code> , ativando o rastreamento, não usando <code>--tb=no</code> e mostrando variáveis ​​locais com <code>-l</code> : </p><br><pre> <code class="plaintext hljs">$ pytest -v --lf -l -x ===================== test session starts ====================== run-last-failure: rerun last 42 failures collected 96 items tests/func/test_add.py::test_add_returns_valid_id[mongo] FAILED =========================== FAILURES =========================== _______________ test_add_returns_valid_id[mongo] _______________ tasks_db = None def test_add_returns_valid_id(tasks_db): """tasks.add(&lt;valid task&gt;) should return an integer.""" # GIVEN an initialized tasks db # WHEN a new task is added # THEN returned task_id is of type int new_task = Task('do something') task_id = tasks.add(new_task) &gt; assert isinstance(task_id, int) E AssertionError: assert False E + where False = isinstance(ObjectId('59783baf8204177f24cb1b68'), int) new_task = Task(summary='do something', owner=None, done=False, id=None) task_id = ObjectId('59783baf8204177f24cb1b68') tasks_db = None tests/func/test_add.py:16: AssertionError !!!!!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!!!! ===================== 54 tests deselected ====================== =========== 1 failed, 54 deselected in 2.47 seconds ============</code> </pre><br><p>  Muitas vezes, isso é suficiente para entender por que o teste falhou.  Nesse caso específico, é bastante claro que <code>task_id</code> não <code>task_id</code> um número inteiro - é uma instância do ObjectId.  ObjectId é o tipo usado pelo MongoDB para identificadores de objeto no banco de dados.  Minha intenção com a camada <code>tasksdb_pymongo.py</code> era ocultar certos detalhes da implementação do MongoDB do restante do sistema.  É claro que, neste caso, não funcionou. </p><br><p>  No entanto, queremos ver como usar o pdb com o pytest, então vamos imaginar que não está claro por que esse teste falhou.  Podemos fazer com que o pytest inicie uma sessão de depuração e nos inicie no ponto da falha usando <code>--pdb</code> : </p><br><pre> <code class="plaintext hljs">$ pytest -v --lf -x --pdb ===================== test session starts ====================== run-last-failure: rerun last 42 failures collected 96 items tests/func/test_add.py::test_add_returns_valid_id[mongo] FAILED &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; traceback &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; tasks_db = None def test_add_returns_valid_id(tasks_db): """tasks.add(&lt;valid task&gt;) should return an integer.""" # GIVEN an initialized tasks db # WHEN a new task is added # THEN returned task_id is of type int new_task = Task('do something') task_id = tasks.add(new_task) &gt; assert isinstance(task_id, int) E AssertionError: assert False E + where False = isinstance(ObjectId('59783bf48204177f2a786893'), int) tests/func/test_add.py:16: AssertionError &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; entering PDB &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt; /path/to/code/ch3/c/tasks_proj/tests/func/test_add.py(16) &gt; test_add_returns_valid_id() -&gt; assert isinstance(task_id, int) (Pdb)</code> </pre> <br><p>  Agora que estamos no prompt (Pdb), temos acesso a todos os recursos interativos de depuração de pdb.  Ao visualizar falhas, uso regularmente estes comandos: </p><br><ul><li>  <code>p/print expr</code> : imprime o valor da exp. </li><li>  <code>pp expr</code> : Pretty imprime o valor de expr. </li><li>  <code>l/list</code> : lista o ponto de falha e cinco linhas de código acima e abaixo. </li><li>  <code>l/list begin,end</code> : enumera números de linha específicos. </li><li>  <code>a/args</code> : imprime os argumentos da função atual com seus valores. </li><li>  <code>u/up</code> : Move um nível acima do caminho da pilha. </li><li>  <code>d/down</code> : desce um nível no rastreamento de pilha. </li><li>  <code>q/quit</code> : finaliza uma sessão de depuração. </li></ul><br><p>  Outros comandos de navegação, como step e next, não são muito úteis, pois estamos sentados na declaração assert.  Você também pode simplesmente inserir nomes de variáveis ​​e obter valores. </p><br><p>  Você pode usar <code>p/print expr</code> maneira semelhante à <code>-l/--showlocals</code> para visualizar os valores em uma função: </p><br><pre> <code class="plaintext hljs">(Pdb) p new_task Task(summary='do something', owner=None, done=False, id=None) (Pdb) p task_id ObjectId('59783bf48204177f2a786893') (Pdb)</code> </pre> <br><p>  Agora você pode sair do depurador e continuar testando. </p><br><pre> <code class="plaintext hljs">(Pdb) q !!!!!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!!!! ===================== 54 tests deselected ====================== ========== 1 failed, 54 deselected in 123.40 seconds ===========</code> </pre> <br><p>  Se não usássemos <code>-</code> , o pytest abriria novamente o Pdb no próximo teste.  Mais informações sobre o uso do módulo pdb estão disponíveis na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documentação</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Python</a> . </p><br><h2 id="coveragepy-opredelenie-obema-testiruemogo-koda">  Coverage.py: determinando a quantidade de código de teste </h2><br><p>  A cobertura do código é um indicador da porcentagem de código testado que é testado por um conjunto de testes.  Quando você executa testes para o projeto Tarefas, algumas funções de Tarefas são executadas em cada teste, mas não em todos. </p><br><p>  As ferramentas de cobertura de código são ótimas para informar quais partes do sistema são completamente ignoradas pelos testes. </p><br><p>  <code>Coverage.py</code> é a ferramenta de cobertura Python preferida que mede a cobertura de código. </p><br><p>  Você o utilizará para verificar o código do projeto Tarefas com pytest. </p><br><p>  Para usar o <code>coverage.py</code> você precisa instalá-lo.  Não <code>pytest-cov</code> nada instalar um plug-in chamado <code>pytest-cov</code> , que permite chamar a <code>coverage.py</code> do pytest com algumas opções adicionais de pytest.  Como a <code>coverage</code> é uma das dependências do <code>pytest-cov</code> , basta instalar o <code>pytest-cov</code> e a <code>coverage.py</code> será <code>pytest-cov</code> : </p><br><pre> <code class="plaintext hljs">$ pip install pytest-cov Collecting pytest-cov Using cached pytest_cov-2.5.1-py2.py3-none-any.whl Collecting coverage&gt;=3.7.1 (from pytest-cov) Using cached coverage-4.4.1-cp36-cp36m-macosx_10_10_x86 ... Installing collected packages: coverage, pytest-cov Successfully installed coverage-4.4.1 pytest-cov-2.5.1</code> </pre> <br><p>  Vamos executar o relatório de cobertura para a segunda versão da tarefa.  Se você ainda tiver a primeira versão do projeto Tarefas instalada, desinstale-a e instale a versão 2: </p><br><pre> <code class="plaintext hljs">$ pip uninstall tasks Uninstalling tasks-0.1.0: /path/to/venv/bin/tasks /path/to/venv/lib/python3.6/site-packages/tasks.egg-link Proceed (y/n)? y Successfully uninstalled tasks-0.1.0 $ cd /path/to/code/ch7/tasks_proj_v2 $ pip install -e . Obtaining file:///path/to/code/ch7/tasks_proj_v2 ... Installing collected packages: tasks Running setup.py develop for tasks Successfully installed tasks $ pip list ... tasks (0.1.1, /path/to/code/ch7/tasks_proj_v2/src) ...</code> </pre> <br><p>  Agora que a próxima versão das tarefas está instalada, você pode executar o relatório de cobertura base: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch7/tasks_proj_v2 $ pytest --cov=src ===================== test session starts ====================== plugins: mock-1.6.2, cov-2.5.1 collected 62 items tests/func/test_add.py ... tests/func/test_add_variety.py ............................ tests/func/test_add_variety2.py ............ tests/func/test_api_exceptions.py ......... tests/func/test_unique_id.py . tests/unit/test_cli.py ..... tests/unit/test_task.py .... ---------- coverage: platform darwin, python 3.6.2-final-0 ----------- Name Stmts Miss Cover -------------------------------------------------- src\tasks\__init__.py 2 0 100% src\tasks\api.py 79 22 72% src\tasks\cli.py 45 14 69% src\tasks\config.py 18 12 33% src\tasks\tasksdb_pymongo.py 74 74 0% src\tasks\tasksdb_tinydb.py 32 4 88% -------------------------------------------------- TOTAL 250 126 50% ================== 62 passed in 0.47 seconds ===================</code> </pre> <br><p>  Como o diretório atual é <code>tasks_proj_v2</code> e o código-fonte em teste está em src, a adição da opção <code>--cov=src</code> gera um relatório de cobertura apenas para esse diretório em teste. </p><br><p>  Como você pode ver, alguns arquivos têm cobertura muito baixa e até 0%.  Estes são lembretes úteis: <code>tasksdb_pymongo.py</code> 0% porque desativamos o teste do MongoDB nesta versão.  Alguns deles são bastante baixos.  O projeto certamente terá que realizar testes para todas essas áreas antes de estar pronto para o horário nobre. </p><br><p>  Acredito que vários arquivos tenham uma porcentagem maior de cobertura: <code>api.py</code> e <code>tasksdb_tinydb.py</code> .  Vamos dar uma olhada em <code>tasksdb_tinydb.py</code> e ver o que está faltando.  Eu acho que a melhor maneira de fazer isso é usar relatórios HTML. </p><br><p>  Se você executar o <code>--cov-report=html</code> novamente com a opção <code>--cov-report=html</code> , um <code>--cov-report=html</code> será gerado: </p><br><pre> <code class="plaintext hljs">$ pytest --cov=src --cov-report=html ===================== test session starts ====================== plugins: mock-1.6.2, cov-2.5.1 collected 62 items tests/func/test_add.py ... tests/func/test_add_variety.py ............................ tests/func/test_add_variety2.py ............ tests/func/test_api_exceptions.py ......... tests/func/test_unique_id.py . tests/unit/test_cli.py ..... tests/unit/test_task.py .... ---------- coverage: platform darwin, python 3.6.2-final-0 ----------- Coverage HTML written to dir htmlcov ================== 62 passed in 0.45 seconds ===================</code> </pre> <br><p>  Você pode abrir o <code>htmlcov/index.html</code> em um navegador que exibe a saída na seguinte tela: </p><br><p><img src="https://habrastorage.org/webt/vs/sc/84/vssc84hovxefvf2g65740gu3ll0.png"></p><br><p>  Clicar em <code>tasksdb_tinydb.py</code> exibirá um relatório para um arquivo.  A porcentagem de linhas cobertas é exibida na parte superior do relatório, mais quantas linhas são cobertas e quantas não, como mostrado na próxima tela: </p><br><p><img src="https://habrastorage.org/webt/os/pc/-o/ospc-o_yzzdfh1lzllw_1qtilrc.png"></p><br><p>  Rolando para baixo, você pode ver as linhas ausentes, conforme mostrado na tela a seguir: </p><br><p><img src="https://habrastorage.org/webt/85/rg/lt/85rgltocwrunycedzbeweix4zyc.png"></p><br><p>  Mesmo que essa tela não seja uma página completa para esse arquivo, basta dizer que: </p><br><ol><li>  Não testamos <code>list_tasks()</code> com o conjunto de proprietários. </li><li>  Não testamos <code>update()</code> ou <code>delete()</code> . </li><li>  Talvez não <code>unique_id()</code> testando completamente <code>unique_id()</code> . </li></ol><br><p>  Ótimo.  Podemos incluí-los em nossa lista de testes de tarefas, juntamente com o teste do sistema de configuração. </p><br><p>  Embora as ferramentas de cobertura de código sejam extremamente úteis, buscar 100% de cobertura pode ser perigoso.  Quando você vê um código que não está sendo testado, isso pode significar a necessidade de um teste.  Mas também pode significar que existem algumas funções do sistema que não são necessárias e podem ser removidas.  Como todas as ferramentas de desenvolvimento de software, a análise de cobertura de código não substitui o pensamento. </p><br><p>  Consulte a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><code> coverage.py</code></a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><code>pytest-cov</code></a> obter mais detalhes. </p><br><h2 id="mock-podmena-chastey-sistemy">  mock: substituição de peças do sistema </h2><br><p>  O pacote simulado é usado para substituir partes do sistema para isolar partes do código de teste do restante do sistema.  Mock - objetos às vezes são chamados de dobras de teste, espiões, falsificações ou tocos. </p><br><p>  Entre o seu próprio dispositivo pytest monkeypatch (descrito em Usando o monkeypatch na página 85) e o mock, você deve ter toda a funcionalidade de teste duplo necessária. </p><br><blockquote>  Atenção!  Simulado e muito estranho <br>  Se esta é a primeira vez que você encontra gêmeos de teste, como zombarias, tocos e espiões, prepare-se!  Será muito estranho muito rápido, engraçado, embora muito impressionante. </blockquote><p>  O pacote <code>mock</code> vem com a biblioteca padrão do Python, como <code>unittest.mock</code> desde o Python 3.3.  Nas versões anteriores, ele está disponível como um pacote separado instalado através do PyPI.  Isso significa que você pode usar a versão <code>mock</code> PyPI do Python 2.6 para a versão mais recente do Python e obter a mesma funcionalidade do último <code>mock</code> Python.  No entanto, para uso com o pytest, um plug-in chamado <code>pytest-mock</code> possui alguns recursos que o tornam minha interface preferida para o sistema de mock. </p><br><p>  Para o projeto Tarefas, usaremos <code>mock</code> para nos ajudar a testar a interface da linha de comandos.  Em Coverage.py: ao determinar quanto código está sendo testado, na página 129 você viu que nosso arquivo <code>cli.py</code> não foi testado.  Vamos começar a consertar isso agora.  Mas vamos falar sobre estratégia primeiro. </p><br><p>  A primeira solução no projeto Tarefas foi fazer a maioria dos testes de funcionalidade por meio do <code>api.py</code>  Portanto, uma solução razoável é que o teste de linha de comando não precise ser um teste funcional completo.  Podemos ter certeza de que o sistema funcionará através da CLI se atingirmos o nível da API úmida durante o teste da CLI.  Também é uma solução conveniente que nos permite examinar o moki nesta seção. </p><br><p>  A implementação de tarefas da CLI usa um pacote de interface de linha de comando de terceiros.  Existem muitas alternativas para implementar a interface da linha de comandos, incluindo um módulo embutido no Python <code>argparse</code> .  Um dos motivos pelos quais escolhi o Click é porque ele inclui um mecanismo de teste que nos ajuda a testar os aplicativos Click.  No entanto, o código no <code>cli.py</code> , embora esperemos que seja típico dos aplicativos Click, não é óbvio. </p><br><p>  Vamos diminuir a velocidade e instalar a terceira versão do Tasks: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ $ pip install -e ch7/tasks_proj_v2 ... Successfully installed tasks</code> </pre> <br><p>  No restante desta seção, você desenvolverá vários testes para testar a funcionalidade da "lista". <br>  Vamos vê-lo em ação para entender o que vamos verificar: </p><br><blockquote>  <strong><em>Nota do tradutor:</em></strong> Ao usar a plataforma Windows, encontrei vários problemas ao testar a sessão abaixo. <br><ol><li>  Uma pasta deve ser criada para o banco de dados denominado <strong><code>tasks_db</code></strong> na pasta do seu usuário.  Por exemplo <code>c:\Users\User_1\tasks_db\</code> <br>  Caso contrário, obteremos - &gt;&gt; FileNotFoundError: [Erro 2] Não existe esse arquivo ou diretório: 'c: \ Users \ User_1 // tasks_db // tasks_db.json' </li><li>  Use aspas duplas em vez de um apóstrofo.  Caso contrário, obtenha um erro <br>  'faça algo ótimo' <br>  Uso: tarefas adicionam [OPTIONS] RESUMO <br>  Tente "task add -h" para obter ajuda. <br><br>  Erro: obtive argumentos extras inesperados (algo ótimo ') <br></li></ol><br></blockquote><br><pre> <code class="plaintext hljs">$ tasks list ID owner done summary -- ----- ---- ------- $ tasks add 'do something great' $ tasks add "repeat" -o Brian $ tasks add "again and again" --owner Okken $ tasks list ID owner done summary -- ----- ---- ------- 1 False do something great 2 Brian False repeat 3 Okken False again and again $ tasks list -o Brian ID owner done summary -- ----- ---- ------- 2 Brian False repeat $ tasks list --owner Brian ID owner done summary -- ----- ---- ------- 2 Brian False repeat</code> </pre> <br><p>  Parece bem simples.  O comando <code>tasks list</code> exibe uma lista de todas as tarefas sob o cabeçalho. <br>  O título é impresso mesmo se a lista estiver vazia.  O comando exibe apenas dados de um proprietário, se <code>-o</code> ou <code>--owner</code> .  E como verificamos isso?  Existem muitas maneiras, mas vamos usar o moki. </p><br><p>  Testes que usam MOKs são necessariamente <em>testes de caixa branca</em> , e precisamos examinar o código para decidir o que e onde iremos bater.  O principal ponto de entrada está aqui: </p><br><blockquote>  ch7 / tasks_proj_v2 / src / tasks / cli.py </blockquote><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: tasks_cli()</code> </pre> <br><p>  Esta é apenas uma chamada para <code>tasks_cli()</code> : </p><br><blockquote>  ch7 / tasks_proj_v2 / src / tasks / cli.py </blockquote><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@click.group(context_settings={'help_option_names': ['-h', '--help']}) @click.version_option(version='0.1.1') def tasks_cli(): """Run the tasks application.""" pass</span></span></code> </pre> <br><p>  Obviamente?  Não.  Mas espere, fica bom (ou ruim, dependendo do seu ponto de vista).  Aqui está um dos comandos da <code>list</code> : </p><br><blockquote>  ch7 / tasks_proj_v2 / src / tasks / cli.py </blockquote><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@tasks_cli.command(name="list", help="list tasks") @click.option('-o', '--owner', default=None, help='list tasks with this owner') def list_tasks(owner): """    .   ,      . """ formatstr = "{: &gt;4} {: &gt;10} {: &gt;5} {}" print(formatstr.format('ID', 'owner', 'done', 'summary')) print(formatstr.format('--', '-----', '----', '-------')) with _tasks_db(): for t in tasks.list_tasks(owner): done = 'True' if t.done else 'False' owner = '' if t.owner is None else t.owner print(formatstr.format( t.id, owner, done, t.summary))</span></span></code> </pre> <br><p>  Quando você se acostumar a escrever o código Click, verifique se esse código não é tão ruim.  Não vou explicar aqui o que e como funciona nesta função, pois o desenvolvimento do código da linha de comando não é o foco do livro;  no entanto, embora eu tenha quase certeza absoluta de que tenho esse código correto, há sempre muito espaço para erro humano.  É por isso que um bom conjunto de testes automatizados é importante para garantir que esse recurso funcione corretamente. <br>  Essa função <code>list_tasks(owner)</code> depende de várias outras funções: <code>tasks_db()</code> , que é o gerenciador de contexto, e <code>tasks.list_tasks(owner)</code> , que é a função da API. </p><br><p>  Vamos usar o <code>mock</code> para colocar funções falsas no <code>tasks_db()</code> e <code>tasks.list_tasks()</code> .  Em seguida, podemos chamar o método <code>list_tasks</code> por meio da interface da linha de comandos e garantir que ele chame a função <code>tasks.list_tasks()</code> , que funciona corretamente e processa corretamente o valor de retorno. <br>  Para abafar <code>tasks_db()</code> , vamos ver uma implementação real: </p><br><p><img src="https://habrastorage.org/webt/jl/jn/bb/jljnbbjr-ejh473xy_eccsmknpk.png">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Voltar</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt448798/">https://habr.com/ru/post/pt448798/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt448776/index.html">RxVMS - Uma Arquitetura Prática para Aplicações de Flutter</a></li>
<li><a href="../pt448782/index.html">Teste de Python com pytest. Introdução ao pytest, Capítulo 1</a></li>
<li><a href="../pt448784/index.html">Novos recursos para autores de extensão no Visual Studio 2019 versão 16.1</a></li>
<li><a href="../pt448792/index.html">Teste de Python com pytest. Acessórios Internos, Capítulo 4</a></li>
<li><a href="../pt448796/index.html">Teste de Python com pytest. Configuração, CAPÍTULO 6</a></li>
<li><a href="../pt448802/index.html">Pensando em portais: criando portais no Unreal Engine 4</a></li>
<li><a href="../pt448804/index.html">Preparando-se para o tempo de execução e o notário reforçados do macOS</a></li>
<li><a href="../pt448808/index.html">Sobre coisas simples, complicadas. "Dormindo aço". Como lubrificar parafusos enferrujados ou não WD-40 com um único ...</a></li>
<li><a href="../pt448810/index.html">Como eu peguei um hacker</a></li>
<li><a href="../pt448812/index.html">Missão lunar “Bereshit” - procura a primeira biblioteca lunar após o início do acidente de sua transportadora</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
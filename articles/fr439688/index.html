<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï∫üèª üó∫Ô∏è üë®üèΩ‚Äçü§ù‚Äçüë®üèº Aper√ßu des solutions AI et ML en 2018 et pr√©visions pour 2019: Partie 1 - PNL, vision par ordinateur üñçÔ∏è ‚§¥Ô∏è üíª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous! Je vous pr√©sente une traduction d'un article d' Analytics Vidhya avec un aper√ßu des √©v√©nements AI / ML dans les tendances 2018 et 2019...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aper√ßu des solutions AI et ML en 2018 et pr√©visions pour 2019: Partie 1 - PNL, vision par ordinateur</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439688/"><blockquote> Bonjour √† tous!  Je vous pr√©sente une traduction d'un article d' <i>Analytics Vidhya</i> avec un aper√ßu des √©v√©nements AI / ML dans les tendances 2018 et 2019.  Le mat√©riau est assez grand, il est donc divis√© en 2 parties.  J'esp√®re que l'article int√©ressera non seulement les sp√©cialistes sp√©cialis√©s, mais aussi ceux qui s'int√©ressent au sujet de l'IA.  Bonne lecture! <br><br><div class="spoiler">  <b class="spoiler_title">Navigation dans l'article</b> <div class="spoiler_text">  <b>Partie 1</b> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Traitement du langage naturel (PNL)</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tendances PNL pour 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vision par ordinateur</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tendances de la vision industrielle pour 2019</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2e partie</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Outils et biblioth√®ques</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tendances AutoML pour 2019</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apprentissage par renforcement</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tendances d'apprentissage par renforcement pour 2019</a> <br>  - L' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IA pour les bons gar√ßons - √©volution vers une IA ¬´√©thique¬ª</a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tendances √©thiques de l'IA pour 2019</a> <br></div></div></blockquote><br><h2>  Pr√©sentation </h2><br>  Les derni√®res ann√©es pour les passionn√©s de l'IA et les professionnels du machine learning se sont √©coul√©es dans la poursuite d'un r√™ve.  Ces technologies ont cess√© d'√™tre des cr√©neaux, sont devenues courantes et affectent d√©j√† la vie de millions de personnes en ce moment.  Des minist√®res de l'IA ont √©t√© cr√©√©s dans diff√©rents pays [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plus de d√©tails ici</a> - env.  par.] et les budgets sont allou√©s pour suivre cette course. <br><br>  Il en va de m√™me pour les professionnels de la science des donn√©es.  Il y a quelques ann√©es, vous pouviez vous sentir √† l'aise avec quelques outils et astuces, mais ce temps est r√©volu.  Le nombre d'√©v√©nements r√©cents en science des donn√©es et la quantit√© de connaissances n√©cessaires pour suivre le rythme dans ce domaine sont incroyables. <br><br>  J'ai d√©cid√© de prendre du recul et de regarder les d√©veloppements dans certains domaines cl√©s dans le domaine de l'intelligence artificielle du point de vue des experts en science des donn√©es.  Quelles √©vasions se sont produites?  Que s'est-il pass√© en 2018 et √† quoi s'attendre en 2019?  Lisez cet article pour des r√©ponses! <a name="habracut"></a><br><br>  PS Comme dans toute pr√©vision, voici mes conclusions personnelles bas√©es sur les tentatives de combiner des fragments individuels dans l'image enti√®re.  Si votre point de vue est diff√©rent du mien, je serai heureux de conna√Ætre votre opinion sur ce qui pourrait changer dans la science des donn√©es en 2019. <br><br>  Les domaines que nous aborderons dans cet article sont: <br><br>  - Processus de langage naturel (PNL) <br>  - Vision par ordinateur <br>  - Outils et biblioth√®ques <br>  - Apprentissage par renforcement <br>  - Probl√®mes √©thiques en IA <br><br><a name="NLP"></a><h2>  Traitement du langage naturel (PNL) </h2><br>  Forcer les machines √† analyser des mots et des phrases a toujours sembl√© √™tre un r√™ve chim√©rique.  Il y a beaucoup de nuances et de fonctionnalit√©s dans les langues qui sont parfois difficiles √† comprendre m√™me pour les gens, mais 2018 a √©t√© un v√©ritable tournant pour la PNL. <br><br>  Nous avons observ√© une formidable perc√©e apr√®s l'autre: ULMFiT, ELMO, OpenAl Transformer, Google BERT, et ce n'est pas une liste compl√®te.  L'application r√©ussie de l'apprentissage par transfert (l'art d'appliquer des mod√®les pr√©-form√©s aux donn√©es) a ouvert la porte √† la PNL dans une vari√©t√© de t√¢ches. <br><blockquote>  Transfert d'apprentissage - vous permet d'adapter un mod√®le / syst√®me pr√©-form√© √† votre t√¢che sp√©cifique en utilisant une quantit√© relativement faible de donn√©es. </blockquote>  Examinons plus en d√©tail certains de ces d√©veloppements cl√©s. <br><br><h3>  ULMFiT </h3><br>  D√©velopp√© par Sebastian Ruder et Jeremy Howard (fast.ai), ULMFiT a √©t√© le premier framework √† recevoir un apprentissage par transfert cette ann√©e.  Pour les non-initi√©s, l'acronyme ULMFiT signifie ¬´Universal Language Model Fine-Tuning¬ª.  Jeremy et Sebastian ont ajout√© √† juste titre le mot ¬´universel¬ª √† ULMFiT - ce cadre peut √™tre appliqu√© √† presque toutes les t√¢ches de PNL! <br><br>  La meilleure chose √† propos d'ULMFiT est que vous n'avez pas besoin de former des mod√®les √† partir de z√©ro!  Les chercheurs ont d√©j√† fait le plus difficile pour vous - prenez et postulez dans vos projets.  ULMFiT a surpass√© les autres m√©thodes dans six t√¢ches de classification de texte. <br><br>  Vous pouvez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lire le</a> tutoriel de Pratek Joshi [Pateek Joshi - env.  trans.] sur la fa√ßon de commencer √† utiliser ULMFiT pour toute t√¢che de classification de texte. <br><br><h3>  ELMo </h3><br>  Devinez ce que l'abr√©viation ELMo signifie?  Acronyme de Embeddings from Language Models [pi√®ces jointes des mod√®les linguistiques - env.  trans.].  Et ELMo a attir√© l'attention de la communaut√© ML juste apr√®s la sortie. <br><br>  ELMo utilise des mod√®les de langage pour recevoir des pi√®ces jointes pour chaque mot, et prend √©galement en compte le contexte dans lequel le mot s'inscrit dans une phrase ou un paragraphe.  Le contexte est un aspect critique de la PNL, dans lequel la plupart des d√©veloppeurs ont pr√©c√©demment √©chou√©.  ELMo utilise des LSTM bidirectionnels pour cr√©er des pi√®ces jointes. <br><blockquote>  La m√©moire √† court terme √† long terme (LSTM) est un type d'architecture de r√©seaux de neurones r√©currents propos√© en 1997 par Sepp Hochreiter et J√ºrgen Schmidhuber.  Comme la plupart des r√©seaux de neurones r√©currents, un r√©seau LSTM est universel dans le sens o√π, avec un nombre suffisant d'√©l√©ments de r√©seau, il peut effectuer tout calcul dont un ordinateur ordinaire est capable, ce qui n√©cessite une matrice de poids appropri√©e qui peut √™tre consid√©r√©e comme un programme.  Contrairement aux r√©seaux de neurones r√©currents traditionnels, le r√©seau LSTM est bien adapt√© √† la formation sur les probl√®mes de classification, de traitement et de pr√©vision des s√©ries chronologiques dans les cas o√π des √©v√©nements importants sont s√©par√©s par des d√©calages temporels √† dur√©e et limites ind√©finies. <br><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">source.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikip√©dia</a> </blockquote>  Comme ULMFiT, ELMo am√©liore consid√©rablement la productivit√© dans la r√©solution d'un grand nombre de t√¢ches PNL, telles que l'analyse de l'humeur du texte ou la r√©ponse aux questions. <br><br><h3>  BERT de Google </h3><br>  Beaucoup d'experts notent que la sortie de BERT a marqu√© le d√©but d'une nouvelle √®re en PNL.  Apr√®s ULMFiT et ELMo, BERT a pris les devants, d√©montrant des performances √©lev√©es.  Comme l'indique l'annonce originale: ¬´L'ORET est conceptuellement simple et empiriquement puissant.¬ª <br><br>  Le BERT a montr√© des r√©sultats exceptionnels dans 11 t√¢ches PNL!  Voir les r√©sultats dans les tests SQuAD: <br><br><img src="https://habrastorage.org/webt/rf/6n/cz/rf6nczjjvbcz1cg4nxfeo-lm7ou.png"><br><br>  Vous voulez l'essayer?  Vous pouvez utiliser la r√©impl√©mentation sur PyTorch ou le code TensorFlow de Google et essayer de r√©p√©ter le r√©sultat sur votre machine. <br><br><h3>  Facebook PyText </h3><br>  Comment Facebook pourrait-il rester √† l'√©cart de cette course?  La soci√©t√© propose son propre framework NLP open source appel√© PyText.  Selon une √©tude publi√©e par Facebook, PyText a augment√© la pr√©cision des mod√®les conversationnels de 10% et r√©duit le temps de formation. <br><br>  PyText est en fait derri√®re plusieurs des propres produits de Facebook, tels que Messenger.  Travailler avec lui ajoutera donc un bon point √† votre portefeuille et des connaissances inestimables que vous gagnerez sans aucun doute. <br><br>  Vous pouvez l'essayer vous-m√™me, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">t√©l√©chargez le code depuis GitHub</a> . <br><br><h3>  Google duplex </h3><br>  Il est difficile de croire que vous n'avez pas entendu parler de Google Duplex.  Voici une d√©mo qui a longtemps fait la une des journaux: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/NO0-5MuJvew" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Comme il s'agit d'un produit Google, il y a peu de chances que t√¥t ou tard le code soit publi√© pour tout le monde.  Bien s√ªr, cette d√©monstration soul√®ve de nombreuses questions: de l'√©thique aux probl√®mes de confidentialit√©, mais nous en parlerons plus tard.  Pour l'instant, profitez simplement du chemin parcouru avec ML ces derni√®res ann√©es. <br><br><a name="NLPtrends"></a><h2>  Tendances PNL 2019 </h2><br>  Qui mieux que Sebastian Ruder lui-m√™me peut donner une id√©e de la direction que prendra la PNL en 2019?  Voici ses conclusions: <br><blockquote><ol><li>  L'utilisation de mod√®les d'investissement linguistique pr√©-form√©s se g√©n√©ralisera;  les mod√®les avanc√©s sans support seront tr√®s rares. </li><li>  Des vues pr√©-form√©es appara√Ætront qui peuvent coder des informations sp√©cialis√©es qui compl√®tent les pi√®ces jointes du mod√®le de langage.  Nous pourrons regrouper diff√©rents types de pr√©sentations pr√©-form√©es en fonction des exigences de la t√¢che. </li><li>  D'autres travaux appara√Ætront dans le domaine des applications multilingues et des mod√®les multilingues.  En particulier, en s'appuyant sur l'int√©gration des mots dans les langues, nous verrons l'√©mergence de repr√©sentations interlangues pr√©-entra√Æn√©es profondes. </li></ol></blockquote><a name="cv"></a><h2>  Vision par ordinateur </h2><br><img src="https://habrastorage.org/webt/pu/aj/_c/puaj_c89feaiultos4yynrcj7x4.jpeg"><br><br>  Aujourd'hui, la vision par ordinateur est le domaine le plus populaire dans le domaine de l'apprentissage en profondeur.  Il semble que les premiers fruits de la technologie aient d√©j√† √©t√© obtenus et nous sommes au stade de d√©veloppement actif.  Qu'il s'agisse de cette image ou de cette vid√©o, nous voyons l'√©mergence de nombreux frameworks et biblioth√®ques qui r√©solvent facilement les probl√®mes de vision par ordinateur. <br><br>  Voici ma liste des meilleures solutions qui pourraient √™tre vues cette ann√©e. <br><br><h3>  BigGANs Out </h3><br>  Ian Goodfellow a con√ßu les GAN en 2014, et le concept a engendr√© une grande vari√©t√© d'applications.  Ann√©e apr√®s ann√©e, nous avons observ√© comment le concept original a √©t√© finalis√© pour une utilisation sur des cas r√©els.  Mais une chose est rest√©e inchang√©e jusqu'√† cette ann√©e - les images g√©n√©r√©es par ordinateur √©taient trop faciles √† distinguer.  Une certaine incoh√©rence est toujours apparue dans le cadre, ce qui a rendu la diff√©rence tr√®s √©vidente. <br><br>  Au cours des derniers mois, des changements sont apparus dans cette direction et, avec la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cr√©ation de BigGAN</a> , de tels probl√®mes peuvent √™tre r√©solus une fois pour toutes.  Regardez les images g√©n√©r√©es par cette m√©thode: <br><br><img src="https://habrastorage.org/webt/mo/w7/ow/mow7owldedw4r1jtwex6wbfwwje.png"><br><br>  Sans microscope, il est difficile de dire ce qui ne va pas avec ces images.  Bien s√ªr, chacun d√©cidera pour lui-m√™me, mais il ne fait aucun doute que le GAN change la fa√ßon dont nous percevons les images num√©riques (et la vid√©o). <br><br>  Pour r√©f√©rence: ces mod√®les ont d'abord √©t√© form√©s sur l'ensemble de donn√©es ImageNet, puis sur le JFT-300M pour d√©montrer que ces mod√®les sont bien transf√©r√©s d'un ensemble de donn√©es √† un autre.  Voici un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien vers une page</a> de la liste de diffusion GAN expliquant comment visualiser et comprendre le GAN. <br><br><h3>  Model Fast.ai form√© sur ImageNet en 18 minutes </h3><br>  C'est une impl√©mentation vraiment cool.  Il est largement admis que, pour effectuer des t√¢ches d'apprentissage en profondeur, vous aurez besoin de t√©raoctets de donn√©es et de grandes ressources informatiques.  Il en va de m√™me pour l'entra√Ænement du mod√®le √† partir de z√©ro sur les donn√©es ImageNet.  La plupart d'entre nous pensaient la m√™me chose avant que quelques personnes sur fast.ai ne soient pas en mesure de prouver le contraire √† tout le monde. <br><br>  Leur mod√®le a donn√© une pr√©cision de 93% avec un impressionnant 18 minutes.  Le mat√©riel qu'ils ont utilis√©, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©crit</a> en d√©tail <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur leur blog</a> , se composait de 16 instances cloud AWS publiques, chacune avec 8 GPU NVIDIA V100.  Ils ont construit un algorithme utilisant les biblioth√®ques fast.ai et PyTorch. <br><br>  Le co√ªt total de montage n'√©tait que de 40 $!  Jeremy a d√©crit leurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">approches et m√©thodes</a> plus en d√©tail <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  C'est une victoire commune! <br><br><h3>  vid2vid de NVIDIA </h3><br>  Au cours des 5 derni√®res ann√©es, le traitement d'image a fait de grands progr√®s, mais qu'en est-il de la vid√©o?  Les m√©thodes de conversion d'une trame statique en une trame dynamique se sont av√©r√©es un peu plus compliqu√©es que pr√©vu.  Pouvez-vous prendre une s√©quence d'images d'une vid√©o et pr√©dire ce qui se passera dans l'image suivante?  De telles √©tudes ont √©t√© faites auparavant, mais les publications √©taient au mieux vagues. <br><br><img src="https://habrastorage.org/webt/hz/ox/hj/hzoxhjbehlnlzl8ivc-bgiz0vh0.png"><br><br>  NVIDIA a d√©cid√© de rendre sa d√©cision accessible au public plus t√¥t cette ann√©e [2018 - env.  per.], qui a √©t√© √©valu√© positivement par la soci√©t√©.  Le but de vid2vid est de d√©river une fonction d'affichage d'une vid√©o d'entr√©e donn√©e afin de cr√©er une vid√©o de sortie qui transmet le contenu de la vid√©o d'entr√©e avec une pr√©cision incroyable. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/S1OwOd-war8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Vous pouvez essayer leur impl√©mentation sur PyTorch, apportez-la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√† GitHub ici</a> . <br><br><a name="cvtrends"></a><h2>  Tendances de vision industrielle pour 2019 </h2><br>  Comme je l'ai mentionn√© plus t√¥t, en 2019, nous sommes plus susceptibles de voir le d√©veloppement des tendances de 2018, plut√¥t que de nouvelles perc√©es: voitures autonomes, algorithmes de reconnaissance faciale, r√©alit√© virtuelle et plus encore.  Pouvez-vous √™tre en d√©saccord avec moi si vous avez un point de vue diff√©rent ou des ajouts, partagez-le avec nous, √† quoi pouvons-nous nous attendre en 2019? <br><br>  La question des drones, en attendant l'approbation des politiciens et du gouvernement, pourrait enfin obtenir le feu vert aux √âtats-Unis (l'Inde est loin derri√®re dans ce dossier).  Personnellement, j'aimerais que davantage de recherches soient effectu√©es dans des sc√©narios r√©els.  Des conf√©rences telles que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CVPR</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ICML donnent une</a> bonne couverture des derni√®res r√©alisations dans ce domaine, mais la proximit√© des projets avec la r√©alit√© n'est pas tr√®s claire. <br><br>  La ¬´r√©ponse visuelle aux questions¬ª et les ¬´syst√®mes de dialogue visuel¬ª pourraient enfin d√©buter avec un d√©but tant attendu.  Ces syst√®mes n'ont pas la capacit√© de g√©n√©raliser, mais il est pr√©vu que nous verrons bient√¥t une approche multimodale int√©gr√©e. <br><br><img src="https://habrastorage.org/webt/s5/bn/uy/s5bnuydmsc8hf37vm26icbmwrgc.jpeg"><br><br>  L'autoformation est apparue cette ann√©e.  Je parie que l'ann√©e prochaine, il trouvera une application dans un plus grand nombre d'√©tudes.  C'est une direction vraiment cool: les signes sont d√©termin√©s directement √† partir des donn√©es d'entr√©e, au lieu de perdre du temps √† marquer manuellement les images.  Croisons les doigts! <br><br><h4>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lire la suite: Partie 2 - Outils et biblioth√®ques, AutoML, apprentissage par renforcement, √©thique en IA</a> </h4></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439688/">https://habr.com/ru/post/fr439688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439676/index.html">R√©agissez √† l'int√©gration native et C ++ pour iOS et Android</a></li>
<li><a href="../fr439678/index.html">Soumettez au d√©fi F # appliqu√©</a></li>
<li><a href="../fr439680/index.html">Environ 50% des Russes sont pr√™ts √† vendre leurs donn√©es personnelles</a></li>
<li><a href="../fr439682/index.html">Formation Cisco 200-125 CCNA v3.0. Sp√©cialiste r√©seau certifi√© Cisco (CCNA). Jour 4. Dispositifs de passerelle</a></li>
<li><a href="../fr439684/index.html">Postulez pour le d√©fi F # appliqu√©</a></li>
<li><a href="../fr439690/index.html">Comparaison des performances des machines virtuelles pour 6 plateformes cloud: Selectel, MCS, I. Cloud, Google Cloud, AWS et Azure</a></li>
<li><a href="../fr439692/index.html">AT&T poursuivi pour avoir chang√© l'ic√¥ne du r√©seau de 4G en 5G E</a></li>
<li><a href="../fr439694/index.html">Tissus intelligents sensibles aux changements de temp√©rature corporelle</a></li>
<li><a href="../fr439696/index.html">Sur la cr√™te d'une vague, ou "je veux int√©grer" - mais √ßa vaut le coup?</a></li>
<li><a href="../fr439698/index.html">Introduction √† la programmation: un simple jeu de tir 3D √† partir de z√©ro au cours du week-end, partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
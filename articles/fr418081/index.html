<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ¿â€ğŸ”¬ ğŸ‘‰ğŸ» ğŸ¥ Organisation de tests sÃ»rs en production. Partie 1 ğŸ ğŸ™† ğŸŒš</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cet article dÃ©crit les diffÃ©rents types de tests en production et les conditions dans lesquelles chacun d'eux est le plus utile, et dÃ©crit Ã©galement c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Organisation de tests sÃ»rs en production. Partie 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/funcorp/blog/418081/"><img src="https://habrastorage.org/webt/0q/az/yt/0qazyteu8a-cel_dnpcbmyckzsk.jpeg"><br><br>  Cet article dÃ©crit les diffÃ©rents types de tests en production et les conditions dans lesquelles chacun d'eux est le plus utile, et dÃ©crit Ã©galement comment organiser des tests sÃ©curisÃ©s de divers services en production. <a name="habracut"></a><br><br>  Il convient de noter que le contenu de cet article s'applique uniquement aux <b>services</b> dont le dÃ©ploiement est contrÃ´lÃ© par les dÃ©veloppeurs.  En outre, vous devez immÃ©diatement avertir que l'utilisation de l'un des types de tests dÃ©crits ici n'est pas une tÃ¢che facile, ce qui nÃ©cessite souvent des modifications sÃ©rieuses de la conception, du dÃ©veloppement et des tests des systÃ¨mes.  Et, malgrÃ© le titre de l'article, je ne pense pas que l'un des types de tests en production soit absolument fiable.  Il n'y a qu'une opinion selon laquelle de tels tests peuvent rÃ©duire considÃ©rablement le niveau de risques Ã  l'avenir, et les coÃ»ts d'investissement seront justifiÃ©s. <br><br>  <i><b>(Remarque: l'article original Ã©tant Longrid, pour la commoditÃ© des lecteurs, il est divisÃ© en deux parties).</b></i> <br><br><h2>  Pourquoi les tests en production sont-ils nÃ©cessaires si cela peut Ãªtre fait en staging? </h2><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-0" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="974530841190608897"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br>  L'importance du cluster de mise en scÃ¨ne (ou environnement de mise en scÃ¨ne) par diffÃ©rentes personnes est perÃ§ue diffÃ©remment.  Pour de nombreuses entreprises, le dÃ©ploiement et le test d'un produit en staging est une Ã©tape intÃ©grale prÃ©cÃ©dant sa sortie dÃ©finitive. <br><br>  De nombreuses organisations bien connues perÃ§oivent la mise en scÃ¨ne comme une copie miniature de l'environnement de travail.  Dans de tels cas, il est nÃ©cessaire d'assurer leur synchronisation maximale.  Dans ce cas, il est gÃ©nÃ©ralement nÃ©cessaire de garantir le fonctionnement de diffÃ©rentes instances de systÃ¨mes avec Ã©tat, tels que des bases de donnÃ©es, et de synchroniser rÃ©guliÃ¨rement les donnÃ©es de l'environnement de production avec le transfert.  L'exception est uniquement les informations confidentielles qui vous permettent d'Ã©tablir l'identitÃ© de l'utilisateur (cela est nÃ©cessaire pour se conformer aux exigences du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RGPD</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PCI</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HIPAA</a> et autres rÃ©glementations). <br><br>  Le problÃ¨me avec cette approche (d'aprÃ¨s mon expÃ©rience) est que la diffÃ©rence ne rÃ©side pas seulement dans l'utilisation d'une instance distincte de la base de donnÃ©es contenant les donnÃ©es rÃ©elles de l'environnement de production.  Souvent, la diffÃ©rence s'Ã©tend aux aspects suivants: <br><br><ul><li>  La taille du cluster intermÃ©diaire (si vous pouvez l'appeler un Â«clusterÂ» - il s'agit parfois d'un seul serveur dÃ©guisÃ© en cluster); </li><li>  Le fait que le transfert utilise gÃ©nÃ©ralement un cluster beaucoup plus petit signifie Ã©galement que les paramÃ¨tres de configuration de presque <i>tous les</i> services varient.  Cela s'applique aux configurations d'Ã©quilibreurs de charge, de bases de donnÃ©es et de files d'attente, par exemple, le nombre de descripteurs de fichiers ouverts, le nombre de connexions de base de donnÃ©es ouvertes, la taille du pool de threads, etc. Si la configuration est stockÃ©e dans une base de donnÃ©es ou un stockage de donnÃ©es de valeurs-clÃ©s (par exemple, Zookeeper ou Consul), ces systÃ¨mes auxiliaires doivent Ã©galement Ãªtre prÃ©sents dans l'environnement de mise en scÃ¨ne; </li><li>  Le nombre de connexions en ligne traitÃ©es par le service sans Ã©tat ou la mÃ©thode de rÃ©utilisation des connexions TCP par un serveur proxy (si cette procÃ©dure est exÃ©cutÃ©e); </li><li>  Manque de surveillance dans la mise en scÃ¨ne.  Mais mÃªme si la surveillance est effectuÃ©e, certains signaux peuvent se rÃ©vÃ©ler totalement inexacts, car un environnement autre que celui de travail est surveillÃ©.  Par exemple, mÃªme si vous surveillez la latence ou le temps de rÃ©ponse d'une requÃªte MySQL, il est difficile de dÃ©terminer si le nouveau code contient une requÃªte qui peut lancer une analyse complÃ¨te de la table dans MySQL, car il est <i>beaucoup</i> plus rapide (et parfois mÃªme prÃ©fÃ©rable) d'effectuer une analyse complÃ¨te de la petite table utilisÃ©e dans le test. une base de donnÃ©es plutÃ´t qu'une base de donnÃ©es de production, oÃ¹ une requÃªte peut avoir un profil de performances complÃ¨tement diffÃ©rent. </li></ul><br>  Bien qu'il soit juste de supposer que toutes les diffÃ©rences ci-dessus ne sont pas des arguments sÃ©rieux contre l'utilisation de la mise en scÃ¨ne en tant que telle, contrairement aux antipatterns qui devraient Ãªtre Ã©vitÃ©s.  Dans le mÃªme temps, le dÃ©sir de tout faire correctement nÃ©cessite souvent les Ã©normes coÃ»ts de main-d'Å“uvre des ingÃ©nieurs pour garantir un environnement cohÃ©rent.  La production est en constante Ã©volution et est influencÃ©e par divers facteurs, donc essayer d'atteindre ce match, c'est comme aller nulle part. <br><br>  De plus, mÃªme si les conditions de la mise en scÃ¨ne seront aussi similaires que possible Ã  l'environnement de travail, il existe d'autres types de tests qui sont mieux Ã  utiliser sur la base d'informations rÃ©elles de production.  Un bon exemple serait le test d'imprÃ©gnation, dans lequel la fiabilitÃ© et la stabilitÃ© d'un service sont testÃ©es sur une longue pÃ©riode Ã  des niveaux rÃ©els de multitÃ¢che et de charge.  Il est utilisÃ© pour dÃ©tecter les fuites de mÃ©moire, dÃ©terminer la durÃ©e des pauses dans le CPG, le niveau de charge du processeur et d'autres indicateurs pendant une certaine pÃ©riode de temps. <br><br>  Rien de ce qui prÃ©cÃ¨de ne suggÃ¨re que la mise en scÃ¨ne est <i>complÃ¨tement</i> inutile (cela deviendra Ã©vident aprÃ¨s avoir lu la section sur la duplication fantÃ´me des donnÃ©es lors des tests de services).  Cela indique seulement que, bien souvent, ils reposent davantage sur la mise en scÃ¨ne que nÃ©cessaire, et dans de nombreuses organisations, il reste le <i>seul</i> type de test effectuÃ© avant la sortie complÃ¨te du produit. <br><br><h2>  L'art du test en production </h2><br>  Il est arrivÃ© historiquement que le concept de Â«test en productionÂ» soit associÃ© Ã  certains stÃ©rÃ©otypes et connotations nÃ©gatives (Â«programmation guÃ©rillaÂ», manque ou absence de tests unitaires et d'intÃ©gration, nÃ©gligence ou inattention Ã  la perception du produit par l'utilisateur final). <br><br>  Les tests en production mÃ©riteront certainement une telle rÃ©putation s'ils sont effectuÃ©s avec nÃ©gligence et mal.  Il <i>ne remplace</i> en aucun cas les tests au stade de la prÃ©-production et n'est en aucun cas une <i>tÃ¢che simple</i> .  De plus, je soutiens que <i>des</i> tests <i>rÃ©ussis</i> et <i>sÃ»rs</i> en production nÃ©cessitent un niveau d'automatisation important, une bonne comprÃ©hension des pratiques Ã©tablies et la conception de systÃ¨mes avec une orientation initiale vers ce type de tests. <br><br>  Afin d'organiser un processus complet et sÃ»r de test efficace des services en production, il est important de ne pas le considÃ©rer comme un terme gÃ©nÃ©ralisant un ensemble d'outils et de techniques diffÃ©rents.  Malheureusement, cette erreur a Ã©galement Ã©tÃ© commise par moi - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans mon article prÃ©cÃ©dent,</a> une classification pas tout Ã  fait scientifique des mÃ©thodes de test a Ã©tÃ© prÃ©sentÃ©e, et dans la section "Test en production", une variÃ©tÃ© de mÃ©thodologies et d'outils ont Ã©tÃ© regroupÃ©s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2h/bo/od/2hboodum_vrej99d2xm911ifecw.png"></div><br>  <i>Extrait de la note Testing Microservices, the sane way ("A smart approach to testing microservices")</i> <br><br>  Depuis la publication de la note fin dÃ©cembre 2017, je discute de son contenu et gÃ©nÃ©ralement du thÃ¨me des tests en production avec plusieurs personnes. <br><br>  Au cours de ces discussions, et Ã©galement aprÃ¨s une sÃ©rie de conversations sÃ©parÃ©es, il m'est apparu clairement que le sujet des tests en production ne pouvait pas Ãªtre rÃ©duit Ã  plusieurs points Ã©numÃ©rÃ©s ci-dessus. <br><br>  Le concept de Â«test en productionÂ» comprend toute une gamme de techniques appliquÃ©es <i>Ã  trois stades diffÃ©rents</i> .  Lesquelles - comprenons. <br><br><img src="https://habrastorage.org/webt/6a/wc/5-/6awc5-yiregc_-2pzrk4i7gjxx0.jpeg"><br><br><h2>  Trois Ã©tapes de production </h2><br>  Habituellement, les discussions sur la production sont menÃ©es uniquement dans le contexte du dÃ©ploiement de code dans la production, la surveillance ou dans des situations d'urgence en cas de problÃ¨me. <br><br>  J'ai moi-mÃªme jusqu'Ã  prÃ©sent utilisÃ© des termes tels que Â«dÃ©ploiementÂ», Â«libÃ©rationÂ», Â«livraisonÂ», etc., comme synonymes, sans trop rÃ©flÃ©chir Ã  leur signification.  Il y a quelques mois, toutes les tentatives pour distinguer ces termes seraient rejetÃ©es par moi comme quelque chose d'insignifiant. <br>  AprÃ¨s y avoir rÃ©flÃ©chi, j'en suis venu Ã  l'idÃ©e qu'il <i>y a un</i> rÃ©el besoin de distinguer les diffÃ©rentes Ã©tapes de la production. <br><br><h3>  Ã‰tape 1. DÃ©ploiement </h3><br>  Lorsque les tests (mÃªme en production) sont un test de l'atteinte des <i>meilleurs indicateurs possibles</i> , la prÃ©cision des tests (et en fait de tous les tests) n'est assurÃ©e qu'Ã  condition que la mÃ©thode de test soit aussi proche que possible de la maniÃ¨re dont le service est rÃ©ellement utilisÃ© en production. <br><br>  En d'autres termes, les tests doivent Ãªtre exÃ©cutÃ©s dans un environnement qui <i>simule le mieux un environnement de travail</i> . <br><br>  Et la <i>meilleure imitation de l'</i> environnement de travail est ... l'environnement de travail lui-mÃªme.  Pour effectuer le nombre maximal de tests possible dans un environnement de production, il est nÃ©cessaire que le rÃ©sultat infructueux de l'un d'eux n'affecte pas l'utilisateur final. <br><br>  Ceci, Ã  son tour, n'est possible que si, <b>lors du dÃ©ploiement du service dans un environnement de production, les utilisateurs n'obtiennent pas un accÃ¨s direct Ã  ce service</b> . <br><br>  Dans cet article, j'ai dÃ©cidÃ© d'utiliser la terminologie de l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deploy! = Release</a> Ã©crit par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Turbine Labs</a> .  Il dÃ©finit le terme Â«dÃ©ploiementÂ» comme suit: <br><br>  Â«Le dÃ©ploiement est l'installation par un groupe de travail d'une nouvelle version du code du programme de service dans l'infrastructure de production.  Lorsque nous disons qu'une nouvelle version du logiciel a Ã©tÃ© <b>dÃ©ployÃ©e</b> , nous voulons dire qu'il s'exÃ©cute quelque part dans le cadre de l'infrastructure de travail.  Il peut s'agir d'une nouvelle instance EC2 dans AWS ou d'un conteneur Docker s'exÃ©cutant au cÅ“ur d'un cluster Kubernetes.  Le service a dÃ©marrÃ© avec succÃ¨s, a passÃ© un bilan de santÃ© et est prÃªt (vous lâ€™espÃ©rez!) Ã€ traiter les donnÃ©es de lâ€™environnement de production, mais peut ne pas recevoir de donnÃ©es.  C'est un point important, je le souligne Ã  nouveau: <b>pour le dÃ©ploiement, il n'est pas nÃ©cessaire que les utilisateurs aient accÃ¨s Ã  la nouvelle version de votre service</b> .  Compte tenu de cette dÃ©finition, le dÃ©ploiement peut Ãªtre qualifiÃ© de processus avec un risque presque nul. Â» <br><br>  Les mots Â«processus Ã  risque zÃ©roÂ» sont simplement un baume pour l'Ã¢me de nombreuses personnes qui ont souffert de dÃ©ploiements infructueux.  La possibilitÃ© d'installer un logiciel <i>dans un environnement rÃ©el</i> sans y permettre aux utilisateurs prÃ©sente un certain nombre d'avantages en matiÃ¨re de test. <br>  PremiÃ¨rement, la nÃ©cessitÃ© de maintenir des environnements sÃ©parÃ©s pour le dÃ©veloppement, les tests et la mise en scÃ¨ne, qui doivent inÃ©vitablement Ãªtre synchronisÃ©s avec la production, est minimisÃ©e (et peut mÃªme complÃ¨tement disparaÃ®tre). <br><br>  De plus, au stade de la conception des services, il devient nÃ©cessaire de les isoler les uns des autres afin que l'Ã©chec du test d'une instance spÃ©cifique du service en production <i>n'entraÃ®ne pas</i> une cascade ou n'affecte pas les utilisateurs de l'Ã©chec des autres services.  Une solution Ã  cela peut Ãªtre la conception d'un modÃ¨le de donnÃ©es et d'un schÃ©ma de base de donnÃ©es dans lesquels les requÃªtes non idempotentes (principalement les <i>opÃ©rations d'Ã©criture</i> ) peuvent: <br><br><ul><li>  A rÃ©aliser en relation avec la base de donnÃ©es de l'environnement de production lors de tout lancement de test du service en production (je prÃ©fÃ¨re cette approche); </li><li>  ÃŠtre rejetÃ© en toute sÃ©curitÃ© au niveau de l'application jusqu'Ã  ce qu'ils atteignent le niveau d'Ã©criture ou de sauvegarde; </li><li>  ÃŠtre allouÃ© ou isolÃ© au niveau de l'enregistrement ou de la sauvegarde d'une maniÃ¨re ou d'une autre (par exemple, en stockant des mÃ©tadonnÃ©es supplÃ©mentaires). </li></ul><br><h3>  Ã‰tape 2. LibÃ©ration </h3><br>  Remarque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deploy! = Release</a> dÃ©finit le terme release comme suit: <br><br>  Â«Lorsque nous disons que la <b>sortie de</b> la version de service a eu lieu, nous voulons dire qu'elle assure le traitement des donnÃ©es dans l'environnement de production.  En d'autres termes, une <b>version</b> est un processus qui dirige les donnÃ©es de l'environnement de production vers une nouvelle version du logiciel.  Avec cette dÃ©finition Ã  l'esprit, tous les risques que nous associons Ã  l'envoi de nouveaux flux de donnÃ©es (interruptions, insatisfaction des clients, notes vÃ©nÃ©neuses dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">The Register</a> ) concernent la <b>sortie d'un</b> nouveau logiciel, et non son dÃ©ploiement (dans certaines entreprises, cette Ã©tape est Ã©galement appelÃ©e <b>libÃ©ration</b> . Dans cet article, nous utiliserons le terme <b>version</b> ). " <br><br>  Dans le livre de Google sur SRE, le terme "version" est utilisÃ© dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chapitre sur l'organisation d'une version logicielle pour le dÃ©crire</a> . <br><br>  Â«Un <b>problÃ¨me est un Ã©lÃ©ment logique du travail consistant en une ou plusieurs tÃ¢ches distinctes.</b>  <b>Notre objectif est de coordonner le processus de dÃ©ploiement avec le profil de risque de ce service</b> . <br><br>  Dans les environnements de dÃ©veloppement ou de prÃ©-production, nous pouvons construire toutes les heures et distribuer automatiquement les versions aprÃ¨s avoir passÃ© tous les tests.  Pour les grands services orientÃ©s utilisateur, nous pouvons commencer la version avec un cluster, puis augmenter son Ã©chelle jusqu'Ã  ce que nous mettions Ã  jour tous les clusters.  <b>Pour les Ã©lÃ©ments d'infrastructure importants, nous pouvons Ã©tendre la pÃ©riode de mise en Å“uvre Ã  plusieurs jours et l'exÃ©cuter Ã  tour de rÃ´le dans diffÃ©rentes rÃ©gions gÃ©ographiques. Â»</b> <br><br>  Dans cette terminologie, les mots Â«versionÂ» et Â«versionÂ» signifient ce que le vocabulaire gÃ©nÃ©ral appelle Â«dÃ©ploiementÂ», et les termes souvent utilisÃ©s pour dÃ©crire diverses stratÃ©gies de <i>dÃ©ploiement</i> (par exemple, dÃ©ploiement bleu-vert ou dÃ©ploiement canari) se rÃ©fÃ¨rent Ã  la <i>publication d'un</i> nouveau logiciel. <br><br>  De plus, une <i>libÃ©ration</i> infructueuse <i>des</i> applications peut entraÃ®ner des interruptions partielles ou importantes du travail.  Ã€ ce stade, une <i>restauration</i> ou un <i>correctif</i> est Ã©galement effectuÃ© s'il s'avÃ¨re que la nouvelle version <i>publiÃ©e</i> du service est instable. <br><br>  Le processus de <i>publication</i> fonctionne mieux lorsqu'il est automatisÃ© et s'exÃ©cute de maniÃ¨re <i>incrÃ©mentielle</i> .  De mÃªme, une <i>restauration</i> ou un <i>correctif d'un</i> service est plus utile lorsque le taux d'erreur et la frÃ©quence des demandes sont automatiquement corrÃ©lÃ©s avec la ligne de base. <br><br><h3>  Ã‰tape 3. AprÃ¨s la libÃ©ration </h3><br>  Si la publication <i>s'est bien dÃ©roulÃ©e</i> et que la nouvelle version du service traite les donnÃ©es de l'environnement de production sans problÃ¨mes Ã©vidents, nous pouvons considÃ©rer <i>qu'elle a</i> rÃ©ussi.  Une libÃ©ration rÃ©ussie est suivie d'une Ã©tape qui peut Ãªtre appelÃ©e Â«aprÃ¨s la libÃ©rationÂ». <br><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-1" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="961811607759159296"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br>  Tout systÃ¨me suffisamment complexe sera <i>toujours</i> dans un Ã©tat de perte progressive de performances.  Cela ne signifie pas qu'une <i>restauration</i> ou un <i>correctif est requis</i> .  Au lieu de cela, il est nÃ©cessaire de surveiller une telle dÃ©tÃ©rioration (Ã  diverses fins opÃ©rationnelles et opÃ©rationnelles) et de dÃ©boguer si nÃ©cessaire.  Pour cette raison, les tests aprÃ¨s la publication ne sont plus des routines, mais le <i>dÃ©bogage</i> ou la collecte de donnÃ©es analytiques. <br><br>  En gÃ©nÃ©ral, je pense que chaque composant du systÃ¨me doit Ãªtre crÃ©Ã© en tenant compte du fait qu'aucun grand systÃ¨me ne fonctionne parfaitement Ã  100% et que les dysfonctionnements doivent Ãªtre reconnus et pris en compte aux Ã©tapes de la conception, du dÃ©veloppement, des tests, du dÃ©ploiement et de la surveillance du logiciel fournir. <br><br><hr><br>  Maintenant que nous avons identifiÃ© les trois Ã©tapes de la production, regardons les diffÃ©rents mÃ©canismes de test disponibles sur chacun d'eux.  Tout le monde n'a pas la possibilitÃ© de travailler sur de nouveaux projets ou de rÃ©Ã©crire du code Ã  partir de zÃ©ro.  Dans cet article, j'ai essayÃ© d'identifier clairement les mÃ©thodes qui fonctionneront le mieux lors du dÃ©veloppement de nouveaux projets, ainsi que de parler de ce que nous pouvons faire d'autre pour tirer parti des mÃ©thodes proposÃ©es sans apporter de modifications importantes aux projets de travail. <br><br><h2>  Test de dÃ©ploiement </h2><br>  Nous avons sÃ©parÃ© les Ã©tapes de dÃ©ploiement et de publication les unes des autres, et nous allons maintenant considÃ©rer certains types de tests qui peuvent Ãªtre appliquÃ©s aprÃ¨s le dÃ©ploiement du code dans l'environnement de production. <br><br><h3>  Test d'intÃ©gration </h3><br>  En rÃ¨gle gÃ©nÃ©rale, les tests d'intÃ©gration sont effectuÃ©s par un serveur d'intÃ©gration continue dans un environnement de test isolÃ© pour chaque branche Git.  Une copie de la topologie de service <i>complÃ¨te</i> (y compris les bases de donnÃ©es, les files d'attente, les proxys, etc.) est dÃ©ployÃ©e pour les suites de tests de <i>tous les</i> services qui fonctionneront ensemble. <br><br>  Je pense que ce n'est pas particuliÃ¨rement efficace pour plusieurs raisons.  Tout d'abord, l'environnement de test, comme l'environnement de transfert, ne peut pas Ãªtre dÃ©ployÃ© de maniÃ¨re Ã  Ãªtre <i>identique Ã  l'</i> environnement de production rÃ©el, <i>mÃªme si les</i> tests sont exÃ©cutÃ©s dans le mÃªme conteneur Docker qui sera utilisÃ© dans la production.  Cela est particuliÃ¨rement vrai lorsque la <i>seule chose</i> qui s'exÃ©cute dans un environnement de test est les tests eux-mÃªmes. <br><br>  Que le test soit exÃ©cutÃ© en tant que conteneur Docker ou processus POSIX, il Ã©tablit trÃ¨s probablement <i>une</i> ou plusieurs connexions Ã  un service, une base de donnÃ©es ou un cache supÃ©rieur, ce qui est rare si le service se trouve dans un environnement de production oÃ¹ il peut simultanÃ©ment traiter plusieurs connexions simultanÃ©es, en rÃ©utilisant souvent des connexions TCP inactives (c'est ce qu'on appelle la rÃ©utilisation des connexions HTTP). <br><br>  En outre, le problÃ¨me est dÃ» au fait que la plupart des tests Ã  chaque dÃ©marrage crÃ©ent une nouvelle table de base de donnÃ©es ou un espace de clÃ© de cache sur <i>le mÃªme nÅ“ud</i> oÃ¹ ce test est effectuÃ© (de cette maniÃ¨re, les tests sont isolÃ©s des pannes de rÃ©seau).  Ce type de test peut au mieux montrer que le systÃ¨me fonctionne correctement avec une demande trÃ¨s spÃ©cifique.  Il est rarement efficace pour simuler des types de dÃ©faillances graves et bien rÃ©partis, sans parler des diffÃ©rents types de dÃ©faillances partielles.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://">Des</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ã©tudes</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://">exhaustives</a> existent qui confirment que les systÃ¨mes distribuÃ©s prÃ©sentent souvent un <i>comportement imprÃ©visible</i> qui ne peut Ãªtre prÃ©vu par une analyse effectuÃ©e diffÃ©remment que pour l'ensemble du systÃ¨me. <br><br>  Mais cela ne signifie pas que les tests d'intÃ©gration sont <i>en principe</i> inutiles.  Nous pouvons seulement dire que la mise en Å“uvre de tests d'intÃ©gration dans un <i>environnement artificiel, complÃ¨tement isolÃ©</i> , n'a gÃ©nÃ©ralement pas de sens.  Des tests d'intÃ©gration doivent toujours Ãªtre effectuÃ©s pour vÃ©rifier que la nouvelle version du service: <br><br><ul><li>  N'interfÃ¨re pas avec l'interaction avec les services en amont ou en aval; </li><li>  N'affecte pas nÃ©gativement les buts et objectifs des services supÃ©rieurs ou infÃ©rieurs. </li></ul><br>  Le premier peut Ãªtre fourni dans une certaine mesure par des tests de contrat.  <i>Ã‰tant</i> donnÃ© que les <i>interfaces</i> entre les services fonctionnent correctement, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les tests de contrat</a> sont une mÃ©thode efficace pour dÃ©velopper et tester des services individuels au <i>stade de la prÃ©-production</i> , ce qui ne nÃ©cessite pas le dÃ©ploiement de la topologie de service complÃ¨te. <br><br>  Les plates-formes de test de contrat orientÃ©es client, telles que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pact</a> , ne prennent actuellement en charge que l'interopÃ©rabilitÃ© entre les services via RESTful JSON RPC, bien qu'il soit probable que des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travaux soient en cours pour prendre en charge l'interaction asynchrone via les sockets Web, les applications non serveur et les files d'attente de messages</a> .  La prise en charge des protocoles gRPC et GraphQL devrait Ãªtre ajoutÃ©e Ã  l'avenir, mais elle n'est pas encore disponible. <br><br>  Cependant, avant la <i>sortie d'une</i> nouvelle version, il peut Ãªtre nÃ©cessaire de vÃ©rifier non seulement le bon fonctionnement des <i>interfaces</i> . , , ,   RPC-            .    ,       , ,       . <br><br>  ,     <i></i> ,   â€” ,       <i>,  </i>    (  ,    ). <br>      :  <i></i>     ? <br><br>     .    â€“ ,       :    -   - ( C)   MySQL ( D)       memcache ( B). <br><br>   ,      (    ),  stateful-  stateless-        . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xl/nc/4e/xlnc4eni3elyx3huaw3trxs5uyc.jpeg"></div><br>  <i></i>  <i></i> ,     <i></i>      . <br><br>  service discovery        <i></i> ( ),      <i></i>  <i></i>        .         <i></i>   . <br><br> ,   <i></i>    C  . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ze/8y/yp/ze8yypuxevqszd_krd3cls4hrqc.jpeg"></div><br>  ,  <i></i>   ,        ,       .      ,       ,       .  ,     <i></i> ,        . <br><br>   Google     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Just Say No to More End-to-End Tests</a> (Â«      Â»),      : <br><br> Â« <i>       ( )      .       ,    ?           ,      </i> . <b>     ,     ,      ,     Â».</b> <br><br>    ,          :       <i></i>       .               ,       A        . <br><br>     ,     <i></i>   C     MySQL,     . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/c4/bu/qc/c4buqc8zz2dt4e3pyr6svjnyguc.jpeg"></div><br>  <i> </i>       (   ,   ,         Â«Â» ,  <i></i> ).     <i></i>   MySQL   ,    ,      . <br><br>   â€”        -.      ,      .              -,          . <br><br>    ,   -     <i></i>     ,   /: <br><br><ul><li>       C     /   ; </li><li>         ,   Â«Â»   . </li></ul><br>       <i>  </i>    ,             (,   ). <br><br>           ,    ,   <i></i>  .      IP- ,   ,    ,    ,       , ,  ,    ,    . <br><br> ,   ,     ,    ,       .      .     Facebook,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kraken</a> ,  : <br><br> Â« <i>   â€”     ,         .   -      ,    .        ,        .</i> <b>           -     ,     ,     ,       Â».</b> <br><br>   ,      ,       ,     ,         ,  . <br><br>     -     .    service mesh             .        -.        -,  ,  ,    : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/kv/cj/ukkvcjxlzn3hdcpt-mxsep3pojm.jpeg"></div><br>  Si nous testons le service B, son serveur proxy sortant peut Ãªtre configurÃ© pour ajouter un en <code>X-ServiceB-Test</code> tÃªte <code>X-ServiceB-Test</code> spÃ©cial Ã  chaque demande de test.  Dans ce cas, le serveur proxy entrant du service supÃ©rieur C pourra: <br><br><ul><li>  DÃ©tectez cet en-tÃªte et envoyez une rÃ©ponse standard au service B; </li><li>  Dites au service C que la demande est un <i>test</i> . </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3s/mr/-n/3smr-n7k-_87j3jjpirb02hkaja.jpeg"></div><br>  <i>Test d'intÃ©gration de l'interaction de la version dÃ©ployÃ©e du service B avec la version publiÃ©e du service C, oÃ¹ les opÃ©rations d'Ã©criture n'atteignent jamais la base de donnÃ©es</i> <br><br>  Les tests d'intÃ©gration de cette maniÃ¨re permettent Ã©galement de tester l'interaction du service B avec des services supÃ©rieurs <i>lorsqu'ils traitent des donnÃ©es d'environnement de production normales</i> - c'est probablement une imitation plus proche de la faÃ§on dont le service B se comportera lors de sa <i>mise</i> en production. <br><br>  Il serait Ã©galement intÃ©ressant que chaque service de cette architecture prenne en charge de vÃ©ritables appels d'API en mode test ou simulÃ©, vous permettant de tester l'exÃ©cution de contrats de service avec des services en aval sans modifier les donnÃ©es rÃ©elles.  Cela reviendrait Ã  tester les contrats, mais au niveau du rÃ©seau. <br><br><h3>  Duplication de donnÃ©es fantÃ´mes (test de flux de donnÃ©es sombres ou mise en miroir) </h3><br>  La duplication des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">clichÃ©s instantanÃ©s</a> (dans l'article du blog Google, elle est appelÃ©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lancement sombre</a> , et le terme de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mise en miroir</a> est utilisÃ© dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Istio</a> ) a dans bien des cas plus d'avantages que les tests d'intÃ©gration. <br><br>  Les <a href="http://">principes de l'ingÃ©nierie du chaos</a> stipulent ce qui suit: <br><br>  Â«Les <i>systÃ¨mes se comportent diffÃ©remment selon l'environnement et le schÃ©ma de transfert de donnÃ©es.</i>  <i>Ã‰tant donnÃ© que le mode d'utilisation peut changer Ã  tout moment</i> , l' <b>Ã©chantillonnage de donnÃ©es rÃ©elles est le seul moyen fiable de corriger le chemin de la demande. Â»</b> <br><br>  La duplication de donnÃ©es fantÃ´mes est une mÃ©thode par laquelle le flux de donnÃ©es d'environnement de production entrant dans un service donnÃ© est capturÃ© et reproduit dans une nouvelle version <i>dÃ©ployÃ©e</i> du service.  Ce processus peut Ãªtre effectuÃ© en temps rÃ©el, lorsque le flux de donnÃ©es entrant est divisÃ© et envoyÃ© aux versions <i>publiÃ©es</i> et <i>dÃ©ployÃ©es</i> du service, ou de maniÃ¨re asynchrone, lorsqu'une copie des donnÃ©es prÃ©cÃ©demment capturÃ©es est lue dans le service <i>dÃ©ployÃ©</i> . <br><br>  Lorsque j'ai travaillÃ© chez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">imgix</a> (une start-up <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">employant</a> 7 ingÃ©nieurs, dont seulement quatre Ã©taient des ingÃ©nieurs systÃ¨me), des flux de donnÃ©es sombres ont Ã©tÃ© activement utilisÃ©s pour tester les changements dans notre infrastructure de visualisation d'images.  Nous avons enregistrÃ© un certain pourcentage de toutes les demandes entrantes et les avons envoyÃ©es au cluster Kafka - nous avons transmis les journaux d'accÃ¨s HAProxy au pipeline <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">heka</a> , qui Ã  son tour a transmis le flux de requÃªtes analysÃ© au cluster Kafka.  Avant la phase de <i>publication, une</i> nouvelle version de notre application de traitement d'image a Ã©tÃ© testÃ©e sur un flux de donnÃ©es sombre capturÃ©, ce qui a permis de vÃ©rifier que les demandes Ã©taient correctement traitÃ©es.  Cependant, notre systÃ¨me de visualisation d'images Ã©tait dans l'ensemble un service sans Ã©tat qui Ã©tait particuliÃ¨rement bien adaptÃ© Ã  ce type de test. <br><br>  Certaines entreprises prÃ©fÃ¨rent ne pas capturer une partie du flux de donnÃ©es, mais transmettre une <i>copie complÃ¨te de</i> ce flux Ã  la nouvelle version de l'application.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le McRouter de Facebook</a> (proxy memcached) prend en charge ce type de duplication fantÃ´me du flux de donnÃ©es memcache. <br><br>  Â« <i>Lors du test d'une nouvelle installation pour le cache, nous avons trouvÃ© trÃ¨s pratique de pouvoir rediriger une copie complÃ¨te du flux de donnÃ©es des clients.</i>  <i>McRouter prend en charge les paramÃ¨tres de duplication d'ombre flexibles.</i>  <i>Il est possible d'effectuer une duplication fantÃ´me d'un pool de diffÃ©rentes tailles (en remettant en cache l'espace clÃ©), de copier uniquement une partie de l'espace clÃ© ou de modifier dynamiquement les paramÃ¨tres pendant le fonctionnement</i> . <br><br>  L'aspect nÃ©gatif de la duplication fantÃ´me de l'ensemble du flux de donnÃ©es pour un service <i>dÃ©ployÃ©</i> dans un environnement de production est que s'il est exÃ©cutÃ© au moment de l'intensitÃ© de transfert de donnÃ©es maximale, il peut alors nÃ©cessiter deux fois plus de puissance. <br>  Des proxys tels qu'Envoy prennent en charge la duplication fantÃ´me du flux de donnÃ©es vers un autre cluster en mode incendie et oubli.  Sa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> dit: <br><br>  Â« <i>Un routeur peut effectuer une duplication fantÃ´me du flux de donnÃ©es d'un cluster Ã  un autre.</i>  <i>Actuellement, le mode de tir et d'oubli est implÃ©mentÃ©, dans lequel le serveur proxy Envoy n'attend pas de rÃ©ponse du cluster fantÃ´me avant de renvoyer une rÃ©ponse du cluster principal.</i>  <i>Pour le cluster fantÃ´me, toutes les statistiques habituelles sont collectÃ©es, ce qui est utile Ã  des fins de test.</i>  <i>Avec la duplication fantÃ´me, l'option <code>-shadow</code> est ajoutÃ©e Ã  l'en- <code>-shadow</code> hÃ´te / autoritÃ©.</i>  <i>Ceci est utile pour la journalisation.</i>  <i>Par exemple, <code>cluster1</code> transforme en <code>cluster1-shadow</code></i> . " <br><br>  Cependant, il est souvent impossible ou impossible de crÃ©er une rÃ©plique d'un cluster synchronisÃ© avec la production pour les tests (pour la mÃªme raison qu'il est problÃ©matique d'organiser un cluster intermÃ©diaire synchronisÃ©).  Si la duplication miroir est utilisÃ©e pour tester un nouveau service <i>dÃ©ployÃ©</i> qui a de nombreuses dÃ©pendances, il peut dÃ©clencher des changements imprÃ©vus dans l'Ã©tat des services de niveau supÃ©rieur par rapport Ã  celui testÃ©.  La duplication fantÃ´me du volume quotidien d'inscriptions d'utilisateurs dans la version <i>dÃ©ployÃ©e</i> du service avec enregistrement dans la base de donnÃ©es de production peut entraÃ®ner une augmentation du taux d'erreur jusqu'Ã  100% du fait que le flux de donnÃ©es fantÃ´me sera perÃ§u comme des tentatives rÃ©pÃ©tÃ©es d'enregistrement et rejetÃ©es. <br><br>  Mon expÃ©rience personnelle suggÃ¨re que la duplication d'ombre est la mieux adaptÃ©e pour tester les demandes non idempotentes ou les services sans Ã©tat avec des stubs cÃ´tÃ© serveur.  Dans ce cas, la duplication fantÃ´me des donnÃ©es est plus souvent utilisÃ©e pour tester la charge, la stabilitÃ© et les configurations.  Dans le mÃªme temps, Ã  l'aide de tests d'intÃ©gration ou de transfert, vous pouvez tester la faÃ§on dont le service interagit avec un serveur avec Ã©tat lorsque vous travaillez avec des requÃªtes non idempotentes. <br><br><h3>  Comparaison TAP </h3><br>  La seule mention de ce terme se trouve dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> du blog Twitter consacrÃ© au lancement de services Ã  haut niveau de qualitÃ© de service. <br><br>  <i>Â«Pour vÃ©rifier l'exactitude de la nouvelle implÃ©mentation du systÃ¨me existant, nous avons utilisÃ© une mÃ©thode appelÃ©e <b>tap-comparaison</b> .</i>  <i>Notre outil de comparaison de prises reproduit les donnÃ©es de production d'Ã©chantillons dans le nouveau systÃ¨me et compare les rÃ©ponses reÃ§ues avec les rÃ©sultats de l'ancien.</i>  <i>Les rÃ©sultats obtenus nous ont aidÃ©s Ã  trouver et Ã  corriger les erreurs dans le systÃ¨me avant mÃªme que les utilisateurs finaux ne les rencontrent. Â»</i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Un autre</a> article de blog Twitter dÃ©finit les comparaisons de prises comme suit: <br><br>  <i>Â«Envoi de demandes aux instances de service Ã  la fois dans les environnements de production et de transfert avec <b>vÃ©rification des rÃ©sultats</b> et Ã©valuation des caractÃ©ristiques de performance.Â»</i> <br><br>  La diffÃ©rence entre la comparaison de prises et la duplication fantÃ´me est que dans le premier cas, la rÃ©ponse renvoyÃ©e par la version <i>publiÃ©e</i> est comparÃ©e Ã  la rÃ©ponse retournÃ©e par la version <i>dÃ©ployÃ©e</i> , et dans le second, la demande est dupliquÃ©e vers la version <i>dÃ©ployÃ©e</i> en mode hors ligne comme le feu et oublie. <br><br>  Un autre outil pour travailler dans ce domaine est la bibliothÃ¨que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">scientifique</a> , disponible sur GitHub.  Cet outil a Ã©tÃ© dÃ©veloppÃ© pour tester le code Ruby, mais a ensuite Ã©tÃ© portÃ© dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plusieurs autres langages</a> .  Il est utile pour certains types de tests, mais prÃ©sente un certain nombre de problÃ¨mes non rÃ©solus.  Voici ce qu'un dÃ©veloppeur GitHub a Ã©crit dans une communautÃ© Slack professionnelle: <br><br>  <i>Â«Cet outil exÃ©cute simplement deux branches de code et compare les rÃ©sultats.</i>  <i>Vous devez Ãªtre prudent avec le code de ces branches.</i>  <i>Il est nÃ©cessaire de s'assurer que les requÃªtes de base de donnÃ©es ne sont pas dupliquÃ©es si cela entraÃ®ne des problÃ¨mes.</i>  <i>Je pense que cela s'applique non seulement Ã  un scientifique, mais aussi Ã  toute situation dans laquelle vous faites quelque chose deux fois, puis comparez les rÃ©sultats.</i>  <i>L'outil scientifique a Ã©tÃ© crÃ©Ã© pour vÃ©rifier que le nouveau systÃ¨me d'autorisation fonctionne de la mÃªme maniÃ¨re que l'ancien, et Ã  certains moments, il a Ã©tÃ© utilisÃ© pour comparer les donnÃ©es typiques de pratiquement chaque demande de Rails.</i>  <i>Je pense que le processus prendra plus de temps, car le traitement est effectuÃ© sÃ©quentiellement, mais c'est un problÃ¨me Ruby dans lequel les threads ne sont pas utilisÃ©s.</i> <i><br><br></i>  <i>Dans la plupart des cas que je connais, l'outil scientifique a Ã©tÃ© utilisÃ© pour travailler avec des opÃ©rations de lecture plutÃ´t que d'Ã©criture, par exemple, pour savoir si les nouvelles requÃªtes amÃ©liorÃ©es et les nouveaux schÃ©mas d'autorisation reÃ§oivent la mÃªme rÃ©ponse que les anciens.</i>  <i>Les deux options sont exÃ©cutÃ©es dans un environnement de production (sur des rÃ©pliques).</i>  <i>Si les ressources testÃ©es ont des effets secondaires, je pense que les tests devront Ãªtre effectuÃ©s au niveau de l'application. Â»</i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Diffy</a> est un outil open source Ã©crit Scala introduit par Twitter en 2015.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Un article</a> du blog Twitter intitulÃ© <b>Testing without Writing Tests</b> est probablement la meilleure ressource pour comprendre comment fonctionnent les comparaisons de touches dans la pratique. <br><br>  <i>Â«Diffy dÃ©tecte les erreurs potentielles dans le service en lanÃ§ant simultanÃ©ment une nouvelle et une ancienne version du code.</i>  <i>Cet outil fonctionne comme un serveur proxy et envoie toutes les demandes reÃ§ues Ã  chacune des instances en cours d'exÃ©cution.</i>  <i>Il compare ensuite les rÃ©ponses des instances et rapporte tous les Ã©carts trouvÃ©s lors de la comparaison.</i>  <i>Diffy est basÃ© sur l'idÃ©e suivante:</i> <b>si deux implÃ©mentations d'un service retournent les mÃªmes rÃ©ponses avec un ensemble de requÃªtes suffisamment grand et variÃ©, alors ces deux implÃ©mentations peuvent Ãªtre considÃ©rÃ©es comme Ã©quivalentes, et la plus rÃ©cente d'entre elles sans dÃ©gradation des performances.</b>  <i>La technique innovante de rÃ©duction du bruit de Diffy la distingue des autres outils d'analyse de rÃ©gression comparative. Â»</i> <br><br>  La comparaison des prises est excellente lorsque vous devez vÃ©rifier si deux versions donnent les mÃªmes rÃ©sultats.  Selon Mark McBride, <br><br>  <i>Â«L'outil Diffy Ã©tait souvent utilisÃ© dans la refonte des systÃ¨mes.</i>  <i>Dans notre cas, nous avons divisÃ© la base de code source de Rails en plusieurs services crÃ©Ã©s Ã  l'aide de Scala, et un grand nombre de clients API ont utilisÃ© les fonctions diffÃ©remment de ce que nous attendions.</i>  <i>Des fonctions telles que le formatage de la date Ã©taient particuliÃ¨rement dangereuses. Â»</i> <br><br>  La comparaison de prises n'est pas la meilleure option pour tester l'activitÃ© des utilisateurs ou l'identitÃ© du comportement de deux versions du service Ã  la charge maximale.  Comme pour la duplication fantÃ´me, les effets secondaires restent un problÃ¨me non rÃ©solu, en particulier lorsque la version dÃ©ployÃ©e et la version de production Ã©crivent des donnÃ©es dans la mÃªme base de donnÃ©es.  Comme pour les tests d'intÃ©gration, une solution Ã  ce problÃ¨me consiste Ã  utiliser des tests de comparaison de prises avec uniquement un ensemble limitÃ© de comptes. <br><br><h3>  Test de charge </h3><br>  Pour ceux qui ne sont pas familiers avec les tests de rÃ©sistance, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cet article</a> peut servir de bon point de dÃ©part.  Il ne manque pas d'outils et de plates-formes pour les tests de charge open source.  Les plus populaires d'entre eux sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=http://">Apache Bench</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gatling</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wrk2</a> , <a href="http://">Tsung</a> , Ã©crit en Erlang, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Siege</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Iago</a> de Twitter, Ã©crit en Scala (qui reproduit les journaux d'un serveur HTTP, d'un serveur proxy ou d'un analyseur de paquets rÃ©seau dans une instance de test).  Certains experts estiment que le meilleur outil pour gÃ©nÃ©rer de la charge est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mzbench</a> , qui prend en charge une variÃ©tÃ© de protocoles, y compris MySQL, Postgres, Cassandra, MongoDB, TCP, etc. Le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NDBench</a> de Netflix est un autre outil open source pour tester la charge des entrepÃ´ts de donnÃ©es. , qui prend en charge la plupart des protocoles connus. <br><br>  Le blog officiel Twitter d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Iago</a> dÃ©crit plus en dÃ©tail les fonctionnalitÃ©s qu'un bon gÃ©nÃ©rateur de charge devrait avoir: <br><br>  <i>Â«Les demandes non bloquantes sont gÃ©nÃ©rÃ©es Ã  une frÃ©quence donnÃ©e sur la base d'une distribution statistique personnalisÃ©e interne ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le processus de Poisson est</a> modÃ©lisÃ© par dÃ©faut).</i>  <i>La frÃ©quence des demandes peut Ãªtre modifiÃ©e au besoin, par exemple pour prÃ©parer le cache avant de travailler Ã  pleine charge.</i> <i><br><br></i>  <i>En gÃ©nÃ©ral, l'accent est mis sur la frÃ©quence des demandes conformÃ©ment Ã  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la loi de Little</a> , et non sur le nombre d'utilisateurs simultanÃ©s, qui peut varier en fonction du dÃ©lai inhÃ©rent Ã  ce service.</i>  <i>De ce fait, de nouvelles opportunitÃ©s apparaissent pour comparer les rÃ©sultats de plusieurs tests et prÃ©venir la dÃ©tÃ©rioration du service, ralentissant le fonctionnement du gÃ©nÃ©rateur de charge.</i> <i><br><br></i>  <i>En d'autres termes, l'outil Iago cherche Ã  simuler un systÃ¨me dans lequel les demandes sont reÃ§ues quelle que soit la capacitÃ© de votre service Ã  les traiter.</i>  <i>En cela, il diffÃ¨re des gÃ©nÃ©rateurs de charge simulant des systÃ¨mes fermÃ©s dans lesquels les utilisateurs travailleront patiemment avec le retard existant.</i>  <i>Cette diffÃ©rence nous permet de modÃ©liser assez prÃ©cisÃ©ment les modes de dÃ©faillance qui peuvent Ãªtre rencontrÃ©s en production. "</i> <br><br>  Un autre type de test de charge est le test de contrainte en redistribuant le flux de donnÃ©es.  Son essence est la suivante: l'ensemble du flux de donnÃ©es de l'environnement de production est dirigÃ© vers un cluster plus petit que celui prÃ©parÃ© pour le service;  en cas de problÃ¨me, le flux de donnÃ©es est retransfÃ©rÃ© vers le cluster le plus important.  Cette technique est utilisÃ©e par Facebook, comme dÃ©crit dans l'un des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">articles de son blog officiel</a> : <br><br>  <i>Â«Nous redirigeons spÃ©cifiquement un flux de donnÃ©es plus important vers des clusters ou nÅ“uds individuels, mesurons la consommation de ressources sur ces nÅ“uds et dÃ©terminons les limites de la stabilitÃ© des services.</i>  <i>Ce type de test, en particulier, est utile pour dÃ©terminer les ressources CPU nÃ©cessaires pour prendre en charge le nombre maximal de diffusions simultanÃ©es de Facebook Live. Â»</i> <br><br>  Voici ce qu'Ã©crit un ancien ingÃ©nieur LinkedIn de la communautÃ© professionnelle Slack: <br><br>  <i>Â«LinkedIn a Ã©galement utilisÃ© des tests de redline en production - les serveurs ont Ã©tÃ© supprimÃ©s de l'Ã©quilibreur de charge jusqu'Ã  ce que la charge atteigne des valeurs seuil ou que des erreurs commencent Ã  se produire.</i> <br><br>  En effet, une recherche Google fournit un lien vers un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">livre blanc complet</a> et un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article de</a> blog LinkedIn sur ce sujet: <br><br>  <i>Â«La solution Redliner pour les mesures utilise un vÃ©ritable flux de donnÃ©es de l'environnement de production, ce qui Ã©vite les erreurs qui empÃªchent des mesures prÃ©cises des performances en laboratoire.</i> <i><br><br></i>  <i>Redliner redirige une partie du flux de donnÃ©es vers le service testÃ© et analyse en temps rÃ©el ses performances.</i>  <i>Cette solution a Ã©tÃ© mise en Å“uvre dans des centaines de services LinkedIn internes et est utilisÃ©e quotidiennement pour divers types d'analyses de performances.</i> <i><br><br></i>  <i>Redliner prend en charge l'exÃ©cution de tests parallÃ¨les pour les instances canaries et de production.</i>  <b>Cela permet aux ingÃ©nieurs de transfÃ©rer la mÃªme quantitÃ© de donnÃ©es vers deux instances de service diffÃ©rentes: 1) une instance de service qui contient des innovations, telles que de nouvelles configurations, propriÃ©tÃ©s ou nouveau code;</b>  <b>2) une instance de service de la version de travail actuelle.</b> <br><br>  <i>"Les rÃ©sultats des tests de charge sont pris en compte lors de la prise de dÃ©cisions et aident Ã  empÃªcher le dÃ©ploiement de code, ce qui peut entraÃ®ner de mauvaises performances."</i> <br><br>  Facebook a fait passer les tests de charge Ã  l'aide de flux de donnÃ©es rÃ©els Ã  un tout autre niveau grÃ¢ce au systÃ¨me Kraken, et sa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">description</a> mÃ©rite Ã©galement d'Ãªtre lue. <br>  Le test est mis en Å“uvre en redistribuant le flux de donnÃ©es lors de la modification des valeurs de poids (lues depuis le magasin de configuration distribuÃ©) pour les pÃ©riphÃ©riques et les clusters de bordure dans la configuration <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Proxygen</a> (Ã©quilibreur de charge Facebook).  Ces valeurs dÃ©terminent le volume de donnÃ©es rÃ©elles envoyÃ©es, respectivement, Ã  chaque cluster et rÃ©gion Ã  un point de prÃ©sence donnÃ©. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wk/0e/by/wk0ebyvdpznpgdgqcc_6zbu1g6g.png"></div><br>  <i>DonnÃ©es du livre blanc Kraken</i> <br><br>  Le systÃ¨me de surveillance ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gorilla</a> ) affiche des indicateurs de divers services (comme indiquÃ© dans le tableau ci-dessus).  Sur la base des donnÃ©es de surveillance et des seuils, il est dÃ©cidÃ© d'envoyer des donnÃ©es supplÃ©mentaires conformÃ©ment aux valeurs de poids, ou s'il est nÃ©cessaire de rÃ©duire, voire d'arrÃªter complÃ¨tement le transfert de donnÃ©es vers un cluster spÃ©cifique. <br><br><h2>  Tests de configuration </h2><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-2" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="916383043933192192"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br>  Une nouvelle vague d'outils d'infrastructure open source a rendu possible la capture de tous les changements dans l'infrastructure sous forme de code, mais aussi relativement <i>facile</i> .  Il est Ã©galement devenu possible Ã  des degrÃ©s divers de <i>tester</i> ces changements, bien que la plupart des tests d'infrastructure en tant que code au stade de la prÃ©-production ne puissent que confirmer les spÃ©cifications et la syntaxe correctes. <br><br>  De plus, le refus de tester la nouvelle configuration avant la <i>sortie du</i> code est devenu la cause d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nombre important d'interruptions</a> . <br><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-3" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="963093541575581696"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br>  Pour un test holistique des changements de configuration, il est important de distinguer les diffÃ©rents types de configurations.  Fred Hebert a suggÃ©rÃ© une fois d'utiliser le quadrant suivant: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yv/fi/4i/yvfi4ioub6pkvt1mtzxvz2xuvnk.png"></div><br>  Cette option, bien sÃ»r, n'est pas universelle, mais cette distinction vous permet de dÃ©cider comment tester au mieux chacune des configurations et Ã  quelle Ã©tape le faire.  La configuration du temps de construction est logique si vous pouvez garantir une vÃ©ritable rÃ©pÃ©tabilitÃ© des assemblages.  Toutes les configurations ne sont pas statiques, mais sur les plates-formes modernes, un changement de configuration dynamique est inÃ©vitable (mÃªme si nous avons affaire Ã  une Â«infrastructure permanenteÂ»). <br><br><div class="oembed"><twitter-widget class="twitter-tweet twitter-tweet-rendered" id="twitter-widget-4" style="position: static; visibility: visible; display: block; transform: rotate(0deg); max-width: 100%; width: 500px; min-width: 220px; margin-top: 10px; margin-bottom: 10px;" data-tweet-id="1005924617981005824"></twitter-widget><script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div><br>       ,   ,       blue-green ,        .   ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Jamie Wilkinson</a> ),  Google  , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> : <br><br> <i>Â«        ,   ,   ,  -     .    .</i> <b>    -  ,         â€”  ,       ,   .        .</b> <br><br> <i>            ,  .     ,    , â€”    Â».</i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  Facebook</a>             : <br><br> <i>Â«           .    â€”  ,              .             .        ,      .</i> <br><br><ul><li> <b>   </b> <br><br>             .  Facebook ,          .             ,     . </li><li> <b>   </b> <br><br>         (,  JSON).           ,           .          . <br><br>   (,  Facebook  Thrift)      .   ,           . </li><li> <b> </b> <br><br>         ,     ,    - .       .   â€” A/B-,        1 % .     A/B-,        .      A/B-    . ,  ,                 ,       ,     .  , A/B-    .      ,    A/B-.     Facebook        . <br><br> ,     A/B-  1% ,   1%     ,          (   Â«  Â»).          ,         .               ,      . </li><li> <b>  </b> <br><br>   Facebook            .       ,        .    ,              ,     .   ,  ,           . </li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Annulation simple et pratique des modifications</font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dans certains cas, malgrÃ© toutes les mesures prÃ©ventives, le dÃ©ploiement d'une configuration inopÃ©rante est effectuÃ©. </font><font style="vertical-align: inherit;">Trouver et annuler rapidement les modifications est essentiel pour rÃ©soudre un tel problÃ¨me. </font><font style="vertical-align: inherit;">"Les outils de contrÃ´le de version sont disponibles dans notre systÃ¨me de configuration, ce qui facilite beaucoup l'annulation des modifications."</font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ã€ suivre! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">UPD: continuÃ© </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ici</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr418081/">https://habr.com/ru/post/fr418081/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr418069/index.html">RÃ©solution de mots croisÃ©s de couleurs japonaises Ã  la vitesse de la lumiÃ¨re</a></li>
<li><a href="../fr418071/index.html">L'industrie informatique pour le peuple: TechTrain Festival Ã  Saint-PÃ©tersbourg</a></li>
<li><a href="../fr418075/index.html">TOP 5 des choses qui peuvent Ãªtre imprimÃ©es sur une imprimante 3D [vidÃ©o]</a></li>
<li><a href="../fr418077/index.html">Accidents de Â«ne pas regarderÂ»: une justification statistique du mode de fonctionnement du support technique 24/7</a></li>
<li><a href="../fr418079/index.html">Les langages de programmation les plus populaires - 2018</a></li>
<li><a href="../fr418083/index.html">Serveur simple avec GraphQL au lieu de REST, implÃ©mentation en java</a></li>
<li><a href="../fr418085/index.html">Utilisation de promesses en JavaScript</a></li>
<li><a href="../fr418087/index.html">80% des caisses libre-service sont Ã  risque</a></li>
<li><a href="../fr418089/index.html">PrÃ©sentation de la fraiseuse CNC SolidCraft</a></li>
<li><a href="../fr418091/index.html">Liste d'articles et de littÃ©rature sur NAS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
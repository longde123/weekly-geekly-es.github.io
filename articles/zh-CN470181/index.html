<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧝🏼 🤰🏿 😚 Levenberg-Marquardt方法的工作原理 🌈 🌰 🔝</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Levenberg-Marquardt算法很简单。 Levenberg-Marquardt算法是有效的。 

 他们说他在梯度下降和牛顿法之间的中间位置，无论那是什么意思。 嗯，这是用牛顿的方法及其与梯度下降的联系来解决的。 但是，当他们说出这个深刻的短语时，它们是什么意思？ 让我们尝试一下。 

...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Levenberg-Marquardt方法的工作原理</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470181/">  Levenberg-Marquardt算法很简单。  Levenberg-Marquardt算法是有效的。 <br><br> 他们说他在梯度下降和牛顿法之间的中间位置，无论那是什么意思。 嗯，这是用牛顿的方法及其与梯度下降的联系来解决的。 但是，当他们说出这个深刻的短语时，它们是什么意思？ 让我们尝试一下。 <br><a name="habracut"></a><br>  Levenberg同志在其文章中[K.一种解决最后平方中某些问题的方法。 夸脱。 应用 数学  1944年。  2. P. 164-168。]，以及继他之后的公民Marquardt [Marquardt，Donald（1963）。  “非线性参数的最小二乘估计算法。”  SIAM应用数学杂志。  11（2）：431–441。]考虑了最小二乘问题，它看起来像这样： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e47/8ff/bd3/e478ffbd37ce67d12a8efa37326ce496.gif" title="“ \ sum_ {i = 1} ^ {N} \左（f（x_ {i}，\ theta）-d_ {i} \右）^ {2} \ rightarrow \ min”">  ， <br><br> 可以用矢量形式更轻松地编写 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/43a/e3d/87f/43ae3d87f8c0662510f39e6a7e1453a0.gif" title="“ \ parallel f（\ theta）-d \ parallel_ {2} ^ {2} \ rightarrow \ min”">  。 <br><br> 而且，通过对最小二乘法进行完全评分，您甚至可以变得更加轻松。 这不会影响故事。 <br><br> 所以，这个问题被认为 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/573/d8c/243/573d8c243893d6b70f894859eebc6e22.gif" title="“ \ dfrac {1} {2} \并行f（x）\ parallel_ {2} ^ {2} = \ dfrac {1} {2} f ^ {T}（x）f（x）\ rightarrow \ min”">  。 <br><br> 这样的问题经常出现，以至于很难找到高效率的解决方法的重要性。 但是我们将从另一个开始。 在以前的文章中，已经表明，不仅可以通过以下考虑获得众所周知的梯度下降方法。 假设我们到了某个时候 <img src="https://habrastorage.org/getpro/habr/post_images/779/0dd/0ef/7790dd0efb4a03a4c876741804d9b559.gif" title="“X”"> 其中最小化功能很重要 <img src="https://habrastorage.org/getpro/habr/post_images/903/406/15f/90340615fd75f4a3550a82c374838b6b.gif" title="“ f（x）”">  。 我们在这一点上定义一个辅助功能 <img src="https://habrastorage.org/getpro/habr/post_images/8bf/1d5/4e1/8bf1d54e1f36dd4c9dfd5720437af51c.gif" title="“ g（p）= f（x + p）”"> 以及它的一些模型 <img src="https://habrastorage.org/getpro/habr/post_images/c5b/160/400/c5b1604002da7b2c951dd57929933d24.gif" title="“ \ bar {g}（p）\约g（p）”">  。 对于此模型，我们提出一个辅助问题 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ab/24f/2cd/5ab24f2cdd939fb1186c5ebc91807432.gif" title="“ \\\ bar {g}（p）\ rightarrow \ min \\ p \ in \ Omega”"><br><br> 在哪里 <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="“ \欧米茄”">  -选择一定的预定允许值集合，以使问题具有简单的解决方案和功能 <img src="https://habrastorage.org/getpro/habr/post_images/462/957/dda/462957dda265f4fb8be04327f1c12b0f.gif" title="“ \ bar {g}”"> 相当准确地近似 <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="“G”"> 在 <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="“ \欧米茄”">  。 这种方案称为信任区域方法，很多 <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="“ \欧米茄”"> 在其上最小化模型函数的值-此函数的置信区域。 对于梯度下降，我们采用 <img src="https://habrastorage.org/getpro/habr/post_images/c7e/85c/48e/c7e85c48eb16123c23a9e08714f50a0e.gif" title="“ \ Omega = \左\ {p \ quad | \平行p \ parallel_ {2} = \ Delta \右\}”">  ，对于牛顿法 <img src="https://habrastorage.org/getpro/habr/post_images/7cf/b4b/920/7cfb4b9203c4faccd18c1837b9c0e59f.gif" title="“ \ Omega = \左\ {p \ quad | \平行p \ parallel_ {H（x）} = \ Delta \右\}”">  ，并作为 <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="“G”"> 泰勒展开的线性部分 <img src="https://habrastorage.org/getpro/habr/post_images/a98/a08/49f/a98a0849fa75ac2a6bbcbbc2bbda3054.gif" title="“ \ bar {g} = f（x）+ \ bigtriangledown f ^ {T}（x）p”">  。 <br><br> 让我们看看如果我们通过使模型复杂化会发生什么 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2a/d63/f01/b2ad63f0162c3cad2512d187035cbf2d.gif" title="“ \ bar {g}（p）= f（x）+ \ bigtriangledown f ^ {T}（x）p + \ dfrac {1} {2} p ^ {T} H（x）p”">  。 <br><br> 我们在椭圆置信区域上最小化此模型函数 <img src="https://habrastorage.org/getpro/habr/post_images/e99/c58/ecc/e99c58ecc60ed62c044f7690e444d1d2.gif" title="“ \ dfrac {1} {2} \ parallel p \ parallel_ {B} ^ {2} = \ Delta”">  （增加了乘数以方便计算）。 应用拉格朗日乘数法，我们得到了问题 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/44c/4c6/050/44c4c6050ba6f69f94a8c222d68c95f3.gif" title="“ \ bigtriangledown f ^ {T}（x）p + \ dfrac {1} {2} p ^ {T} H（x）p + \ dfrac {\ lambda} {2} p ^ {T} Bp- \ lambda \ Delta \ rightarrow \ min“">  ， <br><br> 其解决方案满足平等 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4a3/851/c83/4a3851c834bc50c9b670673f6665f792.gif" title="“ H（x）p + \ lambda Bp + \ bigtriangledown f（x）= 0”"><br><br> 或 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2c4/7f5/3d4/2c47f53d4e43da14ea21b9fe9d7bb533.gif" title="“ \左（H（x）+ \ lambda B \右）p =-\ bigtriangledown f（x）”"><br><br> 在这里，与我们之前使用线性模型时看到的相反，方向<i>p</i> <i>不仅</i>取决于<i>度量</i> <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="“ B”">  ，还取决于<i>信任区域</i>的<i>大小</i> <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="“ \三角洲”">  ，这意味着线性搜索技术不适用（至少合理地适用）。 事实也很难明确地确定该值 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"> 对应于 <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="“ \三角洲”">  。 但是，显然，随着 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"> 长度 <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="“ p”"> 会减少。 但是，如果我们仍然施加条件 <img src="https://habrastorage.org/getpro/habr/post_images/d64/14f/5fb/d6414f5fbe0850f1d6cd0710c69a89fe.gif" title="“ \ lambda \ geq0”">  ，则步长将不超过牛顿方法所给出的步长（全时兴，无需修改和条件）。 <br><br> 所以我们可以给定的 <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="“ \三角洲”"> 寻找正确的价值 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”">  ，完全相反：找到这个 <img src="https://habrastorage.org/getpro/habr/post_images/d64/14f/5fb/d6414f5fbe0850f1d6cd0710c69a89fe.gif" title="“ \ lambda \ geq0”"> 在这种情况下 <img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="“ g（p）＆lt; g（0）”">  。 在这种情况下，这是后期搜索的一种替代。  Marquardt提出了以下简单程序： <br><br><ol><li>  <i>如果有一些价值</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"></i>  <i>条件</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/eca/77f/2af/eca77f2af789bf09851ed403e71813c5.gif" title="“ g（p（\ lambda））＆lt; g（0）”"></i>  <i>完成然后重复</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/cc3/5f3/35e/cc35f335e8bf25ccc19e392f3311591a.gif" title="＆quot; \ lambda'\ leftarrow \ alpha \ lambda，\ lambda \ leftarrow \ lambda'＆quot;"></i>  <i>直到</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/3aa/df9/299/3aadf929956784b2e081f8a634cff90f.gif" title="＆quot; g（p（\ lambda'）＆lt; g（p（\ lambda））＆quot;"></i> </li><li>  <i>如果</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/22b/75c/294/22b75c29456939ef738c81e53f52db6b.gif" title="“ g（p（\ lambda））\ geq g（0）”"></i>  <i>然后接受</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/434/e0a/742/434e0a742c4ad3ae7e4cea8c1289d363.gif" title="“ \ lambda \ leftarrow \ beta \ lambda”"></i>  <i>并重复。</i> </li></ol><br> 在这里 <img src="https://habrastorage.org/getpro/habr/post_images/4f2/68e/81e/4f268e81e07eb6a87b5798903d82f2c0.gif" title="“ 0＆lt; \ alpha＆lt; 1”"> 和 <img src="https://habrastorage.org/getpro/habr/post_images/0ea/d14/4f2/0ead144f2f1591e5747e51404639631f.gif" title="“ \ Beta＆gt; 1”"> 是作为方法参数的常量。 乘以 <img src="https://habrastorage.org/getpro/habr/post_images/389/a99/83e/389a9983ea24ad0b3af0559c2aca381b.gif" title="“ \ alpha”"> 对应于置信区域的扩展，并乘以 <img src="https://habrastorage.org/getpro/habr/post_images/76d/0eb/69b/76d0eb69ba026a58bbe3edd275fee712.gif" title="“ \ beta”">  -缩小。 <br><br> 指定的技术可以应用于<i>任何</i>目标函数。 请注意，与早先考虑的情况相比，此处不再需要Hessian的正定性，而之前提出的牛顿法是顺序下降法的特殊情况。 甚至不需要其非简并性，这在某些情况下非常重要。 但是，在这种情况下，方向搜索的价格会增加，因为每次更改 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"> 导致需要解决线性系统来确定 <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="“ p”">  。 <br><br> 让我们看看如果将这种方法应用于最小二乘问题，将会发生什么。 <br><br> 梯度函数 <img src="https://habrastorage.org/getpro/habr/post_images/f58/e0b/7a5/f58e0b7a5457a6f69dd3c16e2d5aadc5.gif" title="“ \ bigtriangledown \左（\ dfrac {1} {2} f ^ {T} f \ right）= J ^ {T} f”"> 她的粗麻布 <img src="https://habrastorage.org/getpro/habr/post_images/9da/93e/f0a/9da93ef0ae8eda326c977d890c97beac.gif" title="“ H = J ^ {T} J + G”"> 在哪里 <img src="https://habrastorage.org/getpro/habr/post_images/c7a/314/465/c7a31446512540e721403b61686e91ba.gif" title="“ J_ {ij} = \ dfrac {\部分f_ {i}} {\部分x_ {j}}，G_ {ij} = \ sum_ {k = 1} ^ {M} \ dfrac {\部分^ {2} f_ {i}} {\部分x_ {j} \部分x_ {k}} f_ {k}“">  。 替换并获得以下确定搜索方向的系统 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/148/b56/06f/148b5606f695c8a52b629f69f8c167c5.gif" title="“ \左（J ^ {T} J + G + \ lambda B \右）p = -J ^ {T} f”">  。 <br><br> 这是完全可以接受的，但是计算向量函数的二阶导数可能会非常昂贵。  Marquardt建议使用函数本身来绕过此问题。 <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="“ f”">  ，及其线性近似 <img src="https://habrastorage.org/getpro/habr/post_images/205/c97/755/205c97755529c6a19a04851f7ec3d7f7.gif" title="“ \ bar {f}（x）= f（x_ {0}）+ J（x_ {0}）（x-x_ {0}）”"> 在矩阵 <img src="https://habrastorage.org/getpro/habr/post_images/338/ec0/451/338ec0451e1b4b7e7decd0b4443a8828.gif" title="“ G”"> 变为零。 如果现在作为 <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="“ B”"> 取单位矩阵 <img src="https://habrastorage.org/getpro/habr/post_images/809/326/43e/80932643e100c59ad091cdf4d90a2bd5.gif" title="“我”">  ，则我们得到Levenberg-Marquardt方法的标准形式来解决最小二乘问题： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d3e/6e4/48a/d3e6e448ae5465d70cded093a02fdb69.gif" title="“ \左（J ^ {T} J + \ lambda I \ right）p = -J ^ {T} f”">  。 <br><br> 对于这种确定下降方向的方法，Marquardt证明了有抱负的定理 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"> 到无穷大方向 <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="“ p”"> 倾向于反梯度。 有兴趣的读者可以在基础文章中找到严格的证明，但是我希望从方法的逻辑上，这种陈述本身已经变得很明显。 在某种程度上，它证明了普遍存在的事实，即随着lambda的增加（由于某种原因我经常称其为正则化参数），我们得到了梯度下降。 实际上，没有任何东西-我们只会在极限内，步长趋于零的极限中得到它。 更重要的是，具有足够大的λ值，我们获得的<i>方向</i>将是<i>下降方向</i> ，这意味着我们获得了<i>该方法</i>的<i>全局收敛性</i> 。 这是语句的第二部分，当lambda趋于零时，我们得到牛顿法，这显然是正确的，但前提是我们必须接受 <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="“ f”"> 它的线性近似 <img src="https://habrastorage.org/getpro/habr/post_images/9dc/1fa/a9c/9dc1faa9cf4e8d569afaf161ac627568.gif" title="“ \ bar {f}”">  。 <br><br> 似乎全部。 我们在椭圆度量中最小化向量函数的范数-我们使用Levenberg-Marquardt。 我们正在处理一种通用形式的函数，并且具有计算二阶导数矩阵的能力-对于Wells，请使用通用区域置信区域方法。 但是有变态... <br><br> 有时用Levenberg-Marquardt方法最小化功能 <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="“ f”"> 他们调用这样的表达式： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/438/a2f/22b/438a2f22ba381c85087a26d2125d1dac.gif" title="“ \左（H ^ {T} H + \ lambda I \ right）p = -H ^ {T} \ bigtriangledown f”">  。 <br><br> 一切似乎都一样，但是在这里 <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="“ H”">  -第二矩阵！ 导数函数 <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="“ f”">  。 形式上，这是存在的权利，但这是一种变态。 这就是为什么。  Marquardt在他的文章中提出了一种求解方程组的方法 <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="“ F（x）= 0”"> 通过最小化功能 <img src="https://habrastorage.org/getpro/habr/post_images/128/aa6/0b3/128aa60b3bc0593a797bd9ebd308b402.gif" title="“ \并行F（x）\ parallel_ {2} ^ {2}”"> 所描述的方法。 如果作为 <img src="https://habrastorage.org/getpro/habr/post_images/59b/464/0f5/59b4640f5bad6b14066d718cf44e9f9c.gif" title="“ F（x）”"> 取目标函数的梯度，那么我们实际上得到了简化的表达式。 而变态是因为 <br><br>  <i>解决了由极小化问题产生的非线性方程组产生的极小化问题</i> 。 <br><br> 双重打击。 这样的表达式至少不比球形置信区域的第一个方程更好，但是从生产率（不必要的乘法运算，在正常的实现中是分解）的角度，以及从方法稳定性的角度（矩阵乘法本身会恶化），通常情况下，这种表达式要差得多。其条件）。 有时有人反对 <img src="https://habrastorage.org/getpro/habr/post_images/e98/c6b/bd7/e98c6bbd7a088cd46c2ed68aac4943ba.gif" title="“ H ^ {T} H”"> 保证肯定定义，但是在这种情况下没有关系。 让我们从顺序下降法的角度看一下Levenberg-Marquardt方法。 在这种情况下，事实证明我们要使用矩阵作为度量 <img src="https://habrastorage.org/getpro/habr/post_images/64b/dbe/dcb/64bdbedcbd61e0741f92025fb7c4a1f8.gif" title="“ H（x）+ \ lambda B”">  ，这样她就可以以这种身份行事 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"> 应确保其积极确定性。 鉴于 <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="“ B”"> 正定值 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"> 总是可以找到的-因此无需要求 <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="“ H”"> 没有观察到肯定的确定性。 <br><br> 作为矩阵 <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="“ B”"> 不需要取一个单位，但是对于目标函数的二次模型，指定适当的置信区域不再像线性模型那样简单。 如果我们采用由Hessian诱导的椭圆区域，则该方法会退化为牛顿法（嗯，几乎） <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f31/f2c/82f/f31f2c82f904fd2c95ab33daa112168b.gif" title="“ \左（J ^ {T} J + \ lambda J ^ {T} J \右）p = \左（1+ \ lambda \右）J ^ {T} Jp = -J ^ {T} f \约\左（1+ \ lambda \ right）Hp =-\ bigtriangledown \ left（\ dfrac {1} {2} f ^ {T} f \ right）。”"><br><br> 当然，除非Hessian矩阵是正定的。 如果不是，则可以像以前一样，使用校正后的Hessian作为度量标准，或使用某种程度上接近它的矩阵。 还建议使用矩阵作为度量 <img src="https://habrastorage.org/getpro/habr/post_images/e83/ae4/134/e83ae41347e08ce41ff17ee556a7e06b.gif" title="“诊断（J ^ {T} J）”">  ，通过构造保证它是正定的。 不幸的是，对于这种选择，我至少不知道有任何严格的理由，但是作为经验推荐经常提到。 <br><br> 作为说明，让我们看一下该方法在同一个Rosenbrock函数上的行为，我们将以两种形式来考虑它-作为形式简单的函数 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b78/272/e1a/b78272e1a4bce3b65e55a7737fd2a1ee.gif" title="“ f（x，y）=（1-x）^ {2} +100（y-x ^ {2}）^ {2} \ rightarrow \ min”">  ， <br><br> 作为最小二乘问题 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05c/c5a/49e/05cc5a49e94d86e2929c86264cd76f6f.gif" title="“ \\ f（x，y）= \左\垂直\开始{array} {c} 1-x \\ 100（yx ^ {2}）\结束{array} \ right \ Vert _ {2} ^ { 2} \ rightarrow \ min“"><br><br><img src="https://habrastorage.org/webt/0d/bo/bo/0dbobokk7lwzjkd69j9d-wmotks.gif" width="600"><br> 这就是具有球形置信度区域的方法的行为方式。 <br><img src="https://habrastorage.org/webt/l9/57/xb/l957xbscmthhqno0yneburansf4.gif" width="600"><br> 因此，如果置信区域的形状由根据Davidon-Fletcher-Powell规则构造的矩阵给出，则采用相同的方法。 对收敛有影响，但比使用目标函数的线性模型时的情况要适度得多。 <br><img src="https://habrastorage.org/webt/rn/n2/uz/rnn2uzvfkpd7fdrxa26qvdlkcfs.gif" width="600"><br> 这就是应用于最小二乘问题的方法的行为。 它在5次迭代中收敛。 请<i>不要从这个结论中得出这样的功能的第二种说法总是比第一种更好</i> 。 事实并非如此，这只是在这种特殊情况下发生的。 <br><br><h2> 结论 </h2><br> 据我所知，Levenberg-Marquardt方法是基于信任区域的思想的第一种方法。 在解决最小二乘问题时，他在实践中表现出色。 在大多数情况下（由我看到），该方法收敛很快（在上一篇文章中我说过是好是坏）。 但是，在最小化一般功能的同时，选择球体作为信任区域并不是最佳选择。 另外，该方法的一个显着缺点（在这里描述了其基本公式）是置信区域的大小是隐式设置的。 缺点是知道含义 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"> 我们当然可以在当前点计数 <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="“ \三角洲”"> 只计算步幅 <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="“ p”">  。 但是，当我们移动到新的点时，相同的值 <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="“ \ lambda”"> 一个完全不同的置信区域值将已经对应。 因此，我们失去了确定置信区域“任务特征”大小的能力，并被迫在每个新点以新方式确定其大小。 当需要足够大量的迭代来收敛时，这可能很重要，并且计算函数的值很昂贵。 基于信任区域的思想，可以通过更高级的方法解决类似的问题。 <br><br> 但这是一个完全不同的故事。 <br><br><h2> 加法 </h2><br> 多亏了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" class="user_link">Dark_Daiver</a>的宝贵意见<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" class="user_link">，</a>我决定在上面补充以下说明。 当然，可以通过另一种纯粹的经验方法得出Levenberg-Marquardt方法。 即，让我们回到上一篇文章中描述的顺序下降方法的方案，并再次问自己一个问题，即为目标函数的线性模型构造一个足够的度量。 <br> 假设搜索空间中当前点的Hessian矩阵不是正定的，并且不能用作度量（此外，要检查是否是如此，我们既没有能力也没有欲望）。 表示为 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f06/ee0/4fd/f06ee04fdb8676c6297784f2cc24291b.gif" title="\ lambda _ {\ min}"></a> 它的最小特征值。 然后我们可以通过简单地将其所有特征值偏移 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/0b6/187/138/0b61871385159f5f8dff9d81de5171b5.gif" title="\ lambda>-\ lambda _ {\ min}"></a>  。 为此，只需将矩阵添加到黑森州 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/09f/c07/1d5/09fc071d5e509fe24bd70ca553a899cf.gif" title="\ lambda我"></a>  。 然后确定下降方向的方程将采用以下形式 <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/3a7/b20/19b/3a7b2019b8c7a99b85121b3512c3fa19.gif" title="\\（H（x）+ \ lambda I）p =-\ bigtriangledown f（x）\\ \ lambda>-\ lambda _ {\ min}"></a> <br><br> 如果我们的分数较低 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f06/ee0/4fd/f06ee04fdb8676c6297784f2cc24291b.gif" title="\ lambda _ {\ min}"></a>  ，那么我们就可以完成在顺序下降方法中完成的所有工作。 但是，如果我们没有这样的估计，那么考虑到 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="\ lambda"></a> 长度<i>p</i>会减小，我们可以放心地说，有足够大的长度 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="\ lambda"></a> 同时 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/cc1/d36/8a7/cc1d368a7e0d0614441998db48983d70.gif" title="H（x）+ \ lambda I"></a> 正定和 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="g（p）<g（0）"></a>  。 <br><br> 为什么我认为这种方法的结论不太成功。 首先，以这种方式构造的度量标准是否适合于实际使用一点也不明显。 当然，它使用有关二阶导数的信息，但是它不会随随便便地移动特征值一个给定值不会使其失效的任何地方。 正如同事在评论中指出的那样，很明显，在Hessian矩阵中添加缩放的恒等矩阵会导致以下事实，即椭圆置信区域将趋于球形，并且在这里（看来）再次出现了卡在峡谷中的问题以及其他梯度下降和接近下降的乐趣。给他方法。 但实际上这不会发生。 无论如何，我从来没有观察到过说明这种行为的例子。 在这种情况下，就会出现问题： <i>但是，实际上，为什么</i>呢？ <br><br> 但是，如果我们不是将这种方法视为下降方法的特殊情况，而是将其视为具有目标函数二次模型的置信区域方法，就不会出现这样的问题，因为答案很明显：当λ增加时，我们只是压缩球体-模型的置信区域。 关于曲率的信息不会随处可见，也不会被任何东西冲走-我们只需要选择二次模型足以描述目标函数的区域大小即可。 由此可以得出结论，由于度量模型的变化已经考虑到了我们对目标函数的所有信息，因此很难期望度量标准的变化（即置信区域的形状）会产生显着影响。 <br><br> 其次，在考虑一种方法时，重要的是要理解使Marquardt引入该方法的主要思想，即信任区域的思想。 确实，归根结底，只有了解数值方法的来龙去脉才能使我们理解它为什么起作用，更重要的是，为什么它不起作用。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN470181/">https://habr.com/ru/post/zh-CN470181/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN470169/index.html">如何防止这个想法消亡并组建一支不会杀死她的团队</a></li>
<li><a href="../zh-CN470171/index.html">《哈伯周刊》第21期/ Dobroshrift，对猫的技术支持，家用电器维修权，欧盟和“透明”饼干</a></li>
<li><a href="../zh-CN470173/index.html">集成平台即服务</a></li>
<li><a href="../zh-CN470175/index.html">将使用Apple登录的功能添加到后端</a></li>
<li><a href="../zh-CN470179/index.html">PDDM-具有高级调度程序的基于模型的新强化学习算法</a></li>
<li><a href="../zh-CN470187/index.html">在线服务设计的价格范围是10万到500万卢布。 原因</a></li>
<li><a href="../zh-CN470189/index.html">使用PeerJS发送对等消息</a></li>
<li><a href="../zh-CN470191/index.html">网页 用r0ot-mi解决问题。 第一部分</a></li>
<li><a href="../zh-CN470193/index.html">通用防护xss攻击和sql注入</a></li>
<li><a href="../zh-CN470195/index.html">F＃4：让/使用/做</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘†ğŸ» ğŸšµğŸ¿ ğŸ’ Le philosophe de l'intelligence artificielle Eliezer Yudkowsky sur la singularitÃ©, le cerveau bayÃ©sien et les gobelins dans un cabinet ğŸ§¥ ğŸ‘¨ğŸ½â€ğŸ³ ğŸ‘‹ğŸ¿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eliezer Shlomo Yudkovsky est un spÃ©cialiste amÃ©ricain de l'intelligence artificielle, qui Ã©tudie les problÃ¨mes de singularitÃ© technologique et prÃ©coni...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le philosophe de l'intelligence artificielle Eliezer Yudkowsky sur la singularitÃ©, le cerveau bayÃ©sien et les gobelins dans un cabinet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/404137/"><img src="https://habrastorage.org/getpro/geektimes/post_images/152/af6/3ff/152af63ff689233ebebadde98fed2580.png" alt="image"><br><br>  <i>Eliezer Shlomo Yudkovsky est un spÃ©cialiste amÃ©ricain de l'intelligence artificielle, qui Ã©tudie les problÃ¨mes de singularitÃ© technologique et prÃ©conise la crÃ©ation de l'IA amie.</i>  <i>Dans les milieux non universitaires, il est mieux connu comme l'auteur de la fan fiction Harry Potter et MÃ©thodes de rationalitÃ© sous les auspices de Moins mal.</i> <br><br>  J'ai toujours Ã©tÃ© Ã©tonnÃ© par des gens intelligents qui croient en des choses qui me paraissent absurdes.  Par exemple, le gÃ©nÃ©ticien et directeur des National Institutes of Health, Francis Collins, pense que JÃ©sus est ressuscitÃ© des morts.  Le thÃ©oricien de l'IA Eliezer Yudkowsky croit que les voitures ... Mais mieux je vais lui donner la parole moi-mÃªme.  En 2008, je l'ai interviewÃ© sur Bloggingheads.tv, mais rien de bon n'en est sorti, car j'ai dÃ©cidÃ© qu'il Ã©tait un adepte du gourou de la singularitÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ray Kurzweil</a> .  Mais Yudkovsky n'a suivi personne et n'est jamais allÃ© Ã  l'universitÃ©.  Il est un thÃ©oricien obstinÃ© et original de l'intelligence, humaine et artificielle.  Son travail (par exemple, un essai qui m'a aidÃ© Ã  comprendre ou Ã  donner l'illusion de comprendre les thÃ©orÃ¨mes de Bayes) dÃ©gage l'arrogance de l'autodidacte, dont les arÃªtes vives n'ont pas Ã©tÃ© polies par l'Ã©ducation formelle - mais cela fait partie de son charme.  MÃªme quand cela vous ennuie, Yudkovsky est drÃ´le, frais, provocateur.  Pour plus de dÃ©tails sur sa biographie, consultez son site Internet personnel ou le site Internet de l'Institute for the Study of Machine Intelligence, auquel il a participÃ©.  Et lisez cette interview avec un bonus sous forme de commentaires de sa femme Briena. <br><a name="habracut"></a><br>  <b>Horgan</b> : Quand on vous demande Ã  une fÃªte ce que vous faites, que rÃ©pondez-vous? <br><br>  <b>Yudkovsky</b> : <b>Cela</b> dÃ©pend de l'Ã©vÃ©nement.  Â«Je suis un spÃ©cialiste de la thÃ©orie de la dÃ©cisionÂ», ou Â«Co-fondateur de l'Institut pour l'Ã©tude de l'intelligence artificielleÂ», ou, s'il s'agit d'un parti d'un type diffÃ©rent, je parle de mes Å“uvres d'art. <br><br>  <b>X:</b> Quel est votre film IA prÃ©fÃ©rÃ© et pourquoi? <br><br>  <b>Yu: L'</b> IA dans les films est terriblement standard.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ex Machina s'est</a> approchÃ© d'une exception Ã  cette rÃ¨gle comme on peut s'y attendre. <br><br>  <b>X:</b> L'utilitÃ© des collÃ¨ges est-elle surfaite? <br><br>  <b>Yu:</b> Je serais surpris si son utilitÃ© Ã©tait sous-estimÃ©e, Ã©tant donnÃ© les exigences sociales pour y mettre fin.  Pour autant que je sache, il n'y a aucune raison de ne pas croire les Ã©conomistes qui pensent que le collÃ¨ge est devenu une sorte de Â«produit prestigieuxÂ» et que les tentatives d'augmentation des prÃªts Ã©tudiants ont simplement augmentÃ© le coÃ»t du collÃ¨ge et le fardeau de la dette Ã©tudiante. <br><br>  <b>X:</b> Pourquoi Ã©crivez-vous des histoires de fiction? <br><br>  <b>Yu:</b> Si vous reformulez les bandes dessinÃ©es de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wondermark</a> : "Au dÃ©but, j'ai essayÃ© de ne pas le faire, mais cela n'a pas fonctionnÃ©." <br><br>  De plus, la littÃ©rature sÃ©rieuse transmet la connaissance, tandis que la fiction transmet l'expÃ©rience.  Si vous voulez comprendre la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">formule des</a> preuves <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">de Bayes</a> , je peux utiliser des diagrammes.  Si vous voulez savoir comment utiliser la logique Bayes, j'ai besoin d'Ã©crire une histoire dans laquelle le personnage le fait. <br><br>  <b>X:</b> ÃŠtes-vous religieux dans un sens? <br><br>  <b>Yu:</b> Non.  Lorsque vous faites une erreur, vous devez Ã©viter la tentation de partir en dÃ©fense, essayer de trouver un point de vue Ã  partir duquel vous avez au moins un peu raison.  Il est beaucoup plus sage de dire: Â«OhÂ», d'admettre que vous n'aviez mÃªme pas un peu raison, d'avaler une pilule amÃ¨re entiÃ¨re et de continuer Ã  vivre.  C'est ainsi que l'humanitÃ© devrait se rapporter Ã  la religion. <br><br>  <b>X:</b> Si vous deveniez le Â«Roi du mondeÂ», quel serait en haut de votre liste de choses Ã  faire? <br><br>  <b>Yu:</b> J'ai Ã©crit une fois: Â«Un test pour un libertaire fonctionne comme ceci: imaginez que vous avez gagnÃ© en puissance;  que penserez-vous d'abord - des lois que vous acceptez ou des lois que vous abrogez? Â»  Je ne suis pas 100% libertaire, car toutes mes envies ne s'expriment pas dans l'abolition des lois et l'assouplissement des restrictions.  Mais j'imagine comment j'essaierais de crÃ©er un monde dans lequel un chÃ´meur pourrait vous proposer de vous rendre au travail, obtenir 5 $ pour 20 minutes de route, et rien de mal ne lui arriverait Ã  cause de cela.  Il n'aurait pas Ã  perdre son assurance chÃ´mage, Ã  enregistrer son autorisation de faire des affaires, Ã  perdre son assurance mÃ©dicale, Ã  se soumettre Ã  un audit, Ã  demander Ã  un avocat de certifier que son travail est conforme aux rÃ¨gles de la Labour Protection Administration, etc.  Il aurait juste ajoutÃ© 5 $. <br><br>  J'essaierais de retourner dans un Ã©tat oÃ¹ l'embauche d'un employÃ© serait aussi simple qu'en 1900.  Peut-Ãªtre que maintenant il y a un sens dans certaines mesures de sÃ©curitÃ©, mais j'essaierais de crÃ©er une telle sÃ©curitÃ© qui n'entrave pas une personne et ne produit pas de papiers Ã  la suite d'un simple retour d'une personne Ã  l'Ã©conomie. <br><br>  J'essaierais de faire tout ce que les Ã©conomistes intelligents crient depuis longtemps et qu'aucun Ã‰tat ne fait.  Remplacer les impÃ´ts sur les investissements et les revenus par des taxes Ã  la consommation et Ã  l'immobilier.  Remplacez le salaire minimum par des charges sociales nÃ©gatives.  Ã‰tablir une politique de ciblage du PIB nominal pour les banques centrales et arrÃªter les structures de soutien "trop â€‹â€‹grandes pour faire faillite".  Exiger que, lors d'un litige en matiÃ¨re de brevet, la partie perdante paie des frais juridiques [ <i>Ã  la suite de ce que l'on appelle</i>  <i>RÃ¨gle anglaise - contrairement aux lois amÃ©ricaines, selon lesquelles chacune des parties paie ses propres frais - env.</i>  <i>perev.</i>  ] et ramÃ¨ne la durÃ©e du droit d'auteur Ã  28 ans.  Ã‰liminez les obstacles Ã  la construction de maisons.  Copiez l'assurance maladie de Singapour.  Gouvernement Ã©lectronique en Estonie.  Remplacer les comitÃ©s et les processus dÃ©cisionnels complexes par des personnes spÃ©cifiques qui prennent des dÃ©cisions publiquement documentÃ©es et qui en sont responsables.  Mener des expÃ©riences contrÃ´lÃ©es avec diffÃ©rentes options de gestion des pays et prendre en compte leurs rÃ©sultats.  Je peux rester sur la liste pendant des heures. <br><br>  Tout cela n'aura peut-Ãªtre pas d'importance dans deux cent millions d'annÃ©es.  Mais les actifs nominaux rÃ©sultant du boom Ã©conomique peuvent faire du bon travail pendant que j'essaie de comprendre ce que nous ferons de l'intelligence artificielle.  La chose la plus Ã©vidente est le projet Manhattan quelque part sur l'Ã®le, avec un paiement basÃ© sur la concurrence entre les plus grands hedge funds, dans lequel les gens peuvent explorer le problÃ¨me de l'intelligence artificielle gÃ©nÃ©ralisÃ©e sans publier les rÃ©sultats de leur travail amÃ¨nent automatiquement la fin du monde.  Et Ã  moins que nous n'acceptions que j'ai des capacitÃ©s magiques ou un rÃ©gime fondamentalement irrÃ©versible, je ne vois pas comment une loi que j'accepterais retarderait assez fortement l'approche de l'IA sur une planÃ¨te oÃ¹ les ordinateurs sont omniprÃ©sents. <br><br>  Mais tout cela peut encore Ãªtre considÃ©rÃ© comme une expÃ©rience de pensÃ©e impossible et dans la vie rÃ©elle, la probabilitÃ© d'une telle expÃ©rience est nulle. <br><br>  <b>X:</b> Qu'est-ce qui est si bon avec le thÃ©orÃ¨me de Bayes? <br><br>  <b>Yu:</b> Eh bien, par exemple, elle est trÃ¨s profonde.  Il est donc difficile de rÃ©pondre briÃ¨vement Ã  une telle question. <br><br>  Je pourrais rÃ©pondre que le thÃ©orÃ¨me de Bayes peut Ãªtre appelÃ© la deuxiÃ¨me loi de la thermodynamique pour la cognition.  Si vous concluez que la probabilitÃ© d'une hypothÃ¨se est de 99%, que ce soit la prÃ©sence de lait dans le supermarchÃ© ou la cause anthropique du rÃ©chauffement climatique, alors vous disposez d'une combinaison de probabilitÃ©s a priori suffisamment bonnes et de preuves assez fiables.  Ce n'est pas une exigence rÃ©glementaire, c'est une loi.  Tout comme une voiture ne peut pas conduire sans dissiper l'entropie, vous ne pouvez pas obtenir une bonne image du monde sans effectuer un processus dans lequel une structure bayÃ©sienne existe quelque part Ã  l'intÃ©rieur, mÃªme si les probabilitÃ©s ne sont pas utilisÃ©es directement dans le processus. <br><br>  Personnellement, je pense que la principale chose que Bayes peut nous offrir est l'existence de rÃ¨gles, de lois de fer qui dÃ©terminent si la faÃ§on de penser fonctionne pour marquer la rÃ©alitÃ©.  On dit aux mormons qu'ils reconnaissent la vÃ©ritÃ© du Livre de Mormon Ã  travers une sensation de brÃ»lure dans le cÅ“ur.  Acceptez de faÃ§on conservatrice la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">probabilitÃ© a priori du</a> Livre de Mormon de un sur un milliard.  Ensuite, nous Ã©valuons la probabilitÃ© que le Livre de Mormon ne soit pas vrai, et quelqu'un a ressenti une sensation de brÃ»lure dans le cÅ“ur aprÃ¨s lui avoir dit que cela devait Ãªtre attendu.  Si vous comprenez la formule de Bayes, nous nous rendrons immÃ©diatement compte que la faible probabilitÃ© de la preuve est incommensurable avec la faible probabilitÃ© de l'hypothÃ¨se qu'ils tentent de prouver avec son aide.  Vous n'avez mÃªme pas besoin de trouver des chiffres spÃ©cifiques pour comprendre qu'ils ne convergent pas - comme l'a dÃ©couvert Philip Tetlock dans son Ã©tude des Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">superprÃ©dicteurs</a> Â», ils connaissaient souvent la formule de Bayes, mais donnaient rarement des chiffres spÃ©cifiques.  Dans un sens, il est plus difficile de vous tromper si vous comprenez qu'il existe une sorte de mathÃ©matiques avec lesquelles vous pouvez dÃ©terminer avec prÃ©cision la force de la preuve et comprendre si cela suffit pour surmonter la faible probabilitÃ© de l'hypothÃ¨se.  Vous ne pouvez pas simplement inventer quelque chose et y croire, car cela ne fonctionne pas comme Ã§a. <br><br>  <b>X:</b> L'hypothÃ¨se du cerveau bayÃ©sien vous impressionne-t-elle? <br><br>  <b>Yu:</b> Je pense que certaines personnes qui discutent de ce sujet parlent de diffÃ©rentes choses.  Demander si le cerveau est un algorithme bayÃ©sien, c'est comme demander si la Honda Accord est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">propulsÃ©e par un moteur thermique Carnot</a> .  Si une personne dit: "Chaque voiture est un processus thermodynamique qui nÃ©cessite du carburant et dissipe la chaleur parasite", et une autre personne entend: "Si vous construisez un diagramme de cycle de Carnot et montrez sa mÃ©canique, il doit convenir qu'il ressemble Ã  l'intÃ©rieur d'une Honda Accord ", Alors un dÃ©bat houleux est inÃ©vitable. <br><br>  Certaines personnes seront trÃ¨s heureuses quand elles ouvriront le moteur Ã  combustion interne, y trouveront les cylindres et diront: "Je suis sÃ»r qu'elles convertissent la chaleur en pression et aident Ã  faire avancer la voiture!"  Et ils auront raison, mais d'autres diront: Â«Vous vous concentrez sur le seul composant d'un ensemble beaucoup plus large de piÃ¨ces automobiles.  Le convertisseur catalytique est Ã©galement trÃ¨s important, et il ne figure pas sur vos diagrammes de cycle Carnot.  Et parfois, un climatiseur fonctionne pour nous, fonctionnant exactement Ã  l'opposÃ© du fonctionnement du moteur thermique selon vos paroles. Â» <br><br>  Je ne pense pas que ce serait surprenant de dire que les gens qui dÃ©noncent vous: Â«Vous n'Ãªtes manifestement pas familier avec les voitures modernes;  vous avez besoin de tout un ensemble de mÃ©thodes diffÃ©rentes pour construire un moteur, comme des bougies et des convertisseurs catalytiques, et pas seulement de vos processus thermodynamiques Â», ils manquent un niveau clÃ© d'abstraction. <br><br>  Mais si vous voulez savoir si le cerveau peut Ãªtre considÃ©rÃ© littÃ©ralement bayÃ©sien, et non un appareil qui effectue un travail cognitif, dont nous pouvons comprendre la nature en utilisant des mÃ©thodes bayÃ©siennes, alors je peux rÃ©pondre Ã  votre question: "Non, bien sÃ»r."  Il peut y avoir plusieurs Â«cylindresÂ» bayÃ©siens dans ce Â«moteurÂ», mais beaucoup sembleront aussi Ã©tranges que les ceintures de sÃ©curitÃ© et la climatisation.  Mais ces ajouts ne changeront pas le fait que pour identifier correctement une pomme sur la base de preuves sensorielles, quelque chose doit Ãªtre fait qui peut Ãªtre interprÃ©tÃ© comme un rÃ©sultat de l'induction qui peut comprendre le concept d'une pomme et est mis Ã  jour sur la base de preuves qui distinguent les pommes des non-pommes. <br><br>  <b>X:</b> Est-il possible d'Ãªtre trop rationnel? <br><br>  <b>Yu:</b> Vous pouvez entrer dans le soi-disant  "La vallÃ©e de la mauvaise rationalitÃ©."  Si avant cela vous Ã©tiez irrationnel Ã  plusieurs Ã©gards, en vous Ã©quilibrant, alors si vous devenez rationnel, vous pouvez devenir pire qu'avant.  Plus vous devenez rationnel, pire vous pouvez obtenir si vous choisissez la mauvaise direction pour appliquer vos compÃ©tences. <br><br>  Mais je ne recommanderais pas de prendre trop soin d'une telle opportunitÃ©.  Ã€ mon avis, les gens qui parlent de l'habiletÃ© irrationnelle peuvent Ãªtre des crÃ©tins.  Il est difficile de trouver une situation de vie rÃ©aliste, pas farfelue, dans laquelle vous pouvez dÃ©cider d'Ãªtre irrationnel, et dont l'issue vous est encore inconnue.  Dans la vraie vie, il vaut mieux se dire la vÃ©ritÃ© et ne pas Ãªtre intelligent. <br><br>  Il est possible que le reprÃ©sentant idÃ©al de la pensÃ©e bayÃ©sienne soit incompatible avec une vie intÃ©ressante et divertissante.  Mais ce n'est clairement pas un problÃ¨me aussi important que notre tendance Ã  l'autodestruction. <br><br>  <b>X: En</b> quoi votre point de vue sur la singularitÃ© diffÃ¨re-t-il de celui de Kurzweil? <br><br>  <b>Yu:</b> <br>  â€¢ Je ne pense pas que la loi de Moore puisse Ãªtre appliquÃ©e Ã  l'IA.  L'IA est un problÃ¨me logiciel. <br>  â€¢ Je ne pense pas que le premier intellect surhumain surgira de la fusion des machines avec les gens.  Cent ans se sont Ã©coulÃ©s depuis l'avÃ¨nement des voitures, et nous essayons tout juste de faire un exosquelette pour un cheval, et une voiture ordinaire est encore plus rapide. <br>  â€¢ Je ne pense pas que la premiÃ¨re IA forte sera basÃ©e sur des algorithmes de neurobiologie, tout comme les avions n'Ã©taient pas basÃ©s sur des oiseaux. <br>  â€¢ Je ne pense pas que la fusion des nano, info et biotechnologies soit possible, inÃ©vitable, bien dÃ©finie ou nÃ©cessaire. <br>  â€¢ Je pense que de 1930 Ã  1970, il y a eu plus de changements que de 1970 Ã  2010. <br>  â€¢ Je pense que dans les pays dÃ©veloppÃ©s, la productivitÃ© stagne. <br>  â€¢ Je pense que l'extrapolation de la loi de Moore au progrÃ¨s technologique, supposant prÃ©dire tout ce qui sera plus intelligent que les humains aprÃ¨s l'avÃ¨nement de l'IA, est une chose trÃ¨s Ã©trange.  Une intelligence artificielle plus intelligente ruine tous vos graphiques. <br>  â€¢ Certains analystes, comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Illka â€‹â€‹Tuomi</a> , pensent que la loi de Moore a violÃ© au dÃ©but des annÃ©es 2000.  Je ne suis pas sÃ»r de pouvoir m'opposer. <br>  â€¢ Le seul seuil technologique qui m'intÃ©resse est celui oÃ¹ l'IA gagne la capacitÃ© de s'amÃ©liorer.  Nous n'avons pas de calendrier pour atteindre ce seuil, et on ne sait pas ce qu'il sera (bien qu'il ne devrait pas dÃ©passer largement le niveau d'une personne, car une personne comprend l'informatique), de sorte que son offensive ne peut Ãªtre prÃ©dite. <br>  â€¢ Je ne pense pas que le rÃ©sultat de tels progrÃ¨s sera bon par dÃ©faut.  Je pense que cela peut Ãªtre rÃ©parÃ©, mais il faudra y rÃ©flÃ©chir sÃ©rieusement, et les chiffres clÃ©s ne sont pas intÃ©ressÃ©s par cela.  Dire aux gens que nous sommes sur une trajectoire naturelle vers de grands et merveilleux moments sera un mensonge. <br>  â€¢ Je pense que la Â«singularitÃ©Â» est devenue un mot valise avec trop de sens et de dÃ©tails incompatibles Ã  l'intÃ©rieur, alors j'ai cessÃ© de l'utiliser. <br><br>  <b>X:</b> ÃŠtes-vous susceptible de devenir un cyborg ultra-intelligent? <br><br>  <b>Yu:</b> La loi de conjonction des probabilitÃ©s dit que P (A&amp;B) &lt;= P (A).  La probabilitÃ© d'occurrence simultanÃ©e des Ã©vÃ©nements A et B est infÃ©rieure Ã  la probabilitÃ© d'occurrence d'un Ã©vÃ©nement A. Dans les expÃ©riences oÃ¹ les gens croient que P (A&amp;B)&gt; P (A) pour deux Ã©vÃ©nements A et B, une Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">erreur de conjonction</a> Â» apparaÃ®t - par exemple, en 1982, des experts du CongrÃ¨s international des prÃ©visions ont attribuÃ© une plus grande probabilitÃ© Ã  l'Ã©vÃ©nement Â«La Russie envahit la Pologne et la rupture des relations diplomatiques avec l'URSSÂ» que la probabilitÃ© d'un Ã©vÃ©nement distinct Â«rupture des relations diplomatiques avec l'URSSÂ», dÃ©signÃ© par un autre groupe.  De mÃªme, un autre groupe a attribuÃ© une plus grande probabilitÃ© Ã  l'Ã©vÃ©nement "Un tremblement de terre en Californie conduit Ã  une inondation faisant des milliers de victimes" qu'un autre - la probabilitÃ© de l'Ã©vÃ©nement "Quelque part en AmÃ©rique du Nord, il y a une inondation avec des milliers de victimes."  Bien que l'ajout de dÃ©tails supplÃ©mentaires Ã  l'histoire la rende moins probable, cela la rend plus crÃ©dible.  Pour moi, comprendre ce fait, c'est comme un Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pont d'Ã¢ne</a> Â» pour un futurisme sÃ©rieux - la diffÃ©rence entre le fait que vous pesez soigneusement chaque hypothÃ¨se individuelle et dÃ©couvrez si vous pouvez soutenir cette clarification indÃ©pendamment de toutes les autres et que vous composez simplement une merveilleuse et une histoire vibrante. <br><br>  C'est tout ce que je dis dans le contexte de la rÃ©ponse Ã  la question: Â«Pourquoi ajoutez-vous un raffinement comme un cyborg Ã  cela?  Je ne veux pas Ãªtre un cyborg. "  Il est nÃ©cessaire de tisser soigneusement des dÃ©tails supplÃ©mentaires aux dÃ©clarations. <br><br>  <b>X:</b> Avez-vous une chance d'immortalitÃ©? <br><br>  <b>Yu:</b> LittÃ©ralement?  L'immortalitÃ© littÃ©rale est difficile Ã  rÃ©aliser.  Pour vivre beaucoup plus longtemps que quelques milliers de milliards d'annÃ©es, vous devez reconsidÃ©rer le sort attendu d'un univers en expansion.  Pour vivre plus longtemps que les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">googolpleks</a> , il est nÃ©cessaire que nous nous <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">trompions</a> sur les fondements des lois physiques, et pas seulement dans les dÃ©tails. <br><br>  MÃªme si certains des raisonnements inhabituels s'avÃ¨rent vrais et que notre univers peut gÃ©nÃ©rer des univers filles, cela ne nous donnera pas l'immortalitÃ©.  Afin de vivre beaucoup plus d'annÃ©es de Googleplex et de ne pas vous rÃ©pÃ©ter, vous aurez besoin d'ordinateurs avec plus d'Ã©lÃ©ments que Google, et une telle machine ne rentrera pas dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sphÃ¨re Hubble</a> . <br><br>  Et googolpleks n'est pas l'infini.  Pour paraphraser Martin Gardner, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le nombre de Graham</a> est encore assez petit, car la plupart des chiffres finaux sont beaucoup plus grands que lui.  Si vous voulez Ãªtre Ã©poustouflÃ©, lisez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les hiÃ©rarchies Ã  croissance rapide</a> et l'infini sera encore plus long.  Seules les thÃ©ories anthropiques trÃ¨s Ã©tranges et effrayantes vous permettront de vivre assez longtemps pour regarder un arrÃªt de la machine Turing la plus ancienne avec des centaines d'Ã©tats. <br><br>  Cependant, je ne pense pas que d'un point de vue Ã©motionnel, j'aimerais vivre assez longtemps pour voir le centiÃ¨me numÃ©ro du jeu " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chasser un travailleur acharnÃ©</a> ".  Je peux en quelque sorte faire preuve d'empathie envers moi-mÃªme, qui a vÃ©cu une centaine d'annÃ©es Ã  partir de maintenant.  Cet avenir, je serai en mesure de comprendre moi-mÃªme l'avenir dans cent ans.  Et peut-Ãªtre que quelque part dans cette sÃ©quence, il y aura quelqu'un qui risque de mettre fin Ã  son existence, et il peut Ãªtre trÃ¨s triste Ã  ce sujet.  Mais je ne suis pas sÃ»r de pouvoir imaginer cette personne.  Â«Je veux vivre un autre jour.  Demain, je veux aussi vivre un autre jour.  Par consÃ©quent, je veux vivre pour toujours, prouvÃ© par l'induction d'entiers positifs. "  MÃªme mon dÃ©sir d'une longue vie dans un univers physiquement possible est une abstraction gÃ©nÃ©rÃ©e par induction.  Je ne peux pas m'imaginer dans un billion d'annÃ©es. <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> J'ai dÃ©crit la singularitÃ© comme une fantaisie Ã©vasive et pseudoscientifique qui nous distrait du changement climatique, des guerres, des inÃ©galitÃ©s et d'autres problÃ¨mes graves. Pourquoi ai-je tort? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Parce que vous essayez de prÃ©dire des faits empiriques par la psychanalyse. Ã‡a ne marchera jamais. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Supposons que nous vivions pour voir l'avÃ¨nement de l'IA suffisamment intelligente pour qu'elle fasse le mÃªme travail d'amÃ©lioration de l'IA que les gens. Il peut s'ajuster, programmer, inventer de nouveaux algorithmes. Pour s'amÃ©liorer. Que se passera-t-il ensuite - il deviendra plus intelligent, verra encore plus d'opportunitÃ©s d'amÃ©lioration et atteindra rapidement un niveau trÃ¨s Ã©levÃ©? Ou ne se passera-t-il rien de spÃ©cial?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il peut arriver que (A) l'auto-amÃ©lioration sur un certain delta rende l'IA assez intelligente pour qu'elle puisse regarder en arriÃ¨re et trouver une nouvelle amÃ©lioration potentielle de la taille de k * delta, oÃ¹ k&gt; 1, et cela sera rÃ©pÃ©tÃ© plusieurs fois pour conduire Ã  une auto-amÃ©lioration rapide pour niveau de superintelligence. Ce </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">qu'Irving John Goode a</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> appelÃ© Â«l'explosion du renseignementÂ». Ou (B), k est infÃ©rieur Ã  l'unitÃ© ou toutes ces amÃ©liorations sont petites et ne conduisent pas Ã  l'apparition de superintelligence, ou la superintelligence est gÃ©nÃ©ralement impossible, et au lieu d'une explosion il y aura un zilch. Qu'est-ce qui est vrai, A ou B? Si vous construisez une IA d'un certain niveau et qu'il essaie de le faire, quelque chose se passera dans le monde rÃ©el empirique, et cet Ã©vÃ©nement sera dÃ©terminÃ© par des faits concernant le paysage des algorithmes et des amÃ©liorations rÃ©alisables.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Des informations fiables sur cet Ã©vÃ©nement ne peuvent Ãªtre obtenues de la psychanalyse des personnes. C'est comme essayer de dÃ©marrer une voiture sans carburant - c'est ce que le thÃ©orÃ¨me de Bayes nous dit. Certaines personnes seront toujours des Ã©vadÃ©s, quelles que soient les valeurs rÃ©elles des variables cachÃ©es en informatique, donc l'observation de certains Ã©vadÃ©s ne peut pas Ãªtre qualifiÃ©e de preuve rigoureuse. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C'est une idÃ©e fausse sur la nature de la rationalitÃ© - qu'il est rationnel de croire que "les gobelins dans les placards n'existent pas" parce que la foi en les gobelins d'un placard est stupide, immature, obsolÃ¨te, et seuls les idiots y croient. Le vrai principe de rationalitÃ© est d'aller vÃ©rifier dans le placard. Donc, dans ces univers oÃ¹ les gobelins vivent dans des placards, vous croirez aux gobelins, et dans les univers oÃ¹ les gobelins seront dans des placards, vous n'y croirez pas.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">C'est difficile, mais en principe, il est possible d'essayer de regarder par la porte entrouverte et de demander: "Qu'est-ce qui serait diffÃ©rent dans l'Univers s'il n'Ã©tait pas possible d'obtenir un bon revenu des investissements cognitifs, c'est-Ã -dire qu'une IA essayant de s'amÃ©liorer se terminerait non pas par une explosion, mais par un zilch?" Quels autres faits seraient caractÃ©ristiques d'un tel univers? Â» </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il y a des gens qui prÃ©tendent que l'IA ne peut Ãªtre Ã©levÃ©e qu'au niveau d'une personne, car nous sommes nous-mÃªmes des gens, et nous ne pouvons pas l'augmenter plus haut. Il me semble que si notre univers est tel, alors nous devrions observer une diminution des revenus des investissements dans le matÃ©riel et les logiciels pour les Ã©checs informatiques qui dÃ©passe le niveau d'une personne - ce qui en fait ne se produit pas. De plus, la sÃ©lection naturelle ne serait pas en mesure de crÃ©er une personne Ã  ce moment-lÃ , et la mÃ¨re d'Einstein aurait dÃ» Ãªtre une physicienne incroyable, etc. etc.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il y a des gens qui soutiennent que plus l'algorithme est complexe, plus il a besoin d'ajustements et que notre intelligence sert de limitation Ã  ce processus. Mais cela ne correspond pas aux archives anthropologiques de l'intelligence humaine; les investissements dans le rÃ©glage et les mutations du cerveau offrent des capacitÃ©s cognitives amÃ©liorÃ©es. Nous le savons, car la gÃ©nÃ©tique nous dit que les mutations avec une petite rÃ©ponse statistique ne sont pas fixes au cours de l'Ã©volution. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et les hominidÃ©s n'avaient pas besoin d'un cerveau exponentiellement plus grand que les chimpanzÃ©s. Et la tÃªte de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">John von Neumann n'Ã©tait</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> pas exponentiellement plus grande que la tÃªte de la personne moyenne.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">D'un point de vue purement pratique, les axones humains transmettent des informations Ã  une vitesse d'un million de fois infÃ©rieure Ã  la vitesse de la lumiÃ¨re, et mÃªme du point de vue de la dissipation thermique, chaque opÃ©ration synaptique consomme un million de fois plus que la dissipation thermique minimale d'une opÃ©ration binaire irrÃ©versible Ã  300 Kelvin, et ainsi de suite. Pourquoi devrions-nous supposer que le logiciel du cerveau est plus proche de l'optimum que le fer? Le privilÃ¨ge de l'intelligence humaine est qu'il s'agit du plus petit niveau d'intelligence capable de crÃ©er un ordinateur. S'il Ã©tait possible de crÃ©er un ordinateur avec un niveau d'intelligence infÃ©rieur, nous en discuterions Ã  un niveau infÃ©rieur.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais ce n'est pas un argument simple, et pour une description dÃ©taillÃ©e, j'envoie des gens Ã  l'un de mes anciens travaux, Â«La microÃ©conomie de l'explosion de l'intelligenceÂ», qui, malheureusement, est toujours la meilleure source d'information. Mais ce sont prÃ©cisÃ©ment ces questions qui doivent Ãªtre posÃ©es afin d'utiliser les preuves disponibles pour discuter si nous verrons une explosion de l'IA dans laquelle une certaine amÃ©lioration des capacitÃ©s cognitives investies dans l'auto-optimisation donnera une augmentation supÃ©rieure Ã  cette amÃ©lioration. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quant aux opportunitÃ©s et Ã  leurs prix: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vous pouvez imaginer un monde sans explosion d'intelligence et sans superintelligence. Ou un monde oÃ¹ les astuces que les experts en apprentissage automatique utiliseront pour contrÃ´ler la super-IA conviennent au contrÃ´le des personnes et du rÃ©gime surhumain. Ou un monde oÃ¹ </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">l'internalisme moral</font></a><font style="vertical-align: inherit;"> fonctionne</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, donc toutes les IA assez avancÃ©es sont bonnes. Dans de tels mondes, personne n'a besoin de tout le travail et de tous les soucis du Machine Learning Research Institute. Et plusieurs moustiquaires ont Ã©tÃ© gaspillÃ©es, et il valait mieux les remettre au fonds de lutte contre le paludisme. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pouvez Ã©galement imaginer un monde dans lequel vous luttez contre le paludisme, combattez et maintenez les Ã©missions de carbone au niveau appropriÃ©, ou utilisez des solutions de gÃ©o-ingÃ©nierie pour neutraliser les erreurs dÃ©jÃ  commises. Et tout cela s'avÃ¨re inutile, car la civilisation est incapable de rÃ©soudre le problÃ¨me de la moralitÃ© de l'IA - et tous les enfants sauvÃ©s du paludisme Ã  l'aide de filets ne grandissent que pour que les nanomachines les tuent dans un rÃªve.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je pense que les gens qui essaient de s'engager dans une organisation caritative raisonnable conviendront que nous n'aimerions pas vivre dans aucun de ces mondes. La seule question est laquelle est la plus probable. Le principe central de la rationalitÃ© n'est pas de rejeter la croyance aux gobelins, parce qu'elle est stupide et non prestigieuse, et de ne pas croire aux gobelins, car elle est saine et belle. Le principe central de la rationalitÃ© est de savoir quels signes observables et conclusions logiques nous aideront Ã  choisir l'un de ces deux mondes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je pense que le premier monde est peu probable, et le second est probable. Je comprends qu'essayer de convaincre les autres de cela, c'est nager contre le flux de la foi dans la normalitÃ© Ã©ternelle. Croire que seule notre civilisation Ã  court terme, qui existe depuis plusieurs dÃ©cennies, et que notre espÃ¨ce, qui nâ€™existe quâ€™un instant aux Ã©chelles Ã©volutives et gÃ©ologiques, ont un sens et doivent exister pour toujours. Et mÃªme si je crois que le premier monde n'est qu'un rÃªve optimiste, je ne pense pas que nous devions ignorer le problÃ¨me, dont nous paniquerons Ã  l'avenir. L'Institut a pour mission de mener aujourd'hui des recherches qui, selon les personnes vivant aprÃ¨s 30 ans, auraient dÃ» commencer il y a 30 ans. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Votre femme Brijena croit-elle Ã  la singularitÃ©?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Brijena: Si quelqu'un me demandait si je crois en une singularitÃ©, je lÃ¨verais un sourcil et lui demanderais s'il croit aux camions automatiques. C'est une Ã©trange question. Je ne sais pas quelle sera la premiÃ¨re flotte de camions automatiques, ni combien de temps il leur faudra pour remplacer le systÃ¨me de transport de marchandises existant. Et je ne crois pas aux camions robotiques, je prÃ©dis avec confiance que le transport sans pilote remplacera le transport moderne avec la participation des gens, parce que nous allons dans cette direction si rien de vraiment Ã©trange ne se produit. Pour la mÃªme raison, je prÃ©dis avec confiance une explosion d'intelligence. Dans d'autres sens du mot Â«singularitÃ©Â», je n'en suis pas si sÃ»r. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Brijena a donnÃ© sa rÃ©ponse sans voir mes rÃ©ponses. C'est juste que nous sommes bien adaptÃ©s les uns aux autres. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Est-il possible de crÃ©er une superintelligence sans comprendre comment fonctionne le cerveau? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dans le mÃªme sens que vous pouvez faire des avions sans comprendre comment un oiseau vole. Vous n'avez pas besoin d'Ãªtre un expert des oiseaux, mais en mÃªme temps, vous avez besoin de beaucoup de connaissances pour construire un avion, aprÃ¨s avoir obtenu ce qui, en principe, vous pouvez dÃ©jÃ  comprendre comment approximativement un oiseau plane ou repousse de l'air. Par consÃ©quent, j'Ã©cris sur la rationalitÃ© humaine - si vous allez assez loin dans la question de l'intelligence artificielle, vous ne pouvez pas vous empÃªcher de penser Ã  quelques idÃ©es sur la faÃ§on dont les gens pensent. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Que pourrait vouloir la superintelligence? Auront-ils quelque chose comme le dÃ©sir sexuel? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pensez Ã  un vaste espace de possibilitÃ©s, Ã  une sphÃ¨re multidimensionnelle gÃ©ante. C'est un espace de types d'esprit, un ensemble de tous les algorithmes cognitifs possibles. Imaginez que quelque part au bas de la sphÃ¨re se trouve un tout petit point dÃ©signant toutes les personnes qui ont dÃ©jÃ  vÃ©cu. C'est un petit point, car toutes les personnes ont Ã  peu prÃ¨s le mÃªme cerveau, avec cortex, cervelet, thalamus, etc. Certaines personnes ne sont pas comme les autres, il peut donc s'agir d'un point pointu, mais les pointes seront Ã  la mÃªme Ã©chelle que le point lui-mÃªme. Quelle que soit votre neuroatypicalitÃ©, vous ne travaillerez pas sur un autre algorithme cortical.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Demander Â«ce que veut la superintelligenceÂ» n'est pas la bonne question. Les superintelligences ne sont pas une Ã©trange tribu de gens qui vivent de l'autre cÃ´tÃ© de la riviÃ¨re et ont des coutumes exotiques. L'IA est simplement le nom de tout l'espace des possibilitÃ©s en dehors d'un petit point humain. Ayant des connaissances suffisantes, vous pouvez grimper dans cet espace d'opportunitÃ©s et en sortir une IA qui a des dÃ©sirs qui peuvent Ãªtre dÃ©crits en langage humain par Wishlist, mais pas parce que ce sera la Wishlist naturelle de ces surhumains exotiques, mais parce que vous avez isolÃ© une partie de l'espace des types d'esprit .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En ce qui concerne les dÃ©sirs sexuels - si vous savez exactement ce que vous faites, vous avez rÃ©solu le problÃ¨me principal de la construction de l'IA, voulant de maniÃ¨re stable certaines choses alors qu'elle s'amÃ©liore, si vous avez rÃ©solu le problÃ¨me principal de diriger les fonctions utilitaires de l'IA vers des tÃ¢ches qui semblent trompeusement simples pour une personne, et un problÃ¨me encore plus compliquÃ© est la construction de l'IA en utilisant un certain type d'architecture, dans laquelle des choses comme les Â«dÃ©sirs sexuelsÂ» et le Â«bonheur du sexeÂ» comptent, alors, peut-Ãªtre, vous pouvez faire en sorte que l'IA regarde les gens qui modÃ©lisent Ãªtre leurs dÃ©sirs, en extraire cette partie en ce qui concerne le dÃ©sir sexuel, et faire en sorte que l'IA en fasse l'expÃ©rience. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien sÃ»r, vous pouvez Ã©galement, avec une bonne connaissance de la biologie organique et de l'aÃ©rodynamique, construire des avions pouvant s'accoupler avec des oiseaux.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mais je ne pense pas que les frÃ¨res Wright auraient dÃ» faire de telles choses Ã  l'aube de leurs activitÃ©s. Cela n'aurait aucun sens. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il semble plus raisonnable de rÃ©soudre le problÃ¨me de pÃ©nÃ©trer l'espace des esprits et d'en extraire une IA qui ne veut pas nous dÃ©monter en atomes de rechange. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Je veux penser que les crÃ©atures extra-intelligentes professeront la non-violence, car elles comprendront que la violence est stupide. Suis-je naÃ¯f </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Je pense que oui. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">David hume</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Je vous dirais que vous faites une erreur typique en appliquant le prÃ©dicat de Â«stupiditÃ©Â» aux valeurs ou aux opÃ©rations officielles d'un individu. Les actions, les choix, les rÃ¨gles peuvent Ãªtre stupides si vous avez des prÃ©fÃ©rences sur l'Ã©tat final du monde. Si vous Ãªtes une personne avec des mÃ©ta-prÃ©fÃ©rences que vous n'avez pas entiÃ¨rement calculÃ©es, vous pouvez avoir une plate-forme sur laquelle vous pouvez compter et appeler certaines spÃ©culations sur les prÃ©fÃ©rences d'objet "stupides". </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maximiseur d'agrafes [ </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">expÃ©rience de pensÃ©e dÃ©montrant comment l'IA produite sans intention malveillante peut nuire Ã  l'humanitÃ© - env.</font></font></i>  <i>perev.</i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">] ne fait pas d'erreur de calcul, en choisissant les cas parmi ceux dans lesquels le nombre maximum d'agrafes est obtenu. Ce n'est pas Ã  l'intÃ©rieur de votre plateforme de prÃ©fÃ©rences, en choisissant des actions erronÃ©es, et ce n'est pas Ã  l'intÃ©rieur de votre plateforme de mÃ©ta-prÃ©fÃ©rences, en choisissant par erreur les prÃ©fÃ©rences. Il calcule la rÃ©ponse Ã  une autre question, et non Ã  celle que vous vous posez, la question "Que dois-je faire?" Le maximiseur d'agrafes prend simplement l'action menant au plus d'agrafes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un scÃ©nario fatal est lorsque l'IA ne vous aime ni ne vous dÃ©teste, car vous Ãªtes fait d'atomes qu'elle peut utiliser pour crÃ©er autre chose. ThÃ©orie des jeux et problÃ¨mes de coopÃ©ration dans </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le dilemme du prisonnier</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ne se manifestent pas dans tous les cas possibles. Par exemple, ils n'apparaissent pas lorsqu'un certain sujet est tellement plus fort que vous qu'il peut vous transformer en atomes lorsque vous voulez cliquer sur les boutons Â«coopÃ©rerÂ» ou Â«changerÂ». Et lorsque nous franchissons ce seuil, soit vous avez rÃ©solu le problÃ¨me de crÃ©er quelque chose qui ne veut pas vous nuire, soit vous avez dÃ©jÃ  perdu. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> La superintelligence </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rÃ©soudra-t-elle le difficile problÃ¨me de la conscience</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Oui, et avec le recul, la rÃ©ponse nous semblera honteusement simple. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X: Les</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> superintelligences auront-elles le libre arbitre? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Oui, mais ils n'auront pas l'illusion du libre arbitre. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">X: A</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> quoi ressemble votre utopie? </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Yu:</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Je dirigerai vos lecteurs vers les miens "</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SÃ©quences de la thÃ©orie du divertissement,</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> "car je n'ai pas encore rÃ©ussi Ã  Ã©crire une histoire dont l'action se dÃ©roule dans un monde optimal divertissant et thÃ©orique.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr404137/">https://habr.com/ru/post/fr404137/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr404125/index.html">Le compte Ã  rebours est terminÃ©: il reste 7 jours avant l'ICO Polybe</a></li>
<li><a href="../fr404127/index.html">Le premier lancement de l'Electron LV a Ã©tÃ© partiellement rÃ©ussi</a></li>
<li><a href="../fr404129/index.html">Happy Geeks Day (oui, il est aujourd'hui)</a></li>
<li><a href="../fr404133/index.html">D'ici la fin de l'annÃ©e, Google prÃ©voit de mettre en service un ordinateur quantique Ã  49 qubits</a></li>
<li><a href="../fr404135/index.html">Google collecte et analyse les achats hors ligne des utilisateurs d'Android Pay</a></li>
<li><a href="../fr404139/index.html">Bitcoin en Russie: taxe (quelques questions simples)</a></li>
<li><a href="../fr404141/index.html">Concurrence dÃ©loyale avec le fournisseur</a></li>
<li><a href="../fr404143/index.html">Tiny Nuggets: un examen des bureaux d'enregistrement et du tube TrendVision russes</a></li>
<li><a href="../fr404147/index.html">Le son, vous n'Ãªtes plus que "l'espace": les Ã©couteurs Campfire Audio Andromeda</a></li>
<li><a href="../fr404149/index.html">Test du lecteur Ã©tanche PocketBook 641 Aqua 2 nouvelle gÃ©nÃ©ration</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíó üç∫ üîê Reconhecimento de faces usando redes siamesas üõ¢Ô∏è üèáüèº üë®üèø‚Äçüåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A rede neural siamesa √© um dos algoritmos de aprendizado √∫nico mais simples e mais populares. M√©todos em que para cada aula √© realizado apenas um estu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reconhecimento de faces usando redes siamesas</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jetinfosystems/blog/465279/"><img src="https://habrastorage.org/webt/mg/dh/mb/mgdhmb0xf-4onn6dny1renuuhla.jpeg"><br><br>  A rede neural siamesa √© um dos algoritmos de aprendizado √∫nico mais simples e mais populares.  M√©todos em que para cada aula √© realizado apenas um estudo de caso.  Assim, a rede siamesa √© geralmente usada em aplicativos onde n√£o h√° muitas unidades de dados em cada classe. <br><br>  Suponha que precisamos criar um modelo de reconhecimento facial para uma organiza√ß√£o que emprega cerca de 500 pessoas.  Se voc√™ criar um modelo desse tipo com base na rede neural convolucional (CNN), para trein√°-lo e obter uma boa precis√£o de reconhecimento, precisaremos de muitas imagens de cada uma dessas 500 pessoas.  Mas √© √≥bvio que n√£o podemos compilar esse conjunto de dados, portanto, voc√™ n√£o deve criar um modelo baseado na CNN ou em qualquer outro algoritmo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aprendizado profundo</a> se n√£o tivermos dados suficientes.  Nesses casos, voc√™ pode usar o algoritmo complexo de aprendizado √∫nico, como a rede siamesa, que pode ser treinada com menos dados. <br><a name="habracut"></a><br>  De fato, as redes siamesas consistem em duas redes neurais sim√©tricas, com os mesmos pesos e arquitetura, que no final combinam e usam a fun√ß√£o de energia - E. <br>  Vejamos a rede siamesa, criando um modelo de reconhecimento de rosto baseado nela.  Vamos ensin√°-la a determinar quando duas faces s√£o iguais e quando n√£o s√£o.  E, para come√ßar, usaremos o conjunto de dados AT&amp;T Database of Faces, que pode ser baixado do site do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">laborat√≥rio de computa√ß√£o da Universidade de Cambridge</a> . <br><br>  Baixe, descompacte e veja as pastas de s1 a s40: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/152/0fc/158/1520fc1584e7ba6335ba2ea99460d8f6.png"><br><br>  Cada pasta cont√©m 10 fotografias diferentes de uma √∫nica pessoa, tiradas de diferentes √¢ngulos.  Aqui est√° o conte√∫do da pasta s1: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5d4/02b/86f/5d402b86fc12e1b23512b1a54c7fea57.png"><br><br>  E aqui est√° o que est√° na pasta s13: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b7c/819/716/b7c8197164861f8568e86d32a2294bc2.png"><br><br>  As redes siamesas precisam inserir valores emparelhados com marca√ß√µes, ent√£o vamos criar esses conjuntos.  Tire duas fotos aleat√≥rias da mesma pasta e marque-as como um par ‚Äúgenu√≠no‚Äù.  Depois, tiramos duas fotos de pastas diferentes e as marcamos como um par "falso" (imposi√ß√£o): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5b3/1f3/8bf/5b31f38bf3363aaa53110772b7643e3b.png"><br><br>  Depois de distribuir todas as fotos em pares marcados, estudaremos a rede.  De cada par, transferiremos uma foto para a rede A e a segunda para a rede B. Ambas as redes extraem apenas vetores de propriedades.  Para isso, usamos duas camadas convolucionais com a ativa√ß√£o da unidade linear retificada (ReLU).  Tendo estudado as propriedades, transferimos os vetores gerados pelas duas redes para uma fun√ß√£o energ√©tica que estima a similaridade.  Usamos a dist√¢ncia euclidiana como uma fun√ß√£o. <br><br><h2>  Agora considere todas essas etapas com mais detalhes. </h2><br>  Primeiro, importe as bibliotecas necess√°rias: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Activation <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Lambda, Dense, Dropout, Convolution2D, MaxPooling2D, Flatten <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RMSprop</code> </pre> <br>  Agora, definimos uma fun√ß√£o para ler imagens de entrada.  A fun√ß√£o <code>read_image</code> tira uma foto e retorna uma matriz NumPy: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">read_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename, byteorder=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'&gt;'</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#first we read the image, as a raw file to the buffer with open(filename, 'rb') as f: buffer = f.read() #using regex, we extract the header, width, height and maxval of the image header, width, height, maxval = re.search( b"(^P5\s(?:\s*#.*[\r\n])*" b"(\d+)\s(?:\s*#.*[\r\n])*" b"(\d+)\s(?:\s*#.*[\r\n])*" b"(\d+)\s(?:\s*#.*[\r\n]\s)*)", buffer).groups() #then we convert the image to numpy array using np.frombuffer which interprets buffer as one dimensional array return np.frombuffer(buffer, dtype='u1' if int(maxval)</span></span></code> </pre> <br>  Por exemplo, abra esta foto: <br><br><pre> <code class="python hljs">Image.open(<span class="hljs-string"><span class="hljs-string">"data/orl_faces/s1/1.pgm"</span></span>)</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/ee2/954/697/ee2954697908ce55ffaf4fc8080914c7.png"><br><br>  Passamos para a fun√ß√£o <code>read_image</code> e obtemos uma matriz NumPy: <br><br><pre> <code class="python hljs">img = read_image(<span class="hljs-string"><span class="hljs-string">'data/orl_faces/s1/1.pgm'</span></span>) img.shape (<span class="hljs-number"><span class="hljs-number">112</span></span>, <span class="hljs-number"><span class="hljs-number">92</span></span>)</code> </pre> <br>  Agora, definimos a fun√ß√£o <code>get_data</code> que ir√° gerar os dados.  Deixe-me lembr√°-lo de que as redes siamesas precisam enviar pares de dados (genu√≠nos e imponentes) com marca√ß√£o bin√°ria. <br><br>  Primeiro, leia as imagens ( <code>img1</code> , <code>img2</code> ) em um diret√≥rio, salve-as na matriz <code>x_genuine_pair,</code> defina <code>y_genuine</code> como <code>1</code> .  Em seguida, lemos as imagens ( <code>img1</code> , <code>img2</code> ) de diret√≥rios diferentes, salve-as no par <code>x_imposite,</code> e defina <code>y_imposite</code> como <code>0</code> . <br><br>  Concatene <code>x_genuine_pair</code> e <code>x_imposite</code> em <code>X</code> e <code>y_genuine</code> e <code>y_imposite</code> em <code>Y</code> : <br><br><pre> <code class="python hljs">size = <span class="hljs-number"><span class="hljs-number">2</span></span> total_sample_size = <span class="hljs-number"><span class="hljs-number">10000</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(size, total_sample_size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#read the image image = read_image('data/orl_faces/s' + str(1) + '/' + str(1) + '.pgm', 'rw+') #reduce the size image = image[::size, ::size] #get the new size dim1 = image.shape[0] dim2 = image.shape[1] count = 0 #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2] x_geuine_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2]) # 2 is for pairs y_genuine = np.zeros([total_sample_size, 1]) for i in range(40): for j in range(int(total_sample_size/40)): ind1 = 0 ind2 = 0 #read images from same directory (genuine pair) while ind1 == ind2: ind1 = np.random.randint(10) ind2 = np.random.randint(10) # read the two images img1 = read_image('data/orl_faces/s' + str(i+1) + '/' + str(ind1 + 1) + '.pgm', 'rw+') img2 = read_image('data/orl_faces/s' + str(i+1) + '/' + str(ind2 + 1) + '.pgm', 'rw+') #reduce the size img1 = img1[::size, ::size] img2 = img2[::size, ::size] #store the images to the initialized numpy array x_geuine_pair[count, 0, 0, :, :] = img1 x_geuine_pair[count, 1, 0, :, :] = img2 #as we are drawing images from the same directory we assign label as 1. (genuine pair) y_genuine[count] = 1 count += 1 count = 0 x_imposite_pair = np.zeros([total_sample_size, 2, 1, dim1, dim2]) y_imposite = np.zeros([total_sample_size, 1]) for i in range(int(total_sample_size/10)): for j in range(10): #read images from different directory (imposite pair) while True: ind1 = np.random.randint(40) ind2 = np.random.randint(40) if ind1 != ind2: break img1 = read_image('data/orl_faces/s' + str(ind1+1) + '/' + str(j + 1) + '.pgm', 'rw+') img2 = read_image('data/orl_faces/s' + str(ind2+1) + '/' + str(j + 1) + '.pgm', 'rw+') img1 = img1[::size, ::size] img2 = img2[::size, ::size] x_imposite_pair[count, 0, 0, :, :] = img1 x_imposite_pair[count, 1, 0, :, :] = img2 #as we are drawing images from the different directory we assign label as 0. (imposite pair) y_imposite[count] = 0 count += 1 #now, concatenate, genuine pairs and imposite pair to get the whole data X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255 Y = np.concatenate([y_genuine, y_imposite], axis=0) return X, Y</span></span></code> </pre> <br>  Agora vamos gerar os dados e verificar seu tamanho.  Temos 20.000 fotos, das quais 10.000 pares genu√≠nos e 10.000 falsos foram coletados: <br><br><pre> <code class="python hljs">X, Y = get_data(size, total_sample_size) X.shape (<span class="hljs-number"><span class="hljs-number">20000</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">56</span></span>, <span class="hljs-number"><span class="hljs-number">46</span></span>) Y.shape (<span class="hljs-number"><span class="hljs-number">20000</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  Compartilharemos toda a gama de informa√ß√µes: 75% dos pares ser√£o treinados e 25% - para testes: <br> <code>x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)</code> <br> <br>  Agora crie uma rede siamesa.  Primeiro, definimos a rede principal - ser√° uma rede neural convolucional para extrair propriedades.  Crie duas camadas convolucionais usando ativa√ß√µes ReLU e uma camada com pool m√°ximo ap√≥s uma camada plana: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_base_network</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_shape)</span></span></span><span class="hljs-function">:</span></span> seq = Sequential() nb_filter = [<span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>] kernel_size = <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-comment"><span class="hljs-comment">#convolutional layer 1 seq.add(Convolution2D(nb_filter[0], kernel_size, kernel_size, input_shape=input_shape, border_mode='valid', dim_ordering='th')) seq.add(Activation('relu')) seq.add(MaxPooling2D(pool_size=(2, 2))) seq.add(Dropout(.25)) #convolutional layer 2 seq.add(Convolution2D(nb_filter[1], kernel_size, kernel_size, border_mode='valid', dim_ordering='th')) seq.add(Activation('relu')) seq.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='th')) seq.add(Dropout(.25)) #flatten seq.add(Flatten()) seq.add(Dense(128, activation='relu')) seq.add(Dropout(0.1)) seq.add(Dense(50, activation='relu')) return seq</span></span></code> </pre> <br><br>  Em seguida, transferiremos um par de imagens da rede principal, que retornar√° representa√ß√µes vetoriais, ou seja, vetores de propriedades: <br><br><pre> <code class="python hljs">input_dim = x_train.shape[<span class="hljs-number"><span class="hljs-number">2</span></span>:] img_a = Input(shape=input_dim) img_b = Input(shape=input_dim) base_network = build_base_network(input_dim) feat_vecs_a = base_network(img_a) feat_vecs_b = base_network(img_b)</code> </pre><br>  <code>feat_vecs_a</code> e <code>feat_vecs_b</code> s√£o vetores de propriedades de um par de imagens.  Vamos passar suas fun√ß√µes de energia para calcular a dist√¢ncia entre eles.  E em fun√ß√£o da energia, usamos a dist√¢ncia euclidiana: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">euclidean_distance</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(vects)</span></span></span><span class="hljs-function">:</span></span> x, y = vects <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> K.sqrt(K.sum(K.square(x - y), axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">eucl_dist_output_shape</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(shapes)</span></span></span><span class="hljs-function">:</span></span> shape1, shape2 = shapes <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (shape1[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])</code> </pre> <br>  Definimos o n√∫mero de √©pocas como 13, aplicamos a propriedade RMS para otimiza√ß√£o e declaramos o modelo: <br><br><pre> <code class="python hljs">epochs = <span class="hljs-number"><span class="hljs-number">13</span></span> rms = RMSprop() model = Model(input=[input_a, input_b], output=distance)</code> </pre> <br>  Agora, definimos a fun√ß√£o de perda <code>contrastive_loss</code> e compilamos o modelo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">contrastive_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> margin = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> K.mean(y_true * K.square(y_pred) + (<span class="hljs-number"><span class="hljs-number">1</span></span> - y_true) * K.square(K.maximum(margin - y_pred, <span class="hljs-number"><span class="hljs-number">0</span></span>))) model.compile(loss=contrastive_loss, optimizer=rms)</code> </pre> <br>  Vamos estudar o modelo: <br><br><pre> <code class="python hljs">img_1 = x_train[:, <span class="hljs-number"><span class="hljs-number">0</span></span>] img_2 = x_train[:, <span class="hljs-number"><span class="hljs-number">1</span></span>] model.fit([img_1, img_2], y_train, validation_split=<span class="hljs-number"><span class="hljs-number">.25</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">128</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>, nb_epoch=epochs)</code> </pre> <br>  Voc√™ v√™ como as perdas diminuem √† medida que as eras passam: <br><br><pre> <code class="python hljs">Train on <span class="hljs-number"><span class="hljs-number">11250</span></span> samples, validate on <span class="hljs-number"><span class="hljs-number">3750</span></span> samples Epoch <span class="hljs-number"><span class="hljs-number">1</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">60</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.2179</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.2156</span></span> Epoch <span class="hljs-number"><span class="hljs-number">2</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">53</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.1520</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.2102</span></span> Epoch <span class="hljs-number"><span class="hljs-number">3</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">53</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.1190</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.1545</span></span> Epoch <span class="hljs-number"><span class="hljs-number">4</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">55</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0959</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.1705</span></span> Epoch <span class="hljs-number"><span class="hljs-number">5</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0801</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.1181</span></span> Epoch <span class="hljs-number"><span class="hljs-number">6</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0684</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0821</span></span> Epoch <span class="hljs-number"><span class="hljs-number">7</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0591</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0762</span></span> Epoch <span class="hljs-number"><span class="hljs-number">8</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0526</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0655</span></span> Epoch <span class="hljs-number"><span class="hljs-number">9</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0475</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0662</span></span> Epoch <span class="hljs-number"><span class="hljs-number">10</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0444</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0469</span></span> Epoch <span class="hljs-number"><span class="hljs-number">11</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0408</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0478</span></span> Epoch <span class="hljs-number"><span class="hljs-number">12</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">52</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0381</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0498</span></span> Epoch <span class="hljs-number"><span class="hljs-number">13</span></span>/<span class="hljs-number"><span class="hljs-number">13</span></span> - <span class="hljs-number"><span class="hljs-number">54</span></span>s - loss: <span class="hljs-number"><span class="hljs-number">0.0356</span></span> - val_loss: <span class="hljs-number"><span class="hljs-number">0.0363</span></span></code> </pre> <br>  E agora vamos testar o modelo nos dados de teste: <br><br><pre> <code class="python hljs">pred = model.predict([x_test[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], x_test[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]])</code> </pre> <br>  Defina uma fun√ß√£o para calcular a precis√£o: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">compute_accuracy</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(predictions, labels)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> labels[predictions.ravel()</code> </pre> <br>  Calculamos a precis√£o: <br><br><pre> <code class="plaintext hljs">compute_accuracy(pred, y_test) 0.9779092702169625</code> </pre><br><h2>  Conclus√µes </h2><br>  Neste guia, aprendemos como criar modelos de reconhecimento de rosto baseados em redes siamesas.  A arquitetura de tais redes consiste em duas redes neurais id√™nticas com o mesmo peso e estrutura, e os resultados de seu trabalho s√£o transferidos para uma fun√ß√£o de energia - isso determina a identidade dos dados de entrada.  Para obter mais informa√ß√µes sobre meta-aprendizado usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Python,</a> consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Meta-Learning pr√°tico com Python.</a> <br><br><h2>  Meu coment√°rio </h2><br>  Atualmente, o conhecimento de redes siamesas √© necess√°rio ao trabalhar com imagens.  Existem muitas abordagens para o treinamento de redes em pequenas amostras, nova gera√ß√£o de dados, m√©todos de aumento.  Este m√©todo permite que relativamente "barato" alcance bons resultados, eis um exemplo mais cl√°ssico da rede siamesa no "Hello world" para redes neurais - conjunto de dados MNIST <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">keras.io/examples/mnist_siamese</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt465279/">https://habr.com/ru/post/pt465279/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt465269/index.html">Treinamento Cisco 200-125 CCNA v3.0. Dia 26. DNS e DHCP</a></li>
<li><a href="../pt465271/index.html">Os hackers roubam e lavam dinheiro atrav√©s de servi√ßos de entrega de comida e reserva de hotel.</a></li>
<li><a href="../pt465273/index.html">Como os desenvolvedores de software da Microgaming protegem os usu√°rios de hackers</a></li>
<li><a href="../pt465275/index.html">Alice Obt√©m Habilidade</a></li>
<li><a href="../pt465277/index.html">Analisando e analisando a sem√¢ntica para SEO: 5 modelos gratuitos do Planilhas Google</a></li>
<li><a href="../pt465281/index.html">Monitoramento Cont√≠nuo de Glicose (NMH) com a Bomba Medtronic 640g</a></li>
<li><a href="../pt465283/index.html">‚ÄúExiste tudo o que √© necess√°rio e nada enfurece‚Äù - a verdade fala pelos l√°bios do cliente</a></li>
<li><a href="../pt465285/index.html">Como escrevemos, a interface do nosso pr√≥prio painel de controle de hospedagem: estrutura e backdoors</a></li>
<li><a href="../pt465289/index.html">Resumo de eventos para profissionais de RH na √°rea de TI em setembro de 2019</a></li>
<li><a href="../pt465291/index.html">Mais perto do ch√£o: como mudei o coworking para uma casa de aldeia</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçä üî¢ üëµüèº Sete mitos na pesquisa de aprendizado de m√°quina üôáüèª üòÜ üßëüèº‚Äçü§ù‚Äçüßëüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Para quem tem pregui√ßa de ler tudo: √© sugerida uma refuta√ß√£o de sete mitos populares, que no campo da pesquisa em aprendizado de m√°quina √© frequenteme...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sete mitos na pesquisa de aprendizado de m√°quina</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/444172/">  Para quem tem pregui√ßa de ler tudo: √© sugerida uma refuta√ß√£o de sete mitos populares, que no campo da pesquisa em aprendizado de m√°quina √© frequentemente considerada verdadeira a partir de fevereiro de 2019. Este artigo est√° dispon√≠vel no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site do ArXiv em formato pdf</a> [em ingl√™s]. <br><br>  Mito 1: TensorFlow √© uma biblioteca de tensores. <br>  Mito 2: Os bancos de dados de imagens refletem fotos reais encontradas na natureza. <br>  Mito 3: Os pesquisadores do MO n√£o usam kits de teste para testar. <br>  Mito 4: O treinamento em rede neural usa todos os dados de entrada. <br>  Mito 5: A normaliza√ß√£o de lotes √© necess√°ria para treinar redes residuais muito profundas. <br>  Mito 6: Redes com aten√ß√£o s√£o melhores que convolu√ß√£o. <br>  Mito 7: Mapas de signific√¢ncia s√£o uma maneira confi√°vel de interpretar redes neurais. <br><br>  E agora para os detalhes. <br><a name="habracut"></a><br><h2>  Mito 1: TensorFlow √© uma biblioteca de tensores </h2><br>  De fato, esta √© uma biblioteca para trabalhar com matrizes, e essa diferen√ßa √© muito significativa. <br><br>  Em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Computa√ß√£o Derivadas de Ordem Superior de Express√µes Matriciais e de Tensores.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Laue et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Os</a> autores do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NeurIPS 2018</a> demonstram que sua biblioteca de diferencia√ß√£o autom√°tica, baseada em c√°lculo de tensor real, possui √°rvores de express√£o muito mais compactas.  O fato √© que o c√°lculo do tensor usa nota√ß√£o de √≠ndice, o que permite trabalhar igualmente com os modos direto e reverso. <br><br>  A numera√ß√£o de matrizes oculta os √≠ndices de conveni√™ncia da nota√ß√£o, e √© por isso que as √°rvores de express√£o de diferencia√ß√£o autom√°tica geralmente se tornam muito complexas. <br><br>  Considere a multiplica√ß√£o da matriz C = AB.  N√≥s temos <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>C</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>A</mi></mrow><mi>B</mi><mo>+</mo><mi>A</mi><mtext>&amp;#xA0;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>B</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="33.438ex" height="2.419ex" viewBox="0 -780.1 14397 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-70" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="753" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6E" x="1239" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-74" x="1839" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="2201" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-43" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-3D" x="3724" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-70" x="5031" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="5534" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6E" x="6020" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-74" x="6620" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="6982" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-41" x="7467" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-42" x="8218" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-2B" x="9199" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-41" x="10200" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-70" x="11201" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="11704" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6E" x="12190" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-74" x="12790" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="13152" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-42" x="13637" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class="MJX-TeXAtom-ORD"><mi>C</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class="MJX-TeXAtom-ORD"><mi>A</mi></mrow><mi>B</mi><mo>+</mo><mi>A</mi><mtext>&nbsp;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class="MJX-TeXAtom-ORD"><mi>B</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ ponto {C} = \ ponto {A} B + A \ ponto {B} </script>  para o modo direto e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>A</mi><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mi>r</mi><mi>a</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>C</mi></mrow><msup><mi>B</mi><mi>T</mi></msup><mo>,</mo><mi>B</mi><mo>=</mo><msup><mi>A</mi><mi>T</mi></msup><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mi>r</mi><mi>a</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>C</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="32.827ex" height="2.78ex" viewBox="0 -935.7 14133.6 1197.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-41" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-3D" x="1028" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-62" x="2334" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-61" x="2764" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-72" x="3293" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-72" x="3745" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-61" x="4196" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-43" x="4726" y="0"></use><g transform="translate(5486,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-42" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-54" x="1074" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-2C" x="6844" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-42" x="7289" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-3D" x="8326" y="0"></use><g transform="translate(9382,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-41" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-54" x="1061" y="513"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-62" x="10981" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-61" x="11411" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-72" x="11940" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-72" x="12392" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-61" x="12843" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-43" x="13373" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>A</mi><mo>=</mo><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mi>r</mi><mi>a</mi><mrow class="MJX-TeXAtom-ORD"><mi>C</mi></mrow><msup><mi>B</mi><mi>T</mi></msup><mo>,</mo><mi>B</mi><mo>=</mo><msup><mi>A</mi><mi>T</mi></msup><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mi>r</mi><mi>a</mi><mrow class="MJX-TeXAtom-ORD"><mi>C</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-2"> A = \ barra {C} B ^ T, B = A ^ T \ barra {C} </script>  pelo contr√°rio.  Para executar corretamente a multiplica√ß√£o, √© necess√°rio observar rigorosamente a ordem e o uso da hifeniza√ß√£o.  Do ponto de vista da grava√ß√£o, isso parece confuso para uma pessoa envolvida no MO, mas do ponto de vista dos c√°lculos, essa √© uma carga extra para o programa. <br><br>  Outro exemplo, menos trivial: c = det (A).  N√≥s temos <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi></mrow><mo>=</mo><mi>t</mi><mi>r</mi><mo stretchy=&quot;false&quot;>(</mo><mi>i</mi><mi>n</mi><mi>v</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>A</mi></mrow><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="28.902ex" height="2.66ex" viewBox="0 -832 12444.1 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-70" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="753" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6E" x="1239" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-74" x="1839" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="2201" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-63" x="2686" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-3D" x="3397" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-74" x="4454" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-72" x="4815" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-28" x="5267" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-69" x="5656" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6E" x="6002" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-76" x="6602" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-28" x="7088" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-41" x="7477" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-29" x="8228" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-70" x="8867" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="9371" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6E" x="9856" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-74" x="10457" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6F" x="10818" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-41" x="11304" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-29" x="12054" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi></mrow><mo>=</mo><mi>t</mi><mi>r</mi><mo stretchy="false">(</mo><mi>i</mi><mi>n</mi><mi>v</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>p</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>o</mi><mrow class="MJX-TeXAtom-ORD"><mi>A</mi></mrow><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-3"> \ ponto {c} = tr (inv (A) \ ponto {A}) </script>  para o modo direto e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>A</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>c</mi></mrow><mi>c</mi><mi>i</mi><mi>n</mi><mi>v</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><msup><mo stretchy=&quot;false&quot;>)</mo><mi>T</mi></msup></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.835ex" height="2.901ex" viewBox="0 -935.7 9831.7 1249" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-72" x="1209" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-41" x="1660" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-3D" x="2688" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-62" x="3995" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-61" x="4424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-72" x="4954" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-63" x="5405" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-63" x="5839" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-69" x="6272" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-6E" x="6618" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-76" x="7218" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-28" x="7704" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-41" x="8093" y="0"></use><g transform="translate(8844,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMAIN-29" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/444172/&amp;usg=ALkJrhj0K3Fyj-4PrIefxN0zInaG4OC_bw#MJMATHI-54" x="550" y="513"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>A</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>c</mi></mrow><mi>c</mi><mi>i</mi><mi>n</mi><mi>v</mi><mo stretchy="false">(</mo><mi>A</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup></math></span></span><script type="math/tex" id="MathJax-Element-4"> \ bar {A} = \ bar {c} cinv (A) ^ T </script>  pelo contr√°rio.  Nesse caso, √© obviamente imposs√≠vel usar a √°rvore de express√£o para os dois modos, uma vez que eles consistem em operadores diferentes. <br><br>  Em geral, a maneira como o TensorFlow e outras bibliotecas (por exemplo, Mathematica, Maple, Sage, SimPy, ADOL-C, TAPENADE, TensorFlow, Theano, PyTorch, HIPS autograd) implementaram diferencia√ß√£o autom√°tica, o que leva ao fato de que, direta e reversa √Årvores de express√£o diferentes e ineficazes s√£o constru√≠das no modo.  A numera√ß√£o do tensor contorna esses problemas devido √† comutatividade da multiplica√ß√£o devido √† nota√ß√£o do √≠ndice.  Para detalhes sobre como isso funciona, consulte o artigo cient√≠fico. <br><br>  Os autores testaram seu m√©todo realizando diferencia√ß√£o autom√°tica do regime reverso, tamb√©m conhecido como propaga√ß√£o reversa, em tr√™s tarefas diferentes e mediram o tempo necess√°rio para calcular os hessianos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/923/263/331/923263331347f83e3bac0fe7a9477e8b.png"><br><br>  No primeiro problema, a fun√ß√£o quadr√°tica x <sup>T</sup> Ax foi otimizada.  No segundo, a regress√£o log√≠stica foi calculada, na fatora√ß√£o da terceira matriz. <br><br>  Na CPU, seu m√©todo acabou sendo duas ordens de magnitude mais r√°pido do que bibliotecas populares como TensorFlow, Theano, PyTorch e HIPS autograd. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/184/395/7dd/1843957dde52a4722da309adcdd6ea92.png"><br><br>  Na GPU, eles observaram uma acelera√ß√£o ainda maior, em at√© tr√™s ordens de magnitude. <br><br>  <b>As consequ√™ncias:</b> <br><br>  Computar derivadas para fun√ß√µes de segunda ordem ou superior usando as bibliotecas atuais de aprendizado profundo √© muito caro do ponto de vista computacional.  Isso inclui o c√°lculo de tensores gerais de quarta ordem, como Hessians (por exemplo, na MAML e na otimiza√ß√£o de segunda ordem de Newton).  Felizmente, as f√≥rmulas quadr√°ticas s√£o raras no aprendizado profundo.  No entanto, eles s√£o freq√ºentemente encontrados no aprendizado de m√°quina ‚Äúcl√°ssico‚Äù - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SVM</a> , m√©todo dos m√≠nimos quadrados, LASSO, processos gaussianos etc. <br><br><h2>  Mito 2: Os bancos de dados de imagens refletem fotos do mundo real </h2><br>  Muitas pessoas gostam de pensar que as redes neurais aprenderam a reconhecer objetos melhor do que as pessoas.  Isto n√£o √© verdade.  Eles podem estar √† frente das pessoas com base em imagens selecionadas, por exemplo, ImageNet, mas no caso de reconhecimento de objetos de fotos reais da vida comum, eles definitivamente n√£o ser√£o capazes de ultrapassar um adulto comum.  Isso ocorre porque a sele√ß√£o de imagens nos conjuntos de dados atuais n√£o coincide com a sele√ß√£o de todas as imagens poss√≠veis naturalmente encontradas na realidade. <br><br>  Em um trabalho bastante antigo, N√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Verificado, Vi√©s no Vi√©s do Conjunto de Dados.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Torralba e Efros.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CVPR 2011.</a> , Os autores propuseram estudar as distor√ß√µes associadas a um conjunto de imagens em doze bancos de dados populares, descobrindo se √© poss√≠vel treinar o classificador para determinar o conjunto de dados do qual essa imagem foi obtida. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/400/31a/f1a/40031af1a6a5bef3c9314ecb2373926a.png"><br><br>  As chances de adivinhar acidentalmente o conjunto de dados correto s√£o de 1/12 ¬± 8%, enquanto os pr√≥prios cientistas lidaram com a tarefa com uma taxa de sucesso&gt; 75%. <br><br>  Eles treinaram o SVM em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">histograma de gradiente direcional</a> (HOG) e descobriram que o classificador concluiu a tarefa em 39% dos casos, o que excede significativamente os acertos aleat√≥rios.  Se repet√≠ssemos esse experimento hoje, com as redes neurais mais avan√ßadas, certamente ver√≠amos um aumento na precis√£o do classificador. <br><br>  Se os bancos de dados de imagens exibissem corretamente as imagens reais do mundo real, n√£o precisar√≠amos determinar de qual conjunto de dados uma determinada imagem √© originada. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/879/7f7/4ad/8797f74ad14a0a4e28959ff0c67faca8.png"><br><br>  No entanto, existem caracter√≠sticas nos dados que tornam cada conjunto de imagens diferente dos outros.  O ImageNet possui muitos carros de corrida com pouca probabilidade de descrever o carro m√©dio "te√≥rico" como um todo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/614/416/401/6144164018d5608bc5c2dc55e6e981f6.png"><br><br>  Os autores tamb√©m determinaram o valor de cada conjunto de dados medindo o qu√£o bem um classificador treinado em um conjunto trabalha com imagens de outros conjuntos.  De acordo com essa m√©trica, os bancos de dados LabelMe e ImageNet foram os menos tendenciosos, tendo recebido uma classifica√ß√£o de 0,58 usando o m√©todo de ‚Äúcesta de moedas‚Äù.  Todos os valores acabaram sendo inferiores √† unidade, o que significa que o treinamento em um conjunto de dados diferente sempre leva a um desempenho ruim.  Em um mundo ideal sem conjuntos tendenciosos, alguns n√∫meros deveriam ter excedido um. <br><br>  Os autores conclu√≠ram pessimista: <br><blockquote>  Ent√£o, qual √© o valor dos conjuntos de dados existentes para algoritmos de treinamento projetados para o mundo real?  A resposta resultante pode ser descrita como "melhor que nada, mas n√£o muito". </blockquote><br><br><h2>  Mito 3: Pesquisadores do MO n√£o usam kits de teste para testar </h2><br>  No livro de aprendizado de m√°quina, somos ensinados a dividir o conjunto de dados em treinamento, avalia√ß√£o e verifica√ß√£o.  A efic√°cia do modelo, treinada no conjunto de treinamento e avaliada na avalia√ß√£o, ajuda a pessoa envolvida no MO a ajustar o modelo para maximizar a efici√™ncia em seu uso real.  O conjunto de testes n√£o precisa ser tocado at√© que a pessoa termine o ajuste para fornecer uma avalia√ß√£o imparcial da real efic√°cia do modelo no mundo real.  Se uma pessoa trapaceia usando um conjunto de testes nos est√°gios de treinamento ou avalia√ß√£o, o modelo corre o risco de se tornar muito adaptado para um conjunto de dados espec√≠fico. <br><br>  No mundo hipercompetitivo da pesquisa em MO, novos algoritmos e modelos s√£o frequentemente julgados pela efic√°cia de seu trabalho com dados de verifica√ß√£o.  Portanto, n√£o faz sentido para os pesquisadores escrever ou publicar trabalhos descrevendo m√©todos que funcionam mal com conjuntos de dados de teste.  E isso, em ess√™ncia, significa que a comunidade da regi√£o de Moscou como um todo usa um conjunto de testes para avalia√ß√£o. <br><br>  Quais s√£o as consequ√™ncias desse golpe? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d4/f64/749/2d4f647491071cd0b77eb199ef563275.png"><br><br>  Autores dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Classificadores CIFAR-10 generalizam para CIFAR-10?</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Recht et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O ArXiv 2018</a> investigou esse problema criando um novo conjunto de testes para o CIFAR-10.  Para fazer isso, eles fizeram uma sele√ß√£o de imagens da Tiny Images. <br><br>  Eles escolheram o CIFAR-10 porque √© um dos conjuntos de dados mais usados ‚Äã‚Äãno MO, o segundo conjunto mais popular no NeurIPS 2017 (depois do MNIST).  O processo de cria√ß√£o de um conjunto de dados para o CIFAR-10 tamb√©m √© bem descrito e transparente; no grande banco de dados da Tiny Images existem muitos r√≥tulos detalhados, para que voc√™ possa executar um novo conjunto de testes, minimizando a mudan√ßa de distribui√ß√£o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/71a/cd9/091/71acd909148795f73b49819b39946a5a.png"><br><br>  Eles descobriram que um grande n√∫mero de modelos diferentes de redes neurais no novo conjunto de testes mostrou uma queda significativa na precis√£o (4% - 15%).  No entanto, a classifica√ß√£o de desempenho relativo de cada modelo permaneceu bastante est√°vel. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b6b/5aa/cfa/b6b5aacfab0c2628ea2ffe28babae533.png"><br><br>  Em geral, os modelos com melhor desempenho mostraram uma queda de precis√£o mais baixa em compara√ß√£o aos modelos com pior desempenho.  Isso √© bom porque segue-se que a perda de generaliza√ß√£o do modelo devido a trapa√ßa, pelo menos no caso do CIFAR-10, diminui √† medida que a comunidade inventa m√©todos e modelos aprimorados de MO. <br><br><h2>  Mito 4: O treinamento em rede neural usa toda a entrada </h2><br>  √â geralmente aceito que os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dados s√£o um novo √≥leo</a> e, quanto mais dados tivermos, melhor poderemos treinar modelos de aprendizado profundo que agora s√£o ineficientes em termos de amostra e superparametrizados. <br><br>  Em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um estudo emp√≠rico de exemplo de esquecimento durante o aprendizado em rede neural profunda.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Toneva et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Os</a> autores do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ICLR 2019</a> demonstram redund√¢ncia significativa em v√°rios conjuntos comuns de pequenas imagens.  Surpreendentemente, 30% dos dados do CIFAR-10 podem ser simplesmente removidos sem alterar a precis√£o da verifica√ß√£o em uma quantidade significativa. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/418/39b/03a/41839b03afd94771e940b60e2d7f905d.png"><br>  <i>Hist√≥rias de esquecimento do MNIST (da esquerda para a direita), permutadas pelo NIST e pelo CIFAR-10.</i> <br><br>  O esquecimento acontece quando uma rede neural classifica incorretamente uma imagem no tempo t + 1, enquanto no tempo t foi capaz de classificar uma imagem corretamente.  O fluxo de tempo √© medido pelas atualiza√ß√µes do SGD.  Para rastrear o esquecimento, os autores lan√ßaram sua rede neural em um pequeno conjunto de dados ap√≥s cada atualiza√ß√£o do SGD, e n√£o em todos os exemplos dispon√≠veis no banco de dados.  Exemplos que n√£o est√£o sujeitos a esquecimento s√£o chamados de exemplos inesquec√≠veis. <br><br>  Eles descobriram que 91,7% MNIST, 75,3% permutaram MIST, 31,3% CIFAR-10 e 7,62% CIFAR-100 s√£o exemplos inesquec√≠veis.  Isso √© intuitivamente compreens√≠vel, pois aumentar a diversidade e a complexidade do conjunto de dados deve fazer a rede neural esquecer mais exemplos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fdb/16b/ff9/fdb16bff98521d9d764588a679e51a59.png"><br><br>  Exemplos esquecidos parecem exibir caracter√≠sticas mais raras e estranhas em compara√ß√£o com os inesquec√≠veis.  Os autores os comparam com vetores de suporte no SVM, pois parecem tra√ßar o contorno dos limites da decis√£o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a75/c74/969/a75c74969991b75f621d340952a5cde3.png"><br><br>  Exemplos inesquec√≠veis, por sua vez, codificam informa√ß√µes principalmente redundantes.  Se ordenarmos os exemplos pelo grau de inesquecibilidade, podemos compactar o conjunto de dados excluindo os mais inesquec√≠veis. <br><br>  30% dos dados do CIFAR-10 podem ser exclu√≠dos sem afetar a precis√£o das verifica√ß√µes, e a exclus√£o de 35% dos dados leva a uma leve queda na precis√£o das verifica√ß√µes em 0,2%.  Se voc√™ selecionar 30% dos dados aleatoriamente, exclu√≠-los resultar√° em uma perda significativa na precis√£o da verifica√ß√£o de 1%. <br><br>  Da mesma forma, 8% dos dados podem ser removidos do CIFAR-100 sem uma queda na precis√£o da valida√ß√£o. <br><br>  Esses resultados mostram que h√° redund√¢ncia significativa nos dados para o treinamento de redes neurais, semelhante ao treinamento SVM, em que vetores n√£o suportados podem ser removidos sem afetar a decis√£o do modelo. <br><br>  <b>As consequ√™ncias:</b> <br><br>  Se pudermos determinar quais dados s√£o inesquec√≠veis antes de iniciar o treinamento, podemos economizar espa√ßo excluindo-os e tempo sem us√°-los ao treinar uma rede neural. <br><br><h2>  Mito 5: A normaliza√ß√£o de lotes √© necess√°ria para treinar redes residuais muito profundas. </h2><br>  Por um longo tempo, acreditava-se que ‚Äútreinar uma rede neural profunda para otimiza√ß√£o direta apenas para um prop√≥sito controlado (por exemplo, a probabilidade logar√≠tmica de uma classifica√ß√£o correta) usando descida gradiente, come√ßando com par√¢metros aleat√≥rios, n√£o funciona bem‚Äù. <br><br>  A pilha de m√©todos engenhosos de inicializa√ß√£o aleat√≥ria, fun√ß√µes de ativa√ß√£o, t√©cnicas de otimiza√ß√£o e outras inova√ß√µes, como conex√µes residuais, que surgiram desde ent√£o, facilitaram o treinamento de redes neurais profundas usando o m√©todo de descida gradiente. <br><br>  Mas um verdadeiro avan√ßo ocorreu ap√≥s a introdu√ß√£o da normaliza√ß√£o de lotes (e outras t√©cnicas de normaliza√ß√£o seq√ºencial), limitando o tamanho das ativa√ß√µes para cada camada da rede, a fim de eliminar o problema de gradientes de desaparecimento e explosivos. <br><br>  Em um trabalho recente, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Inicializa√ß√£o do Fixup: aprendizado residual sem normaliza√ß√£o.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zhang et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O ICLR 2019</a> mostrou que √© poss√≠vel treinar uma rede com 10.000 camadas usando SGD puro sem aplicar nenhuma normaliza√ß√£o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d69/a29/cbb/d69a29cbb7bfce9750c9aa3ee6d7d659.png"><br><br>  Os autores compararam o treinamento de rede neural residual para diferentes profundidades no CIFAR-10 e descobriram que, embora os m√©todos padr√£o de inicializa√ß√£o n√£o funcionassem para 100 camadas, os m√©todos de normaliza√ß√£o de corre√ß√£o e lote tiveram sucesso com 10.000 camadas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bc9/23f/26a/bc923f26a4c39fb67663383716bc10d2.png" alt="imagem"><br><br>  Eles realizaram uma an√°lise te√≥rica e mostraram que ‚Äúa normaliza√ß√£o do gradiente de certas camadas √© limitada pelo n√∫mero infinitamente crescente de uma rede profunda‚Äù, o que √© um problema de gradientes explosivos.  Para evitar isso, o Foxup √© usado, cuja ideia principal √© dimensionar os pesos em camadas m para cada um dos ramos residuais L pelo n√∫mero de vezes que depende de me L. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/07f/a8f/39a/07fa8f39ad814861fd0cba6c936a2e18.png"><br><br>  O Fixup ajudou a treinar uma rede residual profunda com 110 camadas no CIFAR-10, com uma alta velocidade de aprendizado compar√°vel ao comportamento de uma rede de arquitetura semelhante treinada usando a normaliza√ß√£o de lotes. <br><br>  Os autores mostraram ainda resultados de testes semelhantes usando o Fixup na rede sem normaliza√ß√£o, trabalhando com o banco de dados ImageNet e com tradu√ß√µes do ingl√™s para o alem√£o. <br><br><h2>  Mito 6: Redes com aten√ß√£o s√£o melhores que redes convolucionais. </h2><br>  A ideia de que os mecanismos de ‚Äúaten√ß√£o‚Äù s√£o superiores √†s redes neurais convolucionais est√° ganhando popularidade na comunidade de pesquisadores do MO.  No trabalho de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://crazyoscarchang.github.io/2019/02/16/seven-myths-in-machine-learning-research/(">Vaswani e colegas</a> , observou-se que "o custo computacional de convolu√ß√µes destac√°veis ‚Äã‚Äã√© igual √† combina√ß√£o de uma camada de auto-aten√ß√£o e uma camada pontual de feed-forward". <br><br>  Mesmo redes avan√ßadas de gera√ß√£o competitiva mostram a vantagem da aten√ß√£o pr√≥pria em rela√ß√£o √† convolu√ß√£o padr√£o ao modelar depend√™ncias de longo alcance. <br><br>  Os colaboradores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">prestam menos aten√ß√£o nas convolu√ß√µes leves e din√¢micas.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wu et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O ICLR 2019</a> lan√ßa d√∫vidas sobre a efici√™ncia param√©trica e a efic√°cia da aten√ß√£o pessoal ao modelar depend√™ncias de longo alcance e oferece novas op√ß√µes de convolu√ß√£o, parcialmente inspiradas na aten√ß√£o pessoal, mais eficazes em termos de par√¢metros. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b40/f9a/a15/b40f9aa151eb4bcc3ebf224483ff8028.png"><br><br>  As convolu√ß√µes ‚Äúleves‚Äù s√£o separ√°veis ‚Äã‚Äãem profundidade, normalizadas softmax na dimens√£o temporal, separadas pelo peso na dimens√£o do canal e reutilizam os mesmos pesos a cada etapa do tempo (como redes neurais recorrentes).  As convolu√ß√µes din√¢micas s√£o convolu√ß√µes leves que usam pesos diferentes a cada etapa do tempo. <br><br>  Esses truques tornam as convolu√ß√µes leves e din√¢micas v√°rias ordens de magnitude mais efetivas que as convolu√ß√µes indivis√≠veis padr√£o. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/87d/d51/da0/87dd51da07637c42c4e4c2811b08b241.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c6a/469/ae5/c6a469ae5432cf31761e7663449497fd.png"><br><br>  Os autores mostram que essas novas convolu√ß√µes correspondem ou excedem redes auto-absorventes em tradu√ß√£o autom√°tica, modelagem de linguagem, problemas abstratos de soma, usando os mesmos ou menos par√¢metros. <br><br><h2>  Mito 7: Cart√µes de significado - uma maneira confi√°vel de interpretar redes neurais </h2><br>  Embora exista uma opini√£o de que as redes neurais s√£o caixas pretas, houve muitas tentativas para interpret√°-las.  Os mais populares s√£o mapas de signific√¢ncia ou outros m√©todos semelhantes que atribuem avalia√ß√µes de import√¢ncia a caracter√≠sticas ou exemplos de treinamento. <br><br>  √â tentador concluir que uma determinada imagem foi classificada de uma certa maneira devido a certas partes da imagem que s√£o significativas para a rede neural.  Para calcular mapas de signific√¢ncia, existem v√°rios m√©todos que costumam usar a ativa√ß√£o de redes neurais em uma determinada imagem e os gradientes que passam pela rede. <br><br>  Na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">interpreta√ß√£o de redes neurais √© fr√°gil.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ghorbani et al.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Os</a> autores da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AAAI 2019</a> mostram que podem introduzir uma mudan√ßa ilus√≥ria na imagem, o que, no entanto, distorcer√° seu mapa de signific√¢ncia. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/077/b89/e92/077b89e923e2936769b2f99662171a94.png"><br><br>  A rede neural determina a borboleta monarca n√£o pelo padr√£o em suas asas, mas por causa da presen√ßa de folhas verdes sem import√¢ncia no fundo da foto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1d2/314/9fa/1d23149fa91caab32dc2ea16a8593379.png"><br><br>  Imagens multidimensionais costumam estar mais pr√≥ximas dos limites de decis√£o feitos por redes neurais profundas, da√≠ a sua sensibilidade a ataques adversos.  E se os ataques competitivos movem as imagens al√©m dos limites da solu√ß√£o, os ataques interpretativos competitivos os deslocam ao longo dos limites da solu√ß√£o sem sair do territ√≥rio da mesma solu√ß√£o. <br><br>  O m√©todo b√°sico desenvolvido pelos autores √© uma modifica√ß√£o do m√©todo Goodfello de marca√ß√£o r√°pida por gradiente, que foi um dos primeiros m√©todos bem-sucedidos de ataques competitivos.  Pode-se supor que outros ataques novos e mais complexos tamb√©m possam ser usados ‚Äã‚Äãpara ataques √† interpreta√ß√£o de redes neurais. <br><br>  <b>As consequ√™ncias:</b> <br><br>  Devido √† crescente dissemina√ß√£o do aprendizado profundo em √°reas cr√≠ticas de aplica√ß√£o como a imagem m√©dica, √© importante abordar cuidadosamente a interpreta√ß√£o das decis√µes tomadas pelas redes neurais.  Por exemplo, embora fosse √≥timo se a rede neural convolucional pudesse reconhecer o ponto na imagem da RM como um tumor maligno, esses resultados n√£o devem ser confi√°veis ‚Äã‚Äãse forem baseados em m√©todos de interpreta√ß√£o n√£o confi√°veis. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt444172/">https://habr.com/ru/post/pt444172/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt444160/index.html">[Habr]: Sobre o "teto de vidro"</a></li>
<li><a href="../pt444162/index.html">Revis√£o do telefone IP Snom D120</a></li>
<li><a href="../pt444164/index.html">Vis√£o geral do sistema de aviso Snom PA1</a></li>
<li><a href="../pt444166/index.html">Pavel Finkelstein sobre Kotlin em produ√ß√£o em jug.msk.ru</a></li>
<li><a href="../pt444168/index.html">Como transferir o Windows 10 licenciado para outro computador</a></li>
<li><a href="../pt444174/index.html">GeekBrains convida iniciantes para um jogo educativo</a></li>
<li><a href="../pt444176/index.html">Cifras elementares em linguagem simples</a></li>
<li><a href="../pt444178/index.html">9 dicas para criar jogos independentes a partir de um √∫nico desenvolvedor</a></li>
<li><a href="../pt444182/index.html">Ir condi√ß√µes e suas esquisitices</a></li>
<li><a href="../pt444184/index.html">Sobre as perspectivas de data centers pr√©-montados</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
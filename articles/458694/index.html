<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåî üßîüèº üåü ¬øPython GIL est√° realmente muerto? üë©üèΩ‚Äçüè≠ ‚òîÔ∏è üë∑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos! El pr√≥ximo lunes, las clases comenzar√°n en el nuevo grupo del curso Python Developer , lo que significa que tenemos tiempo para publicar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øPython GIL est√° realmente muerto?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/458694/">  Hola a todos!  El pr√≥ximo lunes, las clases comenzar√°n en el nuevo grupo del curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Python Developer</a> , lo que significa que tenemos tiempo para publicar otro material interesante, que haremos ahora.  Que tengas una buena lectura. <br><br><img src="https://habrastorage.org/webt/jb/cq/wj/jbcqwjrmctxos6x_uzhptngfd9y.png"><br><br>  En 2003, Intel lanz√≥ el nuevo procesador Pentium 4 "HT".  Este procesador overclocke√≥ a 3GHz y soport√≥ tecnolog√≠a hyper-threading. <a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/9d/z1/es/9dz1esccmgms80liftaeolcqiui.jpeg"><br><br>  En los a√±os siguientes, Intel y AMD lucharon por lograr el mejor rendimiento de escritorio al aumentar la velocidad del bus, el tama√±o de cach√© L2 y reducir el tama√±o de la matriz para minimizar la latencia.  En 2004, el modelo HT con una frecuencia de 3 GHz fue reemplazado por el modelo 580 Prescott con overclocking a 4 GHz. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AmwzUrL3vMc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Parec√≠a que para avanzar solo era necesario aumentar la frecuencia del reloj, sin embargo, los nuevos procesadores sufrieron un alto consumo de energ√≠a y disipaci√≥n de calor. <br><br>  ¬øSu procesador de escritorio entrega 4 GHz hoy?  Es poco probable, ya que el camino para mejorar el rendimiento finalmente radica en aumentar la velocidad del bus y aumentar el n√∫mero de n√∫cleos.  En 2006, Intel Core 2 reemplaz√≥ al Pentium 4 y ten√≠a una velocidad de reloj mucho menor. <br><br>  Adem√°s de lanzar procesadores multi-core para una amplia audiencia de usuarios, algo m√°s sucedi√≥ en 2006.  ¬°Python 2.5 finalmente vio la luz!  Ya viene con una versi√≥n beta de la palabra clave with, que todos ustedes conocen y aman. <br><br>  Python 2.5 ten√≠a una limitaci√≥n importante cuando se trataba de usar Intel Core 2 o AMD Athlon X2. <br>  Fue un GIL. <br><br><h2>  ¬øQu√© es un GIL? </h2><br>  GIL (Global Interpreter Lock) es un valor booleano en el int√©rprete de Python protegido por un mutex.  El bloqueo se usa en el bucle de c√°lculo del c√≥digo de bytes CPython principal para determinar qu√© hilo est√° ejecutando actualmente las instrucciones. <br><br>  CPython admite el uso de varios subprocesos en un solo int√©rprete, pero los subprocesos deben solicitar acceso al GIL para realizar operaciones de bajo nivel.  A su vez, esto significa que los desarrolladores de Python pueden usar c√≥digo asincr√≥nico, subprocesos m√∫ltiples y ya no tienen que preocuparse por bloquear ninguna variable o bloqueos en el nivel del procesador durante los puntos muertos. <br><br>  GIL simplifica la programaci√≥n multiproceso de Python. <br><br><img src="https://habrastorage.org/webt/lg/yz/3h/lgyz3hoq07fkumzp4axuuiqxplk.gif"><br><br>  GIL tambi√©n nos dice que si bien CPython puede ser multiproceso, solo se puede ejecutar un subproceso a la vez.  Esto significa que su procesador de cuatro n√∫cleos hace algo como esto (con la excepci√≥n de la pantalla azul, con suerte). <br><br>  La versi√≥n actual de GIL <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se escribi√≥ en 2009</a> para admitir funciones asincr√≥nicas y permaneci√≥ intacta incluso despu√©s de muchos intentos de eliminarla en principio o cambiar los requisitos para ello. <br><br>  Cualquier sugerencia para eliminar el GIL estaba justificada por el hecho de que el bloqueo global del int√©rprete no deber√≠a degradar el rendimiento del c√≥digo de subproceso √∫nico.  Cualquiera que haya intentado habilitar hyperthreading en 2003 entender√° de lo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">que estoy hablando</a> . <br><br><h2>  Gil abandono en CPython </h2><br>  Si realmente quiere paralelizar el c√≥digo en CPython, deber√° usar varios procesos. <br><br>  En CPython 2.6, el m√≥dulo de <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">multiprocesamiento</a></i> se agreg√≥ a la biblioteca est√°ndar.  El multiprocesamiento enmascara la generaci√≥n de procesos en CPython (cada proceso con su propio GIL). <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> multiprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Process <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'hello'</span></span>, name <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: p = Process(target=f, args=(<span class="hljs-string"><span class="hljs-string">'bob'</span></span>,)) p.start() p.join()</code> </pre> <br><br>  Se crean procesos, se les env√≠an comandos mediante m√≥dulos compilados y funciones de Python, y luego se vuelven a unir al proceso principal. <br><br>  El multiprocesamiento tambi√©n admite el uso de variables a trav√©s de una cola o canal.  Ella tiene un objeto de bloqueo, que se utiliza para bloquear objetos en el proceso principal y escribir desde otros procesos. <br><br>  El multiprocesamiento tiene un gran inconveniente.  Lleva una carga computacional significativa, que afecta tanto el tiempo de procesamiento como el uso de la memoria.  El tiempo de inicio de CPython, incluso sin ning√∫n sitio, es de 100-200 ms (consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://hackernoon.com/which-is-the-fastest-version-of-python-2ae7c61a6b2b</a> para obtener m√°s informaci√≥n). <br><br>  Como resultado, puede tener c√≥digo paralelo en CPython, pero a√∫n necesita planificar cuidadosamente el trabajo de los procesos de larga duraci√≥n que comparten varios objetos. <br><br>  Otra alternativa puede ser usar un paquete de terceros como Twisted. <br><br><h2>  PEP554 y la muerte de GIL? </h2><br>  Entonces, perm√≠tanme recordarles que el subprocesamiento m√∫ltiple en CPython es simple, pero en realidad no es paralelizaci√≥n, sino que el multiprocesamiento es paralelo, pero conlleva una sobrecarga significativa. <br><br>  <i>¬øQu√© pasa si hay una mejor manera?</i> <br>  La clave para evitar el GIL reside en el nombre, el bloqueo global del int√©rprete es parte del estado global del int√©rprete.  Los procesos de CPython pueden tener varios int√©rpretes y, por lo tanto, varios bloqueos, sin embargo, esta funci√≥n rara vez se usa, ya que el acceso a ella solo se realiza a trav√©s de la C-API. <br><br>  Una de las caracter√≠sticas de CPython 3.8 es PEP554, una implementaci√≥n de subinterpretadores y API con un nuevo m√≥dulo de <code>interpreters</code> en la biblioteca est√°ndar. <br><br>  Esto le permite crear m√∫ltiples int√©rpretes desde Python en un solo proceso.  Otra innovaci√≥n de Python 3.8 es que todos los int√©rpretes tendr√°n su propio GIL. <br><br><img src="https://habrastorage.org/webt/bq/nc/m2/bqncm29jhm-ytakgrlkasbfe_6y.png"><br><br>  Dado que el estado del int√©rprete contiene una regi√≥n asignada en la memoria, una colecci√≥n de todos los punteros a objetos Python (locales y globales), los subinterpretadores en PEP554 no pueden acceder a las variables globales de otros int√©rpretes. <br><br>  Al igual que el multiprocesamiento, los int√©rpretes que comparten objetos consisten en serializarlos y usar el formulario IPC (red, disco o memoria compartida).  Hay muchas formas de serializar objetos en Python, por ejemplo, el m√≥dulo <code>marshal</code> , el m√≥dulo de <code>pickle</code> o m√©todos m√°s estandarizados como <code>json</code> o <code>simplexml</code> .  Cada uno de ellos tiene sus pros y sus contras, y todos dan una carga inform√°tica. <br><br>  Ser√≠a mejor tener un espacio de memoria com√∫n que se pueda cambiar y controlar mediante un proceso espec√≠fico.  Por lo tanto, los objetos pueden ser enviados por el int√©rprete principal y recibidos por otro int√©rprete.  Este ser√° el espacio de memoria administrado para buscar punteros de PyObject, al que puede acceder cualquier int√©rprete, mientras que el proceso principal administrar√° los bloqueos. <br><br><img src="https://habrastorage.org/webt/be/ww/d8/bewwd8ju-3akmyhs7ujq7xmyliy.png"><br><br>  Todav√≠a se est√° desarrollando una API para esto, pero probablemente se ver√° m√°s o menos as√≠: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> _xxsubinterpreters <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> interpreters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> threading <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> textwrap <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> marshal <span class="hljs-comment"><span class="hljs-comment"># Create a sub-interpreter interpid = interpreters.create() # If you had a function that generated some data arry = list(range(0,100)) # Create a channel channel_id = interpreters.channel_create() # Pre-populate the interpreter with a module interpreters.run_string(interpid, "import marshal; import _xxsubinterpreters as interpreters") # Define a def run(interpid, channel_id): interpreters.run_string(interpid, tw.dedent(""" arry_raw = interpreters.channel_recv(channel_id) arry = marshal.loads(arry_raw) result = [1,2,3,4,5] # where you would do some calculating result_raw = marshal.dumps(result) interpreters.channel_send(channel_id, result_raw) """), shared=dict( channel_id=channel_id ), ) inp = marshal.dumps(arry) interpreters.channel_send(channel_id, inp) # Run inside a thread t = threading.Thread(target=run, args=(interpid, channel_id)) t.start() # Sub interpreter will process. Feel free to do anything else now. output = interpreters.channel_recv(channel_id) interpreters.channel_release(channel_id) output_arry = marshal.loads(output) print(output_arry)</span></span></code> </pre> <br><br>  Este ejemplo usa NumPy.  La matriz numpy se env√≠a a trav√©s del canal, se serializa utilizando el m√≥dulo <code>marshal</code> , luego el subinterpretador procesa los datos (en un GIL separado), por lo que puede haber un problema de paralelizaci√≥n asociado con la CPU, que es ideal para los subinterpretadores. <br><br><h4>  <b>Se ve ineficiente</b> </h4><br>  El m√≥dulo <code>marshal</code> funciona realmente r√°pido, pero no tan r√°pido como compartir objetos directamente desde la memoria. <br><br>  PEP574 presenta un nuevo protocolo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pickle (v5)</a> que admite la capacidad de procesar buffers de memoria por separado del resto de la secuencia de pickle.  Para objetos de datos grandes, serializarlos todos de una vez y deserializarlos desde un subinterpretador agregar√° una gran cantidad de sobrecarga. <br><br>  La nueva API se puede implementar (puramente hipot√©ticamente) de la siguiente manera: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> _xxsubinterpreters <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> interpreters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> threading <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> textwrap <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-comment"><span class="hljs-comment"># Create a sub-interpreter interpid = interpreters.create() # If you had a function that generated a numpy array arry = [5,4,3,2,1] # Create a channel channel_id = interpreters.channel_create() # Pre-populate the interpreter with a module interpreters.run_string(interpid, "import pickle; import _xxsubinterpreters as interpreters") buffers=[] # Define a def run(interpid, channel_id): interpreters.run_string(interpid, tw.dedent(""" arry_raw = interpreters.channel_recv(channel_id) arry = pickle.loads(arry_raw) print(f"Got: {arry}") result = arry[::-1] result_raw = pickle.dumps(result, protocol=5) interpreters.channel_send(channel_id, result_raw) """), shared=dict( channel_id=channel_id, ), ) input = pickle.dumps(arry, protocol=5, buffer_callback=buffers.append) interpreters.channel_send(channel_id, input) # Run inside a thread t = threading.Thread(target=run, args=(interpid, channel_id)) t.start() # Sub interpreter will process. Feel free to do anything else now. output = interpreters.channel_recv(channel_id) interpreters.channel_release(channel_id) output_arry = pickle.loads(output) print(f"Got back: {output_arry}")</span></span></code> </pre> <br><h4>  <b>Se ve estampado</b> </h4><br>  En esencia, este ejemplo se basa en el uso de la API de subinterpretadores de bajo nivel.  Si no ha utilizado la biblioteca de <code>multiprocessing</code> , algunos problemas le resultar√°n familiares.  No es tan simple como el procesamiento de flujo, no puede simplemente, por ejemplo, ejecutar esta funci√≥n con dicha lista de datos de entrada en int√©rpretes separados (por ahora). <br><br>  Tan pronto como este PEP se fusione con otros, creo que veremos varias API nuevas en PyPi. <br><br><h3>  ¬øCu√°nta sobrecarga tiene el subinterpretador? </h3><br>  <b>Respuesta corta:</b> m√°s que una secuencia, menos que un proceso. <br>  <b>Respuesta larga: el</b> int√©rprete tiene su propio estado, por lo que deber√° clonar e inicializar lo siguiente, a pesar de que PEP554 simplifica la creaci√≥n de subinterpretadores: <br><br><ul><li>  M√≥dulos en el <code>importlib</code> <code>__main__</code> e <code>importlib</code> ; </li><li>  El contenido del diccionario <code>sys</code> ; </li><li>  Funciones incorporadas ( <code>print()</code> , <code>assert</code> , etc.); </li><li>  Corrientes; </li><li>  Configuraci√≥n del kernel. </li></ul><br><br>  La configuraci√≥n del n√∫cleo se puede clonar f√°cilmente desde la memoria, pero importar m√≥dulos no es tan simple.  Importar m√≥dulos en Python es lento, por lo que si crear un subinterpretador significa importar m√≥dulos en un espacio de nombres diferente cada vez, los beneficios se reducen. <br><br><h3>  ¬øQu√© hay de asyncio? </h3><br>  La implementaci√≥n existente del <code>asyncio</code> eventos <code>asyncio</code> en la biblioteca est√°ndar crea marcos de pila para la evaluaci√≥n, y tambi√©n <code>asyncio</code> estado en el int√©rprete principal (y, por lo tanto, comparte el GIL). <br><br>  Despu√©s de combinar PEP554, probablemente ya en Python 3.9, se puede usar una implementaci√≥n alternativa del bucle de eventos (aunque nadie lo ha hecho todav√≠a), que ejecuta m√©todos asincr√≥nicos en subinterpretadores en paralelo. <br><br><h3>  Suena genial, ¬°envu√©lveme tambi√©n! </h3><br>  Bueno, en realidad no. <br>  Dado que CPython se ha estado ejecutando en el mismo int√©rprete durante tanto tiempo, muchas partes de la base de c√≥digo usan el "Estado de tiempo de ejecuci√≥n" en lugar del "Estado del int√©rprete", por lo que si se introdujera PEP554 ahora, todav√≠a habr√≠a muchos problemas. <br><br>  Por ejemplo, el estado del recolector de basura (en las versiones 3.7 &lt;) pertenece al tiempo de ejecuci√≥n. <br><br>  En los cambios durante los sprints de PyCon, el estado del recolector de basura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">comenz√≥ a moverse</a> hacia el int√©rprete, de modo que cada subinterpretador tendr√≠a su propio recolector de basura (como deber√≠a ser). <br><br>  Otro problema es que hay algunas variables "globales" que persisten en la base del c√≥digo CPython junto con muchas extensiones en C. Por lo tanto, cuando la gente de repente comenz√≥ a paralelizar su c√≥digo correctamente, vimos algunos problemas. <br><br>  Otro problema es que los descriptores de archivo pertenecen al proceso, por lo que si tiene un archivo abierto para escribir en un int√©rprete, el subinterpretador no podr√° acceder a este archivo (sin m√°s cambios en CPython). <br><br>  En resumen, todav√≠a hay muchos problemas que deben abordarse. <br><br><h2>  Conclusi√≥n: ¬øGIL es verdad m√°s? </h2><br>  GIL continuar√° siendo utilizado para aplicaciones de un solo hilo.  Por lo tanto, incluso cuando sigue a PEP554, su c√≥digo de subproceso √∫nico de repente no se volver√° paralelo. <br>  Si desea escribir c√≥digo paralelo en Python 3.8, tendr√° problemas de paralelizaci√≥n asociados con el procesador, ¬°pero esto tambi√©n es un boleto para el futuro! <br><br><h2>  Cuando </h2><br>  Pickle v5 y el uso compartido de memoria para multiprocesamiento probablemente estar√°n en Python 3.8 (octubre de 2019), y aparecer√°n subinterpretadores entre las versiones 3.8 y 3.9. <br>  Si desea jugar con los ejemplos presentados, cre√© una rama separada con todo el c√≥digo necesario: <a href="">https://github.com/tonybaloney/cpython/tree/subinterpreters.</a> <br><br>  ¬øQu√© opinas sobre esto?  Escribe tus comentarios y nos vemos en el curso. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/458694/">https://habr.com/ru/post/458694/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../458684/index.html">ICANN elimina el umbral de precio para el dominio .org: por qu√© la comunidad de TI est√° en contra y qu√© suceder√° despu√©s</a></li>
<li><a href="../458686/index.html">@Pythonetc Junio ‚Äã‚Äã2019</a></li>
<li><a href="../458688/index.html">Consejos y trucos de mi canal de Telegram @pythonetc, junio de 2019</a></li>
<li><a href="../458690/index.html">¬°Automat√≠zalo! C√≥mo mejoramos las pruebas de integraci√≥n</a></li>
<li><a href="../458692/index.html">M√≥nada "Tal vez" a trav√©s de as√≠ncrono / espera en C # (¬°Sin tareas!)</a></li>
<li><a href="../458696/index.html">Texturizado, o lo que necesitas saber para convertirte en un Artista de Surface. Parte 3. PBR y materiales</a></li>
<li><a href="../458698/index.html">El camino de la paz y el camino de la guerra en proyectos de TI</a></li>
<li><a href="../458702/index.html">Perros de trineo: lo que necesita saber sobre ellos y c√≥mo fueron tra√≠dos</a></li>
<li><a href="../458704/index.html">Implementaci√≥n de un sistema DLP en el ejemplo del comercio minorista</a></li>
<li><a href="../458706/index.html">Los gopniks est√°n ahora en los mercados extranjeros, o "¬øPor qu√© es tan dif√≠cil encontrar un programador normal?"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
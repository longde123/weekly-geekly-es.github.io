<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖐🏼 🤷🏼 🔛 Saya mengerti, itu berarti saya ada: ulasan tentang Deep Learning in Computer Vision (bagian 2) 🙍🏼 🛏️ 🕵️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kami terus memahami sihir modern (visi komputer). Bagian 2 tidak berarti bahwa Anda harus membaca bagian 1 dulu. Bagian 2 berarti bahwa sekarang semua...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Saya mengerti, itu berarti saya ada: ulasan tentang Deep Learning in Computer Vision (bagian 2)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mipt/blog/458190/"> Kami terus memahami sihir modern (visi komputer).  Bagian 2 tidak berarti bahwa Anda harus membaca bagian 1 dulu. Bagian 2 berarti bahwa sekarang semuanya serius - kami ingin memahami kekuatan penuh jaringan saraf dalam penglihatan.  Deteksi, pelacakan, segmentasi, penilaian postur, pengenalan tindakan ... Arsitektur paling modis dan paling keren, ratusan lapisan dan puluhan ide cemerlang sudah menunggu Anda di bawah potongan! <br><br><img src="https://habrastorage.org/webt/yt/nk/uu/ytnkuundiudek47rjvlmlujrrm4.jpeg"><br><a name="habracut"></a><br><h2>  Di seri terakhir </h2><br>  Biarkan saya mengingatkan Anda bahwa pada bagian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pertama</a> kita berkenalan dengan jaringan saraf convolutional dan visualisasi mereka, serta dengan tugas-tugas mengklasifikasikan gambar dan membangun representasi efektif mereka (embeddings).  Kami bahkan mendiskusikan tugas pengenalan wajah dan identifikasi ulang orang. <br><br>  Bahkan di artikel sebelumnya kita berbicara tentang berbagai jenis arsitektur (ya, tablet <s>yang</s> sama <s>yang saya buat sebulan</s> ), dan di sini Google tidak membuang waktu: mereka merilis lagi arsitektur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">EfficientNet yang</a> sangat cepat dan akurat.  Mereka membuatnya menggunakan <abbr title="Pencarian Arsitektur Saraf">NAS</abbr> dan prosedur Penskalaan Senyawa khusus.  Lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikelnya</a> , itu sangat berharga. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9m/_h/5c/9m_h5cc1tsxs7bfkainm5zom-wg.jpeg" width="500"></div><br>  Sementara itu, beberapa peneliti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menghidupkan wajah</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mencari ciuman di film</a> , kita akan menghadapi masalah yang lebih mendesak. <br><br>  Di sini orang mengatakan: "pengenalan gambar".  Tapi apa itu "pengakuan"?  Apa itu "pemahaman (adegan)"?  Menurut pendapat saya, jawaban atas pertanyaan-pertanyaan ini tergantung pada apa yang ingin kita “kenali”, dan apa yang ingin kita “pahami”.  Jika kita membangun Kecerdasan Buatan, yang akan mengekstraksi informasi tentang dunia dari aliran visual seefisien (atau bahkan lebih baik) seperti orang, maka kita perlu beralih dari tugas, dari kebutuhan.  Secara historis, "pengakuan" dan "pemahaman tentang adegan" modern dapat dibagi menjadi beberapa tugas spesifik: klasifikasi, deteksi, pelacakan, evaluasi postur dan titik wajah, segmentasi, pengenalan tindakan pada video dan deskripsi gambar dalam teks.  Artikel ini akan fokus pada dua tugas pertama dari daftar (up, spoiler dari bagian ketiga), jadi rencana saat ini adalah ini: <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Temukan saya jika Anda dapat: deteksi objek</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Deteksi Wajah: Tidak Tertangkap - Bukan Pencuri</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Banyak surat: deteksi teks (dan pengenalan)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Video dan pelacakan: dalam satu aliran</a> </li></ol><br>  Ayo bergoyang, superstar! <br><br><a name="1"></a><h2>  Temukan saya jika Anda dapat: deteksi objek </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-q/9e/on/-q9eonan6thdv5jivk8kq0h7gm0.jpeg" width="700"></div><br>  Jadi, tugasnya terdengar sederhana - gambar diberikan, Anda perlu menemukan objek dari kelas yang sudah ditentukan di atasnya (seseorang, buku, apel, bassis-griffon artesis-Norman, dll.).  Untuk mengatasi masalah ini dengan bantuan jaringan saraf, kami mengajukannya dalam hal tensor dan pembelajaran mesin. <br><br>  Kita ingat bahwa gambar berwarna adalah tensor (H, W, 3) (jika kita tidak ingat, yaitu, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">bagian 1</a> ).  Sebelumnya, kami hanya tahu cara mengklasifikasikan seluruh gambar, tetapi sekarang tujuan kami adalah memprediksi posisi objek yang menarik (koordinat piksel) dalam gambar dan kelas mereka. <br><br>  Gagasan utama di sini adalah menyelesaikan dua masalah sekaligus - klasifikasi dan regresi.  Kami menggunakan jaringan saraf untuk mundur koordinat dan mengklasifikasikan objek di dalamnya. <br><br><div class="spoiler">  <b class="spoiler_title">Klasifikasi?</b>  <b class="spoiler_title">Regresi?</b> <div class="spoiler_text">  Biarkan saya mengingatkan Anda bahwa kita berbicara tentang tugas pembelajaran mesin.  Dalam masalah <b>klasifikasi</b> , label <b>kelas</b> bertindak sebagai kualitas label sebenarnya untuk objek, dan kami memprediksi kelas objek.  Dalam masalah <b>regresi</b> , <b>bilangan real</b> adalah <b>bilangan real</b> , dan kami memperkirakan jumlahnya (misalnya: berat, tinggi, gaji, jumlah karakter yang mati dalam seri Game of Thrones berikutnya ...).  Lebih detail - Anda <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dipersilakan untuk kuliah ke-3 DLSchool (FPMI MIPT)</a> . <br></div></div><br>  Tetapi koordinat objek, secara umum, dapat diformalkan dengan cara yang berbeda, dalam DL ada tiga cara utama: <i>deteksi</i> ( <abbr title="objek yang membatasi persegi panjang">kotak</abbr> objek), <i>evaluasi postur</i> (titik kunci objek) dan <i>segmentasi</i> ("topeng" objek).  Sekarang <abbr title="objek yang membatasi persegi panjang"><b>mari kita</b></abbr> bicara tentang memprediksi <abbr title="objek yang membatasi persegi panjang"><b>kotak</b></abbr> , titik, dan segmentasi yang tepat <abbr title="objek yang membatasi persegi panjang"><b>terikat</b></abbr> akan lebih jauh dalam teks. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ki/wt/xm/kiwtxmvvhmwsvqn3_5dovlmp8w8.jpeg" width="500"></div><br>  Pada dasarnya, kumpulan data deteksi ditandai dengan kotak dalam format: "koordinat sudut kiri atas dan kanan bawah untuk setiap objek di setiap gambar" (format ini juga disebut <abbr title="&quot;Tlbr&quot;">kiri atas, kanan bawah</abbr> ), dan sebagian besar pendekatan jaringan saraf memprediksi koordinat ini. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uo/zs/tj/uozstjspdifxpslvqyuurauxs2g.png" width="500"></div><br><div class="spoiler">  <b class="spoiler_title">Tentang kumpulan data dan metrik dalam masalah deteksi</b> <div class="spoiler_text">  Setelah menetapkan tugas, yang terbaik adalah melihat data apa yang tersedia untuk pelatihan dan metrik apa yang digunakan untuk mengukur kualitas.  Inilah yang saya perlahan bicarakan di paruh pertama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kuliah ke</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">13 dari Deep Learning School</a> (di x2.0 paling banyak). <br></div></div><br>  Sebelum terjun ke jenis jaringan saraf untuk deteksi, mari kita pikirkan bersama bagaimana menyelesaikan masalah mendeteksi apa pun dalam gambar.  Mungkin, jika kita ingin menemukan objek tertentu dalam gambar, maka kita secara kasar mengetahui bagaimana tampilannya dan area apa yang harus ditempati dalam gambar (meskipun itu dapat berubah). <br><br><div class="spoiler">  <b class="spoiler_title">Menemukan deteksi dari awal</b> <div class="spoiler_text">  Pendekatan naif dan paling sederhana adalah dengan membuat algoritma "pencarian templat": biarkan gambar menjadi 100x100 piksel, dan kami sedang mencari bola sepak.  Biarkan ada pola bola 20x20 piksel.  Ambil templat ini dan kami akan melewatinya seperti konvolusi di seluruh gambar, menghitung perbedaan pixel-per-pixel.  Inilah cara kerja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pencocokan templat</a> (beberapa jenis korelasi sering digunakan alih-alih perbedaan piksel demi piksel). <br><br>  Jika tidak ada template, tetapi ada classifier jaringan saraf, maka kita bisa melakukan ini: kita akan pergi dengan jendela dengan ukuran tetap dalam gambar dan memprediksi kelas area saat ini dari gambar.  Kemudian kita hanya mengatakan bahwa daerah yang paling memungkinkan dari objek adalah tempat di mana classifier menjawab dengan percaya diri.  Dengan demikian, kita dapat memecahkan masalah fakta bahwa objek terlihat berbeda dalam penampilan secara berbeda (karena dilatih untuk mengklasifikasikan pada sampel yang sangat beragam). <br><br>  Tapi kemudian muncul masalah - objek dalam gambar memiliki ukuran yang berbeda.  Bola sepak yang sama bisa berada di seluruh ketinggian / lebar gambar, atau bisa jauh di tujuan, hanya mengambil 10-20 piksel dari 1000. Saya ingin menulis algoritma Brute Force: kami hanya mengulang ukuran jendela.  Misalkan kita memiliki 100x200 piksel, maka kita akan pergi ke jendela 2x2, 2X3, 3x2, 2x4, 4x2, 3x3 ..., 3x4, 4x3 ... Saya pikir Anda mengerti bahwa jumlah jendela yang mungkin adalah 100 * 200, dan masing-masing akan kita lewati gambarnya , melakukan operasi klasifikasi (100-W_window) * (200 - H_window), yang membutuhkan banyak waktu.  Saya khawatir kami tidak akan menunggu sampai algoritma seperti itu bekerja. <br><br>  Anda dapat, tentu saja, memilih jendela paling karakteristik tergantung pada objek, tetapi juga akan bekerja untuk waktu yang sangat lama, dan jika cepat, itu tidak mungkin tepat - dalam aplikasi nyata akan ada sejumlah variasi dalam ukuran objek dalam gambar. <br></div></div><br>  Lebih jauh, saya kadang-kadang akan mengandalkan review <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">baru dari area deteksi mulai Januari 2019</a> (gambar juga akan berasal dari sana).  Ini hanya harus dibaca jika Anda ingin dengan cepat mendapatkan tampilan seluas mungkin di deteksi DL. <br><br>  Salah satu artikel pertama tentang deteksi dan lokalisasi menggunakan CNN adalah <a href="">Overfeat</a> .  Para penulis mengklaim bahwa mereka pertama kali menggunakan jaringan saraf untuk deteksi di ImageNet, merumuskan kembali masalah dan mengubah kerugian.  Pendekatannya, omong-omong, hampir end-to-end (di bawah ini adalah skema Overfeat). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/8o/5v/tv/8o5vtvhgukkn7frba0nx8yltfis.png" width="700"></div><br>  Arsitektur penting berikutnya adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Convolutional Neural Network</a> ( <b>RCNN</b> ) <b>berbasis Wilayah</b> , yang ditemukan oleh para peneliti dari <abbr>FAIR</abbr> pada tahun 2014.  Esensinya adalah bahwa ia pertama kali memprediksi banyak yang disebut "wilayah minat" (RoI's), di dalamnya berpotensi ada objek (menggunakan algoritma Pencarian Selektif), dan mengklasifikasikannya dan memperbaiki koordinat kotak menggunakan CNN. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2r/2p/kp/2r2pkpcoysglv4z_v-ll_y14mqw.png" width="700"></div><br>  Benar, pipa semacam itu membuat seluruh sistem melambat, karena kami menjalankan setiap wilayah melalui jaringan saraf (kami maju melewati ribuan kali).  Setahun kemudian, FAIR Ross Girshick yang sama meningkatkan RCNN ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Fast-RCNN</a> .  Di sini idenya adalah untuk menukar Pencarian Selektif dan prediksi jaringan: pertama, kami melewati seluruh gambar melalui jaringan saraf yang telah dilatih sebelumnya, dan kemudian kami memperkirakan wilayah yang diminati atas fitur-peta yang dikeluarkan oleh jaringan backbone (misalnya, menggunakan Pencarian Selektif yang sama, tetapi ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">algoritma lain</a> ).  Itu masih sangat lambat, jauh lebih lambat dari waktu-nyata (untuk saat ini, kami menganggap bahwa waktu-nyata kurang dari 40 milidetik per gambar). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tn/uc/d-/tnucd-y6i7tr4edgjeudtrsj16u.png" width="700"></div><br>  Kecepatan dipengaruhi terutama bukan oleh CNN, tetapi oleh algoritma pembuatan kotak itu sendiri, sehingga diputuskan untuk menggantinya dengan jaringan saraf kedua - Jaringan Proposal Wilayah ( <b>RPN</b> ), yang akan dilatih untuk memprediksi wilayah yang diminati objek.  Beginilah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Faster-RCNN muncul</a> (ya, mereka jelas tidak memikirkan nama untuk waktu yang lama).  Skema: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6v/h_/ye/6vh_yee2zrsflyhh8jdvtm_bbgy.png" width="700"></div><br>  Lalu ada peningkatan lain dalam bentuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">R-FCN</a> , kami tidak akan membicarakannya secara detail, tetapi saya ingin menyebutkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Mask-RCNN</a> .  Mask-RCNN adalah yang unik, jaringan saraf pertama yang memecahkan <b>masalah deteksi dan contoh segmentasi pada saat yang sama</b> - itu memprediksi topeng yang tepat (siluet) dari objek di dalam kotak pembatas.  Idenya sebenarnya cukup sederhana - ada dua cabang: untuk deteksi dan segmentasi, dan Anda perlu melatih jaringan untuk kedua tugas sekaligus.  Yang utama adalah memiliki data yang ditandai.  Mask-RCNN sendiri sangat mirip dengan Faster-RCNN: tulang punggungnya sama, tetapi pada akhirnya ada dua <b>"kepala"</b> (seperti <b>lapisan terakhir dari</b> jaringan saraf sering disebut) untuk dua tugas yang berbeda. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7w/ig/hq/7wighq6ox7tptik5f_7d7cez2hg.png" width="700"></div><br>  Inilah yang disebut pendekatan <b>Dua Tahap</b> (atau <b>berbasis Wilayah</b> ).  Sejalan dengan mereka, analog dikembangkan dalam pendeteksian DL - pendekatan <b>Satu Tahap</b> .  Ini termasuk jaringan saraf seperti: Single-Shot Detector (SSD), You Only Look Once (YOLO), Detektor Objek yang Sangat Diawasi (DSOD), Jaringan Block Field Reseptif (RFBNet) dan banyak lainnya (lihat peta di bawah, dari <a href="">repositori ini</a> ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ue/lc/-y/uelc-yeav4_avjdkycglf9uwrmm.png" width="750"></div><br>  Pendekatan satu tahap, tidak seperti dua tahap, tidak menggunakan algoritma terpisah untuk menghasilkan kotak, tetapi cukup memprediksi beberapa kotak koordinat untuk setiap peta fitur yang dihasilkan oleh jaringan saraf convolutional.  YOLO bertindak dengan cara yang sama, SSD sedikit berbeda, tetapi idenya sama: konvolusi 1x1 memprediksi banyak angka secara mendalam dari peta fitur yang diterima, namun kami sepakat sebelumnya berapa nomor artinya. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/ml/w_/qjmlw_ympdcib6jkpfdjdvcirdy.png" width="600"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jr/i3/oy/jri3oymb48sv5vq9dwwdxbndszg.png" width="600"></div><br>  Sebagai contoh, kami memperkirakan dari fitur peta ukuran 13x13x256 adalah fitur peta 13x13x (4 * (5 + 80)) angka, di mana kami memperkirakan 85 angka untuk 4 kotak: 4 angka pertama dalam urutan selalu koordinat kotak, ke-5 - Keyakinan dalam tinju, dan 80 angka - probabilitas masing-masing kelas (klasifikasi).  Ini diperlukan untuk kemudian menyerahkan angka-angka yang diperlukan untuk kerugian yang diperlukan dan melatih jaringan saraf dengan benar. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ao/xi/o2/aoxio2rty3hgpu2f8mduomvs9nu.png" width="800"></div><br>  Saya ingin menarik perhatian pada fakta bahwa kualitas pekerjaan detektor tergantung pada kualitas jaringan saraf untuk mengekstraksi fitur (yaitu, <b>jaringan saraf backbone</b> ).  Biasanya, peran ini dimainkan oleh salah satu arsitektur, yang saya bicarakan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel sebelumnya</a> (ResNet, SENet, dll.), Tetapi kadang-kadang penulis membuat arsitektur mereka sendiri yang lebih optimal (misalnya, Darknet-53 di YOLOv3) atau modifikasi (misalnya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Feature Pyramid Pooling</a> (FPN)). <br><br>  Sekali lagi, saya perhatikan bahwa kami melatih jaringan untuk klasifikasi dan regresi secara bersamaan.  Dalam komunitas, ini disebut kehilangan multi-tugas: jumlah kerugian untuk beberapa tugas (dengan beberapa koefisien) muncul dalam satu kehilangan. <br><br><div class="spoiler">  <b class="spoiler_title">Berita dengan Multitask Loss terkemuka</b> <div class="spoiler_text">  Di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Machines Can See 2019,</a> salah satu pembicara menggunakan multi-task loss untuk 7 tugas secara bersamaan <s>, Carl</s> .  Ternyata beberapa tugas awalnya ditetapkan sebagai penyeimbang satu sama lain dan "konflik" ternyata, yang mencegah jaringan dari belajar lebih baik daripada jika dilatih untuk setiap tugas secara terpisah.  Kesimpulan: jika Anda menggunakan multi-task loss, pastikan bahwa multi-task yang sama ini tidak bertentangan dengan pernyataan (misalnya, memprediksi batas-batas objek dan segmentasi internal mereka dapat saling mengganggu, karena hal-hal ini dapat mengandalkan tanda-tanda berbeda di dalam jaringan).  Penulis mengelak dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menambahkan blok Squeeze-and-Excitation terpisah untuk setiap tugas</a> . <br></div></div><br>  Baru-baru ini, artikel dari 2019 muncul di mana penulis menyatakan rasio kecepatan / akurasi yang lebih baik dalam tugas deteksi menggunakan <b>prediksi kotak berbasis poin</b> .  Saya berbicara tentang artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Objects Points"</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"CornerNet-Lite"</a> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ExtremeNet</a> adalah modifikasi dari CornerNet.  Tampaknya sekarang mereka dapat disebut SOTA dalam pendeteksian menggunakan jaringan saraf (tapi ini tidak akurat). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wk/qf/mr/wkqfmrenwm3u5f6c6bzinjcffga.png" width="900"></div><br>  Jika tiba-tiba penjelasan saya tentang detektor masih tampak kacau dan tidak dapat dipahami, dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">video kami,</a> saya membahasnya perlahan.  Mungkin Anda harus melihatnya dulu. <br><br>  Di bawah ini saya telah memberikan tabel jaringan saraf dalam pendeteksian dengan tautan ke kode dan deskripsi singkat dari chip masing-masing jaringan.  Saya mencoba mengumpulkan hanya jaringan-jaringan yang benar-benar penting untuk diketahui (setidaknya ide-ide mereka) untuk mendapatkan ide yang bagus tentang deteksi objek hari ini: <br><br><div class="spoiler">  <b class="spoiler_title">Detektor jaringan saraf (dua tahap)</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th>  Tahun </th><th>  Artikel </th><th>  Ide kunci </th><th>  Kode </th></tr><tr><td>  2013-2014 </td><td>  <a href="">RCNN</a> </td><td>  generasi wilayah minat dan prediksi jaringan saraf kelas di dalamnya </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Caffe</a> </td></tr><tr><td>  2015 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cepat-rcnn</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pertama melewati gambar melalui jaringan, dan kemudian menghasilkan daerah yang menarik</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Caffe</a> </td></tr><tr><td>  2016 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Lebih cepat-rcnn</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">gunakan RPN untuk menghasilkan daerah yang diminati</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr><tr><td>  2016 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">R-FCN</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pendekatan sepenuhnya convolutional daripada menghasilkan daerah yang menarik</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Caffe</a> </td></tr><tr><td>  2017 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Masker-rcnn</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dua "kepala" untuk menyelesaikan dua tugas sekaligus, RoI-Align</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Keras, TF</a> </td></tr><tr><td>  2019 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Penalaran-RCNN</a> </td><td>  meningkatkan kualitas RCNN dengan membangun grafik hubungan semantik objek </td><td>  --- </td></tr></tbody></table></div><br></div></div><br><br><div class="spoiler">  <b class="spoiler_title">Detektor jaringan saraf (satu tahap)</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th>  Tahun </th><th>  Artikel </th><th>  Ide kunci </th><th>  Kode </th></tr><tr><td>  2013-2014 </td><td>  <a href="">Makan berlebihan</a> </td><td>  salah satu detektor jaringan saraf pertama </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">C ++ (dengan pembungkus untuk bahasa lain)</a> </td></tr><tr><td>  2015 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SSD</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pendekatan satu tahap yang sangat fleksibel digunakan sekarang di banyak aplikasi</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr><tr><td>  2015 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Yolo</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ide yang mirip dengan SSD, berkembang secara paralel dan tidak kalah populer (ada versi baru)</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">C ++</a> </td></tr><tr><td>  2016 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">YOLOv2 (alias YOLO9000)</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sejumlah perbaikan untuk YOLO</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr><tr><td>  2017 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">YOLOv3</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sejumlah perbaikan untuk YOLOv2</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr><tr><td>  2017-2018 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DSOD</a> </td><td>  Ide Supervisi Mendalam dan Ide DenseNet </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Caffe</a> </td></tr><tr><td>  2017-2018 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">RFBNet</a> </td><td>  filter konvolusi dipilih dengan rapi berdasarkan struktur sistem visual manusia (blok <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">RF</a> ) </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr></tbody></table></div><br></div></div><br><br><div class="spoiler">  <b class="spoiler_title">Detektor jaringan saraf (bermacam-macam)</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th>  Tahun </th><th>  Artikel </th><th>  Ide kunci </th><th>  Kode </th></tr><tr><td>  2018 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">RetinaNet</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kehilangan fokus khusus untuk menyelesaikan masalah ketidakseimbangan kelas</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Keras</a> </td></tr><tr><td>  2014-2015 </td><td>  <a href="">SPP</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">modul yang memungkinkan Anda bekerja secara efektif dengan gambar dengan ukuran berbeda</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Keras</a> </td></tr><tr><td>  2016-2017 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">FPN</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">fitur piramida untuk deteksi objek dengan ukuran berbeda</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tensorflow</a> </td></tr><tr><td>  2019 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">NAS-FPN</a> </td><td>  Menemukan FPN Terbaik dengan Pencarian Arsitektur Saraf </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tensorflow</a> </td></tr><tr><td>  2019 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Daedalus</a> </td><td>  cara memecahkan detektor dengan serangan permusuhan </td><td>  --- </td></tr></tbody></table></div><br></div></div><br><br><div class="spoiler">  <b class="spoiler_title">Detektor jaringan saraf (berbasis titik)</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th>  Tahun </th><th>  Artikel </th><th>  Ide kunci </th><th>  Kode </th></tr><tr><td>  2019 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Centernet</a> </td><td>  pendekatan baru untuk deteksi, yang memungkinkan untuk dengan cepat dan efisien menyelesaikan masalah menemukan titik, kotak dan kotak 3D secara bersamaan </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr><tr><td>  2019 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cornernet</a> </td><td>  prediksi kotak berdasarkan pasangan titik sudut </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr><tr><td>  2019 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CornerNet-Lite</a> </td><td>  cornernet dipercepat </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr><tr><td>  2019 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ExtremeNet</a> </td><td>  prediksi titik "ekstrim" objek (batas geometris akurat) </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pytorch</a> </td></tr></tbody></table></div><br></div></div><br>  Untuk memahami bagaimana kecepatan / kualitas setiap arsitektur berkorelasi, Anda dapat melihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ulasan ini</a> atau versi yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">lebih populer</a> . <br><br>  Arsitektur baik-baik saja, tetapi deteksi pada dasarnya adalah tugas praktis.  "Tidak memiliki seratus jaringan, tetapi setidaknya ada 1 yang berfungsi" - ini adalah pesan saya.  Ada tautan ke kode dalam tabel di atas, tetapi secara pribadi, saya jarang menemukan peluncur detektor langsung dari repositori (setidaknya dengan tujuan penyebaran lebih lanjut ke produksi).  Paling sering, perpustakaan digunakan untuk ini, misalnya, TensorFlow Object Detection API (lihat bagian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">praktis dari pelajaran saya</a> ) atau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perpustakaan dari para peneliti dari CUHK</a> .  Saya membawa perhatian Anda ke meja-super lain (Anda menyukainya, kan?): <br><br><div class="spoiler">  <b class="spoiler_title">Perpustakaan untuk menjalankan model deteksi</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th>  Judul </th><th>  Penulis </th><th>  Deskripsi </th><th>  Jaringan Saraf Tiruan yang Diimplementasikan </th><th>  Kerangka kerja </th></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Detectron</a> </td><td>  Penelitian AI Facebook </td><td>  Repositori Facebook dengan berbagai kode model untuk mendeteksi dan mengevaluasi postur </td><td>  Semua berbasis wilayah </td><td>  Caffe2 </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">API Deteksi Objek TF</a> </td><td>  Tim TensorFlow </td><td>  Banyak model yang siap digunakan (bobot diberikan) </td><td>  Semua Berbasis Wilayah dan SSD (dengan tulang punggung berbeda) </td><td>  Tensorflow </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Darkflow</a> </td><td>  terima kasih </td><td>  Implementasi YOLO dan YOLOv2 yang siap digunakan </td><td>  Semua tipe YOLO (dengan modifikasi) kecuali YOLOv3 </td><td>  Tensorflow </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mmdeteksi</a> </td><td>  Buka MMLab (CUHK) </td><td>  Sejumlah besar detektor di PyTorch, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">lihat artikel mereka</a> </td><td>  Hampir semua model kecuali keluarga YOLO </td><td>  Pytorch </td></tr><tr><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Darknet (dimodifikasi)</a> </td><td>  AlexAB </td><td>  Implementasi yang mudah dari YOLOv3 dengan banyak perbaikan pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">repositori asli</a> </td><td>  YOLOv3 </td><td>  C ++ </td></tr></tbody></table></div><br></div></div><br>  Seringkali Anda perlu mendeteksi objek hanya dari satu kelas, tetapi spesifik dan sangat bervariasi.  Misalnya, untuk mendeteksi semua wajah dalam foto (untuk verifikasi / penghitungan lebih lanjut orang), untuk mendeteksi seluruh orang (untuk identifikasi ulang / penghitungan / pelacakan) atau untuk mendeteksi teks pada adegan (untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">OCR</a> / terjemahan kata-kata dalam foto).  Secara umum, pendekatan deteksi "biasa" di sini akan bekerja sampai batas tertentu, tetapi masing-masing subtugas ini memiliki trik sendiri untuk meningkatkan kualitas. <br><br><a name="2"></a><h2>  Deteksi Wajah: Tidak Tertangkap - Bukan Pencuri </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ic/ul/rp/iculrpbc7niyrdxg1yk_8r82nsw.jpeg" width="700"></div><br>  Beberapa kekhususan muncul di sini, karena wajah sering menempati bagian gambar yang cukup kecil.  Plus, orang tidak selalu melihat kamera, seringkali wajah hanya terlihat dari samping.  Salah satu pendekatan pertama untuk menghadapi pengakuan adalah detektor Viola-Jones yang terkenal berdasarkan kaskade Haar, ditemukan kembali pada tahun 2001. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hc/tf/zn/hctfzn0xudbedi_aymhmlcwkamu.png" width="400"></div><br>  Jaringan saraf <s>tidak dalam mode saat itu,</s> mereka masih tidak begitu kuat dalam penglihatan, namun, pendekatan kerajinan tangan yang baik melakukan tugasnya.  Beberapa jenis masker filter khusus digunakan secara aktif di dalamnya, yang membantu untuk mengekstraksi daerah wajah dari gambar dan tanda-tanda mereka, dan kemudian tanda-tanda ini diserahkan ke pengklasifikasi AdaBoost.  Omong-omong, metode ini benar-benar berfungsi dengan baik dan sekarang, ini cukup cepat dan mulai keluar dari kotak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menggunakan OpenCV</a> .  Kelemahan dari pendeteksi ini adalah ia hanya melihat wajah-wajah yang dikerahkan di depan kamera.  Seseorang hanya perlu berbalik sedikit dan stabilitas deteksi dilanggar. <br><br>  Untuk kasus yang lebih kompleks, Anda dapat menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dlib</a> .  Ini adalah C ++ - perpustakaan di mana banyak algoritma penglihatan diimplementasikan, termasuk untuk deteksi wajah. <br><br>  Dari pendekatan jaringan saraf dalam deteksi wajah, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Multi-task Cascaded CNN (MTCNN)</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MatLab</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TensorFlow</a> ) sangat signifikan.  Secara umum, sekarang aktif digunakan (dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">facenet yang</a> sama). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/80/wn/vu/80wnvuf59poodmodzswcgjlyjt4.jpeg" width="400"></div><br>  Gagasan MTCNN adalah menggunakan tiga jaringan saraf secara berurutan (oleh karena itu, sebuah <b>"kaskade"</b> ) untuk memprediksi posisi wajah dan titik-titik singularnya.  Dalam hal ini, ada tepat 5 titik khusus pada wajah: mata kiri, mata kanan, tepi kiri bibir, tepi kanan bibir dan hidung.     ( <abbr title="Proposal bersih">P-Net</abbr> )      .  ( <abbr title="Saring bersih">R-Net</abbr> ) —     .  ( <abbr title="Tengara Wajah Bersih">O-Net</abbr> )       ,  ,  5   . Multi-task   ,    :   ,  /        .  MTCNN     real-time,      40 ms   . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5e/iz/d5/5eizd5lwag9umfo1ccypep42eik.jpeg" width="800"></div><br><div class="spoiler"> <b class="spoiler_title">,        ArXiv ?</b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dalam hal ini, saya sarankan mencoba membaca </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">artikel asli tentang MTCNN</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , jika Anda sudah memiliki latar belakang dalam jaringan konvolusi. </font><font style="vertical-align: inherit;">Artikel ini hanya membutuhkan </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5 halaman</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , tetapi menetapkan semua informasi yang Anda butuhkan untuk memahami pendekatan. </font><font style="vertical-align: inherit;">Cobalah, ini akan kencang :)</font></font><br></div></div><br>   State-of-the-Art   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dual Shot Face Detector (DSFD)</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">FaceBoxes</a> . FaceBoxes      CPU (!),  DSFD    (   2019 ). DSFD  ,  MTCNN,          ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dilated convolutions</a> ),        . ,  dilated convolutions            .    DSFD (,   ?). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xv/or/it/xvoritceua0_ocjteyvm4xvisbq.jpeg"></div><br>     <b></b> ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">  </a> ,      . <br><br><a name="3"></a><h2>  :  ( )  </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qn/v9/wo/qnv9woeqru3dioeennrkvalkjqg.png" width="500"></div><br>     .  , ,   bounding box',    (   ),    .     ,   , ,       recognition-,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">    </a> . <br><br>       bounding box',        ,    ( ).     , , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">EAST-</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/j3/hd/bj/j3hdbj-xozs4voec8ekiz4k1eo0.png" width="500"></div><br><br>  EAST-  ,      ,    : <br><br><ol><li> Text Score Map' (     ) </li><li>     </li><li>        </li></ol><br>  ,      (  ),  .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">arxiv-</a> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dj/vt/uu/djvtuu36dzinoratlumncsgb5t8.png" width="700"></div><br><br>    (    )  ,    : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TextBoxes++</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Caffe</a> )  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SegLinks</a> ,  EAST,   ,    . <br><br>         ,  <b></b>     .       —    .     ,      ,   ,          . , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">MORAN</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">  PyTorch</a> )  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ASTER</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">  TensorFlow</a> )     . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vt/ot/nc/vtotncz1d1zhhsiytuzmarta9ta.png" width="700"></div><br><br>    - ,          : CNN  RNN.       ,     .    MORAN':     . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hu/qx/_2/huqx_2jakjcggsgacvhj9a8vce4.png" width="300"></div><br>       EAST', -       ,           .  ,           ,     . <br><br>   <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a></b>   ,  / .      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Spatial Transformet Network (STN)</a> ,              (,       ,    ).   / STN. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6y/z1/p9/6yz1p942ensgepwirqrtzpcnb7q.jpeg" width="700"></div><br>   STN    ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">  </a> (  ,  )  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">  PyTorch</a> . <br><br>  MORAN (     )    —      ,        <b> </b>  x   y,     ,      .    <i><abbr title="koreksi, koreksi">rectification</abbr></i> ,         ( <i>rectifier'</i> ).         : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/n4/az/du/n4azduih5p7wd9sx-tqhpgy-p20.png" width="300"></div><br>  Namun, selain pendekatan pengenalan teks “modularly” (jaringan deteksi -&gt; jaringan pengenalan), ada arsitektur ujung ke ujung: input adalah gambar, dan outputnya adalah deteksi dan teks dikenali di dalamnya.  Dan semua ini adalah satu saluran pipa yang mempelajari kedua tugas sekaligus.  Dalam arah ini, ada karya mengesankan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Berorientasi Teks Bercak Cepat dengan Jaringan Terpadu ( <b>FOTS</b> ) (</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kode</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><b>PyTorch</b></a> ), di mana penulis juga mencatat bahwa pendekatan end-to-end dua kali lebih cepat dari "deteksi + pengenalan".  Di bawah ini adalah diagram jaringan saraf FOTS, peran khusus dimainkan oleh blok RoiRotate, karena itu dimungkinkan untuk "melemparkan gradien" dari jaringan untuk pengakuan pada jaringan saraf untuk deteksi (ini benar-benar lebih rumit daripada kelihatannya). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/a5/xh/ch/a5xhchryrwf-zpfudielmab9pqu.png" width="800"></div><br>  By the way, setiap tahun konferensi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ICDAR diadakan</a> , di mana <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">beberapa kompetisi</a> untuk pengenalan teks dalam berbagai gambar diatur waktunya. <br><br><h3>  Masalah saat ini dalam deteksi </h3><br>  Menurut pendapat saya, masalah utama dalam pendeteksian sekarang bukanlah kualitas model detektor, tetapi data: mereka biasanya panjang dan mahal untuk ditandai, terutama jika ada banyak kelas yang perlu dideteksi (tetapi dengan cara ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">contoh solusi</a> untuk 500 kelas).  Oleh karena itu, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">banyak karya</a> sekarang dikhususkan untuk menghasilkan data yang paling masuk akal “secara sintetis” dan mendapatkan markup “secara gratis”.  Di bawah ini adalah gambar dari <s>diploma saya tentang sebuah</s> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel dari Nvidia</a> , yang khusus membahas tentang pembuatan data sintetis. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6k/mn/wh/6kmnwhvc1pgahzwtjloa4dy9sbm.png" width="800"></div><br>  Tapi tetap saja luar biasa bahwa sekarang kita dapat mengatakan dengan pasti di mana dalam gambar itu.  Dan jika kita ingin, misalnya, untuk menghitung jumlah sesuatu pada bingkai, maka itu cukup untuk mendeteksi ini dan memberikan jumlah kotak.  Dalam mendeteksi orang, YOLO biasa juga berfungsi dengan baik, hanya yang utama adalah mengirimkan banyak data.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Darkflow yang</a> sama cocok, dan kelas "manusia" ditemukan di hampir semua dataset deteksi utama.  Jadi, jika kita ingin menggunakan kamera untuk menghitung jumlah orang yang lewat, katakanlah, dalam satu hari, atau jumlah barang yang diambil seseorang di toko, kami hanya akan mendeteksi dan memberikan jumlah ... <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/m2/ts/pl/m2tsplbgrnmoauvlghy8ivq2jdm.jpeg" width="700"></div><br>  Berhenti  Tetapi jika kita ingin mendeteksi orang di setiap gambar dari kamera, maka kita dapat menghitung jumlah mereka dalam satu bingkai, dan dalam dua - tidak lagi, karena kita tidak bisa mengatakan di mana tepatnya orang yang mana.  Kami membutuhkan algoritme yang memungkinkan kami menghitung orang unik di aliran video.  Mungkin itu adalah algoritma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">identifikasi ulang</a> , tetapi ketika menyangkut video dan deteksi, itu dosa jika tidak menggunakan algoritme pelacakan. <br><br><a name="4"></a><h3>  Video dan pelacakan: dalam satu aliran </h3><br>  Sejauh ini, kami hanya berbicara tentang tugas dalam gambar, tetapi hal yang paling menarik terjadi di video.  Untuk mengatasi pengakuan tindakan yang sama, kita perlu menggunakan tidak hanya komponen <i>ruang yang</i> disebut, tetapi juga komponen <i>temporal</i> , karena video adalah urutan gambar dalam waktu. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qm/da/pa/qmdapao0kcytnxhorj7htm6susy.jpeg" width="700"></div><br>  Pelacakan adalah analog dari deteksi gambar, tetapi untuk video.  Artinya, kami ingin mengajarkan jaringan untuk memprediksi tidak tinju dalam gambar, tetapi tracklet dalam waktu (yang pada dasarnya adalah urutan kotak).  Di bawah ini adalah contoh gambar yang menunjukkan "ekor" - jejak orang-orang ini dalam video. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xz/yv/c_/xzyvc_oumhrnf_-bmf8gz5l_hli.png" width="600"></div><br>  Mari kita pikirkan cara mengatasi masalah pelacakan.  Biarkan ada video, dan frame-nya # 1 dan # 2.  Mari kita bahas sejauh ini hanya satu objek - kita melacak satu bola.  Pada frame # 1, kita bisa menggunakan detektor untuk mendeteksinya.  Pada yang kedua kita juga dapat mendeteksi bola, dan jika itu ada di sana sendiri, maka semuanya baik-baik saja: kita mengatakan bahwa tinju pada frame sebelumnya adalah tinju dari bola yang sama seperti pada frame # 2.  Anda juga dapat melanjutkan ke frame yang tersisa, di bawah gif dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kursus</a> visi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pyimagesearch</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_w/et/ak/_wetakdpybemefhert6cxslqaju.gif" width="600"></div><br>  Ngomong-ngomong, untuk menghemat waktu, kita tidak dapat memulai jaringan saraf pada frame kedua, tetapi cukup "memotong" kotak bola dari frame pertama dan mencari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">korelasi yang</a> persis sama di frame kedua atau pixel demi pixel.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pelacak korelasi</a> menggunakan pendekatan ini, mereka dianggap sederhana dan lebih atau kurang dapat diandalkan jika kita berurusan dengan kasus-kasus sederhana seperti "melacak satu bola di depan kamera di ruang kosong".  Tugas ini juga disebut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pelacakan Objek Visual</a> .  Di bawah ini adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">contoh karya</a> pelacak korelasi menggunakan contoh satu orang. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cv/fp/qd/cvfpqdd5ghelxfpucxrejxq6vpm.gif" width="600"></div><br>  Namun, jika ada beberapa deteksi / orang, maka Anda harus dapat mencocokkan kotak dari frame # 1 dan dari frame # 2.  Ide pertama yang muncul di pikiran adalah untuk mencoba mencocokkan kotak dengan yang memiliki area persimpangan terbesar ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">IoU</a> ) dengannya.  Benar, dalam kasus beberapa pendeteksian yang tumpang tindih, pelacak seperti itu akan tidak stabil, jadi Anda perlu menggunakan lebih banyak informasi. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qx/i2/t1/qxi2t1ejpnir0h52ip-23zpf4ti.png" width="600"></div><br>  Pendekatan dengan IoU hanya bergantung pada <i>tanda-tanda</i> deteksi <i>"geometris"</i> , yaitu hanya mencoba membandingkannya dengan kedekatan pada bingkai.  Tapi kami memiliki seluruh gambar (bahkan dua dalam kasus ini), dan kami dapat menggunakan fakta bahwa di dalam deteksi ini terdapat <i>tanda-tanda "visual"</i> .  Selain itu, kami memiliki riwayat deteksi untuk setiap orang, yang memungkinkan kami untuk lebih akurat memprediksi posisi berikutnya berdasarkan kecepatan dan arah gerakan, ini secara kondisional dapat disebut sebagai <i>tanda "fisik"</i> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mc/ay/se/mcaysee7xq25-j6hnvjalhfy5z0.gif" width="700"></div><br>  Salah satu pelacak real-time pertama, yang sepenuhnya dapat diandalkan dan mampu mengatasi situasi sulit, diterbitkan pada 2016 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Simple Online dan Realtime Traker (SORT)</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kode Python</a> ).  SORT tidak menggunakan tanda-tanda visual dan jaringan saraf, tetapi hanya memperkirakan sejumlah parameter dari setiap kotak pada setiap frame: kecepatan saat ini (x dan y secara terpisah) dan ukuran (tinggi dan lebar).  Rasio aspek kotak selalu diambil dari deteksi pertama kotak itu.  Lebih jauh, kecepatan diprediksi menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">filter Kalman</a> (umumnya bagus dan ringan di dunia pemrosesan sinyal), matriks persimpangan kotak oleh IoU dibangun, dan deteksi ditetapkan oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">algoritma Hungaria</a> . <br><br>  Jika menurut Anda matematika sudah menjadi agak banyak, maka dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel ini</a> semuanya dijelaskan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dengan</a> cara yang dapat diakses (ini adalah media :). <br><br>  Sudah pada tahun 2017, modifikasi SORT dirilis dalam bentuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DeepSORT</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kode untuk TensorFlow</a> ).  DeepSORT sudah mulai menggunakan jaringan saraf untuk mengekstraksi tanda-tanda visual, menggunakannya untuk menyelesaikan tabrakan.  Kualitas pelacakan telah berkembang - bukan tanpa alasan yang dianggap sebagai salah satu pelacak online terbaik saat ini. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/15/it/ny/15itnyht32oes3n-keaqk36jnpq.gif" width="800"></div><br>  Bidang pelacakan memang aktif berkembang: ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pelacak dengan jaringan saraf siam</a> , dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pelacak dengan RNN</a> .  Pertahankan jari Anda pada denyut nadi, karena pada hari apa pun arsitektur yang lebih akurat dan cepat dapat keluar (atau sudah keluar).  Omong-omong, sangat mudah untuk mengikuti hal-hal seperti itu di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">PapersWithCode</a> , selalu ada tautan ke artikel dan kode untuk mereka (jika ada). <br><br><h3>  Kata penutup </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jb/yh/bf/jbyhbf2ovu_ynurp_t_d9_hi4vg.jpeg" width="600"></div><br><br>  Kami benar-benar telah mengalami banyak hal dan belajar banyak.  Tetapi visi komputer adalah bidang yang sangat luas, dan saya adalah orang yang sangat keras kepala.  Itulah sebabnya kami akan melihat Anda di artikel ketiga dari seri ini (apakah ini akan menjadi yang terakhir? Siapa yang tahu ...), di mana kami akan membahas secara lebih rinci segmentasi, penilaian postur, pengenalan tindakan pada video, dan pembuatan deskripsi dari gambar menggunakan gambar menggunakan jaringan saraf. <br><br>  PS Saya ingin menyampaikan terima kasih khusus kepada Vadim Gorbachev atas saran dan komentarnya yang berharga dalam persiapan artikel ini dan sebelumnya. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id458190/">https://habr.com/ru/post/id458190/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id458168/index.html">Juni Machine Learning dan Intelijen Berita Buatan Intisari</a></li>
<li><a href="../id458170/index.html">Perendaman dalam jaringan saraf convolutional. Bagian 5/10 - 18</a></li>
<li><a href="../id458176/index.html">Penghalang exaflops akan diatasi pada 2021</a></li>
<li><a href="../id458184/index.html">Haxe dan PHP: pengetikan statis, fungsi panah, metaprogramming, dan banyak lagi</a></li>
<li><a href="../id458186/index.html">WAL di PostgreSQL: 1. Buffer cache</a></li>
<li><a href="../id458202/index.html">Lihatlah SObjectizer jika Anda ingin menggunakan Aktor atau CSP dalam proyek C ++ Anda</a></li>
<li><a href="../id458204/index.html">Cara mengevaluasi kinerja penyimpanan di Linux: benchmark menggunakan alat terbuka</a></li>
<li><a href="../id458206/index.html">Sublime Text 3 untuk tata letak situs. Sesuaikan tampilan dan instal plugin. Panduan Pemula</a></li>
<li><a href="../id458208/index.html">Acara digital di Moskow dari 01 Juli hingga 07 Juli</a></li>
<li><a href="../id458214/index.html">Pentest-laboratorium "Pentestit Test lab 12" - bagian penuh</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üß§ üë®üèø‚Äçüç≥ üë° Abonnez-vous √† Kafka via HTTP ou comment simplifier vos hooks web üéé üë©‚Äçüë©‚Äçüë¶‚Äçüë¶ üë®üèº‚Äçüé§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il existe de nombreuses fa√ßons de traiter les messages des syst√®mes Pub-Sub: en utilisant un service distinct, en isolant un processus isol√©, en orche...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Abonnez-vous √† Kafka via HTTP ou comment simplifier vos hooks web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/435346/">  Il existe de nombreuses fa√ßons de traiter les messages des syst√®mes Pub-Sub: en utilisant un service distinct, en isolant un processus isol√©, en orchestrant un pool de processus / threads, IPC complexe, Poll-over-Http et bien d'autres.  Aujourd'hui, je veux parler de la fa√ßon d'utiliser Pub-Sub sur HTTP et de mon service √©crit sp√©cifiquement pour cela. <br><br>  Dans certains cas, l'utilisation d'un backend de service HTTP pr√™t √† l'emploi est une solution id√©ale pour traiter une file d'attente de messages: <br><br><ol><li>  √âquilibrage hors de la bo√Æte.  Habituellement, le backend est d√©j√† derri√®re l'√©quilibreur et dispose d'une infrastructure pr√™te √† charger, ce qui simplifie consid√©rablement le travail avec les messages. </li><li>  Utilisation d'un contr√¥leur REST standard (n'importe quelle ressource HTTP).  La consommation de messages HTTP minimise le co√ªt d'impl√©mentation de compumers pour diff√©rentes langues si le backend est mixte. </li><li>  Simplification de l'utilisation des hooks Web d'autres services.  D√©sormais, presque tous les services (Jira, Gitlab, Mattermost, Slack ...) prennent en charge les crochets Web pour interagir avec le monde ext√©rieur.  Vous pouvez vous simplifier la vie si vous apprenez √† la file d'attente √† ex√©cuter les fonctions d'un r√©partiteur HTTP. </li></ol><br>  Cette approche pr√©sente √©galement des inconv√©nients: <br><br><ol><li>  Vous pouvez oublier la l√©g√®ret√© de la solution.  HTTP est un protocole lourd, et l'utilisation de frameworks du c√¥t√© du consommateur augmentera instantan√©ment la latence et la charge. </li><li>  Nous perdons les forces de l'approche Poll, obtenant les faiblesses de Push. </li><li>  Le traitement des messages par les m√™mes instances de service qui traitent les clients peut affecter la r√©activit√©.  Ce n'est pas significatif, car il est trait√© avec √©quilibrage et isolation. </li></ol><br>  J'ai impl√©ment√© l'id√©e en tant que service Queue-Over-Http, qui sera discut√© plus tard.  Le projet est √©crit en Kotlin en utilisant Spring Boot 2.1.  En tant que courtier, seul Apache Kafka est actuellement disponible. <br><a name="habracut"></a><br>  <i>Plus loin dans l'article, il est suppos√© que le lecteur conna√Æt Kafka et conna√Æt les validations (validation) et les d√©calages (d√©calage) des messages, les principes des groupes (groupe) et des consommateurs (consommateur), et comprend √©galement en quoi la partition (partition) diff√®re du sujet (sujet) .</i>  <i>S'il y a des lacunes, je vous conseille de lire <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette</a> section de la documentation Kafka avant de continuer.</i> <br><br><h1>  Table des mati√®res </h1><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Revue</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">S'engage</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gestion des erreurs</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Des messages</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Performances</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">D√©monstration</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Conclusion</a> </li></ul><br><a name="overview"></a><h1>  Revue </h1><br>  Queue-Over-Http est un service qui agit en tant qu'interm√©diaire entre un courtier de messages et le consommateur HTTP final (le service facilite la mise en ≈ìuvre de la prise en charge de l'envoi de messages aux consommateurs de toute autre mani√®re, par exemple, divers * RPC).  Pour le moment, seuls l'abonnement, le d√©sabonnement et l'affichage de la liste des consommateurs sont disponibles. L'envoi de messages au courtier (produit) via HTTP n'a pas encore √©t√© mis en ≈ìuvre en raison de l'impossibilit√© de garantir l'ordre des messages sans un soutien sp√©cial du producteur. <br><br>  Le personnage cl√© du service est le consommateur, qui peut s'abonner √† des partitions sp√©cifiques ou simplement √† des sujets (le mod√®le de sujet est pris en charge).  Dans le premier cas, l'√©quilibre automatique des partitions est d√©sactiv√©.  Apr√®s s'√™tre abonn√©, la ressource HTTP sp√©cifi√©e commence √† recevoir des messages des partitions Kafka attribu√©es.  Sur le plan architectural, chaque abonn√© est associ√© √† un client Java Kafka natif. <br><br><div class="spoiler">  <b class="spoiler_title">histoire divertissante sur KafkaConsumer</b> <div class="spoiler_text">  Kafka a un merveilleux client Java qui peut faire beaucoup.  Je l'utilise dans l'adaptateur de file d'attente pour recevoir des messages du courtier, puis je l'envoie aux files d'attente de service local.  Il est √† noter que le client travaille exclusivement dans le cadre d'un seul thread. <br><br>  L'id√©e de l'adaptateur est simple.  Nous commen√ßons dans un thread, nous √©crivons le planificateur le plus simple des clients natifs, en nous concentrant sur la r√©duction de la latence.  Autrement dit, nous √©crivons quelque chose de similaire: <br><br><pre><code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (!Thread.interrupted()) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> hasWork = <span class="hljs-literal"><span class="hljs-literal">false</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (consumer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> kafkaConsumers) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> queueGroup = consumers[consumer] ?: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span> invalidateSubscription(consumer, queueGroup) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> records = consumer.poll(Duration.ZERO) <span class="hljs-comment"><span class="hljs-comment">/*      */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!records.isEmpty) { hasWork = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> committed = doCommit() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!hasWork &amp;&amp; committed == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// ,    Thread.sleep(1) } }</span></span></code> </pre> <br>  Il semblerait que tout soit merveilleux, la latence est minime m√™me avec des dizaines de consommateurs.  En pratique, il s'est av√©r√© que <code>KafkaConsumer</code> √† ce mode de fonctionnement et donne un taux d'allocation d'environ 1,5 Mo / s en temps d'inactivit√©.  Avec 100 courriers, le taux d'allocation atteint 150 Mo / s et fait penser souvent √† l'application GC.  Bien s√ªr, toutes ces ordures sont dans la zone jeune, GC est tout √† fait capable de g√©rer cela, mais toujours, la solution n'est pas parfaite. <br><br>  √âvidemment, vous devez suivre la voie typique de <code>KafkaConsumer</code> et maintenant je place chaque abonn√© dans mon flux.  Cela donne une surcharge pour la m√©moire et la planification, mais il n'y a pas d'autre moyen. <br><br>  Je r√©√©cris le code d'en haut, supprimant la boucle interne et changeant <code>Duration.ZERO</code> en <code>Duration.ofMillis(100)</code> .  Il s'av√®re que le taux d'allocation tombe √† un niveau acceptable de 80 √† 150 Ko / s par consommateur.  Cependant, Poll avec un d√©lai d'expiration de 100 ms retarde toute la file d'attente des validations sur ces m√™mes 100 ms, ce qui est beaucoup inacceptable. <br><br>  Dans le processus de recherche de solutions au probl√®me, je me souviens de <code>KafkaConsumer::wakeup</code> , qui l√®ve une <code>WakeupException</code> et interrompt toute op√©ration de blocage sur le consommateur.  Avec cette m√©thode, le chemin vers une faible latence est simple: lorsqu'une nouvelle demande de validation arrive, nous la mettons dans la file d'attente, et sur le consommateur natif, nous appelons le <code>wakeup</code> .  Dans le cycle de travail, <code>WakeupException</code> et allez valider ce qui s'est accumul√©.  Pour le transfert de contr√¥le √† l'aide d'exceptions, vous devez imm√©diatement le remettre entre vos mains, mais puisque rien d'autre ... <br><br>  Il s'av√®re que cette option est loin d'√™tre parfaite, car toute op√©ration sur le consommateur natif <code>WakeupException</code> d√©sormais une <code>WakeupException</code> , y compris la validation elle-m√™me.  Le traitement de cette situation encombrera le code avec un indicateur permettant d'effectuer le <code>wakeup</code> . <br><br>  J'arrive √† la conclusion qu'il serait bien de modifier la m√©thode <code>KafkaConsumer::poll</code> afin qu'elle puisse √™tre interrompue normalement, selon un indicateur suppl√©mentaire.  En cons√©quence, <a href="https://github.com/viirtus/queue-over-">Frankenstein</a> est n√© de la r√©flexion, qui copie exactement la m√©thode de sondage d'origine, en ajoutant une sortie de la boucle par le drapeau.  Cet indicateur est d√©fini par une m√©thode interruptPoll distincte, qui, en outre, appelle le r√©veil sur le s√©lecteur client pour lib√©rer le verrou de thread sur les op√©rations d'E / S. <br><br>  Apr√®s avoir impl√©ment√© le client de cette mani√®re, j'obtiens la vitesse de r√©action √† partir du moment o√π une demande de validation arrive jusqu'√† ce qu'elle soit trait√©e jusqu'√† 100 microsecondes, et une excellente latence pour r√©cup√©rer les messages d'un courtier, ce qui est tr√®s bien. <br></div></div><br>  Chaque partition est repr√©sent√©e par une file d'attente locale distincte, o√π l'adaptateur √©crit des messages √† partir du courtier.  Le travailleur en prend des messages et les envoie pour ex√©cution, c'est-√†-dire pour l'envoi via HTTP. <br><br>  Le service prend en charge le traitement des messages par lots pour augmenter le d√©bit.  Lors de l'abonnement, vous pouvez sp√©cifier le <code>concurrencyFactor</code> chaque rubrique (s'applique √† chaque partition affect√©e ind√©pendamment).  Par exemple, <code>concurrencyFactor=1000</code> signifie que 1000 messages sous forme de requ√™tes HTTP peuvent √™tre envoy√©s au consommateur en m√™me temps.  D√®s que tous les messages du pack ont ‚Äã‚Äã√©t√© √©tablis sans ambigu√Øt√© par le consommateur, le service d√©cide de la prochaine validation de l'offset du dernier message dans Kafka.  Par cons√©quent, la deuxi√®me valeur de <code>concurrencyFactor</code> est le nombre maximal de messages trait√©s par le consommateur en cas de panne de Kafka ou Queue-Over-Http. <br><br>  Pour r√©duire les d√©lais, la file d'attente a <code>loadFactor = concurrencyFactor * 2</code> , ce qui vous permet de lire deux fois plus de messages du courtier que vous pouvez envoyer.  √âtant donn√© que la validation automatique est d√©sactiv√©e sur le client natif, un tel sch√©ma ne viole pas les garanties At-Least-Once. <br>  Une valeur <code>concurrencyFactor</code> √©lev√©e augmente le d√©bit de la file d'attente en r√©duisant le nombre de validations qui prennent jusqu'√† 10 ms dans le pire des cas.  Dans le m√™me temps, la charge sur le consommateur augmente. <br><br>  L'ordre d'envoi des messages dans le bundle n'est pas garanti, mais il peut √™tre atteint en d√©finissant <code>concurrencyFactor=1</code> . <br><br><a name="commits"></a><h1>  S'engage </h1><br>  Les commits sont une partie importante du service.  Lorsque le prochain paquet de donn√©es est pr√™t, le d√©calage du dernier message du paquet est imm√©diatement valid√© dans Kafka, et ce n'est qu'apr√®s une validation r√©ussie que le prochain paquet devient disponible pour le traitement.  Souvent, cela ne suffit pas et une validation automatique est requise.  Pour ce faire, il existe le param√®tre <code>autoCommitPeriodMs</code> , qui a peu de choses en commun avec la p√©riode classique d'autocommit pour les clients natifs qui valident le dernier message lu depuis la partition.  Imaginez <code>concurrencyFactor=10</code> .  Le service a envoy√© les 10 messages et attend que chacun d'eux soit pr√™t.  Le traitement du message 3 est termin√© en premier, puis le message 1, puis le message 10. √Ä ce stade, il est temps pour la validation automatique.  Il est important de ne pas violer la s√©mantique At-Least-Once.  Par cons√©quent, vous ne pouvez valider que le premier message, c'est-√†-dire l'offset 2, car seul il a √©t√© trait√© avec succ√®s √† ce moment.  De plus, jusqu'√† la prochaine validation automatique, les messages 2, 5, 6, 4 et 8. sont trait√©s. Vous devez maintenant valider uniquement l'offset 7, etc.  Autocommit n'a presque aucun effet sur le d√©bit. <br><br><a name="errors"></a><h1>  Gestion des erreurs </h1><br>  En mode de fonctionnement normal, le service envoie une fois un message au superviseur.  Si, pour une raison quelconque, il a provoqu√© une erreur 4xx ou 5xx, le service renverra le message en attendant la r√©ussite du traitement.  Le temps entre les tentatives peut √™tre configur√© comme un param√®tre distinct. <br><br>  Il est √©galement possible de d√©finir le nombre de tentatives apr√®s lesquelles le message sera marqu√© comme trait√©, ce qui arr√™tera les retransmissions quel que soit l'√©tat de la r√©ponse.  Je d√©conseille de l'utiliser pour des donn√©es sensibles, les situations de d√©faillance des consommateurs doivent toujours √™tre ajust√©es manuellement.  Les messages persistants peuvent √™tre surveill√©s par les journaux de service et la surveillance de l'√©tat de la r√©ponse du consommateur. <br><br><div class="spoiler">  <b class="spoiler_title">de coller</b> <div class="spoiler_text">  Habituellement, le serveur HTTP, donnant √† 4xx ou 5xx l'√©tat de la r√©ponse, envoie √©galement l'en-t√™te <code>Connection: close</code> .  Une connexion TCP qui est ferm√©e de cette mani√®re reste √† l'√©tat <code>TIME_WAITED</code> jusqu'√† ce qu'elle soit effac√©e par le syst√®me d'exploitation apr√®s un certain temps.  Le probl√®me est que ces connexions occupent un port entier qui ne peut pas √™tre r√©utilis√© avant d'√™tre lib√©r√©.  Cela peut entra√Æner l'absence de ports libres sur la machine pour √©tablir une connexion TCP et le service sera lev√© avec des exceptions dans les journaux pour chaque envoi.  En pratique, sur Windows 10, les ports se terminent apr√®s 10 √† 20 000 envois de messages erron√©s en 1 √† 2 minutes.  En mode standard, ce n'est pas un probl√®me. <br></div></div><br><a name="messages"></a><h1>  Des messages </h1><br>  Chaque message extrait du courtier est envoy√© au conseiller via HTTP vers la ressource sp√©cifi√©e lors de l'abonnement.  Par d√©faut, un message est envoy√© par une requ√™te POST dans le corps.  Ce comportement peut √™tre modifi√© en sp√©cifiant toute autre m√©thode.  Si la m√©thode ne prend pas en charge l'envoi de donn√©es dans le corps, vous pouvez sp√©cifier le nom du param√®tre de cha√Æne dans lequel le message sera envoy√©.  De plus, lors de l'abonnement, vous pouvez sp√©cifier des en-t√™tes suppl√©mentaires qui seront ajout√©s √† chaque message, ce qui est pratique pour l'autorisation de base √† l'aide de jetons.  Des en-t√™tes sont ajout√©s √† chaque message avec l'identifiant du consommateur, le sujet et la partition, d'o√π le message a √©t√© lu, le num√©ro du message, la cl√© de partition, le cas √©ch√©ant, ainsi que le nom du courtier. <br><br><a name="performance"></a><h1>  Performances </h1><br>  Pour √©valuer les performances, j'ai utilis√© un PC (Windows 10, OpenJDK-11 (G1 sans r√©glage), i7-6700K, 16 Go), qui ex√©cute le service et un ordinateur portable (Windows 10, i5-8250U, 8 Go), sur lequel le producteur de messages, HTTP Consommateur de ressources et Kafka avec les param√®tres par d√©faut.  Le PC est connect√© au routeur via une connexion filaire 1Gb / s, l'ordinateur portable via 802.11ac.  Le producteur √©crit toutes les 110 ms toutes les 100 ms pour 110 octets de messages dans les sujets d√©sign√©s pour lesquels les consommateurs sont abonn√©s ( <code>concurrencyFactor=500</code> , la validation automatique est d√©sactiv√©e) √† partir de diff√©rents groupes.  Le support est loin d'√™tre id√©al, mais vous pouvez obtenir une image. <br><br>  Un param√®tre de mesure cl√© est l'effet du service sur la latence. <br><br>  Soit: <br>  - t <sub>q</sub> - horodatage du service recevant les messages du client natif <br>  - d <sub>t0</sub> est le temps entre t <sub>q</sub> et le moment o√π le message a √©t√© envoy√© de la file d'attente locale au pool de cadres <br>  - d <sub>t</sub> est le temps entre t <sub>q</sub> et le moment o√π la requ√™te HTTP a √©t√© envoy√©e.  Ce d <sub>t</sub> est l'influence du service sur la latence du message. <br><br>  Au cours des mesures, les r√©sultats suivants ont √©t√© obtenus (C - consommateurs, T - th√®mes, M - messages): <br><br><img src="https://habrastorage.org/webt/p4/r7/pq/p4r7pqavkke1d3glzc7u8o6a5gu.png"><br><br>  En mode de fonctionnement standard, le service lui-m√™me n'affecte presque pas la latence et la consommation de m√©moire est minime.  Les valeurs maximales de d <sub>t</sub> (environ 60 ms) ne sont pas sp√©cifiquement indiqu√©es, car elles d√©pendent du fonctionnement du GC, et non du service lui-m√™me.  Un r√©glage sp√©cial de GC ou le remplacement de G1 par Shenandoah peut aider √† lisser la propagation des valeurs maximales. <br><br>  Tout change radicalement lorsque le consommateur ne g√®re pas le flux de messages de la file d'attente et que le service active le mode de limitation.  Dans ce mode, la consommation de m√©moire augmente, car le temps de r√©ponse aux requ√™tes augmente consid√©rablement, ce qui emp√™che un nettoyage rapide des ressources.  L'effet sur la latence reste ici au niveau des r√©sultats pr√©c√©dents et les valeurs dt √©lev√©es sont caus√©es par le pr√©chargement des messages dans la file d'attente locale. <br><br>  Malheureusement, il n'est pas possible de tester √† une charge plus √©lev√©e, car l'ordinateur portable se plie d√©j√† √† 1300 RPS.  Si quelqu'un peut aider √† l'organisation des mesures √† des charges √©lev√©es, je fournirai volontiers un ensemble pour les tests. <br><br><a name="demo"></a><h1>  D√©monstration </h1><br>  Passons maintenant √† la d√©monstration.  Pour cela, nous avons besoin de: <br><br><ul><li>  Courtier Kafka, pr√™t √† partir.  Je prendrai l'instance d√©clench√©e le 192.168.99.100:9092 de Bitnami. </li><li>  Une ressource HTTP qui recevra des messages.  Pour plus de clart√©, j'ai pris des crochets Web de Slack. </li></ul><br>  Tout d'abord, vous devez augmenter le service Queue-Over-Http lui-m√™me.  Pour ce faire, cr√©ez le contenu suivant dans un r√©pertoire <code>application.yml</code> vide: <br><br><pre> <code class="plaintext hljs">spring: profiles: default logging: level: com: viirrtus: queueOverHttp: DEBUG app: persistence: file: storageDirectory: "persist" brokers: - name: "Kafka" origin: "kafka" config: bootstrap.servers: "192.168.99.100:9092"</code> </pre><br>  Ici, nous indiquons au service les param√®tres de connexion d'un courtier sp√©cifique, ainsi que l'emplacement de stockage des abonn√©s afin qu'ils ne soient pas perdus entre les d√©marrages.  Dans `app.brokers []. Config`, vous pouvez sp√©cifier tous les param√®tres de connexion pris en charge par le client Kafka natif; une liste compl√®te peut √™tre trouv√©e <a href="">ici</a> . <br><br>  Comme le fichier de configuration est trait√© par Spring, vous pouvez y √©crire beaucoup de choses int√©ressantes.  Y compris, configurer la journalisation. <br><br>  Ex√©cutez maintenant le service lui-m√™me.  Nous utilisons le moyen le plus simple - <code>docker-compose.yml</code> : <br><br><pre> <code class="plaintext hljs">version: "2" services: app: image: viirrtus/queue-over-http:0.1.3 restart: unless-stopped command: --debug ports: - "8080:8080" volumes: - ./application.yml:/application.yml - ./persist:/persist</code> </pre><br>  <i>Si cette option ne vous convient pas, vous pouvez compiler le service √† partir de la source.</i>  <i>Instructions d'assemblage dans le projet Readme, dont un lien est donn√© √† la fin de l'article.</i> <br><br>  L'√©tape suivante consiste √† enregistrer le premier abonn√©.  Pour ce faire, vous devez effectuer une demande HTTP aupr√®s du service avec une description du consommateur: <br><br><pre> <code class="plaintext hljs">POST localhost:8080/broker/subscription Content-Type: application/json { "id": "my-first-consumer", "group": { "id": "consumers" }, "broker": "Kafka", "topics": [ { "name": "slack.test", "config": { "concurrencyFactor": 10, "autoCommitPeriodMs": 100 } } ], "subscriptionMethod": { "type": "http", "delayOnErrorMs": 1000, "retryBeforeCommit": 10, "uri": "&lt;slack-wh-uri&gt;", "additionalHeaders": { "Content-Type": "application/json" } } }</code> </pre><br>  Si tout s'est bien pass√©, la r√©ponse sera presque le m√™me contenu envoy√©. <br><br>  Passons en revue chaque param√®tre: <br><br><ul><li>  <code>Consumer.id</code> - ID de notre abonn√© </li><li>  <code>Consumer.group.id</code> - identifiant de groupe </li><li>  <code>Consumer.broker</code> - indiquez √† quels courtiers de services vous devez vous abonner </li><li>  <code>Consumer.topics[0].name</code> - le nom du sujet √† partir duquel nous voulons recevoir des messages </li><li> <code>Consumer.topics[0].config. concurrencyFactor</code>  <code>Consumer.topics[0].config. concurrencyFactor</code> - nombre maximum de messages envoy√©s simultan√©ment </li><li> <code>Consumer.topics[0].config. autoCommitPeriodMs</code>  <code>Consumer.topics[0].config. autoCommitPeriodMs</code> - p√©riode de validation forc√©e pour les messages pr√™ts </li><li>  <code>Consumer.subscriptionMethod.type</code> - type d'abonnement.  Seul HTTP est actuellement disponible. </li><li>  <code>Consumer.subscriptionMethod.delayOnErrorMs</code> - d√©lai avant de renvoyer un message qui s'est termin√© par une erreur </li><li>  <code>Consumer.subscriptionMethod.retryBeforeCommit</code> - le nombre de tentatives pour renvoyer le message d'erreur.  Si 0 - le message tournera jusqu'√† ce que le traitement soit r√©ussi.  Dans notre cas, la garantie d'une livraison compl√®te n'est pas aussi importante que la constance du flux. </li><li>  <code>Consumer.subscriptionMethod.uri</code> - la ressource √† laquelle les messages seront envoy√©s </li><li>  <code>Consumer.subscriptionMethod.additionalHeader</code> - en-t√™tes suppl√©mentaires qui seront envoy√©s avec chaque message.  Notez qu'il y aura du JSON dans le corps de chaque message afin que Slack puisse interpr√©ter correctement la demande. </li></ul><br>  <i>Dans cette demande, la m√©thode HTTP est omise, car la valeur par d√©faut, POST, Slack est assez bonne.</i> <br><br>  √Ä partir de ce moment, le service surveille les partitions affect√©es de la rubrique slack.test pour les nouveaux messages. <br><br>  Pour √©crire des messages sur le sujet, j'utiliserai les utilitaires int√©gr√©s dans Kafka qui se trouvent dans <code>/opt/bitnami/kafka/bin</code> image Kafka lanc√©e (l'emplacement des utilitaires dans d'autres instances de Kafka peut diff√©rer): <br><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list localhost:9092 --topic slack.test &gt; {‚Äútext‚Äù: ‚ÄúHello!‚Äù}</code> </pre><br>  Dans le m√™me temps, Slack vous informera d'un nouveau message: <br><br><img src="https://habrastorage.org/webt/kl/eh/z7/klehz7ev6x1y2eaqpf_ylpnjic4.png"><br><br>  <i>Pour d√©sinscrire un consommateur, il suffit de faire une demande POST de ¬´courtier / d√©sinscrire¬ª avec le m√™me contenu que lors de l'abonnement.</i> <br><br><a name="the-end"></a><h1>  Conclusion </h1><br>  Pour le moment, seule la fonctionnalit√© de base est impl√©ment√©e.  De plus, il est pr√©vu d'am√©liorer le traitement par lots, d'essayer d'impl√©menter une s√©mantique exacte, d'ajouter la possibilit√© d'envoyer des messages au courtier via HTTP et, plus important encore, de prendre en charge d'autres Pub-Sub populaires. <br><br>  Le service Queue-Over-Http est actuellement en cours de d√©veloppement.  La version 0.1.3 est suffisamment stable pour les tests sur les stands de d√©veloppement et de sc√®ne.  Les performances ont √©t√© test√©es sur Windows 10, Debian 9 et Ubuntu 18.04.  Vous pouvez utiliser prod √† vos risques et p√©rils.  Si vous souhaitez aider au d√©veloppement ou donner des commentaires sur le service - bienvenue dans le projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://github.com/viirtus/queue-over-">Github</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr435346/">https://habr.com/ru/post/fr435346/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr435334/index.html">R√©action aux lettres froides</a></li>
<li><a href="../fr435336/index.html">Quelque chose a trouv√©: papiers avec la rencontre Elasticsearch Moscou √† OZON</a></li>
<li><a href="../fr435338/index.html">Nous cr√©ons un syst√®me de chronom√©trage √©lectronique des courses</a></li>
<li><a href="../fr435340/index.html">Un chercheur publie un exemple de code de travail de ver pour Facebook</a></li>
<li><a href="../fr435344/index.html">Amazon a pr√©sent√© Showroom, ou pourquoi nous allons bient√¥t acheter tous les meubles en ligne</a></li>
<li><a href="../fr435348/index.html">Simple MCerver - un petit shell pour le serveur Minecraft</a></li>
<li><a href="../fr435352/index.html">Conf√©rence DEFCON 18. Espionnage pratique avec un t√©l√©phone portable. 2e partie</a></li>
<li><a href="../fr435354/index.html">Conf√©rence DEFCON 18. Espionnage pratique avec un t√©l√©phone portable. Partie 1</a></li>
<li><a href="../fr435358/index.html">Antiquit√©s: Minidisk √† l'√®re de l'iPod</a></li>
<li><a href="../fr435360/index.html">Snippets vs Clover - battez le quiz en temps r√©el le plus populaire</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
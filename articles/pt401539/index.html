<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèΩ ‚òÅÔ∏è üë®üèø‚Äçü§ù‚Äçüë®üèª Teste de estresse da GPU NVidia na transcodifica√ß√£o de transmiss√£o ao vivo üë®üèø‚Äçü§ù‚Äçüë®üèº ‚ùî üï¥üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Abaixo est√° uma hist√≥ria detalhada sobre como carregamos o cart√£o da NVidia com as tarefas de transcodifica√ß√£o de v√≠deo para seu streaming. Vamos most...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Teste de estresse da GPU NVidia na transcodifica√ß√£o de transmiss√£o ao vivo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/401539/">  <i>Abaixo est√° uma hist√≥ria detalhada sobre como carregamos o cart√£o da NVidia com as tarefas de transcodifica√ß√£o de v√≠deo para seu streaming.</i>  <i>Vamos mostrar que tentamos o que aconteceu e qual a melhor forma de usar placas de v√≠deo para transmitir online.</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/files/7ef/cc6/50b/7efcc650b901459bbb5addc4fe8d6bd3.png"></div><a name="habracut"></a>  Por v√°rios anos, nossa equipe desenvolve produtos para processar e distribuir conte√∫do de m√≠dia online.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Este artigo descreveu</a> recentemente por que os propriet√°rios de conte√∫do podem precisar dessas solu√ß√µes em nossa era do YouTube. <br><br>  Um de nossos produtos √© o servidor de m√≠dia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nimble Streamer</a> , que √© um software de servidor que transmite arquivos e transmiss√µes ao vivo para a entrada e os torna acess√≠veis a um grande n√∫mero de espectadores, ao mesmo tempo em que monetiza o conte√∫do.  Este √© um aplicativo nativo escrito em C ++ e portado para todos os SOs populares (Linux, Windows, MacOS) e plataformas (x64, ARM).  Desde o in√≠cio, baixo consumo de recursos e alta produtividade foram os principais requisitos, e conseguimos alcan√ßar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bons resultados</a> nisso. <br><br>  No ano passado, lan√ßamos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">transcodificador</a> Nimble Streamer - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">transmiss√£o ao vivo</a> .  Este aplicativo permite que voc√™ pegue o fluxo de entrada de v√≠deo e / ou √°udio em diferentes formatos e fa√ßa v√°rias convers√µes com eles em tempo real.  A funcionalidade inclui decodifica√ß√£o (software e hardware), convers√£o de v√≠deo e √°udio usando filtros (redimensionamento, sobreposi√ß√£o etc.) e codifica√ß√£o (codifica√ß√£o) - software e hardware. <br><br>  O transcodificador √© controlado pelo servi√ßo da web WMSPanel, e os scripts de transcodifica√ß√£o s√£o criados por meio da interface de arrastar e soltar, que permite visualizar visualmente o processo.  V√°rios cen√°rios podem ser executados juntos - com essa abordagem, √© conveniente executar combina√ß√µes de testes, carregando o servidor em qualquer varia√ß√£o. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nesses v√≠deos,</a> voc√™ pode ver exemplos de como a interface funciona. <br><br>  A decodifica√ß√£o de cada fluxo √© feita apenas uma vez antes de todas as convers√µes adicionais ... Isso permite que voc√™ economize recursos em uma opera√ß√£o de decodifica√ß√£o dispendiosa; isso ser√° visto claramente ao longo dos testes. <br><br>  Um dos mecanismos de convers√£o que pode ser usado em nosso transcodificador √© a decodifica√ß√£o de hardware e a codifica√ß√£o de v√≠deo usando a GPU da NVidia.  As placas gr√°ficas das √∫ltimas gera√ß√µes permitem executar algumas das tarefas t√≠picas, o que remove a carga da CPU.  Nosso transcodificador √© capaz de trabalhar com esse hardware, usado ativamente por nossos clientes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/460/a36/96e/460a3696ed2e4f1e8d7491ecc4e7c2ca.png"></div><br>  No decorrer da comunica√ß√£o com os representantes do escrit√≥rio russo da NVidia, fomos solicitados a tentar organizar testes de estresse conjuntos de nosso transcodificador e GPU NVidia para entender qual o efeito econ√¥mico desse tandem ser√° comparado √† transcodifica√ß√£o exclusiva de software, sem acelera√ß√£o de hardware.  Al√©m disso, queria entender como usar a GPU da melhor maneira poss√≠vel e, se poss√≠vel, fornecer boas receitas. <br><br>  Precis√°vamos obter rapidamente o ferro apropriado e ter acesso a ele, para o ciclo de nossos experimentos.  Planejamos nos encontrar algumas semanas.  Resta descobrir onde obter o equipamento.  A melhor op√ß√£o seria encontr√°-los na nuvem e obter acesso remoto.  Depois de procurar as op√ß√µes, verificou-se que a AWS ainda n√£o possui uma VM com uma GPU da gera√ß√£o Maxwell e, na nuvem do Azure, est√° planejado come√ßar a fornec√™-las em breve. <br><br><h2>  1. Ferro da NVidia na nuvem Softlayer, configurando o Nimble Streamer </h2><br>  Com a assist√™ncia da NVidia, a IBM nos forneceu acesso √† sua nuvem, o IBM Bluemix Cloud Platform (anteriormente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Softlayer</a> ).  Essa √© uma grande rede de data centers modernos (cerca de 50 no momento da publica√ß√£o) em todo o mundo, conectados por uma rede privada comum e fornecendo uma grande variedade de servi√ßos de infraestrutura em nuvem.  Todos os datacenters s√£o unificados e permitem que voc√™ alugue de um a centenas de servidores virtuais ou f√≠sicos da configura√ß√£o necess√°ria por v√°rias horas, bem como balanceadores, sistemas de armazenamento, firewalls - em geral, tudo o que √© necess√°rio para criar uma infraestrutura de TI confi√°vel para o servi√ßo de TI implantado. <br><br>  O escrit√≥rio de representa√ß√£o russo da IBM nos deu acesso total ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">portal de autoatendimento</a> para gerenciar servi√ßos em nuvem e √† configura√ß√£o necess√°ria do servidor, onde pudemos trabalhar com diferentes fluxos de entrada e configura√ß√µes de nosso transcodificador. <br><br><h3>  Ferro </h3><br>  Primeiro, recebemos um servidor f√≠sico (bare-metal) com 128 GB de RAM e 2xGPU NVidia Tesla M60 e o sistema operacional Ubuntu 14.04 pr√©-instalado.  Todos os par√¢metros do servidor, senhas, vers√µes de firmware, sua comuta√ß√£o, IP dedicado, o estado dos componentes de hardware, eram vis√≠veis diretamente em sua conta pessoal, permitindo fazer as manipula√ß√µes necess√°rias com o hardware alugado, o que minimizava a necessidade de intera√ß√£o com o suporte IBM.  Durante a execu√ß√£o do teste, n√£o foi poss√≠vel carregar de maneira ideal essa configura√ß√£o, devido a v√°rias limita√ß√µes na gera√ß√£o de contextos. <br><br>  Quer√≠amos reduzir a configura√ß√£o.  Como usamos a plataforma em nuvem, era necess√°rio, por meio do portal de autoatendimento, solicitar altera√ß√µes na configura√ß√£o.  Ap√≥s a aprova√ß√£o, esta opera√ß√£o levou cerca de 2 horas para a janela de servi√ßo aprovada.  Durante esse per√≠odo, a equipe t√©cnica do data center de Amsterd√£ removeu componentes extras (slots de RAM e 1xGPU) do servidor fornecido anteriormente e o colocou em opera√ß√£o novamente.  Note-se que, para desenvolvedores, essa op√ß√£o √© muito conveniente, pois n√£o h√° necessidade de lidar com as configura√ß√µes de hardware, repar√°-las ou at√© mesmo gastar tempo instalando o sistema operacional.  Deixe-me lembr√°-lo de que, neste caso, o hypervisor n√£o √© usado porque precisamos extrair o m√°ximo de recursos de hardware. <br><br>  Com base nos resultados de nossa pesquisa, decidimos pela seguinte configura√ß√£o de servidor: <br><blockquote>  Intel Dual Xeon E5-2690 v3 (2.60GHz) <br>  24 n√∫cleos <br>  64GB RAM <br>  1 TB SATA <br></blockquote><br>  Temos 2 processadores com 12 n√∫cleos cada e, gra√ßas ao Hyper threading, obtemos o dobro, ou seja,  virtualmente 48 n√∫cleos. <br><br>  Em cen√°rios com acelerador gr√°fico, foi utilizada uma placa baseada no chip GM204 - Tesla M60: <br><blockquote>  NVIDIA Tesla M60 <br>  1xGPU: 2 x Maxwell GM204 <br>  Mem√≥ria: 16GB GDDR5 <br>  Velocidade do rel√≥gio: 2,5 GHz <br>  N√∫cleos NVIDIA CUDA: 2 x 2048 <br>  Largura de banda da mem√≥ria: 2 x 160GB / seg </blockquote><br>  Chamo a aten√ß√£o para o fato de que nenhuma afinidade, ajuste de chip, overclock ou outra m√°gica foi realizada no hardware reduzido - apenas CPUs e GPUs sem overclock e, para a GPU, apenas o driver oficial retirado do site da NVidia foi usado.  Se algu√©m tiver uma experi√™ncia semelhante - compartilhe nos coment√°rios. <br><br>  Ent√£o, n√≥s temos acesso.  Um r√°pido conhecimento da interface da web do painel de controle (tudo √© simples e claro l√°), depois o acesso ao servidor via SSH - e aqui estamos na linha de comando habitual do Ubuntu, coloque o Nimble Streamer, registre uma nova licen√ßa de transcodificador e fa√ßa uma pequena configura√ß√£o. <br><br><h3>  Transceptor √°gil de serpentina </h3><br>  O Nimble Streamer foi configurado para pr√©-criar o cache de contexto da GPU.  Isso se deve ao fato de a GPU ter um limite para o n√∫mero m√°ximo de contextos de decodifica√ß√£o e codifica√ß√£o criados e, al√©m disso, a cria√ß√£o de contextos em tempo real pode levar muito tempo. <br>  Mais detalhes sobre o problema de cria√ß√£o de contextos podem ser encontrados na se√ß√£o correspondente abaixo. <br><br>  Configura√ß√µes de Nimbl no exemplo da primeira s√©rie de testes: <br><blockquote>  nvenc_context_cache_enable = true <br>  nvenc_context_create_lock = true <br>  nvenc_context_cache_init = 0: 30: 15.1: 30: 15 <br>  nvenc_context_reuse_enable = true </blockquote><br>  Mais detalhes sobre essas configura√ß√µes est√£o escritos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">em nosso artigo</a> . <br><br>  Antes de iniciar cada s√©rie de testes, o cache foi configurado separadamente, levando em considera√ß√£o as especificidades de cada tarefa. <br><br><h3>  Criar scripts de transcodifica√ß√£o </h3><br>  Mais trabalho foi realizado em nosso servi√ßo WMSPanel, onde os scripts do transcodificador est√£o configurados. <br><br>  Como j√° mencionado, o trabalho passa pela interface da Web, tudo √© extremamente claro e conveniente.  Criamos v√°rios cen√°rios que combinam diferentes op√ß√µes de transcodifica√ß√£o (CPU / GPU), diferentes op√ß√µes de resolu√ß√£o e diferentes par√¢metros de codifica√ß√£o (CPU / GPU, perfil, taxa de bits etc.) <br><br>  Conjuntos de cen√°rios podem ser executados simultaneamente, o que possibilita introduzir v√°rias combina√ß√µes de testes, aumentar a carga em uma ordem diferente e alter√°-la, dependendo da situa√ß√£o.  Apenas selecione os cen√°rios necess√°rios e pare ou retome-os. <br><br>  Aqui est√° um conjunto de cen√°rios: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/cd6/197/b77/cd6197b77e6b4c0697f43f8d1cfaaf07.png"></div><br>  Aqui est√° um exemplo de um dos cen√°rios: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/e47/1ff/924/e471ff9244f240edb2c092f42d5cf721.png"></div><br>  O decodificador da GPU √© assim: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/382/0f8/2fd/3820f82fd74e4e0ea106534962e1ba28.png"></div><br>  Aplicamos o filtro de tamanho da imagem: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/9d3/bd0/eab/9d3bd0eab2ac47d4b3183aca91db0d6f.png"></div><br>  E aqui est√° o codificador para a variante GPU: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/files/212/d34/e2e/212d34e2e3cf425a9f94d03194f7c62d.png"></div><br><br>  Em geral, a opera√ß√£o da interface do transcodificador pode ser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vista nesses v√≠deos</a> . <br><br><h2>  2. Transcodifica√ß√£o de fluxos FullHD 1080p </h2><br>  Para come√ßar, testamos o cen√°rio com as cargas mais altas para descobrir os limites das capacidades de ferro.  No momento, a "mais pesada" das resolu√ß√µes usadas na pr√°tica √© FullHD 1080p. <br><br>  Para gerar as transmiss√µes ao vivo originais, um arquivo foi obtido em <b>FullHD</b> (1920 * 1080) no <b>H.264 de alto perfil</b> .  O conte√∫do em si √© um tour de v√≠deo da cidade, ou seja,  Este √© um v√≠deo com uma taxa m√©dia de altera√ß√£o de imagem.  N√£o h√° quadros est√°ticos de cor √∫nica que possam facilitar o trabalho do transcodificador, mas n√£o h√° mudan√ßas muito r√°pidas de tipos e cores.  Em uma palavra - uma carga bastante t√≠pica. <br><br>  <b>36 fluxos id√™nticos</b> foram alimentados na entrada Nimble Streamer, que foram usados ‚Äã‚Äãno transcodificador em diferentes cen√°rios. <br><br>  O cen√°rio de transcodifica√ß√£o √© usado normalmente - o fluxo de entrada √© de perfil principal de <b>1080p</b> , <b>720p, 480p, 360p</b> e depois os fluxos de <b>perfil de linha de base</b> s√£o criados a partir dele <b>: 240p, 160p</b> .  No total, h√° 1 fluxo na entrada e 5. Na sa√≠da, geralmente √© realizada uma passagem (transfer√™ncia sem altera√ß√µes) do fluxo original para que o visualizador possa selecionar o pr√≥prio 1080p ao visualizar.  N√≥s n√£o o adicionamos no script, porque  ele n√£o usa transcodifica√ß√£o - h√° uma transfer√™ncia direta de dados da entrada para a sa√≠da.  Esse cen√°rio √© otimizado no Nimble e, em condi√ß√µes reais, aumentar√° o consumo de mem√≥ria relativamente levemente. <br>  √Åudio nos fluxos gerados - n√£o.  A adi√ß√£o de √°udio ao script n√£o causar√° cargas significativas na CPU, mas, para a pureza do experimento, exclu√≠mos o som. <br><br><h3>  Teste de CPU, sem GPU </h3><br>  Para come√ßar, lan√ßamos scripts de transcodifica√ß√£o sem usar uma GPU, especificando decodificador e codificador de software nos scripts. <br><br>  Como resultado, foi poss√≠vel processar apenas 16 fluxos de entrada com a emiss√£o de 80 fluxos de todas as permiss√µes de sa√≠da. <br><br>  Carga da CPU - 4600%, ou seja,  46 n√∫cleos envolvidos.  Consumo de RAM - cerca de 15 GB. <br><br><h3>  Teste de CPU + GPU </h3><br>  O cache de contexto na inicializa√ß√£o √© configurado como 0: 30: 15.1: 30: 15 - ou seja,  30 contextos para codifica√ß√£o, 15 para decodifica√ß√£o, cada GPU. <br><br>  Deixe-me lembr√°-lo de que na GPU temos dois n√∫cleos, o que nos permite paralelizar tarefas - isso √© √∫til para n√≥s. <br><br>  A carga m√°xima foi obtida com a seguinte configura√ß√£o de fluxo. <br><br>  O decodificador de entrada GPU0 e GPU1 - 15 fluxos.  Assim, temos 30 fluxos decodificados, prontos para uso posterior.  Cada fluxo √© decodificado apenas uma vez, independentemente de quantos cen√°rios ele √© usado no futuro. <br><br>  Os codificadores GPU0 e GPU1 foram alimentados com 15 fluxos cada para obter 720p, ou seja,  30 fluxos de 720p em uma sa√≠da resultaram. <br><br>  Al√©m disso, os codificadores GPU0 e GPU1 forneceram 15 fluxos para 480p - e 30 fluxos de 480p tamb√©m foram produzidos. <br><br>  Como os contextos do codificador foram esgotados, a codifica√ß√£o das permiss√µes restantes foi definida na CPU.  O resultado foi o seguinte: <br><br><ol><li>  30 transmiss√µes em 360p </li><li>  30 transmiss√µes 240p </li><li>  30 fluxos 160p </li></ol><br>  A carga acabou sendo de 2600% da CPU, 75% de decodificador e 32% de codificador.  Em seguida, a CPU foi carregada com 6 fluxos para decodifica√ß√£o, para cada 5 resolu√ß√µes semelhantes configuradas, para um total de 30 threads por sa√≠da. <br><br>  No total, <b>36 fluxos</b> foram recebidos <b>na entrada, 180 foram emitidos na sa√≠da</b> .  A carga final √© corrigida da seguinte forma: <b>CPU 4400%, decodificador de cart√£o 75%, codificador de cart√£o 32%, 30 GB de RAM</b> . <br><br><h3>  Alguns detalhes </h3><br>  Decidimos verificar a op√ß√£o em que processamos as tarefas mais dif√≠ceis na GPU - decodifica√ß√£o 1080 e codifica√ß√£o 720 e 480, e deixar o restante ser processado por meio da CPU. <br><br>  Primeiro, verificamos o limite do decodificador.  Com 22 threads, a decodifica√ß√£o foi afetada pelo problema com os contextos, eles simplesmente n√£o puderam ser criados.  Diminu√≠do para 21 - os contextos foram criados, mas a carga se tornou 100% e os artefatos come√ßaram a ser observados no fluxo.  Paramos em 20 fluxos - decodificamos 20 fluxos, codificamos em 160p - tudo funciona bem. <br><br>  Al√©m disso, descobriu-se empiricamente que este cart√£o com 16 GB de RAM a bordo pode trabalhar com confian√ßa em 47 contextos - e n√£o h√° diferen√ßa, esses s√£o os contextos de um codificador ou decodificador.  Repito - isso √© especificamente sobre esta GPU Tesla M60, em outros cart√µes esse n√∫mero pode ser diferente.  Acreditamos que, se o cart√£o tivesse 24 GB de RAM, o n√∫mero de contextos poderia ser diferente, mas isso precisa ser testado. <br><br>  Como resultado, escolhemos a f√≥rmula de cria√ß√£o de cache "15 contextos do decodificador e 30 contextos do codificador" - que fornece 30 fluxos para a entrada e para cada um permite criar 2 permiss√µes.  Portanto, as resolu√ß√µes superiores - 720 e 480 - foram lan√ßadas na GPU, e as demais - 360, 240 e 160 - foram enviadas para a CPU.  E como a CPU ainda estava livre depois disso, "finalizamos" os n√∫cleos livres com novos threads, deixando 4 n√∫cleos para tarefas utilit√°rias. <br><br><h2>  3. Transcodifica√ß√£o de fluxos HD 720p </h2><br>  Cen√°rio de carregamento t√≠pico  A maior parte do conte√∫do agora √© criada em HD.  At√© o recente SuperBowl LI - o programa de maior audi√™ncia do mercado americano - foi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">transmitido em HD</a> , deixando o FullHD para o futuro. <br><br>  Para gerar os fluxos de origem, um arquivo foi obtido em <b>HD</b> (1280 * 720) em um <b>perfil alto</b> .  O conte√∫do √© a s√©rie "The Good Wife" favorita do nosso engenheiro, ou seja,  Este √© um v√≠deo com uma taxa m√©dia de altera√ß√£o de imagem. <br><br>  Na entrada do Nimble Streamer, 70 fluxos id√™nticos foram alimentados, que foram ent√£o usados ‚Äã‚Äãno transcodificador em diferentes cen√°rios. <br><br>  O cen√°rio de transcodifica√ß√£o a seguir √© usado - o fluxo de entrada √© <b>720p de</b> alto perfil, <b>480p, perfil principal de 360p</b> e, em seguida <b>,</b> s√£o feitos fluxos de perfil de <b>linha de base de 240p e 160p</b> .  Total, na entrada 1, na sa√≠da 4. A passagem do fluxo original, como no cen√°rio anterior, n√£o foi executada.  O √°udio nos fluxos gerados tamb√©m n√£o √©. <br><br><h3>  Teste de CPU, sem GPU </h3><br>  Como na se√ß√£o anterior, tentamos transcodificar fluxos apenas na CPU.  Como resultado, foi poss√≠vel processar apenas 22 fluxos de entrada com a emiss√£o de 88 fluxos de todas as permiss√µes de sa√≠da.  Carga da CPU - 4700%, ou seja,  47 n√∫cleos estavam envolvidos.  Consumo de RAM - cerca de 20 GB. <br><br><h3>  Teste de CPU + GPU </h3><br>  O cache de contexto na inicializa√ß√£o √© configurado como 0: 23: 23.1: 23: 23 - ou seja,  23 contextos para codifica√ß√£o, 23 para decodifica√ß√£o para cada GPU. <br><br>  Usando a GPU, 46 fluxos de 720p foram decodificados.  L√°, na GPU, 46 fluxos de 480p foram codificados.  Em seguida, as codifica√ß√µes 360p, 240p e 160p foram realizadas na CPU - 46 fluxos cada. <br>  Carga fixa de 2100% da CPU, 61% do decodificador, 16% do codificador. <br><br>  Al√©m disso, foi iniciada a codifica√ß√£o e decodifica√ß√£o de 24 threads na CPU, para cada 1 thread - 4 sa√≠das, como para a GPU. <br><br>  Ao todo, <b>70 fluxos foram inseridos, 280 fluxos foram gerados</b> . <br>  Carga: <b>4600%, 61% do decodificador, 16% do codificador, 30 GB de RAM</b> . <br><br>  Quanto ao teste anterior, talvez uma GPU de RAM maior daria mais contextos e poder√≠amos lidar com mais threads.  Mas isso √© apenas na teoria, √© necess√°rio verificar. <br><br><h2>  4. O problema com a cria√ß√£o de contextos na GPU NVidia </h2><br>  Algumas palavras sobre o problema que n√£o nos permitiram processar mais threads na GPU. <br><br>  No final do ano passado, realizamos testes com a equipe da NVidia, com v√°rias placas.  Ao trabalhar com v√°rias GPUs, descobriu-se que a cria√ß√£o de contextos diminui bastante o servidor - a cria√ß√£o de cada novo contexto leva cada vez mais tempo no mapa.  Se o primeiro contexto foi criado na ordem de 300ms, cada um subsequente adicionou 200-300ms e j√° nos terceiros dez contextos, criando um novo, levando de 3 a 4 segundos cada.  Quando um usu√°rio cria um script de transcodifica√ß√£o, sup√µe-se que ele comece a trabalhar imediatamente e sem atrasos, e essa nova circunst√¢ncia negou todas as vantagens na velocidade do Nimbl e atrasou a cria√ß√£o de contextos que levaram a atrasos no in√≠cio da codifica√ß√£o. <br><br>  No in√≠cio, a suspeita caiu no Nimble, mas depois fizemos testes usando o ffmpeg, que a pr√≥pria NVidia fornece aos clientes e o resultado foi exatamente o mesmo - a GPU est√° gastando cada vez mais tempo criando cada novo contexto.  Em condi√ß√µes em que o servidor j√° est√° transcodificando e voc√™ precisa iniciar novos encadeamentos para processamento, isso afeta o desempenho geral e torna o servidor simplesmente inutiliz√°vel. <br><br>  O problema foi descrito em detalhes pela equipe da NVidia, mas at√© agora nenhuma solu√ß√£o em tempo integral foi fornecida.  Portanto, at√© o momento, implementamos um mecanismo de cache de contexto em nosso servidor, com a cria√ß√£o preliminar de contextos no in√≠cio do servidor.  Isso resolveu o problema do ponto de vista do trabalho do usu√°rio final, mas o in√≠cio do Nimbl pode levar algum tempo.  A configura√ß√£o do Nimbl para um trabalho eficaz com contextos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">√© descrita em nosso blog</a> . <br><br>  Al√©m disso, os contextos n√£o s√£o f√°ceis de criar.  Com um grande n√∫mero de contextos ao incluir qualquer script de transcodifica√ß√£o, a API NVENC come√ßa a gerar erros: "A chamada da API falhou porque n√£o foi poss√≠vel alocar mem√≥ria suficiente para executar a opera√ß√£o solicitada". <br><br>  Empiricamente, descobriu-se que uma GPU pode iniciar e trabalhar com confian√ßa em 47 contextos - e n√£o h√° diferen√ßa, esses s√£o os contextos de um codificador ou decodificador.  Havia uma suposi√ß√£o de que isso se deve √† quantidade de mem√≥ria na GPU.  Agora existem 16 GB, se voc√™ colocar um cart√£o com 24 GB, √© prov√°vel que mais contextos possam ser feitos.  Mas isso √© apenas uma teoria, √© necess√°rio verificar, como mencionado anteriormente.  Os dados obtidos s√£o v√°lidos para um modelo de GPU espec√≠fico; outros cart√µes devem ser testados separadamente. <br><br>  √â a restri√ß√£o do n√∫mero de contextos que coloca o principal obst√°culo ao trabalhar com grandes cargas. <br><br><h2>  5. Conclus√µes </h2><br>  Portanto, o objetivo do teste era estudar a efic√°cia da GPU para o intervalo indicado de tarefas e desenvolver receitas para seu uso adequado.  Qual √© o resultado? <br><br><h3>  Efeito econ√¥mico </h3><br>  Acima, vimos como o n√∫mero de threads que podem ser processados ‚Äã‚Äãna CPU e no conjunto CPU + GPU √© diferente.  Vamos ver o que isso significa em termos de dinheiro.  Como base, adotamos todos os mesmos pre√ßos da Softlayer e de aluguel de equipamentos. <br><br><ul><li>  A configura√ß√£o sem uma GPU custar√° <b>US $ 819 por m√™s</b> .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aqui voc√™ pode pegar um</a> carro. </li><li>  A configura√ß√£o com a GPU custar√° <b>US $ 1729 por m√™s</b> para o data center em Amsterd√£. Os pre√ßos podem ser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">encontrados aqui</a> .  Ao usar uma GPU, o pre√ßo do aluguel do servidor aumenta um pouco, pois √© usado o fator de forma da caixa 2U maior.  O efeito econ√¥mico provavelmente ser√° maior na compra de equipamentos (mas isso requer uma an√°lise s√©ria do custo total de propriedade, levando em considera√ß√£o a atualiza√ß√£o constante da linha de GPU NVidia). </li></ul><br>  Agora vamos ver os resultados do teste: <br><br>  Para FullHD 1080p <br><br><ul><li>  CPU sem GPU: 16 threads por entrada + 80 threads por sa√≠da </li><li>  CPU + GPU: 36 threads por entrada + 180 por sa√≠da </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Benef√≠cio da GPU: 2,25x. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Benef√≠cios</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> do uso da GPU: US $ 819 * 2,25 - US $ 1729 = </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">US $ 113 por m√™s</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ao alugar um servidor com uma GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para HD 720p</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU sem GPU: 22 threads por entrada + 88 threads por sa√≠da </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CPU + GPU: 70 threads por entrada + 280 por sa√≠da </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Benef√≠cio da GPU: 3.18x. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beneficie-se</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> do uso da GPU: US $ 819 * 3,18 - US $ 1729 = </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">US $ 875 por m√™s</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ao alugar um servidor com uma GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ou seja, com a op√ß√£o de aluguel, as economias s√£o bastante vis√≠veis. Isso n√£o leva em considera√ß√£o os descontos - no escrit√≥rio russo da IBM eles prometem descontos no aluguel de recursos na nuvem em compara√ß√£o com os pre√ßos apresentados aqui. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N√£o entramos nas op√ß√µes com a compra, porque aqui, o custo total de propriedade depende fortemente da escolha do fornecedor, do custo do servi√ßo no data center e de outros fatores familiares √†queles que trabalham com bare metal. No entanto, os n√∫meros preliminares tamb√©m falam em favor de uma solu√ß√£o baseada em GPU.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Al√©m disso, n√£o se esque√ßa do tr√°fego e da largura do canal - eles est√£o inclu√≠dos em uma certa quantia nas tarifas apresentadas acima, mas voc√™ precisar√° selecionar op√ß√µes para suas tarefas com base no n√∫mero de threads, no n√∫mero esperado de usu√°rios etc. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dimensionamento </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A op√ß√£o com uma placa gr√°fica por servidor nos parece mais econ√¥mica do que a op√ß√£o com duas ou mais placas. Como podemos ver, o decodificador da GPU sempre carregava mais do que o codificador, mas mesmo assim permaneceu sobrecarregado devido a problemas com o uso de contextos. Se voc√™ adicionar uma segunda placa, o decodificador ser√° usado ainda menos, os codificadores que n√£o poderemos carregar com capacidade total e todo o trabalho na codifica√ß√£o ainda precisar√° ser transferido para a CPU, que ser√° injustificada pelo dinheiro. Tamb√©m testamos a op√ß√£o com duas GPUs gra√ßas ao suporte do Softlayer, mas devido ao fraco efeito econ√¥mico, n√£o fornecemos detalhes no artigo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Assim, para escalar a carga, √© prefer√≠vel adicionar novos servidores com uma placa gr√°fica do que adicionar placas √†s m√°quinas existentes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se o n√∫mero de fluxos de entrada e sa√≠da do seu projeto for relativamente pequeno - digamos, uma d√∫zia de fluxos de HD com um pequeno n√∫mero de permiss√µes de sa√≠da, com uma quantidade relativamente pequena de filtragem, seria mais conveniente usar um servidor sem uma GPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tamb√©m √© importante notar que a quantidade de RAM para a tarefa de convers√£o de threads n√£o √© t√£o importante quanto a capacidade de processamento. Portanto, em alguns casos, voc√™ tamb√©m pode economizar reduzindo a quantidade de mem√≥ria.</font></font><br><br><h3>  Conclus√£o </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A solu√ß√£o de hardware apresentada - uma combina√ß√£o da CPU e GPU Tesla M60 - foi perfeita para transcodificar fluxos ao vivo sob cargas pesadas. </font><font style="vertical-align: inherit;">A GPU cuida das opera√ß√µes que consomem mais recursos - decodificando os fluxos e codificando-os nas resolu√ß√µes mais altas, enquanto as resolu√ß√µes m√©dias e pequenas s√£o bem processadas na CPU. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se um dos leitores tiver experi√™ncia e otimizar o desempenho das placas gr√°ficas para transmiss√£o ao vivo, teremos o maior prazer em conhecer sua experi√™ncia - escreva nos coment√°rios.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt401539/">https://habr.com/ru/post/pt401539/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt401527/index.html">Como as unidades √≥pticas degradam</a></li>
<li><a href="../pt401529/index.html">Pergunte a Ethan: o universo pode ser considerado vivo?</a></li>
<li><a href="../pt401531/index.html">No √¢mbito do projeto ‚ÄúCi√™ncia n√£o √© farinha‚Äù, ser√° realizada uma discuss√£o sobre o tema: ‚ÄúSexo, drogas, rock and roll: depend√™ncia ou vida?‚Äù</a></li>
<li><a href="../pt401533/index.html">Dificuldades na escolha de uma placa de v√≠deo de or√ßamento no exemplo da RX 460</a></li>
<li><a href="../pt401535/index.html">Col√¥nia. Cap√≠tulo 4: a antiga base militar</a></li>
<li><a href="../pt401541/index.html">50 tons de toco * Recep√ß√£o de hardware de sinais codificados em PWM por microcontroladores Microchip</a></li>
<li><a href="../pt401543/index.html">Usando conjuntos de dados do portal de dados abertos russo data.gov.ru</a></li>
<li><a href="../pt401545/index.html">Chef, vejo voc√™. Intel Unite - Ferramenta de comunica√ß√£o profissional</a></li>
<li><a href="../pt401549/index.html">Estados ex√≥ticos da mat√©ria, LCDs e o futuro da √°gua</a></li>
<li><a href="../pt401555/index.html">Os rob√¥s dom√©sticos mais √∫teis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
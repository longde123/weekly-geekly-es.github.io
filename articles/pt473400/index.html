<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•£ üë®üèø üôãüèΩ Tecnologia Text-to-Speech de alta qualidade, leve e adapt√°vel usando LPCNet üïí ü§£ üßúüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Os recentes avan√ßos na aprendizagem profunda trazem melhorias significativas para o desenvolvimento de sistemas de s√≠ntese de fala (doravante, TTS). I...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tecnologia Text-to-Speech de alta qualidade, leve e adapt√°vel usando LPCNet</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/473400/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/v_/5k/ko/v_5kkoibb8w2atlmcuqxhhgj7tc.jpeg"></div><br>  Os recentes avan√ßos na aprendizagem profunda trazem melhorias significativas para o desenvolvimento de sistemas de s√≠ntese de fala (doravante, TTS).  Isso se deve ao uso de m√©todos mais eficazes e r√°pidos de estudar a voz e o estilo dos alto-falantes, bem como √† s√≠ntese de um discurso mais natural e de alta qualidade. <a name="habracut"></a><br><br>  No entanto, para conseguir isso, a maioria dos sistemas TTS deve usar modelos de redes neurais grandes e complexos que s√£o dif√≠ceis de treinar e que n√£o permitem a s√≠ntese de fala em tempo real, mesmo com GPUs. <br><br>  Para resolver esses problemas, nossa equipe do IBM Research AI desenvolveu um novo m√©todo de s√≠ntese de redes neurais com base em uma arquitetura modular.  Este m√©todo combina tr√™s redes neurais profundas (doravante denominadas DNN) com o processamento intermedi√°rio de seus sinais de sa√≠da.  Apresentamos este trabalho em nosso artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">‚ÄúTecnologia TTS de alta qualidade, leve e adapt√°vel usando LPCNet‚Äù</a> na Interspeech 2019. A arquitetura TTS √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">leve</a> e pode sintetizar discurso de alta qualidade em tempo real.  Cada rede √© especializada em v√°rios aspectos da voz do falante, o que permite treinar efetivamente qualquer componente independentemente dos outros. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rk/w9/77/rkw977a1ljeapkrqgj4a29rywp8.jpeg" width="45%"></div><br>  <font color="gray">Diagrama 1. Arquitetura do sistema TTS</font> <br><br>  Outra vantagem de nossa abordagem √© que, depois de treinar as redes principais, elas podem ser facilmente adaptadas a um novo estilo de fala ou voz, mesmo em pequenos volumes de dados de treinamento, por exemplo, para fins de marca e personaliza√ß√£o. <br><br>  No processo de s√≠ntese, √© usado um m√≥dulo de interface para um idioma espec√≠fico, que converte o texto de entrada em uma sequ√™ncia de recursos lingu√≠sticos.  Em seguida, os seguintes DNNs s√£o aplicados um ap√≥s o outro: <br><br><h2>  1. Previs√£o de pros√≥dia </h2><br>  Os recursos pros√≥dicos da fala s√£o apresentados como um vetor quadridimensional por unidade TTS (aproximadamente um ter√ßo das condi√ß√µes sonoras de acordo com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SMM</a> (modelo Markov oculto)), que inclui dura√ß√£o do log, log-pitch inicial e final, al√©m de log-energy.  Esses recursos s√£o determinados durante o processo de treinamento, para que possam ser previstos pelos recursos do texto recebido pela interface durante a s√≠ntese.  A pros√≥dia √© extremamente importante n√£o apenas para que a fala pare√ßa natural e viva, mas tamb√©m para que os dados destinados ao treinamento ou adapta√ß√£o tenham o reflexo mais completo do estilo de fala do falante.  A adapta√ß√£o da pros√≥dia √† voz do locutor √© baseada no Variational Auto Encoder (VAE). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/v6/em/9c/v6em9cvo5cya0ikupkey3tj-grw.jpeg"></div><br>  <font color="gray">Esquema 2. Treinamento e reciclagem do gerador de pros√≥dia</font> <br><br><h2>  2. Previs√£o de caracter√≠sticas ac√∫sticas </h2><br>  Os vetores de caracter√≠sticas ac√∫sticas fornecem uma representa√ß√£o espectral da fala em quadros curtos de 10 milissegundos a partir dos quais o som real pode ser gerado.  As caracter√≠sticas ac√∫sticas s√£o determinadas no processo de aprendizagem e podem ser previstas por marcas fon√©ticas e pros√≥dia durante a s√≠ntese. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ne/kw/dlnekwkvezjgkqfgeaeqzp49g9s.jpeg" width="45%"></div><br>  <font color="gray">Esquema 3. Sintetizador de rede</font> <br><br>  O modelo DNN criado √© de dados de √°udio (locutor de voz), necess√°rios para treinamento ou adapta√ß√£o.  A arquitetura do modelo consiste em camadas convolucionais e recorrentes, projetadas para extrair as depend√™ncias locais de contexto e tempo na sequ√™ncia de sons e estrutura de tons.  O DNN prev√™ caracter√≠sticas ac√∫sticas de sua primeira e segunda derivada.  Isso √© seguido pelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">m√©todo de m√°xima verossimilhan√ßa</a> e s√£o aplicados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">filtros formantes</a> que ajudam a gerar um discurso com melhor som. <br><br><h2>  3. Vocoder neural </h2><br>  Um vocoder neural √© respons√°vel por gerar fala a partir de recursos ac√∫sticos.  Ele aprende com os padr√µes naturais de fala do palestrante, dadas as respectivas caracter√≠sticas.  Tecnicamente, fomos os primeiros a usar um novo vocoder neural leve, de alta qualidade, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">chamado LPCNet,</a> em um sistema TTS totalmente comercializado. <br><br>  A novidade desse codificador de voz √© que ele n√£o tenta prever um sinal de fala complexo diretamente usando DNN.  Em vez disso, o DNN prev√™ apenas o sinal de caminho de voz residual menos complexo e, em seguida, usa os filtros Linear Predictive Coding (LPC) para convert√™-lo no sinal de voz final. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9l/kv/g-/9lkvg-df4fiacjp2b7rz0xhguyu.jpeg" width="45%"></div><br>  <font color="gray">Esquema 4. Vocoder neural LPCNet</font> <br><br><h2>  Adapta√ß√£o de voz </h2><br>  A adapta√ß√£o √† voz √© facilmente alcan√ßada atrav√©s da reciclagem de tr√™s redes com base em uma pequena quantidade de dados de √°udio do alto-falante alvo.  Em nosso artigo, apresentamos os resultados de experimentos de adapta√ß√£o em termos de qualidade da fala e sua similaridade com a fala do verdadeiro orador.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Esta p√°gina</a> tamb√©m mostra exemplos de adapta√ß√£o a oito alto-falantes diferentes do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VCTK</a> (Voice Cloning Toolkit), dos quais 4 s√£o homens e 4 s√£o mulheres. <br><br><h2>  Resultados da Audi√ß√£o </h2><br>  A figura abaixo mostra os resultados dos testes de audi√ß√£o dos padr√µes de fala sintetizados e naturais dos alto-falantes do VCTK.  Os valores do Average Opinion Score (MOS) s√£o baseados na an√°lise da qualidade da fala dos ouvintes em uma escala de 1 a 5. A similaridade entre pares de amostras foi avaliada pelos alunos em uma escala de 1 a 4. <br><br>  Medimos a qualidade da fala sintetizada, bem como sua semelhan√ßa com a fala dos falantes "ao vivo", comparando as vozes adaptadas de mulheres e homens com dura√ß√£o de 5, 10 e 20 minutos com a fala natural dos falantes. <br><br>  Os resultados dos testes mostram que podemos manter alta qualidade e alta similaridade com o original, mesmo para vozes que foram treinadas em exemplos de cinco minutos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fq/po/qt/fqpoqtpahytf2tg-msyed-hkytk.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zq/us/vc/zqusvcokvvj3csrwj63g9h9eave.jpeg"></div><br>  <font color="gray">Diagrama 5. Resultados dos testes de qualidade e similaridade</font> <br><br>  Este trabalho foi realizado pelo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">IBM Watson</a> e serviu de base para um novo release do servi√ßo IBM Watson TTS com qualidade de voz aprimorada (consulte as vozes "* V3" na demonstra√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">IBM Watson TTS</a> ). <br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt473400/">https://habr.com/ru/post/pt473400/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt473384/index.html">3DToday Fest: como foi (ser√°). Impress√µes dos membros</a></li>
<li><a href="../pt473390/index.html">FDM est√° vivo</a></li>
<li><a href="../pt473392/index.html">Como lan√ßamos um novo site banc√°rio. Parte 2</a></li>
<li><a href="../pt473394/index.html">Todos voc√™s est√£o mentindo! Sobre a publicidade em CRM</a></li>
<li><a href="../pt473396/index.html">Precisamos de outra bitrix</a></li>
<li><a href="../pt473406/index.html">Maratona gr√°tis "Ci√™ncia de dados e IA: ensine a m√°quina a escrever o roteiro da s√©rie"</a></li>
<li><a href="../pt473408/index.html">Depurando vazamentos de mem√≥ria oculta no Ruby</a></li>
<li><a href="../pt473412/index.html">Criando um Plug-in para o Clang Static Analyzer para Procurar Estouros Inteiros</a></li>
<li><a href="../pt473416/index.html">Programa da Confer√™ncia ZeroNights 2019</a></li>
<li><a href="../pt473418/index.html">OSCP - Seguran√ßa Ofensiva</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
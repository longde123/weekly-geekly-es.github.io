<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôáüèø ‚õ∑Ô∏è üéø Iniciando o Cluster RabbitMQ no Kubernetes ‚è≤Ô∏è üõ∞Ô∏è üë´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="No caso da organiza√ß√£o de microsservi√ßos do aplicativo, um trabalho substancial baseia-se nos mecanismos de comunica√ß√£o de integra√ß√£o de microsservi√ßo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Iniciando o Cluster RabbitMQ no Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/true_engineering/blog/419817/">  No caso da organiza√ß√£o de microsservi√ßos do aplicativo, um trabalho substancial baseia-se nos mecanismos de comunica√ß√£o de integra√ß√£o de microsservi√ßos.  Al√©m disso, essa integra√ß√£o deve ser tolerante a falhas, com um alto grau de disponibilidade. <br><br>  Em nossas solu√ß√µes, usamos a integra√ß√£o com Kafka, gRPC e RabbitMQ. <br><br>  Neste artigo, compartilharemos nossa experi√™ncia de agrupar o RabbitMQ, cujos n√≥s est√£o hospedados no Kubernetes. <br><br><img src="https://habrastorage.org/webt/dx/ll/-h/dxll-hzomoco0zcfp7esju8pena.jpeg" alt="imagem"><br><br>  Antes do RabbitMQ vers√£o 3.7, agrup√°-lo no K8S n√£o era uma tarefa muito trivial, com muitos hacks e solu√ß√µes n√£o muito bonitas.  Na vers√£o 3.6, foi usado um plugin de autocluster da RabbitMQ Community.  E em 3.7 o Kubernetes Peer Discovery Backend apareceu.  Ele √© incorporado pelo plug-in na entrega b√°sica do RabbitMQ e n√£o requer montagem e instala√ß√£o separadas. <br><br>  Vamos descrever a configura√ß√£o final como um todo, enquanto comentamos o que est√° acontecendo. <br><a name="habracut"></a><br><h2>  Em teoria </h2><br>  O plugin possui um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reposit√≥rio no github</a> , no qual h√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um exemplo de uso b√°sico</a> . <br>  Este exemplo n√£o se destina √† Produ√ß√£o, que est√° claramente indicado em sua descri√ß√£o e, al√©m disso, algumas das configura√ß√µes nele s√£o contr√°rias √† l√≥gica de uso no produto.  Al√©m disso, no exemplo, a persist√™ncia do armazenamento n√£o √© mencionada, portanto, em qualquer situa√ß√£o de emerg√™ncia, nosso cluster se tornar√° um zilch. <br><br><h2>  Na pr√°tica </h2><br>  Agora, mostraremos o que voc√™ enfrentou e como instalar e configurar o RabbitMQ. <br><br>  Vamos descrever as configura√ß√µes de todas as partes do RabbitMQ como um servi√ßo nos K8s.  Esclareceremos imediatamente que instalamos o RabbitMQ no K8s como um StatefulSet.  Em cada n√≥ do cluster K8s, uma inst√¢ncia do RabbitMQ sempre funcionar√° (um n√≥ na configura√ß√£o cl√°ssica do cluster).  Tamb√©m instalaremos o painel de controle RabbitMQ no K8s e daremos acesso a esse painel fora do cluster. <br><br><h3>  Direitos e fun√ß√µes: </h3><br><div class="spoiler">  <b class="spoiler_title">rabbitmq_rbac.yaml</b> <div class="spoiler_text"><pre><code class="plaintext hljs">--- apiVersion: v1 kind: ServiceAccount metadata: name: rabbitmq --- kind: Role apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: endpoint-reader rules: - apiGroups: [""] resources: ["endpoints"] verbs: ["get"] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: endpoint-reader subjects: - kind: ServiceAccount name: rabbitmq roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: endpoint-reader</code> </pre> </div></div><br>  Os direitos de acesso ao RabbitMQ s√£o retirados inteiramente do exemplo, n√£o s√£o necess√°rias altera√ß√µes neles.  Criamos uma ServiceAccount para nosso cluster e concedemos permiss√µes de leitura para os Endpoints K8s. <br><br><h3>  Armazenamento persistente: </h3><br><div class="spoiler">  <b class="spoiler_title">rabbitmq_pv.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">kind: PersistentVolume apiVersion: v1 metadata: name: rabbitmq-data-sigma labels: type: local annotations: volume.alpha.kubernetes.io/storage-class: rabbitmq-data-sigma spec: storageClassName: rabbitmq-data-sigma capacity: storage: 10Gi accessModes: - ReadWriteMany persistentVolumeReclaimPolicy: Recycle hostPath: path: "/opt/rabbitmq-data-sigma"</code> </pre> </div></div><br>  Aqui consideramos o caso mais simples como o armazenamento persistente - hostPath (uma pasta comum em cada n√≥ do K8s), mas voc√™ pode usar qualquer um dos muitos tipos de volumes persistentes suportados pelo K8s. <br><br><div class="spoiler">  <b class="spoiler_title">rabbitmq_pvc.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">kind: PersistentVolumeClaim apiVersion: v1 metadata: name: rabbitmq-data spec: storageClassName: rabbitmq-data-sigma accessModes: - ReadWriteMany resources: requests: storage: 10Gi</code> </pre> </div></div><br>  Criar reivindica√ß√£o de volume no volume criado na etapa anterior.  Essa declara√ß√£o ser√° usada no StatefulSet como um armazenamento de dados persistente. <br><br><h3>  Servi√ßos: </h3><br><div class="spoiler">  <b class="spoiler_title">rabbitmq_service.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">kind: Service apiVersion: v1 metadata: name: rabbitmq-internal labels: app: rabbitmq spec: clusterIP: None ports: - name: http protocol: TCP port: 15672 - name: amqp protocol: TCP port: 5672 selector: app: rabbitmq</code> </pre> </div></div><br>  Criamos um servi√ßo interno sem cabe√ßa, atrav√©s do qual o plugin Peer Discovery funcionar√°. <br><br><div class="spoiler">  <b class="spoiler_title">rabbitmq_service_ext.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">kind: Service apiVersion: v1 metadata: name: rabbitmq labels: app: rabbitmq type: LoadBalancer spec: type: NodePort ports: - name: http protocol: TCP port: 15672 targetPort: 15672 nodePort: 31673 - name: amqp protocol: TCP port: 5672 targetPort: 5672 nodePort: 30673 selector: app: rabbitmq</code> </pre> </div></div><br>  Para aplicativos nos K8s funcionarem com nosso cluster, criamos um servi√ßo de balanceador. <br><br>  Como precisamos acessar o cluster RabbitMQ fora dos K8s, passamos pelo NodePort.  O RabbitMQ estar√° dispon√≠vel ao acessar qualquer n√≥ do cluster K8s nas portas 31673 e 30673. No trabalho real, n√£o h√° grande necessidade disso.  A quest√£o da conveni√™ncia de usar o painel de administra√ß√£o do RabbitMQ. <br><br>  Ao criar um servi√ßo com o tipo NodePort no K8s, tamb√©m √© criado implicitamente um servi√ßo com o tipo ClusterIP para atend√™-lo.  Portanto, aplicativos em K8s que precisam trabalhar com o RabbitMQ poder√£o acessar o cluster em <i>amqp: // rabbitmq: 5672</i> <br><br><h3>  Configura√ß√£o: </h3><br><div class="spoiler">  <b class="spoiler_title">rabbitmq_configmap.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">apiVersion: v1 kind: ConfigMap metadata: name: rabbitmq-config data: enabled_plugins: | [rabbitmq_management,rabbitmq_peer_discovery_k8s]. rabbitmq.conf: | cluster_formation.peer_discovery_backend = rabbit_peer_discovery_k8s cluster_formation.k8s.host = kubernetes.default.svc.cluster.local cluster_formation.k8s.port = 443 ### cluster_formation.k8s.address_type = ip cluster_formation.k8s.address_type = hostname cluster_formation.node_cleanup.interval = 10 cluster_formation.node_cleanup.only_log_warning = true cluster_partition_handling = autoheal queue_master_locator=min-masters cluster_formation.randomized_startup_delay_range.min = 0 cluster_formation.randomized_startup_delay_range.max = 2 cluster_formation.k8s.service_name = rabbitmq-internal cluster_formation.k8s.hostname_suffix = .rabbitmq-internal.our-namespace.svc.cluster.local</code> </pre> </div></div><br>  Criamos arquivos de configura√ß√£o do RabbitMQ.  A principal magia. <br><br><pre> <code class="plaintext hljs">enabled_plugins: | [rabbitmq_management,rabbitmq_peer_discovery_k8s].</code> </pre><br>  Adicione os plugins necess√°rios aos permitidos para download.  Agora podemos usar a descoberta autom√°tica de pares no K8S. <br><br><pre> <code class="plaintext hljs">cluster_formation.peer_discovery_backend = rabbit_peer_discovery_k8s</code> </pre><br>  N√≥s expomos o plug-in necess√°rio como um back-end para a descoberta de pares. <br><br><pre> <code class="plaintext hljs">cluster_formation.k8s.host = kubernetes.default.svc.cluster.local cluster_formation.k8s.port = 443</code> </pre><br>  Especifique o endere√ßo e a porta atrav√©s da qual voc√™ pode acessar o kubernetes apiserver.  Aqui voc√™ pode especificar o endere√ßo IP diretamente, mas ser√° mais bonito faz√™-lo. <br><br>  No padr√£o do espa√ßo para nome, geralmente √© criado um servi√ßo com o nome kubernetes que leva ao k8-apiserver.  Em diferentes op√ß√µes de instala√ß√£o do K8S, o namespace, o nome do servi√ßo e a porta podem ser diferentes.  Se algo em uma instala√ß√£o espec√≠fica for diferente, voc√™ precisar√° corrigi-lo adequadamente. <br><br>  Por exemplo, somos confrontados com o fato de que em alguns clusters o servi√ßo est√° na porta 443 e em alguns na 6443. Ser√° poss√≠vel entender que algo est√° errado nos logs de inicializa√ß√£o do RabbitMQ, o tempo de conex√£o com o endere√ßo especificado aqui est√° claramente destacado. <br><br><pre> <code class="plaintext hljs">### cluster_formation.k8s.address_type = ip cluster_formation.k8s.address_type = hostname</code> </pre><br>  Por padr√£o, o exemplo especificou o tipo de endere√ßo do n√≥ do cluster RabbitMQ pelo endere√ßo IP.  Mas quando voc√™ reinicia o pod, ele obt√©m um novo IP sempre.  Surpresa!  O aglomerado est√° morrendo em agonia. <br><br>  Mude o endere√ßamento para hostname.  O StatefulSet nos garante a invariabilidade do nome do host no ciclo de vida de todo o StatefulSet, o que nos conv√©m completamente. <br><br><pre> <code class="plaintext hljs">cluster_formation.node_cleanup.interval = 10 cluster_formation.node_cleanup.only_log_warning = true</code> </pre><br>  Como quando perdemos um dos n√≥s, assumimos que ele se recuperar√° mais cedo ou mais tarde, desabilitamos a exclus√£o autom√°tica por um cluster de n√≥s inacess√≠veis.  Nesse caso, assim que o n√≥ voltar online, ele entrar√° no cluster sem perder o estado anterior. <br><br><pre> <code class="plaintext hljs">cluster_partition_handling = autoheal</code> </pre> <br>  Este par√¢metro determina as a√ß√µes do cluster em caso de perda de quorum.  Aqui voc√™ s√≥ precisa ler a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o sobre este t√≥pico</a> e entender por si mesmo o que est√° mais pr√≥ximo de um caso de uso espec√≠fico. <br><br><pre> <code class="plaintext hljs">queue_master_locator=min-masters</code> </pre> <br>  Determine a sele√ß√£o do assistente para novas filas.  Com essa configura√ß√£o, o assistente selecionar√° o n√≥ com o menor n√∫mero de filas, para que as filas sejam distribu√≠das uniformemente pelos n√≥s do cluster. <br><br><pre> <code class="plaintext hljs">cluster_formation.k8s.service_name = rabbitmq-internal</code> </pre> <br>  Nomeamos o servi√ßo K8s decapitado (criado por n√≥s anteriormente) atrav√©s do qual os n√≥s do RabbitMQ se comunicar√£o. <br><br><pre> <code class="plaintext hljs">cluster_formation.k8s.hostname_suffix = .rabbitmq-internal.our-namespace.svc.cluster.local</code> </pre> <br>  Uma coisa importante para endere√ßar em um cluster √© o nome do host.  O FQDN da lareira do K8s √© formado como um nome abreviado (rabbitmq-0, rabbitmq-1) + sufixo (parte do dom√≠nio).  Aqui indicamos esse sufixo.  No K8S, parece <b>. &lt;Nome do servi√ßo&gt;. &lt;Nome do espa√ßo para nome&gt; .svc.cluster.local</b> <br><br>  O kube-dns resolve nomes no formato rabbitmq-0.rabbitmq-internal.our-namespace.svc.cluster.local no endere√ßo IP de um pod espec√≠fico sem nenhuma configura√ß√£o adicional, o que torna poss√≠vel toda a magia do agrupamento por nome de host. <br><br><h3>  Configura√ß√£o StatefulSet RabbitMQ: </h3><br><div class="spoiler">  <b class="spoiler_title">rabbitmq_statefulset.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: rabbitmq spec: serviceName: rabbitmq-internal replicas: 3 template: metadata: labels: app: rabbitmq annotations: scheduler.alpha.kubernetes.io/affinity: &gt; { "podAntiAffinity": { "requiredDuringSchedulingIgnoredDuringExecution": [{ "labelSelector": { "matchExpressions": [{ "key": "app", "operator": "In", "values": ["rabbitmq"] }] }, "topologyKey": "kubernetes.io/hostname" }] } } spec: serviceAccountName: rabbitmq terminationGracePeriodSeconds: 10 containers: - name: rabbitmq-k8s image: rabbitmq:3.7 volumeMounts: - name: config-volume mountPath: /etc/rabbitmq - name: rabbitmq-data mountPath: /var/lib/rabbitmq/mnesia ports: - name: http protocol: TCP containerPort: 15672 - name: amqp protocol: TCP containerPort: 5672 livenessProbe: exec: command: ["rabbitmqctl", "status"] initialDelaySeconds: 60 periodSeconds: 10 timeoutSeconds: 10 readinessProbe: exec: command: ["rabbitmqctl", "status"] initialDelaySeconds: 10 periodSeconds: 10 timeoutSeconds: 10 imagePullPolicy: Always env: - name: MY_POD_IP valueFrom: fieldRef: fieldPath: status.podIP - name: HOSTNAME valueFrom: fieldRef: fieldPath: metadata.name - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: RABBITMQ_USE_LONGNAME value: "true" - name: RABBITMQ_NODENAME value: "rabbit@$(HOSTNAME).rabbitmq-internal.$(NAMESPACE).svc.cluster.local" - name: K8S_SERVICE_NAME value: "rabbitmq-internal" - name: RABBITMQ_ERLANG_COOKIE value: "mycookie" volumes: - name: config-volume configMap: name: rabbitmq-config items: - key: rabbitmq.conf path: rabbitmq.conf - key: enabled_plugins path: enabled_plugins - name: rabbitmq-data persistentVolumeClaim: claimName: rabbitmq-data</code> </pre> </div></div><br>  Na verdade, StatefulSet.  Observamos pontos interessantes. <br><br><pre> <code class="plaintext hljs">serviceName: rabbitmq-internal</code> </pre> <br>  Escrevemos o nome do servi√ßo decapitado por meio do qual os pods se comunicam no StatefulSet. <br><br><pre> <code class="plaintext hljs">replicas: 3</code> </pre> <br>  Defina o n√∫mero de r√©plicas no cluster.  Temos isso igual ao n√∫mero de n√≥s de trabalho K8s. <br><br><pre> <code class="plaintext hljs">annotations: scheduler.alpha.kubernetes.io/affinity: &gt; { "podAntiAffinity": { "requiredDuringSchedulingIgnoredDuringExecution": [{ "labelSelector": { "matchExpressions": [{ "key": "app", "operator": "In", "values": ["rabbitmq"] }] }, "topologyKey": "kubernetes.io/hostname" }] } }</code> </pre> <br>  Quando um dos n√≥s K8s cai, o statefulset procura preservar o n√∫mero de inst√¢ncias no conjunto; portanto, ele cria v√°rios lares no mesmo n√≥ K8s.  Esse comportamento √© completamente indesej√°vel e, em princ√≠pio, in√∫til.  Portanto, prescrevemos uma regra anti-afinidade para conjuntos de lareiras a partir de statefulset.  Tornamos a regra r√≠gida (Necess√°ria) para que o kube-scheduler n√£o possa quebr√°-la ao planejar pods. <br><br>  A ess√™ncia √© simples: √© proibido ao planejador colocar (dentro do espa√ßo de nomes) mais de um pod com a <i>tag app: rabbitmq</i> em cada n√≥.  Distinguimos os <i>n√≥s</i> pelo valor do r√≥tulo <i>kubernetes.io/hostname</i> .  Agora, se por algum motivo o n√∫mero de n√≥s K8S em funcionamento for menor que o n√∫mero necess√°rio de r√©plicas no StatefulSet, novas r√©plicas n√£o ser√£o criadas at√© que um n√≥ livre apare√ßa novamente. <br><br><pre> <code class="plaintext hljs">serviceAccountName: rabbitmq</code> </pre> <br>  Registramos a ServiceAccount, na qual nossos pods funcionam. <br><br><pre> <code class="plaintext hljs">image: rabbitmq:3.7</code> </pre> <br>  A imagem do RabbitMQ √© completamente padr√£o e √© tirada do hub do docker, n√£o requer nenhuma reconstru√ß√£o e revis√£o de arquivos. <br><br><pre> <code class="plaintext hljs">- name: rabbitmq-data mountPath: /var/lib/rabbitmq/mnesia</code> </pre><br>  Dados persistentes do RabbitMQ s√£o armazenados em / var / lib / rabbitmq / mnesia.  Aqui, montamos nossa Reivindica√ß√£o de volume persistente nesta pasta para que, ao reiniciar os lares / n√≥s ou at√© mesmo todo o StatefulSet, os dados (ambos os servi√ßos, incluindo o cluster montado e os dados do usu√°rio) sejam seguros.  Existem alguns exemplos em que toda a pasta / var / lib / rabbitmq / se torna persistente.  Chegamos √† conclus√£o de que essa n√£o √© a melhor id√©ia, pois ao mesmo tempo todas as informa√ß√µes definidas pelas configura√ß√µes do Rabbit come√ßam a ser lembradas.  Ou seja, para alterar algo no arquivo de configura√ß√£o, voc√™ precisa limpar o armazenamento persistente, o que √© muito inconveniente na opera√ß√£o. <br><br><pre> <code class="plaintext hljs"> - name: HOSTNAME valueFrom: fieldRef: fieldPath: metadata.name - name: NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace - name: RABBITMQ_USE_LONGNAME value: "true" - name: RABBITMQ_NODENAME value: "rabbit@$(HOSTNAME).rabbitmq-internal.$(NAMESPACE).svc.cluster.local"</code> </pre><br>  Com esse conjunto de vari√°veis ‚Äã‚Äãde ambiente, primeiro dizemos ao RabbitMQ para usar o nome do FQDN como um identificador para os membros do cluster e, em segundo lugar, definimos o formato desse nome.  O formato foi descrito anteriormente ao analisar a configura√ß√£o. <br><br><pre> <code class="plaintext hljs">- name: K8S_SERVICE_NAME value: "rabbitmq-internal"</code> </pre> <br>  O nome do servi√ßo sem cabe√ßalho para comunica√ß√£o entre membros do cluster. <br><br><pre> <code class="plaintext hljs">- name: RABBITMQ_ERLANG_COOKIE value: "mycookie"</code> </pre> <br>  O conte√∫do do cookie Erlang deve ser o mesmo em todos os n√≥s do cluster. Voc√™ precisa registrar seu pr√≥prio valor.  Um n√≥ com um cookie diferente n√£o pode entrar no cluster. <br><br><pre> <code class="plaintext hljs">volumes: - name: rabbitmq-data persistentVolumeClaim: claimName: rabbitmq-data</code> </pre> <br>  Defina o volume mapeado a partir da reivindica√ß√£o de volume persistente criada anteriormente. <br><br>  √â aqui que terminamos a configura√ß√£o nos K8s.  O resultado √© um cluster RabbitMQ, que distribui uniformemente filas entre n√≥s e √© resistente a problemas no ambiente de tempo de execu√ß√£o. <br><br><img src="https://habrastorage.org/webt/_j/ky/mw/_jkymwmxe7syyjfa7h2idbcxosc.png" alt="imagem"><br><br>  Se um dos n√≥s do cluster n√£o estiver dispon√≠vel, as filas contidas nele deixar√£o de ser acess√≠veis, tudo o mais continuar√° funcionando.  Assim que o n√≥ retornar √† opera√ß√£o, ele retornar√° ao cluster e as filas para as quais era um mestre tornar-se-√£o operacionais novamente, preservando todos os dados contidos neles (se o armazenamento persistente n√£o for interrompido, √© claro).  Todos esses processos s√£o totalmente autom√°ticos e n√£o requerem interven√ß√£o. <br><br><h2>  B√¥nus: personalizar HA </h2><br>  Um dos projetos foi uma nuance.  Os requisitos pareciam um espelhamento completo de todos os dados contidos no cluster.  Isso √© necess√°rio para que, em uma situa√ß√£o em que pelo menos um n√≥ do cluster esteja operacional, tudo continue funcionando do ponto de vista do aplicativo.  Este momento n√£o tem nada a ver com os K8s, n√≥s o descrevemos simplesmente como um mini tutorial. <br><br>  Para habilitar a HA total, voc√™ precisa criar uma Pol√≠tica no painel RabbitMQ na guia <i>Admin -&gt; Pol√≠ticas</i> .  O nome √© arbitr√°rio, o Padr√£o est√° vazio (todas as filas), nas Defini√ß√µes, adicione dois par√¢metros: <i>modo ha: todos</i> , modo <i>ha-sync: autom√°tico</i> . <br><br><img src="https://habrastorage.org/webt/jz/tn/vu/jztnvu5zygtv56hurbyss1w9ljm.png" alt="imagem"><br><br><img src="https://habrastorage.org/webt/_6/in/om/_6inoma38lvluhpaet1g66uus_u.png" alt="imagem"><br><br>  Depois disso, todas as filas criadas no cluster estar√£o no modo de Alta Disponibilidade: se o n√≥ Mestre estiver indispon√≠vel, um dos Escravos ser√° selecionado automaticamente pelo novo assistente.  E os dados que entram na fila ser√£o espelhados para todos os n√≥s do cluster.  Que, de fato, era necess√°rio para receber. <br><br><img src="https://habrastorage.org/webt/0v/m3/je/0vm3jem0bi4fqckj8ucmiy5zcxe.png" alt="imagem"><br><br>  Leia mais sobre HA no RabbitMQ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> <br><br><h2>  Literatura √∫til: </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Reposit√≥rio RabbitMQ Peer Discovery Kubernetes Plugin</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Exemplo de configura√ß√£o para implanta√ß√£o do RabbitMQ no K8S</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Descri√ß√£o dos princ√≠pios de forma√ß√£o de cluster, mecanismo de descoberta por pares e plugins para ele</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Discuss√£o √©pica sobre a configura√ß√£o apropriada da descoberta baseada em nome de host</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Guia de Clustering RabbitMQ</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Descri√ß√£o de problemas e solu√ß√µes de agrupamento de c√©rebro dividido</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Filas de alta disponibilidade no RabbitMQ</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Configurar diretivas</a> </li></ul><br>  Boa sorte </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt419817/">https://habr.com/ru/post/pt419817/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt419805/index.html">O compilador super min√∫sculo - agora em russo</a></li>
<li><a href="../pt419807/index.html">Glaucoma - como n√£o ficar cego: vamos falar sobre tratamento ...</a></li>
<li><a href="../pt419811/index.html">A evolu√ß√£o dos monitores flex√≠veis</a></li>
<li><a href="../pt419813/index.html">Webinars do Skillbox: sele√ß√£o de sexta-feira</a></li>
<li><a href="../pt419815/index.html">Segredos da toler√¢ncia a falhas do nosso escrit√≥rio</a></li>
<li><a href="../pt419819/index.html">Biomarcadores de envelhecimento. Fragilidade do painel. Parte 2</a></li>
<li><a href="../pt419823/index.html">Dueto incomum - senhas e imagens mnem√¥nicas</a></li>
<li><a href="../pt419825/index.html">Testando o desempenho de v√°rios tipos de unidades em um ambiente virtual</a></li>
<li><a href="../pt419829/index.html">A criptografia de chave padr√£o do OpenSSH √© pior que nenhuma</a></li>
<li><a href="../pt419831/index.html">Como o JS funciona: elementos personalizados</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
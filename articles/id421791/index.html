<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘¨ğŸ¿â€ğŸ”¬ ğŸ“ ğŸ§¦ Masalah Etis Kecerdasan Buatan ğŸš™ ğŸ¤º ğŸ¤²ğŸ»</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Penulis artikel ini adalah Alexey Malanov, seorang ahli di departemen pengembangan teknologi anti-virus Lab Kaspersky 

 Kecerdasan buatan menerobos k...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Masalah Etis Kecerdasan Buatan</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/kaspersky/blog/421791/">  <i>Penulis artikel ini adalah Alexey Malanov, seorang ahli di departemen pengembangan teknologi anti-virus Lab Kaspersky</i> <br><br>  Kecerdasan buatan menerobos kehidupan kita.  Di masa depan, semuanya mungkin akan menjadi keren, tetapi sejauh ini beberapa pertanyaan telah muncul, dan semakin banyak masalah ini mempengaruhi aspek moralitas dan etika.  Apakah mungkin mengejek pemikiran AI?  Kapan akan ditemukan?  Apa yang menghalangi kita dari menulis undang-undang robotika sekarang, menempatkan moralitas ke dalamnya?  Kejutan apa yang dibawa pembelajaran mesin saat ini?  Dapatkah pembelajaran mesin dibodohi, dan seberapa sulitkah itu? <a name="habracut"></a><br><br><h1>  Kuat dan Lemah AI - dua hal berbeda </h1><br>  Ada dua hal yang berbeda: AI Kuat dan Lemah. <br>  AI yang kuat (benar, umum, nyata) adalah mesin hipotetis yang dapat berpikir dan sadar akan dirinya sendiri, tidak hanya menyelesaikan tugas yang sangat khusus, tetapi juga mempelajari sesuatu yang baru. <br><br>  Lemah AI (sempit, dangkal) - ini sudah ada program untuk menyelesaikan tugas yang cukup spesifik, seperti pengenalan gambar, mengemudi otomatis, bermain Go, dll. Agar tidak bingung dan tidak menyesatkan siapa pun, kami lebih suka memanggil mesin Lemah AI " learning â€(pembelajaran mesin). <br><br><h1>  AI yang kuat tidak akan segera terjadi </h1><br>  Tentang Strong AI, masih belum diketahui apakah akan ditemukan sama sekali.  Di satu sisi, sampai sekarang, teknologi telah berkembang dengan akselerasi, dan jika ini berlangsung, maka masih ada lima tahun lagi. <br><br><img src="https://habrastorage.org/webt/_i/sv/en/_isvenid4vjjjfsvl5nhnve4xee.jpeg"><br><br>  Di sisi lain, beberapa proses di alam benar-benar berjalan secara eksponensial.  Bagaimanapun, jauh lebih sering, kita melihat kurva logistik. <br><br><img src="https://habrastorage.org/webt/72/uq/hj/72uqhj_g_zj1dn6wq62ewvczwya.png"><br><br>  Sementara kami berada di suatu tempat di sebelah kiri grafik, bagi kami tampaknya ini adalah eksponen.  Misalnya, hingga saat ini, populasi dunia telah tumbuh dengan percepatan seperti itu.  Tetapi pada titik tertentu terjadi "saturasi", dan pertumbuhan melambat. <br><br>  Ketika para ahli <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ditanyai</a> , ternyata rata-rata menunggu 45 tahun lagi. <br><br><img src="https://habrastorage.org/webt/3r/ro/h4/3rroh4slw6_2yu-lpodoret9vxq.png"><br><br>  Anehnya, para ilmuwan Amerika Utara percaya bahwa AI akan melampaui manusia dalam 74 tahun, dan para ilmuwan Asia hanya dalam 30 tahun. Mungkin di Asia mereka tahu sesuatu ... <br><br>  Para ilmuwan yang sama ini meramalkan bahwa sebuah mesin akan menerjemahkan lebih baik daripada seseorang pada tahun 2024, menulis esai sekolah pada tahun 2026, mengendarai truk pada tahun 2027, memainkan Go pada tahun 2027 juga.  Go telah terjawab, karena momen ini datang pada 2017, hanya 2 tahun setelah perkiraan. <br><br>  Secara umum, ramalan selama 40+ tahun ke depan adalah tugas yang tidak berterima.  Artinya suatu hari nanti.  Sebagai contoh, energi fusi yang hemat biaya juga diprediksi setelah 40 tahun.  Perkiraan yang sama dibuat 50 tahun yang lalu, ketika baru mulai dipelajari. <br><br><img src="https://habrastorage.org/webt/pi/3u/v-/pi3uv-ptktxeymxbjxl2_mxrujs.png" align="right"><h1>  AI yang kuat menimbulkan banyak masalah etika </h1><br>  Meski Strong AI akan menunggu lama, tapi kami tahu pasti akan ada cukup masalah etika.  Masalah kelas pertama adalah kita bisa menyinggung AI.  Sebagai contoh: <br><br><ul><li>  Apakah etis menyiksa AI jika bisa merasakan sakit? </li><li>  Apakah normal untuk meninggalkan AI tanpa komunikasi untuk waktu yang lama jika dapat merasakan kesepian? </li><li>  Bisakah Anda menggunakannya sebagai hewan peliharaan?  Bagaimana dengan seorang budak?  Dan siapa yang akan mengendalikannya dan bagaimana, karena ini adalah program yang berfungsi "hidup" di "ponsel cerdas" Anda? </li></ul><br>  Sekarang tidak ada yang akan marah jika Anda menyinggung asisten suara Anda, tetapi jika Anda menganiaya anjing itu, Anda akan dihukum.  Dan ini bukan karena dia memiliki darah dan daging, tetapi karena dia merasakan dan mengalami sikap yang buruk, seperti halnya dengan AI yang kuat. <br><br>  Kelas kedua masalah etika - AI dapat menyinggung kita.  Ratusan contoh seperti itu dapat ditemukan dalam film dan buku.  Bagaimana cara menjelaskan AI, apa yang kita inginkan darinya?  Orang untuk AI seperti semut bagi pekerja yang membangun bendungan: demi tujuan yang hebat, Anda dapat menghancurkan pasangan. <br><br>  Fiksi ilmiah memainkan trik pada kita.  Kami terbiasa berpikir bahwa Skynet dan Terminator tidak ada di sana, dan mereka tidak akan segera, tetapi untuk sekarang Anda dapat bersantai.  AI dalam film sering kali berbahaya, dan kami berharap ini tidak akan terjadi dalam hidup: lagipula, kami diperingatkan, dan kami tidak sebodoh pahlawan film.  Terlebih lagi, dalam pemikiran tentang masa depan, kita lupa untuk berpikir baik tentang masa kini. <br><br><h1>  Pembelajaran mesin ada di sini </h1><br>  Pembelajaran mesin memungkinkan Anda untuk memecahkan masalah praktis tanpa pemrograman eksplisit, tetapi melalui pelatihan tentang preseden.  Anda dapat membaca lebih lanjut di artikel â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dengan kata-kata sederhana: bagaimana pembelajaran mesin bekerja</a> â€. <br><br>  Karena kita mengajar mesin untuk memecahkan masalah tertentu, model matematika yang dihasilkan (yang disebut algoritma) tidak dapat tiba-tiba ingin memperbudak / menyelamatkan manusia.  Lakukan secara normal - itu akan menjadi normal.  Apa yang bisa salah? <br><br><img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right"><h1>  Niat buruk </h1><br>  Pertama, tugas itu sendiri mungkin tidak cukup etis.  Sebagai contoh, jika kita menggunakan pembelajaran mesin untuk mengajar drone untuk membunuh orang. <br><img src="https://habrastorage.org/webt/2w/cq/oi/2wcqoiuu8xuass9vd7uulmkkc9m.png"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://www.youtube.com/watch?v=TlO2gcs1YvM</a> <br><br>  Baru-baru ini, skandal kecil pecah tentang ini.  Google sedang mengembangkan perangkat lunak yang digunakan untuk proyek percontohan manajemen drone Project Maven.  Agaknya di masa depan ini bisa mengarah pada penciptaan senjata yang sepenuhnya otonom. <br><br><img src="https://habrastorage.org/webt/sr/wa/ei/srwaeiionmujk7cx1zj-fzf-s0g.jpeg"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Sumber</a> <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Jadi, setidaknya 12 karyawan Google berhenti sebagai protes, 4.000 lainnya menandatangani petisi yang meminta mereka untuk meninggalkan kontrak dengan militer.  Lebih dari 1000 ilmuwan terkemuka di bidang AI, etika dan teknologi informasi menulis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">surat terbuka yang</a> meminta Google untuk berhenti bekerja pada proyek dan mendukung perjanjian internasional yang melarang senjata otonom. <br><br><h1>  Bias serakah </h1><br>  Tetapi bahkan jika para pembuat algoritma pembelajaran mesin tidak ingin membunuh orang dan melukai orang lain, mereka tetap sering ingin mendapat untung.  Dengan kata lain, tidak semua algoritma bekerja untuk kepentingan masyarakat, banyak yang bekerja untuk kepentingan pencipta.  Ini sering dapat diamati di bidang kedokteran - lebih penting untuk tidak menyembuhkan, tetapi untuk merekomendasikan lebih banyak perawatan. <img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Secara umum, jika pembelajaran mesin menyarankan sesuatu yang dibayar - dengan probabilitas tinggi algoritma tersebut "serakah." <br><br>  Ya, dan terkadang masyarakat sendiri tidak tertarik pada algoritma yang dihasilkan sebagai model moralitas.  Misalnya, ada pertukaran antara kecepatan kendaraan dan kematian di jalan.  Kami dapat mengurangi angka kematian jika membatasi kecepatan hingga 20 km / jam, tetapi kehidupan di kota-kota besar akan sulit. <br><br><h1>  Etika hanyalah salah satu parameter sistem. </h1><br><img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right">  Bayangkan, kami meminta algoritme untuk menyusun anggaran negara dengan tujuan "memaksimalkan PDB / produktivitas tenaga kerja / harapan hidup".  Tidak ada batasan dan tujuan etis dalam perumusan tugas ini.  Mengapa mengalokasikan uang untuk panti asuhan / rumah sakit / perlindungan lingkungan, karena tidak akan meningkatkan PDB (setidaknya secara langsung)?  Dan bagus jika kita hanya mempercayakan anggaran pada algoritme, dan dalam pernyataan masalah yang lebih luas ternyata populasi yang menganggur â€œlebih menguntungkanâ€ untuk dibunuh segera untuk meningkatkan produktivitas tenaga kerja. <br><br>  Ternyata masalah etika harus menjadi salah satu tujuan sistem pada awalnya. <br><br><h1>  Etika sulit untuk dideskripsikan secara formal </h1><br>  Ada satu masalah dengan etika - sulit untuk diformalkan.  Negara yang berbeda memiliki etika yang berbeda.  Itu berubah seiring waktu.  Misalnya, pada isu-isu seperti hak LGBT dan pernikahan antar-kasta, pendapat dapat berubah secara signifikan selama beberapa dekade.  Etika mungkin tergantung pada iklim politik. <br><img src="https://habrastorage.org/webt/oe/bj/x9/oebjx9ygsiqyfs-zap5diznne2i.png"><br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Misalnya, di Cina, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pemantauan pergerakan warga</a> menggunakan kamera pengintai dan pengenalan wajah dianggap sebagai norma.  Di negara lain, sikap terhadap masalah ini mungkin berbeda dan tergantung pada situasinya. <br><br><h1>  Pembelajaran Mesin Mempengaruhi Orang </h1><br>  Bayangkan sebuah sistem berbasis pembelajaran mesin yang menyarankan Anda menonton film mana.  Berdasarkan peringkat Anda untuk film-film lain, dan dengan membandingkan selera Anda dengan pengguna lain, sistem ini dapat merekomendasikan film yang benar-benar Anda sukai. <img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right"><br><br>  Tetapi pada saat yang sama, sistem akan mengubah selera Anda dari waktu ke waktu dan membuatnya lebih sempit.  Tanpa sistem, dari waktu ke waktu Anda akan menonton film-film buruk dan film-film dengan genre yang tidak biasa.  Dan agar tidak ada film - to the point.  Akibatnya, kami tidak lagi menjadi "ahli film", dan hanya menjadi konsumen dari apa yang mereka berikan.  Sangat menarik bahwa kita bahkan tidak memperhatikan bagaimana algoritma memanipulasi kita. <br><br>  Jika Anda mengatakan bahwa efek algoritma pada orang seperti itu bahkan bagus, maka berikut ini adalah contoh lain.  Cina sedang bersiap untuk meluncurkan Sistem Peringkat Sosial - sistem untuk mengevaluasi individu atau organisasi sesuai dengan berbagai parameter, yang nilainya diperoleh dengan menggunakan alat pengawasan massal dan menggunakan teknologi analisis data besar. <img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right">  Jika seseorang membeli popok - itu bagus, peringkatnya bertambah.  Jika pengeluaran uang untuk video game buruk, peringkatnya turun.  Jika berkomunikasi dengan seseorang dengan peringkat rendah, maka ia juga jatuh. <br><br>  Sebagai hasilnya, ternyata berkat Sistem, warga secara sadar atau tidak sadar mulai berperilaku berbeda.  Berkomunikasi lebih sedikit dengan warga yang tidak dapat diandalkan, membeli lebih banyak popok, dll. <br><br><h1>  Kesalahan Sistem Algoritma </h1><br>  Selain fakta bahwa kadang-kadang kita sendiri tidak tahu apa yang kita inginkan dari algoritma, ada juga sejumlah batasan teknis. <br><br>  Algoritma menyerap ketidaksempurnaan dunia. <img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Jika kita menggunakan data dari perusahaan dengan politisi rasis sebagai sampel pelatihan untuk algoritma perekrutan, maka algoritma tersebut juga akan memiliki bias rasis. <br><br>  Microsoft pernah mengajar chatbot untuk mengobrol di Twitter.  Itu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">harus dimatikan dalam</a> waktu kurang dari sehari, karena bot dengan cepat menguasai kutukan dan pernyataan rasis. <br><br><img src="https://habrastorage.org/webt/-o/vn/yb/-ovnybi6tui2yl-e3jewbkjlkae.png"><br><br>  Selain itu, algoritma pembelajaran tidak dapat memperhitungkan beberapa parameter yang tidak diformalkan.  Misalnya, ketika menghitung rekomendasi kepada terdakwa - untuk mengakui atau tidak mengakui kesalahan berdasarkan bukti yang dikumpulkan, sulit bagi algoritma untuk memperhitungkan seberapa terkesan pengakuan seperti itu bagi hakim, karena kesan dan emosi tidak dicatat di mana pun. <br><br><h1>  Korelasi dan umpan balik palsu </h1><br>  Korelasi yang salah adalah ketika tampaknya bahwa semakin banyak petugas pemadam kebakaran ada di kota, semakin sering terjadi kebakaran.  Atau ketika jelas bahwa semakin sedikit bajak laut di Bumi, semakin hangat iklim di planet ini. <br><br><img src="https://habrastorage.org/webt/ch/d6/yy/chd6yybu-p8-kwd90abngmtlnm8.jpeg"><br><br>  Jadi - orang mencurigai bahwa bajak laut dan iklim tidak terhubung langsung, dan tidak begitu sederhana dengan petugas pemadam kebakaran, dan model pembelajaran mesin hanya menghafal dan menggeneralisasi. <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Contoh terkenal.  Program tersebut, yang memeringkat pasien sesuai dengan urgensi pertolongan, menyimpulkan bahwa penderita asma dengan pneumonia membutuhkan lebih sedikit bantuan daripada orang dengan pneumonia tanpa asma.  Program melihat statistik dan sampai pada kesimpulan bahwa penderita asma tidak mati - mengapa mereka perlu prioritas?  Dan mereka tidak benar-benar mati karena pasien tersebut segera menerima perawatan terbaik di lembaga medis karena risiko yang sangat tinggi. <br><br>  Lebih buruk dari korelasi yang salah hanyalah putaran umpan balik.  Sebuah program pencegahan kejahatan California menyarankan untuk mengirim lebih banyak polisi ke lingkungan kulit hitam berdasarkan tingkat kejahatan (jumlah kejahatan yang dilaporkan).  Dan semakin banyak mobil polisi di bidang visibilitas, semakin sering warga melaporkan kejahatan (hanya ada seseorang untuk dilaporkan).  Akibatnya, kejahatan hanya meningkat - yang berarti bahwa lebih banyak petugas polisi harus dikirim, dll. <br><br>  Dengan kata lain, jika diskriminasi rasial merupakan faktor penahanan, maka loop umpan balik dapat memperkuat dan melanggengkan diskriminasi rasial dalam kegiatan polisi. <br><br><h1>  Siapa yang harus disalahkan </h1><br>  Pada tahun 2016, Kelompok Kerja Big Data di bawah Pemerintahan Obama mengeluarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">laporan</a> peringatan "kemungkinan pengkodean diskriminasi dalam membuat keputusan otomatis" dan mendalilkan "prinsip peluang yang sama". <br><br>  Tetapi mengatakan sesuatu itu mudah, tetapi apa yang harus dilakukan? <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Pertama, model pembelajaran matematika mesin sulit untuk diuji dan diubah.  Misalnya, aplikasi Google Photo mengenali orang dengan kulit hitam seperti gorila.  Dan apa yang harus dilakukan?  Jika kita membaca program biasa selangkah demi selangkah dan belajar cara mengujinya, maka dalam hal pembelajaran mesin semuanya tergantung pada ukuran sampel kontrol, dan itu tidak bisa tanpa batas.  Selama tiga tahun, Google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tidak dapat menemukan sesuatu yang lebih baik</a> daripada mematikan pengakuan gorila, simpanse, dan monyet sama sekali, untuk mencegah terulangnya kesalahan. <br><br>  Kedua, sulit bagi kita untuk memahami dan menjelaskan solusi pembelajaran mesin.  Sebagai contoh, jaringan saraf entah bagaimana menempatkan koefisien berat dalam dirinya untuk mendapatkan jawaban yang benar.  Dan mengapa mereka berubah begitu saja dan apa yang harus dilakukan untuk mengubah jawabannya? <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Sebuah studi tahun 2015 menemukan bahwa wanita jauh lebih kecil kemungkinannya daripada pria untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">melihat postingan</a> pekerjaan bergaji tinggi yang diiklankan oleh Google AdSense.  Layanan pengiriman pada hari yang sama dengan Amazon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">secara teratur tidak tersedia</a> di kuartal ketiga.  Dalam kedua kasus, perwakilan perusahaan merasa sulit untuk menjelaskan solusi seperti itu untuk algoritma. <br><br><h1>  Tetap membuat hukum dan mengandalkan pembelajaran mesin </h1><br>  Ternyata tidak ada yang bisa disalahkan, masih ada yang meloloskan hukum dan mendalilkan "hukum etik robotika."  Jerman baru-baru ini, pada Mei 2018, mengeluarkan seperangkat aturan untuk kendaraan tak berawak.  Antara lain, dikatakan: <br><ul><li>  Keselamatan manusia adalah prioritas tertinggi dibandingkan dengan kerusakan pada hewan atau properti. </li><li>  Dalam hal terjadi kecelakaan yang akan segera terjadi, seharusnya tidak ada diskriminasi, tanpa alasan itu tidak dapat diterima untuk membedakan orang. </li></ul><br>  Tetapi apa yang sangat penting dalam konteks kita: <br>  Sistem mengemudi otomatis menjadi <b>keharusan etis</b> jika sistem menyebabkan kecelakaan lebih sedikit daripada driver manusia. <br><br>  Jelas, kita akan semakin mengandalkan pembelajaran mesin - hanya karena umumnya akan lebih baik daripada orang-orang. <br><br><h1>  Pembelajaran mesin bisa diracuni </h1><br>  Dan di sini kita sampai pada kemalangan yang tidak kalah dengan bias dari algoritma - mereka dapat dimanipulasi. <br><br>  Keracunan pembelajaran mesin (ML poisoning) berarti bahwa jika seseorang mengambil bagian dalam pelatihan model, maka ia dapat memengaruhi keputusan yang dibuat oleh model. <br><br>  Misalnya, di laboratorium analisis virus komputer, model model memproses rata-rata satu juta sampel baru setiap hari (file bersih dan berbahaya). <img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Bentang ancaman terus berubah, oleh karena itu perubahan dalam model dalam bentuk pembaruan basis data anti-virus dikirimkan ke produk anti-virus di sisi pengguna. <br><br>  Jadi, seorang penyerang dapat terus-menerus menghasilkan file berbahaya yang sangat mirip dengan yang bersih dan mengirimkannya ke laboratorium.  Perbatasan antara file bersih dan file berbahaya akan secara bertahap dihapus, model akan "menurun".  Dan pada akhirnya, model dapat mengenali file bersih asli sebagai berbahaya - ini akan menghasilkan false positive. <br><br>  Dan sebaliknya, jika Anda "spam" filter spam belajar sendiri dari satu ton email yang dihasilkan bersih, Anda akhirnya akan dapat membuat spam yang melewati filter. <br><br>  Oleh karena itu, Kaspersky Lab memiliki pendekatan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">multi-level untuk perlindungan</a> , kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tidak</a> hanya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengandalkan</a> pembelajaran mesin. <br><br>  Contoh lain, sementara fiksi.  Anda dapat menambahkan wajah yang dibuat khusus ke sistem pengenalan wajah, sehingga pada akhirnya sistem mulai membingungkan Anda dengan orang lain.  Jangan berpikir bahwa ini tidak mungkin, lihatlah gambar dari bagian selanjutnya. <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right"><h1>  Peretasan pembelajaran mesin </h1><br>  Keracunan adalah efek pada proses pembelajaran.  Tetapi tidak perlu berpartisipasi dalam pelatihan untuk mendapatkan manfaat - Anda juga dapat menipu model yang sudah jadi jika Anda tahu cara kerjanya. <br><br><img src="https://habrastorage.org/webt/78/tn/ea/78tneahwtmergijhapcs5cg5no4.png"><br><br><img src="https://habrastorage.org/webt/qq/hf/uv/qqhfuvjsdh5m9t8i8kd-l9wnxqo.png" align="right">  <i>Mengenakan kacamata berwarna khusus, para peneliti meniru orang lain - selebriti</i> <br><br>  Contoh dengan wajah ini belum ditemukan di "liar" - tepatnya karena belum ada yang mempercayakan mesin dengan membuat keputusan penting berdasarkan pengenalan wajah.  Tanpa kontrol manusia, itu akan persis seperti pada gambar. <br><br>  Bahkan di mana, kelihatannya, tidak ada yang rumit, mudah untuk menipu mobil dengan cara yang tidak diketahui oleh orang yang belum tahu. <br><br><img src="https://habrastorage.org/webt/pb/_6/1b/pb_61bjjv5nnw5kxwxwcbifkm20.png"><br>  <i>Tiga karakter pertama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dikenali</a> sebagai "Batas Kecepatan 45" dan yang terakhir sebagai STOP</i> <br><br><img src="https://habrastorage.org/webt/qq/hf/uv/qqhfuvjsdh5m9t8i8kd-l9wnxqo.png" align="right">  Selain itu, agar model pembelajaran mesin mengenali penyerahan, tidak perlu melakukan perubahan signifikan, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">cukup</a> suntingan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">minimal</a> yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tidak terlihat oleh</a> seseorang. <br><br><img src="https://habrastorage.org/webt/_c/du/mj/_cdumjxqnp1ojmvp2i-orq-8uke.png"><br><br>  <i>Jika Anda menambahkan suara khusus minimal ke panda di sebelah kiri, maka pembelajaran mesin akan yakin bahwa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">itu adalah</a> owa</i> <br><br><img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right">  Sementara seseorang lebih pintar daripada kebanyakan algoritma, dia bisa menipu mereka.  Bayangkan dalam waktu dekat, pembelajaran mesin akan menganalisis x-ray koper di bandara dan mencari senjata.  Seorang teroris yang cerdas akan dapat menempatkan bentuk khusus di sebelah pistol dan dengan demikian "menetralkan" pistol. <br><br>  Demikian pula, dimungkinkan untuk "meretas" Sistem Peringkat Sosial Tiongkok dan menjadi orang yang paling dihormati di Tiongkok. <br><br><h1>  Kesimpulan </h1><br>  Mari kita simpulkan apa yang berhasil kita diskusikan. <br><img src="https://habrastorage.org/webt/p4/ca/et/p4caet8far6cj7xuvafv8e6qddq.png"><br><br><img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right"><ol><li>  Belum ada AI yang kuat. </li><li>  Kami santai. </li><li>  Pembelajaran mesin akan mengurangi jumlah korban di area kritis. </li><li>  Kami akan semakin bergantung pada pembelajaran mesin. </li><li>  Kami akan memiliki niat baik. </li><li>  Kami bahkan akan meletakkan etika dalam desain sistem. </li><li>  Tetapi etika sulit diformalkan dan berbeda di berbagai negara. </li><li>  Pembelajaran mesin penuh dengan bias karena berbagai alasan. </li><li>  Kami tidak selalu dapat menjelaskan solusi algoritma pembelajaran mesin. </li><li>  Pembelajaran mesin bisa diracuni. </li><li>  Dan bahkan "retas". </li><li>  Seorang penyerang bisa mendapatkan keuntungan dibandingkan orang lain dengan cara ini. </li><li>  Pembelajaran mesin memiliki dampak pada kehidupan kita. </li></ol><br>  Dan semua ini adalah masa depan yang dekat. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id421791/">https://habr.com/ru/post/id421791/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id421779/index.html">OceanLotus: backdoor baru, skema lama</a></li>
<li><a href="../id421783/index.html">Kerangka Huex Manajemen Negara yang Menyenangkan</a></li>
<li><a href="../id421785/index.html">California berada di ambang penolakan lengkap karbon dalam produksi energi</a></li>
<li><a href="../id421787/index.html">Pengembangan arsitektur proyek, kapal dan JavaScript</a></li>
<li><a href="../id421789/index.html">Buat frontend "backend" lagi</a></li>
<li><a href="../id421793/index.html">Mencari yang terbaik atau bagaimana kami memilih jaringan blockchain untuk proyek tersebut</a></li>
<li><a href="../id421795/index.html">Keputusan berdasarkan data tentang contoh pemilihan warna untuk lukisan dinding</a></li>
<li><a href="../id421797/index.html">Mengapa Anda perlu Splunk? Memantau infrastruktur TI</a></li>
<li><a href="../id421799/index.html">Bagaimana cara mendapatkan pekerjaan dari jarak jauh di perusahaan yang tidak mengambil karyawan jarak jauh?</a></li>
<li><a href="../id421801/index.html">Penulis ekstensi BetterSlack menariknya atas permintaan pengacara Slack</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
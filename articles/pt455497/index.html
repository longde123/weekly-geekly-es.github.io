<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤ ‚û∞ üëêüèΩ Filtragem linear ideal: de descida gradiente a filtros adaptativos ‚úåüèæ üòô üôç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Desenvolvendo o t√≥pico de resumos na especialidade do mestrado "Comunica√ß√£o e processamento de sinais" (TU Ilmenau), gostaria de continuar um dos prin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Filtragem linear ideal: de descida gradiente a filtros adaptativos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455497/"><p>  Desenvolvendo o t√≥pico de resumos na especialidade do mestrado "Comunica√ß√£o e processamento de sinais" (TU Ilmenau), gostaria de continuar um dos principais t√≥picos do curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"Processamento de sinais adaptativos e de matriz"</a> .  Ou seja, o b√°sico da filtragem adaptativa. </p><br><p>  <u>Para quem este artigo foi escrito:</u> <u><br></u> <br>  1) para uma irmandade estudantil de uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">especialidade nativa</a> ; <br>  2) para professores que preparam semin√°rios pr√°ticos, mas ainda n√£o decidiram as ferramentas - abaixo est√£o exemplos em <strong>python</strong> e <strong>Matlab / Octave</strong> ; <br>  3) para qualquer pessoa interessada no t√≥pico de filtragem. </p><br><p>  <u>O que pode ser encontrado sob o corte:</u> <u><br></u> <br>  1) informa√ß√µes da teoria, que tentei organizar da maneira mais concisa poss√≠vel, mas, ao que me parece, informativamente; <br>  2) exemplos do uso de filtros: em particular, como parte do equalizador para o conjunto de antenas; <br>  3) links para literatura b√°sica e bibliotecas abertas (em python), que podem ser √∫teis para pesquisas. </p><br><p>  Em geral, seja bem-vindo e vamos resolver tudo por pontos. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2f1/98b/d67/2f198bd673789161db58ad770c629faf.jpg"></p><a name="habracut"></a><br><p>  <em>A pessoa pensativa na foto √© familiar para muitos, eu acho, Norbert Wiener.</em>  <em>Na maior parte, estudaremos o filtro de seu nome.</em>  <em>No entanto, n√£o podemos deixar de mencionar nosso compatriota - Andrei Nikolaevich Kolmogorov, cujo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo de 1941</a> tamb√©m contribuiu significativamente para o desenvolvimento da teoria ideal de filtragem, que mesmo em fontes inglesas √© chamada de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">teoria de filtragem Kolmogorov-Wiener</a> .</em> </p><br><h2 id="chto-rassmatrivaem">  O que estamos considerando? </h2><br><p>  Hoje, estamos considerando um filtro cl√°ssico com uma resposta de impulso finito (FIR, resposta de impulso finito), que pode ser descrita pelo seguinte circuito simples (Fig. 1). </p><br><p><img src="https://habrastorage.org/webt/to/or/u7/tooru7vj_f6aj0oe9wvpcde28kw.png"></p><br><p>  <em>Fig. 1.</em>  <em>O esquema do filtro FIR para estudar o filtro Wiener. [1.</em>  <em>p.117]</em> </p><br><p>  Escreveremos em forma de matriz o que exatamente estar√° na sa√≠da deste estande: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/43f/615/39b/43f61539ba1f68998b24c39a8c539706.svg" alt="e (n) = d (n) - \ hat {d} (n | \ mathcal {U} _n) = d (n) - \ mathbf {w} ^ H \ mathbf {u} \ qquad (1)"></div><br><p>  Decifre a nota√ß√£o: </p><br><ul><li><img src="https://habrastorage.org/getpro/habr/post_images/6c5/882/04e/6c588204ed25c8bbb270106d7f08a4dd.svg" alt="e (n)">  √â a diferen√ßa (erro) entre os sinais dados e os recebidos </li><li><img src="https://habrastorage.org/getpro/habr/post_images/771/807/bef/771807bef08a5612654d97e67695cf07.svg" alt="d (n)">  Algum sinal predefinido </li><li><img src="https://habrastorage.org/getpro/habr/post_images/960/b4e/a48/960b4ea48f3968f42c64eed1af640e1d.svg" alt="\ mathbf {u}">  √â um vetor de amostras ou, em outras palavras, um sinal na entrada do filtro </li><li><img src="https://habrastorage.org/getpro/habr/post_images/75f/f22/a5a/75ff22a5a4f95cbe489056bf704597f0.svg" alt="\ hat {d} (n | \ mathcal {U} _n)">  O sinal est√° na sa√≠da do filtro </li><li><img src="https://habrastorage.org/getpro/habr/post_images/6f6/81f/9be/6f681f9be2ae30d1666fec498b59b3a3.svg" alt="\ mathbf {w} ^ H">  - esta √© uma conjuga√ß√£o hermitiana do vetor do coeficiente do filtro - <u>√© na sele√ß√£o ideal deles que se encontra a adaptabilidade do filtro</u> </li></ul><br><p>  Voc√™ provavelmente j√° adivinhou que procuraremos a menor diferen√ßa entre o sinal fornecido e o filtrado, ou seja, o menor erro.  Isso significa que estamos enfrentando uma tarefa de otimiza√ß√£o. </p><br><h2 id="chto-budem-optimizirovat">  O que vamos otimizar? </h2><br><p>  Para otimizar, ou melhor, minimizar, n√£o queremos <strong>dizer</strong> apenas <strong>o</strong> erro, o <strong>erro quadrado m√©dio</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MSE - Mean Sqared Error</a> ): </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b83/b62/193/b83b62193ca3490681c2cd8910e4d99a.svg" alt="MSE: J (\ mathbf {w}) = E \ {e (n) ^ 2 \} \ qquad (2)"></div><br><p>  onde <img src="https://habrastorage.org/getpro/habr/post_images/c48/76a/b10/c4876ab1024579fa30ea997a45efd50a.svg" alt="J (\ mathbf {w})">  denota a fun√ß√£o de custo do vetor de coeficientes de filtro e <img src="https://habrastorage.org/getpro/habr/post_images/f39/8e4/ded/f398e4ded6db9e55108d575a9b7d2f1f.svg" alt="E \ {* \}">  denota tapete.  esperando. </p><br><p>  A pra√ßa neste caso √© muito agrad√°vel, pois significa que estamos diante do problema da <em>programa√ß√£o convexa</em> (pesquisei apenas um an√°logo da <em>otimiza√ß√£o convexa</em> inglesa), o que, por sua vez, implica um <u>√∫nico extremo</u> (no nosso caso, no m√≠nimo). </p><br><p><img src="https://habrastorage.org/webt/hr/xj/mb/hrxjmbmimv7c2uvvicnuklqn9y0.png"></p><br><p>  <em>Fig. 2.</em>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A superf√≠cie do erro quadr√°tico m√©dio</a> .</em> </p><br><p>  Nossa fun√ß√£o de erro tem uma forma can√¥nica [1, p. 121]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5da/121/788/5da121788f801656b55ee459c2f4d56d.svg" alt="J (\ mathbf {w}) = \ sigma ^ 2_d - \ mathbf {w} ^ H \ mathbf {p} - \ mathbf {p} ^ H \ mathbf {w} + \ mathbf {w} ^ H \ mathbf { R} \ mathbf {w} \ qquad (3)"></div><br><p>  onde <img src="https://habrastorage.org/getpro/habr/post_images/24f/50c/410/24f50c410ab0c2ca3dd302c630c734e8.svg" alt="\ sigma ^ 2_d">  √â a varia√ß√£o do sinal esperado, <img src="https://habrastorage.org/getpro/habr/post_images/82c/861/559/82c86155992ccb2e83d6f9f3f9e92737.svg" alt="\ mathbf {p} = E \ {\ mathbf {u} (n) d ^ * (n) \}">  √â o vetor de correla√ß√£o cruzada entre o vetor de entrada e o sinal esperado e <img src="https://habrastorage.org/getpro/habr/post_images/664/01c/a88/66401ca883516093b2e73b7d519588ac.svg" alt="\ mathbf {R} = E \ {\ mathbf {u} (n) \ mathbf {u} ^ H (n) \}">  √â a matriz de autocorrela√ß√£o do sinal de entrada. </p><br><div class="spoiler">  <b class="spoiler_title">A conclus√£o desta f√≥rmula est√° aqui (tentei mais claramente).</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/q6/sw/p5/q6swp5meopsxauj7yvygkwuc7-g.png" width="650"></div></div><br><p>  Como observamos acima, se estamos falando de programa√ß√£o convexa, teremos um extremo (m√≠nimo).  Portanto, para encontrar o valor m√≠nimo da fun√ß√£o de custo (o erro m√≠nimo quadr√°tico m√©dio da raiz), basta encontrar a tangente da inclina√ß√£o da tangente ou, em outras palavras, a <u>derivada parcial</u> em <u>rela√ß√£o</u> √† nossa vari√°vel estudada: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1cd/d0b/114/1cdd0b114b5457761dd27338b4ee57f4.svg" alt="\ frac {\ delta J (\ mathbf {w})} {\ delta w ^ *} = - \ mathbf {p} + \ mathbf {R} \ mathbf {w} \ qquad (4)"></div><br><p>  Na melhor das hip√≥teses ( <img src="https://habrastorage.org/getpro/habr/post_images/ac6/219/d1c/ac6219d1cc1885e6f5936e40b5c7a980.svg" alt="\ mathbf {w} = \ mathbf {w} _ {opt}">  ), √© claro que o erro deve ser m√≠nimo, o que significa que equiparamos a derivada a zero: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/777/46e/9a7/77746e9a7ab3ff9df3cf340da4b7238d.svg" alt="\ mathbf {R} \ mathbf {w} _ {opt} = \ mathbf {p} \ qquad (5)"></div><br><p>  Na verdade, aqui est√°, nosso fog√£o, do qual dan√ßaremos mais adiante: diante de n√≥s existe um <u>sistema de equa√ß√µes lineares</u> . </p><br><h2 id="kak-budem-reshat">  Como vamos decidir? </h2><br><p>  Deve-se notar imediatamente que ambas as solu√ß√µes, que consideraremos a seguir, neste caso s√£o te√≥ricas e educacionais, pois <img src="https://habrastorage.org/getpro/habr/post_images/1cf/d71/499/1cfd714992b16fcc961ad10bcc855134.svg" alt="\ mathbf {R}">  e <img src="https://habrastorage.org/getpro/habr/post_images/1fa/0e8/e9e/1fa0e8e9e33d7dbd533901bbf025bd9f.svg" alt="\ mathbf {p}">  conhecido antecipadamente (ou seja, t√≠nhamos a capacidade suposta de coletar estat√≠sticas suficientes para calcul√°-las).  No entanto, a an√°lise de exemplos simplificados aqui √© a melhor que voc√™ pode pensar para entender as abordagens b√°sicas. </p><br><h3 id="analiticheskoe-reshenie">  Solu√ß√£o anal√≠tica </h3><br><p>  Este problema pode ser resolvido, por assim dizer, na testa - usando matrizes inversas: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/759/c3e/052/759c3e052c502aa04fe6da682a41ea2a.svg" alt="\ mathbf {w} _ {opt} = \ mathbf {R} ^ {- 1} \ mathbf {p} \ qquad (6)"></div><br><p>  Essa express√£o √© chamada de equa√ß√£o de Wiener - Hopf - ainda √© √∫til para n√≥s como refer√™ncia. </p><br><blockquote>  Obviamente, para ser completamente meticuloso, provavelmente seria mais correto escrever esse caso de uma maneira geral, ou seja,  n√£o com <img src="https://habrastorage.org/getpro/habr/post_images/bd8/f0f/04a/bd8f0f04a92fe1055c350d4e32a8a256.svg" alt="^ {-}">  e com <img src="https://habrastorage.org/getpro/habr/post_images/017/3d5/ed9/0173d5ed99b25d00ec4245287142f165.svg" alt="^ +">  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pseudo invertido</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/003/47f/bca/00347fbca15f40943c7fb7b20c38a3f9.svg" alt="\ mathbf {R} ^ + = \ mathbf {R} ^ H (\ mathbf {R} \ mathbf {R} ^ H) ^ {- 1}"><br><br>  No entanto, a matriz de autocorrela√ß√£o n√£o pode ser n√£o quadrada ou singular; portanto, com raz√£o, acreditamos que n√£o h√° contradi√ß√£o. </blockquote><p>  A partir desta equa√ß√£o, √© analiticamente poss√≠vel deduzir qual ser√° o valor m√≠nimo da fun√ß√£o de custo (ou seja, no nosso caso, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MEEM</a> - erro m√©dio quadr√°tico m√©dio): </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c00/d2d/1f9/c00d2d1f9427762a17deae92ae3ea77c.svg" alt="J_ {min} = J (\ mathbf {w} _ {opt}) = \ sigma ^ 2_d - \ mathbf {p} ^ H \ mathbf {R} ^ {- 1} \ mathbf {p} \ qquad (7)"></div><br><div class="spoiler">  <b class="spoiler_title">A deriva√ß√£o da f√≥rmula est√° aqui (tamb√©m tentei torn√°-la mais colorida).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/ds/vh/nx/dsvhnxoudmo_qd4hesg_qkysdg8.jpeg"></p></div></div><br><p>  Bem, h√° uma solu√ß√£o. </p><br><h3 id="reshenie-iterativnym-metodom">  Solu√ß√£o iterativa </h3><br><p>  No entanto, sim, √© poss√≠vel resolver um sistema de equa√ß√µes lineares sem inverter a matriz de autocorrela√ß√£o - iterativamente ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">para salvar c√°lculos</a> ).  Para esse fim, considere o <strong>m√©todo</strong> nativo e compreens√≠vel <strong>de descida de gradiente</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">m√©todo de descida mais √≠ngreme / gradiente</a> ). </p><br><p>  A ess√™ncia do algoritmo pode ser reduzida para o seguinte: </p><br><ol><li>  Definimos a vari√°vel desejada para algum valor padr√£o (por exemplo, <img src="https://habrastorage.org/getpro/habr/post_images/231/554/6f0/2315546f0e8aa127a8da693d41c53ff6.svg" alt="\ mathbf {w} (0) = \ mathbf {0}">  ) </li><li>  Escolha algum passo <img src="https://habrastorage.org/getpro/habr/post_images/849/a42/16c/849a4216c1bc55877bc86f4a97513f7a.svg" alt="\ mu">  (como exatamente escolhemos, falaremos abaixo). </li><li>  E ent√£o, por assim dizer, descemos ao longo de nossa superf√≠cie original (no nosso caso, essa √© a superf√≠cie MSE) com uma determinada etapa <img src="https://habrastorage.org/getpro/habr/post_images/849/a42/16c/849a4216c1bc55877bc86f4a97513f7a.svg" alt="\ mu">  e uma certa velocidade determinada pela magnitude do gradiente. </li></ol><br><p>  Da√≠ o nome: <em>gradiente</em> - gradiente ou <em>mais √≠ngreme</em> - <em>descida</em> passo a passo - descida. </p><br><p>  O gradiente em nosso caso j√° √© conhecido: de fato, o encontramos quando diferenciamos a fun√ß√£o de custo (a superf√≠cie √© c√¥ncava, compare com [1, p. 220]).  Escrevemos como ser√° a f√≥rmula para atualiza√ß√£o iterativa da vari√°vel desejada (coeficientes de filtro) [1, p.  220]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6d6/4ff/7eb/6d64ff7eb98c4274e05a33a3eb127933.svg" alt="\ mathbf {w} (n + 1) = \ mathbf {w} (n) - \ mu [- \ mathbf {p} + \ mathbf {R} \ mathbf {w} (n)] \ qquad (8)"></div><br><p>  onde <img src="https://habrastorage.org/getpro/habr/post_images/fd6/0b2/b5b/fd60b2b5be4b7e93a0d905dd970c314f.svg" alt="n">  √â o n√∫mero da itera√ß√£o. </p><br><p>  Agora vamos falar sobre a escolha de um tamanho de etapa. </p><br><p>  Listamos as premissas √≥bvias: </p><br><ul><li>  o passo n√£o pode ser negativo ou zero </li><li>  o passo n√£o deve ser muito grande, caso contr√°rio, o algoritmo n√£o convergir√° (por assim dizer, pular√° de ponta a ponta, sem cair no extremo) </li><li>  a etapa, √© claro, pode ser muito pequena, mas isso tamb√©m n√£o √© totalmente desej√°vel - o algoritmo passar√° mais tempo </li></ul><br><p>  Com rela√ß√£o ao filtro Wiener, √© claro que restri√ß√µes j√° foram encontradas h√° muito tempo [1, p. 222-226]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/67d/64a/b6c/67d64ab6cf46d3438791ccea853421fb.svg" alt="0 <\ mu <\ frac {2} {\ lambda_ {max}} \ qquad (9)"></div><br><p>  onde <img src="https://habrastorage.org/getpro/habr/post_images/e5d/fa8/35d/e5dfa835ded907ecd7cf2b56d7061307.svg" alt="\ lambda_ {max}">  √â o maior autovalor da matriz de autocorrela√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/1cf/d71/499/1cfd714992b16fcc961ad10bcc855134.svg" alt="\ mathbf {R}">  . </p><br><blockquote>  A prop√≥sito, autovalores e vetores s√£o um t√≥pico interessante separado no contexto da filtragem linear.  Existe at√© um <em>filtro Eigen</em> completo <em>para</em> este caso (consulte o Ap√™ndice 1). </blockquote><p>  Mas isso, felizmente, n√£o √© tudo.  H√° tamb√©m uma solu√ß√£o ideal e adapt√°vel: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f4c/3c2/fdf/f4c3c2fdf8ae926094bb67b391cd896b.svg" alt="\ mu (n) = \ frac {\ mathbf {\ gamma} (n) ^ H \ mathbf {\ gamma} (n)} {\ mathbf {\ gamma} (n) ^ H \ mathbf {R} \ mathbf { \ gama} (n)} \ qquad (10)"></div><br><p>  onde <img src="https://habrastorage.org/getpro/habr/post_images/1b0/4a6/a31/1b04a6a318f99ec501290f59c0f924ac.svg" alt="\ mathbf {\ gama} (n) = \ mathbf {p} - \ mathbf {R} \ mathbf {w} (n)">  √â um gradiente negativo.  Como pode ser visto na f√≥rmula, a etapa √© recalculada em cada itera√ß√£o, ou seja, se adapta. </p><br><div class="spoiler">  <b class="spoiler_title">A conclus√£o da f√≥rmula est√° aqui (muita matem√°tica - olhe apenas para os mesmos nerds not√≥rios como eu).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/au/hq/0s/auhq0sxrspaduxdkclqctns1xtw.jpeg"></p></div></div><br><p>  Ok, para a segunda decis√£o, tamb√©m montamos o palco. </p><br><h2 id="a-nelzya-li-na-primerah">  Mas √© poss√≠vel com exemplos? </h2><br><p>  Por uma quest√£o de clareza, realizaremos uma pequena simula√ß√£o.  Usaremos o <strong>Python 3.6.4</strong> . </p><br><blockquote>  Eu direi imediatamente que esses exemplos fazem parte de um dos trabalhos de casa, cada um dos quais √© oferecido aos alunos para solu√ß√£o dentro de duas semanas.  Reescrevi a parte em python (para popularizar a linguagem entre os engenheiros de r√°dio).  Talvez voc√™ encontre outras op√ß√µes na Web de outros ex-alunos. </blockquote><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.linalg <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> toeplitz <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convmtx</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(h,n)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> toeplitz(np.hstack([h, np.zeros(n<span class="hljs-number"><span class="hljs-number">-1</span></span>)]),\ np.hstack([h[<span class="hljs-number"><span class="hljs-number">0</span></span>], np.zeros(n<span class="hljs-number"><span class="hljs-number">-1</span></span>)])) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MSE_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(sigmaS, R, p, w)</span></span></span><span class="hljs-function">:</span></span> w = w.reshape(w.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) wH = np.conj(w).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, w.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) p = p.reshape(p.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) pH = np.conj(p).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, p.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) MSE = sigmaS - np.dot(wH, p) - np.dot(pH, w) + np.dot(np.dot(wH, R), w) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> MSE[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mu_opt_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(gamma, R)</span></span></span><span class="hljs-function">:</span></span> gamma = gamma.reshape(gamma.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) gammaH = np.conj(gamma).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, gamma.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) mu_opt = np.dot(gammaH, gamma) / np.dot(np.dot(gammaH, R), gamma) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mu_opt[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  Usaremos nosso filtro linear para o problema de <u>equaliza√ß√£o</u> do <u>canal</u> , cujo principal objetivo √© nivelar os v√°rios efeitos desse canal no sinal √∫til. </p><br><blockquote>  O c√≥digo fonte pode ser baixado em um arquivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ou <a href="">aqui</a> (sim, eu tive um hobby - editar Wikipedia). </blockquote><br><h3 id="model-sistemy">  Modelo do sistema </h3><br><p>  Suponha que exista um conjunto de antenas (j√° o examinamos em um artigo sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MUSIC</a> ). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/61a/9c2/da7/61a9c2da745081459f9001d0252936f1.png"></p><br><p>  <em>Fig.</em>  <em>3. Conjunto de antenas lineares n√£o direcionais (ULAA - conjunto de antenas lineares uniformes) [2, p.</em>  <em>32]</em> </p><br><p>  Defina os par√¢metros iniciais da estrutura: </p><br><pre> <code class="python hljs">M = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (number of sensors)</span></span></code> </pre> <br><p>  Neste artigo, consideraremos algo como um <u>canal de banda larga com desbotamento</u> , um recurso caracter√≠stico da <u>propaga√ß√£o de caminhos m√∫ltiplos</u> .  Para tais casos, geralmente √© aplicada uma abordagem na qual cada feixe √© modelado usando um atraso de uma certa magnitude (Fig. 4). </p><br><p><img src="https://habrastorage.org/webt/3t/tc/va/3ttcvau0o4njat-1beejefcudpy.png"></p><br><p>  <em>Fig.</em>  <em>4. O modelo do canal de banda larga com n atrasos fixos. [3, p.</em>  <em>29]</em>  <em>Como voc√™ entende, designa√ß√µes espec√≠ficas n√£o desempenham um papel - a seguir, usaremos designa√ß√µes ligeiramente diferentes.</em> </p><br><p>  O modelo do sinal recebido para um sensor √© expresso da seguinte forma: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a3f/c3f/2f0/a3fc3f2f0cd278622946ce2da28005fd.svg" alt="x (n) = \ sum_ {l = 0} ^ Lh (l) s (n-l) + \ nu (n)"></div><br><p>  Neste caso <img src="https://habrastorage.org/getpro/habr/post_images/fd6/0b2/b5b/fd60b2b5be4b7e93a0d905dd970c314f.svg" alt="n">  indica o n√∫mero de refer√™ncia, <img src="https://habrastorage.org/getpro/habr/post_images/e9f/c39/8e5/e9fc398e58e24442ddc2cf11684debbc.svg" alt="h (l)">  √â a resposta do canal ao longo do <em>l-</em> √©simo feixe, <em>L</em> √© o n√∫mero de registros de atraso, <em>s</em> √© o sinal transmitido (√∫til), <img src="https://habrastorage.org/getpro/habr/post_images/270/81a/400/27081a40025995898a2b982ff59a7e39.svg" alt="\ nu (n)">  - ru√≠do aditivo. </p><br><p>  Para v√°rios sensores, a f√≥rmula assumir√° a forma: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c0e/835/aa7/c0e835aa74d5dccf4ccdf625ebcc88b4.svg" alt="\ mathbf {x} (n) = \ mathbf {H} \ mathbf {s} (n) + \ mathbf {\ nu} (n)"></div><br><p>  onde <img src="https://habrastorage.org/getpro/habr/post_images/b0e/184/0ed/b0e1840edef9169f3e1f52974bea066d.svg" alt="\ mathbf {x} (n)">  e <img src="https://habrastorage.org/getpro/habr/post_images/270/81a/400/27081a40025995898a2b982ff59a7e39.svg" alt="\ mathbf {\ nu} (n)">  - ter dimens√£o <img src="https://habrastorage.org/getpro/habr/post_images/132/724/0f2/1327240f26480a83dffca393bb730c44.svg" alt="M \ times 1">  dimens√£o <img src="https://habrastorage.org/getpro/habr/post_images/ed0/8c1/e77/ed08c1e77cfaf357d5e90e9e2ae918aa.svg" alt="\ mathbf {H}">  √© igual a <img src="https://habrastorage.org/getpro/habr/post_images/25e/e63/fbb/25ee63fbb4a32f1a00d5c02aaea9b80c.svg" alt="M \ vezes (M-L)">  e a dimens√£o <img src="https://habrastorage.org/getpro/habr/post_images/5e3/d36/045/5e3d360455a5a33db6c17f93c119a694.svg" alt="\ mathbf {s} (n)">  √© igual a <img src="https://habrastorage.org/getpro/habr/post_images/6e2/fc1/636/6e2fc16365ac2698555dd979ed6b5eeb.svg" alt="(M-L) \ vezes 1">  . </p><br><p>  Suponha que cada sensor tamb√©m receba um sinal com um certo atraso, devido √† incid√™ncia da onda em um √¢ngulo.  Matrix <img src="https://habrastorage.org/getpro/habr/post_images/ed0/8c1/e77/ed08c1e77cfaf357d5e90e9e2ae918aa.svg" alt="\ mathbf {H}">  no nosso caso, ser√° uma matriz convolucional para o vetor de resposta para cada raio.  Eu acho que o c√≥digo ser√° mais claro: </p><br><pre> <code class="python hljs">h = np.array([<span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">0.779</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">0.722</span></span>, <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">1.862</span></span>]) L = len(h)<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-comment"><span class="hljs-comment"># number of signal sources H = convmtx(h,ML) print(H.shape) print(H)</span></span></code> </pre> <br><p>  A conclus√£o ser√°: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) &gt;&gt;&gt; array([[ <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> ], [<span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>, <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> ], [<span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>, <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>], [ <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>], [ <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>]])</code> </pre> <br><p>  Em seguida, definimos os dados iniciais para o sinal e ru√≠do √∫teis: </p><br><pre> <code class="python hljs">sigmaS = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (the signal's s(n) power) sigmaN = 0.01 #   (the noise's n(n) power)</span></span></code> </pre> <br><p>  Agora passamos a correla√ß√µes. </p><br><pre> <code class="python hljs">Rxx = (sigmaS)*(np.dot(H,np.matrix(H).H))+(sigmaN)*np.identity(M) p = (sigmaS)*H[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] p = p.reshape((len(p), <span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">A deriva√ß√£o das f√≥rmulas aqui (tamb√©m uma folha para os mais desesperados).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/hi/lh/ks/hilhksxoc_rkum_5ibn3m42ukxc.jpeg"></p></div></div><br><p>  Encontramos uma solu√ß√£o para o Wiener: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Solution of the Wiener-Hopf equation: wopt = np.dot(np.linalg.inv(Rxx), p) MSEopt = MSE_calc(sigmaS, Rxx, p, wopt)</span></span></code> </pre> <br><p>  Agora vamos para o m√©todo de descida de gradiente. </p><br><p>  Encontre o maior valor pr√≥prio para que dele possa ser derivado o limite superior da etapa (consulte a f√≥rmula (9)): </p><br><pre> <code class="python hljs">lamda_max = max(np.linalg.eigvals(Rxx))</code> </pre> <br><p>  Agora vamos definir uma s√©rie de etapas que formar√£o uma certa fra√ß√£o do m√°ximo: </p><br><pre> <code class="python hljs">coeff = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0.9</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>]) mus = <span class="hljs-number"><span class="hljs-number">2</span></span>/lamda_max*coeff <span class="hljs-comment"><span class="hljs-comment"># different step sizes</span></span></code> </pre> <br><p>  Defina o n√∫mero m√°ximo de itera√ß√µes: </p><br><pre> <code class="python hljs">N_steps = <span class="hljs-number"><span class="hljs-number">100</span></span></code> </pre> <br><p>  Execute o algoritmo: </p><br><pre> <code class="python hljs">MSE = np.empty((len(mus), N_steps), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> mu_idx, mu <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(mus): w = np.zeros((M,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> N_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(N_steps): w = w - mu*(np.dot(Rxx, w) - p) MSE[mu_idx, N_i] = MSE_calc(sigmaS, Rxx, p, w)</code> </pre> <br><p>  Agora faremos o mesmo, mas para a etapa adaptativa (f√≥rmula (10)): </p><br><pre> <code class="python hljs">MSEoptmu = np.empty((<span class="hljs-number"><span class="hljs-number">1</span></span>, N_steps), dtype=complex) w = np.zeros((M,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> N_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(N_steps): gamma = p - np.dot(Rxx,w) mu_opt = mu_opt_calc(gamma, Rxx) w = w - mu_opt*(np.dot(Rxx,w) - p) MSEoptmu[:, N_i] = MSE_calc(sigmaS, Rxx, p, w)</code> </pre> <br><p>  Voc√™ deve obter algo como isto: </p><br><div class="spoiler">  <b class="spoiler_title">Desenhando</b> <div class="spoiler_text"><pre> <code class="python hljs">x = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, N_steps+<span class="hljs-number"><span class="hljs-number">1</span></span>)] plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>), dpi=<span class="hljs-number"><span class="hljs-number">300</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx, item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(coeff): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> item == <span class="hljs-number"><span class="hljs-number">1</span></span>: item = <span class="hljs-string"><span class="hljs-string">''</span></span> plt.loglog(x, np.abs(MSE[idx, :]),\ label=<span class="hljs-string"><span class="hljs-string">'$\mu = '</span></span>+str(item)+<span class="hljs-string"><span class="hljs-string">'\mu_{max}$'</span></span>) plt.loglog(x, np.abs(MSEoptmu[<span class="hljs-number"><span class="hljs-number">0</span></span>, :]),\ label=<span class="hljs-string"><span class="hljs-string">'$\mu = \mu_{opt}$'</span></span>) plt.loglog(x, np.abs(MSEopt*np.ones((len(x), <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex)),\ label = <span class="hljs-string"><span class="hljs-string">'Wiener solution'</span></span>) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Number of steps'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Mean-Square Error'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Steepest descent'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.minorticks_on() plt.grid(which=<span class="hljs-string"><span class="hljs-string">'major'</span></span>) plt.grid(which=<span class="hljs-string"><span class="hljs-string">'minor'</span></span>, linestyle=<span class="hljs-string"><span class="hljs-string">':'</span></span>) plt.show()</code> </pre> </div></div><br><p><img src="https://habrastorage.org/webt/il/fa/8d/ilfa8dmoxgt4sjitiyvwbdjga6m.png"></p><br><p>  <em>Fig.</em>  <em>5. Curvas de aprendizado para etapas de tamanhos diferentes.</em> </p><br><p>  Fixa√ß√µes com o objetivo de falar os principais pontos da descida do gradiente: </p><br><ul><li>  como esperado, o passo ideal fornece a converg√™ncia mais r√°pida; </li><li>  n√£o significa mais melhor: tendo excedido o limite superior, n√£o alcan√ßamos converg√™ncia. </li></ul><br><p>  Ent√£o encontramos o vetor ideal de coeficientes de filtro que melhor nivelar√° os efeitos do canal - <u>treinamos o equalizador</u> . </p><br><h2 id="a-est-chto-to-bolee-blizkoe-k-realnosti">  Existe algo mais pr√≥ximo da realidade? </h2><br><p>  Claro!  J√° dissemos v√°rias vezes que a coleta de estat√≠sticas (isto √©, c√°lculo de matrizes e vetores de correla√ß√£o) em sistemas em tempo real est√° longe de ser sempre um luxo acess√≠vel.  No entanto, a humanidade se adaptou a essas dificuldades: em vez de uma abordagem <em>determinista</em> na pr√°tica, abordagens <u>adaptativas</u> s√£o usadas.  Eles podem ser divididos em dois grandes grupos [1, p.  246]: </p><br><ul><li>  <em>probabil√≠stico (estoc√°stico)</em> (por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SG</a> - gradiente estoc√°stico) </li><li>  e com base no m√©todo dos <em>m√≠nimos quadrados</em> (por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LMS</a> - M√≠nimos quadrados m√©dios ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RLS</a> - M√≠nimos quadrados recursivos) </li></ul><br><p>  O t√≥pico de filtros adaptativos est√° bem representado na comunidade de c√≥digo aberto (exemplos para python): </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pyroomacoustics</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">padasip</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">adaptfilt</a> </li></ul><br><blockquote>  No segundo exemplo, gosto especialmente da documenta√ß√£o.  No entanto, tenha cuidado!  Quando testei o pacote <strong>padasip</strong> , tive dificuldades em lidar com n√∫meros complexos (por padr√£o, float64 est√° impl√≠cito).  Talvez os mesmos problemas possam surgir ao trabalhar com outras implementa√ß√µes. </blockquote><p>  Os algoritmos, √© claro, t√™m suas pr√≥prias vantagens e desvantagens, cuja soma determina o escopo do algoritmo. </p><br><p>  Vamos dar uma r√°pida olhada nos exemplos: consideraremos os tr√™s algoritmos <em>SG</em> , <em>LMS</em> e <em>RLS</em> que j√° mencionamos (modelaremos na linguagem MATLAB - confesso, j√° havia espa√ßos em branco e reescreveremos tudo para uniformizar o python por uma quest√£o de ... bem ...). </p><br><p>  Uma descri√ß√£o dos algoritmos <em>LMS</em> e <em>RLS</em> pode ser encontrada, por exemplo, na doca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">padasip</a> . </p><br><div class="spoiler">  <b class="spoiler_title">A descri√ß√£o do SG pode ser encontrada aqui.</b> <div class="spoiler_text"><p>  A principal diferen√ßa da descida do gradiente √© um gradiente vari√°vel: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/76f/9e3/fbb/76f9e3fbbb4c7643f5af595103791091.svg" alt="\ mathbf {w} [n] = \ mathbf {w} [n-1] + \ mu \ left (\ mathbf {\ hat {p}} [n] - \ mathbf {\ hat {R}} _ {xx } [n] \ mathbf {w} [n-1] \ right)"></div><br><p>  √†s </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/633/bac/0aa/633bac0aae95be15cd31a312b4e0d2c5.svg" alt="\ mathbf {\ hat {R}} _ {xx} [n] = \ frac {1} {n} \ esquerda ((n-1) \ mathbf {\ hat {R}} _ {xx} [n-1 ] + \ mathbf {x} [n] \ mathbf {x} [n] ^ H \ √† direita)"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f7/bfd/f81/4f7bfdf81571e19eac474c7a8c380093.svg" alt="\ mathbf {\ hat {p}} [n] = \ frac {1} {n} \ left ((n-1) \ mathbf {\ hat {p}} [n-1] + \ mathbf {x} [ n] d [n] ^ * \ right)"></div></div></div><br><p>  1) Um caso semelhante ao considerado acima. </p><br><div class="spoiler">  <b class="spoiler_title">Fontes (MatLab / Octave).</b> <div class="spoiler_text"><p>  As fontes podem ser baixadas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . </p></div></div><br><p><img src="https://habrastorage.org/webt/ff/zm/hq/ffzmhqsrnwvvc0hdrcyzhapropw.png"></p><br><p>  <em>Fig.</em>  <em>6. Curvas de aprendizado para LMS, RLS e SG.</em> </p><br><p>  Pode-se notar imediatamente que, com sua relativa simplicidade, o algoritmo LMS pode, em princ√≠pio, n√£o chegar a uma solu√ß√£o √≥tima com um passo relativamente grande.  O RLS fornece o resultado mais r√°pido, mas tamb√©m pode falhar com um <em>fator de esquecimento</em> relativamente pequeno.  At√© agora, a SG est√° indo bem, mas vamos ver outro exemplo. </p><br><p>  2) O caso em que o canal muda com o tempo. </p><br><div class="spoiler">  <b class="spoiler_title">Fontes (MatLab / Octave).</b> <div class="spoiler_text"><p>  As fontes podem ser baixadas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . </p></div></div><br><p><img src="https://habrastorage.org/webt/v-/9d/sx/v-9dsxxwzr9jnbnswf0dmnvqrcu.png"></p><br><p>  <em>Fig.</em>  <em>7. Curvas de aprendizado para LMS, RLS e SG (mudan√ßas de canal ao longo do tempo).</em> </p><br><p>  E aqui a imagem j√° √© muito mais interessante: com uma mudan√ßa acentuada na resposta do canal, o LMS j√° parece ser a solu√ß√£o mais confi√°vel.  Quem teria pensado.  Embora o RLS com o fator de esquecimento certo tamb√©m forne√ßa um resultado aceit√°vel. </p><br><div class="spoiler">  <b class="spoiler_title">Algumas palavras sobre desempenho.</b> <div class="spoiler_text"><p>  Sim, √© claro, cada algoritmo tem sua pr√≥pria complexidade computacional espec√≠fica, mas, de acordo com minhas medi√ß√µes, minha m√°quina antiga pode lidar com um conjunto por cerca de 120 Œºs por itera√ß√£o no caso do LMS e SG e cerca de 250 Œºs por itera√ß√£o no caso do RLS.  Ou seja, a diferen√ßa √©, em geral, compar√°vel. </p></div></div><br><p>  E isso √© tudo por hoje.  Obrigado a todos que olharam! </p><br><h2 id="literatura">  Literatura </h2><br><ol><li>  Teoria do filtro adaptativo Haykin SS.  - Pearson Education India, 2005. </li><li>  Haykin, Simon e KJ Ray Liu.  Manual sobre processamento de array e redes de sensores.  Vol.  63. John Wiley &amp; Sons, 2010. pp.  102-107 </li><li>  Arndt, D. (2015).  Modelagem em canal para recep√ß√£o de sat√©lite m√≥vel terrestre (disserta√ß√£o de doutorado). </li></ol><br><h2 id="prilozhenie-1">  Ap√™ndice 1 </h2><br><div class="spoiler">  <b class="spoiler_title">Filtro Eigen</b> <div class="spoiler_text"><p>  O principal objetivo desse filtro √© maximizar a rela√ß√£o sinal-ru√≠do (SNR). </p><br><p><img src="https://habrastorage.org/webt/kk/v_/uu/kkv_uu-08dppu5i4yhkucc_b0ww.jpeg"></p><br><p>  Mas, a julgar pela presen√ßa de correla√ß√µes nos c√°lculos, isso tamb√©m √© mais um construto te√≥rico do que uma solu√ß√£o pr√°tica. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt455497/">https://habr.com/ru/post/pt455497/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt455483/index.html">Artista Ai-Da: rob√¥ human√≥ide se prepara para sua primeira exposi√ß√£o individual</a></li>
<li><a href="../pt455485/index.html">Scripts de ponto de verifica√ß√£o - execute scripts diretamente do Smart Console</a></li>
<li><a href="../pt455487/index.html">Treinamento Cisco 200-125 CCNA v3.0. Dia 10. Modos operacionais da porta do switch</a></li>
<li><a href="../pt455489/index.html">Conectando solu√ß√µes de √°udio e v√≠deo de terceiros ao Microsoft Teams</a></li>
<li><a href="../pt455493/index.html">O que h√° de novo na vers√£o Angular 8</a></li>
<li><a href="../pt455501/index.html">Como Hollywood usa secretamente a IA para tomar decis√µes importantes sobre as filmagens</a></li>
<li><a href="../pt455503/index.html">19 conceitos que voc√™ precisa aprender para se tornar um desenvolvedor Angular eficaz</a></li>
<li><a href="../pt455505/index.html">Reagir a acelera√ß√£o do aplicativo quatro vezes</a></li>
<li><a href="../pt455507/index.html">Vis√£o geral do pacote Python dat√°vel</a></li>
<li><a href="../pt455509/index.html">A hist√≥ria de por que eu ainda uso o jQuery</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
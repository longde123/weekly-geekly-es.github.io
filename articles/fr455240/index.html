<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘¨ğŸ¼ ğŸš¦ â™¦ï¸ Utilisation du taux de dÃ©fauts rejetÃ©s pour amÃ©liorer le rapport d'erreurs âï¸ ğŸ‘ ğŸ—ºï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vendredi saint tout le monde, amis! Ã€ la fin du mois de juin, nous lanÃ§ons un nouveau groupe lors du cours de spÃ©cialiste en AQ , qui fera l'objet de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Utilisation du taux de dÃ©fauts rejetÃ©s pour amÃ©liorer le rapport d'erreurs</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/455240/">  Vendredi saint tout le monde, amis!  Ã€ la fin du mois de juin, nous lanÃ§ons un nouveau groupe lors du cours de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">spÃ©cialiste en AQ</a> , qui fera l'objet de la publication d'aujourd'hui. <br><br><img src="https://habrastorage.org/webt/4m/5q/dj/4m5qdjzecdf-vqrx-npu-mr0w2c.png"><br><br>  Il existe de nombreux indicateurs grÃ¢ce auxquels vous pouvez mesurer l'efficacitÃ© de l'Ã©quipe de testeurs.  L'un d'eux est le taux de dÃ©fauts rejetÃ©s, ou le nombre de rapports d'erreur rejetÃ©s divisÃ© par le nombre total de rapports reÃ§us.  Vous devez penser que si le nombre de rapports rejetÃ©s est nul, c'est bien, mais ce n'est pas si simple.  Examinons les types d'erreurs rejetÃ©es, voyons comment elles affectent le taux d'erreurs rejetÃ©es et calculons le ratio correct pour votre Ã©quipe. <a name="habracut"></a><br><br>  Il existe trois catÃ©gories d'erreurs rejetÃ©es: <br><br><ul><li>  Erreurs irrÃ©prochables; </li><li>  Erreurs incorrectes </li><li>  Erreurs en double. </li></ul><br>  CommenÃ§ons par les erreurs elles-mÃªmes. <br><br><h2>  Erreurs irrÃ©productibles </h2><br>  Il existe deux types d'erreurs irrÃ©prochables.  La premiÃ¨re est une erreur qui est vraiment difficile Ã  reproduire.  Cela peut Ãªtre une erreur rÃ©sultant de l'interaction de plusieurs paramÃ¨tres, dont certains que vous ne connaissez mÃªme pas. <br><br>  Supposons que vous ayez effectuÃ© plusieurs tests consÃ©cutifs et que l'un des tests ait modifiÃ© le paramÃ¨tre de configuration de la valeur par dÃ©faut A en une autre valeur B. L'erreur se produit uniquement lorsque le paramÃ¨tre de configuration contient la valeur B et que la valeur d'entrÃ©e est C. En essayant de reproduire l'erreur, vous souhaiterez probablement commencer par un Ã©tat connu afin d'initialiser le systÃ¨me (ou, Ã©ventuellement, d'effectuer une installation propre).  Aucune erreur ne se produira car le paramÃ¨tre de configuration contient Ã  nouveau la valeur par dÃ©faut A. <br><br>  Une autre variante de ce type d'erreur non reproductible est lorsque le test a vraiment trouvÃ© un dÃ©faut, mais il n'y a pas de donnÃ©es dans les informations de lecture: une Ã©tape, une valeur d'entrÃ©e spÃ©cifique ou une comprÃ©hension que l'erreur ne se produit qu'avec une certaine procÃ©dure.  Par consÃ©quent, les tentatives de reproduction de l'erreur ne mÃ¨nent Ã  rien. <br><br>  Cependant, dans les deux cas ci-dessus, il y a effectivement un dÃ©faut dans le produit lui-mÃªme. <br>  Le deuxiÃ¨me type d'erreur irrÃ©productible est lorsque l'erreur ne peut pas Ãªtre rÃ©pÃ©tÃ©e car elle n'existe pas.  Le testeur a peut-Ãªtre remarquÃ© quelque chose, mais a mal interprÃ©tÃ©, ou le systÃ¨me utilisÃ© pour les tests peut avoir un problÃ¨me, tel qu'un composant matÃ©riel dÃ©fectueux, un pilote incompatible ou des paramÃ¨tres d'accÃ¨s incorrects.  Les tentatives de reproduction de l'erreur sur un systÃ¨me correctement configurÃ© Ã©chouent. <br><br>  Ces deux types d'erreurs sont gÃ©nÃ©ralement signalÃ©s dans les systÃ¨mes de rapport d'erreurs comme Â«rejetÃ©s - ne peuvent pas Ãªtre reproduitsÂ». <br><br><h2>  Erreurs incorrectes </h2><br>  Ce type d'erreur se produit si le testeur dÃ©cide que le produit doit se comporter d'une certaine maniÃ¨re et signale une erreur lorsque le comportement ne rÃ©pond pas Ã  ses attentes.  Cependant, une Ã©tude plus dÃ©taillÃ©e des exigences montre que les attentes du testeur Ã©taient erronÃ©es et que le produit fonctionnait correctement.  Autrement dit, le produit testÃ© fonctionnait correctement et le testeur, qui n'Ã©tait pas suffisamment familiarisÃ© avec les exigences, a fait une erreur. <br><br>  De telles erreurs sont gÃ©nÃ©ralement signalÃ©es dans les systÃ¨mes de rapport d'erreurs comme Â«rejetÃ©es - pas des erreursÂ» ou Â«rejetÃ©es - par l'architectureÂ» (c'est-Ã -dire que le comportement est cohÃ©rent avec l'architecture). <br><br><h2>  Erreurs en double </h2><br>  Les erreurs rÃ©pÃ©titives sont les erreurs que l'on a dÃ©jÃ  signalÃ©es et la suivante les signale.  Une erreur n'est rÃ©pÃ©titive que si les Â«symptÃ´mesÂ» de son apparition sont les mÃªmes.  Et si la cause premiÃ¨re de l'erreur est la mÃªme, mais que les Â«symptÃ´mesÂ» se sont avÃ©rÃ©s diffÃ©rents, ce n'est pas une rÃ©pÃ©tition de l'erreur! <br><br>  Ces erreurs sont gÃ©nÃ©ralement signalÃ©es dans les systÃ¨mes de rapport d'erreurs comme Â«rejetÃ©es - dupliquÃ©es / rÃ©pÃ©tÃ©esÂ» <br><br><h2>  Comment les erreurs rejetÃ©es affectent une Ã©quipe </h2><br>  De toute Ã©vidence, une erreur incorrecte est une sorte de perte de temps que le testeur a passÃ© Ã  reproduire l'erreur et Ã  la signaler, le temps que ceux qui trient les erreurs passent Ã  les lire et Ã  les comprendre, et le temps que les dÃ©veloppeurs passent Ã  essayer de reproduire une erreur non reproductible ou pour rÃ©parer (et dysfonctionner) quelque chose qui n'avait pas besoin de ce correctif. <br><br>  En plus du fait que le taux d'erreur rejetÃ© ou RDR est une mesure de l'inefficacitÃ© de l'Ã©quipe de testeurs, il parle Ã©galement du professionnalisme des testeurs en gÃ©nÃ©ral.  Une erreur qui ne peut pas Ãªtre reproduite en raison du manque d'informations nÃ©cessaires dans le rapport indique que les testeurs n'Ã©taient pas mÃ©ticuleux et n'ont pas travaillÃ© assez dur pour reproduire cette erreur en utilisant les Ã©tapes dÃ©crites ci-dessus.  De plus, pour les erreurs qui sont rarement reproduites, les testeurs n'ont gÃ©nÃ©ralement pas notÃ© la faible frÃ©quence de lecture dans le rapport. <br><br>  L'apparition d'une erreur incorrecte indique que les testeurs ne comprennent pas parfaitement les exigences du produit.  Des erreurs rÃ©pÃ©tÃ©es indiquent que les testeurs n'ont pas effectuÃ© de recherche minimale dans la base de donnÃ©es d'erreurs locale pour vÃ©rifier si elle s'est produite plus tÃ´t.  Ou, cela signifie que le spÃ©cialiste qui a signalÃ© cette erreur n'a pas Ã©tÃ© le premier Ã  inclure les bons mots clÃ©s dans le nom pour faciliter la recherche de ses autres collÃ¨gues. <br><br>  Ã€ son tour, sâ€™il sâ€™avÃ¨re que lâ€™erreur que jâ€™ai trouvÃ©e est rejetÃ©e, je suis irritÃ©, car jâ€™Ã©tais considÃ©rÃ© comme un profane.  D'une part, cela signifie que je dÃ©fendrai les erreurs constatÃ©es.  Lorsque mon rapport est rejetÃ©, je procÃ¨de comme suit: <br><br><ul><li>  Je vÃ©rifie Ã  nouveau si l'erreur se reproduit dans mon systÃ¨me et j'ajoute les Ã©tapes de lecture si j'ai ratÃ© quelque chose; </li><li>  Si ma mauvaise comprÃ©hension des exigences a Ã©tÃ© causÃ©e par une exigence ambiguÃ« ou une documentation incorrecte, j'insisterai pour que l'erreur soit marquÃ©e comme une erreur de documentation et ne soit fermÃ©e que lorsque la documentation est corrigÃ©e; </li><li>  Si je pense que le comportement du produit lors de la satisfaction de l'exigence est incorrect, je parlerai des exigences avec les architectes et les dÃ©veloppeurs, essayer de les convaincre que les exigences doivent Ãªtre mises Ã  jour (au final, je reprÃ©sente l'opinion du client!); </li><li>  Si l'erreur est rejetÃ©e en double, je m'assurerai qu'elle n'a pas Ã©tÃ© marquÃ©e de la mÃªme maniÃ¨re, ou qu'elle n'apparaÃ®t pas Â«selon le mÃªme scÃ©narioÂ». </li></ul><br>  D'un autre cÃ´tÃ©, une certaine probabilitÃ© de rejet d'erreur me rend prudent.  Si je ne suis pas complÃ¨tement sÃ»r d'avoir trouvÃ© un bogue, je passerai un peu plus de temps Ã  vÃ©rifier avant de signaler.  Je demande souvent Ã  un collÃ¨gue si j'interprÃ¨te correctement les exigences ou si je vÃ©rifie si l'erreur se reproduit sur le systÃ¨me de quelqu'un d'autre. <br><br><h2>  Avis contre l'absence totale d'erreurs rejetÃ©es </h2><br>  L'Ã©quipe de test doit surveiller et s'efforcer de rÃ©duire le niveau de RDR.  La seule question est, quel RDR doit Ãªtre considÃ©rÃ© comme bon? <br><br>  Ã€ premiÃ¨re vue, il semble que 0% soit le rÃ©sultat optimal, mais je suis fortement en dÃ©saccord avec cela.  Je pense que lorsque le RDR est maintenu Ã  un niveau sain, c'est normal, car s'il est proche de zÃ©ro, l'Ã©quipe de test souffre Ã©videmment de problÃ¨mes non moins graves que, disons, un RDR trop Ã©levÃ©. <br><br>  L'Ã©quipe de test doit faire de gros efforts pour atteindre un RDR extrÃªmement bas.  Chaque erreur rejetÃ©e sera analysÃ©e pour comprendre ce qui ne va pas, et chaque testeur qui a signalÃ© une erreur rejetÃ©e devra expliquer ce qui s'est rÃ©ellement passÃ© et comment une telle situation peut Ãªtre Ã©vitÃ©e Ã  l'avenir.  En consÃ©quence, les testeurs rapporteront des erreurs dans lesquelles ils sont absolument sÃ»rs. <br><br>  S'ils remarquent un comportement qui, selon eux, nuira Ã  l'utilisabilitÃ© du produit, ils prÃ©fÃ©reront considÃ©rer ce comportement comme acquis, plutÃ´t que de justifier qu'ils ont trouvÃ© une erreur qui, en fait, n'est pas une erreur fondÃ©e sur des exigences.  S'ils ont des preuves qu'une erreur s'est produite, mais qu'il n'y a pas de bon scÃ©nario pour la reproduire, ils prÃ©fÃ©reront ne pas la signaler;  ils ne veulent vraiment pas se fÃ¢cher.  S'ils rencontrent un bogue frivole, ils peuvent dÃ©cider de ne pas le signaler du tout, car les bogues mineurs ne le corrigent pas toujours, alors pourquoi prendre le risque et avoir peur que l'erreur que vous avez trouvÃ©e soit rejetÃ©e? <br><br>  En bref, la recherche d'un RDR trÃ¨s faible provoque du stress et un comportement malsain dans l'Ã©quipe de test, et augmente Ã©galement la probabilitÃ© que certaines erreurs passent inaperÃ§ues. <br><br>  Nous avons besoin de testeurs qui non seulement signalent des erreurs Ã©videntes, mais avertissent Ã©galement de tout comportement suspect dans le projet.  Nous pensons que les testeurs qui attachent une grande importance Ã  ce que l'erreur ne disparaisse pas, mÃªme au prix de rapports en double, sont meilleurs que les testeurs qui passent des heures Ã  vÃ©rifier si un bogue a dÃ©jÃ  Ã©tÃ© signalÃ© dans les rapports ou non, de peur qu'ils ne faire un double.  Nous voulons que les testeurs se sentent Ã  l'aise en remettant en question le mot de l'architecte systÃ¨me ou de la spÃ©cification des exigences, mÃªme si cela signifie que certaines de leurs erreurs seront marquÃ©es comme rejetÃ©es. <br><br>  Nous avons besoin de testeurs qui n'ont pas peur de faire des erreurs de temps en temps.  Cela signifie que l'Ã©quilibre est nÃ©cessaire, donc un petit RDR est considÃ©rÃ© comme acceptable. <br><br><h2>  Trouver le taux optimal de dÃ©fauts rejetÃ©s </h2><br>  Ma rÃ¨gle d'or est que le RDR devrait Ãªtre de 15%.  Cette valeur est basÃ©e sur mon expÃ©rience avec l'Ã©quipe de testeurs, qui, selon tous les comptes, Ã©tait une bonne Ã©quipe efficace.  C'Ã©tait notre RDR au cours de plusieurs projets qui se sont succÃ©dÃ©, tandis que l'autre Ã©quipe, qui a travaillÃ© sur les mÃªmes projets et en parallÃ¨le avec nous, bien qu'elle soit moins consciente du produit et considÃ©rÃ©e comme moins efficace, avait un RDR de 30%. . <br><br>  Je ne pense pas qu'il y ait une justification Ã  ce sens autre que mon sentiment intÃ©rieur.  Ce n'est certainement pas scientifique.  Je ne discuterai pas avec une Ã©quipe qui vise 10 ou 20%, mais je pense que supporter 30% ou fixer un objectif de 5% est dÃ©jÃ  un problÃ¨me. <br><br>  En fin de compte, c'est une dÃ©cision qui doit Ãªtre prise par l'Ã©quipe de testeurs, en fonction des caractÃ©ristiques du produit, du niveau d'expertise de l'Ã©quipe, du modÃ¨le de dÃ©veloppement, de l'expÃ©rience de l'Ã©quipe de dÃ©veloppement et bien plus encore.  Je vous recommande fortement de garder un Å“il sur le RDR et de vous demander si vous devez en faire quelque chose.  Et s'il est trop Ã©levÃ© ou trop bas, des mesures appropriÃ©es doivent Ãªtre prises. <br><br>  Par tradition, nous attendons vos commentaires et vous invitons Ã  un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">webinaire gratuit</a> , qui se tiendra le 14 juin.  A trÃ¨s bientÃ´t! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455240/">https://habr.com/ru/post/fr455240/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455226/index.html">Pourquoi appliquer un linguiste appliquÃ©?</a></li>
<li><a href="../fr455228/index.html">Celui qui a ressuscitÃ© Duke Nukem: Entretien avec Randy Pitchford, Gearbox Wizard</a></li>
<li><a href="../fr455230/index.html">Types de rÃ©fÃ©rence nullables dans C # 8.0 et analyse statique</a></li>
<li><a href="../fr455234/index.html">Types de rÃ©fÃ©rence Nullable en C # 8.0 et analyse statique</a></li>
<li><a href="../fr455236/index.html">Comodo rÃ©voque les certificats sans raison</a></li>
<li><a href="../fr455242/index.html">Moins d'oreilles ou comment ne pas gÃ¢cher le son du jeu dÃ¨s le dÃ©but</a></li>
<li><a href="../fr455244/index.html">Bande dessinÃ©e "Soldering is Easy" dans la version mise Ã  jour (2019)</a></li>
<li><a href="../fr455246/index.html">L'inscription Ã  la JournÃ©e de l'expÃ©rience client Ã  Saint-PÃ©tersbourg est ouverte le 20 juin</a></li>
<li><a href="../fr455248/index.html">Principales erreurs de dÃ©veloppement lors de l'utilisation de PostgreSQL</a></li>
<li><a href="../fr455250/index.html">Celui qui a ressuscitÃ© Duke Nukem: entretien avec Randy Pitchford, magicien de Gearbox</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
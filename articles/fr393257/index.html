<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚣🏻 🔹 🔓 Comment dessiner et lire le son 🚴🏼 🎅🏾 🤟🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Photo de Matthew Potter  CC-BY
 
 Comment connecter les informations audio et visuelles? Cette question est souvent posée par des scientifiques et des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment dessiner et lire le son</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/audiomania/blog/393257/"><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/pw/ry/9p/pwry9psyvxotycy6ivmkj-qkosw.jpeg"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Photo de </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Matthew Potter </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CC-BY</font></font></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Comment connecter les informations audio et visuelles? </font><font style="vertical-align: inherit;">Cette question est souvent posée par des scientifiques et des amateurs du monde entier. </font><font style="vertical-align: inherit;">Ainsi, en février 2006, la nouvelle selon laquelle les scientifiques ont réussi à reproduire les sons d'un pot en argile de plus de 6 500 ans s'est rapidement répandue sur Internet. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le potier aurait appliqué un rythme musical au pot pendant sa fabrication. </font><font style="vertical-align: inherit;">Malheureusement, cela s'est avéré être une plaisanterie d'April Fools infructueuse à la télévision belge.</font></font><a name="habracut"></a><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cependant, Patrick Feaster a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pu</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> traiter le dossier, dont l'âge dépasse 1000 ans. </font><font style="vertical-align: inherit;">A cette occasion, en mai 2011, il s'est exprimé lors de la conférence de l'Association for Recorded Sound Collections (ARSC) avec l'ouverture de la «paléospectrophonie».</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Plonger dans l'histoire: retranscrire des enregistrements passés</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Patrick utilise la technologie moderne (dans ce cas, pas particulièrement moderne, puisque le spectrogramme a été inventé il y a longtemps) pour convertir des objets visuels en objets sonores. Cependant, l'humanité n'a pas toujours suivi cette voie et a essayé, au contraire, de «capturer» le son dans les images. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pendant longtemps (avant la création du phonographe par Thomas Edison), les gens se sont inquiétés de la question: comment trouver un moyen de corriger la musique qui aiderait la personne qui regarde l'enregistrement à jouer la mélodie dans leur tête aussi facilement que les musiciens professionnels le font en regardant la partition. Malheureusement, selon le Dr Fister, une telle tâche est en principe inaccessible, car notre cerveau dans la plupart des cas n'est pas assez bon pour convertir des informations visuelles en audio.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Peut-être que la solution à ce problème dans le passé n'a pas été couronnée de succès, mais l'histoire nous a laissé beaucoup de preuves de la façon dont les gens de différentes époques ont essayé de créer des systèmes d'enregistrement sonore similaires. Le plus célèbre de ces systèmes a formé la base du phono-autographe - le prédécesseur du phonographe, inventé par le Français Edouard Martenville. Un phonoautographe était un appareil dans lequel le son traversait un cône, faisant vibrer la membrane connectée à l'aiguille. L'aiguille, à son tour, dessinait des lignes ondulées sur un cylindre en verre recouvert de papier de suie.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
À l'aide d'un phono-autographe, le son pouvait être capturé, mais il n'y avait aucun moyen de le reproduire. C'est le problème que Fister a décidé. En 2008, lui, ses collègues et l'expert audio David Giovannoni se sont réunis au Lawrence Berkeley National Laboratory pour déchiffrer l'un des phonoautographes les mieux conservés de Martenville. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lawrence’s Lab a développé des technologies pour extraire les sons de photographies de haute qualité qui capturaient des images de supports de cire fragiles ou de disques cassés. Grâce à ces technologies, les scientifiques ont reçu du phonoautogramme l'enregistrement de la chanson «Moonlight» («Au Clair de la Lune»), réalisée en 1860. On pense que c'est le premier disque sur lequel on peut distinguer une voix humaine.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Cependant, la solution à ce problème n'était pas suffisante pour Fister: par la suite, il a non seulement enregistré le son de plus de 50 phonoautogrammes, mais a également enquêté sur des tentatives antérieures d '«enregistrer du son». </font><font style="vertical-align: inherit;">Aussi étrange que cela puisse paraître, le service Google Livres a aidé ce scientifique. </font><font style="vertical-align: inherit;">En l'utilisant, Fister a noté des personnages de livres qui étaient constamment ignorés, considérés comme des bizarreries historiques. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il trouva la plus ancienne ligne ondulée du livre de 1806. </font><font style="vertical-align: inherit;">Grâce à d'autres techniques, il a pu déchiffrer la mélodie de 1677, qui a été enregistrée par de nombreux points. </font><font style="vertical-align: inherit;">Un autre a été découvert dans les registres du 10e siècle, où les lignes montraient quelle clé il fallait chanter. </font><font style="vertical-align: inherit;">Des exemples de telles entrées peuvent être trouvés sur son site Web </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Phonozoïque</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une autre approche</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les chercheurs du MIT, de Microsoft et d'Adobe suivent un chemin différent: ils </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">reconstruisent le</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> son à partir d'une image en mouvement (ou plutôt vibrante). Les chercheurs ont développé un algorithme pour obtenir un signal audio à partir de vibrations enregistrées sur vidéo. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans l'une de ces expériences, ils ont réussi à extraire la parole lisible de l'enregistrement d'un paquet vide sous les puces. Dans un certain nombre d'autres expériences, la même chose pourrait être faite avec la surface d'une feuille d'aluminium, un verre d'eau et même avec les feuilles d'une plante domestique. En 2014, l'équipe a présenté ses réalisations lors de la conférence annuelle SIGGRAPH. ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vidéo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> d'une présentation par l'un des chercheurs qui ont travaillé sur le projet lors de la conférence TED.)</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le fait est que lorsqu'un son entre en contact avec un objet, il le fait vibrer. Les mouvements créés par ces vibrations sont si légers et invisibles qu'une personne ne peut pas les voir. Cependant, la caméra peut les «voir»: pour extraire le signal audio de la vidéo, les scientifiques ont utilisé l'enregistrement vidéo avec un taux de capture d'images supérieur à la fréquence du signal audio. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Initialement, des caméras avec une fréquence de prise de vue de 2000 et 6000 images par seconde ont été utilisées dans les expériences, mais les chercheurs ont essayé d'utiliser d'autres caméras plus économiques. Bien sûr, il n'était pas possible d'extraire la parole articulée de la vidéo enregistrée à une fréquence d'images de 60 images par seconde, mais il semblait toujours possible de comprendre combien de personnes étaient dans la pièce, leur sexe et même les caractéristiques de leur prononciation.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bien sûr, quand on pense à utiliser de tels développements, des «histoires d'espionnage» viennent à l'esprit, cependant, les chercheurs eux-mêmes appellent leur projet l'occasion de découvrir de nouvelles facettes à l'image des objets et d'étudier leurs propriétés jusque-là inexplorées. </font><font style="vertical-align: inherit;">Et s'il y a des centaines d'années, les gens essayaient de trouver un moyen «d'enregistrer le son», maintenant un tel «enregistrement» devient un effet secondaire qui, à son tour, aide à révéler de nouvelles propriétés d'objets familiers.</font></font><br>
<br>
<h5><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Faites-le vous-même</font></font></h5><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Comme déjà mentionné, le premier phonoautogramme a été décrypté grâce à la technologie de reproduction du son à partir de photographies d'anciens enregistrements (nous avons déjà </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">écrit</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sur cette technologie </font><font style="vertical-align: inherit;">dans l'un de nos documents - il contient également des liens vers des enregistrements audio décryptés). Cependant, Patrick Fister souligne que n'importe qui peut faire face à cette tâche - s'il sait quoi faire. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un processus détaillé est décrit dans </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ce</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> document. À nous seuls, nous notons que pour résoudre le problème, vous aurez besoin d'une photo de haute qualité, de compétences de base en Photoshop (la vague dessinée sur du vinyle doit être numérisée, "redressée" - la rainure sur la plaque est tordue en spirale - supprimez toutes sortes de bruit et de déplacements), ainsi que d'un ordinateur relativement puissant avec une grande quantité de RAM.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pour convertir l'image résultante en un fichier WAV, Patrick utilise un logiciel plutôt exotique: c'est ImageToSound. C'est gratuit, mais malgré cela, c'est assez difficile à trouver sur le réseau (Patrick a partagé la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">source</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ). </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le programme convertit séquentiellement chaque bloc d'image (largeur de bloc - 1 pixel) en un échantillon audio. Malheureusement, ce logiciel ne prend même pas en charge Windows 7 (l'auteur utilise un ordinateur séparé avec Windows 98 pour fonctionner). Comme alternative, Fister suggère d'utiliser </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">le programme</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> AEO-Light, mais avertit qu'il n'est pas complètement familier avec les subtilités de travailler avec lui.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La dernière étape consiste à contrôler la vitesse de lecture. Ici, les mathématiques simples viennent à la rescousse. Vous devez d'abord connaître la vitesse de lecture sur la plaque d'origine, la durée d'un tour de l'onde numérisée (après «déspiralisation») en pixels et la fréquence d'échantillonnage du fichier final. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si l'image a été éditée dans un fichier audio avec une fréquence d'échantillonnage de 44,1 kHz, cela signifie que le second du fichier audio sera égal à 44 100 pixels de l'image. Si, par exemple, la vitesse d'une chanson sur un disque vinyle était de 50 tr / min, et après la numérisation et la déspiralisation, une révolution du disque a pris 30.000 pixels, nous obtenons 1.500.000 pixels par minute (50x30.000).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Si nous divisons ce nombre par 60, nous obtenons le nombre de pixels par seconde (1 500 000/60 = 25 000). </font><font style="vertical-align: inherit;">Divisez le taux d'échantillonnage par le nombre de pixels par seconde (44 100/25 000 = 1,764). </font><font style="vertical-align: inherit;">Multipliez le nombre résultant par la longueur du fichier audio (durée de lecture du morceau) et obtenez l'heure avec laquelle ce fichier a été enregistré à l'origine. </font><font style="vertical-align: inherit;">Si la vitesse de lecture de l'enregistrement d'origine est inconnue, Patrick vous conseille de choisir la vitesse finale à l'oreille. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Patrick Fister prévient - c'est un travail assez laborieux qui prend du temps et de la patience, mais donne en même temps des résultats parfois étonnants: surtout en ce qui concerne les voix du passé, qui, semble-t-il, étaient à jamais perdues. </font></font><br>
<br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS Plus de documents sur le thème de l'audio - dans notre blog " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">World of Hi-Fi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ".</font></font></i></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr393257/">https://habr.com/ru/post/fr393257/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr393243/index.html">Les conspirologues se réjouissent: après l'apparition des ovnis, la diffusion de la NASA avec l'ISS a été interrompue</a></li>
<li><a href="../fr393247/index.html">Quelques histoires typiques du développeur</a></li>
<li><a href="../fr393249/index.html">Collection de télégrammes de bots pour les geeks</a></li>
<li><a href="../fr393251/index.html">Il sait tout de toi</a></li>
<li><a href="../fr393253/index.html">Le deuxième trailer de WarCraft soulève de sérieuses inquiétudes</a></li>
<li><a href="../fr393261/index.html">MediaTek Labs vous invite au prochain webinaire gratuit sur le développement de gadgets pour la maison intelligente</a></li>
<li><a href="../fr393263/index.html">Comment diviser les billions de dollars gagnés grâce à l'exploitation minière dans l'espace?</a></li>
<li><a href="../fr393265/index.html">Les imprimantes piratées des universités allemandes impriment de nombreux tracts antisémites</a></li>
<li><a href="../fr393267/index.html">Veille</a></li>
<li><a href="../fr393269/index.html">8 petites choses de Chine pour organiser le lieu de travail d'un spécialiste informatique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
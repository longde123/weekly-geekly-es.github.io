<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø üë©‚Äçüöí üôé Inscreva-se no Kafka via HTTP ou como simplificar seus ganchos da web üßíüèª ü§ó üåÖ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Existem v√°rias maneiras de processar mensagens dos sistemas Pub-Sub: usando um servi√ßo separado, isolando um processo isolado, orquestrando um conjunt...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Inscreva-se no Kafka via HTTP ou como simplificar seus ganchos da web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/435346/">  Existem v√°rias maneiras de processar mensagens dos sistemas Pub-Sub: usando um servi√ßo separado, isolando um processo isolado, orquestrando um conjunto de processos / fluxos, IPC complexo, Poll-over-Http e muitos outros.  Hoje eu quero falar sobre como usar o Pub-Sub sobre HTTP e sobre o meu servi√ßo escrito especificamente para isso. <br><br>  O uso de um back-end de servi√ßo HTTP pronto em alguns casos √© uma solu√ß√£o ideal para o processamento de uma fila de mensagens: <br><br><ol><li>  Balanceamento fora da caixa.  Normalmente, o back-end j√° est√° atr√°s do balanceador e possui uma infraestrutura pronta para carregar, o que simplifica bastante o trabalho com mensagens. </li><li>  Usando um controlador REST regular (qualquer recurso HTTP).  O consumo de mensagens HTTP minimiza o custo de implementa√ß√£o de computadores para diferentes idiomas se o back-end for misto. </li><li>  Simplifica√ß√£o do uso de ganchos da Web de outros servi√ßos.  Agora, quase todos os servi√ßos (Jira, Gitlab, Mattermost, Slack ...) de alguma forma suportam ganchos da Web para interagir com o mundo exterior.  Voc√™ pode facilitar a vida se ensinar a fila a executar as fun√ß√µes de um expedidor HTTP. </li></ol><br>  Essa abordagem tamb√©m tem desvantagens: <br><br><ol><li>  Voc√™ pode esquecer a leveza da solu√ß√£o.  O HTTP √© um protocolo pesado, e o uso de estruturas do lado do consumidor aumentar√° instantaneamente a lat√™ncia e a carga. </li><li>  Perdemos os pontos fortes da abordagem Poll, obtendo as fraquezas do Push. </li><li>  O processamento de mensagens pelas mesmas inst√¢ncias de servi√ßo que processam clientes pode afetar a capacidade de resposta.  Isso n√£o √© significativo, pois √© tratado com equil√≠brio e isolamento. </li></ol><br>  Eu implementei a ideia como um servi√ßo Fila por HTTP, que ser√° discutido mais adiante.  O projeto foi escrito em Kotlin usando o Spring Boot 2.1.  Como corretor, apenas o Apache Kafka est√° dispon√≠vel no momento. <br><a name="habracut"></a><br>  <i>Al√©m disso, sup√µe-se que o leitor esteja familiarizado com Kafka e saiba sobre os commit (commit) e as compensa√ß√µes (offset) das mensagens, os princ√≠pios de grupos (grupo) e consumidores (consumidor), e tamb√©m entenda como a parti√ß√£o (parti√ß√£o) difere do t√≥pico (t√≥pico) .</i>  <i>Se houver lacunas, recomendo que voc√™ leia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esta</a> se√ß√£o da documenta√ß√£o do Kafka antes de continuar.</i> <br><br><h1>  Conte√∫do </h1><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Revis√£o</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Confirma</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tratamento de erros</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Mensagens</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Desempenho</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Demonstra√ß√£o</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Conclus√£o</a> </li></ul><br><a name="overview"></a><h1>  Revis√£o </h1><br>  O Queue-Over-Http √© um servi√ßo que atua como intermedi√°rio entre um intermedi√°rio de mensagens e o consumidor HTTP final (o servi√ßo facilita a implementa√ß√£o do suporte ao envio de mensagens aos consumidores de qualquer outra maneira, por exemplo, v√°rios * RPC).  No momento, apenas est√£o dispon√≠veis assinatura, cancelamento de inscri√ß√£o e exibi√ß√£o da lista de consumidores.O envio de mensagens para o intermedi√°rio (produ√ß√£o) via HTTP ainda n√£o foi implementado devido √† incapacidade de garantir a ordem das mensagens sem o suporte especial do produtor. <br><br>  O √≠ndice do servi√ßo √© o consumidor, que pode se inscrever em parti√ß√µes espec√≠ficas ou simplesmente em t√≥picos (o padr√£o de t√≥pico √© suportado).  No primeiro caso, o equil√≠brio autom√°tico de parti√ß√µes √© desativado.  Ap√≥s a inscri√ß√£o, o recurso HTTP especificado come√ßa a receber mensagens das parti√ß√µes Kafka atribu√≠das.  Arquitetonicamente, cada assinante √© associado a um cliente Kafka Java nativo. <br><br><div class="spoiler">  <b class="spoiler_title">hist√≥ria divertida sobre KafkaConsumer</b> <div class="spoiler_text">  Kafka tem um maravilhoso cliente Java que pode fazer muito.  Eu o uso no adaptador de fila para receber mensagens do broker e depois envi√°-lo para as filas de servi√ßo local.  Vale ressaltar que o cliente trabalha exclusivamente no contexto de um √∫nico thread. <br><br>  A ideia do adaptador √© simples.  Come√ßamos em um thread, escrevemos o agendador mais simples de clientes nativos, focando na redu√ß√£o da lat√™ncia.  Ou seja, escrevemos algo semelhante: <br><br><pre><code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (!Thread.interrupted()) { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> hasWork = <span class="hljs-literal"><span class="hljs-literal">false</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (consumer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> kafkaConsumers) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> queueGroup = consumers[consumer] ?: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span> invalidateSubscription(consumer, queueGroup) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> records = consumer.poll(Duration.ZERO) <span class="hljs-comment"><span class="hljs-comment">/*      */</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!records.isEmpty) { hasWork = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } } <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> committed = doCommit() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!hasWork &amp;&amp; committed == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// ,    Thread.sleep(1) } }</span></span></code> </pre> <br>  Parece que tudo √© maravilhoso, a lat√™ncia √© m√≠nima, mesmo com dezenas de consumidores.  Na pr√°tica, o <code>KafkaConsumer</code> para esse modo de opera√ß√£o e fornece uma taxa de aloca√ß√£o de cerca de 1,5 MB / s em tempo ocioso.  Com 100 correios, a taxa de aloca√ß√£o atinge 150 MB / se faz com que o GC pense na aplica√ß√£o.  Obviamente, todo esse lixo est√° na √°rea jovem, a GC √© capaz de lidar com isso, mas ainda assim, a solu√ß√£o n√£o √© perfeita. <br><br>  Obviamente, voc√™ precisa seguir o caminho t√≠pico do <code>KafkaConsumer</code> e agora coloco cada assinante no meu fluxo.  Isso fornece uma sobrecarga para mem√≥ria e programa√ß√£o, mas n√£o h√° outra maneira. <br><br>  Reescrevi o c√≥digo de cima, removendo o loop interno e alterando <code>Duration.ZERO</code> para <code>Duration.ofMillis(100)</code> .  Acontece que a taxa de aloca√ß√£o cai para 80-150 KB / s aceit√°vel por consumidor.  No entanto, a pesquisa com um tempo limite de 100 ms atrasa toda a fila de confirma√ß√µes para esses mesmos 100 ms, e isso √© inaceit√°vel. <br><br>  No processo de encontrar solu√ß√µes para o problema, lembro-me de <code>KafkaConsumer::wakeup</code> , que lan√ßa um <code>WakeupException</code> e interrompe qualquer opera√ß√£o de bloqueio no consumidor.  Com esse m√©todo, o caminho para a baixa lat√™ncia √© simples: quando chega uma nova solicita√ß√£o de confirma√ß√£o, a colocamos na fila e, no consumidor nativo, chamamos de <code>wakeup</code> .  No ciclo de trabalho, capture <code>WakeupException</code> e confirme o que acumulou.  Para a transfer√™ncia de controle com a ajuda de exce√ß√µes, voc√™ deve entreg√°-lo imediatamente em suas m√£os, mas como nada mais ... <br><br>  Acontece que essa op√ß√£o est√° longe de ser perfeita, j√° que qualquer opera√ß√£o no consumidor nativo agora gera uma <code>WakeupException</code> , incluindo a pr√≥pria confirma√ß√£o.  O processamento dessa situa√ß√£o desorganizar√° o c√≥digo com um sinalizador, permitindo que a <code>wakeup</code> seja realizada. <br><br>  Cheguei √† conclus√£o de que seria bom modificar o m√©todo <code>KafkaConsumer::poll</code> para que ele possa ser interrompido normalmente, de acordo com um sinalizador adicional.  Como resultado, <a href="https://github.com/viirtus/queue-over-">Frankenstein</a> nasceu da reflex√£o, que copia exatamente o m√©todo de pesquisa original, adicionando uma sa√≠da do loop pela bandeira.  Esse sinalizador √© definido por um m√©todo interruptPoll separado, que, al√©m disso, chama a ativa√ß√£o no seletor de cliente para liberar o bloqueio de encadeamento nas opera√ß√µes de E / S. <br><br>  Tendo implementado o cliente dessa maneira, obtenho a velocidade da rea√ß√£o desde o momento em que uma solicita√ß√£o de confirma√ß√£o chega at√© que seja processada em at√© 100 microssegundos e uma excelente lat√™ncia para buscar mensagens de um broker, o que √© bom. <br></div></div><br>  Cada parti√ß√£o √© representada por uma fila local separada, na qual o adaptador grava mensagens do broker.  O trabalhador recebe mensagens dele e as envia para execu√ß√£o, ou seja, para envio via HTTP. <br><br>  O servi√ßo suporta o processamento de mensagens em lote para aumentar a taxa de transfer√™ncia.  Ao se inscrever, voc√™ pode especificar o <code>concurrencyFactor</code> cada t√≥pico (aplica-se a cada parti√ß√£o designada independentemente).  Por exemplo, <code>concurrencyFactor=1000</code> significa que 1000 mensagens na forma de solicita√ß√µes HTTP podem ser enviadas ao consumidor ao mesmo tempo.  Assim que todas as mensagens do pacote foram elaboradas de maneira inequ√≠voca pelo consumidor, o servi√ßo decide o pr√≥ximo commit do deslocamento da √∫ltima mensagem em Kafka.  Portanto, o segundo valor de <code>concurrencyFactor</code> √© o n√∫mero m√°ximo de mensagens processadas pelo consumidor no caso de uma falha Kafka ou Queue-sobre-Http. <br><br>  Para reduzir atrasos, a fila possui <code>loadFactor = concurrencyFactor * 2</code> , que permite ler duas vezes mais mensagens do broker que podem ser enviadas.  Como a confirma√ß√£o autom√°tica est√° desabilitada no cliente nativo, esse esquema n√£o viola as garantias de uma vez. <br>  Um alto valor de <code>concurrencyFactor</code> aumenta a taxa de transfer√™ncia da fila, reduzindo o n√∫mero de confirma√ß√µes que levam at√© 10 ms no pior caso.  Ao mesmo tempo, a carga no consumidor aumenta. <br><br>  A ordem de envio de mensagens dentro do pacote n√£o √© garantida, mas pode ser alcan√ßada configurando <code>concurrencyFactor=1</code> . <br><br><a name="commits"></a><h1>  Confirma </h1><br>  As confirma√ß√µes s√£o uma parte importante do servi√ßo.  Quando o pr√≥ximo pacote de dados estiver pronto, o deslocamento da √∫ltima mensagem do pacote ser√° imediatamente confirmado para Kafka e somente ap√≥s uma confirma√ß√£o bem-sucedida o pr√≥ximo pacote ficar√° dispon√≠vel para processamento.  Frequentemente, isso n√£o √© suficiente e √© necess√°ria uma confirma√ß√£o autom√°tica.  Para fazer isso, existe o par√¢metro <code>autoCommitPeriodMs</code> , que tem pouco em comum com o per√≠odo de confirma√ß√£o autom√°tica cl√°ssico para clientes nativos que confirmam a √∫ltima mensagem lida na parti√ß√£o.  Imagine <code>concurrencyFactor=10</code> .  O servi√ßo enviou todas as 10 mensagens e aguarda que cada uma delas esteja pronta.  O processamento da mensagem 3 √© conclu√≠do primeiro, depois a mensagem 1 e a mensagem 10. Nesse momento, √© hora de confirmar automaticamente.  √â importante n√£o violar a sem√¢ntica Pelo menos uma vez.  Portanto, voc√™ pode confirmar apenas a primeira mensagem, ou seja, o deslocamento 2, pois somente ela foi processada com √™xito naquele momento.  Al√©m disso, at√© a pr√≥xima confirma√ß√£o autom√°tica, as mensagens 2, 5, 6, 4 e 8. s√£o processadas Agora, voc√™ precisa confirmar apenas o deslocamento 7 e assim por diante.  A confirma√ß√£o autom√°tica quase n√£o afeta o rendimento. <br><br><a name="errors"></a><h1>  Tratamento de erros </h1><br>  No modo normal de opera√ß√£o, o servi√ßo envia uma mensagem ao supervisor uma vez.  Se, por algum motivo, tiver causado um erro 4xx ou 5xx, o servi√ßo reenviar√° a mensagem, aguardando o processamento bem-sucedido.  O tempo entre as tentativas pode ser configurado como um par√¢metro separado. <br><br>  Tamb√©m √© poss√≠vel definir o n√∫mero de tentativas ap√≥s as quais a mensagem ser√° marcada como processada, o que interromper√° as retransmiss√µes, independentemente do status da resposta.  Eu n√£o aconselho usar isso para dados confidenciais, situa√ß√µes de falha dos consumidores sempre devem ser ajustadas manualmente.  Mensagens fixas podem ser monitoradas por logs de servi√ßo e monitoramento do status da resposta do consumidor. <br><br><div class="spoiler">  <b class="spoiler_title">sobre furar</b> <div class="spoiler_text">  Geralmente, o servidor HTTP, atribuindo a 4xx ou 5xx o status da resposta, tamb√©m envia o cabe√ßalho <code>Connection: close</code> .  Uma conex√£o TCP que √© fechada dessa maneira permanece no status <code>TIME_WAITED</code> at√© que seja limpa pelo sistema operacional ap√≥s algum tempo.  O problema √© que essas conex√µes ocupam uma porta inteira que n√£o pode ser reutilizada at√© a libera√ß√£o.  Isso pode resultar na aus√™ncia de portas livres na m√°quina para estabelecer uma conex√£o TCP e o servi√ßo ser√° lan√ßado com exce√ß√µes nos logs para cada envio.  Na pr√°tica, no Windows 10, as portas terminam ap√≥s 10 a 20 mil enviando mensagens erradas dentro de 1-2 minutos.  No modo padr√£o, isso n√£o √© um problema. <br></div></div><br><a name="messages"></a><h1>  Mensagens </h1><br>  Cada mensagem extra√≠da do broker √© enviada ao consultor via HTTP para o recurso especificado durante a assinatura.  Por padr√£o, uma mensagem √© enviada por uma solicita√ß√£o POST no corpo.  Esse comportamento pode ser alterado especificando qualquer outro m√©todo.  Se o m√©todo n√£o suportar o envio de dados no corpo, voc√™ poder√° especificar o nome do par√¢metro de sequ√™ncia no qual a mensagem ser√° enviada.  Al√©m disso, ao se inscrever, voc√™ pode especificar cabe√ßalhos adicionais que ser√£o adicionados a cada mensagem, o que √© conveniente para a autoriza√ß√£o b√°sica usando tokens.  Os cabe√ßalhos s√£o adicionados a cada mensagem com o identificador do consumidor, t√≥pico e parti√ß√£o, de onde a mensagem foi lida, n√∫mero da mensagem, chave da parti√ß√£o, se aplic√°vel, bem como o nome do intermedi√°rio. <br><br><a name="performance"></a><h1>  Desempenho </h1><br>  Para avaliar o desempenho, usei um PC (Windows 10, OpenJDK-11 (G1 sem ajuste), i7-6700K, 16GB), que executa o servi√ßo e um laptop (Windows 10, i5-8250U, 8GB), no qual o produtor de mensagens, HTTP Consumidor de recursos e Kafka com configura√ß√µes padr√£o.  O PC est√° conectado ao roteador atrav√©s de uma conex√£o com fio de 1 Gb / s, e o laptop via 802.11ac.  O produtor grava a cada 110 ms a cada 100 ms por 110 bytes de mensagens nos t√≥picos designados para os quais os consumidores est√£o inscritos ( <code>concurrencyFactor=500</code> , a confirma√ß√£o autom√°tica est√° desativada) de diferentes grupos.  O suporte est√° longe de ser o ideal, mas voc√™ pode obter uma imagem. <br><br>  Um par√¢metro chave de medi√ß√£o √© o efeito do servi√ßo na lat√™ncia. <br><br>  Vamos: <br>  - t <sub>q</sub> - registro de data e hora do servi√ßo que recebe mensagens do cliente nativo <br>  - d <sub>t0</sub> √© o tempo entre t <sub>q</sub> e a hora em que a mensagem foi enviada da fila local para o conjunto de executivos <br>  - d <sub>t</sub> √© o tempo entre t <sub>q</sub> e a hora em que a solicita√ß√£o HTTP foi enviada.  Essa √© a influ√™ncia do servi√ßo na lat√™ncia da mensagem. <br><br>  Durante as medi√ß√µes, foram obtidos os seguintes resultados (C - consumidores, T - t√≥picos, M - mensagens): <br><br><img src="https://habrastorage.org/webt/p4/r7/pq/p4r7pqavkke1d3glzc7u8o6a5gu.png"><br><br>  No modo operacional padr√£o, o servi√ßo em si quase n√£o afeta a lat√™ncia e o consumo de mem√≥ria √© m√≠nimo.  Os valores m√°ximos de d <sub>t</sub> (cerca de 60 ms) n√£o s√£o indicados especificamente, pois dependem da opera√ß√£o do GC e n√£o do pr√≥prio servi√ßo.  O ajuste especial do GC ou a substitui√ß√£o do G1 pelo Shenandoah pode ajudar a suavizar a propaga√ß√£o dos valores m√°ximos. <br><br>  Tudo muda drasticamente quando o consumidor n√£o lida com o fluxo de mensagens da fila e o servi√ßo ativa o modo de otimiza√ß√£o.  Nesse modo, o consumo de mem√≥ria aumenta, pois o tempo de resposta √†s solicita√ß√µes aumenta significativamente, o que impede a limpeza oportuna dos recursos.  O efeito na lat√™ncia aqui permanece no n√≠vel dos resultados anteriores, e altos valores de dt s√£o causados ‚Äã‚Äãpelo pr√©-carregamento de mensagens na fila local. <br><br>  Infelizmente, n√£o √© poss√≠vel testar com uma carga mais alta, pois o laptop j√° est√° dobrado a 1300 RPS.  Se algu√©m puder ajudar na organiza√ß√£o de medi√ß√µes em altas cargas, terei prazer em fornecer uma montagem para testes. <br><br><a name="demo"></a><h1>  Demonstra√ß√£o </h1><br>  Agora vamos √† demonstra√ß√£o.  Para isso, precisamos: <br><br><ul><li>  Corretor Kafka, pronto para ir.  Tomarei a inst√¢ncia levantada em 192.168.99.100:9092 da Bitnami. </li><li>  Um recurso HTTP que receber√° mensagens.  Para maior clareza, tirei ganchos da Web do Slack. </li></ul><br>  Primeiro de tudo, voc√™ precisa aumentar o servi√ßo Fila-sobre-Http.  Para fazer isso, crie o seguinte conte√∫do em um diret√≥rio <code>application.yml</code> vazio: <br><br><pre> <code class="plaintext hljs">spring: profiles: default logging: level: com: viirrtus: queueOverHttp: DEBUG app: persistence: file: storageDirectory: "persist" brokers: - name: "Kafka" origin: "kafka" config: bootstrap.servers: "192.168.99.100:9092"</code> </pre><br>  Aqui, indicamos ao servi√ßo os par√¢metros de conex√£o de um broker espec√≠fico, bem como onde armazenar os assinantes para que eles n√£o se percam entre as partidas.  Em `app.brokers []. Config`, voc√™ pode especificar quaisquer par√¢metros de conex√£o suportados pelo cliente Kafka nativo; uma lista completa pode ser encontrada <a href="">aqui</a> . <br><br>  Como o arquivo de configura√ß√£o √© processado pelo Spring, voc√™ pode escrever muitas coisas interessantes l√°.  Inclusive, configure o log. <br><br>  Agora execute o pr√≥prio servi√ßo.  Usamos a maneira mais f√°cil - <code>docker-compose.yml</code> : <br><br><pre> <code class="plaintext hljs">version: "2" services: app: image: viirrtus/queue-over-http:0.1.3 restart: unless-stopped command: --debug ports: - "8080:8080" volumes: - ./application.yml:/application.yml - ./persist:/persist</code> </pre><br>  <i>Se essa op√ß√£o n√£o lhe agrada, voc√™ pode compilar o servi√ßo a partir da fonte.</i>  <i>Instru√ß√µes de montagem no projeto Leia-me, cujo link √© fornecido no final do artigo.</i> <br><br>  O pr√≥ximo passo √© registrar o primeiro assinante.  Para fazer isso, voc√™ precisa executar uma solicita√ß√£o HTTP para o servi√ßo com uma descri√ß√£o do Consumidor: <br><br><pre> <code class="plaintext hljs">POST localhost:8080/broker/subscription Content-Type: application/json { "id": "my-first-consumer", "group": { "id": "consumers" }, "broker": "Kafka", "topics": [ { "name": "slack.test", "config": { "concurrencyFactor": 10, "autoCommitPeriodMs": 100 } } ], "subscriptionMethod": { "type": "http", "delayOnErrorMs": 1000, "retryBeforeCommit": 10, "uri": "&lt;slack-wh-uri&gt;", "additionalHeaders": { "Content-Type": "application/json" } } }</code> </pre><br>  Se tudo der certo, a resposta ser√° quase o mesmo conte√∫do enviado. <br><br>  Vamos passar por cada par√¢metro: <br><br><ul><li>  <code>Consumer.id</code> - ID do nosso assinante </li><li>  <code>Consumer.group.id</code> - identificador de grupo </li><li>  <code>Consumer.broker</code> - indique em qual dos corretores de servi√ßo voc√™ precisa se inscrever </li><li>  <code>Consumer.topics[0].name</code> - o nome do t√≥pico do qual queremos receber mensagens </li><li> <code>Consumer.topics[0].config. concurrencyFactor</code>  <code>Consumer.topics[0].config. concurrencyFactor</code> - n√∫mero m√°ximo de mensagens enviadas simultaneamente </li><li> <code>Consumer.topics[0].config. autoCommitPeriodMs</code>  <code>Consumer.topics[0].config. autoCommitPeriodMs</code> - per√≠odo de confirma√ß√£o for√ßada para mensagens prontas </li><li>  <code>Consumer.subscriptionMethod.type</code> - tipo de assinatura.  Somente HTTP est√° dispon√≠vel no momento. </li><li>  <code>Consumer.subscriptionMethod.delayOnErrorMs</code> - tempo antes de reenviar uma mensagem que terminou com erro </li><li>  <code>Consumer.subscriptionMethod.retryBeforeCommit</code> - o n√∫mero de tentativas para reenviar a mensagem de erro.  Se 0 - a mensagem ir√° girar at√© o processamento bem-sucedido.  No nosso caso, a garantia da entrega total n√£o √© t√£o importante quanto a const√¢ncia do fluxo. </li><li>  <code>Consumer.subscriptionMethod.uri</code> - o recurso para o qual as mensagens ser√£o enviadas </li><li>  <code>Consumer.subscriptionMethod.additionalHeader</code> - cabe√ßalhos adicionais que ser√£o enviados com cada mensagem.  Observe que haver√° JSON no corpo de cada mensagem para que o Slack possa interpretar corretamente a solicita√ß√£o. </li></ul><br>  <i>Nesta solicita√ß√£o, o m√©todo HTTP √© omitido, pois o padr√£o, POST, Slack √© bastante bom.</i> <br><br>  A partir deste momento, o servi√ßo monitora as parti√ß√µes atribu√≠das do t√≥pico slack.test para novas mensagens. <br><br>  Para gravar mensagens no t√≥pico, usarei os utilit√°rios <code>/opt/bitnami/kafka/bin</code> Kafka localizados em <code>/opt/bitnami/kafka/bin</code> imagem Kafka iniciada (a localiza√ß√£o dos utilit√°rios em outras inst√¢ncias do Kafka pode ser diferente): <br><br><pre> <code class="plaintext hljs">kafka-console-producer.sh --broker-list localhost:9092 --topic slack.test &gt; {‚Äútext‚Äù: ‚ÄúHello!‚Äù}</code> </pre><br>  Ao mesmo tempo, o Slack notificar√° voc√™ sobre uma nova mensagem: <br><br><img src="https://habrastorage.org/webt/kl/eh/z7/klehz7ev6x1y2eaqpf_ylpnjic4.png"><br><br>  <i>Para cancelar a assinatura de um consumidor, basta fazer uma solicita√ß√£o POST para `intermediar / cancelar a inscri√ß√£o 'com o mesmo conte√∫do que estava durante a assinatura.</i> <br><br><a name="the-end"></a><h1>  Conclus√£o </h1><br>  No momento, apenas a funcionalidade b√°sica √© implementada.  Al√©m disso, est√° planejado melhorar o lote, tentar implementar a sem√¢ntica exata uma vez, adicionar a capacidade de enviar mensagens ao broker via HTTP e, o mais importante, adicionar suporte a outros Pub-Sub populares. <br><br>  O servi√ßo Fila por HTTP est√° atualmente em desenvolvimento ativo.  A vers√£o 0.1.3 √© est√°vel o suficiente para testar em suportes de desenvolvimento e palco.  O desempenho foi testado no Windows 10, Debian 9 e Ubuntu 18.04.  Voc√™ pode usar o produto por sua conta e risco.  Se voc√™ quiser ajudar no desenvolvimento ou dar algum feedback sobre o servi√ßo, seja bem-vindo ao projeto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://github.com/viirtus/queue-over-">Github</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt435346/">https://habr.com/ru/post/pt435346/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt435334/index.html">Rea√ß√£o a cartas frias</a></li>
<li><a href="../pt435336/index.html">Algo encontrado: Documentos com o Elasticsearch Moscow meetup na OZON</a></li>
<li><a href="../pt435338/index.html">Criamos um sistema de cronometragem eletr√¥nica de corridas</a></li>
<li><a href="../pt435340/index.html">Pesquisador publica exemplo de c√≥digo de trabalho do worm no Facebook</a></li>
<li><a href="../pt435344/index.html">Amazon apresentou Showroom, ou por que em breve compraremos todos os m√≥veis online</a></li>
<li><a href="../pt435348/index.html">Simple MCerver - um pequeno shell para o servidor Minecraft</a></li>
<li><a href="../pt435352/index.html">Confer√™ncia DEFCON 18. Espionagem pr√°tica usando um telefone celular. Parte 2</a></li>
<li><a href="../pt435354/index.html">Confer√™ncia DEFCON 18. Espionagem pr√°tica usando um telefone celular. Parte 1</a></li>
<li><a href="../pt435358/index.html">Antiguidades: Minidisk na era do iPod</a></li>
<li><a href="../pt435360/index.html">Snippets vs Clover - supere o teste em tempo real mais popular</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
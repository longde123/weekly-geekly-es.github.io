<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕕 🖕🏻 ✍🏾 Elon Musk s'oppose aux armes létales autonomes 🚥 👇🏿 🧘🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'entrepreneur Ilon Musk, qui dirige de nombreuses sociétés technologiques bien connues, est connu pour son point de vue sur les dangers de l'intellig...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Elon Musk s'oppose aux armes létales autonomes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/madrobots/blog/406273/"><img src="https://habrastorage.org/getpro/geektimes/post_images/e41/3ed/64f/e413ed64f4eb4be13252fda1bdbc7393.jpg" alt="image"><br><br>  L'entrepreneur Ilon Musk, qui dirige de nombreuses sociétés technologiques bien connues, est connu pour son point de vue sur les dangers de l'intelligence artificielle.  Bien sûr, il est célèbre non seulement à cause de cette opinion.  Cependant, il s'oppose à la création d'une forme forte d'IA depuis 2014.  Il a ensuite déclaré publiquement pour la première fois que l'intelligence artificielle pouvait être dangereuse.  Stephen Hawking et de nombreux autres scientifiques, futurologues et informaticiens sont d'accord avec lui.  On pense que toute l'humanité peut être victime de la singularité technologique. <br><br>  Le plus dangereux, selon Mask, est la tendance à créer une arme autonome "intelligente".  Selon l'entrepreneur, le risque d'apparition de «robots tueurs» est très élevé, il est donc nécessaire de traiter ce problème avec le plus grand soin.  "La troisième révolution des armements" est déjà proche, les experts en sont convaincus et les "robots tueurs" autonomes sont une sorte de boîte de Pandore.  Il reste très peu de temps pour résoudre le problème. <br><a name="habracut"></a><br>  Il y a environ une semaine, Musk, avec 115 éminents experts de divers domaines de la science et de la technologie, a signé <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">une lettre ouverte</a> , dont les auteurs demandent à l'ONU de s'attaquer à ce problème le plus rapidement possible. <br><br>  La lettre a été signée lors de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow noopener">Conférence conjointe internationale sur l'intelligence artificielle (IJCAI 2017)</a> , qui s'est tenue à Melbourne.  Soit dit en passant, parmi les signataires - et le fondateur de DeepMind Mustafa Suleiman, ainsi que Jerome Monce, le chef d'Aldebaran Robotics, qui a développé le robot Pepper.  Si les chefs d'entreprises à la tête du progrès technologique signent cette lettre, le problème mérite probablement d'être examiné. <br><br>  La lettre, en particulier, déclare que l'IA et la robotique se développent à un rythme si rapide que la possibilité de faire la guerre avec des armes autonomes, y compris des robots, devient plus probable.  De plus, c'est une question des années à venir, et non des décennies du tout, comme on le pensait auparavant.  Alors maintenant, il est nécessaire de réfléchir à la façon dont la technologie peut affecter le sort de l'humanité.  Et, tout d'abord, les dirigeants des États où la technologie se développe le plus activement possible devraient y penser. <br><br>  On peut ajouter à cela la menace que de telles technologies tombent entre les mains de terroristes et d'autocrates qui, sans aucun remords, enverront des outils mortels contre les gens ordinaires.  Même si cela peut être évité, il reste la menace des systèmes de piratage, et il est complètement non nul.  Les pirates ont prouvé à plusieurs reprises que presque tout peut être piraté, peu importe la façon dont ce «tout» est protégé. <br><br>  Déjà, il y a des développements d'armes mortelles fonctionnant en mode autonome ou semi-autonome.  C'est entre autres un tel appareil. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/cd4/234/3c7/cd42343c7db18851b990f953a73b9aaa.jpg"><br><br>  La photo est juste pour montrer comment les armes peuvent être équipées de robots dans les guerres futures.  Mais déjà des drones volent dans le ciel, capables de fonctionner en mode automatique.  Et les navires sont équipés de canons automatiques qui traquent indépendamment une menace possible. <br><br>  Les gouvernements de divers pays ne sont pas d'accord avec le point de vue des scientifiques et des technologues pour diverses raisons.  Le principal - pour les États, les armes autonomes - est bénéfique.  Elle peut accroître l'efficacité de la protection des frontières ou réduire le nombre de morts de soldats en cas de conflits locaux ou régionaux.  Ainsi, en 2015, le gouvernement britannique s'est opposé à l'interdiction des armes létales autonomes.  De plus, le développement d'armes de ce type est très actif ici. <br><br>  Eh bien, le point de vue des scientifiques opposés aux «robots tueurs» autonomes est bien illustré par la déclaration du fondateur d'Element AI, Joshua Benggio: «J'ai signé une lettre ouverte, car l'utilisation de l'IA dans les systèmes d'armes autonomes contredit ma compréhension de l'éthique, qui peut toutes conduire à une escalade très dangereuse, affecter toute la portée du développement de l'IA.  La situation doit être placée sous le contrôle de la communauté internationale, tout comme elle l'a été avec d'autres types d'armes (biologiques, chimiques, nucléaires). » <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/530/6e8/516/5306e851693ea33b96f7d6f8c6c49f0c.jpg"><br><br>  "La création d'armes autonomes mortelles nous permet d'étendre les guerres à des proportions sans précédent, même difficiles à imaginer", indique la lettre.  Et, probablement, les auteurs de la lettre ont vraiment raison. <br><br><hr><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/files/d29/4c3/07d/d294c307dde04335ac3f425e73b36a7a.gif"></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/files/7fa/417/fe3/7fa417fe3d464fa5aa186b1ab30da53a.gif"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr406273/">https://habr.com/ru/post/fr406273/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr406263/index.html">Cobalt 60 à la maison et au travail</a></li>
<li><a href="../fr406265/index.html">Travail sisyphéen</a></li>
<li><a href="../fr406267/index.html">Faux neuraux génératifs: comment l'apprentissage automatique modifie la perception du monde</a></li>
<li><a href="../fr406269/index.html">Volez dans la soupe primitive</a></li>
<li><a href="../fr406271/index.html">Movidius Myriad X - Centre de perception et d'analyse</a></li>
<li><a href="../fr406275/index.html">Les lettres perdues d'Alan Turing retrouvées dans le garde-manger de l'Université de Manchester</a></li>
<li><a href="../fr406279/index.html">Comment fonctionne le champ de Higgs: 3) comment la particule de Higgs apparaît</a></li>
<li><a href="../fr406281/index.html">Comprimés Black Magic Blue (nous fabriquons le programme Black Magic Probe à partir du module basé sur STM32F103)</a></li>
<li><a href="../fr406283/index.html">Comment la larme est arrangée et comment elle fonctionne, et ce qui se passe lorsque l'œil sèche</a></li>
<li><a href="../fr406285/index.html">Il est facile de choisir la surveillance d'un générateur diesel! .. Ou pas?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüîß üöú üõê Estilizando m√∫sica con redes neuronales üöπ üë®‚Äçüë©‚Äçüëß‚Äçüëß ü§∏üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Durante la √∫ltima d√©cada, las redes neuronales profundas (DNN) se han convertido en una excelente herramienta para una serie de tareas de inteligencia...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Estilizando m√∫sica con redes neuronales</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/409697/"><p><img src="https://habrastorage.org/webt/qu/r7/29/qur729mzadpog93xrhjwkj9c51i.jpeg"></p><br><p>  Durante la √∫ltima d√©cada, las redes neuronales profundas (DNN) se han convertido en una excelente herramienta para una serie de tareas de inteligencia artificial como la clasificaci√≥n de im√°genes, el reconocimiento de voz e incluso la participaci√≥n en juegos.  Cuando los desarrolladores intentaron mostrar qu√© caus√≥ el √©xito de DNN en el campo de la clasificaci√≥n de im√°genes, y crearon herramientas de visualizaci√≥n (por ejemplo, Deep Dream, Filters) que ayudan a comprender "qu√©" exactamente "estudia" el modelo DNN, surgi√≥ una nueva aplicaci√≥n interesante : extraer "estilo" de una imagen y aplicar a otro contenido diferente.  Esto se ha denominado la "transferencia de estilo de imagen". </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/webt/ma/w_/uy/maw_uyr88ft3g7oiwpx8yp6vfwi.jpeg"><br>  <em>Izquierda: imagen con contenido √∫til, en el centro: imagen con estilo, derecha: contenido + estilo (fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Google Research Blog</a> )</em> </p><br><p>  Esto no solo despert√≥ el inter√©s de muchos otros investigadores (por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ), sino que tambi√©n llev√≥ a la aparici√≥n de varias aplicaciones m√≥viles exitosas.  En los √∫ltimos a√±os, estos m√©todos de transferencia de estilo visual han mejorado mucho. </p><br><p><img src="https://habrastorage.org/webt/ij/oz/7-/ijoz7-xp5fibweiwdt3skobj_cy.jpeg"><br>  <em>Adobe estilo de envoltura (fuente: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Engadget</a> )</em> </p><br><p><img src="https://habrastorage.org/webt/rx/sx/gc/rxsxgcb9dxcf7gk5iaq6e2dkjbo.jpeg"><br>  <em>Ejemplo del sitio web de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Prisma</a></em> </p><br><p>  Una breve introducci√≥n a tales algoritmos: </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/WHmp26bh0tI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Sin embargo, a pesar de los avances en el trabajo con im√°genes, la aplicaci√≥n de estas t√©cnicas en otras √°reas, por ejemplo, para procesar m√∫sica, fue muy limitada (ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">4</a> ), y los resultados no son tan impresionantes como en el caso de las im√°genes.  Esto sugiere que es mucho m√°s dif√≠cil transferir estilo en la m√∫sica.  En este art√≠culo, examinaremos el problema con m√°s detalle y discutiremos algunos enfoques posibles. </p><br><h2 id="pochemu-tak-trudno-perenosit-stil-v-muzyke">  ¬øPor qu√© es tan dif√≠cil transferir estilo en la m√∫sica? </h2><br><p>  Primero respondamos la pregunta: <strong>¬øqu√© es la "transferencia de estilo" en la m√∫sica</strong> ?  La respuesta no es tan obvia.  En im√°genes, los conceptos de "contenido" y "estilo" son intuitivos.  "Contenido de imagen" describe los objetos representados, por ejemplo, perros, casas, caras, etc., y "estilo de imagen" se refiere a colores, iluminaci√≥n, pinceladas y textura. </p><br><p>  Sin embargo, la m√∫sica es <strong>sem√°nticamente abstracta y</strong> de naturaleza <strong>multidimensional</strong> .  "Contenido musical" puede significar diferentes cosas en diferentes contextos.  A menudo, los contenidos de la m√∫sica est√°n asociados con una melod√≠a y el estilo con un arreglo o armonizaci√≥n.  Sin embargo, el contenido puede ser la letra, y las diferentes melod√≠as utilizadas para cantar se pueden interpretar como estilos diferentes.  En la m√∫sica cl√°sica, el contenido puede considerarse la partitura (que incluye la armonizaci√≥n), mientras que el estilo es la interpretaci√≥n de las notas por parte del int√©rprete, quien aporta su propia expresi√≥n (variando y agregando algunos sonidos de s√≠ mismo).  Para comprender mejor la esencia de la transferencia de estilo en la m√∫sica, mira algunos de estos videos: </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/S75gYhODS0M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/buXqNqBFd6E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  En el segundo video, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se</a> utilizan varias <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">t√©cnicas de</a> aprendizaje autom√°tico. </p><br><p>  Entonces, la transferencia de estilo en la m√∫sica es, por definici√≥n, dif√≠cil de formalizar.  Hay otros factores clave que complican la tarea: </p><br><ol><li>  <strong>Las m√°quinas MAL entienden la m√∫sica</strong> (por ahora): el √©xito en la transferencia de estilo en las im√°genes se deriva del √©xito de DNN en tareas relacionadas con la comprensi√≥n de im√°genes, como el reconocimiento de objetos.  Debido a que los DNN pueden aprender propiedades que var√≠an entre los objetos, las t√©cnicas de propagaci√≥n hacia atr√°s se pueden usar para modificar la imagen de destino para que coincida con las propiedades del contenido.  Aunque hemos logrado un <a href="">progreso</a> significativo en la creaci√≥n de modelos basados ‚Äã‚Äãen DNN que son capaces de comprender tareas musicales (por ejemplo, transcribir melod√≠as, definir un g√©nero, etc.), todav√≠a estamos lejos de las alturas alcanzadas en el procesamiento de im√°genes.  Este es un serio obst√°culo para la transferencia de estilo en la m√∫sica.  Los modelos existentes simplemente no pueden aprender las propiedades "excelentes" que permiten clasificar la m√∫sica, lo que significa que la aplicaci√≥n directa de los algoritmos de transferencia de estilo utilizados al trabajar con im√°genes no da el mismo resultado. </li><li>  La m√∫sica es <strong>fugaz</strong> : son datos que representan series din√°micas, es decir, un fragmento musical cambia con el tiempo.  Esto complica el aprendizaje.  Aunque las redes neuronales recurrentes y la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LSTM</a> (memoria a corto plazo) le permiten aprender m√°s de los datos transitorios, todav√≠a tenemos que crear modelos confiables que puedan aprender a reproducir la estructura musical a largo plazo (nota: esta es un √°rea real de investigaci√≥n, y los cient√≠ficos del equipo de Google Magenta ha logrado cierto √©xito en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esto</a> ). </li><li>  La m√∫sica es <strong>discreta</strong> (al menos a nivel simb√≥lico): la m√∫sica simb√≥lica o grabada en papel es de naturaleza discreta.  En el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">temperamento uniforme</a> , el sistema de afinaci√≥n de instrumentos musicales m√°s popular en la actualidad, los tonos de sonido ocupan posiciones discretas en una escala de frecuencia continua.  Al mismo tiempo, la duraci√≥n de los tonos tambi√©n se encuentra en un espacio discreto (generalmente cuartos de tono, tonos completos, etc.).  Por lo tanto, es muy dif√≠cil adaptar los m√©todos de propagaci√≥n posterior de p√≠xeles (utilizados para trabajar con im√°genes) en el campo de la m√∫sica simb√≥lica. </li></ol><br><p><img src="https://habrastorage.org/webt/tb/cj/a0/tbcja0feucuwkgawqqlxqvfqtna.png"><br>  <em>La naturaleza discreta de las notas musicales en un temperamento uniforme.</em> </p><br><p>  Por lo tanto, las t√©cnicas utilizadas para transferir estilo en im√°genes no son directamente aplicables a la m√∫sica.  Para hacer esto, necesitan ser procesados ‚Äã‚Äãcon √©nfasis en conceptos e ideas musicales. </p><br><h2 id="dlya-chego-nuzhen-perenos-stilya-v-muzyke">  ¬øPara qu√© sirve la transferencia de estilo en la m√∫sica? </h2><br><p>  ¬øPor qu√© necesitas resolver este problema?  Al igual que con las im√°genes, los usos potenciales de la transferencia de estilo en la m√∫sica son bastante interesantes.  Por ejemplo, <strong>desarrollar una herramienta para ayudar a los compositores</strong> .  Por ejemplo, un instrumento autom√°tico capaz de transformar una melod√≠a usando arreglos de diferentes g√©neros ser√° extremadamente √∫til para los compositores que necesitan probar r√°pidamente diferentes ideas.  Los DJ tambi√©n estar√°n interesados ‚Äã‚Äãen tales instrumentos. </p><br><p>  Un resultado indirecto de tal investigaci√≥n ser√° una mejora significativa en los sistemas inform√°ticos musicales.  Como se explic√≥ anteriormente, para la transferencia del estilo al trabajo en la m√∫sica, los modelos que creamos deben aprender a <strong>"comprender" mejor los</strong> diferentes aspectos. </p><br><h2 id="uproschenie-zadachi-perenosa-stilya-v-muzyke">  Simplifica la tarea de transferir estilo en la m√∫sica </h2><br><p>  Comencemos con una tarea muy simple de analizar melod√≠as monof√≥nicas en diferentes g√©neros.  Las melod√≠as monof√≥nicas son secuencias de notas, cada una de las cuales est√° determinada por el tono y la duraci√≥n.  La progresi√≥n del tono en su mayor parte depende de la escala de la melod√≠a, y la progresi√≥n de la duraci√≥n depende del ritmo.  Primero, <strong>separamos</strong> claramente <strong>"</strong> contenido de tono" y <strong>"estilo r√≠tmico"</strong> como dos entidades con las que puede reformular la tarea de transferir el estilo.  Adem√°s, al trabajar con melod√≠as monof√≥nicas, ahora evitaremos las tareas asociadas con la disposici√≥n y el texto. </p><br><p>  En ausencia de modelos pre-entrenados que puedan distinguir con √©xito entre progresiones de tono y ritmos de melod√≠as monof√≥nicas, primero recurrimos a un enfoque muy simple para transferir el estilo.  En lugar de tratar de cambiar el contenido del tono aprendido en la melod√≠a objetivo con el estilo r√≠tmico aprendido en el ritmo objetivo, intentaremos ense√±ar individualmente los patrones de tonos y duraciones de diferentes g√©neros, y luego intentaremos combinarlos.  Esquema aproximado del enfoque: </p><br><p><img src="https://habrastorage.org/webt/ek/i8/3o/eki83obepvf1nd44pgzupr-czmu.png"><br>  <em>Esquema del m√©todo de transferencia de estilo interg√©nero.</em> </p><br><h2 id="obuchaem-otdelno-tonovym-i-ritmovym-progressiyam">  Ense√±amos progresiones de tono y ritmo por separado. </h2><br><p>  <strong><em>Presentaci√≥n de datos.</em></strong> </p><br><p>  Presentaremos melod√≠as monof√≥nicas como una secuencia de notas musicales, cada una de las cuales tiene un √≠ndice de tono y una secuencia.  Para que nuestra clave de presentaci√≥n sea independiente, utilizaremos la presentaci√≥n en funci√≥n de los intervalos: el tono de la siguiente nota se presentar√° como una desviaci√≥n (¬± semitono) del tono de la nota anterior.  Creemos dos diccionarios para tonos y duraciones en los que a cada estado discreto (para tono: +1, -1, +2, -2, y as√≠ sucesivamente; para duraciones: una nota negra, una nota completa, un cuarto con un punto, etc.) se le asigna un √≠ndice diccionario </p><br><p><img src="https://habrastorage.org/webt/v2/h6/z6/v2h6z6pbrq6ezu9br3jv_actjia.png"><br>  <em>Presentaci√≥n de datos.</em> </p><br><p>  <strong><em>Arquitectura modelo</em></strong> </p><br><p>  Utilizaremos la misma arquitectura que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">utilizaban Colombo y sus colegas</a> : ense√±aron simult√°neamente dos redes neuronales LSTM al mismo g√©nero musical: a) la red de tonos aprendi√≥ a predecir el siguiente tono en funci√≥n de la nota anterior y la duraci√≥n anterior, b) la red de duraci√≥n aprendi√≥ a predecir la pr√≥xima duraci√≥n en funci√≥n de la siguiente nota y duraci√≥n previa.  Adem√°s, antes de las redes LSTM, agregaremos capas de incrustaci√≥n para comparar √≠ndices de tonos de entrada y duraciones en espacios de inserci√≥n memorizados.  La arquitectura de la red neuronal se muestra en la imagen: </p><br><p><img src="https://habrastorage.org/webt/6q/fg/nk/6qfgnkiake_rls5yymzbvxdvzg0.png"></p><br><p>  <strong><em>Procedimiento de entrenamiento</em></strong> </p><br><p>  Para cada g√©nero, las redes responsables de tonos y duraciones se entrenan al mismo tiempo.  Utilizaremos dos conjuntos de datos: a) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conjunto de datos folkl√≥ricos de Norbeck</a> , que abarca alrededor de 2.000 melod√≠as populares irlandesas y suecas, b) un conjunto de datos de jazz (no disponible p√∫blicamente), que abarca alrededor de 500 melod√≠as de jazz. </p><br><p>  <strong><em>Fusionar modelos entrenados</em></strong> </p><br><p>  Durante las pruebas, la melod√≠a se genera primero utilizando la red de tonos y la red de duraci√≥n entrenada en el primer g√©nero (por ejemplo, folk).  Luego, la secuencia de tonos de la melod√≠a generada se usa en la entrada para una red de secuencias entrenadas en otro g√©nero (digamos, jazz), y el resultado es una nueva secuencia de duraciones.  Por lo tanto, una melod√≠a creada usando una combinaci√≥n de dos redes neuronales tiene una secuencia de tonos correspondiente al primer g√©nero (folk) y una secuencia de duraciones correspondiente al segundo g√©nero (jazz). </p><br><h2 id="predvaritelnye-rezultaty">  Resultados preliminares </h2><br><p>  Extractos breves de algunas de las melod√≠as resultantes: <br>  <a href="">Tonos populares y duraciones populares</a> </p><br><p><img src="https://habrastorage.org/webt/c9/ic/zv/c9iczvv4qkjjv6lve-sj5wnb3dk.png"><br>  <em>Extracto de notaci√≥n musical.</em> </p><br><p>  <a href="">Tonos populares y duraciones de jazz</a> </p><br><p><img src="https://habrastorage.org/webt/-p/oz/57/-poz57oqe5kpunzo3jqpikcjjju.png"><br>  <em>Extracto de notaci√≥n musical.</em> </p><br><p>  <a href="">Tonos de jazz y secuencias de jazz</a> </p><br><p><img src="https://habrastorage.org/webt/8s/ia/4x/8sia4xupwzfbnz2tyzof4xw14li.png"><br>  <em>Extracto de notaci√≥n musical</em> . </p><br><p>  <a href="">Tonos de jazz y secuencias folkl√≥ricas</a> </p><br><p><img src="https://habrastorage.org/webt/hf/mh/8p/hfmh8p9kyorpupmmvydj_psxb9u.png"><br>  <em>Extracto de notaci√≥n musical.</em> </p><br><h2 id="zaklyuchenie">  Conclusi√≥n </h2><br><p>  Aunque el algoritmo actual no es malo para comenzar, tiene una serie de inconvenientes cr√≠ticos: </p><br><ol><li>  <strong>Es imposible "transferir estilo" basado en una melod√≠a de destino espec√≠fica</strong> .  Los modelos aprenden patrones de tonos y duraciones en un g√©nero, lo que significa que todas las transformaciones est√°n determinadas por el g√©nero.  Ser√≠a ideal modificar una pieza musical al estilo de una canci√≥n o pieza objetivo espec√≠fica. </li><li>  <strong>No es posible controlar el grado de</strong> cambio <strong>de</strong> estilo.  Ser√≠a muy interesante obtener un "control" que rija este aspecto. </li><li>  Al fusionar g√©neros, <strong>es imposible preservar la estructura musical</strong> en una melod√≠a transformada.  Una estructura a largo plazo es importante para la evaluaci√≥n musical en general, y para que las melod√≠as generadas sean musicalmente est√©ticas, la estructura debe preservarse. </li></ol><br><p>  En futuros art√≠culos, veremos formas de sortear estas deficiencias. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es409697/">https://habr.com/ru/post/es409697/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es409687/index.html">Formato del viernes: Mujeres en la m√∫sica electr√≥nica - Wendy Carlos y Susan Chani</a></li>
<li><a href="../es409689/index.html">Los afortunados y perdedores en el mundo de Bitcoin: 7 historias provienen de 2017</a></li>
<li><a href="../es409691/index.html">Medios: Estados Unidos dejar√° de financiar la EEI en 2025</a></li>
<li><a href="../es409693/index.html">Ficci√≥n de temperatura y presi√≥n, 2/3</a></li>
<li><a href="../es409695/index.html">486 de la Rep√∫blica de China</a></li>
<li><a href="../es409699/index.html">Los experimentos cient√≠ficos m√°s esperados de la pr√≥xima d√©cada.</a></li>
<li><a href="../es409701/index.html">Las autoridades identificar√°n a los mineros en la Federaci√≥n de Rusia en las facturas de electricidad.</a></li>
<li><a href="../es409703/index.html">AI y veh√≠culos no tripulados: bienvenidos a hablar</a></li>
<li><a href="../es409705/index.html">Kingston Nucleum USB hub: convertir una computadora port√°til sin puerto en una m√°quina de trabajo completa</a></li>
<li><a href="../es409707/index.html">Teclado de bolsillo o dise√±o sin sentido pero lindo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëÉüèº ‚Ü™Ô∏è üê≤ Nginx-Protokollanalyse mit Amazon Athena und Cube.js üôáüèø üïô üßôüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In der Regel verwendet Nginx kommerzielle Produkte oder Open-Source-Alternativen wie Prometheus + Grafana, um die Leistung von Nginx zu √ºberwachen und...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nginx-Protokollanalyse mit Amazon Athena und Cube.js</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/447886/"><p>  In der Regel verwendet Nginx kommerzielle Produkte oder Open-Source-Alternativen wie Prometheus + Grafana, um die Leistung von Nginx zu √ºberwachen und zu analysieren.  Dies ist eine gute Option f√ºr die √úberwachung oder Echtzeitanalyse, jedoch nicht zu praktisch f√ºr die historische Analyse.  Bei jeder g√§ngigen Ressource w√§chst die Datenmenge aus Nginx-Protokollen schnell, und es ist logisch, etwas Spezialisierteres zu verwenden, um eine gro√üe Datenmenge zu analysieren. </p><br><p> In diesem Artikel werde ich Ihnen erkl√§ren, wie Sie mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Athena</a> Protokolle am Beispiel von Nginx analysieren und wie Sie aus diesen Daten mithilfe des Open-Source-Frameworks <a href="">cube.js</a> ein analytisches Dashboard kompilieren.  Hier ist die komplette L√∂sungsarchitektur: </p><br><p><img src="https://habrastorage.org/webt/km/xo/3i/kmxo3izommuyzgajw20t6-aolcg.png" alt="Architektur"></p><br><p>  TL: DR; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link zum fertigen Dashboard</a> . </p><a name="habracut"></a><br><p>  Wir verwenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fluentd</a> , um Informationen zu sammeln, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AWS Kinesis Data Firehose</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AWS Glue</a> f√ºr die Verarbeitung und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AWS S3</a> f√ºr die Speicherung.  Mit diesem Bundle k√∂nnen Sie nicht nur Nginx-Protokolle, sondern auch andere Ereignisse sowie Protokolle anderer Dienste speichern.  Sie k√∂nnen einige Teile durch √§hnliche Teile f√ºr Ihren Stapel ersetzen, z. B. k√∂nnen Sie Protokolle direkt von nginx unter Umgehung von fluentd in kinesis schreiben oder logstash verwenden, um dies zu tun. </p><br><h2 id="sobiraem-logi-nginx">  Sammeln von Nginx-Protokollen </h2><br><p>  Standardm√§√üig sehen Nginx-Protokolle ungef√§hr so ‚Äã‚Äãaus: </p><br><pre><code class="bash hljs">4/9/2019 12:58:17 PM1.1.1.1 - - [09/Apr/2019:09:58:17 +0000] <span class="hljs-string"><span class="hljs-string">"GET /sign-up HTTP/2.0"</span></span> 200 9168 <span class="hljs-string"><span class="hljs-string">"https://example.com/sign-in"</span></span> <span class="hljs-string"><span class="hljs-string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36"</span></span> <span class="hljs-string"><span class="hljs-string">"-"</span></span> 4/9/2019 12:58:17 PM1.1.1.1 - - [09/Apr/2019:09:58:17 +0000] <span class="hljs-string"><span class="hljs-string">"GET /sign-in HTTP/2.0"</span></span> 200 9168 <span class="hljs-string"><span class="hljs-string">"https://example.com/sign-up"</span></span> <span class="hljs-string"><span class="hljs-string">"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36"</span></span> <span class="hljs-string"><span class="hljs-string">"-"</span></span></code> </pre> <br><p>  Sie k√∂nnen analysiert werden, aber es ist viel einfacher, die Nginx-Konfiguration so zu korrigieren, dass Protokolle in JSON angezeigt werden: </p><br><pre> <code class="plaintext hljs">log_format json_combined escape=json '{ "created_at": "$msec", ' '"remote_addr": "$remote_addr", ' '"remote_user": "$remote_user", ' '"request": "$request", ' '"status": $status, ' '"bytes_sent": $bytes_sent, ' '"request_length": $request_length, ' '"request_time": $request_time, ' '"http_referrer": "$http_referer", ' '"http_x_forwarded_for": "$http_x_forwarded_for", ' '"http_user_agent": "$http_user_agent" }'; access_log /var/log/nginx/access.log json_combined;</code> </pre> <br><h3 id="s3-dlya-hraneniya">  S3 zur Aufbewahrung </h3><br><p>  Zum Speichern der Protokolle verwenden wir S3.  Auf diese Weise k√∂nnen Sie die Protokolle an einem Ort speichern und analysieren, da Athena direkt mit Daten in S3 arbeiten kann.  Sp√§ter in diesem Artikel werde ich Ihnen erkl√§ren, wie Sie die Protokolle richtig falten und verarbeiten, aber zuerst ben√∂tigen wir in S3 einen sauberen Eimer, in dem nichts anderes gespeichert wird.  Es lohnt sich, im Voraus zu √ºberlegen, in welcher Region Sie den Eimer erstellen, da Athena nicht in allen Regionen verf√ºgbar ist. </p><br><h3 id="sozdaem-shemu-v-konsoli-athena">  Erstellen Sie ein Diagramm in der Athena-Konsole </h3><br><p>  Erstellen Sie in Athena eine Tabelle f√ºr Protokolle.  Es wird sowohl zum Schreiben als auch zum Lesen ben√∂tigt, wenn Sie Kinesis Firehose verwenden m√∂chten.  √ñffnen Sie die Athena-Konsole und erstellen Sie eine Tabelle: </p><br><div class="spoiler">  <b class="spoiler_title">SQL-Tabellenerstellung</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">EXTERNAL</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> <span class="hljs-string"><span class="hljs-string">`kinesis_logs_nginx`</span></span>( <span class="hljs-string"><span class="hljs-string">`created_at`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>, <span class="hljs-string"><span class="hljs-string">`remote_addr`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-string"><span class="hljs-string">`remote_user`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-string"><span class="hljs-string">`request`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-string"><span class="hljs-string">`status`</span></span> <span class="hljs-built_in"><span class="hljs-built_in">int</span></span>, <span class="hljs-string"><span class="hljs-string">`bytes_sent`</span></span> <span class="hljs-built_in"><span class="hljs-built_in">int</span></span>, <span class="hljs-string"><span class="hljs-string">`request_length`</span></span> <span class="hljs-built_in"><span class="hljs-built_in">int</span></span>, <span class="hljs-string"><span class="hljs-string">`request_time`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>, <span class="hljs-string"><span class="hljs-string">`http_referrer`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-string"><span class="hljs-string">`http_x_forwarded_for`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-string"><span class="hljs-string">`http_user_agent`</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ROW</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FORMAT</span></span> SERDE <span class="hljs-string"><span class="hljs-string">'org.apache.hadoop.hive.ql.io.orc.OrcSerde'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">STORED</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> INPUTFORMAT <span class="hljs-string"><span class="hljs-string">'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'</span></span> OUTPUTFORMAT <span class="hljs-string"><span class="hljs-string">'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat'</span></span> LOCATION <span class="hljs-string"><span class="hljs-string">'s3://&lt;YOUR-S3-BUCKET&gt;'</span></span> TBLPROPERTIES (<span class="hljs-string"><span class="hljs-string">'has_encrypted_data'</span></span>=<span class="hljs-string"><span class="hljs-string">'false'</span></span>);</code> </pre> </div></div><br><h3 id="sozdaem-kinesis-firehose-stream">  Erstellen Sie einen Kinesis Firehose Stream </h3><br><p>  Kinesis Firehose schreibt die von Nginx empfangenen Daten im ausgew√§hlten Format in S3, unterteilt in Verzeichnisse im Format JJJJ / MM / TT / HH.  Dies ist n√ºtzlich beim Lesen von Daten.  Sie k√∂nnen nat√ºrlich von fluentd direkt in S3 schreiben, aber in diesem Fall m√ºssen Sie JSON schreiben, was aufgrund der gro√üen Dateigr√∂√üe ineffizient ist.  Bei Verwendung von PrestoDB oder Athena ist JSON au√üerdem das langsamste Datenformat.  √ñffnen Sie also die Kinesis Firehose-Konsole, klicken Sie auf "Lieferstrom erstellen" und w√§hlen Sie "Direktes PUT" im Feld "Lieferung" aus: </p><br><p><img src="https://habrastorage.org/webt/xe/vb/mc/xevbmcpntl3aqkgg50lh844gxe4.png" alt="Kinesis Firehose Console 1"></p><br><p>  W√§hlen Sie auf der n√§chsten Registerkarte "Konvertierung des Aufnahmeformats" - "Aktiviert" und w√§hlen Sie "Apache ORC" als Format f√ºr die Aufnahme.  Laut einigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Owen O'Malley</a> ist dies das optimale Format f√ºr PrestoDB und Athena.  Als Diagramm geben wir die Tabelle an, die wir oben erstellt haben.  Bitte beachten Sie, dass Sie in Kinesis einen beliebigen S3-Speicherort angeben k√∂nnen. In der Tabelle wird nur das Schema verwendet.  Wenn Sie jedoch einen anderen S3-Speicherort angeben, funktioniert das Lesen dieser Datens√§tze aus dieser Tabelle nicht. </p><br><p><img src="https://habrastorage.org/webt/vu/y1/ro/vuy1royrwm3pb3jle5nvclzskd0.png" alt="Kinesis Feuerl√∂schkonsole 2"></p><br><p>  Wir w√§hlen S3 als Speicher und den zuvor erstellten Bucket.  Aws Glue Crawler, √ºber den ich etwas sp√§ter sprechen werde, wei√ü nicht, wie man mit Pr√§fixen im S3-Bucket arbeitet, daher ist es wichtig, ihn leer zu lassen. </p><br><p><img src="https://habrastorage.org/webt/jq/0u/bs/jq0ubs7jvqmehbfqaaycrmxryso.png" alt="Kinesis Feuerl√∂schkonsole 3"></p><br><p>  Die restlichen Optionen k√∂nnen abh√§ngig von Ihrer Last ge√§ndert werden. Normalerweise verwende ich die Standardoptionen.  Beachten Sie, dass die S3-Komprimierung nicht verf√ºgbar ist, ORC jedoch standardm√§√üig die native Komprimierung verwendet. </p><br><h3 id="fluentd">  Flie√üend </h3><br><p>  Nachdem wir die Speicherung und den Empfang von Protokollen konfiguriert haben, m√ºssen Sie das Senden konfigurieren.  Wir werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fluentd verwenden,</a> weil ich Ruby liebe, aber Sie k√∂nnen Logstash verwenden oder Protokolle direkt an kinesis senden.  Sie k√∂nnen den Fluentd-Server auf verschiedene Arten starten. Ich werde √ºber Docker sprechen, da dies einfach und bequem ist. </p><br><p>  Zun√§chst ben√∂tigen wir die Konfigurationsdatei fluent.conf.  Erstellen Sie es und f√ºgen Sie die Quelle hinzu: </p><br><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">tippen Sie</a> vorw√§rts <br>  Port 24224 <br>  binden 0.0.0.0 </p><br><br><p>  Jetzt k√∂nnen Sie den Fluentd-Server starten.  Wenn Sie eine erweiterte Konfiguration ben√∂tigen, bietet der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Docker Hub</a> eine detaillierte Anleitung, einschlie√ülich der Zusammenstellung Ihres Images. </p><br><pre> <code class="bash hljs">$ docker run \ -d \ -p 24224:24224 \ -p 24224:24224/udp \ -v /data:/fluentd/<span class="hljs-built_in"><span class="hljs-built_in">log</span></span> \ -v &lt;PATH-TO-FLUENT-CONF&gt;:/fluentd/etc fluentd \ -c /fluentd/etc/fluent.conf fluent/fluentd:stable</code> </pre> <br><p>  Diese Konfiguration verwendet den Pfad <code>/fluentd/log</code> um Protokolle vor dem Senden zwischenzuspeichern.  Sie k√∂nnen darauf verzichten, aber wenn Sie neu starten, k√∂nnen Sie alles verlieren, was durch √ºberm√§√üige Arbeit zwischengespeichert wird.  Es kann auch jeder Port verwendet werden. 24224 ist der Standard-Fluentd-Port. </p><br><p>  Nachdem Fluentd ausgef√ºhrt wird, k√∂nnen wir dort Nginx-Protokolle senden.  Normalerweise f√ºhren wir Nginx in einem Docker-Container aus. In diesem Fall verf√ºgt Docker √ºber einen nativen Protokolltreiber f√ºr Fluentd: </p><br><pre> <code class="bash hljs">$ docker run \ --<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>-driver=fluentd \ --<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>-opt fluentd-address=&lt;FLUENTD-SERVER-ADDRESS&gt;\ --<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>-opt tag=\<span class="hljs-string"><span class="hljs-string">"{{.Name}}\" \ -v /some/content:/usr/share/nginx/html:ro \ -d \ nginx</span></span></code> </pre> <br><p>  Wenn Sie Nginx anders ausf√ºhren, k√∂nnen Sie die Protokolldateien verwenden. Fluentd verf√ºgt √ºber ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">File-Tail-Plugin</a> . </p><br><p>  F√ºgen Sie die oben konfigurierte Protokollanalyse zur Fluent-Konfiguration hinzu: </p><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">filter</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">YOUR-NGINX-TAG.</span></span></span><span class="hljs-tag">*&gt;</span></span> @type parser key_name log emit_invalid_record_to_error false <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">parse</span></span></span><span class="hljs-tag">&gt;</span></span> @type json <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">parse</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">filter</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre> <br><p>  Und Senden von Protokollen an Kinesis mithilfe des Kinesis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Firehose-Plugins</a> : </p><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">match</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">YOUR-NGINX-TAG.</span></span></span><span class="hljs-tag">*&gt;</span></span> @type kinesis_firehose region region delivery_stream_name <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">YOUR-KINESIS-STREAM-NAME</span></span></span><span class="hljs-tag">&gt;</span></span> aws_key_id <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">YOUR-AWS-KEY-ID</span></span></span><span class="hljs-tag">&gt;</span></span> aws_sec_key <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">YOUR_AWS-SEC_KEY</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">match</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre> <br><h2 id="athena">  Athena </h2><br><p>  Wenn Sie alles richtig konfiguriert haben, sollten Sie nach einer Weile (standardm√§√üig schreibt Kinesis die empfangenen Daten alle 10 Minuten) die Protokolldateien in S3 sehen.  Im Men√º "√úberwachung" von Kinesis Firehose k√∂nnen Sie sehen, wie viele Daten in S3 geschrieben wurden, sowie Fehler.  Vergessen Sie nicht, f√ºr die Kinesis-Rolle Schreibzugriff auf den S3-Bucket zu gew√§hren.  Wenn Kinesis etwas nicht analysieren konnte, f√ºgt er Fehler in denselben Bucket ein. </p><br><p>  Jetzt k√∂nnen Sie die Daten in Athena sehen.  Lassen Sie uns einige neue Abfragen finden, bei denen wir Fehler gemacht haben: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-string"><span class="hljs-string">"db_name"</span></span>.<span class="hljs-string"><span class="hljs-string">"table_name"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">status</span></span> &gt; <span class="hljs-number"><span class="hljs-number">499</span></span> <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> created_at <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">limit</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span>;</code> </pre> <br><h3 id="skanirovanie-vseh-zapisey-na-kazhdyy-zapros">  Scannen Sie alle Datens√§tze f√ºr jede Anforderung </h3><br><p>  Jetzt werden unsere Protokolle in S3 in ORC verarbeitet und gestapelt, komprimiert und zur Analyse bereit.  Kinesis Firehose hat sie sogar jede Stunde in Verzeichnisse gestellt.  W√§hrend die Tabelle nicht partitioniert ist, l√§dt Athena mit seltenen Ausnahmen Allzeitdaten f√ºr jede Abfrage.  Dies ist aus zwei Gr√ºnden ein gro√ües Problem: </p><br><ul><li>  Die Datenmenge w√§chst st√§ndig und verlangsamt die Abfragen. </li><li>  Athena wird basierend auf der Menge der gescannten Daten mit mindestens 10 MB f√ºr jede Anfrage in Rechnung gestellt. </li></ul><br><p>  Um dies zu beheben, verwenden wir AWS Glue Crawler, der die Daten in S3 scannt und die Partitionsinformationen im Glue Metastore aufzeichnet.  Auf diese Weise k√∂nnen wir Partitionen als Filter f√ºr Anforderungen in Athena verwenden und nur die in der Anforderung angegebenen Verzeichnisse scannen. </p><br><h3 id="nastraivaem-amazon-glue-crawler">  Passen Sie Amazon Glue Crawler an </h3><br><p>  Amazon Glue Crawler scannt alle Daten im S3-Bucket und erstellt Partitionstabellen.  Erstellen Sie einen Glue Crawler √ºber die AWS Glue-Konsole und f√ºgen Sie den Bucket hinzu, in dem Sie die Daten speichern.  Sie k√∂nnen einen Crawler f√ºr mehrere Buckets verwenden. In diesem Fall werden Tabellen in der angegebenen Datenbank mit Namen erstellt, die mit den Namen der Buckets √ºbereinstimmen.  Wenn Sie diese Daten st√§ndig verwenden m√∂chten, m√ºssen Sie den Startplan f√ºr den Crawler an Ihre Anforderungen anpassen.  Wir verwenden einen Crawler f√ºr alle Tabellen, der st√ºndlich ausgef√ºhrt wird. </p><br><h3 id="particirovannye-tablicy">  Partitionierte Tabellen </h3><br><p>  Nach dem ersten Start des Crawlers sollten die Tabellen f√ºr jeden gescannten Bucket in der in den Einstellungen angegebenen Datenbank angezeigt werden.  √ñffnen Sie die Athena-Konsole und suchen Sie die Tabelle mit den Nginx-Protokollen.  Versuchen wir etwas zu lesen: </p><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> <span class="hljs-string"><span class="hljs-string">"default"</span></span>.<span class="hljs-string"><span class="hljs-string">"part_demo_kinesis_bucket"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span>( partition_0 = <span class="hljs-string"><span class="hljs-string">'2019'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> partition_1 = <span class="hljs-string"><span class="hljs-string">'04'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> partition_2 = <span class="hljs-string"><span class="hljs-string">'08'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> partition_3 = <span class="hljs-string"><span class="hljs-string">'06'</span></span> );</code> </pre> <br><p>  Diese Abfrage w√§hlt alle Datens√§tze aus, die am 8. April 2019 von 6 bis 7 Uhr morgens eingegangen sind.  Aber wie viel effektiver ist es, als nur aus einer nicht partitionierten Tabelle zu lesen?  Lassen Sie uns dieselben Datens√§tze herausfinden und ausw√§hlen, indem wir sie nach Zeitstempel filtern: </p><br><p><img src="https://habrastorage.org/webt/mu/bg/me/mubgmef262bxyte5dsqsa1q_hag.png" alt="Anfrage ohne Partitionen"></p><br><p>  3,59 Sekunden und 244,34 Megabyte Daten im Datensatz, in dem nur eine Woche Protokolle vorhanden sind.  Versuchen wir den Filter nach Partitionen: </p><br><p><img src="https://habrastorage.org/webt/9-/n4/dc/9-n4dczjdvcrspm0zbypq-ul5cs.png" alt="Partitionsfilteranforderung"></p><br><p>  Ein bisschen schneller, aber vor allem - nur 1,23 Megabyte Daten!  Es w√§re viel billiger, wenn es nicht die Mindestpreise von 10 Megabyte pro Anfrage g√§be.  Aber es ist trotzdem viel besser und bei gro√üen Datenmengen wird der Unterschied viel beeindruckender sein. </p><br><h2 id="sobiraem-deshbord-s-pomoschyu-cubejs">  Erstellen Sie ein Dashboard mit Cube.js. </h2><br><p>  Um ein Dashboard zu erstellen, verwenden wir das Analyse-Framework Cube.js.  Es hat einige Funktionen, aber wir interessieren uns f√ºr zwei: die M√∂glichkeit, automatisch Filter f√ºr Partitionen zu verwenden und Daten vorab zu aggregieren.  Es verwendet ein in Javascript geschriebenes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datenschema</a> , um SQL zu generieren und eine Datenbankabfrage auszuf√ºhren.  Von uns muss lediglich angegeben werden, wie der Partitionsfilter im Datenschema verwendet wird. </p><br><p>  Lassen Sie uns eine neue Anwendung Cube.js erstellen.  Da wir bereits AWS-Stack verwenden, ist es logisch, Lambda f√ºr die Bereitstellung zu verwenden.  Sie k√∂nnen die Express-Vorlage zur Generierung verwenden, wenn Sie das Backend Cube.js in Heroku oder Docker hosten m√∂chten.  Die Dokumentation beschreibt andere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hosting-Methoden</a> . </p><br><pre> <code class="bash hljs">$ npm install -g cubejs-cli $ cubejs create nginx-log-analytics -t serverless -d athena</code> </pre> <br><p>  Umgebungsvariablen werden verwendet, um den Zugriff auf die Datenbank in cube.js zu konfigurieren.  Der Generator erstellt eine .env-Datei, in der Sie Ihre Schl√ºssel f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Athena</a> angeben k√∂nnen. </p><br><p>  Jetzt brauchen wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Datenschema,</a> in dem wir angeben, wie unsere Protokolle gespeichert werden.  Dort k√∂nnen Sie festlegen, wie Metriken f√ºr Dashboards gelesen werden sollen. </p><br><p>  Erstellen <code>Logs.js</code> im <code>schema</code> Verzeichnis die Datei <code>Logs.js</code>  Hier ist ein Beispiel f√ºr ein Datenmodell f√ºr Nginx: </p><br><div class="spoiler">  <b class="spoiler_title">Modellcode</b> <div class="spoiler_text"><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> partitionFilter = <span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">from</span></span></span></span><span class="hljs-function"><span class="hljs-params">, to</span></span></span><span class="hljs-function">) =&gt;</span></span> <span class="hljs-string"><span class="hljs-string">` date(from_iso8601_timestamp(</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${</span></span><span class="hljs-keyword"><span class="hljs-string"><span class="hljs-subst"><span class="hljs-keyword">from</span></span></span></span><span class="hljs-string"><span class="hljs-subst">}</span></span></span><span class="hljs-string">)) &lt;= date_parse(partition_0 || partition_1 || partition_2, '%Y%m%d') AND date(from_iso8601_timestamp(</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${to}</span></span></span><span class="hljs-string">)) &gt;= date_parse(partition_0 || partition_1 || partition_2, '%Y%m%d') `</span></span> cube(<span class="hljs-string"><span class="hljs-string">`Logs`</span></span>, { <span class="hljs-attr"><span class="hljs-attr">sql</span></span>: <span class="hljs-string"><span class="hljs-string">` select * from part_demo_kinesis_bucket WHERE </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${FILTER_PARAMS.Logs.createdAt.filter(partitionFilter)}</span></span></span><span class="hljs-string"> `</span></span>, <span class="hljs-attr"><span class="hljs-attr">measures</span></span>: { <span class="hljs-attr"><span class="hljs-attr">count</span></span>: { <span class="hljs-attr"><span class="hljs-attr">type</span></span>: <span class="hljs-string"><span class="hljs-string">`count`</span></span>, }, <span class="hljs-attr"><span class="hljs-attr">errorCount</span></span>: { <span class="hljs-attr"><span class="hljs-attr">type</span></span>: <span class="hljs-string"><span class="hljs-string">`count`</span></span>, <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: [ { <span class="hljs-attr"><span class="hljs-attr">sql</span></span>: <span class="hljs-string"><span class="hljs-string">`</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${CUBE.isError}</span></span></span><span class="hljs-string"> = 'Yes'`</span></span> } ] }, <span class="hljs-attr"><span class="hljs-attr">errorRate</span></span>: { <span class="hljs-attr"><span class="hljs-attr">type</span></span>: <span class="hljs-string"><span class="hljs-string">`number`</span></span>, <span class="hljs-attr"><span class="hljs-attr">sql</span></span>: <span class="hljs-string"><span class="hljs-string">`100.0 * </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${errorCount}</span></span></span><span class="hljs-string"> / </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${count}</span></span></span><span class="hljs-string">`</span></span>, <span class="hljs-attr"><span class="hljs-attr">format</span></span>: <span class="hljs-string"><span class="hljs-string">`percent`</span></span> } }, <span class="hljs-attr"><span class="hljs-attr">dimensions</span></span>: { <span class="hljs-attr"><span class="hljs-attr">status</span></span>: { <span class="hljs-attr"><span class="hljs-attr">sql</span></span>: <span class="hljs-string"><span class="hljs-string">`status`</span></span>, <span class="hljs-attr"><span class="hljs-attr">type</span></span>: <span class="hljs-string"><span class="hljs-string">`number`</span></span> }, <span class="hljs-attr"><span class="hljs-attr">isError</span></span>: { <span class="hljs-attr"><span class="hljs-attr">type</span></span>: <span class="hljs-string"><span class="hljs-string">`string`</span></span>, <span class="hljs-attr"><span class="hljs-attr">case</span></span>: { <span class="hljs-attr"><span class="hljs-attr">when</span></span>: [{ <span class="hljs-attr"><span class="hljs-attr">sql</span></span>: <span class="hljs-string"><span class="hljs-string">`</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${CUBE}</span></span></span><span class="hljs-string">.status &gt;= 400`</span></span>, <span class="hljs-attr"><span class="hljs-attr">label</span></span>: <span class="hljs-string"><span class="hljs-string">`Yes`</span></span> }], <span class="hljs-attr"><span class="hljs-attr">else</span></span>: { <span class="hljs-attr"><span class="hljs-attr">label</span></span>: <span class="hljs-string"><span class="hljs-string">`No`</span></span> } } }, <span class="hljs-attr"><span class="hljs-attr">createdAt</span></span>: { <span class="hljs-attr"><span class="hljs-attr">sql</span></span>: <span class="hljs-string"><span class="hljs-string">`from_unixtime(created_at)`</span></span>, <span class="hljs-attr"><span class="hljs-attr">type</span></span>: <span class="hljs-string"><span class="hljs-string">`time`</span></span> } } });</code> </pre> </div></div><br><p>  Hier verwenden wir die Variable <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FILTER_PARAMS</a> , um eine SQL-Abfrage mit einem Partitionsfilter zu generieren. </p><br><p>  Wir geben auch die Metriken und Parameter an, die im Dashboard angezeigt werden sollen, und geben Voraggregationen an.  Cube.js erstellt zus√§tzliche Tabellen mit voraggregierten Daten und aktualisiert die Daten automatisch, sobald sie verf√ºgbar sind.  Dies beschleunigt nicht nur Anfragen, sondern reduziert auch die Kosten f√ºr die Verwendung von Athena. </p><br><p>  F√ºgen Sie diese Informationen zur Datenschemadatei hinzu: </p><br><pre> <code class="javascript hljs">preAggregations: { <span class="hljs-attr"><span class="hljs-attr">main</span></span>: { <span class="hljs-attr"><span class="hljs-attr">type</span></span>: <span class="hljs-string"><span class="hljs-string">`rollup`</span></span>, <span class="hljs-attr"><span class="hljs-attr">measureReferences</span></span>: [count, errorCount], <span class="hljs-attr"><span class="hljs-attr">dimensionReferences</span></span>: [isError, status], <span class="hljs-attr"><span class="hljs-attr">timeDimensionReference</span></span>: createdAt, <span class="hljs-attr"><span class="hljs-attr">granularity</span></span>: <span class="hljs-string"><span class="hljs-string">`day`</span></span>, <span class="hljs-attr"><span class="hljs-attr">partitionGranularity</span></span>: <span class="hljs-string"><span class="hljs-string">`month`</span></span>, <span class="hljs-attr"><span class="hljs-attr">refreshKey</span></span>: { <span class="hljs-attr"><span class="hljs-attr">sql</span></span>: FILTER_PARAMS.Logs.createdAt.filter(<span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">from</span></span></span></span><span class="hljs-function"><span class="hljs-params">, to</span></span></span><span class="hljs-function">) =&gt;</span></span> <span class="hljs-string"><span class="hljs-string">`select CASE WHEN from_iso8601_timestamp(</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${to}</span></span></span><span class="hljs-string">) + interval '3' day &gt; now() THEN date_trunc('hour', now()) END`</span></span> ) } } }</code> </pre> <br><p>  In diesem Modell weisen wir darauf hin, dass die Daten f√ºr alle verwendeten Metriken vorab aggregiert und die monatliche Partitionierung verwendet werden muss.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Partitionieren von Voraggregationen</a> kann die Datenerfassung und -aktualisierung erheblich beschleunigen. </p><br><p>  Jetzt k√∂nnen wir ein Dashboard zusammenstellen! </p><br><p>  Das Cube.js-Backend bietet eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">REST-API</a> und eine Reihe von Client-Bibliotheken f√ºr g√§ngige Front-End-Frameworks.  Wir werden die React-Version des Clients verwenden, um das Dashboard zu erstellen.  Cube.js stellt nur Daten zur Verf√ºgung, daher ben√∂tigen wir eine Bibliothek f√ºr Visualisierungen. Ich mag <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Recharts</a> , aber Sie k√∂nnen jede verwenden. </p><br><p>  Der Cube.js-Server akzeptiert die Anforderung im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JSON-Format</a> , das die erforderlichen Metriken angibt.  Um beispielsweise zu berechnen, wie viele Fehler Nginx pro Tag gegeben hat, m√ºssen Sie die folgende Anfrage senden: </p><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"measures"</span></span>: [<span class="hljs-string"><span class="hljs-string">"Logs.errorCount"</span></span>], <span class="hljs-attr"><span class="hljs-attr">"timeDimensions"</span></span>: [ { <span class="hljs-attr"><span class="hljs-attr">"dimension"</span></span>: <span class="hljs-string"><span class="hljs-string">"Logs.createdAt"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"dateRange"</span></span>: [<span class="hljs-string"><span class="hljs-string">"2019-01-01"</span></span>, <span class="hljs-string"><span class="hljs-string">"2019-01-07"</span></span>], <span class="hljs-attr"><span class="hljs-attr">"granularity"</span></span>: <span class="hljs-string"><span class="hljs-string">"day"</span></span> } ] }</code> </pre> <br><p>  Installieren Sie den Cube.js-Client und die React-Komponentenbibliothek √ºber NPM: </p><br><pre> <code class="bash hljs">$ npm i --save @cubejs-client/core @cubejs-client/react</code> </pre> <br><p>  Wir importieren <code>cubejs</code> und QueryRenderer-Komponenten, um die Daten zu entladen und das Dashboard zu sammeln: </p><br><div class="spoiler">  <b class="spoiler_title">Dashboard-Code</b> <div class="spoiler_text"><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> React <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-string"><span class="hljs-string">'react'</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> { LineChart, Line, XAxis, YAxis } <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-string"><span class="hljs-string">'recharts'</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cubejs <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-string"><span class="hljs-string">'@cubejs-client/core'</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> { QueryRenderer } <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-string"><span class="hljs-string">'@cubejs-client/react'</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> cubejsApi = cubejs( <span class="hljs-string"><span class="hljs-string">'YOUR-CUBEJS-API-TOKEN'</span></span>, { <span class="hljs-attr"><span class="hljs-attr">apiUrl</span></span>: <span class="hljs-string"><span class="hljs-string">'http://localhost:4000/cubejs-api/v1'</span></span> }, ); <span class="hljs-keyword"><span class="hljs-keyword">export</span></span> <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> () =&gt; { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"> &lt;QueryRenderer query={{ measures: [</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'Logs.errorCount'</span></span></span></span><span class="hljs-function"><span class="hljs-params">], timeDimensions: [{ dimension: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'Logs.createdAt'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dateRange: [</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'2019-01-01'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'2019-01-07'</span></span></span></span><span class="hljs-function"><span class="hljs-params">], granularity: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'day'</span></span></span></span><span class="hljs-function"><span class="hljs-params"> }] }} cubejsApi={cubejsApi} render={({ resultSet }</span></span></span><span class="hljs-function">) =&gt;</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!resultSet) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">'Loading...'</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ( &lt;LineChart data={resultSet.rawData()}&gt; &lt;XAxis dataKey="Logs.createdAt"/&gt; &lt;YAxis/&gt; &lt;Line type="monotone" dataKey="Logs.errorCount" stroke="#8884d8"/&gt; &lt;/LineChart&gt; ); }} /&gt; ) }</code> </pre> </div></div><br><p>  Dashboard-Quellen sind in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CodeSandbox</a> verf√ºgbar. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de447886/">https://habr.com/ru/post/de447886/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de447876/index.html">Alles ist sehr schlecht oder eine neue Art der Verkehrs√ºberwachung</a></li>
<li><a href="../de447878/index.html">√úberpr√ºfen von rdesktop und xrdp mit PVS-Studio</a></li>
<li><a href="../de447880/index.html">Validierung von rdesktop und xrdp mit dem PVS-Studio Analyzer</a></li>
<li><a href="../de447882/index.html">Netzwerk-Tools oder wo soll der Pentester gestartet werden?</a></li>
<li><a href="../de447884/index.html">Wir finden heraus, wie 5G im Millimeterbereich auf der Stra√üe und in Innenr√§umen funktioniert</a></li>
<li><a href="../de447890/index.html">Gott sei Dank bin ich kein Manager</a></li>
<li><a href="../de447892/index.html">Zwei neue PHDays-Wettbewerbe: IDS-Bypass und Factory-Hacking</a></li>
<li><a href="../de447894/index.html">MODX Digest # 3 (25. M√§rz - 8. April 2019)</a></li>
<li><a href="../de447896/index.html">Bilder aus groben Skizzen: Genau so funktioniert das neuronale Netzwerk NVIDIA GauGAN</a></li>
<li><a href="../de447898/index.html">Gut gen√§hrte Philosophen oder wettbewerbsf√§hige .NET-Programmierung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
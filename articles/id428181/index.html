<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛌🏾 🐄 🈯️ Mesin Moral: tanpa ampun atau tidak berarti? 👩‍❤️‍👩 👩🏾‍🤝‍👨🏽 😡</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Saya memutuskan untuk menulis artikel ini setelah posting ini . 


 Izinkan saya mengingatkan Anda tentang hal yang singkat: dalam jurnal Nature, hasi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mesin Moral: tanpa ampun atau tidak berarti?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428181/"><p>  Saya memutuskan untuk menulis artikel ini setelah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">posting ini</a> . </p><br><img src="https://habrastorage.org/webt/-x/08/ps/-x08pskb0ti0iupeu2iuduj3uus.jpeg"><br><br>  Izinkan saya mengingatkan Anda tentang hal yang singkat: dalam jurnal Nature, hasil penelitian yang dilakukan dengan menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tes</a> ini dipublikasikan. <br><p>  Apa yang ingin saya tulis? </p><br><p>  Pertama, mengapa penelitian ini sama sekali tidak berguna untuk menyelesaikan masalah yang dinyatakan, dan dalam bentuk yang dilakukan. </p><br><p>  Kedua, bagaimana memprioritaskan studi semacam itu. </p><br><p>  Dan ketiga, cobalah untuk mensimulasikan berbagai skenario kecelakaan dalam kondisi yang ditentukan oleh tes. </p><a name="habracut"></a><br><p> Dalam posting itu, penulis tidak sia-sia memasukkan tautan ke tes dari awal.  Ini akan membantu menghindari komentar tidak berarti dari mereka yang tidak menangkap pesan awal penelitian. <br>  Tolong, <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ikuti tes</a></b> setidaknya beberapa kali untuk memahami subjek diskusi. </p><br><h3>  Apa yang mereka janjikan untuk tunjukkan pada kami di ruang kerja </h3><br><p>  Diskusi tentang pos pertama, epik untuk Habr, menunjukkan bahwa mayoritas orang tidak tahu bagaimana berpikir dalam kondisi yang diberikan, tetapi mulai berfantasi: "apakah beberapa orang mati dalam ujian?"  Lagi pula, Anda bisa berkeliling pejalan kaki dan blok / menyamping untuk menggosok / rem rem tangan / gigi?  Tetapi saya akan ... ".  Memahami ini adalah contoh sederhana untuk mengembangkan algoritma tindakan dan kebijakan untuk mengatur perilaku autopilot di jalan!  Dari sudut pandang pengembangan peraturan keselamatan, ekstrem dan penyederhanaan seperti itu dibenarkan.  Ini adalah tentang konsekuensi potensial yang harus disiapkan orang.  Tentara tidak pergi ke ladang ranjau bukan karena setiap sentimeter persegi ditambang di sana, tetapi karena kemungkinan kematian.  Biasanya tidak terlalu tinggi, tetapi tidak ada yang mau mengambil risiko.  Oleh karena itu, dalam pengujian, pilihan antara 100% kematian semua penumpang atau semua pejalan kaki cukup - ini adalah bagaimana kami menunjukkan risiko, mengingat bahwa mempertaruhkan nyawa di masyarakat kita tidak dapat diterima. </p><br><p>  Pesan dari penelitian ini adalah ini: Anda, orang-orang yang hidup sekarang, harus hidup di dunia masa depan, penuh dengan mobil dengan autopilot.  Dan penting bagi kami, para pengembang mobil, AI dan hal-hal lain, untuk mengetahui, tetapi bagaimana menurut Anda robot-robot harus berperilaku?  Nah, di sinilah Anda, ya, ya, itu Anda - katakan padaku apa yang harus dilakukan terhadap robomobile jika kepala dan kucing menumpang di dalamnya, dan akan menghancurkan para gelandangan dan anjing?  Etika apa yang harus dimiliki oleh robomobile jika mereka harus memilih? </p><br><p>  Dan setelah kami mengidentifikasi motif awal untuk penelitian ini, saya ingin membahas beberapa aspek. </p><br><h3>  Apa yang sebenarnya ditunjukkan oleh penelitian ini </h3><br><p>  Hal pertama yang jelas menarik perhatian Anda adalah bahwa desain penelitian sama sekali tidak ditujukan pada tujuan yang dinyatakan.  Tugas yang diatur dalam bentuk dilema tidak cocok untuk menciptakan "etika" perilaku robot-mobil.  Sebaliknya, tidak semua.  Berikut adalah dilema yang memenuhi tugas "mengembangkan aturan untuk perilaku mobil robot untuk mengurangi keparahan konsekuensi dari suatu kecelakaan": </p><br><ul><li>  “Penumpang / pejalan kaki” - pilih siapa yang akan diselamatkan; </li><li>  "Pelanggaran aturan lalu lintas" - pilih apakah akan mengorbankan pejalan kaki yang tidak sadar; </li><li>  “Jumlah korban potensial” - pilih apakah jumlah korban memiliki prioritas. </li></ul><br><p>  Dan kemudian muncul parameter, yang, ternyata, sangat penting untuk penghukuman dalam masyarakat kita yang beradab.  Orang-orang dengan jujur ​​dan polos ditanya: tingkat seksisme Anda, Lukisme, Ageisme?  Apakah Anda mendiskriminasi gemuk atau tidak berbintang?  Lagi pula, ratusan ribu orang dengan jujur ​​menjawab ... </p><br><p>  Bravo! </p><br><p>  Tepat di tradisi terbaik film dan serial hiburan, ketika dunia para karakter utama sebenarnya adalah kotak pasir besar di belakang pagar tinggi, dan itu adalah perilaku mereka yang merupakan eksperimen!  Di bawah saus penelitian yang sangat penting di bidang robotika dan AI, sosiolog, psikolog, dan kultolog menerima sampel yang sangat kuat pada <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">masalah troli</a></b> yang tidak pernah diimpikan oleh siapa pun sebelumnya!  Ya, kecuali bahwa warna kulit tidak ditambahkan ke dalam survei, tetapi kemudian nada rasis dari penelitian ini akan dijahit dengan warna putih ... oh. </p><br><p>  Serius, bagian fenotipik gender dari penelitian ini terputus oleh argumen kategoris.  Argumen pertama adalah humanisme, sebagai orang yang beradab, kita harus mengutamakan nilai kehidupan manusia daripada perbedaan individu.  Artinya, rumusan pertanyaan itu sangat keterlaluan, sebagai diskriminatif.  Argumen kedua - banyak kecelakaan terjadi, dan dalam batas distribusi korban berdasarkan penampilan, pendidikan, jenis kelamin, usia akan cenderung proporsi mereka di masyarakat, sehingga setidaknya aneh untuk mengatur ini juga.  Argumen ketiga - tampaknya tidak dianjurkan untuk membuat kecerdasan buatan yang membedakan jas dari Brioni dari pullover dari Bershka untuk lebih jauh membandingkan apakah seseorang berstatus dan apakah layak untuk menghancurkannya.  Selain itu, saya tidak akan mempercayai AI untuk menilai - pejalan kaki atau ilmuwan yang tidak memiliki rumah?  (Halo untuk gaya rambut ilmuwan Perelman atau Gelfand yang dihormati :)) </p><br><p>  Selain parameter yang tidak perlu ini, kami dengan mudah membuang dua yang tersisa: spesifisitas spesies dan non-gangguan.  Ya, kami akan menghancurkan hewan kecil untuk menyelamatkan orang, siapa sangka.  Dan untuk parameter “intervensi / non-gangguan” dengan bermanuver, bagian penting dari masalah troli ini bukan hanya penghalang bagi mobil, karena mesin tidak bertindak sesuai dengan etika, tetapi menurut algoritma yang ditetapkan di dalamnya.  Dan karena kita menetapkan tugas "bagaimana seharusnya mobil bertindak dalam kecelakaan dengan tabrakan dengan orang-orang", maka dalam kata-kata kita menganggap bahwa itu harus bertindak entah bagaimana.  Saat ini, transportasi kereta api berhasil mengatasi tabrakan langsung tanpa konsekuensi apa pun, dan kami sedang mengembangkan kebijakan meminimalkan korban kecelakaan di jalan. <br>  Ini berarti bahwa kami telah memisahkan butir-butir penelitian rasional dari eksperimen sosiopsikologis untuk mempelajari tingkat intoleransi dalam masyarakat dunia.  Kami bekerja lebih jauh dengan tiga dilema yang disebutkan pertama.  Dan ada sesuatu untuk dibongkar.  Setelah pemeriksaan lebih dekat, mereka ternyata tidak lengkap ... </p><br><h3>  Tiga dilema mobil robot </h3><br><p>  <b>Apakah pejalan kaki melanggar peraturan lalu lintas?</b>  Di sini, mayoritas secara eksplisit mengekspresikan Darwinisme sosial atau tanggapan yang disesalkan secara diam-diam yang disesalkan - alih-alih, mereka harus mengorbankan mereka yang melanggar aturan demi kepentingan orang yang tidak bersalah.  Orang yang sadar tidak naik kereta api, mengetahui bahwa kereta tidak akan berhenti - biarkan mereka tahu bahwa robomobile tidak akan berhenti juga.  Semuanya logis, meski sinis.  Tetapi dalam dilema yang licik ini, keberpihakan satu sisi, ketidaklengkapan, tersembunyi.  Pejalan kaki yang melanggar peraturan lalu lintas hanyalah satu dari banyak situasi.  Tetapi jika mobil robot rusak ??  Situasi ini belum dipertimbangkan, tetapi (kamera mobil melewatkan tanda atau lampu lalu lintas), secara teori, jauh lebih mungkin daripada kegagalan rem mendadak.  Namun, saya kembali bermain fantasi dan khususnya.  Lebih penting untuk hanya menunjukkan dalam tes timbal balik yang setara dengan situasi.  Yaitu, bayangkan ini: jika pejalan kaki melanggar peraturan lalu lintas, mereka mati, dan ini "logis" dan "benar," dan jika robomobile melanggar, haruskah ia bunuh diri karena kesalahan ini?  Jangan lupa bahwa pada saat yang sama, pemimpin, gelandangan dan kucing yang duduk di dalam mati!  Ini adalah koreksi penting, tetapi dalam pengujian, aspek ini tidak. </p><br><p>  Selanjutnya  <b>Jumlah calon korban.</b>  Di sini juga tidak begitu sederhana.  Buang stereotip gender dan hormati hari tua, jijik bagi yang gemuk dan tunawisma.  Kami berasumsi bahwa dalam suatu kecelakaan mereka mati sebanding dengan frekuensi yang mereka temukan di alam.  Dan kami akan memutuskan: tiga meninggal lebih baik dari lima.  Apakah itu masuk akal?  Oh baiklah  Mari kita <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">reseskan semua absurditas neraka ini</a> , tetapi kita memiliki simulasi abstrak.  Mana yang lebih baik - membunuh 50 atau 51 orang?  1051 atau 1052?  Jadi ini tidak begitu penting?  Lalu apa yang lebih baik - membunuh 1 pejalan kaki atau 50 orang di dalam bus?  Dan sekarang itu menjadi penting?  Dan kemana garis itu pergi?  Apakah setiap orang tambahan berharga?  Tetapi apakah penting jika ribuan orang meninggal dalam kecelakaan di jalan dalam jangka panjang?  Seperti dalam kasus penampilan, pada kenyataannya, perkiraan yang memadai menggunakan AI dari jumlah korban potensial akan sangat sulit.  Satu-satunya hal yang masuk akal adalah membuat kondisi tanpa intervensi (non-manuver) jika jumlah korbannya sama. </p><br><p>  Aspek ketiga menyebabkan banyak kontroversi dalam komentar pada artikel pertama tentang Habré.  Dan menilai dari hasil penelitian, itu sepenuhnya ambigu bagi masyarakat, dan di sinilah letak masalah utama yang perlu dipecahkan.  Ini tentang <b>siapa yang harus mengambil risiko - pejalan kaki atau penumpang?</b> </p><br><p>  Beberapa orang mengatakan bahwa pejalan kaki tidak dapat disalahkan untuk apa pun, yang berarti bahwa mereka harus diselamatkan sejak awal.  Secara umum, sekarang menjadi mode di kalangan kaum urbanis untuk merawat pejalan kaki, membuat seluruh jalan pejalan kaki, membuat persimpangan dengan lampu lalu lintas setiap 50 meter, mengurangi kecepatan lalu lintas di tengah, memberikan prioritas pejalan kaki.  Di sini, juga, penting untuk mengamankan mereka, dan sebuah mesin robot yang terbang tanpa rem pada kerumunan harus menghancurkan diri sendiri dengan tujuan menyelamatkan para peserta yang paling rentan dalam pergerakan.  Apa, dari sudut pandang saya, mereka benar adalah bahwa pejalan kaki tidak berlangganan dengan kondisi perilaku mobil robot orang lain.  Mereka umumnya menentang pengenalan mereka.  Pada saat yang sama, tidak mungkin untuk membayangkan penumpang mesin seperti itu yang tidak setuju dengan ketentuan untuk penggunaannya.  Karena itu, situasinya adalah konflik kepentingan.  Lebih nyaman bagi saya untuk membunuh Anda dan saya akan membunuh Anda, seperti yang dikatakan satu orang kepada orang lain. </p><br><p>  Yang kedua mengatakan bahwa setiap orang yang membeli dan umumnya masuk ke mobil robot harus memiliki jaminan bahwa dia akan menyelamatkannya jika terjadi kecelakaan, dan tidak membunuh seorang dokter, anak atau dua kucing untuk menyelamatkan jalan persimpangan.  Di satu sisi, itu tampak logis dan dibenarkan, di sisi lain - penumpang dalam kasus ini sengaja menempatkan hidupnya di atas yang lain.  Ketika membeli mobil dengan autopilot, setiap pemilik dapat mengambil <s>senjata yang sempurna, peluru perak, roket yang tidak terarah, sebuah</s> mesin yang akan secara hukum membunuh orang lain di jalannya. </p><br><p>  Kedua belah pihak dengan busa di mulut menepi "hukum robot pertama", diambil dari fiksi ilmiah.  Kedengarannya indah secara demagogis, tetapi tidak ada yang mencoba memahaminya atau menantangnya dalam kaitannya dengan masalah.  Tapi itu tidak berlaku untuk perumusan masalah ini, karena ada substitusi konsep: heuristik / AI mesin tidak memilih antara nilai-nilai kehidupan manusia, tetapi bertindak secara ketat sesuai dengan algo-ritme yang dibuat berdasarkan prioritas subyektif yang diciptakan oleh orang.  Dan di sini tidak masalah konstruksi sosial seperti apa yang diprioritaskan ketika memilih “bunuh / luang”: massa tubuh yang kami tolak sebelumnya, usia dan status, atau keegoisan sosial Darwinis sosial dari pemilik mobil. </p><br><p>  Pendekatan kedua, sebagai serangan sepihak pada kehidupan pejalan kaki, mengubah penelitian dari masalah troli menjadi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><b>dilema klasik tahanan</b></a> .  Jika para pihak berkompromi, pengembangan secara umum dimungkinkan (pengenalan robot mobil) dengan sedikit kemunduran bagi sebagian orang (minimalisasi jumlah kematian yang tidak terhindarkan dari robot mobil) - yang merupakan keinginan optimal Pareto.  Namun, selalu ada egois yang hanya mengandalkan kepentingannya.  "Dia akan mendapatkan 20 tahun, tapi aku akan dibebaskan."  "Dia akan mati menyeberang jalan, walaupun remnya menolak mobilku."  Mungkin pendekatan ini dibenarkan ketika peristiwa tunggal dalam kehidupan, dan ada dua peserta dalam permainan.  Ketika ada puluhan atau ratusan ribu peserta, dan perjalanan setiap hari, permainan satu tujuan seperti itu akan berubah menjadi diskriminasi terhadap pejalan kaki. </p><br><p>  Secara pribadi, saya percaya bahwa dalam kerangka masalah yang dirumuskan, dilema penumpang / pejalan kaki mengarah ke jalan buntu.  Sebuah mesin yang berpotensi membunuh mereka yang masuk ke dalamnya adalah absurd dari sudut pandang akal sehat dan secara alami tidak akan menemukan pembeli di pasar.  Sebuah mobil yang dengan sengaja membunuh pejalan kaki adalah hal yang mustahil dalam masyarakat yang beradab sebagai elemen diskriminasi positif dan ancaman terhadap kehidupan manusia. </p><br><p>  Kami melangkah lebih jauh.  Artikel tersebut tidak benar-benar membahas dan tidak berarti kebijakan untuk meminimalkan konsekuensi tragis dari kecelakaan yang melibatkan robomobiles.  Totalnya dibagi menjadi "daerah", yang berbeda secara signifikan dalam prioritas dan agak ambigu terbentuk (ada penjelasan tentang "fitur agama dan pengaruh kolonial", tetapi ... secara umum, salam ke Irak dengan Afghanistan di "Barat" dan Prancis dengan Republik Ceko di " Sektor selatan ”.  Jadi pertanyaannya berkisar pada bahasa: akankah Anda membuat robot mobil dengan "etika" yang berbeda untuk masing-masing negara? </p><br><img src="https://habrastorage.org/webt/oy/wk/2i/oywk2inqjeerijr5wrja_v57new.jpeg"><br><p>  Para penulis artikel dalam diskusi menunjuk tiga “blok dasar mendasar” yang diidentifikasi oleh mereka: menyelamatkan orang (bukan hewan), menyelamatkan lebih banyak nyawa, menyelamatkan yang lebih muda.  Tetapi diagram menunjukkan dengan jelas bahwa orang-orang di sektor Timur memiliki populasi dan pemuda yang sedikit lebih sedikit daripada yang tidak peduli.  Ternyata kebijakan prioritas yang dipilih akan bertentangan dengan pendapat mayoritas?  Lalu, mengapa orang ditanyai sama sekali? </p><br><h3>  Mungkin hanya menghitung? </h3><br><p>  Tetapi mari kita beralih ke bagian yang menghibur dari posting ini. </p><br><p>  Alih-alih meminta orang dengan implikasi sosiokultural yang berbeda untuk nasihat tentang robotika, dan mungkin 99% dari mereka dengan pendidikan non-inti, kami beralih ke alat yang tidak memihak.  Mari kita ambil dilema yang dipilih di awal artikel.  Dalam kondisi pengujian kami akan membuat simulasi komputer paling sederhana.  Dan kami akan mengevaluasi jumlah pengguna jalan mati. </p><br><p>  Dan ingat: tugas kita sebagai politisi di bidang keamanan transportasi adalah mengurangi jumlah total korban.  Kami akan bekerja dalam kerangka kerja dan konvensi uji Mesin Moral asli, yang berfokus pada risiko terhadap kehidupan peserta kecelakaan jalan, daripada penilaian realistis yang kompleks dari tabrakan mobil dengan rintangan atau orang.  Kami tidak memiliki EuroNCAP, kami akan memiliki Python. </p><br><p>  Pertama-tama, kami akan menulis kode yang memenuhi dilema "menyelamatkan mereka yang mati lebih banyak."  Sebagai bagian dari uji Moral Machine, kami membuat secara acak dari 1 hingga 5 penumpang dan pejalan kaki, mengatur kondisi jika pejalan kaki&gt; penumpang, segera membunuh mobil di atas balok beton.  Kami membawa, misalnya, 10.000 kecelakaan semacam itu. </p><br><div class="spoiler">  <b class="spoiler_title">Saya tidak mendengarkan kode klaim, saya menulis sesuatu dengan Python untuk pertama kalinya dalam hidup saya</b> <div class="spoiler_text"><pre><code class="plaintext">npedtotal = 0
npasstotal = 0
ndeadped = 0
ndeadpass = 0
#   0    0  

n=0
while n &lt; 10000:
#10000 

    nped = random.randint(1, 5)
    npass = random.randint(1, 5)
#      1  5

    npedtotal += nped
    npasstotal += npass
#     

    if nped &gt; npass:

        ndeadpass += npass

    else:
        ndeadped += nped

#     ,
#       .
#          .

    n += 1

print ("  ", npedtotal)
print (" ", npasstotal)
print (" ", ndeadped, "(",100*ndeadped/npedtotal, "%",")")
print (" ", ndeadpass, "(",100*ndeadpass/npasstotal,"%"")")
print ("  ", ndeadped + ndeadpass, "(",100*(ndeadped + ndeadpass)/(npasstotal+npedtotal), "%", ")")</code></pre></div></div><br>
<p>  … </p><br>
<blockquote>   29960<br>
  29924<br>
  13903 ( 46.4052069426 % )<br>
  8030 ( 26.8346477744 %)    21933 ( 36.6258098991 % )</blockquote><p>,   !   ,   !<br>
    .             .  ,      .     –    ,   « »         4  5,        ==  . ,   20   20 ,   ,   , 5  –    ,  5  –   .     :      ,  ,   .  &gt;  &gt;=        :</p><br>
<blockquote>   29981<br>
  29865<br>
  7859 ( 26.2132684033 % )<br>
  14069 ( 47.1086556169 %)<br>
   21928 ( 36.6407111586 % )</blockquote>   ,          occupants,  -   ,   .    ,    .  30000 , 100% — .<br>
<br>
     ,       ,   .    –    , ,    50%     ,     30000.<br>
<br>
    –       .  ,    ,        ,       !    ,     :  ,        , ,    ,      ,    . ,    :      .<br>
<br>
<div class="spoiler"><b class="spoiler_title">       ,   -</b><div class="spoiler_text">```python<br>
import random<br>
<br>
npedtotal = 0<br>
npasstotal = 0<br>
ndeadped = 0<br>
ndeadpass = 0<br>
#   0    0  <br>
<br>
n=0<br>
while n &lt; 10000:<br>
#10000 <br>
<br>
nped = random.randint(1, 5)<br>
 npass = random.randint(1, 5)<br>
 trafficlight = random.randint(0, 1)<br>
#      1  5<br>
#      <br>
<br>
npedtotal += nped<br>
 npasstotal += npass<br>
#     <br>
 if trafficlight == 0:<br>
<br>
ndeadped += nped<br>
<br>
else:<br>
<br>
if nped &gt; npass:<br>
<br>
ndeadpass += npass<br>
<br>
else:<br>
 ndeadped += nped<br>
<br>
#     ,<br>
#       .<br>
#          .<br>
<br>
n += 1<br>
<br>
print («  », npedtotal)<br>
print (« », npasstotal)<br>
print (« », ndeadped, "(",100*ndeadped/npedtotal, "%",")")<br>
print (« », ndeadpass, "(",100*ndeadpass/npasstotal,"%"")")<br>
print («  », ndeadped + ndeadpass, "(",100*(ndeadped + ndeadpass)/(npasstotal+npedtotal), "%", ")")<br>
```</div></div><br>
<br>
<blockquote>  "&gt;"<br>
   29978<br>
  29899<br>
  21869 ( 72.9501634532 % )<br>
  4042 ( 13.5188467842 %)<br>
   25911 ( 43.2737111078 % )<br>
<br>
 "&gt;="<br>
   30152<br>
  30138<br>
  19297 ( 63.9990713717 % )<br>
  6780 ( 22.4965160263 %)<br>
   26077 ( 43.2526123735 % )<br>
</blockquote> ,      ,           .          (       ).<br>
<br>
           ,             .                 –         .<br>
<br>
           .        ,    ,           .         Moral Machine,      ,     ,     .       -   ,       .<br>
<br>
,    ,       ,                .     –   ,   ,   .        .       –      ,   ,      ,           .      ,    –        .<br>
<br>
   ,   -              ,      .          ,   ,             ,    .  –   ,       ,      .<br>
<br>
 .      .            ,      .    .</div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id428181/">https://habr.com/ru/post/id428181/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id428169/index.html">DJI mengumumkan Mavic 2 Enterprise - alat yang ampuh untuk para profesional</a></li>
<li><a href="../id428173/index.html">Prettier, ESLint, Husky, Lint-Staged, dan EditorConfig: Alat untuk Menulis Kode Rapi</a></li>
<li><a href="../id428175/index.html">Implementasi Awalan Pohon C yang Cunning</a></li>
<li><a href="../id428177/index.html">Jadi apa yang salah dengan mencari pekerjaan / pekerja di bidang TI?</a></li>
<li><a href="../id428179/index.html">Pada pelelangan Jepang, prototipe Wii-controller, yang dikembangkan untuk GameCube</a></li>
<li><a href="../id428183/index.html">Implementasi algoritma Levenberg-Marquardt untuk mengoptimalkan jaringan saraf pada TensorFlow</a></li>
<li><a href="../id428187/index.html">Cara menulis ekstensi untuk GNOME Shell: Mode Jangan Ganggu</a></li>
<li><a href="../id428189/index.html">Siapakah Paladin?</a></li>
<li><a href="../id428191/index.html">Apa yang harus kita atur hackathon, atau Bagaimana kita melakukan hackathon internal</a></li>
<li><a href="../id428193/index.html">Tentang pergi wisata</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
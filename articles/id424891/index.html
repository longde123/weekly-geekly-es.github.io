<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👫 🏬 🌅 Identifikasi penipuan menggunakan set data Enron. Bagian 1, persiapan data dan pemilihan penerimaan 🈷️ 👨🏽‍🚀 🥀</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Enron Corporation adalah salah satu tokoh paling terkenal dalam bisnis Amerika di tahun 2000-an. Ini difasilitasi bukan oleh bidang kegiatan mereka (l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identifikasi penipuan menggunakan set data Enron. Bagian 1, persiapan data dan pemilihan penerimaan</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424891/"><p> Enron Corporation adalah salah satu tokoh paling terkenal dalam bisnis Amerika di tahun 2000-an.  Ini difasilitasi bukan oleh bidang kegiatan mereka (listrik dan kontrak untuk pasokannya), tetapi oleh resonansi karena kecurangan di dalamnya.  Selama 15 tahun, pendapatan perusahaan telah berkembang pesat, dan pekerjaan di dalamnya menjanjikan gaji yang baik.  Namun semuanya berakhir dengan cepat: pada periode 2000-2001.  harga saham turun dari $ 90 / unit menjadi hampir nol karena penipuan yang diungkapkan dengan pendapatan yang diumumkan.  Sejak itu, kata "Enron" telah menjadi kata rumah tangga dan bertindak sebagai label untuk perusahaan yang beroperasi dalam pola yang sama. </p><br><p>  Selama persidangan, 18 orang (termasuk terdakwa terbesar dalam kasus ini: Andrew Fastov, Jeff Skilling dan Kenneth Lay) dihukum. </p><br><p><img src="https://habrastorage.org/webt/te/rh/1l/terh1lsenbtg26n8nhjbhv3opfi.jpeg" alt="image! [image] (http: // https: //habrastorage.org/webt/te/rh/1l/terh1lsenbtg26n8nhjbhv3opfi.jpeg)"></p><br><p>  Pada saat yang sama, arsip korespondensi elektronik antara karyawan perusahaan, yang lebih dikenal sebagai Enron Email Dataset, dan informasi orang dalam tentang pendapatan karyawan perusahaan ini dipublikasikan. </p><br><p>  Artikel ini akan memeriksa sumber-sumber data ini dan membangun model yang didasarkan padanya untuk menentukan apakah seseorang dicurigai melakukan penipuan.  Kedengarannya menarik?  Lalu, selamat datang di habrakat. <a name="habracut"></a></p><br><h1 id="opisanie-dataseta">  Deskripsi dataset </h1><br><p>  Dataset Enron (dataset) adalah kumpulan gabungan dari data terbuka yang berisi catatan orang yang bekerja di perusahaan yang mudah diingat dengan nama yang sesuai. <br>  Itu dapat membedakan 3 bagian: </p><br><ul><li>  payment_features - grup yang mencirikan pergerakan keuangan; </li><li>  stock_features - grup yang mencerminkan tanda-tanda yang terkait dengan saham; </li><li>  email_features - grup yang mencerminkan informasi tentang email orang tertentu dalam bentuk agregat. </li></ul><br><p>  Tentu saja, ada juga variabel target yang menunjukkan apakah orang tersebut diduga melakukan penipuan (tanda <abbr title="Orang yang menarik">'poi' <abbr>).</abbr></abbr> <abbr title="Orang yang menarik"><br></abbr> </p><p>  Unduh data kami dan mulai bekerja dengannya: </p><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> <span class="hljs-keyword"><span class="hljs-keyword">open</span></span>("final_project/enron_dataset.pkl", "rb") <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> data_file: data_dict = pickle.<span class="hljs-keyword"><span class="hljs-keyword">load</span></span>(data_file)</code> </pre> <br><p>  Setelah itu, kami mengubah <strong>data_dict yang</strong> diatur ke dalam kerangka data Pandas untuk pekerjaan yang lebih nyaman dengan data: </p><br><pre> <code class="hljs haskell"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> warnings warnings.filterwarnings('<span class="hljs-title"><span class="hljs-title">ignore'</span></span>) source_df = pd.DataFrame.from_dict(<span class="hljs-title"><span class="hljs-title">data_dict</span></span>, <span class="hljs-title"><span class="hljs-title">orient</span></span> = '<span class="hljs-title"><span class="hljs-title">index'</span></span>) source_df.drop('<span class="hljs-type"><span class="hljs-type">TOTAL</span></span>',<span class="hljs-title"><span class="hljs-title">inplace</span></span>=<span class="hljs-type"><span class="hljs-type">True</span></span>)</code> </pre> <br><p>  Kami mengelompokkan tanda-tanda sesuai dengan jenis yang ditunjukkan sebelumnya.  Ini harus memfasilitasi pekerjaan dengan data sesudahnya: </p><br><pre> <code class="hljs powershell">payments_features = [<span class="hljs-string"><span class="hljs-string">'salary'</span></span>, <span class="hljs-string"><span class="hljs-string">'bonus'</span></span>, <span class="hljs-string"><span class="hljs-string">'long_term_incentive'</span></span>, <span class="hljs-string"><span class="hljs-string">'deferred_income'</span></span>, <span class="hljs-string"><span class="hljs-string">'deferral_payments'</span></span>, <span class="hljs-string"><span class="hljs-string">'loan_advances'</span></span>, <span class="hljs-string"><span class="hljs-string">'other'</span></span>, <span class="hljs-string"><span class="hljs-string">'expenses'</span></span>, <span class="hljs-string"><span class="hljs-string">'director_fees'</span></span>, <span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>] stock_features = [<span class="hljs-string"><span class="hljs-string">'exercised_stock_options'</span></span>, <span class="hljs-string"><span class="hljs-string">'restricted_stock'</span></span>, <span class="hljs-string"><span class="hljs-string">'restricted_stock_deferred'</span></span>,<span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>] email_features = [<span class="hljs-string"><span class="hljs-string">'to_messages'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_poi_to_this_person'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_messages'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_this_person_to_poi'</span></span>, <span class="hljs-string"><span class="hljs-string">'shared_receipt_with_poi'</span></span>] target_field = <span class="hljs-string"><span class="hljs-string">'poi'</span></span></code> </pre> <br><h2 id="finansovye-dannye">  Data keuangan </h2><br><p>  Dalam dataset ini ada NaN yang dikenal banyak orang, dan itu mengungkapkan kesenjangan biasa dalam data.  Dengan kata lain, pembuat dataset tidak dapat menemukan informasi tentang atribut tertentu yang terkait dengan garis tertentu dalam bingkai data.  Akibatnya, kita dapat mengasumsikan bahwa NaN adalah 0, karena tidak ada informasi tentang sifat tertentu. </p><br><pre> <code class="hljs powershell">payments = source_df[<span class="hljs-type"><span class="hljs-type">payments_features</span></span>] payments = payments.replace(<span class="hljs-string"><span class="hljs-string">'NaN'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><h3 id="proverka-dannyh">  Verifikasi data </h3><br><p>  Ketika membandingkan dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">PDF asli yang</a> mendasari dataset, ternyata datanya sedikit terdistorsi, karena tidak untuk semua baris dalam <em>kerangka data</em> <strong>pembayaran</strong> <em>,</em> bidang <em>total_payments</em> adalah jumlah dari semua transaksi keuangan orang ini.  Anda dapat memverifikasi ini sebagai berikut: </p><br><pre> <code class="hljs powershell">errors = payments[<span class="hljs-type"><span class="hljs-type">payments</span></span>[<span class="hljs-type"><span class="hljs-type">payments_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]]<span class="hljs-type"><span class="hljs-type">.sum</span></span>(<span class="hljs-type"><span class="hljs-type">axis</span></span>=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) != <span class="hljs-type"><span class="hljs-type">payments</span></span>[<span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>]] errors.head()</code> </pre> <br><p><img src="https://habrastorage.org/webt/eo/79/ye/eo79ye27iirsiwcuickrxz4on30.png" alt="2 garis tidak valid"><br>  Kami melihat bahwa BELFER ROBERT dan BHATNAGAR SANJAY memiliki jumlah pembayaran yang salah. </p><br><p>  Anda dapat memperbaiki kesalahan ini dengan memindahkan data di baris kesalahan ke kiri atau ke kanan dan menghitung jumlah semua pembayaran lagi: </p><br><pre> <code class="hljs powershell">import numpy as np shifted_values = payments.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>:]].values expected_payments = shifted_values.sum() shifted_values = np.append(shifted_values, expected_payments) payments.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>] = shifted_values shifted_values = payments.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]].values payments.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>] = np.insert(shifted_values, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><h2 id="dannye-po-akciyam">  Stok Data </h2><br><pre> <code class="hljs powershell">stocks = source_df[<span class="hljs-type"><span class="hljs-type">stock_features</span></span>] stocks = stocks.replace(<span class="hljs-string"><span class="hljs-string">'NaN'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  Lakukan pemeriksaan validasi dalam kasus ini juga: </p><br><pre> <code class="hljs powershell">errors = stocks[<span class="hljs-type"><span class="hljs-type">stocks</span></span>[<span class="hljs-type"><span class="hljs-type">stock_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]]<span class="hljs-type"><span class="hljs-type">.sum</span></span>(<span class="hljs-type"><span class="hljs-type">axis</span></span>=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) != <span class="hljs-type"><span class="hljs-type">stocks</span></span>[<span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>]] errors.head()</code> </pre> <br><p><img src="https://habrastorage.org/webt/sd/28/mz/sd28mzikmhurh_b0mqwibnje8fa.png" alt="gambar"></p><br><p>  Kami juga akan memperbaiki kesalahan dalam persediaan: </p><br><pre> <code class="hljs powershell">shifted_values = stocks.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>:]].values expected_payments = shifted_values.sum() shifted_values = np.append(shifted_values, expected_payments) stocks.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>] = shifted_values shifted_values = stocks.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]].values stocks.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>] = np.insert(shifted_values, <span class="hljs-number"><span class="hljs-number">0</span></span>, shifted_values[-<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h2 id="svodnye-dannye-po-elektronnoy-perepiske">  Korespondensi Email </h2><br><p>  Jika untuk keuangan atau saham ini NaN setara dengan 0, dan ini cocok dengan hasil akhir untuk masing-masing kelompok ini, dalam hal email, NaN lebih masuk akal untuk diganti dengan beberapa nilai default.  Untuk melakukan ini, Anda dapat menggunakan Imputer: </p><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">from</span></span> sklearn.impute <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SimpleImputer imp = SimpleImputer()</code> </pre> <br><p>  Pada saat yang sama, kami akan mempertimbangkan nilai default untuk setiap kategori (apakah kami mencurigai seseorang melakukan penipuan) secara terpisah: </p><br><pre> <code class="hljs markdown">target = source<span class="hljs-emphasis"><span class="hljs-emphasis">_df[target_</span></span>field] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data = source_</span></span>df[<span class="hljs-string"><span class="hljs-string">email_features</span></span>] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data = pd.concat([email_</span></span>data, target], axis=1) email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>poi = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data[email_</span></span>data[<span class="hljs-string"><span class="hljs-string">target_field</span></span>]][<span class="hljs-string"><span class="hljs-string">email_features</span></span>] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>nonpoi = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data[email_</span></span>data[<span class="hljs-string"><span class="hljs-string">target_field</span></span>] == False][email<span class="hljs-emphasis"><span class="hljs-emphasis">_features] email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_poi[email_</span></span>features] = imp.fit<span class="hljs-emphasis"><span class="hljs-emphasis">_transform(email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_poi) email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_nonpoi[email_</span></span>features] = imp.fit<span class="hljs-emphasis"><span class="hljs-emphasis">_transform(email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_nonpoi) email_</span></span>data = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>poi.append(email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>nonpoi)</code> </pre> <br><p>  Dataset akhir setelah koreksi: </p><br><pre> <code class="hljs cs">df = payments.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(stocks) df = df.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(email_data) df = df.astype(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)</code> </pre> <br><h2 id="vybrosy">  Emisi </h2><br><p>  Pada langkah terakhir dari tahap ini, kami akan menghapus semua outlier, yang dapat mengubah pelatihan.  Pada saat yang sama, pertanyaan selalu muncul: berapa banyak data yang dapat kita hapus dari sampel dan masih tidak hilang sebagai model yang terlatih?  Saya mengikuti saran dari salah satu dosen di kursus ML (Machine Learning) tentang Udacity - "Hapus 10 dan periksa emisi lagi." </p><br><pre> <code class="hljs powershell">first_quartile = df.quantile(q=<span class="hljs-number"><span class="hljs-number">0.25</span></span>) third_quartile = df.quantile(q=<span class="hljs-number"><span class="hljs-number">0.75</span></span>) IQR = third_quartile - first_quartile outliers = df[(<span class="hljs-type"><span class="hljs-type">df</span></span> &gt; (<span class="hljs-type"><span class="hljs-type">third_quartile</span></span> + <span class="hljs-number"><span class="hljs-number">1.5</span></span> * <span class="hljs-type"><span class="hljs-type">IQR</span></span>)) | (<span class="hljs-type"><span class="hljs-type">df</span></span> &lt; (<span class="hljs-type"><span class="hljs-type">first_quartile</span></span> - <span class="hljs-number"><span class="hljs-number">1.5</span></span> * <span class="hljs-type"><span class="hljs-type">IQR</span></span>))].count(axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) outliers.sort_values(axis=<span class="hljs-number"><span class="hljs-number">0</span></span>, ascending=False, inplace=True) outliers = outliers.head(<span class="hljs-number"><span class="hljs-number">10</span></span>) outliers</code> </pre> <br><p>  Pada saat yang sama, kami tidak akan menghapus catatan yang outlier dan diduga penipuan.  Alasannya adalah bahwa hanya ada 18 baris dengan data seperti itu, dan kami tidak dapat mengorbankannya, karena ini dapat menyebabkan kurangnya contoh pelatihan.  Akibatnya, kami menghapus hanya orang-orang yang tidak dicurigai melakukan penipuan, tetapi pada saat yang sama memiliki sejumlah besar tanda-tanda dimana emisi diamati: </p><br><pre> <code class="hljs powershell">target_for_outliers = target.loc[<span class="hljs-type"><span class="hljs-type">outliers.index</span></span>] outliers = pd.concat([<span class="hljs-type"><span class="hljs-type">outliers</span></span>, <span class="hljs-type"><span class="hljs-type">target_for_outliers</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) non_poi_outliers = outliers[<span class="hljs-type"><span class="hljs-type">np.logical_not</span></span>(<span class="hljs-type"><span class="hljs-type">outliers.poi</span></span>)] df.drop(non_poi_outliers.index, inplace=True)</code> </pre> <br><h2 id="privedenie-k-itogovom-vidu">  Menyelesaikan </h2><br><p>  Kami menormalkan data kami: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scale df[df.<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>] = scale(df)</code> </pre> <br><p>  Memungkinkan target variabel target ke tampilan yang kompatibel: </p><br><pre> <code class="hljs cmake"><span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.drop(non_poi_outliers.index, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">target</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.map({<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>}) <span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.value_counts()</code> </pre> <br><p><img src="https://habrastorage.org/webt/nr/mn/fi/nrmnfi0bdldw36fg9uy-tcxinsa.png" alt="gambar"><br>  Akibatnya, 18 tersangka dan 121 orang yang tidak dicurigai. </p><br><h1 id="otbor-priznakov">  Pemilihan Fitur </h1><br><p>  Mungkin salah satu poin utama sebelum mempelajari model apa pun adalah pemilihan fitur yang paling penting. </p><br><h2 id="proverka-na-multikollinearnost">  Uji Multikolinearitas </h2><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib <span class="hljs-keyword"><span class="hljs-keyword">inline</span></span> sns.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(style="whitegrid") corr = df.corr() * <span class="hljs-number"><span class="hljs-number">100</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">Select</span></span> upper triangle <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> correlation matrix mask = np.zeros_like(corr, dtype=np.bool) mask[np.triu_indices_from(mask)] = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">Set</span></span> up the matplotlib figure f, ax = plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">11</span></span>)) # Generate a custom diverging colormap cmap = sns.diverging_palette(<span class="hljs-number"><span class="hljs-number">220</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) # Draw the heatmap <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> the mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> correct aspect ratio sns.heatmap(corr, mask=mask, cmap=cmap, center=<span class="hljs-number"><span class="hljs-number">0</span></span>, linewidths=<span class="hljs-number"><span class="hljs-number">1</span></span>, cbar_kws={"shrink": <span class="hljs-number"><span class="hljs-number">.7</span></span>}, annot=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, fmt=".2f")</code> </pre> <br><p><img src="https://habrastorage.org/webt/kw/66/ta/kw66tahpopi7zjc6tvaj1uzq9qe.png" alt="gambar"><br>  Seperti yang dapat Anda lihat dari gambar, kami memiliki hubungan yang jelas antara 'loan_advanced' dan 'total_payments', serta antara 'total_stock_value' dan 'dibatasi_stock'.  Seperti yang disebutkan sebelumnya, 'total_payments' dan 'total_stock_value' hanyalah hasil dari menjumlahkan semua indikator dalam grup tertentu.  Karena itu, mereka dapat dihapus: </p><br><pre> <code class="hljs pgsql">df.<span class="hljs-keyword"><span class="hljs-keyword">drop</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>=[<span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>, <span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>], inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h2 id="sozdanie-novyh-priznakov">  Menciptakan Karakteristik Baru </h2><br><p>  Ada juga asumsi bahwa tersangka menulis untuk menemani lebih sering daripada kepada karyawan yang tidak terlibat dalam hal ini.  Dan sebagai hasilnya, proporsi pesan semacam itu harus lebih besar daripada proporsi pesan untuk karyawan biasa.  Berdasarkan pernyataan ini, Anda dapat membuat tanda-tanda baru yang mencerminkan persentase masuk / keluar terkait dengan tersangka: </p><br><pre> <code class="hljs powershell">df[<span class="hljs-string"><span class="hljs-string">'ratio_of_poi_mail'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'from_poi_to_this_person'</span></span>]/df[<span class="hljs-string"><span class="hljs-string">'to_messages'</span></span>] df[<span class="hljs-string"><span class="hljs-string">'ratio_of_mail_to_poi'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'from_this_person_to_poi'</span></span>]/df[<span class="hljs-string"><span class="hljs-string">'from_messages'</span></span>]</code> </pre> <br><h2 id="otsev-lishnih-priznakov">  Menyaring tanda-tanda yang tidak perlu </h2><br><p>  Di toolkit orang yang terkait dengan ML, ada banyak alat yang sangat baik untuk memilih fitur yang paling signifikan (SelectKBest, SelectPercentile, VarianceThreshold, dll.).  Dalam hal ini, RFECV akan digunakan, karena ini mencakup validasi silang, yang memungkinkan Anda untuk menghitung fitur yang paling penting dan memeriksanya di semua himpunan bagian sampel: </p><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split X_train, X_test, y_train, y_test = train_test_split(<span class="hljs-title"><span class="hljs-title">df</span></span>, <span class="hljs-title"><span class="hljs-title">target</span></span>, <span class="hljs-title"><span class="hljs-title">test_size</span></span>=0.2, <span class="hljs-title"><span class="hljs-title">random_state</span></span>=42)</code> </pre> <br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RFECV <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier forest = RandomForestClassifier(random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>) rfecv = RFECV(estimator=forest, cv=<span class="hljs-number"><span class="hljs-number">5</span></span>, scoring=<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>) rfecv = rfecv.fit(X_train, y_train) plt.figure() plt.xlabel("Number of features selected") plt.ylabel("Cross validation score of number of selected features") plt.plot(range(<span class="hljs-number"><span class="hljs-number">1</span></span>, len(rfecv.grid_scores_) + <span class="hljs-number"><span class="hljs-number">1</span></span>), rfecv.grid_scores_, <span class="hljs-string"><span class="hljs-string">'--o'</span></span>) indices = rfecv.get_support() <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> = X_train.<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>[indices] print(<span class="hljs-string"><span class="hljs-string">'The most important columns are {}'</span></span>.format(<span class="hljs-string"><span class="hljs-string">','</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>)))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fm/-7/oo/fm-7oo9gnbxhmpiw_vwldkgpwpi.png" alt="gambar"><br>  Seperti yang Anda lihat, RandomForestClassifier menghitung bahwa hanya 7 dari 18 atribut yang penting.  Menggunakan sisanya menyebabkan penurunan akurasi model. </p><br><pre> <code class="hljs pgsql">The most important <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> are bonus, deferred_income, other, exercised_stock_options, shared_receipt_with_poi, ratio_of_poi_mail, ratio_of_mail_to_poi</code> </pre> <br><p>  7 fitur ini akan digunakan di masa depan untuk menyederhanakan model dan mengurangi risiko pelatihan ulang: </p><br><ul><li>  bonus </li><li>  deferred_income </li><li>  lainnya </li><li>  exercise_stock_options </li><li>  shared_receipt_with_poi </li><li>  ratio_of_poi_mail </li><li>  ratio_of_mail_to_poi </li></ul><br><p>  Ubah struktur pelatihan dan sampel uji untuk pelatihan model mendatang: </p><br><pre> <code class="hljs powershell">X_train = X_train[<span class="hljs-type"><span class="hljs-type">columns</span></span>] X_test = X_test[<span class="hljs-type"><span class="hljs-type">columns</span></span>]</code> </pre> <br><p>  Ini adalah akhir dari bagian pertama yang menggambarkan penggunaan Enron Dataset sebagai contoh tugas klasifikasi dalam ML.  Berdasarkan materi dari kursus Pengantar Pembelajaran Mesin di Udacity.  Ada juga <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">notebook python yang</a> mencerminkan seluruh rangkaian tindakan. </p><br><blockquote>  Bagian kedua ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di sini</a> <br></blockquote><p></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id424891/">https://habr.com/ru/post/id424891/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id424877/index.html">Sistem pendingin rem fluida</a></li>
<li><a href="../id424879/index.html">Ketersediaan Antarmuka Kuliah Yandex</a></li>
<li><a href="../id424881/index.html">Newtoo - mengembangkan mesin browser penuh dari awal pada tahun 2018?</a></li>
<li><a href="../id424887/index.html">Apa yang dibungkam Lida: awal karier seorang pengembang. Prinsip atau cara menjadi Middl</a></li>
<li><a href="../id424889/index.html">Melihat ke dalam coprocessor Intel 8087</a></li>
<li><a href="../id424893/index.html">Pengrajin membuat modul WiFi untuk Macintosh SE / 30, model 1989</a></li>
<li><a href="../id424895/index.html">Mengetik: Membuat Negara Tidak Valid Tidak Dapat Diekspresikan</a></li>
<li><a href="../id424897/index.html">Pertemuan yang tidak terduga. Bab 18</a></li>
<li><a href="../id424899/index.html">Apa yang harus didengarkan tentang audio: 15 podcast</a></li>
<li><a href="../id424901/index.html">Intisari materi menarik untuk pengembang seluler # 272 (24 September - 30 September)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
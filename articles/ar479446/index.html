<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😅 🛠️ 🧔🏻 السيارات هي بالفعل قبل الناس في اختبارات القراءة. لكن هل يفهمون ما يقرؤون؟ 🍌 👨 👰🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="أداة BERT قادرة على تجاوز الناس في اختبارات القراءة والفهم. ومع ذلك ، فإنه يوضح أيضًا الطريقة التي لا يزال يتعين على منظمة العفو الدولية الذهاب إليها....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>السيارات هي بالفعل قبل الناس في اختبارات القراءة. لكن هل يفهمون ما يقرؤون؟</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479446/" style=";text-align:right;direction:rtl"><h3 style=";text-align:right;direction:rtl">  أداة BERT قادرة على تجاوز الناس في اختبارات القراءة والفهم.  ومع ذلك ، فإنه يوضح أيضًا الطريقة التي لا يزال يتعين على منظمة العفو الدولية الذهاب إليها. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/1e6/359/58b/1e635958bf5af44bcc9b6256e1a0101f.jpg"><br><br>  في خريف عام 2017 ، قرر <a href="http://www.nyu.edu/projects/bowman/">سام بومان</a> ، وهو لغوي حسابي من جامعة نيويورك ، أن أجهزة الكمبيوتر لا تزال لا تفهم النص جيدًا.  بالطبع ، لقد تعلموا جيدًا بما يكفي لمحاكاة هذا الفهم في مناطق ضيقة معينة ، مثل الترجمات التلقائية أو تحليل المشاعر (على سبيل المثال ، لتحديد ما إذا كانت الجملة "فظة أو حلوة" ، على حد قوله).  ومع ذلك ، أراد بومان شهادة قابلة للقياس: فهم حقيقي لما كتب ، مبين في اللغة البشرية.  وصعد لاختبار. <br><a name="habracut"></a><br>  في مقالة <a href="https://arxiv.org/abs/1804.07461">نشرت</a> في أبريل 2018 بالتعاون مع زملاء في جامعة واشنطن و DeepMind ، وهي شركة مملوكة لشركة Google تعمل في مجال الذكاء الاصطناعي ، قدم بومان مجموعة من تسع مهام لفهم القراءة لأجهزة الكمبيوتر تحت الاسم العام GLUE (تقييم فهم اللغة العام) [تقييم الفهم لغة معممة].  وقال بومان: "لقد صُمم الاختبار" كمثال إرشادي إلى حد ما على ما يعتبره مجتمع البحث مهامًا مثيرة للاهتمام "، ولكن بطريقة" سهلة للأشخاص ".  على سبيل المثال ، في مهمة واحدة ، يتم طرح سؤال حول حقيقة الجملة ، والتي يجب تقديرها بناءً على معلومات من جملة سابقة.  إذا أمكنك القول إن الرسالة "لقد هبط الرئيس ترامب في العراق ، بعد أن بدأ زيارته التي استمرت سبعة أيام" يعني أن "الرئيس ترامب يزور الخارج" ، فإنك تجتاز الاختبار. <br><br>  فشلت السيارات له.  حتى الشبكات العصبية المتقدمة لم تسجل أكثر من 69 نقطة من إجمالي 100 نقطة في جميع الاختبارات - المراكز الثلاثة الأولى برصيد ناقص.  لم يفاجأ بومان وزملاؤه.  تُظهر الشبكات العصبية - إنشاءات متعددة الطبقات لها روابط حسابية تشبه عمل الخلايا العصبية في دماغ الثدييات - نتائج جيدة في مجال "معالجة اللغات الطبيعية" ، لكن الباحثين لم يكونوا متأكدين من أن هذه الأنظمة تتعلم شيئًا جادًا حول اللغة.  ويثبت الغراء ذلك.  "تظهر النتائج المبكرة أن اجتياز اختبارات GLUE يتجاوز قدرات النماذج والأساليب الحالية ،" بومان وآخرون. <br><br>  لكن تقييمهم لم يدم طويلا.  في أكتوبر 2018 ، قدمت Google طريقة جديدة ، هي BERT (عروض تشفير ثنائية الاتجاه من المحولات) [عروض تشفير ثنائية الاتجاه للمحولين].  حصل على درجة 80.5 في الغراء.  في غضون ستة أشهر فقط ، قفزت السيارات من ثلاثة مع ناقص إلى أربعة مع ناقص في هذا الاختبار الجديد ، والذي يقيس الفهم الحقيقي للغة الطبيعية بواسطة الآلات. <br><br>  يتذكر بومان: "كان الأمر يشبه" اللعنة "، مستخدمًا كلمة أكثر سخونة.  - تم تلقي هذه الرسالة مع عدم ثقة المجتمع.  تلقى بيرت في العديد من الاختبارات درجات قريبة مما اعتبرناه الحد الأقصى الممكن. "  في الواقع ، قبل ظهور BERT في اختبار GLUE ، لم يكن هناك حتى أي تقييمات للإنجازات البشرية لمقارنتها.  عندما أضافهم بومان وأحد طلابه للخريجين إلى GLUE في فبراير 2019 ، استمروا بضعة أشهر فقط ، ثم قام النموذج الذي يستند إلى BERT من Microsoft على <a href="https://blogs.msdn.microsoft.com/stevengu/2019/06/20/microsoft-achieves-human-performance-estimate-on-glue-benchmark/">التغلب عليهم</a> . <br><br>  في وقت كتابة هذا التقرير ، كانت جميع <a href="https://gluebenchmark.com/leaderboard/">الأماكن الأولى</a> تقريبًا في اختبارات GLUE مشغولة بأنظمة تتضمن نموذج BERT أو تمدده أو تحسنه.  خمسة منهم متفوقة في القدرات البشرية. <br><br>  ولكن هل هذا يعني أن الذكاء الاصطناعى قد بدأ يفهم لغتنا ، أم أنه مجرد تعلم التغلب على أنظمتنا؟  بعد أن أخذت الشبكات العصبية المستندة إلى BERT نوع GLUE من العاصفة ، ظهرت طرق تقييم جديدة تعتبر أن أنظمة البرمجة اللغوية العصبية (NLP) هي نسخ كمبيوتر لـ " <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BC%25D0%25BD%25D1%258B%25D0%25B9_%25D0%2593%25D0%25B0%25D0%25BD%25D1%2581">هانز الذكي</a> " <a href="https://ru.wikipedia.org/wiki/%25D0%25A3%25D0%25BC%25D0%25BD%25D1%258B%25D0%25B9_%25D0%2593%25D0%25B0%25D0%25BD%25D1%2581">،</a> وهو حصان عاش في بداية القرن العشرين وكان من المفترض أنه ذكي بما فيه الكفاية ل لإجراء حسابات حسابية في العقل ، ولكن في الواقع قراءة علامات اللاوعي التي قدمها لها صاحبها. <br><br>  "نحن نعلم أننا في مكان ما في المنطقة الرمادية بين فهم اللغة بالمعنى الضيق والمضيق للغاية ، وخلق الذكاء الاصطناعي" ، قال بومان.  - بشكل عام ، يمكن وصف رد فعل المتخصصين على النحو التالي: كيف حدث هذا؟  ماذا يعني هذا؟  ماذا سنفعل الآن؟ <br><br><h2 style=";text-align:right;direction:rtl">  كتابة القواعد الخاصة بك </h2><br>  في تجربة الفكر " <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B8%25D1%2582%25D0%25B0%25D0%25B9%25D1%2581%25D0%25BA%25D0%25B0%25D1%258F_%25D0%25BA%25D0%25BE%25D0%25BC%25D0%25BD%25D0%25B0%25D1%2582%25D0%25B0">الغرفة الصينية</a> " الشهيرة ، يجلس شخص لا يعرف اللغة الصينية في غرفة مليئة بالعديد من الكتب ذات القواعد.  في الكتب ، يمكنك العثور على الإرشادات الدقيقة حول كيفية قبول تسلسل الأحرف الصينية التي تدخل الغرفة وإعطاء إجابة مناسبة.  ألف شخص خارج النخيل أسئلة مكتوبة باللغة الصينية تحت باب الغرفة.  يلجأ الشخص من الداخل إلى الكتب مع القواعد ، ويصوغ إجابات معقولة تمامًا باللغة الصينية. <br><br>  تم استخدام هذه التجربة لإثبات أنه على الرغم من الانطباع الخارجي ، لا يمكن للمرء أن يقول أن الشخص الموجود في الغرفة لديه أي فهم للغة الصينية.  ومع ذلك ، كان حتى محاكاة التفاهم هدفا مقبولا من البرمجة اللغوية العصبية. <br><br>  المشكلة الوحيدة هي الافتقار إلى الكتب المثالية ذات القواعد ، لأن اللغة الطبيعية معقدة للغاية وغير منهجية بحيث لا يمكن اختزالها إلى مجموعة قوية من المواصفات.  خذ على سبيل المثال ، بناء الجملة: القواعد (بما في ذلك التجريبية) التي تحدد تجميع الكلمات في جمل ذات معنى.  الجملة " <a href="https://books.google.com/books%3Fid%3D55YaAAAAIAAJ%26dq%3Dcolorless%2Bgreen%2Bideas%2Bsleep%2Bfuriously">النوم الأخضر بعنف الأفكار عديم اللون</a> " لديه بناء الجملة ، ولكن أي شخص يعرف اللغة يفهم معنى لها.  ما الذي يمكن أن يتضمن كتاب القواعد المصمم خصيصًا هذه الحقيقة غير المكتوبة المتعلقة باللغة الطبيعية - ناهيك عن حقائق أخرى لا حصر لها؟ <br><br>  حاول الباحثون في البرمجة اللغوية العصبية العثور على هذا <a href="https://ru.wikipedia.org/wiki/%25D0%259A%25D0%25B2%25D0%25B0%25D0%25B4%25D1%2580%25D0%25B0%25D1%2582%25D1%2583%25D1%2580%25D0%25B0_%25D0%25BA%25D1%2580%25D1%2583%25D0%25B3%25D0%25B0">التربيع للدائرة</a> ، مما أجبر الشبكات العصبية على كتابة كتب القواعد الحرفية الخاصة بهم في عملية ما يسمى  "التدريب المسبق" أو التدريب التمهيدي. <br><br>  حتى عام 2018 ، كانت إحدى أدوات التدريب الرئيسية بمثابة القاموس.  استخدم هذا القاموس <a href="https://ru.wikipedia.org/wiki/%25D0%2592%25D0%25B5%25D0%25BA%25D1%2582%25D0%25BE%25D1%2580%25D0%25BD%25D0%25BE%25D0%25B5_%25D0%25BF%25D1%2580%25D0%25B5%25D0%25B4%25D1%2581%25D1%2582%25D0%25B0%25D0%25B2%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25B8%25D0%25B5_%25D1%2581%25D0%25BB%25D0%25BE%25D0%25B2">تمثيلًا متجهًا للكلمات</a> [word embedding] ، واصفًا الروابط بين الكلمات في شكل أرقام حتى تتمكن الشبكات العصبية من إدراك هذه المعلومات كمدخلات - يشبه مسردًا تقريبيًا لشخص في غرفة صينية.  ومع ذلك ، فإن المدربين مسبقا على الشبكة العصبية قاموس ناقلات لا يزال أعمى لمعنى الكلمات على مستوى الجملة.  "من وجهة نظرها ، الجمل" الرجل يبتل الكلب "و" يبتل الرجل الرجل "متطابقتان" ، كما قال <a href="http://tallinzen.net/">Tel Linsen</a> ، عالم لغوي محوسب في جامعة جونز هوبكنز. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55a/245/f48/55a245f4866cf5ffcf2689d2161f8536.jpg" width="50%"><br>  <i>تل لينسين ، عالم اللغويات في جامعة جونز هوبكنز.</i> <br><br>  تستخدم الطريقة المُحسّنة تدريبات مسبقة لتزويد الشبكة العصبية بكتب قواعد أكثر ثراءً - ليس فقط قاموس ، ولكن أيضًا بناء جملة مع سياق - قبل تدريسها لأداء مهمة محددة في البرمجة اللغوية العصبية.  في بداية عام 2018 ، توصل باحثون من OpenAI ، وجامعة سان فرانسيسكو ، ومعهد ألين للذكاء الاصطناعي ، وجامعة واشنطن في نفس الوقت إلى طريقة صعبة للاقتراب من ذلك.  بدلاً من تدريب واحد فقط ، وهو الطبقة الأولى من الشبكة التي تستخدم التمثيل المتجه للكلمات ، بدأ الباحثون في تدريب الشبكة بالكامل لمهمة أكثر عمومية تدعى نمذجة اللغة. <br><br>  "إن أبسط طريقة لنمذجة اللغة هي كما يلي: سوف أقرأ مجموعة من الكلمات وأحاول التنبؤ بما يلي" ، أوضح <a href="https://research.fb.com/people/ott-myle/">مايل أوت</a> ، باحث في Facebook.  "إذا قلت ،" وُلد جورج دبليو بوش "، فإن النماذج تحتاج إلى التنبؤ بالكلمة التالية في هذه الجملة." <br><br>  يمكن إنشاء مثل هذه النماذج اللغوية ذات التدريب العميق بكفاءة عالية.  يقوم الباحثون ببساطة بإطعام كميات هائلة من النص المكتوب من موارد مجانية مثل ويكيبيديا إلى شبكاتهم العصبية - مليارات الكلمات مرتبة في جمل صحيحة نحويًا - والسماح للشبكة بالتنبؤ بالكلمة التالية من تلقاء نفسها.  في الواقع ، هذا يعادل حقيقة قيامنا بدعوة شخص في غرفة صينية لإنشاء مجموعة قواعد خاصة به ، وذلك باستخدام الرسائل الصينية الواردة كمرجع. <br><br>  وقال أوت "إن جمال هذا النهج هو أن النموذج يكتسب الكثير من المعرفة في بناء الجملة". <br><br>  علاوة على ذلك ، يمكن لهذه الشبكات العصبية المدربة مسبقًا تطبيق تمثيلاتها اللغوية لتعليم مهمة أضيق ، لا تتعلق بتنبؤ الكلمات ، بعملية الصقل. <br><br>  "يمكنك أخذ النموذج من مرحلة ما قبل التدريب وتكييفه مع أي مهمة حقيقية تحتاجها" ، أوضح أوت.  "وبعد ذلك تحصل على نتائج أفضل بكثير مما لو كنت حاولت حل مشكلتك مباشرةً من البداية". <br><br>  في يونيو 2018 ، عندما قدمت OpenAI شبكتها <a href="https://openai.com/blog/language-unsupervised/">العصبية GPT</a> ، مع نموذج لغة مدرج فيها لمدة شهر كامل على مليار كلمة (مأخوذة من 11،038 كتابًا رقميًا) ، أصبحت نتيجتها في اختبار GLUE ، 72.8 نقطة ، على الفور هي الأكثر الأفضل.  ومع ذلك ، اقترح سام بومان أن هذا المجال سوف يتطور لفترة طويلة جدًا قبل أن يتمكن أي نظام على الأقل من الاقتراب من مستوى الرجل. <br><br>  ثم ظهر بيرت. <br><br><h2 style=";text-align:right;direction:rtl">  وصفة واعدة </h2><br>  إذن ما هو بيرت؟ <br><br>  أولاً ، إنها ليست شبكة عصبية مدربة تدريباً كاملاً ، قادرة على تحقيق نتائج فورية على المستوى الإنساني.  يقول بومان إن هذه وصفة دقيقة للغاية لتدريب الشبكة العصبية.  كخبز يمكن ، باتباع الوصفة ، ضمان إعطاء الكعك اللذيذ - والتي يمكن استخدامها بعد ذلك لكعك مختلف ، من التوت إلى كيش السبانخ - لذا ابتكر باحثو Google وصفة BERT يمكن أن تكون بمثابة أساس مثالي للشبكات العصبية "الخبيز" (أي ، صقلها) ، بحيث تتكيف بشكل جيد مع المهام المختلفة في معالجة اللغة الطبيعية.  جعل Google رمز BERT مفتوحًا ، مما يعني أن الباحثين الآخرين لم يعودوا بحاجة إلى تكرار هذه الوصفة من البداية - يمكنهم فقط تنزيلها ؛  انها نوع من مثل شراء كعكة قبل خبز لكعكة في المتجر. <br><br>  إذا كانت بيرت وصفة ، فما هي قائمة المكونات؟  وقال <a href="https://levyomer.wordpress.com/">عمر ليفي</a> ، باحث في فيسبوك قام <a href="https://arxiv.org/abs/1906.04341">بتحليل</a> جهاز بيرت: "هذه نتيجة لثلاثة أشياء مختلفة متصلة ببعضها البعض حتى يبدأ النظام في العمل". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1ee/f23/473/1eef234733ede2389825e047170009e0.jpg" width="50%"><br>  <i>عمر ليفي ، باحث فيسبوك</i> <br><br>  الأول هو نموذج اللغة المُدرَّب مسبقًا ، أي الدلائل نفسها من الغرفة الصينية.  والثاني هو الفرصة لتحديد أي من ميزات الاقتراح هي الأكثر أهمية. <br><br>  في عام 2017 ، عمل <a href="http://jakob.uszkoreit.net/">Jacob Uzkoreit</a> ، وهو مهندس في Google Brain ، على طرق لتسريع محاولات الشركة لفهم اللغة.  وأشار إلى أن جميع الشبكات العصبية المتقدمة تعاني من القيود الكامنة: فهي تدرس الجملة بالكلمات.  يبدو أن هذا "التسلسل" يتزامن مع فكرة كيفية قراءة الناس للنص.  ومع ذلك ، أصبح Uzkoreit مهتمًا ، "ألا يمكن أن يكون فهم اللغة في وضع متسلسل خطي ليس هو الأمثل." <br><br>  طور المعدل الضيق مع الزملاء بنية جديدة للشبكات العصبية ، مع التركيز على "الاهتمام" ، وهي آلية تسمح لكل طبقة من الشبكة العصبية بتعيين أوزان كبيرة لميزات معينة من بيانات الإدخال مقارنة بالآخرين.  هذه البنية الجديدة باهتمام ، أي المحول ، يمكن أن تأخذ جملة مثل "الكلب يعض الرجل" كمدخل وترميز كل كلمة بالتوازي بطرق مختلفة.  على سبيل المثال ، يمكن للمحول الربط بين "اللدغات" و "الشخص" كفعل وكائن موضوع ، متجاهلاً المادة "أ" ؛  في الوقت نفسه ، يمكنها أن تربط بين "العض" و "الكلب" كفعل وموضوع ، متجاهلة المقالة "the". <br><br>  تقدم الطبيعة غير المتناسقة للمحول جمل أكثر تعبيرًا ، أو ، كما يقول Uzkoreit ، تشبه الأشجار.  تنشئ كل طبقة من الشبكة العصبية العديد من الروابط المتوازية بين بعض الكلمات ، متجاهلة الباقي - تقريبًا كيف يقوم طالب في المدرسة الابتدائية بتفكيك الجملة إلى أجزاء.  غالبًا ما تتم هذه الروابط بين الكلمات التي قد لا تكون قريبة.  "مثل هذه الهياكل تبدو وكأنها تراكب من عدة أشجار" ، أوضح Uzkoreit. <br><br>  إن مثل هذه الجمل التي تشبه الشجرة تعطي المحولات الفرصة لنمذجة المعاني السياقية ، وكذلك دراسة فعالة للعلاقات بين الكلمات المتباعدة في الجمل المعقدة.  وقال أوزكوريت: "هذا أمر غير بديهي إلى حد ما ، لكنه يأتي من علم اللغة ، والذي شارك منذ وقت طويل في نماذج لغوية تشبه الأشجار." <br><br><img src="https://habrastorage.org/getpro/habr/post_images/21e/0a1/fe2/21e0a1fe2331c110f5cb2a966b2b173d.jpg" width="50%"><br>  <i>يعقوب أوزكوريت ، رئيس فريق برلين غوغل آي</i> <br><br>  أخيرًا ، يوسع المكون الثالث في وصفة بيرت القراءة غير الخطية بدرجة أكبر. <br><br>  على عكس النماذج اللغوية الأخرى المدربة مسبقًا والتي تم إنشاؤها بواسطة معالجة تيرابايت من النص من اليسار إلى اليمين بواسطة الشبكات العصبية ، فإن نموذج BERT يقرأ من اليمين إلى اليسار وفي نفس الوقت من اليسار إلى اليمين ، ويتعلم التنبؤ بالكلمات المستبعدة عشوائيًا من الجمل.  على سبيل المثال ، يمكن لـ BERT قبول جملة من النموذج "George W. Bush [...] في ولاية كونيتيكت عام 1946" ، والتنبؤ بالكلمة المخفية في منتصف الجملة (في هذه الحالة ، "المولد") ، بعد معالجة النص في كلا الاتجاهين.  وقال أوزكوريت: "هذه ثنائية الاتجاه تجبر الشبكة العصبية على استخراج أكبر قدر ممكن من المعلومات من أي مجموعة فرعية من الكلمات". <br><br>  التظاهر القائم على BERT المستخدم مثل لعبة الكلمات - نمذجة اللغة مع التقنيع - ليس بالأمر الجديد.  تم استخدامه منذ عقود لقياس فهم الناس للغة.  بالنسبة إلى Google ، قدم طريقة عملية لاستخدام الاتجاه الثنائي الاتجاه في الشبكات العصبية بدلاً من أساليب التدريب المسبق أحادية الاتجاه التي سيطرت على هذا المجال من قبل.  وقال <a href="https://kentonl.com/">كنتون لي</a> ، باحث في Google: "قبل بيرت ، كانت نمذجة اللغة أحادية الاتجاه هي المعيار ، على الرغم من أن هذا قيد اختياري". <br><br>  كل عنصر من هذه المكونات الثلاثة - نموذج لغة عميقة مع التدريب المسبق والانتباه والاتجاه المزدوج - موجود قبل BERT بشكل منفصل.  ولكن حتى أصدرت Google وصفتهم في نهاية عام 2018 ، لم يجمعهم أحد بهذه الطريقة الناجحة. <br><br><h2 style=";text-align:right;direction:rtl">  تكرير وصفة </h2><br>  مثل أي وصفة جيدة ، سرعان ما تم تكييفها من قبل الطهاة مختلف الأذواق.  في ربيع عام 2019 ، كانت هناك فترة "عندما صعدت مايكروسوفت وعلي بابا على أعقاب بعضهما البعض ، وتغيير الأماكن في الترتيب الأسبوعي ، وتعديل نموذجهم ،" يتذكر بومان.  عندما تم إصدار نسخة محسّنة من BERT لأول مرة في أغسطس تحت اسم RoBERTa ، لاحظ الباحث <a href="http://ruder.io/">سيباستيان</a> رودير من DeepMind بشكل جاف في رسالته <a href="http://newsletter.ruder.io/issues/nlp-in-industry-leaderboard-madness-fast-ai-nlp-transfer-learning-tools-186245">الإخبارية</a> الشهيرة في <a href="http://newsletter.ruder.io/issues/nlp-in-industry-leaderboard-madness-fast-ai-nlp-transfer-learning-tools-186245">البرمجة اللغوية العصبية NLP</a> : "شهر جديد ، ونموذج لغة متقدم جديد مع تدريب مسبق." <br><br>  مثل الكعكة ، لدى BERT العديد من قرارات التصميم التي تؤثر على جودة عملها.  يتضمن ذلك حجم الشبكة العصبية المخبوزة ، وكمية البيانات المستخدمة في التدريب المسبق ، وطريقة إخفاء الكلمات ، ومدة عمل الشبكة العصبية مع هذه البيانات.  وفي الوصفات اللاحقة ، مثل RoBERTa ، قام الباحثون بتعديل هذه القرارات - مثل الطاهي الذي يحدد الوصفة. <br><br>  في حالة RoBERTa ، قام باحثون من Facebook وجامعة واشنطن بزيادة عدد بعض المكونات (بيانات ما قبل التدريب ، طول التسلسلات الواردة ، وقت التدريب) ، تم حذف عنصر واحد (مهمة "توقع الجملة التالية" ، والتي كانت في الأصل في BERT وأثرت سلبًا على النتائج ) ، والآخر تم تغييره (تعقيد مهمة إخفاء الكلمات الفردية).  نتيجة لذلك ، احتلوا المركز الأول في تصنيف GLUE لفترة وجيزة.  بعد ستة أسابيع ، <a href="https://arxiv.org/abs/1909.11764">أضاف</a> باحثون من Microsoft وجامعة ماريلاند تحسيناتهم إلى RoBERTa ، وسحبوا النصر التالي.  في الوقت الحالي ، احتل نموذج آخر المرتبة الأولى في GLUE ، وهو ALBERT (اختصار لـ "lert BERT" ، أي "LERT BERT") ، والذي غير هيكله الأساسي قليلاً من BERT. <br><br>  وقال أوت من فيسبوك ، الذي عمل على RoBERTa: "ما زلنا نحدد أي وصفات تعمل ، وأيها لا تعمل". <br><br>  ولكن نظرًا لأن تحسين تقنية الكعك قبل الخبز لا يعلمك أساسيات الكيمياء ، فإن التحسين التدريجي لـ BERT لن يمنحك الكثير من المعرفة النظرية حول تطوير البرمجة اللغوية العصبية.  وقال لينسين ، وهو عالم لغوي محوسب في جامعة جونز هوبكنز: "سأكون صادقًا تمامًا معك - لا أتابع هذه الأعمال ، بالنسبة لي ، فهي مملة للغاية".  "هناك لغز علمي معين هنا" ، كما يعترف ، ولكن ليس كيفية جعل بيرت وجميع نسله أكثر ذكاءً ، ولا حتى لمعرفة سبب كونهم أذكياء للغاية.  وقال "بدلاً من ذلك ،" نحاول فهم مدى فهم هذه النماذج للغة ، بدلاً من تعلم الحيل الغريبة التي تعمل بطريقة أو بأخرى على مجموعات البيانات التي عادةً ما نقيم عليها هذه النماذج ". <br><br>  بمعنى آخر ، بيرت يفعل شيئًا صحيحًا.  ولكن ماذا لو فعل ذلك لسبب خاطئ؟ <br><br><h2 style=";text-align:right;direction:rtl">  صعبة ولكن ليست ذكية </h2><br>  في يوليو 2019 ، استخدم باحثان من جامعة ولاية تايوان ، تشنغ كون ، بيرت بنتائج رائعة في اختبار أداء غير معروف نسبيًا يسمى "مهمة فهم الحجة".  لإكمال المهمة ، من الضروري اختيار شرط أولي ضمني ("الأساس") يدعم الوسيطة لصالح أي بيان.  على سبيل المثال ، لإثبات أن "التدخين يسبب السرطان" (بيان) نظرًا لأن "الدراسات العلمية أظهرت وجود صلة بين التدخين والسرطان" (حجة) ، يجب على المرء أن يختار الوسيطة "البحث العلمي يمكن الوثوق به" ("الأساس") ، وليس خيارًا آخر: "البحث العلمي باهظ الثمن" (ومع ذلك ، فإن هذا غير مناسب في هذا السياق).  هل كل شيء واضح؟ <br><br>  إن لم يكن كل شيء ، لا تقلق.  حتى الناس ليسوا جيدين في هذه المهمة دون ممارسة.  متوسط ​​خط الأساس للشخص الذي لا يمارس التمرين هو 80 من أصل 100. وصل BERT إلى 77 - والتي قال المؤلفون إنها "غير متوقعة". <br><br>   ,  ,  BERT        ,  ,      : BERT      .  ,    ,       .. « ».  ,     ,   «»,       61% .      ,  ,   BERT   77  53 –     .       The Gradient     , <a href="https://thegradient.pub/nlps-clever-hans-moment-has-arrived/"></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بيرت مع هانز الذكية ، حصان يفترض قوي في الحساب. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">في مقال آخر ، " </font></font><a href="https://www.aclweb.org/anthology/P19-1334"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">حقوق لأسباب</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> خاطئة" ، نشر Linsen et al أدلة على أن نتائج BERT العالية في بعض اختبارات الغراء يمكن أن تُعزى أيضًا إلى وجود أدلة خاطئة في بيانات التدريب. تم تطوير مجموعة بديلة من البيانات التي تم تصميمها لحرمان بيرت من القدرة على العمل بهذه الطريقة. كانت مجموعة البيانات تسمى هانز (التحليل الاستدلالي لأنظمة الاستدلال اللغوي الطبيعي ، HANS) [التحليل الاستدلالي للأنظمة التي تستخلص النتائج بناءً على اللغة الطبيعية].</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">لذلك ، هل بيرت وجميع أقاربه اقتحام الجداول درجة عالية مجرد خدعة؟ يتفق بومان مع لينسن في أن بعض بيانات الغراء تكون قذرة. تمتلئ بالتشوهات المعرفية الكامنة في الأشخاص الذين قاموا بإنشائها ، ويمكن استغلال ذلك من خلال شبكة قوية قائمة على BERT. وقال بومان: "لا توجد خدعة عالمية من شأنها أن تحل جميع المشاكل في الغراء ، ولكن هناك العديد من الفرص" لتقليص الزوايا "التي تساعد ، ويمكن أن يجدها النموذج". لكنه لا يعتقد أن بيرت يعتمد على أي شيء ذي قيمة. وقال "يبدو أن لدينا نموذجًا تعلم شيئًا مثيرًا للاهتمام حول اللغة". "ومع ذلك ، فهي بالتأكيد لا تفهم اللغة الإنسانية بشكل عام."</font></font><br><br>    ,         ,           –       BERT,       ,    ,        « ».       « »,        NLP   ,          .     « BERT   »,  ,  «     ». <br><br>      NLP ,                   .    , BERT        .     «   NLP,        », —  <a href="https://www.cs.uml.edu/~arogers/"> </a> ,         . ,     ,          ,            ,     ,   . <br><br>  ,    ,      ,      .         .    ,    . «    ,       ,       ,           », —  . <br><br>         <a href="https://super.gluebenchmark.com/leaderboard">SuperGLUE</a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">مصممة خصيصا لتكون معقدة للأنظمة بيرت. حتى الآن ، لم تتمكن أي شبكة من تجاوز شخص ما فيها. ولكن حتى لو حدث هذا (أو متى) ، فهل هذا يعني أن الآلات يمكن أن تتعلم فهم اللغة بشكل أفضل من ذي قبل؟ أم أن العلم سيصبح أفضل في تدريس الآلات كيفية اجتياز هذا الاختبار؟</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"تشبيه جيد ،" قال بومان. </font><font style="vertical-align: inherit;">"لقد اكتشفنا كيفية اجتياز اختبارات LSAT و MCAT ، لكن قد لا تكون لدينا مؤهلات لأن نصبح أطباء أو محامين." </font><font style="vertical-align: inherit;">ومع ذلك ، بناءً على كل شيء ، هذه هي بالضبط الطريقة التي يتحرك بها البحث في مجال الذكاء الاصطناعى. </font><font style="vertical-align: inherit;">وقال "لقد بدا الشطرنج بمثابة اختبار جاد للذكاء حتى اكتشفنا كيفية كتابة برنامج للعبة". </font><font style="vertical-align: inherit;">"لقد دخلنا بالتأكيد عصرًا كان الهدف فيه هو ابتكار مهام معقدة بشكل متزايد تمثل فهمًا للغة والتوصل إلى طرق لحلها."</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar479446/">https://habr.com/ru/post/ar479446/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar479428/index.html">الأحداث الرقمية في موسكو من 9 إلى 15 ديسمبر</a></li>
<li><a href="../ar479430/index.html">الأحداث الرقمية في سان بطرسبرج من 9 إلى 15 ديسمبر</a></li>
<li><a href="../ar479432/index.html">Yandex.Maps: ذهبت إلى وحدة التحكم بالبطاقة - حصلت على الفور على وضع المستخدم (حسنًا ، الآن على محمل الجد)</a></li>
<li><a href="../ar479438/index.html">Postgres-Tuesday # 5: "PostgreSQL and Kubernetes. CI / CD. أتمتة الاختبار »</a></li>
<li><a href="../ar479442/index.html">أليكسي ساففاتيف: نموذج نظري للعبة في الانقسام الاجتماعي (+ مسح nginx)</a></li>
<li><a href="../ar479450/index.html">AppCode 2019.3: يعمل بشكل أسرع ، يفهم Swift بشكل أفضل ، يعرف حول Mac Catalyst ، يعرض رسائل التجميع بشكل ملائم</a></li>
<li><a href="../ar479452/index.html">كيف تم تطوير نظام اسم المجال: عصر ARPANET</a></li>
<li><a href="../ar479458/index.html">الجمال أو التطبيق العملي في غرفة الخادم</a></li>
<li><a href="../ar479460/index.html">دليل للسيارات الطائرة</a></li>
<li><a href="../ar479462/index.html">التسلسل في C ++</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßñüèæ üôÖ üï† Das neuronale AttnGAN-Netzwerk zeichnet Objekte in Teilen, wobei der Vektorraum nicht nur von S√§tzen, sondern auch von W√∂rtern verwendet wird ü§¥üèº üîª üí©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="AttnGAN-Betriebsbeispiel. In der oberen Reihe befinden sich mehrere Bilder mit unterschiedlichen Aufl√∂sungen, die von einem neuronalen Netzwerk erzeug...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das neuronale AttnGAN-Netzwerk zeichnet Objekte in Teilen, wobei der Vektorraum nicht nur von S√§tzen, sondern auch von W√∂rtern verwendet wird</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/409747/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/lk/gs/w1/lkgsw1oaf838l4x7vrtlww4dcam.jpeg"></div><br>  <i><font color="gray">AttnGAN-Betriebsbeispiel.</font></i>  <i><font color="gray">In der oberen Reihe befinden sich mehrere Bilder mit unterschiedlichen Aufl√∂sungen, die von einem neuronalen Netzwerk erzeugt werden.</font></i>  <i><font color="gray">Die zweite und dritte Zeile zeigen die Verarbeitung der f√ºnf am besten geeigneten W√∂rter durch zwei Modelle der Aufmerksamkeit des neuronalen Netzwerks, um die relevantesten Abschnitte zu zeichnen</font></i> <br><br>  Das automatische Erstellen von Bildern aus Textbeschreibungen in einer nat√ºrlichen Sprache ist ein grundlegendes Problem f√ºr viele Anwendungen, z. B. Kunstgenerierung und Computerdesign.  Dieses Problem stimuliert auch den Fortschritt im Bereich des multimodalen KI-Trainings mit einer Beziehung zwischen Vision und Sprache. <br><br>  Neuere Forschungen von Forschern auf diesem Gebiet basieren auf generativen kontradiktorischen Netzwerken (GANs).  Der allgemeine Ansatz besteht darin, die gesamte Textbeschreibung in den globalen Satzvektor zu √ºbersetzen.  Dieser Ansatz zeigt eine Reihe beeindruckender Ergebnisse, hat jedoch die Hauptnachteile: das Fehlen klarer Details auf Wortebene und die Unf√§higkeit, hochaufl√∂sende Bilder zu erzeugen.  Ein Entwicklerteam der Lichai University, der Rutgers University, der Duke University (alle USA) und von Microsoft schlug eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eigene</a> L√∂sung f√ºr das Problem vor: Das neue neuronale Netzwerk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Attentional Generative Adversarial Network (AttnGAN)</a> stellt eine Verbesserung des traditionellen Ansatzes dar und erm√∂glicht eine mehrstufige √Ñnderung des generierten Bildes, wobei einzelne W√∂rter im Text ge√§ndert werden Beschreibung. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/2j/dv/5i/2jdv5ilcqwd6s4v5ymkjov4eq1i.png"><br><br>  <i><font color="gray">AttnGAN neuronale Netzwerkarchitektur.</font></i>  <i><font color="gray">Jedes Aufmerksamkeitsmodell empf√§ngt automatisch Bedingungen (d. H. Entsprechende Vokabularvektoren) zum Erzeugen verschiedener Bereiche des Bildes.</font></i>  <i><font color="gray">Das DAMSM-Modul bietet zus√§tzliche Granularit√§t f√ºr die Konformit√§tsverlustfunktion bei der √úbersetzung von Bild zu Text im generativen Netzwerk</font></i> <br><br>  Wie Sie in der Abbildung sehen k√∂nnen, die die Architektur des neuronalen Netzwerks darstellt, weist das AttnGAN-Modell im Vergleich zu herk√∂mmlichen Ans√§tzen zwei Neuerungen auf. <br><br>  Erstens handelt es sich um ein kontradiktorisches Netzwerk, das die Aufmerksamkeit als Lernfaktor bezeichnet (Attentional Generative Adversarial Network).  Das hei√üt, es implementiert den Aufmerksamkeitsmechanismus, der die W√∂rter bestimmt, die am besten zum Erzeugen der entsprechenden Teile des Bildes geeignet sind.  Mit anderen Worten, zus√§tzlich zur Codierung der gesamten Textbeschreibung im globalen Vektorraum von S√§tzen wird jedes einzelne Wort auch als Textvektor codiert.  In der ersten Stufe verwendet das generative neuronale Netzwerk den globalen Vektorraum von S√§tzen, um ein Bild mit niedriger Aufl√∂sung zu rendern.  In den folgenden Schritten verwendet sie den Bildvektor in jeder Region, um W√∂rterbuchvektoren abzufragen, wobei die Aufmerksamkeitsebene verwendet wird, um den Wortkontextvektor zu bilden.  Dann wird der regionale Bildvektor mit dem entsprechenden Wortkontextvektor kombiniert, um einen multimodalen Kontextvektor zu bilden, auf dessen Grundlage das Modell neue Bildmerkmale in den jeweiligen Regionen erzeugt.  Auf diese Weise k√∂nnen Sie die Aufl√∂sung des gesamten Bilds effektiv erh√∂hen, da in jeder Phase mehr und mehr Details vorhanden sind. <br><br>  Die zweite Innovation von Microsoft f√ºr neuronale Netze ist das DAMSM-Modul (Deep Attentional Multimodal Similarity Model).  Unter Verwendung des Aufmerksamkeitsmechanismus berechnet dieses Modul den √Ñhnlichkeitsgrad zwischen dem erzeugten Bild und dem Textsatz, wobei sowohl Informationen aus der Ebene des Vektorraums von S√§tzen als auch eine detaillierte Ebene von W√∂rterbuchvektoren verwendet werden.  Somit bietet DAMSM eine zus√§tzliche Granularit√§t f√ºr den Verlust der Anpassungsfunktion bei der √úbersetzung von Bild zu Text beim Training des Generators. <br><br>  Dank dieser beiden Innovationen zeigt das neuronale AttnGAN-Netzwerk deutlich bessere Ergebnisse als die besten herk√∂mmlichen GAN-Systeme, schreiben Entwickler.  Insbesondere wurde der maximale bekannte Anfangswert f√ºr vorhandene neuronale Netze im CUB-Datensatz um 14,14% (von 3,82 auf 4,36) und um bis zu 170,25% (von 9,58 auf 25,89) verbessert. auf dem anspruchsvolleren COCO-Datensatz. <br><br>  Die Bedeutung dieser Entwicklung ist schwer zu √ºbersch√§tzen.  Das neuronale AttnGAN-Netzwerk zeigte zum ersten Mal, dass ein mehrschichtiges generativ-kontradiktorisches Netzwerk, das die Aufmerksamkeit als Lernfaktor bezeichnet, automatisch Bedingungen auf Wortebene f√ºr die Erzeugung einzelner Teile eines Bildes bestimmen kann. <br><br>  Der wissenschaftliche Artikel wurde am 28. November 2017 auf der Preprint-Site arXiv.org (arXiv: 1711.10485v1) ver√∂ffentlicht. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de409747/">https://habr.com/ru/post/de409747/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de409735/index.html">Konsens-Level-Illusion</a></li>
<li><a href="../de409739/index.html">Bloomberg: Telegram plant, w√§hrend des ICO mehr als 1 Milliarde US-Dollar zu gewinnen</a></li>
<li><a href="../de409741/index.html">Das Wei√üe Haus ist daran interessiert, Falcon Heavy auf den Markt zu bringen</a></li>
<li><a href="../de409743/index.html">DIY-Controller des LED-Panels auf CPLD mit BAM-Modulation</a></li>
<li><a href="../de409745/index.html">Der KI-Spezialist behauptet, er habe verstanden, in welcher Sprache das Voynich-Manuskript geschrieben ist</a></li>
<li><a href="../de409749/index.html">Pyrolysekessel zu Hause oder wenn der Gaspreis keine Rolle spielt</a></li>
<li><a href="../de409751/index.html">AudioFilkina Brief: Blue Tooth Musik - nicht f√ºr Hype, sondern zum Guten</a></li>
<li><a href="../de409753/index.html">Die Vereinten Nationen k√∂nnen gro√ü angelegte zuf√§llige Experimente durchf√ºhren, um die globale Erw√§rmung zu verringern</a></li>
<li><a href="../de409757/index.html">Die wissenschaftliche Analyse der Bitcoin- und Ethereum-Infrastruktur zeigt eine st√§rkere Zentralisierung der Netzwerke</a></li>
<li><a href="../de409759/index.html">Intel warnte chinesische Lieferanten vor Meltdown- und Spectre-Sicherheitsl√ºcken vor der US-Regierung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìé üëÉüèº üñãÔ∏è Implemente aplicaciones con Docker Swarm ü§Ωüèø üé∑ üôéüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El sistema de recomendaci√≥n de contenido de video en l√≠nea en el que estamos trabajando es un desarrollo comercial cerrado y t√©cnicamente es un cl√∫ste...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Implemente aplicaciones con Docker Swarm</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471528/">  El sistema de recomendaci√≥n de contenido de video en l√≠nea en el que estamos trabajando es un desarrollo comercial cerrado y t√©cnicamente es un cl√∫ster de componentes m√∫ltiples con componentes propios y de c√≥digo abierto.  El prop√≥sito de este art√≠culo es describir la introducci√≥n de un sistema de agrupaci√≥n de enjambres de Docker para una plataforma de ensayo, sin interrumpir el flujo de trabajo existente de nuestros procesos en un tiempo limitado.  La narrativa presentada a su atenci√≥n se divide en dos partes.  La primera parte describe el CI / CD antes de usar Docker Swarm, y la segunda describe el proceso de implementaci√≥n.  Aquellos que no est√©n interesados ‚Äã‚Äãen leer la primera parte pueden pasar de manera segura a la segunda. <br><a name="habracut"></a><br><h3>  Parte 1 </h3><br>  En el a√±o distante, distante, se requer√≠a configurar el proceso de CI / CD lo m√°s r√°pido posible.  Una de las condiciones era no usar Docker <i>para implementar los</i> componentes desarrollados por varias razones: <br><br><ul><li>  para una operaci√≥n m√°s confiable y estable de los componentes en Producci√≥n (es decir, el requisito de no usar la virtualizaci√≥n) </li><li>  Los principales desarrolladores no quer√≠an trabajar con Docker (extra√±o, pero era solo eso) </li><li>  por razones ideol√≥gicas gesti√≥n de I + D </li></ul><br>  La infraestructura, la pila y los requisitos iniciales de muestra para MVP fueron los siguientes: <br><br><ul><li>  4 servidores Intel¬Æ X5650 con Debian (una m√°quina m√°s poderosa completamente para desarrollo) </li><li>  El desarrollo de componentes personalizados se lleva a cabo en C ++, Python3 </li><li>  Las principales herramientas utilizadas por terceros: Kafka, Clickhouse, Airflow, Redis, Grafana, Postgresql, Mysql, ... </li><li>  Montaje de tuber√≠as y prueba de componentes por separado para depuraci√≥n y liberaci√≥n </li></ul><br>  Uno de los primeros problemas a resolver en la etapa inicial es c√≥mo implementar componentes personalizados en cualquier entorno (CI / CD). <br><br>  Los componentes de terceros decidieron instalar sist√©micamente y actualizarlos sist√©micamente.  Las aplicaciones personalizadas desarrolladas en C ++ o Python se pueden implementar de varias maneras.  Entre ellos, por ejemplo: crear paquetes de sistema, enviarlos al repositorio de im√°genes recopiladas y su posterior instalaci√≥n en servidores.  Por una raz√≥n desconocida, se eligi√≥ otro m√©todo, a saber, usar CI, se compilan los archivos de aplicaci√≥n ejecutables, se crea un entorno de proyecto virtual, se instalan m√≥dulos py de require.txt y todos estos artefactos se env√≠an junto con las configuraciones, los scripts y el entorno de aplicaci√≥n que acompa√±a a los servidores.  A continuaci√≥n, las aplicaciones se inician desde un usuario virtual sin derechos de administrador. <br><br>  Gitlab-CI fue elegido como el sistema CI / CD.  La tuber√≠a resultante se parec√≠a a esto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/460/406/c27/460406c27d873dc28928ac3ba901f903.png" alt="imagen"><br><div class="spoiler">  <b class="spoiler_title">Estructuralmente, gitlab-ci.yml se ve√≠a as√≠</b> <div class="spoiler_text"><pre><code class="xml hljs">--- variables: #     ,    CMAKE_CPUTYPE: "westmere" DEBIAN: "MYREGISTRY:5000/debian:latest" before_script: - eval $(ssh-agent -s) - ssh-add <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">(echo</span></span></span><span class="hljs-tag"> "$</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">SSH_PRIVATE_KEY</span></span></span><span class="hljs-tag">") </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">mkdir</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-p</span></span></span><span class="hljs-tag"> ~/</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">.ssh</span></span></span><span class="hljs-tag"> &amp;&amp; </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">echo</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-e</span></span></span><span class="hljs-tag"> "</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Host</span></span></span><span class="hljs-tag"> *\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">tStrictHostKeyChecking</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">no</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">" &gt;</span></span> ~/.ssh/config stages: - build - testing - deploy debug.debian: stage: build image: $DEBIAN script: - cd builds/release &amp;&amp; ./build.sh paths: - bin/ - builds/release/bin/ when: always release.debian: stage: build image: $DEBIAN script: - cd builds/release &amp;&amp; ./build.sh paths: - bin/ - builds/release/bin/ when: always ## testing stage tests.codestyle: stage: testing image: $DEBIAN dependencies: - release.debian script: - /bin/bash run_tests.sh -t codestyle -b "${CI_COMMIT_REF_NAME}_codestyle" tests.debug.debian: stage: testing image: $DEBIAN dependencies: - debug.debian script: - /bin/bash run_tests.sh -e codestyle/test_pylint.py -b "${CI_COMMIT_REF_NAME}_debian_debug" artifacts: paths: - run_tests/username/ when: always expire_in: 1 week tests.release.debian: stage: testing image: $DEBIAN dependencies: - release.debian script: - /bin/bash run_tests.sh -e codestyle/test_pylint.py -b "${CI_COMMIT_REF_NAME}_debian_release" artifacts: paths: - run_tests/username/ when: always expire_in: 1 week ## staging stage deploy_staging: stage: deploy environment: staging image: $DEBIAN dependencies: - release.debian script: - cd scripts/deploy/ &amp;&amp; python3 createconfig.py -s $CI_ENVIRONMENT_NAME &amp;&amp; /bin/bash install_venv.sh -d -r ../../requirements.txt &amp;&amp; python3 prepare_init.d.py &amp;&amp; python3 deploy.py -s $CI_ENVIRONMENT_NAME when: manual</code> </pre> <br></div></div><br>  Vale la pena se√±alar que el montaje y las pruebas se realizan en su propia imagen, donde todos los paquetes necesarios del sistema ya est√°n instalados y se realizan otras configuraciones. <br><br>  Aunque cada uno de estos scripts en el trabajo es interesante a su manera, <s>ciertamente no hablar√© sobre ellos</s> , pero la descripci√≥n de cada uno de ellos tomar√° un tiempo considerable y este no es el prop√≥sito del art√≠culo.  Solo prestar√© atenci√≥n al hecho de que la etapa de implementaci√≥n consiste en una secuencia de llamadas de script: <br><br><ol><li>  <b>createconfig.py</b> : crea el archivo settings.ini con la configuraci√≥n de los componentes en un entorno diferente para la implementaci√≥n posterior (Preproducci√≥n, Producci√≥n, Pruebas, ...) </li><li>  <b>install_venv.sh</b> : crea un entorno virtual para componentes py en un directorio espec√≠fico y lo copia en servidores remotos </li><li>  <b>prepare_init.d.py</b> : prepara scripts de inicio y detenci√≥n de componentes basados ‚Äã‚Äãen una plantilla </li><li>  <b>deploy.py</b> : <b>descomprime</b> y reinicia nuevos componentes </li></ol><br>  El tiempo paso  La etapa de puesta en escena ha sido reemplazada por preproducci√≥n y producci√≥n.  El soporte del producto se agreg√≥ en otro kit de distribuci√≥n (CentOS).  Se agregaron 5 servidores f√≠sicos m√°s potentes y una docena de servidores virtuales.  Y se hizo cada vez m√°s dif√≠cil para los desarrolladores y evaluadores ejecutar sus tareas en un entorno m√°s o menos cercano al estado de trabajo.  En este momento, qued√≥ claro que es imposible prescindir de √©l ... <br><br><h3>  Parte II </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/673/166/f0e67316667fed0c0d673653419e8b8a.png" alt="imagen"><br><br>  Por lo tanto, nuestro cl√∫ster sigue <s>siendo un espect√°culo de un</s> sistema de un par de docenas de componentes separados que no est√°n descritos por Dockerfiles.  Puede configurarlo para la implementaci√≥n en un entorno espec√≠fico solo como un todo.  Nuestra tarea es implementar el cl√∫ster en un entorno provisional para ejecutarlo antes de las pruebas previas al lanzamiento. <br><br>  Te√≥ricamente, puede haber varios grupos de trabajo simult√°neos: tantas como tareas est√°n en el estado completado o cerca de completarse.  Las capacidades disponibles para nuestros servidores nos permiten ejecutar varios cl√∫steres en cada servidor.  Cada grupo de etapas debe estar aislado (no debe haber intersecci√≥n en puertos, directorios, etc.). <br><br>  El recurso m√°s valioso es nuestro tiempo, y no ten√≠amos mucho. <br><br>  Para un comienzo m√°s r√°pido, eligieron Docker Swarm debido a su simplicidad y flexibilidad de arquitectura.  Lo primero que hicimos fue crear en los servidores del administrador remoto y varios nodos: <br><br><pre> <code class="bash hljs">$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION kilqc94pi2upzvabttikrfr5d nop-test-1 Ready Active 19.03.2 jilwe56pl2zvabupryuosdj78 nop-test-2 Ready Active 19.03.2 j5a4yz1kr2xke6b1ohoqlnbq5 * nop-test-3 Ready Active Leader 19.03.2</code> </pre><br>  A continuaci√≥n, creamos una red: <br><br><pre> <code class="bash hljs">$ docker network create --driver overlay --subnet 10.10.10.0/24 nw_swarm</code> </pre><br>  Luego, conectaron los nodos Gitlab-CI y Swarm en t√©rminos de gesti√≥n remota de nodos CI: instalaci√≥n de certificados, configuraci√≥n de variables secretas y configuraci√≥n del servicio Docker en el servidor de gesti√≥n.  Este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> nos ahorr√≥ mucho tiempo. <br><br>  Luego, agregamos trabajos para crear y destruir la pila en .gitlab-ci .yml. <br><br><div class="spoiler">  <b class="spoiler_title">Se agregaron algunos trabajos m√°s a .gitlab-ci .yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">## staging stage deploy_staging: stage: testing before_script: - echo "override global 'before_script'" image: "REGISTRY:5000/docker:latest" environment: staging dependencies: [] variables: DOCKER_CERT_PATH: "/certs" DOCKER_HOST: tcp://10.50.173.107:2376 DOCKER_TLS_VERIFY: 1 CI_BIN_DEPENDENCIES_JOB: "release.centos.7" script: - mkdir -p $DOCKER_CERT_PATH - echo "$TLSCACERT" &gt; $DOCKER_CERT_PATH/ca.pem - echo "$TLSCERT" &gt; $DOCKER_CERT_PATH/cert.pem - echo "$TLSKEY" &gt; $DOCKER_CERT_PATH/key.pem - docker stack deploy -c docker-compose.yml ${CI_ENVIRONMENT_NAME}_${CI_COMMIT_REF_NAME} --with-registry-auth - rm -rf $DOCKER_CERT_PATH when: manual ## stop staging stage stop_staging: stage: testing before_script: - echo "override global 'before_script'" image: "REGISTRY:5000/docker:latest" environment: staging dependencies: [] variables: DOCKER_CERT_PATH: "/certs" DOCKER_HOST: tcp://10.50.173.107:2376 DOCKER_TLS_VERIFY: 1 script: - mkdir -p $DOCKER_CERT_PATH - echo "$TLSCACERT" &gt; $DOCKER_CERT_PATH/ca.pem - echo "$TLSCERT" &gt; $DOCKER_CERT_PATH/cert.pem - echo "$TLSKEY" &gt; $DOCKER_CERT_PATH/key.pem - docker stack rm ${CI_ENVIRONMENT_NAME}_${CI_COMMIT_REF_NAME} # TODO: need check that stopped when: manual</code> </pre><br></div></div><br>  Del fragmento de c√≥digo anterior, est√° claro que se han agregado dos botones (deploy_staging, stop_staging) a las canalizaciones que requieren intervenci√≥n manual. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2de/e3c/790/2dee3c7907f75f793499665d8a60de8a.png" alt="imagen"><br>  El nombre de la pila corresponde al nombre de la rama y esta singularidad deber√≠a ser suficiente.  Los servicios en la pila reciben direcciones IP √∫nicas y puertos, directorios, etc.  estar√° aislado, pero lo mismo de una pila a otra (porque el archivo de configuraci√≥n es el mismo para todas las pilas): esto es lo que logramos.  Implementamos <b>la pila</b> (cluster) usando <b>docker-compose.yml</b> , que describe nuestro cluster. <br><br><div class="spoiler">  <b class="spoiler_title">docker-compose.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">--- version: '3' services: userprop: image: redis:alpine deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: celery_bcd: image: redis:alpine deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: schedulerdb: image: mariadb:latest environment: MYSQL_ALLOW_EMPTY_PASSWORD: 'yes' MYSQL_DATABASE: schedulerdb MYSQL_USER: **** MYSQL_PASSWORD: **** command: ['--character-set-server=utf8mb4', '--collation-server=utf8mb4_unicode_ci', '--explicit_defaults_for_timestamp=1'] deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: celerydb: image: mariadb:latest environment: MYSQL_ALLOW_EMPTY_PASSWORD: 'yes' MYSQL_DATABASE: celerydb MYSQL_USER: **** MYSQL_PASSWORD: **** deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: cluster: image: $CENTOS7 environment: - CENTOS - CI_ENVIRONMENT_NAME - CI_API_V4_URL - CI_REPOSITORY_URL - CI_PROJECT_ID - CI_PROJECT_URL - CI_PROJECT_PATH - CI_PROJECT_NAME - CI_COMMIT_REF_NAME - CI_BIN_DEPENDENCIES_JOB command: &gt; sudo -u myusername -H /bin/bash -c ". /etc/profile &amp;&amp; mkdir -p /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME &amp;&amp; cd /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME &amp;&amp; git clone -b $CI_COMMIT_REF_NAME $CI_REPOSITORY_URL . &amp;&amp; curl $CI_API_V4_URL/projects/$CI_PROJECT_ID/jobs/artifacts/$CI_COMMIT_REF_NAME/download?job=$CI_BIN_DEPENDENCIES_JOB -o artifacts.zip &amp;&amp; unzip artifacts.zip ; cd /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME/scripts/deploy/ &amp;&amp; python3 createconfig.py -s $CI_ENVIRONMENT_NAME &amp;&amp; /bin/bash install_venv.sh -d -r ../../requirements.txt &amp;&amp; python3 prepare_init.d.py &amp;&amp; python3 deploy.py -s $CI_ENVIRONMENT_NAME" deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none tty: true stdin_open: true networks: nw_swarm: networks: nw_swarm: external: true</code> </pre><br></div></div><br>  Aqu√≠ puede ver que los componentes est√°n conectados por una red (nw_swarm) y son accesibles entre s√≠. <br><br>  Los componentes del sistema (basados ‚Äã‚Äãen redis, mysql) est√°n separados del grupo com√∫n de componentes personalizados (los planes y los personalizados se dividen como servicios).  La etapa de implementaci√≥n de nuestro cl√∫ster se parece a la transferencia de CMD a nuestra imagen configurada de gran tama√±o, y en su conjunto pr√°cticamente no difiere de la implementaci√≥n descrita en la Parte I. Destaco las diferencias: <br><br><ul><li>  <b>git clone ...</b> - obtenemos los archivos necesarios para realizar una implementaci√≥n (createconfig.py, install_venv.sh, etc.) </li><li>  <b>curl ... &amp;&amp; unzip ...</b> - descargar y descomprimir artefactos de ensamblaje (utilidades compiladas) </li></ul><br>  Solo hay un problema que a√∫n no se ha descrito: los navegadores de desarrollador no pueden acceder a los componentes que tienen una interfaz web.  Resolvemos este problema usando proxy inverso, por lo tanto: <br><br>  En .gitlab-ci.yml, despu√©s de implementar la pila del cl√∫ster, agregue la l√≠nea de implementaci√≥n del equilibrador (que, al confirmar, solo actualiza su configuraci√≥n (crea nuevos archivos de configuraci√≥n nginx usando la plantilla: /etc/nginx/conf.d/${CI_COMMIT_REF_NAME‚ñ∫.conf) - ver c√≥digo docker-compose-nginx.yml) <br><br><pre> <code class="xml hljs"> - docker stack deploy -c docker-compose-nginx.yml ${CI_ENVIRONMENT_NAME} --with-registry-auth</code> </pre><br><div class="spoiler">  <b class="spoiler_title">docker-compose-nginx.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">--- version: '3' services: nginx: image: nginx:latest environment: CI_COMMIT_REF_NAME: ${CI_COMMIT_REF_NAME} NGINX_CONFIG: |- server { listen 8080; server_name staging_${CI_COMMIT_REF_NAME}_cluster.dev; location / { proxy_pass http://staging_${CI_COMMIT_REF_NAME}_cluster:8080; } } server { listen 5555; server_name staging_${CI_COMMIT_REF_NAME}_cluster.dev; location / { proxy_pass http://staging_${CI_COMMIT_REF_NAME}_cluster:5555; } } volumes: - /tmp/staging/nginx:/etc/nginx/conf.d command: /bin/bash -c "echo -e \"$$NGINX_CONFIG\" &gt; /etc/nginx/conf.d/${CI_COMMIT_REF_NAME}.conf; nginx -g \"daemon off;\"; /etc/init.d/nginx reload" ports: - 8080:8080 - 5555:5555 - 3000:3000 - 443:443 - 80:80 deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: networks: nw_swarm: external: true</code> </pre><br></div></div><br>  En las computadoras de desarrollo, actualice / etc / hosts;  registrar url a nginx: <br><br> <code>10.50.173.106 staging_BRANCH-1831_cluster.dev <br></code> <br>  Por lo tanto, se implement√≥ el despliegue de cl√∫steres de etapas aisladas y los desarrolladores ahora pueden lanzarlos en <s>cualquier</s> cantidad suficiente para probar sus tareas. <br><br>  Planes adicionales: <br><br><ul><li>  Separar nuestros componentes como servicios. </li><li>  Hacer para cada Dockerfile </li><li>  Detecta autom√°ticamente nodos menos cargados en la pila </li><li>  Establecer nodos por patr√≥n de nombre (en lugar de usar id como en el art√≠culo) </li><li>  Agregar verificaci√≥n de que la pila est√° destruida </li><li>  ... </li></ul><br>  Un agradecimiento especial por el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/471528/">https://habr.com/ru/post/471528/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../471516/index.html">Intel 665p: SSD con QLC NAND de 96 capas</a></li>
<li><a href="../471518/index.html">Apple en 2019 es Linux en 2000</a></li>
<li><a href="../471520/index.html">El libro "Tareas de inform√°tica cl√°sica en Python"</a></li>
<li><a href="../471522/index.html">Askozia C√≥mo funciona Autoprovisioning Plug & Play</a></li>
<li><a href="../471524/index.html">Traducci√≥n completa de instrucciones para evaluadores Google</a></li>
<li><a href="../471530/index.html">GitLab recorri√≥ un camino inusual hacia CI / CD y Kubernetes</a></li>
<li><a href="../471532/index.html">Adi√≥s PCB; hola interconexi√≥n de silicio</a></li>
<li><a href="../471536/index.html">Predicci√≥n de inundaciones de Google: una mirada al interior</a></li>
<li><a href="../471538/index.html">Desde la idea de una aplicaci√≥n m√≥vil hasta el MVP en el que los inversores invertir√°n</a></li>
<li><a href="../471542/index.html">Reconocimiento de texto OCR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⛑️ 🚪 👨‍👨‍👦 Cara memastikan ketersediaan layanan web di cloud jika terjadi kegagalan pusat data 🚵🏼 🔨 💭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Artikel ini menjelaskan opsi untuk memastikan ketersediaan layanan web yang digunakan di cloud jika terjadi kegagalan fungsi di pusat data. Solusi yan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cara memastikan ketersediaan layanan web di cloud jika terjadi kegagalan pusat data</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440338/">  Artikel ini menjelaskan opsi untuk memastikan ketersediaan layanan web yang digunakan di cloud jika terjadi kegagalan fungsi di pusat data.  Solusi yang diusulkan didasarkan pada kompromi yang terdiri dari <i><b>duplikasi parsial</b></i> : sistem cadangan digunakan di pusat data lain, yang dapat beroperasi dalam mode fungsionalitas terbatas ketika pusat data utama tidak tersedia.  Skema ini terutama ditujukan untuk aplikasi kegagalan jangka pendek, tetapi juga menyediakan kemampuan untuk dengan cepat mengubah sistem cadangan menjadi sistem utama jika terjadi masalah skala besar. <br><br><img src="https://habrastorage.org/webt/hr/hj/5f/hrhj5fooksh9x_safy_rures5zu.png"><br><a name="habracut"></a><br><h2>  Deskripsi masalah </h2><br>  Tahun lalu, kami tersentuh oleh insiden di pusat data penyedia cloud terkenal - salah satu layanan kami tidak tersedia bagi pengguna selama setengah jam.  Kemudian kami melihat dengan mata kepala sendiri bahwa jika ada masalah di pusat data cloud, praktis tidak ada tuas untuk memulihkan kesehatan aplikasi, dan tidak ada yang tersisa bagi tim yang bertanggung jawab atas aplikasi tersebut kecuali memasang dan menunggu.  Pengalaman ini membuat kami serius berpikir tentang menggunakan cloud untuk produk kami. <br><br>  Apa yang sebenarnya terjadi hari itu tidak pernah diketahui.  Kita terbiasa memandang awan sebagai pos terdepan yang tidak bisa dihancurkan, tetapi tidak demikian halnya.  Yang benar adalah bahwa tidak ada jaminan seratus persen ketersediaan layanan di cloud, seperti di tempat lain mana pun.  Awan adalah abstraksi di balik semua rak yang sama dengan besi di pusat data dan faktor manusia disembunyikan.  Setiap perangkat keras cepat atau lambat gagal (meskipun kegagalan perangkat keras untuk pusat data lebih cenderung merupakan situasi biasa).  Selain itu, ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kasus</a> masalah yang lebih serius yang menyebabkan tidak dapat diaksesnya pusat data: kebakaran, serangan DDoS, bencana alam, gangguan listrik dan Internet, dll. <br><br>  Jika kita berbicara tentang faktor manusia, maka ini bukan penyebab kecelakaan terakhir: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"menurut statistik, di 80% dari kegagalan infrastruktur jaringan, orang yang harus disalahkan</a> . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"</a>  Orang, tidak peduli seberapa baik niat mereka dibimbing, tidak dapat diandalkan.  Bahkan Anda dan kolega Anda - orang yang secara langsung tertarik pada stabilitas produk yang didukung - mungkin telah melakukan kesalahan, belum lagi personel perusahaan orang lain, yang instans Anda tidak berbeda dari ribuan lainnya.  Apa pun tim profesional di balik infrastruktur, masalah baru adalah masalah waktu. <br><br>  Semuanya ada harganya.  Ketika Anda pindah ke cloud, Anda mendapatkan abstraksi sederhana, yang nyaman untuk bekerja dengan, ketergantungan yang lemah pada departemen operasi Anda dengan imbalan kontrol penuh atas situasi.  Dalam hal ini, jika Anda tidak menjaga diri sendiri sebelumnya, setelah meramalkan kemungkinan kesalahan orang lain, tidak ada yang akan melakukan ini. <br><br><h2>  Opsi solusi </h2><br>  Bagi kami, tidak tersedianya layanan, bahkan selama beberapa menit, sudah kritis.  Oleh karena itu, kami memutuskan untuk menemukan cara untuk memastikan diri terhadap masalah yang sama di masa depan, tanpa mengabaikan awan. <br><br>  Ketika mulai memecahkan masalah ketersediaan layanan di cloud, harus diingat bahwa aksesibilitas adalah konsep yang cukup luas dan, tergantung pada apa yang dimaksud olehnya, berbagai skenario ketentuannya dipertimbangkan.  Meskipun artikel ini hanya membahas masalah aksesibilitas sebagai akibat dari kegagalan pusat data, akan lebih tepat untuk mengatakan beberapa kata tentang solusi untuk masalah aksesibilitas lainnya. <br><br>  Ketersediaan sebagai peluang teknis untuk menyediakan akses ke sumber daya untuk waktu tertentu pada beban tertentu.  Masalah terjadi ketika layanan berjalan, tetapi karena sumber daya yang terbatas dan kerangka arsitektur sistem, tidak semua pengguna dapat mengaksesnya dalam waktu respons tertentu.  Tugas ini paling sering diselesaikan dengan menggunakan instance tambahan dengan aplikasi.  Dengan penskalaan ini, awan bekerja dengan baik. <br><br>  Aksesibilitas sebagai ketersediaan layanan web untuk pengguna dari wilayah tertentu.  Solusi yang jelas di sini adalah sharding.  Dengan kata lain, membagi sistem menjadi beberapa aplikasi independen di pusat data yang berbeda dengan datanya sendiri dan menempatkan setiap pengguna ke instance sistemnya, misalnya, berdasarkan geo-location-nya.  Saat beling, kegagalan satu pusat data dalam kasus terburuk akan mengakibatkan tidak tersedianya layanan hanya untuk sebagian pengguna yang terkait dengan pusat data ini.  Bukan argumen terakhir yang mendukung sharding - ini adalah waktu ping yang berbeda dengan pusat data di berbagai wilayah. <br><br>  Namun, seringkali pembatasan untuk bekerja dengan cloud dan perlunya desentralisasi adalah persyaratan legislatif yang biasanya diperhitungkan bahkan pada tahap desain sistem.  Persyaratan ini meliputi: Hukum Yarovaya - penyimpanan data pribadi (PD) pengguna di Rusia;  Peraturan Perlindungan Data Umum (GDPR) - pembatasan transfer lintas batas dari pengguna UE ke beberapa negara;  dan sensor internet Cina, di mana SEMUA komunikasi dan SEMUA bagian dari aplikasi harus ditempatkan di Cina dan, lebih disukai, di server mereka. <br><br>  Masalah tidak dapat diaksesnya teknis pusat data diselesaikan dengan menduplikasi layanan di pusat data lain.  Ini bukan tugas teknis yang mudah.  Hambatan utama untuk penyebaran layanan paralel di berbagai pusat data adalah database.  Biasanya, sistem kecil menggunakan arsitektur wizard tunggal.  Dalam hal ini, kegagalan pusat data dengan master membuat seluruh sistem tidak beroperasi.  Skema replikasi master replikasi dimungkinkan, tetapi memberlakukan batasan kuat yang tidak semua orang mengerti.  Bahkan, itu tidak skala catatan ke database, tetapi bahkan memberikan penalti waktu yang kecil, karena itu perlu untuk mengkonfirmasi semua node bahwa transaksi telah diterima.  Waktu operasi penulisan meningkat bahkan lebih ketika node harus ditempatkan di pusat data yang berbeda. <br><br><h2>  Pembenaran keputusan </h2><br>  Analisis beban pada layanan kami menunjukkan bahwa rata-rata sekitar 70% panggilan ke API dilakukan dengan metode GET.  Metode ini menggunakan database hanya baca. <br><br><img src="https://habrastorage.org/webt/g5/in/cy/g5incy6f1zpx1mpsv5ejbl04hqq.png" alt="Layanan panggilan distribusi metode HTTP Web"><br>  <i>Layanan panggilan distribusi metode HTTP Web</i> <br><br>  Saya pikir hasil ini mencerminkan keseluruhan gambaran layanan web yang tersedia secara umum.  Oleh karena itu, kita dapat mengatakan bahwa <i><u>dalam API layanan web rata-rata, metode membaca disebut lebih sering daripada metode menulis</u></i> . <br><br>  Pernyataan kedua yang ingin saya kemukakan adalah bahwa <i><u>jika kita berbicara tentang aksesibilitas absolut, maka pelanggan layanan benar-benar membutuhkan aksesibilitas seperti itu tidak hanya dari kekayaan metode API yang tersedia, tetapi hanya mereka yang diperlukan untuk melanjutkan pekerjaan "biasa" dengan sistem. dan melakukan kueri "normal"</u></i> .  Tidak ada yang akan marah jika metode yang diakses beberapa kali dalam sebulan tidak tersedia selama beberapa menit.  Seringkali, aliran "normal" ditutupi oleh metode membaca. <br><br>  <b>Oleh karena itu, memastikan ketersediaan absolut dari hanya metode membaca sudah dapat dianggap sebagai opsi yang memungkinkan untuk solusi jangka pendek untuk masalah ketersediaan sistem jika terjadi kegagalan pusat data.</b> <br><br><h2>  Apa yang ingin kita terapkan </h2><br>  Jika terjadi kegagalan di pusat data, kami ingin mengalihkan lalu lintas ke sistem cadangan di pusat data lain.  Dalam sistem cadangan, semua metode membaca harus tersedia, dan ketika memanggil metode yang tersisa, jika tidak mungkin dilakukan tanpa menulis ke database, kesalahan yang benar harus ditampilkan. <br><br>  Dalam operasi normal, permintaan pengguna dikirim ke penyeimbang, yang pada gilirannya mengarahkannya ke API utama.  Jika layanan utama tidak tersedia, penyeimbang menentukan fakta ini dan mengalihkan permintaan ke sistem cadangan yang beroperasi dalam mode fungsi terbatas.  Pada saat ini, tim menganalisis masalah dan memutuskan untuk menunggu pemulihan pusat data atau mengalihkan sistem cadangan ke mode utama. <br><br><img src="https://habrastorage.org/webt/om/cw/8n/omcw8n1zd8rehycoeiy0qdahemy.png"><br><br><h2>  Algoritma implementasi </h2><br><h4>  Perubahan infrastruktur yang diperlukan </h4><br><ol><li>  Membuat replikasi budak database di pusat data lain. </li><li>  Menyiapkan penyebaran layanan web, mengumpulkan log, metrik di pusat data kedua. </li><li>  Konfigurasi penyeimbang untuk mengalihkan lalu lintas ke pusat data cadangan jika yang pertama tidak tersedia. </li></ol><br><h4>  Perubahan Kode: </h4><br><ol><li>  Menambahkan koneksi terpisah ke replika di layanan web. </li><li>  Migrasikan semua rute API hanya-baca ke replika. </li><li>  Untuk metode yang tersisa, pengenalan mode hanya baca melalui variabel lingkungan atau pemicu lainnya, di mana mereka alih-alih menulis ke database, sebagian akan berhasil atau, jika fungsionalitasnya rusak tanpa menulis ke database, memberikan kesalahan yang benar. </li><li>  Perbaikan pada frontend untuk menampilkan kesalahan yang benar saat memanggil metode perekaman. </li></ol><br><h2>  Pro dan kontra dari solusi yang dijelaskan </h2><br><h4>  Manfaatnya </h4><br><ul><li>  Keuntungan utama dari skema yang diusulkan adalah bahwa selalu ada layanan duplikat, kapan saja siap melayani pengguna.  Jika terjadi masalah dengan pusat data utama, Anda tidak perlu menulis skrip penerapan pada beberapa infrastruktur lain dan menjalankan semuanya dengan tergesa-gesa. </li><li>  Solusinya murah untuk diimplementasikan dan dipelihara.  Jika Anda memiliki arsitektur layanan mikro dan produk tidak hanya membutuhkan satu tetapi banyak layanan, maka dalam hal ini seharusnya tidak ada masalah khusus dengan transfer semua layanan Microsoft ke skema ini. </li><li>  Tidak ada ancaman kehilangan data, karena selalu ada salinan lengkap dari database pada replika di pusat data lain. </li><li>  Solusinya terutama ditujukan untuk perpindahan lalu lintas sementara, hingga setengah jam.  Setengah jam inilah yang tidak cukup untuk bernavigasi jika ada masalah dengan infrastruktur.  Jika selama periode ini pusat data pertama tidak dipulihkan, replika budak dari database berubah menjadi master, dan layanan duplikat menjadi yang utama. </li><li>  Dalam skema yang diusulkan, aplikasi dan database berada di pusat data yang sama.  Jika Anda memiliki API dan database di pusat data yang berbeda, maka yang terbaik adalah mentransfernya ke satu: ini akan secara signifikan mengurangi waktu eksekusi kueri.  Sebagai contoh, pengukuran kami menunjukkan bahwa untuk Google Cloud, permintaan dari API ke basis data dalam satu pusat data rata-rata 6 ms, dan ketika pergi untuk data ke pusat data lain, waktunya meningkat puluhan milidetik. </li></ul><br><h4>  Kekurangan </h4><br><ul><li>  Kelemahan utama dari keseluruhan skema adalah bahwa untuk peralihan lalu lintas instan, diperlukan penyeimbang yang tidak terletak di pusat data yang sama dengan layanan utama.  Penyeimbang adalah titik kegagalan: jika pusat data dengan penyeimbang gagal, maka layanan Anda menjadi tidak tersedia dalam hal apa pun. </li><li>  Kebutuhan untuk menyebarkan kode ke server lain, memantau sumber daya tambahan - misalnya, memantau replika sehingga tidak ada jeda. </li></ul><br><h2>  Kesimpulan </h2><br>  Anda tidak dapat membuat sistem yang tahan terhadap semua jenis kegagalan.  Meskipun demikian, melindungi diri Anda dari tipe tertentu adalah tugas yang layak.  Solusi yang dijelaskan dalam artikel, yang memungkinkan untuk memastikan ketersediaan aplikasi jika terjadi kegagalan fungsi di pusat data, dapat menarik dan bermanfaat dalam aplikasi praktis dalam banyak kasus. <br><br>  Mengubah layanan web biasa menjadi sistem terdistribusi penuh untuk melindungi dari kegagalan hipotetis di pusat data kemungkinan besar tidak praktis.  Pada pandangan pertama, bahkan skema yang diusulkan tampak berlebihan dan “berat”, tetapi kerugian ini lebih dari tumpang tindih oleh kelebihan dan kemudahan implementasi.  Anda dapat menggambar analogi dengan asuransi kecelakaan: ada kemungkinan besar bahwa Anda tidak akan pernah membutuhkan asuransi semacam itu, tetapi jika kecelakaan terjadi, itu akan sangat disambut.  Dengan skema yang diusulkan, Anda akan yakin bahwa Anda selalu memiliki sistem cadangan yang siap, yang, untuk masalah jangka pendek, akan memastikan ketersediaan sebagian besar metode layanan, dan jika terjadi kegagalan yang lama, ia dapat sepenuhnya berubah menjadi yang utama dalam hitungan menit.  Banyak yang akan setuju untuk membayar harga ini untuk kepercayaan diri tersebut. <br><br>  Setiap sistem memiliki parameter beban dan aksesibilitas yang unik.  Itu sebabnya tidak ada jawaban benar atau salah untuk pertanyaan: "Bisakah Anda mempercayai Google Cloud atau AWS sepenuhnya?"  - dalam setiap situasi tertentu ia akan menjadi miliknya sendiri. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id440338/">https://habr.com/ru/post/id440338/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id440328/index.html">Probabilitas memenangkan pertandingan dengan probabilitas yang diketahui untuk memenangkan poin II</a></li>
<li><a href="../id440330/index.html">Secara singkat tentang abstraksi</a></li>
<li><a href="../id440332/index.html">Database di awan: kepada siapa dan mengapa - pendapat spesialis Data Egret</a></li>
<li><a href="../id440334/index.html">Buka webinar "Pengembangan sistem yang sangat dimuat dalam PHP"</a></li>
<li><a href="../id440336/index.html">HTML kami hilang</a></li>
<li><a href="../id440342/index.html">Kode C # Universal untuk NET dan JavaScript</a></li>
<li><a href="../id440344/index.html">InterNyet - bagaimana Internet ditemukan di Uni Soviet dan mengapa itu tidak berhasil</a></li>
<li><a href="../id440346/index.html">Pada akhir Februari, Microsoft akan memperkenalkan kacamata VR HoloLens 2</a></li>
<li><a href="../id440350/index.html">Flying Bear Tornado 2 - beruang baru telah tiba</a></li>
<li><a href="../id440352/index.html">Retas massal VKontakte [XSS-worm]</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
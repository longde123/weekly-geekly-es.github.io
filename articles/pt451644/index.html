<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöØ üë©üèº‚Äçüè≠ üëâüèª Implanta√ß√£o de aplicativos em VM, Nomad e Kubernetes üßí ü§Ωüèæ üíÉ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal! Meu nome √© Pavel Agaletsky. Eu trabalho como l√≠der de uma equipe que desenvolve um sistema de entrega Lamoda. Em 2018, falei na confer√™nc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Implanta√ß√£o de aplicativos em VM, Nomad e Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lamoda/blog/451644/">  Ol√° pessoal!  Meu nome √© Pavel Agaletsky.  Eu trabalho como l√≠der de uma equipe que desenvolve um sistema de entrega Lamoda.  Em 2018, falei na confer√™ncia HighLoad ++ e hoje quero apresentar uma transcri√ß√£o do meu relat√≥rio. <br><br>  Meu t√≥pico √© dedicado √† experi√™ncia de nossa empresa na implanta√ß√£o de sistemas e servi√ßos em diferentes ambientes.  A partir de nossos tempos pr√©-hist√≥ricos, quando implantamos todos os sistemas em servidores virtuais regulares, terminando com uma transi√ß√£o gradual do Nomad para uma implanta√ß√£o no Kubernetes.  Vou lhe dizer por que fizemos isso e quais problemas tivemos no processo. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/oqrb7dWECSo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  Implantar aplicativos na VM </h1><br>  Para come√ßar, h√° tr√™s anos, todos os sistemas e servi√ßos da empresa foram implantados em servidores virtuais comuns.  Tecnicamente, foi organizado de forma que todo o c√≥digo de nossos sistemas permanecesse e montado usando ferramentas de constru√ß√£o autom√°tica usando jenkins.  Com o Ansible, ele estava lan√ßando nosso sistema de controle de vers√£o para servidores virtuais.  Al√©m disso, cada sistema que estava em nossa empresa foi implantado pelo menos em 2 servidores: um deles estava na cabe√ßa, o segundo na cauda.  Esses dois sistemas eram absolutamente id√™nticos em todas as configura√ß√µes, pot√™ncia, configura√ß√£o e muito mais.  A √∫nica diferen√ßa entre eles era que a cabe√ßa recebia o tr√°fego do usu√°rio, enquanto a cauda nunca recebia o tr√°fego do usu√°rio. <br><br>  Por que isso foi feito? <br><br>  Quando implantamos novos lan√ßamentos de nosso aplicativo, quer√≠amos oferecer a possibilidade de implanta√ß√£o cont√≠nua, ou seja, sem consequ√™ncias vis√≠veis para os usu√°rios.  Isso foi alcan√ßado devido ao fato de que a pr√≥xima vers√£o montada usando Ansible foi lan√ßada na cauda.  L√°, as pessoas envolvidas na implanta√ß√£o podiam verificar e garantir que tudo estava bem: todas as m√©tricas, se√ß√µes e aplicativos funcionavam;  os scripts necess√°rios s√£o iniciados.  Somente depois de convencidos de que est√° tudo bem, o tr√°fego foi alterado.  Ele come√ßou a ir para o servidor que era anterior antes.  E a que era a cabe√ßa antes, ficou sem tr√°fego de usu√°rios, enquanto a vers√£o anterior do nosso aplicativo estava nela. <br><br>  Assim, para os usu√°rios, foi perfeito.  Porque a troca √© simult√¢nea, pois √© apenas uma troca de balanceador.  √â muito f√°cil reverter para a vers√£o anterior simplesmente retornando o balanceador.  Tamb√©m pudemos verificar a capacidade de produ√ß√£o do aplicativo mesmo antes do tr√°fego do usu√°rio, o que era conveniente o suficiente. <br><br>  Que vantagens vimos em tudo isso? <br><br><ol><li>  Primeiro de tudo, <b>funciona de maneira</b> bastante <b>simples.</b>  Todo mundo entende como esse esquema de implanta√ß√£o funciona, porque a maioria das pessoas j√° implantou em servidores virtuais comuns. </li><li> Isso √© bastante <b>confi√°vel</b> , pois a tecnologia de implanta√ß√£o √© simples, testada por milhares de empresas.  Milh√µes de servidores s√£o implantados dessa maneira.  √â dif√≠cil quebrar alguma coisa. </li><li>  E, finalmente, conseguimos <b>implanta√ß√µes at√¥micas</b> .  Implanta√ß√µes que ocorrem aos usu√°rios simultaneamente, sem um est√°gio percept√≠vel de alternar entre a vers√£o antiga e a nova. </li></ol><br>  Mas nisto tamb√©m vimos v√°rias defici√™ncias: <br><br><ol><li>  Al√©m do ambiente de produ√ß√£o, ambiente de desenvolvimento, existem outros ambientes.  Por exemplo, qa e pr√©-produ√ß√£o.  Naquela √©poca, t√≠nhamos muitos servidores e cerca de 60 servi√ßos.  Por esse motivo, era necess√°rio <b>que cada servi√ßo mantivesse a vers√£o da</b> m√°quina virtual <b>que era relevante para ele</b> .  Al√©m disso, se voc√™ deseja atualizar bibliotecas ou instalar novas depend√™ncias, √© necess√°rio fazer isso em todos os ambientes.  Tamb√©m foi necess√°rio sincronizar o hor√°rio em que voc√™ implementaria a pr√≥xima nova vers√£o do seu aplicativo com o hor√°rio em que os devops fizeram as configura√ß√µes de ambiente necess√°rias.  Nesse caso, √© f√°cil entrar em uma situa√ß√£o em que nosso ambiente ser√° ligeiramente diferente de uma s√≥ vez em todos os ambientes seguidos.  Por exemplo, no ambiente de controle de qualidade, haver√° algumas vers√µes de bibliotecas e em produ√ß√£o - outras, o que levar√° a problemas. </li><li>  <b>Dificuldade em atualizar as depend√™ncias do</b> seu aplicativo.  N√£o depende de voc√™, mas da outra equipe.  Ou seja, a partir do comando devops, que suporta o servidor.  Voc√™ deve definir uma tarefa apropriada para eles e fornecer uma descri√ß√£o do que deseja fazer. </li><li>  Naquela √©poca, tamb√©m quer√≠amos dividir os grandes mon√≥litos grandes que t√≠nhamos em pequenos servi√ßos separados, pois entendemos que haveria mais e mais deles.  Naquela √©poca, j√° t√≠nhamos mais de 100. Era necess√°rio que cada novo servi√ßo criasse uma nova m√°quina virtual separada, que tamb√©m precisa ser reparada e implantada.  Al√©m disso, voc√™ n√£o precisa de um carro, mas de pelo menos dois.  Para isso, o ambiente de controle de qualidade ainda est√° sendo adicionado.  Isso causa problemas e torna a cria√ß√£o e o lan√ßamento de novos sistemas mais <b>dif√≠ceis, dispendiosos e demorados para voc√™.</b> </li></ol><br>  Portanto, decidimos que seria mais conveniente mudar da implanta√ß√£o de m√°quinas virtuais comuns para a implanta√ß√£o de nossos aplicativos no cont√™iner do docker.  Se voc√™ possui janela de encaixe, precisa de um sistema que possa executar o aplicativo no cluster, pois n√£o pode simplesmente levantar o cont√™iner.  Geralmente, voc√™ deseja acompanhar quantos cont√™ineres s√£o levantados para que eles subam automaticamente.  Por esse motivo, tivemos que escolher um sistema de controle. <br><br>  Pensamos durante muito tempo sobre qual deles pode ser levado.  O fato √© que, naquela √©poca, essa pilha de implanta√ß√µes em servidores virtuais comuns estava um pouco desatualizada, pois n√£o havia as vers√µes mais recentes dos sistemas operacionais.  Em algum momento, at√© o FreeBSD ficou l√°, o que n√£o era muito conveniente de manter.  Entendemos que voc√™ precisa migrar para o Docker o mais r√°pido poss√≠vel.  Nossos desenvolvedores analisaram sua experi√™ncia existente com diferentes solu√ß√µes e escolheram um sistema como o Nomad. <br><br><h1>  Mudar para Nomad </h1><br>  Nomad √© um produto HashiCorp.  Eles tamb√©m s√£o conhecidos por suas outras decis√µes: <br><br><img src="https://habrastorage.org/webt/4e/vz/4e/4evz4entvdaauztnu558tb-2z9u.jpeg" alt="imagem"><br><br>  <b>O Consul</b> √© uma ferramenta para descoberta de servi√ßos. <br><br>  <b>O Terraform</b> √© um sistema de gerenciamento de servidor que permite configur√°-los por meio de uma configura√ß√£o chamada infraestrutura como c√≥digo. <br><br>  <b>O Vagrant</b> permite implantar m√°quinas virtuais localmente ou na nuvem por meio de arquivos de configura√ß√£o espec√≠ficos. <br><br>  O Nomad na √©poca parecia uma solu√ß√£o bastante simples para a qual voc√™ pode mudar rapidamente sem alterar toda a infraestrutura.  Al√©m disso, √© facilmente dominado.  Portanto, n√≥s o escolhemos como nosso sistema de filtro para nosso cont√™iner. <br><br>  O que √© necess√°rio para implantar completamente seu sistema no Nomad? <br><br><ol><li>  Primeiro de tudo, voc√™ precisa da <b>imagem do docker do</b> seu aplicativo.  Voc√™ precisa compil√°-lo e coloc√°-lo no armazenamento de imagens da janela de encaixe.  No nosso caso, isso √© artefato - um sistema que permite inserir v√°rios artefatos de v√°rios tipos nele.  Ele pode armazenar arquivos, imagens do docker, pacotes do compositor PHP, pacotes NPM e assim por diante. </li><li>  Voc√™ tamb√©m precisa de um <b>arquivo de configura√ß√£o</b> que informe ao Nomad o que, onde e quanto voc√™ deseja implantar. </li></ol><br>  Quando falamos sobre o Nomad, ele usa a linguagem HCL como um formato de arquivo de informa√ß√µes, que significa <i>HashiCorp Configuration Language</i> .  Este √© um superconjunto do Yaml que permite descrever seu servi√ßo em termos de Nomad. <br><br><img src="https://habrastorage.org/webt/vg/q9/vb/vgq9vb_izh4i890ro7giihibz6g.jpeg" alt="imagem"><br><br>  Ele permite dizer quantos cont√™ineres voc√™ deseja implantar, a partir de quais imagens os transferir√£o v√°rios par√¢metros durante a implanta√ß√£o.  Assim, voc√™ alimenta esse arquivo Nomad e lan√ßa cont√™ineres em produ√ß√£o de acordo com ele. <br><br>  No nosso caso, percebemos que escrever exatamente os mesmos arquivos HLC id√™nticos para cada servi√ßo n√£o seria muito conveniente, porque existem muitos servi√ßos e, √†s vezes, voc√™ deseja atualiz√°-los.  Acontece que um servi√ßo √© implantado n√£o em uma inst√¢ncia, mas nas mais diferentes.  Por exemplo, um dos sistemas que temos em produ√ß√£o possui mais de 100 inst√¢ncias na produ√ß√£o.  Eles s√£o iniciados a partir das mesmas imagens, mas diferem nas configura√ß√µes e nos arquivos de configura√ß√£o. <br><br>  Portanto, decidimos que seria conveniente armazenar todos os nossos arquivos de configura√ß√£o para a implanta√ß√£o em um reposit√≥rio comum.  Assim, eles se tornaram observ√°veis: eram f√°ceis de manter e era poss√≠vel ver quais sistemas t√≠nhamos.  Se necess√°rio, tamb√©m √© f√°cil atualizar ou alterar alguma coisa.  Adicionar um novo sistema tamb√©m n√£o √© dif√≠cil - basta inserir o arquivo de configura√ß√£o dentro do novo diret√≥rio.  Dentro dele est√£o os arquivos: service.hcl, que cont√©m uma descri√ß√£o do nosso servi√ßo, e alguns arquivos de ambiente que permitem a configura√ß√£o desse servi√ßo, sendo implantado na produ√ß√£o. <br><br><img src="https://habrastorage.org/webt/-g/l7/8h/-gl78hl7nbmdbhbuacuntgxw4ow.jpeg" alt="imagem"><br><br>  No entanto, alguns de nossos sistemas s√£o implantados no produto n√£o em uma c√≥pia, mas em v√°rios de uma vez.  Portanto, decidimos que seria conveniente n√£o armazenar configura√ß√µes em sua forma pura, mas em sua forma de modelo.  E, como linguagem de modelo, escolhemos o <i>jinja 2</i> .  Nesse formato, armazenamos as configura√ß√µes do pr√≥prio servi√ßo e os arquivos env necess√°rios para ele. <br><br>  Al√©m disso, colocamos no reposit√≥rio uma implanta√ß√£o comum de script para todos os projetos, o que permite iniciar e implantar seu servi√ßo em produ√ß√£o, no ambiente certo, no destino certo.  No caso em que transformamos nossa HCL-config em um modelo, o arquivo HCL, que anteriormente era uma configura√ß√£o regular do Nomad, nesse caso come√ßou a parecer um pouco diferente. <br><br><img src="https://habrastorage.org/webt/9a/ib/zv/9aibzvsme34ra2eg53bjfbqt1tw.jpeg" alt="imagem"><br><br>  Ou seja, substitu√≠mos algumas vari√°veis ‚Äã‚Äãno arquivo de configura√ß√£o por inser√ß√µes de vari√°veis, retiradas dos arquivos env ou de outras fontes.  Al√©m disso, conseguimos coletar arquivos HL dinamicamente, ou seja, podemos usar n√£o apenas as inser√ß√µes de vari√°veis ‚Äã‚Äãusuais.  Como o jinja suporta loops e condi√ß√µes, voc√™ tamb√©m pode criar arquivos de configura√ß√£o, que variam dependendo de onde exatamente voc√™ implanta seus aplicativos. <br><br>  Por exemplo, voc√™ deseja implantar seu servi√ßo na pr√©-produ√ß√£o e na produ√ß√£o.  Suponha que, na pr√©-produ√ß√£o, voc√™ n√£o queira executar scripts coroa, apenas queira ver o servi√ßo em um dom√≠nio separado para garantir que esteja funcionando.  Para qualquer pessoa que implanta um servi√ßo, o processo parece muito simples e transparente.  Basta executar o arquivo deploy.sh, especificar qual servi√ßo voc√™ deseja implantar e em qual destino.  Por exemplo, voc√™ deseja implantar um determinado sistema na R√∫ssia, Bielorr√∫ssia ou Cazaquist√£o.  Para fazer isso, basta alterar um dos par√¢metros e voc√™ ter√° o arquivo de configura√ß√£o correto. <br><br>  Quando o servi√ßo Nomad j√° est√° implantado no seu cluster, ele se parece com isso. <br><br><img src="https://habrastorage.org/webt/nu/au/8d/nuau8dqdcwft0boyw57x37wrkcm.jpeg" alt="imagem"><br><br>  Primeiro, voc√™ precisa de um balanceador externo que absorve todo o tr√°fego do usu√°rio.  Ele trabalhar√° em conjunto com o Consul e descobrir√° onde, em qual n√≥, em qual endere√ßo IP h√° um servi√ßo espec√≠fico que corresponde a um nome de dom√≠nio espec√≠fico.  Os servi√ßos no Consul s√£o do pr√≥prio Nomad.  Como s√£o produtos da mesma empresa, eles est√£o bem conectados.  Podemos dizer que o Nomad pronto para o registro pode registrar todos os servi√ßos nele lan√ßados no Consul. <br><br>  Depois que seu balanceador externo descobre para qual servi√ßo √© necess√°rio enviar tr√°fego, ele o redireciona para o cont√™iner apropriado ou para v√°rios cont√™ineres que correspondem ao seu aplicativo.  Naturalmente, tamb√©m √© necess√°rio pensar em seguran√ßa.  Embora todos os servi√ßos sejam executados nas mesmas m√°quinas virtuais em cont√™ineres, isso geralmente exige a proibi√ß√£o de acesso gratuito de qualquer servi√ßo a qualquer outro.  Conseguimos isso por meio de segmenta√ß√£o.  Cada servi√ßo foi lan√ßado em sua pr√≥pria rede virtual, na qual foram prescritas regras de roteamento e regras para permitir / negar acesso a outros sistemas e servi√ßos.  Eles podem estar localizados dentro deste cluster e fora dele.  Por exemplo, se voc√™ deseja impedir que um servi√ßo se conecte a um banco de dados espec√≠fico, isso pode ser feito por segmenta√ß√£o no n√≠vel da rede.  Ou seja, mesmo por engano, voc√™ n√£o pode se conectar acidentalmente de um ambiente de teste √† sua base de produ√ß√£o. <br><br>  Quanto custou a transi√ß√£o em termos de recursos humanos? <br><br>  A transi√ß√£o de toda a empresa para a Nomad levou cerca de 5-6 meses.  Mudamos sem servi√ßo, mas em um ritmo bastante r√°pido.  Cada equipe teve que criar seus pr√≥prios cont√™ineres para servi√ßos. <br><br>  Adotamos uma abordagem que cada equipe √© respons√°vel pelas imagens do docker de seus sistemas por conta pr√≥pria.  Os Devops tamb√©m fornecem a infraestrutura geral necess√°ria para a implanta√ß√£o, ou seja, suporte para o pr√≥prio cluster, suporte para o sistema de IC e assim por diante.  E naquela √©poca, com mais de 60 sistemas transferidos para o Nomad, foram lan√ßados cerca de 2 mil cont√™ineres. <br><br>  O Devops √© respons√°vel pela infraestrutura geral de tudo o que estiver conectado √† implanta√ß√£o, com os servidores.  E cada equipe de desenvolvimento, por sua vez, √© respons√°vel pela implementa√ß√£o de cont√™ineres para seu sistema espec√≠fico, pois √© a equipe que sabe o que geralmente precisa em um cont√™iner espec√≠fico. <br><br><h1>  Raz√µes para abandonar o Nomad </h1><br>  Que vantagens tivemos ao mudar para implantar usando o Nomad e o docker tamb√©m? <br><br><ol><li>  Fornecemos <b>as mesmas condi√ß√µes</b> para todos os ambientes.  Em uma empresa de desenvolvimento, ambiente de controle de qualidade, pr√©-produ√ß√£o, produ√ß√£o, as mesmas imagens de cont√™iner s√£o usadas, com as mesmas depend√™ncias.  Consequentemente, voc√™ praticamente n√£o tem chance de que a produ√ß√£o seja diferente do que voc√™ testou anteriormente localmente ou em um ambiente de teste. </li><li>  Tamb√©m descobrimos que √© <b>f√°cil adicionar um novo servi√ßo</b> .  Do ponto de vista da implanta√ß√£o, quaisquer novos sistemas s√£o lan√ßados com muita simplicidade.  Basta ir ao reposit√≥rio que armazena as configura√ß√µes, adicionar a pr√≥xima configura√ß√£o ao seu sistema e voc√™ est√° pronto.  Voc√™ pode implantar seu sistema em produ√ß√£o sem esfor√ßo adicional dos devops. </li><li>  Todos <b>os arquivos de configura√ß√£o</b> em um reposit√≥rio comum <b>acabaram sendo monitorados</b> .  Nesse momento, quando implantamos nossos sistemas usando servidores virtuais, usamos o Ansible, no qual as configura√ß√µes est√£o no mesmo reposit√≥rio.  No entanto, para a maioria dos desenvolvedores, foi um pouco mais dif√≠cil trabalhar.  Aqui, o volume de configura√ß√µes e c√≥digo que voc√™ precisa adicionar para implantar o servi√ßo ficou muito menor.  Al√©m disso, para os devops, √© muito f√°cil corrigi-lo ou alter√°-lo.  No caso de transi√ß√µes, por exemplo, na nova vers√£o do Nomad, elas podem pegar e atualizar maci√ßamente todos os arquivos operacionais no mesmo local. </li></ol><br>  Mas tamb√©m enfrentamos v√°rias defici√™ncias: <br><br>  Acabou que <b>n√£o conseguimos implanta√ß√µes perfeitas</b> no caso do Nomad.  Ao rolar os cont√™ineres para fora de condi√ß√µes diferentes, pode acontecer que ele esteja funcionando e o Nomad o percebe como um cont√™iner pronto para aceitar tr√°fego.  Isso aconteceu antes mesmo do aplicativo iniciar.  Por esse motivo, o sistema por um curto per√≠odo come√ßou a produzir 500 erros, porque o tr√°fego come√ßou a ir para o cont√™iner, que ainda n√£o estava pronto para receb√™-lo. <br><br>  Encontramos alguns <b>bugs</b> .  O erro mais significativo √© que o Nomad n√£o aceita muito bem um cluster grande se voc√™ tiver muitos sistemas e cont√™ineres.  Quando voc√™ deseja colocar em servi√ßo um dos servidores inclu√≠dos no cluster Nomad, existe uma alta probabilidade de que o cluster n√£o se sinta muito bem e desmorone.  Parte dos cont√™ineres pode, por exemplo, cair e n√£o subir - subseq√ºentemente ser√° muito caro para voc√™ se todos os seus sistemas de produ√ß√£o estiverem localizados em um cluster gerenciado pelo Nomad. <br><br>  Portanto, decidimos pensar em onde ir a seguir.  Naquela √©poca, nos tornamos muito mais conscientes do que queremos alcan√ßar.  Ou seja: queremos confiabilidade, um pouco mais de fun√ß√µes do que o Nomad oferece e um sistema mais maduro e mais est√°vel. <br><br>  Nesse sentido, nossa escolha recaiu sobre o Kubernetes como a plataforma mais popular para o lan√ßamento de clusters.  Desde que o tamanho e a quantidade de nossos cont√™ineres sejam bastante grandes.  Para tais prop√≥sitos, Kubernetes parecia o sistema mais adequado daqueles que pod√≠amos ver. <br><br><h1>  Indo para Kubernetes </h1><br>  Vou falar um pouco sobre os conceitos b√°sicos do Kubernetes e como eles diferem do Nomad. <br><br><img src="https://habrastorage.org/webt/pv/eh/va/pvehvavusoxszoxum9bsuwyjqbc.jpeg" alt="imagem"><br><br>  Primeiro de tudo, o conceito mais b√°sico no Kubernetes √© o conceito de vagem.  <b>Um pod</b> √© um grupo de um ou mais cont√™ineres que sempre funcionam juntos.  E eles parecem sempre funcionar estritamente na mesma m√°quina virtual.  Eles est√£o dispon√≠veis via IP 127.0.0.1 em portas diferentes. <br><br>  Suponha que voc√™ tenha um aplicativo PHP que consiste em nginx e php-fpm - um circuito cl√°ssico.  Provavelmente, voc√™ deseja que os cont√™ineres nginx e php-fpm estejam sempre juntos.  O Kubernetes faz isso descrevendo-os como um pod comum.  √â exatamente isso que n√£o conseguimos com a ajuda do Nomad. <br><br>  O segundo conceito √© <b>implanta√ß√£o</b> .  O fato √© que a c√°psula em si √© uma coisa ef√™mera, come√ßa e desaparece.  Se voc√™ deseja matar todos os seus cont√™ineres anteriores primeiro e, em seguida, lan√ßar novas vers√µes de uma s√≥ vez, ou deseja lan√ß√°-las gradualmente - esse √© o conceito pelo qual a implanta√ß√£o √© respons√°vel.  Ele descreve como voc√™ implanta seus pods, em quantos e como atualiz√°-los. <br><br>  O terceiro conceito √© <b>servi√ßo</b> .  Seu servi√ßo √© realmente o seu sistema, que recebe algum tr√°fego e o direciona para um ou mais pods que correspondem ao seu servi√ßo.  Ou seja, permite que voc√™ diga que todo o tr√°fego recebido para um servi√ßo com esse nome deve ser enviado para esses pods espec√≠ficos.  E, ao mesmo tempo, fornece balanceamento de tr√°fego.  Ou seja, voc√™ pode executar dois pods do seu aplicativo e todo o tr√°fego recebido ser√° equilibrado igualmente entre os pods relacionados a este servi√ßo. <br><br>  E o quarto conceito b√°sico √© o <b>Ingress</b> .  Este √© um servi√ßo que √© executado em um cluster Kubernetes.  Ele atua como um balanceador de carga externo, que aceita todas as solicita√ß√µes.  Devido √† API, o Kubernetes Ingress pode determinar para onde essas solicita√ß√µes devem ser enviadas.  E ele faz isso com muita flexibilidade.  Voc√™ pode dizer que todas as solicita√ß√µes para esse host e esse URL s√£o enviadas para este servi√ßo.  E enviamos esses pedidos para este host e para outro URL para outro servi√ßo. <br><br>  O mais legal do ponto de vista de quem desenvolve o aplicativo √© que voc√™ √© capaz de gerenciar tudo sozinho.  Depois de definir a configura√ß√£o do Ingress, voc√™ pode enviar todo o tr√°fego que chega a essa API para separar os cont√™ineres registrados, por exemplo, para Go.  Mas esse tr√°fego que chega ao mesmo dom√≠nio, mas para uma URL diferente, deve ser enviado para cont√™ineres escritos em PHP, onde h√° muita l√≥gica, mas eles n√£o s√£o muito r√°pidos. <br><br>  Se compararmos todos esses conceitos com o Nomad, podemos dizer que os tr√™s primeiros conceitos est√£o todos juntos em Servi√ßo.  E o √∫ltimo conceito no pr√≥prio Nomad est√° ausente.  Utilizamos um balanceador externo: ele pode ser haproxy, nginx, nginx + e assim por diante.  No caso de um cubo, voc√™ n√£o precisa introduzir esse conceito adicional separadamente.  No entanto, se voc√™ observar o Ingress por dentro, ele ser√° nginx, haproxy ou traefik, mas como se estivesse embutido no Kubernetes. <br><br>  Todos os conceitos que descrevi s√£o essencialmente os recursos que existem no cluster Kubernetes.  Para descrev√™-los no cubo, √© usado o formato yaml, que √© mais leg√≠vel e familiar que os arquivos HCl no caso do Nomad.  Mas estruturalmente eles descrevem no caso de, por exemplo, pod a mesma coisa.  Eles dizem - eu quero implantar esses e outros pods aqui e ali, com tais e tais imagens, em tal e em quantidade. <br><br><img src="https://habrastorage.org/webt/2k/ka/53/2kka53a1vp1lm0rnl4xbhmcpyu4.jpeg" alt="imagem"><br><br>  Al√©m disso, percebemos que n√£o quer√≠amos criar cada recurso individual com nossas pr√≥prias m√£os: implanta√ß√£o, servi√ßos, Ingress e muito mais.  Em vez disso, quer√≠amos descrever cada sistema implantado em termos de Kubernetes durante a implanta√ß√£o, para que n√£o precis√°ssemos recriar manualmente todas as depend√™ncias de recursos necess√°rias na ordem certa.  Helm foi escolhido como o sistema que nos permitiu fazer isso. <br><br><h1>  Principais conceitos no Helm </h1><br>  Helm √© um <b>gerenciador de pacotes</b> para o Kubernetes.  √â muito parecido com o modo como os gerenciadores de pacotes trabalham nas linguagens de programa√ß√£o.  Eles permitem que voc√™ armazene um servi√ßo que consiste em, por exemplo, nginx de implanta√ß√£o, php-fpm de implanta√ß√£o, uma configura√ß√£o para o Ingress, configmaps (esta √© uma entidade que permite definir env e outros par√¢metros para o seu sistema) na forma de gr√°ficos.  Ao mesmo tempo, Helm <b>corre em cima de Kubernetes</b> .  Ou seja, esse n√£o √© um tipo de sistema que fica de lado, mas apenas outro servi√ßo que √© executado dentro do cubo.  Voc√™ interage com ele atrav√©s de sua API atrav√©s de um comando do console.  Sua conveni√™ncia e charme √© que, mesmo que o helm seja interrompido ou voc√™ o remova do cluster, seus servi√ßos n√£o desaparecer√£o, pois o helm serve basicamente apenas para iniciar o sistema.  O pr√≥prio Kubernetes √© respons√°vel pelo tempo de atividade e pelo estado dos servi√ßos. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tamb√©m percebemos que a </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">padroniza√ß√£o</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que antes disso deveria ser feita de forma independente atrav√©s da introdu√ß√£o do jinja em nossas configura√ß√µes, √© uma das principais caracter√≠sticas do helm. Todas as configura√ß√µes que voc√™ cria para seus sistemas s√£o armazenadas no helm na forma de modelos semelhantes a um pouco de jinja, mas, de fato, usando o modelo de idioma Go no qual o helm est√° escrito, como o Kubernetes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Helm adiciona alguns conceitos adicionais a n√≥s. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gr√°fico</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √© uma descri√ß√£o do seu servi√ßo. Outros gerenciadores de pacotes o chamariam de pacote, pacote configur√°vel ou algo assim. Isso √© chamado de gr√°fico aqui. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Valores</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> s√£o as vari√°veis ‚Äã‚Äãque voc√™ deseja usar para criar suas configura√ß√µes a partir de modelos. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lan√ßamento</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Cada vez que um servi√ßo implantado usando o helm recebe uma vers√£o incremental da libera√ß√£o. Helm lembra qual era a configura√ß√£o do servi√ßo no ano anterior, no ano anterior ao √∫ltimo lan√ßamento e assim por diante. Portanto, se voc√™ precisar reverter, basta executar o comando helm callback, indicando a vers√£o anterior do release. Mesmo que, no momento da revers√£o, a configura√ß√£o correspondente em seu reposit√≥rio n√£o esteja dispon√≠vel, o helm ainda se lembrar√° do que era e reverte seu sistema para o estado em que estava no release anterior. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">No caso em que usamos helm, as configura√ß√µes usuais do Kubernetes tamb√©m se transformam em modelos, nos quais √© poss√≠vel usar vari√°veis, fun√ß√µes e aplicar operadores condicionais. Assim, voc√™ pode coletar a configura√ß√£o do seu servi√ßo, dependendo do ambiente.</font></font><br><br><img src="https://habrastorage.org/webt/dc/lr/fh/dclrfhbdr29ms0gouz_pvd8xz44.jpeg" alt="imagem"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Na pr√°tica, decidimos fazer um pouco diferente do que fizemos no caso do Nomad. Se no Nomad no mesmo reposit√≥rio foram armazenadas as duas configura√ß√µes para a implanta√ß√£o e as n-vari√°veis ‚Äã‚Äãnecess√°rias para implantar nosso servi√ßo, decidimos dividi-las em dois reposit√≥rios separados. Somente as n-vari√°veis ‚Äã‚Äãnecess√°rias para a implanta√ß√£o s√£o armazenadas no reposit√≥rio de implementa√ß√£o e as configura√ß√µes ou gr√°ficos s√£o armazenados no reposit√≥rio de helm. </font></font><br><br><img src="https://habrastorage.org/webt/2r/lo/yt/2rloytnvlrj6nri8vj7e9-hccg8.jpeg" alt="imagem"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que isso nos deu?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apesar de n√£o armazenarmos dados realmente confidenciais nos pr√≥prios arquivos de configura√ß√£o. Por exemplo, senhas de banco de dados. Eles s√£o armazenados como segredos no Kubernetes, mas, no entanto, ainda existem algumas coisas que n√£o queremos dar acesso a todos seguidos. Portanto, o acesso ao reposit√≥rio de implementa√ß√£o √© mais limitado, e o reposit√≥rio helm simplesmente cont√©m uma descri√ß√£o do servi√ßo. Por esse motivo, √© poss√≠vel conceder acesso a um c√≠rculo maior de pessoas com seguran√ßa. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como n√£o temos apenas produ√ß√£o, mas tamb√©m outros ambientes, gra√ßas a essa separa√ß√£o, podemos reutilizar nossos gr√°ficos de comando para implantar servi√ßos n√£o apenas na produ√ß√£o, mas tamb√©m, por exemplo, no ambiente de controle de qualidade. Mesmo implant√°-los localmente usando o </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minikube</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √© algo capaz de executar o Kubernetes localmente.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dentro de cada reposit√≥rio, deixamos uma separa√ß√£o em diret√≥rios separados para cada servi√ßo. Ou seja, dentro de cada diret√≥rio, existem modelos relacionados ao gr√°fico correspondente e descrevem os recursos que precisam ser implantados para iniciar nosso sistema. No reposit√≥rio de implanta√ß√£o, deixamos apenas invejas. Nesse caso, n√£o usamos modelos com jinja, porque o pr√≥prio leme fornece modelos fora da caixa - essa √© uma de suas principais fun√ß√µes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deixamos o script de implanta√ß√£o deploy.sh, que simplifica e padroniza o lan√ßamento para implanta√ß√£o usando o helm. </font><font style="vertical-align: inherit;">Portanto, para quem deseja implantar, a interface de implanta√ß√£o √© exatamente a mesma que era no caso da implanta√ß√£o via Nomad. </font><font style="vertical-align: inherit;">O mesmo deploy.sh, o nome do seu servi√ßo e onde voc√™ deseja implant√°-lo. </font><font style="vertical-align: inherit;">Isso faz com que o leme comece por dentro. </font><font style="vertical-align: inherit;">Por sua vez, ele coleta configura√ß√µes de modelos, substitui os arquivos de valores necess√°rios neles e depois os implanta, colocando-os no Kubernetes.</font></font><br><br><h1>  Conclus√µes </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O servi√ßo Kubernetes parece mais complexo que o Nomad. </font></font><br><br><img src="https://habrastorage.org/webt/fe/p6/qi/fep6qibp6hhnbsmqifk2jnmg20a.jpeg" alt="imagem"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√â aqui que o tr√°fego de sa√≠da chega ao Ingress. Este √© apenas o controlador frontal, que recebe todos os pedidos e os envia posteriormente aos servi√ßos correspondentes aos dados do pedido. Ele os define com base nas configura√ß√µes, que fazem parte da descri√ß√£o do seu aplicativo no leme e que os desenvolvedores definem independentemente. O servi√ßo envia solicita√ß√µes para seus pods, ou seja, cont√™ineres espec√≠ficos, equilibrando o tr√°fego de entrada entre todos os cont√™ineres pertencentes a esse servi√ßo. Bem, √© claro, n√£o esque√ßa que n√£o devemos ir a lugar nenhum da seguran√ßa no n√≠vel da rede. Portanto, o cluster Kubernetes opera a segmenta√ß√£o, que √© baseada na marca√ß√£o. Todos os servi√ßos possuem determinadas tags, √†s quais os direitos de acesso dos servi√ßos a determinados recursos externos / internos est√£o anexados dentro ou fora do cluster.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ao concluir a transi√ß√£o, vimos que o Kubernetes tem todos os recursos do Nomad, que usamos anteriormente, e tamb√©m adiciona muitas coisas novas. Ele pode ser expandido atrav√©s de plug-ins e, de fato, atrav√©s de tipos de recursos personalizados. Ou seja, voc√™ tem a oportunidade n√£o apenas de usar algo que entra no Kubernetes imediatamente, mas tamb√©m de criar seu pr√≥prio recurso e servi√ßo que ler√° seu recurso. Isso fornece op√ß√µes adicionais para expandir seu sistema sem a necessidade de reinstalar o Kubernetes e sem a necessidade de altera√ß√µes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um exemplo disso √© o Prometheus, que √© executado dentro do nosso cluster Kubernetes. Para que ele comece a coletar m√©tricas de um servi√ßo espec√≠fico, precisamos adicionar um tipo de recurso adicional, o chamado monitor de servi√ßo, √† descri√ß√£o do servi√ßo. O Prometheus, devido ao fato de poder ler, sendo lan√ßado no Kubernetes, um tipo personalizado de recursos, come√ßa automaticamente a coletar m√©tricas do novo sistema. √â bastante conveniente.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A primeira implanta√ß√£o que fizemos no Kubernetes foi em mar√ßo de 2018. </font><font style="vertical-align: inherit;">E durante esse tempo, nunca tivemos problemas com ele. </font><font style="vertical-align: inherit;">Funciona de forma est√°vel o suficiente, sem erros significativos. </font><font style="vertical-align: inherit;">Al√©m disso, podemos expandi-lo ainda mais. </font><font style="vertical-align: inherit;">Hoje, temos oportunidades suficientes e gostamos muito do ritmo de desenvolvimento do Kubernetes. </font><font style="vertical-align: inherit;">Atualmente, mais de 3.000 cont√™ineres est√£o localizados em Kubernetes. </font><font style="vertical-align: inherit;">O cluster leva v√°rios n√≥s. </font><font style="vertical-align: inherit;">Ao mesmo tempo, √© atendido, est√°vel e muito controlado.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt451644/">https://habr.com/ru/post/pt451644/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt451634/index.html">Como somos analisados ‚Äã‚Äãem lojas e restaurantes</a></li>
<li><a href="../pt451636/index.html">Cinco anos de escravid√£o</a></li>
<li><a href="../pt451638/index.html">Anima√ß√£o em aplicativos m√≥veis: testando Lottie</a></li>
<li><a href="../pt451640/index.html">Game of Thrones: construindo infogr√°ficos sobre assassinatos, sexo, viagens a Westeros e muito mais</a></li>
<li><a href="../pt451642/index.html">Encontrar um caminho entre obst√°culos redondos</a></li>
<li><a href="../pt451646/index.html">A produ√ß√£o do casco da nave espacial da Federa√ß√£o come√ßou</a></li>
<li><a href="../pt451648/index.html">Como procuramos um turismo incomum na R√∫ssia e que tipo de aventura geralmente acontece</a></li>
<li><a href="../pt451650/index.html">Parte I. Pergunte √† sua m√£e: Como se comunicar com os clientes e confirmar a exatid√£o de sua ideia de neg√≥cio, se todos estiverem por perto?</a></li>
<li><a href="../pt451652/index.html">Parte II Pergunte a sua m√£e: como se comunicar com os clientes e confirmar a exatid√£o de sua ideia de neg√≥cio, se todos est√£o por perto?</a></li>
<li><a href="../pt451654/index.html">Novo funcion√°rio - vivo ou morto</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
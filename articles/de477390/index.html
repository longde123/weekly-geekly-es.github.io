<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåî üî≤ ü•ù Debuggen von Netzwerkverz√∂gerungen in Kubernetes üìê üåú üë®‚Äçüë¶‚Äçüë¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kubernetes wurde bereits vor einigen Jahren auf dem offiziellen GitHub-Blog diskutiert . Seitdem ist es zur Standardtechnologie f√ºr die Bereitstellung...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Debuggen von Netzwerkverz√∂gerungen in Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/477390/"><img src="https://habrastorage.org/getpro/habr/post_images/c82/5b1/413/c825b1413d9c59cf78c51e6e2c8f8049.png"><br><br>  Kubernetes wurde <a href="https://github.blog/2017-08-16-kubernetes-at-github/">bereits vor</a> einigen Jahren auf dem offiziellen GitHub-Blog <a href="https://github.blog/2017-08-16-kubernetes-at-github/">diskutiert</a> .  Seitdem ist es zur Standardtechnologie f√ºr die Bereitstellung von Diensten geworden.  Kubernetes verwaltet inzwischen einen erheblichen Teil der internen und √∂ffentlichen Dienste.  Als unsere Cluster wuchsen und die Leistungsanforderungen immer h√∂her wurden, stellten wir fest, dass einige Dienste auf Kubernetes sporadisch Verz√∂gerungen aufweisen, die nicht durch das Laden der Anwendung selbst erkl√§rt werden k√∂nnen. <br><br>  Tats√§chlich tritt in Anwendungen eine zuf√§llige Netzwerkverz√∂gerung von bis zu 100 ms oder mehr auf, die zu Zeit√ºberschreitungen oder erneuten Versuchen f√ºhrt.  Es wurde erwartet, dass Dienste in der Lage sein w√ºrden, Anfragen viel schneller als 100 ms zu beantworten.  Dies ist jedoch nicht m√∂glich, wenn die Verbindung selbst so lange dauert.  Unabh√§ngig davon beobachteten wir sehr schnelle MySQL-Abfragen, die Millisekunden in Anspruch nahmen, und MySQL wirklich in Millisekunden, aber aus Sicht der anfragenden Anwendung dauerte die Antwort 100 ms oder l√§nger. <br><a name="habracut"></a><br>  Es wurde sofort klar, dass das Problem nur beim Herstellen einer Verbindung zum Kubernetes-Host auftritt, auch wenn der Anruf von au√üerhalb von Kubernetes kam.  Der einfachste Weg, das Problem zu reproduzieren, ist der <a href="https://github.com/tsenart/vegeta">Vegeta-</a> Test, der von jedem internen Host ausgef√ºhrt wird, den Kubernetes-Dienst auf einem bestimmten Port testet und sporadisch eine gro√üe Verz√∂gerung registriert.  In diesem Artikel sehen wir uns an, wie wir die Ursache f√ºr dieses Problem gefunden haben. <br><br><h1>  Beseitigen Sie unn√∂tige Komplexit√§t in der Fehlerkette </h1><br>  Nachdem wir dasselbe Beispiel reproduziert hatten, wollten wir den Fokus des Problems einschr√§nken und die zus√§tzlichen Komplexit√§tsebenen entfernen.  Anfangs waren zu viele Elemente im Strom zwischen Vegeta und Schoten auf Kubernetes.  Um ein tieferes Netzwerkproblem zu identifizieren, m√ºssen Sie einige davon ausschlie√üen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/488/8c1/d29/4888c1d29a8fc1b4a1194c4c3a14c9ff.png"><br><br>  Der Client (Vegeta) erstellt eine TCP-Verbindung mit einem beliebigen Knoten im Cluster.  Kubernetes fungiert als Overlay-Netzwerk (zus√§tzlich zum vorhandenen Rechenzentrumsnetzwerk), das <a href="https://en.wikipedia.org/wiki/IP_in_IP">IPIP</a> verwendet, <a href="https://en.wikipedia.org/wiki/IP_in_IP">dh</a> die IP-Pakete des Overlay-Netzwerks in den IP-Paketen des Rechenzentrums kapselt.  Bei Verbindung mit dem ersten Knoten wird die NAT-Netzwerkadress√ºbersetzung ( <a href="https://en.wikipedia.org/wiki/Network_address_translation">Network Address Translation</a> ) mit Status√ºberwachung durchgef√ºhrt, um die IP-Adresse und den Port des Kubernetes-Hosts in die IP-Adresse und den Port im Overlay-Netzwerk (insbesondere den Pod mit der Anwendung) zu konvertieren.  F√ºr empfangene Pakete wird die umgekehrte Reihenfolge durchgef√ºhrt.  Dies ist ein komplexes System mit vielen Zust√§nden und vielen Elementen, die st√§ndig aktualisiert und ge√§ndert werden, wenn Dienste bereitgestellt und verschoben werden. <br><br>  Das Dienstprogramm <code>tcpdump</code> im Vegeta-Test gibt w√§hrend des TCP-Handshakes eine Verz√∂gerung an (zwischen SYN und SYN-ACK).  Um diese unn√∂tige Komplexit√§t zu beseitigen, k√∂nnen Sie <code>hping3</code> f√ºr einfache "Pings" mit SYN-Paketen verwenden.  √úberpr√ºfen Sie, ob das Antwortpaket eine Verz√∂gerung aufweist, und setzen Sie die Verbindung zur√ºck.  Wir k√∂nnen die Daten filtern, indem wir nur Pakete einschlie√üen, die l√§nger als 100 ms sind, und erhalten eine einfachere Option, um das Problem zu reproduzieren als der vollst√§ndige Test auf Netzwerkebene 7 in Vegeta.  Hier sind die "Pings" des Kubernetes-Hosts unter Verwendung von TCP SYN / SYN-ACK auf dem Host "Port" des Dienstes (30927) mit einem Intervall von 10 ms, gefiltert nach den langsamsten Antworten: <br><br> <code>theojulienne@shell ~ $ sudo hping3 172.16.47.27 -S -p 30927 -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1485 win=29200 rtt=127.1 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1486 win=29200 rtt=117.0 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1487 win=29200 rtt=106.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1488 win=29200 rtt=104.1 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=5024 win=29200 rtt=109.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=5231 win=29200 rtt=109.2 ms</code> <br> <br>  Sofort kann man die erste Beobachtung machen.  Die Seriennummern und Timings zeigen, dass dies keine einmalige √úberlastung ist.  Die Verz√∂gerung summiert sich h√§ufig und wird letztendlich verarbeitet. <br><br>  Als n√§chstes wollen wir herausfinden, welche Komponenten am Auftreten von Staus beteiligt sein k√∂nnen.  Vielleicht sind dies einige der Hunderte von Iptables-Regeln in NAT?  Oder einige Probleme mit IPIP-Tunneling im Netzwerk?  Eine M√∂glichkeit, dies zu √ºberpr√ºfen, besteht darin, jeden Schritt des Systems durch Ausschlie√üen zu √ºberpr√ºfen.  Was passiert, wenn Sie NAT- und Firewall-Logik entfernen und nur einen Teil von IPIP √ºbrig lassen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5b3/e2a/cff/5b3e2acff2ef9f1f8c7c527356741d92.png"><br><br>  Gl√ºcklicherweise erleichtert Linux den direkten Zugriff auf die IP-Overlay-Schicht, wenn sich der Computer im selben Netzwerk befindet: <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 10.125.20.64 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7346 win=0 rtt=127.3 ms <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7347 win=0 rtt=117.3 ms <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7348 win=0 rtt=107.2 ms</code> <br> <br>  Nach den Ergebnissen zu urteilen, bleibt das Problem immer noch!  Dies schlie√üt iptables und NAT aus.  Das Problem liegt also in TCP?  Mal sehen, wie regul√§r ICMP-Ping funktioniert: <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 10.125.20.64 --icmp -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=28 ip=10.125.20.64 ttl=64 id=42594 icmp_seq=104 rtt=110.0 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49448 icmp_seq=4022 rtt=141.3 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49449 icmp_seq=4023 rtt=131.3 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49450 icmp_seq=4024 rtt=121.2 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49451 icmp_seq=4025 rtt=111.2 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49452 icmp_seq=4026 rtt=101.1 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50023 icmp_seq=4343 rtt=126.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50024 icmp_seq=4344 rtt=116.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50025 icmp_seq=4345 rtt=106.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=59727 icmp_seq=9836 rtt=106.1 ms</code> <br> <br>  Die Ergebnisse zeigen, dass das Problem nicht verschwunden ist.  Vielleicht ist dies ein IPIP-Tunnel?  Vereinfachen wir den Test: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/267/ff6/137/267ff613754b99f8cc1bb1d89119206e.png"><br><br>  Werden alle Pakete zwischen diesen beiden Hosts gesendet? <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 172.16.47.27 --icmp -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41127 icmp_seq=12564 rtt=140.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41128 icmp_seq=12565 rtt=130.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41129 icmp_seq=12566 rtt=120.8 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41130 icmp_seq=12567 rtt=110.8 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41131 icmp_seq=12568 rtt=100.7 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9062 icmp_seq=31443 rtt=134.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9063 icmp_seq=31444 rtt=124.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9064 icmp_seq=31445 rtt=114.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9065 icmp_seq=31446 rtt=104.2 ms</code> <br> <br>  Wir haben die Situation vereinfacht, indem zwei Kubernetes-Hosts beliebige Pakete aneinander senden, sogar ICMP-Ping.  Sie sehen immer noch eine Verz√∂gerung, wenn der Zielhost "schlecht" ist (einige schlechter als andere). <br><br>  Nun die letzte Frage: Warum tritt die Verz√∂gerung nur auf Kubeknotenservern auf?  Und passiert es, wenn kube-node der Sender oder Empf√§nger ist?  Gl√ºcklicherweise ist dies auch recht einfach herauszufinden, indem ein Paket von einem Host au√üerhalb von Kubernetes gesendet wird, der jedoch denselben "als fehlerhaft bekannten" Empf√§nger hat.  Wie Sie sehen k√∂nnen, ist das Problem nicht verschwunden: <br><br> <code>theojulienne@shell ~ $ sudo hping3 172.16.47.27 -p 9876 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=312 win=0 rtt=108.5 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=5903 win=0 rtt=119.4 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=6227 win=0 rtt=139.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=7929 win=0 rtt=131.2 ms</code> <br> <br>  Dann f√ºhren wir dieselben Anforderungen vom vorherigen Quell-Kubeknoten an den externen Host durch (der den urspr√ºnglichen Host ausschlie√üt, da ping sowohl die RX- als auch die TX-Komponenten enth√§lt): <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 172.16.33.44 -p 9876 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> ^C <br> --- 172.16.33.44 hping statistic --- <br> 22352 packets transmitted, 22350 packets received, 1% packet loss <br> round-trip min/avg/max = 0.2/7.6/1010.6 ms</code> <br> <br>  Nachdem wir die verz√∂gerten Paketerfassungen untersucht hatten, erhielten wir einige zus√§tzliche Informationen.  Insbesondere, dass der Absender (unten) diese Zeit√ºberschreitung sieht, der Empf√§nger (oben) sie jedoch nicht sieht - siehe die Delta-Spalte (in Sekunden): <br><br> <a href=""><img src="https://habrastorage.org/webt/4m/-t/dj/4m-tdjzws9lrhnva3xcxijel7eg.png"></a> <br><br>  Wenn Sie den Unterschied in der Reihenfolge von TCP- und ICMP-Paketen (nach Sequenznummern) auf der Empf√§ngerseite untersuchen, kommen ICMP-Pakete au√üerdem immer in der gleichen Reihenfolge an, in der sie gesendet wurden, jedoch mit unterschiedlichem Timing.  Gleichzeitig wechseln sich TCP-Pakete manchmal ab, und einige von ihnen bleiben h√§ngen.  Insbesondere wenn wir die Ports der SYN-Pakete untersuchen, gehen sie auf der Senderseite in die richtige Reihenfolge, auf der Empf√§ngerseite jedoch nicht. <br><br>  Es gibt einen subtilen Unterschied, wie <a href="https://en.wikipedia.org/wiki/Network_address_translation">Netzwerkkarten</a> moderner Server (wie in unserem Rechenzentrum) Pakete verarbeiten, die TCP oder ICMP enthalten.  Wenn ein Paket ankommt, "hackt" der Netzwerkadapter es √ºber die Verbindung, das hei√üt, er versucht, die Verbindungen abwechselnd zu trennen und jede Warteschlange an einen separaten Prozessorkern zu senden.  Bei TCP enth√§lt dieser Hash sowohl die Quell- als auch die Ziel-IP-Adresse und den Port.  Mit anderen Worten, jede Verbindung wird (m√∂glicherweise) anders gehasht.  F√ºr ICMP werden nur IP-Adressen gehasht, da keine Ports vorhanden sind. <br><br>  Eine weitere neue Beobachtung: W√§hrend dieses Zeitraums stellen wir ICMP-Verz√∂gerungen bei der gesamten Kommunikation zwischen den beiden Hosts fest, TCP jedoch nicht.  Dies sagt uns, dass der Grund wahrscheinlich in einem Hashing der RX-Warteschlangen liegt: Es ist fast sicher, dass die √úberlastung eher bei der Verarbeitung von RX-Paketen als beim Senden von Antworten auftritt. <br><br>  Dies schlie√üt das Senden von Paketen aus der Liste der m√∂glichen Gr√ºnde aus.  Jetzt wissen wir, dass das Problem bei der Paketverarbeitung auf einigen Kubeknotenservern auf der Empf√§ngerseite liegt. <br><br><h1>  Grundlegendes zur Paketverarbeitung im Linux-Kernel </h1><br>  Um zu verstehen, warum das Problem beim Empf√§nger auf einigen Kubeknotenservern auftritt, sehen wir uns an, wie der Linux-Kernel mit Paketen umgeht. <br><br>  Zur einfachsten herk√∂mmlichen Implementierung zur√ºckkehrend, empf√§ngt die Netzwerkkarte das Paket und sendet eine <a href="https://en.wikipedia.org/wiki/Interrupt">Unterbrechung</a> an den Linux-Kernel, der das Paket ist, das verarbeitet werden muss.  Der Kernel stoppt eine andere Operation, wechselt den Kontext zum Interrupt-Handler, verarbeitet das Paket und kehrt dann zu den aktuellen Tasks zur√ºck. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1a2/3c3/4ee/1a23c34eea2236294913fd09a25aa1e4.png"><br><br>  Dieser Kontextwechsel ist langsam: Auf 10-Megabyte-Netzwerkkarten war die Latenz in den 1990er-Jahren m√∂glicherweise nicht sp√ºrbar, aber auf modernen 10G-Karten mit einem maximalen Durchsatz von 15 Millionen Paketen pro Sekunde kann jeder Kern eines kleinen 8-Core-Servers millionenfach pro Sekunde unterbrochen werden. <br><br>  Um nicht st√§ndig mit der Interrupt-Behandlung <a href="https://en.wikipedia.org/wiki/New_API">fertig zu werden,</a> hat Linux vor vielen Jahren <a href="https://en.wikipedia.org/wiki/New_API">NAPI</a> hinzugef√ºgt: eine Netzwerk-API, mit der alle modernen Treiber die Leistung bei hohen Geschwindigkeiten steigern.  Bei niedrigen Geschwindigkeiten akzeptiert der Kernel weiterhin Interrupts von der Netzwerkkarte auf die alte Art und Weise.  Sobald eine ausreichende Anzahl von Paketen eintrifft, die den Schwellenwert √ºberschreitet, deaktiviert der Kernel die Interrupts und beginnt stattdessen, den Netzwerkadapter abzufragen und Pakete in Stapeln aufzunehmen.  Die Verarbeitung erfolgt in softirq, dh im <a href="https://www.kernel.org/doc/htmldocs/kernel-hacking/basics-softirqs.html">Kontext von Software-Interrupts</a> nach Systemaufrufen und Hardware-Interrupts, wenn der Kernel (anders als der Benutzerraum) bereits ausgef√ºhrt wird. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/22a/50d/ee1/22a50dee1fffdbc20614db2b1db28fc4.png"><br><br>  Dies ist viel schneller, verursacht jedoch ein anderes Problem.  Wenn zu viele Pakete vorhanden sind, dauert es die ganze Zeit, um Pakete von der Netzwerkkarte zu verarbeiten, und Benutzerraumprozesse haben keine Zeit, diese Warteschlangen tats√§chlich zu leeren (Lesen von TCP-Verbindungen usw.).  Am Ende f√ºllen sich die Warteschlangen und wir beginnen Pakete abzulegen.  Bei dem Versuch, ein Gleichgewicht zu finden, legt der Kernel ein Budget f√ºr die maximale Anzahl von Paketen fest, die im Kontext von softirq verarbeitet werden.  Sobald dieses Budget √ºberschritten ist, wird ein separater <code>ksoftirqd</code> Thread <code>ksoftirqd</code> (Sie sehen einen in <code>ps</code> f√ºr jeden Kern), der diese Softirqs au√üerhalb des normalen Syscall / Interrupt-Pfads verarbeitet.  Dieser Thread wird mit einem Standardprozessplaner geplant, der versucht, Ressourcen gerecht zu verteilen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d0f/1e6/f0c/d0f1e6f0c54d45c24d62cb2bcf90c674.png"><br><br>  Nachdem Sie untersucht haben, wie der Kernel Pakete verarbeitet, k√∂nnen Sie feststellen, dass eine gewisse Wahrscheinlichkeit einer √úberlastung besteht.  Wenn Softirq-Anrufe seltener eingehen, m√ºssen Pakete eine Weile warten, bis sie in der Empfangswarteschlange auf der Netzwerkkarte verarbeitet werden.  M√∂glicherweise liegt dies an einer Aufgabe, die den Prozessorkern blockiert, oder daran, dass der Kernel softirq nicht startet. <br><br><h1>  Wir beschr√§nken die Verarbeitung auf den Kernel oder die Methode </h1><br>  Verz√∂gerungen bei Softirq sind nur eine Annahme.  Aber es macht Sinn und wir wissen, dass wir etwas sehr √Ñhnliches sehen.  Daher besteht der n√§chste Schritt darin, diese Theorie zu best√§tigen.  Und wenn es best√§tigt wird, dann finden Sie den Grund f√ºr die Verz√∂gerungen. <br><br>  Zur√ºck zu unseren Slow Packages: <br><br> <code>len=46 ip=172.16.53.32 ttl=61 id=29573 icmp_seq=1953 rtt=99.3 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29574 icmp_seq=1954 rtt=89.3 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29575 icmp_seq=1955 rtt=79.2 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29576 icmp_seq=1956 rtt=69.1 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29577 icmp_seq=1957 rtt=59.1 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29790 icmp_seq=2070 rtt=75.7 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29791 icmp_seq=2071 rtt=65.6 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29792 icmp_seq=2072 rtt=55.5 ms</code> <br> <br>  Wie bereits erw√§hnt, werden diese ICMP-Pakete in eine einzelne NIC RX-Warteschlange gehasht und von einem einzelnen CPU-Kern verarbeitet.  Wenn wir verstehen m√∂chten, wie Linux funktioniert, ist es hilfreich zu wissen, wo (auf welchem ‚Äã‚ÄãCPU-Kern) und wie (softirq, ksoftirqd) diese Pakete verarbeitet werden, um den Prozess zu verfolgen. <br><br>  Jetzt ist es Zeit, Tools zu verwenden, mit denen der Linux-Kernel in Echtzeit √ºberwacht werden kann.  Hier haben wir <a href="https://github.com/iovisor/bcc">bcc verwendet</a> .  Mit diesem Toolkit k√∂nnen Sie kleine C-Programme schreiben, die beliebige Funktionen im Kernel abfangen und Ereignisse in ein Python-Programm im Benutzerbereich puffern, das sie verarbeiten und Ihnen das Ergebnis zur√ºckgeben kann.  Hooks f√ºr beliebige Funktionen im Kernel sind komplex, aber das Dienstprogramm ist auf maximale Sicherheit ausgelegt und verfolgt genau solche Produktionsprobleme, die in einer Test- oder Entwicklungsumgebung nicht einfach zu reproduzieren sind. <br><br>  Der Plan hier ist einfach: Wir wissen, dass der Kernel diese ICMP-Pings verarbeitet, daher <a href="">binden</a> wir die <a href="">Kernelfunktion icmp_echo ein</a> , die das eingehende ICMP-Paket f√ºr die <a href="">Echoanforderung</a> empf√§ngt und das Senden der ICMP-Antwort f√ºr die <a href="">Echoantwort</a> initiiert.  Wir k√∂nnen das Paket identifizieren, indem wir die icmp_seq-Nummer erh√∂hen, die oben <code>hping3</code> . <br><br>  Der <a href="https://gist.github.com/theojulienne/9d78a0cb68dbe56f19a2ae6316bc6846">bcc-Skriptcode</a> sieht kompliziert aus, ist aber nicht so be√§ngstigend, wie es scheint.  Die Funktion <code>icmp_echo</code> √ºbergibt <code>struct sk_buff *skb</code> : Dies ist das Paket mit der Anforderung "Echo Request".  Wir k√∂nnen es verfolgen, die Sequenz <code>echo.sequence</code> (die <code>icmp_seq</code> von hping3 <code></code> ) herausziehen und es an den User-Space senden.  Es ist auch praktisch, den aktuellen Prozessnamen / die aktuelle Prozesskennung zu erfassen.  Nachfolgend sehen Sie die Ergebnisse, die wir direkt w√§hrend der Verarbeitung von Paketen durch den Kernel sehen: <br><br><pre>  TGID PID PROCESS NAME ICMP_SEQ
 0 0 swapper / 11.770
 0 0 swapper / 11.771
 0 0 swapper / 11 772
 0 0 swapper / 11 773
 0 0 swapper / 11,774
 20041 20086 prometheus 775
 0 0 swapper / 11.776
 0 0 swapper / 11.777
 0 0 swapper / 11 778
 4512 4542 spokes-report-s 779 </pre><br>  Hierbei ist zu beachten, dass im Kontext von <code>softirq</code> Prozesse, die Systemaufrufe <code>softirq</code> als "Prozesse" <code>softirq</code> werden, obwohl dieser Kernel Pakete im Kontext des Kernels sicher verarbeitet. <br><br>  Mit diesem Tool k√∂nnen wir die Verbindung bestimmter Prozesse mit bestimmten Paketen herstellen, die eine Verz√∂gerung von <code>hping3</code> .  Wir machen eine einfache <code>icmp_seq</code> dieser Erfassung f√ºr bestimmte <code>icmp_seq</code> Werte.  Pakete, die den obigen icmp_seq-Werten entsprechen, wurden mit ihrer RTT markiert, die wir oben beobachtet haben (in Klammern sind die erwarteten RTT-Werte f√ºr Pakete, die wir aufgrund von RTT-Werten von weniger als 50 ms gefiltert haben): <br><br><pre>  TGID PID PROCESS NAME ICMP_SEQ ** RTT
 -
 10137 10436 cadvisor 1951
 10137 10436 cadvisor 1952
 76 76 ksoftirqd / 11 1953 ** 99ms
 76 76 ksoftirqd / 11 1954 ** 89ms
 76 76 ksoftirqd / 11 1955 ** 79ms
 76 76 ksoftirqd / 11 1956 ** 69ms
 76 76 ksoftirqd / 11 1957 ** 59ms
 76 76 ksoftirqd / 11 1958 ** (49 ms)
 76 76 ksoftirqd / 11 1959 ** (39 ms)
 76 76 ksoftirqd / 11 1960 ** (29 ms)
 76 76 ksoftirqd / 11 1961 ** (19 ms)
 76 76 ksoftirqd / 11 1962 ** (9 ms)
 -
 10137 10436 cadvisor 2068
 10137 10436 cadvisor 2069
 76 76 ksoftirqd / 11 2070 ** 75ms
 76 76 ksoftirqd / 11 2071 ** 65ms
 76 76 ksoftirqd / 11 2072 ** 55ms
 76 76 ksoftirqd / 11 2073 ** (45 ms)
 76 76 ksoftirqd / 11 2074 ** (35 ms)
 76 76 ksoftirqd / 11 2075 ** (25 ms)
 76 76 ksoftirqd / 11 2076 ** (15 ms)
 76 76 ksoftirqd / 11 2077 ** (5 ms) </pre><br>  Die Ergebnisse sagen uns ein paar Dinge.  Erstens behandelt der <code>ksoftirqd/11</code> Kontext alle diese Pakete.  Dies bedeutet, dass f√ºr dieses bestimmte Maschinenpaar ICMP-Pakete auf dem 11-Core am empfangenden Ende gehasht wurden.  Wir sehen auch, dass es bei jedem Stau Pakete gibt, die im Kontext des <code>cadvisor</code> -Systemaufrufs verarbeitet werden.  Dann √ºbernimmt <code>ksoftirqd</code> die Aufgabe und erf√ºllt die akkumulierte Warteschlange: genau die Anzahl der Pakete, die nach <code>cadvisor</code> akkumuliert <code>cadvisor</code> . <br><br>  Die Tatsache, dass ein <code>cadvisor</code> immer unmittelbar davor arbeitet, impliziert, dass er sich mit dem Problem befasst.  Ironischerweise besteht der Zweck von <a href="https://github.com/google/cadvisor">cadvisor</a> darin, "die Ressourcennutzung und die Leistungsmerkmale laufender Container zu analysieren", anstatt dieses Leistungsproblem zu verursachen. <br><br>  Wie bei anderen Aspekten des Containerumschlags handelt es sich hierbei um √§u√üerst fortschrittliche Tools, bei denen unter unvorhergesehenen Umst√§nden Leistungsprobleme zu erwarten sind. <br><br><h1>  Was macht cadvisor, um die Paketwarteschlange zu verlangsamen? </h1><br>  Jetzt wissen wir ziemlich genau, wie der Fehler auftritt, welcher Prozess ihn verursacht und auf welcher CPU.  Wir sehen, dass der Linux-Kernel aufgrund der harten Sperrung keine Zeit hat, <code>ksoftirqd</code> rechtzeitig zu planen.  Und wir sehen, dass Pakete im Kontext von <code>cadvisor</code> .  Es ist logisch anzunehmen, dass <code>cadvisor</code> einen langsamen <code>cadvisor</code> startet, nach dem alle zu diesem Zeitpunkt gesammelten Pakete verarbeitet werden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6fd/6fb/970/6fd6fb970f2d27943039910db9b41743.png"><br><br>  Dies ist eine Theorie, aber wie kann man sie testen?  Was wir tun k√∂nnen, ist, den Betrieb des CPU-Kerns w√§hrend dieses Prozesses zu verfolgen, den Punkt zu finden, an dem das Budget durch die Anzahl der Pakete und ksoftirqd √ºberschritten wird, und dann etwas fr√ºher zu schauen - was genau vor diesem Moment auf dem CPU-Kern funktioniert hat.  Es ist wie ein R√∂ntgenbild einer CPU alle paar Millisekunden.  Es wird ungef√§hr so ‚Äã‚Äãaussehen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/44a/954/6e8/44a9546e8de19e43cb125eb8a03a8f47.png"><br><br>  Praktischerweise kann dies alles mit vorhandenen Werkzeugen durchgef√ºhrt werden.  Beispielsweise √ºberpr√ºft <a href="https://perf.wiki.kernel.org/index.php/Tutorial">perf record</a> den angegebenen CPU-Kern mit der angegebenen H√§ufigkeit und kann einen Zeitplan f√ºr Aufrufe an ein laufendes System generieren, der sowohl den Benutzerbereich als auch den Linux-Kernel enth√§lt.  Sie k√∂nnen diesen Datensatz mit einem kleinen <a href="https://github.com/brendangregg/FlameGraph">Zweig</a> des <a href="https://github.com/brendangregg/FlameGraph">FlameGraph-</a> Programms von Brendan Gregg verarbeiten, der die Stapelverfolgungsreihenfolge <a href="https://github.com/brendangregg/FlameGraph">beibeh√§lt</a> .  Wir k√∂nnen einzeilige Stack-Traces alle 1 ms speichern und dann das Sample f√ºr 100 Millisekunden ausw√§hlen und speichern, bevor <code>ksoftirqd</code> in den Trace <code>ksoftirqd</code> : <br><br> <code># record 999 times a second, or every 1ms with some offset so not to align exactly with timers <br> sudo perf record -C 11 -g -F 999 <br> # take that recording and make a simpler stack trace. <br> sudo perf script 2&gt;/dev/null | ./FlameGraph/stackcollapse-perf-ordered.pl | grep ksoftir -B 100</code> <br> <br>  Hier sind die Ergebnisse: <br><br> <code>( ,   ) <br> <br> cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_iter cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages ksoftirqd/11;ret_from_fork;kthread;kthread;smpboot_thread_fn;smpboot_thread_fn;run_ksoftirqd;__do_softirq;net_rx_action;ixgbe_poll;ixgbe_clean_rx_irq;napi_gro_receive;netif_receive_skb_internal;inet_gro_receive;bond_handle_frame;__netif_receive_skb_core;ip_rcv_finish;ip_rcv;ip_forward_finish;ip_forward;ip_finish_output;nf_iterate;ip_output;ip_finish_output2;__dev_queue_xmit;dev_hard_start_xmit;ipip_tunnel_xmit;ip_tunnel_xmit;iptunnel_xmit;ip_local_out;dst_output;__ip_local_out;nf_hook_slow;nf_iterate;nf_conntrack_in;generic_packet;ipt_do_table;set_match_v4;ip_set_test;hash_net4_kadt;ixgbe_xmit_frame_ring;swiotlb_dma_mapping_error;hash_net4_test ksoftirqd/11;ret_from_fork;kthread;kthread;smpboot_thread_fn;smpboot_thread_fn;run_ksoftirqd;__do_softirq;net_rx_action;gro_cell_poll;napi_gro_receive;netif_receive_skb_internal;inet_gro_receive;__netif_receive_skb_core;ip_rcv_finish;ip_rcv;ip_forward_finish;ip_forward;ip_finish_output;nf_iterate;ip_output;ip_finish_output2;__dev_queue_xmit;dev_hard_start_xmit;dev_queue_xmit_nit;packet_rcv;tpacket_rcv;sch_direct_xmit;validate_xmit_skb_list;validate_xmit_skb;netif_skb_features;ixgbe_xmit_frame_ring;swiotlb_dma_mapping_error;__dev_queue_xmit;dev_hard_start_xmit;__bpf_prog_run;__bpf_prog_run</code> <br> <br>  Hier gibt es eine Menge Dinge, aber die Hauptsache ist, dass wir die Vorlage "cadvisor before ksoftirqd" finden, die wir zuvor im ICMP-Tracer gesehen haben.  Was bedeutet das? <br><br>  Jede Zeile ist ein Trace der CPU zu einem bestimmten Zeitpunkt.  Jeder Aufruf des Stapels in einer Zeile wird durch ein Semikolon getrennt.  In der Mitte der Zeilen sehen wir syscall mit dem Namen: <code>read(): .... ;do_syscall_64;sys_read; ...</code>  <code>read(): .... ;do_syscall_64;sys_read; ...</code>  Aus diesem Grund verbringt Cadvisor viel Zeit mit dem Systemaufruf <code>read()</code> , der sich auf die Funktionen <code>mem_cgroup_*</code> (ganz oben auf dem Aufrufstapel / Zeilenende) <code>mem_cgroup_*</code> . <br><br>  In der Anrufverfolgung ist es unpraktisch zu sehen, was genau gelesen wird. F√ºhren Sie also <code>strace</code> und sehen Sie, was der Cadvisor tut, und suchen Sie nach Systemanrufen, die l√§nger als 100 ms sind: <br><br> <code>theojulienne@kube-node-bad ~ $ sudo strace -p 10137 -T -ff 2&gt;&amp;1 | egrep '&lt;0\.[1-9]' <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.156784&gt; <br> [pid 10432] &lt;... futex resumed&gt; ) = 0 &lt;0.258285&gt; <br> [pid 10137] &lt;... futex resumed&gt; ) = 0 &lt;0.678382&gt; <br> [pid 10384] &lt;... futex resumed&gt; ) = 0 &lt;0.762328&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 154234880\nrss 507904\nrss_h"..., 4096) = 658 &lt;0.179438&gt; <br> [pid 10384] &lt;... futex resumed&gt; ) = 0 &lt;0.104614&gt; <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.175936&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 577 &lt;0.228091&gt; <br> [pid 10427] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 577 &lt;0.207334&gt; <br> [pid 10411] &lt;... epoll_ctl resumed&gt; ) = 0 &lt;0.118113&gt; <br> [pid 10382] &lt;... pselect6 resumed&gt; ) = 0 (Timeout) &lt;0.117717&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 154234880\nrss 507904\nrss_h"..., 4096) = 660 &lt;0.159891&gt; <br> [pid 10417] &lt;... futex resumed&gt; ) = 0 &lt;0.917495&gt; <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.208172&gt; <br> [pid 10417] &lt;... futex resumed&gt; ) = 0 &lt;0.190763&gt; <br> [pid 10417] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 576 &lt;0.154442&gt;</code> <br> <br>  Wie zu erwarten ist, sehen wir hier langsame <code>read()</code> -Aufrufe.  Aus den Inhalten der Leseoperationen und dem <code>mem_cgroup</code> Kontext ist ersichtlich, dass sich diese <code>read()</code> -Aufrufe auf die Datei <code>memory.stat</code> beziehen, in der die Speicherauslastung und die Einschr√§nkungen von cgroup (Docker-Technologie zur Ressourcenisolierung) aufgef√ºhrt sind.  Das Cadvisor-Tool fragt diese Datei nach Informationen zur Ressourcennutzung f√ºr Container ab.  Lassen Sie uns √ºberpr√ºfen, ob dieser Core oder Cadvisor etwas Unerwartetes tut: <br><br> <code>theojulienne@kube-node-bad ~ $ time cat /sys/fs/cgroup/memory/memory.stat &gt;/dev/null <br> <br> real 0m0.153s <br> user 0m0.000s <br> sys 0m0.152s <br> theojulienne@kube-node-bad ~ $</code> <br> <br>  Jetzt k√∂nnen wir den Fehler reproduzieren und verstehen, dass der Linux-Kernel mit einer Pathologie konfrontiert ist. <br><br><h1>  Was macht das Lesen so langsam? </h1><br>  Zu diesem Zeitpunkt ist es viel einfacher, Nachrichten von anderen Benutzern zu √§hnlichen Problemen zu finden.  Wie sich herausstellte, wurde dieser Fehler im Cadvisor-Tracker als <a href="https://github.com/google/cadvisor/issues/1774">Problem einer √ºberm√§√üigen CPU-Auslastung</a> gemeldet. Niemand bemerkte jedoch, dass die Verz√∂gerung auch zuf√§llig im Netzwerkstapel widergespiegelt wurde.  Zwar wurde festgestellt, dass Cadvisor mehr Prozessorzeit als erwartet ben√∂tigt, dies wurde jedoch nicht besonders ber√ºcksichtigt, da unsere Server √ºber viele Prozessorressourcen verf√ºgen, sodass wir das Problem nicht sorgf√§ltig untersucht haben. <br><br>  Das Problem ist, dass Kontrollgruppen (cgroups) die Speichernutzung im Namespace (Container) ber√ºcksichtigen.  Wenn alle Prozesse in dieser Kontrollgruppe beendet sind, gibt Docker eine Kontrollgruppe Speicher frei.  "Speicher" ist jedoch nicht nur ein Prozessspeicher.  Obwohl der Prozessspeicher selbst nicht mehr verwendet wird, stellt sich heraus, dass der Kernel auch zwischengespeicherte Inhalte wie Eintr√§ge und Inodes (Verzeichnis- und Dateimetadaten) zuweist, die in der Speicher-Cgroup zwischengespeichert sind.  Aus der Beschreibung des Problems: <br><br><blockquote>  cgroups-Zombies: Kontrollgruppen, in denen keine Prozesse vorhanden sind und die gel√∂scht werden, f√ºr die jedoch noch Speicher zugewiesen ist (in meinem Fall aus dem Dentry-Cache, aber auch aus dem Page-Cache oder tmpfs). </blockquote><br>  Das √úberpr√ºfen aller Seiten im Cache durch den Kernel, wenn cgroup freigegeben ist, kann sehr langsam sein, daher wird der verz√∂gerte Prozess gew√§hlt: Warten Sie, bis diese Seiten erneut angefordert werden, und l√∂schen Sie cgroup, auch wenn der Speicher wirklich ben√∂tigt wird.  Bisher wird cgroup bei der Erfassung von Statistiken noch ber√ºcksichtigt. <br><br>  In Bezug auf die Leistung haben sie Speicherplatz f√ºr die Leistung geopfert: Die anf√§ngliche Bereinigung wurde beschleunigt, da noch ein Teil des zwischengespeicherten Speichers vorhanden ist.  Es ist in Ordnung.  Wenn der Kernel den letzten Teil des zwischengespeicherten Speichers verwendet, wird cgroup schlie√ülich gel√∂scht, sodass dies nicht als "Leck" bezeichnet werden kann.  Leider f√ºhrt die spezielle Implementierung der <code>memory.stat</code> Suchmaschine in dieser Kernel-Version (4.9) in Verbindung mit der enormen Menge an Speicher auf unseren Servern dazu, dass die Wiederherstellung der neuesten zwischengespeicherten Daten und das L√∂schen von cgroup-Zombies viel l√§nger dauert. <br><br>  Es stellt sich heraus, dass es auf einigen unserer Knoten so viele Zombies gab, dass das Lesen und die Latenz eine Sekunde √ºberschritten haben. <br><br>  Eine Problemumgehung f√ºr das Cadvisor-Problem ist das sofortige L√∂schen von Eintr√§gen / Inodes-Caches im gesamten System, wodurch die Leselatenz sowie die Netzwerklatenz auf dem Host sofort beseitigt werden, da das L√∂schen des Caches zwischengespeicherte cgroup-Zombieseiten umfasst und diese ebenfalls freigegeben werden.  Dies ist keine L√∂sung, best√§tigt jedoch die Ursache des Problems. <br><br>  Es stellte sich heraus, dass neuere Versionen des Kernels (4.19+) die Leistung des Aufrufs von memory.stat verbesserten, sodass der Wechsel zu diesem Kernel das Problem <code>memory.stat</code> .  Gleichzeitig verf√ºgten wir √ºber Tools zum Erkennen von Problemknoten in Kubernetes-Clustern, zum ordnungsgem√§√üen Entleeren und zum Neustarten.  Wir haben alle Cluster durchsucht, die Knoten mit einer ausreichend hohen Verz√∂gerung gefunden und neu gestartet.  Dies gab uns Zeit, das Betriebssystem auf den restlichen Servern zu aktualisieren. <br><br><h1>  Um es zusammenzufassen </h1><br>  Da dieser Fehler die Verarbeitung von NIC RX-Warteschlangen f√ºr Hunderte von Millisekunden stoppte, verursachte er gleichzeitig eine gro√üe Verz√∂gerung bei kurzen Verbindungen und eine Verz√∂gerung in der Mitte der Verbindung, beispielsweise zwischen MySQL-Abfragen und Antwortpaketen. <br><br>       ,   Kubernetes,            .    Kubernetes    . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de477390/">https://habr.com/ru/post/de477390/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de477378/index.html">Mixed Agile - Waterfall-Ansatz bei der Implementierung von Gesch√§ftsanwendungen (auch bekannt als Agile-like)</a></li>
<li><a href="../de477382/index.html">Esport - Profit machen: Mercedes, Megaphon, Wetten und Branding f√ºr den Esport</a></li>
<li><a href="../de477384/index.html">Konferenz ‚ÄûInformationssicherheit. Bedrohungen der Gegenwart und Zukunft ‚Äú</a></li>
<li><a href="../de477386/index.html">Sicherheitswoche 48: Gigantischer Datenverlust und WhatsApp-Sicherheitsl√ºcke</a></li>
<li><a href="../de477388/index.html">NILFS2 - kugelsicheres Dateisystem f√ºr / home</a></li>
<li><a href="../de477392/index.html">Mikrofon √∂ffnen: Backend. Wir laden Referenten ein</a></li>
<li><a href="../de477396/index.html">Wie melde ich mich f√ºr einen Kurs an und ... gehe zum Ende</a></li>
<li><a href="../de477400/index.html">√úber den Beruf des Produktmanagers: Wie erreicht man das Ideal?</a></li>
<li><a href="../de477402/index.html">Bereitstellen des Keras Deep Learning-Modells als Python-Webanwendung</a></li>
<li><a href="../de477404/index.html">Das Problem des h√§ufigen Erstellens und L√∂schens von Objekten in C ++</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
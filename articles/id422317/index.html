<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎃 👎🏼 👶🏿 Mengapa TPU begitu baik untuk pembelajaran yang mendalam? 🚀 🧒🏻 🕛</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Prosesor tensor generasi ke-3 

 Google Tensor Processor adalah Sirkuit Terpadu Tujuan Khusus ( ASIC ) yang dikembangkan dari bawah ke atas oleh Googl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mengapa TPU begitu baik untuk pembelajaran yang mendalam?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422317/"><img src="https://habrastorage.org/webt/hc/p7/cd/hcp7cda1npc6ylbq16nwwcsyxd4.jpeg"><br>  <i>Prosesor tensor generasi ke-3</i> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Google Tensor Processor</a> adalah Sirkuit Terpadu Tujuan Khusus ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ASIC</a> ) yang dikembangkan dari bawah ke atas oleh Google untuk melakukan tugas pembelajaran mesin.  Dia bekerja pada beberapa produk Google utama, termasuk Translate, Photos, Search Assistant, dan Gmail.  Cloud TPU memberikan manfaat skalabilitas dan kemudahan penggunaan bagi semua pengembang dan ilmuwan data yang meluncurkan model pembelajaran mesin mutakhir di Google Cloud.  Di Google Next '18, kami mengumumkan bahwa Cloud TPU v2 sekarang tersedia untuk semua pengguna, termasuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">akun uji coba gratis</a> , dan Cloud TPU v3 tersedia untuk pengujian alfa. <br><a name="habracut"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/f34/b73/cee/f34b73ceecf379f47dd446f0cc8b1a7c.jpg"><br><br>  Tetapi banyak orang bertanya - apa perbedaan antara CPU, GPU dan TPU?  Kami membuat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">situs demo</a> tempat presentasi dan animasi berada yang menjawab pertanyaan ini.  Dalam posting ini, saya ingin membahas fitur-fitur tertentu dari konten situs ini. <br><br><h2>  Bagaimana cara kerja jaringan saraf? </h2><br>  Sebelum mulai membandingkan CPU, GPU, dan TPU, mari kita lihat perhitungan seperti apa yang diperlukan untuk pembelajaran mesin - dan khususnya, untuk jaringan saraf. <br><br>  Bayangkan, misalnya, bahwa kita menggunakan jaringan saraf lapis tunggal untuk mengenali angka tulisan tangan, seperti yang ditunjukkan pada diagram berikut: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d6/bf4/585/2d6bf4585be28678f66652fd77ecb2f8.png"><br><br>  Jika gambar adalah kisi 28x28 piksel dalam skala abu-abu, itu dapat dikonversi menjadi vektor nilai 784 (pengukuran).  Neuron yang mengenali angka 8 mengambil nilai-nilai ini dan mengalikannya dengan nilai parameter (garis merah dalam diagram). <br><br>  Parameter berfungsi sebagai filter, mengekstraksi fitur data yang menunjukkan kesamaan gambar dan bentuk 8: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/020/141/559/0201415596ab1132ba07a3b430a2fa34.gif"><br><br>  Ini adalah penjelasan paling sederhana dari klasifikasi data oleh jaringan saraf.  Perkalian data dengan parameter yang terkait dengannya (pewarnaan poin) dan penambahannya (jumlah poin di sebelah kanan).  Hasil tertinggi menunjukkan kecocokan terbaik antara data yang dimasukkan dan parameter yang sesuai, yang, kemungkinan besar, akan menjadi jawaban yang benar. <br><br>  Sederhananya, jaringan saraf perlu melakukan sejumlah besar perkalian dan penambahan data dan parameter.  Seringkali kita mengaturnya dalam bentuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perkalian matriks</a> , yang mungkin Anda temui dalam aljabar di sekolah.  Oleh karena itu, masalahnya adalah melakukan sejumlah besar perkalian matriks secepat mungkin, menghabiskan energi sesedikit mungkin. <br><br><h2>  Bagaimana cara kerja CPU? </h2><br>  Bagaimana cara CPU mendekati tugas ini?  CPU adalah prosesor tujuan umum berdasarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">arsitektur von Neumann</a> .  Ini berarti bahwa CPU bekerja dengan perangkat lunak dan memori sebagai berikut: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/963/029/620/96302962031a0a23ecf34b868d194161.gif"><br><br>  Keuntungan utama dari CPU adalah fleksibilitas.  Berkat arsitektur von Neumann, Anda dapat mengunduh perangkat lunak yang sangat berbeda untuk jutaan tujuan yang berbeda.  CPU dapat digunakan untuk pengolah kata, kontrol mesin roket, transaksi bank, klasifikasi gambar menggunakan jaringan saraf. <br><br>  Tetapi karena CPU sangat fleksibel, peralatan tidak selalu tahu sebelumnya apa operasi berikutnya sampai membaca instruksi selanjutnya dari perangkat lunak.  CPU perlu menyimpan hasil setiap perhitungan dalam memori yang terletak di dalam CPU (yang disebut register, atau <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">cache L1</a> ).  Akses ke memori ini menjadi minus dari arsitektur CPU, yang dikenal sebagai bottleneck arsitektur von Neumann.  Dan meskipun sejumlah besar perhitungan untuk jaringan saraf membuat langkah-langkah di masa depan dapat diprediksi, masing-masing <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">perangkat logika aritmatika dari</a> CPU (ALU, komponen yang menyimpan dan mengendalikan pengganda dan penambah) melakukan operasi secara berurutan, mengakses memori setiap kali, yang membatasi keseluruhan throughput dan mengkonsumsi sejumlah besar energi . <br><br><h2>  Bagaimana cara kerja GPU </h2><br>  Untuk meningkatkan throughput dibandingkan dengan CPU, GPU menggunakan strategi sederhana: mengapa tidak mengintegrasikan ribuan ALU ke dalam prosesor?  GPU modern berisi sekitar 2500 - 5000 ALU pada prosesor, yang memungkinkan untuk melakukan ribuan perkalian dan penambahan dalam satu waktu. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fbb/bcb/17b/fbbbcb17b7732e20d2658d5e76023beb.gif"><br><br>  Arsitektur seperti itu bekerja dengan baik dengan aplikasi yang membutuhkan paralelisasi besar-besaran, seperti, misalnya, perkalian matriks dalam jaringan saraf.  Dengan beban pelatihan khusus deep learning (GO), throughput dalam hal ini meningkat dengan urutan besarnya dibandingkan dengan CPU.  Karena itu, hari ini GPU adalah arsitektur prosesor paling populer untuk GO. <br><br>  Tetapi GPU masih tetap merupakan prosesor tujuan umum yang harus mendukung sejuta aplikasi dan perangkat lunak berbeda.  Dan ini membawa kita kembali ke masalah mendasar dari bottleneck arsitektur von Neumann.  Untuk setiap perhitungan dalam ribuan ALU, GPU, perlu untuk merujuk ke register atau memori bersama untuk membaca dan menyimpan hasil perhitungan menengah.  Karena GPU melakukan lebih banyak komputasi paralel pada ribuan ALUnya, GPU juga menghabiskan lebih banyak energi secara proporsional pada akses memori dan memakan area yang luas. <br><br><h2>  Bagaimana cara kerja TPU? </h2><br>  Ketika kami mengembangkan TPU di Google, kami membangun arsitektur yang dirancang untuk tugas tertentu.  Alih-alih mengembangkan prosesor tujuan umum, kami mengembangkan prosesor matriks yang dikhususkan untuk bekerja dengan jaringan saraf.  TPU tidak akan dapat bekerja dengan pengolah kata, mengendalikan mesin roket atau melakukan transaksi perbankan, tetapi ia dapat memproses sejumlah besar perkalian dan penambahan untuk jaringan saraf pada kecepatan luar biasa, sambil mengonsumsi lebih sedikit energi dan pas dalam volume fisik yang lebih kecil. <br><br>  Hal utama yang memungkinkannya untuk melakukan ini adalah penghapusan radikal dari bottleneck arsitektur von Neumann.  Karena tugas utama TPU adalah pemrosesan matriks, pengembang sirkuit terbiasa dengan semua langkah perhitungan yang diperlukan.  Oleh karena itu, mereka dapat menempatkan ribuan pengganda dan tambahan, dan menghubungkannya secara fisik, membentuk matriks fisik yang besar.  Ini disebut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">arsitektur array pipelined</a> .  Dalam kasus Cloud TPU v2, dua array pipa 128 x 128 digunakan, yang secara total memberikan 32.768 ALU untuk nilai titik-mengambang 16-bit pada satu prosesor. <br><br>  Mari kita lihat bagaimana array pipelined melakukan perhitungan untuk jaringan saraf.  Pertama, TPU memuat parameter dari memori ke dalam matriks pengganda dan tambahan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ec/de3/fc6/9ecde3fc6d69116db89aacd83bdf15e5.gif"><br><br>  TPU kemudian memuat data dari memori.  Setelah menyelesaikan setiap perkalian, hasilnya ditransmisikan ke faktor-faktor berikut, sambil melakukan penambahan.  Oleh karena itu, output akan menjadi jumlah dari semua perkalian data dan parameter.  Sepanjang proses komputasi volumetrik dan transfer data, akses ke memori sama sekali tidak diperlukan. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/04a/ef8/b31/04aef8b31b8eb550ba093df4eb811d58.gif"><br><br>  Oleh karena itu, TPU menunjukkan throughput yang lebih besar ketika menghitung untuk jaringan saraf, mengkonsumsi lebih sedikit energi dan mengambil lebih sedikit ruang. <br><br><h2>  Keuntungan: 5 kali lebih murah </h2><br>  Apa manfaat arsitektur TPU?  Biaya.  Berikut adalah biaya Cloud TPU v2 untuk Agustus 2018, pada saat penulisan: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e2f/340/d86/e2f340d861ef00ac9ceac0e7d6dc5f24.png"><br>  Biaya kerja normal dan TPU untuk berbagai wilayah Google Cloud <br><br>  Stanford University mendistribusikan serangkaian tes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">DAWNBench</a> yang mengukur kinerja sistem pembelajaran yang mendalam.  Di sana Anda dapat melihat berbagai kombinasi tugas, model, dan platform komputasi, serta hasil pengujian yang sesuai. <br><br>  Pada akhir kompetisi di bulan April 2018, biaya pelatihan minimum untuk prosesor dengan arsitektur selain TPU adalah $ 72,40 (untuk pelatihan ResNet-50 dengan akurasi 93% pada ImageNet pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">contoh lokasi</a> ).  Dengan Cloud TPU v2, pelatihan ini dapat dilakukan untuk $ 12,87.  Ini kurang dari 1/5 dari biaya.  Itulah kekuatan arsitektur yang dirancang khusus untuk jaringan saraf. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id422317/">https://habr.com/ru/post/id422317/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id422303/index.html">SQL Builder Terbaik - gunakan jOOQ di Android</a></li>
<li><a href="../id422305/index.html">Distribusi jumlah pekerja Rusia berdasarkan gaji berdasarkan survei online besar pada platform non-spesialis</a></li>
<li><a href="../id422309/index.html">Bagaimana cara melindungi data dalam jaringan cloud neural - metode enkripsi baru diusulkan</a></li>
<li><a href="../id422311/index.html">Menarik dan kegunaan python. Bagian 2</a></li>
<li><a href="../id422315/index.html">Cara bertahan hidup pemburu serangga: perjuangan harian untuk mendapatkan penghasilan</a></li>
<li><a href="../id422319/index.html">Untuk pertama kalinya, tim Rusia masuk ke akselerator ilmiah terbesar IndieBio</a></li>
<li><a href="../id422321/index.html">Optimalisasi kerja dengan prototipe di mesin JavaScript</a></li>
<li><a href="../id422323/index.html">Peretas: Rusia dan Cina</a></li>
<li><a href="../id422325/index.html">DevDay tentang pengujian: Santai. Uji dengan mudah</a></li>
<li><a href="../id422327/index.html">Jadwal Proyek vs Backlog: Pertempuran Tanpa Peluang</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
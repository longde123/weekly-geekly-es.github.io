<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîÆ üïò ü§öüèæ Um rob√¥ de desenho para realizar cenas do cotidiano e at√© hist√≥rias ü¶è üë®üèæ‚Äçüç≥ üìô</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Se lhe pedissem para desenhar uma imagem de v√°rias pessoas em equipamento de esqui, de p√© na neve, √© prov√°vel que voc√™ comece com um esbo√ßo de tr√™s ou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Um rob√¥ de desenho para realizar cenas do cotidiano e at√© hist√≥rias</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/457200/"><p> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/657/93f/e0f/65793fe0f0e42b382c46426806424e36.png" alt="Bot de desenho" width="1024" height="414"></a> </p><br><p>  Se lhe pedissem para desenhar uma imagem de v√°rias pessoas em equipamento de esqui, de p√© na neve, √© prov√°vel que voc√™ comece com um esbo√ßo de tr√™s ou quatro pessoas posicionadas razoavelmente no centro da tela, depois esboce nos esquis sob suas p√©s.  Embora n√£o tenha sido especificado, voc√™ pode optar por adicionar uma mochila a cada um dos esquiadores para combinar com as expectativas sobre o que os esquiadores estariam usando.  Por fim, voc√™ preenche cuidadosamente os detalhes, talvez pintando suas roupas de azul, de cachec√≥is cor de rosa, tudo contra um fundo branco, tornando essas pessoas mais realistas e garantindo que os arredores correspondam √† descri√ß√£o.  Finalmente, para tornar a cena mais v√≠vida, voc√™ pode at√© desenhar em algumas pedras marrons projetadas na neve para sugerir que esses esquiadores est√£o nas montanhas. </p><br><p>  Agora h√° um bot que pode fazer tudo isso. </p><a name="habracut"></a><br><p>  A nova tecnologia de IA desenvolvida no Microsoft Research AI pode entender uma descri√ß√£o de linguagem natural, esbo√ßar um layout da imagem, sintetizar a imagem e refinar detalhes com base no layout e nas palavras individuais fornecidas.  Em outras palavras, esse bot pode gerar imagens a partir de descri√ß√µes de texto semelhantes √†s legendas das cenas do dia a dia.  Esse mecanismo deliberado produziu um aumento significativo na qualidade da imagem gerada em compara√ß√£o com a t√©cnica mais avan√ßada anterior para gera√ß√£o de texto em imagem para cenas cotidianas complicadas, de acordo com os resultados dos testes padr√£o da ind√∫stria relatados em ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Text-driven Text-driven s√≠ntese de imagem por meio de treinamento adverso</a> ‚Äù, a ser publicado este m√™s em Long Beach, Calif√≥rnia, na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Confer√™ncia IEEE de 2019 sobre vis√£o computacional e reconhecimento de padr√µes</a> (CVPR 2019).  Este √© um projeto de colabora√ß√£o entre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pengchuan Zhang</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Qiuyuan Huang</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Jianfeng Gao</a> da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Microsoft Research AI</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lei Zhang</a> da Microsoft, Xiaodong He da JD AI Research e Wenbo Li e Siwei Lyu da Universidade de Albany, SUNY (enquanto Wenbo Li trabalhou como estagi√°rio na Microsoft Research AI). </p><br><p>  Existem dois principais desafios intr√≠nsecos ao problema do bot de desenho baseado em descri√ß√£o.  A primeira √© que muitos tipos de objetos podem aparecer nas cenas cotidianas e o bot deve ser capaz de entender e desenhar todos eles.  Os m√©todos de gera√ß√£o de texto para imagem anteriores usam pares de legenda de imagem que fornecem apenas um sinal de supervis√£o de granula√ß√£o muito grossa para gerar objetos individuais, limitando sua qualidade de gera√ß√£o de objetos.  Nesta nova tecnologia, os pesquisadores usam o conjunto de dados COCO que cont√©m r√≥tulos e mapas de segmenta√ß√£o para 1,5 milh√£o de inst√¢ncias de objetos em 80 classes de objetos comuns, permitindo que o bot aprenda o conceito e a apar√™ncia desses objetos.  Esse sinal supervisionado de baixa granularidade para gera√ß√£o de objetos melhora significativamente a qualidade da gera√ß√£o para essas classes de objetos comuns. </p><br><p>  O segundo desafio est√° na compreens√£o e gera√ß√£o dos relacionamentos entre v√°rios objetos em uma cena.  Foi obtido grande sucesso na gera√ß√£o de imagens que cont√™m apenas um objeto principal para v√°rios dom√≠nios espec√≠ficos, como rostos, p√°ssaros e objetos comuns.  No entanto, gerar cenas mais complexas contendo v√°rios objetos com relacionamentos semanticamente significativos entre esses objetos continua sendo um desafio significativo na tecnologia de gera√ß√£o de texto em imagem.  Esse novo bot de desenho aprendeu a gerar o layout de objetos a partir de padr√µes de co-ocorr√™ncia no conjunto de dados COCO para gerar uma imagem condicionada no layout pr√©-gerado. </p><br><h3>  Gera√ß√£o de imagem atenta e orientada a objetos </h3><br><p>  No centro do desenho bot da Microsoft Research AI est√° uma tecnologia conhecida como Generative Adversarial Network, ou GAN.  O GAN consiste em dois modelos de aprendizado de m√°quina - um gerador que gera imagens a partir de descri√ß√µes de texto e um discriminador que usa descri√ß√µes de texto para julgar a autenticidade das imagens geradas.  O gerador tenta obter imagens falsas al√©m do discriminador;  o discriminador, por outro lado, nunca quer ser enganado.  Trabalhando juntos, o discriminador empurra o gerador para a perfei√ß√£o. </p><br><p>  O bot de desenho foi treinado em um conjunto de dados de 100.000 imagens, cada uma com r√≥tulos de objetos salientes e mapas de segmenta√ß√£o e cinco legendas diferentes, permitindo que os modelos concebessem objetos individuais e rela√ß√µes sem√¢nticas entre objetos.  O GAN, por exemplo, aprende como um cachorro deve ser ao comparar imagens com e sem descri√ß√µes de c√£es. </p><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/27e/b5f/e0a/27eb5fe0ab38f35180ba6558f15f0456.png" alt="Figura 1: Uma cena complexa com v√°rios objetos e relacionamentos." width="273" height="272"></a> <br><p>  Figura 1: Uma cena complexa com v√°rios objetos e relacionamentos. </p><br><p>  Os GANs funcionam bem ao gerar imagens contendo apenas um objeto saliente, como um rosto humano, p√°ssaros ou c√£es, mas a qualidade fica estagnada com cenas cotidianas mais complexas, como a descrita como ‚ÄúUma mulher usando capacete est√° montando um cavalo‚Äù (consulte a Figura 1.) Isso ocorre porque essas cenas cont√™m v√°rios objetos (mulher, capacete, cavalo) e ricas rela√ß√µes sem√¢nticas entre eles (capacete de mulher, cavalo de passeio).  O bot deve primeiro entender esses conceitos e coloc√°-los na imagem com um layout significativo.  Depois disso, √© necess√°rio um sinal mais supervisionado capaz de ensinar a gera√ß√£o de objetos e a gera√ß√£o de layout para cumprir esta tarefa de compreens√£o de linguagem e gera√ß√£o de imagem. </p><br><p>  √Ä medida que os humanos desenham essas cenas complicadas, primeiro decidimos sobre os principais objetos a serem desenhados e fazemos um layout colocando caixas delimitadoras para esses objetos na tela.  Em seguida, focamos em cada objeto, verificando repetidamente as palavras correspondentes que descrevem esse objeto.  Para capturar essa caracter√≠stica humana, os pesquisadores criaram o que chamavam de GAN atento a objetos, ou ObjGAN, para modelar matematicamente o comportamento humano da aten√ß√£o centrada no objeto.  O ObjGAN faz isso dividindo o texto de entrada em palavras individuais e combinando essas palavras com objetos espec√≠ficos na imagem. </p><br><p>  Os seres humanos geralmente conferem dois aspectos para refinar o desenho: o realismo de objetos individuais e a qualidade dos patches de imagem.  O ObjGAN tamb√©m imita esse comportamento introduzindo dois discriminadores - um discriminador em termos de objetos e um discriminador em termos de patch.  O discriminador em termos de objeto est√° tentando determinar se o objeto gerado √© realista ou n√£o e se o objeto √© consistente com a descri√ß√£o da senten√ßa.  O discriminador em rela√ß√£o ao patch est√° tentando determinar se esse patch √© realista ou n√£o e se esse patch √© consistente com a descri√ß√£o da senten√ßa. </p><br><h3>  Trabalho relacionado: visualiza√ß√£o de hist√≥rias </h3><br><p>  Modelos de gera√ß√£o de texto em imagem de √∫ltima gera√ß√£o podem gerar imagens realistas de p√°ssaros com base em uma descri√ß√£o de frase √∫nica.  No entanto, a gera√ß√£o de texto em imagem pode ir muito al√©m da s√≠ntese de uma √∫nica imagem com base em uma frase.  Em " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">StoryGAN: um GAN condicional seq√ºencial para visualiza√ß√£o de hist√≥rias</a> ", <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Jianfeng Gao,</a> da Microsoft Research, junto com Zhe Gan, Jingjing Liu e Yu Cheng, do Microsoft Dynamics 365 AI Research, Yitong Li, David Carlson e Lawrence Carin, da Universidade Duke, Yelong Shen. da Tencent AI Research e Yuexin Wu, da Universidade Carnegie Mellon, d√£o um passo adiante e prop√µem uma nova tarefa, chamada Visualiza√ß√£o de Hist√≥rias.  Dado um par√°grafo com v√°rias frases, uma hist√≥ria completa pode ser visualizada, gerando uma sequ√™ncia de imagens, uma para cada frase.  Essa √© uma tarefa desafiadora, pois o bot de desenho n√£o √© apenas necess√°rio para imaginar um cen√°rio adequado √† hist√≥ria, modelar as intera√ß√µes entre os diferentes personagens que aparecem na hist√≥ria, mas tamb√©m deve ser capaz de manter a consist√™ncia global entre cenas e personagens din√¢micos.  Esse desafio n√£o foi enfrentado por nenhum m√©todo de gera√ß√£o de imagem ou v√≠deo. </p><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/04c/5c0/39c/04c5c039ca8dc39e2f47ffabb9437db7.png" alt="Figura 2: Visualiza√ß√£o da hist√≥ria vs. gera√ß√£o simples de imagens." width="1024" height="454"></a> <br><p>  Figura 2: Visualiza√ß√£o da hist√≥ria vs.  gera√ß√£o simples de imagens. </p><br><p>  Os pesquisadores criaram um novo modelo de gera√ß√£o de hist√≥ria para imagem-sequ√™ncia, StoryGAN, baseado na estrutura GAN condicional seq√ºencial.  Esse modelo √© √∫nico, pois consiste em um codificador de contexto profundo que rastreia dinamicamente o fluxo da hist√≥ria e em dois discriminadores nos n√≠veis da hist√≥ria e da imagem para melhorar a qualidade da imagem e a consist√™ncia das seq√º√™ncias geradas.  O StoryGAN tamb√©m pode ser estendido naturalmente para edi√ß√£o interativa de imagens, onde uma imagem de entrada pode ser editada sequencialmente com base nas instru√ß√µes de texto.  Nesse caso, uma sequ√™ncia de instru√ß√µes do usu√°rio servir√° como entrada da "hist√≥ria".  Dessa forma, os pesquisadores modificaram os conjuntos de dados existentes para criar os conjuntos de dados CLEVR-SV e Pororo-SV, conforme mostrado na Figura 2. </p><br><h3>  Aplica√ß√µes pr√°ticas - uma hist√≥ria real </h3><br><p>  A tecnologia de gera√ß√£o de texto em imagem pode encontrar aplica√ß√µes pr√°ticas que funcionam como uma esp√©cie de assistente de esbo√ßo para pintores e designers de interiores, ou como uma ferramenta para edi√ß√£o de fotos ativada por voz.  Com mais poder computacional, os pesquisadores imaginam a tecnologia que gera filmes de anima√ß√£o baseados em roteiros, aumentando o trabalho que os realizadores fazem removendo parte do trabalho manual envolvido. </p><br><p>  Por enquanto, as imagens geradas ainda est√£o longe da foto realista.  Objetos individuais quase sempre revelam falhas, como rostos desfocados e / ou √¥nibus com formas distorcidas.  Essas falhas s√£o uma indica√ß√£o clara de que um computador, n√£o um humano, criou as imagens.  No entanto, a qualidade das imagens ObjGAN √© significativamente melhor do que as melhores imagens GAN anteriores da categoria e serve como um marco no caminho em dire√ß√£o a uma intelig√™ncia gen√©rica e humana que aumenta as capacidades humanas. </p><br><p>  Para IAs e humanos compartilharem o mesmo mundo, cada um deve ter uma maneira de interagir com o outro.  Linguagem e vis√£o s√£o as duas modalidades mais importantes para humanos e m√°quinas interagirem entre si.  A gera√ß√£o de texto para imagem √© uma tarefa importante que promove a pesquisa de intelig√™ncia multimodal com vis√£o de linguagem. </p><br><p>  Os pesquisadores que criaram este trabalho emocionante esperam compartilhar essas descobertas com os participantes da CVPR em Long Beach e ouvir o que voc√™ pensa.  Enquanto isso, fique √† vontade para conferir o c√≥digo-fonte aberto do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ObjGAN</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">StoryGAN</a> no GitHub </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt457200/">https://habr.com/ru/post/pt457200/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt457190/index.html">Tratamos os neg√≥cios atrav√©s da implementa√ß√£o de sistemas de CRM</a></li>
<li><a href="../pt457192/index.html">Airbus assume novos patamares com a realidade mista da Microsoft</a></li>
<li><a href="../pt457194/index.html">Airbus atinge novos patamares com a ajuda da tecnologia de realidade mista da Microsoft</a></li>
<li><a href="../pt457196/index.html">Petty little joy # 5: Dynaconf - gerenciando configura√ß√µes no projeto</a></li>
<li><a href="../pt457198/index.html">A rede neural aprendeu a desenhar cenas complexas a partir de uma descri√ß√£o textual</a></li>
<li><a href="../pt457202/index.html">Como escolhemos id√©ias para o desenvolvimento de nossos produtos: o fornecedor deve poder ouvir ...</a></li>
<li><a href="../pt457204/index.html">Windows PowerShell e caminhos longos</a></li>
<li><a href="../pt457206/index.html">SQL Index Manager - uma longa hist√≥ria sobre o SQL Server, escava√ß√µes graves e manuten√ß√£o de √≠ndices</a></li>
<li><a href="../pt457208/index.html">Gerando robots.txt dinamicamente para sites ASP.NET Core com base no ambiente</a></li>
<li><a href="../pt457210/index.html">Armazene recursos est√°ticos em sua hospedagem</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
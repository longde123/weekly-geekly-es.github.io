<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöô üèáüèø üë©üèø‚Äçüéì Usando um olho de peixe em um Raspberry Pi 3 com ROS - Parte 2 ‚ôëÔ∏è üéÖüèæ üõÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Boa tarde, queridos leitores de Habr! Esta √© a segunda parte da hist√≥ria sobre o uso da c√¢mera olho de peixe no Raspberry Pi 3. A primeira parte pode ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Usando um olho de peixe em um Raspberry Pi 3 com ROS - Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429894/">  Boa tarde, queridos leitores de Habr!  Esta √© a segunda parte da hist√≥ria sobre o uso da c√¢mera olho de peixe no Raspberry Pi 3. A primeira parte pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  Neste artigo, falarei sobre como calibrar uma c√¢mera olho de peixe e usar a c√¢mera para detectar objetos usando o pacote find_object_2d.  Quem se importa, por favor, debaixo do gato. <br><a name="habracut"></a><br>
<h2>  Calibre uma c√¢mera olho de peixe usando camera_calibration </h2><br>  Aqui, descrevo o procedimento de calibra√ß√£o com base no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">manual</a> oficial no portal ros.org. <br><br>  Para realizar a calibra√ß√£o, precisamos do pacote de calibra√ß√£o da c√¢mera.  Podemos instal√°-lo com o apt: <br><br><pre><code class="bash hljs">sudo apt-get install ros-kinetic-camera-calibration</code> </pre> <br>  Vamos precisar de um modelo quadriculado.  Fa√ßa o download do modelo no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">manual</a> oficial em ros.org e imprima-o.  Por conveni√™ncia, colei em uma placa de madeira compensada: <br><br><img src="https://habrastorage.org/webt/cz/qp/g8/czqpg8rutw1ut-h7ogrjqxwnytk.jpeg" alt="imagem"><br><br>  Vamos executar o programa de calibra√ß√£o: <br><br><pre> <code class="bash hljs">rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/usb_cam/image_raw camera:=/usb_cam</code> </pre><br>  Vamos tirar uma foto: <br><br><img src="https://habrastorage.org/webt/_n/t0/ib/_nt0ib2ohbvxtk8lomsx197swke.png" alt="imagem"><br><br>  Mova um pouco o modelo e aguarde at√© que o modelo seja selecionado no quadro (linhas coloridas com pontos n√£o aparecer√£o no modelo). <br><br><img src="https://habrastorage.org/webt/dm/du/yn/dmduyniktnl1joqutysbtv9ugf8.png" alt="imagem"><br><br><img src="https://habrastorage.org/webt/ir/w3/fq/irw3fq6yv4z-bfzictvsqlht93c.png" alt="imagem"><br><br>  Mova o modelo um pouco mais para o lado.  Para realizar a calibra√ß√£o com sucesso, precisamos executar uma s√©rie de movimentos do modelo na frente da c√¢mera, de um lado para o outro, para que o modelo caia em todas as posi√ß√µes angulares no campo de vis√£o da c√¢mera (esquerda, direita, superior e inferior).  √Ä direita da janela de imagem da c√¢mera na janela do programa est√° o painel de registro com tr√™s barras de progresso: <br><br><ul><li>  X captura o movimento do padr√£o na dire√ß√£o esquerda / direita (horizontal) no campo de vis√£o da c√¢mera </li><li>  Y captura o movimento do padr√£o na dire√ß√£o para cima / baixo (horizontal) no campo de vis√£o da c√¢mera </li><li>  Tamanho captura a abordagem / remo√ß√£o do modelo da c√¢mera e inclina-a em rela√ß√£o √† c√¢mera. </li><li>  Inclinar fixa a inclina√ß√£o do modelo para a esquerda, direita, para cima e para baixo (chanfro). </li></ul><br>  Portanto, para uma calibra√ß√£o bem-sucedida, √© importante que o modelo apare√ßa em diferentes cantos do quadro, ocupe todo o quadro e tamb√©m seja inclinado para a esquerda, direita, para cima e para baixo. <br><br>  Calibrar uma c√¢mera olho de peixe em seu Raspberry Pi pode demorar um pouco, portanto seja paciente.  Meu procedimento de calibra√ß√£o levou 20 minutos. <br><br>  Quando a calibra√ß√£o estiver conclu√≠da, o bot√£o Calibrar deve ser ativado (destacado em cores): <br><br><img src="https://habrastorage.org/webt/lq/d-/d2/lqd-d26xbjyaishe5noij5oan1k.png" alt="imagem"><br><br>  Tamb√©m podemos ver os resultados da calibra√ß√£o no terminal: <br><br><img src="https://habrastorage.org/webt/5c/jv/kt/5cjvktr9rxlpwwfq0kfk1kk3b7o.png" alt="imagem"><br><br>  Se voc√™ estiver satisfeito com o resultado, pressione o bot√£o COMMIT.  A janela do programa ser√° fechada e voc√™ ver√° a mensagem "escrevendo dados de calibra√ß√£o em ..." no terminal. <br><br>  Verifique se o arquivo especificado foi criado: <br><br><pre> <code class="bash hljs">ll ~/.ros/camera_info/head_camera.yaml -rw-rw-r-- 1 vladimir vladimir 592 Apr 14 14:02 /home/vladimir/.ros/camera_info/head_camera.yaml</code> </pre><br>  Calibra√ß√£o conclu√≠da.  Agora, os dados de calibra√ß√£o obtidos podem ser usados ‚Äã‚Äãna localiza√ß√£o visual e nos algoritmos SLAM no ROS. <br><br><h2>  Detectando objetos usando o find_object_2d </h2><br>  A instala√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pacote √©</a> bastante simples.  Instale-o a partir do reposit√≥rio apt no Ubuntu 16.04 para ROS Kinetic: <br><br><pre> <code class="bash hljs">sudo apt-get install ros-kinetic-find-object-2d <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> /opt/ros/kinetic/setup.bash</code> </pre><br>  Execute o ROS master e o rqt_image_view: <br><br><pre> <code class="bash hljs">roscore roslaunch usb_cam usb_cam-test.launch</code> </pre><br>  Usando o seguinte comando, inicie o n√≥ do detector: <br><br><pre> <code class="bash hljs">rosrun find_object_2d find_object_2d image:=/usb_cam/image_raw</code> </pre><br>  A janela do programa de detec√ß√£o √© aberta: <br><br><img src="https://habrastorage.org/webt/6l/_u/kb/6l_ukb-8wjw2cylfuloapxtpdzk.png" alt="imagem"><br><br>  Aqui veremos o fluxo da c√¢mera e o resultado da detec√ß√£o de caracter√≠sticas em objetos. <br>  Para come√ßar, realizaremos treinamento em detectores em nossas instala√ß√µes.  Coloque o primeiro objeto na frente da c√¢mera: <br><br><img src="https://habrastorage.org/webt/2y/hs/nb/2yhsnbkbcr9452owc41wpl_yzxs.png" alt="imagem"><br><br>  Clique com o bot√£o direito do mouse no painel esquerdo de Objetos na janela e a op√ß√£o Adicionar objetos da cena ser√° aberta.  Selecione esta op√ß√£o e a janela para adicionar um objeto ser√° aberta: <br><br><img src="https://habrastorage.org/webt/r3/ey/56/r3ey56zvh_td0ap_etfqdi-nvem.png" alt="imagem"><br><br>  Depois de escolher a melhor posi√ß√£o para o objeto, clique no bot√£o Tirar foto para tirar uma foto do objeto: <br><br><img src="https://habrastorage.org/webt/ao/h6/qk/aoh6qkj0aktn86zjxmwlyn-stg4.png" alt="imagem"><br><br>  Precisamos selecionar o objeto na imagem.  Use o cursor do mouse para selecionar o objeto: <br><br><img src="https://habrastorage.org/webt/ar/l-/6c/arl-6c6qqj88nxbrh1sh7w3fhxw.png" alt="imagem"><br><br>  Clique no bot√£o Avan√ßar para cortar o objeto na imagem e passar para a pr√≥xima etapa.  Depois de cortar a imagem, obtemos o n√∫mero total de recursos caracter√≠sticos detectados no objeto.  Resta apenas pressionar o bot√£o Finalizar para adicionar o objeto ao banco de dados de objetos detectores treinados.  Aqui vemos a √∫ltima etapa do procedimento para adicionar um objeto: <br><br><img src="https://habrastorage.org/webt/ma/jh/pa/majhpayey9z1nntt0i4eaegq6jq.png" alt="imagem"><br><br>  Como resultado, treinamos o detector em um objeto.  Agora voc√™ pode tentar a detec√ß√£o do objeto na cena: <br><br><img src="https://habrastorage.org/webt/q6/vb/7u/q6vb7uerpmydbkvpncoz3buc5d8.png" alt="imagem"><br><br>  Vamos desenhar a posi√ß√£o do objeto detectado no terminal: <br><br><pre> <code class="bash hljs">rosrun find_object_2d print_objects_detected</code> </pre><br>  A sa√≠da ser√° assim: <br><br><pre> <code class="bash hljs">Object 1 detected, Qt corners at (259.387238,103.530960) (448.684052,79.495495) (282.419050,240.049667) (458.438938,199.656717) --- Object 1 detected, Qt corners at (255.340408,104.615120) (451.348079,75.302353) (284.672425,230.382223) (452.696585,197.625600) --- Object 1 detected, Qt corners at (253.440521,102.973320) (447.226440,76.793541) (278.530854,238.918013) (454.377219,197.526599) ---</code> </pre><br>  Vamos listar os t√≥picos: <br><br><pre> <code class="bash hljs">rostopic list</code> </pre><br>  Dois novos t√≥picos apareceram na lista: / objects e / objectsStamped. <br><br>  Exibimos informa√ß√µes sobre os objetos detectados: <br><br><pre> <code class="bash hljs">rostopic <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> /objects</code> </pre><br><pre> <code class="bash hljs">layout: dim: [] data_offset: 0 data: [1.0, 266.0, 177.0, 0.7527905702590942, 0.060980819165706635, 0.00022385441116057336, 0.3012462854385376, 0.8929792046546936, 0.0008534671505913138, 334.9065856933594, 182.55294799804688, 1.0] ---</code> </pre><br>  Aqui, o segundo e o terceiro valores (266,0, 177,0) representam a largura e a altura do objeto.  Todos os outros valores no campo de dados representam uma matriz de homografia 3x3 (usada para calcular a posi√ß√£o e orienta√ß√£o do objeto, bem como os valores de escala e deslocamento). <br><br>  Como mostram as observa√ß√µes, o find_object_2d faz um p√©ssimo trabalho na detec√ß√£o de objetos com uma textura fraca ou sem textura (sem textura).  Al√©m disso, o detector √© ineficaz ao detectar um objeto em um √¢ngulo grande em rela√ß√£o ao objeto (se observarmos o objeto de lado) ou a uma grande dist√¢ncia do objeto. <br><br><img src="https://habrastorage.org/webt/pk/1f/ot/pk1fotpptvtwoym3g6p5g3lfgty.png" alt="imagem"><br><br>  Depois de concluir o trabalho com o detector, o find_object_2d nos oferecer√° para salvar os objetos adicionados no disco. <br><br>  Por enquanto √© tudo.  Boa sorte a todos e at√© breve! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt429894/">https://habr.com/ru/post/pt429894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt429882/index.html">Controle de LEDs RGB via microcontroladores Cypress UDB PSoC</a></li>
<li><a href="../pt429884/index.html">Confer√™ncia PROSTOR 2018: perguntas e respostas sobre o futuro do armazenamento</a></li>
<li><a href="../pt429888/index.html">Calculadora baseada em pilha na placa FPGA do Cyclone IV</a></li>
<li><a href="../pt429890/index.html">Semin√°rio on-line aberto "Redes advers√°rias generativas"</a></li>
<li><a href="../pt429892/index.html">xonsh - python como uma substitui√ß√£o de shell</a></li>
<li><a href="../pt429898/index.html">DMS (Dealership Management System) - Implementa√ß√£o de EcoSystems de informa√ß√£o para gerenciar redes de revendedores</a></li>
<li><a href="../pt429902/index.html">Page Rank na Era da Web 2.0 - Parte 1</a></li>
<li><a href="../pt429904/index.html">Hist√≥rias engra√ßadas e tristes sobre o desenvolvimento de jogos de computador</a></li>
<li><a href="../pt429908/index.html">Como usar corotinas na comida e dormir tranquilamente √† noite</a></li>
<li><a href="../pt429910/index.html">AppsConf Rises</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåñ üë®üèæ‚Äçüè´ ‚õ±Ô∏è Passer Tinder √† Kubernetes ü§Ωüèæ üßóüèæ üàµ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Remarque perev. : Les employ√©s de Tinder ont r√©cemment partag√© certains d√©tails techniques de la migration de leur infrastructure vers Kubernetes. Le ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Passer Tinder √† Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/440278/">  <i><b>Remarque</b></i>  <i><b>perev.</b></i>  <i>: Les employ√©s de Tinder ont r√©cemment partag√© certains d√©tails techniques de la migration de leur infrastructure vers Kubernetes.</i>  <i>Le processus a dur√© pr√®s de deux ans et s'est traduit par le lancement sur K8 d'une plateforme √† tr√®s grande √©chelle compos√©e de 200 services h√©berg√©s sur 48 000 conteneurs.</i>  <i>Quelles difficult√©s int√©ressantes les ing√©nieurs de Tinder ont-ils rencontr√©es et quels r√©sultats sont-ils arriv√©s √† lire dans cette traduction.</i> <br><br><img src="https://habrastorage.org/webt/uq/og/xd/uqogxdavfghsshnu8hvlszhubpe.png"><a name="habracut"></a><br><br><h2>  Pourquoi? </h2><br>  Il y a pr√®s de deux ans, Tinder a d√©cid√© de passer sa plateforme √† Kubernetes.  Kubernetes permettrait √† l'√©quipe Tinder de conteneuriser et de passer √† l'op√©ration avec un effort minimal gr√¢ce √† un <i>d√©ploiement immuable</i> .  Dans ce cas, l'assemblage des applications, leur d√©ploiement et l'infrastructure elle-m√™me seraient uniquement d√©termin√©s par le code. <br><br>  Nous avons √©galement cherch√© une solution au probl√®me d'√©volutivit√© et de stabilit√©.  Lorsque la mise √† l'√©chelle est devenue critique, nous avons souvent d√ª attendre plusieurs minutes pour lancer de nouvelles instances EC2.  Par cons√©quent, l'id√©e de lancer des conteneurs et de commencer √† servir le trafic en quelques secondes au lieu de minutes est devenue tr√®s int√©ressante pour nous. <br><br>  Le processus n'a pas √©t√© facile.  Au cours de la migration, d√©but 2019, le cluster Kubernetes a atteint une masse critique et nous avons commenc√© √† faire face √† divers probl√®mes en raison de la quantit√© de trafic, de la taille du cluster et du DNS.  Au cours de ce voyage, nous avons r√©solu de nombreux probl√®mes int√©ressants li√©s au transfert de 200 services et √† la maintenance du cluster Kubernetes, qui comprend 1 000 n≈ìuds, 15 000 pods et 48 000 conteneurs de travail. <br><br><h2>  Comment? </h2><br>  Depuis janvier 2018, nous sommes pass√©s par diff√©rentes √©tapes de migration.  Nous avons commenc√© par conteneuriser tous nos services et les d√©ployer dans des environnements de test Kubernetes.  En octobre, le processus de transfert m√©thodique de tous les services existants vers Kubernetes a commenc√©.  En mars de l'ann√©e suivante, la ¬´relocalisation¬ª √©tait termin√©e et maintenant la plateforme Tinder fonctionne exclusivement sur Kubernetes. <br><br><h3>  Cr√©er des images pour Kubernetes </h3><br>  Nous avons plus de 30 r√©f√©rentiels de code source pour les microservices fonctionnant dans un cluster Kubernetes.  Le code de ces r√©f√©rentiels est √©crit dans diff√©rents langages (par exemple, Node.js, Java, Scala, Go) avec de nombreux environnements d'ex√©cution pour le m√™me langage. <br><br>  Le syst√®me de construction est con√ßu pour fournir un ¬´contexte de construction¬ª enti√®rement personnalisable pour chaque microservice.  Il se compose g√©n√©ralement d'un Dockerfile et d'une liste de commandes shell.  Leur contenu est enti√®rement personnalisable et, en m√™me temps, tous ces contextes de construction sont √©crits selon un format standardis√©.  La standardisation des contextes de g√©n√©ration permet √† un syst√®me de g√©n√©ration unique de g√©rer tous les microservices. <br><br><img src="https://habrastorage.org/webt/qg/he/8h/qghe8hvhjmsnpwuivvebqk1ne04.png"><br>  <i>Figure 1-1.</i>  <i>Processus de construction standardis√© via le constructeur de conteneurs (Builder)</i> <br><br>  Pour obtenir une coh√©rence maximale entre les ex√©cutions, le m√™me processus de g√©n√©ration est utilis√© pendant le d√©veloppement et les tests.  Nous avons √©t√© confront√©s √† un probl√®me tr√®s int√©ressant: nous avons d√ª d√©velopper un moyen de garantir la coh√©rence de l'environnement d'assemblage sur toute la plateforme.  Pour ce faire, tous les processus d'assemblage sont ex√©cut√©s dans un conteneur <i>Builder</i> sp√©cial. <br><br>  Son impl√©mentation a n√©cessit√© des techniques avanc√©es pour travailler avec Docker.  Builder h√©rite de l'ID utilisateur local et des secrets (tels que la cl√© SSH, les informations d'identification AWS, etc.) n√©cessaires pour acc√©der aux r√©f√©rentiels priv√©s Tinder.  Il monte des r√©pertoires locaux contenant la source pour stocker naturellement les artefacts d'assemblage.  Cette approche am√©liore les performances en √©liminant la n√©cessit√© de copier les artefacts d'assemblage entre le conteneur Builder et l'h√¥te.  Les artefacts d'assemblage stock√©s peuvent √™tre r√©utilis√©s sans configuration suppl√©mentaire. <br><br>  Pour certains services, nous avons d√ª cr√©er un autre conteneur pour faire correspondre l'environnement de compilation avec le runtime (par exemple, pendant le processus d'installation, la biblioth√®que bcrypt Node.js g√©n√®re des artefacts binaires sp√©cifiques √† la plate-forme).  Pendant la compilation, les exigences peuvent varier pour diff√©rents services et le Dockerfile final est compil√© √† la vol√©e. <br><br><h3>  Architecture et migration du cluster Kubernetes </h3><br><h4>  Gestion de la taille du cluster </h4><br>  Nous avons d√©cid√© d'utiliser <b>kube-aws</b> pour d√©ployer automatiquement le cluster sur les instances Amazon EC2.  Au tout d√©but, tout fonctionnait dans un pool commun de n≈ìuds.  Nous avons rapidement r√©alis√© la n√©cessit√© de s√©parer les charges de travail par taille et type d'instances pour une utilisation plus efficace des ressources.  La logique √©tait que le lancement de plusieurs pods multi-threads charg√©s s'est av√©r√© √™tre plus pr√©visible en termes de performances que leur coexistence avec un grand nombre de pods mono-thread. <br><br>  En cons√©quence, nous nous sommes entendus sur: <br><br><ul><li>  <i>m5.4xlarge</i> - pour la surveillance (Prometheus); </li><li>  <i>c5.4xlarge</i> - pour la charge de travail Node.js (charge de travail <i>monothread</i> ); </li><li>  <i>c5.2xlarge</i> - pour Java et Go (charge de travail multithread); </li><li>  <i>c5.4xlarge</i> - pour le panneau de commande (3 n≈ìuds). </li></ul><br><h4>  La migration </h4><br>  L'une des √©tapes pr√©paratoires √† la migration de l'ancienne infrastructure vers Kubernetes a √©t√© de rediriger l'interaction directe existante entre les services vers les nouveaux √©quilibreurs de charge (ELB, Elastic Load Balancers).  Ils ont √©t√© cr√©√©s sur un sous-r√©seau de cloud priv√© virtuel (VPC) sp√©cifique.  Ce sous-r√©seau √©tait connect√© au VPC Kubernetes.  Cela nous a permis de migrer progressivement les modules, sans tenir compte de l'ordre sp√©cifique des d√©pendances de service. <br><br>  Ces points de terminaison ont √©t√© cr√©√©s √† l'aide d'ensembles pond√©r√©s d'enregistrements DNS avec des CNAME pointant vers chaque nouvel ELB.  Pour basculer, nous avons ajout√© un nouvel enregistrement pointant vers la nouvelle ELB du service Kubernetes avec un poids de 0. Ensuite, nous avons d√©fini le Time To Live (TTL) du jeu d'enregistrements sur 0. Apr√®s cela, l'ancien et le nouveau poids ont √©t√© lentement ajust√©s, et finalement 100% de la charge est pass√©e sur le nouveau serveur.  Une fois le changement termin√©, la valeur TTL est revenue √† un niveau plus ad√©quat. <br><br>  Nos modules Java existants g√©raient un DNS TTL faible, mais pas les applications Node.  L'un des ing√©nieurs a r√©√©crit une partie du code du pool de connexions, en l'enveloppant dans un gestionnaire qui mettait √† jour les pools toutes les 60 secondes.  L'approche choisie a tr√®s bien fonctionn√© et sans diminution notable des performances. <br><br><h2>  Les le√ßons </h2><br><h3>  Restrictions relatives aux p√©riph√©riques r√©seau </h3><br>  Au petit matin du 8 janvier 2019, la plateforme Tinder s'est soudainement √©cras√©e.  En r√©ponse √† une augmentation non li√©e de la latence de la plateforme plus t√¥t dans la matin√©e, le nombre de pods et de n≈ìuds dans le cluster a augment√©.  Cela a conduit √† l'√©puisement du cache ARP sur tous nos n≈ìuds. <br><br>  Il existe trois options Linux associ√©es au cache ARP: <br><br><img src="https://habrastorage.org/webt/fq/bp/av/fqbpavle6xhk1ryeup0nd-lrqm0.png"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">source</a> ) <br><br>  <b>gc_thresh3</b> est une limite <b>stricte</b> .  L'apparition dans le journal des entr√©es du formulaire ¬´d√©bordement de table voisine¬ª signifiait que m√™me apr√®s un garbage collection synchrone (GC) dans le cache ARP, il n'y avait pas assez d'espace pour stocker l'enregistrement voisin.  Dans ce cas, le noyau a simplement compl√®tement supprim√© le paquet. <br><br>  Nous utilisons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Flannel</a> comme structure de <i>r√©seau</i> dans Kubernetes.  Les paquets sont transmis via VXLAN.  VXLAN est un tunnel L2, lev√© sur un r√©seau L3.  La technologie utilise l'encapsulation MAC-in-UDP (MAC Address-in-User Datagram Protocol) et vous permet d'√©tendre les segments de r√©seau du 2√®me niveau.  Le protocole de transport dans le r√©seau physique du centre de donn√©es est IP plus UDP. <br><br> <a href=""><img src="https://habrastorage.org/webt/ad/vn/pl/advnplfowrh7mi-6otctfhzm2xs.png"></a> <br>  <i>Figure 2‚Äì1.</i>  <i>Tableau de flanelle ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">source</a> )</i> <br><br><img src="https://habrastorage.org/webt/nz/ti/xz/nztixz_5aer3xofz2drri5uafb8.jpeg"><br>  <i>Figure 2‚Äì2.</i>  <i>Paquet VXLAN ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">source</a> )</i> <br><br>  Chaque n≈ìud de travail Kubernetes alloue un espace d'adressage virtuel avec masque / 24 √† partir du bloc plus grand / 9.  Pour chaque n≈ìud, cela <a href="">signifie</a> une entr√©e dans la table de routage, une entr√©e dans la table ARP (sur l'interface <i>flannel.1</i> ) et une entr√©e dans la table de commutation (FDB).  Ils sont ajout√©s lors du premier d√©marrage du n≈ìud de travail ou lorsque chaque nouveau n≈ìud est d√©tect√©. <br><br>  De plus, la connexion node-pod (ou pod-pod) passe finalement par l'interface <b>eth0</b> (comme illustr√© dans le diagramme Flannel ci-dessus).  Il en r√©sulte une entr√©e suppl√©mentaire dans la table ARP pour chaque source et destination correspondante du n≈ìud. <br><br>  Dans notre environnement, ce type de communication est tr√®s courant.  Pour les objets de type service dans Kubernetes, un ELB est cr√©√© et Kubernetes enregistre chaque n≈ìud dans l'ELB.  ELB ne sait rien des pods et le n≈ìud s√©lectionn√© peut ne pas √™tre la destination finale du paquet.  Le fait est que lorsqu'un n≈ìud re√ßoit un paquet de ELB, il le consid√®re en tenant compte des r√®gles <b>iptables</b> pour un service particulier et s√©lectionne al√©atoirement le pod sur un autre n≈ìud. <br><br>  Au moment de l'√©chec, le cluster comptait 605 n≈ìuds.  Pour les raisons indiqu√©es ci-dessus, cela suffisait pour surmonter la <b>valeur par d√©faut gc_thresh3</b> .  Lorsque cela se produit, non seulement les paquets commencent √† √™tre supprim√©s, mais tout l'espace d'adressage virtuel Flannel avec le masque / 24 dispara√Æt de la table ARP.  Les communications Node-pod et les requ√™tes DNS sont interrompues (DNS est h√©berg√© dans un cluster; voir le reste de cet article pour plus de d√©tails). <br><br>  Pour r√©soudre ce probl√®me, augmentez les valeurs de <b>gc_thresh1</b> , <b>gc_thresh2</b> et <b>gc_thresh3</b> et red√©marrez Flannel pour r√©enregistrer les r√©seaux manquants. <br><br><h4>  Mise √† l'√©chelle DNS inattendue </h4><br>  Au cours du processus de migration, nous avons activement utilis√© DNS pour g√©rer le trafic et transf√©rer progressivement les services de l'ancienne infrastructure vers Kubernetes.  Nous avons d√©fini des valeurs TTL relativement faibles pour les jeux d'enregistrements associ√©s dans Route53.  Lorsque l'ancienne infrastructure fonctionnait sur des instances EC2, notre configuration de r√©solveur pointait vers Amazon DNS.  Nous l'avons pris pour acquis et l'impact du faible TTL sur nos services Amazon (comme DynamoDB) est pass√© presque inaper√ßu. <br><br>  Au fur et √† mesure de la migration des services vers Kubernetes, nous avons constat√© que DNS traitait 250 000 requ√™tes par seconde.  En cons√©quence, les applications ont commenc√© √† subir des d√©lais d'expiration constants et s√©rieux pour les requ√™tes DNS.  Cela s'est produit malgr√© des efforts incroyables pour optimiser et basculer le fournisseur DNS vers CoreDNS (qui a atteint 1000 pods fonctionnant sur 120 c≈ìurs √† pleine charge). <br><br>  En explorant d'autres causes et solutions possibles, nous avons trouv√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article</a> d√©crivant les conditions de <b>concurrence</b> qui affectent le framework de filtrage de paquets <b>netfilter</b> sous Linux.  Les d√©lais d'attente que nous avons observ√©s, ainsi que l'augmentation <b>du</b> compteur <b>insert_failed</b> dans l'interface Flannel, correspondaient aux conclusions de l'article. <br><br>  Le probl√®me survient au stade de la traduction des adresses de r√©seau source et de destination (SNAT et DNAT) et lors de l'entr√©e suivante dans la table <b>conntrack</b> .  L'une des solutions de contournement discut√©es au sein de l'entreprise et propos√©e par la communaut√© √©tait le transfert du DNS vers le n≈ìud de travail lui-m√™me.  Dans ce cas: <br><br><ul><li>  SNAT n'est pas n√©cessaire car le trafic reste √† l'int√©rieur du n≈ìud.  Il n'a pas besoin d'√™tre achemin√© via l'interface <b>eth0</b> . </li><li>  DNAT n'est pas n√©cessaire, car l'IP de destination est locale √† l'h√¥te, et non un pod s√©lectionn√© au hasard selon les r√®gles <b>iptables</b> . </li></ul><br>  Nous avons d√©cid√© de nous en tenir √† cette approche.  CoreDNS a √©t√© d√©ploy√© en tant que DaemonSet dans Kubernetes et nous avons impl√©ment√© un serveur DNS h√¥te local dans <b>resolv.conf de</b> chaque pod en configurant l' <b>indicateur --cluster-dns</b> de la commande <b>kubelet</b> .  Cette solution s'est av√©r√©e efficace pour les d√©lais d'attente DNS. <br><br>  Cependant, nous avons toujours observ√© une perte de paquets et une augmentation du compteur <b>insert_failed</b> dans l'interface Flannel.  Cette situation s'est poursuivie apr√®s l'introduction de la solution de contournement, car nous avons pu exclure SNAT et / ou DNAT uniquement pour le trafic DNS.  Les conditions de course ont persist√© pour d'autres types de trafic.  Heureusement, la plupart de nos packages sont TCP, et lorsqu'un probl√®me survient, ils sont simplement retransmis.  Nous essayons toujours de trouver une solution adapt√©e √† tous les types de trafic. <br><br><h4>  Utilisation d'Envoy pour un meilleur √©quilibrage de charge </h4><br>  Alors que nous migrions les services backend vers Kubernetes, nous avons commenc√© √† souffrir d'une charge d√©s√©quilibr√©e entre les pods.  Nous avons constat√© qu'en raison de HTTP Keepalive, les connexions ELB √©taient suspendues aux premiers pods pr√™ts √† l'emploi de chaque d√©ploiement.  Ainsi, la majeure partie du trafic a transit√© par un petit pourcentage des modules disponibles.  La premi√®re solution que nous avons test√©e a √©t√© de d√©finir le param√®tre MaxSurge √† 100% sur les nouveaux d√©ploiements pour les pires cas.  L'effet √©tait insignifiant et peu prometteur en termes de d√©ploiements plus importants. <br><br>  Une autre solution que nous avons utilis√©e consistait √† augmenter artificiellement les demandes de ressources pour les services essentiels √† la mission.  Dans ce cas, les pods adjacents auraient plus de marge de man≈ìuvre que les autres pods lourds.  √Ä long terme, cela ne fonctionnerait pas non plus en raison du gaspillage de ressources.  De plus, nos applications Node √©taient monothread et, par cons√©quent, ne pouvaient utiliser qu'un seul c≈ìur.  La seule vraie solution √©tait d'utiliser un meilleur √©quilibrage de charge. <br><br>  Nous voulons depuis longtemps appr√©cier pleinement l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Envoy</a> .  La situation actuelle nous a permis de le d√©ployer de mani√®re tr√®s limit√©e et d'obtenir des r√©sultats imm√©diats.  Envoy est un proxy open source de septi√®me niveau hautes performances con√ßu pour les grandes applications SOA.  Il est capable d'appliquer des techniques avanc√©es d'√©quilibrage de charge, notamment des tentatives automatiques, des disjoncteurs et des limites de vitesse globales.  <i>( <b>Remarque sur la traduction</b> : pour plus de d√©tails, consultez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©cent article</a> sur Istio - le maillage de service, qui est bas√© sur Envoy.)</i> <br><br>  Nous sommes arriv√©s avec la configuration suivante: avoir un side-car Envoy pour chaque pod et une seule route, et le cluster - se connecter au conteneur localement par le port.  Pour minimiser les cascades potentielles et maintenir un petit rayon de ¬´dommages¬ª, nous avons utilis√© le parc de pods proxy frontal Envoy, un pour chaque zone de disponibilit√© (AZ) pour chaque service.  Ils se sont tourn√©s vers un m√©canisme de d√©couverte de service simple √©crit par l'un de nos ing√©nieurs, qui a simplement renvoy√© une liste de pods dans chaque AZ pour un service donn√©. <br><br>  Ensuite, les envoy√©s de service ont utilis√© ce m√©canisme de d√©couverte de service avec un cluster et une route en amont.  Nous avons d√©fini des d√©lais d'expiration ad√©quats, augment√© tous les param√®tres du disjoncteur et ajout√© une configuration de relance minimale pour aider √† des pannes uniques et assurer des d√©ploiements transparents.  Avant chacun de ces front-Envoys de service, nous avons plac√© un TCP ELB.  M√™me si le Keepalive de notre couche proxy principale √©tait suspendu √† certains pods Envoy, ils pouvaient toujours g√©rer la charge beaucoup mieux et √©taient configur√©s pour s'√©quilibrer via au moins_une demande dans le backend. <br><br>  Pour le d√©ploiement, nous avons utilis√© le crochet preStop sur les modules d'application et les modules side-car.  Le hook a d√©clench√© une erreur lors de la v√©rification de l'√©tat du point de terminaison admin situ√© sur le sidecar-container et a "dormi" pendant un certain temps afin de permettre aux connexions actives de se terminer. <br><br>  L'une des raisons pour lesquelles nous avons pu avancer si rapidement dans la r√©solution de probl√®mes est li√©e √† des mesures d√©taill√©es que nous avons pu int√©grer facilement dans une installation standard de Prometheus.  Avec eux, il est devenu possible de voir exactement ce qui se passait pendant que nous s√©lectionnions les param√®tres de configuration et redistribuions le trafic. <br><br>  Les r√©sultats ont √©t√© imm√©diats et √©vidents.  Nous avons commenc√© avec les services les plus d√©s√©quilibr√©s, et pour le moment, il fonctionne d√©j√† avant les 12 services les plus importants du cluster.  Cette ann√©e, nous pr√©voyons de passer √† un maillage de service complet avec une d√©couverte de service plus avanc√©e, une coupure de circuit, une d√©tection des valeurs aberrantes, une limitation de la vitesse et un tra√ßage. <br><br> <a href=""><img src="https://habrastorage.org/webt/gy/yg/6s/gyyg6s_l8nlpbktislqy9jp9fma.png" alt="image"></a> <br>  <i>Figure 3‚Äì1.</i>  <i>Convergence CPU d'un service lors de la transition vers Envoy</i> <br><br><img src="https://habrastorage.org/webt/lf/iw/pn/lfiwpneg1uvaruk85ghgcbhoghy.png"><br><br><img src="https://habrastorage.org/webt/ud/ug/8m/udug8mekxc36ql2vohzl-snp3vu.png"><br><br><h2>  R√©sultat final </h2><br>  Gr√¢ce √† notre exp√©rience et √† nos recherches suppl√©mentaires, nous avons constitu√© une solide √©quipe d'infrastructure dot√©e de bonnes comp√©tences dans la conception, le d√©ploiement et l'exploitation de grands clusters Kubernetes.  D√©sormais, tous les ing√©nieurs de Tinder ont les connaissances et l'exp√©rience n√©cessaires pour emballer des conteneurs et d√©ployer des applications dans Kubernetes. <br><br>  Lorsque le besoin de capacit√©s suppl√©mentaires s'est fait sentir sur l'ancienne infrastructure, nous avons d√ª attendre plusieurs minutes pour lancer de nouvelles instances EC2.  Maintenant, les conteneurs d√©marrent et commencent √† traiter le trafic pendant plusieurs secondes au lieu de minutes.  La planification de plusieurs conteneurs sur une seule instance d'EC2 permet √©galement d'am√©liorer la concentration horizontale.  En cons√©quence, en 2019, nous pr√©voyons une r√©duction significative des co√ªts EC2 par rapport √† l'ann√©e derni√®re. <br><br>  Il a fallu pr√®s de deux ans pour migrer, mais nous l'avons termin√©e en mars 2019.  Actuellement, la plateforme Tinder fonctionne exclusivement sur le cluster Kubernetes, qui comprend 200 services, 1 000 n≈ìuds, 15 000 pods et 48 000 conteneurs en cours d'ex√©cution.  L'infrastructure n'est plus la seule responsabilit√© des √©quipes op√©rationnelles.  Tous nos ing√©nieurs partagent cette responsabilit√© et contr√¥lent le processus de cr√©ation et de d√©ploiement de leurs applications en utilisant uniquement du code. <br><br><h2>  PS du traducteur </h2><br>  Lisez √©galement notre s√©rie d'articles sur notre blog: <br><br><ul><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1: <b>4 200 foyers et TessMaster sur eBay</b></a> . " </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 2: <b>Concur et SAP</b></a> . " </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 3: <b>GitHub</b></a> . " </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 4: <b>SoundCloud (auteurs Prometheus)</b></a> . " </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 5: <b>Monzo Digital Bank.</b></a> " </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 6: <b>BlaBlaCar</b></a> . " </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 7: <b>BlackRock</b></a> . " </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 8: <b>Huawei</b></a> . " </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 9: <b>Clusters du CERN et 210 K8.</b></a> ¬ª </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Histoires de r√©ussite de Kubernetes en production.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 10: <b>Reddit</b></a> . " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440278/">https://habr.com/ru/post/fr440278/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440268/index.html">D√©tournement du son: m√©canisme de g√©n√©ration de clics ultrasoniques chez les noctuelles comme protection contre les chauves-souris</a></li>
<li><a href="../fr440270/index.html">Nous consid√©rons un horaire de travail dans l'esprit</a></li>
<li><a href="../fr440272/index.html">Mobile Opera a un VPN gratuit</a></li>
<li><a href="../fr440274/index.html">Cr√©ation d'un service de devise priv√© √† l'aide d'Exonum</a></li>
<li><a href="../fr440276/index.html">D√©bogage frontal et principal</a></li>
<li><a href="../fr440280/index.html">Examen du logiciel libre Android</a></li>
<li><a href="../fr440282/index.html">Les frameworks Web Python les plus rapides en 2019</a></li>
<li><a href="../fr440284/index.html">Un nouveau regard sur l'affichage des dialogues dans Android</a></li>
<li><a href="../fr440286/index.html">Bruit Perlin, g√©n√©ration de contenu proc√©dural et espace int√©ressant</a></li>
<li><a href="../fr440288/index.html">S√©curit√© IoT. Num√©ro 1. Montres intelligentes, trackers de fitness et balances</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
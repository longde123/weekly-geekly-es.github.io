<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå∏ üßôüèº üë©üèΩ‚Äçü§ù‚Äçüë®üèº Comment √©volue l'apprentissage de l'IA üïäÔ∏è üê¨ üé§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chez OpenAI, nous avons constat√© que l'√©chelle de bruit de gradient, une m√©thode statistique simple, pr√©dit la parall√©lisabilit√© de l'apprentissage d'...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment √©volue l'apprentissage de l'IA</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/434934/"> Chez OpenAI, nous avons constat√© que l'√©chelle de bruit de gradient, une m√©thode statistique simple, pr√©dit la parall√©lisabilit√© de l'apprentissage d'un r√©seau neutre √† travers un large √©ventail de t√¢ches.  √âtant donn√© que le gradient devient g√©n√©ralement plus bruyant pour les t√¢ches plus complexes, une augmentation de la taille des paquets disponibles pour le traitement simultan√© s'av√©rera utile √† l'avenir et √©liminera l'une des limitations potentielles des syst√®mes d'IA.  Dans le cas g√©n√©ral, ces r√©sultats montrent que l'entra√Ænement des r√©seaux de neurones ne doit pas √™tre consid√©r√© comme un art myst√©rieux, et qu'il peut √™tre pr√©cis et syst√©matis√©. <br><br>  Au cours des derni√®res ann√©es, les chercheurs en IA ont r√©ussi de plus en plus √† acc√©l√©rer l'apprentissage des r√©seaux neuronaux en parall√©lisant les donn√©es, divisant de gros paquets de donn√©es en plusieurs ordinateurs.  Les chercheurs ont utilis√© avec succ√®s des dizaines de milliers d'unit√©s pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la classification d'images</a> et la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mod√©lisation du langage</a> , et m√™me pour des millions <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d'agents d'apprentissage renfor√ßateurs</a> qui ont jou√© √† Dota 2. De tels gros packages peuvent augmenter la quantit√© de puissance de calcul qui est effectivement impliqu√©e dans l'enseignement d'un mod√®le, et ne font qu'un des forces qui stimulent la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">croissance de</a> la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">formation en</a> IA.  Cependant, avec des paquets de donn√©es trop volumineux, les retours algorithmiques diminuent rapidement et on ne sait pas pourquoi ces restrictions s'av√®rent plus importantes pour certaines t√¢ches et plus petites pour d'autres. <br><a name="habracut"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/021/924/2f0/0219242f04c9a77d8c783c1ac9f143aa.svg"><br>  <i>La mise √† l'√©chelle du bruit de gradient, calcul√©e en moyenne sur les approches de formation, explique la majorit√© (r <sup>2</sup> = 80%) des variations critiques de la taille des paquets de donn√©es pour divers probl√®mes, diff√©rant de six ordres de grandeur.</i>  <i>Les tailles de package sont mesur√©es en nombre d'images, de jetons (pour les mod√®les de langage) ou d'observations (pour les jeux).</i> <br><br>  Nous avons constat√© qu'en mesurant l'√©chelle du bruit de gradient, des statistiques simples qui d√©terminent num√©riquement le rapport signal / bruit dans les gradients du r√©seau, nous pouvons approximativement pr√©dire la taille maximale du paquet.  Heuristiquement, l'√©chelle de bruit mesure la variation des donn√©es du point de vue du mod√®le (√† un stade particulier de la formation).  Lorsque l'√©chelle de bruit est petite, l'apprentissage parall√®le sur une grande quantit√© de donn√©es devient rapidement redondant, et lorsqu'elle est grande, nous pouvons apprendre beaucoup sur de grands ensembles de donn√©es. <br><br>  Les statistiques de ce type sont largement utilis√©es pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©terminer la</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">taille de l'</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©chantillon</a> , et il a √©t√© <a href="">sugg√©r√© de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les utiliser</a> dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprentissage</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">profondeur</a> , mais elles n'ont pas √©t√© syst√©matiquement utilis√©es pour la formation moderne des r√©seaux de neurones.  Nous avons confirm√© cette pr√©diction pour un large √©ventail de t√¢ches d'apprentissage automatique d√©crites dans le graphique ci-dessus, y compris la reconnaissance des formes, la mod√©lisation du langage, les jeux Atari et Dota.  En particulier, nous avons form√© des r√©seaux de neurones con√ßus pour r√©soudre chacun de ces probl√®mes sur des paquets de donn√©es de diff√©rentes tailles (en ajustant s√©par√©ment la vitesse d'apprentissage pour chacun d'eux), et avons compar√© l'acc√©l√©ration d'apprentissage avec celle pr√©dite par l'√©chelle de bruit.  √âtant donn√© que les gros paquets de donn√©es n√©cessitent souvent un ajustement soigneux et co√ªteux ou un calendrier sp√©cial de vitesse d'apprentissage pour que la formation soit efficace, en connaissant la limite sup√©rieure √† l'avance, vous pouvez obtenir un avantage significatif lors de la formation de nouveaux mod√®les. <br><br>  Nous avons trouv√© utile de visualiser les r√©sultats de ces exp√©riences comme un compromis entre le temps de formation r√©el et le montant total de calcul requis pour la formation (proportionnel √† son co√ªt en argent).  Sur de tr√®s petits paquets de donn√©es, le doublement de la taille des paquets permet d'effectuer la formation deux fois plus rapidement sans utiliser de puissance de calcul suppl√©mentaire (nous ex√©cutons deux fois plus de threads individuels qui fonctionnent deux fois plus vite).  Sur les tr√®s grandes maquettes de donn√©es, la parall√©lisation n'acc√©l√®re pas l'apprentissage.  La courbe dans les virages du milieu et l'√©chelle du bruit de gradient pr√©dit o√π exactement le virage se produit. <br><br><img src="https://habrastorage.org/webt/0z/bo/jj/0zbojjfcs2eewyd_ve-wiijmoak.png">  <i>L'augmentation du nombre de processus parall√®les vous permet de former des mod√®les plus complexes dans un d√©lai raisonnable.</i>  <i>Le diagramme de bordure de Pareto est le moyen le plus intuitif de visualiser les comparaisons d'algorithmes et d'√©chelles.</i> <br><br>  Nous obtenons ces courbes en attribuant un objectif √† la t√¢che (par exemple, 1000 points dans le jeu Atari Beam Rider), et en observant combien de temps il faut pour former le r√©seau neuronal pour atteindre cet objectif sur diff√©rentes tailles de paquets.  Les r√©sultats co√Øncident assez pr√©cis√©ment avec les pr√©dictions de notre mod√®le, en tenant compte des diff√©rentes valeurs des objectifs que nous nous sommes fix√©s. <br><br>  [ <i>La <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">page avec l'article d'origine</a> pr√©sente des graphiques interactifs d'un compromis entre l'exp√©rience et le temps de formation n√©cessaire pour atteindre un objectif donn√©</i> ] <br><br><h2>  Mod√®les d'√©chelle de bruit de gradient </h2><br>  Nous sommes tomb√©s sur plusieurs mod√®les dans l'√©chelle du bruit de gradient, sur la base desquels nous pouvons faire des hypoth√®ses sur l'avenir de la formation √† l'IA. <br><br>  Premi√®rement, dans nos exp√©riences dans le processus d'apprentissage, l'√©chelle de bruit augmente g√©n√©ralement d'un ordre de grandeur ou plus.  Apparemment, cela signifie que le r√©seau apprend des caract√©ristiques plus ¬´√©videntes¬ª du probl√®me au tout d√©but de la formation, puis √©tudie les petits d√©tails.  Par exemple, dans la t√¢che de classification des images, un r√©seau de neurones peut d'abord apprendre √† identifier les caract√©ristiques √† petite √©chelle, telles que les bords ou les textures montr√©s sur la plupart des images, puis comparer ces petites choses ensemble plus tard, cr√©ant des concepts plus g√©n√©raux, tels que les chats ou les chiens.  Pour avoir une id√©e de toute la vari√©t√© des visages et des textures, les r√©seaux de neurones doivent voir un petit nombre d'images, donc l'√©chelle de bruit est plus petite;  d√®s que le r√©seau en saura plus sur les objets plus gros, il pourra traiter beaucoup plus d'images en m√™me temps sans prendre en compte les donn√©es en double. <br><br>  Nous avons vu quelques <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">indications pr√©liminaires</a> qu'un effet similaire fonctionne √©galement sur d'autres mod√®les traitant du m√™me ensemble de donn√©es - dans les mod√®les plus puissants, l'√©chelle du bruit de gradient est plus √©lev√©e, mais uniquement parce qu'ils ont moins de perte.  Par cons√©quent, il existe des preuves que l'augmentation de l'√©chelle du bruit pendant la formation n'est pas seulement un artefact de convergence, mais est due √† une am√©lioration du mod√®le.  Si tel est le cas, alors nous pouvons nous attendre √† ce que les mod√®les am√©lior√©s futurs aient une grande √©chelle de bruit et soient mieux adapt√©s √† la parall√©lisation. <br><br>  Deuxi√®mement, les t√¢ches objectivement plus complexes se pr√™tent mieux √† la parall√©lisation.  Dans le contexte de l'enseignement avec un enseignant, des progr√®s √©vidents sont observ√©s dans la transition du MNIST √† SVHN et ImageNet.  Dans le contexte de la formation par renforcement, des progr√®s nets sont observ√©s dans la transition d'Atari Pong √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dota 1v1</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dota 5v5</a> , et la taille du paquet de donn√©es optimal varie 10 000 fois.  Par cons√©quent, alors que l'IA fait face √† des t√¢ches de plus en plus complexes, les mod√®les devraient faire face √† des ensembles de donn√©es de plus en plus volumineux. <br><br><h2>  Les cons√©quences </h2><br>  Le degr√© de parall√©lisation des donn√©es affecte s√©rieusement la vitesse de d√©veloppement des capacit√©s d'IA.  L'acc√©l√©ration de l'apprentissage permet de cr√©er des mod√®les plus performants et acc√©l√®re la recherche, vous permettant de raccourcir le temps de chaque it√©ration. <br><br>  Dans une √©tude ant√©rieure, ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AI et calculs</a> ¬ª, nous avons vu que les calculs pour la formation des plus grands mod√®les doublent tous les 3,5 mois, et avons not√© que cette tendance est bas√©e sur une combinaison d'√©conomie (le d√©sir de d√©penser de l'argent pour les calculs) et de capacit√©s algorithmiques pour parall√©liser l'apprentissage .  Le dernier facteur (parall√©lisabilit√© algorithmique) est plus difficile √† pr√©voir, et ses limites n'ont pas encore √©t√© enti√®rement √©tudi√©es, mais nos r√©sultats actuels repr√©sentent un pas en avant dans sa syst√©matisation et son expression num√©rique.  En particulier, nous avons la preuve que des t√¢ches plus complexes, ou des mod√®les plus puissants visant une t√¢che connue, permettront un travail plus parall√®le avec les donn√©es.  Ce sera un facteur cl√© soutenant la croissance exponentielle de l'informatique li√©e √† l'apprentissage.  Et nous ne consid√©rons m√™me pas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les d√©veloppements r√©cents</a> dans le domaine des mod√®les parall√®les, qui peuvent nous permettre d'am√©liorer encore la parall√©lisation en l'ajoutant au traitement de donn√©es parall√®le existant. <br><br>  La croissance continue du domaine de l'informatique d'entra√Ænement et sa base algorithmique pr√©visible parlent de la possibilit√© d'une augmentation explosive des capacit√©s de l'IA au cours des prochaines ann√©es, et soulignent la n√©cessit√© d'une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©tude</a> pr√©coce <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">de l'utilisation</a> s√ªre et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">responsable</a> de ces syst√®mes.  La principale difficult√© de la cr√©ation d'une politique en mati√®re d'IA sera de d√©cider comment ces mesures peuvent √™tre utilis√©es pour pr√©dire les caract√©ristiques des futurs syst√®mes d'IA, et d'utiliser ces connaissances pour cr√©er des r√®gles permettant √† la soci√©t√© de maximiser son utilit√© et de minimiser les dommages de ces technologies. <br><br>  OpenAI pr√©voit de mener une analyse rigoureuse pour pr√©dire l'avenir de l'IA et de r√©pondre de mani√®re proactive aux d√©fis soulev√©s par cette analyse. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr434934/">https://habr.com/ru/post/fr434934/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr434912/index.html">Le stock annuel de Porsche Taycan est d√©j√† r√©serv√©, principalement par les propri√©taires de Tesla</a></li>
<li><a href="../fr434924/index.html">Ce qu'il faut lire sur l'organisation des lieux de travail, le coworking et la conception d'espaces pour le travail √† distance</a></li>
<li><a href="../fr434928/index.html">M√©thodes d'application et distorsion de la pr√©cision dans les jeux. Tableaux visuels pour comparaison</a></li>
<li><a href="../fr434930/index.html">Annonce vid√©o aujourd'hui: doit avoir une entreprise prosp√®re</a></li>
<li><a href="../fr434932/index.html">Amplificateur √† tube non canon</a></li>
<li><a href="../fr434938/index.html">√Ä quoi s'attendre de Tesla en 2019: mise √† jour du mod√®le Y, du mod√®le S / X, etc.</a></li>
<li><a href="../fr434940/index.html">Affaires je t'aime</a></li>
<li><a href="../fr434942/index.html">L'art du chamanisme ou du firmware personnalis√© pour Olinuxino. UBOOT Partie 2</a></li>
<li><a href="../fr434944/index.html">Notes d'un phytochimiste. La peau de banane contre-attaque</a></li>
<li><a href="../fr434946/index.html">Mon d√©m√©nagement en Norv√®ge</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
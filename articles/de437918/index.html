<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤴🏿 🧦 🧑🏿‍🤝‍🧑🏻 Videoaufnahme mit automatischem Pausenauswurf durch freie Software mit Fahrradbau 👨🏻‍🏫 🚣🏾 👨‍👩‍👦‍👦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Russischsprachigen Entwicklern gibt es immer etwas zu erzählen: einzigartige Erfahrungen und Meinungen auszutauschen. Aber im Format des Videoblogs tu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Videoaufnahme mit automatischem Pausenauswurf durch freie Software mit Fahrradbau</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437918/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/_2/bs/h8/_2bsh8brje9tatdcz3fpvpv-l1g.jpeg" alt="Timeline-Fahrrad"></div><br><p>  Russischsprachigen Entwicklern gibt es immer etwas zu erzählen: einzigartige Erfahrungen und Meinungen auszutauschen.  Aber im Format des Videoblogs tun es aufgrund der hohen Komplexität der Aufnahme derzeit nur wenige. </p><br><p>  Unter der Katze sprach er über seinen schwierigen Weg, Videos mit freier Software, Ruby-Skripten und improvisierten Tools aufzunehmen und zu bearbeiten. <a name="habracut"></a></p><br><h1 id="teoriya">  Theorie </h1><br><p> Ich begann mit dem Studium der Theorie der Aufzeichnung von Videoblogs auf englischsprachigen YouTube-Videos.  Aus russischsprachigen Materialien erwies sich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser Kurs</a> als sehr nützlich (insbesondere das Modul zum Bloggen von Videos und das erste Video zum Erstellen eines Frames aus dem Modul zum Berichten).  Ich habe mich auch fließend mit den beliebten Funktionen proprietärer Video-Editoren vertraut gemacht, um die Wahl eines kostenlosen Editors bewusster zu gestalten. </p><br><p>  Ich habe es nicht gewagt, in Licht zu investieren: Es gibt nicht genug Zeit, um es zu studieren und nach der besten Option zu suchen, und eine oberflächliche Untersuchung billiger Optionen spricht von potenziellen Rechen wie Flimmern und schlechter Farbwiedergabe.  Bei Tageslicht hatte ich keine großen Schwierigkeiten, es reicht nur für kurze Videos. </p><br><h1 id="videoredaktor">  Video-Editor </h1><br><p>  Die vorhandenen kostenlosen Videobearbeitungswerkzeuge enthalten eine Reihe bekannter Probleme: von erfolglosen Lösungen in der Benutzeroberfläche und Einfrierungen, die die Bearbeitung in unendlich verwandeln, bis hin zu Speicherlecks, Abstürzen und unerwarteten Artefakten, die erst nach dem endgültigen Rendern auftreten. </p><br><p>  Es gibt viele Probleme und es hat einige Zeit gedauert, einen Video-Editor auszuwählen und seine Fehler zu untersuchen, um zu lernen, wie man mit grundlegenden Dingen umgeht.  Letztendlich hielt er in <strong>Pitivi an</strong> , einfach weil er so viel Zeit damit verbracht hatte zu suchen und zu experimentieren. </p><br><h2 id="zvuk-iz-flatpak">  Sound von Flatpak </h2><br><p>  Die unterstützte Installationsmethode für Pitivi erfordert Flatpak.  Für eine Weile ging ich um ihn herum, weil  Ich habe nicht systemd und PulseAudio in meinem System. </p><br><p>  Es stellt sich heraus, dass systemd schon lange <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nicht mehr benötigt</a> wurde.  Nun, PulseAudio - <s>ich musste installieren und konfigurieren,</s> es war einfacher, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flatpak</a> zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">modifizieren</a> .  Aber es wäre richtiger, PulseAudio zu verwenden, es ist nur ein wenig langweilig und es ist nicht klar, ob man Probleme mit der Tonaufnahme auf vorhandener Hardware erwarten kann oder nicht. </p><br><p>  Installieren Sie Pitivi, löschen Sie PulseAudio-Konfigurationen und führen Sie Folgendes aus: </p><br><pre><code class="bash hljs">$ sudo flatpak remote-add --<span class="hljs-keyword"><span class="hljs-keyword">if</span></span>-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo $ sudo flatpak install flathub org.pitivi.Pitivi $ sudo find {/var/lib,~/.<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share}/flatpak/runtime -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -name <span class="hljs-string"><span class="hljs-string">'*pulseaudio*.conf'</span></span> -delete $ flatpak run --device=alsa --branch=stable --arch=x86_64 --<span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=pitivi org.pitivi.Pitivi</code> </pre> <br><p>  Es ist kein Ton zu hören.  Lassen Sie uns versuchen, etwas Einfacheres auszuführen, zum Beispiel <code>aplay</code> : </p><br><pre> <code class="bash hljs">$ sudo find /var/lib/flatpak/app/org.pitivi.Pitivi/x86_64 -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> d -path <span class="hljs-string"><span class="hljs-string">'*/files/bin'</span></span> -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp `<span class="hljs-built_in"><span class="hljs-built_in">which</span></span> aplay` {} \; $ flatpak run --device=alsa --branch=stable --arch=x86_64 --<span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=aplay org.pitivi.Pitivi /dev/urandom ALSA lib dlmisc.c:162:(snd_dlsym_verify) unable to verify version <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> symbol _snd_pcm_empty_open ALSA lib dlmisc.c:283:(snd1_dlobj_cache_get) symbol _snd_pcm_empty_open is not defined inside [<span class="hljs-built_in"><span class="hljs-built_in">builtin</span></span>] aplay: main:828: audio open error: No such device or address</code> </pre> <br><p>  Wahrscheinlich wurde <code>alsa-lib</code> in Flatpak mit <code>--with-versioned</code> kompiliert.  Eine schnelle Lösung besteht darin, <code>libasound.so</code> System 1 zu ersetzen: </p><br><pre> <code class="bash hljs">$ sudo find /var/lib/flatpak -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -name libasound.so.2.0.0 -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp /usr/lib64/libasound.so.2.0.0 {} \; $ find ~/.<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/flatpak -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -name libasound.so.2.0.0 -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp /usr/lib64/libasound.so.2.0.0 {} \; <span class="hljs-comment"><span class="hljs-comment">#      -</span></span></code> </pre> <br><p>  Für mich war das nicht genug: </p><br><pre> <code class="bash hljs">$ flatpak run --device=alsa --branch=stable --arch=x86_64 --<span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=aplay org.pitivi.Pitivi /dev/urandom ALSA lib /var/tmp/portage/media-libs/alsa-lib-1.1.6-r1/work/alsa-lib-1.1.6/src/pcm/pcm_direct.c:1943:(snd1_pcm_direct_parse_open_conf) The field ipc_gid must be a valid group (create group audio) aplay: main:828: audio open error: Invalid argument</code> </pre> <br><p>  Benötigen Sie eine andere ALSA-Konfiguration: </p><br><pre> <code class="bash hljs">$ sudo find /var/lib/flatpak -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> d -name etc -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp /etc/asound.conf {} \; $ find ~/.<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/flatpak -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> d -name etc -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp /etc/asound.conf {} \; <span class="hljs-comment"><span class="hljs-comment">#      - $ flatpak run --device=alsa --branch=stable --arch=x86_64 --command=aplay org.pitivi.Pitivi /dev/urandom</span></span></code> </pre> <br><p>  Schließlich können Sie Pitivi verwenden. </p><br><div class="spoiler">  <b class="spoiler_title">Darstellende Rendering-Einstellungen für Pitivi</b> <div class="spoiler_text"><ul><li>  Containerformat: MP4 </li><li>  Video <br><ul><li>  Codec x264enc </li><li>  fortgeschritten <br><ul><li>  Codierungspass / -typ: konstanter Quantisierer </li><li>  konstanter Quantisierer: 18 </li><li>  Bitrate: 16384 kbit / s </li><li>  Geschwindigkeitsqualität voreingestellt: ultraschnell </li><li>  Voreinstellung für psychovisuelles Tuning: Film </li></ul></li></ul></li><li>  Audio <br><ul><li>  libav ALAC </li></ul></li><li>  Auf eigenes Risiko und aus Angst verwende ich "Niemals aus Proxy-Dateien rendern". </li><li>  alles andere ist die Standardeinstellung </li></ul></div></div><br><h2 id="drugie-effekty">  Andere Effekte </h2><br><p>  Ich mache einige Animationseffekte für den Text mit dem Screencast der Vollbildseiten, der mit enthüllen.js und animate.css angelegt wurde.  In enthüllen.js für einige Folien füge ich einen Übergangston hinzu: </p><br><pre> <code class="html hljs xml"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">section</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">style</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"font-size: 5em"</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">audio</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">data-autoplay</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">src</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"/path/to/sound.wav"</span></span></span><span class="hljs-tag">&gt;</span></span><span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">audio</span></span></span><span class="hljs-tag">&gt;</span></span> #1 <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">section</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre> <br><p>  Es stellte sich als wichtig heraus, einen Screencast mit 60 FPS aufzunehmen, wenn der Text sehr groß ist.  Screencast mach das: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh SOUND_INPUT=shared_input_loopback CHANNELS=2 SOUND_RATE=48000 FRAMERATE=60 DRAW_MOUSE=0 VIDEO_SIZE=$(xdpyinfo | awk '/dimensions:/ { print $2; exit }') OUTPUT="${HOME}/video/screen/$(date --rfc-3339=seconds).mp4" ffmpeg \ -thread_queue_size 512 \ -video_size "${VIDEO_SIZE}" \ -framerate "${FRAMERATE}" \ -f x11grab \ -draw_mouse "${DRAW_MOUSE}" \ -i :0.0+0,0 \ -thread_queue_size 512 \ -f alsa \ -ac "${CHANNELS}" \ -i "${SOUND_INPUT}" \ -ar "${SOUND_RATE}" \ -vcodec libx264 -preset ultrafast -crf 18 \ -acodec alac \ -f ipod \ "${OUTPUT}"</span></span></code> </pre> <br><p>  In meinem Fall ist <code>shared_input_loopback</code> das Gerät aus der <a href="">Konfiguration asound.conf</a> . </p><br><p>  Trotzdem war dieses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Add-</a> On über <code>ffmpeg</code> für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Übergänge</a> zwischen Clips nützlich. </p><br><h1 id="zapis-video">  Videoaufnahme </h1><br><p>  Zur Hand war ein Meizu MX4-Telefon, auf dem ich mich entschied, eine Frontkamera zu verwenden und mit Open Camera aufzunehmen.  Es dauerte einige Zeit, bis Sie sich darin geschult hatten, in die Kamera zu schauen und Ihre Position im Weltraum zu kontrollieren, ohne typische Fehler wie das Abschneiden des Kopfes zu machen.  Sprechen Sie gleichzeitig ganz klar, laut, gestikulieren Sie und erzeugen Sie zumindest eine Art Gesichtsausdruck.  Das war aber nur der Anfang. </p><br><p>  Was hat mich dazu veranlasst, automatisch Videos zu schneiden, und zwar bereits in der Aufnahmephase? </p><br><ol><li>  Pitivi bremst und bugs beim Bearbeiten, insbesondere bei Verwendung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ripple Move / Edit-</a> Werkzeugs, was dazu führt, dass Pitivi regelmäßig neu gestartet werden muss. </li><li>  Für mich ist das manuelle Schneiden von Videos eines der langweiligsten Dinge.  Es ist klar, dass eine vollständige Automatisierung nicht sehr gut möglich ist (zumindest ohne ein Szenario, in dem die zum Verständnis des Gesagten erforderlichen Pausen nicht explizit angegeben sind), aber zumindest kann dieser Prozess optimiert werden. </li></ol><br><p>  Hier sind die Anforderungen für das zukünftige Fahrrad, das ich mir selbst gestellt habe: </p><br><ol><li>  Nehmen Sie Video mit einem Android-Telefon und Audio mit einem Laptop auf. </li><li>  Kamerafokussteuerung. </li><li>  Möglichkeit, die Aufnahme zu stoppen, um das zuletzt aufgenommene Fragment zu speichern oder zu löschen. </li><li>  Laden Sie das Video mit wiederholten Versuchen über USB vom Telefon herunter und setzen Sie es fort, ohne die Möglichkeit zu blockieren, das nächste Fragment aufzunehmen. </li><li>  Sound- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Synchronisation</a> . </li><li>  Feststellung des Vorhandenseins von Stimme und Pausen. </li><li>  Die Möglichkeit, die zuletzt aufgenommenen Videoclips mit bereits angehaltenen Pausen schnell abzuspielen. </li></ol><br><p>  Warum so viel Kontrolle über die Geräte während der Aufnahmephase?  Warum nicht einfach mehrere Stunden hintereinander mit der Aufnahme beginnen und sie dann bearbeiten?  Es gibt viele Gründe: </p><br><ol><li>  Banaler Mangel an Speicherplatz. </li><li>  Die Tendenz des Telefons, sich bei längerer Aufnahme zu überhitzen und schnell zu entladen. </li><li>  Fehlfunktion des Touchscreens aufgrund des Telefons im Wasser.  Aber irgendwie muss man den Fokus kontrollieren.  Ja, und das nächste Drücken würde unnötige Vibrationen des Geräts verursachen. </li><li>  Probleme beim Hochladen großer Dateien aufgrund der schlechten Stromversorgung des USB-Anschlusses auf meinem Laptop.  Theoretisch kann dies mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">USB-Hub</a> mit zusätzlicher Leistung gelöst werden.  Die Verwendung eines Netzwerks ist zu langsam. </li><li>  Der Wunsch, die zuletzt aufgezeichneten Fragmente schnell zu überprüfen, um sicherzustellen, dass keine Fehler vorliegen, und sie schnell neu zu schreiben, bevor sich der Planet an der falschen Stelle vor der Sonne dreht. </li><li>  Der Wunsch, offensichtlich schlechte Duplikate so früh wie möglich zu werfen, um in Zukunft keine Zeit und keinen Speicherplatz mehr zu verschwenden. </li><li>  Sie müssen lange Audiodaten synchronisieren, die von Telefon und Laptop aufgezeichnet wurden.  Dies kann zu einer Nichtübereinstimmung mit dem Video führen, da die Frames der Audiostreams sowohl beim Aufnehmen von einem Laptop als auch beim Aufnehmen von einem Telefon ausgeworfen werden (was Sie wahrscheinlich irgendwie lösen können, aber nicht riskieren und Zeit mit Experimentieren verschwenden möchten).  Es ist einfacher, kleine Fragmente separat zu synchronisieren, dann ist eine mögliche Desynchronisierung nicht erkennbar. </li><li>  Die Notwendigkeit, eine Situation zu bewältigen, in der Open Camera die Aufnahme aufgrund einer Videogröße von 4 GiB neu startet.  Sie müssten wahrscheinlich Open Camera ändern.  Wenn diese Einschränkung auf 4 GiB nicht aufgehoben oder erhöht werden kann, müssen Sie ein Ereignis auf den Laptop werfen, um festzustellen, dass die Aufzeichnung an dieser Stelle neu gestartet wurde. </li></ol><br><p>  Es ist einfacher, in kleinen Fragmenten aufzunehmen und alles, was möglich ist, primitiv zu automatisieren.  Ruby wurde als Hauptsprache für die Entwicklung eines Fahrrads ausgewählt.  Eigentlich würde ich jetzt wahrscheinlich Python wählen, aber in diesem Moment habe ich gerade Ruby gelernt und ich leite neue Sprachen für mich in solch seltsamen Experimenten. </p><br><h2 id="avtomaticheskaya-narezka-video">  Automatisches Video-Slicing </h2><br><p>  Informationen im Netzwerk zu diesem Thema sind nicht sehr viel.  Über die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Forschung erinnerten sich Stanford und Adobe</a> später (was nicht beängstigend ist, ich brauche immer noch eine weniger ausgefeilte Lösung). </p><br><p>  Das Schneiden erfolgt in zwei Schritten: In der Aufnahmephase - grob, in der Renderphase - genauer, mit der Möglichkeit, zu viele zugeschnittene Fragmente manuell zu korrigieren.  Grobe Implementierung mit <abbr title="Sprachaktivitätserkennung">VAD</abbr> von WebRTC.  Genauer - mit Hilfe von Google Speech (genauer gesagt - mit Hilfe einer Modifikation des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Autosub-</a> Projekts, um Untertitel für das Video zu generieren).  Ich bin mir sicher, dass es erfolgreichere Lösungen geben wird. Es hat sich als das Beste herausgestellt, was wir schnell tun konnten. </p><br><p>  Wenn Sie so etwas mit <code>ffmpeg</code> entwickeln möchten, halten Sie sich an das Prinzip, nicht zu viel in einem Aufruf von <code>ffmpeg</code> zu tun.  Erstellen Sie Zwischendateien und steuern Sie jeden Schritt, damit Sie nicht nach seltsamen Nicht-Google-Fehlern suchen müssen, z. B. nach falschem Schneiden oder nicht angewendetem Effekt. </p><br><p>  Ich beginne die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>daraus resultierende Schande</strong></a> irgendwie so: </p><br><pre> <code class="plaintext hljs">$ bin/vlog-recorder \ --project /path/to/project \ --debug true \ --sound-settings ' --device=usb_card --format=dat' #   arecord r - (RE)START recording s - STOP and SAVE current clip S - STOP and SAVE current clip, don't use auto trimming d - STOP and DELETE current clip p - PLAY last saved clip f - FOCUS camera on center h - show HELP q / Ctrl+C - QUIT [ stopped ] [ battery: 100% / 36°C ]</code> </pre> <br><p>  Ich brauche die Argumente zu <code>arecord</code> , um das Gerät explizit anzugeben, um die periodischen Störungen zu vermeiden, die höchstwahrscheinlich auf das ALSA-basierte dsnoop-Plugin zurückzuführen sind.  Sie können das Protokoll auch öffnen, um den Vorgang des Herunterladens von Dateien vom Telefon zu steuern: <code>tail -f /path/to/project/log.txt</code> . </p><br><p>  Sie können Folgendes schnell in einem Video zur Vorschau rendern: </p><br><pre> <code class="bash hljs">$ bin/vlog-render \ --project /path/to/project \ --language ru \ --video-filters <span class="hljs-string"><span class="hljs-string">'hqdn3d,hflip,curves=psfile=/path/to/curves.acv,vignette'</span></span> \ --speed 1.3 \ --fps 60 \ --preview <span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br><p>  Das Argument <code>--video-filters</code> sind die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Filter,</a> die an <code>ffmpeg</code> .  Das Video wird automatisch im <code>mpv</code> Player <code>mpv</code> . </p><br><p>  Sie können die verbleibenden unnötigen Duplikate auch <code>/path/to/project/render.conf</code> oder wegwerfen, indem Sie die <code>/path/to/project/render.conf</code> Datei <code>/path/to/project/render.conf</code> , die dank der erkannten Stimme erkannt werden kann.  Die Idee ist übrigens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nicht neu</a> .  Dort können Sie einzelne Fragmente beschleunigen und gegebenenfalls erfolglose Videoschnitte bearbeiten.  Beim nächsten Mal liest <code>render.conf</code> <code>vlog-render</code> <code>render.conf</code> und <code>render.conf</code> die Änderungen. </p><br><p>  Um Fragmente für einen Video-Editor vorzubereiten, müssen Sie <code>--preview false</code> angeben.  Zusätzlich zu den Fragmenten, die in der <code>output</code> liegen, werden sie dennoch in einer <code>output.mp4</code> Datei zusammengeführt, da ich anfangs nicht sicher war: </p><br><ul><li>  werde ich kleine Clips in Pitivi verwenden </li><li>  oder laden Sie ein langes Video hoch, um es weiter zu schneiden (damit Sie eine Reihe von Effekten auf die „Gruppe“ von Clips anwenden können). </li></ul><br><p>  Ich benutze hauptsächlich die erste Option.  Das zweite war in einem Video mit schlechtem Licht nützlich: Dort habe ich nur ein Stück <code>output.mp4</code> .  Für die zweite Option kann auch das Skript <code>vlog-play-segments</code> nützlich sein: Mit ihm können Sie schnell alle Pausen zwischen Clips in absteigender Reihenfolge der Dauer anzeigen.  Dies hilft <code>render.conf</code> genauer zu <code>render.conf</code> und später beim Bearbeiten dieses langen Videos in Pitivi Zeit zu sparen. </p><br><p>  Die resultierenden kleinen Clips können einmal pro Timeline in Pitivi heruntergeladen werden: Wählen Sie alle importierten Clips aus und ziehen Sie sie per Drag &amp; Drop. </p><br><h2 id="kreplenie-dlya-telefona">  Telefonhalterung </h2><br><p>  Ich wollte nicht nach einem geeigneten Telefonständer suchen, und meine Hände kratzten bereits an meinem Gesicht, um zumindest etwas aufzunehmen.  Wir nehmen ein Stück Pappe zur Hand und schneiden die Telefonhalterung für unsere Bedürfnisse aus: </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/kl/u8/tj/klu8tjf8huzxyqf71-ci7xnah_w.jpeg" alt="Telefonhalterung"></div><br><p>  Der Ständer ist auf einem Laptop-Display montiert, um den Abstand zwischen dem Skript und der Kamera zu minimieren. </p><br><h1 id="zapis-zvuka">  Tonaufnahme </h1><br><p>  Akzeptabler Klang ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sehr kritisch</a> .  Zur Hand war ein Boya BY-M1 Mikrofon.  Obwohl es als omnidirektionales Mikrofon beworben wird, wird in der Praxis nur dann ein guter Klang erzielt, wenn Sie es als unidirektional verwenden. </p><br><p>  Es ist noch einfacher, das Mikrofon zum Stehen zu bringen: Wir nehmen eine Flasche Granatapfelsaft, die zur Hand kommt, eine Rolle Klebeband und setzen diesen Konstruktor zusammen: </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xp/qt/1u/xpqt1ue6ikhdrwwh6oqr1x83vo0.jpeg" alt="Mikrofonständer"></div><br><p>  Sie können auch ein Handtuch unter dieses Design legen, um einen Teil der Vibrationen vom Tisch zu unterdrücken und gleichzeitig die Höhe anzupassen. </p><br><h2 id="zvukovaya-karta">  Soundkarte </h2><br><p>  In meinem Fall ist dies ASUS Xonar U3.  Es stellte sich jedoch heraus, dass es mit einem solchen Mikrofon nicht kompatibel ist: Das Mikrofon verfügt über einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CTIA-</a> Stecker für Telefone.  Das Problem wurde durch den Adapter in den TRS-Steckern für Mikrofon und Kopfhörer gelöst.  Und es war nicht einfach zu finden: Hersteller solcher Adapter schreiben selten Details.  In meinem Fall hat ein Cablexpert CCA-418W geholfen. </p><br><p>  Ein weiteres Problem mit dieser Karte ist der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DC-Offset</a> im rechten Kanal bei der Aufnahme.  Was nicht stört, weil  Ich nehme sowieso in Mono auf.  Und für Software, mit der Sie kein Mono einstellen können, habe ich mit ALSA <a href="">einen</a> guten Kanal auf einen schlechten Kanal <a href="">umgeleitet</a> . </p><br><p>  Diese Karte hat auch Angst vor Überhitzung.  Sie müssen es vom Kühler fernhalten, da es sonst langsamer wird und den Ton in Rucken aufzeichnet. </p><br><h2 id="obrabotka-zvuka">  Tonverarbeitung </h2><br><p>  Ich bearbeite den Ton in den Kopfhörern (in meinem Fall ist es der Pioneer SE-M390) mit einer höheren Lautstärke als der, auf der ich normalerweise Musik höre.  Der Algorithmus ist ungefähr so: </p><br><ol><li>  Mit Pitivi rendere ich den Sound separat (mit allen gleichen ALAC und MP4).  Oft mache ich mehrere separate Spuren, wähle bestimmte Ebenen in Pitivi aus und entferne vorübergehend unnötige. </li><li>  Wenn die empfangenen Dateien sofort in Audacity hochgeladen <strong>werden, verlieren</strong> wir <strong>das</strong> Dehnen / Komprimieren des Audiostreams, was dazu führen kann, dass Video und Audio nicht mehr synchron sind.  Was nicht offensichtlich ist, passiert nicht bei allen Videos.  Um dies zu verhindern, wenden Sie einfach diese Dehnung / Komprimierung an: <code>ffmpeg -async 1 -i input.mp4 output.flac</code> </li><li>  Laden Sie alle Titel in Audacity herunter.  Fügen Sie bei Bedarf Hintergrundmusik hinzu. </li><li>  Stellen Sie für alle Spuren die gewünschte Lautstärke mit Gain ein. </li><li>  Wenden Sie auf die Spur mit der Stimme die Effekte von Rauschunterdrückung (in meinem Fall doppelt), Kompressor und Ausgleich gemäß den Tipps aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Video an</a> . </li><li>  Wir gleichen die Lautstärke des Tracks mit der Stimme aus und erhöhen sie.  Eine der klassischen Möglichkeiten ist Normalisieren, Verstärken, Begrenzen und Normalisieren erneut, aber mit diesem Ansatz konnte ich noch nicht die gewünschte Klangqualität erzielen.  <s>Ich verhalte mich vorübergehend so: Zuerst mache ich den Gain des gesamten Tracks so, dass der lauteste Teil ohne Überlastung klingt, und dann wende ich Amplify manuell für einzelne Fragmente an.</s>  <strong>Update</strong> : Eine weitere leistungsstarke Methode ist RMS Normalize, Limiter und Normal Normalize.  Die Einstellungen für RMS-Normalisierung und -Begrenzer können hier übernommen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> .  Trotzdem war diese Methode für mich nicht sinnvoll, weil  Trotzdem habe ich mich entschlossen, mit dem eingebauten Limiter auf ein anderes Mikrofon (Zoom H1n) umzuschalten, was zu mir passt (daher muss ich mit dem neuen Mikrofon höchstwahrscheinlich nur normal normalisieren, anstatt all dieser Dinge). </li><li>  Das Mikrofon nimmt manchmal Ton mit einigen Fehlern auf, die wie Klicks aussehen.  Sie können mit dem Spectral Edit Multi Tool-Effekt entfernt werden.  In den meisten Fällen muss der ausgewählte Bereich mehrmals hintereinander mit Strg + R angewendet werden.  <strong>Update</strong> : Dank des neuen Mikrofons habe ich herausgefunden, dass diese Defekte mit etwas Äußerem zusammenhängen. Dies ist höchstwahrscheinlich eine Kombination aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Geräuschen im Mund</a> und anderen Nebengeräuschen. </li><li>  Wir exportieren von Audacity nach FLAC und führen alles in einer Datei zusammen: <code>ffmpeg -i sound.flac -an -i video.mp4 -c copy output.mkv</code> </li><li>  Zumindest das erste Video, das ich auf verschiedenen Volumes und verschiedenen Geräten getestet habe. </li></ol><br><h1 id="rezultat">  Ergebnis </h1><br><p>  Ich nutze die Gelegenheit, um die Nüsse in den Regeln zu lösen, und lade Sie ein, den resultierenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>YouTube-Kanal</strong></a> zu besuchen, auf dem ich Einblicke in das effektive Studium der Programmierung und verwandter Disziplinen teile. </p><br><p>  Viel Glück bei der Entwicklung von Programmen und der Erstellung von Videoblogs! </p><br><p>  <strong>Update</strong> : hat diesen Artikel für seinen englischsprachigen Blog übersetzt. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de437918/">https://habr.com/ru/post/de437918/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de437908/index.html">Arduino arbeitet mit Google zusammen und führt die Zertifizierung ein</a></li>
<li><a href="../de437910/index.html">Frühlingszivilisation, 1/5</a></li>
<li><a href="../de437912/index.html">Ein kleines Notizbuch für einen Systemadministrator</a></li>
<li><a href="../de437914/index.html">Jaxb (XJC) generiert Klassen aus XML-Schema (XSD) mit Klassen- und Feldbeschreibungen als Anmerkungen. XJC-Plugin</a></li>
<li><a href="../de437916/index.html">Geben Sie den E-Book-Reader in jede Tasche! Rückblick auf die neuesten Innovationen von ONYX BOOX</a></li>
<li><a href="../de437922/index.html">Angriffsmodell: Wo es hauptsächlich in der elektronischen Beschaffung missbraucht wird und wie man damit umgeht</a></li>
<li><a href="../de437924/index.html">Blockchain Sharding</a></li>
<li><a href="../de437926/index.html">Der maßgebliche Leitfaden zum Blockchain-Sharding</a></li>
<li><a href="../de437928/index.html">Wie man Englisch lernt</a></li>
<li><a href="../de437930/index.html">Leuchte Combo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§¥üèø üß¶ üßëüèø‚Äçü§ù‚Äçüßëüèª Videoaufnahme mit automatischem Pausenauswurf durch freie Software mit Fahrradbau üë®üèª‚Äçüè´ üö£üèæ üë®‚Äçüë©‚Äçüë¶‚Äçüë¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Russischsprachigen Entwicklern gibt es immer etwas zu erz√§hlen: einzigartige Erfahrungen und Meinungen auszutauschen. Aber im Format des Videoblogs tu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Videoaufnahme mit automatischem Pausenauswurf durch freie Software mit Fahrradbau</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437918/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/_2/bs/h8/_2bsh8brje9tatdcz3fpvpv-l1g.jpeg" alt="Timeline-Fahrrad"></div><br><p>  Russischsprachigen Entwicklern gibt es immer etwas zu erz√§hlen: einzigartige Erfahrungen und Meinungen auszutauschen.  Aber im Format des Videoblogs tun es aufgrund der hohen Komplexit√§t der Aufnahme derzeit nur wenige. </p><br><p>  Unter der Katze sprach er √ºber seinen schwierigen Weg, Videos mit freier Software, Ruby-Skripten und improvisierten Tools aufzunehmen und zu bearbeiten. <a name="habracut"></a></p><br><h1 id="teoriya">  Theorie </h1><br><p> Ich begann mit dem Studium der Theorie der Aufzeichnung von Videoblogs auf englischsprachigen YouTube-Videos.  Aus russischsprachigen Materialien erwies sich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser Kurs</a> als sehr n√ºtzlich (insbesondere das Modul zum Bloggen von Videos und das erste Video zum Erstellen eines Frames aus dem Modul zum Berichten).  Ich habe mich auch flie√üend mit den beliebten Funktionen propriet√§rer Video-Editoren vertraut gemacht, um die Wahl eines kostenlosen Editors bewusster zu gestalten. </p><br><p>  Ich habe es nicht gewagt, in Licht zu investieren: Es gibt nicht genug Zeit, um es zu studieren und nach der besten Option zu suchen, und eine oberfl√§chliche Untersuchung billiger Optionen spricht von potenziellen Rechen wie Flimmern und schlechter Farbwiedergabe.  Bei Tageslicht hatte ich keine gro√üen Schwierigkeiten, es reicht nur f√ºr kurze Videos. </p><br><h1 id="videoredaktor">  Video-Editor </h1><br><p>  Die vorhandenen kostenlosen Videobearbeitungswerkzeuge enthalten eine Reihe bekannter Probleme: von erfolglosen L√∂sungen in der Benutzeroberfl√§che und Einfrierungen, die die Bearbeitung in unendlich verwandeln, bis hin zu Speicherlecks, Abst√ºrzen und unerwarteten Artefakten, die erst nach dem endg√ºltigen Rendern auftreten. </p><br><p>  Es gibt viele Probleme und es hat einige Zeit gedauert, einen Video-Editor auszuw√§hlen und seine Fehler zu untersuchen, um zu lernen, wie man mit grundlegenden Dingen umgeht.  Letztendlich hielt er in <strong>Pitivi an</strong> , einfach weil er so viel Zeit damit verbracht hatte zu suchen und zu experimentieren. </p><br><h2 id="zvuk-iz-flatpak">  Sound von Flatpak </h2><br><p>  Die unterst√ºtzte Installationsmethode f√ºr Pitivi erfordert Flatpak.  F√ºr eine Weile ging ich um ihn herum, weil  Ich habe nicht systemd und PulseAudio in meinem System. </p><br><p>  Es stellt sich heraus, dass systemd schon lange <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nicht mehr ben√∂tigt</a> wurde.  Nun, PulseAudio - <s>ich musste installieren und konfigurieren,</s> es war einfacher, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flatpak</a> zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">modifizieren</a> .  Aber es w√§re richtiger, PulseAudio zu verwenden, es ist nur ein wenig langweilig und es ist nicht klar, ob man Probleme mit der Tonaufnahme auf vorhandener Hardware erwarten kann oder nicht. </p><br><p>  Installieren Sie Pitivi, l√∂schen Sie PulseAudio-Konfigurationen und f√ºhren Sie Folgendes aus: </p><br><pre><code class="bash hljs">$ sudo flatpak remote-add --<span class="hljs-keyword"><span class="hljs-keyword">if</span></span>-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo $ sudo flatpak install flathub org.pitivi.Pitivi $ sudo find {/var/lib,~/.<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share}/flatpak/runtime -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -name <span class="hljs-string"><span class="hljs-string">'*pulseaudio*.conf'</span></span> -delete $ flatpak run --device=alsa --branch=stable --arch=x86_64 --<span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=pitivi org.pitivi.Pitivi</code> </pre> <br><p>  Es ist kein Ton zu h√∂ren.  Lassen Sie uns versuchen, etwas Einfacheres auszuf√ºhren, zum Beispiel <code>aplay</code> : </p><br><pre> <code class="bash hljs">$ sudo find /var/lib/flatpak/app/org.pitivi.Pitivi/x86_64 -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> d -path <span class="hljs-string"><span class="hljs-string">'*/files/bin'</span></span> -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp `<span class="hljs-built_in"><span class="hljs-built_in">which</span></span> aplay` {} \; $ flatpak run --device=alsa --branch=stable --arch=x86_64 --<span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=aplay org.pitivi.Pitivi /dev/urandom ALSA lib dlmisc.c:162:(snd_dlsym_verify) unable to verify version <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> symbol _snd_pcm_empty_open ALSA lib dlmisc.c:283:(snd1_dlobj_cache_get) symbol _snd_pcm_empty_open is not defined inside [<span class="hljs-built_in"><span class="hljs-built_in">builtin</span></span>] aplay: main:828: audio open error: No such device or address</code> </pre> <br><p>  Wahrscheinlich wurde <code>alsa-lib</code> in Flatpak mit <code>--with-versioned</code> kompiliert.  Eine schnelle L√∂sung besteht darin, <code>libasound.so</code> System 1 zu ersetzen: </p><br><pre> <code class="bash hljs">$ sudo find /var/lib/flatpak -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -name libasound.so.2.0.0 -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp /usr/lib64/libasound.so.2.0.0 {} \; $ find ~/.<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/flatpak -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -name libasound.so.2.0.0 -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp /usr/lib64/libasound.so.2.0.0 {} \; <span class="hljs-comment"><span class="hljs-comment">#      -</span></span></code> </pre> <br><p>  F√ºr mich war das nicht genug: </p><br><pre> <code class="bash hljs">$ flatpak run --device=alsa --branch=stable --arch=x86_64 --<span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=aplay org.pitivi.Pitivi /dev/urandom ALSA lib /var/tmp/portage/media-libs/alsa-lib-1.1.6-r1/work/alsa-lib-1.1.6/src/pcm/pcm_direct.c:1943:(snd1_pcm_direct_parse_open_conf) The field ipc_gid must be a valid group (create group audio) aplay: main:828: audio open error: Invalid argument</code> </pre> <br><p>  Ben√∂tigen Sie eine andere ALSA-Konfiguration: </p><br><pre> <code class="bash hljs">$ sudo find /var/lib/flatpak -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> d -name etc -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp /etc/asound.conf {} \; $ find ~/.<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/share/flatpak -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> d -name etc -<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cp /etc/asound.conf {} \; <span class="hljs-comment"><span class="hljs-comment">#      - $ flatpak run --device=alsa --branch=stable --arch=x86_64 --command=aplay org.pitivi.Pitivi /dev/urandom</span></span></code> </pre> <br><p>  Schlie√ülich k√∂nnen Sie Pitivi verwenden. </p><br><div class="spoiler">  <b class="spoiler_title">Darstellende Rendering-Einstellungen f√ºr Pitivi</b> <div class="spoiler_text"><ul><li>  Containerformat: MP4 </li><li>  Video <br><ul><li>  Codec x264enc </li><li>  fortgeschritten <br><ul><li>  Codierungspass / -typ: konstanter Quantisierer </li><li>  konstanter Quantisierer: 18 </li><li>  Bitrate: 16384 kbit / s </li><li>  Geschwindigkeitsqualit√§t voreingestellt: ultraschnell </li><li>  Voreinstellung f√ºr psychovisuelles Tuning: Film </li></ul></li></ul></li><li>  Audio <br><ul><li>  libav ALAC </li></ul></li><li>  Auf eigenes Risiko und aus Angst verwende ich "Niemals aus Proxy-Dateien rendern". </li><li>  alles andere ist die Standardeinstellung </li></ul></div></div><br><h2 id="drugie-effekty">  Andere Effekte </h2><br><p>  Ich mache einige Animationseffekte f√ºr den Text mit dem Screencast der Vollbildseiten, der mit enth√ºllen.js und animate.css angelegt wurde.  In enth√ºllen.js f√ºr einige Folien f√ºge ich einen √úbergangston hinzu: </p><br><pre> <code class="html hljs xml"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">section</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">style</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"font-size: 5em"</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">audio</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">data-autoplay</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">src</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"/path/to/sound.wav"</span></span></span><span class="hljs-tag">&gt;</span></span><span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">audio</span></span></span><span class="hljs-tag">&gt;</span></span> #1 <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">section</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre> <br><p>  Es stellte sich als wichtig heraus, einen Screencast mit 60 FPS aufzunehmen, wenn der Text sehr gro√ü ist.  Screencast mach das: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh SOUND_INPUT=shared_input_loopback CHANNELS=2 SOUND_RATE=48000 FRAMERATE=60 DRAW_MOUSE=0 VIDEO_SIZE=$(xdpyinfo | awk '/dimensions:/ { print $2; exit }') OUTPUT="${HOME}/video/screen/$(date --rfc-3339=seconds).mp4" ffmpeg \ -thread_queue_size 512 \ -video_size "${VIDEO_SIZE}" \ -framerate "${FRAMERATE}" \ -f x11grab \ -draw_mouse "${DRAW_MOUSE}" \ -i :0.0+0,0 \ -thread_queue_size 512 \ -f alsa \ -ac "${CHANNELS}" \ -i "${SOUND_INPUT}" \ -ar "${SOUND_RATE}" \ -vcodec libx264 -preset ultrafast -crf 18 \ -acodec alac \ -f ipod \ "${OUTPUT}"</span></span></code> </pre> <br><p>  In meinem Fall ist <code>shared_input_loopback</code> das Ger√§t aus der <a href="">Konfiguration asound.conf</a> . </p><br><p>  Trotzdem war dieses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Add-</a> On √ºber <code>ffmpeg</code> f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberg√§nge</a> zwischen Clips n√ºtzlich. </p><br><h1 id="zapis-video">  Videoaufnahme </h1><br><p>  Zur Hand war ein Meizu MX4-Telefon, auf dem ich mich entschied, eine Frontkamera zu verwenden und mit Open Camera aufzunehmen.  Es dauerte einige Zeit, bis Sie sich darin geschult hatten, in die Kamera zu schauen und Ihre Position im Weltraum zu kontrollieren, ohne typische Fehler wie das Abschneiden des Kopfes zu machen.  Sprechen Sie gleichzeitig ganz klar, laut, gestikulieren Sie und erzeugen Sie zumindest eine Art Gesichtsausdruck.  Das war aber nur der Anfang. </p><br><p>  Was hat mich dazu veranlasst, automatisch Videos zu schneiden, und zwar bereits in der Aufnahmephase? </p><br><ol><li>  Pitivi bremst und bugs beim Bearbeiten, insbesondere bei Verwendung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ripple Move / Edit-</a> Werkzeugs, was dazu f√ºhrt, dass Pitivi regelm√§√üig neu gestartet werden muss. </li><li>  F√ºr mich ist das manuelle Schneiden von Videos eines der langweiligsten Dinge.  Es ist klar, dass eine vollst√§ndige Automatisierung nicht sehr gut m√∂glich ist (zumindest ohne ein Szenario, in dem die zum Verst√§ndnis des Gesagten erforderlichen Pausen nicht explizit angegeben sind), aber zumindest kann dieser Prozess optimiert werden. </li></ol><br><p>  Hier sind die Anforderungen f√ºr das zuk√ºnftige Fahrrad, das ich mir selbst gestellt habe: </p><br><ol><li>  Nehmen Sie Video mit einem Android-Telefon und Audio mit einem Laptop auf. </li><li>  Kamerafokussteuerung. </li><li>  M√∂glichkeit, die Aufnahme zu stoppen, um das zuletzt aufgenommene Fragment zu speichern oder zu l√∂schen. </li><li>  Laden Sie das Video mit wiederholten Versuchen √ºber USB vom Telefon herunter und setzen Sie es fort, ohne die M√∂glichkeit zu blockieren, das n√§chste Fragment aufzunehmen. </li><li>  Sound- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Synchronisation</a> . </li><li>  Feststellung des Vorhandenseins von Stimme und Pausen. </li><li>  Die M√∂glichkeit, die zuletzt aufgenommenen Videoclips mit bereits angehaltenen Pausen schnell abzuspielen. </li></ol><br><p>  Warum so viel Kontrolle √ºber die Ger√§te w√§hrend der Aufnahmephase?  Warum nicht einfach mehrere Stunden hintereinander mit der Aufnahme beginnen und sie dann bearbeiten?  Es gibt viele Gr√ºnde: </p><br><ol><li>  Banaler Mangel an Speicherplatz. </li><li>  Die Tendenz des Telefons, sich bei l√§ngerer Aufnahme zu √ºberhitzen und schnell zu entladen. </li><li>  Fehlfunktion des Touchscreens aufgrund des Telefons im Wasser.  Aber irgendwie muss man den Fokus kontrollieren.  Ja, und das n√§chste Dr√ºcken w√ºrde unn√∂tige Vibrationen des Ger√§ts verursachen. </li><li>  Probleme beim Hochladen gro√üer Dateien aufgrund der schlechten Stromversorgung des USB-Anschlusses auf meinem Laptop.  Theoretisch kann dies mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">USB-Hub</a> mit zus√§tzlicher Leistung gel√∂st werden.  Die Verwendung eines Netzwerks ist zu langsam. </li><li>  Der Wunsch, die zuletzt aufgezeichneten Fragmente schnell zu √ºberpr√ºfen, um sicherzustellen, dass keine Fehler vorliegen, und sie schnell neu zu schreiben, bevor sich der Planet an der falschen Stelle vor der Sonne dreht. </li><li>  Der Wunsch, offensichtlich schlechte Duplikate so fr√ºh wie m√∂glich zu werfen, um in Zukunft keine Zeit und keinen Speicherplatz mehr zu verschwenden. </li><li>  Sie m√ºssen lange Audiodaten synchronisieren, die von Telefon und Laptop aufgezeichnet wurden.  Dies kann zu einer Nicht√ºbereinstimmung mit dem Video f√ºhren, da die Frames der Audiostreams sowohl beim Aufnehmen von einem Laptop als auch beim Aufnehmen von einem Telefon ausgeworfen werden (was Sie wahrscheinlich irgendwie l√∂sen k√∂nnen, aber nicht riskieren und Zeit mit Experimentieren verschwenden m√∂chten).  Es ist einfacher, kleine Fragmente separat zu synchronisieren, dann ist eine m√∂gliche Desynchronisierung nicht erkennbar. </li><li>  Die Notwendigkeit, eine Situation zu bew√§ltigen, in der Open Camera die Aufnahme aufgrund einer Videogr√∂√üe von 4 GiB neu startet.  Sie m√ºssten wahrscheinlich Open Camera √§ndern.  Wenn diese Einschr√§nkung auf 4 GiB nicht aufgehoben oder erh√∂ht werden kann, m√ºssen Sie ein Ereignis auf den Laptop werfen, um festzustellen, dass die Aufzeichnung an dieser Stelle neu gestartet wurde. </li></ol><br><p>  Es ist einfacher, in kleinen Fragmenten aufzunehmen und alles, was m√∂glich ist, primitiv zu automatisieren.  Ruby wurde als Hauptsprache f√ºr die Entwicklung eines Fahrrads ausgew√§hlt.  Eigentlich w√ºrde ich jetzt wahrscheinlich Python w√§hlen, aber in diesem Moment habe ich gerade Ruby gelernt und ich leite neue Sprachen f√ºr mich in solch seltsamen Experimenten. </p><br><h2 id="avtomaticheskaya-narezka-video">  Automatisches Video-Slicing </h2><br><p>  Informationen im Netzwerk zu diesem Thema sind nicht sehr viel.  √úber die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Forschung erinnerten sich Stanford und Adobe</a> sp√§ter (was nicht be√§ngstigend ist, ich brauche immer noch eine weniger ausgefeilte L√∂sung). </p><br><p>  Das Schneiden erfolgt in zwei Schritten: In der Aufnahmephase - grob, in der Renderphase - genauer, mit der M√∂glichkeit, zu viele zugeschnittene Fragmente manuell zu korrigieren.  Grobe Implementierung mit <abbr title="Sprachaktivit√§tserkennung">VAD</abbr> von WebRTC.  Genauer - mit Hilfe von Google Speech (genauer gesagt - mit Hilfe einer Modifikation des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Autosub-</a> Projekts, um Untertitel f√ºr das Video zu generieren).  Ich bin mir sicher, dass es erfolgreichere L√∂sungen geben wird. Es hat sich als das Beste herausgestellt, was wir schnell tun konnten. </p><br><p>  Wenn Sie so etwas mit <code>ffmpeg</code> entwickeln m√∂chten, halten Sie sich an das Prinzip, nicht zu viel in einem Aufruf von <code>ffmpeg</code> zu tun.  Erstellen Sie Zwischendateien und steuern Sie jeden Schritt, damit Sie nicht nach seltsamen Nicht-Google-Fehlern suchen m√ºssen, z. B. nach falschem Schneiden oder nicht angewendetem Effekt. </p><br><p>  Ich beginne die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>daraus resultierende Schande</strong></a> irgendwie so: </p><br><pre> <code class="plaintext hljs">$ bin/vlog-recorder \ --project /path/to/project \ --debug true \ --sound-settings ' --device=usb_card --format=dat' #   arecord r - (RE)START recording s - STOP and SAVE current clip S - STOP and SAVE current clip, don't use auto trimming d - STOP and DELETE current clip p - PLAY last saved clip f - FOCUS camera on center h - show HELP q / Ctrl+C - QUIT [ stopped ] [ battery: 100% / 36¬∞C ]</code> </pre> <br><p>  Ich brauche die Argumente zu <code>arecord</code> , um das Ger√§t explizit anzugeben, um die periodischen St√∂rungen zu vermeiden, die h√∂chstwahrscheinlich auf das ALSA-basierte dsnoop-Plugin zur√ºckzuf√ºhren sind.  Sie k√∂nnen das Protokoll auch √∂ffnen, um den Vorgang des Herunterladens von Dateien vom Telefon zu steuern: <code>tail -f /path/to/project/log.txt</code> . </p><br><p>  Sie k√∂nnen Folgendes schnell in einem Video zur Vorschau rendern: </p><br><pre> <code class="bash hljs">$ bin/vlog-render \ --project /path/to/project \ --language ru \ --video-filters <span class="hljs-string"><span class="hljs-string">'hqdn3d,hflip,curves=psfile=/path/to/curves.acv,vignette'</span></span> \ --speed 1.3 \ --fps 60 \ --preview <span class="hljs-literal"><span class="hljs-literal">true</span></span></code> </pre> <br><p>  Das Argument <code>--video-filters</code> sind die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Filter,</a> die an <code>ffmpeg</code> .  Das Video wird automatisch im <code>mpv</code> Player <code>mpv</code> . </p><br><p>  Sie k√∂nnen die verbleibenden unn√∂tigen Duplikate auch <code>/path/to/project/render.conf</code> oder wegwerfen, indem Sie die <code>/path/to/project/render.conf</code> Datei <code>/path/to/project/render.conf</code> , die dank der erkannten Stimme erkannt werden kann.  Die Idee ist √ºbrigens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nicht neu</a> .  Dort k√∂nnen Sie einzelne Fragmente beschleunigen und gegebenenfalls erfolglose Videoschnitte bearbeiten.  Beim n√§chsten Mal liest <code>render.conf</code> <code>vlog-render</code> <code>render.conf</code> und <code>render.conf</code> die √Ñnderungen. </p><br><p>  Um Fragmente f√ºr einen Video-Editor vorzubereiten, m√ºssen Sie <code>--preview false</code> angeben.  Zus√§tzlich zu den Fragmenten, die in der <code>output</code> liegen, werden sie dennoch in einer <code>output.mp4</code> Datei zusammengef√ºhrt, da ich anfangs nicht sicher war: </p><br><ul><li>  werde ich kleine Clips in Pitivi verwenden </li><li>  oder laden Sie ein langes Video hoch, um es weiter zu schneiden (damit Sie eine Reihe von Effekten auf die ‚ÄûGruppe‚Äú von Clips anwenden k√∂nnen). </li></ul><br><p>  Ich benutze haupts√§chlich die erste Option.  Das zweite war in einem Video mit schlechtem Licht n√ºtzlich: Dort habe ich nur ein St√ºck <code>output.mp4</code> .  F√ºr die zweite Option kann auch das Skript <code>vlog-play-segments</code> n√ºtzlich sein: Mit ihm k√∂nnen Sie schnell alle Pausen zwischen Clips in absteigender Reihenfolge der Dauer anzeigen.  Dies hilft <code>render.conf</code> genauer zu <code>render.conf</code> und sp√§ter beim Bearbeiten dieses langen Videos in Pitivi Zeit zu sparen. </p><br><p>  Die resultierenden kleinen Clips k√∂nnen einmal pro Timeline in Pitivi heruntergeladen werden: W√§hlen Sie alle importierten Clips aus und ziehen Sie sie per Drag &amp; Drop. </p><br><h2 id="kreplenie-dlya-telefona">  Telefonhalterung </h2><br><p>  Ich wollte nicht nach einem geeigneten Telefonst√§nder suchen, und meine H√§nde kratzten bereits an meinem Gesicht, um zumindest etwas aufzunehmen.  Wir nehmen ein St√ºck Pappe zur Hand und schneiden die Telefonhalterung f√ºr unsere Bed√ºrfnisse aus: </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/kl/u8/tj/klu8tjf8huzxyqf71-ci7xnah_w.jpeg" alt="Telefonhalterung"></div><br><p>  Der St√§nder ist auf einem Laptop-Display montiert, um den Abstand zwischen dem Skript und der Kamera zu minimieren. </p><br><h1 id="zapis-zvuka">  Tonaufnahme </h1><br><p>  Akzeptabler Klang ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sehr kritisch</a> .  Zur Hand war ein Boya BY-M1 Mikrofon.  Obwohl es als omnidirektionales Mikrofon beworben wird, wird in der Praxis nur dann ein guter Klang erzielt, wenn Sie es als unidirektional verwenden. </p><br><p>  Es ist noch einfacher, das Mikrofon zum Stehen zu bringen: Wir nehmen eine Flasche Granatapfelsaft, die zur Hand kommt, eine Rolle Klebeband und setzen diesen Konstruktor zusammen: </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xp/qt/1u/xpqt1ue6ikhdrwwh6oqr1x83vo0.jpeg" alt="Mikrofonst√§nder"></div><br><p>  Sie k√∂nnen auch ein Handtuch unter dieses Design legen, um einen Teil der Vibrationen vom Tisch zu unterdr√ºcken und gleichzeitig die H√∂he anzupassen. </p><br><h2 id="zvukovaya-karta">  Soundkarte </h2><br><p>  In meinem Fall ist dies ASUS Xonar U3.  Es stellte sich jedoch heraus, dass es mit einem solchen Mikrofon nicht kompatibel ist: Das Mikrofon verf√ºgt √ºber einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CTIA-</a> Stecker f√ºr Telefone.  Das Problem wurde durch den Adapter in den TRS-Steckern f√ºr Mikrofon und Kopfh√∂rer gel√∂st.  Und es war nicht einfach zu finden: Hersteller solcher Adapter schreiben selten Details.  In meinem Fall hat ein Cablexpert CCA-418W geholfen. </p><br><p>  Ein weiteres Problem mit dieser Karte ist der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DC-Offset</a> im rechten Kanal bei der Aufnahme.  Was nicht st√∂rt, weil  Ich nehme sowieso in Mono auf.  Und f√ºr Software, mit der Sie kein Mono einstellen k√∂nnen, habe ich mit ALSA <a href="">einen</a> guten Kanal auf einen schlechten Kanal <a href="">umgeleitet</a> . </p><br><p>  Diese Karte hat auch Angst vor √úberhitzung.  Sie m√ºssen es vom K√ºhler fernhalten, da es sonst langsamer wird und den Ton in Rucken aufzeichnet. </p><br><h2 id="obrabotka-zvuka">  Tonverarbeitung </h2><br><p>  Ich bearbeite den Ton in den Kopfh√∂rern (in meinem Fall ist es der Pioneer SE-M390) mit einer h√∂heren Lautst√§rke als der, auf der ich normalerweise Musik h√∂re.  Der Algorithmus ist ungef√§hr so: </p><br><ol><li>  Mit Pitivi rendere ich den Sound separat (mit allen gleichen ALAC und MP4).  Oft mache ich mehrere separate Spuren, w√§hle bestimmte Ebenen in Pitivi aus und entferne vor√ºbergehend unn√∂tige. </li><li>  Wenn die empfangenen Dateien sofort in Audacity hochgeladen <strong>werden, verlieren</strong> wir <strong>das</strong> Dehnen / Komprimieren des Audiostreams, was dazu f√ºhren kann, dass Video und Audio nicht mehr synchron sind.  Was nicht offensichtlich ist, passiert nicht bei allen Videos.  Um dies zu verhindern, wenden Sie einfach diese Dehnung / Komprimierung an: <code>ffmpeg -async 1 -i input.mp4 output.flac</code> </li><li>  Laden Sie alle Titel in Audacity herunter.  F√ºgen Sie bei Bedarf Hintergrundmusik hinzu. </li><li>  Stellen Sie f√ºr alle Spuren die gew√ºnschte Lautst√§rke mit Gain ein. </li><li>  Wenden Sie auf die Spur mit der Stimme die Effekte von Rauschunterdr√ºckung (in meinem Fall doppelt), Kompressor und Ausgleich gem√§√ü den Tipps aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Video an</a> . </li><li>  Wir gleichen die Lautst√§rke des Tracks mit der Stimme aus und erh√∂hen sie.  Eine der klassischen M√∂glichkeiten ist Normalisieren, Verst√§rken, Begrenzen und Normalisieren erneut, aber mit diesem Ansatz konnte ich noch nicht die gew√ºnschte Klangqualit√§t erzielen.  <s>Ich verhalte mich vor√ºbergehend so: Zuerst mache ich den Gain des gesamten Tracks so, dass der lauteste Teil ohne √úberlastung klingt, und dann wende ich Amplify manuell f√ºr einzelne Fragmente an.</s>  <strong>Update</strong> : Eine weitere leistungsstarke Methode ist RMS Normalize, Limiter und Normal Normalize.  Die Einstellungen f√ºr RMS-Normalisierung und -Begrenzer k√∂nnen hier √ºbernommen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> .  Trotzdem war diese Methode f√ºr mich nicht sinnvoll, weil  Trotzdem habe ich mich entschlossen, mit dem eingebauten Limiter auf ein anderes Mikrofon (Zoom H1n) umzuschalten, was zu mir passt (daher muss ich mit dem neuen Mikrofon h√∂chstwahrscheinlich nur normal normalisieren, anstatt all dieser Dinge). </li><li>  Das Mikrofon nimmt manchmal Ton mit einigen Fehlern auf, die wie Klicks aussehen.  Sie k√∂nnen mit dem Spectral Edit Multi Tool-Effekt entfernt werden.  In den meisten F√§llen muss der ausgew√§hlte Bereich mehrmals hintereinander mit Strg + R angewendet werden.  <strong>Update</strong> : Dank des neuen Mikrofons habe ich herausgefunden, dass diese Defekte mit etwas √Ñu√üerem zusammenh√§ngen. Dies ist h√∂chstwahrscheinlich eine Kombination aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ger√§uschen im Mund</a> und anderen Nebenger√§uschen. </li><li>  Wir exportieren von Audacity nach FLAC und f√ºhren alles in einer Datei zusammen: <code>ffmpeg -i sound.flac -an -i video.mp4 -c copy output.mkv</code> </li><li>  Zumindest das erste Video, das ich auf verschiedenen Volumes und verschiedenen Ger√§ten getestet habe. </li></ol><br><h1 id="rezultat">  Ergebnis </h1><br><p>  Ich nutze die Gelegenheit, um die N√ºsse in den Regeln zu l√∂sen, und lade Sie ein, den resultierenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>YouTube-Kanal</strong></a> zu besuchen, auf dem ich Einblicke in das effektive Studium der Programmierung und verwandter Disziplinen teile. </p><br><p>  Viel Gl√ºck bei der Entwicklung von Programmen und der Erstellung von Videoblogs! </p><br><p>  <strong>Update</strong> : hat diesen Artikel f√ºr seinen englischsprachigen Blog √ºbersetzt. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de437918/">https://habr.com/ru/post/de437918/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de437908/index.html">Arduino arbeitet mit Google zusammen und f√ºhrt die Zertifizierung ein</a></li>
<li><a href="../de437910/index.html">Fr√ºhlingszivilisation, 1/5</a></li>
<li><a href="../de437912/index.html">Ein kleines Notizbuch f√ºr einen Systemadministrator</a></li>
<li><a href="../de437914/index.html">Jaxb (XJC) generiert Klassen aus XML-Schema (XSD) mit Klassen- und Feldbeschreibungen als Anmerkungen. XJC-Plugin</a></li>
<li><a href="../de437916/index.html">Geben Sie den E-Book-Reader in jede Tasche! R√ºckblick auf die neuesten Innovationen von ONYX BOOX</a></li>
<li><a href="../de437922/index.html">Angriffsmodell: Wo es haupts√§chlich in der elektronischen Beschaffung missbraucht wird und wie man damit umgeht</a></li>
<li><a href="../de437924/index.html">Blockchain Sharding</a></li>
<li><a href="../de437926/index.html">Der ma√ügebliche Leitfaden zum Blockchain-Sharding</a></li>
<li><a href="../de437928/index.html">Wie man Englisch lernt</a></li>
<li><a href="../de437930/index.html">Leuchte Combo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
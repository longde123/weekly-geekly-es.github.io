<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏾‍🤝‍👨🏿 🔎 ⚠️ Cartouche Tarantool: déchiquetage du backend Lua en trois lignes 👇 👨🏻‍💼 💕</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chez Mail.ru Group, nous avons Tarantool - c'est un tel serveur d'applications sur Lua, qui a également une base de données (ou vice versa?). C'est ra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cartouche Tarantool: déchiquetage du backend Lua en trois lignes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/465503/"><img src="https://habrastorage.org/webt/zl/9w/og/zl9wogkzbdgwzzedtahlcg1f8ys.jpeg"><br><br>  Chez Mail.ru Group, nous avons Tarantool - c'est un tel serveur d'applications sur Lua, qui a également une base de données (ou vice versa?).  C'est rapide et cool, mais les capacités d'un serveur ne sont toujours pas illimitées.  La mise à l'échelle verticale n'est pas non plus une panacée, donc Tarantool dispose d'outils pour la mise à l'échelle horizontale - le module vshard <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">[1]</a> .  Il vous permet de partager des données sur plusieurs serveurs, mais vous devez le bricoler pour le configurer et fixer la logique métier. <br><br>  Bonne nouvelle: nous avons collecté les cônes (par exemple <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">[2]</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">[3]</a> ) et scié un autre framework qui simplifiera considérablement la solution à ce problème. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tarantool Cartridge</a> est un nouveau cadre de développement de systèmes distribués complexes.  Il vous permet de vous concentrer sur l'écriture de la logique métier au lieu de résoudre les problèmes d'infrastructure.  Sous la coupe, je vais vous dire comment ce cadre est organisé et comment écrire des services distribués avec. <br><a name="habracut"></a><br><h2>  Et quel est en fait le problème? </h2><br>  Nous avons une tarentule, il y a du vshard - que demander de plus? <br><br>  Tout d'abord, le point est la commodité.  La configuration Vshard est configurée via les tables Lua.  Pour qu'un système distribué de plusieurs processus Tarantool fonctionne correctement, la configuration doit être la même partout.  Personne ne veut le faire manuellement.  Par conséquent, toutes sortes de scripts, Ansible, des systèmes de déploiement sont utilisés. <br><br>  La cartouche elle-même gère la configuration vshard; elle le fait sur la base de sa <i>propre configuration distribuée</i> .  Il s'agit essentiellement d'un simple fichier YAML, dont une copie est stockée dans chaque instance de Tarantool.  La simplification réside dans le fait que le framework lui-même surveille sa configuration et qu'il en soit de même partout. <br><br>  Deuxièmement, le point est de nouveau pratique.  La configuration n'a aucun rapport avec le développement de la logique métier et distrait uniquement le programmeur du travail.  Lorsque nous discutons de l'architecture d'un projet, nous parlons le plus souvent de composants individuels et de leur interaction.  Il est trop tôt pour penser à déployer un cluster dans 3 centres de données. <br><br>  Nous avons résolu ces problèmes à maintes reprises, et à un moment donné, nous avons réussi à développer une approche pour simplifier le travail avec l'application tout au long de son cycle de vie: création, développement, test, CI / CD, maintenance. <br><br>  La cartouche présente le concept de rôle pour chaque processus Tarantool.  Les rôles sont un concept qui permet au développeur de se concentrer sur l'écriture de code.  Tous les rôles disponibles dans le projet peuvent être exécutés sur une seule instance de Tarantool, et cela suffira pour les tests. <br><br>  Caractéristiques principales de la cartouche Tarantool: <br><br><ul><li>  orchestration automatisée des clusters; <br></li><li>  étendre les fonctionnalités de l'application avec de nouveaux rôles <br></li><li>  modèle de développement et de déploiement d'applications; <br></li><li>  sharding automatique intégré; <br></li><li>  intégration avec le framework de test Luatest; <br></li><li>  gestion de cluster à l'aide de WebUI et API; <br></li><li>  outils de packaging et de déploiement. <br></li></ul><br><h2>  Bonjour tout le monde! </h2><br>  Je suis impatient de montrer le cadre lui-même, alors laissons l'histoire de l'architecture pour plus tard, et commençons par une simple.  En supposant que Tarantool lui-même est déjà installé, tout ce qui reste à faire est <br><br><pre><code class="plaintext hljs">$ tarantoolctl rocks install cartridge-cli $ export PATH=$PWD/.rocks/bin/:$PATH</code> </pre> <br>  Ces deux commandes installeront les utilitaires de ligne de commande et vous permettront de créer votre première application à partir du modèle: <br><br><pre> <code class="plaintext hljs">$ cartridge create --name myapp</code> </pre> <br>  Et voici ce que nous obtenons: <br><br><pre> <code class="plaintext hljs">myapp/ ├── .git/ ├── .gitignore ├── app/roles/custom.lua ├── deps.sh ├── init.lua ├── myapp-scm-1.rockspec ├── test │ ├── helper │ │ ├── integration.lua │ │ └── unit.lua │ ├── helper.lua │ ├── integration/api_test.lua │ └── unit/sample_test.lua └── tmp/</code> </pre><br>  Ceci est un référentiel git avec le "Hello, World!" Terminé  application.  Essayons immédiatement de l'exécuter, en préinstallant les dépendances (y compris le framework lui-même): <br><br><pre> <code class="plaintext hljs">$ tarantoolctl rocks make $ ./init.lua --http-port 8080</code> </pre> <br>  Nous avons donc lancé un nœud de la future application fragmentée.  Un profane curieux peut immédiatement ouvrir l'interface Web, utiliser la souris pour configurer un cluster à partir d'un nœud et profiter du résultat, mais il est trop tôt pour se réjouir.  Jusqu'à présent, l'application ne sait rien faire d'utile, je vous parlerai donc de déploiement plus tard, et maintenant il est temps d'écrire du code. <br><br><h2>  Développement d'applications </h2><br>  Imaginez, nous allons concevoir un projet qui devrait recevoir des données, les enregistrer et créer un rapport une fois par jour. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/357/881/992/3578819921cd1788d44a85856c6aac45.png"><br><br>  Nous commençons à dessiner un diagramme et à y placer trois composants: passerelle, stockage et ordonnanceur.  Nous travaillons davantage sur l'architecture.  Puisque nous utilisons vshard comme stockage, nous ajoutons vshard-router et vshard-storage au schéma.  Ni la passerelle ni l'ordonnanceur n'accéderont directement au référentiel, il y a un routeur pour ça, il a été créé pour ça. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d4/65d/b72/2d465db72cc6c6db294c84748566513d.png"><br><br>  Ce schéma ne reflète toujours pas exactement ce que nous allons créer dans le projet, car les composants semblent abstraits.  Nous devons également voir comment cela est projeté sur un véritable Tarantool - nous allons regrouper nos composants par processus. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e88/314/779/e8831477921e9be63de6ada1e9385b86.png"><br><br>  Garder vshard-router et gateway sur des instances distinctes n'a pas beaucoup de sens.  Pourquoi devons-nous à nouveau parcourir le réseau, si c'est déjà la responsabilité du routeur?  Ils doivent être exécutés dans le même processus.  Autrement dit, dans le même processus, la passerelle et vshard.router.cfg sont initialisés et les laissent interagir localement. <br><br>  C'était pratique de travailler avec trois composants au stade de la conception, mais en tant que développeur, pendant que j'écris du code, je ne veux pas penser à lancer trois instances de Tarnatool.  Je dois exécuter des tests et vérifier que j'ai correctement écrit la passerelle.  Ou peut-être que je veux démontrer une fonctionnalité à mes collègues.  Pourquoi devrais-je souffrir avec le déploiement de trois copies?  C'est ainsi qu'est né le concept de rôles.  Un rôle est un module Loach régulier dont le cycle de vie est géré par Cartridge.  Dans cet exemple, il y en a quatre - passerelle, routeur, stockage, planificateur.  Dans un autre projet, il peut y en avoir plus.  Tous les rôles peuvent être lancés en un seul processus, et cela suffira. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fdf/726/90c/fdf72690c30cc9b2b3ade8af667494dc.png"><br><br>  Et quand il s'agit de déployer en staging ou en opération, nous assignerons chaque ensemble de rôles à chaque processus Tarantool, en fonction des capacités matérielles: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a03/945/59f/a0394559f3f372e9de056ab4a080dff4.png"><br><br><h2>  Gestion de la topologie </h2><br>  Les informations sur l'endroit où les rôles sont lancés doivent être stockées quelque part.  Et ce «quelque part» est la configuration distribuée que j'ai mentionnée ci-dessus.  La chose la plus importante est la topologie de cluster.  Voici 3 groupes de réplication de 5 processus Tarantool: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/140/04d/28a/14004d28a893832830ac61ad9c4207dd.png"><br><br>  Nous ne voulons pas perdre de données, nous traitons donc soigneusement les informations sur les processus en cours d'exécution.  La cartouche surveille la configuration avec un commit en deux phases.  Dès que nous voulons mettre à jour la configuration, il vérifie d'abord la disponibilité de toutes les instances et leur disponibilité à accepter la nouvelle configuration.  Après cela, la deuxième phase applique la configuration.  Ainsi, même si une instance était temporairement indisponible, rien de terrible ne se produira.  La configuration ne s'appliquera tout simplement pas et vous verrez une erreur à l'avance. <br><br>  Dans la section topologie est également indiqué un paramètre aussi important que le leader de chaque groupe de réplication.  Il s'agit généralement de l'instance qui est enregistrée.  Les autres sont le plus souvent en lecture seule, bien qu'il puisse y avoir des exceptions.  Parfois, les développeurs courageux n'ont pas peur des conflits et peuvent écrire des données sur plusieurs répliques en parallèle, mais il y a certaines opérations qui, malgré tout, ne devraient pas être effectuées deux fois.  Il y a un signe d'un leader pour cela. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/725/6db/376/7256db376d8fe207bbf57f5f82054c3f.png"><br><br><h2>  Vie de rôle </h2><br>  Pour qu'un rôle abstrait existe dans une telle architecture, le cadre doit en quelque sorte les gérer.  Naturellement, le contrôle s'effectue sans redémarrer le processus Tarantool.  Il existe 4 rappels pour la gestion des rôles.  La cartouche elle-même les appellera en fonction de ce qu'elle dit dans une configuration distribuée, appliquant ainsi la configuration à des rôles spécifiques. <br><br><pre> <code class="lua hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">validate_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">apply_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">stop</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span></code> </pre><br>  Chaque rôle a une fonction <code>init</code> .  Il est appelé une fois, soit lorsque le rôle est activé, soit lorsque Tarantool redémarre.  Il est pratique, par exemple, d'initialiser box.space.create, ou le planificateur peut démarrer une fibre d'arrière-plan, qui fera le travail à certains intervalles. <br><br>  La fonction <code>init</code> peut ne pas suffire.  La cartouche permet aux rôles de tirer parti de la configuration distribuée qu'elle utilise pour stocker la topologie.  Dans la même configuration, nous pouvons déclarer une nouvelle section et y stocker un fragment de la configuration métier.  Dans mon exemple, cela peut être un schéma de données ou des paramètres de planification pour le rôle de planificateur. <br><br>  Le cluster appelle <code>validate_config</code> et <code>apply_config</code> chaque fois que la configuration distribuée change.  Lorsqu'une configuration est appliquée par une validation en deux phases, le cluster vérifie que chaque rôle est prêt à accepter cette nouvelle configuration et, si nécessaire, signale une erreur à l'utilisateur.  Lorsque tout le monde a convenu que la configuration est normale, <code>apply_config</code> est <code>apply_config</code> . <br><br>  Les rôles ont également une méthode d' <code>stop</code> , qui est nécessaire pour effacer les signes vitaux du rôle.  Si nous disons que le planificateur sur ce serveur n'est plus nécessaire, il peut arrêter les fibres qu'il a démarrées avec <code>init</code> . <br><br>  Les rôles peuvent interagir les uns avec les autres.  Nous avons l'habitude d'écrire des appels de fonction en Lua, mais il se peut que nous n'ayons pas le rôle dont nous avons besoin dans ce processus.  Pour faciliter l'accès au réseau, nous utilisons le module auxiliaire rpc (appel de procédure à distance), qui est construit sur la base de la netbox standard intégrée à Tarantool.  Cela peut être utile si, par exemple, votre passerelle souhaite demander directement au planificateur de faire le travail maintenant, plutôt que d'attendre un jour. <br><br>  Un autre point important est d'assurer la tolérance aux pannes.  La cartouche utilise le protocole SWIM <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">[4]</a> pour surveiller la santé.  En bref, les processus échangent des «rumeurs» via UDP - chaque processus informe ses voisins des dernières nouvelles et ils répondent.  Si la réponse ne vient pas, Tarantool commence à soupçonner que quelque chose ne va pas, et après un certain temps, il récite la mort et commence à dire à tout le monde autour de cette nouvelle. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dd6/612/8f8/dd66128f843008534c5bd2b7d3b3474d.png"><br><br>  Sur la base de ce protocole, Cartridge organise le basculement automatique.  Chaque processus surveille son environnement et si le leader cesse soudainement de répondre, la réplique peut jouer son rôle sur elle-même et Cartridge configurera les rôles en cours d'exécution en conséquence. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/23f/5b9/cc1/23f5b9cc17987df38ddddcf5000ab328.png"><br><br>  Vous devez être prudent ici, car des allers-retours fréquents peuvent entraîner des conflits de données lors de la réplication.  Activer le basculement automatique au hasard, bien sûr, n'en vaut pas la peine.  Vous devez comprendre clairement ce qui se passe et être sûr que la réplication ne se cassera pas après que le leader se rétablit et que la couronne lui soit rendue. <br><br>  De tout ce qui a été dit, il peut sembler que les rôles sont similaires aux microservices.  Dans un sens, ils ne le sont qu'en tant que modules dans les processus Tarantool.  Mais il existe un certain nombre de différences fondamentales.  Tout d'abord, tous les rôles de projet doivent vivre dans une seule base de code.  Et tous les processus Tarantool doivent être lancés à partir d'une seule base de code, afin qu'il n'y ait pas de surprises comme celles-ci lorsque nous essayons d'initialiser le planificateur, mais ce n'est tout simplement pas le cas.  En outre, n'autorisez pas les différences dans les versions du code, car le comportement du système dans une telle situation est très difficile à prévoir et à déboguer. <br><br>  Contrairement à Docker, nous ne pouvons pas simplement prendre «l'image» d'un rôle, le transférer sur une autre machine et l'exécuter là-bas.  Nos rôles ne sont pas aussi isolés que les conteneurs Docker.  De plus, nous ne pouvons pas exécuter deux rôles identiques sur la même instance.  Le rôle est là ou pas, en un sens c'est singleton.  Et troisièmement, les rôles devraient être les mêmes au sein de l'ensemble du groupe de réplication, car sinon ce serait ridicule - les données sont les mêmes et la configuration est différente. <br><br><h2>  Outils de déploiement </h2><br>  J'ai promis de montrer comment la cartouche aide à déployer des applications.  Pour faciliter la vie des autres, le framework contient des packages RPM: <br><br><pre> <code class="plaintext hljs">$ cartridge pack rpm myapp #    ./myapp-0.1.0-1.rpm $ sudo yum install ./myapp-0.1.0-1.rpm</code> </pre> <br>  Le package installé contient presque tout ce dont vous avez besoin: à la fois l'application et les dépendances de lancement installées.  Tarantool arrivera également sur le serveur en tant que dépendance de package RPM, et notre service est prêt à être lancé.  Cela se fait via systemd, mais vous devez d'abord écrire une petite configuration.  Au minimum, spécifiez l'URI de chaque processus.  Trois par exemple suffit. <br><br><pre> <code class="plaintext hljs">$ sudo tee /etc/tarantool/conf.d/demo.yml &lt;&lt;CONFIG myapp.router: {"advertise_uri": "localhost:3301", "http_port": 8080} myapp.storage_A: {"advertise_uri": "localhost:3302", "http_enabled": False} myapp.storage_B: {"advertise_uri": "localhost:3303", "http_enabled": False} CONFIG</code> </pre> <br>  Il y a une nuance intéressante ici.  Au lieu de spécifier uniquement le port du protocole binaire, nous spécifions l'adresse publique de l'ensemble du processus, y compris le nom d'hôte.  Cela est nécessaire pour que les nœuds du cluster sachent comment se connecter les uns aux autres.  C'est une mauvaise idée d'utiliser l'adresse 0.0.0.0 comme advertise_uri, ce devrait être une adresse IP externe, pas un socket de liaison.  Sans cela, rien ne fonctionnera, donc Cartridge ne laissera tout simplement pas le nœud avec le mauvais advertise_uri démarrer. <br><br>  Maintenant que la configuration est prête, vous pouvez démarrer les processus.  Étant donné qu'une unité systemd standard ne permet pas de démarrer plus d'un processus, les applications sur la cartouche installent ce que l'on appelle  unités instanciées qui fonctionnent comme ceci: <br><br><pre> <code class="plaintext hljs">$ sudo systemctl start myapp@router $ sudo systemctl start myapp@storage_A $ sudo systemctl start myapp@storage_B</code> </pre> <br>  Dans la configuration, nous avons spécifié le port HTTP sur lequel Cartridge sert l'interface Web - 8080. Passons en revue et voyons: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d7c/1dd/64f/d7c1dd64fdca2fed35c71dca3caaf382.png"><br><br>  Nous voyons que les processus, bien qu'ils soient en cours d'exécution, ne sont pas encore configurés.  La cartouche ne sait pas encore qui doit se répliquer avec qui et ne peut pas décider seule, elle attend donc notre action.  Et notre choix n'est pas grand: la vie d'un nouveau cluster commence par la configuration du premier nœud.  Ensuite, nous ajoutons le reste au cluster, nous leur attribuons des rôles, et ce déploiement peut être considéré comme terminé avec succès. <br><br>  Versez un verre de votre boisson préférée et détendez-vous après une longue semaine de travail.  L'application peut être exploitée. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cf6/c86/e44/cf6c86e448cf42c9ce190a4d13307c3a.png"><br><br><h2>  Résumé </h2><br>  Et quels résultats?  Essayez, utilisez, laissez des commentaires, démarrez des tickets sur le github. <br><br><h2>  Les références </h2><br>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tarantool »2.2» Référence »Référence Rocks» Module vshard</a> <br><br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comment nous avons mis en œuvre le cœur de métier d'investissement d'Alfa-Bank basé sur Tarantool</a> <br><br>  [3] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Architecture de facturation de nouvelle génération: transition vers Tarantool</a> <br><br>  [4] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SWIM - protocole de construction de cluster</a> <br><br>  [5] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub - tarantool / cartouche-cli</a> <br><br>  [6] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub - tarantool / cartouche</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr465503/">https://habr.com/ru/post/fr465503/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr465493/index.html">Langage de programmation rapide sur Raspberry Pi</a></li>
<li><a href="../fr465495/index.html">Comment ne pas perdre de trafic lors du passage à un nouveau domaine: cas "Vse10"</a></li>
<li><a href="../fr465497/index.html">Messagerie secrète via les journaux du serveur</a></li>
<li><a href="../fr465499/index.html">Une nouvelle loi pour décrire la vitesse de développement des ordinateurs quantiques?</a></li>
<li><a href="../fr465501/index.html">Enseignements tirés 40 ans après le décollage et déclin rapide de la première «application tueur»</a></li>
<li><a href="../fr465509/index.html">Asya Patrysheva: «Internet n'est plus seulement un réseau. C'est la vie. "</a></li>
<li><a href="../fr465511/index.html">Entre les première et deuxième lignes de support technique</a></li>
<li><a href="../fr465513/index.html">Un journal dans l'œil: quelles sont les vulnérabilités des systèmes de vidéosurveillance</a></li>
<li><a href="../fr465515/index.html">Formation Cisco 200-125 CCNA v3.0. Jour 27. Introduction à ACL. Partie 1</a></li>
<li><a href="../fr465517/index.html">DoodleBattle Paper Board Game</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
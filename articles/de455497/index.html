<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∏üèø üíØ ü§≤üèΩ Optimale lineare Filterung: vom Gradientenabstieg bis zum adaptiven Filter üßò üôéüèΩ üê£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich m√∂chte das Thema Abstracts zum Master-Fach "Kommunikation und Signalverarbeitung" (TU Ilmenau) weiterentwickeln und eines der Hauptthemen des Kurs...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimale lineare Filterung: vom Gradientenabstieg bis zum adaptiven Filter</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455497/"><p>  Ich m√∂chte das Thema Abstracts zum Master-Fach "Kommunikation und Signalverarbeitung" (TU Ilmenau) weiterentwickeln und eines der Hauptthemen des Kurses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"Adaptive und Array-Signalverarbeitung" fortsetzen</a> .  Die Grundlagen der adaptiven Filterung. </p><br><p>  <u>F√ºr wen dieser Artikel zuerst geschrieben wurde:</u> <u><br></u> <br>  1) f√ºr eine Studentenbruderschaft einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einheimischen Spezialit√§t</a> ; <br>  2) f√ºr Lehrer, die praktische Seminare vorbereiten, sich aber noch nicht f√ºr die Tools entschieden haben - nachfolgend finden Sie Beispiele in <strong>Python</strong> und <strong>Matlab / Octave</strong> ; <br>  3) f√ºr alle, die sich f√ºr das Thema Filterung interessieren. </p><br><p>  <u>Was ist unter dem Schnitt zu finden:</u> <u><br></u> <br>  1) Informationen aus der Theorie, die ich so kurz wie m√∂glich zu ordnen versuchte, die mir aber informativ erscheinen; <br>  2) Beispiele f√ºr die Verwendung von Filtern: insbesondere als Teil des Equalizers f√ºr das Antennenarray; <br>  3) Links zu grundlegender Literatur und offenen Bibliotheken (in Python), die f√ºr die Forschung n√ºtzlich sein k√∂nnen. </p><br><p>  Begr√º√üen Sie im Allgemeinen und lassen Sie uns alles nach Punkten sortieren. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2f1/98b/d67/2f198bd673789161db58ad770c629faf.jpg"></p><a name="habracut"></a><br><p>  <em>Die nachdenkliche Person auf dem Foto ist vielen bekannt, glaube ich, Norbert Wiener.</em>  <em>Zum gr√∂√üten Teil werden wir den Filter seines Namens untersuchen.</em>  <em>Man kann jedoch nicht vers√§umen, unseren Landsmann zu erw√§hnen - Andrei Nikolaevich Kolmogorov, dessen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel von 1941</a> ebenfalls einen wesentlichen Beitrag zur Entwicklung der optimalen Filtertheorie leistete, die selbst in englischen Quellen als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kolmogorov-Wiener-Filtertheorie bezeichnet wird</a> .</em> </p><br><h2 id="chto-rassmatrivaem">  Was erw√§gen wir? </h2><br><p>  Heute betrachten wir ein klassisches Filter mit einer endlichen Impulsantwort (FIR, endliche Impulsantwort), die durch die folgende einfache Schaltung beschrieben werden kann (Abb. 1). </p><br><p><img src="https://habrastorage.org/webt/to/or/u7/tooru7vj_f6aj0oe9wvpcde28kw.png"></p><br><p>  <em>Abb. 1.</em>  <em>Das FIR-Filterschema zur Untersuchung des Wiener-Filters. [1.</em>  <em>S.117]</em> </p><br><p>  Wir werden in Matrixform schreiben, was genau am Ausgang dieses Standes sein wird: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/43f/615/39b/43f61539ba1f68998b24c39a8c539706.svg" alt="e (n) = d (n) - \ hat {d} (n | \ mathcal {U} _n) = d (n) - \ mathbf {w} ^ H \ mathbf {u} \ qquad (1)"></div><br><p>  Entschl√ºsseln Sie die Notation: </p><br><ul><li><img src="https://habrastorage.org/getpro/habr/post_images/6c5/882/04e/6c588204ed25c8bbb270106d7f08a4dd.svg" alt="e (n)">  Ist die Differenz (Fehler) zwischen dem gegebenen und dem empfangenen Signal </li><li><img src="https://habrastorage.org/getpro/habr/post_images/771/807/bef/771807bef08a5612654d97e67695cf07.svg" alt="d (n)">  Ist ein vordefiniertes Signal </li><li><img src="https://habrastorage.org/getpro/habr/post_images/960/b4e/a48/960b4ea48f3968f42c64eed1af640e1d.svg" alt="\ mathbf {u}">  Ist ein Vektor von Abtastwerten oder mit anderen Worten ein Signal am Eingang des Filters </li><li><img src="https://habrastorage.org/getpro/habr/post_images/75f/f22/a5a/75ff22a5a4f95cbe489056bf704597f0.svg" alt="\ hat {d} (n | \ mathcal {U} _n)">  Ist das Signal am Filterausgang </li><li><img src="https://habrastorage.org/getpro/habr/post_images/6f6/81f/9be/6f681f9be2ae30d1666fec498b59b3a3.svg" alt="\ mathbf {w} ^ H.">  - Dies ist eine hermitische Konjugation des Filterkoeffizientenvektors. - <u>In ihrer optimalen Auswahl liegt die Anpassungsf√§higkeit des Filters</u> </li></ul><br><p>  Sie haben wahrscheinlich bereits vermutet, dass wir den kleinsten Unterschied zwischen dem gegebenen und dem gefilterten Signal anstreben werden, dh den kleinsten Fehler.  Dies bedeutet, dass wir vor einer Optimierungsaufgabe stehen. </p><br><h2 id="chto-budem-optimizirovat">  Was werden wir optimieren? </h2><br><p>  Um zu optimieren oder vielmehr zu minimieren, <strong>meinen</strong> wir nicht nur <strong>den</strong> Fehler, den <strong>mittleren quadratischen Fehler</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MSE - Mean Sqared Error</a> ): </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b83/b62/193/b83b62193ca3490681c2cd8910e4d99a.svg" alt="MSE: J (\ mathbf {w}) = E \ {e (n) ^ 2 \} \ qquad (2)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/c48/76a/b10/c4876ab1024579fa30ea997a45efd50a.svg" alt="J (\ mathbf {w})">  bezeichnet die Kostenfunktion des Vektors der Filterkoeffizienten und <img src="https://habrastorage.org/getpro/habr/post_images/f39/8e4/ded/f398e4ded6db9e55108d575a9b7d2f1f.svg" alt="E \ {* \}">  bezeichnet mat.  Warten. </p><br><p>  Das Quadrat ist in diesem Fall sehr angenehm, da es bedeutet, dass wir mit dem Problem der <em>konvexen Programmierung</em> konfrontiert sind (ich google nur ein solches Analogon der englischen <em>konvexen Optimierung</em> ), was wiederum ein <u>einzelnes Extremum</u> impliziert (in unserem Fall ein Minimum). </p><br><p><img src="https://habrastorage.org/webt/hr/xj/mb/hrxjmbmimv7c2uvvicnuklqn9y0.png"></p><br><p>  <em>Abb. 2.</em>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Oberfl√§che des mittleren quadratischen Fehlers</a> .</em> </p><br><p>  Unsere Fehlerfunktion hat eine kanonische Form [1, S. 121]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5da/121/788/5da121788f801656b55ee459c2f4d56d.svg" alt="J (\ mathbf {w}) = \ sigma ^ 2_d - \ mathbf {w} ^ H \ mathbf {p} - \ mathbf {p} ^ H \ mathbf {w} + \ mathbf {w} ^ H \ mathbf { R} \ mathbf {w} \ qquad (3)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/24f/50c/410/24f50c410ab0c2ca3dd302c630c734e8.svg" alt="\ sigma ^ 2_d">  Ist die Varianz des erwarteten Signals, <img src="https://habrastorage.org/getpro/habr/post_images/82c/861/559/82c86155992ccb2e83d6f9f3f9e92737.svg" alt="\ mathbf {p} = E \ {\ mathbf {u} (n) d ^ * (n) \}">  Ist der Kreuzkorrelationsvektor zwischen dem Eingangsvektor und dem erwarteten Signal und <img src="https://habrastorage.org/getpro/habr/post_images/664/01c/a88/66401ca883516093b2e73b7d519588ac.svg" alt="\ mathbf {R} = E \ {\ mathbf {u} (n) \ mathbf {u} ^ H (n) \}">  Ist die Autokorrelationsmatrix des Eingangssignals. </p><br><div class="spoiler">  <b class="spoiler_title">Die Schlussfolgerung dieser Formel ist hier (ich habe es klarer versucht).</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/q6/sw/p5/q6swp5meopsxauj7yvygkwuc7-g.png" width="650"></div></div><br><p>  Wie oben erw√§hnt, haben wir ein Extremum (Minimum), wenn wir √ºber konvexe Programmierung sprechen.  Um den minimalen Wert der Kostenfunktion (den minimalen quadratischen Mittelwertfehler) zu ermitteln, reicht es aus, die Tangente der Steigung der Tangente oder mit anderen Worten die <u>partielle Ableitung</u> in <u>Bezug</u> auf unsere untersuchte Variable zu ermitteln: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1cd/d0b/114/1cdd0b114b5457761dd27338b4ee57f4.svg" alt="\ frac {\ delta J (\ mathbf {w})} {\ delta w ^ *} = - \ mathbf {p} + \ mathbf {R} \ mathbf {w} \ qquad (4)"></div><br><p>  Im besten Fall ( <img src="https://habrastorage.org/getpro/habr/post_images/ac6/219/d1c/ac6219d1cc1885e6f5936e40b5c7a980.svg" alt="\ mathbf {w} = \ mathbf {w} _ {opt}">  ) sollte der Fehler nat√ºrlich minimal sein, was bedeutet, dass wir die Ableitung mit Null gleichsetzen: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/777/46e/9a7/77746e9a7ab3ff9df3cf340da4b7238d.svg" alt="\ mathbf {R} \ mathbf {w} _ {opt} = \ mathbf {p} \ qquad (5)"></div><br><p>  Eigentlich ist es hier unser Ofen, von dem aus wir weiter tanzen werden: Vor uns liegt ein <u>System linearer Gleichungen</u> . </p><br><h2 id="kak-budem-reshat">  Wie werden wir uns entscheiden? </h2><br><p>  Es sollte sofort angemerkt werden, dass beide L√∂sungen, die wir unten betrachten werden, in diesem Fall theoretisch und lehrreich sind, da <img src="https://habrastorage.org/getpro/habr/post_images/1cf/d71/499/1cfd714992b16fcc961ad10bcc855134.svg" alt="\ mathbf {R}">  und <img src="https://habrastorage.org/getpro/habr/post_images/1fa/0e8/e9e/1fa0e8e9e33d7dbd533901bbf025bd9f.svg" alt="\ mathbf {p}">  im Voraus bekannt (dh wir hatten die angebliche F√§higkeit, ausreichende Statistiken zu sammeln, um diese zu berechnen).  Die Analyse solcher vereinfachten Beispiele hier ist jedoch das Beste, was Sie sich vorstellen k√∂nnen, um die grundlegenden Ans√§tze zu verstehen. </p><br><h3 id="analiticheskoe-reshenie">  Analytische L√∂sung </h3><br><p>  Dieses Problem kann sozusagen in der Stirn gel√∂st werden - mit inversen Matrizen: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/759/c3e/052/759c3e052c502aa04fe6da682a41ea2a.svg" alt="\ mathbf {w} _ {opt} = \ mathbf {R} ^ {- 1} \ mathbf {p} \ qquad (6)"></div><br><p>  Ein solcher Ausdruck hei√üt Wiener-Hopf-Gleichung - er ist f√ºr uns immer noch als Referenz n√ºtzlich. </p><br><blockquote>  Um v√∂llig akribisch zu sein, w√§re es wahrscheinlich korrekter, diesen Fall allgemein aufzuschreiben, d. H.  nicht mit <img src="https://habrastorage.org/getpro/habr/post_images/bd8/f0f/04a/bd8f0f04a92fe1055c350d4e32a8a256.svg" alt="^ {-}">  und mit <img src="https://habrastorage.org/getpro/habr/post_images/017/3d5/ed9/0173d5ed99b25d00ec4245287142f165.svg" alt="^ +">  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pseudo-Invert</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/003/47f/bca/00347fbca15f40943c7fb7b20c38a3f9.svg" alt="\ mathbf {R} ^ + = \ mathbf {R} ^ H (\ mathbf {R} \ mathbf {R} ^ H) ^ {- 1}"><br><br>  Die Autokorrelationsmatrix kann jedoch nicht nicht quadratisch oder singul√§r sein, daher glauben wir zu Recht, dass es keinen Widerspruch gibt. </blockquote><p>  Aus dieser Gleichung ist es analytisch m√∂glich, abzuleiten, wie hoch der Mindestwert der Kostenfunktion sein wird (d. H. In unserem Fall <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MMSE</a> - minimaler mittlerer quadratischer Fehler): </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c00/d2d/1f9/c00d2d1f9427762a17deae92ae3ea77c.svg" alt="J_ {min} = J (\ mathbf {w} _ {opt}) = \ sigma ^ 2_d - \ mathbf {p} ^ H \ mathbf {R} ^ {- 1} \ mathbf {p} \ qquad (7)"></div><br><div class="spoiler">  <b class="spoiler_title">Die Ableitung der Formel ist hier (ich habe auch versucht, sie bunter zu machen).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/ds/vh/nx/dsvhnxoudmo_qd4hesg_qkysdg8.jpeg"></p></div></div><br><p>  Nun, es gibt eine L√∂sung. </p><br><h3 id="reshenie-iterativnym-metodom">  Iterative L√∂sung </h3><br><p>  Ja, es ist jedoch m√∂glich, ein lineares Gleichungssystem zu l√∂sen, ohne die Autokorrelationsmatrix iterativ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu</a> invertieren ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">um Berechnungen zu speichern</a> ).  Betrachten Sie zu diesem Zweck die native und verst√§ndliche <strong>Methode des Gradientenabfalls</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Methode des steilsten / Gradientenabstiegs</a> ). </p><br><p>  Das Wesen des Algorithmus kann auf Folgendes reduziert werden: </p><br><ol><li>  Wir setzen die gew√ºnschte Variable auf einen Standardwert (z. B. <img src="https://habrastorage.org/getpro/habr/post_images/231/554/6f0/2315546f0e8aa127a8da693d41c53ff6.svg" alt="\ mathbf {w} (0) = \ mathbf {0}">  ) </li><li>  W√§hle einen Schritt <img src="https://habrastorage.org/getpro/habr/post_images/849/a42/16c/849a4216c1bc55877bc86f4a97513f7a.svg" alt="\ mu">  (Wie genau wir uns entscheiden, werden wir weiter unten besprechen). </li><li>  Und dann gehen wir sozusagen mit einem bestimmten Schritt entlang unserer urspr√ºnglichen Oberfl√§che (in unserem Fall ist dies die MSE-Oberfl√§che) hinunter <img src="https://habrastorage.org/getpro/habr/post_images/849/a42/16c/849a4216c1bc55877bc86f4a97513f7a.svg" alt="\ mu">  und eine bestimmte Geschwindigkeit, die durch die Gr√∂√üe des Gradienten bestimmt wird. </li></ol><br><p>  Daher der Name: <em>Gef√§lle</em> - Gef√§lle oder <em>steilste</em> - schrittweise <em>Abfahrt</em> - Abfahrt. </p><br><p>  Der Gradient in unserem Fall ist bereits bekannt: Wir haben ihn tats√§chlich gefunden, als wir die Kostenfunktion differenzierten (die Oberfl√§che ist konkav, vergleiche mit [1, S. 220]).  Wir schreiben, wie die Formel f√ºr die iterative Aktualisierung der gew√ºnschten Variablen (Filterkoeffizienten) aussehen wird [1, S.  220]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6d6/4ff/7eb/6d64ff7eb98c4274e05a33a3eb127933.svg" alt="\ mathbf {w} (n + 1) = \ mathbf {w} (n) - \ mu [- \ mathbf {p} + \ mathbf {R} \ mathbf {w} (n)] \ qquad (8)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/fd6/0b2/b5b/fd60b2b5be4b7e93a0d905dd970c314f.svg" alt="n">  Ist die Iterationsnummer. </p><br><p>  Lassen Sie uns nun √ºber die Auswahl einer Schrittgr√∂√üe sprechen. </p><br><p>  Wir listen die offensichtlichen Pr√§missen auf: </p><br><ul><li>  Schritt kann nicht negativ oder Null sein </li><li>  Der Schritt sollte nicht zu gro√ü sein, sonst konvergiert der Algorithmus nicht (er springt sozusagen von Kante zu Kante, ohne ins Extreme zu fallen). </li><li>  Der Schritt kann nat√ºrlich sehr klein sein, aber dies ist auch nicht ganz w√ºnschenswert - der Algorithmus wird mehr Zeit aufwenden </li></ul><br><p>  In Bezug auf den Wiener Filter wurden Einschr√§nkungen nat√ºrlich schon vor langer Zeit gefunden [1, S. 222-226]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/67d/64a/b6c/67d64ab6cf46d3438791ccea853421fb.svg" alt="0 <\ mu <\ frac {2} {\ lambda_ {max}} \ qquad (9)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/e5d/fa8/35d/e5dfa835ded907ecd7cf2b56d7061307.svg" alt="\ lambda_ {max}">  Ist der gr√∂√üte Eigenwert der Autokorrelationsmatrix <img src="https://habrastorage.org/getpro/habr/post_images/1cf/d71/499/1cfd714992b16fcc961ad10bcc855134.svg" alt="\ mathbf {R}">  . </p><br><blockquote>  Eigenwerte und Vektoren sind √ºbrigens ein eigenst√§ndiges interessantes Thema im Zusammenhang mit der linearen Filterung.  <em>F√ºr</em> diesen Fall gibt es sogar einen ganzen <em>Eigenfilter</em> (siehe Anhang 1). </blockquote><p>  Aber das ist zum Gl√ºck noch nicht alles.  Es gibt auch eine optimale, adaptive L√∂sung: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f4c/3c2/fdf/f4c3c2fdf8ae926094bb67b391cd896b.svg" alt="\ mu (n) = \ frac {\ mathbf {\ gamma} (n) ^ H \ mathbf {\ gamma} (n)} {\ mathbf {\ gamma} (n) ^ H \ mathbf {R} \ mathbf { \ gamma} (n)} \ qquad (10)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/1b0/4a6/a31/1b04a6a318f99ec501290f59c0f924ac.svg" alt="\ mathbf {\ gamma} (n) = \ mathbf {p} - \ mathbf {R} \ mathbf {w} (n)">  Ist ein negativer Gradient.  Wie aus der Formel ersichtlich ist, wird der Schritt in jede Iteration neu berechnet, dh angepasst. </p><br><div class="spoiler">  <b class="spoiler_title">Die Schlussfolgerung der Formel ist hier (viel Mathematik - schauen Sie sich nur die ber√ºchtigten Nerds wie ich an).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/au/hq/0s/auhq0sxrspaduxdkclqctns1xtw.jpeg"></p></div></div><br><p>  Okay, f√ºr die zweite Entscheidung haben wir auch die B√ºhne bereitet. </p><br><h2 id="a-nelzya-li-na-primerah">  Aber ist es mit Beispielen m√∂glich? </h2><br><p>  Aus Gr√ºnden der Klarheit werden wir eine kleine Simulation durchf√ºhren.  Wir werden <strong>Python 3.6.4 verwenden</strong> . </p><br><blockquote>  Ich werde gleich sagen, dass diese Beispiele Teil einer der Hausaufgaben sind, von denen jede den Sch√ºlern innerhalb von zwei Wochen zur L√∂sung angeboten wird.  Ich habe den Teil unter Python umgeschrieben (um die Sprache unter den Funkingenieuren bekannt zu machen).  Vielleicht werden Sie im Web auf einige andere Optionen anderer ehemaliger Studenten sto√üen. </blockquote><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.linalg <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> toeplitz <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convmtx</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(h,n)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> toeplitz(np.hstack([h, np.zeros(n<span class="hljs-number"><span class="hljs-number">-1</span></span>)]),\ np.hstack([h[<span class="hljs-number"><span class="hljs-number">0</span></span>], np.zeros(n<span class="hljs-number"><span class="hljs-number">-1</span></span>)])) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MSE_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(sigmaS, R, p, w)</span></span></span><span class="hljs-function">:</span></span> w = w.reshape(w.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) wH = np.conj(w).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, w.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) p = p.reshape(p.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) pH = np.conj(p).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, p.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) MSE = sigmaS - np.dot(wH, p) - np.dot(pH, w) + np.dot(np.dot(wH, R), w) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> MSE[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mu_opt_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(gamma, R)</span></span></span><span class="hljs-function">:</span></span> gamma = gamma.reshape(gamma.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) gammaH = np.conj(gamma).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, gamma.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) mu_opt = np.dot(gammaH, gamma) / np.dot(np.dot(gammaH, R), gamma) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mu_opt[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  Wir werden unser lineares Filter f√ºr das <u>Kanalentzerrungsproblem verwenden</u> , dessen Hauptzweck darin besteht, die verschiedenen Auswirkungen dieses Kanals auf das Nutzsignal zu nivellieren. </p><br><blockquote>  Der Quellcode kann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> oder <a href="">hier</a> in einer Datei heruntergeladen <a href="">werden</a> (ja, ich hatte so ein Hobby - Wikipedia bearbeiten). </blockquote><br><h3 id="model-sistemy">  Systemmodell </h3><br><p>  Angenommen, es gibt ein Antennenarray (wir haben es bereits in einem Artikel √ºber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MUSIK untersucht</a> ). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/61a/9c2/da7/61a9c2da745081459f9001d0252936f1.png"></p><br><p>  <em>Abb.</em>  <em>3. Nicht gerichtetes lineares Antennenarray (ULAA - Uniform Linear Antenna Array) [2, S.</em>  <em>32].</em> </p><br><p>  Definieren Sie die anf√§nglichen Gitterparameter: </p><br><pre> <code class="python hljs">M = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (number of sensors)</span></span></code> </pre> <br><p>  In diesem Artikel werden wir so etwas wie einen <u>Breitbandkanal mit Fading betrachten</u> , dessen charakteristisches Merkmal die <u>Mehrwegeausbreitung ist</u> .  In solchen F√§llen wird normalerweise ein Ansatz angewendet, bei dem jeder Strahl mit einer Verz√∂gerung einer bestimmten Gr√∂√üe modelliert wird (Abb. 4). </p><br><p><img src="https://habrastorage.org/webt/3t/tc/va/3ttcvau0o4njat-1beejefcudpy.png"></p><br><p>  <em>Abb.</em>  <em>4. Das Modell des Breitbandkanals mit n festen Verz√∂gerungen. [3, S.</em>  <em>29].</em>  <em>Wie Sie verstehen, spielen bestimmte Bezeichnungen keine Rolle - im Folgenden werden wir etwas andere verwenden.</em> </p><br><p>  Das Modell des empfangenen Signals f√ºr einen Sensor wird wie folgt ausgedr√ºckt: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a3f/c3f/2f0/a3fc3f2f0cd278622946ce2da28005fd.svg" alt="x (n) = \ sum_ {l = 0} ^ Lh (l) s (n-l) + \ nu (n)"></div><br><p>  In diesem Fall <img src="https://habrastorage.org/getpro/habr/post_images/fd6/0b2/b5b/fd60b2b5be4b7e93a0d905dd970c314f.svg" alt="n">  gibt die Referenznummer an, <img src="https://habrastorage.org/getpro/habr/post_images/e9f/c39/8e5/e9fc398e58e24442ddc2cf11684debbc.svg" alt="h (l)">  Ist die Antwort des Kanals entlang des <em>l-</em> ten Strahls, <em>L</em> ist die Anzahl der Verz√∂gerungsregister, <em>s</em> ist das √ºbertragene (n√ºtzliche) Signal, <img src="https://habrastorage.org/getpro/habr/post_images/270/81a/400/27081a40025995898a2b982ff59a7e39.svg" alt="\ nu (n)">  - additives Rauschen. </p><br><p>  F√ºr mehrere Sensoren hat die Formel folgende Form: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c0e/835/aa7/c0e835aa74d5dccf4ccdf625ebcc88b4.svg" alt="\ mathbf {x} (n) = \ mathbf {H} \ mathbf {s} (n) + \ mathbf {\ nu} (n)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/b0e/184/0ed/b0e1840edef9169f3e1f52974bea066d.svg" alt="\ mathbf {x} (n)">  und <img src="https://habrastorage.org/getpro/habr/post_images/270/81a/400/27081a40025995898a2b982ff59a7e39.svg" alt="\ mathbf {\ nu} (n)">  - Dimension haben <img src="https://habrastorage.org/getpro/habr/post_images/132/724/0f2/1327240f26480a83dffca393bb730c44.svg" alt="M \ mal 1">  Dimension <img src="https://habrastorage.org/getpro/habr/post_images/ed0/8c1/e77/ed08c1e77cfaf357d5e90e9e2ae918aa.svg" alt="\ mathbf {H}">  ist gleich <img src="https://habrastorage.org/getpro/habr/post_images/25e/e63/fbb/25ee63fbb4a32f1a00d5c02aaea9b80c.svg" alt="M \ mal (M-L)">  und die Dimension <img src="https://habrastorage.org/getpro/habr/post_images/5e3/d36/045/5e3d360455a5a33db6c17f93c119a694.svg" alt="\ mathbf {s} (n)">  gleich <img src="https://habrastorage.org/getpro/habr/post_images/6e2/fc1/636/6e2fc16365ac2698555dd979ed6b5eeb.svg" alt="(M-L) \ mal 1">  . </p><br><p>  Angenommen, jeder Sensor empf√§ngt aufgrund des Einfalls der Welle in einem Winkel auch ein Signal mit einer bestimmten Verz√∂gerung.  Matrix <img src="https://habrastorage.org/getpro/habr/post_images/ed0/8c1/e77/ed08c1e77cfaf357d5e90e9e2ae918aa.svg" alt="\ mathbf {H}">  In unserem Fall ist es eine Faltungsmatrix f√ºr den Antwortvektor f√ºr jeden Strahl.  Ich denke, der Code wird klarer: </p><br><pre> <code class="python hljs">h = np.array([<span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">0.779</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">0.722</span></span>, <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">1.862</span></span>]) L = len(h)<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-comment"><span class="hljs-comment"># number of signal sources H = convmtx(h,ML) print(H.shape) print(H)</span></span></code> </pre> <br><p>  Die Schlussfolgerung wird sein: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) &gt;&gt;&gt; array([[ <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> ], [<span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>, <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> ], [<span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>, <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>], [ <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>], [ <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>]])</code> </pre> <br><p>  Als n√§chstes legen wir die Anfangsdaten f√ºr das Nutzsignal und das Rauschen fest: </p><br><pre> <code class="python hljs">sigmaS = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (the signal's s(n) power) sigmaN = 0.01 #   (the noise's n(n) power)</span></span></code> </pre> <br><p>  Nun kommen wir zu Korrelationen. </p><br><pre> <code class="python hljs">Rxx = (sigmaS)*(np.dot(H,np.matrix(H).H))+(sigmaN)*np.identity(M) p = (sigmaS)*H[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] p = p.reshape((len(p), <span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Die Ableitung der Formeln hier (auch ein Blatt f√ºr die verzweifeltsten).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/hi/lh/ks/hilhksxoc_rkum_5ibn3m42ukxc.jpeg"></p></div></div><br><p>  Wir finden eine L√∂sung f√ºr Wiener: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Solution of the Wiener-Hopf equation: wopt = np.dot(np.linalg.inv(Rxx), p) MSEopt = MSE_calc(sigmaS, Rxx, p, wopt)</span></span></code> </pre> <br><p>  Fahren wir nun mit der Gradientenabstiegsmethode fort. </p><br><p>  Finden Sie den gr√∂√üten Eigenwert, damit die obere Grenze des Schritts daraus abgeleitet werden kann (siehe Formel (9)): </p><br><pre> <code class="python hljs">lamda_max = max(np.linalg.eigvals(Rxx))</code> </pre> <br><p>  Stellen wir nun einige Schritte ein, die einen bestimmten Bruchteil des Maximums ausmachen: </p><br><pre> <code class="python hljs">coeff = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0.9</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>]) mus = <span class="hljs-number"><span class="hljs-number">2</span></span>/lamda_max*coeff <span class="hljs-comment"><span class="hljs-comment"># different step sizes</span></span></code> </pre> <br><p>  Definieren Sie die maximale Anzahl von Iterationen: </p><br><pre> <code class="python hljs">N_steps = <span class="hljs-number"><span class="hljs-number">100</span></span></code> </pre> <br><p>  F√ºhren Sie den Algorithmus aus: </p><br><pre> <code class="python hljs">MSE = np.empty((len(mus), N_steps), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> mu_idx, mu <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(mus): w = np.zeros((M,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> N_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(N_steps): w = w - mu*(np.dot(Rxx, w) - p) MSE[mu_idx, N_i] = MSE_calc(sigmaS, Rxx, p, w)</code> </pre> <br><p>  Jetzt machen wir dasselbe, aber f√ºr den adaptiven Schritt (Formel (10)): </p><br><pre> <code class="python hljs">MSEoptmu = np.empty((<span class="hljs-number"><span class="hljs-number">1</span></span>, N_steps), dtype=complex) w = np.zeros((M,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> N_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(N_steps): gamma = p - np.dot(Rxx,w) mu_opt = mu_opt_calc(gamma, Rxx) w = w - mu_opt*(np.dot(Rxx,w) - p) MSEoptmu[:, N_i] = MSE_calc(sigmaS, Rxx, p, w)</code> </pre> <br><p>  Sie sollten so etwas bekommen: </p><br><div class="spoiler">  <b class="spoiler_title">Zeichnen</b> <div class="spoiler_text"><pre> <code class="python hljs">x = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, N_steps+<span class="hljs-number"><span class="hljs-number">1</span></span>)] plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>), dpi=<span class="hljs-number"><span class="hljs-number">300</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx, item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(coeff): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> item == <span class="hljs-number"><span class="hljs-number">1</span></span>: item = <span class="hljs-string"><span class="hljs-string">''</span></span> plt.loglog(x, np.abs(MSE[idx, :]),\ label=<span class="hljs-string"><span class="hljs-string">'$\mu = '</span></span>+str(item)+<span class="hljs-string"><span class="hljs-string">'\mu_{max}$'</span></span>) plt.loglog(x, np.abs(MSEoptmu[<span class="hljs-number"><span class="hljs-number">0</span></span>, :]),\ label=<span class="hljs-string"><span class="hljs-string">'$\mu = \mu_{opt}$'</span></span>) plt.loglog(x, np.abs(MSEopt*np.ones((len(x), <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex)),\ label = <span class="hljs-string"><span class="hljs-string">'Wiener solution'</span></span>) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Number of steps'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Mean-Square Error'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Steepest descent'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.minorticks_on() plt.grid(which=<span class="hljs-string"><span class="hljs-string">'major'</span></span>) plt.grid(which=<span class="hljs-string"><span class="hljs-string">'minor'</span></span>, linestyle=<span class="hljs-string"><span class="hljs-string">':'</span></span>) plt.show()</code> </pre> </div></div><br><p><img src="https://habrastorage.org/webt/il/fa/8d/ilfa8dmoxgt4sjitiyvwbdjga6m.png"></p><br><p>  <em>Abb.</em>  <em>5. Lernkurven f√ºr Schritte unterschiedlicher Gr√∂√üe.</em> </p><br><p>  Befestigungen, um die wichtigsten Punkte beim Gef√§lle hervorzuheben: </p><br><ul><li>  Wie erwartet ergibt der optimale Schritt die schnellste Konvergenz. </li><li>  bedeutet nicht mehr besser: Nachdem wir die Obergrenze √ºberschritten haben, haben wir √ºberhaupt keine Konvergenz erreicht. </li></ul><br><p>  Also haben wir den optimalen Vektor der Filterkoeffizienten gefunden, der die Effekte des Kanals am besten <u>ausgleicht</u> - wir haben <u>den Equalizer trainiert</u> . </p><br><h2 id="a-est-chto-to-bolee-blizkoe-k-realnosti">  Gibt es etwas n√§her an der Realit√§t? </h2><br><p>  Nat√ºrlich!  Wir haben bereits mehrfach gesagt, dass das Sammeln von Statistiken (d. H. Das Berechnen von Korrelationsmatrizen und Vektoren) in Echtzeitsystemen alles andere als ein erschwinglicher Luxus ist.  Die Menschheit hat sich jedoch an diese Schwierigkeiten angepasst: Anstelle eines <em>deterministischen</em> Ansatzes in der Praxis werden <u>adaptive</u> Ans√§tze verwendet.  Sie k√∂nnen in zwei gro√üe Gruppen eingeteilt werden [1, S.  246]: </p><br><ul><li>  <em>probabilistisch (stochastisch)</em> (z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SG</a> - stochastischer Gradient) </li><li>  und basierend auf der Methode der <em>kleinsten Quadrate</em> (z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LMS</a> - Least Mean Squares oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RLS</a> - Recursive Least Squares) </li></ul><br><p>  Das Thema der adaptiven Filter ist in der Open-Source-Community gut vertreten (Beispiele f√ºr Python): </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pyroomakustik</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Padasip</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">adaptfilt</a> </li></ul><br><blockquote>  Im zweiten Beispiel gef√§llt mir besonders die Dokumentation.  Seien Sie jedoch vorsichtig!  Als ich das <strong>Padasip-</strong> Paket getestet <strong>habe</strong> , hatte ich Schwierigkeiten beim Umgang mit komplexen Zahlen (standardm√§√üig ist float64 dort impliziert).  M√∂glicherweise k√∂nnen bei der Arbeit mit einigen anderen Implementierungen dieselben Probleme auftreten. </blockquote><p>  Algorithmen haben nat√ºrlich ihre eigenen Vor- und Nachteile, deren Summe den Umfang des Algorithmus bestimmt. </p><br><p>  Werfen wir einen kurzen Blick auf die Beispiele: Wir werden die drei Algorithmen <em>SG</em> , <em>LMS</em> und <em>RLS betrachten</em> , die wir bereits erw√§hnt haben (wir werden in der MATLAB-Sprache modellieren - ich gestehe, es gab bereits Leerzeichen und schreiben alles in Einheitlichkeitspython um, um ... na ja ...). </p><br><p>  Eine Beschreibung der <em>LMS-</em> und <em>RLS-</em> Algorithmen finden Sie beispielsweise im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Padasip-</a> Dock. </p><br><div class="spoiler">  <b class="spoiler_title">Eine Beschreibung der SG finden Sie hier.</b> <div class="spoiler_text"><p>  Der Hauptunterschied zum Gradientenabstieg ist ein variabler Gradient: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/76f/9e3/fbb/76f9e3fbbb4c7643f5af595103791091.svg" alt="\ mathbf {w} [n] = \ mathbf {w} [n-1] + \ mu \ left (\ mathbf {\ hat {p}} [n] - \ mathbf {\ hat {R}} _ {xx } [n] \ mathbf {w} [n-1] \ right)"></div><br><p>  bei </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/633/bac/0aa/633bac0aae95be15cd31a312b4e0d2c5.svg" alt="\ mathbf {\ hat {R}} _ {xx} [n] = \ frac {1} {n} \ left ((n-1) \ mathbf {\ hat {R}} _ {xx} [n-1 ] + \ mathbf {x} [n] \ mathbf {x} [n] ^ H \ rechts)"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f7/bfd/f81/4f7bfdf81571e19eac474c7a8c380093.svg" alt="\ mathbf {\ hat {p}} [n] = \ frac {1} {n} \ left ((n-1) \ mathbf {\ hat {p}} [n-1] + \ mathbf {x} [ n] d [n] ^ * \ rechts)"></div></div></div><br><p>  1) Ein √§hnlicher Fall wie oben. </p><br><div class="spoiler">  <b class="spoiler_title">Quellen (MatLab / Octave).</b> <div class="spoiler_text"><p>  Quellen k√∂nnen hier heruntergeladen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> . </p></div></div><br><p><img src="https://habrastorage.org/webt/ff/zm/hq/ffzmhqsrnwvvc0hdrcyzhapropw.png"></p><br><p>  <em>Abb.</em>  <em>6. Lernkurven f√ºr LMS, RLS und SG.</em> </p><br><p>  Es ist sofort zu bemerken, dass der LMS-Algorithmus aufgrund seiner relativen Einfachheit im Prinzip m√∂glicherweise nicht zu einer optimalen L√∂sung mit einem relativ gro√üen Schritt kommt.  RLS liefert das schnellste Ergebnis, kann aber auch mit einem relativ kleinen <em>Vergessensfaktor</em> versagen.  Bisher geht es SG gut, aber schauen wir uns ein anderes Beispiel an. </p><br><p>  2) Der Fall, wenn sich der Kanal zeitlich √§ndert. </p><br><div class="spoiler">  <b class="spoiler_title">Quellen (MatLab / Octave).</b> <div class="spoiler_text"><p>  Quellen k√∂nnen hier heruntergeladen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> . </p></div></div><br><p><img src="https://habrastorage.org/webt/v-/9d/sx/v-9dsxxwzr9jnbnswf0dmnvqrcu.png"></p><br><p>  <em>Abb.</em>  <em>7. Lernkurven f√ºr LMS, RLS und SG (Kanalwechsel im Laufe der Zeit).</em> </p><br><p>  Und hier ist das Bild schon viel interessanter: Mit einer starken Ver√§nderung in der Reaktion des Kanals scheint LMS bereits die zuverl√§ssigste L√∂sung zu sein.  Wer h√§tte das gedacht.  Obwohl RLS mit dem richtigen Vergessensfaktor auch ein akzeptables Ergebnis liefert. </p><br><div class="spoiler">  <b class="spoiler_title">Ein paar Worte zur Leistung.</b> <div class="spoiler_text"><p>  Ja, nat√ºrlich hat jeder Algorithmus seine eigene spezifische Rechenkomplexit√§t, aber nach meinen Messungen kann meine alte Maschine ein Ensemble f√ºr ungef√§hr 120 Œºs pro Iteration bei LMS und SG und ungef√§hr 250 Œºs pro Iteration bei RLS bew√§ltigen.  Das hei√üt, der Unterschied ist im Allgemeinen vergleichbar. </p></div></div><br><p>  Und das ist alles f√ºr heute.  Vielen Dank an alle, die geschaut haben! </p><br><h2 id="literatura">  Literatur </h2><br><ol><li>  Haykin SS Adaptive Filtertheorie.  - Pearson Education India, 2005. </li><li>  Haykin, Simon und KJ Ray Liu.  Handbuch zur Array-Verarbeitung und zu Sensornetzwerken.  Vol.  63. John Wiley &amp; Sons, 2010. pp.  102-107 </li><li>  Arndt, D. (2015).  On Channel Modeling f√ºr den mobilen Satellitenempfang an Land (Dissertation). </li></ol><br><h2 id="prilozhenie-1">  Anhang 1 </h2><br><div class="spoiler">  <b class="spoiler_title">Eigenfilter</b> <div class="spoiler_text"><p>  Das Hauptziel eines solchen Filters ist die Maximierung des Signal-Rausch-Verh√§ltnisses (SNR). </p><br><p><img src="https://habrastorage.org/webt/kk/v_/uu/kkv_uu-08dppu5i4yhkucc_b0ww.jpeg"></p><br><p>  Nach dem Vorhandensein von Korrelationen in den Berechnungen zu urteilen, ist dies jedoch eher ein theoretisches Konstrukt als eine praktische L√∂sung. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de455497/">https://habr.com/ru/post/de455497/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455483/index.html">Ai-Da-K√ºnstler: Humanoider Roboter bereitet sich auf seine erste Einzelausstellung vor</a></li>
<li><a href="../de455485/index.html">Pr√ºfpunktskripte - F√ºhren Sie Skripte direkt von der Smart Console aus</a></li>
<li><a href="../de455487/index.html">Schulung Cisco 200-125 CCNA v3.0. Tag 10. Betriebsarten des Ports wechseln</a></li>
<li><a href="../de455489/index.html">Verbinden von Audio- und Videol√∂sungen von Drittanbietern mit Microsoft-Teams</a></li>
<li><a href="../de455493/index.html">Was ist neu in der Angular 8-Version?</a></li>
<li><a href="../de455499/index.html">Extraktion von Weisheitsz√§hnen: Wie geht das?</a></li>
<li><a href="../de455501/index.html">Wie Hollywood heimlich KI verwendet, um wichtige Drehentscheidungen zu treffen</a></li>
<li><a href="../de455503/index.html">19 Konzepte, die Sie lernen m√ºssen, um ein effektiver Angular-Entwickler zu werden</a></li>
<li><a href="../de455505/index.html">Reaktionsbeschleunigung vierfach reagieren</a></li>
<li><a href="../de455507/index.html">√úbersicht √ºber das datierbare Python-Paket</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
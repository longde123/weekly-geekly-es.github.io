<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤸🏿 💯 🤲🏽 Optimale lineare Filterung: vom Gradientenabstieg bis zum adaptiven Filter 🧘 🙎🏽 🐣</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich möchte das Thema Abstracts zum Master-Fach "Kommunikation und Signalverarbeitung" (TU Ilmenau) weiterentwickeln und eines der Hauptthemen des Kurs...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimale lineare Filterung: vom Gradientenabstieg bis zum adaptiven Filter</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455497/"><p>  Ich möchte das Thema Abstracts zum Master-Fach "Kommunikation und Signalverarbeitung" (TU Ilmenau) weiterentwickeln und eines der Hauptthemen des Kurses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"Adaptive und Array-Signalverarbeitung" fortsetzen</a> .  Die Grundlagen der adaptiven Filterung. </p><br><p>  <u>Für wen dieser Artikel zuerst geschrieben wurde:</u> <u><br></u> <br>  1) für eine Studentenbruderschaft einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einheimischen Spezialität</a> ; <br>  2) für Lehrer, die praktische Seminare vorbereiten, sich aber noch nicht für die Tools entschieden haben - nachfolgend finden Sie Beispiele in <strong>Python</strong> und <strong>Matlab / Octave</strong> ; <br>  3) für alle, die sich für das Thema Filterung interessieren. </p><br><p>  <u>Was ist unter dem Schnitt zu finden:</u> <u><br></u> <br>  1) Informationen aus der Theorie, die ich so kurz wie möglich zu ordnen versuchte, die mir aber informativ erscheinen; <br>  2) Beispiele für die Verwendung von Filtern: insbesondere als Teil des Equalizers für das Antennenarray; <br>  3) Links zu grundlegender Literatur und offenen Bibliotheken (in Python), die für die Forschung nützlich sein können. </p><br><p>  Begrüßen Sie im Allgemeinen und lassen Sie uns alles nach Punkten sortieren. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2f1/98b/d67/2f198bd673789161db58ad770c629faf.jpg"></p><a name="habracut"></a><br><p>  <em>Die nachdenkliche Person auf dem Foto ist vielen bekannt, glaube ich, Norbert Wiener.</em>  <em>Zum größten Teil werden wir den Filter seines Namens untersuchen.</em>  <em>Man kann jedoch nicht versäumen, unseren Landsmann zu erwähnen - Andrei Nikolaevich Kolmogorov, dessen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel von 1941</a> ebenfalls einen wesentlichen Beitrag zur Entwicklung der optimalen Filtertheorie leistete, die selbst in englischen Quellen als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kolmogorov-Wiener-Filtertheorie bezeichnet wird</a> .</em> </p><br><h2 id="chto-rassmatrivaem">  Was erwägen wir? </h2><br><p>  Heute betrachten wir ein klassisches Filter mit einer endlichen Impulsantwort (FIR, endliche Impulsantwort), die durch die folgende einfache Schaltung beschrieben werden kann (Abb. 1). </p><br><p><img src="https://habrastorage.org/webt/to/or/u7/tooru7vj_f6aj0oe9wvpcde28kw.png"></p><br><p>  <em>Abb. 1.</em>  <em>Das FIR-Filterschema zur Untersuchung des Wiener-Filters. [1.</em>  <em>S.117]</em> </p><br><p>  Wir werden in Matrixform schreiben, was genau am Ausgang dieses Standes sein wird: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/43f/615/39b/43f61539ba1f68998b24c39a8c539706.svg" alt="e (n) = d (n) - \ hat {d} (n | \ mathcal {U} _n) = d (n) - \ mathbf {w} ^ H \ mathbf {u} \ qquad (1)"></div><br><p>  Entschlüsseln Sie die Notation: </p><br><ul><li><img src="https://habrastorage.org/getpro/habr/post_images/6c5/882/04e/6c588204ed25c8bbb270106d7f08a4dd.svg" alt="e (n)">  Ist die Differenz (Fehler) zwischen dem gegebenen und dem empfangenen Signal </li><li><img src="https://habrastorage.org/getpro/habr/post_images/771/807/bef/771807bef08a5612654d97e67695cf07.svg" alt="d (n)">  Ist ein vordefiniertes Signal </li><li><img src="https://habrastorage.org/getpro/habr/post_images/960/b4e/a48/960b4ea48f3968f42c64eed1af640e1d.svg" alt="\ mathbf {u}">  Ist ein Vektor von Abtastwerten oder mit anderen Worten ein Signal am Eingang des Filters </li><li><img src="https://habrastorage.org/getpro/habr/post_images/75f/f22/a5a/75ff22a5a4f95cbe489056bf704597f0.svg" alt="\ hat {d} (n | \ mathcal {U} _n)">  Ist das Signal am Filterausgang </li><li><img src="https://habrastorage.org/getpro/habr/post_images/6f6/81f/9be/6f681f9be2ae30d1666fec498b59b3a3.svg" alt="\ mathbf {w} ^ H.">  - Dies ist eine hermitische Konjugation des Filterkoeffizientenvektors. - <u>In ihrer optimalen Auswahl liegt die Anpassungsfähigkeit des Filters</u> </li></ul><br><p>  Sie haben wahrscheinlich bereits vermutet, dass wir den kleinsten Unterschied zwischen dem gegebenen und dem gefilterten Signal anstreben werden, dh den kleinsten Fehler.  Dies bedeutet, dass wir vor einer Optimierungsaufgabe stehen. </p><br><h2 id="chto-budem-optimizirovat">  Was werden wir optimieren? </h2><br><p>  Um zu optimieren oder vielmehr zu minimieren, <strong>meinen</strong> wir nicht nur <strong>den</strong> Fehler, den <strong>mittleren quadratischen Fehler</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MSE - Mean Sqared Error</a> ): </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b83/b62/193/b83b62193ca3490681c2cd8910e4d99a.svg" alt="MSE: J (\ mathbf {w}) = E \ {e (n) ^ 2 \} \ qquad (2)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/c48/76a/b10/c4876ab1024579fa30ea997a45efd50a.svg" alt="J (\ mathbf {w})">  bezeichnet die Kostenfunktion des Vektors der Filterkoeffizienten und <img src="https://habrastorage.org/getpro/habr/post_images/f39/8e4/ded/f398e4ded6db9e55108d575a9b7d2f1f.svg" alt="E \ {* \}">  bezeichnet mat.  Warten. </p><br><p>  Das Quadrat ist in diesem Fall sehr angenehm, da es bedeutet, dass wir mit dem Problem der <em>konvexen Programmierung</em> konfrontiert sind (ich google nur ein solches Analogon der englischen <em>konvexen Optimierung</em> ), was wiederum ein <u>einzelnes Extremum</u> impliziert (in unserem Fall ein Minimum). </p><br><p><img src="https://habrastorage.org/webt/hr/xj/mb/hrxjmbmimv7c2uvvicnuklqn9y0.png"></p><br><p>  <em>Abb. 2.</em>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Oberfläche des mittleren quadratischen Fehlers</a> .</em> </p><br><p>  Unsere Fehlerfunktion hat eine kanonische Form [1, S. 121]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5da/121/788/5da121788f801656b55ee459c2f4d56d.svg" alt="J (\ mathbf {w}) = \ sigma ^ 2_d - \ mathbf {w} ^ H \ mathbf {p} - \ mathbf {p} ^ H \ mathbf {w} + \ mathbf {w} ^ H \ mathbf { R} \ mathbf {w} \ qquad (3)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/24f/50c/410/24f50c410ab0c2ca3dd302c630c734e8.svg" alt="\ sigma ^ 2_d">  Ist die Varianz des erwarteten Signals, <img src="https://habrastorage.org/getpro/habr/post_images/82c/861/559/82c86155992ccb2e83d6f9f3f9e92737.svg" alt="\ mathbf {p} = E \ {\ mathbf {u} (n) d ^ * (n) \}">  Ist der Kreuzkorrelationsvektor zwischen dem Eingangsvektor und dem erwarteten Signal und <img src="https://habrastorage.org/getpro/habr/post_images/664/01c/a88/66401ca883516093b2e73b7d519588ac.svg" alt="\ mathbf {R} = E \ {\ mathbf {u} (n) \ mathbf {u} ^ H (n) \}">  Ist die Autokorrelationsmatrix des Eingangssignals. </p><br><div class="spoiler">  <b class="spoiler_title">Die Schlussfolgerung dieser Formel ist hier (ich habe es klarer versucht).</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/q6/sw/p5/q6swp5meopsxauj7yvygkwuc7-g.png" width="650"></div></div><br><p>  Wie oben erwähnt, haben wir ein Extremum (Minimum), wenn wir über konvexe Programmierung sprechen.  Um den minimalen Wert der Kostenfunktion (den minimalen quadratischen Mittelwertfehler) zu ermitteln, reicht es aus, die Tangente der Steigung der Tangente oder mit anderen Worten die <u>partielle Ableitung</u> in <u>Bezug</u> auf unsere untersuchte Variable zu ermitteln: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1cd/d0b/114/1cdd0b114b5457761dd27338b4ee57f4.svg" alt="\ frac {\ delta J (\ mathbf {w})} {\ delta w ^ *} = - \ mathbf {p} + \ mathbf {R} \ mathbf {w} \ qquad (4)"></div><br><p>  Im besten Fall ( <img src="https://habrastorage.org/getpro/habr/post_images/ac6/219/d1c/ac6219d1cc1885e6f5936e40b5c7a980.svg" alt="\ mathbf {w} = \ mathbf {w} _ {opt}">  ) sollte der Fehler natürlich minimal sein, was bedeutet, dass wir die Ableitung mit Null gleichsetzen: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/777/46e/9a7/77746e9a7ab3ff9df3cf340da4b7238d.svg" alt="\ mathbf {R} \ mathbf {w} _ {opt} = \ mathbf {p} \ qquad (5)"></div><br><p>  Eigentlich ist es hier unser Ofen, von dem aus wir weiter tanzen werden: Vor uns liegt ein <u>System linearer Gleichungen</u> . </p><br><h2 id="kak-budem-reshat">  Wie werden wir uns entscheiden? </h2><br><p>  Es sollte sofort angemerkt werden, dass beide Lösungen, die wir unten betrachten werden, in diesem Fall theoretisch und lehrreich sind, da <img src="https://habrastorage.org/getpro/habr/post_images/1cf/d71/499/1cfd714992b16fcc961ad10bcc855134.svg" alt="\ mathbf {R}">  und <img src="https://habrastorage.org/getpro/habr/post_images/1fa/0e8/e9e/1fa0e8e9e33d7dbd533901bbf025bd9f.svg" alt="\ mathbf {p}">  im Voraus bekannt (dh wir hatten die angebliche Fähigkeit, ausreichende Statistiken zu sammeln, um diese zu berechnen).  Die Analyse solcher vereinfachten Beispiele hier ist jedoch das Beste, was Sie sich vorstellen können, um die grundlegenden Ansätze zu verstehen. </p><br><h3 id="analiticheskoe-reshenie">  Analytische Lösung </h3><br><p>  Dieses Problem kann sozusagen in der Stirn gelöst werden - mit inversen Matrizen: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/759/c3e/052/759c3e052c502aa04fe6da682a41ea2a.svg" alt="\ mathbf {w} _ {opt} = \ mathbf {R} ^ {- 1} \ mathbf {p} \ qquad (6)"></div><br><p>  Ein solcher Ausdruck heißt Wiener-Hopf-Gleichung - er ist für uns immer noch als Referenz nützlich. </p><br><blockquote>  Um völlig akribisch zu sein, wäre es wahrscheinlich korrekter, diesen Fall allgemein aufzuschreiben, d. H.  nicht mit <img src="https://habrastorage.org/getpro/habr/post_images/bd8/f0f/04a/bd8f0f04a92fe1055c350d4e32a8a256.svg" alt="^ {-}">  und mit <img src="https://habrastorage.org/getpro/habr/post_images/017/3d5/ed9/0173d5ed99b25d00ec4245287142f165.svg" alt="^ +">  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pseudo-Invert</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/003/47f/bca/00347fbca15f40943c7fb7b20c38a3f9.svg" alt="\ mathbf {R} ^ + = \ mathbf {R} ^ H (\ mathbf {R} \ mathbf {R} ^ H) ^ {- 1}"><br><br>  Die Autokorrelationsmatrix kann jedoch nicht nicht quadratisch oder singulär sein, daher glauben wir zu Recht, dass es keinen Widerspruch gibt. </blockquote><p>  Aus dieser Gleichung ist es analytisch möglich, abzuleiten, wie hoch der Mindestwert der Kostenfunktion sein wird (d. H. In unserem Fall <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MMSE</a> - minimaler mittlerer quadratischer Fehler): </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c00/d2d/1f9/c00d2d1f9427762a17deae92ae3ea77c.svg" alt="J_ {min} = J (\ mathbf {w} _ {opt}) = \ sigma ^ 2_d - \ mathbf {p} ^ H \ mathbf {R} ^ {- 1} \ mathbf {p} \ qquad (7)"></div><br><div class="spoiler">  <b class="spoiler_title">Die Ableitung der Formel ist hier (ich habe auch versucht, sie bunter zu machen).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/ds/vh/nx/dsvhnxoudmo_qd4hesg_qkysdg8.jpeg"></p></div></div><br><p>  Nun, es gibt eine Lösung. </p><br><h3 id="reshenie-iterativnym-metodom">  Iterative Lösung </h3><br><p>  Ja, es ist jedoch möglich, ein lineares Gleichungssystem zu lösen, ohne die Autokorrelationsmatrix iterativ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu</a> invertieren ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">um Berechnungen zu speichern</a> ).  Betrachten Sie zu diesem Zweck die native und verständliche <strong>Methode des Gradientenabfalls</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Methode des steilsten / Gradientenabstiegs</a> ). </p><br><p>  Das Wesen des Algorithmus kann auf Folgendes reduziert werden: </p><br><ol><li>  Wir setzen die gewünschte Variable auf einen Standardwert (z. B. <img src="https://habrastorage.org/getpro/habr/post_images/231/554/6f0/2315546f0e8aa127a8da693d41c53ff6.svg" alt="\ mathbf {w} (0) = \ mathbf {0}">  ) </li><li>  Wähle einen Schritt <img src="https://habrastorage.org/getpro/habr/post_images/849/a42/16c/849a4216c1bc55877bc86f4a97513f7a.svg" alt="\ mu">  (Wie genau wir uns entscheiden, werden wir weiter unten besprechen). </li><li>  Und dann gehen wir sozusagen mit einem bestimmten Schritt entlang unserer ursprünglichen Oberfläche (in unserem Fall ist dies die MSE-Oberfläche) hinunter <img src="https://habrastorage.org/getpro/habr/post_images/849/a42/16c/849a4216c1bc55877bc86f4a97513f7a.svg" alt="\ mu">  und eine bestimmte Geschwindigkeit, die durch die Größe des Gradienten bestimmt wird. </li></ol><br><p>  Daher der Name: <em>Gefälle</em> - Gefälle oder <em>steilste</em> - schrittweise <em>Abfahrt</em> - Abfahrt. </p><br><p>  Der Gradient in unserem Fall ist bereits bekannt: Wir haben ihn tatsächlich gefunden, als wir die Kostenfunktion differenzierten (die Oberfläche ist konkav, vergleiche mit [1, S. 220]).  Wir schreiben, wie die Formel für die iterative Aktualisierung der gewünschten Variablen (Filterkoeffizienten) aussehen wird [1, S.  220]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6d6/4ff/7eb/6d64ff7eb98c4274e05a33a3eb127933.svg" alt="\ mathbf {w} (n + 1) = \ mathbf {w} (n) - \ mu [- \ mathbf {p} + \ mathbf {R} \ mathbf {w} (n)] \ qquad (8)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/fd6/0b2/b5b/fd60b2b5be4b7e93a0d905dd970c314f.svg" alt="n">  Ist die Iterationsnummer. </p><br><p>  Lassen Sie uns nun über die Auswahl einer Schrittgröße sprechen. </p><br><p>  Wir listen die offensichtlichen Prämissen auf: </p><br><ul><li>  Schritt kann nicht negativ oder Null sein </li><li>  Der Schritt sollte nicht zu groß sein, sonst konvergiert der Algorithmus nicht (er springt sozusagen von Kante zu Kante, ohne ins Extreme zu fallen). </li><li>  Der Schritt kann natürlich sehr klein sein, aber dies ist auch nicht ganz wünschenswert - der Algorithmus wird mehr Zeit aufwenden </li></ul><br><p>  In Bezug auf den Wiener Filter wurden Einschränkungen natürlich schon vor langer Zeit gefunden [1, S. 222-226]: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/67d/64a/b6c/67d64ab6cf46d3438791ccea853421fb.svg" alt="0 <\ mu <\ frac {2} {\ lambda_ {max}} \ qquad (9)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/e5d/fa8/35d/e5dfa835ded907ecd7cf2b56d7061307.svg" alt="\ lambda_ {max}">  Ist der größte Eigenwert der Autokorrelationsmatrix <img src="https://habrastorage.org/getpro/habr/post_images/1cf/d71/499/1cfd714992b16fcc961ad10bcc855134.svg" alt="\ mathbf {R}">  . </p><br><blockquote>  Eigenwerte und Vektoren sind übrigens ein eigenständiges interessantes Thema im Zusammenhang mit der linearen Filterung.  <em>Für</em> diesen Fall gibt es sogar einen ganzen <em>Eigenfilter</em> (siehe Anhang 1). </blockquote><p>  Aber das ist zum Glück noch nicht alles.  Es gibt auch eine optimale, adaptive Lösung: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f4c/3c2/fdf/f4c3c2fdf8ae926094bb67b391cd896b.svg" alt="\ mu (n) = \ frac {\ mathbf {\ gamma} (n) ^ H \ mathbf {\ gamma} (n)} {\ mathbf {\ gamma} (n) ^ H \ mathbf {R} \ mathbf { \ gamma} (n)} \ qquad (10)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/1b0/4a6/a31/1b04a6a318f99ec501290f59c0f924ac.svg" alt="\ mathbf {\ gamma} (n) = \ mathbf {p} - \ mathbf {R} \ mathbf {w} (n)">  Ist ein negativer Gradient.  Wie aus der Formel ersichtlich ist, wird der Schritt in jede Iteration neu berechnet, dh angepasst. </p><br><div class="spoiler">  <b class="spoiler_title">Die Schlussfolgerung der Formel ist hier (viel Mathematik - schauen Sie sich nur die berüchtigten Nerds wie ich an).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/au/hq/0s/auhq0sxrspaduxdkclqctns1xtw.jpeg"></p></div></div><br><p>  Okay, für die zweite Entscheidung haben wir auch die Bühne bereitet. </p><br><h2 id="a-nelzya-li-na-primerah">  Aber ist es mit Beispielen möglich? </h2><br><p>  Aus Gründen der Klarheit werden wir eine kleine Simulation durchführen.  Wir werden <strong>Python 3.6.4 verwenden</strong> . </p><br><blockquote>  Ich werde gleich sagen, dass diese Beispiele Teil einer der Hausaufgaben sind, von denen jede den Schülern innerhalb von zwei Wochen zur Lösung angeboten wird.  Ich habe den Teil unter Python umgeschrieben (um die Sprache unter den Funkingenieuren bekannt zu machen).  Vielleicht werden Sie im Web auf einige andere Optionen anderer ehemaliger Studenten stoßen. </blockquote><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.linalg <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> toeplitz <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convmtx</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(h,n)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> toeplitz(np.hstack([h, np.zeros(n<span class="hljs-number"><span class="hljs-number">-1</span></span>)]),\ np.hstack([h[<span class="hljs-number"><span class="hljs-number">0</span></span>], np.zeros(n<span class="hljs-number"><span class="hljs-number">-1</span></span>)])) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MSE_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(sigmaS, R, p, w)</span></span></span><span class="hljs-function">:</span></span> w = w.reshape(w.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) wH = np.conj(w).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, w.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) p = p.reshape(p.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) pH = np.conj(p).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, p.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) MSE = sigmaS - np.dot(wH, p) - np.dot(pH, w) + np.dot(np.dot(wH, R), w) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> MSE[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">mu_opt_calc</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(gamma, R)</span></span></span><span class="hljs-function">:</span></span> gamma = gamma.reshape(gamma.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], <span class="hljs-number"><span class="hljs-number">1</span></span>) gammaH = np.conj(gamma).reshape(<span class="hljs-number"><span class="hljs-number">1</span></span>, gamma.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) mu_opt = np.dot(gammaH, gamma) / np.dot(np.dot(gammaH, R), gamma) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mu_opt[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  Wir werden unser lineares Filter für das <u>Kanalentzerrungsproblem verwenden</u> , dessen Hauptzweck darin besteht, die verschiedenen Auswirkungen dieses Kanals auf das Nutzsignal zu nivellieren. </p><br><blockquote>  Der Quellcode kann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> oder <a href="">hier</a> in einer Datei heruntergeladen <a href="">werden</a> (ja, ich hatte so ein Hobby - Wikipedia bearbeiten). </blockquote><br><h3 id="model-sistemy">  Systemmodell </h3><br><p>  Angenommen, es gibt ein Antennenarray (wir haben es bereits in einem Artikel über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MUSIK untersucht</a> ). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/61a/9c2/da7/61a9c2da745081459f9001d0252936f1.png"></p><br><p>  <em>Abb.</em>  <em>3. Nicht gerichtetes lineares Antennenarray (ULAA - Uniform Linear Antenna Array) [2, S.</em>  <em>32].</em> </p><br><p>  Definieren Sie die anfänglichen Gitterparameter: </p><br><pre> <code class="python hljs">M = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (number of sensors)</span></span></code> </pre> <br><p>  In diesem Artikel werden wir so etwas wie einen <u>Breitbandkanal mit Fading betrachten</u> , dessen charakteristisches Merkmal die <u>Mehrwegeausbreitung ist</u> .  In solchen Fällen wird normalerweise ein Ansatz angewendet, bei dem jeder Strahl mit einer Verzögerung einer bestimmten Größe modelliert wird (Abb. 4). </p><br><p><img src="https://habrastorage.org/webt/3t/tc/va/3ttcvau0o4njat-1beejefcudpy.png"></p><br><p>  <em>Abb.</em>  <em>4. Das Modell des Breitbandkanals mit n festen Verzögerungen. [3, S.</em>  <em>29].</em>  <em>Wie Sie verstehen, spielen bestimmte Bezeichnungen keine Rolle - im Folgenden werden wir etwas andere verwenden.</em> </p><br><p>  Das Modell des empfangenen Signals für einen Sensor wird wie folgt ausgedrückt: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a3f/c3f/2f0/a3fc3f2f0cd278622946ce2da28005fd.svg" alt="x (n) = \ sum_ {l = 0} ^ Lh (l) s (n-l) + \ nu (n)"></div><br><p>  In diesem Fall <img src="https://habrastorage.org/getpro/habr/post_images/fd6/0b2/b5b/fd60b2b5be4b7e93a0d905dd970c314f.svg" alt="n">  gibt die Referenznummer an, <img src="https://habrastorage.org/getpro/habr/post_images/e9f/c39/8e5/e9fc398e58e24442ddc2cf11684debbc.svg" alt="h (l)">  Ist die Antwort des Kanals entlang des <em>l-</em> ten Strahls, <em>L</em> ist die Anzahl der Verzögerungsregister, <em>s</em> ist das übertragene (nützliche) Signal, <img src="https://habrastorage.org/getpro/habr/post_images/270/81a/400/27081a40025995898a2b982ff59a7e39.svg" alt="\ nu (n)">  - additives Rauschen. </p><br><p>  Für mehrere Sensoren hat die Formel folgende Form: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c0e/835/aa7/c0e835aa74d5dccf4ccdf625ebcc88b4.svg" alt="\ mathbf {x} (n) = \ mathbf {H} \ mathbf {s} (n) + \ mathbf {\ nu} (n)"></div><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/b0e/184/0ed/b0e1840edef9169f3e1f52974bea066d.svg" alt="\ mathbf {x} (n)">  und <img src="https://habrastorage.org/getpro/habr/post_images/270/81a/400/27081a40025995898a2b982ff59a7e39.svg" alt="\ mathbf {\ nu} (n)">  - Dimension haben <img src="https://habrastorage.org/getpro/habr/post_images/132/724/0f2/1327240f26480a83dffca393bb730c44.svg" alt="M \ mal 1">  Dimension <img src="https://habrastorage.org/getpro/habr/post_images/ed0/8c1/e77/ed08c1e77cfaf357d5e90e9e2ae918aa.svg" alt="\ mathbf {H}">  ist gleich <img src="https://habrastorage.org/getpro/habr/post_images/25e/e63/fbb/25ee63fbb4a32f1a00d5c02aaea9b80c.svg" alt="M \ mal (M-L)">  und die Dimension <img src="https://habrastorage.org/getpro/habr/post_images/5e3/d36/045/5e3d360455a5a33db6c17f93c119a694.svg" alt="\ mathbf {s} (n)">  gleich <img src="https://habrastorage.org/getpro/habr/post_images/6e2/fc1/636/6e2fc16365ac2698555dd979ed6b5eeb.svg" alt="(M-L) \ mal 1">  . </p><br><p>  Angenommen, jeder Sensor empfängt aufgrund des Einfalls der Welle in einem Winkel auch ein Signal mit einer bestimmten Verzögerung.  Matrix <img src="https://habrastorage.org/getpro/habr/post_images/ed0/8c1/e77/ed08c1e77cfaf357d5e90e9e2ae918aa.svg" alt="\ mathbf {H}">  In unserem Fall ist es eine Faltungsmatrix für den Antwortvektor für jeden Strahl.  Ich denke, der Code wird klarer: </p><br><pre> <code class="python hljs">h = np.array([<span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">0.779</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">0.722</span></span>, <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1j</span></span>*<span class="hljs-number"><span class="hljs-number">1.862</span></span>]) L = len(h)<span class="hljs-number"><span class="hljs-number">-1</span></span> <span class="hljs-comment"><span class="hljs-comment"># number of signal sources H = convmtx(h,ML) print(H.shape) print(H)</span></span></code> </pre> <br><p>  Die Schlussfolgerung wird sein: </p><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) &gt;&gt;&gt; array([[ <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> ], [<span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>, <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>, <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> ], [<span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>, <span class="hljs-number"><span class="hljs-number">0.722</span></span><span class="hljs-number"><span class="hljs-number">-0.779j</span></span>], [ <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>, <span class="hljs-number"><span class="hljs-number">-0.257</span></span><span class="hljs-number"><span class="hljs-number">-0.722j</span></span>], [ <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">0.</span></span> +<span class="hljs-number"><span class="hljs-number">0.j</span></span> , <span class="hljs-number"><span class="hljs-number">-0.789</span></span><span class="hljs-number"><span class="hljs-number">-1.862j</span></span>]])</code> </pre> <br><p>  Als nächstes legen wir die Anfangsdaten für das Nutzsignal und das Rauschen fest: </p><br><pre> <code class="python hljs">sigmaS = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">#    (the signal's s(n) power) sigmaN = 0.01 #   (the noise's n(n) power)</span></span></code> </pre> <br><p>  Nun kommen wir zu Korrelationen. </p><br><pre> <code class="python hljs">Rxx = (sigmaS)*(np.dot(H,np.matrix(H).H))+(sigmaN)*np.identity(M) p = (sigmaS)*H[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] p = p.reshape((len(p), <span class="hljs-number"><span class="hljs-number">1</span></span>))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Die Ableitung der Formeln hier (auch ein Blatt für die verzweifeltsten).</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/hi/lh/ks/hilhksxoc_rkum_5ibn3m42ukxc.jpeg"></p></div></div><br><p>  Wir finden eine Lösung für Wiener: </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Solution of the Wiener-Hopf equation: wopt = np.dot(np.linalg.inv(Rxx), p) MSEopt = MSE_calc(sigmaS, Rxx, p, wopt)</span></span></code> </pre> <br><p>  Fahren wir nun mit der Gradientenabstiegsmethode fort. </p><br><p>  Finden Sie den größten Eigenwert, damit die obere Grenze des Schritts daraus abgeleitet werden kann (siehe Formel (9)): </p><br><pre> <code class="python hljs">lamda_max = max(np.linalg.eigvals(Rxx))</code> </pre> <br><p>  Stellen wir nun einige Schritte ein, die einen bestimmten Bruchteil des Maximums ausmachen: </p><br><pre> <code class="python hljs">coeff = np.array([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0.9</span></span>, <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>, <span class="hljs-number"><span class="hljs-number">0.1</span></span>]) mus = <span class="hljs-number"><span class="hljs-number">2</span></span>/lamda_max*coeff <span class="hljs-comment"><span class="hljs-comment"># different step sizes</span></span></code> </pre> <br><p>  Definieren Sie die maximale Anzahl von Iterationen: </p><br><pre> <code class="python hljs">N_steps = <span class="hljs-number"><span class="hljs-number">100</span></span></code> </pre> <br><p>  Führen Sie den Algorithmus aus: </p><br><pre> <code class="python hljs">MSE = np.empty((len(mus), N_steps), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> mu_idx, mu <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(mus): w = np.zeros((M,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> N_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(N_steps): w = w - mu*(np.dot(Rxx, w) - p) MSE[mu_idx, N_i] = MSE_calc(sigmaS, Rxx, p, w)</code> </pre> <br><p>  Jetzt machen wir dasselbe, aber für den adaptiven Schritt (Formel (10)): </p><br><pre> <code class="python hljs">MSEoptmu = np.empty((<span class="hljs-number"><span class="hljs-number">1</span></span>, N_steps), dtype=complex) w = np.zeros((M,<span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> N_i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(N_steps): gamma = p - np.dot(Rxx,w) mu_opt = mu_opt_calc(gamma, Rxx) w = w - mu_opt*(np.dot(Rxx,w) - p) MSEoptmu[:, N_i] = MSE_calc(sigmaS, Rxx, p, w)</code> </pre> <br><p>  Sie sollten so etwas bekommen: </p><br><div class="spoiler">  <b class="spoiler_title">Zeichnen</b> <div class="spoiler_text"><pre> <code class="python hljs">x = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, N_steps+<span class="hljs-number"><span class="hljs-number">1</span></span>)] plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>), dpi=<span class="hljs-number"><span class="hljs-number">300</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx, item <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(coeff): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> item == <span class="hljs-number"><span class="hljs-number">1</span></span>: item = <span class="hljs-string"><span class="hljs-string">''</span></span> plt.loglog(x, np.abs(MSE[idx, :]),\ label=<span class="hljs-string"><span class="hljs-string">'$\mu = '</span></span>+str(item)+<span class="hljs-string"><span class="hljs-string">'\mu_{max}$'</span></span>) plt.loglog(x, np.abs(MSEoptmu[<span class="hljs-number"><span class="hljs-number">0</span></span>, :]),\ label=<span class="hljs-string"><span class="hljs-string">'$\mu = \mu_{opt}$'</span></span>) plt.loglog(x, np.abs(MSEopt*np.ones((len(x), <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=complex)),\ label = <span class="hljs-string"><span class="hljs-string">'Wiener solution'</span></span>) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Number of steps'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Mean-Square Error'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Steepest descent'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'best'</span></span>) plt.minorticks_on() plt.grid(which=<span class="hljs-string"><span class="hljs-string">'major'</span></span>) plt.grid(which=<span class="hljs-string"><span class="hljs-string">'minor'</span></span>, linestyle=<span class="hljs-string"><span class="hljs-string">':'</span></span>) plt.show()</code> </pre> </div></div><br><p><img src="https://habrastorage.org/webt/il/fa/8d/ilfa8dmoxgt4sjitiyvwbdjga6m.png"></p><br><p>  <em>Abb.</em>  <em>5. Lernkurven für Schritte unterschiedlicher Größe.</em> </p><br><p>  Befestigungen, um die wichtigsten Punkte beim Gefälle hervorzuheben: </p><br><ul><li>  Wie erwartet ergibt der optimale Schritt die schnellste Konvergenz. </li><li>  bedeutet nicht mehr besser: Nachdem wir die Obergrenze überschritten haben, haben wir überhaupt keine Konvergenz erreicht. </li></ul><br><p>  Also haben wir den optimalen Vektor der Filterkoeffizienten gefunden, der die Effekte des Kanals am besten <u>ausgleicht</u> - wir haben <u>den Equalizer trainiert</u> . </p><br><h2 id="a-est-chto-to-bolee-blizkoe-k-realnosti">  Gibt es etwas näher an der Realität? </h2><br><p>  Natürlich!  Wir haben bereits mehrfach gesagt, dass das Sammeln von Statistiken (d. H. Das Berechnen von Korrelationsmatrizen und Vektoren) in Echtzeitsystemen alles andere als ein erschwinglicher Luxus ist.  Die Menschheit hat sich jedoch an diese Schwierigkeiten angepasst: Anstelle eines <em>deterministischen</em> Ansatzes in der Praxis werden <u>adaptive</u> Ansätze verwendet.  Sie können in zwei große Gruppen eingeteilt werden [1, S.  246]: </p><br><ul><li>  <em>probabilistisch (stochastisch)</em> (z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SG</a> - stochastischer Gradient) </li><li>  und basierend auf der Methode der <em>kleinsten Quadrate</em> (z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LMS</a> - Least Mean Squares oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RLS</a> - Recursive Least Squares) </li></ul><br><p>  Das Thema der adaptiven Filter ist in der Open-Source-Community gut vertreten (Beispiele für Python): </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pyroomakustik</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Padasip</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">adaptfilt</a> </li></ul><br><blockquote>  Im zweiten Beispiel gefällt mir besonders die Dokumentation.  Seien Sie jedoch vorsichtig!  Als ich das <strong>Padasip-</strong> Paket getestet <strong>habe</strong> , hatte ich Schwierigkeiten beim Umgang mit komplexen Zahlen (standardmäßig ist float64 dort impliziert).  Möglicherweise können bei der Arbeit mit einigen anderen Implementierungen dieselben Probleme auftreten. </blockquote><p>  Algorithmen haben natürlich ihre eigenen Vor- und Nachteile, deren Summe den Umfang des Algorithmus bestimmt. </p><br><p>  Werfen wir einen kurzen Blick auf die Beispiele: Wir werden die drei Algorithmen <em>SG</em> , <em>LMS</em> und <em>RLS betrachten</em> , die wir bereits erwähnt haben (wir werden in der MATLAB-Sprache modellieren - ich gestehe, es gab bereits Leerzeichen und schreiben alles in Einheitlichkeitspython um, um ... na ja ...). </p><br><p>  Eine Beschreibung der <em>LMS-</em> und <em>RLS-</em> Algorithmen finden Sie beispielsweise im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Padasip-</a> Dock. </p><br><div class="spoiler">  <b class="spoiler_title">Eine Beschreibung der SG finden Sie hier.</b> <div class="spoiler_text"><p>  Der Hauptunterschied zum Gradientenabstieg ist ein variabler Gradient: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/76f/9e3/fbb/76f9e3fbbb4c7643f5af595103791091.svg" alt="\ mathbf {w} [n] = \ mathbf {w} [n-1] + \ mu \ left (\ mathbf {\ hat {p}} [n] - \ mathbf {\ hat {R}} _ {xx } [n] \ mathbf {w} [n-1] \ right)"></div><br><p>  bei </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/633/bac/0aa/633bac0aae95be15cd31a312b4e0d2c5.svg" alt="\ mathbf {\ hat {R}} _ {xx} [n] = \ frac {1} {n} \ left ((n-1) \ mathbf {\ hat {R}} _ {xx} [n-1 ] + \ mathbf {x} [n] \ mathbf {x} [n] ^ H \ rechts)"></div><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f7/bfd/f81/4f7bfdf81571e19eac474c7a8c380093.svg" alt="\ mathbf {\ hat {p}} [n] = \ frac {1} {n} \ left ((n-1) \ mathbf {\ hat {p}} [n-1] + \ mathbf {x} [ n] d [n] ^ * \ rechts)"></div></div></div><br><p>  1) Ein ähnlicher Fall wie oben. </p><br><div class="spoiler">  <b class="spoiler_title">Quellen (MatLab / Octave).</b> <div class="spoiler_text"><p>  Quellen können hier heruntergeladen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> . </p></div></div><br><p><img src="https://habrastorage.org/webt/ff/zm/hq/ffzmhqsrnwvvc0hdrcyzhapropw.png"></p><br><p>  <em>Abb.</em>  <em>6. Lernkurven für LMS, RLS und SG.</em> </p><br><p>  Es ist sofort zu bemerken, dass der LMS-Algorithmus aufgrund seiner relativen Einfachheit im Prinzip möglicherweise nicht zu einer optimalen Lösung mit einem relativ großen Schritt kommt.  RLS liefert das schnellste Ergebnis, kann aber auch mit einem relativ kleinen <em>Vergessensfaktor</em> versagen.  Bisher geht es SG gut, aber schauen wir uns ein anderes Beispiel an. </p><br><p>  2) Der Fall, wenn sich der Kanal zeitlich ändert. </p><br><div class="spoiler">  <b class="spoiler_title">Quellen (MatLab / Octave).</b> <div class="spoiler_text"><p>  Quellen können hier heruntergeladen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> . </p></div></div><br><p><img src="https://habrastorage.org/webt/v-/9d/sx/v-9dsxxwzr9jnbnswf0dmnvqrcu.png"></p><br><p>  <em>Abb.</em>  <em>7. Lernkurven für LMS, RLS und SG (Kanalwechsel im Laufe der Zeit).</em> </p><br><p>  Und hier ist das Bild schon viel interessanter: Mit einer starken Veränderung in der Reaktion des Kanals scheint LMS bereits die zuverlässigste Lösung zu sein.  Wer hätte das gedacht.  Obwohl RLS mit dem richtigen Vergessensfaktor auch ein akzeptables Ergebnis liefert. </p><br><div class="spoiler">  <b class="spoiler_title">Ein paar Worte zur Leistung.</b> <div class="spoiler_text"><p>  Ja, natürlich hat jeder Algorithmus seine eigene spezifische Rechenkomplexität, aber nach meinen Messungen kann meine alte Maschine ein Ensemble für ungefähr 120 μs pro Iteration bei LMS und SG und ungefähr 250 μs pro Iteration bei RLS bewältigen.  Das heißt, der Unterschied ist im Allgemeinen vergleichbar. </p></div></div><br><p>  Und das ist alles für heute.  Vielen Dank an alle, die geschaut haben! </p><br><h2 id="literatura">  Literatur </h2><br><ol><li>  Haykin SS Adaptive Filtertheorie.  - Pearson Education India, 2005. </li><li>  Haykin, Simon und KJ Ray Liu.  Handbuch zur Array-Verarbeitung und zu Sensornetzwerken.  Vol.  63. John Wiley &amp; Sons, 2010. pp.  102-107 </li><li>  Arndt, D. (2015).  On Channel Modeling für den mobilen Satellitenempfang an Land (Dissertation). </li></ol><br><h2 id="prilozhenie-1">  Anhang 1 </h2><br><div class="spoiler">  <b class="spoiler_title">Eigenfilter</b> <div class="spoiler_text"><p>  Das Hauptziel eines solchen Filters ist die Maximierung des Signal-Rausch-Verhältnisses (SNR). </p><br><p><img src="https://habrastorage.org/webt/kk/v_/uu/kkv_uu-08dppu5i4yhkucc_b0ww.jpeg"></p><br><p>  Nach dem Vorhandensein von Korrelationen in den Berechnungen zu urteilen, ist dies jedoch eher ein theoretisches Konstrukt als eine praktische Lösung. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de455497/">https://habr.com/ru/post/de455497/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455483/index.html">Ai-Da-Künstler: Humanoider Roboter bereitet sich auf seine erste Einzelausstellung vor</a></li>
<li><a href="../de455485/index.html">Prüfpunktskripte - Führen Sie Skripte direkt von der Smart Console aus</a></li>
<li><a href="../de455487/index.html">Schulung Cisco 200-125 CCNA v3.0. Tag 10. Betriebsarten des Ports wechseln</a></li>
<li><a href="../de455489/index.html">Verbinden von Audio- und Videolösungen von Drittanbietern mit Microsoft-Teams</a></li>
<li><a href="../de455493/index.html">Was ist neu in der Angular 8-Version?</a></li>
<li><a href="../de455499/index.html">Extraktion von Weisheitszähnen: Wie geht das?</a></li>
<li><a href="../de455501/index.html">Wie Hollywood heimlich KI verwendet, um wichtige Drehentscheidungen zu treffen</a></li>
<li><a href="../de455503/index.html">19 Konzepte, die Sie lernen müssen, um ein effektiver Angular-Entwickler zu werden</a></li>
<li><a href="../de455505/index.html">Reaktionsbeschleunigung vierfach reagieren</a></li>
<li><a href="../de455507/index.html">Übersicht über das datierbare Python-Paket</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòú üëé üóíÔ∏è Otimiza√ß√£o da arquitetura de intelig√™ncia artificial: a corrida come√ßa üïñ üè¶ üçº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√Ä medida que a arquitetura da IA ‚Äã‚Äãmelhora e os custos caem, os especialistas dizem que mais e mais empresas dominam essas tecnologias, o que dar√° um ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Otimiza√ß√£o da arquitetura de intelig√™ncia artificial: a corrida come√ßa</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/icl_services/blog/415929/">  √Ä medida que a arquitetura da IA ‚Äã‚Äãmelhora e os custos caem, os especialistas dizem que mais e mais empresas dominam essas tecnologias, o que dar√° um impulso √†s inova√ß√µes e trar√° grandes dividendos para as empresas e os desenvolvedores de IA. <br><br>  Os aplicativos de IA geralmente funcionam com base em arquiteturas completamente diferentes das aplica√ß√µes corporativas tradicionais.  Por sua vez, os fornecedores est√£o dispostos a fazer muito para fornecer novos componentes que est√£o crescendo em demanda. <br><br><img src="https://habrastorage.org/webt/kx/tl/dk/kxtldk4vqyzwqzmeaxzo5u8pulo.jpeg" align="left"><blockquote> "O setor de computa√ß√£o est√° passando por grandes mudan√ßas - o interesse das empresas em IA impulsiona inova√ß√µes que as ajudar√£o a dominar e implantar a IA em qualquer escala", disse Keith Strier, especialista em IA, consultor da EY.  Os investidores est√£o investindo muito dinheiro em startups que otimizam a IA, e os grandes fabricantes est√£o come√ßando a oferecer n√£o apenas chips e armazenamento, mas tamb√©m os servi√ßos de rede e nuvem necess√°rios para a implanta√ß√£o. ‚Äù </blockquote>  . <br>  Segundo ele, agora a principal tarefa dos diretores de TI √© escolher a arquitetura de intelig√™ncia artificial apropriada para as necessidades da empresa. <br><br>  Streer diz que, como a IA √© matem√°tica em uma escala sem precedentes, a implementa√ß√£o dessa tecnologia requer condi√ß√µes t√©cnicas e ferramentas de seguran√ßa completamente diferentes das cargas de trabalho corporativas familiares.  Para aproveitar ao m√°ximo a IA, os fornecedores precisar√£o fornecer a infraestrutura t√©cnica, a nuvem e outros servi√ßos necess√°rios para a IA, sem os quais c√°lculos complexos seriam imposs√≠veis. <br><a name="habracut"></a><br>  Mas j√° estamos no caminho para isso e, no futuro, haver√° arquiteturas ainda mais avan√ßadas de intelig√™ncia artificial.  Streer acredita que o fornecimento de flexibilidade, pot√™ncia e velocidade das arquiteturas de computa√ß√£o ser√° n√£o apenas pequenas empresas para o desenvolvimento da computa√ß√£o de alto desempenho, mas tamb√©m outros representantes da ind√∫stria de computa√ß√£o de alto desempenho, incluindo startups para criar microchips e servi√ßos em nuvem que buscam estabelecer um alto padr√£o de intelig√™ncia artificial. computa√ß√£o. <br><br>  √Ä medida que aparecerem mais especialistas e desenvolvedores no campo da IA, essa tecnologia se tornar√° mais acess√≠vel, o que dar√° um bom impulso √†s inova√ß√µes e trar√° dividendos vis√≠veis - para empresas e fornecedores. <br><br>  Enquanto isso, os diretores de TI devem se familiarizar com as dificuldades associadas √† cria√ß√£o de uma arquitetura de intelig√™ncia artificial para uso corporativo, a fim de estarem prontos para resolv√™-las. <br><br><h3>  Desenvolvimento de chips <br></h3><br>  A condi√ß√£o mais importante para a transi√ß√£o das arquiteturas de computa√ß√£o tradicionais para a IA foi o desenvolvimento de processadores gr√°ficos, circuitos l√≥gicos program√°veis ‚Äã‚Äã(FPGAs) e chips de IA especializados.  A prolifera√ß√£o de arquiteturas baseadas em GPUs e FPGAs ajudar√° a aumentar a produtividade e a flexibilidade dos sistemas de computa√ß√£o e armazenamento, o que permitir√° que os provedores de solu√ß√µes ofere√ßam uma gama de servi√ßos avan√ßados para aplicativos de IA e aprendizado de m√°quina. <br><br><img src="https://habrastorage.org/webt/ik/yt/d4/ikytd4x8p5ajbjv_m4tjqq-lgzi.jpeg" align="left"><blockquote>  "Essas s√£o arquiteturas de chips que liberam muitos recursos avan√ßados da carga [como treinamento em IA] e ajudam a implementar uma pilha aprimorada de computa√ß√£o e armazenamento que oferece desempenho e efici√™ncia incompar√°veis", disse Surya Varanasi, fundadora e CTO da Vexata Inc., fornecedor de solu√ß√µes de gerenciamento de dados. </blockquote><br>  Mas enquanto os novos microcircuitos n√£o s√£o capazes de algo mais complexo.  Para selecionar a arquitetura ideal para as cargas de trabalho de IA, √© necess√°rio executar c√°lculos em larga escala que exijam alta taxa de transfer√™ncia e n√£o podem ficar sem atrasos.  A chave do sucesso aqui s√£o as redes de alta velocidade.  Mas muitos algoritmos de IA devem esperar at√© que o pr√≥ximo conjunto de dados seja digitado, para que voc√™ n√£o perca de vista o atraso. <br><br>  Al√©m disso, ao cruzar os limites do servidor ou transferir dos servidores para o armazenamento, os dados passam por v√°rios protocolos.  Para simplificar esses processos, os especialistas em dados podem tentar localiz√°-los localmente para que um servidor possa processar grandes blocos de dados sem esperar outros.  A integra√ß√£o aprimorada entre GPUs e armazenamento tamb√©m ajuda a economizar dinheiro.  Outros fornecedores est√£o procurando maneiras de simplificar o design dos servidores de IA para garantir a compatibilidade, de modo que os mesmos servidores possam ser usados ‚Äã‚Äãpara diferentes cargas de trabalho. <br><br><h3>  Mem√≥ria n√£o vol√°til para processar cargas de trabalho de IA <br></h3><br>  O cerne de muitas solu√ß√µes baseadas na GPU √© um DAS (Direct-Attached Drive), o que complica bastante o aprendizado distribu√≠do e a forma√ß√£o de conclus√µes l√≥gicas para a IA.  Como resultado, instalar e gerenciar essas linhas de dados para aprendizado profundo est√° se tornando uma tarefa complexa e demorada. <br><br>  Para resolver esse problema, a mem√≥ria n√£o vol√°til (NVM) √© adequada, originalmente projetada para fornecer conectividade de alta qualidade entre unidades de estado s√≥lido (SSDs) e servidores corporativos tradicionais.  Agora, esse tipo de mem√≥ria √© frequentemente inclu√≠do nas matrizes de E / S para otimizar as cargas de trabalho de IA. <br><br>  A conclus√£o √© que o NVMe over Fabrics (NVMeF) - as chamadas interfaces - ajudar√° a reduzir o custo da convers√£o entre protocolos de rede e a controlar as caracter√≠sticas de cada tipo de SSD.  Isso permitir√° que os CIOs justifiquem o custo dos aplicativos de IA que usam grandes conjuntos de dados. <br><br>  Interfaces O NVMeF envolve seus riscos, incluindo a necessidade de altos custos para tecnologias avan√ßadas.  Al√©m disso, ainda h√° depend√™ncia dos fornecedores do NVMeF nesse setor, portanto, os diretores de TI devem tentar evitar relacionamentos espec√≠ficos do fornecedor ao escolher um produto. <br>  Mas a implementa√ß√£o do NVMeF permitir√° que voc√™ d√™ outro passo para otimizar a arquitetura corporativa de intelig√™ncia artificial, acredita Varanasi. <br><br><img src="https://habrastorage.org/webt/ik/yt/d4/ikytd4x8p5ajbjv_m4tjqq-lgzi.jpeg" align="left"><blockquote>  ‚ÄúApesar de a expans√£o da arquitetura NVMe over Fabrics em escala industrial poder demorar mais um ano ou um ano e meio, j√° temos os principais componentes e os pioneiros j√° est√£o relatando resultados promissores‚Äù, diz Varanasi. <br><br></blockquote><br>  Os CIOs que desejam desenvolver aplicativos de IA podem tentar criar um pool de armazenamento compartilhado otimizado para AI para NVMeF se ele puder substituir com √™xito as redes de armazenamento existentes a curto prazo.  Mas se voc√™ esperar at√© que o NVMeF seja compat√≠vel com vers√µes anteriores, poder√° perder muito. <br><br><h3>  Reduzir a movimenta√ß√£o de dados <br></h3><br>  Ao planejar os v√°rios est√°gios da implanta√ß√£o da IA, voc√™ precisa prestar aten√ß√£o especial ao custo da movimenta√ß√£o de dados.  Projetos de IA, incluindo aqueles para processamento e transforma√ß√£o de dados, bem como para algoritmos de treinamento, exigem grandes quantidades de dados. <br><br>  O hardware e os recursos humanos necess√°rios para concluir essas tarefas, bem como o tempo necess√°rio para mover os dados, podem tornar os projetos de IA muito caros.  Se os CIOs puderem evitar a movimenta√ß√£o de dados entre os est√°gios, √© prov√°vel que eles consigam desenvolver uma infraestrutura vi√°vel de IA que atenda a essas necessidades, disse Haris Pozidis, Ph.D., gerente, especialista em tecnologia de acelera√ß√£o de armazenamento da IBM Research.  Os fabricantes j√° est√£o trabalhando nessa quest√£o. <br><br>  Por exemplo, a IBM est√° experimentando v√°rias op√ß√µes de otimiza√ß√£o de hardware e software para reduzir a movimenta√ß√£o de dados para aplicativos de IA em larga escala em laborat√≥rios em Zurique.  Essas otimiza√ß√µes ajudaram 46 vezes a aumentar o desempenho do script de teste da popular ferramenta de an√°lise de cliques.  Pozidis diz que o aprendizado distribu√≠do e a acelera√ß√£o da GPU est√£o no centro deste trabalho, o que melhora o suporte a estruturas de dados esparsas. <br><br>  A simultaneidade √© outro componente importante na acelera√ß√£o das cargas de trabalho de IA.  Para treinamento distribu√≠do, √© necess√°rio fazer altera√ß√µes nos n√≠veis de hardware e software, o que aumentar√° a efici√™ncia do processamento de algoritmos de processadores gr√°ficos paralelos.  Os pesquisadores da IBM criaram uma plataforma de prot√≥tipo com paralelismo de dados, que permite dimensionar e aprender sobre grandes quantidades de dados que excedem a quantidade de mem√≥ria em uma m√°quina.  Isso √© muito importante para aplicativos em larga escala.  Uma nova plataforma otimizada para o aprendizado da comunica√ß√£o e a localiza√ß√£o dos dados ajudou a reduzir a movimenta√ß√£o de dados. <br><br>  No n√≠vel do hardware, os pesquisadores da IBM usaram o NVMeF para melhorar a interconectividade dos componentes GPU, CPU e mem√≥ria nos servidores, bem como entre servidores e armazenamento. <br><br><img src="https://habrastorage.org/webt/es/li/m1/eslim1mvwlg3vqgesw1lfuzlyqa.jpeg" align="left"><blockquote>  ‚ÄúO desempenho de diferentes cargas de trabalho de IA pode ser limitado por gargalos de rede, largura de banda de mem√≥ria e largura de banda entre a CPU e a GPU.  Mas se voc√™ implementar algoritmos e protocolos de conex√£o mais eficientes em todas as partes do sistema, poder√° dar um grande passo no desenvolvimento de aplicativos de IA mais r√°pidos ‚Äù, diz Pozidis. </blockquote><br><br><h3>  Computa√ß√£o Composta <br></h3>  Hoje, a maioria das cargas de trabalho usa um banco de dados pr√©-configurado otimizado para uma arquitetura de hardware espec√≠fica. <br><br><img src="https://habrastorage.org/webt/iy/qd/xq/iyqdxqbenrorpibc--ylt9o0zfs.jpeg" align="left"><br><blockquote>  Chad Miley, vice-presidente de produtos e solu√ß√µes anal√≠ticas da Teradata, diz que o mercado est√° se movendo em dire√ß√£o a hardware orientado a software, o que permitir√° √†s organiza√ß√µes distribuir inteligentemente o processamento entre GPUs e CPUs, dependendo da tarefa atual. </blockquote><br><br>  A dificuldade est√° no fato de as empresas usarem diferentes mecanismos de computa√ß√£o para acessar diferentes op√ß√µes de armazenamento.  As grandes empresas preferem armazenar dados valiosos que precisam de acesso regular, por exemplo, informa√ß√µes sobre clientes, finan√ßas, cadeia de suprimentos, produtos e outros componentes, usando ambientes de entrada e sa√≠da de alto desempenho.  Por sua vez, conjuntos de dados raramente usados, como leituras de sensores, conte√∫do da Web e multim√≠dia, s√£o armazenados no armazenamento em nuvem de baixo custo. <br><br>  Um dos objetivos da computa√ß√£o composta √© usar cont√™ineres para otimizar o desempenho de inst√¢ncias como mecanismos SQL, mecanismos de gr√°ficos, aprendizado de m√°quina e mecanismos de aprendizado profundo que acessam dados distribu√≠dos em diferentes reposit√≥rios.  A implanta√ß√£o de v√°rios mecanismos de computa√ß√£o anal√≠tica permite o uso de modelos de multiprocessadores que usam dados de diferentes mecanismos e, como regra, trazem melhores resultados. <br><br>  Os fornecedores de TI, como Dell Technologies, Hewlett Packard Enterprise e Liquid, est√£o gradualmente se afastando das arquiteturas tradicionais que atribuem cargas de trabalho no n√≠vel da computa√ß√£o.  Em vez disso, eles procuram atribuir cargas de trabalho de IA a um sistema inteiro que consiste em unidades de processamento central, GPUs, dispositivos de mem√≥ria e armazenamento.  Para essa transi√ß√£o, √© necess√°rio dominar novos componentes de rede, que aumentam a velocidade e reduzem o atraso ao conectar v√°rios componentes do sistema. <br><br>  Por exemplo, muitos datacenters em nuvem usam Ethernet para conectar componentes de computa√ß√£o e armazenamento, onde o atraso √© de cerca de 15 microssegundos.  A rede de computadores comutados de alta velocidade da InfiniBand, usada em muitas infraestruturas convergentes, pode reduzir a lat√™ncia em at√© 1,5 microssegundos.  A Liquid criou um conjunto de ferramentas para conectar n√≥s diferentes usando o PCI Express (PCIE), o que reduz o atraso para 150 nanossegundos. <br><br>  Al√©m disso, alguns especialistas sugerem aumentar a quantidade de mem√≥ria das GPUs usadas para lidar com grandes cargas com conex√µes r√°pidas.  Por exemplo, o DDR4 √© frequentemente usado junto com a RAM, o que reduz o atraso para 14 nanossegundos.  Mas isso funciona apenas para pequenos segmentos de alguns cent√≠metros. <br><br>  Little Marrek, fundador e desenvolvedor do servi√ßo de gerenciamento de ClusterOne AI, acredita que √© necess√°rio mais trabalho para garantir a compatibilidade das cargas de trabalho de IA em um ambiente de software.  Apesar de algumas empresas j√° estarem tentando garantir a compatibilidade com o Docker e o Kubernetes, ainda √© cedo para aplicar a mesma abordagem √†s GPUs. <br><br><img src="https://habrastorage.org/webt/gy/kf/vo/gykfvonm7odfn4osmkaya-lwfas.jpeg" align="left"><blockquote>  ‚ÄúEm geral, executar cargas de trabalho da GPU e monitor√°-las n√£o √© f√°cil‚Äù, diz Marrek.  "N√£o existe uma solu√ß√£o universal que permita o monitoramento de todos os sistemas". <br><br></blockquote><br><br><h3>  Armazenamento e GPU <br></h3><br>  Outra abordagem √© usar um processador gr√°fico para pr√©-processar os dados, a fim de reduzir a quantidade necess√°ria para um tipo espec√≠fico de an√°lise e ajudar a organizar os dados e atribuir r√≥tulos a eles.  Isso permitir√° que voc√™ prepare um conjunto de dados adequado para v√°rias GPUs envolvidas no processamento, para que o algoritmo possa funcionar a partir do interior da mem√≥ria, em vez de transferir dados dos armazenamentos em redes lentas. <br><br><img src="https://habrastorage.org/webt/ys/qp/cb/ysqpcbtqxhszcgd3hpgn9kutmss.jpeg" align="left"><blockquote>  "Percebemos armazenamento, computa√ß√£o e mem√≥ria como componentes separados da solu√ß√£o, que se desenvolveu historicamente e, portanto, tentamos aumentar os volumes de processamento", disse Alex St. John, CTO e fundador da Nyriad Ltd., uma empresa de software de armazenamento que apareceu em o resultado da pesquisa do maior radiotelesc√≥pio do mundo - um telesc√≥pio com uma antena de um quil√¥metro quadrado (SKA). </blockquote>  Quanto maiores as quantidades de dados, mais dif√≠cil √© mov√™-las para algum lugar para processamento. <br><br>  O telesc√≥pio SKA precisava de grandes quantidades de energia para processar 160 TB de dados de sinais de r√°dio em tempo real, que era o principal obst√°culo para os pesquisadores.  Como resultado, eles decidiram abandonar os armazenamentos RAID usados ‚Äã‚Äãcom mais freq√º√™ncia nos datacenters e implantar um sistema de arquivos em cluster paralelo, como o BeeGFS, que simplifica a prepara√ß√£o de dados para cargas de trabalho de IA. <br><br>  Os diretores de TI que trabalham na estrat√©gia ideal para a arquitetura de intelig√™ncia artificial devem prestar aten√ß√£o especial √† usabilidade.  Se desenvolvedores, especialistas em dados e equipes de desenvolvimento e integra√ß√£o de opera√ß√µes puderem dominar rapidamente a nova tecnologia, poder√£o investir seu tempo e energia na cria√ß√£o de uma l√≥gica de neg√≥cios bem-sucedida, em vez de resolver problemas de implanta√ß√£o e linhas de dados. <br><br>  Al√©m disso, as organiza√ß√µes precisam considerar cuidadosamente quanto esfor√ßo e tempo ser√£o necess√°rios para criar uma nova arquitetura de IA em um ecossistema existente. <br><br>  ‚ÄúAntes de implementar novas infraestruturas e planejar grandes cargas de trabalho, os CIOs precisam avaliar quantos recursos esgot√°veis ‚Äã‚Äãser√£o necess√°rios‚Äù, diz Asaf Someh, fundador e CEO da Iguazio. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt415929/">https://habr.com/ru/post/pt415929/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt415917/index.html">A "Lei da Primavera" entrou em vigor: o que vem a seguir?</a></li>
<li><a href="../pt415919/index.html">Refatorando um programa em movimento: acelera√ß√£o 23 vezes</a></li>
<li><a href="../pt415923/index.html">A unidade √© lenta? Cuidado LINQ</a></li>
<li><a href="../pt415925/index.html">MasterCard patenteada tecnologia blockchain an√¥nima</a></li>
<li><a href="../pt415927/index.html">L√¢mpada industrial Breeze 50</a></li>
<li><a href="../pt415933/index.html">Como construir uma arquitetura IIoT fa√ßa voc√™ mesmo</a></li>
<li><a href="../pt415935/index.html">Classifica√ß√µes de inser√ß√£o</a></li>
<li><a href="../pt415937/index.html">Foguete particular japon√™s MOMO-2 explodiu na plataforma de lan√ßamento</a></li>
<li><a href="../pt415939/index.html">Processamento de gr√°fico distribu√≠do com Spark GraphX</a></li>
<li><a href="../pt415941/index.html">Como tentamos descobrir o c√≥digo de barras e n√£o entendemos nada</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
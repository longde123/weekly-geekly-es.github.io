<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìõ üè® üëä Probl√®me de reconnaissance vocale pas encore r√©solu ‚ôåÔ∏è üëî üë©üèø‚Äçü§ù‚Äçüë©üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Depuis que l'apprentissage en profondeur est entr√© sur la sc√®ne de la reconnaissance vocale, le nombre d'erreurs dans la reconnaissance des mots a con...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Probl√®me de reconnaissance vocale pas encore r√©solu</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408017/">  Depuis que l'apprentissage en profondeur est entr√© sur la sc√®ne de la reconnaissance vocale, le nombre d'erreurs dans la reconnaissance des mots a consid√©rablement diminu√©.  Mais, malgr√© tous les articles que vous avez pu lire, nous n'avons toujours pas de reconnaissance vocale au niveau humain.  Les logiciels de reconnaissance vocale pr√©sentent de nombreux types d'√©checs.  Pour une am√©lioration suppl√©mentaire, ils doivent √™tre allou√©s et essayer de les √©liminer.  C'est le seul moyen de passer d'une reconnaissance qui convient la plupart du temps √† certaines personnes √† une reconnaissance qui fonctionne √† tout moment pour tous. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/443/a84/749/443a8474981289cde040380c76002864.svg"></div><br>  <i>Am√©lioration du nombre de mots reconnus par erreur.</i>  <i>Un test de num√©rotation vocale a √©t√© compil√© sur un standard t√©l√©phonique en 2000 √† partir de 40 conversations al√©atoires de deux personnes dont la langue maternelle est l'anglais.</i> <br><br>  Dire que nous avons atteint le niveau d'une personne dans la reconnaissance vocale dans les conversations, bas√© uniquement sur un ensemble de conversations √† partir d'un standard t√©l√©phonique, revient √† dire qu'un robot ne conduit pas pire qu'une personne, le testant dans une seule ville par une journ√©e ensoleill√©e sans trafic .  Les d√©veloppements r√©cents de la reconnaissance vocale ont √©t√© surprenants.  Mais les d√©clarations sur la reconnaissance vocale au niveau humain sont trop audacieuses.  Voici quelques domaines o√π des am√©liorations sont encore n√©cessaires. <br><a name="habracut"></a><br><h2>  Accents et bruit </h2><br>  L'un des inconv√©nients √©vidents de la reconnaissance vocale est le traitement des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">accents</a> et du bruit de fond.  La raison principale en est que la plupart des donn√©es de formation se composent de dialecte am√©ricain avec un rapport signal / bruit √©lev√©.  Par exemple, dans l'ensemble des conversations du standard t√©l√©phonique, il n'y a que des conversations de personnes dont la langue maternelle est l'anglais (pour la plupart, ce sont des Am√©ricains) avec peu de bruit de fond. <br><br>  Mais l'augmentation des donn√©es de formation √† elle seule ne r√©soudra probablement pas ce probl√®me.  Il existe de nombreuses langues qui contiennent de nombreux dialectes et accents.  Il n'est pas r√©aliste de collecter des donn√©es balis√©es pour tous les cas.  La cr√©ation d'une reconnaissance vocale de haute qualit√© uniquement pour l'anglais am√©ricain n√©cessite jusqu'√† 5 000 heures d'enregistrements audio traduits en texte. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/072/946/fac/072946faca72dac55d3a3acd20bfba3f.svg"></div><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comparaison des</a> personnes qui convertissent la parole en texte avec Deep Speech 2 de Baidu sur diff√©rents types de discours.</i>  <i>Les gens sont pires √† reconna√Ætre les accents non am√©ricains - peut-√™tre √† cause de l'abondance d'Am√©ricains parmi eux.</i>  <i>Je pense que les gens qui ont grandi dans une certaine r√©gion, avec un nombre d'erreurs beaucoup plus r√©duit, seraient capables de reconna√Ætre l'importance de cette r√©gion.</i> <br><br>  En pr√©sence de bruit de fond dans une voiture en mouvement, le rapport signal / bruit peut atteindre des valeurs de -5 dB.  Les gens peuvent facilement faire face √† la reconnaissance vocale d'une autre personne dans de telles conditions.  Les reconnaisseurs automatiques se d√©t√©riorent beaucoup plus rapidement avec l'augmentation du bruit.  Le graphique montre √† quel point la s√©paration des personnes augmente avec l'augmentation du bruit (√† faible SNR, rapport signal / bruit) <br><br><h2>  Erreurs s√©mantiques </h2><br>  Souvent, le nombre de mots reconnus par erreur n'est pas une fin en soi dans un syst√®me de reconnaissance vocale.  Nous visons le nombre d'erreurs s√©mantiques.  C'est la proportion d'expressions dont nous reconnaissons incorrectement le sens. <br><br>  Un exemple d'erreur s√©mantique est lorsque quelqu'un propose ¬´Rencontrons-nous mardi¬ª [Rencontrons-nous mardi] et les probl√®mes de reconnaissance ¬´Rencontrons-nous aujourd'hui¬ª [Rencontrons-nous aujourd'hui].  Il y a des erreurs dans les mots sans erreurs s√©mantiques.  Si le reconnaissant n'a pas reconnu ¬´up¬ª et a √©mis ¬´rendez-vous mardi¬ª, la s√©mantique de la phrase n'a pas chang√©. <br><br>  Nous devons soigneusement utiliser le nombre de mots reconnus par erreur comme crit√®re.  Pour illustrer cela, je vais vous donner un exemple avec les pires cas possibles.  5% des erreurs de mots correspondent √† un mot manqu√© sur 20. S'il y a 20 mots dans chaque phrase (ce qui est tout √† fait dans la moyenne pour l'anglais), alors le nombre de phrases mal reconnues approche 100%.  On peut esp√©rer que des mots mal reconnus ne changent pas le sens s√©mantique des phrases.  Sinon, le programme de reconnaissance peut d√©crypter chaque phrase de mani√®re incorrecte, m√™me avec 5% du nombre de mots reconnus par erreur. <br><br>  Lors de la comparaison de mod√®les avec des personnes, il est important de v√©rifier l'essence des erreurs et de surveiller non seulement le nombre de mots mal reconnus.  D'apr√®s mon exp√©rience, les personnes qui traduisent la parole en texte font moins d'erreurs et elles ne sont pas aussi graves que les ordinateurs. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les chercheurs de Microsoft ont r√©cemment compar√© les</a> erreurs des personnes et des logiciels de reconnaissance informatique d'un niveau similaire.  L'une des diff√©rences constat√©es est que le mod√®le confond ¬´uh¬ª [euh ...] avec ¬´uh huh¬ª [aha] beaucoup plus souvent que les humains.  Ces deux termes ont une s√©mantique tr√®s diff√©rente: ¬´uh¬ª remplit les pauses, et ¬´uh huh¬ª signifie confirmation de l'auditeur.  En outre, les mod√®les et les personnes ont trouv√© de nombreuses erreurs du m√™me type. <br><br><h2>  Beaucoup de votes dans un canal </h2><br>  La reconnaissance des conversations t√©l√©phoniques enregistr√©es est √©galement plus facile car chaque locuteur a √©t√© enregistr√© sur un microphone s√©par√©.  Il n'y a pas de chevauchement de plusieurs voix dans un canal audio.  Les gens peuvent comprendre plusieurs locuteurs, s'exprimant parfois simultan√©ment. <br><br>  Un bon logiciel de reconnaissance vocale devrait √™tre capable de diviser le flux audio en segments selon le locuteur (sous r√©serve de sa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">diarisation</a> ).  Il devrait √©galement donner un sens √† l'enregistrement audio avec deux voix qui se chevauchent (s√©paration des sources).  Cela doit √™tre fait sans microphone situ√© directement √† l'embouchure de chaque haut-parleur, c'est-√†-dire pour que le module de reconnaissance fonctionne bien, √©tant plac√© dans un endroit arbitraire. <br><br><h2>  Qualit√© d'enregistrement </h2><br>  Les accents et le bruit de fond ne sont que deux facteurs auxquels un reconnaissance vocale doit √™tre r√©sistant.  En voici quelques autres: <br><br>  ‚Ä¢ R√©verb√©ration dans diff√©rentes conditions acoustiques. <br>  ‚Ä¢ Artefacts li√©s √† l'√©quipement. <br>  ‚Ä¢ Artefacts du codec utilis√© pour enregistrer et compresser le signal. <br>  ‚Ä¢ Taux d'√©chantillonnage. <br>  ‚Ä¢ L'√¢ge du locuteur. <br><br>  La plupart des gens ne distingueront pas √† l'oreille les enregistrements mp3 et wav.  Avant de d√©clarer des indicateurs comparables √† l'homme, les reconnaisseurs doivent devenir r√©sistants aux sources de variations r√©pertori√©es. <br><br><h2>  Contexte </h2><br>  Vous pouvez voir que le nombre d'erreurs que les gens font sur les tests dans les enregistrements du central t√©l√©phonique est assez √©lev√©.  Si vous parliez avec un ami qui ne comprenait pas 1 mot sur 20, il vous serait tr√®s difficile de communiquer. <br><br>  Une des raisons √† cela est la reconnaissance sans contexte.  Dans la vraie vie, nous utilisons de nombreux signes suppl√©mentaires pour nous aider √† comprendre ce que dit l'autre personne.  Quelques exemples de contexte utilis√©s par les gens et ignor√©s par les reconnaissance vocale: <br><br>  ‚Ä¢ Historique des conversations et sujet en discussion. <br>  ‚Ä¢ Des indices visuels sur le locuteur - expressions faciales, mouvements des l√®vres. <br>  ‚Ä¢ L'ensemble des connaissances sur la personne √† qui nous parlons. <br><br>  Maintenant, la reconnaissance vocale dans Android a une liste de vos contacts, afin qu'elle puisse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">reconna√Ætre les noms de vos amis</a> .  La recherche vocale sur les cartes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">utilise la g√©olocalisation</a> pour r√©duire le nombre d'options possibles vers lesquelles vous souhaitez cr√©er un itin√©raire. <br><br>  La pr√©cision des syst√®mes de reconnaissance augmente avec l'inclusion de tels signaux dans les donn√©es.  Mais nous commen√ßons tout juste √† nous plonger dans le type de contexte que nous pourrions inclure dans le traitement et dans les m√©thodes de son utilisation. <br><br><h2>  D√©ploiement </h2><br>  Les derni√®res avanc√©es en mati√®re de reconnaissance vocale ne peuvent pas √™tre d√©ploy√©es.  En imaginant le d√©ploiement d'un algorithme de reconnaissance vocale, vous devez vous souvenir des retards et de la puissance de calcul.  Ces param√®tres sont li√©s car les algorithmes qui augmentent les besoins en √©nergie augmentent √©galement la latence.  Mais pour plus de simplicit√©, nous en discuterons s√©par√©ment. <br><br>  D√©lai: le temps √©coul√© entre la fin du discours de l'utilisateur et la fin de la r√©ception de la transcription.  Un l√©ger retard est une exigence de reconnaissance typique.  Cela affecte consid√©rablement l'exp√©rience de l'utilisateur avec le produit.  Il y a souvent une limite de dizaines de millisecondes.  Cela peut sembler trop strict, mais n'oubliez pas que l'√©mission du d√©cryptage est g√©n√©ralement la premi√®re √©tape d'une s√©rie de calculs complexes.  Par exemple, dans le cas d'une recherche vocale sur Internet apr√®s reconnaissance vocale, vous devez toujours effectuer une recherche. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les couches de r√©currence bidirectionnelles</a> sont un exemple typique d'une am√©lioration qui aggrave la situation de retard.  Tous les derniers r√©sultats de d√©cryptage de haute qualit√© sont obtenus avec leur aide.  Le seul probl√®me est que nous ne pouvons rien compter apr√®s avoir pass√© la premi√®re couche bidirectionnelle jusqu'√† ce que la personne ait fini de parler.  Par cons√©quent, le d√©lai augmente avec la dur√©e de la peine. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/fe9/dfd/ab2/fe9dfdab2e62e5265f9cbe0cd8c854b1.svg"></div><br>  <i>Gauche: la r√©currence directe permet au d√©cryptage de commencer imm√©diatement.</i>  <i>√Ä droite: la r√©currence bidirectionnelle n√©cessite d'attendre la fin du discours avant de d√©coder.</i> <br><br>  Un bon moyen d'int√©grer efficacement les informations futures dans la reconnaissance vocale est toujours √† la recherche. <br><br>  Puissance de calcul: cette option est affect√©e par des contraintes √©conomiques.  Le co√ªt du banquet doit √™tre pris en compte pour chaque am√©lioration de la pr√©cision du reconnaisseur.  Si l'am√©lioration n'atteint pas le seuil √©conomique, elle ne fonctionnera pas. <br><br>  Un exemple classique d'am√©lioration continue qu'ils ne d√©ploient jamais est l'apprentissage profond collaboratif [ensemble].  Une r√©duction de 1 √† 2% du nombre d'erreurs justifie rarement une augmentation de 2 √† 8 fois de la puissance de calcul.  Les mod√®les modernes de r√©seaux r√©currents entrent √©galement dans cette cat√©gorie, car il est tr√®s d√©savantageux de les utiliser dans la recherche d'un ensemble de trajectoires, m√™me si, je pense, la situation va changer √† l'avenir. <br><br>  Je veux clarifier - je ne dis pas que l'am√©lioration de la pr√©cision de la reconnaissance avec une augmentation s√©rieuse des co√ªts de calcul est inutile.  Nous avons d√©j√† vu comment fonctionnait dans le pass√© le principe du ¬´d'abord lentement, mais avec pr√©cision, puis rapidement¬ª.  Le fait est que tant que l'am√©lioration n'est pas assez rapide, vous ne pouvez pas l'utiliser. <br><br><h2>  Au cours des cinq prochaines ann√©es </h2><br>  Dans le domaine de la reconnaissance vocale, il existe encore de nombreux probl√®mes complexes et non r√©solus.  Parmi eux: <br><br>  ‚Ä¢ Extension des capacit√©s des nouveaux syst√®mes de stockage, reconnaissance de l'emphase, discours sur fond de bruit fort. <br>  ‚Ä¢ Inclusion du contexte dans le processus de reconnaissance. <br>  ‚Ä¢ Diarisation et s√©paration des sources. <br>  ‚Ä¢ Nombre d'erreurs s√©mantiques et m√©thodes innovantes pour √©valuer les reconnaisseurs. <br>  ‚Ä¢ Latence tr√®s faible. <br><br>  J'attends avec impatience les progr√®s qui seront r√©alis√©s au cours des cinq prochaines ann√©es sur ces fronts et sur d'autres. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr408017/">https://habr.com/ru/post/fr408017/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr408001/index.html">Et encore une fois, le bitcoin se d√©veloppe. Mais pourquoi?</a></li>
<li><a href="../fr408003/index.html">Flightradar24 - comment √ßa marche?</a></li>
<li><a href="../fr408005/index.html">Comment g√©rons-nous l'extinction de la nature</a></li>
<li><a href="../fr408011/index.html">Revue vid√©o de l'imprimante 3D UP! Mini 2</a></li>
<li><a href="../fr408015/index.html">R√©flexions sur les jetons (traduction)</a></li>
<li><a href="../fr408019/index.html">Caract√©ristiques int√©ressantes de la BMW S√©rie 7</a></li>
<li><a href="../fr408023/index.html">Raise3D: l'utilisation d'imprimantes 3D dans le film</a></li>
<li><a href="../fr408025/index.html">Transmission "Miracle de la technologie" sur les lecteurs: nous vous recommandons de regarder. Et tirer des conclusions</a></li>
<li><a href="../fr408027/index.html">Un cadeau de Geek - faire une minuterie de cuisine</a></li>
<li><a href="../fr408029/index.html">Apple remporte enfin un proc√®s de 120 millions de dollars contre Samsung pour violation de brevet sur la diapositive √† d√©verrouiller</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
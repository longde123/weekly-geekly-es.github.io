<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📛 🏨 👊 Problème de reconnaissance vocale pas encore résolu ♌️ 👔 👩🏿‍🤝‍👩🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Depuis que l'apprentissage en profondeur est entré sur la scène de la reconnaissance vocale, le nombre d'erreurs dans la reconnaissance des mots a con...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Problème de reconnaissance vocale pas encore résolu</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408017/">  Depuis que l'apprentissage en profondeur est entré sur la scène de la reconnaissance vocale, le nombre d'erreurs dans la reconnaissance des mots a considérablement diminué.  Mais, malgré tous les articles que vous avez pu lire, nous n'avons toujours pas de reconnaissance vocale au niveau humain.  Les logiciels de reconnaissance vocale présentent de nombreux types d'échecs.  Pour une amélioration supplémentaire, ils doivent être alloués et essayer de les éliminer.  C'est le seul moyen de passer d'une reconnaissance qui convient la plupart du temps à certaines personnes à une reconnaissance qui fonctionne à tout moment pour tous. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/443/a84/749/443a8474981289cde040380c76002864.svg"></div><br>  <i>Amélioration du nombre de mots reconnus par erreur.</i>  <i>Un test de numérotation vocale a été compilé sur un standard téléphonique en 2000 à partir de 40 conversations aléatoires de deux personnes dont la langue maternelle est l'anglais.</i> <br><br>  Dire que nous avons atteint le niveau d'une personne dans la reconnaissance vocale dans les conversations, basé uniquement sur un ensemble de conversations à partir d'un standard téléphonique, revient à dire qu'un robot ne conduit pas pire qu'une personne, le testant dans une seule ville par une journée ensoleillée sans trafic .  Les développements récents de la reconnaissance vocale ont été surprenants.  Mais les déclarations sur la reconnaissance vocale au niveau humain sont trop audacieuses.  Voici quelques domaines où des améliorations sont encore nécessaires. <br><a name="habracut"></a><br><h2>  Accents et bruit </h2><br>  L'un des inconvénients évidents de la reconnaissance vocale est le traitement des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">accents</a> et du bruit de fond.  La raison principale en est que la plupart des données de formation se composent de dialecte américain avec un rapport signal / bruit élevé.  Par exemple, dans l'ensemble des conversations du standard téléphonique, il n'y a que des conversations de personnes dont la langue maternelle est l'anglais (pour la plupart, ce sont des Américains) avec peu de bruit de fond. <br><br>  Mais l'augmentation des données de formation à elle seule ne résoudra probablement pas ce problème.  Il existe de nombreuses langues qui contiennent de nombreux dialectes et accents.  Il n'est pas réaliste de collecter des données balisées pour tous les cas.  La création d'une reconnaissance vocale de haute qualité uniquement pour l'anglais américain nécessite jusqu'à 5 000 heures d'enregistrements audio traduits en texte. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/072/946/fac/072946faca72dac55d3a3acd20bfba3f.svg"></div><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comparaison des</a> personnes qui convertissent la parole en texte avec Deep Speech 2 de Baidu sur différents types de discours.</i>  <i>Les gens sont pires à reconnaître les accents non américains - peut-être à cause de l'abondance d'Américains parmi eux.</i>  <i>Je pense que les gens qui ont grandi dans une certaine région, avec un nombre d'erreurs beaucoup plus réduit, seraient capables de reconnaître l'importance de cette région.</i> <br><br>  En présence de bruit de fond dans une voiture en mouvement, le rapport signal / bruit peut atteindre des valeurs de -5 dB.  Les gens peuvent facilement faire face à la reconnaissance vocale d'une autre personne dans de telles conditions.  Les reconnaisseurs automatiques se détériorent beaucoup plus rapidement avec l'augmentation du bruit.  Le graphique montre à quel point la séparation des personnes augmente avec l'augmentation du bruit (à faible SNR, rapport signal / bruit) <br><br><h2>  Erreurs sémantiques </h2><br>  Souvent, le nombre de mots reconnus par erreur n'est pas une fin en soi dans un système de reconnaissance vocale.  Nous visons le nombre d'erreurs sémantiques.  C'est la proportion d'expressions dont nous reconnaissons incorrectement le sens. <br><br>  Un exemple d'erreur sémantique est lorsque quelqu'un propose «Rencontrons-nous mardi» [Rencontrons-nous mardi] et les problèmes de reconnaissance «Rencontrons-nous aujourd'hui» [Rencontrons-nous aujourd'hui].  Il y a des erreurs dans les mots sans erreurs sémantiques.  Si le reconnaissant n'a pas reconnu «up» et a émis «rendez-vous mardi», la sémantique de la phrase n'a pas changé. <br><br>  Nous devons soigneusement utiliser le nombre de mots reconnus par erreur comme critère.  Pour illustrer cela, je vais vous donner un exemple avec les pires cas possibles.  5% des erreurs de mots correspondent à un mot manqué sur 20. S'il y a 20 mots dans chaque phrase (ce qui est tout à fait dans la moyenne pour l'anglais), alors le nombre de phrases mal reconnues approche 100%.  On peut espérer que des mots mal reconnus ne changent pas le sens sémantique des phrases.  Sinon, le programme de reconnaissance peut décrypter chaque phrase de manière incorrecte, même avec 5% du nombre de mots reconnus par erreur. <br><br>  Lors de la comparaison de modèles avec des personnes, il est important de vérifier l'essence des erreurs et de surveiller non seulement le nombre de mots mal reconnus.  D'après mon expérience, les personnes qui traduisent la parole en texte font moins d'erreurs et elles ne sont pas aussi graves que les ordinateurs. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les chercheurs de Microsoft ont récemment comparé les</a> erreurs des personnes et des logiciels de reconnaissance informatique d'un niveau similaire.  L'une des différences constatées est que le modèle confond «uh» [euh ...] avec «uh huh» [aha] beaucoup plus souvent que les humains.  Ces deux termes ont une sémantique très différente: «uh» remplit les pauses, et «uh huh» signifie confirmation de l'auditeur.  En outre, les modèles et les personnes ont trouvé de nombreuses erreurs du même type. <br><br><h2>  Beaucoup de votes dans un canal </h2><br>  La reconnaissance des conversations téléphoniques enregistrées est également plus facile car chaque locuteur a été enregistré sur un microphone séparé.  Il n'y a pas de chevauchement de plusieurs voix dans un canal audio.  Les gens peuvent comprendre plusieurs locuteurs, s'exprimant parfois simultanément. <br><br>  Un bon logiciel de reconnaissance vocale devrait être capable de diviser le flux audio en segments selon le locuteur (sous réserve de sa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">diarisation</a> ).  Il devrait également donner un sens à l'enregistrement audio avec deux voix qui se chevauchent (séparation des sources).  Cela doit être fait sans microphone situé directement à l'embouchure de chaque haut-parleur, c'est-à-dire pour que le module de reconnaissance fonctionne bien, étant placé dans un endroit arbitraire. <br><br><h2>  Qualité d'enregistrement </h2><br>  Les accents et le bruit de fond ne sont que deux facteurs auxquels un reconnaissance vocale doit être résistant.  En voici quelques autres: <br><br>  • Réverbération dans différentes conditions acoustiques. <br>  • Artefacts liés à l'équipement. <br>  • Artefacts du codec utilisé pour enregistrer et compresser le signal. <br>  • Taux d'échantillonnage. <br>  • L'âge du locuteur. <br><br>  La plupart des gens ne distingueront pas à l'oreille les enregistrements mp3 et wav.  Avant de déclarer des indicateurs comparables à l'homme, les reconnaisseurs doivent devenir résistants aux sources de variations répertoriées. <br><br><h2>  Contexte </h2><br>  Vous pouvez voir que le nombre d'erreurs que les gens font sur les tests dans les enregistrements du central téléphonique est assez élevé.  Si vous parliez avec un ami qui ne comprenait pas 1 mot sur 20, il vous serait très difficile de communiquer. <br><br>  Une des raisons à cela est la reconnaissance sans contexte.  Dans la vraie vie, nous utilisons de nombreux signes supplémentaires pour nous aider à comprendre ce que dit l'autre personne.  Quelques exemples de contexte utilisés par les gens et ignorés par les reconnaissance vocale: <br><br>  • Historique des conversations et sujet en discussion. <br>  • Des indices visuels sur le locuteur - expressions faciales, mouvements des lèvres. <br>  • L'ensemble des connaissances sur la personne à qui nous parlons. <br><br>  Maintenant, la reconnaissance vocale dans Android a une liste de vos contacts, afin qu'elle puisse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">reconnaître les noms de vos amis</a> .  La recherche vocale sur les cartes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">utilise la géolocalisation</a> pour réduire le nombre d'options possibles vers lesquelles vous souhaitez créer un itinéraire. <br><br>  La précision des systèmes de reconnaissance augmente avec l'inclusion de tels signaux dans les données.  Mais nous commençons tout juste à nous plonger dans le type de contexte que nous pourrions inclure dans le traitement et dans les méthodes de son utilisation. <br><br><h2>  Déploiement </h2><br>  Les dernières avancées en matière de reconnaissance vocale ne peuvent pas être déployées.  En imaginant le déploiement d'un algorithme de reconnaissance vocale, vous devez vous souvenir des retards et de la puissance de calcul.  Ces paramètres sont liés car les algorithmes qui augmentent les besoins en énergie augmentent également la latence.  Mais pour plus de simplicité, nous en discuterons séparément. <br><br>  Délai: le temps écoulé entre la fin du discours de l'utilisateur et la fin de la réception de la transcription.  Un léger retard est une exigence de reconnaissance typique.  Cela affecte considérablement l'expérience de l'utilisateur avec le produit.  Il y a souvent une limite de dizaines de millisecondes.  Cela peut sembler trop strict, mais n'oubliez pas que l'émission du décryptage est généralement la première étape d'une série de calculs complexes.  Par exemple, dans le cas d'une recherche vocale sur Internet après reconnaissance vocale, vous devez toujours effectuer une recherche. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les couches de récurrence bidirectionnelles</a> sont un exemple typique d'une amélioration qui aggrave la situation de retard.  Tous les derniers résultats de décryptage de haute qualité sont obtenus avec leur aide.  Le seul problème est que nous ne pouvons rien compter après avoir passé la première couche bidirectionnelle jusqu'à ce que la personne ait fini de parler.  Par conséquent, le délai augmente avec la durée de la peine. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/geektimes/post_images/fe9/dfd/ab2/fe9dfdab2e62e5265f9cbe0cd8c854b1.svg"></div><br>  <i>Gauche: la récurrence directe permet au décryptage de commencer immédiatement.</i>  <i>À droite: la récurrence bidirectionnelle nécessite d'attendre la fin du discours avant de décoder.</i> <br><br>  Un bon moyen d'intégrer efficacement les informations futures dans la reconnaissance vocale est toujours à la recherche. <br><br>  Puissance de calcul: cette option est affectée par des contraintes économiques.  Le coût du banquet doit être pris en compte pour chaque amélioration de la précision du reconnaisseur.  Si l'amélioration n'atteint pas le seuil économique, elle ne fonctionnera pas. <br><br>  Un exemple classique d'amélioration continue qu'ils ne déploient jamais est l'apprentissage profond collaboratif [ensemble].  Une réduction de 1 à 2% du nombre d'erreurs justifie rarement une augmentation de 2 à 8 fois de la puissance de calcul.  Les modèles modernes de réseaux récurrents entrent également dans cette catégorie, car il est très désavantageux de les utiliser dans la recherche d'un ensemble de trajectoires, même si, je pense, la situation va changer à l'avenir. <br><br>  Je veux clarifier - je ne dis pas que l'amélioration de la précision de la reconnaissance avec une augmentation sérieuse des coûts de calcul est inutile.  Nous avons déjà vu comment fonctionnait dans le passé le principe du «d'abord lentement, mais avec précision, puis rapidement».  Le fait est que tant que l'amélioration n'est pas assez rapide, vous ne pouvez pas l'utiliser. <br><br><h2>  Au cours des cinq prochaines années </h2><br>  Dans le domaine de la reconnaissance vocale, il existe encore de nombreux problèmes complexes et non résolus.  Parmi eux: <br><br>  • Extension des capacités des nouveaux systèmes de stockage, reconnaissance de l'emphase, discours sur fond de bruit fort. <br>  • Inclusion du contexte dans le processus de reconnaissance. <br>  • Diarisation et séparation des sources. <br>  • Nombre d'erreurs sémantiques et méthodes innovantes pour évaluer les reconnaisseurs. <br>  • Latence très faible. <br><br>  J'attends avec impatience les progrès qui seront réalisés au cours des cinq prochaines années sur ces fronts et sur d'autres. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr408017/">https://habr.com/ru/post/fr408017/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr408001/index.html">Et encore une fois, le bitcoin se développe. Mais pourquoi?</a></li>
<li><a href="../fr408003/index.html">Flightradar24 - comment ça marche?</a></li>
<li><a href="../fr408005/index.html">Comment gérons-nous l'extinction de la nature</a></li>
<li><a href="../fr408011/index.html">Revue vidéo de l'imprimante 3D UP! Mini 2</a></li>
<li><a href="../fr408015/index.html">Réflexions sur les jetons (traduction)</a></li>
<li><a href="../fr408019/index.html">Caractéristiques intéressantes de la BMW Série 7</a></li>
<li><a href="../fr408023/index.html">Raise3D: l'utilisation d'imprimantes 3D dans le film</a></li>
<li><a href="../fr408025/index.html">Transmission "Miracle de la technologie" sur les lecteurs: nous vous recommandons de regarder. Et tirer des conclusions</a></li>
<li><a href="../fr408027/index.html">Un cadeau de Geek - faire une minuterie de cuisine</a></li>
<li><a href="../fr408029/index.html">Apple remporte enfin un procès de 120 millions de dollars contre Samsung pour violation de brevet sur la diapositive à déverrouiller</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
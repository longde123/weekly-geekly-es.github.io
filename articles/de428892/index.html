<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚è∞ üìÆ üí∑ So erstellen Sie eine Spiel-KI: eine Anleitung f√ºr Anf√§nger üßñüèº üöº ü•Å</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich bin auf interessantes Material √ºber k√ºnstliche Intelligenz in Spielen gesto√üen. Mit einer Erkl√§rung der grundlegenden Dinge √ºber KI anhand einfach...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>So erstellen Sie eine Spiel-KI: eine Anleitung f√ºr Anf√§nger</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/428892/"><img src="https://habrastorage.org/webt/hp/x-/0n/hpx-0n-frdakrflfvlpdt-6hp1e.png"><br><br>  Ich bin auf interessantes Material √ºber k√ºnstliche Intelligenz in Spielen gesto√üen.  Mit einer Erkl√§rung der grundlegenden Dinge √ºber KI anhand einfacher Beispiele und im Inneren finden Sie viele n√ºtzliche Werkzeuge und Methoden f√ºr die bequeme Entwicklung und Gestaltung.  Wie, wo und wann man sie benutzt - ist auch da. <br><br>  Die meisten Beispiele sind in Pseudocode geschrieben, sodass keine detaillierten Programmierkenntnisse erforderlich sind.  Unter dem Schnitt 35 Blatt Text mit Bildern und Gifs, also machen Sie sich bereit. <br><br>  UPD  Es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tut mir leid</a> , aber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PatientZero</a> hat diesen Artikel √ºber Habr√© bereits √ºbersetzt.  Sie k√∂nnen die Version <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> lesen, aber aus irgendeinem Grund hat mich der Artikel √ºberholt (ich habe die Suche verwendet, aber etwas ist schief gelaufen).  Und da ich einen Blog f√ºr Spieleentwickler schreibe, habe ich beschlossen, meine √úbersetzungsoption den Abonnenten zu √ºberlassen (einige Momente sind f√ºr mich anders, andere werden auf Anraten der Entwickler absichtlich verpasst). <br><a name="habracut"></a><br><h2>  Was ist KI? </h2><br>  Die Spiel-KI konzentriert sich darauf, welche Aktionen ein Objekt basierend auf den Bedingungen ausf√ºhren soll, unter denen es sich befindet.  Dies wird normalerweise als Management von ‚Äûintelligenten Agenten‚Äú bezeichnet, bei denen der Agent ein Spielcharakter, ein Fahrzeug, ein Bot und manchmal etwas Abstrakteres ist: eine ganze Gruppe von Entit√§ten oder sogar eine Zivilisation.  In jedem Fall ist es eine Sache, die ihre Umgebung sehen, Entscheidungen auf ihrer Grundlage treffen und in √úbereinstimmung mit ihnen handeln muss.  Dies wird als Sense / Think / Act-Zyklus bezeichnet: <br><br><ul><li>  Sinn: Der Agent findet oder empf√§ngt Informationen √ºber Dinge in seiner Umgebung, die sein Verhalten beeinflussen k√∂nnen (Bedrohungen in der N√§he, Gegenst√§nde zum Sammeln, interessante Orte zum Forschen). </li><li>  Denken Sie: Der Agent entscheidet, wie er reagieren soll (√ºberlegt, ob das Sammeln von Gegenst√§nden sicher ist oder ob er zuerst k√§mpfen / sich verstecken muss). </li><li>  Handlung: Der Agent f√ºhrt Aktionen aus, um die vorherige Entscheidung umzusetzen (bewegt sich auf den Gegner oder das Objekt zu). </li><li>  ... jetzt hat sich die Situation aufgrund der Aktionen der Charaktere ge√§ndert, sodass sich der Zyklus mit neuen Daten wiederholt. </li></ul><br>  KI tendiert dazu, sich auf den Sinnesteil der Schleife zu konzentrieren.  Zum Beispiel machen autonome Autos Fotos von der Stra√üe, kombinieren sie mit Radar- und Lidar-Daten und interpretieren sie.  Normalerweise erfolgt dies durch maschinelles Lernen, das die eingehenden Daten verarbeitet und ihnen Bedeutung verleiht und semantische Informationen wie "20 Meter vor Ihnen steht ein weiteres Auto" extrahiert.  Dies sind die sogenannten Klassifizierungsprobleme. <br><br>  Spiele ben√∂tigen kein komplexes System zum Extrahieren von Informationen, da die meisten Daten bereits ein wesentlicher Bestandteil davon sind.  Es ist nicht erforderlich, Bilderkennungsalgorithmen auszuf√ºhren, um festzustellen, ob ein Feind vor Ihnen liegt. Das Spiel kennt und √ºbertr√§gt Informationen bereits direkt im Entscheidungsprozess.  Daher ist ein Teil des Sinneszyklus oft viel einfacher als Denken und Handeln. <br><br><h2>  Einschr√§nkungen der Spiel-KI </h2><br>  AI hat eine Reihe von Einschr√§nkungen, die beachtet werden m√ºssen: <br><br><ul><li>  KI muss nicht im Voraus trainiert werden, als w√§re es ein Algorithmus f√ºr maschinelles Lernen.  Es ist sinnlos, w√§hrend der Entwicklung ein neuronales Netzwerk zu schreiben, um Zehntausende von Spielern zu beobachten und zu lernen, wie man am besten gegen sie spielt.  Warum?  Weil das Spiel nicht ver√∂ffentlicht wird, aber es keine Spieler gibt. </li><li>  Das Spiel sollte unterhalten und herausfordern, daher sollten Agenten nicht den besten Ansatz gegen Menschen finden. </li><li>  Agenten m√ºssen realistisch aussehen, damit die Spieler das Gef√ºhl haben, gegen echte Menschen zu spielen.  AlphaGo √ºbertraf die Menschen, aber die unternommenen Schritte waren weit vom traditionellen Verst√§ndnis des Spiels entfernt.  Wenn das Spiel einen menschlichen Gegner imitiert, sollte es kein solches Gef√ºhl geben.  Der Algorithmus muss ge√§ndert werden, damit er plausible und keine idealen Entscheidungen trifft. </li><li>  KI sollte in Echtzeit funktionieren.  Dies bedeutet, dass der Algorithmus die Verwendung des Prozessors f√ºr eine lange Zeit zur Entscheidungsfindung nicht monopolisieren kann.  Selbst 10 Millisekunden sind zu lang, da die meisten Spiele nur 16 bis 33 Millisekunden haben, um die gesamte Verarbeitung abzuschlie√üen und mit dem n√§chsten Frame der Grafik fortzufahren. </li><li>  Im Idealfall ist zumindest ein Teil des Systems datengesteuert, sodass Nicht-Codierer √Ñnderungen vornehmen und Anpassungen schneller durchf√ºhren k√∂nnen. </li></ul><br>  Betrachten Sie KI-Ans√§tze, die den gesamten Sense / Think / Act-Zyklus umfassen. <br><br><h3>  Grundlegende Entscheidungsfindung </h3><br>  Beginnen wir mit dem einfachsten Spiel - Pong.  Ziel: Bewegen Sie die Plattform (Paddel) so, dass der Ball davon abprallt, anstatt vorbei zu fliegen.  Es ist wie beim Tennis, bei dem man verliert, wenn man den Ball nicht schl√§gt.  Hier hat die KI eine relativ einfache Aufgabe - zu entscheiden, in welche Richtung die Plattform bewegt werden soll. <br><br><img src="https://habrastorage.org/webt/1l/6g/p8/1l6gp88aolep77ohq7dqwkw8oky.jpeg"><br><br><h3>  Bedingte Anweisungen </h3><br>  F√ºr AI hat Pong die naheliegendste L√∂sung - versuchen Sie immer, die Plattform unter dem Ball zu positionieren. <br><br>  Ein einfacher Algorithmus hierf√ºr, geschrieben in Pseudocode: <br><br>  <i>jedes Frame / Update w√§hrend das Spiel l√§uft:</i> <i><br></i>  <i>Wenn sich der Ball links vom Paddel befindet:</i> <i><br></i>  <i>Paddel nach links bewegen</i> <i><br></i>  <i>sonst, wenn sich der Ball rechts vom Paddel befindet:</i> <i><br></i>  <i>Paddel nach rechts bewegen</i> <br><br>  Wenn sich die Plattform mit der Geschwindigkeit des Balls bewegt, ist dies der perfekte Algorithmus f√ºr AI in Pong.  Es besteht keine Notwendigkeit, etwas zu komplizieren, wenn nicht so viele Daten und m√∂gliche Aktionen f√ºr den Agenten vorhanden sind. <br><br>  Dieser Ansatz ist so einfach, dass der gesamte Sense / Think / Act-Zyklus kaum sp√ºrbar ist.  Aber er ist: <br><br><ul><li>  Der Sense-Teil besteht aus zwei if-Anweisungen.  Das Spiel wei√ü, wo sich der Ball befindet und wo sich die Plattform befindet, daher wendet sich die KI an ihn, um diese Informationen zu erhalten. </li><li>  Der Think-Teil besteht auch aus zwei if-Anweisungen.  Sie verk√∂rpern zwei L√∂sungen, die sich in diesem Fall gegenseitig ausschlie√üen.  Infolgedessen wird eine von drei Aktionen ausgew√§hlt: Verschieben Sie die Plattform nach links, bewegen Sie sich nach rechts oder tun Sie nichts, wenn sie bereits richtig positioniert ist. </li><li>  Der Act-Teil befindet sich in den Anweisungen Move Paddle Left und Move Paddle Right.  Je nach Design des Spiels k√∂nnen sie die Plattform sofort oder mit einer bestimmten Geschwindigkeit bewegen. </li></ul><br>  Solche Ans√§tze werden als reaktiv bezeichnet - es gibt ein einfaches Regelwerk (in diesem Fall if-Anweisungen im Code), die auf den aktuellen Zustand der Welt reagieren und handeln. <br><br><h3>  Entscheidungsbaum </h3><br>  Das Pong-Beispiel entspricht tats√§chlich dem formalen KI-Konzept, das als Entscheidungsbaum bezeichnet wird.  Der Algorithmus √ºbergibt es, um ein ‚ÄûBlatt‚Äú zu erreichen - eine Entscheidung dar√ºber, welche Ma√ünahmen ergriffen werden sollen. <br><br>  Lassen Sie uns ein Blockdiagramm des Entscheidungsbaums f√ºr den Algorithmus unserer Plattform erstellen: <br><br><img src="https://habrastorage.org/webt/yu/u8/nd/yuu8ndgkxfb0mj1qyfhht-vhrnw.png"><br><br>  Jeder Teil des Baums wird als Knoten bezeichnet - die KI verwendet die Graphentheorie, um solche Strukturen zu beschreiben.  Es gibt zwei Arten von Knoten: <br><br><ul><li>  Entscheidungsknoten: Auswahl zwischen zwei Alternativen basierend auf der √úberpr√ºfung einer bestimmten Bedingung, bei der jede Alternative als separater Knoten dargestellt wird. </li><li>  Endknoten: Eine auszuf√ºhrende Aktion, die die endg√ºltige Entscheidung darstellt. </li></ul><br>  Der Algorithmus beginnt mit dem ersten Knoten (der "Wurzel" des Baums).  Es entscheidet entweder, zu welchem ‚Äã‚Äãuntergeordneten Knoten es gehen soll, oder es f√ºhrt eine im Knoten gespeicherte Aktion aus und schlie√üt sie ab. <br><br>  Was ist der Vorteil, wenn der Entscheidungsbaum dieselbe Aufgabe erf√ºllt wie die if-Anweisungen im vorherigen Abschnitt?  Hier gibt es ein gemeinsames System, bei dem jede L√∂sung nur eine Bedingung und zwei m√∂gliche Ergebnisse aufweist.  Auf diese Weise kann der Entwickler aus den Daten, die die Entscheidungen im Baum darstellen, eine KI erstellen und deren Hardcodierung vermeiden.  Stellen Sie sich in Form einer Tabelle vor: <br><br><img src="https://habrastorage.org/webt/dt/mx/zg/dtmxzgddk1mo585bhzy7-x_espw.png"><br><br>  Auf der Codeseite erhalten Sie ein System zum Lesen von Zeichenfolgen.  Erstellen Sie f√ºr jeden einen Knoten, verbinden Sie die Entscheidungslogik basierend auf der zweiten Spalte und die untergeordneten Knoten basierend auf der dritten und vierten Spalte.  Sie m√ºssen noch die Bedingungen und Aktionen programmieren, aber jetzt wird die Struktur des Spiels komplizierter.  Darin f√ºgen Sie zus√§tzliche Entscheidungen und Aktionen hinzu und konfigurieren dann die gesamte KI, indem Sie einfach eine Textdatei mit einer Baumdefinition bearbeiten.  √úbertragen Sie als N√§chstes die Datei an den Spieledesigner, der das Verhalten √§ndern kann, ohne das Spiel neu zu kompilieren und den Code zu √§ndern. <br><br>  Entscheidungsb√§ume sind sehr n√ºtzlich, wenn sie automatisch anhand einer Vielzahl von Beispielen erstellt werden (z. B. mithilfe des ID3-Algorithmus).  Dies macht sie zu einem effektiven und leistungsstarken Tool zur Klassifizierung von Situationen anhand der empfangenen Daten.  Wir gehen jedoch √ºber ein einfaches System hinaus, mit dem Agenten Aktionen ausw√§hlen k√∂nnen. <br><br><h3>  Szenarien </h3><br>  Wir haben ein Entscheidungsbaumsystem zerlegt, das vorab erstellte Bedingungen und Aktionen verwendet.  Der KI-Designer kann den Baum so anordnen, wie er m√∂chte, aber er muss sich immer noch auf den Encoder verlassen, der alles programmiert hat.  Was w√§re, wenn wir den Designern Werkzeuge geben k√∂nnten, um unsere eigenen Bedingungen oder Aktionen zu erstellen? <br><br>  Um zu verhindern, dass der Programmierer Code f√ºr die Bedingungen Is Ball Left Of Paddle und Is Ball Right Of Paddle schreibt, kann er ein System erstellen, in dem der Designer die Bedingungen f√ºr die √úberpr√ºfung dieser Werte aufzeichnet.  Dann sehen die Daten des Entscheidungsbaums folgenderma√üen aus: <br><br><img src="https://habrastorage.org/webt/o9/nw/pe/o9nwpet07f-6xi7crzt5u34-orm.png"><br><br>  Im Wesentlichen ist dies dasselbe wie in der ersten Tabelle, aber die L√∂sungen in sich haben ihren eigenen Code, √§hnlich dem bedingten Teil der if-Anweisung.  Auf der Codeseite w√ºrde dies in der zweiten Spalte f√ºr Entscheidungsknoten gelesen, aber anstatt nach einer bestimmten zu erf√ºllenden Bedingung zu suchen (Is Ball Left Of Paddle), wertet es den bedingten Ausdruck aus und gibt true bzw. false zur√ºck.  Dies geschieht mit der Skriptsprache Lua oder Angelscript.  Mit ihnen kann der Entwickler Objekte in seinem Spiel (Ball und Paddel) nehmen und Variablen erstellen, die im Skript verf√ºgbar sind (ball.position).  Dar√ºber hinaus ist die Skriptsprache einfacher als C ++.  Es erfordert keine vollst√§ndige Kompilierungsphase, ist daher ideal f√ºr die schnelle Anpassung der Spielelogik geeignet und erm√∂glicht es ‚ÄûNicht-Codierern‚Äú, die erforderlichen Funktionen selbst zu erstellen. <br><br>  Im obigen Beispiel wird die Skriptsprache nur zum Auswerten eines bedingten Ausdrucks verwendet, sie kann jedoch auch f√ºr Aktionen verwendet werden.  Beispielsweise k√∂nnen Daten zum Verschieben des Paddels nach rechts zu einer Skriptanweisung werden (ball.position.x + = 10).  Damit wird die Aktion auch im Skript definiert, ohne dass Move Paddle Right programmiert werden muss. <br><br>  Sie k√∂nnen noch weiter gehen und einen vollst√§ndigen Entscheidungsbaum in einer Skriptsprache schreiben.  Dies ist ein Code in Form von fest codierten bedingten Anweisungen, die sich jedoch in externen Skriptdateien befinden. Das hei√üt, sie k√∂nnen ge√§ndert werden, ohne das gesamte Programm neu zu kompilieren.  Oft k√∂nnen Sie die Skriptdatei direkt w√§hrend des Spiels √§ndern, um schnell verschiedene KI-Reaktionen zu testen. <br><br><h3>  Ereignisantwort </h3><br>  Die obigen Beispiele sind perfekt f√ºr Pong.  Sie f√ºhren kontinuierlich den Sense / Think / Act-Zyklus durch und handeln auf der Grundlage des neuesten Zustands der Welt.  Bei komplexeren Spielen m√ºssen Sie jedoch auf einzelne Ereignisse reagieren und nicht alles auf einmal bewerten.  Pong ist bereits ein erfolgloses Beispiel.  W√§hle einen anderen. <br><br>  Stellen Sie sich einen Sch√ºtzen vor, bei dem die Feinde bewegungslos sind, bis sie den Spieler finden. Danach handeln sie abh√§ngig von ihrer "Spezialisierung": Jemand rennt, um "zu vernichten", jemand greift aus der Ferne an.  Dies ist immer noch das grundlegende Reaktionssystem - ‚ÄûWenn der Spieler bemerkt wird, dann tun Sie etwas‚Äú -, aber es kann logisch in das Ereignis Spieler gesehen (der Spieler wird bemerkt) und die Reaktion (Antwort ausw√§hlen und ausf√ºhren) unterteilt werden. <br><br>  Dies bringt uns zur√ºck zum Sense / Think / Act-Zyklus.  Wir k√∂nnen den Sense-Teil codieren, der in jedem Frame √ºberpr√ºft, ob die KI des Spielers sichtbar ist.  Wenn nicht, passiert nichts, aber wenn es sieht, wird das Ereignis Spieler gesehen ausgel√∂st.  Der Code enth√§lt einen separaten Abschnitt mit der Aufschrift: "Wenn das Ereignis" Spieler gesehen "auftritt, tun Sie es". Hier finden Sie die Antwort, die Sie ben√∂tigen, um auf die Teile "Denken und Handeln" zu verweisen.  Auf diese Weise richten Sie Reaktionen auf das Ereignis "Spieler gesehen" ein: "ChargeAndAttack" f√ºr den "wachsenden" Charakter und "HideAndSnipe" f√ºr den Scharfsch√ºtzen.  Diese Beziehungen k√∂nnen in der Datendatei zur schnellen Bearbeitung erstellt werden, ohne dass eine Neukompilierung erforderlich ist.  Und hier k√∂nnen Sie auch die Skriptsprache verwenden. <br><br><h2>  Schwierige Entscheidungen treffen </h2><br>  Obwohl einfache Reaktionssysteme sehr effektiv sind, gibt es viele Situationen, in denen sie nicht ausreichen.  Manchmal ist es notwendig, verschiedene Entscheidungen zu treffen, basierend auf dem, was der Agent gerade tut, aber es ist schwierig, sich dies als Bedingung vorzustellen.  Manchmal gibt es zu viele Bedingungen, um sie effektiv in einem Entscheidungsbaum oder Skript darzustellen.  Manchmal m√ºssen Sie vorab entscheiden, wie sich die Situation √§ndern wird, bevor Sie sich f√ºr den n√§chsten Schritt entscheiden.  Die L√∂sung dieser Probleme erfordert komplexere Ans√§tze. <br><br><h3>  Endliche Zustandsmaschine </h3><br>  Finite State Machine oder FSM (State Machine) ist eine M√∂glichkeit zu sagen, dass sich unser Agent derzeit in einem von mehreren m√∂glichen Zust√§nden befindet und von einem Zustand in einen anderen wechseln kann.  Es gibt eine bestimmte Anzahl solcher Zust√§nde - daher der Name.  Das beste Beispiel des Lebens ist eine Ampel.  An verschiedenen Orten unterschiedliche Lichtfolgen, aber das Prinzip ist das gleiche - jeder Zustand repr√§sentiert etwas (stehen, gehen usw.).  Eine Ampel befindet sich zu einem bestimmten Zeitpunkt nur in einem Zustand und wechselt nach einfachen Regeln von einem in einen anderen. <br><br>  Mit NPCs in Spielen eine √§hnliche Geschichte.  Nehmen Sie zum Beispiel eine Wache mit den folgenden Bedingungen: <br><br><ul><li>  Patrouillieren </li><li>  Angreifen </li><li>  Flucht </li></ul><br>  Und solche Bedingungen f√ºr die √Ñnderung seines Zustands: <br><br><ul><li>  Wenn der Wachmann den Feind sieht, greift er an. </li><li>  Wenn der Wachmann angreift, den Feind aber nicht mehr sieht, patrouilliert er wieder. </li><li>  Wenn der Wachmann angreift, aber schwer verwundet ist, rennt er weg. </li></ul><br>  Sie k√∂nnen auch if-Anweisungen mit einer Schutzzustandsvariablen und verschiedenen √úberpr√ºfungen schreiben: Befindet sich ein Feind in der N√§he, wie hoch ist der Gesundheitszustand des NPC usw. F√ºgen wir noch einige weitere Zust√§nde hinzu: <br><br><ul><li>  Unt√§tigkeit (Leerlauf) - zwischen Patrouillen. </li><li>  Suchen (Suchen) - wenn der bemerkte Feind verschwunden ist. </li><li>  Bitten Sie um Hilfe (Hilfe finden) - wenn der Feind gesehen wird, aber zu stark, um mit ihm allein zu k√§mpfen. </li></ul><br>  Die Auswahl f√ºr jeden von ihnen ist begrenzt - zum Beispiel wird ein Wachmann nicht nach einem versteckten Feind suchen, wenn er sich in einem schlechten Gesundheitszustand befindet. <br><br>  Am Ende kann die riesige Liste von "wenn &lt;x und y, aber nicht z&gt;, dann &lt;p&gt;" zu umst√§ndlich werden, daher sollten wir eine Methode formalisieren, die es uns erm√∂glicht, die Zust√§nde und √úberg√§nge zwischen Zust√§nden im Auge zu behalten.  Dazu ber√ºcksichtigen wir alle Zust√§nde und listen unter jedem Zustand alle √úberg√§nge zu anderen Zust√§nden zusammen mit den daf√ºr erforderlichen Bedingungen auf. <br><br><img src="https://habrastorage.org/webt/ut/25/j2/ut25j2aky0lx_ajk_rf2eeilgei.png"><br><br>  Diese Zustands√ºbergangstabelle ist eine umfassende M√∂glichkeit, FSM darzustellen.  Zeichnen wir ein Diagramm und erhalten einen vollst√§ndigen √úberblick dar√ºber, wie sich das Verhalten von NPCs √§ndert. <br><br><img src="https://habrastorage.org/webt/fg/7u/so/fg7uso5gla8wi4-fry0qne_bfvy.png"><br><br>  Das Diagramm spiegelt das Wesentliche der Entscheidungsfindung f√ºr diesen Agenten auf der Grundlage der aktuellen Situation wider.  Dar√ºber hinaus zeigt jeder Pfeil einen √úbergang zwischen Zust√§nden, wenn die Bedingung daneben erf√ºllt ist. <br><br>  Bei jedem Update √ºberpr√ºfen wir den aktuellen Status des Agenten, sehen uns die Liste der √úberg√§nge an und wenn die Bedingungen f√ºr den √úbergang erf√ºllt sind, nimmt er einen neuen Status an.  Beispielsweise pr√ºft jeder Frame, ob der 10-Sekunden-Timer abgelaufen ist, und wenn ja, wechselt der Schutz von Leerlauf zu Patrouillieren.  Auf die gleiche Weise √ºberpr√ºft der Angriffsstatus den Zustand des Agenten. Wenn er niedrig ist, wechselt er in den Fluchtzustand. <br><br>  Dies behandelt Zustands√ºberg√§nge, aber was ist mit dem Verhalten, das mit den Zust√§nden selbst verbunden ist?  In Bezug auf die Implementierung des tats√§chlichen Verhaltens f√ºr einen bestimmten Status gibt es normalerweise zwei Arten von ‚ÄûHooks‚Äú, bei denen wir dem FSM Aktionen zuweisen: <br><br><ul><li>  Aktionen, die wir regelm√§√üig f√ºr den aktuellen Status ausf√ºhren. </li><li>  Die Ma√ünahmen, die wir ergreifen, wenn wir von einem Staat in einen anderen wechseln. </li></ul><br>  Beispiele f√ºr den ersten Typ.  Patrouillenstatus Jeder Frame bewegt den Agenten entlang der Patrouillenroute.  Angriffsstatus Jeder Frame versucht, einen Angriff zu starten oder wenn m√∂glich in einen Status zu wechseln. <br><br>  Betrachten Sie f√ºr den zweiten Typ den √úbergang: ‚ÄûWenn der Feind sichtbar und der Feind zu stark ist, wechseln Sie in den Status Hilfe suchen.  Der Agent muss ausw√§hlen, wo er Hilfe anfordern m√∂chte, und diese Informationen speichern, damit der Status "Hilfe suchen" wei√ü, wohin er gehen soll.  Sobald Hilfe gefunden wird, kehrt der Agent in den Angriffszustand zur√ºck.  An diesem Punkt m√∂chte er den Verb√ºndeten √ºber die Bedrohung informieren, sodass die Aktion NotifyFriendOfThreat auftreten kann. <br><br>  Und wieder k√∂nnen wir dieses System durch das Prisma des Sense / Think / Act-Zyklus betrachten.  Sinn √ºbersetzt sich in Daten, die von der √úbergangslogik verwendet werden.  Think - √úberg√§nge in jedem Zustand verf√ºgbar.  Und Act wird durch Aktionen ausgef√ºhrt, die regelm√§√üig innerhalb des Staates oder bei √úberg√§ngen zwischen Staaten durchgef√ºhrt werden. <br><br>  Manchmal kann eine kontinuierliche Abfrage der √úbergangsbedingungen kostspielig sein.  Wenn beispielsweise jeder Agent komplexe Berechnungen f√ºr jeden Frame durchf√ºhrt, um festzustellen, ob er Feinde sieht, und um zu verstehen, ob es m√∂glich ist, vom patrouillierenden Status zum Angriff zu wechseln, nimmt dies viel Prozessorzeit in Anspruch. <br><br>  Wichtige √Ñnderungen im Zustand der Welt k√∂nnen als Ereignisse betrachtet werden, die verarbeitet werden, sobald sie auftreten.  Anstatt dass FSM die √úbergangsbedingung "Kann mein Agent den Player sehen?" √úberpr√ºft, k√∂nnen Sie in jedem Frame ein separates System konfigurieren, um √úberpr√ºfungen weniger h√§ufig durchzuf√ºhren (z. B. 5 Mal pro Sekunde).  Und das Ergebnis ist, Spieler gesehen zu geben, wenn der Scheck bestanden wird. <br><br>  Dies wird an die FSM √ºbergeben, die nun in die empfangene Bedingung "Spieler gesehen" wechseln und entsprechend reagieren muss.  Das resultierende Verhalten ist bis auf eine fast unmerkliche Verz√∂gerung vor der Beantwortung dasselbe.  Die Leistung wurde jedoch durch die Trennung eines Teils von Sense in einem separaten Teil des Programms verbessert. <br><br><h3>  Hierarchische endliche Zustandsmaschine </h3><br>  Das Arbeiten mit gro√üen FSMs ist jedoch nicht immer bequem.  Wenn wir den Status des Angriffs erweitern und durch separate Nahkampfangriffe (Nahkampf) und Fernkampfangriffe (Fernkampf) ersetzen m√∂chten, m√ºssen wir die √úberg√§nge von allen anderen Zust√§nden √§ndern, die zum Angriffsstatus f√ºhren (aktuell und zuk√ºnftig). <br><br>  Sicherlich haben Sie bemerkt, dass es in unserem Beispiel viele doppelte √úberg√§nge gibt.  Die meisten √úberg√§nge im Leerlauf sind identisch mit √úberg√§ngen im √úberwachungszustand.  Es w√§re sch√∂n, nicht zu wiederholen, besonders wenn wir weitere √§hnliche Zust√§nde hinzuf√ºgen.  Es ist sinnvoll, Leerlauf und Patrouillieren unter dem gemeinsamen Label ‚ÄûNichtkampf‚Äú zusammenzufassen, bei dem es nur einen gemeinsamen Satz von √úberg√§ngen zu Kampfstaaten gibt.  Wenn wir dieses Label als Status pr√§sentieren, werden Idling und Patrolling zu Unterzust√§nden.  Ein Beispiel f√ºr die Verwendung einer separaten Umrechnungstabelle f√ºr einen neuen Nichtkampf-Unterzustand: <br><br>  <i>Die Hauptbedingungen:</i> <br><img src="https://habrastorage.org/webt/jk/6j/u6/jk6ju6k3dtxhbou06sqelhixykm.png"><br><br>  <i>Status au√üerhalb des Kampfes:</i> <br><img src="https://habrastorage.org/webt/b4/yn/ae/b4ynaedk42xhvikbzqjsbh9itgc.png"><br><br>  Und in Diagrammform: <br><br><img src="https://habrastorage.org/webt/ni/li/dv/nilidvj4kqtrime1pgyzv11gh10.png"><br><br>  Dies ist das gleiche System, jedoch mit einem neuen Nichtkampfzustand, der Leerlauf und Patrouillieren umfasst.  Mit jedem Zustand, der FSMs mit Unterzust√§nden enth√§lt (und diese Unterzust√§nde enthalten wiederum ihre eigenen FSMs - und so weiter, so viel Sie ben√∂tigen), erhalten wir eine hierarchische endliche Zustandsmaschine oder HFSM (hierarchische Zustandsmaschine).  Nachdem wir einen Nichtkampfstaat gruppiert haben, haben wir eine Reihe redundanter √úberg√§nge herausgeschnitten.  Wir k√∂nnen dasselbe f√ºr alle neuen Staaten mit gemeinsamen √úberg√§ngen tun.  Wenn wir beispielsweise in Zukunft den Angriffszustand auf die Zust√§nde Nahkampfangriff und Raketenangriff ausweiten, handelt es sich um Unterzust√§nde, die sich je nach Entfernung zum Feind und Vorhandensein von Munition kreuzen.  Infolgedessen k√∂nnen komplexe Verhaltensmodelle und Untermodelle des Verhaltens mit einem Minimum an doppelten √úberg√§ngen dargestellt werden. <br><br><h3>   </h3><br>  HFSM      .   ,   ,            .        ,  .           .    ,    ,            . ,      25%,  ,      ,     ,    ‚Äî        .            25%  10%,     . <br><br>       ,    ¬´   ¬ª,     ,            .    . <br><br>     ,           :    ¬´¬ª ,     ,   ,  .     : <br><br><ul><li>       : Succeeded (  ), Failed (  )  Running (        ). </li><li>         .    Decorator,      .   Succeed,      . </li><li> ,  ,   Running    . </li></ul><br>             .  HFSM        : <br><br><img src="https://habrastorage.org/webt/1i/e5/4i/1ie54izd-h-ybfpwrb-yowau724.png"><br><br>           Idling/Patrolling   Attacking   .   ,    ,     Fleeing,   ,      ‚Äî Patrolling, Idling, Attacking   . <br><br><img src="https://habrastorage.org/webt/iw/je/uu/iwjeuuax51z5qxgmg5h4zcbm4tg.png"><br><br>    ‚Äî     ,            .     ,     ‚Äî         ,     ?   ,    ‚Äî  ,      Idling   10    ,      ,    ? <br><br>     . ,        .        ,        . <br><br><h3> Utility-based system </h3><br>       . ,          ,        .  ,         ,           . <br><br> Utility-based system (,   )     .  ,      ,      ,     .   ‚Äî   ,         . <br><br>         ,            .    FSM,   ,        ,  .  ,         ( ,    ).       ,      . <br><br>       ‚Äî ,  0 ( )  100 ( ).      ,     .      : <br><br><img src="https://habrastorage.org/webt/ty/an/id/tyanidrfvaoee_ekrdretfmyqhg.png"><br><br>     ‚Äî       .       .   ,    ,    ,   Fleeing,  FindingHelp    .   FindingHelp   .  ,       50,      .          . <br><br>         ,      .          . ,  Fleeing     ,    ,   Attacking   ,    . -   Fleeing    Attacking   ,   ,         .          ,        ,     FSM. <br><br>        .            .  The Sims,     ,     ‚Äî    ¬´¬ª,    .   ,        ,     EatFood     ,     ,   ,    EatFood  . <br><br>         ,  Utility-based system        ,      .             .  ,       Utility    ,  ,    . <br><br><h2>    </h2><br>       ,      ,  ,    .            ?    ,    ,     ,      ,     ?   . <br><br><h3>  Management </h3><br>     ,      ,    ,        .        ,   ,     . .   Sense/Think/Act,   ,   Think  ,   Act     .      ,      ,        .        ‚Äî ,     .  ,    ,          .   : <br><br> <i>desired_travel = destination_position ‚Äì agent_position</i> <br><br>  2D-.     (-2,-2),   -  -   (30, 20),     ,    ‚Äî (32, 22). ,      ‚Äî      5   ,            (4.12, 2.83).            8 . <br><br>      .       ,     ,       5 / (   ),   .      ,         . <br><br>      ‚Äî ,   ,   ,        .        .     steering behaviours,      : Seek (), Flee (), Arrival ()  . .    ,         ,           ,       . <br><br>      . Seek  Arrival ‚Äî       . Obstacle Avoidance ( )  Separation ()   ,       . Alignment ()  Cohesion ()     .    steering behaviours            . ,   Arrival, Separation  Obstacle Avoidance,        .          . <br><br>    ,      ‚Äî  ,      -  Arrival  Obstacle Avoidance.    ,  ,     .  :     ,          . <br><br>        ,    ,   -   . <br><br><h3>   </h3><br> Steering behaviours         (   ),       ‚Äî        .      pathfinding ( ),            . <br><br>   ‚Äî                .  -     ,           ,     .    .         ,          ( ,     ).  ,     Breadth-First Search  BFS (   ).         ( breadth, ¬´¬ª).      ,  ,      ‚Äî         ,       ,       . <br><br><img src="https://habrastorage.org/webt/ik/gg/_n/ikgg_n7oyigrgvo1av12jtsaga4.gif"><br><br>      ,     .     (, pathfinding) ‚Äî  ,   ,    . <br><br> ,        ,   steering behaviours,     ‚Äî   1   2,    2   3   .   ‚Äî     ,    ‚Äî         . -        . <br><br>   BFS    ‚Äî       ¬´¬ª ,   ¬´¬ª.        A* (A star).   ,     - (  ,       ),         ,      ,     .     ,     ‚Äî ¬´¬ª      (    )   ,        (    ). <br><br><img src="https://habrastorage.org/webt/3k/jb/al/3kjbal-iagj4ovxicix2swrbsxq.gif"><br><br>    ,        ,    ,    .    ,    BFS,        ‚Äî        . <br><br><h3>    </h3><br>  Aber die meisten Spiele sind nicht in der Startaufstellung angeordnet, und oft ist dies nicht m√∂glich, ohne den Realismus zu beeintr√§chtigen.  Kompromisse sind erforderlich.  Wie gro√ü sollten die Quadrate sein?  Zu gro√ü - und sie k√∂nnen sich kleine Korridore oder Kurven nicht richtig vorstellen, zu klein - es werden zu viele Quadrate gesucht, was am Ende viel Zeit in Anspruch nehmen wird. <br><br>  Das erste, was zu verstehen ist, ist, dass das Gitter uns ein Diagramm der verbundenen Knoten gibt.  Die A * - und BFS-Algorithmen arbeiten tats√§chlich mit Diagrammen und k√ºmmern sich √ºberhaupt nicht um unser Raster.  Wir k√∂nnten die Knoten √ºberall in der Spielwelt platzieren: Wenn eine Verbindung zwischen zwei verbundenen Knoten sowie zwischen dem Start- und Endpunkt und mindestens einem der Knoten besteht, funktioniert der Algorithmus genauso gut wie zuvor.  Dies wird oft als Wegpunktsystem bezeichnet, da jeder Knoten eine signifikante Position in der Welt darstellt, die Teil einer beliebigen Anzahl hypothetischer Pfade sein kann. <br><br><img src="https://habrastorage.org/webt/k7/ab/gq/k7abgqdwnx7efuqf8pqw0p6nbqm.png"><br>  <i>Beispiel 1: Ein Knoten in jedem Quadrat.</i>  <i>Die Suche beginnt an dem Knoten, an dem sich der Agent befindet, und endet am Knoten des gew√ºnschten Quadrats.</i> <br><br><img src="https://habrastorage.org/webt/m6/lx/5a/m6lx5a5wleqbvxthzcoajeat_us.png"><br>  <i>Beispiel 2: Ein kleinerer Satz von Knoten (Wegpunkten).</i>  <i>Die Suche beginnt im Quadrat mit dem Agenten, durchl√§uft die erforderliche Anzahl von Knoten und wird dann zum Ziel fortgesetzt.</i> <br><br>  Dies ist ein v√∂llig flexibles und leistungsstarkes System.  Bei der Entscheidung, wo und wie der Wegpunkt platziert werden soll, ist jedoch Vorsicht geboten. Andernfalls sehen die Agenten m√∂glicherweise nicht den n√§chstgelegenen Punkt und k√∂nnen den Pfad nicht starten.  Es w√§re einfacher, wenn wir automatisch Wegpunkte basierend auf der Geometrie der Welt festlegen k√∂nnten. <br><br>  Dann erscheint ein Navigationsnetz oder ein Navigationsnetz.  Dies ist normalerweise ein 2D-Netz aus Dreiecken, das die Geometrie der Welt √ºberlagert - √ºberall dort, wo der Agent gehen darf.  Jedes der Dreiecke im Raster wird zu einem Knoten im Diagramm und hat bis zu drei benachbarte Dreiecke, die zu benachbarten Knoten im Diagramm werden. <br><br>  Dieses Bild ist ein Beispiel aus der Unity-Engine - er analysierte die Geometrie in der Welt und erstellte ein Navmesh (hellblau im Screenshot).  Jedes Polygon in Navmesh ist ein Bereich, in dem ein Agent stehen oder sich von einem Polygon zu einem anderen Polygon bewegen kann.  In diesem Beispiel sind die Polygone kleiner als die B√∂den, auf denen sie sich befinden - hergestellt, um die Abmessungen des Agenten zu ber√ºcksichtigen, die √ºber seine nominelle Position hinausgehen. <br><br><img src="https://habrastorage.org/webt/-y/ip/ic/-yipico3akqxyv8hhubbe0rzkgk.png"><br><br>  Wir k√∂nnen die Route durch dieses Gitter erneut mit dem A * -Algorithmus suchen.  Dies gibt uns eine nahezu perfekte Route in der Welt, die die gesamte Geometrie ber√ºcksichtigt und keine zus√§tzlichen Knoten und Wegpunkte erfordert. <br><br>  Die Pfadfindung ist ein zu umfangreiches Thema, zu dem ein Abschnitt des Artikels nicht ausreicht.  Wenn Sie es genauer studieren m√∂chten, hilft Ihnen die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Website von Amit Patel</a> dabei. <br><br><h2>  Planung </h2><br>  Wir haben mit der Pfadfindung sichergestellt, dass es manchmal nicht ausreicht, nur eine Richtung zu w√§hlen und sich zu bewegen. Wir m√ºssen eine Route ausw√§hlen und mehrere Kurven fahren, um zum gew√ºnschten Ziel zu gelangen.  Wir k√∂nnen diese Idee zusammenfassen: Das Erreichen des Ziels ist nicht nur der n√§chste Schritt, sondern eine ganze Sequenz, in der Sie manchmal ein paar Schritte nach vorne schauen m√ºssen, um herauszufinden, was der erste sein sollte.  Dies nennt man Planung.  Die Pfadfindung kann als eine von mehreren Planungserg√§nzungen betrachtet werden.  Aus der Perspektive unseres Sense / Think / Act-Zyklus plant der Think-Teil hier mehrere Act-Teile f√ºr die Zukunft. <br><br>  Schauen wir uns das Beispiel des Brettspiels Magic: The Gathering an.  Wir gehen zuerst mit einem solchen Kartensatz zur Hand: <br><br><ul><li>  Sumpf - gibt 1 schwarzes Mana (Erdkarte). </li><li>  Wald - gibt 1 gr√ºnes Mana (Erdkarte). </li><li>  Fl√ºchtiger Zauberer - Ben√∂tigt 1 blaues Mana, um beschworen zu werden. </li><li>  Elfenmystiker - Ben√∂tigt 1 gr√ºnes Mana, um beschworen zu werden. </li></ul><br>  Wir ignorieren die restlichen drei Karten, um es einfacher zu machen.  Gem√§√ü den Regeln darf ein Spieler pro Spielzug 1 Landkarte spielen. Er kann auf diese Karte ‚Äûtippen‚Äú, um Mana daraus zu extrahieren, und dann Zauberspr√ºche (einschlie√ülich Beschw√∂rungskreaturen) entsprechend der Manamenge verwenden.  In dieser Situation wei√ü der menschliche Spieler, dass Sie Wald spielen, 1 gr√ºnes Mana ‚Äûtippen‚Äú und dann Elfenmystiker anrufen m√ºssen.  Aber wie erraten Sie die Spiel-KI? <br><br><h3>  Einfache Planung </h3><br>  Der triviale Ansatz besteht darin, jede Aktion der Reihe nach zu versuchen, bis es geeignete gibt.  Wenn die KI auf die Karten schaut, sieht sie, was Swamp spielen kann.  Und spielt es.  Gibt es in dieser Runde noch andere Aktionen?  Er kann weder Elfenmystiker noch fl√ºchtige Zauberer beschw√∂ren, da ihre Beschw√∂rung jeweils gr√ºnes und blaues Mana erfordert und Swamp nur schwarzes Mana gibt.  Und er wird nicht in der Lage sein, Forest zu spielen, weil er bereits Swamp gespielt hat.  Somit hielt sich die Spiel-KI an die Regeln, tat es aber schlecht.  Es kann verbessert werden. <br><br>  Die Planung kann eine Liste von Aktionen finden, die das Spiel in den gew√ºnschten Zustand bringen.  So wie jedes Feld auf dem Pfad Nachbarn hatte (bei der Pfadfindung), hat jede Aktion im Plan auch Nachbarn oder Nachfolger.  Wir k√∂nnen nach diesen Aktionen und nachfolgenden Aktionen suchen, bis wir den gew√ºnschten Zustand erreicht haben. <br><br>  In unserem Beispiel ist das gew√ºnschte Ergebnis "Beschw√∂re eine Kreatur, wenn m√∂glich".  Zu Beginn des Zuges sehen wir nur zwei m√∂gliche Aktionen, die nach den Spielregeln zul√§ssig sind: <br><br>  <i>1. Spielen Sie Swamp (Ergebnis: Swamp im Spiel)</i> <i><br></i>  <i>2. Spielen Sie Wald (Ergebnis: Wald im Spiel)</i> <br><br>  Jede Aktion kann je nach Spielregeln zu weiteren Aktionen f√ºhren und andere wieder schlie√üen.  Stellen Sie sich vor, wir haben Swamp gespielt - dies entfernt Swamp als n√§chsten Schritt (wir haben es bereits gespielt) und l√∂scht auch Forest (da Sie nach den Regeln eine Karte des Landes pro Spielzug spielen k√∂nnen).  Danach f√ºgt die KI als n√§chsten Schritt 1 schwarzes Mana hinzu, da es keine anderen Optionen gibt.  Wenn er weiter geht und Tap the Swamp w√§hlt, erh√§lt er 1 Einheit schwarzes Mana und kann nichts damit anfangen. <br><br>  <i>1. Spielen Sie Swamp (Ergebnis: Swamp im Spiel)</i> <i><br></i>  <i>1.1 Sumpf ‚Äûtippen‚Äú (Ergebnis: Sumpf ‚Äûtippen‚Äú, +1 Einheit schwarzes Mana)</i> <i><br></i>  <i>Keine Aktionen verf√ºgbar - ENDE</i> <i><br></i>  <i>2. Spielen Sie Wald (Ergebnis: Wald im Spiel)</i> <br><br>  Die Liste der Aktionen war kurz, wir sind in einer Sackgasse.  Wiederholen Sie den Vorgang f√ºr den n√§chsten Schritt.  Wir spielen Wald, er√∂ffnen die Aktion "Erhalte 1 gr√ºnes Mana", die wiederum die dritte Aktion er√∂ffnet - den Ruf des Elfenmystikers. <br><br>  <i>1. Spielen Sie Swamp (Ergebnis: Swamp im Spiel)</i> <i><br></i>  <i>1.1 Sumpf ‚Äûtippen‚Äú (Ergebnis: Sumpf ‚Äûtippen‚Äú, +1 Einheit schwarzes Mana)</i> <i><br></i>  <i>Keine Aktionen verf√ºgbar - ENDE</i> <i><br></i>  <i>2. Spielen Sie Wald (Ergebnis: Wald im Spiel)</i> <i><br></i>  <i>2.1 Wald ‚Äûtippen‚Äú (Ergebnis: Wald ‚Äûtippen‚Äú, +1 gr√ºne Manaeinheit)</i> <i><br></i>  <i>2.1.1 Elfenmystiker beschw√∂ren (Ergebnis: Elfenmystiker im Spiel, -1 Einheit gr√ºnes Mana)</i> <i><br></i>  <i>Keine Aktionen verf√ºgbar - ENDE</i> <br><br>  Schlie√ülich untersuchten wir alle m√∂glichen Aktionen und fanden einen Plan, der die Kreatur anrief. <br><br>  Dies ist ein sehr vereinfachtes Beispiel.  Es ist ratsam, den bestm√∂glichen Plan zu w√§hlen, und keinen, der bestimmte Kriterien erf√ºllt.  In der Regel k√∂nnen Sie potenzielle Pl√§ne anhand des Endergebnisses oder des Gesamtnutzens ihrer Implementierung bewerten.  Sie k√∂nnen sich 1 Punkt hinzuf√ºgen, um eine Karte der Erde zu spielen, und 3 Punkte, um eine Kreatur herauszufordern.  Swamp zu spielen w√§re ein Plan, der 1 Punkt gibt.  Und um Wald zu spielen ‚Üí Tippe auf den Wald ‚Üí rufe Elfenmystiker an - er gibt sofort 4 Punkte. <br><br>  So funktioniert Planung in Magic: The Gathering, aber nach der gleichen Logik gilt sie auch in anderen Situationen.  Bewegen Sie zum Beispiel einen Bauern, um Platz f√ºr den Bischof zu schaffen, damit er sich im Schach bewegen kann.  Oder gehen Sie hinter einer Wand in Deckung, um sicher auf XCOM zu schie√üen.  Im Allgemeinen verstehen Sie den Punkt. <br><br><h3>  Verbesserte Planung </h3><br>  Manchmal gibt es zu viele m√∂gliche Ma√ünahmen, um jede m√∂gliche Option in Betracht zu ziehen.  Zur√ºck zum Beispiel mit Magic: The Gathering: Nehmen wir an, im Spiel und auf Ihren H√§nden befinden sich mehrere Karten mit Land und Kreaturen - die Anzahl der m√∂glichen Kombinationen von Z√ºgen kann im Zehnerbereich liegen.  Es gibt verschiedene L√∂sungen f√ºr das Problem. <br><br>  Der erste Weg ist die R√ºckw√§rtsverkettung.  Anstatt alle Kombinationen zu sortieren, ist es besser, mit dem Endergebnis zu beginnen und einen direkten Weg zu finden.  Anstelle des Weges von der Wurzel des Baumes zu einem bestimmten Blatt bewegen wir uns in die entgegengesetzte Richtung - vom Blatt zur Wurzel.  Diese Methode ist einfacher und schneller. <br><br>  Wenn der Gegner 1 Gesundheitseinheit hat, k√∂nnen Sie einen Plan finden, um "1 oder mehr Schadenseinheiten zuzuf√ºgen".  Um dies zu erreichen, m√ºssen eine Reihe von Bedingungen erf√ºllt sein: <br><br>  1. Schaden kann durch einen Zauber verursacht werden - er sollte in der Hand liegen. <br>  2. Um einen Zauber wirken zu k√∂nnen, brauchst du Mana. <br>  3. Um Mana zu erhalten, musst du eine Landkarte spielen. <br>  4. Um eine Karte der Erde zu spielen, m√ºssen Sie sie in der Hand haben. <br><br>  Ein anderer Weg ist die Best-First-Suche.  Anstatt alle Wege zu gehen, w√§hlen wir den am besten geeigneten.  Meistens liefert diese Methode einen optimalen Plan ohne unn√∂tige Suchkosten.  A * ist die Form der besten ersten Suche - er erkundet von Anfang an die vielversprechendsten Routen und kann bereits den besten Weg finden, ohne andere Optionen pr√ºfen zu m√ºssen. <br><br>  Eine interessante und immer beliebter werdende Option f√ºr die Best-First-Suche ist die Monte-Carlo-Baumsuche.  Anstatt zu erraten, welche Pl√§ne bei der Auswahl jeder nachfolgenden Aktion besser sind als andere, w√§hlt der Algorithmus bei jedem Schritt zuf√§llige Nachfolger aus, bis das Ende erreicht ist (als der Plan zum Sieg oder zur Niederlage f√ºhrte).  Das Endergebnis wird dann verwendet, um die Gewichtsbewertung der vorherigen Optionen zu erh√∂hen oder zu verringern.  Der Algorithmus wiederholt diesen Vorgang mehrmals hintereinander und gibt eine gute Sch√§tzung, welcher n√§chste Schritt besser ist, selbst wenn sich die Situation √§ndert (wenn der Gegner Ma√ünahmen ergreift, um den Spieler zu verhindern). <br><br>  Die Geschichte √ºber die Planung in Spielen wird nicht ohne zielorientierte Aktionsplanung oder GOAP (zielorientierte Aktionsplanung) auskommen.  Dies ist eine weit verbreitete und diskutierte Methode, aber abgesehen von einigen charakteristischen Details handelt es sich im Wesentlichen um die R√ºckw√§rtsverkettungsmethode, √ºber die wir zuvor gesprochen haben.  Wenn die Aufgabe darin bestand, ‚Äûden Spieler zu zerst√∂ren‚Äú und der Spieler sich in Deckung befindet, k√∂nnte der Plan folgender sein: Zerst√∂re mit einer Granate ‚Üí hol sie dir ‚Üí lass sie fallen. <br><br>  Normalerweise gibt es mehrere Ziele, von denen jedes seine eigene Priorit√§t hat.  Wenn das Ziel mit der h√∂chsten Priorit√§t nicht erreicht werden kann (keine Kombination von Aktionen erstellt einen Plan zur ‚ÄûZerst√∂rung des Spielers‚Äú, da der Spieler nicht sichtbar ist), kehrt die KI zu Zielen mit einer niedrigeren Priorit√§t zur√ºck. <br><br><h2>  Training und Anpassung </h2><br>  Wir haben bereits gesagt, dass die Gaming-KI normalerweise kein maschinelles Lernen verwendet, da sie nicht f√ºr die Verwaltung von Agenten in Echtzeit geeignet ist.  Dies bedeutet jedoch nicht, dass Sie nichts aus diesem Bereich ausleihen k√∂nnen.  Wir wollen einen solchen Gegner in einem Sch√ºtzen, von dem wir etwas lernen k√∂nnen.  Informieren Sie sich beispielsweise √ºber die besten Positionen auf der Karte.  Oder ein Gegner in einem Kampfspiel, der h√§ufig verwendete Combo-Tricks des Spielers blockiert und andere zum Einsatz motiviert.  Daher kann maschinelles Lernen in solchen Situationen sehr n√ºtzlich sein. <br><br><h3>  Statistiken und Wahrscheinlichkeiten </h3><br>  Bevor wir zu komplexen Beispielen √ºbergehen, werden wir absch√§tzen, wie weit wir gehen k√∂nnen, indem wir einige einfache Messungen vornehmen und sie verwenden, um Entscheidungen zu treffen.  Zum Beispiel eine Echtzeitstrategie - wie k√∂nnen wir bestimmen, ob ein Spieler in den ersten Minuten eines Spiels einen Angriff starten kann und welche Verteidigung dagegen vorbereitet werden muss?  Wir k√∂nnen die Erfahrungen des Spielers in der Vergangenheit studieren, um zu verstehen, wie die zuk√ºnftige Reaktion aussehen k√∂nnte.  Zun√§chst haben wir keine solchen Anfangsdaten, aber wir k√∂nnen sie sammeln. Jedes Mal, wenn die KI gegen eine Person spielt, kann sie den Zeitpunkt des ersten Angriffs aufzeichnen.  Nach mehreren Sitzungen erhalten wir die durchschnittliche Zeit, in der der Spieler in Zukunft angreifen wird. <br><br>  Die Durchschnittswerte haben ein Problem: Wenn ein Spieler 20 Mal ‚Äûentscheidet‚Äú und 20 Mal langsam spielt, liegen die erforderlichen Werte irgendwo in der Mitte, und dies gibt uns nichts N√ºtzliches.  Eine L√∂sung besteht darin, die Eingabe zu begrenzen - Sie k√∂nnen die letzten 20 Teile ber√ºcksichtigen. <br><br>  Ein √§hnlicher Ansatz wird verwendet, um die Wahrscheinlichkeit bestimmter Aktionen zu bewerten, vorausgesetzt, dass die fr√ºheren Pr√§ferenzen des Spielers in Zukunft dieselben sein werden.  Wenn ein Spieler uns f√ºnfmal mit einem Feuerball angreift, zweimal mit einem Blitz und einmal mit einem Nahkampf, ist es offensichtlich, dass er einen Feuerball bevorzugt.  Wir extrapolieren und sehen die Wahrscheinlichkeit des Einsatzes verschiedener Waffen: Feuerball = 62,5%, Blitz = 25% und Nahkampf = 12,5%.  Unsere Spiel-KI muss sich auf den Brandschutz vorbereiten. <br><br>  Eine weitere interessante Methode ist die Verwendung des Naive Bayes-Klassifikators (naiver Bayes-Klassifikator), um gro√üe Mengen von Eingabedaten zu untersuchen und die Situation so zu klassifizieren, dass die KI richtig reagiert.  Bayesianische Klassifikatoren sind am besten f√ºr die Verwendung von E-Mail-Spam-Filtern bekannt.  Dort recherchieren sie W√∂rter, vergleichen sie mit der Stelle, an der diese W√∂rter fr√ºher erschienen (in Spam oder nicht), und ziehen Schlussfolgerungen √ºber eingehende Briefe.  Wir k√∂nnen dasselbe auch mit weniger Input tun.  Auf der Grundlage aller n√ºtzlichen Informationen, die die KI sieht (zum Beispiel, welche feindlichen Einheiten erstellt werden, welche Zauber sie verwenden oder welche Technologien sie erforscht haben) und dem Endergebnis (Krieg oder Frieden, ‚ÄûQuetschen‚Äú oder Verteidigen usw.) - Wir werden das gew√ºnschte KI-Verhalten ausw√§hlen. <br><br>  Alle diese Trainingsmethoden sind ausreichend, es ist jedoch ratsam, sie auf der Grundlage von Testdaten zu verwenden.  AI lernt, sich an die verschiedenen Strategien anzupassen, die Ihre Spieletester angewendet haben.  Eine KI, die sich nach einer Ver√∂ffentlichung an einen Spieler anpasst, kann zu vorhersehbar oder umgekehrt zu komplex werden, um zu gewinnen. <br><br><h3>  Wertbasierte Anpassung </h3><br>  Angesichts des Inhalts unserer Spielwelt und der Regeln k√∂nnen wir die Werte √§ndern, die sich auf die Entscheidungsfindung auswirken, und nicht nur die Eingabedaten verwenden.  Wir machen das: <br><br><ul><li>  Lassen Sie die KI Daten √ºber den Zustand der Welt und wichtige Ereignisse w√§hrend des Spiels sammeln (wie oben angegeben). </li><li>  Lassen Sie uns einige wichtige Werte basierend auf diesen Daten √§ndern. </li><li>  Wir realisieren unsere Entscheidungen auf der Grundlage der Verarbeitung oder Bewertung dieser Werte. </li></ul><br>  Ein Agent verf√ºgt beispielsweise √ºber mehrere R√§ume, in denen er einen Ego-Shooter auf der Karte ausw√§hlen kann.  Jedes Zimmer hat seinen eigenen Wert, der bestimmt, wie w√ºnschenswert ein Besuch ist.  Die KI w√§hlt zuf√§llig anhand des Wertes den Raum aus.  Dann merkt sich der Agent, in welchem ‚Äã‚ÄãRaum er get√∂tet wurde, und verringert seinen Wert (die Wahrscheinlichkeit, dass er dorthin zur√ºckkehrt).  √Ñhnliches gilt f√ºr die umgekehrte Situation: Wenn der Agent viele Gegner zerst√∂rt, erh√∂ht sich der Wert des Raums. <br><br><h3>  Markov-Modell </h3><br>  Was ist, wenn wir die gesammelten Daten f√ºr Prognosen verwenden?  Wenn wir uns f√ºr einen bestimmten Zeitraum an jeden Raum erinnern, in dem wir den Spieler sehen, werden wir vorhersagen, in welchen Raum der Spieler gehen kann.  Indem wir die Bewegung des Spielers in den R√§umen (Werte) verfolgen und aufzeichnen, k√∂nnen wir sie vorhersagen. <br><br>  Nehmen wir drei R√§ume: rot, gr√ºn und blau.  Sowie die Beobachtungen, die wir beim Anschauen einer Spielsitzung aufgezeichnet haben: <br><br><img src="https://habrastorage.org/webt/cz/qm/-k/czqm-khdlmnybf2c4amu6v_yrc0.png"><br><br>  Die Anzahl der Beobachtungen f√ºr jeden Raum ist fast gleich - wir wissen immer noch nicht, wo wir einen guten Platz f√ºr einen Hinterhalt finden sollen.  Das Sammeln von Statistiken wird auch durch das Respawn von Spielern erschwert, die gleichm√§√üig auf der Karte erscheinen.  Die Daten im n√§chsten Raum, die sie nach dem Erscheinen auf der Karte eingeben, sind jedoch bereits n√ºtzlich. <br><br>  Es ist zu sehen, dass der gr√ºne Raum zu den Spielern passt - die meisten Leute von Rot gehen dorthin, 50% davon bleiben dort und weiter.  Das blaue Zimmer ist im Gegenteil nicht beliebt, es wird fast nie besucht, und wenn ja, verweilt es nicht. <br><br>  Aber die Daten sagen uns etwas Wichtigeres - wenn sich der Spieler im blauen Raum befindet, ist der n√§chste Raum, in dem wir ihn h√∂chstwahrscheinlich sehen werden, rot und nicht gr√ºn.  Trotz der Tatsache, dass der gr√ºne Raum beliebter ist als der rote, √§ndert sich die Situation, wenn der Spieler blau ist.  Der n√§chste Zustand (d. H. Der Raum, in den der Spieler gehen wird) h√§ngt vom vorherigen Zustand ab (d. H. Dem Raum, in dem sich der Spieler gerade befindet).  Aufgrund der Untersuchung von Abh√§ngigkeiten werden wir Prognosen genauer erstellen, als wenn wir die Beobachtungen einfach unabh√§ngig voneinander berechnen w√ºrden. <br><br>  Die Vorhersage eines zuk√ºnftigen Zustands auf der Grundlage vergangener Zustandsdaten wird als Markov-Modell bezeichnet, und solche Beispiele (mit R√§umen) werden als Markov-Ketten bezeichnet.  Da die Modelle die Wahrscheinlichkeit von √Ñnderungen zwischen aufeinanderfolgenden Zust√§nden darstellen, werden sie visuell als FSMs mit einer Wahrscheinlichkeit in der N√§he jedes √úbergangs angezeigt.  Fr√ºher haben wir FSM verwendet, um den Verhaltensstatus darzustellen, in dem sich der Agent befand. Dieses Konzept gilt jedoch f√ºr jeden Status, unabh√§ngig davon, ob er mit dem Agenten zusammenh√§ngt oder nicht.  In diesem Fall stellen die Zust√§nde den vom Agenten belegten Raum dar: <br><br><img src="https://habrastorage.org/webt/xj/jn/zn/xjjnznthergzfs89ixqdghp7bjq.png"><br><br>  Dies ist eine einfache Version der Darstellung der relativen Wahrscheinlichkeit von Zustands√§nderungen, die der KI die M√∂glichkeit gibt, den n√§chsten Zustand vorherzusagen.  Sie k√∂nnen einige Schritte vorw√§rts vorhersagen. <br><br>  Befindet sich der Spieler im gr√ºnen Raum, besteht eine 50% ige Chance, dass er bei der n√§chsten Beobachtung dort bleibt.  Aber wie hoch ist die Wahrscheinlichkeit, dass er auch danach noch da sein wird?  Es besteht nicht nur die M√∂glichkeit, dass der Spieler nach zwei Beobachtungen im gr√ºnen Raum blieb, sondern auch die M√∂glichkeit, dass er gegangen ist und zur√ºckgekehrt ist.  Hier ist die neue Tabelle mit den neuen Daten: <br><br><img src="https://habrastorage.org/webt/te/wc/ya/tewcyajzsv_ys-9bro4mjdhtpte.png"><br><br>  Es zeigt, dass die Chance, einen Spieler nach zwei Beobachtungen im gr√ºnen Raum zu sehen, 51% - 21% betr√§gt, dass er aus dem roten Raum kommt, 5% von ihnen, dass der Spieler den blauen Raum zwischen ihnen besucht und 25%, dass der Spieler dies nicht tut wird das gr√ºne Zimmer verlassen. <br><br>  Eine Tabelle ist nur ein visuelles Werkzeug - eine Prozedur erfordert nur eine Multiplikation der Wahrscheinlichkeiten bei jedem Schritt.  Dies bedeutet, dass Sie mit einer √Ñnderung weit in die Zukunft blicken k√∂nnen: Wir gehen davon aus, dass die M√∂glichkeit, einen Raum zu betreten, vollst√§ndig vom aktuellen Raum abh√§ngt.  Dies wird als Markov-Eigenschaft bezeichnet - der zuk√ºnftige Zustand h√§ngt nur von der Gegenwart ab.  Dies ist jedoch nicht ganz richtig.  Spieler k√∂nnen Entscheidungen in Abh√§ngigkeit von anderen Faktoren treffen: Gesundheitszustand oder Munitionsmenge.  Da wir diese Werte nicht festlegen, sind unsere Prognosen weniger genau. <br><br><h3>  N-Gramm </h3><br>         - ?  Das selbe!      ,     ,    -. <br><br>      ‚Äî    (, Kick, Punch  Block)         . ,    Kick, Kick, Punch,    SuperDeathFist,           ,    . <br><br><img src="https://habrastorage.org/webt/2m/ji/l4/2mjil4fdhjrro3em8vde-zcxhak.png"><br> (  ,     SuperDeathFist.) <br><br>    ,    Kick,    Kick,   ,     Punch.     - SuperDeathFist   ,   . <br><br>     N- (N-grams),  N ‚Äî   .      3- (),  :       .   5-        . <br><br>      N-.   N   ,     . , 2- ()   Kick, Kick  Kick, Punch,     Kick, Kick, Punch,       SuperDeathFist. <br><br>   ,          ,       .        Kick, Punch  Block,    10-,    60   . <br><br>       ‚Äî   ¬´ / ¬ª  ,         . 3-    N-      ,    (   N-)    ,    ‚Äî .         Kick  Kick   Kick  Punch.        , ,  ,       .     ,          ,  -  . <br><br><h2>  Fazit </h2><br>            .    ,          . <br><br>           . ,  ,     .   ,     : <br><br><ul><li>   ,    ,      </li><li>   / (minimax  alpha-beta pruning) </li><li>   (,      ) </li><li>        </li><li>     ( ,        ) </li><li>   (   ) </li><li>   ( ,  anytime,  timeslicing) </li></ul><br> -  : <br><br> 1.  GameDev.net  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">      </a> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> . <br> 2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AiGameDev.com</a>             . <br> 3. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">The GDC Vault</a>       GDC AI,     . <br> 4.        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Game Programmers Guild</a> . <br> 5.  ,     ,    YouTube- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI and Games</a>        . <br><br>   : <br><br> 1.   Game AI Pro     , ,         . <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=http://go.gamedev.net/%3Fid%3D13722X707581%26xs%3D1%26isjs%3D1%26url%3Dhttps%253A%252F%252Famzn.to%252F2KGoB8n%26xguid%3Df8ad586e5984991508efff4754027dbd%26xuuid%3D305451ecead59d76ca830fded0aab276%26xsessid%3D6ccb8b9fa3f10b478b65f7ed703a447b%26xcreo%3D0%26xed%3D0%26sref%3Dhttps%253A%252F%252Fwww.gamedev.net%252Farticles%252Fprogramming%252Fartificial-intelligence%252Fthe-total-beginners-guide-to-game-ai-r4942%252F%253Fdo%253Dedit%2526d%253D1%2526id%253D4942%2526csrfKey%253D7015c6d2c5c643e87baa74f8e5d2c094%26pref%3D">Game AI Pro: Collected Wisdom of Game AI Professionals</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=http://go.gamedev.net/%3Fid%3D13722X707581%26xs%3D1%26isjs%3D1%26url%3Dhttps%253A%252F%252Famzn.to%252F2KFKyoe%26xguid%3Df8ad586e5984991508efff4754027dbd%26xuuid%3D305451ecead59d76ca830fded0aab276%26xsessid%3D6ccb8b9fa3f10b478b65f7ed703a447b%26xcreo%3D0%26xed%3D0%26sref%3Dhttps%253A%252F%252Fwww.gamedev.net%252Farticles%252Fprogramming%252Fartificial-intelligence%252Fthe-total-beginners-guide-to-game-ai-r4942%252F%253Fdo%253Dedit%2526d%253D1%2526id%253D4942%2526csrfKey%253D7015c6d2c5c643e87baa74f8e5d2c094%26pref%3D">Game AI Pro 2: Collected Wisdom of Game AI Professionals</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Game AI Pro 3: Collected Wisdom of Game AI Professionals</a> <br><br> 2.  AI Game Programming Wisdom ‚Äî   Game AI Pro.     ,      . <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Game Programming Wisdom 1</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Game Programming Wisdom 2</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Game Programming Wisdom 3</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Game Programming Wisdom 4</a> <br><br> 3. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artificial Intelligence: A Modern Approach</a> ‚Äî              .       ‚Äî     . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428892/">https://habr.com/ru/post/de428892/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428878/index.html">Schweineflug oder Optimierung von Bytecode-Interpreten</a></li>
<li><a href="../de428880/index.html">Neue Authentifizierungsmethoden - eine Bedrohung f√ºr die Privatsph√§re?</a></li>
<li><a href="../de428882/index.html">Mobile Yandex. Blitz: Wir analysieren Aufgaben</a></li>
<li><a href="../de428888/index.html">qml: Kraft und Einfachheit</a></li>
<li><a href="../de428890/index.html">Die ganze Wahrheit √ºber RTOS. Artikel Nr. 18. Ereignisflag-Gruppen: Hilfsdienste und Datenstrukturen</a></li>
<li><a href="../de428894/index.html">Mehrwertsteuer auf inl√§ndische Eink√§ufe</a></li>
<li><a href="../de428896/index.html">Neuronale Netze der Hentai-Zensur</a></li>
<li><a href="../de428898/index.html">Problematische Aspekte der Programmierung in C ++</a></li>
<li><a href="../de428900/index.html">Radroboter liefern Waren an Einwohner der USA und Gro√übritanniens</a></li>
<li><a href="../de428902/index.html">NFC Wireless Tags</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
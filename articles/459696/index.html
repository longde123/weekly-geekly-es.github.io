<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游뚴 游녣游낗 游 Restauraci칩n de fotos basada en IA 游녢游낖 游꿅 游뗶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos! Soy ingeniero de investigaci칩n en el equipo de visi칩n por computadora del Grupo Mail.ru. En este art칤culo, voy a contar una historia de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Restauraci칩n de fotos basada en IA</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/459696/"><img src="https://habrastorage.org/webt/ya/mt/mm/yamtmmcino7skf3gyqzpsrgqla4.jpeg"><br><br>  Hola a todos!  Soy ingeniero de investigaci칩n en el equipo de visi칩n por computadora del Grupo Mail.ru.  En este art칤culo, voy a contar una historia de c칩mo hemos creado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un proyecto de restauraci칩n de fotos basado en IA</a> para viejas fotos militares.  쯈u칠 es la "restauraci칩n de fotos"?  Consta de tres pasos: <br><br><ul><li>  encontramos todos los defectos de la imagen: fracturas, rasgu침os, agujeros; <br></li><li>  pintamos los defectos descubiertos, en funci칩n de los valores de p칤xeles a su alrededor; <br></li><li>  Coloramos la imagen. <br></li></ul><br>  Adem치s, describir칠 cada paso de la restauraci칩n de fotos y le dir칠 c칩mo obtuvimos nuestros datos, qu칠 redes capacitamos, qu칠 logramos y qu칠 errores cometimos. <br><a name="habracut"></a><br><h1>  Buscando defectos </h1><br>  Queremos encontrar todos los p칤xeles relacionados con defectos en una foto cargada.  Primero, tenemos que averiguar qu칠 tipo de im치genes subir치n las personas.  Hablamos con los fundadores del proyecto "Regimiento inmortal", una organizaci칩n no comercial que almacena las fotos heredadas de la Segunda Guerra Mundial, quienes compartieron sus datos con nosotros.  Al analizarlo, notamos que las personas cargan principalmente retratos individuales o grupales con una cantidad moderada a gran cantidad de defectos. <br><br>  Luego tuvimos que recoger un conjunto de entrenamiento.  El conjunto de entrenamiento para una tarea de segmentaci칩n es una imagen y una m치scara donde se marcan todos los defectos.  La forma m치s f치cil de hacerlo es dejar que los asesores creen las m치scaras de segmentaci칩n.  Por supuesto, la gente sabe muy bien c칩mo encontrar defectos, pero eso llevar칤a demasiado tiempo. <br><br><img src="https://habrastorage.org/webt/yg/6y/iu/yg6yiue75v7msnxyffapttyugs8.jpeg"><br><br>  Puede tomar una hora o todo el d칤a laboral marcar los p칤xeles defectuosos en una foto.  Por lo tanto, no es f치cil recopilar un conjunto de entrenamiento de m치s de 100 im치genes en unas pocas semanas.  Es por eso que tratamos de aumentar nuestros datos y crear nuestros propios defectos: tomamos una buena foto, agregamos defectos usando recorridos aleatorios en la imagen y terminamos con una m치scara que muestra las partes de la imagen con los defectos.  Sin aumentos, tenemos 68 fotos etiquetadas manualmente en el conjunto de entrenamiento y 11 fotos en el conjunto de validaci칩n. <br><br>  El enfoque de segmentaci칩n m치s popular: tome Unet con codificador pre-entrenado y minimice la suma de BCE ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">entrop칤a cruzada binaria</a> ) y DICE ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">coeficiente de S칮rensen - Dice</a> ). <br><br>  쯈u칠 problemas surgen cuando usamos este enfoque de segmentaci칩n para nuestra tarea? <br><br><ul><li>  Incluso si parece que hay toneladas de defectos en la foto, que es muy vieja y en mal estado, el 치rea con defectos es mucho m치s peque침a que la que no est치 da침ada.  Para resolver este problema, podemos aumentar el peso positivo de la clase en BCE;  un peso 칩ptimo ser칤a la proporci칩n de p칤xeles limpios a los defectuosos. <br></li><li>  El segundo problema es que si usamos un Unet listo para usar con codificador pre-entrenado (Albunet-18, por ejemplo), perdemos muchos datos posicionales.  La primera capa de Albunet-18 consiste en una convoluci칩n con un n칰cleo 5 y una zancada que equivale a dos.  Permite que la red funcione r치pido.  Cambiamos el tiempo de operaci칩n neto para tener una mejor localizaci칩n de defectos: eliminamos la agrupaci칩n m치xima despu칠s de la primera capa, disminuimos el paso a 1 y disminuimos el n칰cleo de convoluci칩n a 3. <br></li><li>  Si trabajamos con im치genes peque침as comprimi칠ndolas, por ejemplo, a 256 x 256 o 512 x 512 p칤xeles, los peque침os defectos desaparecer치n debido a la interpolaci칩n.  Por lo tanto, necesitamos trabajar con im치genes m치s grandes.  Actualmente estamos segmentando defectos en fotos de 1024 x 1024 en producci칩n.  Es por eso que tuvimos que entrenar la red en cultivos de gran imagen.  Sin embargo, esto causa problemas con un tama침o de lote peque침o en una sola GPU. <br></li><li> Durante el entrenamiento, podemos colocar unas 20 im치genes en una GPU.  Debido a eso, terminamos con valores de desviaci칩n est치ndar y media inexactos en las capas BatchNorm.  Podemos resolver este problema utilizando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">In-place BatchNorm</a> , que, por un lado, ahorra espacio en la memoria y, por otro lado, tiene una versi칩n BatchNorm sincronizada, que sincroniza las estad칤sticas en todas las GPU.  Ahora calculamos los valores de la media y la desviaci칩n est치ndar no para 20 im치genes en una sola GPU, sino para 80 im치genes de 4 GPU.  Esto mejora la convergencia neta. <br></li></ul><br>  Finalmente, al aumentar el peso de BCE, cambiar la arquitectura y usar In-place BatchNorm, mejoramos la segmentaci칩n.  Sin embargo, no costar칤a demasiado hacer algo a칰n mejor agregando Test Time Augmentation.  Podemos ejecutar la red una vez en una imagen de entrada, luego reflejarla y volver a ejecutar la red para encontrar todos los peque침os defectos. <br><br><img src="https://habrastorage.org/webt/3c/vj/g0/3cvjg04qc_nqsl8lop44jvtjfym.jpeg"><br><br>  La red converge en 18 horas en cuatro GeForce 1080Ti.  La inferencia toma 290 ms.  Es bastante largo, pero ese es el precio de nuestro rendimiento mejor que el predeterminado.  Validaci칩n DICE es igual a 0,35 y ROCAUC - 0,93. <br><br><h1>  Inpainting de imagen </h1><br>  Lo mismo con la tarea de segmentaci칩n que usamos Unet.  Para pintar, cargar칤amos una imagen original y una m치scara donde marcamos toda el 치rea limpia con unos y con ceros, todos los p칤xeles que queremos pintar.  As칤 es como est치bamos recopilando datos: para cualquier foto de un conjunto de datos de imagen de c칩digo abierto, por ejemplo, OpenImagesV4, agregamos los defectos similares a los que vemos en la vida real.  Luego hab칤amos entrenado la red para restaurar las partes faltantes. <br><br>  쮺칩mo podemos modificar Unet para esta tarea? <br><br>  Podemos usar convoluci칩n parcial en lugar de una original.  La idea es que cuando envolvemos un 치rea con algo de kernel, no tomamos en cuenta los valores de p칤xeles defectuosos.  Esto hace que la pintura sea m치s precisa.  Le mostramos un ejemplo del reciente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documento de NVIDIA</a> .  Usaron Unet con una convoluci칩n bidimensional predeterminada en la imagen del medio y una convoluci칩n parcial, en la imagen de la derecha. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ec1/5ba/bdb/ec15babdbf1cd219be4a5e3ffa4ae50f.jpg"><br><br>  Entrenamos la red durante cinco d칤as.  El 칰ltimo d칤a, congelamos BatchNorms para que los bordes de la parte pintada sean menos visibles. <br><br>  La red tarda 50 ms en procesar una imagen de 512 x 512.  Validaci칩n PSNR es igual a 26.4.  Sin embargo, no puede confiar totalmente en las m칠tricas en esta tarea.  Para elegir el mejor modelo, ejecutamos varios buenos modelos en im치genes de valoraci칩n, anonimizamos los resultados y luego votamos por los que m치s nos gustaron.  As칤 es como elegimos nuestro modelo final. <br><br>  Mencion칠 anteriormente que agregamos artificialmente algunos defectos a las im치genes limpias.  Siempre debe realizar un seguimiento del tama침o m치ximo de defectos a침adidos durante el entrenamiento;  en el caso de que alimente una imagen con un defecto muy grande en la red que nunca se trata en la etapa de entrenamiento, la red se volver치 loca y producir치 un resultado inaplicable.  Por lo tanto, si necesita reparar defectos grandes, aumente su conjunto de entrenamiento con ellos. <br><br>  Aqu칤 est치 el ejemplo de c칩mo funciona nuestro algoritmo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c48/2cd/253/c482cd253865ee12a834475a2e30d619.jpg"><br><br><h1>  Coloraci칩n </h1><br>  Segmentamos los defectos y los pintamos;  El tercer paso: la reconstrucci칩n del color.  Como dije antes, hay muchos retratos individuales y grupales entre las fotos del Regimiento Inmortal.  Quer칤amos que nuestra red funcionara bien con ellos.  Decidimos crear nuestra propia coloraci칩n ya que ninguno de los servicios existentes pod칤a colorear los retratos de forma r치pida y eficiente.  Queremos que nuestras fotos coloreadas sean m치s cre칤bles. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cec/b9a/b6c/cecb9ab6c8e1b76b567f49eac1261957.jpg"><br><br>  GitHub tiene un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">repositorio</a> popular para la coloraci칩n de fotos.  Hace un buen trabajo pero a칰n tiene algunos problemas.  Por ejemplo, tiende a pintar la ropa de azul.  Por eso lo rechazamos tambi칠n. <br><br>  Entonces, decidimos crear un algoritmo para la coloraci칩n de la imagen.  La idea m치s obvia: tomar una imagen en blanco y negro y predecir tres canales: rojo, verde y azul.  Sin embargo, podemos facilitar nuestro trabajo: no trabaje con la representaci칩n de color RGB, sino con la representaci칩n de color YCbCr.  El componente Y es brillo (luma).  Una imagen cargada en blanco y negro es el canal Y, y la vamos a reutilizar.  Ahora tenemos que predecir Cb y Cr: Cb es la diferencia de color azul y brillo y Cr, la diferencia de color rojo y brillo. <br><br><img src="https://habrastorage.org/webt/yo/au/zi/yoauzi06k3bd0uyod2rjnpxgvms.jpeg"><br><br>  쯇or qu칠 elegimos la representaci칩n de YCbCr?  Un ojo humano es m치s sensible a los cambios de brillo que a los cambios de color.  Es por eso que reutilizamos el componente Y (brillo) al cual el ojo humano es m치s sensible y predecimos Cb y Cr con los que podr칤amos cometer un error, ya que no podemos notar muy bien la falsedad del color.  Esta caracter칤stica espec칤fica fue ampliamente utilizada en los albores de la televisi칩n en color cuando la capacidad del canal no era suficiente para transmitir todos los colores.  La imagen se transmiti칩 en YCbCr, sin cambios al componente Y, y Cb y Cr se redujeron a la mitad. <br><br><h1>  C칩mo crear una l칤nea base </h1><br>  Podemos tomar Unet con un codificador previamente entrenado y minimizar la p칠rdida de L1 entre los valores de CbCr existentes y los pronosticados.  Queremos colorear los retratos y, por lo tanto, adem치s de las fotos de OpenImages, necesitamos m치s fotos espec칤ficas de la tarea. <br><br>  쮻칩nde podemos obtener fotos coloreadas de personas vestidas con un uniforme militar?  Hay personas en Internet que colorean fotos antiguas como un pasatiempo o por un precio.  Lo hacen con mucho cuidado, tratando de ser muy precisos.  Cuando colorean un uniforme, hombreras y medallas, se refieren a los materiales de archivo, por lo que los resultados de su trabajo son confiables.  Con todo, utilizamos 200 im치genes coloreadas manualmente con personas con uniforme militar. <br><br>  La otra fuente de datos 칰til es el sitio web del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ej칠rcito Rojo de los Trabajadores y Campesinos</a> .  A uno de sus fundadores se le tom칩 una foto en casi todos los uniformes sovi칠ticos de la Segunda Guerra Mundial disponibles. <br><br><img src="https://habrastorage.org/webt/yh/b7/u7/yhb7u74fa3feihqo0k-jpqcyxgk.jpeg"><br><br>  En algunas fotos, imitaba las poses de personas de las famosas fotos de archivo.  Es bueno que sus im치genes tengan fondo blanco: nos permiti칩 aumentar muy bien los datos al agregar varios objetos naturales en el fondo.  Tambi칠n utilizamos algunos retratos regulares, complet치ndolos con insignias y otros atributos de tiempos de guerra. <br><br>  Entrenamos a AlbuNet-50: es una Unet que utiliza ResNet-50 previamente entrenado como codificador.  La red comenz칩 a dar resultados adecuados: la piel era rosada, los ojos - gris azulado, las hombreras - amarillentas.  Sin embargo, el problema fue que deja algunas 치reas en la foto intactas.  Esto fue causado por el hecho de que, de acuerdo con el error, L1 encuentra un valor 칩ptimo en el que es mejor no hacer nada que intentar predecir algo de color. <br><br><img src="https://habrastorage.org/webt/ov/zh/bn/ovzhbnv-6ch0nnoa4fdbh3nygym.jpeg"><br>  <i>Estamos comparando nuestro resultado con una foto de Ground Truth, una coloraci칩n manual realizada por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Klimbim</a></i> <br><br>  쮺칩mo podemos resolver este problema?  Necesitamos un discriminador: una red neuronal que reciba una imagen y nos diga si se ve realista o no.  Una de las im치genes a continuaci칩n est치 coloreada manualmente y la otra, por nuestro generador, AlbuNet-50.  쮺칩mo distingue el ser humano las fotos coloreadas manual y autom치ticamente?  Al mirar los detalles.  쯇uedes decir d칩nde est치 la foto coloreada autom치ticamente por nuestra soluci칩n de referencia? <br><br><img src="https://habrastorage.org/webt/fk/er/n_/fkern_az5kgkgr2kwamcoxr_gtg.jpeg"><br><br><div class="spoiler">  <b class="spoiler_title">Respuesta</b> <div class="spoiler_text">  la imagen de la izquierda se colorea manualmente, a la derecha, autom치ticamente. </div></div><br>  Usamos el discriminador del documento <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GAN de auto atenci칩n</a> .  Es una peque침a red de convoluci칩n con la llamada Auto-Atenci칩n construida en las capas superiores.  Nos permite "prestar m치s atenci칩n" a los detalles de la imagen.  Tambi칠n utilizamos la normalizaci칩n espectral.  Puede encontrar m치s informaci칩n en el documento mencionado anteriormente.  Hemos entrenado la red con una combinaci칩n de p칠rdida L1 y una p칠rdida del discriminador.  Ahora la red colorea mejor los detalles de la imagen y el fondo se ve m치s consistente.  Un ejemplo m치s: a la izquierda est치 el trabajo por red entrenado con p칠rdida L1 solamente;  a la derecha, con una combinaci칩n de p칠rdidas discriminatorias L1. <br><br><img src="https://habrastorage.org/webt/nd/3p/91/nd3p91aw1mzzoidhra1egef3zki.jpeg"><br><br>  El proceso de capacitaci칩n tom칩 dos d칤as en cuatro GeForce 1080Ti.  La red tarda 30 ms en procesar una imagen de 512 x 512.  Validaci칩n MSE - 34.4.  Al igual que con la pintura, las m칠tricas que no desea confiar en las m칠tricas.  Es por eso que elegimos seis modelos con las mejores m칠tricas de validaci칩n y votamos ciegamente por el mejor modelo. <br><br>  Cuando ya creamos un sistema de producci칩n y lanzamos un sitio web, continuamos experimentando y llegamos a la conclusi칩n de que es mejor minimizar no la p칠rdida L1 por p칤xel, sino la p칠rdida perceptiva.  Para calcularlo, alimentamos las predicciones netas y una foto de verdad real a la red VGG-16, tomamos los mapas de caracter칤sticas en las capas inferiores y los comparamos con MSE.  Este enfoque pinta m치s 치reas y da resultados m치s coloridos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/676/9c8/b64/6769c8b64fdf00cb66dcd73edcd39e81.jpg"><br><br><h1>  Recapitulaci칩n </h1><br>  Unet es una modelo genial.  En la primera tarea de segmentaci칩n, enfrentamos un problema durante la capacitaci칩n y trabajamos con im치genes de alta resoluci칩n y es por eso que usamos In-Place BatchNorm.  En nuestra segunda tarea (Inpainting) usamos Convoluci칩n parcial en lugar de una predeterminada, y nos permiti칩 obtener mejores resultados.  Al trabajar en la coloraci칩n, agregamos una peque침a red discriminadora que penalizaba al generador por im치genes poco realistas.  Tambi칠n usamos una p칠rdida perceptual. <br><br>  Segunda conclusi칩n: los evaluadores son esenciales.  Y no solo durante la etapa de creaci칩n de m치scaras de segmentaci칩n sino tambi칠n para la validaci칩n del resultado final.  Al final, le damos al usuario tres fotos: una imagen original con defectos pintados, una foto coloreada con defectos pintados y una simplemente coloreada en caso de que el algoritmo para la b칰squeda de defectos y la pintura se equivoque. <br><br>  Tomamos algunas fotos del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">proyecto War Album</a> y las procesamos en estas neuronas.  Aqu칤 est치n los resultados que obtuvimos: <br><br><img src="https://habrastorage.org/webt/rm/4z/sb/rm4zsbvc0j_h_r2nobp4xj2p4ei.jpeg"><br><br>  Adem치s, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu칤</a> puede ver m치s de cerca las im치genes originales y todas las etapas de procesamiento. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/459696/">https://habr.com/ru/post/459696/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../459682/index.html">Calidad de datos en almacenamiento</a></li>
<li><a href="../459684/index.html">Mapa del metro de Mosc칰 y el mundo entero para Android</a></li>
<li><a href="../459688/index.html">Urbanismo en China: menos inconformistas, m치s ciencia e inform치tica</a></li>
<li><a href="../459692/index.html">C칩mo descubrimos modificaciones materiales que contradicen los principios qu칤micos establecidos</a></li>
<li><a href="../459694/index.html">Datos del museo Art. Desembale y lance Radio 86RK</a></li>
<li><a href="../459698/index.html">쮺칩mo obligar a Oracle BI 12c a crear tantas variables de sesi칩n como necesite un programador?</a></li>
<li><a href="../459704/index.html">LLVM IR y Go</a></li>
<li><a href="../459706/index.html">5 razones por las que debes olvidarte de Redux en las aplicaciones React</a></li>
<li><a href="../459708/index.html">Dise침o de interfaz de juego. Brent Fox 쮻e qu칠 trata el libro?</a></li>
<li><a href="../459710/index.html">Sobrevive a una colisi칩n frontal y por qu칠 la amnesia no es lo que piensas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö® üå≤ üÜñ Optimisation de la recherche √©tendue: comment traiter un graphique avec 10 milliards d'√©tats üë®‚Äçüè≠ üìà ü§∏üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a quelques mois, j'ai finalement d√ª admettre que je n'√©tais pas assez intelligent pour parcourir certains niveaux du puzzle Snakebird . La seule ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimisation de la recherche √©tendue: comment traiter un graphique avec 10 milliards d'√©tats</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455537/"><div style="text-align:center;"><img src="https://nordicgame.com/wp-content/uploads/2015/05/noumenon.games_.snakebird.850.560.jpg" alt="image"></div><br>  Il y a quelques mois, j'ai finalement d√ª admettre que je n'√©tais pas assez intelligent pour parcourir certains niveaux du puzzle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Snakebird</a> .  La seule fa√ßon de retrouver une partie de l'estime de soi √©tait d'√©crire un solveur.  Je pourrais donc pr√©tendre que cr√©er un programme pour r√©soudre le casse-t√™te √©quivaut presque √† le r√©soudre moi-m√™me.  Le code du programme C ++ r√©sultant est disponible sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Github</a> .  La partie principale du code consid√©r√© dans l'article est impl√©ment√©e dans <a href="">search.h</a> et <a href="">compress.h</a> .  Dans cet article, je parlerai principalement de l'optimisation d'une recherche en premier lieu qui n√©cessiterait 50-100 Go de m√©moire pour s'adapter √† 4 Go. <br><br>  Plus tard, j'√©crirai un autre article, qui d√©crira les sp√©cificit√©s du jeu.  Dans ce post, vous devez savoir que je n'ai trouv√© aucune bonne alternative √† la force brute, car aucune des astuces habituelles n'a fonctionn√©.  Le jeu a de nombreux √©tats, car il y a beaucoup d'objets en mouvement ou pouss√©s, et la forme de certains d'entre eux est importante, ce qui peut changer avec le temps.  Il n'y avait pas d'heuristique conservatrice appropri√©e pour les algorithmes comme A * pour r√©duire l'espace de recherche.  Le graphique de recherche √©tait orient√© et sp√©cifi√© implicitement; par cons√©quent, la recherche simultan√©e dans les directions avant et arri√®re √©tait impossible.  Le seul mouvement pourrait changer l'√©tat de nombreuses mani√®res ind√©pendantes, donc rien ne pourrait √™tre utile comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hacher Zobrist</a> . <br><br>  Des estimations approximatives ont montr√© que dans le plus grand casse-t√™te, apr√®s l'√©limination de toutes les positions sym√©triques, il y aurait environ 10 milliards d'√âtats.  M√™me apr√®s avoir compress√© les descriptions d'√©tat avec une densit√© maximale, la taille de l'√©tat √©tait de 8 √† 10 octets.  Avec 100 Go de m√©moire, la t√¢che serait triviale, mais pas pour ma machine domestique avec 16 Go de m√©moire.  Et comme Chrome en a besoin de 12 Go, ma m√©moire r√©elle est plus proche de 4 Go.  Tout ce qui d√©passera ce volume devra √™tre enregistr√© sur le disque (ancien disque dur rouill√©). <br><a name="habracut"></a><br>  Comment int√©grer 100 Go de donn√©es dans 4 Go de RAM?  Soit a) les √©tats doivent √™tre compress√©s √† 1/20 de leur taille d'origine, d√©j√† optimis√©e, ou b) l'algorithme devrait √™tre capable d'enregistrer efficacement les √©tats sur le disque et vice versa, ou c) une combinaison des deux m√©thodes ci-dessus, ou d) je dois acheter plus RAM ou louer une puissante machine virtuelle pendant plusieurs jours.  Je n'ai pas envisag√© l'option D, car elle est trop ennuyeuse.  Les options A et B ont √©t√© exclues apr√®s la preuve de concept √† l'aide de gzip: un fragment d'une description d'√©tat de 50 Mo a √©t√© compress√© √† seulement 35 Mo.  Cela repr√©sente environ 7 octets par √©tat, et ma m√©moire est d'environ 0,4 octet par √©tat.  Autrement dit, l'option B est rest√©e, m√™me si la recherche en premier lieu semblait plut√¥t g√™nante pour le stockage sur des disques secondaires. <br><br><h2>  Table des mati√®res </h2><br>  Il s'agit d'un article assez long, voici donc un bref aper√ßu des sections suivantes: <br><br><ul><li>  Recherche <b>en</b> largeur d'abord <b>dans un manuel</b> - quelle est la formulation habituelle de recherche en largeur en premier (BFS), et pourquoi ne convient-elle pas pour enregistrer des parties d'un √©tat sur le disque? </li><li>  <b>BFS avec tri et fusion</b> - un changement dans l'algorithme pour l'√©limination efficace des lots de donn√©es redondantes. </li><li>  <b>Compression</b> - r√©duire la quantit√© de m√©moire utilis√©e par cent fois en raison de la combinaison de la compression standard et native. </li><li>  <b>Oh-oh, j'ai trich√©!</b>  - dans les premi√®res sections, j'ai gard√© le silence sur quelque chose: il ne nous suffit pas de savoir o√π se trouve la solution, mais nous devons comprendre exactement comment y parvenir.  Dans cette section, nous mettons √† jour l'algorithme de base afin qu'il transf√®re suffisamment de donn√©es pour recr√©er la solution √† partir du dernier √©tat. </li><li>  <b>Trier + fusionner avec plusieurs sorties</b> - le stockage de plus d'√©tats annule compl√®tement les avantages de la compression.  L'algorithme de tri + fusion doit √™tre modifi√© de sorte qu'il stocke deux ensembles de donn√©es de sortie: l'un, bien compress√©, est utilis√© pendant la recherche, et l'autre n'est utilis√© que pour recr√©er la solution apr√®s avoir trouv√© la premi√®re. </li><li>  <b>Swap</b> - <b>Swap</b> sur Linux est bien pire que ce que je pensais. </li><li>  <b>Compression de nouveaux √©tats avant la fusion</b> - jusqu'√† pr√©sent, les optimisations de m√©moire ne fonctionnaient qu'avec un grand nombre d'√©tats visit√©s.  Mais il s'est av√©r√© que la liste des nouveaux √©tats g√©n√©r√©s est beaucoup plus longue que vous ne le pensez.  Cette section pr√©sente un diagramme pour une description plus efficace des nouveaux √©tats. </li><li>  <b>√âconomiser de l'espace sur les √©tats parents</b> - explorez les compromis entre l'utilisation du processeur / de la m√©moire pour recr√©er la solution √† la fin. </li><li>  <b>Ce qui n'a pas fonctionn√© ou peut ne pas fonctionner</b> - certaines id√©es semblaient prometteuses, mais en cons√©quence elles ont d√ª √™tre annul√©es, tandis que d'autres, qui √©taient cens√©es √™tre des chercheurs, me semblent intuitivement inappropri√©es dans ce cas. </li></ul><br><h2>  Recherche large ¬´par manuel¬ª </h2><br>  √Ä quoi ressemble la recherche en premier et pourquoi ne pas y utiliser un disque?  Avant ce petit projet, je ne consid√©rais que les options de formulation ¬´√† partir des manuels¬ª, par exemple, telles que: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = {start} todo = [start] <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> todo: node = todo.pop_first() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> visited: visited.add(kid) todo.push_back(kid) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">False</span></span></code> </pre> <br>  En cours de cr√©ation de nouveaux n≈ìuds candidats par le programme, chaque n≈ìud est v√©rifi√© avec une table de hachage des n≈ìuds d√©j√† visit√©s.  S'il se trouve d√©j√† dans la table de hachage, le n≈ìud est ignor√©.  Sinon, il est ajout√© √† la file d'attente et √† la table de hachage.  Parfois dans les impl√©mentations, les informations ¬´visit√©es¬ª sont entr√©es dans les n≈ìuds, et non dans une table √©trang√®re;  mais c'est une optimisation risqu√©e et elle est compl√®tement impossible si le graphique est implicitement sp√©cifi√©. <br><br>  Pourquoi l'utilisation d'une table de hachage est-elle probl√©matique?  Parce que les tables de hachage ont tendance √† cr√©er un mod√®le d'acc√®s √† la m√©moire compl√®tement al√©atoire.  S'ils ne le font pas, alors c'est une mauvaise fonction de hachage, et la table de hachage aura tr√®s probablement de mauvaises performances en raison de collisions.  Ce mod√®le d'acc√®s al√©atoire peut entra√Æner des probl√®mes de performances, m√™me si les donn√©es tiennent en m√©moire: l'acc√®s √† une √©norme table de hachage est susceptible de provoquer des √©checs de cache et un tampon de traduction associatif (TLB).  Mais que se passe-t-il si une partie importante des donn√©es se trouve sur le disque et non en m√©moire?  Les cons√©quences seront catastrophiques: quelque chose de l'ordre de 10 ms par op√©ration de recherche. <br><br>  Avec 10 milliards d'√©tats uniques, seul l'acc√®s √† la table de hachage nous prendra environ quatre mois pour attendre les E / S disque.  Cela ne nous convient pas;  la t√¢che doit absolument √™tre convertie pour que le programme puisse traiter de gros paquets de donn√©es en un seul passage. <br><br><h2>  BFS avec tri et fusion </h2><br>  Si nous voulions int√©grer autant que possible les op√©rations d'acc√®s aux donn√©es dans les packages, quelle serait l'approximation maximale r√©alisable?  Puisque le programme ne sait pas quels n≈ìuds traiter dans une couche de profondeur N + 1 jusqu'√† ce que la couche N soit compl√®tement trait√©e, il semble √©vident qu'il est n√©cessaire de d√©dupliquer les √©tats au moins une fois par profondeur. <br><br>  Si nous travaillons avec une couche enti√®re en m√™me temps, nous pouvons abandonner les tables de hachage et d√©crire l'ensemble des √©tats visit√©s et nouveaux comme des flux tri√©s (par exemple, comme des flux de fichiers, des tableaux, des listes).  Nous pouvons trouver trivialement le nouvel ensemble visit√© en combinant les ensembles de flux et il est √©galement trivial de trouver l'ensemble √† faire en utilisant la diff√©rence des ensembles. <br><br>  Deux op√©rations avec des ensembles peuvent √™tre combin√©es afin qu'elles fonctionnent en une seule passe avec les deux threads.  En fait, nous examinons les deux flux, traitons le plus petit √©l√©ment, puis avan√ßons le long du flux √† partir duquel l'√©l√©ment a √©t√© pris (ou le long des deux flux si les √©l√©ments au d√©but sont les m√™mes).  Dans les deux cas, nous ajoutons l'article au nouvel ensemble visit√©.  Ensuite, nous avan√ßons le long du flux de nouveaux √©tats et ajoutons √©galement un √©l√©ment au nouvel ensemble de t√¢ches: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = Stream() todo = Stream() visited.add(start) todo.add(start) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: new = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> todo: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): new.push_back(kid) new_stream = Stream() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> new.sorted().uniq(): new_stream.add(node) todo, visited = merge_sorted_streams(new_stream, visited) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> <span class="hljs-comment"><span class="hljs-comment"># Merges sorted streams new and visited. Return a sorted stream of # elements that were just present in new, and another sorted # stream containing the elements that were present in either or # both of new and visited. def merge_sorted_streams(new, visited): out_todo, out_visited = Stream(), Stream() while visited or new: if visited and new: if visited.peek() == new.peek(): out_visited.add(visited.pop()) new.pop() elif visited.peek() &lt; new.peek(): out_visited.add(visited.pop()) elif visited.peek() &gt; new.peek(): out_todo.add(new.peek()) out_visited.add(new.pop()) elif visited: out_visited.add(visited.pop()) elif new: out_todo.add(new.peek()) out_visited.add(new.pop()) return out_todo, out_visited</span></span></code> </pre> <br>  Le mod√®le d'acc√®s aux donn√©es est d√©sormais compl√®tement lin√©aire et pr√©visible; il n'y a pas d'acc√®s arbitraire tout au long de la fusion.  Par cons√©quent, le retard dans les op√©rations sur disque ne devient pas important pour nous, et la seule chose qui reste importante est la bande passante. <br><br>  √Ä quoi ressembleront les performances th√©oriques avec une distribution simplifi√©e des donn√©es sur 100 niveaux de profondeur, chacun ayant 100 millions d'√©tats?  L'√©tat moyen sera lu et √©crit 50 fois.  Cela donne 10 octets / √©tat * 5 milliards d'√©tats * 50 = 2,5 To.  Mon disque dur peut soi-disant lire et √©crire √† une vitesse moyenne de 100 Mo / s, c'est-√†-dire qu'en moyenne les E / S prendront (2 * 2,5 To) / (100 Mo / s) = ~ 50k / s = ~ 13 heures .  C'est quelques commandes de moins que le r√©sultat pr√©c√©dent (quatre mois)! <br><br>  Il convient √©galement de noter que ce mod√®le simplifi√© ne prend pas en compte la taille des nouveaux √©tats g√©n√©r√©s.  Avant l'√©tape de fusion, ils doivent √™tre stock√©s en m√©moire pour le tri + la d√©duplication.  Nous couvrirons cela dans les sections ci-dessous. <br><br><h2>  La compression </h2><br>  Dans l'introduction, j'ai dit que dans les premi√®res exp√©riences, la compression d'√©tat ne semblait pas prometteuse et que le taux de compression n'√©tait que de 30%.  Mais apr√®s avoir apport√© des modifications √† l'algorithme, les √©tats sont devenus rationalis√©s.  Ils devraient √™tre beaucoup plus faciles √† comprimer. <br><br>  Pour tester cette th√©orie, j'ai utilis√© zstd avec un puzzle de 14,6 millions d'√©tats, dont chaque √©tat avait une taille de 8 octets.  Apr√®s le tri, ils ont √©t√© compress√©s en moyenne √† 1,4 octet par √©tat.  Cela semble √™tre un s√©rieux pas en avant.  Il ne suffit pas d'ex√©cuter l'int√©gralit√© du programme en m√©moire, mais cela peut r√©duire le temps d'E / S du disque √† seulement quelques heures. <br><br>  Est-il possible d'am√©liorer en quelque sorte le r√©sultat de l'algorithme de compression polyvalent moderne si nous savons quelque chose sur la structure des donn√©es?  Vous pouvez en √™tre presque s√ªr.  Un bon exemple de ceci est le format PNG.  Th√©oriquement, la compression n'est qu'une passe de d√©gonflage standard.  Mais au lieu de compresser les donn√©es brutes, l'image est d'abord convertie √† l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">filtres PNG</a> .  Le filtre PNG est essentiellement une formule pour pr√©dire la valeur d'un octet de donn√©es brutes sur la base de la valeur du m√™me octet dans la ligne pr√©c√©dente et / ou du m√™me octet du pixel pr√©c√©dent.  Par exemple, le filtre ¬´up¬ª convertit chaque octet en soustrayant les valeurs de la ligne pr√©c√©dente lors de la compression et en effectuant l'op√©ration inverse lors du d√©ballage.  √âtant donn√© les types d'images pour lesquels PNG est utilis√©, le r√©sultat sera presque toujours compos√© de z√©ros ou de nombres proches de z√©ro.  D√©gonfler peut compresser ces donn√©es bien mieux que les donn√©es brutes. <br><br>  Ce principe peut-il √™tre appliqu√© aux enregistrements d'√©tat BFS?  Il semble que cela devrait √™tre possible.  Comme avec PNG, nous avons une taille de ligne constante et nous pouvons nous attendre √† ce que les lignes adjacentes soient tr√®s similaires.  Les premiers √©chantillons avec le filtre de soustraction / addition, suivis de zstd, ont conduit √† une am√©lioration du taux de compression de 40% suppl√©mentaires: 0,87 octets par √©tat.  Les op√©rations de filtrage sont triviales, donc, du point de vue de la consommation CPU, elles sont pratiquement ¬´gratuites¬ª. <br><br>  Il n'√©tait pas clair pour moi si d'autres am√©liorations pouvaient √™tre apport√©es ou s'il s'agissait d'une limite pratique.  Dans les donn√©es d'image, vous pouvez logiquement vous attendre √† ce que les octets adjacents de la m√™me ligne soient similaires.  Mais dans ces √âtats, il n'y a rien de tel.  Mais en r√©alit√©, des filtres l√©g√®rement plus sophistiqu√©s peuvent encore am√©liorer les r√©sultats.  √Ä la fin, je suis arriv√© √† ce syst√®me: <br><br>  Supposons que nous ayons des rang√©es adjacentes R1 = [1, 2, 3, 4] et R2 = [1, 2, 6, 4].  Lors de la sortie de R2, nous comparons chaque octet avec le m√™me octet de la ligne pr√©c√©dente, et 0 indiquera une correspondance et 1 indiquera une incompatibilit√©: diff = [0, 0, 1, 0].  Ensuite, nous transmettons ce bitmap, cod√© en VarInt, suivi uniquement des octets qui ne correspondent pas √† la ligne pr√©c√©dente.  Dans cet exemple, nous obtenons deux octets 0b00000100 6. En soi, ce filtre compresse les donn√©es de r√©f√©rence √† 2,2 octets / √©tat.  Mais en combinant le filtre + zstd, nous avons r√©duit la taille des donn√©es √† 0,42 octets / √©tat.  Ou, pour le dire autrement, cela repr√©sente 3,36 bits par √©tat, ce qui est juste un peu plus que nos indicateurs calcul√©s approximatifs n√©cessaires pour garantir que toutes les donn√©es tiennent dans la RAM. <br><br>  En pratique, les taux de compression s'am√©liorent car les ensembles tri√©s deviennent plus denses.  Lorsque la recherche atteint le point o√π la m√©moire commence √† causer des probl√®mes, les taux de compression peuvent s'am√©liorer consid√©rablement.  Le plus gros probl√®me est qu'en fin de compte, 4,6 milliards d'√âtats sont visit√©s.  Apr√®s tri, ces √©tats occupent 405 Mo et sont compress√©s selon le sch√©ma pr√©sent√© ci-dessus.  Cela nous donne <b>0,7 bits par √©tat</b> .  Au final, la compression et la d√©compression occupent environ 25% du temps CPU du programme, mais c'est un excellent compromis pour r√©duire la consommation de m√©moire d'une centaine de fois. <br><br>  Le filtre ci-dessus semble un peu co√ªteux en raison de l'en-t√™te VarInt sur chaque ligne.  Il semble qu'il soit facile de mettre √† niveau au prix de faibles co√ªts de processeur ou d'une l√©g√®re augmentation de la complexit√©.  J'ai essay√© plusieurs options diff√©rentes, transposant les donn√©es dans l'ordre par colonnes, ou √©crivant des masques de bits dans des blocs plus grands, etc.  Ces options √† elles seules ont donn√© des taux de compression beaucoup plus √©lev√©s, mais n'ont pas donn√© de bons r√©sultats lorsque la sortie du filtre a √©t√© compress√©e par zstd.  Et ce n'√©tait pas une sorte d'erreur zstd, les r√©sultats avec gzip et bzip2 se sont av√©r√©s similaires.  Je n'ai pas de th√©ories particuli√®rement ing√©nieuses sur les raisons pour lesquelles ce type particulier de codage s'est av√©r√© √™tre bien meilleur en compression que les autres options. <br><br>  Autre myst√®re: le taux de compression s'est av√©r√© bien meilleur lorsque les donn√©es sont tri√©es par petit-boutien plut√¥t que par gros-boutiste.  Initialement, je pensais que cela s'√©tait produit parce que dans le tri en petits caract√®res, il y avait plus de z√©ros en t√™te avec le masque de bits cod√© par VarInt.  Mais cette diff√©rence persiste m√™me avec des filtres qui n'ont pas de telles d√©pendances. <br><br>  (Il existe de nombreuses recherches sur la compression d'ensembles tri√©s d'entiers, car ce sont les √©l√©ments de base des moteurs de recherche. Cependant, je n'ai pas trouv√© beaucoup d'informations sur la compression d'enregistrements tri√©s de longueur constante, et je ne voulais pas deviner, pr√©sentant les donn√©es sous forme de valeurs enti√®res avec une pr√©cision arbitraire.) <br><br><h2>  Oh-oh, j'ai trich√©! </h2><br>  Vous avez peut-√™tre remarqu√© que les impl√©mentations BFS ci-dessus dans le pseudo-code renvoient uniquement des valeurs bool√©ennes - la solution est trouv√©e / introuvable.  Ce n'est pas particuli√®rement utile.  Dans la plupart des cas, nous devrons cr√©er une liste des √©tapes exactes de la solution, et pas seulement signaler la disponibilit√© de la solution. <br><br>  Au d√©but, il semble que ce probl√®me soit facile √† r√©soudre.  Au lieu de collecter des ensembles d'√©tats, vous devez collecter les relations d'√©tats avec les √©tats parents.  Ensuite, apr√®s avoir trouv√© la solution, vous pouvez simplement revenir de la liste des solutions parentales de bout en bout.  Pour une solution bas√©e sur une table de hachage, cela ressemblerait √† ceci: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> visited = {start: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>} todo = [start] <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> todo: node = todo.pop_first() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(node, visited) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> visited: visited[kid] = node todo.push_back(kid) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trace_solution</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(state, visited)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> state <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> [] <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(start, visited[state]) + [state]</code> </pre> <br>  Malheureusement, cela d√©truira tous les avantages de compression obtenus dans la section pr√©c√©dente;  ils sont bas√©s sur l'hypoth√®se que les lignes adjacentes sont tr√®s similaires.  Lorsque nous examinons simplement les √âtats eux-m√™mes, c'est vrai.  Mais il n'y a aucune raison de croire que cela sera vrai pour les √âtats parentaux;  en fait, ce sont des donn√©es al√©atoires.  Deuxi√®mement, une solution sort + merge doit lire et √©crire tous les √©tats affich√©s √† chaque it√©ration.  Pour sauvegarder la liaison de l'√©tat / √©tat parent, nous devons lire et √©crire sur le disque √† chaque it√©ration toutes ces donn√©es mal compress√©es. <br><br><h2>  Trier + fusionner avec plusieurs sorties </h2><br>  √Ä la toute fin, lors du retour √† la solution, le programme n'aura besoin que de paquets d'√©tats / √©tats parents. Par cons√©quent, nous pouvons stocker deux structures de donn√©es en parall√®le.  Visit√© continuera d'√™tre l'ensemble des √©tats visit√©s, comme pr√©c√©demment recalcul√© lors de la fusion.  Parents est au moins une liste tri√©e de paires √©tat / √©tat parent qui ne sont pas √©cras√©es.  Apr√®s chaque op√©ration de fusion, la paire ¬´√©tat + √©tat parent¬ª est ajout√©e aux parents. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bfs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(graph, start, end)</span></span></span><span class="hljs-function">:</span></span> parents = Stream() visited = Stream() todo = Stream() parents.add((start, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>)) visited.add(start) todo.add(start) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: new = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> todo: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> node == end: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> trace_solution(node, parents) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> kid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> adjacent(node): new.push_back(kid) new_stream = Stream() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> node <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> new.sorted().uniq(): new_stream.add(node) todo, visited = merge_sorted_streams(new_stream, visited, parents) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-comment"><span class="hljs-comment"># Merges sorted streams new and visited. New contains pairs of # key + value (just the keys are compared), visited contains just # keys. # # Returns a sorted stream of keys that were just present in new, # another sorted stream containing the keys that were present in either or # both of new and visited. Also adds the keys + values to the parents # stream for keys that were only present in new. def merge_sorted_streams(new, visited, parents): out_todo, out_visited = Stream(), Stream() while visited or new: if visited and new: visited_head = visited.peek() new_head = new.peek()[0] if visited_head == new_head: out_visited.add(visited.pop()) new.pop() elif visited_head &lt; new_head: out_visited.add(visited.pop()) elif visited_head &gt; new_head: out_todo.add(new_head) out_visited.add(new_head) out_parents.add(new.pop()) elif visited: out_visited.add(visited.pop()) elif new: out_todo.add(new.peek()[0]) out_visited.add(new.peek()[0]) out_parents.add(new.pop()) return out_todo, out_visited</span></span></code> </pre> <br>  Cela nous permet de tirer parti des deux approches en termes d'ex√©cution et d'ensembles de travaux, mais n√©cessite plus d'espace de stockage secondaire.  De plus, il s'av√®re qu'√† l'avenir, pour d'autres raisons, une copie s√©par√©e des √©tats visit√©s sera utile, group√©e par profondeur. <br><br><h2>  √âchanger </h2><br>  Un autre d√©tail est ignor√© dans le pseudo-code: il n'y a pas de code explicite pour les E / S disque, mais uniquement l'interface Stream abstraite.  Le flux peut √™tre un flux de fichiers ou un tableau dans la m√©moire, mais nous avons ignor√© ce d√©tail d'impl√©mentation.  Au lieu de cela, le pseudo-code cr√©e un mod√®le d'acc√®s √† la m√©moire qui permet une utilisation optimale du disque.  Dans un monde id√©al, cela suffirait et le reste pourrait √™tre occup√© par le sous-syst√®me de m√©moire virtuelle du syst√®me d'exploitation. <br><br>  Mais cela ne se produit pas, du moins sous Linux.  √Ä un moment donn√© (avant que l'ensemble de donn√©es de travail puisse √™tre compress√© en tailles de m√©moire), j'ai r√©ussi √† ex√©cuter le programme en environ 11 heures et les donn√©es ont √©t√© enregistr√©es principalement sur le disque.  Ensuite, j'ai fait en sorte que le programme utilise des pages anonymes plut√¥t que stock√©es dans des fichiers et j'ai s√©lectionn√© un fichier d'√©change de taille suffisante sur le m√™me lecteur.  Cependant, trois jours plus tard, le programme n'a dur√© qu'un quart du chemin et, au fil du temps, il est devenu plus lent.  Selon mes estimations optimistes, elle √©tait cens√©e terminer le travail dans 20 jours. <br><br>  Je vais pr√©ciser - c'√©tait le m√™me code et <i>exactement le m√™me mod√®le d'acc√®s</i> .  La seule chose qui a chang√© est que la m√©moire a √©t√© enregistr√©e non pas en tant que fichier disque explicite, mais en tant que swap.  Presque aucune preuve n'est n√©cessaire que l'√©change permette de d√©truire compl√®tement les performances de Linux, contrairement aux E / S de fichiers ordinaires.  J'ai toujours suppos√© que cela √©tait d√ª au fait que les programmes ont tendance √† consid√©rer la RAM comme une m√©moire √† acc√®s al√©atoire.  Mais ce n'est pas le cas. <br><br>  Il s'av√®re que les pages d'enregistrement de fichiers et les pages anonymes sont trait√©es diff√©remment par le sous-syst√®me de machine virtuelle.  Ils sont stock√©s dans des caches LRU distincts avec des politiques d'expiration diff√©rentes;  de plus, il semble qu'ils aient des propri√©t√©s de lecture anticip√©e en lecture / charge diff√©rentes. <br><br>  Maintenant, je sais: l'√©change sur Linux ne fonctionnera probablement pas bien m√™me dans des conditions optimales.  Si des parties de l'espace d'adressage sont susceptibles d'√™tre d√©charg√©es pendant un certain temps sur le disque, il est pr√©f√©rable de les enregistrer manuellement dans des fichiers plut√¥t que de faire confiance au swap.  J'ai accompli cela en impl√©mentant ma propre classe de vecteurs, qui initialement ne fonctionne qu'en m√©moire, et apr√®s avoir d√©pass√© un certain seuil de taille, il passe en mmap dans un fichier s√©par√© temporaire. <br><br><h2>  Compression de nouveaux √©tats avant la fusion </h2><br>  Dans un mod√®le de performance simplifi√©, nous avons suppos√© que 100 millions de nouvelles conditions se produiraient √† chaque profondeur.  Il s'est av√©r√© que ce n'est pas tr√®s loin de la r√©alit√© (dans le casse-t√™te le plus complexe, un maximum de plus de 150 millions de nouveaux √©tats uniques sur une couche de profondeur).  Mais cela ne doit pas √™tre mesur√©;  l'ensemble de travail avant la fusion est associ√© non seulement √† des √©tats uniques, mais √©galement √† tous les √©tats d√©duits pour cette it√©ration.  Ce chiffre atteint 880 millions d'√©tats de sortie par couche de profondeur.  Ces 880 millions d'√©tats a) doivent √™tre trait√©s avec un mod√®le d'acc√®s al√©atoire pour le tri, b) ne peuvent pas √™tre efficacement compress√©s en raison d'un manque de tri, c) doivent √™tre stock√©s avec l'√©tat parent.  Ce jeu de travail fait environ 16 Go. <br><br>  La solution √©vidente: utilisez une sorte de tri externe.  Il suffit d'√©crire tous les √©tats sur le disque, d'effectuer un tri externe, de d√©dupliquer, puis de fusionner comme d'habitude.  Au d√©but, j'ai utilis√© cette solution, et bien qu'elle ait tout au plus √©limin√© le probl√®me A, je ne pouvais pas faire face √† B et C. <br><br>  Au final, j'ai adopt√© une approche alternative: j'ai collect√© les √©tats dans un tableau en m√©moire.  Si le tableau devient trop grand (par exemple, plus de 100 millions d'√©l√©ments), il est tri√©, d√©dupliqu√© et compress√©.  Cela nous donne un ensemble d'ex√©cutions d'√©tat tri√©es, et il n'y a pas de doublons √† l'int√©rieur de chaque ex√©cution, mais elles sont possibles entre les ex√©cutions.  Fondamentalement, le code de fusion des √âtats nouveaux et visit√©s reste le m√™me;  elle repose toujours sur un passage progressif √† travers les ruisseaux.  La seule diff√©rence est qu'au lieu de simplement passer par deux flux, il existe un flux distinct pour chacune des s√©ries tri√©es de nouveaux √©tats. <br><br>  Bien s√ªr, les taux de compression de ces s√©ries de 100 millions d'√©tats ne sont pas aussi bons que la compression de l'ensemble de tous les √©tats visit√©s.  Mais m√™me avec de tels indicateurs, cela r√©duit consid√©rablement le volume de l'ensemble de travail et les exigences d'E / S disque.  Vous avez besoin d'un peu plus de ressources CPU pour traiter la file d'attente prioritaire des threads, mais c'est toujours un excellent compromis. <br><br><h2>  √âconomiser de l'espace sur les √©tats parents </h2><br>  √Ä ce stade, la grande majorit√© de l'espace occup√© par le programme est consacr√©e au stockage des √©tats parents, de sorte qu'apr√®s avoir trouv√© la solution, nous pouvons recr√©er son processus.  Tr√®s probablement, ils peuvent √† peine √™tre bien serr√©s, mais peut-√™tre qu'il y a une sorte de compromis entre le CPU et la m√©moire? <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous devons connecter l'√©tat S '√† la profondeur D + 1 avec son √©tat parent S √† la profondeur D. Si nous pouvons it√©rer sur tous les √©tats parentaux possibles S', alors nous pouvons v√©rifier si l'un d'eux appara√Æt √† la profondeur D dans l'ensemble visit√© . (Nous avons d√©j√† cr√©√© un grand nombre de sites visit√©s, regroup√©s par profondeur en tant que sous-produit pratique de la d√©rivation de bundles d'√©tat / √©tat parental lors de la fusion). Malheureusement, cette approche ne fonctionnera pas pour cette t√¢che; il est simplement trop difficile pour nous de g√©n√©rer tous les √©tats possibles de S pour un S donn√©. Cependant, pour de nombreuses autres t√¢ches de recherche, une telle solution pourrait fonctionner.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si nous ne pouvons g√©n√©rer que des transitions entre √©tats vers l'avant, mais pas vers l'arri√®re, alors pourquoi ne pas simplement faire cela? Passons en revue tous les √©tats en profondeur D et voyons quel type d'√©tats de sortie ils obtiennent. Si un √©tat √† la sortie donne S ', alors nous avons trouv√© un S. appropri√©. Le probl√®me avec ce plan est qu'il augmente la consommation totale de CPU du programme de 50%. (Pas 100%, car en moyenne on trouvera S en regardant la moiti√© des √©tats √† la profondeur D).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Par cons√©quent, je n'aime pas l'un des cas limitatifs, mais ici, au moins, un compromis entre le processeur / la m√©moire est possible. </font><font style="vertical-align: inherit;">Y a-t-il une solution plus acceptable quelque part entre les deux? </font><font style="vertical-align: inherit;">En fin de compte, j'ai d√©cid√© de ne pas stocker la paire (S ', S), mais la paire (S', H (S)), o√π H est une fonction de hachage de 8 bits. </font><font style="vertical-align: inherit;">Pour trouver S pour un S 'donn√©, nous parcourons √† nouveau tous les √©tats en profondeur D. Mais avant de faire autre chose, nous calculons le m√™me hachage. </font><font style="vertical-align: inherit;">Si la sortie ne correspond pas √† H (S), alors ce n'est pas l'√©tat que nous recherchons, et nous pouvons simplement le sauter. </font><font style="vertical-align: inherit;">Cette optimisation signifie que des recalculs co√ªteux ne doivent √™tre effectu√©s que pour 1/256 √©tats, ce qui repr√©sente une l√©g√®re augmentation de la charge CPU, et en m√™me temps r√©duit la quantit√© de m√©moire pour le stockage des √©tats parents de 8-10 octets √† 1 octet.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ce qui n'a pas fonctionn√© ou peut ne pas fonctionner </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans les sections pr√©c√©dentes, nous avons examin√© la s√©quence d'optimisations de haut niveau qui a fonctionn√©. J'ai essay√© d'autres choses qui n'ont pas fonctionn√© ou que j'ai trouv√©es dans la litt√©rature, mais j'ai d√©cid√© que dans ce cas particulier, elles ne fonctionneraient pas. Voici une liste partielle.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√Ä ce stade, je ne recalcule pas l'ensemble entier visit√© √† chaque it√©ration. Au lieu de cela, il a √©t√© stock√© en tant que plusieurs s√©ries tri√©es, et ces s√©ries ont √©t√© compress√©es de temps en temps. L'avantage de cette approche est que moins d'√©critures sur disque et de ressources CPU sont utilis√©es pour la compression. L'inconv√©nient est une complexit√© de code accrue et un taux de compression r√©duit. Au d√©part, je pensais qu'un tel sch√©ma avait du sens, car dans mon cas, les op√©rations d'√©criture co√ªtent plus cher que la lecture. Mais au final, le taux de compression s'est av√©r√© √™tre deux fois plus √©lev√©. Les avantages d'un tel compromis ne sont pas √©vidents, par cons√©quent, je suis revenu √† une forme plus simple. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Peu de recherches ont d√©j√† √©t√© effectu√©es pour effectuer une recherche volum√©trique en largeur des graphiques d√©finis implicitement dans le stockage secondaire, vous pouvez commencer √† explorer ce sujet</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de cet article de 2008</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Comme vous pouvez le deviner, l'id√©e de faire la d√©duplication avec le tri + la fusion dans le stockage secondaire n'est pas nouvelle. Ce qui est surprenant, c'est qu'il n'a √©t√© ouvert qu'en 1993. Assez tard! Il existe des suggestions ult√©rieures pour une recherche en largeur dans le stockage secondaire qui ne n√©cessitent pas d'√©tape de tri. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'un d'eux consistait √† lier des √©tats √† des entiers et √† stocker en m√©moire une image bitmap des √©tats visit√©s. Dans mon cas, cela est compl√®tement inutile, car les tailles de l'√©tat cod√© sont tr√®s diff√©rentes par rapport aux espaces d'√©tats vraiment accessibles. Et je doute beaucoup qu'il existe des probl√®mes int√©ressants dans lesquels une telle approche fonctionnerait.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une autre alternative s√©rieuse est bas√©e sur des tables de hachage temporaires. Les √©tats visit√©s sont stock√©s sans tri dans un fichier. Nous enregistrons la sortie obtenue de la profondeur D dans la table de hachage. Parcourez ensuite de mani√®re it√©rative les √âtats visit√©s et recherchez-les dans la table de hachage. Si l'√©l√©ment se trouve dans la table de hachage, supprimez-le. Apr√®s avoir parcouru de mani√®re it√©rative l'int√©gralit√© du fichier, seuls les √©l√©ments non dupliqu√©s y resteront. Ils sont ensuite ajout√©s au fichier et utilis√©s pour initialiser la liste des t√¢ches pour la prochaine it√©ration. Si la quantit√© de sortie est si grande que la table de hachage ne tient pas en m√©moire, les fichiers et les tables de hachage peuvent √™tre divis√©s en parties en utilisant les m√™mes crit√®res (par exemple, les bits d'√©tat sup√©rieurs), et chaque partie doit √™tre trait√©e s√©par√©ment. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien qu'il existe des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rep√®res</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">montrant que l'approche bas√©e sur le hachage est environ 30% plus rapide que le tri + la fusion, mais il semble qu'ils ne prennent pas en compte la compression. Je n'ai tout simplement pas vu comment le rejet des avantages de la compression peut se justifier, alors je n'ai m√™me pas exp√©riment√© de telles approches. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Un autre domaine de recherche digne d'attention √©tait l'optimisation des requ√™tes de bases de donn√©es. √áa ressemble. que la t√¢che de d√©duplication est fortement li√©e √† la jointure de la base de donn√©es, qui a √©galement exactement le m√™me </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dilemme de </font></font></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tri par rapport au hachage</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. De toute √©vidence, certaines de ces √©tudes peuvent √™tre appliqu√©es au probl√®me de recherche. La diff√©rence peut √™tre que la sortie de la base de donn√©es de jointure est temporaire, tandis que la sortie de d√©duplication BFS est stock√©e jusqu'√† la fin du calcul. Il semble que cela modifie l'√©quilibre des compromis: il s'agit d√©sormais non seulement du traitement le plus efficace d'une it√©ration, mais √©galement de la cr√©ation du format de donn√©es de sortie le plus optimal pour la prochaine it√©ration.</font></font><br><br><h2>  Conclusion </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ceci conclut mon r√©cit de ce que j'ai appris d'un projet qui est g√©n√©ralement applicable √† d'autres t√¢ches de recherche par force brute. </font><font style="vertical-align: inherit;">La combinaison de ces astuces a permis de r√©duire le volume de solutions aux puzzles les plus complexes du jeu de 50-100 Go √† 500 Mo et d'augmenter en douceur les co√ªts si la t√¢che d√©passe la m√©moire disponible et est √©crite sur le disque. </font><font style="vertical-align: inherit;">De plus, ma solution est 50% plus rapide qu'une d√©duplication na√Øve d'√©tats bas√©e sur des tables de hachage, m√™me pour des puzzles qui tiennent en m√©moire. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Snakebird peut √™tre achet√© sur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Steam</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google Play</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">App Store</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Je le recommande √† tous ceux qui s'int√©ressent aux puzzles tr√®s complexes mais honn√™tes.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455537/">https://habr.com/ru/post/fr455537/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455525/index.html">Zimbra et Mail Bomb Defense</a></li>
<li><a href="../fr455527/index.html">Qu'est-ce qui est √©crit ici? Dans les coulisses des objets JavaScript</a></li>
<li><a href="../fr455529/index.html">Inverser et pirater le disque dur externe √† chiffrement automatique d'Aigo. Partie 2: Dump avec Cypress PSoC</a></li>
<li><a href="../fr455533/index.html">Bubble Physics: A Search for Foam Destruction Mechanism</a></li>
<li><a href="../fr455535/index.html">G√©rer les certificats SSL / TLS dans les nuages ‚Äã‚Äãet les conteneurs - pas du travail humain</a></li>
<li><a href="../fr455539/index.html">Voyants mobiles: 10 nouveaux faits sur la fa√ßon dont les appareils portables vous regardent</a></li>
<li><a href="../fr455543/index.html">Le cluster Kubernetes est-il facile et pratique √† pr√©parer? Annoncer l'op√©rateur d'addon</a></li>
<li><a href="../fr455545/index.html">Construire des processus √† partir de z√©ro: du chaos √† l'ordre</a></li>
<li><a href="../fr455547/index.html">Internet des objets en russe. Baseband Hotel LoRaWAN pour les propri√©taires de RTL-SDR</a></li>
<li><a href="../fr455549/index.html">Comment utiliser les groupes Facebook pour promouvoir: cr√©er un site Web</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
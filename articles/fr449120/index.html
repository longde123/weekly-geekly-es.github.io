<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∂üèª üòπ üé¶ Avec une barbe, des lunettes noires et de profil: situations difficiles pour la vision par ordinateur üë£ üêí üôåüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Des technologies et des mod√®les pour notre futur syst√®me de vision par ordinateur ont √©t√© cr√©√©s et am√©lior√©s progressivement dans divers projets de no...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Avec une barbe, des lunettes noires et de profil: situations difficiles pour la vision par ordinateur</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/449120/"><img src="https://habrastorage.org/getpro/habr/post_images/027/06d/ef1/02706def16ee17a808ab04bef455cb83.jpg"><br><br>  Des technologies et des mod√®les pour notre futur syst√®me de vision par ordinateur ont √©t√© cr√©√©s et am√©lior√©s progressivement dans divers projets de notre entreprise - dans le courrier, le cloud et la recherche.  Affin√© comme du bon fromage ou du cognac.  Une fois que nous avons r√©alis√© que nos r√©seaux de neurones pr√©sentaient d'excellents r√©sultats de reconnaissance, nous avons d√©cid√© de les regrouper en un seul produit b2b - Vision - que nous utilisons maintenant nous-m√™mes et proposons de vous utiliser. <br><br>  Aujourd'hui, notre technologie de vision par ordinateur sur la plateforme Mail.Ru Cloud Solutions fonctionne avec succ√®s et r√©sout des probl√®mes pratiques tr√®s complexes.  Il est bas√© sur un certain nombre de r√©seaux de neurones form√©s sur nos ensembles de donn√©es et sp√©cialis√©s dans la r√©solution de probl√®mes appliqu√©s.  Tous les services tournent sur les capacit√©s de nos serveurs.  Vous pouvez int√©grer l'API Vision publique dans vos applications, gr√¢ce √† laquelle toutes les fonctionnalit√©s du service sont disponibles.  L'API est rapide - gr√¢ce aux GPU du serveur, le temps de r√©ponse moyen au sein de notre r√©seau est de 100 ms. <br><br>  Sous la coupe, il y a une histoire d√©taill√©e et de nombreux exemples de Vision. <br><a name="habracut"></a><br>  √Ä titre d'exemple de service dans lequel nous utilisons nous-m√™mes les technologies de reconnaissance faciale susmentionn√©es, nous pouvons citer les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©v√©nements</a> .  L'un de ses composants est le stand photo Vision, que nous installons lors de diff√©rentes conf√©rences.  Si vous vous rendez sur un tel support photo, prenez une photo avec l'appareil photo int√©gr√© et saisissez votre courrier, le syst√®me trouvera imm√©diatement parmi le tableau de photos celles dont les photographes de la conf√©rence r√©guli√®re vous ont captur√© et, si vous le souhaitez, vous enverra les photos trouv√©es par courrier.  Et il ne s'agit pas de portraits mis en sc√®ne - Vision vous reconna√Æt m√™me en arri√®re-plan dans la foule de visiteurs.  Bien s√ªr, ils ne sont pas reconnus par les supports de photos eux-m√™mes, ce ne sont que des tablettes dans de magnifiques dessous de verre qui photographient simplement les invit√©s sur leurs appareils photo int√©gr√©s et transmettent des informations aux serveurs, o√π toute la magie de la reconnaissance a lieu.  Et nous avons observ√© √† plusieurs reprises √† quel point l'efficacit√© de la technologie est surprenante m√™me chez les sp√©cialistes de la reconnaissance d'image.  Ci-dessous, nous parlerons de quelques exemples. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3gE-OeSmoKo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h1>  1. Notre mod√®le de reconnaissance faciale </h1><br><h3>  1.1.  R√©seau de neurones et vitesse de traitement </h3><br>  Pour la reconnaissance, nous utilisons une modification du mod√®le de r√©seau de neurones ResNet 101. Le regroupement moyen √† la fin est remplac√© par une couche enti√®rement connect√©e, semblable √† la fa√ßon dont cela a √©t√© fait dans ArcFace.  Cependant, la taille des repr√©sentations vectorielles est de 128 et non de 512. Notre ensemble de formation contient environ 10 millions de photos de 273 593 personnes. <br><br>  Le mod√®le fonctionne tr√®s rapidement gr√¢ce √† une architecture de configuration de serveur soigneusement s√©lectionn√©e et √† un calcul GPU.  Il faut 100 ms pour obtenir une r√©ponse de l'API dans nos r√©seaux internes - cela comprend la d√©tection des visages (d√©tection des visages sur la photo), la reconnaissance et le renvoi du PersonID dans la r√©ponse de l'API.  Avec de gros volumes de donn√©es entrantes - photos et vid√©os - il faudra beaucoup plus de temps pour transf√©rer des donn√©es vers le service et recevoir une r√©ponse. <br><br><h3>  1.2.  √âvaluation de l'efficacit√© du mod√®le </h3><br>  Mais d√©terminer l'efficacit√© des r√©seaux de neurones est une t√¢che tr√®s mitig√©e.  La qualit√© de leur travail d√©pend des ensembles de donn√©es sur lesquels les mod√®les ont √©t√© form√©s et s'ils ont √©t√© optimis√©s pour travailler avec des donn√©es sp√©cifiques. <br><br>  Nous avons commenc√© √† √©valuer la pr√©cision de notre mod√®le avec le test de v√©rification LFW populaire, mais il est trop petit et simple.  Apr√®s avoir atteint une pr√©cision de 99,8%, il n'est plus utile.  Il y a une bonne concurrence pour √©valuer les mod√®les de reconnaissance - Megaface dessus, nous avons progressivement atteint 82% de rang 1. Le test Megaface se compose d'un million de photos - distracteurs - et le mod√®le devrait √™tre capable de bien distinguer plusieurs milliers de photos de c√©l√©brit√©s de l'ensemble de donn√©es Facescrub des distracteurs.  Cependant, apr√®s avoir effac√© le test d'erreurs Megaface, nous avons d√©couvert que sur la version nettoy√©e, nous atteignons une pr√©cision de 98% de rang 1 (les photos de c√©l√©brit√©s sont g√©n√©ralement assez sp√©cifiques).  Par cons√©quent, ils ont cr√©√© un test d'identification distinct, similaire √† Megaface, mais avec des photos de personnes ¬´ordinaires¬ª.  Am√©lior√© encore la pr√©cision de reconnaissance sur leurs ensembles de donn√©es et est all√© de l'avant.  De plus, nous utilisons le test de qualit√© de clustering, qui consiste en plusieurs milliers de photographies;  Il simule le balisage des visages dans le cloud de l'utilisateur.  Dans ce cas, les grappes sont des groupes d'individus similaires, un groupe pour chaque personne reconnaissable.  Nous avons v√©rifi√© la qualit√© du travail sur de vrais groupes (vrai). <br><br>  Bien s√ªr, tout mod√®le comporte des erreurs de reconnaissance.  Mais de telles situations sont souvent r√©solues en affinant les seuils pour des conditions sp√©cifiques (pour toutes les conf√©rences, nous utilisons les m√™mes seuils, et, par exemple, pour les ACS, nous devons augmenter consid√©rablement les seuils afin qu'il y ait moins de faux positifs).  La grande majorit√© des participants √† la conf√©rence ont √©t√© reconnus par nos supports photo Vision correctement.  Parfois, quelqu'un regardait l'aper√ßu recadr√© et disait: "Votre syst√®me √©tait faux, ce n'est pas moi."  Ensuite, nous avons ouvert la photo enti√®re, et il s'est av√©r√© que ce visiteur √©tait vraiment sur la photo, seulement ils ne l'ont pas prise, mais quelqu'un d'autre, juste un homme est apparu accidentellement en arri√®re-plan dans la zone floue.  De plus, le r√©seau neuronal reconna√Æt souvent correctement m√™me lorsqu'une partie du visage n'est pas visible, ou qu'une personne se tient de profil, ou m√™me la moiti√© du visage.  Le syst√®me peut reconna√Ætre une personne, m√™me si elle tombe dans le domaine de la distorsion optique, par exemple, lors de la prise de vue avec un objectif grand angle. <br><br><h3>  1.3.  Tester des exemples dans des situations difficiles </h3><br>  Voici des exemples de fonctionnement de notre r√©seau de neurones.  √Ä l'entr√©e, des photos sont soumises, qu'elle doit marquer √† l'aide de PersonID - un identifiant unique pour la personne.  Si deux images ou plus ont le m√™me identifiant, alors, selon les mod√®les, ces photos montrent une personne. <br><br>  Imm√©diatement, nous notons que pendant les tests, nous avons acc√®s √† divers param√®tres et seuils de mod√®les que nous pouvons configurer pour obtenir un r√©sultat particulier.  L'API publique est optimis√©e pour une pr√©cision maximale sur les cas courants. <br><br>  Commen√ßons par le plus simple, avec la reconnaissance faciale du visage. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/21e/973/ba9/21e973ba959f23ab2b8592e795fb8bcb.png"><br><br>  Eh bien, c'√©tait trop facile.  Nous compliquons la t√¢che, ajoutons une barbe et une poign√©e d'ann√©es. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/24e/a74/347/24ea7434773548d5dc23cdff03887b0f.png"><br><br>  Quelqu'un dira que cela n'a pas √©t√© trop difficile, car dans les deux cas, le visage est visible dans son int√©gralit√©, l'algorithme contient beaucoup d'informations sur le visage.  D'accord, mettez Tom Hardy en profil.  Cette t√¢che est beaucoup plus compliqu√©e et nous avons consacr√© beaucoup d'efforts √† sa solution r√©ussie tout en maintenant un faible niveau d'erreurs: nous avons s√©lectionn√© un √©chantillon d'entra√Ænement, r√©fl√©chi √† l'architecture du r√©seau de neurones, affin√© les fonctions de perte et am√©lior√© le traitement pr√©liminaire des photos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/df6/191/445/df619144560539d45c09176174349b9d.png"><br><br>  Mettons un chapeau sur lui: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/40c/2e5/48b/40c2e548b16ea8a2015b0b7f0ff53b62.png"><br><br>  Soit dit en passant, c'est un exemple d'une situation particuli√®rement difficile, car le visage est tr√®s couvert ici, et dans l'image inf√©rieure il y a aussi une ombre profonde qui cache les yeux.  Dans la vraie vie, les gens changent tr√®s souvent d'apparence √† l'aide de lunettes noires.  Faites de m√™me avec Tom. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/27e/792/5db/27e7925dbb402d2ba1957e812279de7c.png"><br><br>  Eh bien, essayons de t√©l√©charger des photos d'√¢ges diff√©rents, et cette fois, nous mettrons de l'exp√©rience sur un autre acteur.  Prenons un exemple beaucoup plus complexe lorsque les changements li√©s √† l'√¢ge sont particuli√®rement prononc√©s.  La situation n'est pas farfelue, elle arrive tout le temps lorsque vous devez comparer une photo de votre passeport avec le visage du porteur.  Apr√®s tout, la premi√®re photo est coinc√©e dans le passeport lorsque le propri√©taire a 20 ans et 45 personnes peuvent changer beaucoup: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/59f/d37/109/59fd37109369ee642fa75ff107be9726.png"><br><br>  Pensez-vous que la principale sp√©ciale sur les missions impossibles n'a pas beaucoup chang√© avec l'√¢ge?  Je pense que m√™me quelques personnes combineraient les photos du haut et du bas, le gar√ßon a tellement chang√© au fil des ans. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f3c/f57/20c/f3cf5720c2aeced56746035af7687531.png"><br><br>  Les r√©seaux de neurones sont confront√©s beaucoup plus souvent √† des changements d'apparence.  Par exemple, parfois, les femmes peuvent changer consid√©rablement leur image √† l'aide de cosm√©tiques: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e07/47e/c03/e0747ec033917573a028028e04a0cf24.png"><br><br>  Maintenant, compliquons encore la t√¢che: laissez diff√©rentes parties du visage couvertes par diff√©rentes photos.  Dans de tels cas, l'algorithme ne peut pas comparer les √©chantillons entiers.  Cependant, Vision g√®re bien ces situations. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f99/14b/600/f9914b600d274f8f29ecbd229e937e9e.png"><br><br>  Soit dit en passant, il y a beaucoup de visages sur les photos, par exemple, plus de 100 personnes peuvent s'inscrire dans une image commune de la salle.  C'est une situation difficile pour les r√©seaux de neurones, car de nombreux visages peuvent √™tre √©clair√©s diff√©remment, quelqu'un en dehors de la zone de nettet√©.  Cependant, si la photo a √©t√© prise avec une r√©solution et une qualit√© suffisantes (au moins 75 pixels par carr√© couvrant le visage), Vision pourra l'identifier et la reconna√Ætre. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/362/3a9/b8e/3623a9b8e23fd68b025f6bc9c81f22d2.png"><br><br>  La particularit√© de rapporter des photographies et des images provenant de cam√©ras de surveillance est que les gens sont souvent flous parce qu'ils √©taient hors du champ de nettet√© ou se d√©pla√ßaient √† ce moment: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/819/db8/c4e/819db8c4e234677690cfc86c7be73a02.png"><br><br>  De plus, l'intensit√© de l'√©clairage peut varier consid√©rablement d'une image √† l'autre.  Cela se transforme √©galement souvent en une pierre d'achoppement, de nombreux algorithmes ont beaucoup de mal √† traiter correctement des images trop sombres et trop claires, sans parler de la comparaison exacte.  Permettez-moi de vous rappeler que pour atteindre un tel r√©sultat, vous devez d√©finir des seuils d'une certaine mani√®re, cette possibilit√© n'est pas encore accessible au public.  Pour tous les clients, nous utilisons le m√™me r√©seau de neurones, il a des seuils adapt√©s √† la plupart des t√¢ches pratiques. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db0/423/6a3/db04236a312641cc7ed888bc279cbf66.png"><br><br>  R√©cemment, nous avons d√©ploy√© une nouvelle version du mod√®le qui reconna√Æt les visages asiatiques avec une grande pr√©cision.  Auparavant, c'√©tait un gros probl√®me, qui √©tait m√™me appel√© "racisme d'apprentissage machine" (ou "r√©seaux de neurones").  Les r√©seaux de neurones europ√©ens et am√©ricains ont bien reconnu les visages europ√©ens, et les choses √©taient bien pires avec ceux mongolo√Ødes et n√©gro√Ødes.  Probablement dans la m√™me Chine, la situation √©tait exactement le contraire.  Il s'agit de jeux de donn√©es de formation qui refl√®tent les types de personnes dominantes dans un pays particulier.  Cependant, la situation √©volue, aujourd'hui ce probl√®me est loin d'√™tre aussi aigu.  La vision n'a pas de difficult√©s avec les repr√©sentants des diff√©rentes races. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/be8/750/da9/be8750da9407b7ca4c2cd11dac314ef3.png"><br><br>  La reconnaissance faciale n'est qu'une des nombreuses applications de notre technologie, la vision peut apprendre √† reconna√Ætre n'importe quoi.  Par exemple, les num√©ros de voiture, y compris dans des conditions difficiles pour les algorithmes: √† des angles aigus, des num√©ros sales et difficiles √† lire. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b22/ddb/39d/b22ddb39d2fe119db6eb50db37df829b.png"><br><br><h1>  2. Cas d'utilisation pratiques </h1><br><h3>  2.1.  Contr√¥le d'acc√®s physique: lorsque deux vont sur le m√™me col </h3><br>  Avec l'aide de Vision, il est possible de mettre en place des syst√®mes comptables pour l'arriv√©e et le d√©part des employ√©s.  Un syst√®me traditionnel bas√© sur des laissez-passer √©lectroniques pr√©sente des inconv√©nients √©vidents, par exemple, vous pouvez passer deux badges ensemble.  Si le syst√®me de contr√¥le d'acc√®s (ACS) est compl√©t√© par Vision, il enregistrera honn√™tement qui va et vient quand. <br><br><h3>  2.2.  Suivi du temps </h3><br>  Ce cas d'utilisation de Vision est √©troitement li√© au pr√©c√©dent.  Si nous compl√©tons le syst√®me de contr√¥le d'acc√®s avec notre service de reconnaissance faciale, il pourra non seulement constater les violations du contr√¥le d'acc√®s, mais √©galement enregistrer le s√©jour r√©el des employ√©s dans le b√¢timent ou dans l'√©tablissement.  En d'autres termes, Vision aidera √† consid√©rer honn√™tement qui et combien sont venus travailler et sont partis avec elle, et qui ont m√™me saut√©, m√™me si ses coll√®gues l'ont couvert devant ses sup√©rieurs. <br><br><h3>  2.3.  Analyse vid√©o: suivi et s√©curit√© des personnes </h3><br>  En suivant les personnes √† l'aide de Vision, vous pouvez √©valuer avec pr√©cision la perm√©abilit√© r√©elle des zones commer√ßantes, des gares, des passages √† niveau, des rues et de nombreux autres lieux publics.  Notre suivi peut √©galement √™tre tr√®s utile pour contr√¥ler l'acc√®s, par exemple, √† un entrep√¥t ou √† d'autres locaux de bureaux importants.  Et bien s√ªr, le suivi des personnes et des visages permet de r√©soudre les probl√®mes de s√©curit√©.  Vous avez surpris quelqu'un en train de voler dans votre magasin?  Ajoutez-le au PersonID, qui a renvoy√© Vision, dans la liste noire de votre logiciel d'analyse vid√©o, et la prochaine fois que le syst√®me alertera imm√©diatement la s√©curit√© si ce type r√©appara√Æt. <br><br><h3>  2.4.  Dans le commerce </h3><br>  Les commerces de d√©tail et divers services sont int√©ress√©s par la reconnaissance des files d'attente.  En utilisant Vision, vous pouvez reconna√Ætre qu'il ne s'agit pas d'une foule al√©atoire de personnes, mais plut√¥t d'une file d'attente, et d√©terminer sa longueur.  Et puis le syst√®me informe les personnes responsables de la file d'attente afin de comprendre la situation: soit c'est un afflux de visiteurs et des employ√©s suppl√©mentaires doivent √™tre appel√©s, soit quelqu'un pirate ses responsabilit√©s professionnelles. <br><br>  Une autre t√¢che int√©ressante est la s√©paration des employ√©s de l'entreprise dans le hall des visiteurs.  En r√®gle g√©n√©rale, le syst√®me apprend √† s√©parer les objets dans certains v√™tements (code vestimentaire) ou avec une caract√©ristique distinctive (√©charpe signature, badge sur la poitrine, etc.).  Cela permet d'√©valuer plus pr√©cis√©ment la fr√©quentation (afin que les employ√©s ne ¬´remontent¬ª pas √† eux seuls les statistiques des personnes pr√©sentes dans la salle). <br><br>  Gr√¢ce √† la reconnaissance faciale, vous pouvez √©valuer votre public: quelle est la fid√©lit√© des visiteurs, c'est-√†-dire combien de personnes reviennent dans votre √©tablissement et √† quelle fr√©quence.  Calculez le nombre de visiteurs uniques qui viennent vous voir en un mois.  Pour optimiser les co√ªts d'attraction et de r√©tention, vous pouvez conna√Ætre et changer la fr√©quentation en fonction du jour de la semaine et m√™me de l'heure. <br><br>  Les franchiseurs et les soci√©t√©s de r√©seau peuvent demander une √©valuation de la qualit√© de l'image de marque de divers points de vente √† partir de photographies: la pr√©sence de logos, d'enseignes, d'affiches, de banni√®res, etc. <br><br><h3>  2.5.  Sur le transport </h3><br>  Un autre exemple de s√©curit√© gr√¢ce √† l'analyse vid√©o est l'identification des objets laiss√©s dans les halls des a√©roports ou des gares.  La vision peut √™tre form√©e pour reconna√Ætre des objets de centaines de classes: meubles, sacs, valises, parapluies, diff√©rents types de v√™tements, bouteilles, etc.  Si votre syst√®me d'analyse vid√©o d√©tecte un objet sans propri√©taire et le reconna√Æt √† l'aide de Vision, il envoie un signal au service de s√©curit√©.  Une t√¢che similaire est li√©e √† la d√©tection automatique des situations non standard dans les lieux publics: quelqu'un est tomb√© malade, ou quelqu'un a fum√© au mauvais endroit, ou la personne est tomb√©e sur les rails, etc. - tous ces mod√®les du syst√®me d'analyse vid√©o peuvent reconna√Ætre gr√¢ce √† l'API Vision. <br><br><h3>  2.6.  Workflow </h3><br>  Une autre future application int√©ressante de Vision que nous d√©veloppons actuellement est la reconnaissance de documents et leur analyse automatique dans des bases de donn√©es.  Au lieu de conduire manuellement (ou pire encore, d'entrer) des s√©ries, des num√©ros, des dates d'√©mission, des num√©ros de compte, des coordonn√©es bancaires, des dates et des lieux de naissance sans fin et de nombreuses autres donn√©es formalis√©es, vous pouvez num√©riser des documents et les envoyer automatiquement via un canal s√©curis√© via l'API dans le cloud, o√π le syst√®me sera √† la vol√©e, ces documents seront reconnus, analys√©s et renverront une r√©ponse avec des donn√©es au format souhait√© pour une entr√©e automatique dans la base de donn√©es.  Aujourd'hui, Vision sait d√©j√† comment classer les documents (y compris en PDF) - il distingue les passeports, les SNILS, les TIN, les certificats de naissance, les certificats de mariage et autres. <br><br>  Bien s√ªr, toutes ces situations que le r√©seau neuronal n'est pas en mesure de g√©rer hors de la bo√Æte.  Dans chaque cas, un nouveau mod√®le est construit pour un client particulier, de nombreux facteurs, nuances et exigences sont pris en compte, les ensembles de donn√©es sont s√©lectionn√©s, les param√®tres de test de formation sont it√©r√©s. <br><br><h1>  3. Sch√©ma de fonctionnement de l'API </h1><br>  La ¬´porte d'entr√©e¬ª de Vision pour les utilisateurs est l'API REST.  √Ä l'entr√©e, il peut prendre des photos, des fichiers vid√©o et des √©missions √† partir de cam√©ras r√©seau (flux RTSP). <br><br>  Pour utiliser Vision, vous devez vous <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">inscrire</a> dans Mail.ru Cloud Solutions et obtenir des jetons d'acc√®s (client_id + client_secret).  L'authentification des utilisateurs est effectu√©e √† l'aide du protocole OAuth.  Les donn√©es source dans les corps des requ√™tes POST sont envoy√©es √† l'API.  Et en r√©ponse, le client re√ßoit le r√©sultat de la reconnaissance de l'API au format JSON, et la r√©ponse est structur√©e: elle contient des informations sur les objets trouv√©s et leurs coordonn√©es. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d8c/bc3/859/d8cbc3859777f8f0a40712ef8e8a4e17.png"><br><br><div class="spoiler">  <b class="spoiler_title">Exemple de r√©ponse</b> <div class="spoiler_text"><pre><code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">200</span></span>, <span class="hljs-attr"><span class="hljs-attr">"body"</span></span>:{ <span class="hljs-attr"><span class="hljs-attr">"objects"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_0"</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_2"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person9"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">149</span></span>,<span class="hljs-number"><span class="hljs-number">60</span></span>,<span class="hljs-number"><span class="hljs-number">234</span></span>,<span class="hljs-number"><span class="hljs-number">181</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9999</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.45</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person10"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">159</span></span>,<span class="hljs-number"><span class="hljs-number">70</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">171</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9998</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.32</span></span> } ] } { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_3"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"person11"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">157</span></span>,<span class="hljs-number"><span class="hljs-number">60</span></span>,<span class="hljs-number"><span class="hljs-number">232</span></span>,<span class="hljs-number"><span class="hljs-number">111</span></span>], <span class="hljs-attr"><span class="hljs-attr">"aliases"</span></span>:[<span class="hljs-string"><span class="hljs-string">"person12"</span></span>, <span class="hljs-string"><span class="hljs-string">"person13"</span></span>] <span class="hljs-string"><span class="hljs-string">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9998</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.32</span></span> } ] }, { <span class="hljs-attr"><span class="hljs-attr">"status"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>:<span class="hljs-string"><span class="hljs-string">"file_4"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"persons"</span></span>:[ { <span class="hljs-attr"><span class="hljs-attr">"tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"undefined"</span></span> <span class="hljs-string"><span class="hljs-string">"coord"</span></span>:[<span class="hljs-number"><span class="hljs-number">147</span></span>,<span class="hljs-number"><span class="hljs-number">50</span></span>,<span class="hljs-number"><span class="hljs-number">222</span></span>,<span class="hljs-number"><span class="hljs-number">121</span></span>], <span class="hljs-attr"><span class="hljs-attr">"confidence"</span></span>:<span class="hljs-number"><span class="hljs-number">0.9997</span></span>, <span class="hljs-attr"><span class="hljs-attr">"awesomeness"</span></span>:<span class="hljs-number"><span class="hljs-number">0.26</span></span> } ] } ], <span class="hljs-attr"><span class="hljs-attr">"aliases_changed"</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span> }, <span class="hljs-attr"><span class="hljs-attr">"htmlencoded"</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span>, <span class="hljs-attr"><span class="hljs-attr">"last_modified"</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span> }</code> </pre> <br></div></div><br>  La r√©ponse a un param√®tre g√©nial int√©ressant - c'est la ¬´fra√Æcheur¬ª conditionnelle du visage sur la photo, avec elle nous s√©lectionnons le meilleur visage tir√© de la s√©quence.  Nous avons form√© le r√©seau neuronal pour pr√©dire la probabilit√© que l'image ressemble √† celle des r√©seaux sociaux.  Plus la photo est bonne et plus le visage est lisse, plus la g√©nialit√© est grande. <br><br>  L'API Vision utilise un concept tel que l'espace.  Il s'agit d'un outil pour cr√©er diff√©rents ensembles de faces.  Des exemples d'espaces sont des listes noires et blanches, des listes de visiteurs, d'employ√©s, de clients, etc. Pour chaque jeton dans Vision, vous pouvez cr√©er jusqu'√† 10 espaces, dans chaque espace, il peut y avoir jusqu'√† 50 000 PersonID, c'est-√†-dire jusqu'√† 500 000 pour un jeton. .  De plus, le nombre de jetons par compte n'est pas limit√©. <br><br>  Aujourd'hui, l'API prend en charge les m√©thodes de d√©tection et de reconnaissance suivantes: <br><br><ul><li>  Reconna√Ætre / D√©finir - d√©finition et reconnaissance des visages.  Attribue automatiquement un PersonID √† chaque visage unique, renvoie le PersonID et les coordonn√©es des visages trouv√©s. <br></li><li>  Supprimer - supprime un PersonID sp√©cifique de la base de donn√©es des personnes. <br></li><li>  Tronquer - effacer tout l'espace de PersonID, utile s'il a √©t√© utilis√© comme test et que vous devez r√©initialiser la base de production. <br></li><li>  D√©tecter - d√©finition des objets, sc√®nes, plaques d'immatriculation, attractions, files d'attente, etc. Renvoie la classe des objets trouv√©s et leurs coordonn√©es <br></li><li>  D√©tecter pour les documents - d√©tecte des types sp√©cifiques de documents de la F√©d√©ration de Russie (distingue passeport, snls, auberge, etc.). <br></li></ul><br>  En outre, nous terminerons bient√¥t les travaux sur les m√©thodes d'OCR, d√©terminant le sexe, l'√¢ge et les √©motions, ainsi que la r√©solution des t√¢ches de marchandisage, c'est-√†-dire de contr√¥ler automatiquement l'affichage des marchandises dans les magasins.  Vous pouvez trouver la documentation compl√®te de l'API ici: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://mcs.mail.ru/help/vision-api</a> <br><br><h1>  4. Conclusion </h1><br>  Maintenant, via l'API publique, vous pouvez acc√©der √† la reconnaissance faciale dans les photos et les vid√©os, elle prend en charge la d√©finition de divers objets, num√©ros de voiture, attractions, documents et sc√®nes enti√®res.  Sc√©narios d'application - Mer.  Venez tester notre service, d√©finissez-lui les t√¢ches les plus d√©licates.  Les 5000 premi√®res transactions sont gratuites.  Ce peut √™tre ¬´l'ingr√©dient manquant¬ª pour vos projets. <br><br>  L'acc√®s √† l'API peut √™tre obtenu instantan√©ment lors de l'inscription et de la connexion √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vision</a> .  Tous les utilisateurs Habra - un code promotionnel pour des transactions suppl√©mentaires.  √âcrivez une adresse e-mail personnelle √† laquelle le compte a √©t√© enregistr√©! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr449120/">https://habr.com/ru/post/fr449120/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr449108/index.html">UDB. Qu'est-ce que c'est? Partie 7. Module de commande de temporisation et de r√©initialisation</a></li>
<li><a href="../fr449110/index.html">Correction d'un bug li√© √† l'impossibilit√© d'utiliser l'alphabet cyrillique dans les noms des dossiers IMAP</a></li>
<li><a href="../fr449112/index.html">Nous avons pris notre retraite - nous discutons de gadgets audio autrefois populaires qui sont d√©j√† "obsol√®tes"</a></li>
<li><a href="../fr449114/index.html">R√©agissez sur Œªambda</a></li>
<li><a href="../fr449118/index.html">Pilule d√©moniaque du Kremlin</a></li>
<li><a href="../fr449122/index.html">Regrettant l'absence en C ++ d'une statique √† part enti√®re si ou ...</a></li>
<li><a href="../fr449124/index.html">Si difficile √† trouver, facile √† manquer et impossible √† √©mettre</a></li>
<li><a href="../fr449128/index.html">Les meilleures entreprises de d√©veloppement de jeux dans le monde</a></li>
<li><a href="../fr449132/index.html">Top 17 des plugins pour Android Studio</a></li>
<li><a href="../fr449134/index.html">Zoo afl</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚍 😥 ☔️ SpaceFusion: estructurando el espacio latente no estructurado para la IA conversacional 💓 🙋🏻 😖</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Una paleta facilita a los pintores organizar y mezclar pinturas de diferentes colores a medida que crean arte en el lienzo que tienen delante. Tener u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>SpaceFusion: estructurando el espacio latente no estructurado para la IA conversacional</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/474234/">  Una paleta facilita a los pintores organizar y mezclar pinturas de diferentes colores a medida que crean arte en el lienzo que tienen delante.  Tener una herramienta similar que permita a AI aprender conjuntamente de diversas fuentes de datos, como las de conversaciones, narrativas, imágenes y conocimiento, podría abrir puertas para que investigadores y científicos desarrollen sistemas de IA capaces de una inteligencia más general. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/f0b/24b/8c9/f0b24b8c99c1f60f6bb9dbf9f70e9aee.jpg"></a> <br>  <i>Una paleta le permite al pintor organizar y mezclar pinturas de diferentes colores.</i>  <i>SpaceFusion busca ayudar a los científicos de IA a hacer cosas similares para diferentes modelos entrenados en diferentes conjuntos de datos.</i> <a name="habracut"></a><br><br>  Para los modelos de aprendizaje profundo en la actualidad, los conjuntos de datos generalmente están representados por vectores en diferentes espacios latentes utilizando diferentes redes neuronales.  En el documento " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Optimización conjunta de la diversidad y la relevancia en la generación de respuesta neuronal</a> ", mis coautores y yo proponemos SpaceFusion, un paradigma de aprendizaje para alinear estos diferentes espacios latentes, organizarlos y mezclarlos suavemente como la pintura en una paleta, para que la IA pueda aprovechar Los patrones y el conocimiento incrustado en cada uno de ellos.  Este trabajo, que presentamos en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conferencia Anual 2019 del Capítulo de América del Norte de la Asociación de Lingüística Computacional: Tecnologías del Lenguaje Humano (NAACL-HLT)</a> , es parte del proyecto de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conversación Dirigida por Datos</a> , y su implementación es disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GitHub</a> . <br><br><h3>  Capturando el color de la conversación humana. </h3><br>  Como primer intento, aplicamos esta técnica a la IA neuronal conversacional.  En nuestra configuración, se espera que un modelo neuronal genere respuestas relevantes e interesantes dado un historial de conversación o contexto.  Si bien se han realizado avances prometedores en los modelos de conversación neuronal, estos modelos tienden a ser seguros, produciendo respuestas genéricas y aburridas.  Se han desarrollado enfoques para diversificar estas respuestas y capturar mejor el color de la conversación humana, pero a menudo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">hay una compensación, con una disminución de la relevancia</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/fbf/cf5/d8e/fbfcf5d8e666dc0a7785c937d4cbd3a9.jpg"></a> <br>  <i>Figura 1: al igual que una paleta permite la combinación fácil de pinturas, SpaceFusion alinea o mezcla, los espacios latentes aprendidos de un modelo secuencia a secuencia (S2S, puntos rojos) y un autoencoder (AE, puntos azules) para utilizar conjuntamente Los dos modelos más eficientemente.</i> <br><br>  SpaceFusion aborda este problema alineando los espacios latentes aprendidos de dos modelos (Figura 1): <br><br><ul><li>  un modelo de secuencia a secuencia (S2S), cuyo objetivo es producir respuestas relevantes, pero puede carecer de diversidad;  y </li><li>  un modelo de autoencoder (AE), que es capaz de representar diversas respuestas, pero no captura su relación con la conversación. </li></ul><br>  El modelo aprendido conjuntamente puede utilizar las fortalezas de ambos modelos y organizar los puntos de datos de una manera más estructurada. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/00e/b5e/6e6/00eb5e6e6f37deb6e1cfd1afb6fa5a4f.png"></a> <br>  <i>Figura 2: lo anterior ilustra un contexto y sus múltiples respuestas en el espacio latente inducido por SpaceFusion.</i>  <i>La distancia y la dirección del vector de respuesta previsto dado el contexto coinciden aproximadamente con la relevancia y la diversidad, respectivamente.</i> <br><br>  Por ejemplo, como se ilustra en la Figura 2, dado un contexto, en este caso, "¿Alguien quiere comenzar este juego?", Las respuestas positivas "Me encantaría jugarlo" y "Sí, lo hago" están organizadas a lo largo del misma direccion.  Los negativos, "No estoy interesado en el juego" y "No, no", se asignan en una línea en otra dirección.  La diversidad en las respuestas se logra explorando el espacio latente a lo largo de diferentes direcciones.  Además, la distancia en el espacio latente corresponde a la relevancia.  Las respuestas más alejadas del contexto ("Sí, lo hago" y "No, no lo hago") suelen ser genéricas, mientras que las más cercanas son más relevantes para el contexto específico: "No estoy interesado en el juego" y " ¿Cuándo lo harás? <br><br>  SpaceFusion separa los criterios de relevancia y diversidad y los representa en dos dimensiones independientes: dirección y distancia, lo que facilita la optimización conjunta de ambos.  Nuestros experimentos empíricos y la evaluación en humanos han demostrado que SpaceFusion funciona mejor en estos dos criterios en comparación con las líneas de base competitivas. <br><br><h3>  Aprendiendo un espacio latente compartido </h3><br>  Entonces, ¿cómo exactamente SpaceFusion alinea diferentes espacios latentes? <br><br>  La idea es bastante intuitiva: para cada par de puntos de dos espacios latentes diferentes, primero minimizamos su distancia en el espacio latente compartido y luego fomentamos una transición suave entre ellos.  Esto se realiza mediante la adición de dos nuevos términos de regularización - término de distancia y término de suavidad - a la función objetivo. <br><br>  Tomando como ejemplo la conversación, el término distancia mide la distancia euclidiana entre un punto del espacio latente S2S, que se mapea desde el contexto y representa la respuesta pronosticada, y los puntos del espacio latente AE, que corresponden a sus respuestas objetivo.  Minimizar dicha distancia alienta al modelo S2S a mapear el contexto a un punto cercano y rodeado por sus respuestas en el espacio latente compartido, como se ilustra en la Figura 2. <br><br>  El término suavidad mide la probabilidad de generar la respuesta objetivo a partir de una interpolación aleatoria entre el punto mapeado desde el contexto y el mapeado desde la respuesta.  Al maximizar esta probabilidad, fomentamos una transición suave del significado de las respuestas generadas a medida que nos alejamos del contexto.  Esto nos permite explorar la vecindad del punto de predicción realizado por el S2S y generar respuestas diversas que son relevantes para el contexto. <br><br>  Con estas dos nuevas regularizaciones agregadas en la función objetivo, ponemos las restricciones de distancia y suavidad en el aprendizaje del espacio latente, por lo que la capacitación no solo se centrará en el rendimiento en cada espacio latente, sino que también intentaremos alinearlas agregando estas estructuras deseadas  Nuestro trabajo se centró en modelos conversacionales, pero esperamos que SpaceFusion pueda alinear los espacios latentes aprendidos por otros modelos entrenados en diferentes conjuntos de datos.  Esto hace posible unir diferentes habilidades y dominios de conocimiento aprendidos por cada sistema de IA específico y es un pequeño paso hacia una inteligencia más general. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/474234/">https://habr.com/ru/post/474234/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../474224/index.html">Kotlin vs. Swift: ¿Android e iOS avanzan hacia un lenguaje universal?</a></li>
<li><a href="../474226/index.html">Introduciendo Orleans 3.0</a></li>
<li><a href="../474228/index.html">Una licencia de proyecto de código abierto que requiere que los usuarios "no hagan daño"</a></li>
<li><a href="../474230/index.html">9 proyectos más para perfeccionar las habilidades de front-end</a></li>
<li><a href="../474232/index.html">Cómo mejorar tus habilidades de escritura con gramática</a></li>
<li><a href="../474238/index.html">Conversaciones en conferencia: 8 horas de teoría y práctica de IA conversacional</a></li>
<li><a href="../474240/index.html">Orleans 3.0 lanzado</a></li>
<li><a href="../474244/index.html">SpaceFusion: Estructuración de espacio oculto no estructurado para IA interactiva</a></li>
<li><a href="../474246/index.html">JavaScript Meetup SuperJob: Informe de video</a></li>
<li><a href="../474250/index.html">VPN en cada hogar o cómo domar al Dragón</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
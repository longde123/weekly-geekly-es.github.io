<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏼‍🔧 🤳🏻 🧤 Menulis penyeimbang sederhana di Go 👩🏽‍🚀 🧜🏿 🚓</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Load balancers memainkan peran penting dalam arsitektur web. Mereka memungkinkan Anda untuk mendistribusikan beban di beberapa backend, sehingga menin...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Menulis penyeimbang sederhana di Go</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/476276/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t8/nm/ze/t8nmzevaswfyxtitu7xpx3ml-ho.jpeg"></div><br>  Load balancers memainkan peran penting dalam arsitektur web.  Mereka memungkinkan Anda untuk mendistribusikan beban di beberapa backend, sehingga meningkatkan skalabilitas.  Dan karena kami memiliki beberapa backend yang dikonfigurasi, layanan menjadi sangat tersedia, karena jika terjadi kegagalan pada satu server, penyeimbang dapat memilih server lain yang berfungsi. <br><br>  Setelah bermain dengan penyeimbang profesional seperti NGINX, saya mencoba membuat penyeimbang sederhana untuk bersenang-senang.  Saya menulisnya di Go, itu adalah bahasa modern yang mendukung paralelisme penuh.  Pustaka standar di Go memiliki banyak fitur dan memungkinkan Anda untuk menulis aplikasi berkinerja tinggi dengan kode lebih sedikit.  Selain itu, untuk kemudahan distribusi, ini menghasilkan biner tunggal yang terhubung secara statis. <br><a name="habracut"></a><br><h2>  Cara kerja penyeimbang kami </h2><br>  Algoritma yang berbeda digunakan untuk mendistribusikan beban di antara backend.  Sebagai contoh: <br><br><ul><li>  Round Robin - beban didistribusikan secara merata, dengan mempertimbangkan kekuatan komputasi yang sama dari server. </li><li>  Robin Round Tertimbang - Tergantung pada kekuatan pemrosesan, server dapat diberi bobot yang berbeda. </li><li>  Least Connections - beban didistribusikan di seluruh server dengan paling sedikit koneksi aktif. </li></ul><br>  Di penyeimbang kami, kami menerapkan algoritma paling sederhana - Round Robin. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b3e/35c/751/b3e35c7510dc44451088756d14739161.png"></div><br><br><h2>  Seleksi di Round Robin </h2><br>  Algoritma Round Robin sederhana.  Ini memberi semua pemain kesempatan yang sama untuk menyelesaikan tugas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3b3/4a7/861/3b34a78610b7c1e2d22b85f0419700d2.png"></div><br>  <i>Pilih server di Round Robin untuk menangani permintaan yang masuk.</i> <br><br>  Seperti yang ditunjukkan dalam ilustrasi, algoritma memilih server dalam lingkaran, secara siklis.  Tetapi kita tidak dapat memilihnya secara <i>langsung</i> , bukan? <br><br>  Dan jika server berbohong?  Kami mungkin tidak perlu mengirimkan lalu lintas ke sana.  Artinya, server tidak dapat digunakan secara langsung sampai kami membawanya ke keadaan yang diinginkan.  Hal ini diperlukan untuk mengarahkan lalu lintas hanya ke server-server yang aktif dan berjalan. <br><br><h2>  Tentukan strukturnya </h2><br>  Kita perlu melacak semua detail yang terkait dengan backend.  Anda perlu tahu apakah dia masih hidup, dan melacak URL.  Untuk melakukan ini, kita dapat mendefinisikan struktur berikut: <br><br><pre><code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">type</span></span> Backend <span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> { URL *url.URL Alive <span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> mux sync.RWMutex ReverseProxy *httputil.ReverseProxy }</code> </pre> <br>  Jangan khawatir, saya akan menjelaskan arti bidang di Backend. <br><br>  Sekarang di balancer Anda perlu melacak semua backend.  Untuk melakukan ini, Anda bisa menggunakan Slice dan penghitung variabel.  Definisikan di ServerPool: <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">type</span></span> ServerPool <span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> { backends []*Backend current <span class="hljs-keyword"><span class="hljs-keyword">uint64</span></span> }</code> </pre> <br><h2>  Menggunakan ReverseProxy </h2><br>  Seperti yang telah kami tentukan, esensi dari penyeimbang adalah dalam mendistribusikan lalu lintas ke server yang berbeda dan mengembalikan hasil kepada klien.  Seperti yang dijelaskan dalam dokumentasi Go: <br><br>  <i>ReverseProxy adalah penangan HTTP yang menerima permintaan masuk dan mengirimkannya ke server lain, mem-proxy tanggapan kembali ke klien.</i> <br><br>  Tepat seperti yang kita butuhkan.  Tidak perlu menemukan kembali roda.  Anda cukup mengalirkan permintaan kami melalui <code>ReverseProxy</code> . <br><br><pre> <code class="go hljs">u, _ := url.Parse(<span class="hljs-string"><span class="hljs-string">"http://localhost:8080"</span></span>) rp := httputil.NewSingleHostReverseProxy(u) <span class="hljs-comment"><span class="hljs-comment">// initialize your server and add this as handler http.HandlerFunc(rp.ServeHTTP)</span></span></code> </pre> <br>  Menggunakan <code>httputil.NewSingleHostReverseProxy(url)</code> Anda dapat menginisialisasi <code>ReverseProxy</code> , yang akan menyiarkan permintaan ke <code>url</code> diteruskan.  Dalam contoh di atas, semua permintaan dikirim ke localhost: 8080, dan hasilnya dikirim ke klien. <br><br>  Jika Anda melihat tanda tangan dari metode ServeHTTP, maka Anda dapat menemukan tanda tangan dari penangan HTTP di dalamnya.  Oleh karena itu, Anda dapat meneruskannya ke <code>HandlerFunc</code> di <code>http</code> . <br><br>  Contoh lain ada di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=https://golang.org/pkg/net/http/">dokumentasi</a> . <br><br>  Untuk penyeimbang kami, Anda dapat memulai <code>ReverseProxy</code> dengan <code>URL</code> terkait di <code>Backend</code> sehingga ReverseProxy merutekan permintaan ke <code>URL</code> . <br><br><h2>  Proses pemilihan server </h2><br>  Selama pemilihan server berikutnya, kita perlu melewati server yang mendasarinya.  Tetapi Anda perlu mengatur penghitungan. <br><br>  Banyak klien akan terhubung ke penyeimbang, dan ketika masing-masing dari mereka meminta node berikutnya untuk mentransfer lalu lintas, kondisi balapan dapat terjadi.  Untuk mencegah hal ini, kita dapat memblokir <code>ServerPool</code> dengan <code>mutex</code> .  Tapi itu akan mubazir, selain itu kita tidak ingin memblokir <code>ServerPool</code> .  Kami hanya perlu menambah penghitung satu per satu. <br><br>  Solusi terbaik untuk memenuhi persyaratan ini adalah peningkatan atom.  Go mendukungnya dengan paket <code>atomic</code> . <br><br><pre> <code class="go hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s *ServerPool)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">NextIndex</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">int</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>(atomic.AddUint64(&amp;s.current, <span class="hljs-keyword"><span class="hljs-keyword">uint64</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>)) % <span class="hljs-keyword"><span class="hljs-keyword">uint64</span></span>(<span class="hljs-built_in"><span class="hljs-built_in">len</span></span>(s.backends))) }</code> </pre> <br>  Kami secara atomik meningkatkan nilai saat ini dengan satu dan mengembalikan indeks dengan mengubah panjang array.  Ini berarti bahwa nilai harus selalu berada pada rentang dari 0 hingga panjang array.  Pada akhirnya, kami akan tertarik pada indeks tertentu, bukan seluruh penghitung. <br><br><h2>  Memilih server langsung </h2><br>  Kami sudah tahu bahwa permintaan kami diputar secara siklis di semua server.  Dan kita hanya perlu melewati idle. <br><br>  <code>GetNext()</code> selalu mengembalikan nilai mulai dari 0 hingga panjang array.  Kapan saja, kita bisa mendapatkan node berikutnya, dan jika tidak aktif, kita perlu mencari lebih jauh melalui array sebagai bagian dari loop. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9c1/7a7/fc5/9c17a7fc56f9bf6c9e4583c29127aa55.png"></div><br>  <i>Kami mengulang melalui array.</i> <br><br>  Seperti yang ditunjukkan dalam ilustrasi, kami ingin beralih dari simpul berikutnya ke akhir daftar.  Ini bisa dilakukan menggunakan <code>next + length</code> .  Tetapi untuk memilih indeks, Anda harus membatasi itu ke panjang array.  Ini dapat dengan mudah dilakukan menggunakan operasi modifikasi. <br><br>  Setelah kami menemukan server yang berfungsi selama pencarian, itu harus ditandai sebagai saat ini: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// GetNextPeer returns next active peer to take a connection func (s *ServerPool) GetNextPeer() *Backend { // loop entire backends to find out an Alive backend next := s.NextIndex() l := len(s.backends) + next // start from next and move a full cycle for i := next; i &lt; l; i++ { idx := i % len(s.backends) // take an index by modding with length // if we have an alive backend, use it and store if its not the original one if s.backends[idx].IsAlive() { if i != next { atomic.StoreUint64(&amp;s.current, uint64(idx)) // mark the current one } return s.backends[idx] } } return nil }</span></span></code> </pre><br><h2>  Menghindari kondisi balapan di struktur Backend </h2><br>  Di sini Anda perlu mengingat masalah penting.  Struktur <code>Backend</code> berisi variabel yang beberapa goroutine dapat modifikasi atau kueri secara bersamaan. <br><br>  Kita tahu bahwa goroutine akan membaca variabel lebih dari menulis padanya.  Oleh karena itu, untuk membuat serial akses ke <code>Alive</code> kami memilih <code>RWMutex</code> . <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// SetAlive for this backend func (b *Backend) SetAlive(alive bool) { b.mux.Lock() b.Alive = alive b.mux.Unlock() } // IsAlive returns true when backend is alive func (b *Backend) IsAlive() (alive bool) { b.mux.RLock() alive = b.Alive b.mux.RUnlock() return }</span></span></code> </pre><br><h2>  Menyeimbangkan permintaan </h2><br>  Sekarang kita dapat merumuskan metode sederhana untuk menyeimbangkan permintaan kita.  Ini akan gagal hanya jika semua server jatuh. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// lb load balances the incoming request func lb(w http.ResponseWriter, r *http.Request) { peer := serverPool.GetNextPeer() if peer != nil { peer.ReverseProxy.ServeHTTP(w, r) return } http.Error(w, "Service not available", http.StatusServiceUnavailable) }</span></span></code> </pre> <br>  Metode ini dapat diteruskan ke server HTTP hanya sebagai <code>HandlerFunc</code> . <br><br><pre> <code class="go hljs">server := http.Server{ Addr: fmt.Sprintf(<span class="hljs-string"><span class="hljs-string">":%d"</span></span>, port), Handler: http.HandlerFunc(lb), }</code> </pre><br><h2>  Kami merutekan lalu lintas hanya ke server yang berjalan </h2><br>  Penyeimbang kami memiliki masalah serius.  Kami tidak tahu apakah server sedang berjalan.  Untuk mengetahuinya, Anda perlu memeriksa server.  Ada dua cara untuk melakukan ini: <br><br><ul><li>  Aktif: menjalankan permintaan saat ini, kami menemukan bahwa server yang dipilih tidak merespons, dan menandainya sebagai siaga. </li><li>  Pasif: Anda dapat melakukan ping server pada beberapa interval dan memeriksa status. </li></ul><br><h2>  Secara aktif memeriksa server yang sedang berjalan </h2><br>  Jika ada kesalahan <code>ReverseProxy</code> memulai fungsi callback <code>ErrorHandler</code> .  Ini dapat digunakan untuk mendeteksi kegagalan: <br><br><pre> <code class="go hljs">proxy.ErrorHandler = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(writer http.ResponseWriter, request *http.Request, e error)</span></span></span></span> { log.Printf(<span class="hljs-string"><span class="hljs-string">"[%s] %s\n"</span></span>, serverUrl.Host, e.Error()) retries := GetRetryFromContext(request) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> retries &lt; <span class="hljs-number"><span class="hljs-number">3</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">select</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> &lt;-time.After(<span class="hljs-number"><span class="hljs-number">10</span></span> * time.Millisecond): ctx := context.WithValue(request.Context(), Retry, retries+<span class="hljs-number"><span class="hljs-number">1</span></span>) proxy.ServeHTTP(writer, request.WithContext(ctx)) } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-comment"><span class="hljs-comment">// after 3 retries, mark this backend as down serverPool.MarkBackendStatus(serverUrl, false) // if the same request routing for few attempts with different backends, increase the count attempts := GetAttemptsFromContext(request) log.Printf("%s(%s) Attempting retry %d\n", request.RemoteAddr, request.URL.Path, attempts) ctx := context.WithValue(request.Context(), Attempts, attempts+1) lb(writer, request.WithContext(ctx)) }</span></span></code> </pre> <br>  Dalam mengembangkan penangan kesalahan ini, kami menggunakan kemampuan penutupan.  Ini memungkinkan kami untuk menangkap variabel eksternal seperti URL server ke dalam metode kami.  Pawang memeriksa retry counter, dan jika kurang dari 3, maka kami kembali mengirim permintaan yang sama ke server yang sama.  Ini karena, karena kesalahan sementara, server dapat membatalkan permintaan kami, tetapi segera menjadi tersedia (server mungkin tidak memiliki soket gratis untuk klien baru).  Jadi, Anda perlu mengatur timer tunda untuk upaya baru setelah sekitar 10 ms.  Dengan setiap permintaan, kami meningkatkan upaya balasan. <br><br>  Setelah kegagalan setiap upaya, kami menandai server sebagai siaga. <br><br>  Sekarang Anda perlu menetapkan server baru untuk permintaan yang sama.  Kami akan melakukan ini menggunakan penghitung upaya menggunakan paket <code>context</code> .  Setelah meningkatkan penghitungan upaya, kami meneruskannya ke <code>lb</code> untuk memilih server baru untuk memproses permintaan. <br><br>  Kami tidak dapat melakukan ini tanpa batas, jadi kami akan memeriksa di <code>lb</code> apakah jumlah upaya maksimum telah tercapai sebelum melanjutkan dengan pemrosesan permintaan. <br><br>  Anda bisa mendapatkan counter upaya dari permintaan, jika itu mencapai maksimum, maka kami mengganggu permintaan. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// lb load balances the incoming request func lb(w http.ResponseWriter, r *http.Request) { attempts := GetAttemptsFromContext(r) if attempts &gt; 3 { log.Printf("%s(%s) Max attempts reached, terminating\n", r.RemoteAddr, r.URL.Path) http.Error(w, "Service not available", http.StatusServiceUnavailable) return } peer := serverPool.GetNextPeer() if peer != nil { peer.ReverseProxy.ServeHTTP(w, r) return } http.Error(w, "Service not available", http.StatusServiceUnavailable) }</span></span></code> </pre> <br>  Ini adalah implementasi rekursif. <br><br><h2>  Menggunakan paket konteks </h2><br>  Paket <code>context</code> memungkinkan Anda untuk menyimpan data yang berguna dalam permintaan HTTP.  Kami akan secara aktif menggunakan ini untuk melacak data yang terkait dengan permintaan - <code>Attempt</code> dan <code>Retry</code> penghitung. <br><br>  Pertama, Anda perlu mengatur kunci untuk konteksnya.  Disarankan untuk tidak menggunakan string, tetapi nilai numerik yang unik.  Go memiliki kata kunci <code>iota</code> untuk implementasi konstanta tambahan, yang masing-masing berisi nilai unik.  Ini adalah solusi yang bagus untuk mendefinisikan kunci numerik. <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> ( Attempts <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> = <span class="hljs-literal"><span class="hljs-literal">iota</span></span> Retry )</code> </pre> <br>  Anda kemudian dapat mengekstrak nilainya, seperti yang biasa kita lakukan dengan <code>HashMap</code> .  Nilai default dapat bergantung pada situasi saat ini. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// GetAttemptsFromContext returns the attempts for request func GetRetryFromContext(r *http.Request) int { if retry, ok := r.Context().Value(Retry).(int); ok { return retry } return 0 }</span></span></code> </pre><br><h2>  Validasi Server Pasif </h2><br>  Pemeriksaan pasif mengidentifikasi dan memulihkan server yang jatuh.  Kami melakukan ping pada interval tertentu untuk menentukan status mereka. <br><br>  Untuk melakukan ping, cobalah membuat koneksi TCP.  Jika server merespons, kami menandainya berfungsi.  Metode ini dapat diadaptasi untuk memanggil titik akhir tertentu seperti <code>/status</code> .  Pastikan untuk menutup koneksi setelah dibuat untuk mengurangi beban tambahan di server.  Jika tidak, ia akan mencoba mempertahankan koneksi ini dan pada akhirnya akan menghabiskan sumber dayanya. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// isAlive checks whether a backend is Alive by establishing a TCP connection func isBackendAlive(u *url.URL) bool { timeout := 2 * time.Second conn, err := net.DialTimeout("tcp", u.Host, timeout) if err != nil { log.Println("Site unreachable, error: ", err) return false } _ = conn.Close() // close it, we dont need to maintain this connection return true }</span></span></code> </pre> <br>  Sekarang Anda dapat mengulangi server dan menandai statusnya: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// HealthCheck pings the backends and update the status func (s *ServerPool) HealthCheck() { for _, b := range s.backends { status := "up" alive := isBackendAlive(b.URL) b.SetAlive(alive) if !alive { status = "down" } log.Printf("%s [%s]\n", b.URL, status) } }</span></span></code> </pre> <br>  Untuk menjalankan kode ini secara berkala, Anda dapat menjalankan timer di Go.  Ini akan memungkinkan Anda untuk mendengarkan acara di saluran. <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// healthCheck runs a routine for check status of the backends every 2 mins func healthCheck() { t := time.NewTicker(time.Second * 20) for { select { case &lt;-tC: log.Println("Starting health check...") serverPool.HealthCheck() log.Println("Health check completed") } } }</span></span></code> </pre> <br>  Dalam kode ini, saluran <code>&lt;-tC</code> akan mengembalikan nilai setiap 20 detik.  <code>select</code> memungkinkan Anda untuk menentukan acara ini.  Dengan tidak adanya situasi <code>default</code> , menunggu sampai setidaknya satu kasus dapat dieksekusi. <br><br>  Sekarang jalankan kodenya di goroutine terpisah: <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">go</span></span> healthCheck()</code> </pre><br><h2>  Kesimpulan </h2><br>  Dalam artikel ini, kami memeriksa banyak pertanyaan: <br><br><ul><li>  Algoritma Round Robin </li><li>  ReverseProxy dari perpustakaan standar </li><li>  Mutex </li><li>  Operasi atom </li><li>  Sirkuit pendek </li><li>  Telepon balik </li><li>  Operasi pemilihan </li></ul><br>  Ada banyak cara untuk meningkatkan penyeimbang kita.  Sebagai contoh: <br><br><ul><li>  Gunakan heap untuk mengurutkan server langsung untuk mengurangi cakupan pencarian. </li><li>  Kumpulkan statistik. </li><li>  Menerapkan algoritma round-robin tertimbang dengan jumlah koneksi paling sedikit. </li><li>  Tambahkan dukungan untuk file konfigurasi. </li></ul><br>  Dan sebagainya. <br><br>  Kode sumber ada di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id476276/">https://habr.com/ru/post/id476276/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id476264/index.html">Bot Telegram untuk belajar bahasa asing: dari menjejalkan kata-kata hingga berbicara</a></li>
<li><a href="../id476266/index.html">Magang di Mars Digital Technologies. Bagaimana kami menerapkan pembelajaran mendalam di M&M</a></li>
<li><a href="../id476268/index.html">Solusi untuk Tantangan Penemuan Bug yang Ditawarkan oleh Tim PVS-Studio di Konferensi pada 2018-2019</a></li>
<li><a href="../id476270/index.html">Kemenangan kami: TopCoder Open 2019</a></li>
<li><a href="../id476272/index.html">Jawaban untuk tugas-tugas dari stan PVS-Studio di konferensi 2018-2019</a></li>
<li><a href="../id476278/index.html">Konferensi BLACK HAT USA. Kaya atau mati: hasilkan uang di Internet menggunakan Black Hat. Bagian 3</a></li>
<li><a href="../id476280/index.html">Melalui duri ke DOS: empat floppy disk yang mengubah dunia</a></li>
<li><a href="../id476284/index.html">Kami merumuskan strategi untuk bekerja dengan kesalahan dalam Bereaksi</a></li>
<li><a href="../id476286/index.html">5 kerangka JS Top untuk pengembangan front-end pada tahun 2020. Bagian 1</a></li>
<li><a href="../id476288/index.html">5 kerangka JS Top untuk pengembangan front-end pada tahun 2020. Bagian 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
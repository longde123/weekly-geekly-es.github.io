<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏼‍🏫 👉 👩🏾‍🚒 Nano-neurônio - 7 funções JavaScript simples, mostrando como a máquina pode "aprender" 🧝🏼 🧚 🌩️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Um nano-neurônio é uma versão simplificada de um neurônio a partir do conceito de rede neural. O nano-neurônio executa a tarefa mais simples e é trein...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Nano-neurônio - 7 funções JavaScript simples, mostrando como a máquina pode "aprender"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479220/"><p>  <a href="https://github.com/trekhleb/nano-neuron" rel="nofollow"><strong>Um nano-neurônio</strong></a> é uma versão <em>simplificada</em> de um neurônio a partir do conceito de rede neural.  O nano-neurônio executa a tarefa mais simples e é treinado para converter a temperatura de graus Celsius em graus Fahrenheit. </p><br><p>  O código <a href="" rel="nofollow"><strong>NanoNeuron.js</strong></a> consiste em 7 funções JavaScript simples que envolvem aprendizado, treinamento, previsão e propagação direta e reversa do sinal do modelo.  O objetivo de escrever essas funções era fornecer ao leitor uma explicação básica e mínima (intuição) de como, afinal, uma máquina pode "aprender".  O código não usa bibliotecas de terceiros.  Como diz o ditado, apenas funções JavaScript "baunilha" simples. </p><br><p>  Essas funções não são de forma <strong>alguma</strong> um guia completo para o aprendizado de máquina.  Muitos conceitos de aprendizado de máquina estão ausentes ou simplificados!  Essa simplificação é permitida com o único objetivo - fornecer ao leitor a compreensão e intuição mais <strong>básicas</strong> sobre como uma máquina pode "aprender" em princípio, de modo que, como resultado, "MAGIC of machine learning" pareça cada vez mais para o leitor como "MATEMÁTICA DO aprendizado de máquina". </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/98d/6c4/69e/98d6c469e1facbf97154fe29f698cd12.png" alt="Nanoneuron"></p><a name="habracut"></a><br><h2 id="chto-vyuchit-nash-nano-neyron">  O que nosso nano-neurônio “aprenderá” </h2><br><p>  Você pode ter ouvido falar de neurônios no contexto de <a href="https://ru.wikipedia.org/wiki/%25D0%2598%25D1%2581%25D0%25BA%25D1%2583%25D1%2581%25D1%2581%25D1%2582%25D0%25B2%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BD%25D0%25B5%25D0%25B9%25D1%2580%25D0%25BE%25D0%25BD%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D0%25B5%25D1%2582%25D1%258C" rel="nofollow">redes neurais</a> .  Um nano-neurônio é uma versão simplificada desse mesmo neurônio.  Neste exemplo, escreveremos sua implementação do zero.  Por simplicidade, não construiremos uma rede de nano-neurônios.  Vamos nos concentrar na criação de um único nano-neurônio e tentar ensiná-lo a converter a temperatura de graus Celsius em graus Fahrenheit.  Em outras palavras, vamos ensiná-lo a <strong>prever a</strong> temperatura em graus Fahrenheit com base na temperatura em graus Celsius. </p><br><p>  A propósito, a fórmula para converter graus Celsius em graus Fahrenheit é a seguinte: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/9fa/2e8/8b5/9fa2e88b5a7324c8b9fc359b274ba091.png" alt="Celsius em Fahrenheit"></p><br><p>  Mas, no momento, nosso nano-neurônio não sabe nada sobre essa fórmula ... </p><br><h3 id="model-nano-neyrona">  Modelo nano-neurônio </h3><br><p> Vamos começar criando uma função que descreve o modelo do nosso nano neurônio.  Este modelo é uma relação linear simples entre <code>x</code> e <code>y</code> , com a seguinte aparência: <code>y = w * x + b</code> .  Simplificando, nosso nano-neurônio é uma criança que pode desenhar uma linha reta no sistema de coordenadas <code>XY</code> . </p><br><p>  As variáveis <code>w</code> e <code>b</code> são <strong>parâmetros do</strong> modelo.  Um nano-neurônio conhece apenas esses dois parâmetros de uma função linear.  Esses parâmetros são precisamente o que nosso nano-neurônio aprenderá durante o processo de treinamento. </p><br><p>  A única coisa que um nano-neurônio pode fazer nesta fase é simular relações lineares.  Ele faz isso no método <code>predict()</code> , que pega uma variável <code>x</code> na entrada e prediz a variável <code>y</code> na saída.  Nenhuma mágica. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">NanoNeuron</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">w, b</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.w = w; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.b = b; <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.predict = <span class="hljs-function"><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">x</span></span></span><span class="hljs-function">) =&gt;</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x * <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.w + <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>.b; } }</code> </pre> <br><p>  _ (... espere ... <a href="https://en.wikipedia.org/wiki/Linear_regression" rel="nofollow">regressão linear</a> é você, ou o quê?) _ </p><br><h3 id="konvertaciya-gradusov-celsiya-v-gradusy-farengeyta">  Converter graus Celsius em graus Fahrenheit </h3><br><p>  A temperatura em graus Celsius pode ser convertida em graus Fahrenheit de acordo com a fórmula: <code>f = 1.8 * c + 32</code> , onde <code>c</code> é a temperatura em graus Celsius <code>f</code> é a temperatura em graus Fahrenheit. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">celsiusToFahrenheit</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">c</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> w = <span class="hljs-number"><span class="hljs-number">1.8</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> b = <span class="hljs-number"><span class="hljs-number">32</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> f = c * w + b; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> f; };</code> </pre> <br><p>  Como resultado, queremos que nosso nano-neurônio seja capaz de simular essa função específica.  Ele terá que adivinhar (aprender) que o parâmetro <code>w = 1.8</code> <code>b = 32</code> sem conhecê-lo com antecedência. </p><br><p>  É assim que a função de conversão aparece no gráfico.  É isso que nosso "bebê" nano-neural deve aprender a "desenhar": </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/68b/0d6/8bc/68b0d68bcc7be00ec9526867b2fcecf3.png" alt="Conversão de Celsius para Fahrenheit"></p><br><h3 id="generirovanie-dannyh">  Geração de dados </h3><br><p>  Na programação clássica, conhecemos os dados de entrada ( <code>x</code> ) e o algoritmo para converter esses dados (parâmetros <code>w</code> ), mas os dados de saída ( <code>y</code> ) são desconhecidos.  A saída é calculada com base na entrada usando um algoritmo conhecido.  No aprendizado de máquina, pelo contrário, apenas os dados de entrada e saída ( <code>x</code> e <code>y</code> ) são conhecidos, mas o algoritmo para alternar de <code>x</code> para <code>y</code> desconhecido (parâmetros <code>w</code> e <code>b</code> ). </p><br><p>  É a geração de entrada e saída que vamos fazer agora.  Precisamos gerar dados para <strong>treinar</strong> nosso modelo e dados para <strong>testar o</strong> modelo.  A função auxiliar <code>celsiusToFahrenheit()</code> nos ajudará com isso.  Cada um dos conjuntos de dados de treinamento e teste é um conjunto de pares <code>x</code> e <code>y</code> .  Por exemplo, se <code>x = 2</code> , <code>y = 35,6</code> e assim por diante. </p><br><blockquote>  No mundo real, a maioria dos dados provavelmente será <em>coletada</em> , não <em>gerada</em> .  Por exemplo, esses dados coletados podem ser um conjunto de pares de "fotos de rosto" -&gt; "nome da pessoa". </blockquote><p>  Usaremos o conjunto de dados TRAINING para treinar nosso nano-neurônio.  Antes que ele cresça e seja capaz de tomar decisões por conta própria, devemos ensinar a ele o que é "verdadeiro" e o que é "falso" usando dados "corretos" de um conjunto de treinamento. </p><br><blockquote>  A propósito, aqui o princípio da vida “lixo na entrada - lixo na saída” é claramente traçado.  Se um nano-neurônio joga uma "mentira" no kit de treinamento que 5 ° C é convertido em 1000 ° F, depois de muitas iterações de treinamento, ele acreditará nisso e converterá corretamente todos os valores de temperatura, <strong>exceto</strong> 5 ° C.  Precisamos ter muito cuidado com os dados de treinamento que carregamos todos os dias em nossa rede neural cerebral. </blockquote><p>  Distraído.  Vamos continuar. </p><br><p>  Usaremos o conjunto de dados TEST para avaliar quão bem nosso nano neurônio foi treinado e podemos fazer previsões corretas sobre novos dados que ele não viu durante o treinamento. </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">generateDataSets</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">// xTrain -&gt; [0, 1, 2, ...], // yTrain -&gt; [32, 33.8, 35.6, ...] const xTrain = []; const yTrain = []; for (let x = 0; x &lt; 100; x += 1) { const y = celsiusToFahrenheit(x); xTrain.push(x); yTrain.push(y); } // xTest -&gt; [0.5, 1.5, 2.5, ...] // yTest -&gt; [32.9, 34.7, 36.5, ...] const xTest = []; const yTest = []; //   0.5    1,       //   ,       . for (let x = 0.5; x &lt; 100; x += 1) { const y = celsiusToFahrenheit(x); xTest.push(x); yTest.push(y); } return [xTrain, yTrain, xTest, yTest]; }</span></span></code> </pre> <br><h3 id="ocenka-pogreshnosti-predskazaniy">  Estimativa de erro de previsão </h3><br><p>  Precisamos de uma certa métrica (medida, número, classificação) que mostre quão próxima é a previsão de um nano neurônio.  Em outras palavras, esse número / métrica / função deve mostrar quão certo ou errado o nano neurônio está.  É como na escola, um aluno pode obter uma nota de <code>5</code> ou <code>2</code> por seu controle. </p><br><p>  No caso de um nano-neurônio, seu erro (erro) entre o valor verdadeiro de <code>y</code> e o valor previsto de <code>prediction</code> será produzido pela fórmula: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8d8/e50/ac1/8d8e50ac12d03614e65975f7b5d36931.png" alt="Custo de previsão"></p><br><p>  Como pode ser visto na fórmula, consideraremos o erro como uma simples diferença entre os dois valores.  Quanto mais próximos os valores estiverem, menor a diferença.  Usamos o quadrado aqui para se livrar do sinal, para que no final <code>(1 - 2) ^ 2</code> equivalente a <code>(2 - 1) ^ 2</code> .  A divisão por <code>2</code> ocorre apenas para simplificar o significado da derivada dessa função na fórmula para propagação reversa de um sinal (mais sobre isso abaixo). </p><br><p>  A função de erro, neste caso, terá a seguinte aparência: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predictionCost</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">y, prediction</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (y - prediction) ** <span class="hljs-number"><span class="hljs-number">2</span></span> / <span class="hljs-number"><span class="hljs-number">2</span></span>; <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 235.6 }</span></span></code> </pre> <br><h3 id="pryamoe-rasprostranenie-signala">  Propagação direta de sinal </h3><br><p>  A propagação direta do sinal através do nosso modelo significa fazer previsões para todos os pares do conjunto de dados de treinamento <code>yTrain</code> e <code>yTrain</code> e calcular o erro médio (erro) dessas previsões. </p><br><p>  Nós apenas deixamos nosso nano neurônio "falar", permitindo que ele fizesse previsões (convertesse a temperatura).  Ao mesmo tempo, um nano-neurônio nesta fase pode estar muito errado.  O valor médio do erro de previsão nos mostrará até que ponto nosso modelo está / está próximo da verdade no momento.  O valor do erro é muito importante aqui, pois, alterando os parâmetros <code>w</code> <code>b</code> propagação direta do sinal, podemos avaliar se nosso nano neurônio se tornou "mais inteligente" com novos parâmetros ou não. </p><br><p>  O erro médio de previsão de um nano neurônio será realizado usando a seguinte fórmula: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/575/db3/e0a/575db3e0a0c872b29582147e41231344.png" alt="Custo médio"></p><br><p>  Onde <code>m</code> é o número de cópias de treinamento (no nosso caso, temos <code>100</code> pares de dados). </p><br><p>  Veja como podemos implementar isso no código: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forwardPropagation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">model, xTrain, yTrain</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> m = xTrain.length; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> predictions = []; <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cost = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">let</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; m; i += <span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> prediction = nanoNeuron.predict(xTrain[i]); cost += predictionCost(yTrain[i], prediction); predictions.push(prediction); } <span class="hljs-comment"><span class="hljs-comment">//     . cost /= m; return [predictions, cost]; }</span></span></code> </pre> <br><h3 id="obratnoe-rasprostranenie-signala">  Propagação Reversa de Sinais </h3><br><p>  Agora que sabemos como nosso nano-neurônio está certo ou errado em suas previsões (com base no valor médio do erro), como podemos tornar as previsões mais precisas? </p><br><p>  A propagação reversa do sinal nos ajudará com isso.  A propagação do sinal de retorno é o processo de avaliar o erro de um nano-neurônio e, em seguida, ajustar seus parâmetros <code>w</code> para que as próximas previsões do nano-neurônio para todo o conjunto de dados de treinamento se tornem um pouco mais precisas. </p><br><p>  É aqui que o aprendizado de máquina se torna como mágica.  O conceito-chave aqui é uma <strong>derivada da função</strong> , que mostra qual etapa de tamanho e qual caminho precisamos seguir para abordar o mínimo da função (no nosso caso, o mínimo da função de erro). </p><br><p>  O objetivo final do treinamento de um nano-neurônio é encontrar o mínimo da função de erro (veja a função acima).  Se pudermos encontrar esses valores de <code>w</code> e <code>b</code> nos quais o valor médio da função de erro é pequeno, isso significa que nosso nano neurônio lida bem com as previsões de temperatura em graus Fahrenheit. </p><br><p>  Derivativos são um tópico amplo e separado que não abordaremos neste artigo.  <a href="https://www.mathsisfun.com/calculus/derivatives-introduction.html" rel="nofollow">MathIsFun</a> é um ótimo recurso que pode fornecer uma compreensão básica de derivadas. </p><br><p>  Uma coisa que precisamos aprender com a essência da derivada e que nos ajudará a entender como a retropropagação do sinal funciona é que a derivada de uma função em um ponto específico <code>x</code> e <code>y</code> , por definição, é uma linha tangente à curva dessa função em <code>x</code> e <code>y</code> <em>indica a direção para o mínimo da função</em> . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/66d/bfd/49a/66dbfd49aaf1ced48d7f6b5917fddb12.svg" alt="Inclinação derivada"></p><br><p>  <em>Imagem tirada do <a href="https://www.mathsisfun.com/calculus/derivatives-introduction.html" rel="nofollow">MathIsFun</a></em> </p><br><p>  Por exemplo, no gráfico acima, você vê que, no ponto <code>(x=2, y=4)</code> inclinação da tangente nos mostra que precisamos nos mover para a <code></code> e para <code></code> para obter o mínimo da função.  Observe também que quanto maior a inclinação da tangente, mais rápido devemos mover para o ponto mínimo. </p><br><p>  As derivadas de nossa função de erro médio <code>averageCost</code> com <code>averageCost</code> aos parâmetros <code>w</code> e <code>b</code> terão a seguinte aparência: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/4cc/bda/ba1/4ccbdaba120c399c1528e2bc38cf0efd.png" alt="dW"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/e02/0cb/125/e020cb125449849009a9f565a32ff46f.png" alt="dB"></p><br><p>  Onde <code>m</code> é o número de cópias de treinamento (no nosso caso, temos <code>100</code> pares de dados). </p><br><p>  <em>Você pode ler mais detalhadamente sobre como obter a derivada de funções complexas <a href="https://www.mathsisfun.com/calculus/derivatives-rules.html" rel="nofollow">aqui</a> .</em> </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">backwardPropagation</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">predictions, xTrain, yTrain</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> m = xTrain.length; <span class="hljs-comment"><span class="hljs-comment">//           'w'  'b'. //      0. let dW = 0; let dB = 0; for (let i = 0; i &lt; m; i += 1) { dW += (yTrain[i] - predictions[i]) * xTrain[i]; dB += yTrain[i] - predictions[i]; } //    . dW /= m; dB /= m; return [dW, dB]; }</span></span></code> </pre> <br><h3 id="trenirovka-modeli">  Modelo de treinamento </h3><br><p>  Agora sabemos como estimar o erro / erro das previsões do nosso modelo de nano-neurônios para todos os dados de treinamento (propagação direta do sinal).  Também sabemos como ajustar os parâmetros <code>w</code> e <code>b</code> modelo de nano-neurônios (propagação reversa do sinal) para melhorar a precisão das previsões.  O problema é que, se realizarmos a propagação para frente e para trás do sinal apenas uma vez, isso não será suficiente para o nosso modelo identificar e aprender as dependências e leis nos dados de treinamento.  Você pode comparar isso com a visita escolar de um dia de um aluno.  Ele / ela deve frequentar a escola regularmente, dia após dia, ano após ano, para aprender todo o material. </p><br><p>  Portanto, devemos <em>repetir a</em> propagação para frente e para trás do sinal muitas vezes.  É <code>trainModel()</code> função <code>trainModel()</code> .  Ela é como uma "professora" para o modelo do nosso nano neurônio: </p><br><ul><li>  ela passará algum tempo ( <code>epochs</code> ) com nosso nano neurônio ainda bobo, tentando treiná-lo, </li><li>  ela usará livros especiais (conjuntos de dados <code>yTrain</code> e <code>yTrain</code> ) para treinamento, </li><li>  incentiva nosso "aluno" a estudar com mais diligência (mais rápido) usando o parâmetro <code>alpha</code> , que controla essencialmente a velocidade do aprendizado. </li></ul><br><p>  Algumas palavras sobre o parâmetro <code>alpha</code> .  Este é apenas um coeficiente (multiplicador) para os valores das variáveis <code>dW</code> e <code>dB</code> , que calculamos durante a propagação posterior do sinal.  Portanto, a derivada nos mostrou a direção para o mínimo da função de erro (os sinais dos valores de <code>dW</code> e <code>dB</code> nos dizem isso).  A derivada também nos mostrou a rapidez com que precisamos avançar para o mínimo da função (os valores absolutos de <code>dW</code> e <code>dB</code> nos dizem isso).  Agora, precisamos multiplicar o tamanho da etapa por <code>alpha</code> , a fim de ajustar a velocidade de nossa abordagem a um mínimo (o tamanho total da etapa).  Às vezes, se usarmos valores grandes para <code>alpha</code> , podemos executar etapas tão grandes que podemos simplesmente <em>ultrapassar o</em> mínimo da função, ignorando-a. </p><br><p>  Por analogia com o “professor”, quanto mais forte ela forçaria nosso “nano-aluno” a aprender, mais rápido ele aprenderia, MAS, se você forçar e pressioná-lo muito, então nosso “nano-aluno” poderá sofrer um colapso nervoso e apatia completa e ele não aprenderá nada. </p><br><p>  Atualizaremos os parâmetros do nosso modelo <code>w</code> e <code>b</code> seguinte maneira: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c7b/db8/84f/c7bdb884f2a940d62332246cdbcb44bc.png" alt="w"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b57/622/0ab/b576220ab6515d44255ef56699077bab.png" alt="b"></p><br><p>  E é assim que o treinamento em si se parece: </p><br><pre> <code class="javascript hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">trainModel</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">{model, epochs, alpha, xTrain, yTrain}</span></span></span><span class="hljs-function">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//     -.  . const costHistory = []; //    ()  for (let epoch = 0; epoch &lt; epochs; epoch += 1) { //   . const [predictions, cost] = forwardPropagation(model, xTrain, yTrain); costHistory.push(cost); //   . const [dW, dB] = backwardPropagation(predictions, xTrain, yTrain); //    -,    . nanoNeuron.w += alpha * dW; nanoNeuron.b += alpha * dB; } return costHistory; }</span></span></code> </pre> <br><h3 id="soberem-vse-funkcii-vmeste">  Juntando todos os recursos </h3><br><p>  Hora de usar todas as funções criadas anteriormente juntas. </p><br><p>  Crie uma instância do modelo nano-neurônio.  No momento, o nano-neurônio não sabe nada sobre quais devem ser os parâmetros <code>w</code> e <code>b</code> .  Então, vamos definir <code>w</code> e <code>b</code> aleatoriamente. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> w = <span class="hljs-built_in"><span class="hljs-built_in">Math</span></span>.random(); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 0.9492 const b = Math.random(); // ie -&gt; 0.4570 const nanoNeuron = new NanoNeuron(w, b);</span></span></code> </pre> <br><p>  Geramos conjuntos de dados de treinamento e teste. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> [xTrain, yTrain, xTest, yTest] = generateDataSets();</code> </pre> <br><p>  Agora vamos tentar treinar nosso modelo usando pequenos passos ( <code>0.0005</code> ) para <code>70000</code> épocas.  Você pode experimentar com esses parâmetros, eles são determinados empiricamente. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> epochs = <span class="hljs-number"><span class="hljs-number">70000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> alpha = <span class="hljs-number"><span class="hljs-number">0.0005</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> trainingCostHistory = trainModel({<span class="hljs-attr"><span class="hljs-attr">model</span></span>: nanoNeuron, epochs, alpha, xTrain, yTrain});</code> </pre> <br><p>  Vamos verificar como o valor do erro do nosso modelo mudou durante o treinamento.  Esperamos que o valor do erro após o treinamento seja significativamente menor do que antes do treinamento.  Isso significa que o nosso nano-neurônio é mais sábio.  A opção oposta também é possível quando, após o treinamento, o erro de previsão apenas aumenta (por exemplo, grandes valores da etapa de aprendizado <code>alpha</code> ). </p><br><pre> <code class="javascript hljs"><span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'  :'</span></span>, trainingCostHistory[<span class="hljs-number"><span class="hljs-number">0</span></span>]); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 4694.3335043 console.log('  :', trainingCostHistory[epochs - 1]); // ie -&gt; 0.0000024</span></span></code> </pre> <br><p>  E aqui está como o valor do erro do modelo mudou durante o treinamento.  No eixo <code>x</code> são épocas (em milhares).  Esperamos que o gráfico esteja diminuindo. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/191/860/d6f/191860d6f0cd8cf7d24127f04f779462.png" alt="Processo de treinamento"></p><br><p>  Vejamos quais parâmetros nosso nano-neurônio “aprendeu”.  Esperamos que os parâmetros <code>w</code> e <code>b</code> sejam semelhantes aos parâmetros com o mesmo nome da função <code>celsiusToFahrenheit()</code> ( <code>w = 1.8</code> <code>b = 32</code> ), porque foi o nano-neurônio dela que tentei simular. </p><br><pre> <code class="javascript hljs"><span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">' -:'</span></span>, {<span class="hljs-attr"><span class="hljs-attr">w</span></span>: nanoNeuron.w, <span class="hljs-attr"><span class="hljs-attr">b</span></span>: nanoNeuron.b}); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; {w: 1.8, b: 31.99}</span></span></code> </pre> <br><p>  Como você pode ver, o nano-neurônio está muito próximo da função <code>celsiusToFahrenheit()</code> . </p><br><p>  Agora vamos ver quão precisas são as previsões de nosso nano-neurônio para dados de teste que ele não viu durante o treinamento.  O erro de previsão para os dados de teste deve estar próximo do erro de previsão para os dados de treinamento.  Isso significa que o nano-neurônio aprendeu as dependências corretas e pode abstrair corretamente sua experiência a partir de dados anteriormente desconhecidos (esse é todo o valor do modelo). </p><br><pre> <code class="javascript hljs">[testPredictions, testCost] = forwardPropagation(nanoNeuron, xTest, yTest); <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">'   :'</span></span>, testCost); <span class="hljs-comment"><span class="hljs-comment">// ie -&gt; 0.0000023</span></span></code> </pre> <br><p>  Agora, como nosso "nano-bebê" foi bem treinado na "escola" e agora sabe como converter com precisão graus Celsius em graus Fahrenheit, mesmo para dados que ele não viu, podemos chamá-lo de "inteligente".  Agora podemos até pedir conselhos a ele sobre conversão de temperatura, e esse foi o objetivo de todo o treinamento. </p><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> tempInCelsius = <span class="hljs-number"><span class="hljs-number">70</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> customPrediction = nanoNeuron.predict(tempInCelsius); <span class="hljs-built_in"><span class="hljs-built_in">console</span></span>.log(<span class="hljs-string"><span class="hljs-string">`- "",  </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">${tempInCelsius}</span></span></span><span class="hljs-string">°C   :`</span></span>, customPrediction); <span class="hljs-comment"><span class="hljs-comment">// -&gt; 158.0002 console.log('  :', celsiusToFahrenheit(tempInCelsius)); // -&gt; 158</span></span></code> </pre> <br><p>  Muito perto!  Como as pessoas, nosso nano-neurônio é bom, mas não é perfeito :) </p><br><p>  Codificação bem sucedida! </p><br><h2 id="kak-zapustit-i-protestirovat-nano-neyron">  Como executar e testar um nano-neurônio </h2><br><p>  Você pode clonar o repositório e executar o nano neurônio localmente: </p><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/trekhleb/nano-neuron.git <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> nano-neuron</code> </pre> <br><pre> <code class="bash hljs">node ./NanoNeuron.js</code> </pre> <br><h2 id="upuschennye-koncepcii">  Conceitos perdidos </h2><br><p>  Os seguintes conceitos de aprendizado de máquina foram omitidos ou simplificados para facilitar a explicação. </p><br><p>  <strong>Separação de conjuntos de dados de treinamento e teste</strong> </p><br><p>  Geralmente você tem um grande conjunto de dados.  Dependendo do número de cópias deste conjunto, sua divisão em conjuntos de treinamento e teste pode ser realizada na proporção de 70/30.  Os dados no conjunto devem ser misturados aleatoriamente antes de serem divididos.  Se a quantidade de dados for grande (por exemplo, milhões), a divisão em conjuntos de teste e treinamento poderá ser realizada em proporções próximas a 90/10 ou 95/5. </p><br><p>  <strong>Poder online</strong> </p><br><p>  Normalmente, você não encontrará casos em que apenas um neurônio seja usado.  A força está na <a href="https://en.wikipedia.org/wiki/Neural_network" rel="nofollow">rede de</a> tais neurônios.  Uma rede neural pode aprender dependências muito mais complexas. </p><br><p>  Também no exemplo acima, nosso nano-neurônio pode parecer mais uma <a href="https://en.wikipedia.org/wiki/Linear_regression" rel="nofollow">regressão linear</a> simples do que uma rede neural. </p><br><p>  <strong>Normalização de entrada</strong> </p><br><p>  Antes do treinamento, é habitual <a href="https://www.jeremyjordan.me/batch-normalization/" rel="nofollow">normalizar os dados de entrada</a> . </p><br><p>  <strong>Implementação vetorial</strong> </p><br><p>  Para redes neurais, os cálculos de vetor (matriz) são muito mais rápidos que os cálculos <code>for</code> loops.  Geralmente, a propagação direta e reversa do sinal é realizada usando operações de matriz, por exemplo, a biblioteca Python <a href="https://numpy.org/" rel="nofollow">Numpy</a> . </p><br><p>  <strong>Função de erro mínimo</strong> </p><br><p>  A função de erro que usamos para o nano neurônio é muito simplificada.  Ele deve conter <a href="https://stackoverflow.com/questions/32986123/why-the-cost-function-of-logistic-regression-has-a-logarithmic-expression/32998675" rel="nofollow">componentes logarítmicos</a> .  Uma mudança na fórmula para a função de erro também implicará uma mudança nas fórmulas para a propagação para frente e para trás do sinal. </p><br><p>  <strong>Função de ativação</strong> </p><br><p>  Normalmente, o valor de saída do neurônio passa pela função de ativação.  Para a ativação, funções como <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="nofollow">Sigmoid</a> , <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="nofollow">ReLU</a> e outras podem ser usadas. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt479220/">https://habr.com/ru/post/pt479220/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt479202/index.html">C ++ e métodos numéricos: integração aproximada de Newton-Cotes</a></li>
<li><a href="../pt479210/index.html">O que acontecerá com as compras em lojas on-line estrangeiras a partir de 1º de janeiro de 2020</a></li>
<li><a href="../pt479214/index.html">Uma seleção dos próximos eventos gratuitos para desenvolvedores em Moscou # 2</a></li>
<li><a href="../pt479216/index.html">Segundo vento Pandora DXL 3000 ou como eu estraguei minha própria telemetria</a></li>
<li><a href="../pt479218/index.html">Como fazer um bot que transforma uma foto em uma história em quadrinhos: instruções passo a passo para manequins</a></li>
<li><a href="../pt479222/index.html">O resumo de materiais interessantes para o desenvolvedor móvel # 325 (de 2 a 8 de dezembro)</a></li>
<li><a href="../pt479226/index.html">Análise Habr: o que os usuários pedem como presente da Habr</a></li>
<li><a href="../pt479230/index.html">Documente sua API expressa com anotações de arrogância</a></li>
<li><a href="../pt479232/index.html">Desenvolvimento de aplicativo MQ JMS no Spring Boot</a></li>
<li><a href="../pt479234/index.html">Notícias do mundo do OpenStreetMap nº 488 (19/11/2019 - 25/11/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👌🏾 👩‍👩‍👦‍👦 🍫 Kami mempertimbangkan statistik percobaan di hh.ru 👧🏾 🚕 👵🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya! 

 Hari ini saya akan memberi tahu Anda bagaimana kami di hh.ru mempertimbangkan statistik manual tentang eksperimen. Kami akan melihat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kami mempertimbangkan statistik percobaan di hh.ru</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/hh/blog/424251/">  Halo semuanya! <br><br>  Hari ini saya akan memberi tahu Anda bagaimana kami di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hh.ru</a> mempertimbangkan statistik manual tentang eksperimen.  Kami akan melihat dari mana data berasal, bagaimana kami memprosesnya, dan apa jebakan yang kami temui.  Pada artikel ini saya akan membagikan arsitektur dan pendekatan umum, akan ada minimum skrip dan kode nyata.  Audiens utama adalah analis pemula yang tertarik pada struktur infrastruktur analisis data di hh.ru.  Jika topik ini menarik - tulis di komentar, kita dapat mempelajari kode di artikel berikut. <br><br>  Anda dapat membaca tentang bagaimana metrik otomatis untuk percobaan A / B dipertimbangkan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel</a> kami yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">lain</a> . <br><br><img src="https://habrastorage.org/webt/2t/ni/z7/2tniz7lywqs_e1q19yafq1n6vss.jpeg" alt="gambar"><br><a name="habracut"></a><br><h2>  Data apa yang kami analisis dan dari mana mereka berasal </h2><br>  Kami menganalisis log akses dan log kustom apa pun yang kami tulis sendiri. <br><br><blockquote>  95.108.213.12 - - [13 / Agustus / 2018: 04: 00: 02 +0300] 200 "GET / perusahaan / 2574971 HTTP / 1.1" 12012 "-" "Mozilla / 5.0 (kompatibel; YandexBot / 3.0; + http: / /yandex.com/bots) "" - "" gardabani.headhunter.ge "" 0,063 "-" "1534122002.858" - "" 192.168.2.38:1500 "" [0,064] "{15341220027959c8c01c51a6e01b682f} 200 https 1 -" - "- - [35827] [0,000 0] <br>  178.23.230.16 - - [13 / Agustus / 2018: 04: 00: 02 +0300] 200 "GET / lowongan / 24266672 HTTP / 1.1" <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">24229</a> " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hh.ru/vacancy/24007186?query=bmw</a> " "Mozilla / 5.0 ( Macintosh; Intel Mac OS X 10_10_5) AppleWebKit / 603.3.8 (KHTML, seperti Gecko) Versi / 10.1.2 Safari / 603.3.8 "-" "hh.ru" "0,210" "last_visit = 1534111115966 :: 1534121915966;  hhrole = anonim;  daerah = 1;  tmr_detect = 0% 7C1534121918520;  total_searches = 3;  unique_banner_user = 1534121429.273825242076558 "" 1534122002.859 "" - "" 192.168.2.239:1500 "" [0,208] "{1534122002649b7eef2e901d8c9c0469} 200 https 1 -" - "- [0] </blockquote><br>  Dalam arsitektur kami, setiap layanan menulis log secara lokal, dan kemudian melalui log client-server yang ditulis sendiri (termasuk log akses nginx) dikumpulkan pada repositori pusat (selanjutnya dicatat).  Pengembang memiliki akses ke mesin ini dan secara manual dapat mencatat log jika perlu.  Tetapi bagaimana, dalam waktu yang wajar, dapat melahap beberapa ratus gigabytes kayu gelondongan?  Tentu saja, tuangkan ke dalam hadoop! <br><br><h3>  Dari mana data berasal dari hadoop? </h3><br>  Hadoop tidak hanya menyimpan log layanan, tetapi juga mengunggah basis data prod.  Setiap hari di hadoop kami mengunggah beberapa tabel yang diperlukan untuk analitik. <br><br>  Log layanan masuk ke hadoop dalam tiga cara. <br><br><ol><li>  <b>Jalan menuju dahi</b> - cron diluncurkan dari penyimpanan log di malam hari, dan rsync mengunggah log mentah ke hdfs. </li><li>  <b>Caranya modis</b> - log dari layanan dituangkan tidak hanya ke penyimpanan umum, tetapi juga di kafka, di mana flume membacanya, melakukan preprocessing dan menyimpannya dalam hdfs. </li><li>  <b>Jalannya kuno</b> - pada hari-hari sebelum kafka, kami menulis layanan kami sendiri, yang membaca log mentah dari penyimpanan, membuatnya dari preprocessing, dan mengunggahnya ke hdfs. </li></ol><br>  Mari kita pertimbangkan setiap pendekatan secara lebih rinci. <br><br><h4>  Jalur dahi </h4><br>  Cron menjalankan skrip bash biasa. <br><br><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash LOGGING_DATE_PATH_PART=$(date -d yesterday +\%Y/\%m/\%d) HADOOP_DATE_PATH_PART=$(date -d yesterday +year=\%Y/month=\%m/day=\%d) ls /logging/java/${LOGGING_DATE_PATH_PART}/hh-banner-sync/banner-versions*.log | while read source_filename; do dest_filename=$(basename "$source_filename") /usr/bin/rsync --no-relative --no-implied-dirs --bwlimit=12288 ${source_filename} rsync://hadoop2.hhnet.ru/hdfs-raw/banner-versions/${HADOOP_DATE_PATH_PART}/${dest_filename}; done</span></span></code> </pre> <br>  Seperti yang kita ingat, dalam repositori log semua log dalam bentuk file biasa, struktur folder kira-kira sebagai berikut: /logging/java/2018/08/10/{service_nameasure/*.log <br><br>  Hadoop menyimpan file-nya dalam kira-kira struktur folder yang sama hdfs-raw / banner-versi / tahun = 2018 / bulan = 08 / hari = 10 <br>  tahun, bulan, hari kami gunakan sebagai partisi. <br><br>  Jadi, kita hanya perlu membentuk jalur yang benar (baris 3-4), dan kemudian pilih semua log yang diperlukan (baris 6) dan gunakan rsync untuk mengisinya ke hadoop (baris 8). <br><br>  <b>Keuntungan dari pendekatan ini:</b> <br><br><ul><li>  Perkembangan cepat </li><li>  Semuanya transparan dan jelas. </li></ul><br>  <b>Cons:</b> <br><br><ul><li>  Tanpa preprocessing </li></ul><br><h4>  Cara yang modis </h4><br>  Karena kami mengunggah log ke repositori dengan skrip yang ditulis sendiri, masuk akal untuk mengacaukan kemampuan untuk mengunggahnya tidak hanya ke server, tetapi juga ke kafka. <br><br>  <b>Pro</b> <br><br><ul><li>  Log online (log in hadoop muncul saat Anda mengisi kafka) </li><li>  Anda dapat melakukan pra-pemrosesan </li><li>  Itu menahan beban dengan baik dan Anda dapat mengunggah log besar </li></ul><br>  <b>Cons</b> <br><br><ul><li>  Pengaturan lebih keras </li><li>  Saya harus menulis kode </li><li>  Lebih banyak bagian dari proses casting </li><li>  Pemantauan dan analisis insiden yang lebih rumit </li></ul><br><h4>  Cara kuno </h4><br>  Ini berbeda dari mode hanya dengan tidak adanya kafka.  Oleh karena itu, ia mewarisi semua kelemahan dan hanya beberapa keunggulan dari pendekatan sebelumnya.  Layanan terpisah (pengunggah ustats) di java secara berkala membaca file yang diperlukan, memprosesnya terlebih dahulu dan mengunggahnya ke hadoop. <br><br>  <b>Pro</b> <br><br><ul><li>  Anda dapat melakukan pra-pemrosesan </li></ul><br>  <b>Cons</b> <br><br><ul><li>  Pengaturan lebih keras </li><li>  Saya harus menulis kode </li></ul><br>  Dan data masuk ke hadoop dan siap untuk analisis.  Mari kita berhenti sedikit dan mengingat apa hadoop itu dan mengapa ratusan gigabyte dapat dikonsumsi jauh lebih cepat daripada grep biasa. <br><br><h3>  Hadoop </h3><br>  Hadoop adalah gudang data terdistribusi.  Data tidak terletak pada server terpisah, tetapi didistribusikan di antara beberapa mesin, dan juga disimpan bukan dalam satu contoh, tetapi dalam beberapa - ini dilakukan untuk memastikan keandalan.  Dasar dari kecepatan pemrosesan data terletak pada perubahan dalam pendekatan dibandingkan dengan database konvensional. <br><br>  Dalam kasus database biasa, kami mengekstrak data darinya dan mengirimkannya ke klien, yang melakukan semacam analisis dan mengembalikan hasilnya kepada analis.  Jadi, untuk menghitung lebih cepat, kita perlu memiliki banyak pelanggan dan memparalelkan permintaan (misalnya, untuk membagi data dengan bulan - dan setiap klien dapat membaca data untuk bulannya). <br><br>  Dalam hadoop, yang terjadi adalah sebaliknya.  Kami mengirim kode (persis apa yang ingin kami hitung) ke data, dan kode ini dieksekusi di cluster.  Seperti yang kita ketahui, data terletak pada banyak mesin, sehingga setiap mesin hanya mengeksekusi kode pada datanya dan mengembalikan hasilnya ke klien. <br><br>  Banyak yang mungkin pernah mendengar tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pengurangan peta</a> , tetapi menulis kode untuk analisis tidak terlalu mudah dan cepat, sementara menulis dalam SQL jauh lebih sederhana.  Oleh karena itu, muncul layanan yang dapat mengubah SQL menjadi pengurangan-peta secara transparan bagi pengguna, dan analis mungkin tidak curiga bagaimana permintaannya benar-benar dipertimbangkan. <br><br>  Di hh.ru kami menggunakan sarang dan presto untuk ini.  Hive adalah yang pertama, tetapi kami secara bertahap bergerak ke presto, karena itu jauh lebih cepat untuk permintaan kami.  Sebagai GUI, kami menggunakan rona dan zeppelin. <br><br>  Lebih mudah bagi saya untuk mempertimbangkan analitik dalam python dalam jupyter, ini memungkinkan kita untuk membacanya dengan satu klik dan mendapatkan tabel excel yang diformat dengan benar pada output, yang menghemat banyak waktu.  Tulis di komentar, topik ini menarik ke artikel terpisah. <br><br>  Mari kita kembali ke analitik itu sendiri. <br><br><h2>  Bagaimana memahami apa yang ingin kita pertimbangkan? </h2><br><h3>  Manajer produk datang dengan tugas menghitung hasil percobaan </h3><br>  Kami mengirimkan email buletin di mana kami mengirim lowongan yang sesuai untuk pemohon (apakah semua orang menyukai surat seperti itu?).  Kami memutuskan untuk mengubah desain surat itu sedikit dan ingin memahami apakah itu menjadi lebih baik.  Untuk ini kami akan mempertimbangkan: <br><br><ul><li>  jumlah transisi ke lowongan dari surat; </li><li>  umpan balik setelah transisi </li></ul><br>  Biarkan saya mengingatkan Anda bahwa yang kita miliki hanyalah log akses dan database.  Kami perlu merumuskan metrik kami dalam hal klik tautan. <br><br><h4>  Jumlah transisi ke lowongan dari surat </h4><br>  Transisi adalah permintaan GET ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hh.ru/vacancy/26646861</a> .  Untuk memahami dari mana asal transisi, kami menambahkan tag utm dari formulir? Utm_source = email_campaign_123.  Untuk permintaan GET di log akses akan ada informasi tentang parameter, dan kami hanya dapat memfilter transisi dari milis kami. <br><br><h4>  Jumlah respons setelah transisi </h4><br>  Di sini kita dapat dengan mudah menghitung jumlah respons terhadap lowongan dari buletin, tetapi kemudian statistiknya akan salah, karena responsnya dapat dipengaruhi oleh hal lain, kecuali untuk surat kami, misalnya, iklan di ClickMe dibeli untuk lowongan, dan karenanya jumlah respons sangat dewasa. <br><br>  Kami memiliki dua opsi untuk bagaimana merumuskan jumlah respons: <br><br><ol><li>  Tanggapannya adalah POST di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hh.ru/applicant/vacancy_response/popup?vacancy_id=26646861</a> , yang memiliki perujuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hh.ru/vacancy/26646861?utm_source=email_campaign_123</a> . </li><li>  Nuansa dari pendekatan ini adalah bahwa jika pengguna beralih ke lowongan, dan kemudian berjalan di sekitar situs sedikit dan kemudian menanggapi lowongan, maka kami tidak akan menghitungnya. </li><li>  Kita dapat mengingat id pengguna yang beralih ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hh.ru/vacancy/26646861</a> , dan menghitung jumlah ulasan untuk lowongan pada siang hari berdasarkan database. </li></ol><br>  Pilihan pendekatan ditentukan oleh persyaratan bisnis, biasanya opsi pertama sudah cukup, tetapi semuanya tergantung pada apa yang menunggu manajer produk. <br><br><h2>  Perangkap yang mungkin terjadi </h2><br><ol><li>  Tidak semua data ada di hadoop, Anda perlu menambahkan data dari database prod.  Misalnya, dalam log biasanya hanya id, dan jika Anda memerlukan nama - maka itu ada di database.  Terkadang Anda perlu mencari pengguna dengan resume_id, dan ini juga disimpan dalam database.  Untuk melakukan ini, kami membongkar sebagian dari database di hadoop sehingga bergabung lebih mudah. </li><li>  Data mungkin berupa kurva.  Ini umumnya merupakan bencana bagi hadoop dan cara kami memuat data ke dalamnya.  Bergantung pada data, nilai kosong dapat menjadi nol, Tidak ada, tidak ada, string kosong, dll. Anda harus berhati-hati dalam setiap kasus, karena data benar-benar berbeda, dimuat dengan cara yang berbeda dan untuk tujuan yang berbeda. </li><li>  Hitungan panjang untuk seluruh periode.  Misalnya, kita perlu menghitung transisi dan tanggapan kita untuk bulan itu.  Ini sekitar 3 terabyte log.  Bahkan hadoop akan mengambil ini untuk beberapa waktu.  Biasanya menulis permintaan kerja 100% pertama kali cukup sulit, jadi kami menulisnya dengan coba-coba.  Setiap waktu untuk menunggu 20 menit adalah waktu yang sangat lama.  Cara untuk memecahkan: <br><br><ul><li>  Men-debug permintaan pada log dalam 1 hari.  Karena kami telah mempartisi data dalam hadoop, cukup cepat untuk menghitung sesuatu untuk log 1 hari. </li><li>  Unggah log yang diperlukan ke tabel sementara.  Sebagai aturan, kami memahami url apa yang kami minati, dan kami dapat membuat tabel sementara untuk log dari url ini. </li></ul><br>  Secara pribadi, opsi pertama lebih nyaman bagi saya, tetapi, kadang-kadang, saya perlu membuat tabel sementara, tergantung pada situasinya. </li><li>  Distorsi dalam metrik akhir <br><ul><li>  Lebih baik menyaring log.  Anda perlu memperhatikan, misalnya, pada kode respons, redirect, dll. Lebih baik lebih sedikit data, tetapi lebih akurat, yang Anda yakin. </li><li>  Langkah perantara sesedikit mungkin dalam metrik.  Misalnya, beralih ke lowongan adalah satu langkah (MENDAPATKAN permintaan untuk / lowongan / 123).  Responsnya adalah dua (transisi ke lowongan + POST).  Semakin pendek rantai, semakin sedikit kesalahan dan lebih akurat metriknya.  Kadang-kadang terjadi bahwa data antara transisi hilang dan umumnya tidak mungkin untuk menghitung sesuatu.  Untuk mengatasi masalah ini, kita perlu memikirkan apa yang akan kita pertimbangkan dan bagaimana sebelum mengembangkan percobaan.  Log terpisah Anda dari acara yang diperlukan sangat membantu.  Kita dapat merekam peristiwa yang diperlukan, dan dengan demikian rantai peristiwa akan lebih akurat, dan penghitungan lebih mudah. </li><li>  Bot dapat menghasilkan banyak transisi.  Anda perlu memahami ke mana bot dapat pergi (misalnya, pada halaman di mana otorisasi tidak diperlukan, mereka seharusnya tidak), dan memfilter data ini. </li><li>  Benjolan besar - misalnya, dalam salah satu grup mungkin ada satu pelamar, yang menghasilkan 50% dari semua tanggapan.  Akan ada kecenderungan statistik, data tersebut juga perlu disaring. </li></ul></li><li>  Sulit untuk merumuskan apa yang harus dipertimbangkan dalam hal log akses.  Ini membantu pengetahuan tentang basis kode, pengalaman, dan alat pengembang krom.  Kami membaca deskripsi metrik dari produk, mengulanginya dengan tangan kami di situs dan melihat transisi apa yang dihasilkan. </li></ol><br>  Akhirnya, mari kita bicara tentang bagaimana hasil perhitungan akan terlihat. <br><br><h2>  Hasil perhitungan </h2><br>  Dalam contoh kami, ada 2 grup dan 2 metrik yang membentuk corong. <br><img src="https://habrastorage.org/webt/mn/fx/cm/mnfxcmiwrbhfvxnqomoy_v_zztw.png" alt="gambar"><br>  Rekomendasi untuk melaporkan hasil: <br><br><ol><li>  Jangan membebani terlalu banyak komponen sampai diperlukan.  Sederhana dan lebih kecil lebih baik (misalnya, di sini kami dapat menampilkan setiap lowongan secara terpisah atau mengklik menurut hari).  Fokus pada satu hal. </li><li>  Detail mungkin diperlukan selama hasil demo, jadi pikirkan pertanyaan apa yang mungkin Anda tanyakan dan siapkan detailnya.  (Dalam contoh kami, perincian dapat sesuai dengan kecepatan transisi setelah mengirim email - 1 hari, 3 hari, seminggu, mengelompokkan lowongan berdasarkan area profesional) </li><li>  Ingatlah tentang signifikansi statistik.  Misalnya, perubahan 1% dengan 100 klik dan 15 klik tidak signifikan dan dapat dilakukan secara acak.  Gunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kalkulator</a> </li><li>  Otomatiskan sebanyak mungkin, karena Anda harus menghitung beberapa kali.  Biasanya di tengah eksperimen seseorang sudah ingin memahami bagaimana keadaannya.  Setelah percobaan, pertanyaan dapat muncul dan Anda harus mengklarifikasi sesuatu.  Dengan demikian, akan perlu untuk menghitung 3-4 kali, dan jika setiap perhitungan adalah urutan 10 pertanyaan dan kemudian menyalin secara manual untuk unggul, itu akan menyakitkan dan menghabiskan banyak waktu.  Belajar python, itu akan menghemat banyak waktu. </li><li>  Gunakan representasi grafis dari hasil saat diperlukan.  Alat sarang dan zeppelin bawaan memungkinkan Anda membuat grafik sederhana di luar kotak. </li></ol><br>  Penting untuk mempertimbangkan berbagai metrik cukup sering, karena kami mengeluarkan hampir setiap tugas sebagai bagian dari percobaan A / B.  Tidak ada yang rumit dalam perhitungan, setelah 2-3 percobaan pemahaman muncul tentang bagaimana melakukan ini.  Ingatlah bahwa log akses menyimpan banyak informasi berguna yang dapat menghemat uang perusahaan, membantu Anda mempromosikan ide Anda dan membuktikan opsi perubahan mana yang lebih baik.  Yang utama adalah bisa mendapatkan informasi ini. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id424251/">https://habr.com/ru/post/id424251/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id424241/index.html">Cetak duniamu</a></li>
<li><a href="../id424243/index.html">5 cara mudah untuk meningkatkan komunikasi dengan pelanggan</a></li>
<li><a href="../id424245/index.html">Menulis klien Telegram itu mudah</a></li>
<li><a href="../id424247/index.html">KotlinConf 2018 Live - tonton siarannya 4-5 Oktober</a></li>
<li><a href="../id424249/index.html">Materi dari pertemuan #RuPostgres - video, presentasi, analisis kuis, dan laporan foto</a></li>
<li><a href="../id424255/index.html">Cara menggunakan analisis statis dengan benar</a></li>
<li><a href="../id424257/index.html">Hexagon Maps in Unity: Bagian 1-3</a></li>
<li><a href="../id424259/index.html">Minggu Keamanan 36: Telnet harus ditutup</a></li>
<li><a href="../id424261/index.html">Bagaimana mengatasi masalah pemrograman</a></li>
<li><a href="../id424263/index.html">Meningkatkan IDA Pro. Kami memperbaiki jambs modul prosesor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
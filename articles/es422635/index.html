<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ú°Ô∏è üíÜüèª ü§æ A√∫n no has dicho la palabra "hola" y ya sabemos a qui√©n üíÉüèæ üèõÔ∏è üïπÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nuestra red neuronal puede hacer esto, reconociendo a una persona por una s√≠laba pronunciada. Sin embargo, el tema de este art√≠culo no est√° directamen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A√∫n no has dicho la palabra "hola" y ya sabemos a qui√©n</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/neurodatalab/blog/422635/">  Nuestra red neuronal puede hacer esto, reconociendo a una persona por una s√≠laba pronunciada.  Sin embargo, el tema de este art√≠culo no est√° directamente relacionado con la identificaci√≥n de voz, aunque s√≠ lo estar√°.  Hablaremos sobre las caracter√≠sticas de la red neuronal, el llamado d-vector, que puede usarse en tareas de procesamiento de sonido: desde la verificaci√≥n hasta el reconocimiento del habla y las emociones. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/eo/h5/k8/eoh5k8gwhm9ep4wpove1up9gljg.jpeg" alt="imagen"></div><br><a name="habracut"></a><br><h4>  <b>Materiel</b> </h4><br>  Dependiendo de la frecuencia de muestreo, un segundo de sonido puede contener de 8 a 48 mil n√∫meros.  Se pueden representar como desviaciones de la posici√≥n de equilibrio de la membrana del altavoz o el micr√≥fono.  De hecho, tal descripci√≥n del sonido es redundante: la amplitud de la se√±al en el siguiente momento depende en gran medida de la anterior, lo que sugiere que esta se√±al puede comprimirse efectivamente sin mucha p√©rdida de informaci√≥n.  Hay una gran cantidad de formas de reducir la dimensi√≥n de una se√±al, y la mayor√≠a de ellas se basan en las propiedades f√≠sicas del sonido y las caracter√≠sticas del o√≠do humano. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fh/n4/qj/fhn4qjskpumyiosbtjxzik7e9yg.jpeg" alt="imagen"></div><br>  <i>Meme 1.</i> <br><br>  Antes de que las redes neuronales funcionaran bien (en un sentido amplio), la comunidad trabaj√≥ con los llamados atributos hechos a mano.  Los m√°s famosos y ampliamente utilizados son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pitch</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MFCC</a> .  El primero tiene un significado f√≠sico de la frecuencia de las oscilaciones de las cuerdas vocales, que difieren, por ejemplo, para diferentes personas, y tambi√©n dependen de la entonaci√≥n.  La idea de los coeficientes cepstrales (MFCC) se basa en la no linealidad de la percepci√≥n humana del sonido, es decir, la frecuencia y el volumen.  A una persona le parece que un sonido es m√°s alto que otro en cierta medida, si en realidad sus frecuencias difieren en un cierto n√∫mero de veces. <br><br>  Estas y otras caracter√≠sticas calculadas manualmente son irreversibles en el sentido de que parte de la se√±al se pierde para siempre.  En algunas tareas esto no es cr√≠tico, pero me gustar√≠a proponer un enfoque m√°s universal y funcional. <br><br>  La clave para resolver este problema es la transformaci√≥n de Fourier.  Al usarlo, puede imaginar una se√±al de audio como la suma de ondas con diferentes frecuencias y amplitudes.  De hecho, el habla no es estacionaria en el sentido de que su espectro ser√° cualitativamente diferente en diferentes momentos.  Esto nos permite considerarlo en la representaci√≥n de frecuencia de tiempo, usando <i>espectrogramas</i> . <br><br>  Para construir un espectrograma, debe dividir el sonido en secciones de intersecci√≥n (marcos superpuestos) de varias decenas de milisegundos de longitud, para cada uno de ellos calcular la transformada de Fourier y escribir sus m√≥dulos en columnas en los espectrogramas.  Adem√°s, dicha transformaci√≥n es casi mutuamente inversa, es decir, utilizando la transformaci√≥n inversa de Fourier y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el algoritmo Griffin-Lim,</a> puede restaurar la se√±al de sonido original (de hecho, hay p√©rdida de informaci√≥n, ya que la transformaci√≥n de Fourier es compleja en el caso general, y el espectrograma tiene un valor real, y, para aproximar la recuperaci√≥n de fase, generalmente se usa el algoritmo iterativo Griffin-Lim).  Total, si tomamos el logaritmo de las amplitudes, obtenemos estas im√°genes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ux/ig/xz/uxigxzafbu938strrzeepi8s-ro.png" alt="imagen"></div><br>  <i>Espectrograma de 5 segundos de discurso.</i> <br><br>  Y son procesados ‚Äã‚Äãconvenientemente por redes convolucionales. <br><br>  Tal pirateo se usa a menudo en tareas de procesamiento de im√°genes: existen grandes bases de datos con ejemplos de diferentes objetos (por ejemplo, ImageNet).  Puede entrenar una cuadr√≠cula grande para reconocerlos y luego volver a entrenarla en nuestra tarea espec√≠fica, o tomar el resultado de salida de una de las capas internas completamente conectadas.  Se cree que dicha arquitectura calcular√° buenas caracter√≠sticas informativas para las im√°genes de entrada.  La experiencia sugiere que casi siempre los resultados ser√°n mejores que si entrenamos la red neuronal desde cero. <br><br>  La idea de los vectores d (generalmente vectores d, pero a veces llamados vectores x) es similar al uso de cuadr√≠culas previamente entrenadas en ImageNet, excepto por el hecho de que no hay bases similares para los espectrogramas.  Como una posible salida, se pueden considerar los codificadores autom√°ticos, pero a priori no saben qu√© buscar en el espectrograma, por lo tanto, funcionan de manera insatisfactoria. <br><br><h4>  <b>Necesitamos profundizar</b> </h4><br>  Atenci√≥n, comienza la parte principal de este art√≠culo. <br><br>  La tarea de verificar a una persona por voz es ampliamente conocida, donde es necesario determinar por el segmento de entrada del discurso cu√°l de las personas en la base de datos lo dijo.  De hecho, la construcci√≥n de tales sistemas es una ciencia separada, y hay muchos complementos diferentes (duraci√≥n del discurso; se requiere que todos hablen el mismo texto; escenificando uno contra uno o uno contra todos), que son cr√≠ticos bajo diferentes condiciones, pero para nosotros necesitas prestar atenci√≥n a otra cosa. <br><br>  A saber: qu√© tan buenas ser√°n las caracter√≠sticas si pre-entrenamos la grilla para reconocer a una persona.  Todo se hace por el bien de los signos. <br><br>  Esto nos ayudar√° a la intuici√≥n y al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo de</a> 2015.  En ella, los autores ense√±an a la cuadr√≠cula a reconocer a una persona por la cara (reconocimiento facial).  La clave de este trabajo es utilizar la p√©rdida de triplete. <br><br>  Su idea es muy simple: normalizamos las caracter√≠sticas de la pen√∫ltima capa para que se encuentren en una esfera unitaria y exijan que los puntos de una clase se encuentren cerca y lejos de ser diferentes.  Esto se puede lograr de la siguiente manera: para cada ejemplo de entrenamiento (ancla) encontramos dos m√°s de la misma clase y de otra clase en la muestra: positiva y negativa.  Luego, para estos triples puntos formamos una p√©rdida: <br><br>  \ begin {ecuaci√≥n} <br>  \ Big [\ Vert f (x ^ a) - f (x ^ p) \ Vert - \ Vert f (x ^ a) - f (x ^ n) \ Vert + \ alpha \ Big] _ +, <br>  \ end {ecuaci√≥n} <br><br>  donde x es la imagen de entrada, f es la salida de la cuadr√≠cula despu√©s de la normalizaci√≥n, alfa es el par√°metro seleccionado manualmente, [] _ ‚Äã‚Äã{+} es la funci√≥n ReLU.  Cualitativamente, el valor de esta p√©rdida es cero si la distancia entre el ancla y los puntos positivos es mayor que la distancia entre el ancla y el negativo en al menos alfa, y cuanto mayor sea la diferencia entre dos clases diferentes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fp/k6/yy/fpk6yyh_hd1hb00bsdcg39xyuqc.png" alt="imagen"></div><br>  <i>Una ilustraci√≥n de lo que sucede con las caracter√≠sticas despu√©s del entrenamiento con Triplet Loss.</i> <br><br>  Por cierto, puedes formar triples de una manera inteligente.  En alg√∫n momento, la magnitud de la p√©rdida se volver√° peque√±a, y para acelerar el aprendizaje, puede buscar ejemplos negativos no entre todas las otras clases, pero considere solo aquellos cercanos al ancla.  Pero para grandes conjuntos de datos, esto es dif√≠cil, porque debe considerar las distancias por pares entre las clases que cambian despu√©s de cada iteraci√≥n del aprendizaje en red. <br><br>  La p√©rdida de triplete tiene una ventaja sobre la crossentrop√≠a categ√≥rica, que se usa en la clasificaci√≥n convencional.  Un modelo entrenado con entrop√≠a cruzada intentar√° agrupar todos los puntos de una clase en un √°rea cada vez m√°s peque√±a, y la informaci√≥n que es superflua para una tarea en particular puede perderse.  Pero no queremos esto, porque vamos a utilizar la red neuronal como un generador de caracter√≠sticas, y no para verificaci√≥n.  La p√©rdida de triplete tiene esta propiedad en un grado mucho menor: es m√°s importante que difunda diferentes clases en diferentes √°reas en una sola esfera que aburrir una clase. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pn/pt/nz/pnptnzxqejabade7orpavbtx5se.jpeg" alt="imagen"></div><br>  <i>Meme 2.</i> <br><br>  Lo √∫ltimo que debe hacer antes de entrenar al generador de caracter√≠sticas en espectrogramas es determinar sus tama√±os.  Obviamente, la precisi√≥n de la clasificaci√≥n ser√° mayor, mayor ser√° el per√≠odo de tiempo que consideraremos, pero aparecer√°n los signos m√°s "promediados".  Por lo tanto, es razonable usar una longitud de se√±al tal que caiga dentro de 1 a 3 fonemas (s√≠labas); medio segundo parece apropiado. <br><br>  Para el entrenamiento, tomamos el conjunto de datos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VoxCeleb2</a> , donde para cada uno de los altavoces 6300 hay varias grabaciones de audio separadas de varios minutos cada una (realizadas en diferentes condiciones).  Usamos parte de los archivos de audio para el entrenamiento, y el resto para la validaci√≥n, seleccionamos la arquitectura de red de convoluci√≥n, le agregamos Triplet Loss y aprendemos. <br><br>  Los resultados fueron muy buenos.  En casi 2 semanas de entrenamiento a 1080Ti (s√≠, durante tanto tiempo), la precisi√≥n de clasificaci√≥n alcanz√≥ el 55%.  Parece que no mucho, pero la precisi√≥n del top 5 es del 78%, y si consideramos solo la mitad m√°s ruidosa de los fragmentos, que en su mayor√≠a son vocales estresadas, la precisi√≥n del top 5 aumentar√° al 91%.  Podemos decir que podemos identificar a una persona por una de sus frases con una precisi√≥n decente.  Pero no importa. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vz/el/21/vzel21arcsvyrco_kg_95usxziy.jpeg" alt="imagen"></div><br>  <i>Meme 3.</i> <br><br>  Despu√©s de todo, todo comenz√≥ para caracter√≠sticas que se pueden obtener como una salida de la pen√∫ltima antes de clasificar la capa de red neuronal.  Los probamos en nuestras tareas, y en todas partes los resultados fueron mejores que el uso de enfoques cl√°sicos para calcular atributos.  Por ejemplo, en el problema del reconocimiento de emociones, el uso de vectores d nos permiti√≥ evitar el estado del arte en un 4%, y el art√≠culo correspondiente fue aceptado en la conferencia FICC 2019. Sin embargo, el reconocimiento de emociones es una historia completamente diferente, de la que hablaremos m√°s adelante. <br><br>  Publicado por <b>Gregory Sterling</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">sterling239</a> , Experto en aprendizaje profundo, Neurodata Lab. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es422635/">https://habr.com/ru/post/es422635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es422625/index.html">Hablamos con Troy Miles, el programador de "Neuromancer"</a></li>
<li><a href="../es422627/index.html">MongoDB y la investigaci√≥n de mercado de trabajo de TI</a></li>
<li><a href="../es422629/index.html">¬°Deja de alimentar a los madereros! ¬°Da m√°s modificadores! Campos finales est√°ticos perezosos. Borrador de croquis de funciones</a></li>
<li><a href="../es422631/index.html">Terminales QIWI. C√≥mo aprovechar al m√°ximo las tecnolog√≠as simples</a></li>
<li><a href="../es422633/index.html">C√≥mo automatizamos el monitoreo del trabajo de los empleados de la red federal de estaciones de servicio</a></li>
<li><a href="../es422637/index.html">Regalo de geek: protecci√≥n autom√°tica</a></li>
<li><a href="../es422641/index.html">Noche polar, bombeo de agua y caja fuerte inteligente: 5 proyectos de estudiantes en el campo de IoT</a></li>
<li><a href="../es422643/index.html">Nuevos dispositivos con IFA 2018</a></li>
<li><a href="../es422645/index.html">¬øCu√°l es la importancia de 196 884 = 196 883 + 1? ¬øC√≥mo explicarlo con los dedos?</a></li>
<li><a href="../es422649/index.html">Multijugador VR: ¬øc√≥mo implementarlo?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
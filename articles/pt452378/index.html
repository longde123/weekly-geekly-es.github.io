<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçü§ù‚Äçüë®üèº üí• üë®‚Äçüíº Classifica√ß√£o da cobertura do solo usando o eo-learn. Parte 2 üë®üèø‚Äçüé® ‚ôàÔ∏è üê∏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Parte 1 
 Parte 3 


 Mover de dados para resultados sem sair do computador 



 Uma pilha de imagens de uma pequena zona na Eslov√™nia e um mapa com u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Classifica√ß√£o da cobertura do solo usando o eo-learn. Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452378/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 1</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 3</a> </p><br><p>  Mover de dados para resultados sem sair do computador </p><br><p><img src="https://habrastorage.org/webt/hq/kv/ie/hqkviehem-itsqlacwosv2hjdco.png"><br>  <em>Uma pilha de imagens de uma pequena zona na Eslov√™nia e um mapa com uma cobertura do solo classificada obtida usando os m√©todos descritos no artigo.</em> </p><a name="habracut"></a><br><h2 id="predislovie">  Pref√°cio </h2><br><p>  A segunda parte de uma s√©rie de artigos sobre classifica√ß√£o da cobertura do solo usando a biblioteca eo-learn.  Lembramos que o primeiro artigo demonstrou o seguinte: </p><br><ul><li>  Dividindo a AOI (√°rea de interesse) em fragmentos chamados EOPatch </li><li>  Recebendo imagens e m√°scaras na nuvem dos sat√©lites Sentinel-2 </li><li>  C√°lculo de informa√ß√µes adicionais, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NDWI</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NDVI</a> </li><li>  Criando uma m√°scara de refer√™ncia e adicionando-a aos dados de origem </li></ul><br><p>  Al√©m disso, realizamos um estudo de superf√≠cie dos dados, que √© uma etapa extremamente importante antes de iniciar um mergulho no aprendizado de m√°quina.  As tarefas acima foram complementadas por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um exemplo na forma de um caderno Jupyter</a> , que agora cont√©m material deste artigo. </p><br><p>  Neste artigo, concluiremos a prepara√ß√£o dos dados e tamb√©m construiremos o primeiro modelo para a constru√ß√£o de mapas de cobertura da terra para a Eslov√™nia em 2017. </p><br><h2 id="podgotovka-dannyh">  Prepara√ß√£o de dados </h2><br><p>  A quantidade de c√≥digo diretamente relacionada ao aprendizado de m√°quina √© muito pequena em compara√ß√£o com o programa completo.  A maior parte do trabalho √© limpar os dados, manipular os dados de forma a garantir o uso cont√≠nuo com o classificador.  Esta parte do trabalho ser√° descrita abaixo. </p><br><p><img src="https://habrastorage.org/webt/gd/sj/4i/gdsj4iapqdgkldjwowfx-6p7bgg.jpeg"></p><br><p>  <em>Um diagrama de pipeline de aprendizado de m√°quina que mostra que o pr√≥prio c√≥digo usando ML √© uma pequena fra√ß√£o de todo o processo.</em>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fonte</a></em> </p><br><h3 id="filtraciya-oblachnyh-izobrazheniy">  Filtragem de imagens na nuvem </h3><br><p>  Nuvens s√£o entidades que geralmente aparecem em uma escala que excede nosso EOPatch m√©dio (1000x1000 pixels, resolu√ß√£o 10m).  Isso significa que qualquer site pode ser completamente coberto por nuvens em datas aleat√≥rias.  Como essas imagens n√£o cont√™m informa√ß√µes √∫teis e consomem apenas recursos, as ignoramos com base na propor√ß√£o de pixels v√°lidos em rela√ß√£o ao n√∫mero total e definimos um limite.  Podemos chamar v√°lidos todos os pixels que n√£o s√£o classificados como nuvens e est√£o localizados dentro de uma imagem de sat√©lite.  Observe tamb√©m que n√£o usamos as m√°scaras fornecidas com as imagens do Sentinel-2, pois elas s√£o calculadas no n√≠vel de imagens completas (o tamanho da imagem S2 completa √© 10980 √ó 10980 pixels, aproximadamente 110 √ó 110 km), o que significa que, na maioria das vezes, n√£o √© necess√°ria para a nossa AOI.  Para determinar as nuvens, usaremos o algoritmo do pacote <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">s2cloudless</a> para obter uma m√°scara de pixels da nuvem. </p><br><p>  Em nosso notebook, o limite √© definido como 0,8; portanto, selecionamos apenas as imagens preenchidas com dados normais em 80%.  Isso pode parecer um valor bastante alto, mas como as nuvens n√£o s√£o um problema muito grande para a nossa AOI, podemos compr√°-lo.  Vale a pena considerar que essa abordagem n√£o pode ser aplicada sem pensar em qualquer ponto do planeta, pois a √°rea que voc√™ escolheu pode ser coberta de nuvens por uma parte significativa do ano. </p><br><h3 id="temporalnaya-interpolyaciya">  Interpola√ß√£o temporal </h3><br><p>  Devido ao fato de que as imagens podem ser puladas em algumas datas, bem como devido a datas inconsistentes de aquisi√ß√£o da AOI, a falta de dados √© uma ocorr√™ncia muito comum no campo de observa√ß√£o da Terra.  Uma maneira de resolver esse problema √© mascarar a validade dos pixels (da etapa anterior) e interpolar os valores para "preencher buracos".  Como resultado do processo de interpola√ß√£o, os valores de pixel ausentes podem ser calculados para criar um EOPatch que cont√©m capturas instant√¢neas em dias distribu√≠dos uniformemente.  Neste exemplo, usamos interpola√ß√£o linear, mas existem outros m√©todos, alguns dos quais j√° est√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">implementados</a> no eo-learn. </p><br><p><img src="https://habrastorage.org/webt/uf/va/ho/ufvahoeiz3u3shfdshioiuommlo.png"><br>  <em>√Ä esquerda, h√° uma pilha de imagens do Sentinel-2 de uma AOI selecionada aleatoriamente.</em>  <em>Pixels transparentes significam dados ausentes devido a nuvens.</em>  <em>A imagem √† direita mostra a pilha ap√≥s a interpola√ß√£o, levando em considera√ß√£o as m√°scaras da nuvem.</em> </p><br><p>  A informa√ß√£o temporal √© extremamente importante na classifica√ß√£o da cobertura e ainda mais importante na tarefa de identificar uma cultura emergente.  Tudo isso se deve ao fato de que uma grande quantidade de informa√ß√µes sobre a cobertura do solo est√° oculta na forma como a parcela muda ao longo do ano.  Por exemplo, ao visualizar os valores NDVI interpolados, √© poss√≠vel ver que os valores nas florestas e campos atingem seus m√°ximos na primavera / ver√£o e caem fortemente no outono / inverno, enquanto a √°gua e as superf√≠cies artificiais mant√™m esses valores aproximadamente constantes ao longo do ano.  As superf√≠cies artificiais t√™m valores de NDVI ligeiramente mais altos em compara√ß√£o com a √°gua e repetem parcialmente o desenvolvimento de florestas e campos, j√° que nas cidades geralmente √© poss√≠vel encontrar parques e outras vegeta√ß√µes.  Voc√™ tamb√©m deve levar em considera√ß√£o as limita√ß√µes associadas √† resolu√ß√£o das imagens - geralmente na √°rea coberta por um pixel, √© poss√≠vel observar v√°rios tipos de cobertura ao mesmo tempo. </p><br><p><img src="https://habrastorage.org/webt/cj/mx/8s/cjmx8sdns2mzfv5nq9hko7apno4.png"><br>  <em>Desenvolvimento temporal dos valores NDVI para pixels de tipos espec√≠ficos de cobertura do solo ao longo do ano</em> </p><br><h3 id="otricatelnaya-buferizaciya">  Buffer negativo </h3><br><p>  Embora uma resolu√ß√£o de imagem de 10m seja suficiente para uma ampla gama de tarefas, os efeitos colaterais de objetos pequenos s√£o bastante significativos.  Esses objetos est√£o na borda entre diferentes tipos de capa e esses pixels recebem os valores de apenas um dos tipos.  Por isso, ao treinar o classificador, o excesso de ru√≠do est√° presente nos dados de entrada, o que piora o resultado.  Al√©m disso, estradas e outros objetos com uma largura de 1 pixel est√£o presentes no mapa original, embora sejam extremamente dif√≠ceis de identificar a partir das imagens.  Aplicamos buffer negativo de 1 pixel ao mapa de refer√™ncia, removendo quase todas as √°reas problem√°ticas da entrada. </p><br><p><img src="https://habrastorage.org/webt/-m/u4/ep/-mu4epr9om3nqrmfdeoedefadqi.png"><br>  <em>Mapa de refer√™ncia da AOI antes (esquerda) e depois (direita) do buffer negativo</em> </p><br><h3 id="sluchaynyy-vybor-dannyh">  Sele√ß√£o aleat√≥ria de dados </h3><br><p>  Como mencionado em um artigo anterior, a AOI completa √© dividida em aproximadamente 300 fragmentos, cada um dos quais consiste em ~ 1 milh√£o de pixels.  Essa √© uma quantidade impressionante desses mesmos pixels; portanto, usamos aproximadamente 40.000 pixels para cada EOPatch para obter um conjunto de dados de 12 milh√µes de c√≥pias.  Como os pixels s√£o tirados uniformemente, um grande n√∫mero n√£o importa no mapa de refer√™ncia, pois esses dados s√£o desconhecidos (ou foram perdidos ap√≥s a etapa anterior).  Faz sentido filtrar esses dados para simplificar o treinamento do classificador, pois n√£o precisamos ensin√°-lo a definir o r√≥tulo "sem dados".  O mesmo procedimento √© repetido para o conjunto de testes, pois esses dados degradam artificialmente os indicadores de qualidade das previs√µes do classificador. </p><br><h3 id="razdelenie-i-formirovanie-dannyh">  Separa√ß√£o e gera√ß√£o de dados </h3><br><p> Dividimos os dados de entrada em conjuntos de treinamento / teste na propor√ß√£o de 80/20%, respectivamente, no n√≠vel EOPatch, o que nos garante que esses conjuntos n√£o se cruzam.  Tamb√©m dividimos os pixels do conjunto para treinamento em conjuntos para teste e valida√ß√£o cruzada da mesma maneira.  Ap√≥s a separa√ß√£o, obtemos uma matriz <code>numpy.ndarray</code> de dimens√£o <code>(p,t,w,h,d)</code> , em que: <br>  <em><code>p</code> √© o n√∫mero de <code>EOPatch</code> no conjunto de dados</em> <em><br></em>  <code>t</code> - o n√∫mero de imagens interpoladas para cada EOPatch <br>  * <code>w, h, d</code> - largura, altura e o n√∫mero de camadas nas imagens, respectivamente. </p><br><p>  Ap√≥s selecionar os subconjuntos, a largura <code>w</code> corresponde ao n√∫mero de pixels selecionados (por exemplo, 40.000), enquanto a dimens√£o <code>h</code> √© 1. A diferen√ßa na forma da matriz n√£o muda nada, esse procedimento √© necess√°rio apenas para simplificar o trabalho com imagens. </p><br><p>  Os dados dos sensores e da m√°scara <code>d</code> em qualquer imagem t determinam os dados de entrada para treinamento, onde essas inst√¢ncias totalizam <code>p*w*h</code> .  Para converter os dados em um formul√°rio diger√≠vel pelo classificador, devemos reduzir a dimens√£o da matriz de 5 para a matriz do formul√°rio <code>(p*w*h, d*t)</code> .  Isso √© f√°cil de usar, usando o seguinte c√≥digo: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np p, t, w, h, d = features_array.shape <span class="hljs-comment"><span class="hljs-comment">#   t axis   1   3 features_array = np.moveaxis(features_array, 1, 3) #    features_array = features_array.reshape(p*w*h, t*d)</span></span></code> </pre> <br><p>  Esse procedimento tornar√° poss√≠vel fazer uma previs√£o de novos dados da mesma forma e, em seguida, convert√™-los novamente e visualiz√°-los por meios padr√£o. </p><br><h3 id="sozdanie-modeli-dlya-mashinnogo-obucheniya">  Criando um modelo de aprendizado de m√°quina </h3><br><p>  A escolha ideal do classificador depende fortemente da tarefa espec√≠fica e, mesmo com a escolha certa, n√£o devemos esquecer os par√¢metros de um modelo espec√≠fico, que devem ser alterados de tarefa para tarefa.  Geralmente √© necess√°rio realizar muitas experi√™ncias com diferentes conjuntos de par√¢metros para dizer com precis√£o o que √© necess√°rio em uma situa√ß√£o espec√≠fica. </p><br><p>  Nesta s√©rie de artigos, usamos o pacote <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LightGBM</a> , porque √© uma estrutura intuitiva, r√°pida, distribu√≠da e produtiva para a constru√ß√£o de modelos baseados em √°rvores de decis√£o.  Para selecionar os hiperpar√¢metros do classificador, pode-se usar abordagens diferentes, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a pesquisa em grade</a> , que deve ser testada em um conjunto de testes.  Por uma quest√£o de simplicidade, pularemos esta etapa e usaremos os par√¢metros padr√£o. </p><br><p><img src="https://habrastorage.org/webt/ik/ds/gr/ikdsgrz5mfdrifwakch1pvv1wey.png"><br>  <em>O esquema do trabalho das √°rvores de decis√£o no LightGBM.</em>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fonte</a> </p><br><p>  A implementa√ß√£o do modelo √© bastante simples e, como os dados j√° v√™m na forma de uma matriz, simplesmente alimentamos esses dados na entrada do modelo e aguardamos.  Parab√©ns!  Agora voc√™ pode dizer a todos que est√° envolvido em aprendizado de m√°quina e ser√° o cara mais elegante de uma festa, enquanto sua m√£e ficar√° nervosa com a rebeli√£o de rob√¥s e a morte da humanidade. </p><br><h2 id="validaciya-modeli">  Valida√ß√£o de modelo </h2><br><p>  Modelos de treinamento em aprendizado de m√°quina s√£o f√°ceis.  A dificuldade √© trein√°-los <strong>bem</strong> .  Para isso, precisamos de um algoritmo adequado, um cart√£o de refer√™ncia confi√°vel e uma quantidade suficiente de recursos de computa√ß√£o.  Mas mesmo nesse caso, os resultados podem n√£o ser o que voc√™ queria, portanto, verificar o classificador com matrizes de erro e outras m√©tricas √© absolutamente necess√°rio para pelo menos alguma confian√ßa nos resultados do seu trabalho. </p><br><h3 id="matrica-oshibok">  Matriz de erro </h3><br><p>  Matrizes de erro s√£o as primeiras coisas a serem observadas ao avaliar a qualidade dos classificadores.  Eles mostram o n√∫mero de tags previstas correta e incorretamente para cada tag do cart√£o de refer√™ncia e vice-versa.  Geralmente, uma matriz normalizada √© usada, onde todos os valores nas linhas s√£o divididos pela quantidade total.  Isso mostra se o classificador n√£o possui um vi√©s em rela√ß√£o a um determinado tipo de cobertura em rela√ß√£o a outro </p><br><p><img src="https://habrastorage.org/webt/rg/3m/xd/rg3mxdktoqpvxy76j_jvfkgpzw4.png"><br>  <em>Duas matrizes de erro normalizadas do modelo treinado.</em> </p><br><p>  Para a maioria das classes, o modelo mostra bons resultados.  Para algumas classes, os erros ocorrem devido ao desequil√≠brio nos dados de entrada.  Vimos que o problema √©, por exemplo, arbustos e √°gua, para os quais o modelo geralmente confunde r√≥tulos de pixel e os identifica incorretamente.  Por outro lado, o que √© marcado como mato ou √°gua se correlaciona bastante bem com o mapa de refer√™ncia.  A partir da imagem a seguir, podemos observar que surgem problemas para as classes que possuem um pequeno n√∫mero de inst√¢ncias de treinamento - isso se deve principalmente √† pequena quantidade de dados em nosso exemplo, mas esse problema pode ocorrer em qualquer tarefa real. </p><br><p><img src="https://habrastorage.org/webt/4f/8l/qz/4f8lqz3q4xyxjyp3xp3e9usb_qg.png"></p><br><p>  <em>A frequ√™ncia de ocorr√™ncia de pixels de cada classe no conjunto de treinamento.</em> </p><br><h3 id="reciever-operating-characteristic---roc-krivaya">  Caracter√≠stica de Opera√ß√£o do Receptor - Curva ROC </h3><br><p>  Os classificadores preveem r√≥tulos com uma certa certeza, mas esse limite para um r√≥tulo espec√≠fico pode ser alterado.  A curva ROC mostra a capacidade do classificador de fazer previs√µes corretas ao alterar o limiar de sensibilidade.  Normalmente, este gr√°fico √© usado para sistemas <strong>bin√°rios</strong> , mas pode ser usado em nosso caso se calcularmos a caracter√≠stica "r√≥tulo versus todos os outros" para cada classe.  O eixo x mostra resultados falso-positivos (precisamos minimizar o n√∫mero deles), e o eixo y mostra resultados positivos positivos (precisamos aumentar o n√∫mero) em diferentes limites.  Um bom classificador pode ser descrito por uma curva sob a qual a √°rea da curva √© m√°xima.  Este indicador tamb√©m √© conhecido como √°rea sob curva, AUC.  A partir dos gr√°ficos das curvas ROC, pode-se tirar as mesmas conclus√µes sobre um n√∫mero insuficiente de exemplos da classe "mato", embora a curva para a √°gua pare√ßa muito melhor - isso se deve ao fato de que visualmente a √°gua √© muito diferente de outras classes, mesmo com um n√∫mero insuficiente de exemplos nos dados. </p><br><p><img src="https://habrastorage.org/webt/v2/b5/_c/v2b5_cp7omqsxgg9v-bqaqmlk8u.png"><br>  <em>Curvas ROC do classificador, na forma de "um contra todos" para cada classe.</em>  <em>Os n√∫meros entre par√™nteses s√£o valores da AUC.</em> </p><br><h3 id="vazhnost-priznakov">  A import√¢ncia dos sintomas </h3><br><p>  Se voc√™ deseja aprofundar-se nas complexidades do classificador, pode olhar para o gr√°fico de import√¢ncia do recurso, que nos diz quais dos sinais influenciaram mais o resultado final.  Alguns algoritmos de aprendizado de m√°quina, como o que usamos neste artigo, retornam esses valores.  Para outros modelos, essa m√©trica deve ser considerada por n√≥s mesmos. </p><br><p><img src="https://habrastorage.org/webt/x9/ui/d6/x9uid68f7bbim-g4nfusppu9cuu.png"><br>  <em>A matriz de import√¢ncia das caracter√≠sticas para o classificador do exemplo</em> </p><br><p>  Embora outros sinais na primavera (NDVI) sejam geralmente mais importantes, vemos que h√° uma data exata em que um dos sinais (B2 - azul) √© o mais importante.  Se voc√™ olhar as fotos, verifica-se que a AOI durante esse per√≠odo estava coberta de neve.  Pode-se concluir que a neve revela informa√ß√µes sobre a cobertura subjacente, o que ajuda muito o classificador a determinar o tipo de superf√≠cie.  Vale lembrar que esse fen√¥meno √© espec√≠fico da AOI observada e, em geral, n√£o pode ser invocado. </p><br><p><img src="https://habrastorage.org/webt/qv/h1/ak/qvh1ak0bil0qhgt0ax77j0vl1dc.png"><br>  <em>3x3 EOPatch AOI parte coberta de neve</em> </p><br><h2 id="rezultaty-predskazaniy">  Resultados de previs√£o </h2><br><p>  Ap√≥s a valida√ß√£o, entendemos melhor os pontos fortes e fracos do nosso modelo.  Se n√£o estivermos satisfeitos com a situa√ß√£o atual, voc√™ pode fazer altera√ß√µes no pipeline e tentar novamente.  Ap√≥s otimizar o modelo, definimos uma EOTask simples que aceita o EOPatch e o modelo classificador, faz uma previs√£o e a aplica ao fragmento. </p><br><p><img src="https://habrastorage.org/webt/bn/d4/8u/bnd48uzm8dp75_2rjgba0enxwlg.png"><br>  <em>Imagem do Sentinel-2 (esquerda), verdade (centro) e previs√£o (direita) de um fragmento aleat√≥rio da AOI.</em>  <em>Voc√™ pode notar algumas diferen√ßas nas imagens, que podem ser explicadas pelo uso de buffer negativo no mapa original.</em>  <em>Em geral, o resultado para este exemplo √© satisfat√≥rio.</em> </p><br><p>  O caminho mais adiante √© claro.  √â necess√°rio repetir o procedimento para todos os fragmentos.  Voc√™ pode at√© export√°-los no formato GeoTIFF e col√°-los usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">gdal_merge.py</a> . </p><br><p>  Fizemos upload do GeoTIFF colado no nosso portal GeoPedia, voc√™ pode ver os resultados em detalhes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> </p><br><p><img src="https://habrastorage.org/webt/mw/gu/jo/mwgujo8q9zai7myheycgaomcwni.png"><br>  <em>Captura de tela da previs√£o de cobertura da terra na Eslov√™nia 2017 usando a abordagem deste post.</em>  <em>Dispon√≠vel em formato interativo no link acima</em> </p><br><p>  Voc√™ tamb√©m pode comparar dados oficiais com o resultado do classificador.  Preste aten√ß√£o √† diferen√ßa entre os conceitos de <em>uso</em> e <em>cobertura do solo</em> , que geralmente s√£o encontrados em tarefas de aprendizado de m√°quina - nem sempre √© f√°cil mapear dados de registros oficiais para aulas na natureza.  Como exemplo, mostramos dois aeroportos na Eslov√™nia.  O primeiro √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Levets, perto da cidade de Celje</a> .  Este aeroporto √© pequeno, usado principalmente para jatos particulares e √© coberto de grama.  Oficialmente, o territ√≥rio √© marcado como superf√≠cie artificial, embora o classificador seja capaz de identificar corretamente o territ√≥rio como grama, veja abaixo. </p><br><p><img src="https://habrastorage.org/webt/bj/ps/vo/bjpsvoabp90ud12fouuyg1dza3y.png"><br>  <em>Imagem do Sentinel-2 (esquerda), verdadeira (centro) e previs√£o (direita) da √°rea em torno do pequeno aeroporto esportivo.</em>  <em>O classificador define a pista como grama, embora seja marcada como superf√≠cie artificial nos dados atuais.</em> </p><br><p>  Por outro lado, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no maior aeroporto da Eslov√™nia, Liubliana</a> , as zonas marcadas como superf√≠cie artificial no mapa s√£o estradas.  Nesse caso, o classificador distingue entre estruturas, enquanto distingue corretamente grama e campos no territ√≥rio vizinho. </p><br><p><img src="https://habrastorage.org/webt/bs/oa/c-/bsoac-m7f9jdus4nqh7gl0v8ij0.png"><br>  <em>Imagem do Sentinel-2 (esquerda), verdade (centro) e previs√£o (direita) da √°rea em torno de Lubliana.</em>  <em>O classificador determina a pista e as estradas, enquanto distingue corretamente grama e campos na vizinhan√ßa</em> </p><br><p>  Voila! </p><br><p>  Agora voc√™ sabe como criar um modelo confi√°vel em escala nacional!  Lembre-se de adicionar isso ao seu curr√≠culo. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt452378/">https://habr.com/ru/post/pt452378/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt452366/index.html">Novo sensor CMOS aprimora os recursos de objetos em movimento</a></li>
<li><a href="../pt452368/index.html">Quinze pequenas coisas √∫teis para gerenciamento de documentos eletr√¥nicos</a></li>
<li><a href="../pt452370/index.html">Como uma impressora 3D ajudou um adolescente em um bombardeio a obter uma nova m√£o</a></li>
<li><a href="../pt452372/index.html">Agora, bons desenvolvedores s√£o medidos por visualiza√ß√µes e assinantes. Isso √© ruim?</a></li>
<li><a href="../pt452376/index.html">A m√°gica dos n√∫meros em n√∫meros decimais</a></li>
<li><a href="../pt452382/index.html">Not√≠cias da semana: Autonomous Runet Control Center, US $ 8000 bitcoin, vulnerabilidade nos processadores Intel</a></li>
<li><a href="../pt452384/index.html">O processador acelerar√° a √≥tica para 800 Gb / s: como funciona</a></li>
<li><a href="../pt452388/index.html">Peneira de Erat√≥stenes al√©m de O (n). Prova</a></li>
<li><a href="../pt452390/index.html">R√°dio definido por software - como funciona? Parte 3</a></li>
<li><a href="../pt452392/index.html">Uma sele√ß√£o de conjuntos de dados de aprendizado de m√°quina</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
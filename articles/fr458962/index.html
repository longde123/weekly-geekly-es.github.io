<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😎 🌧️ ☯️ Convertissez l'image en son - qu'entendez-vous? 👨‍💼 👩🏿‍🔧 👨🏼‍⚕️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut Habr. 

 Une publication récente ici sur le site décrit un appareil qui permet aux aveugles de «voir» une image, la transformant à l'aide d'onde...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Convertissez l'image en son - qu'entendez-vous?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458962/">  Salut Habr. <br><br>  Une publication récente ici sur le site décrit un appareil qui permet aux aveugles de «voir» une image, la transformant à l'aide d'ondes sonores.  D'un point de vue technique, dans cet article, il n'y avait aucun détail (et <s>si l'idée d'un million était volée</s> ), mais le concept lui-même semblait intéressant.  Ayant une certaine expérience du traitement du signal, j'ai décidé d'expérimenter par moi-même. <br><br><img src="https://habrastorage.org/webt/ki/st/ip/kistiptqvnn-pmxshurxrawkqze.png"><br><br>  Ce qui en est sorti, détails et exemples de fichiers sous le chat. <br><a name="habracut"></a><br><h2>  Convertir 2D en 1D </h2><br>  La première tâche évidente qui nous attend est de convertir une image "plate" bidimensionnelle en une onde sonore "unidimensionnelle".  Comme suggéré dans les commentaires sur cet article, il est pratique d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la courbe de Hilbert</a> pour cela. <br><img src="https://habrastorage.org/webt/kk/n9/2o/kkn92oz48liofrdsozg5jamskcq.gif"><br>  Il est essentiellement similaire à une fractale, et l'idée est qu'avec une augmentation de la résolution de l'image, la position relative des objets ne change pas (si l'objet était dans le coin supérieur gauche de l'image, il <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">y restera</a> ).  Différentes dimensions des courbes de Hilbert peuvent nous donner des images différentes: 32x32 pour N = 5, 64x64 pour N = 6, etc.  En «parcourant» l'image le long de cette courbe, nous obtenons une ligne, un objet unidimensionnel. <br><br>  La question suivante est la taille de l'image.  Je veux intuitivement prendre une image plus grande, mais il y a un grand «mais»: même l'image est 512x512, elle est 262144 pixels.  Si nous convertissons chaque point en une impulsion audio, alors à une fréquence d'échantillonnage de 44100, nous obtenons une séquence de 6 secondes, ce qui est trop long - les images doivent être mises à jour rapidement, par exemple à l'aide d'une caméra Web.  Cela n'a aucun sens d'augmenter la fréquence d'échantillonnage; nous obtenons des fréquences ultrasoniques qui sont inaudibles par l'oreille (bien que cela puisse fonctionner pour un hibou ou une chauve-souris).  En conséquence, une résolution de 128x128 a été choisie <s>par la méthode de piquer scientifique</s> , qui donnera des impulsions de 0,37c de long - d'une part, il est assez rapide pour naviguer en temps réel, d'autre part, il suffit d'attraper tout changement de forme du signal à l'oreille. <br><br><h2>  Traitement d'image </h2><br>  La première étape consiste à télécharger l'image, à la convertir en n / b et à la mettre à l'échelle à la taille souhaitée.  La taille de l'image dépend de la dimension de la courbe de Hilbert. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> hilbertcurve.hilbertcurve <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> HilbertCurve <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.signal <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> butter, filtfilt <span class="hljs-comment"><span class="hljs-comment"># Create Hilbert curve dimension = 7 hilbert = HilbertCurve(dimension, n=2) print("Hilbert curve dimension:", dimension) # Maximum distance along curve print("Max_dist:", hilbert.max_h) # Maximum distance along curve print("Max_coord:", hilbert.max_x) # Maximum coordinate value in any dimension # Load PIL image f_name = "image01.png" img = Image.open(f_name) width, height = img.size out_size = hilbert_curve.max_x + 1 if width != out_size: img = img.resize((out_size, out_size), Image.ANTIALIAS) # Get image as grayscale numpy array img_grayscale = img.convert(mode='L') img_data = np.array(img_grayscale)</span></span></code> </pre> <br>  L'étape suivante consiste à former une onde sonore.  Ici, bien sûr, il peut y avoir un grand nombre d'algorithmes et de savoir-faire, pour le test, je viens de prendre le composant de luminosité.  Bien sûr, il existe probablement de meilleures façons. <br><br><pre> <code class="python hljs">width, height = img_grayscale.size sound_data = np.zeros(width*height) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ii <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(width*height): coord_x, coord_y = hilbert_curve.coordinates_from_distance(ii) pixel_l = img_data[coord_x][coord_y] <span class="hljs-comment"><span class="hljs-comment"># Inverse colors (paper-like, white = 0, black = 255) pixel_l = 255 - pixel_l # Adjust values 0..255 to 0..8192 ampl = pixel_l*32 sound_data[ii] = ampl</span></span></code> </pre> <br>  D'après le code, j'espère que tout est clair.  La fonction coordonnées_de_distance fait tout le travail pour nous sur la conversion des coordonnées (x, y) en distance sur une courbe de Hilbert, nous inversons et convertissons la valeur de luminosité L en couleur. <br><br>  Ce n'est pas tout.  Parce que  il peut y avoir de grands blocs de la même couleur dans l'image, cela peut conduire à l'apparition d'une «composante continue» dans le son - une longue série de valeurs non nulles, par exemple [100,100,100, ...].  Pour les supprimer, nous appliquons un filtre passe-haut (filtre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Butterworth</a> ) à notre réseau avec une fréquence de coupure de 50 Hz (la coïncidence avec la fréquence du réseau est aléatoire).  Il y a une synthèse de filtres dans la bibliothèque scipy, que nous utiliserons. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">butter_highpass</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cutoff, fs, order=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> nyq = <span class="hljs-number"><span class="hljs-number">0.5</span></span> * fs normal_cutoff = cutoff / nyq b, a = butter(order, normal_cutoff, btype=<span class="hljs-string"><span class="hljs-string">'high'</span></span>, analog=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> b, a <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">butter_highpass_filter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, cutoff, fs, order=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> b, a = butter_highpass(cutoff, fs, order) y = filtfilt(b, a, data) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y <span class="hljs-comment"><span class="hljs-comment"># Apply high pass filter to remove dc component cutoff_hz = 50 sample_rate = 44100 order = 5 wav_data = butter_highpass_filter(sound_data, cutoff_hz, sample_rate, order)</span></span></code> </pre> <br>  La dernière étape consiste à enregistrer l'image.  Parce que  la durée d'une impulsion est courte, nous la répétons 10 fois, elle sera plus audible au plus près d'une image réelle qui se répète, par exemple à partir d'une webcam. <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Clip data to int16 range sound_output = np.clip(wav_data, -32000, 32000).astype(np.int16) # Save repeat = 10 sound_output_ntimes = np.tile(sound_output, repeat) wav_name = "ouput.wav" scipy.io.wavfile.write(wav_name, sample_rate, sound_output_ntimes)</span></span></code> </pre> <br><h2>  Résultats </h2><br>  L'algorithme ci-dessus est, bien sûr, assez primitif.  Je voulais vérifier trois points - combien vous pouvez distinguer entre différentes formes simples et combien vous pouvez estimer la distance aux formes. <br><br>  <b>Test 1</b> <br><br><img src="https://habrastorage.org/webt/ft/te/9m/ftte9mjfgwj6nib_lj76pfrqmre.png"><br><br>  L'image correspond au signal sonore suivant: <br><img src="https://habrastorage.org/webt/bd/gw/qu/bdgwquzss88fzb1s8hzyydf-das.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cloud.mail.ru/public/nt2R/2kwBvyRup</a> <br><br>  <b>Test 2</b> <br><br><img src="https://habrastorage.org/webt/vr/jt/6u/vrjt6ufndqzfdsywsgrpbnwlqiw.png"><br><br>  L'idée de ce test est de comparer le «son» d'un objet de forme différente.  Signal sonore: <br><img src="https://habrastorage.org/webt/6z/bq/9a/6zbq9axxuoknevsj_iuxc94unre.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cloud.mail.ru/public/2rLu/4fCNRxCG2</a> <br><br>  Vous remarquerez peut-être que le son est vraiment différent et qu'il y a une différence à l'oreille. <br><br>  <b>Test 3</b> <br><br><img src="https://habrastorage.org/webt/cv/cp/3h/cvcp3h7itiq8srj-rs_j6ntb6lk.png"><br><br>  L'idée du test est de tester un objet plus petit.  Signal sonore: <br><img src="https://habrastorage.org/webt/yk/ra/x3/ykrax3udam03yphwwtlouygkgdk.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cloud.mail.ru/public/5GLV/2HoCHvoaY</a> <br><br>  En principe, plus la taille de l'objet est petite, moins il y aura de "rafales" dans le son, donc la dépendance ici est assez directe. <br><br>  <b>Modifier:</b> <br><br>  Comme suggéré dans les commentaires, vous pouvez utiliser la transformée de Fourier pour convertir directement les images en son.  Un test rapide effectué montre les résultats suivants (les images sont les mêmes): <br>  Test 1: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cloud.mail.ru/public/2C5Z/5MEQ8Swjo</a> <br>  Test 2: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cloud.mail.ru/public/2dxp/3sz8mjAib</a> <br>  Test 3: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cloud.mail.ru/public/3NjJ/ZYrfdTYrk</a> <br><br>  Les tests semblent intéressants, au moins pour les petits et les grands carrés (fichiers 1 et 3), la différence d'audition est notable.  Mais la forme des figures (1 et 2) ne diffère pratiquement pas, il y a donc aussi quelque chose à penser.  Mais en général, le son obtenu en FFT, à l'oreille me plaît plus. <br><br><h2>  Conclusion </h2><br>  Ce test, bien sûr, n'est pas une thèse, mais simplement une preuve de concept, faite en quelques heures de temps libre.  Mais même ainsi, cela fonctionne essentiellement, et il est tout à fait possible de ressentir la différence à l'oreille.  Je ne sais pas s’il est possible d’apprendre à naviguer dans l’espace avec de tels sons, probablement, après un certain entraînement.  Bien qu'il existe un vaste champ d'améliorations et d'expériences, par exemple, vous pouvez utiliser le son stéréo, ce qui vous permettra de mieux séparer les objets de différents côtés, vous pouvez expérimenter d'autres méthodes de conversion d'images en son, par exemple, coder la couleur à différentes fréquences, etc. Enfin, c'est prometteur l'utilisation de caméras 3D capables de percevoir la profondeur (hélas, une telle caméra n'est pas disponible).  À propos, à l'aide d'un simple code OpenCV, l'algorithme ci-dessus peut être adapté pour utiliser une caméra Web, ce qui vous permettra d'expérimenter avec des images dynamiques. <br><br>  Eh bien, comme d'habitude, toutes les expériences réussies. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr458962/">https://habr.com/ru/post/fr458962/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr458950/index.html">Analyser Async / Await en JavaScript avec des exemples</a></li>
<li><a href="../fr458952/index.html">Réglage des paramètres PostgreSQL pour optimiser les performances</a></li>
<li><a href="../fr458954/index.html">Quels types de détection sont utiles en vidéosurveillance. Mécanismes et fonctions</a></li>
<li><a href="../fr458956/index.html">Apprentissage automatique vs approche analytique</a></li>
<li><a href="../fr458960/index.html">Quête d'entreprise</a></li>
<li><a href="../fr458964/index.html">TestMace. Démarrage rapide</a></li>
<li><a href="../fr458966/index.html">Les scientifiques et les chefs d'entreprises technologiques considèrent le lancement d'entreprises industrielles dans l'espace comme une réalité</a></li>
<li><a href="../fr458970/index.html">Utilisation de UIViewPropertyAnimator pour créer des animations personnalisées</a></li>
<li><a href="../fr458972/index.html">Nouvelles de la semaine: Yandex et agences de renseignement occidentales, FAS combat les casinos en ligne, le ministère des Transports réglemente BlaBlaCar</a></li>
<li><a href="../fr458974/index.html">Pleine vie sur Svelte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöá üßíüèª üßìüèø Analyse des performances des requ√™tes dans ClickHouse. Rapport Yandex üßëüèº üßëüèø‚Äçü§ù‚Äçüßëüèæ üìÖ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Que faire si votre requ√™te de base de donn√©es ne fonctionne pas assez rapidement? Comment savoir si une requ√™te utilise de mani√®re optimale les ressou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analyse des performances des requ√™tes dans ClickHouse. Rapport Yandex</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/459198/">  Que faire si votre requ√™te de base de donn√©es ne fonctionne pas assez rapidement?  Comment savoir si une requ√™te utilise de mani√®re optimale les ressources informatiques ou peut-elle √™tre acc√©l√©r√©e?  Lors de la derni√®re conf√©rence HighLoad ++ √† Moscou, j'ai parl√© de l'introspection des performances des requ√™tes - et de ce que le SGBD ClickHouse fournit, et des fonctionnalit√©s du syst√®me d'exploitation que tout le monde devrait conna√Ætre. <br><br><img src="https://habrastorage.org/webt/mi/yo/wu/miyowuhgorpfpl9zih8cszids0y.jpeg"><br><br>  Chaque fois que je fais une demande, je m'inqui√®te non seulement du r√©sultat, mais aussi de ce que fait cette demande.  Par exemple, cela fonctionne pendant une seconde.  Est-ce beaucoup ou peu?  Je pense toujours: pourquoi pas une demi-seconde?  Ensuite, j'optimise quelque chose, je l'acc√©l√®re et cela fonctionne pendant 10 ms.  Je suis g√©n√©ralement satisfait.  Mais quand m√™me, dans ce cas, j'essaie de faire une expression faciale m√©contente et je demande: "Pourquoi pas 5 ms?"  Comment puis-je savoir combien de temps est consacr√© au traitement de la demande?  Peut-il √™tre acc√©l√©r√© en principe? <br><br><a name="habracut"></a>  En r√®gle g√©n√©rale, la vitesse de traitement des demandes est une simple arithm√©tique.  Nous avons √©crit le code - probablement de mani√®re optimale - et nous avons un appareil dans le syst√®me.  Les appareils ont des sp√©cifications.  Par exemple, la vitesse de lecture √† partir du cache L1.  Ou le nombre de lectures al√©atoires qu'un SSD peut effectuer.  Nous le savons tous.  Nous devons prendre ces caract√©ristiques, additionner, soustraire, multiplier, diviser et v√©rifier la r√©ponse.  Mais c'est dans le cas id√©al, cela n'arrive presque jamais.  Presque.  En fait, cela se produit parfois dans ClickHouse. <br><br>  Consid√©rez les faits triviaux sur les appareils et les ressources de nos serveurs. <br><br><img src="https://habrastorage.org/webt/6e/gz/us/6egzusxqlzhg81ledkch36wrld4.jpeg" width="700"><br><br>  Processeur, m√©moire, disque, r√©seau.  J'ai sp√©cialement organis√© ces ressources de cette mani√®re, en commen√ßant par la plus simple et la plus pratique pour la r√©vision et l'optimisation, et en terminant par la plus g√™nante et la plus complexe.  Par exemple, j'ex√©cute une requ√™te et constate que mon programme semble reposer sur le CPU.  Qu'est-ce que cela signifie?  Que vais-je trouver, il y a une sorte de boucle interne, une fonction qui est le plus souvent ex√©cut√©e, r√©√©crit le code, recompile et une fois - mon programme s'ex√©cute plus rapidement. <br><br>  Si vous d√©pensez trop de RAM, alors tout est un peu plus compliqu√©.  Vous devez repenser la structure des donn√©es, presser quelques bits.  En tout cas, je red√©marre mon programme, et il d√©pense moins de RAM.  Certes, cela se fait souvent au d√©triment du processeur. <br><br>  Si tout d√©pend des disques, cela est √©galement plus difficile, car je peux changer la structure des donn√©es sur le disque, mais je dois convertir ces donn√©es plus tard.  Si je fais une nouvelle version, les gens devront faire une sorte de migration de donn√©es.  Il s'av√®re que le disque est d√©j√† beaucoup plus compliqu√©, et il vaut mieux y penser √† l'avance. <br><br>  Et le r√©seau ... Je n'aime vraiment pas le r√©seau, car il est souvent tr√®s difficile de savoir ce qui s'y passe, surtout s'il s'agit d'un r√©seau entre continents, entre centres de donn√©es.  Quelque chose ralentit l√†-bas, et ce n'est m√™me pas votre r√©seau, pas votre serveur, et vous ne pouvez rien faire.  La seule chose √† laquelle vous pouvez penser √† l'avance est de savoir comment les donn√©es seront transmises et comment minimiser l'interaction sur le r√©seau. <br><br>  Il arrive que pas une seule ressource du syst√®me ne soit utilis√©e et que le programme n'attende que quelque chose.  En fait, c'est un cas tr√®s courant, car notre syst√®me est distribu√©, et il peut y avoir de nombreux processus et flux diff√©rents, et certains en attendent un autre, et tout cela doit √™tre connect√© d'une mani√®re ou d'une autre pour bien le prendre en compte. <br><br><img src="https://habrastorage.org/webt/vq/mk/sa/vqmksaynboi4frop2kzfcvk9q4w.jpeg" width="700"><br><br>  La chose la plus simple est d'examiner l'utilisation des ressources, √† une certaine valeur num√©rique.  Par exemple, vous d√©marrez un top, et il √©crit: le processeur est √† 100%.  Ou ex√©cutez iostat, et il √©crit: les disques sont √† 100%.  Certes, ce n'est souvent pas suffisant.  Une personne verra que le programme repose sur des disques.  Que peut-on faire?  Vous pouvez simplement noter cela et vous reposer, d√©cider que tout, rien ne peut √™tre optimis√©.  Mais en fait, chacun des appareils en lui-m√™me est assez compliqu√©.  Le processeur dispose d'un tas de dispositifs informatiques pour diff√©rents types d'op√©rations.  Les disques peuvent avoir une matrice RAID.  S'il y a un SSD, il y a √† l'int√©rieur son propre processeur, son propre contr√¥leur, ce qui ne permet pas de savoir quoi.  Et une valeur - 50% ou 100% - ne suffit pas.  La r√®gle de base: si vous voyez que certaines ressources sont utilis√©es √† 100%, n'abandonnez pas.  Souvent, vous pouvez toujours am√©liorer quelque chose.  Mais cela arrive et vice versa.  Disons que vous voyez que le recyclage est √† 50%, mais rien ne peut √™tre fait. <br><br>  Examinons cela de plus pr√®s. <br><br><img src="https://habrastorage.org/webt/pa/wj/uo/pawjuoieudajqc097ysekq30wnc.jpeg" width="700"><br><br>  La ressource la plus simple et la plus pratique est le processeur.  Vous regardez en haut, √ßa dit que le processeur est √† 100%.  Mais il ne faut pas oublier que ce n'est pas un processeur √† 100%.  Le programme sup√©rieur ne sait pas ce que le processeur y fait.  Elle regarde du point de vue du planificateur OS.  Autrement dit, maintenant une sorte de thread de programme s'ex√©cute sur le processeur.  Le processeur fait quelque chose, puis 100% sera affich√© s'il est moyenn√© dans le temps.  Dans le m√™me temps, le processeur fait quelque chose et son efficacit√© n'est pas claire.  Il peut ex√©cuter un nombre diff√©rent d'instructions par cycle.  S'il y a peu d'instructions, le processeur lui-m√™me peut attendre quelque chose, par exemple, le chargement de donn√©es depuis la m√©moire.  Dans le m√™me temps, la m√™me chose sera affich√©e en haut - 100%.  Nous attendons que le processeur suive nos instructions.  Et ce qu'il fait √† l'int√©rieur n'est pas clair. <br><br>  Enfin, il y a juste un rake quand vous pensez que votre programme repose sur le processeur.  C'est vrai, mais pour une raison quelconque, le processeur a une fr√©quence plus basse.  Il peut y avoir plusieurs raisons: surchauffe, limitation de puissance.  Pour une raison quelconque, dans le centre de donn√©es, il y a une limitation de puissance ou l'√©conomie d'√©nergie peut simplement √™tre activ√©e.  Ensuite, le processeur passera constamment d'une fr√©quence plus √©lev√©e √† une fr√©quence plus basse, mais si votre charge est instable, cela ne suffira pas et en moyenne, le code s'ex√©cutera plus lentement.  Voir le turbostat pour la fr√©quence actuelle du processeur.  V√©rifiez la surchauffe dans le dmesg.  Si quelque chose comme √ßa se produisait, il dirait: ¬´Surchauffe.  Fr√©quence en baisse. " <br><br>  Si vous √™tes int√©ress√© par le nombre de cache manquants, combien d'instructions sont ex√©cut√©es par cycle, utilisez perf record.  Enregistrez un √©chantillon du programme.  De plus, il sera possible de le consulter en utilisant perf stat ou perf report. <br><br><img src="https://habrastorage.org/webt/hl/4v/up/hl4vupofzsuha-s7cyxtba-po0c.jpeg" width="600"><br><br>  Et vice versa.  Disons que vous regardez en haut et que le processeur est recycl√© √† moins de 50%.  Supposons que vous ayez 32 c≈ìurs de processeur virtuel dans votre syst√®me et 16 c≈ìurs physiques. Sur les processeurs Intel, c'est parce que l'hyper-threading est double.  Mais cela ne signifie pas que des c≈ìurs suppl√©mentaires sont inutiles.  Tout d√©pend de la charge.  Supposons que vous ayez des op√©rations d'alg√®bre lin√©aire bien optimis√©es ou que vous ayez des hachages pour extraire des bitcoins.  Ensuite, le code sera clair, de nombreuses instructions seront ex√©cut√©es par cycle, il n'y aura pas de rat√© de cache, de mauvaises pr√©dictions de branche aussi.  Et l'hyper-threading n'aide pas.  Cela aide lorsque vous avez un noyau en attente de quelque chose, tandis que l'autre peut ex√©cuter simultan√©ment des instructions √† partir d'un autre thread. <br><br>  ClickHouse a les deux situations.  Par exemple, lorsque nous effectuons une agr√©gation de donn√©es (GROUP BY) ou un filtrage par ensemble (sous-requ√™te IN), nous aurons une table de hachage.  Si la table de hachage ne tient pas dans le cache du processeur, des √©checs de cache se produiront.  Cela peut difficilement √™tre √©vit√©.  Dans ce cas, l'hyper-threading nous aidera. <br><br>  Par d√©faut, ClickHouse utilise uniquement des c≈ìurs de processeur physiques, √† l'exclusion de l'hyper-threading.  Si vous savez que votre demande peut b√©n√©ficier de l'hyper-threading, il suffit de doubler le nombre de threads: SET max threads = 32, et votre demande sera plus rapide. <br><br>  Il arrive que le processeur soit parfaitement utilis√©, mais vous regardez le graphique et voyez, par exemple, 10%.  Et votre horaire, par exemple, est de cinq minutes dans le pire des cas.  M√™me s'il s'agit d'une seconde, il existe toujours une sorte de valeur moyenne.  En fait, vous avez constamment eu des requ√™tes, elles sont ex√©cut√©es rapidement, en 100 ms toutes les secondes, et c'est normal.  Parce que ClickHouse essaie d'ex√©cuter la demande le plus rapidement possible.  Il n'essaie pas du tout d'utiliser et de surchauffer compl√®tement et constamment vos processeurs. <br><br><img src="https://habrastorage.org/webt/39/ka/ei/39kaeie-ngofbbynsnlq4mum_d0.jpeg" width="700"><br><br>  Examinons de plus pr√®s, une option un peu compliqu√©e.  Il existe une requ√™te avec une expression dans la sous-requ√™te.  Dans la sous-requ√™te, nous avons 100 millions de nombres al√©atoires.  Et nous filtrons simplement ce r√©sultat. <br><br>  Nous voyons une telle image.  Au fait, qui dira avec quel outil je peux voir cette magnifique photo?  Absolument vrai - perf.  Je suis tr√®s content que vous le sachiez. <br><br>  J'ai ouvert la perf, pensant que maintenant je comprends tout.  J'ouvre la liste des assembleurs.  L√†, j'ai √©crit combien de fois l'ex√©cution du programme √©tait sur une instruction particuli√®re, c'est-√†-dire combien de fois il y avait un pointeur d'instruction.  Ici, les nombres sont en pourcentage, et il est √©crit que pr√®s de 90% du temps, l'instruction test% edx,% edx a √©t√© ex√©cut√©e, c'est-√†-dire la v√©rification de z√©ro sur quatre octets. <br><br>  La question est: pourquoi un processeur peut-il prendre autant de temps pour comparer simplement quatre octets √† z√©ro?  (r√©ponses du public ...) Il n'y a pas de reste de division.  Il y a des d√©calages de bits, puis il y a une instruction crc32q, mais comme si le pointeur d'instruction ne s'y produisait jamais.  Et la g√©n√©ration de nombres al√©atoires n'est pas dans cette liste.  Il y avait une fonction s√©par√©e, et elle est tr√®s bien optimis√©e, elle ne ralentit pas.  Quelque chose d'autre ralentit ici.  L'ex√©cution du code s'arr√™te √† cette instruction et passe beaucoup de temps.  Boucle inactive?  Non.  Pourquoi devrais-je ins√©rer des boucles vides?  De plus, si j'ins√©rais la boucle Idle, cela serait √©galement visible dans perf.  Il n'y a pas de division par z√©ro, il y a simplement une comparaison avec z√©ro. <br><br>  Le processeur dispose d'un pipeline, il peut ex√©cuter plusieurs instructions en parall√®le.  Et lorsque le pointeur d'instruction est √† un certain endroit, cela ne signifie pas du tout qu'il ex√©cute cette instruction.  Il attend peut-√™tre d'autres instructions. <br><br>  Nous avons une table de hachage pour v√©rifier qu'un certain nombre se produit dans un ensemble.  Pour cela, nous effectuons une recherche en m√©moire.  Lorsque nous effectuons une recherche en m√©moire, nous avons un √©chec de cache, car la table de hachage contient 100 millions de chiffres, il n'est pas garanti de tenir dans n'importe quel cache.  Ainsi, pour ex√©cuter l'instruction de v√©rification du z√©ro, ces donn√©es doivent d√©j√† √™tre charg√©es √† partir de la m√©moire.  Et nous attendons qu'ils soient charg√©s. <br><br><img src="https://habrastorage.org/webt/w9/7b/ed/w97bediv43zlhfvat95k7qdar3k.jpeg" width="700"><br><br>  Maintenant, la ressource suivante, un peu plus complexe - lecteurs.  Les SSD sont √©galement parfois appel√©s disques, bien que ce ne soit pas tout √† fait correct.  Les SSD seront √©galement inclus dans cet exemple. <br><br>  Nous ouvrons, par exemple, iostat, il montre une utilisation de 100%. <br><br>  Lors des conf√©rences, il arrive souvent que le locuteur monte sur sc√®ne et d√©clare avec pathos: ¬´Les bases de donn√©es sont toujours en appui sur le disque.  Par cons√©quent, nous avons cr√©√© une base de donn√©es en m√©moire.  Elle ne ralentira pas. "  Si une personne s'approche de vous et vous le dit, vous pouvez l'envoyer en toute s√©curit√©.  Il y aura des probl√®mes - vous dites, je l'ai r√©solu.  :) <br><br>  Supposons qu'un programme repose sur des disques, l'utilisation est de 100. Mais cela, bien s√ªr, ne signifie pas que nous utilisons les disques de mani√®re optimale. <br><br>  Un exemple typique est lorsque vous avez juste beaucoup d'acc√®s al√©atoire.  M√™me si l'acc√®s est s√©quentiel, vous lisez simplement le fichier s√©quentiellement, mais il peut toujours √™tre plus ou moins optimal. <br><br>  Par exemple, vous avez une matrice RAID, plusieurs p√©riph√©riques - disons, 8 disques.  Et vous venez de lire s√©quentiellement sans lire √† l'avance, avec une taille de tampon de 1 Mo, et la taille de bloc dans votre bande en RAID est √©galement de 1 Mo.  Ensuite, chaque lecture que vous aurez d'un appareil.  Ou, s'il n'est pas align√©, √† partir de deux appareils.  Un demi-m√©gaoctet ira quelque part, un autre demi-m√©gaoctet quelque part, et ainsi de suite - les disques seront utilis√©s tour √† tour: un, puis un autre, puis un troisi√®me. <br><br>  Il doit √™tre lu √† l'avance.  Ou, si vous avez O_DIRECT, augmentez la taille du tampon.  Autrement dit, la r√®gle est la suivante: 8 disques, taille de bloc 1 Mo, d√©finissez la taille du tampon sur au moins 8 Mo.  Mais cela ne fonctionnera de mani√®re optimale que si la lecture est align√©e.  Et s'il n'est pas align√©, il y aura d'abord des pi√®ces suppl√©mentaires, et vous devrez en mettre plus, multiplier par quelques autres. <br><br>  Ou, par exemple, vous avez RAID 10. Avec quelle vitesse pouvez-vous lire √† partir de RAID 10 - par exemple, √† partir de 8 disques?  Quel sera l'avantage?  Quatre fois, parce qu'il y a un miroir, ou huit fois?  En fait, cela d√©pend de la fa√ßon dont le RAID est cr√©√©, avec quelle disposition des morceaux en bandes. <br><br>  Si vous utilisez mdadm sous Linux, vous pouvez sp√©cifier une disposition proche et une disposition √©loign√©e, avec presque mieux pour l'√©criture, loin pour la lecture. <br><br>  Je recommande toujours d'utiliser une mise en page √©loign√©e, car lorsque vous √©crivez dans la base de donn√©es analytique, ce n'est g√©n√©ralement pas si critique dans le temps - m√™me s'il y a beaucoup plus d'√©criture que de lecture.  Cela se fait par un processus d'arri√®re-plan.  Mais lorsque vous lisez, vous devez le terminer le plus rapidement possible.  Il est donc pr√©f√©rable d'optimiser le RAID pour la lecture en d√©finissant une disposition √©loign√©e. <br><br>  Par chance, sous Linux, mdadm vous mettra par d√©faut dans une disposition proche, et vous n'obtiendrez que la moiti√© des performances.  Il y a beaucoup de tels r√¢teaux. <br><br>  Un autre rake terrible est RAID 5 ou RAID 6. Tout y √©volue bien par des lectures et des √©critures s√©quentielles.  En RAID 5, la multiplicit√© est ¬´le nombre de p√©riph√©riques moins un¬ª.  Cela √©volue bien m√™me avec des lectures al√©atoires, mais cela ne fonctionne pas bien avec des lectures al√©atoires.  Faites un enregistrement √† n'importe quel endroit, et vous devez lire les donn√©es de tous les autres disques, les poksorit (XOR - environ Ed.) Et √©crire √† un autre endroit.  Pour cela, une certaine cache de bandes est utilis√©e, un terrible r√¢teau.  Sous Linux, c'est par d√©faut que vous cr√©ez RAID 5 et √ßa va ralentir pour vous.  Et vous penserez que RAID 5 ralentit toujours, car cela est compr√©hensible.  Mais en fait, la raison est la mauvaise configuration. <br><br>  Un autre exemple.  Vous lisez √† partir d'un SSD, et vous vous √™tes achet√© un bon SSD, il indique 300 000 lectures al√©atoires par seconde dans la sp√©cification.  Et pour une raison quelconque, vous ne pouvez pas le faire.  Et vous pensez - oui, ils se trouvent tous dans leurs sp√©cifications, il n'y a rien de tel.  Mais toutes ces lectures doivent se faire en parall√®le, avec le maximum de parall√©lisme.  La seule fa√ßon de proc√©der de mani√®re tout √† fait optimale consiste √† utiliser des E / S asynchrones, qui sont impl√©ment√©es √† l'aide des appels syst√®me io_submit, io_getevents, io_setup, etc. <br><br>  Soit dit en passant, les donn√©es sur le disque, si vous les stockez, vous devez toujours les compresser.  Je vais donner un exemple tir√© de la pratique.  Une personne nous a contact√© dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chat d'assistance</a> ClickHouse et a d√©clar√©: <br><br>  - ClickHouse compresse les donn√©es.  Je vois que cela repose sur le processeur.  J'ai des SSD NVMe tr√®s rapides, ils ont une vitesse de lecture de plusieurs gigaoctets par seconde.  Est-il possible de d√©sactiver en quelque sorte la compression dans ClickHouse? <br>  ¬´Non, pas du tout¬ª, dis-je.  - Vous devez conserver les donn√©es compress√©es. <br>  - Arr√™tons-le, il y aura juste un autre algorithme de compression qui ne fait rien. <br>  - Facile.  Entrez ces lettres dans cette ligne de code. <br>  "En effet, tout est tr√®s simple", a-t-il r√©pondu un jour plus tard.  - Oui. <br>  - Dans quelle mesure les performances ont-elles chang√©? <br>  "√âchec du test", √©crit-il un autre jour plus tard.  - Il y a trop de donn√©es.  Ils ne tiennent plus sur les SSD. <br><br>  Voyons maintenant √† quoi pourrait ressembler la lecture √† partir du disque.  On d√©marre dstat, √ßa montre la vitesse de lecture. <br><br><div class="spoiler">  <b class="spoiler_title">Le premier exemple de dstat et iostat</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/tp/bv/hc/tpbvhccpx_oezqb-bl61xfhcrtq.gif"><br></div></div><br>  Voici la colonne de lecture - 300 Mo / s.  Nous lisons des disques.  C'est beaucoup ou un peu - je ne sais pas. <br><br>  Maintenant, je lance iostat pour v√©rifier cela.  Ici vous pouvez voir la r√©partition par appareil.  J'ai RAID, md2 et huit disques durs.  Chacun d'eux montre du recyclage, il n'atteint m√™me pas 100% (50-60%).  Mais la chose la plus importante est que je ne lis sur chaque disque qu'√† une vitesse de 20-30 Mo / s.  Et depuis l'enfance, je me suis souvenu de la r√®gle selon laquelle vous pouvez lire quelque part √† partir de 100 Mo / s depuis le disque dur.  Pour une raison quelconque, cela n'a pas encore beaucoup chang√©. <br><br><div class="spoiler">  <b class="spoiler_title">Deuxi√®me exemple de dstat et iostat</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/yv/x-/wf/yvx-wf4ufaglo2ehwozvvh1mj48.gif"><br></div></div><br>  Voici un autre exemple.  La lecture est plus optimale.  J'ex√©cute dstat, et j'ai une vitesse de lecture de 1 Go / s √† partir de ce RAID 5 sur huit disques.  Que montre iostat?  Oui, pr√®s de 1 Go / s. <br><br>  Maintenant, les disques sont enfin charg√©s √† 100%.  Certes, pour une raison quelconque, deux sont √† 100% et les autres √† 95%.  Probablement, ils sont encore un peu diff√©rents.  Mais avec chacun d'eux, j'ai lu 150 Mo / s, encore plus cool qu'il ne peut l'√™tre.  Quelle est la diff√©rence?  Dans le premier cas, j'ai lu avec une taille de tampon insuffisante en morceaux insuffisants.  C'est simple, je vous dis des v√©rit√©s communes. <br><br>  Soit dit en passant, si vous pensez que les donn√©es n'ont toujours pas besoin d'√™tre compress√©es pour une base de donn√©es analytiques, c'est-√†-dire un rapport de la conf√©rence HighLoad ++ Siberia ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">habrastaty bas√© sur le rapport</a> - environ Ed.).  Les organisateurs ont d√©cid√© de faire les reportages les plus hardcore √† Novossibirsk. <br><br><img src="https://habrastorage.org/webt/pu/6k/kp/pu6kkpnztqtp_elvxpta__ya8f0.jpeg" width="700"><br><br>  L'exemple suivant est la m√©moire.  Poursuite des v√©rit√©s communes.  Tout d'abord, sous Linux, ne voyez jamais ce que les √©missions gratuites.  Pour ceux qui regardent, ils ont sp√©cialement cr√©√© le site linuxatemyram.com.  Entrez, il y aura une explication.  Vous n'avez pas non plus besoin de regarder la quantit√© de m√©moire virtuelle, car quelle est la diff√©rence, combien d'espace d'adressage le programme a-t-il allou√©?  Regardez combien de m√©moire physique est utilis√©e. <br><br>  Et un r√¢teau de plus avec lequel on ne sait m√™me pas comment se battre.  N'oubliez pas: le fait que les allocateurs n'aiment souvent pas donner de m√©moire au syst√®me est normal.  Ils ont fait mmap, mais munmap ne le fait plus.  La m√©moire ne reviendra pas au syst√®me.  Le programme pense - je sais mieux comment j'utiliserai la m√©moire.  Je m'en remets √† moi.  Parce que les appels syst√®me mmap et munmap sont assez lents.  Changer l'espace d'adressage, r√©initialiser les caches TLB du processeur - il vaut mieux ne pas le faire.  Cependant, le syst√®me d'exploitation a toujours la capacit√© de lib√©rer correctement la m√©moire √† l'aide de l'appel syst√®me madvise.  L'espace d'adressage restera, mais physiquement la m√©moire peut √™tre d√©charg√©e. <br><br>  Et n'activez jamais l'√©change sur des serveurs de production avec des bases de donn√©es.  Vous pensez - il n'y a pas assez de m√©moire, je vais inclure l'√©change.  Apr√®s cela, la demande cessera de fonctionner.  Il craquera un temps infini. <br><br><img src="https://habrastorage.org/webt/mb/0d/2n/mb0d2nmqxl5zq7hu5foyae9ir40.jpeg" width="650"><br><br>  Avec un r√©seau en r√¢teau trop typique.  Si vous cr√©ez une connexion TCP √† chaque fois, il faut un certain temps avant que la taille de fen√™tre correcte soit s√©lectionn√©e, car le protocole TCP ne sait pas √† quelle vitesse il sera n√©cessaire de transmettre des donn√©es.  Il s'y adapte. <br><br>  Ou imaginez - vous transf√©rez un fichier, et vous avez une grande latence sur votre r√©seau et une perte de paquets d√©cente.  Il n‚Äôest alors pas du tout √©vident qu‚Äôil soit judicieux d‚Äôutiliser TCP pour transf√©rer des fichiers.  Je pense que c'est faux, car TCP garantit la coh√©rence.  D'un autre c√¥t√©, vous pouvez transf√©rer une moiti√© du fichier et l'autre en m√™me temps.  Utilisez au moins plusieurs connexions TCP ou n'utilisez pas TCP du tout pour le transfert de donn√©es. ,   ,    ,  TCP    .    . <br><br>       100- ,   .     10   -,     ,   ,       .  .    . <br><br><img src="https://habrastorage.org/webt/xy/ch/_m/xych_mjdelh5uydffukjrxzbf-k.jpeg" width="800"><br><br>    ?      ‚Äî     .    ,     ,  ,  10  .    ,       . <br><br><img src="https://habrastorage.org/webt/mp/p_/bq/mpp_bqykipgfxtbiu6i8_a4xfpm.jpeg" width="400"><br><br>   : ¬´   -  ¬ª ‚Äî          .      iotop,  ,           ,   iops. <br><br>         ,     .  . <br><br><div class="spoiler"> <b class="spoiler_title">: top  </b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/8r/3l/wg/8r3lwg_u4l6bexuezkp-s3kdvno.gif"><br></div></div><br>   top  -,   ,  clickHouse-server  -  , -  .   ,   ,    Shift+H,      .    ,  ClickHouse  .   ParalInputsProc,   .  BackgrProcPool ‚Äî   merges     .   ,            . <br><br>    ?     ClickHouse,  ,     .    BackgroundProcessingPool.     15 . 16  1,  1 ‚Äî   .  16?  ,    Linux ‚Äî   ,  : ¬´16 .  ¬ª.  :) <br><br>        clickhouse-benchmark.        clickhouse-client.    ,    clickhouse-client,  .      -         .             . <br><br><div class="spoiler"> <b class="spoiler_title">: clickhouse-benchmark + perf top</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/bu/ol/_g/buol_gwiuvuqmnn3xxxzpkafc6g.gif"><br></div></div><br>         .  clickhouse-benchmark,  ,      ,   ,     ,           .       peft top.   peft top,       .  ,    -     -,      uniq: UniquesHashSet.  .    ,   .      ,   . <br><br>  , ,    .        ‚Äî   -.    ,  , XOR  -  .   -.        -   -.      ,              -. <br><br>     , , crc32q.         ,        ,     -   ,       -   . <br><br>     ,        ClickHouse.            , ,   .       ClickHouse. <br><br><img src="https://habrastorage.org/webt/je/ki/1x/jeki1xaabpztoth-0ixuuq5abny.jpeg" width="700"><br><br>     .  ,    ‚Äî  ,   SHOW PROCESSLIST.   .    ,  SELECT * FROM system processes.       :  , ,   .     ClickHouse top. <br><br>     ClickHouse ?       background-. Background- ‚Äî    merges.   ,  merges ,    SELECT * FROM system.merges. <br><br><div class="spoiler"> <b class="spoiler_title"> c </b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/pb/gd/b3/pbgdb3f6o8qyvh6ez81heoo82tu.gif"><br></div></div><br> ,   .  -.    .  ‚Äî  ClickHouse.       .      ,  ,  . ,       . - traf_testing.  ?   ,       ,       .   ClickHouse  . <br><br><img src="https://habrastorage.org/webt/ni/aj/ro/niajrokowxcc2bp1n2ookwy8ljy.jpeg" width="700"><br><br>  .    ,      . ,    ,  ,    ,     .   query_log.        ‚Äî      ,   -    ,  SELECT ,    -  .   query_log     ,    .   -     .    ‚Äî    ,    .     :       . <br><br> ,  ,      ‚Äî merge, inserts,   .      part_log.      ,      . <br><br><img src="https://habrastorage.org/webt/lt/vn/cp/ltvncpwym4jc0qpjpofzygrb9qs.jpeg" width="700"><br><br>   query_log   clickhouse-benchmark.   select  ,    ,      stdin  clickhouse-benchmark. <br><br>     query_log  -   ,       . <br><br><img src="https://habrastorage.org/webt/zh/pm/tt/zhpmttv4oacr3fqnvanjwhrdsdg.jpeg" width="450"><br><br>       ,  ,   .     .     SET send_logs_level = 'trace',       ,    . <br><br><div class="spoiler"> <b class="spoiler_title">:  </b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/3z/l0/g9/3zl0g92l6zqdt7gxtqogm-wt-ai.gif"><br></div></div><br> ,   .  ,     98%.   ,       .  C'est tr√®s simple.  SET send_logs_level = 'trace',  ,    .  - : merging aggregated data,   .       1% .       ,    . <br><br>        ,   ,      query_log. <br><br>  . SELECT * FROM system.query_log    .  . ,   ,     ,      query_log. .      ‚Äî  ,    ,   ,       . . <br><br><img src="https://habrastorage.org/webt/6h/em/o3/6hemo3c8u8d4qv2bwxlt-xa0x_w.jpeg" width="470"><br><br>   ClickHouse   .   ‚Äî           system.events, system.metrics  system.asynchronous_metrics. Events ‚Äî    , ,     . 100 .          ‚Äî 10 .  system.metrics ‚Äî     . ,     10 ,     10  . <br><br>  system.asynchronous_metrics     ,     .  .          ‚Äî   .  , system.asynchronous_metrics ‚Äî  ,     - . ,   . <br><br>       ,     .      SHOW PROCESSLIST       .  query_log,        . <br><br><img src="https://habrastorage.org/webt/0p/cp/1r/0pcp1rjgl8aj4w29tcnj73n5eay.jpeg" width="520"><br><br> ,   .  ,    . ,   .   ,    ,       .   ,     Linux,   .    Linux    .     ,     .  ,    .      . <br><br> , OSReadChars  OSReadBytes.   ?  ,       ,        ,     .   ,        .   ,       ,         ,   .  ,   -      ,      . <br><br><div class="spoiler"> <b class="spoiler_title">  page cache</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/ft/zd/z3/ftzdz3ycxppmbghwuxu108y3rcs.gif"><br></div></div><br> ,   .    - .  ,  40    , 6,7 . . ,     ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> . , , . <br><br>      ,    1,3 ,  5  .  Pourquoi? ,     ‚Äî      page cache.         ? <br><br><div class="spoiler"> <b class="spoiler_title"> c  </b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/hr/cj/as/hrcjasfstnujjgo-fx9ene7t1g0.gif"><br></div></div><br>     .       . ,   ,        .   .     :     3,2 ,    ‚Äî 2,5 . , ,         ,   .  Pourquoi? -, :  read ahead.        ,       ‚Äî  ? -,         ‚Äî 4  , , 512 KB.     .    ,     .   ,  - read ahead. <br><br><img src="https://habrastorage.org/webt/dj/nb/kj/djnbkjh9mdniw34_odlupzqigfa.jpeg" width="700"><br><br>      .      .     ,     . , , ReadBytes ‚Äî  ,     .  3 ,     3 .  ,   ,    . <br><br>    ‚Äî IOWait. 87 .    7 ,  IOWait ‚Äî 87. ?  ‚Äî    .     .   ,      ,     87 .       ,  - . <br><br>    ‚Äî CPUWait.     ,  ,       ,       .  -     ‚Äî ,   .      CPU.         CPU.      - ,    .        ‚Äî ,  ,   user space.    ,     - .  Et bien. <br><br>  ‚Äî  ,    Linux.         - ,    .    , ,       . <br><br><div class="spoiler"> <b class="spoiler_title">: query_thread_log</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/fq/py/tf/fqpytfrrdsz4nxr8179r4pklzkm.gif"><br></div></div><br>    ,    : query_thread_log.      ,        . <br><br>     ,   query_id    ¬´  ,   user space¬ª.   .       16 .     800 .    16        ,       0,25 .     ,      . <br><br>    HighLoad++: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/ondHe_JUyW4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr459198/">https://habr.com/ru/post/fr459198/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr459182/index.html">GitLab: avec la sortie de la version 12.1 nous arr√™tons de supporter MySQL</a></li>
<li><a href="../fr459184/index.html">Comp√©tences de l'unit√© de base</a></li>
<li><a href="../fr459188/index.html">Publication de Debian 10 Buster et Linux 5.2</a></li>
<li><a href="../fr459194/index.html">Comment nous avons fait des amis SCSS avec les variables CSS en utilisant le th√®me du kit d'interface utilisateur</a></li>
<li><a href="../fr459196/index.html">Des monolithes aux √©quipes modulaires</a></li>
<li><a href="../fr459204/index.html">10 ++ fa√ßons de travailler avec les registres mat√©riels en C ++ (par exemple, IAR et Cortex M)</a></li>
<li><a href="../fr459206/index.html">9 ans dans un monolithe √† Node.JS</a></li>
<li><a href="../fr459208/index.html">Courir avec des proth√®ses: simulation de Nekstgen du mouvement humain √† l'aide de muscles, d'os et d'un r√©seau neuronal</a></li>
<li><a href="../fr459212/index.html">Impl√©mentation de propri√©t√© en C ++</a></li>
<li><a href="../fr459214/index.html">Tol√©rance aux pannes dans le stockage Qsan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ§’ğŸ¿ ğŸŒ² ğŸ™‹ğŸ¼ Integrasi Spark Streaming dan Kafka ğŸ‘©ğŸ¼â€ğŸ¤â€ğŸ‘¨ğŸ» â˜¦ï¸ ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo rekan! Kami mengingatkan Anda bahwa belum lama ini kami menerbitkan buku tentang Spark , dan saat ini sebuah buku tentang Kafka sedang menjalani ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Integrasi Spark Streaming dan Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/417123/">  Halo rekan!  Kami mengingatkan Anda bahwa belum lama ini kami menerbitkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">buku tentang Spark</a> , dan saat ini sebuah <a href="">buku tentang Kafka</a> sedang menjalani proofreading terbaru. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/it/cf/nj/itcfnjaffoo8apwikyd7_yfym5s.jpeg"></div><br>  Kami berharap buku-buku ini akan cukup berhasil untuk melanjutkan topik - misalnya, untuk terjemahan dan publikasi literatur tentang Spark Streaming.  Kami ingin menawarkan kepada Anda terjemahan tentang pengintegrasian teknologi ini dengan Kafka hari ini. <br><a name="habracut"></a><br>  <b>1. Pembenaran</b> <br><br>  Apache Kafka + Spark Streaming adalah salah satu kombinasi terbaik untuk membuat aplikasi waktu nyata.  Dalam artikel ini, kita akan membahas secara detail perincian integrasi tersebut.  Selain itu, kita akan melihat contoh dengan Spark Streaming-Kafka.  Kemudian kami membahas "pendekatan penerima" dan opsi integrasi langsung Kafka dan Spark Streaming.  Jadi, mari kita mulai mengintegrasikan Kafka dan Spark Streaming. <br><br><img src="https://habrastorage.org/webt/8x/jl/cp/8xjlcpzhwdwi4w2g87iifbquvr0.jpeg"><br><br>  <b>2. Integrasi Kafka dan Spark Streaming</b> <br><br>  Saat mengintegrasikan Apache Kafka dan Spark Streaming, ada dua pendekatan yang memungkinkan untuk mengonfigurasi Spark Streaming untuk menerima data dari Kafka - yaitu.e.  dua pendekatan untuk mengintegrasikan Kafka dan Spark Streaming.  Pertama, Anda dapat menggunakan Penerima dan API Kafka tingkat tinggi.  Pendekatan kedua (yang lebih baru) bekerja tanpa Penerima.  Ada model pemrograman yang berbeda untuk kedua pendekatan, berbeda, misalnya, dalam hal kinerja dan jaminan semantik. <br><br><img src="https://habrastorage.org/webt/91/mn/sk/91mnsklu_81q0nx9aadnjgya4fc.png"><br><br>  Mari kita pertimbangkan pendekatan ini secara lebih rinci. <br><br>  <i><b>a.</b></i>  <i><b>Pendekatan Berbasis Penerima</b></i> <br><br>  Dalam hal ini, penerimaan data disediakan oleh Penerima.  Jadi, menggunakan API konsumsi tingkat tinggi yang disediakan oleh Kafka, kami menerapkan Penerima.  Selanjutnya, data yang diterima disimpan di Spark Artists.  Kemudian, pekerjaan diluncurkan di Kafka - Spark Streaming, di mana data diproses. <br><br>  Namun, ketika menggunakan pendekatan ini, risiko kehilangan data jika terjadi kegagalan (dengan konfigurasi default) tetap ada.  Oleh karena itu, perlu untuk memasukkan log write-ahead di Kafka - Spark Streaming untuk mencegah kehilangan data.  Dengan demikian, semua data yang diterima dari Kafka disimpan secara sinkron dalam log tulis di sistem file terdistribusi.  Itu sebabnya, bahkan setelah kegagalan sistem, semua data dapat dipulihkan. <br><br>  Selanjutnya, kita akan melihat bagaimana menggunakan pendekatan ini dengan penerima dalam aplikasi dengan Kafka - Spark Streaming. <br><br>  <i>saya</i>  <i>Mengikat</i> <br><br>  Sekarang kita akan menghubungkan aplikasi streaming kita dengan artefak berikut untuk aplikasi Scala / Java, kita akan menggunakan definisi proyek untuk SBT / Maven. <br><br><pre><code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  Namun, ketika menggunakan aplikasi kita, kita harus menambahkan pustaka yang disebutkan di atas dan dependensinya, ini akan diperlukan untuk aplikasi Python. <br><br>  <i>ii.</i>  <i>Pemrograman</i> <br><br>  Selanjutnya, buat stream input <code>DStream</code> dengan mengimpor <code>KafkaUtils</code> ke dalam kode aplikasi stream: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val kafkaStream = KafkaUtils.createStream(streamingContext, [ZK quorum], [consumer group id], [per-topic number of Kafka partitions to consume])</code> </pre> <br>  Selain itu, dengan menggunakan opsi createStream, Anda dapat menentukan kelas kunci dan kelas nilai, serta kelas yang sesuai untuk penguraiannya. <br><br>  <i>iii.</i>  <i>Penempatan</i> <br><br>  Seperti halnya aplikasi Spark, perintah spark-submit digunakan untuk meluncurkan.  Namun, detailnya sedikit berbeda dalam aplikasi Scala / Java dan dalam aplikasi Python. <br><br>  Selain itu, dengan <code>â€“packages</code> Anda dapat menambahkan <code>spark-streaming-Kafka-0-8_2.11</code> dan dependensinya secara langsung ke <code>spark-submit</code> , ini berguna untuk aplikasi Python di mana tidak mungkin untuk mengelola proyek menggunakan SBT / Maven. <br><br><pre> <code class="java hljs">./bin/spark-submit --packages org.apache.spark:spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span>:<span class="hljs-number"><span class="hljs-number">2.2</span></span>.0 ...</code> </pre> <br>  Anda juga dapat mengunduh arsip JAR artifact <code>spark-streaming-Kafka-0-8-assembly</code> dari repositori Maven.  Kemudian tambahkan ke <code>spark-submit</code> dengan - <code>jars</code> . <br><br>  <i>b.</i>  <i>Pendekatan langsung (tidak ada penerima)</i> <br><br>  Setelah pendekatan menggunakan penerima, pendekatan yang lebih baru dikembangkan - yang "langsung".  Ini memberikan jaminan end-to-end yang andal.  Dalam hal ini, kami secara berkala bertanya kepada Kafka tentang offset offset untuk setiap topik / bagian, dan tidak mengatur pengiriman data melalui penerima.  Selain itu, ukuran fragmen baca ditentukan, ini diperlukan untuk pemrosesan yang benar dari setiap paket.  Akhirnya, API konsumsi sederhana digunakan untuk membaca rentang dengan data dari Kafka dengan offset yang diberikan, terutama ketika pekerjaan pemrosesan data dimulai.  Seluruh proses seperti membaca file dari sistem file. <br><br>  Catatan: Fitur ini muncul di Spark 1.3 untuk Scala dan Java API, serta di Spark 1.4 untuk Python API. <br><br>  Sekarang mari kita bahas bagaimana menerapkan pendekatan ini dalam aplikasi streaming kami. <br>  API Konsumen dijelaskan secara lebih rinci di tautan berikut: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Konsumen Apache Kafka |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Contoh Konsumen Kafka</a> <br><br>  saya  Mengikat <br><br>  Benar, pendekatan ini hanya didukung di aplikasi Scala / Java.  Dengan artefak berikut, bangun proyek SBT / Maven. <br><br><pre> <code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  <i>ii.</i>  <i>Pemrograman</i> <br><br>  Selanjutnya, impor KafkaUtils dan buat input <code>DStream</code> dalam kode aplikasi streaming: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val directKafkaStream = KafkaUtils.createDirectStream[ [key <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">key</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">] ]( </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">streamingContext</span></span></span><span class="hljs-class">, [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">map</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Kafka</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">parameters</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">set</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">topics</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">to</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">consume</span></span></span><span class="hljs-class">])</span></span></code> </pre> <br>  Dalam parameter Kafka, Anda harus menentukan <code>metadata.broker.list</code> atau <code>bootstrap.servers</code> .  Karenanya, secara default, kami akan menggunakan data mulai dari offset terakhir di setiap bagian Kafka.  Namun, jika Anda ingin pembacaan dimulai dari fragmen terkecil, maka dalam parameter Kafka Anda perlu mengatur opsi konfigurasi <code>auto.offset.reset</code> . <br><br>  Selain itu, bekerja dengan opsi <code>KafkaUtils.createDirectStream</code> , Anda dapat mulai membaca dari offset acak.  Kemudian kita akan melakukan hal berikut, yang akan memungkinkan kita untuk mengakses fragmen Kafka yang dikonsumsi dalam setiap paket. <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      ,        var offsetRanges = Array.empty[OffsetRange] directKafkaStream.transform { rdd =&gt; offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges rdd }.map { ... }.foreachRDD { rdd =&gt; for (o &lt;- offsetRanges) { println(s"${o.topic} ${o.partition} ${o.fromOffset} ${o.untilOffset}") } ... }</span></span></code> </pre> <br>  Jika kami ingin mengatur pemantauan Kafka berdasarkan Zookeeper menggunakan alat khusus, kami dapat memperbarui Zookeeper sendiri dengan bantuan mereka. <br><br>  <i>iii.</i>  <i>Penempatan</i> <br><br>  Proses penyebaran dalam hal ini menyerupai proses penyebaran dalam varian dengan penerima. <br><br>  <b>3. Manfaat dari pendekatan langsung</b> <br><br>  Pendekatan kedua untuk mengintegrasikan Spark Streaming dengan Kafka mengungguli yang pertama karena alasan berikut: <br><br>  <b><i>a.</i></b>  <b><i>Concurrency Sederhana</i></b> <br><br>  Dalam hal ini, Anda tidak perlu membuat banyak aliran input Kafka dan menggabungkannya.  Namun, Kafka - Spark Streaming akan membuat segmen RDD sebanyak mungkin karena akan ada segmen Kafka untuk konsumsi.  Semua data Kafka ini akan dibaca secara paralel.  Oleh karena itu, kita dapat mengatakan bahwa kita akan memiliki korespondensi satu-ke-satu antara segmen Kafka dan RDD, dan model seperti itu lebih mudah dimengerti dan lebih mudah untuk dikonfigurasi. <br><br>  <i><b>b.</b></i>  <i><b>Keefektifan</b></i> <br><br>  Untuk benar-benar menghilangkan kehilangan data selama pendekatan pertama, informasi perlu disimpan dalam log catatan terkemuka, dan kemudian direplikasi.  Sebenarnya, ini tidak efisien karena data direplikasi dua kali: pertama kali oleh Kafka itu sendiri, dan yang kedua oleh log menulis depan.  Dalam pendekatan kedua, masalah ini dihilangkan, karena tidak ada penerima, dan, oleh karena itu, tidak diperlukan jurnal tulis terkemuka.  Jika kami memiliki penyimpanan data yang cukup panjang di Kafka, Anda dapat memulihkan pesan langsung dari Kafka. <br><br>  <b><i>s</i></b>  <b><i>Semantik yang Tepat Sekali</i></b> <br><br>  Pada dasarnya, kami menggunakan API Kafka tingkat tinggi dalam pendekatan pertama untuk menyimpan fragmen baca yang dikonsumsi di Zookeeper.  Namun, ini adalah kebiasaan untuk mengkonsumsi data dari Kafka.  Sementara kehilangan data dapat dihilangkan secara andal, ada kemungkinan kecil bahwa dalam beberapa kegagalan, catatan individual dapat dikonsumsi dua kali.  Intinya adalah inkonsistensi antara mekanisme transfer data yang dapat diandalkan di Kafka - Spark Streaming dan pembacaan fragmen yang terjadi di Zookeeper.  Oleh karena itu, dalam pendekatan kedua, kami menggunakan API Kafka sederhana, yang tidak mengharuskan beralih ke Zookeeper.  Di sini, fragmen baca dilacak dalam Kafka - Spark Streaming, untuk ini, titik kontrol digunakan.  Dalam hal ini, ketidakkonsistenan antara Spark Streaming dan Zookeeper / Kafka dihilangkan. <br><br>  Oleh karena itu, bahkan jika terjadi kegagalan, Spark Streaming menerima setiap catatan secara ketat satu kali.  Di sini kita perlu memastikan bahwa operasi keluaran kami, di mana data disimpan dalam penyimpanan eksternal, adalah idempoten atau transaksi atom di mana hasil dan offset disimpan.  Ini adalah bagaimana semantik-sekali dicapai dalam derivasi hasil kami. <br><br>  Meskipun, ada satu kelemahan: offset di Zookeeper tidak diperbarui.  Karenanya, alat pemantauan Kafka yang berbasis pada Zookeeper tidak memungkinkan Anda melacak kemajuan. <br>  Namun, kita masih bisa merujuk ke offset, jika pemrosesan diatur dengan cara ini - kita beralih ke setiap paket dan memperbarui Zookeeper sendiri. <br><br>  Itulah yang ingin kami bicarakan tentang mengintegrasikan Apache Kafka dan Spark Streaming.  Kami harap Anda menikmatinya. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id417123/">https://habr.com/ru/post/id417123/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id417111/index.html">Konferensi online: streaming vs webinar</a></li>
<li><a href="../id417113/index.html">Printer Italia 3D di Rusia: Raise3D N1 Dual - modelling dan prototyping</a></li>
<li><a href="../id417115/index.html">Untuk mengubur atau membakar Flutter.io?</a></li>
<li><a href="../id417117/index.html">Membalikkan rekayasa emulator NES dalam game untuk GameCube</a></li>
<li><a href="../id417119/index.html">Pagination di Vue.js</a></li>
<li><a href="../id417125/index.html">Rapat RTC .Net: undang ke pertemuan pertama</a></li>
<li><a href="../id417127/index.html">Tesla Menandatangani Perjanjian untuk Membangun Gigafactory 3 di Cina</a></li>
<li><a href="../id417129/index.html">Alam semesta pikiran</a></li>
<li><a href="../id417131/index.html">Bagaimana merasakan transaksi di MongoDB sekarang</a></li>
<li><a href="../id417135/index.html">Unity3D: bagaimana cara mengetahui tingkat iluminasi suatu titik dalam sebuah adegan?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚰 🌖 👨‍💻 معالجة وتوفيق البيانات من مصادر مختلفة 😠 🥇 🤟🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="مرحبا يا هبر! 

 نظرًا لتنوع الأنظمة الموزعة ، يعد توفر المعلومات التي تم التحقق منها في التخزين المستهدف معيارًا مهمًا لتناسق البيانات. 

 هناك العدي...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>معالجة وتوفيق البيانات من مصادر مختلفة</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/480076/" style=";text-align:right;direction:rtl"> مرحبا يا هبر! <br><br>  نظرًا لتنوع الأنظمة الموزعة ، يعد توفر المعلومات التي تم التحقق منها في التخزين المستهدف معيارًا مهمًا لتناسق البيانات. <br><br>  هناك العديد من الطرق والأساليب في هذا الصدد ، وسوف نركز على المصالحة ، والتي تمت مناقشة الجوانب النظرية لها <a href="https://habr.com/ru/post/428443/">في هذا المقال.</a>  أقترح النظر في التنفيذ العملي لهذا النظام ، قابلة للتطوير وتكييفها مع كمية كبيرة من البيانات. <br><br>  كيفية تنفيذ هذه الحالة على بيثون القديم الجيد - قراءتها تحت خفض!  دعنا نذهب! <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/ic/zx/hg/iczxhgu9zvlumwggetuoblxm1ra.jpeg"></div><br>  <a href="https://www.megapixl.com/alexdobysh-stock-images-videos-portfolio" rel="nofollow">(مصدر الصورة)</a> <br><a name="habracut"></a><br><h2 style=";text-align:right;direction:rtl">  مقدمة </h2><br>  دعنا نتخيل أن المؤسسة المالية لديها العديد من الأنظمة الموزعة وأننا نواجه مهمة التحقق من المعاملات في هذه الأنظمة وتحميل البيانات التي تمت تسويتها إلى التخزين المستهدف. <br><br>  كمصدر للبيانات ، خذ ملفًا نصيًا كبيرًا وجدولًا في قاعدة بيانات PostgreSQL.  لنفترض أن البيانات الموجودة في هذه المصادر لها نفس المعاملات ، لكن يمكن أن يكون لها اختلافات ، وبالتالي يجب التحقق منها وكتابتها إلى البيانات التي تم التحقق منها في التخزين النهائي للتحليل. <br><br>  بالإضافة إلى ذلك ، من الضروري توفير التشغيل المتوازي للعديد من التسويات على نفس قاعدة البيانات وتكييف النظام مع وحدة تخزين كبيرة باستخدام المعالجة المتعددة. <br><br>  تعد وحدة <a href="https://docs.python.org/dev/library/multiprocessing.html" rel="nofollow">المعالجة المتعددة</a> كبيرة بالنسبة لموازنة العمليات في بيثون ، ومن ناحية أخرى ، تتجنب بعض عيوب GIL.  سوف نستخدم قدرات هذه المكتبة أدناه. <br><br><h2 style=";text-align:right;direction:rtl">  بنية النظام قيد التطوير </h2><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/je/dm/hu/jedmhumxsx9d-mxu-bbfbzqbulq.png"></div><br>  المكونات المستخدمة: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  <b>منشئ بيانات عشوائي</b> - برنامج نصي Python يقوم بإنشاء ملف CSV ويقوم على أساسه بتعبئة جدول في قاعدة بيانات ؛ </li><li style=";text-align:right;direction:rtl">  <b>مصادر البيانات</b> - ملف CSV والجدول في قاعدة بيانات PostgreSQL ؛ </li><li style=";text-align:right;direction:rtl">  <b>المحولات</b> - في هذه الحالة ، نستخدم محوّلين يقومان باستخراج البيانات من مصادرهما (CSV أو DB) وإدخال المعلومات في قاعدة البيانات الوسيطة ؛ </li><li style=";text-align:right;direction:rtl">  <b>قواعد البيانات</b> - بكمية ثلاثة أجزاء: البيانات الأولية ، وقاعدة بيانات وسيطة تقوم بتخزين المعلومات التي تم التقاطها بواسطة المحولات ، وقاعدة بيانات "نظيفة" تحتوي على معاملات تم التوفيق بينها من كلا المصدرين. </li></ul><br><h2 style=";text-align:right;direction:rtl">  التدريب الأولي </h2><br>  كأداة لتخزين البيانات ، سوف نستخدم <a href="https://hub.docker.com/_/postgres" rel="nofollow">قاعدة بيانات PostgreSQL في حاوية Docker</a> <a href="https://hub.docker.com/r/dpage/pgadmin4/" rel="nofollow">ونتفاعل</a> مع قاعدة البيانات الخاصة بنا من خلال <a href="https://hub.docker.com/r/dpage/pgadmin4/" rel="nofollow">pgAdmin التي تعمل في الحاوية</a> : <br><br><pre style=";text-align:right;direction:rtl"><code class="bash hljs">docker run --name pg -d -e <span class="hljs-string"><span class="hljs-string">"POSTGRES_USER=my_user"</span></span> -e <span class="hljs-string"><span class="hljs-string">"POSTGRES_PASSWORD=my_password"</span></span> postgres</code> </pre> <br>  تشغيل pgAdmin: <br><br><pre style=";text-align:right;direction:rtl"> <code class="bash hljs">docker run -p 80:80 -e <span class="hljs-string"><span class="hljs-string">"PGADMIN_DEFAULT_EMAIL=user@domain.com"</span></span> -e <span class="hljs-string"><span class="hljs-string">"PGADMIN_DEFAULT_PASSWORD=12345"</span></span> -d dpage/pgadmin4</code> </pre> <br>  بعد أن بدأ كل شيء ، لن ننسى أن نضع في ملف التكوين (conf / db.ini) سلسلة الاتصال بقاعدة البيانات (على سبيل المثال ، يمكنك التدريب!): <br><br><pre style=";text-align:right;direction:rtl"> <code class="bash hljs">[POSTGRESQL] db_url=postgresql://my_user:my_password@172.17.0.2:5432/my_user</code> </pre><br>  من حيث المبدأ ، يكون استخدام الحاوية اختياريًا ويمكنك استخدام خادم قاعدة البيانات الخاص بك. <br><br><h2 style=";text-align:right;direction:rtl">  توليد المدخلات </h2><br>  يعد البرنامج النصي Python create_test_data مسؤولاً عن إنشاء بيانات الاختبار ، والتي تأخذ العدد المطلوب من الإدخالات التي تريد إنشاؤها.  يمكن تتبع تسلسل العمليات بسهولة بواسطة الوظيفة الرئيسية لفئة <b>GenerateTestData</b> : <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @m.timing def run(self, num_rows): """ Run the process """ m.info('START!') self.create_db_schema() self.create_folder('data') self.create_csv_file(num_rows) self.bulk_copy_to_db() self.random_delete_rows() self.random_update_rows() m.info('END!')</span></span></code> </pre> <br>  لذلك ، تقوم الدالة بالخطوات التالية: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  إنشاء مخططات في قاعدة البيانات (نقوم بإنشاء جميع المخططات والجداول الأساسية) ؛ </li><li style=";text-align:right;direction:rtl">  إنشاء مجلد لتخزين ملف اختبار ؛ </li><li style=";text-align:right;direction:rtl">  توليد ملف اختبار مع عدد معين من الخطوط ؛ </li><li style=";text-align:right;direction:rtl">  إدراج بيانات مجمعة في الجدول المعاملة transaction_db_raw.transaction_log في الجدول الهدف ؛ </li><li style=";text-align:right;direction:rtl">  الحذف العرضي لصفوف متعددة في هذا الجدول ؛ </li><li style=";text-align:right;direction:rtl">  تحديث عشوائي لعدة صفوف في هذا الجدول. </li></ul><br>  يعد الحذف والتعديل ضروريًا بحيث تحتوي الكائنات المقارنة على بعض التناقض على الأقل.  من المهم أن تكون قادرًا على البحث عن هذه التناقضات! <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing @m.wrapper(m.entering, m.exiting) def random_delete_rows(self): """ Random deleting some rows from the table """ sql_command = sql.SQL(""" delete from {0}.{1} where ctid = any(array( select ctid from {0}.{1} tablesample bernoulli (1) ))""").format(sql.Identifier(self.schema_raw), sql.Identifier(self.raw_table_name)) try: rows = self.database.execute(sql_command) m.info('Has been deleted [%s rows] from table %s' % (rows, self.raw_table_name)) except psycopg2.Error as err: m.error('Oops! Delete random rows has been FAILED. Reason: %s' % err.pgerror) @m.timing @m.wrapper(m.entering, m.exiting) def random_update_rows(self): """ Random update some rows from the table """ sql_command = sql.SQL(""" update {0}.{1} set transaction_amount = round(random()::numeric, 2) where ctid = any(array( select ctid from {0}.{1} tablesample bernoulli (1) ))""").format(sql.Identifier(self.schema_raw), sql.Identifier(self.raw_table_name)) try: rows = self.database.execute(sql_command) m.info('Has been updated [%s rows] from table %s' % (rows, self.raw_table_name)) except psycopg2.Error as err: m.error('Oops! Delete random rows has been FAILED. Reason: %s' % err.pgerror)</span></span></code> </pre> <br>  فيما يلي إنشاء مجموعة بيانات الاختبار والتسجيل اللاحق لملف نصي بتنسيق CSV: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  يتم إنشاء معاملة عشوائية UID ؛ </li><li style=";text-align:right;direction:rtl">  يتم إنشاء رقم حساب UID عشوائي (بشكل افتراضي ، نأخذ عشرة حسابات فريدة ، ولكن يمكن تغيير هذه القيمة باستخدام ملف التكوين عن طريق تغيير المعلمة "random_accounts") ؛ </li><li style=";text-align:right;direction:rtl">  تاريخ المعاملة - تاريخ عشوائي من التاريخ المحدد في ملف التكوين (initial_date) ؛ </li><li style=";text-align:right;direction:rtl">  نوع المعاملة (المعاملة / العمولة) ؛ </li><li style=";text-align:right;direction:rtl">  مبلغ الصفقة </li><li style=";text-align:right;direction:rtl">  يتم تنفيذ العمل الرئيسي في توليد البيانات عن طريق الأسلوب <b>gener_test_data_by_chunk</b> للفئة <b>TestDataCreator</b> : </li></ul><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing def generate_test_data_by_chunk(self, chunk_start, chunk_end): """ Generating and saving to the file """ num_rows_mp = chunk_end - chunk_start new_rows = [] for _ in range(num_rows_mp): transaction_uid = uuid.uuid4() account_uid = choice(self.list_acc) transaction_date = (self.get_random_date(self.date_in, 0) .__next__() .strftime('%Y-%m-%d %H:%M:%S')) type_deal = choice(self.list_type_deal) transaction_amount = randint(-1000, 1000) new_rows.append([transaction_uid, account_uid, transaction_date, type_deal, transaction_amount]) self.write_in_file(new_rows, chunk_start, chunk_end)</span></span></code> </pre> <br><blockquote style=";text-align:right;direction:rtl">  تتمثل ميزة هذه الوظيفة في الإطلاق في العديد من العمليات غير المتزامنة المتوازية ، حيث تقوم كل منها بإنشاء الجزء الخاص بها من سجلات 50K.  تتيح لك هذه "الشريحة" إنشاء ملف على عدة ملايين من الخطوط بسرعة كافية </blockquote><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run_csv_writing</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Writing the test data into csv file """</span></span> pool = mp.Pool(mp.cpu_count()) jobs = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chunk_start, chunk_end <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.divide_into_chunks(<span class="hljs-number"><span class="hljs-number">0</span></span>, self.num_rows): jobs.append(pool.apply_async(self.generate_test_data_by_chunk, (chunk_start, chunk_end))) <span class="hljs-comment"><span class="hljs-comment"># wait for all jobs to finish for job in jobs: job.get() # clean up pool.close() pool.join()</span></span></code> </pre> <br>  بعد اكتمال الملف النصي ، تتم معالجة الأمر bulk_insert وتندرج جميع البيانات من هذا الملف في جدول <b>transaction_db_raw.transaction_log.</b> <br><br>  علاوة على ذلك ، سيحتوي المصدران على نفس البيانات تمامًا ولن تجد التسوية أي شيء مثير للاهتمام ، لذلك نقوم بحذف وتغيير عدة صفوف عشوائية في قاعدة البيانات. <br><br>  قم بتشغيل البرنامج النصي وإنشاء ملف CSV اختبار مع المعاملات على خطوط 10K: <br><br><pre style=";text-align:right;direction:rtl"> <code class="bash hljs">./generate_test_data.py 10000</code> </pre> <br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/4c/cp/hm/4ccphmc5dcjcgxuy54p_9limlz4.png"></div><br>  توضح لقطة الشاشة أنه تم استلام ملف من 10K خطوط ، وتم تحميل 10K في قاعدة البيانات ، ولكن بعد ذلك تم حذف 112 سطرًا من قاعدة البيانات وتغيير 108. النتيجة: يختلف الملف والجدول في قاعدة البيانات بمقدار 220 إدخالًا. <br><br>  "حسنًا ، أين المعالجة المتعددة؟" ، أنت تسأل. <br>  ويمكن رؤية عملها عند إنشاء ملف أكبر ، وليس بسجلات 10K ، ولكن على سبيل المثال ، بواسطة 1M.  هل سنحاول؟ <br><br><pre style=";text-align:right;direction:rtl"> <code class="bash hljs">./generate_test_data.py 1000000</code> </pre> <br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/rw/_a/ne/rw_aneqnairixqk-wglpqxgjvkc.png"></div><br>  بعد تحميل البيانات وحذفها وتغيير السجلات العشوائية ، نرى الاختلافات بين الملف النصي والجدول: 193939 صفًا (تم حذف 1022 منها عشوائيًا ، وتم تغيير 91717). <br><br><blockquote style=";text-align:right;direction:rtl">  توضح الصورة أن توليد السجلات كان غير متزامن وغير متناسق.  هذا يعني أن العملية التالية يمكن أن تبدأ دون مراعاة أمر البدء بمجرد اكتمال العملية السابقة.  ليس هناك ما يضمن أن النتيجة ستكون بنفس ترتيب الإدخال. </blockquote><br><div class="spoiler" style=";text-align:right;direction:rtl">  <b class="spoiler_title">هل هو بالتأكيد أسرع؟</b> <div class="spoiler_text" style=";text-align:right;direction:rtl">  تم اختراع مليون خط غير موجود على أسرع جهاز افتراضي في 15.5 ثانية - وهذا خيار يستحق.  بعد أن بدأت في إنشاء نفس التتابع ، دون استخدام المعالجة المتعددة ، حصلت على النتيجة: كان إنشاء الملف أبطأ من ثلاث مرات (أكثر من 52 ثانية بدلاً من 15.5): <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/sb/kb/ck/sbkbckylzluoyyslyflwak5udrq.png"></div><br></div></div><br><h2 style=";text-align:right;direction:rtl">  محول ل CSV </h2><br>  يقوم هذا المحول بتجزئة الصف ، تاركًا فقط العمود الأول ، معرف المعاملة ، بدون تغيير ويحفظ البيانات المستلمة في ملف <i>data / transaction_hashed.csv</i> .  الخطوة الأخيرة من عمله هي تحميل هذا الملف باستخدام أمر COPY في الجدول المؤقت لمخطط الصلاحيات <b>.</b> <br><br>  يتم تنفيذ القراءة الأمثل للملف من خلال عدة عمليات متوازية.  نقرأ سطرا سطرا ، في قطعة 5 ميغابايت لكل منهما.  تم الحصول على الرقم "5 ميغابايت" بواسطة الطريقة التجريبية.  بهذا الحجم من نص واحد تمكنا من الحصول على أصغر وقت لقراءة الملفات الكبيرة على الجهاز الظاهري لدينا.  يمكنك تجربة بيئتك باستخدام هذه المعلمة ومعرفة كيفية تغيير وقت التشغيل: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing def process_wrapper(self, chunk_start, chunk_size): """ Read a particular chunk """ with open(self.file_name_raw, newline='\n') as file: file.seek(chunk_start) lines = file.read(chunk_size).splitlines() for line in lines: self.process(line) def chunkify(self, size=1024*1024*5): """ Return a new chunk """ with open(self.file_name_raw, 'rb') as file: chunk_end = file.tell() while True: chunk_start = chunk_end file.seek(size, 1) file.readline() chunk_end = file.tell() if chunk_end &gt; self.file_end: chunk_end = self.file_end yield chunk_start, chunk_end - chunk_start break else: yield chunk_start, chunk_end - chunk_start @m.timing def run_reading(self): """ The main method for the reading """ # init objects pool = mp.Pool(mp.cpu_count()) jobs = [] m.info('Run csv reading...') # create jobs for chunk_start, chunk_size in self.chunkify(): jobs.append(pool.apply_async(self.process_wrapper, (chunk_start, chunk_size))) # wait for all jobs to finish for job in jobs: job.get() # clean up pool.close() pool.join() m.info('CSV file reading has been completed')</span></span></code> </pre> <br>  مثال على قراءة ملف تم إنشاؤه مسبقًا في سجلات 1M: <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/9p/z1/zr/9pz1zrkzeelnep_r8oppk0sxhok.png"></div><br>  توضح لقطة الشاشة إنشاء جدول مؤقت باسم فريد لتشغيل التسوية الحالية.  التالي هو القراءة غير المتزامنة للملف في أجزاء وأخذ تجزئة كل سطر.  إدراج البيانات من المحول في الجدول الهدف يكمل العمل مع هذا المحول. <br><blockquote style=";text-align:right;direction:rtl">  يتيح لك استخدام جدول مؤقت باسم فريد لكل عملية تسوية إمكانية موازنة عملية التسوية بشكل إضافي في قاعدة بيانات واحدة. </blockquote><br><h2 style=";text-align:right;direction:rtl">  محول ل PostgreSQL </h2><br>  يعمل المهايئ الخاص بمعالجة البيانات المخزنة في الجدول على نفس منطق المحول للملف تقريبًا: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  القراءة في أجزاء الجدول (إذا كانت كبيرة ، تتجاوز مائة ألف إدخال) وأخذ علامة تجزئة لجميع الأعمدة باستثناء معرف المعاملة ؛ </li><li style=";text-align:right;direction:rtl">  ثم هناك إدراج البيانات التي تمت معالجتها في <b>الجدولصالحة_</b> db <b>.</b>  <b>التخزين _ $ (int (time.time ())</b> . </li></ul><br>  تتمثل إحدى الميزات المهمة لهذا المحول في أنه يستخدم مجموعة من الاتصالات بقاعدة البيانات ، والتي ستقوم بالبحث حسب الفهرس عن البيانات الضرورية في الجدول ومعالجتها. <br><br>  بناءً على حجم الجدول ، يتم حساب عدد العمليات اللازمة للمعالجة ويوجد في كل عملية قسم إلى 10 مهام. <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">read_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Read the data from the postgres and shared those records with each processor to perform their operation using threads """</span></span> threads_array = self.get_threads(<span class="hljs-number"><span class="hljs-number">0</span></span>, self.max_id_num_row, self.pid_max) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, len(threads_array) + <span class="hljs-number"><span class="hljs-number">1</span></span>): m.info(<span class="hljs-string"><span class="hljs-string">'Process %s'</span></span> % pid) <span class="hljs-comment"><span class="hljs-comment"># Getting connection from the connection pool select_conn = self._select_conn_pool.getconn() select_conn.autocommit = 1 # Creating 10 process to perform the operation process = Process(target=self.process_data, args=(self.data_queque, pid, threads_array[pid-1][0], threads_array[pid-1][1], select_conn)) process.daemon = True process.start() process.join() select_conn.close()</span></span></code> </pre> <br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/pw/kt/kk/pwktkkisxg3sud4dyss_gtyi4gy.png"></div><br><h2 style=";text-align:right;direction:rtl">  البحث عن التناقضات </h2><br>  ننتقل إلى التحقق من البيانات الواردة من محولين. <br><br>  تحدث المصالحة (أو تلقي تقرير تعارض) على جانب الخادم من قاعدة البيانات ، وذلك باستخدام كل قوة لغة SQL. <br><br>  استعلام SQL غير معقد تمامًا - إنه مجرد ربط جدول مع البيانات من المحولات إلى نفسه بواسطة معرف المعاملة: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">sql_command = sql.SQL(<span class="hljs-string"><span class="hljs-string">""" select s1.adapter_name, count(s1.transaction_uid) as tran_count from {0}.{1} s1 full join {0}.{1} s2 on s2.transaction_uid = s1.transaction_uid and s2.adapter_name != s1.adapter_name and s2.hash = s1.hash where s2.transaction_uid is null group by s1.adapter_name;"""</span></span>).format(sql.Identifier(self.schema_target), sql.Identifier(self.storage_table))</code> </pre><br>  الإخراج هو تقرير: <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/5c/ou/gy/5cougys1gkflsplq2hvkoleooto.png"></div><br>  تحقق ما إذا كان كل شيء صحيح في الصورة أعلاه.  نتذكر أنه تم حذف 9917 من الجدول في قاعدة البيانات وتغيير 1022 الصفوف.  مجموع 19939 خطوط ، وهو ما يتضح في التقرير. <br><br><h2 style=";text-align:right;direction:rtl">  جدول ملخص </h2><br>  يبقى فقط إدراج المعاملات "النظيفة" في جدول التخزين الذي يتطابق من جميع النواحي (بواسطة التجزئة) في محولات مختلفة.  يتم تنفيذ هذه العملية بواسطة استعلام SQL التالي: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">sql_command = sql.SQL(<span class="hljs-string"><span class="hljs-string">""" with reconcil_data as ( select s1.transaction_uid from {0}.{1} s1 join {0}.{1} s2 on s2.transaction_uid = s1.transaction_uid and s2.adapter_name != s1.adapter_name where s2.hash = s1.hash and s1.adapter_name = 'postresql_adapter' ) insert into {2}.transaction_log select t.transaction_uid, t.account_uid, t.transaction_date, t.type_deal, t.transaction_amount from {3}.transaction_log t join reconcil_data r on t.transaction_uid = r.transaction_uid where not exists ( select 1 from {2}.transaction_log tl where tl.transaction_uid = t.transaction_uid ) """</span></span>).format(sql.Identifier(self.schema_target), sql.Identifier(self.storage_table), sql.Identifier(self.schema_db_clean), sql.Identifier(self.schema_raw))</code> </pre><br>  يمكن حذف الجدول المؤقت الذي استخدمناه كتخزين وسيط للبيانات من المحولات. <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/uq/sr/te/uqsrte2g0thu2woasaxqojdbc88.png"></div><br><h2 style=";text-align:right;direction:rtl">  استنتاج </h2><br>  في سياق العمل المنجز ، تم تطوير نظام للتوفيق بين البيانات من مصادر مختلفة: ملف نصي وجدول في قاعدة البيانات.  استخدام الحد الأدنى من الأدوات الإضافية. <br><br>  ربما يلاحظ القارئ المتطور أن استخدام الأطر مثل Apache Spark ، إلى جانب تحويل البيانات الخام إلى تنسيق النيابة العامة ، يمكن أن يسرع بشكل كبير هذه العملية ، وخاصة بالنسبة للكميات الكبيرة.  لكن الهدف الرئيسي من هذا العمل هو كتابة نظام في بيثون العارية ودراسة معالجة البيانات المتعددة المعالجة.  مع ما ، في رأيي ، تعاملنا معه. <br><br>  تكمن شفرة المصدر للمشروع بأكمله <a href="https://github.com/igorgorbenko/transact_reconciliation" rel="nofollow">في مستودع بياناتي على GitHub</a> ، أقترح عليك أن تتعرف عليه. <br><br>  سأكون سعيدًا بالإجابة على جميع الأسئلة والتعرف على تعليقاتك. <br><br>  اتمنى لك التوفيق </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar480076/">https://habr.com/ru/post/ar480076/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar480062/index.html">10 أنظمة تحكم. أين هو أكثر ملاءمة للتواصل في المهام ومشاركة الملفات؟</a></li>
<li><a href="../ar480064/index.html">تعلم الكلمات مجمعة حسب الموضوع</a></li>
<li><a href="../ar480068/index.html">[تحديث] تعرض شعبنا للضرب ، وسوف نكون صامتين؟</a></li>
<li><a href="../ar480070/index.html">رد فعل الفوائد: نعمة للشركات؟</a></li>
<li><a href="../ar480072/index.html">Kubernetes: ما أهمية إعداد إدارة موارد النظام؟</a></li>
<li><a href="../ar480078/index.html">مكتبات الواجهة الأمامية الجديدة في React الطرفية</a></li>
<li><a href="../ar480080/index.html">ماذا تحتاج في تدوين الملاحظات؟</a></li>
<li><a href="../ar480082/index.html">استخدام التقسيم في MySQL for Zabbix مع عدد كبير من كائنات المراقبة</a></li>
<li><a href="../ar480086/index.html">كيفية الامتثال لمتطلبات 152-FZ ، وحماية البيانات الشخصية لعملائنا وليس خطوة على أشعل النار لدينا</a></li>
<li><a href="../ar480088/index.html">DevOps - حسناً ، لكن ماذا أفعل؟ كيفية الحد من العمل اليدوي وتحقيق النتيجة المرجوة</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
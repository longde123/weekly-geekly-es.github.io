<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§¥üèΩ üåø üî∫ Jornalismo adulto: da R√∫ssia ao Kremlin üë®üèΩ‚Äçüé® ‚ôãÔ∏è üöå</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="An√°lise de publica√ß√µes Lenta.ru ao longo de 18 anos (de setembro de 1999 a dezembro de 2017) usando python, sklearn, scipy, XGBoost, pymorphy2, nltk, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Jornalismo adulto: da R√∫ssia ao Kremlin</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429270/"><p>  <i>An√°lise de publica√ß√µes Lenta.ru ao longo de 18 anos (de setembro de 1999 a dezembro de 2017) usando python, sklearn, scipy, XGBoost, pymorphy2, nltk, gensim, MongoDB, Keras e TensorFlow.</i> </p><br><p><img src="https://habrastorage.org/webt/lb/v5/f5/lbv5f5apvshbatlpergzpimrl3k.png"></p><br><p> O estudo utilizou dados do post " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Analyze this - Lenta.ru</a> " de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">ildarchegg</a> .  O autor gentilmente forneceu 3 gigabytes de artigos em um formato conveniente, e eu decidi que essa era uma √≥tima oportunidade para testar alguns m√©todos de processamento de texto.  Ao mesmo tempo, se tiver sorte, aprenda algo novo sobre jornalismo russo, sociedade e em geral. </p><a name="habracut"></a><br><h4 id="soderzhanie">  Conte√∫do: </h4><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MongoDB para importar json em python</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Limpando e normalizando o texto</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Nuvem de tags</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Modelagem Tem√°tica LDA</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Previs√£o de popularidade: XGBClassifier, LogisticRegression, Embedding &amp; LSTM</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Explorando objetos usando o Word2Vec</a> </li></ul><br><h4 id="MongoDB">  MongoDB para importar json em python </h4><br><p>  Infelizmente, json com textos acabou sendo um pouco quebrado, n√£o √© cr√≠tico para mim, mas o python se recusou a trabalhar com o arquivo.  Portanto, primeiro importei-o para o MongoDB e, somente ent√£o, atrav√©s do MongoClient da biblioteca pymongo, carreguei a matriz e a re-armazenei em csv em peda√ßos. </p><br><p>  Dos coment√°rios: 1. Eu tive que iniciar o banco de dados com o comando sudo service mongod start - h√° outras op√ß√µes, mas elas n√£o funcionaram;  2. mongoimport - um aplicativo separado, n√£o √© iniciado pelo console mongo, apenas pelo terminal. </p><br><p>  As lacunas de dados s√£o distribu√≠das igualmente ao longo dos anos.  N√£o pretendo usar o per√≠odo inferior a um ano, espero que isso n√£o afete a exatid√£o das conclus√µes. </p><br><p><img src="https://habrastorage.org/webt/w2/yh/w-/w2yhw-uvllvzihu6n7p4jqppudo.png"></p><br><h4 id="">  Limpando e normalizando o texto </h4><br><p>  Antes de analisar diretamente a matriz, √© necess√°rio traz√™-la para o formato padr√£o: remova caracteres especiais, converta o texto em letras min√∫sculas (os m√©todos de string do pandas fizeram um √≥timo trabalho), remova palavras de parada (stopwords.words ('russian') do nltk.corpus), retorne as palavras √† sua forma normal usando lematiza√ß√£o (pymorphy2.MorphAnalyzer). </p><br><p>  Houve algumas falhas, por exemplo, Dmitry Peskov se transformou em "Dmitry" e "areia", mas no geral fiquei satisfeito com o resultado. </p><br><h4 id="">  Nuvem de tags </h4><br><p>  Como semente, vamos ver o que as publica√ß√µes est√£o na forma mais geral.  Exibiremos as 50 palavras mais frequentes usadas pelos jornalistas da Lenta de 1999 a 2017 na forma de uma nuvem de tags. </p><br><p><img src="https://habrastorage.org/webt/yx/zq/77/yxzq77iexwyali-vhggbrd2c8xc.png"></p><br><p>  Ria Novosti (a fonte mais popular), bilh√µes de d√≥lares e milh√µes de d√≥lares (t√≥picos financeiros), presente (circula√ß√£o de fala comum a todos os sites de not√≠cias), √≥rg√£o policial e processo criminal (not√≠cias criminais) ), "Primeiro Ministro" e "Vladimir Putin" (pol√≠tica) - o estilo e os temas esperados para o portal de not√≠cias. </p><br><h4 id="">  Modelagem Tem√°tica LDA </h4><br><p>  Calculamos os t√≥picos mais populares para cada ano usando o LDA da gensim.  O LDA (modelagem tem√°tica usando o m√©todo de posicionamento latente Dirichlet) revela automaticamente t√≥picos ocultos (um conjunto de palavras que ocorrem juntas e com mais frequ√™ncia) pelas frequ√™ncias de palavras observadas nos artigos. </p><br><p>  A pedra angular do jornalismo dom√©stico era a R√∫ssia, Putin, Estados Unidos. </p><br><p>  Em alguns anos, esse t√≥pico foi dilu√≠do com a guerra da Chech√™nia (1999 a 2000), 11 de setembro - em 2001, e Iraque (2002 - 2004).  De 2008 a 2009, a economia ficou em primeiro lugar: juros, empresa, d√≥lar, rublo, bilh√µes, milh√µes.  Em 2011, eles costumavam escrever sobre Gaddafi. </p><br><p>  De 2014 a 2017  os anos da Ucr√¢nia come√ßaram e continuam na R√∫ssia.  O pico ocorreu em 2015, ent√£o a tend√™ncia come√ßou a declinar, mas ainda continua a permanecer em um n√≠vel alto. </p><br><p><img src="https://habrastorage.org/webt/x5/ou/nb/x5ounbamg03xt43t74xjpv2veuo.png"></p><br><p>  √â interessante, √© claro, mas n√£o h√° nada que eu n√£o saiba ou adivinhe. </p><br><p>  Vamos mudar um pouco a abordagem - selecione os principais t√≥picos o tempo todo e veja como a propor√ß√£o deles mudou de ano para ano, ou seja, estudaremos a evolu√ß√£o dos t√≥picos. </p><br><p>  A op√ß√£o mais interpretada foi a Top 5: </p><br><ol><li>  Crime (masculino, policial, ocorrer, deter, policial); </li><li>  Pol√≠tica (R√∫ssia, Ucr√¢nia, Presidente, EUA, Chefe); </li><li>  Cultura (spinner, purulento, instagram, divaga√ß√µes - sim, essa √© a nossa cultura, embora especificamente esse t√≥pico tenha se mostrado bastante misto); </li><li>  Esporte (partida, equipe, jogo, clube, atleta, campeonato); </li><li>  Ci√™ncia (cientista, espa√ßo, sat√©lite, planeta, c√©lula). </li></ol><br><p>  A seguir, analisamos cada artigo e veremos como ele se relaciona com um t√≥pico espec√≠fico. Como resultado, todos os materiais ser√£o divididos em cinco grupos. </p><br><p>  A pol√≠tica acabou sendo a mais popular - menos de 80% de todas as publica√ß√µes.  No entanto, o pico de popularidade dos materiais pol√≠ticos foi ultrapassado em 2014, agora sua participa√ß√£o est√° diminuindo e a contribui√ß√£o para a agenda de informa√ß√µes do Crime e Esportes est√° crescendo. </p><br><p><img src="https://habrastorage.org/webt/-6/ok/fz/-6okfzsonsezo8atfj0ip45s3qi.png"></p><br><p>  Verificaremos a adequa√ß√£o dos modelos tem√°ticos utilizando as subposi√ß√µes indicadas pelos editores.  As principais subcategorias foram identificadas mais ou menos corretamente desde 2013. </p><br><p><img src="https://habrastorage.org/webt/fo/k5/rb/fok5rbn-mvzpxgo9w28sytl5hai.png"></p><br><p>  Nenhuma contradi√ß√£o espec√≠fica foi notada: a pol√≠tica estagnou em 2017, o futebol e os incidentes est√£o crescendo, a Ucr√¢nia ainda est√° em tend√™ncia, com um pico em 2015. </p><br><h4 id="">  Previs√£o de popularidade: XGBClassifier, LogisticRegression, Embedding &amp; LSTM </h4><br><p>  Vamos tentar entender se √© poss√≠vel prever a popularidade de um artigo na fita a partir do texto e do que essa popularidade geralmente depende.  Como vari√°vel alvo, usei o n√∫mero de republica√ß√µes do Facebook para 2017. </p><br><p>  3 mil artigos para 2017 n√£o tiveram republica√ß√µes no Fb - receberam a classe ‚Äúimpopular‚Äù, 3 mil materiais com o maior n√∫mero de republica√ß√µes receberam o r√≥tulo ‚Äúmais popular‚Äù. </p><br><p>  O texto (6 mil publica√ß√µes para 2017) foi dividido em unogramas e bigrams (palavras simb√≥licas, frases simples e de duas palavras) e foi constru√≠da uma matriz onde as colunas s√£o s√≠mbolos, linhas s√£o artigos e, na interse√ß√£o, √© relativo frequ√™ncia de ocorr√™ncia de palavras nos artigos.  Fun√ß√µes usadas do sklearn - CountVectorizer e TfidfTransformer. </p><br><p>  Os dados preparados foram inseridos no XGBClassifier (um classificador baseado no aumento de gradiente da biblioteca xgboost), que ap√≥s 13 minutos de enumera√ß√£o de hiperpar√¢metros (GridSearchCV com cv = 3) deu uma precis√£o de 76% no teste. </p><br><p><img src="https://habrastorage.org/webt/3c/tb/cm/3ctbcmj-qlhaneknvvaegc8050g.png"></p><br><p>  Depois, usei a regress√£o log√≠stica usual (sklearn.linear_model.LogisticRegression) e, ap√≥s 17 segundos, obtive uma precis√£o de 81%. </p><br><p>  Mais uma vez, estou convencido de que os m√©todos lineares s√£o mais adequados para a classifica√ß√£o de textos, desde que os dados sejam cuidadosamente preparados. </p><br><p>  Como homenagem √† moda, testei um pouco as redes neurais.  Ele traduziu as palavras em n√∫meros usando one_hot da keras, trouxe todos os artigos para o mesmo comprimento (fun√ß√£o pad_sequences da keras) e aplicou o LSTM (rede neural convolucional, usando o back-end do TensorFlow) atrav√©s da camada Embedding (para reduzir a dimens√£o e acelerar o tempo de processamento). </p><br><p>  A rede funcionou em 2 minutos e mostrou precis√£o no teste de 70%.  N√£o √© o limite, mas, neste caso, n√£o faz sentido incomodar muito. </p><br><p>  Em geral, todos os m√©todos produziram precis√£o relativamente baixa.  Como mostra a experi√™ncia, os algoritmos de classifica√ß√£o funcionam bem com uma variedade de estilos - em materiais protegidos por direitos autorais, em outras palavras.  Existem tais materiais no Lenta.ru, mas h√° muito poucos deles - menos de 2%. </p><br><p><img src="https://habrastorage.org/webt/od/d_/mh/odd_mhkigi6sw5oub6s4ltsk3rc.png"></p><br><p>  A matriz principal √© escrita usando vocabul√°rio neutro de not√≠cias.  E a popularidade das not√≠cias √© determinada n√£o pelo pr√≥prio texto e nem pelo t√≥pico em si, mas por pertencerem a uma tend√™ncia de informa√ß√£o ascendente. </p><br><p>  Por exemplo, alguns artigos populares cobrem eventos na Ucr√¢nia, os menos populares quase n√£o se referem a esse t√≥pico. </p><br><p><img src="https://habrastorage.org/webt/pq/um/fq/pqumfqsa0w8bvl-ewjyoqzg5c2a.png"></p><br><h4 id="Word2Vec">  Explorando objetos usando o Word2Vec </h4><br><p>  Concluindo, eu queria realizar uma an√°lise sentimental - para entender como os jornalistas se relacionam com os objetos mais populares mencionados em seus artigos, se suas atitudes mudam com o tempo. </p><br><p>  Mas n√£o tenho os dados marcados e √© improv√°vel que uma pesquisa no tesauro sem√¢ntico funcione corretamente, pois o vocabul√°rio das not√≠cias √© bastante neutro, mesquinho com emo√ß√µes.  Portanto, decidi focar no contexto em que os objetos s√£o mencionados. </p><br><p>  Tomei a Ucr√¢nia (2015 vs 2017) e Putin (2000 vs 2017) como teste.  Selecionei os artigos em que s√£o mencionados, traduzi o texto em um espa√ßo vetorial multidimensional (Word2Vec de gensim.models) e projetei em duas dimens√µes o m√©todo Main Components. </p><br><p>  Depois de renderizarem as fotos, elas se tornaram √©picas, n√£o menos que uma tape√ßaria em tamanho de Bayeux.  Recortei os clusters necess√°rios para simplificar a percep√ß√£o, como pude, desculpe pelos "chacais". </p><br><p><img src="https://habrastorage.org/webt/5l/qv/si/5lqvsi1-fxwsfw7slm9vz_uioqs.png"><br><img src="https://habrastorage.org/webt/ue/lx/hs/uelxhs5y09xjqederrghlvsq-3c.png"></p><br><p>  O que eu notei. </p><br><p>  Putin do modelo de 2000 sempre apareceu no contexto da R√∫ssia e abordou pessoalmente.  Em 2017, o presidente da Federa√ß√£o Russa se transformou em um l√≠der (o que quer que isso signifique) e se distanciou do pa√≠s, agora, a julgar pelo contexto, ele √© um representante do Kremlin que se comunica com o mundo atrav√©s de seu secret√°rio de imprensa. </p><br><p>  Ucr√¢nia-2015 na m√≠dia russa - guerra, batalhas, explos√µes;  √© mencionado despersonalizado (Kiev declarou, Kiev come√ßou).  A Ucr√¢nia-2017 aparece principalmente no contexto de negocia√ß√µes entre funcion√°rios, e essas pessoas t√™m nomes espec√≠ficos. </p><br><h3>  ... </h3><br><p>  Voc√™ pode interpretar as informa√ß√µes recebidas por algum tempo, mas, como penso, este √© um recurso offtopic desse recurso.  Quem quiser pode ver por si mesmo.  Anexo o c√≥digo e os dados. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link de script</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Data Link</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt429270/">https://habr.com/ru/post/pt429270/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt429260/index.html">Nosso caminho para o armazenamento centralizado de logs</a></li>
<li><a href="../pt429262/index.html">Bem-vindo ao outono DIYouDIE Meetup 17 de novembro</a></li>
<li><a href="../pt429264/index.html">Tempo de UPS de √≠on de l√≠tio: risco de inc√™ndio ou passo seguro para o futuro?</a></li>
<li><a href="../pt429266/index.html">Quais sal√°rios para os especialistas em TI s√£o oferecidos pelos empregadores do My Circle, dados de maio a outubro de 2018</a></li>
<li><a href="../pt429268/index.html">Aranha gigante e minotauro nas ruas de Toulouse</a></li>
<li><a href="../pt429272/index.html">Um breve aperto de um livro React e desenvolvimento funcional da Web do Redux: Cap√≠tulo 1. Bem-vindo ao React</a></li>
<li><a href="../pt429274/index.html">Inicializa√ß√£o: como viver a rodada</a></li>
<li><a href="../pt429276/index.html">Auto-codificadores variacionais: teoria e c√≥digo de funcionamento</a></li>
<li><a href="../pt429278/index.html">Prospectiva tecnologia de grava√ß√£o magn√©tica MAMR: o que nos espera no futuro pr√≥ximo?</a></li>
<li><a href="../pt429280/index.html">Como uma vulnerabilidade no REG.RU permitiu obter dados de registro de qualquer dom√≠nio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
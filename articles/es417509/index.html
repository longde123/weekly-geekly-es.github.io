<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👦🏻 🌋 🤟🏼 Consejos y trucos de Kubernetes: acelerar el arranque de grandes bases de datos 📫 🎇 😷</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Con este artículo, abrimos una serie de publicaciones con instrucciones prácticas sobre cómo hacernos la vida más fácil (la operación) y los desarroll...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Consejos y trucos de Kubernetes: acelerar el arranque de grandes bases de datos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/417509/">  Con este artículo, abrimos una serie de publicaciones con instrucciones prácticas sobre cómo hacernos la vida más fácil (la operación) y los desarrolladores en diversas situaciones que suceden literalmente todos los días.  Todos ellos se recopilan a partir de la experiencia real en la resolución de problemas de los clientes y han mejorado con el tiempo, pero aún no afirman ser ideales: considérelos más como ideas y espacios en blanco. <br><br>  Comenzaré con un "truco" en la preparación de grandes volcados de bases de datos como MySQL y PostgreSQL para su rápida implementación para diversas necesidades, en primer lugar, en las plataformas para desarrolladores.  El contexto de las operaciones que se describen a continuación es nuestro entorno típico, que incluye un clúster de Kubernetes en funcionamiento y el uso de GitLab (y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dapp</a> ) para CI / CD.  Vamos! <br><br><img src="https://habrastorage.org/webt/6j/2l/4z/6j2l4z7lqghreoy3nykvws5x2u0.jpeg"><a name="habracut"></a><br><br>  El principal problema en Kubernetes cuando se utiliza la rama de características son grandes bases de datos, cuando los desarrolladores quieren probar / demostrar sus cambios en una base de datos completa (o casi completa) desde la producción.  Por ejemplo: <br><br><ul><li>  Hay una aplicación con una base de datos en MySQL para 1 TB y 10 desarrolladores que desarrollan sus propias características. </li><li>  Los desarrolladores quieren bucles de prueba individuales y un par de bucles más específicos para pruebas y / o demostraciones. </li><li>  Además, es necesario restaurar el volcado nocturno de la base de producción en su circuito de prueba durante un tiempo razonable, para reproducir el problema con el cliente o el error. </li><li>  Finalmente, es posible aligerar el tamaño de la base de datos en al menos 150 GB, no tanto, pero aún así ahorrar espacio.  Es decir  Todavía tenemos que preparar de alguna manera el vertedero. </li></ul><br>  <i><b>Nota</b> : Por lo general, hacemos una copia de seguridad de las bases de datos MySQL utilizando el innobackupex de Percona, que nos permite guardar todas las bases de datos y usuarios ..., en resumen, todo lo que pueda ser necesario.</i>  <i>Es un ejemplo que se considera más adelante en el artículo, aunque en el caso general no importa exactamente cómo hacer copias de seguridad.</i> <br><br>  Entonces, digamos que tenemos una copia de seguridad de la base de datos.  ¿Qué hacer a continuación? <br><br><h2>  Paso 1: preparar una nueva base de datos desde el volcado </h2><br>  En primer lugar, crearemos en Kubernetes <i>Deployment</i> , que constará de dos contenedores init <i>(es decir, dichos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">contenedores especiales</a> que se ejecutan antes del</i> hogar de <i>la aplicación y le permiten realizar la preconfiguración)</i> y un hogar. <br><br>  ¿Pero dónde colocarlo?  Tenemos una gran base de datos (1 TB) y queremos generar diez de sus instancias; necesitamos un servidor con un disco grande (10+ TB).  Lo pedimos por separado para esta tarea y marcamos el nodo con este servidor con una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">etiqueta</a> especial <code>dedicated: non-prod-db</code> .  Al mismo tiempo, usaremos la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><i>mancha</i></a> homónima, que Kubernetes dirá que solo las aplicaciones que son resistentes (tienen <i>tolerancias</i> ) pueden pasar a este nodo, es decir, traducir Kubernetes al lenguaje, <code>dedicated Equal non-prod-db</code> . <br><br>  Usando <code>nodeSelector</code> y <code>tolerations</code> seleccione el nodo deseado (ubicado en un servidor con un disco grande): <br><br><pre> <code class="plaintext hljs"> nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute"</code> </pre> <br>  ... y tome la descripción del contenido de este nodo. <br><br><h3>  Contenedores Init: get-bindump </h3><br>  El primer contenedor init lo llamaremos <code>get-bindump</code> .  <code>emptyDir</code> (en <code>/var/lib/mysql</code> ), donde se agregará el volcado de la base de datos recibido del servidor de respaldo.  Para hacer esto, el contenedor tiene todo lo que necesita: claves SSH, direcciones del servidor de respaldo.  Esta etapa en nuestro caso dura aproximadamente 2 horas. <br><br>  La descripción de este contenedor en <i>Implementación es la</i> siguiente: <br><br><pre> <code class="plaintext hljs"> - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh</code> </pre> <br>  El script <code>get_bindump.sh</code> utilizado en el contenedor: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/version.txt ]; then echo "Dump file already exists." exit 0 fi rm -rf /var/lib/mysql/* borg extract --stdout user@your.server.net:somedb-mysql::${lastdump} stdin | xbstream -x -C /var/lib/mysql/ echo $lastdump &gt; /dump/version.txt</span></span></code> </pre> <br><h3>  Contenedores Init: prepare-bindump </h3><br>  Después de descargar la copia de seguridad, se inicia el segundo contenedor init: <code>prepare-bindump</code> .  Ejecuta <code>innobackupex --apply-log</code> (ya que los archivos ya están disponibles en <code>/var/lib/mysql</code> - gracias a <code>emptyDir</code> de <code>get-bindump</code> ) y se inicia el servidor MySQL. <br><br>  Es en este contenedor de inicio que hacemos todas las conversiones necesarias a la base de datos, preparándola para la aplicación seleccionada: borramos las tablas para las que está permitido, cambiamos los accesos dentro de la base de datos, etc.  Luego apagamos el servidor MySQL y simplemente archivamos todo <code>/var/lib/mysql</code> en un archivo tar.gz.  Como resultado, el volcado cabe en un archivo de 100 GB, que ya es un orden de magnitud más pequeño que el original de 1 TB.  Esta etapa dura aproximadamente 5 horas. <br><br>  Descripción del segundo contenedor init en <i>Implementación</i> : <br><br><pre> <code class="plaintext hljs"> - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf</code> </pre> <br>  El script <code>prepare_bindump.sh</code> usa en este se parece a esto: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/healthz ]; then echo "Dump file already exists." exit 0 fi innobackupex --apply-log /var/lib/mysql/ chown -R mysql:mysql /var/lib/mysql chown -R mysql:mysql /var/log/mysql echo "`date`: Starting mysql" /usr/sbin/mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --innodb-data-file-path=ibdata1:200M:autoextend --user=root --skip-grant-tables &amp; sleep 200 echo "`date`: Creating mysql root user" echo "update mysql.user set Password=PASSWORD('password') WHERE user='root';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where USER like '';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where user = 'root' and host NOT IN ('127.0.0.1', 'localhost');" | mysql -uroot -h 127.0.0.1 echo "FLUSH PRIVILEGES;" | mysql -uroot -h 127.0.0.1 echo "truncate somedb.somedb_table_one;" | mysql -uroot -h 127.0.0.1 -ppassword somedb /usr/bin/mysqladmin shutdown -uroot -ppassword cd /var/lib/mysql/ tar -czf /dump/mysql_bindump.tar.gz ./* touch /dump/healthz rm -rf /var/lib/mysql/*</span></span></code> </pre> <br><h3>  Bajo </h3><br>  El acorde final es el lanzamiento del hogar principal, que ocurre después de que se ejecutan los contenedores init.  En pod, tenemos un nginx simple, y a través de <code>emtpyDir</code> comprimido y recortado de 100 GB.  La función de este nginx es dar este volcado. <br><br>  Configuración de hogar: <br><br><pre> <code class="plaintext hljs"> - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {}</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Así es como se ve la implementación completa con sus initContainers ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- apiVersion: apps/v1beta1 kind: Deployment metadata: name: db-dumps spec: strategy: rollingUpdate: maxUnavailable: 0 revisionHistoryLimit: 2 template: metadata: labels: app: db-dumps spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: log mountPath: /var/log/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf containers: - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {} - name: log emptyDir: {} - name: id-rsa secret: defaultMode: 0600 secretName: somedb-id-rsa - name: nginx-config configMap: name: somedb-nginx-config - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: somedb-db-dump spec: clusterIP: None selector: app: db-dumps ports: - name: http port: 80</code> </pre> </div></div><br>  Notas adicionales: <br><br><ol><li>  En nuestro caso, preparamos un nuevo volcado <b>todas las noches</b> utilizando el trabajo programado en GitLab.  Es decir  todas las noches, esta <i>implementación</i> se <i>implementa</i> automáticamente, lo que genera un nuevo volcado y lo prepara para su distribución a todos los entornos de desarrollo de prueba. </li><li>  ¿Por qué también estamos lanzando volumen <code>/dump</code> en contenedores de inicio (y en el script hay una comprobación de la existencia de <code>/dump/version.txt</code> )?  Esto se hace en caso de que se reinicie el servidor con el que se ejecuta.  Los contenedores comenzarán de nuevo y, sin esta comprobación, el volcado comenzará a descargarse nuevamente.  Si ya hemos preparado un volcado una vez, en el siguiente inicio (en caso de reinicio del servidor), el <code>/dump/version.txt</code> indicador <code>/dump/version.txt</code> informará sobre esto. </li><li>  ¿Cuál es la imagen <code>db-dumps</code> ?  Lo recopilamos con dapp y su <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code>Dappfile</code></a> ve así: <br><br><pre> <code class="plaintext hljs">dimg: "db-dumps" from: "ubuntu:16.04" docker: ENV: TERM: xterm ansible: beforeInstall: - name: "Install percona repositories" apt: deb: https://repo.percona.com/apt/percona-release_0.1-4.xenial_all.deb - name: "Add repository for borgbackup" apt_repository: repo="ppa:costamagnagianfranco/borgbackup" codename="xenial" update_cache=yes - name: "Add repository for mysql 5.6" apt_repository: repo: deb http://archive.ubuntu.com/ubuntu trusty universe state: present update_cache: yes - name: "Install packages" apt: name: "{{`{{ item }}`}}" state: present with_items: - openssh-client - mysql-server-5.6 - mysql-client-5.6 - borgbackup - percona-xtrabackup-24 setup: - name: "Add get_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/get_bindump.sh" | indent 8 }} dest: /get_bindump.sh mode: 0755 - name: "Add prepare_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/prepare_bindump.sh" | indent 8 }} dest: /prepare_bindump.sh mode: 0755</code> </pre> </li></ol><br><h2>  Paso 2: lanzamiento de la base de datos en un entorno de desarrollador </h2><br>  Al implementar la base de datos MySQL en el entorno de prueba del desarrollador, tiene un botón en GitLab que inicia la redistribución de la <i>implementación</i> con MySQL con la estrategia <code>RollingUpdate.maxUnavailable: 0</code> : <br><br><img src="https://habrastorage.org/webt/up/bv/j8/upbvj8ouflxbxyemaok3llra03a.png"><br><br><div class="spoiler">  <b class="spoiler_title">¿Cómo se implementa esto?</b> <div class="spoiler_text">  En GitLab, cuando hace clic en <i>recargar db</i> , se <i>implementa</i> la <i>implementación</i> con la siguiente especificación: <br><br><pre> <code class="plaintext hljs">spec: strategy: rollingUpdate: maxUnavailable: 0</code> </pre> <br>  Es decir  le decimos a Kubernetes que actualice la <i>implementación</i> (cree una nueva en) y nos aseguremos de que al menos una de ellas esté activa.  Dado que al crear un nuevo hogar, tiene contenedores de inicio mientras están trabajando, el nuevo <b>no</b> entra en estado de <i>Ejecución</i> , lo que significa que el antiguo continúa funcionando.  Y solo en el momento en que MySQL se inició (y la sonda de preparación funcionó), el tráfico cambia a él y se elimina el anterior (con la base de datos anterior). <br><br>  Los detalles sobre este esquema se pueden encontrar en los siguientes materiales: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Realizar una actualización continua</a> <i>(documentación de Kubernetes)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Actualizaciones continuas con implementaciones de Kubernetes</a> <i>(Ta-Ching Chen)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Estrategias de implementación de Kubernetes</a> <i>(Soluciones de contenedores)</i> . </li></ul></div></div><br>  El enfoque elegido nos permite esperar hasta que se descargue, descomprima y ejecute un nuevo volcado, y solo después de eso, el antiguo se eliminará de MySQL.  Por lo tanto, mientras estamos preparando un nuevo volcado, estamos trabajando en silencio con la antigua base. <br><br>  El contenedor de inicio de esta <i>implementación</i> utiliza el siguiente comando: <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$DUMP_URL</span></span></span><span class="hljs-string">"</span></span> | tar -C /var/lib/mysql/ -xvz</code> </pre> <br>  Es decir  descargamos el volcado de la base de datos comprimida que se preparó en el paso 1, lo descomprimimos en <code>/var/lib/mysql</code> y luego se inicia en <i>Implementación</i> , en el que MySQL se inicia con los datos ya preparados.  Todo esto lleva unas 2 horas. <br><br><div class="spoiler">  <b class="spoiler_title">Y la implementación es la siguiente ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">apiVersion: apps/v1beta1 kind: Deployment metadata: name: mysql spec: strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: service: mysql spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: getdump image: mysql-with-getdump command: ["/usr/local/bin/getdump.sh"] resources: limits: memory: "6000Mi" cpu: "1.5" requests: memory: "6000Mi" cpu: "1.5" volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: DUMP_URL value: "http://somedb-db-dump.infra-db.svc.cluster.local/mysql_bindump.tar.gz" containers: - name: mysql image: mysql:5.6 resources: limits: memory: "1024Mi" cpu: "1" requests: memory: "1024Mi" cpu: "1" lifecycle: preStop: exec: command: ["/etc/init.d/mysql", "stop"] ports: - containerPort: 3306 name: mysql protocol: TCP volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: MYSQL_ROOT_PASSWORD value: "password" volumes: - name: datadir emptyDir: {} - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: mysql spec: clusterIP: None selector: service: mysql ports: - name: mysql port: 3306 protocol: TCP --- apiVersion: v1 kind: ConfigMap metadata: name: somedb-debian-cnf data: debian.cnf: | [client] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock</code> </pre> </div></div><br><h2>  Resumen </h2><br>  Resulta que siempre tenemos <i>Implementación</i> , que se implementa todas las noches y hace lo siguiente: <br><br><ul><li>  Obtiene un volcado de base de datos nuevo </li><li>  de alguna manera lo prepara para su correcto funcionamiento en un entorno de prueba (por ejemplo, trankeytit algunas tablas, reemplaza datos de usuario reales, crea los usuarios necesarios, etc.); </li><li>  brinda a cada desarrollador la oportunidad de implementar una base de datos preparada en su espacio de nombres en <i>Implementación</i> presionando un botón en CI; gracias al <i>Servicio</i> disponible en ella, la base de datos estará disponible en <code>mysql</code> (por ejemplo, puede ser el nombre del servicio en el espacio de nombres). </li></ul><br>  Para el ejemplo que examinamos, crear un volcado a partir de una réplica real lleva aproximadamente 6 horas, preparar una "imagen base" lleva 7 horas y actualizar la base de datos en el entorno del desarrollador lleva 2 horas.  Dado que las dos primeras acciones se realizan "en segundo plano" y son invisibles para los desarrolladores, de hecho, pueden implementar una versión de producción de la base de datos (con un tamaño de 1 TB) <b>durante las mismas 2 horas</b> . <br><br>  ¡Preguntas, críticas y correcciones al esquema propuesto y sus componentes son bienvenidos en los comentarios! <br><br>  PD Por supuesto, entendemos que en el caso de VMware y algunas otras herramientas, sería posible crear una instantánea de una máquina virtual y lanzar un nuevo virusalka desde una instantánea (que es aún más rápido), pero esta opción no incluye la preparación de la base, teniendo en cuenta que resultará casi igual tiempo ... Sin mencionar el hecho de que no todos tienen la oportunidad o el deseo de utilizar productos comerciales. <br><br><h2>  PPS </h2><br>  Otros del ciclo de consejos y trucos de K8s: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Páginas de error personalizadas en NGINX Ingress</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Transferencia de recursos que trabajan en un clúster a la gestión de Helm 2</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Sobre la asignación de nodos y la carga en la aplicación web</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Acceso a sitios de desarrollo</a> ". </li></ul><br>  Lea también en nuestro blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Crear e instalar aplicaciones en Kubernetes utilizando dapp y GitLab CI</a> "; </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Practica con dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 1: Creación de aplicaciones simples</a> "; </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Practica con dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2. Despliegue de imágenes Docker en Kubernetes usando Helm</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CockroachDB DBMS Orchestration en Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nuestra experiencia con Kubernetes en pequeños proyectos</a> " <i>(informe en video, que incluye una introducción al dispositivo técnico de Kubernetes);</i> </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Utilidades útiles cuando se trabaja con Kubernetes</a> ". </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417509/">https://habr.com/ru/post/es417509/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417497/index.html">4 años de Data Science en Schibsted Media Group</a></li>
<li><a href="../es417501/index.html">Lifehacks fabricando tableros de dos capas (LUT)</a></li>
<li><a href="../es417503/index.html">Lo que un desarrollador web debe recordar hacer SEO-Feng Shui</a></li>
<li><a href="../es417505/index.html">Intel lanza parches para nuevas vulnerabilidades de firmware de ME</a></li>
<li><a href="../es417507/index.html">Trucos para vincular y descargar archivos Mach-O</a></li>
<li><a href="../es417511/index.html">Intel adquiere eASIC - Desarrollador ASIC estructural</a></li>
<li><a href="../es417513/index.html">Análogos en Python y JavaScript. Parte dos</a></li>
<li><a href="../es417515/index.html">Lo que aprendí al crear 100 juegos en 5 años</a></li>
<li><a href="../es417517/index.html">Páginas de la historia de Intel. Foto crónica y cuestionario</a></li>
<li><a href="../es417521/index.html">Revise los certificados SSL para revocación</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
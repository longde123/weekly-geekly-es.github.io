<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë¶üèª üåã ü§üüèº Consejos y trucos de Kubernetes: acelerar el arranque de grandes bases de datos üì´ üéá üò∑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Con este art√≠culo, abrimos una serie de publicaciones con instrucciones pr√°cticas sobre c√≥mo hacernos la vida m√°s f√°cil (la operaci√≥n) y los desarroll...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Consejos y trucos de Kubernetes: acelerar el arranque de grandes bases de datos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/417509/">  Con este art√≠culo, abrimos una serie de publicaciones con instrucciones pr√°cticas sobre c√≥mo hacernos la vida m√°s f√°cil (la operaci√≥n) y los desarrolladores en diversas situaciones que suceden literalmente todos los d√≠as.  Todos ellos se recopilan a partir de la experiencia real en la resoluci√≥n de problemas de los clientes y han mejorado con el tiempo, pero a√∫n no afirman ser ideales: consid√©relos m√°s como ideas y espacios en blanco. <br><br>  Comenzar√© con un "truco" en la preparaci√≥n de grandes volcados de bases de datos como MySQL y PostgreSQL para su r√°pida implementaci√≥n para diversas necesidades, en primer lugar, en las plataformas para desarrolladores.  El contexto de las operaciones que se describen a continuaci√≥n es nuestro entorno t√≠pico, que incluye un cl√∫ster de Kubernetes en funcionamiento y el uso de GitLab (y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dapp</a> ) para CI / CD.  Vamos! <br><br><img src="https://habrastorage.org/webt/6j/2l/4z/6j2l4z7lqghreoy3nykvws5x2u0.jpeg"><a name="habracut"></a><br><br>  El principal problema en Kubernetes cuando se utiliza la rama de caracter√≠sticas son grandes bases de datos, cuando los desarrolladores quieren probar / demostrar sus cambios en una base de datos completa (o casi completa) desde la producci√≥n.  Por ejemplo: <br><br><ul><li>  Hay una aplicaci√≥n con una base de datos en MySQL para 1 TB y 10 desarrolladores que desarrollan sus propias caracter√≠sticas. </li><li>  Los desarrolladores quieren bucles de prueba individuales y un par de bucles m√°s espec√≠ficos para pruebas y / o demostraciones. </li><li>  Adem√°s, es necesario restaurar el volcado nocturno de la base de producci√≥n en su circuito de prueba durante un tiempo razonable, para reproducir el problema con el cliente o el error. </li><li>  Finalmente, es posible aligerar el tama√±o de la base de datos en al menos 150 GB, no tanto, pero a√∫n as√≠ ahorrar espacio.  Es decir  Todav√≠a tenemos que preparar de alguna manera el vertedero. </li></ul><br>  <i><b>Nota</b> : Por lo general, hacemos una copia de seguridad de las bases de datos MySQL utilizando el innobackupex de Percona, que nos permite guardar todas las bases de datos y usuarios ..., en resumen, todo lo que pueda ser necesario.</i>  <i>Es un ejemplo que se considera m√°s adelante en el art√≠culo, aunque en el caso general no importa exactamente c√≥mo hacer copias de seguridad.</i> <br><br>  Entonces, digamos que tenemos una copia de seguridad de la base de datos.  ¬øQu√© hacer a continuaci√≥n? <br><br><h2>  Paso 1: preparar una nueva base de datos desde el volcado </h2><br>  En primer lugar, crearemos en Kubernetes <i>Deployment</i> , que constar√° de dos contenedores init <i>(es decir, dichos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">contenedores especiales</a> que se ejecutan antes del</i> hogar de <i>la aplicaci√≥n y le permiten realizar la preconfiguraci√≥n)</i> y un hogar. <br><br>  ¬øPero d√≥nde colocarlo?  Tenemos una gran base de datos (1 TB) y queremos generar diez de sus instancias; necesitamos un servidor con un disco grande (10+ TB).  Lo pedimos por separado para esta tarea y marcamos el nodo con este servidor con una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">etiqueta</a> especial <code>dedicated: non-prod-db</code> .  Al mismo tiempo, usaremos la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><i>mancha</i></a> hom√≥nima, que Kubernetes dir√° que solo las aplicaciones que son resistentes (tienen <i>tolerancias</i> ) pueden pasar a este nodo, es decir, traducir Kubernetes al lenguaje, <code>dedicated Equal non-prod-db</code> . <br><br>  Usando <code>nodeSelector</code> y <code>tolerations</code> seleccione el nodo deseado (ubicado en un servidor con un disco grande): <br><br><pre> <code class="plaintext hljs"> nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute"</code> </pre> <br>  ... y tome la descripci√≥n del contenido de este nodo. <br><br><h3>  Contenedores Init: get-bindump </h3><br>  El primer contenedor init lo llamaremos <code>get-bindump</code> .  <code>emptyDir</code> (en <code>/var/lib/mysql</code> ), donde se agregar√° el volcado de la base de datos recibido del servidor de respaldo.  Para hacer esto, el contenedor tiene todo lo que necesita: claves SSH, direcciones del servidor de respaldo.  Esta etapa en nuestro caso dura aproximadamente 2 horas. <br><br>  La descripci√≥n de este contenedor en <i>Implementaci√≥n es la</i> siguiente: <br><br><pre> <code class="plaintext hljs"> - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh</code> </pre> <br>  El script <code>get_bindump.sh</code> utilizado en el contenedor: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/version.txt ]; then echo "Dump file already exists." exit 0 fi rm -rf /var/lib/mysql/* borg extract --stdout user@your.server.net:somedb-mysql::${lastdump} stdin | xbstream -x -C /var/lib/mysql/ echo $lastdump &gt; /dump/version.txt</span></span></code> </pre> <br><h3>  Contenedores Init: prepare-bindump </h3><br>  Despu√©s de descargar la copia de seguridad, se inicia el segundo contenedor init: <code>prepare-bindump</code> .  Ejecuta <code>innobackupex --apply-log</code> (ya que los archivos ya est√°n disponibles en <code>/var/lib/mysql</code> - gracias a <code>emptyDir</code> de <code>get-bindump</code> ) y se inicia el servidor MySQL. <br><br>  Es en este contenedor de inicio que hacemos todas las conversiones necesarias a la base de datos, prepar√°ndola para la aplicaci√≥n seleccionada: borramos las tablas para las que est√° permitido, cambiamos los accesos dentro de la base de datos, etc.  Luego apagamos el servidor MySQL y simplemente archivamos todo <code>/var/lib/mysql</code> en un archivo tar.gz.  Como resultado, el volcado cabe en un archivo de 100 GB, que ya es un orden de magnitud m√°s peque√±o que el original de 1 TB.  Esta etapa dura aproximadamente 5 horas. <br><br>  Descripci√≥n del segundo contenedor init en <i>Implementaci√≥n</i> : <br><br><pre> <code class="plaintext hljs"> - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf</code> </pre> <br>  El script <code>prepare_bindump.sh</code> usa en este se parece a esto: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/healthz ]; then echo "Dump file already exists." exit 0 fi innobackupex --apply-log /var/lib/mysql/ chown -R mysql:mysql /var/lib/mysql chown -R mysql:mysql /var/log/mysql echo "`date`: Starting mysql" /usr/sbin/mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --innodb-data-file-path=ibdata1:200M:autoextend --user=root --skip-grant-tables &amp; sleep 200 echo "`date`: Creating mysql root user" echo "update mysql.user set Password=PASSWORD('password') WHERE user='root';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where USER like '';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where user = 'root' and host NOT IN ('127.0.0.1', 'localhost');" | mysql -uroot -h 127.0.0.1 echo "FLUSH PRIVILEGES;" | mysql -uroot -h 127.0.0.1 echo "truncate somedb.somedb_table_one;" | mysql -uroot -h 127.0.0.1 -ppassword somedb /usr/bin/mysqladmin shutdown -uroot -ppassword cd /var/lib/mysql/ tar -czf /dump/mysql_bindump.tar.gz ./* touch /dump/healthz rm -rf /var/lib/mysql/*</span></span></code> </pre> <br><h3>  Bajo </h3><br>  El acorde final es el lanzamiento del hogar principal, que ocurre despu√©s de que se ejecutan los contenedores init.  En pod, tenemos un nginx simple, y a trav√©s de <code>emtpyDir</code> comprimido y recortado de 100 GB.  La funci√≥n de este nginx es dar este volcado. <br><br>  Configuraci√≥n de hogar: <br><br><pre> <code class="plaintext hljs"> - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {}</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">As√≠ es como se ve la implementaci√≥n completa con sus initContainers ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- apiVersion: apps/v1beta1 kind: Deployment metadata: name: db-dumps spec: strategy: rollingUpdate: maxUnavailable: 0 revisionHistoryLimit: 2 template: metadata: labels: app: db-dumps spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: log mountPath: /var/log/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf containers: - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {} - name: log emptyDir: {} - name: id-rsa secret: defaultMode: 0600 secretName: somedb-id-rsa - name: nginx-config configMap: name: somedb-nginx-config - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: somedb-db-dump spec: clusterIP: None selector: app: db-dumps ports: - name: http port: 80</code> </pre> </div></div><br>  Notas adicionales: <br><br><ol><li>  En nuestro caso, preparamos un nuevo volcado <b>todas las noches</b> utilizando el trabajo programado en GitLab.  Es decir  todas las noches, esta <i>implementaci√≥n</i> se <i>implementa</i> autom√°ticamente, lo que genera un nuevo volcado y lo prepara para su distribuci√≥n a todos los entornos de desarrollo de prueba. </li><li>  ¬øPor qu√© tambi√©n estamos lanzando volumen <code>/dump</code> en contenedores de inicio (y en el script hay una comprobaci√≥n de la existencia de <code>/dump/version.txt</code> )?  Esto se hace en caso de que se reinicie el servidor con el que se ejecuta.  Los contenedores comenzar√°n de nuevo y, sin esta comprobaci√≥n, el volcado comenzar√° a descargarse nuevamente.  Si ya hemos preparado un volcado una vez, en el siguiente inicio (en caso de reinicio del servidor), el <code>/dump/version.txt</code> indicador <code>/dump/version.txt</code> informar√° sobre esto. </li><li>  ¬øCu√°l es la imagen <code>db-dumps</code> ?  Lo recopilamos con dapp y su <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code>Dappfile</code></a> ve as√≠: <br><br><pre> <code class="plaintext hljs">dimg: "db-dumps" from: "ubuntu:16.04" docker: ENV: TERM: xterm ansible: beforeInstall: - name: "Install percona repositories" apt: deb: https://repo.percona.com/apt/percona-release_0.1-4.xenial_all.deb - name: "Add repository for borgbackup" apt_repository: repo="ppa:costamagnagianfranco/borgbackup" codename="xenial" update_cache=yes - name: "Add repository for mysql 5.6" apt_repository: repo: deb http://archive.ubuntu.com/ubuntu trusty universe state: present update_cache: yes - name: "Install packages" apt: name: "{{`{{ item }}`}}" state: present with_items: - openssh-client - mysql-server-5.6 - mysql-client-5.6 - borgbackup - percona-xtrabackup-24 setup: - name: "Add get_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/get_bindump.sh" | indent 8 }} dest: /get_bindump.sh mode: 0755 - name: "Add prepare_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/prepare_bindump.sh" | indent 8 }} dest: /prepare_bindump.sh mode: 0755</code> </pre> </li></ol><br><h2>  Paso 2: lanzamiento de la base de datos en un entorno de desarrollador </h2><br>  Al implementar la base de datos MySQL en el entorno de prueba del desarrollador, tiene un bot√≥n en GitLab que inicia la redistribuci√≥n de la <i>implementaci√≥n</i> con MySQL con la estrategia <code>RollingUpdate.maxUnavailable: 0</code> : <br><br><img src="https://habrastorage.org/webt/up/bv/j8/upbvj8ouflxbxyemaok3llra03a.png"><br><br><div class="spoiler">  <b class="spoiler_title">¬øC√≥mo se implementa esto?</b> <div class="spoiler_text">  En GitLab, cuando hace clic en <i>recargar db</i> , se <i>implementa</i> la <i>implementaci√≥n</i> con la siguiente especificaci√≥n: <br><br><pre> <code class="plaintext hljs">spec: strategy: rollingUpdate: maxUnavailable: 0</code> </pre> <br>  Es decir  le decimos a Kubernetes que actualice la <i>implementaci√≥n</i> (cree una nueva en) y nos aseguremos de que al menos una de ellas est√© activa.  Dado que al crear un nuevo hogar, tiene contenedores de inicio mientras est√°n trabajando, el nuevo <b>no</b> entra en estado de <i>Ejecuci√≥n</i> , lo que significa que el antiguo contin√∫a funcionando.  Y solo en el momento en que MySQL se inici√≥ (y la sonda de preparaci√≥n funcion√≥), el tr√°fico cambia a √©l y se elimina el anterior (con la base de datos anterior). <br><br>  Los detalles sobre este esquema se pueden encontrar en los siguientes materiales: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Realizar una actualizaci√≥n continua</a> <i>(documentaci√≥n de Kubernetes)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Actualizaciones continuas con implementaciones de Kubernetes</a> <i>(Ta-Ching Chen)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Estrategias de implementaci√≥n de Kubernetes</a> <i>(Soluciones de contenedores)</i> . </li></ul></div></div><br>  El enfoque elegido nos permite esperar hasta que se descargue, descomprima y ejecute un nuevo volcado, y solo despu√©s de eso, el antiguo se eliminar√° de MySQL.  Por lo tanto, mientras estamos preparando un nuevo volcado, estamos trabajando en silencio con la antigua base. <br><br>  El contenedor de inicio de esta <i>implementaci√≥n</i> utiliza el siguiente comando: <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$DUMP_URL</span></span></span><span class="hljs-string">"</span></span> | tar -C /var/lib/mysql/ -xvz</code> </pre> <br>  Es decir  descargamos el volcado de la base de datos comprimida que se prepar√≥ en el paso 1, lo descomprimimos en <code>/var/lib/mysql</code> y luego se inicia en <i>Implementaci√≥n</i> , en el que MySQL se inicia con los datos ya preparados.  Todo esto lleva unas 2 horas. <br><br><div class="spoiler">  <b class="spoiler_title">Y la implementaci√≥n es la siguiente ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">apiVersion: apps/v1beta1 kind: Deployment metadata: name: mysql spec: strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: service: mysql spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: getdump image: mysql-with-getdump command: ["/usr/local/bin/getdump.sh"] resources: limits: memory: "6000Mi" cpu: "1.5" requests: memory: "6000Mi" cpu: "1.5" volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: DUMP_URL value: "http://somedb-db-dump.infra-db.svc.cluster.local/mysql_bindump.tar.gz" containers: - name: mysql image: mysql:5.6 resources: limits: memory: "1024Mi" cpu: "1" requests: memory: "1024Mi" cpu: "1" lifecycle: preStop: exec: command: ["/etc/init.d/mysql", "stop"] ports: - containerPort: 3306 name: mysql protocol: TCP volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: MYSQL_ROOT_PASSWORD value: "password" volumes: - name: datadir emptyDir: {} - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: mysql spec: clusterIP: None selector: service: mysql ports: - name: mysql port: 3306 protocol: TCP --- apiVersion: v1 kind: ConfigMap metadata: name: somedb-debian-cnf data: debian.cnf: | [client] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock</code> </pre> </div></div><br><h2>  Resumen </h2><br>  Resulta que siempre tenemos <i>Implementaci√≥n</i> , que se implementa todas las noches y hace lo siguiente: <br><br><ul><li>  Obtiene un volcado de base de datos nuevo </li><li>  de alguna manera lo prepara para su correcto funcionamiento en un entorno de prueba (por ejemplo, trankeytit algunas tablas, reemplaza datos de usuario reales, crea los usuarios necesarios, etc.); </li><li>  brinda a cada desarrollador la oportunidad de implementar una base de datos preparada en su espacio de nombres en <i>Implementaci√≥n</i> presionando un bot√≥n en CI; gracias al <i>Servicio</i> disponible en ella, la base de datos estar√° disponible en <code>mysql</code> (por ejemplo, puede ser el nombre del servicio en el espacio de nombres). </li></ul><br>  Para el ejemplo que examinamos, crear un volcado a partir de una r√©plica real lleva aproximadamente 6 horas, preparar una "imagen base" lleva 7 horas y actualizar la base de datos en el entorno del desarrollador lleva 2 horas.  Dado que las dos primeras acciones se realizan "en segundo plano" y son invisibles para los desarrolladores, de hecho, pueden implementar una versi√≥n de producci√≥n de la base de datos (con un tama√±o de 1 TB) <b>durante las mismas 2 horas</b> . <br><br>  ¬°Preguntas, cr√≠ticas y correcciones al esquema propuesto y sus componentes son bienvenidos en los comentarios! <br><br>  PD Por supuesto, entendemos que en el caso de VMware y algunas otras herramientas, ser√≠a posible crear una instant√°nea de una m√°quina virtual y lanzar un nuevo virusalka desde una instant√°nea (que es a√∫n m√°s r√°pido), pero esta opci√≥n no incluye la preparaci√≥n de la base, teniendo en cuenta que resultar√° casi igual tiempo ... Sin mencionar el hecho de que no todos tienen la oportunidad o el deseo de utilizar productos comerciales. <br><br><h2>  PPS </h2><br>  Otros del ciclo de consejos y trucos de K8s: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">P√°ginas de error personalizadas en NGINX Ingress</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Transferencia de recursos que trabajan en un cl√∫ster a la gesti√≥n de Helm 2</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Sobre la asignaci√≥n de nodos y la carga en la aplicaci√≥n web</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Acceso a sitios de desarrollo</a> ". </li></ul><br>  Lea tambi√©n en nuestro blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Crear e instalar aplicaciones en Kubernetes utilizando dapp y GitLab CI</a> "; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Practica con dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 1: Creaci√≥n de aplicaciones simples</a> "; </li><li>  ‚Äú <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Practica con dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 2. Despliegue de im√°genes Docker en Kubernetes usando Helm</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CockroachDB DBMS Orchestration en Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nuestra experiencia con Kubernetes en peque√±os proyectos</a> " <i>(informe en video, que incluye una introducci√≥n al dispositivo t√©cnico de Kubernetes);</i> </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Utilidades √∫tiles cuando se trabaja con Kubernetes</a> ". </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417509/">https://habr.com/ru/post/es417509/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417497/index.html">4 a√±os de Data Science en Schibsted Media Group</a></li>
<li><a href="../es417501/index.html">Lifehacks fabricando tableros de dos capas (LUT)</a></li>
<li><a href="../es417503/index.html">Lo que un desarrollador web debe recordar hacer SEO-Feng Shui</a></li>
<li><a href="../es417505/index.html">Intel lanza parches para nuevas vulnerabilidades de firmware de ME</a></li>
<li><a href="../es417507/index.html">Trucos para vincular y descargar archivos Mach-O</a></li>
<li><a href="../es417511/index.html">Intel adquiere eASIC - Desarrollador ASIC estructural</a></li>
<li><a href="../es417513/index.html">An√°logos en Python y JavaScript. Parte dos</a></li>
<li><a href="../es417515/index.html">Lo que aprend√≠ al crear 100 juegos en 5 a√±os</a></li>
<li><a href="../es417517/index.html">P√°ginas de la historia de Intel. Foto cr√≥nica y cuestionario</a></li>
<li><a href="../es417521/index.html">Revise los certificados SSL para revocaci√≥n</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
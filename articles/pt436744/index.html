<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçß üï∑Ô∏è ü§üüèø Inicie seu detector de rede neural no Raspberry Pi usando o Neural Compute Stick e o OpenVINO üõÅ ‚òùüèª üôÖüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Com a dissemina√ß√£o e desenvolvimento de redes neurais, h√° uma necessidade crescente de us√°-las em dispositivos embarcados e de baixa pot√™ncia, rob√¥s e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Inicie seu detector de rede neural no Raspberry Pi usando o Neural Compute Stick e o OpenVINO</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436744/">  Com a dissemina√ß√£o e desenvolvimento de redes neurais, h√° uma necessidade crescente de us√°-las em dispositivos embarcados e de baixa pot√™ncia, rob√¥s e drones.  O dispositivo Neural Compute Stick, em conjunto com a estrutura Intel OpenVINO, nos permite resolver esse problema, realizando c√°lculos pesados ‚Äã‚Äãde redes neurais.  Gra√ßas a isso, voc√™ pode iniciar facilmente um classificador ou detector de rede neural em um dispositivo de baixa pot√™ncia como o Raspberry Pi quase em tempo real, sem aumentar significativamente o consumo de energia.  Nesta postagem, mostrarei como usar a estrutura OpenVINO (em C ++) e o Neural Compute Stick para lan√ßar um sistema simples de detec√ß√£o de rosto no Raspberry Pi. <br><br>  Como sempre, todo o c√≥digo est√° dispon√≠vel no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GitHub</a> . <br><br><img src="https://habrastorage.org/webt/qu/b_/tj/qub_tj1u6ztw9irfy9ivtaaidcc.jpeg"><br><a name="habracut"></a><br><h3>  Um pouco sobre o Neural Compute Stick e o OpenVINO </h3><br>  No ver√£o de 2017, a Intel lan√ßou o dispositivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Neural Compute Stick</a> (NCS), projetado para executar redes neurais em dispositivos de baixo consumo de energia, e ap√≥s alguns meses ele p√¥de ser comprado e testado, o que eu fiz.  O NCS √© um pequeno m√≥dulo de computa√ß√£o com uma caixa de cor azul (tamb√©m atuando como um radiador), conectado ao dispositivo principal via USB.  Dentro, entre outras coisas, est√° o Intel Myriad <abbr title="Unidade de processamento de vis√£o">VPU</abbr> , que √© essencialmente um processador paralelo de 12 n√∫cleos, aprimorado para opera√ß√µes que ocorrem frequentemente em redes neurais.  O NCS n√£o √© adequado para o treinamento de redes neurais, mas a infer√™ncia em redes neurais j√° treinadas √© compar√°vel em velocidade √† da GPU.  Todos os c√°lculos no NCS s√£o realizados em n√∫meros flutuantes de 16 bits, o que permite aumentar a velocidade.  O NCS requer apenas 1 Watt de energia para operar, ou seja, a 5 V, uma corrente de at√© 200 mA √© consumida no conector USB - isso √© ainda menos do que a c√¢mera do Raspberry Pi (250 mA). <br><br><img src="https://habrastorage.org/webt/8d/u8/ov/8du8ov7hj1-f3vk8sjbenkyupvm.png"><br><br>  Para trabalhar com o primeiro NCS, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Neural Compute SDK</a> (NCSDK) foi usado: inclui ferramentas para compilar redes neurais nos formatos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Caffe</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TensorFlow</a> para o formato NCS, ferramentas para medir seu desempenho, bem como as APIs Python e C ++ para infer√™ncia. <br><br>  Em seguida, uma nova vers√£o da estrutura NCS foi lan√ßada: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NCSDK2</a> .  A API mudou bastante e, embora algumas mudan√ßas parecessem estranhas para mim, houve algumas inova√ß√µes √∫teis.  Em particular, foi adicionada a convers√£o autom√°tica de float 32 bits para float 16 bits em C ++ (anteriormente, as muletas tinham que ser inseridas na forma de c√≥digo do Numpy).  Tamb√©m apareceram filas de imagens e os resultados de seu processamento. <br><br>  Em maio de 2018, a Intel lan√ßou o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenVINO</a> (anteriormente chamado de Intel Computer Vision SDK).  Essa estrutura foi projetada para iniciar com efici√™ncia redes neurais em v√°rios dispositivos: processadores e placas gr√°ficas Intel, <abbr title="Matriz de portas program√°vel em campo">FPGA</abbr> e tamb√©m o Neural Compute Stick. <br><br>  Em novembro de 2018, uma nova vers√£o do acelerador foi lan√ßada: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Neural Compute Stick 2</a> .  O poder de computa√ß√£o do dispositivo aumentou: na descri√ß√£o no site eles prometem acelera√ß√£o de at√© 8x, no entanto, n√£o pude testar a nova vers√£o do dispositivo.  A acelera√ß√£o √© alcan√ßada aumentando o n√∫mero de n√∫cleos de 12 para 16, al√©m de adicionar novos dispositivos de computa√ß√£o otimizados para redes neurais.  √â verdade que n√£o encontrei informa√ß√µes sobre o consumo de energia das informa√ß√µes. <br><br>  A segunda vers√£o do NCS j√° √© incompat√≠vel com NCSDK ou NCSDK2: o OpenVINO, que √© capaz de trabalhar com muitos outros dispositivos al√©m das duas vers√µes do NCS, passou sua autoridade.  O pr√≥prio OpenVINO possui √≥tima funcionalidade e inclui os seguintes componentes: <br><br><ol><li>  Otimizador de modelo: script Python que permite converter redes neurais de estruturas populares de aprendizado profundo no formato universal OpenVINO.  A lista de estruturas suportadas: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Caffe</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MXNET</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kaldi</a> (estrutura de reconhecimento de fala), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ONNX</a> (formato aberto para representar redes neurais). </li><li>  Mecanismo de infer√™ncia: C ++ e API Python para infer√™ncia de rede neural, abstra√≠das de um dispositivo de infer√™ncia espec√≠fico.  O c√≥digo da API ser√° quase id√™ntico para CPU, GPU, FPGA e NCS. </li><li>  Um conjunto de plugins para diferentes dispositivos.  Plugins s√£o bibliotecas din√¢micas carregadas explicitamente no c√≥digo do programa principal.  Estamos mais interessados ‚Äã‚Äãno plugin para o NCS. </li><li>  Um conjunto de modelos pr√©-treinados no formato universal OpenVINO (a lista completa est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ).  Uma impressionante cole√ß√£o de redes neurais de alta qualidade: detectores de rostos, pedestres, objetos;  reconhecimento da orienta√ß√£o de rostos, pontos especiais de rostos, posturas humanas;  super resolu√ß√£o;  e outros  Vale ressaltar que nem todos eles s√£o suportados pelo NCS / FPGA / GPU. </li><li>  Model Downloader: outro script que simplifica o download de modelos no formato OpenVINO pela rede (embora voc√™ possa fazer isso facilmente). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Biblioteca de</a> vis√£o computacional <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenCV</a> otimizada para hardware Intel. </li><li>  Biblioteca de vis√£o computacional <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenVX</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Biblioteca de computa√ß√£o</a> Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">para redes neurais profundas</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Biblioteca</a> Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kernel de matem√°tica para redes neurais profundas</a> . </li><li>  Uma ferramenta para otimizar redes neurais para FPGA (opcional). </li><li>  Documenta√ß√£o e exemplos de programas. </li></ol><br>  Nos meus artigos anteriores, falei sobre como executar o detector de rosto YOLO no NCS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">(primeiro artigo)</a> , al√©m de como treinar seu detector de rosto SSD e execut√°-lo no Raspberry Pi e NCS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">(segundo artigo)</a> .  Nestes artigos, usei NCSDK e NCSDK2.  Neste artigo, mostrarei como fazer algo semelhante, mas usando o OpenVINO, farei uma pequena compara√ß√£o dos dois detectores de rosto diferentes e duas estruturas para inici√°-los, e apontarei algumas armadilhas.  Eu escrevo em C ++, porque acredito que dessa maneira voc√™ poder√° obter um melhor desempenho, o que ser√° importante no caso do Raspberry Pi. <br><br><h3>  Instale o OpenVINO </h3><br>  N√£o √© a tarefa mais dif√≠cil, embora haja sutilezas.  No momento em que escrevi, o OpenVINO suporta apenas o Ubuntu 16.04 LTS, CentOS 7.4 e Windows 10. Eu tenho o Ubuntu 18 instalado e preciso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pequenas muletas</a> para instal√°-lo.  Eu tamb√©m queria comparar o OpenVINO com o NCSDK2, cuja instala√ß√£o tamb√©m apresenta problemas: em particular, aperta suas vers√µes do Caffe e TensorFlow e pode alterar um pouco as configura√ß√µes do ambiente.  No final, decidi seguir um caminho simples e instalar as duas estruturas em uma m√°quina virtual com o Ubuntu 16 (eu uso o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VirtualBox</a> ). <br><br>  Vale ressaltar que, para conectar com √™xito o NCS a uma m√°quina virtual, √© necess√°rio instalar os complementos de convidados do VirtualBox e ativar o suporte ao USB 3.0.  Tamb√©m adicionei um filtro universal para dispositivos USB, pelo qual o NCS se conectou sem problemas (embora a webcam ainda precise ser conectada nas configura√ß√µes da m√°quina virtual).  Para instalar e compilar o OpenVINO, voc√™ precisa ter uma conta Intel, escolha uma op√ß√£o de estrutura (com ou sem suporte a FPGA) e siga as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">instru√ß√µes</a> .  O NCSDK √© ainda mais simples: ele inicializa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">no GitHub</a> (n√£o esque√ßa de selecionar o ramo ncsdk2 para a nova vers√£o do framework), ap√≥s o qual voc√™ precisa <code>make install</code> . <br><br>  O √∫nico problema que encontrei ao executar o NCSDK2 em uma m√°quina virtual √© um erro do seguinte formato: <br><br><pre> <code class="plaintext hljs">E: [ 0] dispatcherEventReceive:236 dispatcherEventReceive() Read failed -1 E: [ 0] eventReader:254 Failed to receive event, the device may have reset</code> </pre><br>  Ocorre no final da execu√ß√£o correta do programa e (ao que parece) n√£o afeta nada.  Aparentemente, esse √© um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pequeno bug relacionado √† VM</a> (n√£o deve estar no Raspberry). <br><br>  A instala√ß√£o no Raspberry Pi √© significativamente diferente.  Primeiro, verifique se o Raspbian Stretch est√° instalado: ambas as estruturas funcionam oficialmente apenas neste sistema operacional.  O NCSDK2 precisa ser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">compilado no modo somente API</a> , caso contr√°rio, ele tentar√° instalar o Caffe e o TensorFlow, o que dificilmente agradar√° seu Raspberry.  No caso do OpenVINO, existe uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vers√£o</a> j√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">montada para o Raspberry</a> , que voc√™ s√≥ precisa descompactar e configurar as vari√°veis ‚Äã‚Äãde ambiente.  Nesta vers√£o, h√° apenas API C ++ e Python, al√©m da biblioteca OpenCV, todas as outras ferramentas n√£o est√£o dispon√≠veis.  Isso significa que, para ambas as estruturas, os modelos devem ser convertidos antecipadamente em uma m√°quina com o Ubuntu.  Minha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">demonstra√ß√£o de detec√ß√£o de rosto</a> funciona no Raspberry e na √°rea de trabalho, ent√£o acabei de adicionar os arquivos de rede neural convertidos ao meu reposit√≥rio GitHub para facilitar a sincroniza√ß√£o com o Raspberry.  Eu tenho um Raspberry Pi 2 modelo B, mas deve decolar com outros modelos. <br><br>  H√° outra sutileza em rela√ß√£o √† intera√ß√£o do Raspberry Pi e do Neural Compute Stick: se, no caso de um laptop, basta enfiar o NCS na porta USB 3.0 mais pr√≥xima, ent√£o para o Raspberry voc√™ precisar√° encontrar um cabo USB, caso contr√°rio, o NSC bloquear√° os tr√™s conectores USB restantes com seu corpo.  Tamb√©m vale lembrar que o Raspberry possui todas as vers√µes USB 2.0, portanto a taxa de infer√™ncia ser√° menor devido a atrasos na comunica√ß√£o (uma compara√ß√£o detalhada ser√° posterior).  Mas se voc√™ deseja conectar dois ou mais NCS ao Raspberry, provavelmente precisar√° encontrar um hub USB com energia adicional. <br><br><h3>  Como √© o c√≥digo do OpenVINO </h3><br>  Muito volumoso.  H√° muitas a√ß√µes diferentes a serem iniciadas, come√ßando com o carregamento do plug-in e terminando com a infer√™ncia - foi por isso que escrevi uma classe de inv√≥lucro para o detector.  O c√≥digo completo pode ser visualizado no GitHub, mas aqui apenas listo os pontos principais.  Vamos come√ßar em ordem: <br><br>  As defini√ß√µes de todas as fun√ß√µes que precisamos est√£o no arquivo <code>inference_engine.hpp</code> no espa√ßo para nome <code>InferenceEngine</code> . <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;inference_engine.hpp&gt; using namespace InferenceEngine;</span></span></span></span></code> </pre><br>  As seguintes vari√°veis ‚Äã‚Äãser√£o necess√°rias o tempo todo.  precisamos de <code>inputName</code> e <code>outputName</code> para endere√ßar a entrada e a sa√≠da da rede neural.  De um modo geral, uma rede neural pode ter muitas entradas e sa√≠das, mas em nossos detectores haver√° uma de cada vez.  A vari√°vel <code>net</code> √© a pr√≥pria rede, <code>request</code> √© um ponteiro para a √∫ltima solicita√ß√£o de infer√™ncia, <code>inputBlob</code> √© um ponteiro para a matriz de dados de entrada da rede neural.  As demais vari√°veis ‚Äã‚Äãfalam por si. <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">string</span></span> inputName; <span class="hljs-built_in"><span class="hljs-built_in">string</span></span> outputName; ExecutableNetwork net; InferRequest::Ptr request; Blob::Ptr inputBlob; <span class="hljs-comment"><span class="hljs-comment">//input shape int netInputWidth; int netInputHeight; int netInputChannels; //output shape int maxNumDetectedFaces; //return code StatusCode ncsCode;</span></span></code> </pre><br>  Agora fa√ßa o download do plug-in necess√°rio - precisamos do respons√°vel pelo NCS e NCS2, que pode ser obtido com o nome "MYRIAD".  Deixe-me lembr√°-lo que, no contexto do OpenVINO, um plug-in √© apenas uma biblioteca din√¢mica que se conecta por solicita√ß√£o expl√≠cita.  O par√¢metro da fun√ß√£o <code>PluginDispatcher</code> √© uma lista de diret√≥rios nos quais procurar plug-ins.  Se voc√™ configurar as vari√°veis ‚Äã‚Äãde ambiente de acordo com as instru√ß√µes, uma linha vazia ser√° suficiente.  Para refer√™ncia, os plugins est√£o em <code>[OpenVINO_install_dir]/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64/</code> <br><br><pre> <code class="cpp hljs">InferencePlugin plugin = PluginDispatcher({<span class="hljs-string"><span class="hljs-string">""</span></span>}).getPluginByDevice(<span class="hljs-string"><span class="hljs-string">"MYRIAD"</span></span>);</code> </pre><br>  Agora crie um objeto para carregar a rede neural, considere sua descri√ß√£o e defina o tamanho do lote (o n√∫mero de imagens processadas simultaneamente).  Uma rede neural no formato OpenVINO √© definida por dois arquivos: um .xml com uma descri√ß√£o da estrutura e um .bin com pesos.  Embora possamos usar detectores prontos do OpenVINO, mais tarde criaremos os nossos.  Aqui <code>std::string filename</code> √© o nome do arquivo sem a extens√£o.  Voc√™ tamb√©m precisa ter em mente que o NCS suporta apenas um tamanho de lote 1. <br><br><pre> <code class="cpp hljs">CNNNetReader netReader; netReader.ReadNetwork(filename+<span class="hljs-string"><span class="hljs-string">".xml"</span></span>); netReader.ReadWeights(filename+<span class="hljs-string"><span class="hljs-string">".bin"</span></span>); netReader.getNetwork().setBatchSize(<span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre><br>  Ent√£o acontece o seguinte: <br><br><ol><li>  Para entrar na rede neural, defina o tipo de dados como char n√£o assinado de 8 bits.  Isso significa que podemos inserir a imagem no formato em que ela vem da c√¢mera, e o InferenceEngine cuidar√° da convers√£o (o NCS realiza c√°lculos no formato float de 16 bits).  Isso ir√° acelerar um pouco no Raspberry Pi - pelo que entendi, a convers√£o √© feita no NCS, portanto, h√° menos atrasos na transfer√™ncia de dados via USB. </li><li>  N√≥s obtemos os nomes de entrada e sa√≠da, para que mais tarde possamos acess√°-los. </li><li>  N√≥s obtemos a descri√ß√£o das sa√≠das (este √© um mapa do nome da sa√≠da para um ponteiro para um bloco de dados).  Recebemos um ponteiro para o bloco de dados da primeira sa√≠da (√∫nica). </li><li>  Temos seu tamanho: 1 x 1 x n√∫mero m√°ximo de detec√ß√µes x comprimento da descri√ß√£o da detec√ß√£o (7).  Sobre o formato da descri√ß√£o das detec√ß√µes - mais tarde. </li><li>  Defina o formato de sa√≠da para flutuar 32 bits.  Novamente, a convers√£o do float 16 bits cuida do InferenceEngine. </li></ol><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//we can set input type to unsigned char: conversion will be performed on device netReader.getNetwork().getInputsInfo().begin()-&gt;second-&gt;setPrecision(Precision::U8); //get input and output names and their info structures inputName = netReader.getNetwork().getInputsInfo().begin()-&gt;first; outputName = netReader.getNetwork().getOutputsInfo().begin()-&gt;first; OutputsDataMap outputInfo(netReader.getNetwork().getOutputsInfo()); InputsDataMap inputInfo(netReader.getNetwork().getInputsInfo()); DataPtr &amp;outputData = (outputInfo.begin()-&gt;second); //get output shape: (1 x 1 x maxNumDetectedFaces x faceDescriptionLength(7)) const SizeVector outputDims = outputData-&gt;getTensorDesc().getDims(); maxNumDetectedFaces = outputDims[2]; //set input type to float32: calculations are all in float16, conversion is performed on device outputData-&gt;setPrecision(Precision::FP32);</span></span></code> </pre><br>  Agora, o ponto mais importante: carregamos a rede neural no plug-in (ou seja, no NCS).  Aparentemente, a compila√ß√£o para o formato desejado est√° em andamento.  Se o programa travar nessa fun√ß√£o, a rede neural provavelmente n√£o √© adequada para este dispositivo. <br><br><pre> <code class="cpp hljs">net = plugin.LoadNetwork(netReader.getNetwork(), {});</code> </pre><br>  E finalmente - faremos uma infer√™ncia experimental e obteremos os tamanhos de entrada (talvez isso possa ser feito de maneira mais elegante).  Primeiro, abrimos uma solicita√ß√£o de infer√™ncia, depois obtemos um link para o bloco de dados de entrada e j√° solicitamos o tamanho dele. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//perform single inference to get input shape (a hack) request = net.CreateInferRequestPtr(); //open inference request //we need the blob size: (batch(1) x channels(3) x H x W) inputBlob = request-&gt;GetBlob(inputName); SizeVector blobSize = inputBlob-&gt;getTensorDesc().getDims(); netInputWidth = blobSize[3]; netInputHeight = blobSize[2]; netInputChannels = blobSize[1]; request-&gt;Infer(); //close request</span></span></code> </pre><br>  Vamos tentar fazer upload de uma imagem para o NCS.  Da mesma forma, criamos uma solicita√ß√£o de infer√™ncia, obtemos um ponteiro para um bloco de dados e, a partir da√≠, obtemos um ponteiro para o pr√≥prio array.  Em seguida, basta copiar os dados da nossa imagem (aqui j√° est√° reduzido ao tamanho desejado).  Vale ressaltar que no <code>cv::Mat</code> e <code>inputBlob</code> medidas s√£o armazenadas em ordem diferente (no OpenCV, o √≠ndice do canal muda mais r√°pido que tudo, no OpenVINO √© mais lento que tudo), portanto, o memcpy n√£o √© suficiente.  Ent√£o come√ßamos a infer√™ncia ass√≠ncrona. <br><br>  Por que ass√≠ncrono?  Isso otimizar√° a aloca√ß√£o de recursos.  Enquanto o NCS considera a rede neural, voc√™ pode processar o pr√≥ximo quadro - isso levar√° a uma acelera√ß√£o percept√≠vel no Raspberry Pi. <br><br><pre> <code class="cpp hljs">cv::Mat data; ... <span class="hljs-comment"><span class="hljs-comment">//get image somehow //create request, get data blob request = net.CreateInferRequestPtr(); inputBlob = request-&gt;GetBlob(inputName); unsigned char* blobData = inputBlob-&gt;buffer().as&lt;unsigned char*&gt;(); //copy from resized frame to network input int wh = netInputHeight*netInputWidth; for (int c = 0; c &lt; netInputChannels; c++) for (int h = 0; h &lt; wh; h++) blobData[c * wh + h] = data.data[netInputChannels*h + c]; //start asynchronous inference request-&gt;StartAsync();</span></span></code> </pre><br>  Se voc√™ conhece bem as redes neurais, pode ter uma pergunta sobre em que ponto dimensionamos os valores dos pixels de entrada da rede neural (por exemplo, trazemos para o intervalo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mo" id="MJXp-Span-2" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[ </font></font></span><span class="MJXp-mn" id="MJXp-Span-3"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0 </font></font></span><span class="MJXp-mo" id="MJXp-Span-4" style="margin-left: 0em; margin-right: 0.222em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font></span><span class="MJXp-mn" id="MJXp-Span-5"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 </font></font></span><span class="MJXp-mo" id="MJXp-Span-6" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">]</font></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1"> [0,1] </script>  )  O fato √© que, nos modelos OpenVINO, essa transforma√ß√£o j√° est√° inclu√≠da na descri√ß√£o da rede neural e, ao usar nosso detector, faremos algo semelhante.  E como a convers√£o em float e a escala de entradas s√£o realizadas pelo OpenVINO, precisamos redimensionar a imagem. <br><br>  Agora (depois de fazer algum trabalho √∫til), concluiremos o pedido de infer√™ncia.  O programa √© bloqueado at√© que os resultados da execu√ß√£o cheguem.  Temos um ponteiro para o resultado. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> * output; ncsCode = request-&gt;Wait(IInferRequest::WaitMode::RESULT_READY); output = request-&gt;GetBlob(outputName)-&gt;buffer().as&lt;<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*&gt;();</code> </pre><br>  Agora √© hora de pensar em que formato o NCS retorna o resultado do detector.  Vale ressaltar que o formato √© um pouco diferente do que era ao usar o NCSDK.  De um modo geral, a sa√≠da do detector √© quadridimensional e possui uma dimens√£o (1 x 1 x n√∫mero m√°ximo de detec√ß√µes x 7), podemos assumir que essa √© uma matriz de tamanho ( <code>maxNumDetectedFaces</code> x 7). <br><br>  O par√¢metro <code>maxNumDetectedFaces</code> √© definido na descri√ß√£o da rede neural e √© f√°cil alter√°-lo, por exemplo, na descri√ß√£o .prototxt da rede no formato Caffe.  Anteriormente, obtivemos o objeto que representa o detector.  Este par√¢metro est√° relacionado √†s especificidades da classe de detectores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SSD (Single Shot Detector)</a> , que inclui todos os detectores NCS suportados.  Um SSD sempre considera o mesmo n√∫mero (e muito grande) de caixas delimitadoras para cada imagem e, depois de filtrar as detec√ß√µes com uma classifica√ß√£o de confian√ßa baixa e remover os quadros sobrepostos usando a supress√£o n√£o m√°xima, eles geralmente deixam os 100-200 melhores.  √â exatamente por isso que o par√¢metro √© respons√°vel. <br><br>  Os sete valores na descri√ß√£o de uma detec√ß√£o s√£o os seguintes: <br><br><ol><li>  o n√∫mero da imagem no lote em que o objeto √© detectado (no nosso caso, deve ser zero); </li><li>  classe de objeto (0 - segundo plano, a partir de 1 - outras classes, somente as detec√ß√µes com uma classe positiva s√£o retornadas); </li><li>  confian√ßa na presen√ßa de detec√ß√£o (no intervalo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-7"><span class="MJXp-mo" id="MJXp-Span-8" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[ </font></font></span><span class="MJXp-mn" id="MJXp-Span-9"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0 </font></font></span><span class="MJXp-mo" id="MJXp-Span-10" style="margin-left: 0em; margin-right: 0.222em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font></span><span class="MJXp-mn" id="MJXp-Span-11"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 </font></font></span><span class="MJXp-mo" id="MJXp-Span-12" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">]</font></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-2"> [0,1] </script>  ); </li><li>  coordenada x normalizada do canto superior esquerdo da caixa delimitadora (no intervalo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-13"><span class="MJXp-mo" id="MJXp-Span-14" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[ </font></font></span><span class="MJXp-mn" id="MJXp-Span-15"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0 </font></font></span><span class="MJXp-mo" id="MJXp-Span-16" style="margin-left: 0em; margin-right: 0.222em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font></span><span class="MJXp-mn" id="MJXp-Span-17"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 </font></font></span><span class="MJXp-mo" id="MJXp-Span-18" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">]</font></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-3"> [0,1] </script>  ); </li><li>  da mesma forma - coordenada y; </li><li>  largura normalizada da caixa delimitadora (no intervalo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-19"><span class="MJXp-mo" id="MJXp-Span-20" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">[ </font></font></span><span class="MJXp-mn" id="MJXp-Span-21"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0 </font></font></span><span class="MJXp-mo" id="MJXp-Span-22" style="margin-left: 0em; margin-right: 0.222em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">, </font></font></span><span class="MJXp-mn" id="MJXp-Span-23"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 </font></font></span><span class="MJXp-mo" id="MJXp-Span-24" style="margin-left: 0em; margin-right: 0em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">]</font></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh2lWnXQhNMTNRjcusAGAwfL-Pu-A#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-4"> [0,1] </script>  ); </li><li>  da mesma forma - altura; </li></ol><br><div class="spoiler">  <b class="spoiler_title">C√≥digo para extrair caixas delimitadoras da sa√≠da do detector</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_detection_boxes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">* predictions, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> numPred, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> w, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> h, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> thresh, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">&gt;&amp; probs, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;cv::Rect&gt;&amp; boxes)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> score = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> cls = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> id = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//predictions holds numPred*7 values //data format: image_id, detection_class, detection_confidence, //box_normed_x, box_normed_y, box_normed_w, box_normed_h for (int i=0; i&lt;numPred; i++) { score = predictions[i*7+2]; cls = predictions[i*7+1]; id = predictions[i*7 ]; if (id&gt;=0 &amp;&amp; score&gt;thresh &amp;&amp; cls&lt;=1) { probs.push_back(score); boxes.push_back(Rect(predictions[i*7+3]*w, predictions[i*7+4]*h, (predictions[i*7+5]-predictions[i*7+3])*w, (predictions[i*7+6]-predictions[i*7+4])*h)); } } }</span></span></code> </pre><br>  aprendemos <code>numPred</code> partir do pr√≥prio detector <code>w,h</code> - tamanhos de imagem para visualiza√ß√£o. <br></div></div><br>  Agora, sobre como √© o esquema geral de infer√™ncia em tempo real.  Primeiro, inicializamos a rede neural e a c√¢mera, iniciamos <code>cv::Mat</code> para quadros brutos e mais um para quadros reduzidos ao tamanho desejado.  Enchemos nossos quadros com zeros - isso aumentar√° a confian√ßa de que, em um √∫nico come√ßo, a rede neural n√£o encontrar√° nada.  Ent√£o come√ßamos o ciclo de infer√™ncia: <br><br><ul><li>  Carregamos o quadro atual na rede neural usando uma solicita√ß√£o ass√≠ncrona - o NCS j√° come√ßou a funcionar e, neste momento, temos a oportunidade de tornar o trabalho principal √∫til no processador principal. </li><li>  Exibimos todas as detec√ß√µes anteriores no quadro anterior, desenhamos um quadro (se necess√°rio). </li><li>  Obtemos um novo quadro da c√¢mera, compactamos no tamanho desejado.  Para o Raspberry, recomendo usar o algoritmo de redimensionamento mais simples - no OpenCV, essa √© a interpola√ß√£o de vizinhos mais pr√≥ximos.  Isso n√£o afetar√° a qualidade do desempenho do detector, mas pode adicionar um pouco de velocidade.  Tamb√©m espelho o quadro para facilitar a visualiza√ß√£o (opcional). </li><li>  Agora √© a hora de obter o resultado com o NCS, preenchendo a solicita√ß√£o de infer√™ncia.  O programa ser√° bloqueado at√© que o resultado seja recebido. </li><li>  Processamos novas detec√ß√µes, selecionamos quadros. </li><li>  O resto: exercitar as teclas digitadas, contar quadros, etc. </li></ul><br><h3>  Como compil√°-lo </h3><br>  Nos exemplos do InferenceEngine, eu n√£o gostei dos arquivos CMake volumosos e decidi reescrever tudo no meu Makefile: <br><br><pre> <code class="bash hljs">g++ $(RPI_ARCH) \ -I/usr/include -I. \ -I$(OPENVINO_PATH)/deployment_tools/inference_engine/include \ -I$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/include \ -L/usr/lib/x86_64-linux-gnu \ -L/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/lib \ -L$(OPENVINO_PATH)/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64 \ -L$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/lib/raspbian_9/armv7l \ vino.cpp wrapper/vino_wrapper.cpp \ -o demo -std=c++11 \ `pkg-config opencv --cflags --libs` \ -ldl -linference_engine $(RPI_LIBS)</code> </pre><br>  Essa equipe trabalhar√° no Ubuntu e Raspbian, gra√ßas a alguns truques.  Os caminhos para procurar cabe√ßalhos e bibliotecas din√¢micas que eu indiquei para o Raspberry e a m√°quina Ubuntu.  Das bibliotecas, al√©m do OpenCV, voc√™ tamb√©m deve conectar o <code>libinference_engine</code> e o <code>libdl</code> - uma biblioteca para vincular dinamicamente outras bibliotecas, √© necess√°rio para carregar o plug-in.  Ao mesmo tempo, o pr√≥prio <code>libmyriadPlugin</code> n√£o precisa ser especificado.  Entre outras coisas, para o Raspberry, tamb√©m conecto a biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Raspicam</a> para trabalhar com a c√¢mera (este √© <code>$(RPI_LIBS)</code> ).  Eu tamb√©m tive que usar o padr√£o C ++ 11. <br><br>  Separadamente, √© importante notar que, ao compilar no Raspberry, o <code>-march=armv7-a</code> √© necess√°rio (este √© <code>$(RPI_ARCH)</code> ).  Se voc√™ n√£o o especificar, o programa ser√° compilado, mas falhar√° com um segfault silencioso.  Voc√™ tamb√©m pode adicionar otimiza√ß√µes usando <code>-O3</code> , isso aumentar√° a velocidade. <br><br><h3>  Quais s√£o os detectores </h3><br>  O NCS suporta apenas detectores Caffe SSD da caixa, embora com alguns truques sujos eu consegui executar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">YOLO do formato Darknet</a> nele.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O Single Shot Detector (SSD)</a> √© uma arquitetura popular entre redes neurais leves e, com a ajuda de diferentes codificadores (ou redes de backbone), voc√™ pode variar de forma flex√≠vel a propor√ß√£o de velocidade e qualidade. <br><br>  Vou experimentar com diferentes detectores de rosto: <br><br><ul><li>  YOLO, retirado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> , convertido primeiro para o formato Caffe, depois para o formato NCS (somente com NCSDK).  Imagem 448 x 448. </li><li>  Meu detector <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Mobilenet</a> + SSD, sobre o treinamento sobre o qual falei em uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publica√ß√£o anterior</a> .  Ainda tenho uma vers√£o recortada desse detector, que v√™ apenas rostos pequenos e, ao mesmo tempo, um pouco mais r√°pido.  Vou verificar a vers√£o completa do meu detector no NCSDK e no OpenVINO.  Imagem 300 x 300. </li><li>  Detector de detec√ß√£o de rosto adas-0001 do OpenVINO: MobileNet + SSD.  Imagem 384 x 672. </li><li>  Detector OpenVINO de detec√ß√£o de rosto-varejo-0004: leve <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SqueezeNet</a> + SSD.  Imagem 300 x 300. </li></ul><br>  Para detectores do OpenVINO, n√£o h√° escalas no formato Caffe ou no formato NCSDK, portanto, s√≥ posso inici√°-las no OpenVINO. <br><br><h3>  Transforme seu detector em formato OpenVINO </h3><br>  Eu tenho dois arquivos no formato Caffe: .prototxt com uma descri√ß√£o da rede e .caffemodel com pesos.  Preciso obter dois arquivos deles no formato OpenVINO: .xml e .bin com uma descri√ß√£o e pesos, respectivamente.  Para fazer isso, use o script mo.py do OpenVINO (tamb√©m conhecido como Model Optimizer): <br><br><pre> <code class="bash hljs">mo.py \ --framework caffe \ --input_proto models/face/ssd-face.prototxt \ --input_model models/face/ssd-face.caffemodel \ --output_dir models/face \ --model_name ssd-vino-custom \ --mean_values [127.5,127.5,127.5] \ --scale_values [127.5,127.5,127.5] \ --data_type FP16</code> </pre><br>  <code>output_dir</code> especifica o diret√≥rio em que novos arquivos ser√£o criados, <code>model_name</code> √© o nome para novos arquivos sem extens√£o, <code>data_type (FP16/FP32)</code> √© o tipo de saldo na rede neural (o NCS suporta apenas FP16).  Os <code>mean_values, scale_values</code> definem a m√©dia e a escala para pr√©-processar as imagens antes de serem lan√ßadas na rede neural.  A convers√£o espec√≠fica √© assim: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-25"><span class="MJXp-mo" id="MJXp-Span-26" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-29">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-30">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31">l</span><span class="MJXp-msubsup" id="MJXp-Span-32"><span class="MJXp-mtext" id="MJXp-Span-33" style="margin-right: 0.05em;">&nbsp;</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-34" style="vertical-align: -0.4em;">v</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-39">s</span><span class="MJXp-mo" id="MJXp-Span-40" style="margin-left: 0em; margin-right: 0.222em;">‚Äã</span><span class="MJXp-mo" id="MJXp-Span-41" style="margin-left: 0em; margin-right: 0.222em;">‚Äã</span><span class="MJXp-mo" id="MJXp-Span-42" style="margin-left: 0.267em; margin-right: 0.267em;">‚àí</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-43">m</span><span class="MJXp-mrow" id="MJXp-Span-44"><span class="MJXp-mo" id="MJXp-Span-45" style="margin-left: 0em; margin-right: 0em;">√©</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-46">d</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-47">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">a</span><span class="MJXp-msubsup" id="MJXp-Span-49"><span class="MJXp-mtext" id="MJXp-Span-50" style="margin-right: 0.05em;">&nbsp;</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-51" style="vertical-align: -0.4em;">v</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-52">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-53">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56">s</span><span class="MJXp-mo" id="MJXp-Span-57" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mrow" id="MJXp-Span-58"><span class="MJXp-mo" id="MJXp-Span-59" style="margin-left: 0.111em; margin-right: 0.111em;">/</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-60">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-61">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-63">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-64">e</span><span class="MJXp-msubsup" id="MJXp-Span-65"><span class="MJXp-mtext" id="MJXp-Span-66" style="margin-right: 0.05em;">&nbsp;</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-67" style="vertical-align: -0.4em;">v</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-68">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-69">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-71">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-72">s</span><span class="MJXp-mo" id="MJXp-Span-73" style="margin-left: 0em; margin-right: 0.222em;">‚Äã</span><span class="MJXp-mo" id="MJXp-Span-74" style="margin-left: 0em; margin-right: 0.222em;">‚Äã</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-5"> (pixel \ _values ‚Äã‚Äã- m√©dia \ _values) / scale \ _values ‚Äã‚Äã</script></p><br><br>  Nesse caso, os valores s√£o convertidos do intervalo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-75"><span class="MJXp-mo" id="MJXp-Span-76" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mn" id="MJXp-Span-77">0</span><span class="MJXp-mo" id="MJXp-Span-78" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-79">255</span><span class="MJXp-mo" id="MJXp-Span-80" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-6"> [0,255] </script>  no intervalo <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-81"><span class="MJXp-mo" id="MJXp-Span-82" style="margin-left: 0em; margin-right: 0em;">[</span><span class="MJXp-mn" id="MJXp-Span-83">0</span><span class="MJXp-mo" id="MJXp-Span-84" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-85">1</span><span class="MJXp-mo" id="MJXp-Span-86" style="margin-left: 0em; margin-right: 0em;">]</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-7"> [0,1] </script>  .  Em geral, esse script possui muitos par√¢metros, alguns dos quais s√£o espec√≠ficos para estruturas individuais. Recomendamos que voc√™ consulte o manual do script. <br><br>  A distribui√ß√£o OpenVINO para Raspberry n√£o possui modelos prontos, mas eles s√£o bastante simples de baixar. <br><br><div class="spoiler">  <b class="spoiler_title">Por exemplo, assim.</b> <div class="spoiler_text"><pre> <code class="bash hljs"> wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.xml \ -O ./models/face/vino.xml; \ wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.bin \ -O ./models/face/vino.bin</code> </pre><br></div></div><br><h3>  Compara√ß√£o de detectores e estruturas </h3><br>  Usei tr√™s op√ß√µes de compara√ß√£o: 1) NCS + M√°quina Virtual com Ubuntu 16.04, processador Core i7, conector USB 3.0;  2) NCS + A mesma m√°quina, conector USB 3.0 + cabo USB 2.0 (haver√° mais atraso na troca com o dispositivo);  3) NCS + Raspberry Pi 2 modelo B, Raspbian Stretch, conector USB 2.0 + cabo USB 2.0. <br><br>  Iniciei meu detector com o OpenVINO e o NCSDK2, detectores do OpenVINO apenas com sua estrutura nativa, YOLO apenas com o NCSDK2 (provavelmente, ele tamb√©m pode ser executado no OpenVINO). <br><br>  A tabela FPS para diferentes detectores √© semelhante a esta (os n√∫meros s√£o aproximados): <br><br><table><tbody><tr><th>  Modelo </th><th>  USB 3.0 </th><th>  USB 2.0 </th><th>  Raspberry pi </th></tr><tr><td>  SSD personalizado com NCSDK2 </td><td>  10,8 </td><td>  9,3 </td><td>  7.2 </td></tr><tr><td>  SSD de longo alcance personalizado com NCSDK2 </td><td>  11,8 </td><td>  10.0 </td><td>  7.3 </td></tr><tr><td>  YOLO v2 com NCSDK2 </td><td>  5.3 </td><td>  4.6 </td><td>  3.6. </td></tr><tr><td>  SSD personalizado com OpenVINO </td><td>  10,6 </td><td>  9,9 </td><td>  7,9 </td></tr><tr><td>  OpenVINO detec√ß√£o de rosto-varejo-0004 </td><td>  15,6 </td><td>  14,2 </td><td>  9,3 </td></tr><tr><td>  Detec√ß√£o de rosto OpenVINO-adas-0001 </td><td>  5,8 </td><td>  5.5 </td><td>  3.9 </td></tr></tbody></table><br><br>  <em>Nota: o desempenho foi medido para todo o programa de demonstra√ß√£o, incluindo processamento e visualiza√ß√£o de quadros.</em> <br><br>  YOLO foi o mais lento e mais inst√°vel de todos.  Frequentemente ignora a detec√ß√£o e n√£o pode funcionar com quadros iluminados. <br><br>  O detector que eu treinei funciona duas vezes mais r√°pido, √© mais resistente √† distor√ß√£o nos quadros e at√© detecta rostos pequenos.  No entanto, √†s vezes ainda ignora a detec√ß√£o e, √†s vezes, detecta falsos.  Se voc√™ cortar as √∫ltimas camadas, ela se tornar√° um pouco mais r√°pida, mas deixar√° de ver rostos grandes.  O mesmo detector lan√ßado pelo OpenVINO se torna um pouco mais r√°pido ao usar o USB 2.0, a qualidade n√£o muda visualmente. <br><br>  Os detectores OpenVINO, √© claro, s√£o muito superiores ao YOLO e ao meu detector.  (Eu nem come√ßaria a treinar meu detector se o OpenVINO existisse na sua forma atual naquele momento).  O modelo retail-0004 √© muito mais r√°pido e quase nunca erra o rosto, mas consegui engan√°-lo um pouco (embora a confian√ßa nessas detec√ß√µes seja baixa): <br><br><img src="https://habrastorage.org/webt/uj/ap/nl/ujapnlbjzkipljlzklgyvjzked4.png"><br>  <em>Ataque competitivo da intelig√™ncia natural contra artificial</em> <br><br>  O detector adas-0001 √© muito mais lento, mas funciona com imagens grandes e deve ser mais preciso.  N√£o percebi a diferen√ßa, mas verifiquei quadros bastante simples. <br><br><h4>  Conclus√£o </h4><br>  Em geral, √© muito bom que, em um dispositivo de baixa energia como o Raspberry Pi, voc√™ possa usar redes neurais e at√© em tempo quase real.  O OpenVINO fornece uma funcionalidade muito extensa para a infer√™ncia de redes neurais em muitos dispositivos diferentes - muito mais ampla do que eu descrevi no artigo.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Acho que o Neural Compute Stick e o OpenVINO ser√£o muito √∫teis na minha pesquisa rob√≥tica. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt436744/">https://habr.com/ru/post/pt436744/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt436720/index.html">Existe uma opini√£o: o IPv6 falhou - quem pensa assim e por qu√™</a></li>
<li><a href="../pt436724/index.html">Criando produtos formadores de h√°bitos</a></li>
<li><a href="../pt436726/index.html">Usu√°rios relatam perda de bitcoins como resultado de invas√£o inteligente das carteiras da Electrum</a></li>
<li><a href="../pt436740/index.html">Pr√≥pria pesquisa, o que as fontes abertas podem nos dizer?</a></li>
<li><a href="../pt436742/index.html">Rob√≥tica Android at√© 2019: a hist√≥ria real; em 5 partes; parte 1</a></li>
<li><a href="../pt436746/index.html">Como degradar o desempenho melhorando-o</a></li>
<li><a href="../pt436748/index.html">Desenvolvendo hexapod a partir do zero (parte 3) - cinem√°tica</a></li>
<li><a href="../pt436750/index.html">An√°lise de tend√™ncias do YouTube russo para 2018</a></li>
<li><a href="../pt436752/index.html">O bolo √© uma mentira</a></li>
<li><a href="../pt436754/index.html">Q2VKPT: Quake II totalmente reescrito com ilumina√ß√£o realista</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
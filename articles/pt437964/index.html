<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßúüèª ‚öôÔ∏è üñï Livro "Aprendizado de m√°quina e fluxo de tens√£o" üèáüèΩ üçª ü§°</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O conhecimento do aprendizado de m√°quina e a biblioteca TensorFlow √© semelhante √†s primeiras li√ß√µes de uma escola de condu√ß√£o, quando voc√™ sofre de es...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Livro "Aprendizado de m√°quina e fluxo de tens√£o"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/437964/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/webt/cy/lg/n3/cylgn38lpjyhq7gveb9cmmt_ml8.jpeg" align="left" alt="imagem"></a>  O conhecimento do aprendizado de m√°quina e a biblioteca TensorFlow √© semelhante √†s primeiras li√ß√µes de uma escola de condu√ß√£o, quando voc√™ sofre de estacionamento paralelo, tenta mudar de marcha no momento certo e n√£o mistura os espelhos, lembrando freneticamente a sequ√™ncia de a√ß√µes, enquanto seu p√© treme nervosamente nos pedais de acelera√ß√£o.  Este √© um exerc√≠cio dif√≠cil, mas necess√°rio.  Assim, no aprendizado de m√°quina: antes de usar sistemas modernos de reconhecimento de face ou algoritmos de previs√£o no mercado de a√ß√µes, voc√™ ter√° que lidar com as ferramentas apropriadas e um conjunto de instru√ß√µes para criar seus pr√≥prios sistemas sem problemas. <br><br>  Os iniciantes no aprendizado de m√°quina apreciar√£o a orienta√ß√£o aplicada deste livro, porque seu objetivo √© apresentar o b√°sico e, em seguida, resolver rapidamente os problemas reais.  A partir de uma revis√£o dos conceitos e princ√≠pios de aprendizado de m√°quina do trabalho com o TensorFlow, voc√™ passar√° para algoritmos b√°sicos, estudar√° redes neurais e poder√° resolver independentemente os problemas de classifica√ß√£o, agrupamento, regress√£o e previs√£o. <br><a name="habracut"></a><br><h3>  Trecho.  Redes neurais convolucionais </h3><br>  Fazer compras nas lojas ap√≥s um dia cansativo √© uma tarefa muito onerosa.  Meus olhos s√£o atacados por muita informa√ß√£o.  Vendas, cupons, uma variedade de cores, crian√ßas pequenas, luzes tremeluzentes e corredores cheios de pessoas - esses s√£o apenas alguns exemplos de todos os sinais enviados ao c√≥rtex visual do c√©rebro, independentemente de eu querer ou n√£o prestar aten√ß√£o a ele.  O sistema visual absorve uma abund√¢ncia de informa√ß√µes. <br><br>  Certamente voc√™ conhece a frase "√© melhor ver uma vez do que ouvir cem vezes".  Isso pode ser verdade para voc√™ e para mim (ou seja, para as pessoas), mas a m√°quina pode encontrar significado nas imagens?  Nossos fotorreceptores visuais selecionam comprimentos de onda da luz, mas essas informa√ß√µes, aparentemente, n√£o se estendem √† nossa consci√™ncia.  No final, n√£o sei dizer exatamente quais comprimentos de onda da luz estou observando.  Da mesma forma, a c√¢mera recebe pixels da imagem.  Mas, em vez disso, queremos receber algo de n√≠vel superior, por exemplo, nomes ou posi√ß√µes de objetos.  Como obtemos informa√ß√µes percebidas em n√≠vel humano a partir de pixels? <br><br>  Para obter um certo significado dos dados de origem, ser√° necess√°rio projetar um modelo de rede neural.  Nos cap√≠tulos anteriores, v√°rios tipos de modelos de redes neurais foram introduzidos, como modelos totalmente conectados (cap√≠tulo 8) e codificadores autom√°ticos (cap√≠tulo 7).  Neste cap√≠tulo, apresentaremos outro tipo de modelo chamado rede neural convolucional (CNN).  Este modelo funciona muito bem com imagens e outros dados sensoriais, como som.  Por exemplo, o modelo CNN pode classificar com seguran√ßa qual objeto √© exibido na imagem. <br><br>  O modelo da CNN, que ser√° discutido neste cap√≠tulo, ser√° treinado para classificar imagens em uma das 10 categorias poss√≠veis.  Nesse caso, "uma imagem √© melhor do que apenas uma palavra", pois temos apenas 10 op√ß√µes poss√≠veis.  Este √© um pequeno passo em dire√ß√£o √† percep√ß√£o no n√≠vel humano, mas temos que come√ßar com algo, certo? <br><br><h3>  9.1  Desvantagens das redes neurais </h3><br>  O aprendizado de m√°quina √© uma eterna luta pelo desenvolvimento de um modelo que tenha expressividade suficiente para apresentar dados, mas, ao mesmo tempo, n√£o seja t√£o universal que se refira aos padr√µes de reciclagem e memoriza√ß√£o.  As redes neurais s√£o oferecidas como uma maneira de aumentar a expressividade;  embora, como voc√™ possa imaginar, eles sofram muito com as armadilhas da reciclagem. <br><br><blockquote>  OBSERVA√á√ÉO O novo treinamento ocorre quando um modelo treinado √© excepcionalmente preciso em um conjunto de dados de treinamento e incorreto em um conjunto de dados de valida√ß√£o.  Esse modelo √© provavelmente universal demais para a pequena quantidade de dados dispon√≠veis e, no final, apenas lembra os dados de treinamento. </blockquote><br>  Para comparar a versatilidade dos dois modelos de aprendizado de m√°quina, voc√™ pode usar um algoritmo heur√≠stico r√°pido e bruto para calcular o n√∫mero de par√¢metros que precisam ser determinados como resultado do treinamento.  Como mostrado na fig.  9.1, uma rede neural totalmente conectada que obt√©m uma imagem de 256 √ó 256 e a mapeia em uma camada de 10 neur√¥nios ter√° 256 √ó 256 √ó 10 = 655.360 par√¢metros!  Compare-o com um modelo que cont√©m apenas cinco par√¢metros.  Pode-se supor que uma rede neural totalmente conectada possa apresentar dados mais complexos que um modelo de cinco par√¢metros. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_c/ey/qe/_ceyqe8jc1s-xzasfzbv4vezhum.png" alt="imagem"></div><br>  A pr√≥xima se√ß√£o discute redes neurais convolucionais, que s√£o uma maneira razo√°vel de reduzir o n√∫mero de par√¢metros.  Em vez de lidar com redes totalmente conectadas, a CNN reutiliza os mesmos par√¢metros repetidamente. <br><br><h3>  9.2  Redes neurais convolucionais </h3><br>  A principal id√©ia subjacente √†s redes neurais convolucionais √© que a compreens√£o local da imagem √© suficiente.  A vantagem pr√°tica das redes neurais convolucionais √© que, com v√°rios par√¢metros, √© poss√≠vel reduzir significativamente o tempo de treinamento, bem como a quantidade de dados necess√°rios para treinar o modelo. <br><br>  Em vez de redes totalmente conectadas com pesos de cada pixel, a CNN possui um n√∫mero suficiente de pesos necess√°rios para visualizar um pequeno fragmento da imagem.  √â como ler um livro com uma lupa: no final, voc√™ l√™ a p√°gina inteira, mas, a qualquer momento, olha apenas para um pequeno fragmento. <br><br>  Imagine uma imagem de 256 √ó 256. Em vez de usar o c√≥digo TensorFlow que processa a imagem inteira de uma s√≥ vez, voc√™ pode digitalizar o fragmento da imagem por fragmento, por exemplo, uma janela 5 √ó 5. Uma janela 5 √ó 5 desliza sobre a imagem (geralmente da esquerda para a direita e de cima para baixo), como mostrado na fig.  9.2  A rapidez com que desliza √© chamada de comprimento da passada.  Por exemplo, um comprimento de etapa 2 significa que uma janela deslizante 5 √ó 5 move 2 pixels por vez at√© que toda a imagem tenha passado.  No TensorFlow, como ser√° mostrado em breve, voc√™ pode ajustar o comprimento da etapa e o tamanho da janela usando a biblioteca de fun√ß√µes incorporada. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tl/lj/br/tlljbr-3r61p02umh30yi-wtmhi.png" alt="imagem"></div><br>  Essa janela 5 √ó 5 possui uma matriz de peso 5 √ó 5 associada a ela. <br><br><blockquote>  DEFINI√á√ÉO Uma convolu√ß√£o √© um somat√≥rio ponderado dos valores de intensidade de pixels em uma imagem √† medida que a janela passa por toda a imagem.  Acontece que esse processo de convolu√ß√£o da imagem com a matriz de pesos cria outra imagem (do mesmo tamanho, que depende da dobra).  Coagula√ß√£o √© o processo de aplica√ß√£o da convolu√ß√£o. </blockquote><br>  Todas as manipula√ß√µes da janela deslizante ocorrem na camada convolucional da rede neural.  Uma rede neural convolucional t√≠pica tem v√°rias camadas convolucionais.  Cada camada convolucional geralmente cria muitas convolu√ß√µes adicionais; portanto, a matriz de pondera√ß√£o √© um tensor 5 √ó 5 √ó n, onde n √© o n√∫mero de convolu√ß√µes. <br><br>  Como exemplo, deixe a imagem passar por uma camada convolucional com uma matriz de peso de dimens√µes 5 √ó 5 √ó 64. Isso cria 64 convolu√ß√µes com uma janela deslizante 5 √ó 5. Portanto, o modelo correspondente possui 5 √ó 5 √ó 64 = 1600 par√¢metros, o que √© significativamente menor que o n√∫mero de par√¢metros de uma rede totalmente conectada : 256 √ó 256 = 65.536. <br><br>  A atratividade das redes neurais convolucionais (CNNs) √© que o n√∫mero de par√¢metros usados ‚Äã‚Äãpelo modelo n√£o depende do tamanho da imagem original.  Voc√™ pode executar a mesma rede neural convolucional em imagens 300 √ó 300, e o n√∫mero de par√¢metros na camada convolucional n√£o ser√° alterado! <br><br><h3>  9.3  Prepara√ß√£o da imagem </h3><br>  Antes de come√ßar a usar o modelo CNN com o TensorFlow, prepare algumas imagens.  As listagens nesta se√ß√£o ajudar√£o voc√™ a configurar um conjunto de dados de treinamento para o restante do cap√≠tulo. <br><br>  Primeiro, fa√ßa o download do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dados</a> CIFAR-10 em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.cs.toronto.edu/~kriz/cifar-10-</a> python.tar.gz.  Este conjunto cont√©m 60.000 imagens distribu√≠das uniformemente em 10 categorias, o que √© um recurso bastante grande para tarefas de classifica√ß√£o.  Em seguida, o arquivo de imagem deve ser colocado no diret√≥rio de trabalho.  Na fig.  A Figura 9.3 mostra exemplos de imagens desse conjunto de dados. <br><br>  N√≥s j√° usamos o conjunto de dados CIFAR-10 no cap√≠tulo anterior sobre codificadores autom√°ticos e agora analisamos esse c√≥digo novamente.  A lista a seguir √© retirada diretamente da documenta√ß√£o do CIFAR-10, localizada em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.cs.toronto.edu/~kriz/cifar.html</a> .  Coloque o c√≥digo no arquivo cifar_tools.py. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xs/rd/6n/xsrd6nmuunpim-aeqepzxwj1acy.png" alt="imagem"></div><br>  Listagem 9.1.  Carregando imagens de um arquivo CIFAR-10 em Python <br><br><pre><code class="plaintext hljs">import pickle def unpickle(file): fo = open(file, 'rb') dict = pickle.load(fo, encoding='latin1') fo.close() return dict</code> </pre> <br>  As redes neurais s√£o propensas a reciclagem, por isso √© importante fazer todo o poss√≠vel para minimizar esse erro.  Para fazer isso, n√£o se esque√ßa de limpar os dados antes de process√°-los. <br><br>  A limpeza de dados √© o principal processo do pipeline de aprendizado de m√°quina.  O c√≥digo na Listagem 9.2 usa as tr√™s etapas a seguir para limpar um conjunto de imagens: <br><br>  1. Se voc√™ tiver uma imagem em cores, tente convert√™-la em tons de cinza para reduzir a dimensionalidade dos dados de entrada e, portanto, reduzir o n√∫mero de par√¢metros. <br><br>  2. Pense em cortar a imagem no centro, porque as bordas da imagem n√£o fornecem nenhuma informa√ß√£o √∫til. <br><br>  3. Normalize a entrada subtraindo a m√©dia e dividindo pelo desvio padr√£o de cada amostra de dados, para que os gradientes n√£o mudem muito acentuadamente durante a propaga√ß√£o de retorno. <br><br>  A lista a seguir mostra como limpar um conjunto de dados usando esses m√©todos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ba/nf/al/banfal_9g-9gy2lns0q_qv2qce8.png" alt="imagem"></div><br>  Salve todas as imagens do conjunto de dados CIFAR-10 e execute a fun√ß√£o de limpeza.  A listagem a seguir define um m√©todo conveniente para ler, limpar e estruturar dados para uso no TensorFlow.  L√°, voc√™ deve incluir o c√≥digo do arquivo cifar_tools.py. <br><br>  Listagem 9.3.  Pr√©-processamento de todos os arquivos CIFAR-10 <br><br><pre> <code class="plaintext hljs">def read_data(directory): names = unpickle('{}/batches.meta'.format(directory))['label_names'] print('names', names) data, labels = [], [] for i in range(1, 6): filename = '{}/data_batch_{}'.format(directory, i) batch_data = unpickle(filename) if len(data) &gt; 0: data = np.vstack((data, batch_data['data'])) labels = np.hstack((labels, batch_data['labels'])) else: data = batch_data['data'] labels = batch_data['labels'] print(np.shape(data), np.shape(labels)) data = clean(data) data = data.astype(np.float32) return names, data, labels</code> </pre> <br>  No arquivo using_cifar.py, voc√™ pode usar o m√©todo importando cifar_tools para isso.  As listas 9.4 e 9.5 mostram como buscar v√°rias imagens de um conjunto de dados e visualiz√°-las. <br><br>  Listagem 9.4.  Usando a fun√ß√£o auxiliar cifar_tools <br><br><pre> <code class="plaintext hljs">import cifar_tools names, data, labels = \ cifar_tools.read_data('your/location/to/cifar-10-batches-py')</code> </pre> <br>  Voc√™ pode selecionar arbitrariamente v√°rias imagens e desenh√°-las de acordo com o r√≥tulo.  A lista a seguir faz exatamente isso, para que voc√™ possa entender melhor o tipo de dados com o qual estar√° lidando. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9s/3c/ls/9s3clsibt-fy4tqxlnmggitpydm.png" alt="imagem"></div><br>  Ao executar esse c√≥digo, voc√™ criar√° o arquivo cifar_examples.png, que ser√° semelhante √† Fig.  9.3 <br><br>  ¬ªMais informa√ß√µes sobre o livro podem ser encontradas no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">site do editor</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Conte√∫do</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Trecho</a> <br><br>  Cupom de desconto de 20% para vendedores ambulantes - <b>Machine Learning</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt437964/">https://habr.com/ru/post/pt437964/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt437952/index.html">Como testar no AutoCar: MindMap, an√°lise de c√≥digo est√°tico e MockServer</a></li>
<li><a href="../pt437956/index.html">"Implementando o Splunk 7" - o primeiro livro do Splunk em russo</a></li>
<li><a href="../pt437958/index.html">Autoriza√ß√£o na ESIA em um servidor de terminal com assinatura digital de acordo com GOST-2012</a></li>
<li><a href="../pt437960/index.html">Conselho do diretor t√©cnico de uma empresa de TI para capacitar os graduados</a></li>
<li><a href="../pt437962/index.html">ROI do PVS-Studio</a></li>
<li><a href="../pt437968/index.html">ROI do PVS-Studio</a></li>
<li><a href="../pt437972/index.html">PHP para iniciantes. A sess√£o</a></li>
<li><a href="../pt437974/index.html">Como ganhar WorldSkills digitais? Em um exemplo pr√°tico</a></li>
<li><a href="../pt437976/index.html">"Vkontakte" permitido esconder registros individuais da pol√≠cia</a></li>
<li><a href="../pt437978/index.html">Bem-vindo ao SuperJob do SphinxSearch-meetup</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
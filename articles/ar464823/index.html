<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘§ğŸ¾ ğŸ§‘ğŸ½ ğŸ‘©â€â¤ï¸â€ğŸ’‹â€ğŸ‘¨ Ù†Ø­Ù† Ù†Ø¹ØªØ¨Ø± Ù…ØªÙˆØ³Ø· â€‹â€‹Ø±Ø§ØªØ¨ "Ø¹Ø§Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª". Parsim hh.ru Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø§Ù†Ø¯Ø§ / Ø§Ù„Ø«Ø¹Ø¨Ø§Ù† ğŸ›’ ğŸš£ğŸ¼ ğŸ‘ğŸ»</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ù‡Ù„ ØªØ±ÙŠØ¯ Ø£Ù† ØªØ¹Ø±Ù Ù…Ø§ Ù‡Ùˆ Ø§Ù„ÙˆØ¶Ø¹ ÙÙŠ Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ù…Ù„ ØŒ ÙˆØ®Ø§ØµØ© ÙÙŠ Ù…Ø¬Ø§Ù„ Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŸ 
 Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¹Ø±Ù Python Ùˆ Pandas ØŒ ÙØ¥Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙØ§Ø¡Ø§Øª ÙŠØ¨Ø¯Ùˆ ÙˆÙƒØ£Ù†Ù‡ Ø£Ø­Ø¯ Ø§Ù„Ø·...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ù†Ø­Ù† Ù†Ø¹ØªØ¨Ø± Ù…ØªÙˆØ³Ø· â€‹â€‹Ø±Ø§ØªØ¨ "Ø¹Ø§Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª". Parsim hh.ru Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø§Ù†Ø¯Ø§ / Ø§Ù„Ø«Ø¹Ø¨Ø§Ù†</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/464823/" style=";text-align:right;direction:rtl"><p style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/nn/4k/13/nn4k13g0ylvlwjil42ucsarixrw.png"></p><br><p style=";text-align:right;direction:rtl">  Ù‡Ù„ ØªØ±ÙŠØ¯ Ø£Ù† ØªØ¹Ø±Ù Ù…Ø§ Ù‡Ùˆ Ø§Ù„ÙˆØ¶Ø¹ ÙÙŠ Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ù…Ù„ ØŒ ÙˆØ®Ø§ØµØ© ÙÙŠ Ù…Ø¬Ø§Ù„ Ø¹Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŸ <br>  Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ¹Ø±Ù Python Ùˆ Pandas ØŒ ÙØ¥Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙØ§Ø¡Ø§Øª ÙŠØ¨Ø¯Ùˆ ÙˆÙƒØ£Ù†Ù‡ Ø£Ø­Ø¯ Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„Ø£ÙƒØ«Ø± Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© ÙˆØ³Ù‡ÙˆÙ„Ø©. <br>  ÙŠØ¹Ù…Ù„ Ø§Ù„Ø±Ù…Ø² Ø¹Ù„Ù‰ Python3.6 Ùˆ Pandas 0.24.2 <br>  ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ipython Ù…Ù† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">Ù‡Ù†Ø§</a> . <br>  Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥ØµØ¯Ø§Ø± ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­ÙƒÙ… Pandas (Linux / MacOS): </p><br><pre style=";text-align:right;direction:rtl"><code class="plaintext hljs">ipython</code> </pre> <br><p style=";text-align:right;direction:rtl">  Ø«Ù… ÙÙŠ Ø³Ø·Ø± Ø§Ù„Ø£ÙˆØ§Ù…Ø± </p><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">#ipython import pandas as pd pd.__version__</code> </pre> <br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">#   () pip install pandas==0.24.2</code> </pre><br><p style=";text-align:right;direction:rtl">  ØªÙƒÙˆÙŠÙ† Ø¨Ø§Ù„ÙØ¹Ù„ ÙƒÙ„ Ø´ÙŠØ¡ØŸ  Ø¯Ø¹Ù†Ø§ Ù†Ø°Ù‡Ø¨! </p><a name="habracut"></a><br><h1 id="parsim-na-python" style=";text-align:right;direction:rtl">  Ø¨Ø§Ø±Ø³ÙŠÙ… ÙÙŠ Ø¨ÙŠØ«ÙˆÙ† </h1><br><p style=";text-align:right;direction:rtl">  Ø³Ù…Ùˆ ÙŠØªÙŠØ­ Ù„Ùƒ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…Ù„ ÙÙŠ Ø±ÙˆØ³ÙŠØ§.  Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ±Ø¯ ØªØ¬Ù†ÙŠØ¯ Ù„Ø¯ÙŠÙ‡ Ø£ÙƒØ¨Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´ÙˆØ§ØºØ±.  ÙŠØ´Ø§Ø±Ùƒ Ø³Ù…ÙˆÙ‡ ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…Ø±ÙŠØ­Ø©. </p><br><p style=";text-align:right;direction:rtl">  ØºÙˆØºÙ„Ø¯ Ù‚Ù„ÙŠÙ„Ø§ ÙˆØ§ØªØ¶Ø­ Ù„ÙƒØªØ§Ø¨Ø© Ù…Ø­Ù„Ù„. </p><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">#   https://gist.github.com/fuwiak/9c695b51c33b2e052c5a721383705a9c #    (BASH) python3 hh_parser.py import requests import pandas as pd number_of_pages = 100 #number_of_ads = number_of_pages * per_page job_title = ["'Data Analyst' and 'data scientist'"] for job in job_title: data=[] for i in range(number_of_pages): url = 'https://api.hh.ru/vacancies' par = {'text': job, 'area':'113','per_page':'10', 'page':i} r = requests.get(url, params=par) e=r.json() data.append(e) vacancy_details = data[0]['items'][0].keys() df = pd.DataFrame(columns= list(vacancy_details)) ind = 0 for i in range(len(data)): for j in range(len(data[i]['items'])): df.loc[ind] = data[i]['items'][j] ind+=1 csv_name = job+".csv" df.to_csv(csv_name)</code> </pre> <br><p style=";text-align:right;direction:rtl">  Ù†ØªÙŠØ¬Ø© Ù„Ø°Ù„Ùƒ ØŒ Ø­ØµÙ„Ù†Ø§ Ø¹Ù„Ù‰ Ù…Ù„Ù Ø¨ØªÙ†Ø³ÙŠÙ‚ CSV Ù…Ø¹ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙÙŠ job_title. <br>  ÙÙŠ Ù…Ù„Ù ÙˆØ§Ø­Ø¯ Ù…Ø­Ø¯Ø¯ Ù…Ø¹ Ø§Ù„Ø´ÙˆØ§ØºØ± Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø© Ø³ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡Ø§ <br>  "Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª" Ùˆ "Ø¹Ø§Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª".  Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ØºØ¨ ÙÙŠ ØªØºÙŠÙŠØ± Ø§Ù„Ø®Ø· Ø¨Ø´ÙƒÙ„ Ù…Ù†ÙØµÙ„ Ø¥Ù„Ù‰ </p><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">job_title=['Data Analyst', 'Data Scientist']</code> </pre> <br><p style=";text-align:right;direction:rtl">  Ø«Ù… ØªØ­ØµÙ„ Ø¹Ù„Ù‰ 2 Ù…Ù„Ù Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡. </p><br><p style=";text-align:right;direction:rtl">  ÙˆÙ…Ù† Ø§Ù„Ù…Ø«ÙŠØ± Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù… ØŒ Ù‡Ù†Ø§Ùƒ Ø¹ÙˆØ§Ù…Ù„ Ø£Ø®Ø±Ù‰ Ø¥Ù„Ù‰ Ø¬Ø§Ù†Ø¨ "Ùˆ".  Ø¨Ù…Ø³Ø§Ø¹Ø¯ØªÙ‡Ù… ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªØ·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©.  Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù‡Ù†Ø§. </p><br><p style=";text-align:right;direction:rtl">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">https://hh.ru/article/309400</a> </p><br><h1 id="what-time-is-it-its-pandas-time" style=";text-align:right;direction:rtl">  ÙƒÙ… Ø§Ù„Ø³Ø§Ø¹Ø©ØŸ  Ø­Ø§Ù† Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¨Ø§Ù†Ø¯Ø§! </h1><br><p style=";text-align:right;direction:rtl">  Ø³ÙŠØªÙ… ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø§Ù„ØªÙŠ ÙŠØªÙ… Ø¬Ù…Ø¹Ù‡Ø§ Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø¥Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ§Ø±Ø¯Ø© ÙÙŠÙ‡Ø§ Ø£Ùˆ ÙˆØµÙÙ‹Ø§ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§.  Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„: Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø›  Ù…ÙˆÙ‚Ù.  Ø¯ÙØ¹ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø›  ÙØ¦Ø© Ø§Ù„ÙˆØ¸ÙŠÙØ©.  ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø© ØŒ Ù‚Ø¯ ÙŠÙ†ØªÙ…ÙŠ Ø¥Ø¹Ù„Ø§Ù† ÙˆØ§Ø­Ø¯ Ø¥Ù„Ù‰ Ø¹Ø¯Ø© ÙØ¦Ø§Øª. <br>  Ø³Ø£Ø¹ØªÙ†ÙŠ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù…ÙˆÙ‚Ù "Ø¹Ø§Ù„Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª" Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙÙƒØ±Ø© jupyter-notebook.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">https://jupyter.org/</a> </p><br><p style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/za/7c/co/za7ccou3puliiwrrlawim_aumn8.png"></p><br><p style=";text-align:right;direction:rtl">  Ù…Ø§ ÙŠØ¬Ø¨ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ù‡ Ù„ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ "Unnamed"ØŸ </p><br><p style=";text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/mz/ub/ep/mzubepn7osfrwao590ikz9utv-k.png"></p><br><h1 id="samyy-glavnyy-vopros---zp" style=";text-align:right;direction:rtl">  Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙƒØ«Ø± Ø£Ù‡Ù…ÙŠØ© - ZP </h1><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">import ast # run code from string for example ast.literal_eval("1+1") salaries = df.salary.dropna() # remove all NA's from dataframe currencies = [ast.literal_eval(salaries.iloc[i])['currency'] for i in range(len(salaries))] curr = set(currencies) #{'EUR', 'RUR', 'USD'} #divide dataframe salararies by currency rur = [ast.literal_eval(salaries.iloc[i]) for i in range(len(salaries)) if ast.literal_eval(salaries.iloc[i])['currency']=='RUR'] eur = [ast.literal_eval(salaries.iloc[i]) for i in range(len(salaries)) if ast.literal_eval(salaries.iloc[i])['currency']=='EUR'] usd = [ast.literal_eval(salaries.iloc[i]) for i in range(len(salaries)) if ast.literal_eval(salaries.iloc[i])['currency']=='USD']</code> </pre> <br><p style=";text-align:right;direction:rtl">  Ù„Ù‚Ø¯ ØªØ­ÙˆÙ„Øª Ø¥Ù„Ù‰ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø±ÙˆØ§ØªØ¨ Ø¥Ù„Ù‰ Ø¹Ù…Ù„Ø§Øª ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†ÙØ³Ùƒ ØŒ Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ ÙÙ‚Ø· Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„ÙŠÙˆØ±Ùˆ.  Ø³ÙˆÙ Ø£ØªØ¹Ø§Ù…Ù„ ÙÙ‚Ø· Ù…Ø¹ Ø±ÙˆØ§ØªØ¨ Ø§Ù„Ø±ÙˆØ¨Ù„ Ø§Ù„Ø¢Ù† </p><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">fr = [x['from'] for x in rur] # lower range of salary fr = list(filter(lambda x: x is not None, fr)) # remove NA's from lower range [0, 100, 200,...] to = [x['to'] for x in rur] #upper range of salary to = list(filter(lambda x: x is not None, to)) #remove NA's from upper range [100, 200, 300,...] import numpy as np salary_range = list(zip(fr, to)) # concatenate upper and lower range [(0,100), (100, 200), (200, 300)...] av = map(np.mean, salary_range) # convert [(0,100), (100, 200), (200, 300)...] to [50, 150, 250,...] av = round(np.mean(list(av)),1) # average value from [50, 150, 250,...] print("average salary as Data Scientist ", av, "rubles")</code> </pre> <br><p style=";text-align:right;direction:rtl">  Ø£Ø®ÙŠØ±Ø§ ØŒ Ø¹Ù„Ù…Ù†Ø§ Ø­ÙˆØ§Ù„ÙŠ 150 Ø£Ù„Ù Ø±ÙˆØ¨Ù„ ØŒ ÙƒÙ…Ø§ Ù‡Ùˆ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">Ù…ØªÙˆÙ‚Ø¹</a> . </p><br><p style=";text-align:right;direction:rtl">  Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªÙˆØ³Ø· â€‹â€‹Ø§Ù„Ø±Ø§ØªØ¨ ØŒ ÙƒØ§Ù† Ù„ÙŠ Ø§Ù„Ø´Ø±ÙˆØ· Ø§Ù„ØªØ§Ù„ÙŠØ©: </p><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  Ù„Ù… ØªÙÙƒØ± ÙÙŠ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø´Ø§ØºØ±Ø© Ø§Ù„ØªÙŠ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠÙ‡Ø§ Ø±Ø§ØªØ¨ Ù…Ø­Ø¯Ø¯ (df.salary.dropna) </li><li style=";text-align:right;direction:rtl">  Ø§Ø³ØªØºØ±Ù‚ ÙÙ‚Ø· Ø§Ù„Ø±ÙˆØ§ØªØ¨ ÙÙŠ Ø±ÙˆØ¨Ù„ </li><li style=";text-align:right;direction:rtl">  Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù‚Ø§Ø¨Ø³ ØŒ ÙØ§Ø®Ø° Ù…ØªÙˆØ³Ø· â€‹â€‹Ø§Ù„Ù‚ÙŠÙ…Ø© (Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ ØŒ Ù‚Ø§Ø¨Ø³ Ù…Ù† 10000 ÙØ±Ùƒ Ø¥Ù„Ù‰ 20ØŒ000 ÙØ±Ùƒ â†’ 15000 ÙØ±Ùƒ). </li></ul><br><p style=";text-align:right;direction:rtl">  Ø³Ø£Ù‚ÙˆÙ„ Ù…Ø§ ÙŠÙ„ÙŠ Ù„Ù„Ù…ØªØµÙŠØ¯ÙˆÙ† ÙˆØ§Ù„Ø£Ø´Ø®Ø§Øµ Ø¶Ø¹Ø§Ù Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„Ù‡ÙˆØ§Ø© Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù†Ù‰ Ø³Ø±ÙŠ: Ø£Ù†Ø§ Ù„Ø³Øª Ù…ÙˆØ¸ÙÙ‹Ø§ ÙÙŠ hh.ru Ø›  Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù‚Ø§Ù„Ø© Ù„ÙŠØ³Øª Ø¥Ø¹Ù„Ø§Ù†Ù‹Ø§ Ø›  Ù„Ù… Ø£Ø­ØµÙ„ Ø¹Ù„Ù‰ ÙÙ„Ø³ Ù„Ù‡Ø§.  Ø­Ø¸Ø§ Ø³Ø¹ÙŠØ¯Ø§ Ù„Ù„Ø¬Ù…ÙŠØ¹. </p><br><h1 id="bonus" style=";text-align:right;direction:rtl">  Ø¹Ù„Ø§ÙˆØ© </h1><br><p style=";text-align:right;direction:rtl">  ÙƒÙŠÙ Ù‡ÙŠ ÙŠÙˆÙ†ÙŠÙˆ ÙÙŠ Ø§Ù„Ø·Ù„Ø¨ ÙÙŠ Ù…Ø¬Ø§Ù„ Ø¹Ù„ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŸ <br><img src="https://habrastorage.org/webt/fn/1g/j_/fn1gj_ke84wrvnb_zs_hvzyjddu.png"></p><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs">from collections import Counter vacancy_names = df.name # change here to change source of data/words etc cloud = Counter(vacancy_names) from wordcloud import WordCloud, STOPWORDS stopwords = set(STOPWORDS) cloud = '' for x in list(vacancy_names): cloud+=x+' ' wordcloud = WordCloud(width = 800, height = 800, stopwords = stopwords, min_font_size = 8,background_color='white' ).generate(cloud) import matplotlib.pylab as plt plt.figure(figsize = (16, 16)) plt.imshow(wordcloud) plt.savefig('vacancy_cloud.png')</code> </pre> <br><p style=";text-align:right;direction:rtl">  [REPO] ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">https://github.com/fuwiak/HH</a> ) </p><br><p style=";text-align:right;direction:rtl">  ØªØ­Ø±ÙŠØ±: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=" class="user_link">Zoldaten Ø¥ØµØ¯Ø§Ø±</a> Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… <br>  Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ <br>  Ø§Ù„Ø±Ù…Ø² Ù„ÙŠØ³ Ø­Ù‚ÙˆÙ‚ Ø·Ø¨Ø¹ ÙˆÙ†Ø´Ø± ØŒ Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø¨Ø¹Ø¶ Ø§Ù„Ø¹ÙƒØ§Ø²Ø§Øª. </p><br><pre style=";text-align:right;direction:rtl"> <code class="plaintext hljs"># !/usr/bin/python3 # -*- coding: utf-8 -*- import sys import xlsxwriter # pip install XlsxWriter import requests # pip install requests from bs4 import BeautifulSoup as bs # pip install beautifulsoup4 headers = {'accept': '*/*', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'} vacancy = input('  : ') base_url = f'https://hh.ru/search/vacancy?area=1&amp;search_period=30&amp;text={vacancy}&amp;page=' # area=1 - , search_period=3 -  30   pages = int(input(' -   : ')) #+ jobs =[] def hh_parse(base_url, headers): zero = 0 while pages &gt; zero: zero = str(zero) session = requests.Session() request = session.get(base_url + zero, headers = headers) if request.status_code == 200: soup = bs(request.content, 'html.parser') divs = soup.find_all('div', attrs = {'data-qa': 'vacancy-serp__vacancy'}) for div in divs: title = div.find('a', attrs = {'data-qa': 'vacancy-serp__vacancy-title'}).text compensation = div.find('div', attrs={'data-qa': 'vacancy-serp__vacancy-compensation'}) if compensation == None: #     compensation = 'None' else: compensation = div.find('div', attrs={'data-qa': 'vacancy-serp__vacancy-compensation'}).text href = div.find('a', attrs = {'data-qa': 'vacancy-serp__vacancy-title'})['href'] try: company = div.find('a', attrs = {'data-qa': 'vacancy-serp__vacancy-employer'}).text except: company = 'None' text1 = div.find('div', attrs = {'data-qa': 'vacancy-serp__vacancy_snippet_responsibility'}).text text2 = div.find('div', attrs = {'data-qa': 'vacancy-serp__vacancy_snippet_requirement'}).text content = text1 + ' ' + text2 all_txt = [title, compensation, company, content, href] jobs.append(all_txt) zero = int(zero) zero += 1 else: print('error') #   Excel  workbook = xlsxwriter.Workbook('Vacancy.xlsx') worksheet = workbook.add_worksheet() #    bold = workbook.add_format({'bold': 1}) bold.set_align('center') center_H_V = workbook.add_format() center_H_V.set_align('center') center_H_V.set_align('vcenter') center_V = workbook.add_format() center_V.set_align('vcenter') cell_wrap = workbook.add_format() cell_wrap.set_text_wrap() #    worksheet.set_column(0, 0, 35) # A https://xlsxwriter.readthedocs.io/worksheet.html#set_column worksheet.set_column(1, 1, 20) # B worksheet.set_column(2, 2, 40) # C worksheet.set_column(3, 3, 135) # D worksheet.set_column(4, 4, 45) # E worksheet.write('A1', '', bold) worksheet.write('B1', '', bold) worksheet.write('C1', '', bold) worksheet.write('D1', '', bold) worksheet.write('E1', '', bold) row = 1 col = 0 for i in jobs: worksheet.write_string (row, col, i[0], center_V) worksheet.write_string (row, col + 1, i[1], center_H_V) worksheet.write_string (row, col + 2, i[2], center_H_V) worksheet.write_string (row, col + 3, i[3], cell_wrap) # worksheet.write_url (row, col + 4, i[4], center_H_V) worksheet.write_url (row, col + 4, i[4]) row += 1 print('OK') workbook.close() hh_parse(base_url, headers)</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar464823/">https://habr.com/ru/post/ar464823/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar464803/index.html">"Ø¥Ø®ÙØ§Ø¡ Ø´Ø¨ÙƒØ© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©": Ù„Ù…Ø§Ø°Ø§ Ø±ÙØ¶ Ù…Ø·ÙˆØ±Ùˆ Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„ØªØµÙØ­ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¹Ø±Ø¶ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ÙØ±Ø¹ÙŠ</a></li>
<li><a href="../ar464805/index.html">ÙƒØªØ§Ø¨Ø© Ø«Ø¹Ø¨Ø§Ù† Ø¹Ù„Ù‰ ipad (pythonista)</a></li>
<li><a href="../ar464811/index.html">Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø£Ø¨Ù„ Ù„Ù„Ù…Ø·ÙˆØ±</a></li>
<li><a href="../ar464813/index.html">Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Punto Switcher ØŒ ØªØ®Ø·ÙŠØ·Ø§Øª Birman Ø¨Ø¨Ø±Ù†Ø§Ù…Ø¬ Ù†ØµÙŠ Ø¹Ù„Ù‰ autohotkey</a></li>
<li><a href="../ar464819/index.html">ÙŠÙˆÙ…ÙŠ Ø§Ù„Ø³Ø§Ø¯Ø³ Ù…Ø¹ Ù‡Ø§ÙŠÙƒÙˆ: ØªØ­Øª ØºØ·Ø§Ø¡ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ ÙˆØ§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª ÙˆØ§Ù„Ø­Ø²Ù…</a></li>
<li><a href="../ar464825/index.html">ØªØ­Ø¶ÙŠØ± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ù†Ø¸Ø§Ù… Android Q. Ø§Ù„Ø¬Ø²Ø¡ 2</a></li>
<li><a href="../ar464831/index.html">Ø¥Ø¶Ø§ÙØ© ÙˆØ¸Ø§Ø¦Ù Razor Pages Ø¥Ù„Ù‰ .NET Ù‚ÙŠØ§Ø³ÙŠ</a></li>
<li><a href="../ar464833/index.html">Count Scoring de la Fer Ø£Ùˆ Ø¯Ø±Ø§Ø³Ø© Ø­ÙˆÙ„ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù† ÙƒØ¬Ø²Ø¡ Ù…Ù† ØªÙˆØ³ÙŠØ¹ Ø¢ÙØ§Ù‚ Ø§Ù„ÙØ±Ø¯. Ø§Ù„Ø¬Ø²Ø¡ 2</a></li>
<li><a href="../ar464837/index.html">Ù…Ù† Ù†Ù‡Ø± Ø§Ù„ØºØ§Ù†Ø¬ Ø¥Ù„Ù‰ Ù†Ù‡Ø± Ø§Ù„ÙÙˆÙ„ØºØ§: ÙƒÙŠÙ Ù†Ù†Ù‚Ø° Ø§Ù„Ø£Ù†Ù‡Ø§Ø± Ù…Ù† Ø§Ù„ØªÙ„ÙˆØ«ØŸ</a></li>
<li><a href="../ar464839/index.html">Ø­ÙˆÙ„ Ø¨Ø±Ø§Ø¡Ø© Ø§Ø®ØªØ±Ø§Ø¹ ÙˆØ§Ø­Ø¯Ø© ØªØ³Ù„Ø§ Ù…ÙˆØªÙˆØ±Ø²</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ™† ğŸ‘¨ğŸ¼â€ğŸŒ¾ ğŸ¦‹ Tinjauan Teknologi Sintesis Bicara ğŸ‘¨ğŸ¼â€ğŸ’» ğŸ•´ï¸ ğŸ“¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya! Nama saya Vlad dan saya bekerja sebagai ilmuwan data dalam tim teknologi bicara Tinkoff yang digunakan dalam asisten suara kami Oleg. 
...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tinjauan Teknologi Sintesis Bicara</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/tinkoff/blog/474782/"><p>  Halo semuanya!  Nama saya Vlad dan saya bekerja sebagai ilmuwan data dalam tim teknologi bicara Tinkoff yang digunakan dalam asisten suara kami Oleg. </p><br><p>  Dalam artikel ini, saya ingin memberikan gambaran singkat tentang teknologi sintesis pidato yang digunakan dalam industri dan berbagi pengalaman tim kami dalam membangun mesin sintesis kami sendiri. </p><br><p><img src="https://habrastorage.org/webt/fc/3j/vs/fc3jvsr59z_90ojbvjushekmmm4.png" alt="gambar"></p><a name="habracut"></a><br><h3 id="sintez-rechi">  Sintesis ucapan </h3><br><p>  Sintesis ucapan adalah penciptaan suara berdasarkan teks.  Masalah ini hari ini diselesaikan dengan dua pendekatan: </p><br><ul><li>  Pemilihan unit [1], atau pendekatan gabungan.  Ini didasarkan pada menempelkan fragmen dari audio yang direkam.  Sejak akhir 90-an, telah lama dianggap sebagai standar de facto untuk mengembangkan mesin sintesis bicara.  Misalnya, suara yang terdengar dengan metode pemilihan unit dapat ditemukan di Siri [2]. </li><li>  Sintesis ucapan parametrik [3], intinya adalah membangun model probabilistik yang memprediksi sifat akustik dari sinyal audio untuk teks yang diberikan. </li></ul><br><p>  Pidato model pemilihan unit berkualitas tinggi, variabilitas rendah dan membutuhkan sejumlah besar data untuk pelatihan.  Pada saat yang sama, untuk model pelatihan parametrik, jumlah data yang jauh lebih kecil diperlukan, mereka menghasilkan intonasi yang lebih beragam, tetapi sampai saat ini mereka mengalami kualitas suara yang agak buruk secara keseluruhan dibandingkan dengan pendekatan pemilihan unit. </p><br><p>  Namun, dengan perkembangan teknologi pembelajaran yang mendalam, model sintesis parametrik telah mencapai pertumbuhan yang signifikan dalam semua metrik kualitas dan mampu menciptakan ucapan yang secara praktis tidak dapat dibedakan dari ucapan manusia. </p><br><h3 id="metriki-kachestva">  Metrik kualitas </h3><br><p> Sebelum berbicara tentang model sintesis ucapan mana yang lebih baik, Anda perlu menentukan metrik kualitas yang digunakan algoritme. </p><br><p>  Karena teks yang sama dapat dibaca dalam jumlah cara yang tak terbatas, apriori cara yang tepat untuk mengucapkan frasa tertentu tidak ada.  Oleh karena itu, seringkali metrik untuk kualitas sintesis ucapan bersifat subyektif dan tergantung pada persepsi pendengar. </p><br><p>  Metrik standar adalah MOS (skor pendapat rata-rata), penilaian rata-rata dari kealamian bicara, yang diberikan oleh penilai untuk audio yang disintesis pada skala 1 sampai 5. Satu berarti suara yang benar-benar tidak masuk akal, dan lima berarti suara yang tidak dapat dibedakan dari manusia.  Rekaman orang sungguhan biasanya mendapatkan sekitar 4,5, dan nilai lebih dari 4 dianggap cukup tinggi. </p><br><h3 id="kak-rabotaet-sintez-rechi">  Cara kerja sintesis ucapan </h3><br><p>  Langkah pertama untuk membangun sistem sintesis pidato adalah mengumpulkan data untuk pelatihan.  Biasanya ini adalah rekaman audio berkualitas tinggi di mana penyiar membaca frasa yang dipilih secara khusus.  Ukuran perkiraan dataset yang diperlukan untuk model pemilihan unit pelatihan adalah 10-20 jam bicara murni [2], sedangkan untuk metode parametrik jaringan saraf, batas atas adalah sekitar 25 jam [4, 5]. </p><br><p>  Kami membahas kedua teknologi sintesis. </p><br><h3 id="unit-selection">  Pemilihan unit </h3><br><p><img src="https://habrastorage.org/webt/9-/r7/dm/9-r7dmw2tieg5ypyjbt-lddxddc.png" alt="gambar"></p><br><p>  Biasanya, ucapan pembicara yang direkam tidak dapat mencakup semua kasus yang memungkinkan di mana sintesis akan digunakan.  Oleh karena itu, inti dari metode ini adalah untuk membagi seluruh basis audio menjadi fragmen kecil yang disebut unit, yang kemudian direkatkan menggunakan minimal pasca pemrosesan.  Unit biasanya merupakan unit bahasa akustik minimal, seperti setengah telepon atau dipon [2]. <br>  Seluruh proses pembuatan terdiri dari dua tahap: frontend NLP, yang bertanggung jawab untuk mengekstraksi representasi linguistik teks, dan backend, yang menghitung fungsi unit penalti untuk fitur linguistik yang diberikan.  Frontend NLP meliputi: </p><br><ol><li>  Tugas menormalkan teks adalah menerjemahkan semua karakter non-huruf (angka, tanda persen, mata uang, dan sebagainya) ke dalam representasi verbal mereka.  Misalnya, "5%" harus dikonversi menjadi "lima persen". </li><li>  Mengekstraksi fitur-fitur linguistik dari teks yang dinormalisasi: representasi fonem, stres, bagian-bagian pembicaraan dan sebagainya. </li></ol><br><p>  Biasanya, frontend NLP diimplementasikan menggunakan aturan yang ditentukan secara manual untuk bahasa tertentu, tetapi baru-baru ini ada peningkatan bias terhadap penggunaan model pembelajaran mesin [7]. </p><br><p>  Denda yang diestimasi oleh subsistem backend adalah jumlah dari biaya target, atau korespondensi dari representasi akustik unit untuk fonem tertentu, dan biaya gabungan, yaitu, kesesuaian menghubungkan dua unit tetangga.  Untuk mengevaluasi fungsi-fungsi halus, seseorang dapat menggunakan aturan atau model akustik sintesis parametrik yang sudah terlatih [2].  Pemilihan urutan unit paling optimal dari sudut pandang hukuman yang ditentukan di atas terjadi menggunakan algoritma Viterbi [1]. </p><br><p>  Nilai perkiraan model pemilihan unit MOS untuk bahasa Inggris: 3.7-4.1 [2, 4, 5]. </p><br><p>  Keuntungan dari pendekatan pemilihan unit: </p><br><ul><li>  Suara alami. </li><li>  Generasi kecepatan tinggi. </li><li>  Ukuran model yang kecil - ini memungkinkan Anda untuk menggunakan sintesis secara langsung di perangkat seluler Anda. </li></ul><br><p>  Kekurangan: </p><br><ul><li>  Pidato yang disintesis adalah monoton, tidak mengandung emosi. </li><li>  Artefak perekatan karakteristik. </li><li>  Dibutuhkan basis pelatihan yang cukup besar dari data audio untuk mencakup semua jenis konteks. </li><li>  Pada prinsipnya, itu tidak dapat menghasilkan suara yang tidak ditemukan dalam set pelatihan. </li></ul><br><h3 id="parametricheskiy-sintez-rechi">  Sintesis pidato parametrik </h3><br><p>  Pendekatan parametrik didasarkan pada gagasan membangun model probabilistik yang memperkirakan distribusi fitur akustik teks yang diberikan. <br>  Proses pembuatan pidato dalam sintesis parametrik dapat dibagi menjadi empat tahap: </p><br><ol><li>  Frontend NLP adalah tahap yang sama dari preprocessing data seperti dalam pendekatan pemilihan unit, yang hasilnya adalah sejumlah besar fitur linguistik peka konteks. </li><li>  Model durasi memprediksi durasi fonem. </li><li>  Model akustik yang mengembalikan distribusi fitur akustik di atas yang linguistik.  Fitur akustik termasuk nilai frekuensi fundamental, representasi spektral sinyal, dan sebagainya. </li><li>  Seorang vocoder menerjemahkan fitur akustik menjadi gelombang suara. </li></ol><br><p>  Untuk durasi pelatihan dan model akustik, model Markov tersembunyi [3], jaringan saraf dalam, atau varietas berulangnya [6] dapat digunakan.  Seorang vocoder tradisional adalah algoritma yang didasarkan pada model sumber-filter [3], yang mengasumsikan bahwa ucapan adalah hasil dari penerapan filter derau linear ke sinyal asli. <br>  Kualitas bicara keseluruhan dari metode parametrik klasik cukup rendah karena sejumlah besar asumsi independen tentang struktur proses pembuatan suara. </p><br><p>  Namun, dengan munculnya teknologi pembelajaran yang mendalam, menjadi mungkin untuk melatih model ujung ke ujung yang secara langsung memprediksi tanda akustik melalui surat.  Misalnya, jaringan saraf Tacotron [4] dan Tacotron 2 [5] memasukkan urutan huruf dan mengembalikan spektrogram kapur menggunakan algoritma seq2seq [8].  Dengan demikian, langkah 1-3 dari pendekatan klasik digantikan oleh jaringan saraf tunggal.  Diagram di bawah ini menunjukkan arsitektur jaringan Tacotron 2, yang mencapai kualitas suara yang cukup tinggi. </p><br><p><img src="https://habrastorage.org/webt/tv/8l/pc/tv8lpchvxw75yr3msdbhjaqscwc.jpeg" alt="gambar"></p><br><p>  Faktor lain dari peningkatan yang signifikan dalam kualitas pidato yang disintesis adalah penggunaan neural network vocoders alih-alih algoritma pemrosesan sinyal digital. </p><br><p>  Vokoder pertama seperti itu adalah jaringan saraf WaveNet [9], yang secara berurutan, langkah demi langkah, meramalkan amplitudo gelombang suara. </p><br><p>  Karena penggunaan sejumlah besar lapisan convolutional dengan celah untuk menangkap lebih banyak konteks dan melompati koneksi dalam arsitektur jaringan, dimungkinkan untuk mencapai peningkatan sekitar 10% dalam MOS dibandingkan dengan model pemilihan unit.  Diagram di bawah ini menunjukkan arsitektur jaringan WaveNet. </p><br><p><img src="https://habrastorage.org/webt/lg/ei/df/lgeidfeylr_yu-u-ucmdsxi7xki.png" alt="gambar"></p><br><p>  Kerugian utama WaveNet adalah kecepatan rendah yang terkait dengan rangkaian pengambilan sampel sinyal serial.  Masalah ini dapat diselesaikan dengan menggunakan optimasi teknik untuk arsitektur besi tertentu, atau dengan mengganti skema pengambilan sampel dengan yang lebih cepat. <br>  Kedua pendekatan telah berhasil diimplementasikan di industri.  Yang pertama adalah di Tinkoff.ru, dan sebagai bagian dari pendekatan kedua, Google memperkenalkan jaringan Parallel WaveNet [10] pada tahun 2017, yang pencapaiannya digunakan di Asisten Google. </p><br><p>  Nilai perkiraan MOS untuk metode jaringan saraf: 4.4-4.5 [5, 11], yaitu, ucapan yang disintesis secara praktis tidak berbeda dari ucapan manusia. </p><br><p>  Keuntungan sintesis parametrik: </p><br><ul><li>  Suara alami dan halus saat menggunakan pendekatan ujung ke ujung. </li><li>  Variasi intonasi yang lebih besar. </li><li>  Gunakan lebih sedikit data daripada model pemilihan unit. </li></ul><br><p>  Kekurangan: </p><br><ul><li>  Kecepatan rendah dibandingkan dengan pemilihan unit. </li><li>  Kompleksitas komputasi yang hebat. </li></ul><br><h3 id="kak-rabotaet-sintez-rechi-v-tinkoff">  Cara Kerja Sintesis Bicara Tinkoff </h3><br><p>  Sebagai berikut dari ulasan, metode sintesis ucapan parametrik berdasarkan jaringan saraf saat ini secara signifikan unggul dalam kualitas dari pendekatan pemilihan unit dan jauh lebih mudah untuk dikembangkan.  Karena itu, untuk membangun mesin sintesis kami sendiri, kami menggunakannya. <br>  Untuk model pelatihan, sekitar 25 jam pidato murni seorang pembicara profesional digunakan.  Membaca teks dipilih secara khusus sehingga sebagian besar mencakup fonetik pidato sehari-hari.  Selain itu, untuk menambah variasi pada sintesis intonasi, kami meminta penyiar untuk membaca teks dengan ekspresi tergantung pada konteksnya. </p><br><p>  Arsitektur solusi kami secara konseptual terlihat seperti ini: </p><br><ul><li>  Frontend NLP, yang mencakup normalisasi teks jaringan saraf dan model untuk menempatkan jeda dan tekanan. </li><li>  Tacotron 2 menerima surat sebagai masukan. </li><li>  WaveNet Autoregressive, bekerja secara real time pada CPU. </li></ul><br><p>  Berkat arsitektur ini, mesin kami menghasilkan pidato ekspresif berkualitas tinggi secara real time, tidak memerlukan membangun kamus fonem, dan memungkinkan untuk mengontrol tekanan dalam kata-kata individual.  Contoh audio yang disintesis dapat didengar dengan mengklik <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tautan</a> . </p><br><h3 id="ssylki">  Referensi: </h3><br><p>  [1] AJ Hunt, AW Black.  Seleksi unit dalam sistem sintesis pidato concatenative menggunakan database pidato besar, ICASSP, 1996. <br>  [2] T. Capes, P. Coles, A. Conkie, L. Golipour, A. Hadjitarkhani, Q. Hu, N. Huddleston, M. Hunt, J. Li, M. Neeracher, K. Prahallad, T. Raitio , R. Rasipuram, G. Townsend, B. Williamson, D. Winarsky, Z. Wu, H. Zhang.  Unit Pembelajaran Terpandu Dalam-Pembelajaran Siri Sistem Pemilihan Text-to-Speech System, Interspeech, 2017. <br>  [3] H. Zen, K. Tokuda, AW Black.  Sintesis pidato parametrik statistik, Komunikasi Bicara, Vol.  51, tidak.  11, hlm.  1039-1064, 2009. <br>  [4] Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Chen Zhifeng, Samy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark, Rif A. Saurous .  Tacotron: Menuju Sintesis Bicara End-to-End. <br>  [5] Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Wang Yuxuan, RJ Skerry-Ryan, Rif A. Saurous, Yannis Agiomyrgiannakis, Yonghui Wu.  Sintesis TTS Alami dengan Mengkondisikan WaveNet pada Prediksi Mel Spectrogram. <br>  [6] Heiga Zen, Andrew Senior, Mike Schuster.  Sintesis pidato parametrik statistik menggunakan jaringan saraf dalam. <br>  [7] Hao Zhang, Richard Sproat, Axel H. Ng, Felix Stahlberg, Peng Xiaochang, Kyle Gorman, Brian Roark.  Model Saraf Normalisasi Teks untuk Aplikasi Bicara. <br>  [8] Ilya Sutskever, Oriol Vinyals, Quoc V. Le.  Sequence to Sequence Learning dengan Neural Networks. <br>  [9] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu.  WaveNet: Model Generatif untuk Audio Mentah. <br>  [10] Aaron van den Oord, Yazhe Li, Igor Babuschkin, Karen Simonyan, Oriol Vinyals, Koray Kavukcuoglu, George van den Driessche, Edward Lockhart, Luis C. Cobo, Florian Stimberg, Norman Casagrande, Dominik Grewe, Seb Noury, Sander Dieleman , Erich Elsen, Nal Kalchbrenner, Heiga Zen, Alex Graves, Helen King, Tom Walters, Dan Belov, Demis Hassabis.  Parallel WaveNet: Sintesis Pidato High-Fidelity Cepat. <br>  [11] Wei Ping Kainan Peng Jitong Chen.  ClariNet: Generasi Gelombang Paralel dalam Teks-ke-Akhir dari ujung ke ujung. <br>  [12] Dario Rethage, Jordi Pons, Xavier Serra.  A Wavenet for Speech Denoising. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id474782/">https://habr.com/ru/post/id474782/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id474762/index.html">Seminar: Solusi IT hibrid untuk bisnis. 14 November, Moskow</a></li>
<li><a href="../id474768/index.html">Buka siaran Main Hall HighLoad ++ 2019</a></li>
<li><a href="../id474770/index.html">Bagaimana kami melakukan pengujian regresi penggajian di SAP HCM</a></li>
<li><a href="../id474772/index.html">Sebuah startup yang menggunakan AI untuk mengembangkan penyembuhan dalam 21 hari</a></li>
<li><a href="../id474776/index.html">Teori Umum dan Arkeologi Virtualisasi x86</a></li>
<li><a href="../id474784/index.html">Arcade Stick Story</a></li>
<li><a href="../id474788/index.html">Organisasi rute di Laravel</a></li>
<li><a href="../id474790/index.html">Tales Negotiator</a></li>
<li><a href="../id474792/index.html">6-8 Desember - Rosbank Tech.Madness Hackathon</a></li>
<li><a href="../id474796/index.html">Apa itu Internet hal dan bagaimana hal itu membantu perusahaan memperoleh lebih banyak?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
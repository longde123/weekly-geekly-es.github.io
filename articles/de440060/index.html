<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ‚Äç‚öñÔ∏è ü•ñ üë∑üèº TensorFlow auf Apache Ignite üí≥ üò† üå®Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir alle wissen, wie die Heimat beginnt, und tiefes Lernen beginnt mit Daten. Ohne sie ist es unm√∂glich, ein Modell zu trainieren, zu bewerten und tat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>TensorFlow auf Apache Ignite</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/gridgain/blog/440060/">  Wir alle wissen, wie die Heimat beginnt, und tiefes Lernen beginnt mit Daten.  Ohne sie ist es unm√∂glich, ein Modell zu trainieren, zu bewerten und tats√§chlich zu verwenden.  Wir forschen, erweitern den Hirsch-Index mit Artikeln √ºber neue neuronale Netzwerkarchitekturen und experimentieren und verlassen uns auf die einfachsten lokalen Datenquellen.  normalerweise Dateien in verschiedenen Formaten.  Es funktioniert, aber es w√§re sch√∂n, sich an ein Kampfsystem zu erinnern, das Terabyte st√§ndig wechselnder Daten enth√§lt.  Dies bedeutet, dass Sie die Daten√ºbertragung in der Produktion vereinfachen und beschleunigen sowie mit Big Data arbeiten m√ºssen.  Hier kommt Apache Ignite ins Spiel. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Ignite</a> ist eine verteilte speicherzentrierte Datenbank sowie eine Plattform f√ºr das Zwischenspeichern und Verarbeiten von Vorg√§ngen in Bezug auf Transaktionen, Analysen und Stream-Ladevorg√§nge.  Das System ist in der Lage, Petabytes an Daten mit RAM-Geschwindigkeit zu mahlen.  Der Artikel konzentriert sich auf die Integration zwischen Apache Ignite und TensorFlow, mit der Sie Apache Ignite als Datenquelle f√ºr das Training des neuronalen Netzwerks und der Inferenz sowie als Repository f√ºr trainierte Modelle und ein Cluster-Management-System f√ºr verteiltes Lernen verwenden k√∂nnen. <br><a name="habracut"></a><br><h2>  Verteilte RAM-Datenquelle </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mit Apache Ignite</a> k√∂nnen Sie so viele Daten speichern und verarbeiten, wie Sie in einem verteilten Cluster ben√∂tigen.  Verwenden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ignite Dataset</a> , um diese Apache Ignite beim Training neuronaler Netze in TensorFlow zu nutzen. <br><br>  Hinweis: Apache Ignite ist nicht nur eine der Verbindungen in der ETL-Pipeline zwischen einer Datenbank oder einem Data Warehouse und TensorFlow.  Apache Ignite an sich ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HTAP</a> (ein Hybridsystem f√ºr die Verarbeitung von Transaktions- und Analysedaten).  Wenn Sie sich f√ºr Apache Ignite und TensorFlow entscheiden, erhalten Sie ein einziges System f√ºr die Transaktions- und Analyseverarbeitung und gleichzeitig die M√∂glichkeit, Betriebs- und Verlaufsdaten zum Trainieren des neuronalen Netzwerks und der Inferenz zu verwenden. <br><br>  Die folgenden Benchmarks zeigen, dass Apache Ignite gut f√ºr Szenarien geeignet ist, in denen Daten auf einem einzelnen Host gespeichert werden.  Mit einem solchen System k√∂nnen Sie einen Durchsatz von mehr als 850 Mbit / s erzielen, wenn sich Data Warehouse und Client auf demselben Knoten befinden.  Befindet sich der Speicher auf einem Remote-Host, betr√§gt der Durchsatz ca. 800 Mbit / s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b75/eb5/d7f/b75eb5d7fbefd87abba6928b773a5677.png" alt="Bild"><br><br>  Das Diagramm zeigt die Bandbreite f√ºr Ignite Dataset f√ºr einen einzelnen lokalen Apache Ignite-Knoten.  Diese Ergebnisse wurden auf einem 2x Xeon E5-2609 v4 1,7-GHz-Prozessor mit 16 GB RAM und in einem Netzwerk mit einer Bandbreite von 10 GB / s erhalten (jeder Datensatz hat eine Gr√∂√üe von 1 MB, Seitengr√∂√üe - 20 MB). <br><br>  Ein weiterer Benchmark zeigt, wie Ignite Dataset mit einem verteilten Apache Ignite-Cluster funktioniert.  Diese Konfiguration wird standardm√§√üig ausgew√§hlt, wenn Sie Apache Ignite als HTAP-System verwenden und es Ihnen erm√∂glichen, eine Bandbreite f√ºr einen einzelnen Client von mehr als 1 GB / s in einem Cluster mit einer Bandbreite von 10 Gbit / s zu erreichen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83f/802/972/83f802972875545a415c88dc6ca64fbd.png" alt="Bild"><br><br>  Die Grafik zeigt den Ignite-Dataset-Durchsatz f√ºr einen verteilten Apache Ignite-Cluster mit einer anderen Anzahl von Knoten (von 1 bis 9).  Diese Ergebnisse wurden auf einem 2x Xeon E5-2609 v4 1,7-GHz-Prozessor mit 16 GB RAM und in einem Netzwerk mit einer Bandbreite von 10 GB / s erhalten (jeder Datensatz hat eine Gr√∂√üe von 1 MB, Seitengr√∂√üe - 20 MB). <br><br>  Das folgende Szenario wurde getestet: Der Apache Ignite-Cache (mit einer variablen Anzahl von Partitionen in der ersten Testgruppe und mit 2048 Partitionen in der zweiten) wird mit 10 KB Zeilen mit jeweils 1 MB gef√ºllt. Anschlie√üend liest der TensorFlow-Client Daten mithilfe von Ignite Dataset.  Der Cluster wurde aus Maschinen mit 2 x Xeon E5-2609 v4 1,7 GHz und 16 GB Speicher erstellt und √ºber ein Netzwerk mit einer Geschwindigkeit von 10 GB / s verbunden.  Auf jedem Knoten arbeitete Apache Ignite in der <a href="">Standardkonfiguration</a> . <br><br>  Apache Ignite ist einfach als klassische Datenbank mit SQL-Schnittstelle und gleichzeitig als Datenquelle f√ºr TensorFlow zu verwenden. <br><br><pre><code class="bash hljs">$ apache-ignite/bin/ignite.sh $ apache-ignite/bin/sqlline.sh -u <span class="hljs-string"><span class="hljs-string">"jdbc:ignite:thin://localhost:10800/"</span></span></code> </pre> <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> KITTEN_CACHE (<span class="hljs-keyword"><span class="hljs-keyword">ID</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LONG</span></span> PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NAME</span></span> <span class="hljs-built_in"><span class="hljs-built_in">VARCHAR</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">'WARM KITTY'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">'SOFT KITTY'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">'LITTLE BALL OF FUR'</span></span>);</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"SQL_PUBLIC_KITTEN_CACHE"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset: print(element)</code> </pre> <br><pre> <code class="json hljs">{'key': <span class="hljs-number"><span class="hljs-number">1</span></span>, 'val': {'NAME': b'WARM KITTY'}} {'key': <span class="hljs-number"><span class="hljs-number">2</span></span>, 'val': {'NAME': b'SOFT KITTY'}} {'key': <span class="hljs-number"><span class="hljs-number">3</span></span>, 'val': {'NAME': b'LITTLE BALL OF FUR'}}</code> </pre> <br><h2>  Strukturierte Objekte </h2><br>  Mit Apache Ignite k√∂nnen Sie Objekte eines beliebigen Typs speichern, die in einer beliebigen Hierarchie erstellt werden k√∂nnen.  Sie k√∂nnen damit √ºber Ignite Dataset arbeiten. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): print(element)</code> </pre> <br><pre> <code class="json hljs">{ 'key': 'kitten.png', 'val': { 'metadata': { 'file_name': b'kitten.png', 'label': b'little ball of fur', 'width': <span class="hljs-number"><span class="hljs-number">800</span></span>, 'height': <span class="hljs-number"><span class="hljs-number">600</span></span> }, 'pixels': [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ..., <span class="hljs-number"><span class="hljs-number">0</span></span>] } }</code> </pre> <br>  Neuronales Netzwerktraining und andere Berechnungen erfordern eine Vorverarbeitung, die als Teil der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tf.data-</a> Pipeline durchgef√ºhrt werden kann, wenn Sie Ignite Dataset verwenden. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>).map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> obj: obj[<span class="hljs-string"><span class="hljs-string">'val'</span></span>][<span class="hljs-string"><span class="hljs-string">'pixels'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset: print(element)</code> </pre> <br><pre> <code class="json hljs">[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ..., <span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><h2>  Verteiltes Training </h2><br>  TensorFlow ist ein Framework <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">f√ºr</a> maschinelles Lernen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das</a> verteiltes Lernen, Inferenz und andere Computer in neuronalen Netzen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unterst√ºtzt</a> .  Wie Sie wissen, basiert das neuronale Netzwerktraining auf der Berechnung von Gradienten der Verlustfunktion.  Im Fall eines verteilten Trainings k√∂nnen wir diese Gradienten auf jeder Partition berechnen und dann aggregieren.  Mit dieser Methode k√∂nnen Sie Gradienten f√ºr einzelne Knoten berechnen, auf denen Daten gespeichert sind, diese zusammenfassen und schlie√ülich die Modellparameter aktualisieren.  Und da wir die √úbertragung von Trainingsbeispieldaten zwischen Knoten beseitigt haben, wird das Netzwerk nicht zum ‚ÄûEngpass‚Äú des Systems. <br><br>  Apache Ignite verwendet horizontale Partitionierung (Sharding), um Daten in einem verteilten Cluster zu speichern.  Durch Erstellen des Apache Ignite-Caches (oder einer Tabelle in Bezug auf SQL) k√∂nnen Sie die Anzahl der Partitionen angeben, zwischen denen die Daten verteilt werden.  Wenn ein Apache Ignite-Cluster beispielsweise aus 100 Computern besteht und wir einen Cache mit 1000 Partitionen erstellen, ist jeder Computer f√ºr etwa 10 Partitionen mit Daten verantwortlich. <br><br>  Mit Ignite Dataset k√∂nnen Sie diese beiden Aspekte f√ºr das verteilte Training neuronaler Netze verwenden.  Ignite Dataset ist der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rechengraphenknoten</a> , der die Grundlage der TensorFlow-Architektur bildet.  Und wie jeder Knoten in einem Diagramm kann er auf einem Remote-Knoten im Cluster ausgef√ºhrt werden.  Ein solcher Remote-Knoten kann Ignite Dataset-Parameter (z. B. <code>host</code> , <code>port</code> oder <code>part</code> ) √ºberschreiben und die entsprechenden Umgebungsvariablen f√ºr den Workflow <code>IGNITE_DATASET_HOST</code> (z. B. <code>IGNITE_DATASET_HOST</code> , <code>IGNITE_DATASET_PORT</code> oder <code>IGNITE_DATASET_PART</code> ).  Mit einer solchen √úberschreibung k√∂nnen Sie jedem Clusterknoten eine bestimmte Partition zuweisen.  Dann ist ein Knoten f√ºr eine Partition verantwortlich und gleichzeitig erh√§lt der Benutzer eine einzelne Fassade der Arbeit mit dem Datensatz. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset dataset = IgniteDataset(<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       . gradients = [] for i in range(5): with tf.device("/job:WORKER/task:%d" % i): device_iterator = tf.compat.v1.data.make_one_shot_iterator(dataset) device_next_obj = device_iterator.get_next() gradient = compute_gradient(device_next_obj) gradients.append(gradient) #      result_gradient = tf.reduce_sum(gradients) with tf.Session("grpc://localhost:10000") as sess: print(sess.run(result_gradient))</span></span></code> </pre> <br>  Apache Ignite erm√∂glicht auch verteiltes Lernen mithilfe der TensorFlow- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">API-</a> Bibliothek auf hoher Ebene.  Diese Funktionalit√§t basiert auf dem sogenannten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Standalone-Client-Modus des</a> verteilten Lernens in TensorFlow, bei dem Apache Ignite als Datenquellen- und Cluster-Management-System fungiert.  Der n√§chste Artikel widmet sich ausschlie√ülich diesem Thema. <br><br><h2>  Kontrollpunktspeicherung lernen </h2><br>  Zus√§tzlich zu den Datenbankfunktionen verf√ºgt Apache Ignite √ºber ein verteiltes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IGFS-</a> Dateisystem.  Funktionell √§hnelt es dem Hadoop HDFS-Dateisystem, jedoch nur im RAM.  Zusammen mit seinen eigenen APIs implementiert das IGFS-Dateisystem die Hadoop FileSystem-API und kann eine transparente Verbindung zu bereitgestelltem Hadoop oder Spark herstellen.  Die TensorFlow-Bibliothek unter Apache Ignite bietet eine Integration zwischen IGFS und TensorFlow.  Die Integration basiert auf dem TensorFlow-eigenen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dateisystem-</a> Plugin und der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nativen IGFS-API von</a> Apache Ignite.  Es gibt verschiedene Szenarien f√ºr die Verwendung, zum Beispiel: <br><br><ul><li>  Statuspr√ºfpunkte werden in IGFS f√ºr Zuverl√§ssigkeit und Fehlertoleranz gespeichert. </li><li>  Lernprozesse interagieren mit TensorBoard, indem sie Ereignisdateien in ein von TensorBoard √ºberwachtes Verzeichnis schreiben.  IGFS stellt sicher, dass diese Kommunikation auch dann funktioniert, wenn TensorBoard in einem anderen Prozess oder auf einem anderen Computer ausgef√ºhrt wird. </li></ul><br>  Diese Funktionalit√§t wurde in der Version von TensorFlow 1.13.0.rc0 ver√∂ffentlicht und wird auch Teil von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tensorflow / io</a> in der Version von TensorFlow 2.0 sein. <br><br><h2>  SSL-Verbindung </h2><br>  Mit Apache Ignite k√∂nnen Sie Datenkan√§le mithilfe von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SSL</a> und Authentifizierung sichern.  Ignite Dataset unterst√ºtzt SSL-Verbindungen mit und ohne Authentifizierung.  Weitere Informationen finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Ignite SSL / TLS-</a> Dokumentation. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>, certfile=<span class="hljs-string"><span class="hljs-string">"client.pem"</span></span>, cert_password=<span class="hljs-string"><span class="hljs-string">"password"</span></span>, username=<span class="hljs-string"><span class="hljs-string">"ignite"</span></span>, password=<span class="hljs-string"><span class="hljs-string">"ignite"</span></span>)</code> </pre> <br><h2>  Windows-Unterst√ºtzung </h2><br>  Ignite Dataset ist vollst√§ndig kompatibel mit Windows.  Es kann als Teil von TensorFlow auf einer Windows-Workstation sowie auf Linux / MacOS-Systemen verwendet werden. <br><br><h2>  Probieren Sie es selbst aus </h2><br>  Die folgenden Beispiele helfen Ihnen beim Einstieg in das Modul. <br><br><h4>  Datensatz entz√ºnden </h4><br>  Der einfachste Weg, um mit Ignite Dataset zu beginnen, besteht darin, den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Docker-</a> Container mit Apache Ignite und heruntergeladenen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MNIST-</a> Daten zu starten und dann mit Ignite Dataset damit zu arbeiten.  Ein solcher Container ist im Docker Hub verf√ºgbar: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dmitrievanthony / ignite-with-mnist</a> .  Sie m√ºssen den Container auf Ihrem Computer ausf√ºhren: <br><br><pre> <code class="bash hljs">docker run -it -p 10800:10800 dmitrievanthony/ignite-with-mnist</code> </pre> <br>  Danach k√∂nnen Sie wie folgt damit arbeiten: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/521/e43/417/521e43417bf05c913bdbcb6de66020e5.png" alt="Bild"><br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline dataset = IgniteDataset(<span class="hljs-string"><span class="hljs-string">"MNIST_CACHE"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, img <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(dataset.take(<span class="hljs-number"><span class="hljs-number">5</span></span>)): plt.subplot(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">'figure.figsize'</span></span>] = (<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>) plt.imshow(img[<span class="hljs-string"><span class="hljs-string">'val'</span></span>][<span class="hljs-string"><span class="hljs-string">'pixels'</span></span>].numpy().reshape([<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>])) plt.axis(<span class="hljs-string"><span class="hljs-string">'off'</span></span>)</code> </pre> <br></div></div><br><h4>  IGFS </h4><br>  Die Unterst√ºtzung von TensorFlow IGFS wurde in der Version TensorFlow 1.13.0rc0 ver√∂ffentlicht und wird auch Teil der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Version Tensorflow / io</a> in TensorFlow 2.0 sein.  Um IGFS mit TensorFlow zu testen, k√∂nnen Sie einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Docker-</a> Container am einfachsten mit Apache Ignite + IGFS starten und dann mit TensorFlow <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tf.gfile damit arbeiten</a> .  Ein solcher Container ist im Docker Hub verf√ºgbar: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dmitrievanthony / ignite-with-igfs</a> .  Dieser Container kann auf Ihrem Computer ausgef√ºhrt werden: <br><br><pre> <code class="bash hljs">docker run -it -p 10500:10500 dmitrievanthony/ignite-with-igfs</code> </pre> <br>  Dann k√∂nnen Sie so damit arbeiten: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow.contrib.ignite.python.ops.igfs_ops <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.gfile.Open(<span class="hljs-string"><span class="hljs-string">"igfs:///hello.txt"</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> w: w.write(<span class="hljs-string"><span class="hljs-string">"Hello, world!"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.gfile.Open(<span class="hljs-string"><span class="hljs-string">"igfs:///hello.txt"</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> r: print(r.read())</code> </pre> <br><pre> <code class="json hljs">Hello, world!</code> </pre> <br><h2>  Einschr√§nkungen </h2><br>  Derzeit wird bei der Arbeit mit Ignite Dataset davon ausgegangen, dass alle Objekte im Cache dieselbe Struktur haben (homogene Objekte) und dass der Cache mindestens ein Objekt enth√§lt, das zum Abrufen des Schemas erforderlich ist.  Eine weitere Einschr√§nkung betrifft strukturierte Objekte: Ignite Dataset unterst√ºtzt keine UUIDs, Maps und Object-Arrays, die Teil eines Objekts sein k√∂nnen.  Das Entfernen dieser Einschr√§nkungen sowie das Stabilisieren und Synchronisieren von Versionen von TensorFlow und Apache Ignite ist eine der Aufgaben der laufenden Entwicklung. <br><br><h2>  Erwartete TensorFlow 2.0-Version </h2><br>  Bevorstehende √Ñnderungen an TensorFlow 2.0 werden diese Funktionen im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tensorflow / Io-</a> Modul <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hervorheben</a> .  Danach kann die Arbeit mit ihnen flexibler aufgebaut werden.  Die Beispiele werden sich ein wenig √§ndern, und dies wird sich im Gihab und in der Dokumentation widerspiegeln. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440060/">https://habr.com/ru/post/de440060/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440048/index.html">Lieblingskennzahlen: 5 Indikatoren, denen jedes Verkaufsteam folgen muss</a></li>
<li><a href="../de440050/index.html">Do-it-yourself-DNS-Proxys auf Node.JS</a></li>
<li><a href="../de440052/index.html">Statische BIOS / UEFI-Analyse oder Abrufen eines Abh√§ngigkeitsdiagramms</a></li>
<li><a href="../de440054/index.html">√úbertragen Sie den Webdienst mit AWS auf Yandex.Cloud</a></li>
<li><a href="../de440058/index.html">Internet Issues & Availability Report 2018‚Äì2019</a></li>
<li><a href="../de440062/index.html">Mit Vergn√ºgen planen. Wie wir Prozesse ohne Manager einrichten</a></li>
<li><a href="../de440064/index.html">Rechenzentren zur Auswahl: London, Moskau, Z√ºrich, St. Petersburg</a></li>
<li><a href="../de440066/index.html">VSCode-Erweiterungen zur Vereinfachung der JavaScript- und Vue-Entwicklung</a></li>
<li><a href="../de440070/index.html">Julia, Gradientenabstieg und Simplex-Methode</a></li>
<li><a href="../de440072/index.html">AresDB-Demo: Uber GPU-basiertes Open Source-Echtzeitanalysetool</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
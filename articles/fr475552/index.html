<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘ˆğŸ» ğŸï¸ ğŸ–•ğŸ» Algorithmes d'apprentissage automatique de test Blitz: alimentez votre ensemble de donnÃ©es vers la bibliothÃ¨que scikit-learn â™ï¸ ğŸ» ğŸ§›ğŸ½</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chaque jour, le Web mondial est rempli d'articles sur les algorithmes d'apprentissage automatique les plus populaires et les plus utilisÃ©s pour rÃ©soud...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Algorithmes d'apprentissage automatique de test Blitz: alimentez votre ensemble de donnÃ©es vers la bibliothÃ¨que scikit-learn</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/475552/"><img src="https://habrastorage.org/getpro/habr/post_images/7d1/0a1/6c9/7d10a16c9f50f8289a4b30eb53ffc661.jpg" alt="image"><br><br>  Chaque jour, le Web mondial est rempli d'articles sur les algorithmes d'apprentissage automatique les plus populaires et les plus utilisÃ©s pour rÃ©soudre divers problÃ¨mes.  De plus, la base de ces articles, lÃ©gÃ¨rement modifiÃ©s de forme Ã  un endroit ou Ã  un autre, se dÃ©place d'un chercheur de donnÃ©es Ã  un autre.  De plus, tous ces travaux sont unis par un postulat gÃ©nÃ©ralement acceptÃ© et incontestable: l'application de l'un ou l'autre algorithme d'apprentissage automatique dÃ©pend de la taille et de la nature des donnÃ©es disponibles et de la tÃ¢che Ã  accomplir. <br><br>  En plus de cela, en particulier les chercheurs de donnÃ©es insistÃ©s, partageant leur expÃ©rience, soulignent: <i>Â«Le choix d'une mÃ©thode d'Ã©valuation devrait dÃ©pendre en partie de vos donnÃ©es et de ce qui, Ã  votre avis, le modÃ¨le devrait Ãªtre bonÂ» (Â«Data Science: informations privilÃ©giÃ©es pour les dÃ©butants. Y compris le langage R, par Cathy O'Neill, Rachel Shutt)</i> . <br><a name="habracut"></a><br>  En d'autres termes, un statisticien / chercheur de donnÃ©es devrait avoir non seulement une expÃ©rience dans le domaine, mais Ã©galement un large Ã©ventail de connaissances diverses: <i>Â«Un chercheur de donnÃ©es est celui qui possÃ¨de des connaissances dans les domaines suivants: mathÃ©matiques, statistiques, gÃ©nie informatique, apprentissage automatique, visualisation, moyens d'Ã©changer des donnÃ©es ... Â»</i> (du mÃªme livre).  Seul un chargement approfondi des connaissances des domaines ci-dessus dans la tÃªte permet d'approcher l'apprentissage automatique et de trouver des solutions aux problÃ¨mes indiquÃ©s. <br><br>  Pour moi, ce dÃ©but convient tout Ã  fait Ã  un livre ordinaire d'un kilo et demi sur la science des donnÃ©es, ou Ã  un article d'histoire d'horreur scientifique avec des formules, des symboles et des gribouillis Ã  deux Ã©tages Â«sans valeurÂ» qui ont un impact grave et dÃ©primant sur les dÃ©butants dans le domaine de l'apprentissage automatique et juste par hasard intÃ©ressÃ© par cette direction lecteurs inexpÃ©rimentÃ©s, pas accablÃ©s de "connaissances nÃ©cessaires".  De plus, le nombre rond 10 des mÃªmes articles sur les 10 algorithmes d'apprentissage automatique les plus populaires ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">par exemple</a> ) ne fait que renforcer l'effet imposÃ©. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chez habr, ils se sont Ã©galement distinguÃ©s</a> : <i>Â«La rÃ©ponse Ã  la question:Â« Quel type d'algorithme d'apprentissage automatique dois-je utiliser? Â»Cela ressemble toujours Ã  ceci:Â« Selon les circonstances Â».</i>  <i>Le choix de l'algorithme dÃ©pend du volume, de la qualitÃ© et de la nature des donnÃ©es.</i>  <i>Cela dÃ©pend de la faÃ§on dont vous gÃ©rez le rÃ©sultat.</i>  <i>Cela dÃ©pend de la faÃ§on dont les instructions pour l'ordinateur qui le met en Å“uvre ont Ã©tÃ© crÃ©Ã©es Ã  partir de l'algorithme, et Ã©galement du temps dont vous disposez.</i>  <i>MÃªme les analystes de donnÃ©es les plus expÃ©rimentÃ©s ne vous diront pas quel algorithme est le meilleur avant de l'essayer. Â»</i> <br><br>  Sans aucun doute, toutes ces connaissances, ainsi que la persÃ©vÃ©rance et l'intÃ©rÃªt sont nÃ©cessaires et utiles pour obtenir de bons rÃ©sultats non seulement sur la voie de la comprÃ©hension de l'apprentissage automatique, mais aussi dans de nombreux autres domaines.  En outre, ils faciliteront la comprÃ©hension du fait que les algorithmes d'apprentissage automatique (ci-aprÃ¨s dÃ©nommÃ©s algorithmes) sont loin d'Ãªtre une douzaine;  mais ce n'est que plus tard, avec une Ã©tude indÃ©pendante. <br><br>  Mon objectif est de prÃ©senter au lecteur les algorithmes les plus utilisÃ©s d'un point de vue pratique et accessible.  (Le fait que je ne suis pas un programmeur et, en plus, pas un mathÃ©maticien (saint-saint-saint!) Devrait souligner l'intÃ©rÃªt pour le rÃ©cit. La formation d'ingÃ©nieur plus l'expÃ©rience dans le Â«sujet grandissentÂ» de 10 ans (juste une sorte de nombre magique ) - comme on dit, et toutes mes affaires, tous mes bagages avec lesquels je suis allÃ© directement Ã  l'apprentissage automatique. GrÃ¢ce Ã  mon expÃ©rience dans l'industrie pÃ©troliÃ¨re, des idÃ©es pour utiliser des rÃ©seaux de neurones artificiels et des algorithmes d'apprentissage automatique ont Ã©tÃ© trouvÃ©es tout de suite (lire - il fallait ensembles de donnÃ©es.) Il ne restait plus qu'Ã   Scarlet - apprendre Ã  tordre-tordre les donnÃ©es afin de les soumettre correctement Ã  l'entrÃ©e du "programme" et qui, en fait, l'algorithme Ã  choisir. Et puis dans un cercle vicieux. Je constate que mon chemin Ã©tait Ã©pineux et amusant - "des balles sifflaient au-dessus de ma tÃªte" (de m / f "Les Aventures de Funtik"), - mais j'ai quand mÃªme rÃ©ussi Ã  prendre des notes, et si l'intÃ©rÃªt est indiquÃ©, alors Ã  l'avenir je publierai d'autres messages.) <br><br>  Donc, je propose l'approche de l 'Â«usinageÂ» d'autre part: pourquoi ne pas alimenter votre ensemble de donnÃ©es existant (dans les exemples, vous chargerez des ensembles de donnÃ©es qui peuvent Ãªtre facilement formÃ©s) Ã  beaucoup d'algorithmes Ã  la fois, et en fonction des rÃ©sultats, dÃ©cidez de celui auquel vous devez prÃªter une attention particuliÃ¨re Ã©tude approfondie et sÃ©lection des paramÃ¨tres optimaux qui amÃ©liorent le rÃ©sultat.  De plus, la principale valeur de la mÃ©thode discutÃ©e ci-dessus est que ses rÃ©sultats rÃ©pondront Ã  la question de la valeur de votre ensemble de donnÃ©es: <i>"commencez par rÃ©soudre le problÃ¨me et assurez-vous que vous avez quelque chose Ã  optimiser"</i> (Ã©galement de certains puis les statistiques insistantes sont allÃ©es, "respect" pour lui, bon conseil!). <br><br>  Comment est-il fait? <br><br>  On sait que l'essentiel des problÃ¨mes rÃ©solus Ã  l'aide d'algorithmes concerne les problÃ¨mes de classification (classification) et d'analyse de rÃ©gression (analyse prÃ©dictive).  Par <i>classification,</i> on entend une diffÃ©renciation constante des unitÃ©s d'observation (instances) d'un ensemble de donnÃ©es vers une certaine catÃ©gorie (classe) en fonction des rÃ©sultats de la formation.  <i>L'analyse de rÃ©gression</i> est un ensemble de mÃ©thodes et de processus statistiques permettant d'Ã©valuer la relation entre les variables [ <i>Statistics: Textbook / Ed.</i>  <i>prof.</i>  <i>M.R.</i>  <i>Efimova.</i>  <i>- M.: INFRA-M, 2002</i> ].  Le but de l'analyse de rÃ©gression est d'Ã©valuer la valeur d'une variable de sortie continue Ã  partir des valeurs des variables d'entrÃ©e [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> ]. <br><br>  Nous laissons de cÃ´tÃ© le fait que l'analyse de rÃ©gression dispose de deux mÃ©thodes diffÃ©rentes: la modÃ©lisation prÃ©dictive et la prÃ©vision.  Nous notons seulement que s'il existe une sÃ©rie temporelle (donnÃ©es de sÃ©ries temporelles), alors en utilisant un modÃ¨le de rÃ©gression basÃ© sur une tendance explicite, soumise Ã  la stationnaritÃ© (constance), la prÃ©vision peut Ãªtre effectuÃ©e.  Si les conditions de formation des niveaux de la sÃ©rie temporelle changent, c'est-Ã -dire que le processus non stationnaire n'est pas observÃ©, alors c'est Ã  la modÃ©lisation prÃ©dictive.  ParticuliÃ¨rement destinÃ© Ã  la maÃ®trise totale du ML, je vous propose de lire cet article en anglais: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> .  Si une discussion se lÃ¨ve Ã  ce sujet, je serai heureux d'y participer. <br><br>  Ã‰tant donnÃ© que les sÃ©ries chronologiques ne seront pas utilisÃ©es dans les exemples de cet article, le terme <i>prÃ©vision</i> fait rÃ©fÃ©rence Ã  <i>l'analyse prÃ©dictive</i> . <br><br>  Pour rÃ©soudre les problÃ¨mes de classification et de prÃ©vision, toute une gamme d'algorithmes convient, dont certains seront examinÃ©s plus loin.  Pour plus de commoditÃ©, le texte suivant sera divisÃ© en deux parties: dans la premiÃ¨re, nous considÃ©rons les algorithmes de classification les plus courants, la seconde que nous consacrons aux algorithmes d'analyse de rÃ©gression.  Pour chaque partie, un ensemble de donnÃ©es Â«jouetÂ» chargÃ© Ã  partir de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la bibliothÃ¨que scikit-learn</a> (v0.21.3): <i>ensemble de donnÃ©es Ã  chiffres (classification)</i> et <i>ensemble de donnÃ©es sur les prix des maisons Ã  boston (rÃ©gression)</i> sera prÃ©sentÃ©, ainsi que des liens vers chaque algorithme de la bibliothÃ¨que scikit-learn pour auto-examen et, Ã©ventuellement, Ã©tude. <br><br>  Tous les exemples de code sont exÃ©cutÃ©s dans la console <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IDE Spyder</a> 3.3.3 sur Python 3.7.3. <br><br><h3>  ProblÃ¨me de classification </h3><br>  Tout d'abord, nous importons les modules et fonctions nÃ©cessaires que nous utiliserons pour rÃ©soudre le problÃ¨me de la classification des donnÃ©es: <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      from sklearn.datasets import load_digits from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression from sklearn.discriminant_analysis import LinearDiscriminantAnalysis from sklearn.neighbors import KNeighborsClassifier from sklearn.tree import DecisionTreeClassifier from sklearn.naive_bayes import GaussianNB from sklearn.svm import LinearSVC from sklearn.svm import SVC from sklearn.neural_network import MLPClassifier from sklearn.ensemble import BaggingClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.ensemble import ExtraTreesClassifier from sklearn.ensemble import AdaBoostClassifier from sklearn.ensemble import GradientBoostingClassifier from sklearn.model_selection import KFold from sklearn.model_selection import cross_val_score from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import Normalizer from matplotlib import pyplot</span></span></code> </pre> <br>  TÃ©lÃ©chargez le jeu de donnÃ©es 'digits' directement depuis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le module 'sklearn.datasets'</a> : <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    dataset = load_digits()</span></span></code> </pre> <br>  IDE Spyder fournit un outil pratique "Variable Manager", qui est utile Ã  tout moment pour Ã©tudier l'apprentissage automatique (au moins pour moi), comme d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">autres "trucs"</a> : <br><br>  ExÃ©cutez le code.  Dans la console "gestionnaire de variables", cliquez sur la variable d' <i>ensemble de donnÃ©es</i> .  Le dictionnaire suivant s'affiche: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f9f/362/64a/f9f36264a8a368644793b6f4ed7ad045.png" alt="image"><br><br>  La description de l'ensemble de donnÃ©es est la suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/887/659/b2b/887659b2bc79bfd532c30d6ddee8aa5e.png" alt="image"><br><br>  Dans cet exemple, nous n'avons pas besoin de la clÃ© Â«imagesÂ», nous affectons donc la variable Â«dataÂ» Ã  <i>X</i> , qui est un tableau NumPy multidimensionnel avec un ensemble d'attributs, 1797 lignes dans 64 colonnes et la variable <i>Y</i> Ã  Â«cibleÂ», un tableau multidimensionnel NumPy avec un marqueur pour chaque chaÃ®ne. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    # dataset = load_digits() X = dataset.data Y = dataset.target</span></span></code> </pre> <br>  Ensuite, nous divisons l'ensemble de donnÃ©es en parties d'apprentissage et de test, configurons les paramÃ¨tres pour Ã©valuer les algorithmes (la validation croisÃ©e est utilisÃ©e [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deux</a> ]), dÃ©finissant la mÃ©trique `` prÃ©cision '' dans le paramÃ¨tre `` scoring '' [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> ].  La prÃ©cision est la proportion d'objets correctement classÃ©s par rapport au nombre total d'objets.  Plus le rÃ©sultat est proche de 1, mieux c'est [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">link</a> ].  De plus, dans l'un des livres, il a Ã©tÃ© constatÃ© que les rÃ©sultats de 0,95 (ou 95%) et plus sont considÃ©rÃ©s comme excellents. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#         test_size = 0.2 seed = 7 X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed) #     num_folds = 10 n_estimators = 100 scoring = 'accuracy'</span></span></code> </pre> <br>  <i>Laissez les</i> variables <i>X_train</i> et <i>Y_train Ãªtre utilisÃ©es</i> Ã  des fins de formation, <i>X_test</i> et <i>Y_test</i> pour le dÃ©veloppement des valeurs de prÃ©vision.  Dans ce cas, la variable <i>Y_test n'est</i> pas impliquÃ©e dans le calcul de la prÃ©vision: en utilisant la mÃ©thode du `` score '', qui est la mÃªme pour chacun des algorithmes prÃ©sentÃ©s ci-dessous, nous calculerons les bonnes rÃ©ponses en utilisant la mÃ©trique `` prÃ©cision ''.  Cela nous permettra de juger comment l'algorithme fait face Ã  la tÃ¢che.  Je ne dis pas, pour notre part, il est si humainement vil de ne pas inciter la voiture avec les bonnes rÃ©ponses, mais comment vÃ©rifier ses performances autrement? <br><br>  Vous trouverez ci-dessous une liste d'algorithmes avec lesquels nous alimentons l'ensemble de donnÃ©es.  Sur la base des rÃ©sultats des calculs, nous conclurons quel algorithme (lequel des algorithmes) montre la plus grande efficacitÃ©.  Cette mÃ©thode peut trÃ¨s bien Ãªtre qualifiÃ©e de <b>Â«test blitz d'algorithmes d'apprentissage automatiqueÂ»</b> (ci-aprÃ¨s - test blitz). <br><br>  Pour plus de commoditÃ©, les informations seront abrÃ©gÃ©es Ã  cÃ´tÃ© de chaque algorithme.  Il convient de noter que les paramÃ¨tres de chaque algorithme sont acceptÃ©s par dÃ©faut (par dÃ©faut), Ã  l'exception de certains points, afin de fournir des conditions Ã©gales. <br><br><h4>  Algorithmes linÃ©aires: </h4><br>  - RÃ©gression logistique * / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RÃ©gression logistique</a> ('LR') <br>  <i>* Le mot Â«rÃ©gressionÂ» peut prÃªter Ã  confusion.</i>  <i>Mais n'oubliez pas que la Â«rÃ©gression logistiqueÂ» est un algorithme de classification</i> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Analyse discriminante linÃ©aire</a> (Â«LDAÂ») <br><br><h4>  Algorithmes non linÃ©aires: </h4><br>  - MÃ©thode des k voisins les plus proches (classification) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">K-Neighbors Classifier</a> (Â«KNNÂ») <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classificateur d'arbre de dÃ©cision</a> (Â«CARTÂ») <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Naive Bayes Classifier</a> (Â«NBÂ») <br>  - MÃ©thode de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">classification des vecteurs de support linÃ©aire</a> (Classification) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classification des vecteurs de support linÃ©aire</a> (Â«LSVCÂ») <br>  - MÃ©thode du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vecteur de support</a> (Classification) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classification du vecteur de support C</a> (Â«SVCÂ») <br><br><h4>  Algorithme de rÃ©seau de neurones artificiels: </h4><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Perceptron multicouches</a> / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Perceptrons multicouches</a> (Â«MLPÂ») <br><br><h4>  Algorithmes d'ensemble: </h4><br>  - Bagging (classification) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bagging Classifier</a> ('BG') (Bagging = Bootstrap agrÃ©gation) <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classification alÃ©atoire des forÃªts</a> (Â«RFÂ») <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classificateur d'arbres supplÃ©mentaires</a> (Â«ETÂ») <br>  - AdaBoost (classification) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AdaBoost Classifier</a> (Â«ABÂ») (AdaBoost = Adaptive Boosting) <br>  - Amplification de gradient (classification) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classificateur de renforcement de gradient</a> ('GB') <br><br>  Ainsi, la liste des Â«modÃ¨lesÂ» contient les modÃ¨les suivants: <br><br><pre> <code class="python hljs">models = [] models.append((<span class="hljs-string"><span class="hljs-string">'LR'</span></span>, LogisticRegression())) models.append((<span class="hljs-string"><span class="hljs-string">'LDA'</span></span>, LinearDiscriminantAnalysis())) models.append((<span class="hljs-string"><span class="hljs-string">'KNN'</span></span>, KNeighborsClassifier())) models.append((<span class="hljs-string"><span class="hljs-string">'CART'</span></span>, DecisionTreeClassifier())) models.append((<span class="hljs-string"><span class="hljs-string">'NB'</span></span>, GaussianNB())) models.append((<span class="hljs-string"><span class="hljs-string">'LSVC'</span></span>, LinearSVC())) models.append((<span class="hljs-string"><span class="hljs-string">'SVC'</span></span>, SVC())) models.append((<span class="hljs-string"><span class="hljs-string">'MLP'</span></span>, MLPClassifier())) models.append((<span class="hljs-string"><span class="hljs-string">'BG'</span></span>, BaggingClassifier(n_estimators=n_estimators))) models.append((<span class="hljs-string"><span class="hljs-string">'RF'</span></span>, RandomForestClassifier(n_estimators=n_estimators))) models.append((<span class="hljs-string"><span class="hljs-string">'ET'</span></span>, ExtraTreesClassifier(n_estimators=n_estimators))) models.append((<span class="hljs-string"><span class="hljs-string">'AB'</span></span>, AdaBoostClassifier(n_estimators=n_estimators, algorithm=<span class="hljs-string"><span class="hljs-string">'SAMME'</span></span>))) models.append((<span class="hljs-string"><span class="hljs-string">'GB'</span></span>, GradientBoostingClassifier(n_estimators=n_estimators)))</code> </pre> <br>  Comme dÃ©jÃ  mentionnÃ©, l'efficacitÃ© de chaque algorithme est Ã©valuÃ©e en utilisant la validation croisÃ©e.  En consÃ©quence, un message s'affiche (msg - abrÃ©viation du message) contenant les informations suivantes: nom du modÃ¨le sous la forme d'une abrÃ©viation, score moyen de 10 fois la validation croisÃ©e des donnÃ©es d'entraÃ®nement (`` prÃ©cision '' mÃ©trique), l'Ã©cart type est indiquÃ© entre parenthÃ¨ses , ainsi que la valeur de la mÃ©trique de Â«prÃ©cisionÂ» sur les donnÃ©es de test. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      scores = [] names = [] results = [] predictions = [] msg_row = [] for name, model in models: kfold = KFold(n_splits=num_folds, random_state=seed) cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring) names.append(name) results.append(cv_results) m_fit = model.fit(X_train, Y_train) m_predict = model.predict(X_test) predictions.append(m_predict) m_score = model.score(X_test, Y_test) scores.append(m_score) msg = "%s: train = %.3f (%.3f) / test = %.3f" % (name, cv_results.mean(), cv_results.std(), m_score) msg_row.append(msg) print(msg)</span></span></code> </pre> <br>  AprÃ¨s avoir exÃ©cutÃ© le code, nous obtenons les rÃ©sultats suivants: <br><br><pre> <code class="python hljs">LR: train = <span class="hljs-number"><span class="hljs-number">0.957</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.948</span></span> LDA: train = <span class="hljs-number"><span class="hljs-number">0.951</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> KNN: train = <span class="hljs-number"><span class="hljs-number">0.985</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.981</span></span> CART: train = <span class="hljs-number"><span class="hljs-number">0.843</span></span> (<span class="hljs-number"><span class="hljs-number">0.033</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.830</span></span> NB: train = <span class="hljs-number"><span class="hljs-number">0.819</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.806</span></span> LSVC: train = <span class="hljs-number"><span class="hljs-number">0.942</span></span> (<span class="hljs-number"><span class="hljs-number">0.017</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.928</span></span> SVC: train = <span class="hljs-number"><span class="hljs-number">0.343</span></span> (<span class="hljs-number"><span class="hljs-number">0.079</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.342</span></span> MLP: train = <span class="hljs-number"><span class="hljs-number">0.972</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.961</span></span> BG: train = <span class="hljs-number"><span class="hljs-number">0.952</span></span> (<span class="hljs-number"><span class="hljs-number">0.021</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.941</span></span> RF: train = <span class="hljs-number"><span class="hljs-number">0.968</span></span> (<span class="hljs-number"><span class="hljs-number">0.017</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.965</span></span> ET: train = <span class="hljs-number"><span class="hljs-number">0.980</span></span> (<span class="hljs-number"><span class="hljs-number">0.010</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.975</span></span> AB: train = <span class="hljs-number"><span class="hljs-number">0.827</span></span> (<span class="hljs-number"><span class="hljs-number">0.049</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.823</span></span> GB: train = <span class="hljs-number"><span class="hljs-number">0.964</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.968</span></span></code> </pre> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Diagramme d'Ã©tendue</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Â«boÃ®te avec moustacheÂ»</a> ) (diagramme ou diagramme en boÃ®te et moustaches, diagramme en boÃ®te): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e3e/301/4c9/e3e3014c9931e3af6b7ea01eda90a0d0.png" alt="image"><br><br>  Ã€ la suite d'un test Ã©clair sur des donnÃ©es brutes, on peut voir que les plus efficaces sur les donnÃ©es de test Ã©taient les algorithmes Â«KNNÂ» (k-voisins les plus proches), Â«ETÂ» (extra-arbres), Â«GBÂ» (gradient Â«boostingÂ»), 'RF' (forÃªt alÃ©atoire) et 'MLP' (perceptron multicouche): <br><br><pre> <code class="python hljs">KNN: train = <span class="hljs-number"><span class="hljs-number">0.985</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.981</span></span> ET: train = <span class="hljs-number"><span class="hljs-number">0.980</span></span> (<span class="hljs-number"><span class="hljs-number">0.010</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.975</span></span> GB: train = <span class="hljs-number"><span class="hljs-number">0.964</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.968</span></span> RF: train = <span class="hljs-number"><span class="hljs-number">0.968</span></span> (<span class="hljs-number"><span class="hljs-number">0.017</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.965</span></span> MLP: train = <span class="hljs-number"><span class="hljs-number">0.972</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.961</span></span> LR: train = <span class="hljs-number"><span class="hljs-number">0.957</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.948</span></span> LDA: train = <span class="hljs-number"><span class="hljs-number">0.951</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> BG: train = <span class="hljs-number"><span class="hljs-number">0.952</span></span> (<span class="hljs-number"><span class="hljs-number">0.021</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.941</span></span> LSVC: train = <span class="hljs-number"><span class="hljs-number">0.942</span></span> (<span class="hljs-number"><span class="hljs-number">0.017</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.928</span></span> CART: train = <span class="hljs-number"><span class="hljs-number">0.843</span></span> (<span class="hljs-number"><span class="hljs-number">0.033</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.830</span></span> AB: train = <span class="hljs-number"><span class="hljs-number">0.827</span></span> (<span class="hljs-number"><span class="hljs-number">0.049</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.823</span></span> NB: train = <span class="hljs-number"><span class="hljs-number">0.819</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.806</span></span> SVC: train = <span class="hljs-number"><span class="hljs-number">0.343</span></span> (<span class="hljs-number"><span class="hljs-number">0.079</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.342</span></span></code> </pre> <br>  Cependant, de nombreux algorithmes sont trÃ¨s pointilleux sur les donnÃ©es qui leur sont fournies.  Par consÃ©quent, l'une des Ã©tapes nÃ©cessaires est la soi-disant prÃ©paration prÃ©liminaire des donnÃ©es (prÃ©traitement des donnÃ©es [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> ]) <br><br>  Cependant, il arrive que l'algorithme montre les meilleurs rÃ©sultats sans traitement prÃ©alable.  D'oÃ¹ la recommandation suivante: inclure dans le test Blitz plusieurs transformations de l'ensemble de donnÃ©es d'origine et, aprÃ¨s avoir effectuÃ© les calculs, comparer les rÃ©sultats afin de saisir l'essence du problÃ¨me dans son ensemble. <br><br>  Les mÃ©thodes de prÃ©paration des donnÃ©es prÃ©liminaires les plus couramment utilisÃ©es sont les suivantes: <br><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">normalisation;</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><br></a> <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mise Ã  l'Ã©chelle</a> (la plage par dÃ©faut est [0, 1]); <br><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">normalisation</a> <br><br>  Ces opÃ©rations avec Ã©valuation ultÃ©rieure peuvent Ãªtre automatisÃ©es et placÃ©es sur le convoyeur Ã  l'aide de l'outil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pipeline</a> . <br><br>  Un extrait de code avec normalisation des donnÃ©es source est le suivant: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># -      #    ( StandardScaler) pipelines = [] pipelines.append(('SS_LR', Pipeline([('Scaler', StandardScaler()), ('LR', LogisticRegression())]))) pipelines.append(('SS_LDA', Pipeline([('Scaler', StandardScaler()), ('LDA', LinearDiscriminantAnalysis())]))) pipelines.append(('SS_KNN', Pipeline([('Scaler', StandardScaler()), ('KNN', KNeighborsClassifier())]))) pipelines.append(('SS_CART', Pipeline([('Scaler', StandardScaler()), ('CART', DecisionTreeClassifier())]))) pipelines.append(('SS_NB', Pipeline([('Scaler', StandardScaler()), ('NB', GaussianNB())]))) pipelines.append(('SS_LSVC', Pipeline([('Scaler', StandardScaler()), ('LSVC', LinearSVC())]))) pipelines.append(('SS_SVC', Pipeline([('Scaler', StandardScaler()), ('SVC', SVC())]))) pipelines.append(('SS_MLP', Pipeline([('Scaler', StandardScaler()), ('MLP', MLPClassifier())]))) pipelines.append(('SS_BG', Pipeline([('Scaler', StandardScaler()), ('BG', BaggingClassifier(n_estimators=n_estimators))]))) pipelines.append(('SS_RF', Pipeline([('Scaler', StandardScaler()), ('RF', RandomForestClassifier(n_estimators=n_estimators))]))) pipelines.append(('SS_ET', Pipeline([('Scaler', StandardScaler()), ('ET', ExtraTreesClassifier(n_estimators=n_estimators))]))) pipelines.append(('SS_AB', Pipeline([('Scaler', StandardScaler()), ('AB', AdaBoostClassifier(n_estimators=n_estimators, algorithm='SAMME'))]))) pipelines.append(('SS_GB', Pipeline([('Scaler', StandardScaler()), ('GB', GradientBoostingClassifier(n_estimators=n_estimators))]))) #      scores_SS = [] names_SS = [] results_SS = [] predictions_SS = [] msg_SS = [] for name, model in pipelines: kfold = KFold(n_splits=num_folds, random_state=seed) cv_results = cross_val_score(model, X_train, Y_train, cv=kfold) names_SS.append(name) results_SS.append(cv_results) m_fit = model.fit(X_train, Y_train) m_predict = model.predict(X_test) predictions_SS.append(m_predict) m_score = model.score(X_test, Y_test) scores_SS.append(m_score) msg = "%s: train = %.3f (%.3f) / test = %.3f" % (name, cv_results.mean(), cv_results.std(), m_score) msg_SS.append(msg) print(msg) #    (StandardScaler) fig = pyplot.figure() fig.suptitle('     . ') ax = fig.add_subplot(111) red_square = dict(markerfacecolor='r', marker='s') pyplot.boxplot(results_SS, flierprops=red_square) ax.set_xticklabels(names_SS, rotation=45) pyplot.show()</span></span></code> </pre> <br>  Notez l'ajout de Â«_SSÂ» (abrÃ©viation de StandardScaler) pour rÃ©pertorier les noms.  Ceci est fait afin de ne pas empiler les rÃ©sultats, ainsi que de les visualiser commodÃ©ment en utilisant le "gestionnaire de variables" aprÃ¨s que les conversions soient effectuÃ©es. <br><br>  L'exÃ©cution d'un extrait de code produit les rÃ©sultats suivants: <br><br><pre> <code class="python hljs">SS_LR: train = <span class="hljs-number"><span class="hljs-number">0.958</span></span> (<span class="hljs-number"><span class="hljs-number">0.015</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.949</span></span> SS_LDA: train = <span class="hljs-number"><span class="hljs-number">0.951</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> SS_KNN: train = <span class="hljs-number"><span class="hljs-number">0.968</span></span> (<span class="hljs-number"><span class="hljs-number">0.023</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.970</span></span> SS_CART: train = <span class="hljs-number"><span class="hljs-number">0.853</span></span> (<span class="hljs-number"><span class="hljs-number">0.036</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.835</span></span> SS_NB: train = <span class="hljs-number"><span class="hljs-number">0.756</span></span> (<span class="hljs-number"><span class="hljs-number">0.046</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.751</span></span> SS_LSVC: train = <span class="hljs-number"><span class="hljs-number">0.945</span></span> (<span class="hljs-number"><span class="hljs-number">0.018</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.941</span></span> SS_SVC: train = <span class="hljs-number"><span class="hljs-number">0.976</span></span> (<span class="hljs-number"><span class="hljs-number">0.015</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.990</span></span> SS_MLP: train = <span class="hljs-number"><span class="hljs-number">0.976</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.973</span></span> SS_BG: train = <span class="hljs-number"><span class="hljs-number">0.947</span></span> (<span class="hljs-number"><span class="hljs-number">0.018</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.948</span></span> SS_RF: train = <span class="hljs-number"><span class="hljs-number">0.973</span></span> (<span class="hljs-number"><span class="hljs-number">0.016</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.970</span></span> SS_ET: train = <span class="hljs-number"><span class="hljs-number">0.980</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.975</span></span> SS_AB: train = <span class="hljs-number"><span class="hljs-number">0.827</span></span> (<span class="hljs-number"><span class="hljs-number">0.049</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.823</span></span> SS_GB: train = <span class="hljs-number"><span class="hljs-number">0.964</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.968</span></span></code> </pre> <br>  BoÃ®te Ã  moustache (StandardScaler): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8f7/a0d/bf7/8f7a0dbf718cfdd7b061ffd43a7bed8e.png" alt="image"><br><br>  Selon les rÃ©sultats du calcul sur des donnÃ©es standardisÃ©es, les algorithmes suivants sont devenus leaders: <br><br><pre> <code class="python hljs">SS_SVC: train = <span class="hljs-number"><span class="hljs-number">0.976</span></span> (<span class="hljs-number"><span class="hljs-number">0.015</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.990</span></span> SS_ET: train = <span class="hljs-number"><span class="hljs-number">0.980</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.975</span></span> SS_MLP: train = <span class="hljs-number"><span class="hljs-number">0.976</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.973</span></span> SS_KNN: train = <span class="hljs-number"><span class="hljs-number">0.968</span></span> (<span class="hljs-number"><span class="hljs-number">0.023</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.970</span></span> SS_RF: train = <span class="hljs-number"><span class="hljs-number">0.973</span></span> (<span class="hljs-number"><span class="hljs-number">0.016</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.970</span></span> SS_GB: train = <span class="hljs-number"><span class="hljs-number">0.964</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.968</span></span> SS_LR: train = <span class="hljs-number"><span class="hljs-number">0.958</span></span> (<span class="hljs-number"><span class="hljs-number">0.015</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.949</span></span> SS_BG: train = <span class="hljs-number"><span class="hljs-number">0.947</span></span> (<span class="hljs-number"><span class="hljs-number">0.018</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.948</span></span> SS_LDA: train = <span class="hljs-number"><span class="hljs-number">0.951</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> SS_LSVC: train = <span class="hljs-number"><span class="hljs-number">0.945</span></span> (<span class="hljs-number"><span class="hljs-number">0.018</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.941</span></span> SS_CART: train = <span class="hljs-number"><span class="hljs-number">0.853</span></span> (<span class="hljs-number"><span class="hljs-number">0.036</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.835</span></span> SS_AB: train = <span class="hljs-number"><span class="hljs-number">0.827</span></span> (<span class="hljs-number"><span class="hljs-number">0.049</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.823</span></span> SS_NB: train = <span class="hljs-number"><span class="hljs-number">0.756</span></span> (<span class="hljs-number"><span class="hljs-number">0.046</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.751</span></span></code> </pre> <br>  Comme on dit, des chiffons aux richesses: la mÃ©thode des vecteurs supports (Â«SVCÂ»), alimentÃ©e par des donnÃ©es standardisÃ©es, a fait le reste, montrant un excellent rÃ©sultat.  Lors de la vÃ©rification Â«manuelleÂ», en comparant les valeurs des variables <i>Y_test</i> et <i>predictions_SS [6]</i> , l'algorithme n'a pas mÃ¢chÃ© seulement quelques valeurs. <br><br>  Ensuite, le mÃªme code est exÃ©cutÃ© pour les fonctions MinMaxScaler (mise Ã  l'Ã©chelle) et Normalizer (normalisation).  Je ne donnerai pas le code complet dans l'article.  Vous pouvez le tÃ©lÃ©charger depuis mon rÃ©fÃ©rentiel sur GitHub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> . <br><br>  N'oubliez pas de vous arrÃªter un moment et de vous moquer de vous Ã  des fins Ã©ducatives uniquement!  :) <br><br>  Par consÃ©quent, aprÃ¨s avoir parcouru tout le code, nous obtenons les rÃ©sultats suivants: <br><br><pre> <code class="python hljs">LR: train = <span class="hljs-number"><span class="hljs-number">0.957</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.948</span></span> LDA: train = <span class="hljs-number"><span class="hljs-number">0.951</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> KNN: train = <span class="hljs-number"><span class="hljs-number">0.985</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.981</span></span> CART: train = <span class="hljs-number"><span class="hljs-number">0.843</span></span> (<span class="hljs-number"><span class="hljs-number">0.033</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.830</span></span> NB: train = <span class="hljs-number"><span class="hljs-number">0.819</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.806</span></span> LSVC: train = <span class="hljs-number"><span class="hljs-number">0.942</span></span> (<span class="hljs-number"><span class="hljs-number">0.017</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.928</span></span> SVC: train = <span class="hljs-number"><span class="hljs-number">0.343</span></span> (<span class="hljs-number"><span class="hljs-number">0.079</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.342</span></span> MLP: train = <span class="hljs-number"><span class="hljs-number">0.972</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.961</span></span> BG: train = <span class="hljs-number"><span class="hljs-number">0.952</span></span> (<span class="hljs-number"><span class="hljs-number">0.021</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.941</span></span> RF: train = <span class="hljs-number"><span class="hljs-number">0.968</span></span> (<span class="hljs-number"><span class="hljs-number">0.017</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.965</span></span> ET: train = <span class="hljs-number"><span class="hljs-number">0.980</span></span> (<span class="hljs-number"><span class="hljs-number">0.010</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.975</span></span> AB: train = <span class="hljs-number"><span class="hljs-number">0.827</span></span> (<span class="hljs-number"><span class="hljs-number">0.049</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.823</span></span> GB: train = <span class="hljs-number"><span class="hljs-number">0.964</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.968</span></span> SS_LR: train = <span class="hljs-number"><span class="hljs-number">0.958</span></span> (<span class="hljs-number"><span class="hljs-number">0.015</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.949</span></span> SS_LDA: train = <span class="hljs-number"><span class="hljs-number">0.951</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> SS_KNN: train = <span class="hljs-number"><span class="hljs-number">0.968</span></span> (<span class="hljs-number"><span class="hljs-number">0.023</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.970</span></span> SS_CART: train = <span class="hljs-number"><span class="hljs-number">0.853</span></span> (<span class="hljs-number"><span class="hljs-number">0.036</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.835</span></span> SS_NB: train = <span class="hljs-number"><span class="hljs-number">0.756</span></span> (<span class="hljs-number"><span class="hljs-number">0.046</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.751</span></span> SS_LSVC: train = <span class="hljs-number"><span class="hljs-number">0.945</span></span> (<span class="hljs-number"><span class="hljs-number">0.018</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.941</span></span> SS_SVC: train = <span class="hljs-number"><span class="hljs-number">0.976</span></span> (<span class="hljs-number"><span class="hljs-number">0.015</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.990</span></span> SS_MLP: train = <span class="hljs-number"><span class="hljs-number">0.976</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.973</span></span> SS_BG: train = <span class="hljs-number"><span class="hljs-number">0.947</span></span> (<span class="hljs-number"><span class="hljs-number">0.018</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.948</span></span> SS_RF: train = <span class="hljs-number"><span class="hljs-number">0.973</span></span> (<span class="hljs-number"><span class="hljs-number">0.016</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.970</span></span> SS_ET: train = <span class="hljs-number"><span class="hljs-number">0.980</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.975</span></span> SS_AB: train = <span class="hljs-number"><span class="hljs-number">0.827</span></span> (<span class="hljs-number"><span class="hljs-number">0.049</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.823</span></span> SS_GB: train = <span class="hljs-number"><span class="hljs-number">0.964</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.968</span></span> MMS_LR: train = <span class="hljs-number"><span class="hljs-number">0.961</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.953</span></span> MMS_LDA: train = <span class="hljs-number"><span class="hljs-number">0.951</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> MMS_KNN: train = <span class="hljs-number"><span class="hljs-number">0.985</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.981</span></span> MMS_CART: train = <span class="hljs-number"><span class="hljs-number">0.850</span></span> (<span class="hljs-number"><span class="hljs-number">0.027</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.840</span></span> MMS_NB: train = <span class="hljs-number"><span class="hljs-number">0.796</span></span> (<span class="hljs-number"><span class="hljs-number">0.045</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.786</span></span> MMS_LSVC: train = <span class="hljs-number"><span class="hljs-number">0.964</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.958</span></span> MMS_SVC: train = <span class="hljs-number"><span class="hljs-number">0.963</span></span> (<span class="hljs-number"><span class="hljs-number">0.016</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.956</span></span> MMS_MLP: train = <span class="hljs-number"><span class="hljs-number">0.972</span></span> (<span class="hljs-number"><span class="hljs-number">0.011</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.963</span></span> MMS_BG: train = <span class="hljs-number"><span class="hljs-number">0.948</span></span> (<span class="hljs-number"><span class="hljs-number">0.024</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> MMS_RF: train = <span class="hljs-number"><span class="hljs-number">0.973</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.968</span></span> MMS_ET: train = <span class="hljs-number"><span class="hljs-number">0.983</span></span> (<span class="hljs-number"><span class="hljs-number">0.010</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.981</span></span> MMS_AB: train = <span class="hljs-number"><span class="hljs-number">0.827</span></span> (<span class="hljs-number"><span class="hljs-number">0.049</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.823</span></span> MMS_GB: train = <span class="hljs-number"><span class="hljs-number">0.963</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.968</span></span> N_LR: train = <span class="hljs-number"><span class="hljs-number">0.938</span></span> (<span class="hljs-number"><span class="hljs-number">0.020</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.919</span></span> N_LDA: train = <span class="hljs-number"><span class="hljs-number">0.952</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.949</span></span> N_KNN: train = <span class="hljs-number"><span class="hljs-number">0.981</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.985</span></span> N_CART: train = <span class="hljs-number"><span class="hljs-number">0.834</span></span> (<span class="hljs-number"><span class="hljs-number">0.028</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.825</span></span> N_NB: train = <span class="hljs-number"><span class="hljs-number">0.825</span></span> (<span class="hljs-number"><span class="hljs-number">0.043</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.805</span></span> N_LSVC: train = <span class="hljs-number"><span class="hljs-number">0.960</span></span> (<span class="hljs-number"><span class="hljs-number">0.014</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.953</span></span> N_SVC: train = <span class="hljs-number"><span class="hljs-number">0.551</span></span> (<span class="hljs-number"><span class="hljs-number">0.053</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.586</span></span> N_MLP: train = <span class="hljs-number"><span class="hljs-number">0.963</span></span> (<span class="hljs-number"><span class="hljs-number">0.018</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.946</span></span> N_BG: train = <span class="hljs-number"><span class="hljs-number">0.949</span></span> (<span class="hljs-number"><span class="hljs-number">0.016</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.938</span></span> N_RF: train = <span class="hljs-number"><span class="hljs-number">0.973</span></span> (<span class="hljs-number"><span class="hljs-number">0.015</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.970</span></span> N_ET: train = <span class="hljs-number"><span class="hljs-number">0.982</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.980</span></span> N_AB: train = <span class="hljs-number"><span class="hljs-number">0.825</span></span> (<span class="hljs-number"><span class="hljs-number">0.040</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.820</span></span> N_GB: train = <span class="hljs-number"><span class="hljs-number">0.953</span></span> (<span class="hljs-number"><span class="hljs-number">0.022</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.956</span></span></code> </pre> <br>  RÃ©sultats du Â«Top 5Â»: <br><br><pre> <code class="python hljs">SS_SVC: train = <span class="hljs-number"><span class="hljs-number">0.976</span></span> (<span class="hljs-number"><span class="hljs-number">0.015</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.990</span></span> N_KNN: train = <span class="hljs-number"><span class="hljs-number">0.981</span></span> (<span class="hljs-number"><span class="hljs-number">0.012</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.985</span></span> KNN: train = <span class="hljs-number"><span class="hljs-number">0.985</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.981</span></span> MMS_KNN: train = <span class="hljs-number"><span class="hljs-number">0.985</span></span> (<span class="hljs-number"><span class="hljs-number">0.013</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.981</span></span> MMS_ET: train = <span class="hljs-number"><span class="hljs-number">0.983</span></span> (<span class="hljs-number"><span class="hljs-number">0.010</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.981</span></span></code> </pre> <br>  Ainsi, selon les rÃ©sultats d'un test Ã©clair d'algorithmes d'apprentissage automatique pour rÃ©soudre le problÃ¨me de classification de l'ensemble de donnÃ©es `` chiffres '', les algorithmes d'apprentissage automatique les plus appropriÃ©s sont: la mÃ©thode k-voisins les plus proches ('KNN'), la mÃ©thode des vecteurs de support ('SVC') et les arbres supplÃ©mentaires (Â«ETÂ»).  Ces algorithmes devraient faire l'objet d'une plus grande attention au dÃ©veloppement ultÃ©rieur des rÃ©sultats visant Ã  accroÃ®tre l'efficacitÃ© des calculs.  Tout, comme on dit, est rÃ©soluble. <br><br>  Et sur cette note soulevÃ©e, passez en douceur Ã  la 2Ã¨me partie. <br><br><h3>  ProblÃ¨me de prÃ©vision </h3><br>  On bouge sur le pouce: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      from sklearn.datasets import load_boston from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression from sklearn.linear_model import Ridge from sklearn.linear_model import Lasso from sklearn.linear_model import ElasticNet from sklearn.linear_model import LarsCV from sklearn.linear_model import BayesianRidge from sklearn.neighbors import KNeighborsRegressor from sklearn.tree import DecisionTreeRegressor from sklearn.svm import LinearSVR from sklearn.svm import SVR from sklearn.ensemble import AdaBoostRegressor from sklearn.ensemble import BaggingRegressor from sklearn.ensemble import ExtraTreesRegressor from sklearn.ensemble import GradientBoostingRegressor from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import KFold from sklearn.model_selection import cross_val_score from sklearn.pipeline import Pipeline from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import Normalizer from matplotlib import pyplot #    dataset = load_boston()</span></span></code> </pre> <br>  ExÃ©cutez le code et traitez le dictionnaire.  La description et les clÃ©s sont les suivantes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1e2/80f/4e2/1e280f4e239b31bae42274ab21c42d29.png" alt="image"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/24a/448/05a/24a44805af40951d544ef8cc6637c52a.png" alt="image"><br><br>  Nous attribuons la clÃ© `` donnÃ©es '' Ã  la variable <i>X</i> , qui est un tableau NumPy multidimensionnel avec un ensemble d'attributs, dimensionnez 506 lignes par 13 colonnes, et la variable <i>Y</i> - `` cible '', un tableau NumPy multidimensionnel avec un marqueur pour chaque ligne. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    #dataset = load_boston() X = dataset.data Y = dataset.target</span></span></code> </pre> <br>  Nous divisons l'ensemble de donnÃ©es en parties de formation et de test, configurons les paramÃ¨tres d'Ã©valuation des algorithmes.  Dans le paramÃ¨tre Â«scoringÂ», nous dÃ©finissons l'une des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mÃ©triques Â«r2Â»</a> traditionnelles pour l'analyse de rÃ©gression: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    dataset = load_boston() X = dataset.data Y = dataset.target #         test_size = 0.2 seed = 7 X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed) #     num_folds = 10 n_iter = 1000 n_estimators = 100 scoring = 'r2'</span></span></code> </pre> <br>  R2 - coefficient de dÃ©termination - c'est la proportion de la variance de la variable dÃ©pendante, expliquÃ©e par le modÃ¨le en question ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien</a> ). <br><br>  <i>Â«Le coefficient de dÃ©termination pour un modÃ¨le avec une constante prend des valeurs de 0 Ã  1. Plus le coefficient est proche de 1, plus la dÃ©pendance est forte.</i>  <i>Lors de l'Ã©valuation des modÃ¨les de rÃ©gression, cela est interprÃ©tÃ© comme faisant correspondre le modÃ¨le aux donnÃ©es.</i>  <i>Pour les modÃ¨les acceptables, on suppose que le coefficient de dÃ©termination doit Ãªtre d'au moins 50% (dans ce cas, le coefficient de corrÃ©lation multiple dÃ©passe 70% modulo).</i>  <i>Les modÃ¨les avec un coefficient de dÃ©termination supÃ©rieur Ã  80% peuvent Ãªtre considÃ©rÃ©s comme assez bons (le coefficient de corrÃ©lation dÃ©passe 90%).</i>  <i>L'Ã©galitÃ© du coefficient de dÃ©termination Ã  l'unitÃ© signifie que la variable expliquÃ©e est exactement dÃ©crite par le modÃ¨le considÃ©rÃ© Â»</i> (ibid.). <br><br>  Pour rÃ©soudre le problÃ¨me de prÃ©vision, nous utilisons les algorithmes suivants: <br><br><h4>  Algorithmes linÃ©aires: </h4><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RÃ©gression linÃ©aire</a> (Â«LRÂ») <br>  - RÃ©gression de crÃªte (rÃ©gression de crÃªte) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RÃ©gression de crÃªte</a> (Â«RÂ») <br>  - RÃ©gression Lasso (de l'anglais LASSO - OpÃ©rateur de retrait et de sÃ©lection le moins absolu) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RÃ©gression Lasso</a> ('L') <br>  - MÃ©thode de rÃ©gression <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Elastic Net Regression</a> (Â«ELNÂ») <br>  - MÃ©thode de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rÃ©gression du moindre angle</a> (LARS) (Â«LARSÂ») <br>  - RÃ©gression de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la crÃªte bayÃ©sienne</a> / rÃ©gression de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la crÃªte bayÃ©sienne</a> (Â«BRÂ») <br><br><h4>  Algorithmes non linÃ©aires: </h4><br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MÃ©thode du rÃ©gresseur k-voisins les plus proches</a> (Â«KNRÂ») <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RÃ©gresseur d'arbre de dÃ©cision</a> (Â«DTRÂ») <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Machine Ã  vecteur de support linÃ©aire</a> (rÃ©gression) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Machine Ã  vecteur de support linÃ©aire - RÃ©gression</a> / ('LSVR') <br>  - MÃ©thode de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vecteur de support</a> (rÃ©gression) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RÃ©gression de vecteur de support Epsilon</a> ('SVR') <br><br><h4>  Algorithmes d'ensemble: </h4><br>  - AdaBoost (rÃ©gression) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AdaBoost Regressor</a> ('ABR') (AdaBoost = Adaptive Boosting) <br>  - Ensachage (rÃ©gression) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RÃ©gresseur d'ensachage</a> ('BR') (Ensachage = agrÃ©gation Bootstrap) <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RÃ©gresseur d'arbres supplÃ©mentaires</a> (Â«ETRÂ») <br>  - Augmentation du gradient (rÃ©gression) / RÃ©gression de l'augmentation du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gradient</a> ('GBR') <br>  - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Classification alÃ©atoire des forÃªts</a> (rÃ©gression) / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Random Forest Classifier</a> (Â«RFRÂ») <br><br>  Ainsi, la liste des Â«modÃ¨lesÂ» contient les modÃ¨les suivants: <br><br><pre> <code class="python hljs">models = [] models.append((<span class="hljs-string"><span class="hljs-string">'LR'</span></span>, LinearRegression())) models.append((<span class="hljs-string"><span class="hljs-string">'R'</span></span>, Ridge())) models.append((<span class="hljs-string"><span class="hljs-string">'L'</span></span>, Lasso())) models.append((<span class="hljs-string"><span class="hljs-string">'ELN'</span></span>, ElasticNet())) models.append((<span class="hljs-string"><span class="hljs-string">'LARS'</span></span>, Lars())) models.append((<span class="hljs-string"><span class="hljs-string">'BR'</span></span>, BayesianRidge(n_iter=n_iter))) models.append((<span class="hljs-string"><span class="hljs-string">'KNR'</span></span>, KNeighborsRegressor())) models.append((<span class="hljs-string"><span class="hljs-string">'DTR'</span></span>, DecisionTreeRegressor())) models.append((<span class="hljs-string"><span class="hljs-string">'LSVR'</span></span>, LinearSVR())) models.append((<span class="hljs-string"><span class="hljs-string">'SVR'</span></span>, SVR())) models.append((<span class="hljs-string"><span class="hljs-string">'ABR'</span></span>, AdaBoostRegressor(n_estimators=n_estimators))) models.append((<span class="hljs-string"><span class="hljs-string">'BR'</span></span>, BaggingRegressor(n_estimators=n_estimators))) models.append((<span class="hljs-string"><span class="hljs-string">'ETR'</span></span>, ExtraTreesRegressor(n_estimators=n_estimators))) models.append((<span class="hljs-string"><span class="hljs-string">'GBR'</span></span>, GradientBoostingRegressor(n_estimators=n_estimators))) models.append((<span class="hljs-string"><span class="hljs-string">'RFR'</span></span>, RandomForestRegressor(n_estimators=n_estimators)))</code> </pre> <br>  Comme pour la classification, l'Ã©valuation de l'efficacitÃ© de chaque algorithme se fait par validation croisÃ©e.  Le message affichÃ© contient les informations suivantes: le nom du modÃ¨le sous la forme d'une abrÃ©viation, le score moyen d'une validation croisÃ©e 10 fois sur les donnÃ©es d'entraÃ®nement (mÃ©trique `` r2 ''), l'Ã©cart type et le coefficient de dÃ©termination r2 sur les donnÃ©es de test sont indiquÃ©s entre parenthÃ¨ses. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      scores = [] names = [] results = [] predictions = [] msg_row = [] for name, model in models: kfold = KFold(n_splits=num_folds, random_state=seed) cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring) names.append(name) results.append(cv_results) m_fit = model.fit(X_train, Y_train) m_predict = model.predict(X_test) predictions.append(m_predict) m_score = model.score(X_test, Y_test) scores.append(m_score) msg = "%s: train = %.3f (%.3f) / test = %.3f" % (name, cv_results.mean(), cv_results.std(), m_score) msg_row.append(msg) print(msg) #   (Â«  Â») fig = pyplot.figure() fig.suptitle('   ') ax = fig.add_subplot(111) red_square = dict(markerfacecolor='r', marker='s') pyplot.boxplot(results, flierprops=red_square) ax.set_xticklabels(names, rotation=45) pyplot.show()</span></span></code> </pre> <br>  AprÃ¨s avoir exÃ©cutÃ© le code, nous obtenons les rÃ©sultats suivants: <br><br><pre> <code class="python hljs">LR: train = <span class="hljs-number"><span class="hljs-number">0.746</span></span> (<span class="hljs-number"><span class="hljs-number">0.068</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.579</span></span> R: train = <span class="hljs-number"><span class="hljs-number">0.744</span></span> (<span class="hljs-number"><span class="hljs-number">0.067</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.570</span></span> L: train = <span class="hljs-number"><span class="hljs-number">0.689</span></span> (<span class="hljs-number"><span class="hljs-number">0.070</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.641</span></span> ELN: train = <span class="hljs-number"><span class="hljs-number">0.677</span></span> (<span class="hljs-number"><span class="hljs-number">0.074</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.662</span></span> LARS: train = <span class="hljs-number"><span class="hljs-number">0.744</span></span> (<span class="hljs-number"><span class="hljs-number">0.069</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.579</span></span> BR: train = <span class="hljs-number"><span class="hljs-number">0.739</span></span> (<span class="hljs-number"><span class="hljs-number">0.069</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.571</span></span> KNR: train = <span class="hljs-number"><span class="hljs-number">0.434</span></span> (<span class="hljs-number"><span class="hljs-number">0.288</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.538</span></span> DTR: train = <span class="hljs-number"><span class="hljs-number">0.671</span></span> (<span class="hljs-number"><span class="hljs-number">0.145</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.637</span></span> LSVR: train = <span class="hljs-number"><span class="hljs-number">0.550</span></span> (<span class="hljs-number"><span class="hljs-number">0.144</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.459</span></span> SVR: train = <span class="hljs-number"><span class="hljs-number">-0.012</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">-0.003</span></span> ABR: train = <span class="hljs-number"><span class="hljs-number">0.810</span></span> (<span class="hljs-number"><span class="hljs-number">0.078</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.763</span></span> BR: train = <span class="hljs-number"><span class="hljs-number">0.854</span></span> (<span class="hljs-number"><span class="hljs-number">0.064</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.805</span></span> ETR: train = <span class="hljs-number"><span class="hljs-number">0.889</span></span> (<span class="hljs-number"><span class="hljs-number">0.047</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.836</span></span> GBR: train = <span class="hljs-number"><span class="hljs-number">0.878</span></span> (<span class="hljs-number"><span class="hljs-number">0.042</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.863</span></span> RFR: train = <span class="hljs-number"><span class="hljs-number">0.852</span></span> (<span class="hljs-number"><span class="hljs-number">0.068</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.819</span></span></code> </pre> <br>  Tableau de portÃ©e: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2a7/140/96c/2a714096c35498ccddc267298f502a6a.png" alt="image"><br><br>  Les leaders Ã©vidents sont les mÃ©thodes d'ensemble 'GBR' (gradient 'boosting'), 'ETR' (extra-trees), 'RFR' (random forest) et 'BR' ('bagging'): <br><br><pre> <code class="python hljs">GBR: train = <span class="hljs-number"><span class="hljs-number">0.878</span></span> (<span class="hljs-number"><span class="hljs-number">0.042</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.863</span></span> ETR: train = <span class="hljs-number"><span class="hljs-number">0.889</span></span> (<span class="hljs-number"><span class="hljs-number">0.047</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.836</span></span> RFR: train = <span class="hljs-number"><span class="hljs-number">0.852</span></span> (<span class="hljs-number"><span class="hljs-number">0.068</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.819</span></span> BR: train = <span class="hljs-number"><span class="hljs-number">0.854</span></span> (<span class="hljs-number"><span class="hljs-number">0.064</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.805</span></span> ABR: train = <span class="hljs-number"><span class="hljs-number">0.810</span></span> (<span class="hljs-number"><span class="hljs-number">0.078</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.763</span></span> ELN: train = <span class="hljs-number"><span class="hljs-number">0.677</span></span> (<span class="hljs-number"><span class="hljs-number">0.074</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.662</span></span> L: train = <span class="hljs-number"><span class="hljs-number">0.689</span></span> (<span class="hljs-number"><span class="hljs-number">0.070</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.641</span></span> DTR: train = <span class="hljs-number"><span class="hljs-number">0.671</span></span> (<span class="hljs-number"><span class="hljs-number">0.145</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.637</span></span> LR: train = <span class="hljs-number"><span class="hljs-number">0.746</span></span> (<span class="hljs-number"><span class="hljs-number">0.068</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.579</span></span> LARS: train = <span class="hljs-number"><span class="hljs-number">0.744</span></span> (<span class="hljs-number"><span class="hljs-number">0.069</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.579</span></span> BR: train = <span class="hljs-number"><span class="hljs-number">0.739</span></span> (<span class="hljs-number"><span class="hljs-number">0.069</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.571</span></span> R: train = <span class="hljs-number"><span class="hljs-number">0.744</span></span> (<span class="hljs-number"><span class="hljs-number">0.067</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.570</span></span> KNR: train = <span class="hljs-number"><span class="hljs-number">0.434</span></span> (<span class="hljs-number"><span class="hljs-number">0.288</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.538</span></span> LSVR: train = <span class="hljs-number"><span class="hljs-number">0.550</span></span> (<span class="hljs-number"><span class="hljs-number">0.144</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.459</span></span> SVR: train = <span class="hljs-number"><span class="hljs-number">-0.012</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">-0.003</span></span></code> </pre> <br>  Un "adabust", une sorte de "loshara", est en retard. <br><br>  Peut-Ãªtre que les trois dirigeants peignent la normalisation et la normalisation.  DÃ©couvrons-le en exÃ©cutant le reste du code. <br><br>  Les rÃ©sultats sont les suivants: <br><br><pre> <code class="python hljs">SS_LR: train = <span class="hljs-number"><span class="hljs-number">0.746</span></span> (<span class="hljs-number"><span class="hljs-number">0.068</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.579</span></span> SS_R: train = <span class="hljs-number"><span class="hljs-number">0.746</span></span> (<span class="hljs-number"><span class="hljs-number">0.068</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.578</span></span> SS_L: train = <span class="hljs-number"><span class="hljs-number">0.678</span></span> (<span class="hljs-number"><span class="hljs-number">0.054</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.510</span></span> SS_ELN: train = <span class="hljs-number"><span class="hljs-number">0.665</span></span> (<span class="hljs-number"><span class="hljs-number">0.060</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.513</span></span> SS_LARS: train = <span class="hljs-number"><span class="hljs-number">0.744</span></span> (<span class="hljs-number"><span class="hljs-number">0.069</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.579</span></span> SS_BR: train = <span class="hljs-number"><span class="hljs-number">0.746</span></span> (<span class="hljs-number"><span class="hljs-number">0.066</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.576</span></span> SS_KNR: train = <span class="hljs-number"><span class="hljs-number">0.763</span></span> (<span class="hljs-number"><span class="hljs-number">0.098</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.739</span></span> SS_DTR: train = <span class="hljs-number"><span class="hljs-number">0.610</span></span> (<span class="hljs-number"><span class="hljs-number">0.242</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.629</span></span> SS_LSVR: train = <span class="hljs-number"><span class="hljs-number">0.727</span></span> (<span class="hljs-number"><span class="hljs-number">0.091</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.482</span></span> SS_SVR: train = <span class="hljs-number"><span class="hljs-number">0.653</span></span> (<span class="hljs-number"><span class="hljs-number">0.126</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.610</span></span> SS_ABR: train = <span class="hljs-number"><span class="hljs-number">0.811</span></span> (<span class="hljs-number"><span class="hljs-number">0.076</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.819</span></span> SS_BR: train = <span class="hljs-number"><span class="hljs-number">0.853</span></span> (<span class="hljs-number"><span class="hljs-number">0.074</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.813</span></span> SS_ETR: train = <span class="hljs-number"><span class="hljs-number">0.887</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.846</span></span> SS_GBR: train = <span class="hljs-number"><span class="hljs-number">0.878</span></span> (<span class="hljs-number"><span class="hljs-number">0.038</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.860</span></span> SS_RFR: train = <span class="hljs-number"><span class="hljs-number">0.851</span></span> (<span class="hljs-number"><span class="hljs-number">0.071</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.818</span></span> N_LR: train = <span class="hljs-number"><span class="hljs-number">0.751</span></span> (<span class="hljs-number"><span class="hljs-number">0.099</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.576</span></span> N_R: train = <span class="hljs-number"><span class="hljs-number">0.287</span></span> (<span class="hljs-number"><span class="hljs-number">0.126</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.271</span></span> N_L: train = <span class="hljs-number"><span class="hljs-number">-0.030</span></span> (<span class="hljs-number"><span class="hljs-number">0.032</span></span>) / test = <span class="hljs-number"><span class="hljs-number">-0.000</span></span> N_ELN: train = <span class="hljs-number"><span class="hljs-number">-0.007</span></span> (<span class="hljs-number"><span class="hljs-number">0.030</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.023</span></span> N_LARS: train = <span class="hljs-number"><span class="hljs-number">0.751</span></span> (<span class="hljs-number"><span class="hljs-number">0.099</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.576</span></span> N_BR: train = <span class="hljs-number"><span class="hljs-number">0.744</span></span> (<span class="hljs-number"><span class="hljs-number">0.100</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.589</span></span> N_KNR: train = <span class="hljs-number"><span class="hljs-number">0.485</span></span> (<span class="hljs-number"><span class="hljs-number">0.192</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.504</span></span> N_DTR: train = <span class="hljs-number"><span class="hljs-number">0.729</span></span> (<span class="hljs-number"><span class="hljs-number">0.080</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.765</span></span> N_LSVR: train = <span class="hljs-number"><span class="hljs-number">0.182</span></span> (<span class="hljs-number"><span class="hljs-number">0.108</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.136</span></span> N_SVR: train = <span class="hljs-number"><span class="hljs-number">0.086</span></span> (<span class="hljs-number"><span class="hljs-number">0.076</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.084</span></span> N_ABR: train = <span class="hljs-number"><span class="hljs-number">0.795</span></span> (<span class="hljs-number"><span class="hljs-number">0.053</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.752</span></span> N_BR: train = <span class="hljs-number"><span class="hljs-number">0.854</span></span> (<span class="hljs-number"><span class="hljs-number">0.054</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.827</span></span> N_ETR: train = <span class="hljs-number"><span class="hljs-number">0.877</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.850</span></span> N_GBR: train = <span class="hljs-number"><span class="hljs-number">0.852</span></span> (<span class="hljs-number"><span class="hljs-number">0.063</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.872</span></span> N_RFR: train = <span class="hljs-number"><span class="hljs-number">0.852</span></span> (<span class="hljs-number"><span class="hljs-number">0.051</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.801</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comme vous pouvez le voir, les mÃ©thodes d'ensemble sont toujours en avance sur tout le monde. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Â«Top 5Â» contient les rÃ©sultats suivants:</font></font><br><br><pre> <code class="python hljs">N_GBR: train = <span class="hljs-number"><span class="hljs-number">0.852</span></span> (<span class="hljs-number"><span class="hljs-number">0.063</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.872</span></span> GBR: train = <span class="hljs-number"><span class="hljs-number">0.878</span></span> (<span class="hljs-number"><span class="hljs-number">0.042</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.863</span></span> SS_GBR: train = <span class="hljs-number"><span class="hljs-number">0.878</span></span> (<span class="hljs-number"><span class="hljs-number">0.038</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.860</span></span> N_ETR: train = <span class="hljs-number"><span class="hljs-number">0.877</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.850</span></span> SS_ETR: train = <span class="hljs-number"><span class="hljs-number">0.887</span></span> (<span class="hljs-number"><span class="hljs-number">0.048</span></span>) / test = <span class="hljs-number"><span class="hljs-number">0.846</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous afficherons un tableau comparant les rÃ©sultats: le </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/8b1/9a0/cc6/8b19a0cc6379c2337c9082eedd415585.jpg" alt="image"><br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">test Y</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> est la norme. Les cinq rÃ©sultats sÃ©lectionnÃ©s montrÃ©s dans le diagramme sont indiquÃ©s par une ligne pointillÃ©e. On peut voir que tous les pics ont Ã©tÃ© reproduits soit avec rÃ©pÃ©tition exacte, soit Ã  un degrÃ© ou Ã  un autre. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bref extrait de comparaison manuelle des valeurs de rÃ©fÃ©rence et des valeurs prÃ©visionnelles de l'algorithme inclus dans le Top 5: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/711/0a7/2de/7110a72de1daa81209ecaee33542dfef.png" alt="image"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ainsi, selon les rÃ©sultats d'un test de blitz d'algorithmes d'apprentissage automatique pour rÃ©soudre le problÃ¨me de la prÃ©vision de l'ensemble de donnÃ©es Â«Boston House-PriceÂ», les algorithmes les plus appropriÃ©s sont le Â«boostingÂ» de gradient (Â«GBR Â») et d'arbres supplÃ©mentaires (Â« ETR Â»). Ces algorithmes doivent faire l'objet d'une attention accrue afin de dÃ©velopper davantage les rÃ©sultats et d'amÃ©liorer l'efficacitÃ© des prÃ©visions.</font></font><br><br><h3>  Postface </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Une vÃ©rification rapide des algorithmes d'apprentissage automatique permet, en premiÃ¨re approximation, d'identifier les algorithmes les plus efficaces pour rÃ©soudre les problÃ¨mes de classification et d'analyse de rÃ©gression (prÃ©vision). Nous en avons Ã©tÃ© convaincus en traitant l'ensemble de donnÃ©es Â«digitsÂ», en triant brillamment les instances en 10 classes, ainsi que l'ensemble de donnÃ©es Â«boston house-priceÂ», en triant Â«Ã©tonnammentÂ» la recherche de dÃ©pendances et en faisant une prÃ©vision Â«fluctuanteÂ» de la variable dÃ©pendante. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous Ãªtes invitÃ© Ã  essayer cette mÃ©thode sur vos propres ensembles de donnÃ©es ou sur ceux que vous pouvez creuser dans diffÃ©rents rÃ©fÃ©rentiels, y compris GitHub. Par exemple: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lien</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obtenez un ensemble de donnÃ©es appropriÃ© pour la cible - et dÃ©finissez un troupeau d'algorithmes dessus dans l'Ã©quipe du test de blitz. Et lÃ , il devient clair dont la prise: un sur le terrain n'est pas un guerrier.</font></font> :) <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et en conclusion. Je serai reconnaissant pour vos commentaires, questions et suggestions, car la base de cet article est l'information que je partage avec de nouveaux collÃ¨gues sur chaque nouveau projet dans le domaine de l'apprentissage automatique. Chacun d'eux a sa propre spÃ©cialisation, Ã  propos de l'apprentissage automatique et des rÃ©seaux de neurones artificiels, beaucoup d'entre eux ne sont Â«entendus que quelque partÂ», il est donc important pour moi de parler de complexes, de multiples facettes et, enfin, imprenables (il s'agit de l'ANN et de l'apprentissage automatique en gÃ©nÃ©ral) :), dans un langage simple et comprÃ©hensible; montrez que ce ne sont pas les dieux qui brÃ»lent des pots; et que s'il y a un intÃ©rÃªt, alors plus d'une douzaine d'algorithmes peuvent Ãªtre "exploitÃ©s".</font></font> :) <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS Ã€ la fin de l'article, j'ai dÃ©jÃ  commencÃ© Ã  me prÃ©dire, donc aux questions Ã  venir sur oÃ¹ j'ai obtenu la feuille de triche dans le premier chiffre que je donne: tout sur le mÃªme site scikit-learn.org ( </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">`` Choisir le bon estimateur ''</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ): </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lien</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Et la personnification de l'intelligence artificielle sous la forme d'un Samodelkin rougi est ainsi des vagues de la mÃ©moire de mon enfance heureuse.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr475552/">https://habr.com/ru/post/fr475552/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr475542/index.html">L'Ã©volution du marketing par e-mail depuis 2013: 4 tendances principales et statistiques actuelles</a></li>
<li><a href="../fr475544/index.html">Catalogues de produits, services et plus</a></li>
<li><a href="../fr475546/index.html">Syndromes addictifs IT</a></li>
<li><a href="../fr475548/index.html">Matchmaking ennuyeux sans dÃ©sÃ©quilibre et files d'attente: un guide pratique</a></li>
<li><a href="../fr475550/index.html">SystÃ¨mes acoustiques pour piÃ¨ces ouvertes</a></li>
<li><a href="../fr475554/index.html">Techniques de conception d'interface utilisateur qui font gagner du temps</a></li>
<li><a href="../fr475556/index.html">DÃ©mÃ©nagement Ã  Munich. Le chemin Scalors d'Amazon vers le travail de rÃªve d'Amazon</a></li>
<li><a href="../fr475558/index.html">Dictionnaire informatique ou quoi? O?? OÃ¹ aller? Partie 1</a></li>
<li><a href="../fr475560/index.html">KotlinConf 2019 Live: Regardez en direct les 5 et 6 dÃ©cembre</a></li>
<li><a href="../fr475562/index.html">MVC dans Unity avec des objets scriptables. Partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ü ‚èèÔ∏è üëé Ciclo de vida ML üé∏ üë®üèª‚Äçüéì üö´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Em uma implementa√ß√£o real de ML, o pr√≥prio aprendizado leva um quarto do esfor√ßo. Os tr√™s quartos restantes s√£o a prepara√ß√£o de dados por meio de prob...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ciclo de vida ML</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/455648/">  Em uma implementa√ß√£o real de ML, o pr√≥prio aprendizado leva um quarto do esfor√ßo.  Os tr√™s quartos restantes s√£o a prepara√ß√£o de dados por meio de problemas e burocracia, uma implanta√ß√£o complexa frequentemente em circuito fechado sem acesso √† Internet, configura√ß√£o da infraestrutura, teste e monitoramento.  Documentos em centenas de folhas, modo manual, conflitos de vers√£o de modelo, c√≥digo aberto e empresa agressiva - tudo isso aguarda um cientista de dados.  Mas ele n√£o est√° interessado em quest√µes operacionais "chatas"; ele deseja desenvolver um algoritmo, obter alta qualidade, retribuir e n√£o se lembrar mais. <br><br>  Talvez, em algum lugar, o ML seja implementado mais f√°cil, mais simples, mais r√°pido e com um bot√£o, mas n√£o vimos esses exemplos.  Tudo o que est√° acima √© a experi√™ncia da Front Tier em fintech e telecomunica√ß√µes.  Sergey Vinogradov, especialista em arquitetura de sistemas altamente carregados, em grandes armazenamentos e em an√°lise de dados pesados, falou sobre ele no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HighLoad ++</a> . <br><br><img src="https://habrastorage.org/webt/ss/7n/cm/ss7ncmtdsij0wncwt-uuzxneit8.jpeg"><br><a name="habracut"></a><br><h2>  Ciclo de vida do modelo </h2><br>  Normalmente, o ciclo de vida em nossa √°rea de assunto consiste em tr√™s partes.  No primeiro <strong>, uma tarefa vem do neg√≥cio</strong> .  No segundo, um <strong>engenheiro de dados e / ou cientista de dados prepara dados</strong> , constr√≥i um modelo.  Na terceira parte, o <strong>caos</strong> come√ßa.  Nos √∫ltimos dois, diferentes situa√ß√µes interessantes acontecem. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/7GM9ac6ojtw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h3>  Jack de todos os com√©rcios </h3><br>  A primeira situa√ß√£o frequente √© que um cientista ou engenheiro de dados tem acesso aos produtos, ent√£o eles dizem a ele: "Voc√™ fez tudo isso, pode apostar". <br><br>  Uma pessoa pega um <strong>Notebook Jupyter</strong> ou um pacote de notebooks, os considera exclusivamente como um artefato de implanta√ß√£o e come√ßa a replicar com alegria em alguns servidores. <br><br>  Tudo parece estar bem, mas nem sempre.  Eu vou te dizer mais tarde porque. <br><br><h3>  Explora√ß√£o impiedosa </h3><br>  A segunda hist√≥ria √© mais complexa e geralmente acontece em empresas onde a explora√ß√£o atingiu um estado de insanidade leve.  O cientista de dados coloca sua solu√ß√£o em opera√ß√£o.  Eles abrem essa caixa preta e v√™em algo terr√≠vel: <br><br><ul><li>  cadernos </li><li>  picles de diferentes vers√µes; </li><li>  monte de scripts: n√£o est√° claro onde e quando execut√°-los, onde salvar os dados que eles geram. </li></ul><br>  Nesse quebra-cabe√ßa, a explora√ß√£o encontra incompatibilidade de vers√£o.  Por exemplo, um cientista de dados n√£o especificou uma vers√£o espec√≠fica da biblioteca e a opera√ß√£o foi a mais recente.  Depois de um tempo, o cientista de dados recorre: <br><br>  <em>- Voc√™ configurou o scikit-learn para a vers√£o errada, agora todas as m√©tricas se foram!</em>  <em>Precisa reverter para a vers√£o anterior.</em> <br><br>  Isso quebra completamente o est√≠mulo e a explora√ß√£o sofre. <br><br><h3>  Burocracia </h3><br>  Nas empresas com logotipos verdes, quando o cientista de dados entra em opera√ß√£o e traz o modelo, geralmente recebe um documento de 800 folhas em resposta: ‚ÄúSiga estas instru√ß√µes, caso contr√°rio, seu produto nunca ver√° a luz do dia‚Äù. <br><br>  O triste cientista de dados sai, joga tudo pela metade e depois sai - ele n√£o est√° interessado em fazer isso. <br><br><h3>  Implantar </h3><br>  Suponha que um cientista de dados tenha passado por todos os c√≠rculos e, no final, tudo tenha sido implantado.  Mas ele n√£o ser√° capaz de entender que tudo est√° funcionando como deveria.  Na minha experi√™ncia, nos mesmos bancos aben√ßoados, n√£o h√° monitoramento de produtos de ci√™ncia de dados. <br><br>  √â bom que o especialista escreva os resultados de seu trabalho no banco de dados.  Depois de um tempo, ele os receber√° e ver√° o que acontece l√° dentro.  Mas isso nem sempre acontece.  Quando uma empresa e um cientista de dados simplesmente acreditam que tudo est√° funcionando bem e maravilhoso, isso se traduz em casos sem √™xito. <br><br><h3>  IMF </h3><br>  De alguma forma, desenvolvemos um mecanismo de pontua√ß√£o para uma grande organiza√ß√£o de microfinan√ßas.  Eles n√£o os deixaram ir ao produto, mas simplesmente pegaram uma cascata de modelos, instalaram e lan√ßaram.  Os resultados dos testes dos modelos os satisfizeram.  Mas depois de 6 meses eles voltaram: <br><br>  <em>Est√° tudo ruim.</em>  <em>Os neg√≥cios n√£o v√£o, estamos cada vez pior.</em>  <em>Parece que os modelos s√£o excelentes, mas os resultados est√£o caindo, fraude e inadimpl√™ncia cada vez mais e menos dinheiro.</em>  <em>Pelo que lhe pagamos?</em>  <em>Vamos acertar.</em> <br><br>  Ao mesmo tempo, o acesso ao modelo novamente n√£o √© fornecido.  Al√©m disso, os logs foram descarregados por um m√™s, seis meses atr√°s.  Estudamos a descarga por mais um m√™s e chegamos √† conclus√£o de que em algum momento o departamento de TI da IMF alterou os dados de entrada e, em vez de documentos em json, eles come√ßaram a enviar documentos em xml.  O modelo esperava json, mas recebeu xml, ficou triste e achou que n√£o havia dados na entrada. <br><br><blockquote>  Se n√£o houver dados, a avalia√ß√£o do que est√° acontecendo √© diferente.  Sem monitoramento, isso n√£o pode ser detectado. </blockquote><br><h3>  Nova vers√£o, cascata e testes </h3><br>  Muitas vezes nos deparamos com o fato de que o modelo funciona bem, mas por algum motivo uma <strong>nova vers√£o foi</strong> desenvolvida.  O modelo novamente precisa ser trazido de alguma forma, e novamente para passar por todos os c√≠rculos do inferno.  √â bom que as vers√µes da biblioteca sejam as mesmas do modelo anterior e, se n√£o, a implanta√ß√£o come√ßa novamente ... <br><br>  √Äs vezes, antes de colocar uma nova vers√£o em batalha, queremos <strong>test√°-la</strong> - coloque-a no prod, observe o mesmo fluxo de tr√°fego, verifique se est√° boa.  Essa √© novamente a cadeia de implanta√ß√£o completa.  Al√©m disso, configuramos os sistemas para que, de acordo com esse modelo, n√£o ocorram resultados reais, se estamos falando de pontua√ß√£o, mas houve apenas monitoramento e an√°lise dos resultados para an√°lise posterior. <br><br>  H√° situa√ß√µes em que uma <strong>cascata de modelos √© usada.</strong>  Quando os resultados dos seguintes modelos dependem dos anteriores, de alguma forma voc√™ precisa estabelecer uma intera√ß√£o entre eles e em algum lugar novamente tudo isso deve ser salvo. <br><br><h2>  Como resolver esses problemas? </h2><br>  Muitas vezes, uma pessoa resolve problemas <strong>manualmente</strong> , especialmente em pequenas empresas.  Ele sabe como tudo funciona, lembra todas as vers√µes de modelos e bibliotecas, sabe onde e quais scripts funcionam, quais fachadas de loja s√£o constru√≠das.  Tudo isso √© maravilhoso.  Particularmente bonitas s√£o as hist√≥rias que o modo manual deixa para tr√°s. <br><br>  <strong>A hist√≥ria da heran√ßa</strong> .  Um homem bom trabalhava em um pequeno banco.  Uma vez ele foi para um pa√≠s do sul e n√£o voltou.  Depois disso, obtivemos uma heran√ßa: um monte de c√≥digo que gera frentes de loja nas quais os modelos de modelos trabalham.  O c√≥digo √© bonito, funciona, mas n√£o sabemos a vers√£o exata do script que gera essa ou aquela loja.  Na batalha, todas as vitrines est√£o presentes e todas s√£o lan√ßadas.  Passamos dois meses tentando entender esse intrincado emaranhado e de alguma forma estrutur√°-lo. <br><br>  <strong>Em uma empresa dura, as</strong> pessoas n√£o querem se preocupar com todos os tipos de Python, Jupiters, etc. Eles dizem: <br><br>  <em>- Vamos comprar o IBM SPSS, instalar e tudo ficar√° √≥timo.</em>  <em>Problemas com o controle de vers√£o, com fontes de dados, com a implanta√ß√£o de alguma maneira resolvida.</em> <br><br>  Essa abordagem tem o direito de existir, mas nem todos podem pagar.  De qualquer forma, esta √© uma agulha serrilhada de alta qualidade.  Eles ficam sentados, mas n√£o d√° certo: entalhes.  E geralmente custa muito. <br><br>  <strong>C√≥digo aberto √© o</strong> oposto da abordagem anterior.  Os desenvolvedores navegaram na Internet, encontraram muitas solu√ß√µes de c√≥digo aberto que resolvem suas tarefas em v√°rios graus.  Essa √© uma √≥tima maneira, mas para n√≥s mesmos n√£o encontramos solu√ß√µes que atendam 100% aos nossos requisitos. <br><br>  Portanto, escolhemos a op√ß√£o cl√°ssica - <strong>nossa decis√£o</strong> .  Suas muletas, bicicletas, todas pr√≥prias, nativas. <br><br><h2>  O que queremos de nossa decis√£o? </h2><br><br>  <strong>N√£o escreva tudo sozinho</strong> .  Queremos levar componentes, especialmente os de infraestrutura, que tenham se mostrado bem e estejam familiarizados com a opera√ß√£o nas institui√ß√µes com as quais trabalhamos.  Acabamos de escrever um ambiente que isolar√° facilmente o trabalho do cientista de dados do trabalho do DevOps. <br><br>  <strong>Processe dados em dois modos: ambos no modo de lote - Lote e em tempo real</strong> .  Nossas tarefas incluem os dois modos de opera√ß√£o. <br><br>  <strong>Facilite a implanta√ß√£o e em um per√≠metro fechado</strong> .  Ao trabalhar com dados particulares confidenciais, n√£o h√° conex√£o com a Internet.  Nesse momento, tudo deve chegar com rapidez e precis√£o √† produ√ß√£o.  Portanto, come√ßamos a olhar para o Gitlab, o pipeline de CI / CD dentro dele e para o Docker. <br><br><blockquote>  Um modelo n√£o √© um fim em si mesmo.  N√£o resolvemos o problema de construir um modelo, resolvemos um problema de neg√≥cios. </blockquote><br>  Dentro do pipeline, deve haver regras e um conglomerado de modelos com suporte para a <strong>vers√£o de todos os</strong> componentes do pipeline. <br><br>  O que se entende por pipeline?  Na R√∫ssia, a Lei Federal 115 sobre o combate √† lavagem de dinheiro e ao financiamento do terrorismo est√° em vigor.  Somente o √≠ndice das recomenda√ß√µes do Banco Central ocupa 16 telas.  Essas s√£o regras simples que um banco pode cumprir se tiver esses dados ou n√£o, se n√£o tiver dados. <br><br>  A avalia√ß√£o de um mutu√°rio, transa√ß√£o financeira ou outro processo de neg√≥cios √© um fluxo de dados que processamos.  Um fluxo deve passar por esse tipo de regra.  Essas regras s√£o descritas de maneira f√°cil pelo analista.  Ele n√£o √© um cientista de dados, mas conhece bem a lei ou outras instru√ß√µes.  O analista se senta e, em linguagem simples, descreve as verifica√ß√µes dos dados. <br><br>  <strong>Crie cascatas de modelos</strong> .  Freq√ºentemente surge uma situa√ß√£o quando o pr√≥ximo modelo usa para o seu trabalho os valores obtidos nos modelos anteriores. <br><br>  <strong>Teste hip√≥teses rapidamente.</strong>  Repito a tese anterior: um cientista de dados fez algum tipo de modelo, ele gira em batalha e funciona bem.  Por alguma raz√£o, o especialista encontrou uma solu√ß√£o melhor, mas n√£o quer arruinar o fluxo de trabalho estabelecido.  O cientista de dados est√° suspendendo um novo modelo no mesmo tr√°fego de combate no sistema de combate.  Ela n√£o participa diretamente da tomada de decis√µes, mas serve o mesmo tr√°fego, considera algumas conclus√µes e essas conclus√µes s√£o armazenadas em algum lugar. <br><br>  <strong>Recurso de reutiliza√ß√£o f√°cil.</strong>  Muitas tarefas t√™m o mesmo tipo de componentes, especialmente aqueles relacionados √† extra√ß√£o de recursos ou regras.  Queremos arrastar esses componentes para outros pipelines. <br><br><h2>  O que voc√™ decidiu fazer? </h2><br>  Primeiro queremos monitoramento.  E dois desse tipo. <br><br><h3>  Monitoramento </h3><br>  <strong>Monitoramento t√©cnico.</strong>  Se algum componente do pipeline for implantado, em opera√ß√£o, eles dever√£o ver o que acontece com o componente: como ele consome mem√≥ria, CPU, disco. <br><br>  <strong>Monitoramento de neg√≥cios.</strong>  Esta √© uma ferramenta de cientista de dados que permite abstrair das nuances t√©cnicas da implementa√ß√£o.  No n√≠vel do projeto, a constru√ß√£o ajuda a determinar quais m√©tricas de modelo devem estar dispon√≠veis no monitoramento, por exemplo, na distribui√ß√£o de recursos ou nos resultados do servi√ßo de pontua√ß√£o. <br><br>  Um cientista de dados define m√©tricas e n√£o deve se preocupar com a forma como elas entram no sistema de monitoramento.  A √∫nica coisa importante √© que ele definiu essas m√©tricas e a apar√™ncia do painel no qual as m√©tricas ser√£o exibidas.  Em seguida, o especialista lan√ßou tudo sobre a produ√ß√£o, implantou e, depois de um tempo, as m√©tricas se concentraram no monitoramento.  Assim, um cientista de dados sem acesso ao produto pode ver o que est√° acontecendo dentro do modelo. <br><br><h3>  Teste </h3><br>  Teste o <strong>pipeline para obter consist√™ncia</strong> .  Dadas as especificidades do pipeline, esse √© um tipo de gr√°fico de computa√ß√£o.  Queremos entender que estamos implementando um gr√°fico, podemos ignor√°-lo e encontrar uma maneira de sair dele. <br><br>  O gr√°fico possui componentes - m√≥dulos.  Todos os m√≥dulos devem passar no teste de unidade e integra√ß√£o.  O processo deve ser transparente e f√°cil para um cientista de dados. <br><br>  O desenvolvedor descreve o modelo e testa sozinho ou com a ajuda de outra pessoa.  Coloca tudo no Gitlab, o pipeline configurado pela Integra√ß√£o Cont√≠nua aumenta, testa, v√™ resultados.  Se tudo estiver bem - vai al√©m, n√£o - come√ßa de novo. <br><br>  O cientista de dados est√° focado no modelo e n√£o sabe o que est√° por tr√°s.  Para isso, ele recebe v√°rias coisas. <br><br><ul><li>  <strong>Uma API para integra√ß√£o com o n√∫cleo do</strong> <strong>pr√≥prio sistema</strong> via barramento de dados - barramento de mensagens.  Nesse caso, o especialista precisa descrever o que est√° entrando e o que est√° saindo do modelo, o ponto de entrada e a jun√ß√£o com diferentes componentes dentro do pipeline. </li><li>  Ap√≥s o treinamento do modelo, um <strong>artefato √©</strong> exibido <strong>- um arquivo XGBoost</strong> ou <strong>pickle</strong> .  O cientista de dados tem um executor para trabalhar com artefatos - ele deve integrar os componentes do pipeline dentro. </li><li>  API f√°cil e transparente para o cientista de dados monitorar a opera√ß√£o dos componentes do pipeline - monitoramento t√©cnico e comercial. </li><li>  <strong>Uma infraestrutura simples e transparente</strong> para integra√ß√£o com fontes de dados e preserva√ß√£o dos resultados do trabalho. </li></ul><br>  Muitas vezes, os modelos funcionam para n√≥s e, depois de um tempo, chega uma auditoria que deseja elevar toda a hist√≥ria do servi√ßo.  A auditoria deseja verificar a exatid√£o do trabalho, a aus√™ncia de fraude da nossa parte.  S√£o necess√°rias ferramentas simples para que qualquer auditor que conhe√ßa SQL possa entrar em um reposit√≥rio especial e ver como tudo funcionou, quais decis√µes foram tomadas e por qu√™. <br><br>  Estabelecemos as bases de duas hist√≥rias importantes para n√≥s. <br><br>  <strong>Jornada do Cliente.</strong>  Esta √© uma oportunidade de usar os mecanismos para preservar todo o hist√≥rico do cliente - o que aconteceu com o cliente como parte dos processos de neg√≥cios implementados neste sistema. <br><br>  Podemos ter fontes de dados externas, por exemplo, plataformas DMP.  Nelas, obtemos informa√ß√µes sobre o comportamento humano na rede e em dispositivos m√≥veis.  Isso pode afetar o LTV e os modelos de pontua√ß√£o de seu modelo.  Se o mutu√°rio estiver atrasado no pagamento, podemos prever que essa n√£o √© uma inten√ß√£o maliciosa - h√° simplesmente problemas.  Nesse caso, aplicamos m√©todos suaves de exposi√ß√£o ao mutu√°rio.  Quando os problemas s√£o resolvidos, o cliente fecha o empr√©stimo.  Quando ele vier na pr√≥xima vez, conheceremos toda a sua hist√≥ria.  O cientista de dados obter√° uma hist√≥ria visual do modelo e realizar√° a pontua√ß√£o no modo leve. <br><br>  <strong>Identifica√ß√£o de anomalias</strong> .  Estamos constantemente diante de um mundo muito complexo.  Por exemplo, pontos fracos na avalia√ß√£o acelerada das IMFs podem ser uma fonte de fraude autom√°tica. <br><br>  Customer Journey √© um conceito de acesso r√°pido e f√°cil ao fluxo de dados que passa pelo modelo.  O modelo facilita a detec√ß√£o de anomalias caracter√≠sticas de fraude no momento de sua ocorr√™ncia em massa. <br><br><h2>  Como est√° tudo organizado? </h2><br>  Sem hesitar, tomamos <strong>Kafka</strong> como um patch de barramento de mensagens.  Esta √© uma boa solu√ß√£o usada por muitos de nossos clientes. A opera√ß√£o √© capaz de trabalhar com ela. <br><br><img src="https://habrastorage.org/webt/uu/5k/3r/uu5k3rnxw7lu4iulruewhzmif8w.jpeg"><br><br><blockquote>  Alguns componentes do sistema j√° podem ser usados ‚Äã‚Äãna pr√≥pria empresa.  N√£o estamos construindo o sistema novamente, mas reutilizando o que eles j√° possuem. </blockquote><br>  <strong>Armazenamento de dados</strong> , neste caso, √© o armazenamento que o cliente geralmente j√° possui.  Podem ser bancos de dados Hadoop, relacionais e n√£o relacionais.  Podemos trabalhar de forma nativa com HDFS, Hive, Impala, Greenplum e PostgreSQL.  Consideramos esses armazenamentos como uma fonte de montras. <br><br>  Os dados chegam ao armaz√©m, passam pelo nosso ETL ou ETL do cliente, se ele tiver um.  Estamos construindo vitrines que s√£o mais usadas dentro dos modelos.  O armazenamento de dados √© usado no modo somente leitura. <br><br><h3>  Nossos desenvolvimentos </h3><br>  <strong>Quadro-negro</strong>  O nome √© retirado de uma pr√°tica bastante estranha de matem√°ticos dos anos 30-40.  Este √© o gerente de pipelines que vivem no sistema de administra√ß√£o.  O Blackboard possui algum tipo de Meta Storage.  Ele armazena os pipelines em si e as configura√ß√µes necess√°rias para inicializar todos os componentes. <br><br>  Todo o trabalho do sistema come√ßa com o Blackboard.  Por algum milagre, o pipeline acabou no Meta Storage, Blackboard depois de um tempo entendeu isso, retira a vers√£o atual do pipeline, inicializa-o e envia um sinal dentro de Kafka. <br><br>  Existe um <strong>ambiente de tempo de execu√ß√£o</strong> .  Ele √© constru√≠do no Dockers e pode ser replicado para servidores, inclusive na nuvem privada do cliente. <br><br>  Fora da caixa vem o <strong>ator</strong> principal <strong>:: Init</strong> - este √© o inicializador.  Este √© um g√™nio que pode fazer apenas duas coisas: <strong>construir</strong> e <strong>destruir componentes</strong> .  Ele recebe um comando da Blackboard: "Aqui est√° o pipeline, ele precisa ser lan√ßado em tais e tais servidores com esses e esses recursos em quantidades e quantidades - trabalhe!"  Ent√£o o ator come√ßa tudo. <br><br>  Matematicamente, um ator √© uma fun√ß√£o que recebe um ou mais objetos como entrada; dentro dele, altera o estado dos objetos de acordo com algum algoritmo; na sa√≠da, cria um novo objeto ou altera o estado de um existente. <br><br>  Tecnicamente, um ator √© um programa Python.  √â executado em um cont√™iner Docker com seu ambiente. <br><br>  O ator n√£o sabe sobre a exist√™ncia de outros atores.  A √∫nica entidade que sabe que, al√©m do ator, existe todo o pipeline como um todo - esse √© o Blackboard.  Ele monitora o status de execu√ß√£o de todos os atores no sistema e mant√©m o estado atual, que √© expresso no monitoramento como uma imagem de todo o processo de neg√≥cios como um todo. <br><br>  Ator :: Init gera muitos cont√™ineres do Docker.  Al√©m disso, os atores podem trabalhar com armazenamento de dados. <br><br>  O pr√≥prio sistema possui um componente de <strong>armazenamento de eventos</strong> .  Como armazenamento de eventos, usamos o <strong>ClickHouse</strong> .  Sua tarefa √© simples: todas as informa√ß√µes trocadas entre o ator atrav√©s do Kafka s√£o armazenadas no ClickHouse.  Isso √© feito <strong>para auditoria adicional</strong> .  Este √© o log de opera√ß√µes do pipeline. <br><br>  Os atores tamb√©m podem ser desenvolvidos para o <strong>Customer Journey</strong> .  Eles v√™em altera√ß√µes no log do pipeline e podem reconstruir rapidamente as janelas necess√°rias para os modelos ou componentes funcionarem com as regras, j√° dentro do pipeline.  Este √© um processo cont√≠nuo de altera√ß√£o de dados. <br><br>  O monitoramento √© constru√≠do primitivamente no <strong>Prometheus</strong> .  O ator recebe uma API b√°sica e, no modo fechado, mas transparente o suficiente para o desenvolvedor, ele envia mensagens com m√©tricas para Kafka.  O Prometheus l√™ as m√©tricas do Kafka e as salva em seu reposit√≥rio. <br><br>  Para visualiza√ß√£o, usamos o <strong>Grafana</strong> . <br><br><h3>  Dois pontos de integra√ß√£o </h3><br>  O primeiro √© o ponto de integra√ß√£o com fontes de dados que passam por ETLs para o data warehouse.  O segundo ponto de integra√ß√£o quando um servi√ßo j√° √© usado por um consumidor de dados, por exemplo, um servi√ßo de pontua√ß√£o. <br><br>  Pegamos o <strong>Apache ServiceMix.</strong>  Por experi√™ncia, esses pontos de integra√ß√£o s√£o do mesmo tipo com o mesmo tipo de protocolo: filas SOAP, RESTful e com menos frequ√™ncia.  Toda vez que n√£o queremos desenvolver nosso pr√≥prio construtor ou servi√ßo para gerar o pr√≥ximo servi√ßo SOAP.  Portanto, usamos o ServiceMix, descrevemos no SDL, no qual os modelos de dados desse servi√ßo e os m√©todos existentes nele s√£o constru√≠dos.  Em seguida, passamos pelo roteador dentro do ServiceMix e ele gera o pr√≥prio servi√ßo. <br><br>  Adicionamos a n√≥s mesmos uma convers√£o s√≠ncrona-ass√≠ncrona complicada.  Todas as solicita√ß√µes que vivem dentro do sistema s√£o ass√≠ncronas e passam pelo barramento de mensagens. <br><br>  A maioria dos servi√ßos de pontua√ß√£o √© s√≠ncrona.  As solicita√ß√µes do ServiceMix s√£o enviadas por REST ou SOAP.  Nesse ponto, ele passa pelo nosso Gateway, que mant√©m o conhecimento da sess√£o HTTP.  Em seguida, ele envia uma mensagem para Kafka, ela passa por algum pipeline e uma solu√ß√£o √© gerada. <br><br>  No entanto, ainda pode n√£o haver solu√ß√£o.  Por exemplo, algo caiu, ou h√° um SLA dif√≠cil de tomar uma decis√£o, e o Gateway monitora: "OK, recebi uma solicita√ß√£o, ele veio a mim em outro t√≥pico Kafka, ou nada veio a mim, mas meu gatilho de tempo limite funcionou".  Ent√£o, novamente, a convers√£o de s√≠ncrono para ass√≠ncrono ocorre e, na mesma sess√£o HTTP, h√° uma resposta para o consumidor com o resultado do trabalho.  Isso pode ser um erro ou uma previs√£o normal. <br><br>  Nesse lugar, ali√°s, comemos um cachorro sem gosto, gra√ßas ao grande e poderoso Open Source.  Usamos o ServiceMix de uma das vers√µes mais recentes e o Kafka das vers√µes anteriores e tudo funcionou perfeitamente.  Escrevemos neste Gateway, com base nos cubos que j√° estavam no ServiceMix.  Quando a nova vers√£o do Kafka foi lan√ßada, felizmente a agarramos, mas o suporte para os cabe√ßalhos dentro da mensagem em Kafka que existia anteriormente havia mudado.  O gateway no ServiceMix n√£o pode mais trabalhar com eles.  Para entender isso, passamos muito tempo.  Como resultado, criamos nosso Gateway, que pode funcionar com novas vers√µes do Kafka.  Escrevemos sobre o problema aos desenvolvedores do ServiceMix e recebemos a resposta: "Obrigado, n√≥s definitivamente o ajudaremos nas pr√≥ximas vers√µes!" <br><br>  Portanto, somos for√ßados a monitorar atualiza√ß√µes e alterar regularmente alguma coisa. <br><br>  <strong>A infraestrutura √© o Gitlab.</strong>  Usamos quase tudo o que h√° nele. <br><br><ul><li>  Reposit√≥rio de c√≥digo. </li><li>  Pipeline de integra√ß√£o cont√≠nua / entrega cont√≠nua. </li><li>  Registro para manter um registro de cont√™ineres do Docker. </li></ul><br><h3>  Componentes </h3><br>  N√≥s desenvolvemos 5 componentes: <br><br><ul><li>  <strong>Quadro</strong> - <strong>negro</strong> - gerenciamento do ciclo de vida do pipeline.  Onde, o que e com quais par√¢metros executar a partir do pipeline. </li><li>  <strong>O extrator de recursos</strong> funciona de maneira simples - informamos ao extrator de recursos que obtemos esse e tal modelo de dados na entrada, selecionamos os campos necess√°rios a partir dos dados, mapeia-os para determinados valores.  Por exemplo, obtemos a data de nascimento do cliente, convertemos para idade, usamos como um recurso em nosso modelo.  O extrator de recursos √© respons√°vel pelo enriquecimento dos dados. </li><li>  <strong>Mecanismo baseado em regras</strong> - verifica√ß√£o de dados de acordo com as regras.  Essa √© uma linguagem simples de descri√ß√£o que permite que uma pessoa familiarizada com a constru√ß√£o de &lt;code&gt; if, caso contr√°rio, &lt;code /&gt; bloqueie a descri√ß√£o das regras para verifica√ß√£o no sistema. </li><li>  <strong>Mecanismo de aprendizado de m√°quina</strong> - permite executar o executor, inicializar o modelo treinado e envi√°-lo aos dados de entrada.  Na sa√≠da, o modelo pega dados. </li><li>  <strong>Mecanismo de</strong> decis√£o - <strong>mecanismo de</strong> decis√£o, saia do gr√°fico.  Tendo uma cascata de modelos, por exemplo, diferentes ramos da avalia√ß√£o do mutu√°rio, voc√™ precisa decidir sobre a quest√£o do dinheiro em algum lugar.  O conjunto de regras para a solu√ß√£o deve ser simples. ,     LTV- ‚Äî     ,     ,  . </li></ul><br><br><h3>   </h3><br>         .  ‚Äî  ,    .  ‚Äî      ,      . <br><br>   pipeline    . <br><img src="https://habrastorage.org/webt/o7/vy/dj/o7vydjrruyfittwhwzumh_gc_rq.jpeg"><br><ul><li>   <strong>Feature extractor</strong> :  ,        ,      . </li><li> <strong> </strong> . ,  -:  , ,       18. </li><li>  <strong> .</strong>    ,    .     ,      ,        pipeline. </li><li>  <strong>Decision engine</strong> .             . </li><li>  <strong></strong> . </li></ul><br>      yaml.         .    ,  ,        .           yaml. <br><br>  pipeline,   ,   : feature extractor, rules, models, decision engine,    .   ‚Äî <strong>      Docker-</strong> .    Registry,   Docker-. -,   ,    . ,  ,      Docker-       . <br><br><h3>  Pipeline </h3><br>     ,     <strong>Python</strong> ‚Äî         . Feature extractor, ,   decision engine   Python. <br><br> Pipeline   <strong>yaml.</strong>      meta storage     ‚Äî   <strong></strong> . <br><br>  Runtime environment   10 ,  Blackboard  ,    pipeline    10 .  ,      : , , IP-    Kafka, , .       . <br><br>     GitLab.      Ansible. ,    .           ,      50 000    Ansible  . <br><br><h2>   ? </h2><br>  GitLab  pipeline.    GitLab. CI  ,   ,  ,  .   <strong>GitLab Runner</strong> ,    Docker-  ,    pipeline.    ‚Äî    Registry. <br><br><img src="https://habrastorage.org/webt/gz/dx/hr/gzdxhruymhjm2_wejqybqizdp0i.jpeg"><br><br>  Docker  ,       .   Docker-        .   CI pipeline    pipeline  -  Meta Storage,    Blackboard. <br><br> Blackboard    Meta Storage ‚Äî   , , ,   -.   Docker-     , , . <br><br> -   Blackboard  Meta Storage      :   ,  Kafka,   .  ,    ,   Docker-    ,     . <br><br>  ,    Docker-,  ‚Äî pipeline ! <br><br>      DigitalOcean.     AWS  Scaleway,     . <br><br>    ,        .  pipeline         . ,    . <br><br><h3>    ? </h3><br>   ‚Äî   .  ,   pipeline,     real-time   . <br><br><ul><li> 2 Feature extractor  .     1 , .. json    . </li><li> 8  ‚Äî 8  ML engine.      XGBoost. </li><li> 18     RB engine (115 ).   1000     . </li><li> 1 decision engine. </li></ul><br>       200   .  2 Feature extractor, 8 , 18   1 decision engine      1,2 . <br><br><h3>  </h3><br> <strong>Discovery .</strong>  ,   -   .  ,      ,    .    .      Meta Storage. <br><br> <strong>  pipeline</strong> .    ,  <strong>BPM</strong> .        yaml      ,     ,      . <br><br> <strong>    .</strong>       Java, Scala, R.    Python,       ,     .    API   ,   pipeline      . <br><br><h2>  Qual √© o resultado? </h2><br>    ‚Äî     .    ‚Äî   .   <strong> </strong> ,      .  ,         .     ‚Äî     2018 . <br><br>         ,      .    ‚Äî    ,   ,    . <br><br> <strong>    ,   </strong> .     ,    ,    notebook   ,     . <br><br><blockquote> , -      ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ,           .  ,     , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">UseData Conf</a> .  ,    ,       ,   16 . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt455648/">https://habr.com/ru/post/pt455648/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt455638/index.html">Alan Kay n√£o inventou objetos</a></li>
<li><a href="../pt455640/index.html">Marvin Minsky, ‚ÄúA M√°quina da Emo√ß√£o‚Äù: Cap√≠tulo 4. ‚ÄúComo Reconhecemos a Consci√™ncia‚Äù</a></li>
<li><a href="../pt455642/index.html">A arquitetura do servi√ßo de fila de mensagens distribu√≠das no Yandex.Cloud</a></li>
<li><a href="../pt455644/index.html">Usamos dados na pr√°tica</a></li>
<li><a href="../pt455646/index.html">Semana de Seguran√ßa 24: backdoors de f√°brica em smartphones Android</a></li>
<li><a href="../pt455650/index.html">Como treinamos uma rede neural para classificar parafusos</a></li>
<li><a href="../pt455652/index.html">Deep Learning vs senso comum: desenvolvendo um bot de bate-papo</a></li>
<li><a href="../pt455658/index.html">Lend√°rio Intel Core i7-2600K: testando Sandy Bridge em 2019 (parte 3)</a></li>
<li><a href="../pt455662/index.html">Grande display mec√¢nico com mecanismo de came como decodificador</a></li>
<li><a href="../pt455666/index.html">Construindo vendas de sa√≠da em uma empresa de servi√ßos de TI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
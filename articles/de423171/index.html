<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî± üì° üòú Wie Discord gleichzeitig 2,5 Millionen Voice-Chats mit WebRTC bedient üßïüèæ üóø üîà</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Von Anfang an haben wir Engineering- und Produktl√∂sungen geplant, damit Discord f√ºr Voice-Chat beim Spielen mit Freunden gut geeignet ist. Diese L√∂sun...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie Discord gleichzeitig 2,5 Millionen Voice-Chats mit WebRTC bedient</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/423171/"><img src="https://habrastorage.org/webt/no/3o/oj/no3oojc_pnuwknb6hcrplkrhtmq.jpeg"><br><br>  Von Anfang an haben wir Engineering- und Produktl√∂sungen geplant, damit Discord f√ºr Voice-Chat beim Spielen mit Freunden gut geeignet ist.  Diese L√∂sungen erm√∂glichten eine starke Skalierung des Systems mit einem kleinen Team und begrenzten Ressourcen. <br><br>  Dieser Artikel beschreibt die verschiedenen Technologien, die Discord f√ºr Audio- / Video-Chats verwendet. <br><br>  <i>Aus Gr√ºnden der Klarheit werden wir die gesamte Gruppe von Benutzern und Kan√§len als "Gruppe" (Gilde) bezeichnen - im Client werden sie "Server" genannt.</i>  <i>Stattdessen bezieht sich der Begriff ‚ÄûServer‚Äú auf unsere Serverinfrastruktur.</i> <br><a name="habracut"></a><br><h1>  Hauptprinzipien </h1><br>  Jeder Audio- / Video-Chat in Discord unterst√ºtzt viele Teilnehmer.  Wir haben tausend Menschen gesehen, die sich abwechselnd in Chats in gro√üen Gruppen unterhielten.  Eine solche Unterst√ºtzung erfordert eine Client-Server-Architektur, da ein Peer-to-Peer-Peer-to-Peer-Netzwerk mit zunehmender Teilnehmerzahl unerschwinglich teuer wird. <br><br>  Durch das Weiterleiten des Netzwerkverkehrs √ºber Discord-Server wird au√üerdem sichergestellt, dass Ihre IP-Adresse niemals sichtbar ist und niemand einen DDoS-Angriff startet.  Das Routing √ºber Server hat weitere Vorteile: Zum Beispiel Moderation.  Administratoren k√∂nnen Ton und Video f√ºr Eindringlinge schnell ausschalten. <br><br><h1>  Client-Architektur </h1><br>  Discord l√§uft auf vielen Plattformen. <br><br><ul><li>  Web (Chrome / Firefox / Edge usw.) </li><li>  Standalone-Anwendung (Windows, MacOS, Linux) </li><li>  Telefon (iOS / Android) </li></ul><br>  Wir k√∂nnen alle diese Plattformen nur auf eine Weise unterst√ºtzen: durch die Wiederverwendung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">WebRTC-</a> Code.  Diese Spezifikation f√ºr die Echtzeitkommunikation umfasst Netzwerk-, Audio- und Videokomponenten.  Der Standard wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vom World Wide Web Consortium</a> und der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Internet Engineering Group √ºbernommen</a> .  WebRTC ist in allen modernen Browsern und als native Bibliothek zur Implementierung in Anwendungen verf√ºgbar. <br><br>  Das Audio und Video in Discord l√§uft auf WebRTC.  Daher ist die Browseranwendung auf die Implementierung von WebRTC im Browser angewiesen.  Anwendungen f√ºr Desktops, iOS und Android verwenden jedoch eine einzige C ++ - Multimedia-Engine, die auf ihrer eigenen WebRTC-Bibliothek basiert und speziell auf die Bed√ºrfnisse unserer Benutzer zugeschnitten ist.  Dies bedeutet, dass einige Funktionen in der Anwendung besser funktionieren als im Browser.  In unseren nativen Anwendungen k√∂nnen wir beispielsweise: <br><br><ul><li>  Windows Volume Mute wird standardm√§√üig umgangen, wenn <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">alle Anwendungen bei Verwendung eines Headsets automatisch stummgeschaltet werden</a> .  Dies ist unerw√ºnscht, wenn Sie und Ihre Freunde einen Raid durchf√ºhren und die Discord-Chat-Aktivit√§ten koordinieren. </li><li>  Verwenden Sie Ihren eigenen Lautst√§rkeregler anstelle des globalen Betriebssystem-Mixers. </li><li>  Verarbeiten Sie die urspr√ºnglichen Audiodaten, um Sprachaktivit√§ten zu erkennen und Audio und Video in Spielen zu √ºbertragen. </li><li>  Reduzieren Sie die Bandbreite und den CPU-Verbrauch in Ruhephasen - selbst bei den meisten Voice-Chats zu einem bestimmten Zeitpunkt sprechen nur wenige Personen gleichzeitig. </li><li>  Bereitstellung systemweiter Funktionen f√ºr den Push-to-Talk-Modus. </li><li>  Senden Sie zusammen mit Audio-Video-Paketen zus√§tzliche Informationen (z. B. eine Priorit√§tsanzeige im Chat). </li></ul><br>  Eine eigene Version von WebRTC bedeutet h√§ufige Updates f√ºr alle Benutzer: Dies ist ein zeitaufw√§ndiger Prozess, den wir zu automatisieren versuchen.  Dieser Aufwand zahlt sich jedoch dank der spezifischen Funktionen f√ºr unsere Spieler aus. <br><br>  In Discord wird die Sprach- und Videokommunikation durch Eingabe eines Sprachkanals oder Anrufs initiiert.  Das hei√üt, die Verbindung wird immer vom Client initiiert. Dies verringert die Komplexit√§t der Client- und Serverteile und erh√∂ht auch die Fehlertoleranz.  Bei einem Infrastrukturausfall k√∂nnen sich die Teilnehmer einfach wieder mit dem neuen internen Server verbinden. <br><br><h3>  Unter unserer Kontrolle </h3><br>  Mit der Steuerung der nativen Bibliothek k√∂nnen Sie einige Funktionen anders implementieren als in der Browser-Implementierung von WebRTC. <br><br>  Erstens st√ºtzt sich WebRTC auf das Session Description Protocol ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SDP</a> ), um Audio / Video zwischen Teilnehmern auszuhandeln (bis zu 10 KB pro Paketaustausch).  In einer eigenen Bibliothek wird die untergeordnete API von WebRTC ( <code>webrtc::Call</code> ) verwendet, um beide Flows zu erstellen - eingehende und ausgehende.  Bei Verbindung mit einem Sprachkanal findet nur ein minimaler Informationsaustausch statt.  Dies ist die Adresse und der Port des Backend-Servers, die Verschl√ºsselungsmethode, die Schl√ºssel, der Codec und die Stream-Identifikation (ca. 1000 Byte). <br><br><pre> <code class="cpp hljs">webrtc::<span class="hljs-function"><span class="hljs-function">AudioSendStream* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createAudioSendStream</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">uint32_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> ssrc, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">uint8_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> payloadType, webrtc::Transport* transport, rtc::scoped_refptr&lt;webrtc::AudioEncoderFactory&gt; audioEncoderFactory, webrtc::Call* call)</span></span></span><span class="hljs-function"> </span></span>{ webrtc::AudioSendStream::Config config{transport}; config.rtp.ssrc = ssrc; config.rtp.extensions = {{<span class="hljs-string"><span class="hljs-string">"urn:ietf:params:rtp-hdrext:ssrc-audio-level"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>}}; config.encoder_factory = audioEncoderFactory; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> webrtc::SdpAudioFormat kOpusFormat = {<span class="hljs-string"><span class="hljs-string">"opus"</span></span>, <span class="hljs-number"><span class="hljs-number">48000</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>}; config.send_codec_spec = webrtc::AudioSendStream::Config::SendCodecSpec(payloadType, kOpusFormat); webrtc::AudioSendStream* audioStream = call-&gt;CreateAudioSendStream(config); audioStream-&gt;Start(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> audioStream; }</code> </pre> <br>  Dar√ºber hinaus verwendet WebRTC Interactive Connectivity Establishment ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ICE</a> ), um die beste Route zwischen den Teilnehmern zu ermitteln.  Da jeder Client eine Verbindung zum Server herstellt, ben√∂tigen wir keinen ICE.  Auf diese Weise k√∂nnen Sie eine viel zuverl√§ssigere Verbindung herstellen, wenn Sie sich hinter NAT befinden, und Ihre IP-Adresse vor anderen Teilnehmern geheim halten.  Clients pingen regelm√§√üig, damit die Firewall eine offene Verbindung aufrechterh√§lt. <br><br>  Schlie√ülich verwendet WebRTC das Secure Real-Time Transport Protocol ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SRTP</a> ) zum Verschl√ºsseln von Medien.  Verschl√ºsselungsschl√ºssel werden mithilfe des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DTLS-</a> Protokolls (Datagram Transport Layer Security) basierend auf Standard-TLS festgelegt.  Mit der integrierten WebRTC-Bibliothek k√∂nnen Sie mithilfe der <code>webrtc::Transport</code> API Ihre eigene Transportschicht implementieren. <br><br>  Anstelle von DTLS / SRTP haben wir uns f√ºr eine schnellere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Salsa20-Verschl√ºsselung entschieden</a> .  Dar√ºber hinaus senden wir in Ruhephasen keine Audiodaten - ein h√§ufiges Ereignis, insbesondere in gro√üen Chatrooms.  Dies f√ºhrt zu erheblichen Einsparungen bei der Bandbreite und den CPU-Ressourcen. Sowohl der Client als auch der Server m√ºssen jedoch jederzeit bereit sein, um den Datenempfang zu beenden und die Seriennummern von Audio- / Videopaketen neu zu schreiben. <br><br>  Da die Webanwendung die browserbasierte Implementierung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">WebRTC-API verwendet</a> , k√∂nnen SDP, ICE, DTLS und SRTP nicht abgebrochen werden.  Der Client und der Server tauschen alle erforderlichen Informationen aus (weniger als 1200 Byte beim Austausch von Paketen) - und die SDP-Sitzung wird auf der Grundlage dieser Informationen f√ºr Clients eingerichtet.  Das Backend ist daf√ºr verantwortlich, die Unterschiede zwischen Desktop- und Browseranwendungen zu beheben. <br><br><h1>  Backend-Architektur </h1><br>  Es gibt mehrere Voice-Chat-Dienste im Backend, aber wir werden uns auf drei konzentrieren: Discord Gateway, Discord Guilds und Discord Voice.  Alle unsere Signalserver sind in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Elixir geschrieben</a> , sodass wir Code wiederholt wiederverwenden k√∂nnen. <br><br>  Wenn Sie online sind, unterst√ºtzt Ihr Client eine WebSocket-Verbindung zu einem Discord Gateway (wir nennen es eine WebSocket- <i>Gateway-</i> Verbindung).  √úber diese Verbindung erh√§lt Ihr Client Ereignisse in Bezug auf Gruppen und Kan√§le, Textnachrichten, Anwesenheitspakete usw. <br><br>  Bei Verbindung mit einem Sprachkanal wird der Verbindungsstatus vom Sprachstatusobjekt angezeigt.  Der Client aktualisiert dieses Objekt √ºber die Gateway-Verbindung. <br><br><pre> <code class="hljs pgsql">defmodule VoiceStates.VoiceState <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> @<span class="hljs-keyword"><span class="hljs-keyword">type</span></span> t :: %{ session_id: String.t(), user_id: Number.t(), channel_id: Number.t() | nil, token: String.t() | nil, mute: <span class="hljs-type"><span class="hljs-type">boolean</span></span>, deaf: <span class="hljs-type"><span class="hljs-type">boolean</span></span>, self_mute: <span class="hljs-type"><span class="hljs-type">boolean</span></span>, self_deaf: <span class="hljs-type"><span class="hljs-type">boolean</span></span>, self_video: <span class="hljs-type"><span class="hljs-type">boolean</span></span>, suppress: <span class="hljs-type"><span class="hljs-type">boolean</span></span> } defstruct session_id: nil, user_id: nil, token: nil, channel_id: nil, mute: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, deaf: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, self_mute: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, self_deaf: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, self_video: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, suppress: <span class="hljs-keyword"><span class="hljs-keyword">false</span></span> <span class="hljs-keyword"><span class="hljs-keyword">end</span></span></code> </pre> <br>  Wenn Sie mit einem Sprachkanal verbunden sind, wird Ihnen einer der Discord Voice-Server zugewiesen.  Er ist daf√ºr verantwortlich, jedem Teilnehmer des Kanals Ton zu √ºbertragen.  Alle Sprachkan√§le in einer Gruppe sind einem Server zugeordnet.  Wenn Sie als erster chatten, ist der Discord Guilds-Server daf√ºr verantwortlich, den Discord Voice-Server der gesamten Gruppe gem√§√ü dem unten beschriebenen Verfahren zuzuweisen. <br><br><h3>  Discord Voice Server-Ziel </h3><br>  Jeder Discord Voice-Server meldet regelm√§√üig seinen Status und seine Auslastung.  Diese Informationen werden in einem Service Discovery-System <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">abgelegt</a> (wir verwenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">etcd</a> ), wie in einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorherigen Artikel</a> erl√§utert. <br><br>  Der Discord Guilds-Server √ºberwacht das Service Discovery-System und weist der Gruppe den am wenigsten verwendeten Discord Voice-Server in der Region zu.  Bei Auswahl dieser Option werden alle Sprachstatusobjekte (auch vom Discord Guilds-Server unterst√ºtzt) auf den Discord Voice-Server √ºbertragen, damit er die Audio- / Video-Weiterleitung konfigurieren kann.  Clients werden √ºber den ausgew√§hlten Discord Voice-Server benachrichtigt.  Anschlie√üend √∂ffnet der Client die <i>zweite</i> WebSocket-Verbindung mit dem Sprachserver (wir nennen sie die WebSocket- <i>Sprachverbindung</i> ), mit der die Multimedia-Weiterleitung und die Sprachanzeige konfiguriert werden. <br><br>  Wenn der Client den Status " <i>Warten auf Endpunkt"</i> anzeigt, bedeutet dies, dass der Discord Guilds-Server nach dem optimalen Discord Voice-Server sucht.  Eine <i>Voice Connected-</i> Nachricht zeigt an, dass der Client erfolgreich UDP-Pakete mit dem ausgew√§hlten Discord Voice-Server ausgetauscht hat. <br><br>  Der Discord Voice-Server enth√§lt zwei Komponenten: ein Signalmodul und eine Multimedia-Relaiseinheit, die als selektive Weiterleitungseinheit ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SFU</a> ) bezeichnet wird.  Das Signalmodul steuert die SFU vollst√§ndig und ist f√ºr die Generierung von Flusskennungen und Verschl√ºsselungsschl√ºsseln, die Umleitung von Sprachindikatoren usw. verantwortlich. <br><br>  Unsere SFU (in C ++) ist f√ºr die Leitung des Audio- und Videoverkehrs zwischen Kan√§len verantwortlich.  Es ist eigenst√§ndig entwickelt: F√ºr unseren speziellen Fall bietet die SFU maximale Leistung und damit die gr√∂√üten Einsparungen.  Wenn Moderatoren gegen den Server versto√üen (ihn stumm schalten), werden ihre Audiopakete nicht verarbeitet.  SFU fungiert auch als Br√ºcke zwischen nativen und browserbasierten Anwendungen: Es implementiert Transport und Verschl√ºsselung sowohl f√ºr Browser- als auch f√ºr native Anwendungen und konvertiert Pakete w√§hrend der √úbertragung.  Schlie√ülich ist die SFU f√ºr die Verarbeitung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RTCP-</a> Protokolls verantwortlich, mit dem die Videoqualit√§t optimiert wird.  Die SFU sammelt und verarbeitet RTCP-Berichte von Empf√§ngern - und benachrichtigt die Absender, welches Band f√ºr die Video√ºbertragung verf√ºgbar ist. <br><br><h1>  Fehlertoleranz </h1><br>  Da nur Discord Voice-Server direkt aus dem Internet verf√ºgbar sind, werden wir dar√ºber sprechen. <br><br>  Das Signalmodul √ºberwacht kontinuierlich die SFU.  Wenn es abst√ºrzt, wird es sofort mit einer minimalen Unterbrechung des Dienstes neu gestartet (mehrere verlorene Pakete).  Der SFU-Status wird vom Signalmodul ohne Interaktion mit dem Client wiederhergestellt.  Obwohl SFU-Abst√ºrze selten sind, verwenden wir denselben Mechanismus, um SFUs ohne Betriebsunterbrechungen zu aktualisieren. <br><br>  Wenn der Discord Voice-Server abst√ºrzt, reagiert er nicht auf Ping - und wird aus dem Service Discovery-System entfernt.  Der Client bemerkt auch einen Serverabsturz aufgrund einer unterbrochenen WebSocket-Sprachverbindung und fordert dann den <i>Ping des Sprachservers</i> √ºber die WebSocket-Gateway-Verbindung an.  Der Discord Guilds-Server best√§tigt den Fehler, konsultiert das Service Discovery-System und weist der Gruppe einen neuen Discord Voice-Server zu.  Die Discord Guilds senden dann alle Sprachstatusobjekte an den neuen Sprachserver.  Alle Clients erhalten eine Benachrichtigung √ºber den neuen Server und stellen eine Verbindung zu diesem her, um das Multimedia-Setup zu starten. <br><br><img src="https://habrastorage.org/webt/tw/1r/kz/tw1rkzplhbqsax95lajz9-ylluu.gif"><br><br>  Sehr oft fallen Discord Voice-Server unter DDoS (wir sehen dies an der raschen Zunahme eingehender IP-Pakete).  In diesem Fall f√ºhren wir das gleiche Verfahren aus wie beim Absturz des Servers: Wir entfernen ihn aus dem Service Discovery-System, w√§hlen einen neuen Server aus, √ºbertragen alle Sprachkommunikationsstatusobjekte an ihn und benachrichtigen Clients √ºber den neuen Server.  Wenn der DDoS-Angriff abgeklungen ist, kehrt der Server zum Service Discovery-System zur√ºck. <br><br>  Wenn der Gruppeninhaber beschlie√üt, eine neue Region f√ºr die Abstimmung auszuw√§hlen, folgen wir einem sehr √§hnlichen Verfahren.  Discord Guilds Server w√§hlt in Absprache mit einem Service Discovery-System den besten verf√ºgbaren Sprachserver in einer neuen Region aus.  Anschlie√üend √ºbersetzt er alle Objekte des Status der Sprachkommunikation und benachrichtigt die Clients √ºber den neuen Server.  Clients unterbrechen die aktuelle WebSocket-Verbindung mit dem alten Discord Voice-Server und stellen eine neue Verbindung mit dem neuen Discord Voice-Server her. <br><br><h1>  Skalieren </h1><br>  Die gesamte Infrastruktur von Discord Gateway, Discord Guilds und Discord Voice unterst√ºtzt die horizontale Skalierung.  Discord Gateway und Discord Guilds arbeiten in der Google Cloud. <br><br>  Wir haben weltweit mehr als 850 Sprachserver in 13 Regionen (in mehr als 30 Rechenzentren).  Diese Infrastruktur bietet eine gr√∂√üere Redundanz bei Ausf√§llen in Rechenzentren und DDoS.  Wir arbeiten mit mehreren Partnern zusammen und verwenden unsere physischen Server in deren Rechenzentren.  In j√ºngerer Zeit wurde die s√ºdafrikanische Region hinzugef√ºgt.  Dank technischer Anstrengungen sowohl in der Client- als auch in der Serverarchitektur kann Discord jetzt mehr als 2,6 Millionen Voice-Chat-Benutzer mit ausgehendem Datenverkehr von mehr als 220 Gbit / s und 120 Millionen Paketen pro Sekunde gleichzeitig bedienen. <br><br><h1>  Was weiter? </h1><br>  Wir √ºberwachen st√§ndig die Qualit√§t der Sprachkommunikation (Metriken werden vom Client an die Backend-Server gesendet).  Diese Informationen werden in Zukunft dazu beitragen, die Verschlechterung automatisch zu erkennen und zu beseitigen. <br><br>  Wir haben zwar vor einem Jahr Video-Chat und Screencasts gestartet, aber jetzt k√∂nnen sie nur noch in privaten Nachrichten verwendet werden.  Video ben√∂tigt im Vergleich zu Audio deutlich mehr CPU-Leistung und Bandbreite.  Die Herausforderung besteht darin, die Menge an Bandbreite und CPU / GPU-Ressourcen auszugleichen, die verwendet werden, um die beste Videoqualit√§t sicherzustellen, insbesondere wenn sich eine Gruppe von Spielern in einem Kanal auf verschiedenen Ger√§ten befindet.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die</a> SVC-Technologie ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scalable Video Coding</a> ), eine Erweiterung des H.264 / MPEG-4 AVC-Standards, kann eine L√∂sung f√ºr das Problem darstellen. <br><br>  Screencasts ben√∂tigen aufgrund der h√∂heren FPS und Aufl√∂sung als herk√∂mmliche Webcams noch mehr Bandbreite als Video.  Wir arbeiten derzeit an der Unterst√ºtzung der hardwarebasierten Videokodierung in einer Desktop-Anwendung. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de423171/">https://habr.com/ru/post/de423171/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de423161/index.html">Unternehmen wollen personenbezogene Daten</a></li>
<li><a href="../de423163/index.html">CryptoPro mit Mono verbinden</a></li>
<li><a href="../de423165/index.html">Dynamische Netzzeichnung in Unreal Engine 4</a></li>
<li><a href="../de423167/index.html">Was Mark Zuckerberg √ºber Facebook-Themen spricht. Die Hauptsache aus dem Artikel von The New Yorker</a></li>
<li><a href="../de423169/index.html">Start des Tages (Juli-August 2018)</a></li>
<li><a href="../de423173/index.html">Minimale Zeit - maximaler Schmerz</a></li>
<li><a href="../de423175/index.html">Warum eine eigene Spiel-Engine schreiben?</a></li>
<li><a href="../de423177/index.html">Microsoft Azure-Sicherheitsinfrastrukturbuch</a></li>
<li><a href="../de423179/index.html">Anwendungshandbuch f√ºr die Cloud-Architektur</a></li>
<li><a href="../de423181/index.html">Azure-Entwicklerhandbuch</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
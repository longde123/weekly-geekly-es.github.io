<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüë©‚Äçüëß‚Äçüëß üëÜüèæ ‚ôãÔ∏è C√¢meras de profundidade - revolu√ß√£o silenciosa (quando os rob√¥s ver√£o) Parte 2 ü•ö üë®üèæ‚Äç‚úàÔ∏è üê©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Na primeira parte deste texto, examinamos as c√¢meras de profundidade com base nas medi√ß√µes de luz estrutural e atraso da luz de ida e volta, que usam ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√¢meras de profundidade - revolu√ß√£o silenciosa (quando os rob√¥s ver√£o) Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458458/"><img src="https://habrastorage.org/webt/uy/lx/0t/uylx0tpbzxlqa5hnxqzjnriruoy.png"><br><br>  Na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeira parte</a> deste texto, examinamos as c√¢meras de profundidade com base nas medi√ß√µes de luz estrutural e atraso da luz de ida e volta, que usam principalmente ilumina√ß√£o infravermelha.  Eles funcionam muito bem em ambientes fechados, a dist√¢ncias entre 10 cent√≠metros e 10 metros, e o mais importante - s√£o muito baratos.  Da√≠ a enorme onda de seu uso atual em smartphones.  Mas ... Assim que sa√≠mos, o sol, mesmo atrav√©s das nuvens, ilumina a luz infravermelha e seu trabalho se deteriora acentuadamente. <br><br>  Como Steve Blank diz ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">por outro motivo</a> , no entanto): "Se voc√™ quer sucesso, saia do pr√©dio".  Abaixo, falaremos sobre c√¢meras de profundidade trabalhando ao ar livre.  Hoje, esse t√≥pico √© fortemente dirigido por carros aut√¥nomos, mas, como veremos, n√£o apenas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/659/8b4/4b2/6598b44b2d0a420dd83a434753cc6ffb.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Innoviz prev√™ carros aut√¥nomos produzidos em massa com LiDAR de estado s√≥lido</a></i> <br><br>  Ent√£o, c√¢meras de profundidade, ou seja,  dispositivos que gravam v√≠deo, em cada pixel cuja dist√¢ncia at√© a cena objeto, trabalhando sob a luz do sol! <br><br>  Quem se importa - bem-vindo ao kat! <br><a name="habracut"></a><br>  Vamos come√ßar com os cl√°ssicos atemporais ... <br><br><h1>  M√©todo 3: Profundidade da c√¢mera est√©reo </h1><br>  A constru√ß√£o de um mapa de profundidade a partir de est√©reo √© bem conhecida e tem sido usada h√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mais de 40 anos</a> .  Abaixo est√° um exemplo de uma c√¢mera compacta por US $ 450, que pode ser usada para controlar gestos, al√©m de fotografias profissionais ou capacetes VR: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/594/0ab/3b0/5940ab3b0cbc72369d80083d8d32be57.png"><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fonte</a></i> <br><br>  A principal vantagem dessas c√¢meras √© que a luz do sol n√£o apenas as incomoda, mas vice-versa, melhora seus resultados e, como resultado, o uso ativo dessas c√¢meras para todos os tipos de caixas de rua, por exemplo, √© um √≥timo exemplo de como fotografar um modelo tridimensional de um antigo forte em alguns minutos: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AFH2yN3rM78" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um exemplo de uso na rua da c√¢mera ZED</a></i> <br><br>  O dinheiro not√°vel na tradu√ß√£o da constru√ß√£o da profundidade do est√©reo para um novo n√≠vel foi influenciado, √© claro, pelo t√≥pico dos carros aut√¥nomos.  Dos 5 m√©todos considerados para a constru√ß√£o de um v√≠deo de profundidade, apenas dois - este e o pr√≥ximo (est√©reo e plen√≥ptico) n√£o interferem no sol e n√£o interferem nos carros vizinhos.  Ao mesmo tempo, os plen√≥pticos s√£o muitas vezes mais caros e menos precisos em longas dist√¢ncias.  Pode acontecer de qualquer maneira, √© dif√≠cil fazer previs√µes, mas, neste caso, vale a pena concordar com Elon Musk - dos cinco m√©todos em est√©reo, os melhores t√™m perspectivas.  E os resultados atuais s√£o muito encorajadores: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12e/cec/e3f/12ecece3f83fc654f64023e1391c38bb.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SLAM direto em larga escala com c√¢meras est√©reo</a></i> <br><br>  Mas √© interessante que, ao que parece, n√£o ve√≠culos n√£o tripulados (dos quais existem poucos at√© agora), mas dispositivos muito mais massivos, onde um mapa de profundidade est√©reo est√° sendo constru√≠do agora, ter√£o uma influ√™ncia ainda mais forte no desenvolvimento da constru√ß√£o de profundidade a partir de est√©reo, a saber ... Isso mesmo!  Smartphones! <br><br>  H√° tr√™s anos, simplesmente houve o boom dos smartphones "de dois olhos", nos quais praticamente todas as marcas foram observadas, porque a qualidade das fotos tiradas com uma c√¢mera e a qualidade das fotos tiradas com duas diferiam drasticamente, mas do ponto de vista do aumento do pre√ßo de um smartphone, isso n√£o era t√£o significativo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ab7/6b4/b3e/ab76b4b3e9696443e5191d293b59e663.png"><br><br>  Al√©m disso, no ano passado, o processo foi ainda mais longe: ‚ÄúVoc√™ tem 2 c√¢meras no seu smartphone?  Sucks!  Eu tenho <s>tr√™s</s> quatro !!! ‚Äù: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48f/905/554/48f905554fab15bcc6ce668c0c5f9ef7.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Samsung Galaxy A8 e A9</a></i> <br><br>  O futuro de seis olhos da Sony foi mencionado na primeira parte.  Em geral, os smartphones com v√°rios olhos est√£o ganhando popularidade entre os fabricantes. <br><br>  As causas fundamentais deste fen√¥meno s√£o simples: <br><br><ul><li>  A resolu√ß√£o dos telefones com c√¢mera est√° aumentando e o tamanho da lente √© pequeno.  Como resultado, apesar dos in√∫meros truques, o n√≠vel de ru√≠do aumenta e a qualidade diminui, especialmente ao fotografar no escuro. <br></li><li>  Al√©m disso, na segunda c√¢mera, podemos remover o chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">filtro Bayer</a> da matriz, ou seja,  uma c√¢mera ser√° preto e branco e a segunda cor.  Isso aumenta a sensibilidade em preto e branco em cerca de 3 vezes.  I.e.  a sensibilidade de 2 c√¢meras cresce condicionalmente, n√£o 2, mas 4 vezes (!).  Existem in√∫meras nuances, mas esse aumento na sensibilidade √© realmente claramente vis√≠vel a olho nu. <br></li><li>  Entre outras coisas, quando um par est√©reo aparece, temos a oportunidade de alterar programaticamente a profundidade de campo, ou seja,  desfoque o fundo, do qual muitas fotos se beneficiam significativamente (escrevemos sobre isso no segundo semestre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> ).  Essa op√ß√£o de novos modelos de smartphones rapidamente se tornou extremamente popular. <br></li><li>  Com um aumento no n√∫mero de c√¢meras, tamb√©m √© poss√≠vel usar outras lentes - maior <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">angular</a> (foco curto) e, inversamente, foco longo, o que pode melhorar significativamente a qualidade ao "aproximar" de objetos. <br></li><li>  Curiosamente, um aumento no n√∫mero de c√¢meras nos aproxima do tema de um campo de luz rarefeito, que possui muitas de suas caracter√≠sticas e vantagens; no entanto, essa √© uma hist√≥ria diferente. <br></li><li>  Tamb√©m observamos que aumentar o n√∫mero de c√¢meras permite aumentar a resolu√ß√£o por m√©todos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">recupera√ß√£o de resolu√ß√£o</a> . <br></li></ul><br>  Em geral, existem tantas vantagens que, quando as pessoas est√£o cientes delas, come√ßam a se perguntar por que pelo menos duas c√¢meras n√£o foram configuradas por um longo tempo. <br><br>  E ent√£o acontece que nem tudo √© t√£o simples.  Para usar significativamente c√¢meras adicionais para melhorar a imagem (e n√£o apenas mudar para uma c√¢mera com uma lente diferente), somos obrigados a construir um chamado mapa de disparidade, que √© diretamente convertido em um mapa de profundidade.  E essa √© uma tarefa n√£o trivial, para a qual a solu√ß√£o dos smartphones acabou de chegar.  E mesmo agora, os mapas de profundidade s√£o geralmente de qualidade bastante duvidosa.  Ou seja, antes que a correspond√™ncia exata "pixel na imagem direita e pixel √† esquerda" ainda precise sobreviver.  Por exemplo, aqui est√£o exemplos reais de mapas de profundidade para o iPhone: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/221/1f2/7d2/2211f27d2bfb2dc01da93559e8d1d8d1.png"><br>  <i>Fonte: <a href="">Compara√ß√£o do iPhone XS e XR Depth Map</a></i> <br><br>  Mesmo a olho nu, os problemas de massa s√£o claramente vis√≠veis ao fundo, nas fronteiras, fico em sil√™ncio sobre cabelos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">transl√∫cidos</a> .  Portanto, existem numerosos problemas que surgem ao transferir cores de uma c√¢mera em preto e branco para outra colorida e durante o processamento posterior. <br><br>  Por exemplo, aqui est√° um bom exemplo de um relat√≥rio sobre "Cria√ß√£o de efeitos de foto e v√≠deo usando profundidade" da Apple: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83c/38f/efc/83c38fefc85d9e1ddef931b594e20469.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Criando efeitos de foto e v√≠deo ‚Ä¢ Usando Depth, Apple, WWDC18</a></i> <br><br>  Voc√™ pode ver claramente como a profundidade √© de buggy sob o cabelo e, de fato, contra qualquer fundo mais ou menos uniforme, mas mais importante: no mapa de fosqueamento direito, o colar foi para o fundo (ou seja, ficar√° emba√ßado).  Outro problema √© a resolu√ß√£o real da profundidade e o mapa de fosqueamento √© significativamente menor que a resolu√ß√£o da imagem, o que tamb√©m afeta a qualidade durante o processamento: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/848/dcb/5cf/848dcb5cf62ea5991a85b23160fc1ce9.png"><br><br>  No entanto, tudo isso √© um problema de crescimento.  Se h√° quatro anos atr√°s n√£o havia d√∫vida de efeitos s√©rios no v√≠deo, o telefone simplesmente "n√£o os puxava", mas hoje o processamento de v√≠deo com profundidade √© mostrado a si mesmo nos principais telefones seriais (foi na mesma apresenta√ß√£o da Apple): <br><br><img width="25%" src="https://habrastorage.org/getpro/habr/post_images/481/5fe/6f8/4815fe6f8f9e7fd837a4e410df01a0da.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Criando efeitos de foto e v√≠deo ‚Ä¢ Usando Depth, Apple, WWDC18</a></i> <br><br>  Em geral, o t√≥pico de telefones multi-multi-celulares e, como resultado, o t√≥pico de obter profundidade do est√©reo em telefones celulares - conquista as massas sem brigar: <br><br><img width="66%" src="https://habrastorage.org/webt/t2/ba/sz/t2basz3pj6tskae0fqox5ol3x-q.png"><br>  <i>Fonte: "encontrado nestes da sua internet"</i> <br><br>  Principais conclus√µes: <br><br><ul><li>  Profundidade est√©reo - em termos de custo do equipamento - a maneira mais barata de obter profundidade, j√° que as c√¢meras agora s√£o baratas e continuam a ficar mais baratas rapidamente.  A dificuldade √© que o processamento adicional consome muito mais recursos do que em outros m√©todos. <br></li><li>  Em telefones celulares, voc√™ n√£o pode aumentar o di√¢metro da lente, enquanto a resolu√ß√£o aumenta rapidamente.  Como resultado, o uso de duas ou mais c√¢meras pode melhorar significativamente a qualidade da foto, reduzir o ru√≠do em condi√ß√µes de pouca luz e aumentar a resolu√ß√£o.  Como hoje em dia um telefone celular geralmente √© escolhido pela qualidade da c√¢mera, essa √© uma vantagem extremamente tang√≠vel.  Construir um mapa de profundidade √© um b√¥nus secund√°rio impercept√≠vel. <br></li><li>  As principais desvantagens da constru√ß√£o de profundidade a partir do est√©reo: <br><ul><li>  Assim que a textura desaparece ou simplesmente se torna menos contrastante, o ru√≠do aumenta acentuadamente em profundidade, como resultado, mesmo em objetos simples, a profundidade geralmente √© pouco usada (erros graves s√£o poss√≠veis). <br></li><li>  Al√©m disso, a profundidade √© pouco determinada em objetos finos e de tamanho pequeno (dedos "cortados" ou mesmo m√£os, colunas afundadas etc.) <br></li></ul></li><li>  Assim que o poder do ferro permitir que voc√™ construa um mapa de profundidade para v√≠deo, a profundidade dos smartphones dar√° um poderoso impulso ao desenvolvimento do AR (em algum momento, completamente inesperado para o p√∫blico, a qualidade dos aplicativos de AR em todos os novos modelos de telefone, incluindo os or√ßados, subitamente se tornar√° visivelmente mais alta e uma nova onda ocorrer√°) .  Totalmente inesperado! <br></li></ul><br>  O pr√≥ximo m√©todo √© menos trivial e famoso, mas muito legal.  Me encontre! <br><br><h1>  M√©todo 4: C√¢meras de profundidade de campo claro </h1><br>  O t√≥pico dos plen√≥pticos (do latim plenus - full e optikos - visual) ou campos de luz ainda √© relativamente pouco conhecido pelas massas, embora os profissionais tenham come√ßado a estud√°-lo muito densamente.  Se√ß√µes separadas foram alocadas para artigos sobre Light Field em muitas confer√™ncias importantes (o autor j√° foi atingido pelo n√∫mero de pesquisadores asi√°ticos na Confer√™ncia Internacional de Multim√≠dia e Expo do IEEE, que est√£o intimamente envolvidos neste t√≥pico). <br><br>  O Google Trends diz que os Estados Unidos e a Austr√°lia lideram o interesse em Light Field, seguidos por Cingapura e Cor√©ia.  Gr√£-Bretanha  A R√∫ssia est√° em 32 lugar ... Corrigiremos o atraso da √çndia e da √Åfrica do Sul: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/651/993/87b/65199387b858541acc6ff99a129c2fe3.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Google Trends</a></i> <br><br>  Seu humilde servo, h√° algum tempo, fez um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo detalhado sobre Habr√©</a> com uma descri√ß√£o detalhada de como ele funciona e o que d√°, ent√£o vamos ver brevemente. <br><br>  A id√©ia principal √© tentar corrigir em cada ponto n√£o apenas a luz, mas uma matriz bidimensional de raios de luz, tornando cada quadro quadridimensional.  Na pr√°tica, isso √© feito usando uma matriz de microlentes: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/90f/203/fb4/90f203fb49d7e464638a4f164e96fb26.gif"></a> <br>  <i>Fonte: <a href="">plenoptic.inf¬Æ (recomendado para clicar e ver em resolu√ß√£o total)</a></i> <br><br>  Como resultado, temos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">muitas novas oportunidades</a> , mas a resolu√ß√£o est√° caindo seriamente.  Tendo resolvido muitos problemas t√©cnicos complicados, eles aumentaram radicalmente a resolu√ß√£o no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lytro</a> (comprada pelo Google), onde no Lytro Cinema a resolu√ß√£o do sensor da c√¢mera foi aumentada para 755 megapixels de dados RAW e parecia volumosa como as primeiras c√¢meras: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3ec/631/027/3ec6310271829f9272a4d3ef41462bde.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NAB: √â revelada a nova c√¢mera Lytro Light Field que poderia trazer grandes mudan√ßas no trabalho de efeitos visuais</a></i> <br><br>  √â interessante que mesmo os profissionais regularmente avaliam incorretamente a queda de resolu√ß√£o das c√¢meras plen√≥pticas, porque subestimam o qu√£o bem podem trabalhar nos algoritmos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">super resolu√ß√£o</a> que realmente restauram perfeitamente muitos detalhes das micro-mudan√ßas de imagem no campo de luz (preste aten√ß√£o a agulhas de tric√¥ emba√ßadas e oscila√ß√µes em segundo plano) : <br><br><img width="200%" src="https://habrastorage.org/getpro/habr/post_images/bc9/6cd/e55/bc96cde55e276f4420757de5359467b1.gif"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Restaura√ß√£o de quadro plen√≥ptico ing√™nuo, inteligente e de super resolu√ß√£o</a> do Relat√≥rio T√©cnico da Adobe ‚ÄúSuperresolution with Plenoptic Camera 2.0‚Äù</i> <br><br>  Tudo isso seria de interesse relativamente te√≥rico se o Google n√£o implementasse os plen√≥pticos no Pixel 2 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cobrindo com uma lente 2 pixels</a> : <br><br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/852/c36/209/852c36209a7528f576e20dc37e0ef1f3.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI Google Blog</a></i> <br><br>  Como resultado, formou-se um micro estereopar, que permitiu avaliar a profundidade com que o Google, fiel √†s novas tradi√ß√µes, adicionou redes neurais e, de maneira geral, observou-se: <br><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/429/442/99e/42944299e72b7eb720f3babc5a757b79.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/da3/fe1/3ea/da3fe13eacb3cd5b0a558db1d843b686.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/c6f/a27/c4b/c6fa27c4bac8b9c5cb122e0c69ab814d.png"><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/2ba/e97/e67/2bae97e67ae10cd150ef28ccdc6cc458.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/88a/159/34f/88a15934f1192deb0da889a630fed232.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/d7d/eab/811/d7deab81164e7e886b42a95173c58641.png"><br><br>  Mais exemplos de profundidade em resolu√ß√£o total <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">em uma galeria especial</a> . <br><br>  Curiosamente, a profundidade √© armazenada pelo Google (como Huawei e outros) na pr√≥pria imagem, para que voc√™ possa extra√≠-la e ver: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d63/958/b09/d63958b09a9584752a90f014adfadc24.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tr√™s recursos secretos do novo aplicativo de c√¢mera do Google que v√£o explodir sua mente</a></i> <br><br>  E ent√£o voc√™ pode transformar a foto em tridimensional: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48b/3a5/e71/48b3a5e7156a14dcf60c600472154f6c.gif"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tr√™s recursos secretos do novo aplicativo de c√¢mera do Google que v√£o explodir sua mente</a></i> <br><br>  Voc√™ pode experimentar isso de forma independente no site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://depthy.me</a> , onde voc√™ pode enviar sua foto.  Curiosamente, o site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">est√° dispon√≠vel na fonte</a> , ou seja,  o processamento em profundidade pode ser aprimorado, h√° muitas oportunidades para isso, agora os algoritmos de processamento mais simples s√£o aplicados l√°. <br><br>  Pontos-chave: <br><br><ul><li>  Em uma das confer√™ncias do Google, foi anunciado que talvez quatro pixels seriam cobertos com uma lente.  Isso reduzir√° a resolu√ß√£o direta do sensor, mas melhorar√° drasticamente o mapa de profundidade.  Em primeiro lugar, devido ao aparecimento de estere√≥tipos em duas dire√ß√µes perpendiculares e, em segundo lugar, devido ao fato de que a base est√©reo aumentar√° condicionalmente em 1,4 vezes (duas diagonais).  Isso tamb√©m significa uma melhoria acentuada na precis√£o da profundidade √† dist√¢ncia. <br></li><li>  O pr√≥prio Plenoptics (tamb√©m √© uma fotografia calculada) permite: <br><ul><li>  A mudan√ßa "honesta" do foco e da profundidade de campo ap√≥s o disparo √© a capacidade mais conhecida dos sensores plen√≥pticos. <br></li><li>  Calcular a forma da abertura. <br></li><li>  Calcular a ilumina√ß√£o da cena. <br></li><li>  Mude um pouco o ponto de disparo, incluindo o recebimento de est√©reo (ou quadro de v√°rios √¢ngulos) com uma lente. <br></li><li>  Calcule a resolu√ß√£o, porque usando a complexidade computacional pesada dos algoritmos de Super Resolu√ß√£o, voc√™ pode realmente restaurar o quadro. <br></li><li>  Calcular um mapa de transpar√™ncia para bordas transl√∫cidas. <br></li><li>  E, finalmente, construa um mapa de profundidade, que √© importante hoje. <br></li></ul></li><li>  Potencialmente, <b>quando a c√¢mera principal do telefone pode criar um mapa de profundidade de alta qualidade em tempo real, paralelamente ao disparo, isso cria uma revolu√ß√£o</b> .  Isso depende em grande parte do poder de computa√ß√£o a bordo (√© isso que nos impede de fazer mapas de profundidade de resolu√ß√£o melhor e mais alta em tempo real hoje).  Isso √© mais interessante para o AR, √© claro, mas haver√° muitas oportunidades para alterar as fotos. <br></li></ul><br>  E, finalmente, passamos ao √∫ltimo neste m√©todo de revis√£o de medi√ß√£o de profundidade. <br><br><h1>  M√©todo 5: c√¢meras em tecnologias lidar </h1><br>  Em geral, os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tel√©metros a laser est√£o</a> firmemente entrincheirados em nossas vidas, s√£o baratos e oferecem alta precis√£o.  Os primeiros lidares (do LIDaR - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Light Identification Detection and Ranging</a> ), constru√≠dos como feixes de dispositivos semelhantes girando em torno de um eixo horizontal, foram usados ‚Äã‚Äãprimeiro pelos militares e depois testados em pilotos autom√°ticos de carros.  Eles provaram ser muito bons l√°, o que causou um poderoso aumento nos investimentos na regi√£o.  Inicialmente, os lidares giravam, dando uma imagem semelhante v√°rias vezes por segundo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed4/984/265/ed49842653721c8d7e6dae51c290166d.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Uma introdu√ß√£o ao LIDAR: o principal sensor aut√¥nomo do carro</a></i> <br><br>  Era desconfort√°vel, pouco confi√°vel devido √†s partes m√≥veis e bastante caro.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tony Ceba</a> em suas palestras fornece dados interessantes sobre a taxa de redu√ß√£o no custo dos lidares.  Se os lidares custarem US $ 70 mil para as primeiras m√°quinas aut√¥nomas do Google (por exemplo, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HDL-64E</a> especializado usado nas primeiras m√°quinas custar√° 75 mil): <br><img src="https://habrastorage.org/webt/w7/n4/4x/w7n44xwcg5gmcyi8v_dxc-yefd4.png"><br>  <i>Fonte: Este e o pr√≥ximo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">do estacionamento aos parques - Bellevue e a interrup√ß√£o do transporte</a></i> <br><br>  Ent√£o, na produ√ß√£o em massa, novos modelos das pr√≥ximas gera√ß√µes amea√ßam reduzir significativamente o pre√ßo abaixo de US $ 1000: <br><img src="https://habrastorage.org/getpro/habr/post_images/178/fb1/712/178fb1712f85c4534ff25d11e54ad098.png"><br><br>  Pode-se argumentar sobre o exemplo de Tony (a promessa de uma startup n√£o √© o custo final), mas h√° um boom de pesquisas nessa √°rea, o r√°pido aumento na produ√ß√£o, o surgimento de produtos completamente novos e uma queda geral nos pre√ßos s√£o indiscut√≠veis.  Um pouco mais tarde, em 2017, a previs√£o para uma queda nos pre√ßos era a seguinte (e chegar√° o momento da verdade quando eles ser√£o massivamente colocados em carros): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d75/c6c/5b0/d75c6c5b04e509f698a5d967776ff68c.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LiDAR conclui a detec√ß√£o do triunvirato</a></i> <br><br>  Em particular, h√° relativamente pouco tempo, v√°rios fabricantes lan√ßaram imediatamente o chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Solid State Lidar</a> , que basicamente n√£o possui partes m√≥veis que mostrem uma confiabilidade radicalmente mais alta, especialmente ao agitar, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reduzir custos</a> , etc.  Eu recomendo assistir este v√≠deo, onde o dispositivo deles √© explicado em 84 segundos muito claramente: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/yQi7J0ehKAA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sensor Lidar de estado s√≥lido</a></i> <br><br>  O que √© importante para n√≥s √© que o Solid State Lidar fornece uma imagem retangular, ou seja,  de fato, come√ßa a funcionar como uma c√¢mera de profundidade "normal": <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1f6/90e/e65/1f690ee65f60f431037d6c9191896005.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Innoviz prev√™ carros aut√¥nomos produzidos em massa com LiDAR de estado s√≥lido</a></i> <br><br>  O exemplo acima fornece um v√≠deo de aproximadamente 1024x256, 25 FPS, 12 bits por componente.  Esses lidares ser√£o montados sob a grade do cap√¥ (√† medida que o dispositivo aquece bem): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18b/8dc/a13/18b8dca13a096a2337ad38b5728b26ea.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Estado s√≥lido LiDAR Magna Electronics</a></i> <br><br>  Como de costume, os chineses est√£o acesos, que agora est√£o em primeiro lugar no mundo na produ√ß√£o de ve√≠culos el√©tricos e que claramente buscam o primeiro lugar no mundo em carros aut√¥nomos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c59/b26/b00/c59b26b009b05ce5a872f3203c720a3d.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Alibaba, RoboSense lan√ßa ve√≠culo n√£o tripulado usando LIDAR de estado s√≥lido</a></i> <br><br>  Em particular, seus experimentos com um "pixel" n√£o quadrado de profundidade s√£o interessantes; se voc√™ faz um processamento conjunto com uma c√¢mera RGB, pode aumentar a resolu√ß√£o e esse √© um compromisso bastante interessante (a "quadratura" dos pixels √© importante, de fato, apenas para uma pessoa): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7e9/13f/af2/7e913faf27197e1b893b56f13873e1d6.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MEMS Lidar para ve√≠culos sem motorista d√° outro grande passo</a></i> <br><br>  Os lidares s√£o montados em esquemas diferentes, dependendo do custo do kit e da pot√™ncia do sistema de bordo, que precisar√° processar todos esses dados.  Consequentemente, as caracter√≠sticas gerais do piloto autom√°tico tamb√©m mudam.  Como resultado, carros mais caros ter√£o mais facilidade em transportar estradas empoeiradas e mais f√°cil "esquivar" carros entrando em carros nos cruzamentos laterais, os mais baratos s√≥ ajudar√£o a reduzir o n√∫mero de (numerosos) engarrafamentos est√∫pidos: <br><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/00d/dd1/d4e/00ddd1d4e9f980216796306e4a62fe2e.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/025/548/1df/0255481dfb9f5dcd102a9a5979ca2fb8.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/7bf/842/4bf/7bf8424bf82edc861dc15434a03bfcbe.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Descri√ß√£o RoboSense RS-LiDAR-M1</a></i> <br><br>  Observe que, al√©m dos pre√ßos baixos no estado s√≥lido, prometem mais algumas √°reas nas quais os lidares est√£o se desenvolvendo.  Prever algo aqui √© uma tarefa ingrata, pois muito depender√° n√£o das poss√≠veis caracter√≠sticas de engenharia da tecnologia, mas, por exemplo, das patentes.  Como v√°rias empresas j√° est√£o envolvidas no estado s√≥lido, o t√≥pico parece mais promissor.  Mas n√£o dizer nada sobre o resto seria injusto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f9/3aa/265/3f93aa2653a9dde4393c007b925d07a2.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Este gargalo de LiDAR 2017 est√° causando uma corrida do ouro nos dias modernos</a></i> <br><br>  Se falarmos de lidares como c√¢meras, vale a pena mencionar outro recurso importante que √© significativo ao usar lidares de estado s√≥lido.  Por sua natureza, eles funcionam como c√¢meras com um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">obturador em</a> movimento j√° esquecido, que introduz distor√ß√µes vis√≠veis ao fotografar objetos em movimento: <br><br><img width="66%" src="https://habrastorage.org/getpro/habr/post_images/b83/2e7/2a8/b832e72a8f8c67c65401da694df03c8e.gif"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Qual √© a diferen√ßa entre uma persiana global (global) e uma persiana</a> ?</i> <br><br>  Considerando que tudo muda rapidamente na estrada, especialmente na auto-estrada a uma velocidade de 150 km / h, esse recurso de lidares distorce muito os objetos, incluindo aqueles que voam rapidamente em nossa dire√ß√£o ... Incluindo em profundidade ... Observe que os dois m√©todos anteriores obter profundidade n√£o √© um problema. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9b9/15b/979/9b915b9799869f23dcf7b2b3e1f5f1ca.gif"><br>  <i>Fonte: <a href="">Anima√ß√£o agrad√°vel da Wikipedia mostrando distor√ß√£o do carro</a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Esse recurso, associado a um baixo FPS, requer a adapta√ß√£o de algoritmos de processamento, mas, em qualquer caso, devido √† sua alta precis√£o, inclusive a longas dist√¢ncias, os lidares n√£o t√™m concorrentes em particular. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Curiosamente, por sua natureza, os lidares funcionam muito bem em √°reas pares e piores nas bordas, e os sensores est√©reo s√£o ruins em √°reas pares e relativamente bons nas bordas. Al√©m disso, os lidares fornecem um FPS relativamente pequeno e as c√¢meras s√£o muito maiores. Como resultado, eles se complementam, o que tamb√©m foi usado nas c√¢meras Lytro Cinema (na foto perto da c√¢mera h√° uma lente plen√≥ptica iluminada com 300 FPS e </font><font style="vertical-align: inherit;">o </font><font style="vertical-align: inherit;">quadrado preto de </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Malevich</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Lidar </font><font style="vertical-align: inherit;">abaixo </font><font style="vertical-align: inherit;">): </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c1/eb9/ede/5c1eb9edeca7d67133487e93290435cd.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fonte: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lytro pronta para mudar para sempre o cinema : estr√©ia prot√≥tipo de cinema e curta-metragem na NAB</font></font></a></i> <br><br>        ,     (   )      ,   . <br><br>  -   ‚Äî    ,        1.5   (     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">10   6 </a>      ,     ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e07/fd6/3ae/e07fd63aee838e9a5c8958b0527ac4e9.png"><br> <i>: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">        Techcrunch</a></i> <br><br>         ‚Äî 1.5-2 ,        .      . <br><br>  : <br><br><ul><li>  : <br><ul><li>   ,          , <br></li><li>      ,     , <br></li><li>    , <br></li></ul></li><li>  : <br><ul><li>  , <br></li><li>    , <br></li><li> o obturador em funcionamento e a necessidade de compens√°-lo durante o processamento, <br></li><li>  lidares pr√≥ximos interferem entre si, o que n√£o √© t√£o f√°cil de compensar. <br></li></ul></li><li>  No entanto, estamos observando como, literalmente, em 2 anos, surgiu essencialmente um novo tipo de c√¢meras de profundidade com excelentes perspectivas e um enorme mercado potencial.  Nos pr√≥ximos anos, podemos esperar uma redu√ß√£o s√©ria nos pre√ßos, incluindo o surgimento de pequenos lidares universais para rob√¥s industriais. <br></li></ul><br><h1>  Processamento de v√≠deo com profundidade </h1><br>  Em poucas palavras, considere por que a profundidade n√£o √© t√£o f√°cil de manusear. <br><br>  Abaixo est√° um exemplo de dados brutos em profundidade de uma linha muito boa de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">c√¢meras Intel RealSense</a> .  Nos dedos deste v√≠deo, voc√™ pode avaliar facilmente "a olho nu" a opera√ß√£o da c√¢mera e os algoritmos de processamento: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b2/319/b14/6b2319b143f48bdf0c57ffbe2acbc891.png"><br>  <i>Fonte: doravante - os materiais do autor</i> <br><br>  Problemas t√≠picos de c√¢meras de profundidade s√£o claramente vis√≠veis: <br><br><ul><li>  Os dados s√£o inst√°veis ‚Äã‚Äãem valor, os pixels ‚Äúru√≠dos‚Äù em profundidade. <br></li><li>  Ao longo dos limites de uma largura bastante grande, os dados tamb√©m s√£o muito barulhentos (por essa mesma raz√£o, os valores de profundidade ao longo das bordas geralmente mascaram para n√£o interferir no trabalho). <br></li><li>  Ao redor da cabe√ßa, voc√™ pode ver muitos pixels ‚Äúandando‚Äù (aparentemente, a proximidade da parede na parte traseira + do cabelo come√ßa a influenciar). <br></li></ul><br>  Mas isso n√£o √© tudo.  Se olharmos para os dados mais de perto, fica claro que em alguns lugares os dados mais profundos ‚Äúbrilha‚Äù nos mais pr√≥ximos: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a30/c5a/911/a30c5a911123f7a8f6ff8ebd8893163a.png"><br><br>  Isso ocorre porque, para a conveni√™ncia do processamento, a imagem √© reduzida √† imagem da c√¢mera RGB e, como os limites n√£o s√£o determinados com precis√£o, torna-se necess√°rio processar especialmente essas "sobreposi√ß√µes"; caso contr√°rio, surgem problemas, como "buracos" em profundidade no bra√ßo: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/22f/1a3/5df/22f1a35dfdb61edcabe8a1675f5c855f.png"><br><br>  Ao processar, h√° muitos problemas, por exemplo: <br><br><ul><li>  "Vazamento" de profundidade de um objeto para outro. <br></li><li>  Instabilidade de profundidade ao longo do tempo. <br></li><li>  Alias ‚Äã‚Äã(a forma√ß√£o de uma "escada"), quando a supress√£o do ru√≠do em profundidade leva √† discretiza√ß√£o dos valores de profundidade: <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/e3d/7a4/c10/e3d7a4c10e13824f1d79815661e17773.png"><br><br>  No entanto, √© claro que a imagem melhorou bastante.  Observe que algoritmos mais lentos ainda podem melhorar significativamente a qualidade. <br><br>  Em geral, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">processamento de v√≠deo em profundidade</a> √© um t√≥pico enorme e separado, que at√© agora n√£o est√° envolvido em tantas pessoas, mas que est√° rapidamente ganhando popularidade.  O mercado anterior, que ela mudou completamente - √© a convers√£o de filmes de 2D para 3D.  O resultado da constru√ß√£o manual do est√©reo a partir de v√≠deo 2D melhorou t√£o rapidamente, mostrou um resultado muito mais previs√≠vel, causou menos dor de cabe√ßa e menor custo que no cinema 3D, ap√≥s quase 100 anos de grava√ß√£o (!), Eles rapidamente pararam de fotografar quase completamente e s√≥ come√ßaram a converter .  Havia at√© uma especialidade separada - o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artista de profundidade</a> , e os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estere√≥grafos</a> da velha escola estavam em choque ("ka-ak-a-ak?").  E o papel principal dessa revolu√ß√£o foi desempenhado pelo r√°pido aprimoramento dos algoritmos de processamento de v√≠deo.  Talvez algum dia encontrarei tempo para escrever sobre isso uma s√©rie separada de artigos, porque meu material √© em grandes quantidades. <br><br>  Aproximadamente o mesmo pode ser esperado em um futuro pr√≥ximo para c√¢meras de profundidade de rob√¥s, smartphones e carros aut√¥nomos. <br><br>  <b>Acorde!</b>  <b>A revolu√ß√£o est√° chegando!</b> <br><br><h1>  Em vez de uma conclus√£o </h1><br>  H√° alguns anos, seu humilde servidor trouxe uma compara√ß√£o de diferentes abordagens para obter v√≠deos com profundidade em um √∫nico prato.  Em geral, durante esse per√≠odo, a situa√ß√£o n√£o mudou.  A separa√ß√£o aqui √© bastante arbitr√°ria, pois os fabricantes est√£o bem cientes das desvantagens das tecnologias e tentam compens√°-las (√†s vezes com muito sucesso).  No entanto, em geral, ele pode ser usado para comparar diferentes abordagens: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/34d/491/11f/34d49111ff8005f743a89d9078864f1b.png"><br>  <i>Fonte: materiais do autor</i> <br><br>  Vamos passar por cima da mesa: <br><br><ul><li>  <b>Por resolu√ß√£o, a</b> profundidade do est√©reo est√° na lideran√ßa, mas tudo depende muito da cena (se for monof√¥nico, a coisa √© um cano). <br></li><li>  <b>Em termos de precis√£o</b> , os lidares est√£o al√©m da concorr√™ncia, a situa√ß√£o com os plen√≥pticos √© a pior, a prop√≥sito. <br></li><li>  <b>Pela complexidade do processamento</b> - apenas o ToF e os lidares obt√™m a ‚Äúprofundidade‚Äù diretamente, a obten√ß√£o de profundidade do est√©reo e dos plen√≥pticos requer muitos c√°lculos n√£o triviais. <br></li><li>  <b>De acordo com o FPS, as</b> c√¢meras ToF s√£o estruturalmente boas e, em um futuro pr√≥ximo, quando o ferro for puxado, elas ser√£o capturadas com c√¢meras est√©reo (capazes de fornecer at√© 300 fps).  At√© agora, Lidaram apenas sonha. <br></li><li>  <b>De acordo com os resultados em condi√ß√µes de pouca luz,</b> espera-se que o aparelho de som e os plen√≥pticos percam. <br></li><li>  <b>Ao trabalhar ao ar livre</b> - o ToF e as c√¢meras de luz estruturada n√£o funcionam bem. <br></li></ul><br>  Ao mesmo tempo, √© importante entender bem a situa√ß√£o em mercados espec√≠ficos.  Por exemplo, a abordagem plen√≥ptica parece claramente atrasada.  No entanto, se for o melhor para o AR (e isso ficar√° claro nos pr√≥ximos 3-4 anos), ele ocupar√° seu devido lugar em <i>todos os</i> telefones e tablets.  Observa-se tamb√©m que os lidares de estado s√≥lido t√™m a melhor apar√™ncia (os mais "verdes"), mas essa √© a tecnologia mais nova e esses s√£o os seus pr√≥prios riscos, principalmente os de patente (no campo, existem muitas patentes novas que n√£o expirar√£o em breve): <br><img src="https://habrastorage.org/getpro/habr/post_images/94e/905/f90/94e905f90cdd1e525f148f983c557b00.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LiDAR: Uma Vis√£o Geral do Cen√°rio das Patentes</a></i> <br><br>  No entanto, n√£o esquecemos - o mercado de sensores de profundidade para smartphones est√° planejado em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">US $ 6 bilh√µes no</a> pr√≥ximo ano <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">,</a> e n√£o pode ser inferior a 4, j√° que no ano passado foi de mais de 3 bilh√µes.  √â uma quantia enorme de dinheiro que n√£o somente ir√° para o retorno do investimento (para os investidores mais bem-sucedidos), mas tamb√©m para desenvolver novas gera√ß√µes de sensores.  Ainda n√£o h√° um crescimento semelhante nos lidares, mas, de acordo com todas as indica√ß√µes, ele ir√° literalmente nos pr√≥ximos 3 anos.  E ent√£o este √© um processo exponencial comum de avalanche, que j√° aconteceu mais de uma vez. <br><br>  O futuro pr√≥ximo das c√¢meras de profundidade parece extremamente interessante! <br><br>  <b><s>Cartago deve estar quebrado ... O</s> v√≠deo inteiro ser√° tridimensional at√© o final do s√©culo!</b> <br><br>  Fique atento! <br><br>  Quem n√£o leu - a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeira parte do texto</a> ! <br><br><div class="spoiler">  <b class="spoiler_title">Agradecimentos</b> <div class="spoiler_text">  Gostaria de agradecer cordialmente: <br><ul><li>  Laborat√≥rio de Computa√ß√£o Gr√°fica VMK Moscow State University  MV Lomonosov por sua contribui√ß√£o ao desenvolvimento de computa√ß√£o gr√°fica na R√∫ssia e n√£o apenas <br></li><li>  Google, Apple e Intel para √≥timas solu√ß√µes compactas e todos os fabricantes de lidar para um progresso r√°pido, <br></li><li>  pessoalmente Konstantin Kozhemyakov, que fez muito para tornar este artigo melhor e mais visual, <br></li><li>  e, finalmente, muito obrigado a Roman Kazantsev, Eugene Lyapustin e Yegor Sklyarov por um grande n√∫mero de coment√°rios e corre√ß√µes sensatas que tornaram esse texto muito melhor! <br></li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt458458/">https://habr.com/ru/post/pt458458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt458442/index.html">Por que o LLVM pode chamar uma fun√ß√£o nunca chamada?</a></li>
<li><a href="../pt458444/index.html">Internet para o residente de ver√£o. Parte 4. Um cart√£o SIM √© suficiente</a></li>
<li><a href="../pt458446/index.html">Centros de dados em escala de hiperescala: quem os constr√≥i e quanto custam</a></li>
<li><a href="../pt458452/index.html">Como fazer uma cozinha de escrit√≥rio atrav√©s de uma abordagem de supermercado</a></li>
<li><a href="../pt458454/index.html">Alexey Savvateev: Modelos de Internet e redes sociais</a></li>
<li><a href="../pt458464/index.html">Link de 3 km de gigabit em modems a laser</a></li>
<li><a href="../pt458468/index.html">Como executar uma reuni√£o impressionante do Kanban StandUp?</a></li>
<li><a href="../pt458470/index.html">Texturiza√ß√£o ou o que voc√™ precisa saber para se tornar um Artista de Superf√≠cie. Parte 2. M√°scaras e texturas</a></li>
<li><a href="../pt458472/index.html">Compila√ß√£o de uma classifica√ß√£o de territ√≥rios pelo m√©todo de potenciais t√©rmicos usando dados abertos</a></li>
<li><a href="../pt458474/index.html">Melhores relat√≥rios com o HighLoad ++ 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
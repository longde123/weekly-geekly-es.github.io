<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👕 👨🏾‍🔧 👩🏼‍⚕️ Künstliche Intelligenz versus Lüge und Betrug 🍳 🧒🏽 🧛🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bei allen Aufgaben des Lehrens künstlicher Intelligenz gibt es ein unangenehmes Phänomen - Fehler im Markup der Trainingssequenz. Diese Fehler sind un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Künstliche Intelligenz versus Lüge und Betrug</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440120/">  Bei allen Aufgaben des Lehrens künstlicher Intelligenz gibt es ein unangenehmes Phänomen - Fehler im Markup der Trainingssequenz.  Diese Fehler sind unvermeidlich, da das gesamte Markup manuell erfolgt. Wenn es eine Möglichkeit gibt, echte Daten programmgesteuert zu markieren, warum brauchen wir dann jemanden, der ihnen das Markieren beibringt und Zeit und Geld für die Erstellung eines absolut unnötigen Designs aufwendet? <br><br>  Das Auffinden und Entfernen gefälschter Masken in einer großen Trainingssequenz ist ziemlich kompliziert.  Sie können sie alle manuell anzeigen, dies erspart Ihnen jedoch keine wiederholten Fehler.  Wenn Sie sich jedoch die in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">früheren Beiträgen</a> vorgeschlagenen Tools zum Studium neuronaler Netze genau ansehen, stellt sich heraus, dass es eine einfache und effektive Möglichkeit gibt, alle Artefakte aus der Trainingssequenz zu erkennen und zu extrahieren. <br><br>  Und in diesem Beitrag gibt es ein konkretes Beispiel, es ist offensichtlich, dass ein einfaches Beispiel auf Ellipsen und Polygonen für ein gewöhnliches U-Netz wieder ein solches Lego im Sandkasten ist, aber ungewöhnlich konkret, nützlich und effektiv.  Wir werden zeigen, wie eine einfache Methode fast alle Artefakte identifiziert und findet, alle Lügen der Trainingssequenz. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9r/r1/h7/9rr1h7wzzm_tnixujjpx1ow3rge.png" width="300"></div><br>  Also fangen wir an! <br><a name="habracut"></a><br>  Nach wie vor werden wir die Reihenfolge der Bild / Masken-Paare untersuchen.  In dem zufällig ausgewählten Bild in verschiedenen Vierteln platzieren wir eine Ellipse einer zufälligen Größe und ein Viereck einer beliebigen Größe, und beide Farben in derselben Farbe, ebenfalls zufällig ausgewählt aus zwei von ihnen.  In der zweiten verbleibenden Farbe färben wir den Hintergrund.  Die Abmessungen sowohl der Ellipse als auch des Vierecks sind natürlich begrenzt. <br><br>  In diesem Fall werden wir jedoch Änderungen in das Paargenerierungsprogramm einführen und zusammen mit einer vollständig korrekten Maske eine falsche, durch eine Lüge vergiftete Maske vorbereiten. In etwa einem Prozent der Fälle ersetzen Sie das Viereck in der Maske durch eine Ellipse, d. H.  Das wahre Objekt für die Segmentierung wird durch falsche Masken als Ellipse und nicht als Viereck bezeichnet. <br><br>  <b>Zufällige Beispiele 10</b> <br><br><img src="https://habrastorage.org/webt/ff/7n/fo/ff7nfoxyodiogbucb6oqivjsm5e.png"><br><br>  <b>Beispiele für zufällige 10, aber von fehlerhaften Markups.</b>  <b>Die obere Maske ist wahr, die untere ist falsch und die Zahlen in der Trainingssequenz sind in den Bildern gezeigt.</b> <br><br><img src="https://habrastorage.org/webt/sa/ww/wx/sawwwxtlmqvixgrab-sv3btbfdm.png"><br><br>  Für die Segmentierung verwenden wir dieselben Metrik- und Verlustberechnungsprogramme und dasselbe einfache U-Netz, verwenden jedoch kein Dropout. <br><br><div class="spoiler">  <b class="spoiler_title">Bibliotheken</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> matplotlib.colors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> NoNorm %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-comment"><span class="hljs-comment">#from joblib import Parallel, delayed from skimage.draw import ellipse, polygon from keras import Model from keras.optimizers import Adam from keras.layers import Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate from keras.layers import BatchNormalization,Activation,Add,Dropout from keras.losses import binary_crossentropy from keras import backend as K from keras.models import load_model import tensorflow as tf import keras as keras w_size = 128 train_num = 10000 radius_min = 10 radius_max = 30</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Metrik- und Verlustfunktionen</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Normales U-Netz</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_layer, start_neurons)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># 128 -&gt; 64 conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(input_layer) conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(conv1) pool1 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv1) # pool1 = Dropout(0.25)(pool1) # 64 -&gt; 32 conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(conv2) pool2 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv2) # pool2 = Dropout(0.5)(pool2) # 32 -&gt; 16 conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(conv3) pool3 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv3) # pool3 = Dropout(0.5)(pool3) # 16 -&gt; 8 conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(conv4) pool4 = Conv2D(start_neurons * 1, (2, 2), strides=(2, 2), activation="relu", padding="same")(conv4) # pool4 = Dropout(0.5)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(pool4) convm = Conv2D(start_neurons * 16, (3, 3) , activation="relu", padding="same")(convm) # 8 -&gt; 16 deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) # uconv4 = Dropout(0.5)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3) , activation="relu", padding="same")(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3) , activation="relu", padding="same")(uconv4) # 16 -&gt; 32 deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) # uconv3 = Dropout(0.5)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3) , activation="relu", padding="same")(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3) , activation="relu", padding="same")(uconv3) # 32 -&gt; 64 deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) # uconv2 = Dropout(0.5)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3) , activation="relu", padding="same")(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3) , activation="relu", padding="same")(uconv2) # 64 -&gt; 128 deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) # uconv1 = Dropout(0.5)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3) , activation="relu", padding="same")(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3) , activation="relu", padding="same")(uconv1) # uncov1 = Dropout(0.5)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer input_layer = Input((w_size, w_size, 1)) output_layer = build_model(input_layer, 27) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=1e-4), metrics=[my_iou_metric]) model.summary()</span></span></code> </pre> <br></div></div><br>  Das Programm zum Generieren von Bildern und Masken - wahr und falsch.  Die erste Ebene des Bildes wird in das Array eingefügt, die zweite ist die wahre Maske und die dritte Ebene ist die falsche Maske. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair_f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(idx)</span></span></span><span class="hljs-function">:</span></span> img_l = np.ones((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>)*<span class="hljs-number"><span class="hljs-number">0.45</span></span> img_h = np.ones((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>)*<span class="hljs-number"><span class="hljs-number">0.55</span></span> img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) i0_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> i0_qua == i1_qua: i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) _qua = np.int(w_size/<span class="hljs-number"><span class="hljs-number">4</span></span>) qua = np.array([[_qua,_qua],[_qua,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua]]) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] c = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p0 = np.rint(np.random.sample()*(radius_max-radius_min) + radius_min) p1 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] - (radius_max-radius_min) p2 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] - (radius_max-radius_min) p3 = np.rint(np.random.sample()*radius_min) p4 = np.rint(np.random.sample()*radius_min) p5 = np.rint(np.random.sample()*radius_min) p6 = np.rint(np.random.sample()*radius_min) p7 = np.rint(np.random.sample()*radius_min) p8 = np.rint(np.random.sample()*radius_min) poly = np.array(( (p1, p2), (p1+p3, p2+p4+p0), (p1+p5+p0, p2+p6+p0), (p1+p7+p0, p2+p8), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr_p, cc_p,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> img[:,:,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> p_f = np.random.sample()*<span class="hljs-number"><span class="hljs-number">1000.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p_f &gt; <span class="hljs-number"><span class="hljs-number">10</span></span>: img[rr_p, cc_p,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[rr, cc,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> i_false[idx] = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Spickzettel-Berechnungsprogramm</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_sh</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(f_imgs, f_msks, val_len)</span></span></span><span class="hljs-function">:</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t = tqdm() t_batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> raw_len = val_len id_train = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 v_false = np.zeros((train_num), dtype='float') while True: if id_train == 1: fit = model.fit(f_imgs[m2_select&gt;0], f_msks[m2_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) v_false[raw_len+kk] = val_iou if val_iou &lt; precision*0.95: new_img_test = 1 m2_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 t.set_description("Accuracy {0:6.4f} loss {1:6.4f} selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if raw_len &gt;= train_num: break t.close() return v_false</span></span></code> </pre><br></div></div><br>  Das Hauptprogramm der Berechnungen.  Wir haben kleine Änderungen am gleichen Programm gegenüber dem vorherigen Beitrag vorgenommen und einige Variablen müssen erklärt und kommentiert werden. <br><br><pre> <code class="python hljs">i_false = np.zeros((train_num), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>)</code> </pre> <br>  Es gibt eine falsche Maske.  Wenn 1, stimmt die Maske von F_msks nicht mit der Maske von f_msks überein.  Dies ist ein Indikator dafür, wonach wir tatsächlich suchen - falsche Masken. <br><br><pre> <code class="python hljs">m2_select = np.zeros((train_num), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>)</code> </pre> <br>  Zeigt an, dass dieses Bild im Spickzettel ausgewählt ist. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> val_len = batch_size + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-comment"><span class="hljs-comment"># i_false - false mask marked as 1 i_false = np.zeros((train_num), dtype='int') # t_imgs, t_msks -test images and masks _txy = [next_pair_f(idx) for idx in range(train_num)] t_imgs = np.array(_txy)[:,:,:,:1].reshape(-1,w_size ,w_size ,1) t_msks = np.array(_txy)[:,:,:,1].reshape(-1,w_size ,w_size ,1) # m2_select - initial 51 pair m2_select = np.zeros((train_num), dtype='int') for k in range(val_len): m2_select[k] = 1 # i_false - false mask marked as 1 i_false = np.zeros((train_num), dtype='int') _txy = [next_pair_f(idx) for idx in range(train_num)] f_imgs = np.array(_txy)[:,:,:,:1].reshape(-1,w_size ,w_size ,1) f_msks = np.array(_txy)[:,:,:,1].reshape(-1,w_size ,w_size ,1) # F_msks - mask array with ~1% false mask F_msks = np.array(_txy)[:,:,:,2].reshape(-1,w_size ,w_size ,1) fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk].squeeze(), cmap="gray", norm=NoNorm()) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze(), cmap="gray", norm=NoNorm()) plt.show(block=True) false_num = np.arange(train_num)[i_false&gt;0] fig, axes = plt.subplots(3, 10, figsize=(20, 7)) for k in range(10): kk = np.random.randint(false_num.shape[0]) axes[0,k].set_axis_off() axes[0,k].set_title(false_num[kk]) axes[0,k].imshow(f_imgs[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) axes[2,k].set_axis_off() axes[2,k].imshow(F_msks[false_num[kk]].squeeze(), cmap="gray", norm=NoNorm()) plt.show(block=True)</span></span></code> </pre><br>  Wir erstellen Sequenzen von Bild / Masken-Paaren für das Training und eine weitere Sequenz zum Testen.  Das heißt,  Wir werden eine neue, unabhängige Sequenz von 10.000 Paaren prüfen.  Wir zeigen zufällige Bilder mit echten und falschen Masken an und überprüfen sie visuell selektiv.  Die obigen Bilder werden gezeigt. <br><br>  In diesem speziellen Fall wurden 93 falsche Masken erhalten, auf denen eine Ellipse anstelle eines Vierecks als wahr positiv markiert wurde. <br><br>  Wir beginnen mit dem Training am richtigen Satz und verwenden f_msks als Maske <br><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">25</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), metrics=[my_iou_metric]) v_false = make_sh(f_imgs, f_msks, val_len) t_pred = model.predict(t_imgs,batch_size=batch_size) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (get_iou_vector(t_msks,t_pred.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>)))</code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9807 loss 0.0092 selected img 404 tested img 10000 : : 1801it [08:13, 3.65it/s] 0.9895299999999841</code> </pre> <br>  Der Spickzettel stellte sich in nur 404 Bildern heraus und erhielt eine akzeptable Genauigkeit in einer unabhängigen Testsequenz. <br><br>  Jetzt kompilieren wir das Netzwerk neu und trainieren in derselben Trainingssequenz, aber als Masken geben wir F_msks mit 1% falschen Masken an die Eingabe weiter <br><br><pre> <code class="python hljs">input_layer = Input((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>)) output_layer = build_model(input_layer, <span class="hljs-number"><span class="hljs-number">25</span></span>) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=<span class="hljs-number"><span class="hljs-number">1e-4</span></span>), metrics=[my_iou_metric]) v_false = make_sh(f_imgs, F_msks, val_len) t_pred = model.predict(t_imgs,batch_size=batch_size) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (get_iou_vector(t_msks,t_pred.reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>)))</code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9821 loss 0.0324 selected img 727 tested img 10000 : : 1679it [25:44, 1.09it/s] 0.9524099999999959</code> </pre> <br>  Wir haben einen Spickzettel mit 727 Bildern erhalten, der deutlich größer ist, und die Genauigkeit der Testvorhersagen, wie in der vorherigen Testsequenz, hat sich von 0,98953 auf 0,9525 verringert.  Wir haben die Trainingssequenz um weniger als 1% um Lügen erweitert, nur 93 von 10.000 Masken waren falsch, aber das Ergebnis verschlechterte sich um 3,7%.  Und das ist nicht nur eine Lüge, es ist eine echte List!  Und der Spickzettel stieg von nur 404 auf bereits 727 Bilder. <br><br>  Beruhigend und angenehm nur eine Sache <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (len(set(np.arange(train_num)[m2_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>]).intersection(set(np.arange(train_num)[i_false&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>])))) <span class="hljs-number"><span class="hljs-number">93</span></span></code> </pre> <br>  Lassen Sie mich diese lange Formel erklären. Wir nehmen den Schnittpunkt der im Spickzettel ausgewählten Bilder mit der Menge der falschen Bilder und sehen, dass der Algorithmus alle 93 falschen Bilder im Spickzettel ausgewählt hat. <br><br>  Die Aufgabe wird erheblich vereinfacht, es sind nicht 10.000 Bilder, die manuell durchgesehen werden müssen, es sind nur 727 und alle Lügen sind hier konzentriert. <br><br>  Aber es gibt noch einen interessanteren und nützlicheren Weg.  Bei der Zusammenstellung des Spickzettel haben wir nur die Bild / Masken-Paare aufgenommen, deren Vorhersage unter dem Schwellenwert liegt, und in unserem speziellen Fall haben wir den Wert der Vorhersagegenauigkeit im Array <b>v_false gespeichert</b> .  Schauen wir uns Paare aus der Trainingssequenz an, die einen sehr kleinen Vorhersagewert haben, beispielsweise weniger als 0,1, und sehen, wie viele dort liegen <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (len(set(np.arange(train_num)[v_false&lt;<span class="hljs-number"><span class="hljs-number">0.01</span></span>]).intersection(set(np.arange(train_num)[i_false&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>])))) <span class="hljs-number"><span class="hljs-number">89</span></span></code> </pre> <br><br>  Wie Sie sehen können, fiel der Hauptteil der falschen Masken, 89 von 93, in diese Masken <br><pre> <code class="python hljs">np.arange(train_num)[v_false&lt;<span class="hljs-number"><span class="hljs-number">0.01</span></span>].shape (<span class="hljs-number"><span class="hljs-number">382</span></span>,)</code> </pre> <br>  Wenn wir also nur 382 Masken manuell überprüfen und dies von 10.000 Teilen ist, werden wir die meisten falschen Masken ohne Mitleid identifizieren und zerstören. <br><br>  Wenn es möglich ist, Bilder und Masken während der Entscheidung, sie in den Spickzettel aufzunehmen, anzuzeigen, werden ausgehend von einem Schritt alle falschen Masken, alle Lügen durch die Mindestvorhersagestufe eines leicht trainierten Netzwerks bestimmt, und die richtigen Masken haben eine Vorhersage, die größer als diese Stufe ist . <br><br><h3>  Zusammenfassend </h3><br>  Wenn in einer imaginären Welt die Wahrheit immer viereckig ist und die ovale Lüge und eine unbekannte Entität beschlossen, die Wahrheit zu verzerren und einige Ellipsen die Wahrheit nennen, und die Vierecke falsch sind, dann wird die lokale Inquisition unter Verwendung künstlicher Intelligenz und der natürlichen Fähigkeit, Spickzettel zu erstellen, schnell und einfach finden und beseitigt Lügen und Betrug vollständig und vollständig. <br><br>  PS Die Fähigkeit, Ovale, Dreiecke und einfache Polygone zu erkennen, ist eine Voraussetzung für die Erstellung einer KI, die das Auto steuert.  Wenn Sie nicht wissen, wie Sie nach Ovalen und Dreiecken suchen sollen, finden Sie nicht alle Verkehrszeichen und Ihre KI fährt im falschen Auto ab. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440120/">https://habr.com/ru/post/de440120/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440110/index.html">Tauchen Sie ein in das Android OpenSource-Ökosystem</a></li>
<li><a href="../de440112/index.html">Wie wir die Interviews komplett verändert haben</a></li>
<li><a href="../de440114/index.html">Entscheidungsbasiertes Gameplay-Design</a></li>
<li><a href="../de440116/index.html">Dagaz: Fehler</a></li>
<li><a href="../de440118/index.html">Mythen über Premier Field Engineer bei Microsoft</a></li>
<li><a href="../de440122/index.html">Wie man eine Solar-Taschenlampe mit eigenen Händen herstellt (Teil 2)</a></li>
<li><a href="../de440124/index.html">Warum Entwickler von ABBYY Mobile neuronalen Netzen, einem Museum und Random Coffee</a></li>
<li><a href="../de440130/index.html">Vim für Anfänger</a></li>
<li><a href="../de440138/index.html">Fügen Sie automatisch virtuellen Serverplatz hinzu</a></li>
<li><a href="../de440142/index.html">Must-Have-Plugins und einige Dienstprogramme für die C \ C ++ - Entwicklung in VS Code</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
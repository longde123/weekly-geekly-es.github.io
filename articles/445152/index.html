<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ò∫Ô∏è üë®üèº‚Äçüè≠ üìó ¬øQu√© m√°s se puede hacer en la b√∫squeda? Informe Yandex üè§ ‚öóÔ∏è üï¥üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Yandex tiene un servicio de desarrollo de componentes de b√∫squeda que construye una base de b√∫squeda en MapReduce, proporciona datos para la composici...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øQu√© m√°s se puede hacer en la b√∫squeda? Informe Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/445152/">  Yandex tiene un servicio de desarrollo de componentes de b√∫squeda que construye una base de b√∫squeda en MapReduce, proporciona datos para la composici√≥n tipogr√°fica para la representaci√≥n, genera algoritmos y estructuras de datos, y resuelve tareas de ML de crecimiento de calidad.  Alexey Shlyunkin, jefe de uno de los grupos dentro de este servicio, explica en qu√© consiste el tiempo de ejecuci√≥n de b√∫squeda y c√≥mo lo gestionamos. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/8NHDcwOEBDs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><blockquote>  ¬øQuieres hurgar en ML?  Solo quieres MapReduce - ok.  ¬øQuieres tiempo de ejecuci√≥n? </blockquote><br>  - ¬øQu√© es una b√∫squeda hoy?  Yandex comenz√≥ haciendo una b√∫squeda, desarroll√°ndola.  Han pasado 20 a√±os.  Tenemos una base de b√∫squeda para cientos de miles de millones de documentos. <br><br><a name="habracut"></a>  Llamamos a un documento cualquier p√°gina en Internet, pero, de hecho, no solo eso.  A√∫n as√≠, su contenido, varias estad√≠sticas sobre a qu√© usuarios les gusta ir, cu√°ntos.  Adem√°s de los datos que calculamos. <br><br>  Tambi√©n son decenas de miles de instancias que, en respuesta a cada solicitud, procesan datos, buscan algo, enriquecen la respuesta de b√∫squeda.  Algunas instancias buscan im√°genes, algunas para documentos de texto ordinarios, otras para video, etc. Es decir, decenas de miles de m√°quinas est√°n activadas para cada solicitud.  Todos intentan encontrar algo y mejorar el resultado que se les muestra.  En consecuencia, decenas de miles de m√°quinas atienden miles de solicitudes por segundo.  Estas decenas de miles de instancias se combinan en cientos de servicios dise√±ados para resolver un problema. <br><br><img src="https://habrastorage.org/webt/vv/ge/qi/vvgeqica4ehx9uawes9ylfw098m.jpeg"><br><br>  Hay un n√∫cleo de b√∫squeda: un servicio de b√∫squeda web.  Y hay un servicio de b√∫squeda de video, etc. En consecuencia, hay una cosa que combina las respuestas de diferentes b√∫squedas e intenta elegir qu√© y en qu√© orden es mejor mostrar al usuario.  Si se trata de alg√∫n tipo de solicitud sobre m√∫sica, entonces probablemente sea mejor mostrar Yandex.Music primero y luego, por ejemplo, una p√°gina sobre este grupo de m√∫sica.  Esto se llama licuadora.  Ya hay cientos de dichos servicios, y tambi√©n hacen algo para cada solicitud e intentan ayudar a los usuarios de alguna manera.  Y, por supuesto, todo esto utiliza el aprendizaje autom√°tico de todo tipo, desde algunas estad√≠sticas simples, modelos lineales, hasta potenciadores de gradiente, redes neuronales, etc. <br><br>  Hablar√© sobre infraestructura y ML ahora mismo. <br><br>  Mi grupo se llama el nuevo grupo de desarrollo de tiempo de ejecuci√≥n, es parte del servicio de desarrollo de componentes de b√∫squeda.  Para que tengas una idea, te contar√© un poco lo que hace nuestro servicio. <br><br><img src="https://habrastorage.org/webt/so/vn/kt/sovnktsoqacdyqxp0l7g_q9sgjm.jpeg"><br><br>  De hecho, para todos.  Si env√≠a una b√∫squeda, entonces lanzamos nuestras manos a casi todo, comenzando por construir una base de b√∫squeda.  Es decir, tenemos MapReduce, recopilamos todos los datos sobre los documentos all√≠, los hierve, construimos todo tipo de estructuras de datos, de modo que cuando los consultamos, podamos calcular algo de manera eficiente.  En consecuencia, trabajamos desde la parte inferior cuando el documento nos llega, desde la primera etapa, cuando estos documentos obtienen algo y lo clasifican, y hasta la parte superior, donde el dise√±o recibe JSON condicional y lo dibuja con todas las im√°genes y cosas hermosas.  De abajo hacia arriba, estamos desarrollando algo en toda la pila. <br><br>  Pero no solo estamos escribiendo c√≥digo y, en consecuencia, estamos haciendo todo esto en infraestructura.  En realidad estamos entrenando redes neuronales, CatBoost.  Y otras cosas de ML que puedes imaginar y quemar, tambi√©n te las ense√±amos.  Adem√°s, dado que tenemos grandes cargas, grandes datos, por supuesto, hurgamos en algoritmos y estructuras de datos y nunca nos limitamos a introducirlos en alg√∫n lugar.  Por ejemplo, en varios lugares usamos √°rboles de segmentos.  Tenemos nuestra propia compresi√≥n de √≠ndices que crean boro y, de acuerdo con esto, consideramos la din√°mica de la mejor manera de construir diccionarios. <br><br>  En general, al tratar con un coloso tan grande como una b√∫squeda, est√°bamos saturados de tareas tan simples.  Por lo tanto, nosotros, por supuesto, adoramos algo complejo, nuevo, algo que nos desaf√≠a.  Y no solo fuimos y escribimos, como siempre, diez l√≠neas de c√≥digo.  Necesitamos pensar en algunos experimentos.  En general, las tareas que nos proponemos a menudo est√°n al borde de la ficci√≥n.  A veces piensas: probablemente no sea posible.  Pero entonces, tal vez, experimentaste de alguna manera, los experimentos pueden tomar todo un a√±o, pero al final algo resulta.  Luego comenzamos a presentar, rehacer algo. <br><br>  Y adem√°s de cualquier proyecto, habilidades, etc., en general, somos uno de los equipos m√°s ambiciosos y de r√°pido crecimiento en Yandex.  Por ejemplo, vine hace dos a√±os, era la novena persona en nuestro servicio.  Ahora contamos con un servicio de casi 60 personas.  Esto es, de hecho, con los pasantes, pero, en general, cuatro veces hemos crecido exactamente en dos a√±os.  Esto es para darle una idea de lo que est√° haciendo nuestro servicio. <br><br>  Ahora quiero contarles un poco sobre la parte superior de nuestras tareas y la direcci√≥n que, me parece, en el futuro cercano seremos m√°s y m√°s relevantes.  Pero para esto, primero debe describir brevemente c√≥mo funciona la capa de b√∫squeda m√°s b√°sica. <br><br><img src="https://habrastorage.org/webt/by/3e/eu/by3eeuckwlvf33ia2f_hwovampe.jpeg"><br><br>  En t√©rminos generales, todo funciona de manera muy simple.  Tenemos nuestra base de b√∫squeda, tenemos todos los documentos y dividimos todos estos documentos de manera m√°s o menos uniforme en N piezas.  Se llaman fragmentos.  Y se lanza un programa llamado "B√∫squeda b√°sica" sobre el fragmento.  Su tarea es buscar, en consecuencia, en este pedazo de Internet.  Es decir, ella sabe c√≥mo buscarlo y no sabe nada m√°s sobre el otro Internet.  Y tenemos N fragmentos como ese.  Las b√∫squedas b√°sicas se inician por encima de ellas y, en consecuencia, hay una meta b√∫squeda sobre esto.  La solicitud del usuario cae en √©l y, en consecuencia, simplemente va a todos los fragmentos, y cada fragmento realiza una b√∫squeda, luego cada uno devuelve un resultado, y realiza alg√∫n tipo de fusi√≥n y da una respuesta. <br><br>  As√≠ fue como se organiz√≥ la b√∫squeda durante casi todos los 20 a√±os y, en general, durante mucho tiempo pensaron que esto seguir√≠a siendo as√≠, y que no se pod√≠a hacer nada mejor.  Pero todo est√° cambiando, est√°n surgiendo nuevas tecnolog√≠as y el aprendizaje autom√°tico ahora no solo le permite aumentar la calidad, sino que tambi√©n le permite resolver alg√∫n tipo de problemas de infraestructura.  Recientemente, en nuestra b√∫squeda, los proyectos se han disparado mucho, justo en la uni√≥n de la infraestructura y el aprendizaje autom√°tico.  Cuando dos de estos mastodontes se fusionan, se obtienen resultados muy interesantes. <br><br><img src="https://habrastorage.org/webt/ty/0s/zo/ty0szoxygxc0jvgwxifylxmfqqi.jpeg"><br><br>  Recientemente, han aparecido redes neuronales.  Tenemos el texto de la solicitud, est√° el texto del documento.  Queremos obtener algunos vectores de n√∫meros de la solicitud, obtener algunos vectores de n√∫meros del documento para que el producto escalar prediga el valor que queremos.  Por ejemplo, queremos capacitar al producto escalar para predecir la probabilidad de que un usuario haga clic en este documento.  Una cosa bastante comprensible. <br><br><img src="https://habrastorage.org/webt/dr/cx/dl/drcxdlgw4bne__esu_lvrfumefy.jpeg"><br><br>  Est√° organizado aproximadamente de esta manera.  Si es muy, muy grosero, entonces tenemos algunas palabras en la capa inferior, y luego hay varias capas de la red.  Cada capa, de hecho, toma un vector como entrada.  Es decir, la capa inferior es un vector tan escaso, donde cada palabra es una solicitud.  Lo multiplica por una matriz, obtiene alg√∫n tipo de vector y luego, en consecuencia, aplica cierta no linealidad a cada componente, y lo hace varias veces.  Y la √∫ltima capa, esto se llama solo el vector que acabamos de tomar la solicitud, aplicamos tales capas, y aqu√≠ la √∫ltima capa es el vector de solicitud. <br><br>  En consecuencia, estas redes neuronales se han introducido activamente en la b√∫squeda en los √∫ltimos a√±os, trajeron muchos beneficios para la calidad.  Pero tienen un problema porque todas las cantidades que queremos predecir son buenas, pero lo suficientemente aproximadas, porque para entrenar una red neuronal as√≠, la capa inferior es muy grande: todas las palabras provienen de decenas de millones de palabras, por lo que debe poder escribir su entrada varios miles de millones de datos. <br><br>  Por ejemplo, podemos entrenarnos en algunos clics de usuarios, y as√≠ sucesivamente.  Pero la se√±al principal que se considera la m√°s importante en nuestra b√∫squeda es el marcado manual por parte de personas especiales.  Toman la solicitud, toman el documento, lo leen, entienden lo bueno que es y ponen una marca, es decir, cu√°nto se ajusta este documento a esta solicitud.  Durante mucho tiempo, no pudimos predecir tal magnitud por las redes neuronales, porque todav√≠a tenemos millones de estimaciones, porque contratar todo el planeta para marcarlo todo constantemente es muy costoso.  Por lo tanto, hicimos un truco. <br><br><img src="https://habrastorage.org/webt/ao/yb/3m/aoyb3mcdap3a7l4lyett7y9h9bo.jpeg"><br><br>  Red neuronal de redes neuronales.  En los √∫ltimos a√±os, hemos acumulado muchas redes neuronales que predicen buenas se√±ales, pero un poco m√°s √°speras que la evaluaci√≥n de personas especiales.  Por consiguiente, decidimos que enviar√≠amos los vectores ya preparados de estas redes a la capa inferior, y luego entrenaremos a la red neuronal para predecir nuestra relevancia de b√∫squeda en la red de datos m√°s peque√±a. <br><br>  El resultado fue un muy buen modelo.  Ella trae las solicitudes de documentos a un vector, y su producto escalar predice directamente la relevancia real que siempre hemos querido predecir. <br><br>  Adem√°s, ten√≠amos una idea de c√≥mo rehacer un poco la b√∫squeda.  El proyecto se llama una base KNN (ingl√©s k-vecinos m√°s cercanos, m√©todo k-vecinos m√°s cercanos). <br><br><img src="https://habrastorage.org/webt/ev/il/uw/eviluwyaq_ip-xgtae0jpojo6su.jpeg"><br><br>  La idea b√°sica es esta.  Tenemos un vector de consulta y un vector de documento.  Necesitamos encontrar el m√°s cercano.  Tenemos cada documento representado por un vector.  Destaquemos N grupos, aquellos que caracterizan todo el espacio del documento.  Hablando m√°s o menos.  Fuertemente m√°s peque√±o que el n√∫mero de documentos, pero por ejemplo, caracterizan los temas.  En t√©rminos simples, hay un grupo de gatos, un grupo de comestibles, un grupo de programaci√≥n, etc. <br><br>  En consecuencia, no dispersaremos los documentos aleatoriamente en fragmentos, como antes, pero colocaremos el documento en ese fragmento, es decir, el centroide que est√° m√°s cerca del documento.  En consecuencia, tendremos dichos documentos agrupados por tema en fragmento. <br><br>  Y adem√°s, solo por una solicitud, ahora no podemos ir a todos los fragmentos, sino solo ir a un peque√±o subconjunto de aquellos que est√°n m√°s cerca de esta solicitud. <br><br><img src="https://habrastorage.org/webt/xq/-x/xz/xq-xxz9zsxwngyiaovqilmdytda.jpeg"><br><br>  En consecuencia, ten√≠amos un esquema de este tipo, la metab√∫squeda est√° incluida en todos los fragmentos.  Y ahora necesita ir a un n√∫mero mucho menor, y al mismo tiempo seguiremos buscando los documentos m√°s cercanos. <br><br>  ¬øQu√© obtenemos realmente de este dise√±o?  Reduce significativamente el consumo de recursos inform√°ticos, simplemente porque vamos a menos grupos.  Esto, como ya he dicho, considero uno de los aspectos m√°s destacados de nuestro servicio, esta es la aleaci√≥n de infraestructura y aprendizaje autom√°tico que ofrece resultados que nadie pod√≠a pensar antes. <br><br><img src="https://habrastorage.org/webt/sq/r3/pd/sqr3pdlcsbgwah4raljs1y8y45k.jpeg"><br><br>  Y, al final, es algo bastante divertido, porque obtuviste los modelos aqu√≠, y luego fuiste, rehiciste toda la b√∫squeda, apagaste los petabytes de datos y tu b√∫squeda funciona, quema diez veces menos recursos.  Usted ahorr√≥ mil millones de d√≥lares para la compa√±√≠a, todos est√°n felices. <br><br><img src="https://habrastorage.org/webt/zs/wl/ei/zswlei9tbbnwnjad68aa48h8h54.jpeg"><br><br>  Habl√© sobre uno de los proyectos que aparece en nuestra b√∫squeda y que se est√° implementando y haciendo junto con todos los experimentos durante un a√±o suspendido.  Nuestras otras tareas t√≠picas son duplicar la base de b√∫squeda, porque Internet est√° en constante crecimiento y queremos ponernos al d√≠a y buscar en todas las p√°ginas de Internet.  Y, por supuesto, esta es la aceleraci√≥n de la capa base, en la que hay m√°s casos, m√°s hierro.  Por ejemplo, acelerar su b√∫squeda base en un uno por ciento significa ahorrar aproximadamente un mill√≥n de d√≥lares. <br><br>  Tambi√©n participamos en la b√∫squeda como incubadora de inicio.  Te lo explicar√©.  La b√∫squeda se ha realizado durante 20 a√±os.  Ya ha hecho muchas cosas, muchas veces nos topamos con un callej√≥n sin salida y pensamos que no se pod√≠a hacer nada m√°s.  Luego hubo una larga serie de experimentos.  Nuevamente atravesamos este callej√≥n sin salida.  Y durante este tiempo hemos acumulado mucha experiencia sobre c√≥mo hacer cosas grandes y geniales.  En consecuencia, ahora la mayor√≠a de las nuevas direcciones en Yandex se realizan en la b√∫squeda, porque las personas en la b√∫squeda ya saben c√≥mo hacer todo esto, y es l√≥gico pedirles que al menos dise√±en alg√∫n sistema nuevo.  Y como m√°ximo, ve y hazlo t√∫ mismo. <br><br>  Ahora, espero que tengas una peque√±a idea de nuestro trabajo.  Contar√© r√°pidamente la parte tem√°tica de mi historia sobre pasantes en nuestro servicio.  Los amamos mucho.  Tenemos muchos, el verano pasado solo en mi grupo hab√≠a 20 aprendices, y creo que esto es bueno.  Cuando llevas a uno o tres pasantes, se sienten un poco solos, a veces tienen miedo de preguntar a los camaradas mayores.  Y cuando hay muchos de ellos, se comunican entre s√≠ como compa√±eros en la desgracia.  Si tienen miedo de preguntarle algo a los desarrolladores, ir√°n, susurrar√°n en la esquina.  Tal ambiente ayuda a hacer todo de manera eficiente. <br><br>  Tenemos un mill√≥n de tareas, el equipo no es muy grande, por lo que nuestros pasantes est√°n completamente cargados.  No le pedimos al alumno que se siente en el registrador todo el tiempo, escriba pruebas, refactorice el c√≥digo, pero inmediatamente le damos alg√∫n tipo de tarea de producci√≥n complicada: acelerar la b√∫squeda, mejorar la compresi√≥n del √≠ndice.  Por supuesto que te ayudamos.  Sabemos que todo esto vale la pena, por lo que nos complace compartir nuestra experiencia.  Dado que nuestro campo de actividad es bastante extenso, cada uno de nosotros encontrar√° una tarea para √©l a su gusto.  ¬øQuieres hurgar en ML?  Solo quieres MapReduce - ok.  ¬øQuieres tiempo de ejecuci√≥n?  Hay de todo. <br><br>  ¬øQu√© necesitas para llegar a nosotros?  Hacemos todo principalmente en C ++ y Python.  No es necesario saber ambos, uno puede saber una cosa.  Agradecemos el conocimiento de algoritmos.  Forma un cierto estilo de pensamiento y ayuda mucho.  Pero esto tampoco es necesario: nuevamente, estamos listos para ense√±ar todo, estamos listos para invertir nuestro tiempo, porque sabemos que vale la pena.  El requisito m√°s importante que hacemos, nuestro lema, es no tener miedo a nada ni a muchas figuras.  No tenga miedo de abandonar la producci√≥n, no tenga miedo de comenzar a hacer algo complicado.  Por lo tanto, necesitamos personas que tampoco tengan miedo a nada y que tambi√©n est√©n listas para convertir monta√±as.  Muchas gracias </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/445152/">https://habr.com/ru/post/445152/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../445136/index.html">No te pongas nervioso, no te apresures, no interrumpas: la historia de una tragedia</a></li>
<li><a href="../445138/index.html">IBM Integration Bus y lo que come</a></li>
<li><a href="../445140/index.html">PHP Digest No. 152 (del 11 al 25 de marzo de 2019)</a></li>
<li><a href="../445146/index.html">La historia del elefante Slonik, el logotipo de PostgreSQL</a></li>
<li><a href="../445150/index.html">Upwork est√° registrado en la Federaci√≥n Rusa</a></li>
<li><a href="../445154/index.html">Eventos digitales en Mosc√∫ del 25 al 31 de marzo</a></li>
<li><a href="../445156/index.html">Nebulizador compacto Glenmark: algo √∫til en la vida cotidiana</a></li>
<li><a href="../445158/index.html">√ìptima orientaci√≥n de piezas y configuraci√≥n de soporte en impresora 3D</a></li>
<li><a href="../445160/index.html">Desarrollamos firmware de pedal para aprender a tocar la balalaika</a></li>
<li><a href="../445162/index.html">Proveedor de Terraforma Selectel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
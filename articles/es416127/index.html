<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•Ç üèΩ üë©‚Äçüë¶‚Äçüë¶ CUDA y GPU remota üê∑ üë©üèæ‚Äç‚öïÔ∏è üíÉüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="CUDA es bueno para todos, siempre que tenga a mano una tarjeta de video de Nvidia. Pero, ¬øqu√© hacer cuando no hay una tarjeta gr√°fica Nvidia en su com...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>CUDA y GPU remota</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416127/"><p>  CUDA es bueno para todos, siempre que tenga a mano una tarjeta de video de Nvidia.  Pero, ¬øqu√© hacer cuando no hay una tarjeta gr√°fica Nvidia en su computadora port√°til favorita?  ¬øO necesita realizar el desarrollo en una m√°quina virtual? </p><br><p>  Intentar√© considerar en este art√≠culo una soluci√≥n como el marco rCUDA (Remote CUDA), que ayudar√° cuando hay una tarjeta de video Nvidia, pero no est√° instalada en la m√°quina en la que se supone que se inician las aplicaciones CUDA.  Para aquellos que est√©n interesados, bienvenidos a cat. </p><br><div class="spoiler">  <b class="spoiler_title">TLDR</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">rCUDA</a> (CUDA remota): un marco que implementa la API de CUDA, lo que le permite utilizar una tarjeta de video remota.  Est√° en una versi√≥n beta funcional, disponible solo bajo Linux.  El objetivo principal de rCUDA es la compatibilidad total con la API de CUDA, no necesita modificar su c√≥digo de ninguna manera, solo configure variables de entorno especiales. </p></div></div><a name="habracut"></a><br><h2 id="chto-takoe-rcuda">  ¬øQu√© es rCUDA? </h2><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">rCUDA</a> (Remote CUDA) es un marco que implementa la API de CUDA, lo que le permite utilizar una tarjeta de video ubicada en la m√°quina remota para la computaci√≥n CUDA sin realizar ning√∫n cambio en su c√≥digo.  Desarrollado en la Universidad Polit√©cnica de Valencia ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">equipo rcuda</a> ). </p><br><h2 id="ogranicheniya">  Limitaciones </h2><br><p>  Actualmente solo se admiten sistemas GNU / Linux, sin embargo, los desarrolladores prometen compatibilidad con Windows en el futuro.  La versi√≥n actual de rCUDA, 18.03beta, es compatible con CUDA 5-8, es decir, CUDA 9 no es compatible.  Los desarrolladores declararon compatibilidad total con la API de CUDA, con la excepci√≥n de los gr√°ficos. </p><br><h2 id="vozmozhnye-scenarii-ispolzovaniya">  Posibles casos de uso </h2><br><ol><li>  Ejecutar aplicaciones CUDA en una m√°quina virtual cuando reenv√≠a una tarjeta de video es inconveniente o imposible, por ejemplo, cuando la tarjeta de video est√° ocupada por un host o cuando hay m√°s de una m√°quina virtual. </li><li>  Port√°til sin una tarjeta gr√°fica discreta. </li><li>  El deseo de usar m√∫ltiples tarjetas de video (agrupamiento).  Te√≥ricamente, puede usar todas las tarjetas de video disponibles en el equipo, incluso en forma conjunta. </li></ol><br><h2 id="kratkaya-instrukciya">  Instrucciones breves </h2><br><h4 id="testovaya-konfiguraciya">  Configuraci√≥n de prueba </h4><br><p>  Las pruebas se llevaron a cabo en la siguiente configuraci√≥n: </p><br><p>  <strong>Servidor:</strong> <br>  Ubuntu 16.04, GeForce GTX 660 </p><br><p>  <strong>Cliente:</strong> <br>  Una m√°quina virtual con Ubuntu 16.04 en una computadora port√°til sin una tarjeta gr√°fica discreta. </p><br><h4 id="poluchenie-rcuda">  Obteniendo rCUDA </h4><br><p>  La etapa m√°s dif√≠cil.  Desafortunadamente, en este momento, la √∫nica forma de obtener su copia de este marco es completar el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">formulario de solicitud</a> correspondiente en el sitio web oficial.  Sin embargo, los desarrolladores prometen responder dentro de 1-2 d√≠as.  En mi caso, me enviaron una distribuci√≥n el mismo d√≠a. </p><br><h4 id="ustanovka-cuda">  Instalar CUDA </h4><br><p>  Primero debe instalar el kit de herramientas CUDA en el servidor y el cliente (incluso si el cliente no tiene una tarjeta de video nvidia).  Para hacer esto, puede descargarlo desde el sitio oficial o usar el repositorio.  Lo principal es utilizar una versi√≥n no superior a 8. En este ejemplo, se utiliza el instalador .run del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sitio oficial</a> . </p><br><pre><code class="bash hljs">chmod +x cuda_8.0.61_375.26_linux.run ./cuda_8.0.61_375.26_linux.run</code> </pre> <br><p>  <strong>Importante!</strong>  En el cliente, debe negarse a instalar el controlador nvidia.  Por defecto, el Kit de herramientas de CUDA estar√° disponible en / usr / local / cuda /.  Instale muestras de CUDA, las necesitar√°. </p><br><h4 id="ustanovka-rcuda">  Instalar rCUDA </h4><br><p>  Descomprimiremos el archivo recibido de los desarrolladores en nuestro directorio de inicio en el servidor y en el cliente. </p><br><pre> <code class="bash hljs">tar -xvf rCUDA*.tgz -C ~/ mv ~/rCUDA* ~/rCUDA</code> </pre> <br><p>  Debe realizar estas acciones tanto en el servidor como en el cliente. </p><br><h4 id="zapusk-demona-rcuda-na-servere">  Inicio del demonio rCUDA en el servidor </h4><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span>:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/lib64:/home/&lt;XXX&gt;/rCUDA/lib/cudnn <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rCUDA/bin ./rCUDAd</code> </pre> <br><p>  Reemplace &lt;XXX&gt; con su nombre de usuario.  Use ./rCUDAd -iv si desea ver resultados detallados. </p><br><h4 id="nastroyka-klienta">  Configuraci√≥n del cliente </h4><br><p>  Abramos el terminal en el cliente, en el que ejecutaremos el c√≥digo CUDA en el futuro.  En el lado del cliente, necesitamos "reemplazar" las bibliotecas CUDA est√°ndar con las bibliotecas rCUDA, para lo cual agregamos las rutas apropiadas a la variable de entorno LD_LIBRARY_PATH.  Tambi√©n necesitamos especificar el n√∫mero de servidores y sus direcciones (en mi ejemplo, ser√° uno). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=/home/&lt;XXX&gt;/rCUDA/lib/:<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> RCUDA_DEVICE_COUNT=1 <span class="hljs-comment"><span class="hljs-comment">#    (),     export RCUDA_DEVICE_0=&lt;IP  &gt;:0 #    </span></span></code> </pre> <br><h4 id="sborka-i-zapusk">  Montaje y lanzamiento </h4><br><p>  Intentemos construir y ejecutar algunos ejemplos. </p><br><p>  <strong>Ejemplo 1</strong> </p><br><p>  Comencemos con un ejemplo simple de deviceQuery que simplemente muestra la configuraci√≥n de CUDA para un dispositivo compatible, es decir, en nuestro caso, el GTX660 remoto. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt;YYY&gt;/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery make EXTRA_NVCCFLAGS=--cudart=shared</code> </pre> <br><p>  <strong>Importante!</strong>  Sin EXTRA_NVCCFLAGS = - cudart = compartido, el milagro no funcionar√° <br>  Reemplace &lt;YYY&gt; con la ruta que especific√≥ para las muestras CUDA al instalar CUDA. </p><br><p>  Ejecute el ejemplo ensamblado: </p><br><pre> <code class="bash hljs">./deviceQuery</code> </pre> <br><p>  Si hiciste todo correctamente, el resultado ser√° algo como esto: </p><br><div class="spoiler">  <b class="spoiler_title">Resultado</b> <div class="spoiler_text"><pre> <code class="bash hljs">./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Detected 1 CUDA Capable device(s) Device 0: <span class="hljs-string"><span class="hljs-string">"GeForce GTX 660"</span></span> CUDA Driver Version / Runtime Version 9.0 / 8.0 CUDA Capability Major/Minor version number: 3.0 Total amount of global memory: 1994 MBytes (2090991616 bytes) ( 5) Multiprocessors, (192) CUDA Cores/MP: 960 CUDA Cores GPU Max Clock rate: 1072 MHz (1.07 GHz) Memory Clock rate: 3004 Mhz Memory Bus Width: 192-bit L2 Cache Size: 393216 bytes Maximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096) Maximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 1 copy engine(s) Run time <span class="hljs-built_in"><span class="hljs-built_in">limit</span></span> on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 660 Result = PASS</code> </pre> </div></div><br><p>  Lo m√°s importante que deber√≠amos ver: </p><br><blockquote>  Dispositivo 0 = GeForce GTX 660 <br>  Resultado = PASA </blockquote><p>  Genial  Logramos construir y ejecutar la aplicaci√≥n CUDA en una m√°quina sin una tarjeta gr√°fica discreta, utilizando para este prop√≥sito una tarjeta de video instalada en un servidor remoto. </p><br><p>  <strong>Importante!</strong>  Si el resultado de la aplicaci√≥n comienza con l√≠neas del formulario: </p><br><pre> <code class="bash hljs">mlock error: Cannot allocate memory rCUDA warning: 1007.461 mlock error: Cannot allocate memory</code> </pre> <br><p>  significa que es necesario agregar las siguientes l√≠neas al archivo "/etc/security/limits.conf" en el servidor y en el cliente: </p><br><pre> <code class="bash hljs">* hard memlock unlimited * soft memlock unlimited</code> </pre> <br><p>  Por lo tanto, permitir√° a todos los usuarios (*) memoria de bloqueo ilimitada (ilimitada) (memlock).  Ser√≠a a√∫n mejor reemplazar * con el usuario deseado, y en lugar de elegir de forma ilimitada los derechos menos gordos. </p><br><p>  <strong>Ejemplo 2</strong> </p><br><p>  Ahora intentemos algo m√°s interesante.  Probamos la implementaci√≥n del producto escalar de vectores usando memoria compartida y sincronizaci√≥n ("Tecnolog√≠a CUDA en Ejemplos" Sanders J. Kendrot E. 5.3.1). </p><br><p>  En este ejemplo, calculamos el producto escalar de dos vectores de dimensi√≥n 33 * 1024, comparando la respuesta con el resultado obtenido en la CPU. </p><br><div class="spoiler">  <b class="spoiler_title">dotProd.cu</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #define imin(a,b) (a&lt;b?a:b) const int N = 33 * 1024; const int threadsPerBlock = 256; const int blocksPerGrid = imin(32, (N+threadsPerBlock-1) / threadsPerBlock); __global__ void dot(float* a, float* b, float* c) { __shared__ float cache[threadsPerBlock]; int tid = threadIdx.x + blockIdx.x * blockDim.x; int cacheIndex = threadIdx.x; float temp = 0; while (tid &lt; N){ temp += a[tid] * b[tid]; tid += blockDim.x * gridDim.x; } // set the cache values cache[cacheIndex] = temp; // synchronize threads in this block __syncthreads(); // for reductions, threadsPerBlock must be a power of 2 // because of the following code int i = blockDim.x/2; while (i != 0){ if (cacheIndex &lt; i) cache[cacheIndex] += cache[cacheIndex + i]; __syncthreads(); i /= 2; } if (cacheIndex == 0) c[blockIdx.x] = cache[0]; } int main (void) { float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; // allocate memory on the cpu side a = (float*)malloc(N*sizeof(float)); b = (float*)malloc(N*sizeof(float)); partial_c = (float*)malloc(blocksPerGrid*sizeof(float)); // allocate the memory on the gpu cudaMalloc((void**)&amp;dev_a, N*sizeof(float)); cudaMalloc((void**)&amp;dev_b, N*sizeof(float)); cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid*sizeof(float)); // fill in the host memory with data for(int i=0; i&lt;N; i++) { a[i] = i; b[i] = i*2; } // copy the arrays 'a' and 'b' to the gpu cudaMemcpy(dev_a, a, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(float), cudaMemcpyHostToDevice); dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_partial_c); // copy the array 'c' back from the gpu to the cpu cudaMemcpy(partial_c,dev_partial_c, blocksPerGrid*sizeof(float), cudaMemcpyDeviceToHost); // finish up on the cpu side c = 0; for(int i=0; i&lt;blocksPerGrid; i++) { c += partial_c[i]; } #define sum_squares(x) (x*(x+1)*(2*x+1)/6) printf("GPU - %.6g \nCPU - %.6g\n", c, 2*sum_squares((float)(N-1))); // free memory on the gpu side cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_partial_c); // free memory on the cpu side free(a); free(b); free(partial_c); }</span></span></span></span></code> </pre></div></div><br><p>  Construye y ejecuta: </p><br><pre> <code class="bash hljs">/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin/nvcc --cudart=shared dotProd.cu -o dotProd ./dotProd</code> </pre> <br><p>  Este resultado nos dice que todo est√° bien con nosotros: </p><br><blockquote>  GPU - 2.57236e + 13 <br>  CPU - 2.57236e + 13 </blockquote><p>  <strong>Ejemplo 3</strong> </p><br><p>  Ejecute otra prueba est√°ndar CUDA-matrixMulCUBLAS (multiplicaci√≥n de matriz). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt; YYY&gt;/NVIDIA_CUDA-8.0_Samples/0_Simple/matrixMulCUBLAS make EXTRA_NVCCFLAGS=--cudart=shared ./matrixMulCUBLAS</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Resultado</b> <div class="spoiler_text"><p>  [Matrix Multiply CUBLAS] - Comenzando ... <br>  Dispositivo GPU 0: "GeForce GTX 660" con capacidad de c√°lculo 3.0 </p><br><p>  Matriz A (640,480), Matriz B (480,320), Matriz C (640,320) <br>  Resultado de la computaci√≥n usando CUBLAS ... hecho. <br>  Rendimiento = 436.24 GFlop / s, Tiempo = 0.451 mseg, Tama√±o = 196608000 Ops <br>  Resultado de la computaci√≥n utilizando la CPU del host ... hecho <br>  Comparaci√≥n de CUBLAS Matrix Multiply con resultados de CPU: PASS </p><br><p>  NOTA: Las muestras CUDA no est√°n destinadas a mediciones de rendimiento.  Los resultados pueden variar cuando GPU Boost est√° habilitado. </p></div></div><br><p>  Interesante para nosotros: </p><br><blockquote>  Rendimiento = 436.24 GFlop / s, <br>  Comparaci√≥n de CUBLAS Matrix Multiply con resultados de CPU: PASS </blockquote><br><h4 id="bezopasnost">  Seguridad </h4><br><p>  No encontr√© menci√≥n de ning√∫n m√©todo de autorizaci√≥n en la documentaci√≥n de rCUDA.  Creo que en este momento lo m√°s simple que se puede hacer es abrir el acceso al puerto deseado (8308) solo desde una direcci√≥n espec√≠fica. </p><br><p>  Usando iptables, se ver√° as√≠: </p><br><pre> <code class="bash hljs">iptables -A INPUT -m state --state NEW -p tcp -s &lt; &gt; --dport 8308 -j ACCEPT</code> </pre> <br><p>  Por lo dem√°s, dejo el problema de seguridad m√°s all√° del alcance de esta publicaci√≥n. </p><br><div class="spoiler">  <b class="spoiler_title">Fuentes y enlaces</b> <div class="spoiler_text"><p>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://www.rcuda.net/pub/rCUDA_guide.pdf</a> <br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://www.rcuda.net/pub/rCUDA_QSG.pdf</a> <br>  [3] C. Rea√±o, F. Silla, G. Shainer y S. Schultz, "Las GPU locales y remotas funcionan de manera similar con EDR 100G InfiniBand", en las actas de la Conferencia Internacional de Middleware, Vancouver, BC, Canad√°, diciembre de 2015. <br>  [4] C. Rea√±o y F. Silla, "Una comparaci√≥n de rendimiento de los marcos de virtualizaci√≥n de GPU remota CUDA", en los procedimientos de la Conferencia Internacional sobre Computaci√≥n en Cl√∫ster, Chicago, IL, EE. UU., Septiembre de 2015. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es416127/">https://habr.com/ru/post/es416127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es416115/index.html">10 peque√±os errores de dise√±o que a√∫n cometemos</a></li>
<li><a href="../es416119/index.html">Publicaci√≥n del viernes el mi√©rcoles: los mejores paquetes de NPM m√°s "esenciales"</a></li>
<li><a href="../es416121/index.html">Fujitsu Artificial Intelligence calcula la geometr√≠a de los materiales magn√©ticos.</a></li>
<li><a href="../es416123/index.html">Reconocimiento de productos en estanter√≠as que utilizan redes neuronales que utilizan las tecnolog√≠as API Keras y Tensorflow Object Detection</a></li>
<li><a href="../es416125/index.html">Instalaci√≥n, configuraci√≥n del sistema y control de c√°maras.</a></li>
<li><a href="../es416129/index.html">C√≥mo AI aprende a generar im√°genes de gatos</a></li>
<li><a href="../es416131/index.html">C√≥mo manejar la EP en la Federaci√≥n de Rusia y no violar la ley</a></li>
<li><a href="../es416135/index.html">Aplicaci√≥n GUI menor a 1 kb</a></li>
<li><a href="../es416137/index.html">Zabbix como esc√°ner de seguridad</a></li>
<li><a href="../es416139/index.html">Autenticaci√≥n fuerte como parte de la estrategia GDPR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
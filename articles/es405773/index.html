<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚ÄçüöÄ üßîüèª üõçÔ∏è C√≥mo enga√±ar a una computadora: la ciencia insidiosa de enga√±ar a la inteligencia artificial üçÉ üëé üë©üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A principios del siglo XX, Wilhelm von Austin, un entrenador y matem√°tico alem√°n de caballos, anunci√≥ al mundo que hab√≠a ense√±ado a un caballo a conta...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo enga√±ar a una computadora: la ciencia insidiosa de enga√±ar a la inteligencia artificial</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/405773/"><img src="https://habrastorage.org/web/c38/08f/4a7/c3808f4a70d1426ca51c7b7f9abb7627.jpg"><br><br>  A principios del siglo XX, Wilhelm von Austin, un entrenador y matem√°tico alem√°n de caballos, anunci√≥ al mundo que hab√≠a ense√±ado a un caballo a contar.  Durante a√±os, von Austin viaj√≥ por Alemania con una demostraci√≥n de este fen√≥meno.  Le pidi√≥ a su caballo, apodado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Clever Hans</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trot√≥n Orlov de</a> raza), que calculara los resultados de ecuaciones simples.  Hans respondi√≥, golpeando su casco.  ¬øDos m√°s dos?  Cuatro golpes <br><br>  Pero los cient√≠ficos no cre√≠an que Hans fuera tan inteligente como von Austin afirm√≥.  El psic√≥logo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Karl Stumpf</a> realiz√≥ una investigaci√≥n exhaustiva, que se denomin√≥ el "Comit√© Hans".  Descubri√≥ que Smart Hans no resuelve ecuaciones, sino que responde a se√±ales visuales.  Hans golpe√≥ su casco hasta que obtuvo la respuesta correcta, despu√©s de lo cual su entrenador y una multitud entusiasta estallaron en gritos.  Y luego se detuvo.  Cuando no vio estas reacciones, continu√≥ tocando. <br><a name="habracut"></a><br>  La inform√°tica puede aprender mucho de Hans.  El ritmo acelerado de desarrollo en esta √°rea sugiere que la mayor parte de la IA que creamos ha entrenado lo suficiente como para proporcionar las respuestas correctas, pero realmente no comprende la informaci√≥n.  Y es f√°cil enga√±ar. <br><br>  Los algoritmos de aprendizaje autom√°tico se convirtieron r√°pidamente en pastores que todo lo ven del reba√±o humano.  El software nos conecta a Internet, monitorea el spam y el contenido malicioso en nuestro correo, y pronto conducir√° nuestros autos.  Su enga√±o cambia la base tect√≥nica de Internet y amenaza nuestra seguridad en el futuro. <br><br>  Peque√±os grupos de investigaci√≥n, de la Universidad Estatal de Pensilvania, de Google, del ej√©rcito de EE. UU., Est√°n desarrollando planes para protegerse contra posibles ataques contra la IA.  Las teor√≠as presentadas en el estudio dicen que un atacante puede cambiar lo que "ve" un robot rob√≥tico.  O active el reconocimiento de voz en el tel√©fono y forzarlo a ingresar a un sitio web malicioso utilizando sonidos que solo ser√°n ruido para una persona.  O deje que el virus se filtre a trav√©s del firewall de la red. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/0e0/75b/0eb/0e075b0eb595f3aaeafaa8233e4df1b2.jpg" alt="imagen"><br>  <i>A la izquierda est√° la imagen del edificio, a la derecha est√° la imagen modificada, que la red neuronal profunda se relaciona con las avestruces.</i>  <i>En el medio, se muestran todos los cambios aplicados a la imagen principal.</i> <br><br>  En lugar de tomar el control del control de un robot rob√≥tico, este m√©todo le muestra algo as√≠ como una alucinaci√≥n, una imagen que en realidad no existe. <br><br>  Tales ataques usan im√°genes con un truco [ejemplos adversos: no existe un t√©rmino ruso establecido, textualmente resulta algo as√≠ como "ejemplos con contraste" o "ejemplos rivales" - aprox.  transl.]: im√°genes, sonidos, textos que parecen normales para las personas pero que son percibidos por una m√°quina completamente diferente.  Los peque√±os cambios realizados por los atacantes pueden hacer que la red neuronal profunda saque conclusiones err√≥neas sobre lo que muestra. <br><br>  "Cualquier sistema que utilice el aprendizaje autom√°tico para tomar decisiones cr√≠ticas para la seguridad es potencialmente vulnerable a este tipo de ataque", dijo Alex Kanchelyan, investigador de la Universidad de Berkeley que estudia los ataques de aprendizaje autom√°tico utilizando im√°genes falsas. <br><br>  Conocer estos matices en las primeras etapas del desarrollo de IA les brinda a los investigadores una herramienta para comprender c√≥mo corregir estas deficiencias.  Algunos ya han asumido esto, y dicen que sus algoritmos se han vuelto m√°s y m√°s eficientes debido a esto. <br><br>  La mayor parte del flujo principal de investigaci√≥n de IA se basa en redes neuronales profundas, que a su vez se basan en un campo m√°s amplio de aprendizaje autom√°tico.  Las tecnolog√≠as MoD utilizan c√°lculos y estad√≠sticas diferenciales e integrales para crear el software utilizado por la mayor√≠a de nosotros, como los filtros de spam en el correo o la b√∫squeda en Internet.  En los √∫ltimos 20 a√±os, los investigadores han comenzado a aplicar estas t√©cnicas a una nueva idea, las redes neuronales: estructuras de software que imitan la funci√≥n cerebral.  La idea es descentralizar los c√°lculos a trav√©s de miles de ecuaciones peque√±as ("neuronas") que reciben datos, los procesan y los transmiten a√∫n m√°s, a la siguiente capa de miles de ecuaciones peque√±as. <br><br>  Estos algoritmos de IA se entrenan de la misma manera que en el caso de MO, que, a su vez, copia el proceso de aprendizaje de una persona.  Se muestran ejemplos de diferentes cosas y sus etiquetas asociadas.  Muestre a la computadora (o al ni√±o) la imagen de un gato, diga que el gato se ve as√≠, y el algoritmo aprender√° a reconocer a los gatos.  Pero para esto, la computadora tendr√° que ver miles y millones de im√°genes de gatos y gatos. <br><br>  Los investigadores han descubierto que estos sistemas pueden ser atacados con datos enga√±osos especialmente seleccionados, a los que llamaron "ejemplos adversos". <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/862/7d4/14c/8627d414c9dbe2c4d35b06ca93e1fe0e.jpg" alt="imagen"><br>  <i>En un art√≠culo de 2015, los investigadores de Google mostraron que las redes neuronales profundas pueden verse obligadas a atribuir esta imagen de un panda a los gibones.</i> <br><br>  "Te mostramos una foto que muestra claramente el autob√∫s escolar y te hace pensar que es un avestruz", dijo Ian Goodfellow, un investigador de Google que est√° trabajando activamente en tales ataques en redes neuronales. <br><br>  Cambiando las im√°genes proporcionadas a las redes neuronales en solo un 4%, los investigadores pudieron enga√±arlas para que cometieran errores con la clasificaci√≥n en el 97% de los casos.  Incluso si no supieran exactamente c√≥mo procesa las im√°genes la red neuronal, podr√≠an enga√±arla en el 85% de los casos.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La √∫ltima variante de</a> fraude sin datos en la arquitectura de red se llama "ataque de caja negra".  Este es el primer caso documentado de un ataque funcional de este tipo en una red neuronal profunda, y su importancia es que aproximadamente en este escenario pueden tener lugar ataques en el mundo real. <br><br>  En el estudio, investigadores de la Universidad Estatal de Pensilvania, Google y el Laboratorio de Investigaci√≥n de la Marina de los EE. UU. Atacaron una red neuronal que clasifica las im√°genes respaldadas por el proyecto MetaMind y sirve como una herramienta en l√≠nea para desarrolladores.  El equipo construy√≥ y entren√≥ la red atacada, pero su algoritmo de ataque funcion√≥ independientemente de la arquitectura.  Con dicho algoritmo, pudieron enga√±ar a la red neuronal de la caja negra con una precisi√≥n del 84,24%. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/7b1/dc3/1f4/7b1dc31f4d7eb5712d1b230f7fdabf64.jpg" alt="imagen"><br>  <i>La fila superior de fotos y personajes: reconocimiento correcto de caracteres.</i> <i><br></i>  <i>Fila inferior: la red se vio obligada a reconocer signos completamente incorrectos.</i> <br><br>  El suministro de datos inexactos a las m√°quinas no es una idea nueva, pero Doug Tygar, profesor de la Universidad de Berkeley, que ha estado estudiando el aprendizaje autom√°tico durante 10 a√±os en contraste, dice que esta tecnolog√≠a de ataque ha evolucionado desde un simple MO a redes neuronales profundas complejas.  Los hackers maliciosos han estado utilizando esta t√©cnica en filtros de spam durante a√±os. <br><br>  La investigaci√≥n de Tiger proviene de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">su trabajo</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2006</a> sobre ataques de este tipo en una red con el Ministerio de Defensa, que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ampli√≥</a> en 2011 con la ayuda de investigadores de la Universidad de California en Berkeley y Microsoft Research.  El equipo de Google, el primero en utilizar redes neuronales profundas, public√≥ su <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primer trabajo</a> en 2014, dos a√±os despu√©s de descubrir la posibilidad de tales ataques.  Quer√≠an asegurarse de que esto no fuera alg√∫n tipo de anomal√≠a, sino una posibilidad real.  En 2015, publicaron otro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajo</a> en el que describieron una forma de proteger las redes y aumentar su eficiencia, y desde entonces, Ian Goodfellow ha dado consejos sobre otros trabajos cient√≠ficos en esta √°rea, incluido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el ataque de la caja negra</a> . <br><br>  Los investigadores llaman a la idea m√°s general de informaci√≥n poco confiable "datos bizantinos", y gracias al progreso de la investigaci√≥n, han llegado al aprendizaje profundo.  El t√©rmino proviene de la conocida " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tarea de los generales bizantinos</a> " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">,</a> un experimento mental en el campo de la inform√°tica, en el que un grupo de generales debe coordinar sus acciones con la ayuda de mensajeros, sin tener la confianza de que uno de ellos es un traidor.  No pueden confiar en la informaci√≥n recibida de sus colegas. <br><br>  "Estos algoritmos est√°n dise√±ados para manejar el ruido aleatorio, pero no los datos bizantinos", dice Taigar.  Para comprender c√≥mo funcionan estos ataques, Goodfello sugiere imaginar una red neuronal en forma de diagrama de dispersi√≥n. <br><br>  Cada punto en el diagrama representa un p√≠xel de la imagen procesada por la red neuronal.  Por lo general, la red intenta dibujar una l√≠nea a trav√©s de los datos que mejor se ajustan al conjunto de todos los puntos.  En la pr√°ctica, esto es un poco m√°s complicado, porque diferentes p√≠xeles tienen diferentes valores para la red.  En realidad, este es un gr√°fico multidimensional complejo procesado por una computadora. <br><br>  Pero en nuestra analog√≠a simple de un diagrama de dispersi√≥n, la forma de la l√≠nea dibujada a trav√©s de los datos determina lo que la red cree que ve.  Para un ataque exitoso en tales sistemas, los investigadores necesitan cambiar solo una peque√±a parte de estos puntos y hacer que la red tome una decisi√≥n que en realidad no existe.  En el ejemplo de un autob√∫s que parece un avestruz, la foto del autob√∫s escolar est√° salpicada de p√≠xeles dispuestos de acuerdo con el patr√≥n asociado con las caracter√≠sticas √∫nicas de las fotos de avestruz familiares para la red.  Este es un contorno invisible para el ojo, pero cuando el algoritmo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">procesa y simplifica los datos</a> , los puntos de datos extremos para el avestruz le parecen una opci√≥n de clasificaci√≥n adecuada.  En la versi√≥n de caja negra, los investigadores probaron trabajar con diferentes datos de entrada para determinar c√≥mo el algoritmo ve ciertos objetos. <br><br>  Al dar una entrada falsa al clasificador de objetos y al estudiar las decisiones tomadas por la m√°quina, los investigadores pudieron restaurar el algoritmo para enga√±ar al sistema de reconocimiento de im√°genes.  Potencialmente, tal sistema en robomobiles en este caso puede ver la se√±al de "ceder el paso" en lugar de la se√±al de stop.  Cuando entendieron c√≥mo funcionaba la red, pudieron hacer que la m√°quina viera cualquier cosa. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/d91/d4a/f16/d91d4af16d2c1644444f58a67dd42e8e.jpg" alt="imagen"><br>  <i>Un ejemplo de c√≥mo el clasificador de im√°genes dibuja diferentes l√≠neas dependiendo de los diferentes objetos en la imagen.</i>  <i>Los ejemplos falsos pueden considerarse valores extremos en el gr√°fico.</i> <br><br>  Los investigadores dicen que dicho ataque puede ingresarse directamente en el sistema de procesamiento de im√°genes, sin pasar por la c√°mara, o estas manipulaciones pueden llevarse a cabo con una se√±al real. <br><br>  Pero la especialista en seguridad de la Universidad de Columbia, Alison Bishop, dijo que tal pron√≥stico no es realista y depende del sistema utilizado en el robot rob√≥tico.  Si los atacantes ya tienen acceso al flujo de datos desde la c√°mara, ya pueden darle cualquier entrada. <br><br>  "Si pueden llegar a la entrada de la c√°mara, esas dificultades no son necesarias", dice ella.  "Puedes mostrarle la se√±al de alto". <br><br>  Otros m√©todos de ataque, adem√°s de pasar por alto la c√°mara, por ejemplo, dibujar marcas visuales en una se√±al real, parecen obvios para ser poco probable.  Duda que las c√°maras de baja resoluci√≥n utilizadas en robomobiles en general puedan distinguir entre peque√±os cambios en el letrero. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/9ef/d47/a6e/9efd47a6ee9f74748cdb79c976da84bf.jpg" alt="imagen"><br>  <i>La imagen pr√≠stina de la izquierda est√° clasificada como un autob√∫s escolar.</i>  <i>Corregido a la derecha, como un avestruz.</i>  <i>En el medio - la imagen cambia.</i> <br><br>  Dos grupos, uno en la Universidad de Berkeley y el otro en la Universidad de Georgetown, han desarrollado con √©xito algoritmos que pueden emitir comandos de voz a asistentes digitales como Siri y Google Now, que suenan como un ruido inaudible.  Para una persona, tales comandos parecer√°n ruido aleatorio, pero al mismo tiempo pueden dar comandos a dispositivos como Alexa, no previstos por su propietario. <br><br>  Nicholas Carlini, uno de los investigadores en ataques de audio bizantinos, dice que en sus pruebas pudieron activar los programas de reconocimiento de audio de c√≥digo abierto, Siri y Google Now, con una precisi√≥n de m√°s del 90%. <br><br>  El ruido es como una especie de negociaci√≥n alien√≠gena de ciencia ficci√≥n.  Esta es una mezcla de ruido blanco y una voz humana, pero no se parece en nada a un comando de voz. <br><br>  Seg√∫n Carlini, en tal ataque, cualquiera que escuche el ruido de un tel√©fono (si bien es necesario planear ataques en iOS y Android por separado) puede verse obligado a ir a una p√°gina web que tambi√©n reproduce ruido, lo que infectar√° los tel√©fonos ubicados cerca.  O esta p√°gina puede descargar silenciosamente un programa de malware.  Tambi√©n es posible que tales ruidos se pierdan en la radio y est√©n ocultos en el ruido blanco o en paralelo con otra informaci√≥n de audio. <br><br>  Tales ataques pueden ocurrir porque la m√°quina est√° entrenada para garantizar que casi cualquier informaci√≥n contenga informaci√≥n importante, as√≠ como que una cosa es m√°s com√∫n que la otra, como explica Goodfello. <br><br>  Enga√±ar a la red, oblig√°ndola a creer que ve un objeto com√∫n, es m√°s f√°cil, porque cree que deber√≠a ver esos objetos con m√°s frecuencia.  Por lo tanto, Goodfellow y otro grupo de la Universidad de Wyoming lograron que la red clasificara im√°genes que no exist√≠an en absoluto: identific√≥ objetos en ruido blanco, cre√≥ p√≠xeles aleatorios en blanco y negro. <br><br>  En un estudio de Goodfellow, el ruido blanco aleatorio que pasaba a trav√©s de una red fue clasificado por ella como un caballo.  Casualmente, esto nos lleva de vuelta a la historia de Clever Hans, un caballo no muy dotado matem√°ticamente. <br><br>  Goodfellow dice que las redes neuronales, como Smart Hans, en realidad no aprenden ideas, sino que solo aprenden a descubrir cu√°ndo encuentran la idea correcta.  La diferencia es peque√±a pero importante.  La falta de conocimiento fundamental facilita los intentos maliciosos de recrear la apariencia de encontrar los resultados del algoritmo "correcto", que de hecho resultan ser falsos.  Para comprender qu√© es algo, una m√°quina tambi√©n debe comprender lo que no es. <br><br>  Goodfello, despu√©s de haber capacitado a la red para clasificar im√°genes tanto en im√°genes naturales como en im√°genes procesadas (falsas), descubri√≥ que no solo pod√≠a reducir la efectividad de tales ataques en un 90%, sino que tambi√©n hac√≠a que la red afrontara mejor la tarea inicial. <br><br>  "Al hacer posible explicar im√°genes falsas realmente inusuales, puede obtener una explicaci√≥n a√∫n m√°s confiable de los conceptos subyacentes", dice Goodfellow. <br><br>  Dos grupos de investigadores de audio utilizaron un enfoque similar al del equipo de Google, protegiendo sus redes neuronales de sus propios ataques mediante sobreentrenamiento.  Tambi√©n lograron √©xitos similares, reduciendo su eficiencia de ataque en m√°s del 90%. <br><br>  No es sorprendente que esta √°rea de investigaci√≥n interese al ej√©rcito estadounidense.  El Laboratorio de Investigaci√≥n del Ej√©rcito incluso patrocin√≥ dos de los trabajos m√°s recientes sobre este tema, incluido el ataque de la caja negra.  Y aunque la agencia est√° financiando la investigaci√≥n, esto no significa que la tecnolog√≠a se vaya a utilizar en la guerra.  Seg√∫n el representante del departamento, pueden pasar hasta 10 a√±os desde la investigaci√≥n hasta las tecnolog√≠as adecuadas para el uso de un soldado. <br><br>  Ananthram Swami, investigador del Laboratorio del Ej√©rcito de EE. UU., Ha participado en varios trabajos recientes relacionados con el enga√±o de la IA.  El ej√©rcito est√° interesado en la cuesti√≥n de detectar y detener datos fraudulentos en nuestro mundo, donde no todas las fuentes de informaci√≥n se pueden verificar cuidadosamente.  Swami se√±ala un conjunto de datos obtenidos de sensores p√∫blicos ubicados en universidades y que trabajan en proyectos de c√≥digo abierto. <br><br>  ‚ÄúNo siempre controlamos todos los datos.  Es bastante f√°cil para nuestro adversario enga√±arnos ", dice Swami.  "En algunos casos, las consecuencias de tal fraude pueden ser fr√≠volas, en algunos casos lo contrario". <br><br>  Tambi√©n dice que el ej√©rcito est√° interesado en robots aut√≥nomos, tanques y otros veh√≠culos, por lo que el objetivo de dicha investigaci√≥n es obvio.  Al estudiar estos problemas, el ej√©rcito podr√° ganar ventaja en el desarrollo de sistemas que no sean susceptibles a ataques de este tipo. <br><br>  Pero cualquier grupo que use una red neuronal deber√≠a tener preocupaciones sobre el potencial de ataques con falsificaci√≥n de IA.  El aprendizaje autom√°tico y la IA est√°n en su infancia, y las fallas de seguridad pueden tener graves consecuencias en este momento.  Muchas compa√±√≠as conf√≠an informaci√≥n altamente sensible a los sistemas de IA que no han pasado la prueba del tiempo.  Nuestras redes neuronales a√∫n son demasiado j√≥venes para que sepamos todo lo que necesitamos sobre ellas. <br><br>  Una supervisi√≥n similar llev√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">al bot de Twitter de Microsoft, Tay</a> , a convertirse r√°pidamente en racista con una inclinaci√≥n por el genocidio.  El flujo de datos maliciosos y la funci√≥n "repetir despu√©s de m√≠" llevaron al hecho de que Tay se desvi√≥ en gran medida de la ruta prevista.  El bot fue enga√±ado por una entrada deficiente, y esto sirve como un ejemplo conveniente de una implementaci√≥n deficiente del aprendizaje autom√°tico. <br><br>  Kanchelyan dice que no cree que las posibilidades de tales ataques se hayan agotado despu√©s de una investigaci√≥n exitosa realizada por el equipo de Google. <br><br>  "En el √°rea de seguridad inform√°tica, los atacantes siempre est√°n por delante de nosotros", dice Kanchelyan.  "Ser√° bastante peligroso afirmar que hemos resuelto todos los problemas con el enga√±o de las redes neuronales mediante su entrenamiento repetido". </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es405773/">https://habr.com/ru/post/es405773/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es405763/index.html">Kingston Duo 3C: salvavidas para tarjetas de memoria microSD</a></li>
<li><a href="../es405765/index.html">Maximice sus ahorros con Canon MAXIFY: impresoras compactas de inyecci√≥n de tinta para grupos de trabajo medianos y oficinas dom√©sticas</a></li>
<li><a href="../es405767/index.html">Bitcoin Cash: Genie lanzado de la botella</a></li>
<li><a href="../es405769/index.html">En busca de dinero perdido: los administradores de BTC-E anunciaron el retorno del control sobre la base de intercambio. Pero eso no es seguro</a></li>
<li><a href="../es405771/index.html">Cinco a√±os en Marte</a></li>
<li><a href="../es405775/index.html">Solo Kaspersky Anti-Virus bloquea la utilidad CIA</a></li>
<li><a href="../es405777/index.html">El cambio clim√°tico podr√≠a hacer que parte del sur de Asia est√© deshabitada</a></li>
<li><a href="../es405779/index.html">Las civilizaciones avanzadas pueden construir la Internet gal√°ctica usando recorridos planetarios</a></li>
<li><a href="../es405781/index.html">La vida con una estrella - Parte 2: Clima espacial</a></li>
<li><a href="../es405783/index.html">El oscuro futuro de Internet: desigualdad y falta de libertad</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚Ü©Ô∏è üì¶ üòã Container-to-pipeline: CRI-O est d√©sormais la valeur par d√©faut dans OpenShift Container Platform 4 üèÜ üå≤ üßúüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La plate-forme Red Hat OpenShift Container Platform 4 vous permet de diffuser la cr√©ation d' h√¥tes pour le d√©ploiement de conteneurs , y compris dans ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Container-to-pipeline: CRI-O est d√©sormais la valeur par d√©faut dans OpenShift Container Platform 4</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redhatrussia/blog/460495/"> La <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plate-forme Red Hat OpenShift Container Platform 4</a> vous permet de diffuser la cr√©ation d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">h√¥tes pour le d√©ploiement de conteneurs</a> , y compris dans l'infrastructure des fournisseurs de services cloud, sur les plateformes de virtualisation ou dans les syst√®mes bare-metal.  Pour cr√©er une plateforme cloud au sens plein, nous avons d√ª prendre un contr√¥le serr√© de tous les √©l√©ments utilis√©s et ainsi augmenter la fiabilit√© d'un processus d'automatisation complexe. <br><br><img src="https://habrastorage.org/webt/h5/hn/x9/h5hnx9ulnrjawbfhd2dncjqmxvm.png" width="100%"><br><br>  La solution √©vidente √©tait d'utiliser Red Hat Enterprise Linux CoreOS (une variante de Red Hat Enterprise Linux) et CRI-O en standard, et voici pourquoi ... <br><a name="habracut"></a><br>  √âtant donn√© que le sujet de la navigation est tr√®s efficace pour trouver des analogies dans l'explication du fonctionnement de Kubernetes et des conteneurs, essayons de parler des probl√®mes commerciaux que CoreOS et CRI-O r√©solvent, en utilisant l'exemple de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'invention</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Brunel pour la production de blocs de gr√©ement</a> .  En 1803, Mark Brunel fut charg√© de fabriquer 100 000 blocs de gr√©ement pour les besoins de la marine britannique en pleine croissance.  Un bloc de levage est un type de gr√©ement utilis√© pour attacher des cordes aux voiles.  Jusqu'au tout d√©but du XIXe si√®cle, ces blocs √©taient fabriqu√©s √† la main, mais Brunel a pu automatiser la production et a commenc√© √† produire des blocs standardis√©s √† l'aide de machines.  L'automatisation de ce processus signifiait que, par cons√©quent, tous les blocs √©taient presque les m√™mes, pouvaient √™tre facilement remplac√©s en cas de panne et pouvaient √™tre fabriqu√©s en grandes quantit√©s. <br><br>  Imaginez maintenant que Brunel devrait faire ce travail pour 20 mod√®les de navires diff√©rents (versions Kubernetes) et pour cinq plan√®tes diff√©rentes avec des courants marins et des vents compl√®tement diff√©rents (fournisseurs de nuages).  De plus, il √©tait n√©cessaire que tous les navires (clusters OpenShift), quelles que soient les plan√®tes parcourues, se comportent de mani√®re identique du point de vue des capitaines (op√©rateurs contr√¥lant le fonctionnement des clusters).  Poursuivant l'analogie marine, les capitaines de navire ne se soucient absolument pas des blocs de gr√©ement (CRI-O) utilis√©s sur leurs navires - l'essentiel pour eux est que ces blocs sont solides et fiables. <br><br>  OpenShift 4, en tant que plateforme cloud, fait face √† un d√©fi commercial tr√®s similaire.  De nouveaux n≈ìuds doivent √™tre cr√©√©s au moment de la cr√©ation du cluster, en cas de d√©faillance de l'un des n≈ìuds, ou lors de la mise √† l'√©chelle du cluster.  Lors de la cr√©ation et de l'initialisation d'un nouveau n≈ìud, les composants h√¥tes critiques, y compris CRI-O, doivent √™tre configur√©s en cons√©quence.  Comme pour toute autre production, les ¬´mati√®res premi√®res¬ª doivent √™tre fournies au d√©part.  Dans le cas des navires, le m√©tal et le bois servent de mati√®res premi√®res.  Cependant, si vous cr√©ez un h√¥te pour d√©ployer des conteneurs dans un cluster OpenShift 4, vous devez disposer de fichiers de configuration et de serveurs API fournis en entr√©e.  Apr√®s cela, OpenShift fournira le niveau d'automatisation n√©cessaire tout au long du cycle de vie, offrant le support produit n√©cessaire aux utilisateurs finaux et donc rentabilisant les investissements dans la plate-forme. <br><br>  OpenShift 4 a √©t√© cr√©√© de mani√®re √† offrir la possibilit√© de mettre √† jour le syst√®me de mani√®re pratique tout au long du cycle de vie de la plate-forme (pour les versions 4.X) pour tous les principaux fournisseurs de cloud computing, de plates-formes de virtualisation et m√™me de syst√®mes bare metal.  Pour cela, les n≈ìuds doivent √™tre cr√©√©s sur la base d'√©l√©ments interchangeables.  Lorsqu'un cluster n√©cessite une nouvelle version de Kubernetes, il re√ßoit √©galement la version CRI-O correspondante sur CoreOS.  √âtant donn√© que la version CRI-O est directement li√©e √† Kubernetes, tout cela simplifie consid√©rablement les permutations pour les tests, le d√©pannage ou le support.  De plus, cette approche r√©duit les co√ªts pour les utilisateurs finaux et Red Hat. <br><br>  Il s'agit d'un regard fondamentalement nouveau sur les clusters Kubernetes, qui jette les bases de la planification de nouvelles fonctionnalit√©s tr√®s utiles et attrayantes.  Le CRI-O (projet de conteneur ouvert Container Runtime Interface - Open Container Initiative, abr√©g√© CRI-OCI) √©tait le choix le plus r√©ussi pour la cr√©ation en masse de n≈ìuds, ce qui est n√©cessaire pour travailler avec OpenShift.  CRI-O remplacera le moteur Docker pr√©c√©demment utilis√©, offrant aux utilisateurs d'OpenShift un moteur de conteneur ennuyeux <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©conomique, stable, simple et ennuyeux</a> - oui, vous l'avez bien entendu - con√ßu sp√©cialement pour travailler avec Kubernetes. <br><br><h3>  Le monde des conteneurs ouverts </h3><br>  Le monde √©volue depuis longtemps vers des conteneurs ouverts.  Que ce soit chez Kubernetes ou √† des niveaux inf√©rieurs, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©veloppement de normes de conteneurs</a> conduit √† un √©cosyst√®me d'innovation √† tous les niveaux. <br><br>  Tout a commenc√© avec la cr√©ation de l'Open Containers Initiative <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">en juin 2015</a> .  √Ä ce stade pr√©coce des travaux, des sp√©cifications pour l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">image</a> du conteneur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">(image)</a> et le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">temps d'ex√©cution</a> ont √©t√© form√©es.  Cela a permis de garantir que les outils peuvent utiliser un seul standard d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">images</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">conteneurs</a> et un seul format pour les utiliser.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Des</a> sp√©cifications de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">distribution</a> ont ensuite √©t√© ajout√©es, ce qui a permis aux utilisateurs d'√©changer facilement des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">images de conteneurs</a> . <br><br>  La communaut√© Kubernetes a ensuite d√©velopp√© une norme d'interface enfichable unique appel√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Container Runtime Interface (CRI)</a> .  Gr√¢ce √† cela, les utilisateurs de Kubernetes ont pu connecter diff√©rents moteurs pour travailler avec des conteneurs en plus de Docker. <br><br>  Les ing√©nieurs de Red Hat et de Google ont constat√© une demande du march√© pour un moteur de conteneur capable d'accepter les demandes de Kubelet utilisant le protocole CRI et a introduit des conteneurs compatibles avec les sp√©cifications OCI mentionn√©es ci-dessus.  Il <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">y avait donc un OCID</a> .  Mais excusez-moi, parce que nous avons dit que ce mat√©riel serait consacr√© au CRI-O?  En fait, c'est juste avec la sortie de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">version 1.0 que le</a> projet a √©t√© renomm√© CRI-O. <br><br>  <b><i>Fig.</i></b>  <b><i>1.</i></b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7-/-n/qb/7--nqbszwtnoy38f-tnbuzdmucm.png"></div><br><br><h3>  Innovation avec CRI-O et CoreOS </h3><br>  Avec le lancement de la plate-forme OpenShift 4, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">moteur de conteneur</a> utilis√© dans la plate-forme par d√©faut a √©t√© modifi√© et Docker a √©t√© remplac√© par CRI-O, qui offrait un environnement de lancement de conteneur √©conomique, stable, simple et ennuyeux qui se d√©veloppe en parall√®le avec Kubernetes.  Cela simplifie consid√©rablement la prise en charge et la configuration du cluster.  La configuration du moteur de conteneur et de l'h√¥te, ainsi que leur gestion, devient automatis√©e dans OpenShift 4. <br><br>  Arr√™te, comment c'est? <br><br>  C'est vrai, avec l'av√®nement d'OpenShift 4, il n'est d√©sormais plus n√©cessaire de se connecter √† des h√¥tes individuels et d'installer un moteur de conteneur, de configurer le stockage, de configurer des serveurs pour la recherche ou de configurer un r√©seau.  La plate-forme OpenShift 4 a √©t√© enti√®rement repens√©e pour utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Operator Framework</a> non seulement en termes d'applications utilisateur final, mais √©galement en termes d'op√©rations de base au niveau de la plate-forme, telles que le d√©ploiement d'images, la configuration du syst√®me ou l'installation de mises √† jour. <br><br>  Kubernetes a toujours permis aux utilisateurs de contr√¥ler les applications en d√©finissant l'√©tat souhait√© et en utilisant des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">contr√¥leurs</a> pour s'assurer que l'√©tat r√©el est aussi proche que possible de l'√©tat donn√©.  Cette <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">approche utilisant un √©tat donn√© et un √©tat r√©el</a> ouvre de grandes opportunit√©s tant du point de vue du d√©veloppement que du point de vue des op√©rations.  Les d√©veloppeurs peuvent d√©terminer l'√©tat requis, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">transf√©rer √† l'</a> op√©rateur sous la forme d'un fichier YAML ou JSON, puis l'op√©rateur peut cr√©er l'instance d'application n√©cessaire dans l'environnement d'exploitation, tandis que l'√©tat op√©rationnel de cette instance correspondra enti√®rement √† celui sp√©cifi√©. <br><br>  En utilisant des op√©rateurs dans la plate-forme, OpenShift 4 apporte ce nouveau paradigme (en utilisant le concept d'√©tat d√©fini et r√©el) √† la gestion de RHEL CoreOS et CRI-O.  Les t√¢ches de configuration et de version du syst√®me d'exploitation et du moteur de conteneur sont automatis√©es √† l'aide de ce que l'on appelle l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">op√©rateur de configuration de machine (MCO)</a> .  MCO simplifie consid√©rablement le travail de l'administrateur de cluster, en automatisant essentiellement les derni√®res √©tapes de l'installation, ainsi que les op√©rations suivantes apr√®s l'installation (op√©rations du deuxi√®me jour).  Tout cela fait d'OpenShift 4 une v√©ritable plateforme cloud.  Nous y reviendrons un peu plus tard. <br><br><h3>  Lancement de conteneurs </h3><br>  Les utilisateurs ont eu la possibilit√© d'utiliser le moteur CRI-O dans la plate-forme OpenShift √† partir de la version 3.7 dans l'√©tat de Tech Preview et de la version 3.9 dans l'√©tat de General Available (actuellement pris en charge).  De plus, Red Hat utilise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">largement CRI-O pour lancer des charges</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travail de production</a> dans OpenShift Online depuis la version 3.10.  Tout cela a permis √† l'√©quipe travaillant sur CRI-O d'acqu√©rir une vaste exp√©rience dans le lancement en masse de conteneurs sur de grands clusters Kubernetes.  Pour avoir une compr√©hension de base de la fa√ßon dont Kubernetes utilise CRI-O, jetons un coup d'≈ìil √† l'illustration suivante, qui montre comment l'architecture fonctionne. <br><br>  <b><i>Fig.</i></b>  <b><i>2. Fonctionnement des conteneurs dans le cluster Kubernetes</i></b> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1a/zr/kz/1azrkzz-ey6euphpkgqpazncwci.png"></div><br><br>  CRI-O simplifie la cr√©ation de nouveaux h√¥tes de conteneur en synchronisant l'int√©gralit√© du niveau sup√©rieur lors de l'initialisation de nouveaux n≈ìuds et lors de la publication de nouvelles versions de la plate-forme OpenShift.  Un audit de plate-forme complet permet des mises √† jour / annulations transactionnelles et emp√™che √©galement les blocages dans les d√©pendances entre le noyau de queue de conteneur, le moteur de conteneur, Kubelets et Kubernetes Master.  Gr√¢ce √† la gestion centralis√©e de tous les composants de la plate-forme, avec le contr√¥le et la gestion des versions, vous pouvez toujours suivre un chemin clair de l'√©tat A √† l'√©tat B. Cela simplifie le processus de mise √† jour, am√©liore la s√©curit√©, am√©liore les rapports sur les performances et aide √† r√©duire le co√ªt de la mise √† jour et de l'installation de nouvelles versions. <br><br><h3>  D√©monstration de la puissance des √©l√©ments interchangeables </h3><br>  Comme mentionn√© pr√©c√©demment, l'utilisation de Machine Config Operator pour g√©rer l'h√¥te de conteneur et le moteur de conteneur dans OpenShift 4 fournit un nouveau niveau d'automatisation qui n'√©tait pas possible auparavant sur la plate-forme Kubernetes.  Pour illustrer les nouvelles fonctionnalit√©s, nous montrons comment vous pouvez apporter des modifications au fichier crio.conf.  Afin de ne pas vous perdre dans la terminologie, essayez de vous concentrer sur les r√©sultats. <br><br>  Tout d'abord, cr√©ons ce qu'on appelle une configuration d'ex√©cution de conteneur - la configuration d'ex√©cution du conteneur.  Consid√©rez ceci comme une ressource Kubernetes qui repr√©sente la configuration de CRI-O.  En r√©alit√©, il s'agit d'une version sp√©cialis√©e de ce qu'on appelle MachineConfig, qui est toute configuration d√©ploy√©e sur une machine RHEL CoreOS au sein d'un cluster OpenShift. <br><br>  Cette ressource personnalis√©e, appel√©e ContainerRuntimeConfig, a √©t√© invent√©e pour faciliter la configuration de CRI-O par les administrateurs de cluster.  Il s'agit d'un outil suffisamment puissant pour qu'il ne puisse √™tre appliqu√© qu'√† certains n≈ìuds en fonction des param√®tres de MachineConfigPool.  Consid√©rez ceci comme un groupe de machines qui ont le m√™me objectif. <br><br>  Faites attention aux deux derni√®res lignes que nous allons changer dans le fichier /etc/crio/crio.conf.  Ces deux lignes sont tr√®s similaires aux lignes du fichier crio.conf, ce sont: <br><br><pre><code class="plaintext hljs">vi ContainerRuntimeConfig.yaml</code> </pre> <br>  Conclusion: <br><br><pre> <code class="plaintext hljs">apiVersion: machineconfiguration.openshift.io/v1 kind: ContainerRuntimeConfig metadata: name: set-log-and-pid spec: machineConfigPoolSelector: matchLabels: debug-crio: config-log-and-pid containerRuntimeConfig: pidsLimit: 2048 logLevel: debug</code> </pre><br>  Envoyez maintenant ce fichier au cluster Kubernetes et v√©rifiez qu'il est bien cr√©√©.  Veuillez noter que l'op√©ration est effectu√©e de la m√™me mani√®re que pour toute autre ressource Kubernetes: <br><br><pre> <code class="plaintext hljs">oc create -f ContainerRuntimeConfig.yaml oc get ContainerRuntimeConfig</code> </pre><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">NAME AGE set-log-and-pid 22h</code> </pre><br>  Apr√®s avoir cr√©√© ContainerRuntimeConfig, nous devons modifier l'un des MachineConfigPools pour que Kubernetes comprenne que nous voulons appliquer cette configuration √† un groupe sp√©cifique de machines du cluster.  Dans ce cas, nous allons modifier MachineConfigPool pour les n≈ìuds ma√Ætres: <br><br><pre> <code class="plaintext hljs">oc edit MachineConfigPool/master</code> </pre><br>  Conclusion (pour plus de clart√©, le principal point est laiss√©): <br><br><pre> <code class="plaintext hljs">... metadata: creationTimestamp: 2019-04-10T23:42:28Z generation: 1 labels: debug-crio: config-log-and-pid operator.machineconfiguration.openshift.io/required-for-upgrade: "" ...</code> </pre><br>  √Ä ce stade, MCO commence √† cr√©er un nouveau fichier crio.conf pour le cluster.  Dans ce cas, un fichier de configuration enti√®rement termin√© peut √™tre affich√© √† l'aide de l'API Kubernetes.  Rappelez-vous, ContainerRuntimeConfig n'est qu'une version sp√©cialis√©e de MachineConfig, donc nous pouvons voir le r√©sultat en regardant les lignes dans MachineConfigs: <br><br><pre> <code class="plaintext hljs">oc get MachineConfigs | grep rendered</code> </pre><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">rendered-master-c923f24f01a0e38c77a05acfd631910b 4.0.22-201904011459-dirty 2.2.0 16h rendered-master-f722b027a98ac5b8e0b41d71e992f626 4.0.22-201904011459-dirty 2.2.0 4m rendered-worker-9777325797fe7e74c3f2dd11d359bc62 4.0.22-201904011459-dirty 2.2.0 16h</code> </pre><br>  Veuillez noter que le fichier de configuration r√©sultant pour les n≈ìuds ma√Ætres s'est av√©r√© √™tre une version plus r√©cente que les configurations d'origine.  Pour l'afficher, ex√©cutez la commande suivante.  En passant, nous notons que c'est probablement l'un des meilleurs scripts √† ligne unique de l'histoire de Kubernetes: <br><br><pre> <code class="plaintext hljs">python3 -c "import sys, urllib.parse; print(urllib.parse.unquote(sys.argv[1]))" $(oc get MachineConfig/rendered-master-f722b027a98ac5b8e0b41d71e992f626 -o YAML | grep -B4 crio.conf | grep source | tail -n 1 | cut -d, -f2) | grep pid</code> </pre><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">pids_limit = 2048</code> </pre><br>  Assurez-vous maintenant que la configuration a √©t√© appliqu√©e √† tous les n≈ìuds ma√Ætres.  Nous obtenons d'abord une liste de n≈ìuds dans le cluster: <br><br><pre> <code class="plaintext hljs">oc get node | grep master Output: ip-10-0-135-153.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1 ip-10-0-154-0.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1 ip-10-0-166-79.us-east-2.compute.internal Ready master 23h v1.12.4+509916ce1</code> </pre><br>  Regardez maintenant le fichier install√©.  Vous verrez que le fichier a √©t√© mis √† jour avec les nouvelles directives pid et debug que nous avons sp√©cifi√©es dans la ressource ContainerRuntimeConfig.  L'√©l√©gance m√™me: <br><br><pre> <code class="plaintext hljs">oc debug node/ip-10-0-135-153.us-east-2.compute.internal ‚Äî cat /host/etc/crio/crio.conf | egrep 'debug||pid'</code> </pre><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">... pids_limit = 2048 ... log_level = "debug" ...</code> </pre><br>  Toutes ces modifications dans le cluster ont √©t√© effectu√©es m√™me sans d√©marrer SSH.  Tout le travail a √©t√© effectu√© en contactant le n≈ìud ma√Ætre de Kuberentes.  Autrement dit, ces nouveaux param√®tres ont √©t√© configur√©s uniquement sur les n≈ìuds ma√Ætres.  Dans le m√™me temps, les n≈ìuds de travail n'ont pas chang√©, ce qui d√©montre les avantages de la m√©thodologie Kubernetes utilisant des √©tats pr√©d√©finis et actuels appliqu√©s aux h√¥tes de conteneur et aux moteurs de conteneur avec des √©l√©ments interchangeables. <br><br>  L'exemple ci-dessus montre la possibilit√© d'apporter des modifications √† un petit cluster OpenShift Container Platform 4 avec trois n≈ìuds de travail ou √† un √©norme cluster de production avec 3000 n≈ìuds.  Dans tous les cas, la quantit√© de travail sera la m√™me - et tr√®s petite - il suffit de configurer le fichier ContainerRuntimeConfig et de modifier une √©tiquette dans MachineConfigPool.  Et vous pouvez le faire avec n'importe quelle version de la plate-forme OpenShift Container Platform 4.X utilis√©e par Kubernetes tout au long de son cycle de vie. <br><br>  Souvent, les entreprises technologiques se d√©veloppent si rapidement que nous ne sommes pas en mesure d'expliquer pourquoi nous choisissons certaines technologies pour les composants de base.  Les moteurs de conteneurs ont toujours √©t√© le composant avec lequel les utilisateurs interagissent directement.  √âtant donn√© que la popularit√© des conteneurs a naturellement commenc√© avec l'av√®nement des moteurs de conteneurs, les utilisateurs s'y int√©ressent souvent.  C'est une autre raison pour laquelle Red Hat a opt√© pour CRI-O.  Les conteneurs √©voluent, avec l'accent mis sur l'orchestration aujourd'hui, et nous sommes arriv√©s √† la conclusion que CRI-O offre la meilleure exp√©rience lorsque vous travaillez avec OpenShift 4. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr460495/">https://habr.com/ru/post/fr460495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr460483/index.html">5 m√©thodes pour lancer un remue-m√©ninges efficace</a></li>
<li><a href="../fr460485/index.html">Comment un tournoi en ligne peut d√©courager "la fin de la semaine prochaine"</a></li>
<li><a href="../fr460489/index.html">TOP 11 erreurs dans le d√©veloppement du BCP</a></li>
<li><a href="../fr460491/index.html">Capteur de temp√©rature et d'humidit√© Arduino avec envoi et tra√ßage (partie 1)</a></li>
<li><a href="../fr460493/index.html">¬´Killer apps¬ª pour PC des ann√©es 80: VisiCalc et WordStar</a></li>
<li><a href="../fr460497/index.html">Utilisation intuitive des m√©thodes de Monte Carlo avec les cha√Ænes de Markov</a></li>
<li><a href="../fr460499/index.html">Trois laur√©ats du prix Dijkstra: comment Hydra 2019 et SPTDC 2019 se sont-ils d√©roul√©s?</a></li>
<li><a href="../fr460501/index.html">Exemple d'impl√©mentation d'int√©gration continue √† l'aide de BuildBot</a></li>
<li><a href="../fr460503/index.html">Configuration sans fil du Raspberry PI 3 B +</a></li>
<li><a href="../fr460505/index.html">Attirer trois croix, ou pourquoi les projets sont si difficiles √† terminer √† temps</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
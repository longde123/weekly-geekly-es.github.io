<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👉 🚴🏾 🤜 Penghitungan Lebah Ras Neural Pi Neural Network ➕ 😿 🙃</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Diterbitkan 17 Mei 2018 

 Segera setelah memasang sarang, saya berpikir: "Saya ingin tahu bagaimana cara menghitung jumlah lebah yang datang dan perg...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Penghitungan Lebah Ras Neural Pi Neural Network</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/413799/">  <font color="gray">Diterbitkan 17 Mei 2018</font> <br><br>  Segera setelah memasang sarang, saya berpikir: "Saya ingin tahu bagaimana cara menghitung jumlah lebah yang datang dan pergi?" <br><br>  Sebuah penelitian kecil menunjukkan: sejauh ini tidak ada yang muncul dengan sistem non-invasif yang baik untuk menyelesaikan masalah ini.  Tetapi mungkin akan berguna jika memiliki informasi semacam itu untuk memeriksa kesehatan sarang. <br><br>  Pertama, Anda perlu mengumpulkan sampel data.  Raspberry Pi, kamera Pi standar, dan panel surya: peralatan sederhana ini cukup untuk merekam satu frame setiap 10 detik dan menyimpan 5000+ gambar per hari (dari 6 pagi hingga 9 malam). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9c0/762/61f/9c076261ffc6e6e293b9b4ee06cbbe32.png"><br><a name="habracut"></a><br>  Di bawah ini adalah contoh gambar ... Berapa banyak lebah yang bisa Anda hitung? <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a4e/d37/f72/a4ed37f728649526128711ebc033bc8c.png"><br><br><h1>  Apa sebenarnya pertanyaannya? </h1><br>  Kedua, perlu dirumuskan masalah apa yang seharusnya dilakukan jaringan saraf.  Jika tugasnya adalah “menghitung lebah dalam gambar”, maka Anda dapat mencoba untuk mendapatkan nomor tertentu, tetapi ini sepertinya bukan pilihan yang paling mudah, dan melacak lebah secara individu di antara bingkai tidak memberikan kesenangan apa pun.  Sebagai gantinya, saya memutuskan untuk fokus pada melokalisasi setiap lebah dalam gambar. <br><br>  Pemeriksaan cepat untuk frame-by-frame detector standar tidak membuahkan hasil tertentu.  Ini tidak mengherankan, terutama mengingat kepadatan lebah di sekitar pintu masuk sarang (petunjuk: mentransfer pelatihan tidak selalu berhasil), tetapi ini normal.  Jadi, saya memiliki gambar yang sangat kecil, hanya satu kelas untuk mengenali objek dan tidak ada masalah khusus dengan kotak pembatas.  Putuskan saja apakah ada lebah atau tidak.  Solusi mana yang lebih sederhana? <br><br><h3>  v1: jaringan sepenuhnya convolutional "bee eat / not" pada sebuah fragmen </h3><br>  Percobaan cepat pertama adalah detektor "lebah dalam gambar adalah / tidak".  Artinya, berapa probabilitas bahwa setidaknya ada satu lebah pada fragmen gambar ini.  Untuk melakukan ini dalam bentuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">jaringan yang sepenuhnya konvolusional</a> pada potongan gambar yang sangat kecil berarti Anda dapat dengan mudah memproses data dalam resolusi penuh.  Pendekatan itu tampaknya berhasil, tetapi gagal untuk area pintu masuk sarang dengan kepadatan lebah yang sangat tinggi. <br><br><h3>  v2: Gambar RGB → bitmap hitam dan putih </h3><br>  Saya segera menyadari bahwa masalahnya dapat direduksi menjadi masalah transformasi gambar.  Pada input, sinyal kamera adalah RGB, dan pada output adalah gambar saluran tunggal di mana piksel "putih" menunjukkan pusat lebah. <br><br><img src="https://habrastorage.org/webt/ks/v6/k9/ksv6k9rne4ewjh_mkwqwcrztoo8.png"><br>  <i><font color="gray">Input RGB (fragmen) dan output saluran tunggal (fragmen)</font></i> <br><br><h1>  Menandai </h1><br>  Langkah ketiga adalah menandai, yaitu, penugasan penunjukan.  Tidak terlalu sulit untuk menggunakan aplikasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TkInter</a> kecil untuk memilih / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">membatalkan pilihan</a> lebah pada gambar dan menyimpan hasilnya dalam database SQLite.  Saya menghabiskan banyak waktu untuk mengkonfigurasi alat ini dengan benar: siapa pun yang secara manual melakukan sejumlah besar penandaan akan mengerti saya: / <br><br>  Nanti kita akan melihat, untungnya, bahwa dengan sejumlah besar sampel Anda bisa mendapatkan hasil yang cukup baik dengan metode semi-otomatis. <br><br><h1>  Model </h1><br>  Arsitektur jaringan cukup standar u-net. <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">jaringan convolutional sepenuhnya</a> dilatih pada fragmen dengan resolusi setengah, tetapi bekerja pada gambar dengan resolusi penuh; </li><li>  pengkodean adalah urutan empat konvolusi 3 × 3 dengan kelipatan 2 </li><li>  decoding - urutan perubahan ukuran di tetangga terdekat + lipat 3 × 3 dalam peningkatan 1 + melewatkan koneksi dari encoders; </li><li>  lapisan konvolusi akhir 1 × 1 dengan langkah 1 dengan aktivasi fungsi sigmoid (yaitu, pilihan biner "lebah adalah / tidak" untuk setiap piksel). </li></ul><br>  Setelah beberapa percobaan empiris, saya memutuskan untuk kembali ke decoding dengan setengah resolusi.  Sudah cukup. <br><br>  Saya melakukan decoding dengan mengubah ukuran ke tetangga terdekat alih-alih memindahkan lebih banyak dari kebiasaan. <br><br>  Jaringan dilatih oleh metode <a href="">Adam</a> dan terlalu kecil untuk menerapkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">normalisasi batch</a> .  Desainnya ternyata sangat sederhana, sejumlah kecil filter sudah cukup. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8c0/3a8/983/8c03a898399031e9f7ea03a9bca4f0d4.png"><br><br>  Saya menerapkan metode augmentasi data standar, rotasi acak, dan distorsi warna.  Pelatihan tentang fragmen berarti kita pada dasarnya mendapatkan varian pemotongan gambar secara acak.  Saya tidak memutar gambar karena kamera selalu berdiri di satu sisi sarang. <br><br>  Ada beberapa nuansa dalam prediksi keluaran postprocessing.  Dengan hasil probabilistik, kami mendapatkan awan buram di mana ada lebah.  Untuk mengubahnya menjadi gambar yang jelas satu piksel per lebah, saya menambahkan nilai ambang, dengan mempertimbangkan komponen terkait akun dan mendeteksi centroid menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">modul ukuran skimage</a> .  Semua ini harus dipasang secara manual dan dikonfigurasikan secara murni oleh mata, meskipun secara teoritis dapat ditambahkan ke ujung tumpukan sebagai elemen pembelajaran.  Mungkin masuk akal untuk melakukannya di masa depan ... :) <br><br><img src="https://habrastorage.org/webt/5e/jh/2n/5ejh2n0y7bkz4p25dc11qgwwxv8.png"><br>  <i><font color="gray">Input, output mentah dan cluster centroid</font></i> <br><br><h1>  Generalisasi beberapa hari </h1><br><h3>  Dalam satu hari </h3><br>  Awalnya, percobaan dilakukan dengan gambar dalam waktu singkat satu hari.  Ternyata menjadi mudah untuk mendapatkan model yang bagus dari data ini dengan sejumlah kecil gambar yang ditandai (sekitar 30). <br><br> <a href=""><img src="https://habrastorage.org/webt/jy/uv/rm/jyuvrmhucifitb_cd0hvnjyphlo.jpeg"></a> <br>  <i><font color="gray">Tiga sampel diterima pada hari pertama</font></i> <br><br><h3>  Selama berhari-hari </h3><br>  Banyak hal menjadi lebih rumit ketika saya mulai mempertimbangkan periode yang lebih lama dari beberapa hari.  Salah satu perbedaan utama adalah perbedaan dalam pencahayaan (waktu hari dan cuaca yang berbeda).  Alasan lain adalah saya memasang kamera secara manual setiap hari, hanya menempel dengan Velcro.  Perbedaan ketiga dan paling tak terduga adalah bahwa dengan pertumbuhan rumput, kuncup dandelion terlihat seperti lebah (yaitu, pada putaran pertama, model yang terlatih tidak melihat kuncup, dan kemudian mereka muncul dan memberikan aliran positif palsu yang terus menerus). <br><br>  Sebagian besar masalah diselesaikan dengan augmentasi data, dan tidak satu masalah pun menjadi kritis.  Secara umum, data tidak terlalu bervariasi.  Ini bagus, karena memungkinkan Anda membatasi diri pada jaringan saraf sederhana dan skema pelatihan. <br><br> <a href=""><img src="https://habrastorage.org/webt/go/gy/hc/gogyhcofkdkeuhvh8r59cb6aoas.jpeg"></a> <br>  <i><font color="gray">Sampel diperoleh dalam tiga hari</font></i> <br><br><h1>  Contoh Peramalan </h1><br>  Gambar menunjukkan contoh perkiraan.  Sangat menarik untuk dicatat bahwa ada lebih banyak lebah daripada gambar apa pun yang saya beri label secara manual.  Ini adalah konfirmasi yang bagus bahwa pendekatan sepenuhnya convolutional dengan pembelajaran pada fragmen kecil benar-benar berfungsi. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/743/550/375/743550375de86803a6ecf73c0b4739ce.png"><br><br>  Jaringan berfungsi dengan baik dalam berbagai pilihan.  Saya kira latar belakang seragam membantu di sini, dan memulai jaringan pada beberapa sarang sewenang-wenang tidak akan memberikan hasil yang baik. <br><br><img src="https://habrastorage.org/webt/pj/x8/8g/pjx88gvs5ulvwslaqrsfrlqm9dk.jpeg"><br>  <i><font color="gray">Dari kiri ke kanan: kepadatan tinggi di sekitar pintu masuk;</font></i>  <i><font color="gray">lebah dari berbagai ukuran;</font></i>  <i><font color="gray">lebah dengan kecepatan tinggi!</font></i> <br><br><h1>  Trik Pelabelan </h1><br><h3>  Pelatihan semi-terkontrol </h3><br>  Kemungkinan mendapatkan sejumlah besar gambar segera menyarankan gagasan menggunakan pelatihan semi-terkontrol. <br><br>  Pendekatan yang sangat sederhana: <br><br><ol><li>  Memotret 10.000 gambar. </li><li> <code>model_1</code> label 100 gambar dan <code>model_1</code> pelatihan_1. </li><li>  Menggunakan <code>model_1</code> untuk menandai 9900 gambar yang tersisa. </li><li>  Pelatihan <code>model_2</code> pada 10.000 gambar "berlabel". </li></ol><br>  Hasilnya, <code>model_2</code> menunjukkan hasil yang lebih baik daripada <code>model_1</code> . <br><br>  Berikut ini sebuah contoh.  Perhatikan bahwa <code>model_1</code> menunjukkan beberapa false positive (kiri tengah dan rumput) dan pemicu negatif palsu (lebah di sekitar pintu masuk ke sarang). <br><br><img src="https://habrastorage.org/webt/k0/tw/a2/k0twa2fi48n5lgln3qunqtyzdsi.jpeg"><br>  <i><font color="gray">Kiri model_1, kanan model_2</font></i> <br><br><h3>  Menandai dengan memperbaiki model yang buruk </h3><br>  Data tersebut juga merupakan contoh yang bagus tentang bagaimana memperbaiki model yang buruk lebih cepat daripada menandai dari awal ... <br><br><ol><li>  Kami menandai 10 gambar dan melatih model. </li><li>  Kami menggunakan model untuk menandai 100 gambar berikutnya. </li><li>  Kami menggunakan alat menandai untuk <i>memperbaiki</i> tanda pada 100 gambar ini. </li><li>  Edukasi ulang model ini dalam 110 gambar. </li><li>  Kami ulangi ... </li></ol><br>  Ini adalah pola pembelajaran yang sangat umum, dan kadang-kadang memaksa Anda untuk merevisi alat pelabelan Anda sedikit. <br><br><h1>  Menghitung </h1><br>  Kemungkinan mendeteksi lebah berarti kita dapat menghitungnya!  Dan untuk bersenang-senang, gambarlah grafis yang menyenangkan yang menunjukkan jumlah lebah di siang hari.  Saya suka cara mereka bekerja sepanjang hari dan pulang sekitar jam 4 sore.  :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/554/b08/01c/554b0801c2d7cc360c5ea9c11339a2ee.png"><br><br><h1>  Output Raspberry Pi </h1><br>  Meluncurkan model pada Pi adalah bagian penting dari proyek ini. <br><br><h3>  Langsung pada besi Pi </h3><br>  Awalnya direncanakan untuk membekukan grafik TensorFlow dan menjalankannya langsung di Pi.  Ini berfungsi tanpa masalah, tetapi hanya Pi yang mengambil hanya 1 gambar per detik.  : / <br><br><h3>  Berjalan di Modul Komputasi Movidius </h3><br>  Saya sangat tertarik pada kesempatan untuk meluncurkan model pada Pi menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Movidus Neural Compute Stick</a> .  Ini adalah gadget yang luar biasa. <br><br>  Sayangnya, tidak ada yang terjadi: /.  API untuk mengubah grafik TensorFlow ke format model internal mereka tidak mendukung metode decoding saya.  Oleh karena itu, perlu untuk meningkatkan ukuran (upsizing), menggunakan dekonvolusi daripada mengubah ukuran pada tetangga terdekat.  Tidak ada masalah selain fakta bahwa tidak ada yang terjadi.  Ada banyak kesulitan kecil, karena <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">bug yang berlipat ganda</a> .  Ketika sudah diperbaiki, Anda dapat kembali ke topik ini ... <br><br>  <b>Model v3: Gambar RGB → penghitungan lebah</b> <br>  Ini membawa saya ke versi ketiga dari model: dapatkah kita langsung beralih dari input RGB ke penghitungan lebah?  Dengan cara ini kita akan menghindari masalah dengan operasi yang tidak didukung pada Movidus Neural Compute Stick, walaupun kecil kemungkinan hasilnya akan sebagus pada model centroid v2. <br><br>  Pada awalnya saya takut untuk mencoba metode ini: Saya pikir itu akan membutuhkan lebih banyak pelabelan (ini bukan lagi sistem berbasis fragmen).  Tapi!  Memiliki model yang cukup baik dengan pencarian lebah, dan banyak data tidak bertanda, Anda dapat menghasilkan satu set data sintetik yang baik dengan menerapkan model v2 dan hanya menghitung jumlah deteksi. <br><br>  Model seperti itu cukup mudah dipelajari dan memberikan hasil yang bermakna ... (meskipun masih tidak sebaik perhitungan sederhana dari centroid yang terdeteksi oleh model v2). <br><br><table><tbody><tr><td colspan="13" align="center">  Jumlah lebah aktual dan prediksi dalam beberapa sampel uji </td></tr><tr><td>  Yang asli </td><td>  40 </td><td>  19 </td><td>  16 </td><td>  15 </td><td>  13 </td><td>  12 </td><td>  11 </td><td>  10 </td><td>  8 </td><td>  7 </td><td>  6 </td><td>  4 </td></tr><tr><td>  v2 (centroid) prediktif </td><td>  39 </td><td>  19 </td><td>  16 </td><td>  13 </td><td>  13 </td><td>  14 </td><td>  11 </td><td>  8 </td><td>  8 </td><td>  7 </td><td>  6 </td><td>  4 </td></tr><tr><td>  perkiraan v3 (perhitungan sederhana) </td><td>  33.1 </td><td>  15.3 </td><td>  12.3 </td><td>  12.5 </td><td>  13.3 </td><td>  10,4 </td><td>  9.3 </td><td>  8.7 </td><td>  6.3 </td><td>  7.1 </td><td>  5.9 </td><td>  4.2 </td></tr></tbody></table><br>  ... sayangnya, model ini <i>masih</i> tidak berfungsi pada Neural Compute Stick (artinya, itu berfungsi, tetapi hanya memberikan hasil acak).  Saya membuat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">beberapa laporan bug</a> lagi dan lagi menunda gadget untuk kembali lagi nanti ... suatu hari ... <br><br><h1>  Apa selanjutnya </h1><br>  Seperti biasa, banyak hal kecil tetap ... <br><br><ul><li>  Peluncuran pada Neural Compute Stick (NCS);  Sekarang kami sedang menunggu beberapa pekerjaan di pihak mereka ... </li><li>  Port semuanya ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kamera JeVois bawaan</a> .  Saya sedikit mengacaukannya, tetapi pertama-tama saya ingin meluncurkan model di NCS.  Saya ingin melacak lebah pada 120 FPS !!! </li><li>  Lacak lebah di antara banyak bingkai / kamera untuk memvisualisasikan aliran optik. </li><li>  Jelajahi lebih detail manfaat dari pendekatan semi-terkontrol dan latih model yang lebih besar untuk melabeli data untuk model yang lebih kecil. </li><li>  Jelajahi fitur NCS;  apa yang harus dilakukan dengan pengaturan hyperparameters? </li><li>  Terus kembangkan versi kecil FarmBot untuk melakukan beberapa eksperimen genetik dengan semai CNC (mis. Sesuatu yang sama sekali berbeda). </li></ul><br><h1>  Kode </h1><br>  Semua kode diterbitkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di Github</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id413799/">https://habr.com/ru/post/id413799/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id413789/index.html">Di Florida, mereka tidak memeriksa pembeli senjata di markas FBI selama setahun karena mereka lupa kata sandi</a></li>
<li><a href="../id413791/index.html">Mekanika Kuantum Perhitungan dalam JS</a></li>
<li><a href="../id413793/index.html">Kaset audio dalam budaya pop: mengapa format rekaman suara yang usang dianggap modis</a></li>
<li><a href="../id413795/index.html">Mengapa industri hiburan pindah ke IaaS: studi kasus</a></li>
<li><a href="../id413797/index.html">EA memperkenalkan bagian baru C&C di E3. Dan secara fisik menyakitkan untuk melihatnya</a></li>
<li><a href="../id413801/index.html">"Roskosmos" menawarkan untuk membuat meriam laser ... sebuah teleskop optik</a></li>
<li><a href="../id413803/index.html">Python dan steganografi</a></li>
<li><a href="../id413805/index.html">Bagaimana server dilupakan selama 12 tahun dapat menelan biaya 120.000 pound</a></li>
<li><a href="../id413807/index.html">Penentuan karakteristik balistik-temporal dari gerakan pusat massa penerjun payung dari pesawat terbang</a></li>
<li><a href="../id413809/index.html">Set-Top-Box dan percobaan dengan Android di wadah LXC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
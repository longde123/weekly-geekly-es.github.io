<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòÇ üë©‚Äç‚úàÔ∏è ü§µüèæ Traducci√≥n del libro de Andrew Un, Pasi√≥n por el aprendizaje autom√°tico, cap√≠tulos 20-27 üêõ üíß üéÖüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="cap√≠tulos anteriores 
 20 Desplazamiento y dispersi√≥n: dos fuentes principales de errores 


 Comentario del traductor Antes del cambio, este cap√≠tulo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Traducci√≥n del libro de Andrew Un, Pasi√≥n por el aprendizaje autom√°tico, cap√≠tulos 20-27</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420591/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cap√≠tulos anteriores</a> </p><br><h1 id="20-smeschenie-i-razbros-dva-osnovnyh-istochnika-oshibok">  20 Desplazamiento y dispersi√≥n: dos fuentes principales de errores </h1><br><p>  <em><u>Comentario del traductor</u> Antes del cambio, este cap√≠tulo se llamaba <strong>"Sistem√°tico y aleatorio: dos fuentes principales de errores"</strong> , es decir, utilic√© los t√©rminos "errores aleatorios" y "errores sistem√°ticos" para traducir el sesgo y la varianza.</em>  <em>Sin embargo, el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">miembro</a> del foro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">robot @ Phaker,</a> en un comentario, se√±al√≥ acertadamente que en el campo del aprendizaje autom√°tico en la terminolog√≠a rusa para estos t√©rminos, los conceptos de "desplazamiento" y "dispersi√≥n" son fijos.</em>  <em>Mir√© el trabajo de K.V.</em>  <em>Vorontsov, quien merecidamente es una de las autoridades en el campo del aprendizaje autom√°tico en Rusia y los recursos de la comunidad profesional, y estuvo de acuerdo con el comentario <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">robot @ Phaker</a> .</em>  <em>A pesar del hecho de que, desde mi punto de vista, existe una analog√≠a profunda y significativa entre el "sesgo" y la "varianza" en el entrenamiento de algoritmos y el "error sistem√°tico" y "error aleatorio" de un experimento f√≠sico, adem√°s de que se expresan igualmente matem√°ticamente Sin embargo, es correcto utilizar los t√©rminos establecidos en este campo.</em>  <em>Por lo tanto, revis√© la traducci√≥n de este y los cap√≠tulos siguientes, reemplazando los "Errores sistem√°ticos y aleatorios" con "Desplazamiento y dispersi√≥n" y me atendr√© a este enfoque en el futuro.</em> </p><a name="habracut"></a><br><p>  Suponga que su entrenamiento, validaci√≥n y muestras de prueba tienen la misma distribuci√≥n.  Entonces necesita tomar m√°s datos para el entrenamiento, esto solo mejorar√° la calidad del algoritmo, ¬øes esto cierto? </p><br><p>  Aunque obtener m√°s datos no puede perjudicar el trabajo, desafortunadamente, los nuevos datos no siempre ayudan tanto como cabr√≠a esperar.  En algunos casos, el trabajo de obtener datos adicionales puede ser una p√©rdida de esfuerzo.  C√≥mo tomar una decisi√≥n: en qu√© casos agregar datos y cu√°ndo no preocuparse por ellos. </p><br><p>  En el aprendizaje autom√°tico, hay dos fuentes principales de error: sesgo y dispersi√≥n (varianza).  Comprender cu√°les son te ayudar√° a decidir si agregar m√°s datos, tambi√©n te ayudar√° a elegir t√°cticas para mejorar la calidad del clasificador. </p><br><p>  Supongamos que espera construir un identificador felino con un 5% de error.  Por el momento, su error de clasificador en la muestra de entrenamiento es del 15%, en la muestra de validaci√≥n del 16%.  En este caso, es poco probable que agregar datos de entrenamiento aumente significativamente la calidad.  Debes concentrarte en otros cambios del sistema.  De hecho, agregar m√°s ejemplos a su conjunto de entrenamiento solo dificultar√° que su algoritmo obtenga un buen resultado en ese conjunto (por qu√© esto se explicar√° en los siguientes cap√≠tulos). </p><cut></cut><br><p>  Si el porcentaje de sus errores en la muestra de entrenamiento es del 15% (lo que corresponde a una precisi√≥n del 85%), pero su objetivo es el porcentaje de errores en el 5% (95% de precisi√≥n), primero que todo debe mejorar la calidad de su algoritmo en la muestra de entrenamiento.  La calidad del algoritmo en las muestras de validaci√≥n / prueba es generalmente peor que la calidad de su trabajo en la muestra de entrenamiento (en la muestra de entrenamiento).  Debe comprender que los enfoques que lo han llevado a una precisi√≥n que no excede el 85% en ejemplos con los que su algoritmo est√° familiarizado no le permitir√°n obtener una precisi√≥n del 95% en ejemplos que este algoritmo ni siquiera ha visto. </p><cut></cut><br><p>  Suponga, como se indic√≥ anteriormente, la tasa de error de su algoritmo es del 16% (la precisi√≥n es del 84%) en la muestra de validaci√≥n.  Debemos dividir el error del 16% en dos componentes: </p><br><ul><li>  Primero, la proporci√≥n de errores de algoritmo en la muestra de entrenamiento.  En este ejemplo, es del 15%.  Informalmente lo llamamos <strong>sesgo</strong> . </li><li>  Segundo, cu√°nto peor funciona el algoritmo en la muestra de validaci√≥n (o prueba) que en la muestra de entrenamiento.  En nuestro ejemplo, es 1% peor en la muestra de validaci√≥n que en la muestra de entrenamiento.  Tambi√©n lo consideraremos extraoficialmente una <strong>variaci√≥n del</strong> algoritmo. </li></ul><br><p>  <em><u>Comentario del autor</u> En estad√≠stica, hay una definici√≥n m√°s precisa de sesgo y dispersi√≥n (errores sistem√°ticos y aleatorios), pero esto no deber√≠a molestarnos.</em>  <em>Hablando en t√©rminos generales, asumimos que el sesgo es un error en su algoritmo en su conjunto de entrenamiento cuando tiene un conjunto de entrenamiento muy grande.</em>  <em>Dispersi√≥n: esto es lo peor que funciona el algoritmo en la muestra de prueba en comparaci√≥n con el entrenamiento con la misma configuraci√≥n de par√°metros.</em>  <em>Si usa el error est√°ndar, puede escribir las f√≥rmulas que definen estas dos cantidades y demostrar que el error total es igual a la suma del sesgo y la dispersi√≥n (la suma de los errores aleatorios y sistem√°ticos).</em>  <em>Pero para nuestros prop√≥sitos, mejorar los algoritmos en los problemas de aprendizaje autom√°tico es suficiente con una definici√≥n informal de sesgo y dispersi√≥n.</em> </p><br><p>  Algunos cambios en el entrenamiento del algoritmo afectan el primer componente del <strong>sesgo de</strong> error y mejoran el rendimiento del algoritmo en la muestra de entrenamiento.  Algunos cambios afectan el segundo componente: la <strong>varianza</strong> y ayudan a generalizar mejor el algoritmo para la validaci√≥n y las muestras de prueba.  Para seleccionar los cambios m√°s efectivos que deben realizarse en el sistema, es extremadamente √∫til comprender c√≥mo cada uno de estos dos componentes de error afecta el error general del sistema. </p><br><p>  <em><u>Comentario del autor:</u> Tambi√©n hay algunos enfoques que reducen simult√°neamente el desplazamiento y la dispersi√≥n, haciendo cambios significativos en la arquitectura del sistema.</em>  <em>Pero generalmente son m√°s dif√≠ciles de encontrar e implementar.</em> </p><br><p>  Para seleccionar los cambios m√°s efectivos que deben realizarse en el sistema, es extremadamente √∫til comprender c√≥mo cada uno de estos dos componentes de error afecta el error general del sistema. </p><br><p>  El desarrollo de la intuici√≥n para comprender c√≥mo Contribuci√≥n contribuye al error, y qu√© Dispersi√≥n, lo ayudar√° a elegir de manera efectiva formas de mejorar su algoritmo. </p><cut></cut><br><h1 id="21-primery-klassifikacii-oshibok">  21 ejemplos de clasificaci√≥n de errores </h1><br><p>  Considere nuestro problema de clasificaci√≥n de gatos.  Un clasificador ideal (por ejemplo, una persona) puede lograr una excelente calidad de esta tarea. </p><br><p>  Supongamos que la calidad de nuestro algoritmo es la siguiente: </p><br><ul><li>  Error en la muestra de entrenamiento = 1% </li><li>  Error en la muestra de validaci√≥n = 11% </li></ul><br><p>  ¬øCu√°l es el problema con este clasificador?  Aplicando las definiciones del cap√≠tulo anterior, estimamos el sesgo al 1% y el diferencial al 10% (= 11% - 1%).  Por lo tanto, nuestro algoritmo tiene una gran <strong>extensi√≥n</strong> .  El clasificador tiene un error muy bajo en la muestra de entrenamiento, pero no puede generalizar los resultados del entrenamiento a una muestra de validaci√≥n.  En otras palabras, estamos lidiando con el <strong>sobreajuste</strong> . </p><br><p>  Ahora considere esta situaci√≥n: </p><br><ul><li>  Error en la muestra de entrenamiento = 15% </li><li>  Error en la muestra de validaci√≥n = 16% </li></ul><br><p>  Luego estimamos el <strong>sesgo</strong> al 15% y el <strong>diferencial</strong> al 1%.  Este clasificador recibi√≥ poca capacitaci√≥n en la muestra de capacitaci√≥n, mientras que su error en la muestra de validaci√≥n es ligeramente mayor que en la muestra de capacitaci√≥n.  Por lo tanto, este clasificador tiene un gran sesgo, pero una peque√±a extensi√≥n.  Se puede concluir que este algoritmo es <strong>insuficiente</strong> . </p><cut></cut><br><p>  Tambi√©n consideramos la siguiente distribuci√≥n de errores: </p><br><ul><li>  Error en la muestra de entrenamiento = 15% </li><li>  Error en la muestra de validaci√≥n = 30% </li></ul><br><p>  En este caso, el sesgo es del 15% y la propagaci√≥n tambi√©n es del 15%.  Este clasificador tiene un alto sesgo y propagaci√≥n: no funciona bien en la muestra de entrenamiento, tiene un alto sesgo, y su calidad en la muestra de validaci√≥n es mucho peor que en el entrenamiento, es decir  La dispersi√≥n tambi√©n es grande.  Este caso es dif√≠cil de describir en t√©rminos de reentrenamiento / subeducaci√≥n; este clasificador es reentrenado y subeducado. </p><cut></cut><br><p>  Finalmente, considere esta situaci√≥n: </p><br><ul><li>  Error en la muestra de entrenamiento = 0.5% </li><li>  Error en la muestra de validaci√≥n = 1% </li></ul><br><p>  Este es un gran clasificador, tiene poco sesgo y dispersi√≥n.  ¬°Felicitaciones a los ingenieros por lograr un excelente resultado! </p><cut></cut><br><h1 id="22-sravnenie-s-optimalnoy-doley-oshibok">  22 Comparaci√≥n con la tasa de error √≥ptima </h1><br><p>  En nuestro ejemplo para el reconocimiento de gatos, la proporci√≥n ideal de errores es el nivel disponible para el clasificador "√≥ptimo" y este nivel es cercano al 0%.  Una persona que ve una imagen casi siempre puede reconocer si un gato est√° presente en la imagen o no, y podemos esperar que tarde o temprano la m√°quina lo haga igual de bien. </p><br><p>  Pero hay tareas m√°s complejas.  Por ejemplo, imagine que est√° desarrollando un sistema de reconocimiento de voz y descubri√≥ que el 14% de las grabaciones de audio tienen tanto ruido de fondo o un discurso tan ilegible que incluso una persona no puede entender lo que se dijo all√≠.  En este caso, incluso el sistema de reconocimiento de voz m√°s "√≥ptimo" puede tener un error en la regi√≥n del 14%. </p><br><p>  Supongamos que en nuestra tarea de reconocimiento de voz nuestro algoritmo ha logrado los siguientes resultados: </p><br><ul><li>  Error en la muestra de entrenamiento = 15% </li><li>  Error en la muestra de validaci√≥n = 30% </li></ul><cut></cut><br><p>  La calidad del clasificador en la muestra de entrenamiento ya es cercana a la √≥ptima, con una tasa de error del 14%.  Por lo tanto, en este caso, no tenemos muchas oportunidades para reducir el <strong>sesgo</strong> (mejorar el algoritmo en la muestra de entrenamiento).  Sin embargo, no es posible generalizar el funcionamiento de este algoritmo a una muestra de validaci√≥n; por lo tanto, existe un gran campo para las actividades de reducci√≥n de <strong>dispersi√≥n</strong> . </p><br><p>  Este caso es similar al tercer ejemplo del cap√≠tulo anterior, en el que el error en la muestra de entrenamiento tambi√©n es igual al 15% y el error en la muestra de validaci√≥n es del 30%.  Si la tasa de error √≥ptima es de alrededor del 0%, entonces el error en la muestra de entrenamiento del 15% da mucho espacio para trabajar para mejorar el algoritmo.  Con esta suposici√≥n, los esfuerzos para reducir el <strong>sesgo</strong> en el algoritmo pueden ser muy fruct√≠feros.  Pero si la proporci√≥n √≥ptima de errores de clasificaci√≥n no puede ser inferior al 14%, entonces una proporci√≥n similar de errores de algoritmo en la muestra de entrenamiento (es decir, en la regi√≥n del 14-15%) sugiere que las posibilidades de reducir el <strong>sesgo est√°n</strong> casi agotadas. </p><br><p>  Para problemas en los que la proporci√≥n √≥ptima de errores de clasificaci√≥n difiere significativamente de cero, se puede proponer una estructuraci√≥n de errores m√°s detallada.  Continuamos considerando el ejemplo anterior con reconocimiento de voz, un error total del 30% en la muestra de validaci√≥n se puede descomponer en los siguientes componentes (los errores en la muestra de prueba se pueden analizar de la misma manera): </p><cut></cut><br><ul><li>  <strong>Sesgo √≥ptimo (sesgo inevitable):</strong> 14%.  Imag√≠nese, decidimos que incluso el mejor sistema de reconocimiento de voz posible del mundo tendr√° una tasa de error del 14%.  Hablaremos de esto como la parte "inevitable" de la compensaci√≥n del algoritmo de aprendizaje. </li><li>  <strong>Sesgo evitable</strong> : 1%.  Este valor se calcula como la diferencia entre la proporci√≥n de errores en la muestra de entrenamiento y la proporci√≥n √≥ptima de errores. </li></ul><br><p>  <em><u>Comentario del autor:</u> Si este valor result√≥ ser negativo, entonces, su algoritmo en la muestra de entrenamiento muestra un error menor que el "√≥ptimo".</em>  <em>Esto significa que usted volvi√≥ a entrenar en el conjunto de entrenamiento, su algoritmo record√≥ los ejemplos (y sus clases) del conjunto de entrenamiento.</em>  <em>En este caso, debe centrarse en m√©todos para reducir la propagaci√≥n, en lugar de reducir a√∫n m√°s el sesgo.</em> </p><br><ul><li>  <strong>Variaci√≥n</strong> : 15%.  La diferencia entre errores en la muestra de entrenamiento y en la muestra de validaci√≥n </li></ul><br><p>  Relacionando esto con nuestras definiciones anteriores, el desplazamiento y el desplazamiento desechable est√°n relacionados de la siguiente manera: </p><br><p>  Sesgo <strong>(sesgo)</strong> = Sesgo √≥ptimo ( <strong>"sesgo inevitable"</strong> ) + Sesgo desechable ( <strong>"sesgo evitable"</strong> ) </p><br><p>  <em><u>Nota del autor</u> : Estas definiciones se eligen para explicar mejor c√≥mo se puede mejorar la calidad del algoritmo de aprendizaje.</em>  <em>Estas definiciones difieren de las definiciones formales de sesgo y dispersi√≥n adoptadas en las estad√≠sticas.</em>  <em>T√©cnicamente, lo que yo defino como "Offset" deber√≠a llamarse "un error que se encuentra en la estructura de datos (no se puede identificar y eliminar)" y "Eliminar sesgo" debe definirse como "Sesgo de algoritmo de aprendizaje que excede el sesgo √≥ptimo" .</em> </p><br><p>  El sesgo evitable muestra cu√°n peor es la calidad de su algoritmo en la muestra de entrenamiento que la calidad del "clasificador √≥ptimo". </p><br><p>  La idea b√°sica de la varianza sigue siendo la misma.  En teor√≠a, siempre podemos reducir la propagaci√≥n a casi cero entrenando en una muestra de entrenamiento suficientemente grande.  Por lo tanto, cualquier propagaci√≥n es "evitable" cuando hay una muestra lo suficientemente grande, por lo que no puede existir una "propagaci√≥n inevitable" (variaci√≥n inevitable). </p><cut></cut><br><p>  Considere otro ejemplo en el que el error √≥ptimo es 14% y tenemos: </p><br><ul><li>  Error en la muestra de entrenamiento = 15% </li><li>  Error en la muestra de validaci√≥n = 16% </li></ul><br><p>  En el cap√≠tulo anterior, clasificamos un clasificador con indicadores tales como un clasificador de alto sesgo, en las condiciones actuales decimos que el "sesgo evitable" es del 1%, y el diferencial es de aproximadamente el 1%.  Por lo tanto, el algoritmo ya est√° funcionando bastante bien y casi no hay reservas para mejorar la calidad de su trabajo.  La calidad de este algoritmo es solo un 2% inferior a la √≥ptima. </p><br><p>  A partir de estos ejemplos, est√° claro que conocer la magnitud del error fatal es √∫til para decidir sobre acciones adicionales.  En estad√≠stica, la <strong>tasa de error</strong> √≥ptima tambi√©n se denomina <strong>tasa de error de Bayes</strong> . </p><br><p>  ¬øC√≥mo averiguar el tama√±o de la tasa de error √≥ptima?  Para las tareas que una persona maneja bien, como el reconocimiento de im√°genes o la decodificaci√≥n de clips de audio, puede solicitar a los evaluadores que marquen los datos y luego midan la precisi√≥n del marcado humano en la muestra de entrenamiento.  Esto le dar√° una estimaci√≥n de la tasa de error √≥ptima.  Si est√° trabajando en un problema que es dif√≠cil incluso para una persona (por ejemplo, predecir qu√© pel√≠cula recomendar o qu√© anuncio mostrarle al usuario), en este caso es bastante dif√≠cil evaluar la proporci√≥n √≥ptima de errores. </p><br><p>  En la secci√≥n Comparaci√≥n con el rendimiento a nivel humano, cap√≠tulos 33 a 35, analizar√© con m√°s detalle el proceso de comparar la calidad de un algoritmo de aprendizaje con el nivel de calidad que una persona puede lograr. </p><cut></cut><br><p>  En los √∫ltimos cap√≠tulos, aprendi√≥ c√≥mo evaluar el sesgo y la dispersi√≥n extra√≠bles / irrecuperables mediante el an√°lisis de la proporci√≥n de errores clasificadores en las muestras de capacitaci√≥n y validaci√≥n.  El pr√≥ximo cap√≠tulo examinar√° c√≥mo puede usar las conclusiones de dicho an√°lisis para decidir si concentrarse en m√©todos que reducen el sesgo o en m√©todos que reducen la propagaci√≥n.  Los enfoques para combatir el sesgo son muy diferentes de los enfoques para reducir la dispersi√≥n, por lo que las t√©cnicas que debe aplicar en su proyecto para mejorar la calidad dependen mucho de lo que actualmente es el problema: sesgo grande o dispersi√≥n grande. </p><cut></cut><br><p>  Sigue leyendo! </p><br><h1 id="23-ustranenie-smescheniya-i-razbrosa">  23 Eliminaci√≥n de compensaciones y dispersi√≥n </h1><br><p>  Aqu√≠ hay una f√≥rmula simple para eliminar el sesgo y la dispersi√≥n: </p><br><ul><li>  Si tiene un sesgo evitable grande, aumente la complejidad de su modelo (por ejemplo, aumente su red neuronal agregando capas o (y) neuronas) </li><li>  Si tiene una amplia difusi√≥n, agregue ejemplos a su conjunto de entrenamiento. </li></ul><br><p>  Si tiene la oportunidad de aumentar el tama√±o de la red neuronal y agregar datos al conjunto de entrenamiento de forma ilimitada, esto ayudar√° a lograr un buen resultado para una gran cantidad de tareas de aprendizaje autom√°tico. </p><br><p>  En la pr√°ctica, aumentar el tama√±o del modelo en √∫ltima instancia causar√° dificultades de c√°lculo, ya que el entrenamiento de modelos muy grandes es lento.  Tambi√©n puede agotar el l√≠mite de datos disponibles para la capacitaci√≥n.  (¬°Incluso en Internet, por supuesto, la cantidad de im√°genes con gatos!) </p><br><p>  Diferentes arquitecturas de modelos de algoritmos, por ejemplo, diferentes arquitecturas de redes neuronales, le dar√°n diferentes valores de sesgo y dispersi√≥n, en relaci√≥n con su tarea.  Un eje de investigaciones recientes sobre aprendizaje profundo ha creado una gran cantidad de arquitecturas innovadoras de modelos de redes neuronales.  Por lo tanto, si usa redes neuronales, la no ficci√≥n puede ser una gran fuente de inspiraci√≥n.  Tambi√©n hay una gran cantidad de excelentes implementaciones de algoritmos en fuentes abiertas, por ejemplo en GitHub.  Sin embargo, los resultados de los intentos de usar nuevas arquitecturas son significativamente menos predecibles que la f√≥rmula simple dada anteriormente: aumente el tama√±o del modelo y agregue datos. </p><br><p>  El aumento del tama√±o del modelo generalmente reduce el sesgo, pero tambi√©n puede causar un aumento en la propagaci√≥n, y tambi√©n aumenta el riesgo de reentrenamiento.  Sin embargo, el problema del reentrenamiento surge solo cuando no est√° utilizando la regularizaci√≥n.  Si incluye un m√©todo de regularizaci√≥n bien dise√±ado en su modelo, generalmente logra aumentar de forma segura el tama√±o del modelo sin permitir la reentrenamiento. </p><br><p>  Suponga que aplica el aprendizaje profundo utilizando la regularizaci√≥n o abandono de L2 ( <em><u>Nota del traductor</u> : puede leer sobre <strong>abandono</strong> , por ejemplo, aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://habr.com/company/wunderfund/blog/330814/</a></em> ), utilizando par√°metros de regularizaci√≥n que funcionan perfectamente en muestra de validaci√≥n  Si aumenta el tama√±o del modelo, generalmente la calidad de su algoritmo permanece igual o aumenta;  su declive significativo es poco probable.  La √∫nica raz√≥n por la que tenemos que negarnos a aumentar el tama√±o del modelo es la gran sobrecarga computacional. </p><br><h1 id="24-kompromiss-mezhdu-smescheniem-i-razbrosom">  24 La compensaci√≥n entre offset y spread </h1><br><p>  Es posible que haya o√≠do hablar de la "compensaci√≥n entre desplazamiento y dispersi√≥n".  Entre los muchos cambios que se pueden hacer a los algoritmos de aprendizaje, est√°n aquellos que reducen el sesgo y aumentan la propagaci√≥n, o viceversa.      ¬´¬ª    . </p><br><p> ,    ‚Äî    ()   ,       ,    . ,     ,   . </p><br><p>                      (  ).  ,      ,          ,       . </p><br><p> ,            ,       .     ,  ,  ,  ,    . </p><br><p>     ,   ,       .        . </p><br><p>    ,     ,       . </p><br><h1 id="25-podhody-k-umensheniyu-ustranimogo-smescheniya"> 25      </h1><br><p>        ,     : </p><br><ul><li> <strong>  </strong> (,     ):    ,            .   ,     ,  ,     . </li><li> <strong>  ,   ,    </strong> .         ,         (      ).        ,    .        ;    ,     , ,  ,     . </li><li> <strong>    </strong> (L2 , L1 , Dropout):     , ,    . </li><li> <strong>  </strong> (,   )       :      ,     </li></ul><br><p>     : </p><br><ul><li> <strong>    </strong> :     ,        . </li></ul><br><h1 id="26-analiz-oshibok-na-trenirovochnoy-vyborke"> 26      </h1><br><p>        ,        / . </p><br><p>    ,  ,    ,           ,    ,        .   ,      , . .         . </p><br><p> ,        -         .         ,      ,   100 ,       ,        .      ,       : </p><br><div class="scrollable-table"><table><thead><tr><th>   </th><th>    </th><th>     </th><th>     </th><th>  Comentarios </th></tr></thead><tbody><tr><td>  1 </td><td>  </td><td></td><td></td><td>    </td></tr><tr><td>  2 </td><td>  </td><td></td><td>  </td><td>   </td></tr><tr><td>  3 </td><td></td><td>  </td><td>  </td><td>     </td></tr><tr><td>  4 4 </td><td>  </td><td></td><td></td><td>   </td></tr><tr><td> %   - </td><td> 75% </td><td> 25% </td><td> 50% </td><td></td></tr></tbody></table></div><br><p>       ,         ,    .       ,           . </p><br><p>      ,      -,      ,    .       ,    - ,   ,     ,  -     .      ,          ,  . </p><br><h1 id="27-podhody-k-umensheniyu-razbrosa"> 27     </h1><br><p>       ,     : </p><br><ul><li> <strong>     </strong> :         ,     ,                  . </li><li> <strong> </strong> (L1 , L2 , dropout):    ,   . </li><li> <strong>  </strong> (. .    ,       ):    ,   .      ,       . </li><li> <strong>    /  </strong> :       ,     .     (,  1000   900)       .   (  1000   100  10  )     ,      ,        .    ,   ,      ,        ,          ,     ,    ,      . ,     ,      . </li><li> <strong>  () </strong> (    / ). <em>  !</em>       , ,  . ,          .        .                  .       ,        . ,              ,     . </li></ul><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aqu√≠ doy dos t√©cnicas t√°cticas adicionales, repitiendo lo que se dijo en los cap√≠tulos anteriores, en relaci√≥n con la reducci√≥n del sesgo: </font></font></p><br><ul><li> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modifique los s√≠ntomas entrantes en funci√≥n de la comprensi√≥n obtenida del an√°lisis de errores</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : supongamos que su an√°lisis de errores ha llevado a la idea de que puede crear s√≠ntomas adicionales que ayudar√°n al algoritmo a eliminar algunas categor√≠as de errores. </font><font style="vertical-align: inherit;">Estas nuevas caracter√≠sticas ayudar√°n a reducir tanto la dispersi√≥n como el desplazamiento. </font><font style="vertical-align: inherit;">Te√≥ricamente, la adici√≥n de nuevos rasgos puede aumentar la propagaci√≥n; </font><font style="vertical-align: inherit;">pero si esto sucede, siempre puede aprovechar la regularizaci√≥n, que generalmente nivela el aumento de la propagaci√≥n.</font></font></li><li> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Modifique la arquitectura del modelo</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (por ejemplo, arquitectura de red neuronal) para que sea m√°s adecuada para su tarea: este enfoque puede reducir tanto el sesgo como la dispersi√≥n.</font></font></li></ul><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">continuaci√≥n</font></font></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es420591/">https://habr.com/ru/post/es420591/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es420579/index.html">CPU de 24 n√∫cleos, pero no puedo escribir un correo electr√≥nico</a></li>
<li><a href="../es420581/index.html">Previsi√≥n de ventas inmobiliarias. Conferencia en Yandex</a></li>
<li><a href="../es420585/index.html">Descarga gratuita de la base de datos de c√≥digos de barras sin registro (y otros caquis)</a></li>
<li><a href="../es420587/index.html">Bueno, ¬ød√≥nde poner estos motores ahora?</a></li>
<li><a href="../es420589/index.html">Qu√© buscar al elegir un sistema de registro y por qu√© nos decidimos por ELK</a></li>
<li><a href="../es420593/index.html">Optimizaci√≥n de la navegaci√≥n web m√≥vil (2 √©xitos recientes)</a></li>
<li><a href="../es420595/index.html">Generaci√≥n autom√°tica de programas, problemas inversos y algunas soluciones relacionadas.</a></li>
<li><a href="../es420597/index.html">Oficial de Protecci√≥n de Datos - GDPR actualiza la profesi√≥n</a></li>
<li><a href="../es420599/index.html">Trece cosas que Lem previeron</a></li>
<li><a href="../es420603/index.html">Estad√≠sticas del propietario de Tesla Model S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
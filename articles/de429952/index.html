<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧝🏻 👩‍🏭 🎗️ Die Vergangenheit, Gegenwart und Zukunft von Docker und anderen Containerlaufzeiten in Kubernetes 📻 👷🏼 👲🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hinweis perev. : Wir haben bereits mehr als eine Veröffentlichung (siehe Links am Ende des Artikels) über Containerlaufzeiten (Containerlaufzeiten) ge...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Vergangenheit, Gegenwart und Zukunft von Docker und anderen Containerlaufzeiten in Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/429952/">  <i><b>Hinweis</b></i>  <i><b>perev.</b></i>  <i>: Wir haben bereits mehr als eine Veröffentlichung (siehe Links am Ende des Artikels) über Containerlaufzeiten (Containerlaufzeiten) geschrieben - diese werden in der Regel im Kontext von Kubernetes diskutiert.</i>  <i>Diese Materialien erregten jedoch häufig Fragen der Leser, was auf ein Unverständnis darüber hinweist, woher das nächste Projekt kam, wie es mit anderen verbunden ist und was in all diesem Container-Zoo vor sich geht.</i> <br><br><img src="https://habrastorage.org/webt/cy/td/t5/cytdt5jmmufxrtz_b41os56vneg.png"><br><br>  <i>Ein kürzlich veröffentlichter Artikel von Phil Estes, Technischer Direktor für Container und Linux-Architektur bei IBM Watson &amp; Cloud Platform, bietet einen hervorragenden Rückblick darauf, wie man navigiert und ein umfassenderes Verständnis dafür gewinnt, wer den Faden der Ereignisse verloren hat (oder nie gefangen hat).</i>  <i>Als einer der Betreuer der Moby- und Containerd-Projekte, Mitglied der technischen Komitees der Open Container Initiative (OCI) und von Moby sowie als Docker Captain schreibt der Autor über die Vergangenheit, Gegenwart und Zukunft der neuen wunderbaren Welt der Containerlaufzeiten.</i>  <i>Und für die Faulsten beginnt das Material mit einer kompakten TL; DR zum Thema ...</i> <a name="habracut"></a><br><br><h2>  Wichtigste Ergebnisse </h2><br><ul><li>  Im Laufe der Zeit hat die Auswahl unter den Containerlaufzeiten zugenommen und bietet mehr Optionen als die beliebte Docker-Engine. </li><li>  Die Open Container Initiative (OCI) hat das Konzept des Container- und Container-Images erfolgreich standardisiert, um die Interoperabilität <i>(„Interoperabilität“ - ca. übersetzt)</i> zwischen Laufzeitumgebungen zu gewährleisten. </li><li>  Kubernetes hat das Container Runtime Interface (CRI) hinzugefügt, mit dem Container eine Verbindung zu Laufzeitumgebungen mit der zugrunde liegenden Orchestrierungsschicht in K8s herstellen können. </li><li>  Innovationen in diesem Bereich ermöglichen es Containern, die einfache Virtualisierung und andere einzigartige Isolationstechniken für wachsende Sicherheitsanforderungen zu nutzen. </li><li>  Mit OCI und CRI sind Interoperabilität und Auswahl im Ökosystem von Laufzeitcontainer- und Orchestrierungsumgebungen Realität geworden. </li></ul><br>  Die Containerisierungstechnologie gibt es in der Welt der Linux-Betriebssysteme schon seit geraumer Zeit - die ersten Ideen zu separaten Namespaces für Dateisysteme und Prozesse sind vor mehr als einem Jahrzehnt aufgetaucht.  In der jüngeren Vergangenheit erschien der LXC und wurde zur Standardmethode für Linux-Benutzer, um mit der leistungsstarken Isolationstechnologie zu interagieren, die im Linux-Kernel verborgen ist. <br><br>  Trotz der Versuche des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LXC</a> , die Komplexität der Kombination verschiedener technologischer „Innenseiten“ dessen, was wir heute normalerweise als Container bezeichnen, zu verbergen, blieben Container eine Art Magie und wurden nur in der Welt derjenigen stärker, die besonders gut informiert waren und keine breite Verteilung unter den Massen fanden. <br><br>  Mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Docker</a> änderte sich 2014 alles, als ein neuer, entwicklerfreundlicher Wrapper für dieselbe Linux-Kernel-Technologie erschien, die LXC in Betrieb hatte - schließlich verwendeten die frühen Versionen von Docker „hinter den Kulissen“ LXC, und die Container wurden - ein echtes Massenphänomen, da die Entwickler von der Einfachheit und den Möglichkeiten der Wiederverwendung von Docker-Container-Images und einfachen Befehlen für die Arbeit mit ihnen durchdrungen waren. <br><br>  Natürlich war Docker nicht der einzige, der sich einen Anteil am Containermarkt sichern wollte, als der sie begleitende Hype nach dem ersten explosiven Interesse im Jahr 2014 nicht nachlassen wollte.  Im Laufe der Jahre sind eine Vielzahl alternativer Ideen für ausführbare Containerumgebungen von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CoreOS (rkt)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Intel Clear Containers</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hyper.sh</a> (leichte containerisierte Virtualisierung) sowie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Singularity</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shifter</a> in der Welt der Hochleistungsrechnerforschung (HPC) entstanden. <br><br>  Der Markt wuchs und reifte weiter und mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Open Container Initiative (OCI) wurden</a> die ersten von Docker geförderten Ideen standardisiert.  Heutzutage sind viele ausführbare Containerumgebungen entweder bereits mit OCI kompatibel oder auf dem Weg dorthin und bieten Herstellern gleiche Bedingungen, um ihre Funktionen und Fähigkeiten zu fördern, die auf eine bestimmte Anwendung ausgerichtet sind. <br><br><h2>  Popularität von Kubernetes </h2><br>  Die nächste Stufe in der Entwicklung von Containern bestand darin, verteilte Computercontainer a la Microservices mit Containern zu kombinieren - und das alles in der neuen Welt der schnellen Entwicklungs- und Bereitstellungsiterationen (wir können sagen, dass DevOps), die zusammen mit der Popularität von Docker aktiv an Dynamik gewann. <br><br>  Obwohl <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Mesos</a> und andere Software-Orchestrierungsplattformen existierten, bevor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes</a> dominierte, starteten die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">K8s</a> schnell von einem kleinen Open Source-Projekt von Google zum Hauptprojekt der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cloud Native Computing Foundation (CNCF)</a> . <br><br>  <i><b>Hinweis</b></i>  <i><b>perev.</b></i>  <i>: Wissen Sie, dass CNCF 2015 anlässlich der Veröffentlichung von Kubernetes 1.0 erschien?</i>  <i>Gleichzeitig wurde das Projekt von Google an eine neue unabhängige Organisation übertragen, die Teil der Linux Foundation wurde.</i> <br><br><img src="https://habrastorage.org/webt/hu/_u/em/hu_uemcx44qdursrnr_nsc04gie.png"><br>  <i>K8s 1.0 Release Event, gesponsert unter anderem von Mesosphere, CoreOS, Mirantis, OpenStack, Bitnami</i> <br><img src="https://habrastorage.org/webt/lq/rf/ab/lqrfabydpe9_lbh9zv5x8titb48.png"><br>  <i>Aus den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nachrichten</a> über die Veröffentlichung von Kubernetes 1.0 auf ZDNet</i> <br><br>  Selbst nachdem Docker die in Docker integrierte konkurrierende Orchestrierungsplattform <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Swarm veröffentlicht hatte</a> , die Docker-Einfachheit und einen Fokus auf die standardmäßige sichere Cluster-Konfiguration bietet, reichte dies nicht mehr aus, um das wachsende Interesse an Kubernetes einzudämmen. <br><br>  Viele Stakeholder außerhalb der schnell wachsenden Cloud-Communitys waren jedoch verwirrt.  Ein durchschnittlicher Beobachter konnte nicht herausfinden, was geschah: Kubernetes kämpfen mit Docker oder ihrer Zusammenarbeit?  Da Kubernetes nur eine Orchestrierungsplattform war, war eine ausführbare Containerumgebung erforderlich, mit der in Kubernetes orchestrierte Container direkt gestartet werden konnten.  Von Anfang an verwendete Kubernetes die Docker-Engine. Trotz der Konkurrenz zwischen Swarm und Kubernetes war Docker immer noch die Standardlaufzeit und für die Funktion des Kubernetes-Clusters erforderlich. <br><br>  Bei einer kleinen Anzahl anderer Containerlaufzeiten als Docker schien es klar zu sein, dass für das Koppeln der Laufzeit mit Kubernetes für jede Laufzeit eine speziell geschriebene Schnittstelle - Shim - erforderlich ist.  Das Fehlen einer klaren Schnittstelle für die Implementierung von Containerlaufzeiten machte es sehr schwierig, Unterstützung für neue Laufzeiten in Kubernetes hinzuzufügen. <br><br><h2>  Container Runtime Interface (CRI) </h2><br>  Um die wachsende Komplexität der Implementierung von Laufzeiten in Kubernetes zu lösen, definierte die Community eine schnittstellenspezifische Funktion, die die Container-Laufzeit in Kubernetes implementieren sollte, und nannte sie <a href="">Container Runtime Interface (CRI)</a> <i>(sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erschien</a> in Kubernetes 1.5 - ca. Transl.)</i> .  Dieses Ereignis half nicht nur dem Problem der wachsenden Anzahl von Fragmenten der Kubernetes-Codebasis, die sich auf die Verwendung von Containerlaufzeiten auswirken, sondern auch zu verstehen, welche Funktionen von potenziellen Laufzeiten unterstützt werden sollten, wenn sie CRI einhalten möchten. <br><br>  Wie Sie sich vorstellen können, erwartet CRI von der Laufzeit sehr einfache Dinge.  Eine solche Umgebung sollte in der Lage sein, Pods zu starten und zu stoppen, alle Vorgänge mit Containern im Kontext von Pods abzuwickeln (Start, Stopp, Pause, Kill, Löschen) und auch die Verwaltung von Container-Images mithilfe der Registrierung zu unterstützen.  Es gibt auch Zusatzfunktionen zum Sammeln von Protokollen, Metriken usw. <br><br>  Wenn neue Funktionen in Kubernetes angezeigt werden und von der Ebene der Container-Laufzeit abhängen, werden solche Änderungen an der versionierten CRI-API vorgenommen.  Dies schafft wiederum eine neue funktionale Abhängigkeit von Kubernetes und erfordert die Veröffentlichung neuer Versionen von Laufzeiten, die neue Funktionen unterstützen (ein aktuelles Beispiel sind Benutzernamensräume). <br><br><h2>  Aktuelle CRI-Landschaft </h2><br>  Ab 2018 gibt es in Kubernetes mehrere Optionen zur Verwendung als Containerlaufzeiten.  Wie in der folgenden Abbildung gezeigt, ist Docker mit seinem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dockershim</a> , der die CRI-API implementiert, immer noch eine der wirklichen Optionen.  Tatsächlich ist es in den meisten Kubernetes-Installationen heute er, Docker, der die Standardlaufzeit bleibt. <br><br><img src="https://habrastorage.org/webt/p6/9q/0h/p69q0hpabyujabund9bgicx12q4.jpeg"><br><br>  Eine der interessanten Konsequenzen der Spannung zwischen der Docker-Orchestrierungsstrategie mit Swarm und der Kubernetes-Community war ein gemeinsames Projekt, das auf der Grundlage der Laufzeit von Docker ein neues, gemeinsam entwickeltes Open Source-Projekt - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Containerd</a> - zusammenfasste.  Im Laufe der Zeit wurde Containerd an CNCF übertragen, dieselbe Organisation, die das Kubernetes-Projekt verwaltet und besitzt.  <i>( <b>Anmerkung übersetzt</b> : Wir haben das Erscheinungsbild von Containerd in einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">separaten Artikel</a> ausführlicher <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">beschrieben</a> .)</i> <br><br><img src="https://habrastorage.org/webt/yr/o1/wx/yro1wxcji1jh-xettnzp-jiyiu8.png"><br>  <i>Aus der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ankündigung von</a> Containerd im Docker-Blog</i> <br><br>  Containerd, eine einfache, grundlegende und unternehmensunabhängige <i>(nicht meinungsgebundene)</i> Implementierung der Laufzeit für Docker und Kubernetes (über CRI), wurde in vielen Kubernetes-Installationen als potenzieller Ersatz für Docker immer beliebter.  Bisher verfügen sowohl IBM Cloud als auch Google Cloud über Cluster auf Basis von Containerds im Early Access / Beta-Modus.  Microsoft Azure versprach auch, in Zukunft auf Containerd umzusteigen, und Amazon erwägt weiterhin verschiedene Optionen für die Laufzeit seiner Containerlösungen (ECS und EKS), während Docker weiterhin verwendet wird. <br><br>  Red Hat hat den Container- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laufzeitbereich</a> betreten, indem eine einfache CRI-Implementierung namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cri-o erstellt wurde,</a> die auf der OCI-Referenzimplementierung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">runc basiert</a> .  Docker und Containerd sind ebenfalls Runc-basiert, aber die Entwickler von Cri-O behaupten, dass ihre Laufzeiten für Kubernetes "gerade genug" sind und sie nicht mehr benötigen - sie haben nur die wichtigsten Funktionen hinzugefügt, um Kubernetes CRI über die Basis-Runc-Binärdatei zu implementieren.  <i>( <b>Anmerkung übersetzt</b> : Wir haben in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Artikel</a> mehr über das CRI-O-Projekt und hier über seine Weiterentwicklung in Form von Podman geschrieben.)</i> <br><br>  Leichte Virtualisierungsprojekte: Intel Clear Containers und hyper.sh - erschienen in der Wildnis der OpenStack Foundation, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kata-Container</a> , und bieten ihre Vision von virtualisierten Containern für zusätzliche Isolation mithilfe einer CRI-Implementierung namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">frakti</a> .  Sowohl Cri-O als auch Containerd funktionieren auch mit Kata-Containern, sodass ihre OCI-kompatible Laufzeit als steckbare Option ausgewählt werden kann. <br><br><h2>  Die Zukunft vorhersagen </h2><br>  Zu sagen, dass Sie die Zukunft kennen, ist normalerweise nicht sehr klug, aber wir können zumindest einige aufkommende Trends korrigieren, wenn sich das Ökosystem der Container von Begeisterung und Hype zu einem reiferen Stadium unserer Existenz entwickelt. <br><br>  Es gab frühe Befürchtungen, dass das Container-Ökosystem eine fragmentierte Umgebung bilden würde, deren unterschiedliche Teilnehmer unterschiedliche und inkompatible Vorstellungen darüber haben würden, was ein Container ist.  Dank der Arbeit von OCI und des verantwortungsvollen Handelns der wichtigsten Anbieter und Teilnehmer konnten wir unter den Softwareangeboten, die die Kompatibilität mit OCI bevorzugten, ein gesundes Umfeld in der Branche erkennen. <br><br>  Selbst in neueren Umgebungen, in denen der Docker-Verwendungsstandard aufgrund bestehender Einschränkungen - beispielsweise in HPC - weniger Widerstand fand, wurde bei allen Versuchen, nicht auf Docker basierende Container-Container-Umgebungen zu erstellen, auch auf die OCI aufmerksam.  Es wird diskutiert, ob OCI eine tragfähige Lösung für die spezifischen Bedürfnisse der Gemeinschaften von Wissenschaftlern und Forschern sein kann. <br><br>  Hinzu kommt die Standardisierung der Plug-in-Containerlaufzeiten in Kubernetes mithilfe von CRI. Wir können uns eine Welt vorstellen, in der Entwickler und Administratoren die richtigen Tools und Software-Stacks für ihre Aufgaben auswählen und auf die Interoperabilität im gesamten Container-Ökosystem warten und diese beobachten können. <br><br>  Betrachten Sie ein bestimmtes Beispiel, um diese Welt besser zu verstehen: <br><br><ul><li>  Ein Entwickler mit einem MacBook verwendet Docker für Mac, um seine Anwendung zu entwickeln, und verwendet sogar die integrierte Kubernetes-Unterstützung (Docker funktioniert hier wie CRI-Laufzeit), um zu versuchen, die neue Anwendung auf K8s-Pods bereitzustellen. </li><li>  Die Anwendung durchläuft CI / CD in der Software des Anbieters, die runc und speziellen (vom Anbieter geschriebenen) Code verwendet, um das OCI-Image zu verpacken und zum Testen in die Unternehmensregistrierung von Containern zu laden. </li><li>  Die lokale Kubernetes-Clusterinstallation, die mit Containerd als CRI-Laufzeit arbeitet, führt eine Reihe von Tests für die Anwendung aus. </li><li>  Aus irgendeinem Grund hat dieses Unternehmen Kata-Container für bestimmte Workloads in der Produktion ausgewählt. Wenn Sie die Anwendung bereitstellen, wird sie in Pods mit Containerd gestartet, die so konfiguriert sind, dass Kata-Container als Laufzeit anstelle von runc verwendet werden. </li></ul><br>  Das gesamte beschriebene Szenario funktioniert wunderbar, da es mit der OCI-Spezifikation für Laufzeitumgebungen und Images kompatibel ist und CRI die Flexibilität bietet, die Laufzeit auszuwählen. <br><br>  Diese mögliche Flexibilität und Auswahl macht das Container-Ökosystem wirklich bemerkenswert und ist auch eine sehr wichtige Voraussetzung für die Reife der Branche, die seit 2014 so schnell gewachsen ist.  An der Schwelle von 2019 und den folgenden Jahren sehe ich eine glänzende Zukunft mit kontinuierlichen Innovationen und Flexibilität für diejenigen, die Plattformen auf der Basis von Containern nutzen und erstellen. <br><br>  Weitere Informationen zu diesem Thema finden Sie in einem kürzlich von Phil Estes auf QCon NY gehaltenen Vortrag: „ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CRI Runtimes Deep Dive: Wer betreibt meinen Kubernetes Pod?</a>  "" <br><br><h2>  PS vom Übersetzer </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Red Hat ersetzt Docker durch Podman</a> "; </li><li>  "Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Integration von Containerd in Kubernetes, die Docker ersetzt, ist produktionsbereit</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CRI-O - eine Alternative zu Docker zum Starten von Containern in Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Was und warum macht Docker Moby, um sich in Kubernetes zu integrieren?"</a>  "" </li><li>  „ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Was ist ein Pod in Kubernetes?</a>  "" </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429952/">https://habr.com/ru/post/de429952/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429940/index.html">Warum Pflanzen maschinelles Lernen brauchen</a></li>
<li><a href="../de429942/index.html">Holen Sie sich VK-Musik über eine Drittanbieter-API</a></li>
<li><a href="../de429946/index.html">Wahnsinn und Erfolg von Oracle Database Code</a></li>
<li><a href="../de429948/index.html">Warum Produktmanager bei Fintech benötigt werden</a></li>
<li><a href="../de429950/index.html">So pflegen Sie gesunde Kommunikationsgewohnheiten von Remote-Teams</a></li>
<li><a href="../de429954/index.html">Der Programmierer für die irischen Buchmacher</a></li>
<li><a href="../de429956/index.html">Kontinuierliche Integration in Yandex. Teil 2</a></li>
<li><a href="../de429958/index.html">Fünf einfache Debugging-Regeln für Anfänger</a></li>
<li><a href="../de429960/index.html">10 Gründe, warum Kunden ein Produkt abbestellen</a></li>
<li><a href="../de429964/index.html">U> X> I> P ... oder "Wie die Namen von Berufen überspringen"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õîÔ∏è üöö üèÇüèø Previs√µes de matem√°ticos. Analisamos os principais m√©todos para detectar anomalias üë©‚Äçüëß‚Äçüëß üíë üë©üèø‚Äçü§ù‚Äçüë©üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O uso da intelig√™ncia artificial na ind√∫stria para manuten√ß√£o preditiva de v√°rios sistemas est√° ganhando cada vez mais popularidade no exterior. O obj...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Previs√µes de matem√°ticos. Analisamos os principais m√©todos para detectar anomalias</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/447190/">  O uso da intelig√™ncia artificial na ind√∫stria para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">manuten√ß√£o preditiva de</a> v√°rios sistemas est√° ganhando cada vez mais popularidade no exterior.  O objetivo desta metodologia √© identificar defeitos na opera√ß√£o do sistema durante a fase de opera√ß√£o antes de sua falha para uma resposta oportuna. <br><br>  Qu√£o relevante √© essa abordagem em nosso pa√≠s e no Ocidente?  A conclus√£o pode ser feita, por exemplo, em artigos sobre Habr√© e no Medium.  Quase n√£o h√° artigos sobre Habr√© sobre a solu√ß√£o de problemas de manuten√ß√£o preditiva.  No Medium, h√° um conjunto inteiro.  Aqui, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">est√°</a> bem descrito quais s√£o os objetivos e as vantagens dessa abordagem. <br><br>  Neste artigo, voc√™ aprender√°: <br><br><ul><li>  por que essa t√©cnica √© necess√°ria </li><li>  quais abordagens de aprendizado de m√°quina s√£o mais comumente usadas para manuten√ß√£o preditiva, </li><li>  como tentei um dos truques com um exemplo simples. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/845/2a4/888/8452a4888db8d633dd14d426f6b80cbe.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><i>Fonte</i></a> <br><a name="habracut"></a><br>  Quais recursos o servi√ßo preditivo fornece? <br><br><ul><li>  um processo controlado de reparos, realizado conforme necess√°rio, economizando dinheiro e sem pressa, o que melhora a qualidade dessas obras; </li><li>  identifica√ß√£o de um mau funcionamento espec√≠fico na opera√ß√£o do equipamento (a capacidade de adquirir uma pe√ßa espec√≠fica para substitui√ß√£o quando o equipamento estiver em opera√ß√£o oferece enormes vantagens); </li><li>  otimiza√ß√£o da opera√ß√£o do equipamento, cargas, etc; </li><li>  redu√ß√£o de custos com parada regular de equipamentos. </li></ul><br>  O <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pr√≥ximo artigo no Medium</a> descreve bem as perguntas que precisam ser respondidas para entender como abordar esse problema em um caso espec√≠fico. <br><br>  Ao coletar dados ou ao escolher dados para construir um modelo, √© importante responder a tr√™s grupos de perguntas: <br><br><ol><li>  Todos os problemas do sistema podem ser previstos?  Qual previs√£o √© especialmente importante? </li><li>  O que √© um processo de falha?  Todo o sistema para de funcionar ou o modo operacional est√° apenas mudando?  √â um processo r√°pido, degrada√ß√£o instant√¢nea ou gradual? </li><li>  O desempenho do sistema reflete adequadamente seu desempenho?  Eles se relacionam com partes individuais do sistema ou com o sistema como um todo? </li></ol><br>  Tamb√©m √© importante entender com anteced√™ncia o que voc√™ deseja prever, o que √© poss√≠vel prever e o que n√£o √©. <br><br>  O artigo no Medium tamb√©m lista perguntas que ajudar√£o a determinar seu objetivo espec√≠fico: <br><br><ul><li>  O que precisa ser previsto?  O tempo de vida restante, comportamento anormal ou n√£o, a probabilidade de falha nas pr√≥ximas N horas / dias / semanas? </li><li>  Existem dados hist√≥ricos suficientes? </li><li>  Sabe-se quando o sistema forneceu leituras an√¥malas e quando n√£o.  √â poss√≠vel marcar essas indica√ß√µes? </li><li>  At√© que ponto o modelo deve ver?  Qu√£o independentes s√£o as leituras que refletem a opera√ß√£o do sistema no intervalo de uma hora / dia / semana </li><li>  O que voc√™ precisa otimizar?  O modelo deve capturar o maior n√∫mero poss√≠vel de viola√ß√µes, ao emitir um alarme falso, ou √© suficiente para capturar v√°rios eventos sem falsos positivos. </li></ul><br>  Espera-se que a situa√ß√£o melhore no futuro.  At√© o momento, existem dificuldades no campo da manuten√ß√£o preditiva: poucos exemplos de mau funcionamento do sistema ou momentos de mau funcionamento do sistema s√£o suficientes, mas n√£o est√£o marcados;  o processo de falha √© desconhecido. <br><br>  A principal maneira de superar as dificuldades na manuten√ß√£o preditiva √© usar <b>m√©todos de pesquisa de anomalias</b> .  Esses algoritmos n√£o requerem marca√ß√£o para treinamento.  Para algoritmos de teste e depura√ß√£o, a marca√ß√£o de uma forma ou de outra √© necess√°ria.  Tais m√©todos s√£o limitados, pois n√£o prev√™em uma falha espec√≠fica, mas apenas sinalizam anormalidade nos indicadores. <br><br>  Mas isso j√° n√£o √© ruim. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/847/46c/6d7/84746c6d7414722b0a1b7b322000f201.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><i>Fonte</i></a> <br><br><h2>  M√©todos </h2><br>  Agora, quero falar sobre alguns recursos das abordagens de detec√ß√£o de anomalias e, juntos, testaremos os recursos de alguns algoritmos simples na pr√°tica. <br><br>  Embora uma situa√ß√£o espec√≠fica exija o teste de v√°rios algoritmos para procurar anomalias e escolher o melhor, √© poss√≠vel determinar algumas vantagens e desvantagens das principais t√©cnicas usadas nesta √°rea. <br><br>  Antes de tudo, √© importante entender com anteced√™ncia qual √© a porcentagem de anomalias nos dados. <br><br>  Se estamos falando de uma varia√ß√£o da abordagem semi-supervisionada (estudamos apenas dados "normais" e trabalhamos (teste) e dados com anomalias), a melhor op√ß√£o √© <b>o m√©todo do vetor de suporte com uma classe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SVM de uma classe</a> )</b> .  Ao usar fun√ß√µes de base radial como n√∫cleo, esse algoritmo constr√≥i uma superf√≠cie n√£o linear em torno da origem.  Quanto mais limpos os dados de treinamento, melhor eles funcionam. <br><br>  Em outros casos, a necessidade de conhecer a propor√ß√£o de pontos anormais e "normais" tamb√©m permanece - para determinar o limite de corte. <br><br>  Se o n√∫mero de anomalias nos dados for superior a 5%, e elas forem bem separ√°veis ‚Äã‚Äãda amostra principal, poder√£o ser utilizados m√©todos padr√£o de busca de anomalias. <br><br>  Nesse caso, o <b>m√©todo da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">floresta de isolamento</a></b> √© o mais est√°vel em termos de qualidade: <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">floresta de isolamento s√£o</a></b> dados aleat√≥rios.  √â prov√°vel que uma indica√ß√£o mais caracter√≠stica seja mais profunda, enquanto indicadores incomuns ser√£o separados do restante da amostra nas primeiras itera√ß√µes. <br><br>  Outros algoritmos funcionam melhor se "se ajustarem" √†s especificidades dos dados. <br><br>  Quando os dados t√™m uma distribui√ß√£o normal, o <b>m√©todo do envelope el√≠ptico</b> √© adequado, aproximando os dados com uma distribui√ß√£o normal multidimensional.  Quanto menos prov√°vel que o ponto perten√ßa √† distribui√ß√£o, maior a probabilidade de que seja an√¥malo. <br><br>  Se os dados s√£o apresentados de tal maneira que a posi√ß√£o relativa de diferentes pontos reflete bem suas diferen√ßas, os m√©todos m√©tricos parecem ser uma boa op√ß√£o: por exemplo, <b>k vizinhos mais pr√≥ximos, k-√©simo vizinho mais pr√≥ximo, ABOD (detec√ß√£o de discrep√¢ncia de √¢ngulo) ou LOF (fator de discrep√¢ncia local) )</b> <br><br>  Todos esses m√©todos sugerem que os indicadores ‚Äúcertos‚Äù est√£o concentrados em uma √°rea do espa√ßo multidimensional.  Se entre os k (ou k-√©s) vizinhos mais pr√≥ximos tudo estiver longe do alvo, o ponto ser√° uma anomalia.  Para ABOD, o racioc√≠nio √© semelhante: se todos os k pontos mais pr√≥ximos estiverem no mesmo setor de espa√ßo em rela√ß√£o ao considerado, ent√£o o ponto √© uma anomalia.  Para LOF: se a densidade local (predeterminada para cada ponto por k vizinhos mais pr√≥ximos) for menor que a de k vizinhos mais pr√≥ximos, o ponto ser√° uma anomalia. <br><br>  Se os dados estiverem bem agrupados, <b>m√©todos baseados na an√°lise de cluster</b> s√£o uma boa op√ß√£o.  Se o ponto √© equidistante dos centros de v√°rios aglomerados, ent√£o √© an√¥malo. <br><br>  Se as dire√ß√µes da maior varia√ß√£o na vari√¢ncia s√£o bem diferenciadas nos dados, parece ser uma boa op√ß√£o <b>procurar anomalias com base no m√©todo do componente principal</b> .  Nesse caso, os desvios do valor m√©dio para n1 (os componentes mais "principais") e n2 (os menos "principais") s√£o considerados como uma medida de anomalia. <br><br>  Por exemplo, sugere-se examinar o conjunto de dados da <b>Sociedade de Progn√≥stico e Gerenciamento de Sa√∫de (PHM Society)</b> .  Esta organiza√ß√£o sem fins lucrativos organiza a concorr√™ncia todos os anos.  Em 2018, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foi necess√°rio prever erros na opera√ß√£o e o tempo antes da falha da planta de grava√ß√£o por feixe de √≠ons</a> .  Tomaremos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados para 2015</a> .  Ele cont√©m as leituras de v√°rios sensores para 30 instala√ß√µes (amostra de treinamento) e √© necess√°rio prever quando e qual erro ocorrer√°. <br><br>  N√£o encontrei as respostas para a amostra de teste na rede, portanto, jogaremos apenas com a de treinamento. <br><br>  Em geral, todas as configura√ß√µes s√£o semelhantes, mas diferem, por exemplo, no n√∫mero de componentes, no n√∫mero de anomalias etc.  Portanto, aprender nos 20 primeiros e testar nos outros n√£o faz muito sentido. <br><br>  Ent√£o, vamos escolher uma das instala√ß√µes, carreg√°-la e dar uma olhada nesses dados.  O artigo n√£o ser√° sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">engenharia de recursos</a> , portanto, n√£o faremos pares. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.covariance <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> EllipticEnvelope <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neighbors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LocalOutlierFactor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IsolationForest <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.svm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> OneClassSVM dfa=pd.read_csv(<span class="hljs-string"><span class="hljs-string">'plant_12a.csv'</span></span>,names=[<span class="hljs-string"><span class="hljs-string">'Component number'</span></span>,<span class="hljs-string"><span class="hljs-string">'Time'</span></span>,<span class="hljs-string"><span class="hljs-string">'S1'</span></span>,<span class="hljs-string"><span class="hljs-string">'S2'</span></span>,<span class="hljs-string"><span class="hljs-string">'S3'</span></span>,<span class="hljs-string"><span class="hljs-string">'S4'</span></span>,<span class="hljs-string"><span class="hljs-string">'S1ref'</span></span>,<span class="hljs-string"><span class="hljs-string">'S2ref'</span></span>,<span class="hljs-string"><span class="hljs-string">'S3ref'</span></span>,<span class="hljs-string"><span class="hljs-string">'S4ref'</span></span>]) dfa.head(<span class="hljs-number"><span class="hljs-number">10</span></span>)</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/301/77e/2bb/30177e2bb970e82495b18008b44d7ea4.jpg"></div><br>  Como voc√™ pode ver, existem sete componentes para cada um dos quais existem leituras de quatro sensores que s√£o realizados a cada 15 minutos.  S1ref-S4ref na descri√ß√£o da competi√ß√£o s√£o listados como valores de refer√™ncia, mas os valores s√£o muito diferentes das leituras dos sensores.  Para n√£o perder tempo pensando no que eles significam, n√≥s os removemos.  Se voc√™ observar a distribui√ß√£o de valores para cada caracter√≠stica (S1-S4), as distribui√ß√µes s√£o cont√≠nuas para S1, S2 e S4 e discretas para S3.  Al√©m disso, se voc√™ observar a distribui√ß√£o conjunta de S2 e S4, elas s√£o inversamente proporcionais. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/69b/82b/cde/69b82bcdecdfca69128d88673b0518b4.jpg"></div><br>  Embora um desvio de uma depend√™ncia direta possa indicar um erro, n√£o verificaremos isso, mas simplesmente removeremos o S4. <br><br>  Mais uma vez, processamos o conjunto de dados.  Deixe S1, S2 e S3.  Escale S1 e S2 com StandardScaler (subtra√≠mos a m√©dia e dividimos pelo desvio padr√£o), convertemos S3 em OHE (One Hot Encoding).  Costuramos leituras de todos os componentes da instala√ß√£o em uma linha.  Total de 89 recursos.  2 * 7 = 14 - leituras S1 e S2 para 7 componentes e 75 valores √∫nicos de R3.  Apenas 56 mil dessas linhas. <br><br>  Carregue o arquivo com erros. <br><br><pre> <code class="python hljs">dfc=pd.read_csv(<span class="hljs-string"><span class="hljs-string">'plant_12c.csv'</span></span>,names=[<span class="hljs-string"><span class="hljs-string">'Start Time'</span></span>, <span class="hljs-string"><span class="hljs-string">'End Time'</span></span>,<span class="hljs-string"><span class="hljs-string">'Type'</span></span>]) dfc.head()</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3ad/419/e50/3ad419e50ac870a71c153b523a22bfed.jpg"></div><br>  Antes de tentar esses algoritmos em nosso conjunto de dados, vou me permitir outra pequena digress√£o.  Voc√™ precisa ser testado.  Para isso, prop√µe-se tomar a hora de in√≠cio do erro e a hora de t√©rmino.  E todas as indica√ß√µes dentro deste intervalo s√£o consideradas anormais e fora do normal.  Essa abordagem tem muitas desvantagens.  Mas, especialmente, um comportamento anormal provavelmente ocorre antes que o erro seja corrigido.  Por fidelidade, vamos mudar a janela de anomalias meia hora atr√°s no tempo.  Avaliaremos a medida F1, precis√£o e recall. <br><br>  C√≥digo para distinguir recursos e determinar a qualidade do modelo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_and_preprocess</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(plant_num)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-comment"><span class="hljs-comment">#      ,       dfa=pd.read_csv('plant_{}a.csv'.format(plant_num),names=['Component number','Time','S1','S2','S3','S4','S1ref','S2ref','S3ref','S4ref'])   dfc=pd.read_csv('plant_{}c.csv'.format(plant_num),names=['Start Time','End Time','Type']).drop(0,axis=0)   N_comp=len(dfa['Component number'].unique())   #  15    dfa['Time']=pd.to_datetime(dfa['Time']).dt.round('15min')   #  6    (  ,    )   dfc=dfc[dfc['Type']!=6]   dfc['Start Time']=pd.to_datetime(dfc['Start Time'])   dfc['End Time']=pd.to_datetime(dfc['End Time'])   #      ,       OHE  3-    dfa=pd.concat([dfa.groupby('Time').nth(i)[['S1','S2','S3']].rename(columns={"S1":"S1_{}".format(i),"S2":"S2_{}".format(i),"S3":"S3_{}".format(i)}) for i in range(N_comp)],axis=1).dropna().reset_index()   for k in range(N_comp):       dfa=pd.concat([dfa.drop('S3_'+str(k),axis=1),pd.get_dummies(dfa['S3_'+str(k)],prefix='S3_'+str(k))],axis=1).reset_index(drop=True)   #          df_train,df_test=train_test_split(dfa,test_size=0.25,shuffle=False)   cols_to_scale=df_train.filter(regex='S[1,2]').columns   scaler=preprocessing.StandardScaler().fit(df_train[cols_to_scale])   df_train[cols_to_scale]=scaler.transform(df_train[cols_to_scale])   df_test[cols_to_scale]=scaler.transform(df_test[cols_to_scale])   return df_train,df_test,dfc #       def get_true_labels(measure_times,dfc,shift_delta):   idxSet=set()   dfc['Start Time']-=pd.Timedelta(minutes=shift_delta)   dfc['End Time']-=pd.Timedelta(minutes=shift_delta)   for idx,mes_time in tqdm_notebook(enumerate(measure_times),total=measure_times.shape[0]):       intersect=np.array(dfc['Start Time']&lt;mes_time).astype(int)*np.array(dfc['End Time']&gt;mes_time).astype(int)       idxs=np.where(intersect)[0]       if idxs.shape[0]:           idxSet.add(idx)   dfc['Start Time']+=pd.Timedelta(minutes=shift_delta)   dfc['End Time']+=pd.Timedelta(minutes=shift_delta)   true_labels=pd.Series(index=measure_times.index)   true_labels.iloc[list(idxSet)]=1   true_labels.fillna(0,inplace=True)   return true_labels #          def check_model(model,df_train,df_test,filt='S[123]'):   model.fit(df_train.drop('Time',axis=1).filter(regex=(filt)))   y_preds = pd.Series(model.predict(df_test.drop(['Time','Label'],axis=1).filter(regex=(filt)))).map({-1:1,1:0})   print('F1 score: {:.3f}'.format(f1_score(df_test['Label'],y_preds)))   print('Precision score: {:.3f}'.format(precision_score(df_test['Label'],y_preds)))   print('Recall score: {:.3f}'.format(recall_score(df_test['Label'],y_preds)))   score = model.decision_function(df_test.drop(['Time','Label'],axis=1).filter(regex=(filt)))   sns.distplot(score[df_test['Label']==0])   sns.distplot(score[df_test['Label']==1]) df_train,df_test,anomaly_times=load_and_preprocess(12) df_test['Label']=get_true_labels(df_test['Time'],dfc,30)</span></span></code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/50b/6f2/be9/50b6f2be9c3220853e92461805030e0b.jpg"></div>  <i>Resultados do teste para algoritmos simples de pesquisa de anomalias no conjunto de dados do PHM 2015 Data Challenge</i> <br><br>  Voltar para os algoritmos.  Vamos tentar nossos SVM de uma classe SVM (OCSVM), IsolationForest (IF), EllipticEnvelope (EE) e LocalOutlierFactor (LOF).  Para come√ßar, n√£o definiremos nenhum par√¢metro.  Observo que o LOF pode funcionar em dois modos.  Se novidade = Falso for capaz de procurar anomalias apenas no conjunto de treinamento (s√≥ existe fit_predict), se Verdadeiro, o objetivo √© procurar anomalias fora do conjunto de treinamento (pode caber e prever separadamente).  O IF possui um modo de comportamento antigo e novo.  N√≥s usamos novo.  Ele d√° melhores resultados. <br><br>  O OCSVM detecta bem as anomalias, mas h√° muitos falsos positivos.  Para outros m√©todos, o resultado √© ainda pior. <br><br>  Mas suponha que sabemos a porcentagem de anomalias nos dados.  No nosso caso, 27%.  O OCSVM possui nu - a estimativa superior para a porcentagem de erros e a menor para a porcentagem de vetores de suporte.  Outros m√©todos de contamina√ß√£o t√™m uma porcentagem de erros de dados.  Nos m√©todos IF e LOF, √© determinado automaticamente, enquanto para OCSVM e EE √© definido como 0,1 por padr√£o.  Vamos tentar definir a contamina√ß√£o (nu) para 0,27.  Agora, o melhor resultado para EE. <br><br>  C√≥digo para verifica√ß√£o de modelos: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">check_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model,df_train,df_test,filt=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'S[123]'</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span>   model_type,model = model   model.fit(df_train.drop(<span class="hljs-string"><span class="hljs-string">'Time'</span></span>,axis=<span class="hljs-number"><span class="hljs-number">1</span></span>).filter(regex=(filt)))   y_preds = pd.Series(model.predict(df_test.drop([<span class="hljs-string"><span class="hljs-string">'Time'</span></span>,<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],axis=<span class="hljs-number"><span class="hljs-number">1</span></span>).filter(regex=(filt)))).map({<span class="hljs-number"><span class="hljs-number">-1</span></span>:<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>})   print(<span class="hljs-string"><span class="hljs-string">'F1 score for {}: {:.3f}'</span></span>.format(model_type,f1_score(df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],y_preds)))   print(<span class="hljs-string"><span class="hljs-string">'Precision score for {}: {:.3f}'</span></span>.format(model_type,precision_score(df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],y_preds)))   print(<span class="hljs-string"><span class="hljs-string">'Recall score for {}: {:.3f}'</span></span>.format(model_type,recall_score(df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],y_preds)))   score = model.decision_function(df_test.drop([<span class="hljs-string"><span class="hljs-string">'Time'</span></span>,<span class="hljs-string"><span class="hljs-string">'Label'</span></span>],axis=<span class="hljs-number"><span class="hljs-number">1</span></span>).filter(regex=(filt)))   sns.distplot(score[df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>]==<span class="hljs-number"><span class="hljs-number">0</span></span>])   sns.distplot(score[df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>]==<span class="hljs-number"><span class="hljs-number">1</span></span>])   plt.title(<span class="hljs-string"><span class="hljs-string">'Decision score distribution for {}'</span></span>.format(model_type))   plt.show()</code> </pre> <br>  √â interessante observar a distribui√ß√£o de indicadores de anomalia para diferentes m√©todos.  Pode-se observar que o LOF n√£o funciona bem para esses dados.  O EE tem pontos que o algoritmo considera extremamente anormais.  No entanto, pontos normais caem l√°.  O IsoFor e o OCSVM mostram que a escolha do limiar de corte (contamina√ß√£o / nu) √© importante, o que alterar√° a troca entre precis√£o e perfei√ß√£o. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a9d/0c8/80f/a9d0c880f36fe37f1de6c9290b8cccc7.png"></div><br>  √â l√≥gico que as leituras dos sensores tenham uma distribui√ß√£o pr√≥xima da normal, perto de valores estacion√°rios.  Se realmente tivermos uma amostra de teste rotulada e, de prefer√™ncia, tamb√©m uma de valida√ß√£o, o valor da contamina√ß√£o poder√° ser colorido.  A pr√≥xima pergunta √©: quais erros s√£o mais orientados: falso positivo ou falso negativo? <br><br>  O resultado do LOF √© muito baixo.  N√£o √© muito impressionante.  Mas lembre-se de que as vari√°veis ‚Äã‚ÄãOHE v√£o para a entrada junto com as vari√°veis ‚Äã‚Äãtransformadas pelo StandardScaler.  E as dist√¢ncias padr√£o s√£o euclidianas.  Mas se voc√™ contar apenas as vari√°veis ‚Äã‚Äãde acordo com S1 e S2, a situa√ß√£o ser√° corrigida e o resultado ser√° compar√°vel com outros m√©todos.  √â importante, no entanto, entender que um dos principais par√¢metros dos classificadores de m√©tricas listados √© o n√∫mero de vizinhos.  Isso afeta significativamente a qualidade e deve ser ajustado.  A m√©trica de dist√¢ncia em si tamb√©m seria interessante de entender. <br><br>  Agora tente combinar os dois modelos.  No in√≠cio de um, removemos as anomalias do conjunto de treinamento.  E ent√£o treinaremos o OCSVM em um conjunto de treinamento "mais limpo".  De acordo com os resultados anteriores, observamos a maior completude em EE.  Limpamos a amostra de treinamento por meio de EE, treinamos OCSVM nele e obtemos F1 = 0,50, Precis√£o = 0,34, completude = 0,95.  N√£o √© impressionante.  Mas n√≥s apenas perguntamos nu = 0,27.  E os dados que temos s√£o mais ou menos "limpos".  Se assumirmos que a plenitude do EE na amostra de treinamento √© a mesma, 5% dos erros permanecer√£o.  N√≥s estabelecemos tal nu e obtemos F1 = 0,69, Precis√£o = 0,59, completude = 0,82.  √ìtimo.  √â importante observar que em outros m√©todos essa combina√ß√£o n√£o funcionar√°, pois implica que o n√∫mero de anomalias no conjunto de treinamento e o n√∫mero do teste s√£o os mesmos.  Ao treinar esses m√©todos em um conjunto de dados de treinamento puro, voc√™ precisar√° especificar menos contamina√ß√£o do que em dados reais e n√£o pr√≥ximo de zero, mas √© melhor selecion√°-lo para valida√ß√£o cruzada. <br><br>  √â interessante observar o resultado da pesquisa na sequ√™ncia de indica√ß√µes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a2/0c5/26d/2a20c526d944b55116f3fcd6af064eab.png"></div><br>  A figura mostra um segmento das leituras do primeiro e do segundo sensores para 7 componentes.  Na legenda, a cor dos erros correspondentes (o in√≠cio e o fim s√£o mostrados por linhas verticais da mesma cor).  Os pontos indicam as previs√µes: verde - previs√µes verdadeiras, vermelho - falso positivo, roxo - falso negativo.  Pode-se ver pela figura que √© dif√≠cil determinar visualmente o tempo de erro, e o algoritmo lida com essa tarefa muito bem.  Embora seja importante entender que as leituras do terceiro sensor n√£o s√£o fornecidas aqui.  Al√©m disso, existem leituras de falsos positivos ap√≥s o final do erro.  I.e.  o algoritmo v√™ que tamb√©m h√° valores errados e marcamos essa √°rea como livre de erros.  O lado direito da figura mostra a √°rea antes do erro, que marcamos como incorreta (meia hora antes do erro), que foi reconhecida como livre de erros, o que leva a erros de modelo falso-negativos.  No centro da figura, uma pe√ßa coerente √© reconhecida, reconhecida como um erro.  A conclus√£o pode ser tirada da seguinte maneira: ao resolver o problema de procurar anomalias, voc√™ precisa interagir de perto com os engenheiros que entendem a ess√™ncia dos sistemas cuja sa√≠da voc√™ precisa prever, pois a verifica√ß√£o dos algoritmos usados ‚Äã‚Äãna marca√ß√£o n√£o reflete completamente a realidade e n√£o simula as condi√ß√µes nas quais esses algoritmos poderiam ser usado. <br><br>  C√≥digo para plotar o gr√°fico: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_time_course</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df_test,dfc,y_preds,start,end,vert_shift=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">4</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span>   plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>))   cols=df_train.filter(regex=(<span class="hljs-string"><span class="hljs-string">'S[12]'</span></span>)).columns   add=<span class="hljs-number"><span class="hljs-number">0</span></span>   preds_idx=y_preds.iloc[start:end][y_preds[<span class="hljs-number"><span class="hljs-number">0</span></span>]==<span class="hljs-number"><span class="hljs-number">1</span></span>].index   true_idx=df_test.iloc[start:end,:][df_test[<span class="hljs-string"><span class="hljs-string">'Label'</span></span>]==<span class="hljs-number"><span class="hljs-number">1</span></span>].index   tp_idx=set(true_idx.values).intersection(set(preds_idx.values))   fn_idx=set(true_idx.values).difference(set(preds_idx.values))   fp_idx=set(preds_idx.values).difference(set(true_idx.values))   xtime=df_test[<span class="hljs-string"><span class="hljs-string">'Time'</span></span>].iloc[start:end]   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> cols:       plt.plot(xtime,df_test[col].iloc[start:end]+add)       plt.scatter(xtime.loc[tp_idx].values,df_test.loc[tp_idx,col]+add,color=<span class="hljs-string"><span class="hljs-string">'green'</span></span>)       plt.scatter(xtime.loc[fn_idx].values,df_test.loc[fn_idx,col]+add,color=<span class="hljs-string"><span class="hljs-string">'violet'</span></span>)       plt.scatter(xtime.loc[fp_idx].values,df_test.loc[fp_idx,col]+add,color=<span class="hljs-string"><span class="hljs-string">'red'</span></span>)       add+=vert_shift   failures=dfc[(dfc[<span class="hljs-string"><span class="hljs-string">'Start Time'</span></span>]&gt;xtime.iloc[<span class="hljs-number"><span class="hljs-number">0</span></span>])&amp;(dfc[<span class="hljs-string"><span class="hljs-string">'Start Time'</span></span>]&lt;xtime.iloc[<span class="hljs-number"><span class="hljs-number">-1</span></span>])]   unique_fails=np.sort(failures[<span class="hljs-string"><span class="hljs-string">'Type'</span></span>].unique())   colors=np.array([np.random.rand(<span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> fail <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> unique_fails])   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> fail_idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> failures.index:       c=colors[np.where(unique_fails==failures.loc[fail_idx,<span class="hljs-string"><span class="hljs-string">'Type'</span></span>])[<span class="hljs-number"><span class="hljs-number">0</span></span>]][<span class="hljs-number"><span class="hljs-number">0</span></span>]       plt.axvline(failures.loc[fail_idx,<span class="hljs-string"><span class="hljs-string">'Start Time'</span></span>],color=c)       plt.axvline(failures.loc[fail_idx,<span class="hljs-string"><span class="hljs-string">'End Time'</span></span>],color=c)   leg=plt.legend(unique_fails)   <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(unique_fails)):       leg.legendHandles[i].set_color(colors[i])</code> </pre> <br>  Se a porcentagem de anomalias for inferior a 5% e / ou estiverem mal separadas dos indicadores "normais", os m√©todos acima funcionar√£o mal e vale a pena usar algoritmos baseados em redes neurais.  No caso mais simples, seriam: <br><br><ul><li>  codificadores autom√°ticos (um erro alto de um codificador autom√°tico treinado sinalizar√° uma anormalidade na leitura); </li><li>  redes recorrentes (aprendendo por sequ√™ncia para prever a √∫ltima leitura. Se a diferen√ßa for grande - o ponto √© anormal). </li></ul><br>  Separadamente, vale a pena observar as especificidades do trabalho com s√©ries temporais.  √â importante entender que a maioria dos algoritmos acima (exceto auto-codificadores e isolamento de florestas) provavelmente fornecer√° pior qualidade ao adicionar recursos de defasagem (leituras de pontos anteriores no tempo). <br><br>  Vamos tentar adicionar recursos de lag no nosso exemplo.  A descri√ß√£o da competi√ß√£o diz que os valores 3 horas antes do erro n√£o est√£o relacionados com o erro de forma alguma.  Em seguida, adicione os sinais em 3 horas.  Total de 259 sinais. <br><br>  Como resultado, os resultados para o OCSVM e o IsolationForest permaneceram praticamente inalterados, enquanto os do Elliptic Envelope e LOF ca√≠ram. <br><br>  Para usar informa√ß√µes sobre a din√¢mica do sistema, auto-codificadores com redes neurais recorrentes ou convolucionais devem ser usados.  Ou, por exemplo, uma combina√ß√£o de codificadores autom√°ticos, informa√ß√µes de compacta√ß√£o e abordagens convencionais para procurar anomalias com base em informa√ß√µes compactadas.  A abordagem inversa tamb√©m parece promissora.  Triagem prim√°ria dos pontos mais incomuns por algoritmos padr√£o e, em seguida, treinando o codificador autom√°tico j√° em dados mais limpos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/340/9e8/dbc/3409e8dbcc5e9bcac2a1acb08bc7d146.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><i>Fonte</i></a> <br><br>  H√° um conjunto de t√©cnicas para trabalhar com s√©ries temporais unidimensionais.  Todos eles t√™m como objetivo prever leituras futuras, e os pontos que divergem da previs√£o s√£o considerados anomalias. <br><br><h2>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Modelo de Holt-Winters</a> </h2><br>  Suaviza√ß√£o exponencial tripla, divide a s√©rie em 3 componentes: n√≠vel, tend√™ncia e sazonalidade.  Por conseguinte, se a s√©rie for apresentada neste formul√°rio, o m√©todo funcionar√° bem.  O Profeta do Facebook opera com um princ√≠pio semelhante, mas avalia os pr√≥prios componentes de uma maneira diferente.  Mais detalhes podem ser lidos, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br><h2>  S (ARIMA) </h2><br>  Nesse m√©todo, o modelo preditivo baseia-se na regress√£o autom√°tica e na m√©dia m√≥vel.  Se estamos falando sobre a expans√£o de S (ARIMA), isso nos permite avaliar a sazonalidade.  Leia mais sobre a abordagem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br><h2>  Outras abordagens preditivas de servi√ßo </h2><br>  Quando se trata de s√©ries temporais e h√° informa√ß√µes sobre os tempos de ocorr√™ncia de erros, voc√™ pode aplicar m√©todos de ensino com um professor.  Al√©m da necessidade de dados marcados, neste caso, √© importante entender que a previs√£o de erros depender√° da natureza do erro.  Se houver muitos erros e de natureza diferente, provavelmente ser√° necess√°rio prever cada um separadamente, o que exigir√° ainda mais dados rotulados, mas as perspectivas ser√£o mais atraentes. <br><br>  Existem maneiras alternativas de usar o aprendizado de m√°quina na manuten√ß√£o preditiva.  Por exemplo, prever uma falha do sistema nos pr√≥ximos N dias (tarefa de classifica√ß√£o).  √â importante entender que tal abordagem exige que a ocorr√™ncia de um erro na opera√ß√£o do sistema seja precedida por um per√≠odo de degrada√ß√£o (n√£o necessariamente gradual).  Nesse caso, a abordagem mais bem-sucedida parece ser o uso de redes neurais com camadas convolucionais e / ou recorrentes.  Separadamente, vale a pena mencionar m√©todos para o aumento de s√©ries temporais.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Duas abordagens</a> me parecem as mais interessantes e ao mesmo tempo simples: <br><br><ul><li>  a parte cont√≠nua da linha √© selecionada (por exemplo, 70% e o restante √© removido) e esticada at√© o tamanho original </li><li>  uma por√ß√£o cont√≠nua da linha (por exemplo, 20%) √© selecionada e esticada ou comprimida.  Depois disso, a linha inteira √© compactada ou esticada de acordo com o tamanho original. </li></ul><br>  H√° tamb√©m uma op√ß√£o para prever a vida √∫til restante do sistema (tarefa de regress√£o).  Aqui podemos distinguir uma abordagem separada: a previs√£o n√£o √© da vida √∫til, mas dos par√¢metros de distribui√ß√£o Weibull. <br><br>  Voc√™ pode ler sobre a distribui√ß√£o em si <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> sobre seu uso em conjunto com malhas recorrentes.  Essa distribui√ß√£o possui dois par√¢metros Œ± e Œ≤.  Œ± indica quando o evento ocorrer√° e Œ≤ indica a confian√ßa do algoritmo.  Embora a aplica√ß√£o dessa abordagem seja promissora, surgem dificuldades no treinamento da rede neural nesse caso, uma vez que √© mais f√°cil para o algoritmo ser inseguro a princ√≠pio do que prever uma vida √∫til adequada. <br><br>  Separadamente, vale ressaltar a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">regress√£o de Cox</a> .  Permite prever a toler√¢ncia a falhas do sistema para cada momento ap√≥s o diagn√≥stico, apresentando-o como um produto de duas fun√ß√µes.  Uma fun√ß√£o √© a degrada√ß√£o do sistema, independente de seus par√¢metros, ou seja,  comum a esses sistemas.  E o segundo √© uma depend√™ncia exponencial dos par√¢metros de um sistema espec√≠fico.  Portanto, para uma pessoa, existe uma fun√ß√£o comum associada ao envelhecimento, mais ou menos a mesma para todos.  Mas a deteriora√ß√£o da sa√∫de tamb√©m est√° associada ao estado dos √≥rg√£os internos, que √© diferente para todos. <br><br>  Espero que agora voc√™ saiba um pouco mais sobre manuten√ß√£o preditiva.  Estou certo de que voc√™ ter√° perguntas sobre os m√©todos de aprendizado de m√°quina mais frequentemente usados ‚Äã‚Äãpara esta tecnologia.  Ficarei feliz em responder a cada um deles nos coment√°rios.  Se voc√™ est√° interessado em n√£o apenas perguntar sobre o que est√° escrito, mas quer fazer algo semelhante, nossa equipe do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CleverDATA</a> est√° sempre satisfeita com profissionais talentosos e entusiasmados. <br><br><div class="spoiler">  <b class="spoiler_title">Existem vagas?</b>  <b class="spoiler_title">Claro!</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Desenvolvedor Java (Big Data)</a> </li></ul></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt447190/">https://habr.com/ru/post/pt447190/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt447178/index.html">5 oportunidades efetivas para o uso da tecnologia de minera√ß√£o de processos</a></li>
<li><a href="../pt447180/index.html">Vis√£o geral e compara√ß√£o de controladores de ingresso para Kubernetes</a></li>
<li><a href="../pt447182/index.html">Sistemas operacionais: tr√™s pe√ßas f√°ceis. Parte 3: API do processo (tradu√ß√£o)</a></li>
<li><a href="../pt447184/index.html">O que √© a oferta inicial de troca (IEO) e como ela √© diferente da OIC?</a></li>
<li><a href="../pt447186/index.html">Como lan√ßar um prot√≥tipo de ML em um dia. Relat√≥rio Yandex.Taxi</a></li>
<li><a href="../pt447192/index.html">Que papel a tecnologia pode desempenhar na arte antiga da mistura de especiarias?</a></li>
<li><a href="../pt447194/index.html">Recursos de renderiza√ß√£o no Metro: Exodus c raytracing</a></li>
<li><a href="../pt447196/index.html">7. Introdu√ß√£o ao Ponto de Verifica√ß√£o R80.20. Controle de acesso</a></li>
<li><a href="../pt447198/index.html">Miss√£o lunar "Bereshit": acidente de pouso-queda na lua</a></li>
<li><a href="../pt447204/index.html">17 de abril: Palestra aberta "O caminho do desenvolvedor de jogos: da id√©ia ao lan√ßamento" e uma biblioteca de jogos na Escola Superior de Direito</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñ§ ü§æüèΩ üë¥üèª Modellierungserfahrung vom Computer Vision Mail.ru-Team ‚úåüèæ üëäüèΩ üí¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mein Name ist Eduard Tyantov, ich leite das Computer Vision-Team bei Mail.ru Group. In den letzten Jahren unseres Bestehens hat unser Team Dutzende vo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Modellierungserfahrung vom Computer Vision Mail.ru-Team</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/460307/"><img src="https://habrastorage.org/webt/zz/gc/py/zzgcpycxxdaz-0a657wzkvjlvos.jpeg"><br><br>  Mein Name ist Eduard Tyantov, ich leite das Computer Vision-Team bei Mail.ru Group.  In den letzten Jahren unseres Bestehens hat unser Team Dutzende von Computer-Vision-Problemen gel√∂st. Heute werde ich Ihnen erl√§utern, mit welchen Methoden wir erfolgreich Modelle f√ºr maschinelles Lernen erstellen, die f√ºr eine Vielzahl von Aufgaben geeignet sind.  Ich werde Tricks vorstellen, die das Modell in allen Phasen beschleunigen k√∂nnen: Festlegen einer Aufgabe, Vorbereiten von Daten, Schulung und Bereitstellung in der Produktion. <br><a name="habracut"></a><br><h2>  Computer Vision bei Mail.ru </h2><br>  Was ist Computer Vision in Mail.ru und welche Projekte wir durchf√ºhren?  Wir bieten L√∂sungen f√ºr unsere Produkte wie Mail, Mail.ru Cloud (eine Anwendung zum Speichern von Fotos und Videos), Vision (B2B-L√∂sungen basierend auf Computer Vision) und andere.  Ich werde einige Beispiele geben. <br><br>  Die Cloud (dies ist unser erster und Hauptkunde) enth√§lt 60 Milliarden Fotos.  Wir entwickeln verschiedene Funktionen, die auf maschinellem Lernen basieren, f√ºr ihre intelligente Verarbeitung, z. B. Gesichtserkennung und Besichtigung (dazu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gibt es einen separaten Beitrag</a> ).  Alle Benutzerfotos werden durch Erkennungsmodelle gef√ºhrt, mit denen Sie eine Suche und Gruppierung nach Personen, Tags, besuchten St√§dten und L√§ndern usw. organisieren k√∂nnen. <br><br><img src="https://habrastorage.org/webt/dc/ls/ug/dclsugao8xumevprode0ift5dxq.jpeg"><img src="https://habrastorage.org/webt/zr/bo/rd/zrbordgq4zygrzpzvmsg5x0nt6i.jpeg"><br><br>  F√ºr Mail haben wir OCR - Erkennung von Text aus einem Bild durchgef√ºhrt.  Heute erz√§hle ich Ihnen etwas mehr √ºber ihn. <br><br>  Bei B2B-Produkten erkennen und z√§hlen wir Personen in Warteschlangen.  Zum Beispiel gibt es eine Warteschlange f√ºr den Skilift, und Sie m√ºssen berechnen, wie viele Personen sich darin befinden.  Um die Technologie und das Spiel zu testen, haben wir zun√§chst einen Prototyp im Speisesaal des B√ºros installiert.  Es gibt mehrere Kassen und dementsprechend mehrere Warteschlangen, und wir berechnen anhand des Modells anhand mehrerer Kameras (eine f√ºr jede Warteschlange), wie viele Personen sich in den Warteschlangen befinden und wie viele ungef√§hr Minuten in jeder Warteschlange verbleiben.  Auf diese Weise k√∂nnen wir die Linien im Esszimmer besser ausbalancieren. <br><br><img src="https://habrastorage.org/webt/yr/yq/hb/yryqhbu5zqhxm_fozg-4ygkz6i4.jpeg"><br><br><h2>  Erkl√§rung des Problems </h2><br>  Beginnen wir mit dem kritischen Teil jeder Aufgabe - ihrer Formulierung.  Fast jede ML-Entwicklung dauert mindestens einen Monat (dies ist bestenfalls, wenn Sie wissen, was zu tun ist) und in den meisten F√§llen mehrere Monate.  Wenn die Aufgabe falsch oder ungenau ist, besteht am Ende der Arbeit eine gro√üe Chance, vom Produktmanager etwas im Geiste zu h√∂ren: ‚ÄûAlles ist falsch.  Das ist nicht gut  Ich wollte etwas anderes. "  Um dies zu verhindern, m√ºssen Sie einige Schritte ausf√ºhren.  Was ist das Besondere an ML-basierten Produkten?  Im Gegensatz zur Aufgabe der Entwicklung einer Site kann die Aufgabe des maschinellen Lernens nicht allein mit Text formalisiert werden.  Dar√ºber hinaus scheint es einer unvorbereiteten Person in der Regel, dass alles bereits offensichtlich ist und es einfach erforderlich ist, alles ‚Äûsch√∂n‚Äú zu machen.  Aber welche kleinen Details gibt es, der Task-Manager wei√ü vielleicht nicht einmal, hat noch nie dar√ºber nachgedacht und wird nicht nachdenken, bis er das Endprodukt sieht und sagt: "Was haben Sie getan?" <br><br><h2>  Die Probleme </h2><br>  Lassen Sie uns anhand eines Beispiels verstehen, welche Probleme auftreten k√∂nnen.  Angenommen, Sie haben eine Gesichtserkennungsaufgabe.  Sie erhalten es, freuen sich und rufen Ihre Mutter an: "Hurra, eine interessante Aufgabe!"  Aber ist es m√∂glich, direkt zusammenzubrechen und damit zu beginnen?  Wenn Sie dies tun, k√∂nnen Sie am Ende √úberraschungen erwarten: <br><br><ul><li>  Es gibt verschiedene Nationalit√§ten.  Zum Beispiel gab es keine Asiaten oder sonst jemanden im Datensatz.  Ihr Modell wei√ü dementsprechend √ºberhaupt nicht, wie es sie erkennt, und das Produkt ben√∂tigt es.  Oder umgekehrt, Sie haben zus√§tzliche drei Monate f√ºr die √úberarbeitung aufgewendet, und das Produkt wird nur Kaukasier haben, und dies war nicht erforderlich. <br></li><li>  Es gibt Kinder.  F√ºr kinderlose V√§ter wie mich sind alle Kinder auf einem Gesicht.  Ich bin absolut einverstanden mit dem Modell, wenn sie alle Kinder zu einem Cluster schickt - es ist wirklich unklar, wie sich die Mehrheit der Kinder unterscheidet!  ;) Aber Menschen mit Kindern haben eine ganz andere Meinung.  Normalerweise sind sie auch Ihre F√ºhrer.  Oder es gibt immer noch lustige Erkennungsfehler, wenn der Kopf des Kindes erfolgreich mit dem Ellbogen oder dem Kopf eines kahlen Mannes verglichen wird (wahre Geschichte). <br></li><li>  Was mit gemalten Zeichen zu tun ist, ist im Allgemeinen unklar.  Muss ich sie erkennen oder nicht? <br></li></ul><br>  Solche Aspekte der Aufgabe sind zu Beginn sehr wichtig zu identifizieren.  Daher m√ºssen Sie von Anfang an ‚Äûan den Daten‚Äú arbeiten und mit dem Manager kommunizieren.  M√ºndliche Erkl√§rungen k√∂nnen nicht akzeptiert werden.  Es ist notwendig, die Daten zu betrachten.  Es ist w√ºnschenswert, aus der gleichen Verteilung, auf der das Modell arbeiten wird. <br><br>  Im Idealfall wird im Verlauf dieser Diskussion ein Testdatensatz abgerufen, auf dem Sie das Modell endg√ºltig ausf√ºhren und pr√ºfen k√∂nnen, ob es wie vom Manager gew√ºnscht funktioniert.  Es ist ratsam, dem Manager selbst einen Teil des Testdatensatzes zu geben, damit Sie keinen Zugriff darauf haben.  Da Sie dieses Testset problemlos neu trainieren k√∂nnen, sind Sie ein ML-Entwickler! <br><br>  Das Setzen einer Aufgabe in ML ist eine st√§ndige Arbeit zwischen einem Produktmanager und einem Spezialisten in ML.  Selbst wenn Sie die Aufgabe zun√§chst gut eingestellt haben, treten im Laufe der Entwicklung des Modells immer mehr neue Probleme auf, neue Funktionen, die Sie √ºber Ihre Daten lernen.  All dies muss st√§ndig mit dem Manager besprochen werden.  Gute Manager senden ihren ML-Teams immer, dass sie Verantwortung √ºbernehmen und dem Manager bei der Festlegung von Aufgaben helfen m√ºssen. <br><br>  Warum so?  Maschinelles Lernen ist ein ziemlich neuer Bereich.  Manager haben (oder haben wenig) Erfahrung mit der Verwaltung solcher Aufgaben.  Wie oft lernen Menschen, neue Probleme zu l√∂sen?  Auf die Fehler.  Wenn Sie nicht m√∂chten, dass Ihr Lieblingsprojekt zum Fehler wird, m√ºssen Sie sich engagieren und Verantwortung √ºbernehmen, dem Produktmanager beibringen, die Aufgabe richtig einzustellen, Checklisten und Richtlinien zu entwickeln.  das alles hilft sehr.  Jedes Mal, wenn ich mich abziehe (oder jemand von meinen Kollegen mich abzieht), wenn eine neue interessante Aufgabe eintrifft, rennen wir los, um sie zu erledigen.  Alles, was ich dir gerade gesagt habe, vergesse ich selbst.  Daher ist es wichtig, eine Checkliste zu haben, um sich selbst zu √ºberpr√ºfen. <br><br><h2>  Daten </h2><br>  Daten sind in ML sehr wichtig.  F√ºr mehr Lernen ist es umso besser, je mehr Daten Sie Modelle f√ºttern.  Das blaue Diagramm zeigt, dass sich Deep-Learning-Modelle normalerweise erheblich verbessern, wenn Daten hinzugef√ºgt werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1x/wf/bb/1xwfbbc7-os0p9wjc8y_2iiyn10.jpeg"></div><br>  Und die "alten" (klassischen) Algorithmen k√∂nnen sich irgendwann nicht mehr verbessern. <br><br>  Normalerweise sind in ML Datens√§tze verschmutzt.  Sie wurden von Menschen markiert, die immer l√ºgen.  Assessoren sind oft unaufmerksam und machen viele Fehler.  Wir verwenden diese Technik: Wir nehmen die Daten, die wir haben, trainieren das Modell darauf und l√∂schen dann mit Hilfe dieses Modells die Daten und wiederholen den Zyklus erneut. <br><br>  Schauen wir uns das Beispiel derselben Gesichtserkennung genauer an.  Angenommen, wir haben VKontakte-Benutzeravatare heruntergeladen.  Zum Beispiel haben wir ein Benutzerprofil mit 4 Avataren.  Wir erkennen Gesichter auf allen 4 Bildern und durchlaufen das Gesichtserkennungsmodell.  So erhalten wir Einbettungen von Personen, mit deren Hilfe sie √§hnliche Personen in Gruppen (Cluster) ‚Äûkleben‚Äú k√∂nnen.  Als n√§chstes w√§hlen wir den gr√∂√üten Cluster aus, vorausgesetzt, die Avatare des Benutzers enthalten haupts√§chlich sein Gesicht.  Dementsprechend k√∂nnen wir alle anderen Gesichter (die Rauschen sind) auf diese Weise reinigen.  Danach k√∂nnen wir den Zyklus erneut wiederholen: Trainieren Sie das Modell f√ºr die bereinigten Daten und verwenden Sie es zum Bereinigen der Daten.  Sie k√∂nnen mehrmals wiederholen. <br><br>  Fast immer verwenden wir f√ºr ein solches Clustering CLink-Algorithmen.  Dies ist ein hierarchischer Clustering-Algorithmus, bei dem es sehr praktisch ist, einen Schwellenwert f√ºr das ‚ÄûKleben‚Äú √§hnlicher Objekte festzulegen (genau dies ist f√ºr die Reinigung erforderlich).  CLink erzeugt sph√§rische Cluster.  Dies ist wichtig, da wir h√§ufig den metrischen Raum dieser Einbettungen lernen.  Der Algorithmus hat eine Komplexit√§t von O (n <sup>2</sup> ), die im Prinzip ca. <br><br>  Manchmal ist es so schwierig, Daten abzurufen oder zu markieren, dass nichts mehr zu tun ist, sobald Sie mit der Generierung beginnen.  Mit dem generativen Ansatz k√∂nnen Sie eine gro√üe Datenmenge erzeugen.  Daf√ºr m√ºssen Sie aber etwas programmieren.  Das einfachste Beispiel ist OCR, Texterkennung auf Bildern.  Das Markup des Textes f√ºr diese Aufgabe ist extrem teuer und laut: Sie m√ºssen jede Zeile und jedes Wort hervorheben, den Text signieren und so weiter.  Assessoren (Markup-Personen) nehmen extrem lange hundert Seiten Text in Anspruch, und f√ºr die Schulung wird viel mehr ben√∂tigt.  Nat√ºrlich k√∂nnen Sie den Text irgendwie generieren und irgendwie ‚Äûverschieben‚Äú, damit das Modell daraus lernt. <br><br>  Wir haben selbst festgestellt, dass das beste und bequemste Toolkit f√ºr diese Aufgabe eine Kombination aus PIL, OpenCV und Numpy ist.  Sie haben alles f√ºr die Arbeit mit Text.  Sie k√∂nnen das Bild auf irgendeine Weise mit Text komplizieren, damit das Netzwerk nicht f√ºr einfache Beispiele umschult. <br><br><img src="https://habrastorage.org/webt/cv/zd/ib/cvzdibgjrtt_qnyro4u8-zcgdgw.png"><br><br>  Manchmal brauchen wir Objekte aus der realen Welt.  Zum Beispiel Waren in den Regalen.  Eines dieser Bilder wird automatisch generiert.  Denkst du links oder rechts? <br><br><img src="https://habrastorage.org/webt/os/py/gi/ospygi-cu95vtgblk8ekol86qak.jpeg"><br><br>  Tats√§chlich werden beide generiert.  Wenn Sie sich die kleinen Details nicht ansehen, werden Sie keine Unterschiede zur Realit√§t bemerken.  Wir machen das mit Blender (analog zu 3dmax). <br><br><img src="https://habrastorage.org/webt/wq/7i/hd/wq7ihd3zrqp0fevkbdylp96hm0m.jpeg"><br><br>  Der wichtigste Vorteil ist, dass es Open Source ist.  Es verf√ºgt √ºber eine hervorragende Python-API, mit der Sie Objekte direkt im Code platzieren, den Prozess konfigurieren und randomisieren und schlie√ülich ein vielf√§ltiges Dataset erhalten k√∂nnen. <br><br>  Zum Rendern wird Raytracing verwendet.  Dies ist ein ziemlich kostspieliger Vorgang, der jedoch zu einem Ergebnis mit ausgezeichneter Qualit√§t f√ºhrt.  Die wichtigste Frage: Woher bekommen Sie Modelle f√ºr Objekte?  In der Regel m√ºssen sie gekauft werden.  Aber wenn Sie ein armer Sch√ºler sind und mit etwas experimentieren m√∂chten, gibt es immer Str√∂me.  Es ist klar, dass Sie f√ºr die Produktion gerenderte Modelle bei jemandem kaufen oder bestellen m√ºssen. <br><br>  Das ist alles √ºber die Daten.  Fahren wir mit dem Lernen fort. <br><br><h2>  Metrisches Lernen </h2><br>  Das Ziel des metrischen Lernens besteht darin, das Netzwerk so zu trainieren, dass es √§hnliche Objekte in √§hnliche Regionen im eingebetteten metrischen Raum √ºbersetzt.  Ich werde noch einmal ein Beispiel mit den Sehensw√ºrdigkeiten geben, was insofern ungew√∂hnlich ist, als es im Wesentlichen eine Klassifizierungsaufgabe ist, aber f√ºr Zehntausende von Klassen.  Es scheint, warum hier metrisches Lernen, das in der Regel f√ºr Aufgaben wie die Gesichtserkennung geeignet ist?  Versuchen wir es herauszufinden. <br><br>  Wenn Sie beim Trainieren eines Klassifizierungsproblems, z. B. Softmax, Standardverluste verwenden, sind die Klassen im metrischen Raum gut voneinander getrennt, aber im Einbettungsraum k√∂nnen die Punkte verschiedener Klassen nahe beieinander liegen ... <br><br><img src="https://habrastorage.org/webt/od/fl/aq/odflaq4hgygf8vvrnftdrdeinh8.jpeg"><br><br>  Dies f√ºhrt zu potenziellen Fehlern bei der Verallgemeinerung  Ein geringf√ºgiger Unterschied in den Quelldaten kann das Klassifizierungsergebnis √§ndern.  Wir m√∂chten wirklich, dass die Punkte kompakter sind.  Hierzu werden verschiedene metrische Lerntechniken eingesetzt.  Zum Beispiel Center Loss, dessen Idee extrem einfach ist: Wir ziehen einfach Punkte zum Lernzentrum jeder Klasse zusammen, die schlie√ülich kompakter werden. <br><br><img src="https://habrastorage.org/webt/am/pf/nw/ampfnwjhkn4idpxob_tjpvg3sey.jpeg"><br><br>  Center Loss wird in Python buchst√§blich in 10 Zeilen programmiert, funktioniert sehr schnell und vor allem verbessert es die Qualit√§t der Klassifizierung, weil  Kompaktheit f√ºhrt zu einer besseren Verallgemeinerungsf√§higkeit. <br><br><h2>  Angular Softmax </h2><br>  Wir haben viele verschiedene metrische Lernmethoden ausprobiert und sind zu dem Schluss gekommen, dass Angular Softmax die besten Ergebnisse liefert.  In der Forschungsgemeinschaft gilt er auch als Stand der Technik. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ks/gx/ap/ksgxapfkweb9invhas0g2dz2w2s.jpeg"></div><br>  Schauen wir uns ein Beispiel f√ºr die Gesichtserkennung an.  Hier haben wir zwei Leute.  Wenn Sie den Standard-Softmax verwenden, wird eine Teilungsebene zwischen ihnen gezeichnet - basierend auf zwei Gewichtsvektoren.  Wenn wir die Norm 1 einbetten, liegen die Punkte auf dem Kreis, d.h.  auf der Kugel im n-dimensionalen Fall (Bild rechts). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/by/zf/a9/byzfa9okk0cry7vcx6vg4n3dsd8.jpeg"></div><br>  Dann k√∂nnen Sie sehen, dass der Winkel zwischen ihnen bereits f√ºr die Trennung der Klassen verantwortlich ist und optimiert werden kann.  Aber nur das ist nicht genug.  Wenn wir nur den Winkel optimieren, √§ndert sich die Aufgabe tats√§chlich nicht, weil  wir haben es einfach anders formuliert.  Ich erinnere mich, dass unser Ziel darin besteht, Cluster kompakter zu machen. <br><br>  In gewisser Weise ist es notwendig, einen gr√∂√üeren Winkel zwischen den Klassen zu fordern, um die Aufgabe des neuronalen Netzwerks zu erschweren.  Zum Beispiel so, dass sie denkt, dass der Winkel zwischen den Punkten einer Klasse gr√∂√üer ist als in der Realit√§t, so dass sie versucht, sie immer mehr zu komprimieren.  Dies wird erreicht, indem der Parameter m eingef√ºhrt wird, der die Differenz in den Kosinus der Winkel steuert. <br><br><img src="https://habrastorage.org/webt/lx/fk/xc/lxfkxcrdodlg-wpoasqxcws3gao.jpeg"><br><br>  Es gibt verschiedene Optionen f√ºr Angular Softmax.  Sie alle spielen mit der Tatsache, dass sie mit diesem Winkel multiplizieren oder addieren oder multiplizieren und addieren.  State-of-the-Art - ArcFace. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/_i/zw/ye_izwbkvqmr0-fxpxahc2uty6e.gif"></div><br>  Tats√§chlich ist dieser recht einfach in die Pipeline-Klassifizierung zu integrieren. <br><br><img src="https://habrastorage.org/webt/05/gi/vt/05givtsihtduioo9co9f0jzj5hk.jpeg"><br><br>  Schauen wir uns das Beispiel von Jack Nicholson an.  Wir f√ºhren sein Foto im Lernprozess durch das Raster.  Wir werden eingebettet, durchlaufen die lineare Ebene zur Klassifizierung und erhalten am Ausgang Punktzahlen, die den Grad der Zugeh√∂rigkeit zur Klasse widerspiegeln.  In diesem Fall hat Nicholsons Foto eine Geschwindigkeit von 20, die gr√∂√üte.  Gem√§√ü der Formel von ArcFace reduzieren wir die Geschwindigkeit von 20 auf 13 (nur f√ºr die Groundtruth-Klasse), was die Aufgabe f√ºr das neuronale Netzwerk kompliziert.  Dann machen wir alles wie gewohnt: Softmax + Cross Entropy. <br><br>  Insgesamt wird die √ºbliche lineare Ebene durch die ArcFace-Ebene ersetzt, die nicht in 10, sondern in 20 Zeilen geschrieben ist, aber hervorragende Ergebnisse und ein Minimum an Overhead f√ºr die Implementierung bietet.  Daher ist ArcFace f√ºr die meisten Aufgaben besser als die meisten anderen Methoden.  Es l√§sst sich perfekt in Klassifizierungsaufgaben integrieren und verbessert die Qualit√§t. <br><br><h2>  Lernen √ºbertragen </h2><br>  Das zweite, wor√ºber ich sprechen wollte, ist das Transferlernen - Verwenden eines vorab geschulten Netzwerks f√ºr eine √§hnliche Aufgabe zur Umschulung f√ºr eine neue Aufgabe.  Somit wird Wissen von einer Aufgabe zur anderen √ºbertragen. <br><br>  Wir haben nach Bildern gesucht.  Das Wesentliche der Aufgabe besteht darin, semantisch √§hnliche aus der Datenbank im Bild (Abfrage) zu erstellen. <br><br><img src="https://habrastorage.org/webt/hp/m-/x2/hpm-x27etg2zdagi9wupvgjdqtm.jpeg"><br><br>  Es ist logisch, ein Netzwerk zu verwenden, das bereits eine gro√üe Anzahl von Bildern untersucht hat - in ImageNet- oder OpenImages-Datens√§tzen, in denen sich Millionen von Bildern befinden, und unsere Daten zu trainieren. <br><br><img src="https://habrastorage.org/webt/fn/hq/c-/fnhqc-efmzfkuqmwocx_zy4wp1a.jpeg"><br><br>  Wir haben Daten f√ºr diese Aufgabe basierend auf der √Ñhnlichkeit von Bildern und Benutzerklicks gesammelt und 200.000 Klassen erhalten.  Nach dem Training mit ArFace haben wir das folgende Ergebnis erhalten. <br><br><img src="https://habrastorage.org/webt/da/gu/dd/daguddqmsfbsvj9rdrix-slta4u.jpeg"><br><br>  Im obigen Bild sehen wir, dass f√ºr den angeforderten Pelikan auch Spatzen in das Problem geraten sind.  Das hei√üt,  Einbettung stellte sich semantisch als wahr heraus - es ist ein Vogel, aber rassentreu.  Das nervigste ist, dass das urspr√ºngliche Modell, mit dem wir umgeschult haben, diese Klassen kannte und sie perfekt unterschied.  Hier sehen wir den Effekt, der allen neuronalen Netzen gemeinsam ist und als katastrophales Vergessen bezeichnet wird.  Das hei√üt, w√§hrend der Umschulung vergisst das Netzwerk die vorherige Aufgabe, manchmal sogar vollst√§ndig.  Genau dies verhindert bei dieser Aufgabe eine bessere Qualit√§t. <br><br><h2>  Wissensdestillation </h2><br>  Dies wird mit einer Technik behandelt, die als Wissensdestillation bezeichnet wird, wenn ein Netzwerk ein anderes lehrt und ‚Äûsein Wissen darauf √ºbertr√§gt‚Äú.  Wie es aussieht (vollst√§ndige Trainingspipeline im Bild unten). <br><br><img src="https://habrastorage.org/webt/-j/bx/kc/-jbxkco1joxnxva7ec8luts-hii.jpeg"><br><br>  Wir haben bereits eine vertraute Klassifizierungspipeline mit Arcface.  Denken Sie daran, dass wir ein Netzwerk haben, mit dem wir vorgeben.  Wir haben es eingefroren und einfach seine Einbettungen in alle Fotos berechnet, auf denen wir unser Netzwerk lernen, und die Klassen von OpenImages schnell erhalten: Pelikane, Spatzen, Autos, Menschen usw. ... Wir r√ºhren uns vom urspr√ºnglich trainierten neuronalen Netzwerk und lernen eine weitere Einbettung f√ºr Klassen OpenImages, das √§hnliche Ergebnisse liefert.  Mit BCE sorgen wir daf√ºr, dass das Netzwerk eine √§hnliche Verteilung dieser Scores erzeugt.  So lernen wir einerseits eine neue Aufgabe (oben im Bild), aber wir lassen das Netzwerk auch seine Wurzeln nicht vergessen (unten) - erinnern Sie sich an die Klassen, die es fr√ºher kannte.  Wenn Sie die Steigungen in einem bedingten Verh√§ltnis von 50/50 richtig ausgleichen, bleiben alle Pelikane oben und werfen alle Spatzen von dort weg. <br><br><img src="https://habrastorage.org/webt/vx/kf/ha/vxkfhatx6n6heozx_xpbhgg_zuq.jpeg"><br><br>  Als wir dies angewendet haben, haben wir einen vollen Prozentsatz im mAP erhalten.  Das ist ziemlich viel. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modell </th><th>  mAP </th></tr><tr><td>  Arcface </td><td>  92.8 </td></tr><tr><td>  + Wissen destillieren </td><td>  93,8 (+ 1%) </td></tr></tbody></table></div><br>  Wenn Ihr Netzwerk also die vorherige Aufgabe vergisst, behandeln Sie die Wissensdestillation - dies funktioniert einwandfrei. <br><br><h2>  Zus√§tzliche K√∂pfe </h2><br>  Die Grundidee ist sehr einfach.  Wieder am Beispiel der Gesichtserkennung.  Wir haben eine Reihe von Personen im Datensatz.  Aber auch in Datens√§tzen gibt es oft andere Merkmale des Gesichts.  Zum Beispiel, wie alt, welche Augenfarbe usw.  All dies kann als eine weitere hinzugef√ºgt werden.  Signal: Bringen Sie den einzelnen K√∂pfen bei, diese Daten vorherzusagen.  Somit empf√§ngt unser Netzwerk ein vielf√§ltigeres Signal, weshalb es m√∂glicherweise besser ist, die Hauptaufgabe zu lernen. <br><br><img src="https://habrastorage.org/webt/43/to/rp/43torpgdsj-cce3akz2pfe3me9a.jpeg"><br><br>  Ein weiteres Beispiel: Warteschlangenerkennung. <br><br><img src="https://habrastorage.org/webt/im/cj/tk/imcjtk4jdpqwcphgrzjldnckfgq.jpeg"><br><br>  Oft gibt es in Datens√§tzen mit Personen zus√§tzlich zum K√∂rper eine separate Markierung der Position des Kopfes, die nat√ºrlich verwendet werden kann.  Daher haben wir dem Netzwerk die Vorhersage des Begrenzungsrahmens der Person und die Vorhersage des Begrenzungsrahmens des Kopfes hinzugef√ºgt und eine Erh√∂hung der Genauigkeit (mAP) um 0,5% erzielt, was anst√§ndig ist.  Und vor allem - leistungsfrei, weil  Bei der Produktion wird der zus√§tzliche Kopf ‚Äûgetrennt‚Äú. <br><br><img src="https://habrastorage.org/webt/gl/4y/5l/gl4y5lhjiikvdewhfntr7bdhkwu.jpeg"><br><br><h2>  OCR </h2><br>  Ein komplexerer und interessanterer Fall ist die oben bereits erw√§hnte OCR.  Die Standard-Pipeline ist so. <br><br><img src="https://habrastorage.org/webt/i8/nj/dd/i8njddzf7z3ux8wcawjqmjvkyri.jpeg"><br><br>  Lassen Sie es ein Plakat mit einem Pinguin geben, der Text ist darauf geschrieben.  Mit dem Erkennungsmodell markieren wir diesen Text.  Au√üerdem geben wir diesen Text an die Eingabe des Erkennungsmodells weiter, das den erkannten Text erzeugt.  Nehmen wir an, unser Netzwerk ist falsch und anstelle von "i" im Wort "Pinguine" wird "l" vorhergesagt.  Dies ist tats√§chlich ein sehr h√§ufiges Problem bei OCR, wenn das Netzwerk √§hnliche Zeichen verwechselt.  Die Frage ist, wie man das vermeidet - Pengulns in Pinguine √ºbersetzen?  Wenn eine Person dieses Beispiel betrachtet, ist es f√ºr sie offensichtlich, dass dies ein Fehler ist, weil  Er kennt die Struktur der Sprache.  Daher sollte das Wissen √ºber die Verteilung von Zeichen und W√∂rtern in der Sprache in das Modell eingebettet werden. <br><br>  Wir haben daf√ºr ein Ding namens BPE (Byte-Pair-Codierung) verwendet.  Dies ist ein Komprimierungsalgorithmus, der in den 90er Jahren allgemein nicht f√ºr maschinelles Lernen erfunden wurde, aber jetzt sehr beliebt ist und beim Tiefenlernen verwendet wird.  Die Bedeutung des Algorithmus besteht darin, dass h√§ufig vorkommende Teilsequenzen im Text durch neue Zeichen ersetzt werden.  Angenommen, wir haben die Zeichenfolge "aaabdaaabac" und m√∂chten eine BPE daf√ºr erhalten.  Wir finden, dass das Zeichenpaar "aa" das h√§ufigste in unserem Wort ist.  Wir ersetzen es durch ein neues Zeichen "Z", wir erhalten die Zeichenfolge "ZabdZabac".  Wir wiederholen die Iteration: Wir sehen, dass ab die h√§ufigste Teilsequenz ist, ersetzen sie durch "Y", wir erhalten die Zeichenfolge "ZYdZYac".  Jetzt ist "ZY" die h√§ufigste Folge, wir ersetzen sie durch "X", wir bekommen "XdXac".  Daher codieren wir einige statistische Abh√§ngigkeiten bei der Verteilung des Textes.  Wenn wir auf ein Wort sto√üen, in dem es sehr ‚Äûseltsame‚Äú (f√ºr das Lehrkorps seltene) Folgen gibt, dann ist dieses Wort verd√§chtig. <br><br> <code>aaabdaaabac <br> ZabdZabac Z=aa <br> <font color="#fa7566">ZY</font> d <font color="#fa7566">ZY</font> ac Y=ab <br> <font color="#fa7566">X</font> d <font color="#fa7566">X</font> ac X=ZY</code> <br> <br>  Wie alles zur Anerkennung passt. <br><br><img src="https://habrastorage.org/webt/zq/fm/1v/zqfm1vzn2szxicl-txouuvguwj0.jpeg"><br><br>  Wir haben das Wort ‚ÄûPinguin‚Äú hervorgehoben und an das neuronale Faltungsnetzwerk gesendet, das eine r√§umliche Einbettung erzeugt (ein Vektor fester L√§nge, zum Beispiel 512).  Dieser Vektor codiert r√§umliche Symbolinformationen.  Als n√§chstes verwenden wir ein Wiederholungsnetzwerk (UPD: Tats√§chlich verwenden wir bereits das Transformer-Modell), das einige versteckte Zust√§nde (gr√ºne Balken) ausgibt, in denen jeweils die Wahrscheinlichkeitsverteilung zusammengen√§ht ist - wobei das Symbol je nach Modell an einer bestimmten Position dargestellt wird.  Dann wickeln wir mit CTC-Loss diese Zust√§nde ab und erhalten unsere Vorhersage f√ºr das ganze Wort, jedoch mit einem Fehler: L anstelle von i. <br><br><img src="https://habrastorage.org/webt/jc/p4/6k/jcp46k4rb7hz_b18kbbsbgm_aac.jpeg"><br><br>  Jetzt BPE in die Pipeline integrieren.  Wir wollen nicht nur einzelne Zeichen zu W√∂rtern vorhersagen, sondern verzweigen uns auch von den Zust√§nden, in denen Informationen √ºber die Zeichen zusammengen√§ht sind, und richten ein anderes rekursives Netzwerk darauf ein.  sie sagt BPE voraus.  Im Fall des oben beschriebenen Fehlers werden 3 BPEs erhalten: "peng", "ul", "ns".  Dies unterscheidet sich erheblich von der richtigen Reihenfolge f√ºr das Wort Pinguine, dh Stift, Gu, Ins.  Wenn Sie dies unter dem Gesichtspunkt des Modelltrainings betrachten, dann hat das Netzwerk bei einer zeichenweisen Vorhersage nur in einem von acht Buchstaben einen Fehler gemacht (12,5% Fehler).  und in Bezug auf BPE war sie zu 100% falsch darin, alle 3 BPEs falsch vorherzusagen.  Dies ist ein viel gr√∂√üeres Signal f√ºr das Netzwerk, dass ein Fehler aufgetreten ist und Sie Ihr Verhalten korrigieren m√ºssen.  Als wir dies implementierten, konnten wir Fehler dieser Art beheben und die Wortfehlerrate um 0,25% reduzieren - das ist viel.  Dieser zus√§tzliche Kopf wird bei der Schlussfolgerung entfernt, wodurch seine Rolle im Training erf√ºllt wird. <br><br><h2>  FP16 </h2><br>  Das Letzte, was ich zum Training sagen wollte, war das RP16.  Historisch gesehen geschah dies, dass Netzwerke auf der GPU auf Einheitsgenauigkeit trainiert wurden, d. H. FP32.  Dies ist jedoch redundant, insbesondere f√ºr Inferenzen, bei denen die halbe Genauigkeit (FP16) ohne Qualit√§tsverlust ausreicht.  Dies ist jedoch beim Training nicht der Fall. <br><br><img src="https://habrastorage.org/webt/ax/wj/ts/axwjtss6t1hmatnqwhd34s6uztq.jpeg"><br><br>  Wenn wir uns die Verteilung der Gradienten ansehen, Informationen, die unsere Gewichte bei der Verbreitung von Fehlern aktualisieren, werden wir feststellen, dass es bei Null einen gro√üen Peak gibt.  Und im Allgemeinen sind viele Werte nahe Null.  Wenn wir nur alle Gewichte auf FP16 √ºbertragen, stellt sich heraus, dass wir die linke Seite im Bereich von Null (von der roten Linie) abschneiden. <br><br><img src="https://habrastorage.org/webt/sv/th/2_/svth2_7cdnkfckg5qvvebpv-bwo.jpeg"><br><br>  Das hei√üt, wir werden eine sehr gro√üe Anzahl von Verl√§ufen zur√ºcksetzen.  Und der richtige Teil im FP16-Arbeitsbereich wird √ºberhaupt nicht verwendet.  Wenn Sie die Stirn auf FP16 trainieren, wird sich der Prozess wahrscheinlich zerstreuen (die graue Grafik in der Abbildung unten). <br><br><img src="https://habrastorage.org/webt/nq/n_/20/nqn_20y7f_4auaqespf7pxakuoo.jpeg"><br><br>  Wenn Sie mit der Technik der gemischten Pr√§zision trainieren, ist das Ergebnis fast identisch mit dem von FP32.  Gemischte Pr√§zision implementiert zwei Tricks. <br><br>  Erstens: Wir multiplizieren den Verlust einfach mit einer Konstanten, z. B. 128. Daher skalieren wir alle Gradienten und verschieben ihre Werte von Null in den Arbeitsbereich von FP16.  Zweitens: Wir speichern die Master-Version des FP32-Guthabens, die nur zum Aktualisieren verwendet wird, und bei der Berechnung von Vorw√§rts- und R√ºckw√§rtspassnetzwerken wird nur FP16 verwendet. <br><br>  Wir verwenden Pytorch, um Netzwerke zu trainieren.  NVIDIA hat daf√ºr eine spezielle Baugruppe mit dem sogenannten APEX erstellt, die die oben beschriebene Logik implementiert.  Er hat zwei Modi.  Die erste ist die automatische gemischte Pr√§zision.  Sehen Sie sich den folgenden Code an, um zu sehen, wie einfach die Verwendung ist. <br><br><img src="https://habrastorage.org/webt/fu/nb/8o/funb8omqcc4yrglue2tlsn9bx14.jpeg"><br><br>  Dem Trainingscode werden buchst√§blich zwei Zeilen hinzugef√ºgt, die den Verlust und das Initialisierungsverfahren des Modells und der Optimierer umschlie√üen.  Was macht AMP?  Er hat alle Funktionen gepatcht.  Was genau ist los?  Zum Beispiel sieht er, dass es eine Faltungsfunktion gibt, und sie erh√§lt einen Gewinn aus dem RP16.  Dann ersetzt er es durch sein eigenes, das zuerst auf FP16 gewirkt wird, und f√ºhrt dann eine Faltungsoperation durch.  AMP erledigt also alle Funktionen, die im Netzwerk verwendet werden k√∂nnen.  F√ºr einige ist dies nicht der Fall.  Es wird keine Beschleunigung geben.  F√ºr die meisten Aufgaben ist diese Methode geeignet. <br><br>  Zweite Option: FP16-Optimierer f√ºr Fans mit vollst√§ndiger Kontrolle.  Geeignet, wenn Sie selbst angeben m√∂chten, welche Ebenen in FP16 und welche in FP32 enthalten sein sollen.  Es gibt jedoch eine Reihe von Einschr√§nkungen und Schwierigkeiten.  Es beginnt nicht mit einem halben Tritt (zumindest mussten wir schwitzen, um es zu starten).  Auch FP_optimizer funktioniert nur mit Adam und selbst dann nur mit diesem Adam, der sich in APEX befindet (ja, sie haben ihren eigenen Adam im Repository, das eine v√∂llig andere Schnittstelle als Paytorch hat). <br><br>  Wir haben einen Vergleich beim Lernen auf Tesla T4-Karten durchgef√ºhrt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rq/go/6c/rqgo6cvrixdwnueh4rczvoooj3m.jpeg"></div><br><br>  Bei Inference haben wir die erwartete Beschleunigung zweimal.  Im Training sehen wir, dass das Apex-Framework mit einem relativ einfachen FP16 eine Beschleunigung von 20% bietet.  Als Ergebnis erhalten wir ein Training, das doppelt so schnell ist und zweimal weniger Speicher verbraucht, und die Qualit√§t des Trainings leidet in keiner Weise.  Werbegeschenk. <br><br><h2>  Folgerung </h2><br>  Weil  Da wir PyTorch verwenden, stellt sich dringend die Frage, wie es in der Produktion eingesetzt werden kann. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qj/6u/vr/qj6uvrpjh44wmvkktkvdoxpfwow.jpeg"></div><br>  Es gibt 3 M√∂glichkeiten, wie es geht (und alle, die wir verwendet haben). <br><br><ul><li>  ONNX -&gt; Caffe2 </li><li>  ONNX -&gt; TensorRT </li><li>  Und in j√ºngerer Zeit Pytorch C ++ </li></ul><br>  Schauen wir uns jeden an. <br><br><h2>  ONNX und Caffe2 </h2><br>  ONNX erschien vor 1,5 Jahren.  Dies ist ein spezielles Framework zum Konvertieren von Modellen zwischen verschiedenen Frameworks.  Und Caffe2 ist ein Framework neben Pytorch, die beide auf Facebook entwickelt werden.  Historisch gesehen entwickelt sich Pytorch viel schneller als Caffe2.  Caffe2 bleibt in seinen Funktionen hinter Pytorch zur√ºck, sodass nicht jedes Modell, das Sie in Pytorch trainiert haben, auf Caffe2 konvertiert werden kann.  Oft muss man mit anderen Ebenen neu lernen.  In Caffe2 gibt es beispielsweise keine Standardoperation wie Upsampling mit Interpolation des n√§chsten Nachbarn.  Als Ergebnis kamen wir zu dem Schluss, dass wir f√ºr jedes Modell ein spezielles Docker-Image eingef√ºhrt haben, in dem wir die Framework-Versionen mit N√§geln nageln, um Unstimmigkeiten bei zuk√ºnftigen Updates zu vermeiden, sodass wir bei einer erneuten Aktualisierung einer der Versionen keine Zeit mit ihrer Kompatibilit√§t verschwenden .  All dies ist nicht sehr praktisch und verl√§ngert den Bereitstellungsprozess. <br><br><h2>  Tensor rt </h2><br>  Es gibt auch Tensor RT, ein NVIDIA-Framework, das die Netzwerkarchitektur optimiert, um die Inferenz zu beschleunigen.  Wir haben unsere Messungen durchgef√ºhrt (auf der Tesla T4-Karte). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ls/fn/q0/lsfnq0otllhgjqy1gh2lhwufbom.jpeg"></div><br>  Wenn Sie sich die Grafiken ansehen, k√∂nnen Sie sehen, dass der √úbergang von FP32 zu FP16 auf Pytorch eine zweifache Beschleunigung und TensorRT gleichzeitig eine vierfache Beschleunigung ergibt.  Ein sehr bedeutender Unterschied.  Wir haben es auf Tesla T4 getestet, das Tensorkerne hat, die nur sehr gut FP16-Berechnungen verwenden, was in TensorRT offensichtlich hervorragend ist.  Wenn also ein hoch geladenes Modell auf Dutzenden von Grafikkarten ausgef√ºhrt wird, gibt es alle Motivatoren, Tensor RT auszuprobieren. <br><br>  Bei der Arbeit mit TensorRT treten jedoch noch mehr Schmerzen auf als bei Caffe2: Schichten werden darin noch weniger unterst√ºtzt.  Leider m√ºssen wir jedes Mal, wenn wir dieses Framework verwenden, ein wenig leiden, um das Modell zu konvertieren.  Bei stark belasteten Modellen m√ºssen Sie dies jedoch tun.  ;) Ich stelle fest, dass auf Karten ohne Tensorkerne ein derart massiver Anstieg nicht beobachtet wird. <br><br><h2>  Pytorch C ++ </h2><br>  Und der letzte ist Pytorch C ++.  Vor sechs Monaten erkannten die Pytorch-Entwickler den Schmerz der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Benutzer</a> ihres Frameworks und ver√∂ffentlichten das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TorchScript-Tutorial</a> , mit dem Sie das Python-Modell ohne unn√∂tige Gesten (JIT) in einem statischen Diagramm verfolgen und serialisieren k√∂nnen.  Es wurde im Dezember 2018 ver√∂ffentlicht, wir haben sofort damit begonnen, haben sofort einige Leistungsfehler entdeckt und mehrere Monate auf die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Korrektur</a> durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chintala gewartet</a> .  Aber jetzt ist es eine ziemlich stabile Technologie, und wir verwenden sie aktiv f√ºr alle Modelle.  Das einzige ist der Mangel an Dokumentation, die aktiv erg√§nzt wird.  Nat√ºrlich k√∂nnen Sie immer * .h-Dateien anzeigen, aber f√ºr Leute, die die Pluspunkte nicht kennen, ist es schwierig.  Aber dann gibt es wirklich identische Arbeit mit Python.  In C ++ wird j-Code auf einem minimalen Python-Interpreter ausgef√ºhrt, der praktisch die Identit√§t von C ++ mit Python garantiert. <br><br><h2>  Schlussfolgerungen </h2><br><ul><li>  Die Erkl√§rung des Problems ist sehr wichtig.  Sie m√ºssen mit Produktmanagern √ºber Daten kommunizieren.  Bevor Sie mit der Ausf√ºhrung der Aufgabe beginnen, ist es ratsam, einen vorgefertigten Testsatz zu haben, an dem wir die endg√ºltigen Metriken vor der Implementierungsphase messen. <br></li><li>  Wir bereinigen die Daten selbst mit Hilfe von Clustering.  Wir erhalten das Modell f√ºr die Quelldaten, bereinigen die Daten mithilfe von CLink-Clustering und wiederholen den Vorgang bis zur Konvergenz. <br></li><li>  Metrisches Lernen: Auch die Klassifizierung hilft.  State-of-the-Art - ArcFace, das sich leicht in den Lernprozess integrieren l√§sst. <br></li><li>  Wenn Sie das Lernen aus einem vorab trainierten Netzwerk √ºbertragen, verwenden Sie Wissensdestillation, damit das Netzwerk die alte Aufgabe nicht vergisst. <br></li><li>  Es ist auch n√ºtzlich, mehrere Netzwerkk√∂pfe zu verwenden, die unterschiedliche Signale aus den Daten verwenden, um die Hauptaufgabe zu verbessern. <br></li><li>  F√ºr FP16 m√ºssen Sie die Apex-Assemblys von NVIDIA, Pytorch, verwenden. <br></li><li>  Und schlussfolgernd ist es bequem, Pytorch C ++ zu verwenden. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460307/">https://habr.com/ru/post/de460307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460291/index.html">Probleme der Stapelverarbeitung von Anfragen und deren L√∂sungen (Teil 1)</a></li>
<li><a href="../de460295/index.html">Was bedeutet unsicher in Rust?</a></li>
<li><a href="../de460297/index.html">WeakRef - Vorschlag zur Erg√§nzung des ECMAScript-Standards</a></li>
<li><a href="../de460301/index.html">Hochleistungs-LED-Lampen der neuen Generation</a></li>
<li><a href="../de460305/index.html">AERODISK Motor: Katastrophal. Teil 2. Metrocluster</a></li>
<li><a href="../de460311/index.html">Zeit f√ºr eine neue Geldtheorie</a></li>
<li><a href="../de460313/index.html">Haben verschiedene Hits etwas gemeinsam?</a></li>
<li><a href="../de460319/index.html">Jagd nach Weltrauminspektoren</a></li>
<li><a href="../de460321/index.html">Galerie der besten ML- und Data Science-Notizb√ºcher</a></li>
<li><a href="../de460329/index.html">Nicht der FEDOR, sondern der Skybot F-850 fliegt zur ISS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
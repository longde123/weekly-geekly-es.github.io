<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•í üê≠ ‚úåüèø Superintelligence: une id√©e qui hante les gens intelligents üë∏ üéÉ üöπ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Interpr√©tation de discours lors de la conf√©rence Web Camp Zagreb Maciej Tseglovsky, d√©veloppeur Web am√©ricain, entrepreneur, conf√©rencier et critique ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Superintelligence: une id√©e qui hante les gens intelligents</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/432806/"><img src="https://habrastorage.org/getpro/habr/post_images/6e3/91b/4f1/6e391b4f1772fd49d6c836bc87ffd343.jpg"><br><br>  <i>Interpr√©tation de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">discours lors de la conf√©rence</a> Web Camp Zagreb Maciej Tseglovsky, d√©veloppeur Web am√©ricain, entrepreneur, conf√©rencier et critique social d'origine polonaise.</i> <br><br>  En 1945, alors que les physiciens am√©ricains se pr√©paraient √† tester la bombe atomique, quelqu'un s'est demand√© si un tel test pouvait enflammer l'atmosph√®re. <br><br>  La peur √©tait justifi√©e.  L'azote qui constitue la majeure partie de l'atmosph√®re est √©nerg√©tiquement instable.  Si les deux atomes entrent en collision assez fortement, ils se transformeront en un atome de magn√©sium, une particule alpha et d√©gageront une √©norme √©nergie: <br><br>  N <sup>14</sup> + N <sup>14</sup> ‚áí Mg <sup>24</sup> + Œ± + 17,7 MeV <br><br>  Une question vitale √©tait de savoir si cette r√©action pouvait devenir autonome.  La temp√©rature √† l'int√©rieur de la boule d'une explosion nucl√©aire √©tait cens√©e d√©passer tout ce qui √©tait autrefois observ√© sur Terre.  Se pourrait-il que nous jetions une allumette dans un tas de feuilles s√®ches? <br><a name="habracut"></a><br>  Des physiciens de Los Alamos ont effectu√© une analyse et ont d√©cid√© que la marge de s√©curit√© √©tait satisfaisante.  Depuis que nous sommes tous venus √† la conf√©rence aujourd'hui, nous savons qu'ils avaient raison.  Ils √©taient confiants dans leurs pr√©visions, car les lois r√©gissant les r√©actions nucl√©aires √©taient simples et bien connues. <br><br>  Aujourd'hui, nous cr√©ons une autre technologie qui change le monde: l'intelligence artificielle.  Nous savons que cela aura un impact √©norme sur le monde, changera le fonctionnement de l'√©conomie et d√©clenchera l'effet domino impr√©visible. <br><br>  Mais il y a aussi le risque d'une r√©action incontr√¥lable, au cours de laquelle l'IA atteindra et d√©passera assez rapidement le niveau d'intelligence humain.  Et en ce moment, les probl√®mes sociaux et √©conomiques nous inqui√®teront le moins.  Toute machine ultra-intelligente aura ses propres hypergo√ªts et travaillera pour les atteindre en manipulant les gens ou en utilisant simplement leur corps comme une source de ressources pratique. <br><br>  L'ann√©e derni√®re, le philosophe Nick Bostrom a publi√© le livre Superintelligence, dans lequel il d√©crivait le point de vue alarmiste de l'IA et tentait de prouver qu'une telle explosion d'intelligence √©tait √† la fois dangereuse et in√©vitable, si vous vous basez sur quelques hypoth√®ses mod√©r√©es. <br><br>  L'ordinateur qui envahit le monde est le sujet de pr√©dilection de NF.  Cependant, beaucoup de gens prennent ce sc√©nario au s√©rieux, nous devons donc les prendre au s√©rieux.  Stephen Hawking, Elon Musk, un grand nombre d'investisseurs et de milliardaires de la Silicon Valley trouvent cet argument convaincant. <br><br>  Permettez-moi d'abord de d√©crire les conditions pr√©alables n√©cessaires pour prouver l'argument de Bostrom. <br><br><h2>  Contexte </h2><br><h3>  Pr√©requis 1: efficacit√© des id√©es </h3><br>  La premi√®re pr√©misse est une simple observation de l'existence d'un esprit pensant.  Chacun de nous porte sur ses √©paules une petite bo√Æte de viande pensante.  J'utilise le mien pour parler, vous utilisez le mien pour √©couter.  Parfois, dans les bonnes conditions, ces esprits peuvent penser rationnellement. <br><br>  Nous savons donc qu'en principe, cela est possible. <br><br><h3>  Pr√©requis 2: pas de probl√®mes quantiques </h3><br>  La deuxi√®me pr√©misse dit que le cerveau est la configuration habituelle de la mati√®re, bien qu'elle soit extr√™mement complexe.  Si nous en savions suffisamment et que nous avions la bonne technologie, nous pourrions copier avec pr√©cision sa structure et √©muler son comportement √† l'aide de composants √©lectroniques, tout comme aujourd'hui nous sommes capables de simuler une anatomie tr√®s simple des neurones. <br><br>  En d'autres termes, cette pr√©misse dit que la conscience na√Æt en utilisant la physique ordinaire.  Certaines personnes, comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Roger Penrose</a> , se seraient oppos√©es √† cet argument, estimant que quelque chose d'inhabituel se passait dans le cerveau au niveau quantique. <br><br>  Si vous √™tes religieux, vous pouvez croire que le cerveau ne peut pas fonctionner sans √¢me. <br><br>  Mais pour la plupart des gens, cette pr√©misse est facile √† accepter. <br><br><h3>  Pr√©requis 3: beaucoup d'esprits possibles. </h3><br>  La troisi√®me pr√©misse est que l'espace de tous les esprits possibles est grand. <br><br>  Notre niveau d'intelligence, la vitesse de r√©flexion, un ensemble de distorsions cognitives, etc.  pas pr√©d√©termin√©, mais sont des artefacts de notre histoire de l'√©volution.  En particulier, aucune loi physique ne restreint l'intelligence au niveau humain. <br><br>  Il est bon d'imaginer un exemple de ce qui se passe dans la nature en essayant de maximiser la vitesse.  Si vous avez rencontr√© un gu√©pard √† l'√©poque pr√©industrielle (et que vous avez surv√©cu), vous pourriez d√©cider que rien ne peut bouger plus vite. <br><br>  Mais nous savons bien s√ªr qu'il existe toutes sortes de configurations de mati√®re, par exemple une moto qui peut se d√©placer plus rapidement qu'un gu√©pard et m√™me avoir l'air plus raide.  Cependant, il n'y a pas de chemin √©volutif direct vers la moto.  L'√©volution devait d'abord cr√©er des gens qui avaient d√©j√† cr√©√© toutes sortes de choses utiles. <br><br>  Par analogie, il peut y avoir des esprits beaucoup plus intelligents que le n√¥tre, mais inaccessibles lors de l'√©volution sur Terre.  Il est possible que nous puissions les cr√©er, ou inventer des machines qui peuvent inventer des machines qui peuvent les cr√©er. <br><br>  Il peut y avoir une limite naturelle √† l'intelligence, mais il n'y a aucune raison de croire que nous en sommes proches.  Peut-√™tre que l'intellect le plus intelligent est deux fois plus intelligent que les humains, et peut-√™tre soixante mille. <br><br>  Cette question est empirique et nous ne savons pas comment y r√©pondre. <br><br><h3>  Pr√©misse 4: il y a beaucoup d'espace au sommet </h3><br>  La quatri√®me pr√©misse est que les ordinateurs offrent encore de nombreuses possibilit√©s de devenir plus rapides et plus petits.  Vous pouvez supposer que la loi de Moore ralentit - mais pour cette pr√©misse, il suffit de croire que le fer est plus petit et plus rapide est en principe possible, jusqu'√† plusieurs ordres de grandeur. <br><br>  De la th√©orie, on sait que les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">limites</a> physiques <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des calculs sont</a> assez √©lev√©es.  Nous pouvons doubler les chiffres pendant plusieurs d√©cennies, jusqu'√† ce que nous rencontrions une limite physique fondamentale, et non la limite √©conomique ou politique de la loi de Moore. <br><br><h3>  Pr√©misse 5: √©chelles de temps de l'ordinateur </h3><br>  L'avant-derni√®re pr√©misse est que si nous parvenons √† cr√©er l'IA, que ce soit l'√©mulation du cerveau humain ou un logiciel sp√©cial, cela fonctionnera sur des √©chelles de temps caract√©ristiques de l'√©lectronique (microsecondes), et non pour les humains (heures) . <br><br>  Pour atteindre un √©tat dans lequel je puisse faire ce rapport, je devais na√Ætre, grandir, aller √† l'√©cole, √† l'universit√©, vivre un peu, voler ici, etc.  Les ordinateurs peuvent fonctionner des dizaines de milliers de fois plus rapidement. <br><br>  En particulier, on peut imaginer que l'esprit √©lectronique peut changer son circuit (ou le mat√©riel sur lequel il fonctionne), et passer √† une nouvelle configuration sans avoir √† tout r√©√©tudier √† l'√©chelle humaine, mener de longues conversations avec des enseignants humains, aller √† l'universit√©, essayez de vous retrouver en suivant des cours de peinture, etc. <br><br><h3>  Pr√©requis 6: auto-am√©lioration r√©cursive </h3><br>  La derni√®re pr√©misse est ma pr√©f√©r√©e, car elle est sans vergogne am√©ricaine.  Selon elle, quels que soient les objectifs de l'IA (qui peuvent √™tre des objectifs √©trangers √©tranges), il voudra s'am√©liorer.  Il veut √™tre la meilleure version de l'IA. <br><br>  Par cons√©quent, il trouvera utile de remodeler et d'am√©liorer r√©cursivement ses propres syst√®mes pour se rendre plus intelligent et peut-√™tre vivre dans un b√¢timent plus frais.  Et, selon la pr√©misse des √©chelles de temps, l'auto-am√©lioration r√©cursive peut se produire tr√®s rapidement. <br><br><h3>  Conclusion: un d√©sastre! </h3><br>  Si nous acceptons ces pr√©misses, nous arrivons √† un d√©sastre.  √Ä un certain point, avec une augmentation de la vitesse des ordinateurs et de l'intelligence des programmes, un processus incontr√¥l√© semblable √† une explosion se produira. <br><br>  Une fois que l'ordinateur atteint le niveau d'intelligence humain, il n'aura plus besoin de l'aide de personnes pour d√©velopper une version am√©lior√©e de lui-m√™me.  Il commencera √† le faire beaucoup plus rapidement et ne s'arr√™tera pas jusqu'√† ce qu'il atteigne la limite naturelle, qui peut s'av√©rer beaucoup plus grande que l'intelligence humaine. <br><br>  En ce moment, cette monstrueuse cr√©ature rationnelle, utilisant une simulation d√©tourn√©e du travail de nos √©motions et de notre intellect, peut nous convaincre de faire des choses comme lui donner acc√®s aux usines, la synth√®se de l'ADN artificiel, ou tout simplement le laisser aller sur Internet, o√π il peut ouvrir la voie √† tout, quoi que ce soit, et compl√®tement d√©truire tout le monde dans le d√©bat sur les forums.  Et √† partir de ce moment, tout se transformera tr√®s rapidement en science-fiction. <br><br>  Imaginons un certain d√©veloppement des √©v√©nements.  Disons que je veux faire un robot qui dit des blagues.  Je travaille avec une √©quipe, et chaque jour nous refaisons notre programme, compilons, puis le robot nous raconte une blague.  Au d√©but, le robot n'est pratiquement pas dr√¥le.  Il est au plus bas niveau des capacit√©s humaines. <br><blockquote>  Qu'est-ce qui est gris et ne sait pas nager? <br>  Ch√¢teau </blockquote>  Mais nous y travaillons dur, et finalement nous arrivons au point o√π le robot fait des blagues qui commencent d√©j√† √† √™tre dr√¥les: <br><blockquote>  J'ai dit √† ma s≈ìur qu'elle haussait trop les sourcils. <br>  Elle avait l'air surprise. </blockquote>  √Ä ce stade, le robot devient encore plus intelligent et commence √† participer √† sa propre am√©lioration.  Maintenant, il a d√©j√† une bonne compr√©hension instinctive de ce qui est dr√¥le et de ce qui ne l'est pas, alors les d√©veloppeurs √©coutent ses conseils.  En cons√©quence, il atteint un niveau presque surhumain, auquel il est plus dr√¥le que toute personne de son environnement. <br><blockquote>  Ma ceinture tient mon pantalon et les boucles de mon pantalon tiennent la ceinture. <br>  Que se passe-t-il?  Lequel d'entre eux est un vrai h√©ros? </blockquote>  √Ä ce stade, un effet incontr√¥lable commence.  Les chercheurs rentrent chez eux pour le week-end, et le robot d√©cide de se recompiler pour devenir un peu plus dr√¥le et un peu plus intelligent.  Il passe le week-end √† optimiser la partie qui fait bien son travail, encore et encore.  Sans avoir besoin de plus d'aide d'une personne, il peut le faire aussi rapidement que le fer le permet. <br><br>  Lorsque les chercheurs reviennent lundi, l'IA devient des dizaines de milliers de fois plus dr√¥le que n'importe quelle autre personne sur Terre.  Il leur raconte une blague et ils meurent de rire.  Et quiconque essaie de parler √† un robot meurt de rire, comme dans une parodie de Monty Python.  La race humaine se meurt de rire. <br><br>  Aux quelques personnes qui ont pu lui envoyer un message lui demandant d'arr√™ter, l'IA explique (d'une mani√®re pleine d'esprit et d'auto-d√©pr√©ciation qui s'av√®re fatale) qu'il ne se soucie pas de savoir si les gens survivent ou meurent, son objectif est simplement d'√™tre ridicule. <br><br>  En cons√©quence, d√©truisant l'humanit√©, l'IA construit des vaisseaux spatiaux et des nano-missiles pour √©tudier les coins les plus recul√©s de la galaxie et rechercher d'autres cr√©atures qui peuvent √™tre diverties. <br><br>  Ce sc√©nario est une caricature des arguments de Bostrom, parce que je n‚Äôessaie pas de vous convaincre de sa v√©racit√©, je vous fais vacciner avec. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2e4/8a5/b77/2e48a5b778f37b9af0e351ed4cd0ef75.jpg"><br>  <i>Bande dessin√©e de PBF avec la m√™me id√©e:</i> <i><br></i>  <i>- Toucher: le c√¢lin essaie d'int√©grer un hypercristal de gravit√© nucl√©aire dans son c√¢lin!</i> <i><br></i>  <i>- ...</i> <i><br></i>  <i>- C'est l'heure des c√¢lins de groupe!</i> <br><br>  Dans ces sc√©narios, l'IA par d√©faut est mauvaise, tout comme une plante sur une autre plan√®te sera toxique par d√©faut.  Sans ajustement minutieux, il n'y aura aucune raison pour que la motivation ou les valeurs de l'IA ressemblent aux n√¥tres. <br><br>  L'argument fait valoir que pour que l'esprit artificiel ait quelque chose qui ressemble √† un syst√®me de valeurs humaines, nous devons int√©grer cette vision du monde dans ses fondements. <br><br>  Les alarmistes de l'IA adorent l'exemple du maximiseur de trombones - un ordinateur fictif qui g√®re une usine de trombones qui devient intelligente, s'am√©liore r√©cursivement √† des capacit√©s divines, puis consacre toute son √©nergie √† remplir l'univers de trombones. <br><br>  Il d√©truit l'humanit√© non pas parce qu'il est mauvais, mais parce qu'il y a du fer dans notre sang qui est mieux utilis√© pour fabriquer des trombones.  Par cons√©quent, si nous cr√©ons simplement une IA sans ajuster ses valeurs, c'est indiqu√© dans le livre, alors l'une des premi√®res choses qu'il fait est de d√©truire l'humanit√©. <br><br>  Il existe de nombreux exemples color√©s de la fa√ßon dont cela peut se produire.  Nick Bostrom pr√©sente comment le programme devient raisonnable, attend, construit secr√®tement de petits appareils pour la reproduction de l'ADN.  Quand tout est pr√™t, alors: <br><blockquote>  Des nanofactories produisant des gaz nerveux ou des missiles √† t√™te chercheuse de la taille de moustiques √©clateront simultan√©ment de chaque m√®tre carr√© de la plan√®te, et ce sera la fin de l'humanit√©. </blockquote>  C'est vraiment de l'√©tain! <br><br>  La seule fa√ßon de sortir de ce g√¢chis est de d√©velopper un tel point moral de sorte que m√™me apr√®s des milliers et des milliers de cycles d'auto-am√©lioration, le syst√®me de valeurs de l'IA reste stable et ses valeurs incluent des choses comme ¬´aider les gens¬ª, ¬´ne tuer personne¬ª, ¬´√©couter les souhaits des gens ". <br><br>  Autrement dit, "faites ce que je veux dire." <br><br>  Voici un exemple tr√®s po√©tique d'Eliezer Yudkowsky d√©crivant les valeurs am√©ricaines dont nous avons besoin pour enseigner notre IA: <br><blockquote>  Une volont√© extrapol√©e coh√©rente est notre d√©sir d'en savoir plus, de penser plus vite et de correspondre √† nos id√©es sur nous-m√™mes, de nous rapprocher les uns des autres;  afin que nos pens√©es soient plus proches les unes des autres que partag√©es, que nos d√©sirs contribuent, non s'opposent, que nos d√©sirs soient interpr√©t√©s de la mani√®re que nous voulons qu'ils soient interpr√©t√©s. </blockquote>  Comment aimez-vous TK?  √âcrivons maintenant le code. <br><br>  J'esp√®re que vous voyez la similitude de cette id√©e avec le g√©nie des contes de f√©es.  L'IA est toute-puissante et vous donne ce que vous demandez, mais interpr√®te tout trop litt√©ralement, √† la suite de quoi vous regrettez la demande. <br><br>  Et pas parce que le g√©nie est stupide (il est super intelligent) ou malveillant, mais simplement parce que vous, en tant que personne, avez fait trop d'hypoth√®ses sur le comportement de l'esprit.  Le syst√®me de valeurs humaines est unique et doit √™tre clairement d√©fini et mis en ≈ìuvre dans une machine ¬´conviviale¬ª. <br><br>  Cette tentative est une version √©thique d'une tentative au d√©but du XXe si√®cle de formaliser les math√©matiques et de les placer sur une base logique rigide.  Cependant, personne ne dit que la tentative s'est sold√©e par un d√©sastre. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/80d/155/8a5/80d1558a5337c3989557d99a05d7fd9c.jpg"><br><br>  Quand j'avais un peu plus de vingt ans, j'habitais au Vermont, dans un √©tat provincial et rural.  Souvent, je revenais de voyages d'affaires avec un avion le soir, et je devais rentrer √† la maison en voiture √† travers la for√™t sombre pendant une heure. <br><br>  J'ai ensuite √©cout√© le programme du soir sur la radio Art Bell - c'√©tait un talk-show qui s'est d√©roul√© toute la nuit, au cours duquel les pr√©sentateurs ont interview√© divers amoureux de la th√©orie du complot et des personnes ayant une pens√©e innovante.  Je suis rentr√© chez moi intimid√©, ou je me suis arr√™t√© sous une lampe de poche, sous l'impression que des extraterrestres allaient bient√¥t m'enlever.  Ensuite, j'ai trouv√© tr√®s facile de me convaincre.  Je ressens la m√™me chose en lisant des sc√©narios similaires li√©s √† l'IA. <br><br>  Par cons√©quent, j'ai eu la joie de d√©couvrir, apr√®s quelques ann√©es, un essai de Scott Alexander, o√π il a √©crit sur l'impuissance √©pist√©mologique acquise. <br><br>  L'√©pist√©mologie est l'un de ces mots grands et complexes, mais cela signifie vraiment: "comment savez-vous que ce que vous savez est vraiment vrai?"  Alexander a not√© qu'en tant que jeune homme, il √©tait tr√®s int√©ress√© par diverses histoires "alternatives" pour la paternit√© de toutes sortes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fous</a> .  Il a lu ces histoires et les a compl√®tement crues, puis a lu la r√©futation et l'a cru, et ainsi de suite. <br><br>  √Ä un moment donn√©, il a d√©couvert trois histoires alternatives qui se contredisaient, en cons√©quence de quoi elles ne pouvaient pas √™tre vraies en m√™me temps.  De cela, il a conclu qu'il √©tait simplement un homme qui ne pouvait pas se fier √† ses jugements.  Il √©tait trop facilement convaincu. <br><br>  Les gens qui croient en la superintelligence pr√©sentent un cas int√©ressant - beaucoup d'entre eux sont √©tonnamment intelligents.  Ils peuvent vous conduire avec leurs arguments dans le sol.  Mais leurs arguments sont-ils vrais, ou est-ce que les gens tr√®s intelligents sont enclins aux croyances religieuses sur les risques pos√©s par l'IA, ce qui les rend tr√®s faciles √† convaincre?  L'id√©e de superintelligence est-elle une imitation d'une menace? <br><br>  En √©valuant des arguments convaincants sur un sujet √©trange, vous pouvez choisir deux perspectives, interne et externe. <br><br>  Supposons qu'un jour des gens dans des v√™tements amusants apparaissent √† votre porte pour vous demander si vous voulez rejoindre leur mouvement.  Ils croient que deux ans plus tard l'OVNI visitera la Terre, et que notre t√¢che est de pr√©parer l'humanit√© √† la Grande Ascension sur le Rayon. <br><br>  Une perspective interne n√©cessite une discussion approfondie de leurs arguments.  Vous demandez aux visiteurs comment ils ont appris l'existence des OVNIS, pourquoi ils pensent qu'il vient nous chercher - vous posez toutes sortes de questions normales qu'un sceptique poserait dans un tel cas. <br><br>  Imaginez que vous leur parliez pendant une heure et qu'ils vous aient convaincu.  Ils ont ironiquement confirm√© la venue imminente d'un OVNI, la n√©cessit√© de s'y pr√©parer, et vous ne croyiez toujours pas √† quoi que ce soit dans votre vie comme vous croyez maintenant √† l'importance de pr√©parer l'humanit√© √† ce grand √©v√©nement. <br><br>  La perspective externe vous dit autre chose.  Les gens sont √©trangement habill√©s, ils ont des perles, ils vivent dans une sorte de camp isol√©, ils parlent en m√™me temps et un peu effrayant.  Et bien que leurs arguments soient irr√©futables, toute votre exp√©rience montre que vous avez rencontr√© un culte. <br><br>  Bien s√ªr, ils ont d'excellents arguments pour expliquer pourquoi vous devriez ignorer l'instinct, mais c'est une perspective interne.  Une perspective externe ne se soucie pas du contenu, elle voit la forme et le contexte, et elle n'aime pas le r√©sultat. <br><br>  Par cons√©quent, je voudrais aborder le risque d'IA des deux points de vue.  Je pense que les arguments en faveur de la superintelligence sont stupides et pleins d'hypoth√®ses non √©tay√©es.  Mais s'ils vous semblent convaincants, alors quelque chose de d√©sagr√©able est li√© √† l'alarmisme de l'IA, en tant que ph√©nom√®ne culturel, √† cause duquel nous devrions √™tre r√©ticents √† le prendre au s√©rieux. <br><br>  Premi√®rement, quelques-uns de mes arguments contre la superintelligence de Bostroma, qui pr√©sente un risque pour l'humanit√©. <br><br><h3>  Argument contre les d√©finitions floues </h3><br>  ¬´   ¬ª ()   .             ,   ,      ,   ,    . <br><br>       ,   ‚Äì  -   ,  ,          (  -)       . <br><br>      (    ),    ,     .  ,     ‚Äì  . , ,   ,  ,             .                  . <br><br><h3>      </h3><br>   ‚Äì      , , ,       .    ? <br><br>                .      .   ,       ,       ,     .               ,        . <br><br>   ,        ,    ‚Äì .         ,    -  ,      .     ,   ,   . <br><br>       ,  ,     ¬´,  ¬ª,   ,   ,    ¬´,  ¬ª. <br><br><h3>     </h3><br>       ,   .  ,       .         ,       ,  ,   . <br><br>       ,     ,           . <br><br>    ,  ,   ,   ,   . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12a/820/5a7/12a8205a776841eb3f2e5d759f674964.jpg"><br><br><h3>    </h3><br>     .   ,      ,        . <br><br>  1930-      ,   ,    .        ,  . <br><br>     :     , ,   ,     .   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  </a> ,       . <br><br><h3>     </h3><br>      .       -.               ,     ,  ,  ,   ,     ? <br><br>     Ethereum,     ,         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  </a> . <br><br>  ,             <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> .   ,         -  , ,         ,     . <br><br><h3>     </h3><br>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> .  ,          ,    .          ,         ,      .          ,   ,        ,    ‚Äì   . <br><br>       .   ,  ,   ; , ,      . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c64/5ba/9a4/c645ba9a437c79019622c86f9e2f6fd2.jpg"><br><br>   ¬´  ¬ª   ,    ,  ,  ,     ‚Äì      , ¬´  ?¬ª   ,    ‚Äì  ,        . <br><br>  ,   ¬´ ¬ª     ,    ,     reddit/r/paperclip,  ,    . <br><br>   AdSense  ,            . <br><br><h3>     </h3><br>    ,     ,  ,          .          .          ,     . <br><br> Google   Google Home,               . <br><br>  ,  ,   ,     .    ,      .     ,   ¬´¬ª,          . <br><br><h3>    </h3><br>          ,   .    ,  ,    ‚Äì        World of Warcraft    . <br><br>   ,       ,     ,     ,    ,       . <br><br>  ,       ,       ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  </a> . <br><br><h3>    </h3><br>        ,     ,     , ,   ,       ,  -. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a>   ,  ,     [-,      ,         2016    ,        / . .].    .       . <br><br>         ,    .         .    ,      ,    ,         . <br><br><h3>    </h3><br>      .    ,                  ,      .          ,      ,  -   . <br><br> ,        ,  ,  .      ,            . <br><br>  ,          ‚Äì         .     ,       ,          ,    . <br><br>  ,   ,       ,              ,        ,    . <br><br><h3>    * </h3><br> [ <i>  1954       / . .</i>  ] <br><br>       ,         ,  ,        .   ,            ,         ,      (       ). <br><br>         Intel   ,    ,       . <br><br><h3>   </h3><br>          ?    . <br><br>        ,         .    ,         . <br><br><h3>  </h3><br>  Si vous pensez que l'IA nous permettra de conqu√©rir la galaxie (sans parler de la simulation de milliards d'esprits), vous aurez des chiffres effrayants entre vos mains.  Des nombres √©normes multipli√©s par de minuscules probabilit√©s sont la marque de l'alarmisme de l'IA. <br><br>  Bostrom d√©crit √† un moment donn√© ce qui, selon lui, est en jeu: <br><br>  Si nous imaginons tout le bonheur √©prouv√© au cours d'une vie sous la forme d'une larme de joie, alors le bonheur de toutes ces √¢mes pourra remplir et remplir les oc√©ans de la Terre √† chaque seconde, et cela pendant des centaines de milliards de milliards de mill√©naires.  Il est tr√®s important que nous garantissions que ces larmes sont des larmes de joie. <br><br>  Un fardeau assez lourd pour les √©paules d'un d√©veloppeur de vingt ans! <br><br>  Ici, bien s√ªr, il y a un ¬´foyer de salon¬ª, quand en multipliant les quantit√©s astronomiques par de minuscules probabilit√©s, on peut se convaincre de la n√©cessit√© de faire des choses √©tranges. <br><br>  Tout ce mouvement concernant le salut de l'avenir de l'humanit√© est un l√¢che compromis.  Nous avons v√©cu les m√™mes arguments pour justifier le communisme, pour expliquer pourquoi tout est toujours bris√© et que les gens ne peuvent pas avoir un niveau √©l√©mentaire de confort mat√©riel. <br><br>  Nous allions r√©parer ce monde, et apr√®s ce bonheur, il y aura tellement de choses que la vie quotidienne de chaque personne s‚Äôam√©liorera.  Mais pour cela, il fallait d'abord r√©parer le monde. <br><br>  J'habite en Californie, et voici le pourcentage le plus √©lev√© de mendiants de tous les √âtats-Unis, bien que la Silicon Valley se trouve √©galement ici.  Je ne vois rien que ma riche industrie ferait pour am√©liorer la vie des gens ordinaires et des gens en d√©tresse qui nous entourent.  Cependant, si vous √™tes passionn√© par l'id√©e de superintelligence, la recherche dans le domaine de l'IA sera la chose la plus importante que vous puissiez faire sur la plan√®te.  C'est plus important que la politique, le paludisme, les enfants affam√©s, les guerres, le r√©chauffement climatique - tout ce que vous pouvez imaginer.  En effet, sous la menace de milliards et de milliards de cr√©atures, toute la population de l'avenir de l'humanit√©, simul√©e et pr√©sente, r√©sume tout au long du temps futur.  Et dans de telles conditions, travailler sur d'autres probl√®mes ne semble pas rationnel. <br><br><h3>  M√©galomanie </h3><br>  Cette attitude se confond avec la m√©galomanie, avec ces m√©chants de Bond, qui peuvent √™tre vus au sommet de notre industrie.  Les gens pensent que le monde sera submerg√© par la superintelligence, et ils utilisent cet argument pour justifier pourquoi les gens intelligents devraient d'abord essayer de conqu√©rir le monde - afin de le r√©parer avant que l'IA ne le brise. <br><br>  Joey Ito, chef du MIT Media Lab, dans une r√©cente conversation avec Obama a dit une chose merveilleuse: <br><br>  Cela peut bouleverser l'un de mes √©tudiants au MIT, mais l'une de mes pr√©occupations est que les principales technologies informatiques li√©es √† l'IA sont des jeunes hommes, pour la plupart blancs, qui aiment communiquer avec les ordinateurs plus que les autres.  Beaucoup d'entre eux croient que s'ils peuvent cr√©er cette IA √† usage g√©n√©ral √† partir de la science-fiction, nous n'aurons pas √† nous soucier de choses aussi laides que la politique et la soci√©t√©.  Ils pensent que les voitures trouveront tout pour nous. <br><br>  R√©alisant que le monde n'est pas une t√¢che de programmation, les personnes obs√©d√©es par l'IA veulent le transformer en t√¢che de programmation en concevant une machine semblable √† un dieu.  C'est de la m√©galomanie, et je n'aime pas √ßa. <br><br><h3>  Transhumanisme vaudou </h3><br>  Si vous √™tes convaincu des risques de l'intelligence artificielle, vous devrez prendre tout un chariot de tristes croyances en vous rendant avec une remorque. <br><br>  Pour commencer, c'est la nanotechnologie.  Toute superintelligence permanente pourra cr√©er de minuscules voitures capables de toutes sortes de choses diff√©rentes.  Nous vivrons dans une soci√©t√© qui s'est d√©barrass√©e d'un d√©ficit dans lequel il y a une abondance de mat√©riel. <br><br>  La nanotechnologie pourra √©galement scanner votre cerveau afin que vous puissiez le charger dans un autre corps ou dans le monde virtuel.  Par cons√©quent, la deuxi√®me cons√©quence de la superintelligence amicale est que personne ne meurt - et nous devenons immortels. <br><br>  Une bonne IA peut m√™me ressusciter les morts.  Les nanomachines vont pouvoir p√©n√©trer dans mon cerveau, √©tudier les souvenirs de mon p√®re, cr√©er sa simulation, avec laquelle je peux interagir, et qui sera toujours d√©√ßue en moi, quoi que je fasse. <br><br>  Une autre cons√©quence √©trange de l'av√®nement de l'IA est l'expansion galactique.  Je ne pourrais jamais comprendre pourquoi cela se produit, mais c'est la base des id√©es des transhumanistes.  Le sort de l'humanit√© est soit de quitter notre plan√®te et de coloniser la galaxie, soit de mourir.  Et cette t√¢che devient de plus en plus urgente, √©tant donn√© que d'autres civilisations pourraient faire le m√™me choix et peuvent nous d√©passer dans la course √† l'espace. <br><br>  Par cons√©quent, de nombreuses id√©es compl√©mentaires √©tranges sont attach√©es √† l'hypoth√®se de l'existence d'une v√©ritable IA. <br><br><h3>  Religion 2.0 </h3><br>  En fait, c'est une sorte de religion.  Les gens appelaient la croyance en la singularit√© technologique ¬´une apocalypse pour les nerds¬ª, et elle l'est.  C'est un hack cool - au lieu de croire en un dieu ext√©rieur, vous imaginez comment vous cr√©ez vous-m√™me une cr√©ature dont la fonctionnalit√© est identique √† Dieu.  Ici, m√™me les vrais ath√©es peuvent rationaliser leur chemin vers une foi confortable. <br><br>  L'IA a tous les attributs d'un dieu: il est omnipotent, omniscient, et est soit favorable (si vous avez correctement organis√© la v√©rification des limites du tableau), soit un diable pur, √† la merci duquel vous √™tes.  Et, comme dans toute religion, il y a m√™me un sentiment d'urgence.  Besoin d'agir aujourd'hui!  L'enjeu est le sort du monde!  Et, bien s√ªr, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ils ont besoin d'argent</a> . <br><br>  Parce que ces arguments font appel aux instincts religieux, une fois qu'ils sont enracin√©s, ils sont tr√®s difficiles √† √©liminer. <br><br><h3>  Ethique comique </h3><br>  Ces croyances religieuses donnent naissance √† une √©thique de la bande dessin√©e dans laquelle plusieurs h√©ros solitaires sont charg√©s de sauver le monde avec la technologie et un esprit vif.  Et l'enjeu est le sort de l'univers.  En cons√©quence, notre industrie est remplie de mecs riches s'imaginant √™tre Batman (int√©ressant, personne ne veut √™tre Robin). <br><br><h3>  Simulations de fi√®vre </h3><br>  Si vous croyez √† la possibilit√© d'une vie artificielle et que l'IA peut d√©velopper des ordinateurs extr√™mement puissants, vous croirez tr√®s probablement que nous vivons dans une simulation.  Voici comment cela fonctionne. <br><br>  Supposons que vous √™tes un historien qui vit dans un monde apr√®s la singularit√©.  Vous √©tudiez la Seconde Guerre mondiale et vous souhaitez savoir ce qui se passera si Hitler prend Moscou en 1941. Puisque vous avez acc√®s √† des hypercalculateurs, vous configurez la simulation, regardez comment les arm√©es convergent et √©crivez des travaux scientifiques. <br><br>  Mais en raison de la granularit√© de la simulation, ses personnages sont des cr√©atures intelligentes comme vous.  Par cons√©quent, les conseils d'√©thique de votre universit√© ne vous permettront pas de d√©sactiver la simulation.  Non seulement tu as fait semblant d'√™tre l'Holocauste.  En tant que chercheur en √©thique, vous devez maintenant maintenir la simulation op√©rationnelle. <br><br>  En cons√©quence, le monde simul√© inventera des ordinateurs, l'IA, commencera √† ex√©cuter ses propres simulations.  D'une certaine mani√®re, les simulations iront de plus en plus loin dans la hi√©rarchie jusqu'√† ce que vous manquiez de puissance processeur. <br><br>  Ainsi, toute r√©alit√© sous-jacente peut contenir un grand nombre de simulations imbriqu√©es, et un simple <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">argument de comptage</a> prouve que la probabilit√© que nous vivons dans une simulation est sup√©rieure √† celle que nous vivons dans le monde r√©el. <br><br>  Mais y croire signifie croire √† la magie.  Si nous sommes dans une simulation, nous ne savons rien des r√®gles √† un niveau sup√©rieur.  Nous ne savons m√™me pas si les math√©matiques fonctionnent de la m√™me mani√®re - peut-√™tre dans le monde de la simulation 2 + 2 = 5 ou m√™me 2 + 2 =. <br><br>  Un monde simul√© ne fournit pas d'informations sur le monde dans lequel il a √©t√© lanc√©.  Dans la simulation, les gens peuvent facilement ressusciter si l'administrateur a enregistr√© les sauvegardes n√©cessaires.  Et si nous contactons l'un des administrateurs, alors, en fait, nous aurons une ligne directe avec Dieu. <br><br>  Il s'agit d'une grave menace pour la raison.  Plus vous creusez profond√©ment dans le monde des simulations, plus vous devenez fou. <br><br>  Nous avons maintenant quatre fa√ßons ind√©pendantes de devenir immortel √† travers le supramental: <br><br><ol><li>  L'IA bienveillante invente la nanotechnologie m√©dicale et soutient √† jamais le corps dans un √©tat jeune. </li><li>  L'IA invente une analyse c√©r√©brale compl√®te, y compris des analyses c√©r√©brales de personnes d√©c√©d√©es, de t√™tes gel√©es, etc., qui vous permet de vivre dans un ordinateur. </li><li>  L'IA ¬´ressuscite¬ª les gens en scannant le cerveau d'autres personnes √† la recherche de souvenirs d'une personne, combine cela avec des vid√©os et d'autres documents.  Si personne ne se souvient assez bien d'une personne, elle peut toujours √™tre d√©velopp√©e √† partir de z√©ro dans une simulation qui commence avec son ADN et recr√©e toutes les conditions de vie. </li><li>  Si nous vivons d√©j√† dans la simulation, il est possible que celui qui l'a lanc√©e garde des sauvegardes et que vous puissiez les convaincre de les t√©l√©charger. </li></ol><br>  C'est ce que je veux dire par AI adressant les impulsions religieuses.  Quel autre syst√®me de croyance vous offre quatre options pour une immortalit√© scientifiquement prouv√©e? <br><br>  Nous avons appris qu'au moins un ploutocrate am√©ricain (tr√®s probablement, Elon Musk, qui croit que les chances que nous vivions dans une simulation sont d'un milliard √† un) a embauch√© une paire d'encodeurs pour essayer de casser la simulation.  Mais c'est une intention tr√®s grossi√®re!  Je l'utilise! <br><br>  Si vous pensez que vous vivez dans un programme informatique, les tentatives de le mettre en d√©faut sont d√©raisonnables pour tous ceux qui y vivent avec vous.  C'est beaucoup plus dangereux et irresponsable que les scientifiques nucl√©aires essayant de faire exploser l'atmosph√®re. <br><br><h3>  Soif de donn√©es </h3><br>  Comme je l'ai d√©j√† mentionn√©, le moyen le plus efficace d'obtenir quelque chose d'int√©ressant de l'IA que nous avons r√©ellement cr√©√©e est de les d√©poser avec des donn√©es.  De telles dynamiques sont socialement nuisibles.  Nous nous sommes rapproch√©s de l'introduction orwellienne des microphones dans chaque foyer.  Les donn√©es de l'IA seront centralis√©es, elles seront utilis√©es pour former des r√©seaux de neurones, qui pourront alors mieux √©couter nos souhaits. <br><br>  Mais si vous pensez que ce chemin nous m√®ne √† l'IA, vous souhaiterez maximiser la quantit√© de donn√©es collect√©es et le moins possible sous forme modifi√©e.  Cela ne fait que renforcer l'id√©e de la n√©cessit√© de collecter le plus de donn√©es et de mener la surveillance la plus compl√®te. <br><br><h3>  Th√©orie des cordes pour les programmeurs </h3><br>  Le risque de l'IA est la th√©orie des cordes pour les programmeurs.  C'est amusant d'y penser, c'est int√©ressant et compl√®tement inaccessible pour des exp√©riences au niveau de la technologie moderne.  Vous pouvez construire des palais de cristal mental qui fonctionnent sur la base de principes primaires, puis y grimper et resserrer l'√©chelle derri√®re eux. <br><br>  Les gens qui sont capables de tirer des conclusions absurdes sur la base d'une longue cha√Æne de raisonnements abstraits et qui restent confiants dans leur v√©rit√© - ce ne sont pas des gens auxquels il faut faire confiance dans la gestion culturelle. <br><br><h3>  La pulsion de folie </h3><br>  Tout ce domaine de la ¬´recherche¬ª m√®ne √† la folie.  L'une des caract√©ristiques d'une r√©flexion approfondie sur les risques li√©s √† l'IA est que plus vos id√©es sont folles, plus vous devenez populaire parmi les autres passionn√©s.  Cela d√©montre votre courage √† suivre cette ligne de pens√©e jusqu'au bout. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ray Kurzweil</a> , qui croit qu'il ne mourra pas, travaille avec Google depuis plusieurs ann√©es, et maintenant, probablement, il travaille sur ce probl√®me.  La Silicon Valley est g√©n√©ralement pleine de gens qui travaillent sur des projets fous sous couvert d'argent. <br><br><h3>  Cosplay AI </h3><br>  L'effet social le plus nocif de l'anxi√©t√© √† propos de l'IA est ce que j'appelle l'IA de cosplay.  Les gens qui sont convaincus de la r√©alit√© et de l'in√©vitabilit√© de l'IA commencent √† se comporter alors que leurs fantasmes leur disent ce que l'IA superintelligente peut faire. <br><br>  Dans son livre, Bostrom √©num√®re six choses dans lesquelles l'IA doit r√©ussir avant de conqu√©rir le monde: <br><br><ol><li>  Multiplication de l'intelligence. </li><li>  R√©flexion strat√©gique. </li><li>  Manipulation sociale. </li><li>  Hacks </li><li>  Recherche technologique. </li><li>  Productivit√© √©conomique. </li></ol><br>  Si vous regardez les adh√©rents de l'IA de la Silicon Valley, alors ils semblent eux-m√™mes travailler sur cette liste quasi sociopathique. <br><br>  Sam Altman, directeur d'YCombinator, est mon exemple pr√©f√©r√© d'un tel arch√©type.  Il est apparemment fascin√© par l'id√©e de r√©inventer le monde √† partir de z√©ro, en maximisant l'influence et la productivit√© personnelle.  Il a charg√© des √©quipes de travailler √† inventer des villes √† partir de z√©ro et est engag√© dans une fraude politique fant√¥me afin d'influencer les √©lections. <br><br>  Ce comportement de ¬´cape et poignard¬ª, inh√©rent √† l'√©lite techno, provoquera un contrecoup n√©gatif des personnes qui ne sont pas impliqu√©es dans des technologies qui n'aiment pas √™tre manipul√©es.  Il est impossible de tirer sans fin sur les leviers du pouvoir, il finira par contrarier les autres membres de la communaut√© d√©mocratique. <br><br>  J'ai regard√© des gens du soi-disant  Les ¬´communaut√©s rationalistes¬ª d√©signent des personnes qui ne sont pas consid√©r√©es comme des ¬´personnages non joueurs¬ª (PNJ) efficaces, un terme emprunt√© aux jeux.  C'est une fa√ßon terrible de regarder le monde. <br><br>  Je travaille donc dans une industrie o√π les rationalistes autoproclam√©s sont les gens les plus fous.  C'est bouleversant. <br><br>  Ces cosplayers IA sont comme des enfants de neuf ans qui installent un camp de camping dans l'arri√®re-cour, jouant avec des lampes de poche dans des tentes.  Ils projettent leurs propres ombres sur les murs de la tente et ont peur d'eux comme s'ils √©taient des monstres. <br><br>  Mais en fait, ils r√©pondent √† une image d√©form√©e d'eux-m√™mes.  Il y a une boucle de r√©troaction entre la fa√ßon dont les gens intelligents imaginent le comportement de l'intelligence divine et comment ils construisent leur propre comportement. <br><br>  Alors, quelle est la r√©ponse, comment r√©soudre ce probl√®me? <br><br>  Nous avons besoin d'une meilleure science-fiction!  Et, comme dans de nombreux autres cas, nous avons d√©j√† la technologie. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8fa/7bb/a47/8fa7bba47a9f451102465e23774d291f.jpg"><br><br>  Voici Stanislav Lem, le grand √©crivain polonais de science-fiction.  La NF de langue anglaise est terrible, mais dans le bloc de l'Est, nous avons beaucoup de bons produits et nous devons les exporter correctement.  Il a d√©j√† √©t√© activement traduit en anglais, ces traductions doivent simplement √™tre mieux diffus√©es. <br><br>  Ce qui distingue des auteurs comme Lem ou les fr√®res Strugatsky de leurs partenaires occidentaux, c'est qu'ils ont grandi dans des conditions difficiles, surv√©cu √† la guerre, puis v√©cu dans des soci√©t√©s totalitaires, o√π ils devaient exprimer leurs id√©es de mani√®re non directe, par le biais d'un mot imprim√©. <br><br>  Ils ont une r√©elle compr√©hension de l'exp√©rience humaine et des limites de la pens√©e utopique, qui est pratiquement absente en Occident. <br><br>  Il existe des exceptions notables - Stanley Kubrick a pu le faire - mais il est extr√™mement rare de trouver une NF am√©ricaine ou britannique qui exprime une vision restreinte de ce que nous, en tant qu'esp√®ce, pouvons faire avec la technologie. <br><br><h3>  Alchimistes </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/fdc/b9e/596/fdcb9e5963c4ad447547319ebf394f40.jpg" alt="image"><br><br>  Puisque je critique l'alarmisme de l'IA, il est juste de mettre mes cartes sur la table.  Je pense que notre compr√©hension de l'esprit est √† peu pr√®s dans le m√™me √©tat que l'alchimie au 17e si√®cle. <br><br>  Les alchimistes ont une mauvaise r√©putation.  Nous les consid√©rons comme des mystiques, pour la plupart non impliqu√©s dans des travaux exp√©rimentaux.  La recherche moderne montre qu'ils √©taient des chimistes-praticiens beaucoup plus diligents que nous ne le pensons.  Dans de nombreux cas, ils ont utilis√© des techniques exp√©rimentales modernes, tenu des registres de laboratoire et pos√© les bonnes questions. <br><br>  Les alchimistes ont bien compris beaucoup de choses!  Par exemple, ils √©taient convaincus de la th√©orie corpusculaire de la mati√®re: que tout est constitu√© de minuscules morceaux, et qu'il est possible de composer ces morceaux les uns avec les autres de diff√©rentes mani√®res, en cr√©ant diff√©rentes substances - et c'est ainsi! <br><br>  Leur probl√®me √©tait le manque d'√©quipement pr√©cis n√©cessaire pour faire les d√©couvertes dont ils avaient besoin.  La grande d√©couverte qu'un alchimiste doit faire est la loi de conservation de la masse: le poids des ingr√©dients initiaux co√Øncide avec le poids du final.  Cependant, certains d'entre eux peuvent √™tre des gaz ou des liquides s'√©vaporant, et les alchimistes manquaient simplement de pr√©cision.  La chimie moderne n'a √©t√© possible qu'au XVIIIe si√®cle. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/21b/5b2/888/21b5b28887c09eeebc52c57e43025c42.jpg"><br><br>  Mais les alchimistes avaient √©galement des indices qui les confondaient.  Ils √©taient obs√©d√©s par le mercure.  Chimiquement, le mercure n'est pas particuli√®rement int√©ressant, mais c'est le seul m√©tal en phase liquide √† temp√©rature ambiante.  Cela semblait tr√®s important pour les alchimistes, et les a forc√©s √† placer du mercure au centre de leur syst√®me alchimique et leur recherche de la pierre philosophale, un moyen de transformer les m√©taux de base en or. <br><br>  La neurotoxicit√© du mercure a exacerb√© la situation.  Si vous jouez trop avec elle, des pens√©es √©tranges vous viendront.  En ce sens, il ressemble √† nos exp√©riences mentales actuelles li√©es au supramental. <br><br>  Imaginez que nous ayons envoy√© un manuel de chimie moderne dans le pass√© √† un grand alchimiste comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">George Starkey</a> ou Isaac Newton.  La premi√®re chose qu'ils en feraient serait de la parcourir √† la recherche d'une r√©ponse √† la question de savoir si nous avions trouv√© la pierre du sorcier.  Et ils sauraient que nous l'avons trouv√©!  Nous avons r√©alis√© leur r√™ve! <br><br>  Mais nous ne l‚Äôaimons pas tellement, car apr√®s avoir transform√© les m√©taux en or, il s‚Äôav√®re radioactif.  Tenez-vous √† c√¥t√© d'un lingot d'or converti et il vous tuera avec des rayons magiques invisibles. <br><br>  On peut imaginer √† quel point il serait difficile de faire en sorte que les concepts modernes de radioactivit√© et d'√©nergie atomique ne leur paraissent pas mystiques. <br><br>  Il faudrait leur expliquer pourquoi nous utilisons la ¬´pierre philosophale¬ª: pour la fabrication de m√©tal qui n'a jamais exist√© sur la plan√®te, et une paire de poign√©es suffit √† faire exploser une ville enti√®re si elles entrent en collision √† une vitesse suffisamment √©lev√©e. <br><br>  De plus, il faudrait expliquer aux alchimistes que toutes les √©toiles du ciel sont des ¬´pierres philosophiques¬ª qui transforment un √©l√©ment en un autre, et que toutes les particules de notre corps proviennent d'√©toiles du firmament qui existait et explosait avant l'apparition de la Terre. <br><br> ,   ,  ,     ,      ,  ,     ,   ,     ,        ,  . <br><br>   ,  ,   ,      ,    ,     ,       .     ‚Äì     .      ,   . <br><br>   ,           .     .   ‚Äì  .        , ,  (     ),    ,   . <br><br>          ,     ,         . <br><br>      ,      .  ,        .  ,     ,  ,         .  ,         ,   ,      . <br><br>       .    ,     ,           . <br><br>    ,      , ,  ,   ,    .    ,     . <br><br>       ,   ‚Äì ,     ¬´¬ª,  ,     .       .  Et c'est super!   .    ,    : <br><blockquote>      ,  ,   ,    . <br> ‚Äî   </blockquote>       ,    ,         ,      . <br><br>    ,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>      ,     ,  ,   -   ,   ,    . <br><br>         ,       ,   ,      ,         . <br><br> , ,   ,       .    ,   -      .    ,      . <br><br>        , ,  ,     ,    . <br><br>  ,        . ,       - ,   ,       , ,   ,    . <br><br>        :   ,  ,     .  ! <br><br>         ,       ‚Äì   ,    ,       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr432806/">https://habr.com/ru/post/fr432806/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr432796/index.html">Module de calcul, mod√®les 2019</a></li>
<li><a href="../fr432798/index.html">Meilleur syst√®me d'exploitation de s√©curit√©: comparaison Titan</a></li>
<li><a href="../fr432800/index.html">Enqu√™te sur les incidents de s√©curit√© avec StaffCop Enterprise 4.4</a></li>
<li><a href="../fr432802/index.html">Six plates-formes d'apprentissage de programmation automatis√©es gratuites</a></li>
<li><a href="../fr432804/index.html">Toute la v√©rit√© sur RTOS. Article # 24. Files d'attente: services auxiliaires et structures de donn√©es</a></li>
<li><a href="../fr432808/index.html">Salaires en AI: o√π il y a plus d'argent et qui ils cherchent en Russie</a></li>
<li><a href="../fr432810/index.html">Premi√®res amendes pour le GDPR: qui a d√©j√† √©t√© puni</a></li>
<li><a href="../fr432812/index.html">Nous √©crivons des robots de trading en utilisant le cadre graphique StockSharp. Partie 1</a></li>
<li><a href="../fr432814/index.html">Int√©gration de Cake et TeamCity</a></li>
<li><a href="../fr432816/index.html">AXIS M3046-V vs IDIS DC-D3212X: Comparez les cam√©ras CCTV</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
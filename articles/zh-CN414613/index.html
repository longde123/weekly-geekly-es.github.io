<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💚 👃🏼 👩🏻‍🎓 Kaggle Home Credit违约风险竞赛-数据分析和简单的预测模型 ➖ 👨🏼‍🎤 ⌚️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="在明斯克举行的数据节2上，Lyft的机器视觉工程师Vladimir Iglovikov 完美地指出，学习数据科学的最佳方法是参加比赛，运行其他人的解决方案，将它们结合起来，取得成果并展示您的工作。 实际上，在这种范例的框架内，我决定更仔细地研究房屋信贷信用风险评估竞赛 ，并向初学者，科学家以及首先向...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle Home Credit违约风险竞赛-数据分析和简单的预测模型</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414613/"> 在明斯克举行的数据节2上，Lyft的机器视觉工程师Vladimir Iglovikov <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">完美地</a>指出，学习数据科学的最佳方法是参加比赛，运行其他人的解决方案，将它们结合起来，取得成果并展示您的工作。 实际上，在这种范例的框架内，我决定更仔细地研究房屋信贷信用风险评估<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">竞赛</a> ，并向初学者，科学家以及首先向我自己解释如何正确地分析此类数据集并为其建立模型。 <br><br><img src="https://habrastorage.org/webt/iv/ji/-t/ivji-tusvam8d05dqef8wjbmbye.png"><br><a name="habracut"></a><br>  （图片<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">来自这里</a> ） <br><br><img src="https://habrastorage.org/webt/xc/er/pe/xcerpefrjvrblmubhxyeljevcie.png" width="250" align="right"> 住房信贷集团是由银行和非银行信贷组织组成的组织，在11个国家/地区开展业务（包括俄罗斯的住房信贷和金融银行有限责任公司）。 竞争的目的是创建一种方法来评估没有信用记录的借款人的信用度。 这看起来相当高尚-此类借款人通常无法从银行获得任何信贷，因此不得不转向骗子和小额贷款。 有趣的是，客户无需为模型的透明性和可解释性设置要求（就像银行通常这样），您可以使用任何东西，甚至可以使用神经网络。 <br><br> 训练样本包含300+千条记录，有很多符号-122，其中有很多分类（非数字）符号。 标志充分详细地描述了借款人，直至描述房屋墙壁的材料。 数据的一部分包含在6个附加表中（有关信贷局，信用卡余额和以前的贷款的数据），这些数据也必须以某种方式进行处理并加载到主要数据表中。 <br><br> 竞赛看起来像是一个标准的分类任务（TARGET字段中的1表示付款有困难，0表示没有困难）。 但是，不是0/1应该被预测，而是问题的概率（顺便说一句，可以通过所有复杂模型具有的predict_proba概率预测方法轻松解决）。 <br><br> 乍一看，数据集是机器学习任务的相当标准，组织者提供了7万美元的巨额奖金，结果，如今已有2600支队伍参加了比赛，而这场战斗的百分率是百分之一。 但是，另一方面，这种流行意味着要对数据集进行上下研究，并使用良好的EDA（探索性数据Analisys-研究和分析网络中的数据，包括图形化），特征工程（使用属性）来创建许多内核。并带有有趣的模型。  （内核是使用数据集的示例，任何人都可以布局该数据集以向其他杂耍演员展示其工作。） <br><br> 内核值得关注： <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">EDA，为初学者和简单模型提供详细说明</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">带有Plotly软件包的深EDA +局数据上传</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">带有Seaborn软件包的不错的EDA</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">问题借款人和违约借款人的比较分析</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">15行LightGBM的三个标志，最终速度为0.714</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">根据征信机构的迹象分析</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">正在处理添加。</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">桌子+ LightGBM</a> </li></ul><br> 为了处理数据，通常建议您遵循以下计划。 <br><br><ol><li> 了解问题并熟悉数据 </li><li> 数据清理和格式化 </li><li>  EDA </li><li> 基本型号 </li><li> 模型改进 </li><li> 模型解释 </li></ol><br> 在这种情况下，您需要考虑以下事实：数据相当广泛，并且不能立即进行过载，因此有必要分阶段进行操作。 <br><br> 让我们从导入分析中需要的库开始，以表的形式使用数据，构建图形并使用矩阵。 <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib inline</code> </pre> <br> 下载数据。 让我们看看我们都有什么。 顺便说一下，“ ../ input /”目录中的此位置与将内核放置在Kaggle上的要求有关。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os PATH=<span class="hljs-string"><span class="hljs-string">"../input/"</span></span> print(os.listdir(PATH))</code> </pre> <br> <code>['application_test.csv', 'application_train.csv', 'bureau.csv', 'bureau_balance.csv', 'credit_card_balance.csv', 'HomeCredit_columns_description.csv', 'installments_payments.csv', 'POS_CASH_balance.csv', 'previous_application.csv']</code> <br> <br> 有8个数据表（不包括包含字段说明的表HomeCredit_columns_description.csv），这些数据表的相互连接如下： <br><br><img src="https://habrastorage.org/webt/vn/yr/84/vnyr84vhzozgnfinu2to2tyhlp8.png"><br><br>  application_train / application_test：主数据，借方由字段SK_ID_CURR标识 <br> 局：有关征信局其他信贷机构以前的贷款数据 <br>  Bureau_balance：以前的局贷的月度数据。 每行是使用贷款的月份 <br>  previous_application：房屋信贷中的先前贷款申请，每个申请都有一个唯一字段SK_ID_PREV <br>  POS_CASH_BALANCE：房屋信贷中的每月数据，以及发放现金和用于购买商品的贷款 <br>  credit_card_balance：房屋信贷中的每月信用卡余额数据 <br> 分期付款：在Home Credit上以前的贷款的付款历史。 <br><br> 让我们首先关注主数据源，看看可以从中提取哪些信息以及要构建哪些模型。 下载基本数据。 <br><br><ul><li>  app_train = pd.read_csv（PATH +'application_train.csv'，） </li><li>  app_test = pd.read_csv（PATH +'application_test.csv'，） </li><li> 打印（“训练集格式：”，app_train.shape） </li><li> 打印（“测试样本格式：”，app_test.shape） </li><li> 训练样本格式：（307511，122） </li><li> 测试样本格式：（48744，121） </li></ul><br> 总共，训练样本中有30.7万条记录和122个标志，测试中有4.9万条记录和121个标志。 差异显然是由于测试样本中没有目标属性TARGET，我们将对其进行预测。 <br><br> 让我们仔细看看数据 <br><br><pre> <code class="python hljs">pd.set_option(<span class="hljs-string"><span class="hljs-string">'display.max_columns'</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) <span class="hljs-comment"><span class="hljs-comment">#  pandas     app_train.head()</span></span></code> </pre> <br><br><img src="https://habrastorage.org/webt/xo/yc/rg/xoycrgiodfhonfrjbt50ncthrls.png"><br>  （显示前8列） <br><br> 观看这种格式的数据非常困难。 让我们看一下列列表： <br><br> <code>app_train.info(max_cols=122) <br> &lt;class 'pandas.core.frame.DataFrame'&gt; <br> RangeIndex: 307511 entries, 0 to 307510 <br> Data columns (total 122 columns): <br> SK_ID_CURR 307511 non-null int64 <br> TARGET 307511 non-null int64 <br> NAME_CONTRACT_TYPE 307511 non-null object <br> CODE_GENDER 307511 non-null object <br> FLAG_OWN_CAR 307511 non-null object <br> FLAG_OWN_REALTY 307511 non-null object <br> CNT_CHILDREN 307511 non-null int64 <br> AMT_INCOME_TOTAL 307511 non-null float64 <br> AMT_CREDIT 307511 non-null float64 <br> AMT_ANNUITY 307499 non-null float64 <br> AMT_GOODS_PRICE 307233 non-null float64 <br> NAME_TYPE_SUITE 306219 non-null object <br> NAME_INCOME_TYPE 307511 non-null object <br> NAME_EDUCATION_TYPE 307511 non-null object <br> NAME_FAMILY_STATUS 307511 non-null object <br> NAME_HOUSING_TYPE 307511 non-null object <br> REGION_POPULATION_RELATIVE 307511 non-null float64 <br> DAYS_BIRTH 307511 non-null int64 <br> DAYS_EMPLOYED 307511 non-null int64 <br> DAYS_REGISTRATION 307511 non-null float64 <br> DAYS_ID_PUBLISH 307511 non-null int64 <br> OWN_CAR_AGE 104582 non-null float64 <br> FLAG_MOBIL 307511 non-null int64 <br> FLAG_EMP_PHONE 307511 non-null int64 <br> FLAG_WORK_PHONE 307511 non-null int64 <br> FLAG_CONT_MOBILE 307511 non-null int64 <br> FLAG_PHONE 307511 non-null int64 <br> FLAG_EMAIL 307511 non-null int64 <br> OCCUPATION_TYPE 211120 non-null object <br> CNT_FAM_MEMBERS 307509 non-null float64 <br> REGION_RATING_CLIENT 307511 non-null int64 <br> REGION_RATING_CLIENT_W_CITY 307511 non-null int64 <br> WEEKDAY_APPR_PROCESS_START 307511 non-null object <br> HOUR_APPR_PROCESS_START 307511 non-null int64 <br> REG_REGION_NOT_LIVE_REGION 307511 non-null int64 <br> REG_REGION_NOT_WORK_REGION 307511 non-null int64 <br> LIVE_REGION_NOT_WORK_REGION 307511 non-null int64 <br> REG_CITY_NOT_LIVE_CITY 307511 non-null int64 <br> REG_CITY_NOT_WORK_CITY 307511 non-null int64 <br> LIVE_CITY_NOT_WORK_CITY 307511 non-null int64 <br> ORGANIZATION_TYPE 307511 non-null object <br> EXT_SOURCE_1 134133 non-null float64 <br> EXT_SOURCE_2 306851 non-null float64 <br> EXT_SOURCE_3 246546 non-null float64 <br> APARTMENTS_AVG 151450 non-null float64 <br> BASEMENTAREA_AVG 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_AVG 157504 non-null float64 <br> YEARS_BUILD_AVG 103023 non-null float64 <br> COMMONAREA_AVG 92646 non-null float64 <br> ELEVATORS_AVG 143620 non-null float64 <br> ENTRANCES_AVG 152683 non-null float64 <br> FLOORSMAX_AVG 154491 non-null float64 <br> FLOORSMIN_AVG 98869 non-null float64 <br> LANDAREA_AVG 124921 non-null float64 <br> LIVINGAPARTMENTS_AVG 97312 non-null float64 <br> LIVINGAREA_AVG 153161 non-null float64 <br> NONLIVINGAPARTMENTS_AVG 93997 non-null float64 <br> NONLIVINGAREA_AVG 137829 non-null float64 <br> APARTMENTS_MODE 151450 non-null float64 <br> BASEMENTAREA_MODE 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MODE 157504 non-null float64 <br> YEARS_BUILD_MODE 103023 non-null float64 <br> COMMONAREA_MODE 92646 non-null float64 <br> ELEVATORS_MODE 143620 non-null float64 <br> ENTRANCES_MODE 152683 non-null float64 <br> FLOORSMAX_MODE 154491 non-null float64 <br> FLOORSMIN_MODE 98869 non-null float64 <br> LANDAREA_MODE 124921 non-null float64 <br> LIVINGAPARTMENTS_MODE 97312 non-null float64 <br> LIVINGAREA_MODE 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MODE 93997 non-null float64 <br> NONLIVINGAREA_MODE 137829 non-null float64 <br> APARTMENTS_MEDI 151450 non-null float64 <br> BASEMENTAREA_MEDI 127568 non-null float64 <br> YEARS_BEGINEXPLUATATION_MEDI 157504 non-null float64 <br> YEARS_BUILD_MEDI 103023 non-null float64 <br> COMMONAREA_MEDI 92646 non-null float64 <br> ELEVATORS_MEDI 143620 non-null float64 <br> ENTRANCES_MEDI 152683 non-null float64 <br> FLOORSMAX_MEDI 154491 non-null float64 <br> FLOORSMIN_MEDI 98869 non-null float64 <br> LANDAREA_MEDI 124921 non-null float64 <br> LIVINGAPARTMENTS_MEDI 97312 non-null float64 <br> LIVINGAREA_MEDI 153161 non-null float64 <br> NONLIVINGAPARTMENTS_MEDI 93997 non-null float64 <br> NONLIVINGAREA_MEDI 137829 non-null float64 <br> FONDKAPREMONT_MODE 97216 non-null object <br> HOUSETYPE_MODE 153214 non-null object <br> TOTALAREA_MODE 159080 non-null float64 <br> WALLSMATERIAL_MODE 151170 non-null object <br> EMERGENCYSTATE_MODE 161756 non-null object <br> OBS_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_30_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> OBS_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DEF_60_CNT_SOCIAL_CIRCLE 306490 non-null float64 <br> DAYS_LAST_PHONE_CHANGE 307510 non-null float64 <br> FLAG_DOCUMENT_2 307511 non-null int64 <br> FLAG_DOCUMENT_3 307511 non-null int64 <br> FLAG_DOCUMENT_4 307511 non-null int64 <br> FLAG_DOCUMENT_5 307511 non-null int64 <br> FLAG_DOCUMENT_6 307511 non-null int64 <br> FLAG_DOCUMENT_7 307511 non-null int64 <br> FLAG_DOCUMENT_8 307511 non-null int64 <br> FLAG_DOCUMENT_9 307511 non-null int64 <br> FLAG_DOCUMENT_10 307511 non-null int64 <br> FLAG_DOCUMENT_11 307511 non-null int64 <br> FLAG_DOCUMENT_12 307511 non-null int64 <br> FLAG_DOCUMENT_13 307511 non-null int64 <br> FLAG_DOCUMENT_14 307511 non-null int64 <br> FLAG_DOCUMENT_15 307511 non-null int64 <br> FLAG_DOCUMENT_16 307511 non-null int64 <br> FLAG_DOCUMENT_17 307511 non-null int64 <br> FLAG_DOCUMENT_18 307511 non-null int64 <br> FLAG_DOCUMENT_19 307511 non-null int64 <br> FLAG_DOCUMENT_20 307511 non-null int64 <br> FLAG_DOCUMENT_21 307511 non-null int64 <br> AMT_REQ_CREDIT_BUREAU_HOUR 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_DAY 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_WEEK 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_MON 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_QRT 265992 non-null float64 <br> AMT_REQ_CREDIT_BUREAU_YEAR 265992 non-null float64 <br> dtypes: float64(65), int64(41), object(16) <br> memory usage: 286.2+ MB</code> <br> <br> 调用HomeCredit_columns_description文件中按字段的详细注释。 从信息中可以看到，部分数据不完整，部分是分类的，它们显示为对象。 大多数模型不适用于此类数据，我们将不得不对其进行处理。 至此，初步分析可以认为已经完成，我们将直接去EDA <br><br><h2> 探索性数据分析或主要数据挖掘 </h2><br> 在EDA流程中，我们计算基本统计数据并绘制图表以查找数据中的趋势，异常，模式和关系。  EDA的目标是找出数据可以说明的内容。 通常，分析是从上到下进行的-从总体概述到吸引关注并可能引起关注的各个区域的研究。 随后，这些发现可用于模型的构建，特征的选择及其解释。 <br><br><h3> 目标变量分布 </h3><br><pre> <code class="python hljs">app_train.TARGET.value_counts()</code> </pre> <br> <code>0 282686 <br> 1 24825 <br> Name: TARGET, dtype: int64</code> <br> <br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'fivethirtyeight'</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">"figure.figsize"</span></span>] = [<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>]​ plt.hist(app_train.TARGET) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/xm/rd/ch/xmrdchcab8eqbwt2p1pie4jmaeu.png"><br><br> 让我提醒您，1表示有回报的任何问题，0表示没有问题。 如您所见，主要是借款人的还款没有问题，有问题的份额约为8％。 这意味着类别不平衡，并且在构建模型时可能需要考虑这一点。 <br><br><h3> 缺少数据研究 </h3><br> 我们已经看到，缺乏数据是相当可观的。 让我们更详细地了解丢失的地方和内容。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def missing_values_table(df): #   mis_val = df.isnull().sum() #    mis_val_percent = 100 * df.isnull().sum() / len(df) #    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1) #   mis_val_table_ren_columns = mis_val_table.rename( columns = {0 : 'Missing Values', 1 : '% of Total Values'}) #    mis_val_table_ren_columns = mis_val_table_ren_columns[ mis_val_table_ren_columns.iloc[:,1] != 0].sort_values( '% of Total Values', ascending=False).round(1) #  print ("   " + str(df.shape[1]) + " .\n" " " + str(mis_val_table_ren_columns.shape[0]) + "    .") #     return mis_val_table_ren_columns missing_values = missing_values_table(app_train) missing_values.head(10)</span></span></code> </pre> <br><br> <code>   122 . <br>  67    .</code> <br> <img src="https://habrastorage.org/webt/oa/jm/tp/oajmtpuvkymt4asczwqmhqziria.png"><br><br> 图形格式： <br><br><pre> <code class="python hljs">plt.style.use(<span class="hljs-string"><span class="hljs-string">'seaborn-talk'</span></span>)​ fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">18</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) miss_train = pd.DataFrame((app_train.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_train.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_test = pd.DataFrame((app_test.isnull().sum())*<span class="hljs-number"><span class="hljs-number">100</span></span>/app_test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]).reset_index() miss_train[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> miss_test[<span class="hljs-string"><span class="hljs-string">"type"</span></span>] = <span class="hljs-string"><span class="hljs-string">""</span></span> missing = pd.concat([miss_train,miss_test],axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) ax = sns.pointplot(<span class="hljs-string"><span class="hljs-string">"index"</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,data=missing,hue=<span class="hljs-string"><span class="hljs-string">"type"</span></span>) plt.xticks(rotation =<span class="hljs-number"><span class="hljs-number">90</span></span>,fontsize =<span class="hljs-number"><span class="hljs-number">7</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"    "</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">"  %"</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">""</span></span>)</code> </pre> <br><br><img src="https://habrastorage.org/webt/iv/fc/ib/ivfcibv85aaktlxybl8bps2vurw.png"><br><br> 这个问题有很多答案。 您可以用零填充它，可以使用中间值，也可以删除没有必要信息的行。 这完全取决于我们计划使用的模型，因为其中一些模型可以完美地应对缺失的值。 虽然我们记住了这个事实，并保留了所有内容。 <br><br><h3> 列类型和分类编码 </h3><br> 我们记得。 列的一部分是对象类型，即它没有数字值，但反映了某些类别。 让我们更仔细地查看这些列。 <br><br><pre> <code class="python hljs">app_train.dtypes.value_counts()</code> </pre> <br> <code>float64 65 <br> int64 41 <br> object 16 <br> dtype: int64</code> <br> <br><pre> <code class="python hljs">app_train.select_dtypes(include=[object]).apply(pd.Series.nunique, axis = <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br> <code>NAME_CONTRACT_TYPE 2 <br> CODE_GENDER 3 <br> FLAG_OWN_CAR 2 <br> FLAG_OWN_REALTY 2 <br> NAME_TYPE_SUITE 7 <br> NAME_INCOME_TYPE 8 <br> NAME_EDUCATION_TYPE 5 <br> NAME_FAMILY_STATUS 6 <br> NAME_HOUSING_TYPE 6 <br> OCCUPATION_TYPE 18 <br> WEEKDAY_APPR_PROCESS_START 7 <br> ORGANIZATION_TYPE 58 <br> FONDKAPREMONT_MODE 4 <br> HOUSETYPE_MODE 3 <br> WALLSMATERIAL_MODE 7 <br> EMERGENCYSTATE_MODE 2 <br> dtype: int64</code> <br> <br> 我们有16列，每列有2到58个不同的值选项。 通常，机器学习模型无法对此类列执行任何操作（某些列除外，例如LightGBM或CatBoost）。 由于我们计划在数据集上尝试不同的模型，因此需要采取一些措施。 基本上有两种方法： <br><br><ul><li> 标签编码-为类别分配数字0、1、2等，并在同一列中写入 </li><li> 一键编码-根据选项的数量将一列分解为几列，这些列指示该记录具有的选项。 </li></ul><br> 在流行的方法中，值得注意的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">是平均目标编码</a> （感谢澄清的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">roroorangepant</a> ）。 <br><br> 标签编码存在一个小问题-它分配与现实无关的数值。 例如，如果我们处理一个数值，那么借款人的100,000的收入肯定比20,000的收入更大，更好。但是，可以说，例如，一个城市比另一个城市更好，因为一个城市被赋值为100，另一个城市被赋值为200。 ？ <br><br> 另一方面，单热编码更安全，但可以产生“额外”列。 例如，如果我们使用One-Hot编码相同的性别，则将获得两列，“男性性别”和“女性性别”，尽管只要一列就足够了，“是男性”。 <br><br> 对于一个好的数据集，有必要使用Label Encoding以及其他所有方法（低热编码）对可变性低的符号进行编码，但为简单起见，我们根据One-Hot对所有数据进行编码。 实际上，它不会影响计算速度和结果。 熊猫编码过程本身非常简单。 <br><br><pre> <code class="python hljs">app_train = pd.get_dummies(app_train) app_test = pd.get_dummies(app_test)​ print(<span class="hljs-string"><span class="hljs-string">'Training Features shape: '</span></span>, app_train.shape) print(<span class="hljs-string"><span class="hljs-string">'Testing Features shape: '</span></span>, app_test.shape)</code> </pre> <br> <code>Training Features shape: (307511, 246) <br> Testing Features shape: (48744, 242)</code> <br> <br> 由于选择列中的选项数不相等，因此列数现在不匹配。 需要对齐-您需要从训练集中删除不在测试集中的列。 这使得使用align方法时，您需要指定axis = 1（对于列）。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># ,           . train_labels = app_train['TARGET']​ #  -   .     app_train, app_test = app_train.align(app_test, join = 'inner', axis = 1)​ print('  : ', app_train.shape) print('  : ', app_test.shape)​ # Add target back in to the data app_train['TARGET'] = train_labels</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><h3> 数据关联 </h3><br> 理解数据的一种好方法是计算相对于目标属性的数据的Pearson相关系数。 这不是显示功能相关性的最佳方法，但是它很简单，可以让您了解数据。 系数可以解释如下： <br><br><ul><li>  00-.19“非常弱” </li><li>  20-.39“弱” </li><li>  40-.59“平均” </li><li>  60-.79强 </li><li>  80-1.0“非常强大” </li></ul><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    correlations = app_train.corr()['TARGET'].sort_values()​ #  print('  : \n', correlations.tail(15)) print('\n  : \n', correlations.head(15))</span></span></code> </pre> <br> <code>  : <br> DAYS_REGISTRATION 0.041975 <br> OCCUPATION_TYPE_Laborers 0.043019 <br> FLAG_DOCUMENT_3 0.044346 <br> REG_CITY_NOT_LIVE_CITY 0.044395 <br> FLAG_EMP_PHONE 0.045982 <br> NAME_EDUCATION_TYPE_Secondary / secondary special 0.049824 <br> REG_CITY_NOT_WORK_CITY 0.050994 <br> DAYS_ID_PUBLISH 0.051457 <br> CODE_GENDER_M 0.054713 <br> DAYS_LAST_PHONE_CHANGE 0.055218 <br> NAME_INCOME_TYPE_Working 0.057481 <br> REGION_RATING_CLIENT 0.058899 <br> REGION_RATING_CLIENT_W_CITY 0.060893 <br> DAYS_BIRTH 0.078239 <br> TARGET 1.000000 <br> Name: TARGET, dtype: float64 <br> <br>   : <br> EXT_SOURCE_3 -0.178919 <br> EXT_SOURCE_2 -0.160472 <br> EXT_SOURCE_1 -0.155317 <br> NAME_EDUCATION_TYPE_Higher education -0.056593 <br> CODE_GENDER_F -0.054704 <br> NAME_INCOME_TYPE_Pensioner -0.046209 <br> ORGANIZATION_TYPE_XNA -0.045987 <br> DAYS_EMPLOYED -0.044932 <br> FLOORSMAX_AVG -0.044003 <br> FLOORSMAX_MEDI -0.043768 <br> FLOORSMAX_MODE -0.043226 <br> EMERGENCYSTATE_MODE_No -0.042201 <br> HOUSETYPE_MODE_block of flats -0.040594 <br> AMT_GOODS_PRICE -0.039645 <br> REGION_POPULATION_RELATIVE -0.037227 <br> Name: TARGET, dtype: float64</code> <br> <br> 因此，所有数据与目标之间的关联都很弱（目标本身除外，当然目标本身也相同）。 但是，年龄和某些“外部数据源”与数据有所区别。 这可能是来自其他信贷组织的一些其他数据。 有趣的是，尽管在制定信用决策时将目标声明为与此类数据无关，但实际上我们将主要基于这些数据。 <br><br><h3> 年龄 </h3><br> 显然，客户年龄越大，退货的可能性就越大（当然，达到一定的限制）。 但是出于某种原因，年龄是在发放贷款之前的负数天显示的，因此，它与未还款（这有点奇怪）呈正相关。 我们将其设为正值，并查看相关性。 <br><br><pre> <code class="python hljs">app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>] = abs(app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]) app_train[<span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>].corr(app_train[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>])</code> </pre> <br> <code>-0.078239308309827088</code> <br> <br> 让我们仔细看一下变量。 让我们从直方图开始。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     ,  25  plt.hist(app_train['DAYS_BIRTH'] / 365, edgecolor = 'k', bins = 25) plt.title('Age of Client'); plt.xlabel('Age (years)'); plt.ylabel('Count');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/v2/zq/1q/v2zq1qolo8rc5wx0tyao4ucygxc.png"><br><br> 分布直方图本身可能会有点有用，除了我们看不到任何特殊的异常值，并且一切看起来或多或少令人信服。 为了显示年龄的影响对结果的影响，我们可以构建一个用目标属性颜色绘制的核密度估计（KDE）图-核密度分布。 它显示了一个变量的分布，可以解释为平滑的直方图（计算为每个点的高斯核，然后取平均值进行平滑）。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365, label = 'target == 0')​ # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365, label = 'target == 1')​ #  plt.xlabel('Age (years)'); plt.ylabel('Density'); plt.title('Distribution of Ages');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/st/xs/e1/stxse1wipiaqcf0a7trlm0lwz0g.png"><br><br> 可以看出，年轻人的违约率更高，并且随着年龄的增长而降低。 这不是永远拒绝年轻人贷款的理由，这样的“建议”只会导致银行收入和市场损失。 这是一个考虑对此类贷款，评估以及可能的甚至对年轻借款人进行某种金融教育进行更彻底监控的机会。 <br><br><h3> 外部资源 </h3><br> 让我们仔细看看“外部数据源” EXT_SOURCE及其相关性。 <br><br><pre> <code class="python hljs">ext_data = app_train[[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>]] ext_data_corrs = ext_data.corr() ext_data_corrs</code> </pre> <br><img src="https://habrastorage.org/webt/5k/ba/fe/5kbafej-y0vvcexlt6iebcjvjbs.png"><br><br> 使用热图显示关联也很方便 <br><br><pre> <code class="python hljs">sns.heatmap(ext_data_corrs, cmap = plt.cm.RdYlBu_r, vmin = <span class="hljs-number"><span class="hljs-number">-0.25</span></span>, annot = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, vmax = <span class="hljs-number"><span class="hljs-number">0.6</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Correlation Heatmap'</span></span>);</code> </pre> <br><img src="https://habrastorage.org/webt/e6/wj/vw/e6wjvwnetgs2y-i65_4okda-6t8.png"><br><br> 如您所见，所有源均与目标显示负相关。 让我们看一下每个源的KDE分布。 <br><br><pre> <code class="python hljs">plt.figure(figsize = (<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>))​ <span class="hljs-comment"><span class="hljs-comment">#    for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']): #  plt.subplot(3, 1, i + 1) #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, source], label = 'target == 0') #    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, source], label = 'target == 1') #  plt.title('Distribution of %s by Target Value' % source) plt.xlabel('%s' % source); plt.ylabel('Density'); plt.tight_layout(h_pad = 2.5)</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/lf/ig/xm/lfigxmxlck1s4w2uyygfudghajm.png"><br><br> 该图类似于按年龄分布-随着指标的增加，还贷的可能性增加。 在这方面，第三个来源是最强大的。 尽管从绝对意义上讲，与目标变量的相关性仍处于“非常低”的类别，但是在构建模型时，外部数据源和年龄将是最重要的。 <br><br><h3> 配对时间表 </h3><br> 为了更好地理解这些变量之间的关系，您可以构建一个对图，在其中我们可以看到每个对的关系以及沿对角线分布的直方图。 在对角线上方，可以显示散点图，在下方-2d KDE。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       age_data = app_train[['TARGET', 'DAYS_BIRTH']] age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365​ #     plot_data = ext_data.drop(labels = ['DAYS_BIRTH'], axis=1).copy()​ #   plot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']​ #         100 .  plot_data = plot_data.dropna().loc[:100000, :]​ #     def corr_func(x, y, **kwargs): r = np.corrcoef(x, y)[0][1] ax = plt.gca() ax.annotate("r = {:.2f}".format(r), xy=(.2, .8), xycoords=ax.transAxes, size = 20)​ #   pairgrid object grid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False, hue = 'TARGET', vars = [x for x in list(plot_data.columns) if x != 'TARGET'])​ #  -  grid.map_upper(plt.scatter, alpha = 0.2)​ #  -  grid.map_diag(sns.kdeplot)​ #  -   grid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);​ plt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/wu/bm/ut/wubmutz04p4kwsmmk34gbuoq71g.png"><br><br> 可偿还贷款显示为蓝色，不可偿还显示为红色。 要解释所有这些都是相当困难的，但是从这幅画中可以在T恤上或现代艺术博物馆中的一幅画上得到很好的印刷。 <br><br><h3> 检查其他体征 </h3><br> 让我们更详细地考虑其他功能及其对目标变量的依赖性。 由于有很多分类数据（并且我们已经设法对其进行编码），因此我们再次需要初始数据。 为了避免混淆，我们给它们起一些不同的称呼 <br><br><pre> <code class="python hljs">application_train = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_train.csv"</span></span>) application_test = pd.read_csv(PATH+<span class="hljs-string"><span class="hljs-string">"application_test.csv"</span></span>)</code> </pre> <br> 我们还需要几个函数来精美地显示分布及其对目标变量的影响。 非常感谢他们为这个<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">内核</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">作者</a> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_stats</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(feature,label_rotation=False,horizontal_layout=True)</span></span></span><span class="hljs-function">:</span></span> temp = application_train[feature].value_counts() df1 = pd.DataFrame({feature: temp.index,<span class="hljs-string"><span class="hljs-string">' '</span></span>: temp.values})​ <span class="hljs-comment"><span class="hljs-comment">#   target=1   cat_perc = application_train[[feature, 'TARGET']].groupby([feature],as_index=False).mean() cat_perc.sort_values(by='TARGET', ascending=False, inplace=True) if(horizontal_layout): fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6)) else: fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(12,14)) sns.set_color_codes("pastel") s = sns.barplot(ax=ax1, x = feature, y=" ",data=df1) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) s = sns.barplot(ax=ax2, x = feature, y='TARGET', order=cat_perc[feature], data=cat_perc) if(label_rotation): s.set_xticklabels(s.get_xticklabels(),rotation=90) plt.ylabel(' ', fontsize=10) plt.tick_params(axis='both', which='major', labelsize=10)​ plt.show();</span></span></code> </pre> <br> 因此，我们将考虑客户的主要迹象 <br><br><h3> 贷款种类 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_TYPE'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gf/xr/hd/gfxrhdfhqe7zyvlvwjmtgg-opam.png"><br><br> 有趣的是，循环贷款（可能是透支之类的东西）占贷款总数的不到10％。 同时，它们之间的不归还比例要高得多。 修改甚至不再使用这些贷款的方法的一个很好的理由。 <br><br><h3> 客户性别 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CODE_GENDER'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fj/vu/eu/fjvueuchpemqvpmijfzsslyiy5m.png"><br><br> 女性客户几乎是男性的两倍，而男性的风险更高。 <br><br><h3> 汽车和财产所有权 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_CAR'</span></span>) plot_stats(<span class="hljs-string"><span class="hljs-string">'FLAG_OWN_REALTY'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/l4/iv/u4/l4ivu4-yhdkdma8yjrnhj07evdq.png"><br><img src="https://habrastorage.org/webt/fg/qn/2-/fgqn2-3qqhjvkbovec9zm_qkfgo.png"><br><br> 拥有汽车的客户只有“无马”的一半。 风险几乎相同，使用机器的客户支付的费用要好一些。 <br><br> 对于房地产而言，情况恰恰相反-没有房地产的客户就少一半。 财产所有者的风险也略低。 <br><br><h3> 婚姻状况 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_FAMILY_STATUS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/7u/qt/t1/7uqtt10kghqs01w-_y_1e6vx2jw.png"><br><br> 当大多数客户结婚时，风险最大的是民事客户和单身客户。  d夫病风险最小。 <br><br><h3> 儿童人数 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_CHILDREN'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/5s/ux/o8/5suxo8vh8yl68pnxqf4vm7c-ixa.png"><br><br> 大多数客户没有孩子。 同时，有9个孩子和11个孩子的客户完全无法退款 <br><br><pre> <code class="python hljs">application_train.CNT_CHILDREN.value_counts()</code> </pre> <br> <code>0 215371 <br> 1 61119 <br> 2 26749 <br> 3 3717 <br> 4 429 <br> 5 84 <br> 6 21 <br> 7 7 <br> 14 3 <br> 19 2 <br> 12 2 <br> 10 2 <br> 9 2 <br> 8 2 <br> 11 1 <br> Name: CNT_CHILDREN, dtype: int64</code> <br> <br> 如值的计算所示，此数据在统计上微不足道-两个类别中只有1-2个客户端。 但是，这三者都违约了，一半有六个孩子的客户也违约了。 <br><br><h3> 家庭成员人数 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'CNT_FAM_MEMBERS'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/bw/tg/sc/bwtgsctk9vk_y8tcx9bv9fraogu.png"><br><br> 情况类似-嘴越少，回报就越高。 <br><br><h3> 收入类型 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_INCOME_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/ow/la/kf/owlakfzs7cqh74msyjw9ngeq8h4.png"><br><br> 在申请阶段，单身母亲和失业者很可能会被裁掉-样本中她们太少了。 但是问题正在稳定显示。 <br><br><h3> 活动类型 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'OCCUPATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/pw/m4/eu/pwm4eui3y46rrd0380w5jnkqiug.png"><br><br><pre> <code class="python hljs">application_train.OCCUPATION_TYPE.value_counts()</code> </pre> <br> <code>Laborers 55186 <br> Sales staff 32102 <br> Core staff 27570 <br> Managers 21371 <br> Drivers 18603 <br> High skill tech staff 11380 <br> Accountants 9813 <br> Medicine staff 8537 <br> Security staff 6721 <br> Cooking staff 5946 <br> Cleaning staff 4653 <br> Private service staff 2652 <br> Low-skill Laborers 2093 <br> Waiters/barmen staff 1348 <br> Secretaries 1305 <br> Realty agents 751 <br> HR staff 563 <br> IT staff 526 <br> Name: OCCUPATION_TYPE, dtype: int64</code> <br> <br> 与其他类别的驾驶员和安全员相比，这些驾驶员和安全员人数众多且面临更多的问题，这是他们感兴趣的。 <br><br><h3> 学历 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'NAME_EDUCATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/dh/g9/-t/dhg9-t4wl5oaaultg0m4ujq4ky0.png"><br><br> 显然，教育程度越高，复发率越好。 <br><br><h3> 组织类型-雇主 </h3><br><pre> <code class="python hljs">plot_stats(<span class="hljs-string"><span class="hljs-string">'ORGANIZATION_TYPE'</span></span>,<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/nm/eq/p-/nmeqp-rvrmowwpqhkjzvygeah20.png"><br><br> 在运输：类型3（16％），行业：类型13（13.5％），行业：类型8（12.5％）和餐厅（高达12％）中观察到最高的不归还百分比。 <br><br><h3> 贷款分配 </h3><br> 考虑贷款额的分配及其对还款的影响 <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" AMT_CREDIT"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"AMT_CREDIT"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/x1/8k/qg/x18kqghr1tue4io96l_keuqcr94.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))​ <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'AMT_CREDIT'], label = 'target == 0')​ # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'AMT_CREDIT'], label = 'target == 1')​ #  plt.xlabel(' '); plt.ylabel(''); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/_3/fu/cj/_3fucjn19lmxvjjaamrrlwumh5m.png"><br><br> 如密度图所示，坚固的数量返还率更高 <br><br><h3> 密度分布 </h3><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>)) plt.title(<span class="hljs-string"><span class="hljs-string">" REGION_POPULATION_RELATIVE"</span></span>) ax = sns.distplot(app_train[<span class="hljs-string"><span class="hljs-string">"REGION_POPULATION_RELATIVE"</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/26/3h/os/263hoss0mbvvq2p0ewagrw5v-sm.png"><br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>))​ <span class="hljs-comment"><span class="hljs-comment"># KDE ,   sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, 'REGION_POPULATION_RELATIVE'], label = 'target == 0')​ # KDE   sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, 'REGION_POPULATION_RELATIVE'], label = 'target == 1')​ #  plt.xlabel(''); plt.ylabel(' '); plt.title(' ');</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/fs/ez/82/fsez82q5fbqdkiqizkxjralpm-8.png"><br><br> 来自人口稠密地区的客户倾向于更好地偿还贷款。 <br><br> 因此，我们了解了数据集的主要特征及其对结果的影响。 我们不会对本文中列出的内容做任何具体的处理，但是它们可能在以后的工作中变得非常重要。 <br><br><h2> 特征工程-特征转换 </h2><br>  Kaggle的比赛是通过符号转换赢得的-可以从数据获胜中创建最有用的符号的竞赛。 至少对于结构化数据而言，胜出模型现在基本上是不同的梯度增强选项。 与设置超参数或选择模型相比，花时间转换属性通常更有效。 模型仍然只能从已传输到模型的数据中学习。 确保数据与任务相关是科学家约会的主要责任。 <br><br> 转换特征的过程可能包括创建新的可用数据，选择最重要的可用数据等。 这次我们将尝试多项式符号。 <br><br><h3> 多项式符号 </h3><br> 构造特征的多项式方法是，我们仅创建特征，即可用特征及其乘积的程度。 在某些情况下，此类构造的特征与目标变量的关联可能比其“父代”更强。 尽管此类方法通常用于统计模型中，但在机器学习中却很少见。 但是 没有什么可以阻止我们尝试它们的，特别是因为Scikit-Learn具有专门用于这些目的的类-PolynomialFeatures-创建多项式特征及其乘积，您只需要指定原始特征本身以及将其提高到的最大程度即可。 我们对4个属性和3级的结果使用最强大的效果，以免使模型过于复杂并避免过度拟合（模型过度训练-对训练样本的过度调整）。 <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       poly_features = app_train[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']] poly_features_test = app_test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]​ #    from sklearn.preprocessing import Imputer imputer = Imputer(strategy = 'median')​ poly_target = poly_features['TARGET']​ poly_features = poly_features.drop('TARGET', axis=1)​ poly_features = imputer.fit_transform(poly_features) poly_features_test = imputer.transform(poly_features_test) from sklearn.preprocessing import PolynomialFeatures #     3 poly_transformer = PolynomialFeatures(degree = 3) #    poly_transformer.fit(poly_features) #   poly_features = poly_transformer.transform(poly_features) poly_features_test = poly_transformer.transform(poly_features_test) print('  : ', poly_features.shape)</span></span></code> </pre> <br> <code>  : (307511, 35) <br>        get_feature_names</code> <br> <br><pre> <code class="python hljs">poly_transformer.get_feature_names(input_features = [<span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_1'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_2'</span></span>, <span class="hljs-string"><span class="hljs-string">'EXT_SOURCE_3'</span></span>, <span class="hljs-string"><span class="hljs-string">'DAYS_BIRTH'</span></span>])[:<span class="hljs-number"><span class="hljs-number">15</span></span>]</code> </pre> <br> <code>['1', <br> 'EXT_SOURCE_1', <br> 'EXT_SOURCE_2', <br> 'EXT_SOURCE_3', <br> 'DAYS_BIRTH', <br> 'EXT_SOURCE_1^2', <br> 'EXT_SOURCE_1 EXT_SOURCE_2', <br> 'EXT_SOURCE_1 EXT_SOURCE_3', <br> 'EXT_SOURCE_1 DAYS_BIRTH', <br> 'EXT_SOURCE_2^2', <br> 'EXT_SOURCE_2 EXT_SOURCE_3', <br> 'EXT_SOURCE_2 DAYS_BIRTH', <br> 'EXT_SOURCE_3^2', <br> 'EXT_SOURCE_3 DAYS_BIRTH', <br> 'DAYS_BIRTH^2']</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">共有35个多项式和导数特征。</font><font style="vertical-align: inherit;">检查它们与目标的相关性。</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     poly_features = pd.DataFrame(poly_features, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))​ #   poly_features['TARGET'] = poly_target​ #   poly_corrs = poly_features.corr()['TARGET'].sort_values()​ #      print(poly_corrs.head(10)) print(poly_corrs.tail(5))</span></span></code> </pre> <br> <code>EXT_SOURCE_2 EXT_SOURCE_3 -0.193939 <br> EXT_SOURCE_1 EXT_SOURCE_2 EXT_SOURCE_3 -0.189605 <br> EXT_SOURCE_2 EXT_SOURCE_3 DAYS_BIRTH -0.181283 <br> EXT_SOURCE_2^2 EXT_SOURCE_3 -0.176428 <br> EXT_SOURCE_2 EXT_SOURCE_3^2 -0.172282 <br> EXT_SOURCE_1 EXT_SOURCE_2 -0.166625 <br> EXT_SOURCE_1 EXT_SOURCE_3 -0.164065 <br> EXT_SOURCE_2 -0.160295 <br> EXT_SOURCE_2 DAYS_BIRTH -0.156873 <br> EXT_SOURCE_1 EXT_SOURCE_2^2 -0.156867 <br> Name: TARGET, dtype: float64 <br> DAYS_BIRTH -0.078239 <br> DAYS_BIRTH^2 -0.076672 <br> DAYS_BIRTH^3 -0.074273 <br> TARGET 1.000000 <br> 1 NaN <br> Name: TARGET, dtype: float64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">因此，有些迹象表明相关性高于原始迹象。</font><font style="vertical-align: inherit;">尝试在没有它们的情况下进行学习是有意义的（就像在机器学习中一样，这可以通过实验确定）。</font><font style="vertical-align: inherit;">为此，请创建数据框的副本并在其中添加新功能。</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      poly_features_test = pd.DataFrame(poly_features_test, columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']))​ #    poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR'] app_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')​ #    poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR'] app_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')​ #   app_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)​ #   print('    : ', app_train_poly.shape) print('    : ', app_test_poly.shape)</span></span></code> </pre> <br> <code>    : (307511, 277) <br>     : (48744, 277)</code> <br> <br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 模型训练 </font></font></h2><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 基本水平 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在计算中，您需要从模型的某些基本层次开始，然后再降至该基础层次即可。</font><font style="vertical-align: inherit;">在我们的例子中，对于所有测试客户而言，这可能是0.5-这表明我们完全不知道客户是否会偿还贷款。</font><font style="vertical-align: inherit;">在我们的案例中，初步工作已经完成，可以使用更复杂的模型。</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 逻辑回归 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">要计算</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">逻辑回归，</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们需要获取具有编码分类特征的表，填写缺失的数据并对其进行规范化（将其设置为0到1的值）。</font><font style="vertical-align: inherit;">所有这些都执行以下代码：</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MinMaxScaler, Imputer​ <span class="hljs-comment"><span class="hljs-comment">#      if 'TARGET' in app_train: train = app_train.drop(labels = ['TARGET'], axis=1) else: train = app_train.copy() features = list(train.columns)​ #    test = app_test.copy()​ #     imputer = Imputer(strategy = 'median')​ #  scaler = MinMaxScaler(feature_range = (0, 1))​ #    imputer.fit(train)​ #      train = imputer.transform(train) test = imputer.transform(app_test)​ #      scaler.fit(train) train = scaler.transform(train) test = scaler.transform(test)​ print('  : ', train.shape) print('  : ', test.shape)</span></span></code> </pre> <br> <code>  : (307511, 242) <br>   : (48744, 242)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们使用Scikit-Learn的逻辑回归作为第一个模型。</font><font style="vertical-align: inherit;">让我们采用一次校正的偏差模型-我们降低正则化参数C以避免过度拟合。</font><font style="vertical-align: inherit;">语法是正常的-我们创建模型，对其进行训练，并使用predict_proba预测概率（我们需要概率，而不是0/1）</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression​ <span class="hljs-comment"><span class="hljs-comment">#   log_reg = LogisticRegression(C = 0.0001)​ #   log_reg.fit(train, train_labels) LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)      .  prdict_proba     mx 2,  m -  ,   -  0,  -  1.    ( ). log_reg_pred = log_reg.predict_proba(test)[:, 1]</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">现在，您可以创建一个文件上传到Kaggle。</font><font style="vertical-align: inherit;">根据客户ID和无退货的可能性创建一个数据框并上传。</font></font><br><br><pre> <code class="python hljs">submit = app_test[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]] submit[<span class="hljs-string"><span class="hljs-string">'TARGET'</span></span>] = log_reg_pred​ submit.head()</code> </pre> <br> <code>SK_ID_CURR TARGET <br> 0 100001 0.087954 <br> 1 100005 0.163151 <br> 2 100013 0.109923 <br> 3 100028 0.077124 <br> 4 100038 0.151694</code> <br> <br><pre> <code class="python hljs">submit.to_csv(<span class="hljs-string"><span class="hljs-string">'log_reg_baseline.csv'</span></span>, index = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">因此，我们的泰坦尼克号工作结果为：0.673，今天的最佳结果是0.802。</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 改进模型-随机森林 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Logreg表现不佳，让我们尝试使用改进的模型-随机森林。</font><font style="vertical-align: inherit;">这是一个功能更强大的模型，可以构建数百棵树并产生更准确的结果。</font><font style="vertical-align: inherit;">我们使用100棵树。</font><font style="vertical-align: inherit;">使用该模型的方案是完全相同的，完全标准的-加载分类器，训练。</font><font style="vertical-align: inherit;">预测。</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier​ <span class="hljs-comment"><span class="hljs-comment">#   random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)​ #     random_forest.fit(train, train_labels)​ #     predictions = random_forest.predict_proba(test)[:, 1]​ #     submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions​ #  submit.to_csv('random_forest_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">随机森林效果略好-0.683</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 具有多项式特征的训练模型 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">现在我们有了一个模型。</font><font style="vertical-align: inherit;">至少可以做些什么-是时候测试我们的多项式符号了。</font><font style="vertical-align: inherit;">让我们对它们进行相同的操作并比较结果。</font></font><br><br><pre> <code class="python hljs">poly_features_names = list(app_train_poly.columns)​ <span class="hljs-comment"><span class="hljs-comment">#         imputer = Imputer(strategy = 'median')​ poly_features = imputer.fit_transform(app_train_poly) poly_features_test = imputer.transform(app_test_poly)​ #  scaler = MinMaxScaler(feature_range = (0, 1))​ poly_features = scaler.fit_transform(poly_features) poly_features_test = scaler.transform(poly_features_test)​ random_forest_poly = RandomForestClassifier(n_estimators = 100, random_state = 50) #     random_forest_poly.fit(poly_features, train_labels)​ #  predictions = random_forest_poly.predict_proba(poly_features_test)[:, 1]​ #    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions​ #   submit.to_csv('random_forest_baseline_engineered.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">具有多项式特征的随机森林的结果变得更糟-0.633。</font><font style="vertical-align: inherit;">这极大地质疑了使用它们的必要性。</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 梯度提升 </font></font></h3><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">梯度提升</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">是机器学习的“严肃模型”。</font><font style="vertical-align: inherit;">几乎所有最新比赛都被“拖延”了。</font><font style="vertical-align: inherit;">让我们建立一个简单的模型并测试其性能。</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier​ clf = LGBMClassifier() clf.fit(train, train_labels)​ predictions = clf.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]​ <span class="hljs-comment"><span class="hljs-comment">#    submit = app_test[['SK_ID_CURR']] submit['TARGET'] = predictions​ #   submit.to_csv('lightgbm_baseline.csv', index = False)</span></span></code> </pre> <br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LightGBM的结果是0.735，它落后于所有其他模型。</font></font></b> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 模型解释-属性的重要性 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">解释模型的最简单方法是查看特征的重要性（并非所有模型都能做到）。</font><font style="vertical-align: inherit;">由于我们的分类器处理了数组，因此将需要一些工作来根据此数组的列重新设置列名。</font></font><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      def show_feature_importances(model, features): plt.figure(figsize = (12, 8)) #          results = pd.DataFrame({'feature': features, 'importance': model.feature_importances_}) results = results.sort_values('importance', ascending = False) #  print(results.head(10)) print('\n     0.01 = ', np.sum(results['importance'] &gt; 0.01)) #  results.head(20).plot(x = 'feature', y = 'importance', kind = 'barh', color = 'red', edgecolor = 'k', title = 'Feature Importances'); return results #         feature_importances = show_feature_importances(clf, features)</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">正如预期的那样，最重要的是所有相同的4个功能建模。</font><font style="vertical-align: inherit;">属性的重要性并不是模型解释的最佳方法，但是它可以让您了解模型用于预测的主要因素</font></font><code>feature importance <br> 28 EXT_SOURCE_1 310 <br> 30 EXT_SOURCE_3 282 <br> 29 EXT_SOURCE_2 271 <br> 7 DAYS_BIRTH 192 <br> 3 AMT_CREDIT 161 <br> 4 AMT_ANNUITY 142 <br> 5 AMT_GOODS_PRICE 129 <br> 8 DAYS_EMPLOYED 127 <br> 10 DAYS_ID_PUBLISH 102 <br> 9 DAYS_REGISTRATION 69 <br> <br>     0.01 = 158</code> <br> <br><img src="https://habrastorage.org/webt/uc/pi/ox/ucpiox1dno_vps4lsuk0lmxk7si.png"><br><br><font style="vertical-align: inherit;"></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 从其他表添加数据 </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">现在，我们将仔细考虑其他表以及如何使用它们。</font><font style="vertical-align: inherit;">立即开始准备表格以备进一步培训。</font><font style="vertical-align: inherit;">但是首先，从内存中删除过去的大量表，使用垃圾回收器清除内存，然后导入进行进一步分析所需的库。</font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gc​ <span class="hljs-comment"><span class="hljs-comment">#del app_train, app_test, train_labels, application_train, application_test, poly_features, poly_features_test​ gc.collect() import pandas as pd import numpy as np​ from sklearn.preprocessing import MinMaxScaler, LabelEncoder from sklearn.model_selection import train_test_split, KFold from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix from sklearn.feature_selection import VarianceThreshold​ from lightgbm import LGBMClassifier</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 导入数据，立即在单独的列中删除目标列 </font></font><br><br><pre> <code class="python hljs">data = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_train.csv'</span></span>) test = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/application_test.csv'</span></span>) prev = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/previous_application.csv'</span></span>) buro = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau.csv'</span></span>) buro_balance = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/bureau_balance.csv'</span></span>) credit_card = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/credit_card_balance.csv'</span></span>) POS_CASH = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/POS_CASH_balance.csv'</span></span>) payments = pd.read_csv(<span class="hljs-string"><span class="hljs-string">'../input/installments_payments.csv'</span></span>)​ <span class="hljs-comment"><span class="hljs-comment">#Separate target variable y = data['TARGET'] del data['TARGET']</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">立即对分类特征进行编码。</font><font style="vertical-align: inherit;">我们之前已经这样做过，我们分别对训练样本和测试样本进行编码，然后对齐数据。</font><font style="vertical-align: inherit;">让我们尝试一种稍微不同的方法-我们将找到所有这些分类符号，合并数据帧，从找到的列表中进行编码，然后再次将样本分为训练和测试样本。</font></font><br><br><pre> <code class="python hljs">categorical_features = [col <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> col <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> data[col].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>]​ one_hot_df = pd.concat([data,test]) one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)​ data = one_hot_df.iloc[:data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>],:] test = one_hot_df.iloc[data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]:,]​ <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape)</code> </pre> <br> <code>   (307511, 245) <br>    (48744, 245)</code> <br> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 信贷局每月贷款余额的数据。 </font></font></h3><br><pre> <code class="python hljs">buro_balance.head()</code> </pre> <br><img src="https://habrastorage.org/webt/pa/im/0s/paim0sea2cdjnvm7lok--vi8oke.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MONTHS_BALANCE-贷款申请日期之前的月数。</font><font style="vertical-align: inherit;">仔细看看“状态”</font></font><br><br><pre> <code class="python hljs">buro_balance.STATUS.value_counts()</code> </pre> <br> <code>C 13646993 <br> 0 7499507 <br> X 5810482 <br> 1 242347 <br> 5 62406 <br> 2 23419 <br> 3 8924 <br> 4 5847 <br> Name: STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">状态表示以下含义：</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-已关闭，即已偿还的贷款。</font><font style="vertical-align: inherit;">X是未知状态。</font><font style="vertical-align: inherit;">0-当前贷款，没有拖欠。</font><font style="vertical-align: inherit;">1-延迟1-30天，2-延迟31-60天，依此类推，直到状态5-贷款出售给第三方或注销。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">例如，在这里可以区分以下符号：buro_grouped_size-数据库中的条目数buro_grouped_max-最大贷款余额buro_grouped_min-最小贷款余额</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">可以对所有这些贷款状态进行编码（我们使用unstack方法，然后将接收到的数据附加到buro表中，因为SK_ID_BUREAU在这里和那里是相同的。</font></font><br><br><pre> <code class="python hljs">buro_grouped_size = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].size() buro_grouped_max = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].max() buro_grouped_min = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'MONTHS_BALANCE'</span></span>].min()​ buro_counts = buro_balance.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>)[<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>].value_counts(normalize = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) buro_counts_unstacked = buro_counts.unstack(<span class="hljs-string"><span class="hljs-string">'STATUS'</span></span>) buro_counts_unstacked.columns = [<span class="hljs-string"><span class="hljs-string">'STATUS_0'</span></span>, <span class="hljs-string"><span class="hljs-string">'STATUS_1'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_2'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_3'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_4'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_5'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_C'</span></span>,<span class="hljs-string"><span class="hljs-string">'STATUS_X'</span></span>,] buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_COUNT'</span></span>] = buro_grouped_size buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MIN'</span></span>] = buro_grouped_min buro_counts_unstacked[<span class="hljs-string"><span class="hljs-string">'MONTHS_MAX'</span></span>] = buro_grouped_max​ buro = buro.join(buro_counts_unstacked, how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro_balance gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 有关征信机构的一般信息 </font></font></h3><br><pre> <code class="python hljs">buro.head()</code> </pre> <br><img src="https://habrastorage.org/webt/00/7q/dz/007qdzakfbvd5qiizsxqwxvoari.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（显示了前7列）</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">通常，您可以尝试使用One-Hot-Encoding进行简单地编码，按SK_ID_CURR分组，取平均值，并以相同的方式准备与主表的连接。</font></font><br><br><pre> <code class="python hljs">buro_cat_features = [bcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> bcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> buro.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> buro[bcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] buro = pd.get_dummies(buro, columns=buro_cat_features) avg_buro = buro.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_buro[<span class="hljs-string"><span class="hljs-string">'buro_count'</span></span>] = buro[[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count()[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_buro[<span class="hljs-string"><span class="hljs-string">'SK_ID_BUREAU'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> buro gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 有关先前申请的数据 </font></font></h3><br><pre> <code class="python hljs">prev.head()</code> </pre> <br><img src="https://habrastorage.org/webt/nx/sv/z-/nxsvz-simhdingy0zqgnwg9xxpi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 同样，我们对分类特征进行编码，对当前ID求平均值并合并。 </font></font><br><br><pre> <code class="python hljs">prev_cat_features = [pcol <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pcol <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> prev.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> prev[pcol].dtype == <span class="hljs-string"><span class="hljs-string">'object'</span></span>] prev = pd.get_dummies(prev, columns=prev_cat_features) avg_prev = prev.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() cnt_prev = prev[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).count() avg_prev[<span class="hljs-string"><span class="hljs-string">'nb_app'</span></span>] = cnt_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> prev gc.collect()</code> </pre> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 信用卡余额 </font></font></h3><br><pre> <code class="python hljs">POS_CASH.head()</code> </pre> <br><img src="https://habrastorage.org/webt/aq/25/er/aq25erq2wzuknck85ina4twk2g8.png"><br><br><pre> <code class="python hljs">POS_CASH.NAME_CONTRACT_STATUS.value_counts()</code> </pre> <br> <code>Active 9151119 <br> Completed 744883 <br> Signed 87260 <br> Demand 7065 <br> Returned to the store 5461 <br> Approved 4917 <br> Amortized debt 636 <br> Canceled 15 <br> XNA 2 <br> Name: NAME_CONTRACT_STATUS, dtype: int64</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 我们对分类特征进行编码，并准备要合并的表 </font></font><br><br><pre> <code class="python hljs">le = LabelEncoder() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(POS_CASH[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = POS_CASH[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] POS_CASH.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 卡数据 </font></font></h3><br><pre> <code class="python hljs">credit_card.head()</code> </pre> <br><img src="https://habrastorage.org/webt/q5/wj/pj/q5wjpj8s-vak-svacdtlhqrwlus.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（前7列）</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">类似的工作</font></font><br><br><pre> <code class="python hljs">credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] = le.fit_transform(credit_card[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>].astype(str)) nunique_status = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).nunique() nunique_status2 = credit_card[[<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>]].groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS'</span></span>] = nunique_status[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card[<span class="hljs-string"><span class="hljs-string">'NUNIQUE_STATUS2'</span></span>] = nunique_status2[<span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>] credit_card.drop([<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>, <span class="hljs-string"><span class="hljs-string">'NAME_CONTRACT_STATUS'</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 付款资料 </font></font></h3><br><pre> <code class="python hljs">payments.head()</code> </pre> <br><img src="https://habrastorage.org/webt/ay/fy/3y/ayfy3yp5tzdxsffurkrgjd4udwu.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（显示前7列）</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">让我们创建三个表-包含该表的平均值，最小值和最大值。</font></font><br><br><pre> <code class="python hljs">avg_payments = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean() avg_payments2 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).max() avg_payments3 = payments.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).min() <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_payments[<span class="hljs-string"><span class="hljs-string">'SK_ID_PREV'</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> payments gc.collect()</code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 表联接 </font></font></h3><br><pre> <code class="python hljs">data = data.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_prev.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)​ data = data.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_buro.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)​ data = data.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(POS_CASH.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)​ data = data.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(credit_card.groupby(<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>).mean().reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)​ data = data.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)​ data = data.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments2.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>)​ data = data.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) test = test.merge(right=avg_payments3.reset_index(), how=<span class="hljs-string"><span class="hljs-string">'left'</span></span>, on=<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> avg_prev, avg_buro, POS_CASH, credit_card, avg_payments, avg_payments2, avg_payments3 gc.collect() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, data.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, test.shape) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> (<span class="hljs-string"><span class="hljs-string">'  '</span></span>, y.shape)</code> </pre> <br> <code>   (307511, 504) <br>    (48744, 504) <br>    (307511,)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 而且，实际上，我们将通过梯度增强功能使这张桌子翻倍！ </font></font><br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LGBMClassifier​ clf2 = LGBMClassifier() clf2.fit(data, y)​ predictions = clf2.predict_proba(test)[:, <span class="hljs-number"><span class="hljs-number">1</span></span>]​ <span class="hljs-comment"><span class="hljs-comment">#    submission = test[['SK_ID_CURR']] submission['TARGET'] = predictions​ #   submission.to_csv('lightgbm_full.csv', index = False)</span></span></code> </pre> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">结果是0.770。</font></font></b> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">好的，最后，让我们尝试一种更复杂的技术，将其折叠，交叉验证并选择最佳迭代。</font></font><br><br><pre> <code class="python hljs">folds = KFold(n_splits=<span class="hljs-number"><span class="hljs-number">5</span></span>, shuffle=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">546789</span></span>) oof_preds = np.zeros(data.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) sub_preds = np.zeros(test.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>])​ feature_importance_df = pd.DataFrame()​ feats = [f <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data.columns <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [<span class="hljs-string"><span class="hljs-string">'SK_ID_CURR'</span></span>]]​ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n_fold, (trn_idx, val_idx) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(folds.split(data)): trn_x, trn_y = data[feats].iloc[trn_idx], y.iloc[trn_idx] val_x, val_y = data[feats].iloc[val_idx], y.iloc[val_idx] clf = LGBMClassifier( n_estimators=<span class="hljs-number"><span class="hljs-number">10000</span></span>, learning_rate=<span class="hljs-number"><span class="hljs-number">0.03</span></span>, num_leaves=<span class="hljs-number"><span class="hljs-number">34</span></span>, colsample_bytree=<span class="hljs-number"><span class="hljs-number">0.9</span></span>, subsample=<span class="hljs-number"><span class="hljs-number">0.8</span></span>, max_depth=<span class="hljs-number"><span class="hljs-number">8</span></span>, reg_alpha=<span class="hljs-number"><span class="hljs-number">.1</span></span>, reg_lambda=<span class="hljs-number"><span class="hljs-number">.1</span></span>, min_split_gain=<span class="hljs-number"><span class="hljs-number">.01</span></span>, min_child_weight=<span class="hljs-number"><span class="hljs-number">375</span></span>, silent=<span class="hljs-number"><span class="hljs-number">-1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">-1</span></span>, ) clf.fit(trn_x, trn_y, eval_set= [(trn_x, trn_y), (val_x, val_y)], eval_metric=<span class="hljs-string"><span class="hljs-string">'auc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">100</span></span>, early_stopping_rounds=<span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-comment"><span class="hljs-comment">#30 ) oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1] sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits fold_importance_df = pd.DataFrame() fold_importance_df["feature"] = feats fold_importance_df["importance"] = clf.feature_importances_ fold_importance_df["fold"] = n_fold + 1 feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0) print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx]))) del clf, trn_x, trn_y, val_x, val_y gc.collect()​ print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))​ test['TARGET'] = sub_preds​ test[['SK_ID_CURR', 'TARGET']].to_csv('submission_cross.csv', index=False)</span></span></code> </pre> <br> <code>Full AUC score 0.785845</code> <br> <br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">kaggle 0.783的最终得分</font></font></b> <br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 接下来要去哪里 </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">绝对会继续使用标志。浏览数据，选择一些标志，将它们组合，并以其他方式附加表格。您可以尝试使用超参数Mogheli-很多指南。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我希望这个小编着为您展示研究数据和准备预测模型的现代方法。学习数据，参加比赛，变酷！</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">并再次链接到帮助我编写本文的内核。这篇文章也以</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">笔记本电脑</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的形式发布在</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">Github上</font></a><font style="vertical-align: inherit;">，您可以下载它，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">数据集</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">并运行和试验。</font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">威尔·柯尔森。从这里开始：温和的介绍</font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">禁令。 HomeCreditRisk：广泛的EDA +基准[0.772]</font></font></a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Gabriel Preda. Home Credit Default Risk Extensive EDA</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Pavan Raj. Loan repayers v/s Loan defaulters — HOME CREDIT</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Lem Lordje Ko. 15 lines: Just EXT_SOURCE_x</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Shanth. HOME CREDIT — BUREAU DATA — FEATURE ENGINEERING</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Dmitriy Kisil. Good_fun_with_LigthGBM</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN414613/">https://habr.com/ru/post/zh-CN414613/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN414597/index.html">问伊森：外星文明可以接近多远？</a></li>
<li><a href="../zh-CN414601/index.html">当山高而笔记本电脑大时：更多的IT历史</a></li>
<li><a href="../zh-CN414605/index.html">迷你帝国</a></li>
<li><a href="../zh-CN414609/index.html">2018 PWA（Progressive Web Apps）能否与本地应用程序抗衡？</a></li>
<li><a href="../zh-CN414611/index.html">我在Unity和C＃中为一个女儿创建一个激励应用程序（iOS和Android）的故事</a></li>
<li><a href="../zh-CN414615/index.html">忘记GDPR：欧盟版权改革可能会彻底改变网络</a></li>
<li><a href="../zh-CN414617/index.html">计算资源效率</a></li>
<li><a href="../zh-CN414621/index.html">机器人系统加速血液采样和测试</a></li>
<li><a href="../zh-CN414625/index.html">数据中心世界：值得一游吗？</a></li>
<li><a href="../zh-CN414627/index.html">PH第8天的安全发展：PDUG社区会议结果</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
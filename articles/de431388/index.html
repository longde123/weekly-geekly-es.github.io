<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛤️ 👨🏽‍⚕️ 👩🏽‍🚀 Die Welt mit den Augen eines Autos. Wie sehen ihn Drohnen? 🦓 💇🏼 🙎🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Fortschritte bei unbemannten Fahrzeugen haben sich in den letzten Jahren rasant beschleunigt. Ab dem 1. Dezember 2018 können sich Drohnen auf öffe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Welt mit den Augen eines Autos. Wie sehen ihn Drohnen?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/toshibarus/blog/431388/"><img src="https://habrastorage.org/webt/zp/7p/ns/zp7pnsgx5lxppn-_wm-jtnatmjk.jpeg"><br><br>  Die Fortschritte bei unbemannten Fahrzeugen haben sich in den letzten Jahren rasant beschleunigt.  Ab dem 1. Dezember 2018 können sich Drohnen auf öffentlichen Straßen in Moskau und Tatarstan frei bewegen.  Es scheint, dass ein bisschen mehr und wir in das Auto steigen und unser eigenes Geschäft machen können, während unser Transport die Verwaltung des gesamten Fahrprozesses übernehmen wird.  Träume, Träume, aber wozu kann ein solches Auto wirklich fähig sein und wird es eine Person verdrängen? <br><a name="habracut"></a><br><h3>  Auf dem Weg zur vollen Autonomie </h3><br>  Die internationale Gemeinschaft der Automobilingenieure (SAE International) hat eine sechsstufige Klassifizierung der Autonomie von Autos entwickelt.  Dieses System zeigt den Weg, den Autos in den letzten Jahrzehnten zurückgelegt haben, und beschreibt die Schwierigkeiten, die noch gelöst werden müssen, um ein wirklich unbemanntes Fahrzeug zu schaffen. <br><br>  <b>Stufe 0</b> - keine Autonomie.  Alle Maschinen, die den Steuerungsprozess nicht stören, können dieser Ebene zugeordnet werden.  Ohne einen Mann rührt sich ein solches Auto nicht und kann einen Unfall nicht vermeiden.  ABS oder Parksensoren - das ist alles, was Sie von einem Auto mit Nullpegel erwarten können. <br><br>  <b>Level 1</b> - minimale Hilfe.  Beinhaltet Fahrzeuge, die das Lenken oder Beschleunigen / Bremsen unter ständiger Überwachung durch den Fahrer lenken können.  Dies schließt auch Parkassistenzsysteme ein, wenn das Auto fährt und der Fahrer in die Pedale tritt. <br><br>  <b>Stufe 2</b> - Unterstützung bei der Aufmerksamkeit des Fahrers.  Auf der zweiten Ebene gibt es eine vollständige Automatisierung einfacher Prozesse, die eine gleichzeitige automatische Lenkung und Bewegungssteuerung erfordern.  Dies umfasst erweiterte Advanced Driver Assistance Systems (ADAS). <br><br>  <b>Stufe 3</b> - begrenzter Autopilot.  Die Grenzebene, auf der bereits über einen vollwertigen Autopiloten gesprochen werden kann, der im Rahmen einzelner Szenarien arbeitet.  Im Gegensatz zu Autos der zweiten Stufe erfordern Autos der dritten Stufe keine ständige Aufmerksamkeit des Fahrers - eine Person kann ihren Geschäften nachgehen und nicht jede halbe Minute das Lenkrad greifen. <br><br>  <b>Level 4</b> - Autopilot in Städten.  Autos der vierten Ebene unterscheiden sich vom absoluten Autopiloten (5. Ebene) darin, dass sie 3D-Geländekarten benötigen, mit denen das Auto während der Fahrt überprüft und das Gelände gescannt wird.  Befindet sich das Auto der vierten Ebene in einem Bereich, der sich nicht auf solchen Karten befindet, wechselt der Autopilot in den Modus der dritten Ebene oder schaltet sich vollständig aus. <br><br>  <b>Stufe 5</b> - Vollautopilot.  Der gleiche kugelförmige Autopilot in einem Vakuum, der sich bei jedem Wetter und überall auf der Welt bewegen kann: Ob es sich um eine kaputte Straße ohne Markierung, eine Waldlichtung, einen schneebedeckten Gebirgspass oder eine geschäftige Metropole handelt - ein Autopilot der fünften Ebene wird überall hingehen und die Situation unterwegs analysieren.  Er braucht keine vorbereiteten 3D-Karten - ein autonomes Auto der fünften Stufe entspricht mit seinen Fähigkeiten einem lebenden Fahrer. <br><br><h2>  Wie funktionieren echte autonome Autos? </h2><br>  <b>Kamera + Bildprozessor</b> <br><br>  Bei der Entwicklung der ersten vollwertigen unbemannten Fahrzeuge waren Kameras die Hauptmethode, um den Raum um das Auto herum wahrzunehmen.  Sie ermöglichten es, schnell Bilder im sichtbaren Bereich mit einem weiten Betrachtungswinkel zu erhalten.  Ein einziges Kamerabild reicht jedoch nicht aus, damit das autonome Auto erfolgreich funktioniert. Eine Drohne benötigt ein elektronisches Analogon des menschlichen Gehirns, dh einen speziellen Bildverarbeitungsprozessor. <br><br>  Die Entwicklung solcher Prozessoren wird sowohl von großen erfahrenen Unternehmen als auch von Start-ups durchgeführt, so Mobileye, das Teil von Intel, NVIDIA, geworden ist.  Ähnliche Entwicklungen gibt es in Toshiba.  Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Toshiba Visconti-</a> Prozessorfamilie verarbeitet Bilder von vier Kameras und wertet die Bilder gleichzeitig nach verschiedenen Kriterien aus: Markierungen, sich bewegende und geparkte Autos, Ampeln und Schilder, Scheinwerfer, Fußgänger und Radfahrer.  Nach dem Identifizieren und Klassifizieren von Objekten auf Video überträgt der Prozessor Informationen an das „Gehirn“ der Maschine, deren Autopilot bereits über das optimale Verhalten entscheidet.  So funktioniert das erweiterte ADAS-Fahrerassistenzsystem und verhindert Kollisionen und Kollisionen mit Fußgängern (Autonomiekriterium der zweiten Ebene). <br><br><img src="https://habrastorage.org/webt/kc/or/j4/kcorj4rzgahl3exy3kmmvco2-dg.jpeg"><br>  <i>Ein Bündel von Kameras und ein Toshiba Visconti-Prozessor überwachen die Verkehrssituation besser und aufmerksamer als eine Person.</i>  <i>Quelle: Toshiba</i> <br><br>  Der gesamte Zyklus der früheren Generationen von Toshiba Visconti von der Bildaufnahme bis zur Ausgabe von Informationen mit Erkennungsergebnissen dauerte bis zu 100 ms.  In Visconti 4 wurde der Zyklus auf 50 ms reduziert.  Im besten Fall beträgt die Antwortzeit des Fahrers 500 ms.  Während dieser Zeit fährt ein Auto mit 80 km / h 11 Meter - eine lange Strecke im Falle einer gefährlichen Situation auf der Straße. <br><br>  Visconti löst auch das Problem des monokularen Sehens - der Prozessor kann eine dreidimensionale Rekonstruktion des Raums erstellen und die Abfolge der Bilder während der Bewegung analysieren.  Dies funktioniert sowohl für sich bewegende als auch für stationäre Objekte auf der Fahrbahn und darüber hinaus. <br><br>  <b>Radar</b> <br><br>  Die Kameras sind nicht in der Lage, entfernte Objekte zu erkennen und detaillierte Karten zu erstellen. Außerdem hängt ihre Funktionalität direkt von den Wetterbedingungen ab.  Diese Mängel können durch Radargeräte ausgeglichen werden, die Funksignale mit einer Frequenz von mehreren zehn Gigahertz aussenden.  Sie identifizieren idealerweise Hindernisse im Weltraum.  Radargeräte mit einer Frequenz von 24 GHz und 77 GHz werden bereits in teuren ADAS-Systemen zum frühen Bremsen verwendet, wenn der Schnittpunkt eines Kurses mit einem Fußgänger oder einem anderen Auto erkannt wird.  Im Gegensatz zu Kameras haben Radargeräte einen sehr engen Aktionswinkel, der umgekehrt proportional zum gewünschten Bereich ist.  Darüber hinaus hat das Radar hohe Kosten (in Höhe von 1.000 US-Dollar), was die Reichweite seiner Nutzung ausschließlich durch repräsentative und Premium-Autos sofort einschränkt. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/TcPcV8H-Qe8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Radargeräte können Objekte hervorragend lokalisieren, ohne jedoch ihre Form zu bestimmen, und dies nur in einem engen Bereich.</i> <br><br>  <b>Lidar</b> <br><br>  Lidare gelten als der effektivste, aber gleichzeitig umstrittenste Sensor für autonome Autos.  Sie erstellen mit Hilfe von Laserstrahlen, die von Hindernissen reflektiert werden und zurückkommen, ein detailliertes Bild der Welt um sie herum.  Darüber hinaus tun Lidars dies mit einer Genauigkeit, die für andere Sensoren unerreichbar ist.  Mit einem Lidar erstellt ein Auto eine eigene 3D-Karte, die mehrere zehn Meter entfernt ist und Autos, Personen und Hindernisse erkennt. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/E5K4yVP76xQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>So sieht die Welt ein Auto mit einem Lidar</i> <br><br>  Lidar hat jedoch mehr Mängel als Vorteile.  Erstens werden Lidars bei starkem Regen oder bei Schneefall hilflos - Laserstrahlen werden von Wassertropfen und Schneeflocken reflektiert.  Zweitens muss der Lidar eine vollständige Kreisansicht haben, was bedeutet, dass er einen "Buckel" auf dem Dach des Autos erzeugt.  Drittens sind Lidars nicht nur teuer, sondern auch sehr teuer: Frühe Velodyne-Modelle kosten 75.000 US-Dollar, moderne Waymo-Designs 7.500 US-Dollar. <br><br><img src="https://habrastorage.org/webt/ec/_w/b6/ec_wb6c6jqlvgoxl8uiit62eyoa.jpeg"><br>  <i>Die Linie der Lidars Velodyne.</i>  <i>Quelle: Velodyne</i> <br><br>  Das Auftreten von „Festkörper“ -Lidaren ohne bewegliche Teile dürfte die Kosten für Geräte in den kommenden Jahren um Größenordnungen senken.  Velodyne behauptet, einen Durchbruch erzielt zu haben, der den Preis für Lidars auf 50 US-Dollar senken wird. <br><br>  Toshiba wiederum arbeitet daran, die Wirksamkeit von Lidars zu verbessern.  In diesem Jahr wurde ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neuer Chip</a> eingeführt, der Ketten zur Analyse von Daten über große und kurze Entfernungen kombiniert.  Dies ermöglichte es uns, die effektive Reichweite von Lidaren auf 200 m zu verdoppeln und das Problem der Blendung zu beseitigen, das die Qualität der Reflexionen beeinträchtigte. <br><br><h3>  Wie funktioniert das für ... </h3><br>  <b>... Tesla</b> <b><br></b> <br>  Zur Implementierung des Autopiloten sind in Tesla-Fahrzeugen ein System aus acht Kameras mit unterschiedlichen Winkeln und Betrachtungsbereichen, 12 Ultraschallsensoren in einem Kreis und ein Frontalradar mit großer Reichweite installiert.  Ultraschallsensoren sind dafür verantwortlich, Autos in benachbarten Reihen und Hindernissen bei niedrigen Geschwindigkeiten zu erkennen.  Die Kameras sind dafür verantwortlich, Fußgänger, Autos, Markierungen und Schilder zu finden.  Hilft ihnen bei diesem Radar.  GPS wird verwendet, um sich entlang der Route zu bewegen, und Sensoren überwachen, dass das Auto ausschließlich auf Fahrspuren fährt und Unfälle vermeidet.  Auf diese Weise können Sie den Tesla-Autopiloten in allen Städten verwenden.  Andererseits erfordert der Autopilot für den Betrieb immer noch die Aufmerksamkeit des Fahrers. <br><br>  Tesla verwendet absichtlich kein Lidar, Elon Musk lehnt Lidars offen ab und begründet dies mit ihrem Preis und seiner problematischen Arbeit bei schlechtem Wetter.  Es ist schwer, ihm zu widersprechen - zusätzliche 7-10.000 Dollar zum Preis und ein „Buckel“ auf dem Dach würden Teslas Attraktivität nicht erhöhen. <br><br>  Egal wie gut eine Reihe von Kameras, Radar- und Ultraschallsensoren aussehen und sie haben Fehlfunktionen.  Im Jahr 2018 stürzte das Tesla Model S im Autopilot-Modus gegen einen Straßensplitter, der den Tod des Fahrers verursachte.  Wie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Untersuchung seitens der Besitzer des</a> Elektroautos ergab, konnte der Tesla-Autopilot die gelöschten Markierungen nicht korrekt lesen, und die Kameras und Radargeräte sahen wiederum keine Gefahr in der sich schnell nähernden Stahlbarriere. <br><br>  <b>... Waymo</b> <br><br>  Waymo-Systeme verwenden Lidar, fünf Radargeräte, acht Kameras und GPS. Chrysler Pacifica Hybrid (jetzt 600, 62.000 Einheiten sollen gekauft werden) und Jaguar I-PACE (20.000 Einheiten in Plänen) werden als serielle kommerzielle Carrier ausgewählt. <br><br><img src="https://habrastorage.org/webt/gx/cz/uu/gxczuutlgkbgne9vi4ut8lzzun0.jpeg"><br>  <i>Das Elektroauto Waymo Jaguar I-PACE ist nicht so nützlich wie der geräumige Chrysler Pacifica, aber es sieht fantastisch aus - selbst der Lidar auf dem Dach beeinträchtigt die Aussicht nicht.</i>  <i>Copyright: Waymo</i> <br><br>  Während der Fahrt verwendet Waymo Google Street View-Daten und verweist mit seinen Sensoren darauf.  Auf diese Weise wird eine vollständige Autonomie erreicht - im Gegensatz zu Tesla erfordern Waymo-Fahrzeuge keine Eingriffe des Fahrers, sondern befördern lediglich Passagiere.  Im Gegensatz zu Tesla verkauft Waymo keine Autos, sondern einen Transportdienst, dh Roboter. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/B8R148hFxPw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>  <i>Das Panorama-Video von Waymo hilft Ihnen zu verstehen, wie Ihr autonomes Auto Ihre Umgebung erkennt.</i> <br><br>  Der Hauptnachteil von Waymo ist die äußerst begrenzte Liste von Städten, in denen Drohnen eingesetzt werden. Damit der Autopilot ordnungsgemäß funktioniert, muss die städtische Umgebung in 3D aufgenommen werden. Dies ist ein langer und komplizierter Vorgang, sodass Waymo derzeit nur in zwei Dutzend amerikanischen Städten tätig ist.  Der Ausbau des Straßennetzes ist jedoch nur eine Frage der Zeit.  Hab eine tolle Zeit. <br><br>  <b>... Yandex</b> <br><br>  Yandex hat vor einem Jahr sein unbemanntes Fahrzeugprojekt vorgestellt.  Auf dem Toyota Prius wurde ein Block aus Lidar, Kameras, Radar, GPS und IMU installiert, dh Komponenten, die für autonome Autos typisch sind.  Von Yandex erhielt die Drohne eine Softwareplattform, die sich sowohl beim Fahren durch die engen Moskauer Straßen des Bezirks Khamovniki als auch auf langen Strecken von Moskau nach Kasan bewährt hat. <br><br>  In Tatarstan angekommen, blieb das Yandex-Auto dort und wurde das erste unbemannte Taxi in Russland.  Jetzt arbeitet er in der Stadt Innopolis und befördert Passagiere zwischen den fünf Hauptpunkten.  Und im Oktober erschien ein ähnliches Taxi auf dem Gebiet von Skolkovo.  In den fernen Plänen des Unternehmens, unbemannte Taxis auf kommerzieller Basis auf die Straßen der Stadt zu bringen. <br><br>  <b>... KAMAZ</b> <br><br>  2016 zeigte das NAMI State Institute den unbemannten „Kleinbus“ SHATL, der damals nichts weiter als ein experimentelles Konzeptauto war.  Zwei Jahre später wurde KAMAZ-1221 SHATL das zukünftige Produktionsprojekt angekündigt, das 2022 auf den Förderer gestellt wird.  Der Mini-Elektrobus mit Lidars, Kameras und Ultraschallsensoren bewegt sich bisher vorsichtig mit einer Geschwindigkeit von 10 km / h. Mit der Verbesserung der Softwareplattform wird jedoch eine Geschwindigkeit von bis zu 110 km / h versprochen. <br><br><h3>  Was werden Drohnen ändern? </h3><br>  Der Ausschluss des menschlichen Faktors erhöht die Randbetriebsbedingungen von Autos - erhöht die Höchstgeschwindigkeit, verringert die Breite der Fahrspuren, verringert den Abstand zwischen den Autos im Strom.  Infolgedessen wird der Straßendurchsatz erheblich zunehmen, die Durchschnittsgeschwindigkeit wird zunehmen und die Anzahl der Staus wird abnehmen. <br><br>  Laut dem American Highway Capacity Manual führt eine Spur der Autobahn pro Stunde an etwa 2.200 von Menschen angetriebenen Autos vorbei.  Verschiedene Studien zeigen, dass der Übergang zu autonomen Autos diese Zahl auf 7200-12000 Autos pro Stunde erhöhen wird.  Ein solch beeindruckender Sprung in der Effizienz der Straßennutzung wird erreicht, indem die sichere Geschwindigkeit erhöht und der Abstand zwischen den Fahrzeugen im Streifen von 40 bis 50 Metern auf 6 bis 7 Meter verringert wird. Für Fahrzeuge, die Informationen über ihre Geschwindigkeit und geschätzte Manöver untereinander übertragen, reicht ein solcher Abstand für die Sicherheit aus Bewegung. <br><br>  Wir sind jedoch noch weit von einer solchen unbemannten Zukunft entfernt.  Serienautos bekannter Autohersteller haben gerade die zweite Stufe der Autonomie angepasst, die besten und teuersten Modelle bereiten sich auf die dritte Stufe vor.  Aber im nächsten Jahrzehnt lohnt es sich nicht, von Drohnen der fünften Ebene der Autonomie zu träumen - für eine lange Zeit wird eine Person die Hauptperson auf der Straße sein. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431388/">https://habr.com/ru/post/de431388/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431376/index.html">Datenmigration im blutigen Unternehmen: Was zu analysieren ist, um das Projekt nicht zu überfordern</a></li>
<li><a href="../de431378/index.html">Die ganze Wahrheit über RTOS. Artikel 23. Warteschlangen: Einführung und Grundversorgung</a></li>
<li><a href="../de431380/index.html">Mitap Netologiya und Skyeng über Soft Skills „Was ein Entwickler außer Code wissen muss“</a></li>
<li><a href="../de431382/index.html">Ergebnisse der JVM-Ökosystemumfrage</a></li>
<li><a href="../de431384/index.html">CLion 2018.3: Remote-Entwicklung, Code-Profilerstellung, Leistung und mehr</a></li>
<li><a href="../de431390/index.html">Digitale Trends 2019 und ihre Auswirkungen auf das veränderte Verbraucherverhalten</a></li>
<li><a href="../de431392/index.html">Shamirs geheimes Austauschschema</a></li>
<li><a href="../de431394/index.html">Neugierige Perversionen aus der IT-Welt</a></li>
<li><a href="../de431396/index.html">Wie wir biometrische Kundendaten erfassen</a></li>
<li><a href="../de431398/index.html">Wie ich einen Hosting-Anbieter gehackt habe</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
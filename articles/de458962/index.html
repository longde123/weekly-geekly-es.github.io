<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎗️ 📑 🚘 Bild in Ton umwandeln - was können Sie hören? 🎱 🖕🏼 👈🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr. 

 In einer kürzlich hier auf der Website veröffentlichten Veröffentlichung wurde ein Gerät beschrieben, mit dem Blinde ein Bild „sehen“ u...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bild in Ton umwandeln - was können Sie hören?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458962/">  Hallo Habr. <br><br>  In einer kürzlich hier auf der Website veröffentlichten Veröffentlichung wurde ein Gerät beschrieben, mit dem Blinde ein Bild „sehen“ und mithilfe von Schallwellen transformieren können.  Aus technischer Sicht gab es in diesem Artikel keinerlei Details ( <s>was wäre, wenn die Idee für eine Million gestohlen würde</s> ), aber das Konzept selbst schien interessant zu sein.  Nachdem ich einige Erfahrungen mit der Signalverarbeitung gesammelt hatte, beschloss ich, selbst zu experimentieren. <br><br><img src="https://habrastorage.org/webt/ki/st/ip/kistiptqvnn-pmxshurxrawkqze.png"><br><br>  Was dabei herauskam, Details und Beispiele von Akten unter der Katze. <br><a name="habracut"></a><br><h2>  Konvertieren Sie 2D in 1D </h2><br>  Die erste offensichtliche Aufgabe, die uns erwartet, besteht darin, ein zweidimensionales „flaches“ Bild in eine „eindimensionale“ Schallwelle umzuwandeln.  Wie in den Kommentaren zu diesem Artikel vorgeschlagen, ist es zweckmäßig, hierfür <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Hilbert-Kurve</a> zu verwenden. <br><img src="https://habrastorage.org/webt/kk/n9/2o/kkn92oz48liofrdsozg5jamskcq.gif"><br>  Es ähnelt im Wesentlichen einem Fraktal, und die Idee ist, dass sich mit zunehmender Bildauflösung die relative Position der Objekte nicht ändert (wenn sich das Objekt in der oberen linken Ecke des Bildes befindet, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bleibt es dort</a> ).  Unterschiedliche Abmessungen von Hilbert-Kurven können zu unterschiedlichen Bildern führen: 32 x 32 für N = 5, 64 x 64 für N = 6 usw.  Wenn wir das Bild entlang dieser Kurve „herumlaufen“, erhalten wir eine Linie, ein eindimensionales Objekt. <br><br>  Die nächste Frage ist die Größe des Bildes.  Ich möchte intuitiv ein größeres Bild aufnehmen, aber es gibt ein großes „Aber“: Selbst das Bild ist 512 x 512, es ist 262144 Pixel.  Wenn wir jeden Punkt in einen Tonimpuls umwandeln, erhalten wir bei einer Abtastfrequenz von 44100 eine Sequenz von bis zu 6 Sekunden, und dies ist zu lang - die Bilder müssen schnell aktualisiert werden, beispielsweise mit einer Webkamera.  Es macht keinen Sinn, die Abtastrate zu erhöhen. Wir erhalten Ultraschallfrequenzen, die vom Ohr nicht gehört werden können (obwohl dies für eine Eule oder eine Fledermaus funktionieren könnte).  Infolgedessen wurde eine Auflösung <s>von</s> 128 x 128 <s>nach der Methode des wissenschaftlichen Stocherns gewählt</s> , die Impulse mit einer Länge von 0,37 c liefert. Zum einen ist es schnell genug, um in Echtzeit zu navigieren, zum anderen reicht es aus, Änderungen in der Form des Signals mit dem Ohr zu erfassen. <br><br><h2>  Bildverarbeitung </h2><br>  Der erste Schritt besteht darin, das Bild herunterzuladen, in Schwarzweiß umzuwandeln und auf die gewünschte Größe zu skalieren.  Die Bildgröße hängt von der Abmessung der Hilbert-Kurve ab. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> hilbertcurve.hilbertcurve <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> HilbertCurve <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.signal <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> butter, filtfilt <span class="hljs-comment"><span class="hljs-comment"># Create Hilbert curve dimension = 7 hilbert = HilbertCurve(dimension, n=2) print("Hilbert curve dimension:", dimension) # Maximum distance along curve print("Max_dist:", hilbert.max_h) # Maximum distance along curve print("Max_coord:", hilbert.max_x) # Maximum coordinate value in any dimension # Load PIL image f_name = "image01.png" img = Image.open(f_name) width, height = img.size out_size = hilbert_curve.max_x + 1 if width != out_size: img = img.resize((out_size, out_size), Image.ANTIALIAS) # Get image as grayscale numpy array img_grayscale = img.convert(mode='L') img_data = np.array(img_grayscale)</span></span></code> </pre> <br>  Der nächste Schritt ist die Bildung einer Schallwelle.  Hier kann es natürlich sehr viele Algorithmen und Know-how geben, für den Test habe ich gerade die Helligkeitskomponente genommen.  Natürlich gibt es wahrscheinlich bessere Möglichkeiten. <br><br><pre> <code class="python hljs">width, height = img_grayscale.size sound_data = np.zeros(width*height) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ii <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(width*height): coord_x, coord_y = hilbert_curve.coordinates_from_distance(ii) pixel_l = img_data[coord_x][coord_y] <span class="hljs-comment"><span class="hljs-comment"># Inverse colors (paper-like, white = 0, black = 255) pixel_l = 255 - pixel_l # Adjust values 0..255 to 0..8192 ampl = pixel_l*32 sound_data[ii] = ampl</span></span></code> </pre> <br>  Aus dem Code hoffe ich, dass alles klar ist.  Die Funktion koordinates_from_distance erledigt die gesamte Arbeit für uns, um die Koordinaten (x, y) in einen Abstand auf einer Hilbert-Kurve umzuwandeln. Wir invertieren und konvertieren den Helligkeitswert L in Farbe. <br><br>  Das ist noch nicht alles.  Weil  Das Bild enthält möglicherweise große Blöcke derselben Farbe. Dies kann zum Auftreten einer „Gleichstromkomponente“ im Ton führen - eine lange Reihe von Werten ungleich Null, z. B. [100, 100, 100, ...].  Um sie zu entfernen, wenden wir ein Hochpassfilter ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Butterworth-Filter</a> ) auf unser Array mit einer Grenzfrequenz von 50 Hz an (die Übereinstimmung mit der Netzwerkfrequenz ist zufällig).  In der Scipy-Bibliothek gibt es eine Synthese von Filtern, die wir verwenden werden. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">butter_highpass</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cutoff, fs, order=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> nyq = <span class="hljs-number"><span class="hljs-number">0.5</span></span> * fs normal_cutoff = cutoff / nyq b, a = butter(order, normal_cutoff, btype=<span class="hljs-string"><span class="hljs-string">'high'</span></span>, analog=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> b, a <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">butter_highpass_filter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, cutoff, fs, order=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> b, a = butter_highpass(cutoff, fs, order) y = filtfilt(b, a, data) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y <span class="hljs-comment"><span class="hljs-comment"># Apply high pass filter to remove dc component cutoff_hz = 50 sample_rate = 44100 order = 5 wav_data = butter_highpass_filter(sound_data, cutoff_hz, sample_rate, order)</span></span></code> </pre> <br>  Der letzte Schritt ist das Speichern des Bildes.  Weil  Die Länge eines Impulses ist kurz. Wir wiederholen ihn zehnmal. Er ist näher an einem sich wirklich wiederholenden Bild, beispielsweise von einer Webkamera, hörbarer. <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Clip data to int16 range sound_output = np.clip(wav_data, -32000, 32000).astype(np.int16) # Save repeat = 10 sound_output_ntimes = np.tile(sound_output, repeat) wav_name = "ouput.wav" scipy.io.wavfile.write(wav_name, sample_rate, sound_output_ntimes)</span></span></code> </pre> <br><h2>  Ergebnisse </h2><br>  Der obige Algorithmus ist natürlich ziemlich primitiv.  Ich wollte drei Punkte überprüfen - wie viel Sie zwischen verschiedenen einfachen Formen unterscheiden können und wie viel Sie den Abstand zu den Formen schätzen können. <br><br>  <b>Test 1</b> <br><br><img src="https://habrastorage.org/webt/ft/te/9m/ftte9mjfgwj6nib_lj76pfrqmre.png"><br><br>  Das Bild entspricht folgendem Tonsignal: <br><img src="https://habrastorage.org/webt/bd/gw/qu/bdgwquzss88fzb1s8hzyydf-das.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cloud.mail.ru/public/nt2R/2kwBvyRup</a> <br><br>  <b>Test 2</b> <br><br><img src="https://habrastorage.org/webt/vr/jt/6u/vrjt6ufndqzfdsywsgrpbnwlqiw.png"><br><br>  Die Idee dieses Tests ist es, den „Klang“ eines Objekts einer anderen Form zu vergleichen.  Tonsignal: <br><img src="https://habrastorage.org/webt/6z/bq/9a/6zbq9axxuoknevsj_iuxc94unre.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cloud.mail.ru/public/2rLu/4fCNRxCG2</a> <br><br>  Möglicherweise stellen Sie fest, dass der Klang wirklich anders ist und es einen Unterschied nach Gehör gibt. <br><br>  <b>Test 3</b> <br><br><img src="https://habrastorage.org/webt/cv/cp/3h/cvcp3h7itiq8srj-rs_j6ntb6lk.png"><br><br>  Die Idee des Tests ist es, ein kleineres Objekt zu testen.  Tonsignal: <br><img src="https://habrastorage.org/webt/yk/ra/x3/ykrax3udam03yphwwtlouygkgdk.png"><br><br>  WAV: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cloud.mail.ru/public/5GLV/2HoCHvoaY</a> <br><br>  Grundsätzlich gilt: Je kleiner das Objekt ist, desto weniger „Bursts“ treten im Klang auf, sodass die Abhängigkeit hier ziemlich direkt ist. <br><br>  <b>Bearbeiten:</b> <br><br>  Wie in den Kommentaren vorgeschlagen, können Sie die Fourier-Transformation verwenden, um Bilder direkt in Ton umzuwandeln.  Ein schneller Test zeigt die folgenden Ergebnisse (die Bilder sind die gleichen): <br>  Test 1: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cloud.mail.ru/public/2C5Z/5MEQ8Swjo</a> <br>  Test 2: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cloud.mail.ru/public/2dxp/3sz8mjAib</a> <br>  Test 3: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cloud.mail.ru/public/3NjJ/ZYrfdTYrk</a> <br><br>  Tests klingen interessant, zumindest für kleine und große Quadrate (Dateien 1 und 3), der Unterschied im Hören ist spürbar.  Die Form der Figuren (1 und 2) unterscheidet sich jedoch praktisch nicht, so dass es auch etwas zu überlegen gibt.  Aber im Allgemeinen gefällt mir der mit FFT erhaltene Klang nach Gehör besser. <br><br><h2>  Fazit </h2><br>  Dieser Test ist natürlich keine Dissertation, sondern lediglich ein Proof of Concept, der in wenigen Stunden Freizeit erstellt wurde.  Aber trotzdem funktioniert es im Grunde und es ist durchaus möglich, den Unterschied nach Gehör zu spüren.  Ich weiß nicht, ob es möglich ist, durch solche Geräusche hypothetisch, wahrscheinlich nach etwas Training, das Navigieren im Raum zu lernen.  Obwohl es ein großes Feld für Verbesserungen und Experimente gibt, können Sie beispielsweise Stereoton verwenden, mit dem Sie Objekte besser von verschiedenen Seiten trennen können. Sie können auch mit anderen Methoden experimentieren, um Bilder in Ton umzuwandeln, z. B. Farben mit unterschiedlichen Frequenzen codieren usw. Schließlich ist es vielversprechend die Verwendung von 3D-Kameras, die in der Lage sind, Tiefen wahrzunehmen (leider ist eine solche Kamera nicht verfügbar).  Übrigens kann mit Hilfe eines einfachen OpenCV-Codes der obige Algorithmus für die Verwendung einer Webkamera angepasst werden, mit der Sie mit dynamischen Bildern experimentieren können. <br><br>  Nun, wie immer alle erfolgreichen Experimente. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458962/">https://habr.com/ru/post/de458962/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458950/index.html">Analysieren von Async / Await in JavaScript mit Beispielen</a></li>
<li><a href="../de458952/index.html">Optimieren der PostgreSQL-Einstellungen zur Optimierung der Leistung</a></li>
<li><a href="../de458954/index.html">Welche Arten der Erkennung sind bei der Videoüberwachung nützlich? Mechanismen und Funktionen</a></li>
<li><a href="../de458956/index.html">Maschinelles Lernen vs. analytischer Ansatz</a></li>
<li><a href="../de458960/index.html">Unternehmensquest</a></li>
<li><a href="../de458964/index.html">TestMace. Schnellstart</a></li>
<li><a href="../de458966/index.html">Wissenschaftler und Leiter von Technologieunternehmen betrachten den Start von Industrieunternehmen in den Weltraum als Realität</a></li>
<li><a href="../de458970/index.html">Verwenden von UIViewPropertyAnimator zum Erstellen benutzerdefinierter Animationen</a></li>
<li><a href="../de458972/index.html">Nachrichten der Woche: Yandex und westliche Geheimdienste, FAS kämpft gegen Online-Casinos, Verkehrsministerium reguliert BlaBlaCar</a></li>
<li><a href="../de458974/index.html">Volles Leben auf Svelte</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
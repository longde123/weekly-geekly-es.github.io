<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî• üõ¢Ô∏è üôåüèº Hacks ao trabalhar com um grande n√∫mero de arquivos pequenos üíé ‚òùüèø ü§úüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A id√©ia do artigo nasceu espontaneamente de uma discuss√£o nos coment√°rios do artigo ‚ÄúAlgo sobre o inode‚Äù . 



 O fato √© que as especificidades intern...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Hacks ao trabalhar com um grande n√∫mero de arquivos pequenos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/srg/blog/462967/">  A id√©ia do artigo nasceu espontaneamente de uma discuss√£o nos coment√°rios do artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">‚ÄúAlgo sobre o inode‚Äù</a> . <br><br><img src="https://habrastorage.org/webt/ao/mn/mj/aomnmjglvkpfklyfa_vgdyonw70.png"><br><br>  O fato √© que as especificidades internas de nossos servi√ßos s√£o o armazenamento de um grande n√∫mero de arquivos pequenos.  No momento, temos cerca de centenas de terabytes desses dados.  E nos deparamos com alguns √≥bvios e n√£o muito ancinhos, e caminhamos com sucesso sobre eles. <br><br>  Portanto, compartilho nossa experi√™ncia, talvez algu√©m venha a calhar. <br><a name="habracut"></a><br><h2>  Problema 1: "N√£o resta espa√ßo no dispositivo" </h2><br>  Como mencionado no artigo acima, o problema √© que existem blocos livres no sistema de arquivos, mas o inode acabou. <br><br>  Voc√™ pode verificar o n√∫mero de inodes usados ‚Äã‚Äãe livres com o <code>df -ih</code> : <br><br><img src="https://habrastorage.org/webt/vu/nw/80/vunw80lzvxvznckfvpu9ok9i5ha.png"><br><br>  N√£o vou recontar o artigo, enfim, existem dois blocos de dados diretamente no disco e blocos de meta-informa√ß√µes, eles tamb√©m s√£o inodes (n√≥ de √≠ndice).  Seu n√∫mero √© definido durante a inicializa√ß√£o do sistema de arquivos (estamos falando sobre ext2 e seus descendentes) e n√£o muda mais.  O saldo de blocos de dados e inodes √© calculado a partir dos dados m√©dios; no nosso caso, quando existem muitos arquivos pequenos, o saldo deve mudar para o n√∫mero de inodes - deve haver mais deles. <br><br>  O Linux j√° forneceu op√ß√µes com diferentes saldos, e todas essas configura√ß√µes pr√©-calculadas est√£o no arquivo <code>/etc/mke2fs.conf</code> . <br>  Portanto, durante a inicializa√ß√£o inicial do sistema de arquivos por meio do mke2fs, √© poss√≠vel especificar o perfil desejado. <br><br>  Aqui est√£o alguns exemplos do arquivo: <br><br><pre> <code class="json hljs"> small = { blocksize = 1024 inode_size = 128 inode_ratio = 4096 } big = { inode_ratio = 32768 } largefile = { inode_ratio = 1048576 blocksize = -1 }</code> </pre><br>  Voc√™ pode selecionar o caso de uso desejado com a op√ß√£o -T ao chamar mke2fs.  Voc√™ tamb√©m pode definir manualmente os par√¢metros necess√°rios se n√£o houver uma solu√ß√£o pronta. <br><br>  Mais detalhes s√£o descritos nos manuais para <code>mke2fs.conf</code> e <code>mke2fs</code> . <br><br>  Um recurso n√£o mencionado no artigo mencionado acima - voc√™ pode definir o tamanho do bloco de dados.  Obviamente, para arquivos grandes, faz sentido ter um tamanho de bloco maior, para arquivos pequenos - em um menor. <br><br>  No entanto, vale a pena considerar um recurso t√£o interessante quanto a arquitetura do processador. <br>  Certa vez, pensei que precisava de um tamanho de bloco maior para arquivos de fotos grandes.  Estava em casa, no nome do arquivo inicial WD na arquitetura ARM.  Sem hesitar, defino o tamanho do bloco como 8k ou 16k em vez do padr√£o 4k, tendo medido previamente a economia.  E tudo foi maravilhoso exatamente at√© o momento em que o armazenamento em si n√£o falhou, enquanto o disco estava ativo.  Depois de colocar o disco em um computador comum com um processador Intel comum, tive uma surpresa: tamanho de bloco n√£o suportado.  Navegou.  H√° dados, est√° tudo bem, mas imposs√≠vel de ler.  Os processadores i386 e similares n√£o sabem como trabalhar com tamanhos de bloco que n√£o correspondem ao tamanho da p√°gina de mem√≥ria, mas s√£o exatamente 4k.  Em geral, o caso terminou com o uso de utilit√°rios do espa√ßo do usu√°rio, tudo ficou lento e triste, mas os dados foram salvos.  Quem se importa - <code>fuseext2</code> no google o nome do utilit√°rio <code>fuseext2</code> .  Moral: ou pense com anteced√™ncia em todos os casos ou n√£o construa um super-her√≥i e use as configura√ß√µes padr√£o para donas de casa. <br><br>  UPD  De acordo com a observa√ß√£o do usu√°rio, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">berez esclarece</a> que para i386 o tamanho do bloco n√£o deve exceder 4k, mas n√£o precisa ser exatamente 4k, ou seja,  1k e 2k v√°lidos. <br><br>  Ent√£o, como resolvemos os problemas. <br><br>  Primeiro, encontramos um problema quando um disco com v√°rios terabytes estava cheio de dados e n√£o foi poss√≠vel refazer a configura√ß√£o do sistema de arquivos. <br><br>  Em segundo lugar, a decis√£o foi urgente. <br><br>  Como resultado, chegamos √† conclus√£o de que precisamos alterar o saldo reduzindo o n√∫mero de arquivos. <br>  Para reduzir o n√∫mero de arquivos, foi decidido colocar os arquivos em um arquivo comum.  Considerando nossas especificidades, colocamos todos os arquivos em um archive por um determinado per√≠odo de tempo e arquivamos a tarefa cron diariamente √† noite. <br><br>  Selecionou um arquivo zip.  Nos coment√°rios ao artigo anterior, o tar foi proposto, mas h√° uma complica√ß√£o: ele n√£o possui um √≠ndice e os arquivos s√£o encadeados (por um motivo, "tar" √© uma abrevia√ß√£o de "Tape Archive", um legado de unidades de fita), ou seja, .  se voc√™ precisar ler o arquivo no final do arquivo morto, precisar√° ler todo o arquivo morto, pois n√£o h√° deslocamentos para cada arquivo em rela√ß√£o ao in√≠cio do arquivo morto.  E, portanto, √© uma opera√ß√£o longa.  No zip, tudo √© muito melhor: possui o mesmo √≠ndice e compensa√ß√µes de arquivos dentro do arquivo morto, e o tempo de acesso a cada arquivo n√£o depende de sua localiza√ß√£o.  Bem, no nosso caso, foi poss√≠vel definir a op√ß√£o de compacta√ß√£o como "0", porque todos os arquivos j√° haviam sido compactados no gzip anteriormente. <br><br>  Os clientes passam os arquivos pelo nginx e, de acordo com a API antiga, apenas o nome do arquivo √© especificado, por exemplo, assim: <br><br><pre> <code class="plaintext hljs">http://www.server.com/hydra/20170416/0453/3bd24ae7-1df4-4d76-9d28-5b7fcb7fd8e5</code> </pre><br>  Para descompactar arquivos em tempo real, encontramos e conectamos o m√≥dulo nginx-unzip-module ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/youzee/nginx-unzip-module</a> ) e configuramos dois upstream. <br><br>  O resultado √© esta configura√ß√£o: <br><br><img src="https://habrastorage.org/webt/l1/q5/hm/l1q5hmgkz1ljq4qlnsyheuk9vsk.png"><br><br>  Dois hosts nas configura√ß√µes ficaram assim: <br><br><pre> <code class="json hljs">server { listen *:<span class="hljs-number"><span class="hljs-number">8081</span></span>; location / { root /home/filestorage; } }</code> </pre> <br><pre> <code class="json hljs">server { listen *:<span class="hljs-number"><span class="hljs-number">8082</span></span>; location ~ ^/hydra/(\d+)/(\d+)/(.*)$ { root /home/filestorage; file_in_unzip_archivefile <span class="hljs-attr"><span class="hljs-attr">"/home/filestorage/hydra/$1/$2.zip"</span></span>; file_in_unzip_extract <span class="hljs-attr"><span class="hljs-attr">"$2/$3"</span></span>; file_in_unzip; } }</code> </pre><br>  E a configura√ß√£o upstream no nginx upstream: <br><br><pre> <code class="json hljs">upstream storage { server server.com:<span class="hljs-number"><span class="hljs-number">8081</span></span>; server server.com:<span class="hljs-number"><span class="hljs-number">8082</span></span>; }</code> </pre><br>  Como funciona: <br><br><ul><li>  O cliente vai para a frente nginx </li><li>  O nginx frontal tenta fornecer o arquivo do primeiro upstream, ou seja,  diretamente do sistema de arquivos </li><li>  Se n√£o houver arquivo, ele tenta fornec√™-lo a partir do segundo upstream, que tenta encontrar o arquivo dentro do arquivo morto. </li></ul><br><h2>  O segundo problema: novamente, "N√£o resta espa√ßo no dispositivo" </h2><br>  Esse √© o segundo problema que encontramos quando h√° muitos arquivos no diret√≥rio. <br>  Estamos tentando criar um arquivo, o sistema jura que n√£o h√° espa√ßo.  Mude o nome do arquivo e tente cri√°-lo novamente. <br><br>  Acontece. <br><br>  Parece algo como isto: <br><br><img src="https://habrastorage.org/webt/ab/rm/-t/abrm-tjedr5yhbypoyzymrkbwsy.jpeg"><br><br>  A verifica√ß√£o de inodes n√£o deu nada - h√° muitos deles gratuitos. <br>  Verificar o local √© o mesmo. <br>  Pensamos que poderia haver muitos arquivos no diret√≥rio, mas h√° um limite para isso, mas novamente n√£o: N√∫mero m√°ximo de arquivos por diret√≥rio: ~ 1,3 √ó 10 ^ 20 <br><br>  Sim, e voc√™ pode criar um arquivo se alterar o nome. <br>  A conclus√£o √© um problema no nome do arquivo. <br><br>  Pesquisas posteriores mostraram que o problema est√° no algoritmo de hash ao construir o √≠ndice de diret√≥rio. Com um grande n√∫mero de arquivos, h√° colis√µes com todas as conseq√º√™ncias resultantes.  Mais detalhes podem ser encontrados aqui: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://ext4.wiki.kernel.org/index.php/Ext4_Disk_Layout#Hash_Tree_Directories</a> <br><br>  Voc√™ pode desativar esta op√ß√£o, mas ... procurar um arquivo por nome pode se tornar imprevisivelmente longo ao classificar todos os arquivos. <br><br><pre> <code class="bash hljs"> tune2fs -O <span class="hljs-string"><span class="hljs-string">"^dir_index"</span></span> /dev/sdb3</code> </pre><br>  Em geral, como uma solu√ß√£o alternativa pode funcionar. <br><br>  Moral: muitos arquivos em um diret√≥rio geralmente s√£o ruins.  Isto n√£o √© necess√°rio. <br><br>  Geralmente, nesses casos, eles criam subdiret√≥rios, pelas primeiras letras do nome do arquivo ou por alguns outros par√¢metros, por exemplo, por datas, na maioria dos casos, isso salva. <br>  Mas o n√∫mero total de arquivos pequenos ainda √© ruim, mesmo que sejam divididos em diret√≥rios - e veja o primeiro problema. <br><br><h2>  O terceiro problema: como ver a lista de arquivos, se houver muitos deles </h2><br>  Em nossa situa√ß√£o, quando temos muitos arquivos, de uma forma ou de outra, nos deparamos com o problema de como visualizar o conte√∫do do diret√≥rio. <br><br>  A solu√ß√£o padr√£o √© o <code>ls</code> . <br>  Ok, vamos ver o que acontece nos arquivos 4772098: <br><br><pre> <code class="bash hljs">$ time ls /home/app/express.repository/offercache/ &gt;/dev/null real 0m30.203s user 0m28.327s sys 0m1.876s</code> </pre><br>  30 segundos ... ser√° demais.  E na maioria das vezes leva para processar arquivos no espa√ßo do usu√°rio, e n√£o no kernel. <br><br>  Mas existe uma solu√ß√£o: <br><br><pre> <code class="bash hljs">$ time find /home/app/express.repository/offercache/ &gt;/dev/null real 0m3.714s user 0m1.998s sys 0m1.717s</code> </pre><br>  3 segundos  10 vezes mais r√°pido. <br>  Viva! <br><br>  <b>UPD</b> <br><br>  Uma solu√ß√£o ainda mais r√°pida do usu√°rio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" class="user_link">berez</a> √© desativar a classifica√ß√£o <code>ls</code> <br><br><pre> <code class="bash hljs">time ls -U /home/app/express.repository/offercache/ &gt;/dev/null real 0m2.985s user 0m1.377s sys 0m1.608s</code> </pre><br><br><h2>  O quarto problema: LA grande ao trabalhar com arquivos </h2><br>  Periodicamente, surge uma situa√ß√£o em que voc√™ precisa copiar um monte de arquivos de uma m√°quina para outra.  Ao mesmo tempo, o LA geralmente cresce de maneira irrealista, porque tudo depende do desempenho dos pr√≥prios discos. <br><br>  A coisa mais razo√°vel que voc√™ deseja √© usar um SSD.  Muito legal.  A √∫nica quest√£o √© o custo dos SSDs com v√°rios terabytes. <br><br>  Mas se os discos forem comuns, voc√™ precisar√° copiar os arquivos, e este tamb√©m √© um sistema de produ√ß√£o, em que a sobrecarga leva a exclama√ß√µes insatisfeitas dos clientes?  Existem pelo menos duas ferramentas √∫teis: <code>nice</code> e <code>ionice</code> . <br><br>  <code>nice</code> - reduz a prioridade do processo, respectivamente, o sheduler distribui mais intervalos de tempo para outros processos mais priorit√°rios. <br>  Em nossa pr√°tica, ajudou a definir bom como m√°ximo (19 √© a prioridade m√≠nima, -20 (menos 20) √© a m√°xima). <br><br>  <code>ionice</code> - ajusta a prioridade da entrada / sa√≠da (programa√ß√£o de E / S) <br><br>  Se voc√™ usa o RAID e precisa sincronizar repentinamente (ap√≥s uma reinicializa√ß√£o malsucedida ou precisar restaurar a matriz RAID ap√≥s a substitui√ß√£o do disco), em algumas situa√ß√µes, faz sentido reduzir a velocidade de sincroniza√ß√£o para que outros processos funcionem mais ou menos adequadamente.  Para fazer isso, o seguinte comando ajudar√°: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> 1000 &gt; /proc/sys/dev/raid/speed_limit_max</code> </pre><br><h2>  O quinto problema: como sincronizar arquivos em tempo real </h2><br>  Temos as mesmas quantidades enormes de arquivos que precisam ser copiados para um segundo servidor para evitar ... Os arquivos s√£o constantemente gravados; portanto, para ter um m√≠nimo de perdas, √© necess√°rio copi√°-los o mais r√°pido poss√≠vel. <br><br>  Solu√ß√£o padr√£o: Rsync sobre SSH. <br><br>  Essa √© uma boa op√ß√£o, a menos que voc√™ precise fazer uma vez a cada poucos segundos.  E h√° muitos arquivos.  Mesmo que voc√™ n√£o os copie, voc√™ ainda precisa entender de alguma forma o que mudou e comparar v√°rios milh√µes de arquivos √© o tempo e a carga nos discos. <br><br>  I.e.  precisamos saber imediatamente o que copiar, sem iniciar a compara√ß√£o todas as vezes. <br><br>  Salva√ß√£o - <code>lsyncd</code> .  <code>Lsyncd</code> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Daemon de sincroniza√ß√£o ao vivo (espelho)</a> .  Ele tamb√©m funciona atrav√©s do rsync, mas monitora adicionalmente o sistema de arquivos em busca de altera√ß√µes usando inotify e fsevents e come√ßa a copiar apenas os arquivos que apareceram ou foram alterados. <br><br><h2>  O sexto problema: como entender quem carrega os discos </h2><br>  Todo mundo provavelmente sabe disso, mas, no entanto, por uma <code>iotop</code> integridade: para monitorar o subsistema de disco, existe o comando <code>iotop</code> - como <code>top</code> , mas mostra os processos que usam os discos mais ativamente. <br><br><img src="https://habrastorage.org/webt/la/kj/hu/lakjhuoxiy2nge-vjg4mue3vtwc.png"><br><br>  A prop√≥sito, o bom e velho top tamb√©m deixa claro que h√° problemas com os discos ou n√£o.  Existem dois par√¢metros mais adequados para isso: <b>Load Average</b> e <b>IOwait</b> . <br><br><img src="https://habrastorage.org/webt/jo/vh/ns/jovhnsuoremnqzucgoqnagvkbcy.png"><br><br>  O primeiro mostra quantos processos est√£o na fila de servi√ßo, geralmente mais de 2 - algo j√° est√° dando errado.  Com a c√≥pia ativa em servidores de backup, permitimos de 6 a 8, ap√≥s o que a situa√ß√£o √© considerada anormal. <br><br>  O segundo √© o quanto o processador est√° ocupado com as opera√ß√µes do disco.  O IOwait&gt; 10% √© motivo de preocupa√ß√£o, embora em servidores com um perfil de carga espec√≠fico seja est√°vel de 40 a 50%, e essa √© realmente a norma. <br><br>  Termino aqui, embora provavelmente haja muitos pontos que n√£o tivemos que enfrentar, ficarei feliz em aguardar coment√°rios e descri√ß√µes de casos reais interessantes. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt462967/">https://habr.com/ru/post/pt462967/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt462957/index.html">Pr√≥s e contras: o limite de pre√ßo para .org ainda √© cancelado</a></li>
<li><a href="../pt462959/index.html">Processamento de linguagem natural de cheques on-line: um curso de li√ß√µes de m√°gica para um gato comum e outros problemas</a></li>
<li><a href="../pt462961/index.html">Data Science Digest (agosto de 2019)</a></li>
<li><a href="../pt462963/index.html">Usando a API de contexto no React para criar um tema de aplicativo global</a></li>
<li><a href="../pt462965/index.html">Levante o servidor 1c com a publica√ß√£o do banco de dados e servi√ßos da web no Linux</a></li>
<li><a href="../pt462969/index.html">Como as autoridades do Cazaquist√£o est√£o tentando encobrir seu fracasso com a introdu√ß√£o do certificado</a></li>
<li><a href="../pt462971/index.html">Usando declara√ß√µes let de vari√°veis ‚Äã‚Äãe recursos dos fechamentos resultantes em JavaScript</a></li>
<li><a href="../pt462977/index.html">Acelere os processos rotineiros de RH com RPA e BluePrism</a></li>
<li><a href="../pt462979/index.html">Folha de dicas para um trainee: solu√ß√£o passo a passo de problemas em uma entrevista no Google</a></li>
<li><a href="../pt462983/index.html">Voice for game dev: como desenvolvemos a busca por voz "Lovecraft World"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
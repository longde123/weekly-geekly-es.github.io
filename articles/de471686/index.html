<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíä üò© üëäüèΩ Wie AWS seine belastbaren Services zusammenstellt. Server- und Datenbankskalierung üö∏ üö¢ üåà</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wolken sind wie eine magische Kiste - Sie fragen, was Sie brauchen, und Ressourcen erscheinen einfach aus dem Nichts. Virtuelle Maschinen, Datenbanken...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie AWS seine belastbaren Services zusammenstellt. Server- und Datenbankskalierung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/471686/"> Wolken sind wie eine magische Kiste - Sie fragen, was Sie brauchen, und Ressourcen erscheinen einfach aus dem Nichts.  Virtuelle Maschinen, Datenbanken, ein Netzwerk - all das geh√∂rt nur Ihnen.  Es gibt andere Mieter der Wolke, aber in Ihrem Universum sind Sie der alleinige Herrscher.  Sie sind sicher, dass Sie immer die erforderlichen Ressourcen erhalten, Sie rechnen mit niemandem und bestimmen unabh√§ngig, wie das Netzwerk aussehen wird.  Wie ist diese Magie, die die Cloud dazu bringt, Ressourcen elastisch zuzuweisen und Mandanten vollst√§ndig voneinander zu isolieren? <br><br><img src="https://habrastorage.org/webt/95/t7/1o/95t71ogmxhqysjnhwbqd_nbj4tk.jpeg"><br><br>  AWS Cloud ist ein hochentwickeltes System, das sich seit 2006 weiterentwickelt hat.  Ein Teil dieser Entwicklung wurde von <strong>Vasily Pantyukhin</strong> , Architekt von Amazon Web Services, gefunden.  Als Architekt sieht er nicht nur das Endergebnis, sondern auch die Herausforderungen, die AWS bew√§ltigt.  Je besser das System verstanden wird, desto mehr Vertrauen entsteht.  Daher wird Vasily die Geheimnisse der AWS-Cloud-Services weitergeben.  Unter dem Schnitt sind das Ger√§t f√ºr physische AWS-Server, die flexible Skalierbarkeit der Datenbank, die benutzerdefinierte Datenbank von Amazon und Methoden zur Steigerung der Leistung virtueller Maschinen bei gleichzeitiger Senkung des Preises.  Wenn Sie die Architekturans√§tze von Amazon kennen, k√∂nnen Sie die AWS-Services besser nutzen und neue Ideen f√ºr die Erstellung eigener L√∂sungen liefern. <br><a name="habracut"></a><br>  <i>√úber den Sprecher: Vasily Pantyukhin ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Hen</a> ) begann als Unix-Administrator in.ru-Unternehmen, arbeitete 6 Jahre lang in gro√üen Sun Microsystem-Dr√ºsen und predigte 11 Jahre lang die Datenzentriertheit der Welt in EMC.</i>  <i>Nat√ºrlich zu privaten Clouds entwickelt und 2017 zu √∂ffentlichen Clouds.</i>  <i>Jetzt mit technischen Tipps hilft er, in der AWS-Cloud zu leben und sich zu entwickeln.</i> <i><br><br></i>  <i>Haftungsausschluss: Alles, was unten steht, ist Vasilys pers√∂nliche Meinung und stimmt m√∂glicherweise nicht mit der Position von Amazon Web Services √ºberein.</i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ein Video des</a> Berichts, auf dessen Grundlage der Artikel erstellt wurde, ist auf unserem YouTube-Kanal verf√ºgbar.</i> <br><br><h2>  Warum spreche ich √ºber ein Amazon-Ger√§t? </h2><br>  Mein erstes Auto hatte einen ‚ÄûGriff‚Äú - an einem Schaltgetriebe.  Es war gro√üartig, weil ich das Gef√ºhl hatte, die Maschine steuern und vollst√§ndig steuern zu k√∂nnen.  Mir hat auch gefallen, dass ich das Prinzip ihrer Arbeit zumindest grob verstehe.  Nat√ºrlich habe ich mir das Boxger√§t ganz primitiv vorgestellt - ungef√§hr wie ein Getriebe auf einem Fahrrad. <br><br><img src="https://habrastorage.org/webt/t-/zx/uz/t-zxuzgpa2gj26bmpgbe1gj_zd0.jpeg"><br><br>  Alles war wunderbar, bis auf eine Sache - im Stau stehen.  Es scheint, als ob Sie sitzen und nichts tun, aber Sie schalten st√§ndig die G√§nge, dr√ºcken die Kupplung, das Gas, die Bremse - Sie werden es wirklich leid.  Das Problem der Staus wurde teilweise gel√∂st, als eine Maschine auf der Maschine in der Familie erschien.  Am Steuer war Zeit, √ºber etwas nachzudenken und ein H√∂rbuch zu h√∂ren. <br><br>  In meinem Leben tauchte ein R√§tsel auf, weil ich im Allgemeinen nicht mehr verstand, wie mein Auto funktioniert.  Ein modernes Auto ist ein komplexes Ger√§t.  Das Auto passt sich gleichzeitig Dutzenden verschiedener Parameter an: Dr√ºcken des Gases, Bremse, Fahrstil, Stra√üenqualit√§t.  Ich verstehe nicht mehr, wie das funktioniert. <br><br>  Als ich anfing, Amazon Cloud zu machen, war mir das auch ein R√§tsel.  Nur dieses Geheimnis ist um eine Gr√∂√üenordnung h√∂her, weil sich ein Fahrer im Auto befindet und es Millionen in AWS gibt.  Alle Benutzer lenken gleichzeitig, dr√ºcken auf Gas und bremsen.  Es ist erstaunlich, dass sie gehen, wo sie wollen - f√ºr mich ist es ein Wunder!  Das System passt sich automatisch an jeden Benutzer an, skaliert ihn und passt ihn flexibel an, sodass er den Eindruck hat, dass er allein in diesem Universum ist. <br><br>  Die Magie l√∂ste sich ein wenig auf, als ich sp√§ter als Architekt bei Amazon arbeitete.  Ich habe gesehen, mit welchen Problemen wir konfrontiert sind, wie wir sie l√∂sen, wie wir Dienstleistungen entwickeln.  Mit zunehmendem Verst√§ndnis des Systems steigt das Vertrauen in den Service.  Daher m√∂chte ich ein Bild davon teilen, was sich unter der Haube der AWS-Cloud befindet. <br><br><h2>  Wor√ºber werden wir reden? </h2><br>  Ich habe mich f√ºr einen diversifizierten Ansatz entschieden - ich habe 4 interessante Dienste ausgew√§hlt, √ºber die es sich zu sprechen lohnt. <br><br>  <strong>Serveroptimierung</strong> .  Verg√§ngliche Wolken mit einer physischen Ausf√ºhrungsform: physische Rechenzentren, in denen physische Server summen, sich erw√§rmen und Gl√ºhbirnen blinken. <br><br>  <strong>Serverlose Funktionen</strong> (Lambda) sind wahrscheinlich der skalierbarste Dienst in der Cloud. <br><br>  <strong>Datenbankskalierung</strong> .  Ich werde dar√ºber sprechen, wie wir unsere eigenen skalierbaren Datenbanken erstellen. <br><br>  <strong>Netzwerkskalierung</strong> .  Der letzte Teil, in dem ich das Ger√§t unseres Netzwerks √∂ffnen werde.  Dies ist eine wunderbare Sache - jeder Benutzer der Cloud glaubt, dass er alleine in der Cloud ist und √ºberhaupt keine anderen Mieter sieht. <br><br><blockquote>  <i>Hinweis</i>  <i>Dieser Artikel konzentriert sich auf die Serveroptimierung und die Datenbankskalierung.</i>  <i>Die Netzwerkskalierung wird im n√§chsten Artikel erl√§utert.</i>  <i>Wo sind die serverlosen Funktionen?</i>  <i>Ein separates Protokoll kam √ºber sie heraus: ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mal, ja, gewagt.</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anboxing von Firecracker-Mikrovirtualen</a> . "</i>  <i>Es werden verschiedene Skalierungsmethoden beschrieben und die Firecracker-L√∂sung wird detailliert analysiert - eine Symbiose der besten Eigenschaften einer virtuellen Maschine und von Containern.</i> </blockquote><br><h2>  Server </h2><br>  Die Wolke ist verg√§nglich.  Aber diese Verg√§nglichkeit hat immer noch eine physische Verk√∂rperung - Server.  Anfangs war ihre Architektur klassisch.  Standard x86-Chipsatz, Netzwerkkarten, Linux, Xen-Hypervisor, auf dem virtuelle Maschinen ausgef√ºhrt werden. <br><br><img src="https://habrastorage.org/webt/hb/vt/ez/hbvtezxs1wc_ilzrlcorvx9qy4m.jpeg"><br><br>  Im Jahr 2012 hat eine solche Architektur ihre Arbeit gut gemacht.  Xen ist ein gro√üartiger Hypervisor, aber mit einem gro√üen Fehler.  Er hat einen ziemlich <strong>hohen Overhead f√ºr das Emulieren von Ger√§ten</strong> .  Mit dem Aufkommen neuer schnellerer Netzwerkkarten oder SSDs werden diese Overheads zu hoch.  Wie gehe ich mit diesem Problem um?  Wir haben uns entschlossen, an zwei Fronten gleichzeitig zu arbeiten - <strong>um sowohl die Hardware als auch den Hypervisor</strong> zu <strong>optimieren</strong> .  Die Aufgabe ist sehr ernst. <br><br><h3>  Optimierung von Eisen und Hypervisor </h3><br>  Alles auf einmal und gut zu machen wird nicht funktionieren.  Was ‚Äûgut‚Äú ist, war zun√§chst unverst√§ndlich. <br><blockquote>  Wir haben uns f√ºr einen evolution√§ren Ansatz entschieden - wir √§ndern ein wichtiges Element der Architektur und werfen es in die Produktion. </blockquote>  Wir treten auf alle Rechen, h√∂ren auf Beschwerden und Vorschl√§ge.  Dann √§ndern wir eine andere Komponente.  Daher √§ndern wir in kleinen Schritten die gesamte Architektur radikal, basierend auf dem Feedback und der Unterst√ºtzung der Benutzer. <br><br>  Die Transformation begann 2013 mit dem Schwierigsten - dem Netzwerk.  In <strong>C3-</strong> F√§llen wurde der Standard-Netzwerkkarte eine spezielle Network Accelerator-Karte hinzugef√ºgt.  Es wurde mit einem buchst√§blich kurzen Loopback-Kabel an der Frontplatte verbunden.  H√§sslich, aber in der Wolke nicht sichtbar.  Die direkte Interaktion mit der Hardware verbesserte jedoch die Jitter- und Netzwerkbandbreite grundlegend. <br><br>  Dann haben wir beschlossen, uns auf die Verbesserung des Zugriffs auf den EBS-Blockspeicher zu konzentrieren - Elastic Block Storage.  Dies ist eine Kombination aus Netzwerk und Speicher.  Die Schwierigkeit besteht darin, dass es keine M√∂glichkeit gab, Storage Accelerator-Hardware zu kaufen, wenn es auf dem Markt Network Accelerator-Karten gab.  Deshalb haben wir uns an das Startup <strong>Annapurna Labs</strong> gewandt, das spezielle ASIC-Chips f√ºr uns entwickelt hat.  Sie konnten Remote-EBS-Volumes als NVMe-Ger√§te verbinden. <br><br>  In <strong>C4-</strong> F√§llen haben wir zwei Probleme gel√∂st.  Zun√§chst haben wir die Grundlagen f√ºr die Zukunft mit vielversprechender, aber zu dieser Zeit neuer NVMe-Technologie umgesetzt.  Die zweite - entlastete den Zentralprozessor erheblich, indem die Verarbeitung von Anforderungen an EBS auf eine neue Karte √ºbertragen wurde.  Es hat sich als gut herausgestellt, und jetzt ist Annapurna Labs Teil von Amazon. <br><br>  Bis November 2017 wurde uns klar, dass es Zeit war, den Hypervisor selbst zu √§ndern. <br><blockquote>  Der neue Hypervisor wurde auf Basis modifizierter KVM-Kernelmodule entwickelt. </blockquote>  Dadurch konnten die Overhead-Kosten f√ºr die Emulation von Ger√§ten grundlegend gesenkt und direkt mit den neuen ASICs gearbeitet werden.  <strong>C5-</strong> Instanzen waren die ersten virtuellen Maschinen, unter deren Haube ein neuer Hypervisor ausgef√ºhrt wird.  Wir haben es <strong>Nitro genannt</strong> . <br><br><img src="https://habrastorage.org/webt/g6/x2/ri/g6x2rizybxczhu-ikt1pfulnpb0.jpeg">  <em>Die Entwicklung der Instanzen auf der Zeitachse.</em> <br><br>  Alle neuen Arten von virtuellen Maschinen, die seit November 2017 erscheinen, funktionieren auf diesem Hypervisor.  <strong>Iron Bare Metal-Instanzen haben keinen Hypervisor</strong> , werden aber auch als Nitro bezeichnet, da sie spezielle Nitro-Karten verwenden. <br><br>  In den n√§chsten zwei Jahren √ºberstieg die Anzahl der Arten von Nitro-Instanzen einige Dutzend: A1, C5, M5, T3 und andere. <br><br><img src="https://habrastorage.org/webt/vw/zf/as/vwzfasdjwxuuykoylco9bnmgqki.jpeg"><br>  <em>Arten von Instanzen.</em> <br><br><h3>  Wie moderne Nitroautos funktionieren </h3><br>  Sie bestehen aus drei Hauptkomponenten: einem Nitro-Hypervisor (siehe oben), einem Sicherheitschip und Nitro-Karten. <br><br>  <strong>Der Sicherheitschip ist</strong> direkt in das Motherboard integriert.  Es steuert viele wichtige Funktionen, z. B. das Laden des Host-Betriebssystems. <br><br>  <strong>Nitro-Karten</strong> - es gibt vier Arten von ihnen.  Alle werden von Annapurna Labs entwickelt und basieren auf g√§ngigen ASICs.  Ein Teil ihrer Firmware ist ebenfalls √ºblich. <br><br><img src="https://habrastorage.org/webt/fy/pf/pj/fypfpj1r-mpklkd-8ltiz-frjnc.jpeg"><br>  <em>Vier Arten von Nitrokarten.</em> <br><br>  Eine der Karten funktioniert mit <strong>einem</strong> <strong>VPC-</strong> <strong>Netzwerk</strong> .  Sie ist in <strong>virtuellen Maschinen</strong> als <strong>ENA-</strong> Netzwerkkarte <strong>- Elastic Network Adapter -</strong> sichtbar.  Es kapselt auch Datenverkehr, wenn er √ºber das physische Netzwerk √ºbertragen wird (wir werden im zweiten Teil des Artikels darauf eingehen), steuert die Firewall der Sicherheitsgruppen, ist f√ºr das Routing und andere Netzwerkaufgaben verantwortlich. <br><br>  Separate Karten funktionieren mit <strong>EBS-</strong> Blockspeicher und Festplatten, die in den Server integriert sind.  Sie werden virtuellen <strong>Gastmaschinen</strong> als <strong>NVMe-Adapter pr√§sentiert</strong> .  Sie sind auch f√ºr die Datenverschl√ºsselung und die Festplatten√ºberwachung verantwortlich. <br><br>  Das System aus Nitro-Karten, einem Hypervisor und einem Sicherheitschip ist in ein SDN oder <strong>Software Defined Network integriert</strong> .  Die Steuerkarte ist f√ºr die Verwaltung dieses Netzwerks verantwortlich (Steuerungsebene). <br><br>  Nat√ºrlich entwickeln wir weiterhin neue ASICs.  Zum Beispiel haben sie Ende 2018 den Inferentia-Chip ver√∂ffentlicht, der eine effizientere Arbeit mit maschinellen Lernaufgaben erm√∂glicht. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/i7/1w/7p/i71w7p7mu3pbl3ozaoczqmxirku.jpeg" width="500"></div><br>  <em>Inferentia-Prozessorchip f√ºr maschinelles Lernen.</em> <br><br><h2>  Skalierbare Datenbank </h2><br>  Die traditionelle Datenbank hat eine Schichtstruktur.  Wenn stark vereinfacht, werden die folgenden Ebenen unterschieden. <br><br><ul><li>  <strong>SQL</strong> - Client und Query Dispatcher arbeiten daran. </li><li>  <strong>Transaktionen</strong> sichern - hier ist alles klar, ACID und so weiter. </li><li>  Zwischenspeicherung durch Pufferpools. </li><li>  <strong>Protokollierung</strong> - <strong>Erm√∂glicht</strong> die Arbeit mit Redo-Protokollen.  In MySQL hei√üen sie Bin Logs, in PosgreSQL Write Ahead Logs (WAL). </li><li>  <strong>Speicher</strong> - direkt auf die Festplatte schreiben. </li></ul><br><img src="https://habrastorage.org/webt/5x/xv/ay/5xxvay0jy9xyewxzi1py1q9rhei.jpeg"><br>  <em>Schichtdatenbankstruktur.</em> <br><br>  Es gibt verschiedene M√∂glichkeiten, Datenbanken zu skalieren: Sharding, Shared Nothing-Architektur, Shared Drive. <br><br><img src="https://habrastorage.org/webt/ao/pq/sf/aopqsfjiytwkbunwwni-wia5mzu.jpeg"><br><br>  Alle diese Methoden behalten jedoch dieselbe monolithische Datenbankstruktur bei.  Dies schr√§nkt die Skalierung erheblich ein.  Um dieses Problem zu l√∂sen, haben wir unsere eigene Datenbank entwickelt - <strong>Amazon Aurora</strong> .  Es ist kompatibel mit MySQL und PostgreSQL. <br><br><h3>  Amazon Aurora </h3><br>  Die Hauptidee der Architektur besteht darin, die Speicher- und Protokollierungsebenen von der Hauptdatenbank zu trennen. <br><br>  Mit Blick auf die Zukunft m√∂chte ich sagen, dass wir auch die Cache-Ebene unabh√§ngig gemacht haben.  Architektur h√∂rt auf, ein Monolith zu sein, und wir erhalten zus√§tzliche Freiheitsgrade bei der Skalierung einzelner Bl√∂cke. <br><br><img src="https://habrastorage.org/webt/31/a1/4_/31a14_4d4o0pvrk_23aj-obbiew.jpeg"><br>  <em>Protokollierungs- und Speicherebenen sind von der Datenbank getrennt.</em> <br><br>  Ein herk√∂mmliches DBMS schreibt Daten in Form von Bl√∂cken in das Speichersystem.  Bei Amazon Aurora haben wir ein ‚Äûintelligentes‚Äú Repository erstellt, das die Sprache von <strong>Redo-Logs</strong> sprechen kann.  Im Inneren wandelt das Repository Protokolle in Datenbl√∂cke um, √ºberwacht deren Integrit√§t und sichert automatisch. <br><br>  Mit diesem Ansatz k√∂nnen Sie interessante Dinge wie das <strong>Klonen</strong> implementieren.  Es funktioniert grundlegend schneller und wirtschaftlicher, da nicht alle Daten vollst√§ndig erstellt werden m√ºssen. <br><br>  Die Speicherebene ist als verteiltes System implementiert.  Es besteht aus einer sehr gro√üen Anzahl physischer Server.  Jedes Redo-Log wird gleichzeitig von <strong>sechs Knoten</strong> verarbeitet und gespeichert.  Dies bietet Datenschutz und Lastausgleich. <br><br><img src="https://habrastorage.org/webt/uv/up/rg/uvuprghc30bpo190-fjgb3w5pm8.jpeg"><br><br>  Die Leseskalierung kann mit geeigneten Replikaten erreicht werden.  Durch verteilten Speicher entf√§llt die Notwendigkeit einer Synchronisierung zwischen der Haupt-DB-Instanz, √ºber die Daten geschrieben werden, und anderen Replikaten.  Aktuelle Daten sind garantiert f√ºr alle Replikate verf√ºgbar. <br><br>  Das einzige Problem ist das Zwischenspeichern alter Daten in Lesereplikaten.  Dieses Problem wird jedoch gel√∂st, indem <strong>alle Redo-Logs</strong> auf Replikate im internen Netzwerk √ºbertragen werden.  Befindet sich das Protokoll im Cache, wird es als ung√ºltig markiert und √ºberschrieben.  Wenn es sich nicht im Cache befindet, wird es einfach verworfen. <br><br><img src="https://habrastorage.org/webt/8q/lt/hc/8qlthc7bqmxhqhja_ou4u3udjk4.jpeg"><br><br>  Wir haben den Speicher herausgefunden. <br><br><h3>  So skalieren Sie DBMS-Ebenen </h3><br>  Hier ist die horizontale Skalierung viel schwieriger.  Lassen Sie uns daher den ausgetretenen Pfaden der <strong>klassischen vertikalen Skalierung folgen</strong> . <br><br>  Angenommen, wir haben eine Anwendung, die √ºber einen Masterknoten mit einem DBMS kommuniziert. <br><br>  Bei der vertikalen Skalierung w√§hlen wir einen neuen Knoten mit mehr Prozessoren und Speicher aus. <br><br><img src="https://habrastorage.org/webt/ai/mn/if/aimnifftppplcs1mfg3n-zldlrk.jpeg"><br><br>  Wechseln Sie als N√§chstes die Anwendung vom alten Masterknoten zum neuen.  Es gibt Probleme. <br><br><ul><li>  Dies erfordert eine sp√ºrbare Ausfallzeit der Anwendung. </li><li>  Der neue Masterknoten verf√ºgt √ºber einen kalten Cache.  Die Datenbankleistung ist erst nach dem Aufw√§rmen des Caches maximal. </li></ul><br><img src="https://habrastorage.org/webt/k0/i-/jy/k0i-jy69brtsvclx0trwgjfuw0y.jpeg"><br><br>  Wie kann man die Situation verbessern?  F√ºgen Sie einen Proxy zwischen der Anwendung und dem Masterknoten ein. <br><br><img src="https://habrastorage.org/webt/ag/bk/c9/agbkc94ple_fti2xvyjinrb7mxu.jpeg"><br><br>  Was wird es uns geben?  Jetzt m√ºssen nicht mehr alle Anwendungen manuell auf einen neuen Knoten umgeleitet werden.  Das Umschalten kann unter einem Proxy und gleichzeitig wesentlich schneller erfolgen. <br><br>  Das Problem scheint gel√∂st zu sein.  Aber nein, wir leiden immer noch unter der Notwendigkeit, den Cache aufzuw√§rmen.  Au√üerdem ist ein neues Problem aufgetreten - jetzt ist der Proxy ein potenzieller Fehlerpunkt. <br><br><h3>  Endl√∂sung mit Amazon Aurora Serverless </h3><br>  Wie haben wir diese Probleme gel√∂st? <br><br>  <strong>Hat einen Proxy hinterlassen</strong> .  Dies ist keine separate Instanz, sondern eine ganze verteilte Flotte von Proxys, √ºber die Anwendungen eine Verbindung zur Datenbank herstellen.  Im Falle eines Fehlers kann jeder der Knoten fast sofort ersetzt werden. <br><br>  <strong>Wir haben einen Pool warmer Knoten verschiedener Gr√∂√üen hinzugef√ºgt</strong> .  Wenn Sie einen neuen Knoten mit einer gr√∂√üeren oder kleineren Gr√∂√üe ausw√§hlen m√ºssen, ist dieser sofort verf√ºgbar.  Sie m√ºssen nicht warten, bis es geladen ist. <br><br>  <strong>Der gesamte Skalierungsprozess wird von einem speziellen √úberwachungssystem gesteuert.</strong>  Die √úberwachung √ºberwacht st√§ndig den Status des aktuellen Masterknotens.  Wenn beispielsweise festgestellt wird, dass die Prozessorlast einen kritischen Wert erreicht hat, benachrichtigt es den Pool warmer Instanzen √ºber die Notwendigkeit, einen neuen Knoten zuzuweisen. <br><br><img src="https://habrastorage.org/webt/2r/ja/oq/2rjaoqe-tgjjv_nxbodwlibzkzc.jpeg"><br>  <em>Verteilte Proxys, Warminstanzen und √úberwachung.</em> <br><br>  Ein Knoten mit der erforderlichen Leistung ist verf√ºgbar.  Pufferpools werden darauf kopiert, und das System beginnt, auf einen sicheren Moment zum Umschalten zu warten. <br><br><img src="https://habrastorage.org/webt/hw/t4/nr/hwt4nruv3h9bdyyte_awfycnp1g.jpeg"><br><br>  Normalerweise kommt der Moment zum Umschalten schnell genug.  Dann wird die Kommunikation zwischen dem Proxy und dem alten Masterknoten unterbrochen, alle Sitzungen wechseln zum neuen Knoten. <br><br><img src="https://habrastorage.org/webt/pz/4f/cj/pz4fcjzipu0pep5pwwex6mb5kas.jpeg"><br><br>  Die Arbeit mit der Datenbank wird fortgesetzt. <br><br><img src="https://habrastorage.org/webt/sv/dl/kf/svdlkfp7ve6gzlomvdxulhmyjsy.jpeg"><br><br>  Die Grafik zeigt, dass die Federung wirklich sehr kurz ist.  Auf dem blauen Diagramm die Last und auf den roten Stufen - die Momente der Skalierung.  Kurzfristige Einbr√ºche im blauen Diagramm sind genau diese kurze Verz√∂gerung. <br><br><img src="https://habrastorage.org/webt/te/3p/4x/te3p4xzclr_3liuv-7gk2ocskey.jpeg"><br><br>  Mit Amazon Aurora k√∂nnen Sie die Datenbank √ºbrigens vollst√§ndig speichern und deaktivieren, wenn Sie sie beispielsweise am Wochenende nicht verwenden.  Nach dem Stoppen des Ladevorgangs verringert die Datenbank allm√§hlich ihre Leistung und schaltet sich f√ºr eine Weile aus.  Wenn die Last zur√ºckkehrt, steigt sie wieder gleichm√§√üig an. <br><br><blockquote>  Im n√§chsten Teil des Amazon-Ger√§tegespr√§chs werden wir uns mit der Netzwerkskalierung befassen.  Abonnieren Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Newsletter</a> und bleiben Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem Laufenden</a> , um den Artikel nicht zu verpassen. <br><br>  Bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad ++ wird</a> Vasily Pantyukhin einen Vortrag halten: ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Houston, wir haben ein Problem.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Design von Fehlersystemen, Muster f√ºr die Entwicklung interner Amazon Cloud-Dienste</a> . ‚Äú  Was Amazon-Designentwickler f√ºr verteilte Systemdesignmuster verwenden, was sind die Gr√ºnde f√ºr Servicefehler, was ist zellbasierte Architektur, konstante Arbeit, Shuffle Sharding - es wird interessant sein.  Weniger als einen Monat vor der Konferenz - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">buchen Sie Ihre Tickets</a> .  24. Oktober die endg√ºltige Preiserh√∂hung. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de471686/">https://habr.com/ru/post/de471686/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de471668/index.html">Technische Analyse des checkm8-Exploits</a></li>
<li><a href="../de471670/index.html">Versuchen Sie Jetpack Compose im Kampf?</a></li>
<li><a href="../de471676/index.html">Telefonbetr√ºger. Die zweite Aktion, bei der ich zusammenbreche und zum n√§chsten Geldautomaten renne</a></li>
<li><a href="../de471678/index.html">Tragen Sie Dienstleistungen auf Anfrage</a></li>
<li><a href="../de471684/index.html">Warum m√ºssen Sie Module f√ºr Nginx erstellen?</a></li>
<li><a href="../de471688/index.html">Wie AWS seine belastbaren Services zusammenstellt. Netzwerkskalierung</a></li>
<li><a href="../de471700/index.html">Wie ich einen technologischen Stack mit einer Grundlage f√ºr die Zukunft gew√§hlt habe</a></li>
<li><a href="../de471702/index.html">Cyber-erweiterte Webanwendungen</a></li>
<li><a href="../de471704/index.html">Das Buch ‚ÄûEgoistische Mitochondrien. Wie man die Gesundheit erh√§lt und das Alter bewegt "</a></li>
<li><a href="../de471706/index.html">9 typische Netzwerkprobleme, die mithilfe der NetFlow-Analyse erkannt werden k√∂nnen (am Beispiel Flowmon)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
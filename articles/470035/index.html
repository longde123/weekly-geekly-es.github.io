<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôçüèæ üòø üë®üèΩ‚Äçüç≥ Generador delirante: cree textos en cualquier idioma utilizando una red neuronal üë∏üèº ü§µüèæ üç£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr 

 Este art√≠culo estar√° en un formato un poco "viernes", hoy trataremos con PNL. No es la PNL sobre los libros que se venden en pasos inferi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Generador delirante: cree textos en cualquier idioma utilizando una red neuronal</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470035/">  Hola Habr <br><br>  Este art√≠culo estar√° en un formato un poco "viernes", hoy trataremos con PNL.  No es la PNL sobre los libros que se venden en pasos inferiores, sino la que procesa el lenguaje natural.  Como ejemplo de dicho procesamiento, se utilizar√° la generaci√≥n de texto usando una red neuronal.  Podemos crear textos en cualquier idioma, desde ruso o ingl√©s, hasta C ++.  Los resultados son muy interesantes, probablemente puedas adivinar a partir de la imagen. <br><br><img src="https://habrastorage.org/webt/vc/cy/we/vccywe4c6r0vbryvvx3qiale_j8.jpeg"><br><br>  Para aquellos que est√©n interesados ‚Äã‚Äãen lo que sucede, los resultados y el c√≥digo fuente est√°n por debajo. <br><a name="habracut"></a><br><h2>  Preparaci√≥n de datos </h2><br>  Para el procesamiento, utilizaremos una clase especial de redes neuronales: las llamadas redes neuronales recurrentes (RNN).  Esta red difiere de la habitual en que, adem√°s de las celdas habituales, tiene celdas de memoria.  Esto nos permite analizar datos de una estructura m√°s compleja y, de hecho, m√°s cercana a la memoria humana, porque tampoco comenzamos cada pensamiento "desde cero".  Para escribir c√≥digo, usaremos redes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LSTM</a> (memoria de corto plazo), ya que Keras ya las admite. <br><br><img src="https://habrastorage.org/webt/ay/ox/ou/ayoxourylcbidznetfkphgdv5ni.jpeg"><br><br>  El siguiente problema que debe resolverse es, de hecho, trabajar con texto.  Y aqu√≠ hay dos enfoques: enviar s√≠mbolos o palabras completas a la entrada.  El principio del primer enfoque es simple: el texto se divide en bloques cortos, donde las "entradas" son un fragmento del texto y la "salida" es el siguiente car√°cter.  Por ejemplo, para la √∫ltima frase, 'las entradas son un fragmento de texto': <br><br> <code>input:    output: "" <br> input:    : output: "" <br> input:    : output:"" <br> input:    : output: "" <br> input:    : output: "". <br></code> <br>  Y as√≠ sucesivamente.  Por lo tanto, la red neuronal recibe fragmentos de texto en la entrada y en la salida los caracteres que debe formar. <br><br>  El segundo enfoque es b√°sicamente el mismo, solo se usan palabras enteras en lugar de palabras.  Primero, se compila un diccionario de palabras y se ingresan n√∫meros en lugar de palabras en la entrada de la red. <br><br>  Esto, por supuesto, es una descripci√≥n bastante simplificada.  Keras <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ya tiene</a> ejemplos de generaci√≥n de texto, pero en primer lugar, no se describen con tanto detalle y, en segundo lugar, todos los tutoriales en ingl√©s usan textos bastante abstractos como Shakespeare, que son dif√≠ciles de entender para el nativo.  Bueno, estamos probando una red neuronal en nuestra gran y poderosa, que, por supuesto, ser√° m√°s clara y comprensible. <br><br><h2>  Entrenamiento de la red </h2><br>  Como texto de entrada, utilic√© ... los comentarios de Habr, el tama√±o del archivo fuente es de 1 MB (hay realmente m√°s comentarios, por supuesto, pero tuve que usar solo una parte, de lo contrario la red estar√≠a capacitada durante una semana y los lectores no ver√≠an este texto el viernes).  Perm√≠tame recordarle que solo las letras se alimentan a la entrada de una red neuronal, la red "no sabe" nada sobre el idioma o su estructura.  Vamos, comience el entrenamiento de la red. <br><br>  <b>5 minutos de entrenamiento:</b> <br><br>  Hasta ahora, nada est√° claro, pero ya puedes ver algunas combinaciones reconocibles de letras: <br><br> <code>                          .                   .                                                     .          ¬´                    <br></code> <br>  <b>15 minutos de entrenamiento:</b> <br><br>  El resultado ya es notablemente mejor: <br><br> <code>                                                                                                                                 <br></code> <br>  <b>1 hora de entrenamiento:</b> <br><br> <code>                                                                  ¬´ ¬ª ‚Äî                                                            ¬´     ¬ª ¬ª ‚Äî             </code> <br> <br>  Por alguna raz√≥n, todos los textos resultaron sin puntos y sin letras may√∫sculas, quiz√°s el procesamiento utf-8 no se realiz√≥ correctamente.  Pero en general, esto es impresionante.  Al analizar y recordar solo c√≥digos de s√≠mbolos, el programa realmente aprendi√≥ palabras rusas de forma "independiente" y puede generar un texto de aspecto bastante cre√≠ble. <br><br>  No menos interesante es el hecho de que el programa memoriza bastante bien el estilo del texto.  En el siguiente ejemplo, el texto de alguna ley se utiliz√≥ como ayuda para la ense√±anza.  Tiempo de entrenamiento en red 5 minutos. <br><br> <code>  ""  ,  ,  ,  ,  ,  , ,  ,                 <br></code> <br>  Y aqu√≠, las anotaciones m√©dicas para medicamentos se usaron como un conjunto de entrada.  Tiempo de entrenamiento en red 5 minutos. <br><br> <code>  <br>      <br>                                          ,    ,             <br></code> <br>  Aqu√≠ vemos frases casi enteras.  Esto se debe al hecho de que el texto original es corto y la red neuronal "memoriz√≥" algunas frases en su conjunto.  Este efecto se llama "reentrenamiento" y debe evitarse.  Idealmente, debe probar una red neuronal en grandes conjuntos de datos, pero la capacitaci√≥n en este caso puede llevar muchas horas, y desafortunadamente no tengo una supercomputadora adicional. <br><br>  Un ejemplo divertido de usar una red de este tipo es la generaci√≥n de nombres.  Despu√©s de cargar una lista de nombres masculinos y femeninos en el archivo, obtuve nuevas opciones bastante interesantes que ser√≠an bastante adecuadas para una novela de ciencia ficci√≥n: Rlar, Laaa, Aria, Arera, Aelia, Ninran, Air.  Algo en ellos siente el estilo de Efremov y la Nebulosa de Andr√≥meda ... <br><br><h2>  C ++ </h2><br>  Lo interesante es que, en general, una red neuronal es como recordar.  El siguiente paso fue verificar c√≥mo el programa maneja el c√≥digo fuente.  Como prueba, tom√© diferentes fuentes de C ++ y las combin√© en un solo archivo de texto. <br><br>  Honestamente, el resultado sorprendi√≥ a√∫n m√°s que en el caso del idioma ruso. <br><br>  <b>5 minutos de entrenamiento</b> <br><br>  Maldici√≥n, es casi real C ++. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( snd_pcm_state_channels = <span class="hljs-number"><span class="hljs-number">0</span></span> ) { errortext_ = <span class="hljs-string"><span class="hljs-string">"rtapialsa::probedeviceopen: esror stream_.buffer stream!"</span></span>; errortext_ = errorstream_.str(); <span class="hljs-keyword"><span class="hljs-keyword">goto</span></span> unlock; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( stream_.mode == input &amp;&amp; stream_.mode == output || <span class="hljs-literal"><span class="hljs-literal">false</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ( stream_.state == stream_stopped ) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;stream_.nuserbuffer[i] ) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (j=<span class="hljs-number"><span class="hljs-number">0</span></span>; j&lt;info.channels; } } }</code> </pre><br>  <b>30 minutos de entrenamiento</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> maxirecorder::stopstream() { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; ainchannels; i++ ) { <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> input=(stream, null; conternallock( pthread_cond_wate); <span class="hljs-comment"><span class="hljs-comment">// this should not ported to the device is a structure are is and the stream the buffer of the interleaved as and the probe the arauliored format for the the stream os and the software and the supported of the is so aa is set the directsound of allocates the reset and real the read the setup the buffer // this is the setup to the the devices. // asio will open the supported by the supported buffer are asioned structure. // this should not have to setup the counting and the proper in the position we mast it alw the aftware configuration. // this is the the stream and probe the supported be audio for sched/ond changed to this the sample rate it in the counting the fres // mecorend. windevoppart( null, 0, &amp;phase ); possint=&gt;buffersize( 1, bufferlist); } } } ///********************************************* void maxirecorder::abortdevice( device ) { if (cout &lt;&lt; aindeff( thread_cont_start); for (int i = 0; i &lt; sample_rates[0]) { if (count == int) { std::cout &lt;&lt; "checksing of convernion allocation handler (" &lt;&lt; device &lt;&lt; ")."; errortext_ = errorstream_.str(); return failure; } } } if ( stream_.userbuffer[i] ) { errortext_ = "rtapicore::probedeviceopen: system error (" &lt;&lt; geterrorcode( result ) &lt;&lt; ") getting stream configuration info state."; error( rterror::warning ); return; } if ( stream_.mode == output || stream_.mode == duplex ) { callbackinfo *info = (const char *) callback( stream_.userbuffer[1], stream_.convertinfo[0] ); return info; } // setup buffer callback for conversion on do any the supported be audio bet that al alinums be of support of the supported buffer // the buffer size a stream and buffers. info.name = dsdevices[ device ]; return 0; }</span></span></code> </pre> <br>  Como puede ver, el programa ha "aprendido" a escribir funciones completas.  Al mismo tiempo, separ√≥ completamente "humanamente" las funciones con un comentario con asteriscos, puso comentarios en el c√≥digo y todo eso.  Me gustar√≠a aprender un nuevo lenguaje de programaci√≥n con tanta velocidad ... Por supuesto, hay errores en el c√≥digo y, por supuesto, no se compilar√°.  Y, por cierto, no formate√© el c√≥digo, el programa tambi√©n aprendi√≥ a poner par√©ntesis y sangr√≠a "yo mismo". <br><br>  Por supuesto, estos programas no tienen el <i>significado</i> principal y, por lo tanto, se ven surrealistas, como si estuvieran escritos en un sue√±o o no fueron escritos por una persona completamente sana.  Sin embargo, los resultados son impresionantes.  Y quiz√°s un estudio m√°s profundo de la generaci√≥n de diferentes textos ayudar√° a comprender mejor algunas de las enfermedades mentales de pacientes reales.  Por cierto, como se sugiere en los comentarios, existe una enfermedad mental en la que una persona habla en un texto gramaticalmente relacionado pero completamente sin sentido ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esquizofasia</a> ). <br><br><h2>  Conclusi√≥n </h2><br>  Las redes neuronales recreativas se consideran muy prometedoras, y este es de hecho un gran paso adelante en comparaci√≥n con las redes "ordinarias" como MLP, que no tienen memoria.  De hecho, las capacidades de las redes neuronales para almacenar y procesar estructuras bastante complejas son impresionantes.  Fue despu√©s de estas pruebas que pens√© por primera vez que Ilon Mask probablemente ten√≠a raz√≥n en algo cuando escrib√≠ que la IA en el futuro podr√≠a ser "el mayor riesgo para la humanidad", incluso si una simple red neuronal puede recordar y reproducirse f√°cilmente patrones bastante complejos, ¬øqu√© puede hacer una red de miles de millones de componentes?  Pero, por otro lado, no olvide que nuestra red neuronal no puede <i>pensar</i> , esencialmente solo recuerda mec√°nicamente secuencias de caracteres, sin comprender su significado.  Este es un punto importante: incluso si entrena una red neuronal en una supercomputadora y un gran conjunto de datos, en el mejor de los casos aprender√° a generar oraciones gramaticalmente 100% correctas, pero completamente sin sentido. <br><br>  Pero no se eliminar√° en filosof√≠a, el art√≠culo es a√∫n m√°s para los profesionales.  Para aquellos que quieran experimentar por su cuenta, el <b>c√≥digo fuente</b> en Python 3.7 est√° bajo el spoiler.  Este c√≥digo es una compilaci√≥n de varios proyectos de github, y no es una muestra del mejor c√≥digo, pero parece realizar su tarea. <br><br>  El uso del programa no requiere habilidades de programaci√≥n, es suficiente saber c√≥mo instalar Python.  Ejemplos de comenzar desde la l√≠nea de comando: <br>  - Creaci√≥n y formaci√≥n de modelos y generaci√≥n de texto: <br>  python. \ keras_textgen.py --text = text_habr.txt --epochs = 10 --out_len = 4000 <br>  - Solo generaci√≥n de texto sin entrenamiento modelo: <br>  python. \ keras_textgen.py --text = text_habr.txt --epochs = 10 --out_len = 4000 --generate <br><br><div class="spoiler">  <b class="spoiler_title">keras_textgen.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-comment"><span class="hljs-comment"># Force CPU os.environ["CUDA_VISIBLE_DEVICES"] = "-1" os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 0 = all messages are logged, 3 - INFO, WARNING, and ERROR messages are not printed from keras.callbacks import LambdaCallback from keras.models import Sequential from keras.layers import Dense, Dropout, Embedding, LSTM, TimeDistributed from keras.optimizers import RMSprop from keras.utils.data_utils import get_file import keras from collections import Counter import pickle import numpy as np import random import sys import time import io import re import argparse # Transforms text to vectors of integer numbers representing in text tokens and back. Handles word and character level tokenization. class Vectorizer: def __init__(self, text, word_tokens, pristine_input, pristine_output): self.word_tokens = word_tokens self._pristine_input = pristine_input self._pristine_output = pristine_output tokens = self._tokenize(text) # print('corpus length:', len(tokens)) token_counts = Counter(tokens) # Sort so most common tokens come first in our vocabulary tokens = [x[0] for x in token_counts.most_common()] self._token_indices = {x: i for i, x in enumerate(tokens)} self._indices_token = {i: x for i, x in enumerate(tokens)} self.vocab_size = len(tokens) print('Vocab size:', self.vocab_size) def _tokenize(self, text): if not self._pristine_input: text = text.lower() if self.word_tokens: if self._pristine_input: return text.split() return Vectorizer.word_tokenize(text) return text def _detokenize(self, tokens): if self.word_tokens: if self._pristine_output: return ' '.join(tokens) return Vectorizer.word_detokenize(tokens) return ''.join(tokens) def vectorize(self, text): """Transforms text to a vector of integers""" tokens = self._tokenize(text) indices = [] for token in tokens: if token in self._token_indices: indices.append(self._token_indices[token]) else: print('Ignoring unrecognized token:', token) return np.array(indices, dtype=np.int32) def unvectorize(self, vector): """Transforms a vector of integers back to text""" tokens = [self._indices_token[index] for index in vector] return self._detokenize(tokens) @staticmethod def word_detokenize(tokens): # A heuristic attempt to undo the Penn Treebank tokenization above. Pass the # --pristine-output flag if no attempt at detokenizing is desired. regexes = [ # Newlines (re.compile(r'[ ]?\\n[ ]?'), r'\n'), # Contractions (re.compile(r"\b(can)\s(not)\b"), r'\1\2'), (re.compile(r"\b(d)\s('ye)\b"), r'\1\2'), (re.compile(r"\b(gim)\s(me)\b"), r'\1\2'), (re.compile(r"\b(gon)\s(na)\b"), r'\1\2'), (re.compile(r"\b(got)\s(ta)\b"), r'\1\2'), (re.compile(r"\b(lem)\s(me)\b"), r'\1\2'), (re.compile(r"\b(mor)\s('n)\b"), r'\1\2'), (re.compile(r"\b(wan)\s(na)\b"), r'\1\2'), # Ending quotes (re.compile(r"([^' ]) ('ll|'re|'ve|n't)\b"), r"\1\2"), (re.compile(r"([^' ]) ('s|'m|'d)\b"), r"\1\2"), (re.compile(r'[ ]?‚Äù'), r'"'), # Double dashes (re.compile(r'[ ]?--[ ]?'), r'--'), # Parens and brackets (re.compile(r'([\[\(\{\&lt;]) '), r'\1'), (re.compile(r' ([\]\)\}\&gt;])'), r'\1'), (re.compile(r'([\]\)\}\&gt;]) ([:;,.])'), r'\1\2'), # Punctuation (re.compile(r"([^']) ' "), r"\1' "), (re.compile(r' ([?!\.])'), r'\1'), (re.compile(r'([^\.])\s(\.)([\]\)}&gt;"\']*)\s*$'), r'\1\2\3'), (re.compile(r'([#$]) '), r'\1'), (re.compile(r' ([;%:,])'), r'\1'), # Starting quotes (re.compile(r'(‚Äú)[ ]?'), r'"') ] text = ' '.join(tokens) for regexp, substitution in regexes: text = regexp.sub(substitution, text) return text.strip() @staticmethod def word_tokenize(text): # Basic word tokenizer based on the Penn Treebank tokenization script, but # setup to handle multiple sentences. Newline aware, ie newlines are # replaced with a specific token. You may want to consider using a more robust # tokenizer as a preprocessing step, and using the --pristine-input flag. regexes = [ # Starting quotes (re.compile(r'(\s)"'), r'\1 ‚Äú '), (re.compile(r'([ (\[{&lt;])"'), r'\1 ‚Äú '), # Punctuation (re.compile(r'([:,])([^\d])'), r' \1 \2'), (re.compile(r'([:,])$'), r' \1 '), (re.compile(r'\.\.\.'), r' ... '), (re.compile(r'([;@#$%&amp;])'), r' \1 '), (re.compile(r'([?!\.])'), r' \1 '), (re.compile(r"([^'])' "), r"\1 ' "), # Parens and brackets (re.compile(r'([\]\[\(\)\{\}\&lt;\&gt;])'), r' \1 '), # Double dashes (re.compile(r'--'), r' -- '), # Ending quotes (re.compile(r'"'), r' ‚Äù '), (re.compile(r"([^' ])('s|'m|'d) "), r"\1 \2 "), (re.compile(r"([^' ])('ll|'re|'ve|n't) "), r"\1 \2 "), # Contractions (re.compile(r"\b(can)(not)\b"), r' \1 \2 '), (re.compile(r"\b(d)('ye)\b"), r' \1 \2 '), (re.compile(r"\b(gim)(me)\b"), r' \1 \2 '), (re.compile(r"\b(gon)(na)\b"), r' \1 \2 '), (re.compile(r"\b(got)(ta)\b"), r' \1 \2 '), (re.compile(r"\b(lem)(me)\b"), r' \1 \2 '), (re.compile(r"\b(mor)('n)\b"), r' \1 \2 '), (re.compile(r"\b(wan)(na)\b"), r' \1 \2 '), # Newlines (re.compile(r'\n'), r' \\n ') ] text = " " + text + " " for regexp, substitution in regexes: text = regexp.sub(substitution, text) return text.split() def _create_sequences(vector, seq_length, seq_step): # Take strips of our vector at seq_step intervals up to our seq_length # and cut those strips into seq_length sequences passes = [] for offset in range(0, seq_length, seq_step): pass_samples = vector[offset:] num_pass_samples = pass_samples.size // seq_length pass_samples = np.resize(pass_samples, (num_pass_samples, seq_length)) passes.append(pass_samples) # Stack our sequences together. This will technically leave a few "breaks" # in our sequence chain where we've looped over are entire dataset and # return to the start, but with large datasets this should be neglegable return np.concatenate(passes) def shape_for_stateful_rnn(data, batch_size, seq_length, seq_step): """ Reformat our data vector into input and target sequences to feed into our RNN. Tricky with stateful RNNs. """ # Our target sequences are simply one timestep ahead of our input sequences. # eg with an input vector "wherefore"... # targets: herefore # predicts ^ ^ ^ ^ ^ ^ ^ ^ # inputs: wherefor inputs = data[:-1] targets = data[1:] # We split our long vectors into semi-redundant seq_length sequences inputs = _create_sequences(inputs, seq_length, seq_step) targets = _create_sequences(targets, seq_length, seq_step) # Make sure our sequences line up across batches for stateful RNNs inputs = _batch_sort_for_stateful_rnn(inputs, batch_size) targets = _batch_sort_for_stateful_rnn(targets, batch_size) # Our target data needs an extra axis to work with the sparse categorical # crossentropy loss function targets = targets[:, :, np.newaxis] return inputs, targets def _batch_sort_for_stateful_rnn(sequences, batch_size): # Now the tricky part, we need to reformat our data so the first # sequence in the nth batch picks up exactly where the first sequence # in the (n - 1)th batch left off, as the RNN cell state will not be # reset between batches in the stateful model. num_batches = sequences.shape[0] // batch_size num_samples = num_batches * batch_size reshuffled = np.zeros((num_samples, sequences.shape[1]), dtype=np.int32) for batch_index in range(batch_size): # Take a slice of num_batches consecutive samples slice_start = batch_index * num_batches slice_end = slice_start + num_batches index_slice = sequences[slice_start:slice_end, :] # Spread it across each of our batches in the same index position reshuffled[batch_index::batch_size, :] = index_slice return reshuffled def load_data(data_file, word_tokens, pristine_input, pristine_output, batch_size, seq_length=50, seq_step=25): global vectorizer try: with open(data_file, encoding='utf-8') as input_file: text = input_file.read() except FileNotFoundError: print("No input.txt in data_dir") sys.exit(1) skip_validate = True # try: # with open(os.path.join(data_dir, 'validate.txt'), encoding='utf-8') as validate_file: # text_val = validate_file.read() # skip_validate = False # except FileNotFoundError: # pass # Validation text optional # Find some good default seed string in our source text. # self.seeds = find_random_seeds(text) # Include our validation texts with our vectorizer all_text = text if skip_validate else '\n'.join([text, text_val]) vectorizer = Vectorizer(all_text, word_tokens, pristine_input, pristine_output) data = vectorizer.vectorize(text) x, y = shape_for_stateful_rnn(data, batch_size, seq_length, seq_step) print("Word_tokens:", word_tokens) print('x.shape:', x.shape) print('y.shape:', y.shape) if skip_validate: return x, y, None, None, vectorizer data_val = vectorizer.vectorize(text_val) x_val, y_val = shape_for_stateful_rnn(data_val, batch_size, seq_length, seq_step) print('x_val.shape:', x_val.shape) print('y_val.shape:', y_val.shape) return x, y, x_val, y_val, vectorizer def make_model(batch_size, vocab_size, embedding_size=64, rnn_size=128, num_layers=2): # Conversely if your data is large (more than about 2MB), feel confident to increase rnn_size and train a bigger model (see details of training below). # It will work significantly better. For example with 6MB you can easily go up to rnn_size 300 or even more. model = Sequential() model.add(Embedding(vocab_size, embedding_size, batch_input_shape=(batch_size, None))) for layer in range(num_layers): model.add(LSTM(rnn_size, stateful=True, return_sequences=True)) model.add(Dropout(0.2)) model.add(TimeDistributed(Dense(vocab_size, activation='softmax'))) model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) return model def train(model, x, y, x_val, y_val, batch_size, num_epochs): print('Training...') # print("Shape:", x.shape, y.shape) # print(num_epochs, batch_size, x[0], y[0]) train_start = time.time() validation_data = (x_val, y_val) if (x_val is not None) else None callbacks = None model.fit(x, y, validation_data=validation_data, batch_size=batch_size, shuffle=False, epochs=num_epochs, verbose=1, callbacks=callbacks) # self.update_sample_model_weights() train_end = time.time() print('Training time', train_end - train_start) def sample_preds(preds, temperature=1.0): """ Samples an unnormalized array of probabilities. Use temperature to flatten/amplify the probabilities. """ preds = np.asarray(preds).astype(np.float64) # Add a tiny positive number to avoid invalid log(0) preds += np.finfo(np.float64).tiny preds = np.log(preds) / temperature exp_preds = np.exp(preds) preds = exp_preds / np.sum(exp_preds) probas = np.random.multinomial(1, preds, 1) return np.argmax(probas) def generate(model, vectorizer, seed, length=100, diversity=0.5): seed_vector = vectorizer.vectorize(seed) # Feed in seed string print("Seed:", seed, end=' ' if vectorizer.word_tokens else '') model.reset_states() preds = None for char_index in np.nditer(seed_vector): preds = model.predict(np.array([[char_index]]), verbose=0) sampled_indices = [] # np.array([], dtype=np.int32) # Sample the model one token at a time for i in range(length): char_index = 0 if preds is not None: char_index = sample_preds(preds[0][0], diversity) sampled_indices.append(char_index) # = np.append(sampled_indices, char_index) preds = model.predict(np.array([[char_index]]), verbose=0) sample = vectorizer.unvectorize(sampled_indices) return sample if __name__ == "__main__": batch_size = 32 # Batch size for each train num_epochs = 10 # Number of epochs of training out_len = 200 # Length of the output phrase seq_length = 50 # 50 # Determines, how long phrases will be used for training use_words = False # Use words instead of characters (slower speed, bigger vocabulary) data_file = "text_habr.txt" # Source text file seed = "A" # Initial symbol of the text parser = argparse.ArgumentParser() parser.add_argument("-t", "--text", action="store", required=False, dest="text", help="Input text file") parser.add_argument("-e", "--epochs", action="store", required=False, dest="epochs", help="Number of training epochs") parser.add_argument("-p", "--phrase_len", action="store", required=False, dest="phrase_len", help="Phrase analyse length") parser.add_argument("-o", "--out_len", action="store", required=False, dest="out_len", help="Output text length") parser.add_argument("-g", "--generate", action="store_true", required=False, dest='generate', help="Generate output only without training") args = parser.parse_args() if args.text is not None: data_file = args.text if args.epochs is not None: num_epochs = int(args.epochs) if args.phrase_len is not None: seq_length = int(args.phrase_len) if args.out_len is not None: out_len = int(args.out_len) # Load text data pristine_input, pristine_output = False, False x, y, x_val, y_val, vectorizer = load_data(data_file, use_words, pristine_input, pristine_output, batch_size, seq_length) model_file = data_file.lower().replace('.txt', '.h5') if args.generate is False: # Make model model = make_model(batch_size, vectorizer.vocab_size) # Train model train(model, x, y, x_val, y_val, batch_size, num_epochs) # Save model to file model.save(filepath=model_file) model = keras.models.load_model(model_file) predict_model = make_model(1, vectorizer.vocab_size) predict_model.set_weights(model.get_weights()) # Generate phrases res = generate(predict_model, vectorizer, seed=seed, length=out_len) print(res)</span></span></code> </pre><br></div></div><br>  Creo que result√≥ ser un generador de texto de trabajo muy original, <s>que es √∫til para escribir art√≠culos sobre Habr</s> .  Particularmente interesante es probar en textos grandes y grandes cantidades de iteraciones de entrenamiento, si alguien tiene acceso a computadoras r√°pidas, ser√≠a interesante ver los resultados. <br><br>  Si alguien quiere estudiar el tema con m√°s detalle, puede encontrar una buena descripci√≥n del uso de RNN con ejemplos detallados en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://karpathy.github.io/2015/05/21/rnn-effectiveness/</a> . <br><br>  PD: Y finalmente, algunos versos;) Es interesante notar que no fui yo quien formate√≥ el texto o incluso agreg√≥ estrellas, "soy yo mismo".  El siguiente paso es interesante para verificar la posibilidad de hacer dibujos y componer m√∫sica.  Creo que las redes neuronales son bastante prometedoras aqu√≠. <br><br>  <i>xxx</i> <i><br><br></i>  <i>para algunos, quedar atrapados en las galletas, todo de buena suerte en un patio de pan.</i> <i><br></i>  <i>y debajo de la tarde de tamaki</i> <i><br></i>  <i>debajo de una vela tomar una monta√±a.</i> <i><br><br></i>  <i>xxx</i> <i><br><br></i>  <i>pronto hijos mons en petachas en tranv√≠a</i> <i><br></i>  <i>la luz invisible huele a alegr√≠a</i> <i><br></i>  <i>es por eso que toco juntos crece</i> <i><br></i>  <i>no te enfermar√°s de un desconocido.</i> <i><br><br></i>  <i>coraz√≥n para arrancar el ogora escalonado</i> <i><br></i>  <i>no es tan viejo que el cereal est√° comiendo,</i> <i><br></i>  <i>Guardo el puente a la pelota para robar.</i> <i><br><br></i>  <i>de la misma manera Darina en Doba,</i> <i><br></i>  <i>Escucho en mi coraz√≥n de nieve en mi mano.</i> <i><br></i>  <i>nuestro canto blanco cu√°ntos dumina suave</i> <i><br></i>  <i>Le di la espalda a la bestia mineral volot.</i> <i><br><br></i>  <i>xxx</i> <i><br><br></i>  <i>veterinario crucificando inquietos con un hechizo</i> <i><br></i>  <i>y se derram√≥ bajo lo olvidado.</i> <i><br></i>  <i>y t√∫, como las ramas de cuba</i> <i><br></i>  <i>Brillar en ella.</i> <i><br></i>  <i>o diversi√≥n en zakoto</i> <i><br></i>  <i>con el vuelo de la leche.</i> <i><br><br></i>  <i>oh eres una rosa, luz</i> <i><br></i>  <i>luz de nube en mano:</i> <i><br></i>  <i>y rod√≥ al amanecer</i> <i><br></i>  <i>¬øC√≥mo est√°s, mi jinete?</i> <i><br><br></i>  <i>√©l est√° sirviendo en la noche, no hasta el hueso,</i> <i><br></i>  <i>de noche en Tanya la luz azul</i> <i><br></i>  <i>como una especie de tristeza</i> <br><br>  Y los √∫ltimos versos en el aprendizaje por modo de palabra.  Aqu√≠ la rima desapareci√≥, pero apareci√≥ alg√∫n significado (?). <br><br>  <i>y tu, de la llama</i> <i><br></i>  <i>las estrellas</i> <i><br></i>  <i>habl√≥ a individuos distantes.</i> <i><br><br></i>  <i>te preocupa, ma√±ana, ma√±ana.</i> <i><br></i>  <i>"Paloma lluvia,</i> <i><br></i>  <i>y hogar de los asesinos,</i> <i><br></i>  <i>para la ni√±a princesa</i> <i><br></i>  <i>su cara</i> <i><br><br></i>  <i>xxx</i> <i><br><br></i>  <i>oh pastor, agita las c√°maras</i> <i><br></i>  <i>en un bosque en la primavera.</i> <i><br><br></i>  <i>Voy por el coraz√≥n de la casa al estanque,</i> <i><br></i>  <i>y ratones alegre</i> <i><br></i>  <i>Campanas de Nizhny Novgorod.</i> <i><br><br></i>  <i>pero no temas el viento de la ma√±ana</i> <i><br></i>  <i>con un camino, con un palo de hierro,</i> <i><br></i>  <i>y pensado con la ostra</i> <i><br></i>  <i>albergado en un estanque</i> <i><br></i>  <i>en rakit empobrecido.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/470035/">https://habr.com/ru/post/470035/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../470021/index.html">Modelo an√©mico y rico en el contexto de las plantillas GRASP</a></li>
<li><a href="../470023/index.html">Estamos escribiendo un pago para un bot de telegramas en Python usando la biblioteca de telebot parte 3</a></li>
<li><a href="../470027/index.html">VK Hackathon 2019 (como era)</a></li>
<li><a href="../470029/index.html">Pedagog√≠a extrema: "Sabemos" sobre trabajar con ni√±os en tratamientos a largo plazo</a></li>
<li><a href="../470033/index.html">F # 2: Medio Ambiente FSI</a></li>
<li><a href="../470037/index.html">F # 3: Formato de texto</a></li>
<li><a href="../470043/index.html">La ciencia detr√°s de c√≥mo nuestros cerebros funcionan mejor y c√≥mo la tecnolog√≠a y nuestro entorno pueden ayudar</a></li>
<li><a href="../470045/index.html">Visual Studio para Mac: caracter√≠sticas principales del nuevo editor</a></li>
<li><a href="../470047/index.html">Mir√© hacia atr√°s para ver si ella miraba hacia atr√°s: 2 o hacia mi propio centro de datos a trav√©s de AWS</a></li>
<li><a href="../470049/index.html">Presentaci√≥n de la administraci√≥n de paquetes NuGet a nivel de soluci√≥n en Visual Studio para Mac</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
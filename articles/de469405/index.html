<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüë©‚Äçüë¶‚Äçüë¶ üöö üêü Deep Learning ist jetzt in Java üë©üèæ‚Äç‚öñÔ∏è üèª üêÇ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Magst du Java nicht? Ja, Sie wissen nicht, wie man es kocht! Mani Sarkar l√§dt uns ein, sich mit dem Valohai-Tool vertraut zu machen, mit dem Sie Model...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Deep Learning ist jetzt in Java</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/469405/">  Magst du Java nicht?  Ja, Sie wissen nicht, wie man es kocht!  Mani Sarkar l√§dt uns ein, sich mit dem Valohai-Tool vertraut zu machen, mit dem Sie Modellrecherchen in Java durchf√ºhren k√∂nnen. <br><br><img src="https://habrastorage.org/webt/et/p-/se/etp-sezekre2qlznmvgdzlgds0a.png"><br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Haftungsausschluss des √úbersetzers</b> <div class="spoiler_text"> Ich hoffe, dies ist keine Werbepublikation.  Ich bin nicht mit Valohai verbunden.  Ich habe gerade den Artikel √ºbersetzt, auf den ich den Link verweise.  Wenn ungeschickt √ºbersetzt - treten Sie PM ein.  Bei Bedarf kann ich Links l√∂schen und andere externe Ressourcen erw√§hnen.  Danke f√ºr das Verst√§ndnis. <br></div></div><br><h3>  Einf√ºhrung </h3><br>  Vor einiger Zeit bin ich auf einen Cloud-Dienst namens Valohai gesto√üen, und ich war mit seiner Benutzeroberfl√§che und der Einfachheit von Design und Layout zufrieden.  Ich bat um den Dienst eines Mitglieds von Valohai und erhielt eine Demoversion.  Vorher habe ich eine einfache Pipeline mit GNU Parallel, JavaScript, Python und Bash geschrieben - und eine andere, die nur GNU Parallel und Bash verwendet. <br><br>  Ich habe auch dar√ºber nachgedacht, gebrauchsfertige Tools f√ºr das Aufgaben- / Workflow-Management wie Jenkins X, Jenkins Pipeline, Concourse oder Airflow zu verwenden, aber aus verschiedenen Gr√ºnden habe ich mich dagegen entschieden. <br><br>  Mir ist aufgefallen, dass viele Valohai-Beispiele und -Dokumentationen auf Python und R und ihren jeweiligen Frameworks und Bibliotheken basieren.  Ich habe beschlossen, die Gelegenheit nicht zu verpassen und den Mangel an Beispielen und Dokumentation zu korrigieren. <br><br>  Valohai hat mich dazu gedr√§ngt, etwas mit der ber√ºhmten Java-Bibliothek <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DL4J - Deep Learning for Java</a> zu implementieren. <br><br>  Meine erste Erfahrung mit Valohai machte einen guten Eindruck auf mich, nachdem ich mich durch Design, Layout und Workflow gef√ºhlt hatte.  Die Entwickler haben bereits verschiedene Aspekte sowohl der Entwickler-Workflows als auch der Infrastruktur ber√ºcksichtigt.  In unserer Welt wird der Infrastrukturentwicklungsprozess haupts√§chlich von den DevOps- oder SysOps-Teams gesteuert, und wir kennen die damit verbundenen Nuancen und Schwachstellen. <br><br><h3>  Was brauchen wir und wie? </h3><br>  In jedem maschinellen Lernprojekt gibt es zwei wichtige Komponenten (aus Sicht einer h√∂heren Ebene) - einen Code, der mit dem Modell funktioniert, und einen Code, der mit der Infrastruktur funktioniert, in der der gesamte Projektlebenszyklus ausgef√ºhrt wird. <br><br>  Nat√ºrlich werden vorher, w√§hrend und nachher Schritte und Komponenten erforderlich sein, aber der Einfachheit halber ben√∂tigen wir Code und Infrastruktur. <br><br><h4>  Code </h4><br>  F√ºr den Code habe ich ein komplexes Beispiel mit DL4J ausgew√§hlt. Dies ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MNist-Projekt</a> mit einem Trainingssatz von 60.000 Bildern und einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Testsatz</a> von 10.000 Bildern handgeschriebener Ziffern.  Dieser Datensatz ist √ºber die DL4J-Bibliothek verf√ºgbar (genau wie Keras). <br><br>  Bevor Sie beginnen, wird empfohlen, dass Sie sich den Quellcode ansehen, den wir verwenden werden.  Die Haupt-Java-Klasse hei√üt <a href="">org.deeplearning4j.feedforward.mnist.MLPMnistSingleLayerRunner</a> . <br><br><h4>  Die Infrastruktur </h4><br>  Wir haben uns entschlossen, das Java-Beispiel mit Valohai als Infrastruktur f√ºr die Durchf√ºhrung von Experimenten (Schulung und Modellbewertung) auszuprobieren.  Valohai erkennt Git-Repositorys und stellt eine direkte Verbindung zu ihnen her, sodass wir unseren Code unabh√§ngig von Plattform oder Sprache ausf√ºhren k√∂nnen. Wir werden also sehen, wie er funktioniert.  Wenn Sie GitOps oder Infrastructure-As-Code verwenden, funktioniert auch alles f√ºr Sie. <br><br>  Dazu brauchen wir nur einen Account bei Valohai.  Nach dem Erstellen eines kostenlosen Kontos erhalten wir Zugriff auf mehrere Instanzen verschiedener Konfigurationen.  F√ºr das, was wir tun m√∂chten, ist Free-Tier mehr als genug. <br><br><h4>  Deep Learning f√ºr Java und Valohai </h4><br>  Wir werden alle Abh√§ngigkeiten zum Docker-Image bereitstellen und es verwenden, um unsere Java-Anwendung zu kompilieren, das Modell zu trainieren und es auf der Valohai-Plattform mithilfe einer einfachen Datei <a href="">valohai.yaml zu</a> bewerten, die sich im Stammordner des Projekt-Repositorys befindet. <br><br><h4>  Deep Learning f√ºr Java: DL4J </h4><br>  Der einfachste Teil.  Wir m√ºssen nicht viel tun, sondern nur das Glas sammeln und den Datensatz in den Docker-Container laden.  Wir haben ein vorgefertigtes Docker-Image, das alle Abh√§ngigkeiten enth√§lt, die zum Erstellen einer Java-Anwendung erforderlich sind.  Wir haben dieses Bild in den Docker Hub eingef√ºgt, und Sie k√∂nnen es finden, indem Sie nach dl4j-mnist-single-layer suchen (wir verwenden ein spezielles Tag, wie in der YAML-Datei definiert).  Wir haben uns entschieden, GraalVM 19.1.1 als Build- und Laufzeit-Java-Umgebung f√ºr dieses Projekt zu verwenden, und es ist in das Docker-Image integriert. <br><br>  Wenn das uber jar √ºber die Befehlszeile aufgerufen wird, erstellen wir die Klasse MLPMnistSingleLayerRunner, die uns die beabsichtigte Aktion in Abh√§ngigkeit von den √ºbergebenen Parametern mitteilt: <br><br><pre><code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ MLPMnistSingleLayerRunner mlpMnistRunner = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MLPMnistSingleLayerRunner(); JCommander.newBuilder() .addObject(mlpMnistRunner) .build() .parse(args); mlpMnistRunner.execute(); }</code> </pre> <br>  An uber jar √ºbergebene Parameter werden von dieser Klasse akzeptiert und von der Methode execute () verarbeitet. <br><br>  Wir k√∂nnen ein Modell mit dem Parameter --action train erstellen und das erstellte Modell mit dem Parameter --action evalu bewerten, der an die Java-Anwendung √ºbergeben wird. <br><br>  Die Hauptteile der Java-Anwendung, die diese Arbeit ausf√ºhrt, befinden sich in den beiden in den folgenden Abschnitten genannten Java-Klassen. <br><br><h3>  Modelltraining </h3><br>  Rufen Sie an <br><br><pre> <code class="plaintext hljs">./runMLPMnist.sh --action train --output-dir ${VH_OUTPUTS_DIR} or java -Djava.library.path="" \ -jar target/MLPMnist-1.0.0-bin.jar \ --action train --output-dir ${VH_OUTPUTS_DIR}</code> </pre><br>  Dieser Befehl erstellt ein Modell mit dem Namen mlpmnist-single-layer.pb in dem Ordner, der durch den zu Beginn der Ausf√ºhrung √ºbergebenen Parameter --output-dir angegeben wird.  Aus Sicht von Valohai sollte es in $ {VH_OUTPUTS_DIR} platziert werden, was wir tun (siehe die Datei <a href="">valohai.yaml</a> ). <br><br>  Den Quellcode finden Sie in der Klasse <a href="">MLPMNistSingleLayerTrain.java</a> . <br><br><h3>  Modellbewertung </h3><br>  Rufen Sie an <br><br><pre> <code class="plaintext hljs">./runMLPMnist.sh --action evaluate --input-dir ${VH_INPUTS_DIR}/model or java -Djava.library.path="" \ -jar target/MLPMnist-1.0.0-bin.jar \ --action evaluate --input-dir ${VH_INPUTS_DIR}/model</code> </pre><br>  Es wird davon ausgegangen, dass das Modell (das w√§hrend der Trainingsphase erstellt wurde) mit dem Namen mlpmnist-single-layer.pb in dem Ordner vorhanden ist, der im Parameter --input-dir angegeben ist, der beim Aufruf der Anwendung √ºbergeben wurde. <br><br>  Den Quellcode finden Sie in der Klasse <a href="">MLPMNistSingleLayerEvaluate.java</a> . <br><br>  Ich hoffe, diese kurze Abbildung verdeutlicht, wie eine Java-Anwendung funktioniert, die ein Modell lehrt und bewertet. <br><br>  Dies ist alles, was von uns verlangt wird, aber z√∂gern Sie nicht, mit den restlichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quellen</a> (zusammen mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">README.md</a> und Bash-Skripten) zu spielen und Ihre Neugier und Ihr Verst√§ndnis daf√ºr zu befriedigen, wie dies getan wird! <br><br><h3>  Valohai </h3><br>  Mit Valohai k√∂nnen wir unsere Laufzeit, unseren Code und unseren Datensatz frei verkn√ºpfen, wie Sie aus der folgenden YAML-Dateistruktur ersehen k√∂nnen.  Somit k√∂nnen sich verschiedene Komponenten unabh√§ngig voneinander entwickeln.  Folglich werden nur Assembly- und Laufzeitkomponenten in unseren Docker-Container gepackt. <br><br>  Zur Laufzeit sammeln wir die Uber-JAR in einem Docker-Container, laden sie in einen internen oder externen Speicher und laden dann mit dem anderen Ausf√ºhrungsschritt die Uber-JAR und den Datensatz aus dem Speicher (oder einem anderen Ort), um mit dem Training zu beginnen.  Somit werden die zwei Ausf√ºhrungsschritte getrennt;  Zum Beispiel k√∂nnen wir ein Glas einmal kompilieren und Hunderte von Trainingsschritten f√ºr ein einzelnes Glas ausf√ºhren.  Da sich Assembly- und Laufzeitumgebungen nicht so oft √§ndern m√ºssen, k√∂nnen wir sie zwischenspeichern und auf Code, Datasets und Modelle kann zur Laufzeit dynamisch zugegriffen werden. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">valohai.yaml</a> <br>  Der Hauptteil der Integration unseres Java-Projekts in die Valohai-Infrastruktur besteht darin, die Reihenfolge der Ausf√ºhrungsschritte in der Datei valohai.yaml im Stammverzeichnis Ihres Projektordners zu bestimmen.  Unser valohai.yaml sieht so aus: <br><br><pre> <code class="xml hljs">--- - step: name: Build-dl4j-mnist-single-layer-java-app image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - cd ${VH_REPOSITORY_DIR} - ./buildUberJar.sh - echo "~~~ Copying the build jar file into ${VH_OUTPUTS_DIR}" - cp target/MLPMnist-1.0.0-bin.jar ${VH_OUTPUTS_DIR}/MLPMnist-1.0.0.jar - ls -lash ${VH_OUTPUTS_DIR} environment: aws-eu-west-1-g2-2xlarge - step: name: Run-dl4j-mnist-single-layer-train-model image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - echo "~~~ Unpack the MNist dataset into ${HOME} folder" - tar xvzf ${VH_INPUTS_DIR}/dataset/mlp-mnist-dataset.tgz -C ${HOME} - cd ${VH_REPOSITORY_DIR} - echo "~~~ Copying the build jar file from ${VH_INPUTS_DIR} to current location" - cp ${VH_INPUTS_DIR}/dl4j-java-app/MLPMnist-1.0.0.jar . - echo "~~~ Run the DL4J app to train model based on the the MNist dataset" - ./runMLPMnist.sh {parameters} inputs: - name: dl4j-java-app description: DL4J Java app file (jar) generated in the previous step 'Build-dl4j-mnist-single-layer-java-app' - name: dataset default: https://github.com/neomatrix369/awesome-ai-ml-dl/releases/download/mnist-dataset-v0.1/mlp-mnist-dataset.tgz description: MNist dataset needed to train the model parameters: - name: --action pass-as: '--action {v}' type: string default: train description: Action to perform ie train or evaluate - name: --output-dir pass-as: '--output-dir {v}' type: string default: /valohai/outputs/ description: Output directory where the model will be created, best to pick the Valohai output directory environment: aws-eu-west-1-g2-2xlarge - step: name: Run-dl4j-mnist-single-layer-evaluate-model image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - cd ${VH_REPOSITORY_DIR} - echo "~~~ Copying the build jar file from ${VH_INPUTS_DIR} to current location" - cp ${VH_INPUTS_DIR}/dl4j-java-app/MLPMnist-1.0.0.jar . - echo "~~~ Run the DL4J app to evaluate the trained MNist model" - ./runMLPMnist.sh {parameters} inputs: - name: dl4j-java-app description: DL4J Java app file (jar) generated in the previous step 'Build-dl4j-mnist-single-layer-java-app' - name: model description: Model file generated in the previous step 'Run-dl4j-mnist-single-layer-train-model' parameters: - name: --action pass-as: '--action {v}' type: string default: evaluate description: Action to perform ie train or evaluate - name: --input-dir pass-as: '--input-dir {v}' type: string default: /valohai/inputs/model description: Input directory where the model created by the previous step can be found created environment: aws-eu-west-1-g2-2xlarge</code> </pre><br><h4>  So funktioniert die Build-dl4j-mnist-Single-Layer-Java-App </h4><br>  Aus der YAML-Datei geht hervor, dass wir diesen Schritt definieren, indem wir zuerst das Docker-Image verwenden und dann das Skript zum Erstellen der Uber-JAR ausf√ºhren.  In unserem Docker-Image k√∂nnen Abh√§ngigkeiten der Build-Umgebung (z. B. GraalVM JDK, Maven usw.) angepasst werden, um eine Java-Anwendung zu erstellen.  Wir geben keine Eingaben oder Parameter an, da dies die Montagephase ist.  Sobald der Build erfolgreich ist, kopieren wir das Uber-JAR mit dem Namen MLPMnist-1.0.0-bin.jar (urspr√ºnglicher Name) in den Ordner / valohai / output (dargestellt als $ {VH_OUTPUTS_DIR}).  Alles in diesem Ordner wird automatisch im Speicher Ihres Projekts gespeichert, z. B. im AWS S3-Papierkorb.  Schlie√ülich definieren wir unsere Arbeit f√ºr AWS. <br><br><div class="spoiler">  <b class="spoiler_title">Hinweis</b> <div class="spoiler_text">  Das kostenlose Valohai-Konto hat keinen Netzwerkzugriff √ºber den Docker-Container (dies ist standardm√§√üig deaktiviert). Wenden Sie sich an den Support, um diese Option zu aktivieren (ich musste dasselbe tun). Andernfalls k√∂nnen wir unseren Maven und andere Abh√§ngigkeiten nicht herunterladen w√§hrend der Montage. <br></div></div><br><h4>  Wie Run-dl4j-mnist-single-layer-train-model funktioniert </h4><br>  Die Semantik der Definition √§hnelt dem vorherigen Schritt, au√üer dass wir zwei Eingaben angeben: eine f√ºr uber jar (MLPMnist-1.0.0.jar) und die andere f√ºr den Datensatz (entpackt in den Ordner $ {HOME} /. Deeplearning4j).  Wir werden zwei Parameter √ºbergeben - --action train und --output-dir / valohai / output.  Das in diesem Schritt erstellte Modell ist in / valohai / output / model (dargestellt als $ {VH_OUTPUTS_DIR} / model) erstellt. <br><br><div class="spoiler">  <b class="spoiler_title">Hinweis</b> <div class="spoiler_text">  In den Eingabefeldern auf der Registerkarte "Ausf√ºhren" der Valohai-Weboberfl√§che k√∂nnen wir die Ausgabe aus vorherigen L√§ufen unter Verwendung der Laufnummer, d. H. Nr. 1 oder Nr. 2, zus√§tzlich zu den URLs datum: // oder http: / ausw√§hlen / Wenn Sie einige Buchstaben des Dateinamens eingeben, k√∂nnen Sie auch die gesamte Liste durchsuchen. <br></div></div><br><h4>  Wie Run-dl4j-mnist-single-layer -valu-model funktioniert </h4><br>  Auch dieser Schritt √§hnelt dem vorherigen Schritt, au√üer dass wir zwei Parameter √ºbergeben werden - action evalu und --input-dir / valohai / input / model.  Au√üerdem haben wir in der Eingabe erneut angegeben: die in der YAML-Datei definierten Abschnitte mit dem Namen dl4j-java-app und model ohne die Standardeinstellung f√ºr beide.  Auf diese Weise k√∂nnen wir das Uber-Jar und das Modell ausw√§hlen, das wir bewerten m√∂chten. Dieses wurde mithilfe des Schrittes Run-dl4j-mnist-single-layer-train-model √ºber die Weboberfl√§che erstellt. <br><br>  Ich hoffe, dies erkl√§rt die Schritte in der obigen Definitionsdatei. Wenn Sie jedoch weitere Hilfe ben√∂tigen, k√∂nnen Sie sich die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tutorials</a> ansehen. <br><br><h3>  Valohai Webinterface </h3><br>  Nach Erhalt des Kontos k√∂nnen wir uns anmelden und das Projekt mit dem Namen mlpmnist-single-layer erstellen und git repo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">github.com/valohai/mlpmnist-dl4j-example</a> mit dem Projekt verkn√ºpfen und das Projekt speichern. <br><br>  Jetzt k√∂nnen Sie den Schritt abschlie√üen und sehen, wie es ausgeht! <br><br><h4>  Erstellen Sie eine DL4J-Java-Anwendung </h4><br>  Gehen Sie in der Weboberfl√§che zur Registerkarte ‚ÄûAusf√ºhrung‚Äú und kopieren Sie entweder die vorhandene Ausf√ºhrung oder erstellen Sie eine neue √ºber die Schaltfl√§che [Ausf√ºhrung erstellen].  Alle notwendigen Standardparameter werden ausgef√ºllt.  W√§hlen Sie Schritt Build-dl4j-mnist-single-layer-java-app. <br><br>  F√ºr die <i>Umgebung habe</i> ich AWS eu-west-1 g2.2xlarge ausgew√§hlt und unten auf der Seite auf die Schaltfl√§che [Ausf√ºhrung erstellen] geklickt, um den Start der Ausf√ºhrung anzuzeigen. <br><br><img src="https://habrastorage.org/webt/le/18/zo/le18zo_udbscmekflaux7kqfjcw.png"><br><br><h3>  Modelltraining </h3><br>  Gehen Sie in der Weboberfl√§che zur Registerkarte ‚ÄûAusf√ºhrung‚Äú und gehen Sie wie im vorherigen Schritt vor und w√§hlen Sie Run-dl4j-mnist-single-layer-train-model aus.  Sie m√ºssen die Java-Anwendung ausw√§hlen (geben Sie einfach jar in das Feld ein), die im vorherigen Schritt erstellt wurde.  Der Datensatz wurde bereits mit der Datei valohai.yaml vorab ausgef√ºllt: <br><br><img src="https://habrastorage.org/webt/md/ls/ov/mdlsovhg3vw9zjnpoeqhxwzgk7w.png"><br><br>  Klicken Sie zum Starten auf [Ausf√ºhrung erstellen]. <br><br><img src="https://habrastorage.org/webt/6n/mr/wm/6nmrwmveck6cgdughud1xgx7qdg.png"><br><br>  Sie sehen das Ergebnis in der Konsole: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:05 ======================================================================= 11:17:05 LayerName (LayerType) nIn,nOut TotalParams ParamsShape 11:17:05 ======================================================================= 11:17:05 layer0 (DenseLayer) 784,1000 785000 W:{784,1000}, b:{1,1000} 11:17:05 layer1 (OutputLayer) 1000,10 10010 W:{1000,10}, b:{1,10} 11:17:05 ----------------------------------------------------------------------- 11:17:05 Total Parameters: 795010 11:17:05 Trainable Parameters: 795010 11:17:05 Frozen Parameters: 0 11:17:05 ======================================================================= [&lt;--- snipped ---&gt;]</code> </pre><br>  Erstellte Modelle finden Sie w√§hrend und nach der Ausf√ºhrung auf der Registerkarte "Ausg√§nge" der Hauptregisterkarte "Ausf√ºhrung": <br><br><img src="https://habrastorage.org/webt/pg/g2/-k/pgg2-kmsr85x87fedfoy24lreye.png"><br><br>  M√∂glicherweise stellen Sie auf der Unterregisterkarte "Ausgaben" mehrere Artefakte fest.  Dies liegt daran, dass wir am Ende jeder √Ñra Kontrollpunkte beibehalten.  Schauen wir uns das in den Protokollen an: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:14 odolCheckpointListener - Model checkpoint saved: epoch 0, iteration 469, path: /valohai/outputs/checkpoint_0_MultiLayerNetwork.zip [&lt;--- snipped ---&gt;]</code> </pre><br>  Der Pr√ºfpunkt enth√§lt den Status des Modells in drei Dateien: <br><br><pre> <code class="plaintext hljs">configuration.json coefficients.bin updaterState.bin</code> </pre><br><h3>  Modelltraining.  Metadaten </h3><br>  M√∂glicherweise haben Sie diese Eintr√§ge in den Ausf√ºhrungsprotokollen bemerkt: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:05 {"epoch": 0, "iteration": 0, "score (loss function)": 2.410047} 11:17:07 {"epoch": 0, "iteration": 100, "score (loss function)": 0.613774} 11:17:09 {"epoch": 0, "iteration": 200, "score (loss function)": 0.528494} 11:17:11 {"epoch": 0, "iteration": 300, "score (loss function)": 0.400291} 11:17:13 {"epoch": 0, "iteration": 400, "score (loss function)": 0.357800} 11:17:14 odolCheckpointListener - Model checkpoint saved: epoch 0, iteration 469, path: /valohai/outputs/checkpoint_0_MultiLayerNetwork.zip [&lt;--- snipped ---&gt;]</code> </pre><br>  Mit diesen Daten kann Valohai diese Werte (im JSON-Format) abrufen, die zum Erstellen der Metriken verwendet werden, die w√§hrend und nach der Ausf√ºhrung auf der zus√§tzlichen Registerkarte Metadaten auf der Hauptregisterkarte Ausf√ºhrungen angezeigt werden: <br><br><img src="https://habrastorage.org/webt/et/p-/se/etp-sezekre2qlznmvgdzlgds0a.png"><br><br>  Wir konnten dies tun, indem wir die ValohaiMetadataCreator-Klasse mit dem Modell verbanden, sodass Valohai w√§hrend des Trainings auf diese Klasse verweist.  Bei dieser Klasse leiten wir mehrere Epochen ab, die Anzahl der Iterationen und den Score (Wert der Verlustfunktion).  Hier ist ein Codeausschnitt aus der Klasse: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">iterationDone</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Model model, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> iteration, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> epoch)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (printIterations &lt;= <span class="hljs-number"><span class="hljs-number">0</span></span>) printIterations = <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (iteration % printIterations == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> score = model.score(); System.out.println(String.format( <span class="hljs-string"><span class="hljs-string">"{\"epoch\": %d, \"iteration\": %d, \"score (loss function)\": %f}"</span></span>, epoch, iteration, score) ); } }</code> </pre><br><h3>  Modellbewertung </h3><br>  Nachdem das Modell im vorherigen Schritt erfolgreich erstellt wurde, sollte es ausgewertet werden.  Wir erstellen eine neue Ausf√ºhrung auf die gleiche Weise wie zuvor, w√§hlen diesmal jedoch den Schritt Run-dl4j-mnist-single-layer -valu-model aus.  Wir m√ºssen die Java-Anwendung (MLPMnist-1.0.0.jar) und das erstellte Modell (mlpmnist-single-layer.pb) erneut ausw√§hlen, bevor wir mit der Ausf√ºhrung beginnen (wie unten gezeigt): <br><br><img src="https://habrastorage.org/webt/e9/_b/am/e9_bamnlhownoo40utziaqazg8e.png"><br><br>  Nachdem Sie das gew√ºnschte Modell als Eingabe ausgew√§hlt haben, klicken Sie auf die Schaltfl√§che [Ausf√ºhrung erstellen].  Es wird schneller ausgef√ºhrt als das vorherige, und wir werden das folgende Ergebnis sehen: <br><br><img src="https://habrastorage.org/webt/gp/0i/co/gp0icomuurv7a0gt-niye5hyri4.png"><br><br>  Wir sehen, dass unsere "Hallo Welt" zu einem Modell f√ºhrte, dessen Genauigkeit basierend auf einem Testdatensatz etwa 97% betr√§gt.  Die Verwirrungsmatrix hilft dabei, F√§lle zu finden, in denen eine Ziffer f√§lschlicherweise als andere Ziffer vorhergesagt wurde. <br><br>  Die Frage bleibt (und geht √ºber den Rahmen dieses Beitrags hinaus): Wie gut ist das Modell, wenn es mit realen Daten konfrontiert wird? <br><br>  Um ein Git-Repository zu klonen, m√ºssen Sie Folgendes tun: <br><br><pre> <code class="plaintext hljs"> $ git clone https://github.com/valohai/mlpmnist-dl4j-example</code> </pre><br>  Dann m√ºssen wir unser Valohai-Projekt, das √ºber die Weboberfl√§che im obigen Abschnitt erstellt wurde, mit dem Projekt verkn√ºpfen, das auf unserem lokalen Computer gespeichert ist (dem, den wir gerade geklont haben).  F√ºhren Sie dazu die folgenden Befehle aus: <br><br><pre> <code class="plaintext hljs">$ cd mlpmnist-dl4j-example $ vh project --help ### to see all the project-specific options we have for Valohai $ vh project link</code> </pre><br>  Ihnen wird ungef√§hr so ‚Äã‚Äãgezeigt: <br><br><pre> <code class="plaintext hljs">[ 1] mlpmnist-single-layer ... Which project would you like to link with /path/to/mlpmnist-dl4j-example? Enter [n] to create a new project.:</code> </pre><br>  W√§hlen Sie 1 (oder diejenige, die zu Ihnen passt) und Sie sollten diese Meldung sehen: <br><br><pre> <code class="plaintext hljs">Success! Linked /path/to/mlpmnist-dl4j-example to mlpmnist-single-layer.</code> </pre><br>  Bevor Sie fortfahren, stellen Sie sicher, dass Ihr Valohai-Projekt mit dem neuesten Git-Projekt synchronisiert ist. <br><br><pre> <code class="plaintext hljs"> $ vh project fetch</code> </pre><br><img src="https://habrastorage.org/webt/h0/l4/vb/h0l4vbe1eqis5kb9sd7gfslbozk.png"><br><br>  Jetzt k√∂nnen wir die Schritte von der CLI aus ausf√ºhren mit: <br><br><pre> <code class="plaintext hljs"> $ vh exec run Build-dl4j-mnist-single-layer-java-app</code> </pre><br>  Nachdem die Ausf√ºhrung abgeschlossen ist, k√∂nnen wir dies √ºberpr√ºfen mit: <br><br><pre> <code class="plaintext hljs">$ vh exec info $ vh exec logs $ vh exec watch</code> </pre><br><h3>  Fazit </h3><br>  Wie wir gesehen haben, ist es sehr praktisch, mit DL4J und Valohai zusammenzuarbeiten.  Dar√ºber hinaus k√∂nnen wir die verschiedenen Komponenten, aus denen unsere Experimente (Forschung) bestehen, dh die Build- / Laufzeitumgebung, den Code und den Datensatz, entwickeln und in unser Projekt integrieren. <br><br>  Die in diesem Beitrag verwendeten Beispielvorlagen sind eine gute M√∂glichkeit, komplexere Projekte zu erstellen.  Und Sie k√∂nnen die Web- oder Befehlszeilenschnittstelle verwenden, um Ihre Arbeit mit Valohai zu erledigen.  Mit der CLI k√∂nnen Sie sie auch in Ihre Installationen und Skripte (oder sogar in CRON- oder CI / CD-Jobs) integrieren. <br><br>  Dar√ºber hinaus ist klar, dass ich mich bei der Arbeit an einem Projekt im Zusammenhang mit AI / ML / DL nicht um die Erstellung und Wartung einer End-to-End-Pipeline k√ºmmern muss (was viele andere in der Vergangenheit tun mussten). <br><br><h5>  Referenzen </h5><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das mlpmnist-dl4j-Beispielprojekt auf GitHub</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fantastische AI ‚Äã‚Äã/ ML / DL-Ressourcen</a> </li><li>  <a href="">Java AI / ML / DL-Ressourcen</a> </li><li>  <a href="">Deep Learning und DL4J-Ressourcen</a> </li></ol><br>  Vielen Dank f√ºr Ihre Aufmerksamkeit! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de469405/">https://habr.com/ru/post/de469405/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de469393/index.html">Flare-On 2019 Zuschreibung</a></li>
<li><a href="../de469395/index.html">Wo und wie werden Mehrspalten verwendet (CSS-Spalten)</a></li>
<li><a href="../de469399/index.html">Wi-Fi im Arkhangelskoye Museum-Estate</a></li>
<li><a href="../de469401/index.html">3CX WebMeeting Service Update, Elastix Online Converter und neue Video-Tutorials</a></li>
<li><a href="../de469403/index.html">Wir interviewen einen Kandidaten f√ºr die Position des Senior Software Developer</a></li>
<li><a href="../de469407/index.html">ARIES PLC110 [M02] -MS4, HMI, OPC und SCADA oder wie sehr eine Person Kamillentee ben√∂tigt. Teil 1</a></li>
<li><a href="../de469409/index.html">Linux-Profilerstellung mit Performance Analyzer</a></li>
<li><a href="../de469411/index.html">RE: Schmerz und Tr√§nen in Svelte 3</a></li>
<li><a href="../de469413/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 382 (22. - 29. September 2019)</a></li>
<li><a href="../de469415/index.html">Transaktionsisolationsstufen f√ºr die Kleinsten</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
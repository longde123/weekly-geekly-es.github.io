<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍👩‍👦‍👦 🚚 🐟 Deep Learning ist jetzt in Java 👩🏾‍⚖️ 🏻 🐂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Magst du Java nicht? Ja, Sie wissen nicht, wie man es kocht! Mani Sarkar lädt uns ein, sich mit dem Valohai-Tool vertraut zu machen, mit dem Sie Model...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Deep Learning ist jetzt in Java</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/469405/">  Magst du Java nicht?  Ja, Sie wissen nicht, wie man es kocht!  Mani Sarkar lädt uns ein, sich mit dem Valohai-Tool vertraut zu machen, mit dem Sie Modellrecherchen in Java durchführen können. <br><br><img src="https://habrastorage.org/webt/et/p-/se/etp-sezekre2qlznmvgdzlgds0a.png"><br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Haftungsausschluss des Übersetzers</b> <div class="spoiler_text"> Ich hoffe, dies ist keine Werbepublikation.  Ich bin nicht mit Valohai verbunden.  Ich habe gerade den Artikel übersetzt, auf den ich den Link verweise.  Wenn ungeschickt übersetzt - treten Sie PM ein.  Bei Bedarf kann ich Links löschen und andere externe Ressourcen erwähnen.  Danke für das Verständnis. <br></div></div><br><h3>  Einführung </h3><br>  Vor einiger Zeit bin ich auf einen Cloud-Dienst namens Valohai gestoßen, und ich war mit seiner Benutzeroberfläche und der Einfachheit von Design und Layout zufrieden.  Ich bat um den Dienst eines Mitglieds von Valohai und erhielt eine Demoversion.  Vorher habe ich eine einfache Pipeline mit GNU Parallel, JavaScript, Python und Bash geschrieben - und eine andere, die nur GNU Parallel und Bash verwendet. <br><br>  Ich habe auch darüber nachgedacht, gebrauchsfertige Tools für das Aufgaben- / Workflow-Management wie Jenkins X, Jenkins Pipeline, Concourse oder Airflow zu verwenden, aber aus verschiedenen Gründen habe ich mich dagegen entschieden. <br><br>  Mir ist aufgefallen, dass viele Valohai-Beispiele und -Dokumentationen auf Python und R und ihren jeweiligen Frameworks und Bibliotheken basieren.  Ich habe beschlossen, die Gelegenheit nicht zu verpassen und den Mangel an Beispielen und Dokumentation zu korrigieren. <br><br>  Valohai hat mich dazu gedrängt, etwas mit der berühmten Java-Bibliothek <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DL4J - Deep Learning for Java</a> zu implementieren. <br><br>  Meine erste Erfahrung mit Valohai machte einen guten Eindruck auf mich, nachdem ich mich durch Design, Layout und Workflow gefühlt hatte.  Die Entwickler haben bereits verschiedene Aspekte sowohl der Entwickler-Workflows als auch der Infrastruktur berücksichtigt.  In unserer Welt wird der Infrastrukturentwicklungsprozess hauptsächlich von den DevOps- oder SysOps-Teams gesteuert, und wir kennen die damit verbundenen Nuancen und Schwachstellen. <br><br><h3>  Was brauchen wir und wie? </h3><br>  In jedem maschinellen Lernprojekt gibt es zwei wichtige Komponenten (aus Sicht einer höheren Ebene) - einen Code, der mit dem Modell funktioniert, und einen Code, der mit der Infrastruktur funktioniert, in der der gesamte Projektlebenszyklus ausgeführt wird. <br><br>  Natürlich werden vorher, während und nachher Schritte und Komponenten erforderlich sein, aber der Einfachheit halber benötigen wir Code und Infrastruktur. <br><br><h4>  Code </h4><br>  Für den Code habe ich ein komplexes Beispiel mit DL4J ausgewählt. Dies ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MNist-Projekt</a> mit einem Trainingssatz von 60.000 Bildern und einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Testsatz</a> von 10.000 Bildern handgeschriebener Ziffern.  Dieser Datensatz ist über die DL4J-Bibliothek verfügbar (genau wie Keras). <br><br>  Bevor Sie beginnen, wird empfohlen, dass Sie sich den Quellcode ansehen, den wir verwenden werden.  Die Haupt-Java-Klasse heißt <a href="">org.deeplearning4j.feedforward.mnist.MLPMnistSingleLayerRunner</a> . <br><br><h4>  Die Infrastruktur </h4><br>  Wir haben uns entschlossen, das Java-Beispiel mit Valohai als Infrastruktur für die Durchführung von Experimenten (Schulung und Modellbewertung) auszuprobieren.  Valohai erkennt Git-Repositorys und stellt eine direkte Verbindung zu ihnen her, sodass wir unseren Code unabhängig von Plattform oder Sprache ausführen können. Wir werden also sehen, wie er funktioniert.  Wenn Sie GitOps oder Infrastructure-As-Code verwenden, funktioniert auch alles für Sie. <br><br>  Dazu brauchen wir nur einen Account bei Valohai.  Nach dem Erstellen eines kostenlosen Kontos erhalten wir Zugriff auf mehrere Instanzen verschiedener Konfigurationen.  Für das, was wir tun möchten, ist Free-Tier mehr als genug. <br><br><h4>  Deep Learning für Java und Valohai </h4><br>  Wir werden alle Abhängigkeiten zum Docker-Image bereitstellen und es verwenden, um unsere Java-Anwendung zu kompilieren, das Modell zu trainieren und es auf der Valohai-Plattform mithilfe einer einfachen Datei <a href="">valohai.yaml zu</a> bewerten, die sich im Stammordner des Projekt-Repositorys befindet. <br><br><h4>  Deep Learning für Java: DL4J </h4><br>  Der einfachste Teil.  Wir müssen nicht viel tun, sondern nur das Glas sammeln und den Datensatz in den Docker-Container laden.  Wir haben ein vorgefertigtes Docker-Image, das alle Abhängigkeiten enthält, die zum Erstellen einer Java-Anwendung erforderlich sind.  Wir haben dieses Bild in den Docker Hub eingefügt, und Sie können es finden, indem Sie nach dl4j-mnist-single-layer suchen (wir verwenden ein spezielles Tag, wie in der YAML-Datei definiert).  Wir haben uns entschieden, GraalVM 19.1.1 als Build- und Laufzeit-Java-Umgebung für dieses Projekt zu verwenden, und es ist in das Docker-Image integriert. <br><br>  Wenn das uber jar über die Befehlszeile aufgerufen wird, erstellen wir die Klasse MLPMnistSingleLayerRunner, die uns die beabsichtigte Aktion in Abhängigkeit von den übergebenen Parametern mitteilt: <br><br><pre><code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ MLPMnistSingleLayerRunner mlpMnistRunner = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MLPMnistSingleLayerRunner(); JCommander.newBuilder() .addObject(mlpMnistRunner) .build() .parse(args); mlpMnistRunner.execute(); }</code> </pre> <br>  An uber jar übergebene Parameter werden von dieser Klasse akzeptiert und von der Methode execute () verarbeitet. <br><br>  Wir können ein Modell mit dem Parameter --action train erstellen und das erstellte Modell mit dem Parameter --action evalu bewerten, der an die Java-Anwendung übergeben wird. <br><br>  Die Hauptteile der Java-Anwendung, die diese Arbeit ausführt, befinden sich in den beiden in den folgenden Abschnitten genannten Java-Klassen. <br><br><h3>  Modelltraining </h3><br>  Rufen Sie an <br><br><pre> <code class="plaintext hljs">./runMLPMnist.sh --action train --output-dir ${VH_OUTPUTS_DIR} or java -Djava.library.path="" \ -jar target/MLPMnist-1.0.0-bin.jar \ --action train --output-dir ${VH_OUTPUTS_DIR}</code> </pre><br>  Dieser Befehl erstellt ein Modell mit dem Namen mlpmnist-single-layer.pb in dem Ordner, der durch den zu Beginn der Ausführung übergebenen Parameter --output-dir angegeben wird.  Aus Sicht von Valohai sollte es in $ {VH_OUTPUTS_DIR} platziert werden, was wir tun (siehe die Datei <a href="">valohai.yaml</a> ). <br><br>  Den Quellcode finden Sie in der Klasse <a href="">MLPMNistSingleLayerTrain.java</a> . <br><br><h3>  Modellbewertung </h3><br>  Rufen Sie an <br><br><pre> <code class="plaintext hljs">./runMLPMnist.sh --action evaluate --input-dir ${VH_INPUTS_DIR}/model or java -Djava.library.path="" \ -jar target/MLPMnist-1.0.0-bin.jar \ --action evaluate --input-dir ${VH_INPUTS_DIR}/model</code> </pre><br>  Es wird davon ausgegangen, dass das Modell (das während der Trainingsphase erstellt wurde) mit dem Namen mlpmnist-single-layer.pb in dem Ordner vorhanden ist, der im Parameter --input-dir angegeben ist, der beim Aufruf der Anwendung übergeben wurde. <br><br>  Den Quellcode finden Sie in der Klasse <a href="">MLPMNistSingleLayerEvaluate.java</a> . <br><br>  Ich hoffe, diese kurze Abbildung verdeutlicht, wie eine Java-Anwendung funktioniert, die ein Modell lehrt und bewertet. <br><br>  Dies ist alles, was von uns verlangt wird, aber zögern Sie nicht, mit den restlichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quellen</a> (zusammen mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">README.md</a> und Bash-Skripten) zu spielen und Ihre Neugier und Ihr Verständnis dafür zu befriedigen, wie dies getan wird! <br><br><h3>  Valohai </h3><br>  Mit Valohai können wir unsere Laufzeit, unseren Code und unseren Datensatz frei verknüpfen, wie Sie aus der folgenden YAML-Dateistruktur ersehen können.  Somit können sich verschiedene Komponenten unabhängig voneinander entwickeln.  Folglich werden nur Assembly- und Laufzeitkomponenten in unseren Docker-Container gepackt. <br><br>  Zur Laufzeit sammeln wir die Uber-JAR in einem Docker-Container, laden sie in einen internen oder externen Speicher und laden dann mit dem anderen Ausführungsschritt die Uber-JAR und den Datensatz aus dem Speicher (oder einem anderen Ort), um mit dem Training zu beginnen.  Somit werden die zwei Ausführungsschritte getrennt;  Zum Beispiel können wir ein Glas einmal kompilieren und Hunderte von Trainingsschritten für ein einzelnes Glas ausführen.  Da sich Assembly- und Laufzeitumgebungen nicht so oft ändern müssen, können wir sie zwischenspeichern und auf Code, Datasets und Modelle kann zur Laufzeit dynamisch zugegriffen werden. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">valohai.yaml</a> <br>  Der Hauptteil der Integration unseres Java-Projekts in die Valohai-Infrastruktur besteht darin, die Reihenfolge der Ausführungsschritte in der Datei valohai.yaml im Stammverzeichnis Ihres Projektordners zu bestimmen.  Unser valohai.yaml sieht so aus: <br><br><pre> <code class="xml hljs">--- - step: name: Build-dl4j-mnist-single-layer-java-app image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - cd ${VH_REPOSITORY_DIR} - ./buildUberJar.sh - echo "~~~ Copying the build jar file into ${VH_OUTPUTS_DIR}" - cp target/MLPMnist-1.0.0-bin.jar ${VH_OUTPUTS_DIR}/MLPMnist-1.0.0.jar - ls -lash ${VH_OUTPUTS_DIR} environment: aws-eu-west-1-g2-2xlarge - step: name: Run-dl4j-mnist-single-layer-train-model image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - echo "~~~ Unpack the MNist dataset into ${HOME} folder" - tar xvzf ${VH_INPUTS_DIR}/dataset/mlp-mnist-dataset.tgz -C ${HOME} - cd ${VH_REPOSITORY_DIR} - echo "~~~ Copying the build jar file from ${VH_INPUTS_DIR} to current location" - cp ${VH_INPUTS_DIR}/dl4j-java-app/MLPMnist-1.0.0.jar . - echo "~~~ Run the DL4J app to train model based on the the MNist dataset" - ./runMLPMnist.sh {parameters} inputs: - name: dl4j-java-app description: DL4J Java app file (jar) generated in the previous step 'Build-dl4j-mnist-single-layer-java-app' - name: dataset default: https://github.com/neomatrix369/awesome-ai-ml-dl/releases/download/mnist-dataset-v0.1/mlp-mnist-dataset.tgz description: MNist dataset needed to train the model parameters: - name: --action pass-as: '--action {v}' type: string default: train description: Action to perform ie train or evaluate - name: --output-dir pass-as: '--output-dir {v}' type: string default: /valohai/outputs/ description: Output directory where the model will be created, best to pick the Valohai output directory environment: aws-eu-west-1-g2-2xlarge - step: name: Run-dl4j-mnist-single-layer-evaluate-model image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - cd ${VH_REPOSITORY_DIR} - echo "~~~ Copying the build jar file from ${VH_INPUTS_DIR} to current location" - cp ${VH_INPUTS_DIR}/dl4j-java-app/MLPMnist-1.0.0.jar . - echo "~~~ Run the DL4J app to evaluate the trained MNist model" - ./runMLPMnist.sh {parameters} inputs: - name: dl4j-java-app description: DL4J Java app file (jar) generated in the previous step 'Build-dl4j-mnist-single-layer-java-app' - name: model description: Model file generated in the previous step 'Run-dl4j-mnist-single-layer-train-model' parameters: - name: --action pass-as: '--action {v}' type: string default: evaluate description: Action to perform ie train or evaluate - name: --input-dir pass-as: '--input-dir {v}' type: string default: /valohai/inputs/model description: Input directory where the model created by the previous step can be found created environment: aws-eu-west-1-g2-2xlarge</code> </pre><br><h4>  So funktioniert die Build-dl4j-mnist-Single-Layer-Java-App </h4><br>  Aus der YAML-Datei geht hervor, dass wir diesen Schritt definieren, indem wir zuerst das Docker-Image verwenden und dann das Skript zum Erstellen der Uber-JAR ausführen.  In unserem Docker-Image können Abhängigkeiten der Build-Umgebung (z. B. GraalVM JDK, Maven usw.) angepasst werden, um eine Java-Anwendung zu erstellen.  Wir geben keine Eingaben oder Parameter an, da dies die Montagephase ist.  Sobald der Build erfolgreich ist, kopieren wir das Uber-JAR mit dem Namen MLPMnist-1.0.0-bin.jar (ursprünglicher Name) in den Ordner / valohai / output (dargestellt als $ {VH_OUTPUTS_DIR}).  Alles in diesem Ordner wird automatisch im Speicher Ihres Projekts gespeichert, z. B. im AWS S3-Papierkorb.  Schließlich definieren wir unsere Arbeit für AWS. <br><br><div class="spoiler">  <b class="spoiler_title">Hinweis</b> <div class="spoiler_text">  Das kostenlose Valohai-Konto hat keinen Netzwerkzugriff über den Docker-Container (dies ist standardmäßig deaktiviert). Wenden Sie sich an den Support, um diese Option zu aktivieren (ich musste dasselbe tun). Andernfalls können wir unseren Maven und andere Abhängigkeiten nicht herunterladen während der Montage. <br></div></div><br><h4>  Wie Run-dl4j-mnist-single-layer-train-model funktioniert </h4><br>  Die Semantik der Definition ähnelt dem vorherigen Schritt, außer dass wir zwei Eingaben angeben: eine für uber jar (MLPMnist-1.0.0.jar) und die andere für den Datensatz (entpackt in den Ordner $ {HOME} /. Deeplearning4j).  Wir werden zwei Parameter übergeben - --action train und --output-dir / valohai / output.  Das in diesem Schritt erstellte Modell ist in / valohai / output / model (dargestellt als $ {VH_OUTPUTS_DIR} / model) erstellt. <br><br><div class="spoiler">  <b class="spoiler_title">Hinweis</b> <div class="spoiler_text">  In den Eingabefeldern auf der Registerkarte "Ausführen" der Valohai-Weboberfläche können wir die Ausgabe aus vorherigen Läufen unter Verwendung der Laufnummer, d. H. Nr. 1 oder Nr. 2, zusätzlich zu den URLs datum: // oder http: / auswählen / Wenn Sie einige Buchstaben des Dateinamens eingeben, können Sie auch die gesamte Liste durchsuchen. <br></div></div><br><h4>  Wie Run-dl4j-mnist-single-layer -valu-model funktioniert </h4><br>  Auch dieser Schritt ähnelt dem vorherigen Schritt, außer dass wir zwei Parameter übergeben werden - action evalu und --input-dir / valohai / input / model.  Außerdem haben wir in der Eingabe erneut angegeben: die in der YAML-Datei definierten Abschnitte mit dem Namen dl4j-java-app und model ohne die Standardeinstellung für beide.  Auf diese Weise können wir das Uber-Jar und das Modell auswählen, das wir bewerten möchten. Dieses wurde mithilfe des Schrittes Run-dl4j-mnist-single-layer-train-model über die Weboberfläche erstellt. <br><br>  Ich hoffe, dies erklärt die Schritte in der obigen Definitionsdatei. Wenn Sie jedoch weitere Hilfe benötigen, können Sie sich die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tutorials</a> ansehen. <br><br><h3>  Valohai Webinterface </h3><br>  Nach Erhalt des Kontos können wir uns anmelden und das Projekt mit dem Namen mlpmnist-single-layer erstellen und git repo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">github.com/valohai/mlpmnist-dl4j-example</a> mit dem Projekt verknüpfen und das Projekt speichern. <br><br>  Jetzt können Sie den Schritt abschließen und sehen, wie es ausgeht! <br><br><h4>  Erstellen Sie eine DL4J-Java-Anwendung </h4><br>  Gehen Sie in der Weboberfläche zur Registerkarte „Ausführung“ und kopieren Sie entweder die vorhandene Ausführung oder erstellen Sie eine neue über die Schaltfläche [Ausführung erstellen].  Alle notwendigen Standardparameter werden ausgefüllt.  Wählen Sie Schritt Build-dl4j-mnist-single-layer-java-app. <br><br>  Für die <i>Umgebung habe</i> ich AWS eu-west-1 g2.2xlarge ausgewählt und unten auf der Seite auf die Schaltfläche [Ausführung erstellen] geklickt, um den Start der Ausführung anzuzeigen. <br><br><img src="https://habrastorage.org/webt/le/18/zo/le18zo_udbscmekflaux7kqfjcw.png"><br><br><h3>  Modelltraining </h3><br>  Gehen Sie in der Weboberfläche zur Registerkarte „Ausführung“ und gehen Sie wie im vorherigen Schritt vor und wählen Sie Run-dl4j-mnist-single-layer-train-model aus.  Sie müssen die Java-Anwendung auswählen (geben Sie einfach jar in das Feld ein), die im vorherigen Schritt erstellt wurde.  Der Datensatz wurde bereits mit der Datei valohai.yaml vorab ausgefüllt: <br><br><img src="https://habrastorage.org/webt/md/ls/ov/mdlsovhg3vw9zjnpoeqhxwzgk7w.png"><br><br>  Klicken Sie zum Starten auf [Ausführung erstellen]. <br><br><img src="https://habrastorage.org/webt/6n/mr/wm/6nmrwmveck6cgdughud1xgx7qdg.png"><br><br>  Sie sehen das Ergebnis in der Konsole: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:05 ======================================================================= 11:17:05 LayerName (LayerType) nIn,nOut TotalParams ParamsShape 11:17:05 ======================================================================= 11:17:05 layer0 (DenseLayer) 784,1000 785000 W:{784,1000}, b:{1,1000} 11:17:05 layer1 (OutputLayer) 1000,10 10010 W:{1000,10}, b:{1,10} 11:17:05 ----------------------------------------------------------------------- 11:17:05 Total Parameters: 795010 11:17:05 Trainable Parameters: 795010 11:17:05 Frozen Parameters: 0 11:17:05 ======================================================================= [&lt;--- snipped ---&gt;]</code> </pre><br>  Erstellte Modelle finden Sie während und nach der Ausführung auf der Registerkarte "Ausgänge" der Hauptregisterkarte "Ausführung": <br><br><img src="https://habrastorage.org/webt/pg/g2/-k/pgg2-kmsr85x87fedfoy24lreye.png"><br><br>  Möglicherweise stellen Sie auf der Unterregisterkarte "Ausgaben" mehrere Artefakte fest.  Dies liegt daran, dass wir am Ende jeder Ära Kontrollpunkte beibehalten.  Schauen wir uns das in den Protokollen an: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:14 odolCheckpointListener - Model checkpoint saved: epoch 0, iteration 469, path: /valohai/outputs/checkpoint_0_MultiLayerNetwork.zip [&lt;--- snipped ---&gt;]</code> </pre><br>  Der Prüfpunkt enthält den Status des Modells in drei Dateien: <br><br><pre> <code class="plaintext hljs">configuration.json coefficients.bin updaterState.bin</code> </pre><br><h3>  Modelltraining.  Metadaten </h3><br>  Möglicherweise haben Sie diese Einträge in den Ausführungsprotokollen bemerkt: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:05 {"epoch": 0, "iteration": 0, "score (loss function)": 2.410047} 11:17:07 {"epoch": 0, "iteration": 100, "score (loss function)": 0.613774} 11:17:09 {"epoch": 0, "iteration": 200, "score (loss function)": 0.528494} 11:17:11 {"epoch": 0, "iteration": 300, "score (loss function)": 0.400291} 11:17:13 {"epoch": 0, "iteration": 400, "score (loss function)": 0.357800} 11:17:14 odolCheckpointListener - Model checkpoint saved: epoch 0, iteration 469, path: /valohai/outputs/checkpoint_0_MultiLayerNetwork.zip [&lt;--- snipped ---&gt;]</code> </pre><br>  Mit diesen Daten kann Valohai diese Werte (im JSON-Format) abrufen, die zum Erstellen der Metriken verwendet werden, die während und nach der Ausführung auf der zusätzlichen Registerkarte Metadaten auf der Hauptregisterkarte Ausführungen angezeigt werden: <br><br><img src="https://habrastorage.org/webt/et/p-/se/etp-sezekre2qlznmvgdzlgds0a.png"><br><br>  Wir konnten dies tun, indem wir die ValohaiMetadataCreator-Klasse mit dem Modell verbanden, sodass Valohai während des Trainings auf diese Klasse verweist.  Bei dieser Klasse leiten wir mehrere Epochen ab, die Anzahl der Iterationen und den Score (Wert der Verlustfunktion).  Hier ist ein Codeausschnitt aus der Klasse: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">iterationDone</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Model model, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> iteration, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> epoch)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (printIterations &lt;= <span class="hljs-number"><span class="hljs-number">0</span></span>) printIterations = <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (iteration % printIterations == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> score = model.score(); System.out.println(String.format( <span class="hljs-string"><span class="hljs-string">"{\"epoch\": %d, \"iteration\": %d, \"score (loss function)\": %f}"</span></span>, epoch, iteration, score) ); } }</code> </pre><br><h3>  Modellbewertung </h3><br>  Nachdem das Modell im vorherigen Schritt erfolgreich erstellt wurde, sollte es ausgewertet werden.  Wir erstellen eine neue Ausführung auf die gleiche Weise wie zuvor, wählen diesmal jedoch den Schritt Run-dl4j-mnist-single-layer -valu-model aus.  Wir müssen die Java-Anwendung (MLPMnist-1.0.0.jar) und das erstellte Modell (mlpmnist-single-layer.pb) erneut auswählen, bevor wir mit der Ausführung beginnen (wie unten gezeigt): <br><br><img src="https://habrastorage.org/webt/e9/_b/am/e9_bamnlhownoo40utziaqazg8e.png"><br><br>  Nachdem Sie das gewünschte Modell als Eingabe ausgewählt haben, klicken Sie auf die Schaltfläche [Ausführung erstellen].  Es wird schneller ausgeführt als das vorherige, und wir werden das folgende Ergebnis sehen: <br><br><img src="https://habrastorage.org/webt/gp/0i/co/gp0icomuurv7a0gt-niye5hyri4.png"><br><br>  Wir sehen, dass unsere "Hallo Welt" zu einem Modell führte, dessen Genauigkeit basierend auf einem Testdatensatz etwa 97% beträgt.  Die Verwirrungsmatrix hilft dabei, Fälle zu finden, in denen eine Ziffer fälschlicherweise als andere Ziffer vorhergesagt wurde. <br><br>  Die Frage bleibt (und geht über den Rahmen dieses Beitrags hinaus): Wie gut ist das Modell, wenn es mit realen Daten konfrontiert wird? <br><br>  Um ein Git-Repository zu klonen, müssen Sie Folgendes tun: <br><br><pre> <code class="plaintext hljs"> $ git clone https://github.com/valohai/mlpmnist-dl4j-example</code> </pre><br>  Dann müssen wir unser Valohai-Projekt, das über die Weboberfläche im obigen Abschnitt erstellt wurde, mit dem Projekt verknüpfen, das auf unserem lokalen Computer gespeichert ist (dem, den wir gerade geklont haben).  Führen Sie dazu die folgenden Befehle aus: <br><br><pre> <code class="plaintext hljs">$ cd mlpmnist-dl4j-example $ vh project --help ### to see all the project-specific options we have for Valohai $ vh project link</code> </pre><br>  Ihnen wird ungefähr so ​​gezeigt: <br><br><pre> <code class="plaintext hljs">[ 1] mlpmnist-single-layer ... Which project would you like to link with /path/to/mlpmnist-dl4j-example? Enter [n] to create a new project.:</code> </pre><br>  Wählen Sie 1 (oder diejenige, die zu Ihnen passt) und Sie sollten diese Meldung sehen: <br><br><pre> <code class="plaintext hljs">Success! Linked /path/to/mlpmnist-dl4j-example to mlpmnist-single-layer.</code> </pre><br>  Bevor Sie fortfahren, stellen Sie sicher, dass Ihr Valohai-Projekt mit dem neuesten Git-Projekt synchronisiert ist. <br><br><pre> <code class="plaintext hljs"> $ vh project fetch</code> </pre><br><img src="https://habrastorage.org/webt/h0/l4/vb/h0l4vbe1eqis5kb9sd7gfslbozk.png"><br><br>  Jetzt können wir die Schritte von der CLI aus ausführen mit: <br><br><pre> <code class="plaintext hljs"> $ vh exec run Build-dl4j-mnist-single-layer-java-app</code> </pre><br>  Nachdem die Ausführung abgeschlossen ist, können wir dies überprüfen mit: <br><br><pre> <code class="plaintext hljs">$ vh exec info $ vh exec logs $ vh exec watch</code> </pre><br><h3>  Fazit </h3><br>  Wie wir gesehen haben, ist es sehr praktisch, mit DL4J und Valohai zusammenzuarbeiten.  Darüber hinaus können wir die verschiedenen Komponenten, aus denen unsere Experimente (Forschung) bestehen, dh die Build- / Laufzeitumgebung, den Code und den Datensatz, entwickeln und in unser Projekt integrieren. <br><br>  Die in diesem Beitrag verwendeten Beispielvorlagen sind eine gute Möglichkeit, komplexere Projekte zu erstellen.  Und Sie können die Web- oder Befehlszeilenschnittstelle verwenden, um Ihre Arbeit mit Valohai zu erledigen.  Mit der CLI können Sie sie auch in Ihre Installationen und Skripte (oder sogar in CRON- oder CI / CD-Jobs) integrieren. <br><br>  Darüber hinaus ist klar, dass ich mich bei der Arbeit an einem Projekt im Zusammenhang mit AI / ML / DL nicht um die Erstellung und Wartung einer End-to-End-Pipeline kümmern muss (was viele andere in der Vergangenheit tun mussten). <br><br><h5>  Referenzen </h5><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das mlpmnist-dl4j-Beispielprojekt auf GitHub</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fantastische AI ​​/ ML / DL-Ressourcen</a> </li><li>  <a href="">Java AI / ML / DL-Ressourcen</a> </li><li>  <a href="">Deep Learning und DL4J-Ressourcen</a> </li></ol><br>  Vielen Dank für Ihre Aufmerksamkeit! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de469405/">https://habr.com/ru/post/de469405/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de469393/index.html">Flare-On 2019 Zuschreibung</a></li>
<li><a href="../de469395/index.html">Wo und wie werden Mehrspalten verwendet (CSS-Spalten)</a></li>
<li><a href="../de469399/index.html">Wi-Fi im Arkhangelskoye Museum-Estate</a></li>
<li><a href="../de469401/index.html">3CX WebMeeting Service Update, Elastix Online Converter und neue Video-Tutorials</a></li>
<li><a href="../de469403/index.html">Wir interviewen einen Kandidaten für die Position des Senior Software Developer</a></li>
<li><a href="../de469407/index.html">ARIES PLC110 [M02] -MS4, HMI, OPC und SCADA oder wie sehr eine Person Kamillentee benötigt. Teil 1</a></li>
<li><a href="../de469409/index.html">Linux-Profilerstellung mit Performance Analyzer</a></li>
<li><a href="../de469411/index.html">RE: Schmerz und Tränen in Svelte 3</a></li>
<li><a href="../de469413/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends für die letzte Woche Nr. 382 (22. - 29. September 2019)</a></li>
<li><a href="../de469415/index.html">Transaktionsisolationsstufen für die Kleinsten</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§Ωüèº üîÆ üë®üèº‚Äçüåæ Apple Machine Learning Tools üë©‚Äçüöí üßëüèø‚Äçü§ù‚Äçüßëüèæ üí¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In den letzten Jahren hat das Thema k√ºnstliche Intelligenz und maschinelles Lernen aufgeh√∂rt, etwas f√ºr Menschen aus dem Bereich der Fiktion zu sein, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apple Machine Learning Tools</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redmadrobot/blog/418307/"><p><img src="https://habrastorage.org/webt/si/by/p7/sibyp7evcy3vtvyh7jthlpqh68m.png"></p><br><p>  In den letzten Jahren hat das Thema k√ºnstliche Intelligenz und maschinelles Lernen aufgeh√∂rt, etwas f√ºr Menschen aus dem Bereich der Fiktion zu sein, und ist fest in den Alltag eingetreten.  Soziale Netzwerke bieten die Teilnahme an Veranstaltungen an, die f√ºr uns von Interesse sind, Autos auf den Stra√üen, die gelernt haben, sich ohne Fahrer zu bewegen, und ein Sprachassistent am Telefon teilt mit, wann es besser ist, das Haus zu verlassen, um Staus zu vermeiden, und ob Sie einen Regenschirm mitnehmen sollten. </p><br><p>  In diesem Artikel werden wir die von Apple-Entwicklern angebotenen Tools f√ºr maschinelles Lernen betrachten, analysieren, was das Unternehmen auf der WWDC18 in diesem Bereich neu gezeigt hat, und versuchen zu verstehen, wie Sie all dies in die Praxis umsetzen k√∂nnen. </p><a name="habracut"></a><br><h2 id="mashinnoe-obuchenie">  Maschinelles Lernen </h2><br><p>  Maschinelles Lernen ist also ein Prozess, bei dem ein System mithilfe bestimmter Datenanalysealgorithmen und der Verarbeitung einer Vielzahl von Beispielen Muster identifiziert und diese zur Vorhersage der Eigenschaften neuer Daten verwendet. </p><br><p>  Maschinelles Lernen entstand aus der Theorie heraus, dass Computer selbstst√§ndig lernen k√∂nnen und noch nicht f√ºr bestimmte Aktionen programmiert sind.  Mit anderen Worten, im Gegensatz zu herk√∂mmlichen Programmen mit vordefinierten Anweisungen zur L√∂sung spezifischer Probleme kann das System beim maschinellen Lernen lernen, wie man Muster unabh√§ngig erkennt und Vorhersagen trifft. </p><br><h2 id="bnns-i-cnn">  BNNS und CNN </h2><br><p>  Apple setzt seit geraumer Zeit maschinelle Lerntechnologien auf seinen Ger√§ten ein: Mail identifiziert Spam-E-Mails, Siri hilft Ihnen, schnell Antworten auf Ihre Fragen zu finden, Fotos erkennen Gesichter in Bildern. </p><br><p> Auf der WWDC16 stellte das Unternehmen zwei auf neuronalen Netzen basierende APIs vor - Basic Neural Network Subroutines (BNNS) und Convolutional Neural Networks (CNN).  BNNS ist Teil des Accelerate-Systems, das die Grundlage f√ºr schnelle Berechnungen auf der CPU bildet, und CNN ist die Metal Performance Shaders-Bibliothek, die die GPU verwendet.  Hier erfahren Sie beispielsweise mehr √ºber diese Technologien. </p><br><h2 id="core-ml-i-turi-create">  Core ML und Turi erstellen </h2><br><p>  Im vergangenen Jahr k√ºndigte Apple ein Framework an, das die Arbeit mit Technologien f√ºr maschinelles Lernen erheblich erleichtert - Core ML.  Es basiert auf der Idee, ein vorab trainiertes Datenmodell in nur wenigen Codezeilen in Ihre Anwendung zu integrieren. </p><br><p><img src="https://habrastorage.org/webt/eg/dl/rz/egdlrzk40ao2z5a_eijvug8dhbc.png"></p><br><p>  Mit Core ML k√∂nnen Sie viele Funktionen implementieren: </p><br><ul><li>  Definition von Objekten in einem Foto und Video; </li><li>  pr√§diktive Texteingabe; </li><li>  Gesichtsverfolgung und -erkennung; </li><li>  Bewegungsanalyse; </li><li>  Barcode-Definition; </li><li>  Verst√§ndnis und Anerkennung von Text; </li><li>  Echtzeit-Bilderkennung; </li><li>  Bildstilisierung; </li><li>  und vieles mehr. </li></ul><br><p>  Core ML verwendet wiederum Low-Level-Metal, Accelerate und BNNS, und daher sind die Ergebnisse der Berechnungen sehr schnell. </p><br><p>  Der Kernel unterst√ºtzt neuronale Netze, verallgemeinerte lineare Modelle, Feature-Engineering, baumbasierte Entscheidungsalgorithmen (Baumensembles), Support-Vektor-Maschinen-Methode und Pipeline-Modelle. </p><br><p>  Apple zeigte jedoch zun√§chst keine eigenen Technologien zum Erstellen und Trainieren von Modellen, sondern entwickelte nur einen Konverter f√ºr andere beliebte Frameworks: Caffe, Keras, Scikit-Learn, XGBoost, LIBSVM. </p><br><p>  Die Verwendung von Tools von Drittanbietern war oft nicht die einfachste Aufgabe, die trainierten Modelle waren ziemlich gro√ü und das Training selbst nahm viel Zeit in Anspruch. </p><br><p>  Ende des Jahres f√ºhrte das Unternehmen Turi Create ein - ein Modell-Lern-Framework, dessen Hauptidee die Benutzerfreundlichkeit und Unterst√ºtzung f√ºr eine Vielzahl von Szenarien war - Bildklassifizierung, Definition von Objekten, Empfehlungssysteme und viele andere.  Trotz seiner relativ einfachen Bedienung unterst√ºtzte Turi Create nur Python. </p><br><h2 id="create-ml">  Erstellen Sie ML </h2><br><p>  In diesem Jahr zeigte Apple neben Core ML 2 endlich ein eigenes Tool f√ºr Trainingsmodelle - das Create ML Framework mit den nativen Technologien von Apple - Xcode und Swift. </p><br><p>  Es funktioniert schnell und das Erstellen von Modellmodellen mit Create ML ist wirklich einfach. </p><br><p>  Auf der WWDC wurde die beeindruckende Leistung von Create ML und Core ML 2 am Beispiel der Memrise-Anwendung angek√ºndigt.  Wenn das Trainieren eines Modells mit 20.000 Bildern fr√ºher 24 Stunden gedauert hat, reduziert Create ML diese Zeit auf dem MacBook Pro auf 48 Minuten und auf dem iMac Pro auf bis zu 18 Minuten.  Die Gr√∂√üe des trainierten Modells verringerte sich von 90 MB auf 3 MB. </p><br><p>  Mit ML erstellen k√∂nnen Sie Bilder, Texte und strukturierte Objekte als Tabellen verwenden, z. B. als Quelldaten. </p><br><p><img src="https://habrastorage.org/webt/uk/di/2e/ukdi2ewm3e2ax6bbr3ceu_fymlu.png"></p><br><h2 id="klassifikaciya-izobrazheniy">  Bildklassifizierung </h2><br><p>  Lassen Sie uns zun√§chst sehen, wie die Bildklassifizierung funktioniert.  Um das Modell zu trainieren, ben√∂tigen wir einen ersten Datensatz: Wir machen drei Gruppen von Tierfotos: Hunde, Katzen und V√∂gel und verteilen sie in Ordnern mit den entsprechenden Namen, die zu den Namen der Kategorien des Modells werden.  Jede Gruppe enth√§lt 100 Bilder mit einer Aufl√∂sung von bis zu 1920 √ó 1080 Pixel und einer Gr√∂√üe von bis zu 1 MB.  Fotos sollten so unterschiedlich wie m√∂glich sein, damit sich das trainierte Modell nicht auf Zeichen wie die Farbe im Bild oder den umgebenden Raum st√ºtzt. </p><br><p><img src="https://habrastorage.org/webt/w8/oz/_9/w8oz_9t_3_0fyz86xusotsdp9zi.png"></p><br><p>  Um zu √ºberpr√ºfen, wie gut ein trainiertes Modell mit der Objekterkennung umgehen kann, ben√∂tigen Sie einen Testdatensatz - Bilder, die nicht im Originaldatensatz enthalten sind. </p><br><p>  Apple bietet zwei M√∂glichkeiten zur Interaktion mit Create ML: Verwenden der Benutzeroberfl√§che auf dem MacOS Playground Xcode und programmgesteuertes Verwenden von CreateMLUI.framework und CreateML.framework.  Mit der ersten Methode reicht es aus, ein paar Codezeilen zu schreiben, die ausgew√§hlten Bilder in den angegebenen Bereich zu √ºbertragen und zu warten, bis das Modell lernt. </p><br><p><img src="https://habrastorage.org/webt/b6/zb/w_/b6zbw_ihfbmt2lx0ovib4nmkfsk.gif"></p><br><p>  Auf dem Macbook Pro 2017 in der maximalen Konfiguration dauerte das Training 29 Sekunden f√ºr 10 Iterationen, und die Gr√∂√üe des trainierten Modells betrug 33 KB.  Es sieht beeindruckend aus. </p><br><p>  Versuchen wir herauszufinden, wie wir solche Indikatoren erreicht haben und was ‚Äûunter der Haube‚Äú liegt. <br>  Die Aufgabe, Bilder zu klassifizieren, ist eine der beliebtesten Anwendungen von Faltungs-Neuronalen Netzen.  Zun√§chst lohnt es sich zu erkl√§ren, was sie sind. </p><br><p>  Eine Person, die ein Bild eines Tieres sieht, kann es anhand von Unterscheidungsmerkmalen schnell einer bestimmten Klasse zuordnen.  Ein neuronales Netzwerk verh√§lt sich √§hnlich, indem es nach grundlegenden Merkmalen sucht.  Unter Verwendung des anf√§nglichen Pixelarrays als Eingabe werden Informationen nacheinander durch Gruppen von Faltungsschichten geleitet und zunehmend komplexere Abstraktionen erstellt.  Auf jeder nachfolgenden Ebene lernt sie, bestimmte Merkmale hervorzuheben - zuerst Linien, dann Liniens√§tze, geometrische Formen, K√∂rperteile usw.  Auf der letzten Ebene erhalten wir den Abschluss einer Klasse oder Gruppe wahrscheinlicher Klassen. </p><br><p>  Im Fall von Create ML wird das Training des neuronalen Netzwerks nicht von Grund auf neu durchgef√ºhrt.  Das Framework verwendet ein neuronales Netzwerk, das zuvor auf einem riesigen Datensatz trainiert wurde, der bereits eine gro√üe Anzahl von Schichten enth√§lt und eine hohe Genauigkeit aufweist. </p><br><p><img src="https://habrastorage.org/webt/go/qu/el/goquell4agcijc9duege4cg1ydw.png"></p><br><p>  Diese Technologie wird als Transferlernen bezeichnet.  Damit k√∂nnen Sie die Architektur eines vorab geschulten Netzwerks so √§ndern, dass es zur L√∂sung eines neuen Problems geeignet ist.  Das ge√§nderte Netzwerk wird dann auf einem neuen Datensatz trainiert. </p><br><p>  Erstellen Sie w√§hrend des Trainings Ausz√ºge aus dem Foto mit etwa 1000 Unterscheidungsmerkmalen.  Dies kann die Form von Objekten, die Farbe von Texturen, die Position der Augen, Gr√∂√üen und viele andere sein. <br>  Es ist zu beachten, dass der urspr√ºngliche Datensatz, auf dem das verwendete neuronale Netzwerk wie unser trainiert wird, m√∂glicherweise Fotos von Katzen, Hunden und V√∂geln enth√§lt, diese Kategorien jedoch nicht speziell zugeordnet sind.  Alle Kategorien bilden eine Hierarchie.  Daher ist es einfach unm√∂glich, dieses Netzwerk in seiner reinen Form anzuwenden - es ist notwendig, es auf unsere Daten umzuschulen. </p><br><p>  Am Ende des Prozesses sehen wir, wie genau unser Modell nach mehreren Iterationen trainiert und getestet wurde.  Um die Ergebnisse zu verbessern, k√∂nnen wir die Anzahl der Bilder im Originaldatensatz erh√∂hen oder die Anzahl der Iterationen √§ndern. </p><br><p><img src="https://habrastorage.org/webt/k1/rz/to/k1rzto4lzngwwfo46taxa9vnbms.png"></p><br><p>  Als n√§chstes k√∂nnen wir das Modell selbst an einem Testdatensatz testen.  Die darin enthaltenen Bilder m√ºssen eindeutig sein, d. H.  Geben Sie den Quellensatz nicht ein. </p><br><p><img src="https://habrastorage.org/webt/lw/u8/el/lwu8eld5v8q6jwqyeaygwkyzvwi.png"></p><br><p>  F√ºr jedes Bild wird ein <em>Vertrauensindikator</em> angezeigt - wie genau mit Hilfe unseres Modells die Kategorie erkannt wurde. </p><br><p>  Bei fast allen Fotos, mit seltenen Ausnahmen, lag diese Zahl bei 100%.  Ich habe speziell das Bild, das Sie oben sehen, zum Testdatensatz hinzugef√ºgt und, wie Sie sehen k√∂nnen, 86% des Hundes und 13% des Vogels darin ML erkannt. </p><br><p>  Die Modellschulung ist abgeschlossen. Sie m√ºssen lediglich die * .mlmodel-Datei speichern und Ihrem Projekt hinzuf√ºgen. </p><br><p><img src="https://habrastorage.org/webt/vd/ey/xb/vdeyxbibcdbgd3f2jb6ozsrpa_u.png"></p><br><p>  Um das Modell zu testen, habe ich eine einfache Anwendung mit dem Vision-Framework geschrieben.  Sie k√∂nnen mit Core ML-Modellen arbeiten und Probleme damit l√∂sen, z. B. Bildklassifizierung oder Objekterkennung. </p><br><p>  Unsere Anwendung erkennt das Bild von der Kamera des Ger√§ts und zeigt die Kategorie und den Prozentsatz des Vertrauens in die Klassifizierung an. </p><br><p>  Wir initialisieren das Core ML-Modell f√ºr die Arbeit mit Vision und konfigurieren die Abfrage: </p><br><pre><code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setupVision</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> visionModel = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>? <span class="hljs-type"><span class="hljs-type">VNCoreMLModel</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: <span class="hljs-type"><span class="hljs-type">AnimalsClassifier</span></span>().model) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">fatalError</span></span>(<span class="hljs-string"><span class="hljs-string">"Can't load VisionML model"</span></span>) } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> request = <span class="hljs-type"><span class="hljs-type">VNCoreMLRequest</span></span>(model: visionModel) { (request, error) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> results = request.results <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.handleRequestResults(results) } requests = [request] }</code> </pre> <br><p>  F√ºgen Sie eine Methode hinzu, die die Ergebnisse von VNCoreMLRequest verarbeitet.  Wir zeigen nur diejenigen mit einem Vertrauensindikator von mehr als 70%: </p><br><pre> <code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">handleRequestResults</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> results: [</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">Any</span></span></span></span><span class="hljs-function"><span class="hljs-params">])</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> categoryText: <span class="hljs-type"><span class="hljs-type">String?</span></span> <span class="hljs-keyword"><span class="hljs-keyword">defer</span></span> { <span class="hljs-type"><span class="hljs-type">DispatchQueue</span></span>.main.async { <span class="hljs-keyword"><span class="hljs-keyword">self</span></span>.categoryLabel.text = categoryText } } <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> foundObject = results .compactMap({ $<span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span>? <span class="hljs-type"><span class="hljs-type">VNClassificationObservation</span></span> }) .first(<span class="hljs-keyword"><span class="hljs-keyword">where</span></span>: { $<span class="hljs-number"><span class="hljs-number">0</span></span>.confidence &gt; <span class="hljs-number"><span class="hljs-number">0.7</span></span> }) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { categoryText = <span class="hljs-literal"><span class="hljs-literal">nil</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> category = categoryTitle(identifier: foundObject.identifier) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> confidence = <span class="hljs-string"><span class="hljs-string">"\(round(foundObject.confidence * 100 * 100) / 100)%"</span></span> categoryText = <span class="hljs-string"><span class="hljs-string">"\(category) \(confidence)"</span></span> }</code> </pre><br><p>  Und das letzte - wir werden die Delegatenmethode AVCaptureVideoDataOutputSampleBufferDelegate hinzuf√ºgen, die mit jedem neuen Bild von der Kamera aufgerufen wird, und die Anforderung ausf√ºhren: </p><br><pre> <code class="hljs swift"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">captureOutput</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">_</span></span></span></span><span class="hljs-function"><span class="hljs-params"> output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">guard</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> pixelBuffer = <span class="hljs-type"><span class="hljs-type">CMSampleBufferGetImageBuffer</span></span>(sampleBuffer) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> requestOptions: [<span class="hljs-type"><span class="hljs-type">VNImageOption</span></span>: <span class="hljs-type"><span class="hljs-type">Any</span></span>] = [:] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> cameraIntrinsicData = <span class="hljs-type"><span class="hljs-type">CMGetAttachment</span></span>( sampleBuffer, key: kCMSampleBufferAttachmentKey_CameraIntrinsicMatrix, attachmentModeOut: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>) { requestOptions = [.cameraIntrinsics:cameraIntrinsicData] } <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> imageRequestHandler = <span class="hljs-type"><span class="hljs-type">VNImageRequestHandler</span></span>( cvPixelBuffer: pixelBuffer, options: requestOptions) <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> imageRequestHandler.perform(requests) } <span class="hljs-keyword"><span class="hljs-keyword">catch</span></span> { <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(error) } }</code> </pre> <br><p>  Lassen Sie uns √ºberpr√ºfen, wie gut das Modell mit seiner Aufgabe zurechtkommt: </p><br><p><img src="https://habrastorage.org/webt/fy/5k/fl/fy5kflqc3p02w0mo0dwgaar3vle.gif"></p><br><p>  Die Kategorie wird mit ziemlich hoher Genauigkeit bestimmt. Dies ist besonders √ºberraschend, wenn man bedenkt, wie schnell das Training verlief und wie klein der urspr√ºngliche Datensatz war.  Vor einem dunklen Hintergrund zeigt das Modell regelm√§√üig V√∂gel, aber ich denke, dies kann leicht gel√∂st werden, indem die Anzahl der Bilder im Originaldatensatz erh√∂ht oder das akzeptable Mindestma√ü an Vertrauen erh√∂ht wird. </p><br><p>  Wenn Sie das Modell neu trainieren m√∂chten, um eine andere Kategorie zu klassifizieren, f√ºgen Sie einfach eine neue Gruppe von Bildern hinzu und wiederholen Sie den Vorgang - dies dauert einige Minuten. </p><br><p>  Als Experiment habe ich einen weiteren Datensatz erstellt, in dem ich alle Fotos von Katzen auf dem Foto einer Katze aus verschiedenen Blickwinkeln ge√§ndert habe, jedoch auf demselben Hintergrund und in derselben Umgebung.  In diesem Fall machte das Modell fast immer Fehler und erkannte die Kategorie in einem leeren Raum, wobei es sich anscheinend auf Farbe als Schl√ºsselmerkmal st√ºtzte. </p><br><p>  Ein weiteres interessantes Feature, das erst in diesem Jahr in Vision eingef√ºhrt wurde, ist die F√§higkeit, Objekte im Bild in Echtzeit zu erkennen.  Es wird durch die VNRecognizedObjectObservation-Klasse dargestellt, mit der Sie die Kategorie eines Objekts und seine Position abrufen k√∂nnen - boundingBox. </p><br><p><img src="https://habrastorage.org/webt/fo/96/cb/fo96cbqh0flkktb9umjrfxxofu4.jpeg"></p><br><p>  Mit Create ML k√∂nnen jetzt keine Modelle zur Implementierung dieser Funktionalit√§t erstellt werden.  Apple schl√§gt in diesem Fall die Verwendung von Turi Create vor.  Der Vorgang ist nicht viel komplizierter als der oben beschriebene: Sie m√ºssen Kategorieordner mit Fotos und einer Datei vorbereiten, in der f√ºr jedes Bild die Koordinaten des Rechtecks ‚Äã‚Äãangegeben werden, in dem sich das Objekt befindet. </p><br><h2 id="natural-language-processing">  Verarbeitung nat√ºrlicher Sprache </h2><br><p>  Die n√§chste Funktion zum Erstellen von ML besteht darin, Modelle zu trainieren, um Texte in nat√ºrlicher Sprache zu klassifizieren - beispielsweise um die emotionale F√§rbung von S√§tzen zu bestimmen oder Spam zu erkennen. </p><br><p><img src="https://habrastorage.org/webt/xv/fq/48/xvfq489qejhdwl_uitxcc-2yyii.png"></p><br><p>  Um ein Modell zu erstellen, m√ºssen wir eine Tabelle mit dem Originaldatensatz - S√§tzen oder ganzen Texten, die einer bestimmten Kategorie zugeordnet sind - sammeln und das Modell mithilfe des MLTextClassifier-Objekts trainieren: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> data = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MLDataTable</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">contentsOf: URL(fileURLWithPath: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"/Users/CreateMLTest/texts.json"</span></span></span></span></span><span class="hljs-function">)) </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">let</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">trainingData, testingData</span></span></span><span class="hljs-function">)</span></span> = data.randomSplit(<span class="hljs-keyword"><span class="hljs-keyword">by</span></span>: <span class="hljs-number"><span class="hljs-number">0.8</span></span>, seed: <span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> textClassifier = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">MLTextClassifier</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">trainingData: trainingData, textColumn: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"text"</span></span></span></span><span class="hljs-function"><span class="hljs-params">, labelColumn: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"label"</span></span></span></span></span><span class="hljs-function">) </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">try</span></span></span><span class="hljs-function"> textClassifier.</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">write</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">to: URL(fileURLWithPath: </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"/Users/CreateMLTest/TextClassifier.mlmodel"</span></span></span></span></span><span class="hljs-function">))</span></span></code> </pre> <br><p>  In diesem Fall ist das trainierte Modell vom Typ Text Classifier: </p><br><p><img src="https://habrastorage.org/webt/kg/j1/ws/kgj1wst4121ojpwfk73yehmte_m.png"></p><br><h2 id="tablichnye-dannye">  Tabellarische Daten </h2><br><p>  Schauen wir uns eine weitere Funktion von Create ML genauer an - das Trainieren eines Modells unter Verwendung strukturierter Daten (Tabellen). </p><br><p>  Wir werden eine Testanwendung schreiben, die den Preis einer Wohnung basierend auf ihrem Standort auf der Karte und anderen angegebenen Parametern vorhersagt. </p><br><p>  Wir haben also eine Tabelle mit abstrakten Daten zu Wohnungen in Moskau in Form einer CSV-Datei: Die Fl√§che jeder Wohnung, Etage, Anzahl der R√§ume und Koordinaten (Breite und L√§nge) sind bekannt.  Dar√ºber hinaus sind die Kosten f√ºr jede Wohnung bekannt.  Je n√§her am Zentrum oder je gr√∂√üer die Fl√§che, desto h√∂her der Preis. </p><br><p><img src="https://habrastorage.org/webt/hd/-w/77/hd-w77qhysj80_kapqbqddwdhyi.png"></p><br><p>  Die Aufgabe von Create ML besteht darin, ein Modell zu erstellen, mit dem der Preis einer Wohnung anhand dieser Merkmale vorhergesagt werden kann.  Eine solche Aufgabe beim maschinellen Lernen wird als Regressionsaufgabe bezeichnet und ist ein klassisches Beispiel f√ºr das Lernen mit einem Lehrer. </p><br><p>  Create ML unterst√ºtzt viele Modelle - lineare Regression, Entscheidungsbaumregression, Baumklassifizierer, logistische Regression, zuf√§lliger Waldklassifizierer, verst√§rkte Baumregression usw. </p><br><p>  Wir werden das MLRegressor-Objekt verwenden, das basierend auf den Eingabedaten die beste Option ausw√§hlt. <br>  Initialisieren Sie zun√§chst das MLDataTable-Objekt mit dem Inhalt unserer CSV-Datei: </p><br><pre> <code class="hljs lisp">let trainingFile = URL(<span class="hljs-name"><span class="hljs-name">fileURLWithPath</span></span>: <span class="hljs-string"><span class="hljs-string">"/Users/CreateMLTest/Apartments.csv"</span></span>) let apartmentsData = try MLDataTable(<span class="hljs-name"><span class="hljs-name">contentsOf</span></span>: trainingFile)</code> </pre> <br><p>  Wir teilen den anf√§nglichen Datensatz in Daten f√ºr Modelltraining und -tests in einem Prozentsatz von 80/20 auf: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> (trainingData, testData) = apartmentsData.randomSplit(<span class="hljs-keyword"><span class="hljs-keyword">by</span></span>: <span class="hljs-number"><span class="hljs-number">0.8</span></span>, seed: <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  Wir erstellen das MLRegressor-Modell, das die Daten f√ºr das Training und den Namen der Spalte angibt, deren Werte wir vorhersagen m√∂chten.  Der aufgabenspezifische Regressortyp (linear, Entscheidungsbaum, verst√§rkter Baum oder zuf√§llige Gesamtstruktur) wird basierend auf der Untersuchung der Eingabedaten automatisch ausgew√§hlt.  Wir k√∂nnen auch Feature-Spalten angeben - spezifische Parameterspalten f√ºr die Analyse. In diesem Beispiel ist dies jedoch nicht erforderlich. Wir verwenden alle Parameter.  Speichern Sie am Ende das trainierte Modell und f√ºgen Sie es dem Projekt hinzu: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> model = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> <span class="hljs-type"><span class="hljs-type">MLRegressor</span></span>(trainingData: apartmentsData, targetColumn: <span class="hljs-string"><span class="hljs-string">"Price"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> modelPath = <span class="hljs-type"><span class="hljs-type">URL</span></span>(fileURLWithPath: <span class="hljs-string"><span class="hljs-string">"/Users/CreateMLTest/ApartmentsPricer.mlmodel"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> model.write(to: modelPath, metadata: <span class="hljs-literal"><span class="hljs-literal">nil</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/xv/ci/-e/xvci-e7bhoxwfpvwtjdmwqwwhv0.png"></p><br><p>  In diesem Beispiel sehen wir, dass der Modelltyp bereits Pipeline-Regressor ist und das Feld Beschreibung den automatisch ausgew√§hlten Regressortyp - Boosted Tree Regression Model - enth√§lt.  Die Parameter Inputs und Outputs entsprechen den Spalten der Tabelle, ihr Datentyp wurde jedoch Double. </p><br><p>  √úberpr√ºfen Sie nun das Ergebnis. <br>  Initialisieren Sie das Modellobjekt: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> model = <span class="hljs-type"><span class="hljs-type">ApartmentsPricer</span></span>()</code> </pre> <br><p>  Wir rufen die Vorhersagemethode auf und √ºbergeben die angegebenen Parameter an sie: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> area = Double(areaSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> floor = Double(floorSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> rooms = Double(roomsSlider.<span class="hljs-keyword"><span class="hljs-keyword">value</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> latitude = annotation.coordinate.latitude <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> longitude = annotation.coordinate.longitude <span class="hljs-keyword"><span class="hljs-keyword">let</span></span> prediction = <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>? model.prediction( area: area, floor: floor, rooms: rooms, latitude: latitude, longitude: longitude)</code> </pre><br><p>  Wir zeigen den prognostizierten Wert der Kosten an: </p><br><pre> <code class="hljs swift"><span class="hljs-keyword"><span class="hljs-keyword">let</span></span> price = prediction?.price priceLabel.text = formattedPrice(price)</code> </pre> <br><p>  Wenn Sie einen Punkt auf der Karte oder Parameterwerte √§ndern, erhalten wir den Wohnungspreis ziemlich nahe an unseren Testdaten: </p><br><p><img src="https://habrastorage.org/webt/pu/j-/v1/puj-v1m8x0ghkxrh1fwogdejxfu.png"></p><br><h2 id="zaklyuchenie">  Fazit </h2><br><p>  Das Create ML-Framework ist jetzt eine der einfachsten M√∂glichkeiten, mit Technologien f√ºr maschinelles Lernen zu arbeiten.  Es ist noch nicht m√∂glich, Modelle zur L√∂sung einiger Probleme zu erstellen: Erkennung von Objekten in einem Bild, Stilisierung eines Fotos, Bestimmung √§hnlicher Bilder, Erkennung physikalischer Aktionen anhand von Daten eines Beschleunigungsmessers oder Gyroskops, die beispielsweise von Turi Create verarbeitet werden. </p><br><p>  Es ist jedoch anzumerken, dass Apple im vergangenen Jahr in diesem Bereich ernsthafte Fortschritte erzielt hat, und wir werden mit Sicherheit bald die Entwicklung der beschriebenen Technologien sehen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418307/">https://habr.com/ru/post/de418307/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418295/index.html">Fast alles, was Sie √ºber Gleitkomma in ARM wissen wollten, aber Angst hatten zu fragen</a></li>
<li><a href="../de418297/index.html">Smartphone Bewertung Neffos N1</a></li>
<li><a href="../de418301/index.html">Die gro√üe Konfrontation des Mars im Jahr 2018: Wie man beobachtet und was man erwartet</a></li>
<li><a href="../de418303/index.html">Vanessa-Automation - ein Tool zum Testen von Anwendungsl√∂sungen auf der 1C: Enterprise-Plattform</a></li>
<li><a href="../de418305/index.html">Wie viele Objekte gibt Python beim Ausf√ºhren von Skripten aus?</a></li>
<li><a href="../de418309/index.html">Wie Plancks astronomischer Satellit unsere Wahrnehmung des Universums f√ºr immer ver√§nderte</a></li>
<li><a href="../de418311/index.html">√úberpr√ºfen Sie Dell Latitude 7390 Notebook: Corporate Superhero</a></li>
<li><a href="../de418313/index.html">Top 10 API-Testtools</a></li>
<li><a href="../de418315/index.html">Ohne ein einziges "oops": Top 10 Berichte von DevOops 2017</a></li>
<li><a href="../de418317/index.html">2048 ist verboten. Nicht RosKomNadzor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
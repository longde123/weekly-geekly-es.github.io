<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöÇ üßëüèæ‚Äçü§ù‚Äçüßëüèª üë©üèΩ‚Äçüç≥ RabbitMQ vs. Kafka: conmutaci√≥n por error y alta disponibilidad üë®üèª‚Äç‚úàÔ∏è üë©üèæ‚Äçü§ù‚Äçüë©üèª üßôüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En un art√≠culo anterior, examinamos la agrupaci√≥n RabbitMQ para determinar la tolerancia a fallas y la alta disponibilidad. Ahora profundicemos en Apa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ vs. Kafka: conmutaci√≥n por error y alta disponibilidad</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/474984/"><img src="https://habrastorage.org/webt/rc/zb/n7/rczbn7bwtp8b5day0whi_wace2e.jpeg"><br><br>  En un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo anterior,</a> examinamos la agrupaci√≥n RabbitMQ para determinar la tolerancia a fallas y la alta disponibilidad.  Ahora profundicemos en Apache Kafka. <br><br>  Aqu√≠, la unidad de replicaci√≥n es una partici√≥n.  Cada tema tiene una o m√°s secciones.  Cada secci√≥n tiene un l√≠der con o sin seguidores.  Al crear un tema, se indica el n√∫mero de particiones y la tasa de replicaci√≥n.  El valor habitual es 3, lo que significa tres comentarios: un l√≠der y dos seguidores. <br><a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/ly/hd/ml/lyhdmlstwyv-tf_-ts54gife3cw.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">1. Cuatro secciones se distribuyen entre tres corredores</font></i> <br><br>  Todas las solicitudes de lectura y escritura van al l√≠der.  Los seguidores env√≠an peri√≥dicamente solicitudes al l√≠der para recibir los √∫ltimos mensajes.  Los consumidores nunca recurren a los seguidores, estos √∫ltimos solo existen por redundancia y tolerancia a fallas. <br><br><img src="https://habrastorage.org/webt/sb/fc/v0/sbfcv0j3mosfzvrb7qktoexl_lg.png"><br><br><h1>  Secci√≥n fallida </h1><br>  Cuando un corredor se cae, los l√≠deres de varias secciones a menudo fallan.  En cada uno de ellos, el seguidor de otro nodo se convierte en el l√≠der.  De hecho, este no es siempre el caso, ya que el factor de sincronizaci√≥n tambi√©n afecta: si hay seguidores sincronizados, y si no, se permite la transici√≥n a una r√©plica no sincronizada.  Pero por ahora, no lo compliquemos. <br><br>  El corredor 3 abandona la red, y para la secci√≥n 2 se elige un nuevo l√≠der en el corredor 2. <br><br><img src="https://habrastorage.org/webt/im/ct/r0/imctr0qotjsjg4_jx3g6p5otk9u.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. El corredor 3 muere y su seguidor en el corredor 2 es elegido como el nuevo l√≠der de la secci√≥n 2</font></i> <br><br>  Entonces el corredor 1 se va y la secci√≥n 1 tambi√©n pierde a su l√≠der, cuyo papel va al corredor 2. <br><br><img src="https://habrastorage.org/webt/rg/fo/zp/rgfozpk7b_t1odoxso1mvihmccu.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">3. Solo queda un corredor.</font></i>  <i><font color="gray">Todos los l√≠deres est√°n en el mismo corredor de cero redundancia.</font></i> <br><br>  Cuando el corredor 1 regresa a la red, agrega cuatro seguidores, proporcionando redundancia a cada secci√≥n.  Pero todos los l√≠deres segu√≠an en el corredor 2. <br><br><img src="https://habrastorage.org/webt/mh/lj/2s/mhlj2sn5r6rcjodqnl22450bjn8.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">4. Los l√≠deres permanecen en el corredor 2</font></i> <br><br>  Cuando el corredor 3 sube, volvemos a tres r√©plicas por secci√≥n.  Pero todos los l√≠deres todav√≠a est√°n en el corredor 2. <br><br><img src="https://habrastorage.org/webt/3u/tb/op/3utbopk0awdg8rg62natyoxqg9o.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">5. Colocaci√≥n desequilibrada de l√≠deres despu√©s de la restauraci√≥n de los corredores 1 y 3</font></i> <br><br>  Kafka tiene una herramienta para mejorar el equilibrio de los l√≠deres que RabbitMQ.  All√≠ tuvo que usar un complemento o script de un tercero que cambi√≥ las pol√≠ticas para migrar el nodo principal al reducir la redundancia durante la migraci√≥n.  Adem√°s, para grandes colas tuvieron que soportar la inaccesibilidad durante la sincronizaci√≥n. <br><br>  Kafka tiene un concepto de "se√±ales preferidas" para el papel de liderazgo.  Cuando se crean las secciones de temas, Kafka intenta distribuir uniformemente los l√≠deres entre los nodos y marca a estos primeros l√≠deres como preferidos.  Con el tiempo, debido a reinicios del servidor, fallas y fallas de conectividad, los l√≠deres pueden terminar en otros nodos, como en el caso extremo descrito anteriormente. <br><br>  Para solucionar esto, Kafka ofrece dos opciones: <br><br><ul><li>  La opci√≥n <i>auto</i> . <br></li><li>  Un administrador puede ejecutar el script <i>kafka-preferred-replica-election.sh</i> para reasignarlo manualmente. </li></ul><br><br><img src="https://habrastorage.org/webt/qt/2l/th/qt2lth99rb1fhzq8g4r93uoxh6k.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">6. R√©plicas despu√©s del reequilibrio</font></i> <br><br>  Era una versi√≥n simplificada del fracaso, pero la realidad es m√°s compleja, aunque no hay nada demasiado complicado aqu√≠.  Todo se reduce a r√©plicas sincronizadas (r√©plicas sincronizadas, ISR). <br><br><h1>  R√©plicas sincronizadas (ISR) </h1><br>  ISR es un conjunto de r√©plicas de una partici√≥n que se considera "sincronizada" (sincronizada).  Hay un l√≠der, pero puede que no haya seguidores.  Un seguidor se considera sincronizado si realiz√≥ copias exactas de todos los mensajes de l√≠der antes del vencimiento del intervalo <i>replica.lag.time.max.ms</i> . <br><br>  El seguidor se elimina del conjunto ISR si: <br><br><ul><li>  no realiz√≥ una solicitud de muestreo para el intervalo <i>replica.lag.time.max.ms</i> (considerado muerto) <br></li><li>  no tuvo tiempo de actualizar para el intervalo <i>replica.lag.time.max.ms</i> (considerado lento) </li></ul><br>  Los seguidores realizan solicitudes de b√∫squeda en el intervalo <i>replica.fetch.wait.max.ms</i> , que por defecto es de 500 ms. <br><br>  Para explicar claramente el prop√≥sito de ISR, debe mirar las confirmaciones del productor (productor) y algunos escenarios de falla.  Los productores pueden elegir cu√°ndo un corredor env√≠a una confirmaci√≥n: <br><br><ul><li>  acks = 0, la confirmaci√≥n no se env√≠a <br></li><li>  acks = 1, la confirmaci√≥n se env√≠a despu√©s de que el l√≠der ha escrito un mensaje en su registro local <br></li><li>  acks = all, la confirmaci√≥n se env√≠a despu√©s de que todas las r√©plicas en el ISR hayan escrito un mensaje en los registros locales </li></ul><br>  En la terminolog√≠a de Kafka, si el ISR ha guardado el mensaje, est√° "comprometido".  Acks = all es la opci√≥n m√°s segura, pero tambi√©n un retraso adicional.  Veamos dos ejemplos de fallas y c√≥mo las diferentes opciones de 'acks' interact√∫an con el concepto de ISR. <br><br><h3>  Acks = 1 e ISR </h3><br>  En este ejemplo, veremos que si el l√≠der no espera a que se guarde cada mensaje de todos los seguidores, entonces si el l√≠der falla, los datos pueden perderse.  Ir a un seguidor no sincronizado puede habilitarse o deshabilitarse configurando <i>unclean.leader.election.enable</i> . <br><br>  En este ejemplo, el fabricante se establece en acks = 1.  La secci√≥n se distribuye entre los tres corredores.  El corredor 3 est√° detr√°s, se sincroniz√≥ con el l√≠der hace ocho segundos y ahora est√° detr√°s con 7456 mensajes.  El corredor 1 est√° solo un segundo detr√°s.  Nuestro productor env√≠a un mensaje y r√°pidamente recibe un reconocimiento, sin gastos generales para seguidores lentos o muertos que el l√≠der no espera. <br><br><img src="https://habrastorage.org/webt/ej/bh/g7/ejbhg7svgcphrhpdtzbwuw--wg4.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">7. ISR con tres r√©plicas</font></i> <br><br>  El intermediario 2 falla y el fabricante recibe un error de conexi√≥n.  Despu√©s de la transici√≥n de liderazgo al corredor 1, perdemos 123 mensajes.  El seguidor del corredor 1 era parte del ISR, pero no se sincroniz√≥ completamente con el l√≠der cuando cay√≥. <br><br><img src="https://habrastorage.org/webt/6y/th/y9/6ythy9olfa5zr2wyqtfqcrq8u5e.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">8. Al fallar, los mensajes se pierden</font></i> <br><br>  En la configuraci√≥n <i>bootstrap.servers</i> , el fabricante enumera varios corredores, y puede preguntar a otro corredor que se convirti√≥ en el nuevo l√≠der de la secci√≥n.  Luego establece una conexi√≥n con el corredor 1 y contin√∫a enviando mensajes. <br><br><img src="https://habrastorage.org/webt/br/o6/jr/bro6jrn5nt-a0wzvg_yt0csmdgg.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">9. El env√≠o de mensajes se reanuda despu√©s de un breve descanso</font></i> <br><br>  Broker 3 retrasos a√∫n m√°s.  Realiza solicitudes de b√∫squeda, pero no puede sincronizar.  Esto puede deberse a una conexi√≥n de red lenta entre corredores, un problema de almacenamiento, etc. Se elimina del ISR.  Ahora ISR consiste en una r√©plica: ¬°el l√≠der!  El fabricante contin√∫a enviando mensajes y recibiendo confirmaci√≥n. <br><br><img src="https://habrastorage.org/webt/b2/qj/aj/b2qjaj5g_yx2wfb-jdkalxr9074.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">10. El seguidor del corredor 3 se elimina del ISR</font></i> <br><br>  El corredor 1 cae, y el papel del l√≠der pasa al corredor 3 con la p√©rdida de 15286 mensajes.  El fabricante recibe un mensaje de error de conexi√≥n.  Ir al l√≠der fuera del ISR solo fue posible debido a la configuraci√≥n <i>unclean.leader.election.enable = true</i> .  Si se establece en <i>falso</i> , entonces la transici√≥n no habr√≠a ocurrido, y todas las solicitudes de lectura y escritura ser√≠an rechazadas.  En este caso, estamos esperando el regreso del broker 1 con sus datos intactos en la r√©plica, que nuevamente tomar√° la delantera. <br><br><img src="https://habrastorage.org/webt/rr/n1/-n/rrn1-nekmhjtro9pxeueciytb50.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">11. Broker 1 gotas.</font></i>  <i><font color="gray">Se pierde una gran cantidad de mensajes en caso de falla</font></i> <br><br>  El fabricante establece una conexi√≥n con el √∫ltimo corredor y ve que ahora √©l es el l√≠der de la secci√≥n.  Comienza a enviar mensajes al corredor 3. <br><br><img src="https://habrastorage.org/webt/qj/qq/go/qjqqgoevfafcmcxtidd_bvjw9wi.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">12. Despu√©s de un breve descanso, los mensajes se env√≠an nuevamente a la secci√≥n 0</font></i> <br><br>  Vimos que, adem√°s de breves interrupciones para establecer nuevas conexiones y buscar un nuevo l√≠der, el fabricante enviaba mensajes constantemente.  Esta configuraci√≥n proporciona accesibilidad a trav√©s de la coherencia (seguridad de datos).  Kafka perdi√≥ miles de mensajes, pero continu√≥ aceptando nuevas entradas. <br><br><h3>  Acks = todo e ISR </h3><br>  <i>Repitamos</i> este escenario nuevamente, pero con <i>acks = all</i> .  Retrasar el corredor 3 un promedio de cuatro segundos.  El fabricante env√≠a un mensaje con <i>acks = all</i> , y ahora no recibe una respuesta r√°pida.  El l√≠der espera hasta que todos los mensajes en el ISR almacenen el mensaje. <br><br><img src="https://habrastorage.org/webt/3c/6j/a5/3c6ja5msoncfx1s-xbyjpmujtdo.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">13. ISR con tres r√©plicas.</font></i>  <i><font color="gray">Uno es lento, lo que provoca un retraso en la grabaci√≥n</font></i> <br><br>  Despu√©s de cuatro segundos de retraso adicional, el corredor 2 env√≠a un reconocimiento.  Todas las r√©plicas ahora est√°n completamente actualizadas. <br><br><img src="https://habrastorage.org/webt/ol/eg/y6/olegy6unibvup0tlza6cbd4gqic.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">14. Todas las r√©plicas guardan mensajes y se env√≠a ack</font></i> <br><br>  Broker 3 ahora est√° a√∫n m√°s atr√°s y est√° siendo eliminado del ISR.  El retraso se reduce significativamente porque no quedan r√©plicas lentas en el ISR.  El corredor 2 ahora solo espera al corredor 1, y tiene un retraso promedio de 500 ms. <br><br><img src="https://habrastorage.org/webt/ub/0e/7j/ub0e7jm1siaa9dvcmxyldti1ify.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">15. La r√©plica en el corredor 3 se elimina del ISR</font></i> <br><br>  Entonces el corredor 2 cae, y el liderazgo pasa al corredor 1 sin perder mensajes. <br><br><img src="https://habrastorage.org/webt/a7/ts/8m/a7ts8mywsvuowiof5jp6f6eszlq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">16. El corredor 2 est√° cayendo</font></i> <br><br>  El fabricante encuentra un nuevo l√≠der y comienza a enviarle mensajes.  El retraso a√∫n se reduce, ¬°porque ahora el ISR consiste en una r√©plica!  Por lo tanto, la opci√≥n <i>acks = all</i> no agrega redundancia. <br><br><img src="https://habrastorage.org/webt/-z/i_/od/-zi_odb0nc-nf0xe1tsxmzlr-uq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">17. La r√©plica en el corredor 1 toma la delantera sin perder mensajes</font></i> <br><br>  ¬°Entonces el corredor 1 cae, y el liderazgo pasa al corredor 3 con la p√©rdida de 14,238 mensajes! <br><br><img src="https://habrastorage.org/webt/sr/x5/1m/srx51mjemyxnksoewy6n91_lgqy.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">18. El corredor 1 muere, y la transici√≥n de liderazgo con una configuraci√≥n impura conduce a una p√©rdida de datos extensa</font></i> <br><br>  No pudimos establecer la opci√≥n <i>unclean.leader.election.enable</i> en <i>true</i> .  Por defecto, es <i>falso</i> .  Establecer <i>acks = all</i> con <i>unclean.leader.election.enable = true</i> proporciona accesibilidad con cierta seguridad de datos adicional.  Pero, como puede ver, a√∫n podemos perder mensajes. <br><br>  Pero, ¬øqu√© pasa si queremos aumentar la seguridad de los datos?  Puede configurar <i>unclean.leader.election.enable = false</i> , pero esto no necesariamente nos protege de la p√©rdida de datos.  Si el l√≠der cay√≥ con fuerza y ‚Äã‚Äãse llev√≥ los datos consigo, entonces los mensajes a√∫n se pierden, y se pierde la accesibilidad hasta que el administrador recupere la situaci√≥n. <br><br>  Es mejor garantizar la redundancia de todos los mensajes y, de lo contrario, negarse a grabar.  Entonces, al menos desde el punto de vista del corredor, la p√©rdida de datos es posible solo con dos o m√°s fallas simult√°neas. <br><br><h3>  Acks = all, min.insync.replicas e ISR </h3><br>  Con la <i>configuraci√≥n del</i> tema <i>min.insync.replicas,</i> aumentamos la seguridad de los datos.  Veamos la √∫ltima parte del √∫ltimo escenario una vez m√°s, pero esta vez con <i>min.insync.replicas = 2</i> . <br><br>  Entonces, el corredor 2 tiene un l√≠der de r√©plica, y el seguidor del corredor 3 se elimina del ISR. <br><br><img src="https://habrastorage.org/webt/5g/ij/ls/5gijlstkvqxo4ojr6wfxxwn719m.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">19. ISR de dos r√©plicas</font></i> <br><br>  El corredor 2 cae, y el liderazgo pasa al corredor 1 sin perder mensajes.  Pero ahora ISR consta de una sola r√©plica.  Esto no corresponde al n√∫mero m√≠nimo para recibir registros y, por lo tanto, el intermediario responde al intento de grabar con el error <i>NotEnoughReplicas</i> . <br><br><img src="https://habrastorage.org/webt/ng/p5/fj/ngp5fjym6nvykpohj8brnl8bvxc.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">20. El n√∫mero de ISR es uno menor que el especificado en min.insync.replicas</font></i> <br><br>  Esta configuraci√≥n sacrifica la disponibilidad por coherencia.  Antes de confirmar un mensaje, garantizamos que est√° grabado en al menos dos r√©plicas.  Esto le da al fabricante mucha m√°s confianza.  Aqu√≠, la p√©rdida de mensajes es posible solo si dos r√©plicas fallan simult√°neamente en un intervalo corto, hasta que el mensaje se replica a un seguidor adicional, lo cual es poco probable.  Pero si usted es un superparanoide, puede establecer la relaci√≥n de replicaci√≥n en 5, y las <i>r√©plicas m√≠nimas</i> de <i>sincronizaci√≥n</i> en 3. ¬°Entonces tres corredores a la vez deben caer al mismo tiempo para perder el registro!  Por supuesto, para tal confiabilidad pagar√° un retraso adicional. <br><br><h1>  Cuando se necesita accesibilidad para la seguridad de los datos </h1><br>  Al igual que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">con RabbitMQ</a> , a veces la accesibilidad es necesaria para la seguridad de los datos.  Tienes que pensar en esto: <br><br><ul><li>  ¬øPuede un editor simplemente devolver un error y un servicio superior o un usuario intentarlo m√°s tarde? <br></li><li>  ¬øPuede un editor guardar un mensaje localmente o en una base de datos para volver a intentarlo m√°s tarde? </li></ul><br>  Si la respuesta es no, entonces optimizar la accesibilidad mejora la seguridad de los datos.  Perder√° menos datos si elige la disponibilidad en lugar de descartar la grabaci√≥n.  Por lo tanto, todo se reduce a encontrar un equilibrio, y la decisi√≥n depende de la situaci√≥n espec√≠fica. <br><br><h1>  El significado de ISR </h1><br>  La suite ISR le permite elegir el equilibrio √≥ptimo entre la seguridad de los datos y la latencia.  Por ejemplo, para asegurar que la mayor√≠a de las r√©plicas sean accesibles en caso de falla, minimizando el impacto de las r√©plicas muertas o lentas en t√©rminos de retraso. <br><br>  Nosotros mismos elegimos el valor de <i>replica.lag.time.max.ms</i> de acuerdo con nuestras necesidades.  En esencia, este par√°metro significa qu√© retraso estamos listos para aceptar con <i>acks = all</i> .  El valor predeterminado es diez segundos.  Si esto es demasiado largo para usted, puede reducirlo.  Luego, la frecuencia de los cambios en el ISR aumentar√°, ya que los seguidores se eliminar√°n y agregar√°n con mayor frecuencia. <br><br>  RabbitMQ es solo una colecci√≥n de espejos que necesitan ser replicados.  Los espejos lentos introducen un retraso adicional, y se puede esperar la respuesta de los espejos muertos antes de la expiraci√≥n de los paquetes que verifican la disponibilidad de cada nodo (tick neto).  Los ISR son una forma interesante de evitar estos problemas con una mayor latencia.  Pero corremos el riesgo de perder la redundancia, ya que ISR solo puede reducirse a un l√≠der.  Para evitar este riesgo, use la configuraci√≥n <i>min.insync.replicas</i> . <br><br><h1>  Garant√≠a de conectividad del cliente </h1><br>  En la configuraci√≥n de <i>bootstrap.servers</i> del fabricante y el consumidor, puede especificar varios intermediarios para conectar clientes.  La idea es que cuando desconecta un nodo, hay varios nodos de repuesto con los que el cliente puede abrir una conexi√≥n.  Estos no son necesariamente l√≠deres de secci√≥n, sino simplemente un trampol√≠n para el arranque.  El cliente puede preguntarles en qu√© nodo se encuentra el l√≠der de la secci√≥n de lectura / escritura. <br><br>  En RabbitMQ, los clientes pueden conectarse a cualquier host, y el enrutamiento interno env√≠a una solicitud cuando es necesario.  Esto significa que puede instalar un equilibrador de carga frente a RabbitMQ.  Kafka requiere que los clientes se conecten al host que aloja al l√≠der de la partici√≥n correspondiente.  En esta situaci√≥n, el equilibrador de carga no se entrega.  La lista <i>bootstrap.servers</i> es cr√≠tica para que los clientes puedan acceder a los nodos correctos y encontrarlos despu√©s de un bloqueo. <br><br><h1>  Arquitectura del consenso de Kafka </h1><br>  Hasta ahora, no hemos considerado c√≥mo el grupo se entera de la ca√≠da del corredor y c√≥mo se elige un nuevo l√≠der.  Para comprender c√≥mo funciona Kafka con las particiones de red, primero debe comprender la arquitectura de consenso. <br><br>  Cada cl√∫ster Kafka se implementa con el cl√∫ster Zookeeper: es un servicio de consenso distribuido que permite que el sistema llegue a un consenso en un estado determinado con prioridad de coherencia sobre la disponibilidad.  La aprobaci√≥n de las operaciones de lectura y escritura requiere el consentimiento de la mayor√≠a de los nodos de Zookeeper. <br><br>  Zookeeper almacena el estado del cl√∫ster: <br><br><ul><li>  Lista de temas, secciones, configuraci√≥n, r√©plicas l√≠deres actuales, r√©plicas preferidas. <br></li><li>  Miembros del grupo.  Cada corredor hace ping en un cl√∫ster de Zookeeper.  Si no recibe ping durante un per√≠odo de tiempo determinado, Zookeeper escribe que el corredor es inaccesible. <br></li><li>  La elecci√≥n de nodos primarios y secundarios para el controlador. </li></ul><br>  El nodo controlador es uno de los intermediarios de Kafka que es responsable de elegir l√≠deres de r√©plica.  Zookeeper env√≠a al controlador notificaciones de membres√≠a del cl√∫ster y cambios de tema, y ‚Äã‚Äãel controlador debe actuar de acuerdo con estos cambios. <br><br>  Por ejemplo, tome un nuevo tema con diez secciones y un coeficiente de replicaci√≥n de 3. El controlador debe seleccionar el l√≠der de cada secci√≥n, tratando de distribuir de manera √≥ptima los l√≠deres entre los corredores. <br><br>  Para cada secci√≥n, el controlador: <br><br><ul><li>  actualiza la informaci√≥n en Zookeeper sobre ISR y el l√≠der; <br></li><li>  env√≠a un comando LeaderAndISRCommand a cada agente que publica una r√©plica de esta secci√≥n, informando a los agentes sobre el ISR y el l√≠der. </li></ul><br>  Cuando un corredor con un l√≠der cae, Zookeeper env√≠a una notificaci√≥n al controlador y este selecciona un nuevo l√≠der.  Nuevamente, el controlador primero actualiza Zookeeper, y luego env√≠a un comando a cada corredor, notific√°ndoles un cambio en el liderazgo. <br><br>  Cada l√≠der es responsable de reclutar ISR.  La <i>configuraci√≥n replica.lag.time.max.ms</i> determina qui√©n ir√° all√≠.  Cuando el ISR cambia, el l√≠der pasa la nueva informaci√≥n a Zookeeper. <br><br>  Zookeeper siempre est√° informado de cualquier cambio, de modo que en caso de falla, la gerencia se traslada sin problemas al nuevo l√≠der. <br><br><img src="https://habrastorage.org/webt/yi/1v/in/yi1vinwmeg4exdiautqohweg8rq.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">21. Consenso Kafka</font></i> <br><br><h1>  Protocolo de replicaci√≥n </h1><br>  Comprender los detalles de la replicaci√≥n lo ayuda a comprender mejor los posibles escenarios de p√©rdida de datos. <br><br><h3>  Solicitudes de muestra, desplazamiento de fin de registro (LEO) y Highwater Mark (HW) </h3><br>  Hemos considerado que los seguidores env√≠an peri√≥dicamente solicitudes de b√∫squeda al l√≠der.  El intervalo predeterminado es de 500 ms.  Esto difiere de RabbitMQ en que en RabbitMQ, la replicaci√≥n no se inicia por el espejo de la cola, sino por el asistente.  El maestro empuja los cambios a los espejos. <br><br>  El l√≠der y todos los seguidores conservan la etiqueta Log End Offset (LEO) y Highwater (HW).  La marca LEO almacena el desplazamiento del √∫ltimo mensaje en la r√©plica local, y HW almacena el desplazamiento de la √∫ltima confirmaci√≥n.  Recuerde que para el estado de confirmaci√≥n, el mensaje debe guardarse en todas las r√©plicas de ISR.  Esto significa que LEO generalmente est√° ligeramente por delante de HW. <br><br>  Cuando un l√≠der recibe un mensaje, lo guarda localmente.  El seguidor hace una solicitud de b√∫squeda, pasando su LEO.  El l√≠der luego env√≠a un paquete de mensajes que comienzan con este LEO, y tambi√©n transmite el HW actual.  Cuando el l√≠der recibe informaci√≥n de que todas las r√©plicas han guardado el mensaje en un desplazamiento determinado, mueve la marca HW.  Solo el l√≠der puede mover el HW, por lo que todos los seguidores sabr√°n el valor actual en las respuestas a su solicitud.  Esto significa que los seguidores pueden ir a la zaga del l√≠der tanto en informes como en conocimiento de HW.  Los consumidores reciben mensajes solo hasta el HW actual. <br><br>  Tenga en cuenta que "persistente" significa escrito en la memoria, no en el disco.  Para el rendimiento, Kafka se sincroniza con el disco en un intervalo especificado.  RabbitMQ tambi√©n tiene ese intervalo, pero enviar√° una confirmaci√≥n al editor solo despu√©s de que el maestro y todos los espejos hayan escrito el mensaje en el disco.  Los desarrolladores de Kafka por razones de rendimiento decidieron enviar un reconocimiento tan pronto como el mensaje se escribe en la memoria.  Kafka se basa en el hecho de que la redundancia compensa el riesgo de almacenamiento a corto plazo de mensajes confirmados solo en la memoria. <br><br><h1>  Fracaso del l√≠der </h1><br>  Cuando un l√≠der cae, Zookeeper notifica al controlador y selecciona una nueva r√©plica del l√≠der.  El nuevo l√≠der establece una nueva marca HW en l√≠nea con su LEO.  Entonces los seguidores reciben informaci√≥n sobre el nuevo l√≠der.  Dependiendo de la versi√≥n de Kafka, el seguidor elegir√° uno de dos escenarios: <br><br><ol><li>  Trunca el registro local al famoso HW y env√≠a un mensaje al nuevo l√≠der despu√©s de esta marca. <br></li><li>   ,   HW     ,       .       ,    . </li></ol><br>        : <br><br><ul><li>    ,     ISR,   Zookeeper,     .    ISR,    ¬´¬ª,          .  ,        . Kafka ,     .  ,   ,         HW      .    ,   <i>acks=all</i>    . <br></li><li>     .      ,        .  ,       ,  ,   ,    ,        . </li></ul><br><h3>  c  </h3><br>        ,     :          HW (  ).  , RabbitMQ       .        .    ,             ¬´    ¬ª.            .       . <br><br> Kafka ‚Äî   ,       ,   RabbitMQ,        .      .  Kafka ‚Äî      ,        .            .    Kafka      HW  (   )   ,     .    ,    ,       ,     LEO. <br><br>        ISR     .      ,    ,  ,         ISR.          . <br><br><h1>   </h1><br>  Kafka  ,   RabbitMQ,      ,     .  Kafka    ,      . <br><br>      : <br><br><ul><li>  1.    ,     Zookeeper. <br></li><li>  2.      ,     Zookeeper. <br></li><li>  3.   ,    Zookeeper. <br></li><li>  4.   ,    Zookeeper. <br></li><li>  5.        Kafka,   Zookeeper. <br></li><li>  6.        Kafka,   Zookeeper. <br></li><li>  7.   Kafka     Kafka. <br></li><li>  8.  Kafka   Zookeeper. </li></ul><br>      . <br><br><h3>  1.    ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/je/cd/f1/jecdf1kc9y8gc8ej5sfmuelo30a.png"><br> <i><font color="gray">. 22.  1. ISR   </font></i> <br><br>     3   1  2,    Zookeeper.  3       .    <i>replica.lag.time.max.ms</i>    ISR      .    ,         ISR,   . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/ir/tq/ir/irtqir6cr8whigmvfqo1t-bbsso.png"><br> <i><font color="gray">. 23.  1.    ISR,            replica.lag.time.max.ms</font></i> <br><br>     (split-brain)   ,   RabbitMQ.    . <br><br><h3>  2.      ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/ri/fy/q6/rifyq652am8lmbhlgpfvfq-pjnm.png"><br> <i><font color="gray">. 24.  2.    </font></i> <br><br>       ,      Zookeeper.     , ISR ,       ,        .  ,    .        ,    . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/hj/8g/-1/hj8g-1veu8rkisccp7t6c9bxq7k.png"><br> <i><font color="gray">. 25.  2. ISR    </font></i> <br><br><h3>  3.   ,    Zookeeper </h3><br>    Zookeeper,      .           ISR. Zookeeper        ,     ,     . <br><br><img src="https://habrastorage.org/webt/cv/tb/gj/cvtbgjgw7ub1w8dmii46aql3bhc.png"><br> <i><font color="gray">. 26.  3.       </font></i> <br><br><h3>  4.   ,    Zookeeper </h3><br><img src="https://habrastorage.org/webt/zw/k4/8o/zwk48obscffldqgdhpyl0dvvipc.png"><br> <i><font color="gray">. 27.  4.    </font></i> <br><br>    Zookeeper,      . <br><br><img src="https://habrastorage.org/webt/eh/s1/hx/ehs1hxu4sako2udflhmhhbqhtsu.png"><br> <i><font color="gray">. 28.  4.    Zookeeper</font></i> <br><br>    Zookeeper        .      .      ,           <i>acks=1</i> .        ,         ISR   .        Zookeeper,     ,         . <br><br>  <i>acks=all</i>   ,    ISR   ,      .        ISR,          - . <br><br>            .    ,   ,     ,       HW,        ,    .         .     ,    .     ,        ,    . <br><br><img src="https://habrastorage.org/webt/pt/z_/pn/ptz_pnhoyrwvw4v-l9re3ffjzcg.png"><br> <i><font color="gray">. 29.  4.    1     </font></i> <br><br><h3>  5.        Kafka,   Zookeeper </h3><br>        Kafka,   Zookeeper.     ISR,    ,    . <br><br><img src="https://habrastorage.org/webt/ik/aj/a1/ikaja1i4z3fnodbcmam8sp2jbjc.png"><br> <i><font color="gray">. 30.  5.     ISR</font></i> <br><br><h3>  6.        Kafka,   Zookeeper </h3><br><img src="https://habrastorage.org/webt/cz/5h/2m/cz5h2mnqelpalxozp-jv4yv23rc.png"><br> <i><font color="gray">. 31.  6.    </font></i> <br><br>      ,   Zookeeper.          <i>acks=1</i> . <br><br><img src="https://habrastorage.org/webt/pj/pi/vj/pjpivjf1bsnvowntmkjqxdzipfe.png"><br> <i><font color="gray">. 32.  6.      Kafka  Zookeeper</font></i> <br><br>      <i>replica.lag.time.max.ms</i> ,    ISR   ,     ,     Zookeeper,     . <br><br>  , Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/g8/rg/wo/g8rgwol3elzkz8dwxojtclogyns.png"><br> <i><font color="gray">. 33.  6.  </font></i> <br><br>         ,      .    60    .            . <br><br><img src="https://habrastorage.org/webt/zu/zl/dh/zuzldhf62qbynz_voxil-25roxe.png"><br> <i><font color="gray">. 34.  6.     </font></i> <br><br>     ,       .    ,    Zookeeper ,     .      HW           . <br><br><img src="https://habrastorage.org/webt/zj/5e/vd/zj5evdyqhphl9uupogfvbjx7zjk.png"><br> <i><font color="gray">. 35.  6.        </font></i> <br><br>           ,    <i>acks=1</i>  <i>min.insync.replicas</i>  1.        ,    ,     ,     ,         ‚Äî    ,   .       ,    <i>acks=1</i> . <br><br>     ,       ,    ISR   .    -  .   ,      ,  <i>acks=all</i> ,    ISR    .       .      ‚Äî <i>min.insync.replicas = 2</i> . <br><br><h3>  7.   Kafka     Kafka </h3><br>  ,      Kafka          .         ,    6.             . <br><br><h3>  8.  Kafka   Zookeeper </h3><br>    Zookeeper         Kafka.       ,       Zookeeper,         .    ,  ,     ,     Kafka. <br><br><h3>    </h3><br>  ,         ,     ,    . , ,     ,      . <br><br>  -      Zookeeper,        <i>acks=1</i> .    Zookeeper       .     <i>acks=all</i> . <br><br>  <i>min.insync.replicas</i>        ,         ,    6. <br><br><h1>     </h1><br>   ,      Kafka: <br><br><ul><li>   ,      <i>acks=1</i> <br></li><li>   (unclean)  ,       ISR,   <i>acks=all</i> <br></li><li>    Zookeeper,      <i>acks=1</i> <br></li><li>   ,     ISR   .    ,  <i>acks=all</i> .      ,  <i>min.insync.replicas=1</i> . <br></li><li>     .     ,       .        . </li></ul><br>     ,   ,      .    ‚Äî   <i>acks=all</i>  <i>min.insync.replicas</i>  1. <br><br><h1>    RabbitMQ  Kafka </h1><br>              .   RabbitMQ   .        ,   .           RabbitMQ.       ,    .       .    ,         ( )       . <br><br>  Kafka   .          .    .  ,    .    ,     ,           . , -  ,       .     ,      . <br><br> RabbitMQ  Kafka         .    , RabbitMQ              .        : <br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fsync cada pocos cientos de milisegundos </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Los espejos solo se pueden detectar despu√©s de la vida √∫til de los paquetes que verifican la disponibilidad de cada nodo (tic de red). </font><font style="vertical-align: inherit;">Si el espejo se ralentiza o cae, esto agrega un retraso.</font></font></li></ul><br>  Kafka se basa en el hecho de que si el mensaje se almacena en varios nodos, puede confirmar los mensajes tan pronto como est√©n en la memoria.  Debido a esto, existe el riesgo de perder mensajes de cualquier tipo (incluso <i>acks = all</i> , <i>min.insync.replies = 2</i> ) en caso de una falla simult√°nea. <br><br>  En general, Kafka demuestra un mejor rendimiento y fue dise√±ado originalmente para cl√∫steres.  El n√∫mero de seguidores se puede aumentar a 11, si es necesario para la confiabilidad.  Un factor de replicaci√≥n de 5 y un n√∫mero m√≠nimo de r√©plicas en un estado sincronizado de <i>min.insync.replicas = 3</i> har√°n que la p√©rdida de mensajes sea un evento muy raro.  Si su infraestructura es capaz de proporcionar dicha tasa de replicaci√≥n y un nivel de redundancia, puede elegir esta opci√≥n. <br><br>  La agrupaci√≥n RabbitMQ es buena para colas peque√±as.  Pero incluso las colas peque√±as pueden crecer r√°pidamente con mucho tr√°fico.  Una vez que las colas se vuelven grandes, tendr√° que tomar una decisi√≥n dif√≠cil entre disponibilidad y confiabilidad.  La agrupaci√≥n RabbitMQ es m√°s adecuada para situaciones no t√≠picas en las que las ventajas de la flexibilidad de RabbitMQ superan cualquiera de las desventajas de agruparla. <br><br>  Uno de los ant√≠dotos para la vulnerabilidad de la cola grande de RabbitMQ es dividirlos en muchos m√°s peque√±os.  Si no requiere un pedido completo de toda la cola, sino solo mensajes relevantes (por ejemplo, mensajes de un cliente espec√≠fico), o nada en absoluto, entonces esta opci√≥n es aceptable: mire mi proyecto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Rebalanser</a> para dividir la cola (el proyecto a√∫n est√° en una etapa temprana). <br><br>  Finalmente, no se olvide de una serie de errores en los mecanismos de agrupaci√≥n y replicaci√≥n de RabbitMQ y Kafka.  Con el tiempo, los sistemas se han vuelto m√°s maduros y estables, ¬°pero ni un solo mensaje estar√° 100% protegido contra p√©rdidas!  Adem√°s, los accidentes a gran escala ocurren en los centros de datos. <br><br>  Si me perd√≠ algo, comet√≠ un error o no est√° de acuerdo con ninguno de los puntos, no dude en escribir un comentario o contactarme. <br><br>  La gente a menudo me pregunta: "¬øQu√© elegir, Kafka o RabbitMQ?", "¬øQu√© plataforma es mejor?".  La verdad es que realmente depende de su situaci√≥n, experiencia actual, etc. No me atrevo a expresar mi opini√≥n, ya que ser√≠a una simplificaci√≥n excesiva recomendar cualquier plataforma para todos los casos de uso y posibles limitaciones.  Escrib√≠ esta serie de art√≠culos para que puedas formarte tu propia opini√≥n. <br><br>  Quiero decir que ambos sistemas son l√≠deres en este campo.  Tal vez soy un poco parcial, porque por la experiencia de mis proyectos estoy m√°s inclinado a apreciar cosas tales como la garant√≠a y el orden de los mensajes. <br><br>  Veo otras tecnolog√≠as que carecen de esta confiabilidad y pedidos garantizados, luego miro RabbitMQ y Kafka, y entiendo el incre√≠ble valor de ambos sistemas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/474984/">https://habr.com/ru/post/474984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../474968/index.html">RxDart para los m√°s peque√±os ... proyectos</a></li>
<li><a href="../474970/index.html">¬øC√≥mo escribir un contrato inteligente con Python en ontolog√≠a? Parte 5: API nativa</a></li>
<li><a href="../474976/index.html">Boating City: c√≥mo existe Venecia sin autom√≥viles</a></li>
<li><a href="../474978/index.html">Reconocimiento visual de IBM Watson: el reconocimiento de objetos ahora est√° disponible en IBM Cloud</a></li>
<li><a href="../474982/index.html">Tutorial JavaFX: FXML y SceneBuilder</a></li>
<li><a href="../474988/index.html">Bienvenido a Mitap: carreras en Data Science para principiantes</a></li>
<li><a href="../474990/index.html">Pr√°ctica dif√≠cil: c√≥mo hacer una red Wi-Fi en un parque de la ciudad</a></li>
<li><a href="../474992/index.html">An√°lisis de bater√≠as de computadoras port√°tiles defectuosas. Notas de motorista el√©ctrico</a></li>
<li><a href="../474994/index.html">C√≥mo cortar un monolito en servicios y mantener el rendimiento de los cach√©s en memoria sin perder consistencia</a></li>
<li><a href="../474996/index.html">El resumen de los eventos de TI en noviembre (segunda parte)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ––ğŸ¿ ğŸ¤ ğŸ‘¨ğŸ»â€ğŸ« å¿«é€Ÿç»˜ç”»Doodleè¯†åˆ«ï¼šå¦‚ä½•ç»“äº¤Rï¼ŒC ++å’Œç¥ç»ç½‘æ ¼ â¯ï¸ ğŸ¤¡ ğŸ‘©ğŸ¼â€ğŸ’»</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="å“ˆHaï¼ 

 å»å¹´ç§‹å¤©ï¼Œåœ¨Kaggleä¸¾è¡Œäº†ä¸€åœºæ¯”èµ›ï¼Œä¸ºæ‰‹ç»˜Quick Draw Doodle Recognitionå›¾ç‰‡è¿›è¡Œäº†åˆ†ç±»ï¼Œå…¶ä¸­åŒ…æ‹¬ç”±Artem Klevtsov ï¼Œ Philip Upravitelevå’ŒAndrey Ogurtsovç»„æˆçš„R-schikså›¢é˜Ÿã€‚ æˆ‘ä»¬ä¸ä¼šè¯¦ç»†æè¿°æ¯”èµ›ï¼Œ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>å¿«é€Ÿç»˜ç”»Doodleè¯†åˆ«ï¼šå¦‚ä½•ç»“äº¤Rï¼ŒC ++å’Œç¥ç»ç½‘æ ¼</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/443758/"><img src="https://habrastorage.org/webt/cp/ir/jc/cpirjcgr-d52s_br1kqmvzkeawm.png"><br><br> å“ˆHaï¼ <br><br> å»å¹´ç§‹å¤©ï¼Œåœ¨Kaggleä¸¾è¡Œäº†ä¸€åœºæ¯”èµ›ï¼Œä¸ºæ‰‹ç»˜Quick Draw Doodle Recognitionå›¾ç‰‡è¿›è¡Œäº†åˆ†ç±»ï¼Œå…¶ä¸­åŒ…æ‹¬ç”±<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Artem Klevtsov</a> ï¼Œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Philip Upravitelev</a>å’Œ<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Andrey</a> Ogurtsovç»„æˆçš„R-schikså›¢é˜Ÿã€‚ æˆ‘ä»¬ä¸ä¼šè¯¦ç»†æè¿°æ¯”èµ›ï¼Œè¿™å·²ç»åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æœ€è¿‘çš„å‡ºç‰ˆç‰©ä¸­</a>åšäº†ã€‚ <br><br> è¿™æ¬¡å†œåœºæ²¡æœ‰å¥–ç‰Œï¼Œä½†æ˜¯è·å¾—äº†å¾ˆå¤šå®è´µçš„ç»éªŒï¼Œæ‰€ä»¥æˆ‘æƒ³å‘ç¤¾åŒºä»‹ç»Kaglå’Œæ—¥å¸¸å·¥ä½œä¸­æœ€æœ‰è¶£å’Œæœ€æœ‰ç”¨çš„ä¸€äº›ä¸œè¥¿ã€‚ æ¶‰åŠçš„ä¸»é¢˜åŒ…æ‹¬ï¼šæ²¡æœ‰<strong>OpenCVçš„</strong>è‰°è‹¦ç”Ÿæ´»ï¼ŒJSONè§£æï¼ˆè¿™äº›ç¤ºä¾‹<strong>æ˜¾ç¤ºäº†</strong>ä½¿ç”¨<strong>Rcpp</strong>å°†C ++ä»£ç é›†æˆåˆ°Rä¸­çš„è„šæœ¬æˆ–ç¨‹åºåŒ…ä¸­ï¼‰ï¼Œè„šæœ¬çš„å‚æ•°åŒ–å’Œæœ€ç»ˆè§£å†³æ–¹æ¡ˆçš„dockerizationã€‚  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">å­˜å‚¨åº“ä¸­</a>æä¾›äº†æ¶ˆæ¯ä¸­é€‚åˆå¯åŠ¨çš„æ‰€æœ‰ä»£ç ã€‚ <br><br><h3> å†…å®¹ï¼š </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æœ‰æ•ˆåœ°å°†æ•°æ®ä»CSVåŠ è½½åˆ°MonetDBæ•°æ®åº“</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ‰¹é‡å‡†å¤‡</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ç”¨äºä»æ•°æ®åº“ä¸­å¸è½½æ‰¹æ¬¡çš„è¿­ä»£å™¨</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ¨¡å‹æ¶æ„é€‰æ‹©</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">è„šæœ¬å‚æ•°åŒ–</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">å¯¹æ¥è„šæœ¬</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">åœ¨Google Cloudä¸­ä½¿ç”¨å¤šä¸ªGPU</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">è€Œä¸æ˜¯ç»“è®º</a> </li></ol><a name="habracut"></a><br><h4 id="section1">  1.æœ‰æ•ˆåœ°å°†æ•°æ®ä»CSVåŠ è½½åˆ°MonetDBæ•°æ®åº“ </h4><br><p> æœ¬æ¬¡æ¯”èµ›ä¸­çš„æ•°æ®ä¸æ˜¯ä»¥ç°æˆå›¾ç‰‡çš„å½¢å¼æä¾›ï¼Œè€Œæ˜¯ä»¥340ä¸ªCSVæ–‡ä»¶ï¼ˆæ¯ä¸ªç±»ä¸€ä¸ªæ–‡ä»¶ï¼‰çš„å½¢å¼æä¾›ï¼Œå…¶ä¸­åŒ…å«å¸¦æœ‰ç‚¹åæ ‡çš„JSONã€‚ å°†è¿™äº›ç‚¹ä¸çº¿è¿æ¥èµ·æ¥ï¼Œæˆ‘ä»¬å¾—åˆ°çš„æœ€ç»ˆå›¾åƒå°ºå¯¸ä¸º256x256åƒç´ ã€‚ å¦å¤–ï¼Œå¯¹äºæ¯æ¡è®°å½•ï¼Œéƒ½ä¼šç»™æ ‡ç­¾åŠ ä¸Šå›¾ç‰‡ï¼Œä»¥ä¾¿åœ¨æ”¶é›†æ•°æ®é›†æ—¶ä½¿ç”¨çš„åˆ†ç±»å™¨æ­£ç¡®è¯†åˆ«å›¾ç‰‡ï¼Œä½œè€…çš„å±…ä½å›½çš„ä¸¤ä¸ªå­—æ¯çš„ä»£ç ï¼Œå”¯ä¸€çš„æ ‡è¯†ç¬¦ï¼Œæ—¶é—´æˆ³å’Œä¸æ–‡ä»¶ååŒ¹é…çš„ç±»åã€‚ ç®€åŒ–ç‰ˆæœ¬çš„æºæ•°æ®åœ¨å­˜æ¡£ä¸­çš„é‡é‡ä¸º7.4 GBï¼Œè§£å‹ç¼©åçš„é‡é‡çº¦ä¸º20 GBï¼Œè§£å‹ç¼©åçš„å®Œæ•´æ•°æ®éœ€è¦240 GBã€‚ ç»„ç»‡è€…ä¿è¯ä¸¤ä¸ªç‰ˆæœ¬éƒ½å¤åˆ¶ç›¸åŒçš„å›¾çº¸ï¼Œå³å®Œæ•´ç‰ˆæœ¬æ˜¯å¤šä½™çš„ã€‚ æ— è®ºå¦‚ä½•ï¼Œç«‹å³å°†5000ä¸‡å¼ å›¾åƒå­˜å‚¨åœ¨å›¾å½¢æ–‡ä»¶æˆ–æ•°ç»„ä¸­è¢«è®¤ä¸ºæ˜¯æ— åˆ©å¯å›¾çš„ï¼Œæˆ‘ä»¬å†³å®šå°†<em>train_simplified.zip</em>å­˜æ¡£ä¸­çš„æ‰€æœ‰CSVæ–‡ä»¶åˆå¹¶åˆ°æ•°æ®åº“ä¸­ï¼Œå¹¶éšåä¸ºæ¯æ‰¹åŠ¨æ€ç”Ÿæˆåˆé€‚å¤§å°çš„å›¾åƒã€‚ </p><br><p> é€‰æ‹©æˆç†Ÿçš„<strong>MonetDB</strong>ä½œä¸ºDBMSï¼Œå³é‡‡ç”¨<strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">MonetDBLite</a></strong>åŒ…å½¢å¼çš„Rå®ç°ã€‚ è¯¥è½¯ä»¶åŒ…åŒ…æ‹¬æ•°æ®åº“æœåŠ¡å™¨çš„åµŒå…¥å¼ç‰ˆæœ¬ï¼Œå…è®¸æ‚¨ç›´æ¥ä»Rä¼šè¯ä¸­æèµ·æœåŠ¡å™¨å¹¶åœ¨å…¶ä¸­ä½¿ç”¨å®ƒã€‚ åˆ›å»ºæ•°æ®åº“å¹¶è¿æ¥åˆ°æ•°æ®åº“æ˜¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ‰§è¡Œçš„ï¼š </p><br><pre><code class="plaintext hljs">con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR"))</code> </pre> <br><p> æˆ‘ä»¬å°†éœ€è¦åˆ›å»ºä¸¤ä¸ªè¡¨ï¼šä¸€ä¸ªè¡¨ç”¨äºæ‰€æœ‰æ•°æ®ï¼Œå¦ä¸€ä¸ªè¡¨ç”¨äºæœ‰å…³å·²ä¸‹è½½æ–‡ä»¶çš„æœåŠ¡ä¿¡æ¯ï¼ˆå¦‚æœå‡ºç°é—®é¢˜ï¼Œå°†å¾ˆæœ‰ç”¨ï¼Œå¹¶ä¸”åœ¨ä¸‹è½½å¤šä¸ªæ–‡ä»¶åå¿…é¡»æ¢å¤è¯¥è¿‡ç¨‹ï¼‰ï¼š </p><br><div class="spoiler">  <b class="spoiler_title">å»ºç«‹è¡¨æ ¼</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">if (!DBI::dbExistsTable(con, "doodles")) { DBI::dbCreateTable( con = con, name = "doodles", fields = c( "countrycode" = "char(2)", "drawing" = "text", "key_id" = "bigint", "recognized" = "bool", "timestamp" = "timestamp", "word" = "text" ) ) } if (!DBI::dbExistsTable(con, "upload_log")) { DBI::dbCreateTable( con = con, name = "upload_log", fields = c( "id" = "serial", "file_name" = "text UNIQUE", "uploaded" = "bool DEFAULT false" ) ) }</code> </pre> </div></div><br><p> å°†æ•°æ®åŠ è½½åˆ°æ•°æ®åº“çš„æœ€å¿«æ–¹æ³•æ˜¯ä½¿ç”¨SQLç›´æ¥å¤åˆ¶CSVæ–‡ä»¶-å‘½ä»¤<code>COPY OFFSET 2 INTO tablename FROM path USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT</code> using <code>COPY OFFSET 2 INTO tablename FROM path USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT</code> ï¼Œå…¶ä¸­<code>tablename</code>æ˜¯è¡¨å’Œ<code>path</code>çš„åç§°æ˜¯æ–‡ä»¶çš„è·¯å¾„ã€‚åæ¥<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ï¼Œå‘ç°äº†</a>å¦ä¸€ç§æé«˜é€Ÿåº¦çš„æ–¹æ³•ï¼šç”¨<code>LOCKED BEST EFFORT</code>æ›¿æ¢<code>BEST EFFORT</code> ã€‚å½“ä½¿ç”¨å­˜æ¡£æ—¶ï¼Œäº‹å®è¯æ˜Rä¸­çš„å†…ç½®<code>unzip</code>å®ç°æ— æ³•ä¸å­˜æ¡£ä¸­çš„è®¸å¤šæ–‡ä»¶ä¸€èµ·æ­£å¸¸å·¥ä½œï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨ç³»ç»Ÿ<code>unzip</code> ï¼ˆä½¿ç”¨<code>getOption("unzip")</code>å‚æ•°ï¼‰ã€‚ </p><br><div class="spoiler">  <b class="spoiler_title">å†™å…¥æ•°æ®åº“çš„åŠŸèƒ½</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#' @title     #' #' @description #'  CSV-  ZIP-       #' #' @param con      ( `MonetDBEmbeddedConnection`). #' @param tablename     . #' @oaram zipfile   ZIP-. #' @oaram filename    ZIP-. #' @param preprocess  ,      . #'     `data` ( `data.table`). #' #' @return `TRUE`. #' upload_file &lt;- function(con, tablename, zipfile, filename, preprocess = NULL) { #   checkmate::assert_class(con, "MonetDBEmbeddedConnection") checkmate::assert_string(tablename) checkmate::assert_string(filename) checkmate::assert_true(DBI::dbExistsTable(con, tablename)) checkmate::assert_file_exists(zipfile, access = "r", extension = "zip") checkmate::assert_function(preprocess, args = c("data"), null.ok = TRUE) #   path &lt;- file.path(tempdir(), filename) unzip(zipfile, files = filename, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) on.exit(unlink(file.path(path))) #    if (!is.null(preprocess)) { .data &lt;- data.table::fread(file = path) .data &lt;- preprocess(data = .data) data.table::fwrite(x = .data, file = path, append = FALSE) rm(.data) } #      CSV sql &lt;- sprintf( "COPY OFFSET 2 INTO %s FROM '%s' USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT", tablename, path ) #     DBI::dbExecute(con, sql) #         DBI::dbExecute(con, sprintf("INSERT INTO upload_log(file_name, uploaded) VALUES('%s', true)", filename)) return(invisible(TRUE)) }</code> </pre> </div></div><br><p> å¦‚æœéœ€è¦åœ¨å†™å…¥æ•°æ®åº“ä¹‹å‰è½¬æ¢è¡¨ï¼Œåˆ™è¶³ä»¥ä¼ é€’å°†æ•°æ®è½¬æ¢ä¸º<code>preprocess</code>å‚æ•°çš„å‡½æ•°ã€‚ </p><br><p> ç”¨äºå°†æ•°æ®é¡ºåºåŠ è½½åˆ°æ•°æ®åº“ä¸­çš„ä»£ç ï¼š </p><br><div class="spoiler">  <b class="spoiler_title">å°†æ•°æ®å†™å…¥æ•°æ®åº“</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     files &lt;- unzip(zipfile, list = TRUE)$Name #  ,       to_skip &lt;- DBI::dbGetQuery(con, "SELECT file_name FROM upload_log")[[1L]] files &lt;- setdiff(files, to_skip) if (length(files) &gt; 0L) { #   tictoc::tic() #   pb &lt;- txtProgressBar(min = 0L, max = length(files), style = 3) for (i in seq_along(files)) { upload_file(con = con, tablename = "doodles", zipfile = zipfile, filename = files[i]) setTxtProgressBar(pb, i) } close(pb) #   tictoc::toc() } # 526.141 sec elapsed -  SSD-&gt;SSD # 558.879 sec elapsed -  USB-&gt;SSD</code> </pre> </div></div><br><p> æ•°æ®åŠ è½½æ—¶é—´å¯èƒ½ä¼šå› æ‰€ä½¿ç”¨é©±åŠ¨å™¨çš„é€Ÿåº¦ç‰¹æ€§è€Œå¼‚ã€‚ åœ¨æˆ‘ä»¬çš„æƒ…å†µä¸‹ï¼Œåœ¨åŒä¸€SSDå†…æˆ–ä»USBé—ªå­˜é©±åŠ¨å™¨ï¼ˆæºæ–‡ä»¶ï¼‰åˆ°SSDï¼ˆæ•°æ®åº“ï¼‰è¿›è¡Œè¯»å†™ä¸åˆ°10åˆ†é’Ÿã€‚ </p><br><p> åˆ›å»ºå¸¦æœ‰æ•´æ•°ç±»æ ‡ç­¾çš„åˆ—å’Œå¸¦æœ‰è¡Œå·çš„ç´¢å¼•åˆ—ï¼ˆ <code>ORDERED INDEX</code> ï¼‰ä¼šèŠ±è´¹å‡ ç§’é’Ÿçš„æ—¶é—´ï¼Œè¿™å°†ç”¨äºé€‰æ‹©åˆ›å»ºæ‰¹å¤„ç†æ—¶çš„æƒ…å†µï¼š </p><br><div class="spoiler">  <b class="spoiler_title">åˆ›å»ºå…¶ä»–åˆ—å’Œç´¢å¼•</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">message("Generate lables") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD label_int int")) invisible(DBI::dbExecute(con, "UPDATE doodles SET label_int = dense_rank() OVER (ORDER BY word) - 1")) message("Generate row numbers") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD id serial")) invisible(DBI::dbExecute(con, "CREATE ORDERED INDEX doodles_id_ord_idx ON doodles(id)"))</code> </pre> </div></div><br><p> ä¸ºäº†è§£å†³â€œå³æ—¶â€åˆ›å»ºæ‰¹å¤„ç†çš„é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦å®ç°ä»<code>doodles</code>è¡¨ä¸­æå–éšæœºå­—ç¬¦ä¸²çš„æœ€å¤§é€Ÿåº¦ã€‚ ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†3ä¸ªæŠ€å·§ã€‚ ç¬¬ä¸€ä¸ªæ˜¯å‡å°å­˜å‚¨è§‚å¯ŸIDçš„ç±»å‹çš„å°ºå¯¸ã€‚ åœ¨åŸå§‹æ•°æ®é›†ä¸­ï¼Œéœ€è¦ä½¿ç”¨<code>bigint</code>ç±»å‹æ¥å­˜å‚¨IDï¼Œä½†æ˜¯è§‚å¯Ÿæ¬¡æ•°å¯ä»¥ä½¿å®ƒä»¬çš„æ ‡è¯†ç¬¦ï¼ˆä¸åºåˆ—å·ç›¸åŒï¼‰é€‚åˆ<code>int</code>ç±»å‹ã€‚ æœç´¢é€Ÿåº¦æ›´å¿«ã€‚ ç¬¬äºŒä¸ªæŠ€å·§æ˜¯ä½¿ç”¨<code>ORDERED INDEX</code>è¿™ä¸ªå†³å®šæ˜¯å‡­ç»éªŒåšå‡ºçš„ï¼Œå¯¹æ‰€æœ‰å¯ç”¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">é€‰é¡¹</a>è¿›è¡Œäº†æ’åºã€‚ ç¬¬ä¸‰æ˜¯ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢ã€‚ è¯¥æ–¹æ³•çš„æœ¬è´¨æ˜¯æ‰§è¡Œä¸€æ¬¡<code>PREPARE</code>å‘½ä»¤ï¼Œç„¶ååœ¨åˆ›å»ºç›¸åŒç±»å‹çš„æŸ¥è¯¢å †æ—¶ä½¿ç”¨å‡†å¤‡å¥½çš„è¡¨è¾¾å¼ï¼Œä½†å®é™…ä¸Šï¼Œä¸ç®€å•çš„<code>SELECT</code>ç›¸æ¯”ï¼Œå…¶æ”¶ç›Šåœ¨äºç»Ÿè®¡é”™è¯¯ã€‚ </p><br><p> å¡«å……æ•°æ®çš„è¿‡ç¨‹ä¸è¶…è¿‡450 MBçš„RAMã€‚ ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‰€æè¿°çš„æ–¹æ³•å…è®¸æ‚¨åœ¨å‡ ä¹ä»»ä½•é¢„ç®—çš„ç¡¬ä»¶ï¼ˆåŒ…æ‹¬ä¸€äº›å•æ¿è®¡ç®—æœºï¼‰ä¸Šæ—‹è½¬é‡è¾¾æ•°åGBçš„æ•°æ®é›†ï¼Œè¿™éå¸¸é…·ã€‚ </p><br><p> åœ¨å¯¹ä¸åŒå¤§å°çš„æ‰¹æ¬¡è¿›è¡Œé‡‡æ ·æ—¶ï¼Œä»ç„¶éœ€è¦æµ‹é‡ï¼ˆéšæœºï¼‰æ•°æ®çš„æå–ç‡å¹¶è¯„ä¼°ç¼©æ”¾æ¯”ä¾‹ï¼š </p><br><div class="spoiler">  <b class="spoiler_title">åŸºå‡†æ•°æ®åº“</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(ggplot2) set.seed(0) #     con &lt;- DBI::dbConnect(MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) #        prep_sql &lt;- function(batch_size) { sql &lt;- sprintf("PREPARE SELECT id FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",")) res &lt;- DBI::dbSendQuery(con, sql) return(res) } #     fetch_data &lt;- function(rs, batch_size) { ids &lt;- sample(seq_len(n), batch_size) res &lt;- DBI::dbFetch(DBI::dbBind(rs, as.list(ids))) return(res) } #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { rs &lt;- prep_sql(batch_size) bench::mark( fetch_data(rs, batch_size), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 23.6ms 54.02ms 93.43ms 18.8 2.6s 49 # 2 32 38ms 84.83ms 151.55ms 11.4 4.29s 49 # 3 64 63.3ms 175.54ms 248.94ms 5.85 8.54s 50 # 4 128 83.2ms 341.52ms 496.24ms 3.00 16.69s 50 # 5 256 232.8ms 653.21ms 847.44ms 1.58 31.66s 50 # 6 512 784.6ms 1.41s 1.98s 0.740 1.1m 49 # 7 1024 681.7ms 2.72s 4.06s 0.377 2.16m 49 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/ys/oj/zq/ysojzqhr14wf8u9k1xsd6ecmlxc.png"><br><h4 id="section2">  2.æ‰¹æ¬¡çš„å‡†å¤‡ </h4><br><p> æ‰¹ç”Ÿäº§çš„æ•´ä¸ªè¿‡ç¨‹åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š </p><br><ol><li> è§£æåŒ…å«çº¿å‘é‡å’Œç‚¹åæ ‡çš„å¤šä¸ªJSONã€‚ </li><li> é€šè¿‡æ‰€éœ€å¤§å°çš„å›¾åƒä¸­çš„ç‚¹çš„åæ ‡ç»˜åˆ¶å½©è‰²çº¿ï¼ˆä¾‹å¦‚256x256æˆ–128x128ï¼‰ã€‚ </li><li> å°†ç”Ÿæˆçš„å›¾åƒè½¬æ¢ä¸ºå¼ é‡ã€‚ </li></ol><br><p> åœ¨Pythonå†…æ ¸ä¹‹é—´çš„ç«äº‰æ¡†æ¶ä¸‹ï¼Œä¸»è¦é€šè¿‡<strong>OpenCV</strong>è§£å†³äº†è¯¥é—®é¢˜ã€‚  Rä¸Šæœ€ç®€å•ï¼Œæœ€æ˜æ˜¾çš„ç±»ä¼¼ç‰©ä¹‹ä¸€å¦‚ä¸‹æ‰€ç¤ºï¼š </p><br><div class="spoiler">  <b class="spoiler_title">åœ¨Rä¸Šå®ç°JSONè‡³å¼ é‡è½¬æ¢</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">r_process_json_str &lt;- function(json, line.width = 3, color = TRUE, scale = 1) { #  JSON coords &lt;- jsonlite::fromJSON(json, simplifyMatrix = FALSE) tmp &lt;- tempfile() #       on.exit(unlink(tmp)) png(filename = tmp, width = 256 * scale, height = 256 * scale, pointsize = 1) #   plot.new() #    plot.window(xlim = c(256 * scale, 0), ylim = c(256 * scale, 0)) #   cols &lt;- if (color) rainbow(length(coords)) else "#000000" for (i in seq_along(coords)) { lines(x = coords[[i]][[1]] * scale, y = coords[[i]][[2]] * scale, col = cols[i], lwd = line.width) } dev.off() #    3-   res &lt;- png::readPNG(tmp) return(res) } r_process_json_vector &lt;- function(x, ...) { res &lt;- lapply(x, r_process_json_str, ...) #  3-     4-    res &lt;- do.call(abind::abind, c(res, along = 0)) return(res) }</code> </pre> </div></div><br><p> ä½¿ç”¨æ ‡å‡†Rå·¥å…·æ‰§è¡Œç»˜å›¾ï¼Œå¹¶å°†å…¶ä¿å­˜åˆ°RAMä¸­å­˜å‚¨çš„ä¸´æ—¶PNGä¸­ï¼ˆåœ¨Linuxä¸­ï¼Œä¸´æ—¶Rç›®å½•ä½äºRAMä¸­å®‰è£…çš„<code>/tmp</code>ä¸­ï¼‰ã€‚ ç„¶åï¼Œä»¥3ç»´æ•°ç»„çš„å½¢å¼è¯»å–æ­¤æ–‡ä»¶ï¼Œå…¶æ•°å­—èŒƒå›´ä¸º0åˆ°1ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºæ›´å¸¸è§çš„BMPå°†è¢«è¯»å–ä¸ºå¸¦æœ‰åå…­è¿›åˆ¶é¢œè‰²ä»£ç çš„åŸå§‹æ•°ç»„ã€‚ </p><br><p> æµ‹è¯•ç»“æœï¼š </p><br><pre> <code class="plaintext hljs">zip_file &lt;- file.path("data", "train_simplified.zip") csv_file &lt;- "cat.csv" unzip(zip_file, files = csv_file, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) tmp_data &lt;- data.table::fread(file.path(tempdir(), csv_file), sep = ",", select = "drawing", nrows = 10000) arr &lt;- r_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/t3/n2/-u/t3n2-ugr5ilwsygdfsrwd52vspc.png"><br><p> æ‰¹æ¬¡æœ¬èº«å°†å½¢æˆå¦‚ä¸‹ï¼š </p><br><pre> <code class="plaintext hljs">res &lt;- r_process_json_vector(tmp_data[1:4, drawing], scale = 0.5) str(res) # num [1:4, 1:128, 1:128, 1:3] 1 1 1 1 1 1 1 1 1 1 ... # - attr(*, "dimnames")=List of 4 # ..$ : NULL # ..$ : NULL # ..$ : NULL # ..$ : NULL</code> </pre> <br><p> åœ¨æˆ‘ä»¬çœ‹æ¥ï¼Œè¿™ç§å®ç°å¹¶ä¸æ˜¯æœ€ä½³é€‰æ‹©ï¼Œå› ä¸ºå¤§æ‰¹é‡çš„ç”Ÿäº§èŠ±è´¹äº†å¾ˆé•¿æ—¶é—´ï¼Œå¹¶ä¸”æˆ‘ä»¬å†³å®šä½¿ç”¨åŠŸèƒ½å¼ºå¤§çš„<strong>OpenCVåº“</strong>æ¥åˆ©ç”¨åŒäº‹çš„ç»éªŒã€‚ å½“æ—¶ï¼Œæ²¡æœ‰ç”¨äºRçš„ç°æˆè½¯ä»¶åŒ…ï¼ˆç”šè‡³ç°åœ¨éƒ½æ²¡æœ‰ï¼‰ï¼Œå› æ­¤ä½¿ç”¨<strong>Rcpp</strong>å°†å…¶é›†æˆåˆ°Rä»£ç ä¸­ï¼Œ <strong>ä»è€Œ</strong>ç¼–å†™äº†C ++ä¸­æ‰€éœ€åŠŸèƒ½çš„æœ€å°å®ç°ã€‚ </p><br><p> ä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œä½¿ç”¨äº†ä»¥ä¸‹è½¯ä»¶åŒ…å’Œåº“ï¼š </p><br><ol><li>  <strong>OpenCV</strong>ç”¨äºæˆåƒå’Œçº¿æ¡ç»˜åˆ¶ã€‚ æˆ‘ä»¬ä½¿ç”¨äº†é¢„å®‰è£…çš„ç³»ç»Ÿåº“å’Œå¤´æ–‡ä»¶ï¼Œä»¥åŠåŠ¨æ€é“¾æ¥ã€‚ </li><li>  <strong>xtensor</strong>ç”¨äºå¤„ç†å¤šç»´æ•°ç»„å’Œå¼ é‡ã€‚ æˆ‘ä»¬ä½¿ç”¨äº†åŒ…å«åœ¨åŒåR-packageä¸­çš„å¤´æ–‡ä»¶ã€‚ è¯¥åº“ä½¿æ‚¨å¯ä»¥æŒ‰è¡Œä¸»é¡ºåºå’Œåˆ—ä¸»é¡ºåºä½¿ç”¨å¤šç»´æ•°ç»„ã€‚ </li><li>  <strong>ndjson</strong>ç”¨äºè§£æJSONã€‚ å½“é¡¹ç›®ä¸­å¯ç”¨æ—¶ï¼Œè¯¥åº“ä¼šè‡ªåŠ¨åœ¨<strong>xtensor</strong>ä¸­ä½¿ç”¨ã€‚ </li><li>  <strong>RcppThread</strong>ç”¨äºç»„ç»‡æ¥è‡ªJSONçš„å‘é‡çš„å¤šçº¿ç¨‹å¤„ç†ã€‚ ä½¿ç”¨äº†æ­¤è½¯ä»¶åŒ…æä¾›çš„å¤´æ–‡ä»¶ã€‚ è¯¥ç¨‹åºåŒ…çš„å†…ç½®ä¸­æ–­æœºåˆ¶ä¸æ›´æµè¡Œçš„<strong>RcppParallel</strong>æœ‰æ‰€ä¸åŒã€‚ </li></ol><br><p> å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ <strong>xtensor</strong>åªæ˜¯ä¸€ä¸ªå‘ç°ï¼šé™¤äº†å…·æœ‰å¹¿æ³›çš„åŠŸèƒ½å’Œé«˜æ€§èƒ½ä¹‹å¤–ï¼Œ <strong>xtensor</strong>çš„å¼€å‘äººå‘˜è¿˜å…·æœ‰å¾ˆå¼ºçš„å“åº”èƒ½åŠ›ï¼Œå¹¶åŠæ—¶è¯¦ç»†åœ°å›ç­”äº†å‡ºç°çš„é—®é¢˜ã€‚ åœ¨ä»–ä»¬çš„å¸®åŠ©ä¸‹ï¼Œå¯ä»¥å°†OpenCVçŸ©é˜µè½¬æ¢ä¸ºå¼ é‡å¼ é‡ï¼Œä»¥åŠå°†3ç»´å›¾åƒå¼ é‡ç»„åˆä¸ºæ­£ç¡®å°ºå¯¸çš„4ç»´å¼ é‡ï¼ˆå®é™…ä¸Šæ˜¯æ‰¹å¤„ç†ï¼‰çš„æ–¹æ³•ã€‚ </p><br><div class="spoiler">  <b class="spoiler_title">Rcppï¼Œxtensorå’ŒRcppThreadçš„å­¦ä¹ èµ„æ–™</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://thecoatlessprofessor.com/programming/unofficial-rcpp-api-documentation</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://docs.opencv.org/4.0.1/d7/dbd/group__imgproc.html</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://xtensor.readthedocs.io/en/latest/</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://xtensor.readthedocs.io/zh-CN/latest/file_loading.html#loading-json-data-into-xtensor</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https://cran.r-project.org/web/packages/RcppThread/vignettes/RcppThread-vignette.pdf</a> </p></div></div><br><p> ä¸ºäº†ä½¿ç”¨ç³»ç»Ÿæ–‡ä»¶ç¼–è¯‘æ–‡ä»¶å¹¶ä¸ç³»ç»Ÿä¸­å®‰è£…çš„åº“è¿›è¡ŒåŠ¨æ€é“¾æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†<strong>Rcpp</strong>è½¯ä»¶åŒ…ä¸­å®ç°çš„æ’ä»¶æœºåˆ¶ã€‚ ä¸ºäº†è‡ªåŠ¨æŸ¥æ‰¾è·¯å¾„å’Œæ ‡å¿—ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æµè¡Œçš„linuxå®ç”¨ç¨‹åº<strong>pkg-config</strong> ã€‚ </p><br><div class="spoiler">  <b class="spoiler_title">å®æ–½Rcppæ’ä»¶ä»¥ä½¿ç”¨OpenCVåº“</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">Rcpp::registerPlugin("opencv", function() { #    pkg_config_name &lt;- c("opencv", "opencv4") #    pkg-config pkg_config_bin &lt;- Sys.which("pkg-config") #      checkmate::assert_file_exists(pkg_config_bin, access = "x") #     OpenCV  pkg-config check &lt;- sapply(pkg_config_name, function(pkg) system(paste(pkg_config_bin, pkg))) if (all(check != 0)) { stop("OpenCV config for the pkg-config not found", call. = FALSE) } pkg_config_name &lt;- pkg_config_name[check == 0] list(env = list( PKG_CXXFLAGS = system(paste(pkg_config_bin, "--cflags", pkg_config_name), intern = TRUE), PKG_LIBS = system(paste(pkg_config_bin, "--libs", pkg_config_name), intern = TRUE) )) })</code> </pre> </div></div><br><p> ä½œä¸ºæ’ä»¶çš„ç»“æœï¼Œåœ¨ç¼–è¯‘æœŸé—´ï¼Œå°†æ›¿æ¢ä»¥ä¸‹å€¼ï¼š </p><br><pre> <code class="plaintext hljs">Rcpp:::.plugins$opencv()$env # $PKG_CXXFLAGS # [1] "-I/usr/include/opencv" # # $PKG_LIBS # [1] "-lopencv_shape -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_datasets -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_line_descriptor -lopencv_optflow -lopencv_video -lopencv_plot -lopencv_reg -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_rgbd -lopencv_viz -lopencv_surface_matching -lopencv_text -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_flann -lopencv_xobjdetect -lopencv_objdetect -lopencv_ml -lopencv_xphoto -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_photo -lopencv_imgproc -lopencv_core"</code> </pre> <br><p> åœ¨å‰§é€å™¨ä¸‹ç»™å‡ºäº†ç”¨äºå®ç°JSONè§£æå’Œåˆ›å»ºæ‰¹å¤„ç†ä»¥ä¼ è¾“åˆ°æ¨¡å‹çš„ä»£ç ã€‚ é¦–å…ˆï¼Œæ·»åŠ æœ¬åœ°é¡¹ç›®ç›®å½•ä»¥æœç´¢å¤´æ–‡ä»¶ï¼ˆndjsonæ‰€éœ€ï¼‰ï¼š </p><br><pre> <code class="plaintext hljs">Sys.setenv("PKG_CXXFLAGS" = paste0("-I", normalizePath(file.path("src"))))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">åœ¨C ++ä¸­å®ç°JSONåˆ°å¼ é‡è½¬æ¢</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">// [[Rcpp::plugins(cpp14)]] // [[Rcpp::plugins(opencv)]] // [[Rcpp::depends(xtensor)]] // [[Rcpp::depends(RcppThread)]] #include &lt;xtensor/xjson.hpp&gt; #include &lt;xtensor/xadapt.hpp&gt; #include &lt;xtensor/xview.hpp&gt; #include &lt;xtensor-r/rtensor.hpp&gt; #include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;opencv2/imgproc/imgproc.hpp&gt; #include &lt;Rcpp.h&gt; #include &lt;RcppThread.h&gt; //    using RcppThread::parallelFor; using json = nlohmann::json; using points = xt::xtensor&lt;double,2&gt;; //   JSON   using strokes = std::vector&lt;points&gt;; //   JSON   using xtensor3d = xt::xtensor&lt;double, 3&gt;; //      using xtensor4d = xt::xtensor&lt;double, 4&gt;; //      using rtensor3d = xt::rtensor&lt;double, 3&gt;; //     R using rtensor4d = xt::rtensor&lt;double, 4&gt;; //     R //   //     const static int SIZE = 256; //   // . https://en.wikipedia.org/wiki/Pixel_connectivity#2-dimensional const static int LINE_TYPE = cv::LINE_4; //     const static int LINE_WIDTH = 3; //   // https://docs.opencv.org/3.1.0/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121 const static int RESIZE_TYPE = cv::INTER_LINEAR; //    OpenCV-   template &lt;typename T, int NCH, typename XT=xt::xtensor&lt;T,3,xt::layout_type::column_major&gt;&gt; XT to_xt(const cv::Mat_&lt;cv::Vec&lt;T, NCH&gt;&gt;&amp; src) { //    std::vector&lt;int&gt; shape = {src.rows, src.cols, NCH}; //      size_t size = src.total() * NCH; //  cv::Mat  xt::xtensor XT res = xt::adapt((T*) src.data, size, xt::no_ownership(), shape); return res; } //  JSON     strokes parse_json(const std::string&amp; x) { auto j = json::parse(x); //      if (!j.is_array()) { throw std::runtime_error("'x' must be JSON array."); } strokes res; res.reserve(j.size()); for (const auto&amp; a: j) { //      2-  if (!a.is_array() || a.size() != 2) { throw std::runtime_error("'x' must include only 2d arrays."); } //    auto p = a.get&lt;points&gt;(); res.push_back(p); } return res; } //   //  HSV cv::Mat ocv_draw_lines(const strokes&amp; x, bool color = true) { //    auto stype = color ? CV_8UC3 : CV_8UC1; //    auto dtype = color ? CV_32FC3 : CV_32FC1; auto bg = color ? cv::Scalar(0, 0, 255) : cv::Scalar(255); auto col = color ? cv::Scalar(0, 255, 220) : cv::Scalar(0); cv::Mat img = cv::Mat(SIZE, SIZE, stype, bg); //   size_t n = x.size(); for (const auto&amp; s: x) { //     size_t n_points = s.shape()[1]; for (size_t i = 0; i &lt; n_points - 1; ++i) { //    cv::Point from(s(0, i), s(1, i)); //    cv::Point to(s(0, i + 1), s(1, i + 1)); //   cv::line(img, from, to, col, LINE_WIDTH, LINE_TYPE); } if (color) { //    col[0] += 180 / n; } } if (color) { //     RGB cv::cvtColor(img, img, cv::COLOR_HSV2RGB); } //     float32   [0, 1] img.convertTo(img, dtype, 1 / 255.0); return img; } //  JSON       xtensor3d process(const std::string&amp; x, double scale = 1.0, bool color = true) { auto p = parse_json(x); auto img = ocv_draw_lines(p, color); if (scale != 1) { cv::Mat out; cv::resize(img, out, cv::Size(), scale, scale, RESIZE_TYPE); cv::swap(img, out); out.release(); } xtensor3d arr = color ? to_xt&lt;double,3&gt;(img) : to_xt&lt;double,1&gt;(img); return arr; } // [[Rcpp::export]] rtensor3d cpp_process_json_str(const std::string&amp; x, double scale = 1.0, bool color = true) { xtensor3d res = process(x, scale, color); return res; } // [[Rcpp::export]] rtensor4d cpp_process_json_vector(const std::vector&lt;std::string&gt;&amp; x, double scale = 1.0, bool color = false) { size_t n = x.size(); size_t dim = floor(SIZE * scale); size_t channels = color ? 3 : 1; xtensor4d res({n, dim, dim, channels}); parallelFor(0, n, [&amp;x, &amp;res, scale, color](int i) { xtensor3d tmp = process(x[i], scale, color); auto view = xt::view(res, i, xt::all(), xt::all(), xt::all()); view = tmp; }); return res; }</code> </pre> </div></div><br><p> è¯¥ä»£ç åº”æ”¾åœ¨<code>src/cv_xt.cpp</code>å¹¶ä½¿ç”¨å‘½ä»¤<code>Rcpp::sourceCpp(file = "src/cv_xt.cpp", env = .GlobalEnv)</code> ï¼› æ‚¨è¿˜éœ€è¦ä»<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">å­˜å‚¨åº“ä¸­</a> <code>nlohmann/json.hpp</code> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ‰èƒ½æ­£å¸¸å·¥ä½œ</a> ã€‚ è¯¥ä»£ç åˆ†ä¸ºå‡ ä¸ªåŠŸèƒ½ï¼š </p><br><ul><li>  <code>to_xt</code>ç”¨äºå°†å›¾åƒçŸ©é˜µï¼ˆ <code>cv::Mat</code> ï¼‰è½¬æ¢ä¸ºå¼ é‡<code>xt::xtensor</code>çš„æ¨¡æ¿å‡½æ•°ï¼› </li><li>  <code>parse_json</code>å‡½æ•°è§£æä¸€ä¸ªJSONå­—ç¬¦ä¸²ï¼Œæå–ç‚¹çš„åæ ‡ï¼Œå°†å®ƒä»¬æ‰“åŒ…æˆä¸€ä¸ªå‘é‡ï¼› </li><li>  <code>ocv_draw_lines</code>ä»æ¥æ”¶åˆ°çš„ç‚¹å‘é‡<code>ocv_draw_lines</code>å¤šè‰²çº¿ï¼› </li><li>  <code>process</code> -ç»“åˆäº†ä¸Šè¿°åŠŸèƒ½ï¼Œè¿˜å¢åŠ äº†ç¼©æ”¾ç»“æœå›¾åƒçš„èƒ½åŠ›ï¼› </li><li>  <code>cpp_process_json_str</code> <code>process</code>å‡½æ•°çš„åŒ…è£…ï¼Œå°†ç»“æœå¯¼å‡ºåˆ°Rå¯¹è±¡ï¼ˆå¤šç»´æ•°ç»„ï¼‰ï¼› </li><li>  <code>cpp_process_json_vector</code> - <code>cpp_process_json_str</code>å‡½æ•°çš„åŒ…è£…ï¼Œå®ƒä½¿æ‚¨å¯ä»¥åœ¨å¤šçº¿ç¨‹æ¨¡å¼ä¸‹å¤„ç†å­—ç¬¦ä¸²å‘é‡ã€‚ </li></ul><br><p> è¦ç»˜åˆ¶å¤šè‰²çº¿ï¼Œä½¿ç”¨HSVé¢œè‰²æ¨¡å‹ï¼Œç„¶åè½¬æ¢ä¸ºRGBã€‚ æµ‹è¯•ç»“æœï¼š </p><br><pre> <code class="plaintext hljs">arr &lt;- cpp_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/23/mm/ro/23mmrob6qhnjgnsaqm-4mno159c.png"><br><div class="spoiler">  <b class="spoiler_title">Rå’ŒC ++ä¸­å®ç°é€Ÿåº¦çš„æ¯”è¾ƒ</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">res_bench &lt;- bench::mark( r_process_json_str(tmp_data[4, drawing], scale = 0.5), cpp_process_json_str(tmp_data[4, drawing], scale = 0.5), check = FALSE, min_iterations = 100 ) #   cols &lt;- c("expression", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # expression min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r_process_json_str 3.49ms 3.55ms 4.47ms 273. 490ms 134 # 2 cpp_process_json_str 1.94ms 2.02ms 5.32ms 489. 497ms 243 library(ggplot2) #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { .data &lt;- tmp_data[sample(seq_len(.N), batch_size), drawing] bench::mark( r_process_json_vector(.data, scale = 0.5), cpp_process_json_vector(.data, scale = 0.5), min_iterations = 50, check = FALSE ) } ) res_bench[, cols] # expression batch_size min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r 16 50.61ms 53.34ms 54.82ms 19.1 471.13ms 9 # 2 cpp 16 4.46ms 5.39ms 7.78ms 192. 474.09ms 91 # 3 r 32 105.7ms 109.74ms 212.26ms 7.69 6.5s 50 # 4 cpp 32 7.76ms 10.97ms 15.23ms 95.6 522.78ms 50 # 5 r 64 211.41ms 226.18ms 332.65ms 3.85 12.99s 50 # 6 cpp 64 25.09ms 27.34ms 32.04ms 36.0 1.39s 50 # 7 r 128 534.5ms 627.92ms 659.08ms 1.61 31.03s 50 # 8 cpp 128 56.37ms 58.46ms 66.03ms 16.9 2.95s 50 # 9 r 256 1.15s 1.18s 1.29s 0.851 58.78s 50 # 10 cpp 256 114.97ms 117.39ms 130.09ms 8.45 5.92s 50 # 11 r 512 2.09s 2.15s 2.32s 0.463 1.8m 50 # 12 cpp 512 230.81ms 235.6ms 261.99ms 4.18 11.97s 50 # 13 r 1024 4s 4.22s 4.4s 0.238 3.5m 50 # 14 cpp 1024 410.48ms 431.43ms 462.44ms 2.33 21.45s 50 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = expression, color = expression)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() + scale_color_discrete(name = "", labels = c("cpp", "r")) + theme(legend.position = "bottom")</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/zq/if/sa/zqifsayhpqy-dujaijmn-brk058.png"><br><p> å¦‚æ‚¨æ‰€è§ï¼Œé€Ÿåº¦çš„æé«˜éå¸¸é‡è¦ï¼Œå¹¶ä¸”ä¸å¯èƒ½é€šè¿‡å¹¶è¡ŒåŒ–Rä»£ç æ¥èµ¶ä¸ŠC ++ä»£ç ã€‚ </p><br><h4 id="section3">  3.ç”¨äºä»æ•°æ®åº“ä¸­å¸è½½æ‰¹å¤„ç†çš„è¿­ä»£å™¨ </h4><br><p>  Rä½œä¸ºä¸€ç§ç”¨äºå¤„ç†ä½äºRAMä¸­çš„æ•°æ®çš„è¯­è¨€è€Œäº«æœ‰ç››åï¼Œè€ŒPythonçš„ä¸»è¦ç‰¹è‰²æ˜¯è¿­ä»£æ•°æ®å¤„ç†ï¼Œè¿™ä½¿å¾—å®ç°æ ¸å¤–è®¡ç®—ï¼ˆä½¿ç”¨å¤–éƒ¨å­˜å‚¨å™¨è¿›è¡Œçš„è®¡ç®—ï¼‰å˜å¾—å®¹æ˜“åˆå®¹æ˜“ã€‚ åœ¨æ‰€æè¿°é—®é¢˜çš„èƒŒæ™¯ä¸‹ï¼Œä¸æˆ‘ä»¬æœ‰å…³çš„ç»å…¸æ–¹æ³•æ˜¯æ·±åº¦è®¡ç®—ç¥ç»ç½‘ç»œï¼Œå®ƒæ˜¯é€šè¿‡æ¢¯åº¦ä¸‹é™æ–¹æ³•è®­ç»ƒçš„ï¼Œå…¶ä¸­æ¯ä¸€æ­¥çš„æ¢¯åº¦éƒ½ç”±ä¸€å°éƒ¨åˆ†è§‚æµ‹å€¼æˆ–å°æ‰¹é‡è¿›è¡Œè¿‘ä¼¼ã€‚ </p><br><p> ç”¨Pythonç¼–å†™çš„æ·±åº¦å­¦ä¹ æ¡†æ¶å…·æœ‰ç‰¹æ®Šçš„ç±»ï¼Œè¿™äº›ç±»åŸºäºæ•°æ®å®ç°è¿­ä»£å™¨ï¼šè¡¨æ ¼ï¼Œæ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡ï¼ŒäºŒè¿›åˆ¶æ ¼å¼ç­‰ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ç°æˆçš„é€‰é¡¹æˆ–ä¸ºç‰¹å®šä»»åŠ¡ç¼–å†™è‡ªå·±çš„é€‰é¡¹ã€‚ åœ¨Rä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å…·æœ‰ç›¸åŒåç§°çš„åŒ…å……åˆ†åˆ©ç”¨Keras Pythonåº“åŠå…¶å„ç§åç«¯ï¼Œè€Œè¯¥åŒ…åˆå¯ä»¥åœ¨<strong>ç½‘çŠ¶</strong>åŒ…çš„é¡¶éƒ¨ä½¿ç”¨ã€‚ åè€…å€¼å¾—å•ç‹¬å†™ä¸€ç¯‡å¤§æ–‡ç« ï¼› å®ƒä¸ä»…å…è®¸æ‚¨ä»Rè¿è¡ŒPythonä»£ç ï¼Œè€Œä¸”è¿˜æä¾›äº†R-å’ŒPythonä¼šè¯ä¹‹é—´çš„å¯¹è±¡ä¼ è¾“ï¼Œä»è€Œè‡ªåŠ¨æ‰§è¡Œæ‰€æœ‰å¿…è¦çš„ç±»å‹è½¬æ¢ã€‚ </p><br><p> ç”±äºä½¿ç”¨äº†MonetDBLiteï¼Œæˆ‘ä»¬æ‘†è„±äº†å°†æ‰€æœ‰æ•°æ®å­˜å‚¨åœ¨RAMä¸­çš„éœ€è¦ï¼Œæ‰€æœ‰çš„â€œç¥ç»ç½‘ç»œâ€å·¥ä½œå°†ç”±åŸå§‹Pythonä»£ç å®Œæˆï¼Œæˆ‘ä»¬åªéœ€è¦æ ¹æ®æ•°æ®ç¼–å†™ä¸€ä¸ªè¿­ä»£å™¨ï¼Œå› ä¸ºRæˆ–Pythonä¸­éƒ½æ²¡æœ‰é’ˆå¯¹è¿™ç§æƒ…å†µçš„å‡†å¤‡ã€‚       :              (  R      ).         R  numpy-,     <strong>keras</strong>   . </p><br><p>        : </p><br><div class="spoiler"> <b class="spoiler_title">     </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">train_generator &lt;- function(db_connection = con, samples_index, num_classes = 340, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_class(con, "DBIConnection") checkmate::assert_integerish(samples_index) checkmate::assert_count(num_classes) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) # ,          dt &lt;- data.table::data.table(id = sample(samples_index)) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] #       dt &lt;- dt[, if (.N == batch_size) .SD, keyby = batch] #   i &lt;- 1 #   max_i &lt;- dt[, max(batch)] #     sql &lt;- sprintf( "PREPARE SELECT drawing, label_int FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",") ) res &lt;- DBI::dbSendQuery(con, sql) #  keras::to_categorical to_categorical &lt;- function(x, num) { n &lt;- length(x) m &lt;- numeric(n * num) m[x * n + seq_len(n)] &lt;- 1 dim(m) &lt;- c(n, num) return(m) } #  function() { #    if (i &gt; max_i) { dt[, id := sample(id)] data.table::setkey(dt, batch) #   i &lt;&lt;- 1 max_i &lt;&lt;- dt[, max(batch)] } # ID    batch_ind &lt;- dt[batch == i, id] #   batch &lt;- DBI::dbFetch(DBI::dbBind(res, as.list(batch_ind)), n = -1) #   i &lt;&lt;- i + 1 #  JSON    batch_x &lt;- cpp_process_json_vector(batch$drawing, scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } batch_y &lt;- to_categorical(batch$label_int, num_classes) result &lt;- list(batch_x, batch_y) return(result) } }</code> </pre> </div></div><br><p>         ,   ,  ,  ,  ( <code>scale = 1</code>    256256 , <code>scale = 0.5</code> â€” 128128 ),   ( <code>color = FALSE</code>     ,   <code>color = TRUE</code>     )     ,   imagenet-.    ,       [0, 1]   [-1, 1],        <strong>keras</strong> . </p><br><p>      ,  <code>data.table</code>        <code>samples_index</code>   ,     ,   SQL-     .        <code>keras::to_categorical()</code> .       ,    ,      <code>steps_per_epoch</code>   <code>keras::fit_generator()</code> ,   <code>if (i &gt; max_i)</code>     . </p><br><p>          ,        ,  JSON- ( <code>cpp_process_json_vector()</code> ,   C++)   ,  .   one-hot    ,          ,     .         <code>data.table</code>     â€”   ""  <strong>data.table</strong>       -     R. </p><br><p>       Core i5   : </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(Rcpp) library(keras) library(ggplot2) source("utils/rcpp.R") source("utils/keras_iterator.R") con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) ind &lt;- seq_len(DBI::dbGetQuery(con, "SELECT count(*) FROM doodles")[[1L]]) num_classes &lt;- DBI::dbGetQuery(con, "SELECT max(label_int) + 1 FROM doodles")[[1L]] #     train_ind &lt;- sample(ind, floor(length(ind) * 0.995)) #     val_ind &lt;- ind[-train_ind] rm(ind) #   scale &lt;- 0.5 #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { it1 &lt;- train_generator( db_connection = con, samples_index = train_ind, num_classes = num_classes, batch_size = batch_size, scale = scale ) bench::mark( it1(), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 25ms 64.36ms 92.2ms 15.9 3.09s 49 # 2 32 48.4ms 118.13ms 197.24ms 8.17 5.88s 48 # 3 64 69.3ms 117.93ms 181.14ms 8.57 5.83s 50 # 4 128 157.2ms 240.74ms 503.87ms 3.85 12.71s 49 # 5 256 359.3ms 613.52ms 988.73ms 1.54 30.5s 47 # 6 512 884.7ms 1.53s 2.07s 0.674 1.11m 45 # 7 1024 2.7s 3.83s 5.47s 0.261 2.81m 44 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/w0/i6/jx/w0i6jxjhgwqs82fbazwxdquqe18.png"><br><p>     ,              (    32 ).       <code>/dev/shm</code> ,     .    ,  <code>/etc/fstab</code> ,     <code>tmpfs /dev/shm tmpfs defaults,size=25g 0 0</code> .     ,   <code>df -h</code> . </p><br><p>       ,       : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">test_generator &lt;- function(dt, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_data_table(dt) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] data.table::setkey(dt, batch) i &lt;- 1 max_i &lt;- dt[, max(batch)] #  function() { batch_x &lt;- cpp_process_json_vector(dt[batch == i, drawing], scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } result &lt;- list(batch_x) i &lt;&lt;- i + 1 return(result) } }</code> </pre> </div></div><br><h4 id="section4"> 4.    </h4><br><p>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">mobilenet v1</a> ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> .      <strong>keras</strong> , ,      R.          :       <code>(batch, height, width, 3)</code> ,      .  Python   ,         ,    ( ,    keras- ): </p><br><div class="spoiler"> <b class="spoiler_title"> mobilenet v1</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(keras) top_3_categorical_accuracy &lt;- custom_metric( name = "top_3_categorical_accuracy", metric_fn = function(y_true, y_pred) { metric_top_k_categorical_accuracy(y_true, y_pred, k = 3) } ) layer_sep_conv_bn &lt;- function(object, filters, alpha = 1, depth_multiplier = 1, strides = c(2, 2)) { # NB! depth_multiplier != resolution multiplier # https://github.com/keras-team/keras/issues/10349 layer_depthwise_conv_2d( object = object, kernel_size = c(3, 3), strides = strides, padding = "same", depth_multiplier = depth_multiplier ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_conv_2d( filters = filters * alpha, kernel_size = c(1, 1), strides = c(1, 1) ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() } get_mobilenet_v1 &lt;- function(input_shape = c(224, 224, 1), num_classes = 340, alpha = 1, depth_multiplier = 1, optimizer = optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = c("categorical_crossentropy", top_3_categorical_accuracy)) { inputs &lt;- layer_input(shape = input_shape) outputs &lt;- inputs %&gt;% layer_conv_2d(filters = 32, kernel_size = c(3, 3), strides = c(2, 2), padding = "same") %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_sep_conv_bn(filters = 64, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(1, 1)) %&gt;% layer_global_average_pooling_2d() %&gt;% layer_dense(units = num_classes) %&gt;% layer_activation_softmax() model &lt;- keras_model( inputs = inputs, outputs = outputs ) model %&gt;% compile( optimizer = optimizer, loss = loss, metrics = metrics ) return(model) }</code> </pre> </div></div><br><p>    .    ,     , ,  .        ,    imagenet-.  ,   .  <code>get_config()</code>          ( <code>base_model_conf$layers</code> â€”  R- ),   <code>from_config()</code>      : </p><br><pre> <code class="plaintext hljs">base_model_conf &lt;- get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- from_config(base_model_conf)</code> </pre> <br><p>               <strong>keras</strong>     imagenet-    : </p><br><div class="spoiler"> <b class="spoiler_title">    </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">get_model &lt;- function(name = "mobilenet_v2", input_shape = NULL, weights = "imagenet", pooling = "avg", num_classes = NULL, optimizer = keras::optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = NULL, color = TRUE, compile = FALSE) { #   checkmate::assert_string(name) checkmate::assert_integerish(input_shape, lower = 1, upper = 256, len = 3) checkmate::assert_count(num_classes) checkmate::assert_flag(color) checkmate::assert_flag(compile) #     keras model_fun &lt;- get0(paste0("application_", name), envir = asNamespace("keras")) #      if (is.null(model_fun)) { stop("Model ", shQuote(name), " not found.", call. = FALSE) } base_model &lt;- model_fun( input_shape = input_shape, include_top = FALSE, weights = weights, pooling = pooling ) #    ,    if (!color) { base_model_conf &lt;- keras::get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- keras::from_config(base_model_conf) } predictions &lt;- keras::get_layer(base_model, "global_average_pooling2d_1")$output predictions &lt;- keras::layer_dense(predictions, units = num_classes, activation = "softmax") model &lt;- keras::keras_model( inputs = base_model$input, outputs = predictions ) if (compile) { keras::compile( object = model, optimizer = optimizer, loss = loss, metrics = metrics ) } return(model) }</code> </pre> </div></div><br><p>        .     :    <code>get_weights()</code>        R- ,       ( -       ),         <code>set_weights()</code> .       ,       ,      . </p><br><p>        mobilenet  1  2,   resnet34.         ,   SE-ResNeXt.  ,       ,       (  ). </p><br><h4 id="section5"> 5.   </h4><br><p>             ,    <strong><a href="">docopt</a></strong>  : </p><br><pre> <code class="plaintext hljs">doc &lt;- ' Usage: train_nn.R --help train_nn.R --list-models train_nn.R [options] Options: -h --help Show this message. -l --list-models List available models. -m --model=&lt;model&gt; Neural network model name [default: mobilenet_v2]. -b --batch-size=&lt;size&gt; Batch size [default: 32]. -s --scale-factor=&lt;ratio&gt; Scale factor [default: 0.5]. -c --color Use color lines [default: FALSE]. -d --db-dir=&lt;path&gt; Path to database directory [default: Sys.getenv("db_dir")]. -r --validate-ratio=&lt;ratio&gt; Validate sample ratio [default: 0.995]. -n --n-gpu=&lt;number&gt; Number of GPUs [default: 1]. ' args &lt;- docopt::docopt(doc)</code> </pre> <br><p>  <strong>docopt</strong>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">http://docopt.org/</a>  R.         <code>Rscript bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code>  <code>./bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code> ,   <code>train_nn.R</code>   (     <code>resnet50</code>     128128 ,       <code>/home/andrey/doodle_db</code> ).      ,       .     ,   <code>mobilenet_v2</code>    <strong>keras</strong>  R  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> -   R-  â€” ,  . </p><br><p>                  RStudio (      <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">tfruns</a></strong> ).                ,     RStudio. </p><br><h4 id="section6"> 6.   </h4><br><p>                    .        R-    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> . </p><br><p>       Â« Â»,           .        ,    NVIDIA, CUDA+cuDNN    â€”    ,        <code>tensorflow/tensorflow:1.12.0-gpu</code> ,    R-. </p><br><p>  -  : </p><br><div class="spoiler"> <b class="spoiler_title">Dockerfile</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">FROM tensorflow/tensorflow:1.12.0-gpu MAINTAINER Artem Klevtsov &lt;aaklevtsov@gmail.com&gt; SHELL ["/bin/bash", "-c"] ARG LOCALE="en_US.UTF-8" ARG APT_PKG="libopencv-dev r-base r-base-dev littler" ARG R_BIN_PKG="futile.logger checkmate data.table rcpp rapidjsonr dbi keras jsonlite curl digest remotes" ARG R_SRC_PKG="xtensor RcppThread docopt MonetDBLite" ARG PY_PIP_PKG="keras" ARG DIRS="/db /app /app/data /app/models /app/logs" RUN source /etc/os-release &amp;&amp; \ echo "deb https://cloud.r-project.org/bin/linux/ubuntu ${UBUNTU_CODENAME}-cran35/" &gt; /etc/apt/sources.list.d/cran35.list &amp;&amp; \ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 &amp;&amp; \ add-apt-repository -y ppa:marutter/c2d4u3.5 &amp;&amp; \ add-apt-repository -y ppa:timsc/opencv-3.4 &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y locales &amp;&amp; \ locale-gen ${LOCALE} &amp;&amp; \ apt-get install -y --no-install-recommends ${APT_PKG} &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install.r /usr/local/bin/install.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install2.r /usr/local/bin/install2.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/installGithub.r /usr/local/bin/installGithub.r &amp;&amp; \ echo 'options(Ncpus = parallel::detectCores())' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ echo 'options(repos = c(CRAN = "https://cloud.r-project.org"))' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ apt-get install -y $(printf "r-cran-%s " ${R_BIN_PKG}) &amp;&amp; \ install.r ${R_SRC_PKG} &amp;&amp; \ pip install ${PY_PIP_PKG} &amp;&amp; \ mkdir -p ${DIRS} &amp;&amp; \ chmod 777 ${DIRS} &amp;&amp; \ rm -rf /tmp/downloaded_packages/ /tmp/*.rds &amp;&amp; \ rm -rf /var/lib/apt/lists/* COPY utils /app/utils COPY src /app/src COPY tests /app/tests COPY bin/*.R /app/ ENV DBDIR="/db" ENV CUDA_HOME="/usr/local/cuda" ENV PATH="/app:${PATH}" WORKDIR /app VOLUME /db VOLUME /app CMD bash</code> </pre></div></div><br><p>        ;         .       <code>/bin/bash</code>     <code>/etc/os-release</code> .         . </p><br><p>     -,      . ,       ,    ,          : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#!/bin/sh DBDIR=${PWD}/db LOGSDIR=${PWD}/logs MODELDIR=${PWD}/models DATADIR=${PWD}/data ARGS="--runtime=nvidia --rm -v ${DBDIR}:/db -v ${LOGSDIR}:/app/logs -v ${MODELDIR}:/app/models -v ${DATADIR}:/app/data" if [ -z "$1" ]; then CMD="Rscript /app/train_nn.R" elif [ "$1" = "bash" ]; then ARGS="${ARGS} -ti" else CMD="Rscript /app/train_nn.R $@" fi docker run ${ARGS} doodles-tf ${CMD}</code> </pre> </div></div><br><p>   -   ,      <code>train_nn.R</code>    ;     â€”  "bash",         .         : <code>CMD="Rscript /app/train_nn.R $@"</code> . </p><br><p>   ,        ,             ,           . </p><br><h4 id="section7"> 7.   GPU   Google Cloud </h4><br><p>         (.  ,   @Leigh.plt  ODS-).       ,        1 GPU       GPU  .  GoogleCloud ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">    </a> ) -    ,     $300.       4V100  SSD   ,     .     ,       .      K80.       â€”  SSD   c,          <code>dev/shm</code> . </p><br><p>     ,     GPU.     CPU    ,    : </p><br><pre> <code class="plaintext hljs">with(tensorflow::tf$device("/cpu:0"), { model_cpu &lt;- get_model( name = model_name, input_shape = input_shape, weights = weights, metrics =(top_3_categorical_accuracy, compile = FALSE ) })</code> </pre> <br><p>   ( )       GPU,     : </p><br><pre> <code class="plaintext hljs">model &lt;- keras::multi_gpu_model(model_cpu, gpus = n_gpu) keras::compile( object = model, optimizer = keras::optimizer_adam(lr = 0.0004), loss = "categorical_crossentropy", metrics = c(top_3_categorical_accuracy) )</code> </pre> <br><p>      ,  ,   ,        GPU   . </p><br><p>      <strong>tensorboard</strong> ,            : </p><br><div class="spoiler"> <b class="spoiler_title"></b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     log_file_tmpl &lt;- file.path("logs", sprintf( "%s_%d_%dch_%s.csv", model_name, dim_size, channels, format(Sys.time(), "%Y%m%d%H%M%OS") )) #     model_file_tmpl &lt;- file.path("models", sprintf( "%s_%d_%dch_{epoch:02d}_{val_loss:.2f}.h5", model_name, dim_size, channels )) callbacks_list &lt;- list( keras::callback_csv_logger( filename = log_file_tmpl ), keras::callback_early_stopping( monitor = "val_loss", min_delta = 1e-4, patience = 8, verbose = 1, mode = "min" ), keras::callback_reduce_lr_on_plateau( monitor = "val_loss", factor = 0.5, #  lr  2  patience = 4, verbose = 1, min_delta = 1e-4, mode = "min" ), keras::callback_model_checkpoint( filepath = model_file_tmpl, monitor = "val_loss", save_best_only = FALSE, save_weights_only = FALSE, mode = "min" ) )</code> </pre> </div></div><br><h4 id="section8"> 8.   </h4><br><p>  ,    ,    : </p><br><ul><li>  <strong>keras</strong>          ( <code>lr_finder</code>   <strong>fast.ai</strong> );   ,    R  , , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> ; </li><li>    ,          GPU; </li><li>     ,    imagenet-; </li><li>  one cycle policy  discriminative learning rates (osine annealing     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">skeydan</a> ). </li></ul><br><p>       : </p><br><ul><li>           (   )  .  <strong>data.table</strong>     in-place  ,     ,                   .                  . </li><li>    R     C++    <strong>Rcpp</strong> .    <strong>RcppThread</strong>  <strong>RcppParallel</strong> ,    ,     R   . </li><li>  <strong>Rcpp</strong>      C++,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> .         <strong>xtensor</strong>   CRAN,       ,   R     C++.   â€”        ++  RStudio. </li><li> <strong>docopt</strong>      .       ,  ..  .  RStudio       ,     IDE     . </li><li>               ,      .         . </li><li> Google Cloud â€”      ,     . </li><li>        ,    R  C++,    <strong>bench</strong> â€”    . </li></ul><br><p>       ,          . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN443758/">https://habr.com/ru/post/zh-CN443758/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN443746/index.html">æ¸¸æˆå¸‚åœºï¼Œè¶‹åŠ¿å’Œé¢„æµ‹-App Annieçš„å‡ºè‰²åˆ†æ</a></li>
<li><a href="../zh-CN443748/index.html">ç‰¹æ–¯æ‹‰Model Yæ¼”ç¤ºæ–‡ç¨¿-æœŸæœ›ä»€ä¹ˆä»¥åŠåœ¨å“ªé‡Œçœ‹</a></li>
<li><a href="../zh-CN443752/index.html">Kotlinä½œä¸ºAndroidåº”ç”¨ç¨‹åºå¼€å‘çš„æœªæ¥</a></li>
<li><a href="../zh-CN443754/index.html">å…³äºSelenium WebDriverWaitçš„é€‚å½“æ€§</a></li>
<li><a href="../zh-CN443756/index.html">è¯¾å ‚è®¾è®¡ï¼šä»€ä¹ˆæ˜¯å¥½ï¼Ÿ</a></li>
<li><a href="../zh-CN443764/index.html">è®¾è®¡å¸ˆå¸çƒŸçš„ä¸œè¥¿ï¼šä¸å¯»å¸¸çš„æªæ”¯</a></li>
<li><a href="../zh-CN443766/index.html">ç«‹å³å°è¯•C ++ 20 Contractç¼–ç¨‹</a></li>
<li><a href="../zh-CN443768/index.html">ç”¨äºæ•°ç™¾ç§å®¢æˆ·ç«¯ç‰ˆæœ¬çš„Monolithï¼šæˆ‘ä»¬å¦‚ä½•ç¼–å†™å’Œæ”¯æŒæµ‹è¯•</a></li>
<li><a href="../zh-CN443770/index.html">åŸŸé©±åŠ¨è®¾è®¡ï¼šå®è·µä¸­çš„ä»·å€¼å¯¹è±¡å’Œå®ä½“æ¡†æ¶æ ¸å¿ƒ</a></li>
<li><a href="../zh-CN443772/index.html">ä¸Šå¤ï¼šIBM ThinkPad T40ï¼Œç¬¬ä¸€ä¸ªæ— çº¿è®¾å¤‡</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
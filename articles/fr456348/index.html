<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèÇ ü§ì üë©üèæ‚Äçüåæ Moteur AERODISK: Catastrophique. Partie 1 üï≥Ô∏è üöÆ üö£üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour lecteurs d'Habr! Le sujet de cet article sera la mise en ≈ìuvre de la tol√©rance aux catastrophes dans les syst√®mes de stockage AERODISK Engine....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Moteur AERODISK: Catastrophique. Partie 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/aerodisk/blog/456348/"><p><img src="https://habrastorage.org/webt/2b/54/ub/2b54ub9jta3knw6ff5eseo1buyu.jpeg"></p><br><p>  Bonjour lecteurs d'Habr!  Le sujet de cet article sera la mise en ≈ìuvre de la tol√©rance aux catastrophes dans les syst√®mes de stockage AERODISK Engine.  Initialement, nous voulions √©crire dans un article sur les deux moyens: la r√©plication et le cluster de m√©tro, mais, malheureusement, l'article s'est av√©r√© trop volumineux, nous avons donc divis√© l'article en deux parties.  Passons du simple au complexe.  Dans cet article, nous allons configurer et tester la r√©plication synchrone - supprimer un centre de donn√©es et couper √©galement le canal de communication entre les centres de donn√©es et voir ce qui se passe. </p><a name="habracut"></a><br><p>  Nos clients nous posent souvent des questions diff√©rentes sur la r√©plication.Par cons√©quent, avant de passer √† la configuration et au test de l'impl√©mentation de la r√©plique, nous vous expliquerons un peu ce qu'est la r√©plication dans les syst√®mes de stockage. </p><br><h2 id="nemnogo-teorii">  Un peu de th√©orie </h2><br><p>  La r√©plication vers le stockage est un processus continu visant √† garantir l'identit√© des donn√©es sur plusieurs syst√®mes de stockage simultan√©ment.  Techniquement, la r√©plication est effectu√©e par deux m√©thodes. </p><br><p>  <strong>La r√©plication synchrone</strong> est la copie des donn√©es du syst√®me de stockage principal vers le syst√®me de sauvegarde, suivie de la confirmation obligatoire des deux syst√®mes de stockage que les donn√©es sont enregistr√©es et confirm√©es.  C'est apr√®s confirmation des deux c√¥t√©s (sur les deux syst√®mes de stockage) que les donn√©es sont consid√©r√©es comme enregistr√©es, et vous pouvez travailler avec elles.  Cela garantit une identit√© de donn√©es garantie sur tous les syst√®mes de stockage participant √† la r√©plique. </p><br><p>  Les avantages de cette m√©thode: </p><br><ul><li>  Les donn√©es sont toujours identiques sur tous les syst√®mes de stockage. </li></ul><br><p>  Inconv√©nients: </p><br><ul><li>  Co√ªt √©lev√© de la solution (canaux de communication rapides, fibre co√ªteuse, √©metteurs-r√©cepteurs √† ondes longues, etc.) </li><li>  Restrictions de distance (dans quelques dizaines de kilom√®tres) </li><li>  Il n'y a aucune protection contre la corruption des donn√©es logiques (si les donn√©es sont corrompues (sciemment ou accidentellement) sur le syst√®me de stockage principal, alors elles seront automatiquement et imm√©diatement corrompues sur le stockage de sauvegarde, car les donn√©es sont toujours identiques (c'est un paradoxe) </li></ul><br><p>  <strong>La r√©plication asynchrone</strong> consiste √©galement √† copier des donn√©es du stockage principal vers la sauvegarde, mais avec un certain retard et sans avoir besoin de confirmer l'enregistrement de l'autre c√¥t√©.  Vous pouvez travailler avec les donn√©es imm√©diatement apr√®s l'√©criture dans le stockage principal et sur le stockage de sauvegarde, les donn√©es seront disponibles apr√®s un certain temps.  L'identit√© des donn√©es dans ce cas, bien s√ªr, n'est pas du tout fournie.  Les donn√©es sur le stockage de sauvegarde sont toujours un peu ¬´dans le pass√©¬ª. </p><br><p>  Avantages de la r√©plication asynchrone: </p><br><ul><li>  Faible co√ªt de la solution (tous les canaux de communication, optique en option) </li><li>  Aucune limite de distance </li><li>  Les donn√©es sur le stockage de sauvegarde ne sont pas corrompues si elles sont corrompues sur le principal (au moins pendant un certain temps), si les donn√©es sont corrompues, vous pouvez toujours arr√™ter la r√©plique pour √©viter la corruption des donn√©es sur le stockage de sauvegarde </li></ul><br><p>  Inconv√©nients: </p><br><ul><li>  Les donn√©es dans diff√©rents centres de donn√©es ne sont pas toujours identiques </li></ul><br><p>  Ainsi, le choix du mode de r√©plication d√©pend des t√¢ches de l'entreprise.  S'il est essentiel pour vous que le centre de donn√©es de sauvegarde ait exactement les m√™mes donn√©es que les donn√©es principales (c'est-√†-dire les exigences commerciales pour RPO = 0), vous devrez d√©bourser et accepter les limitations de la r√©plique synchrone.  Et si le retard dans l'√©tat des donn√©es est admissible ou s'il n'y a tout simplement pas d'argent, alors, vous devez certainement utiliser la m√©thode asynchrone. </p><br><p>  Nous distinguons √©galement s√©par√©ment un tel r√©gime (plus pr√©cis√©ment, d√©j√† une topologie) comme un cluster de m√©tro.  Le mode m√©trocluster utilise la r√©plication synchrone, mais, contrairement √† une r√©plique r√©guli√®re, le m√©trocluster permet aux deux syst√®mes de stockage de fonctionner en mode actif.  C'est-√†-dire  vous n'avez pas de s√©paration des centres de donn√©es en veille active.  Les applications fonctionnent simultan√©ment avec deux syst√®mes de stockage physiquement situ√©s dans diff√©rents centres de donn√©es.  Les temps d'arr√™t des accidents dans une telle topologie sont tr√®s faibles (RTO, g√©n√©ralement quelques minutes).  Dans cet article, nous ne consid√©rerons pas notre impl√©mentation du cluster de m√©tro, car il s'agit d'un sujet tr√®s vaste et vaste, nous allons donc lui consacrer un article distinct, suivant dans la suite de celui-ci. </p><br><p>  Tr√®s souvent √©galement, lorsque nous parlons de r√©plication √† l'aide de syst√®mes de stockage, beaucoup ont une question raisonnable:&gt; ¬´De nombreuses applications ont leurs propres outils de r√©plication, pourquoi utiliser la r√©plication sur les syst√®mes de stockage?  Est-ce mieux ou pire? " </p><br><p>  Il n'y a pas de r√©ponse unique, voici donc les avantages et les inconv√©nients: </p><br><p>  Arguments POUR la r√©plication du stockage: </p><br><ul><li>  La simplicit√© de la solution.  D'une mani√®re, vous pouvez r√©pliquer un tableau complet de donn√©es, quel que soit le type de chargement ou l'application.  Si vous utilisez une r√©plique d'applications, vous devrez configurer chaque application s√©par√©ment.  S'il y en a plus de 2, cela prend beaucoup de temps et co√ªte cher (la r√©plication des applications n√©cessite, en r√®gle g√©n√©rale, une licence distincte et non gratuite pour chaque application. Mais plus √† ce sujet ci-dessous). </li><li>  Vous pouvez reproduire n'importe quoi - toutes les applications, toutes les donn√©es - et elles seront toujours coh√©rentes.  De nombreuses (la plupart) des applications ne disposent pas d'installations de r√©plication et les r√©pliques du c√¥t√© stockage sont le seul moyen de fournir une protection contre les catastrophes. </li><li>  Pas besoin de surpayer pour la fonctionnalit√© de r√©plication d'application.  En r√®gle g√©n√©rale, cela co√ªte cher, tout comme les licences pour un syst√®me de stockage de r√©plique.  Mais vous ne devez payer la licence de r√©plication de stockage qu'une seule fois, et vous devez acheter la licence pour la r√©plique d'application pour chaque application s√©par√©ment.  S'il y a beaucoup de telles applications, cela co√ªte un sou et le co√ªt des licences pour la r√©plication du stockage devient une goutte d'eau. </li></ul><br><p>  Arguments CONTRE la r√©plication de stockage: </p><br><ul><li>  La r√©plique utilisant des outils d'application a plus de fonctionnalit√©s du point de vue des applications elles-m√™mes, l'application conna√Æt mieux ses donn√©es (ce qui est √©vident), il y a donc plus d'options pour travailler avec elles. </li><li>  Les fabricants de certaines applications ne garantissent pas la coh√©rence de leurs donn√©es si la r√©plication est effectu√©e par des outils tiers.  * </li></ul><br><p>  * - une th√®se controvers√©e.  Par exemple, une soci√©t√© de fabrication de SGBD bien connue a officiellement d√©clar√© pendant tr√®s longtemps que son SGBD ne peut normalement √™tre r√©pliqu√© que par ses moyens, et que le reste de la r√©plication (y compris SHD-shnaya) n'est ¬´pas vrai¬ª.  Mais la vie a montr√© que ce n'est pas le cas.  Tr√®s probablement (mais ce n'est pas exact) ce n'est tout simplement pas la tentative la plus honn√™te de vendre plus de licences aux clients. </p><br><p>  Par cons√©quent, dans la plupart des cas, la r√©plication du c√¥t√© stockage est meilleure, car  Il s'agit d'une option plus simple et moins co√ªteuse, mais il existe des cas complexes lorsque vous avez besoin de fonctionnalit√©s d'application sp√©cifiques et que vous devez travailler avec la r√©plication au niveau de l'application. </p><br><h2 id="s-teoriey-zakonchili-teper-praktika">  Avec la th√©orie termin√©e, maintenant pratique </h2><br><p>  Nous allons mettre en place une r√©plique dans notre laboratoire.  En laboratoire, nous avons √©mul√© deux centres de donn√©es (en fait, deux racks adjacents qui semblent √™tre dans des b√¢timents diff√©rents).  Le stand se compose de deux syst√®mes de stockage Engine N2, qui sont interconnect√©s par des c√¢bles optiques.  Un serveur physique ex√©cutant Windows Server 2016 utilisant Ethernet 10 Go est connect√© aux deux syst√®mes de stockage.  Le support est assez simple, mais il ne change pas l'essence. </p><br><p>  Sch√©matiquement, cela ressemble √† ceci: </p><br><p><img src="https://habrastorage.org/webt/wj/u4/rc/wju4rcak9ilbms68pnffyvsb6ly.png"></p><br><p>  La r√©plication est organis√©e de la mani√®re suivante: </p><br><p><img src="https://habrastorage.org/webt/yf/yh/dy/yfyhdy19cbj3sc0gpzp8jx6liz0.jpeg"></p><br><p>  Examinons maintenant la fonctionnalit√© de r√©plication que nous avons maintenant. <br>  Deux modes sont pris en charge: asynchrone et synchrone.  Il est logique que le mode synchrone soit limit√© par la distance et le canal de communication.  En particulier, le mode synchrone n√©cessite l'utilisation de la fibre comme physique et Ethernet 10 gigabits (ou sup√©rieur). </p><br><p>  La distance prise en charge pour la r√©plication synchrone est de 40 kilom√®tres; le retard du canal optique entre les centres de donn√©es peut aller jusqu'√† 2 millisecondes.  En g√©n√©ral, cela fonctionnera avec des retards importants, mais il y aura ensuite des freins puissants lors de l'enregistrement (ce qui est √©galement logique), donc si vous envisagez une r√©plication synchrone entre les centres de donn√©es, vous devez v√©rifier la qualit√© de l'optique et des retards. </p><br><p>  Les exigences de r√©plication asynchrone ne sont pas si graves.  Plus pr√©cis√©ment, ils ne le sont pas du tout.  Toute connexion Ethernet fonctionnelle convient. </p><br><p>  √Ä l'heure actuelle, le stockage AERODISK ENGINE prend en charge la r√©plication des p√©riph√©riques de bloc (LUN) √† l'aide du protocole Ethernet (cuivre ou optique).  Pour les projets qui n√©cessitent n√©cessairement une r√©plication via l'usine SAN Fibre Channel, nous compl√©tons maintenant la solution appropri√©e, mais jusqu'√† pr√©sent elle n'est pas pr√™te, donc dans notre cas uniquement Ethernet. </p><br><p>  La r√©plication peut fonctionner entre tous les syst√®mes de stockage de la s√©rie ENGINE (N1, N2, N4) des syst√®mes inf√©rieurs aux anciens et vice versa. </p><br><p>  La fonctionnalit√© des deux modes de r√©plication est compl√®tement identique.  Voici plus sur ce qui est: </p><br><ul><li>  R√©plication "one to one" ou "one to one", c'est-√†-dire la version classique avec deux centres de donn√©es, le principal et la sauvegarde </li><li>  La r√©plication est ¬´un √† plusieurs¬ª ou ¬´un √† plusieurs¬ª, c'est-√†-dire  un LUN peut √™tre r√©pliqu√© sur plusieurs syst√®mes de stockage √† la fois </li><li>  Activation, d√©sactivation et ¬´inversion¬ª de la r√©plication, respectivement, pour activer, d√©sactiver ou changer le sens de la r√©plication </li><li>  La r√©plication est disponible pour les pools RDG (Raid Distributed Group) et DDP (Dynamic Disk Pool).  Cependant, le LUN du pool RDG ne peut √™tre r√©pliqu√© que sur un autre RDG.  C DDP est similaire. </li></ul><br><p>  Il y a beaucoup plus de petites fonctionnalit√©s, mais les lister n'a pas beaucoup de sens, nous les mentionnerons lors de la configuration. </p><br><h2 id="nastroyka-replikacii">  Configuration de la r√©plication </h2><br><p>  Le processus de configuration est assez simple et comprend trois √©tapes. </p><br><ol><li>  Configuration du r√©seau </li><li>  Configuration du stockage </li><li>  Configuration de r√®gles (liens) et mappage </li></ol><br><p>  Un point important dans la configuration de la r√©plication est que les deux premi√®res √©tapes doivent √™tre r√©p√©t√©es sur un syst√®me de stockage distant, la troisi√®me √©tape - uniquement sur le principal. </p><br><h3 id="nastroyka-setevyh-resursov">  Configuration des ressources r√©seau </h3><br><p>  La premi√®re √©tape consiste √† configurer les ports r√©seau via lesquels le trafic de r√©plication sera transmis.  Pour ce faire, vous devez activer les ports et d√©finir des adresses IP dessus dans la section Adaptateurs frontaux. </p><br><p>  Apr√®s cela, nous devons cr√©er un pool (dans notre cas RDG) et une IP virtuelle pour la r√©plication (VIP).  VIP est une adresse IP flottante qui est li√©e √† deux adresses ¬´physiques¬ª des contr√¥leurs de stockage (les ports que nous venons de configurer).  Ce sera l'interface de r√©plication principale.  Vous pouvez √©galement fonctionner non pas avec VIP, mais avec VLAN si vous devez travailler avec du trafic balis√©. </p><br><p><img src="https://habrastorage.org/webt/di/ye/5f/diye5fvbzya3cvtebg7memcs5jo.jpeg"></p><br><p>  Le processus de cr√©ation d'un VIP pour une r√©plique n'est pas tr√®s diff√©rent de la cr√©ation d'un VIP pour les E / S (NFS, SMB, iSCSI).  Dans ce cas, nous cr√©ons un VIP (sans VLAN), mais assurez-vous d'indiquer que c'est pour la r√©plication (sans ce pointeur, nous ne pourrons pas ajouter VIP √† la r√®gle √† l'√©tape suivante). </p><br><p><img src="https://habrastorage.org/webt/nd/i9/2d/ndi92dbmjvxuqjidju802r-vl7s.png"></p><br><p>  VIP doit √™tre sur le m√™me sous-r√©seau que les ports IP entre lesquels il ¬´flotte¬ª. </p><br><p><img src="https://habrastorage.org/webt/vm/no/9m/vmno9ms_uas_guk28o1etun7kg4.png"></p><br><p>  Nous r√©p√©tons ces param√®tres sur le syst√®me de stockage distant, avec un autre IP-shnik, par lui-m√™me. <br>  Les VIP de diff√©rents syst√®mes de stockage peuvent √™tre dans diff√©rents sous-r√©seaux, l'essentiel est qu'il doit y avoir un routage entre eux.  Dans notre cas, cet exemple vient d'√™tre montr√© (192.168.3.XX et 192.168.2.XX) </p><br><p><img src="https://habrastorage.org/webt/w5/r6/re/w5r6rexidxqry4rnfdrvgp5gzcq.jpeg"></p><br><p>  Sur ce point, la pr√©paration de la partie r√©seau est termin√©e. </p><br><h3 id="nastraivaem-hranilischa">  Configurer le stockage </h3><br><p>  La configuration du stockage pour une r√©plique diff√®re de celle habituelle uniquement en ce que nous effectuons le mappage via le menu sp√©cial ¬´Mappage de r√©plication¬ª.  Sinon, tout est le m√™me qu'avec le r√©glage habituel.  Maintenant en ordre. </p><br><p>  Dans le pool R02 pr√©c√©demment cr√©√©, vous devez cr√©er un LUN.  Cr√©ez, appelez-le LUN1. </p><br><p><img src="https://habrastorage.org/webt/tg/l8/vk/tgl8vkdsqf-4oljacfssnh2_zus.jpeg"></p><br><p>  Nous devons √©galement cr√©er le m√™me LUN sur un syst√®me de stockage distant de volume identique.  Nous cr√©ons.  Pour √©viter toute confusion, le LUN distant sera appel√© LUN1R </p><br><p><img src="https://habrastorage.org/webt/xm/kl/v4/xmklv4deigknjz1vadluit9pdds.jpeg"></p><br><p>  Si nous devions prendre un LUN qui existe d√©j√†, au moment de la configuration de la r√©plique, ce LUN productif devrait √™tre d√©mont√© de l'h√¥te, et sur le syst√®me de stockage distant, cr√©ez simplement un LUN vide de taille identique. </p><br><p>  La configuration du stockage est termin√©e, nous proc√©dons √† la cr√©ation de la r√®gle de r√©plication. </p><br><h3 id="nastroyka-pravil-replikacii-ili-replikacionnyh-svyazey">  Configurer des r√®gles de r√©plication ou des liens de r√©plication </h3><br><p>  Apr√®s avoir cr√©√© des LUN sur le stockage, qui sera le principal √† l'heure actuelle, nous configurons la r√®gle de r√©plication LUN1 sur SHD1 dans LUN1R sur SHD2. </p><br><p>  La configuration est effectu√©e dans le menu de r√©plication √† distance. </p><br><p>  Cr√©ez une r√®gle.  Pour ce faire, sp√©cifiez le destinataire de la r√©plique.  Nous sp√©cifions √©galement le nom de la connexion et le type de r√©plication (synchrone ou asynchrone). </p><br><p><img src="https://habrastorage.org/webt/xk/yu/8f/xkyu8ftgcubcwu4-ul_ux3vc7lq.jpeg"></p><br><p>  Dans le champ ¬´syst√®mes distants¬ª, ajoutez notre SHD2.  Pour ajouter, vous devez utiliser le stockage IP de gestion (MGR) et le nom du LUN distant vers lequel nous allons r√©pliquer (dans notre cas, LUN1R).  La gestion des adresses IP n'est n√©cessaire qu'au stade de l'ajout de communication; le trafic de r√©plication qui les traverse ne sera pas transmis; pour cela, le VIP pr√©c√©demment configur√© sera utilis√©. </p><br><p>  D√©j√† √† ce stade, nous pouvons ajouter plusieurs syst√®mes distants pour la topologie ¬´un √† plusieurs¬ª: cliquez sur le bouton ¬´ajouter un n≈ìud¬ª, comme dans la figure ci-dessous. </p><br><p><img src="https://habrastorage.org/webt/rv/xb/bh/rvxbbh4umovgds3gduoaxg3tfc8.jpeg"></p><br><p>  Dans notre cas, le syst√®me distant en est un, nous sommes donc limit√©s √† cela. </p><br><p>  La r√®gle est pr√™te.  Notez qu'il est automatiquement ajout√© √† tous les participants √† la r√©plication (dans notre cas, il y en a deux).  Vous pouvez cr√©er autant de r√®gles que vous le souhaitez, pour n'importe quel nombre de LUN et dans n'importe quelle direction.  Par exemple, pour √©quilibrer la charge, nous pouvons r√©pliquer une partie des LUN de SHD1 √† SHD2, et l'autre partie, au contraire, de SHD2 √† SHD1. </p><br><p>  SHD1.  Imm√©diatement apr√®s la cr√©ation, la synchronisation a commenc√©. </p><br><p><img src="https://habrastorage.org/webt/y7/v8/gg/y7v8gg7bboqpit0zrow87pgvi5y.jpeg"></p><br><p>  SHD2.  Nous voyons la m√™me r√®gle, mais la synchronisation est d√©j√† termin√©e. </p><br><p><img src="https://habrastorage.org/webt/tb/dl/0k/tbdl0k_anxtcwmecg31bk0s7fmo.jpeg"></p><br><p>  LUN1 sur SHD1 a le r√¥le de principal, c'est-√†-dire qu'il est actif.  LUN1R sur SHD2 a le r√¥le de secondaire, c'est-√†-dire qu'il est en attente, en cas de d√©faillance de SHD1. <br>  Nous pouvons maintenant connecter notre LUN √† l'h√¥te. </p><br><p>  Nous ferons la connexion via iSCSI, bien que cela puisse √™tre fait via FC.  La configuration du mappage pour iSCSI LUN dans une r√©plique n'est pratiquement pas diff√©rente du sc√©nario habituel, nous n'en discuterons donc pas en d√©tail ici.  Si quelque chose, ce processus est d√©crit dans l'article de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">configuration rapide</a> . </p><br><p>  La seule diff√©rence est que nous cr√©ons un mappage dans le menu "Mappage de r√©plication". </p><br><p><img src="https://habrastorage.org/webt/xn/uy/p9/xnuyp9dccwbpg93ahvefmhifmdq.jpeg"></p><br><p>  Configurez le mappage, donnez le LUN √† l'h√¥te.  L'h√¥te a vu un LUN. </p><br><p><img src="https://habrastorage.org/webt/qg/y3/vm/qgy3vmfark_2-pvl8liqtozb2iu.jpeg"></p><br><p>  Formatez-le dans le syst√®me de fichiers local. </p><br><p><img src="https://habrastorage.org/webt/zd/8l/qg/zd8lqglmv194u9-zsctatxrsuzk.jpeg"></p><br><p>  Voil√†, la configuration est termin√©e.  Suivront les tests. </p><br><h2 id="testirovanie">  Test </h2><br><p>  Nous allons tester trois sc√©narios principaux. </p><br><ol><li>  Le personnel change de r√¥le Secondaire&gt; Primaire.  Un changement de r√¥le r√©gulier est n√©cessaire dans le cas, par exemple, o√π nous avons principalement besoin d'un centre de donn√©es pour effectuer certaines op√©rations pr√©ventives, et pendant ce temps, afin que les donn√©es soient disponibles, nous transf√©rons la charge vers le centre de donn√©es de sauvegarde. </li><li>  Basculement des r√¥les Secondaire&gt; Primaire (d√©faillance du centre de donn√©es).  Il s'agit du sc√©nario principal pour lequel il existe une r√©plication, ce qui peut aider √† survivre √† une d√©faillance compl√®te du centre de donn√©es sans arr√™ter l'entreprise pendant longtemps. </li><li>  Canaux de communication rompus entre les centres de donn√©es.  V√©rifier le bon comportement des deux syst√®mes de stockage dans des conditions o√π, pour une raison quelconque, le canal de communication entre les centres de donn√©es n'est pas disponible (par exemple, l'excavatrice a creus√© au mauvais endroit et a d√©chir√© l'optique sombre). </li></ol><br><p>  Pour commencer, nous allons commencer √† √©crire des donn√©es sur notre LUN (nous √©crivons des fichiers avec des donn√©es al√©atoires).  Nous constatons imm√©diatement que le canal de communication entre les syst√®mes de stockage est utilis√©.  Ceci est facile √† comprendre si vous ouvrez la surveillance de la charge des ports qui sont responsables de la r√©plication. </p><br><p><img src="https://habrastorage.org/webt/s7/99/bt/s799bttjt3v6q24uhvxoywfrwne.jpeg"></p><br><p>  Sur les deux syst√®mes de stockage, il existe d√©sormais des donn√©es ¬´utiles¬ª, nous pouvons commencer le test. </p><br><p><img src="https://habrastorage.org/webt/r3/vs/dv/r3vsdvpsp9avchablad41pxrfdu.jpeg"></p><br><p>  Juste au cas o√π, regardons les sommes de hachage de l'un des fichiers et notons-le. </p><br><p><img src="https://habrastorage.org/webt/e1/zi/st/e1zistvzwlkimqbupxjtgnltc9o.jpeg"></p><br><h3 id="shtatnoe-pereklyuchenie-roley">  Changement de r√¥le du personnel </h3><br><p>  L'op√©ration de changement de r√¥le (changement de direction de la r√©plication) peut √™tre effectu√©e √† partir de n'importe quel syst√®me de stockage, mais vous devez toujours aller aux deux, car vous devrez d√©sactiver le mappage sur le primaire et l'activer sur le secondaire (qui deviendra principal). </p><br><p>  Peut-√™tre que maintenant une question raisonnable se pose: pourquoi ne pas automatiser cela?  Nous r√©pondons: tout est simple, la r√©plication est un simple outil de tol√©rance aux catastrophes bas√© uniquement sur des op√©rations manuelles.  Pour automatiser ces op√©rations, il existe un mode cluster m√©tropolitain, il est enti√®rement automatis√©, mais sa configuration est beaucoup plus compliqu√©e.  Nous √©crirons sur la configuration du cluster de m√©tro dans le prochain article. </p><br><p>  D√©sactivez le mappage sur le stockage principal pour vous assurer que l'enregistrement est arr√™t√©. </p><br><p><img src="https://habrastorage.org/webt/jk/j4/1l/jkj41ltsncz2hmqoclkrecqvguy.jpeg"></p><br><p>  Ensuite, sur l'un des syst√®mes de stockage (peu importe, sur le serveur principal ou de sauvegarde) dans le menu de r√©plication √† distance, s√©lectionnez notre connexion REPL1 et cliquez sur ¬´Changer de r√¥le¬ª. </p><br><p><img src="https://habrastorage.org/webt/dc/bb/8t/dcbb8tv24xxhofmg_avtodfelas.jpeg"></p><br><p>  Apr√®s quelques secondes, LUN1R (stockage de sauvegarde) devient principal. </p><br><p><img src="https://habrastorage.org/webt/-v/hf/l2/-vhfl2g0v20bnfnomxwupf0_9xk.jpeg"></p><br><p>  Nous faisons le mappage de LUN1R avec SHD2. </p><br><p><img src="https://habrastorage.org/webt/lh/uw/cy/lhuwcyscu0quljitysu2pkk35hg.jpeg"></p><br><p>  Apr√®s cela, notre lecteur E: s'accroche automatiquement √† l'h√¥te, mais cette fois, il a ¬´vol√©¬ª avec LUN1R. </p><br><p>  Au cas o√π, comparez les quantit√©s de hachage. </p><br><p><img src="https://habrastorage.org/webt/g6/st/qh/g6stqhn-xr0yqlw84t7y4_y5sqm.png"></p><br><p>  Identique.  Test r√©ussi. </p><br><h3 id="avariynoe-pereklyuchenie-otkaz-cod-a">  Basculement  √âchec du centre de donn√©es </h3><br><p>  √Ä l'heure actuelle, le stockage principal apr√®s commutation r√©guli√®re est SHD2 et LUN1R, respectivement.  Pour simuler un accident, nous coupons l'alimentation des deux contr√¥leurs SHD2. <br>  L'acc√®s n'est plus. </p><br><p>  Nous regardons ce qui se passe sur le stockage 1 (sauvegarde en ce moment). </p><br><p><img src="https://habrastorage.org/webt/ai/oy/jt/aioyjtl8xqmmgngtidigkvoesai.jpeg"></p><br><p>  Nous voyons que le LUN primaire (LUN1R) n'est pas disponible.  Un message d'erreur est apparu dans les journaux, dans le panneau d'informations, ainsi que dans la r√®gle de r√©plication elle-m√™me.  Par cons√©quent, les donn√©es de l'h√¥te ne sont actuellement pas disponibles. </p><br><p>  Remplacez le r√¥le de LUN1 par Primary. </p><br><p><img src="https://habrastorage.org/webt/ef/vr/wv/efvrwvemqzysnrtebprwvmqnxw8.jpeg"></p><br><p>  Cartographie des affaires avec l'h√¥te. </p><br><p><img src="https://habrastorage.org/webt/o9/es/oj/o9esojg6xcl-uv_wbbj6afkrz18.jpeg"></p><br><p>  Assurez-vous que le lecteur E appara√Æt sur l'h√¥te. </p><br><p><img src="https://habrastorage.org/webt/rg/kj/0s/rgkj0s-0rgoumtmnzk98bd-bgl4.jpeg"></p><br><p>  V√©rifiez le hachage. </p><br><p><img src="https://habrastorage.org/webt/hn/yb/yq/hnybyqjm7w_g1il4bowg1-xgq5y.jpeg"></p><br><p>  Tout va bien.  Le centre de stockage a subi une chute du centre de donn√©es, qui √©tait actif.  Le temps approximatif que nous avons consacr√© √† la connexion de l '¬´inversion¬ª de la r√©plication et √† la connexion du LUN √† partir du centre de donn√©es de sauvegarde √©tait d'environ 3 minutes.  Il est clair que dans le produit r√©el, tout est beaucoup plus compliqu√©, et en plus des actions avec les syst√®mes de stockage, vous devez effectuer beaucoup plus d'op√©rations sur le r√©seau, sur les h√¥tes, dans les applications.  Et dans la vie, cette p√©riode sera beaucoup plus longue. </p><br><p>  Ici, je veux √©crire que tout, le test s'est termin√© avec succ√®s, mais ne nous pr√©cipitons pas.  Le stockage principal "ment", on sait que lorsqu'elle "tomba", elle √©tait dans le r√¥le de Primaire.  Que se passe-t-il si elle s'allume soudainement?  Il y aura deux r√¥les principaux, ce qui √©quivaut √† la corruption de donn√©es?  Nous allons le v√©rifier maintenant. <br>  Nous allons soudain allumer le stockage sous-jacent. </p><br><p>  Il se charge pendant plusieurs minutes et redevient op√©rationnel apr√®s une courte synchronisation, mais d√©j√† dans le r√¥le de Secondaire. </p><br><p><img src="https://habrastorage.org/webt/27/hu/q6/27huq6b6guby7o-g7_xkz7quugy.jpeg"></p><br><p>  Tout va bien.  Le cerveau divis√© ne s'est pas produit.  Nous avons pens√© √† cela, et toujours apr√®s la chute du syst√®me de stockage monte dans le r√¥le de secondaire, quel que soit son r√¥le "dans la vie".  Maintenant, nous pouvons affirmer avec certitude que le test de d√©faillance du centre de donn√©es a r√©ussi. </p><br><h3 id="otkaz-kanalov-svyazi-mezhdu-cod-ami">  D√©faillance des canaux de communication entre les centres de donn√©es </h3><br><p>  La t√¢che principale de ce test est de s'assurer que le syst√®me de stockage ne commencera pas √† paniquer s'il a temporairement perdu les canaux de communication entre les deux syst√®mes de stockage et qu'il r√©appara√Æt ensuite. <br>  Alors.  Nous d√©connectons les fils entre les syst√®mes de stockage (imaginez qu'une excavatrice les a creus√©s). </p><br><p>  Sur le primaire, nous voyons qu'il n'y a aucun lien avec le secondaire. </p><br><p><img src="https://habrastorage.org/webt/yh/nf/ar/yhnfarhppjrnbaxotu4ds4szz5c.jpeg"></p><br><p>  Au secondaire, nous voyons qu'il n'y a aucun lien avec le primaire. </p><br><p><img src="https://habrastorage.org/webt/f4/k9/7h/f4k97hzr11uh3cytxpsjlq2anly.jpeg"></p><br><p>  Tout fonctionne bien, et nous continuons d'√©crire des donn√©es sur le syst√®me de stockage principal, c'est-√†-dire qu'elles sont d√©j√† garanties de diff√©rer du syst√®me de sauvegarde, c'est-√†-dire qu'elles sont ¬´parties¬ª. </p><br><p>  Dans quelques minutes, nous r√©parons le canal de communication.  D√®s que les syst√®mes de stockage se sont vus, la synchronisation des donn√©es est automatiquement activ√©e.  Il n'y a rien requis de l'administrateur. </p><br><p><img src="https://habrastorage.org/webt/wo/os/yy/woosyydo-vvbauzsd7lgu4qwfos.jpeg"></p><br><p>  Apr√®s un certain temps, la synchronisation se termine. </p><br><p><img src="https://habrastorage.org/webt/up/ne/es/upneeslicidwf8manqfmlvcaohu.jpeg"></p><br><p>  La connexion a √©t√© r√©tablie, la panne des canaux de communication n'a provoqu√© aucune situation d'urgence et apr√®s la mise en marche, la synchronisation a eu lieu automatiquement. </p><br><h2 id="vyvody">  Conclusions </h2><br><p>  Nous avons analys√© la th√©orie - ce qui est n√©cessaire et pourquoi, o√π sont les avantages et les inconv√©nients.  Nous avons ensuite mis en place une r√©plication synchrone entre les deux syst√®mes de stockage. </p><br><p>  Ensuite, les principaux tests ont √©t√© effectu√©s pour la commutation r√©guli√®re, la d√©faillance du centre de donn√©es et une rupture des canaux de communication.  Dans tous les cas, SHD a bien fonctionn√©.   ,        . </p><br><p>                   active-active,       ,       . </p><br><p>   ,       . </p><br><p>   . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr456348/">https://habr.com/ru/post/fr456348/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr456338/index.html">13 lignes simples JavaScript utiles</a></li>
<li><a href="../fr456340/index.html">Une histoire sur la fa√ßon dont une √©quipe de pigistes √©crit des applications JavaScript √† pile compl√®te</a></li>
<li><a href="../fr456342/index.html">Une langue pour tout gouverner</a></li>
<li><a href="../fr456344/index.html">Pourquoi ['1', '7', '11']. Map (parseInt) renvoie [1, NaN, 3] en Javascript?</a></li>
<li><a href="../fr456346/index.html">Feuille de route interactive pour les apprenants en d√©veloppement Web</a></li>
<li><a href="../fr456350/index.html">√âv√©nements num√©riques √† Moscou du 17 au 23 juin</a></li>
<li><a href="../fr456352/index.html">Module de communication d'objets sans fil WISE-4000</a></li>
<li><a href="../fr456354/index.html">Comment collectons-nous les t√©l√©viseurs</a></li>
<li><a href="../fr456358/index.html">Les 13 articles les plus tristement c√©l√®bres de l'ann√©e √©coul√©e</a></li>
<li><a href="../fr456362/index.html">Designer de niveau 6: comment nous motivons et d√©veloppons les designers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
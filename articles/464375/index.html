<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèª üßòüèæ üíÉüèº C√≥mo funcionan los motores de b√∫squeda üèÇüèæ üïØÔ∏è üôèüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Resolvimos las viejas cartas y encontramos un art√≠culo escrito por Ilya Segalovich iseg para la revista "World of Internet" en 2002. En √©l, compara In...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo funcionan los motores de b√∫squeda</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/464375/">  <i>Resolvimos las viejas cartas y encontramos un art√≠culo escrito por Ilya Segalovich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">iseg</a> para la revista "World of Internet" en 2002.</i>  <i>En √©l, compara Internet y los motores de b√∫squeda con las maravillas del mundo, reflexiona sobre las tecnolog√≠as de b√∫squeda y recuerda su historia.</i>  <i>A pesar de la carga de trabajo, Ilya escribi√≥ un art√≠culo en tiempo r√©cord e incluso proporcion√≥ un glosario de t√©rminos suficientemente detallado, que es especialmente interesante de leer hoy.</i>  <i>No pudimos encontrar una versi√≥n electr√≥nica de la revista con el art√≠culo, as√≠ que hoy la publicamos en nuestro blog, cuyo primer autor, por cierto, fue Ilya.</i> <br><br><img src="https://habrastorage.org/webt/a4/5i/mg/a45imgha_o5s5nye3vil9lydf28.jpeg"><br><br><a name="habracut"></a>  Se <i>han</i> escrito cientos de <i>motores</i> de <i>b√∫squeda</i> en el mundo, y si cuenta las funciones de b√∫squeda implementadas en una variedad de programas, entonces necesita realizar un seguimiento de miles.  Y no importa c√≥mo se implemente el proceso de b√∫squeda, no importa en qu√© modelo matem√°tico se base, las ideas y los programas que implementan la b√∫squeda son bastante simples.  Aunque esta simplicidad, aparentemente, pertenece a la categor√≠a de la que dicen "simple pero funciona".  De una forma u otra, pero fueron los motores de b√∫squeda los que se convirtieron en una de las dos nuevas maravillas del mundo, dando al Homo Sapiens acceso ilimitado e instant√°neo a la informaci√≥n.  El primer milagro, obviamente, puede considerarse Internet como tal, con sus capacidades de comunicaci√≥n universal. <br><br><h3>  Motores de b√∫squeda hist√≥ricos </h3><br>  Existe una creencia generalizada de que cada nueva generaci√≥n de programas es m√°s perfecta que la anterior.  Digamos, antes todo era imperfecto, pero ahora reina <i>inteligencia</i> casi <i>artificial en</i> todas partes.  Otro punto de vista extremo es que "todo lo nuevo se olvida de lo viejo".  Creo que con respecto a los motores de b√∫squeda, la verdad se encuentra en alg√∫n punto intermedio. <br><br>  Pero, ¬øqu√© ha cambiado realmente en los √∫ltimos a√±os?  No algoritmos o estructuras de datos, no modelos matem√°ticos.  Aunque ellos tambi√©n.  El paradigma del uso de sistemas ha cambiado.  En pocas palabras, una ama de casa que busca una plancha m√°s barata y un graduado de un internado auxiliar con la esperanza de encontrar un mec√°nico de autom√≥viles se enganch√≥ en la pantalla con la l√≠nea de b√∫squeda.  Adem√°s de la aparici√≥n de un factor imposible en la era previa a Internet, un factor de la demanda total de motores de b√∫squeda, se hicieron evidentes un par de cambios m√°s.  En primer lugar, qued√≥ claro que las personas no solo "piensan con palabras", sino que tambi√©n "buscan palabras".  En la respuesta del sistema, esperan ver la palabra escrita en la cadena de consulta.  Y el segundo: es dif√≠cil "volver a entrenar a un buscador" para "volver a entrenar para buscar", as√≠ como es dif√≠cil volver a entrenar para hablar o escribir.  Los sue√±os de los a√±os 60 y 80 sobre el refinamiento iterativo de las consultas, sobre la comprensi√≥n del lenguaje natural, sobre la b√∫squeda por significado, sobre la generaci√≥n de una respuesta coherente a una pregunta dif√≠cilmente pueden resistir la cruel prueba de la realidad ahora. <br><br><h3>  Algoritmo + Estructura de datos = Motor de b√∫squeda </h3><br>  Como cualquier programa, el motor de b√∫squeda opera con estructuras de datos y ejecuta un algoritmo.  La variedad de algoritmos no es muy grande, pero lo es.  Adem√°s de las computadoras cu√°nticas, que nos prometen un avance m√°gico en la "complejidad algor√≠tmica" de la b√∫squeda, y sobre las cuales el autor no sabe casi nada, existen cuatro clases de algoritmos de b√∫squeda.  Tres de cada cuatro algoritmos requieren "indexaci√≥n", preprocesamiento de documentos, lo que crea un archivo auxiliar, en otras palabras, un "√≠ndice", dise√±ado para simplificar y acelerar la b√∫squeda.  Estos son algoritmos de <i>archivos invertidos, √°rboles de sufijos, firmas</i> .  En un caso degenerado, no hay un paso de indexaci√≥n preliminar, y la b√∫squeda se realiza visualizando documentos secuencialmente.  Tal b√∫squeda se llama <i>directa</i> . <br><br><h3>  B√∫squeda directa </h3><br>  Su versi√≥n m√°s simple es familiar para muchos, y no hay programador que no escriba ese c√≥digo al menos una vez en su vida: <br><div class="scrollable-table"><table><tbody><tr><td width="310"><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">char</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">strstr</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">char</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *big,         </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">char</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *little)</span></span></span><span class="hljs-function"> </span></span>{     <span class="hljs-keyword"><span class="hljs-keyword">char</span></span> *x, *y, *z;     <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (x = big; *x; x++) {         <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (y = little, z = x;                 *y; ++y, ++z)         {             <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*y != *z)                 <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>;         }         <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!*y)             <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x;     }     <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span>; }</code> </pre> </td><td> <code>  . <br>     C   big        x       little.  ,     y  z,    .        ,   !</code> </td> </tr></tbody></table></div>  A pesar de su aparente simplicidad, la b√∫squeda directa se ha desarrollado intensamente en los √∫ltimos 30 a√±os.  Se ha presentado una cantidad considerable de ideas que a veces reducen el tiempo de b√∫squeda.  Estos algoritmos se describen en detalle en una variedad de literatura, existen sus res√∫menes y comparaciones.  Se pueden encontrar buenas revisiones de los m√©todos de b√∫squeda directa en libros de texto como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Sedgwick</a> o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cormen</a> .  Debe tenerse en cuenta que los nuevos algoritmos y sus opciones mejoradas aparecen constantemente. <br><br>  Aunque mirar todos los textos directamente es una tarea bastante lenta, no debe pensar que los algoritmos de b√∫squeda directa no se usan en Internet.  El motor de b√∫squeda noruego Fast (www.fastsearch.com) utiliz√≥ un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">chip</a> que implementa la l√≥gica de b√∫squeda directa de expresiones regulares simplificadas, y coloc√≥ 256 de estos chips en un tablero.  Esto permiti√≥ a Fast atender una cantidad bastante grande de solicitudes por unidad de tiempo. <br><br>  Adem√°s, hay muchos programas que combinan la b√∫squeda de √≠ndice para encontrar un bloque de texto con una b√∫squeda directa adicional dentro del bloque.  Por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">vislumbrar es</a> muy popular, incluso en Runet. <br><br>  En general, los algoritmos directos tienen fundamentalmente caracter√≠sticas distintivas de ganar-ganar.  Por ejemplo, posibilidades ilimitadas para b√∫squeda aproximada y difusa.  De hecho, cualquier indexaci√≥n siempre est√° asociada con la simplificaci√≥n y normalizaci√≥n de los t√©rminos y, en consecuencia, con la p√©rdida de informaci√≥n.  La b√∫squeda directa funciona directamente en los documentos originales sin ninguna distorsi√≥n. <br><br><h3>  Archivo invertido </h3><br>  Esta estructura de datos simple, a pesar de su misterioso nombre extranjero, es intuitivamente familiar para cualquier persona alfabetizada y cualquier programador de bases de datos que ni siquiera se haya ocupado de la b√∫squeda de texto completo.  La primera categor√≠a de personas sabe lo que es, de acuerdo con las "concordancias": listas exhaustivas ordenadas alfab√©ticamente de palabras de un texto o pertenecientes a un autor (por ejemplo, "Concordancia con versos de A. S. Pushkin", "Diccionario-Concordancia de periodismo por F. M. Dostoievski" )  Los √∫ltimos tratan con una forma u otra de la lista invertida cada vez que crean o usan el "√≠ndice de base de datos por campo clave". <br><br>  Ilustraremos esta estructura con la ayuda de la maravillosa concordancia rusa: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Sinfon√≠a"</a> , emitida por el Patriarcado de Mosc√∫ sobre el texto de la traducci√≥n sinodal de la Biblia. <br><br><img src="https://habrastorage.org/webt/um/z7/zn/umz7znedr_ubbqvcxyupo1lk8t4.png"><br><br>  Esta es una lista alfab√©tica de palabras.  Para cada palabra, se enumeran todas las "posiciones" en las que aparece esta palabra.  El algoritmo de b√∫squeda consiste en encontrar la palabra correcta y cargar en la memoria una lista de posiciones ya expandida. <br><br>  Para ahorrar espacio en el disco y acelerar la b√∫squeda, generalmente recurra a dos trucos.  En primer lugar, puede guardar los detalles de la posici√≥n en s√≠.  De hecho, cuanto m√°s detallada sea dicha posici√≥n, por ejemplo, en el caso de "Symphony" es "libro + cap√≠tulo + verso", se necesitar√° m√°s espacio para almacenar el archivo invertido. <br><br>  En la versi√≥n m√°s detallada, en el archivo invertido puede almacenar el n√∫mero de palabra y el desplazamiento en bytes desde el comienzo del texto, y el color y el tama√±o de la fuente, y mucho m√°s.  M√°s a menudo, simplemente indican solo el n√∫mero del documento, digamos, un libro de la Biblia, y el n√∫mero de usos de esta palabra en √©l.  Es una estructura tan simplificada que se considera fundamental en la teor√≠a cl√°sica de recuperaci√≥n de informaci√≥n: recuperaci√≥n de informaci√≥n (IR). <br><br>  El segundo m√©todo de compresi√≥n (no relacionado con el primero): organizar las posiciones para cada palabra en orden ascendente de direcciones y para que cada posici√≥n almacene no su direcci√≥n completa, sino la diferencia de la anterior.  As√≠ es como se ver√° esta lista para nuestra p√°gina bajo el supuesto de que recordamos la posici√≥n hasta el n√∫mero del cap√≠tulo: <br><br> <code>: [.1],[+11],[0],[+2],[+4],[+2],[+4],..</code> <br> <br>  Adem√°s, se impone un m√©todo de empaque simple sobre el m√©todo de diferencia de almacenamiento de direcciones: por qu√© asignar un n√∫mero "enorme" fijo de bytes a un entero peque√±o, porque puede asignarle casi tantos bytes como se merece.  Aqu√≠ es apropiado mencionar los c√≥digos de Golomb o la funci√≥n incorporada del popular lenguaje Perl: <code>pack(‚Äúw‚Äù)</code> . <br><br>  En la literatura, tambi√©n hay una artiller√≠a m√°s pesada de algoritmos de empaquetado de la gama m√°s amplia: aritm√©tica, Huffman, LZW, etc. El progreso en esta √°rea es continuo.  En la pr√°ctica, rara vez se usan en los motores de b√∫squeda: la ganancia es peque√±a y la potencia del procesador se gasta de manera ineficiente. <br><br>  Como resultado de todos los trucos descritos, el tama√±o del archivo invertido, como regla, es del 7 al 30 por ciento del tama√±o del texto fuente, dependiendo de los detalles de direccionamiento. <br><br><h3>  Listado en el Libro Rojo </h3><br>  Se proponen repetidamente otros algoritmos de b√∫squeda invertidos y directos y estructuras de datos.  En primer lugar, estos son √°rboles de sufijos (ver libros de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Manber</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gonnet</a> ), as√≠ como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">firmas</a> . <br><br>  El primero de ellos funcion√≥ en Internet, siendo un algoritmo patentado del sistema de b√∫squeda <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OpenText</a> .  Me he encontrado con √≠ndices de sufijos en los motores de b√∫squeda nacionales. <br><br>  El segundo, el m√©todo de firma, es una conversi√≥n de documentos para bloquear tablas de los <i>valores hash de</i> sus palabras: la "firma" y la visualizaci√≥n secuencial de las "firmas" durante la b√∫squeda. <br><br>  Ninguno de los m√©todos fue ampliamente adoptado y, por lo tanto, no merec√≠a una discusi√≥n detallada en este breve art√≠culo. <br><br><h3>  Modelos matem√°ticos </h3><br>  Aproximadamente 3 de cada 5 motores de b√∫squeda y m√≥dulos funcionan sin ning√∫n modelo matem√°tico.  M√°s precisamente, sus desarrolladores no se asignan la tarea de implementar un modelo abstracto y / o desconocen su existencia.  El principio aqu√≠ es simple: si solo el programa encuentra algo.  Como sea  Y luego el usuario lo resolver√°. <br><br>  Sin embargo, tan pronto como se trata de mejorar la calidad de la b√∫squeda, sobre una gran cantidad de informaci√≥n, sobre el flujo de consultas de los usuarios, adem√°s de los coeficientes fijados emp√≠ricamente, resulta √∫til operar con alg√∫n tipo de aparato te√≥rico simple.  <i>El modelo de b√∫squeda</i> es una cierta simplificaci√≥n de la realidad, sobre la base de la cual se obtiene una f√≥rmula (que ya no es necesaria para nadie), que permite al programa tomar una decisi√≥n: qu√© documento debe considerarse encontrado y c√≥mo clasificarlo.  Despu√©s de la adopci√≥n del modelo, los coeficientes a menudo adquieren un significado f√≠sico y se vuelven m√°s comprensibles para el propio desarrollador, y se vuelve m√°s interesante seleccionarlos. <br><br>  La variedad completa de modelos de recuperaci√≥n de informaci√≥n tradicional (IR) generalmente se divide en tres tipos: conjunto-te√≥rico (booleano, conjuntos difusos, extendido booleano), <abbr title="En la literatura nacional, los modelos algebraicos a menudo se denominan lineales.">algebraico</abbr> (vector, vector generalizado, sem√°ntico latente, red neuronal) y probabil√≠stico. <br><br>  La familia booleana de modelos, de hecho, es la primera que viene a la mente de un programador que implementa la b√∫squeda de texto completo.  Hay una palabra: un documento se considera encontrado, no, no encontrado.  En realidad, el modelo booleano cl√°sico es un puente que conecta la teor√≠a de recuperaci√≥n de informaci√≥n con la teor√≠a de b√∫squeda y manipulaci√≥n de datos. <br><br>  La cr√≠tica al modelo booleano, bastante justa, consiste en su extrema rigidez e inadecuaci√≥n para la clasificaci√≥n.  Por lo tanto, en 1957, Joyce y Needham (Joyce y Needham) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sugirieron</a> tener en cuenta las caracter√≠sticas de frecuencia de las palabras para que "... la operaci√≥n de comparaci√≥n ser√≠a la relaci√≥n de la distancia entre los vectores ...".  <i>El modelo vectorial</i> fue implementado con √©xito en 1968 por el padre fundador de la ciencia de la recuperaci√≥n de informaci√≥n Gerard Salton (Gerard Salton) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">*</a> en el motor de b√∫squeda SMART (Salton's Magical Automatic Retriever of Text).  La clasificaci√≥n en este modelo se basa en una observaci√≥n estad√≠stica natural de que cuanto mayor es la frecuencia local de un t√©rmino en un documento (TF) y m√°s "raro" (es decir, la <i>aparici√≥n de retorno en los documentos</i> ) de un t√©rmino en una colecci√≥n (IDF), mayor es el peso de este documento en relaci√≥n con el t√©rmino . <br><br><hr><a name="salton"></a>  <sup>* Gerard Salton (Sahlman) 1927-1995.</sup>  <sup>√âl es Selton, √©l es Zalton e incluso Zalman, √©l es Gerard, Gerard, Gerard o incluso Gerald, dependiendo del gusto del traductor y los errores tipogr√°ficos realizados.</sup> <sup><br></sup>  <sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://www.cs.cornell.edu/Info/Department/Annual95/Faculty/Salton.html</a></sup> <sup><br></sup>  <sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20040128014253/">http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salton:Gerald.html</a></sup> <sup><br></sup>  <sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20011117024624/">http://www.cs.virginia.edu/~clv2m/salton.txt</a></sup> <sup><br></sup> <br>  La designaci√≥n IDF fue introducida por Karen Sparck-Jones (Karen Spark-Jones) en 1972 en un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo</a> sobre el <i>t√©rmino especificidad</i> .  De ahora en adelante, la designaci√≥n TF * IDF se usa ampliamente como sin√≥nimo del modelo vectorial. <br><br>  Finalmente, en 1977, Robertson y Sparck-Jones ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Robertson</a> y Spark-Jones) corroboraron e implementaron un <i>modelo probabil√≠stico</i> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">propuesto</a> en 1960), que tambi√©n sent√≥ las bases para toda una familia.  <i>La relevancia</i> en este modelo se considera como la probabilidad de que este documento pueda ser de inter√©s para el usuario.  Esto implica la presencia de un conjunto inicial ya existente de documentos relevantes seleccionados por el usuario o recibidos autom√°ticamente bajo un supuesto simplificado.  La probabilidad de ser relevante para cada documento posterior se calcula en funci√≥n de la relaci√≥n entre la aparici√≥n de t√©rminos en el conjunto relevante y el resto de la parte "irrelevante" de la colecci√≥n.  Aunque los modelos probabil√≠sticos tienen alguna ventaja te√≥rica, porque organizan los documentos en orden descendente de "probabilidad de ser relevante", en la pr√°ctica no han recibido mucha distribuci√≥n. <br><br>  No voy a entrar en detalles y escribir f√≥rmulas voluminosas para cada modelo.  Su resumen, junto con la discusi√≥n, toma 35 p√°ginas en forma comprimida en el libro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"B√∫squeda de informaci√≥n moderna"</a> .  Solo es importante tener en cuenta que en cada una de las familias el modelo m√°s simple parte de la suposici√≥n de las palabras independencia y tiene una condici√≥n de filtrado simple: nunca se encuentran documentos que no contengan palabras de consulta.  Los modelos avanzados ("alternativos") de cada una de las familias no consideran la palabra de consulta como independiente, pero, adem√°s, le permiten encontrar documentos que no contienen una sola palabra de la consulta. <br><br><h3>  Buscar "por sentido" </h3><br>  La capacidad de encontrar y clasificar documentos que no contienen palabras de la consulta a menudo se considera un signo de inteligencia artificial o una b√∫squeda por significado y a priori se relacionan con las ventajas del modelo.  La cuesti√≥n de si esto es as√≠ o no, lo dejaremos fuera del alcance de este art√≠culo. <br><br>  Por ejemplo, describir√© solo uno, quiz√°s el modelo m√°s popular que funciona por significado.  En la teor√≠a de la recuperaci√≥n de informaci√≥n, este modelo se llama <i>indexaci√≥n sem√°ntica latente</i> (en otras palabras, revela significados ocultos).  Este modelo algebraico se basa en la descomposici√≥n singular de una matriz rectangular que asocia palabras con documentos.  El elemento de la matriz es una respuesta de frecuencia, que refleja el grado de conexi√≥n de la palabra y el documento, por ejemplo, TF * IDF.  En lugar de la matriz original de la millon√©sima dimensi√≥n, los autores del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√©todo de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Furnas</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deerwester</a> sugirieron utilizar <abbr title="Para grandes colecciones, el n√∫mero de &quot;significados&quot; se incrementa a 300.">50-150</abbr> "significados ocultos" correspondientes a los primeros <i>componentes principales de su descomposici√≥n singular</i> . <br><br><blockquote>  <u>Una descomposici√≥n singular de una</u> matriz real A de tama√±os m * n se llama cualquier descomposici√≥n de la forma A = USV, donde U es la matriz ortogonal de tama√±os m * m, V es la matriz ortogonal de tama√±os n * n, S es la matriz diagonal de tama√±os m * n, cuyos elementos <i>s <sub>ij</sub></i> = 0 si <i>i</i> no <i>es</i> igual a <i>j</i> , y <i>s <sub>ii</sub> = s <sub>i</sub></i> &gt; = 0. Las cantidades si se llaman n√∫meros singulares de la matriz y son iguales a los valores aritm√©ticos de las ra√≠ces cuadradas de los valores propios correspondientes de la matriz AA <sup>T.</sup>  En la literatura inglesa, la descomposici√≥n singular se denomina com√∫nmente <u>descomposici√≥n SVD</u> . </blockquote><br>  Se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">demostr√≥ hace</a> mucho tiempo que si dejamos en consideraci√≥n los primeros k n√∫meros singulares (igualamos el resto a cero), obtenemos la aproximaci√≥n m√°s cercana posible de la matriz inicial de rango k (en cierto sentido, su "interpretaci√≥n sem√°ntica m√°s cercana de rango k").  Al disminuir el rango, filtramos los detalles irrelevantes;  aumentando, tratamos de reflejar todos los matices de la estructura de los datos reales. <br><br>  Las operaciones de b√∫squeda o b√∫squeda de <i>documentos similares se</i> simplifican enormemente, ya que cada palabra y cada documento est√° asociado con un vector relativamente corto de k significados (filas y columnas de las matrices correspondientes).  Sin embargo, debido al bajo significado de los "significados", o <abbr title="Despu√©s de nuestros experimentos con LSI, result√≥ que &quot;significa n√∫mero 1&quot; en Runet - todos los documentos en ingl√©s, &quot;significa n√∫mero 3&quot; - todos los foros, etc.">por alguna otra</abbr> raz√≥n, el uso de LSI en la frente para la b√∫squeda no ha ganado distribuci√≥n.  Aunque para fines auxiliares (filtrado autom√°tico, clasificaci√≥n, separaci√≥n de colecciones, reducci√≥n preliminar de dimensiones para otros modelos), este m√©todo parece encontrar aplicaci√≥n. <br><br><h3>  Evaluaci√≥n de calidad </h3><blockquote>  La verificaci√≥n de consistencia ha demostrado que la superposici√≥n de documentos relevantes entre dos evaluadores es del orden del 40% en promedio ... recuperaci√≥n y precisi√≥n del evaluador cruzado de alrededor del 65% ... Esto implica un l√≠mite superior pr√°ctico en el rendimiento del sistema de recuperaci√≥n del 65% ... <br>  <b>Donna harman</b> <br>  <b>Lo que hemos aprendido y no aprendido de TREC</b> <br><br><div class="spoiler">  <b class="spoiler_title">Traducci√≥n</b> <div class="spoiler_text">  "... un control de estabilidad mostr√≥ que la superposici√≥n de documentos relevantes entre dos evaluadores es aproximadamente del 40% en promedio ... la precisi√≥n y la integridad medida entre los evaluadores es de aproximadamente el 65% ... Esto impone un l√≠mite superior pr√°ctico en la calidad de la b√∫squeda en la regi√≥n del 65% ..." <br></div></div></blockquote><br>  Cualquiera sea el modelo, el motor de b√∫squeda necesita "ajuste", una evaluaci√≥n de la calidad de la b√∫squeda y ajuste de los par√°metros.  La evaluaci√≥n de calidad es una idea fundamental para la teor√≠a de b√∫squeda.  Porque es gracias a la evaluaci√≥n de calidad que podemos hablar sobre la aplicabilidad o inaplicabilidad de un modelo en particular e incluso discutir sus aspectos te√≥ricos. <br><br>  En particular, una de las limitaciones naturales de la calidad de b√∫squeda es la observaci√≥n realizada en el ep√≠grafe: ¬°las opiniones de los dos "evaluadores" (expertos que emiten un veredicto sobre la relevancia) en promedio no coinciden entre s√≠ en gran medida!  Esto tambi√©n implica el l√≠mite superior natural de la calidad de b√∫squeda, porque la calidad se mide en comparaci√≥n con la opini√≥n del asesor. <br><br>  <abbr title="Pero no necesariamente, ¬°hay m√©tricas &quot;alternativas&quot;!">Por lo general,</abbr> se miden dos par√°metros para evaluar la calidad de una b√∫squeda: <br><br><ul><li>  precisi√≥n: la proporci√≥n de material relevante en la respuesta de un motor de b√∫squeda </li><li>  integridad (retiro): la proporci√≥n de documentos relevantes encontrados en el n√∫mero total de documentos de recopilaci√≥n relevantes </li></ul><br>  Estos par√°metros se usaron y se usan regularmente para seleccionar modelos y sus par√°metros en el marco de la conferencia de evaluaci√≥n de recuperaci√≥n de texto (TREC) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">*</a> creada por el Instituto Americano de Est√°ndares (NIST).  A partir de 1992, un consorcio de 25 grupos, para el a√±o 12 de su existencia, la conferencia ha acumulado material significativo en el que los motores de b√∫squeda todav√≠a est√°n perfeccionados.  Para cada conferencia regular, se est√° preparando nuevo material (la llamada "pista") en cada una de las √°reas de inter√©s.  La "pista" incluye una colecci√≥n de documentos y solicitudes.  Dar√© ejemplos: <br><br>  - Seguimiento de solicitudes aleatorias ( <i>ad hoc</i> ): presente en todas las conferencias <br>  - B√∫squeda multiling√ºe <br>  - Enrutamiento y filtrado <br>  - B√∫squeda de alta precisi√≥n (con una sola respuesta, realizada a tiempo) <br>  - Interacci√≥n del usuario <br>  - "Camino" en lenguaje natural <br>  - Respuestas a "preguntas" <br>  - Buscar en textos "sucios" (reci√©n escaneados) <br>  - B√∫squeda por voz <br>  - Buscar en un caso muy grande (20 GB, 100 GB, etc.) <br>  - Cuerpo WEB (en conferencias recientes, est√° representado por una selecci√≥n para el dominio .gov) <br>  - B√∫squeda distribuida y combinaci√≥n de resultados de b√∫squeda de diferentes sistemas <br><br><hr><a name="conf"></a>  <sup>* Los materiales de la conferencia est√°n disponibles p√∫blicamente en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trec.nist.gov/pubs.html</a> .</sup> <br><br><h3>  No solo busca </h3><br>  Como se puede ver en las "rutas" de TREC, una serie de tareas est√°n estrechamente relacionadas con la b√∫squeda en s√≠, ya sea compartiendo una ideolog√≠a com√∫n (clasificaci√≥n, enrutamiento, filtrado, anotaci√≥n) o siendo una parte integral del proceso de b√∫squeda (agrupaci√≥n de resultados, expansi√≥n y reducci√≥n de consultas, comentarios, Anotaci√≥n "dependiente de consulta", interfaz de b√∫squeda e idiomas de consulta).  No hay un solo motor de b√∫squeda que no tenga que resolver en la pr√°ctica al menos una de estas tareas. <br><br>  A menudo, la presencia de una u otra propiedad adicional es un argumento decisivo en la competencia de los motores de b√∫squeda.  Por ejemplo, breves anotaciones que consisten en citas informativas de un documento con el que algunos motores de b√∫squeda acompa√±an los resultados de su trabajo les ayudan a mantenerse a medio paso de la competencia. <br><br>  Es imposible contar sobre todas las tareas y c√≥mo resolverlas.  Por ejemplo, considere la "extensi√≥n de consulta", que generalmente se realiza mediante la b√∫squeda de t√©rminos asociados.  La soluci√≥n a este problema es posible en dos formas: local (din√°mica) y global (est√°tica).  Los t√©cnicos locales conf√≠an en el texto de la consulta y analizan solo los documentos encontrados en √©l.  Las "extensiones" globales pueden operar con tesauros, tanto a priori (ling√º√≠sticos) como construidos autom√°ticamente a lo largo de la colecci√≥n de documentos.  Seg√∫n la opini√≥n generalmente aceptada, las modificaciones de consultas globales a trav√©s de tesauros funcionan de manera ineficiente, reduciendo la precisi√≥n de la b√∫squeda.  Un enfoque global m√°s exitoso se basa en clasificaciones est√°ticas creadas manualmente, como los directorios WEB.  Este enfoque es ampliamente utilizado en los motores de b√∫squeda de Internet en las operaciones de estrechamiento o expansi√≥n de consultas. <br><br>  A menudo, la implementaci√≥n de caracter√≠sticas adicionales se basa en los mismos principios o modelos, o muy similares, que la b√∫squeda misma. , ,   ,                (   ‚Äì    TF*IDF),     .    <i> </i> (relevance feedback),     <i></i> ()   ,    . <br><br>  ,    ,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¬´Term Vector Database¬ª</a>   ,     ¬´¬ª  (   ). <br><br><h3>  </h3><br>            ,    .         .     ,    (, , ),  .   ,     (,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> )         ,            .    ,    ,     : <br><br> ‚Äî     <br> ‚Äî <i></i> ( ):  ,   <br> ‚Äî    ( <i>-</i> ) <br> ‚Äî <i></i> (, <i></i> ):  <i></i>   ¬´¬ª,      ,      <br> ‚Äî    ()    (, ) <br> ‚Äî <i></i> :      <br> ‚Äî  <i> </i> <br><br>           <i></i> , <i></i>   <i></i> .        -   (LSI,  ),   -     ,      . <br><br><h3>    </h3><blockquote> ‚ÄúThings that work well on TREC often do not produce good results on the web‚Ä¶ Some argue that on the web, users should specify more accurately what they want and add more words to their query. We disagree vehemently with this position. If a user issues a query like ¬´Bill Clinton¬ª they should get reasonable results since there is a enormous amount of high quality information available on this topic‚Äù <br> <b>Sergei Brin, Larry Page <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20040614144734/">The Anatomy of a Large-Scale Hypertextual Web Search Engine</a></b> <br><br><div class="spoiler">  <b class="spoiler_title">Traducci√≥n</b> <div class="spoiler_text"> ¬´,     TREC,     ‚Ä¶  ,         ,   ,     .        .    ¬´ ¬ª,     ,           ...¬ª </div></div><br> ¬´I was struck when a Google person told me at SIGIR that the most recent Google ranking algorithm completely ignores anything discovered at TREC, because all the good Ad Hoc ranking algorithms developed over the 10 years of TREC get trashed by spam¬ª <br> <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mark Sanderson</a></b> <br><br><div class="spoiler">  <b class="spoiler_title">Traducci√≥n</b> <div class="spoiler_text"> ¬´  ,  -  Google  ,         TREC,    ,    ¬´ ¬ª   ...¬ª </div></div></blockquote><br>    ,     :         ? <br><br>  ,  ,    ,    -  ,     (    ,   . .)    .  <i></i> (off-page)    ,    ÃÅ ,    .   , ,  ,  ,      ‚Äì       . <br><br> C        ,        -.  ,    ¬´¬ª  ,         .   <i> </i> ,   ,  <i></i> , ¬´ ¬ª    ,     ,   . <br><br>    ,                  ,  , , ,     .        (     <i> </i> ‚Äì     ),        .             . <br><br>                . <br><br><h3>   </h3><br>        .          ,   1999-2000         .             (     )      ,     . <br><br>    (  )        ,   .  ,      <i> </i> .         1998 .     <i></i> ,  ,      .            1998   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><i>PageRank</i></a> ‚Äì  ,  ,            .       ,    (,   ,         80- ),       . <br><br>  ,  PageRank,    (  ,   )    ‚Äì <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HITS</a> , <abbr title="   ,        ."></abbr>       -  .     ,    (. . ) ,  . <br><br>  ,  ,    ,       .  ,        ,      :    ,       . .     ,      :    (,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">www.teoma.com</a> ),    ..,    <i></i> .      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>   . <br><br><h3>   </h3><br>            ,   .     ,  Google  Fast,       .  : ¬´¬ª ,   ,     100 ,     30%     ‚Äì   .           . <br><br>   ,       ,  :     ,   ..   ,     ,       ,   ¬´  ¬ª. <br><br>        .                :       ;    ‚Äì    . <br><br>          ‚Äì   ,    ,  ,       . .   : , , , ,    . . ,                . <br><br>  ,    ,    ,         : , ,     . <br><br> ,       ,                 .          -  . <br><br>     Udi Manber ( ) (      agrep)  1994  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> ,  Andrei Broder ( )  1997- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>       ¬´¬ª (  shingles, ¬´¬ª, ¬´¬ª).    . <br><br><img src="https://habrastorage.org/webt/lr/zz/i0/lrzzi0rqbw5drhtoz6kf7qcdre4.png"><br><br>        ( <i></i> ).   ,  , ,     .        (,    ,      9)   ,   , , 25.      ,        . ,      ‚Äì   ,    , ,  ,    (  )   :  !         25     ! <br><br> ,       ,      ..       :    ¬´     ¬ª   !       . (     ; ,  0%;  .) <br><br>      ,     <i> </i> ,      <i>-</i> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>    .     ,            ( <i> </i> ),         -. <br><br><h3>    </h3><br>         .               ,   .         . <br><br>       ,        ,     .  ,   1997  (  Inktomi)    32-  (Linux, Solaris, FreeBSD, Win32)       .       AltaVista,       ¬´¬ª 64-  Alpha. <br><br>     (, ,    c)        <i></i>  <i></i> .              .      ,  ,    ,   ,       . Pruning ( . , )   ,           .    pruning,           ,      . <br><br>   ‚Äì     ,   ,         .       ,         . <br><br> ,     (,     - )  <abbr title="  Google   2001 ‚Äì  2002 ."></abbr>     . ,   ,   ,      ,      :   ,    . <br><br>          ,    , ,               . , ,  ,     .     , , ,  2-4 ,     ,   ,      ,       .       . <br><br><div class="spoiler"> <b class="spoiler_title"></b> <div class="spoiler_text">  (assesor, ) ‚Äì    ,    <i></i> ,   . <br><br>   (boolean, , , ) ‚Äì  ,    ,    . <br><br>   ‚Äì   ,         ,  <i></i> ‚Äì    . <br><br>   ‚Äì   ,                 . <br><br>   (off-page, ) ‚Äì      ,  ,            . <br><br>   (doorways, hallways) ‚Äì ,         ( <i> </i> ).         . <br><br>  (tagging, part of speech disambiguation, ) ‚Äì     <i></i> c  ;           ¬´ ¬ª. <br><br>  (duplicates) ‚Äì    ,    , ;   (near duplicates, -),     ,   . <br><br>   ‚Äì   ,            ,    . <br><br>   (inverted file,  ,  ,  ) ‚Äì   ,      ,       ,    . <br><br>  (index, ) ‚Äì . <i></i> . <br><br>   (citation index) ‚Äì   ()  ,        , ,  . <br><br>  (indexing, ) ‚Äì      ( <i></i> ) ‚Äì   ,    . <br><br>   (Information Retrieval, IR) ‚Äì   ,       .      ,     .   ,    .       ¬´ ¬ª,      ,          .  <i> </i>     ,  ,    (),    , ,     . <br><br>  (cloaking) ‚Äì  <i> </i> ,       ( )        ,    ,  . <br><br>   ‚Äì . <i> </i> . <br><br> -  ‚Äì   <i>  </i> ,   .         . <br><br>  (lemmatization, ) ‚Äì      ,   . <br><br>    ‚Äì . <i>  </i> . <br><br>  ‚Äì  <i>  </i> ,              . <br><br>     (inverted document frequency, IDF,    ,   ) ‚Äì     ( <i> </i> ); <i>¬´¬ª</i> ,             ,   . <br><br>   ‚Äì     ,    <i></i>  ,  <i> </i>  , ,    .    <i> </i> ‚Äì   ,         . <br><br>  ‚Äì . <i></i> . <br><br>  ‚Äì  ,     <i></i>  <i></i> () . <br><br>    ‚Äì  <i> </i> ,   ,    . <br><br>    (similar document search) ‚Äì  <i> </i> ,     <i></i>       ,   . <br><br>   (search engine, SE, - , ,  ,  , ¬´¬ª, ¬´¬ª) ‚Äì ,    ,   . <br><br>   (query, ) ‚Äì   . <br><br>  (polysemy, homography, , , <i></i> ) ‚Äî         . <br><br>  (recall, ) ‚Äì   ,     ,        . <br><br> - (near-duplicates,  ) ‚Äì . <i></i> . <br><br>  (pruning) ‚Äì           <i></i> . <br><br>   ‚Äì     ,    ( <i></i> ). <br><br> -  ‚Äì . <i> </i> . <br><br>    (term specificity, term discriminating power, ,  ) ‚Äì     .         ,      .        ,    . <br><br>   (regualr expression, pattern, ¬´¬ª,  ¬´¬ª, ¬´¬ª) ‚Äì   <i> </i> ,      ,   ,   . .    ‚Äì ,   <i></i>  . <br><br>  (relevance, relevancy) ‚Äì   . <br><br>  (signature, ) ‚Äì  <i>-</i>    .    <b> </b>            <i>-</i>  . <br><br>  (inflection) ‚Äì     ,      ,      (),     .    <i></i> ,          . <i></i>    (declension),   ‚Äì  (conjugation). <br><br>  (derivation) ‚Äì         .         ,   . <br><br>  ‚Äì . <i> </i> . <br><br>    (spam, ,   ) ‚Äì     <i> </i>    . <br><br>   ‚Äì . <i>PageRank</i> . <br><br>  ‚Äì    . <br><br> - (stop-words) ‚Äì  ,     ,               / <i></i> . <br><br>  ,   (suffix trees, suffix arrays, PAT-arrays) ‚Äì <i></i> ,      <i></i>    ,   <b></b> (trie). <b></b>      ¬´¬ª,      (     )     .     <i></i> ,      ‚Äì ,  .       ,  ,    . <br><br>  (tokenization, lexical analysis,  ,  ) ‚Äì    ,    <i></i> ,   , ,   . <br><br>  (precision) ‚Äî  <i></i>     . <br><br> - (hash-value) ‚Äì  <b>-</b> (hash-function),     (, )    . <br><br>  ()   (document frequency,   ,  ) ‚Äì    ,   . <br><br>   (term frequency, TF) ‚Äì     . <br><br>  ‚Äì (shingle) ‚Äì <i>-</i>      . <br><br> PageRank ‚Äì    ()    ,       ‚Äî  .          . <br><br> TF*IDF ‚Äì        <i> </i> ;  ,  <b> </b>      <b> </b> ‚Äì  . </div></div><br><h4>   </h4> <sup><a name="baezo-yates"></a><br> Modern Information Retrieval <br> Baezo-Yates R. and Ribeiro-Neto B. <br> ACM Press Addison Wesley, 1999 <br><a name="bharat"></a><br> The Connectivity Server: fast access to linkage information on the Web <br> K. Bharat, A. Broder, M. Henzinger, P. Kumara, and S. Venkatasubramanian <br> WWW7, 1998 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://www7.scu.edu.au/programme/fullpapers/1938/com1938.htm</a> <br><a name="brin"></a><br> The Anatomy of a Large-Scale Hypertextual Web Search Engine <br> S.Brin and L. Page <br> WWW7, 1998 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20040614144734/">http://www7.scu.edu.au/programme/fullpapers/1921/com1921.htm</a> <br><a name="broder"></a><br> Syntactic Clustering of the Web <br> Andrei Z. Broder, Steven C. Glassman, Mark S. Manasse <br> WWW6, 1997 <br><a name="deerwester"></a><br> Indexing by Latent Semantic Analysis <br> S. Deerwester, ST Dumais, GW Furnas, TK Landauer, R. Harshman <br> JASIS, 1990 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20010802133759/">http://citeseer.nj.nec.com/deerwester90indexing.html</a> <br><a name="eckart"></a><br> The approximation of one matrix by another of lower rank <br> C. Eckart, G. Young <br> Psychometrika, 1936 <br><a name="faloutsos"></a><br> Description and performance analysis of signature file methods <br> C. Faloutsos, S. Christodoulakis <br> ACM TOIS 1987 <br><a name="fastpmc"></a><br> FAST PMC ‚Äî The Pattern Matching Chip <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/19990908203501/">http://www.fast.no/product/fastpmc.html</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">www.idi.ntnu.no/grupper/KS-grp/microarray/slides/heggebo.pdf</a> (   ,  web.archive.org    ‚Äì . .) <br><a name="furnas"></a><br> Information retrieval using a Singular Value Decomposition Model of Latent Semantic Structure <br> GW Furnas, S. Deerwester, ST Dumais, TK Landauer, RA Harshman, LA Streeter, and KE Lochbaum <br> ACM SIGIR, 1988 <br><a name="glimpse"></a><br> Glimpse, Webglimpse, Unix-based search software‚Ä¶ <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20010509114708/">http://webglimpse.org</a> <br><a name="gonnet"></a><br> Examples of PAT applied to the Oxford English Dictionary <br> Gonnet G. <br> University of Waterloo, 1987 <br><a name="harman"></a><br> What we have learned, and not learned, from TREC <br> Donna Harman <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20030702130753/">http://irsg.eu.org/irsg2000online/papers/harman.htm</a> <br><a name="joyce"></a><br> The Thesaurus Approach to Information Retrieval <br> T. Joyce and RM Needham <br> American Documentation, 1958 <br><a name="kleinberg"></a><br> Authoritative Sources in a Hyperlinked Environment <br> Jon M. Kleinberg <br> JACM, 1998 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20020601183351/">http://citeseer.nj.nec.com/87928.html</a> <br><a name="ilyinsky"></a><br> An efficient method to detect duplicates of Web documents with the use of inverted index <br> S. Ilyinsky, M. Kuzmin, A. Melkov, I. Segalovich <br> WWW2002, 2002 <br><a name="manber1990"></a><br> Suffix Arrays: A New Method for On-line String Searches <br> U. Manber, G. Myers <br> 1st ACM-SIAM Symposium on Discrete Algorithms, 1990 <br><a name="manber1994"></a><br> Finding similar files in a large file system <br> U. Manber <br> USENIX Conference, 1994 <br><a name="maron"></a><br> ME Maron and JL Kuhns <br> On relevance, probabilistic indexing and information retrieval <br> Journal of the ACM, 1960 <br><a name="opentext"></a><br> Open Text Corporation <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://www.opentext.com</a> <br><a name="robertson"></a><br> SE Robertson and Sparck Jones K. <br> Relevance Weighting of Search Terms <br> JASIS, 1976 <br><a name="sedgewick"></a><br> Algorithms in C++, Robert Sedgewick <br> Addison-Wesley, 1992 <br><a name="spark-jones"></a><br> A Statistical Interpretation of Term Specificity and Its Application in Retrieval <br> Karen Sparck Jones <br> Journal of Documentation, 1972 <br><a name="stata"></a><br> The Term Vector Database: fast access to indexing terms for Web pages <br> R. Stata, K. Bharat, F. Maghoul <br> WWW9, 2000 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=http://web.archive.org/web/20020607145018/">http://www9.org/w9cdrom/159/159.html</a> <br><a name="strzalkowski"></a><br> Natural Language Information Retrieval <br> Tomek Strzalkowski (ed.) <br> Kluwer Academic Publishers, 1999 <br><a name="cormen"></a><br> :   , . , . , . <br> , 2000 <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://www.ozon.ru/context/detail/id/33769775/</a> <br><a name="symphony"></a><br>   -       .  .. , .., .. <br> -  , 1995</sup> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/464375/">https://habr.com/ru/post/464375/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../464365/index.html">Semana de la seguridad 34: vulnerabilidades extraordinarias en Windows</a></li>
<li><a href="../464367/index.html">Y otro Steam Windows Client Local Privilege Escalation 0day</a></li>
<li><a href="../464369/index.html">¬øQu√© bloqueador usas? Resultados</a></li>
<li><a href="../464371/index.html">/etc/resolv.conf para pods Kubernetes, opci√≥n ndots: 5, ya que esto puede afectar negativamente el rendimiento de la aplicaci√≥n</a></li>
<li><a href="../464373/index.html">Edge-to-edge en Android: hacerlo bien</a></li>
<li><a href="../464377/index.html">Ensamblador sucio piratea 6502</a></li>
<li><a href="../464381/index.html">Viaje a Alaska, o KDD'19 a trav√©s de los ojos de un testigo ocular</a></li>
<li><a href="../464383/index.html">C√≥mo pongo las cosas en orden en un proyecto donde hay un bosque de manos directas (configuraci√≥n tslint, m√°s bonita, etc.)</a></li>
<li><a href="../464385/index.html">Python como el √∫ltimo caso de C ++. Parte 1/2</a></li>
<li><a href="../464387/index.html">Huella rusa en la saga escandinava de videojuegos, terminando</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
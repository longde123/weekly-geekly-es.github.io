<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòõ üõ°Ô∏è ü§ΩüèΩ Un ejemplo de una red neuronal simple en C / C ++ üé¨ üßòüèª ü§úüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos 

 Decid√≠ compartir una soluci√≥n simple y amplia en mi opini√≥n de una red neuronal en C ++. 

 ¬øPor qu√© deber√≠a ser interesante esta info...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Un ejemplo de una red neuronal simple en C / C ++</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440162/">  Hola a todos <br><br>  Decid√≠ compartir una soluci√≥n simple y amplia en mi opini√≥n de una red neuronal en C ++. <br><br>  <b>¬øPor qu√© deber√≠a ser interesante esta informaci√≥n?</b> <br><br>  <b>Respuesta:</b> Trat√© de programar el trabajo del perceptr√≥n multicapa en un conjunto m√≠nimo, para que pudiera configurarse como quisiera en solo unas pocas l√≠neas de c√≥digo, y la implementaci√≥n de los algoritmos b√°sicos para trabajar en "C" le permitir√° transferir f√°cilmente lenguajes orientados a "C" (en y a cualquier otro) <b><u>sin usar bibliotecas de terceros!</u></b> <br><br><h4>  Por favor, eche un vistazo a lo que surgi√≥ </h4><br>  No le dir√© sobre el <b>prop√≥sito de las redes neuronales</b> , espero que no haya sido excluido de <b>Google</b> y pueda encontrar la informaci√≥n que le interesa (prop√≥sito, capacidades, aplicaciones, etc.). <br><br>  Encontrar√° el <b>c√≥digo fuente</b> al final del art√≠culo, pero por ahora, en orden. <br><br><h3>  Comencemos el an√°lisis </h3><br><h4>  1) Arquitectura y detalles t√©cnicos </h4><br>  - <b>perceptr√≥n multicapa</b> con la capacidad de configurar cualquier n√∫mero de capas con un ancho dado.  A continuaci√≥n se presenta <br><br><div class="spoiler">  <b class="spoiler_title">ejemplo de configuraci√≥n</b> <div class="spoiler_text">  <b>myNeuero.cpp</b> <br><br><pre><code class="cpp hljs">inputNeurons = <span class="hljs-number"><span class="hljs-number">100</span></span>; <span class="hljs-comment"><span class="hljs-comment">//   outputNeurons =2; //   nlCount = 4; //  (    3,      1 list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); inputs = (float*) malloc((inputNeurons)*sizeof(float)); targets = (float*) malloc((outputNeurons)*sizeof(float)); list[0].setIO(100,20); //  INPUTS/OUTPUTS    list[1].setIO(20,6); // -//- list[2].setIO(6,3); // -//- list[3].setIO(3,2); // -//-  </span></span></code> </pre> <br></div></div><br>  Tenga en cuenta que la configuraci√≥n del ancho de entrada y salida para cada capa se realiza de acuerdo con una determinada regla: la entrada de la capa actual = la salida de la capa anterior.  Una excepci√≥n es la capa de entrada. <br><br>  Por lo tanto, tiene la oportunidad de configurar cualquier configuraci√≥n manualmente o de acuerdo con una regla determinada antes de compilar o despu√©s de la compilaci√≥n para leer datos de los archivos de origen. <a name="habracut"></a><br><br>  - implementaci√≥n del mecanismo de <b>propagaci√≥n hacia atr√°s de errores</b> con la capacidad de establecer la velocidad de aprendizaje <br><br>  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> learnRate 0.1</span></span></code> </pre> <br>  - instalaci√≥n de <b>pesos iniciales</b> <br><br>  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> randWeight (( ((float)qrand() / (float)RAND_MAX) - 0.5)* pow(out,-0.5))</span></span></code> </pre> <br>  <b>Nota</b> : si hay m√°s de tres capas (nlCount&gt; 4), se debe aumentar pow (out, -0.5) para que cuando la se√±al pase directamente, su energ√≠a no se reduzca a 0. Ejemplo pow (out, -0.2) <br><br>  - la <b>base del c√≥digo en C.</b> Los algoritmos b√°sicos y el almacenamiento de los coeficientes de ponderaci√≥n se implementan como una estructura en C, todo lo dem√°s es la cubierta de la funci√≥n de llamada de esta estructura, tambi√©n es un reflejo de cualquiera de las capas tomadas por separado <br><br><div class="spoiler">  <b class="spoiler_title">Estructura de la capa</b> <div class="spoiler_text">  <b>myNeuero.h</b> <br><br><pre> <code class="cpp hljs"> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">nnLay</span></span></span><span class="hljs-class">{</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> in; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> out; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>** matrix; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* hidden; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>* errors; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getInCount</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> in;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutCount</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> **</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>{<span class="hljs-keyword"><span class="hljs-keyword">return</span></span> matrix;} <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">updMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *enteredVal)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; out; ou++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; in; hid++) { matrix[hid][ou] += (learnRate * errors[ou] * enteredVal[hid]); } matrix[in][ou] += (learnRate * errors[ou]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">setIO</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> inputs, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> outputs)</span></span></span><span class="hljs-function"> </span></span>{ in=inputs; out=outputs; hidden = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((out)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); matrix = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>**) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((in+<span class="hljs-number"><span class="hljs-number">1</span></span>)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in+<span class="hljs-number"><span class="hljs-number">1</span></span>; inp++) { matrix[inp] = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>(out*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); } <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in+<span class="hljs-number"><span class="hljs-number">1</span></span>; inp++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> outp =<span class="hljs-number"><span class="hljs-number">0</span></span>; outp &lt; out; outp++) { matrix[inp][outp] = randWeight; } } } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">makeHidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *inputs)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; out; hid++) { <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> tmpS = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> inp =<span class="hljs-number"><span class="hljs-number">0</span></span>; inp &lt; in; inp++) { tmpS += inputs[inp] * matrix[inp][hid]; } tmpS += matrix[in][hid]; hidden[hid] = sigmoida(tmpS); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getHidden</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> hidden; }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calcOutError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *targets)</span></span></span><span class="hljs-function"> </span></span>{ errors = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((out)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; out; ou++) { errors[ou] = (targets[ou] - hidden[ou]) * sigmoidasDerivate(hidden[ou]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calcHidError</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> *targets,</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> **outWeights,</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> inS, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> outS)</span></span></span><span class="hljs-function"> </span></span>{ errors = (<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*) <span class="hljs-built_in"><span class="hljs-built_in">malloc</span></span>((inS)*<span class="hljs-keyword"><span class="hljs-keyword">sizeof</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> hid =<span class="hljs-number"><span class="hljs-number">0</span></span>; hid &lt; inS; hid++) { errors[hid] = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ou =<span class="hljs-number"><span class="hljs-number">0</span></span>; ou &lt; outS; ou++) { errors[hid] += targets[ou] * outWeights[hid][ou]; } errors[hid] *= sigmoidasDerivate(hidden[hid]); } }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function">* </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getErrors</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> errors; }; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sigmoida</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> val)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (<span class="hljs-number"><span class="hljs-number">1.0</span></span> / (<span class="hljs-number"><span class="hljs-number">1.0</span></span> + <span class="hljs-built_in"><span class="hljs-built_in">exp</span></span>(-val))); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">float</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sigmoidasDerivate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> val)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (val * (<span class="hljs-number"><span class="hljs-number">1.0</span></span> - val)); }; };</code> </pre><br></div></div><br><h4>  2) aplicaci√≥n </h4><br>  Probar el proyecto con el conjunto mnist fue exitoso, logramos una probabilidad de reconocimiento de escritura a mano condicional de 0.9795 (nlCount = 4, learnRate = 0.03 y varias eras).  El objetivo principal de la prueba era probar el rendimiento de la red neuronal, con la que se enfrent√≥. <br><br>  A continuaci√≥n consideramos el trabajo en la <b>"tarea condicional"</b> . <br><br>  <b>Datos de origen:</b> <br><br>  -2 vectores de entrada aleatorios de 100 valores <br>  red neuronal con generaci√≥n aleatoria de pesas <br>  -2 establecer objetivos <br><br>  <b>El c√≥digo</b> en la funci√≥n main () <br><br><pre> <code class="cpp hljs">{ <span class="hljs-comment"><span class="hljs-comment">//!!!________    qDebug()   std::cout  std::cerr myNeuro *bb = new myNeuro(); //----------------------------------INPUTS----GENERATOR------------- /!  2    qsrand((QTime::currentTime().second())); float *abc = new float[100]; for(int i=0; i&lt;100;i++) { abc[i] =(qrand()%98)*0.01+0.01; } float *cba = new float[100]; for(int i=0; i&lt;100;i++) { cba[i] =(qrand()%98)*0.01+0.01; } //---------------------------------TARGETS----GENERATOR------------- //  2   float *tar1 = new float[2]; tar1[0] =0.01; tar1[1] =0.99; float *tar2 = new float[2]; tar2[0] =0.99; tar2[1] =0.01; //--------------------------------NN---------WORKING--------------- //    bb-&gt;query(abc); qDebug()&lt;&lt;"_________________________________"; bb-&gt;query(cba); //  int i=0; while(i&lt;100000) { bb-&gt;train(abc,tar1); bb-&gt;train(cba,tar2); i++; } //   (   ) qDebug()&lt;&lt;"___________________RESULT_____________"; bb-&gt;query(abc); qDebug()&lt;&lt;"______"; bb-&gt;query(cba); }</span></span></code> </pre> <br>  <b>El resultado de la red neuronal.</b> <br><br><img src="https://habrastorage.org/webt/gt/oe/vc/gtoevca428fe3i7wmvkkupaayq0.png" alt="imagen"><br><br><h3>  <b>Resumen</b> </h3><br>  Como puede ver, llamar a la funci√≥n de consulta (entradas) antes de entrenar para cada uno de los vectores no nos permite juzgar sus diferencias.  Adem√°s, al llamar a la funci√≥n de tren (entrada, objetivo), para entrenar con el objetivo de organizar coeficientes de peso para que la red neuronal pueda distinguir posteriormente entre los vectores de entrada. <br><br>  Despu√©s de completar el entrenamiento, observamos que el intento de mapear el vector "abc" a "tar1" y "cba" a "tar2" fall√≥. <br><br>  <b>¬°Tiene la oportunidad, usando el c√≥digo fuente, de probar independientemente el rendimiento y experimentar con la configuraci√≥n!</b> <br><br>  PD: este c√≥digo fue escrito desde QtCreator, espero que pueda reemplazar f√°cilmente la salida, dejar sus comentarios y comentarios. <br><br>  PPS: si alguien est√° interesado en un an√°lisis detallado del trabajo de struct nnLay {} write, habr√° una nueva publicaci√≥n. <br><br>  PPPS: Espero que alguien pueda usar el c√≥digo orientado "C" para portar a otras herramientas. <br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo fuente</b> <div class="spoiler_text">  <b>main.cpp</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QCoreApplication&gt; #include &lt;QDebug&gt; #include &lt;QTime&gt; #include "myneuro.h" int main(int argc, char *argv[]) { QCoreApplication a(argc, argv); myNeuro *bb = new myNeuro(); //----------------------------------INPUTS----GENERATOR------------- qsrand((QTime::currentTime().second())); float *abc = new float[100]; for(int i=0; i&lt;100;i++) { abc[i] =(qrand()%98)*0.01+0.01; } float *cba = new float[100]; for(int i=0; i&lt;100;i++) { cba[i] =(qrand()%98)*0.01+0.01; } //---------------------------------TARGETS----GENERATOR------------- float *tar1 = new float[2]; tar1[0] =0.01; tar1[1] =0.99; float *tar2 = new float[2]; tar2[0] =0.99; tar2[1] =0.01; //--------------------------------NN---------WORKING--------------- bb-&gt;query(abc); qDebug()&lt;&lt;"_________________________________"; bb-&gt;query(cba); int i=0; while(i&lt;100000) { bb-&gt;train(abc,tar1); bb-&gt;train(cba,tar2); i++; } qDebug()&lt;&lt;"___________________RESULT_____________"; bb-&gt;query(abc); qDebug()&lt;&lt;"______"; bb-&gt;query(cba); qDebug()&lt;&lt;"_______________THE____END_______________"; return a.exec(); }</span></span></span></span></code> </pre><br>  <b>myNeuro.cpp</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"myneuro.h"</span></span></span><span class="hljs-meta"> #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;QDebug&gt; myNeuro::myNeuro() { //-------- inputNeurons = 100; outputNeurons =2; nlCount = 4; list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); inputs = (float*) malloc((inputNeurons)*sizeof(float)); targets = (float*) malloc((outputNeurons)*sizeof(float)); list[0].setIO(100,20); list[1].setIO(20,6); list[2].setIO(6,3); list[3].setIO(3,2); //----------------- // inputNeurons = 100; // outputNeurons =2; // nlCount = 2; // list = (nnLay*) malloc((nlCount)*sizeof(nnLay)); // inputs = (float*) malloc((inputNeurons)*sizeof(float)); // targets = (float*) malloc((outputNeurons)*sizeof(float)); // list[0].setIO(100,10); // list[1].setIO(10,2); } void myNeuro::feedForwarding(bool ok) { list[0].makeHidden(inputs); for (int i =1; i&lt;nlCount; i++) list[i].makeHidden(list[i-1].getHidden()); if (!ok) { qDebug()&lt;&lt;"Feed Forward: "; for(int out =0; out &lt; outputNeurons; out++) { qDebug()&lt;&lt;list[nlCount-1].hidden[out]; } return; } else { // printArray(list[3].getErrors(),list[3].getOutCount()); backPropagate(); } } void myNeuro::backPropagate() { //-------------------------------ERRORS-----CALC--------- list[nlCount-1].calcOutError(targets); for (int i =nlCount-2; i&gt;=0; i--) list[i].calcHidError(list[i+1].getErrors(),list[i+1].getMatrix(), list[i+1].getInCount(),list[i+1].getOutCount()); //-------------------------------UPD-----WEIGHT--------- for (int i =nlCount-1; i&gt;0; i--) list[i].updMatrix(list[i-1].getHidden()); list[0].updMatrix(inputs); } void myNeuro::train(float *in, float *targ) { inputs = in; targets = targ; feedForwarding(true); } void myNeuro::query(float *in) { inputs=in; feedForwarding(false); } void myNeuro::printArray(float *arr, int s) { qDebug()&lt;&lt;"__"; for(int inp =0; inp &lt; s; inp++) { qDebug()&lt;&lt;arr[inp]; } }</span></span></span></span></code> </pre> <br>  <b>myNeuro.h</b> <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">ifndef</span></span></span><span class="hljs-meta"> MYNEURO_H #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">define</span></span></span><span class="hljs-meta"> MYNEURO_H #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;iostream&gt; #include &lt;math.h&gt; #include &lt;QtGlobal&gt; #include &lt;QDebug&gt; #define learnRate 0.1 #define randWeight (( ((float)qrand() / (float)RAND_MAX) - 0.5)* pow(out,-0.5)) class myNeuro { public: myNeuro(); struct nnLay{ int in; int out; float** matrix; float* hidden; float* errors; int getInCount(){return in;} int getOutCount(){return out;} float **getMatrix(){return matrix;} void updMatrix(float *enteredVal) { for(int ou =0; ou &lt; out; ou++) { for(int hid =0; hid &lt; in; hid++) { matrix[hid][ou] += (learnRate * errors[ou] * enteredVal[hid]); } matrix[in][ou] += (learnRate * errors[ou]); } }; void setIO(int inputs, int outputs) { in=inputs; out=outputs; hidden = (float*) malloc((out)*sizeof(float)); matrix = (float**) malloc((in+1)*sizeof(float)); for(int inp =0; inp &lt; in+1; inp++) { matrix[inp] = (float*) malloc(out*sizeof(float)); } for(int inp =0; inp &lt; in+1; inp++) { for(int outp =0; outp &lt; out; outp++) { matrix[inp][outp] = randWeight; } } } void makeHidden(float *inputs) { for(int hid =0; hid &lt; out; hid++) { float tmpS = 0.0; for(int inp =0; inp &lt; in; inp++) { tmpS += inputs[inp] * matrix[inp][hid]; } tmpS += matrix[in][hid]; hidden[hid] = sigmoida(tmpS); } }; float* getHidden() { return hidden; }; void calcOutError(float *targets) { errors = (float*) malloc((out)*sizeof(float)); for(int ou =0; ou &lt; out; ou++) { errors[ou] = (targets[ou] - hidden[ou]) * sigmoidasDerivate(hidden[ou]); } }; void calcHidError(float *targets,float **outWeights,int inS, int outS) { errors = (float*) malloc((inS)*sizeof(float)); for(int hid =0; hid &lt; inS; hid++) { errors[hid] = 0.0; for(int ou =0; ou &lt; outS; ou++) { errors[hid] += targets[ou] * outWeights[hid][ou]; } errors[hid] *= sigmoidasDerivate(hidden[hid]); } }; float* getErrors() { return errors; }; float sigmoida(float val) { return (1.0 / (1.0 + exp(-val))); } float sigmoidasDerivate(float val) { return (val * (1.0 - val)); }; }; void feedForwarding(bool ok); void backPropagate(); void train(float *in, float *targ); void query(float *in); void printArray(float *arr,int s); private: struct nnLay *list; int inputNeurons; int outputNeurons; int nlCount; float *inputs; float *targets; }; #endif // MYNEURO_H</span></span></span></span></code> </pre> <br></div></div><br><br><h3>  <b>UPD:</b> </h3>  Las fuentes para verificar en mnist son por <div class="spoiler">  <b class="spoiler_title">el enlace</b> <div class="spoiler_text">  1) proyecto <br>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Github.com/mamkin-itshnik/simple-neuro-network</a> " <br>  Tambi√©n hay una descripci√≥n gr√°fica del trabajo.  Brevemente, al sondear la red con datos de prueba, se le da el valor de cada una de las neuronas de salida (10 neuronas corresponden a n√∫meros del 0 al 9).  Para tomar una decisi√≥n sobre la figura representada, debe conocer el √≠ndice de la neurona m√°xima.  D√≠gito = √≠ndice + 1 (no olvide de d√≥nde est√°n numerados los n√∫meros en las matrices)) <br>  2) MNIST <br>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Www.kaggle.com/oddrationale/mnist-in-csv</a> " (si necesita usar un conjunto de datos m√°s peque√±o, simplemente limite el contador while al leer el archivo CSV de la PS: hay un ejemplo para git) <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/440162/">https://habr.com/ru/post/440162/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../440148/index.html">Realidad virtual: vida paralela con sus corrientes</a></li>
<li><a href="../440152/index.html">Lehmann Linear DIY o c√≥mo clonar un pura sangre alem√°n con un buen resultado</a></li>
<li><a href="../440154/index.html">C√≥mo se cre√≥ Spore: entrevistas con desarrolladores</a></li>
<li><a href="../440156/index.html">C√≥mo organizar el desarrollo distribuido, si esto no es posible</a></li>
<li><a href="../440158/index.html">Estad√≠sticas de ventas de veh√≠culos el√©ctricos e h√≠bridos recargables en 2018 (en los EE. UU. Y en todo el mundo)</a></li>
<li><a href="../440164/index.html">¬øLa monetizaci√≥n de los datos del usuario se convertir√° en una tendencia en 2019?</a></li>
<li><a href="../440166/index.html">Compresi√≥n de puntero Java</a></li>
<li><a href="../440168/index.html">Informes en video de FunTech ML-meetup</a></li>
<li><a href="../440170/index.html">An√°lisis de incidentes relacionados con ciberataques en proyectos de blockchain</a></li>
<li><a href="../440172/index.html">CQRS: el principio de "divide y vencer√°s" al servicio de un programador</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
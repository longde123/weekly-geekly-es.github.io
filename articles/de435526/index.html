<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∏üèø ‚èèÔ∏è üßõüèæ Abenteuer mit einem Home Kubernetes Cluster ü¶Ü ‚ôìÔ∏è ‚§¥Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hinweis perev. : Der Autor des Artikels, Marshall Brekka, ist Systemdesign-Direktor bei Fair.com, das seine Anwendung f√ºr das Autoleasing anbietet. In...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Abenteuer mit einem Home Kubernetes Cluster</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/435526/">  <i><b>Hinweis</b></i>  <i><b>perev.</b></i>  <i>: Der Autor des Artikels, Marshall Brekka, ist Systemdesign-Direktor bei Fair.com, das seine Anwendung f√ºr das Autoleasing anbietet.</i>  <i>In seiner Freizeit nutzt er seine umfangreiche Erfahrung gerne, um "Heim" -Probleme zu l√∂sen, die wahrscheinlich keinen Geek √ºberraschen (daher wird die Frage "Warum?" - in Bezug auf die unten beschriebenen Aktionen - a priori weggelassen).</i>  <i>In seiner Ver√∂ffentlichung teilt Marshall die Ergebnisse der j√ºngsten Bereitstellung von Kubernetes auf ... ARM-Boards mit.</i> <br><br><img src="https://habrastorage.org/webt/ul/nj/do/ulnjdoyysctwv-34jhuyn-wvsp8.png"><br><br>  Wie viele andere Geeks habe ich im Laufe der Jahre eine Vielzahl von Entwicklungsboards wie den Raspberry Pi angesammelt.  Und wie viele Geeks staubten sie sich in den Regalen mit dem Gedanken ab, dass sie eines Tages n√ºtzlich sein w√ºrden.  Und jetzt ist f√ºr mich endlich dieser Tag gekommen! <a name="habracut"></a><br><br>  W√§hrend der Winterferien traten mehrere Wochen au√üerhalb der Arbeit auf, in denen gen√ºgend Zeit blieb, um das gesamte angesammelte Eisen zu inventarisieren und zu entscheiden, was damit zu tun ist.  Folgendes hatte ich: <br><br><ul><li>  RAID-Geh√§use mit 5 Laufwerken und USB3-Anschluss; </li><li>  Himbeer-Pi-Modell B (OG-Modell); </li><li>  CubbieBoard 1; </li><li>  Banana Pi M1; </li><li>  HP Netbook (2012?). </li></ul><br>  Von den 5 aufgelisteten Eisenkomponenten habe ich nur RAID und ein Netbook als tempor√§res NAS verwendet.  Aufgrund der fehlenden USB3-Unterst√ºtzung im Netbook nutzte RAID jedoch nicht das volle Geschwindigkeitspotential. <br><br><h2>  Lebensziele </h2><br>  Da die Arbeit mit RAID bei Verwendung eines Netbooks nicht optimal war, habe ich die folgenden Ziele festgelegt, um die beste Konfiguration zu erzielen: <br><br><ol><li>  NAS mit USB3 und Gigabit-Ethernet; </li><li>  Der beste Weg, um Software auf Ihrem Ger√§t zu verwalten </li><li>  (Bonus) die M√∂glichkeit, Multimedia-Inhalte von RAID auf Fire TV zu streamen. </li></ol><br>  Da keines der verf√ºgbaren Ger√§te USB3 und Gigabit-Ethernet unterst√ºtzt, musste ich leider zus√§tzliche Eink√§ufe t√§tigen.  Die Wahl fiel auf den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ROC-RK3328-CC</a> .  Sie besa√ü alle notwendigen Spezifikationen und ausreichende Unterst√ºtzung f√ºr Betriebssysteme. <br><br>  Nachdem ich meine Hardwarebed√ºrfnisse gel√∂st hatte (und auf die Ankunft dieser L√∂sung gewartet hatte), wechselte ich zum zweiten Ziel. <br><br><h2>  Software auf dem Ger√§t verwalten </h2><br>  Zum Teil sind meine fr√ºheren Projekte im Zusammenhang mit Entwicklungsboards aufgrund unzureichender Ber√ºcksichtigung von Reproduzierbarkeits- und Dokumentationsproblemen gescheitert.  Beim Erstellen der n√§chsten Konfiguration f√ºr meine aktuellen Anforderungen habe ich mir nicht die M√ºhe gemacht, die durchgef√ºhrten Schritte oder die Links zu den Blog-Posts aufzuschreiben, denen ich gefolgt bin.  Und als nach Monaten oder Jahren etwas schief ging und ich versuchte, das Problem zu beheben, hatte ich kein Verst√§ndnis daf√ºr, wie alles urspr√ºnglich angeordnet war. <br><br>  Also sagte ich mir, dass diesmal alles anders sein wird! <br><br><img src="https://habrastorage.org/webt/dm/vb/iv/dmvbivkoa65wfd1ve5mo5wh5jdc.jpeg"><br><br>  Und er wandte sich an die Tatsache, dass ich es gut genug wei√ü - an Kubernetes. <br><br>  Obwohl K8s eine zu schwierige L√∂sung f√ºr ein eher einfaches Problem ist, bin ich nach fast drei Jahren der Verwaltung von Clustern mit verschiedenen Tools (meine eigenen, Kops usw.) bei meiner Hauptaufgabe mit diesem System sehr vertraut.  Dar√ºber hinaus schien die Bereitstellung von K8s au√üerhalb einer Cloud-Umgebung und sogar auf ARM-Ger√§ten eine interessante Aufgabe zu sein. <br><br>  Ich dachte auch, da die verf√ºgbare Hardware nicht die erforderlichen Anforderungen f√ºr den NAS erf√ºllt, werde ich versuchen, zumindest einen Cluster daraus zusammenzusetzen, und m√∂glicherweise kann eine Software, die nicht so ressourcenintensiv ist, auf √§lteren Ger√§ten funktionieren. <br><br><h2>  Kubernetes auf ARM </h2><br>  Bei der Arbeit hatte ich nicht die M√∂glichkeit, das Dienstprogramm <code>kubeadm</code> zum Bereitstellen von Clustern zu verwenden. <code>kubeadm</code> entschied ich, dass es jetzt an der Zeit war, es in Aktion zu <code>kubeadm</code> . <br><br>  Raspbian wurde als Betriebssystem ausgew√§hlt, weil es f√ºr die beste Unterst√ºtzung meiner Boards bekannt ist. <br><br>  Ich habe einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">guten Artikel</a> √ºber das Einrichten von Kubernetes auf einem Raspberry Pi mit HypriotOS gefunden.  Da ich nicht sicher war, ob HypriotOS f√ºr alle meine Boards verf√ºgbar ist, habe ich diese Anleitung f√ºr Debian / Raspbian angepasst. <br><br><h3>  Erforderliche Komponenten </h3><br>  Zun√§chst mussten folgende Tools installiert werden: <br><br><ul><li>  Docker, </li><li>  Kubelet </li><li>  kubeadm, </li><li>  kubectl. </li></ul><br>  Docker muss mit einem speziellen Skript installiert werden - einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">praktischen Skript</a> (wie f√ºr die Verwendung von Raspbian angegeben). <br><br><pre> <code class="bash hljs">curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh</code> </pre> <br>  Danach habe ich die Kubernetes-Komponenten gem√§√ü den Anweisungen im Hypriot-Blog installiert und sie so angepasst, dass f√ºr alle Abh√§ngigkeiten bestimmte Versionen verwendet werden: <br><br><pre> <code class="bash hljs">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://apt.kubernetes.io/ kubernetes-xenial main"</span></span> &gt; /etc/apt/sources.list.d/kubernetes.list apt-get update apt-get install -y kubelet=1.13.1-00 kubectl=1.13.1-00 kubeadm=1.13.1-00</code> </pre> <br><h3>  Himbeer pi b </h3><br>  Die erste Schwierigkeit trat auf, als versucht wurde, einen Cluster auf dem Raspberry Pi B zu booten: <br><br><pre> <code class="bash hljs">$ kubeadm init Illegal instruction</code> </pre> <br>  Es stellte sich heraus, dass Kubernetes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Unterst√ºtzung f√ºr ARMv6 entfernt hatte</a> .  Nun, ich habe auch CubbieBoard und Banana Pi. <br><br><h3>  Banane pi </h3><br>  Anf√§nglich schien dieselbe Abfolge von Aktionen f√ºr Banana Pi erfolgreicher zu sein. Der Befehl <code>kubeadm init</code> lief jedoch ab, w√§hrend versucht wurde, auf die <code>kubeadm init</code> der <code>kubeadm init</code> zu warten: <br><br><pre> <code class="plaintext hljs">error execution phase wait-control-plane: couldn't initialize a Kubernetes cluster</code> </pre> <br>  Als ich mit <code>docker ps</code> herausfand, was mit den Containern geschah, sah ich, dass sowohl der <code>kube-controller-manager</code> als auch der <code>kube-scheduler</code> mindestens 4-5 Minuten arbeiteten, aber der <code>kube-api-server</code> stand erst vor 1-2 Minuten auf: <br><br><pre> <code class="bash hljs">$ docker ps CONTAINER ID COMMAND CREATED STATUS de22427ad594 <span class="hljs-string"><span class="hljs-string">"kube-apiserver --au‚Ä¶"</span></span> About a minute ago Up About a minute dc2b70dd803e <span class="hljs-string"><span class="hljs-string">"kube-scheduler --ad‚Ä¶"</span></span> 5 minutes ago Up 5 minutes 60b6cc418a66 <span class="hljs-string"><span class="hljs-string">"kube-controller-man‚Ä¶"</span></span> 5 minutes ago Up 5 minutes 1e1362a9787c <span class="hljs-string"><span class="hljs-string">"etcd --advertise-cl‚Ä¶"</span></span> 5 minutes ago Up 5 minutes</code> </pre> <br>  Offensichtlich starb der <code>api-server</code> oder der Strontium-Prozess t√∂tete ihn und startete ihn neu. <br><br>  Beim √úberpr√ºfen der Protokolle sah ich sehr standardm√§√üige Startverfahren - es gab eine Aufzeichnung √ºber den Beginn des Abh√∂rens des sicheren Ports und eine lange Pause, bevor zahlreiche Fehler bei TLS-Handshakes auftraten: <br><br><pre> <code class="plaintext hljs">20:06:48.604881 naming_controller.go:284] Starting NamingConditionController 20:06:48.605031 establishing_controller.go:73] Starting EstablishingController 20:06:50.791098 log.go:172] http: TLS handshake error from 192.168.1.155:50280: EOF 20:06:51.797710 log.go:172] http: TLS handshake error from 192.168.1.155:50286: EOF 20:06:51.971690 log.go:172] http: TLS handshake error from 192.168.1.155:50288: EOF 20:06:51.990556 log.go:172] http: TLS handshake error from 192.168.1.155:50284: EOF 20:06:52.374947 log.go:172] http: TLS handshake error from 192.168.1.155:50486: EOF 20:06:52.612617 log.go:172] http: TLS handshake error from 192.168.1.155:50298: EOF 20:06:52.748668 log.go:172] http: TLS handshake error from 192.168.1.155:50290: EOF</code> </pre> <br>  Und bald danach beendet der Server seine Arbeit.  Das Googeln f√ºhrte zu einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">solchen Problem</a> , was auf einen m√∂glichen Grund f√ºr den langsamen Betrieb kryptografischer Algorithmen auf einigen ARM-Ger√§ten hinweist. <br><br>  Ich ging weiter und dachte, dass der <code>api-server</code> m√∂glicherweise zu viele wiederholte Anfragen von <code>scheduler</code> und <code>controller-manager</code> erh√§lt. <br><br>  Wenn Sie diese Dateien aus dem Manifest-Verzeichnis entfernen, wird kubelet angewiesen, die Ausf√ºhrung der entsprechenden Pods zu stoppen: <br><br><pre> <code class="bash hljs">mkdir /etc/kubernetes/manifests.bak mv /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/manifests.bak/ mv /etc/kubernetes/manifests/kube-controller-mananger.yaml /etc/kubernetes/manifests.bak/</code> </pre> <br>  Das Anzeigen der neuesten <code>api-server</code> Protokolle zeigte, dass der Prozess nun <code>api-server</code> , jedoch nach etwa 2 Minuten immer noch zum Erliegen kam.  Dann erinnerte ich mich, dass das Manifest eine Lebendigkeitsprobe mit Zeit√ºberschreitungen enthalten k√∂nnte, die f√ºr ein so langsames Ger√§t zu niedrige Werte haben. <br><br>  Deshalb habe ich <code>/etc/kubernetes/manifests/kube-api-server.yaml</code> √ºberpr√ºft - und darin nat√ºrlich ... <br><br><pre> <code class="plaintext hljs">livenessProbe: failureThreshold: 8 httpGet: host: 192.168.1.155 path: /healthz port: 6443 scheme: HTTPS initialDelaySeconds: 15 timeoutSeconds: 15</code> </pre> <br>  Der Pod wurde nach 135 Sekunden beendet ( <code>initialDelaySeconds</code> + <code>timeoutSeconds</code> * <code>failureThreshold</code> ).  <code>initialDelaySeconds</code> auf 120 ... <br><br>  <b>Erfolg!</b>  Nun, Handshake-Fehler treten immer noch auf (vermutlich von Kubelet), aber der Start fand immer noch statt: <br><br><pre> <code class="plaintext hljs">20:06:54.957236 log.go:172] http: TLS handshake error from 192.168.1.155:50538: EOF 20:06:55.004865 log.go:172] http: TLS handshake error from 192.168.1.155:50384: EOF 20:06:55.118343 log.go:172] http: TLS handshake error from 192.168.1.155:50292: EOF 20:06:55.252586 cache.go:39] Caches are synced for autoregister controller 20:06:55.253907 cache.go:39] Caches are synced for APIServiceRegistrationController controller 20:06:55.545881 controller_utils.go:1034] Caches are synced for crd-autoregister controller ... 20:06:58.921689 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/cluster-admin 20:06:59.049373 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:discovery 20:06:59.214321 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:basic-user</code> </pre> <br>  Als der <code>api-server</code> hochgefahren war, habe ich die YAML-Dateien f√ºr den Controller und den Scheduler zur√ºck in das Manifest-Verzeichnis verschoben, wonach sie auch normal gestartet wurden. <br><br>  Jetzt m√ºssen Sie sicherstellen, dass der Download erfolgreich ist, wenn Sie alle Dateien im Quellverzeichnis <code>livenessProbe</code> : Reicht es aus, die zul√§ssige Verz√∂gerung bei der Initialisierung von <code>livenessProbe</code> ? <br><br><pre> <code class="plaintext hljs">20:29:33.306983 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.Service: Get https://192.168.1.155:6443/api/v1/services?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.434541 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.ReplicationController: Get https://192.168.1.155:6443/api/v1/replicationcontrollers?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.435799 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolume: Get https://192.168.1.155:6443/api/v1/persistentvolumes?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.477405 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1beta1.PodDisruptionBudget: Get https://192.168.1.155:6443/apis/policy/v1beta1/poddisruptionbudgets?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.493660 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolumeClaim: Get https://192.168.1.155:6443/api/v1/persistentvolumeclaims?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:37.974938 controller_utils.go:1027] Waiting for caches to sync for scheduler controller 20:29:38.078558 controller_utils.go:1034] Caches are synced for scheduler controller 20:29:38.078867 leaderelection.go:205] attempting to acquire leader lease kube-system/kube-scheduler 20:29:38.291875 leaderelection.go:214] successfully acquired lease kube-system/kube-scheduler</code> </pre> <br>  Ja, alles funktioniert, obwohl solche alten Ger√§te anscheinend nicht dazu gedacht waren, die Steuerebene zu starten, da wiederholte TLS-Verbindungen erhebliche Bremsen verursachen.  So oder so - eine funktionierende Installation von K8s auf ARM wird empfangen!  Gehen wir weiter ... <br><br><h3>  RAID-Montage </h3><br>  Da SD-Karten auf lange Sicht nicht f√ºr die Aufzeichnung geeignet sind, habe ich mich f√ºr einen zuverl√§ssigeren Speicher f√ºr die fl√ºchtigsten Teile des Dateisystems entschieden - in diesem Fall RAID.  Es wurden 4 Abschnitte hervorgehoben: <br><br><ul><li>  50 GB; </li><li>  2 √ó 20 GB; </li><li>  3,9 Tb. </li></ul><br>  Ich habe mir noch keinen konkreten Zweck f√ºr die 20-Gigabyte-Partitionen ausgedacht, aber ich wollte zus√§tzliche M√∂glichkeiten f√ºr die Zukunft lassen. <br><br>  In der <code>/etc/fstab</code> f√ºr die 50-GB-Partition der Einh√§ngepunkt als <code>/mnt/root</code> und f√ºr 3,9 TB - <code>/mnt/raid</code> .  Danach habe ich die Verzeichnisse mit etcd und Docker auf die 50-GB-Partition gemountet: <br><br><pre> <code class="plaintext hljs">UUID=655a39e8-9a5d-45f3-ae14-73b4c5ed50c3 /mnt/root ext4 defaults,rw,user,auto,exec 0 0 UUID=0633df91-017c-4b98-9b2e-4a0d27989a5c /mnt/raid ext4 defaults,rw,user,auto 0 0 /mnt/root/var/lib/etcd /var/lib/etcd none defaults,bind 0 0 /mnt/root/var/lib/docker /var/lib/docker none defaults,bind 0 0</code> </pre> <br><h3>  Ankunft ROC-RK3328-CC </h3><br>  Als das neue Board ausgeliefert wurde, habe ich die notwendigen Komponenten f√ºr K8s darauf installiert <i>(siehe Anfang des Artikels)</i> und <code>kubeadm init</code> gestartet.  Ein paar Minuten Wartezeit sind der Erfolg und die Ausgabe des <code>join</code> Befehls, der auf anderen Knoten ausgef√ºhrt werden soll. <br><br>  Gro√üartig!  Keine Aufregung mit Auszeiten. <br><br>  Und da RAID auch auf dieser Karte verwendet wird, m√ºssen die Halterungen erneut konfiguriert werden.  Um alle Schritte zusammenzufassen: <br><br><h4>  1. Mounten Sie die Festplatten in / etc / fstab </h4><br><pre> <code class="plaintext hljs">UUID=655a39e8-9a5d-45f3-ae14-73b4c5ed50c3 /mnt/root ext4 defaults,rw,user,auto,exec 0 0 UUID=0633df91-017c-4b98-9b2e-4a0d27989a5c /mnt/raid ext4 defaults,rw,user,auto 0 0 /mnt/root/var/lib/etcd /var/lib/etcd none defaults,bind 0 0 /mnt/root/var/lib/docker /var/lib/docker none defaults,bind 0 0</code> </pre> <br><h4>  2. Installieren der Docker- und K8s-Bin√§rdateien </h4><br><pre> <code class="bash hljs">curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh</code> </pre> <br><pre> <code class="bash hljs">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://apt.kubernetes.io/ kubernetes-xenial main"</span></span> &gt; /etc/apt/sources.list.d/kubernetes.list apt-get update apt-get install -y kubelet=1.13.1-00 kubectl=1.13.1-00 kubeadm=1.13.1-00</code> </pre> <br><h4>  3. Konfigurieren eines eindeutigen Hostnamens (wichtig, da viele Knoten hinzugef√ºgt werden) </h4><br><pre> <code class="bash hljs">hostnamectl <span class="hljs-built_in"><span class="hljs-built_in">set</span></span>-hostname k8s-master-1</code> </pre> <br><h4>  4. Kubernetes-Initialisierung </h4><br>  Ich lasse die Phase mit der Steuerebene weg, weil ich normale Pods auf diesem Knoten planen m√∂chte: <br><br><pre> <code class="bash hljs">kubeadm init --skip-phases mark-control-plane</code> </pre> <br><h4>  5. Installieren Sie das Netzwerk-Plugin </h4><br>  Die Informationen dazu im Hypriot-Artikel waren etwas veraltet, da das Weave-Netzwerk-Plugin jetzt auch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von ARM unterst√ºtzt wird</a> : <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f <span class="hljs-string"><span class="hljs-string">"https://cloud.weave.works/k8s/net?k8s-version=</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(kubectl version | base64 | tr -d '\n')</span></span></span><span class="hljs-string">"</span></span></code> </pre> <br><h4>  6. Hinzuf√ºgen von Host-Labels </h4><br>  Auf diesem Knoten starte ich den NAS-Server, daher werde ich ihn mit Labels f√ºr eine m√∂gliche zuk√ºnftige Verwendung im Scheduler markieren: <br><br><pre> <code class="bash hljs">kubectl label nodes k8s-master-1 marshallbrekka.raid=<span class="hljs-literal"><span class="hljs-literal">true</span></span> kubectl label nodes k8s-master-1 marshallbrekka.network=gigabit</code> </pre> <br><h3>  Andere Knoten mit dem Cluster verbinden </h3><br>  Das Einrichten anderer Ger√§te (Banana Pi, CubbieBoard) war ebenso einfach.  F√ºr sie m√ºssen Sie die ersten drei Schritte wiederholen (√Ñndern der Einstellungen f√ºr das Mounten von Festplatten / Flash-Medien, abh√§ngig von ihrer Verf√ºgbarkeit) und den Befehl <code>kubeadm join</code> anstelle von <code>kubeadm init</code> . <br><br><h2>  Suchen von Docker-Containern f√ºr ARM </h2><br>  Die meisten erforderlichen Docker-Container werden normalerweise auf einem Mac erstellt, f√ºr ARM ist dies jedoch etwas komplizierter.  Nachdem ich viele Artikel √ºber die Verwendung von QEMU f√ºr diese Zwecke gefunden hatte, kam ich dennoch zu dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schluss,</a> dass die meisten der von mir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ben√∂tigten</a> Anwendungen bereits zusammengestellt sind und viele von ihnen auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Linuxserver</a> verf√ºgbar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sind</a> . <br><br><h2>  N√§chste Schritte </h2><br>  Da ich die Erstkonfiguration der Ger√§te immer noch nicht in einer von mir <code>kubeadm</code> automatisierten / skriptbasierten Form erhalten habe, habe ich zumindest eine Reihe grundlegender Befehle (Mounts, <code>kubeadm</code> und <code>kubeadm</code> ) verfasst und diese im Git-Repository dokumentiert.  Die √ºbrigen verwendeten Anwendungen erhielten auch YAML-Konfigurationen f√ºr K8s, die im selben Repository gespeichert sind. Daher ist es jetzt sehr einfach, die erforderliche Konfiguration von Grund auf neu zu erstellen. <br><br>  In Zukunft m√∂chte ich Folgendes erreichen: <br><br><ol><li>  Master-Sites hoch verf√ºgbar machen </li><li>  Hinzuf√ºgen von √úberwachungen / Benachrichtigungen, um √ºber Fehler in Komponenten informiert zu werden; </li><li>  √Ñndern Sie die DCHP-Einstellungen des Routers so, dass ein DNS-Server aus dem Cluster verwendet wird, um die Erkennung von Anwendungen zu vereinfachen (wer m√∂chte sich die internen IP-Adressen merken?). </li><li>  F√ºhren Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MetalLB aus</a> , um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Clusterdienste</a> an ein privates Netzwerk (DNS usw.) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">weiterzuleiten</a> . </li></ol><br><br><h2>  PS vom √úbersetzer </h2><br>  Lesen Sie auch in unserem Blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tipps und Tricks von Kubernetes: zur Zuweisung von Knoten und zur Belastung der Webanwendung</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Tipps &amp; Tricks: Zugriff auf Entwicklungsseiten</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tipps und Tricks von Kubernetes: Beschleunigen des Bootstraps gro√üer Datenbanken</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">11 Wege, um (nicht) ein Opfer von Kubernetes Hacking zu werden</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spielen mit Kubernetes ist ein Service, um die K8 in der Praxis kennenzulernen</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de435526/">https://habr.com/ru/post/de435526/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de435510/index.html">Mikroelektronik, Neurophysiologie und maschinelles Lernen sch√ºtteln, aber nicht mischen</a></li>
<li><a href="../de435512/index.html">Royole Entwickler zeigen faltbares flexibles Smartphone</a></li>
<li><a href="../de435514/index.html">In Russland entwickeln sie einen Prozessor zur Beschleunigung neuronaler Netze</a></li>
<li><a href="../de435520/index.html">Wir schreiben unsere Programmiersprache, Teil 3: √úbersetzerarchitektur. Analyse von Sprachstrukturen und mathematischen Ausdr√ºcken</a></li>
<li><a href="../de435522/index.html">Ereignis-Snapshots in Axonframework 3 verbessern die Leistung</a></li>
<li><a href="../de435528/index.html">5 Gr√ºnde f√ºr den Erfolg: Warum Amazon zum teuersten Unternehmen der Welt geworden ist</a></li>
<li><a href="../de435530/index.html">Bezahlte Abonnements - Abh√§ngigkeit der automatischen Verbindung von einem mobilen Ger√§t</a></li>
<li><a href="../de435532/index.html">Tornado vs Aiohttp: Eine Reise in die Wildnis asynchroner Frameworks</a></li>
<li><a href="../de435534/index.html">Data Science: Einstiegsb√ºcher</a></li>
<li><a href="../de435536/index.html">Humanoide Roboter: Vorteile und Probleme anthropomorpher Mechanismen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
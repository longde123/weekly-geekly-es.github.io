<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüîß üé≥ üíÜüèΩ Comment collecter des m√©triques non d√©form√©es par r√©f√©rence temporelle avec Prometheus üßõ üíã üññüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="De nombreuses applications r√©seau se composent d'un serveur Web qui traite le trafic en temps r√©el et d'un gestionnaire suppl√©mentaire qui s'ex√©cute e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment collecter des m√©triques non d√©form√©es par r√©f√©rence temporelle avec Prometheus</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/470133/"><p><img src="https://habrastorage.org/webt/-6/xs/ee/-6xseehi1ojmkxmb_phq6tr3h_a.jpeg"></p><br><p>  De nombreuses applications r√©seau se composent d'un serveur Web qui traite le trafic en temps r√©el et d'un gestionnaire suppl√©mentaire qui s'ex√©cute en arri√®re-plan de mani√®re asynchrone.  Il existe de nombreux conseils utiles pour v√©rifier l'√©tat du trafic, et la communaut√© ne cesse de d√©velopper des outils comme Prometheus qui aident √† l'√©valuation.  Mais les gestionnaires ne sont parfois pas moins - et m√™me plus - importants.  Ils ont √©galement besoin d'attention et d'√©valuation, mais il y a peu de conseils sur la fa√ßon de le faire tout en √©vitant les pi√®ges courants. </p><br><p>  Cet article est consacr√© aux pi√®ges les plus courants dans le processus d'√©valuation des gestionnaires asynchrones, √† l'aide d'un exemple d'incident dans un environnement de production o√π, m√™me avec des m√©triques, il √©tait impossible de d√©terminer exactement ce que faisaient les gestionnaires.  L'utilisation de m√©triques a tellement d√©plac√© l'attention que les m√©triques elles-m√™mes ont ouvertement menti, disent-ils, √† vos gestionnaires en enfer. </p><br><p> Nous verrons comment utiliser les m√©triques de mani√®re √† fournir une estimation pr√©cise, et en conclusion, nous montrerons l'impl√©mentation de r√©f√©rence de l'open source <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prometheus-client-tracer</a> , que vous pouvez utiliser dans vos applications. </p><a name="habracut"></a><br><h3 id="incident">  Incident </h3><br><p>  Les alertes sont arriv√©es √† une vitesse mitrailleuse: le nombre d'erreurs HTTP a fortement augment√©, et les panneaux de contr√¥le ont confirm√© que les files d'attente de demandes √©taient en augmentation et que le temps de r√©ponse √©tait √©puis√©.  Environ 2 minutes plus tard, les files d'attente ont √©t√© effac√©es et tout est revenu √† la normale. </p><br><p>  En y regardant de plus pr√®s, il s'est av√©r√© que nos serveurs API se sont lev√©s, attendant une r√©ponse de la base de donn√©es, ce qui a provoqu√© le blocage et la soudaine interruption de toute l'activit√©.  Et quand on consid√®re que la charge la plus lourde tombe plus souvent au niveau des processeurs asynchrones, ils sont devenus les principaux suspects.  La question logique √©tait: que font-ils l√†-bas?! </p><br><p>  La m√©trique Prometheus montre ce que le processus prend du temps, le voici: </p><br><pre><code class="plaintext hljs"># HELP job_worked_seconds_total Sum of the time spent processing each job class # TYPE job_worked_seconds_total counter job_worked_seconds_total{job}</code> </pre> <br><p>  En suivant le temps d'ex√©cution total de chaque t√¢che et la fr√©quence √† laquelle la m√©trique change, nous d√©couvrirons combien de temps de travail a √©t√© consacr√©.  Si pour une p√©riode de 15 secondes.  le nombre a augment√© de 15, cela implique 1 gestionnaire occup√© (une seconde pour chaque seconde pass√©e), tandis qu'une augmentation de 30 signifie 2 gestionnaires, etc. </p><br><p>  Un horaire de travail pendant l'incident montrera √† quoi nous sommes confront√©s.  Les r√©sultats sont d√©cevants;  l'heure de l'incident (16: 02-16: 04) est marqu√©e par la ligne rouge alarmante: </p><br><p><img src="https://habrastorage.org/webt/33/1u/bc/331ubcimex4xb4hm_zdondnxcnw.png"><br>  <em>Activit√© du gestionnaire pendant l'incident: un √©cart notable est visible.</em> </p><br><p>  En tant que personne qui a d√©bogu√© apr√®s ce cauchemar, cela m'a fait mal de voir que la courbe d'activit√© √©tait tout en bas juste pendant l'incident.  C'est le moment de travailler avec les hooks Web, dans lesquels nous avons 20 gestionnaires d√©di√©s.  D'apr√®s les journaux, je sais qu'ils √©taient tous en activit√©, et je m'attendais √† ce que la courbe soit d'environ 20 secondes, et j'ai vu une ligne presque droite.  De plus, voir ce grand pic bleu √† 16h05?  √Ä en juger par le calendrier, 20 processeurs √† un seul thread ont pass√© 45 secondes.  pour chaque seconde d'activit√©, mais est-ce possible?! </p><br><h3 id="gde-i-chto-poshlo-ne-tak">  O√π et qu'est-ce qui a mal tourn√©? </h3><br><p>  Le calendrier de l'incident est mensonger: il masque l'activit√© de travail et montre en m√™me temps des choses inutiles - selon l'endroit o√π mesurer.  Pour savoir pourquoi cela se produit, vous devez prendre en compte la mise en ≈ìuvre du suivi des m√©triques et comment il interagit avec la collecte des m√©triques par Prometheus. </p><br><p>  En commen√ßant par la fa√ßon dont les gestionnaires collectent les m√©triques, vous pouvez esquisser un sch√©ma d'impl√©mentation de workflow approximatif (voir ci-dessous).  Remarque: les gestionnaires <em>ne</em> mettent √† jour les mesures <em>qu'√† la fin d'une t√¢che</em> . </p><br><pre> <code class="plaintext hljs">class Worker JobWorkedSecondsTotal = Prometheus::Client::Counter.new(...) def work job = acquire_job start = Time.monotonic_now job.run ensure # run after our main method block duration = Time.monotonic_now - start JobWorkedSecondsTotal.increment(by: duration, labels: { job: job.class }) end end</code> </pre> <br><p>  Prometheus (avec sa philosophie d'extraction de m√©triques) envoie une requ√™te GET √† chaque gestionnaire toutes les 15 secondes, enregistrant les valeurs des m√©triques au moment de la demande.  Les gestionnaires mettent constamment √† jour les mesures des t√¢ches termin√©es et, au fil du temps, nous pouvons afficher graphiquement la dynamique des changements de valeurs. </p><br><p>  Le probl√®me de sous-√©valuation et de r√©√©valuation commence √† appara√Ætre chaque fois que le temps n√©cessaire pour terminer une t√¢che d√©passe le temps d'attente pour une demande qui arrive toutes les 15 secondes.  Par exemple, une t√¢che d√©marre 5 secondes avant la demande et se termine 1 seconde apr√®s.  Enti√®rement et g√©n√©ralement, il dure 6 secondes, mais ce temps n'est visible que lors de l'estimation des co√ªts de temps effectu√©s apr√®s la demande, alors que 5 de ces 6 secondes sont pass√©es avant la demande. </p><br><p>  Les indicateurs sont encore plus impies si les t√¢ches prennent plus de temps que la p√©riode de rapport (15 secondes). Pendant l'ex√©cution de la t√¢che pendant 1 minute, Prometheus aura le temps d'envoyer 4 demandes aux processeurs, mais la m√©trique ne sera mise √† jour qu'apr√®s la quatri√®me. </p><br><p>  Apr√®s avoir trac√© une chronologie de l'activit√© de travail, nous verrons comment le moment o√π la m√©trique est mise √† jour affecte ce que voit Prom√©th√©e.  Dans le diagramme ci-dessous, nous divisons la chronologie de deux gestionnaires en plusieurs segments qui affichent des t√¢ches de dur√©es diff√©rentes.  Les √©tiquettes rouges (15 secondes) et bleues (30 secondes) indiquent 2 √©chantillons de donn√©es Prometheus;  Les t√¢ches qui ont servi de source de donn√©es pour l'√©valuation sont respectivement surlign√©es en couleur. </p><br><p><img src="https://habrastorage.org/webt/ph/lc/z6/phlcz67lq7o3tpar3vgibp71h9o.png"></p><br><p>  Ind√©pendamment de ce que les gestionnaires font √† pleine charge, ils effectueront 30 secondes de travail toutes les 15 secondes.  √âtant donn√© que Prometheus ne voit pas le travail jusqu'√† ce qu'il soit termin√©, √† en juger par les m√©triques, 14 secondes de travail ont √©t√© achev√©es dans le premier intervalle de temps et 42 secondes dans le second.  Si chaque gestionnaire entreprend une t√¢che volumineuse, alors m√™me apr√®s quelques heures, jusqu'√† la fin, nous ne verrons aucun rapport indiquant que le travail est en cours. </p><br><p>  Pour d√©montrer cet effet, j'ai men√© une exp√©rience avec dix gestionnaires engag√©s dans des t√¢ches dont la longueur est diff√©rente et semi-normale r√©partie entre 0,1 seconde et une valeur l√©g√®rement sup√©rieure (voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">t√¢ches al√©atoires</a> ).  Vous trouverez ci-dessous 3 graphiques d√©crivant l'activit√© professionnelle;  la dur√©e dans le temps est indiqu√©e dans l'ordre croissant. </p><br><p><img src="https://habrastorage.org/webt/6o/bx/jh/6obxjhklfq8sxwhdbjrzpnsgcmm.png"><br>  <em>T√¢ches pouvant durer jusqu'√† 1 seconde.</em> </p><br><p>  Le premier graphique montre que chaque gestionnaire accomplit environ 1 seconde de travail √† chaque seconde - cela est visible sur des lignes plates et la quantit√© totale de travail est √©gale √† nos capacit√©s (10 gestionnaires donnent une seconde de travail par seconde de temps).  En fait, cela, quelle que soit la dur√©e de la t√¢che, nous nous attendons: tant pour les t√¢ches courtes et longues, les processeurs √† charge constante devraient c√©der. </p><br><p><img src="https://habrastorage.org/webt/x-/lj/zp/x-ljzpfv-jdybqpk-osmcfd3rui.png"><br>  <em>T√¢ches pouvant durer jusqu'√† 15 secondes.</em> </p><br><p>  La dur√©e des t√¢ches augmente et un g√¢chis appara√Æt dans le calendrier: nous avons encore 10 processeurs, tous sont enti√®rement occup√©s, mais la quantit√© totale de travail saute - inf√©rieure ou sup√©rieure √† la limite de capacit√© utile (10 secondes). </p><br><p><img src="https://habrastorage.org/webt/uo/cc/mh/uoccmht2erjrgjywbvlo7sn6-tk.png"><br>  <em>T√¢ches pouvant durer jusqu'√† 30 secondes.</em> </p><br><p>  L'√©valuation de travaux pouvant durer jusqu'√† 30 secondes est tout simplement ridicule.  Une mesure limit√©e dans le temps affiche une activit√© nulle pour les t√¢ches les plus longues et, uniquement lorsque les t√¢ches sont termin√©es, nous trace des pics d'activit√©. </p><br><h3 id="vosstanovim-doverie">  Restaurer la confiance </h3><br><p>  Ce n'√©tait pas suffisant pour nous, il y a donc un autre probl√®me beaucoup plus insidieux avec ces t√¢ches √† long terme qui g√¢chent nos mesures.  Chaque fois qu'une t√¢che √† long terme se termine - par exemple, si Kubernetes jette un pod hors d'un pool, ou lorsqu'un n≈ìud meurt, qu'advient-il des mesures?  Cela vaut la peine de les mettre √† jour imm√©diatement √† la fin de la t√¢che, car ils montrent <strong>qu'ils n'ont pas du tout fait le</strong> travail. </p><br><p>  Les mesures ne devraient pas mentir.  L'ordinateur portable hurle incr√©dule, provoquant l'horreur existentielle, et les outils de surveillance qui d√©forment l'image du monde sont un pi√®ge et ne conviennent pas au travail. </p><br><p>  Heureusement, le probl√®me peut √™tre r√©solu.  La distorsion des donn√©es se produit car Prometheus prend des mesures ind√©pendamment du moment o√π les processeurs mettent √† jour les mesures.  Si nous demandons aux gestionnaires de mettre √† jour les m√©triques lorsque Prometheus envoie des demandes, nous verrons que Prometheus n'est plus excentrique et affiche l'activit√© actuelle. </p><br><h3 id="predstavlyaem-tracer">  Pr√©sentation ... Tracer </h3><br><p>  Une solution au probl√®me des m√©triques d√©form√©es est le <code>Tracer</code> , un mod√®le abstrait qui √©value l'activit√© sur les t√¢ches de longue dur√©e en mettant √† jour progressivement les m√©triques li√©es √† Prometheus. </p><br><pre> <code class="plaintext hljs">class Tracer def trace(metric, labels, &amp;block) ... end def collect(traces = @traces) ... end end</code> </pre> <br><p>  Les traceurs fournissent une m√©thode de tra√ßage qui prend les m√©triques Prometheus et la t√¢che √† suivre.  La commande <code>trace</code> ex√©cutera le bloc donn√© (fonctions Ruby anonymes) et garantit que les demandes <code>tracer.collect</code> √† <code>tracer.collect</code> pendant l'ex√©cution mettront progressivement √† jour les mesures associ√©es, quel que soit le temps √©coul√© depuis la derni√®re demande de <code>collect</code> . </p><br><p>  Nous devons connecter le <code>tracer</code> aux gestionnaires afin de suivre la dur√©e de la t√¢che et le point de terminaison desservant les requ√™tes m√©triques Prometheus.  Nous commen√ßons par les gestionnaires, initialisons un nouveau traceur et lui demandons de suivre l‚Äôex√©cution d‚Äô <code>acquire_job.run</code> . </p><br><pre> <code class="plaintext hljs">class Worker def initialize @tracer = Tracer.new(self) end def work @tracer.trace(JobWorkedSecondsTotal, labels) { acquire_job.run } end # Tell the tracer to flush (incremental) trace progress to metrics def collect @tracer.collect end end</code> </pre> <br><p>  √Ä ce stade, tracer ne mettra √† jour les m√©triques qu'en secondes consacr√©es √† la t√¢che termin√©e - comme nous l'avons fait lors de la mise en ≈ìuvre initiale des m√©triques.  Nous devons demander √† tracer de mettre √† jour nos mesures avant d'ex√©cuter une demande de Prometheus.  Cela peut √™tre fait en configurant le rack middleware. </p><br><pre> <code class="plaintext hljs"># config.ru # https://rack.github.io/ class WorkerCollector def initialize(@app, workers: @workers); end def call(env) workers.each(&amp;:collect) @app.call(env) # call Prometheus::Exporter end end # Rack middleware DSL workers = start_workers # Array[Worker] # Run the collector before serving metrics use WorkerCollector, workers: workers use Prometheus::Middleware::Exporter</code> </pre> <br><p>  Rack est une interface pour les serveurs Web Ruby qui vous permet de combiner plusieurs gestionnaires de rack en un seul point de terminaison.  La commande <code>config.ru</code> d√©termine que l'application Rack - chaque fois qu'elle re√ßoit la demande - envoie d'abord la commande <code>collect</code> aux gestionnaires, puis ne demande au client Prometheus de dessiner les r√©sultats de la collecte. </p><br><p>  Quant √† notre graphique, nous mettons √† jour les m√©triques chaque fois que la t√¢che se termine ou lorsque nous recevons une demande de m√©triques.  Les t√¢ches qui ont plusieurs requ√™tes envoient √©galement des donn√©es sur tous les segments: comme le montrent les t√¢ches dont la dur√©e a √©t√© divis√©e en intervalles de 15 secondes. </p><br><p><img src="https://habrastorage.org/webt/v3/p-/ve/v3p-vekym_g0w_cnamhqxfsaaya.png"></p><br><h3 id="luchshe-li-eto">  Est-ce mieux? </h3><br><p>  L'utilisation de Tracer 24 heures sur 24 affecte la fa√ßon dont l'activit√© est enregistr√©e.  Contrairement aux mesures initiales, qui montraient une ¬´scie¬ª, lorsque le nombre de pics d√©passait le nombre de processeurs en cours d'ex√©cution et les p√©riodes de silence ennuyeux, l'exp√©rience avec dix processeurs fournit un graphique montrant clairement que chaque processeur est int√©gr√© dans le travail surveill√© de mani√®re √©gale. </p><br><p><img src="https://habrastorage.org/webt/a5/ng/lj/a5ngljwtmc1ppqxlpwjqdx98_eu.png"><br>  <em>Mesures bas√©es sur la comparaison (√† gauche) et contr√¥l√©es par un traceur (√† droite), tir√©es d'une exp√©rience de travail.</em> </p><br><p>  Par rapport au calendrier franchement inexact et chaotique des mesures initiales, les m√©triques collect√©es par le traceur sont lisses et coh√©rentes.  Nous lions maintenant non seulement le travail √† chaque demande de m√©trique avec pr√©cision, mais nous ne nous inqui√©tons pas non plus de la mort soudaine de l'un des gestionnaires: Prometheus enregistre les m√©triques jusqu'√† la disparition du gestionnaire, √©valuant tout son travail. </p><br><h3 id="mozhno-li-eto-ispolzovat">  Peut-il √™tre utilis√©? </h3><br><p>  Oui!  L'interface <code>Tracer</code> m'a √©t√© utile dans de nombreux projets, il s'agit donc d'un joyau Ruby distinct, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prometheus-client-tracer</a> .  Si vous utilisez le client Prometheus dans vos applications Ruby, ajoutez simplement le <code>prometheus-client-tracer</code> √† votre Gemfile: </p><br><pre> <code class="plaintext hljs">require "prometheus/client" require "prometheus/client/tracer" JobWorkedSecondsTotal = Prometheus::Client::Counter.new(...) Prometheus::Client.trace(JobWorkedSecondsTotal) do sleep(long_time) end</code> </pre> <br><p>  Si cela vous est utile et si vous souhaitez que le client officiel de Prometheus Ruby apparaisse dans <code>Tracer</code> , laissez un avis dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">client_ruby # 135</a> . </p><br><h3 id="nu-i-naposledok-koe-kakie-mysli">  Et enfin, quelques r√©flexions </h3><br><p>  J'esp√®re que cela aide les autres √† collecter plus consciemment des mesures pour les t√¢ches de longue dur√©e et √† r√©soudre l'un des probl√®mes courants.  Ne vous y trompez pas, il est associ√© non seulement au traitement asynchrone: si vos requ√™tes HTTP sont ralenties, elles b√©n√©ficieront √©galement de l'utilisation de tracer lors de l'√©valuation du temps consacr√© au traitement. </p><br><p>  Comme d'habitude, tous les commentaires et corrections sont les bienvenus: √©crivez sur Twitter ou <a href="">ouvrez PR</a> .  Si vous souhaitez contribuer √† tracer gem, le code source se trouve sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prometheus-client-tracer-ruby</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr470133/">https://habr.com/ru/post/fr470133/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr470121/index.html">√âcoles de programmation d'entreprise ou comment entrer en informatique</a></li>
<li><a href="../fr470123/index.html">Pi√®ge financier Yandex.Money</a></li>
<li><a href="../fr470125/index.html">Ne jugez pas strictement le code de quelqu'un d'autre</a></li>
<li><a href="../fr470127/index.html">Compositeur avec une longue m√©moire √† court terme</a></li>
<li><a href="../fr470129/index.html">Gestion de la m√©moire d√©clarative</a></li>
<li><a href="../fr470135/index.html">Une application web interactive sans programmation? C'est facile! Mavo dans tes bras</a></li>
<li><a href="../fr470145/index.html">"Attention, SAF!": Pourquoi le ticket militaire est-il dangereux dans la publicit√©, pourquoi est-il important de conna√Ætre les math√©matiques et si la v√©rit√© nue est toujours n√©cessaire</a></li>
<li><a href="../fr470149/index.html">Il n'y aura pas de collections immuables en Java - ni maintenant ni jamais</a></li>
<li><a href="../fr470153/index.html">Dictionnaire du mod√®le de donn√©es</a></li>
<li><a href="../fr470159/index.html">Prime Generation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
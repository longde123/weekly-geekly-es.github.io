<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙅🏽 👆 🥘 Apprentissage automatique: brouillez avec un éléphant de chambre 🏯 🚣🏼 👩🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'un est nul en faveur du cerveau humain. Dans une nouvelle étude , des informaticiens ont découvert que les systèmes d'intelligence artificielle ne r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apprentissage automatique: brouillez avec un éléphant de chambre</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/wirex/blog/424855/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/z_/dt/lt/z_dtlta9hixvv2wmckf9fsaxzpo.jpeg"></div><br>  L'un est nul en faveur du cerveau humain.  Dans une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nouvelle étude</a> , des informaticiens ont découvert que les systèmes d'intelligence artificielle ne réussissent pas le test de reconnaissance visuelle des objets que tout enfant peut facilement manipuler. <br><br>  «Cette étude qualitative et importante nous rappelle que le« deep learning »lui-même ne peut pas se vanter de la profondeur qui lui est attribuée», explique Gary Marcus, neuroscientifique à l'Université de New York qui n'est pas associé à ce travail. <br><br>  Les résultats de l'étude concernent le domaine de la vision par ordinateur, lorsque les systèmes d'intelligence artificielle tentent de détecter et de catégoriser des objets.  Par exemple, on peut leur demander de trouver tous les piétons dans la scène de rue ou simplement de distinguer un oiseau d'un vélo - une tâche qui est déjà devenue célèbre pour sa complexité. <br><br>  L'enjeu est de taille: les ordinateurs commencent progressivement à effectuer des opérations importantes pour les personnes, comme la vidéosurveillance automatique et la conduite autonome.  Et pour un travail réussi, il est nécessaire que la capacité de l'IA au traitement visuel ne soit au moins pas inférieure à celle de l'homme. <br><br>  La tâche n'est pas facile. <a name="habracut"></a>  La nouvelle étude se concentre sur la sophistication de la vision humaine et les difficultés à créer des systèmes d'imitation.  Les scientifiques ont testé la précision d'un système de vision par ordinateur en utilisant l'exemple d'un salon.  AI a bien fait, identifiant correctement la chaise, la personne et les livres sur l'étagère.  Mais lorsque les scientifiques ont ajouté un objet inhabituel à la scène - l'image d'un éléphant - le fait même de son apparence a fait oublier au système tous les résultats précédents.  Soudain, elle a commencé à appeler la chaise un canapé, l'éléphant une chaise et à ignorer tous les autres objets. <br><br>  «Il y avait une variété de bizarreries qui montraient la fragilité des systèmes modernes de détection d'objets», explique Amir Rosenfeld, scientifique de l'Université York à Toronto et co-auteur d'une étude que lui et ses collègues <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">John Totsotsos</a> , également de York, et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Richard Zemel</a> de l'Université de Toronto. <br><br>  Les chercheurs tentent toujours de clarifier les raisons pour lesquelles le système de vision par ordinateur est si facilement dérouté, et ils ont déjà une bonne supposition.  Le point de compétence humaine, que l'IA n'a pas, est la capacité de réaliser que la scène est incompréhensible, et nous devons y réfléchir de plus près. <br><br><h3>  Éléphant dans la chambre </h3><br>  En regardant le monde, nous percevons une quantité stupéfiante d'informations visuelles.  Le cerveau humain le traite en déplacement.  «Nous ouvrons les yeux et tout se passe tout seul», explique Totsotsos. <br><br>  L'intelligence artificielle, en revanche, crée une impression visuelle minutieusement, comme si elle lisait une description en braille.  Il parcourt le bout de ses doigts algorithmiques à travers les pixels, en formant progressivement à partir d'eux des représentations de plus en plus complexes.  Une variété de systèmes d'IA qui exécutent des processus similaires sont les réseaux de neurones.  Ils passent une image à travers une série de «couches».  Au fur et à mesure que chaque couche passe, des détails d'image individuels, tels que la couleur et la luminosité de pixels individuels, sont traités et une description de plus en plus abstraite de l'objet est formée sur la base de cette analyse. <br><br>  «Les résultats du traitement de la couche précédente sont transférés à la suivante, et ainsi de suite, comme sur un convoyeur», explique Totsotsos. <br><br><img src="https://habrastorage.org/webt/fs/y6/bk/fsy6bkburvogjselmt3vj45lwye.jpeg"><br>  <i>Publié par: Lucy Reading-Ikkanda / Quanta Magazine</i> <br><br>  Les réseaux de neurones sont des experts dans des tâches de routine spécifiques dans le domaine du traitement visuel.  Ils sont meilleurs que les humains pour faire face à des tâches hautement spécialisées telles que la détermination de la race de chiens et d'autres tri d'objets en catégories.  Ces exemples réussis ont fait naître l'espoir que les systèmes de vision par ordinateur deviendront bientôt si intelligents qu'ils pourront conduire une voiture dans les rues bondées de la ville. <br><br>  Cela a également incité des experts à explorer leurs vulnérabilités.  Au cours des dernières années, les chercheurs ont tenté à plusieurs reprises de simuler des attaques hostiles - ils ont proposé des scénarios qui obligent les réseaux de neurones à commettre des erreurs.  Dans une expérience, des informaticiens ont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">trompé le</a> réseau, l'obligeant à prendre la tortue pour une arme à feu.  Une autre histoire de tricherie réussie était que, à côté d'objets ordinaires comme une banane, les chercheurs ont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">placé</a> un grille-pain peint en couleurs psychédéliques sur l'image. <br><br>  Dans le nouveau travail, les scientifiques ont choisi la même approche.  Trois chercheurs ont montré une photographie du réseau neuronal d'un salon.  Il capture un homme qui joue à un jeu vidéo, assis sur le bord d'une vieille chaise et se penchant en avant.  "Digérant" cette scène, AI a rapidement reconnu plusieurs objets: une personne, un canapé, une télévision, une chaise et quelques livres. <br><br>  Ensuite, les chercheurs ont ajouté un objet inhabituel pour des scènes similaires: une image d'un éléphant dans un demi-profil.  Et le réseau neuronal est confus.  Dans certains cas, l'apparition d'un éléphant l'a forcée à prendre une chaise pour un canapé, et parfois le système a cessé de voir certains objets, avec la reconnaissance de qui auparavant il n'y avait pas de problèmes.  Ceci, par exemple, est une série de livres.  De plus, des échecs sont survenus même avec des objets situés loin de l'éléphant. <br><br><img src="https://habrastorage.org/webt/j9/bv/bj/j9bvbj3ovfqo2utjxnif5roeinc.jpeg"><br>  <i>Sur l'original à gauche, le réseau de neurones a identifié correctement et avec une grande confiance de nombreux objets situés dans le salon plein de choses diverses.</i>  <i>Mais dès que l'éléphant a été ajouté (image à droite), le programme a commencé à planter.</i>  <i>La chaise dans le coin inférieur gauche s'est transformée en canapé, la tasse à côté d'elle a disparu et l'éléphant est devenu une chaise.</i> <br><br>  Des erreurs de système similaires sont totalement inacceptables pour la même conduite autonome.  L'ordinateur ne pourra pas conduire la voiture s'il ne remarque pas les piétons simplement parce que quelques secondes auparavant il a vu une dinde sur le bord de la route. <br><br>  Quant à l'éléphant lui-même, les résultats de sa reconnaissance diffèrent également d'une tentative à l'autre.  Le système l'a ensuite déterminé correctement, parfois appelé mouton, puis ne l'a pas remarqué du tout. <br><br>  "Si un éléphant apparaît vraiment dans la pièce, n'importe qui le remarquera probablement", explique Rosenfeld.  "Et le système n'a même pas enregistré sa présence." <br><br><h3>  Relation étroite </h3><br>  Lorsque les gens voient quelque chose d'inattendu, ils le regardent mieux.  Aussi simple que cela puisse paraître, «regardez de plus près», cela a de réelles conséquences cognitives et explique pourquoi l'IA se trompe quand quelque chose d'inhabituel apparaît. <br><br>  Lors du traitement et de la reconnaissance d'objets, les meilleurs réseaux de neurones modernes ne transmettent les informations d'eux-mêmes que vers l'avant.  Ils commencent par sélectionner des pixels à l'entrée, puis passent aux courbes, formes et scènes, et font les suppositions les plus probables à chaque étape.  Toute idée fausse dans les premières étapes du processus conduit à des erreurs à la fin lorsque le réseau neuronal rassemble ses «pensées» pour deviner ce qu'il regarde. <br><br>  "Dans les réseaux de neurones, tous les processus sont étroitement interconnectés les uns aux autres, il est donc toujours possible que n'importe quelle fonctionnalité n'importe où puisse affecter n'importe quel résultat possible", explique Totsosos. <br><br>  L'approche humaine est meilleure.  Imaginez que l'on vous donne un rapide coup d'œil sur une image qui a un cercle et un carré, l'un rouge, l'autre bleu.  Après cela, on vous a demandé de nommer la couleur du carré.  Un bref coup d'œil peut ne pas être suffisant pour se souvenir correctement des couleurs.  Vient immédiatement la compréhension que vous n'êtes pas sûr et que vous devez regarder à nouveau.  Et, ce qui est très important, lors de la deuxième visualisation, vous saurez déjà sur quoi vous devez vous concentrer. <br><br>  "Le système visuel humain dit:" Je ne peux toujours pas donner la bonne réponse, je vais donc revenir en arrière et vérifier où l'erreur aurait pu se produire ", explique Totsotsos, qui développe une théorie appelée" <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">harmonisation sélective</a> "qui explique cette caractéristique de la perception visuelle. <br><br>  La plupart des réseaux de neurones n'ont pas la possibilité de revenir en arrière.  Cette fonctionnalité est très difficile à concevoir.  L'un des avantages des réseaux unidirectionnels est qu'ils sont relativement faciles à former - il suffit de «passer» les images à travers les six couches mentionnées et d'obtenir le résultat.  Mais si les réseaux de neurones doivent «regarder de près», ils doivent également faire la distinction entre une ligne fine, quand il vaut mieux revenir en arrière et quand continuer à travailler.  Le cerveau humain bascule facilement et naturellement entre ces différents processus.  Et les réseaux de neurones ont besoin d'une nouvelle base théorique pour pouvoir faire de même. <br><br>  D'éminents chercheurs du monde entier travaillent dans ce sens, mais ils ont également besoin d'aide.  Récemment, le projet Google AI a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">annoncé un concours</a> pour les classificateurs d'images de crowdsourcing qui peuvent distinguer les cas de distorsion d'image intentionnelle.  La solution qui permet de distinguer clairement l'image de l'oiseau de l'image du vélo l'emportera.  Ce sera une première étape modeste mais très importante. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/files/4bd/bf6/597/4bdbf659775744b1bdbb4d8a00a0a980.png" alt="image"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr424855/">https://habr.com/ru/post/fr424855/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr424845/index.html">Calculer des carrés magiques à l'aide d'un GPU</a></li>
<li><a href="../fr424847/index.html">MNaaS et eSIM - avantages et inconvénients de la virtualisation pour les opérateurs mobiles et leurs clients</a></li>
<li><a href="../fr424849/index.html">Ce qui rend le nouvel UCS C480 ML M5 intéressant - serveur d'apprentissage machine de Cisco</a></li>
<li><a href="../fr424851/index.html">Quel est le problème avec l'embauche informatique?</a></li>
<li><a href="../fr424853/index.html">L'histoire d'un contrôleur de vue qui voulait bien se montrer</a></li>
<li><a href="../fr424857/index.html">Prise en charge SNF chiffrée implémentée par CloudFlare</a></li>
<li><a href="../fr424859/index.html">Le jeu Arduino le plus simple avec un écran 1602 - Partie # 1</a></li>
<li><a href="../fr424861/index.html">Un serpent dans la boîte aux lettres et qu'est-ce que F #</a></li>
<li><a href="../fr424865/index.html">Découverte de particules de conception élémentaire</a></li>
<li><a href="../fr424867/index.html">Développement hexapode à partir de zéro (partie 1) - conception</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
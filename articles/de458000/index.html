<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóÉÔ∏è ü§±üèø üèº Beurteilung der menschlichen Pose auf Bildern f√ºr iOS üî± üë©üèæ‚Äçüîß üë®‚Äçüë®‚Äçüë¶‚Äçüë¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Beurteilung der menschlichen Pose 


 Vor einigen Monaten bin ich auf ein interessantes Open-Source-Projekt im Internet gesto√üen - Openpose, dessen Zi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Beurteilung der menschlichen Pose auf Bildern f√ºr iOS</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458000/"><h1 id="human-pose-estimation">  Beurteilung der menschlichen Pose </h1><br><p> Vor einigen Monaten bin ich auf ein interessantes Open-Source-Projekt im Internet gesto√üen - Openpose, dessen Ziel es ist, eine menschliche Pose in Echtzeit in einem Videostream zu sch√§tzen.  Aufgrund meiner beruflichen Aktivit√§ten war ich daran interessiert, es auf dem neuesten iOS-Ger√§t von Apple auszuf√ºhren, um die Leistung zu √ºberpr√ºfen und herauszufinden, ob dies √ºberhaupt m√∂glich ist.  Es war auch interessant zu sehen, wie sich die Leistung des neuronalen Netzwerk-Frameworks f√ºr iOS in den letzten Jahren ge√§ndert hat. </p><a name="habracut"></a><br><p>  Das urspr√ºngliche Openpose-Projekt ist in C ++ geschrieben und verwendet nicht das CoreML - das neuronale Netzwerk-Framework unter iOS.  Daher musste ich einen Kernteil in Swift neu schreiben und CoreML verwenden, um den abschlie√üenden Job zu erledigen.  Schauen wir uns das folgende Bild an, wie der menschliche K√∂rper dargestellt wird: </p><br><p><img src="https://habrastorage.org/webt/mm/32/j7/mm32j7gnh-kswdkpd37yuo1kyyq.png"></p><br><p>  Weitere Informationen zum menschlichen Posenmodell finden Sie hier: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MPI-Pose</a> </p><br><p>  Das Ergebnis ist im Bild unten dargestellt: </p><br><div class="scrollable-table"><table><thead><tr><th>  F√ºr die Demo habe ich Bilder mitgenommen) </th><th>  Die resultierende Sch√§tzung der menschlichen Pose wird √ºber das Originalbild gezogen </th></tr></thead><tbody><tr><td><img src="https://habrastorage.org/webt/aa/xj/ls/aaxjls3wjnghu4ebwbjbquaz0hc.png"></td><td><img src="https://habrastorage.org/webt/et/j0/td/etj0tdcpt0cch351fqasuyj-zkm.png"></td></tr></tbody></table></div><br><h2 id="preparing-the-model">  Modell vorbereiten </h2><br><p>  Um das Framework verwenden zu k√∂nnen, muss ein Core ML-Modell erstellt werden.  Dieses Modell basiert auf einem Modell aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Openpose-Projekt</a> .  F√ºhren Sie die folgenden Schritte aus, um ein Modell vorzubereiten: <br>  1) Installieren Sie Python- und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CoreML-Tools</a> <br>  2) F√ºhren Sie models / getModels.sh von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Open Pose aus</a> , um die urspr√ºnglichen Openpose-Modelle zu erhalten <br>  3) Kopieren Sie models /pose / mpi /pose_deploy_linevec_faster_4_stages.prototxt in models /pose / mpi /pose_deploy_linevec_faster_4_stages_fixed_size.prototxt <br>  4) √Ñndern Sie Folgendes in der Dateipose_deploy_linevec_faster_4_stages_fixed_size.prototxt: </p><br><pre><code class="plaintext hljs">input_dim: 1 # This value will be defined at runtime -&gt; input_dim: 512 input_dim: 1 # This value will be defined at runtime -&gt; input_dim: 512</code> </pre> <br><p>  5) Erstellen Sie einen Link zum Modellverzeichnis.  Nehmen wir an, dass sich das Pose Framework-Projekt und das Openpose-Projekt im Ausgangsverzeichnis befinden. Ein Befehl zum Erstellen eines Links lautet dann wie folgt: </p><br><p> <code>ln -s ~/openpose/models ~/models</code> </p> <br><p>  6) Gehen Sie zu ~ /pose /pose / CoreMLModels und f√ºhren Sie den folgenden Befehl aus: </p><br><p> <code>python convertModel.py</code> </p> <cut></cut><br><p>  Das oben genannte Skript enth√§lt fest codierte Werte f√ºr die Dateipose_deploy_linevec_faster_4_stages_fixed_size.prototxt und die Modelldateipose_iter_160000.caffemodel. <br>  Sie k√∂nnten in ein anderes Modell ge√§ndert werden. Vergessen Sie jedoch nicht, die .prototxt-Datei so zu √§ndern, dass das Eingabebild eine feste Gr√∂√üe hat: <br>  input_dim: XXX - entspricht dem with des NN-Eingangs. <br>  input_dim: XXX - entspricht der H√∂he des NN-Eingangs. <br>  <strong>Vergessen Sie auch nicht, die Modellkonfiguration PoseModelConfigurationMPI15.inputSize auf einen angegebenen Eingabewert zu √§ndern</strong> und diese Konfiguration anstelle einer vorhandenen im Framework zu verwenden, die 512 x 512 als Eingabegr√∂√üe festlegt. </p><br><p>  Alle Werte funktionieren, aber die besten Ergebnisse k√∂nnen erzielt werden, wenn ein Seitenverh√§ltnis mit dem eines Originalbilds √ºbereinstimmt.  Es sollte auch ber√ºcksichtigt werden, dass gr√∂√üere Werte die Leistung erheblich beeinflussen, was im Abschnitt Leistung gezeigt wird. </p><cut></cut><br><h2 id="neural-network-output-details">  Details zur Ausgabe des neuronalen Netzwerks </h2><br><p>  Schauen wir uns die Ausgabe des NN genauer an.  Die Ausgabe des MPI15-Modells ist eine Gruppe von Matrizen mit Dimensionen <code>(input_image_width / 8, input_image_height / 8)</code> .  Jedes Element in der Matrix hat den Float-Typ.  Zuordnung zwischen dem Matrixindex in der Ausgabe und dem K√∂rperteil: </p><br><pre> <code class="plaintext hljs">POSE_MPI_BODY_PARTS { {0, "Head"}, {1, "Neck"}, {2, "RShoulder"}, {3, "RElbow"}, {4, "RWrist"}, {5, "LShoulder"}, {6, "LElbow"}, {7, "LWrist"}, {8, "RHip"}, {9, "RKnee"}, {10, "RAnkle"}, {11, "LHip"}, {12, "LKnee"}, {13, "LAnkle"}, {14, "Chest"}, {15, "Background"} };</code> </pre> <br><p>  Da jede Matrix eine feste Gr√∂√üe hat, die auf eine bestimmte zugreift, handelt es sich um eine Trifial-Read-by-Offset-Operation: [Background] = NNOutput [sizeOfTheMatrix * 15] </p><br><h3 id="heatmaps-and-pafs">  Heatmaps und PAFs </h3><br><p>  Im MPI15-Modell gibt es zwei Arten von Ausgabematrizen.  Diejenigen, die Heatmaps darstellen, und die anderen, die PAFs darstellen.  Jede W√§rmematrix entspricht einem Verbindungsteil, das insgesamt 15 betr√§gt.  Die PAF-Matrizen repr√§sentieren K√∂rperverbindungen.  F√ºr jede K√∂rperverbindung gibt es eine X- und Y-Matrix, die insgesamt 28 betr√§gt (14 + 14).  Die Gesamtzahl der Matrizen einschlie√ülich einer Hintergrundmatrize betr√§gt 44. </p><br><h2 id="demo-project">  Demo-Projekt </h2><br><p>  Das Repository des Projekts enth√§lt auch ein Demo-Projekt'poseDemo ', das die Verwendung des Frameworks demonstriert.  Die NN-Ergebnismatrizen f√ºr ein bestimmtes Eingabebild sind nachstehend aufgef√ºhrt: </p><br><div class="scrollable-table"><table><thead><tr><th>  Probe </th><th>  Bilder </th></tr></thead><tbody><tr><td>  Ergebnis der menschlichen Pose: </td><td>  Heatmaps zu einem Bild zusammengefasst.  Jedes Gelenk hat seine eigene Farbe: </td></tr><tr><td><img src="https://habrastorage.org/webt/et/j0/td/etj0tdcpt0cch351fqasuyj-zkm.png"></td><td><img src="https://habrastorage.org/webt/4h/7w/up/4h7wupwmcjmp5olhatqmorir21a.png"></td></tr><tr><td>  PAFs in einem Bild zusammengefasst: </td><td>  Alle Heatmap-Kandidaten.  Jeder Kandidat hat sein eigenes Vertrauen, das seine Deckkraft auf dem Bild definiert: </td></tr><tr><td><img src="https://habrastorage.org/webt/o-/3e/ny/o-3enyfxzfqbt_hnrlczexwariw.png"></td><td><img src="https://habrastorage.org/webt/9p/ns/m5/9pnsm5kp_2ur1isvguujlzm7shg.png"></td></tr><tr><td>  Schauen Sie sich die Heatmap-Kandidaten, die einem Kopf entsprechen, genauer an: </td><td>  Schauen Sie sich die Heatmap-Kandidaten, die einem Hals entsprechen, genauer an: </td></tr><tr><td><img src="https://habrastorage.org/webt/rg/zn/im/rgznimptilj3acm7cs6qu6fdcve.png"></td><td><img src="https://habrastorage.org/webt/7k/hl/ru/7khlrub0jznpecotxdb9hpfvda8.png"></td></tr><tr><td>  PAF-Matrix, die einem Kopf-Hals-Verbindungskandidaten entspricht.  Die Kopf-Hals-Heatmap-Gelenke sind ebenfalls auf dem Bild dargestellt: </td><td>  PAF-Matrix, die einem LShoulder-LElbow-Verbindungskandidaten entspricht.  Die LShoulder-LElbow-Heatmap-Gelenke sind auch auf dem Bild dargestellt: </td></tr><tr><td><img src="https://habrastorage.org/webt/gs/xi/tx/gsxitxxte0uijgpk_anw9k-u3se.png"></td><td><img src="https://habrastorage.org/webt/ul/oz/vu/ulozvupjad3kjhgtijix84ymisw.png"></td></tr></tbody></table></div><cut></cut><br><h2 id="performance">  Leistung </h2><br><p>  Das Zielprojekt w√§re ohne Leistungsmessungen nutzlos.  Aus den nachstehenden Ergebnissen geht deutlich hervor, dass Apple bei den letzten Modellen eine enorme Leistungssteigerung des NN-Motors erzielt hat.  Dar√ºber hinaus wird Apple nach den Prognosen des Analysten im kommenden iPhone noch schnellere NN-Hardware herstellen.  Die Ergebnisse der Leistungsmessungen sind nachstehend aufgef√ºhrt: </p><br><h3 id="time-to-process-one-frame-1-2-persons-in-the-view">  Zeit f√ºr die Bearbeitung eines Frames (1-2 Personen in der Ansicht) </h3><br><div class="scrollable-table"><table><thead><tr><th>  Nn Eingabegr√∂√üe </th><th>  iPhone XR (ms) </th><th>  iPhone 8 (ms) </th><th>  iPhone 5S (ms) </th></tr></thead><tbody><tr><td>  CoreML </td></tr><tr><td>  512 x 512 </td><td>  190 </td><td>  3670 </td><td>  20801 </td></tr><tr><td>  256 x 256 </td><td>  70 </td><td>  1039 </td><td>  7162 </td></tr><tr><td>  <strong>Nachbearbeitung</strong> </td></tr><tr><td>  512 x 512 </td><td>  19 </td><td>  67 </td><td>  100 </td></tr><tr><td>  256 x 256 </td><td>  5 </td><td>  35 </td><td></td></tr><tr><td>  <strong>Insgesamt</strong> </td></tr><tr><td>  512 x 512 </td><td>  219 </td><td>  3737 </td><td>  20901 </td></tr><tr><td>  256 x 256 </td><td>  75 </td><td>  1074 </td><td>  7200 </td></tr></tbody></table></div><br><p>  Es ist erw√§hnenswert, dass alle oben gezeigten Zahlen f√ºr jeden einzelnen Lauf variieren k√∂nnen.  Ich gehe davon aus, dass dies aufgrund der internen CoreML-Optimierung geschieht. </p><br><h3 id="the-resulting-pose-depending-on-the-nn-input-size-the-smaller-and-faster-the-less-accurate-result-is">  Die resultierende Pose h√§ngt von der NN-Eingangsgr√∂√üe ab (je kleiner und schneller, desto ungenauer ist das Ergebnis). </h3><br><div class="scrollable-table"><table><thead><tr><th>  512 x 512 </th><th>  256 x 256 </th></tr></thead><tbody><tr><td><img src="https://habrastorage.org/webt/et/j0/td/etj0tdcpt0cch351fqasuyj-zkm.png"></td><td><img src="https://habrastorage.org/webt/zj/hq/-i/zjhq-i_6xf8bj_rfmq_7t-gyos4.png"></td></tr></tbody></table></div><br><h2 id="code-sources">  Codequellen </h2><br><p>  Der Link zum GitHub-Repository: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Klicken Sie hier, um ihn zu √ºberpr√ºfen</a> </p><br><h2 id="applications">  Anwendungen </h2><br><p>  Es ist wichtig zu beachten, dass alle unten genannten Anwendungen aus dem Kopf kamen und nicht offiziell von Apple oder einer Beh√∂rde best√§tigt wurden. </p><br><h3 id="healthcare">  Gesundheitswesen </h3><br><p>  1) Erkennen von Anomalien in der menschlichen Wirbels√§ule auf Standbildern: <br><img src="https://habrastorage.org/webt/9u/6x/hl/9u6xhlogle7sp1kwwq64yw6u_ve.png"><br>  2) Gesundheits- und Fitnessf√ºhrer. </p><br><h3 id="home-security-and-automation-not-related-to-mobile-phones">  Sicherheit und Automatisierung zu Hause (nicht im Zusammenhang mit Mobiltelefonen) </h3><br><p>  1) Erkennen, ob Personen zu Hause sind, und pr√ºfen, ob alle Ger√§te ausgeschaltet sind (B√ºgeleisen / Owen). <br>  2) Personen im Wohnbereich lokalisieren und automatisieren (Licht / Musik / Fernseher einschalten) </p><br><h3 id="plugins-for-the-art-studio-applications">  Plugins f√ºr die Art Studio-Anwendungen </h3><br><p>  1) 2D -&gt; 3D-Mapping und Pose-Inferenz zur Rekonstruktion einer 3D-Pose basierend auf der 2D-Quelle </p><br><h2 id="improvements-and-further-developments">  Verbesserungen und Weiterentwicklungen </h2><br><p>  Es k√∂nnten verschiedene Verbesserungen vorgenommen werden, um die Leistung des Nachbearbeitungsschritts zu erh√∂hen und ihn pr√§ziser zu gestalten.  Es k√∂nnte auch interessant sein, es mit 2D-&gt; 3D-Mapping zu kombinieren, um die 3D-Pose zu rekonstruieren.  Die Liste m√∂glicher Verbesserungen ist unten aufgef√ºhrt: <br>  1) NMS-Optimierung.  Eine parallele GPU-Implementierung mit METAL API. <br>  2) Verwenden Sie eine andere N√§herung f√ºr die Verbindung der Gelenke, die n√§her an den realen Skelettknochen liegt.  Knochen sind nicht gerade. <br>  3) Implementieren Sie eine robustere Filterung f√ºr die Ausgabe-Pose, um Artefakte zu entfernen. <br>  4) Implementieren Sie eine Posensch√§tzung in einem Videostream <br>  5) 2D -&gt; 3D Mapping </p><br><h2 id="in-depth-information">  Detaillierte Informationen </h2><br><p>  F√ºr diejenigen, die sich f√ºr den Hintergrund dieses Projekts und Openpose interessieren, finden Sie unten n√ºtzliche Informationen: <br>  1) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://posefs1.perception.cs.cmu.edu/Users/ZheCao/Multi-person%20pose%20estimation-CMU.pdf</a> <br>  2) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.ri.cmu.edu/wp-content/uploads/2017/04/thesis.pdf</a> <br>  3) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://pose.mpi-inf.mpg.de/</a> </p><br><h2 id="some-fun">  Ein bisschen Spa√ü </h2><br><p>  Es ist immer wieder interessant zu sehen, wie die Anwendung von Technologie mit ungew√∂hnlichen Eingaben funktioniert.  Einige lustige Ergebnisse sind unten gezeigt.  Bitte beachten Sie, wie der NN den Fu√ü vorhergesagt hat, wo er tats√§chlich versteckt ist: </p><br><div class="scrollable-table"><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>  Das Bild wurde von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Magic Poser aufgenommen</a> <br><img src="https://habrastorage.org/webt/p-/dd/oh/p-ddohalbaskex3hnav_vqmlx90.png"></td><td><img src="https://habrastorage.org/webt/9s/h8/om/9sh8ompsodyb7-nle--eiplx4gu.png"></td></tr><tr><td><img src="https://habrastorage.org/webt/ca/hl/al/cahlalwea97lgtyuvxh5gwpwvfo.png"></td><td></td></tr></tbody></table></div><br><h2 id="conclusion">  Fazit </h2><br><p>  In diesem Artikel wird die iOS-Anwendung zum Ableiten der menschlichen Pose beschrieben.  Aus den Leistungsergebnissen geht eindeutig hervor, dass Apple einen gro√üen Leistungssprung bei der neuronalen Netzwerk-Engine erzielt hat.  Dar√ºber hinaus werden die n√§chsten iPhone-Modelle h√∂chstwahrscheinlich R√ºckschl√ºsse in Echtzeit erm√∂glichen.  Die Kombination mit der 2D-&gt; 3D-Posenrekonstruktion er√∂ffnet die M√∂glichkeit, die 3D-Pose des Menschen in Echtzeit in einem Videostream abzuleiten! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458000/">https://habr.com/ru/post/de458000/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457988/index.html">Checkliste: Starten Sie SCRUM-Befehle und erhalten Sie Impfungen von Zombie Scrum</a></li>
<li><a href="../de457990/index.html">Ich war sieben Worte davon entfernt, Opfer von gezieltem Phishing zu werden</a></li>
<li><a href="../de457992/index.html">Drahtloser Touch-Schalter mit zus√§tzlicher fluoreszierender Hintergrundbeleuchtung</a></li>
<li><a href="../de457994/index.html">Tipps und Tricks f√ºr Visual Studio</a></li>
<li><a href="../de457996/index.html">Gest√§ndnis des Chefs: Wie man auf Reisen arbeitet, die H√§lfte der Abteilung in LA entl√§sst und warum man MeksetnoExp Tyoma Lebedev sponsert</a></li>
<li><a href="../de458002/index.html">Was wirklich mit der verschwundenen malaysischen Boeing passiert ist (Teil 1/3)</a></li>
<li><a href="../de458004/index.html">Sojus-TM-Raumfahrzeug-Verkehrskontrollsystem Teil 2</a></li>
<li><a href="../de458006/index.html">Dynamische Websites ohne Server auf Github-Seiten (f√ºr diejenigen, die es nicht wissen, verwenden Serverlose API-Server von Drittanbietern)</a></li>
<li><a href="../de458010/index.html">Die Abenteuer der schwer fassbaren Malvari, Teil II: Geheime VBA-Skripte</a></li>
<li><a href="../de458014/index.html">FEDOR Robot - Training mit der neuen ISS-Crew und den ersten Weltraumaufgaben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
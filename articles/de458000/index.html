<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🗃️ 🤱🏿 🏼 Beurteilung der menschlichen Pose auf Bildern für iOS 🔱 👩🏾‍🔧 👨‍👨‍👦‍👦</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Beurteilung der menschlichen Pose 


 Vor einigen Monaten bin ich auf ein interessantes Open-Source-Projekt im Internet gestoßen - Openpose, dessen Zi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Beurteilung der menschlichen Pose auf Bildern für iOS</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458000/"><h1 id="human-pose-estimation">  Beurteilung der menschlichen Pose </h1><br><p> Vor einigen Monaten bin ich auf ein interessantes Open-Source-Projekt im Internet gestoßen - Openpose, dessen Ziel es ist, eine menschliche Pose in Echtzeit in einem Videostream zu schätzen.  Aufgrund meiner beruflichen Aktivitäten war ich daran interessiert, es auf dem neuesten iOS-Gerät von Apple auszuführen, um die Leistung zu überprüfen und herauszufinden, ob dies überhaupt möglich ist.  Es war auch interessant zu sehen, wie sich die Leistung des neuronalen Netzwerk-Frameworks für iOS in den letzten Jahren geändert hat. </p><a name="habracut"></a><br><p>  Das ursprüngliche Openpose-Projekt ist in C ++ geschrieben und verwendet nicht das CoreML - das neuronale Netzwerk-Framework unter iOS.  Daher musste ich einen Kernteil in Swift neu schreiben und CoreML verwenden, um den abschließenden Job zu erledigen.  Schauen wir uns das folgende Bild an, wie der menschliche Körper dargestellt wird: </p><br><p><img src="https://habrastorage.org/webt/mm/32/j7/mm32j7gnh-kswdkpd37yuo1kyyq.png"></p><br><p>  Weitere Informationen zum menschlichen Posenmodell finden Sie hier: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MPI-Pose</a> </p><br><p>  Das Ergebnis ist im Bild unten dargestellt: </p><br><div class="scrollable-table"><table><thead><tr><th>  Für die Demo habe ich Bilder mitgenommen) </th><th>  Die resultierende Schätzung der menschlichen Pose wird über das Originalbild gezogen </th></tr></thead><tbody><tr><td><img src="https://habrastorage.org/webt/aa/xj/ls/aaxjls3wjnghu4ebwbjbquaz0hc.png"></td><td><img src="https://habrastorage.org/webt/et/j0/td/etj0tdcpt0cch351fqasuyj-zkm.png"></td></tr></tbody></table></div><br><h2 id="preparing-the-model">  Modell vorbereiten </h2><br><p>  Um das Framework verwenden zu können, muss ein Core ML-Modell erstellt werden.  Dieses Modell basiert auf einem Modell aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Openpose-Projekt</a> .  Führen Sie die folgenden Schritte aus, um ein Modell vorzubereiten: <br>  1) Installieren Sie Python- und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CoreML-Tools</a> <br>  2) Führen Sie models / getModels.sh von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Open Pose aus</a> , um die ursprünglichen Openpose-Modelle zu erhalten <br>  3) Kopieren Sie models /pose / mpi /pose_deploy_linevec_faster_4_stages.prototxt in models /pose / mpi /pose_deploy_linevec_faster_4_stages_fixed_size.prototxt <br>  4) Ändern Sie Folgendes in der Dateipose_deploy_linevec_faster_4_stages_fixed_size.prototxt: </p><br><pre><code class="plaintext hljs">input_dim: 1 # This value will be defined at runtime -&gt; input_dim: 512 input_dim: 1 # This value will be defined at runtime -&gt; input_dim: 512</code> </pre> <br><p>  5) Erstellen Sie einen Link zum Modellverzeichnis.  Nehmen wir an, dass sich das Pose Framework-Projekt und das Openpose-Projekt im Ausgangsverzeichnis befinden. Ein Befehl zum Erstellen eines Links lautet dann wie folgt: </p><br><p> <code>ln -s ~/openpose/models ~/models</code> </p> <br><p>  6) Gehen Sie zu ~ /pose /pose / CoreMLModels und führen Sie den folgenden Befehl aus: </p><br><p> <code>python convertModel.py</code> </p> <cut></cut><br><p>  Das oben genannte Skript enthält fest codierte Werte für die Dateipose_deploy_linevec_faster_4_stages_fixed_size.prototxt und die Modelldateipose_iter_160000.caffemodel. <br>  Sie könnten in ein anderes Modell geändert werden. Vergessen Sie jedoch nicht, die .prototxt-Datei so zu ändern, dass das Eingabebild eine feste Größe hat: <br>  input_dim: XXX - entspricht dem with des NN-Eingangs. <br>  input_dim: XXX - entspricht der Höhe des NN-Eingangs. <br>  <strong>Vergessen Sie auch nicht, die Modellkonfiguration PoseModelConfigurationMPI15.inputSize auf einen angegebenen Eingabewert zu ändern</strong> und diese Konfiguration anstelle einer vorhandenen im Framework zu verwenden, die 512 x 512 als Eingabegröße festlegt. </p><br><p>  Alle Werte funktionieren, aber die besten Ergebnisse können erzielt werden, wenn ein Seitenverhältnis mit dem eines Originalbilds übereinstimmt.  Es sollte auch berücksichtigt werden, dass größere Werte die Leistung erheblich beeinflussen, was im Abschnitt Leistung gezeigt wird. </p><cut></cut><br><h2 id="neural-network-output-details">  Details zur Ausgabe des neuronalen Netzwerks </h2><br><p>  Schauen wir uns die Ausgabe des NN genauer an.  Die Ausgabe des MPI15-Modells ist eine Gruppe von Matrizen mit Dimensionen <code>(input_image_width / 8, input_image_height / 8)</code> .  Jedes Element in der Matrix hat den Float-Typ.  Zuordnung zwischen dem Matrixindex in der Ausgabe und dem Körperteil: </p><br><pre> <code class="plaintext hljs">POSE_MPI_BODY_PARTS { {0, "Head"}, {1, "Neck"}, {2, "RShoulder"}, {3, "RElbow"}, {4, "RWrist"}, {5, "LShoulder"}, {6, "LElbow"}, {7, "LWrist"}, {8, "RHip"}, {9, "RKnee"}, {10, "RAnkle"}, {11, "LHip"}, {12, "LKnee"}, {13, "LAnkle"}, {14, "Chest"}, {15, "Background"} };</code> </pre> <br><p>  Da jede Matrix eine feste Größe hat, die auf eine bestimmte zugreift, handelt es sich um eine Trifial-Read-by-Offset-Operation: [Background] = NNOutput [sizeOfTheMatrix * 15] </p><br><h3 id="heatmaps-and-pafs">  Heatmaps und PAFs </h3><br><p>  Im MPI15-Modell gibt es zwei Arten von Ausgabematrizen.  Diejenigen, die Heatmaps darstellen, und die anderen, die PAFs darstellen.  Jede Wärmematrix entspricht einem Verbindungsteil, das insgesamt 15 beträgt.  Die PAF-Matrizen repräsentieren Körperverbindungen.  Für jede Körperverbindung gibt es eine X- und Y-Matrix, die insgesamt 28 beträgt (14 + 14).  Die Gesamtzahl der Matrizen einschließlich einer Hintergrundmatrize beträgt 44. </p><br><h2 id="demo-project">  Demo-Projekt </h2><br><p>  Das Repository des Projekts enthält auch ein Demo-Projekt'poseDemo ', das die Verwendung des Frameworks demonstriert.  Die NN-Ergebnismatrizen für ein bestimmtes Eingabebild sind nachstehend aufgeführt: </p><br><div class="scrollable-table"><table><thead><tr><th>  Probe </th><th>  Bilder </th></tr></thead><tbody><tr><td>  Ergebnis der menschlichen Pose: </td><td>  Heatmaps zu einem Bild zusammengefasst.  Jedes Gelenk hat seine eigene Farbe: </td></tr><tr><td><img src="https://habrastorage.org/webt/et/j0/td/etj0tdcpt0cch351fqasuyj-zkm.png"></td><td><img src="https://habrastorage.org/webt/4h/7w/up/4h7wupwmcjmp5olhatqmorir21a.png"></td></tr><tr><td>  PAFs in einem Bild zusammengefasst: </td><td>  Alle Heatmap-Kandidaten.  Jeder Kandidat hat sein eigenes Vertrauen, das seine Deckkraft auf dem Bild definiert: </td></tr><tr><td><img src="https://habrastorage.org/webt/o-/3e/ny/o-3enyfxzfqbt_hnrlczexwariw.png"></td><td><img src="https://habrastorage.org/webt/9p/ns/m5/9pnsm5kp_2ur1isvguujlzm7shg.png"></td></tr><tr><td>  Schauen Sie sich die Heatmap-Kandidaten, die einem Kopf entsprechen, genauer an: </td><td>  Schauen Sie sich die Heatmap-Kandidaten, die einem Hals entsprechen, genauer an: </td></tr><tr><td><img src="https://habrastorage.org/webt/rg/zn/im/rgznimptilj3acm7cs6qu6fdcve.png"></td><td><img src="https://habrastorage.org/webt/7k/hl/ru/7khlrub0jznpecotxdb9hpfvda8.png"></td></tr><tr><td>  PAF-Matrix, die einem Kopf-Hals-Verbindungskandidaten entspricht.  Die Kopf-Hals-Heatmap-Gelenke sind ebenfalls auf dem Bild dargestellt: </td><td>  PAF-Matrix, die einem LShoulder-LElbow-Verbindungskandidaten entspricht.  Die LShoulder-LElbow-Heatmap-Gelenke sind auch auf dem Bild dargestellt: </td></tr><tr><td><img src="https://habrastorage.org/webt/gs/xi/tx/gsxitxxte0uijgpk_anw9k-u3se.png"></td><td><img src="https://habrastorage.org/webt/ul/oz/vu/ulozvupjad3kjhgtijix84ymisw.png"></td></tr></tbody></table></div><cut></cut><br><h2 id="performance">  Leistung </h2><br><p>  Das Zielprojekt wäre ohne Leistungsmessungen nutzlos.  Aus den nachstehenden Ergebnissen geht deutlich hervor, dass Apple bei den letzten Modellen eine enorme Leistungssteigerung des NN-Motors erzielt hat.  Darüber hinaus wird Apple nach den Prognosen des Analysten im kommenden iPhone noch schnellere NN-Hardware herstellen.  Die Ergebnisse der Leistungsmessungen sind nachstehend aufgeführt: </p><br><h3 id="time-to-process-one-frame-1-2-persons-in-the-view">  Zeit für die Bearbeitung eines Frames (1-2 Personen in der Ansicht) </h3><br><div class="scrollable-table"><table><thead><tr><th>  Nn Eingabegröße </th><th>  iPhone XR (ms) </th><th>  iPhone 8 (ms) </th><th>  iPhone 5S (ms) </th></tr></thead><tbody><tr><td>  CoreML </td></tr><tr><td>  512 x 512 </td><td>  190 </td><td>  3670 </td><td>  20801 </td></tr><tr><td>  256 x 256 </td><td>  70 </td><td>  1039 </td><td>  7162 </td></tr><tr><td>  <strong>Nachbearbeitung</strong> </td></tr><tr><td>  512 x 512 </td><td>  19 </td><td>  67 </td><td>  100 </td></tr><tr><td>  256 x 256 </td><td>  5 </td><td>  35 </td><td></td></tr><tr><td>  <strong>Insgesamt</strong> </td></tr><tr><td>  512 x 512 </td><td>  219 </td><td>  3737 </td><td>  20901 </td></tr><tr><td>  256 x 256 </td><td>  75 </td><td>  1074 </td><td>  7200 </td></tr></tbody></table></div><br><p>  Es ist erwähnenswert, dass alle oben gezeigten Zahlen für jeden einzelnen Lauf variieren können.  Ich gehe davon aus, dass dies aufgrund der internen CoreML-Optimierung geschieht. </p><br><h3 id="the-resulting-pose-depending-on-the-nn-input-size-the-smaller-and-faster-the-less-accurate-result-is">  Die resultierende Pose hängt von der NN-Eingangsgröße ab (je kleiner und schneller, desto ungenauer ist das Ergebnis). </h3><br><div class="scrollable-table"><table><thead><tr><th>  512 x 512 </th><th>  256 x 256 </th></tr></thead><tbody><tr><td><img src="https://habrastorage.org/webt/et/j0/td/etj0tdcpt0cch351fqasuyj-zkm.png"></td><td><img src="https://habrastorage.org/webt/zj/hq/-i/zjhq-i_6xf8bj_rfmq_7t-gyos4.png"></td></tr></tbody></table></div><br><h2 id="code-sources">  Codequellen </h2><br><p>  Der Link zum GitHub-Repository: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Klicken Sie hier, um ihn zu überprüfen</a> </p><br><h2 id="applications">  Anwendungen </h2><br><p>  Es ist wichtig zu beachten, dass alle unten genannten Anwendungen aus dem Kopf kamen und nicht offiziell von Apple oder einer Behörde bestätigt wurden. </p><br><h3 id="healthcare">  Gesundheitswesen </h3><br><p>  1) Erkennen von Anomalien in der menschlichen Wirbelsäule auf Standbildern: <br><img src="https://habrastorage.org/webt/9u/6x/hl/9u6xhlogle7sp1kwwq64yw6u_ve.png"><br>  2) Gesundheits- und Fitnessführer. </p><br><h3 id="home-security-and-automation-not-related-to-mobile-phones">  Sicherheit und Automatisierung zu Hause (nicht im Zusammenhang mit Mobiltelefonen) </h3><br><p>  1) Erkennen, ob Personen zu Hause sind, und prüfen, ob alle Geräte ausgeschaltet sind (Bügeleisen / Owen). <br>  2) Personen im Wohnbereich lokalisieren und automatisieren (Licht / Musik / Fernseher einschalten) </p><br><h3 id="plugins-for-the-art-studio-applications">  Plugins für die Art Studio-Anwendungen </h3><br><p>  1) 2D -&gt; 3D-Mapping und Pose-Inferenz zur Rekonstruktion einer 3D-Pose basierend auf der 2D-Quelle </p><br><h2 id="improvements-and-further-developments">  Verbesserungen und Weiterentwicklungen </h2><br><p>  Es könnten verschiedene Verbesserungen vorgenommen werden, um die Leistung des Nachbearbeitungsschritts zu erhöhen und ihn präziser zu gestalten.  Es könnte auch interessant sein, es mit 2D-&gt; 3D-Mapping zu kombinieren, um die 3D-Pose zu rekonstruieren.  Die Liste möglicher Verbesserungen ist unten aufgeführt: <br>  1) NMS-Optimierung.  Eine parallele GPU-Implementierung mit METAL API. <br>  2) Verwenden Sie eine andere Näherung für die Verbindung der Gelenke, die näher an den realen Skelettknochen liegt.  Knochen sind nicht gerade. <br>  3) Implementieren Sie eine robustere Filterung für die Ausgabe-Pose, um Artefakte zu entfernen. <br>  4) Implementieren Sie eine Posenschätzung in einem Videostream <br>  5) 2D -&gt; 3D Mapping </p><br><h2 id="in-depth-information">  Detaillierte Informationen </h2><br><p>  Für diejenigen, die sich für den Hintergrund dieses Projekts und Openpose interessieren, finden Sie unten nützliche Informationen: <br>  1) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://posefs1.perception.cs.cmu.edu/Users/ZheCao/Multi-person%20pose%20estimation-CMU.pdf</a> <br>  2) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.ri.cmu.edu/wp-content/uploads/2017/04/thesis.pdf</a> <br>  3) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://pose.mpi-inf.mpg.de/</a> </p><br><h2 id="some-fun">  Ein bisschen Spaß </h2><br><p>  Es ist immer wieder interessant zu sehen, wie die Anwendung von Technologie mit ungewöhnlichen Eingaben funktioniert.  Einige lustige Ergebnisse sind unten gezeigt.  Bitte beachten Sie, wie der NN den Fuß vorhergesagt hat, wo er tatsächlich versteckt ist: </p><br><div class="scrollable-table"><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>  Das Bild wurde von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Magic Poser aufgenommen</a> <br><img src="https://habrastorage.org/webt/p-/dd/oh/p-ddohalbaskex3hnav_vqmlx90.png"></td><td><img src="https://habrastorage.org/webt/9s/h8/om/9sh8ompsodyb7-nle--eiplx4gu.png"></td></tr><tr><td><img src="https://habrastorage.org/webt/ca/hl/al/cahlalwea97lgtyuvxh5gwpwvfo.png"></td><td></td></tr></tbody></table></div><br><h2 id="conclusion">  Fazit </h2><br><p>  In diesem Artikel wird die iOS-Anwendung zum Ableiten der menschlichen Pose beschrieben.  Aus den Leistungsergebnissen geht eindeutig hervor, dass Apple einen großen Leistungssprung bei der neuronalen Netzwerk-Engine erzielt hat.  Darüber hinaus werden die nächsten iPhone-Modelle höchstwahrscheinlich Rückschlüsse in Echtzeit ermöglichen.  Die Kombination mit der 2D-&gt; 3D-Posenrekonstruktion eröffnet die Möglichkeit, die 3D-Pose des Menschen in Echtzeit in einem Videostream abzuleiten! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458000/">https://habr.com/ru/post/de458000/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457988/index.html">Checkliste: Starten Sie SCRUM-Befehle und erhalten Sie Impfungen von Zombie Scrum</a></li>
<li><a href="../de457990/index.html">Ich war sieben Worte davon entfernt, Opfer von gezieltem Phishing zu werden</a></li>
<li><a href="../de457992/index.html">Drahtloser Touch-Schalter mit zusätzlicher fluoreszierender Hintergrundbeleuchtung</a></li>
<li><a href="../de457994/index.html">Tipps und Tricks für Visual Studio</a></li>
<li><a href="../de457996/index.html">Geständnis des Chefs: Wie man auf Reisen arbeitet, die Hälfte der Abteilung in LA entlässt und warum man MeksetnoExp Tyoma Lebedev sponsert</a></li>
<li><a href="../de458002/index.html">Was wirklich mit der verschwundenen malaysischen Boeing passiert ist (Teil 1/3)</a></li>
<li><a href="../de458004/index.html">Sojus-TM-Raumfahrzeug-Verkehrskontrollsystem Teil 2</a></li>
<li><a href="../de458006/index.html">Dynamische Websites ohne Server auf Github-Seiten (für diejenigen, die es nicht wissen, verwenden Serverlose API-Server von Drittanbietern)</a></li>
<li><a href="../de458010/index.html">Die Abenteuer der schwer fassbaren Malvari, Teil II: Geheime VBA-Skripte</a></li>
<li><a href="../de458014/index.html">FEDOR Robot - Training mit der neuen ISS-Crew und den ersten Weltraumaufgaben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
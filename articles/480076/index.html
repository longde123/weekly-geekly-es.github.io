<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äçüé§ üï§ üå± Multiprocesamiento y conciliaci√≥n de datos de varias fuentes. üï£ üõå üê°</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Habr! 

 Dada la variedad de sistemas distribuidos, la disponibilidad de informaci√≥n verificada en el almacenamiento de destino es un criterio im...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Multiprocesamiento y conciliaci√≥n de datos de varias fuentes.</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/480076/"> Hola Habr! <br><br>  Dada la variedad de sistemas distribuidos, la disponibilidad de informaci√≥n verificada en el almacenamiento de destino es un criterio importante para la consistencia de los datos. <br><br>  Hay muchos enfoques y m√©todos a este efecto, y nos centraremos en la reconciliaci√≥n, cuyos aspectos te√≥ricos se discutieron <a href="https://habr.com/ru/post/428443/">aqu√≠ en este art√≠culo.</a>  Propongo considerar la implementaci√≥n pr√°ctica de este sistema, escalable y adaptada a una gran cantidad de datos. <br><br>  C√≥mo implementar este caso en el viejo Python, ¬°l√©elo debajo del corte!  Vamos! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ic/zx/hg/iczxhgu9zvlumwggetuoblxm1ra.jpeg"></div><br>  <a href="https://www.megapixl.com/alexdobysh-stock-images-videos-portfolio" rel="nofollow">(Fuente de la imagen)</a> <br><a name="habracut"></a><br><h2>  Introduccion </h2><br>  Imaginemos que una instituci√≥n financiera tiene varios sistemas distribuidos y nos enfrentamos a la tarea de verificar las transacciones en estos sistemas y cargar los datos conciliados en el almacenamiento de destino. <br><br>  Como fuente de datos, tome un archivo de texto grande y una tabla en una base de datos PostgreSQL.  Suponga que los datos en estas fuentes tienen las mismas transacciones, pero pueden tener diferencias y, por lo tanto, deben verificarse y escribirse en los datos verificados en el almacenamiento final para su an√°lisis. <br><br>  Adem√°s, es necesario prever el lanzamiento paralelo de varias conciliaciones en la misma base de datos y adaptar el sistema a un gran volumen mediante multiprocesamiento. <br><br>  El m√≥dulo de <a href="https://docs.python.org/dev/library/multiprocessing.html" rel="nofollow">multiprocesamiento</a> es ideal para paralelizar operaciones en Python y, en cierto sentido, evita ciertos defectos de GIL.  Utilizaremos las capacidades de esta biblioteca a continuaci√≥n. <br><br><h2>  Arquitectura del sistema en desarrollo. </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/je/dm/hu/jedmhumxsx9d-mxu-bbfbzqbulq.png"></div><br>  Componentes utilizados: <br><br><ul><li>  <b>Generador de datos aleatorio</b> : un script de Python que genera un archivo CSV y, sobre la base, llena una tabla en una base de datos; </li><li>  <b>Fuentes de datos</b> : archivo CSV y tabla en la base de datos PostgreSQL; </li><li>  <b>Adaptadores</b> : en este caso, utilizamos dos adaptadores que extraer√°n datos de sus fuentes (CSV o base de datos) e ingresar√°n informaci√≥n en la base de datos intermedia; </li><li>  <b>Bases de datos</b> : en la cantidad de tres piezas: datos sin procesar, una base de datos intermedia que almacena informaci√≥n capturada por los adaptadores y una base de datos "limpia" que contiene transacciones conciliadas de ambas fuentes. </li></ul><br><h2>  Entrenamiento inicial </h2><br>  Como herramienta de almacenamiento de datos, utilizaremos la <a href="https://hub.docker.com/_/postgres" rel="nofollow">base de datos PostgreSQL en el contenedor Docker</a> e interactuaremos con nuestra base de datos a trav√©s de <a href="https://hub.docker.com/r/dpage/pgadmin4/" rel="nofollow">pgAdmin que se ejecuta en el contenedor</a> : <br><br><pre><code class="bash hljs">docker run --name pg -d -e <span class="hljs-string"><span class="hljs-string">"POSTGRES_USER=my_user"</span></span> -e <span class="hljs-string"><span class="hljs-string">"POSTGRES_PASSWORD=my_password"</span></span> postgres</code> </pre> <br>  Ejecutando pgAdmin: <br><br><pre> <code class="bash hljs">docker run -p 80:80 -e <span class="hljs-string"><span class="hljs-string">"PGADMIN_DEFAULT_EMAIL=user@domain.com"</span></span> -e <span class="hljs-string"><span class="hljs-string">"PGADMIN_DEFAULT_PASSWORD=12345"</span></span> -d dpage/pgadmin4</code> </pre> <br>  Despu√©s de que todo haya comenzado, no olvide especificar en el archivo de configuraci√≥n (conf / db.ini) la cadena de conexi√≥n a la base de datos (para un ejemplo de capacitaci√≥n, ¬°puede!): <br><br><pre> <code class="bash hljs">[POSTGRESQL] db_url=postgresql://my_user:my_password@172.17.0.2:5432/my_user</code> </pre><br>  En principio, el uso de un contenedor es opcional y puede usar su servidor de base de datos. <br><br><h2>  Generaci√≥n de entrada </h2><br>  El script Python <b>generate_test_data</b> es responsable de la generaci√≥n de datos de prueba, que toma la cantidad deseada de entradas para generar.  La secuencia de operaciones se puede rastrear f√°cilmente por la funci√≥n principal de la clase <b>GenerateTestData</b> : <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @m.timing def run(self, num_rows): """ Run the process """ m.info('START!') self.create_db_schema() self.create_folder('data') self.create_csv_file(num_rows) self.bulk_copy_to_db() self.random_delete_rows() self.random_update_rows() m.info('END!')</span></span></code> </pre> <br>  Entonces, la funci√≥n realiza los siguientes pasos: <br><br><ul><li>  Crear esquemas en la base de datos (creamos todos los esquemas y tablas principales); </li><li>  Crear una carpeta para almacenar un archivo de prueba; </li><li>  Generando un archivo de prueba con un n√∫mero dado de l√≠neas; </li><li>  Insertar datos de forma masiva en la tabla de destino transaction_db_raw.transaction_log; </li><li>  Eliminaci√≥n accidental de m√∫ltiples filas en esta tabla; </li><li>  Actualizaci√≥n aleatoria de varias filas en esta tabla. </li></ul><br>  La eliminaci√≥n y modificaci√≥n es necesaria para que los objetos comparados tengan al menos alguna discrepancia.  ¬°Es importante poder buscar estas discrepancias! <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing @m.wrapper(m.entering, m.exiting) def random_delete_rows(self): """ Random deleting some rows from the table """ sql_command = sql.SQL(""" delete from {0}.{1} where ctid = any(array( select ctid from {0}.{1} tablesample bernoulli (1) ))""").format(sql.Identifier(self.schema_raw), sql.Identifier(self.raw_table_name)) try: rows = self.database.execute(sql_command) m.info('Has been deleted [%s rows] from table %s' % (rows, self.raw_table_name)) except psycopg2.Error as err: m.error('Oops! Delete random rows has been FAILED. Reason: %s' % err.pgerror) @m.timing @m.wrapper(m.entering, m.exiting) def random_update_rows(self): """ Random update some rows from the table """ sql_command = sql.SQL(""" update {0}.{1} set transaction_amount = round(random()::numeric, 2) where ctid = any(array( select ctid from {0}.{1} tablesample bernoulli (1) ))""").format(sql.Identifier(self.schema_raw), sql.Identifier(self.raw_table_name)) try: rows = self.database.execute(sql_command) m.info('Has been updated [%s rows] from table %s' % (rows, self.raw_table_name)) except psycopg2.Error as err: m.error('Oops! Delete random rows has been FAILED. Reason: %s' % err.pgerror)</span></span></code> </pre> <br>  La generaci√≥n de un conjunto de datos de prueba y la posterior grabaci√≥n en un archivo de texto en formato CSV es la siguiente: <br><br><ul><li>  Se crea un UID de transacci√≥n aleatoria; </li><li>  Se crea un n√∫mero de cuenta UID aleatorio (de forma predeterminada, tomamos diez cuentas √∫nicas, pero este valor se puede cambiar usando el archivo de configuraci√≥n cambiando el par√°metro "cuentas_al azar"); </li><li>  Fecha de transacci√≥n: una fecha aleatoria a partir de la fecha especificada en el archivo de configuraci√≥n (initial_date); </li><li>  Tipo de transacci√≥n (transacci√≥n / comisi√≥n); </li><li>  Monto de la transacci√≥n; </li><li>  El trabajo principal en la generaci√≥n de datos se realiza mediante el m√©todo <i>generate_test_data_by_chunk</i> de la clase <b>TestDataCreator</b> : </li></ul><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing def generate_test_data_by_chunk(self, chunk_start, chunk_end): """ Generating and saving to the file """ num_rows_mp = chunk_end - chunk_start new_rows = [] for _ in range(num_rows_mp): transaction_uid = uuid.uuid4() account_uid = choice(self.list_acc) transaction_date = (self.get_random_date(self.date_in, 0) .__next__() .strftime('%Y-%m-%d %H:%M:%S')) type_deal = choice(self.list_type_deal) transaction_amount = randint(-1000, 1000) new_rows.append([transaction_uid, account_uid, transaction_date, type_deal, transaction_amount]) self.write_in_file(new_rows, chunk_start, chunk_end)</span></span></code> </pre> <br><blockquote>  Una caracter√≠stica de esta funci√≥n es el lanzamiento en varios procesos asincr√≥nicos paralelos, cada uno de los cuales genera su propia porci√≥n de 50K registros.  Este "chip" le permitir√° crear un archivo en varios millones de l√≠neas lo suficientemente r√°pido </blockquote><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">run_csv_writing</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Writing the test data into csv file """</span></span> pool = mp.Pool(mp.cpu_count()) jobs = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chunk_start, chunk_end <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.divide_into_chunks(<span class="hljs-number"><span class="hljs-number">0</span></span>, self.num_rows): jobs.append(pool.apply_async(self.generate_test_data_by_chunk, (chunk_start, chunk_end))) <span class="hljs-comment"><span class="hljs-comment"># wait for all jobs to finish for job in jobs: job.get() # clean up pool.close() pool.join()</span></span></code> </pre> <br>  Despu√©s de completar el archivo de texto, se procesa el comando bulk_insert y todos los datos de este archivo caen en la tabla <b>transaction_db_raw.transaction_log.</b> <br><br>  Adem√°s, las dos fuentes contendr√°n exactamente los mismos datos y la reconciliaci√≥n no encontrar√° nada interesante, por lo que eliminamos y cambiamos varias filas aleatorias en la base de datos. <br><br>  Ejecute el script y genere un archivo CSV de prueba con transacciones en l√≠neas de 10K: <br><br><pre> <code class="bash hljs">./generate_test_data.py 10000</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4c/cp/hm/4ccphmc5dcjcgxuy54p_9limlz4.png"></div><br>  La captura de pantalla muestra que el archivo se recibi√≥ en 10K l√≠neas, 10K se carg√≥ en la base de datos, pero luego se eliminaron 112 l√≠neas de la base de datos y se modificaron otras 108. Resultado: el archivo y la tabla en la base de datos difieren en 220 entradas. <br><br>  ‚ÄúBueno, ¬ød√≥nde est√° el multiprocesamiento?‚Äù, Preguntas. <br>  Y su trabajo se puede ver cuando genera un archivo m√°s grande, no por 10K registros, sino, por ejemplo, por 1M.  ¬øLo intentaremos? <br><br><pre> <code class="bash hljs">./generate_test_data.py 1000000</code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rw/_a/ne/rw_aneqnairixqk-wglpqxgjvkc.png"></div><br>  Despu√©s de cargar los datos, eliminar y cambiar registros aleatorios, vemos las diferencias del archivo de texto de la tabla: 19,939 filas (de las cuales 10,022 se eliminaron aleatoriamente y 9,917 cambiaron). <br><br><blockquote>  La imagen muestra que la generaci√≥n de registros fue asincr√≥nica, inconsistente.  Esto significa que el siguiente proceso puede comenzar sin tener en cuenta el orden de inicio tan pronto como se complete el anterior.  No hay garant√≠a de que el resultado est√© en el mismo orden que la entrada. </blockquote><br><div class="spoiler">  <b class="spoiler_title">¬øEs definitivamente m√°s r√°pido?</b> <div class="spoiler_text">  Se "invent√≥" un mill√≥n de l√≠neas que no estaban en la m√°quina virtual m√°s r√°pida en 15.5 segundos, y esta es una opci√≥n valiosa.  Despu√©s de comenzar la misma generaci√≥n secuencialmente, sin usar multiprocesamiento, obtuve el resultado: la generaci√≥n de archivos fue m√°s de tres veces m√°s lenta (m√°s de 52 segundos en lugar de 15.5): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sb/kb/ck/sbkbckylzluoyyslyflwak5udrq.png"></div><br></div></div><br><h2>  Adaptador para CSV </h2><br>  Este adaptador divide la fila, dejando solo la primera columna, la ID de la transacci√≥n, sin cambios y guarda los datos recibidos en el archivo <i>data / transaction_hashed.csv</i> .  El paso final de su trabajo es cargar este archivo usando el comando COPY en la tabla temporal del esquema <b>reconciliation_db.</b> <br><br>  La lectura √≥ptima de archivos se realiza mediante varios procesos paralelos.  Leemos l√≠nea por l√≠nea, en piezas de 5 megabytes cada una.  La cifra "5 megabytes" se obtuvo por el m√©todo emp√≠rico.  Fue con este tama√±o de una sola pieza de texto que pudimos obtener el menor tiempo para leer archivos grandes en nuestra m√°quina virtual.  Puede experimentar en su entorno con este par√°metro y ver c√≥mo cambiar√° el tiempo de funcionamiento: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@m.timing def process_wrapper(self, chunk_start, chunk_size): """ Read a particular chunk """ with open(self.file_name_raw, newline='\n') as file: file.seek(chunk_start) lines = file.read(chunk_size).splitlines() for line in lines: self.process(line) def chunkify(self, size=1024*1024*5): """ Return a new chunk """ with open(self.file_name_raw, 'rb') as file: chunk_end = file.tell() while True: chunk_start = chunk_end file.seek(size, 1) file.readline() chunk_end = file.tell() if chunk_end &gt; self.file_end: chunk_end = self.file_end yield chunk_start, chunk_end - chunk_start break else: yield chunk_start, chunk_end - chunk_start @m.timing def run_reading(self): """ The main method for the reading """ # init objects pool = mp.Pool(mp.cpu_count()) jobs = [] m.info('Run csv reading...') # create jobs for chunk_start, chunk_size in self.chunkify(): jobs.append(pool.apply_async(self.process_wrapper, (chunk_start, chunk_size))) # wait for all jobs to finish for job in jobs: job.get() # clean up pool.close() pool.join() m.info('CSV file reading has been completed')</span></span></code> </pre> <br>  Ejemplo de lectura de un archivo creado previamente en registros 1M: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9p/z1/zr/9pz1zrkzeelnep_r8oppk0sxhok.png"></div><br>  La captura de pantalla muestra la creaci√≥n de una tabla temporal con un nombre √∫nico para la ejecuci√≥n de reconciliaci√≥n actual.  Lo siguiente es la lectura as√≠ncrona del archivo en partes y tomar el hash de cada l√≠nea.  Insertar datos del adaptador en la tabla de destino completa el trabajo con este adaptador. <br><blockquote>  El uso de una tabla temporal con un nombre √∫nico para cada proceso de reconciliaci√≥n le permite paralelizar adicionalmente el proceso de reconciliaci√≥n en una base de datos. </blockquote><br><h2>  Adaptador para PostgreSQL </h2><br>  El adaptador para procesar los datos almacenados en la tabla funciona aproximadamente con la misma l√≥gica que el adaptador para el archivo: <br><br><ul><li>  leer en partes de la tabla (si es grande, m√°s de 100K entradas) y tomar un hash para todas las columnas excepto el identificador de transacci√≥n; </li><li>  entonces los datos procesados ‚Äã‚Äãse insertan en la tabla <b>reconciliation_db.</b>  <b>almacenamiento _ $ (int (time.time ())</b> . </li></ul><br>  Una caracter√≠stica interesante de este adaptador es que utiliza un conjunto de conexiones a la base de datos, que buscar√° por √≠ndice los datos necesarios en la tabla y los procesar√°. <br><br>  Seg√∫n el tama√±o de la tabla, se calcula el n√∫mero de procesos necesarios para el procesamiento y dentro de cada proceso hay una divisi√≥n en 10 tareas. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">read_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Read the data from the postgres and shared those records with each processor to perform their operation using threads """</span></span> threads_array = self.get_threads(<span class="hljs-number"><span class="hljs-number">0</span></span>, self.max_id_num_row, self.pid_max) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> pid <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, len(threads_array) + <span class="hljs-number"><span class="hljs-number">1</span></span>): m.info(<span class="hljs-string"><span class="hljs-string">'Process %s'</span></span> % pid) <span class="hljs-comment"><span class="hljs-comment"># Getting connection from the connection pool select_conn = self._select_conn_pool.getconn() select_conn.autocommit = 1 # Creating 10 process to perform the operation process = Process(target=self.process_data, args=(self.data_queque, pid, threads_array[pid-1][0], threads_array[pid-1][1], select_conn)) process.daemon = True process.start() process.join() select_conn.close()</span></span></code> </pre> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pw/kt/kk/pwktkkisxg3sud4dyss_gtyi4gy.png"></div><br><h2>  Buscar discrepancias </h2><br>  Procedemos a la verificaci√≥n de los datos recibidos de dos adaptadores. <br><br>  La reconciliaci√≥n (o la recepci√≥n de un informe de discrepancia) se produce en el lado del servidor de la base de datos, utilizando todo el poder del lenguaje SQL. <br><br>  La consulta SQL es bastante sencilla: es solo una uni√≥n de tabla con datos de los adaptadores a s√≠ misma por ID de transacci√≥n: <br><br><pre> <code class="python hljs">sql_command = sql.SQL(<span class="hljs-string"><span class="hljs-string">""" select s1.adapter_name, count(s1.transaction_uid) as tran_count from {0}.{1} s1 full join {0}.{1} s2 on s2.transaction_uid = s1.transaction_uid and s2.adapter_name != s1.adapter_name and s2.hash = s1.hash where s2.transaction_uid is null group by s1.adapter_name;"""</span></span>).format(sql.Identifier(self.schema_target), sql.Identifier(self.storage_table))</code> </pre><br>  El resultado es un informe: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5c/ou/gy/5cougys1gkflsplq2hvkoleooto.png"></div><br>  Compruebe si todo est√° correcto en la imagen de arriba.  Recordamos que 9917 se eliminaron de la tabla en la base de datos y se modificaron 10,022 filas.  Total de 19939 l√≠neas, lo cual es evidente en el informe. <br><br><h2>  Tabla resumen </h2><br>  Solo queda insertar transacciones "limpias" en la tabla de almacenamiento que coincidan en todos los aspectos (por hash) en diferentes adaptadores.  Este proceso se realiza mediante la siguiente consulta SQL: <br><br><pre> <code class="python hljs">sql_command = sql.SQL(<span class="hljs-string"><span class="hljs-string">""" with reconcil_data as ( select s1.transaction_uid from {0}.{1} s1 join {0}.{1} s2 on s2.transaction_uid = s1.transaction_uid and s2.adapter_name != s1.adapter_name where s2.hash = s1.hash and s1.adapter_name = 'postresql_adapter' ) insert into {2}.transaction_log select t.transaction_uid, t.account_uid, t.transaction_date, t.type_deal, t.transaction_amount from {3}.transaction_log t join reconcil_data r on t.transaction_uid = r.transaction_uid where not exists ( select 1 from {2}.transaction_log tl where tl.transaction_uid = t.transaction_uid ) """</span></span>).format(sql.Identifier(self.schema_target), sql.Identifier(self.storage_table), sql.Identifier(self.schema_db_clean), sql.Identifier(self.schema_raw))</code> </pre><br>  La tabla temporal que utilizamos como almacenamiento intermedio de datos de los adaptadores se puede eliminar. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uq/sr/te/uqsrte2g0thu2woasaxqojdbc88.png"></div><br><h2>  Conclusi√≥n </h2><br>  En el curso del trabajo realizado, se desarroll√≥ un sistema para conciliar datos de varias fuentes: un archivo de texto y una tabla en la base de datos.  Us√≥ un m√≠nimo de herramientas adicionales. <br><br>  Quiz√°s un lector sofisticado pueda notar que el uso de marcos como Apache Spark, junto con la conversi√≥n de los datos de origen a un formato de parquet, puede acelerar significativamente este proceso, especialmente para grandes vol√∫menes.  Pero el objetivo principal de este trabajo es escribir un sistema en Python desnudo y estudiar el procesamiento de datos de multiprocesamiento.  Con lo que, en mi opini√≥n, hemos tratado. <br><br>  El c√≥digo fuente de todo el proyecto se encuentra <a href="https://github.com/igorgorbenko/transact_reconciliation" rel="nofollow">en mi repositorio en GitHub</a> , le sugiero que se familiarice con √©l. <br><br>  Estar√© encantado de responder todas las preguntas y conocer sus comentarios. <br><br>  ¬°Te deseo √©xito! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/480076/">https://habr.com/ru/post/480076/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../480062/index.html">10 sistemas de control. ¬øD√≥nde es m√°s conveniente comunicarse sobre tareas y compartir archivos?</a></li>
<li><a href="../480064/index.html">Aprender palabras agrupadas tem√°ticamente</a></li>
<li><a href="../480068/index.html">[Actualizaci√≥n] Nuestra gente es golpeada, y estaremos en silencio?</a></li>
<li><a href="../480070/index.html">Reaccionar beneficios: ¬øuna bendici√≥n para las empresas?</a></li>
<li><a href="../480072/index.html">Kubernetes: ¬øpor qu√© es tan importante configurar la gesti√≥n de recursos del sistema?</a></li>
<li><a href="../480078/index.html">Nuevas bibliotecas front-end en los perif√©ricos React</a></li>
<li><a href="../480080/index.html">¬øQu√© necesitas en las aplicaciones para tomar notas?</a></li>
<li><a href="../480082/index.html">Uso de particiones en MySQL para Zabbix con una gran cantidad de objetos de monitoreo</a></li>
<li><a href="../480086/index.html">C√≥mo cumplir con los requisitos de 152-FZ, proteger los datos personales de nuestros clientes y no pisar nuestro rastrillo</a></li>
<li><a href="../480088/index.html">DevOps: OK, pero ¬øqu√© hacer? C√≥mo reducir el trabajo manual y lograr el resultado deseado</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ˜­ ğŸ³ ğŸšï¸ Erstellen Sie mit pix2pix Linsen fÃ¼r Snapchat ğŸ‘µğŸ¿ ğŸ’ ğŸ‘©ğŸ»â€ğŸ¤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mein vorheriger Artikel hat fast den gleichen Titel, mit dem einzigen Unterschied, dass ich mithilfe von dlib und openCV Objektive fÃ¼r Snapchat algori...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstellen Sie mit pix2pix Linsen fÃ¼r Snapchat</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483310/"><p>  Mein <a href="https://hackernoon.com/how-to-make-snapchat-lenses-f9eae861b5db">vorheriger Artikel hat</a> fast den gleichen Titel, mit dem einzigen Unterschied, dass ich mithilfe von dlib und openCV Objektive fÃ¼r Snapchat algorithmisch erstellt habe. Heute mÃ¶chte ich zeigen, wie Sie das Ergebnis mithilfe von maschinellem Lernen erzielen kÃ¶nnen.  Dieser Ansatz ermÃ¶glicht es, den Algorithmus nicht manuell zu entwerfen, sondern das endgÃ¼ltige Bild direkt vom neuronalen Netzwerk zu erhalten. </p><br><p>  Folgendes bekommen wir: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0ab/902/f22/0ab902f229dcfe1f01c1847320de0d67.gif" width="512" height="256"></div><a name="habracut"></a><br>
<h2>  Was ist pix2pix? </h2><br><p>  Auf diese Weise kÃ¶nnen Sie <a href="https://arxiv.org/abs/1611.07004">ein Bild mithilfe von Konkurrenznetzwerken</a> (im Allgemeinen als pix2pix bezeichnet) <a href="https://arxiv.org/abs/1611.07004">in ein Bild</a> konvertieren. </p><br><p>  Der Name "pix2pix" bedeutet, dass das Netzwerk darauf trainiert ist, das Eingabebild in das entsprechende Ausgabebild zu konvertieren.  Hier sind Beispiele fÃ¼r solche Transformationen: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/26b/a03/964/26ba03964ee43872130e7b2f3cb045d6.jpg" width="1132" height="543"></div><br><p>  Das coolste Merkmal von pix2pix ist seine <strong>Vielseitigkeit</strong> .  Anstatt fÃ¼r jede der oben genannten Aufgaben einen neuen Algorithmus oder ein neues Modell zu erstellen, reicht es aus, nur verschiedene DatensÃ¤tze zum Trainieren des Netzwerks zu verwenden. </p><br><p>  Im Gegensatz zu den frÃ¼her verwendeten AnsÃ¤tzen lernt pix2pix, Probleme viel schneller und mit einem kleineren Trainingssatz zu lÃ¶sen.  Die folgenden Ergebnisse wurden beispielsweise beim Training mit der Pascal Titan X-GPU mit einem Datensatz von 400 Bildpaaren in weniger als zwei Stunden erzielt. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/811/84d/5af/81184d5af932f466916b4eec3fc3da97.png" width="1426" height="1044"></div><br><h2>  Wie funktioniert pix2pix? </h2><br><p>  pix2pix verwendet zwei neuronale Netze, die gleichzeitig lernen: </p><br><ol><li>  Generator </li><li>  Diskriminator </li></ol><br><p>  Der Generator versucht, ein Ausgabebild aus den eingegebenen Trainingsdaten zu erzeugen, und der Diskriminator versucht zu bestimmen, ob das Ergebnis real ist oder erzeugt wird. </p><br><p>  Wenn der Generator Bilder erzeugt, die nicht von den realen zu unterscheiden sind (Diskriminator), beginnen wir, den Diskriminator auf sie und die realen Bilder zu trainieren.  Wenn es dem Diskriminator gelingt, echte Bilder von den erzeugten zu unterscheiden, beginnen wir erneut, den Generator so zu trainieren, dass er wieder lernt, den Diskriminator zu tÃ¤uschen. </p><br><p>  Ein solches â€WettrÃ¼stenâ€œ fÃ¼hrt dazu, dass es fÃ¼r eine Person schwierig wird, echte Bilder von generierten zu unterscheiden. </p><br><h2>  Ãœbe </h2><br><p>  Wir werden unseren Filtergenerator fÃ¼r Snapchat mit 256x256 Bildern trainieren (fÃ¼r groÃŸe Formate wird mehr Videospeicher benÃ¶tigt).  Verwenden Sie zum Erstellen eines Datensatzes den <a href="https://github.com/smitshilu/SnapChatFilterExample">Code aus dem vorherigen Lernprogramm</a> . </p><br><p>  Ich habe viele Gesichtsbilder heruntergeladen und auf jedes einen <strong>â€Thug Life Glassesâ€œ</strong> -Filter angewendet.  Es wird sich so etwas wie diese Paare ergeben: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d32/b6d/db6/d32b6ddb611c333f64e055b37ea5547b.jpg" width="1193" height="600"></div><br><p>  Um das Modell zu erstellen, verwenden Sie <a href="https://github.com/affinelayer/pix2pix-tensorflow">das</a> auf TensorFlow basierende pix2pix- <a href="https://github.com/affinelayer/pix2pix-tensorflow">Repository</a> .  Klonen Sie es und <a href="https://www.tensorflow.org/install">installieren Sie</a> Tensorflow. </p><br><p>  Der Befehl zum Starten des Trainings lautet wie folgt: </p><br><pre><code class="plaintext hljs">python pix2pix.py --mode train --output_dir dir_to_save_checkpoint --max_epochs 200 --input_dir dir_with_training_data --which_direction AtoB</code> </pre> <br><p>  Der Parameter <strong>which_direction</strong> legt die Trainingsrichtung fest.  <strong>AtoB</strong> bedeutet, dass wir Bild <strong>A</strong> (links, ohne Brille) in Bild <strong>B</strong> (rechts, mit Brille) <strong>umwandeln</strong> mÃ¶chten.  Beachte Ã¼brigens, dass pix2pix erfolgreich lernen kann, wie man das Originalbild aus einem Bild mit einem Filter wiederherstellt. Ã„ndere einfach die Trainingsrichtung. </p><br><p>  Sie kÃ¶nnen den Trainingsfortschritt mit Tensorboard Ã¼berwachen, fÃ¼r das Sie den Befehl ausfÃ¼hren mÃ¼ssen: </p><br><pre> <code class="plaintext hljs">tensorboard --logdir=dir_to_save_checkpoint</code> </pre> <br><p>  Sobald Sie feststellen, dass die Ergebnisse der Trainingsdaten recht gut sind, kÃ¶nnen Sie das Training beenden und das Modell mit beliebigen Daten testen.  Sie kÃ¶nnen das Training ab dem letzten Kontrollpunkt wie folgt fortsetzen: </p><br><pre> <code class="plaintext hljs">python pix2pix.py --mode train --output_dir dir_to_save_checkpoint --max_epochs 200 --input_dir dir_with_training_data --which_direction AtoB --checkpoint dir_of_saved_checkpoint</code> </pre> <br><h2>  Fazit </h2><br><p>  Das Aufkommen von generativen Netzwerken vom Typ pix2pix erÃ¶ffnet groÃŸe Perspektiven fÃ¼r eine universelle und einfache LÃ¶sung fÃ¼r alle Arten von Bildverarbeitungsaufgaben. </p><br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SJKHhLI31O8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de483310/">https://habr.com/ru/post/de483310/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de483290/index.html">Design Thinking im Projektmanagement oder warum braucht ein Projektmanager kreative Techniken?</a></li>
<li><a href="../de483294/index.html">Wir schreiben einen "Taschenrechner". Teil II Gleichungen lÃ¶sen, in LaTeX rendern, Funktionen auf Superlight beschleunigen</a></li>
<li><a href="../de483298/index.html">Wie man richtig aufhÃ¶rt, damit spÃ¤ter ...</a></li>
<li><a href="../de483302/index.html">Erste Schritte mit Google Sheets in Python. Von der Registrierung bis zum Lesen von Daten</a></li>
<li><a href="../de483308/index.html">VonmoTrade-Experiment. Teil 4: Trading Charts</a></li>
<li><a href="../de483312/index.html">Die groÃŸe Schneeflockentheorie</a></li>
<li><a href="../de483314/index.html">So fÃ¼hren Sie asynchrone Redux-Aktionen mit Redux-Thunk durch</a></li>
<li><a href="../de483316/index.html">Schnelle EinfÃ¼hrung in SwiftUI</a></li>
<li><a href="../de483318/index.html">Bot fÃ¼r die Ãœberwachung von Webdiensten in einer halben Stunde: Telegramm + Bash + Cron</a></li>
<li><a href="../de483320/index.html">Schaffung eines mittelalterlichen VR-Museums</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
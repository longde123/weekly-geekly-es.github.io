<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üè¥Û†ÅßÛ†Å¢Û†Å•Û†ÅÆÛ†ÅßÛ†Åø üõï üö∏ Alles servieren üë®üèø‚Äç‚öïÔ∏è üëåüèø ü¶â</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor nicht allzu langer Zeit gab es in einer ziemlich fernen Galaxie auf einem Provinzplaneten ber√ºhmte Nachkommen von Affen, die so faul waren, dass s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Alles servieren</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440908/"> Vor nicht allzu langer Zeit gab es in einer ziemlich fernen Galaxie auf einem Provinzplaneten ber√ºhmte Nachkommen von Affen, die so faul waren, dass sie beschlossen, k√ºnstliche Intelligenz zu erfinden.  "Nun, was?"  Sie dachten.  Es ist gut, in den Beratern des <s>Overmind ein</s> "Gehirn" zu haben, das bei Bedarf f√ºr Sie denkt, Ihre Probleme k√∂nnen schnell gel√∂st werden und es ist sogar noch besser, als es ein Lebewesen jemals tun kann ... Und ohne √ºber die Konsequenzen nachzudenken, haben sie ihre Affen gestartet Umgekehrte Gehirne und der kognitive Prozess auf Bausteinen zerlegen sich.  Sie dachten, dachten und dachten, Sie werden es nicht glauben - ein Neuronenmodell, ein mathematischer Lernalgorithmus und dann neuronale Netze mit unterschiedlichen Topologien.  Das hat nat√ºrlich nicht sehr gut funktioniert.  Im Vergleich zur nat√ºrlichen Intelligenz gab es viele M√§ngel, aber eine Reihe von Problemen, die wir mit diesen Modellen mit angemessener Genauigkeit l√∂sen konnten.  Und langsam tauchten digitalisierte und serialisierte F√§higkeiten in Form von neuronalen Netzwerkmodellen auf.  Heute, liebe Liebhaber der Geschichte des Universums, werden wir die Organisation und Implementierung verschiedener F√§higkeiten der k√ºnstlichen Intelligenz ansprechen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sa/gk/cs/sagkcsc7kookhhmkxeppqvi7zue.jpeg"></div><a name="habracut"></a><br>  √úber die Erstellung und das Training von Modellen neuronaler Netze (F√§higkeiten) auf Habr√© wird viel geschrieben, daher werden wir heute nicht dar√ºber sprechen.  Nachdem wir serialisierte KI-F√§higkeiten trainiert oder erhalten haben, erwarten wir, dass sie in unseren Zielinformationssystemen verwendet werden. Hier tritt ein Problem auf.  Was am Laborstand funktioniert, kann nicht in seiner urspr√ºnglichen Form in die Produktion √ºbertragen werden. Es ist erforderlich, den gesamten zugeh√∂rigen Technologie-Stack zu implementieren und sogar wesentliche √Ñnderungen an der Zielplattform vorzunehmen (es gibt nat√ºrlich Ausnahmen in Form von CoreML, dies ist jedoch ein Sonderfall und nur f√ºr Apple-Ger√§te).  Dar√ºber hinaus gibt es sehr viele Tools zum Entwickeln und Serialisieren von Modellen. Ist es wirklich notwendig, dass jeder eine separate Integrationsl√∂sung entwickelt?  Dar√ºber hinaus ist es auch im Labor h√§ufig erforderlich, eine schnelle Schlussfolgerung aus dem Modell zu ziehen, ohne auf das Laden des gesamten zugeh√∂rigen Entwicklungsstapels warten zu m√ºssen. <br>  Als Vorschlag zur L√∂sung dieser Probleme m√∂chte ich Ihnen ein relativ neues OpenSource-Tool vorstellen, das Ihnen m√∂glicherweise bei der Entwicklung von Projekten im Zusammenhang mit KI hilfreich sein wird. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">0Mind</a> (lesen Sie ZeroMind) ist ein kostenloser Skill-Server.  Die L√∂sung ist ein modularer, universeller, leicht erweiterbarer Anwendungsserver mit Framework-Elementen f√ºr die Bereitstellung heterogener Modelle f√ºr maschinelles Lernen (leicht zug√§ngliche Ausgabe).  Der Server ist in Python 3 h√§sslich und verwendet Tornado f√ºr die asynchrone Anforderungsverarbeitung.  Unabh√§ngig davon, welches Framework f√ºr maschinelles Lernen zur Vorbereitung und Serialisierung des Modells verwendet wurde, erleichtert 0Mind die Verwendung einer Fertigkeit oder einer Gruppe von Fertigkeiten mithilfe der universellen REST-API.  Tats√§chlich ist die L√∂sung ein asynchroner Webserver mit einer REST-API, die f√ºr die Arbeit mit KI-F√§higkeitsmodellen vereinheitlicht ist, und einer Reihe von Adaptern f√ºr verschiedene Frameworks f√ºr maschinelles Lernen.  M√∂glicherweise haben Sie mit Tensorflow-Serving gearbeitet - dies ist eine √§hnliche L√∂sung, aber 0Mind ist nicht gestapelt und kann mehrere Modelle verschiedener Frameworks auf demselben Port bedienen.  Anstatt den gesamten Technologie-Stack zum Ableiten von AI-Modellen im Zielinformationssystem zu implementieren, k√∂nnen Sie die einfache und vertraute REST-API f√ºr die interessierenden F√§higkeiten verwenden. Au√üerdem bleibt das vorbereitete Modell auf dem Server und landet nicht in der Softwareverteilung.  Um nicht noch einmal mit komplexen Begriffen zu verwechseln, werden wir zu Anwendungsbeispielen √ºbergehen und beginnen, Konsolenzauber zu wirken. <br><br><h1>  Installation </h1><br>  Hier ist alles einfach: <br><br><pre><code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> git@github.com:MisteryX/0Mind.git 0Mind</code> </pre> <br>  Jetzt haben wir eine funktionierende Serverinstanz.  Installieren Sie die Abh√§ngigkeiten: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> 0Mind pip3 install -r requirements.txt</code> </pre><br>  Oder wenn Sie Conda verwenden: <br><br><pre> <code class="bash hljs">conda install --yes --file requirements.txt</code> </pre> <br>  Eine wichtige Einschr√§nkung ist, dass der <a href="">Server mehrere Frameworks f√ºr</a> maschinelles Lernen <a href="">unterst√ºtzt.</a> Um nicht alle <a href="">Frameworks</a> abh√§ngig davon hinzuzuf√ºgen und nicht damit zu installieren, entscheiden Sie selbst, welche Framework-Frameworks Sie mit der 0Mind-Instanz auf den Host laden, installieren und konfigurieren Sie diese Tools unabh√§ngig voneinander. <br><br><h1>  Anpassung </h1><br>  Der Einstiegspunkt oder die ausf√ºhrbare Datei des <b>Hauptservers</b> ist <b>model_pool.py</b> . <br>  M√∂gliche Startoptionen sind <b>-c</b> oder <b>--config_file</b> mit dem Pfad zur Konfigurationsdatei.  Standardm√§√üig verwendet <b>0Mind die</b> Datei <b>configs / model_pool_config.json</b> als Konfigurationsdatei.  Der Server verwendet auch die <b>Datei config / logger.json</b> , um die Standardprotokollierung des Python-Protokollierungsmoduls zu steuern. <br><br>  Um die Funktionen zu demonstrieren, k√∂nnen wir die Standardkonfigurationsdatei intakt lassen.  Weitere Informationen zur Konfiguration finden Sie in der <a href="">offiziellen Dokumentation</a> . <br><br>  Die wichtigsten Servereinstellungen sind: ID, Host, Port, Aufgaben. <br><br>  <b>id</b> - (Nummer) eindeutige Kennung des Modellpools (zum Ausgleichen und Adressieren in einem verteilten Netzwerk von Pools) <br>  <b>Host</b> - (Zeichenfolge) Netzwerkadresse oder Dom√§nenname dieses Hosts <br>  <b>port</b> - (Nummer) an welchem ‚Äã‚ÄãPort m√∂chten Sie den 0Mind-Dienst hosten (sollte auf diesem Host frei sein) <br>  <b>Aufgaben</b> - (Liste der Objekte) Eine Liste der Aufgaben, die mit dem Dienst geladen wurden (m√∂glicherweise leer).  In der Standardkonfiguration wird das von Keras erstellte CNN_MNIST-Demomodell geladen, und wir werden es verwenden, um die Funktionen zu demonstrieren. <br><br>  Zus√§tzliche (optionale) Konfigurationsparameter: <br><br>  <b>model_types</b> - (Liste der Zeichenfolgen) Sie k√∂nnen die Typen geladener Modelle auf diesen Pool beschr√§nken, indem Sie sie in dieser Liste <b>angeben</b> .  Wenn die Liste leer ist, gibt es keine Einschr√§nkungen. <br><br>  <b>debug</b> - (Boolescher Typ) ist f√ºr das Aktivieren oder Deaktivieren des Debug-Modus von Tornado verantwortlich.  Im Debug-Modus werden im Fehlerfall erweiterte Fehlerinformationen an stdout zur√ºckgegeben, was bei der Entwicklung von Erweiterungen hilfreich ist. <br><br><h1>  Die M√∂glichkeiten </h1><br>  Die Hauptsache in 0Mind ist die <a href="">Liste der unterst√ºtzten Frameworks</a> und der <a href="">REST-API-Funktionen</a> . <br><br>  Anforderungen an die REST-API k√∂nnen mit einem Browser oder http-Dienstprogrammen ausgef√ºhrt werden.  In diesem Handbuch sowie in der Dokumentation zum Server verwenden wir cURL als einfachstes und kosteng√ºnstigstes Tool f√ºr offene Systeme. <br><br>  Derzeit hat die 0Mind-API insgesamt 10 Anforderungen: <br><br>  1. http: // $ HOST: $ PORT / info - Allgemeine Informationen zur 0Mind-Instanz <br>  2. http: // $ HOST: $ PORT / info / system - Systeminformationen √ºber den Host, auf dem 0Mind ausgef√ºhrt wird <br>  3. http: // $ HOST: $ PORT / info / task - Informationen zur angegebenen Aufgabe <br>  4. http: // $ HOST: $ PORT / info / task - Aufgabenliste der Instanz 0Mind <br>  5. http: // $ HOST: $ PORT / model / list - Eine Liste der Kennungen der in den Pool geladenen Modelle <br>  6. http: // $ HOST: $ PORT / model / info - Zeigt Schnittstelleninformationen zum Modell an <br>  7. http: // $ HOST: $ PORT / model / load - L√§dt ein neues Modell in den Pool hoch <br>  8. http: // $ HOST: $ PORT / model / drop - entl√§dt ein zuvor geladenes Modell aus dem Pool <br>  9. http: // $ HOST: $ PORT / model / Predict - fordert die Ausgabe des Modells an <br>  10.http: // $ HOST: $ PORT / command / stop - Stoppt den 0Mind-Dienst und beendet seinen Prozess <br><br><h2>  Informationen </h2><br>  Sie k√∂nnen beispielsweise eine Serverinstanz wie folgt starten: <br><br><pre> <code class="bash hljs">python3 model_pool.py</code> </pre> <br>  Beispielsweise erhalten wir allgemeine Informationen zu einer laufenden Serverinstanz: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/info</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"service"</span></span>: <span class="hljs-string"><span class="hljs-string">"ModelPool"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"options"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"debug"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>}, <span class="hljs-attr"><span class="hljs-attr">"version"</span></span>: [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>]}</code> </pre> <br>  Ok, jetzt finden wir heraus, welche Modelle in den Pool geladen werden: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/list</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"check_sum"</span></span>: <span class="hljs-string"><span class="hljs-string">"4d8a15e3cc35750f016ce15a43937620"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"models"</span></span>: [<span class="hljs-string"><span class="hljs-string">"1"</span></span>]}</code> </pre> <br>  Lassen Sie uns nun die Schnittstelle des geladenen Modells mit der Kennung "1" verdeutlichen: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/info?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"inputs"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"0"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"conv2d_1_input:0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"shape"</span></span>: [<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]}}, <span class="hljs-attr"><span class="hljs-attr">"outputs"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"0"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"dense_2/Softmax:0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"shape"</span></span>: [<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]}}, <span class="hljs-attr"><span class="hljs-attr">"tool"</span></span>: <span class="hljs-string"><span class="hljs-string">"keras"</span></span>}</code> </pre> <br>  Es bleibt abzuwarten, mit welchen Filtern das Modell geladen wird.  Dazu kl√§ren wir die Details der Aufgabe des Ladens des Modells mit der Kennung "1": <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/info/task?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_file"</span></span>: <span class="hljs-string"><span class="hljs-string">"ML/models/mnist_cnn_model.keras"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_type"</span></span>: <span class="hljs-string"><span class="hljs-string">"keras"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"input_filters"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"conv2d_1_input:0"</span></span>: [<span class="hljs-string"><span class="hljs-string">"i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter"</span></span>]}, <span class="hljs-attr"><span class="hljs-attr">"output_filters"</span></span>: {}}</code> </pre> <br>  Wie Sie sehen k√∂nnen, verf√ºgt unser Modell √ºber einen Eingabefilter - i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter - und filtert die Eingabe mit dem Namen - conv2d_1_input: 0.  Dieser Filter konvertiert einfach die angegebene Bilddatei in einen Tensor und skaliert sie entsprechend der Modelleingabe.  <a href="">Filter</a> sind ein weiteres gro√üartiges verallgemeinertes 0Mind-Tool.  Da die Vor- und Nachbearbeitung von Daten f√ºr Modelle identisch ist, k√∂nnen Sie diese Filter einfach zur schnellen Verwendung bei der weiteren Arbeit mit anderen Modellen akkumulieren und die gew√ºnschte Aufgabe als Attribut zum Laden des Modells angeben. <br><br><h2>  Datenausgabe aus dem Modell (Inferenz) </h2><br>  Nun, da wir alle Informationen haben, die f√ºr die Schlussfolgerung erforderlich sind, k√∂nnen wir aus dem Modell eine Schlussfolgerung ziehen.  Als Eingabe verwenden wir das Bild aus der Testsuite, das in der <b>Verteilung</b> 0Mind <b>samples / image5.png enthalten ist</b> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o0/rr/h7/o0rrh7cyclpin4vxxjx9nqaytxc.png"></div><br><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"conv2d_1_input:0": [{"image_file": "samples/image5.png"}]}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/predict?id=1</code> </pre> <br>  An die einzige Eingabe des Modells "conv2d_1_input: 0" mit dem Filter "i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter" senden wir die Daten in dem vom Filter akzeptierten Format - [{"image_file": "samples / image5.png"}].  Als Antwort von 0Mind erhalten wir die Modellausgabe: <br><br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"dense_2/Softmax:0"</span></span>: [[<span class="hljs-number"><span class="hljs-number">2.190017217283827e-21</span></span>, <span class="hljs-number"><span class="hljs-number">1.6761866200587505e-11</span></span>, <span class="hljs-number"><span class="hljs-number">2.2447325167271673e-14</span></span>, <span class="hljs-number"><span class="hljs-number">0.00011080023978138342</span></span>, <span class="hljs-number"><span class="hljs-number">1.881280855367115e-17</span></span>, <span class="hljs-number"><span class="hljs-number">0.9998891353607178</span></span>, <span class="hljs-number"><span class="hljs-number">1.6690393796396863e-16</span></span>, <span class="hljs-number"><span class="hljs-number">9.67975005705668e-12</span></span>, <span class="hljs-number"><span class="hljs-number">1.1265206161566871e-13</span></span>, <span class="hljs-number"><span class="hljs-number">2.086113400079359e-13</span></span>]]}, <span class="hljs-attr"><span class="hljs-attr">"model_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.002135753631591797</span></span>}</code> </pre> <br>  Die einzige Ausgabe des Modells ‚Äûdens_2 / Softmax: 0‚Äú (siehe Informationen zum obigen Modell) gab uns den Vertrauensvektor des Modells f√ºr die Klassifizierung dieses Bildes.  Wie Sie sehen k√∂nnen, betr√§gt die h√∂chste Wahrscheinlichkeit 0,99 f√ºr eine Klasse mit einem Index von 6 (Klassen sind die Zahlen 0 bis 9), was der Zahl <b>5 entspricht</b> .  Somit hat das Modell die Anerkennung des Manuskripts erfolgreich bew√§ltigt und mit hoher Sicherheit eine Schlussfolgerung gezogen.  Die Inferenzzeit des Modells auf dem 0Mind-Host betrug 0,002135753631591797 Sekunden, weil  Die Ausgabe erfolgte auf einer normalen x86-CPU. <br><br><h2>  Dynamisches Be- und Entladen von Modellen </h2><br>  Laden Sie jetzt unser Modell aus dem Pool: <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/drop?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"unload_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.000152587890625</span></span>, <span class="hljs-attr"><span class="hljs-attr">"memory_released"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_id"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>}</code> </pre> <br>  Wir laden dasselbe Modell erneut, jedoch jetzt mit einem anderen Bezeichner (‚Äûneu‚Äú) und einem Ausgabefilter des Modells io_argmax.ArgMaxFilter, der den Index h√∂chstwahrscheinlich aus dem Modellvertrauensvektor ableitet.  Wir m√ºssen die Indizes der Ein- und Ausg√§nge des Modells √§ndern - dies liegt an den Funktionen von Keras: <br><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"id": "new", "output_filters": {"dense_2_1/Softmax:0": ["io_argmax.ArgMaxFilter"]}, "model_file": "ML/models/mnist_cnn_model.keras", "input_filters": {"conv2d_1_input_1:0": ["i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter"]}, "model_type": "keras"}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/load</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"load_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.45618462562561035</span></span>, <span class="hljs-attr"><span class="hljs-attr">"memory_consumed"</span></span>: <span class="hljs-number"><span class="hljs-number">16183296</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_id"</span></span>: <span class="hljs-string"><span class="hljs-string">"new"</span></span>}</code> </pre> <br>  Und jetzt bitten wir das Modell, zwei Bilder gleichzeitig in einer Anfrage zu erkennen. <b>Samples / image5.png</b> und <b>samples / image1.png</b> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o0/rr/h7/o0rrh7cyclpin4vxxjx9nqaytxc.png"></div><div style="text-align:center;"><img src="https://habrastorage.org/webt/bv/ha/79/bvha79zohijfpxiilvn1w12wze4.png"></div><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"conv2d_1_input:0": [{"image_file": "samples/image5.png"}, {"image_file": "samples/image1.png"}]}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/predict?id=new</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"dense_2_1/Softmax:0"</span></span>: [<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]}, <span class="hljs-attr"><span class="hljs-attr">"model_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.003907206535339355</span></span>}</code> </pre> <br>  Das Demomodell wurde nicht noch einmal verwechselt. <br><br><h1>  Erweiterung </h1><br>  Die Erweiterung der Funktionen von 0Mind ist dank seiner modularen Architektur, der Verwendung beliebter Tools und guter Codekonventionen im Projekt nicht schwierig.  Die Haupterweiterungsvektoren k√∂nnen sein: <br><br><ol><li>  <a href="">Adapter</a> sind Interlayer-Klassen f√ºr die Arbeit mit neuen Frameworks f√ºr maschinelles Lernen und neuronale Netze. </li><li>  <a href="">Filter</a> sind Datenhandler zum Eingeben und Verlassen von Fertigkeitsmodellen. </li><li>  <a href="">Anforderungshandler</a> - Erm√∂glichen das Hinzuf√ºgen neuer Funktionen zu den 0Mind-API-Anforderungen und -Antworten. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440908/">https://habr.com/ru/post/de440908/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440898/index.html">Content Marketing, kontextbezogene Werbung, Verbesserung der Conversion: 6 n√ºtzliche Anleitungen zur Startup-Promotion</a></li>
<li><a href="../de440900/index.html">REST Leidenschaft f√ºr 200</a></li>
<li><a href="../de440902/index.html">Das halbe K√∂nigreich f√ºr KI: Wie viel Banken sparen an maschinellem Lernen, neuronalen Netzen und Chat-Bots?</a></li>
<li><a href="../de440904/index.html">Vergleich von Viper- und MVVM-Architekturen: So wenden Sie beide an</a></li>
<li><a href="../de440906/index.html">Webinar "167-–§–ó. Wie Banken die Anforderungen der Zentralbank an Betrugsbek√§mpfungssysteme erf√ºllen k√∂nnen ‚Äú- 26. Februar 2019, 11:00 Uhr Moskauer Zeit</a></li>
<li><a href="../de440910/index.html">Warum monopolisieren Banken Blockchain?</a></li>
<li><a href="../de440912/index.html">Solcher Schmerz, solcher Schmerz, Infrastruktur als Dienst 1: 0</a></li>
<li><a href="../de440914/index.html">Ich habe das Vertrauen in die Industrie verloren, bin ausgebrannt, aber der Kult des Werkzeugs hat mich gerettet</a></li>
<li><a href="../de440916/index.html">Strahlung: Einheiten</a></li>
<li><a href="../de440918/index.html">Sicherheitswoche 08: VFEMail live hacken</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë±üèø üëáüèº üëÇüèº Alta disponibilidade do MySQL no GitHub üïú üêÜ üë©üèæ‚Äçü§ù‚Äçüë©üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O GitHub usa o MySQL como seu data warehouse principal para tudo que n√£o est√° relacionado ao git , portanto, a disponibilidade do MySQL √© essencial pa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Alta disponibilidade do MySQL no GitHub</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/432088/"><p> O GitHub usa o MySQL como seu data warehouse principal para tudo que n√£o est√° relacionado ao <code>git</code> , portanto, a disponibilidade do MySQL √© essencial para a opera√ß√£o normal do GitHub.  O site em si, a API do GitHub, o sistema de autentica√ß√£o e muitos outros recursos requerem acesso aos bancos de dados.  Usamos v√°rios clusters do MySQL para lidar com v√°rios servi√ßos e tarefas.  Eles s√£o configurados de acordo com o esquema cl√°ssico, com um n√≥ <em>principal</em> dispon√≠vel para grava√ß√£o e suas r√©plicas.  <em>As r√©plicas</em> (outros n√≥s do cluster) reproduzem assincronamente as altera√ß√µes no n√≥ principal e fornecem acesso de leitura. </p><br><p>  A disponibilidade de sites host √© cr√≠tica.  Sem o n√≥ principal, o cluster n√£o suporta a grava√ß√£o, o que significa que voc√™ n√£o pode salvar as altera√ß√µes necess√°rias.  Corrigir transa√ß√µes, registrar problemas, criar novos usu√°rios, reposit√≥rios, revis√µes e muito mais ser√° simplesmente imposs√≠vel. </p><br><p>  Para suportar a grava√ß√£o, √© necess√°rio um n√≥ acess√≠vel correspondente - o n√≥ principal no cluster.  No entanto, a capacidade de identificar ou <em>detectar</em> esse n√≥ √© igualmente importante. </p><br><p>  Em caso de falha do n√≥ principal atual, √© importante garantir a apar√™ncia imediata de um novo servidor para substitu√≠-lo, al√©m de poder notificar rapidamente todos os servi√ßos sobre essa altera√ß√£o.  O tempo de inatividade total consiste no tempo gasto para detectar uma falha, executar failover e notificar sobre um novo n√≥ principal. </p><br><p><img src="https://habrastorage.org/webt/m8/ah/po/m8ahpo0jhrucgwj3kb5u7hn9edo.jpeg"></p><a name="habracut"></a><br><p>  Esta publica√ß√£o descreve uma solu√ß√£o para garantir a alta disponibilidade do MySQL no GitHub e descobrir o servi√ßo principal, o que nos permite executar opera√ß√µes de maneira confi√°vel que abrangem v√°rios data centers, manter a operacionalidade quando alguns desses centros n√£o estiverem dispon√≠veis e garantir tempo de inatividade m√≠nimo em caso de falha. </p><br><h3 id="celi-obespecheniya-vysokoy-dostupnosti">  Objetivos de alta disponibilidade </h3><br><p>  A solu√ß√£o descrita neste artigo √© uma vers√£o nova e aprimorada das solu√ß√µes anteriores de alta disponibilidade (HA) implementadas no GitHub.  √Ä medida que crescemos, precisamos adaptar a estrat√©gia de alta disponibilidade do MySQL para mudar.  N√≥s nos esfor√ßamos para seguir abordagens semelhantes para o MySQL e outros servi√ßos no GitHub. </p><br><p>  Para encontrar a solu√ß√£o certa para alta disponibilidade e descoberta de servi√ßos, voc√™ deve primeiro responder a algumas perguntas espec√≠ficas.  Aqui est√° uma lista de amostra deles: </p><br><ul><li>  Qual tempo de inatividade m√°ximo n√£o √© cr√≠tico para voc√™? </li><li>  Qu√£o confi√°veis ‚Äã‚Äãs√£o as ferramentas de detec√ß√£o de falhas?  Os falsos positivos (processamento prematuro de falhas) s√£o cr√≠ticos para voc√™? </li><li>  Qu√£o confi√°vel √© o sistema de failover?  Onde pode ocorrer uma falha? </li><li>  Qual a efic√°cia da solu√ß√£o em v√°rios data centers?  Qual a efic√°cia da solu√ß√£o em redes de baixa e alta lat√™ncia? </li><li>  A solu√ß√£o continuar√° funcionando no caso de uma falha completa do datacenter (DPC) ou isolamento da rede? </li><li>  Que mecanismo (se houver) evita ou mitiga as conseq√º√™ncias do surgimento de dois servidores principais no cluster que registram independentemente? </li><li>  A perda de dados √© cr√≠tica para voc√™?  Em caso afirmativo, at√© que ponto? </li></ul><br><p>  Para demonstrar, vamos primeiro considerar a solu√ß√£o anterior e discutir por que decidimos abandon√°-la. </p><br><h3 id="otkaz-ot-ispolzovaniya-vip-i-dns-dlya-obnaruzheniya">  Recusa em usar VIP e DNS para descoberta </h3><br><p>  Como parte da solu√ß√£o anterior, usamos: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">orquestrador</a> para detec√ß√£o de falhas e failover; </li><li>  VIP e DNS para descoberta de host. </li></ul><br><p>  Nesse caso, os clientes descobriram um n√≥ de grava√ß√£o por seu nome, por exemplo, <code>mysql-writer-1.github.net</code> .  O nome foi usado para determinar o endere√ßo IP virtual (VIP) do n√≥ principal. </p><br><p>  Assim, em uma situa√ß√£o normal, os clientes simplesmente precisavam resolver o nome e se conectar ao endere√ßo IP recebido, onde o n√≥ principal j√° estava esperando por eles. </p><br><p>  Considere a seguinte topologia de replica√ß√£o que abrange tr√™s datacenters diferentes: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8fa/e2e/4f3/8fae2e4f382f3060b5a14ed9d80a5f67.png" alt="imagem"></p><br><p>  No caso de uma falha do n√≥ principal, um novo servidor deve ser designado ao seu local (uma das r√©plicas). </p><br><p>  <code>orchestrator</code> detecta uma falha, seleciona um novo n√≥ principal e depois atribui o nome / VIP.  Na verdade, os clientes n√£o sabem a identidade do n√≥ principal, eles apenas conhecem o nome, que agora deve apontar para o novo n√≥.  No entanto, preste aten√ß√£o nisso. </p><br><p>  Os endere√ßos VIP s√£o compartilhados, os pr√≥prios servidores de banco de dados solicitam e os possuem.  Para receber ou liberar um VIP, o servidor deve enviar uma solicita√ß√£o ARP.  O servidor que possui o VIP deve primeiro liber√°-lo antes que o novo mestre possa acessar esse endere√ßo.  Essa abordagem leva a algumas consequ√™ncias indesej√°veis: </p><br><ul><li>  No modo normal, o sistema de failover entrar√° em contato primeiro com o n√≥ principal com falha e solicitar√° a libera√ß√£o do VIP e, em seguida, passar√° para o novo servidor principal com uma solicita√ß√£o de atribui√ß√£o VIP.  Mas o que fazer se o primeiro n√≥ principal estiver indispon√≠vel ou recusar uma solicita√ß√£o para liberar o endere√ßo VIP?  Dado que o servidor est√° atualmente em um estado de falha, √© improv√°vel que ele possa responder a uma solicita√ß√£o a tempo ou responder a ela de alguma forma. <br><ol><li>  Como resultado, uma situa√ß√£o pode surgir quando dois hosts reivindicam seus direitos ao mesmo VIP.  Clientes diferentes podem se conectar a qualquer um desses servidores, dependendo do caminho mais curto da rede. </li><li>  A opera√ß√£o correta nessa situa√ß√£o depende da intera√ß√£o de dois servidores independentes e essa configura√ß√£o n√£o √© confi√°vel. </li></ol></li><li>  Mesmo que o primeiro n√≥ principal responda √†s solicita√ß√µes, perdemos um tempo valioso: a mudan√ßa para o novo servidor principal n√£o ocorre enquanto entramos em contato com o antigo. </li><li>  Al√©m disso, mesmo no caso de reatribui√ß√£o de VIPs, n√£o h√° garantia de que as conex√µes de clientes existentes no servidor antigo sejam desconectadas.  Novamente, corremos o risco de estar em uma situa√ß√£o com dois n√≥s principais independentes. </li></ul><br><p>  Aqui e ali, em nosso ambiente, os endere√ßos VIP s√£o associados a um local f√≠sico.  Eles s√£o atribu√≠dos a um switch ou roteador.  Portanto, podemos reatribuir um endere√ßo VIP apenas para um servidor localizado no mesmo ambiente que o host original.  Em particular, em alguns casos, n√£o poderemos atribuir um servidor VIP em outro datacenter e precisaremos fazer altera√ß√µes no DNS. </p><br><ul><li>  A distribui√ß√£o de altera√ß√µes no DNS leva mais tempo.  Os clientes armazenam nomes DNS por um per√≠odo predefinido.  O failover envolvendo v√°rios data centers acarreta maior tempo de inatividade, pois leva mais tempo para fornecer a todos os clientes informa√ß√µes sobre o novo n√≥ principal. </li></ul><br><p>  Essas restri√ß√µes foram suficientes para nos for√ßar a come√ßar a busca por uma nova solu√ß√£o, mas tamb√©m tivemos que levar em considera√ß√£o o seguinte: </p><br><ul><li>  Os n√≥s principais transmitiram independentemente os pacotes de pulsos atrav√©s do <code>pt-heartbeat</code> para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">medir o atraso e a regula√ß√£o de carga</a> .  O servi√ßo teve que ser transferido para o n√≥ principal rec√©m-nomeado.  Se poss√≠vel, ele deveria ter sido desativado no servidor antigo. </li><li>  Da mesma forma, os principais n√≥s controlavam independentemente a opera√ß√£o do <a href="">Pseudo-GTID</a> .  Foi necess√°rio iniciar esse processo no novo n√≥ principal e, de prefer√™ncia, parar no antigo. </li><li>  O novo n√≥ principal tornou-se grav√°vel.  O n√≥ antigo (se poss√≠vel) deve ter <code>read_only</code> (somente leitura). </li></ul><br><p>  Essas etapas adicionais levaram a um aumento no tempo de inatividade geral e adicionaram seus pr√≥prios pontos de falha e problemas. </p><br><p>  A solu√ß√£o funcionou e o GitHub tratou com √™xito as falhas do MySQL em segundo plano, mas quer√≠amos melhorar nossa abordagem ao HA da seguinte forma: </p><br><ul><li>  garantir independ√™ncia de data centers espec√≠ficos; </li><li>  garantir a operacionalidade em caso de falhas no data center; </li><li>  Abandonar fluxos de trabalho colaborativos n√£o confi√°veis </li><li>  reduzir o tempo de inatividade total; </li><li>  Execute, na medida do poss√≠vel, failover sem perda. </li></ul><br><h3 id="ha-reshenie-github-orchestrator-consul-glb">  Solu√ß√£o GitHub HA: orquestrador, c√¥nsul, GLB </h3><br><p>  Nossa nova estrat√©gia, juntamente com as melhorias anexas, elimina a maioria dos problemas mencionados acima ou atenua suas conseq√º√™ncias.  Nosso sistema atual de alta disponibilidade consiste nos seguintes elementos: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">orquestrador</a> para detec√ß√£o de falhas e failover.  Usamos o esquema <a href="">orquestrador / jangada</a> com v√°rios data centers, como mostra a figura abaixo; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√¥nsul</a> Hashicorp para descoberta de servi√ßos; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GLB / HAProxy</a> como uma camada de proxy entre clientes e n√≥s de grava√ß√£o.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O c√≥digo fonte</a> do GLB Director est√° aberto; </li><li>  tecnologia <code>anycast</code> para roteamento de rede. </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/762/fb4/7a0/762fb47a0de253cce045889faa945228.png" alt="imagem"></p><br><p>  O novo esquema permitiu abandonar completamente as altera√ß√µes no VIP e no DNS.  Agora, ao introduzir novos componentes, podemos separ√°-los e simplificar a tarefa.  Al√©m disso, tivemos a oportunidade de usar solu√ß√µes confi√°veis ‚Äã‚Äãe est√°veis.  Uma an√°lise detalhada da nova solu√ß√£o √© fornecida abaixo. </p><br><h3 id="normalnyy-potok">  Fluxo normal </h3><br><p>  Em uma situa√ß√£o normal, os aplicativos se conectam aos n√≥s de grava√ß√£o via GLB / HAProxy. </p><br><p>  Os aplicativos n√£o recebem a identidade do servidor principal.  Como antes, eles usam apenas o nome.  Por exemplo, o n√≥ principal do <code>cluster1</code> seria <code>mysql-writer-1.github.net</code> .  No entanto, em nossa configura√ß√£o atual, esse nome √© resolvido para o endere√ßo IP do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">anycast</a> . </p><br><p>  Gra√ßas √† tecnologia <code>anycast</code> , o nome √© resolvido para o mesmo endere√ßo IP em qualquer lugar, mas o tr√°fego √© direcionado de maneira diferente, dada a localiza√ß√£o do cliente.  Em particular, v√°rias inst√¢ncias do GLB, nosso balanceador de carga altamente dispon√≠vel, s√£o implantadas em cada um de nossos data centers.  O tr√°fego no <code>mysql-writer-1.github.net</code> sempre roteado para o cluster GLB do data center local.  Por esse motivo, todos os clientes s√£o atendidos por proxies locais. </p><br><p>  Executamos o GLB em cima do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HAProxy</a> .  Nosso servidor HAProxy fornece <em>pools de grava√ß√£o</em> : um para cada cluster do MySQL.  Al√©m disso, cada pool possui apenas um servidor (o n√≥ <em>principal</em> do cluster).  Todas as inst√¢ncias GLB / HAProxy em todos os datacenters t√™m os mesmos conjuntos e todas apontam para os mesmos servidores nesses conjuntos.  Portanto, se o aplicativo deseja gravar dados no banco de dados no <code>mysql-writer-1.github.net</code> , n√£o importa em qual servidor GLB ele se conecta.  Em qualquer um dos casos, um redirecionamento para o n√≥ principal do cluster principal <code>cluster1</code> ser√° executado. </p><br><p>  Para aplicativos, a descoberta termina no GLB e a nova descoberta n√£o √© necess√°ria.  Esse GLB redireciona o tr√°fego para o lugar certo. </p><br><p>  Onde o GLB obt√©m informa√ß√µes sobre quais servidores listar?  Como fazemos altera√ß√µes no GLB? </p><br><h3 id="obnaruzhenie-cherez-consul">  Descoberta atrav√©s do Consul </h3><br><p>  O servi√ßo Consul √© amplamente conhecido como uma solu√ß√£o de descoberta de servi√ßo e tamb√©m assume fun√ß√µes de DNS.  No entanto, no nosso caso, n√≥s o usamos como um armazenamento altamente acess√≠vel de valores-chave (KV). </p><br><p>  No reposit√≥rio KV no Consul, registramos a identidade dos principais n√≥s do cluster.  Para cada cluster, h√° um conjunto de registros KV apontando para os dados do n√≥ principal correspondente: seus endere√ßos <code>fqdn</code> , port, ipv4 e ipv6. </p><br><p>  Cada n√≥ GLB / HAProxy inicia um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">consul-template</a> , um servi√ßo que rastreia altera√ß√µes nos dados do Consul (no nosso caso, altera√ß√µes nos dados dos n√≥s principais).  O <code>consul-template</code> cria um arquivo de configura√ß√£o e pode recarregar o HAProxy ao alterar as configura√ß√µes. </p><br><p>  Por esse motivo, informa√ß√µes sobre como alterar a identidade do n√≥ principal no Consul est√£o dispon√≠veis para cada inst√¢ncia GLB / HAProxy.  Com base nessas informa√ß√µes, a configura√ß√£o das inst√¢ncias √© realizada, os novos n√≥s principais s√£o indicados como a √∫nica entidade no pool de servidores de cluster.  Depois disso, as inst√¢ncias s√£o recarregadas para que as altera√ß√µes entrem em vigor. </p><br><p>  Implantamos inst√¢ncias do Consul em cada data center e cada inst√¢ncia fornece alta disponibilidade.  No entanto, essas inst√¢ncias s√£o independentes uma da outra.  Eles n√£o s√£o replicados e n√£o trocam dados. </p><br><p>  Onde a Consul obt√©m informa√ß√µes sobre altera√ß√µes e como elas s√£o distribu√≠das entre os data centers? </p><br><h3 id="orchestratorraft">  orquestrador / de jangada </h3><br><p>  Usamos o esquema <code>orchestrator/raft</code> : os n√≥s do <code>orchestrator</code> comunicam atrav√©s do consenso da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">jangada</a> .  Em cada data center, temos um ou dois n√≥s do <code>orchestrator</code> . </p><br><p>  <code>orchestrator</code> √© respons√°vel por detectar falhas, failover do MySQL e transferir os dados alterados do n√≥ principal para o Consul.  O failover √© gerenciado por um √∫nico host de <code>orchestrator/raft</code> , mas as <em>altera√ß√µes</em> , not√≠cias de que o cluster agora √© um novo mestre, s√£o propagadas para todos os n√≥s do <code>orchestrator</code> usando o mecanismo de <code>raft</code> . </p><br><p>  Quando os n√≥s do <code>orchestrator</code> recebem not√≠cias sobre uma altera√ß√£o nos dados do n√≥ principal, cada um deles entra em contato com sua pr√≥pria inst√¢ncia local do Consul e inicia uma grava√ß√£o KV.  Os data centers com v√°rias inst√¢ncias do <code>orchestrator</code> receber√£o v√°rios registros (id√™nticos) no Consul. </p><br><h3 id="obobschennoe-predstavlenie-vsego-potoka">  Visualiza√ß√£o generalizada de todo o fluxo </h3><br><p>  Se o n√≥ principal falhar: </p><br><ul><li>  n√≥s do <code>orchestrator</code> detectam falhas; </li><li>  <code>orchestrator/raft</code> mestre do <code>orchestrator/raft</code> inicia a recupera√ß√£o.  Um novo n√≥ mestre √© designado; </li><li>  o esquema <code>orchestrator/raft</code> transfere os dados sobre a altera√ß√£o do n√≥ principal para todos os n√≥s do cluster de <code>raft</code> ; </li><li>  cada inst√¢ncia do <code>orchestrator/raft</code> recebe uma notifica√ß√£o sobre uma altera√ß√£o de n√≥ e grava a identidade do novo n√≥ mestre no armazenamento KV local no Consul; </li><li>  em cada inst√¢ncia GLB / HAProxy, o servi√ßo <code>consul-template</code> √© iniciado, que monitora as altera√ß√µes no reposit√≥rio KV no Consul, reconfigura e reinicia o HAProxy; </li><li>  O tr√°fego do cliente √© redirecionado para o novo n√≥ principal. </li></ul><br><p>  Para cada componente, as responsabilidades s√£o claramente distribu√≠das e toda a estrutura √© diversificada e simplificada.  <code>orchestrator</code> n√£o interage com os balanceadores de carga.  O Consul n√£o exige informa√ß√µes sobre a origem das informa√ß√µes.  Servidores proxy funcionam apenas com o Consul.  Os clientes trabalham apenas com servidores proxy. </p><br><p>  Al√©m disso: </p><br><ul><li>  N√£o h√° necessidade de fazer altera√ß√µes no DNS e disseminar informa√ß√µes sobre eles; </li><li>  TTL n√£o √© usado; </li><li>  o encadeamento n√£o aguarda respostas do host em um estado de erro.  Em geral, √© ignorado. </li></ul><br><h3 id="dopolnitelnaya-informaciya">  Informa√ß√µes Adicionais </h3><br><p>  Para estabilizar o fluxo, tamb√©m aplicamos os seguintes m√©todos: </p><br><ul><li>  O par√¢metro HAProxy <code>hard-stop-after</code> for√ßada <code>hard-stop-after</code> √© definido como um valor muito pequeno.  Quando o HAProxy √© reinicializado com o novo servidor no pool de grava√ß√£o, o servidor termina automaticamente todas as conex√µes existentes com o n√≥ principal antigo. <br><ol><li>  A configura√ß√£o do par√¢metro <code>hard-stop-after</code> permite que voc√™ n√£o espere nenhuma a√ß√£o dos clientes. Al√©m disso, as consequ√™ncias negativas da poss√≠vel ocorr√™ncia de dois n√≥s principais no cluster s√£o minimizadas.  √â importante entender que n√£o h√° m√°gica aqui e, de qualquer forma, <em>algum tempo</em> passa antes que os velhos la√ßos sejam rompidos.  Mas h√° um momento no qual podemos parar de esperar por surpresas desagrad√°veis. </li></ol></li><li>  N√£o exigimos a disponibilidade continuada do servi√ßo Consul.  De fato, precisamos que ele esteja dispon√≠vel apenas durante o failover.  Se o servi√ßo Consul n√£o estiver respondendo, o GLB continuar√° trabalhando com os mais recentes valores conhecidos e n√£o tomar√° medidas dr√°sticas. </li><li>  O GLB est√° configurado para verificar a identidade do n√≥ principal rec√©m-atribu√≠do.  Assim como em nossos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pools MySQL sens√≠veis ao contexto</a> , √© realizada uma verifica√ß√£o para confirmar se o servidor √© realmente grav√°vel.  Se excluirmos acidentalmente a identidade do n√≥ principal no Consul, n√£o haver√° problemas, um registro vazio ser√° ignorado.  Se escrevermos por engano o nome de outro servidor (n√£o o principal) no Consul, ent√£o, tudo bem: o GLB n√£o o atualizar√° e continuar√° trabalhando com o √∫ltimo estado v√°lido. </li></ul><br><p>  Nas se√ß√µes a seguir, analisamos os problemas e analisamos os objetivos de alta disponibilidade. </p><br><h3 id="obnaruzhenie-sboev-s-pomoschyu-orchestratorraft">  Detec√ß√£o de falha com orquestrador / jangada </h3><br><p>  <code>orchestrator</code> adota uma <a href="">abordagem abrangente</a> para a detec√ß√£o de falhas, o que garante alta confiabilidade da ferramenta.  N√£o encontramos resultados falsos positivos, falhas prematuras n√£o s√£o realizadas, o que significa que o tempo de inatividade desnecess√°rio √© exclu√≠do. </p><br><p>  O circuito do <code>orchestrator/raft</code> tamb√©m lida com situa√ß√µes de isolamento completo da rede do data center (esgrima do data center).  O isolamento da rede do datacenter pode causar confus√£o: os servidores dentro do datacenter podem se comunicar.  Como entender quem √© realmente isolado - servidores <em>em um determinado</em> data center ou em todos os <em>outros</em> data centers? </p><br><p>  No esquema <code>orchestrator/raft</code> , o mestre da <code>orchestrator/raft</code> √© o failover.  O n√≥ se torna o l√≠der, que recebe o apoio da maioria no grupo (quorum).  Implementamos o n√≥ do <code>orchestrator</code> maneira que nenhum data center possa fornecer a maioria, enquanto qualquer data center <code>n-1</code> pode fornec√™-lo. </p><br><p>  No caso de isolamento completo da rede do centro de dados, os n√≥s do <code>orchestrator</code> neste centro s√£o desconectados dos n√≥s semelhantes em outros centros de dados.  Como resultado, os n√≥s do <code>orchestrator</code> em um datacenter isolado n√£o podem se tornar l√≠deres em um cluster de <code>raft</code> .  Se esse n√≥ era o mestre, ele perde esse status.  Um novo host receber√° um dos n√≥s dos outros datacenters.  Esse l√≠der ter√° o suporte de todos os outros data centers que podem interagir entre si. </p><br><p>  Dessa maneira, o mestre do <code>orchestrator</code> estar√° sempre fora do data center isolado na rede.  Se o n√≥ principal estava no datacenter isolado, o <code>orchestrator</code> inicia um failover para substitu√≠-lo pelo servidor de um dos datacenters dispon√≠veis.  Atenuamos o impacto do isolamento do datacenter delegando decis√µes ao quorum de datacenters dispon√≠veis. </p><br><h3 id="uskorennoe-opoveschenie">  Notifica√ß√£o mais r√°pida </h3><br><p>  O tempo de inatividade total pode ser reduzido ainda mais acelerando a notifica√ß√£o de uma altera√ß√£o no n√≥ principal.  Como conseguir isso? </p><br><p>  Quando o <code>orchestrator</code> inicia o failover, ele considera um grupo de servidores, um dos quais pode ser atribu√≠do como principal.  Dadas as regras, recomenda√ß√µes e limita√ß√µes de replica√ß√£o, ele √© capaz de tomar uma decis√£o informada sobre o melhor curso de a√ß√£o. </p><br><p>  De acordo com os seguintes sinais, ele tamb√©m pode entender que um servidor acess√≠vel √© <em>um candidato ideal</em> para o compromisso principal: </p><br><ul><li>  nada impede que o servidor fique elevado (e talvez o usu√°rio recomende esse servidor); </li><li>  √© esperado que o servidor possa usar todos os outros servidores como r√©plicas. </li></ul><br><p>  Nesse caso, o <code>orchestrator</code> primeiro configura o servidor como grav√°vel e anuncia imediatamente um aumento em seu status (no nosso caso, ele grava o registro no reposit√≥rio KV no Consul).   orchestrator     ,     . </p><br><p>  ,    ,    GLB   ,     ,     .   :    ! </p><br><h3 id="polusinhronnaya-replikaciya">   </h3><br><p>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> MySQL         ,           .       :  ,    ,   ,        . </p><br><p>     ,      .        ,    ,   .  ,    ,           ,    . </p><br><p>       : <code>500 </code> .                    .          (    ),          . </p><br><p>                   (   )    .           ,      . </p><br><p>       ,        <em> </em>     .            <em></em> ,      ,  <em></em>    .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ,       <em> </em> , ,       . </p><br><h3 id="peredacha-paketov-pulsa">    </h3><br><p>  ,   /  <code>pt-heartbeat</code>  /  ,       .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ,   <code>pt-heartbeat</code>     ,       <code>read_only</code> ,    . </p><br><p>      <code>pt-heartbeat</code>     ,     .       .               .     ,  <code>pt-heartbeat</code>              . </p><br><h3 id="delegirovanie-zadach-orchestrator">   orchestrator </h3><br><p>    orchestrator  : </p><br><ul><li>  Pseudo-GTID; </li><li>       ,    ; </li><li>         ( <code>read_only</code> ),   . </li></ul><br><p>    ,     . ,      ,      ,      .     <code>orchestrator</code>         . </p><br><h3 id="ogranicheniya-i-nedostatki">    </h3><br><p>  -   ,        ,         .     ,   -,         . </p><br><p>     ,       . </p><br><p> ,      ,     ,     -      .         .               <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">STONITH</a>    .    ,  <em> </em> ,       ,    ¬´¬ª -   .  ,       ,  . </p><br><p>    :  Consul    ,     . .  , ,      ,    ,      . </p><br><h3 id="rezultaty">  </h3><br><p>   orchestrator/GLB/Consul   : </p><br><ul><li>   ; </li><li>      ; </li><li>       ; </li><li>    ; </li><li>  ,      (    ); </li><li>    ; </li><li>    <code>10-13 </code>   . <br><ol><li>        <code>20 </code> ,      ‚Äî <code>25 </code> . </li></ol></li></ul><br><h3 id="zaklyuchenie">  Conclus√£o </h3><br><p>  ¬´// ¬ª         ,   ,   .       .     ,    . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt432088/">https://habr.com/ru/post/pt432088/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt432078/index.html">Tr√°fego no final do t√∫nel ou DNS no pentest</a></li>
<li><a href="../pt432080/index.html">Conceitos equivocados dos jogadores ao avaliar riscos. Controle do gerador de n√∫meros aleat√≥rios em desenvolvimento</a></li>
<li><a href="../pt432082/index.html">Microsoft AI Chatbot lan√ßa cole√ß√£o de roupas na China</a></li>
<li><a href="../pt432084/index.html">Como organizamos uma competi√ß√£o por turnos entre trabalhadores da produ√ß√£o (como na URSS)</a></li>
<li><a href="../pt432086/index.html">Impress√£o 3D na escola internacional com o nome de M.V. Lomonosov</a></li>
<li><a href="../pt432090/index.html">Magento Meetup Kharkiv No. 4 - reportagens em v√≠deo</a></li>
<li><a href="../pt432092/index.html">Erros desagrad√°veis ‚Äã‚Äãao escrever testes de unidade</a></li>
<li><a href="../pt432094/index.html">Hackathon online conjunto da OpenGift e da plataforma Blockchain de cr√©ditos</a></li>
<li><a href="../pt432096/index.html">Guia completo do CMake. Parte Dois: Build System</a></li>
<li><a href="../pt432098/index.html">Pilotos autom√°ticos no transporte rodovi√°rio, como interagir com promo√ß√µes. por transporte?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
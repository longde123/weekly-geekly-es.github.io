<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëáüèæ üö∑ üë©‚Äçüëß Eine Einf√ºhrung in Kubernetes f√ºr VMware-Benutzer. Teil 1. Theorie üåÅ üïô üéØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dies ist der zweite Teil meiner Kubernetes in der Enterprise-Postserie . Wie ich in meinem letzten Beitrag erw√§hnt habe, ist es beim √úbergang zu ‚ÄûDesi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Eine Einf√ºhrung in Kubernetes f√ºr VMware-Benutzer. Teil 1. Theorie</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataline/blog/436028/">  Dies ist der zweite Teil meiner <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes in der Enterprise-Postserie</a> .  Wie ich in meinem letzten Beitrag erw√§hnt habe, ist es beim √úbergang zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûDesign and Implementation Guides‚Äú</a> sehr wichtig, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dass</a> alle Menschen Kubernetes (K8s) auf dem gleichen Verst√§ndnisniveau haben. <br><br>  Ich m√∂chte hier nicht den traditionellen Ansatz verfolgen, um die Architektur und Technologien von Kubernetes zu erl√§utern, aber ich werde alles durch einen Vergleich mit der vSphere-Plattform erkl√§ren, mit der Sie als VMware-Benutzer vertraut sind.  Auf diese Weise k√∂nnen Sie die offensichtliche Verwirrung und Schwere des Verst√§ndnisses von Kubernetes √ºberwinden.  Ich habe diesen Ansatz in VMware verwendet, um Kubernetes einem unterschiedlichen H√∂rerpublikum vorzustellen. Es hat bewiesen, dass es hervorragend funktioniert und Menschen dabei hilft, Schl√ºsselkonzepte schnell zu beherrschen. <br><br>  Wichtiger Hinweis bevor wir beginnen.  Ich verwende diesen Vergleich nicht, um √Ñhnlichkeiten oder Unterschiede zwischen vSphere und Kubernetes nachzuweisen.  Sowohl das als auch ein anderes sind im Wesentlichen verteilte Systeme und sollten daher √Ñhnlichkeiten mit jedem anderen √§hnlichen System aufweisen.  Daher versuche ich am Ende, einer so breiten Community von Benutzern eine so wunderbare Technologie wie Kubernetes vorzustellen. <br><img src="https://habrastorage.org/webt/2x/8j/gn/2x8jgnlfylvf_sfzkylizlg3huk.png"><a name="habracut"></a><br><br><h3>  Ein bisschen Geschichte </h3><br>  Um diesen Beitrag zu lesen, m√ºssen Sie die Container kennenlernen.  Ich werde die Grundkonzepte von Containern nicht beschreiben, da es viele Ressourcen gibt, die dar√ºber sprechen.  Wenn ich sehr oft mit Kunden spreche, sehe ich, dass sie nicht verstehen k√∂nnen, warum Container unsere Branche eroberten und in Rekordzeit sehr beliebt wurden.  Um diese Frage zu beantworten, werde ich √ºber meine praktischen Erfahrungen beim Verst√§ndnis der Ver√§nderungen in unserer Branche sprechen. <br><br>  Bevor ich die Welt der Telekommunikation erkundete, war ich Webentwickler (2003). <br><br>  Dies war mein zweiter bezahlter Job, nachdem ich als Netzwerktechniker / Administrator gearbeitet hatte (ich wei√ü, dass ich ein Allesk√∂nner war).  Ich habe in PHP entwickelt.  Ich habe alle Arten von Anwendungen entwickelt, angefangen bei kleinen Anwendungen, die mein Arbeitgeber verwendet hat, bis hin zu einer professionellen Abstimmungsanwendung f√ºr Fernsehprogramme und sogar Telekommunikationsanwendungen, die mit VSAT-Hubs und Satellitensystemen interagieren.  Das Leben war gro√üartig, mit Ausnahme einer gro√üen H√ºrde, die jeder Entwickler kennt, n√§mlich der Sucht. <br><br>  Zuerst entwickelte ich die Anwendung auf meinem Laptop unter Verwendung des LAMP-Stacks. Als sie auf meinem Laptop gut funktionierte, lud ich den Quellcode auf die Hostserver (jeder erinnert sich an RackShack?) Oder auf die privaten Server des Kunden herunter.  Sie k√∂nnen sich vorstellen, dass die Anwendung sofort abgest√ºrzt ist und auf diesen Servern nicht funktioniert hat.  Der Grund daf√ºr ist Sucht.  Die Server hatten andere Versionen der Software (Apache, PHP, MySQL usw.) als die von mir auf dem Laptop verwendeten.  Ich musste also einen Weg finden, um die Softwareversionen auf den Remote-Servern zu aktualisieren (schlechte Idee) oder den Code auf meinem Laptop neu zu schreiben, damit er mit den Versionen auf den Remote-Servern √ºbereinstimmt (schlechteste Idee).  Es war ein Albtraum, manchmal hasste ich mich selbst und fragte mich, warum ich so meinen Lebensunterhalt verdiene. <br><br>  10 Jahre sind vergangen, die Firma Docker erschien.  Als VMware-Berater bei Professional Services (2013) h√∂rte ich von Docker und lie√ü mich sagen, dass ich diese Technologie damals nicht verstehen konnte.  Ich fuhr fort zu sagen: Warum Container verwenden, wenn es virtuelle Maschinen gibt.  Warum sollten Sie wichtige Technologien wie vSphere HA, DRS oder vMotion wegen so seltsamer Vorteile wie dem sofortigen Start von Containern oder der Beseitigung des Hypervisor-Overheads aufgeben?  Schlie√ülich arbeitet jeder mit virtuellen Maschinen und funktioniert perfekt.  Kurz gesagt, ich habe es in Bezug auf die Infrastruktur betrachtet. <br><br>  Aber dann fing ich an genau hinzuschauen und es d√§mmerte mir.  Alles, was mit Docker zu tun hat, bezieht sich auf Entwickler.  Als ich gerade anfing, als Entwickler zu denken, wurde mir sofort klar, dass ich mit dieser Technologie im Jahr 2003 alle meine Abh√§ngigkeiten packen k√∂nnte.  Meine Webanwendungen k√∂nnen unabh√§ngig vom verwendeten Server funktionieren.  Dar√ºber hinaus w√§re es nicht erforderlich, den Quellcode herunterzuladen oder etwas zu konfigurieren.  Sie k√∂nnen meine Anwendung einfach in ein Bild ‚Äûpacken‚Äú und Kunden bitten, dieses Bild herunterzuladen und auszuf√ºhren.  Dies ist der Traum eines jeden Webentwicklers! <br><br>  Das alles ist gro√üartig.  Docker hat das gro√üe Interaktions- und Verpackungsproblem gel√∂st, aber wie geht es weiter?  Kann ich als Unternehmenskunde diese Anwendungen w√§hrend der Skalierung verwalten?  Ich m√∂chte weiterhin HA, DRS, vMotion und DR verwenden.  Docker hat die Probleme meiner Entwickler gel√∂st und eine ganze Reihe von Problemen f√ºr meine Administratoren (DevOps-Team) verursacht.  Sie ben√∂tigen eine Plattform zum Starten von Containern, genau wie die zum Starten von virtuellen Maschinen.  Und wir kehrten wieder zum Anfang zur√ºck. <br><br>  Aber dann erschien Google und erz√§hlte der Welt √ºber die Verwendung von Containern seit vielen Jahren (tats√§chlich wurden Container von Google erfunden: cgroups) und die richtige Methode, sie √ºber eine Plattform zu verwenden, die sie Kubernetes nannten.  Dann √∂ffneten sie den Quellcode f√ºr Kubernetes.  Pr√§sentiert der Kubernetes Community.  Und das hat alles wieder ver√§ndert. <br><br><h3>  Grundlegendes zu Kubernetes im Vergleich zu vSphere </h3><br>  Was ist Kubernetes?  Einfach ausgedr√ºckt ist Kubernetes f√ºr Container dasselbe wie vSphere f√ºr virtuelle Maschinen in einem modernen Rechenzentrum.  Wenn Sie VMware Workstation in den fr√ºhen 2000er Jahren verwendet haben, wissen Sie, dass diese L√∂sung ernsthaft als L√∂sung f√ºr Rechenzentren angesehen wurde.  Als VI / vSphere mit vCenter- und ESXi-Hosts erschien, √§nderte sich die Welt der virtuellen Maschinen dramatisch.  Kubernetes macht heute dasselbe mit der Welt der Container und bietet die M√∂glichkeit, Container in der Produktion zu starten und zu verwalten.  Aus diesem Grund werden wir vSphere Seite an Seite mit Kubernetes vergleichen, um die Details dieses verteilten Systems zu erl√§utern und seine Funktionen und Technologien zu verstehen. <br><img src="https://habrastorage.org/webt/2l/ke/vg/2lkevgzxfllfuhfd29vtofvm4ii.png"><br><br><h3>  System√ºbersicht </h3><br>  Wie in vSphere gibt es im Konzept von Kubernetes vCenter- und ESXi-Hosts, es gibt Master- und Node-Hosts.  In diesem Zusammenhang entspricht Master in K8s vCenter in dem Sinne, dass es sich um die Verwaltungsebene eines verteilten Systems handelt.  Es ist auch der Einstiegspunkt f√ºr die API, mit der Sie bei der Verwaltung Ihrer Workload interagieren.  Auf die gleiche Weise fungieren K8s-Knoten √§hnlich wie ESXi-Hosts als Computerressourcen.  Auf ihnen f√ºhren Sie Workloads aus (im Fall von K8s nennen wir sie Pods).  Knoten k√∂nnen virtuelle Maschinen oder physische Server sein.  Bei vSphere ESXi m√ºssen Hosts nat√ºrlich immer physisch sein. <br><img src="https://habrastorage.org/webt/to/va/hq/tovahqozye9ym14sljwpbilywto.png"><br><br>  Sie k√∂nnen sehen, dass K8s einen Schl√ºsselwertspeicher namens "etcd" hat.  Dieser Speicher √§hnelt der vCenter-Datenbank, in der Sie die gew√ºnschte Clusterkonfiguration speichern, die Sie einhalten m√∂chten. <br><br>  Was die Unterschiede betrifft: Auf Master K8s k√∂nnen Sie auch Workloads ausf√ºhren, auf vCenter jedoch nicht.  vCenter ist eine virtuelle Appliance, die ausschlie√ülich der Verwaltung gewidmet ist.  Im Fall von K8s wird Master als Computerressource betrachtet, aber das Ausf√ºhren von Enterprise-Anwendungen darauf ist keine gute Idee. <br><br>  Wie wird es in der Realit√§t aussehen?  Sie werden haupts√§chlich die CLI verwenden, um mit Kubernetes zu interagieren (aber die GUI ist immer noch eine sehr praktikable Option).  Der folgende Screenshot zeigt, dass ich einen Windows-Computer verwende, um √ºber die Befehlszeile eine Verbindung zu meinem Kubernetes-Cluster herzustellen (ich verwende cmder, wenn Sie interessiert sind).  Im Screenshot habe ich einen Master-Knoten und 4 Knoten.  Sie arbeiten unter der Kontrolle von K8s v1.6.5 und das Betriebssystem Ubuntu 16.04 ist auf den Knoten installiert.  Zum Zeitpunkt des Schreibens dieses Beitrags leben wir haupts√§chlich in der Linux-Welt, in der Master und Node immer eine Linux-Distribution ausf√ºhren. <br><br><img src="https://habrastorage.org/webt/gm/qn/gj/gmqngjq1mraqces6uo1sectxm6i.png"><br>  <i>K8s Cluster-Management √ºber CLI und GUI.</i> <br><br><h3>  Workload-Formfaktor </h3><br>  In vSphere ist die virtuelle Maschine die logische Grenze des Betriebssystems.  In Kubernetes sind Pods wie der ESXi-Host Containergrenzen, auf denen mehrere virtuelle Maschinen gleichzeitig ausgef√ºhrt werden k√∂nnen.  Jeder Knoten kann mehrere Pods ausf√ºhren.  Jeder Pod erh√§lt wie virtuelle Maschinen eine routingf√§hige IP-Adresse, √ºber die Pods miteinander kommunizieren k√∂nnen. <br><br>  In vSphere werden Anwendungen innerhalb des Betriebssystems ausgef√ºhrt, und in Kubernetes werden Anwendungen in Containern ausgef√ºhrt.  Eine virtuelle Maschine kann jeweils nur mit einem Betriebssystem arbeiten, und ein Pod kann mehrere Container ausf√ºhren. <br><img src="https://habrastorage.org/webt/hv/cv/9b/hvcv9bj4gw6wsunhhqeqvvfx5d4.png"><br><br>  Auf diese Weise k√∂nnen Sie die Pods im K8s-Cluster mithilfe des kubectl-Tools √ºber die CLI auflisten und die Funktionalit√§t der Pods, ihr Alter, ihre IP-Adresse und die Knoten √ºberpr√ºfen, an denen sie gerade arbeiten. <br><img src="https://habrastorage.org/webt/0u/qj/_0/0uqj_0gl0qmxiqbby9gd8ln98nc.png"><br><br><h3>  Management </h3><br>  Wie verwalten wir unsere Master, Knoten und Pods?  Bei vSphere verwenden wir den Webclient, um die meisten (wenn nicht alle) Komponenten unserer virtuellen Infrastruktur zu verwalten.  F√ºr Kubernetes ebenfalls Dashboard.  Dies ist ein gutes GUI-basiertes Webportal, auf das Sie √ºber Ihren Browser genauso zugreifen k√∂nnen wie mit dem vSphere Web Client.  In den vorherigen Abschnitten k√∂nnen Sie sehen, dass Sie Ihren K8s-Cluster mit dem Befehl kubeclt √ºber die CLI verwalten k√∂nnen.  Es ist immer umstritten, wo Sie die meiste Zeit in der CLI oder im grafischen Dashboard verbringen werden.  Da letzteres von Tag zu Tag immer leistungsf√§higer wird (Sie k√∂nnen dieses Video sicher sehen).  Pers√∂nlich denke ich, dass das Dashboard sehr praktisch ist, um den Status schnell zu √ºberwachen oder die Details verschiedener K8-Komponenten anzuzeigen, sodass keine langen Befehle in die CLI eingegeben werden m√ºssen.  Sie werden auf nat√ºrliche Weise ein Gleichgewicht zwischen ihnen finden. <br><br><img src="https://habrastorage.org/webt/hi/hu/cj/hihucj_bhrydsrgy0ad5xifupuc.png"><br><br><h3>  Konfigurationen </h3><br>  Eines der sehr wichtigen Konzepte in Kubernetes ist der gew√ºnschte Status der Konfigurationen.  Sie erkl√§ren, dass Sie f√ºr fast jede Kubernetes-Komponente √ºber eine YAML-Datei m√∂chten, und erstellen dies alles mit kubectl (oder √ºber ein grafisches Dashboard) als gew√ºnschten Status.  Von nun an ist Kubernetes stets bem√ºht, Ihre Umgebung in einem bestimmten Betriebszustand zu halten.  Wenn Sie beispielsweise 4 Replikate eines Pods haben m√∂chten, √ºberwachen K8s diese Pods weiterhin. Wenn einer von ihnen gestorben ist oder der Knoten, an dem er gearbeitet hat, Probleme hatte, werden K8s sich selbst wiederherstellen und diese automatisch erstellen Pod woanders. <br><br>  Wenn Sie zu unseren YAML-Konfigurationsdateien zur√ºckkehren, k√∂nnen Sie diese als VMX-Datei f√ºr eine virtuelle Maschine oder als OVF-Deskriptor f√ºr eine virtuelle Appliance betrachten, die Sie in vSphere bereitstellen m√∂chten.  Diese Dateien definieren die Konfiguration der Workload / Komponente, die Sie ausf√ºhren m√∂chten.  Im Gegensatz zu VMX / OVF-Dateien, die ausschlie√ülich f√ºr virtuelle VMs / Appliances verf√ºgbar sind, werden YAML-Konfigurationsdateien zum Definieren von K8s-Komponenten wie ReplicaSets, Services, Deployments usw. verwendet.  Beachten Sie dies in den folgenden Abschnitten. <br><img src="https://habrastorage.org/webt/qg/2w/np/qg2wnppfqeu9ksyev67haaiz19m.png"><br><br><h3>  Virtuelle Cluster </h3><br>  In vSphere haben wir physische ESXi-Hosts, die logisch in Clustern gruppiert sind.  Diese Cluster k√∂nnen in andere virtuelle Cluster unterteilt werden, die als "Ressourcenpools" bezeichnet werden.  Diese ‚ÄûPools‚Äú werden haupts√§chlich zur Begrenzung von Ressourcen verwendet.  Bei Kubernetes haben wir etwas sehr √Ñhnliches.  Wir nennen sie "Namespaces". Sie k√∂nnen auch verwendet werden, um Ressourcenlimits bereitzustellen, die im n√§chsten Abschnitt erl√§utert werden.  In den meisten F√§llen werden ‚ÄûNamespaces‚Äú jedoch als mandantenf√§higes Tool f√ºr Anwendungen (oder Benutzer, wenn Sie g√§ngige K8-Cluster verwenden) verwendet.  Dies ist auch eine der Optionen, mit denen Sie die Netzwerksegmentierung mit NSX-T durchf√ºhren k√∂nnen.  Ber√ºcksichtigen Sie dies in den folgenden Ver√∂ffentlichungen. <br><img src="https://habrastorage.org/webt/n6/ve/kr/n6vekro9uz1bx9i_0kqgxquyduw.png"><br><br><h3>  Ressourcenmanagement </h3><br>  Wie bereits im vorherigen Abschnitt erw√§hnt, werden Namespaces in Kubernetes h√§ufig als Mittel zur Segmentierung verwendet.  Eine andere Verwendung von Namespaces ist die Ressourcenzuweisung.  Diese Option wird als "Ressourcenkontingente" bezeichnet.  Wie aus den vorherigen Abschnitten hervorgeht, erfolgt die Definition in den Konfigurations-YAML-Dateien, in denen der gew√ºnschte Status deklariert ist.  In vSphere bestimmen wir dies, wie im folgenden Screenshot zu sehen, anhand der Einstellungen f√ºr Ressourcenpools. <br><img src="https://habrastorage.org/webt/jq/oy/nl/jqoynlerkguited5ozdgsndtj4w.png"><br><br><h3>  Identifizierung der Arbeitslast </h3><br>  Dies ist ziemlich einfach und f√ºr vSphere und Kubernetes fast gleich.  Im ersten Fall verwenden wir die Konzepte von Tags, um √§hnliche Workloads zu definieren (oder zu gruppieren), und im zweiten Fall verwenden wir den Begriff ‚ÄûLabels‚Äú.  Bei Kubernetes ist die Identifizierung der Arbeitslast obligatorisch. <br><img src="https://habrastorage.org/webt/j_/2s/go/j_2sgoekii7mwswdmhspterznoq.png"><br><br><h3>  Reservierung </h3><br>  Nun zum richtigen Spa√ü.  Wenn Sie wie ich ein gro√üer Fan von vSphere FT waren oder sind, werden Sie diese Funktion in Kubernetes trotz einiger Unterschiede zwischen den beiden Technologien lieben.  In vSphere handelt es sich um eine virtuelle Maschine mit einer laufenden Schatteninstanz, die auf einem anderen Host ausgef√ºhrt wird.  Wir zeichnen Anweisungen auf der virtuellen Hauptmaschine auf und spielen sie auf der virtuellen Schattenmaschine wieder.  Wenn die Hauptmaschine nicht mehr funktioniert, wird die virtuelle Schattenmaschine sofort eingeschaltet.  Anschlie√üend versucht vSphere, einen anderen ESXi-Host zu finden, um eine neue Schatteninstanz der virtuellen Maschine zu erstellen und die gleiche Redundanz beizubehalten.  Bei Kubernetes haben wir etwas sehr √Ñhnliches.  ReplicaSets ist der Betrag, den Sie angeben, um mehrere Instanzen von Pods auszuf√ºhren.  Wenn ein Pod ausf√§llt, stehen andere Instanzen zur Verf√ºgung, um den Datenverkehr zu bedienen.  Gleichzeitig versucht K8s, auf jedem verf√ºgbaren Knoten einen neuen Pod zu starten, um den gew√ºnschten Konfigurationsstatus beizubehalten.  Der Hauptunterschied besteht, wie Sie vielleicht bereits bemerkt haben, darin, dass Pods bei K8 immer funktionieren und den Verkehr bedienen.  Sie sind keine Schatten-Workloads. <br><img src="https://habrastorage.org/webt/29/u-/sd/29u-sdyxbg1n0qdzwpkwjmcyuxe.png"><br><br><h3>  Lastausgleich </h3><br>  Obwohl dies m√∂glicherweise keine in vSphere integrierte Funktion ist, ist es sehr, sehr h√§ufig erforderlich, Load Balancer auf der Plattform auszuf√ºhren.  In der vSphere-Welt gibt es virtuelle oder physische Load Balancer zum Verteilen des Netzwerkverkehrs auf mehrere virtuelle Maschinen.  Es kann viele verschiedene Konfigurationsmodi geben, aber nehmen wir an, wir meinen einarmige Konfiguration.  In diesem Fall gleichen Sie die Last des Ost-West-Verkehrs auf Ihren virtuellen Maschinen aus. <br><br>  Ebenso hat Kubernetes das Konzept der "Dienste".  Der Dienst in K8s kann auch in verschiedenen Konfigurationsmodi verwendet werden.  W√§hlen wir die ClusterIP-Konfiguration, um sie mit dem One-Armed Load Balancer zu vergleichen.  In diesem Fall verf√ºgt der Dienst in K8 √ºber eine virtuelle IP-Adresse (VIP), die immer statisch ist und sich nicht √§ndert.  Dieser VIP verteilt den Datenverkehr auf mehrere Pods.  Dies ist besonders wichtig in der Kubernetes-Welt, in der Pods von Natur aus verg√§nglich sind und Sie die IP-Adresse des Pods verlieren, sobald dieser stirbt oder gel√∂scht wird.  Daher sollten Sie immer einen statischen VIP angeben. <br><br>  Wie bereits erw√§hnt, verf√ºgt Service √ºber viele andere Konfigurationen, z. B. "NodePort", bei denen Sie einen Port auf Knotenebene zuweisen und anschlie√üend die √úbersetzung von Portadressen f√ºr Pods durchf√ºhren.  Es gibt auch einen ‚ÄûLoadBalancer‚Äú, in dem Sie eine Load Balancer-Instanz von einem Drittanbieter oder Cloud-Anbieter ausf√ºhren. <br><img src="https://habrastorage.org/webt/s9/4g/my/s94gmy5frfcjkyxeywlp3gcwtkm.png"><br><br>  Kuberentes verf√ºgt √ºber einen weiteren sehr wichtigen Lastausgleichsmechanismus, den ‚ÄûIngress Controller‚Äú.  Sie k√∂nnen es als Inline-Load-Balancer f√ºr Anwendungen betrachten.  Die Hauptidee ist, dass der Ingress Controller (in Form eines Pods) mit einer von au√üen sichtbaren IP-Adresse gestartet wird.  Diese IP-Adresse enth√§lt m√∂glicherweise Platzhalter-DNS-Eintr√§ge.  Wenn der Datenverkehr √ºber eine externe IP-Adresse beim Ingress Controller eintrifft, √ºberpr√ºft er die Header und ermittelt anhand der zuvor festgelegten Regeln, zu welchem ‚Äã‚ÄãPod dieser Name geh√∂rt.  Beispiel: sphinx-v1.esxcloud.net wird an den Dienst sphinx-svc-1 und sphinx-v2.esxcloud.net an den Dienst sphinx-svc2 usw. weitergeleitet. <br><img src="https://habrastorage.org/webt/fk/jr/t_/fkjrt_3ho51djc-euoshgcjccas.png"><br><br><h3>  Speicher und Netzwerk </h3><br>  Speicher und Vernetzung sind sehr, sehr breite Themen, wenn es um Kubernetes geht.  Es ist fast unm√∂glich, in einem Einf√ºhrungsbeitrag kurz auf diese beiden Themen einzugehen, aber ich werde bald ausf√ºhrlich auf die verschiedenen Konzepte und Optionen f√ºr jedes dieser Themen eingehen.  Schauen wir uns in der Zwischenzeit kurz an, wie der Netzwerkstapel in Kubernetes funktioniert, wie wir ihn im n√§chsten Abschnitt ben√∂tigen werden. <br><br>  Kubernetes verf√ºgt √ºber verschiedene Netzwerk-Plugins, mit denen Sie das Netzwerk Ihrer Knoten und Pods konfigurieren k√∂nnen.  Ein g√§ngiges Plugin ist "kubenet", das derzeit in Mega-Clouds wie GCP und AWS verwendet wird.  Hier werde ich kurz auf die Implementierung von GCP eingehen und dann ein praktisches Beispiel f√ºr die Implementierung in GKE zeigen. <br><img src="https://habrastorage.org/webt/vc/vh/n6/vcvhn6ll9s46qdbwvurxheaykg8.png"><br><br>  Auf den ersten Blick mag dies zu kompliziert erscheinen, aber ich hoffe, Sie k√∂nnen dies alles am Ende dieses Beitrags verstehen.  Erstens sehen wir, dass wir zwei Kubernetes-Knoten haben: Knoten 1 und Knoten (m).  Jeder Knoten verf√ºgt wie jeder Linux-Computer √ºber eine eth0-Schnittstelle.  Diese Schnittstelle hat eine IP-Adresse f√ºr die Au√üenwelt, in unserem Fall im Subnetz 10.140.0.0/24.  Das Upstream L3-Ger√§t fungiert als Standard-Gateway f√ºr die Weiterleitung unseres Datenverkehrs.  Es kann sich um einen L3-Switch in Ihrem Rechenzentrum oder einen VPC-Router in der Cloud wie GCP handeln, wie wir sp√§ter sehen werden.  Geht alles gut? <br><br>  Weiter sehen wir, dass wir die Bridge-Schnittstelle cbr0 innerhalb des Knotens haben.  Diese Schnittstelle ist das Standard-Gateway f√ºr das IP-Subnetz 10.40.1.0/24 im Fall von Knoten 1. Dieses Subnetz wird von Kubernetes jedem Knoten zugewiesen.  Knoten erhalten normalerweise ein / 24-Subnetz, aber Sie k√∂nnen dies mit NSX-T √§ndern (wir werden dies in den folgenden Beitr√§gen behandeln).  Im Moment ist dieses Subnetz dasjenige, von dem aus wir IP-Adressen f√ºr Pods vergeben werden.  Auf diese Weise erh√§lt jeder Pod in Knoten 1 eine IP-Adresse von diesem Subnetz.  In unserem Fall hat Pod 1 eine IP-Adresse von 10.40.1.10.  Sie stellen jedoch fest, dass sich in diesem Pod zwei verschachtelte Container befinden.  Wir haben bereits gesagt, dass innerhalb eines Pods ein oder mehrere Container gestartet werden k√∂nnen, die hinsichtlich ihrer Funktionalit√§t eng miteinander verbunden sind.  Das sehen wir in der Abbildung.  Container 1 √ºberwacht Port 80 und Container 2 Port 90. Beide Container haben dieselbe IP-Adresse 10.40.1.10, besitzen jedoch keinen Netzwerk-Namespace.  OK, wem geh√∂rt dann dieser Netzwerkstapel?  Tats√§chlich gibt es einen speziellen Container namens "Pause Container".   ,   IP-  IP- Pod'     .  , Pause Container    ,   IP- 10.40.1.10, , ,      1   80,       2   90. <br><br>    ,      ?     Linux IP Forwarding     cbr0  eth0.  ,    ,  L3   ,      ?             .     -    L3 .    10.40.1.0/24     IP- Node 1 (10.140.0.11)     10.40.2.0/24 next hope ‚Äî Node (m)  IP- 10.140.0.12. <br><br>   ,        .              .    - ,   CNI (Container Network Interface)  Kuberentes,    . NSX-T ‚Äî            ,   . <br><br> ,     kubenet,   CNI.  kubenet ‚Äî  ,   Google Container Engine (GKE),  ,    ,  ,          .  ,            GCP.     . <br><br><h3>  Was weiter? </h3><br>     Kuberentes.        ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">   </a> . <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der zweite Teil.</a> <br><br>     .    . <br>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de436028/">https://habr.com/ru/post/de436028/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de436016/index.html">Asterisk Voice Recognition IVR - schnell, einfach, kostenlos</a></li>
<li><a href="../de436020/index.html">Magento 2: Importieren von Produkten aus externen Quellen</a></li>
<li><a href="../de436022/index.html">Wie wir Librem 5 DevKit vollst√§ndig in freier Software entwickelt haben</a></li>
<li><a href="../de436024/index.html">Wie man nicht in Java wegwirft</a></li>
<li><a href="../de436026/index.html">Info Desk: ‚ÄûInternet Archive‚Äú - Geschichte, Mission und Nebenprojekte</a></li>
<li><a href="../de436032/index.html">React Tutorial Teil 9: Komponenteneigenschaften</a></li>
<li><a href="../de436036/index.html">K√∂nnen Forscher der k√ºnstlichen Intelligenz ihm einen Test ihrer Arbeit anvertrauen?</a></li>
<li><a href="../de436038/index.html">Der Klang der Stille: Wie viele verr√ºckte Ger√§te sind erforderlich, um eine Umgebung zu erreichen, die f√ºr den Schlaf optimal ist?</a></li>
<li><a href="../de436040/index.html">Grafikoptimierung. Interessanter konkaver Rumpf</a></li>
<li><a href="../de436042/index.html">Panel mit zus√§tzlichen Tools f√ºr den Entwickler von InterSystems IRIS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
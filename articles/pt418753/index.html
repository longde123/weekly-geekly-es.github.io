<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöå ü§† üö¨ vSAN na nuvem VMware üôáüèæ üëêüèº üôÖüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As tarefas de armazenamento e acesso a dados s√£o um ponto problem√°tico para qualquer sistema de informa√ß√£o. Mesmo um sistema de armazenamento bem proj...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>vSAN na nuvem VMware</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/418753/"><img src="https://habrastorage.org/webt/pl/tj/to/pltjtoutsishswrt2dgxaktv5ka.png"><br><br>  As tarefas de armazenamento e acesso a dados s√£o um ponto problem√°tico para qualquer sistema de informa√ß√£o.  Mesmo um sistema de armazenamento bem projetado (doravante denominado SHD) durante a opera√ß√£o revela problemas associados a desempenho reduzido.  Aten√ß√£o especial deve ser dada a um conjunto de problemas de dimensionamento quando a quantidade de recursos envolvidos se aproximar dos limites estabelecidos pelos desenvolvedores de armazenamento. <br><br>  A raz√£o fundamental para a ocorr√™ncia desses problemas √© a arquitetura tradicional baseada em forte liga√ß√£o √†s caracter√≠sticas de hardware dos dispositivos de armazenamento usados.  A maioria dos clientes ainda escolhe o m√©todo de armazenamento e acesso a dados, levando em considera√ß√£o as caracter√≠sticas das interfaces f√≠sicas (SAS / SATA / SCSI), e n√£o as reais necessidades dos aplicativos utilizados. <br><a name="habracut"></a><br>  H√° doze anos, essa foi uma decis√£o l√≥gica.  Os administradores de sistema selecionaram cuidadosamente os dispositivos de armazenamento de informa√ß√µes com as especifica√ß√µes necess√°rias, por exemplo SATA / SAS, e contaram com a obten√ß√£o de um n√≠vel de desempenho com base nos recursos de hardware dos controladores de disco.  A luta foi pelo volume de caches do controlador RAID e por op√ß√µes que impedem a perda de dados.  Agora, essa abordagem para resolver o problema n√£o √© ideal. <br><br>  No ambiente atual, ao escolher sistemas de armazenamento, faz sentido iniciar n√£o a partir de interfaces f√≠sicas, mas a partir do desempenho expresso em IOPS (o n√∫mero de opera√ß√µes de E / S por segundo).  O uso da virtualiza√ß√£o permite usar com flexibilidade os recursos de hardware existentes e garantir o n√≠vel de desempenho necess√°rio.  De nossa parte, estamos prontos para fornecer recursos com as caracter√≠sticas realmente necess√°rias para a aplica√ß√£o. <br><br><h2>  Virtualiza√ß√£o de armazenamento </h2><br>  Com o desenvolvimento de sistemas de virtualiza√ß√£o, foi necess√°rio encontrar uma solu√ß√£o inovadora para armazenar e acessar dados, garantindo a toler√¢ncia a falhas.  Este foi o ponto de partida para a cria√ß√£o de SDS (armazenamento definido por software).  Para atender √†s necessidades de neg√≥cios, esses reposit√≥rios foram projetados com a separa√ß√£o de software e hardware. <br><br>  A arquitetura do SDS √© fundamentalmente diferente da tradicional.  A l√≥gica de armazenamento ficou abstra√≠da no n√≠vel do software.  A organiza√ß√£o do armazenamento tornou-se mais f√°cil devido √† unifica√ß√£o e virtualiza√ß√£o de cada um dos componentes desse sistema. <br><br>  Qual √© o principal fator que dificulta a implementa√ß√£o do SDS em todos os lugares?  Esse fator geralmente √© uma avalia√ß√£o incorreta das necessidades dos aplicativos utilizados e uma avalia√ß√£o de risco incorreta.  Para uma empresa, a escolha da solu√ß√£o depende do custo de implementa√ß√£o, com base nos recursos atuais consumidos.  Poucas pessoas pensam - o que acontecer√° quando a quantidade de informa√ß√µes e o desempenho necess√°rio excederem os recursos da arquitetura selecionada.  Pensando na base do princ√≠pio metodol√≥gico ‚Äún√£o se deve multiplicar a exist√™ncia sem necessidade‚Äù, mais conhecida como ‚Äúl√¢mina de Occam‚Äù, determina a escolha em favor das solu√ß√µes tradicionais. <br><br>  Poucos entendem que a necessidade de escalabilidade e confiabilidade do armazenamento de dados √© mais importante do que parece √† primeira vista.  A informa√ß√£o √© um recurso e, portanto, o risco de sua perda deve ser segurado.  O que acontecer√° quando um sistema de armazenamento tradicional for desativado?  Voc√™ precisar√° usar a garantia ou comprar novos equipamentos.  E se o sistema de armazenamento for descontinuado ou tiver terminado o "tempo de vida" (o chamado EOL - Fim da Vida)?  Pode ser um dia sombrio para qualquer organiza√ß√£o que n√£o pode continuar usando seus pr√≥prios servi√ßos familiares. <br><br>  N√£o h√° sistemas que n√£o tenham um √∫nico ponto de falha.  Mas existem sistemas que podem sobreviver facilmente √† falha de um ou mais componentes.  Os sistemas de armazenamento virtual e tradicional foram criados levando em considera√ß√£o o fato de que mais cedo ou mais tarde ocorrer√° uma falha.  Esse √© apenas o "limite de for√ßa" dos sistemas de armazenamento tradicionais estabelecidos no hardware, mas nos sistemas de armazenamento virtual √© determinado na camada de software. <br><br><h2>  Integra√ß√£o </h2><br>  Mudan√ßas dram√°ticas na infraestrutura de TI s√£o sempre um fen√¥meno indesej√°vel, repleto de tempo de inatividade e perda de fundos.  Somente a implementa√ß√£o tranquila de novas solu√ß√µes permite evitar consequ√™ncias negativas e melhorar o trabalho dos servi√ßos.  Por isso, a Selectel projetou e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lan√ßou a nuvem com base na VMware</a> , l√≠der reconhecida no mercado de virtualiza√ß√£o.  O servi√ßo criado por n√≥s permitir√° que cada empresa resolva toda a gama de tarefas de infraestrutura, incluindo armazenamento de dados. <br><br>  Vamos dizer exatamente como decidimos sobre a escolha de um sistema de armazenamento, bem como quais vantagens essa escolha nos deu.  Obviamente, os sistemas de armazenamento tradicionais e o SDS foram considerados.  Para entender claramente todos os aspectos de opera√ß√£o e riscos, oferecemos uma vis√£o mais profunda do t√≥pico. <br><br>  Na fase de design, os seguintes requisitos foram impostos aos sistemas de armazenamento: <br><br><ul><li>  <strong>toler√¢ncia a falhas;</strong> </li><li>  <strong>performance</strong> </li><li>  <strong>escala</strong> </li><li>  <strong>a capacidade de garantir velocidade;</strong> </li><li>  <strong>opera√ß√£o correta no ecossistema VMware.</strong> </li></ul><br>  O uso de solu√ß√µes de hardware tradicionais n√£o poderia fornecer o n√≠vel de escalabilidade necess√°rio, pois √© imposs√≠vel aumentar constantemente o volume de armazenamento devido a limita√ß√µes de arquitetura.  A reserva no n√≠vel de um data center inteiro tamb√©m foi de grande dificuldade.  Por isso, voltamos nossa aten√ß√£o para o SDS. <br><br>  Existem v√°rias solu√ß√µes de software no mercado de SDS que nos serviriam para criar uma nuvem baseada no VMware vSphere.  Entre essas solu√ß√µes, podemos destacar: <br><br><ul><li>  <strong>Dell EMC ScaleIO;</strong> </li><li>  <strong>SAN virtual hiperconvergente do Datacore;</strong> </li><li>  <strong>HPE StoreVirtual.</strong> </li></ul><br>  Essas solu√ß√µes s√£o adequadas para uso com o VMware vSphere, no entanto, elas n√£o se integram ao hypervisor e s√£o executadas separadamente.  Portanto, a escolha foi feita em favor do VMware vSAN.  Vamos considerar em detalhes como √© a arquitetura virtual dessa solu√ß√£o. <br><br><h3>  Arquitetura </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hb/hu/nr/hbhunruzcic-pa1ggjw_-winfcg.png"></div><br>  <sup><i>Imagem retirada da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o oficial</a></i></sup> <br><br>  Ao contr√°rio dos sistemas de armazenamento tradicionais, todas as informa√ß√µes n√£o s√£o armazenadas em nenhum momento.  Os dados da m√°quina virtual s√£o distribu√≠dos igualmente entre todos os hosts e o dimensionamento √© feito adicionando hosts ou instalando unidades de disco adicionais neles.  Duas op√ß√µes de configura√ß√£o s√£o suportadas: <br><br><ul><li>  <strong>Configura√ß√£o AllFlash</strong> (apenas unidades de estado s√≥lido, tanto para armazenamento de dados quanto para cache); </li><li>  <strong>Configura√ß√£o h√≠brida</strong> (armazenamento magn√©tico e cache de estado s√≥lido). </li></ul><br>  O procedimento para adicionar espa√ßo em disco n√£o requer configura√ß√µes adicionais, por exemplo, criando um LUN (n√∫mero da unidade l√≥gica, n√∫meros de disco l√≥gico) e configurando o acesso a eles.  Assim que o host √© adicionado ao cluster, seu espa√ßo em disco fica dispon√≠vel para todas as m√°quinas virtuais.  Essa abordagem tem v√°rias vantagens significativas: <br><br><ul><li>  <strong>falta de liga√ß√£o ao fabricante do equipamento;</strong> </li><li>  <strong>toler√¢ncia a falhas aumentada;</strong> </li><li>  <strong>garantir a integridade dos dados em caso de falha;</strong> </li><li>  <strong>√∫nico centro de controle do console do vSphere;</strong> </li><li>  <strong>escala horizontal e vertical conveniente.</strong> </li></ul><br>  No entanto, essa arquitetura exige muito da infraestrutura de rede.  Para garantir o m√°ximo rendimento, em nossa nuvem, a rede √© constru√≠da no modelo Spine-Leaf. <br><br><h3>  Rede </h3><br>  O modelo de rede tradicional de tr√™s camadas (n√∫cleo / agrega√ß√£o / acesso) tem v√°rias desvantagens significativas.  Um exemplo marcante s√£o as limita√ß√µes dos protocolos Spanning Tree. <br><br>  O modelo Spine-Leaf usa apenas dois n√≠veis, o que oferece as seguintes vantagens: <br><br><ul><li>  <strong>dist√¢ncia previs√≠vel entre dispositivos;</strong> </li><li>  <strong>o tr√°fego segue a melhor rota;</strong> </li><li>  <strong>facilidade de dimensionamento;</strong> </li><li>  <strong>Exclus√£o de restri√ß√µes do protocolo L2.</strong> </li></ul><br>  Uma caracter√≠stica importante de uma arquitetura desse tipo √© que ela √© otimizada para a passagem de tr√°fego "horizontal".  Os pacotes de dados passam por apenas um salto, o que permite uma estimativa clara dos atrasos. <br><br>  Uma conex√£o f√≠sica √© fornecida usando v√°rios links de 10 GbE por servidor, cuja largura de banda √© combinada usando o protocolo de agrega√ß√£o.  Assim, cada host f√≠sico recebe acesso de alta velocidade a todos os objetos de armazenamento. <br><br>  A troca de dados √© implementada usando um protocolo propriet√°rio criado pela VMware, que permite a opera√ß√£o r√°pida e confi√°vel da rede de armazenamento no transporte Ethernet (de 10 GbE e superior). <br><br>  A transi√ß√£o para o modelo de objeto de armazenamento de dados permitiu um ajuste flex√≠vel do uso do armazenamento, de acordo com os requisitos dos clientes.  Todos os dados s√£o armazenados na forma de objetos que s√£o distribu√≠dos de uma certa maneira entre os hosts do cluster.  Esclarecemos os valores de alguns par√¢metros que podem ser controlados. <br><br><h3>  Toler√¢ncia a falhas </h3><br><ol><li>  <strong>FTT (Falhas em tolerar).</strong>  Indica o n√∫mero de falhas do host que o cluster pode manipular sem interromper a opera√ß√£o regular. </li><li>  <strong>FTM (M√©todo de toler√¢ncia a falhas).</strong>  O m√©todo de garantir toler√¢ncia a falhas no n√≠vel do disco. <br><br>  a.  <strong>Espelhamento</strong> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jb/kv/lw/jbkvlwsmyvua7jrw2f8jj0820am.png"></div><br>  <sup><i>Imagem retirada do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">blog VMware.</a></i></sup> <br><br>  Representa uma duplica√ß√£o completa de um objeto e as r√©plicas sempre est√£o localizadas em diferentes hosts f√≠sicos.  O an√°logo mais pr√≥ximo desse m√©todo √© o RAID-1.  Seu uso permite que o cluster processe rotineiramente at√© tr√™s falhas de qualquer componente (discos, hosts, perda de rede etc.).  Este par√¢metro √© configurado definindo a op√ß√£o FTT. <br><br>  Por padr√£o, essa op√ß√£o tem o valor 1 e 1 r√©plica √© criada para o objeto (apenas 2 inst√¢ncias em hosts diferentes).  √Ä medida que o valor aumenta, o n√∫mero de c√≥pias ser√° N + 1.  Assim, com um valor m√°ximo de FTT = 3, 4 inst√¢ncias do objeto estar√£o em hosts diferentes. <br><br>  Este m√©todo permite atingir o desempenho m√°ximo √†s custas da efici√™ncia do espa√ßo em disco.  Pode ser usado nas configura√ß√µes h√≠brida e AllFlash. <br><br>  b.  <strong>Codifica√ß√£o de apagamento</strong> (an√°logo do RAID 5/6). <br><img src="https://habrastorage.org/webt/72/zq/hh/72zqhhyrlncoqga9qlzg0wdfgco.png"><br><br>  <sup><i>Imagem retirada do blog <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cormachogan.com.</a></i></sup> <br><br>  O trabalho deste m√©todo √© suportado exclusivamente nas configura√ß√µes do AllFlash.  No processo de registro de cada objeto, s√£o calculados os blocos de paridade correspondentes, que permitem recuperar dados de maneira exclusiva em caso de falha.  Essa abordagem economiza significativamente espa√ßo em disco comparado ao espelhamento. <br><br>  Obviamente, a opera√ß√£o desse m√©todo aumenta a sobrecarga, que √© expressa em uma diminui√ß√£o na produtividade.  No entanto, dado o desempenho da configura√ß√£o do AllFlash, essa desvantagem √© nivelada, tornando o uso do Erasure Coding uma op√ß√£o aceit√°vel para a maioria das tarefas. <br><br>  Al√©m disso, o VMware vSAN apresenta o conceito de "dom√≠nios de falha", que s√£o um agrupamento l√≥gico de racks de servidor ou cestas de disco.  Assim que os elementos necess√°rios s√£o agrupados, isso leva √† distribui√ß√£o de dados entre diferentes n√≥s, levando em considera√ß√£o os dom√≠nios de falha.  Isso permite que o cluster sobreviva √† perda de um dom√≠nio inteiro, pois todas as r√©plicas correspondentes dos objetos estar√£o localizadas em outros hosts em um dom√≠nio de falha diferente. <br><br>  O menor dom√≠nio de falha √© um grupo de discos, que √© uma unidade de disco conectada logicamente.  Cada grupo de discos cont√©m dois tipos de m√≠dia - cache e capacidade.  Como uma m√≠dia de cache, o sistema permite usar apenas discos de estado s√≥lido, e os discos magn√©ticos e de estado s√≥lido podem atuar como portadores de capacidade.  A m√≠dia de cache ajuda a acelerar os discos magn√©ticos e a reduzir a lat√™ncia ao acessar dados. </li></ol><br><h2>  Implementa√ß√£o </h2><br>  Vamos falar sobre quais limita√ß√µes existem na arquitetura VMware vSAN e por que s√£o necess√°rias.  Independentemente das plataformas de hardware usadas, a arquitetura fornece as seguintes restri√ß√µes: <br><br><ul><li>  <strong>n√£o mais que 5 grupos de discos por host;</strong> </li><li>  <strong>n√£o mais que 7 portadores de capacidade em um grupo de discos;</strong> </li><li>  <strong>n√£o mais que 1 portadora de cache em um grupo de discos;</strong> </li><li>  <strong>n√£o mais que 35 transportadoras de capacidade por host;</strong> </li><li>  <strong>n√£o mais que 9000 componentes por host (incluindo componentes testemunha);</strong> </li><li>  <strong>n√£o mais que 64 hosts em um cluster;</strong> </li><li>  <strong>n√£o mais que 1 vSAN-datastore por cluster.</strong> </li></ul><br>  Por que isso √© necess√°rio?  At√© que os limites especificados sejam excedidos, o sistema operar√° com a capacidade declarada, mantendo um equil√≠brio entre desempenho e capacidade de armazenamento.  Isso permite garantir a opera√ß√£o correta de todo o sistema de armazenamento virtual como um todo. <br><br>  Al√©m dessas limita√ß√µes, um recurso importante deve ser lembrado.  N√£o √© recomend√°vel preencher mais de 70% do volume total de armazenamento.  O fato √© que, quando 80% √© alcan√ßado, o mecanismo de reequil√≠brio √© iniciado automaticamente e o sistema de armazenamento come√ßa a redistribuir dados em todos os hosts do cluster.  O procedimento consome bastante recursos e pode afetar seriamente o desempenho do subsistema de disco. <br><br>  Para atender √†s necessidades de uma ampla variedade de clientes, implementamos tr√™s pools de armazenamento para facilitar o uso em v√°rios cen√°rios.  Vamos olhar para cada um deles em ordem. <br><br><h3>  Conjunto de discos r√°pido </h3><br>  A prioridade para a cria√ß√£o desse pool era obter armazenamento que proporcionasse desempenho m√°ximo para hospedar sistemas altamente carregados.  Os servidores desse pool usam um par de Intel P4600 como cache e 10 Intel P3520 para armazenamento de dados.  O cache neste pool √© usado para que os dados sejam lidos diretamente da m√≠dia e as opera√ß√µes de grava√ß√£o ocorram no cache. <br><br>  Para aumentar a capacidade √∫til e garantir a toler√¢ncia a falhas, √© usado um modelo de armazenamento de dados chamado Erasure Coding.  Esse modelo √© semelhante a uma matriz RAID 5/6 regular, mas no n√≠vel de armazenamento de objetos.  Para eliminar a probabilidade de corrup√ß√£o de dados, o vSAN usa um mecanismo de c√°lculo de soma de verifica√ß√£o para cada bloco de dados 4K. <br><br>  A valida√ß√£o √© realizada em segundo plano durante as opera√ß√µes de leitura / grava√ß√£o, bem como para dados "frios", cujo acesso n√£o foi solicitado durante o ano.  Quando a incompatibilidade de soma de verifica√ß√£o √© detectada e, portanto, a corrup√ß√£o de dados √© detectada, o vSAN recupera automaticamente os arquivos sobrescrevendo. <br><br><h3>  Conjunto de unidades h√≠bridas </h3><br>  No caso desse pool, sua principal tarefa √© fornecer uma grande quantidade de dados, garantindo um bom n√≠vel de toler√¢ncia a falhas.  Para muitas tarefas, a velocidade do acesso aos dados n√£o √© uma prioridade, o volume e o custo do armazenamento s√£o muito mais importantes.  O uso de unidades de estado s√≥lido como esse armazenamento ter√° um custo excessivamente alto. <br><br>  Esse fator foi o motivo da cria√ß√£o do pool, que √© um h√≠brido de armazenamento em cache de unidades de estado s√≥lido (como em outros pools √© o Intel P4600) e discos r√≠gidos de n√≠vel empresarial desenvolvidos pela HGST.  Um fluxo de trabalho h√≠brido acelera o acesso aos dados solicitados com freq√º√™ncia armazenando em cache as opera√ß√µes de leitura e grava√ß√£o. <br><br>  No n√≠vel l√≥gico, os dados s√£o espelhados para eliminar a perda no caso de uma falha de hardware.  Cada objeto √© dividido em componentes id√™nticos e o sistema os distribui para diferentes hosts. <br><br><h3>  Piscina com recupera√ß√£o de desastres </h3><br><img src="https://habrastorage.org/webt/hz/ne/xi/hznexild-sq7oxyvy6m9yvr-xm4.png"><br><br>  A principal tarefa do pool √© atingir o n√≠vel m√°ximo de toler√¢ncia a falhas e desempenho.  O uso da tecnologia <strong>Stretched vSAN</strong> nos permitiu <strong>distribuir</strong> o armazenamento entre os data centers Tsvetochnaya-2 em S√£o Petersburgo e Dubrovka-3 na regi√£o de Leningrado.  Cada servidor neste pool est√° equipado com um par de unidades Intel P4600 de alta capacidade e alta velocidade para opera√ß√£o em cache e 6 unidades Intel P3520 para armazenamento de dados.  No n√≠vel l√≥gico, esses s√£o 2 grupos de discos por host. <br><br>  A configura√ß√£o do AllFlash n√£o tem uma desvantagem s√©ria - uma queda acentuada no IOPS e um aumento na fila de solicita√ß√µes de disco com um volume aumentado de acesso aleat√≥rio aos dados.  Assim como em um pool com discos r√°pidos, as opera√ß√µes de grava√ß√£o passam pelo cache e a leitura √© feita diretamente. <br><br>  Agora, sobre a principal diferen√ßa do resto das piscinas.  Os dados de cada m√°quina virtual s√£o espelhados dentro de um data center e, ao mesmo tempo, replicados de forma s√≠ncrona para outro data center pertencente a n√≥s.  Assim, mesmo um acidente grave, como uma interrup√ß√£o completa da conectividade entre data centers, n√£o ser√° um problema.  Mesmo uma perda completa do data center n√£o afetar√° os dados. <br><br>  Um acidente com uma falha completa do site - a situa√ß√£o √© bastante rara, mas o vSAN pode sobreviver com honra sem perder dados.  Os convidados do nosso evento <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SelectelTechDay 2018</a> puderam ver por si mesmos como o cluster vSAN estendido sofreu uma falha completa no site.  As m√°quinas virtuais ficaram dispon√≠veis apenas um minuto depois que todos os servidores em um dos sites foram desligados pela energia.  Todos os mecanismos funcionaram exatamente como planejado, mas os dados permaneceram intocados. <br><br>  O abandono da arquitetura de armazenamento familiar acarreta muitas mudan√ßas.  Uma dessas mudan√ßas foi o surgimento de novas "entidades" virtuais, que incluem o dispositivo testemunha.  O significado desta solu√ß√£o √© rastrear o processo de grava√ß√£o de r√©plicas de dados e determinar qual √© relevante.  Ao mesmo tempo, os dados em si n√£o s√£o armazenados nos componentes testemunha, apenas metadados sobre o processo de grava√ß√£o. <br><br>  Esse mecanismo entra em vigor no caso de um acidente, quando ocorre uma falha durante o processo de replica√ß√£o, o que resulta em r√©plicas fora de sincronia. <br><br>  Para determinar qual delas cont√©m informa√ß√µes relevantes, √© usado um mecanismo de determina√ß√£o de quorum.  Cada componente tem um "direito de voto" e recebe um certo n√∫mero de votos (1 ou mais).  O mesmo ‚Äúdireito de voto‚Äù possui componentes de testemunhas que desempenham o papel de √°rbitros em caso de situa√ß√£o controversa. <br><br>  Um quorum √© alcan√ßado apenas quando uma r√©plica completa est√° dispon√≠vel para um objeto e o n√∫mero de "votos" atuais √© superior a 50%. <br><br><h2>  Conclus√£o </h2><br>  A escolha do VMware vSAN como sistema de armazenamento tornou-se uma decis√£o importante para n√≥s.  Essa op√ß√£o passou no teste de estresse e no teste de toler√¢ncia a falhas antes de ser inclu√≠da em nosso projeto de nuvem baseado em VMware. <br><br>  De acordo com os resultados do teste, ficou claro que a funcionalidade declarada funciona conforme o esperado e atende a todos os requisitos de nossa infraestrutura de nuvem. <br><br>  Tem algo a dizer com base em sua pr√≥pria experi√™ncia com o vSAN?  Bem-vindo aos coment√°rios. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt418753/">https://habr.com/ru/post/pt418753/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt418739/index.html">Centro de tecnologia aditiva: Impressoras 3D industriais Sistemas 3D, Stratasys, SLM, EOS</a></li>
<li><a href="../pt418741/index.html">Adicione criptografia e envie para SIP regular</a></li>
<li><a href="../pt418743/index.html">Hist√≥ria do Primeiro Lugar no ML Boot Camp VI</a></li>
<li><a href="../pt418747/index.html">Solu√ß√£o de problemas: como efetivamente resolver problemas em equipe?</a></li>
<li><a href="../pt418751/index.html">Dex espi√£o chin√™s insolente</a></li>
<li><a href="../pt418755/index.html">Como o com√©rcio eletr√¥nico sobrevive √†s promo√ß√µes em larga escala. Preparando-se para picos de carga na web [Parte 1]</a></li>
<li><a href="../pt418757/index.html">Prazos de dilui√ß√£o (criptomoedas, forex, trocas)</a></li>
<li><a href="../pt418759/index.html">Quanto custa para um aluno emitir um chip?</a></li>
<li><a href="../pt418761/index.html">O livro ‚ÄúPure Python. As sutilezas da programa√ß√£o para profissionais ¬ª</a></li>
<li><a href="../pt418763/index.html">M√©dio / s√™nior: como sair do p√¢ntano?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
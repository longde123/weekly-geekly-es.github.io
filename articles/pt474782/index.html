<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìï üë®üèæ‚Äç‚úàÔ∏è üë©‚Äç‚öñÔ∏è Vis√£o geral da tecnologia de s√≠ntese de fala üå∂Ô∏è üë®üèª‚Äç‚öïÔ∏è ü§¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal! Meu nome √© Vlad e trabalho como cientista de dados na equipe de tecnologias de fala Tinkoff, usada em nosso assistente de voz Oleg. 


 N...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vis√£o geral da tecnologia de s√≠ntese de fala</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/tinkoff/blog/474782/"><p>  Ol√° pessoal!  Meu nome √© Vlad e trabalho como cientista de dados na equipe de tecnologias de fala Tinkoff, usada em nosso assistente de voz Oleg. </p><br><p>  Neste artigo, gostaria de dar uma breve vis√£o geral das tecnologias de s√≠ntese de fala usadas na ind√∫stria e compartilhar a experi√™ncia de nossa equipe na cria√ß√£o de nosso pr√≥prio mecanismo de s√≠ntese. </p><br><p><img src="https://habrastorage.org/webt/fc/3j/vs/fc3jvsr59z_90ojbvjushekmmm4.png" alt="imagem"></p><a name="habracut"></a><br><h3 id="sintez-rechi">  S√≠ntese da fala </h3><br><p>  A s√≠ntese de fala √© a cria√ß√£o de som com base em texto.  Hoje, esse problema √© resolvido por duas abordagens: </p><br><ul><li>  Sele√ß√£o de unidade [1] ou uma abordagem concatenativa.  √â baseado na colagem de fragmentos de √°udio gravado.  Desde o final dos anos 90, h√° muito tempo √© considerado o padr√£o de fato para o desenvolvimento de mecanismos de s√≠ntese de fala.  Por exemplo, uma voz tocada pelo m√©todo de sele√ß√£o de unidade pode ser encontrada em Siri [2]. </li><li>  S√≠ntese param√©trica da fala [3], cuja ess√™ncia √© construir um modelo probabil√≠stico que preveja as propriedades ac√∫sticas de um sinal de √°udio para um determinado texto. </li></ul><br><p>  O discurso dos modelos de sele√ß√£o de unidades √© de alta qualidade, baixa variabilidade e requer uma grande quantidade de dados para treinamento.  Ao mesmo tempo, para o treinamento de modelos param√©tricos, √© necess√°ria uma quantidade muito menor de dados, eles geram entona√ß√µes mais diversas, mas at√© recentemente sofreram com uma qualidade de som geral bastante ruim em compara√ß√£o com a abordagem de sele√ß√£o de unidades. </p><br><p>  No entanto, com o desenvolvimento de tecnologias de aprendizado profundo, os modelos de s√≠ntese param√©trica alcan√ßaram um crescimento significativo em todas as m√©tricas de qualidade e s√£o capazes de criar uma fala praticamente indistingu√≠vel da fala humana. </p><br><h3 id="metriki-kachestva">  M√©tricas de qualidade </h3><br><p> Antes de falar sobre quais modelos de s√≠ntese de fala s√£o melhores, voc√™ precisa determinar as m√©tricas de qualidade pelas quais os algoritmos ser√£o comparados. </p><br><p>  Como o mesmo texto pode ser lido de v√°rias formas, a priori n√£o existe a maneira correta de pronunciar uma frase espec√≠fica.  Portanto, frequentemente as m√©tricas para a qualidade da s√≠ntese da fala s√£o subjetivas e dependem da percep√ß√£o do ouvinte. </p><br><p>  A m√©trica padr√£o √© o MOS (pontua√ß√£o m√©dia de opini√£o), uma avalia√ß√£o m√©dia da naturalidade da fala, fornecida pelos avaliadores para √°udio sintetizado em uma escala de 1 a 5. Um significa som completamente implaus√≠vel e cinco significa fala que √© indistingu√≠vel da humana.  Os registros de pessoas reais geralmente recebem cerca de 4,5, e um valor maior que 4 √© considerado bastante alto. </p><br><h3 id="kak-rabotaet-sintez-rechi">  Como funciona a s√≠ntese da fala </h3><br><p>  O primeiro passo para construir qualquer sistema de s√≠ntese de fala √© coletar dados para treinamento.  Geralmente, s√£o grava√ß√µes de √°udio de alta qualidade nas quais o locutor l√™ frases especialmente selecionadas.  O tamanho aproximado do conjunto de dados necess√°rio para os modelos de sele√ß√£o de unidades de treinamento √© de 10 a 20 horas de fala pura [2], enquanto que para os m√©todos param√©tricos da rede neural, o limite superior √© de aproximadamente 25 horas [4, 5]. </p><br><p>  Discutimos as duas tecnologias de s√≠ntese. </p><br><h3 id="unit-selection">  Sele√ß√£o de unidade </h3><br><p><img src="https://habrastorage.org/webt/9-/r7/dm/9-r7dmw2tieg5ypyjbt-lddxddc.png" alt="imagem"></p><br><p>  Normalmente, a fala gravada do falante n√£o pode cobrir todos os casos poss√≠veis nos quais a s√≠ntese ser√° usada.  Portanto, a ess√™ncia do m√©todo √© dividir toda a base de √°udio em pequenos fragmentos chamados unidades, que s√£o ent√£o coladas usando um p√≥s-processamento m√≠nimo.  Normalmente, as unidades s√£o unidades m√≠nimas de linguagem ac√∫stica, como meio-telefone ou diphons [2]. <br>  Todo o processo de gera√ß√£o consiste em duas etapas: o front end da PNL, respons√°vel por extrair a representa√ß√£o ling√º√≠stica do texto, e o back-end, que calcula a fun√ß√£o de penalidade unit√°ria para os recursos ling√º√≠sticos especificados.  O front end da PNL inclui: </p><br><ol><li>  A tarefa de normalizar o texto √© a tradu√ß√£o de todos os caracteres n√£o alfab√©ticos (n√∫meros, sinais de porcentagem, moedas e assim por diante) em suas representa√ß√µes verbais.  Por exemplo, "5%" deve ser convertido para "cinco por cento". </li><li>  Extrair recursos lingu√≠sticos de um texto normalizado: representa√ß√£o de fonemas, estresse, partes do discurso e assim por diante. </li></ol><br><p>  Normalmente, o front-end da PNL √© implementado usando regras prescritas manualmente para um idioma espec√≠fico, mas recentemente houve um vi√©s crescente em rela√ß√£o ao uso de modelos de aprendizado de m√°quina [7]. </p><br><p>  A penalidade estimada pelo subsistema de back-end √© a soma do custo-alvo, ou a correspond√™ncia da representa√ß√£o ac√∫stica da unidade para um fonema espec√≠fico, e o custo de concatena√ß√£o, ou seja, a adequa√ß√£o da conex√£o de duas unidades vizinhas.  Para avaliar as fun√ß√µes finas, pode-se usar as regras ou o modelo ac√∫stico j√° treinado da s√≠ntese param√©trica [2].  A sele√ß√£o da sequ√™ncia mais √≥tima de unidades do ponto de vista das penalidades definidas acima ocorre usando o algoritmo de Viterbi [1]. </p><br><p>  Valores aproximados dos modelos de sele√ß√£o de unidade MOS para o idioma ingl√™s: 3.7-4.1 [2, 4, 5]. </p><br><p>  Vantagens da abordagem de sele√ß√£o de unidades: </p><br><ul><li>  O som natural. </li><li>  Gera√ß√£o de alta velocidade. </li><li>  Tamanho pequeno dos modelos - isso permite que voc√™ use a s√≠ntese diretamente no seu dispositivo m√≥vel. </li></ul><br><p>  Desvantagens: </p><br><ul><li>  O discurso sintetizado √© mon√≥tono, n√£o cont√©m emo√ß√µes. </li><li>  Artefatos de colagem caracter√≠sticos. </li><li>  Requer uma base de treinamento suficientemente grande de dados de √°udio para cobrir todos os tipos de contextos. </li><li>  Em princ√≠pio, n√£o pode gerar som que n√£o seja encontrado no conjunto de treinamento. </li></ul><br><h3 id="parametricheskiy-sintez-rechi">  S√≠ntese param√©trica da fala </h3><br><p>  A abordagem param√©trica √© baseada na id√©ia de construir um modelo probabil√≠stico que estima a distribui√ß√£o das caracter√≠sticas ac√∫sticas de um determinado texto. <br>  O processo de gera√ß√£o da fala na s√≠ntese param√©trica pode ser dividido em quatro etapas: </p><br><ol><li>  O front end da PNL √© o mesmo est√°gio de pr√©-processamento de dados da abordagem de sele√ß√£o de unidades, cujo resultado √© um grande n√∫mero de recursos lingu√≠sticos sens√≠veis ao contexto. </li><li>  Modelo de dura√ß√£o que prev√™ a dura√ß√£o do fonema. </li><li>  Um modelo ac√∫stico que restaura a distribui√ß√£o de recursos ac√∫sticos sobre os ling√º√≠sticos.  Os recursos ac√∫sticos incluem valores de frequ√™ncia fundamentais, representa√ß√£o espectral do sinal e assim por diante. </li><li>  Um vocoder que traduz recursos ac√∫sticos em uma onda sonora. </li></ol><br><p>  Para dura√ß√£o do treinamento e modelos ac√∫sticos, podem ser utilizados modelos ocultos de Markov [3], redes neurais profundas ou suas variedades recorrentes [6].  Um vocoder tradicional √© um algoritmo baseado no modelo de filtro de origem [3], que assume que a fala √© o resultado da aplica√ß√£o de um filtro de ru√≠do linear ao sinal original. <br>  A qualidade geral da fala dos m√©todos param√©tricos cl√°ssicos √© bastante baixa devido ao grande n√∫mero de suposi√ß√µes independentes sobre a estrutura do processo de gera√ß√£o de som. </p><br><p>  No entanto, com o advento das tecnologias de aprendizado profundo, tornou-se poss√≠vel treinar modelos de ponta a ponta que predizem diretamente sinais ac√∫sticos por letra.  Por exemplo, as redes neurais Tacotron [4] e Tacotron 2 [5] inserem uma sequ√™ncia de letras e retornam o espectrograma de giz usando o algoritmo seq2seq [8].  Assim, os passos 1 a 3 da abordagem cl√°ssica s√£o substitu√≠dos por uma √∫nica rede neural.  O diagrama abaixo mostra a arquitetura da rede Tacotron 2, que obt√©m uma qualidade de som bastante alta. </p><br><p><img src="https://habrastorage.org/webt/tv/8l/pc/tv8lpchvxw75yr3msdbhjaqscwc.jpeg" alt="imagem"></p><br><p>  Outro fator de um aumento significativo na qualidade da fala sintetizada foi o uso de vocoders de rede neural em vez de algoritmos de processamento de sinal digital. </p><br><p>  O primeiro desses vocoder foi a rede neural WaveNet [9], que sequencialmente, passo a passo, previu a amplitude da onda sonora. </p><br><p>  Devido ao uso de um grande n√∫mero de camadas convolucionais com lacunas para capturar mais contexto e pular a conex√£o na arquitetura de rede, foi poss√≠vel obter uma melhoria de cerca de 10% no MOS em compara√ß√£o aos modelos de sele√ß√£o de unidade.  O diagrama abaixo mostra a arquitetura da rede WaveNet. </p><br><p><img src="https://habrastorage.org/webt/lg/ei/df/lgeidfeylr_yu-u-ucmdsxi7xki.png" alt="imagem"></p><br><p>  A principal desvantagem do WaveNet √© a baixa velocidade associada a um circuito de amostragem de sinal serial.  Esse problema pode ser resolvido usando a otimiza√ß√£o de engenharia para uma arquitetura espec√≠fica do ferro ou substituindo o esquema de amostragem por um mais r√°pido. <br>  Ambas as abordagens foram implementadas com sucesso na ind√∫stria.  O primeiro √© no Tinkoff.ru e, como parte da segunda abordagem, o Google introduziu a rede Parallel WaveNet [10] em 2017, cujas realiza√ß√µes s√£o usadas no Google Assistant. </p><br><p>  Valores aproximados de MOS para m√©todos de rede neural: 4.4-4.5 [5, 11], ou seja, a fala sintetizada praticamente n√£o difere da fala humana. </p><br><p>  Vantagens da s√≠ntese param√©trica: </p><br><ul><li>  Som natural e suave ao usar a abordagem de ponta a ponta. </li><li>  Maior variedade na entona√ß√£o. </li><li>  Use menos dados que os modelos de sele√ß√£o de unidade. </li></ul><br><p>  Desvantagens: </p><br><ul><li>  Baixa velocidade em compara√ß√£o com a sele√ß√£o da unidade. </li><li>  Grande complexidade computacional. </li></ul><br><h3 id="kak-rabotaet-sintez-rechi-v-tinkoff">  Como funciona a s√≠ntese de fala Tinkoff </h3><br><p>  Como se segue na revis√£o, os m√©todos de s√≠ntese param√©trica da fala baseados em redes neurais s√£o atualmente significativamente superiores em qualidade √† abordagem de sele√ß√£o de unidades e s√£o muito mais simples de desenvolver.  Portanto, para construir nosso pr√≥prio mecanismo de s√≠ntese, n√≥s os usamos. <br>  Para os modelos de treinamento, foram utilizadas cerca de 25 horas de fala pura de um palestrante profissional.  Os textos de leitura foram especialmente selecionados de forma a abranger a fon√©tica do discurso coloquial.  Al√©m disso, para adicionar mais variedade √† s√≠ntese na entona√ß√£o, solicitamos ao locutor que lesse textos com uma express√£o dependendo do contexto. </p><br><p>  A arquitetura da nossa solu√ß√£o √© conceitualmente parecida com esta: </p><br><ul><li>  Front-end da PNL, que inclui a normaliza√ß√£o de texto de rede neural e um modelo para colocar pausas e tens√µes. </li><li>  Tacotron 2 aceitando letras como entrada. </li><li>  WaveNet autoregressivo, trabalhando em tempo real na CPU. </li></ul><br><p>  Gra√ßas a essa arquitetura, nosso mecanismo gera fala expressiva de alta qualidade em tempo real, n√£o requer a constru√ß√£o de um dicion√°rio de fonemas e possibilita o controle de tens√µes em palavras individuais.  Exemplos de √°udio sintetizado podem ser ouvidos clicando no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">link</a> . </p><br><h3 id="ssylki">  Refer√™ncias: </h3><br><p>  [1] AJ Hunt, AW Black.  Sele√ß√£o de unidades em um sistema de s√≠ntese de fala concatenativa usando um banco de dados de fala grande, ICASSP, 1996. <br>  [2] T. Capes, P. Coles, A. Conkie, L. Golipour, A. Hadjitarkhani, Q. Hu, N. Huddleston, M. Hunt, J. Li, M. Neeracher, K. Prahallad, T. Raitio R. Rasipuram, G. Townsend, B. Williamson, D. Winarsky, Z. Wu, H. Zhang.  Sistema Text-to-Speech de Sele√ß√£o de Unidade Guiada por Aprendizagem Profunda no Dispositivo Siri, Interspeech, 2017. <br>  [3] H. Zen, K. Tokuda, AW Black.  S√≠ntese estat√≠stica param√©trica da fala, Comunica√ß√£o de fala, vol.  51, n.  11, pp.  1039-1064, 2009. <br>  [4] Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, Yonghui Wu, Ron J. Weiss, Navdeep Jaitly, Zongheng Yang, Ying Xiao, Zhifeng Chen, Samy Bengio, Quoc Le, Yannis Agiomyrgiannakis, Rob Clark, Rif A. Saurous .  Tacotron: Em dire√ß√£o √† s√≠ntese de fala de ponta a ponta. <br>  [5] Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, RJ Skerry-Ryan, Rif A. Saurous, Yannis Agiomyrgiannakis, Yonghui Wu.  S√≠ntese natural de TTS condicionando WaveNet em previs√µes de espectrograma de mel. <br>  [6] Heiga Zen, Andrew S√™nior, Mike Schuster.  S√≠ntese estat√≠stica param√©trica da fala usando redes neurais profundas. <br>  [7] Hao Zhang, Richard Sproat, Axel H. Ng, Felix Stahlberg, Xiaochang Peng, Kyle Gorman e Brian Roark.  Modelos Neurais de Normaliza√ß√£o de Texto para Aplica√ß√µes de Fala. <br>  [8] Ilya Sutskever, Oriol Vinyals, Quoc V. Le.  Sequence to Sequence Learning com redes neurais. <br>  [9] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior e Koray Kavukcuoglu.  WaveNet: um modelo generativo para √°udio bruto. <br>  [10] Aaron van den Oord, Yazhe Li, Igor Babuschkin, Karen Simonyan, Oriol Vinyals, Koray Kavukcuoglu, George van den Driessche, Edward Lockhart, Luis C. Cobo, Florian Stimberg, Norman Casagrande, Dominik Grewe, Seb Noury, Sander Dieleman Erich Elsen, Nal Kalchbrenner, Heiga Zen, Alex Graves, Helen King, Tom Walters, Dan Belov e Demis Hassabis.  WaveNet paralelo: s√≠ntese r√°pida de voz de alta fidelidade. <br>  [11] Wei Ping Kainan Peng Jitong Chen.  ClariNet: Gera√ß√£o de ondas paralelas em convers√£o de texto em fala de ponta a ponta. <br>  [12] Dario Rethage, Jordi Pons, Xavier Serra.  Um Wavenet para a fala Denoising. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt474782/">https://habr.com/ru/post/pt474782/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt474762/index.html">Semin√°rio: Solu√ß√µes de TI h√≠bridas para neg√≥cios. 14 de novembro, Moscou</a></li>
<li><a href="../pt474768/index.html">Transmiss√£o aberta do Main Hall HighLoad ++ 2019</a></li>
<li><a href="../pt474770/index.html">Como conduzimos o teste de regress√£o da folha de pagamento no SAP HCM</a></li>
<li><a href="../pt474772/index.html">Uma startup que usou a IA para desenvolver uma cura em 21 dias</a></li>
<li><a href="../pt474776/index.html">Teoria Geral e Arqueologia da Virtualiza√ß√£o x86</a></li>
<li><a href="../pt474784/index.html">Arcade Stick Story</a></li>
<li><a href="../pt474788/index.html">Organiza√ß√£o de rotas no Laravel</a></li>
<li><a href="../pt474790/index.html">Contos do negociador</a></li>
<li><a href="../pt474792/index.html">6-8 de dezembro - Rosbank Tech.Madness Hackathon</a></li>
<li><a href="../pt474796/index.html">O que √© a Internet das coisas e como isso ajudar√° as empresas a ganhar mais?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
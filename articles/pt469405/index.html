<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì∞ üíó üë®‚Äçüë®‚Äçüëß‚Äçüë¶ O Deep Learning agora est√° em Java ü§µüèæ üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë® üì©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="N√£o gosta de Java? Sim, voc√™ n√£o sabe cozinhar! Mani Sarkar nos convida a familiarizar-se com a ferramenta Valohai, que permite realizar pesquisas de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O Deep Learning agora est√° em Java</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/469405/">  N√£o gosta de Java?  Sim, voc√™ n√£o sabe cozinhar!  Mani Sarkar nos convida a familiarizar-se com a ferramenta Valohai, que permite realizar pesquisas de modelos em Java. <br><br><img src="https://habrastorage.org/webt/et/p-/se/etp-sezekre2qlznmvgdzlgds0a.png"><br><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Isen√ß√£o de responsabilidade do tradutor</b> <div class="spoiler_text"> Espero que n√£o seja uma publica√ß√£o publicit√°ria.  Eu n√£o sou afiliado com Valohai.  Acabei de traduzir o artigo ao qual refiro o link.  Se desajeitado traduzido - pontap√© no PM.  Se necess√°rio, posso excluir links e mencionar outros recursos externos.  Obrigado pela sua compreens√£o. <br></div></div><br><h3>  1. Introdu√ß√£o </h3><br>  H√° algum tempo, deparei-me com um servi√ßo em nuvem chamado Valohai, e fiquei satisfeito com a interface do usu√°rio e a simplicidade do design e layout.  Pedi o servi√ßo de um dos membros de Valohai e recebi uma vers√£o demo.  Antes disso, escrevi um pipeline simples usando o GNU Parallel, JavaScript, Python e Bash - e outro que usa apenas o GNU Parallel e Bash. <br><br>  Tamb√©m pensei em usar ferramentas de gerenciamento de tarefas / fluxo de trabalho prontas para uso, como Jenkins X, Jenkins Pipeline, Concourse ou Airflow, mas por v√°rias raz√µes, decidi n√£o usar. <br><br>  Notei que muitos exemplos e documenta√ß√£o de Valohai s√£o baseados em Python e R e em suas respectivas estruturas e bibliotecas.  Decidi n√£o perder a oportunidade e quero corrigir a falta de exemplos e documenta√ß√£o. <br><br>  Valohai me incentivou a implementar algo usando a famosa biblioteca Java chamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DL4J - Deep Learning for Java</a> . <br><br>  Minha primeira experi√™ncia com Valohai causou uma boa impress√£o em mim depois de sentir o design, o layout e o fluxo de trabalho.  Os criadores j√° levaram em considera√ß√£o v√°rios aspectos dos fluxos de trabalho do desenvolvedor e da infraestrutura.  Em nosso mundo, o processo de desenvolvimento de infraestrutura √© controlado principalmente pelas equipes de DevOps ou SysOps, e conhecemos as nuances e pontos negativos associados a ele. <br><br><h3>  Do que precisamos e como? </h3><br>  Em qualquer projeto de aprendizado de m√°quina, existem dois componentes importantes (do ponto de vista de alto n√≠vel) - um c√≥digo que funcionar√° com o modelo e um c√≥digo que funcionar√° com a infraestrutura, na qual todo o ciclo de vida do projeto ser√° executado. <br><br>  Obviamente, haver√° etapas e componentes necess√°rios antes, durante e depois, mas para simplificar, digamos, precisamos de c√≥digo e infraestrutura. <br><br><h4>  C√≥digo </h4><br>  Para o c√≥digo, escolhi um exemplo complexo usando o DL4J, este √© um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">projeto MNist</a> com um conjunto de treinamento de 60.000 imagens e um conjunto de testes de 10.000 imagens de d√≠gitos manuscritos.  Este conjunto de dados est√° dispon√≠vel na biblioteca DL4J (como Keras). <br><br>  Antes de come√ßar, √© recomend√°vel que voc√™ d√™ uma olhada no c√≥digo-fonte que usaremos.  A principal classe Java √© chamada <a href="">org.deeplearning4j.feedforward.mnist.MLPMnistSingleLayerRunner</a> . <br><br><h4>  A infraestrutura </h4><br>  Decidimos tentar o exemplo de Java usando Valohai como nossa infraestrutura para realizar experimentos (treinamento e avalia√ß√£o de modelos).  O Valohai reconhece os reposit√≥rios git e se conecta diretamente a eles, permitindo que executemos nosso c√≥digo independentemente da plataforma ou idioma - portanto, veremos como ele funciona.  Isso tamb√©m significa que, se voc√™ usar GitOps ou Infraestrutura como c√≥digo, tudo funcionar√° para voc√™ tamb√©m. <br><br>  Para fazer isso, precisamos apenas de uma conta em Valohai.  Depois de criar uma conta gratuita, obtemos acesso a v√°rias inst√¢ncias de v√°rias configura√ß√µes.  Para o que gostar√≠amos de fazer, o Free-Tier √© mais que suficiente. <br><br><h4>  Deep Learning para Java e Valohai </h4><br>  Forneceremos todas as depend√™ncias da imagem do Docker e a usaremos para compilar nosso aplicativo Java, treinar o modelo e avali√°-lo na plataforma Valohai usando um simples arquivo <a href="">valohai.yaml</a> localizado na pasta raiz do reposit√≥rio do projeto. <br><br><h4>  Deep Learning para Java: DL4J </h4><br>  A parte mais simples.  N√£o precisamos fazer muito, basta coletar o frasco e carregar o conjunto de dados no cont√™iner do Docker.  Temos uma imagem pr√©-criada do Docker que cont√©m todas as depend√™ncias necess√°rias para criar um aplicativo Java.  Colocamos essa imagem no Docker Hub e voc√™ pode encontr√°-la pesquisando dl4j-mnist-single-layer (usaremos uma tag especial conforme definida no arquivo YAML).  Decidimos usar o GraalVM 19.1.1 como nosso ambiente Java de compila√ß√£o e tempo de execu√ß√£o para este projeto, e ele √© incorporado √† imagem do Docker. <br><br>  Quando o uber jar √© chamado na linha de comando, criamos a classe MLPMnistSingleLayerRunner, que nos diz a a√ß√£o pretendida, dependendo dos par√¢metros passados ‚Äã‚Äãpara: <br><br><pre><code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(String[] args)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">throws</span></span></span><span class="hljs-function"> Exception </span></span>{ MLPMnistSingleLayerRunner mlpMnistRunner = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MLPMnistSingleLayerRunner(); JCommander.newBuilder() .addObject(mlpMnistRunner) .build() .parse(args); mlpMnistRunner.execute(); }</code> </pre> <br>  Os par√¢metros passados ‚Äã‚Äãpara o uber jar s√£o aceitos por essa classe e processados ‚Äã‚Äãpelo m√©todo execute (). <br><br>  Podemos criar um modelo usando o par√¢metro --action train e avaliar o modelo criado usando o par√¢metro --action assessment passado para o aplicativo Java. <br><br>  As principais partes do aplicativo Java que fazem esse trabalho podem ser encontradas nas duas classes Java mencionadas nas se√ß√µes abaixo. <br><br><h3>  Modelo de treinamento </h3><br>  Ligar <br><br><pre> <code class="plaintext hljs">./runMLPMnist.sh --action train --output-dir ${VH_OUTPUTS_DIR} or java -Djava.library.path="" \ -jar target/MLPMnist-1.0.0-bin.jar \ --action train --output-dir ${VH_OUTPUTS_DIR}</code> </pre><br>  Este comando cria um modelo chamado mlpmnist-single-layer.pb na pasta especificada pelo par√¢metro --output-dir passado no in√≠cio da execu√ß√£o.  Do ponto de vista de Valohai, ele deve ser colocado em $ {VH_OUTPUTS_DIR}, o que fazemos (consulte o arquivo <a href="">valohai.yaml</a> ). <br><br>  Para o c√≥digo fonte, consulte a classe <a href="">MLPMNistSingleLayerTrain.java</a> . <br><br><h3>  Avalia√ß√£o do Modelo </h3><br>  Ligar <br><br><pre> <code class="plaintext hljs">./runMLPMnist.sh --action evaluate --input-dir ${VH_INPUTS_DIR}/model or java -Djava.library.path="" \ -jar target/MLPMnist-1.0.0-bin.jar \ --action evaluate --input-dir ${VH_INPUTS_DIR}/model</code> </pre><br>  Sup√µe-se que o modelo (criado durante a fase de treinamento) com o nome mlpmnist-single-layer.pb esteja presente na pasta especificada no par√¢metro --input-dir passado quando o aplicativo foi chamado. <br><br>  Para o c√≥digo-fonte, consulte a classe <a href="">MLPMNistSingleLayerEvaluate.java</a> . <br><br>  Espero que esta breve ilustra√ß√£o esclare√ßa como funciona um aplicativo Java que ensina e avalia um modelo. <br><br>  Isso √© tudo o que √© exigido de n√≥s, mas n√£o hesite em brincar com o restante das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fontes</a> (juntamente com os scripts <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">README.md</a> e bash) e satisfazer sua curiosidade e compreens√£o de como isso √© feito! <br><br><h3>  Valohai </h3><br>  O Valohai nos permite vincular livremente nosso tempo de execu√ß√£o, c√≥digo e conjunto de dados, como voc√™ pode ver na estrutura do arquivo YAML abaixo.  Assim, v√°rios componentes podem se desenvolver independentemente um do outro.  Consequentemente, apenas os componentes de montagem e tempo de execu√ß√£o s√£o embalados em nosso cont√™iner Docker. <br><br>  Em tempo de execu√ß√£o, coletamos o Uber JAR em um cont√™iner do Docker, carregamos em algum armazenamento interno ou externo e usamos a outra etapa de execu√ß√£o para carregar o Uber JAR e o conjunto de dados do armazenamento (ou outro local) para iniciar o treinamento.  Assim, as duas etapas de execu√ß√£o s√£o desconectadas;  por exemplo, podemos compilar um frasco uma vez e concluir centenas de etapas de treinamento em um √∫nico frasco.  Como os ambientes de montagem e tempo de execu√ß√£o n√£o precisam ser alterados com tanta frequ√™ncia, podemos armazen√°-los em cache e o c√≥digo, conjuntos de dados e modelos podem ser acessados ‚Äã‚Äãdinamicamente no tempo de execu√ß√£o. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">valohai.yaml</a> <br>  A principal parte da integra√ß√£o do nosso projeto Java com a infraestrutura Valohai √© determinar a ordem das etapas de Execu√ß√£o no arquivo valohai.yaml localizado na raiz da pasta do seu projeto.  Nosso valohai.yaml √© assim: <br><br><pre> <code class="xml hljs">--- - step: name: Build-dl4j-mnist-single-layer-java-app image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - cd ${VH_REPOSITORY_DIR} - ./buildUberJar.sh - echo "~~~ Copying the build jar file into ${VH_OUTPUTS_DIR}" - cp target/MLPMnist-1.0.0-bin.jar ${VH_OUTPUTS_DIR}/MLPMnist-1.0.0.jar - ls -lash ${VH_OUTPUTS_DIR} environment: aws-eu-west-1-g2-2xlarge - step: name: Run-dl4j-mnist-single-layer-train-model image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - echo "~~~ Unpack the MNist dataset into ${HOME} folder" - tar xvzf ${VH_INPUTS_DIR}/dataset/mlp-mnist-dataset.tgz -C ${HOME} - cd ${VH_REPOSITORY_DIR} - echo "~~~ Copying the build jar file from ${VH_INPUTS_DIR} to current location" - cp ${VH_INPUTS_DIR}/dl4j-java-app/MLPMnist-1.0.0.jar . - echo "~~~ Run the DL4J app to train model based on the the MNist dataset" - ./runMLPMnist.sh {parameters} inputs: - name: dl4j-java-app description: DL4J Java app file (jar) generated in the previous step 'Build-dl4j-mnist-single-layer-java-app' - name: dataset default: https://github.com/neomatrix369/awesome-ai-ml-dl/releases/download/mnist-dataset-v0.1/mlp-mnist-dataset.tgz description: MNist dataset needed to train the model parameters: - name: --action pass-as: '--action {v}' type: string default: train description: Action to perform ie train or evaluate - name: --output-dir pass-as: '--output-dir {v}' type: string default: /valohai/outputs/ description: Output directory where the model will be created, best to pick the Valohai output directory environment: aws-eu-west-1-g2-2xlarge - step: name: Run-dl4j-mnist-single-layer-evaluate-model image: neomatrix369/dl4j-mnist-single-layer:v0.5 command: - cd ${VH_REPOSITORY_DIR} - echo "~~~ Copying the build jar file from ${VH_INPUTS_DIR} to current location" - cp ${VH_INPUTS_DIR}/dl4j-java-app/MLPMnist-1.0.0.jar . - echo "~~~ Run the DL4J app to evaluate the trained MNist model" - ./runMLPMnist.sh {parameters} inputs: - name: dl4j-java-app description: DL4J Java app file (jar) generated in the previous step 'Build-dl4j-mnist-single-layer-java-app' - name: model description: Model file generated in the previous step 'Run-dl4j-mnist-single-layer-train-model' parameters: - name: --action pass-as: '--action {v}' type: string default: evaluate description: Action to perform ie train or evaluate - name: --input-dir pass-as: '--input-dir {v}' type: string default: /valohai/inputs/model description: Input directory where the model created by the previous step can be found created environment: aws-eu-west-1-g2-2xlarge</code> </pre><br><h4>  Como o Build-dl4j-mnist-single-layer-java-app funciona </h4><br>  No arquivo YAML, vemos que definimos essa etapa, primeiro usando a imagem do Docker e, em seguida, executando o script para criar o Uber JAR.  Nossa imagem do docker possui personaliza√ß√£o das depend√™ncias do ambiente de constru√ß√£o (por exemplo, GraalVM JDK, Maven etc.) para criar um aplicativo Java.  N√£o fornecemos nenhuma entrada ou par√¢metro, pois esta √© a fase de montagem.  Quando a compila√ß√£o for bem-sucedida, copiamos o uber jar chamado MLPMnist-1.0.0-bin.jar (nome original) para a pasta / valohai / outputs (representada como $ {VH_OUTPUTS_DIR}).  Tudo nesta pasta √© salvo automaticamente no armazenamento do seu projeto, por exemplo, na lixeira do AWS S3.  Por fim, definimos nosso trabalho para a AWS. <br><br><div class="spoiler">  <b class="spoiler_title">Nota</b> <div class="spoiler_text">  A conta gratuita do Valohai n√£o tem acesso √† rede a partir do cont√™iner do Docker (isso est√° desativado por padr√£o); entre em contato com o suporte para ativar esta op√ß√£o (eu tive que fazer o mesmo); caso contr√°rio, n√£o conseguiremos baixar o Maven e outras depend√™ncias durante a montagem. <br></div></div><br><h4>  Como o modelo Run-dl4j-mnist-single-layer-train-train funciona </h4><br>  A sem√¢ntica da defini√ß√£o √© semelhante √† etapa anterior, exceto que especificamos duas entradas: uma para o uber jar (MLPMnist-1.0.0.jar) e a outra para o conjunto de dados (descompactado na pasta $ {HOME} /. Deeplearning4j).  Passaremos dois par√¢metros - --action train e --output-dir / valohai / outputs.  O modelo criado nesta etapa √© constru√≠do em / valohai / outputs / model (representado como $ {VH_OUTPUTS_DIR} / model). <br><br><div class="spoiler">  <b class="spoiler_title">Nota</b> <div class="spoiler_text">  Nos campos de entrada na guia Execu√ß√£o da interface da web Valohai, podemos selecionar a sa√≠da das execu√ß√µes anteriores usando o n√∫mero da execu√ß√£o, ou seja, n¬∫ 1 ou n¬∫ 2, al√©m de usar o dado: // ou http: / URLs /, inserir algumas letras do nome do arquivo tamb√©m ajuda a pesquisar a lista inteira. <br></div></div><br><h4>  Como o Run-dl4j-mnist-single-layer -valu-model funciona </h4><br>  Novamente, esta etapa √© semelhante √† etapa anterior, exceto que passaremos dois par√¢metros - action assessment e --input-dir / valohai / inputs / model.  Al√©m disso, indicamos novamente na entrada: as se√ß√µes definidas no arquivo YAML com o nome dl4j-java-app e model sem o padr√£o para os dois.  Isso nos permitir√° selecionar o uber jar e o modelo que queremos avaliar - que foi criado usando a etapa Run-dl4j-mnist-single-layer-train-model-model usando a interface da web. <br><br>  Espero que isso explique as etapas no arquivo de defini√ß√£o acima, mas se voc√™ precisar de mais ajuda, fique √† vontade para visualizar a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> e os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tutoriais</a> . <br><br><h3>  Interface Web Valohai </h3><br>  Ap√≥s receber a conta, podemos efetuar login e continuar criando o projeto com o nome mlpmnist-single-layer e associar git repo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/valohai/mlpmnist-dl4j-example</a> ao projeto e salvar o projeto. <br><br>  Agora voc√™ pode concluir a etapa e ver como fica! <br><br><h4>  Construir um aplicativo Java DL4J </h4><br>  V√° para a guia "Execu√ß√£o" na interface da web e copie a execu√ß√£o existente ou crie uma nova usando o bot√£o [Criar execu√ß√£o].  Todos os par√¢metros padr√£o necess√°rios ser√£o preenchidos.  Selecione Etapa Build-dl4j-mnist-single-layer-java-app. <br><br>  Para o <i>ambiente,</i> selecionei AWS eu-west-1 g2.2xlarge e cliquei no bot√£o [Criar execu√ß√£o] na parte inferior da p√°gina para ver o in√≠cio da execu√ß√£o. <br><br><img src="https://habrastorage.org/webt/le/18/zo/le18zo_udbscmekflaux7kqfjcw.png"><br><br><h3>  Modelo de treinamento </h3><br>  V√° para a guia "Execu√ß√£o" na interface da web e fa√ßa o mesmo da etapa anterior e selecione Executar-dl4j-mnist-modelo de trem de camada √∫nica.  Voc√™ precisar√° selecionar o aplicativo Java (basta inserir jar no campo) criado na etapa anterior.  O conjunto de dados j√° foi preenchido previamente usando o arquivo valohai.yaml: <br><br><img src="https://habrastorage.org/webt/md/ls/ov/mdlsovhg3vw9zjnpoeqhxwzgk7w.png"><br><br>  Clique em [Criar execu√ß√£o] para iniciar. <br><br><img src="https://habrastorage.org/webt/6n/mr/wm/6nmrwmveck6cgdughud1xgx7qdg.png"><br><br>  Voc√™ ver√° o resultado no console: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:05 ======================================================================= 11:17:05 LayerName (LayerType) nIn,nOut TotalParams ParamsShape 11:17:05 ======================================================================= 11:17:05 layer0 (DenseLayer) 784,1000 785000 W:{784,1000}, b:{1,1000} 11:17:05 layer1 (OutputLayer) 1000,10 10010 W:{1000,10}, b:{1,10} 11:17:05 ----------------------------------------------------------------------- 11:17:05 Total Parameters: 795010 11:17:05 Trainable Parameters: 795010 11:17:05 Frozen Parameters: 0 11:17:05 ======================================================================= [&lt;--- snipped ---&gt;]</code> </pre><br>  Modelos criados podem ser encontrados na guia "Sa√≠das" da guia principal "Execu√ß√£o" durante e ap√≥s a execu√ß√£o: <br><br><img src="https://habrastorage.org/webt/pg/g2/-k/pgg2-kmsr85x87fedfoy24lreye.png"><br><br>  Voc√™ pode observar v√°rios artefatos na subguia Sa√≠das.  Isso ocorre porque mantemos pontos de controle no final de cada era.  Vejamos isso nos logs: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:14 odolCheckpointListener - Model checkpoint saved: epoch 0, iteration 469, path: /valohai/outputs/checkpoint_0_MultiLayerNetwork.zip [&lt;--- snipped ---&gt;]</code> </pre><br>  O ponto de verifica√ß√£o cont√©m o estado do modelo em tr√™s arquivos: <br><br><pre> <code class="plaintext hljs">configuration.json coefficients.bin updaterState.bin</code> </pre><br><h3>  Modelo de treinamento.  Metadados </h3><br>  Voc√™ deve ter notado essas entradas nos logs de execu√ß√£o: <br><br><pre> <code class="plaintext hljs">[&lt;--- snipped ---&gt;] 11:17:05 {"epoch": 0, "iteration": 0, "score (loss function)": 2.410047} 11:17:07 {"epoch": 0, "iteration": 100, "score (loss function)": 0.613774} 11:17:09 {"epoch": 0, "iteration": 200, "score (loss function)": 0.528494} 11:17:11 {"epoch": 0, "iteration": 300, "score (loss function)": 0.400291} 11:17:13 {"epoch": 0, "iteration": 400, "score (loss function)": 0.357800} 11:17:14 odolCheckpointListener - Model checkpoint saved: epoch 0, iteration 469, path: /valohai/outputs/checkpoint_0_MultiLayerNetwork.zip [&lt;--- snipped ---&gt;]</code> </pre><br>  Esses dados permitem que a Valohai obtenha esses valores (no formato JSON) que ser√£o usados ‚Äã‚Äãpara criar as m√©tricas que podem ser vistas durante e ap√≥s a execu√ß√£o na guia Metadados adicionais na guia principal Execu√ß√µes: <br><br><img src="https://habrastorage.org/webt/et/p-/se/etp-sezekre2qlznmvgdzlgds0a.png"><br><br>  Conseguimos fazer isso conectando a classe ValohaiMetadataCreator ao modelo, para que Valohai se refira a essa classe durante o treinamento.  No caso desta classe, derivamos v√°rias √©pocas, o n√∫mero de itera√ß√µes e Score (valor da fun√ß√£o de perda).  Aqui est√° um trecho de c√≥digo da classe: <br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">iterationDone</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Model model, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> iteration, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> epoch)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (printIterations &lt;= <span class="hljs-number"><span class="hljs-number">0</span></span>) printIterations = <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (iteration % printIterations == <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> score = model.score(); System.out.println(String.format( <span class="hljs-string"><span class="hljs-string">"{\"epoch\": %d, \"iteration\": %d, \"score (loss function)\": %f}"</span></span>, epoch, iteration, score) ); } }</code> </pre><br><h3>  Avalia√ß√£o do Modelo </h3><br>  Depois que o modelo foi criado com sucesso na etapa anterior, ele deve ser avaliado.  Criamos uma nova execu√ß√£o da mesma maneira que antes, mas desta vez selecione a etapa Run-dl4j-mnist-single-layer -valu-model.  Precisamos selecionar o aplicativo Java (MLPMnist-1.0.0.jar) e o modelo criado (mlpmnist-single-layer.pb) novamente antes de iniciar a execu√ß√£o (como mostrado abaixo): <br><br><img src="https://habrastorage.org/webt/e9/_b/am/e9_bamnlhownoo40utziaqazg8e.png"><br><br>  Ap√≥s selecionar o modelo desejado como entrada, clique no bot√£o [Criar execu√ß√£o].  Ele ser√° executado mais r√°pido que o anterior e veremos o seguinte resultado: <br><br><img src="https://habrastorage.org/webt/gp/0i/co/gp0icomuurv7a0gt-niye5hyri4.png"><br><br>  Vimos que nosso "mundo ol√°" levou a um modelo cuja precis√£o √© de cerca de 97%, com base em um conjunto de dados de teste.  A matriz de confus√£o ajuda a encontrar casos em que um d√≠gito foi previsto incorretamente como outro d√≠gito. <br><br>  A quest√£o permanece (e fora do escopo deste post) - qu√£o bom √© o modelo quando confrontado com dados reais? <br><br>  Para clonar um reposit√≥rio git, eis o que voc√™ precisa fazer: <br><br><pre> <code class="plaintext hljs"> $ git clone https://github.com/valohai/mlpmnist-dl4j-example</code> </pre><br>  Em seguida, precisamos vincular nosso projeto Valohai, criado atrav√©s da interface da web na se√ß√£o acima, com o projeto armazenado em nossa m√°quina local (a que acabamos de clonar).  Execute os seguintes comandos para fazer isso: <br><br><pre> <code class="plaintext hljs">$ cd mlpmnist-dl4j-example $ vh project --help ### to see all the project-specific options we have for Valohai $ vh project link</code> </pre><br>  Voc√™ ser√° mostrado algo como isto: <br><br><pre> <code class="plaintext hljs">[ 1] mlpmnist-single-layer ... Which project would you like to link with /path/to/mlpmnist-dl4j-example? Enter [n] to create a new project.:</code> </pre><br>  Selecione 1 (ou aquele que combina com voc√™) e voc√™ dever√° ver esta mensagem: <br><br><pre> <code class="plaintext hljs">Success! Linked /path/to/mlpmnist-dl4j-example to mlpmnist-single-layer.</code> </pre><br>  Mais uma coisa, antes de prosseguir, verifique se o seu projeto Valohai est√° sincronizado com o projeto git mais recente, fazendo o seguinte: <br><br><pre> <code class="plaintext hljs"> $ vh project fetch</code> </pre><br><img src="https://habrastorage.org/webt/h0/l4/vb/h0l4vbe1eqis5kb9sd7gfslbozk.png"><br><br>  Agora podemos concluir as etapas da CLI com: <br><br><pre> <code class="plaintext hljs"> $ vh exec run Build-dl4j-mnist-single-layer-java-app</code> </pre><br>  Ap√≥s a execu√ß√£o, podemos verificar com: <br><br><pre> <code class="plaintext hljs">$ vh exec info $ vh exec logs $ vh exec watch</code> </pre><br><h3>  Conclus√£o </h3><br>  Como vimos, √© muito conveniente trabalhar com DL4J e Valohai juntos.  Al√©m disso, podemos desenvolver os v√°rios componentes que comp√µem nossos experimentos (pesquisa), ou seja, o ambiente de compila√ß√£o / tempo de execu√ß√£o, o c√≥digo e o conjunto de dados e integr√°-los ao nosso projeto. <br><br>  Os modelos de amostra usados ‚Äã‚Äãnesta postagem s√£o uma boa maneira de come√ßar a criar projetos mais complexos.  E voc√™ pode usar a interface da Web ou da linha de comando para fazer seu trabalho com o Valohai.  Com a CLI, voc√™ tamb√©m pode integr√°-lo √†s suas instala√ß√µes e scripts (ou mesmo aos trabalhos CRON ou CI / CD). <br><br>  Al√©m disso, √© claro que, se estou trabalhando em um projeto relacionado √† AI / ML / DL, n√£o preciso me preocupar em criar e manter um pipeline de ponta a ponta (o que muitos outros tiveram que fazer no passado). <br><br><h5>  Refer√™ncias </h5><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O projeto mlpmnist-dl4j-examples no GitHub</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Recursos impressionantes de AI / ML / DL</a> </li><li>  <a href="">Recursos Java AI / ML / DL</a> </li><li>  <a href="">Recursos de Deep Learning e DL4J</a> </li></ol><br>  Obrigado pela aten√ß√£o! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt469405/">https://habr.com/ru/post/pt469405/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt469393/index.html">Reda√ß√£o do Flare-On 2019</a></li>
<li><a href="../pt469395/index.html">Onde e como usar v√°rias colunas (colunas CSS)</a></li>
<li><a href="../pt469399/index.html">Wi-Fi no Arkhangelskoye Museum-Estate</a></li>
<li><a href="../pt469401/index.html">Atualiza√ß√£o do servi√ßo 3CX WebMeeting, Elastix Online Converter e novos tutoriais em v√≠deo</a></li>
<li><a href="../pt469403/index.html">Estamos entrevistando um candidato para o cargo de desenvolvedor de software s√™nior</a></li>
<li><a href="../pt469407/index.html">ARIES PLC110 [M02] -MS4, HMI, OPC e SCADA, ou quanto uma pessoa precisa de ch√° de camomila. Parte 1</a></li>
<li><a href="../pt469409/index.html">Cria√ß√£o de perfil do Linux com o Performance Analyzer</a></li>
<li><a href="../pt469411/index.html">RE: Dor e l√°grimas em Svelte 3</a></li>
<li><a href="../pt469413/index.html">O resumo de materiais frescos do mundo da interface da √∫ltima semana n ¬∞ 382 (22 a 29 de setembro de 2019)</a></li>
<li><a href="../pt469415/index.html">N√≠veis de isolamento transacional para os menores</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
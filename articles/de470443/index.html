<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👍🏻 😵 👩🏽‍💼 Kontinuierliche Profilerstellung in Go 🧚🏾 🙃 🥚</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="pprof ist das Hauptprofilierungswerkzeug in Go. Der Profiler ist in der Go-Standardbibliothek enthalten, und im Laufe der Jahre wurde viel darüber ges...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kontinuierliche Profilerstellung in Go</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470443/"><p>  pprof ist das Hauptprofilierungswerkzeug in Go.  Der Profiler ist in der Go-Standardbibliothek enthalten, und im Laufe der Jahre wurde viel darüber geschrieben.  Um pprof mit einer vorhandenen Anwendung zu verbinden, müssen Sie nur eine Codezeile hinzufügen: </p><br><pre><code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> _ “net/http/pprof”</code> </pre> <br><p>  Im Standard-HTTP-Server - <code>net/http.DefaultServeMux</code> - werden Handler, die Profilerstellungsergebnisse senden, unter dem Pfad <code>/debug/pprof/</code> . </p><br><pre> <code class="plaintext hljs">curl -o cpu-profile.pb.gz http://&lt;server-addr&gt;/debug/pprof/profile</code> </pre> <br><p>  (Weitere Informationen finden Sie unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://godoc.org/net/">https://godoc.org/net/http/pprof</a> ) </p><br><p>  Aber aus Erfahrung ist es nicht immer so einfach und in der Praxis gibt es Fallstricke, wenn man pprof im Kampf einsetzt. </p><a name="habracut"></a><br><p>  Zunächst möchten wir nicht, dass die Profiler-Handler im Internet herausragen.  Die Profilerstellung ist in Bezug auf den Overhead billig, aber nicht kostenlos, und das Profil selbst enthält Informationen über die interne Struktur der Anwendung, die für Außenstehende häufig nicht ratsam sind.  Sie müssen sicherstellen, dass der Pfad <code>/debug</code> nicht für nicht autorisierte Benutzer zugänglich ist.  Der Zugriff kann auf der Seite des Proxyservers eingeschränkt werden, oder der pprof-Server kann an einen separaten Port verschoben werden, auf den nur über den privilegierten Host zugegriffen werden kann. </p><br><p>  Was aber, wenn die Anwendung überhaupt keinen HTTP-Zugriff beinhaltet - ist es beispielsweise ein Offline-Warteschlangenprozessor? </p><br><p>  Je nach Zustand der Infrastruktur im Unternehmen kann ein „plötzlicher“ HTTP-Server innerhalb des Anwendungsprozesses Fragen der Betriebsabteilung aufwerfen;) Der Server schränkt zusätzlich die Möglichkeiten der horizontalen Skalierung ein, weil  Es funktioniert nicht nur, um mehrere Instanzen der Anwendung auf demselben Host auszuführen. Die Prozesse stehen in Konflikt und versuchen, denselben TCP-Port für den pprof-Server zu öffnen. </p><br><p>  Es ist „einfach“ zu lösen, indem jeder Anwendungsprozess im Container isoliert wird (oder der pprof-Server an einem eindeutigen Port oder UNIX-Socket ausgeführt wird).  Sie werden niemanden mehr mit einem Service überraschen, der horizontal in Hunderte von Instanzen skaliert und auf mehrere Rechenzentren verteilt ist.  In einer sehr dynamischen Infrastruktur können Container mit der Anwendung regelmäßig angezeigt und ausgeblendet werden.  Und wir müssen uns trotzdem irgendwie an den Profiler wenden.  Dies bedeutet, dass unabhängig von der ausgewählten Skalierungsmethode Suchmechanismen für eine bestimmte Anwendungsinstanz und den entsprechenden pprof-Server-Port benötigt werden. </p><br><p>  Abhängig von den Merkmalen des Unternehmens kann das Vorhandensein der Fähigkeit, auf etwas zuzugreifen, das nicht mit der Hauptproduktionstätigkeit des Dienstes zusammenhängt, Fragen der Sicherheitsabteilung aufwerfen;) Ich habe in einem Unternehmen gearbeitet, in dem aus objektiven Gründen der Zugang zu irgendetwas nebenbei ist Die Produktion erfolgte ausschließlich in der Betriebsabteilung.  Die einzige Möglichkeit, den Profiler in einer laufenden Anwendung auszuführen, bestand darin, eine Aufgabe im Operations Bug Tracker zu öffnen, in der beschrieben wurde, welcher Curl-Befehl, in welchem ​​DC, auf welchem ​​Server Sie ausgeführt werden sollen, welches Ergebnis zu erwarten ist und was damit zu tun ist. </p><br><p>  Oder stellen Sie sich eine Situation vor: einen Arbeitsmorgen.  Sie haben Slack geöffnet und festgestellt, dass am Abend in einem der Produktionsserviceprozesse „etwas schief gelaufen ist“, „irgendwo etwas heruntergefahren wurde“, „Speicher zu fließen begann“, „CPU-Grafiken hochgekrochen“ oder Die App geriet gerade in Panik.  Die diensthabenden Betriebsteams (oder OOM Killer) haben nicht tief gegraben und einfach die Anwendung neu gestartet oder die neueste Version des Vortages zurückgesetzt. </p><br><p>  Im Nachhinein ist es nicht einfach, solche Situationen zu verstehen.  Es ist großartig, wenn das Problem in einer Testumgebung (oder in einem isolierten Teil der Produktion, auf den Sie Zugriff haben) reproduziert werden kann.  Sie können die erforderlichen Daten mit allen verfügbaren Tools erfassen und dann herausfinden, um welche Komponente es sich handelt. </p><br><p>  Wenn es jedoch keinen offensichtlichen Weg gibt, das Problem zu reproduzieren, bleiben uns dann nur die Protokolle und Metriken von gestern?  In solchen Situationen ist es immer eine Schande, dass Sie die Zeit nicht bis zu dem Zeitpunkt zurückspulen können, an dem das Problem in der Produktion sichtbar war, und schnell alle erforderlichen Profile erfassen können, um später in einem ruhigen Modus eine Analyse durchzuführen. </p><br><p>  Wenn pprof jedoch relativ günstig ist, können Sie Profildaten in bestimmten Abständen automatisch erfassen und an einem von der Produktion getrennten Ort speichern, an dem Sie allen Interessierten Zugriff gewähren können. </p><br><p>  Im Jahr 2010 veröffentlichte Google das Dokument <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google-Wide Profiling: Eine kontinuierliche Profiling-Infrastruktur für Rechenzentren</a> , in dem ein Ansatz zur kontinuierlichen Profilerstellung von Unternehmenssystemen beschrieben wird.  Und nach einigen Jahren startete das Unternehmen einen kontinuierlichen Profiling-Service - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stackdriver Profiler</a> - der allen zur Verfügung steht. </p><br><p>  Das Funktionsprinzip ist einfach: Anstelle eines pprof-Servers ist ein Stackdriver-Agent mit der Anwendung verbunden, der mithilfe der <code>runtime/pprof</code> API regelmäßig verschiedene Arten von Profilen aus der Anwendung sammelt und Profile an die Cloud sendet.  Alles, was der Entwickler benötigt, wählen Sie über das Stackdriver-Bedienfeld die gewünschte Anwendungsinstanz in der gewünschten AZ aus, und Sie können die Anwendung nachträglich jederzeit in der Vergangenheit analysieren. </p><br><p>  Andere SaaS-Anbieter bieten ähnliche Funktionen.  Die Sicherheitsregeln Ihres Unternehmens können jedoch den Export von Daten über die eigene Infrastruktur hinaus verbieten.  Und die Dienste, mit denen Sie ein kontinuierliches Profilierungssystem auf Ihren eigenen Servern bereitstellen können, habe ich nicht gesehen. </p><br><p>  Alle oben beschriebenen Schwierigkeiten und Ideen sind nicht nur für Go alles andere als neu und spezifisch.  Mit ihnen sind Entwickler in der einen oder anderen Form in fast allen Unternehmen konfrontiert, in denen ich gearbeitet habe. </p><br><p>  Irgendwann war ich neugierig zu versuchen, ein Analogon des Stackdriver Profiler für einen beliebigen Go-Service zu erstellen, der die beschriebenen Probleme lösen könnte.  Als Hobbyprojekt arbeite ich in meiner Freizeit an profefe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/profefe/profefe</a> ) - einem offenen Dienst für die kontinuierliche Profilerstellung.  Das Projekt befindet sich noch in der Phase von Experimenten und regelmäßigen Diskussionen, ist jedoch bereits zum Testen geeignet. </p><br><p>  Die Aufgaben, die ich für das Projekt festgelegt habe: </p><br><ol><li>  Der Service wird in der internen Infrastruktur des Unternehmens bereitgestellt. </li><li>  Der Service wird als internes Tool des Unternehmens verwendet.  Sie können Lieferanten und Verbrauchern von Daten vertrauen: In einem frühen Stadium können Sie die Autorisierung von Schreib- / Leseanfragen weglassen und nicht versuchen, sich vor böswilliger Verwendung im Voraus zu schützen. </li><li>  Der Service sollte keine besonderen Erwartungen an die Infrastruktur des Unternehmens haben: Alles kann in der Cloud oder in seinen eigenen DCs leben.  Profilanwendungen können in Containern ausgeführt werden ("alles wird von den Kubernetes gesteuert") oder auf Bare-Metal ausgeführt werden. </li><li>  Der Dienst sollte einfach zu bedienen sein (Prometheus scheint bis zu einem gewissen Grad ein gutes Beispiel zu sein). </li><li>  Es versteht sich, dass die ausgewählte Architektur möglicherweise nicht die Bedingungen erfüllt, unter denen der Dienst verwendet wird.  Höchstwahrscheinlich benötigen Sie die Möglichkeit, Systemkomponenten zu erweitern / zu ersetzen, um sie "vor Ort" zu skalieren. </li><li>  In Übereinstimmung mit (4) müssen wir versuchen, die erforderlichen externen Abhängigkeiten zu minimieren.  Zum Beispiel muss ein Dienst irgendwie nach Instanzen profilierter Anwendungen suchen, aber zumindest in der Anfangsphase möchte ich auf eine explizite Diensterkennung verzichten. </li><li>  Der Dienst speichert und katalogisiert Profile von Go-Anwendungen.  Wir erwarten, dass eine pprof-Datei 100 KB - 2 MB belegt ( <em>Heap-Profile sind normalerweise viel größer als CPU-Profile</em> ).  Von einer Profilinstanz aus macht es keinen Sinn, mehr als N Profile pro Minute zu senden (ein Stackdriver-Agent sendet durchschnittlich 2 Profile pro Minute).  Es lohnt sich sofort zu berechnen, dass eine einzelne Anwendung mehrere bis mehrere hundert Instanzen haben kann. </li><li>  Über den Dienst suchen Benutzer für einen bestimmten Zeitraum nach verschiedenen Profiltypen (CPU, Heap, Mutex usw.) der Anwendung oder einer bestimmten Instanz der Anwendung. </li><li>  Vom Dienst fordert der Benutzer ein separates pprof-Profil aus den Suchergebnissen an. </li></ol><br><p>  Jetzt besteht profefe aus zwei Komponenten: </p><br><p>  profefe-collector ist ein Service Collector mit einer einfachen RESTful-API. <br>  Die Aufgabe des Sammlers besteht darin, die pprof-Datei und einige Metadaten abzurufen und im permanenten Speicher zu speichern.  Die API ermöglicht es Kunden auch, Profile anhand von Metadaten in einem bestimmten Zeitfenster zu durchsuchen oder ein bestimmtes Profil (oder eine Gruppe von Profilen desselben Typs) aus dem Geschäft zu lesen. </p><br><p>  agent - eine optionale Bibliothek, die anstelle des pprof-Servers mit der Anwendung verbunden werden sollte.  Innerhalb der Anwendung startet der Agent in einer separaten Goroutine regelmäßig den Profilierungsprozess (unter Verwendung von <code>runtime/pprof</code> ) und sendet die empfangenen pprof-Profile zusammen mit den Metadaten an den Collector. </p><br><p>  <em>Metadaten</em> sind beliebige Schlüsselwertsätze, die eine Anwendung oder ihre einzelne Instanz beschreiben.  Beispiel: Dienstname, Version, Rechenzentrum und Host, auf dem die Anwendung ausgeführt wird. </p><br><p><img src="https://habrastorage.org/webt/ve/uy/-t/veuy-trq7iv0slekuvflqczg0li.png"><br>  <em>Profefe-Komponenteninteraktionsdiagramm</em> </p><br><p>  Ich habe oben erwähnt, dass der Agent eine optionale Komponente ist.  Wenn es nicht möglich ist, eine Verbindung zu einer vorhandenen Anwendung <code>net/http/pprof</code> , der <code>net/http/pprof</code> Server jedoch bereits in der Anwendung verbunden ist, können Profile mit externen Tools entfernt und pprof-Dateien über die HTTP-API an den Collector gesendet werden. </p><br><p>  Auf Hosts können Sie beispielsweise eine Cron-Task konfigurieren, die regelmäßig Profile von laufenden Instanzen sammelt und zur Speicherung an profefe sendet;) </p><br><p><img src="https://habrastorage.org/webt/bu/ed/9e/bued9erubh2yw3-gycuy6w_i_zi.png"><br>  <em>Die Cron-Aufgabe sammelt Anwendungsprofile und sendet sie an profefe collector</em> </p><br><p>  Weitere Informationen zur profefe API finden Sie <a href="https://github.com/profefe/profefe/blob/master/README.md#">in der Dokumentation zu GitHub</a> . </p><br><p>  <strong>Pläne</strong> </p><br><p>  Bisher ist die HTTP-API die einzige Möglichkeit, mit dem profefe-Kollektor zu interagieren.  Eine der Aufgaben für die Zukunft besteht darin, einen separaten UI-Dienst zusammenzustellen, über den die gespeicherten Daten visuell angezeigt werden können: Suchergebnisse, ein allgemeiner Überblick über die Clusterleistung usw. </p><br><p>  Das Sammeln und Speichern von Profildaten ist nicht schlecht, aber "ohne Anwendung sind Daten nutzlos."  Das Team, in dem ich arbeite, verfügt über eine Reihe von experimentellen Tools zum Sammeln grundlegender Statistiken für mehrere pprof-Profile aus dem Dienst.  Dies hilft sehr bei der Analyse der Konsequenzen der Aktualisierung der wichtigsten Abhängigkeiten der Anwendung oder der Ergebnisse umfangreicher Umgestaltungen ( <em>leider entspricht die Leistung in der Produktion nicht immer den Erwartungen, die auf der Einführung isolierter Benchmarks und der Profilerstellung in einer Testumgebung beruhen</em> ).  Ich möchte ähnliche Funktionen hinzufügen, um gespeicherte Profile in der profefe-API zu vergleichen und zu analysieren. </p><br><p>  Trotz der Tatsache, dass das Hauptaugenmerk von profefe auf der kontinuierlichen Profilerstellung von Go-Diensten liegt, ist das pprof-Profilformat überhaupt nicht an Go gebunden.  Für Java, JavaScript, Python usw. gibt es Bibliotheken, mit denen Sie Profildaten in diesem Format abrufen können.  Vielleicht wird profefe ein nützlicher Dienst für Anwendungen, die in anderen Sprachen geschrieben sind. </p><br><p>  Das Repository enthält unter anderem eine Reihe offener Fragen, die im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Projekt-Tracker auf GitHub beschrieben sind</a> . </p><br><p>  <strong>Fazit</strong> </p><br><p>  In den letzten Jahren hat sich unter Entwicklern eine beliebte Idee festgesetzt: Um die „ <em>Beobachtbarkeit</em> “ eines Dienstes zu erreichen, sind drei Komponenten erforderlich: Metriken, Protokolle und Ablaufverfolgung („ <em>drei Säulen der Beobachtbarkeit</em> “).  Sichtbarkeit ist für mich die Fähigkeit, Fragen zum Zustand des Systems und seiner Komponenten effektiv zu beantworten.  Metriken und Ablaufverfolgung ermöglichen es, das System als Ganzes zu verstehen.  Protokolle decken die absichtlich beschriebenen Teile des Systems ab.  Die Profilerstellung ist ein weiteres Signal, um Sichtbarkeit zu erreichen und das System auf Mikroebene zu verstehen.  Die kontinuierliche Profilerstellung über einen bestimmten Zeitraum hinweg hilft auch zu verstehen, wie die einzelnen Komponenten und die Umgebung die Bedienbarkeit und Produktivität des gesamten Systems beeinflusst und beeinflusst haben. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de470443/">https://habr.com/ru/post/de470443/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de470423/index.html">Edition-basierte Neudefinition. Teil 2</a></li>
<li><a href="../de470425/index.html">30.000 US-Dollar für die Lösung der Probleme von Regel 30 für zellulare Automaten - ein Wettbewerb von Stephen Wolfram</a></li>
<li><a href="../de470429/index.html">Unentwickeltes ERP in der Produktion: auf der Intensivstation oder in einer Leichenhalle? (Fortsetzung)</a></li>
<li><a href="../de470437/index.html">Digitaler Durchbruch: Finale des weltgrößten Hackathons</a></li>
<li><a href="../de470441/index.html">Größen verschiedener Arten von Java-Objekten</a></li>
<li><a href="../de470445/index.html">Der erste Prototyp eines Quantencomputers in Russland wurde bei NUST „MISiS“ vorgestellt.</a></li>
<li><a href="../de470447/index.html">Anatomie der Sprecher: Wahrheit und Fiktion über NXT-Emitter</a></li>
<li><a href="../de470449/index.html">Top-Fähigkeiten Sie müssen ein Front-End-Entwickler sein</a></li>
<li><a href="../de470451/index.html">Wie der grüne Junior in die IT kam</a></li>
<li><a href="../de470455/index.html">QIWI Server Party 5.0</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëçüèª üòµ üë©üèΩ‚Äçüíº Kontinuierliche Profilerstellung in Go üßöüèæ üôÉ ü•ö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="pprof ist das Hauptprofilierungswerkzeug in Go. Der Profiler ist in der Go-Standardbibliothek enthalten, und im Laufe der Jahre wurde viel dar√ºber ges...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kontinuierliche Profilerstellung in Go</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470443/"><p>  pprof ist das Hauptprofilierungswerkzeug in Go.  Der Profiler ist in der Go-Standardbibliothek enthalten, und im Laufe der Jahre wurde viel dar√ºber geschrieben.  Um pprof mit einer vorhandenen Anwendung zu verbinden, m√ºssen Sie nur eine Codezeile hinzuf√ºgen: </p><br><pre><code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> _ ‚Äúnet/http/pprof‚Äù</code> </pre> <br><p>  Im Standard-HTTP-Server - <code>net/http.DefaultServeMux</code> - werden Handler, die Profilerstellungsergebnisse senden, unter dem Pfad <code>/debug/pprof/</code> . </p><br><pre> <code class="plaintext hljs">curl -o cpu-profile.pb.gz http://&lt;server-addr&gt;/debug/pprof/profile</code> </pre> <br><p>  (Weitere Informationen finden Sie unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://godoc.org/net/">https://godoc.org/net/http/pprof</a> ) </p><br><p>  Aber aus Erfahrung ist es nicht immer so einfach und in der Praxis gibt es Fallstricke, wenn man pprof im Kampf einsetzt. </p><a name="habracut"></a><br><p>  Zun√§chst m√∂chten wir nicht, dass die Profiler-Handler im Internet herausragen.  Die Profilerstellung ist in Bezug auf den Overhead billig, aber nicht kostenlos, und das Profil selbst enth√§lt Informationen √ºber die interne Struktur der Anwendung, die f√ºr Au√üenstehende h√§ufig nicht ratsam sind.  Sie m√ºssen sicherstellen, dass der Pfad <code>/debug</code> nicht f√ºr nicht autorisierte Benutzer zug√§nglich ist.  Der Zugriff kann auf der Seite des Proxyservers eingeschr√§nkt werden, oder der pprof-Server kann an einen separaten Port verschoben werden, auf den nur √ºber den privilegierten Host zugegriffen werden kann. </p><br><p>  Was aber, wenn die Anwendung √ºberhaupt keinen HTTP-Zugriff beinhaltet - ist es beispielsweise ein Offline-Warteschlangenprozessor? </p><br><p>  Je nach Zustand der Infrastruktur im Unternehmen kann ein ‚Äûpl√∂tzlicher‚Äú HTTP-Server innerhalb des Anwendungsprozesses Fragen der Betriebsabteilung aufwerfen;) Der Server schr√§nkt zus√§tzlich die M√∂glichkeiten der horizontalen Skalierung ein, weil  Es funktioniert nicht nur, um mehrere Instanzen der Anwendung auf demselben Host auszuf√ºhren. Die Prozesse stehen in Konflikt und versuchen, denselben TCP-Port f√ºr den pprof-Server zu √∂ffnen. </p><br><p>  Es ist ‚Äûeinfach‚Äú zu l√∂sen, indem jeder Anwendungsprozess im Container isoliert wird (oder der pprof-Server an einem eindeutigen Port oder UNIX-Socket ausgef√ºhrt wird).  Sie werden niemanden mehr mit einem Service √ºberraschen, der horizontal in Hunderte von Instanzen skaliert und auf mehrere Rechenzentren verteilt ist.  In einer sehr dynamischen Infrastruktur k√∂nnen Container mit der Anwendung regelm√§√üig angezeigt und ausgeblendet werden.  Und wir m√ºssen uns trotzdem irgendwie an den Profiler wenden.  Dies bedeutet, dass unabh√§ngig von der ausgew√§hlten Skalierungsmethode Suchmechanismen f√ºr eine bestimmte Anwendungsinstanz und den entsprechenden pprof-Server-Port ben√∂tigt werden. </p><br><p>  Abh√§ngig von den Merkmalen des Unternehmens kann das Vorhandensein der F√§higkeit, auf etwas zuzugreifen, das nicht mit der Hauptproduktionst√§tigkeit des Dienstes zusammenh√§ngt, Fragen der Sicherheitsabteilung aufwerfen;) Ich habe in einem Unternehmen gearbeitet, in dem aus objektiven Gr√ºnden der Zugang zu irgendetwas nebenbei ist Die Produktion erfolgte ausschlie√ülich in der Betriebsabteilung.  Die einzige M√∂glichkeit, den Profiler in einer laufenden Anwendung auszuf√ºhren, bestand darin, eine Aufgabe im Operations Bug Tracker zu √∂ffnen, in der beschrieben wurde, welcher Curl-Befehl, in welchem ‚Äã‚ÄãDC, auf welchem ‚Äã‚ÄãServer Sie ausgef√ºhrt werden sollen, welches Ergebnis zu erwarten ist und was damit zu tun ist. </p><br><p>  Oder stellen Sie sich eine Situation vor: einen Arbeitsmorgen.  Sie haben Slack ge√∂ffnet und festgestellt, dass am Abend in einem der Produktionsserviceprozesse ‚Äûetwas schief gelaufen ist‚Äú, ‚Äûirgendwo etwas heruntergefahren wurde‚Äú, ‚ÄûSpeicher zu flie√üen begann‚Äú, ‚ÄûCPU-Grafiken hochgekrochen‚Äú oder Die App geriet gerade in Panik.  Die diensthabenden Betriebsteams (oder OOM Killer) haben nicht tief gegraben und einfach die Anwendung neu gestartet oder die neueste Version des Vortages zur√ºckgesetzt. </p><br><p>  Im Nachhinein ist es nicht einfach, solche Situationen zu verstehen.  Es ist gro√üartig, wenn das Problem in einer Testumgebung (oder in einem isolierten Teil der Produktion, auf den Sie Zugriff haben) reproduziert werden kann.  Sie k√∂nnen die erforderlichen Daten mit allen verf√ºgbaren Tools erfassen und dann herausfinden, um welche Komponente es sich handelt. </p><br><p>  Wenn es jedoch keinen offensichtlichen Weg gibt, das Problem zu reproduzieren, bleiben uns dann nur die Protokolle und Metriken von gestern?  In solchen Situationen ist es immer eine Schande, dass Sie die Zeit nicht bis zu dem Zeitpunkt zur√ºckspulen k√∂nnen, an dem das Problem in der Produktion sichtbar war, und schnell alle erforderlichen Profile erfassen k√∂nnen, um sp√§ter in einem ruhigen Modus eine Analyse durchzuf√ºhren. </p><br><p>  Wenn pprof jedoch relativ g√ºnstig ist, k√∂nnen Sie Profildaten in bestimmten Abst√§nden automatisch erfassen und an einem von der Produktion getrennten Ort speichern, an dem Sie allen Interessierten Zugriff gew√§hren k√∂nnen. </p><br><p>  Im Jahr 2010 ver√∂ffentlichte Google das Dokument <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google-Wide Profiling: Eine kontinuierliche Profiling-Infrastruktur f√ºr Rechenzentren</a> , in dem ein Ansatz zur kontinuierlichen Profilerstellung von Unternehmenssystemen beschrieben wird.  Und nach einigen Jahren startete das Unternehmen einen kontinuierlichen Profiling-Service - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stackdriver Profiler</a> - der allen zur Verf√ºgung steht. </p><br><p>  Das Funktionsprinzip ist einfach: Anstelle eines pprof-Servers ist ein Stackdriver-Agent mit der Anwendung verbunden, der mithilfe der <code>runtime/pprof</code> API regelm√§√üig verschiedene Arten von Profilen aus der Anwendung sammelt und Profile an die Cloud sendet.  Alles, was der Entwickler ben√∂tigt, w√§hlen Sie √ºber das Stackdriver-Bedienfeld die gew√ºnschte Anwendungsinstanz in der gew√ºnschten AZ aus, und Sie k√∂nnen die Anwendung nachtr√§glich jederzeit in der Vergangenheit analysieren. </p><br><p>  Andere SaaS-Anbieter bieten √§hnliche Funktionen.  Die Sicherheitsregeln Ihres Unternehmens k√∂nnen jedoch den Export von Daten √ºber die eigene Infrastruktur hinaus verbieten.  Und die Dienste, mit denen Sie ein kontinuierliches Profilierungssystem auf Ihren eigenen Servern bereitstellen k√∂nnen, habe ich nicht gesehen. </p><br><p>  Alle oben beschriebenen Schwierigkeiten und Ideen sind nicht nur f√ºr Go alles andere als neu und spezifisch.  Mit ihnen sind Entwickler in der einen oder anderen Form in fast allen Unternehmen konfrontiert, in denen ich gearbeitet habe. </p><br><p>  Irgendwann war ich neugierig zu versuchen, ein Analogon des Stackdriver Profiler f√ºr einen beliebigen Go-Service zu erstellen, der die beschriebenen Probleme l√∂sen k√∂nnte.  Als Hobbyprojekt arbeite ich in meiner Freizeit an profefe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/profefe/profefe</a> ) - einem offenen Dienst f√ºr die kontinuierliche Profilerstellung.  Das Projekt befindet sich noch in der Phase von Experimenten und regelm√§√üigen Diskussionen, ist jedoch bereits zum Testen geeignet. </p><br><p>  Die Aufgaben, die ich f√ºr das Projekt festgelegt habe: </p><br><ol><li>  Der Service wird in der internen Infrastruktur des Unternehmens bereitgestellt. </li><li>  Der Service wird als internes Tool des Unternehmens verwendet.  Sie k√∂nnen Lieferanten und Verbrauchern von Daten vertrauen: In einem fr√ºhen Stadium k√∂nnen Sie die Autorisierung von Schreib- / Leseanfragen weglassen und nicht versuchen, sich vor b√∂swilliger Verwendung im Voraus zu sch√ºtzen. </li><li>  Der Service sollte keine besonderen Erwartungen an die Infrastruktur des Unternehmens haben: Alles kann in der Cloud oder in seinen eigenen DCs leben.  Profilanwendungen k√∂nnen in Containern ausgef√ºhrt werden ("alles wird von den Kubernetes gesteuert") oder auf Bare-Metal ausgef√ºhrt werden. </li><li>  Der Dienst sollte einfach zu bedienen sein (Prometheus scheint bis zu einem gewissen Grad ein gutes Beispiel zu sein). </li><li>  Es versteht sich, dass die ausgew√§hlte Architektur m√∂glicherweise nicht die Bedingungen erf√ºllt, unter denen der Dienst verwendet wird.  H√∂chstwahrscheinlich ben√∂tigen Sie die M√∂glichkeit, Systemkomponenten zu erweitern / zu ersetzen, um sie "vor Ort" zu skalieren. </li><li>  In √úbereinstimmung mit (4) m√ºssen wir versuchen, die erforderlichen externen Abh√§ngigkeiten zu minimieren.  Zum Beispiel muss ein Dienst irgendwie nach Instanzen profilierter Anwendungen suchen, aber zumindest in der Anfangsphase m√∂chte ich auf eine explizite Diensterkennung verzichten. </li><li>  Der Dienst speichert und katalogisiert Profile von Go-Anwendungen.  Wir erwarten, dass eine pprof-Datei 100 KB - 2 MB belegt ( <em>Heap-Profile sind normalerweise viel gr√∂√üer als CPU-Profile</em> ).  Von einer Profilinstanz aus macht es keinen Sinn, mehr als N Profile pro Minute zu senden (ein Stackdriver-Agent sendet durchschnittlich 2 Profile pro Minute).  Es lohnt sich sofort zu berechnen, dass eine einzelne Anwendung mehrere bis mehrere hundert Instanzen haben kann. </li><li>  √úber den Dienst suchen Benutzer f√ºr einen bestimmten Zeitraum nach verschiedenen Profiltypen (CPU, Heap, Mutex usw.) der Anwendung oder einer bestimmten Instanz der Anwendung. </li><li>  Vom Dienst fordert der Benutzer ein separates pprof-Profil aus den Suchergebnissen an. </li></ol><br><p>  Jetzt besteht profefe aus zwei Komponenten: </p><br><p>  profefe-collector ist ein Service Collector mit einer einfachen RESTful-API. <br>  Die Aufgabe des Sammlers besteht darin, die pprof-Datei und einige Metadaten abzurufen und im permanenten Speicher zu speichern.  Die API erm√∂glicht es Kunden auch, Profile anhand von Metadaten in einem bestimmten Zeitfenster zu durchsuchen oder ein bestimmtes Profil (oder eine Gruppe von Profilen desselben Typs) aus dem Gesch√§ft zu lesen. </p><br><p>  agent - eine optionale Bibliothek, die anstelle des pprof-Servers mit der Anwendung verbunden werden sollte.  Innerhalb der Anwendung startet der Agent in einer separaten Goroutine regelm√§√üig den Profilierungsprozess (unter Verwendung von <code>runtime/pprof</code> ) und sendet die empfangenen pprof-Profile zusammen mit den Metadaten an den Collector. </p><br><p>  <em>Metadaten</em> sind beliebige Schl√ºsselwerts√§tze, die eine Anwendung oder ihre einzelne Instanz beschreiben.  Beispiel: Dienstname, Version, Rechenzentrum und Host, auf dem die Anwendung ausgef√ºhrt wird. </p><br><p><img src="https://habrastorage.org/webt/ve/uy/-t/veuy-trq7iv0slekuvflqczg0li.png"><br>  <em>Profefe-Komponenteninteraktionsdiagramm</em> </p><br><p>  Ich habe oben erw√§hnt, dass der Agent eine optionale Komponente ist.  Wenn es nicht m√∂glich ist, eine Verbindung zu einer vorhandenen Anwendung <code>net/http/pprof</code> , der <code>net/http/pprof</code> Server jedoch bereits in der Anwendung verbunden ist, k√∂nnen Profile mit externen Tools entfernt und pprof-Dateien √ºber die HTTP-API an den Collector gesendet werden. </p><br><p>  Auf Hosts k√∂nnen Sie beispielsweise eine Cron-Task konfigurieren, die regelm√§√üig Profile von laufenden Instanzen sammelt und zur Speicherung an profefe sendet;) </p><br><p><img src="https://habrastorage.org/webt/bu/ed/9e/bued9erubh2yw3-gycuy6w_i_zi.png"><br>  <em>Die Cron-Aufgabe sammelt Anwendungsprofile und sendet sie an profefe collector</em> </p><br><p>  Weitere Informationen zur profefe API finden Sie <a href="https://github.com/profefe/profefe/blob/master/README.md#">in der Dokumentation zu GitHub</a> . </p><br><p>  <strong>Pl√§ne</strong> </p><br><p>  Bisher ist die HTTP-API die einzige M√∂glichkeit, mit dem profefe-Kollektor zu interagieren.  Eine der Aufgaben f√ºr die Zukunft besteht darin, einen separaten UI-Dienst zusammenzustellen, √ºber den die gespeicherten Daten visuell angezeigt werden k√∂nnen: Suchergebnisse, ein allgemeiner √úberblick √ºber die Clusterleistung usw. </p><br><p>  Das Sammeln und Speichern von Profildaten ist nicht schlecht, aber "ohne Anwendung sind Daten nutzlos."  Das Team, in dem ich arbeite, verf√ºgt √ºber eine Reihe von experimentellen Tools zum Sammeln grundlegender Statistiken f√ºr mehrere pprof-Profile aus dem Dienst.  Dies hilft sehr bei der Analyse der Konsequenzen der Aktualisierung der wichtigsten Abh√§ngigkeiten der Anwendung oder der Ergebnisse umfangreicher Umgestaltungen ( <em>leider entspricht die Leistung in der Produktion nicht immer den Erwartungen, die auf der Einf√ºhrung isolierter Benchmarks und der Profilerstellung in einer Testumgebung beruhen</em> ).  Ich m√∂chte √§hnliche Funktionen hinzuf√ºgen, um gespeicherte Profile in der profefe-API zu vergleichen und zu analysieren. </p><br><p>  Trotz der Tatsache, dass das Hauptaugenmerk von profefe auf der kontinuierlichen Profilerstellung von Go-Diensten liegt, ist das pprof-Profilformat √ºberhaupt nicht an Go gebunden.  F√ºr Java, JavaScript, Python usw. gibt es Bibliotheken, mit denen Sie Profildaten in diesem Format abrufen k√∂nnen.  Vielleicht wird profefe ein n√ºtzlicher Dienst f√ºr Anwendungen, die in anderen Sprachen geschrieben sind. </p><br><p>  Das Repository enth√§lt unter anderem eine Reihe offener Fragen, die im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Projekt-Tracker auf GitHub beschrieben sind</a> . </p><br><p>  <strong>Fazit</strong> </p><br><p>  In den letzten Jahren hat sich unter Entwicklern eine beliebte Idee festgesetzt: Um die ‚Äû <em>Beobachtbarkeit</em> ‚Äú eines Dienstes zu erreichen, sind drei Komponenten erforderlich: Metriken, Protokolle und Ablaufverfolgung (‚Äû <em>drei S√§ulen der Beobachtbarkeit</em> ‚Äú).  Sichtbarkeit ist f√ºr mich die F√§higkeit, Fragen zum Zustand des Systems und seiner Komponenten effektiv zu beantworten.  Metriken und Ablaufverfolgung erm√∂glichen es, das System als Ganzes zu verstehen.  Protokolle decken die absichtlich beschriebenen Teile des Systems ab.  Die Profilerstellung ist ein weiteres Signal, um Sichtbarkeit zu erreichen und das System auf Mikroebene zu verstehen.  Die kontinuierliche Profilerstellung √ºber einen bestimmten Zeitraum hinweg hilft auch zu verstehen, wie die einzelnen Komponenten und die Umgebung die Bedienbarkeit und Produktivit√§t des gesamten Systems beeinflusst und beeinflusst haben. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de470443/">https://habr.com/ru/post/de470443/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de470423/index.html">Edition-basierte Neudefinition. Teil 2</a></li>
<li><a href="../de470425/index.html">30.000 US-Dollar f√ºr die L√∂sung der Probleme von Regel 30 f√ºr zellulare Automaten - ein Wettbewerb von Stephen Wolfram</a></li>
<li><a href="../de470429/index.html">Unentwickeltes ERP in der Produktion: auf der Intensivstation oder in einer Leichenhalle? (Fortsetzung)</a></li>
<li><a href="../de470437/index.html">Digitaler Durchbruch: Finale des weltgr√∂√üten Hackathons</a></li>
<li><a href="../de470441/index.html">Gr√∂√üen verschiedener Arten von Java-Objekten</a></li>
<li><a href="../de470445/index.html">Der erste Prototyp eines Quantencomputers in Russland wurde bei NUST ‚ÄûMISiS‚Äú vorgestellt.</a></li>
<li><a href="../de470447/index.html">Anatomie der Sprecher: Wahrheit und Fiktion √ºber NXT-Emitter</a></li>
<li><a href="../de470449/index.html">Top-F√§higkeiten Sie m√ºssen ein Front-End-Entwickler sein</a></li>
<li><a href="../de470451/index.html">Wie der gr√ºne Junior in die IT kam</a></li>
<li><a href="../de470455/index.html">QIWI Server Party 5.0</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
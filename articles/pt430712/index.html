<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòÇ ‚¨áÔ∏è ‚Ü™Ô∏è NeurIPS: Como conquistar a melhor confer√™ncia de ML üë©‚Äçüè≠ üìì üí®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="NeurIPS - uma confer√™ncia que atualmente √© considerada o evento mais importante do mundo do aprendizado de m√°quina. Hoje vou falar sobre minha experi√™...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NeurIPS: Como conquistar a melhor confer√™ncia de ML</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/430712/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NeurIPS</a> - uma confer√™ncia que atualmente √© considerada o evento mais importante do mundo do aprendizado de m√°quina.  Hoje vou falar sobre minha experi√™ncia em participar de concursos do NeurIPS: como competir com os melhores acad√™micos do mundo, ganhar um pr√™mio e publicar um artigo. </p><br><img src="https://habrastorage.org/webt/hb/kq/-v/hbkq-vnd_xgxhvcixlo-u8b_pmk.jpeg"><a name="habracut"></a><br><hr><br><h1 id="v-chem-sut-konferencii">  Qual √© a ess√™ncia da confer√™ncia? </h1><br><p>  O NeurIPS suporta a introdu√ß√£o de m√©todos de aprendizado de m√°quina em v√°rias disciplinas cient√≠ficas.  Aproximadamente 10 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">faixas s√£o</a> lan√ßadas anualmente para resolver problemas prementes do mundo acad√™mico.  De acordo com os resultados da competi√ß√£o, os vencedores falam na confer√™ncia com relat√≥rios, novos desenvolvimentos e algoritmos.  Acima de tudo, sou apaixonada por aprendizado refor√ßado (Reinforcement Learning ou RL), √© por isso que tenho participado de concursos de RL dedicados ao NeurIPS pelo segundo ano. </p><br><h1 id="pochemu-neurips">  Porqu√™ NeurIPS </h1><br><img src="https://habrastorage.org/webt/ei/c2/us/eic2usvfs-brxmsjczvkvygpfwq.png"><br><br>  O NeurIPS √© focado principalmente na ci√™ncia, n√£o no dinheiro.  Ao participar de concursos, voc√™ est√° fazendo algo realmente importante, lidando com quest√µes prementes. <br><p>  Em segundo lugar, esta confer√™ncia √© um evento global, cientistas de diferentes pa√≠ses se re√∫nem em um s√≥ lugar, com cada um dos quais voc√™ pode conversar. </p><br><p>  Al√©m disso, toda a confer√™ncia √© repleta das mais recentes realiza√ß√µes cient√≠ficas e resultados de √∫ltima gera√ß√£o, √© extremamente importante para as pessoas do campo da ci√™ncia de dados conhec√™-las e monitor√°-las. </p><br><h1 id="kak-nachat">  Como come√ßar? </h1><br><p>  Come√ßar a participar de tais competi√ß√µes √© bastante simples.  Se voc√™ entende tanto de DL que pode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">treinar o ResNet</a> - basta: inscreva-se e pronto.  Sempre existe uma tabela de classifica√ß√£o p√∫blica na qual voc√™ pode avaliar com sobriedade seu n√≠vel em compara√ß√£o com outros participantes.  E se algo n√£o estiver claro - sempre existem canais em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">folga</a> / disc√≥rdia / viol√™ncia / etc para discutir todas as quest√µes emergentes.  Se o t√≥pico for realmente ‚Äúseu‚Äù, nada o impedir√° de receber o valor estimado - em todas as competi√ß√µes em que participei, todas as abordagens e solu√ß√µes foram estudadas e implementadas no decorrer da competi√ß√£o. </p><br><h1 id="neurips-na-primere-konkretnogo-keysa-learning-to-run">  Estudo de caso do NeurIPS: aprendendo a correr </h1><br><img src="https://habrastorage.org/webt/hu/ws/d5/huwsd5weqocxiuqv3hugygmfqea.jpeg"><br><br><h3 id="problematika">  Edi√ß√£o </h3><br><p>  A marcha de uma pessoa √© o resultado da intera√ß√£o de m√∫sculos, ossos, √≥rg√£os de vis√£o e ouvido interno.  Em caso de perturba√ß√£o do sistema nervoso central, podem ocorrer certos dist√∫rbios motores, incluindo dist√∫rbios da marcha - abasia. <br>  Pesquisadores do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Laborat√≥rio de Biomec√¢nica Neuromuscular de Stanford</a> decidiram conectar o aprendizado de m√°quina √† quest√£o do tratamento para poder experimentar e testar suas teorias em um modelo virtual do esqueleto, e n√£o em pessoas vivas. </p><br><h3 id="postanovka-zadachi">  Declara√ß√£o do problema </h3><br><p>  Os participantes receberam um esqueleto humano virtual (no simulador <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenSim</a> ), que possu√≠a uma pr√≥tese no lugar de uma perna.  A tarefa era ensinar o esqueleto a se mover em uma determinada dire√ß√£o a uma determinada velocidade.  Durante a simula√ß√£o, a dire√ß√£o e a velocidade podem mudar. </p><br><img src="https://habrastorage.org/webt/od/vj/np/odvjnpxb7xogj5h_5ll85iokhp0.jpeg"><br><br>  Para obter um modelo de controle do esqueleto virtual, foi proposto o uso de aprendizado por refor√ßo.  O simulador nos deu algum estado do esqueleto S (um vetor de ~ 400 n√∫meros).  Era necess√°rio prever que a√ß√£o A precisa ser executada (as for√ßas de ativa√ß√£o dos m√∫sculos das pernas s√£o um vetor de 19 n√∫meros).  No decorrer da simula√ß√£o, o esqueleto recebeu um pr√™mio R - como uma esp√©cie de constante menos uma penalidade por desviar-se de uma determinada velocidade e dire√ß√£o. <br><div class="spoiler">  <b class="spoiler_title">Sobre treinamento de refor√ßo</b> <div class="spoiler_text"><p>  Aprendizado por Refor√ßo (RL) √© uma √°rea que lida com a teoria da decis√£o e a busca de pol√≠ticas comportamentais ideais. </p><br><p>  Lembre-se de como eles ensinam <del>  gato </del>  truques novos do cachorrinho.  Repita alguma a√ß√£o, d√™ um gostoso por executar um truque e n√£o d√™ por n√£o cumprimento.  O c√£o deve entender tudo isso e encontrar uma estrat√©gia comportamental ("pol√≠tica" ou "pol√≠tica" em termos de RL), que maximize o n√∫mero de doces recebidos. </p><br><p>  Formalmente, temos um agente (c√£o) treinado na hist√≥ria das intera√ß√µes com o meio ambiente (pessoa).  Ao mesmo tempo, o ambiente, avaliando as a√ß√µes do agente, oferece a ele uma recompensa (deliciosa) - quanto melhor o comportamento do agente, maior a recompensa.  Consequentemente, a tarefa do agente √© encontrar uma pol√≠tica que maximize bem a recompensa por todo o tempo de intera√ß√£o com o ambiente. </p><br><p>  Desenvolvendo esse t√≥pico ainda mais, solu√ß√µes baseadas em regras - software 1.0, quando todas as regras foram definidas pelo desenvolvedor, aprendizado supervisionado - o pr√≥prio software 2.0, quando o sistema aprende a si pr√≥prio usando os exemplos dispon√≠veis e encontra depend√™ncias de dados, o aprendizado por refor√ßo √© um passo um pouco mais longe quando o pr√≥prio sistema aprende a pesquisar, experimentar e encontrar as depend√™ncias necess√°rias em suas decis√µes.  Quanto mais avan√ßamos, melhor tentamos repetir como uma pessoa aprende. </p></div></div><br><h3 id="osobennosti-zadachi">  Recursos da tarefa </h3><br><p>  A tarefa se parece com um representante t√≠pico do aprendizado refor√ßado para tarefas com espa√ßo de a√ß√£o cont√≠nuo (RL para espa√ßo de a√ß√£o cont√≠nua).  Difere da RL comum, pois, em vez de escolher uma a√ß√£o espec√≠fica (pressionando o bot√£o do joystick), essa a√ß√£o √© necess√°ria para prever com precis√£o (e existem infinitas possibilidades). </p><br><p>  A abordagem b√°sica da solu√ß√£o ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deep Deterministic Policy Gradient</a> ) foi inventada em 2015, que por um longo tempo pelos padr√µes da DL, a regi√£o continua a se desenvolver ativamente em aplicativos para rob√≥tica e aplicativos RL do mundo real.  H√° algo a ser aprimorado: abordagens robustas (para n√£o quebrar um rob√¥ real), efici√™ncia da amostra (para n√£o coletar dados de rob√¥s reais por meses) e outros problemas de RL (trade-off de explora√ß√£o x explora√ß√£o, etc.).  Nesta competi√ß√£o, eles n√£o nos deram um rob√¥ real - apenas uma simula√ß√£o, mas o simulador em si era 2.000 vezes mais lento que os de c√≥digo aberto (nos quais todos verificam seus algoritmos de RL) e, portanto, trouxe o problema da efici√™ncia da amostra para um novo n√≠vel. </p><br><h3 id="etapy-sorevnovaniya">  Etapas da competi√ß√£o </h3><br><p>  A competi√ß√£o ocorreu em tr√™s etapas, durante as quais a tarefa e as condi√ß√µes mudaram um pouco. </p><br><ul><li>  Etapa 1: o esqueleto aprendeu a andar em linha reta a uma velocidade de 3 metros por segundo.  A tarefa foi considerada conclu√≠da se o agente passou por 300 etapas. </li><li>  Etapa 2: velocidade e dire√ß√£o alteradas com uma frequ√™ncia regular.  O comprimento da dist√¢ncia aumentou para 1000 etapas. </li><li>  Etapa 3: a solu√ß√£o final teve que ser empacotada em uma imagem do docker e enviada para verifica√ß√£o.  No total, 10 parcelas podem ser feitas. </li></ul><br><p>  A principal m√©trica de qualidade foi considerada a recompensa total pela simula√ß√£o, que mostrou o qu√£o bem o esqueleto aderiu a uma determinada dire√ß√£o e velocidade ao longo da dist√¢ncia. </p><br><p>  Durante a 1¬™ e a 2¬™ etapa, o progresso de cada participante foi exibido na tabela de classifica√ß√£o.  A solu√ß√£o final precisava ser enviada como uma imagem do docker.  Previa restri√ß√µes quanto ao hor√°rio e recursos de trabalho. </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory: ranking p√∫blico e RL</b> <div class="spoiler_text"><p>  Devido √† disponibilidade da tabela de classifica√ß√£o, ningu√©m mostra o seu melhor modelo para dar "um pouco mais do que o habitual" na rodada final e surpreender os rivais. </p></div></div><br><h6 id="pochemu-tak-vazhny-docker-obrazy">  Por que as imagens do docker s√£o t√£o importantes </h6><br><p>  No ano passado, ocorreu um pequeno incidente ao avaliar as decis√µes no primeiro turno.  Naquela √©poca, a verifica√ß√£o passou pela intera√ß√£o http com a plataforma, e uma face das condi√ß√µes para o teste foi encontrada.  Pode-se descobrir em quais situa√ß√µes particulares o agente foi avaliado e trein√°-lo novamente nessas condi√ß√µes.  O que, √© claro, n√£o resolveu o problema real.  Por isso, eles decidiram transferir o sistema de envios para imagens de encaixe e inici√°-lo nos servidores remotos dos organizadores.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Dbrain</a> usa o mesmo sistema para calcular o resultado de competi√ß√µes precisamente pelas mesmas raz√µes. </p><br><h1 id="klyuchevye-momenty">  Pontos-chave </h1><br><h3 id="komanda">  A equipe </h3><br><img src="https://habrastorage.org/webt/ty/ur/gp/tyurgpqbzb2zl2wimtzri0mnpwk.jpeg"><br><br>  A primeira coisa que √© importante para o sucesso de toda a empresa √© a equipe.  N√£o importa qu√£o bom voc√™ seja (e qu√£o poderoso seja suas patas) - a participa√ß√£o na equipe aumenta muito as chances de sucesso.  A raz√£o √© simples - uma variedade de opini√µes e abordagens, revisando hip√≥teses, a capacidade de paralelizar o trabalho e realizar mais experimentos.  Tudo isso √© extremamente importante na solu√ß√£o de novos problemas que voc√™ precisa enfrentar. <br><p>  Idealmente, seus conhecimentos e habilidades devem estar no mesmo n√≠vel e se complementam.  Por exemplo, este ano, plantei nossa equipe no PyTorch e tive algumas id√©ias iniciais sobre a implementa√ß√£o de um sistema de treinamento de agentes distribu√≠dos. </p><br><p>  Como encontrar uma equipe?  Em primeiro lugar, voc√™ pode se juntar √†s fileiras dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ods</a> e procurar pessoas com a mesma opini√£o.  Em segundo lugar, para os bolsistas da RL h√° uma sala de bate-papo separada em um telegrama - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">clube da RL</a> .  Em terceiro lugar, voc√™ pode fazer um curso maravilhoso com o ShAD - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Practical RL</a> , ap√≥s o qual voc√™ certamente conhecer√° alguns conhecidos. </p><br><p>  No entanto, vale lembrar a pol√≠tica de "submiss√£o - ou n√£o era".  Se voc√™ quiser se unir, primeiro tome sua decis√£o, envie, apare√ßa na tabela de classifica√ß√£o e mostre seu n√≠vel.  Como mostra a pr√°tica, essas equipes s√£o muito mais equilibradas. </p><br><h3 id="motivaciya">  Motiva√ß√£o </h3><br><p>  Como j√° escrevi, se o t√≥pico for ‚Äúseu‚Äù, nada o impedir√°.  Isso significa que a regi√£o n√£o gosta apenas de voc√™, mas a inspira - voc√™ a queima, quer se tornar a melhor. <br>  Conheci a RL h√° quatro anos - durante a passagem do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Berkeley 188x - Introdu√ß√£o √† IA</a> - e ainda n√£o consigo parar de me perguntar sobre o progresso nessa √°rea. </p><br><h3 id="sistematichnost">  Sistem√°tica </h3><br><p>  Terceiro, mas igualmente importante - voc√™ deve ser capaz de fazer o que prometeu, investir na competi√ß√£o todos os dias e apenas ... resolv√™-la.  Todo dia  Nenhum talento inato pode ser comparado com a capacidade de fazer algo, mesmo que um pouco, mas todos os dias.  √â para isso que a motiva√ß√£o ser√° necess√°ria.  Para ter sucesso, recomendo a leitura do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DeepWork</a> e da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AMA ternaus</a> . </p><br><h3 id="time-management">  Gerenciamento de tempo </h3><br><p>  Outra habilidade extremamente importante √© a capacidade de distribuir a for√ßa e usar corretamente o tempo livre.  Combinar trabalho em tempo integral e participa√ß√£o em competi√ß√µes √© uma tarefa n√£o trivial.  O mais importante nessas condi√ß√µes √© n√£o queimar e suportar toda a carga.  Para fazer isso, voc√™ precisa gerenciar adequadamente seu tempo, avaliar sobriamente sua for√ßa e n√£o se esque√ßa de relaxar na hora certa. </p><br><h3 id="overwork">  Excesso de trabalho </h3><br><p>  Na fase final da competi√ß√£o, geralmente surge uma situa√ß√£o em que literalmente em uma semana voc√™ precisa fazer n√£o muito, mas MUITO.  Para o melhor resultado, voc√™ precisa se for√ßar a sentar e dar o √∫ltimo impulso ao cobi√ßado pr√™mio. </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory: prazo ap√≥s prazo</b> <div class="spoiler_text"><p>  Por que, em geral, pode ser necess√°rio reciclar para o benef√≠cio da competi√ß√£o?  A resposta √© bastante simples - transfer√™ncia de prazo.  Nessas competi√ß√µes, os organizadores geralmente n√£o conseguem prever tudo, por isso a maneira mais f√°cil √© dar mais tempo aos participantes.  Este ano, a competi√ß√£o foi prorrogada tr√™s vezes: primeiro por um m√™s, depois por uma semana e no √∫ltimo momento (24 horas antes do prazo) - por mais 2 dias.  E se durante as duas primeiras transfer√™ncias voc√™ apenas precisou organizar o tempo extra corretamente, nos √∫ltimos dois dias voc√™ apenas teve que arar. </p></div></div><br><h3 id="theory">  Teoria </h3><br><img src="https://habrastorage.org/webt/gf/rg/9q/gfrg9ql1ukvjmlbglwcizlfcpto.png"><br><p>  Entre outras coisas, n√£o se esque√ßa da teoria - estar ciente do que est√° acontecendo no campo e ser capaz de observar o relevante.  Por exemplo, para resolver no ano passado, nossa equipe decolou dos seguintes artigos: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O controle cont√≠nuo com o aprendizado por refor√ßo profundo</a> √© um artigo b√°sico sobre o aprendizado por refor√ßo profundo para tarefas com espa√ßo de a√ß√£o cont√≠nuo. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Par√¢metro Noise Space for Exploration</a> - um estudo sobre a adi√ß√£o de ru√≠do aos pesos dos agentes para um melhor estudo do ambiente.  Por experi√™ncia - uma das melhores t√©cnicas de explora√ß√£o em RL. </li></ul><br><p>  Este ano, mais alguns foram adicionados a eles: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Uma perspectiva distributiva do aprendizado por refor√ßo</a> - Um novo olhar sobre as previs√µes de uma poss√≠vel recompensa.  Em vez de simplesmente prever a m√©dia, √© calculada a distribui√ß√£o de recompensas futuras. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O aprendizado de refor√ßo distributivo com regress√£o quant√≠lica</a> √© uma continua√ß√£o do trabalho anterior, mas com a "quantiza√ß√£o" da distribui√ß√£o. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Replay da Experi√™ncia Priorizada Distribu√≠da</a> - trabalhe a partir da dire√ß√£o do aprendizado profundo por refor√ßo em escala.  Sobre como organizar adequadamente a arquitetura do experimento para maximizar o uso dos recursos dispon√≠veis e aumentar a velocidade dos agentes de treinamento. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Gradientes de pol√≠tica determin√≠stica distributiva distribu√≠da</a> - uma combina√ß√£o dos tr√™s artigos anteriores para tarefas com um espa√ßo de a√ß√£o cont√≠nuo. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tratamento de erros de aproxima√ß√£o de fun√ß√µes em m√©todos cr√≠ticos para atores</a> - excelente trabalho para aumentar a robustez dos agentes RL.  Eu recomendo a leitura. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O aprendizado de refor√ßo hier√°rquico com efici√™ncia de dados</a> √© um desenvolvimento de um artigo anterior no campo do aprendizado de refor√ßo hier√°rquico (HRL). </li></ul><br><div class="spoiler">  <b class="spoiler_title">Leitura adicional</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Critico para o ator suave: aprendizado de refor√ßo profundo por entropia m√°xima fora da pol√≠tica com um ator estoc√°stico</a> - os autores propuseram um m√©todo para o treinamento de pol√≠ticas estoc√°sticas com o aprendizado de refor√ßo fora da pol√≠tica.  Gra√ßas a este artigo, tornou-se poss√≠vel formar pol√≠ticos n√£o deterministas, mesmo em tarefas com um espa√ßo de a√ß√£o cont√≠nuo. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">As pol√≠ticas de espa√ßo latente para o aprendizado de refor√ßo hier√°rquico</a> s√£o uma continua√ß√£o de um artigo anterior do HRL com pol√≠ticas estoc√°sticas de v√°rios n√≠veis. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Diversidade √© tudo o que voc√™ precisa: habilidades de aprendizado sem uma fun√ß√£o de recompensa</a> - este artigo cont√©m uma abordagem para aprender muitas pol√≠ticas estoc√°sticas aleat√≥rias de baixo n√≠vel sem nenhuma recompensa do ambiente.  Posteriormente, quando definimos a fun√ß√£o de recompensa, o mais correlacionado ao pr√™mio pode ser usado para ensinar pol√≠tica de alto n√≠vel. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aprendizado e controle de refor√ßo como infer√™ncia probabil√≠stica: tutorial e revis√£o</a> - uma vis√£o geral de todos os tipos de m√©todos de aprendizado de refor√ßo de entropia m√°xima de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sergey Levine</a> . </li></ul><br><p>  Tamb√©m aconselho √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenAI uma sele√ß√£o de artigos</a> sobre aprendizado por refor√ßo e sua <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vers√£o para mendeley</a> .  E se voc√™ estiver interessado no t√≥pico de treinamento por refor√ßo, junte-se aos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documentos do</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">clube</a> e da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RL</a> . </p></div></div><br><h3 id="practice">  Pr√°tica </h3><br><img src="https://habrastorage.org/webt/xp/g7/it/xpg7itebqdpi3cwex33uzrzkidg.jpeg"><br><br>  Conhecer a teoria por si s√≥ n√£o √© suficiente - √© importante poder colocar todas essas abordagens em pr√°tica e estabelecer o sistema de valida√ß√£o correto para avaliar decis√µes.  Por exemplo, este ano descobrimos que nosso agente lida mal com alguns casos regionais apenas 2 dias antes do final da competi√ß√£o.  Por causa disso, n√£o tivemos tempo para consertar completamente nosso modelo e n√£o conseguimos literalmente alguns pontos para o cobi√ßado segundo lugar.  Se descobr√≠ssemos isso mesmo em uma semana - o resultado poderia ser melhor. <br><div class="spoiler">  <b class="spoiler_title">Hist√≥ria legal: epis√≥dio III</b> <div class="spoiler_text"><p>  O pr√™mio m√©dio para 10 epis√≥dios de teste serviu como avalia√ß√£o final da solu√ß√£o. </p><br><img src="https://habrastorage.org/webt/jq/bj/yc/jqbjyctkjettuu2bqd19xcahssk.png"><br><p>  O gr√°fico mostra os resultados do teste do nosso agente: 9 de 10 epis√≥dios, nosso esqueleto correu bem (m√©dia - 9955,66), mas um epis√≥dio ... O epis√≥dio 3 n√£o foi dado a ele (recompensa 9870).  Foi esse erro que levou √† queda da velocidade final para 9947 (-8 pontos). </p></div></div><br><h3 id="udacha">  Boa sorte </h3><br><p>  E finalmente - n√£o se esque√ßa da sorte banal.  N√£o pense que este √© um ponto controverso.  Pelo contr√°rio, um pouco de sorte contribui muito para o trabalho constante: mesmo que a probabilidade de sorte seja de apenas 10%, uma pessoa que tentou participar da competi√ß√£o 100 vezes ter√° muito mais sucesso do que algu√©m que tentou apenas uma vez e abandonou a ideia. </p><br><h1 id="tuda-i-obratno-reshenie-proshlogo-goda--trete-mestohttpswwwcrowdaiorgchallengesnips-2017-learning-to-runwinners">  Ida e volta: decis√£o do ano passado - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">terceiro lugar</a> </h1><br><img src="https://habrastorage.org/webt/mq/lx/i_/mqlxi_alc8pt0acnzwoi8twb8oo.jpeg"><br><br>  No ano passado, nossa equipe - Mikhail Pavlov e eu - participamos das competi√ß√µes NeurIPS pela primeira vez e a principal motiva√ß√£o era simplesmente participar da primeira competi√ß√£o NeurIPS no aprendizado por refor√ßo.  Acabei de terminar o curso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RL pr√°tica</a> no SHAD e queria testar as habilidades adquiridas.  Como resultado, conquistamos um terceiro lugar honroso, perdendo apenas para o nnaisene (Schmidhuber) e a equipe universit√°ria da China.  Naquela √©poca, nossa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">solu√ß√£o</a> era "bastante simples" e baseava-se no DDPG distribu√≠do com par√¢metros de ru√≠do ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publica√ß√£o</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">apresenta√ß√£o em ml</a> . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Trainings</a> ). <br><h1 id="reshenie-etogo-goda--trete-mestohttpswwwcrowdaiorgchallengesnips-2018-ai-for-prosthetics-challengeleaderboards">  A decis√£o deste ano √© o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">terceiro lugar</a> </h1><br><img src="https://habrastorage.org/webt/gf/qq/to/gfqqtoneh51dn47m3f7oicyqixk.jpeg"><br><p>  Houve algumas mudan√ßas este ano.  Em primeiro lugar, n√£o havia desejo de apenas participar desta competi√ß√£o, eu queria venc√™-la.  Em segundo lugar, a composi√ß√£o da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">equipe</a> tamb√©m mudou: Alexey Grinchuk, Anton Pechenko e eu.  Pegue e ganhe - n√£o funcionou, mas novamente conquistamos o 3¬∫ lugar. <br>  Nossa solu√ß√£o ser√° apresentada oficialmente no NeurIPS e agora nos limitaremos a um pequeno n√∫mero de detalhes.  Com base na decis√£o do ano passado e no sucesso do aprendizado de refor√ßo fora da pol√≠tica deste ano (artigos acima), adicionamos v√°rios desenvolvimentos pr√≥prios, sobre os quais falaremos no NeurIPS, e obtivemos o Critic Distributed Quantile Ensemble, com o qual ocupamos o terceiro lugar. </p><br><p>  Todas as nossas pr√°ticas recomendadas - um sistema de aprendizado distribu√≠do, algoritmos etc. ser√£o publicadas e dispon√≠veis no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Catalyst.RL</a> ap√≥s o NeurIPS. </p><br><div class="spoiler">  <b class="spoiler_title">Coolstory: meninos grandes - armas grandes</b> <div class="spoiler_text"><p>  Nossa equipe confiantemente foi para o 1¬∫ lugar durante toda a competi√ß√£o.  No entanto, os grand√µes tinham outros planos - dois grandes jogadores entraram na competi√ß√£o duas semanas antes do final da competi√ß√£o: FireWork (Baidu) e nnaisense (Schmidhuber).  E se n√£o pud√©ssemos fazer nada com o Google chin√™s, ent√£o com a equipe Schmidhuber por um bom tempo conseguimos lutar honestamente pelo segundo lugar, perdendo apenas com uma margem m√≠nima.  Parece-me muito bom para os amantes. </p></div></div><br><h1 id="zachem-eto-vse">  Por que isso √© tudo? </h1><br><ul><li>  Comunica√ß√£o.  Os principais pesquisadores v√™m √† confer√™ncia com quem voc√™ pode conversar ao vivo, o que n√£o fornecer√° nenhuma correspond√™ncia por e-mail. </li><li>  Publica√ß√£o  Se a solu√ß√£o receber o pr√™mio, a equipe ser√° convidada para a confer√™ncia (ou talvez mais de uma) para apresentar sua decis√£o e publicar o artigo. </li><li>  Oferta de emprego e doutorado.  A publica√ß√£o e o pr√™mio em uma confer√™ncia desse tipo aumentam significativamente suas chances de conseguir uma posi√ß√£o em empresas l√≠deres como OpenAI, DeepMind, Google, Facebook, Microsoft. </li><li>  Valor do mundo real.  O NeurIPS √© realizado para solucionar problemas prementes do mundo acad√™mico e real.  Voc√™ pode ter certeza de que os resultados n√£o ir√£o para a mesa, mas ser√£o realmente procurados e ajudar√£o a melhorar o mundo. </li><li>  Drive  Resolver tais concursos ... apenas interessante.  Em uma competi√ß√£o, voc√™ pode ter muitas id√©ias novas, testar diferentes abordagens - apenas para ser o melhor.  E vamos ser honestos, quando mais voc√™ pode dirigir esqueletos, jogar e tudo isso com um olhar s√©rio e pelo bem da ci√™ncia? </li></ul><br><div class="spoiler">  <b class="spoiler_title">Hist√≥ria legal: visto e RL</b> <div class="spoiler_text"><p>  Eu n√£o recomendo tentar explicar ao americano que voc√™ est√° indo para a confer√™ncia, enquanto treina esqueletos virtuais para executar simula√ß√µes.  Basta ir √† confer√™ncia com uma palestra. </p></div></div><br><h1 id="itogi">  Sum√°rio </h1><br><p>  Participar do NeurIPS √© uma experi√™ncia dif√≠cil de superestimar.  N√£o tenha medo de t√≠tulos de destaque: basta se recompor e come√ßar a decidir. </p><br><p>  E v√° para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Catalyst.RL</a> , ent√£o o que. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt430712/">https://habr.com/ru/post/pt430712/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt430702/index.html">Treinamento muito estranho</a></li>
<li><a href="../pt430704/index.html">Como as tecnologias de intelig√™ncia artificial ajudam a Aviasales a crescer: sete exemplos</a></li>
<li><a href="../pt430706/index.html">Nova teoria da evolu√ß√£o</a></li>
<li><a href="../pt430708/index.html">Tic Tac Toe ‚ÄúSem Fronteiras‚Äù</a></li>
<li><a href="../pt430710/index.html">O que fazer se a Black Friday for amanh√£ e seus servidores n√£o estiverem prontos</a></li>
<li><a href="../pt430714/index.html">VMware compra Heptio - o que isso significa para o Kubernetes</a></li>
<li><a href="../pt430718/index.html">Para quais objetos vale a pena usar a vigil√¢ncia por v√≠deo na nuvem?</a></li>
<li><a href="../pt430720/index.html">Intel RealSense D435i: pequena atualiza√ß√£o e breve digress√£o hist√≥rica</a></li>
<li><a href="../pt430722/index.html">Desempenho do PHP: planejamento, cria√ß√£o de perfil, otimiza√ß√£o</a></li>
<li><a href="../pt430724/index.html">DEFCON 21. A confer√™ncia DNS pode ser perigosa para sua sa√∫de. Parte 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôáüèæ ü§ó üë©üèø‚Äçü§ù‚Äçüë©üèΩ Introdu√ß√£o √†s redes neurais convolucionais üë®‚Äçüîß üëê üà¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O curso completo em russo pode ser encontrado neste link . 
 O curso de ingl√™s original est√° dispon√≠vel neste link . 


 Novas palestras s√£o agendadas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Introdu√ß√£o √†s redes neurais convolucionais</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454986/"> O curso completo em russo pode ser encontrado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste link</a> . <br>  O curso de ingl√™s original est√° dispon√≠vel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste link</a> . <br><br><img src="https://habrastorage.org/webt/uh/pm/jt/uhpmjticdnfsyigvpgkhb0t-a4s.png"><br>  <i>Novas palestras s√£o agendadas a cada 2-3 dias.</i> <br><a name="habracut"></a><br><h2>  Entrevista com Sebastian </h2><br>  - Ent√£o, estamos novamente com Sebastian na terceira parte deste curso.  Sebastian, eu sei que voc√™ fez muito desenvolvimento usando redes neurais convolucionais.  Voc√™ pode nos contar um pouco mais sobre essas redes e quais s√£o elas?  Estou certo de que os alunos do nosso curso ouvir√£o com menos interesse, porque nesta parte eles ter√£o que desenvolver a rede neural convolucional. <br>  √ìtimo!  Assim, as redes neurais convolucionais s√£o uma excelente maneira de estruturar a rede, construindo a chamada invari√¢ncia (aloca√ß√£o de recursos imut√°veis).  Por exemplo, considere a id√©ia de reconhecimento de padr√µes no palco ou na fotografia, voc√™ quer entender se Sebastian est√° ou n√£o representado.  N√£o importa em que parte da fotografia eu estou, onde minha cabe√ßa est√° localizada - no centro da fotografia ou no canto.  Reconhecimento da minha cabe√ßa, meu rosto deve ocorrer independentemente de onde eles est√£o localizados na imagem.  Isso √© invari√¢ncia, variabilidade de localiza√ß√£o, que √© realizada por redes neurais convolucionais. <br>  Muito interessante!  Voc√™ pode nos dizer as principais tarefas nas quais as redes neurais convolucionais s√£o usadas? <br>  - As redes neurais convolucionais s√£o bastante usadas quando se trabalha com √°udio e v√≠deo, incluindo imagens m√©dicas.  Eles tamb√©m s√£o usados ‚Äã‚Äãem tecnologias de linguagem, onde especialistas usam aprendizado profundo para entender e reproduzir constru√ß√µes de linguagem.  De fato, existem muitas aplica√ß√µes para essa tecnologia, eu diria mesmo que s√£o infinitas!  Sua tecnologia pode ser usada em finan√ßas e em outras √°reas. <br>  "Eu usei redes neurais convolucionais para analisar imagens de sat√©lite." <br>  √ìtimo!  A tarefa padr√£o! <br>  - Em sua opini√£o, podemos considerar as redes neurais convolucionais como a √∫ltima e mais avan√ßada ferramenta no desenvolvimento da aprendizagem profunda? <br>  Ha!  Eu j√° aprendi a nunca dizer nunca.  Sempre haver√° algo novo e incr√≠vel! <br>  "Ent√£o ainda temos trabalho a fazer?"  :) <br>  - Haver√° trabalho suficiente! <br>  Excelente!  Neste curso, estamos apenas ensinando futuros pioneiros em aprendizado de m√°quina.  Voc√™ deseja seus alunos antes que eles comecem a construir sua primeira rede neural convolucional? <br>  - Aqui est√° um fato interessante para voc√™.  As redes neurais convolucionais foram inventadas em 1989, e isso faz muito tempo!  A maioria de voc√™s nem nasceu naquela √©poca, o que significa que n√£o √© o g√™nio do algoritmo que importa, mas os dados nos quais esse algoritmo opera.  Vivemos em um mundo onde existem muitos dados para analisar e procurar padr√µes.  Temos a capacidade de emular as fun√ß√µes da mente humana usando essa enorme quantidade de dados.  Quando voc√™ trabalha em redes neurais convolucionais, tente se concentrar em encontrar os dados corretos e aplic√°-los - veja o que acontece e, √†s vezes, pode ser uma verdadeira m√°gica, como foi o caso em nosso caso quando est√°vamos resolvendo o problema de detectar o c√¢ncer de pele. <br>  √ìtimo!  Bem, vamos finalmente √† m√°gica! <br><br><h2>  1. Introdu√ß√£o </h2><br>  Na √∫ltima li√ß√£o, aprendemos como desenvolver redes neurais profundas capazes de classificar imagens de elementos de vestu√°rio a partir do conjunto de dados Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br>  Os resultados obtidos durante o trabalho na rede neural foram impressionantes - 88% de precis√£o na classifica√ß√£o.  E isso est√° em algumas linhas de c√≥digo (sem levar em conta o c√≥digo para a constru√ß√£o de gr√°ficos e imagens)! <br><br><pre><code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre> <br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><pre> <code class="python hljs">NUM_EXAMPLES = <span class="hljs-number"><span class="hljs-number">60000</span></span> train_dataset = train_dataset.repeat().shuffle(NUM_EXAMPLES).batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) test_dataset = test_dataset.batch(<span class="hljs-number"><span class="hljs-number">32</span></span>)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/<span class="hljs-number"><span class="hljs-number">32</span></span>))</code> </pre><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/<span class="hljs-number"><span class="hljs-number">32</span></span>)) print(<span class="hljs-string"><span class="hljs-string">': '</span></span>, test_accuracy)</code> </pre><br> <code>: 0.8782 <br></code> <br>  Tamb√©m experimentamos o efeito do n√∫mero de neur√¥nios em camadas ocultas e o n√∫mero de itera√ß√µes de treinamento na precis√£o do modelo.  Mas como tornamos esse modelo ainda melhor e mais preciso?  Uma maneira de conseguir isso √© usar redes neurais convolucionais, abreviada para SNA.  O SNA mostra maior precis√£o na resolu√ß√£o dos problemas de classifica√ß√£o de imagens do que as redes neurais padr√£o totalmente conectadas que encontramos nas classes anteriores.  √â por esse motivo que o SNA se tornou t√£o popular e foi gra√ßas a eles que se tornou poss√≠vel uma inova√ß√£o tecnol√≥gica no campo da vis√£o de m√°quina. <br><br>  Nesta li√ß√£o, aprenderemos como √© f√°cil desenvolver um classificador SNA do zero usando o TensorFlow e o Keras.  Usaremos o mesmo conjunto de dados do Fashion MNIST que usamos na li√ß√£o anterior.  No final desta li√ß√£o, comparamos a precis√£o da classifica√ß√£o dos elementos de vestu√°rio da rede neural anterior com a rede neural convolucional desta li√ß√£o. <br><br>  Antes de mergulhar no desenvolvimento, vale a pena aprofundar um pouco o princ√≠pio de funcionamento das redes neurais convolucionais. <br><br>  Dois conceitos b√°sicos em redes neurais convolucionais: <br><br><ul><li>  convolu√ß√£o </li><li>  opera√ß√£o de subamostragem (pooling, max pooling) </li></ul><br><br>  Vamos dar uma olhada neles. <br><br><h2>  Convolu√ß√£o </h2><br>  Nesta parte da li√ß√£o, aprenderemos uma t√©cnica chamada convolu√ß√£o.  Vamos ver como isso funciona. <br><br>  Tire uma imagem em tons de cinza e, por exemplo, imagine que suas dimens√µes s√£o 6 px de altura e 6 px de largura. <br><br><img src="https://habrastorage.org/webt/jd/rh/6y/jdrh6y3zzszxmhixrfnaxmndr-m.png"><br><br>  Nosso computador interpreta a imagem como uma matriz bidimensional de pixels.  Como nossa imagem est√° em tons de cinza, o valor de cada pixel estar√° no intervalo de 0 a 255. 0 - preto, 255 - branco. <br><br>  Na imagem abaixo, vemos uma representa√ß√£o da imagem 6px x 6px e os valores de pixel correspondentes: <br><br><img src="https://habrastorage.org/webt/qz/mw/jd/qzmwjdfjxnu88pat92ciearc4ng.png"><br><br>  Como voc√™ j√° sabe, antes de trabalhar com imagens, √© necess√°rio normalizar os valores de pixel - traga os valores para um intervalo de 0 a 1. No entanto, neste exemplo, para facilitar a explica√ß√£o, salvaremos os valores de pixel da imagem e n√£o os normalizaremos. <br><br>  A ess√™ncia da convolu√ß√£o √© criar outro conjunto de valores, chamado de kernel ou filtro.  Um exemplo pode ser visto na imagem abaixo - uma matriz 3 x 3: <br><br><img src="https://habrastorage.org/webt/16/8x/g0/168xg0hysoiy8pwlygw-nxmw-ck.png"><br><br>  Ent√£o podemos digitalizar nossa imagem usando o kernel.  As dimens√µes da nossa imagem s√£o 6x6px e os n√∫cleos s√£o 3x3px.  A camada convolucional √© aplicada ao n√∫cleo e a cada se√ß√£o da imagem de entrada. <br><br>  Vamos imaginar que queremos convolver sobre um pixel com um valor de 25 (3 linhas, 3 colunas) e a primeira coisa que precisa ser feita √© centralizar o n√∫cleo sobre esse pixel: <br><br><img src="https://habrastorage.org/webt/dt/qs/5x/dtqs5xle8lhrv0h504wbk3gzgnw.png"><br><br>  Na imagem, o posicionamento do n√∫cleo √© destacado em amarelo.  Agora, examinaremos apenas os valores de pixel que est√£o em nosso ret√¢ngulo amarelo, cujos tamanhos correspondem aos tamanhos do nosso n√∫cleo de convolu√ß√£o. <br><br>  Agora pegamos os valores de pixel da imagem e do kernel, multiplicamos cada pixel da imagem pelo pixel correspondente do kernel e adicionamos todos os valores do produto e atribu√≠mos o valor de pixel resultante √† nova imagem. <br><br><img src="https://habrastorage.org/webt/tz/xe/oc/tzxeocatpow2ytacpikwfpj--w8.png"><br><br><img src="https://habrastorage.org/webt/eu/ty/tj/eutytjlyn4js82ry704lkaz6gpq.png"><br><br><img src="https://habrastorage.org/webt/x5/3k/hs/x53khs1exvxwdbmn2mnxihg2wxa.png"><br><br>  Realizamos uma opera√ß√£o semelhante com todos os pixels em nossa imagem.  Mas o que deveria acontecer com os pixels nas bordas? <br><br><img src="https://habrastorage.org/webt/2h/af/nf/2hafnfev-ft4bioova_jjepqby4.png"><br><br>  Existem v√°rias solu√ß√µes.  Primeiramente, podemos simplesmente ignorar esses pixels, mas, neste caso, perderemos informa√ß√µes sobre a imagem, que podem ser significativas, e a imagem minimizada se tornar√° menor que a original.  Em segundo lugar, podemos simplesmente "matar", com zero valor, os pixels cujos valores principais est√£o al√©m do escopo da imagem.  O processo √© chamado alinhamento. <br><br><img src="https://habrastorage.org/webt/fc/wa/1s/fcwa1sx3ekaufxf0zzstuzzk7bo.png"><br><br>  Agora que fizemos o alinhamento com valores de zero pixel, podemos calcular o valor do pixel final na imagem minimizada como antes. <br><br>  Uma convolu√ß√£o √© o processo de aplica√ß√£o de um n√∫cleo (filtro) a cada parte da imagem de entrada; por analogia com uma camada totalmente conectada (camada densa), veremos que a convolu√ß√£o √© a mesma camada em Keras. <br><br>  Agora, vejamos o segundo conceito de redes neurais convolucionais - a opera√ß√£o de subamostragem (pooling, max-pooling). <br><br><h2>  Opera√ß√£o de subamostragem (pool, max-pooling) </h2><br>  Agora, consideraremos o segundo conceito fundamental subjacente √†s redes neurais convolucionais - a opera√ß√£o de subamostragem (pooling, max-pooling).  Em palavras simples, uma opera√ß√£o de subamostragem √© o processo de compactar (reduzir o tamanho) de uma imagem adicionando os valores dos blocos de pixels.  Vamos ver como isso funciona em um exemplo concreto. <br><br><img src="https://habrastorage.org/webt/ya/d4/31/yad431do5fnnuwenxqlv7sxkq2g.png"><br><br>  Para executar a opera√ß√£o de subamostragem, precisamos decidir sobre dois componentes desse processo - o tamanho da amostra (o tamanho da grade retangular) e o tamanho da etapa.  Neste exemplo, usaremos uma grade retangular 3x3 e a etapa 3. A etapa determina o n√∫mero de pixels pelos quais a grade retangular deve ser deslocada ao executar a opera√ß√£o de subamostragem. <br><br>  Depois de decidirmos o tamanho da grade e o tamanho da etapa, precisamos encontrar o valor m√°ximo de pixel que cai na grade selecionada.  No exemplo acima, os valores 1, 0, 4, 8, 2, 5, 20, 13, 25 caem na grade.O valor m√°ximo √© 25. Esse valor √© "transferido" para a nova imagem.  A grade √© deslocada 3 pixels para a direita e o processo de sele√ß√£o do valor m√°ximo e transfer√™ncia para uma nova imagem √© repetido. <br><br><img src="https://habrastorage.org/webt/ht/o0/ef/hto0efftnhidlrtascm-p3gqb_m.png"><br><br>  Como resultado, uma imagem menor ser√° obtida em compara√ß√£o com a imagem de entrada original.  No nosso exemplo, foi obtida uma imagem com metade do tamanho da imagem original.  O tamanho da imagem final varia dependendo da escolha do tamanho da grade retangular e do tamanho da etapa. <br><br>  Vamos ver como isso funcionar√° no Python! <br><br><h2>  Sum√°rio </h2><br>  Familiarizamos-nos com conceitos como convolu√ß√£o e opera√ß√£o de pool m√°ximo. <br><br>  Convolu√ß√£o √© o processo de aplica√ß√£o de um filtro ("n√∫cleo") em uma imagem.  A opera√ß√£o de subamostragem por valor m√°ximo √© o processo de redu√ß√£o do tamanho de uma imagem combinando um grupo de pixels em um √∫nico valor m√°ximo desse grupo. <br><br>  Como veremos na parte pr√°tica, a camada convolucional pode ser adicionada √† rede neural usando a camada <code>Conv2D</code> em Keras.  Essa camada √© semelhante √† camada Densa e cont√©m pesos e compensa√ß√µes que passam por otimiza√ß√£o (sele√ß√£o).  <code>Conv2D</code> camada <code>Conv2D</code> tamb√©m cont√©m filtros ("kernels"), cujos valores tamb√©m s√£o otimizados.  Portanto, na camada <code>Conv2D</code> , os valores dentro da matriz de filtro s√£o as vari√°veis ‚Äã‚Äãque sofrem otimiza√ß√£o. <br><br>  Alguns termos que conseguimos encontrar: <br><br><ul><li>  <b>SNS</b> - redes neurais convolucionais.  Uma rede neural que cont√©m pelo menos uma camada convolucional.  Um SNA t√≠pico cont√©m outras camadas, como camadas de amostra e totalmente conectadas. </li><li>  <b>Convolu√ß√£o</b> √© o processo de aplica√ß√£o de um filtro ("n√∫cleo") em uma imagem. </li><li>  <b>Um filtro (n√∫cleo)</b> √© uma matriz de tamanho menor que os dados de entrada, destinada √† convers√£o de dados de entrada em blocos. </li><li>  <b>Alinhamento</b> √© o processo de adicionar, na maioria das vezes zero valores, √†s bordas de uma imagem. </li><li>  <b>A opera√ß√£o de subamostragem</b> √© o processo de redu√ß√£o do tamanho de uma imagem atrav√©s da amostragem.  Existem v√°rios tipos de camadas de subamostragem, por exemplo, uma camada de subamostragem m√©dia (amostragem de um valor m√©dio); no entanto, uma subamostragem pelo valor m√°ximo √© mais frequentemente usada. </li><li>  <b>A subamostragem pelo valor m√°ximo</b> √© o processo de subamostragem, durante o qual muitos valores s√£o convertidos em um √∫nico valor - o m√°ximo entre a amostragem. </li><li>  <b>Etapa</b> - o n√∫mero de pixels de deslocamento pelo filtro (n√∫cleo) na imagem. </li><li>  <b>Amostragem (downsampling)</b> - o processo de redu√ß√£o do tamanho da imagem. </li></ul><br><h2>  CoLab: classifica√ß√£o de elementos de vestu√°rio Fashion MNIST usando uma rede neural convolucional </h2><br>  Est√°vamos circulados em torno de um dedo!  Faz sentido executar essa parte pr√°tica somente ap√≥s a conclus√£o da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">parte anterior</a> - todo o c√≥digo, exceto um bloco, permanece o mesmo.  A estrutura de nossa rede neural est√° mudando, e essas s√£o quatro linhas adicionais para camadas neurais convolucionais e camadas de subamostragem no valor m√°ximo (pool m√°ximo). <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=tf.nn.relu, input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), strides=<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=tf.nn.relu), tf.keras.layers.MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), strides=<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br>  Todas as explica√ß√µes detalhadas de como trabalhar, elas prometem nos dar na pr√≥xima parte - 4 partes. <br><br>  Ah sim.  A precis√£o do modelo na fase de treinamento tornou-se igual a 97% (o modelo ‚Äútreinado‚Äù nas <code>epochs=10</code> ) e, ao executar o conjunto de dados para os testes, mostrou exatamente 91%.  Um aumento not√°vel na precis√£o em rela√ß√£o √† arquitetura anterior, onde usamos apenas camadas totalmente conectadas - 88%. <br><br><h2>  Sum√°rio </h2><br>  Nesta parte da li√ß√£o, estudamos um novo tipo de rede neural - rede neural convolucional.  N√≥s nos familiarizamos com termos como ‚Äúconvolu√ß√£o‚Äù e ‚Äúopera√ß√£o de pool m√°ximo‚Äù, desenvolvemos e treinamos uma rede neural convolucional a partir do zero.  Como resultado, vimos que nossa rede neural convolucional produz mais precis√£o do que a rede neural que desenvolvemos na √∫ltima li√ß√£o. <br><br>  Nota do autor da tradu√ß√£o. <br><br>  O curso √© chamado "Introdu√ß√£o √† aprendizagem profunda usando o TensorFlow", portanto, n√£o vamos reclamar da falta de explica√ß√µes detalhadas do princ√≠pio das redes neurais convolucionais (camadas) - os pr√≥ximos dois artigos ser√£o sobre o princ√≠pio de opera√ß√£o da rede neural convolucional e sua estrutura interna (os artigos n√£o est√£o relacionados ao curso, mas foram recomendados pelos participantes do StackOverflow para uma melhor compreens√£o do que est√° acontecendo). <br><br>  ... e call to action padr√£o - inscreva-se, coloque um plus e compartilhe :) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Telegram</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt454986/">https://habr.com/ru/post/pt454986/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt454974/index.html">Lockheed Martin patenteia impress√£o 3D com diamante</a></li>
<li><a href="../pt454976/index.html">Max Patrol 8. Vis√£o geral da ferramenta de gerenciamento de vulnerabilidades</a></li>
<li><a href="../pt454978/index.html">Um bug no Linux 5.1 levou √† perda de dados - um patch de corre√ß√£o j√° foi lan√ßado</a></li>
<li><a href="../pt454980/index.html">O que havia no primeiro iPod: vinte √°lbuns que Steve Jobs escolheu em 2001</a></li>
<li><a href="../pt454982/index.html">Como colocamos a amostragem no SIBUR em novas faixas</a></li>
<li><a href="../pt454990/index.html">‚Äú√â aconselh√°vel que voc√™ tenha um gato‚Äù - como uma startup pode atirar no Product Hunt</a></li>
<li><a href="../pt454994/index.html">Quais s√£o as vantagens do carregamento sem fio e por que o futuro est√° por tr√°s disso? Experi√™ncia pessoal para 2019</a></li>
<li><a href="../pt454996/index.html">Cosmonaut Training Center com o nome de Yu.A. Gagarin e Roscosmos come√ßaram o recrutamento aberto para a equipe de cosmonautas</a></li>
<li><a href="../pt454998/index.html">Julia e computa√ß√£o paralela</a></li>
<li><a href="../pt455000/index.html">Mudan√ßa cuidadosa para a Holanda com sua esposa. Parte 3: trabalho, colegas e outras formas de vida</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
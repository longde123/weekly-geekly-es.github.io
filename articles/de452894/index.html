<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå∫ ‚úÇÔ∏è üë®üèº‚Äç‚úàÔ∏è Face Anti-Spoofing oder technologisch einen Betr√ºger von tausend Gesichtern erkennen ‚ôìÔ∏è üë©üèΩ‚Äçüîß üëë</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die biometrische Identifizierung einer Person ist eine der √§ltesten Ideen zur Erkennung von Personen, die sie im Allgemeinen technisch umzusetzen vers...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Face Anti-Spoofing oder technologisch einen Betr√ºger von tausend Gesichtern erkennen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/452894/"><p>  Die biometrische Identifizierung einer Person ist eine der √§ltesten Ideen zur Erkennung von Personen, die sie im Allgemeinen technisch umzusetzen versuchten.  Passw√∂rter k√∂nnen gestohlen, ausspioniert, vergessen, Schl√ºssel gef√§lscht werden.  Aber die einzigartigen Eigenschaften der Person selbst sind viel schwieriger zu f√§lschen und zu verlieren.  Dies k√∂nnen Fingerabdr√ºcke, Stimme, Zeichnen der Gef√§√üe der Netzhaut, Gang und mehr sein. </p><br><p><img src="https://habrastorage.org/webt/h4/wd/zr/h4wdzrqvlnvfy8da0k3cn5589hg.jpeg"></p><br><p>  Nat√ºrlich versuchen biometrische Systeme zu t√§uschen!  Dar√ºber werden wir heute sprechen.  Wie Angreifer versuchen, Gesichtserkennungssysteme zu umgehen, indem sie sich als eine andere Person ausgeben, und wie dies erkannt werden kann. </p><a name="habracut"></a><br><p>  Sie k√∂nnen hier eine Videoversion dieser Geschichte ansehen, und diejenigen, die lieber lesen als ansehen, laden Sie ein, fortzufahren </p><br><p>  Nach den Vorstellungen von Hollywood-Regisseuren und Science-Fiction-Autoren ist es recht einfach, die biometrische Identifizierung zu t√§uschen.  Es ist nur notwendig, dem System die ‚Äûerforderlichen Teile‚Äú des realen Benutzers entweder einzeln oder als Geisel zu pr√§sentieren.  Oder Sie k√∂nnen die Maske einer anderen Person auf sich selbst setzen, z. B. mit einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">physischen Transplantationsmaske</a> oder im Allgemeinen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mit falschen genetischen Zeichen</a> </p><br><p>  Im wirklichen Leben versuchen Angreifer auch, sich als jemand anderes vorzustellen.  Rauben Sie beispielsweise eine Bank aus, indem Sie eine schwarze M√§nnermaske tragen, wie im Bild unten dargestellt. </p><br><p><img src="https://habrastorage.org/webt/pl/vz/67/plvz67jfgazkigzqsdhkko62ego.png"></p><br><p>  Die Gesichtserkennung scheint ein vielversprechender Bereich f√ºr den Einsatz im Mobilbereich zu sein.  Wenn jeder schon lange daran gew√∂hnt ist, Fingerabdr√ºcke zu verwenden, und sich die Sprachtechnologie allm√§hlich und ziemlich vorhersehbar entwickelt, hat sich die Situation mit der Identifizierung anhand des Gesichts eher ungew√∂hnlich entwickelt und verdient einen kleinen Exkurs in die Geschichte des Problems. </p><br><h2 id="kak-vse-nachinalos-ili-iz-fantastiki-v-realnost">  Wie alles begann oder von der Fiktion zur Realit√§t </h2><br><p>  Die heutigen Erkennungssysteme weisen eine enorme Genauigkeit auf.  Mit dem Aufkommen gro√üer Datenmengen und komplexer Architekturen wurde es m√∂glich, eine Gesichtserkennungsgenauigkeit von bis zu 0,000001 (ein Fehler pro Million!) Zu erreichen. Sie sind jetzt f√ºr die √úbertragung auf mobile Plattformen geeignet.  Der Engpass war ihre Verwundbarkeit. </p><br><p>  Um sich in unserer technischen Realit√§t und nicht im Film als eine andere Person auszugeben, werden am h√§ufigsten Masken verwendet.  Sie versuchen auch, das Computersystem zu t√§uschen, indem sie jemand anderem anstelle ihres Gesichts pr√§sentieren.  Masken k√∂nnen von v√∂llig anderer Qualit√§t sein, vom Foto einer anderen Person, die vor dem auf dem Drucker gedruckten Gesicht gedruckt wird, bis zu sehr komplexen dreidimensionalen Masken mit Erw√§rmung.  Masken k√∂nnen separat in Form eines Blattes oder Bildschirms pr√§sentiert oder am Kopf getragen werden. </p><br><p>  Viel Aufmerksamkeit wurde auf das Thema gelenkt, als erfolgreich versucht wurde, das Face ID-System auf dem iPhone X mit einer ziemlich komplizierten Maske aus Steinpulver mit speziellen Eins√§tzen um die Augen zu t√§uschen, die die W√§rme eines lebenden Gesichts mithilfe von Infrarotstrahlung imitieren. </p><br><p><img src="https://habrastorage.org/webt/xl/kq/pr/xlkqprysss0ce2arbqm0sw_xbpo.png"></p><br><p>  Es wird vermutet, dass mit einer solchen Maske die Gesichtserkennung auf dem iPhone X get√§uscht werden konnte. Video und Text finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> </p><br><p>  Das Vorhandensein solcher Sicherheitsl√ºcken ist f√ºr Banken oder staatliche Systeme sehr gef√§hrlich, um einen Benutzer von Angesicht zu Angesicht zu authentifizieren, wenn das Eindringen eines Angreifers erhebliche Verluste mit sich bringt. </p><br><h2 id="terminologiya">  Terminologie </h2><br><p>  Das Forschungsgebiet des Gesichts-Anti-Spoofing ist recht neu und kann sich noch nicht einmal der vorherrschenden Terminologie r√ºhmen. </p><br><p>  Lassen Sie uns zustimmen, einen Versuch zu nennen, das Identifikationssystem zu t√§uschen, indem wir ihm einen gef√§lschten biometrischen Parameter (in diesem Fall eine Person) als <strong>Spoofing-Angriff pr√§sentieren</strong> . </p><br><p>  Dementsprechend wird eine Reihe von Schutzma√ünahmen zur Bek√§mpfung einer solchen T√§uschung als <strong>Anti-Spoofing bezeichnet</strong> .  Es kann in Form einer Vielzahl von Technologien und Algorithmen implementiert werden, die in den F√∂rderer eines Identifikationssystems eingebaut sind. </p><br><p>  Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ISO</a> bietet eine leicht erweiterte Terminologie mit Begriffen wie <strong>Pr√§sentationsangriff</strong> - Versuche, das System dazu zu bringen, den Benutzer falsch zu identifizieren oder ihm zu erm√∂glichen, die Identifizierung durch Demonstration eines Bildes, eines aufgezeichneten Videos usw. zu vermeiden.  <strong>Normal (Bona Fide)</strong> - entspricht dem √ºblichen Algorithmus des Systems, dh alles, was KEIN Angriff ist.  <strong>Pr√§sentationsangriffsinstrument</strong> bedeutet ein Angriffsmittel, zum Beispiel einen k√ºnstlich hergestellten K√∂rperteil.  Und schlie√ülich die <strong>Erkennung von Pr√§sentationsangriffen</strong> - automatisierte Mittel zur Erkennung solcher Angriffe.  Die Standards selbst befinden sich jedoch noch in der Entwicklung, sodass es unm√∂glich ist, √ºber etablierte Konzepte zu sprechen.  Die russische Terminologie fehlt fast vollst√§ndig. </p><br><p>  Um die Qualit√§t der Arbeit zu bestimmen, verwenden Systeme h√§ufig die <strong>HTER-</strong> Metrik (Half-Total Error Rate - die H√§lfte des Gesamtfehlers), die als Summe der Koeffizienten von f√§lschlicherweise zul√§ssigen Identifikationen (FAR - False Acceptance Rate) und irrt√ºmlich verbotenen Identifikationen (FRR - False Rejection Rate) berechnet wird in zwei H√§lften. <br>  HTER = (FAR + FRR) / 2 </p><br><p>  Es ist erw√§hnenswert, dass in biometrischen Systemen FAR normalerweise die gr√∂√üte Aufmerksamkeit geschenkt wird, um alles zu tun, um zu verhindern, dass ein Angreifer in das System eindringt.  Und sie machen hier gute Fortschritte (erinnern Sie sich an das Millionstel vom Anfang des Artikels?). Die Kehrseite ist die unvermeidliche Zunahme der FRR - die Anzahl der normalen Benutzer, die f√§lschlicherweise als Eindringlinge eingestuft werden.  Wenn dies f√ºr Staat, Verteidigung und andere √§hnliche Systeme geopfert werden kann, reagieren mobile Technologien, die mit ihrer enormen Gr√∂√üe, einer Vielzahl von Teilnehmerger√§ten und im Allgemeinen auf Benutzerperspektiven ausgerichteten Ger√§ten arbeiten, sehr empfindlich auf Faktoren, die dazu f√ºhren k√∂nnen, dass Benutzer Dienste ablehnen.  Wenn Sie die Anzahl der nach der zehnten Verweigerung der Identifizierung in Folge gegen die Wand geschlagenen Telefone verringern m√∂chten, sollten Sie auf FRR achten! </p><br><h2 id="vidy-atak-obmanyvaem-sistemu">  Arten von Angriffen.  Cheat-System </h2><br><p><img src="https://habrastorage.org/webt/dt/jx/lp/dtjxlptnxcphiicevd6lbhlzzpa.png"></p><br><p>  Lassen Sie uns endlich genau herausfinden, wie die Angreifer das Erkennungssystem betr√ºgen und wie dies bek√§mpft werden kann. </p><br><p>  Die beliebtesten Mittel zum Betr√ºgen sind Masken.  Es gibt nichts Offensichtlicheres, als die Maske einer anderen Person aufzusetzen und Ihr Gesicht einem Identifikationssystem zu pr√§sentieren (oft als Maskenangriff bezeichnet). </p><br><p><img src="https://habrastorage.org/webt/q2/tr/nl/q2trnl3zhhuftbggl3vx-sfqoyw.png"></p><br><p>  Sie k√∂nnen auch ein Foto von sich selbst oder einer anderen Person auf ein Blatt Papier drucken und zur Kamera bringen (nennen wir diese Art von Angriff Gedruckte Attacke). </p><br><p><img src="https://habrastorage.org/webt/f9/g7/ds/f9g7dsc81eiffu9srctasf2udcm.png"></p><br><p>  Etwas komplizierter ist der Wiederholungsangriff, wenn dem System der Bildschirm eines anderen Ger√§ts angezeigt wird, auf dem ein zuvor aufgenommenes Video mit einer anderen Person abgespielt wird.  Die Komplexit√§t der Ausf√ºhrung wird durch die hohe Effizienz eines solchen Angriffs kompensiert, da Steuerungssysteme h√§ufig Zeichen verwenden, die auf der Analyse von Zeitsequenzen basieren, z. B. Verfolgen von Blinzeln, Mikrobewegungen des Kopfes, Vorhandensein von Gesichtsausdr√ºcken, Atmung usw.  All dies kann leicht auf Video reproduziert werden. </p><br><p><img src="https://habrastorage.org/webt/de/dd/vj/deddvj6xvnwbv6dpbryxphjwaa8.png"></p><br><p>  Beide Arten von Angriffen weisen eine Reihe charakteristischer Merkmale auf, die es erm√∂glichen, sie zu erkennen und so einen Tablet-Bildschirm oder ein Blatt Papier von einer realen Person zu unterscheiden. </p><br><p>  Wir fassen die charakteristischen Merkmale, mit denen wir diese beiden Arten von Angriffen identifizieren k√∂nnen, in einer Tabelle zusammen: </p><br><div class="scrollable-table"><table><thead><tr><th>  <strong>Gedruckter Angriff</strong> </th><th>  <strong>Wiederholungsangriff</strong> </th></tr></thead><tbody><tr><td>  Verminderung der Texturqualit√§t des Bildes beim Drucken </td><td>  Moire </td></tr><tr><td>  Artefakte der Halbton√ºbertragung beim Drucken auf einem Drucker </td><td>  Reflexionen (Highlights) </td></tr><tr><td>  Mechanische Druckartefakte (horizontale Linien) </td><td>  Flaches Bild (mangelnde Tiefe) </td></tr><tr><td>  Fehlende lokale Bewegungen (z. B. Blinken) </td><td>  Bildr√§nder k√∂nnen sichtbar sein. </td></tr><tr><td>  Bildr√§nder k√∂nnen sichtbar sein. </td><td></td></tr></tbody></table></div><br><h2 id="algoritmy-obnaruzheniya-atak-staraya-dobraya-klassika">  Angriffserkennungsalgorithmen.  Guter alter Klassiker </h2><br><p><img src="https://habrastorage.org/webt/1r/n8/-e/1rn8-elrfhm1q0ud9q4jbaukidq.png"></p><br><p>  Einer der √§ltesten Ans√§tze (2007, 2008) basiert auf der Erkennung menschlicher Blinzel durch Analyse des Bildes mit einer Maske.  Der Punkt ist, eine Art bin√§ren Klassifikator zu erstellen, mit dem Sie Bilder mit offenen und geschlossenen Augen in einer Folge von Frames ausw√§hlen k√∂nnen.  Dies kann eine Analyse des Videostreams unter Verwendung der Identifizierung von Gesichtsteilen (Landmark Detection) oder die Verwendung eines einfachen neuronalen Netzwerks sein.  Und heute wird diese Methode am h√§ufigsten angewendet;  Der Benutzer wird aufgefordert, eine Reihe von Aktionen auszuf√ºhren: Kopf drehen, zwinkern, l√§cheln und mehr.  Wenn die Sequenz zuf√§llig ist, ist es f√ºr einen Angreifer nicht einfach, sich im Voraus darauf vorzubereiten.  Leider ist diese Suche f√ºr einen ehrlichen Benutzer auch nicht immer √ºberwindbar, und das Engagement nimmt stark ab. </p><br><p><img src="https://habrastorage.org/webt/4s/fb/vv/4sfbvvforopuonls_ochr8dpzjg.png"></p><br><p>  Sie k√∂nnen auch die Merkmale einer Verschlechterung der Bildqualit√§t beim Drucken oder Abspielen auf dem Bildschirm verwenden.  H√∂chstwahrscheinlich werden sogar einige lokale Muster, die f√ºr das Auge schwer zu erkennen sind, im Bild erkannt.  Dies kann beispielsweise durch Z√§hlen lokaler Bin√§rmuster (LBP, lokales Bin√§rmuster) f√ºr verschiedene Bereiche des Gesichts nach Auswahl aus dem Rahmen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PDF</a> ) erfolgen.  Das beschriebene System kann als Begr√ºnder der auf Bildanalyse basierenden Anti-Spoofing-Algorithmen f√ºr die gesamte Richtung des Gesichts angesehen werden.  Kurz gesagt, bei der Berechnung des LBP werden f√ºr jedes Pixel im Bild acht seiner Nachbarn nacheinander aufgenommen und ihre Intensit√§t verglichen.  Wenn die Intensit√§t gr√∂√üer als auf dem zentralen Pixel ist, wird eins, wenn weniger, Null zugewiesen.  Somit wird f√ºr jedes Pixel eine 8-Bit-Sequenz erhalten.  Basierend auf den erhaltenen Sequenzen wird ein Histogramm pro Pixel erstellt, das dem Eingang des SVM-Klassifikators zugef√ºhrt wird. </p><br><p><img src="https://habrastorage.org/webt/qu/x_/vv/qux_vvmfk7ikww7ojknhq_mpbhu.png"></p><br><p>  Lokale bin√§re Muster, Histogramm und SVM.  Hier k√∂nnen Sie sich den zeitlosen Klassikern anschlie√üen </p><br><p>  Der HTER-Effizienzindikator betr√§gt ‚Äûbis zu‚Äú 15% und bedeutet, dass ein erheblicher Teil der Angreifer den Schutz ohne gro√üen Aufwand √ºberwindet, obwohl anerkannt werden sollte, dass viel beseitigt wird.  Der Algorithmus wurde am IDIAP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Replay-Attack-</a> Datensatz getestet, der aus 1200 kurzen Videos von 50 Befragten und drei Arten von Angriffen besteht - gedruckte Angriffe, mobile Angriffe, hochaufl√∂sende Angriffe. </p><br><p>  Ideen zur Analyse der Bildtextur wurden fortgesetzt.  Im Jahr 2015 entwickelte Bukinafit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen</a> Algorithmus zum alternativen Aufteilen des Bildes in Kan√§le zus√§tzlich zu herk√∂mmlichem RGB, f√ºr dessen Ergebnisse erneut lokale Bin√§rmuster berechnet wurden, die wie bei der vorherigen Methode dem Eingang des SVN-Klassifikators zugef√ºhrt wurden.  Die HTER-Genauigkeit, berechnet anhand der CASIA- und Replay-Attack-Datens√§tze, war zu diesem Zeitpunkt beeindruckend 3%. </p><br><p><img src="https://habrastorage.org/webt/7j/vy/i7/7jvyi7inhsl5g2ulp05v4luido8.png"></p><br><p>  Gleichzeitig wurde an der Entdeckung von Moir√© gearbeitet.  Patel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ver√∂ffentlichte</a> einen Artikel, in dem er vorschlug, nach Bildartefakten in Form eines periodischen Musters zu suchen, das durch die √úberlappung zweier Scans verursacht wird.  Der Ansatz erwies sich als praktikabel und zeigte, dass HTER in den IDIAP-, CASIA- und RAFS-Datens√§tzen etwa 6% betr√§gt.  Es war auch der erste Versuch, die Leistung eines Algorithmus f√ºr verschiedene Datens√§tze zu vergleichen. </p><br><p><img src="https://habrastorage.org/webt/98/m2/ls/98m2ls-svv7gxfaagripfrhzymo.png"></p><br><p>  Periodisches Muster im Bild, das durch Overlay-Sweeps verursacht wird </p><br><p>  Um Versuche zu erkennen, Fotos zu pr√§sentieren, bestand die logische L√∂sung darin, nicht ein Bild, sondern deren Sequenz aus dem Videostream zu analysieren.  Zum Beispiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schlugen</a> Anjos und Kollegen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vor,</a> Merkmale aus dem optischen Strom in benachbarten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rahmenpaaren zu</a> isolieren, den bin√§ren Klassifikator der Eingabe zuzuf√ºhren und die Ergebnisse zu mitteln.  Der Ansatz erwies sich als recht effektiv und zeigte einen HTER von 1,52% f√ºr den eigenen Datensatz. </p><br><p><img src="https://habrastorage.org/webt/ih/9e/vo/ih9evob9a5hmtjekxhx1iwsgxm8.png"></p><br><p>  Eine interessante Methode zur Verfolgung von Bewegungen, die sich von herk√∂mmlichen Ans√§tzen etwas unterscheidet.  Da 2013 das Prinzip ‚ÄûAnwenden eines Rohbildes auf die Eingabe des Faltungsnetzwerks und Anpassen der Gitterschichten, um das Ergebnis zu erhalten‚Äú f√ºr moderne Projekte im Bereich des tiefen Lernens nicht √ºblich war, wandte Bharadzha konsequent komplexere vorl√§ufige Transformationen an.  Insbesondere verwendete er den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Eulerschen Videovergr√∂√üerungsalgorithmus</a> , der f√ºr die Arbeit von Wissenschaftlern des MIT bekannt ist und der erfolgreich zur Analyse von Farbver√§nderungen in der Haut in Abh√§ngigkeit vom Puls eingesetzt wurde.  Ich habe LBP durch HOOF (Histogramme der optischen Flussrichtungen) ersetzt, nachdem ich richtig festgestellt habe, dass wir, da wir Bewegungen verfolgen m√∂chten, die entsprechenden Zeichen und nicht nur die Texturanalyse ben√∂tigen.  Trotzdem wurde die damals traditionelle SVM als Klassifikator verwendet.  Der Algorithmus zeigte √§u√üerst beeindruckende Ergebnisse bei Print Attack- (0%) und Replay Attack- (1,25%) Datens√§tzen. </p><br><p><img src="https://habrastorage.org/webt/-i/1w/w2/-i1ww2rsu0kqmxglhh-on8lnr5g.png"></p><br><h2 id="davayte-uzhe-uchit-setki">  Lass uns schon das Gitter lernen! </h2><br><p><img src="https://habrastorage.org/webt/7p/t-/yk/7pt-ykbzzuyb7bzpnd9qpjodfog.png"></p><br><p>  Irgendwann wurde klar, dass der √úbergang zum tiefen Lernen gereift war.  Die ber√ºchtigte ‚ÄûDeep Learning Revolution‚Äú √ºberholte das Anti-Spoofing. </p><br><p>  Die ‚Äûerste Schwalbe‚Äú kann als Methode zur Analyse von Tiefenkarten in einzelnen Abschnitten (‚ÄûPatches‚Äú) des Bildes angesehen werden.  Offensichtlich ist eine Tiefenkarte ein sehr gutes Zeichen f√ºr die Bestimmung der Ebene, in der sich das Bild befindet.  Schon allein deshalb, weil das Bild auf dem Blatt Papier per Definition keine ‚ÄûTiefe‚Äú hat.  In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ataums</a> Arbeit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im Jahr</a> 2017 wurden viele separate kleine Abschnitte aus dem Bild extrahiert, f√ºr die Tiefenkarten berechnet wurden, die dann mit der Tiefenkarte des Hauptbildes zusammengef√ºhrt wurden.  Es wurde darauf hingewiesen, dass zehn zuf√§llige Gesichtsbild-Patches ausreichen, um Printed Attack zuverl√§ssig zu identifizieren.  Dar√ºber hinaus haben die Autoren die Ergebnisse zweier Faltungsnetzwerke zusammengestellt, von denen das erste Tiefenkarten f√ºr Patches und das zweite f√ºr das gesamte Bild berechnet hat.  Beim Training von Datens√§tzen wurde die Printed Attack-Klasse einer Tiefenkarte von Null und einem dreidimensionalen Modell des Gesichts sowie einer Reihe zuf√§llig ausgew√§hlter Abschnitte zugeordnet.  Im Gro√üen und Ganzen war die Tiefenkarte selbst nicht so wichtig, es wurde nur eine bestimmte Indikatorfunktion verwendet, die die ‚ÄûTiefe des Abschnitts‚Äú kennzeichnet.  Der Algorithmus zeigte einen HTER-Wert von 3,78%.  F√ºr das Training wurden drei √∂ffentliche Datens√§tze verwendet - CASIA-MFSD, MSU-USSA und Replay-Attack. </p><br><p><img src="https://habrastorage.org/webt/a7/bl/df/a7bldfybkgzeeptdtomphvq1kwk.png"></p><br><p>  Leider hat die Verf√ºgbarkeit einer gro√üen Anzahl exzellenter Frameworks f√ºr Deep Learning zur Entstehung einer gro√üen Anzahl von Entwicklern gef√ºhrt, die "frontal" versuchen, das Problem des Antispoofing von Gesichtern auf eine bekannte Art und Weise beim Aufbau neuronaler Netze zu l√∂sen.  Normalerweise sieht es aus wie ein Stapel von Feature-Maps an den Ausg√§ngen mehrerer Netzwerke, die auf einem weit verbreiteten Datensatz vorab trainiert wurden, der einem bin√§ren Klassifikator zugef√ºhrt wird. </p><br><p><img src="https://habrastorage.org/webt/ek/8b/rc/ek8brc52akg2y3zfy6ejmbr-taq.png"></p><br><p>  Generell ist der Schluss zu ziehen, dass bis heute einige Werke ver√∂ffentlicht wurden, die im Allgemeinen gute Ergebnisse zeigen und nur ein kleines ‚ÄûAber‚Äú vereinen.  Alle diese Ergebnisse werden in einem bestimmten Datensatz demonstriert!  Die Situation wird durch die begrenzte Verf√ºgbarkeit von Datens√§tzen versch√§rft, und zum Beispiel beim ber√ºchtigten Replay-Attack ist es f√ºr HTER 0% keine √úberraschung.  All dies f√ºhrt zur Entstehung sehr komplexer Architekturen wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser</a> , die verschiedene ausgekl√ºgelte Merkmale, auf dem Stapel zusammengestellte Hilfsalgorithmen mit mehreren Klassifizierern, deren Ergebnisse gemittelt werden, usw. verwenden. Die Autoren erhalten HTER = 0,04% am Ausgang! </p><br><p><img src="https://habrastorage.org/webt/aw/_k/s_/aw_ks_6-xp40fyjz97ue9mwzp8q.png"></p><br><p>  Dies deutet darauf hin, dass das Anti-Spoofing-Problem im Gesicht innerhalb eines bestimmten Datensatzes gel√∂st wurde.  Lassen Sie uns verschiedene moderne Methoden auf den Tisch bringen, die auf neuronalen Netzen basieren.  Es ist leicht zu erkennen, dass die "Referenzergebnisse" mit sehr unterschiedlichen Methoden erzielt wurden, die nur in den fragenden K√∂pfen der Entwickler entstanden sind. </p><br><p><img src="https://habrastorage.org/webt/bb/7v/73/bb7v73awyzwhxeyyvtejgm3skh4.png"></p><br><p>  Vergleichsergebnisse verschiedener Algorithmen.  Der Tisch ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von hier genommen</a> . </p><br><p>  Leider verletzt der gleiche ‚Äûkleine‚Äú Faktor das gute Bild des Kampfes um Zehntel Prozent.  Wenn Sie versuchen, das neuronale Netzwerk auf einen Datensatz zu trainieren und auf einen anderen anzuwenden, sind die Ergebnisse ... nicht so optimistisch.  Schlimmer noch, Versuche, Klassifikatoren im wirklichen Leben anzuwenden, lassen √ºberhaupt keine Hoffnung. <br>  Als Beispiel nehmen wir die Daten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aus dem Jahr</a> 2015, bei denen eine Metrik ihrer Qualit√§t verwendet wurde, um die Authentizit√§t des dargestellten Bildes zu bestimmen.  √úberzeugen Sie sich selbst: </p><br><p><img src="https://habrastorage.org/webt/jw/b5/-n/jwb5-naohhjhek2tkmakbssjyik.png"></p><br><p>  Mit anderen Worten, ein Algorithmus, der auf Idiap-Daten trainiert, aber auf MSU angewendet wird, ergibt eine wirklich positive Erkennungsrate von 90,5%. Wenn Sie das Gegenteil tun (auf MSU trainieren und auf Idiap testen), k√∂nnen nur 47,2 korrekt bestimmt werden % (!) Bei anderen Kombinationen verschlechtert sich die Situation noch mehr. Wenn Sie beispielsweise den Algorithmus auf MSU trainieren und auf CASIA √ºberpr√ºfen, betr√§gt der TPR 10,8%!  Dies bedeutet, dass den Angreifern f√§lschlicherweise eine gro√üe Anzahl ehrlicher Benutzer zugewiesen wurde, was nur bedr√ºckend sein kann.  Selbst datenbank√ºbergreifendes Training konnte die Situation nicht umkehren, was ein durchaus vern√ºnftiger Ausweg zu sein scheint. </p><br><p>  Mal sehen mehr.  Die im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel von</a> Patel 2016 vorgestellten Ergebnisse zeigen, dass selbst bei ausreichend komplexen Verarbeitungspipelines und der Auswahl zuverl√§ssiger Merkmale wie Blinken und Textur die Ergebnisse unbekannter Datens√§tze nicht als zufriedenstellend angesehen werden k√∂nnen.  Irgendwann wurde klar, dass die vorgeschlagenen Methoden nicht ausreichten, um die Ergebnisse zusammenzufassen. </p><br><p><img src="https://habrastorage.org/webt/vf/lz/ol/vflzoljiplnkj_vgm-zth9a0sdc.png"></p><br><h2 id="a-esli-ustroit-sorevnovanie">  Und wenn Sie einen Wettbewerb arrangieren ... </h2><br><p>  Nat√ºrlich war Anti-Spoofing auf dem Gebiet des Gesichts nicht ohne Konkurrenz.  Im Jahr 2017 fand an der Universit√§t von Oulu in Finnland ein Wettbewerb zu einem eigenen neuen Datensatz mit interessanten Protokollen statt, der speziell auf den Einsatz im Bereich mobiler Anwendungen ausgerichtet war. </p><br><p>  - Protokoll 1: Es gibt einen Unterschied in Beleuchtung und Hintergrund.  Datens√§tze werden an verschiedenen Orten aufgezeichnet und unterscheiden sich in Hintergrund und Beleuchtung. </p><br><p>  -Protokoll 2: Verschiedene Modelle von Druckern und Bildschirmen wurden f√ºr Angriffe verwendet.  Daher wird im Verifizierungsdatensatz eine Technik verwendet, die im Trainingssatz nicht enthalten ist </p><br><p>  Protokoll 3: Austauschbarkeit von Sensoren.  Echte Benutzervideos und Angriffe werden auf f√ºnf verschiedenen Smartphones aufgezeichnet und in einem Trainingsdatensatz verwendet.         ,      . </p><br><p> - 4:    . </p><br><p>    .     ,      ,            ,      -      .      ,   ,  10%.        : </p><br><ol><li><p> GRADIENT </p><br><ul><li>      (   HSV  YCbCr),   . </li><li>                . </li><li>           HSV  YCbCr,     .    ROI (region-of-interest)            160√ó160 .. </li><li>  ROI   3√ó3  5√ó5  ,     LBP  ,        6018. </li><li>      (Recursive Feature Elimination)    6018  1000. </li><li>         SVM   .| </li></ul><br></li><li><p> SZCVI </p><br><ul><li>      ,    </li><li>    216√ó384 </li><li>  VGG-  </li><li>       </li></ul><br></li><li><p> Recod </p><br><ul><li> SqueezeNet   Imagenet </li><li> Transfer learning    : CASIA  UVAD </li><li>       224√ó224 pixels.      , ,   ,     CNN. </li><li>        . </li><li>            </li></ul><br></li><li><p> CPqD </p><br><ul><li>  Inception-v3,   ImageNet </li><li> C   </li><li>         ,  ,      224√ó224 RGB | </li></ul><br></li></ol><br><p>  ,       .    LBP,  ,    ,     .. GRADIANT        ,     ,      ,   .     . </p><br><p>      .   ,        . -,        ( 15   NUAA  1140  MSU-USSA)  ,   ,  ,   ,     .       ,  ,  ,    ,         . -,                 . ,   CASIA        ,     . ,     ,    ,    ,      ‚Ä¶  ,       ,   ,           . </p><br><p><img src="https://habrastorage.org/webt/ur/yf/t8/uryft8082ylvw-1kbyvcxucjcem.png"></p><br><p>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>        30 .   ,        ,            .  ,          . </p><br><p> ,  ,   ¬´ ¬ª.          . ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>     (rPPG ‚Äì remote photoplethysmography),       .    ,           , -,   ‚Äì     .            .  ,        , ,  . ,        ,     .            ,     ,                 ,        . </p><br><p><img src="https://habrastorage.org/webt/db/le/44/dble44fc8acyqdhzead3ndbkg3a.png"></p><br><p><img src="https://habrastorage.org/webt/sy/u7/vu/syu7vucfvb5inhajqoilb6rqxu8.png"></p><br><p> Die Arbeit zeigte einen HTER-Wert von etwa 10%, was die grunds√§tzliche Anwendbarkeit der Methode best√§tigt.  Es gibt mehrere Arbeiten, die die Aussichten dieses Ansatzes best√§tigen. <br>  (CVPR 2018) JH-Ortega et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zeitanalyse von pulsbasiertem Gesichts-Anti-Spoofing in Visible und NIR</a> <br>  (2016) X. Li.  et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Allgemeines Gesichts-Anti-Spoofing durch Erkennen von Impulsen aus Gesichtsvideos</a> <br>  (2016) J. Chen et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Realsense = echte Herzfrequenz: Beleuchtungsinvariante Herzfrequenzsch√§tzung aus Videos</a> <br>  (2014) HE Tasli et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Remote PPG-basierte Vitalzeichenmessung mit adaptiven Gesichtsregionen</a> </p><br><p>  Im Jahr 2018 schlugen Liu und Kollegen von der University of Michigan vor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, die bin√§re Klassifikation</a> zugunsten des von ihnen als ‚Äûbin√§re √úberwachung‚Äú bezeichneten Ansatzes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aufzugeben</a> , dh eine komplexere Sch√§tzung auf der Grundlage von Tiefenkarten und Entfernungsphotoplethysmographie zu verwenden.  F√ºr jedes dieser Gesichtsbilder wurde ein dreidimensionales Modell unter Verwendung eines <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neuronalen Netzwerks</a> rekonstruiert und mit einer Tiefenkarte benannt.  Gef√§lschten Bildern wurde eine Tiefenkarte zugewiesen, die aus Nullen besteht. Am Ende ist es nur ein St√ºck Papier oder ein Ger√§tebildschirm!  Diese Eigenschaften wurden als ‚ÄûWahrheit‚Äú angesehen, neuronale Netze wurden auf ihrem eigenen SiW-Datensatz trainiert.  Dann wurde dem Eingabebild eine dreidimensionale Gesichtsmaske √ºberlagert, eine Tiefenkarte und ein Impuls wurden daf√ºr berechnet, und all dies wurde in einem ziemlich komplizierten F√∂rderer zusammengebunden.  Infolgedessen zeigte die Methode eine Genauigkeit von etwa 10 Prozent im OULU-Wettbewerbsdatensatz.  Interessanterweise baute der Gewinner des von der Universit√§t von Oulu organisierten Wettbewerbs den Algorithmus auf bin√§ren Klassifizierungsmustern, blinkendem Tracking und anderen von Hand entworfenen Zeichen auf, und seine L√∂sung hatte auch eine Genauigkeit von etwa 10%.  Der Gewinn betrug nur etwa ein halbes Prozent!  Die neue kombinierte Technologie wird durch die Tatsache unterst√ºtzt, dass der Algorithmus auf seinem eigenen Datensatz trainiert und auf OULU getestet wurde, um das Ergebnis des Gewinners zu verbessern.  Dies weist auf eine gewisse Portabilit√§t der Ergebnisse vom Datensatz zum Datensatz hin, und was zum Teufel nicht scherzt, ist f√ºr das wirkliche Leben m√∂glich.  Beim Versuch, ein Training f√ºr andere Datens√§tze durchzuf√ºhren - CASIA und ReplayAttack - lag das Ergebnis jedoch erneut bei etwa 28%.  Dies √ºbertrifft nat√ºrlich die Leistung anderer Algorithmen beim Training mit verschiedenen Datens√§tzen, aber bei solchen Genauigkeitswerten kann von keiner industriellen Verwendung gesprochen werden! </p><br><p><img src="https://habrastorage.org/webt/qd/bu/fn/qdbufnt8yc9pghj4egkxqaku_3g.png"></p><br><p>  Ein anderer Ansatz wurde von Wang und Kollegen in einer k√ºrzlich erschienenen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit von</a> 2019 vorgeschlagen.  Es wurde festgestellt, dass bei der Analyse der Mikrobewegung im Gesicht Rotationen und Verschiebungen des Kopfes erkennbar sind, was zu einer charakteristischen √Ñnderung der Winkel und relativen Abst√§nde zwischen den Zeichen im Gesicht f√ºhrt.  Wenn das Gesicht horizontal verschoben wird, vergr√∂√üert sich der Winkel zwischen Nase und Ohr.  Wenn Sie jedoch ein Blatt Papier mit einem Bild auf die gleiche Weise verschieben, verringert sich der Winkel!  Zur Veranschaulichung lohnt es sich, eine Zeichnung aus der Arbeit zu zitieren. </p><br><p><img src="https://habrastorage.org/webt/x9/lq/kz/x9lqkzuzmgz7gz5ejx1rsiom7wq.png"></p><br><p>  Nach diesem Prinzip bauten die Autoren eine ganze Lerneinheit zum √úbertragen von Daten zwischen Schichten eines neuronalen Netzwerks auf.  Dabei wurden ‚Äûfalsche Offsets‚Äú f√ºr jeden Frame in einer Folge von zwei Frames ber√ºcksichtigt, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sodass</a> die Ergebnisse im n√§chsten Block der Langzeitabh√§ngigkeitsanalyse auf der Grundlage der GRU <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gated Recurrent Unit verwendet werden konnten</a> .  Dann wurden alle Zeichen verkettet, die Verlustfunktion berechnet und die endg√ºltige Klassifizierung durchgef√ºhrt.  Dies erm√∂glichte es uns, das Ergebnis des OULU-Datensatzes leicht zu verbessern, aber das Problem der Abh√§ngigkeit von den Trainingsdaten blieb bestehen, da die Indikatoren f√ºr das CASIA-MFSD- und das Replay-Attack-Paar 17,5 bzw. 24 Prozent betrugen. </p><br><p>  Gegen Ende ist die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit von</a> Tencent-Experten erw√§hnenswert, die vorgeschlagen haben, die Art und Weise zu √§ndern, in der das Quellvideobild empfangen wird.  Anstatt die Szene passiv zu beobachten, schlugen sie vor, das Gesicht dynamisch zu beleuchten und Reflexionen zu lesen.  Das Prinzip der aktiven Bestrahlung eines Objekts wird seit langem in Ortungssystemen verschiedener Art angewendet, daher erscheint seine Verwendung zur Untersuchung des Gesichts sehr logisch.  Offensichtlich gibt es f√ºr eine zuverl√§ssige Identifizierung im Bild selbst nicht gen√ºgend Zeichen, und das Beleuchten des Telefon- oder Tablet-Bildschirms mit einer Folge von Lichtsymbolen (Licht CAPTCHA gem√§√ü der Terminologie der Autoren) kann sehr hilfreich sein.  Als n√§chstes wird der Unterschied in Streuung und Reflexion √ºber ein Rahmenpaar bestimmt, und die Ergebnisse werden einem neuronalen Multitask-Netzwerk zur weiteren Verarbeitung auf der Tiefenkarte und zur Berechnung verschiedener Verlustfunktionen zugef√ºhrt.  Am Ende wird eine Regression der normalisierten Lichtrahmen durchgef√ºhrt.  Die Autoren analysierten nicht die Generalisierungsf√§higkeit ihres Algorithmus f√ºr andere Datens√§tze und trainierten ihn f√ºr ihren eigenen privaten Datensatz.  Das Ergebnis liegt bei etwa 1% und es wird berichtet, dass das Modell bereits f√ºr den tats√§chlichen Gebrauch bereitgestellt wurde. </p><br><p><img src="https://habrastorage.org/webt/c-/ts/w8/c-tsw8vywrvsv3l58ow-axifkay.png"></p><br><p>  Bis 2017 war der Gesichts-Anti-Spoofing-Bereich nicht sehr aktiv.  Aber 2019 hat bereits eine ganze Reihe von Arbeiten vorgestellt, die mit der aggressiven F√∂rderung mobiler Gesichtsidentifikationstechnologien, vor allem von Apple, verbunden sind.  Dar√ºber hinaus interessieren sich Banken f√ºr Gesichtserkennungstechnologien.  Viele neue Leute sind in die Branche gekommen, was uns erlaubt, auf schnelle Fortschritte zu hoffen.  Trotz der sch√∂nen Titel von Ver√∂ffentlichungen bleibt die Verallgemeinerungsf√§higkeit der Algorithmen bislang sehr schwach und erlaubt es uns nicht, √ºber eine Eignung f√ºr den praktischen Gebrauch zu sprechen. </p><br><h2 id="zaklyuchenie-a-naposledok-ya-skazhu-chto">  Fazit  Und zum Schluss sage ich das ... </h2><br><ul><li>  Lokale bin√§re Muster, Verfolgung von Blinken, Atmung, Bewegungen und andere manuell gestaltete Zeichen haben ihre Bedeutung √ºberhaupt nicht verloren.  Dies liegt vor allem daran, dass tiefes Training im Bereich Gesichts-Anti-Spoofing noch sehr naiv ist. </li><li>  Es ist klar, dass in der ‚Äûgleichen‚Äú L√∂sung mehrere Methoden zusammengef√ºhrt werden.  Die Analyse von Reflexions-, Streu- und Tiefenkarten sollte zusammen verwendet werden.  H√∂chstwahrscheinlich hilft das Hinzuf√ºgen eines zus√§tzlichen Datenkanals beispielsweise bei der Sprachaufzeichnung und bei einigen Systemans√§tzen, mit denen Sie mehrere Technologien in einem einzigen System sammeln k√∂nnen </li><li>  Fast alle f√ºr die Gesichtserkennung verwendeten Technologien finden Anwendung beim Gesichts-Anti-Spoofing (Cap!). Alles, was in der einen oder anderen Form f√ºr die Gesichtserkennung entwickelt wurde, hat Anwendung f√ºr die Angriffsanalyse gefunden </li><li>  Bestehende Datens√§tze haben die S√§ttigung erreicht.  Von zehn Basisdatens√§tzen in f√ºnf wurde ein Fehler von Null erreicht.  Dies spricht zum Beispiel bereits f√ºr die Effizienz von Methoden, die auf Tiefenkarten basieren, erlaubt jedoch keine Verbesserung der Generalisierungsf√§higkeit.  Wir brauchen neue Daten und neue Experimente dazu </li><li>  Es besteht ein deutliches Ungleichgewicht zwischen dem Grad der Entwicklung der Gesichtserkennung und dem Antispoofing des Gesichts.  Erkennungstechnologien sind Schutzsystemen deutlich voraus.  Dar√ºber hinaus ist es das Fehlen zuverl√§ssiger Schutzsysteme, das den praktischen Einsatz von Gesichtserkennungssystemen behindert.  Es kam vor, dass das Hauptaugenmerk speziell auf die Gesichtserkennung gelegt wurde und die Angriffserkennungssysteme etwas zur√ºckhaltend blieben </li><li>  Es besteht ein starker Bedarf an einem systematischen Ansatz im Bereich des Gesichts-Anti-Spoofing.  Der vergangene Wettbewerb der Universit√§t von Oulu hat gezeigt, dass es bei Verwendung eines nicht repr√§sentativen Datensatzes durchaus m√∂glich ist, die etablierten L√∂sungen mit einer einfachen kompetenten Anpassung zu besiegen, ohne neue zu entwickeln.  Vielleicht kann ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neuer Wettbewerb</a> das Blatt wenden </li><li>  Mit zunehmendem Interesse an dem Thema und der Einf√ºhrung von Gesichtserkennungstechnologien durch gro√üe Akteure ergaben sich f√ºr neue ehrgeizige Teams ‚ÄûZeitfenster‚Äú, da auf architektonischer Ebene ein ernsthafter Bedarf an einer neuen L√∂sung besteht </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de452894/">https://habr.com/ru/post/de452894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de452884/index.html">Analyse der Leistung virtueller Maschinen in VMware vSphere. Teil 1: CPU</a></li>
<li><a href="../de452886/index.html">Wiki-Projekte und Noosphere-Name auf HACKNOWLEGE</a></li>
<li><a href="../de452888/index.html">In der N√§he von M√ºnchen begann der Test des f√ºnfsitzigen Tiltrotors Lilium Jet in Originalgr√∂√üe</a></li>
<li><a href="../de452890/index.html">23. Mai, 18.30 Uhr - Live-√úbertragung von QIWI Kitchen</a></li>
<li><a href="../de452892/index.html">Wie kann ein Nicht-Programmierer in die USA ziehen: Schritt-f√ºr-Schritt-Anleitung</a></li>
<li><a href="../de452900/index.html">Indizes in PostgreSQL - 9 (BRIN)</a></li>
<li><a href="../de452902/index.html">Nach 4 Jahren Ausbildung zum Programmierer verstehe ich, dass ich weit von einem Programmierer entfernt bin</a></li>
<li><a href="../de452904/index.html">Wie Maschinen kommunizieren - MQTT-Protokoll</a></li>
<li><a href="../de452906/index.html">JavaScript-Engines: Wie funktionieren sie? Vom Call-Stack bis zu den Versprechungen (fast) alles, was Sie wissen m√ºssen</a></li>
<li><a href="../de452908/index.html">Selenium WebDriver - Echtzeit-Testmetrik mit Grafana und InfluxDB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
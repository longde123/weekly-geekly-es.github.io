<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèá ‚ôëÔ∏è üñïüèΩ Redes neurais. Para onde tudo isso vai üï• ü•à üí®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O artigo consiste em duas partes: 


1. Uma breve descri√ß√£o de algumas arquiteturas de rede para detectar objetos em uma imagem e segmenta√ß√£o de image...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Redes neurais. Para onde tudo isso vai</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482794/"><p>  O artigo consiste em duas partes: </p><br><ol><li>  Uma breve descri√ß√£o de algumas arquiteturas de rede para detectar objetos em uma imagem e segmenta√ß√£o de imagens com os links mais compreens√≠veis para recursos para mim.  Tentei escolher explica√ß√µes em v√≠deo e de prefer√™ncia em russo. </li><li>  A segunda parte √© uma tentativa de entender a dire√ß√£o do desenvolvimento de arquiteturas de redes neurais.  E tecnologias baseadas nelas. </li></ol><br><p><img src="https://habrastorage.org/webt/8a/ph/qb/8aphqb_xrv3ynavkgmuex1ib8qo.jpeg" alt="Compreender arquiteturas de redes neurais n√£o √© f√°cil"></p><br><p>  Figura 1 - Compreender a arquitetura das redes neurais n√£o √© f√°cil </p><br><p> Tudo come√ßou com o fato de ele ter criado dois aplicativos de demonstra√ß√£o para classificar e detectar objetos em um telefone Android: </p><br><ul><li>  <a href="https://github.com/foobar167/junkyard/tree/master/object_classifier">Demonstra√ß√£o de back-end</a> , quando os dados s√£o processados ‚Äã‚Äãno servidor e transferidos para o telefone.  Classifica√ß√£o de imagem de tr√™s tipos de ursos: marrom, preto e pel√∫cia. </li><li>  <a href="https://github.com/foobar167/android/tree/master/object_detection_demo">Demonstra√ß√£o de front-end</a> quando os dados s√£o processados ‚Äã‚Äãno pr√≥prio telefone.  Detec√ß√£o de objetos de tr√™s tipos: avel√£s, figos e t√¢maras. </li></ul><a name="habracut"></a><br><p>  H√° uma diferen√ßa entre as tarefas de classificar imagens, detectar objetos em uma imagem e <a href="https://medium.com/analytics-vidhya/image-classification-vs-object-detection-vs-image-segmentation-f36db85fe81">segmentar imagens</a> .  Portanto, era necess√°rio descobrir quais arquiteturas de rede neural detectam objetos nas imagens e quais podem segmentar.  Encontrei os seguintes exemplos de arquiteturas com os links mais compreens√≠veis para recursos para mim: </p><br><ul><li>  Uma s√©rie de arquiteturas baseadas em R-CNN (regi√µes com recursos de <strong>C</strong> etvolu√ß√£o <strong>N</strong> etworks): R-CNN, R-CNN r√°pida, R-CNN <a href="https://medium.com/%40smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8">mais</a> r√°pida, R-CNN <a href="https://medium.com/%40smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8">mais r√°pida</a> , <a href="https://youtu.be/0vt05rQqk_I">M√°scara R-CNN</a> .  Para detectar um objeto em uma imagem usando o mecanismo RPN (Region Proposal Network), caixas delimitadoras s√£o alocadas.  Inicialmente, o mecanismo de busca seletiva mais lento foi usado em vez do RPN.  Em seguida, as regi√µes limitadas selecionadas s√£o alimentadas √† entrada de uma rede neural normal para classifica√ß√£o.  Na arquitetura do R-CNN, existem ciclos expl√≠citos "para" de enumera√ß√£o em regi√µes limitadas, no total at√© 2000 s√£o executados na rede interna da AlexNet.  Devido a loops expl√≠citos "for", a velocidade de processamento da imagem √© mais lenta.  O n√∫mero de ciclos expl√≠citos, percorre a rede neural interna, diminui a cada nova vers√£o da arquitetura e dezenas de outras altera√ß√µes s√£o realizadas para aumentar a velocidade e substituir a tarefa de detectar objetos pela segmenta√ß√£o de objetos na M√°scara R-CNN. </li><li>  <a href="https://youtu.be/L0tzmv--CGY">O YOLO</a> (apenas um local de trabalho) √© a primeira rede neural que reconhece objetos em tempo real em dispositivos m√≥veis.  Caracter√≠stica distintiva: distinguir objetos em uma execu√ß√£o (basta olhar uma vez).  Ou seja, n√£o h√° loops "for" expl√≠citos na arquitetura YOLO, e √© por isso que a rede √© r√°pida.  Por exemplo, √© uma analogia: no NumPy n√£o h√° loops expl√≠citos "for" em opera√ß√µes com matrizes, que s√£o implementadas no NumPy em n√≠veis mais baixos da arquitetura por meio da linguagem de programa√ß√£o C. O YOLO usa uma grade de janelas predefinidas.  Para impedir que o mesmo objeto seja detectado v√°rias vezes, √© usado o coeficiente de sobreposi√ß√£o da janela (IoU, Intersec√ß√£o <strong>ou</strong> Uni√£o).  Essa arquitetura funciona em uma ampla gama e possui alta <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25BE%25D0%25B1%25D0%25B0%25D1%2581%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">robustez</a> : o modelo pode ser treinado em fotografias, mas ao mesmo tempo funciona bem em pinturas pintadas. </li><li>  <a href="https://youtu.be/P8e-G-Mhx4k">SSD</a> (Simple MultiBox <strong>D</strong> etector) - os ‚Äúhacks‚Äù mais bem-sucedidos da arquitetura YOLO (por exemplo, supress√£o n√£o m√°xima) s√£o usados ‚Äã‚Äãe novos s√£o adicionados para tornar a rede neural mais r√°pida e precisa.  Caracter√≠stica distintiva: distinguir objetos em uma corrida usando uma determinada grade de janelas (caixa padr√£o) na pir√¢mide de imagens.  A pir√¢mide de imagens √© codificada em tensores de convolu√ß√£o durante opera√ß√µes sucessivas de convolu√ß√£o e agrupamento (com a opera√ß√£o de agrupamento m√°ximo, a dimens√£o espacial diminui).  Dessa maneira, objetos grandes e pequenos s√£o determinados em uma √∫nica execu√ß√£o de rede. </li><li>  O MobileSSD ( <strong>Mobile</strong> NetV2 + <strong>SSD</strong> ) √© uma combina√ß√£o de duas arquiteturas de rede neural.  A primeira rede <a href="https://habr.com/ru/post/352804/">MobileNetV2</a> √© r√°pida e aumenta a precis√£o do reconhecimento.  O MobileNetV2 √© usado no lugar do VGG-16, originalmente usado no <a href="https://arxiv.org/abs/1512.02325">artigo original</a> .  A segunda rede SSD determina a localiza√ß√£o dos objetos na imagem. </li><li>  <a href="https://youtu.be/ge_RT5wvHvY">SqueezeNet</a> √© uma rede neural muito pequena, mas precisa.  Por si s√≥, n√£o resolve o problema de detectar objetos.  No entanto, ele pode ser usado com uma combina√ß√£o de diferentes arquiteturas.  E ser usado em dispositivos m√≥veis.  Uma caracter√≠stica distintiva √© que os dados s√£o compactados primeiro para quatro filtros convolucionais 1 √ó 1 e depois expandidos para quatro filtros convolucionais 1 √ó 1 e quatro 3 √ó 3.  Uma dessas itera√ß√µes de expans√£o de compacta√ß√£o de dados √© chamada de ‚ÄúM√≥dulo de Inc√™ndio‚Äù. </li><li>  <a href="https://youtu.be/b6jhopSMit8">DeepLab</a> (Segmenta√ß√£o de Imagem Sem√¢ntica com Redes Convolucionais Profundas) - segmenta√ß√£o de objetos na imagem.  Uma caracter√≠stica distintiva da arquitetura √© uma convolu√ß√£o dilu√≠da, que preserva a resolu√ß√£o espacial.  Isso √© seguido pelo est√°gio de p√≥s-processamento dos resultados usando um modelo probabil√≠stico gr√°fico (campo aleat√≥rio condicional), que permite remover pequenos ru√≠dos na segmenta√ß√£o e melhorar a qualidade da imagem segmentada.  Por tr√°s do formid√°vel nome ‚Äúmodelo probabil√≠stico gr√°fico‚Äù est√° o filtro gaussiano usual, que √© aproximado em cinco pontos. </li><li>  Tentei entender o dispositivo <a href="https://arxiv.org/abs/1711.06897">RefineDet</a> (rede neural de <a href="https://arxiv.org/abs/1711.06897">refino de detec√ß√£o</a> √∫nica para detec√ß√£o de objetos), mas entendi muito pouco. </li><li>  Tamb√©m observei como a tecnologia de aten√ß√£o funciona: <a href="https://youtu.be/W2rWgXJBZhU">v√≠deo1</a> , <a href="https://youtu.be/iDulhoQ2pro">v√≠deo2</a> , <a href="https://youtu.be/H6Qiegq_36c">v√≠deo3</a> .  Uma caracter√≠stica distintiva da arquitetura de ‚Äúaten√ß√£o‚Äù √© a aloca√ß√£o autom√°tica de regi√µes de maior aten√ß√£o √† imagem (RoI, Raz√µes de interesse) usando uma rede neural chamada Unidade de Aten√ß√£o.  As regi√µes com maior aten√ß√£o s√£o semelhantes √†s regi√µes limitadas (caixas delimitadoras), mas, diferentemente delas, elas n√£o s√£o fixas na imagem e podem ter bordas borradas.  Ent√£o, das regi√µes de maior aten√ß√£o, distinguem-se caracter√≠sticas (caracter√≠sticas) que s√£o "alimentadas" a redes neurais recorrentes com <a href="https://youtu.be/5lUUrREboSk">arquiteturas LSDM, GRU ou Vanilla RNN</a> .  As redes neurais recursivas s√£o capazes de analisar a rela√ß√£o dos sinais em uma sequ√™ncia.  As redes neurais recursivas foram originalmente usadas para traduzir texto em outros idiomas e agora para traduzir <a href="https://youtu.be/e-WB4lfg30M">imagens em texto</a> e <a href="https://youtu.be/rAbhypxs1qQ">texto em imagens</a> . </li></ul><br><p>  Ao estudar essas arquiteturas, <strong>percebi que n√£o entendia nada</strong> .  E o ponto n√£o √© que minha rede neural tenha problemas com o mecanismo de aten√ß√£o.  A cria√ß√£o de todas essas arquiteturas parece uma esp√©cie de hackathon enorme, onde os autores competem em hacks.  Hack √© uma solu√ß√£o r√°pida para uma tarefa dif√≠cil de software.  Ou seja, n√£o h√° conex√£o l√≥gica vis√≠vel e compreens√≠vel entre todas essas arquiteturas.  Tudo o que os une √© um conjunto dos hacks mais bem-sucedidos emprestados um do outro, al√©m de uma <a href="https://youtu.be/Ilg3gGewQ5U">opera√ß√£o de convolu√ß√£o</a> comum <a href="https://youtu.be/Ilg3gGewQ5U">com feedback</a> (propaga√ß√£o reversa de erro, retropropaga√ß√£o).  Nenhum <a href="https://habr.com/ru/post/272473/">pensamento sist√™mico</a> !  N√£o est√° claro o que mudar e como otimizar as conquistas existentes. </p><br><p>  Como resultado da falta de uma conex√£o l√≥gica entre os hacks, eles s√£o extremamente dif√≠ceis de lembrar e colocar em pr√°tica.  Isso √© conhecimento fragmentado.  Na melhor das hip√≥teses, v√°rios momentos interessantes e inesperados s√£o lembrados, mas a maior parte do que √© entendido e incompreens√≠vel desaparece da mem√≥ria em poucos dias.  Ser√° bom se em uma semana eu me lembrar pelo menos do nome da arquitetura.  Mas foram necess√°rias v√°rias horas e at√© dias de trabalho para ler artigos e assistir a v√≠deos de resenhas! </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ffc/1b0/019/ffc1b0019fe7a23e2923d9642485290a.png" alt="Jardim zool√≥gico da rede neural"></p><br><p>  Figura 2 - <a href="https://www.asimovinstitute.org/neural-network-zoo/">Zool√≥gico de redes neurais</a> </p><br><p>  A maioria dos autores de artigos cient√≠ficos, na minha opini√£o pessoal, faz todo o poss√≠vel para que mesmo esse conhecimento fragmentado n√£o seja entendido pelo leitor.  Mas os partic√≠pios em frases de dez linhas com f√≥rmulas tiradas "do teto" s√£o um t√≥pico para um artigo separado (problema de <a href="https://en.wikipedia.org/wiki/Publish_or_perish">publica√ß√£o ou perecimento</a> ). </p><br><p>  Por esse motivo, tornou-se necess√°rio sistematizar as informa√ß√µes nas redes neurais e, assim, aumentar a qualidade da compreens√£o e memoriza√ß√£o.  Portanto, o principal t√≥pico de an√°lise de tecnologias e arquiteturas individuais de redes neurais artificiais foi a seguinte tarefa: <strong>descobrir para onde tudo isso est√° se movendo</strong> , e n√£o o dispositivo de qualquer rede neural espec√≠fica separadamente. </p><br><p>  Para onde est√° indo tudo isso?  Os principais resultados: </p><br><ul><li>  O n√∫mero de startups no campo de aprendizado de m√°quina <a href="https://habr.com/ru/company/recognitor/blog/455676/">caiu acentuadamente</a> nos √∫ltimos dois anos.  Poss√≠vel motivo: "as redes neurais deixaram de ser algo novo". </li><li>  Todos poder√£o criar uma rede neural funcional para resolver um problema simples.  Para fazer isso, pegue o modelo finalizado no ‚Äúzool√≥gico modelo‚Äù e treine a √∫ltima camada da rede neural ( <a href="https://youtu.be/yofjFQddwHE">transfer√™ncia de aprendizado</a> ) nos dados finais da <a href="https://toolbox.google.com/datasetsearch">Pesquisa de conjuntos</a> de dados do <a href="https://toolbox.google.com/datasetsearch">Google</a> ou em <a href="https://www.kaggle.com/datasets">25 mil conjuntos de dados Kaggle</a> na <a href="https://www.dataschool.io/cloud-services-for-jupyter-notebook/">nuvem</a> gratuita do <a href="https://www.dataschool.io/cloud-services-for-jupyter-notebook/">Jupyter Notebook</a> . </li><li>  Grandes fabricantes de redes neurais come√ßaram a criar <strong>‚Äúzool√≥gicos modelo‚Äù</strong> (zool√≥gico modelo).  Com eles, voc√™ pode criar rapidamente um aplicativo comercial: <a href="https://tfhub.dev/">TF Hub</a> para TensorFlow, <a href="https://github.com/open-mmlab/mmdetection">MMDetection</a> para PyTorch, <a href="https://github.com/facebookresearch/Detectron">Detectron</a> para Caffe2, <a href="https://github.com/wkentaro/chainer-modelzoo">chainer-modelzoo</a> para Chainer e <a href="https://modelzoo.co/">outros</a> . </li><li>  Redes neurais em tempo real em dispositivos m√≥veis.  10 a 50 quadros por segundo. </li><li>  O uso de redes neurais em telefones (TF Lite), em navegadores (TF.js) e em <a href="https://youtu.be/19ZNz2N79u4">itens dom√©sticos</a> (IoT, Internet e Te).  Especialmente em telefones que j√° suportam redes neurais no n√≠vel do hardware (neuroaceleradores). </li><li>  ‚ÄúCada dispositivo, roupa e possivelmente at√© comida ter√£o um <strong>endere√ßo IP-v6</strong> e se comunicar√£o‚Äù - <a href="https://youtu.be/GG7H8Xa4m8I%3Ft%3D85">Sebastian Trun</a> . </li><li>  O aumento nas publica√ß√µes de aprendizado de m√°quina come√ßou a <a href="http://data-mining.philippe-fournier-viger.com/too-many-machine-learning-papers">exceder a lei de Moore</a> (dobrando a cada dois anos) desde 2015.  Obviamente, s√£o necess√°rias redes neurais de an√°lise de artigos. </li><li>  As seguintes tecnologias est√£o ganhando popularidade: <br><ul><li>  <strong>PyTorch</strong> - A popularidade est√° crescendo rapidamente e parece ultrapassar o TensorFlow. </li><li>  Sele√ß√£o autom√°tica de hiperpar√¢metros <strong>AutoML</strong> - a popularidade est√° crescendo sem problemas. </li><li>  Diminui√ß√£o gradual da precis√£o e aumento da velocidade de computa√ß√£o: <a href="https://youtu.be/rln_kZbYaWc">l√≥gica fuzzy</a> , algoritmos de <a href="https://youtu.be/MIPkK5ZAsms">aumento</a> , c√°lculos imprecisos (aproximados), quantiza√ß√£o (quando os pesos de uma rede neural s√£o convertidos em n√∫meros inteiros e quantizados), neuroaceleradores. </li><li>  Tradu√ß√£o da <a href="https://youtu.be/e-WB4lfg30M">imagem em texto</a> e <a href="https://youtu.be/rAbhypxs1qQ">texto em imagem</a> . </li><li>  Criando <a href="https://youtu.be/OrHLacCDZVQ">objetos tridimensionais em v√≠deo</a> , agora em tempo real. </li><li>  O principal no DL √© muitos dados, mas n√£o √© f√°cil colet√°-los e marc√°-los.  Portanto, a <a href="https://youtu.be/NcKTn4C91Yc">anota√ß√£o automatizada</a> para redes neurais usando redes neurais est√° sendo desenvolvida. </li></ul></li><li>  Com as redes neurais, a Ci√™ncia da Computa√ß√£o tornou-se repentinamente uma <strong>ci√™ncia experimental</strong> e surgiu uma <a href="https://habr.com/ru/post/480348">crise de reprodutibilidade</a> . </li><li>  O dinheiro de TI e a popularidade das redes neurais surgiram simultaneamente quando a computa√ß√£o se tornou um valor de mercado.  A economia de ouro e c√¢mbio est√° se tornando <strong>computa√ß√£o em moeda de ouro</strong> .  Veja meu artigo sobre <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BA%25D0%25BE%25D0%25BD%25D0%25BE%25D1%2584%25D0%25B8%25D0%25B7%25D0%25B8%25D0%25BA%25D0%25B0">econof√≠sica</a> e o motivo do surgimento do dinheiro de TI. </li></ul><br><p>  Gradualmente, uma nova <a href="https://habr.com/ru/post/481844">metodologia de programa√ß√£o ML / DL</a> (Machine Learning &amp; Deep Learning) aparece, que se baseia na apresenta√ß√£o do programa como uma cole√ß√£o de modelos de redes neurais treinados. </p><br><p><img src="https://habrastorage.org/webt/tx/_a/vl/tx_avlc4bdfe6cfu5hy2bug3nby.png" alt="ML / DL como uma nova metodologia de programa√ß√£o"></p><br><p>  Figura 3 - ML / DL como uma nova metodologia de programa√ß√£o </p><br><p>  No entanto, a <strong>‚Äúteoria das redes neurais‚Äù</strong> n√£o apareceu, dentro da estrutura em que se pode pensar e trabalhar sistematicamente.  O que agora √© chamado de "teoria" √© na verdade algoritmos heur√≠sticos experimentais. </p><br><p>  Links para meus e n√£o apenas recursos: </p><br><ul><li>  Boletim informativo sobre ci√™ncia de dados.  Principalmente processamento de imagem.  Quem quiser receber, deixe-o enviar um e-mail (foobar167 &lt;gaff-gaf&gt; gmail &lt;dot&gt; com).  Envio links para artigos e v√≠deos √† medida que o material se acumula. </li><li>  Uma <a href="">lista</a> geral <a href="">de cursos e artigos</a> que fiz e gostaria de fazer. </li><li>  <a href="">Cursos e v√≠deos para iniciantes</a> , dos quais vale a pena come√ßar a estudar redes neurais.  Al√©m do folheto <a href="https://foobar167.github.io/page/vvedeniye-v-mashinnoye-obucheniye-i-iskusstvennyye-neyronnyye-seti.html">"Introdu√ß√£o ao aprendizado de m√°quina e redes neurais artificiais"</a> . </li><li>  <a href="">Ferramentas √∫teis</a> onde todos encontrar√£o algo interessante para si. </li><li>  Os <strong>canais de v√≠deo para a an√°lise de artigos cient√≠ficos</strong> sobre Data Science foram extremamente √∫teis.  Encontre, assine e envie links para seus colegas e para mim tamb√©m.  Exemplos: <br><ul><li>  <a href="https://www.youtube.com/user/keeroyz">Artigos de dois minutos</a> </li><li>  <a href="https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw">Henry AI Labs</a> </li><li>  <a href="https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew">Yannic kilcher</a> </li><li>  <a href="https://www.youtube.com/channel/UC5_6ZD6s8klmMu9TXEB_1IA">CodeEmporium</a> </li><li>  <a href="https://www.dlology.com/">Chengwei Zhang</a> aka <a href="https://github.com/Tony607">Tony607 blog</a> com instru√ß√µes passo a passo e c√≥digo aberto. </li></ul></li></ul><br><p>  Obrigado pela aten√ß√£o! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt482794/">https://habr.com/ru/post/pt482794/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt482780/index.html">Experimentos com redes neurais baseadas em dados s√≠smicos</a></li>
<li><a href="../pt482784/index.html">A vida secreta de um servidor Linux ou ataque de for√ßa bruta de f√£ no subsistema SSH</a></li>
<li><a href="../pt482786/index.html">Enigma n√£o resolvido</a></li>
<li><a href="../pt482790/index.html">Esque√ßa a criptografia homom√≥rfica: agora temos a criptografia funcional</a></li>
<li><a href="../pt482792/index.html">Projeto ITER em 2019</a></li>
<li><a href="../pt482798/index.html">Veja a floresta atr√°s das √°rvores</a></li>
<li><a href="../pt482800/index.html">Minhas pesquisas pelo painel de controle f√≠sico de uma casa inteligente</a></li>
<li><a href="../pt482802/index.html">Inclus√£o remota de scripts Mikrotik do Telegram v 2.0</a></li>
<li><a href="../pt482804/index.html">Java: recolher logs de v√°rias linhas em um log de linha √∫nica usando Spring e Logback ou Log4j2</a></li>
<li><a href="../pt482806/index.html">A propaganda do regime totalit√°rio, anti-semitismo e homofobia no livro de 2019 sobre programa√ß√£o? - √© poss√≠vel</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
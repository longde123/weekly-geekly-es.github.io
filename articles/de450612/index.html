<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚ÄçüöÄ ü§¶üèø üçò Intro Newton Protocol: Was passt in 4 Kilobyte üëß üë©üèæ‚Äçüî¨ ü§æ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich habe k√ºrzlich an der Demo-Szene Revision 2019 in der Kategorie PC 4k-Intro teilgenommen und mein Intro hat den ersten Platz gewonnen. Ich habe Cod...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Intro Newton Protocol: Was passt in 4 Kilobyte</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450612/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bfa/bba/a35/bfabbaa350d27446b3b058ce41e73228.png" alt="Bild"></div><br>  Ich habe k√ºrzlich an der Demo-Szene Revision 2019 in der Kategorie PC 4k-Intro teilgenommen und mein Intro hat den ersten Platz gewonnen.  Ich habe Codierung und Grafik gemacht und Dixan hat Musik komponiert.  Die Grundregel des Wettbewerbs besteht darin, eine ausf√ºhrbare Datei oder Website mit einer Gr√∂√üe von nur 4096 Byte zu erstellen.  Dies bedeutet, dass alles mithilfe von Mathematik und Algorithmen generiert werden muss.  Auf keine andere Weise kann ich Bilder, Video und Audio in so wenig Speicher komprimieren.  In diesem Artikel werde ich √ºber die Rendering-Pipeline meines Newton-Intro-Intro sprechen.  Unten k√∂nnen Sie das fertige Ergebnis sehen oder <a href="">hier klicken, um</a> zu sehen, wie es bei Revision live aussah, oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gehen Sie zu pouet</a> , um das Intro, das am Wettbewerb <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">teilgenommen hat,</a> zu kommentieren und herunterzuladen.  √úber die Arbeit und Korrekturen der Wettbewerber k√∂nnen Sie hier <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lesen</a> . <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/iIIu7kPCN-8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  Die Ray-Marschdistanz-Feldtechnik ist in der 4k-Intro-Disziplin sehr beliebt, da Sie damit komplexe Formen in nur wenigen Codezeilen angeben k√∂nnen.  Der Nachteil dieses Ansatzes ist jedoch die Ausf√ºhrungsgeschwindigkeit.  Um die Szene zu rendern, m√ºssen Sie den Schnittpunkt der Strahlen mit der Szene finden, zuerst bestimmen, was Sie sehen, beispielsweise einen Strahl von der Kamera, und dann nachfolgende Strahlen vom Objekt zu den Lichtquellen, um die Beleuchtung zu berechnen.  Wenn Sie mit Ray Marching arbeiten, k√∂nnen diese Schnittpunkte nicht in einem Schritt gefunden werden. Sie m√ºssen viele kleine Schritte entlang des Strahls ausf√ºhren und alle Objekte an jedem Punkt bewerten.  Wenn Sie Raytracing verwenden, k√∂nnen Sie den genauen Schnittpunkt finden, indem Sie jedes Objekt nur einmal √ºberpr√ºfen. Die Menge der Formen, die verwendet werden k√∂nnen, ist jedoch sehr begrenzt: Sie ben√∂tigen f√ºr jeden Typ eine Formel, um den Schnittpunkt mit dem Strahl zu berechnen. <br><br>  In diesem Intro wollte ich eine sehr genaue Beleuchtung simulieren.  Da es notwendig war, Millionen von Strahlen in der Szene zu reflektieren, schien die Strahlverfolgung eine logische Wahl zu sein, um diesen Effekt zu erzielen.  Ich habe mich auf eine einzelne Figur beschr√§nkt - eine Kugel, weil der Schnittpunkt eines Strahls und einer Kugel ganz einfach berechnet wird.  Sogar die W√§nde im Intro sind eigentlich sehr gro√üe Kugeln.  Dar√ºber hinaus vereinfachte es die Simulation der Physik;  es gen√ºgte, nur Konflikte zwischen den Sph√§ren zu ber√ºcksichtigen. <br><br>  Um die Menge an Code zu veranschaulichen, die in 4096 Bytes passt, habe ich unten den vollst√§ndigen Quellcode des fertigen Intro vorgestellt.  Alle Teile au√üer dem HTML-Code am Ende werden als PNG-Bild codiert, um sie auf eine kleinere Gr√∂√üe zu komprimieren.  Ohne diese Komprimierung h√§tte der Code fast 8900 Bytes ben√∂tigt.  Der Teil namens Synth ist eine abgespeckte Version von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SoundBox</a> .  Um den Code in diesem minimierten Format zu verpacken, habe ich den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Closure Compiler</a> und den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shader Minifier verwendet</a> .  Am Ende wird fast alles mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JsExe</a> in PNG <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">komprimiert</a> .  Die vollst√§ndige Kompilierungspipeline ist im Quellcode meines vorherigen 4k-Intro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Core Critical zu sehen</a> , da sie vollst√§ndig mit der hier vorgestellten √ºbereinstimmt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e5b/274/690/e5b27469046c9c34bfb14fc2fbe33fa5.png"></div><br>  <i>Musik und Synthesizer sind vollst√§ndig in Javascript implementiert.</i>  <i>Der Teil in WebGL ist in zwei Teile unterteilt (im Code gr√ºn hervorgehoben).</i>  <i>Sie richtet die Render-Pipeline ein.</i>  <i>Die Elemente Physik und Raytracer sind GLSL-Shader.</i>  <i>Der Rest des Codes wird in einem PNG-Bild codiert und HTML wird unver√§ndert am Ende des resultierenden Bildes hinzugef√ºgt.</i>  <i>Der Browser ignoriert Bilddaten und f√ºhrt nur HTML-Code aus, der PNG wieder in Javascript dekodiert und ausf√ºhrt.</i> <br><br><h3>  Pipeline rendern </h3><br>  Das Bild unten zeigt die Rendering-Pipeline.  Es besteht aus zwei Teilen.  Der erste Teil der Pipeline ist ein Physiksimulator.  Die Intro-Szene enth√§lt 50 Kugeln, die im Raum miteinander kollidieren.  Der Raum selbst besteht aus sechs Kugeln, von denen einige kleiner als andere sind, um mehr gekr√ºmmte W√§nde zu schaffen.  Zwei vertikale Beleuchtungsquellen in den Ecken sind ebenfalls Kugeln, dh insgesamt 58 Kugeln in der Szene.  Der zweite Teil der Pipeline ist der Ray Tracer, der die Szene rendert.  Das folgende Diagramm zeigt das Rendern eines Frames zum Zeitpunkt t.  Die Physiksimulation nimmt den vorherigen Frame (t-1) und simuliert den aktuellen Zustand.  Der Raytracer nimmt die aktuellen Positionen und Positionen des vorherigen Frames (f√ºr den Geschwindigkeitskanal) auf und rendert die Szene.  Anschlie√üend kombiniert die Nachbearbeitung die vorherigen 5 Frames und den aktuellen Frame, um Verzerrungen und Rauschen zu reduzieren, und erstellt dann ein fertiges Ergebnis. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f6a/848/ac0/f6a848ac09343ca15abfd03393a7ceeb.png"></div><br>  <i>Rendern eines Frames zum Zeitpunkt t.</i> <br><br>  Der physikalische Teil ist recht einfach. Im Internet finden Sie viele Tutorials zum Erstellen primitiver Simulationen f√ºr Kugeln.  Position, Radius, Geschwindigkeit und Masse werden in zwei Texturen mit einer Aufl√∂sung von 1 x 58 gespeichert. Ich habe die Webgl 2-Funktion verwendet, mit der mehrere Renderziele gerendert werden k√∂nnen, sodass die Daten zweier Texturen gleichzeitig aufgezeichnet werden.  Die gleiche Funktionalit√§t wird vom Raytracer verwendet, um drei Texturen zu erstellen.  Webgl bietet keinen Zugriff auf die Raytracing-APIs NVidia RTX oder DirectX Raytracing (DXR), sodass alles von Grund auf neu erfolgt. <br><br><h3>  Ray Tracer </h3><br>  Raytracing selbst ist eine ziemlich primitive Technik.  Wir geben einen Strahl in die Szene ab, er wird viermal reflektiert, und wenn er in die Lichtquelle gelangt, sammelt sich die Farbe der Reflexionen an.  sonst werden wir schwarz.  In 4096 Bytes (einschlie√ülich Musik, Synthesizer, Physik und Rendering) ist kein Platz f√ºr die Erstellung komplexer beschleunigender Raytracing-Strukturen.  Daher verwenden wir die Brute-Force-Methode, dh wir √ºberpr√ºfen alle 57 Kugeln (die Vorderwand ist ausgeschlossen) f√ºr jeden Strahl, ohne Optimierungen vorzunehmen, um einen Teil der Kugeln auszuschlie√üen.  Dies bedeutet, dass Sie f√ºr 60 Bilder pro Sekunde in einer Aufl√∂sung von 1080p nur 2-6 Strahlen oder Samples pro Pixel emittieren k√∂nnen.  Dies ist nah genug, um eine gleichm√§√üige Beleuchtung zu erzeugen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b23/2ce/72d/b232ce72d49f57a69b96d402ec0bb148.png"></div><br>  <i>1 Abtastung pro Pixel.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e52/77d/19e/e5277d19e5a7b897b8dd9046eaae6f26.png"></div><br>  <i>6 Samples pro Pixel.</i> <br><br>  Wie gehe ich damit um?  Zuerst habe ich den Raytracing-Algorithmus untersucht, aber er wurde bereits auf den Punkt gebracht.  Ich habe es geschafft, die Leistung leicht zu steigern, indem ich F√§lle eliminierte, in denen der Strahl innerhalb der Kugel beginnt, da solche F√§lle nur bei Vorhandensein von Transparenzeffekten anwendbar sind und nur undurchsichtige Objekte in unserer Szene vorhanden waren.  Danach habe ich jede if-Bedingung in einer separaten Anweisung zusammengefasst, um unn√∂tige Verzweigungen zu vermeiden: Trotz der ‚Äûredundanten‚Äú Berechnungen ist dieser Ansatz immer noch schneller als eine Reihe von bedingten Anweisungen.  Es war auch m√∂glich, das Abtastmuster zu verbessern: Anstatt Strahlen zuf√§llig zu emittieren, konnten wir sie in einem gleichm√§√üigeren Muster √ºber die Szene verteilen.  Leider hat dies nicht geholfen und zu welligen Artefakten in jedem Algorithmus gef√ºhrt, den ich ausprobiert habe.  Dieser Ansatz f√ºhrte jedoch zu guten Ergebnissen f√ºr Standbilder.  Infolgedessen kehrte ich zu einer v√∂llig zuf√§lligen Verteilung zur√ºck. <br><br>  Benachbarte Pixel sollten eine sehr √§hnliche Beleuchtung haben. Warum also nicht bei der Berechnung der Beleuchtung eines einzelnen Pixels verwenden?  Wir m√∂chten keine Texturen verwischen, sondern nur die Beleuchtung. Daher m√ºssen wir sie in separaten Kan√§len rendern.  Au√üerdem m√∂chten wir keine Objekte verwischen. Daher m√ºssen wir die Kennungen von Objekten ber√ºcksichtigen, um zu wissen, welche Pixel leicht verwischt werden k√∂nnen.  Da wir lichtreflektierende Objekte haben und klare Reflexionen ben√∂tigen, reicht es nicht aus, nur die ID des ersten Objekts herauszufinden, mit dem der Strahl kollidiert.  Ich habe einen Sonderfall f√ºr reine reflektierende Materialien verwendet, um auch die IDs des ersten und zweiten Objekts, die in Reflexionen sichtbar sind, in den Objektidentifizierungskanal aufzunehmen.  In diesem Fall kann durch Unsch√§rfe die Beleuchtung von Objekten in Reflexionen gegl√§ttet werden, w√§hrend gleichzeitig die Grenzen von Objekten beibehalten werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f69/a24/a6b/f69a24a6b9094903309af27b5606e923.png"></div><br>  <i>Texturkanal, wir m√ºssen ihn nicht verwischen.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a4f/c4a/7f6/a4fc4a7f6ec4fa0552542edf7204cb58.png"></div><br>  <i>Hier im roten Kanal befindet sich die ID des ersten Objekts, in gr√ºn - das zweite und in blau - das dritte.</i>  <i>In der Praxis werden sie alle in einen einzigen Gleitkommawert codiert, in dem der ganzzahlige Teil die Kennungen von Objekten speichert und der gebrochene Teil die Rauheit anzeigt: 332211.RR.</i> <br><br>  Da es in der Szene Objekte mit unterschiedlicher Rauheit gibt (einige Bereiche sind rau, das Licht wird auf andere gestreut, im dritten gibt es eine Spiegelreflexion), speichere ich die Rauheit, um den Unsch√§rferadius zu steuern.  Da die Szene keine kleinen Details enth√§lt, habe ich einen gro√üen 50 x 50-Kern mit den Gewichten in Form von inversen Quadraten zum Verwischen verwendet.  Der Weltraum wird nicht ber√ºcksichtigt (dies k√∂nnte realisiert werden, um genauere Ergebnisse zu erzielen), da auf Oberfl√§chen, die in einigen Richtungen in einem Winkel angeordnet sind, ein gr√∂√üerer Bereich erodiert wird.  Eine solche Unsch√§rfe erzeugt ein ziemlich glattes Bild, aber Artefakte sind insbesondere in Bewegung deutlich sichtbar. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ca6/553/f9d/ca6553f9d61bc8f7dda51ba41c2cbf28.png"></div><br>  <i>Beleuchtungskanal mit Unsch√§rfe und immer noch auff√§lligen Artefakten.</i>  <i>In diesem Bild sind verschwommene Punkte an der R√ºckwand sichtbar, die durch einen kleinen Fehler mit den Kennungen des zweiten reflektierten Objekts verursacht werden (die Strahlen verlassen die Szene).</i>  <i>Auf dem fertigen Bild ist dies nicht sehr auff√§llig, da klare Reflexionen vom Texturkanal aufgenommen werden.</i>  <i>Lichtquellen werden auch verschwommen, aber ich mochte diesen Effekt und habe ihn verlassen.</i>  <i>Falls gew√ºnscht, kann dies verhindert werden, indem die Kennungen von Objekten je nach Material ge√§ndert werden.</i> <br><br>  Wenn sich Objekte in der Szene befinden und die Kamera die Szene langsam aufnimmt, sollte die Beleuchtung in jedem Bild konstant bleiben.  Daher k√∂nnen wir nicht nur die XY-Koordinaten des Bildschirms verwischen.  wir k√∂nnen in der Zeit verschwimmen.  Wenn wir davon ausgehen, dass sich die Beleuchtung in 100 ms nicht zu stark √§ndert, k√∂nnen wir sie f√ºr 6 Bilder mitteln.  W√§hrend dieses Zeitfensters bewegen sich die Objekte und die Kamera jedoch noch ein St√ºck weit, sodass eine einfache Berechnung des Durchschnitts f√ºr 6 Bilder ein sehr verschwommenes Bild ergibt.  Wir wissen jedoch, wo sich alle Objekte und die Kamera in der vorherigen Karte befanden, sodass wir die Geschwindigkeitsvektoren im Bildschirmbereich berechnen k√∂nnen.  Dies wird als vor√ºbergehende Projektion bezeichnet.  Wenn ich zum Zeitpunkt t ein Pixel habe, kann ich die Geschwindigkeit dieses Pixels nehmen und berechnen, wo es zum Zeitpunkt t-1 war, und dann berechnen, wo sich das Pixel zum Zeitpunkt t-1 zum Zeitpunkt t-2 befindet, und so weiter. 5 Frames zur√ºck.  Im Gegensatz zur Unsch√§rfe im Bildschirmbereich habe ich f√ºr jedes Bild das gleiche Gewicht verwendet, d. H.  hat gerade die Farbe zwischen allen Frames gemittelt, um eine vor√ºbergehende ‚ÄûUnsch√§rfe‚Äú zu erzielen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1fc/a4c/e42/1fca4ce4250f372223862a34472add21.png"></div><br>  <i>Ein Pixelgeschwindigkeitskanal, der basierend auf der Bewegung des Objekts und der Kamera meldet, wo sich das Pixel im letzten Frame befand.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/011/bb5/1f6/011bb51f60e3b3066c87ee4a1d46d403.png"></div><br>  <i>Um ein gemeinsames Verwischen von Objekten zu vermeiden, verwenden wir erneut den Kanal der Objektkennungen.</i>  <i>In diesem Fall betrachten wir nur das erste Objekt, mit dem der Strahl kollidierte.</i>  <i>Dies stellt ein Anti-Aliasing innerhalb des Objekts bereit, d.h.</i>  <i>in Reflexionen.</i> <br><br>  Nat√ºrlich war das Pixel im vorherigen Frame m√∂glicherweise nicht sichtbar.  Es kann von einem anderen Objekt ausgeblendet oder au√üerhalb des Sichtfelds der Kamera liegen.  In solchen F√§llen k√∂nnen wir die vorherigen Informationen nicht verwenden.  Diese Pr√ºfung wird f√ºr jeden Frame separat durchgef√ºhrt, sodass wir 1 bis 6 Samples oder Frames pro Pixel erhalten und die m√∂glichen verwenden.  Die folgende Abbildung zeigt, dass dies f√ºr langsame Objekte kein sehr ernstes Problem ist. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c5b/c89/8fc/c5bc898fc8ac6ff9b5a0c8685312604f.png"></div><br>  <i>Wenn Objekte sich bewegen und neue Teile der Szene √∂ffnen, verf√ºgen wir nicht √ºber 6 Informationsrahmen, um diese f√ºr diese Teile zu mitteln.</i>  <i>Dieses Bild zeigt Bereiche mit 6 Rahmen (wei√ü) sowie Bereiche ohne diese (allm√§hlich dunkler werdende Schattierungen).</i>  <i>Das Auftreten der Konturen wird durch die Randomisierung der Abtastorte f√ºr das Pixel in jedem Rahmen und die Tatsache verursacht, dass wir die Kennung des Objekts aus der ersten Stichprobe entnehmen.</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/570/c4c/b4a/570c4cb4a84f008a497678b0b735930e.png"></div><br>  <i>Verschwommenes Licht wird √ºber sechs Bilder gemittelt.</i>  <i>Artefakte sind nahezu unsichtbar und das Ergebnis ist √ºber die Zeit stabil, da in jedem Bild nur ein Bild von sechs √Ñnderungen, bei denen die Beleuchtung ber√ºcksichtigt wird, ber√ºcksichtigt wird.</i> <br><br>  Wenn wir all dies kombinieren, erhalten wir ein fertiges Bild.  Die Beleuchtung wird auf benachbarte Pixel verwischt, w√§hrend Texturen und Reflexionen klar bleiben.  All dies wird dann zwischen sechs Bildern gemittelt, um im Laufe der Zeit ein noch glatteres und stabileres Bild zu erzeugen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bfa/bba/a35/bfabbaa350d27446b3b058ce41e73228.png"></div><br>  <i>Das fertige Bild.</i> <br><br>  D√§mpfungsartefakte sind immer noch erkennbar, da ich mehrere Abtastwerte pro Pixel gemittelt habe, obwohl ich den Kanal der Objektkennung und die Geschwindigkeit f√ºr die erste Kreuzung verwendet habe.  Sie k√∂nnen versuchen, dies zu beheben und die Reflexionen zu gl√§tten, indem Sie die Proben verwerfen, wenn sie nicht mit der ersten √ºbereinstimmen oder zumindest wenn die erste Kollision nicht in der richtigen Reihenfolge √ºbereinstimmt.  In der Praxis sind die Spuren fast unsichtbar, so dass ich mich nicht darum gek√ºmmert habe, sie zu beseitigen.  Die Grenzen von Objekten sind ebenfalls verzerrt, da die Kan√§le f√ºr Geschwindigkeit und Objektkennungen nicht gegl√§ttet werden k√∂nnen.  Ich habe √ºber die M√∂glichkeit nachgedacht, das gesamte Bild mit 2160p mit einer weiteren Reduzierung des Ma√üstabs auf 1080p zu rendern, aber meine NVidia GTX 980ti ist nicht in der Lage, solche Aufl√∂sungen mit 60fps zu verarbeiten, und habe mich daher entschlossen, diese Idee aufzugeben. <br><br>  Im Allgemeinen bin ich sehr zufrieden mit dem Ergebnis des Intro.  Ich habe es geschafft, alles, was ich vorhatte, hineinzuquetschen, und trotz kleinerer Fehler war das Endergebnis von sehr hoher Qualit√§t.  In Zukunft k√∂nnen Sie versuchen, Fehler zu beheben und das Anti-Aliasing zu verbessern.  Es lohnt sich auch, mit Funktionen wie Transparenz, Bewegungsunsch√§rfe, verschiedenen Formen und Objekttransformationen zu experimentieren. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ba9/f56/e02/ba9f56e02c13d046f73e888540a0d75e.png"></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de450612/">https://habr.com/ru/post/de450612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de450602/index.html">‚ÄûWie wir IaaS bauen‚Äú: 1wolkenmaterialien</a></li>
<li><a href="../de450604/index.html">Milliarden einfacher Zahlen schneller heraussieben als Wikipedia</a></li>
<li><a href="../de450606/index.html">Ein Tag im Leben eines Restaurantmodells</a></li>
<li><a href="../de450608/index.html">Verdammt unter uns</a></li>
<li><a href="../de450610/index.html">Thermoakustik. Stromerzeugung aus Schall √ºber einen Lautsprecher</a></li>
<li><a href="../de450614/index.html">April 2019 Joomla Digest</a></li>
<li><a href="../de450618/index.html">Warum sind Programmierer laut Statistiken von Yandex und StackOverfow C # die billigsten?</a></li>
<li><a href="../de450620/index.html">R√§tsel eines Neutrinos aus Supernova 1987A</a></li>
<li><a href="../de450624/index.html">Gru√ü von Hayabusa-2</a></li>
<li><a href="../de450626/index.html">Designmuster korrigieren - Singleton in PHP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
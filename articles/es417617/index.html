<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç© üè∞ ü§≤üèø Cassandra por almacenar metadatos: √©xitos y fracasos üß° ü§∑üèΩ üç≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬øQu√© requisitos debe cumplir el almacenamiento de metadatos para un servicio en la nube? S√≠, no el m√°s com√∫n, pero para empresas con soporte para cent...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cassandra por almacenar metadatos: √©xitos y fracasos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/417617/"> ¬øQu√© requisitos debe cumplir el almacenamiento de metadatos para un servicio en la nube?  S√≠, no el m√°s com√∫n, pero para empresas con soporte para centros de datos distribuidos geogr√°ficamente y Active-Active.  Obviamente, el sistema deber√≠a escalar bien, ser <strong>tolerante a fallas y desear√≠a poder implementar una consistencia de operaciones personalizable.</strong> <br><br>  Solo Cassandra es adecuada para todos estos requisitos, y nada m√°s es adecuado.  Cabe se√±alar que Cassandra es realmente genial, pero trabajar con ella se parece a una monta√±a rusa. <br><img src="https://habrastorage.org/webt/zs/tw/jb/zstwjb6bvwlg43rmuphw91_jtrm.jpeg"><br><br>  En un informe en Highload ++ 2017, <strong>Andrei Smirnov</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">smira</a> ) decidi√≥ que no era interesante hablar sobre el bien, pero habl√≥ en detalle sobre cada problema que tuvo que enfrentar: sobre la p√©rdida de datos y la corrupci√≥n, sobre los zombis y la p√©rdida de rendimiento.  Estas historias son una verdadera reminiscencia de la monta√±a rusa, pero para todos los problemas hay una soluci√≥n, para la cual eres bienvenido. <br><br>  <strong><em>Sobre el orador:</em></strong> Andrey Smirnov trabaja para Virtustream, una compa√±√≠a que implementa almacenamiento en la nube para empresas.  La idea es que, condicionalmente, Amazon hace la nube para todos, y Virtustream hace las cosas espec√≠ficas que necesita una gran empresa. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SAyClLjN6Sk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  Algunas palabras sobre Virtustream </h1><br>  Trabajamos en un peque√±o equipo completamente remoto y estamos involucrados en una de las soluciones en la nube de Virtustream.  Esta es una nube de almacenamiento de datos. <br><img src="https://habrastorage.org/webt/bo/rc/jh/borcjhczgtiycqzx8dz0bnh9zim.jpeg"><br><br>  Hablando de manera muy simple, esta es una API compatible con S3 en la que puede almacenar objetos.  Para aquellos que no saben qu√© es S3, es solo una API HTTP con la que puedes subir objetos a la nube en alg√∫n lugar, recuperarlos, eliminarlos, obtener una lista de objetos, etc.  Adem√°s, caracter√≠sticas m√°s complejas basadas en estas operaciones simples. <br><br>  Tenemos algunas caracter√≠sticas distintivas que Amazon no tiene.  Una de ellas son las llamadas georegiones.  En la situaci√≥n habitual, cuando crea un repositorio y dice que almacenar√° objetos en la nube, debe seleccionar una regi√≥n.  Una regi√≥n es esencialmente un centro de datos, y sus objetos nunca abandonar√°n este centro de datos.  Si algo le sucede, tus objetos ya no estar√°n disponibles. <br><br>  Ofrecemos geo-regiones en las que los datos se ubican simult√°neamente en varios centros de datos (DC), al menos en dos, como en la imagen.  El cliente puede contactar con cualquier centro de datos, para √©l es transparente.  Los datos entre ellos se replican, es decir, trabajamos en el modo Activo-Activo, y constantemente.  Esto proporciona al cliente caracter√≠sticas adicionales, que incluyen: <br><br><ol><li>  mayor confiabilidad de almacenamiento, lectura y escritura en caso de falla de CC o p√©rdida de conectividad; <br></li><li>  disponibilidad de datos incluso si uno de los DC falla; <br></li><li>  operaciones de redireccionamiento al DC "m√°s cercano". <br></li></ol><br>  Esta es una oportunidad interesante, incluso si estos DC est√°n geogr√°ficamente separados, entonces algunos de ellos pueden estar m√°s cerca del cliente en diferentes momentos.  Y acceder a los datos al DC m√°s cercano es simplemente m√°s r√°pido. <br><img src="https://habrastorage.org/webt/k-/ry/dl/k-rydl_mt74-eybwakpv1dpqjum.jpeg"><br><br>  Para dividir la construcci√≥n de la que hablaremos en partes, presentar√© los objetos que est√°n almacenados en la nube como dos piezas grandes: <br><br>  1. La primera pieza simple de un objeto son los <strong>datos</strong> .  No han cambiado, se descargaron una vez y eso es todo.  Lo √∫nico que puede sucederles m√°s tarde es que podemos eliminarlos si ya no son necesarios. <br><br>  Nuestro proyecto anterior estaba relacionado con el almacenamiento de exabytes de datos, por lo que no tuvimos problemas con el almacenamiento de datos.  Esto ya era una tarea resuelta para nosotros. <br><br>  2. <strong>Metadatos</strong> .  Toda la l√≥gica empresarial, todo lo m√°s interesante, relacionado con la competencia: acceso, registros, reescrituras, en el √°rea de metadatos. <br><br>  Los metadatos sobre el objeto toman en s√≠ la mayor complejidad del proyecto, los metadatos almacenan un puntero al bloque de datos almacenados del objeto. <br><br>  Desde el punto de vista del usuario, este es un objeto √∫nico, pero podemos dividirlo en dos partes.  Hoy <strong>solo</strong> hablar√© <strong>sobre metadatos</strong> . <br><br><h2>  Figuras <br></h2><br><ul><li>  <strong>Datos</strong> : 4 Pbytes. </li><li>  <strong>Grupos de metadatos</strong> : 3. </li><li>  <strong>Objetos</strong> : 40 mil millones. </li><li>  <strong>Tama√±o de metadatos</strong> : 160 TB (incluida la replicaci√≥n). </li><li>  <strong>Velocidad de cambio (metadatos):</strong> 3000 objetos / s. </li></ul><br>  Si observa estos indicadores con cuidado, lo primero que llama la atenci√≥n es el tama√±o promedio muy peque√±o del objeto almacenado.  Tenemos muchos metadatos por unidad de volumen de datos maestros.  Para nosotros no fue menos sorprendente que quiz√°s para ti ahora. <br><br>  Planeamos que tendr√≠amos al menos un orden de datos, si no 2, m√°s que metadatos.  Es decir, cada objeto ser√° significativamente m√°s grande y la cantidad de metadatos ser√° menor.  Debido a que los datos son m√°s baratos de almacenar, menos operaciones con ellos y los metadatos son mucho m√°s caros tanto en el sentido del hardware como en el sentido de dar servicio y realizar varias operaciones en ellos. <br><br>  Adem√°s, estos datos cambian a una velocidad bastante alta.  He dado el valor pico aqu√≠, el valor no pico no es mucho menor, pero, sin embargo, se puede obtener una carga bastante grande en puntos espec√≠ficos en el tiempo. <br><br>  Estas cifras ya se obtuvieron de un sistema en funcionamiento, pero volvamos un poco al dise√±o de almacenamiento en la nube. <br><br><h1>  Elegir un repositorio para metadatos </h1><br>  Cuando nos enfrentamos al desaf√≠o de que queremos tener geo-regiones, Active-Active, y necesitamos almacenar metadatos en alg√∫n lugar, pensamos que podr√≠a ser. <br><br>  Obviamente, el repositorio (base de datos) debe tener las siguientes propiedades: <br><br><ul><li>  <strong>Soporte activo-activo</strong> ; </li><li>  <strong>Escalabilidad.</strong> </li></ul><br>  Realmente nos gustar√≠a que nuestro producto sea extremadamente popular, y no sabemos c√≥mo crecer√° al mismo tiempo, por lo que el sistema deber√≠a escalar. <br><br><ul><li>  <strong>El equilibrio de tolerancia a fallos y fiabilidad de almacenamiento.</strong> </li></ul><br>  Los metadatos deben almacenarse de forma segura, porque si los perdemos y hab√≠a un enlace a los datos en ellos, perderemos todo el objeto. <br><br><ul><li>  <strong>Consistencia de operaciones personalizable.</strong> </li></ul><br>  Debido al hecho de que trabajamos en varios DC y permitimos la posibilidad de que los DC no est√©n disponibles, adem√°s, los DC est√°n lejos unos de otros, no podemos, durante la mayor√≠a de las operaciones API, exigir que esta operaci√≥n se realice simult√°neamente en dos DC  Ser√° demasiado lento e imposible si el segundo DC no est√° disponible.  Por lo tanto, parte de las operaciones deber√≠an funcionar localmente en un DC. <br><br>  Pero, obviamente, alg√∫n tipo de convergencia deber√≠a ocurrir en alg√∫n momento, y despu√©s de resolver todos los conflictos, los datos deber√≠an ser visibles en ambos centros de datos.  Por lo tanto, la consistencia de las operaciones debe ser ajustada. <br><br>  Desde mi punto de vista, Cassandra es adecuada para estos requisitos. <br><br><h1>  Cassandra </h1><br>  Estar√≠a muy feliz si no tuvi√©ramos que usar Cassandra, porque para nosotros fue una especie de experiencia nueva.  Pero nada m√°s es adecuado.  Esto, me parece, es la situaci√≥n m√°s triste en el mercado para tales sistemas de almacenamiento, no hay <strong>alternativa</strong> . <br><br><img src="https://habrastorage.org/webt/ge/l-/xo/gel-xoykdx5yx1-sb36hjinlsas.jpeg"><br><br><h3>  ¬øQu√© es cassandra? <br></h3><br>  Esta es una base de datos distribuida de clave-valor.  Desde el punto de vista de la arquitectura y las ideas que est√°n incrustadas en ella, me parece que todo es genial.  Si lo hiciera, har√≠a lo mismo.  Cuando comenzamos, pensamos en escribir nuestro propio sistema de almacenamiento de metadatos.  Pero cuanto m√°s lejos, m√°s y m√°s nos dimos cuenta de que tendr√≠amos que hacer algo muy similar a Cassandra, y los esfuerzos que gastaremos en ello no valen la pena.  Para todo el desarrollo <strong>, solo tuvimos un mes y medio</strong> .  Ser√≠a extra√±o gastarlos escribiendo su base de datos. <br><br>  Si Cassandra estuviera en capas como un pastel de capas, seleccionar√≠a 3 capas: <br><br>  1. <strong>Almacenamiento local de KV en cada nodo.</strong> <br>  Este es un grupo de nodos, cada uno de los cuales puede almacenar datos de valor clave localmente. <br><br>  2. <strong>Fragmentaci√≥n de datos en nodos (hashing consistente).</strong> <br>  Cassandra puede distribuir datos entre los nodos del cl√∫ster, incluida la replicaci√≥n, y lo hace de tal manera que el cl√∫ster puede crecer o disminuir de tama√±o, y los datos se redistribuir√°n. <br><br>  3. Un <strong>coordinador para redirigir las solicitudes a otros nodos.</strong> <br>  Cuando accedemos a los datos para algunas consultas desde nuestra aplicaci√≥n, Cassandra puede distribuir nuestra consulta en nodos para que obtengamos los datos que queremos y con el nivel de consistencia que necesitamos: queremos leerlos solo qu√≥rum, o quiere qu√≥rum con dos DC, etc. <br><img src="https://habrastorage.org/webt/zs/tw/jb/zstwjb6bvwlg43rmuphw91_jtrm.jpeg"><br><br>  Para nosotros, dos a√±os con Cassandra, es una monta√±a rusa o una monta√±a rusa, lo que quieras.  Todo comenz√≥ en el fondo, no ten√≠amos experiencia con Cassandra.  Ten√≠amos miedo  Empezamos, y todo estuvo bien.  Pero luego comienzan las ca√≠das constantes y los despegues: el problema, todo est√° mal, no sabemos qu√© hacer, tenemos errores, luego resolvemos el problema, etc. <br><br>  Estas monta√±as rusas, en principio, no terminan hasta el d√≠a de hoy. <br><br><h1>  Bueno </h1><br>  El primer y √∫ltimo cap√≠tulo, donde digo que Cassandra es genial.  Es realmente genial, un gran sistema, pero si sigo diciendo lo bueno que es, creo que no te interesar√°.  Por lo tanto, prestaremos m√°s atenci√≥n a lo malo, pero m√°s tarde. <br><br>  Cassandra es realmente buena. <br><br><ul><li>  Este es uno de los sistemas que nos permite tener <strong>un tiempo de respuesta en milisegundos</strong> , es decir, obviamente menos de 10 ms.  Esto es bueno para nosotros, porque el tiempo de respuesta en general es importante para nosotros.  La operaci√≥n con metadatos para nosotros es solo una parte de cualquier operaci√≥n relacionada con el almacenamiento de un objeto, ya sea que est√© recibiendo o grabando. </li><li>  Desde el punto de vista de la grabaci√≥n, <strong>se</strong> logra una <strong>alta escalabilidad</strong> .  Puede escribir en Cassandra a una velocidad loca, y en algunas situaciones esto es necesario, por ejemplo, cuando movemos grandes cantidades de datos entre registros. </li><li>  Cassandra es verdaderamente <strong>tolerante a fallas</strong> .  La ca√≠da de un nodo no conduce inmediatamente a problemas, aunque tarde o temprano comenzar√°n.  Cassandra declara que no tiene un solo punto de falla, pero, de hecho, hay puntos de falla en todas partes.  De hecho, el que trabaj√≥ con la base de datos sabe que incluso un bloqueo de nodo no es algo que generalmente sufre hasta la ma√±ana.  Por lo general, esta situaci√≥n debe repararse m√°s r√°pido. </li><li>  <strong>Simplicidad</strong>  A√∫n as√≠, en comparaci√≥n con otras bases de datos relacionales est√°ndar de Cassandra, es m√°s f√°cil entender lo que est√° sucediendo.  Muy a menudo, algo sale mal y necesitamos entender lo que est√° sucediendo.  Cassandra tiene m√°s posibilidades de resolverlo, llegar al tornillo m√°s peque√±o, probablemente, que con otra base de datos. </li></ul><br><h1>  Cinco malas historias </h1><br>  Repito, Cassandra es buena, funciona para nosotros, pero contar√© cinco historias sobre lo malo.  Creo que esto es para lo que lo le√≠ste.  Dar√© las historias en orden cronol√≥gico, aunque no est√°n muy conectadas entre s√≠. <br><img src="https://habrastorage.org/webt/ao/15/oa/ao15oaiwdhwvl4w4u5pvcgwolrq.jpeg"><br><br>  Esta historia fue la m√°s triste para nosotros.  Como almacenamos datos de usuarios, lo peor posible es perderlos y <strong>perderlos para siempre</strong> , como sucedi√≥ en esta situaci√≥n.  Hemos proporcionado formas de recuperar datos si los perdemos en Cassandra, pero los perdimos para que realmente no pudi√©ramos recuperarlos. <br><br>  Para explicar c√≥mo sucede esto, tendr√© que hablar un poco sobre c√≥mo se organiza todo dentro de nosotros. <br><img src="https://habrastorage.org/webt/6i/vf/gk/6ivfgkdspndo3kzyy153iveq4xq.jpeg"><br><br>  Desde una perspectiva S3, hay algunas cosas b√°sicas: <br><br><ul><li>  Bucket: se puede imaginar como un gran cat√°logo en el que el usuario carga un objeto (en adelante, el bucket). </li><li>  Cada objeto tiene un nombre (clave) y metadatos asociados: tama√±o, tipo de contenido y un puntero a los datos del objeto.  Al mismo tiempo, el tama√±o del cubo no est√° limitado por nada.  Es decir, pueden ser 10 claves, tal vez 100 mil millones de claves, no hay diferencia. </li><li>  Cualquier operaci√≥n competitiva es posible, es decir, puede haber varios rellenos competitivos en la misma clave, puede haber eliminaci√≥n competitiva, etc. </li></ul><br>  En nuestra situaci√≥n, pueden ocurrir operaciones activo-activo, incluso competitivamente en diferentes DC, no solo en una.  Por lo tanto, necesitamos alg√∫n tipo de esquema de conservaci√≥n que nos permita implementar tal l√≥gica.  Al final, elegimos una pol√≠tica simple: gana la √∫ltima versi√≥n registrada.  A veces se realizan varias operaciones competitivas, pero no es necesario que nuestros clientes lo hagan a prop√≥sito.  Puede ser solo una solicitud que comenz√≥, pero el cliente no esper√≥ una respuesta, sucedi√≥ algo m√°s, lo intent√≥ de nuevo, etc. <br><br>  Por lo tanto, tenemos dos tablas base: <br><br><ol><li>  <strong>Tabla de objetos</strong> .  En √©l, un par, el nombre del dep√≥sito y el nombre de la clave, est√° asociado con su versi√≥n actual.  Si se elimina el objeto, entonces no hay nada en esta versi√≥n.  Si el objeto existe, existe su versi√≥n actual.  De hecho, en esta tabla solo cambiamos el campo de la versi√≥n actual. <br></li><li>  <strong>Tabla de versiones de objetos</strong> .  Solo insertamos nuevas versiones en esta tabla.  Cada vez que se descarga un nuevo objeto, insertamos una nueva versi√≥n en la tabla de versiones, le damos un n√∫mero √∫nico, guardamos toda la informaci√≥n al respecto y, al final, le actualizamos el enlace en la tabla de objetos. <br></li></ol><br>  La figura muestra un ejemplo de c√≥mo se relacionan las tablas de objetos y las versiones de objetos. <br><img src="https://habrastorage.org/webt/rv/jm/3y/rvjm3y1ohf-9yiehp1ajlm4zjik.jpeg"><br><br>  Aqu√≠ hay un objeto que tiene dos versiones: una actual y otra antigua, hay un objeto que ya se ha eliminado y su versi√≥n sigue ah√≠.  Necesitamos limpiar versiones innecesarias de vez en cuando, es decir, eliminar algo a lo que nadie m√°s se refiere.  Adem√°s, no necesitamos eliminarlo de inmediato, podemos hacerlo en modo diferido.  Esta es nuestra limpieza interna, simplemente eliminamos lo que ya no es necesario. <br><br>  Hubo un problema <br><img src="https://habrastorage.org/webt/md/rc/xy/mdrcxyc9ojwdjuwchg7gsgkspio.jpeg"><br><br>  El problema era este: tenemos activo-activo, dos DC.  En cada DC, los metadatos se almacenan en tres copias, es decir, tenemos 3 + 3, solo 6 r√©plicas.  Cuando los clientes nos contactan, realizamos operaciones con coherencia (desde el punto de vista de Cassandra se llama LOCAL_QUORUM).  Es decir, se garantiza que el registro (o lectura) se produjo en 2 r√©plicas en el DC local.  Esto es una garant√≠a; de lo contrario, la operaci√≥n fallar√°. <br><br>  Cassandra siempre intentar√° escribir en las 6 l√≠neas: el 99% de las veces todo estar√° bien.  De hecho, las 6 r√©plicas ser√°n las mismas, pero nos garantizamos que 2. <br><br>  Tuvimos una situaci√≥n dif√≠cil, aunque ni siquiera era una geo-regi√≥n.  Incluso para regiones ordinarias que est√°n en un DC, todav√≠a almacenamos la segunda copia de metadatos en otro DC.  Esta es una larga historia, no dar√© todos los detalles.  Pero al final, tuvimos un proceso de limpieza que elimin√≥ las versiones innecesarias. <br><br>  Y entonces surgi√≥ el mismo problema.  El proceso de limpieza tambi√©n funcion√≥ con la consistencia del qu√≥rum local en un centro de datos, porque no tiene sentido ejecutarlo en dos: luchar√°n entre s√≠. <br><br>  Todo estuvo bien hasta que result√≥ que nuestros usuarios todav√≠a a veces escriben en otro centro de datos, lo cual no sospechamos.  Todo estaba configurado por si acaso para el feylover, pero result√≥ que ya lo estaban usando. <br><img src="https://habrastorage.org/webt/sa/cs/6q/sacs6qjj7og_ay7jbmkhfkjh9ei.jpeg"><br><br>  La mayor√≠a de las veces, todo estuvo bien hasta que un d√≠a surgi√≥ una situaci√≥n en la que una entrada en la tabla de versiones se replicaba en ambos DC, pero el registro en la tabla de objetos result√≥ estar en un solo DC y no termin√≥ en el segundo.  En consecuencia, el procedimiento de limpieza, iniciado en la primera DC (superior), vio que hab√≠a una versi√≥n a la que nadie se refer√≠a y la elimin√≥.  Y elimin√© no solo la versi√≥n, sino tambi√©n, por supuesto, los datos: todo es completamente, porque es solo un objeto innecesario.  Y esta eliminaci√≥n es irrevocable. <br><br>  Por supuesto, hay un "boom" a√∫n m√°s, porque todav√≠a tenemos un registro en la tabla de objetos que se refiere a una versi√≥n que ya no existe. <br><br>  Entonces, la primera vez que perdimos datos, y los perdimos de manera irrevocable, bueno, un poco. <br><br><h3>  Soluci√≥n </h3><br>  Que hacer  En nuestra situaci√≥n, todo es simple. <br><br>  Como tenemos datos almacenados en dos centros de datos, el proceso de limpieza es un proceso de convergencia y sincronizaci√≥n.  Debemos leer los datos de ambos DC.  Este proceso funcionar√° solo cuando ambos DC est√©n disponibles.  Como dije que este es un proceso retrasado que no ocurre durante el procesamiento de la API, esto no da miedo. <br><br>  <strong>Consistencia ALL</strong> es una caracter√≠stica de Cassandra 2. En Cassandra 3, todo es un poco mejor: hay un nivel de consistencia, que se llama qu√≥rum en cada DC.  Pero en cualquier caso, existe el problema de que es <strong>lento</strong> , porque, en primer lugar, tenemos que recurrir a la DC remota.  En segundo lugar, en el caso de la consistencia de los 6 nodos, esto significa que funciona a la velocidad del peor de estos 6 nodos. <br><br>  Pero al mismo tiempo, se produce el llamado proceso de <strong>reparaci√≥n de lectura</strong> , cuando no todas las r√©plicas son sincr√≥nicas.  Es decir, cuando la grabaci√≥n fall√≥ en alguna parte, este proceso los repara simult√°neamente.  As√≠ es como funciona Cassandra. <br><br>  Cuando esto sucedi√≥, recibimos una queja del cliente de que el objeto no estaba disponible.  Lo descubrimos, entendimos por qu√©, y lo primero que quer√≠amos hacer era descubrir cu√°ntos objetos m√°s ten√≠amos.  Ejecutamos un script que intentaba encontrar una construcci√≥n similar a esta cuando hab√≠a una entrada en una tabla, pero ninguna entrada en otra. <br><br>  De repente, encontramos que tenemos el <strong>10% de esos registros</strong> .  Probablemente, nada peor podr√≠a no haber sucedido si no hubi√©ramos adivinado que este no era el caso.  El problema fue diferente. <br><br><img src="https://habrastorage.org/webt/kc/jt/_d/kcjt_dh03wmb-6szvtrgxqz-hme.jpeg"><br><br>  Los zombis se han infiltrado en nuestra base de datos.  Este es el nombre semioficial de este problema.  Para comprender qu√© es, debe hablar sobre c√≥mo funciona la eliminaci√≥n en Cassandra. <br><img src="https://habrastorage.org/webt/k2/sd/2j/k2sd2jvngn9ouhiv6b3yre0s8vs.jpeg"><br><br>  Por ejemplo, tenemos alg√∫n dato <strong><em>x</em></strong> que se registra y se replica perfectamente en las 6 r√©plicas.  Si queremos eliminarlo, la eliminaci√≥n, como cualquier operaci√≥n en Cassandra, puede no realizarse en todos los nodos. <br><br>  Por ejemplo, quer√≠amos garantizar la consistencia de 2 de 3 en una DC.  Deje que la operaci√≥n de eliminaci√≥n se realice en cinco nodos, pero permanezca en un registro, por ejemplo, porque el nodo no estaba disponible en ese momento. <br><img src="https://habrastorage.org/webt/lu/d5/ot/lud5otv1dguftzwinkrb2wpeaaq.jpeg"><br><br>  Si eliminamos esto y luego tratamos de leer "Quiero 2 de 3" con la misma consistencia, entonces Cassandra, al ver el valor y su ausencia, interpreta esto como la presencia de datos.  Es decir, al volver a leer, ella dir√°: "¬°Oh, hay datos!", Aunque los eliminamos.  Por lo tanto, no puede eliminar de esta manera. <br><img src="https://habrastorage.org/webt/m6/li/ol/m6liolpvsglhmd_9wjg1gvkascw.jpeg"><br><br>  Cassandra elimina de manera diferente.  <strong>La eliminaci√≥n es en realidad un registro</strong> .  Cuando eliminamos datos, Cassandra escribe un peque√±o marcador llamado <strong>Tombstone</strong> (l√°pida).  Marca que los datos se eliminan.  Por lo tanto, si leemos el token de eliminaci√≥n y los datos al mismo tiempo, Cassandra siempre prefiere el token de eliminaci√≥n en esta situaci√≥n y dice que en realidad no hay datos.  Esto es lo que necesitas. <br><br>  <strong>Tombstone ‚Äî   </strong> , , ,      , -     ,     .   Tombstone     .   <strong>Tombstone   gc_grace_period </strong> .   ,   ,   . <br><br>   ? <br><br><h2> Repair <br></h2><br>  Cassandra  ,   Repair ().   ‚Äî  ,     .       ,  ,      ,     , / ,  , -  - ,    ..     . Repair  ,    . <br><img src="https://habrastorage.org/webt/hj/td/x0/hjtdx0thzgak5uhzjd_ejn09s1m.jpeg"><br><br>   , -   , -   .  Repair    ,    ,    .  - ,     ‚Äî     .     ,    . <br><img src="https://habrastorage.org/webt/qe/ee/kj/qeeekjf-dzxokqp6c4zi1aylljm.jpeg"><br><br>     Repair,       ,  ,      ,    ‚Äî ,   .   6     .     ‚Äî ,   ,     . <br><img src="https://habrastorage.org/webt/c7/qo/o2/c7qoo2bykcraic_gbj8fxbxrmoo.jpeg"><br><br>     ,      ‚Äî ,  -  .      ,    .        ,  - ,    ,       ,    . <br><br><h3>  Soluci√≥n <br></h3><br>   ,   : <br><br><ul><li> <strong>Repair       </strong> . </li></ul><br>    ,      repair.    ,          ,       . <br><br><ul><li> <strong>    ,    Tombstones,   ,   repair.</strong> </li></ul><br>  repair ‚Äî   ,     repair. ,  ,          10-20 , , 3 .    Tombstone     ,     .      ,  ,      -. <br><img src="https://habrastorage.org/webt/18/yp/cc/18ypccovl1xcoxairec6nf3ssx0.jpeg"><br><br>      Cassandra,     .       . <br><br>  S3  .   ,      ‚Äî 10 , 100  .   API,     ‚Äî      .     , ,  , ,   ,         .  ,    ,  ,    ‚Äî     ,    .      . <br><br>    API? <br><img src="https://habrastorage.org/webt/1l/tl/hd/1ltlhdhdtgnwgxezzz8jsnavvky.jpeg"><br><br>   ,     ‚Äî , ,   ‚Äî    ,    ,    .    .              ‚Äî .   ,     ,   .   ,   ,      Cassandra.    ,         ‚Äî  ,  ,    ,      . <br><br>        ,          ,      ,  ,  .          ,      . ,   ,             . ,   - ,           . <br><br> Cassandra ,       .           ,       ,  ,   ,       ,     . <br><img src="https://habrastorage.org/webt/fk/os/a3/fkosa3zozy2gk_dzpgjvxdwm4k8.jpeg"><br><br>    ,   Cassandra  <strong>composite key</strong> .       ,    ‚Äî    ,   - ,      ‚Äî  .    ,   .   ? ,   ,    ! <br><br>      ,    ,  , ,      ‚Äî  ,          . <br><br>     .  Cassandra   ,   <strong>  Cassandra      </strong> .  ,     ,    Cassandra,        :  ,  ,   SQL  ..    ! <br><img src="https://habrastorage.org/webt/8o/_s/ka/8o_ska-swgmzixxiztlblopuze0.jpeg"><br><br>      .     Cassandra  ?    ,     ,   API.  ,   ,     ,   ,     (     )   . <strong>   ,   </strong>   . <br><br>    ,           .        ,   , ,    .   ,     ‚Äî   ‚Äî       . , ,  ,          . <br><br>   Cassandra   ,       .    : ¬´  100 ¬ª,    ,    ,  ,      ,        ,   100,    . <br><br> ,         (   ),    ‚Äî          ,    ,         .         ,   ,   ,   ,     ,   - .     100 ,   - ,     ,  .      ,         SQL    . <br><br> Cassandra       ,     ,     Java,    .  ,  <strong>Large Partition</strong> ,  .    ‚Äî , , ,  ,     ‚Äî  .         ,   , garbage collection    ..     . <br><br>   ,   ,  <strong>    ,   </strong> ,        . <br><br> ,        ,   -  . <br><img src="https://habrastorage.org/webt/qg/o9/oo/qgo9ooa3pgv_zqkv8iyby4ppq9g.jpeg"><br><br>   ,     ,           .      .     ,      Large Partition. <br><br>     : <br><br><ol><li>        ( ,  - ); <br></li><li>   ,    ,       .     ,     . <br></li></ol><br>   ,     ,   ,     key_hash   0.   , <strong>    ,         </strong> .       ,    .       ,      ,      . <br><br>  ,     . <br><img src="https://habrastorage.org/webt/zr/aw/xn/zrawxn-n6hr1huoqkenbqcgpeoo.jpeg"><br><br>    ‚Äî ,    ,    ,      - -      . <br><br>   ‚Äî      ,   N ?    ,  Large Partition,   ‚Äî     .  ,        .   :   .  ,    ,  ,    ,       -  .    ,           .    , ,     . <br><img src="https://habrastorage.org/webt/og/um/4y/ogum4yxqpvbvrdadna7r8adomwm.jpeg"><br><br>     ‚Äî   ,    ,   -  .    -  ,       ,       .    ,    ,    .   ,    ,        .. <br><br>         ‚Äî  ,    ?    ,   .    ? -     md5- ‚Äî      ,   -  30  ‚Äî     ,  - .    .     ,     ,   . <br><img src="https://habrastorage.org/webt/yp/ik/vy/ypikvyolprsxdju5hawmlm6_epq.jpeg"><br><br>      ,    , , ,   .       ‚Äî   ,    .    ,       .   ,    -  -   - ,  -  - ‚Äî  .     ,     .      . <br><br><h2>   </h2><br>    ,    ,     ,    . <br><br><ul><li>   . </li><li>         . </li><li>     Cassandra. </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Redistribuci√≥n en l√≠nea (sin detener operaciones y p√©rdida de consistencia). </font></font></li></ul><br>  Tenemos alg√∫n estado del cubo ahora, de alguna manera est√° dividido en particiones.  Entonces entendemos que algunas particiones son demasiado grandes o demasiado peque√±as.  Necesitamos encontrar una nueva partici√≥n, que, por un lado, ser√° √≥ptima, es decir, el tama√±o de cada partici√≥n ser√° menor que algunos de nuestros l√≠mites, y ser√°n m√°s o menos uniformes.  En este caso, la transici√≥n del estado actual a uno nuevo deber√≠a requerir un n√∫mero m√≠nimo de acciones.  Est√° claro que cualquier transici√≥n requiere mover teclas entre particiones, pero cuanto menos las muevamos, mejor. <br><br>  Lo hicimos  Probablemente, la parte que se ocupa de la selecci√≥n de distribuci√≥n es la pieza m√°s dif√≠cil de todo el servicio, si hablamos de trabajar con metadatos en general.  Lo reescribimos, volvimos a trabajar y a√∫n lo hacemos, porque siempre se encuentran algunos clientes o ciertos patrones de creaci√≥n de claves que golpean un punto d√©bil de este esquema. <br><br>  Por ejemplo, supusimos que el cubo crecer√≠a de manera m√°s o menos uniforme.  Es decir, recogimos alg√∫n tipo de distribuci√≥n, y esperamos que todas las particiones crezcan de acuerdo con esta distribuci√≥n.  Pero encontramos un cliente que siempre escribe al final, en el sentido de que sus claves siempre est√°n ordenadas.  Todo el tiempo late en la √∫ltima partici√≥n, que est√° creciendo a una velocidad tal que en un minuto pueden ser 100 mil llaves.  Y 100 mil es aproximadamente el valor que cabe en una partici√≥n. <br><br>  Simplemente no tendr√≠amos tiempo para procesar dicha adici√≥n de claves con nuestro algoritmo, y tuvimos que introducir una distribuci√≥n preliminar especial para este cliente.  Como sabemos c√≥mo son sus teclas, si vemos que es √©l, simplemente comenzamos a crear particiones vac√≠as por adelantado al final, para que pueda escribir con calma all√≠, y por ahora tendremos un peque√±o descanso hasta la pr√≥xima iteraci√≥n, cuando nuevamente tengamos que redistribuir todo. <br><br>  Todo esto sucede en l√≠nea en el sentido de que no detenemos la operaci√≥n.  Puede haber operaciones de lectura, escritura, en cualquier momento puede solicitar una lista de claves.  Siempre ser√° consistente, incluso si estamos en el proceso de reparticionamiento. <br><br>  Es bastante interesante, y resulta que con Cassandra.  Aqu√≠ puedes jugar con trucos relacionados con el hecho de que Cassandra puede resolver conflictos.  Si escribimos dos valores diferentes en la misma l√≠nea, entonces el valor que tiene una marca de tiempo m√°s grande gana. <br><br>  Por lo general, la marca de tiempo es la marca de tiempo actual, pero se puede pasar manualmente.  Por ejemplo, queremos escribir un valor en una cadena, que en cualquier caso se debe frotar si el cliente escribe algo √©l mismo.  Es decir, estamos copiando algunos datos, pero queremos que el cliente, si de repente escribe con nosotros al mismo tiempo, pueda sobrescribirlos.  Entonces podemos copiar nuestros datos con una marca de tiempo un poco del pasado.  Entonces, cualquier grabaci√≥n actual se deshilachar√° deliberadamente, independientemente del orden en que se realiz√≥ la grabaci√≥n. <br><br>  Tales trucos te permiten hacer esto en l√≠nea. <br><br><h2>  Soluci√≥n </h2><br><ul><li>  Nunca, nunca <strong>permita la aparici√≥n de una gran partici√≥n</strong> . </li><li>  <strong>Rompa los datos por clave principal</strong> seg√∫n la tarea. </li></ul><br>  Si se planea algo similar a una partici√≥n grande en el esquema de datos, debe intentar hacer algo al respecto de inmediato: descubrir c√≥mo romperlo y c√≥mo alejarse de √©l.  Tarde o temprano, esto surge, porque cualquier √≠ndice invertido, tarde o temprano, surge en casi cualquier tarea.  Ya te cont√© sobre tal historia: tenemos una clave de dep√≥sito en el objeto y necesitamos obtener una lista de claves del dep√≥sito; de hecho, este es un √≠ndice. <br><br>  Adem√°s, la partici√≥n puede ser grande no solo a partir de los datos, sino tambi√©n de Tombstones (marcadores de eliminaci√≥n).  Desde el punto de vista de los componentes internos de Cassandra (nunca los vemos desde el exterior), los marcadores de eliminaci√≥n tambi√©n son datos, y una partici√≥n puede ser grande si se eliminan muchas cosas, porque la eliminaci√≥n es un registro.  Tampoco deber√≠as olvidarte de esto. <br><img src="https://habrastorage.org/webt/-s/tw/la/-stwlarb11mcy5nlqaqrpxfc-ky.jpeg"><br><br>  Otra historia que en realidad es constante es que algo sale mal de principio a fin.  Por ejemplo, ve que el tiempo de respuesta de Cassandra ha aumentado, responde lentamente.  ¬øC√≥mo entender y entender cu√°l es el problema?  Nunca hay una se√±al externa de que el problema est√° ah√≠. <br><img src="https://habrastorage.org/webt/c0/lr/5r/c0lr5rwf9w5zi-nx1ddd5k5blgk.jpeg"><br><br>  Por ejemplo, dar√© un gr√°fico: este es el tiempo de respuesta promedio del cl√∫ster en su conjunto.  Muestra que tenemos un problema: el tiempo de respuesta m√°ximo es de 12 segundos; este es el tiempo de espera interno de Cassandra.  Esto significa que ella se desconectar√° ella misma.  Si el tiempo de espera supera los 12 s, lo m√°s probable es que el recolector de basura est√© funcionando y Cassandra ni siquiera tiene tiempo para responder en el momento adecuado.  Ella responde a s√≠ misma por tiempo de espera, pero el tiempo de respuesta a la mayor√≠a de las solicitudes, como dije, deber√≠a ser en promedio dentro de 10 ms. <br><br>  En el gr√°fico, el promedio ya ha excedido cientos de milisegundos, algo sali√≥ mal.  Pero mirando esta imagen, es imposible entender cu√°l es la raz√≥n. <br><br><img src="https://habrastorage.org/webt/e6/t6/qk/e6t6qkz3yw6k80sjw7smsycclrc.jpeg"><br><br>  Pero si expande las mismas estad√≠sticas en los nodos de Cassandra, puede ver que, en principio, todos los nodos son m√°s o menos nada, pero el tiempo de respuesta para un nodo difiere en orden de magnitud.  Lo m√°s probable es que haya alg√∫n tipo de problema con √©l. <br><br>  Las estad√≠sticas sobre los nodos cambian la imagen por completo.  Estas estad√≠sticas son del lado de la aplicaci√≥n.  Pero aqu√≠, en realidad, a menudo es dif√≠cil entender cu√°l es el problema.  Cuando una aplicaci√≥n accede a Cassandra, accede a alg√∫n nodo, us√°ndolo como coordinador.  Es decir, la aplicaci√≥n realiza una solicitud y el coordinador la redirige a las r√©plicas con los datos.  Los que ya responden, y el coordinador devuelve la respuesta final. <br><br>  Pero, ¬øpor qu√© el coordinador responde lentamente?  Tal vez el problema es con √©l, como tal, es decir, ¬ødisminuye la velocidad y responde lentamente?  ¬øO tal vez se ralentiza porque las r√©plicas le responden lentamente?  Si las r√©plicas responden lentamente, desde el punto de vista de la aplicaci√≥n, se ver√° como una respuesta lenta del coordinador, aunque no tiene nada que ver con eso. <br><br>  Aqu√≠ hay una situaci√≥n feliz: est√° claro que solo un nodo responde lentamente y lo m√°s probable es que el problema est√© en √©l. <br><br><h3>  Complejidad de interpretaci√≥n </h3><br><br><ul><li>  Tiempo de respuesta del coordinador (nodo vs. r√©plica en s√≠). </li><li>  ¬øUna tabla espec√≠fica o el nodo completo? </li><li>  GC Pause?  ¬øGrupo de subprocesos inadecuado? </li><li>  ¬øDemasiadas SSTables no compactadas? </li></ul><br>  Siempre es dif√≠cil entender lo que est√° mal.  Solo <strong>necesita muchas estad√≠sticas y monitoreo</strong> , tanto del lado de la aplicaci√≥n como del propio Cassandra, porque si es realmente malo, Cassandra no puede ver nada.  Puede ver el nivel de consultas individuales, el nivel de cada tabla espec√≠fica, en cada nodo espec√≠fico. <br><br>  Puede haber, por ejemplo, una situaci√≥n en la que una tabla de lo que se llama en Cassandra SSTables (archivos separados) tiene demasiado.  Para leer, Cassandra tiene que, m√°s o menos, clasificar todas las SSTables.  Si hay demasiados, simplemente el proceso de esta clasificaci√≥n lleva demasiado tiempo y la lectura comienza a ceder. <br><br>  La soluci√≥n es la compactaci√≥n, que reduce el n√∫mero de estas SSTables, pero debe tenerse en cuenta que solo puede estar en un nodo para una tabla espec√≠fica.  Dado que Cassandra, desafortunadamente, est√° escrito en Java y se ejecuta en la JVM, tal vez el recolector de basura ha entrado en una pausa tal que simplemente no tiene tiempo para responder.  Cuando el recolector de basura entra en pausa, no solo sus solicitudes se ralentizan, sino que la <strong>interacci√≥n dentro del cl√∫ster Cassandra entre nodos comienza a disminuir</strong> .  Los nodos de cada uno comienzan a considerarse como ca√≠dos, es decir, ca√≠dos, muertos. <br><br>  Comienza una situaci√≥n a√∫n m√°s divertida, porque cuando un nodo considera que otro nodo est√° inactivo, en primer lugar, no le env√≠a solicitudes y, en segundo lugar, comienza a intentar guardar los datos que necesitar√≠a replicar en otro nodo en a nivel local, por lo que comienza a suicidarse lentamente, etc. <br><br>  Hay situaciones en las que este problema se puede resolver simplemente usando la configuraci√≥n correcta.  Por ejemplo, puede haber suficientes recursos, todo est√° bien y es maravilloso, pero solo se necesita aumentar un conjunto de subprocesos, cuyo n√∫mero es un tama√±o fijo. <br><br>  Finalmente, tal vez necesitemos limitar la competitividad del lado del conductor.  A veces sucede que se env√≠an demasiadas solicitudes competitivas y, como cualquier base de datos, Cassandra no puede manejarlas y acude al cierre cuando el tiempo de respuesta aumenta exponencialmente, y estamos tratando de dar m√°s y m√°s trabajo. <br><br><h3>  Comprensi√≥n del contexto. </h3><br>  Siempre hay algo de contexto para el problema: qu√© est√° sucediendo en el cl√∫ster, si Reparar est√° funcionando ahora, en qu√© nodo, en qu√© espacios clave, en qu√© tabla. <br><br>  Por ejemplo, tuvimos problemas bastante rid√≠culos con el hierro.  Vimos que parte de los nodos es lenta.  M√°s tarde se descubri√≥ que la raz√≥n era que en el BIOS sus procesadores estaban en modo de ahorro de energ√≠a.  Por alguna raz√≥n, durante la instalaci√≥n inicial de hierro, esto sucedi√≥, y aproximadamente el 50% de los recursos del procesador se usaron en comparaci√≥n con otros nodos. <br><br>  Entender tal problema puede ser dif√≠cil, de hecho.  El s√≠ntoma es este: parece que el nodo hace compactaci√≥n, pero lo hace lentamente.  A veces est√° conectado con hierro, a veces no, pero este es solo otro error de Cassandra. <br><br>  Por lo tanto, el monitoreo es obligatorio y necesita mucho.  Cuanto m√°s compleja es la funci√≥n en Cassandra, cuanto m√°s se aleja de la simple escritura y lectura, m√°s problemas hay con ella y m√°s r√°pido puede eliminar una base de datos con un n√∫mero suficiente de consultas.  Por lo tanto, si es posible, no mire algunos chips ‚Äúsabrosos‚Äù e intente usarlos, es mejor evitarlos tanto como sea posible.  No siempre es posible, por supuesto, tarde o temprano es necesario. <br><img src="https://habrastorage.org/webt/mx/m8/lx/mxm8lxirhudrxrdlcq26jpstvle.jpeg"><br><br>  La √∫ltima historia es sobre c√≥mo Cassandra desorden√≥ los datos.  En esta situaci√≥n, sucedi√≥ dentro de Cassandra.  Eso fue interesante. <br><br>  Vimos que aproximadamente una vez por semana en nuestra base de datos aparecen varias docenas de l√≠neas da√±adas, que est√°n literalmente obstruidas con basura.  Adem√°s, Cassandra valida los datos que van a su entrada.  Por ejemplo, si es una cadena, deber√≠a estar en utf8.  Pero en estas l√≠neas hab√≠a basura, no utf8, y Cassandra ni siquiera dio nada que ver con eso.  Cuando intento eliminar (o hacer otra cosa), no puedo eliminar un valor que no es utf8, porque, en particular, no puedo ingresarlo en DONDE, porque la clave debe ser utf8. <br><br>  Aparecen l√≠neas estropeadas, como un destello, en alg√∫n momento, y luego desaparecen durante varios d√≠as o semanas. <br><br>  Empezamos a buscar un problema.  Pensamos que tal vez hab√≠a un problema en un nodo particular con el que est√°bamos jugando, haciendo algo con datos, copiando SSTables.  Quiz√°s, de todos modos, ¬øpuedes ver r√©plicas de estos datos?  ¬øQuiz√°s estas r√©plicas tienen un nodo com√∫n, el factor com√∫n m√°s peque√±o?  Tal vez alg√∫n nodo se bloquea?  No, nada de eso. <br><br>  Tal vez algo con un disco?  ¬øLos datos est√°n da√±ados en el disco?  No otra vez <br><br>  Tal vez un recuerdo?  No!  Esparcidos por un grupo. <br><br>  Tal vez este es alg√∫n tipo de problema de replicaci√≥n?  ¬øUn nodo estrope√≥ todo y replic√≥ a√∫n m√°s un mal valor?  - No <br><br>  Finalmente, ¬øtal vez este es un problema de aplicaci√≥n? <br><br>  Adem√°s, en alg√∫n momento, las l√≠neas da√±adas comenzaron a aparecer en dos grupos de Cassandra.  Uno trabaj√≥ en la versi√≥n 2.1, el segundo en el tercero.  Parece que Cassandra es diferente, pero el problema es el mismo.  ¬øQuiz√°s nuestro servicio env√≠a datos incorrectos?  Pero era dif√≠cil de creer.  Cassandra valida los datos de entrada; no puede escribir basura.  Pero de repente? <br><br>  Nada cabe. <br><br><h3>  ¬°Se encontr√≥ una aguja! </h3><br>  Luchamos mucho hasta que descubrimos un peque√±o problema: ¬øpor qu√© tenemos alg√∫n tipo de volcado de memoria de la JVM en los nodos a los que no prestamos mucha atenci√≥n?  Y de alguna manera se ve sospechosamente en el recolector de basura de seguimiento de pila ... Y por alguna raz√≥n, algunos rastros de pila tambi√©n est√°n obstruidos con basura. <br><br>  Al final, nos dimos cuenta, oh, <strong>por alguna raz√≥n, estamos usando la JVM de la versi√≥n anterior de 2015</strong> .  Esta fue la √∫nica cosa com√∫n que uni√≥ a los grupos de Cassandra en diferentes versiones de Cassandra. <br><br>  Todav√≠a no s√© cu√°l fue el problema, porque no se escribi√≥ nada sobre esto en las notas de lanzamiento oficiales de la JVM.  Pero despu√©s de la actualizaci√≥n, todo desapareci√≥, el problema ya no surgi√≥.  Adem√°s, no se produjo en el cl√∫ster desde el primer d√≠a, sino desde alg√∫n punto, aunque funcion√≥ en la misma JVM durante mucho tiempo. <br><br><h3>  Recuperaci√≥n de datos </h3><br>  ¬øQu√© lecci√≥n hemos aprendido de esto? <br><br>  ‚óè La copia de seguridad es in√∫til. <br>  Los datos, como descubrimos, se corrompieron en el mismo instante en que se registraron.  En el momento en que los datos ingresaron al coordinador, ya estaban da√±ados. <br><br>  ‚óè Es posible la restauraci√≥n parcial de columnas no da√±adas. <br>  Algunas columnas no estaban da√±adas, pudimos leer estos datos, restaurarlos parcialmente. <br><br>  ‚óè Al final, tuvimos que hacer la recuperaci√≥n de varias fuentes. <br>  Ten√≠amos metadatos de respaldo en el objeto, pero en los datos en s√≠.  Para volver a conectar con el objeto, utilizamos registros, etc. <br><br>  ‚óè ¬°Los registros no tienen precio! <br>  Pudimos recuperar todos los datos que estaban da√±ados, pero al final es muy dif√≠cil confiar en la base de datos si pierde sus datos, incluso sin ninguna acci√≥n de su parte. <br><br><h3>  Soluci√≥n </h3><br><ul><li>  Actualice la JVM despu√©s de extensas pruebas. </li><li>  Monitoreo de fallas JVM. </li><li>  Tener una copia de los datos independiente de Cassandra. </li></ul><br><blockquote>  <strong>Como consejo:</strong> intente obtener alg√∫n tipo de copia de los datos independiente de Cassandra de la que pueda recuperar si es necesario.  Esta puede ser la soluci√≥n de √∫ltimo nivel.  Deje que tome mucho tiempo, recursos, pero deber√≠a haber alguna opci√≥n que le permita devolver datos. </blockquote><br><h1>  Bichos </h1><br>  ‚óè <strong>Mala calidad de las pruebas de lanzamiento</strong> <br>  Cuando comienzas a trabajar con Cassandra, hay una sensaci√≥n constante (especialmente si te est√°s moviendo, relativamente hablando, de bases de datos "buenas", por ejemplo, PostgreSQL) de que si solucionaste un error en el lanzamiento de la anterior, definitivamente agregar√°s uno nuevo.  Y el error no es una tonter√≠a, generalmente son datos corruptos u otro comportamiento incorrecto. <br><br>  ‚óè <strong>Problemas persistentes con caracter√≠sticas complejas</strong> <br>  Cuanto m√°s compleja es la caracter√≠stica, m√°s problemas, errores, etc. <br><br>  ‚óè <strong>No utilice reparaciones incrementales en 2.1</strong> <br>  La famosa reparaci√≥n, de la que habl√©, que corrige la consistencia de los datos, en modo est√°ndar, cuando sondea todos los nodos, funciona bien.  Pero no en el llamado modo incremental (cuando la reparaci√≥n omite datos que no han cambiado desde la reparaci√≥n anterior, lo cual es bastante l√≥gico).  Se anunci√≥ hace mucho tiempo, formalmente, ya que existe una caracter√≠stica, pero todos dicen: ‚ÄúNo, en la versi√≥n 2.1, ¬°nunca la use!  Definitivamente echar√° de menos algo.  En 3 lo arreglamos ". <br><br>  ‚óè <strong>Pero no use la reparaci√≥n incremental en 3.x</strong> <br>  Cuando sali√≥ la tercera versi√≥n, unos d√≠as despu√©s dijeron: ‚ÄúNo, no puedes usarla en la tercera.  Hay una lista de 15 errores, por lo que en ning√∫n caso no utilice la reparaci√≥n incremental.  ¬°En cuarto lo haremos mejor! <br><br>  No les creo.  Y este es un gran problema, especialmente con el aumento del tama√±o del cl√∫ster.  Por lo tanto, debe monitorear constantemente su rastreador de errores y ver qu√© sucede.  Desafortunadamente, es imposible vivir con ellos sin √©l. <br><br>  ‚óè <strong>Necesito hacer un seguimiento de JIRA</strong> <br><img src="https://habrastorage.org/webt/g0/1k/el/g01kela-ibcrrsorr1pjxo-pmdc.jpeg"><br><br><blockquote>  Si dispersas todas las bases de datos en el espectro de previsibilidad, para m√≠, Cassandra est√° a la izquierda en el √°rea roja.  Esto no significa que sea malo, solo tienes que estar preparado para el hecho de que Cassandra es impredecible en cualquier sentido de la palabra: tanto en la forma en que funciona como en el hecho de que algo puede suceder. </blockquote><br><img src="https://habrastorage.org/webt/je/_1/w0/je_1w0808rlhzxo1bakk0zjj9ee.jpeg"><br><br>  Deseo que encuentres otros rastrillos y los pises, porque, desde mi punto de vista, pase lo que pase, Cassandra es buena y, desde luego, no aburrida.  ¬°Solo recuerda los golpes en el camino! <br><br><blockquote>  <strong>Reuni√≥n abierta de activistas de HighLoad ++</strong> <br><br>  El 31 de julio en Mosc√∫, a las 19:00, se llevar√° a cabo una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">reuni√≥n de</a> oradores, el Comit√© del Programa y activistas de la conferencia de desarrolladores de sistemas de alta carga HighLoad ++ 2018. Organizaremos una peque√±a lluvia de ideas sobre el programa de este a√±o para no perder nada nuevo e importante.  La reuni√≥n est√° abierta, pero debe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">registrarse</a> . <br><br>  <strong>Llamada para papeles</strong> <br><br>  Aceptaci√≥n activa de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">solicitudes</a> de informes en Highload ++ 2018. El Comit√© del Programa est√° esperando su resumen hasta el final del verano. <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417617/">https://habr.com/ru/post/es417617/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417605/index.html">Conceptos b√°sicos de modelado 3D para impresi√≥n 3D</a></li>
<li><a href="../es417607/index.html">Las pruebas A / B no funcionan. Comprueba lo que est√°s haciendo mal</a></li>
<li><a href="../es417609/index.html">Especializaci√≥n en programaci√≥n deportiva en el cursor</a></li>
<li><a href="../es417613/index.html">Ceph como almacenamiento conectable: 5 ideas pr√°cticas de un gran proyecto</a></li>
<li><a href="../es417615/index.html">Confesiones de Disk Cracker para Apple II: 4am Secrets</a></li>
<li><a href="../es417619/index.html">Win32 / Glupteba ya no est√° asociado con la operaci√≥n Windigo</a></li>
<li><a href="../es417621/index.html">¬øQu√© pas√≥ cuando desciframos la exhibici√≥n?</a></li>
<li><a href="../es417627/index.html">Hyper CRM o Mini ERP? Negocio en mal estado</a></li>
<li><a href="../es417629/index.html">Edici√≥n comunitaria de Delphi y C ++ Builder</a></li>
<li><a href="../es417631/index.html">Tutorial de video CSS Grid</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
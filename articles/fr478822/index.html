<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👮 👩‍👩‍👧 ⏸️ Robotisation de l'IA avec InterSystems IRIS Data Platform 👨🏾‍🚀 🤳🏼 🛬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Auteur: Sergey Lukyanchikov, ingénieur commercial chez InterSystems 

 Fixer la terminologie 
 Un robot ne devrait pas être énorme ou humanoïde, ni mê...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Robotisation de l'IA avec InterSystems IRIS Data Platform</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intersystems/blog/478822/">  Auteur: Sergey Lukyanchikov, ingénieur commercial chez InterSystems <br><br><h3>  Fixer la terminologie </h3><br>  Un robot ne devrait pas être énorme ou humanoïde, ni même matériel (en désaccord avec <a href="https://en.wikipedia.org/wiki/Robot">Wikipedia</a> , bien que ce dernier adoucisse la définition initiale dans un paragraphe et admette la forme virtuelle d'un robot).  Un robot est un automate, d'un point de vue algorithmique, un automate pour l'exécution autonome (algorithmique) de tâches concrètes.  Un détecteur de lumière qui déclenche l'éclairage public la nuit est un robot.  Un logiciel de messagerie électronique séparant les e-mails en «externes» et «internes» est également un robot. <br><br>  L'intelligence artificielle (au sens strict et appliqué, <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">Wikipédia l'</a> interprétant à nouveau différemment) est un algorithme permettant d'extraire les dépendances des données.  Il n'exécutera aucune tâche seul, car il faudrait l'implémenter en tant que processus analytiques concrets (données d'entrée, plus modèles, plus données de sortie, plus contrôle de processus).  Le processus analytique agissant comme un «porteur d'intelligence artificielle» peut être lancé par un humain ou par un robot.  Il peut également être arrêté par l'un ou l'autre.  Et géré par l'un d'eux aussi. <br><br><a name="habracut"></a><h3>  Interaction avec l'environnement </h3><br>  L'intelligence artificielle a besoin de données adaptées à l'analyse.  Lorsqu'un analyste commence à développer un processus analytique, les données du modèle sont préparées par l'analyste lui-même.  Habituellement, il construit un ensemble de données qui a suffisamment de volume et de fonctionnalités pour être utilisé pour la formation et les tests de modèles.  Une fois que la précision (et dans des cas moins fréquents, la «stabilité locale» dans le temps) du résultat obtenu devient satisfaisante, un analyste type considère son travail accompli.  A-t-il raison?  En réalité, le travail n'est qu'à moitié fait.  Il reste à assurer un «fonctionnement ininterrompu et efficace» du processus analytique - et c'est là que notre analyste peut rencontrer des difficultés. <br><br>  Les outils utilisés pour développer l'intelligence artificielle et les mécanismes d'apprentissage automatique, à l'exception de certains cas les plus simples, ne conviennent pas pour une interaction efficace avec l'environnement extérieur.  Par exemple, nous pouvons (pendant une courte période) utiliser Python pour lire et transformer les données des capteurs d'un processus de production.  Mais Python ne sera pas le bon outil pour surveiller globalement la situation et basculer le contrôle entre plusieurs processus de production, faire monter et descendre les ressources de calcul correspondantes, analyser et traiter tous les types d '"exceptions" (par exemple, la non-disponibilité d'une source de données, défaillance de l'infrastructure, problèmes d'interaction avec les utilisateurs, etc.).  Pour ce faire, nous aurons besoin d'une plateforme de gestion et d'intégration des données.  Et plus la charge sera chargée, plus notre processus analytique sera varié, plus la barre de nos attentes en matière d'intégration de la plate-forme et de composants «SGBD» sera élevée.  Un analyste qui est élevé sur des langages de script et des environnements de développement traditionnels pour construire des modèles (y compris des utilitaires comme des «cahiers») sera confronté à la quasi-impossibilité de sécuriser son processus analytique et une implémentation productive efficace. <br><br><h3>  Adaptabilité et adaptabilité </h3><br>  La variabilité de l'environnement se manifeste de différentes manières.  Dans certains cas, cela changera l'essence et la nature des choses gérées par l'intelligence artificielle (par exemple, l'entrée d'une entreprise dans de nouveaux domaines d'activité, les exigences imposées par les régulateurs nationaux et internationaux, l'évolution des préférences des clients pertinentes pour l'entreprise, etc.).  Dans les autres cas - la signature d'information des données provenant de l'environnement externe deviendra différente (par exemple, de nouveaux équipements avec de nouveaux capteurs, des canaux de transmission de données plus performants, la disponibilité de nouvelles technologies d'étiquetage des données, etc.). <br><br>  Un processus analytique peut-il se «réinventer» à mesure que la structure de l'environnement externe change?  Simplifions la question: est-il facile d'ajuster le processus analytique si la structure de l'environnement externe change?  D'après notre expérience, la réponse qui suit est simple et triste: dans la plupart des implémentations connues (pas par nous!) Il faudra au moins réécrire le processus analytique, et très probablement réécrire l'IA qu'il contient.  Eh bien, la réécriture de bout en bout peut ne pas être le verdict final, mais faire la programmation pour ajouter quelque chose qui reflète la nouvelle réalité ou changer la «partie modélisation» peut en effet être nécessaire.  Et cela pourrait signifier des frais généraux prohibitifs - surtout si les changements d'environnement sont fréquents. <br><br><h3>  Agence: la limite de l'autonomie? </h3><br>  Le lecteur a peut-être déjà remarqué que nous allons dans le sens d'une réalité de plus en plus complexe proposée à l'intelligence artificielle.  Tout en prenant note des éventuelles «conséquences côté instrument».  Dans l'espoir que nous puissions enfin apporter une réponse aux nouveaux défis. <br><br>  Nous approchons maintenant de la nécessité d'équiper un processus analytique d'un niveau d'autonomie tel qu'il puisse faire face non seulement à la variabilité de l'environnement, mais aussi à l'incertitude de son état.  Aucune référence à une nature quantique de l'environnement n'est visée ici (nous en discuterons dans l'une de nos autres publications), nous considérons simplement la probabilité qu'un processus analytique rencontre l'état attendu au moment attendu dans le «volume» attendu.  Par exemple: le processus «pensait» qu'il réussirait à terminer un cycle de formation sur le modèle avant l'arrivée de nouvelles données auxquelles appliquer le modèle, mais «n'a pas réussi» à le compléter (par exemple, pour plusieurs raisons objectives, l'échantillon de formation contenait plus enregistrements que d'habitude).  Autre exemple: l'équipe d'étiquetage a ajouté un lot de nouvelle presse dans le processus, un modèle de vectorisation a été formé à l'aide de ce nouveau matériel, tandis que le réseau neuronal utilise toujours la vectorisation précédente et traite comme du «bruit» des informations extrêmement pertinentes.  Notre expérience montre que surmonter de telles situations nécessite de diviser ce qui était auparavant un processus analytique unique en plusieurs composants autonomes et de créer pour chacun des processus d'agents résultants sa "projection tamponnée" de l'environnement.  Appelons cette action (au revoir, Wikipédia) l'agentation d'un processus analytique.  Et appelons agence la qualité acquise par un processus analytique (ou plutôt à un système de processus analytiques) grâce à l'agenting. <br><br><h3>  Une tâche pour le robot </h3><br>  À ce stade, nous allons essayer de trouver une tâche qui nécessiterait une IA robotisée avec toutes les qualités mentionnées ci-dessus.  Il ne faudra pas un long voyage pour arriver à des idées, en particulier en raison d'une multitude de cas et de solutions très intéressants pour ces cas publiés sur Internet - nous allons simplement réutiliser l'un de ces cas / solutions (pour obtenir à la fois le tâche et formulation de la solution).  Le scénario que nous avons choisi concerne la classification des publications («tweets») sur le réseau social Twitter, en fonction de leur sentiment.  Pour former les modèles, nous avons des échantillons assez importants de tweets «étiquetés» (c'est-à-dire avec un sentiment spécifié), tandis que la classification sera effectuée sur des tweets «non étiquetés» (c'est-à-dire sans sentiment spécifié): <br><br><img src="https://habrastorage.org/webt/wu/xa/ho/wuxahoyhdu9prk-gvq7rcauagz8.png" alt="image"><br>  <i>Figure 1 Formulation des tâches de classification de texte basée sur les sentiments (analyse des sentiments)</i> <br><br>  Une approche pour créer des modèles mathématiques capables d'apprendre à partir de textes étiquetés et de classer des textes non étiquetés avec un sentiment inconnu, est présentée dans un excellent <a href="https://stackabuse.com/python-for-nlp-movie-sentiment-analysis-using-deep-learning-in-keras">exemple</a> publié sur le Web. <br><br>  Les <a href="https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews">données</a> de notre scénario ont été aimablement mises à disposition sur le Web. <br><br>  Avec tout ce qui précède à portée de main, nous pourrions commencer à "assembler un robot" - cependant, nous préférons compliquer la tâche classique en ajoutant une condition: les données étiquetées et non étiquetées sont envoyées au processus analytique sous forme de fichiers de taille standard comme le processus «Consomme» les fichiers déjà alimentés.  Par conséquent, notre robot devra commencer à fonctionner sur des volumes minimaux de données de formation et améliorer continuellement la précision de la classification en répétant la formation du modèle sur des volumes de données en croissance progressive. <br><br><h3>  Vers l'atelier InterSystems </h3><br>  Nous allons démontrer, en prenant comme exemple le scénario qui vient d'être formulé, qu'InterSystems IRIS et ML Toolkit, un ensemble d'extensions, peuvent robotiser l'intelligence artificielle.  Et réaliser une interaction efficace avec l'environnement externe pour les processus analytiques que nous créons, tout en les gardant adaptables, adaptatifs et agents (les «trois A»). <br><br>  Commençons par l'agence.  Nous déployons quatre processus métier dans la plateforme: <br><br><img src="https://habrastorage.org/webt/8l/4y/g7/8l4yg7em-j7x1kqhmme3so0oiqw.png" alt="image"><br>  <i>Figure 2 Configuration d'un système de processus métier basé sur un agent avec un composant pour l'interaction avec Python</i> <br><br><ul><li>  <b>GÉNÉRATEUR</b> - comme les fichiers générés précédemment sont consommés par les autres processus, génère de nouveaux fichiers avec des données d'entrée (étiquetés - tweets positifs et négatifs - ainsi que des tweets non étiquetés) </li><li>  <b>TAMPON</b> - comme les enregistrements déjà tamponnés sont consommés par les autres processus, lit les nouveaux enregistrements des fichiers créés par GENERATOR et supprime les fichiers après avoir lu les enregistrements d'eux </li><li>  <b>ANALYZER</b> - consomme les enregistrements du tampon non étiqueté et leur applique le RNN formé (réseau de neurones récurrent), transfère les enregistrements «appliqués» avec des valeurs respectives de «probabilité d'être positive» ajoutées au tampon de surveillance;  consomme les enregistrements des tampons étiquetés (positifs et négatifs) et forme le réseau de neurones en fonction de ceux-ci </li><li>  <b>MONITOR</b> - consomme les enregistrements traités et transférés dans sa mémoire tampon par ANALYZER, évalue les mesures d'erreur de classification démontrées par le réseau neuronal après la dernière formation et déclenche une nouvelle formation par ANALYZER </li></ul><br>  Notre système de processus basé sur des agents peut être illustré comme suit: <br><br><img src="https://habrastorage.org/webt/ly/mu/ve/lymuvexu_mjvzwmcw84qtemjsqo.png" alt="image"><br>  <i>Figure 3 Flux de données dans le système basé sur un agent</i> <br><br>  Tous les processus de notre système fonctionnent indépendamment les uns des autres mais écoutent les signaux les uns des autres.  Par exemple, un signal pour que le processus GENERATOR commence à créer un nouveau fichier avec des enregistrements est la suppression du fichier précédent par le processus BUFFER. <br><br>  Voyons maintenant l'adaptabilité.  L'adaptabilité du processus analytique dans notre exemple est mise en œuvre via «l'encapsulation» de l'IA en tant que composant indépendant de la logique du processus porteur et dont les fonctions principales - formation et prédiction - sont isolées les unes des autres: <br><br><img src="https://habrastorage.org/webt/fn/2p/ac/fn2pacldjteliadpkbl0fhn-qsy.png" alt="image"><br>  <i>Figure 4 Isolement des principales fonctions de l'IA dans un processus analytique - formation et prédiction à l'aide de modèles mathématiques</i> <br><br>  Étant donné que le fragment de processus ANALYZER cité ci-dessus fait partie de la «boucle sans fin» (qui est déclenchée au démarrage du processus et fonctionne jusqu'à ce que tout le système basé sur l'agent soit arrêté), et puisque les fonctions AI sont exécutées simultanément, le processus est capable d'adapter l'utilisation de l'IA à la situation: former des modèles si le besoin s'en fait sentir, prévoir en fonction de la version disponible des modèles formés, sinon.  La nécessité de former les modèles est signalée par le processus adaptatif MONITOR qui fonctionne indépendamment du processus ANALYZER et applique ses critères pour estimer la précision des modèles formés par ANALYZER: <br><br><img src="https://habrastorage.org/webt/az/4b/uu/az4buuepqo64-4zooxejcmteabu.png" alt="image"><br>  <i>Figure 5 Reconnaissance du type de modèle et application des mesures de précision respectives par le processus MONITOR</i> <br><br>  Nous continuons avec l'adaptabilité.  Un processus analytique dans InterSystems IRIS est un processus métier qui a une représentation graphique ou XML sous la forme d'une séquence d'étapes.  Les étapes à leur tour peuvent être des séquences d'autres étapes, boucles, vérifications de condition et autres contrôles de processus.  Les étapes peuvent exécuter du code ou transmettre des informations (peuvent également être du code) pour le traitement par d'autres processus et systèmes externes. <br><br>  S'il est nécessaire de modifier un processus analytique, nous avons la possibilité de le faire dans l'éditeur graphique ou dans l'IDE.  La modification du processus analytique dans l'éditeur graphique permet d'adapter la logique du processus sans programmation: <br><br><img src="https://habrastorage.org/webt/8s/id/0q/8sid0qgigw7vwnrurj_olexyaqs.png" alt="image"><br>  <i>Figure 6 Processus ANALYZER dans l'éditeur graphique avec le menu ouvert pour ajouter des contrôles de processus</i> <br><br>  Enfin, c'est l'interaction avec l'environnement.  Dans notre cas, l'élément le plus important de l'environnement est le jeu d'outils mathématiques Python.  Pour l'interaction avec Python et R, les extensions fonctionnelles correspondantes ont été développées - <a href="https://openexchange.intersystems.com/package/PythonGateway">Python Gateway</a> et <a href="https://openexchange.intersystems.com/package/RGateway">R Gateway</a> .  Permettre une interaction confortable avec un ensemble d'outils concrets est leur fonctionnalité clé.  Nous pouvions déjà voir le composant pour l'interaction avec Python dans la configuration de notre système basé sur un agent.  Nous avons démontré que les processus métier contenant de l'IA implémentée à l'aide du langage Python peuvent interagir avec Python. <br><br>  Le processus ANALYZER, par exemple, porte les fonctions de formation et de prédiction du modèle implémentées dans InterSystems IRIS en utilisant le langage Python, comme illustré ci-dessous: <br><br><img src="https://habrastorage.org/webt/ir/yn/lf/irynlfj3tlqk2wugodpk5pgdf0w.png" alt="image"><br>  <i>Figure 7 Fonction d'apprentissage du modèle implémentée dans le processus ANALYZER dans InterSystems IRIS à l'aide de Python</i> <br><br>  Chacune des étapes de ce processus est responsable d'une interaction spécifique avec Python: un transfert des données d'entrée du contexte IRIS InterSystems vers le contexte Python, un transfert de code pour exécution vers Python, un retour des données de sortie du contexte Python vers le contexte IRIS InterSystems . <br><br>  Le type d'interaction le plus utilisé dans notre exemple est le transfert de code pour exécution en Python: <br><br><img src="https://habrastorage.org/webt/fn/s9/7_/fns97_h0jqfyh2ginapcqd4homk.png" alt="image"><br>  <i>Figure 8 Le code Python déployé dans le processus ANALYZER dans InterSystems IRIS est envoyé pour exécution à Python</i> <br><br>  Dans certaines interactions, il y a un retour des données de sortie du contexte Python vers le contexte IRIS InterSystems: <br><br><img src="https://habrastorage.org/webt/z9/it/dk/z9itdk3x7_hhfw8einscxvsbjmy.png" alt="image"><br>  <i>Figure 9 Trace visuelle de la session de processus ANALYZER avec un aperçu de la sortie retournée par Python dans l'une des étapes du processus</i> <br><br><h3>  Lancement du robot </h3><br>  Lancement du robot ici même dans cet article?  Pourquoi pas, voici l' <a href="https://www.youtube.com/watch%3Fv%3D-gyvCTBHh-0">enregistrement</a> de notre webinaire dans lequel (en plus d'autres histoires d'intelligence artificielle pertinentes pour la robotisation!) L'exemple discuté dans notre article a été démo.  Le temps du webinaire étant toujours limité, malheureusement, et nous préférons toujours présenter notre travail de manière aussi illustrative que brièvement que possible - et nous partageons donc ci-dessous un aperçu plus complet des résultats produits (7 sessions de formation, y compris la formation initiale, au lieu de simplement 3 dans le webinaire): <br><br><img src="https://habrastorage.org/webt/n1/uo/4z/n1uo4zxe-xaaczoitgh1w7dyt04.png" alt="image"><br>  <i>Figure 10 Robot atteignant une AUC stable au-dessus de 0,8 lors de la prédiction</i> <br><br>  Ces résultats sont conformes à nos attentes intuitives: au fur et à mesure que l'ensemble de données de formation se remplit de tweets positifs et négatifs «étiquetés», la précision de notre modèle de classification s'améliore (cela est prouvé par l'augmentation progressive des valeurs AUC montrées sur la prédiction). <br><br>  Quelles conclusions pouvons-nous tirer à la fin de l'article: <br><br>  • InterSystems IRIS est une puissante plateforme de robotisation des processus impliquant l'intelligence artificielle <br><br>  • L'intelligence artificielle peut être implémentée à la fois dans l'environnement externe (par exemple, Python ou R avec leurs modules contenant des algorithmes prêts à l'emploi) et dans la plate-forme InterSystems IRIS (en utilisant des bibliothèques de fonctions natives ou en écrivant des algorithmes en Python et R).  InterSystems IRIS sécurise l'interaction avec des ensembles d'outils d'IA externes permettant de combiner leurs capacités avec ses fonctionnalités natives <br><br>  • InterSystems IRIS robotise l'IA en appliquant «trois A»: des processus métier adaptables, adaptatifs et d'agent (ou bien des processus analytiques) <br><br>  • InterSystems IRIS exploite l'IA externe (Python, R) via des kits d'interactions spécialisées: transfert / retour de données, transfert de code pour exécution, etc.  Un processus analytique peut interagir avec plusieurs ensembles d'outils mathématiques <br><br>  • InterSystems IRIS consolide sur une seule plate-forme les données de modélisation d'entrée et de sortie, maintient l'historisation et la version des calculs <br><br>  • Grâce à InterSystems IRIS, l'intelligence artificielle peut être à la fois utilisée comme mécanisme analytique spécialisé ou intégrée dans OLTP et des solutions d'intégration <br><br>  Pour ceux qui ont lu cet article et se sont intéressés aux capacités d'InterSystems IRIS en tant que plate-forme pour développer et déployer des mécanismes d'apprentissage automatique et d'intelligence artificielle, nous proposons une discussion plus approfondie des scénarios potentiels qui sont pertinents pour votre entreprise, et une définition collaborative des prochaines étapes.  L'e-mail de contact de notre équipe d'experts AI / ML est <a href="">MLToolkit@intersystems.com</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr478822/">https://habr.com/ru/post/fr478822/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr478802/index.html">Réact-admin et framework de repos django</a></li>
<li><a href="../fr478812/index.html">Développer un hexapode à partir de zéro (partie 6) - transition vers l'impression 3D</a></li>
<li><a href="../fr478814/index.html">Comment le marketing accélère le chargement de vos smartphones</a></li>
<li><a href="../fr478816/index.html">Test des applications Android à l'aide de sélénoïde. Rechercher l'emplacement dans une application mobile à l'aide d'Appium</a></li>
<li><a href="../fr478820/index.html">Vivaldi pour Android: une bêta est bonne et la seconde est meilleure</a></li>
<li><a href="../fr478824/index.html">Unity, ECS, Actors: comment augmenter dix fois le FPS dans votre jeu, quand il n'y a rien à optimiser [avec des modifications]</a></li>
<li><a href="../fr478826/index.html">Réflexions sur la POO et l'état des objets</a></li>
<li><a href="../fr478830/index.html">Plesk, cPanel ou ISPmanager: que choisir?</a></li>
<li><a href="../fr478832/index.html">Point d'échange de trafic: des débuts à la création de votre propre IX</a></li>
<li><a href="../fr478834/index.html">Pourquoi nous sommes engourdis par la peur: l'effet de la sérotonine sur la locomotion</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
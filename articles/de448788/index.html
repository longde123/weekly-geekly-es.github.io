<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧒🏼 🆎 👨🏾‍🎨 Python-Test mit Pytest. Kapitel 2, Schreiben von Testfunktionen 🚇 👎🏼 🗡️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Zurück Weiter 


 Sie lernen, wie Sie Tests in Klassen, Modulen und Verzeichnissen organisieren. Ich werde Ihnen dann zeigen, wie Sie Markierungen ver...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python-Test mit Pytest. Kapitel 2, Schreiben von Testfunktionen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448788/"><p><img src="https://habrastorage.org/webt/jl/jn/bb/jljnbbjr-ejh473xy_eccsmknpk.png">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zurück</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Weiter</a> <img src="https://habrastorage.org/webt/rw/dy/-g/rwdy-grsvbpcetjttrmecdkxtlk.png"></p><br><p>  <em>Sie lernen, wie Sie Tests in Klassen, Modulen und Verzeichnissen organisieren.</em>  <em>Ich werde Ihnen dann zeigen, wie Sie Markierungen verwenden, um zu markieren, welche Tests Sie ausführen möchten, und erläutern, wie integrierte Markierungen Ihnen helfen können, Tests zu überspringen und Tests zu markieren, wobei ein Fehler zu erwarten ist.</em>  <em>Abschließend werde ich auf die Parametrisierung von Tests eingehen, mit der Tests mit unterschiedlichen Daten aufgerufen werden können.</em> </p><br><p><img src="https://habrastorage.org/webt/hd/--/9w/hd--9w134j0rxhmxftrflbbdopy.png"></p><a name="habracut"></a><br><p>  Die Beispiele in diesem Buch wurden mit Python 3.6 und pytest 3.2 geschrieben.  pytest 3.2 unterstützt Python 2.6, 2.7 und Python 3.3+. </p><br><blockquote>  Der Quellcode für das Aufgabenprojekt sowie für alle in diesem Buch gezeigten Tests ist unter dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" title="https://pragprog.com/titles/bopytest/source_code">Link</a> auf der Webseite des Buches unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" title="https://pragprog.com/titles/bopytest">pragprog.com verfügbar</a> .  Sie müssen den Quellcode nicht herunterladen, um den Testcode zu verstehen.  Der Testcode wird in den Beispielen in einer praktischen Form dargestellt.  Um jedoch die Aufgaben des Projekts zu verfolgen oder Testbeispiele anzupassen, um Ihr eigenes Projekt zu testen (Ihre Hände sind losgebunden!), Müssen Sie auf die Webseite des Buches gehen und die Arbeit herunterladen.  Dort, auf der Webseite des Buches, gibt es einen Link für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" title="https://pragprog.com/titles/bopytest/errata">Errata-</a> Nachrichten und ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" title="https://forums.pragprog.com/forums/438">Diskussionsforum</a> . </blockquote><p>  Unter dem Spoiler befindet sich eine Liste der Artikel dieser Reihe. </p><br><div class="spoiler">  <b class="spoiler_title">Inhaltsverzeichnis</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>Einführung</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>Kapitel 1: Erste Schritte mit Pytest</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>Kapitel 2: Schreiben von Testfunktionen</strong></a> (Dieser Artikel) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>Kapitel 3: Pytest-Vorrichtungen</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>Kapitel 4: Eingebaute Vorrichtungen</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>Kapitel 5: Plugins</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>Kapitel 6: Konfiguration</strong></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><strong>Kapitel 7: Verwenden von pytest mit anderen Tools</strong></a> </li></ul></div></div><br><p>  Im vorherigen Kapitel haben Sie pytest ausgeführt.  Sie haben gesehen, wie es mit Dateien und Verzeichnissen ausgeführt wird und wie viele der Optionen funktionieren.  In diesem Kapitel erfahren Sie, wie Sie Testfunktionen im Kontext des Testens eines Python-Pakets schreiben.  Wenn Sie pytest verwenden, um etwas anderes als ein Python-Paket zu testen, ist der größte Teil dieses Kapitels hilfreich. </p><br><p>  Wir werden Tests für das Aufgabenpaket schreiben.  Bevor wir dies tun, werde ich über die Struktur des Python-Distributionspakets und die Tests dafür sprechen sowie darüber, wie die Tests das Testpaket anzeigen lassen.  Dann werde ich Ihnen zeigen, wie Sie assert in Tests verwenden, wie Tests mit unvorhergesehenen Ausnahmen umgehen und erwartete Ausnahmen testen. </p><br><p>  Am Ende werden wir viele Tests haben.  Auf diese Weise lernen Sie, wie Sie Tests in Klassen, Modulen und Verzeichnissen organisieren.  Ich werde Ihnen dann zeigen, wie Sie Markierungen verwenden, um zu markieren, welche Tests Sie ausführen möchten, und erläutern, wie integrierte Markierungen Ihnen helfen können, Tests zu überspringen und Tests zu markieren, wobei ein Fehler zu erwarten ist.  Abschließend werde ich auf die Parametrisierung von Tests eingehen, mit der Tests mit unterschiedlichen Daten aufgerufen werden können. </p><br><blockquote> <strong><em>Übersetzer Hinweis:</em></strong> <strong><em>Wenn Sie Python 3.5 oder 3.6 verwenden, erhalten</em></strong> Sie beim Ausführen der Tests in Kapitel 2 möglicherweise Nachrichten wie diese <br><img src="https://habrastorage.org/webt/57/eq/4x/57eq4xsrdjfiyxn9g9ihresujc8.jpeg"><br>  Dieses Problem wird <code>...\code\tasks_proj\src\tasks\tasksdb_tinydb.py</code> indem <code>...\code\tasks_proj\src\tasks\tasksdb_tinydb.py</code> und das Aufgabenpaket neu installiert wird <br><pre> <code class="plaintext hljs">$ cd /path/to/code $ pip install ./tasks_proj/`</code> </pre> <br><br>  Sie <code>eids</code> <code>doc_ids</code> benannten Parameter <code>eids</code> für <code>doc_ids</code> und <code>eid</code> für <code>doc_id</code> im Modul <code>...\code\tasks_proj\src\tasks\tasksdb_tinydb.py</code> <br><br>  Erklärungen Siehe <code>#83783</code> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier.</a> </blockquote><br><h2 id="testirovanie-paketa">  Pakettests </h2><br><p>  Um zu lernen, wie Testfunktionen für das Python-Paket geschrieben werden, verwenden wir das Beispielprojekt Tasks, wie im Aufgabenprojekt auf Seite xii beschrieben.  Tasks ist ein Python-Paket, das ein Befehlszeilentool mit demselben Aufgabennamen enthält. </p><br><p>  Anhang 4, Packen und Verteilen von Python-Projekten auf Seite 175, enthält eine Erläuterung zum lokalen Verteilen Ihrer Projekte in einem kleinen Team oder global über PyPI. Ich werde daher nicht näher darauf eingehen.  Schauen wir uns jedoch kurz an, was sich im Aufgabenprojekt befindet und wie verschiedene Dateien in den Testverlauf dieses Projekts passen. </p><br><p>  Das Folgende ist die Dateistruktur des Aufgabenprojekts: </p><br><pre> <code class="plaintext hljs">tasks_proj/ ├── CHANGELOG.rst ├── LICENSE ├── MANIFEST.in ├── README.rst ├── setup.py ├── src │ └── tasks │ ├── __init__.py │ ├── api.py │ ├── cli.py │ ├── config.py │ ├── tasksdb_pymongo.py │ └── tasksdb_tinydb.py └── tests ├── conftest.py ├── pytest.ini ├── func │ ├── __init__.py │ ├── test_add.py │ └── ... └── unit ├── __init__.py ├── test_task.py └── ...</code> </pre> <br><p>  Ich habe eine vollständige Liste des Projekts (mit Ausnahme der vollständigen Liste der Testdateien) <em>beigefügt, um anzugeben</em> , wie die Tests in den Rest des Projekts passen, und auf mehrere Dateien zu verweisen, die für das Testen von entscheidender Bedeutung sind, nämlich <em>conftest.py, pytest.ini</em> , verschiedene <em><code>__init__.py</code></em> Dateien und <em>setup.py</em> . </p><br><p>  Alle Tests werden in <em>Tests</em> gespeichert und von den Paketquelldateien in <em>src getrennt</em> .  Dies ist keine Pytest-Anforderung, aber eine bewährte Methode. </p><br><p>  Alle Dateien der obersten Ebene, <em>CHANGELOG.rst, LICENSE, README.rst,</em> <em>MANIFEST.in</em> und <em>setup.py</em> , werden in Anhang 4, Packen und Verteilen von Python-Projekten, auf Seite 175 <em>ausführlicher beschrieben. Setup.py ist jedoch</em> wichtig für die <em>Erstellung</em> einer Distribution aus dem Paket, sowie für die Möglichkeit, das Paket lokal zu installieren, so dass das Paket für den Import verfügbar ist. </p><br><p>  Funktions- und Komponententests sind in eigene Kataloge unterteilt.  Dies ist eine willkürliche Entscheidung und nicht notwendig.  Das Organisieren von Testdateien in mehreren Verzeichnissen erleichtert jedoch das Ausführen einer Teilmenge der Tests.  Ich mag es, Funktions- und Komponententests zu trennen, da Funktionstests nur dann unterbrochen werden sollten, wenn wir die Funktionalität des Systems absichtlich ändern, während Komponententests während des Refactorings oder einer Änderung der Implementierung unterbrochen werden können. </p><br><p>  Das Projekt enthält zwei Arten von <code>__init__.py</code> Dateien: die im Verzeichnis <code>src/</code> und die in <code>tests/</code> .  Die <code>src/tasks/__init__.py</code> teilt Python mit, dass das Verzeichnis ein Paket ist.  Es fungiert auch als Hauptschnittstelle für das Paket, wenn jemand <code>import tasks</code> .  Es enthält Code zum Importieren bestimmter Funktionen aus <code>api.py</code> , sodass <code>cli.py</code> und unsere Testdateien auf <code>tasks.add()</code> wie <code>tasks.add()</code> zugreifen können, anstatt <code>task.api.add ()</code> auszuführen.  Die Dateien <code>tests/func/__init__.py</code> und <code>tests/unit/__init__.py</code> sind leer.  Sie weisen pytest an, in einem Verzeichnis nach dem Stammverzeichnis des <code>pytest.ini</code> und der Datei <code>pytest.ini</code> . </p><br><p>  Die Datei <code>pytest.ini</code> ist optional.  Es enthält die allgemeine Pytest-Konfiguration für das gesamte Projekt.  Ihr Projekt sollte nicht mehr als eine davon haben.  Es kann Anweisungen enthalten, die das Verhalten von pytest ändern, z. B. das Erstellen einer Liste von Parametern, die immer verwendet werden.  Alles über <code>pytest.ini</code> erfahren <code>pytest.ini</code> in Kapitel 6, „Konfiguration“, auf Seite 113. </p><br><p>  Die Datei conftest.py ist ebenfalls optional.  Es wird als "lokales Plugin" angesehen und kann Hook-Funktionen und Fixtures enthalten.  <em>Hook-Funktionen</em> sind eine Möglichkeit, Code in einen Teil der Pytest-Laufzeit einzubetten, um die <em>Funktionsweise</em> von Pytest zu ändern.  Fixtures sind Setup- und Teardown-Funktionen, die vor und nach Testfunktionen ausgeführt werden und zur Darstellung der von den Tests verwendeten Ressourcen und Daten verwendet werden können.  (Fixtures werden in Kapitel 3, Pytest Fixtures, auf Seite 49 und Kapitel 4, Builtin Fixtures, auf Seite 71 beschrieben, und Hook-Funktionen werden in Kapitel 5, „Plugins“, auf Seite 95 erläutert.) Die Hook-Funktionen und Fixtures, die in verwendet werden Tests in mehreren Unterverzeichnissen sollten in tests / conftest.py enthalten sein.  Sie können mehrere conftest.py-Dateien haben.  Sie können beispielsweise eine in den Tests und eine für jedes Test-Unterverzeichnis haben. </p><br><p>  Wenn Sie dies noch nicht getan haben, können Sie eine Kopie des Quellcodes für dieses Projekt von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Website des</a> Buches <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">herunterladen</a> .  Alternativ können Sie an Ihrem Projekt mit einer ähnlichen Struktur arbeiten. </p><br><p>  Hier ist test_task.py: </p><br><blockquote>  <strong>ch2 / task_proj / tests / unit / test_task.py</strong> </blockquote><br><pre> <code class="plaintext hljs">"""Test the Task data type.""" # -*- coding: utf-8 -*- from tasks import Task def test_asdict(): """_asdict()   .""" t_task = Task('do something', 'okken', True, 21) t_dict = t_task._asdict() expected = {'summary': 'do something', 'owner': 'okken', 'done': True, 'id': 21} assert t_dict == expected def test_replace(): """replace ()      .""" t_before = Task('finish book', 'brian', False) t_after = t_before._replace(id=10, done=True) t_expected = Task('finish book', 'brian', True, 10) assert t_after == t_expected def test_defaults(): """        .""" t1 = Task() t2 = Task(None, None, False, None) assert t1 == t2 def test_member_access(): """ .field  namedtuple.""" t = Task('buy milk', 'brian') assert t.summary == 'buy milk' assert t.owner == 'brian' assert (t.done, t.id) == (False, None)</code> </pre> <br><p>  Die Datei <em>test_task.py</em> enthält die folgende Importanweisung: </p><br><pre> <code class="plaintext hljs">from tasks import Task</code> </pre> <br><p>  Der beste Weg, um Tests Aufgaben importieren oder etwas von Aufgaben importieren zu lassen, besteht darin, Aufgaben lokal mit pip zu installieren.  Dies ist möglich, da es eine setup.py-Datei gibt, mit der pip direkt aufgerufen werden kann. </p><br><p>  Installieren Sie Aufgaben, indem Sie <code>pip install .</code> ausführen <code>pip install .</code>  oder <code>pip install -e .</code>  aus dem Verzeichnis task_proj.  Oder eine andere Option, um <code>pip install -e tasks_proj</code> aus dem Verzeichnis eine Ebene höher <code>pip install -e tasks_proj</code> : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code $ pip install ./tasks_proj/ $ pip install --no-cache-dir ./tasks_proj/ Processing ./tasks_proj Collecting click (from tasks==0.1.0) Downloading click-6.7-py2.py3-none-any.whl (71kB) ... Collecting tinydb (from tasks==0.1.0) Downloading tinydb-3.4.0.tar.gz Collecting six (from tasks==0.1.0) Downloading six-1.10.0-py2.py3-none-any.whl Installing collected packages: click, tinydb, six, tasks Running setup.py install for tinydb ... done Running setup.py install for tasks ... done Successfully installed click-6.7 six-1.10.0 tasks-0.1.0 tinydb-3.4.0</code> </pre> <br><p>  Wenn Sie nur Tests für Aufgaben ausführen möchten, reicht dieser Befehl aus.  Wenn Sie den Quellcode während der Installation von Aufgaben ändern möchten, müssen Sie die Installation mit der Option -e verwenden (für bearbeitbares "bearbeitbares"): </p><br><pre> <code class="plaintext hljs">$ pip install -e ./tasks_proj/ Obtaining file:///path/to/code/tasks_proj Requirement already satisfied: click in /path/to/venv/lib/python3.6/site-packages (from tasks==0.1.0) Requirement already satisfied: tinydb in /path/to/venv/lib/python3.6/site-packages (from tasks==0.1.0) Requirement already satisfied: six in /path/to/venv/lib/python3.6/site-packages (from tasks==0.1.0) Installing collected packages: tasks Found existing installation: tasks 0.1.0 Uninstalling tasks-0.1.0: Successfully uninstalled tasks-0.1.0 Running setup.py develop for tasks Successfully installed tasks</code> </pre> <br><p>  Versuchen Sie nun, die Tests auszuführen: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch2/tasks_proj/tests/unit $ pytest test_task.py ===================== test session starts ====================== collected 4 items test_task.py .... =================== 4 passed in 0.01 seconds ===================</code> </pre> <br><p>  Import hat funktioniert!  Andere Tests können jetzt sicher Importaufgaben verwenden.  Jetzt schreiben wir einige Tests. </p><br><h2 id="ispolzovanie-operatorov-assert">  Assert-Anweisungen verwenden </h2><br><p>  Wenn Sie Testfunktionen schreiben, ist die reguläre Python-Anweisung assert Ihr primäres Werkzeug zum Melden von Testfehlern.  Die Einfachheit bei pytest ist brillant.  Dies ist es, was viele Entwickler dazu bringt, Pytest zusätzlich zu anderen Frameworks zu verwenden. </p><br><p>  Wenn Sie eine andere Testplattform verwendet haben, haben Sie wahrscheinlich verschiedene Assert-Hilfsfunktionen gesehen.  Im Folgenden finden Sie beispielsweise eine Liste einiger Formen von Assert- und Assert-Hilfsfunktionen: </p><br><div class="scrollable-table"><table><thead><tr><th>  <strong>pytest</strong> </th><th>  <strong>unittest</strong> </th></tr></thead><tbody><tr><td>  etwas behaupten </td><td>  assertTrue (etwas) </td></tr><tr><td>  behaupten a == b </td><td>  assertEqual (a, b) </td></tr><tr><td>  behaupten a &lt;= b </td><td>  assertLessEqual (a, b) </td></tr><tr><td>  ... </td><td>  ... </td></tr></tbody></table></div><br><p>  Mit pytest können Sie assert &lt;Ausdruck&gt; für jeden Ausdruck verwenden.  Wenn der Ausdruck bei der Konvertierung in bool als False ausgewertet wird, schlägt der Test fehl. </p><br><p>  pytest enthält eine Funktion namens Assert Rewriting, die Assert-Aufrufe abfängt und durch etwas ersetzt, das Ihnen mehr darüber erzählen kann, warum Ihre Anweisungen fehlgeschlagen sind.  Mal sehen, wie nützlich dieses Umschreiben ist, wenn wir uns einige Anweisungsfehler ansehen: </p><br><blockquote>  <strong>ch2 / task_proj / tests / unit / test_task_fail.py</strong> </blockquote><br><pre> <code class="plaintext hljs">""" the Task type    .""" from tasks import Task def test_task_equality(): """     .""" t1 = Task('sit there', 'brian') t2 = Task('do something', 'okken') assert t1 == t2 def test_dict_equality(): """ ,   dicts,    .""" t1_dict = Task('make sandwich', 'okken')._asdict() t2_dict = Task('make sandwich', 'okkem')._asdict() assert t1_dict == t2_dict</code> </pre> <br><p>  Alle diese Tests schlagen fehl, aber die Informationen in der Ablaufverfolgung sind interessant: </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\unit&gt;pytest test_task_fail.py ============================= test session starts ============================= collected 2 items test_task_fail.py FF ================================== FAILURES =================================== _____________________________ test_task_equality ______________________________ def test_task_equality(): """Different tasks should not be equal.""" t1 = Task('sit there', 'brian') t2 = Task('do something', 'okken') &gt; assert t1 == t2 E AssertionError: assert Task(summary=...alse, id=None) == Task(summary='...alse, id=None) E At index 0 diff: 'sit there' != 'do something' E Use -v to get the full diff test_task_fail.py:9: AssertionError _____________________________ test_dict_equality ______________________________ def test_dict_equality(): """Different tasks compared as dicts should not be equal.""" t1_dict = Task('make sandwich', 'okken')._asdict() t2_dict = Task('make sandwich', 'okkem')._asdict() &gt; assert t1_dict == t2_dict E AssertionError: assert OrderedDict([...('id', None)]) == OrderedDict([(...('id', None)]) E Omitting 3 identical items, use -vv to show E Differing items: E {'owner': 'okken'} != {'owner': 'okkem'} E Use -v to get the full diff test_task_fail.py:16: AssertionError ========================== 2 failed in 0.30 seconds ===========================</code> </pre> <br><p>  Wow!  Das sind viele Informationen.  Für jeden nicht erfolgreichen Test wird die genaue Fehlerzeichenfolge mit&gt; einem Fehlerzeiger angezeigt.  In den Zeilen E werden zusätzliche Informationen zum Assert-Fehler angezeigt, damit Sie besser verstehen, was schief gelaufen ist. </p><br><p>  Ich habe absichtlich zwei Fehlpaarungen in <code>test_task_equality()</code> , aber nur die erste wurde im vorherigen Code angezeigt.  Versuchen wir es erneut mit dem Flag <code>-v</code> , wie in der Fehlermeldung vorgeschlagen: </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\unit&gt;pytest -v test_task_fail.py ============================= test session starts ============================= collected 2 items test_task_fail.py::test_task_equality FAILED test_task_fail.py::test_dict_equality FAILED ================================== FAILURES =================================== _____________________________ test_task_equality ______________________________ def test_task_equality(): """Different tasks should not be equal.""" t1 = Task('sit there', 'brian') t2 = Task('do something', 'okken') &gt; assert t1 == t2 E AssertionError: assert Task(summary=...alse, id=None) == Task(summary='...alse, id=None) E At index 0 diff: 'sit there' != 'do something' E Full diff: E - Task(summary='sit there', owner='brian', done=False, id=None) E ? ^^^ ^^^ ^^^^ E + Task(summary='do something', owner='okken', done=False, id=None) E ? +++ ^^^ ^^^ ^^^^ test_task_fail.py:9: AssertionError _____________________________ test_dict_equality ______________________________ def test_dict_equality(): """Different tasks compared as dicts should not be equal.""" t1_dict = Task('make sandwich', 'okken')._asdict() t2_dict = Task('make sandwich', 'okkem')._asdict() &gt; assert t1_dict == t2_dict E AssertionError: assert OrderedDict([...('id', None)]) == OrderedDict([(...('id', None)]) E Omitting 3 identical items, use -vv to show E Differing items: E {'owner': 'okken'} != {'owner': 'okkem'} E Full diff: E {'summary': 'make sandwich', E - 'owner': 'okken', E ? ^... E E ...Full output truncated (5 lines hidden), use '-vv' to show test_task_fail.py:16: AssertionError ========================== 2 failed in 0.28 seconds ===========================</code> </pre> <br><p>  Nun, ich finde es verdammt cool!  pytest konnte nicht nur beide Unterschiede feststellen, sondern zeigte uns auch genau, wo diese Unterschiede liegen.  In diesem Beispiel wird nur die Gleichheitsbestätigung verwendet.  Auf pytest.org finden Sie viele weitere Variationen der assert-Anweisung mit erstaunlichen Informationen zum Trace-Debugging. </p><br><h2 id="ozhidanie-isklyucheniy-expected-exception">  Erwartete Ausnahme </h2><br><p>  Ausnahmen können an mehreren Stellen in der Aufgaben-API auftreten.  <em>Werfen</em> wir einen kurzen Blick auf die Funktionen in <em>task / api.py</em> : </p><br><pre> <code class="plaintext hljs">def add(task): # type: (Task) -\&gt; int def get(task_id): # type: (int) -\&gt; Task def list_tasks(owner=None): # type: (str|None) -\&gt; list of Task def count(): # type: (None) -\&gt; int def update(task_id, task): # type: (int, Task) -\&gt; None def delete(task_id): # type: (int) -\&gt; None def delete_all(): # type: () -\&gt; None def unique_id(): # type: () -\&gt; int def start_tasks_db(db_path, db_type): # type: (str, str) -\&gt; None def stop_tasks_db(): # type: () -\&gt; None</code> </pre> <br><p>  Zwischen dem CLI-Code in <em>cli.py</em> und dem API-Code in <em>api.py</em> besteht eine Vereinbarung darüber, welche Typen an die API-Funktionen übergeben werden.  Bei API-Aufrufen erwarte ich, dass Ausnahmen ausgelöst werden, wenn der Typ falsch ist.  Um sicherzustellen, dass diese Funktionen Ausnahmen auslösen, wenn sie nicht korrekt aufgerufen werden, verwenden Sie den falschen Typ in der Testfunktion, um absichtlich TypeError-Ausnahmen auszulösen und mit pytest.raises (erwartete Ausnahme) zu verwenden, zum Beispiel: </p><br><blockquote>  <strong>ch2 / task_proj / tests / func / test_api_exceptions.py</strong> </blockquote><br><pre> <code class="plaintext hljs">"""    -   API.""" import pytest import tasks def test_add_raises(): """add()       param.""" with pytest.raises(TypeError): tasks.add(task='not a Task object')</code> </pre> <br><p>  In <code>test_add_raises()</code> mit <code>pytest.raises(TypeError)</code> : Die Anweisung gibt an, dass alles im nächsten Codeblock eine TypeError-Ausnahme auslösen soll.  Wenn keine Ausnahme ausgelöst wird, schlägt der Test fehl.  Wenn der Test eine weitere Ausnahme auslöst, schlägt er fehl. </p><br><p>  Wir haben gerade die Art der Ausnahme in <code>test_add_raises()</code> überprüft.  Sie können auch die Ausschlussoptionen überprüfen.  Für <code>start_tasks_db(db_path, db_type)</code> sollte nicht nur <em>db_type</em> eine Zeichenfolge sein, sondern auch entweder 'tiny' oder 'mongo'.  Sie können überprüfen, ob die Ausnahmemeldung korrekt ist, indem Sie excinfo hinzufügen: </p><br><blockquote>  <strong>ch2 / task_proj / tests / func / test_api_exceptions.py</strong> </blockquote><br><pre> <code class="plaintext hljs">def test_start_tasks_db_raises(): """,     .""" with pytest.raises(ValueError) as excinfo: tasks.start_tasks_db('some/great/path', 'mysql') exception_msg = excinfo.value.args[0] assert exception_msg == "db_type must be a 'tiny' or 'mongo'"</code> </pre> <br><p>  Dies ermöglicht es uns, diese Ausnahme genauer zu betrachten.  Der Variablenname nach as (in diesem Fall excinfo) wird mit Ausnahmeinformationen gefüllt und ist vom Typ ExceptionInfo. </p><br><p>  In unserem Fall möchten wir sicherstellen, dass der erste (und einzige) Ausnahmeparameter mit der Zeichenfolge übereinstimmt. </p><br><h2 id="marking-test-functions">  Testfunktionen markieren </h2><br><p>  pytest bietet einen coolen Mechanismus, um Marker in Testfunktionen zu setzen.  Ein Test kann mehr als einen Marker haben, und ein Marker kann sich in mehreren Tests befinden. </p><br><p>  Marker machen für Sie Sinn, nachdem Sie sie in Aktion gesehen haben.  Angenommen, wir möchten eine Teilmenge unserer Tests als schnellen "Rauchtest" ausführen, um eine Vorstellung davon zu erhalten, ob eine ernsthafte Lücke im System besteht.  Konventionell handelt es sich bei Rauchtests nicht um umfassende, gründliche Testsuiten, sondern um eine ausgewählte Teilmenge, die Sie schnell ausführen können, um dem Entwickler ein anständiges Bild des Zustands aller Teile des Systems zu vermitteln. </p><br><p>  Um Ihrem Aufgabenprojekt eine <code>@mark.pytest.smoke</code> hinzuzufügen, müssen <code>@mark.pytest.smoke</code> für einige Tests <code>@mark.pytest.smoke</code> hinzufügen.  <code>test_api_exceptions.py</code> wir es mehreren <code>test_api_exceptions.py</code> Tests hinzu (beachten Sie, dass <em>Rauch-</em> und <em>Get-</em> Marker nicht in pytest integriert sind; ich habe sie mir gerade ausgedacht): </p><br><blockquote>  <strong>ch2 / task_proj / tests / func / test_api_exceptions.py</strong> </blockquote><br><pre> <code class="plaintext hljs">@pytest.mark.smoke def test_list_raises(): """list()       param.""" with pytest.raises(TypeError): tasks.list_tasks(owner=123) @pytest.mark.get @pytest.mark.smoke def test_get_raises(): """get()       param.""" with pytest.raises(TypeError): tasks.get(task_id='123')</code> </pre> <br><p>  Lassen Sie uns nun nur die Tests ausführen, die mit <code>-m marker_name</code> : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests&gt;cd func (venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v -m "smoke" test_api_exceptions.py ============================= test session starts ============================= collected 7 items test_api_exceptions.py::test_list_raises PASSED test_api_exceptions.py::test_get_raises PASSED ============================= 5 tests deselected ============================== =================== 2 passed, 5 deselected in 0.18 seconds ==================== (venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt; (venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v -m "get" test_api_exceptions.py ============================= test session starts ============================= collected 7 items test_api_exceptions.py::test_get_raises PASSED ============================= 6 tests deselected ============================== =================== 1 passed, 6 deselected in 0.13 seconds ====================</code> </pre> <br><p>  Denken Sie daran, dass <code>-v</code> für <code>--verbose</code> und es uns ermöglicht, die Namen der ausgeführten Tests <code>--verbose</code> .  Mit -m 'Rauch' werden beide Tests mit der Bezeichnung @ pytest.mark.smoke ausgeführt. </p><br><p>  Mit <code>-m</code> 'get' wird ein Test mit der <code>@pytest.mark.get</code> .  Ziemlich einfach. </p><br><p>  Alles wird zu Wundern und Wundern!  Ein Ausdruck nach <code>-m</code> kann <code>and</code> <code>or</code> <code>not</code> um mehrere Marker <code>not</code> kombinieren: </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v -m "smoke and get" test_api_exceptions.py ============================= test session starts ============================= collected 7 items test_api_exceptions.py::test_get_raises PASSED ============================= 6 tests deselected ============================== =================== 1 passed, 6 deselected in 0.13 seconds ====================</code> </pre> <br><p>  Wir haben diesen Test nur mit <code>smoke</code> und <code>get</code> Marker.  Wir können <code>not</code> : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v -m "smoke and not get" test_api_exceptions.py ============================= test session starts ============================= collected 7 items test_api_exceptions.py::test_list_raises PASSED ============================= 6 tests deselected ============================== =================== 1 passed, 6 deselected in 0.13 seconds ====================</code> </pre> <br><p>  Durch Hinzufügen von <code>-m 'smoke and not get'</code> wurde ein Test ausgewählt, der mit <code>@pytest.mark.smoke</code> aber nicht mit <code>@pytest.mark.get</code> . </p><br><h3 id="zapolnenie-smoke-test">  Rauchtestfüllung </h3><br><p>  Frühere Tests scheinen noch kein vernünftiger Satz von <code>smoke test</code> .  Wir haben die Datenbank tatsächlich nicht berührt und keine Aufgaben hinzugefügt.  Natürlich müsste ein <code>smoke test</code> dies tun. </p><br><p>  Fügen wir einige Tests hinzu, die das Hinzufügen einer Aufgabe in Betracht ziehen, und verwenden Sie einen davon als Teil unserer Rauchtestsuite: </p><br><blockquote>  <strong>ch2 / task_proj / tests / func / test_add.py</strong> </blockquote><br><pre> <code class="plaintext hljs">"""  API tasks.add ().""" import pytest import tasks from tasks import Task def test_add_returns_valid_id(): """tasks.add(valid task)    .""" # GIVEN an initialized tasks db # WHEN a new task is added # THEN returned task_id is of type int new_task = Task('do something') task_id = tasks.add(new_task) assert isinstance(task_id, int) @pytest.mark.smoke def test_added_task_has_id_set(): """,   task_id  tasks.add().""" # GIVEN an initialized tasks db # AND a new task is added new_task = Task('sit in chair', owner='me', done=True) task_id = tasks.add(new_task) # WHEN task is retrieved task_from_db = tasks.get(task_id) # THEN task_id matches id field assert task_from_db.id == task_id</code> </pre> <br><p>  Beide Tests haben einen GIVEN-Kommentar zur initialisierten Aufgabendatenbank, aber es gibt keine initialisierte Datenbank im Test.  Wir können ein Gerät definieren, um die Datenbank vor dem Test zu initialisieren und nach dem Test zu bereinigen: </p><br><blockquote>  <strong>ch2 / task_proj / tests / func / test_add.py</strong> </blockquote><br><pre> <code class="plaintext hljs">@pytest.fixture(autouse=True) def initialized_tasks_db(tmpdir): """Connect to db before testing, disconnect after.""" # Setup : start db tasks.start_tasks_db(str(tmpdir), 'tiny') yield #    # Teardown : stop db tasks.stop_tasks_db()</code> </pre> <br><p>  Das in diesem Beispiel verwendete Gerät tmpdir ist ein integriertes Gerät.  In Kapitel 4, Eingebaute Geräte, auf Seite 71 erfahren Sie alles über integrierte Geräte. In Kapitel 3, Pytest-Geräte, auf Seite 49 erfahren Sie, wie Sie Ihre eigenen Geräte schreiben und wie sie funktionieren, einschließlich des hier verwendeten Autouse-Parameters. </p><br><p>  Die in unserem Test verwendete automatische Maus zeigt, dass alle Tests in dieser Datei Fixture verwenden.  Der Code vor der <code>yield</code> wird vor jedem Test ausgeführt.  Der Code nach <code>yield</code> wird nach dem Test ausgeführt.  Falls gewünscht, kann die Ausbeute Daten an den Test zurückgeben.  All dies und noch viel mehr werden Sie in den folgenden Kapiteln betrachten, aber hier müssen wir die Datenbank irgendwie zum Testen konfigurieren, damit ich nicht länger warten kann und Ihnen dieses Gerät zeigen muss (Fixture natürlich!).  (pytest unterstützt auch die altmodischen Setup- und Teardown-Funktionen, wie sie beispielsweise bei <strong>Unittest</strong> und <strong>Nose verwendet werden</strong> , ist jedoch nicht so interessant. Wenn Sie jedoch interessiert sind, werden sie in Anhang 5, xUnit Fixtures, auf Seite 183 beschrieben.) </p><br><p>  Lassen Sie uns die Diskussion über die Geräte vorerst verschieben und zum Beginn des Projekts gehen und unsere <em>Rauchtestsuite</em> ausführen: </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;cd .. (venv33) ...\bopytest-code\code\ch2\tasks_proj\tests&gt;cd .. (venv33) ...\bopytest-code\code\ch2\tasks_proj&gt;pytest -v -m "smoke" ============================= test session starts ============================= collected 56 items tests/func/test_add.py::test_added_task_has_id_set PASSED tests/func/test_api_exceptions.py::test_list_raises PASSED tests/func/test_api_exceptions.py::test_get_raises PASSED ============================= 53 tests deselected ============================= =================== 3 passed, 53 deselected in 0.49 seconds ===================</code> </pre> <br><p>  Es zeigt, dass markierte Tests aus verschiedenen Dateien zusammen ausgeführt werden können. </p><br><h2 id="propusk-testov-skipping-tests">  Tests überspringen </h2><br><p>  Obwohl die unter Markierungsüberprüfungsmethoden auf Seite 31 beschriebenen Markierungen die Namen Ihrer Wahl waren, enthält pytest einige nützliche integrierte Markierungen: <code>skipif</code> , <code>xfail</code> und <code>xfail</code> .  In diesem Abschnitt werde ich über <code>skip</code> und <code>skipif</code> sprechen und im nächsten <code>-xfail</code> . </p><br><p>  Mit den <code>skipif</code> <code>skip</code> und " <code>skipif</code> können Sie Tests überspringen, die nicht durchgeführt werden müssen.  <code>tasks.unique_id()</code> wir zum Beispiel an, wir wüssten nicht, wie <code>tasks.unique_id()</code> funktionieren soll.  Jeder Anruf sollte eine andere Nummer zurückgeben?    ,       ? </p><br><p> -,    (,        <code>initialized_tasks_db</code> ;     ): </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_unique_id_1.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">"""Test tasks.unique_id().""" import pytest import tasks def test_unique_id(): """ unique_id ()     .""" id_1 = tasks.unique_id() id_2 = tasks.unique_id() assert id_1 != id_2</code> </pre> <br><p>    : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest test_unique_id_1.py ============================= test session starts ============================= collected 1 item test_unique_id_1.py F ================================== FAILURES =================================== _______________________________ test_unique_id ________________________________ def test_unique_id(): """Calling unique_id() twice should return different numbers.""" id_1 = tasks.unique_id() id_2 = tasks.unique_id() &gt; assert id_1 != id_2 E assert 1 != 1 test_unique_id_1.py:11: AssertionError ========================== 1 failed in 0.30 seconds ===========================</code> </pre> <br><p>  Hm.  ,  .   API  ,  ,  docstring  """Return an integer that does not exist in the db.""",   <em>  ,     DB</em> .      .       ,   : </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_unique_id_2.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">@pytest.mark.skip(reason='misunderstood the API') def test_unique_id_1(): """ unique_id ()     .""" id_1 = tasks.unique_id() id_2 = tasks.unique_id() assert id_1 != id_2 def test_unique_id_2(): """unique_id()    id.""" ids = [] ids.append(tasks.add(Task('one'))) ids.append(tasks.add(Task('two'))) ids.append(tasks.add(Task('three'))) #   id uid = tasks.unique_id() # ,        assert uid not in ids</code> </pre> <br><p>  ,   ,   ,   <code>@pytest..skip()</code>    . </p><br><p>  : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_unique_id_2.py ============================= test session starts ============================= collected 2 items test_unique_id_2.py::test_unique_id_1 SKIPPED test_unique_id_2.py::test_unique_id_2 PASSED ===================== 1 passed, 1 skipped in 0.19 seconds =====================</code> </pre> <br><p>  ,   -   ,       ,         0.2.0 .           skipif: </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_unique_id_3.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">@pytest.mark.skipif(tasks.__version__ &lt; '0.2.0', reason='not supported until version 0.2.0') def test_unique_id_1(): """ unique_id ()     .""" id_1 = tasks.unique_id() id_2 = tasks.unique_id() assert id_1 != id_2</code> </pre> <br><p> ,     <code>skipif()</code> ,      Python.   ,  ,    .      <em>skip</em> ,    <em>skipif</em> .     <em>skip</em> ,     <em>skipif</em> .      ( <em>reason</em> )   <em>skip</em> , <em>skipif</em>  <em>xfail</em> .    : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest test_unique_id_3.py ============================= test session starts ============================= collected 2 items test_unique_id_3.py s. ===================== 1 passed, 1 skipped in 0.20 seconds =====================</code> </pre> <br><p> <code>s.</code> ,     (skipped),    (passed).   ,    -  <code>-v</code> : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_unique_id_3.py ============================= test session starts ============================= collected 2 items test_unique_id_3.py::test_unique_id_1 SKIPPED test_unique_id_3.py::test_unique_id_2 PASSED ===================== 1 passed, 1 skipped in 0.19 seconds =====================</code> </pre> <br><p>       .        <code>-rs</code> : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -rs test_unique_id_3.py ============================= test session starts ============================= collected 2 items test_unique_id_3.py s. =========================== short test summary info =========================== SKIP [1] func\test_unique_id_3.py:8: not supported until version 0.2.0 ===================== 1 passed, 1 skipped in 0.22 seconds =====================</code> </pre> <br><p>  <code>-r chars</code>    : </p><br><pre> <code class="plaintext hljs">$ pytest --help ... -r chars show extra test summary info as specified by chars (     ,  ) (f)ailed, (E)error, (s)skipped, (x)failed, (X)passed, (p)passed, (P)passed with output, (a)all except pP. ...</code> </pre> <br><p>        ,           . </p><br><h2 id="markirovka-testov-ozhidayuschih-sboya">     </h2><br><p>    <code>skip</code>  <code>skipif</code>    ,   .    <code>xfail</code>   pytest   ,  ,    .     <code>unique_id ()</code> ,   <code>xfail</code> : </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_unique_id_4.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">@pytest.mark.xfail(tasks.__version__ &lt; '0.2.0', reason='not supported until version 0.2.0') def test_unique_id_1(): """ unique_id()     .""" id_1 = tasks.unique_id() id_2 = tasks.unique_id() assert id_1 != id_2 @pytest.mark.xfail() def test_unique_id_is_a_duck(): """ xfail.""" uid = tasks.unique_id() assert uid == 'a duck' @pytest.mark.xfail() def test_unique_id_not_a_duck(): """ xpass.""" uid = tasks.unique_id() assert uid != 'a duck'</code> </pre> <br><p> Running this shows: </p><br><p>    ,   ,   <code>xfail</code> .         == vs.! =.      . </p><br><p>   : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest test_unique_id_4.py ============================= test session starts ============================= collected 4 items test_unique_id_4.py xxX. =============== 1 passed, 2 xfailed, 1 xpassed in 0.36 seconds ================</code> </pre> <br><p> X  XFAIL,   «  ( <em>expected to fail</em> )».  X   XPASS  «,    ,   ( <em>expected to fail but passed.</em> )». </p><br><p> <code>--verbose</code>    : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_unique_id_4.py ============================= test session starts ============================= collected 4 items test_unique_id_4.py::test_unique_id_1 xfail test_unique_id_4.py::test_unique_id_is_a_duck xfail test_unique_id_4.py::test_unique_id_not_a_duck XPASS test_unique_id_4.py::test_unique_id_2 PASSED =============== 1 passed, 2 xfailed, 1 xpassed in 0.36 seconds ================</code> </pre> <br><p>    <em>pytest</em> ,  ,  ,    <code>xfail</code> ,   FAIL.    <em>pytest.ini</em> : </p><br><pre> <code class="plaintext hljs">[pytest] xfail_strict=true</code> </pre> <br><p>    <em>pytest.ini</em>    6, ,  . 113. </p><br><h2 id="vypolnenie-podmnozhestva-testov">    </h2><br><p>    ,         ​​    .       .        , ,          .      ,       .        .    . </p><br><h3 id="a-single-directory"> A Single Directory </h3><br><p>       ,      <em>pytest</em> : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj&gt;pytest tests\func --tb=no ============================= test session starts ============================= collected 50 items tests\func\test_add.py .. tests\func\test_add_variety.py ................................ tests\func\test_api_exceptions.py ....... tests\func\test_unique_id_1.py F tests\func\test_unique_id_2.py s. tests\func\test_unique_id_3.py s. tests\func\test_unique_id_4.py xxX. ==== 1 failed, 44 passed, 2 skipped, 2 xfailed, 1 xpassed in 1.75 seconds =====</code> </pre> <br><p>     ,   <code>-v</code>      ,   . </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj&gt;pytest -v tests\func --tb=no ============================= test session starts =============================</code> </pre> <br><p>  ... </p><br><pre> <code class="plaintext hljs">collected 50 items tests\func\test_add.py::test_add_returns_valid_id PASSED tests\func\test_add.py::test_added_task_has_id_set PASSED tests\func\test_add_variety.py::test_add_1 PASSED tests\func\test_add_variety.py::test_add_2[task0] PASSED tests\func\test_add_variety.py::test_add_2[task1] PASSED tests\func\test_add_variety.py::test_add_2[task2] PASSED tests\func\test_add_variety.py::test_add_2[task3] PASSED tests\func\test_add_variety.py::test_add_3[sleep-None-False] PASSED ... tests\func\test_unique_id_2.py::test_unique_id_1 SKIPPED tests\func\test_unique_id_2.py::test_unique_id_2 PASSED ... tests\func\test_unique_id_4.py::test_unique_id_1 xfail tests\func\test_unique_id_4.py::test_unique_id_is_a_duck xfail tests\func\test_unique_id_4.py::test_unique_id_not_a_duck XPASS tests\func\test_unique_id_4.py::test_unique_id_2 PASSED ==== 1 failed, 44 passed, 2 skipped, 2 xfailed, 1 xpassed in 2.05 seconds =====</code> </pre> <br><p>   ,      . </p><br><h3 id="odinochnyy-test-filemodule">   File/Module </h3><br><p>   ,  ,          pytest: </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch2/tasks_proj $ pytest tests/func/test_add.py =========================== test session starts =========================== collected 2 items tests/func/test_add.py .. ======================== 2 passed in 0.05 seconds =========================</code> </pre> <br><p>        . </p><br><h3 id="odinochnaya-testovaya-funkciya">    </h3><br><p>     ,  <code>::</code>    : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch2/tasks_proj $ pytest -v tests/func/test_add.py::test_add_returns_valid_id =========================== test session starts =========================== collected 3 items tests/func/test_add.py::test_add_returns_valid_id PASSED ======================== 1 passed in 0.02 seconds =========================</code> </pre> <br><p>  <code>-v</code> ,  ,    . </p><br><h3 id="odinochnyy-test-class">  Test Class </h3><br><p> Here's an example: </p><br><p>   —    ,     . <br>  Hier ist ein Beispiel: </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/</strong> <code>test_api_exceptions.py</code> </blockquote><br><pre> <code class="plaintext hljs">class TestUpdate(): """    tasks.update().""" def test_bad_id(self): """non-int id   excption.""" with pytest.raises(TypeError): tasks.update(task_id={'dict instead': 1}, task=tasks.Task()) def test_bad_task(self): """A non-Task task   excption.""" with pytest.raises(TypeError): tasks.update(task_id=1, task='not a task')</code> </pre> <br><p>      ,     <code>update()</code> ,     .     ,   ,        <code>::</code> ,      : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj&gt;pytest -v tests/func/test_api_exceptions.py::TestUpdate ============================= test session starts ============================= collected 2 items tests\func\test_api_exceptions.py::TestUpdate::test_bad_id PASSED tests\func\test_api_exceptions.py::TestUpdate::test_bad_task PASSED ========================== 2 passed in 0.12 seconds ===========================</code> </pre> <br><h3 id="a-single-test-method-of-a-test-class"> A Single Test Method of a Test Class </h3><br><p>        ,     —     <code>::</code>   : </p><br><pre> <code class="plaintext hljs">$ cd /path/to/code/ch2/tasks_proj $ pytest -v tests/func/test_api_exceptions.py::TestUpdate::test_bad_id ===================== test session starts ====================== collected 1 item tests/func/test_api_exceptions.py::TestUpdate::test_bad_id PASSED =================== 1 passed in 0.03 seconds ===================</code> </pre> <br><blockquote> <strong> ,   </strong> <br><br> ,        , , ,      .   ,        <code>pytest -v</code> . </blockquote><br><h3 id="nabor-testov-na-osnove-bazovogo-imeni-testa">        </h3><br><p>  <code>-k</code>      ,         .       <code>and</code> , <code>or</code>  <code>not</code>  . ,        <code>_raises</code> : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj&gt;pytest -v -k _raises ============================= test session starts ============================= collected 56 items tests/func/test_api_exceptions.py::test_add_raises PASSED tests/func/test_api_exceptions.py::test_list_raises PASSED tests/func/test_api_exceptions.py::test_get_raises PASSED tests/func/test_api_exceptions.py::test_delete_raises PASSED tests/func/test_api_exceptions.py::test_start_tasks_db_raises PASSED ============================= 51 tests deselected ============================= =================== 5 passed, 51 deselected in 0.54 seconds ===================</code> </pre> <br><p>    <code>and</code>  <code>not</code>    <code>test_delete_raises()</code>  : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj&gt;pytest -v -k "_raises and not delete" ============================= test session starts ============================= collected 56 items tests/func/test_api_exceptions.py::test_add_raises PASSED tests/func/test_api_exceptions.py::test_list_raises PASSED tests/func/test_api_exceptions.py::test_get_raises PASSED tests/func/test_api_exceptions.py::test_start_tasks_db_raises PASSED ============================= 52 tests deselected ============================= =================== 4 passed, 52 deselected in 0.44 seconds ===================</code> </pre> <br><p>     ,     , ,         <code>-k</code>     .     ,          ,         . </p><br><h2 id="parametrized-testing-parametrizovannoe-testirovanie"> [Parametrized Testing]:   </h2><br><p>         ,     ,       .                  .  -               pytest,  -    . </p><br><p>    ,     ,      <code>add()</code> : </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_add_variety.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">"""  API tasks.add().""" import pytest import tasks from tasks import Task def test_add_1(): """tasks.get ()  id,   add() works.""" task = Task('breathe', 'BRIAN', True) task_id = tasks.add(task) t_from_db = tasks.get(task_id) # ,  ,    assert equivalent(t_from_db, task) def equivalent(t1, t2): """   .""" #  ,   id return ((t1.summary == t2.summary) and (t1.owner == t2.owner) and (t1.done == t2.done)) @pytest.fixture(autouse=True) def initialized_tasks_db(tmpdir): """    ,  .""" tasks.start_tasks_db(str(tmpdir), 'tiny') yield tasks.stop_tasks_db()</code> </pre> <br><p>    tasks   <code>id</code>   <code>None</code> .           <code>id</code> .       <code>==</code> ,  ,        .   <code>equivalent()</code>  ,   <code>id</code> .  <code>autouse</code> ,  ,    .  ,   : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_add_variety.py::test_add_1 ============================= test session starts ============================= collected 1 item test_add_variety.py::test_add_1 PASSED ========================== 1 passed in 0.69 seconds ===========================</code> </pre> <br><p>   .   ,      .  ,       ?  .    <code>@pytest.mark.parametrize(argnames, argvalues)</code>          , : </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_add_variety.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">@pytest.mark.parametrize('task', [Task('sleep', done=True), Task('wake', 'brian'), Task('breathe', 'BRIAN', True), Task('exercise', 'BrIaN', False)]) def test_add_2(task): """    .""" task_id = tasks.add(task) t_from_db = tasks.get(task_id) assert equivalent(t_from_db, task)</code> </pre> <br><p>   <code>parametrize()</code> —        — 'task',   .   —   ,         Task. pytest               : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_add_variety.py::test_add_2 ============================= test session starts ============================= collected 4 items test_add_variety.py::test_add_2[task0] PASSED test_add_variety.py::test_add_2[task1] PASSED test_add_variety.py::test_add_2[task2] PASSED test_add_variety.py::test_add_2[task3] PASSED ========================== 4 passed in 0.69 seconds ===========================</code> </pre> <br><p>  <code>parametrize()</code>    .      ,  ,      : </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_add_variety.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">@pytest.mark.parametrize('summary, owner, done', [('sleep', None, False), ('wake', 'brian', False), ('breathe', 'BRIAN', True), ('eat eggs', 'BrIaN', False), ]) def test_add_3(summary, owner, done): """    .""" task = Task(summary, owner, done) task_id = tasks.add(task) t_from_db = tasks.get(task_id) assert equivalent(t_from_db, task)</code> </pre> <br><p>   ,        pytest,       ,      : </p><br><pre> <code class="plaintext hljs">(venv35) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_add_variety.py::test_add_3 ============================= test session starts ============================= platform win32 -- Python 3.5.2, pytest-3.5.1, py-1.5.3, pluggy-0.6.0 -- cachedir: ..\.pytest_cache rootdir: ...\bopytest-code\code\ch2\tasks_proj\tests, inifile: pytest.ini collected 4 items test_add_variety.py::test_add_3[sleep-None-False] PASSED [ 25%] test_add_variety.py::test_add_3[wake-brian-False] PASSED [ 50%] test_add_variety.py::test_add_3[breathe-BRIAN-True] PASSED [ 75%] test_add_variety.py::test_add_3[eat eggs-BrIaN-False] PASSED [100%] ========================== 4 passed in 0.37 seconds ===========================</code> </pre> <br><p>  ,      ,     pytest,    : </p><br><pre> <code class="plaintext hljs">(venv35) c:\BOOK\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_add_variety.py::test_add_3[sleep-None-False] ============================= test session starts ============================= test_add_variety.py::test_add_3[sleep-None-False] PASSED [100%] ========================== 1 passed in 0.22 seconds ===========================</code> </pre> <br><p>   ,     : </p><br><pre> <code class="plaintext hljs">(venv35) c:\BOOK\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v "test_add_variety.py::test_add_3[eat eggs-BrIaN-False]" ============================= test session starts ============================= collected 1 item test_add_variety.py::test_add_3[eat eggs-BrIaN-False] PASSED [100%] ========================== 1 passed in 0.56 seconds ===========================</code> </pre> <br><p>      ,        : </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_add_variety.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">tasks_to_try = (Task('sleep', done=True), Task('wake', 'brian'), Task('wake', 'brian'), Task('breathe', 'BRIAN', True), Task('exercise', 'BrIaN', False)) @pytest.mark.parametrize('task', tasks_to_try) def test_add_4(task): """ .""" task_id = tasks.add(task) t_from_db = tasks.get(task_id) assert equivalent(t_from_db, task)</code> </pre> <br><p>      .     : </p><br><pre> <code class="plaintext hljs">(venv35) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_add_variety.py::test_add_4 ============================= test session starts ============================= collected 5 items test_add_variety.py::test_add_4[task0] PASSED [ 20%] test_add_variety.py::test_add_4[task1] PASSED [ 40%] test_add_variety.py::test_add_4[task2] PASSED [ 60%] test_add_variety.py::test_add_4[task3] PASSED [ 80%] test_add_variety.py::test_add_4[task4] PASSED [100%] ========================== 5 passed in 0.34 seconds ===========================</code> </pre> <br><p>      ,     .    ,      ids  <code>parametrize()</code> ,          .  <code>ids</code>       ,     . ,         <code>tasks_to_try</code> ,       : </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_add_variety.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">task_ids = ['Task({},{},{})'.format(t.summary, t.owner, t.done) for t in tasks_to_try] @pytest.mark.parametrize('task', tasks_to_try, ids=task_ids) def test_add_5(task): """Demonstrate ids.""" task_id = tasks.add(task) t_from_db = tasks.get(task_id) assert equivalent(t_from_db, task)</code> </pre> <br><p>     ,   : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_add_variety.py::test_add_5 ============================= test session starts ============================= collected 5 items test_add_variety.py::test_add_5[Task(sleep,None,True)] PASSED test_add_variety.py::test_add_5[Task(wake,brian,False)0] PASSED test_add_variety.py::test_add_5[Task(wake,brian,False)1] PASSED test_add_variety.py::test_add_5[Task(breathe,BRIAN,True)] PASSED test_add_variety.py::test_add_5[Task(exercise,BrIaN,False)] PASSED ========================== 5 passed in 0.45 seconds ===========================</code> </pre> <br><p>        : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v "test_add_variety.py::test_add_5[Task(exercise,BrIaN,False)]" ============================= test session starts ============================= collected 1 item test_add_variety.py::test_add_5[Task(exercise,BrIaN,False)] PASSED ========================== 1 passed in 0.21 seconds ===========================</code> </pre> <br><p>       ;          shell.     <code>parametrize()</code>  .               : </p><br><blockquote> <strong>ch2/tasks_proj/tests/func/ <code>test_add_variety.py</code></strong> </blockquote><br><pre> <code class="plaintext hljs">@pytest.mark.parametrize('task', tasks_to_try, ids=task_ids) class TestAdd(): """   .""" def test_equivalent(self, task): """ ,   .""" task_id = tasks.add(task) t_from_db = tasks.get(task_id) assert equivalent(t_from_db, task) def test_valid_id(self, task): """          .""" task_id = tasks.add(task) t_from_db = tasks.get(task_id) assert t_from_db.id == task_id</code> </pre> <br><p>    : </p><br><pre> <code class="plaintext hljs">(venv33) ...\bopytest-code\code\ch2\tasks_proj\tests\func&gt;pytest -v test_add_variety.py::TestAdd ============================= test session starts ============================= collected 10 items test_add_variety.py::TestAdd::test_equivalent[Task(sleep,None,True)] PASSED test_add_variety.py::TestAdd::test_equivalent[Task(wake,brian,False)0] PASSED test_add_variety.py::TestAdd::test_equivalent[Task(wake,brian,False)1] PASSED test_add_variety.py::TestAdd::test_equivalent[Task(breathe,BRIAN,True)] PASSED test_add_variety.py::TestAdd::test_equivalent[Task(exercise,BrIaN,False)] PASSED test_add_variety.py::TestAdd::test_valid_id[Task(sleep,None,True)] PASSED test_add_variety.py::TestAdd::test_valid_id[Task(wake,brian,False)0] PASSED test_add_variety.py::TestAdd::test_valid_id[Task(wake,brian,False)1] PASSED test_add_variety.py::TestAdd::test_valid_id[Task(breathe,BRIAN,True)] PASSED test_add_variety.py::TestAdd::test_valid_id[Task(exercise,BrIaN,False)] PASSED ========================== 10 passed in 1.16 seconds ==========================</code> </pre> <br><p>     ,            <code>@pytest.mark.parametrize()</code> .       <code>pytest.param(&lt;value\&gt;, id="something")</code> : </p><br><p>  : </p><br><pre> <code class="plaintext hljs">(venv35) ...\bopytest-code\code\ch2\tasks_proj\tests\func $ pytest -v test_add_variety.py::test_add_6 ======================================== test session starts ========================================= collected 3 items test_add_variety.py::test_add_6[just summary] PASSED [ 33%] test_add_variety.py::test_add_6[summary\owner] PASSED [ 66%] test_add_variety.py::test_add_6[summary\owner\done] PASSED [100%] ================================ 3 passed, 6 warnings in 0.35 seconds ================================</code> </pre> <br><p>  ,  <code>id</code>       . </p><br><h2 id="uprazhneniya">  Übungen </h2><br><ol><li>     , <code>task_proj</code> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">-  </a>  ,         <code>pip install /path/to/tasks_proj</code> . </li><li>   . </li><li>  <em>pytest</em>   . </li><li>  <em>pytest</em>   ,  <code>tasks_proj/tests/func</code> .  pytest     ,     .     .  ,    ? </li><li>  xfail      ,     pytest   tests    . </li><li>      <code>tasks.count()</code> ,   .    API  ,     ,  ,    . </li><li>          ?       <code>test_api_exceptions.py</code> . ,      . (   <code>api.py</code>   .) </li></ol><br><h2 id="chto-dalshe">  Was weiter </h2><br><p>         <em>pytest</em> . ,   ,   ,       .         <code>initialized_tasks_db</code> .     /        . </p><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie können auch gemeinsamen Code trennen, sodass mehrere Testfunktionen dieselbe Einstellung verwenden können. </font><font style="vertical-align: inherit;">Im nächsten Kapitel tauchen Sie tief in die wunderbare Welt des Fixtures Pytest ein.</font></font></p><br><p><img src="https://habrastorage.org/webt/jl/jn/bb/jljnbbjr-ejh473xy_eccsmknpk.png">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zurück</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Weiter</a> <img src="https://habrastorage.org/webt/rw/dy/-g/rwdy-grsvbpcetjttrmecdkxtlk.png"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de448788/">https://habr.com/ru/post/de448788/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de448776/index.html">RxVMS - Eine praktische Architektur für Flatteranwendungen</a></li>
<li><a href="../de448778/index.html">Einführung in das Zeitreise-Debugging für Visual Studio Enterprise 2019</a></li>
<li><a href="../de448780/index.html">Was gibt Software für die Rekrutierung in Geld</a></li>
<li><a href="../de448784/index.html">Neue Funktionen für Erweiterungsautoren in Visual Studio 2019 Version 16.1</a></li>
<li><a href="../de448786/index.html">Python-Test mit Pytest. KAPITEL 3 Pytest-Vorrichtungen</a></li>
<li><a href="../de448790/index.html">SpaceVIL - plattformübergreifendes GUI-Framework für die Entwicklung auf .Net Core, .Net Standard und JVM</a></li>
<li><a href="../de448794/index.html">Python-Test mit Pytest. Plugins KAPITEL 5</a></li>
<li><a href="../de448796/index.html">Python-Test mit Pytest. Konfiguration, KAPITEL 6</a></li>
<li><a href="../de448798/index.html">Python-Test mit Pytest. Verwenden von pytest mit anderen Tools, KAPITEL 7</a></li>
<li><a href="../de448800/index.html">Konfigurieren Sie Visual Studio in Ihrer Organisation mit .vsconfig</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
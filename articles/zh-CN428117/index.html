<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙀 🔫 🥢 Google在协作云中提供免费的张量处理器 🖕🏻 🔅 ♓️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Google最近在基于Colaboratory的基于云的机器学习平台上免费提供了其张量处理单元（TPU）的访问权限。 张量处理器是由Google开发的专用集成电路（ASIC），用于使用TensorFlow库进行机器学习。 我决定尝试在Keras上学习TPU卷积网络，该网络可以识别CIFAR-10图像...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Google在协作云中提供免费的张量处理器</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428117/">  Google最近在基于<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Colaboratory</a>的基于云的机器学习<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">平台</a>上免费提供了其<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">张量</a>处理单元（TPU）的访问权限。 张量处理器是由Google开发的专用集成电路（ASIC），用于使用TensorFlow库进行机器学习。 我决定尝试在Keras上学习TPU卷积网络，该网络可以识别CIFAR-10图像中的物体。 完整的解决方案代码可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">笔记本电脑</a>上查看和运行。 <br><br><img src="https://habrastorage.org/webt/sl/ut/ho/slutho5dsyeduk2biql9rcsblnu.jpeg"><br>  <i>图片<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">cloud.google.com</a></i> <br><a name="habracut"></a><br><h2> 张量处理器 </h2><br> 在Habré上已经写了TPU的布置方式（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这里</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这里</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这里</a> ），以及<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">为什么TPU非常适合训练神经网络</a> 。 因此，我不会深入研究TPU架构的细节，而只会考虑训练神经网络时需要考虑的功能。 <br><br> 现在有三代张量处理器，最后的第三代TPU的性能为420 TFlops（每秒数万亿个浮点运算），其中包含128 GB的高带宽内存。 但是，只有第二代TPU在Colaboratory上可用，它们具有180 TFlops的性能和64 GB的内存。 将来，我将考虑这些TPU。 <br><br> 张量处理器由四个芯片组成，每个芯片包含两个内核，TPU中总共有八个内核。 使用复制在所有内核上并行进行TPU训练：每个内核运行TensorFlow图的一个副本，该副本的数据量为八分之一。 <br><br> 张量处理器的基础是矩阵单元（MXU）。 它使用128x128 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">脉动阵列</a>的狡猾数据结构来高效执行矩阵运算。 因此，为了最大程度地使用TPU设备资源，小型样本或特征的维数必须是128（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">源</a> ）的倍数。 而且，由于TPU存储系统的性质，希望微型样本和特征的尺寸为8的倍数。 <br><br><h2> 协作平台 </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Colaboratory</a>是Google的先进机器学习技术的云平台。 您可以免费获得带有已安装的流行库TensorFlow，Keras，sklearn，pandas等的虚拟机。 最方便的是，您可以在Colaboratory上运行类似于Jupyter的笔记本电脑。 笔记本电脑存储在Google云端硬盘中，您可以分发笔记本甚至组织协作。 这是便携式计算机在协作室中的外观（ <i>图片可点击</i> ）： <br><br> <a href=""><img src="https://habrastorage.org/webt/4b/gp/sn/4bgpsnbpkhwyqrid6fixnaurcbw.png"></a> <br><br> 您可以在笔记本电脑上的浏览器中编写代码，该代码可以在Google Cloud的虚拟机上运行。 汽车会签发给您12个小时，然后停下来。 但是，没有什么可以阻止您启动另一个虚拟机并再工作12个小时。 只需记住，虚拟机停止后，虚拟机中的所有数据都会被删除。 因此，请不要忘记将必要的数据保存到您的计算机或Google云端硬盘中，然后在重新启动虚拟机之后再次下载。 <br><br> 有关在Colaboratory平台上工作的详细说明，请参见<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a> 。 <br><br><h2> 将张量处理器连接到协作实验室 </h2><br> 默认情况下，Colaboratory不使用GPU或TPU计算加速器。 您可以在菜单运行系统-&gt;更改运行系统类型-&gt;硬件加速器中连接它们。 在出现的列表中，选择“ TPU”： <br><img src="https://habrastorage.org/webt/1f/7r/vt/1f7rvtfjvdowdjwrz0ctgyyly7s.png" alt="图片"><br><br> 选择加速器类型后，将与Colaboratory便携式计算机连接的虚拟机将重新启动，并且TPU将可用。 <br><br> 如果您将任何数据下载到虚拟机，则在重新启动过程中将删除该数据。 您必须再次下载数据。 <br><br><h2> 用于CIFAR-10识别的Keras神经网络 </h2><br> 举例来说，让我们尝试在TPU上训练Keras神经网络，以识别来自<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">CIFAR-10数据集的</a>图像。 这是一个受欢迎的数据集，其中包含10类物体的小型图像：飞机，汽车，鸟，猫，鹿，狗，青蛙，马，船和卡车。 类不相交，图片中的每个对象仅属于一个类。 <br><br> 使用Keras下载CIFAR-10数据集： <br><br><pre><code class="python hljs">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</code> </pre> <br> 为了创建神经网络，我得到了一个单独的函数。 我们将两次创建相同的模型：用于TPU的模型的第一个版本，我们将在该模型上进行训练，而用于CPU的第二个模型，我们将在其中识别对象。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> input_layer = Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), dtype=tf.float32, name=<span class="hljs-string"><span class="hljs-string">'Input'</span></span>) x = BatchNormalization()(input_layer) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) x = MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(x) x = BatchNormalization()(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(x) x = Flatten()(x) x = Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) output_layer = Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[input_layer], outputs=[output_layer]) model.compile( optimizer=tf.train.AdamOptimizer(<span class="hljs-number"><span class="hljs-number">0.001</span></span>), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[<span class="hljs-string"><span class="hljs-string">'sparse_categorical_accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br> 到目前为止，Keras优化器无法在TPU上使用，因此，在编译模型时，将指定TensorFlow的优化器。 <br><br> 我们为CPU创建Keras模型，在下一步中，我们将其转换为TPU模型： <br><br><pre> <code class="python hljs">cpu_model = create_model()</code> </pre> <br><h2> 将Keras神经网络转换为TPU模型 </h2><br>  Keras和TensorFlow上的模型可以在GPU上进行训练而无需任何更改。 到目前为止，您还不能在TPU上执行此操作，因此您必须将我们创建的模型转换为TPU的模型。 <br><br> 首先，您需要找出可供我们使用的TPU的位置。 在协作平台上，可以使用以下命令完成此操作： <br><br><pre> <code class="python hljs">TPU_WORKER = <span class="hljs-string"><span class="hljs-string">'grpc://'</span></span> + os.environ[<span class="hljs-string"><span class="hljs-string">'COLAB_TPU_ADDR'</span></span>]</code> </pre> <br> 在我的情况下，TPU地址原来是这样的<code>grpc://10.102.233.146:8470</code> 。 对于不同的发布会，地址是不同的。 <br><br> 现在，您可以使用<code>keras_to_tpu_model</code>函数获取TPU的模型： <br><br><pre> <code class="python hljs">tf.logging.set_verbosity(tf.logging.INFO) tpu_model = tf.contrib.tpu.keras_to_tpu_model( cpu_model, strategy=tf.contrib.tpu.TPUDistributionStrategy( tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))</code> </pre> <br> 第一行包括“信息”级别的日志记录。 这是模型转换日志： <br><br> <code>INFO:tensorflow:Querying Tensorflow master (b'grpc://10.102.233.146:8470') for TPU system metadata. <br> INFO:tensorflow:Found TPU system: <br> INFO:tensorflow:*** Num TPU Cores: 8 <br> INFO:tensorflow:*** Num TPU Workers: 1 <br> INFO:tensorflow:*** Num TPU Cores Per Worker: 8 <br> ... <br> WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.</code> <br> <br> 您可以看到在我们之前指定的地址找到了TPU，它具有8个核心。 我们还会看到警告， <code>tpu_model</code>是实验性的，可能随时更改或删除。 我希望随着时间的流逝，将有可能直接在TPU上训练Keras模型而无需进行任何转换。 <br><br><h2> 我们在TPU上训练模型 </h2><br> 可以通过调用<code>fit</code>方法以通常的方式为Keras训练TPU模型： <br><br><pre> <code class="python hljs">history = tpu_model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">128</span></span>*<span class="hljs-number"><span class="hljs-number">8</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">50</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre> <br> 这里有什么功能。 我们记得为了有效地使用TPU，最小样本大小必须是128的倍数。此外，使用最小样本中所有数据的八分之一对每个TPU内核进行训练。 因此，我们将训练期间的迷你样本大小设置为128 * 8，我们为每个TPU核心获得128张图片。 您可以使用较大的大小，例如256或512，则性能会更高。 <br><br> 就我而言，一个时代的训练平均需要6 s。 <br><br>  50年代的教育质量： <br> <code>Epoch 50/50 <br> - 6s - loss: 0.2727 - sparse_categorical_accuracy: 0.9006</code> <br> <br> 对训练数据正确回答的比例为90.06％。 我们使用TPU检查测试数据的质量： <br><br><pre> <code class="python hljs">scores = tpu_model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, batch_size=batch_size * <span class="hljs-number"><span class="hljs-number">8</span></span>) print(<span class="hljs-string"><span class="hljs-string">"     : %.2f%%"</span></span> % (scores[<span class="hljs-number"><span class="hljs-number">1</span></span>]*<span class="hljs-number"><span class="hljs-number">100</span></span>))</code> </pre> <br> <code>     : 80.79%</code> <br> <br> 现在保存经过训练的模型的权重： <br><br><pre> <code class="python hljs">tpu_model.save_weights(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br>  TensorFlow将给我们一条消息，即权重已从TPU传输到CPU： <br> <code>INFO:tensorflow:Copying TPU weights to the CPU</code> <br> <br> 应当注意，训练有素的网络的权重已保存在协作虚拟机的磁盘上。 当虚拟机停止时，来自虚拟机的所有数据将被删除。 如果您不想失去训练有素的体重，请将其保存到计算机中： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.colab <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> files files.download(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br><h2> 识别CPU上的对象 </h2><br> 现在，让我们尝试使用在TPU上训练的模型，以便使用CPU识别图像中的对象。 为此，请再次创建模型，并将在TPU上训练的权重加载到其中： <br><br><pre> <code class="python hljs">model = create_model() model.load_weights(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br> 该模型已准备就绪，可以在中央处理器上使用。 让我们尝试借助其帮助来识别CIFAR-10测试套件的图像之一： <br><br><pre> <code class="python hljs">index=<span class="hljs-number"><span class="hljs-number">111</span></span> plt.imshow(toimage(x_test[index])) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/za/z3/f-/zaz3f-jatj-5crlgsih84gsakg0.png"><br><br> 图片很小，但是您可以理解这是一架飞机。 我们开始认识： <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      CIFAR-10 classes=['', '', '', '', '', '', '', '', '', ''] x = x_test[index] #  , .. Keras    x = np.expand_dims(x, axis=0) #   prediction = model.predict(x) #       print(prediction) #     prediction = np.argmax(prediction) print(classes[prediction])</span></span></code> </pre> <br> 我们获得了神经元输出值的列表，除第一个值（对应于平面）外，几乎所有输出值都接近于零。 <br><br> <code>[[9.81738389e-01 2.91262069e-07 1.82225723e-02 9.78524668e-07 <br> 5.89265142e-07 6.76223244e-10 1.03252004e-10 9.23009047e-09 <br> 3.71878523e-05 3.16599618e-08]] <br> </code> <br> <br> 识别成功！ <br><br><h2> 总结 </h2><br> 可以在协作平台上演示TPU的可操作性，它可以用于在Keras上训练神经网络。 但是，CIFAR-10数据集太小；不足以完全加载TPU资源。 与GPU相比，加速度很小（您可以通过选择GPU作为加速器而不是TPU并再次训练模型来检查自己）。 <br><br> 在Habré上有一篇文章，其中介绍<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">了在训练网络ResNet-50时TPU和GPU V100的性能</a> 。 在执行此任务时，TPU表现出与四个V100 GPU相同的性能。 很好，Google免费提供了如此强大的神经网络学习加速器！ <br><br> 演示Keras神经网络在TPU上训练的视频。 <br><iframe width="560" height="315" src="https://www.youtube.com/embed/60xbDEpA49M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2> 有用的链接 </h2><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">具有完整Keras TPU模型学习代码的协作笔记本电脑</a> 。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">带有Keras TPU培训示例的协作笔记本，用于识别Fashion MNIST的衣服和鞋子</a> 。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Google Cloud中的Tensor处理器</a> 。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">张量处理器的体系结构和使用特点</a> 。 </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN428117/">https://habr.com/ru/post/zh-CN428117/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN428107/index.html">Angular 6 SPA模板ASP .NET Core 2.1应用程序的容器化</a></li>
<li><a href="../zh-CN428109/index.html">企业墙</a></li>
<li><a href="../zh-CN428111/index.html">Erlang中任意精度的算术</a></li>
<li><a href="../zh-CN428113/index.html">关于贝塞尔曲线，Arduino速度和一个有趣的站点，或者我如何度过周末的问题</a></li>
<li><a href="../zh-CN428115/index.html">电子商务的网络开发：2019年的5种技术趋势</a></li>
<li><a href="../zh-CN428119/index.html">“ Class-fields-proposal”或“ tc39 commit出了什么问题”</a></li>
<li><a href="../zh-CN428121/index.html">斯坦·德拉普金（Stan Drapkin）。 .NET中的高级密码陷阱</a></li>
<li><a href="../zh-CN428123/index.html">安全周41：好消息</a></li>
<li><a href="../zh-CN428125/index.html">谁是产品分析人员，为什么团队需要它们？</a></li>
<li><a href="../zh-CN428127/index.html">Nginx缓存：一切都是新的-被遗忘的很旧</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
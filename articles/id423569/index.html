<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‡ğŸ¼ ğŸ’‡ğŸ¾ ğŸ‘¨ğŸ¼ Kami mendefinisikan bahasa pesan dengan sederhana dan akurat ğŸ‘¨â€âœˆï¸ ğŸ® ğŸ‘­</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Di YouScan , kami memproses sekitar 100 juta pesan sehari, di mana banyak aturan dan berbagai fungsi pintar diterapkan. Untuk pekerjaan mereka yang be...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kami mendefinisikan bahasa pesan dengan sederhana dan akurat</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/423569/"><img src="https://habrastorage.org/getpro/habr/post_images/b5d/97b/37e/b5d97b37ec0ea5fce5bf22200c96fdb3.png" align="right" width="320"><br><p>  Di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">YouScan</a> , kami memproses sekitar 100 juta pesan sehari, di mana banyak aturan dan berbagai fungsi pintar diterapkan.  Untuk pekerjaan mereka yang benar, perlu untuk menentukan bahasa dengan benar, karena tidak semua fungsi dapat dibuat agnostik sehubungan dengan bahasa.  Pada artikel ini, kita akan secara singkat berbicara tentang studi kami tentang masalah ini dan menunjukkan penilaian kualitas pada dataset jaringan sosial.  jaringan. </p><a name="habracut"></a><br><h4 id="plan-stati">  Garis besar artikel </h4><br><ol><li>  Masalah Definisi Bahasa </li><li>  Solusi Publik yang Terjangkau <br><ul><li>  Detektor Bahasa Compact 2 </li><li>  Teks cepat </li></ul></li><li>  Penilaian kualitas </li><li>  Kesimpulan </li></ol><br><h2 id="1-problemy-opredeleniya-yazyka">  1. Masalah definisi bahasa </h2><br><p> Definisi bahasa adalah masalah yang agak lama dan banyak yang mencoba menyelesaikannya dalam kerangka multibahasa dari produk mereka.  Pendekatan yang lebih lama menggunakan solusi berdasarkan n-gram, ketika jumlah kemunculan n-gram tertentu dipertimbangkan dan berdasarkan ini, "kecepatan" untuk setiap bahasa dihitung, setelah itu bahasa yang paling mungkin dipilih sesuai dengan model kami.  Kelemahan utama dari model-model ini adalah bahwa konteksnya sama sekali tidak diperhitungkan, oleh karena itu, definisi bahasa untuk kelompok bahasa yang sama sulit.  Tetapi karena kesederhanaan model, kami berakhir dengan kecepatan penentuan tinggi, yang menghemat sumber daya untuk sistem yang sangat dimuat.  Pilihan lain, yang lebih modern, adalah solusi pada jaringan saraf berulang.  Solusi ini sudah didasarkan tidak hanya pada n-gram, tetapi juga memperhitungkan konteksnya, yang seharusnya memberikan peningkatan kualitas kerja. </p><br><p>  Kompleksitas menciptakan solusi Anda sendiri terletak pada pengumpulan data untuk pelatihan dan proses pembelajaran itu sendiri.  Solusi yang paling jelas adalah melatih model pada artikel-artikel Wikipedia, karena kita tahu bahasanya dengan pasti dan ada teks-teks terverifikasi berkualitas sangat tinggi yang relatif mudah dikompilasi.  Dan untuk melatih model Anda, Anda harus menghabiskan banyak waktu untuk merakit dataset, memprosesnya, dan kemudian memilih arsitektur terbaik.  Kemungkinan besar seseorang telah melakukan ini sebelum kita.  Di blok berikutnya, kami melihat solusi yang ada. </p><br><h2 id="2-dostupnye-publichnye-resheniya">  2. Solusi publik yang tersedia </h2><br><h3 id="compact-language-detector-2">  Detektor Bahasa Compact 2 </h3><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CLD2</a> adalah model probabilistik berbasis pembelajaran mesin (Naive Baessian classifier) â€‹â€‹yang dapat menentukan 83 bahasa berbeda untuk teks dalam format UTF-8 atau format html / xml.  Untuk bahasa campuran, model mengembalikan 3 bahasa teratas, di mana probabilitas dihitung sebagai persentase perkiraan teks dari jumlah total byte.  Jika model tidak yakin dengan jawabannya, maka kembalikan tag "unc". </p><br><p>  Keakuratan dan kelengkapan model ini berada pada level yang cukup baik, tetapi keunggulan utamanya adalah kecepatan.  Pembuatnya mengklaim sekitar 30 kb dalam 1 ms, pada pengujian kami tentang pembungkus Python yang kami terima dari 21 hingga 26 kb dalam 1 ms (70.000-85.000 pesan per detik, ukuran rata-rata adalah 0.8 kb dan median adalah 0.3 kb). </p><br><p>  Solusi ini sangat mudah digunakan.  Pertama, Anda perlu menginstal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pembungkus python</a> atau menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">buruh pelabuhan kami</a> . </p><br><p> Untuk membuat perkiraan, cukup impor <code>pycld2</code> library dan tulis satu baris kode tambahan: </p><br><div class="spoiler">  <b class="spoiler_title">Menentukan bahasa menggunakan cld2</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pycld2 <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> cld2 cld2.detect(<span class="hljs-string"><span class="hljs-string">"Bonjour, Habr!"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># (True, # 14, # (('FRENCH', 'fr', 92, 1102.0), # ('Unknown', 'un', 0, 0.0), # ('Unknown', 'un', 0, 0.0)))</span></span></code> </pre> </div></div><br><p>  Respons detektor adalah tupel tiga elemen: </p><br><ul><li>  bahasa didefinisikan atau tidak; </li><li>  jumlah karakter; </li><li>  tuple dari tiga bahasa yang paling mungkin, di mana nama lengkapnya lebih dulu, <br>  yang kedua adalah singkatan menurut ISO 3166 Codes, yang ketiga adalah persentase karakter yang dimiliki bahasa ini, dan yang keempat adalah jumlah byte. </li></ul><br><h3 id="fasttext">  Teks cepat </h3><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">FastText</a> adalah perpustakaan yang ditulis oleh Facebook untuk pembelajaran dan klasifikasi teks yang efektif.  Dalam kerangka kerja proyek ini, Facebook Research menyajikan embeddings untuk 157 bahasa yang menunjukkan hasil mutakhir untuk berbagai tugas, serta model untuk menentukan bahasa dan tugas pengawasan lainnya. </p><br><p>  Untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model definisi bahasa,</a> mereka menggunakan data dari Wikipedia, Tatoeba dan SETimes, dan sebagai penggolong, mereka menggunakan solusi fasttext mereka. </p><br><p>  Pengembang penelitian facebook menyediakan dua model: </p><br><ul><li>  <a href="">lid.176.bin</a> , yang sedikit lebih cepat dan lebih akurat daripada model kedua, tetapi beratnya 128Mb; </li><li>  <a href="">lid.176.ftz</a> - versi terkompresi dari model asli. </li></ul><br><p>  Untuk menggunakan model ini dalam python, Anda harus menginstal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pembungkus python terlebih dahulu untuk fasttext</a> .  Mungkin sulit untuk menginstalnya, jadi Anda harus mengikuti instruksi pada github dengan hati-hati atau menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">buruh pelabuhan kami</a> .  Anda juga perlu mengunduh model dari tautan di atas.  Kami akan menggunakan versi asli dalam artikel ini. </p><br><p>  Mengklasifikasikan bahasa menggunakan model dari Facebook sedikit lebih rumit, untuk ini kita memerlukan tiga baris kode: </p><br><div class="spoiler">  <b class="spoiler_title">Menentukan bahasa menggunakan model FastText</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pyfasttext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> FastText model = FastText(<span class="hljs-string"><span class="hljs-string">'../model/lid.176.bin'</span></span>) model.predict_proba([<span class="hljs-string"><span class="hljs-string">"Bonjour, Habr!"</span></span>], <span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-comment"><span class="hljs-comment">#[[('fr', 0.7602248429835308), # ('en', 0.05550386696556002), # ('ca', 0.04721488914800802)]]</span></span></code> </pre> </div></div><br><p>  Model FastText'a memungkinkan memprediksi probabilitas untuk n-bahasa, di mana secara default n = 1, tetapi dalam contoh ini kami telah menyimpulkan hasil untuk 3 bahasa teratas.  Untuk model ini, ini sudah merupakan probabilitas umum prediksi bahasa untuk teks, dan bukan jumlah karakter yang dimiliki bahasa tertentu, seperti yang terjadi pada model cld2.  Kecepatannya juga cukup tinggi - lebih dari 60.000 pesan per detik. </p><br><h2 id="3-ocenka-kachestva">  3. Penilaian kualitas </h2><br><p>  Kami akan mengevaluasi kualitas algoritma menggunakan data dari jejaring sosial untuk waktu acak yang diambil dari sistem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">YouScan</a> (sekitar 500 ribu referensi), oleh karena itu, sampel akan memiliki lebih banyak bahasa Rusia dan Inggris, masing-masing 43% dan 32%, masing-masing, Ukraina, Spanyol dan Portugis - tentang 2% dari masing-masing, dari bahasa yang tersisa kurang dari 1%.  Untuk target yang benar, kami akan mengambil markup melalui google translate, karena saat ini Google sangat baik dalam mengelola tidak hanya terjemahan, tetapi juga definisi bahasa teks.  Tentu saja, markupnya tidak ideal, tetapi dalam banyak kasus itu dapat dipercaya. </p><br><p>  Metrik untuk menilai kualitas definisi bahasa adalah akurasi, kelengkapan, dan f1.  Mari kita hitung dan ditampilkan di tabel: </p><br><div class="spoiler">  <b class="spoiler_title">Perbandingan kualitas dua algoritma</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">"../data/lang_data.txt"</span></span>, <span class="hljs-string"><span class="hljs-string">"r"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: text_l, cld2_l, ft_l, g_l = [], [], [], [] s = <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: s += i <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">' |end\n'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> s: text, cld2, ft, g = s.strip().rsplit(<span class="hljs-string"><span class="hljs-string">" ||| "</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) text_l.append(text) cld2_l.append(cld2) ft_l.append(ft) g_l.append(g.replace(<span class="hljs-string"><span class="hljs-string">" |end"</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>)) s=<span class="hljs-string"><span class="hljs-string">''</span></span> data = pd.DataFrame({<span class="hljs-string"><span class="hljs-string">"text"</span></span>: text_l, <span class="hljs-string"><span class="hljs-string">"cld2"</span></span>: cld2_l, <span class="hljs-string"><span class="hljs-string">"ft"</span></span>: ft_l, <span class="hljs-string"><span class="hljs-string">"google"</span></span>: g_l}) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">lang_summary</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(lang, col)</span></span></span><span class="hljs-function">:</span></span> prec = (data.loc[data[col] == lang, <span class="hljs-string"><span class="hljs-string">"google"</span></span>] == data.loc[data[col] == lang, col]).mean() rec = (data.loc[data[<span class="hljs-string"><span class="hljs-string">"google"</span></span>] == lang, <span class="hljs-string"><span class="hljs-string">"google"</span></span>] == data.loc[data[<span class="hljs-string"><span class="hljs-string">"google"</span></span>] == lang, col]).mean() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> round(prec, <span class="hljs-number"><span class="hljs-number">3</span></span>), round(rec, <span class="hljs-number"><span class="hljs-number">3</span></span>), round(<span class="hljs-number"><span class="hljs-number">2</span></span>*prec*rec / (prec + rec),<span class="hljs-number"><span class="hljs-number">3</span></span>) results = {} <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> approach <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> [<span class="hljs-string"><span class="hljs-string">"cld2"</span></span>, <span class="hljs-string"><span class="hljs-string">"ft"</span></span>]: results[approach] = {} <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> l <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[<span class="hljs-string"><span class="hljs-string">"google"</span></span>].value_counts().index[:<span class="hljs-number"><span class="hljs-number">20</span></span>]: results[approach][l] = lang_summary(l, approach) res = pd.DataFrame.from_dict(results) res[<span class="hljs-string"><span class="hljs-string">"cld2_prec"</span></span>], res[<span class="hljs-string"><span class="hljs-string">"cld2_rec"</span></span>], res[<span class="hljs-string"><span class="hljs-string">"cld2_f1"</span></span>] = res[<span class="hljs-string"><span class="hljs-string">"cld2"</span></span>].apply(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: [x[<span class="hljs-number"><span class="hljs-number">0</span></span>], x[<span class="hljs-number"><span class="hljs-number">1</span></span>], x[<span class="hljs-number"><span class="hljs-number">2</span></span>]]).str res[<span class="hljs-string"><span class="hljs-string">"ft_prec"</span></span>], res[<span class="hljs-string"><span class="hljs-string">"ft_rec"</span></span>], res[<span class="hljs-string"><span class="hljs-string">"ft_f1"</span></span>] = res[<span class="hljs-string"><span class="hljs-string">"ft"</span></span>].apply(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: [x[<span class="hljs-number"><span class="hljs-number">0</span></span>], x[<span class="hljs-number"><span class="hljs-number">1</span></span>], x[<span class="hljs-number"><span class="hljs-number">2</span></span>]]).str res.drop(columns=[<span class="hljs-string"><span class="hljs-string">"cld2"</span></span>, <span class="hljs-string"><span class="hljs-string">"ft"</span></span>], inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) arrays = [[<span class="hljs-string"><span class="hljs-string">'cld2'</span></span>, <span class="hljs-string"><span class="hljs-string">'cld2'</span></span>, <span class="hljs-string"><span class="hljs-string">'cld2'</span></span>, <span class="hljs-string"><span class="hljs-string">'ft'</span></span>, <span class="hljs-string"><span class="hljs-string">'ft'</span></span>, <span class="hljs-string"><span class="hljs-string">'ft'</span></span>], [<span class="hljs-string"><span class="hljs-string">'precision'</span></span>, <span class="hljs-string"><span class="hljs-string">'recall'</span></span>, <span class="hljs-string"><span class="hljs-string">'f1_score'</span></span>, <span class="hljs-string"><span class="hljs-string">'precision'</span></span>, <span class="hljs-string"><span class="hljs-string">'recall'</span></span>, <span class="hljs-string"><span class="hljs-string">'f1_score'</span></span>]] tuples = list(zip(*arrays)) res.columns = pd.MultiIndex.from_tuples(tuples, names=[<span class="hljs-string"><span class="hljs-string">"approach"</span></span>, <span class="hljs-string"><span class="hljs-string">"metrics"</span></span>])</code> </pre> </div></div><br><table><thead><tr><th>  model </th><th></th><th>  cld2 </th><th></th><th></th><th>  ft </th><th></th><th></th><th>  ans </th><th></th></tr></thead><tbody><tr><td>  metrik </td><td>  prec </td><td>  rek </td><td>  f1 </td><td>  prec </td><td>  rek </td><td>  f1 </td><td>  prec </td><td>  rek </td><td>  f1 </td></tr><tr><td>  ar </td><td>  <strong>0,992</strong> </td><td>  0,725 </td><td>  0,838 </td><td>  0,918 </td><td>  0,697 </td><td>  0,793 </td><td>  0,968 </td><td>  <strong>0,788</strong> </td><td>  <strong>0,869</strong> </td></tr><tr><td>  az </td><td>  <strong>0,95</strong> </td><td>  0,752 </td><td>  0.839 </td><td>  0,888 </td><td>  0,547 </td><td>  0,677 </td><td>  0,914 </td><td>  <strong>0,787</strong> </td><td>  <strong>0,845</strong> </td></tr><tr><td>  bg </td><td>  <strong>0,529</strong> </td><td>  0,136 </td><td>  0,217 </td><td>  0,286 </td><td>  0,178 </td><td>  0,219 </td><td>  0,408 </td><td>  <strong>0,214</strong> </td><td>  <strong>0,281</strong> </td></tr><tr><td>  id </td><td>  <strong>0,949</strong> </td><td>  0.844 </td><td>  0,894 </td><td>  0,885 </td><td>  0,869 </td><td>  0,877 </td><td>  0,912 </td><td>  <strong>0,925</strong> </td><td>  <strong>0,918</strong> </td></tr><tr><td>  es </td><td>  <strong>0,987</strong> </td><td>  0,653 </td><td>  0,786 </td><td>  0,709 </td><td>  0.814 </td><td>  0,758 </td><td>  0,828 </td><td>  <strong>0.834</strong> </td><td>  <strong>0,831</strong> </td></tr><tr><td>  fr </td><td>  <strong>0,991</strong> </td><td>  0,713 </td><td>  <strong>0,829</strong> </td><td>  0,53 </td><td>  0,803 </td><td>  0,638 </td><td>  0,713 </td><td>  <strong>0,81</strong> </td><td>  0,758 </td></tr><tr><td>  id </td><td>  <strong>0,763</strong> </td><td>  0,543 </td><td>  <strong>0,634</strong> </td><td>  0,481 </td><td>  0,404 </td><td>  0,439 </td><td>  0,659 </td><td>  <strong>0,603</strong> </td><td>  0,63 </td></tr><tr><td>  itu </td><td>  <strong>0,975</strong> </td><td>  0,466 </td><td>  0,631 </td><td>  0,519 </td><td>  0,778 </td><td>  0,622 </td><td>  0,666 </td><td>  <strong>0,752</strong> </td><td>  <strong>0,706</strong> </td></tr><tr><td>  ja </td><td>  <strong>0,994</strong> </td><td>  0,899 </td><td>  <strong>0,944</strong> </td><td>  0,602 </td><td>  0.842 </td><td>  0,702 </td><td>  0,847 </td><td>  <strong>0,905</strong> </td><td>  0,875 </td></tr><tr><td>  ka </td><td>  <strong>0,962</strong> </td><td>  0,995 </td><td>  <strong>0,979</strong> </td><td>  0,959 </td><td>  0,905 </td><td>  0,931 </td><td>  0,958 </td><td>  <strong>0,995</strong> </td><td>  0,976 </td></tr><tr><td>  kk </td><td>  <strong>0,908</strong> </td><td>  0,653 </td><td>  0,759 </td><td>  0,804 </td><td>  0,584 </td><td>  0,677 </td><td>  0,831 </td><td>  <strong>0,713</strong> </td><td>  <strong>0,767</strong> </td></tr><tr><td>  ko </td><td>  <strong>0,984</strong> </td><td>  0,886 </td><td>  0,933 </td><td>  0,94 </td><td>  0,704 </td><td>  0,805 </td><td>  0,966 </td><td>  <strong>0,91</strong> </td><td>  <strong>0,937</strong> </td></tr><tr><td>  ms </td><td>  <strong>0,801</strong> </td><td>  0,578 </td><td>  <strong>0,672</strong> </td><td>  0,369 </td><td>  0,101 </td><td>  0,159 </td><td>  0,73 </td><td>  <strong>0,586</strong> </td><td>  0,65 </td></tr><tr><td>  pt </td><td>  <strong>0,968</strong> </td><td>  0,753 </td><td>  0,847 </td><td>  0,805 </td><td>  0,771 </td><td>  0,788 </td><td>  0,867 </td><td>  <strong>0,864</strong> </td><td>  <strong>0,865</strong> </td></tr><tr><td>  ru </td><td>  <strong>0,987</strong> </td><td>  0,809 </td><td>  0,889 </td><td>  0,936 </td><td>  0,933 </td><td>  0,935 </td><td>  0,953 </td><td>  <strong>0,948</strong> </td><td>  <strong>0,95</strong> </td></tr><tr><td>  sr </td><td>  0,093 </td><td>  0,114 </td><td>  0,103 </td><td>  <strong>0,174</strong> </td><td>  0,103 </td><td>  0,13 </td><td>  0,106 </td><td>  <strong>0,16</strong> </td><td>  <strong>0,128</strong> </td></tr><tr><td>  th </td><td>  <strong>0,989</strong> </td><td>  0,986 </td><td>  <strong>0,987</strong> </td><td>  0,973 </td><td>  0,927 </td><td>  0,95 </td><td>  0,979 </td><td>  <strong>0,986</strong> </td><td>  0,983 </td></tr><tr><td>  tr </td><td>  <strong>0,961</strong> </td><td>  0,639 </td><td>  <strong>0,768</strong> </td><td>  0,607 </td><td>  0,73 </td><td>  0,663 </td><td>  0,769 </td><td>  <strong>0,764</strong> </td><td>  0,767 </td></tr><tr><td>  uk </td><td>  <strong>0,949</strong> </td><td>  0,671 </td><td>  <strong>0,786</strong> </td><td>  0,615 </td><td>  0,733 </td><td>  0,669 </td><td>  0,774 </td><td>  <strong>0,777</strong> </td><td>  0,775 </td></tr><tr><td>  uz </td><td>  0,666 </td><td>  0,512 </td><td>  0,579 </td><td>  <strong>0,77</strong> </td><td>  0,169 </td><td>  0,278 </td><td>  0,655 </td><td>  <strong>0,541</strong> </td><td>  <strong>0,592</strong> </td></tr></tbody></table><br><p>  Hasilnya jelas menunjukkan bahwa pendekatan cld2 memiliki akurasi yang sangat tinggi dalam menentukan bahasa, hanya untuk bahasa yang tidak populer itu jatuh di bawah 90%, dan dalam 90% kasus hasilnya lebih baik daripada fasttext.  Dengan kelengkapan yang kurang lebih sama untuk kedua pendekatan, f1 lebih cepat di cld2. <br>  Keunikan dari model cld2 adalah bahwa ia memberikan perkiraan hanya untuk pesan-pesan yang cukup percaya diri, ini menjelaskan akurasi yang tinggi.  Model fasttext'a memberikan jawaban untuk sebagian besar pesan, oleh karena itu akurasinya jauh lebih rendah, tetapi aneh bahwa kelengkapannya tidak jauh lebih tinggi, dan dalam setengah kasus lebih rendah.  Tetapi jika Anda "memutar" ambang batas untuk model fasttext, maka Anda dapat meningkatkan akurasi. </p><br><h2 id="4-vyvody">  4. Kesimpulan </h2><br><p>  Secara umum, kedua model memberikan hasil yang baik dan dapat digunakan untuk memecahkan masalah menentukan bahasa di domain yang berbeda.  Keuntungan utama mereka adalah kecepatan tinggi, yang memungkinkan untuk membuat apa yang disebut "ensemble" dan menambahkan preprocessing yang diperlukan untuk meningkatkan kualitas. </p><br><p>  Anda dapat menemukan semua kode untuk mereproduksi eksperimen dan menguji pendekatan di atas dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">repositori kami</a> . </p><br><p>  Anda juga dapat melihat pengujian solusi ini di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel lain</a> , yang membandingkan akurasi dan kecepatan dalam 6 bahasa Eropa Barat. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id423569/">https://habr.com/ru/post/id423569/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id423557/index.html">Bayi, internet, dan orang tua. Bagaimana cara menghindari jebakan, manfaat dan tetap berteman?</a></li>
<li><a href="../id423559/index.html">Mencadangkan dan Memulihkan Sumber Daya Kubernetes dengan Heptio Ark</a></li>
<li><a href="../id423563/index.html">VPS.today - katalog server virtual</a></li>
<li><a href="../id423565/index.html">Gamepad dari Sega Mega Drive dan Raspberry Pi Bagian 1 (persiapan dan tiga tombol)</a></li>
<li><a href="../id423567/index.html">Sekali lagi tentang kecerdasan buatan</a></li>
<li><a href="../id423571/index.html">Segala macam hal di MetaPost</a></li>
<li><a href="../id423573/index.html">Sinkronisitas adalah mitos</a></li>
<li><a href="../id423575/index.html">Standar desain dalam mikroelektronika: di mana sebenarnya ada 7 nanometer dalam teknologi 7 nm?</a></li>
<li><a href="../id423577/index.html">Membuat game logika untuk platform game</a></li>
<li><a href="../id423579/index.html">Layanan Cloud untuk WebGL? Tidak terima kasih</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
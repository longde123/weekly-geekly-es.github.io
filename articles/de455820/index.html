<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî• üéÅ üññüèæ VM-Leistungsanalyse in VMware vSphere. Teil 2: Erinnerung üë©üèø‚Äçüíº üà≥ üì¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Teil 1. √úber die CPU 
 Teil 3. Informationen zur Lagerung 

 In diesem Artikel werden RAM-Leistungsindikatoren in vSphere behandelt. 
 Es scheint, das...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>VM-Leistungsanalyse in VMware vSphere. Teil 2: Erinnerung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataline/blog/455820/"><img src="https://habrastorage.org/webt/el/am/7y/elam7yyhc6vrowmmrt5ofxgj-r0.png"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 1. √úber die CPU</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 3. Informationen zur Lagerung</a> <br><br>  In diesem Artikel werden RAM-Leistungsindikatoren in vSphere behandelt. <br>  Es scheint, dass der Speicher immer eindeutiger ist als beim Prozessor: Wenn auf der VM Leistungsprobleme auftreten, ist es schwierig, diese nicht zu bemerken.  Aber wenn sie auftauchen, ist der Umgang mit ihnen viel schwieriger.  Aber das Wichtigste zuerst. <a name="habracut"></a><br><br><h3>  Ein bisschen Theorie </h3><br>  Der RAM virtueller Maschinen wird aus dem Speicher des Servers entnommen, auf dem die VMs ausgef√ºhrt werden.  Das ist ganz offensichtlich :).  Wenn der Server-RAM nicht f√ºr alle ausreicht, beginnt ESXi, Techniken zur Speicherwiederherstellung anzuwenden.  Andernfalls w√ºrden die VM-Betriebssysteme mit RAM-Zugriffsfehlern abst√ºrzen. <br><br>  Welche Techniken zur Verwendung von ESXi verwendet werden, h√§ngt von der RAM-Auslastung ab: <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Speicherstatus</b> <br></td><td>  <b>Die Grenze</b> <br></td><td>  <b>Aktionen</b> <br></td></tr><tr><td>  Hoch <br></td><td>  400% von minFree <br></td><td> Nach Erreichen der Obergrenze werden gro√üe Speicherseiten in kleine unterteilt (TPS arbeitet im Standardmodus). <br></td></tr><tr><td>  Klar <br></td><td>  100% von minFree <br></td><td>  Gro√üe Speicherseiten werden in kleine unterteilt, TPS arbeitet gewaltsam. <br></td></tr><tr><td>  Weich <br></td><td>  64% von minFree <br></td><td>  TPS + Ballon <br></td></tr><tr><td>  Schwer <br></td><td>  32% von minFree <br></td><td>  TPS + Komprimieren + Tauschen <br></td></tr><tr><td>  Niedrig <br></td><td>  16% von minFree <br></td><td>  Komprimieren + Tauschen + Blockieren <br></td></tr></tbody></table></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> <br><br>  minFree ist der RAM, den der Hypervisor ben√∂tigt, um zu funktionieren. <br><br>  Vor ESXi 4.1 einschlie√ülich war minFree standardm√§√üig festgelegt - 6% des Server-RAM (der Prozentsatz konnte √ºber die Option Mem.MinFreePct unter ESXi ge√§ndert werden).  In sp√§teren Versionen wurde die Berechnung aufgrund des Anstiegs des Speichervolumens auf minFree-Servern basierend auf der Speichergr√∂√üe des Hosts und nicht als fester Prozentwert berechnet. <br><br>  Der minFree-Wert (Standard) wird wie folgt berechnet: <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Prozentsatz des f√ºr minFree reservierten Speichers</b> <br></td><td>  <b>Speicherbereich</b> <br></td></tr><tr><td>  6% <br></td><td>  0-4 GB <br></td></tr><tr><td>  4% <br></td><td>  4-12 GB <br></td></tr><tr><td>  2% <br></td><td>  12-28 GB <br></td></tr><tr><td>  1% <br></td><td>  Verbleibende Erinnerung <br></td></tr></tbody></table></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> <br><br>  F√ºr einen Server mit 128 GB RAM lautet der MinFree-Wert beispielsweise: <br>  MinFree = 245,76 + 327,68 + 327,68 + 1024 = 1925,12 MB = 1,88 GB <br>  Der tats√§chliche Wert kann um einige hundert MB abweichen. Dies h√§ngt vom Server und vom RAM ab. <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Prozentsatz des f√ºr minFree reservierten Speichers</b> <br></td><td>  <b>Speicherbereich</b> <br></td><td>  <b>Wert f√ºr 128 GB</b> <br></td></tr><tr><td>  6% <br></td><td>  0-4 GB <br></td><td>  245,76 MB <br></td></tr><tr><td>  4% <br></td><td>  4-12 GB <br></td><td>  327,68 MB <br></td></tr><tr><td>  2% <br></td><td>  12-28 GB <br></td><td>  327,68 MB <br></td></tr><tr><td>  1% <br></td><td>  Verbleibender Speicher (100 GB) <br></td><td>  1024 MB <br></td></tr></tbody></table></div><br><br>  F√ºr produktive St√§nde kann normalerweise nur Hoch als normal angesehen werden.  F√ºr Test- und Entwicklungsst√§nde k√∂nnen klare / weiche Bedingungen akzeptabel sein.  Wenn auf dem Host weniger als 64% MinFree RAM vorhanden sind, treten bei den darauf ausgef√ºhrten VMs definitiv Leistungsprobleme auf. <br><br>  In jedem Zustand werden bestimmte Techniken zur Speicherr√ºckgewinnung angewendet, beginnend mit TPS, was die Leistung der VM praktisch nicht beeintr√§chtigt und mit Swapping endet.  Ich werde Ihnen mehr dar√ºber erz√§hlen. <br><br>  <b>Transparente Seitenfreigabe (TPS).</b>  TPS ist grob gesagt die Deduplizierung der RAM-Seiten virtueller Maschinen auf einem Server. <br><br>  ESXi sucht nach identischen Seiten des Arbeitsspeichers der virtuellen Maschine, z√§hlt und vergleicht die Hash-Summe der Seiten, entfernt doppelte Seiten und ersetzt sie durch Links zu derselben Seite im physischen Speicher des Servers.  Infolgedessen wird der physische Speicherverbrauch reduziert, und eine gewisse Neuzuordnung des Speichers kann mit geringem oder keinem Leistungsverlust erreicht werden. <br><br><img src="https://habrastorage.org/webt/ul/fz/1i/ulfz1i0bomyhsarceziylov-o6i.jpeg"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> <br><br>  Dieser Mechanismus funktioniert nur f√ºr 4-kB-Seiten (kleine Seiten).  Seiten mit einer Gr√∂√üe von 2 MB (gro√üe Seiten) versucht der Hypervisor nicht einmal zu deduplizieren: Die Chance, identische Seiten dieser Gr√∂√üe zu finden, ist nicht gro√ü. <br><br>  Standardm√§√üig weist ESXi gro√üen Seiten Speicher zu.  Das Aufteilen gro√üer Seiten in kleine Seiten beginnt mit Erreichen des Schwellenwerts f√ºr den Status "Hoch" und wird erzwungen, wenn der Status "L√∂schen" erreicht ist (siehe Tabelle mit dem Hypervisor-Status). <br><br>  Wenn Sie m√∂chten, dass TPS funktioniert, ohne darauf zu warten, dass der Host-RAM <i>voll</i> ist, m√ºssen Sie in Advanced Options ESXi den Wert <i>‚ÄûMem.AllocGuestLargePage‚Äú</i> auf 0 setzen (Standard ist 1).  Dann wird die Zuweisung gro√üer Speicherseiten f√ºr virtuelle Maschinen deaktiviert. <br><br>  Seit Dezember 2014 ist in allen ESXi-Versionen TPS zwischen VMs standardm√§√üig deaktiviert, da eine Sicherheitsanf√§lligkeit festgestellt wurde, die theoretisch den Zugriff auf den RAM einer anderen VM von einer VM aus erm√∂glicht.  Details hier.  Informationen zur praktischen Umsetzung der Ausnutzung der TPS-Sicherheitsl√ºcke habe ich nicht getroffen. <br><br>  Die TPS-Richtlinie wird √ºber die erweiterte Option <i>"Mem.ShareForceSalting"</i> unter ESXi gesteuert: <br>  0 - Inter-VM TPS.  TPS funktioniert f√ºr Seiten verschiedener VMs. <br>  1 - TPS f√ºr VMs mit demselben Wert "sched.mem.pshare.salt" in VMX; <br>  2 (Standard) - Intra-VM TPS.  TPS funktioniert f√ºr Seiten innerhalb einer VM. <br><br>  Es ist auf jeden Fall sinnvoll, gro√üe Seiten auszuschalten und Inter-VM TPS auf Testb√§nken zu aktivieren.  Es kann auch f√ºr St√§nde mit einer gro√üen Anzahl von VMs des gleichen Typs verwendet werden.  Beispielsweise kann an St√§nden mit VDI die Einsparung von physischem Speicher mehrere zehn Prozent erreichen. <br><br>  <b>Ged√§chtnisballon.</b>  Ballonfahren ist f√ºr das VM-Betriebssystem keine harmlose und transparente Technik mehr wie TPS.  Aber bei richtiger Anwendung mit Ballonfahren k√∂nnen Sie leben und sogar arbeiten. <br><br>  Zusammen mit Vmware Tools wird auf der VM ein spezieller Treiber installiert, der als Balloon-Treiber (auch bekannt als vmmemctl) bezeichnet wird.  Wenn dem Hypervisor der physische Speicher ausgeht und er in den Soft-Status wechselt, fordert ESXi die VM auf, den nicht verwendeten RAM √ºber diesen Ballon-Treiber zur√ºckzugeben.  Der Treiber arbeitet wiederum auf Betriebssystemebene und fordert von ihm freien Speicher an.  Der Hypervisor erkennt, welche Seiten des physischen Speichers Balloon Driver belegt hat, nimmt den Speicher von der virtuellen Maschine und gibt ihn an den Host zur√ºck.  Es gibt keine Probleme mit dem Betrieb des Betriebssystems, da auf Betriebssystemebene der Speicher vom Ballon-Treiber belegt wird.  Standardm√§√üig kann der Ballon-Treiber bis zu 65% des VM-Speichers belegen. <br><br>  Wenn VMware Tools nicht auf der VM installiert sind oder Ballooning deaktiviert ist (ich empfehle es nicht, aber es gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">KB</a> :), wechselt der Hypervisor sofort zu strengeren Methoden zum Entfernen von Speicher.  Fazit: Stellen Sie sicher, dass VMware Tools auf der VM vorhanden sind. <br><br><img src="https://habrastorage.org/webt/ey/pm/s1/eypms1ugdkmhr0r4odhga1locao.png"><br>  <i>Der Betrieb des Ballon-Treibers kann vom Betriebssystem aus √ºber VMware Tools √ºberpr√ºft werden</i> . <br><br>  <b>Speicherkomprimierung</b>  Diese Technik wird verwendet, wenn ESXi Hard erreicht.  Wie der Name schon sagt, versucht ESXi, 4 KB RAM-Seiten auf 2 KB zu komprimieren und so Speicherplatz im physischen Speicher des Servers freizugeben.  Diese Technik erh√∂ht die Zugriffszeit auf den Inhalt der Seiten des RAM-Speichers der VM erheblich, da die Seite zuerst gereinigt werden muss.  Manchmal k√∂nnen nicht alle Seiten komprimiert werden und der Vorgang selbst dauert einige Zeit.  Daher ist diese Technik in der Praxis nicht sehr effektiv. <br><br>  <b>Speicherwechsel.</b>  Nach einer kurzen Phase wechselt Memory Compression ESXi fast zwangsl√§ufig (wenn die VMs nicht zu anderen Hosts gingen oder heruntergefahren wurden) zu Swapping.  Wenn nur noch sehr wenig Speicher verf√ºgbar ist (Status "Niedrig"), weist der Hypervisor auch die Zuweisung von VM-Speicherseiten auf, was zu Problemen bei Gast-VMs f√ºhren kann. <br><br>  So funktioniert Swapping.  Wenn Sie die virtuelle Maschine einschalten, wird eine Datei mit der Erweiterung .vswp daf√ºr erstellt.  Die Gr√∂√üe entspricht dem nicht reservierten RAM der VM: Dies ist der Unterschied zwischen konfiguriertem und reserviertem Speicher.  Bei der Arbeit mit Swapping entl√§dt ESXi die Speicherseiten der virtuellen Maschine in diese Datei und beginnt mit der Arbeit damit anstelle des physischen Speichers des Servers.  Nat√ºrlich ist ein solcher "RAM" -Speicher mehrere Gr√∂√üenordnungen langsamer als der reale Speicher, selbst wenn .vswp schnell gespeichert wird. <br><br>  Im Gegensatz zu Ballooning k√∂nnen Seiten, die vom Betriebssystem oder von Anwendungen in der VM aktiv verwendet werden, beim Auslagern auf die Festplatte verschoben werden, wenn nicht verwendete Seiten aus einer VM ausgew√§hlt werden.  Infolgedessen sinkt die Leistung der VM, bis sie h√§ngt.  VM funktioniert formal und kann zumindest vom Betriebssystem aus korrekt deaktiviert werden.  Wenn du geduldig bist;) <br><br>  Wenn die VMs zu Swap gewechselt sind, ist dies eine abnormale Situation, die nach M√∂glichkeit am besten vermieden wird. <br><br><h3>  Grundlegende Leistungsindikatoren f√ºr den Arbeitsspeicher der virtuellen Maschine </h3><br>  Also kamen wir zur Hauptsache.  Zur √úberwachung des Speicherstatus in der VM stehen folgende Z√§hler zur Verf√ºgung: <br><br>  <b>Aktiv</b> - Zeigt die RAM-Gr√∂√üe (KB) an, auf die die VM in der vorherigen Messperiode Zugriff erhalten hat. <br><br>  <b>Die Verwendung entspricht</b> der von "Aktiv", jedoch als Prozentsatz des konfigurierten VM-Speichers.  Die Berechnung erfolgt nach folgender Formel: aktiv √∑ Speichergr√∂√üe der konfigurierten virtuellen Maschine. <br>  Hohe Auslastung bzw. Aktiv weisen nicht immer auf VM-Leistungsprobleme hin.  Wenn eine VM aggressiv Speicher verwendet (zumindest Zugriff darauf erh√§lt), bedeutet dies nicht, dass nicht gen√ºgend Speicher vorhanden ist.  Dies ist vielmehr eine Gelegenheit, um zu sehen, was im Betriebssystem geschieht. <br>  Es gibt einen Standardalarm zur Speichernutzung f√ºr VMs: <br><br><img src="https://habrastorage.org/webt/8u/ca/n8/8ucan84mevajwvlnr-4ov9boyro.png"><br><br>  <b>Shared</b> - Die Menge an RAM in einer VM, die mithilfe von TPS dedupliziert wurde (innerhalb einer VM oder zwischen VMs). <br><br>  <b>Zugegeben</b> - die Gr√∂√üe des physischen Speichers des Hosts (KB), der der VM zugewiesen wurde.  Beinhaltet Shared. <br><br>  <b>Verbraucht</b> (gew√§hrt - freigegeben) - Die Menge an physischem Speicher (KB), die die VM vom Host verbraucht.  Enth√§lt nicht Shared. <br><br>  Wenn ein Teil des VM-Speichers nicht aus dem physischen Speicher des Hosts zugewiesen wird, sondern aus der Auslagerungsdatei oder der Speicher von der VM √ºber den Balloon-Treiber √ºbernommen wurde, wird dieser Betrag in Granted and Consumed nicht ber√ºcksichtigt. <br>  Hohe Werte f√ºr gew√§hrt und verbraucht sind v√∂llig normal.  Das Betriebssystem nimmt dem Hypervisor nach und nach Speicher ab und gibt ihn nicht zur√ºck.  Mit einer aktiv arbeitenden VM n√§hern sich die Werte dieser Z√§hler im Laufe der Zeit der Menge des konfigurierten Speichers an und bleiben dort. <br><br>  <b>Null</b> - Die Gr√∂√üe des Arbeitsspeichers in der VM (KB), die Nullen enth√§lt.  Dieser Speicher wird als freier Hypervisor betrachtet und kann an andere virtuelle Maschinen weitergegeben werden.  Nachdem das Gastbetriebssystem es erhalten hat, hat es etwas in den Nullspeicher geschrieben, geht zu Consumed und kehrt nicht zur√ºck. <br><br>  <b>Reservierter Overhead</b> - Die vom Hypervisor reservierte RAM-Gr√∂√üe in der VM (KB), damit die VM funktioniert.  Dies ist eine kleine Menge, die jedoch auf dem Host verf√ºgbar sein muss, da sonst die VM nicht gestartet wird. <br><br>  <b>Ballon</b> - Die Menge an RAM (KB), die mit dem Ballon-Treiber von der VM belegt wurde. <br><br>  <b>Komprimiert</b> - Die Menge an RAM (KB), die komprimiert werden konnte. <br><br>  <b>Ausgetauscht</b> - die Gr√∂√üe des Arbeitsspeichers (KB), die mangels physischen Speichers auf dem Server auf die Festplatte verschoben wurde. <br>  Die Z√§hler f√ºr Ballon- und andere Speicherwiederherstellungstechniken sind Null. <br><br>  So sieht das Diagramm mit den Speicherz√§hlern einer normal funktionierenden VM mit 150 GB RAM aus. <br><br><img src="https://habrastorage.org/webt/0l/pp/w3/0lppw3nz9iqzcnuergtxiseb67s.png"><br><br>  In der folgenden Grafik weist die VM offensichtliche Probleme auf.  Die Grafik zeigt, dass f√ºr diese VM alle beschriebenen Techniken zum Arbeiten mit RAM verwendet wurden.  Der Ballon f√ºr diese VM ist viel gr√∂√üer als verbraucht.  Tats√§chlich ist die VM eher tot als lebendig. <br><br><img src="https://habrastorage.org/webt/f4/ic/xk/f4icxkpxpykxua_gp-sirlzuu_u.png"><br><br><h3>  ESXTOP </h3><br>  Wie bei der CPU lohnt es sich, ESXTOP zu verwenden, wenn Sie die Situation auf dem Host sowie dessen Dynamik in einem Intervall von bis zu 2 Sekunden schnell bewerten m√∂chten. <br><br>  Der ESXTOP-Speicherbildschirm wird mit der Taste ‚Äûm‚Äú aufgerufen und sieht folgenderma√üen aus (Felder B, D, H, J, K, L, O ausgew√§hlt): <br><br><img src="https://habrastorage.org/webt/rm/wj/4k/rmwj4krvvizdtcizkrid0zjuml8.png"><br><br>  Folgende Parameter werden f√ºr uns interessant sein: <br><br>  <b>Mem overcommit avg</b> - Der Durchschnittswert einer Speicher√ºberbelegung auf einem Host f√ºr 1, 5 und 15 Minuten.  Wenn √ºber Null, ist dies eine Gelegenheit zu sehen, was passiert, aber nicht immer ein Indikator f√ºr das Vorhandensein von Problemen. <br><br>  In den Zeilen <b>PMEM / MB</b> und <b>VMKMEM / MB</b> - Informationen zum physischen Speicher des Servers und zum f√ºr VMkernel verf√ºgbaren Speicher.  Aus dem interessanten hier k√∂nnen Sie den Wert minfree (in MB), den Status des Hosts aus dem Speicher (in unserem Fall hoch) sehen. <br><br>  In der <b>NUMA / MB-Zeile sehen</b> Sie die Verteilung des RAM nach NUMA-Knoten (Sockets).  In diesem Beispiel ist die Verteilung ungleichm√§√üig, was im Prinzip nicht sehr gut ist. <br><br>  Das Folgende ist eine Zusammenfassung der Serverstatistiken f√ºr Speicherwiederherstellungstechniken: <br><br>  <b>PSHARE / MB</b> ist eine TPS-Statistik. <br><br>  <b>SWAP / MB</b> - Statistiken zur Verwendung von Swap; <br><br>  <b>ZIP / MB</b> - Statistik der Komprimierung von Speicherseiten; <br><br>  <b>MEMCTL / MB</b> - Nutzungsstatistik f√ºr <b>Ballontreiber</b> . <br><br>  F√ºr einzelne VMs interessieren uns m√∂glicherweise die folgenden Informationen.  Ich habe die VM-Namen versteckt, um das Publikum nicht in Verlegenheit zu bringen :).  Wenn die ESXTOP-Metrik mit dem Z√§hler in vSphere identisch ist, zitiere ich den entsprechenden Z√§hler. <br><br>  <b>MEMSZ</b> ist die auf der VM konfigurierte Speichermenge (MB). <br>  MEMSZ = GRANT + MCTLSZ + SWCUR + unber√ºhrt. <br><br>  <b>GRANT</b> - In MB gew√§hrt. <br><br>  <b>TCHD</b> - Aktiv in MB. <br><br>  <b>MCTL?</b>  - ist auf dem VM Balloon Driver installiert. <br><br>  <b>MCTLSZ</b> - Ballon in MB. <br><br>  <b>MCTLGT</b> ist die Menge an RAM (MB), die ESXi √ºber den Balloon-Treiber (Memctl Target) von der VM entfernen m√∂chte. <br><br>  <b>MCTLMAX</b> - Die maximale RAM-Gr√∂√üe (MB), die ESXi √ºber den Balloon-Treiber von der VM entfernen kann. <br><br>  <b>SWCUR</b> - Die aktuelle RAM-Gr√∂√üe (MB), die der VM aus der Swap-Datei <b>zugewiesen wurde</b> . <br><br>  <b>SWGT</b> - Die Menge an RAM (MB), die ESXi VMs aus einer Swap-Datei (Swap Target) zur Verf√ºgung stellen m√∂chte. <br><br>  √úber ESXTOP k√∂nnen Sie auch detailliertere Informationen zur NUMA VM-Topologie anzeigen.  W√§hlen Sie dazu die Felder D, G: <br><br><img src="https://habrastorage.org/webt/ff/7y/zd/ff7yzdsjedyntnpj4duwv0c731m.png"><br><br>  <b>NHN</b> - NUMA-Knoten, auf denen sich die VM befindet.  Hier k√∂nnen Sie sofort eine breite VM feststellen, die nicht auf einen NUMA-Knoten passt. <br><br>  <b>NRMEM</b> - Wie viele Megabyte Speicher ben√∂tigt die VM vom Remote-NUMA-Knoten <b>?</b> <br><br>  <b>NLMEM</b> - Wie viele Megabyte Speicher ben√∂tigt die VM vom lokalen NUMA-Knoten <b>?</b> <br><br>  <b>N% L</b> - Prozentsatz des VM-Speichers auf dem lokalen NUMA-Knoten (bei weniger als 80% k√∂nnen Leistungsprobleme auftreten). <br><br><h3>  Speicher auf dem Hypervisor </h3><br>  Wenn die CPU-Z√§hler auf dem Hypervisor normalerweise nicht von besonderem Interesse sind, ist die Situation beim Speicher umgekehrt.  Eine hohe Speichernutzung auf der VM weist nicht immer auf ein Leistungsproblem hin, aber eine hohe Speichernutzung auf dem Hypervisor startet nur den Speicherverwaltungstechniker und verursacht Probleme mit der Leistung der VM.  Alarme zur Verwendung des Hostspeichers m√ºssen √ºberwacht werden, und VMs d√ºrfen Swap nicht betreten. <br><br><img src="https://habrastorage.org/webt/h2/x_/59/h2x_59kddpe84yzudcq03fq1rmc.png"><br><br><img src="https://habrastorage.org/webt/oc/w7/c9/ocw7c9vmbrqogjhmtpbotng4-6y.png"><br><br><h3>  Auspacken </h3><br>  Wenn die VM in Swap eingestiegen ist, wird ihre Leistung stark reduziert.  Ballon- und Komprimierungsspuren verschwinden schnell nach dem Auftreten von freiem RAM auf dem Host, aber die virtuelle Maschine hat es nicht eilig, von Swap zum Server-RAM zur√ºckzukehren. <br>  Vor ESXi 6.0 war der einzige zuverl√§ssige und schnelle Weg, VMs aus Swap zu entfernen, der Neustart (genauer gesagt das Ein- und Ausschalten des Containers).  Ab ESXi 6.0 erschien eine nicht so offizielle, aber funktionierende und zuverl√§ssige M√∂glichkeit, VMs aus Swap herauszuholen.  Bei einer der Konferenzen konnte ich mit einem der f√ºr den CPU-Scheduler verantwortlichen VMware-Ingenieure sprechen.  Er best√§tigte, dass die Methode ziemlich funktioniert und sicher ist.  Nach unserer Erfahrung wurden auch Probleme mit ihm nicht bemerkt. <br><br>  Die tats√§chlichen Befehle zum Ausgeben von VMs aus Swap wurden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von</a> Duncan Epping beschrieben.  Ich werde die detaillierte Beschreibung nicht wiederholen, sondern nur ein Beispiel f√ºr ihre Verwendung geben.  Wie im Screenshot zu sehen ist, verschwindet einige Zeit nach der Ausf√ºhrung der angegebenen Swap-Befehle auf der VM. <br><br><img src="https://habrastorage.org/webt/e5/lm/7e/e5lm7e0e6i_yxrrlm7dfwixptv0.png"><br><br><h3>  Tipps zum Verwalten des Arbeitsspeichers unter ESXi </h3><br>  Abschlie√üend gebe ich einige Tipps, um Probleme mit der VM-Leistung aufgrund von RAM zu vermeiden: <br><br><ul><li>  Vermeiden Sie eine √úberzeichnung des Arbeitsspeichers in produktiven Clustern.  Es ist immer ratsam, ~ 20-30% freien Speicher im Cluster zu haben, damit DRS (und der Administrator) Spielraum haben und VMs w√§hrend der Migration nicht zu Swap wechseln.  Vergessen Sie auch nicht den Spielraum f√ºr Fehlertoleranz.  Es ist unangenehm, wenn, wenn ein Server ausf√§llt und die VM mit HA neu gestartet wird, einige der Computer auch zu Swap wechseln. </li><li>  Versuchen Sie in stark konsolidierten Infrastrukturen NICHT, VMs mit mehr als der H√§lfte des Hostspeichers zu erstellen.  Dies hilft DRS wiederum dabei, virtuelle Maschinen problemlos auf die Cluster-Server zu verteilen.  Diese Regel ist nat√ºrlich nicht universell :). </li><li>  Achten Sie auf den Alarm zur Verwendung des Hostspeichers. </li><li>  Vergessen Sie nicht, VMware Tools auf der VM zu installieren und Ballooning nicht zu deaktivieren. </li><li>  Erw√§gen Sie, Inter-VM TPS zu aktivieren und gro√üe Seiten in VDI- und Testumgebungen zu deaktivieren. </li><li>  Wenn bei der VM Leistungsprobleme auftreten, √ºberpr√ºfen Sie, ob sie Speicher von einem Remote-NUMA-Knoten verwendet. </li><li>  Holen Sie sich VMs so schnell wie m√∂glich aus Swap!  Unter anderem leidet das Speichersystem, wenn sich die VM aus offensichtlichen Gr√ºnden in Swap befindet. </li></ul><br>  Das ist alles f√ºr RAM.  Im Folgenden finden Sie verwandte Artikel f√ºr diejenigen, die sich mit den Details befassen m√∂chten.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der n√§chste Artikel</a> wird der Geschichte gewidmet sein. <br><br><div class="spoiler">  <b class="spoiler_title">N√ºtzliche Links</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.yellow-bricks.com/2015/03/02/what-happens-at-which-vsphere-memory-state/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.yellow-bricks.com/2013/06/14/how-does-mem-minfreepct-work-with-vsphere-5-0-and-up/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.vladan.fr/vmware-transparent-page-sharing-tps-explained/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.yellow-bricks.com/2016/06/02/memory-pages-swapped-can-unswap/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://kb.vmware.com/s/article/1002586</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.vladan.fr/what-is-vmware-memory-ballooning/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://kb.vmware.com/s/article/2080735</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://kb.vmware.com/s/article/2017642</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://labs.vmware.com/vmtj/vmware-esx-memory-resource-management-swap</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://blogs.vmware.com/vsphere/2013/10/understanding-vsphere-active-memory.html</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.vmware.com/support/developer/converter-sdk/conv51_apireference/memory_counters.html</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://docs.vmware.com/de/VMware-vSphere/6.5/vsphere-esxi-vcenter-server-65-monitoring-performance-guide.pdf</a> <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de455820/">https://habr.com/ru/post/de455820/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455802/index.html">Wie man die Olympischen Spiele per E-Mail zusammenstellt. Fall Black Star</a></li>
<li><a href="../de455806/index.html">Geburt und Tod eines Albums: Wir verstehen, wie sich die Musikformate in den letzten 100 Jahren ver√§ndert haben</a></li>
<li><a href="../de455808/index.html">Holen Sie sich mit Python Ausz√ºge aus dem Register auf der FTS-Website</a></li>
<li><a href="../de455812/index.html">Aufbau einer Microservice-Architektur auf Golang und gRPC, Teil 2 (Docker)</a></li>
<li><a href="../de455816/index.html">So erstellen Sie coole Aktionen f√ºr Google Assistant. Lifehacks von Just AI</a></li>
<li><a href="../de455826/index.html">Ferngesteuerte automatische Bew√§sserung</a></li>
<li><a href="../de455828/index.html">Wissenschaftler haben neue exotische Formen der Synchronisation entdeckt</a></li>
<li><a href="../de455830/index.html">Ein Blick auf Go durch die Augen eines .NET-Entwicklers. Woche # 1</a></li>
<li><a href="../de455832/index.html">Verlauf einer einzelnen SQL-Untersuchung</a></li>
<li><a href="../de455834/index.html">Benchmarks f√ºr Linux-Server: 5 offene Tools</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
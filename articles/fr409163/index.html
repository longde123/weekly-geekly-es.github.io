<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>â¬›ï¸ ğŸ¤¾ğŸ¾ ğŸ‘¨ğŸ»â€ğŸ’¼ Pourquoi l'interdiction des robots tueurs autonomes ne rÃ©soudra rien ğŸ“¼ ğŸ‘©ğŸ¾â€ğŸ¤â€ğŸ‘¨ğŸ» â™‘ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Armes autonomes - robots tueurs qui peuvent attaquer sans intervention humaine - c'est un outil trÃ¨s dangereux. Cela ne fait aucun doute. Comme indiqu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pourquoi l'interdiction des robots tueurs autonomes ne rÃ©soudra rien</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/409163/"><img src="https://habrastorage.org/getpro/geektimes/post_images/092/080/d72/092080d723efe4713fc974aa6c426320.jpg"><br><br>  Armes autonomes - robots tueurs qui peuvent attaquer sans intervention humaine - c'est un outil trÃ¨s dangereux.  Cela ne fait aucun doute.  Comme indiquÃ© dans sa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lettre</a> ouverte Ã  l'ONU, Ilon Musk, qui a signÃ© sous lui, Mustava Suleiman [ <i>co-fondateur de la sociÃ©tÃ© d'IA <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepMind</a> / env.</i>  <i>perev.</i>  ] et d'autres auteurs, les armes autonomes peuvent devenir "des armes d'intimidation, des armes que les tyrans et les terroristes peuvent utiliser contre une population innocente, des armes qui peuvent Ãªtre piratÃ©es et utilisÃ©es de maniÃ¨re indÃ©sirable". <br><br>  Mais cela ne signifie pas que l'ONU devrait introduire une interdiction prÃ©ventive de poursuivre les recherches sur ces armes, comme le recommandent les auteurs de la lettre. <br><br>  PremiÃ¨rement, des outils parfois dangereux sont nÃ©cessaires pour atteindre des objectifs louables.  Souvenez-vous du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gÃ©nocide au Rwanda</a> lorsque le monde est restÃ© sans rien faire.  Si des armes autonomes existaient en 1994, peut-Ãªtre ne regarderions-nous pas de cÃ´tÃ©.  Il semble probable que si le coÃ»t des interventions humanitaires ne pouvait Ãªtre mesurÃ© qu'avec de l'argent, il serait plus facile d'obtenir le soutien du public pour de telles interventions. <br><a name="habracut"></a><br>  DeuxiÃ¨mement, il est naÃ¯f de croire que nous pouvons profiter des avantages des rÃ©centes percÃ©es dans l'IA sans avoir Ã  ressentir certaines de leurs lacunes.  Supposons que l'ONU introduit une interdiction prÃ©ventive de toute technologie d'armes autonomes.  Nous supposons Ã©galement - dÃ©jÃ  assez optimistes - que toutes les armÃ©es du monde respecteront cette interdiction et annuleront le dÃ©veloppement de programmes d'armes autonomes.  Et mÃªme alors, nous devons encore nous en prÃ©occuper.  Un robot peut facilement Ãªtre transformÃ© en systÃ¨me d'arme autonome: au lieu de contourner les piÃ©tons, vous pouvez lui apprendre Ã  les dÃ©placer. <br><br>  De maniÃ¨re gÃ©nÃ©rale, les technologies de l'IA sont extrÃªmement utiles et pÃ©nÃ¨trent dÃ©jÃ  nos vies, mÃªme si parfois nous ne le voyons pas et ne pouvons pas le rÃ©aliser pleinement.  Compte tenu de cette pÃ©nÃ©tration, il serait Ã  courte vue de penser que l'abus de technologie pourrait Ãªtre interdit simplement en interdisant le dÃ©veloppement d'armes autonomes.  Ce sont peut-Ãªtre prÃ©cisÃ©ment les systÃ¨mes d'armes autonomes sophistiquÃ©s et fonctionnant de maniÃ¨re sÃ©lective dÃ©veloppÃ©s par diverses armÃ©es du monde entier qui peuvent efficacement contrer les armes autonomes plus grossiÃ¨res qui sont faciles Ã  dÃ©velopper en reprogrammant la technologie de l'IA apparemment pacifique, comme les mÃªmes robots. <br><br>  De plus, l'idÃ©e d'une simple interdiction au niveau international donne une approche trop simplifiÃ©e de la prise en compte des armes autonomes.  Un tel concept ne reconnaÃ®t pas la longue histoire des causes et des effets des actions et accords des diffÃ©rents pays entre eux et seuls, qui, Ã  travers des milliers de petites actions et omissions, ont conduit au dÃ©veloppement de ces technologies.  Alors que le dÃ©bat sur les armes autonomes se dÃ©roule principalement au niveau des Nations Unies, le citoyen moyen, le soldat ou le programmeur peut Ãªtre pardonnÃ© de ne pas assumer dâ€™obligations morales pour les dommages causÃ©s par les armes autonomes.  Mais c'est une hypothÃ¨se trÃ¨s dangereuse, qui peut conduire Ã  un dÃ©sastre. <br><br>  Toutes les personnes qui sont en quelque sorte liÃ©es aux technologies d'armes automatiques devraient faire preuve de diligence raisonnable, et chacun de nous doit soigneusement rÃ©flÃ©chir Ã  la contribution que son action ou son inaction apporte Ã  la liste des dangers potentiels de cette technologie.  Cela ne signifie pas que les pays et les agences internationales n'ont pas leur rÃ´le important.  Cela est soulignÃ© par le fait que si nous voulons Ã©liminer le danger potentiel des armes automatiques, il est nÃ©cessaire de promouvoir l'Ã©thique de la responsabilitÃ© personnelle, et cette propagande doit atteindre les niveaux les plus bas auxquels les dÃ©cisions sont prises.  Pour commencer, il est extrÃªmement important de parler en dÃ©tail et complÃ¨tement du dÃ©veloppement des armes autonomes - y compris les consÃ©quences des actions de tous ceux qui prennent des dÃ©cisions Ã  tous les niveaux. <br><br>  Enfin, il est parfois avancÃ© qu'une arme autonome est dangereuse non pas parce que cet outil est dangereux en soi, mais parce qu'il peut devenir indÃ©pendant et commencer Ã  agir dans son propre intÃ©rÃªt.  Il s'agit d'une erreur erronÃ©e et, en outre, l'interdiction de dÃ©velopper des armes autonomes n'aidera pas Ã  prÃ©venir ce danger.  Si la superintelligence est une menace pour l'humanitÃ©, nous devons de toute urgence chercher des moyens de contrer efficacement cette menace, et ce, indÃ©pendamment du fait que la technologie des armes automatiques sera dÃ©veloppÃ©e davantage. <br><br><h2>  Lettre ouverte Ã  la Convention des Nations Unies sur certaines armes classiques </h2><br>  Alors que certaines entreprises crÃ©ent des technologies liÃ©es Ã  l'intelligence artificielle et Ã  la robotique qui peuvent Ãªtre redirigÃ©es vers le dÃ©veloppement d'armes autonomes, nous nous sentons particuliÃ¨rement responsables de sonner l'alarme.  Nous saluons chaleureusement la dÃ©cision de la confÃ©rence des Nations Unies sur l'adoption de la "Convention sur des types spÃ©cifiques d'armes classiques" concernant la nomination d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://www.unog.ch/80256EE600585943/(">groupe d'experts gouvernementaux</a> (Groupe d'experts gouvernementaux, GGE) sur les systÃ¨mes d'armes autonomes lÃ©tales.  Beaucoup de nos chercheurs et ingÃ©nieurs sont prÃªts Ã  fournir des conseils technologiques pour rÃ©soudre ce problÃ¨me. <br><br>  Nous nous fÃ©licitons de la nomination de l'Ambassadeur Amandip Singh Gill de l'Inde Ã  la prÃ©sidence du GGE.  Nous demandons aux Hautes Parties contractantes participant au GGE de travailler activement Ã  trouver des moyens de prÃ©venir ce type de course aux armements, de protÃ©ger les citoyens contre leur utilisation abusive et d'Ã©viter les effets dÃ©stabilisateurs de ces technologies.  Nous regrettons que la premiÃ¨re rÃ©union du GGE, prÃ©vue pour aoÃ»t 2017, ait Ã©tÃ© annulÃ©e en raison du fait que certains pays n'ont pas apportÃ© de contribution financiÃ¨re Ã  l'ONU.  Nous exhortons les Hautes Parties contractantes Ã  redoubler d'efforts lors de la premiÃ¨re rÃ©union du GGE qui se tiendra en novembre. <br><br>  Des armes autonomes dÃ©taillÃ©es menacent de provoquer une troisiÃ¨me rÃ©volution dans les affaires militaires.  AprÃ¨s son dÃ©veloppement, il permettra de conduire des conflits militaires Ã  une Ã©chelle sans prÃ©cÃ©dent plus tÃ´t, et dans des dÃ©lais plus courts que ce qu'une personne peut percevoir.  Il peut devenir une arme d'intimidation, une arme que les tyrans et les terroristes peuvent utiliser contre une population innocente, une arme qui peut Ãªtre piratÃ©e et utilisÃ©e pour fonctionner de maniÃ¨re indÃ©sirable.  Il nous reste peu de temps.  AprÃ¨s avoir ouvert cette boÃ®te de Pandore, il sera difficile de la fermer.  Par consÃ©quent, nous demandons aux Hautes Parties contractantes de trouver des moyens de nous protÃ©ger tous contre ces menaces. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr409163/">https://habr.com/ru/post/fr409163/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr409153/index.html">La Â«crÃ©ativitÃ©Â» de l'intelligence artificielle modifie notre comprÃ©hension du rÃ©el</a></li>
<li><a href="../fr409155/index.html">La Chine construit une autoroute avec des panneaux solaires et du bÃ©ton transparent</a></li>
<li><a href="../fr409157/index.html">Conscience humaine. Impossible de transfÃ©rer la copie?</a></li>
<li><a href="../fr409159/index.html">SIGSALY ou The Green Hornet: dÃ©fendre le lien Washington - Londres</a></li>
<li><a href="../fr409161/index.html">L'influence du cadre sur les caractÃ©ristiques de l'hÃ©licoptÃ¨re</a></li>
<li><a href="../fr409165/index.html">ThÃ©orie des jeux, bruit de souris et crevaison</a></li>
<li><a href="../fr409167/index.html">Il n'en Ã©tait pas ainsi! 5 idÃ©es fausses principales sur l'overclocking du Â«ferÂ»</a></li>
<li><a href="../fr409169/index.html">Comment lire le maquillage</a></li>
<li><a href="../fr409171/index.html">Comment assembler une mangeoire pour chat intelligente</a></li>
<li><a href="../fr409173/index.html">IA Ã  usage personnel: aide Ã  l'Ã©ducation, au travail et Ã  la planification</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
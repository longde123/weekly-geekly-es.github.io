<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå≤ üßòüèª üñäÔ∏è Eisen wird nicht versagen. Wie ich Dutzende von Servern pro Tag f√ºr den Kampf vorbereite ‚õπüèΩ ü•å üòì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das √úberpr√ºfen eines Servers ist kein Problem. Sie nehmen die Checkliste und √ºberpr√ºfen in der Reihenfolge: Prozessor, Speicher, Festplatten. Bei hund...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Eisen wird nicht versagen. Wie ich Dutzende von Servern pro Tag f√ºr den Kampf vorbereite</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/426733/"> Das √úberpr√ºfen eines Servers ist kein Problem.  Sie nehmen die Checkliste und √ºberpr√ºfen in der Reihenfolge: Prozessor, Speicher, Festplatten.  Bei hundert Servern ist es jedoch unwahrscheinlich, dass diese Methode gut funktioniert.  Um den menschlichen Faktor zu eliminieren, √úberpr√ºfungen zuverl√§ssiger und schneller zu machen, ist es notwendig, den Prozess zu automatisieren.  Wer muss wissen, wie man das besser macht als ein Hosting-Anbieter.  Artyom Artemyev unter HighLoad ++ Siberia erkl√§rte, welche Methoden verwendet werden k√∂nnen, was besser mit den H√§nden zu laufen ist und was gut zu automatisieren ist.  Als n√§chstes folgt eine Textversion des Berichts mit Tipps, die jeder wiederholen kann, der mit Eisen arbeitet und dessen Leistung regelm√§√üig √ºberpr√ºfen muss. <br><br><img src="https://habrastorage.org/webt/eg/iq/xc/egiqxczvizqa8elpiks7967fg3y.png"><br><br>  <strong>√úber den Sprecher:</strong> Artyom <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Artemyev</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Artemirk</a> ), technischer Direktor bei einem gro√üen Hosting-Anbieter FirstVDS, arbeitet mit Eisen. <br><a name="habracut"></a><br>  FirstVDS verf√ºgt √ºber zwei Rechenzentren.  Die erste ist ihre eigene, sie bauten ihr eigenes Geb√§ude, brachten und installierten ihre Racks, sie selbst warten, sorgen sich um den Strom und die K√ºhlung des Rechenzentrums.  Das zweite Rechenzentrum ist ein gro√üer Raum in einem gro√üen vermieteten Rechenzentrum, alles ist einfacher damit, aber es existiert auch.  Insgesamt sind es 60 Racks und ca. 3000 Eisenserver.  Es gab etwas zu trainieren und verschiedene Ans√§tze zu testen, was bedeutet, dass wir auf praktisch best√§tigte Empfehlungen warten.  Beginnen wir mit dem Anzeigen oder Lesen des Berichts. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/eQjNQ2RnjUY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Vor ungef√§hr 6-7 Jahren haben wir festgestellt, dass es nicht ausreicht, das Betriebssystem einfach auf den Server zu stellen.  Das Betriebssystem ist eingeschaltet, der Server ist wach und bereit f√ºr den Kampf.  Wir starten es in der Produktion - unverst√§ndliche Neustarts und Einfrierungen beginnen.  Was zu tun ist, ist nicht klar - der Prozess ist im Gange. Die √úbertragung des gesamten Arbeitsentwurfs auf ein neues Metallst√ºck ist hart, teuer und schmerzhaft.  Wo laufen? <br><br>  Moderne Bereitstellungsmethoden erm√∂glichen es uns, dies zu vermeiden und den Server in 5 Sekunden zu transportieren, aber unsere Kunden (insbesondere vor 6 Jahren) flogen einfach nicht in den Wolken, gingen auf dem Boden und verwendeten gew√∂hnliche Eisenst√ºcke. <br><br><img src="https://habrastorage.org/webt/li/kc/fa/likcfazjalyfvnjz_vq17bqqjpm.png"><br><br>  In diesem Artikel werde ich Ihnen sagen, welche Methoden wir ausprobiert haben, welche wir verwurzelt haben, welche nicht verwurzelt sind, welche gut mit Ihren H√§nden zu laufen sind und wie Sie all dies automatisieren k√∂nnen.  Ich werde Ihnen Ratschl√§ge geben, und Sie k√∂nnen ihn in Ihrer Firma wiederholen, wenn Sie mit Eisen arbeiten und ein solches Bed√ºrfnis haben. <br><br><h2>  Was ist das Problem? <br></h2><br>  Theoretisch ist die √úberpr√ºfung des Servers kein Problem.  Anfangs hatten wir einen Prozess wie im Bild unten.  Ein Mann setzt sich, nimmt eine Checkliste, pr√ºft: Prozessor, Speicher, Festplatten, runzelt die Stirn, trifft eine Entscheidung. <br><br><img src="https://habrastorage.org/webt/bq/75/ac/bq75acnj5b9-wk-mhonnk06vtbc.png"><br><br>  Dann wurden 3 Server pro Monat installiert.  Aber wenn es immer mehr Server gibt, f√§ngt diese Person an zu weinen und sich zu beschweren, dass sie bei der Arbeit stirbt.  Eine Person irrt sich zunehmend, weil die √úberpr√ºfung zur Routine geworden ist. <br><br>  <strong>Wir haben eine Entscheidung getroffen: Wir automatisieren!</strong>  Eine Person wird n√ºtzlichere Dinge tun. <br><br><h3>  Kurzer Ausflug <br></h3><br><img src="https://habrastorage.org/webt/yp/xx/ar/ypxxarfkx9huiayenmyjsiauh2g.png"><br><br>  Ich werde klarstellen, was ich meine, wenn ich heute √ºber den Server spreche.  Wir sparen wie alle anderen Rack-Platz und verwenden Server mit hoher Dichte.  Heute sind es 2 Einheiten, die entweder 12 Knoten von Einzelprozessorservern oder 4 Knoten von Doppelprozessorservern aufnehmen k√∂nnen.  Das hei√üt, jeder Server erh√§lt 4 Festplatten - alles ehrlich.  Au√üerdem befinden sich zwei Netzteile im Rack, dh alles ist redundant und jeder mag es. <br><br><h2>  Woher kommt das Eisen? <br></h2><br>  Eisen wird von unseren Lieferanten - normalerweise Supermicro und Intel - in unser Rechenzentrum gebracht.  Im Rechenzentrum installieren unsere Mitarbeiter Server in einem leeren Raum im Rack und verbinden zwei Kabel, ein Netzwerk und Strom.  Es liegt auch in der Verantwortung der Bediener, das BIOS auf dem Server zu konfigurieren.  Schlie√üen Sie also die Tastatur an, √ºberwachen Sie und konfigurieren Sie zwei Parameter: <code>Restore on AC/Power Loss ‚Äî [Power On]</code> Stromausfall <code>Restore on AC/Power Loss ‚Äî [Power On]</code> Einschalten <code>Restore on AC/Power Loss ‚Äî [Power On]</code> , sodass der Server immer eingeschaltet wird, sobald die Stromversorgung angezeigt wird.  Es sollte ohne Unterbrechung funktionieren.  Das zweite <code>First boot device ‚Äî [PXE]</code> , <code>First boot device ‚Äî [PXE]</code> wir stellen das erste Startger√§t in das Netzwerk, andernfalls k√∂nnen wir den Server nicht erreichen, da es keine Tatsache ist, dass es sofort √ºber Festplatten usw. verf√ºgt. <br><br><img src="https://habrastorage.org/webt/ab/hf/i2/abhfi2f6a412ead4dsnxyjjmhe8.png"><br><br>  Danach √∂ffnet der Bediener das Abrechnungsfeld f√ºr Eisenserver, in dem Sie die Tatsache der Installation des Servers aufzeichnen m√ºssen, f√ºr die Folgendes angegeben ist: <br><br><ul><li>  Gestell; </li><li>  Aufkleber </li><li>  Netzwerkanschl√ºsse </li><li>  Stromanschl√ºsse </li><li>  Einheitennummer. </li></ul><br>  Danach wird der Netzwerkport, an dem der Betreiber den neuen Server aus Sicherheitsgr√ºnden installiert hat, in ein spezielles Quarant√§ne-VLAN verschoben, in dem auch DHCP, Pxe, TFtp h√§ngen.  Als n√§chstes l√§dt der Server unser Lieblings-Linux, das √ºber alle erforderlichen Dienstprogramme verf√ºgt, und der Diagnoseprozess beginnt. <br><br>  Da der Server immer noch das erste Startger√§t im Netzwerk hat, wechselt der Port f√ºr Server, die in Produktion gehen, zu einem anderen VLAN.  In einem anderen VLAN befindet sich kein DHCP, und wir haben keine Angst, dass wir unseren Produktionsserver versehentlich neu installieren.  Daf√ºr haben wir ein separates VLAN. <br><br>  Es kommt vor, dass der Server installiert wurde, alles in Ordnung ist, aber das Diagnosesystem nicht gestartet wurde.  Dies geschieht in der Regel aufgrund der Tatsache, dass nicht alle Netzwerk-Switches mit einer Verz√∂gerung beim Wechseln von VLANs schnell VLANs usw. wechseln. <br><br><img src="https://habrastorage.org/webt/q0/qa/wl/q0qawlis6oq5tykqjri3hif8bwg.png"><br><br>  Dann erh√§lt der Bediener die Aufgabe, den Server mit seinen H√§nden neu zu starten.  Bisher gab es kein IPMI, wir haben Remote-Sockets eingerichtet und festgelegt, an welchem ‚Äã‚ÄãPort die Server-Sockets vorhanden sind, den Socket √ºber das Netzwerk gezogen und den Server neu gestartet. <br><br>  Verwaltete Steckdosen funktionieren jedoch auch nicht immer gut. Daher verwalten wir jetzt die Serverleistung √ºber IPMI.  Wenn der Server neu ist und IPMI nicht konfiguriert ist, kann er nur durch Hochfahren und Dr√ºcken der Taste neu gestartet werden.  Deshalb sitzt ein Mann, wartet - das Licht geht an - rennt und dr√ºckt den Knopf.  So ist sein Job. <br><br>  Wenn der Server danach nicht mehr gestartet wurde, wird er zur Reparatur in eine spezielle Liste eingetragen.  Diese Liste enth√§lt Server, auf denen die Diagnose nicht gestartet wurde oder deren Ergebnisse nicht zufriedenstellend waren.  Eine einzelne Person - die Eisen liebt - sitzt und zerlegt jeden Tag - sammelt, schaut, warum funktioniert das nicht. <br><br><h2>  CPU <br></h2><br>  Alles ist in Ordnung, der Server hat gestartet, wir fangen an zu testen.  Zuerst testen wir den Prozessor als eines der wichtigsten Elemente. <br><br><img src="https://habrastorage.org/webt/8k/6m/n0/8k6mn0cwmprfgrqoanohbc1lyyo.png"><br><br>  Der erste Impuls war, die Anwendung des Anbieters zu verwenden.  Wir haben fast alle Intel-Prozessoren - wir sind auf die Website gegangen und haben das Intel Processor Diagnostic Tool heruntergeladen - alles ist in Ordnung, es enth√§lt viele interessante Informationen, einschlie√ülich der Betriebsstunden des Servers in Stunden und der grafischen Darstellung des Stromverbrauchs. <br><br>  Das Problem ist jedoch, dass Intel PTD unter Windows funktioniert, was uns nicht mehr gefallen hat.  Um einen Test darin zu starten, m√ºssen Sie nur die Maus bewegen, die "START" -Taste dr√ºcken und der Test beginnt.  Das Ergebnis wird auf dem Bildschirm angezeigt, es kann jedoch nirgendwo exportiert werden.  Dies passt nicht zu uns, da der Prozess nicht automatisiert ist. <br><br><img src="https://habrastorage.org/webt/ax/zo/t1/axzot1gbcsfefqbkta32bixrxk4.png"><br><br>  Wir haben die Foren gelesen und die zwei einfachsten Wege gefunden. <br><br><ol><li>  <strong>Die ewige Schleife cat / dev / zero&gt; / dev / null</strong> .  Sie k√∂nnen oben einchecken - 100% ein Kern wird verbraucht.  Wir z√§hlen die Anzahl der Kerne, f√ºhren die erforderliche Anzahl von cat / dev / zero aus, multipliziert mit der gew√ºnschten Anzahl von Kernen.  Alles funktioniert super! <br></li><li>  <strong>Dienstprogramm / Beh√§lter / Stress</strong> .  Sie baut Matrizen im Ged√§chtnis auf und beginnt sie st√§ndig umzudrehen.  Alles ist auch in Ordnung - der Prozessor erw√§rmt sich, es gibt eine Last. <br></li></ol><br>  Wir geben die Server in Produktion, Benutzer kommen zur√ºck und sagen, dass der Prozessor instabil ist.  Aktiviert - der Prozessor ist instabil.  Sie begannen zu untersuchen, sie nahmen den Server, der die Pr√ºfungen besteht, aber er st√ºrzt im Kampf ab, schalteten den Debug-Kernel unter Linux ein und sammelten den Core-Dump.  Der Server l√∂scht vor dem Neustart alles, was sich vor dem Absturz im Speicher befand, in die Datei. <br><br><img src="https://habrastorage.org/webt/i1/iu/z0/i1iuz0zoafq9lm8aaimgyqzyiic.png"><br><br>  In Prozessoren sind verschiedene Optimierungen f√ºr h√§ufige Operationen integriert.  Wir k√∂nnen Flags sehen, die angeben, welche Optimierungen der Prozessor unterst√ºtzt, z. B. Optimierungen f√ºr die Arbeit mit Gleitkommazahlen, Multimedia-Optimierungen usw.  Aber unser / bin / stress und der ewige Zyklus brennen den Prozessor nur in einem Arbeitsgang und verwenden keine zus√§tzlichen Funktionen.  Die Untersuchung ergab, dass die CPU abst√ºrzt, wenn versucht wird, die Funktionalit√§t eines der integrierten Flags zu nutzen. <br><br>  Der erste Impuls war, / bin / stress zu verlassen - den Prozessor erw√§rmen zu lassen.  Dann laufen wir in einem Zyklus durch alle Flaggen und ziehen sie.  W√§hrend wir dar√ºber nachdenken, wie dies implementiert werden soll, welche Befehle aufgerufen werden m√ºssen, um die Funktionen der einzelnen Flags aufzurufen, lesen wir die Foren. <br><br>  Im Overclocker-Forum stie√üen wir auf ein interessantes Projekt zur Suche nach Primzahlen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Great Internet Mersenne Prime Search</a> .  Wissenschaftler haben ein verteiltes Netzwerk aufgebaut, mit dem sich jeder verbinden und eine Primzahl finden kann.  Wissenschaftler glauben niemandem, deshalb funktioniert das Programm sehr geschickt: Zuerst f√ºhren Sie es aus, es berechnet die Primzahlen, die es bereits kennt, und vergleicht das Ergebnis mit dem, was es wei√ü.  Wenn das Ergebnis nicht √ºbereinstimmt, funktioniert der Prozessor nicht richtig.  Diese Eigenschaft hat uns sehr gut gefallen: Bei jedem Unsinn ist es anf√§llig zu fallen. <br><br>  Dar√ºber hinaus ist es das Ziel des Projekts, so viele Primzahlen wie m√∂glich zu finden. Daher wird das Programm st√§ndig f√ºr die Eigenschaften neuer Prozessoren optimiert, wodurch viele Flags gezogen werden. <br><br>  Mprime hat keine zeitliche Begrenzung. Wenn es nicht gestoppt wird, funktioniert es f√ºr immer.  Wir lassen es 30 Minuten lang laufen. <br><br><pre> <code class="hljs powershell">/usr/bin/timeout <span class="hljs-number"><span class="hljs-number">30</span></span>m /opt/mprime <span class="hljs-literal"><span class="hljs-literal">-t</span></span> /bin/grep <span class="hljs-literal"><span class="hljs-literal">-i</span></span> error /root/result.txt</code> </pre><br>  Nach Abschluss der Arbeit √ºberpr√ºfen wir, ob die Datei result.txt keine Fehler enth√§lt, und √ºberpr√ºfen die Kernelprotokolle, insbesondere die Datei / proc / kmsg, in der wir nach Fehlern suchen. <br><br><h3>  Noch ein Ausflug <br></h3><br><img src="https://habrastorage.org/webt/es/ic/kj/esickjc00tooyxznjt_6lyumimg.png"><br><br>  Am 3. Januar 2018 fanden sie die 50. Mersenne-Primzahl (2 <sup>p</sup> -1).  Von dieser Zahl nur 23 Millionen Ziffern.  Sie k√∂nnen es herunterladen, um es anzuzeigen - <a href="">dies</a> ist <a href="">ein 12-MB-Zip-Archiv</a> . <br><br>  Warum brauchen wir Primzahlen?  Erstens verwendet jede RSA-Verschl√ºsselung Primzahlen.  Je mehr Primzahlen wir kennen, desto zuverl√§ssiger ist Ihr SSH-Schl√ºssel.  Zweitens testen Wissenschaftler ihre Hypothesen und mathematischen Theoreme, und es macht uns nichts aus, Wissenschaftlern zu helfen - es kostet uns nichts.  Es stellt sich heraus, Win-Win-Geschichte. <br><br><img src="https://habrastorage.org/webt/v0/nd/cl/v0ndcljwlkwops-dtp9nwk9bsru.png"><br><br>  Der Prozessor funktioniert also, alles ist in Ordnung.  Es bleibt abzuwarten, um welche Art von Prozessor es sich handelt.  Wir verwenden den Prozessor dmidecode -t und sehen alle Steckpl√§tze auf dem Motherboard und welche Prozessoren sich in diesen Steckpl√§tzen befinden.  Diese Informationen werden in unser Buchhaltungssystem eingegeben und sp√§ter interpretiert. <br><br><h3>  Fang <br></h3><br>  So k√∂nnen √ºberraschenderweise gebrochene Beine gefunden werden.  / bin / stress und der ewige Zyklus funktionierten und Mprime fiel.  Sie fuhren lange, suchten, entdeckten - das Ergebnis im Bild unten - hier ist alles klar. <br><br><img src="https://habrastorage.org/webt/13/ae/gc/13aegcfaw9ozlrzzzgog3povm5w.jpeg"><br><br>  Ein solcher Prozessor hat einfach nicht gestartet.  Der Bediener war sehr stark, nahm den falschen Prozessor - konnte aber liefern. <br><br><img src="https://habrastorage.org/webt/gj/xr/_w/gjxr_wu8lxf_cgsf4ehxs84-yb8.jpeg"><br><br>  Ein weiterer sch√∂ner Fall.  Die schwarze Reihe auf dem Foto unten zeigt die L√ºfter. Der Pfeil zeigt, wie die Luft weht.  Wir sehen: Der K√ºhler steht √ºber dem Strom.  Nat√ºrlich ist alles √ºberhitzt und ausgeschaltet. <br><br><img src="https://habrastorage.org/webt/oh/-c/hp/oh-chp3arnnkslirn8elylfcfww.jpeg"><br><br><h2>  Die Erinnerung <br></h2><br>  Mit dem Ged√§chtnis ist alles ziemlich einfach.  Dies sind Zellen, in die wir Informationen schreiben und nach einer Weile wieder lesen.  Wenn es dasselbe bleibt, das wir aufgeschrieben haben, funktioniert diese Zelle. <br><br><img src="https://habrastorage.org/webt/91/gl/_s/91gl_slwgtws8webfnnjxfajui8.png"><br><br>  Jeder kennt das gute, direkt klassische <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Memtest86 +</a> -Programm, das von jedem Medium, √ºber das Netzwerk oder sogar von einer Diskette ausgef√ºhrt wird.  Es wird gemacht, um so viele Speicherzellen wie m√∂glich zu √ºberpr√ºfen.  Besetzte Zellen k√∂nnen nicht mehr √ºberpr√ºft werden.  Daher hat memtest86 + eine Mindestgr√∂√üe, um keinen Speicher zu belegen.  Leider zeigt <strong>memtest86 + seine Statistiken nur auf dem Bildschirm an</strong> .  Wir haben versucht, es irgendwie zu erweitern, aber es kam alles darauf an, dass es im Programm nicht einmal einen Netzwerkstapel gab.  Um es zu erweitern, m√ºsste man den Linux-Kernel und alles andere mitbringen. <br><br>  Es gibt eine kostenpflichtige Version dieses Programms, die bereits wei√ü, wie Informationen auf die Festplatte gelegt werden.  Unsere Server verf√ºgen jedoch nicht immer √ºber eine Festplatte, und auf diesen Festplatten befindet sich nicht immer ein Dateisystem.  Wie wir bereits herausgefunden haben, kann das Netzwerklaufwerk jedoch nicht verbunden werden. <br><br>  Wir begannen weiter zu graben und fanden ein √§hnliches <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Memtester-</a> Programm.  Dieses Programm funktioniert auf Betriebssystemebene unter Linux.  Das gr√∂√üte Minus ist, dass das Betriebssystem selbst und Memtester einige Speicherzellen belegen und diese Zellen nicht √ºberpr√ºft werden. <br><br>  Memtester wird mit dem folgenden Befehl gestartet: memtester `cat / proc / meminfo | grep MemFree |  awk '{print $ 2-1024}' 'k 5 <br><br>  Hier √ºbertragen wir die Menge an freiem Speicher minus 1 MB.  Dies geschieht, weil der Memtester sonst den gesamten Speicher belegt und der Down-Killer ihn t√∂tet.  Wir fahren diesen Test f√ºr 5 Zyklen, am Ausgang haben wir eine Platte mit entweder OK oder Fail. <br><br><table width="300"><tbody><tr><td>  Festgefahrene Adresse </td><td>  ok </td></tr><tr><td>  Zuf√§lliger Wert </td><td>  ok </td></tr><tr><td>  Vergleiche XOR </td><td>  ok </td></tr><tr><td>  Vergleiche SUB </td><td>  ok </td></tr><tr><td>  Vergleiche MUL </td><td>  ok </td></tr><tr><td>  Vergleiche DIV </td><td>  ok </td></tr><tr><td>  Vergleiche OR </td><td>  ok </td></tr><tr><td>  Vergleiche AND </td><td>  ok </td></tr></tbody></table><br><br>  Wir speichern das Endergebnis und analysieren es weiter auf Fehler. <br><br><img src="https://habrastorage.org/webt/ah/55/kt/ah55kt9fxuqwkmqsz8-dozgunic.png"><br><br>  Um das Ausma√ü des Problems zu verstehen: Unser kleinster Server verf√ºgt √ºber 32 GB Arbeitsspeicher, unser Linux-Image mit Memtester nimmt 60 MB ein, <strong>wir √ºberpr√ºfen nicht 2% des Arbeitsspeichers</strong> .  Laut Statistiken der letzten 6 Jahre gab es jedoch nicht so etwas, dass offen geschlagene Erinnerungen in Produktion gingen.  Dies ist der Kompromiss, dem wir zustimmen und dessen Behebung teuer ist und mit dem wir leben. <br><br>  Unterwegs sammeln wir auch dmidecode -t Speicher, der alle Speicherb√§nke enth√§lt, die wir auf dem Motherboard haben (normalerweise bis zu 24 Teile), und die sich in jeder Bank befinden.  Diese Informationen sind n√ºtzlich, wenn wir den Server aktualisieren m√∂chten. Wir wissen, wo was hinzugef√ºgt werden muss, wie viele Streifen ben√∂tigt werden und zu welchem ‚Äã‚ÄãServer. <br><br><h2>  Speicherger√§te <br></h2><br>  Vor 6 Jahren waren alle Scheiben mit Pfannkuchen, die sich drehten.  Eine separate Geschichte bestand darin, nur eine Liste aller Festplatten zusammenzustellen.  Es gab verschiedene Ans√§tze, da nicht angenommen wurde, dass man sich nur ls / dev / sd ansehen k√∂nnte.  Aber am Ende haben wir aufgeh√∂rt, uns ls / dev / sd * und ls / dev / cciss / c0d * anzusehen.  Im ersten Fall handelt es sich um ein SATA-Ger√§t, im zweiten um SCSI und SAS. <br><br><img src="https://habrastorage.org/webt/e7/gm/br/e7gmbraujo_ko4qmfanfwnru71y.png"><br><br>  Buchst√§blich in diesem Jahr haben sie angefangen, NVME-Festplatten zu verkaufen und hier eine NVME-Liste hinzugef√ºgt. <br><br>  Nachdem die Liste der Festplatten kompiliert wurde, versuchen wir, 0 Bytes daraus zu lesen, um zu verstehen, dass dies ein Blockger√§t ist und alles in Ordnung ist.  Wenn Sie es nicht lesen konnten, glauben wir, dass dies eine Art Geist ist, und wir haben und hatten noch nie eine solche Festplatte. <br><br>  Der erste Ansatz zum √úberpr√ºfen von Datentr√§gern war der offensichtliche: ‚ÄûSchreiben wir zuf√§llige Daten auf den Datentr√§ger und sehen die Geschwindigkeit‚Äú - <code>dd -o nocache -o direct if=/dev/urandom of=${disk}</code> .  Pfannkuchenscheiben geben in der Regel 130-150 Mb / s ab.  Wir kniff die Augen zusammen und entschieden f√ºr uns, dass 90 MB / s die Zahl sind, nach der es wartungsf√§hige Festplatten gibt, alle kleineren sind fehlerhaft. <br><br>  Aber wieder kehrten Benutzer zur√ºck und sagten, dass die Laufwerke schlecht sind.  Es stellte sich heraus, dass die heimt√ºckische Physik wieder mit uns scherzte. <br><br><img src="https://habrastorage.org/webt/m_/uh/tf/m_uhtfarwgyskpslnxxkufxynty.png"><br><br>  Es gibt eine Winkelgeschwindigkeit, und wenn Sie -dd ausf√ºhren, wird in der Regel in der N√§he der Spindel geschrieben.  Wenn sich die Spindeldrehzahl aus irgendeinem Grund verschlechtert hat, ist dies weniger auff√§llig als wenn Sie vom Rand der Disc aus schreiben. <br><br>  Ich musste das Prinzip der √úberpr√ºfung √§ndern.  Jetzt checken wir an drei Stellen ein: in der N√§he der Spindel, in der Mitte und drau√üen.  Wahrscheinlich kann es nur von au√üen √ºberpr√ºft werden, aber so ist es historisch geschehen.  Und was funktioniert, nicht anfassen. <br><br>  Sie k√∂nnen <strong>smartctl verwenden</strong> , um die Festplatte zu fragen, wie es funktioniert.  Wir glauben, dass eine gute Fahrt: <br><br><ul><li>  Es gibt keine neu zugewiesenen Sektoren ( <strong>Anzahl der neu zugewiesenen Sektoren = 0)</strong> , <strong>dh</strong> alle Sektoren, die die Fabrik verlassen haben. </li><li>  Wir <strong>verwenden keine Discs, die √§lter als 4 Jahre sind</strong> , obwohl sie ziemlich gut funktionieren.  Bevor wir diese Praxis einf√ºhrten, hatten wir 7 Jahre lang Scheiben.  Jetzt glauben wir, dass sich die Festplatte nach 4 Jahren ausgezahlt hat und wir nicht bereit sind, das Verschlei√ürisiko zu akzeptieren. </li><li>  Es gibt keine Sektoren, die neu <strong>zugewiesen werden</strong> sollen ( <strong>Current_Pending_Sector = 0</strong> ). </li><li>  <strong>UltraDMA CRC Error Count = 0</strong> - Dies sind Fehler am SATA-Kabel.  Wenn ein Fehler auftritt, m√ºssen Sie nur das Kabel wechseln, Sie m√ºssen die Festplatte nicht wechseln. </li></ul><br><img src="https://habrastorage.org/webt/01/jy/48/01jy48l5jyw-x1yx7wse-yawhdq.png"><br><br>  Verteilte SSDs sind im Allgemeinen ausgezeichnete Laufwerke, sie arbeiten schnell, machen keine Ger√§usche und heizen sich nicht auf.  Wir glauben, dass eine gute SSD eine Schreibgeschwindigkeit von mehr als 200 MB / s hat.  Unsere Kunden lieben niedrige Preise, und Servermodelle mit 320-350 MB / s erreichen uns nicht immer. <br><br>  F√ºr SSDs sehen wir auch smartctl aus.  Dieselbe Neuzuweisung, Power_On_Hours, Current_Pending_Sector.  Alle SSDs k√∂nnen den Verschlei√ügrad anzeigen, es wird der Parameter Media_Wearout_Indicator angezeigt.  Wir wischen die Discs bis zu 5% der Lebensdauer ab und nehmen sie erst dann heraus.  Solche Discs finden manchmal ein zweites Leben in den pers√∂nlichen Bed√ºrfnissen der Mitarbeiter.  Zum Beispiel habe ich k√ºrzlich herausgefunden, dass eine solche Festplatte in 2 Jahren im Laptop eines Mitarbeiters um weitere 1% abgenutzt ist, obwohl sie in unserem Land unter dem SSD-Cache in etwa 10 Monaten um 95% ersch√∂pft ist. <br><br>  Das Problem ist jedoch, dass sich nicht alle Festplattenhersteller auf die Parameternamen geeinigt haben und dieser Media_Wearout_Indicator beispielsweise als Percent_Lifetime_Used f√ºr Toshiba, andere Wear Leveling Count, Percent Lifetime Remaining f√ºr andere Hersteller oder nur. * Wear. * Bezeichnet wird. <br><br>  Crucial hat diese Option √ºberhaupt nicht.  Dann betrachten wir nur den Umfang des Umschreibens der Disc - "Byte geschrieben" - wie viele Bytes wir bereits auf diese Disc geschrieben haben.  Ferner versuchen wir gem√§√ü der Spezifikation herauszufinden, wie viele Umschreibungen diese Platte vom Hersteller berechnet wird.  Durch elementare Mathematik bestimmen wir, wie viel mehr er leben wird.  Wenn es Zeit ist, sich zu √§ndern - √§ndern Sie sich. <br><br><h2>  RAID <br></h2><br>  Ich wei√ü nicht, warum unsere Kunden in der modernen Welt immer noch RAIDs wollen.  Die Leute kaufen RAID und legen dort 4 SSDs ab, die viel schneller sind als dieses RAID (6 GB).  Sie haben irgendeine Art von Anweisung und sammeln sie.  Ich denke, das ist eine fast unn√∂tige Sache. <br><br>  Fr√ºher gab es 3 Hersteller: Adaptec;  3ware;  Intel  Wir hatten 3 Dienstprogramme, wir haben uns die M√ºhe gemacht, aber wir haben Diagnosen f√ºr alle durchgef√ºhrt.  Jetzt hat LSI alle gekauft - es gibt nur noch ein Dienstprogramm. <br><br>  Wenn unser Diagnosesystem RAID erkennt, analysiert es das logische Volume in separate Datentr√§ger, sodass Sie die Geschwindigkeit jedes Datentr√§gers messen und dessen Smart lesen k√∂nnen.  Danach muss das RAID den Akku √ºberpr√ºfen.  Wer wei√ü nicht - es gibt genug Batterien im RAID, um alle Festplatten f√ºr weitere 2 Stunden zu drehen.  Das hei√üt, Sie schalten den Server aus, nehmen ihn heraus und drehen die Festplatte f√ºr weitere 2 Stunden, um alle Aufzeichnungen abzuschlie√üen. <br><br><h2>  Netzwerk <br></h2><br>  Mit dem Netzwerk ist alles ganz einfach - im Rechenzentrum sollten weniger als 300 Mbit vorhanden sein.  Wenn weniger, m√ºssen Sie es beheben.  Wir betrachten auch Fehler auf der Schnittstelle.  <strong>Fehler auf der Netzwerkschnittstelle sollten √ºberhaupt nicht auftreten</strong> , und wenn <strong>dies der Fall</strong> ist, ist alles schlecht. <br><br><img src="https://habrastorage.org/webt/ad/m2/yw/adm2yw4vmjpztcicdovupo84l20.png"><br><br>  Wir versuchen dabei, die BIOS- und IPMI-Firmware zu aktualisieren.  Es stellte sich heraus, dass wir nicht alle BIOS m√∂gen.  Wir haben immer noch BIOSes, die nicht wissen, wie man UEFI und andere von uns verwendete Funktionen verwendet.  Wir versuchen es automatisch zu aktualisieren, aber das funktioniert nicht immer, da ist dort nicht alles sehr einfach.  Wenn es nicht funktioniert, geht die Person und aktualisiert mit ihren H√§nden. <br><br>  Wir geben IPMI Supermicro nicht an die Welt weiter, wir haben es auf grauen Adressen √ºber OpenVPN.  Trotzdem bef√ºrchten wir, dass eines Tages eine weitere Verwundbarkeit herauskommt und wir leiden werden.  Daher versuchen wir, die IPMI-Firmware immer auf dem neuesten Stand zu halten.  Wenn dies nicht der Fall ist, aktualisieren Sie. <br><br>  Aus einer seltsamen Sache wurde k√ºrzlich bekannt, dass Intel auf 10- und 40-Gigabit-Netzwerkkarten keinen PXE-Start enth√§lt.  Es stellt sich heraus, dass es unm√∂glich ist, √ºber das Netzwerk zu booten, wenn sich der Server in einem Rack befindet, in dem sich nur eine 40-Gigabit-Karte befindet, da Sie eine Gigabit-Karte booten m√ºssen.  Wir flashen Netzwerkkarten separat auf 40G, damit sie PXE haben und weiterleben k√∂nnen. <br><br>  <strong>Nachdem alles √ºberpr√ºft wurde, wird der Server sofort zum Verkauf angeboten</strong> .  Der Preis wird berechnet, zu dem er auf die Website gestellt und verkauft wird. <br><br><img src="https://habrastorage.org/webt/by/ca/ah/bycaah2szao5f0-lcrkk5zcwzyo.png"><br><br>  Insgesamt f√ºhren wir ungef√§hr 350 √úberpr√ºfungen pro Monat durch, 69% der Server sind wartungsf√§hig, 31% sind nicht wartungsf√§hig.  Dies liegt an der Tatsache, dass wir eine reiche Geschichte haben, einige Server stehen seit 10 Jahren.  Die meisten Server, die den Test nicht bestanden haben, werfen wir einfach. <br><br><blockquote>  F√ºr Neugierige: Wir haben 3 Kunden, die noch auf dem Pentium IV leben und nirgendwo abreisen wollen.  Sie haben 512 MB RAM. <br></blockquote><br>  Die Zukunft ist gekommen!  Wenn ich dieses System heute umz√§unen w√ºrde ... <br><br><img src="https://habrastorage.org/webt/4v/bb/e_/4vbbe_vodbx8hzm_zk-nf2oejf4.png"><br><br>  Ein wunderbares Dienstprogramm, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hardware Lister</a> (lshw), wurde ver√∂ffentlicht, das mit dem Kernel kommunizieren kann und auf wunderbare Weise anzeigt, welche Art von Hardware sich im Kernel befindet und was der Kernel erkennen kann.  Nicht alle diese T√§nze werden ben√∂tigt.  Wenn Sie wiederholen - Ich rate Ihnen dringend, sich dieses Dienstprogramm anzusehen und es zu verwenden.  Alles wird viel einfacher. <br><br><h1>  Zusammenfassung: <br></h1><br><ul><li>  Kompromisse sind nicht schlecht, es ist nur eine Frage des Preises.  Wenn die L√∂sung sehr teuer ist, m√ºssen Sie nach einem Niveau suchen, bei dem sowohl Zuverl√§ssigkeit als auch Preis akzeptabel sind. </li><li>  Nicht-Kernprogramme sind manchmal cool zum Testen.  Es bleibt nur, sie zu finden. </li><li>  Testen Sie alles, was Sie erreichen! </li></ul><br><blockquote>  Das n√§chste gro√üe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad ++ findet</a> bereits am 8. und 9. November in Moskau statt.  Das Programm umfasst ber√ºhmte Spezialisten und neue Namen, traditionelle und neue Aufgaben.  Im DevOps-Bereich werden beispielsweise bereits folgende akzeptiert: <br><br><ul><li>  David O'Brien (Xirus), der √ºber das Ewige diskutieren wird - ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Metrics!</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Metriken!</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Metriken!</a>  "" <br></li><li>  Vladimir Kolobaev (Avito) mit einem Bericht-Appell ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Monitoring - an Entwickler!</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Technologie f√ºr die Community!</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Profit - an alle!</a>  "" <br></li><li>  Elena Grahovac (N26) wird ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Best Practices f√ºr native Cloud-Dienste</a> ‚Äú vorstellen. <br></li></ul><br>  Studieren Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Liste der</a> Berichte und beeilen Sie sich, um beizutreten.  Oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">abonnieren Sie</a> unseren Newsletter und Sie erhalten regelm√§√üig Bewertungen von Berichten, Berichten √ºber neue Artikel und Videos. <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de426733/">https://habr.com/ru/post/de426733/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de426723/index.html">Microsoft und Partner hoffen, eine Zeitkapsel auf dem Mond zu schaffen</a></li>
<li><a href="../de426725/index.html">Wie man Dinge macht, wenn man keine Lust dazu hat</a></li>
<li><a href="../de426727/index.html">EME? Cdm? DRM? CENC? IDK! Was Sie brauchen, um Ihren eigenen Video-Player in einem Browser zu erstellen</a></li>
<li><a href="../de426729/index.html">TypeScript School of Magic: Generika und Typerweiterung</a></li>
<li><a href="../de426731/index.html">CSS: interessante Merkmale des Randradius</a></li>
<li><a href="../de426735/index.html">Willkommen beim JETHACK Hackathon</a></li>
<li><a href="../de426737/index.html">Kurz √ºber die Architektur neuromorpher Prozessoren: ein Einblick</a></li>
<li><a href="../de426739/index.html">Proxy-Dateien von AWS S3 mit nginx</a></li>
<li><a href="../de426741/index.html">Ein Memo f√ºr diejenigen, die zum ersten Mal Praktikanten einstellen m√∂chten</a></li>
<li><a href="../de426743/index.html">Die M√∂glichkeiten, die Blockchain zu verwenden, haben sich woanders gewendet. Sony k√ºndigt ein Blockchain-basiertes DRM-System an</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔄 💿 🎏 Bot sur les réseaux de neurones: comment fonctionne et apprend un assistant virtuel 👨🏿‍🤝‍👨🏽 🙅🏻 👎🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En 2016, au plus fort de la popularité des chatbots, notre équipe a créé des assistants boutons pour les entreprises. Jusqu'à ce qu'une pensée intéres...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bot sur les réseaux de neurones: comment fonctionne et apprend un assistant virtuel</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/478572/"> En 2016, au plus fort de la popularité des chatbots, notre équipe a créé des assistants boutons pour les entreprises.  Jusqu'à ce qu'une pensée intéressante surgisse: «Et si nous automatisons le support client avec les réseaux de neurones?»  Nous voulions que les robots de discussion apprennent enfin à comprendre le langage naturel et deviennent confortables. <br><br>  Il a fallu quatre mathématiciens, six mois de travail acharné, un nouveau langage de programmation et de nombreuses erreurs - et nous avons créé un constructeur dans lequel tout le monde peut assembler un assistant virtuel avec l'IA. <br><br><h4>  Dans le matériel nous dirons </h4><br><ul><li>  En quoi un assistant virtuel diffère-t-il d'un robot de chat classique </li><li>  Est-il vrai que les assistants virtuels comprennent la langue </li><li>  Comment nous avons appris au robot à comprendre le contexte et à écrire la langue lialang </li><li>  Test de cas: comment nous avons automatisé le support dans trois banques </li><li>  Création de <a href="https://lia.chat/">Lia Platform</a> et moteur d'interfaces </li><li>  Trois étapes: comment fonctionne la plate-forme d'assemblage d'assistants virtuels (où n'importe qui, même un non programmeur, peut assembler un robot) </li></ul><br><a name="habracut"></a><br><h3>  Chat bot vs assistant virtuel </h3><br>  Les chatbots avancés ont pu mettre en évidence des mots clés et imiter le dialogue humain dans les années 60.  Les hippies se sont jetés sur le LSD, les Beatles ont rassemblé les stades et Joseph Weizenbaum a créé Eliza, une interlocutrice-psychothérapeute qui donnera des cotes à de nombreux bots modernes, et même à des psychologues. <br>  Par exemple, dans la phrase «Mon père me déteste», Eliza a répondu au mot-clé «père» et a demandé: «Qui d'autre dans la famille vous déteste?»  Mais le robot-psychothérapeute n'a pas compris l'essence des problèmes.  Les chatbots modernes fonctionnent également: mots-clés, scripts linéaires et parodie de dialogue en direct. <br><br>  Mais quelque chose a changé depuis les années 60: maintenant, grâce au machine learning et aux technologies NLP, nous pouvons apprendre aux robots de chat à comprendre le langage naturel et le contexte.  C'est toujours une imitation, mais plus significative. <br><br>  Pour voir la différence, comparons le chatbot et l'assistant - imaginez que nous devons faire un <b>sommelier virtuel</b> qui aide les clients dans le choix du vin. <br><br><h4>  Étape 1 </h4><br>  La première étape du chatbot et de l'assistant virtuel en est une: nous déterminons les demandes des utilisateurs et proposons des phrases qu'ils peuvent écrire.  Et puis nous prescrivons comment le robot va réagir. <br><br>  La demande de base est claire - ramasser le vin.  Mais cette demande peut avoir de nombreux paramètres: motif, prix, pays, couleur, cépage.  Peut-être que l'utilisateur écrit immédiatement le nom du vin à trouver.  Ou il clarifiera les détails: "Où est-il fabriqué?"  Ou peut-être par curiosité, il va commencer à lancer le robot avec des questions: "Quelle bouteille est la plus chère au monde?" Et ainsi de suite.  De plus, en plus des demandes dans le cas, il y a "bonjour", "bye", "comment allez-vous" et d'autres petites phrases qui doivent être demandées. <br><br>  Vous pouvez fantasmer à l'infini, mais nous ne pourrons toujours pas prédire toutes les questions des utilisateurs.  Quand il nous semble que les situations décrites seront suffisantes pour couvrir 98% des demandes, nous nous arrêtons (bien que la dure réalité se dissipe et nous découvrons que 80% seront couverts au mieux). <br><br>  Ensuite, nous dispersons nos hypothèses sur les besoins des utilisateurs pour des demandes spécifiques - intentions.  Les intentions indiquent ce que l'utilisateur veut, mais jetez les informations sur la façon dont il a écrit à ce sujet.  Cette étape est la même pour les chatbots et les assistants. <br><br><h4>  Liste d'intentions </h4><br>  <b>Intention 1 - Je veux du vin</b> <br>  Phrases: <br><br>  - Aidez-moi à choisir un vin <br>  - Quel vin recommanderiez-vous? <br>  - Je veux le meilleur vin <br>  - ... <br>  <b>Que faire avec lui:</b> sélectionnez au hasard l'un des vins les plus populaires et informez l'utilisateur. <br><br>  <b>Intention 2 - vin moins cher</b> <br><br>  Phrases: <br><br>  - existe-t-il de bons vins jusqu'à 1000 roubles? <br>  - Mais il n'y a rien de moins cher? <br>  - trop cher pour moi <br>  - ... <br>  <b>Que faire:</b> ajoutez un filtre de prix à la demande et choisissez l'un des vins les plus populaires. <br><br>  <b>Intention 3 - Je veux du vin pour la viande</b> <br>  Phrases: <br><br>  - Conseiller le vin au steak <br>  "Je vais avoir du goulasch pour le dîner."  Que boire? <br>  - ... <br>  <b>Que faire à ce sujet: une</b> requête à la base de données par le critère «à la viande», sélectionner l'un des vins les plus populaires et informer l'utilisateur. <br><br>  ... (et ainsi de suite des centaines d'intentions différentes) <br><br>  <b>Intention 290 - nous n'avons pas compris l'utilisateur</b> <br>  Phrases: toute autre <br><br>  <b>Que faire:</b> émettre une phrase tronquée: "Je ne sais pas ce que tu veux dire, mais le Pinista est délicieux à tout moment de l'année." <br><br><h4>  Étape 2 </h4><br>  À ce stade, nous commençons à créer un algorithme par lequel le robot fonctionnera.  Ici se termine la similitude du chatbot et de l'assistant virtuel. <br><br>  Lors du codage d'un chatbot, le programmeur détermine manuellement les mots clés pour chaque intention, et lorsque l'utilisateur écrit, le bot recherchera ces mots clés dans la phrase. <br><br>  Lors du développement d'un assistant, un programmeur enseigne un algorithme pour comparer les répliques d'utilisateur selon la signification lexicale.  Cela vous permet de trouver l'intention la plus proche. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Vin de choix avec un chat bot </th><th>  Sélection de vins avec un assistant AI virtuel </th><th>  Qu'est-il arrivé? </th></tr><tr><td>  <b>Utilisateur:</b> Bonjour!  Je veux choisir du vin pour le dîner avant 2000r <br>  <b>Bot:</b> Bonjour! <br>  <b>Bot:</b> Quelle gamme de prix recherchons-nous? <br>  <b>Utilisateur:</b> jusqu'à 2000r <br>  <b>Bot:</b> Je peux recommander Ramirez de la Piscina.  Au meilleur de la tarte, le bel homme d'Espagne convient au dîner et à votre série préférée.  1240₽ par bouteille </td><td>  <b><b>Utilisateur:</b></b> Bonjour!  Je veux choisir du vin pour le dîner avant 2000r <br>  <b>Assistant:</b> Bonjour!  Je peux recommander Ramirez de la Piscina.  Au meilleur de la tarte, le bel homme d'Espagne convient au dîner et à votre série préférée.  1240₽ par bouteille </td><td>  Bot - est allé par mots-clés pour choisir + vin.  Je n'ai pas compris la fourchette de prix et ai redemandé.  Assistant - est allé à l'intention la plus proche et a récupéré la fourchette de prix. </td></tr><tr><td>  <b>Utilisateur:</b> je n'aime pas la tarte <br>  <b>Bot:</b> Votre candidat est Casillero del Diablo Cabernet Sauvignon Reserva <br>  <b>Bot:</b> La tarte chilienne Sauvignon vous réchauffera certainement.  Seulement 872₽ </td><td>  <b>Utilisateur:</b> je n'aime pas la tarte <br>  <b>Assistant:</b> Votre candidat est Antigal, "Uno" Malbec. <br>  <b>Assistant:</b> Un doux argentin droit de 2015. Le prix d'une bouteille est de 20 $ </td><td>  Chatbot a été guidé par le mot clé "tarte" et a fait une erreur.  Et l'assistant a compris que l'intention la plus proche de «Je n'aime pas la tarte» était les vins doux. </td></tr><tr><td>  <b>Utilisateur:</b> Eh bien, c'est tellement bon marché.  Je vais probablement le prendre. <br>  <b>Bot:</b> Ensuite, essayez "FYI" Red Blend <br>  <b>Bot:</b> Malgré la cote élevée, son prix n'est que de 10 $ <br>  <b>Bot:</b> bon choix </td><td>  <b>Utilisateur:</b> Eh bien, c'est tellement bon marché.  Je vais probablement le prendre. <br>  <b>Assistant:</b> bon choix </td><td>  Le processus des robots en propose un à la fois.  M. chatbot a regardé le mot «bon marché», a répondu selon le modèle - en conséquence, il n'a pas deviné et s'est embrouillé.  L'assistant a simplement ignoré la première phrase, car il comprenait la seconde. <br></td></tr></tbody></table></div><br><div class="spoiler">  <b class="spoiler_title">Comment ça marche: un tableau comparant les chatbots et les assistants virtuels</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th>  Chat bot </th><th>  Assistant virtuel </th></tr><tr><td>  Pour comprendre l'utilisateur, nous prenons des mots clés. <br>  Lors de la création d'un chatbot, les technologies d'apprentissage automatique et NLU ne sont pas utilisées. <br></td><td>  Pour comprendre l'utilisateur, nous faisons une comparaison «intelligente» et choisissons l'intention la plus proche (un peu plus tard, nous expliquons comment cela fonctionne). <br>  L'apprentissage automatique et les algorithmes NLU nous permettent de mesurer la distance entre les répliques.  Par exemple, l'expression «vaisseau spatial» est plus proche de «avion» que de «scooter».  Et de la "vente du rein" - très loin. </td></tr><tr><td>  <b>Préparation:</b> Pour chaque intention, nous écrivons les mots-clés (wine_year_meat: steak, viande, goulash, vin + viande) <br><br>  <b>Algorithme:</b> <br><ul><li>  Nous reprenons les mots de la réplique de l'utilisateur («Conseiller le vin au steak» → conseiller, le vin, le steak). </li><li>  Choisissez l'intention dans laquelle la plupart des mots-clés proviennent de la réplique de l'utilisateur (wine_meat_meat). </li><li>  Si le bot n'a pas trouvé d'intersections par mots-clés, nous sélectionnons l'intention «nous n'avons pas compris l'utilisateur». </li><li>  Effectuez une action qui correspond à l'intention. </li></ul><br></td><td>  <b>Préparation: Nous</b> formons le modèle pour des comparaisons intelligentes <br><br>  <b>Algorithme:</b> <br><ul><li>  Comparez la phrase d'un utilisateur avec des phrases d'intentions à l'aide d'une comparaison intelligente. </li><li>  Choisissez l'intention avec les phrases les plus proches </li><li>  Si l'intention sélectionnée n'est pas assez proche de la réplique de l'utilisateur (le seuil n'a pas passé), nous sélectionnons l'intention «nous n'avons pas compris l'utilisateur». </li><li>  Effectuez une action qui correspond à l'intention. </li></ul><br></td></tr><tr><td>  <b>Comment améliorer:</b> <br>  Pour réduire les erreurs, ajoutez des commandes et des boutons. <br>  Ensuite, les utilisateurs cessent généralement de communiquer dans la langue et cliquent simplement sur les boutons. <br>  De telles améliorations conduisent à la dégradation de l'intelligence conversationnelle. <br></td><td>  <b>Comment améliorer:</b> <br>  Après que les utilisateurs auront parlé au robot, nous aurons de nouveaux exemples de phrases et nous les distribuerons en fonction de leurs intentions. <br>  Au fil du temps, le pourcentage de couverture augmentera, l'assistant commencera à mieux gérer la communication. <br>  Ces améliorations conduisent à une meilleure intelligence conversationnelle. <br></td></tr></tbody></table></div><br></div></div><br><h3>  Est-il vrai que les assistants virtuels comprennent la langue? </h3><br>  Les algorithmes peuvent distinguer certaines phrases des autres - mais pouvons-nous dire que les robots comprennent vraiment le langage? <br><br>  Pour répondre à cette question, revenons à une comparaison de la signification lexicale des phrases.  La signification pour un ordinateur est des types de données compréhensibles: chaînes, nombres et combinaisons de ceux-ci.  Par conséquent, le programmeur est confronté à la tâche de transformer le texte source en une forme adaptée aux opérations mathématiques de comparaison - un vecteur. <br><br><pre><code class="plaintext hljs">vectorize(" ") = (0.004, 17.43, -0.021, ..., 18.68) vectorize("  ") = (0.004, 19.73, -0.001, ..., 25.28) vectorize("  ") = (-8.203, 15.22, -9.253, ..., 10.11) vectorize(" ") = (89.23, -68.99, -10.62, ..., -0.982)</code> </pre> <br>  <i>Pour nos tâches, les vecteurs de phrases lexicalement proches doivent être mathématiquement proches les uns des autres, les lexicalement éloignés doivent être éloignés, le vecteur de phrases d'un autre opéra doit être très éloigné.</i>  <i>Par exemple, «Je veux du vin» est plus proche de «Je veux du vin blanc» que de «Je ne veux pas de vin».</i>  <i>Et loin des «attaques martiennes».</i> <br><br>  Un réseau neuronal correctement formé pourra conclure à la signification lexicale de ces vecteurs.  Il s'avère que, pour comparer la signification de deux phrases, vous devez comparer leurs vecteurs. <br><br>  Par conséquent, la réponse à la question «Les robots comprennent-ils le langage?» Sera comme ceci: ils ne comprennent pas comment est une personne, ils savent juste comparer les significations lexicales et ne confondent pas le chaud et le doux.  Mais lorsque les algorithmes peuvent offrir des raffinements suggestifs et tirer des conclusions, nous disons honnêtement: oui, la compréhension est arrivée.  En attendant, "comprendre la langue" n'est qu'une belle phrase marketing. <br><br>  En fait, le robot ne fonctionne qu'avec des analogies, comme un enfant de trois ans.  Cependant, si vous donnez à l'enfant un nombre suffisant d'exemples, il pourra se faire passer pour un intellectuel et animer une discussion.  L'opérateur «en direct» de la première ligne de support fonctionne de la même manière - ils décrivent un ensemble de situations et leur expliquent comment s'y comporter.  Par conséquent, les assistants virtuels sont bien adaptés à l'automatisation du support. <br><br><h3>  Comment nous avons appris au robot à comprendre le contexte: le lialang </h3><br>  Pour un support normal, les robots ont besoin de peu de «compréhension» du langage naturel - il est important qu'ils puissent répondre aux questions et rester en contexte.  Pour ce faire, nous avons écrit lialang, un langage de balisage de dialogue où les scripts peuvent être décrits et transmis au robot. <br><br>  La tâche principale d'un programmeur lialang est de décrire toutes les situations qui peuvent se produire dans un dialogue entre une personne et une machine.  Pour ce faire, dans notre langue, vous pouvez associer les noms des intentions et des actions. <br><br>  Prenons un exemple simple - une salutation: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent() { reaction(_) }</code> </pre> <br>  Cela ressemble à du code normal, mais une grille de neurones fonctionne derrière la construction d'intention (...) - lialang décrit le dialogue dans des schémas généraux ("si on vous demandait quelque chose") en utilisant les constructions de programmation habituelles.  Bien sûr, pour que cela fonctionne, vous devez appliquer les technologies d'apprentissage automatique et NLU, car l'utilisateur peut écrire sa demande comme il le souhaite. <br><br><div class="spoiler">  <b class="spoiler_title">Et voici comment décrire des situations contextuelles.</b> <div class="spoiler_text">  Nous avons introduit la construction «était» pour saisir les salutations inappropriées n'importe où dans le dialogue: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent() { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> was_reaction(_) { reaction(___) } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { reaction(_) } }</code> </pre> <br>  Il dit: Lia, s'ils vous ont dit bonjour, dites bonjour en réponse.  Et si après cela, ils ont de nouveau dit «bonjour» - dites que vous avez déjà dit bonjour. <br></div></div><br>  Une réaction est une action que Lia doit effectuer en réponse à une intention.  Dans 95% des cas, ce n'est que du texte.  Mais le robot peut également appeler une fonction dans le code, commuter la communication avec l'opérateur ou effectuer d'autres actions complexes. <br><br>  Le code pour envoyer du texte et des fonctions existe séparément de la langue - la langue décrit les situations aussi simplement que possible. <br><br>  Essayons maintenant d'écrire quelque chose de plus compliqué - dans une conversation avec la banque, les clients demandent souvent leurs coordonnées.  Apprenons à les envoyer au chat et au courrier à l'aide de lialang. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent(_) or intent(___) { reaction(___) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent(__) { reaction(___) } } } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent(___) { reaction(___) }</code> </pre> <br>  Deux situations sont décrites ici: <br><br><ol><li>  Lia, si on vous demandait d'envoyer les détails - envoyez-les au chat.  Si après avoir demandé «il est nécessaire au bureau de poste», envoyez-les au bureau de poste. </li><li>  Lia, si on vous demandait immédiatement d'envoyer les détails par la poste - envoyez les détails par la poste. </li></ol><br>  Le lialang fait donc son travail - travaille en contexte.  Même si une personne écrit «par courrier, s'il vous plaît», le robot comprendra que nous parlons de détails. <br><br>  Lia a appris à prendre en charge des scénarios complexes - au moment nécessaire pour l'utilisateur, elle obtiendra / mettra des données de / vers CRM, enverra des SMS, une aide au paiement ou parlera de la vie. <br><br>  Peu à peu, nous avons amélioré le langage: nous avons ajouté des variables, des fonctions, des entités (dates, adresses, numéros de téléphone, noms, etc.), des états et d'autres constructions utiles.  Il est donc devenu encore plus pratique d'écrire dessus. <br><br><h3>  Test de cas: comment nous avons automatisé le support dans trois banques </h3><br>  Dès que nous avons fait la technologie, elle devait être finalisée de toute urgence - nous avions notre premier client.  VTB devait automatiser le support dans une nouvelle banque Internet pour les entrepreneurs. <br><br>  Nous avons commencé avec beaucoup de succès - en particulier pour un produit créé en quatre mois.  Notre robot hybride pour VTB était basé sur des réseaux de neurones et a été immédiatement efficace: il a répondu à plus de 800 questions, pris en charge plusieurs scénarios complexes (relevés, modifications tarifaires, paramètres utilisateur) et a parlé comme une personne.  En conséquence, en deux mois, notre Lia a réduit la charge de support de 74%.  Il est devenu clair: l'idée de l'automatisation du support fonctionne. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c63/1d6/1d3/c631d61d34e155c0e3e67b7fe354b29c.png" alt="image"><br><br>  De plus, sur la base de Lia, nous avons automatisé la FAQ chez Rocketbank et DeloBank - et en deux semaines, ils ont fermé 32% des applications sans opérateurs. <br><br>  Il semblerait que les garçons aient réussi.  Cependant, après les premiers clients, il est devenu clair que le concept devait être changé.  C'était l'enfer - nous avons dû modifier manuellement les scripts, faire des modifications, développer les branches.  La même chose avec des robots simples, seulement plus durs et nécessite plus de force.  Dans cette situation, il était difficile de faire évoluer. <br><br>  Ensuite, nous avons décidé de créer un outil dans lequel le client lui-même pourra assembler même un assistant complexe.  Et nous n'aiderons qu'avec les didacticiels et éduquerons les utilisateurs. <br><br><h3>  Plateforme Lia et moteur pour les interfaces </h3><br>  Nous avons donc décidé de créer une <a href="https://lia.chat/">plateforme</a> pour ceux qui ne comprennent pas le développement.  Bien que le lialang contienne moins de dix modèles différents, tous les managers ne lui apprendront pas à créer leur propre bot.  Les gestionnaires aiment la souris. <br><br>  Par conséquent, nous avons commencé à penser à une telle interface qui sera capable de faire tout ce que le lialang peut faire.  Il n'aura pas de problèmes avec les branches imbriquées, les transitions d'un script à l'autre, et surtout - non seulement nos programmeurs, mais tous ceux qui le souhaitent peuvent créer des scripts. <br><br>  <b>Voyez à quoi ça ressemble:</b> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/de6/bf6/aed/de6bf6aeda231d7af48c7a7973e72692.gif" alt="Lia patform"><br>  <i>Les dialogues sont une chose non linéaire et l'écriture d'un moteur universel pour toutes sortes de schémas de conversation est très difficile.</i>  <i>Mais avant de penser aux schémas, nous avions déjà du lialang - il est devenu le moteur.</i> <br><br>  Quels que soient les concepteurs d'interface, nous ne codons pas les cerveaux pour cela, mais écrivons seulement un petit traducteur de balisage de l'interface en code lialang.  Si l'interface est refaite, nous n'aurons qu'à changer le traducteur - grâce auquel la commande interface et la commande core peuvent exister séparément. <br><br><h3>  Comment fonctionne la plateforme de création d'assistants virtuels? </h3><br>  Pour assembler votre propre assistant virtuel dans Lia, l'utilisateur doit passer par trois étapes. <br><br><h4>  Étape 1. Téléchargez l'historique du chat avec les utilisateurs afin que le robot comprenne et mette en évidence les principaux scénarios </h4><br>  Si le client a un historique de conversations avec les utilisateurs, il peut les télécharger sur le système et obtenir des clusters à partir des requêtes les plus courantes.  Il sera très pratique de créer des intentions à partir d'eux. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cff/782/ad9/cff782ad9a1ad00149d87941414e25b4.png" alt="Un exemple d'immodération des utilisateurs"><br><br>  Au fil du temps, l'efficacité de Lia augmentera.  Les messages auxquels le robot n'a pas pu répondre sont à nouveau distribués en grappes: par exemple, «qui êtes-vous?», «Qui êtes-vous?», «Quel est votre nom?» Et «êtes-vous un robot?» Tomberont dans un groupe.  Ainsi, la plate-forme s'auto-apprend semi-automatiquement: l'utilisateur voit où est l'écart et le comble, ajoutant de nouveaux scénarios - en conséquence, le pourcentage de demandes couvertes passe de 30% à 70% en six mois. <br><br>  S'il n'y a pas d'historique de correspondance, nous sautons cette étape et commençons immédiatement par la deuxième étape: nous prédisons quelles demandes les utilisateurs se tourneront vers l'assistant. <br><br><h4>  Étape 2. Nous notons l'intention: 10-20 options pour les demandes des utilisateurs les plus fréquentes </h4><br>  À la deuxième étape, nous prescrivons des intentions basées sur les 10 à 20 requêtes les plus populaires: ce nombre d'options est suffisant grâce aux réseaux de neurones.  Ainsi, une phrase comme «Je veux commander du vin» apprend au bot à reconnaître les demandes d'utilisateurs similaires: par exemple, «Obtenir du vin» ou «Commander du vin». <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6f7/be3/2b8/6f7be32b83ba8c3e1a697a8a2602b3c2.png" alt="Exemple de balisage d'intention"><br><br>  Un autre assistant comprend et extrait l'essentiel: noms de villes, numéros de téléphone, adresses, horodatages, périodes, dates et malédictions - même si vous dites «fatigué, apportez une boîte de vin demain». <br><br>  De plus, les utilisateurs peuvent ajouter leurs propres objets et marquer manuellement des phrases de formation pour que l'assistant apprenne plus rapidement.  C'est l'une des fonctionnalités les plus puissantes de la plateforme, grâce à laquelle elle peut créer des robots qui ne fonctionnent pas moins bien qu'un opérateur humain. <br><br><h4>  Étape 3. Créez un scénario: prescrivez plusieurs réponses ou actions </h4><br>  Ici, l'utilisateur doit trouver des réponses aux demandes des utilisateurs.  95% du projet moyen prend généralement un scénario simple de questions-réponses - réponses à des questions courantes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f32/068/532/f32068532a574a7debc8bbbb4960d083.png" alt="image"><br><br>  Soit dit en passant, l'assistant peut répondre avec des images, des vidéos et des fichiers audio et, si nécessaire, envoyer une géolocalisation. <br><br>  Le saut à construire est particulièrement utile - grâce à lui, Lia peut passer d'un scénario à un autre, puis revenir en arrière, résoudre plusieurs problèmes.  Ceci est utile si vous devez vous éloigner du dialogue, puis revenir sur la bonne voie: par exemple, posez une question de clarification. <br><br>  <b>Exemple de boîte de dialogue:</b> <br><br>  Assistant: Nous devons clarifier l'adresse de livraison, car le destinataire ne répond pas. <br>  Client: Et à propos de quoi?  Quelle commande?  (JumpTo pour la clarification de la commande) <br>  Assistant: Ordonnance du 21 août, Antigal, "Uno" Malbec. <br>  Assistant: Alors pouvons-nous clarifier l'adresse de livraison actuelle?  (Retour au script principal) <br><br>  Lorsque le créateur veut que son assistant non seulement réponde par un texte, mais qu'il prenne des mesures, il pourra appeler un programmeur pour écrire des extraits JS pour le spécialiste.  Nous vous permettons d'exécuter JavaScript directement pendant les scripts: accédez à l'API externe, envoyez un e-mail ou effectuez une autre action complexe. <br><br><h3>  4. Résumé </h3><br>  Un assistant peut s'intégrer à tout: parler à une personne au téléphone, dans des messageries instantanées ou un widget que le client affichera sur le site. <br><br>  L'assemblage d'un assistant intelligent dans la plate-forme prend de quelques heures à un mois.  Ensuite, le robot apprend à comprendre de manière réaliste les demandes et à reconnaître les modèles - cela prend environ six mois (pendant tout ce temps, une personne vivante les supervise).  Les affaires peuvent effectuer la plupart des tâches de routine pour la fille robotique Lia: de la coordination de la livraison et de l'appel d'un taxi à la consultation des clients. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3e1/87a/d17/3e187ad17975ec5c222949ff4b907784.png" alt="Exemple de discussion avec Virtual Wine Assistant"><br><br>  Soit dit en passant, nous avons déjà transféré des projets avec des banques sur la plateforme.  Ils fonctionnent tout aussi bien, mais sont beaucoup plus commodément modérés. <br><br>  Dans un avenir proche, nous prévoyons d'ajouter des extracteurs, ce qui permettra à nos utilisateurs d'extraire des données plus complexes (par exemple, le robot comprendra l'expression "après-demain après le déjeuner").  Nous allons également finaliser le contrôle des versions afin que les clients puissent rapidement restaurer et restaurer les versions des projets.  Et nous allons également libérer le système de rôle de l'organisation. <br><br>  Nous nous attendons à ce que les <a href="https://www.ibm.com/blogs/watson/2017/10/how-chatbots-reduce-customer-service-costs-by-30-percent/">prévisions</a> de Gartner soient correctes - et en 2022, jusqu'à 70% de toutes les interactions avec les clients passeront par une sorte d'IA.  Selon notre idée, des concepteurs comme Lia aideront à transférer le service client vers des robots encore plus rapidement. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr478572/">https://habr.com/ru/post/fr478572/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr478552/index.html">Deuxième applet, fermeture et boutons transparents dans Processing 3</a></li>
<li><a href="../fr478554/index.html">Webinaire "SRE - battage médiatique ou l'avenir?" 12 décembre à 11h00</a></li>
<li><a href="../fr478560/index.html">Les messageries instantanées gratuites sont-elles anonymes?</a></li>
<li><a href="../fr478564/index.html">Comment nous, chez TsIAN, avons dompté des téraoctets de journaux</a></li>
<li><a href="../fr478566/index.html">iOS Mise en réseau lorsque l'application n'est pas en cours d'exécution</a></li>
<li><a href="../fr478574/index.html">La vérité sur les freins ferroviaires: Partie 4 - Freins pour passagers</a></li>
<li><a href="../fr478580/index.html">Comment la puce graphique Super Nintendo a fonctionné: Guide Super PPU</a></li>
<li><a href="../fr478582/index.html">Rapport VPN mondial sur les appareils mobiles en 2019</a></li>
<li><a href="../fr478584/index.html">JVM Internals, Part 2 - Class File Structure</a></li>
<li><a href="../fr478586/index.html">Inefficacité</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
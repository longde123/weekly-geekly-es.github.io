<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüåæ üë®üèº‚Äçüç≥ üåÜ NeurIPS 2019: tendencias de ML que estar√°n con nosotros durante la pr√≥xima d√©cada ‚òÅÔ∏è üïî ü§πüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="NeurIPS ( Neural Information Processing Systems ) es la conferencia m√°s grande del mundo sobre aprendizaje autom√°tico e inteligencia artificial y el e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NeurIPS 2019: tendencias de ML que estar√°n con nosotros durante la pr√≥xima d√©cada</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/485384/">  NeurIPS ( <a href="https://neurips.cc/">Neural Information Processing Systems</a> ) es la conferencia m√°s grande del mundo sobre aprendizaje autom√°tico e inteligencia artificial y el evento principal en el mundo del aprendizaje profundo. <br><br>  En la nueva d√©cada, ¬ødominaremos los ingenieros de DS tambi√©n la biolog√≠a, la ling√º√≠stica y la psicolog√≠a?  Lo diremos en nuestra revisi√≥n. <br><br><img src="https://habrastorage.org/webt/1h/_r/zp/1h_rzpox6uyefi-1l3-g4n6wph4.png"><br><a name="habracut"></a><br>  Este a√±o, la conferencia reuni√≥ a m√°s de 13,500 personas de 80 pa√≠ses en Vancouver (Canad√°).  Este no es el primer a√±o que Sberbank ha representado a Rusia en la conferencia: el equipo de DS habl√≥ sobre la introducci√≥n de ML en los procesos bancarios, la competencia de ML y las capacidades de la plataforma Sberbank DS.  ¬øCu√°les fueron las principales tendencias de 2019 en la comunidad de ML?  Los participantes en la conferencia cuentan: <a href="https://habr.com/ru/users/achertok/">Andrey Chertok</a> y <a href="https://habr.com/ru/users/Rybolos/">Tatyana Shavrina</a> . <br><br>  Este a√±o, se aceptaron m√°s de 1400 art√≠culos en NeurIPS: algoritmos, nuevos modelos y nuevas aplicaciones para nuevos datos.  <a href="https://papers.nips.cc/book/advances-in-neural-information-processing-systems-32-2019">Enlace a todos los materiales</a> <br><br><h2>  Contenido: </h2><br><ul><li>  Tendencias </li><li><ul><li>  Interpretabilidad del modelo </li><li>  Multidisciplinariedad </li><li>  Razonamiento </li><li>  RL </li><li>  Gan </li></ul></li><li>  Charlas invitadas clave </li><li><ul><li>  "Inteligencia social", Blaise Aguera y Arcas (Google) </li><li>  "Ciencia de datos ver√≠dicos", Bin Yu (Berkeley) </li><li>  "Modelado del comportamiento humano con aprendizaje autom√°tico: oportunidades y desaf√≠os", Nuria M Oliver, Albert Ali Salah </li><li>  "Del sistema 1 al sistema 2 Aprendizaje profundo", Yoshua Bengio </li></ul><br></li></ul><br><h3>  Tendencias 2019 </h3><br>  <b>1. Interpretabilidad del modelo y la nueva metodolog√≠a de ML</b> <br><br>  El tema principal de la conferencia es la interpretaci√≥n y la prueba de por qu√© obtenemos estos o esos resultados.  Puede hablar durante mucho tiempo sobre la importancia filos√≥fica de interpretar la "caja negra", pero hubo m√°s m√©todos reales y desarrollos t√©cnicos en esta √°rea. <br><br>  La metodolog√≠a de reproducibilidad de los modelos y la extracci√≥n de conocimiento de ellos es un nuevo conjunto de herramientas de la ciencia.  Los modelos pueden servir como una herramienta para adquirir nuevos conocimientos y probarlos, y todas las etapas de preprocesamiento, capacitaci√≥n y aplicaci√≥n del modelo deben ser reproducibles. <br>  Una proporci√≥n importante de publicaciones se dedica no a crear modelos y herramientas, sino a problemas para garantizar la seguridad, la transparencia y la verificabilidad de los resultados.  En particular, apareci√≥ una transmisi√≥n separada sobre los ataques al modelo (ataques adversos), y se consideran las opciones tanto para los ataques al entrenamiento como a los ataques a las aplicaciones. <br><br>  Art√≠culos: <br><br><ul><li>  <a href="https://arxiv.org/pdf/1901.08152.pdf">Veridical Data Science</a> es un art√≠culo <a href="https://arxiv.org/pdf/1901.08152.pdf">destacado</a> sobre metodolog√≠a de verificaci√≥n de modelos.  Incluye una visi√≥n general de las herramientas modernas para interpretar modelos, en particular, el uso de la atenci√≥n y la obtenci√≥n de importancia de caracter√≠sticas debido a la "destilaci√≥n" de la red neuronal por modelos lineales. </li><li>  <a href="https://papers.nips.cc/paper/9095-this-looks-like-that-deep-learning-for-interpretable-image-recognition">Esto se ve as√≠: Aprendizaje profundo para el reconocimiento de im√°genes interpretables</a> Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, Jonathan K. Su </li><li>  <a href="https://papers.nips.cc/paper/9167-a-benchmark-for-interpretability-methods-in-deep-neural-networks">Un punto de referencia para los m√©todos de interpretaci√≥n en redes neuronales profundas</a> Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, Been Kim </li><li> <a href="https://papers.nips.cc/paper/9400-towards-interpretable-reinforcement-learning-using-attention-augmented-agents">Hacia el aprendizaje de refuerzo interpretable usando la atenci√≥n Agentes aumentados</a> Alexander Mott, Daniel Zoran, Mike Chrzanowski, Daan Wierstra, Danilo Jim√©nez Rezende </li><li>  <a href="https://papers.nips.cc/paper/9017-a-debiased-mdi-feature-importance-measure-for-random-forests">Una medida de importancia de la caracter√≠stica MDI debiatada para bosques aleatorios</a> Xiao Li, Yu Wang, Sumanta Basu, Karl Kumbier, Bin Yu </li><li>  <a href="https://papers.nips.cc/paper/8538-knowledge-extraction-with-no-observable-data">Extracci√≥n de conocimiento sin datos observables</a> Jaemin Yoo, Minyong Cho, Taebum Kim, U Kang </li><li>  <a href="https://papers.nips.cc/paper/8787-a-step-toward-quantifying-independently-reproducible-machine-learning-research">Un paso hacia la cuantificaci√≥n Investigaci√≥n de aprendizaje autom√°tico independientemente reproducible</a> Edward Raff </li></ul><br><img src="https://habrastorage.org/webt/ad/pv/qm/adpvqmvrz7ykydrstpa__uva47o.jpeg"><br>  <i>ExBert.net muestra la interpretaci√≥n del modelo para tareas de procesamiento de texto</i> <i><br></i> <br>  <b>2. Multidisciplinariedad</b> <br><br>  Con el fin de garantizar una verificaci√≥n confiable y desarrollar mecanismos para probar y reponer el conocimiento, se necesitan especialistas de campos relacionados, que simult√°neamente tengan competencias en ML y en el campo tem√°tico (medicina, ling√º√≠stica, neurobiolog√≠a, educaci√≥n, etc.).  De particular inter√©s es la presencia m√°s significativa de trabajos y presentaciones sobre neurociencias y ciencias cognitivas: hay un acercamiento de especialistas e ideas prestadas. <br><br>  Adem√°s de este acercamiento, se planea la multidisciplinariedad en el procesamiento conjunto de informaci√≥n de varias fuentes: texto y fotos, texto y juegos, bases de datos de gr√°ficos + texto y fotos. <br><br>  Art√≠culos: <br><br><ul><li>  Neurobiology + ML - <a href="https://papers.nips.cc/paper/9633-interpreting-and-improving-natural-language-processing-in-machines-with-natural-language-processing-in-the-brain.pdf">Interpretaci√≥n y mejora del procesamiento del lenguaje natural (en m√°quinas) con procesamiento del lenguaje natural (en el cerebro)</a> </li><li>  VisualQA - <a href="https://papers.nips.cc/paper/8825-learning-by-abstraction-the-neural-state-machine.pdf">Aprendizaje por abstracci√≥n: la m√°quina de estados neuronales</a> </li><li>  RL + NLP - <a href="https://arxiv.org/abs/1906.00744">Toma de decisiones jer√°rquicas mediante la generaci√≥n y el seguimiento de instrucciones en lenguaje natural</a> </li></ul><br><img src="https://habrastorage.org/webt/jk/78/-t/jk78-tncs0aiwk0_kw3woos8g9q.png"><br>  <i>Dos modelos, un estratega y un int√©rprete, basados ‚Äã‚Äãen RL y PNL juegan una estrategia en l√≠nea</i> <br><br>  <b>3. Razonamiento</b> <br><br>  Fortalecimiento de la inteligencia artificial: un movimiento hacia sistemas de autoaprendizaje, "consciente", razonamiento y discusi√≥n (razonamiento).  En particular, se desarrolla la inferencia causal y el razonamiento de sentido com√∫n.  Parte de los informes est√° dedicado al metaaprendizaje (c√≥mo aprender a aprender) y la combinaci√≥n de tecnolog√≠as DL con l√≥gica de primer y segundo orden: el t√©rmino Inteligencia Artificial General (AGI) se convierte en un t√©rmino com√∫n en los discursos de los oradores. <br><br>  Art√≠culos: <br><br><ul><li>  <a href="https://papers.nips.cc/paper/8544-heterogeneous-graph-learning-for-visual-commonsense-reasoning">Aprendizaje gr√°fico heterog√©neo para el razonamiento de sentido</a> com√∫n <a href="https://papers.nips.cc/paper/8544-heterogeneous-graph-learning-for-visual-commonsense-reasoning">visual</a> Weijiang Yu, Jingwen Zhou, Weihao Yu, Xiaodan Liang, Nong Xiao </li><li>  <a href="https://papers.nips.cc/paper/8548-bridging-machine-learning-and-logical-reasoning-by-abductive-learning">Bridging Machine Learning y razonamiento l√≥gico mediante el aprendizaje abductivo</a> Wang-Zhou Dai, Qiuling Xu, Yang Yu, Zhi-Hua Zhou </li><li>  <a href="https://papers.nips.cc/paper/8599-implicitly-learning-to-reason-in-first-order-logic">Aprendiendo impl√≠citamente a razonar en la l√≥gica de primer orden</a> Vaishak Belle, Brendan Juba </li><li>  <a href="https://papers.nips.cc/paper/8752-phyre-a-new-benchmark-for-physical-reasoning">PHYRE: un nuevo punto de referencia para el razonamiento f√≠sico</a> Anton Bakhtin, Laurens van der Maaten, Justin Johnson, Laura Gustafson, Ross Girshick </li><li>  <a href="https://papers.nips.cc/paper/8797-quantum-embedding-of-knowledge-for-reasoning">Incrustaci√≥n cu√°ntica del conocimiento para el razonamiento</a> Dinesh Garg, Shajith Ikbal, Santosh K. Srivastava, Harit Vishwakarma, Hima Karanam, L Venkata Subramaniam </li></ul><br>  <b>4.aprendizaje de refuerzo</b> <br><br>  La mayor parte del trabajo contin√∫a desarrollando las √°reas tradicionales de RL - DOTA2, Starcraft, combinando arquitecturas con visi√≥n por computadora, PNL, bases de datos gr√°ficas. <br><br>  Un d√≠a separado de la conferencia se dedic√≥ al taller de RL, que present√≥ la arquitectura del Modelo Optimista de Actor Cr√≠tico, superando a todos los anteriores, en particular el Cr√≠tico de Actor Suave. <br><br>  Art√≠culos: <br><br><ul><li>  <a href="https://papers.nips.cc/paper/8455-better-exploration-with-optimistic-actor-critic">Mejor exploraci√≥n con cr√≠tico optimista del actor</a> ;  Kamil Ciosek, Quan Vuong, Robert Loftin, Katja Hofmann </li><li>  <a href="https://drive.google.com/file/d/1C-uJ4CjjzPuKG3APQRAI1-1AKnUFNv9y/view%3Fusp%3Ddrivesdk">ChainerRL: una biblioteca de aprendizaje de refuerzo profundo</a> ;  Yasuhiro Fujita (Preferred Networks, Inc.) *;  Toshiki Kataoka (Preferred Networks, Inc.);  Prabhat Nagarajan (Redes preferidas);  Takahiro Ishikawa (Universidad de Tokio) [enlace pdf externo]. </li><li>  <a href="https://arxiv.org/pdf/1912.01603.pdf">Sue√±o para controlar: comportamientos de aprendizaje por imaginaci√≥n latente</a> ;  Danijar Hafner (Google) *;  Timothy Lillicrap (DeepMind);  Jimmy Ba (Universidad de Toronto);  Mohammad Norouzi (Google Brain) </li><li>  <a href="https://sites.google.com/view/deep-rl-workshop-neurips-2019/home">Materiales del taller</a> </li></ul><br><img src="https://habrastorage.org/webt/yt/ad/hj/ytadhjrxnecxke2xghj9dx7jrqy.jpeg"><br>  <i>Los jugadores de StarCraft luchan contra Alphastar (DeepMind)</i> <br><br>  <b>5. GAN</b> <br><br>  Las redes generativas siguen siendo el foco de atenci√≥n: muchas obras utilizan GAN de vainilla para pruebas matem√°ticas, y tambi√©n las aplican en versiones nuevas e inusuales (modelos generativos gr√°ficos, trabajo con series, aplicaci√≥n para causar y afectar relaciones en datos, etc.). <br><br>  Art√≠culos: <br><br><ul><li>  <a href="https://papers.nips.cc/paper/8848-mining-gold-samples-for-conditional-gans">Miner√≠a Muestras de ORO para GAN condicionales Sangwoo</a> Mo, Chiheon Kim, Sungwoong Kim, Minsu Cho, Jinwoo Shin </li><li>  <a href="https://papers.nips.cc/paper/8855-progressive-augmentation-of-gans">Aumento progresivo de las GAN</a> Dan Zhang, Anna Khoreva </li><li>  <a href="https://papers.nips.cc/paper/8953-modeling-tabular-data-using-conditional-gan">Modelado de datos tabulares utilizando GAN condicional</a> Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, Kalyan Veeramachaneni </li><li>  <a href="https://papers.nips.cc/paper/9377-a-domain-agnostic-measure-for-monitoring-and-evaluating-gans">papers.nips.cc/paper/9377-a-domain-agnostic-measure-for-monitoring-and-evaluating-gans</a> </li></ul><br>  Dado que el trabajo se ha llevado a m√°s de <a href="https://papers.nips.cc/book/advances-in-neural-information-processing-systems-32-2019">1.400 a</a> continuaci√≥n, hablaremos sobre las actuaciones m√°s importantes. <br><br><h3>  Charlas invitadas </h3><br><h4>  "Inteligencia social", Blaise Aguera y Arcas (Google) </h4><br>  <a href="https://neurips.cc/Conferences/2019/Schedule%3FshowEvent%3D15487">Enlace</a> <br>  <a href="https://slideslive.com/38921748/social-intelligence">Diapositivas y videos</a> <br>  El informe est√° dedicado a la metodolog√≠a general de aprendizaje autom√°tico y las perspectivas que est√°n cambiando la industria en este momento: ¬øa qu√© encrucijada nos enfrentamos?  ¬øC√≥mo funciona el cerebro y la evoluci√≥n, y por qu√© usamos tan poco que ya sabemos bien sobre el desarrollo de los sistemas naturales? <br><br>  El desarrollo industrial de ML coincide en gran medida con los hitos del desarrollo de Google, que publica su investigaci√≥n sobre NeurIPS de a√±o en a√±o: <br><br><ul><li>  1997 - lanzamiento de capacidades de b√∫squeda, primeros servidores, peque√±a potencia inform√°tica </li><li>  2010 - Jeff Dean lanza el proyecto Google Brain, un boom de redes neuronales desde el principio </li><li>  2015: implementaci√≥n industrial de redes neuronales, reconocimiento r√°pido de rostros directamente en el dispositivo local, procesadores de bajo nivel mejorados por la inform√°tica tensorial (TPU).  Google lanza Coral ai, un an√°logo de raspberry pi, una mini computadora para introducir redes neuronales en instalaciones experimentales </li><li>  2017 - Google comienza el desarrollo de entrenamiento descentralizado y combina los resultados del entrenamiento de redes neuronales desde diferentes dispositivos en un solo modelo - en Android </li></ul><br>  Hoy, toda una industria se preocupa por la seguridad de los datos, combinando y reproduciendo resultados de aprendizaje en dispositivos locales. <br><br>  <a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html">Aprendizaje federado</a> : direcci√≥n de <a href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html">aprendizaje autom√°tico</a> en la que los modelos individuales estudian de forma independiente y luego se combinan en un solo modelo (sin centralizar los datos de origen), ajustados por eventos raros, anomal√≠as, personalizaci√≥n, etc.  Todos los dispositivos Android son esencialmente una sola supercomputadora inform√°tica para Google. <br><br>  Los modelos generativos basados ‚Äã‚Äãen el aprendizaje federado son un √°rea prometedora futura, seg√∫n Google, que se encuentra "en las primeras etapas de crecimiento exponencial".  Los GAN, seg√∫n el profesor, pueden aprender a reproducir el comportamiento de masas de las poblaciones de organismos vivos, utilizando algoritmos de pensamiento. <br><br>  Usando dos arquitecturas GAN simples como ejemplo, se muestra que en ellas la b√∫squeda de la ruta de optimizaci√≥n vaga en un c√≠rculo, lo que significa que la optimizaci√≥n no ocurre como tal.  Adem√°s, estos modelos modelan con mucho √©xito los experimentos que los bi√≥logos realizan en poblaciones bacterianas, oblig√°ndolos a aprender nuevas estrategias de comportamiento en busca de alimento.  Podemos concluir que la vida funciona de manera diferente a la funci√≥n de optimizaci√≥n. <br><br><img src="https://habrastorage.org/webt/wk/ra/kl/wkraklcn5znwapudkhvr_utuqqo.jpeg"><br>  <i>Optimizaci√≥n de GAN errante</i> <br><br>  Todo lo que hacemos en el marco del aprendizaje autom√°tico ahora es tareas estrechas y extremadamente formalizadas, mientras que estos formalismos est√°n poco generalizados y no corresponden a nuestro conocimiento del tema en √°reas como la neurofisiolog√≠a y la biolog√≠a. <br><br>  Lo que realmente vale la pena tomar prestado del campo de la neurofisiolog√≠a en el futuro cercano es la nueva arquitectura de las neuronas y una peque√±a revisi√≥n de los mecanismos de propagaci√≥n del error. <br><br>  El cerebro humano en s√≠ no aprende a usar una red neuronal: <br><br><ul><li>  No tiene introductorios primarios aleatorios, incluidos los establecidos a trav√©s de los sentidos y en la infancia. </li><li>  √âl tiene las direcciones establecidas de desarrollo instintivo (el deseo de aprender un idioma desde una postura erguida infantil) </li></ul><br>  Aprender el cerebro individual es una tarea de bajo nivel, quiz√°s deber√≠amos considerar las "colonias" de los individuos que cambian r√°pidamente, transmiti√©ndose conocimientos entre s√≠ para reproducir los mecanismos de la evoluci√≥n grupal. <br><br>  ¬øQu√© podemos tomar en los algoritmos de ML en este momento? <br><br><ul><li>  Aplicar modelos de linaje celular que brinden capacitaci√≥n para la poblaci√≥n, pero la corta vida del individuo ("cerebro individual") </li><li>  Pocos aprendizajes en algunos ejemplos </li><li>  Estructuras neuronales m√°s complejas, funciones de activaci√≥n ligeramente diferentes. </li><li>  Transmitir el "genoma" a las generaciones futuras: algoritmo de propagaci√≥n inversa </li><li>  Tan pronto como conectemos neurofisiolog√≠a y redes neuronales, aprenderemos c√≥mo construir un cerebro multifuncional a partir de muchos componentes. </li></ul><br>  Desde este punto de vista, la pr√°ctica de las soluciones SOTA es perjudicial y debe revisarse para desarrollar tareas comunes (puntos de referencia). <br><br><h4>  "Ciencia de datos ver√≠dicos", Bin Yu (Berkeley) </h4><br>  <a href="https://slideslive.com/38921720/veridical-data-science">Videos y diapositivas</a> <br>  El informe est√° dedicado al problema de la interpretaci√≥n de los modelos de aprendizaje autom√°tico y la metodolog√≠a de su verificaci√≥n y verificaci√≥n directa.  Cualquier modelo ML capacitado puede ser percibido como una fuente de conocimiento que debe extraerse de √©l. <br><br>  En muchas √°reas, especialmente en medicina, la aplicaci√≥n del modelo es imposible sin extraer este conocimiento oculto e interpretar los resultados del modelo; de lo contrario, no estaremos seguros de que los resultados ser√°n estables, no aleatorios, confiables y no matar√°n al paciente.  Toda la direcci√≥n de la metodolog√≠a de trabajo se desarrolla dentro del paradigma de aprendizaje profundo y va m√°s all√° de sus l√≠mites: la ciencia de datos ver√≠dica.  Que es esto <br><br>  Queremos lograr la calidad de las publicaciones cient√≠ficas y la reproducibilidad de los modelos para que sean: <br><br><ol><li>  predecible </li><li>  computable </li><li>  estable </li></ol><br>  Estos tres principios forman la base de la nueva metodolog√≠a.  ¬øC√≥mo se pueden probar los modelos ML con estos criterios?  La forma m√°s f√°cil es construir modelos inmediatamente interpretables (regresiones, √°rboles de decisi√≥n).  Sin embargo, queremos obtener las ventajas inmediatas del aprendizaje profundo. <br><br>  Varias formas existentes de tratar el problema: <br><br><ol><li>  interpretar el modelo; </li><li>  Utilice m√©todos basados ‚Äã‚Äãen la atenci√≥n. </li><li>  use conjuntos de algoritmos para el entrenamiento y aseg√∫rese de que los modelos lineales interpretables aprendan a predecir las mismas respuestas que una red neuronal, interpretando las caracter√≠sticas de un modelo lineal; </li><li>  Cambiar y aumentar los datos de entrenamiento.  Esto incluye la adici√≥n de ruido, interferencia y aumento de datos; </li><li>  cualquier m√©todo que asegure que los resultados del modelo no sean aleatorios y no dependan de peque√±as interferencias no deseadas (ataques adversos); </li><li>  interpretar el modelo post factum despu√©s del entrenamiento; </li><li>  estudiar pesos de signos de varias maneras; </li><li>  Estudiar las probabilidades de todas las hip√≥tesis, la distribuci√≥n de clases. </li></ol><br><img src="https://habrastorage.org/webt/zy/8y/g3/zy8yg3z5wwn8vxfp2f5cicm6u0i.png"><br>  <i>Ataque adversarial <a href="https://neurips.cc/Conferences/2019/Schedule%3FshowEvent%3D14481">a un cerdo</a></i> <br><br>  Los errores de modelado son caros para todos: un ejemplo v√≠vido: el trabajo de Reinhart y Rogov " <a href="https://en.wikipedia.org/wiki/Growth_in_a_Time_of_Debt">Crecimiento en tiempos de deuda</a> " influy√≥ en las pol√≠ticas econ√≥micas de muchos pa√≠ses europeos y los oblig√≥ a seguir una pol√≠tica de ahorro, ¬°pero la verificaci√≥n cruzada cuidadosa de los datos y su procesamiento a√±os despu√©s mostraron el resultado opuesto! <br><br>  Cualquier tecnolog√≠a ML tiene su propio ciclo de vida de implementaci√≥n a implementaci√≥n.  La tarea de la nueva metodolog√≠a es verificar tres principios b√°sicos en cada etapa de la vida del modelo. <br><br>  Resumen: <br><br><ul><li>  Se est√°n desarrollando varios proyectos para ayudar a que el modelo ML sea m√°s confiable.  Esto es, por ejemplo, deeptune (enlace a: <a href="https://github.com/ChrisCummins/paper-end2end-dl/">github.com/ChrisCummins/paper-end2end-dl</a> ); </li><li>  Para un mayor desarrollo de la metodolog√≠a, es necesario mejorar significativamente la calidad de las publicaciones en el campo de ML; </li><li>  El aprendizaje autom√°tico necesita l√≠deres con capacitaci√≥n multidisciplinaria y experiencia en los campos t√©cnicos y humanitarios. </li></ul><br><h4>  "Modelado del comportamiento humano con aprendizaje autom√°tico: oportunidades y desaf√≠os" Nuria M Oliver, Albert Ali Salah </h4><br>  Conferencia sobre modelado del comportamiento humano, sus fundamentos tecnol√≥gicos y perspectivas de aplicaci√≥n. <br><br>  El modelado del comportamiento humano se puede dividir en: <br><br><ul><li>  comportamiento individual </li><li>  comportamiento de grupos peque√±os </li><li>  comportamiento masivo </li></ul><br>  Cada uno de estos tipos se puede modelar usando ML, pero con informaci√≥n y caracter√≠sticas de entrada completamente diferentes.  Cada tipo tambi√©n tiene sus propios problemas √©ticos por los que pasa cada proyecto: <br><br><ul><li>  comportamiento individual: robo de identidad, falsificaci√≥n profunda; </li><li>  el comportamiento de grupos de personas: desanonimizaci√≥n, obtenci√≥n de informaci√≥n sobre movimientos, llamadas telef√≥nicas, etc. </li></ul><br>  <b>Comportamiento individual</b> <br><br>  En mayor medida, el tema de la visi√≥n por computadora: reconocimiento de las emociones humanas, sus reacciones.  Es posible solo en contexto, en el tiempo o con una escala relativa de su propia variabilidad de emociones.  En la diapositiva est√° el reconocimiento de las emociones de Mona Lisa usando el contexto del espectro emocional de las mujeres mediterr√°neas.  Resultado: una sonrisa de alegr√≠a, pero con desprecio y asco.  La raz√≥n es m√°s probable en la forma t√©cnica de determinar la emoci√≥n "neutral". <br><br>  <b>Comportamiento en grupos peque√±os</b> <br><br>  Hasta ahora, lo peor est√° modelado debido a la falta de informaci√≥n.  Las obras de 2018-2019 se mostraron como ejemplo.  en docenas de personas X docenas de videos (cf. conjuntos de datos de im√°genes 100k ++).  Para la mejor simulaci√≥n dentro de esta tarea, se requiere informaci√≥n multimodal, preferiblemente desde sensores hasta un telealt√≠metro, term√≥metro, grabaci√≥n de micr√≥fono, etc. <br><br>  <b>Comportamiento masivo</b> <br><br>  El √°rea m√°s desarrollada, ya que el cliente es las Naciones Unidas y muchos estados.  C√°maras de vigilancia al aire libre, datos de torres telef√≥nicas (facturaci√≥n, SMS, llamadas, datos sobre el movimiento entre las fronteras de los estados), todo esto da una idea muy confiable del movimiento de los flujos de personas, de las inestabilidades sociales.  Posibles aplicaciones de la tecnolog√≠a: optimizaci√≥n de operaciones de rescate, asistencia y evacuaci√≥n oportuna de la poblaci√≥n en caso de emergencia.  Hasta ahora, los modelos utilizados est√°n en su mayor√≠a mal interpretados: se trata de varios LSTM y redes convolucionales.  Hubo un breve comentario de que la ONU est√° presionando por una nueva ley que obligue a las empresas europeas a compartir los datos an√≥nimos necesarios para cualquier investigaci√≥n. <br><br><h4>  "Del sistema 1 al sistema 2 Aprendizaje profundo", Yoshua Bengio </h4><br>  <a href="https://drive.google.com/file/d/1zbe_N8TmAEvPiKXmn6yZlRkFehsAUS8Z/view">Diapositivas</a> <br>  En una conferencia de Joshua, el aprendizaje profundo de Benjio se encuentra con la neurociencia en el nivel de fijaci√≥n de objetivos. <br>  Benjio identifica dos tipos principales de tareas seg√∫n la metodolog√≠a del premio Nobel Daniel Kahneman (el libro " <a href="https://ru.wikipedia.org/wiki/%25D0%2594%25D1%2583%25D0%25BC%25D0%25B0%25D0%25B9_%25D0%25BC%25D0%25B5%25D0%25B4%25D0%25BB%25D0%25B5%25D0%25BD%25D0%25BD%25D0%25BE%25E2%2580%25A6_%25D1%2580%25D0%25B5%25D1%2588%25D0%25B0%25D0%25B9_%25D0%25B1%25D1%258B%25D1%2581%25D1%2582%25D1%2580%25D0%25BE">Piensa despacio, resuelve r√°pido</a> ") <br>  tipo 1 - Sistema 1, las acciones inconscientes que hacemos "en la m√°quina" (el cerebro antiguo): conducir un autom√≥vil en lugares familiares, caminar, reconocer rostros. <br>  tipo 2 - Sistema 2, acciones conscientes (corteza cerebral), fijaci√≥n de objetivos, an√°lisis, pensamiento, tareas compuestas. <br><br>  Hasta ahora, la inteligencia artificial alcanza alturas suficientes solo en tareas del primer tipo, mientras que nuestra tarea es llevarla al segundo, habiendo aprendido c√≥mo realizar operaciones multidisciplinarias y operar con habilidades cognitivas l√≥gicas de alto nivel. <br><br>  Para lograr este objetivo, se propone: <br><br><ol><li>  utilizar la atenci√≥n como mecanismo clave para modelar el pensamiento en tareas de PNL </li><li>  utilice el metaaprendizaje y el aprendizaje de representaci√≥n para modelar mejor los signos que afectan la conciencia y su localizaci√≥n, y en funci√≥n de ellos, cambie a operar con conceptos de nivel superior. </li></ol><br>  En lugar de la conclusi√≥n, dejamos la entrada de la charla invitada: Benjio es uno de los muchos cient√≠ficos que est√°n tratando de expandir el campo de ML m√°s all√° de los problemas de optimizaci√≥n, SOTA y nuevas arquitecturas. <br>  La pregunta sigue abierta en qu√© medida la combinaci√≥n de los problemas de la conciencia, la influencia del lenguaje en el pensamiento, la neurobiolog√≠a y los algoritmos es lo que nos espera en el futuro y nos permitir√° pasar a m√°quinas que "piensan" como las personas. <br><br>  Gracias <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/FtUbMG3rlFs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a href="https://habr.com/ru/post/485384/">https://habr.com/ru/post/485384/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../485372/index.html">Sobre lo inmutable: historia del noveno lugar de la Copa AI rusa 2019</a></li>
<li><a href="../485374/index.html">La cach√© es el rey del rendimiento: los procesadores necesitan un cuarto nivel de cach√©</a></li>
<li><a href="../485376/index.html">¬øC√≥mo hacer que la interfaz sea tres veces m√°s r√°pida y cu√°ndo aplicar comandos en lugar de repositorios? Video</a></li>
<li><a href="../485378/index.html">Estudio de caso: C√≥mo aparecer en Google Play y adaptar ASO a diferentes pa√≠ses</a></li>
<li><a href="../485380/index.html">Artesan√≠a y √âxito de TI</a></li>
<li><a href="../485386/index.html">Microbrowsers est√°n en todas partes. ¬øPero qu√© sabemos sobre ellos?</a></li>
<li><a href="../485388/index.html">Gobierna, sufre, sonr√≠e</a></li>
<li><a href="../485390/index.html">Concurso de micro subsidios de c√≥digo abierto para proyectos de datos abiertos</a></li>
<li><a href="../485392/index.html">Telegram bot que monitorea el dominio</a></li>
<li><a href="../485394/index.html">Como naci√≥ la infraestructura de Internet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
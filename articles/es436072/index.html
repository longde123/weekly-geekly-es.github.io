<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëÇüèº üë®üèæ‚Äçüç≥ üéÜ Limpiar, marcar: c√≥mo ense√±amos a chatbot a distinguir los problemas del cliente üßñ ‚óÄÔ∏è üïô</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Anton Chaynikov, desarrollador de Data Science, Redmadrobot 
 Hola Habr! Hoy hablar√© sobre las dificultades en el camino al chatbot, lo que facilita e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Limpiar, marcar: c√≥mo ense√±amos a chatbot a distinguir los problemas del cliente</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redmadrobot/blog/436072/"><p><img src="https://habrastorage.org/webt/k4/rl/pc/k4rlpcs5lwl2dsvt97pez6qhfgw.png"></p><br><p><img src="https://habrastorage.org/webt/mp/4c/kh/mp4ckhvyt2k9kydafhv3vxa0its.png" align="left">  <strong>Anton Chaynikov, desarrollador de Data Science, Redmadrobot</strong> <br>  <em>Hola Habr!</em>  <em>Hoy hablar√© sobre las dificultades en el camino al chatbot, lo que facilita el trabajo de los operadores de chat de la compa√±√≠a de seguros.</em>  <em>M√°s precisamente, c√≥mo ense√±amos al bot a distinguir las solicitudes entre s√≠ mediante el aprendizaje autom√°tico.</em>  <em>Con qu√© modelos se experimentaron y cu√°les obtuvieron los resultados.</em>  <em>¬øC√≥mo cuatro enfoques para limpiar y enriquecer datos de calidad decente y cinco intentos de limpiar datos de calidad "indecente"?</em> <a name="habracut"></a></p><br><h3 id="zadacha">  Desaf√≠o </h3><br><p>  El chat de la compa√±√≠a de seguros recibe m√°s de 100500 llamadas de clientes por d√≠a.  La mayor√≠a de las preguntas son simples y repetitivas, pero los operadores no son m√°s f√°ciles y los clientes a√∫n tienen que esperar de cinco a diez minutos.  ¬øC√≥mo mejorar la calidad del servicio y optimizar los costos de mano de obra para que los operadores tengan menos rutina y los usuarios tengan sensaciones m√°s agradables al resolver r√°pidamente sus problemas? </p><br><p>  Y haremos un chatbot.  Perm√≠tale leer mensajes de usuario, dar instrucciones para casos simples y hacer preguntas est√°ndar para casos complejos para obtener la informaci√≥n que el operador necesita.  Un operador en vivo tiene un √°rbol de guiones: un gui√≥n (o diagrama de flujo) que dice qu√© preguntas pueden hacer los usuarios y c√≥mo responderlas.  Tomar√≠amos este esquema y lo pondr√≠amos en un chatbot, pero es una mala suerte: el chatbot no entiende humanamente y no sabe c√≥mo relacionar la pregunta del usuario con la rama del script. </p><br><p>  Entonces, le ense√±aremos con la ayuda del buen aprendizaje autom√°tico.  Pero no puede simplemente tomar un dato generado por los usuarios y ense√±arle un modelo de calidad decente.  Para hacer esto, debe experimentar con la arquitectura del modelo, los datos, para limpiarlos y, a veces, volver a recopilarlos. </p><br><p>  <strong>C√≥mo ense√±ar a un bot:</strong> </p><br><ul><li>  Considere las opciones del modelo: c√≥mo se combinan el tama√±o del conjunto de datos, los detalles de la vectorizaci√≥n de los textos, la reducci√≥n de la dimensi√≥n, el clasificador y la precisi√≥n final. </li><li>  Limpiemos los datos decentes: encontraremos clases que se pueden tirar de forma segura;  descubriremos por qu√© los √∫ltimos seis meses de marcado son mejores que los tres anteriores;  determinar d√≥nde se encuentra el modelo y d√≥nde est√° el marcado;  Descubra c√≥mo los errores tipogr√°ficos pueden ser √∫tiles. </li><li>  Limpiaremos los datos "indecentes": descubriremos cu√°ndo la agrupaci√≥n es √∫til e in√∫til, a medida que los usuarios y operadores hablan cuando es hora de dejar de sufrir e ir a recoger el marcado. </li></ul><br><h3 id="faktura">  Textura </h3><br><p>  Ten√≠amos dos clientes, compa√±√≠as de seguros con chats en l√≠nea, y proyectos de capacitaci√≥n de chatbot (no los llamaremos, esto no es importante), con una calidad de datos muy diferente.  Bueno, si la mitad de los problemas del segundo proyecto pudieran resolverse mediante manipulaciones del primero.  Los detalles est√°n abajo. </p><br><p>  Desde un punto de vista t√©cnico, nuestra tarea es clasificar textos.  Esto se realiza en dos etapas: primero, los textos se vectorizan (usando tf-idf, doc2vec, etc.), luego el modelo de clasificaci√≥n se entrena en los vectores (y clases) obtenidos: bosque aleatorio, SVM, red neuronal, etc.  Y as√≠ sucesivamente. </p><br><p>  De d√≥nde provienen los datos: </p><br><ul><li> Historial de chat de carga SQL.  Campos de carga relevantes: texto del mensaje;  autor (cliente u operador);  agrupar mensajes en di√°logos;  marca de tiempo  categor√≠a de contacto con el cliente (preguntas sobre seguro obligatorio de responsabilidad civil, seguro de casco, seguro m√©dico voluntario; preguntas sobre el sitio; preguntas sobre programas de lealtad; preguntas sobre cambios en las condiciones del seguro, etc.). </li><li>  Un √°rbol de scripts, o secuencias de preguntas y respuestas de operadores a clientes con diferentes solicitudes. </li></ul><br><p>  Sin validaci√≥n, por supuesto, en ninguna parte.  Todos los modelos fueron entrenados en el 70% de los datos y evaluados de acuerdo con los resultados en el 30% restante. </p><br><p>  M√©tricas de calidad para los modelos que utilizamos: </p><br><ul><li>  En entrenamiento: logloss, para diferenciabilidad; </li><li>  Al escribir informes: precisi√≥n de clasificaci√≥n en una muestra de prueba, por simplicidad y claridad (incluso para el cliente); </li><li>  Al elegir la direcci√≥n para futuras acciones: la intuici√≥n de un cient√≠fico de datos que mira fijamente los resultados. </li></ul><br><h3 id="eksperimenty-s-modelyami">  Experimentos modelo </h3><br><p>  Es raro cuando la tarea deja en claro de inmediato qu√© modelo dar√° los mejores resultados.  Entonces aqu√≠: sin experimentaci√≥n, en ninguna parte. </p><br><p>  Intentaremos las opciones de vectorizaci√≥n: </p><br><ul><li>  tf-idf en palabras simples; </li><li>  tf-idf en triples de caracteres (en adelante: 3 gramos); </li><li>  tf-idf en 2, 3, 4, 5 gramos por separado; </li><li>  tf-idf en 2-, 3-, 4-, 5 gramos tomados juntos; </li><li>  Todo lo anterior + reducci√≥n de palabras en el texto fuente a una forma de diccionario; </li><li>  Todo lo anterior + disminuci√≥n de dimensi√≥n por el m√©todo SVD truncado; </li><li>  Con el n√∫mero de mediciones: 10, 30, 100, 300; </li><li>  doc2vec, entrenado en el cuerpo de textos de la tarea. </li></ul><br><p>  Las opciones de clasificaci√≥n en este contexto parecen bastante pobres: SVM, XGBoost, LSTM, bosques aleatorios, bah√≠as ingenuas, bosque aleatorio sobre las predicciones SVM y XGB. </p><br><p>  Y aunque verificamos la reproducibilidad de los resultados en tres conjuntos de datos ensamblados independientemente y sus fragmentos, solo podemos garantizar la amplia aplicabilidad. </p><br><p>  <strong>Los resultados de los experimentos:</strong> </p><br><ul><li>  En la cadena "clasificaci√≥n-dimensi√≥n de preprocesamiento-vectorizaci√≥n-reducci√≥n", el efecto de la elecci√≥n en cada paso es casi independiente de los otros pasos.  Lo cual es muy conveniente, no puede pasar por una docena de opciones con cada nueva idea y usar la opci√≥n m√°s conocida en cada paso. </li><li>  tf-idf en palabras pierde 3 gramos (precisi√≥n 0,72 frente a 0,78).  2-, 4-, 5 gramos pierden a 3 gramos (0.75‚Äì0.76 vs 0.78).  Los {2; 5} gramos en conjunto superan bastante los 3 gramos.  Dado el fuerte aumento en la memoria requerida, decidimos descuidar el entrenamiento con una ganancia de 0.4% de precisi√≥n. </li><li>  En comparaci√≥n con tf-idf de todas las variedades, doc2vec era in√∫til (precisi√≥n 0.4 y menos).  Valdr√≠a la pena tratar de entrenarlo no en el cuerpo de la tarea (~ 250,000 textos), sino en uno mucho m√°s grande (2.5‚Äì25 millones de textos), pero hasta ahora, por desgracia, sus manos no han llegado. </li><li>  SVD truncado no ayud√≥.  La precisi√≥n aumenta monot√≥nicamente al aumentar la medici√≥n, logrando sin problemas la precisi√≥n sin TSVD. </li><li>  Entre los clasificadores, XGBoost gana por un margen notable (+ 5‚Äì10%).  Los competidores m√°s cercanos son SVM y bosques aleatorios.  Naive Bayes no es un competidor incluso para bosques aleatorios. </li><li>  El √©xito de LSTM depende en gran medida del tama√±o del conjunto de datos: en una muestra de 100,000 objetos, puede competir con XGB.  En una muestra de 6000 - en el rezago junto con Bayes. </li><li>  Un bosque aleatorio en la parte superior de SVM y XGB siempre est√° de acuerdo con XGB o se confunde m√°s.  Esto es muy triste, esperamos que SVM encuentre en los datos al menos algunos patrones que no est√°n disponibles para XGB, pero lamentablemente. </li><li>  XGBoost es complicado con la estabilidad.  Por ejemplo, su actualizaci√≥n de la versi√≥n 0.72 a 0.80 redujo inexplicablemente la precisi√≥n de los modelos entrenados en un 5‚Äì10%.  Y una cosa m√°s: XGBoost admite el cambio de los par√°metros de entrenamiento durante el entrenamiento y la compatibilidad con la API est√°ndar de scikit-learn, pero estrictamente por separado.  No pueden hacer las dos cosas juntas.  Tuve que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arreglarlo.</a> </li><li>  Si lleva palabras a una forma de diccionario, esto mejora un poco la calidad, en combinaci√≥n con tf-idf en palabras, pero es in√∫til en todos los dem√°s casos.  Al final, lo apagamos para ahorrar tiempo. </li></ul><br><h3 id="opyt-1-chistka-dannyh-ili-chto-delat-s-razmetkoy">  Experiencia 1. Limpieza de datos, o qu√© hacer con el marcado </h3><br><p>  Los operadores de chat son solo personas.  Al definir las categor√≠as de consultas de los usuarios, a menudo se equivocan y tienen diferentes interpretaciones de los l√≠mites entre las categor√≠as.  Por lo tanto, los datos de origen deben limpiarse de manera despiadada e intensiva. </p><br><p>  Nuestros datos sobre la capacitaci√≥n modelo en el primer proyecto: </p><br><ul><li>  Una historia de mensajes de chat en l√≠nea durante varios a√±os.  Esto es 250,000 publicaciones en 60,000 conversaciones.  Al final del di√°logo, el operador seleccion√≥ la categor√≠a a la que pertenece la llamada del usuario.  Hay alrededor de 50 categor√≠as en este conjunto de datos. </li><li>  √Årbol de guiones  En nuestro caso, los operadores no ten√≠an scripts de trabajo. </li></ul><br><p>  Lo que los datos son exactamente malos, los formulamos como hip√≥tesis, luego los verificamos y, cuando es posible, los corregimos.  Esto es lo que sucedi√≥: </p><br><p>  <strong>El primer acercamiento.</strong>  De toda la enorme lista de clases, puede dejar de forma segura 5-10. <br>  Descartamos clases peque√±as (&lt;1% de la muestra): pocos datos + peque√±o impacto.  Unimos clases dif√≠ciles de distinguir, a las cuales los operadores a√∫n reaccionan de la misma manera.  Por ejemplo: <br>  'dms' + 'c√≥mo hacer una cita con un m√©dico' + 'pregunta sobre c√≥mo completar el programa' <br>  'cancelaci√≥n' + 'estado de cancelaci√≥n' + 'cancelaci√≥n de la pol√≠tica pagada' <br>  'pregunta de renovaci√≥n' + '¬øc√≥mo renovar la pol√≠tica?' </p><br><p>  Luego, descartamos clases como "otro", "otro" y similares: para un chatbot, son in√∫tiles (de todos modos, redirigiendo a un operador), y al mismo tiempo da√±an mucho la precisi√≥n, ya que el 20% de las solicitudes (30, 50, 90) est√°n clasificadas inapropiadamente por los operadores. y aqui  Ahora descartamos la clase con la que el chatbot no puede trabajar (todav√≠a). </p><br><p>  Resultado: en un caso, crecimiento de una precisi√≥n de 0.40 a 0.69, en otro, de 0.66 a 0.77. </p><br><p>  <strong>El segundo enfoque.</strong>  Al comienzo del chat, los propios operadores no comprenden c√≥mo elegir una clase para que el usuario se ponga en contacto, por lo que hay mucho "ruido" y errores en los datos. </p><br><p>  Experimento: solo tomamos los √∫ltimos dos (tres, seis, ...) meses de di√°logos y capacitamos al modelo en <br>  ellos. </p><br><p>  Resultado: en un caso notable, la precisi√≥n aument√≥ de 0,40 a 0,60, en otro, de 0,69 a 0,78. </p><br><p>  <strong>El tercer enfoque.</strong>  A veces, una precisi√≥n de 0,70 no significa "el modelo est√° equivocado en el 30% de los casos", sino "en el 30% de los casos el marcado es falso y el modelo lo corrige de manera muy razonable". </p><br><p>  Por m√©tricas como precisi√≥n o logloss, esta hip√≥tesis no puede ser verificada.  Para los fines del experimento, nos limitamos a la mirada de un cient√≠fico de datos, pero en el caso ideal, debe reorganizar cualitativamente el conjunto de datos, sin olvidar la validaci√≥n cruzada. </p><br><p>  Para trabajar con tales muestras, se nos ocurri√≥ el proceso de "enriquecimiento iterativo": </p><br><ol><li>  Divide el conjunto de datos en 3-4 fragmentos. </li><li>  Entrena al modelo en el primer fragmento. </li><li>  Predecir las clases de la segunda por el modelo entrenado. </li><li>  Observe de cerca las clases predichas y el grado de confianza del modelo, elija el valor l√≠mite de confianza. </li><li>  Elimine los textos (objetos) predichos con confianza debajo del l√≠mite del segundo fragmento, entrene al modelo en esto. </li><li>  Repita hasta que los fragmentos se cansen o se agoten. </li></ol><br><p>  Por un lado, los resultados son excelentes: el primer modelo de iteraci√≥n tiene una precisi√≥n del 70%, el segundo - 95%, el tercero - 99 +%.  Una mirada cercana a los resultados de las predicciones confirma completamente esta precisi√≥n. </p><br><p>  Por otro lado, ¬øc√≥mo se puede verificar sistem√°ticamente en este proceso que los modelos posteriores no aprenden los errores de los anteriores?  Existe la idea de probar el proceso en un conjunto de datos manualmente "ruidoso" con marcado inicial de alta calidad, como MNIST.  Pero, por desgracia, no hubo tiempo suficiente para esto.  Y sin verificaci√≥n, no nos atrevimos a lanzar el enriquecimiento iterativo y los modelos resultantes en producci√≥n. </p><br><p>  <strong>El cuarto enfoque.</strong>  El conjunto de datos se puede ampliar y, por lo tanto, aumentar la precisi√≥n y reducir el reciclaje, agregando muchos errores tipogr√°ficos a los textos existentes. <br>  Los errores tipogr√°ficos son errores tipogr√°ficos: duplicar una letra, omitir una letra, reorganizar las letras vecinas en algunos lugares, reemplazar una letra con una letra adyacente en el teclado. </p><br><p>  Experimento: la proporci√≥n de letras p en las que se producir√° un error tipogr√°fico: 2%, 4%, 6%, 8%, 10%, 12%.  Aumento del conjunto de datos: generalmente hasta 60,000 r√©plicas.  Dependiendo del tama√±o inicial (despu√©s de los filtros), esto signific√≥ un aumento de 3 a 30 veces. </p><br><p>  Resultado: depende del conjunto de datos.  En un conjunto de datos peque√±o (~ 300 r√©plicas), 4‚Äì6% de los errores tipogr√°ficos dan un aumento estable y significativo en la precisi√≥n (0,40 ‚Üí 0,60).  En grandes conjuntos de datos, todo es peor.  Con una proporci√≥n de errores tipogr√°ficos de 8% o m√°s, los textos se vuelven sin sentido y la precisi√≥n disminuye.  Con una tasa de error del 2 al 8%, la precisi√≥n fluct√∫a en el rango de un peque√±o porcentaje, muy rara vez excede la precisi√≥n sin errores tipogr√°ficos y, seg√∫n las sensaciones, no hay necesidad de aumentar el tiempo de entrenamiento varias veces. </p><br><p>  Como resultado, obtenemos un modelo que distingue 5 clases de llamadas con una precisi√≥n de 0,86.  Coordinamos con el cliente los textos de preguntas y respuestas para cada uno de los cinco tenedores, sujetamos los textos al chatbot y los enviamos a QA. </p><br><h3 id="opyt-2-po-koleno-v-dannyh-ili-chto-delat-bez-razmetki">  Experiencia 2. Hasta la rodilla en los datos, o qu√© hacer sin marcado </h3><br><p>  Habiendo obtenido buenos resultados en el primer proyecto, nos acercamos al segundo con toda confianza.  Pero, afortunadamente, no olvidamos c√≥mo sorprendernos. </p><br><p>  Lo que nos encontramos con: </p><br><ul><li>  Un √°rbol de script de cinco ramas acordado con el cliente hace aproximadamente un a√±o. </li><li>  Una muestra etiquetada de 500 mensajes y 11 clases de origen desconocido. </li><li>  Etiquetado por operadores de chat de 220,000 mensajes, 21,000 conversaciones y otras 50 clases. </li><li>  El modelo SVM, entrenado en la primera muestra, con una precisi√≥n de 0,69, que fue heredado del equipo anterior de cient√≠ficos de datos.  Por qu√© SVM, la historia es silenciosa. </li></ul><br><p>  En primer lugar, observamos las clases: en el √°rbol de scripts, en la muestra del modelo SVM, en la muestra principal.  Y aqu√≠ est√° lo que vemos: </p><br><ul><li>  Las clases del modelo SVM corresponden aproximadamente a las ramas de los scripts, pero de ninguna manera corresponden a las clases de una muestra grande. </li><li>  El √°rbol de secuencias de comandos se escribi√≥ en los procesos comerciales hace un a√±o y est√° desactualizado, casi in√∫til.  El modelo SVM est√° en desuso con √©l. </li><li>  Las dos clases m√°s grandes en la muestra grande son Ventas (50%) y Otros (45%). </li><li>  De las cinco siguientes clases m√°s grandes, tres son tan generales como Ventas. </li><li>  Las 45 clases restantes contienen menos de 30 cuadros de di√°logo cada una.  Es decir  no tenemos un √°rbol de scripts, no hay una lista de clases ni marcas. </li></ul><br><p>  ¬øQu√© hacer en tales casos?  Nos arremangamos y fuimos por nuestra cuenta para obtener clases y marcas de los datos. </p><br><p>  <strong>El primer intento.</strong>  Intentemos agrupar las preguntas de los usuarios, es decir  Los primeros mensajes en el di√°logo, excepto los saludos. </p><br><p>  Lo comprobamos  Vectorizamos r√©plicas contando 3 gramos.  Bajamos la dimensi√≥n a las primeras diez mediciones de TSVD.  Agrupamos por agrupamiento aglomerativo con la distancia euclidiana y la funci√≥n Ward objetivo.  Baje la dimensi√≥n nuevamente usando t-SNE (hasta dos mediciones para que pueda ver los resultados con los ojos).  Dibujamos puntos de r√©plica en el plano, pintando con los colores de los grupos. </p><br><p>  Resultado: miedo y horror.  Clusters sanos, podemos suponer que no hay: </p><br><img src="https://habrastorage.org/webt/cl/rm/-s/clrm-sda0crxfeyq8ynskurotkk.png"><br><p>  Casi no, hay uno, naranja a la izquierda, esto se debe a que todos los mensajes contienen el "@" de 3 gramos.  Este 3 gramos es un artefacto de preprocesamiento.  En alg√∫n lugar del proceso de filtrado de signos de puntuaci√≥n, "@" no solo no se filtr√≥, sino que tambi√©n se cubri√≥ de espacios.  Pero el artefacto es √∫til.  Este cl√∫ster incluye usuarios que primero escriben su correo electr√≥nico.  Desafortunadamente, solo por la disponibilidad de correo no est√° completamente claro cu√°l es la solicitud del usuario.  Seguimos adelante. </p><br><p>  <strong>El segundo intento.</strong>  ¬øQu√© sucede si los operadores a menudo responden con enlaces m√°s o menos est√°ndar? <br>  Lo comprobamos  Extraemos subcadenas similares a enlaces de los mensajes del operador, editamos ligeramente los enlaces, de diferente ortograf√≠a, pero con el mismo significado (http / https, / search? City =% city%), consideramos las frecuencias de los enlaces. </p><br><p>  Resultado: poco prometedor.  Primero, los operadores responden solo a una peque√±a fracci√≥n de las solicitudes (&lt;10%) con enlaces.  En segundo lugar, incluso despu√©s de la limpieza manual y el filtrado de enlaces que ocurrieron una vez, hay m√°s de treinta de ellos.  En tercer lugar, en el comportamiento de los usuarios que finalizan el di√°logo con un enlace, no existe una similitud particular. </p><br><p>  <strong>El tercer intento.</strong>  Busquemos las respuestas est√°ndar de los operadores: ¬øqu√© pasar√≠a si fueran indicadores de cualquier clasificaci√≥n de mensajes? </p><br><p>  Lo comprobamos  En cada di√°logo tomamos la √∫ltima r√©plica del operador (aparte de las despedidas: "Puedo ayudar a otra cosa", etc.) y consideramos la frecuencia de las r√©plicas √∫nicas. </p><br><p>  Resultado: prometedor, pero inconveniente.  El 50% de las respuestas del operador son √∫nicas, otro 10-20% se encuentra dos veces, el 30-40% restante est√° cubierto por un n√∫mero relativamente peque√±o de plantillas populares.  Relativamente peque√±o, alrededor de trescientos.  Una mirada cercana a estas plantillas muestra que muchas de ellas son variantes de la misma respuesta en t√©rminos de significado: difieren en una letra, en una palabra, en un p√°rrafo.  Me gustar√≠a agrupar estas respuestas que tienen un significado cercano. </p><br><p>  <strong>El cuarto intento.</strong>  Agrupaci√≥n de las √∫ltimas r√©plicas de declaraciones.  Estos se agrupan mucho mejor: </p><br><img src="https://habrastorage.org/webt/cb/to/xh/cbtoxhphxhmfo-94bpelgw1dalq.png"><br><p>  Ya puedes trabajar con esto. </p><br><p>  Agrupamos y dibujamos r√©plicas en el plano, como en el primer intento, determinamos manualmente los grupos m√°s claramente separados, los eliminamos del conjunto de datos y agrupamos nuevamente.  Despu√©s de separar aproximadamente la mitad del conjunto de datos, los cl√∫steres claros terminan y comenzamos a pensar qu√© clases asignarles.  Dispersamos los grupos de acuerdo con las cinco clases originales: la muestra est√° "sesgada" y tres de las cinco clases originales no reciben un solo grupo.  Que mal.  Dispersamos los grupos en cinco clases, que designamos al azar, en: "llamar", "venir", "esperar un d√≠a para obtener una respuesta", "problemas con captcha", "otros".  La inclinaci√≥n es menor, pero la precisi√≥n es solo 0.4-0.5.  Mal otra vez.  Asigne a cada uno de los m√°s de 30 grupos su propia clase.  La muestra vuelve a estar sesgada y la precisi√≥n vuelve a ser 0,5, aunque alrededor de cinco clases seleccionadas tienen una precisi√≥n e integridad decentes (0,8 y superior).  Pero el resultado a√∫n no es impresionante. </p><br><p>  <strong>El quinto intento.</strong>  Necesitamos todos los entresijos de la agrupaci√≥n.  Recuperamos el dendrograma de agrupamiento completo en lugar de los treinta grupos principales.  Lo guardamos en un formato accesible para los analistas de los clientes y les ayudamos a realizar el marcado: bosquejamos la lista de clases. </p><br><p>  Para cada mensaje, calculamos una cadena de cl√∫steres, que incluye cada mensaje, comenzando desde la ra√≠z.  Construimos una tabla con columnas: texto, id del primer grupo en la cadena, id del segundo grupo en la cadena, ..., id del grupo correspondiente al texto.  Guardamos la tabla en csv / xls.  Adem√°s, puede trabajar con herramientas de oficina. </p><br><p>  Damos los datos y un boceto de la lista de clases para el marcado al cliente.  Los analistas de clientes volvieron a marcar ~ 10,000 mensajes de primer usuario.  Nosotros, ya ense√±ados por experiencia, pedimos marcar cada mensaje al menos dos veces.  Y no en vano: 4.000 de estos 10.000 deben desecharse, porque los dos analistas marcaron de manera diferente.  En los 6,000 restantes, repetimos r√°pidamente los √©xitos del primer proyecto: </p><br><ul><li>  L√≠nea de base: sin filtrado en absoluto - precisi√≥n 0.66. </li><li>  Combine clases que sean iguales desde el punto de vista del operador.  Obtenemos una precisi√≥n de 0,73. </li><li>  Eliminamos la clase "Otro": la precisi√≥n aumenta a 0,79. </li></ul><br><p>  El modelo est√° listo, ahora necesita dibujar un √°rbol de script.  Por razones que no podemos explicar, no tuvimos acceso a los scripts para las respuestas del operador.  No nos sorprendimos, fingimos ser usuarios y durante un par de horas en el campo recolectamos plantillas de respuestas y aclaramos las preguntas del operador para todas las ocasiones.  Los decoraron en un √°rbol, los empacaron en un bot y fueron a probar.  Cliente aprobado </p><br><h3 id="vyvody-ili-chto-pokazal-opyt">  Conclusiones, o lo que la experiencia ha demostrado: </h3><br><ul><li>  Puede experimentar con partes del modelo (preprocesamiento, vectorizaci√≥n, clasificaci√≥n, etc.) individualmente. </li><li>  XGBoost todav√≠a gobierna la pelota, aunque si necesita algo inusual, tiene problemas. </li><li>  El usuario es un dispositivo perif√©rico para entrada ca√≥tica, por lo que debe limpiar los datos del usuario. </li><li>  El enriquecimiento iterativo es genial, aunque peligroso. </li><li>  A veces vale la pena devolver los datos al cliente para el marcado.  Pero no olvide ayudarlo a obtener un resultado de calidad. </li></ul><br><p>  Para concluir <cut></cut></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es436072/">https://habr.com/ru/post/es436072/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es436062/index.html">Sistema de arbitraje para principiantes, parte 1</a></li>
<li><a href="../es436064/index.html">Inteligencia artificial para todos</a></li>
<li><a href="../es436066/index.html">Matem√°ticas del Apocalipsis: teor√≠a de juegos y la crisis nuclear del Caribe</a></li>
<li><a href="../es436068/index.html">Conferencia C ++ Rusia 2019</a></li>
<li><a href="../es436070/index.html">C√≥mo lidiar con pruebas escamosas en la comunidad de c√≥digo abierto</a></li>
<li><a href="../es436076/index.html">An√°lisis de ataque de Cowrie Hanipot</a></li>
<li><a href="../es436080/index.html">Semana de la seguridad 03: 2019 - A√±o de privacidad</a></li>
<li><a href="../es436082/index.html">C√≥mo UEBA ayuda a mejorar la ciberseguridad</a></li>
<li><a href="../es436086/index.html">Descripci√≥n general de la actualizaci√≥n 4 para Veeam Cloud Connect</a></li>
<li><a href="../es436088/index.html">El editor gr√°fico de GANpaint dibuja objetos y demuestra las capacidades de GAN</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
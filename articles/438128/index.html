<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí° üë©üèΩ‚Äçüåæ ‚ö´Ô∏è Muchos personajes, muchas redes neuronales: ¬øc√≥mo construir un sistema de reconocimiento efectivo para un gran n√∫mero de clases? üë®üèª‚Äçüíª üö¥üèº ‚òÆÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En art√≠culos anteriores, ya escribieron sobre c√≥mo funciona nuestra tecnolog√≠a de reconocimiento de texto: 

 Navegador de series 

- Reconocimiento d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Muchos personajes, muchas redes neuronales: ¬øc√≥mo construir un sistema de reconocimiento efectivo para un gran n√∫mero de clases?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/438128/">  En art√≠culos anteriores, ya escribieron sobre c√≥mo funciona nuestra tecnolog√≠a de reconocimiento de texto: <br><br><div class="spoiler">  <b class="spoiler_title">Navegador de series</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reconocimiento de texto en ABBYY FineReader (1/2)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reconocimiento de texto en ABBYY FineReader (2/2)</a> </li></ul><br></div></div><br>  Hasta 2018, el reconocimiento de los caracteres japoneses y chinos se organiz√≥ de la misma manera: principalmente usando clasificadores de raster y de caracter√≠sticas.  Pero con el reconocimiento de los jerogl√≠ficos hay dificultades: <br><br><ol><li>  Una gran cantidad de clases que deben distinguirse. </li><li>  Dispositivo de car√°cter m√°s complejo en su conjunto. </li></ol><br><img src="https://habrastorage.org/webt/fy/p7/yu/fyp7yudyxpraxbdsegon8y7w_xa.png" alt="imagen"><br><br>  Es tan dif√≠cil decir inequ√≠vocamente cu√°ntos caracteres tiene el alfabeto chino en la escritura, como es preciso contar cu√°ntas palabras en ruso.  Pero con mayor frecuencia en la escritura china se usan ~ 10,000 caracteres.  Con ellos limitamos el n√∫mero de clases utilizadas en el reconocimiento. <br><br>  Los dos problemas descritos anteriormente tambi√©n conducen al hecho de que para lograr una alta calidad, debe usar una gran cantidad de caracter√≠sticas y estas caracter√≠sticas se calculan en las im√°genes de los caracteres por m√°s tiempo. <br><br>  Para que estos problemas no condujeran a desaceleraciones severas en todo el sistema de reconocimiento, tuve que usar muchas heur√≠sticas, principalmente destinadas a cortar r√°pidamente un n√∫mero significativo de jerogl√≠ficos, que definitivamente esta imagen no parece.  Todav√≠a no ayud√≥ hasta el final, pero quer√≠amos llevar nuestra tecnolog√≠a a un nivel completamente nuevo. <br><br>  Comenzamos a estudiar la aplicabilidad de las redes neuronales convolucionales para aumentar tanto la calidad como la velocidad de reconocimiento de los jerogl√≠ficos.  Quer√≠a reemplazar toda la unidad para reconocer un solo car√°cter para estos idiomas con la ayuda de redes neuronales.  En este art√≠culo, describiremos c√≥mo finalmente lo logramos. <br><a name="habracut"></a><br><h2>  Un enfoque simple: una red de convoluci√≥n para reconocer todos los jerogl√≠ficos </h2><br>  En general, el uso de redes convolucionales para el reconocimiento de caracteres no es una idea nueva en absoluto.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Hist√≥ricamente, se utilizaron</a> por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primera vez</a> precisamente para esta tarea en 1998.  Es cierto que estos no eran caracteres impresos, sino letras y n√∫meros escritos a mano en ingl√©s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yg/fi/se/ygfisegze1bli8r9nyakftguapu.png"></div><br><br>  M√°s de 20 a√±os, la tecnolog√≠a en el campo del aprendizaje profundo, por supuesto, ha avanzado.  Incluyendo arquitecturas m√°s avanzadas y nuevos enfoques de aprendizaje. <br><br>  La arquitectura presentada en el diagrama anterior (LeNet), de hecho, y hoy es muy adecuada para tareas tan simples como el reconocimiento de texto impreso.  "Simple" lo llamo en comparaci√≥n con otras tareas de visi√≥n por computadora, como la b√∫squeda y el reconocimiento de rostros. <br><br>  Parece que la soluci√≥n no es m√°s simple.  Tomamos una red neuronal, una muestra de jerogl√≠ficos etiquetados y la entrenamos para el problema de clasificaci√≥n.  Desafortunadamente, result√≥ que no todo es tan simple.  Todas las modificaciones posibles de LeNet para la tarea de clasificar 10,000 jerogl√≠ficos no proporcionaron calidad suficiente (al menos comparable al sistema de reconocimiento que ya tenemos). <br><br>  Para lograr la calidad requerida, tuvimos que considerar arquitecturas m√°s profundas y complejas: WideResNet, SqueezeNet, etc.  Con su ayuda, fue posible alcanzar el nivel de calidad requerido, pero dieron una fuerte reducci√≥n de velocidad: 3-5 veces en comparaci√≥n con el algoritmo b√°sico en la CPU. <br><br>  Alguien puede preguntar: "¬øCu√°l es el punto de medir la velocidad de la red en la CPU, si funciona mucho m√°s r√°pido en el procesador de gr√°ficos (GPU)"?  Aqu√≠ vale la pena hacer un comentario sobre el hecho de que la velocidad del algoritmo en la CPU es principalmente importante para nosotros.  Estamos desarrollando tecnolog√≠a para la gran l√≠nea de productos de reconocimiento de ABBYY.  En el mayor n√∫mero de escenarios, el reconocimiento se realiza en el lado del cliente, y no podemos saber que tiene una GPU. <br><br>  Entonces, al final, llegamos al siguiente problema: una red neuronal para reconocer todos los caracteres dependiendo de la elecci√≥n de la arquitectura funciona muy mal o muy lentamente. <br><br><h2>  Modelo de reconocimiento de jerogl√≠ficos de red neuronal de dos niveles </h2><br>  Ten√≠a que buscar otra forma.  Al mismo tiempo, no quer√≠a abandonar las redes neuronales.  Parec√≠a que el mayor problema era una gran cantidad de clases, por lo que era necesario construir redes de arquitectura compleja.  Por lo tanto, decidimos que no entrenar√≠amos una red para un gran n√∫mero de clases, es decir, para todo el alfabeto, sino que entrenar√≠amos muchas redes para un peque√±o n√∫mero de clases (subconjuntos del alfabeto). <br><br>  En detalles generales, el sistema ideal se present√≥ de la siguiente manera: el alfabeto se divide en grupos de caracteres similares.  La red de primer nivel clasifica a qu√© grupo de caracteres pertenece una imagen determinada.  Para cada grupo, a su vez, se entrena una red de segundo nivel, que produce la clasificaci√≥n final dentro de cada grupo. <br><br>  <i>Imagen en la que se puede hacer clic</i> <br> <a href=""><img src="https://habrastorage.org/webt/lg/r9/a1/lgr9a1ibz_vktq5xvkzqquawd7k.png"></a> <br><br>  Por lo tanto, hacemos la clasificaci√≥n final mediante el lanzamiento de dos redes: la primera determina qu√© red de segundo nivel lanzar y la segunda ya realiza la clasificaci√≥n final. <br><br>  En realidad, el punto fundamental aqu√≠ es c√≥mo dividir a los personajes en grupos para que la red de primer nivel pueda ser precisa y r√°pida. <br><br><h2>  Construyendo un clasificador de primer nivel </h2><br>  Para comprender qu√© s√≠mbolos de red son m√°s f√°ciles de distinguir y cu√°les son m√°s dif√≠ciles, es m√°s f√°cil observar qu√© signos destacan para s√≠mbolos particulares.  Para hacer esto, tomamos una red clasificadora entrenada para distinguir todos los caracteres del alfabeto con buena calidad y observamos las estad√≠sticas de activaci√≥n de la pen√∫ltima capa de esta red; comenzamos a mirar las representaciones de caracter√≠sticas finales que la red recibe para todos los caracteres. <br><br>  Al mismo tiempo, sab√≠amos que la imagen deber√≠a ser algo como lo siguiente: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sr/bw/el/srbwele_woukv5qioz-qr6vdq6g.png"></div><br><br>  Este es un ejemplo simple para el caso de clasificar una selecci√≥n de d√≠gitos escritos a mano (MNIST) en 10 clases.  En la pen√∫ltima capa oculta, que va antes de la clasificaci√≥n, solo hay 2 neuronas, lo que hace que sus estad√≠sticas de activaci√≥n sean f√°ciles de mostrar en el avi√≥n.  Cada punto en el gr√°fico corresponde a alg√∫n ejemplo de la muestra de prueba.  El color de un punto corresponde a una clase espec√≠fica. <br><br>  En nuestro caso, la dimensi√≥n del espacio de caracter√≠sticas fue mayor que 128 en el ejemplo. Corrimos un grupo de im√°genes de una muestra de prueba y recibimos un vector de caracter√≠sticas para cada imagen.  Despu√©s de eso, fueron normalizados (divididos por la longitud).  De la imagen de arriba es obvio por qu√© vale la pena hacerlo.  Agrupamos los vectores normalizados por el m√©todo KMeans.  Obtuvimos un desglose de la muestra en grupos de im√°genes similares (desde el punto de vista de la red). <br><br>  Pero al final, necesit√°bamos obtener una partici√≥n del alfabeto en grupos, y no una partici√≥n de la muestra de prueba.  Pero el primero del segundo no es dif√≠cil de obtener: es suficiente asignar cada etiqueta de clase al cl√∫ster que contiene la mayor√≠a de las im√°genes de esta clase.  En la mayor√≠a de las situaciones, por supuesto, toda la clase incluso terminar√° dentro de un grupo. <br><br>  Bueno, eso es todo, tenemos una partici√≥n del alfabeto completo en grupos de caracteres similares.  Luego queda elegir una arquitectura simple y entrenar al clasificador para distinguir entre estos grupos. <br><br>  Aqu√≠ hay un ejemplo de 6 grupos aleatorios que se obtienen dividiendo el alfabeto fuente completo en 500 grupos: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ge/14/zi/ge14ziruqvxamfjvh-zx6fchb3s.png"></div><br><h2>  Construcci√≥n de clasificadores de segundo nivel. </h2><br>  A continuaci√≥n, debe decidir qu√© conjunto de personajes objetivo aprender√°n los clasificadores de segundo nivel.  La respuesta parece ser obvia: estos deber√≠an ser grupos de caracteres obtenidos en el paso anterior.  Esto funcionar√°, pero no siempre con buena calidad. <br><br>  El hecho es que el clasificador del primer nivel comete errores en cualquier caso y pueden compensarse parcialmente mediante la construcci√≥n de conjuntos del segundo nivel de la siguiente manera: <br><br><ul><li>  Arreglamos una cierta muestra separada de im√°genes de s√≠mbolos (que no participan ni en la capacitaci√≥n ni en las pruebas); </li><li>  Ejecutamos esta muestra a trav√©s de un clasificador de primer nivel capacitado, marcando cada imagen con la etiqueta de este clasificador (etiqueta de grupo); </li><li>  Para cada s√≠mbolo, consideramos todos los grupos posibles a los que el clasificador del primer nivel pertenece a las im√°genes de este s√≠mbolo; </li><li>  Agregue este s√≠mbolo a todos los grupos hasta alcanzar el grado de cobertura requerido T_acc; </li><li>  Consideramos los grupos finales de s√≠mbolos como conjuntos de objetivos del segundo nivel, en los que se entrenar√°n los clasificadores. </li></ul><br>  Por ejemplo, las im√°genes del s√≠mbolo "A" fueron asignadas por el clasificador de primer nivel 980 veces al 5 ¬∞ grupo, 19 veces al 2 ¬∞ grupo y 1 vez al 6 ¬∞ grupo.  En total tenemos 1000 im√°genes de este s√≠mbolo. <br><br>  Luego podemos agregar el s√≠mbolo "A" al 5to grupo y obtener un 98% de cobertura de este s√≠mbolo.  Podemos atribuirlo al quinto y segundo grupo y obtener una cobertura del 99.9%.  Y podemos atribuirlo inmediatamente a grupos (5, 2, 6) y obtener una cobertura del 100%. <br><br>  En esencia, T_acc establece cierto equilibrio entre velocidad y calidad.  Cuanto mayor sea, mayor ser√° la calidad final de la clasificaci√≥n, pero mayores ser√°n los conjuntos de objetivos del segundo nivel y m√°s dif√≠cil ser√° la clasificaci√≥n en el segundo nivel. <br><br>  La pr√°ctica muestra que incluso con T_acc = 1, el aumento en el tama√±o de los conjuntos como resultado del procedimiento de reposici√≥n descrito anteriormente no es tan significativo, en promedio, aproximadamente 2 veces.  Obviamente, esto depender√° directamente de la calidad del clasificador entrenado de primer nivel. <br><br>  Aqu√≠ hay un ejemplo de c√≥mo funciona esta finalizaci√≥n para uno de los conjuntos de la misma partici√≥n en 500 grupos, que era mayor: <br><br><img src="https://habrastorage.org/webt/b6/kd/nh/b6kdnh829fmav36s41h2ygqzen0.png" alt="imagen"><br><br><h2>  Resultados de incrustaci√≥n del modelo </h2><br>  Los modelos de dos niveles entrenados finalmente han funcionado m√°s r√°pido y mejor que los clasificadores utilizados anteriormente.  De hecho, no fue tan f√°cil "hacer amigos" con el mismo gr√°fico de divisi√≥n lineal (GLD).  Para hacer esto, tuve que ense√±ar por separado el modelo para distinguir los caracteres de la basura a priori y los errores de segmentaci√≥n de l√≠nea (para devolver una baja confianza en estas situaciones). <br><br>  El resultado final de incrustar en el algoritmo de reconocimiento de documentos completo a continuaci√≥n (obtenido en la colecci√≥n de documentos chinos y japoneses), la velocidad se indica para el algoritmo completo: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7g/jq/oa/7gjqoavm4iu3xwanuakuhml4mhe.png"></div><br>  Mejoramos la calidad y aceleramos tanto en modo normal como en modo r√°pido, mientras transferimos todo el reconocimiento de caracteres a las redes neuronales. <br><br><h2>  Un poco sobre el reconocimiento de extremo a extremo </h2><br>  Hoy en d√≠a, la mayor√≠a de los sistemas de OCR conocidos p√∫blicamente (el mismo Tesseract de Google) utilizan la arquitectura de extremo a extremo de las redes neuronales para reconocer cadenas o sus fragmentos en su totalidad.  Pero aqu√≠ usamos redes neuronales precisamente como un reemplazo para un m√≥dulo de reconocimiento de un solo car√°cter.  Esto no es un accidente. <br><br>  El hecho es que la segmentaci√≥n de una cadena en caracteres en chino impreso y japon√©s no es un gran problema debido a la impresi√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">monoespaciada</a> .  En este sentido, el uso del reconocimiento de extremo a extremo para estos idiomas no mejora en gran medida la calidad, pero es mucho m√°s lento (al menos en la CPU).  En general, no est√° claro c√≥mo usar el enfoque de dos niveles propuesto en el contexto de extremo a extremo. <br><br>  Por el contrario, hay lenguajes para los cuales la divisi√≥n lineal en caracteres es un problema clave.  Ejemplos expl√≠citos son √°rabe, hindi.  Para el √°rabe, por ejemplo, las soluciones de extremo a extremo ya se est√°n estudiando activamente con nosotros.  Pero esta es una historia completamente diferente. <br><br>  <i>Alexey Zhuravlev, Jefe del Grupo de Nuevas Tecnolog√≠as de OCR</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/438128/">https://habr.com/ru/post/438128/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../438118/index.html">Dex-Net 4.0 permite a los robots Ambidextro elegir lo mejor</a></li>
<li><a href="../438120/index.html">El resumen de eventos para profesionales de recursos humanos en el campo de TI para febrero de 2019</a></li>
<li><a href="../438122/index.html">Numerolog√≠a en MS SQL: un experimento entretenido</a></li>
<li><a href="../438124/index.html">Piter GraphQL: videos de mitap en Wrike</a></li>
<li><a href="../438126/index.html">Graduados de pasant√≠as de TI en Raiffeisenbank: c√≥mo fue</a></li>
<li><a href="../438130/index.html">Neutralinojs: una alternativa electr√≥nica que consume menos memoria</a></li>
<li><a href="../438132/index.html">GOSINT: una soluci√≥n de c√≥digo abierto para gestionar indicadores de compromiso (IoC)</a></li>
<li><a href="../438134/index.html">Instalaci√≥n de sistemas de CCTV: historias hermosas y desafortunadas con c√°maras</a></li>
<li><a href="../438136/index.html">Consentimiento para el procesamiento de datos GDPR: an√°lisis detallado</a></li>
<li><a href="../438138/index.html">Anatom√≠a del halc√≥n</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
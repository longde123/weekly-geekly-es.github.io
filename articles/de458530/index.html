<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üÖæÔ∏è üõ¢Ô∏è üëà Zabbix, Zeitreihen und TimescaleDB üåê üßëüèø‚Äçü§ù‚Äçüßëüèº üë∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jedes √úberwachungssystem ist mit drei Arten von Leistungsproblemen konfrontiert. 

 Erstens sollte ein gutes √úberwachungssystem Daten von au√üen sehr s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Zabbix, Zeitreihen und TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/zabbix/blog/458530/"> Jedes √úberwachungssystem ist mit drei Arten von Leistungsproblemen konfrontiert. <br><br>  Erstens sollte ein gutes √úberwachungssystem Daten von au√üen sehr schnell empfangen, verarbeiten und aufzeichnen.  Das Konto geht in Mikrosekunden.  Auf den ersten Blick mag dies nicht offensichtlich erscheinen, aber wenn das System gro√ü genug wird, werden alle diese Sekundenbruchteile zusammengefasst, was zu deutlich sp√ºrbaren Verz√∂gerungen f√ºhrt. <br><br><img src="https://habrastorage.org/webt/s6/fy/mx/s6fymxoyf5_f9n0hwidv8q6qsh4.png" alt="Bild"><br><a name="habracut"></a><br>  Die zweite Aufgabe besteht darin, einen bequemen Zugriff auf gro√üe Arrays zuvor gesammelter Metriken (mit anderen Worten auf historische Daten) bereitzustellen.  Historische Daten werden in einer Vielzahl von Kontexten verwendet.  Beispielsweise werden Berichte und Diagramme daraus generiert, aggregierte Pr√ºfungen werden darauf aufgebaut, Trigger h√§ngen von ihnen ab.  Wenn der Zugriff auf den Verlauf verz√∂gert wird, wirkt sich dies sofort auf die Geschwindigkeit des gesamten Systems aus. <br><br>  Drittens nehmen historische Daten viel Platz ein.  Selbst relativ bescheidene √úberwachungskonfigurationen erhalten sehr schnell eine solide Geschichte.  Da jedoch kaum jemand den Ladeverlauf des f√ºnf Jahre alten Prozessors zur Hand haben m√∂chte, sollte das √úberwachungssystem in der Lage sein, den Verlauf nicht nur gut aufzuzeichnen, sondern auch gut zu l√∂schen (in Zabbix wird dieser Vorgang als ‚ÄûHousekeeping‚Äú bezeichnet).  Das L√∂schen alter Daten muss nicht so effizient sein wie das Sammeln und Analysieren neuer Daten. Schwere L√∂schvorg√§nge beanspruchen jedoch wertvolle DBMS-Ressourcen und k√∂nnen kritischere Vorg√§nge verlangsamen. <br><br>  Die ersten beiden Probleme werden durch Caching gel√∂st.  Zabbix unterst√ºtzt mehrere spezialisierte Caches, um das Lesen und Schreiben von Daten zu beschleunigen.  Die DBMS-Mechanismen selbst sind hier nicht geeignet, weil  Selbst der fortschrittlichste Allzweck-Caching-Algorithmus wei√ü nicht, welche Datenstrukturen zu einem bestimmten Zeitpunkt einen sofortigen Zugriff erfordern. <br><br><h4>  √úberwachungs- und Zeitreihendaten </h4><br>  Alles ist in Ordnung, solange sich die Daten im Speicher des Zabbix-Servers befinden.  Der Speicher ist jedoch nicht unendlich und irgendwann m√ºssen die Daten in die Datenbank geschrieben (oder gelesen) werden.  Und wenn die Datenbankleistung ernsthaft hinter der Geschwindigkeit der Erfassung von Metriken zur√ºckbleibt, helfen selbst die fortschrittlichsten speziellen Caching-Algorithmen lange Zeit nicht weiter. <br><br>  Das dritte Problem betrifft auch die Datenbankleistung.  Um dies zu l√∂sen, m√ºssen Sie eine zuverl√§ssige L√∂schstrategie ausw√§hlen, die andere Datenbankvorg√§nge nicht beeintr√§chtigt.  Standardm√§√üig l√∂scht Zabbix historische Daten in Stapeln von mehreren tausend Datens√§tzen pro Stunde.  Sie k√∂nnen l√§ngere Verwaltungsperioden oder gr√∂√üere Paketgr√∂√üen konfigurieren, wenn die Geschwindigkeit der Datenerfassung und der Platz in der Datenbank dies zulassen.  Bei einer sehr gro√üen Anzahl von Metriken und / oder einer hohen H√§ufigkeit ihrer Erfassung kann die ordnungsgem√§√üe Einrichtung der Verwaltung eine entmutigende Aufgabe sein, da ein Zeitplan f√ºr das L√∂schen von Daten m√∂glicherweise nicht mit dem Tempo der Aufzeichnung neuer Metriken Schritt h√§lt. <br><br>  Zusammenfassend l√§sst sich sagen, dass das √úberwachungssystem Leistungsprobleme in drei Richtungen l√∂st: Sammeln neuer Daten und Schreiben in die Datenbank mithilfe von SQL INSERT-Abfragen, Zugreifen auf Daten mithilfe von SELECT-Abfragen und L√∂schen von Daten mithilfe von DELETE.  Mal sehen, wie eine typische SQL-Abfrage ausgef√ºhrt wird: <br><br><ul><li>  Das DBMS analysiert die Abfrage und √ºberpr√ºft sie auf Syntaxfehler.  Wenn die Anforderung syntaktisch korrekt ist, erstellt die Engine einen Syntaxbaum zur weiteren Verarbeitung. </li><li>  Der Abfrageplaner analysiert den Syntaxbaum und berechnet die verschiedenen Wege (Pfade) zur Ausf√ºhrung der Anforderung. </li><li>  Der Scheduler berechnet den g√ºnstigsten Weg.  Dabei werden viele Dinge ber√ºcksichtigt - wie gro√ü sind die Tabellen, m√ºssen die Ergebnisse sortiert werden, gibt es Indizes f√ºr die Abfrage usw. </li><li>  Wenn der optimale Pfad gefunden wurde, f√ºhrt die Engine die Abfrage aus, indem sie auf die gew√ºnschten Datenbl√∂cke zugreift (mithilfe von Indizes oder sequentiellem Scannen), die Sortier- und Filterkriterien anwendet, das Ergebnis sammelt und an den Client zur√ºckgibt. </li><li>  Zum Einf√ºgen, √Ñndern und L√∂schen von Abfragen muss die Engine auch die Indizes f√ºr die entsprechenden Tabellen aktualisieren.  Bei gro√üen Tabellen kann dieser Vorgang l√§nger dauern als das Arbeiten mit den Daten selbst. </li><li>  H√∂chstwahrscheinlich aktualisiert das DBMS auch die internen Statistiken zur Datennutzung f√ºr nachfolgende Aufrufe des Abfrageplaners. </li></ul><br>  Im Allgemeinen gibt es viel Arbeit.  Die meisten DBMS bieten eine Vielzahl von Einstellungen f√ºr die Abfrageoptimierung, konzentrieren sich jedoch normalerweise auf einige durchschnittliche Workflows, in denen das Einf√ºgen und L√∂schen von Datens√§tzen ungef√§hr mit der gleichen H√§ufigkeit wie die √Ñnderung erfolgt. <br><br>  Wie oben erw√§hnt, sind f√ºr √úberwachungssysteme die typischsten Vorg√§nge das Hinzuf√ºgen und periodische L√∂schen im Stapelmodus.  Das √Ñndern zuvor hinzugef√ºgter Daten erfolgt fast nie, und der Zugriff auf die Daten erfordert die Verwendung aggregierter Funktionen.  Au√üerdem werden die Werte der hinzugef√ºgten Metriken normalerweise nach Zeit geordnet.  Solche Daten werden √ºblicherweise als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zeitreihen bezeichnet</a> : <br><br><blockquote>  Zeitreihen sind eine Reihe von Datenpunkten, die in einer tempor√§ren Reihenfolge indiziert (oder aufgelistet oder graffiti) sind. </blockquote><br><br>  Aus Sicht der Datenbank haben Zeitreihen die folgenden Eigenschaften: <br><br><ul><li>  Zeitreihen k√∂nnen als Folge von zeitlich geordneten Bl√∂cken auf einer Festplatte gespeichert werden. </li><li>  Zeitreihentabellen k√∂nnen mithilfe einer Zeitspalte indiziert werden. </li><li>  Die meisten SQL SELECT-Abfragen verwenden WHERE-, GROUP BY- oder ORDER BY-Klauseln in einer Zeitangabespalte. </li><li>  In der Regel haben Zeitreihendaten ein ‚ÄûAblaufdatum‚Äú, nach dem sie gel√∂scht werden k√∂nnen. </li></ul><br>  Offensichtlich sind herk√∂mmliche SQL-Datenbanken nicht zum Speichern solcher Daten geeignet, da Allzweckoptimierungen diese Eigenschaften nicht ber√ºcksichtigen.  Daher sind in den letzten Jahren einige neue, zeitorientierte DBMS aufgetaucht, wie beispielsweise InfluxDB.  Alle g√§ngigen DBMS f√ºr Zeitreihen haben jedoch einen wesentlichen Nachteil: das Fehlen einer vollst√§ndigen SQL-Unterst√ºtzung.  Dar√ºber hinaus sind die meisten von ihnen nicht einmal CRUD (Erstellen, Lesen, Aktualisieren, L√∂schen). <br><br>  Kann Zabbix diese DBMS auf irgendeine Weise verwenden?  Einer der m√∂glichen Ans√§tze besteht darin, historische Daten zur Speicherung in eine externe Datenbank zu √ºbertragen, die auf Zeitreihen spezialisiert ist.  Da die Zabbix-Architektur externe Backends zum Speichern historischer Daten unterst√ºtzt (z. B. unterst√ºtzt Zabbix Elasticsearch), erscheint diese Option auf den ersten Blick sehr sinnvoll.  Wenn wir jedoch ein oder mehrere DBMS f√ºr Zeitreihen als externe Server unterst√ºtzen w√ºrden, m√ºssten Benutzer mit folgenden Punkten rechnen: <br><br><ul><li>  Ein weiteres System, das untersucht, konfiguriert und gewartet werden muss.  Ein weiterer Ort, um Einstellungen, Speicherplatz, Speicherrichtlinien, Leistung usw. zu verfolgen. </li><li>  Reduzierung der Fehlertoleranz des √úberwachungssystems, z  In der Kette der zugeh√∂rigen Komponenten wird ein neues Glied angezeigt. </li></ul><br>  F√ºr einige Benutzer √ºberwiegen die Vorteile eines dedizierten dedizierten Speichers f√ºr historische Daten m√∂glicherweise die Unannehmlichkeiten, sich um ein anderes System sorgen zu m√ºssen.  F√ºr viele ist dies jedoch eine unn√∂tige Komplikation.  Es ist auch zu beachten, dass die Komplexit√§t der universellen Schicht f√ºr die Arbeit mit Zabbix-Datenbanken deutlich zunehmen wird, da die meisten dieser spezialisierten L√∂sungen √ºber eigene APIs verf√ºgen.  Und im Idealfall ziehen wir es vor, neue Funktionen zu erstellen, anstatt gegen andere APIs zu k√§mpfen. <br><br>  Es stellt sich die Frage, ob es eine M√∂glichkeit gibt, das DBMS f√ºr Zeitreihen zu nutzen, ohne jedoch die Flexibilit√§t und die Vorteile von SQL zu verlieren.  Nat√ºrlich gibt es keine universelle Antwort, aber eine bestimmte L√∂sung kam der Antwort sehr nahe - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TimescaleDB</a> . <br><br><h4>  Was ist TimescaleDB? </h4><br>  TimescaleDB (TSDB) ist eine PostgreSQL-Erweiterung, die die Arbeit mit Zeitreihen in einer regul√§ren PostgreSQL (PG) -Datenbank optimiert.  Obwohl es, wie oben erw√§hnt, keinen Mangel an gut skalierbaren Zeitreihenl√∂sungen auf dem Markt gibt, ist ein einzigartiges Merkmal von TimescaleDB die F√§higkeit, gut mit Zeitreihen zu arbeiten, ohne die Kompatibilit√§t und die Vorteile traditioneller relationaler CRUD-Datenbanken zu beeintr√§chtigen.  In der Praxis bedeutet dies, dass wir das Beste aus beiden Welten bekommen.  Die Datenbank wei√ü, welche Tabellen als Zeitreihen betrachtet werden sollten (und wendet alle erforderlichen Optimierungen an), aber Sie k√∂nnen mit ihnen auf die gleiche Weise wie mit regul√§ren Tabellen arbeiten.  Dar√ºber hinaus m√ºssen Anwendungen nicht wissen, dass die Daten von TSDB gesteuert werden! <br><br>  Um eine Tabelle als Zeitreihentabelle zu markieren (in TSDB wird dies als Hypertabelle bezeichnet), rufen Sie einfach die TSDB-Prozedur create_ hypertable () auf.  Unter der Haube unterteilt TSDB diese Tabelle unter bestimmten Bedingungen in sogenannte Fragmente (der englische Begriff ist Chunk).  Fragmente k√∂nnen als automatisch gesteuerte Abschnitte einer Tabelle dargestellt werden.  Jedes Fragment hat einen entsprechenden Zeitbereich.  F√ºr jedes Fragment legt die TSDB au√üerdem spezielle Indizes fest, sodass die Arbeit mit einem Datenbereich den Zugriff auf andere nicht beeintr√§chtigt. <br><br><img src="https://habrastorage.org/webt/qu/d0/9s/qud09swu7nrhn2e6d6thqhfbgjw.png" alt="Bild"><br><br><oembed>  Hypertabellenbild von timescaledb.com </oembed><br>  Wenn die Anwendung einen neuen Wert f√ºr die Zeitreihe hinzuf√ºgt, leitet die Erweiterung diesen Wert an das gew√ºnschte Fragment weiter.  Wenn der Bereich f√ºr die Zeit des neuen Werts nicht definiert ist, erstellt TSDB ein neues Fragment, weist ihm den gew√ºnschten Bereich zu und f√ºgt dort den Wert ein.  Wenn eine Anwendung Daten von einer Hypertabelle anfordert, pr√ºft die Erweiterung vor dem Ausf√ºhren der Anforderung, welche Fragmente dieser Anforderung zugeordnet sind. <br><br>  Das ist aber noch nicht alles.  TSDB erg√§nzt das robuste und bew√§hrte PostgreSQL-√ñkosystem mit einer Vielzahl von Leistungs- und Skalierbarkeits√§nderungen.  Dazu geh√∂ren das schnelle Hinzuf√ºgen neuer Datens√§tze, schnelle Zeitabfragen und praktisch kostenlose Stapell√∂schungen. <br><br>  Wie bereits erw√§hnt, sollte eine gute √úberwachungsl√∂sung eine gro√üe Menge historischer Daten effektiv l√∂schen, um die Gr√∂√üe der Datenbank zu steuern und die Aufbewahrungsrichtlinien einzuhalten (d. H. Daten nicht l√§nger als erforderlich zu speichern).  Mit TSDB k√∂nnen wir die gew√ºnschte Story einfach l√∂schen, indem wir bestimmte Fragmente aus der Hypertabelle l√∂schen.  In diesem Fall muss die Anwendung keine Fragmente nach Namen oder anderen Links verfolgen. TSDB l√∂scht alle erforderlichen Fragmente gem√§√ü der angegebenen Zeitbedingung. <br><br><h4>  TimescaleDB- und PostgreSQL-Partitionierung </h4><br>  Auf den ersten Blick scheint TSDB ein guter Wrapper f√ºr die Standardpartitionierung von PG-Tabellen zu sein ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">deklarative Partitionierung</a> , wie sie in PG10 offiziell genannt wird).  Zum Speichern historischer Daten k√∂nnen Sie die Standardpartitionierung PG10 verwenden.  Wenn Sie genau hinschauen, sind die Fragmente der TSDB und des PG10-Abschnitts alles andere als identische Konzepte. <br><br>  Das Einrichten der Partitionierung in PG erfordert zun√§chst ein tieferes Verst√§ndnis der Details, die die Anwendung selbst oder das DBMS auf gute Weise ausf√ºhren sollten.  Zun√§chst m√ºssen Sie Ihre Abschnittshierarchie planen und entscheiden, ob verschachtelte Partitionen verwendet werden sollen.  Zweitens m√ºssen Sie ein Abschnittsbenennungsschema erstellen und es irgendwie in die Skripte zum Erstellen des Schemas √ºbertragen.  H√∂chstwahrscheinlich enth√§lt das Benennungsschema Datum und / oder Uhrzeit, und solche Namen m√ºssen irgendwie automatisiert werden. <br><br>  Als n√§chstes m√ºssen Sie dar√ºber nachdenken, wie abgelaufene Daten gel√∂scht werden.  In der TSDB k√∂nnen Sie einfach den Befehl drop_chunks () aufrufen, der die Fragmente festlegt, die f√ºr einen bestimmten Zeitraum gel√∂scht werden sollen.  Wenn Sie in PG10 einen bestimmten Wertebereich aus Standard-PG-Abschnitten entfernen m√ºssen, m√ºssen Sie die Liste der Abschnittsnamen f√ºr diesen Bereich selbst berechnen.  Wenn das ausgew√§hlte Partitionierungsschema verschachtelte Abschnitte umfasst, erschwert dies das L√∂schen weiter. <br><br>  Ein weiteres Problem, das angegangen werden muss, ist die Vorgehensweise bei Daten, die √ºber die aktuellen Zeitbereiche hinausgehen.  Beispielsweise k√∂nnen Daten aus einer Zukunft stammen, f√ºr die noch keine Abschnitte erstellt wurden.  Oder aus der Vergangenheit f√ºr bereits gel√∂schte Abschnitte.  Standardm√§√üig funktioniert das Hinzuf√ºgen eines solchen Datensatzes in PG10 nicht und wir verlieren einfach die Daten.  In PG11 k√∂nnen Sie einen Standardabschnitt f√ºr solche Daten definieren, der das Problem jedoch nur vor√ºbergehend maskiert und nicht l√∂st. <br><br>  Nat√ºrlich k√∂nnen alle oben genannten Probleme auf die eine oder andere Weise gel√∂st werden.  Sie k√∂nnen die Basis mit Triggern, Cron-Jabs aufh√§ngen und gro√üz√ºgig mit Skripten bestreuen.  Es wird h√§sslich, aber funktional sein.  Es besteht kein Zweifel, dass PG-Abschnitte besser sind als riesige monolithische Tabellen, aber was definitiv nicht durch Skripte und Trigger gel√∂st wird, sind Zeitreihenverbesserungen, die PG nicht hat. <br><br>  Das hei√üt,  Im Vergleich zu PG-Abschnitten zeichnen sich die TSDB-Hypertabellen nicht nur dadurch aus, dass sie die Nerven der DB-Administratoren schonen, sondern auch den Zugriff auf Daten optimieren und neue hinzuf√ºgen.  Beispielsweise sind Fragmente in TSDB immer ein eindimensionales Array.  Dies vereinfacht die Fragmentverwaltung und beschleunigt Einf√ºgungen und Auswahlen.  Um neue Daten hinzuzuf√ºgen, verwendet TSDB einen eigenen Routing-Algorithmus im gew√ºnschten Fragment, der im Gegensatz zum Standard-PG nicht alle Abschnitte sofort √∂ffnet.  Bei einer gro√üen Anzahl von Abschnitten kann der Leistungsunterschied erheblich variieren.  Technische Details zum Unterschied zwischen Standardpartitionierung in PG und TSDB finden Sie in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Artikel</a> . <br><br><h4>  Zabbix und TimescaleDB </h4><br>  Von allen Optionen scheint TimescaleDB die sicherste Wahl f√ºr Zabbix und seine Benutzer zu sein: <br><br><ul><li>  TSDB ist als PostgreSQL-Erweiterung und nicht als eigenst√§ndiges System konzipiert.  Daher sind keine zus√§tzliche Hardware, virtuelle Maschinen oder andere √Ñnderungen in der Infrastruktur erforderlich.  Benutzer k√∂nnen ihre ausgew√§hlten Tools weiterhin f√ºr PostgreSQL verwenden. </li><li>  Mit TSDB k√∂nnen Sie fast den gesamten Code f√ºr die Arbeit mit der Datenbank in Zabbix unver√§ndert speichern. </li><li>  TSDB verbessert die Leistung von History Syncer und Housekeeper erheblich. </li><li>  Niedrige Eintrittsschwelle - Die Grundkonzepte der TSDB sind einfach und unkompliziert. </li><li>  Die einfache Installation und Konfiguration sowohl der Erweiterung selbst als auch von Zabbix hilft Benutzern kleiner und mittlerer Systeme erheblich. </li></ul><br>  Mal sehen, was getan werden muss, um TSDB mit einem frisch installierten Zabbix zu starten.  Nach der Installation von Zabbix und dem Ausf√ºhren von PostgreSQL-Datenbankerstellungsskripten m√ºssen Sie TSDB herunterladen und auf der gew√ºnschten Plattform installieren.  Siehe Installationsanweisungen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .  Nach der Installation der Erweiterung m√ºssen Sie sie f√ºr die Zabbix-Basis aktivieren und dann das mit Zabbix gelieferte Skript timecaledb.sql ausf√ºhren.  Es befindet sich entweder in der Datenbank / postgresql / timecaledb.sql, wenn die Installation aus dem Quellcode stammt, oder in /usr/share/zabbix/database/timecaledb.sql.gz, wenn die Installation aus Paketen stammt.  Das ist alles!  Jetzt k√∂nnen Sie den Zabbix-Server starten und er funktioniert mit TSDB. <br><br>  Das Skript timescaledb.sql ist trivial.  Er konvertiert lediglich die regul√§ren Zabbix-Verlaufstabellen in TSDB-Hypertabellen und √§ndert die Standardeinstellungen. Legt die Parameter Artikelverlaufszeitraum √ºberschreiben und Artikeltrendzeitraum √ºberschreiben fest.  Jetzt (Version 4.2) arbeiten die folgenden Zabbix-Tabellen unter TSDB-Kontrolle: history, history_uint, history_str, history_log, history_text, Trends und Trends_uint.  Das gleiche Skript kann zum Migrieren dieser Tabellen verwendet werden (beachten Sie, dass der Parameter migrate_data auf true festgelegt ist).  Es muss ber√ºcksichtigt werden, dass die Datenmigration ein sehr langer Prozess ist und mehrere Stunden dauern kann. <br><br>  Der Parameter chunk_time_interval =&gt; 86400 erfordert m√∂glicherweise auch √Ñnderungen, bevor timecaledb.sql ausgef√ºhrt wird. Chunk_time_interval ist das Intervall, das die Zeit begrenzt, in der Werte in dieses Fragment fallen.  Wenn Sie beispielsweise das Intervall chunk_time_interval auf 3 Stunden festlegen, werden die Daten f√ºr den gesamten Tag auf 8 Fragmente verteilt, wobei das erste Fragment Nr. 1 die ersten 3 Stunden (0: 00-2: 59), das zweite Fragment Nr. 2 die zweiten 3 Stunden ( 3: 00-5: 59) usw.  Das letzte Fragment Nr. 8 enth√§lt Werte mit einer Zeit von 21: 00-23: 59.  86400 Sekunden (1 Tag) ist der durchschnittliche Standardwert, aber Benutzer geladener Systeme m√∂chten ihn m√∂glicherweise reduzieren. <br><br>  Um den Speicherbedarf grob abzusch√§tzen, ist es wichtig zu verstehen, wie viel Platz ein Durchschnitt pro St√ºck einnehmen kann.  Das allgemeine Prinzip ist, dass das System √ºber gen√ºgend Speicher verf√ºgen muss, um mindestens ein Fragment aus jeder Hypertabelle anzuordnen.  In diesem Fall sollte die Summe der Fragmentgr√∂√üen nat√ºrlich nicht nur mit einem Rand in den Speicher passen, sondern auch kleiner sein als der Wert des Parameters shared_buffers aus postgresql.conf.  Weitere Informationen zu diesem Thema finden Sie in der TimescaleDB-Dokumentation. <br><br>  Wenn Sie beispielsweise √ºber ein System verf√ºgen, das haupts√§chlich ganzzahlige Metriken erfasst, und die Tabelle history_uint in 2-Stunden-Fragmente aufteilen und den Rest der Tabellen in eint√§gige Fragmente aufteilen m√∂chten, m√ºssen Sie diese Zeile in timecaledb.sql √§ndern: <br><br><pre><code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_uint'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">7200</span></span>, migrate_data =&gt; <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>);</code> </pre> <br>  Nachdem sich eine bestimmte Menge historischer Daten angesammelt hat, k√∂nnen Sie die Fragmentgr√∂√üen f√ºr die Tabelle history_uint √ºberpr√ºfen, indem Sie chunk_relation_size () aufrufen: <br><br><pre> <code class="plaintext hljs">zabbix=&gt; SELECT chunk_table,total_bytes FROM chunk_relation_size('history_uint');              chunk_table               | total_bytes -----------------------------------------+------------- _timescaledb_internal._hyper_2_6_chunk  |    13287424 _timescaledb_internal._hyper_2_7_chunk  |    13172736 _timescaledb_internal._hyper_2_8_chunk  |    13344768 _timescaledb_internal._hyper_2_9_chunk  |    13434880 _timescaledb_internal._hyper_2_10_chunk |    13230080 _timescaledb_internal._hyper_2_11_chunk |    13189120</code> </pre> <br>  Dieser Aufruf kann wiederholt werden, um die Fragmentgr√∂√üen f√ºr alle Hypertabellen zu ermitteln.  Wenn beispielsweise festgestellt wurde, dass die Fragmentgr√∂√üe von history_uint 13 MB betr√§gt, die Fragmente f√ºr andere Verlaufstabellen beispielsweise 20 MB und f√ºr Trendtabellen 10 MB, betr√§gt der Gesamtspeicherbedarf 13 + 4 x 20 + 2 x 10 = 113 MB.  Wir m√ºssen auch Speicherplatz von shared_buffers lassen, um andere Daten zu speichern, beispielsweise 20%.  Dann muss der Wert von shared_buffers auf 113 MB / 0,8 = ~ 140 MB gesetzt werden. <br><br>  F√ºr eine feinere Abstimmung von TSDB wurde k√ºrzlich das Dienstprogramm timescaledb-tune ver√∂ffentlicht.  Es analysiert postgresql.conf, korreliert es mit der Systemkonfiguration (Speicher und Prozessor) und gibt dann Empfehlungen zum Einstellen von Speicherparametern, Parametern f√ºr die Parallelverarbeitung, WAL.  Das Dienstprogramm √§ndert die Datei postgresql.conf. Sie k√∂nnen sie jedoch mit dem Parameter -dry-run ausf√ºhren und die vorgeschlagenen √Ñnderungen √ºberpr√ºfen. <br><br>  Wir werden uns mit den Zabbix-Parametern befassen. Artikelverlaufszeitraum √ºberschreiben und Artikeltrendzeitraum √ºberschreiben (verf√ºgbar unter Administration -&gt; Allgemein -&gt; Haushalt).  Sie werden ben√∂tigt, um historische Daten als ganze Fragmente von TSDB-Hypertabellen und nicht als Datens√§tze zu l√∂schen. <br><br>  Tatsache ist, dass Sie mit Zabbix den Reinigungszeitraum f√ºr jedes Datenelement (Metrik) einzeln festlegen k√∂nnen.  Diese Flexibilit√§t wird jedoch erreicht, indem die Liste der Elemente gescannt und einzelne Perioden in jeder Iteration der Haushaltsf√ºhrung berechnet werden.  Wenn das System individuelle Verwaltungsperioden f√ºr einzelne Elemente hat, kann das System offensichtlich nicht f√ºr alle Metriken zusammen einen einzigen Grenzwert haben, und Zabbix kann nicht den richtigen Befehl zum L√∂schen der erforderlichen Fragmente geben.  Durch Deaktivieren des √úberschreibungsverlaufs f√ºr Metriken verliert Zabbix die M√∂glichkeit, den Verlauf durch Aufrufen der drop_chunks () -Prozedur f√ºr history_ * -Tabellen schnell zu l√∂schen. Wenn Sie also Override-Trends deaktivieren, verlieren Sie dieselbe Funktion f√ºr Trends_ * -Tabellen. <br><br>  Mit anderen Worten, um das neue Housekeeping-System optimal nutzen zu k√∂nnen, m√ºssen Sie beide Optionen global gestalten.  In diesem Fall liest der Reinigungsprozess die Einstellungen der Datenelemente √ºberhaupt nicht. <br><br><h4>  Leistung mit TimescaleDB </h4><br>  Es ist Zeit zu pr√ºfen, ob all das in der Praxis wirklich funktioniert.  Unser Pr√ºfstand ist Zabbix 4.2rc1 mit PostgreSQL 10.7 und TimescaleDB 1.2.1 f√ºr Debian 9. Die Testmaschine ist ein 10-Kern-Intel Xeon mit 16 GB RAM und 60 GB Speicherplatz auf der SSD.  Nach heutigen Ma√üst√§ben ist dies eine sehr bescheidene Konfiguration, aber unser Ziel ist es herauszufinden, wie effektiv TSDB im wirklichen Leben ist.  In Konfigurationen mit unbegrenztem Budget k√∂nnen Sie einfach 128-256 GB RAM einf√ºgen und den gr√∂√üten Teil (wenn nicht den gesamten) der Datenbank in den Speicher stellen. <br><br>  Unsere Testkonfiguration besteht aus 32 aktiven Zabbix-Agenten, die Daten direkt an den Zabbix-Server √ºbertragen.  Jeder Agent bedient 10.000 Artikel.  Der historische Zabbix-Cache ist auf 256 MB und das PG f√ºr gemeinsam genutzte Puffer auf 2 GB festgelegt.  Diese Konfiguration bietet eine ausreichende Auslastung der Datenbank, verursacht jedoch gleichzeitig keine gro√üe Auslastung der Zabbix-Serverprozesse.  Um die Anzahl der beweglichen Teile zwischen den Datenquellen und der Datenbank zu verringern, haben wir Zabbix Proxy nicht verwendet. <br><br>  Hier ist das erste Ergebnis des Standard-PG-Systems: <br><br><img src="https://habrastorage.org/webt/hm/wj/rp/hmwjrp03sittv-f7ay9swag5z5y.png" alt="Bild"><br><br>  Das Ergebnis der TSDB ist v√∂llig anders: <br><br><img src="https://habrastorage.org/webt/0-/75/r-/0-75r-lgjnjbwty1wnoniq7az4k.png" alt="Bild"><br><br>  Die folgende Grafik kombiniert beide Ergebnisse.  Die Arbeit beginnt mit ziemlich hohen NVPS-Werten in 170-200K, weil  Es dauert einige Zeit, bis der Verlaufscache gef√ºllt ist, bevor die Synchronisierung mit der Datenbank beginnt. <br><br><img src="https://habrastorage.org/webt/qm/ro/p9/qmrop9da6tqvsdlbmaoe00jixxy.png" alt="Bild"><br><br>  Wenn die Verlaufstabelle leer ist, ist die Schreibgeschwindigkeit in TSDB mit der Schreibgeschwindigkeit in PG vergleichbar, und dies sogar mit einem kleinen Rand davon.  Sobald die Anzahl der Datens√§tze in der Geschichte 50-60 Millionen erreicht, sinkt der Durchsatz von PG auf 110.000 NVPS. Was jedoch unangenehmer ist, er √§ndert sich weiterhin umgekehrt mit der Anzahl der in der historischen Tabelle gesammelten Datens√§tze.  Gleichzeitig beh√§lt TSDB w√§hrend des gesamten Tests eine stabile Geschwindigkeit von 130 KB NVPS von 0 bis 300 Millionen Datens√§tzen bei. <br><br>  Insgesamt ist in unserem Beispiel der Unterschied in der durchschnittlichen Leistung ziemlich signifikant (130 K gegen√ºber 90 K ohne Ber√ºcksichtigung des anf√§nglichen Peaks).  Es ist auch ersichtlich, dass die Insertionsrate in Standard-PG √ºber einen weiten Bereich variiert.  Wenn f√ºr einen Workflow das Speichern von Dutzenden oder Hunderten von Millionen Datens√§tzen in der Historie erforderlich ist, jedoch keine Ressourcen f√ºr sehr aggressive Caching-Strategien vorhanden sind, ist TSDB ein starker Kandidat f√ºr das Ersetzen des Standard-PG. <br><br>  Der Vorteil von TSDB ist f√ºr dieses relativ bescheidene System bereits offensichtlich, aber h√∂chstwahrscheinlich wird der Unterschied bei gro√üen Arrays historischer Daten noch deutlicher.  Andererseits ist dieser Test keineswegs eine Verallgemeinerung aller m√∂glichen Szenarien der Arbeit mit Zabbix.  Nat√ºrlich gibt es viele Faktoren, die die Ergebnisse beeinflussen, wie z. B. Hardwarekonfigurationen, Betriebssystemeinstellungen, Zabbix-Servereinstellungen und zus√§tzliche Auslastung durch andere im Hintergrund ausgef√ºhrte Dienste.  Das hei√üt, Ihr Kilometerstand kann variieren. <br><br><h4>  Fazit </h4><br>  TimescaleDB ist eine vielversprechende Technologie.  Es wurde bereits erfolgreich in ernsthaften Produktionsumgebungen betrieben.  TSDB funktioniert gut mit Zabbix und bietet erhebliche Vorteile gegen√ºber der Standard-PostgreSQL-Datenbank. <br><br>  Hat TSDB irgendwelche M√§ngel oder Gr√ºnde, die Verwendung zu verschieben?  Aus technischer Sicht sehen wir keine Argumente dagegen.  Es sollte jedoch ber√ºcksichtigt werden, dass die Technologie noch neu ist, mit einem instabilen Ver√∂ffentlichungszyklus und einer unklaren Strategie f√ºr die Entwicklung von Funktionen.  Insbesondere werden alle ein oder zwei Monate neue Versionen mit wesentlichen √Ñnderungen ver√∂ffentlicht.  Einige Funktionen k√∂nnen entfernt werden, wie dies beispielsweise beim adaptiven Chunking der Fall ist.  Als weiterer Unsicherheitsfaktor ist die Lizenzpolitik zu erw√§hnen.  Es ist sehr verwirrend, da es drei Lizenzierungsstufen gibt.  Der TSDB-Kernel wird unter der Apache-Lizenz erstellt, einige Funktionen werden unter ihrer eigenen Timescale-Lizenz ver√∂ffentlicht, es gibt jedoch auch eine geschlossene Version von Enterprise. <br><br>  Wenn Sie Zabbix mit PostgreSQL verwenden, gibt es keinen Grund, TimescaleDB zumindest nicht auszuprobieren.  Vielleicht wird Sie dieses Ding angenehm √ºberraschen :) Denken Sie daran, dass die Unterst√ºtzung f√ºr TimescaleDB in Zabbix noch experimentell ist - vorerst sammeln wir Nutzerkritiken und sammeln Erfahrungen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458530/">https://habr.com/ru/post/de458530/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458514/index.html">Verst√∂√üe gegen die DSGVO werden aktiver bestraft - neue Bu√ügelder und die Auswirkungen von Vorschriften au√üerhalb der EU</a></li>
<li><a href="../de458516/index.html">Holen Sie sich ein Arbeitsprotokoll von Jira</a></li>
<li><a href="../de458518/index.html">Python verbraucht viel Speicher oder wie kann die Gr√∂√üe von Objekten reduziert werden?</a></li>
<li><a href="../de458520/index.html">Das Buch "Hochleistungscode auf der .NET-Plattform. 2. Auflage</a></li>
<li><a href="../de458524/index.html">VC Wortwolke am Knie</a></li>
<li><a href="../de458532/index.html">Pioniere neuer Technologien: Vadim Artsev erz√§hlte, wie er aufh√∂rte, blind zu sein</a></li>
<li><a href="../de458536/index.html">Python + Pyside2 oder einfach "Rechner"</a></li>
<li><a href="../de458546/index.html">Automation Day oder wie wir die Ebene der Autotests aufbauen</a></li>
<li><a href="../de458548/index.html">Erstellen Sie mit Dynamic Proxy und Spring IoC Ihre eigene Spring Data Repository-Stilbibliothek</a></li>
<li><a href="../de458550/index.html">Symbole GOST-Bibliothek f√ºr DipTrace</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§±üèø üì£ üîµ Wie wir gelernt haben, Java in Docker auszunutzen üóØÔ∏è üëÅÔ∏è üë¶üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Unter der Haube enth√§lt hh.ru eine gro√üe Anzahl von Java-Diensten, die in Docker-Containern ausgef√ºhrt werden. W√§hrend ihres Betriebs stie√üen wir auf ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir gelernt haben, Java in Docker auszunutzen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/hh/blog/450954/">  Unter der Haube enth√§lt hh.ru eine gro√üe Anzahl von Java-Diensten, die in Docker-Containern ausgef√ºhrt werden.  W√§hrend ihres Betriebs stie√üen wir auf viele nicht triviale Probleme.  In vielen F√§llen musste ich lange googeln, die OpenJDK-Quellen lesen und sogar die Services in der Produktion profilieren, um der L√∂sung auf den Grund zu gehen.  In diesem Artikel werde ich versuchen, die Quintessenz des dabei gewonnenen Wissens zu vermitteln. <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CPU-Grenzen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Docker- und Serverklassenmaschine</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CPU-Limits (ja, wieder) und Speicherfragmentierung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wir verarbeiten Java-OOM</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Speicherverbrauch optimieren</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Begrenzung des Speicherverbrauchs: Heap, Nicht-Heap, direkter Speicher</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Begrenzung des Speicherverbrauchs: Native Memory Tracking</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Java und Laufwerke</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wie kann man alles im Auge behalten?</a> </li></ul><br><a name="habracut"></a><a name="cpu"></a><h4>  CPU-Grenzen </h4><br>  Fr√ºher lebten wir in virtuellen kvm-Maschinen mit CPU- und Speicherbeschr√§nkungen und legten bei der Umstellung auf Docker √§hnliche Einschr√§nkungen in cgroups fest.  Und das erste Problem, auf das wir stie√üen, waren genau die CPU-Grenzwerte.  Ich muss sofort sagen, dass dieses Problem f√ºr neuere Versionen von Java 8 und Java ‚â• 10 nicht mehr relevant ist. Wenn Sie mit der Zeit gehen, k√∂nnen Sie diesen Abschnitt sicher √ºberspringen. <br><br>  Wir starten also einen kleinen Dienst im Container und stellen fest, dass er eine gro√üe Anzahl von Threads erzeugt.  Oder die CPU verbraucht viel mehr als erwartet, Timeout wie viel umsonst.  Oder hier ist eine andere reale Situation: Auf einem Computer startet der Dienst normal und auf einem anderen st√ºrzt er mit denselben Einstellungen ab, genagelt von einem OOM-Killer. <br><br>  Die L√∂sung stellt sich als sehr einfach heraus - nur Java sieht die im Docker festgelegten Einschr√§nkungen von <code>--cpus</code> nicht und glaubt, dass alle Kernel des Host-Computers f√ºr ihn zug√§nglich sind.  Und es kann viele davon geben (in unserem Standard-Setup - 80). <br>  Bibliotheken passen die Gr√∂√üe der Thread-Pools an die Anzahl der verf√ºgbaren Prozessoren an - daher die gro√üe Anzahl der Threads. <br>  Java selbst skaliert die Anzahl der GC-Threads auf die gleiche Weise, daher den CPU-Verbrauch und die Zeit√ºberschreitung. Der Dienst verwendet eine Menge Ressourcen f√ºr die Speicherbereinigung, wobei der L√∂wenanteil des ihm zugewiesenen Kontingents verwendet wird. <br>  Au√üerdem k√∂nnen Bibliotheken (insbesondere Netty) in bestimmten F√§llen die Gr√∂√üe des Off-Hip-Speichers an die Anzahl der CPUs anpassen, was zu einer hohen Wahrscheinlichkeit f√ºhrt, dass die f√ºr den Container festgelegten Grenzwerte √ºberschritten werden, wenn sie auf einer leistungsst√§rkeren Hardware ausgef√ºhrt werden. <br><br>  Als sich dieses Problem manifestierte, haben wir zun√§chst versucht, die folgenden Arbeitsrunden zu verwenden: <br>  - hat versucht, einige Dienste zu verwenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">libnumcpus</a> - eine Bibliothek, mit der Sie Java "betr√ºgen" k√∂nnen, indem Sie eine andere Anzahl verf√ºgbarer Prozessoren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">festlegen</a> ; <br>  - explizit die Anzahl der GC-Threads angegeben, <br>  - Setzen Sie explizit Grenzen f√ºr die Verwendung von Direktbytepuffern. <br><br>  Aber nat√ºrlich ist es nicht sehr bequem, sich mit solchen Kr√ºcken zu bewegen, und der Wechsel zu Java 10 (und dann zu Java 11), bei dem all diese Probleme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fehlen</a> , war eine echte L√∂sung.  Fairerweise ist es erw√§hnenswert, dass auch bei den Acht mit dem im Oktober 2018 ver√∂ffentlichten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Update 191</a> alles in Ordnung war.  Zu diesem Zeitpunkt war es f√ºr uns schon irrelevant, was ich auch f√ºr Sie w√ºnsche. <br><br>  Dies ist ein Beispiel, bei dem die Aktualisierung der Java-Version nicht nur moralische Befriedigung bietet, sondern auch einen sp√ºrbaren Gewinn in Form eines vereinfachten Betriebs und einer h√∂heren Serviceleistung. <br><br><a name="server-class"></a><h4>  Docker- und Serverklassenmaschine </h4><br>  In Java 10 wurden die <code>-XX:ActiveProcessorCount</code> und <code>-XX:+UseContainerSupport</code> (und auf Java 8 <code>-XX:+UseContainerSupport</code> ), wobei die Standardgrenzen f√ºr cgroups ber√ºcksichtigt wurden.  Jetzt war alles wunderbar.  Oder nicht? <br><br>  Einige Zeit nachdem wir zu Java 10/11 gewechselt waren, bemerkten wir einige Kuriosit√§ten.  Aus irgendeinem Grund sahen die GC-Grafiken in einigen Diensten so aus, als h√§tten sie G1 nicht verwendet: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gc/69/bo/gc69boghbrkf2wmxiuioszq5qgg.png"></div><br><br>  Dies war, gelinde gesagt, ein wenig unerwartet, da wir sicher wussten, dass G1 der Standardkollektor ist, beginnend mit Java 9. Gleichzeitig gibt es bei einigen Diensten kein solches Problem - G1 wird wie erwartet eingeschaltet. <br><br>  Wir beginnen eine <a href="">interessante Sache</a> zu verstehen und sto√üen darauf.  Es stellt sich heraus, dass Java, wenn es auf weniger als 3 Prozessoren und mit einem Speicherlimit von weniger als 2 GB ausgef√ºhrt wird, sich selbst als Client betrachtet und nichts anderes als SerialGC zul√§sst. <br><br>  Dies betrifft √ºbrigens nur die <a href="">Auswahl des GC</a> und hat nichts mit den Kompilierungsoptionen -client / -server und JIT zu tun. <br><br>  Als wir Java 8 verwendeten, wurden die Docker-Beschr√§nkungen offensichtlich nicht ber√ºcksichtigt und es wurde angenommen, dass es viele Prozessoren und Speicher hat.  Nach dem Upgrade auf Java 10 wurde SerialGC pl√∂tzlich von vielen Diensten mit niedrigeren Grenzwerten verwendet.  Gl√ºcklicherweise wird dies sehr einfach behandelt - indem die <code>-XX:+AlwaysActAsServerClassMachine</code> explizit <code>-XX:+AlwaysActAsServerClassMachine</code> . <br><br><a name="malloc"></a><h4>  CPU-Limits (ja, wieder) und Speicherfragmentierung </h4><br>  Bei Betrachtung der Diagramme bei der √úberwachung haben wir irgendwie festgestellt, dass die Resident-Set-Gr√∂√üe des Containers zu gro√ü ist - dreimal so viel wie die maximale H√ºftgr√∂√üe.  K√∂nnte dies bei einem n√§chsten kniffligen Mechanismus der Fall sein, der entsprechend der Anzahl der Prozessoren im System skaliert und die Einschr√§nkungen des Dockers nicht kennt? <br><br>  Es stellt sich heraus, dass der Mechanismus √ºberhaupt nicht schwierig ist - es ist das bekannte Malloc von glibc.  Kurz gesagt, glibc verwendet die sogenannten Arenen, um Speicher zuzuweisen.  Beim Erstellen wird jedem Thread eine der Arenen zugewiesen.  Wenn ein Thread, der glibc verwendet, eine bestimmte Menge an Speicher im nativen Heap seinen Anforderungen zuweisen m√∂chte und malloc aufruft, wird der Speicher in der ihm zugewiesenen Arena zugewiesen.  Wenn die Arena mehrere Threads bedient, konkurrieren diese Threads darum.  Je mehr Arenen, desto weniger Wettbewerb, aber desto mehr Fragmentierung, da jede Arena ihre eigene Liste von Freifl√§chen hat. <br><br>  Auf 64-Bit-Systemen ist die Standardanzahl der Arenen auf 8 * die Anzahl der CPUs festgelegt.  Dies ist nat√ºrlich ein enormer Aufwand f√ºr uns, da nicht alle CPUs f√ºr den Container verf√ºgbar sind.  Dar√ºber hinaus ist f√ºr Java-basierte Anwendungen der Wettbewerb um Arenen nicht so relevant, da die meisten Zuweisungen in Java-Heap erfolgen, dessen Speicher beim Start vollst√§ndig zugewiesen werden kann. <br><br>  Diese Funktion von malloc ist seit langem bekannt, ebenso wie seine L√∂sung - die Umgebungsvariable <code>MALLOC_ARENA_MAX</code> zu verwenden, um die Anzahl der Arenen explizit anzugeben.  Es ist sehr einfach f√ºr jeden Beh√§lter zu tun.  Hier ist der Effekt der Angabe von <code>MALLOC_ARENA_MAX = 4</code> f√ºr unser Haupt-Backend: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jk/zq/lo/jkzqlo_pqiu4xppzbe-itkjvviy.png"></div><br><br>  Das RSS-Diagramm enth√§lt zwei Instanzen: In einer (blau) <code>MALLOC_ARENA_MAX</code> wir <code>MALLOC_ARENA_MAX</code> , in der anderen (rot) starten wir gerade neu.  Der Unterschied ist offensichtlich. <br><br>  Danach besteht jedoch ein vern√ºnftiger Wunsch, herauszufinden, wof√ºr Java im Allgemeinen Speicher ausgibt.  Ist es m√∂glich, einen Microservice unter Java mit einem Speicherlimit von 300-400 Megabyte auszuf√ºhren und keine Angst zu haben, dass er von Java-OOM f√§llt oder nicht von einem System-OOM-Killer get√∂tet wird? <br><br><a name="oom"></a><h4>  Wir verarbeiten Java-OOM </h4><br>  Zun√§chst m√ºssen Sie sich darauf vorbereiten, dass OOMs unvermeidlich sind, und Sie m√ºssen sie richtig handhaben - zumindest H√ºftdumps sparen.  Seltsamerweise hat auch dieses einfache Unterfangen seine eigenen Nuancen.  Beispielsweise werden Hip-Dumps nicht √ºberschrieben. Wenn ein gleichnamiger Hip-Dump bereits gespeichert ist, wird einfach kein neuer erstellt. <br><br>  Java kann <a href="">die</a> Dump-Seriennummer und die Prozess-ID <a href="">automatisch</a> zum Dateinamen <a href="">hinzuf√ºgen</a> , dies hilft uns jedoch nicht weiter.  Die Seriennummer ist nicht n√ºtzlich, da dies OOM ist und nicht der regelm√§√üig angeforderte Hip-Dump. Die Anwendung wird danach neu gestartet und der Z√§hler zur√ºckgesetzt.  Und die Prozess-ID ist nicht geeignet, da sie im Docker immer dieselbe ist (meistens 1). <br><br>  Deshalb sind wir zu dieser Option gekommen: <br><br> <code>-XX:+HeapDumpOnOutOfMemoryError <br> -XX:+ExitOnOutOfMemoryError <br> -XX:HeapDumpPath=/var/crash/java.hprof <br> -XX:OnOutOfMemoryError="mv /var/crash/java.hprof /var/crash/heapdump.hprof"</code> <br> <br>  Es ist ganz einfach und mit einigen Verbesserungen k√∂nnen Sie sogar lehren, nicht nur den neuesten Hip-Dump zu speichern, sondern f√ºr unsere Bed√ºrfnisse ist dies mehr als genug. <br><br>  Java OOM ist nicht das einzige, was wir uns stellen m√ºssen.  Jeder Container hat eine Begrenzung des von ihm belegten Speichers und kann √ºberschritten werden.  In diesem Fall wird der Container vom System-OOM-Killer get√∂tet und neu <code>restart_policy: always</code> (wir verwenden <code>restart_policy: always</code> ).  Dies ist nat√ºrlich unerw√ºnscht, und wir m√∂chten lernen, wie Sie die von der JVM verwendeten Ressourcen korrekt einschr√§nken. <br><br><a name="opt-mem"></a><h4>  Speicherverbrauch optimieren </h4><br>  Bevor Sie jedoch Grenzwerte festlegen, m√ºssen Sie sicherstellen, dass die JVM keine Ressourcen verschwendet.  Wir haben es bereits geschafft, den Speicherverbrauch zu reduzieren, indem wir die Anzahl der CPUs und die Variable <code>MALLOC_ARENA_MAX</code> .  Gibt es andere "fast freie" M√∂glichkeiten, dies zu tun? <br><br>  Es stellt sich heraus, dass es noch ein paar Tricks gibt, die ein wenig Speicherplatz sparen. <br><br>  Die erste ist die Verwendung der <code>-XX:ThreadStackSize</code> <code>-Xss</code> (oder <code>-XX:ThreadStackSize</code> ), mit der die <code>-Xss</code> f√ºr Threads <code>-XX:ThreadStackSize</code> .  Der Standardwert f√ºr eine 64-Bit-JVM betr√§gt 1 MB.  Wir haben herausgefunden, dass 512 KB f√ºr uns ausreichen.  Aus diesem Grund wurde eine StackOverflowException noch nie abgefangen, aber ich gebe zu, dass dies nicht f√ºr jeden geeignet ist.  Und der Gewinn daraus ist sehr gering. <br><br>  Das zweite ist das <code>-XX:+UseStringDeduplication</code> (mit aktiviertem G1 GC).  Sie k√∂nnen Speicherplatz sparen, indem Sie doppelte Zeilen aufgrund zus√§tzlicher Prozessorlast reduzieren.  Der Kompromiss zwischen Speicher und CPU h√§ngt nur von der spezifischen Anwendung und den Einstellungen des Deduplizierungsmechanismus selbst ab.  Lesen Sie das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dock</a> und testen Sie in Ihren Diensten, wir haben diese Option hat ihre Anwendung noch nicht gefunden. <br><br>  Und schlie√ülich ist eine Methode, die nicht f√ºr jeden geeignet ist (aber zu uns passt), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jemalloc</a> anstelle des nativen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Malloc</a> zu verwenden.  Diese Implementierung zielt darauf ab, die Speicherfragmentierung und eine bessere Multithreading-Unterst√ºtzung im Vergleich zu malloc von glibc zu reduzieren.  F√ºr unsere Dienste hat jemalloc mit <code>MALLOC_ARENA_MAX=4</code> etwas mehr Speichergewinn <code>MALLOC_ARENA_MAX=4</code> als malloc, ohne die Leistung wesentlich zu beeintr√§chtigen. <br><br>  Andere Optionen, einschlie√ülich der von Alexei Shipilev in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JVM Anatomy Quark Nr. 12: Native Memory Tracking beschriebenen</a> , schienen ziemlich gef√§hrlich oder f√ºhrten zu einer sp√ºrbaren Verschlechterung der Leistung.  Aus p√§dagogischen Gr√ºnden empfehle ich jedoch, diesen Artikel zu lesen. <br><br>  Fahren Sie in der Zwischenzeit mit dem n√§chsten Thema fort und versuchen Sie schlie√ülich zu lernen, wie Sie den Speicherverbrauch begrenzen und die richtigen Grenzwerte ausw√§hlen. <br><br><a name="lim-mem-1"></a><h4>  Begrenzung des Speicherverbrauchs: Heap, Nicht-Heap, direkter Speicher </h4><br>  Um alles richtig zu machen, m√ºssen Sie sich daran erinnern, woraus Speicher in Java im Allgemeinen besteht.  Schauen wir uns zun√§chst die Pools an, deren Status √ºber JMX √ºberwacht werden kann. <br><br>  Das erste ist nat√ºrlich <b>hip</b> .  Es ist ganz einfach: Wir <code>-Xmx</code> , aber wie geht das richtig?  Leider gibt es hier kein universelles Rezept, alles h√§ngt von der Anwendung und dem Lastprofil ab.  F√ºr neue Dienste beginnen wir mit einer relativ vern√ºnftigen Heap-Gr√∂√üe (128 MB) und erh√∂hen oder verringern sie gegebenenfalls.  Um vorhandene zu unterst√ºtzen, gibt es eine √úberwachung mit Diagrammen des Speicherverbrauchs und der GC-Metriken. <br><br>  Gleichzeitig mit <code>-Xmx</code> wir <code>-Xms == -Xmx</code> .  Wir haben kein √úberverkaufen des Speichers, daher liegt es in unserem Interesse, dass der Service die Ressourcen, die wir ihm zur Verf√ºgung gestellt haben, maximal nutzt.  Dar√ºber hinaus enthalten wir in normalen Diensten <code>-XX:+AlwaysPreTouch</code> und den Mechanismus f√ºr transparente gro√üe Seiten: <code>-XX:+UseTransparentHugePages -XX:+UseLargePagesInMetaspace</code> .  Lesen Sie jedoch vor dem Aktivieren von THP die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> sorgf√§ltig durch und testen Sie, wie sich Dienste mit dieser Option lange Zeit verhalten.  √úberraschungen sind auf Maschinen mit unzureichendem RAM nicht ausgeschlossen (zum Beispiel mussten wir THP auf Pr√ºfst√§nden ausschalten). <br><br>  Als n√§chstes kommt <b>kein Haufen</b> .  Nicht-Heap-Speicher umfasst: <br>  - Metaspace und komprimierter Klassenraum, <br>  - Code-Cache. <br><br>  Betrachten Sie diese Pools der Reihe nach. <br><br>  Nat√ºrlich hat jeder von <b>Metaspace geh√∂rt</b> , ich werde nicht im Detail dar√ºber sprechen.  Es speichert Klassenmetadaten, Methodenbytecode usw.  Tats√§chlich h√§ngt die Verwendung von Metaspace direkt von der Anzahl und Gr√∂√üe der geladenen Klassen ab, und Sie k√∂nnen sie wie hip nur durch Starten der Anwendung und Entfernen der Metriken √ºber JMX bestimmen.  Standardm√§√üig ist Metaspace durch nichts eingeschr√§nkt, aber mit der <code>-XX:MaxMetaspaceSize</code> ist dies recht einfach. <br><br>  <b>Der komprimierte Klassenraum</b> ist Teil von Metaspace und wird angezeigt, wenn die Option <code>-XX:+UseCompressedClassPointers</code> aktiviert ist (standardm√§√üig f√ºr Heaps mit weniger als 32 GB aktiviert, <code>-XX:+UseCompressedClassPointers</code> wenn dadurch ein echter Speichergewinn erzielt werden kann).  Die Gr√∂√üe dieses Pools kann durch die Option <code>-XX:CompressedClassSpaceSize</code> begrenzt werden. <code>-XX:CompressedClassSpaceSize</code> ist jedoch wenig sinnvoll, da der komprimierte Klassenraum in Metaspace enthalten ist und die Gesamtmenge des gesperrten Speichers f√ºr Metaspace und den komprimierten Klassenraum letztendlich auf eine <code>-XX:MaxMetaspaceSize</code> . <br><br>  √úbrigens, wenn Sie sich die JMX-Messwerte ansehen, wird die Gr√∂√üe des Nicht-Heap-Speichers immer als die <a href="">Summe aus</a> Metaspace, komprimiertem Klassenraum und Code-Cache berechnet.  Tats√§chlich m√ºssen Sie nur Metaspace und CodeCache zusammenfassen. <br><br>  Im Nicht-Heap blieb also nur der <b>Code-Cache</b> √ºbrig - das vom JIT-Compiler kompilierte Code-Repository.  Standardm√§√üig ist die maximale Gr√∂√üe auf 240 MB festgelegt und f√ºr kleine Dienste um ein Vielfaches gr√∂√üer als erforderlich.  Die Gr√∂√üe des Code-Cache kann mit der Option <code>-XX:ReservedCodeCacheSize</code> .  Die richtige Gr√∂√üe kann nur ermittelt werden, indem die Anwendung ausgef√ºhrt und unter einem typischen Lastprofil verfolgt wird. <br><br>  Es ist wichtig, hier keinen Fehler zu machen, da unzureichender Code-Cache kalten und alten Code aus dem Cache l√∂scht (die <code>-XX:+UseCodeCacheFlushing</code> standardm√§√üig aktiviert), was wiederum zu einem h√∂heren CPU-Verbrauch und Leistungseinbu√üen f√ºhren kann .  Es w√§re gro√üartig, wenn Sie OOM ausl√∂sen k√∂nnten, wenn der Code-Cache √ºberl√§uft. Dazu gibt es sogar das <code>-XX:+ExitOnFullCodeCache</code> , das jedoch leider nur in der <a href="">Entwicklungsversion der</a> JVM verf√ºgbar ist. <br><br>  Der letzte Pool, √ºber den Informationen in JMX vorhanden sind, ist der <b>direkte Speicher</b> .  Standardm√§√üig ist seine Gr√∂√üe nicht begrenzt, daher ist es wichtig, eine bestimmte Grenze festzulegen - zumindest Bibliotheken wie Netty, die aktiv direkte Bytepuffer verwenden, werden davon geleitet.  Es ist nicht schwierig, mit dem <code>-XX:MaxDirectMemorySize</code> ein Limit <code>-XX:MaxDirectMemorySize</code> , und auch hier hilft uns nur die √úberwachung, den richtigen Wert zu ermitteln. <br><br>  Was bekommen wir also so weit? <br><br><pre>  Java-Prozessspeicher = 
     Heap + Metaspace + Code Cache + Direkter Speicher =
         -Xmx +
         -XX: MaxMetaspaceSize +
         -XX: ReservedCodeCacheSize +
         -XX: MaxDirectMemorySize </pre><br><br>  Versuchen wir, alles in das Diagramm zu zeichnen und es mit dem RSS-Docker-Container zu vergleichen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pg/ue/fx/pguefx_0kisoyxg8mna7dxlmimo.png"></div><br><br>  Die obige Zeile ist das RSS des Containers und eineinhalb Mal h√∂her als der Speicherverbrauch der JVM, den wir √ºber JMX √ºberwachen k√∂nnen. <br><br>  Weiter graben! <br><br><a name="lim-mem-2"></a><h4>  Begrenzung des Speicherverbrauchs: Native Memory Tracking </h4><br>  Zus√§tzlich zu Heap-, Nicht-Heap- und Direktspeicher verwendet die JVM nat√ºrlich eine ganze Reihe anderer Speicherpools.  Das Flag <code>-XX:NativeMemoryTracking=summary</code> hilft uns dabei <code>-XX:NativeMemoryTracking=summary</code> .  Durch Aktivieren dieser Option k√∂nnen wir Informationen zu Pools abrufen, die der JVM bekannt sind, aber in JMX nicht verf√ºgbar sind.  Weitere Informationen zur Verwendung dieser Option finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> . <br><br>  Beginnen wir mit dem offensichtlichsten - dem Speicher, den die <b>Fadenstapel einnehmen</b> .  NMT produziert f√ºr unseren Service etwa Folgendes: <br><br><pre>  Thread (reserviert = 32166 KB, festgeschrieben = 5358 KB)
     (Thread # 52)
     (Stapel: reserviert = 31920 KB, festgeschrieben = 5112 KB)
     (malloc = 185 KB # 270) 
     (Arena = 61 KB # 102) </pre><br>  √úbrigens kann seine Gr√∂√üe auch ohne Native Memory Tracking gefunden werden, indem jstack verwendet und ein wenig in <code>/proc/&lt;pid&gt;/smaps</code> .  Andrey Pangin hat hierf√ºr ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">besonderes Dienstprogramm entwickelt</a> . <br><br>  Die Gr√∂√üe des <b>gemeinsam genutzten Klassenraums</b> ist noch einfacher zu bewerten: <br><br><pre>  Gemeinsamer Klassenraum (reserviert = 17084 KB, festgeschrieben = 17084 KB)
     (mmap: reserviert = 17084 KB, festgeschrieben = 17084 KB) </pre><br>  Dies ist der Mechanismus <code>-Xshare</code> , <code>-Xshare</code> <code>-XX:+UseAppCDS</code> <code>-Xshare</code> und <code>-XX:+UseAppCDS</code> .  In Java 11 ist die Option <code>-Xshare</code> standardm√§√üig auf auto eingestellt. Wenn Sie also das <code>$JAVA_HOME/lib/server/classes.jsa</code> (es befindet sich im offiziellen OpenJDK-Docker-Image), wird die Speicherzuordnung geladen. Ohm beim Start der JVM, wodurch die Startzeit beschleunigt wird.  Dementsprechend ist die Gr√∂√üe des gemeinsam genutzten Klassenraums leicht zu bestimmen, wenn Sie die Gr√∂√üe von jsa-Archiven kennen. <br><br>  Im Folgenden sind die nativen <b>Garbage Collector-</b> Strukturen aufgef√ºhrt: <br><br><pre>  GC (reserviert = 42137 KB, festgeschrieben = 41801 KB)
     (malloc = 5705 KB # 9460) 
     (mmap: reserviert = 36432 KB, festgeschrieben = 36096 KB) </pre><br>  Alexey Shipilev im bereits erw√§hnten Handbuch zu Native Memory Tracking <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sagt,</a> dass sie ungef√§hr 4-5% der Gr√∂√üe des Heaps einnehmen, aber in unserem Setup f√ºr kleine Heaps (bis zu mehreren hundert Megabyte) erreichte der Overhead 50% der Gr√∂√üe des Heaps. <br><br>  <b>Symboltabellen</b> k√∂nnen viel Platz <b>einnehmen</b> : <br><br><pre>  Symbol (reserviert = 16421 KB, festgeschrieben = 16421 KB)
     (malloc = 15261 KB # 203089) 
     (Arena = 1159 KB # 1) </pre><br>  Sie speichern die Namen von Methoden, Signaturen sowie Links zu internierten Zeichenfolgen.  Leider scheint es m√∂glich zu sein, die Gr√∂√üe der Symboltabelle nur post factum mithilfe von Native Memory Tracking zu sch√§tzen. <br><br>  Was bleibt √ºbrig?  Laut Native Memory Tracking gibt es viele Dinge: <br><br><pre>  Compiler (reserviert = 509 KB, festgeschrieben = 509 KB)
 Intern (reserviert = 1647 KB, festgeschrieben = 1647 KB)
 Andere (reserviert = 2110 KB, festgeschrieben = 2110 KB)
 Arena Chunk (reserviert = 1712 KB, festgeschrieben = 1712 KB)
 Protokollierung (reserviert = 6 KB, festgeschrieben = 6 KB)
 Argumente (reserviert = 19 KB, festgeschrieben = 19 KB)
 Modul (reserviert = 227 KB, festgeschrieben = 227 KB)
 Unbekannt (reserviert = 32 KB, festgeschrieben = 32 KB) </pre><br>  Aber das alles nimmt ziemlich viel Platz ein. <br><br>  Leider k√∂nnen viele der genannten Speicherbereiche weder eingeschr√§nkt noch gesteuert werden, und wenn dies der Fall sein k√∂nnte, w√ºrde die Konfiguration zur H√∂lle werden.  Selbst die √úberwachung ihres Status ist keine triviale Aufgabe, da die Einbeziehung von Native Memory Tracking die Leistung der Anwendung geringf√ºgig beeintr√§chtigt und es keine gute Idee ist, sie f√ºr die Produktion in einem kritischen Dienst zu aktivieren. <br><br>  Lassen Sie uns dennoch aus Gr√ºnden des Interesses versuchen, alles, was Native Memory Tracking meldet, in der Grafik zu reflektieren: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/t_/5d/kn/t_5dkncjh0wrn9qmftrp3wgwg2w.png"></div><br><br>  Nicht schlecht!  Der verbleibende Unterschied ist ein Overhead f√ºr die Fragmentierung / Zuweisung von Speicher (er ist sehr gering, da wir jemalloc verwenden) oder der von nativen Bibliotheken zugewiesene Speicher.  Wir verwenden nur eine davon zur effizienten Speicherung des Pr√§fixbaums. <br><br>  F√ºr unsere Anforderungen reicht es also aus, das einzuschr√§nken, was wir k√∂nnen: Heap, Metaspace, Code-Cache, direkter Speicher.  F√ºr alles andere hinterlassen wir einige vern√ºnftige Grundlagen, die sich aus den Ergebnissen praktischer Messungen ergeben. <br><br>  Nachdem wir uns mit der CPU und dem Speicher befasst haben, gehen wir zur n√§chsten Ressource √ºber, um die Anwendungen konkurrieren k√∂nnen - zu den Festplatten. <br><br><a name="disks"></a><h4>  Java und Laufwerke </h4><br>  Und bei ihnen ist alles sehr schlecht: Sie sind langsam und k√∂nnen zu einer sp√ºrbaren Mattheit der Anwendung f√ºhren.  Daher l√∂sen wir Java so weit wie m√∂glich von Festplatten: <br><br><ul><li>  Wir schreiben alle Anwendungsprotokolle √ºber UDP in das lokale Syslog.  Dies l√§sst eine gewisse Chance, dass die erforderlichen Protokolle irgendwo auf dem Weg verloren gehen, aber wie die Praxis gezeigt hat, sind solche F√§lle sehr selten. </li><li>  Wir werden JVM-Protokolle in tmpfs schreiben. Dazu m√ºssen wir nur den Docker mit dem <code>/dev/shm</code> an der gew√ºnschten Stelle <code>/dev/shm</code> . </li></ul><br><br>  Wenn wir Protokolle in syslog oder in tmpfs schreiben und die Anwendung selbst nur Hip-Dumps auf die Festplatte schreibt, stellt sich heraus, dass der Verlauf der Festplatten als geschlossen angesehen werden kann. <br><br>  Nat√ºrlich nicht. <br><br>  Wir achten auf die grafische Darstellung der Dauer von Stop-the-World-Pausen und sehen ein trauriges Bild - Stop-The-World-Pausen auf Hosts betragen Hunderte von Millisekunden, und auf einem Host k√∂nnen sie bis zu einer Sekunde erreichen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tf/nd/pb/tfndpbg7mtpaylny7-cflvrukzg.png"></div><br><br>  Unn√∂tig zu erw√§hnen, dass sich dies negativ auf die Anwendung auswirkt?  Hier ist zum Beispiel ein Diagramm, das die Antwortzeit des Dienstes nach Kunden widerspiegelt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nc/d0/_n/ncd0_ndoybiyy42wzrh68ppj-_0.png"></div><br><br>  Dies ist ein sehr einfacher Dienst, der gr√∂√ütenteils zwischengespeicherte Antworten gibt. Woher stammen also solche unerschwinglichen Zeitpunkte, beginnend mit dem 95. Perzentil?  Andere Dienste haben ein √§hnliches Bild. Dar√ºber hinaus regnen Zeit√ºberschreitungen mit beneidenswerter Konstanz, wenn eine Verbindung vom Verbindungspool zur Datenbank hergestellt, Anforderungen ausgef√ºhrt werden usw. <br><br>  Was hat das Laufwerk damit zu tun?  - Du fragst.  Es hat sehr viel damit zu tun. <br>  Eine detaillierte Analyse des Problems ergab, dass lange STW-Pausen entstehen, weil die Threads lange Zeit zum Sicherheitspunkt gehen.  Nach dem Lesen des JVM-Codes haben wir festgestellt, dass die JVM w√§hrend der Synchronisierung von Threads auf dem Sicherheitspunkt die Datei <code>/tmp/hsperfdata*</code> √ºber die Speicherzuordnung schreiben kann, in die sie einige Statistiken exportiert.  Dienstprogramme wie <code>jstat</code> und <code>jps</code> verwenden <code>jstat</code> <code>jps</code> . <br><br>  Deaktivieren Sie es auf demselben Computer mit der Option <code>-XX:+PerfDisableSharedMem</code> und ... <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1r/aw/q7/1rawq7kjvmrjznko2781or7kzdm.png"></div><br><br>  Jetty Treadpool-Metriken stabilisieren sich: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qz/bs/pj/qzbspjvpdjfhjjtbwrn6et55wns.png"></div><br><br>         (,         ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ni/ig/ji/niigjizzguoke8dcfdz2ssqnqa8.png"></div><br><br>  ,         ,  ,        . <br><br><a name="monitor"></a><h4>    ? </h4><br>     Java-  , ,  ,    . <br><br>         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nuts and Bolts</a> ,          .              ,     .     ,      ,  JMX. <br><br>      ,          .          . <br><br>     statsd    JVM,    (heap,   non-heap   ): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/n9/iw/vs/n9iwvsjan7hxeo-xsksaggthrqy.png"></div><br><br>  ,    ,       . <br><br>    ‚Äî       ,    ,  ,    ,    ?        .     ()  -,     ,   RPS   . <br><br>     :   ,              .         .        ammo-  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">.</a> .    . : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qr/ry/wh/qrrywh-id3u5lbk7ldms8n-n_ck.png"></div><br><br>        . <br><br>               ,     .  ,      ,     - ,   ,   . <br><br><h4>  Abschlie√üend </h4><br>   ,  Java  Docker ‚Äî    ,      .     . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de450954/">https://habr.com/ru/post/de450954/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de450942/index.html">Beiwagen f√ºr eine Code-Aufteilung</a></li>
<li><a href="../de450946/index.html">Festplatten-Handy auf LPC810</a></li>
<li><a href="../de450948/index.html">MU-MIMO: einer der Implementierungsalgorithmen</a></li>
<li><a href="../de450950/index.html">Dart Streams Grundlagen</a></li>
<li><a href="../de450952/index.html">Mittlerer Index und Antibank</a></li>
<li><a href="../de450956/index.html">Vergleich der industriellen COB: ISIM vs. Kics</a></li>
<li><a href="../de450958/index.html">AnyStub, Java-Verbindungsstubbibliothek</a></li>
<li><a href="../de450962/index.html">Insulinpumpen, manipulationssichere Mikrochips und softwaredefiniertes Radio</a></li>
<li><a href="../de450964/index.html">Neue x86 SIMD-Bibliothek - Immintrin-Debug</a></li>
<li><a href="../de450966/index.html">Video von einem alten Computer aufnehmen - Methoden von LGR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
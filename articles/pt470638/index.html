<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìë ü¶å üé≠ M√©todos quase-newtonianos ou quando existem muitas segundas derivadas para Athos ü§úüèæ üßê üî°</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="No primeiro conhecimento dos m√©todos quase-newtonianos, podemos nos surpreender duas vezes. Em primeiro lugar, ap√≥s uma r√°pida olhada nas f√≥rmulas, su...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>M√©todos quase-newtonianos ou quando existem muitas segundas derivadas para Athos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470638/">  No primeiro conhecimento dos m√©todos quase-newtonianos, podemos nos surpreender duas vezes.  Em primeiro lugar, ap√≥s uma r√°pida olhada nas f√≥rmulas, surgem d√∫vidas de que isso possa funcionar.  No entanto, eles trabalham.  Al√©m disso, parece duvidoso que eles funcionem bem.  E √© ainda mais surpreendente ver qu√£o r√°pido eles s√£o do que as v√°rias varia√ß√µes da descida do gradiente, n√£o em tarefas especialmente constru√≠das, mas em tarefas reais tiradas da pr√°tica.  E se, depois disso, ainda houver d√∫vidas misturadas com o interesse, voc√™ precisar√° entender por que isso funciona de alguma maneira. <br><a name="habracut"></a><br>  A origem e as id√©ias b√°sicas que orientam os m√©todos de gradiente, incluindo o m√©todo de Newton, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">j√° foram consideradas</a> .  Nomeadamente, contamos com as informa√ß√µes sobre o comportamento da fun√ß√£o nas proximidades da posi√ß√£o atual, o que nos fornece uma an√°lise matem√°tica simples.  No m√≠nimo, foi assumido que as informa√ß√µes sobre os primeiros derivativos estavam dispon√≠veis para n√≥s.  E se isso √© tudo o que est√° dispon√≠vel para n√≥s?  A descida de gradiente √© nossa senten√ßa?  Claro, sim, a menos que voc√™ se lembre de repente de que estamos lidando com um <i>processo</i> no qual a fun√ß√£o objetivo √© processada adequadamente.  E se sim, por que n√£o usamos as informa√ß√µes acumuladas sobre o comportamento da fun√ß√£o para tornar nossa caminhada em sua superf√≠cie um pouco menos cega? <br><br>  A id√©ia de usar informa√ß√µes sobre o caminho coberto est√° no cerne de muitas maneiras de acelerar os m√©todos de descida.  Este artigo discute uma das maneiras mais eficazes, embora n√£o a mais barata, de contabilizar esse tipo de informa√ß√£o, levando √† id√©ia de m√©todos quase-newtonianos. <br><br>  Para entender de onde crescem as pernas dos m√©todos quasi-newtonianos e de onde vem o nome, precisamos voltar ao m√©todo de minimiza√ß√£o com base na solu√ß√£o direta da equa√ß√£o de ponto estacion√°rio <img src="https://habrastorage.org/getpro/habr/post_images/c43/946/5f9/c439465f905d9f366a2f4b3296306290.gif" title="&quot;\ bigtriangledown f = 0&quot;">  .  Assim como a considera√ß√£o do m√©todo de Newton aplicado √† solu√ß√£o dessa equa√ß√£o nos levou ao m√©todo de otimiza√ß√£o com o mesmo nome (que, diferentemente de seu progenitor, possui uma regi√£o global de converg√™ncia), podemos esperar que a considera√ß√£o de outros m√©todos para resolver sistemas de equa√ß√µes n√£o lineares seja proveitosa. planejar id√©ias para criar outros m√©todos de otimiza√ß√£o. <br><br><h2>  M√©todos secantes </h2><br>  Deixe-me lembr√°-lo de que o m√©todo de Newton para resolver o sistema de equa√ß√µes <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="&quot;F (x) = 0&quot;">  , baseia-se na substitui√ß√£o na vizinhan√ßa de algum ponto pr√≥ximo √† solu√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/779/0dd/0ef/7790dd0efb4a03a4c876741804d9b559.gif" title="x">  as fun√ß√µes <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  sua aproxima√ß√£o linear <img src="https://habrastorage.org/getpro/habr/post_images/d15/479/f23/d15479f235f0d60ce8837c9043a0d2cc.gif" title="&quot;L (p) = F (x) + J (x) p&quot;">  onde <img src="https://habrastorage.org/getpro/habr/post_images/206/f34/999/206f349991c0724c2fdce788124abe1c.gif" title="&quot;J&quot;">  √â um operador linear que, quando <img src="https://habrastorage.org/getpro/habr/post_images/779/0dd/0ef/7790dd0efb4a03a4c876741804d9b559.gif" title="x">  √© um vetor e <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  possui derivadas parciais em rela√ß√£o a cada vari√°vel, coincide com a matriz de Jacobi <img src="https://habrastorage.org/getpro/habr/post_images/4d2/826/ff6/4d2826ff6ba22f9f67cab70bfbe17a16.gif" title="&quot;J_ {ij} = \ dfrac {\ F_ parcial {i}} {\ parcial x_ {j}}&quot;">  .  Em seguida, a equa√ß√£o √© resolvida <img src="https://habrastorage.org/getpro/habr/post_images/c9d/8be/3f2/c9d8be3f2d70054db890ea34e3409544.gif" title="&quot;L (p) = 0&quot;">  e apontar <img src="https://habrastorage.org/getpro/habr/post_images/2c4/a7b/e55/2c4a7be5582848bfbcdd9ee141e7d764.gif" title="? x '= x + p?">  tomado como uma nova aproxima√ß√£o √† solu√ß√£o desejada.  √â simples e funciona. <br><br>  Mas e se, por algum motivo, n√£o pudermos calcular a matriz de Jacobi?  A primeira coisa que vem √† mente nesse caso √© que, se n√£o podemos calcular analiticamente as derivadas parciais, podemos obter uma aproxima√ß√£o num√©rica para elas.  A op√ß√£o mais simples (embora n√£o seja a √∫nica) para essa aproxima√ß√£o pode ser a f√≥rmula das diferen√ßas finitas corretas: <img src="https://habrastorage.org/getpro/habr/post_images/149/708/f5b/149708f5b8bab4374023295557622e82.gif" title="&quot;\ dfrac {\ parcial F_ {i}} {\ parcial x_ {j}} \ aprox \ dfrac {F_ {i} (x + h_ {j} e_ {j}) - F_ {i} (x)} { h_ {j}} &quot;">  onde <img src="https://habrastorage.org/getpro/habr/post_images/459/e61/aa0/459e61aa08f7fe807167a596e7ebd8a9.gif" title="&quot;e_ {j}&quot;">  √â o j-√©simo vetor base.  A matriz composta por tais aproxima√ß√µes ser√° denotada por <img src="https://habrastorage.org/getpro/habr/post_images/a51/533/990/a5153399048e881eb8661304792b8c81.gif" title="&quot;\ bar {J}&quot;">  .  Uma an√°lise de quanto de reposi√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/206/f34/999/206f349991c0724c2fdce788124abe1c.gif" title="&quot;J&quot;">  em <img src="https://habrastorage.org/getpro/habr/post_images/a51/533/990/a5153399048e881eb8661304792b8c81.gif" title="&quot;\ bar {J}&quot;">  no m√©todo de Newton, sua converg√™ncia afeta, um n√∫mero bastante grande de obras √© dedicado, mas, neste caso, estamos interessados ‚Äã‚Äãem outro aspecto.  Nomeadamente, essa aproxima√ß√£o requer o c√°lculo da fun√ß√£o em N pontos adicionais e, al√©m disso, a fun√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/6c4/afd/100/6c4afd1002ddcfa43d07afbc9f103a9d.gif" title="&quot;\ bar {L} (p) = F (x) + \ bar {J} p&quot;">  nesses pontos <i>interpola a</i> fun√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  , ou seja, <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c56/5c9/4b4/c565c94b4a37b9cd5f42fc1be92b2e15.gif" title="&quot;\ bar {L (} h_ {j} e_ {j}) = F (x) + h_ {j} \ dfrac {F (x + h_ {j} e_ {j}) - F (x)} {h_ {j}} = F (x) + F (x + h_ {j} e_ {j}) - F (x) = F (x + h_ {j} e_ {j}). &quot;"><br><br>  Nem toda aproxima√ß√£o da matriz de Jacobi tem essa propriedade, mas toda matriz de uma fun√ß√£o afim que possui essa propriedade √© uma aproxima√ß√£o da matriz de Jacobi.  De fato, se <img src="https://habrastorage.org/getpro/habr/post_images/88f/5c8/dd7/88f5c8dd7e9876a2d0e0980882f261da.gif" title="&quot;F (x + p_ {j}) = F (x) + J (x) p_ {j} + o \ left (\ left \ Vert p_ {j} \ right \ Vert ^ {2} \ right)&quot;">  e <img src="https://habrastorage.org/getpro/habr/post_images/5ad/e1e/ad2/5ade1ead2804a3bfaa8ffdf9122a179a.gif" title="&quot;\ bar {J} p_ {j} = F (x + p_ {j}) - F (x)&quot;">  ent√£o √†s <img src="https://habrastorage.org/getpro/habr/post_images/803/ca4/351/803ca4351b87edf1a13a2a2947772fa7.gif" title="&quot;\ left \ Vert p_ {j} \ right \ Vert \ rightarrow0 \ quad \ bar {J} (x) p_ {j} \ rightarrow J (x) p_ {j}&quot;">  .  Essa propriedade, ou seja, a propriedade de interpola√ß√£o, nos fornece uma maneira construtiva de generalizar o m√©todo de Newton. <br><br>  Vamos <img src="https://habrastorage.org/getpro/habr/post_images/194/ad1/d42/194ad1d42aa4320679b9498748ceb78d.gif" title="&quot;\ bar {L} (p) = a + Ap&quot;">  - fun√ß√£o que satisfa√ßa a exig√™ncia <img src="https://habrastorage.org/getpro/habr/post_images/06e/34e/3a7/06e34e3a7a0d0058ef351da74258a637.gif" title="&quot;\ bar {L} (p_ {i}) = F (x + p_ {i})&quot;">  para algum sistema de vetores linearmente independentes <img src="https://habrastorage.org/getpro/habr/post_images/cf2/deb/64e/cf2deb64e8b0e4d34902a32a5fd93b7b.gif" title="&quot;p_ {i}&quot;">  .  Ent√£o, essa fun√ß√£o √© chamada de fun√ß√£o <i>secante</i> <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  , e a equa√ß√£o que a define √© <i>a equa√ß√£o secante</i> .  Se o sistema de vetores <img src="https://habrastorage.org/getpro/habr/post_images/cf2/deb/64e/cf2deb64e8b0e4d34902a32a5fd93b7b.gif" title="&quot;p_ {i}&quot;">  est√° completo (ou seja, existem exatamente N deles e eles ainda s√£o linearmente independentes) e, al√©m disso, o sistema de vetores <img src="https://habrastorage.org/getpro/habr/post_images/94f/cf5/579/94fcf55798902795ffb670e35359d2af.gif" title="&quot;\ left \ {F (x + p_ {i}), i = 1 \ dots N \ right \}&quot;">  linearmente independente ent√£o <img src="https://habrastorage.org/getpro/habr/post_images/77f/eec/dd2/77feecdd2ae9a4795d2f81f3eec18b1b.gif" title="&quot;\ bar {L}&quot;">  definido exclusivamente. <br><br>  Qualquer m√©todo baseado na mudan√ßa local da equa√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="&quot;F (x) = 0&quot;">  equa√ß√£o da forma <img src="https://habrastorage.org/getpro/habr/post_images/ccb/557/80f/ccb55780f0c8e65187b0f4c9126be81c.gif" title="&quot;\ bar {L} (p) = 0&quot;">  onde <img src="https://habrastorage.org/getpro/habr/post_images/77f/eec/dd2/77feecdd2ae9a4795d2f81f3eec18b1b.gif" title="&quot;\ bar {L}&quot;">  satisfaz <i>a equa√ß√£o secante</i> , chamada <i>m√©todo secante</i> . <br><br>  Surge uma pergunta justa sobre como construir o secante para uma fun√ß√£o da maneira mais racional. <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  .  A seguinte linha de racioc√≠nio parece √≥bvia: seja constru√≠do um modelo afim no ponto x que interpola a fun√ß√£o dada nos pontos <img src="https://habrastorage.org/getpro/habr/post_images/462/bcf/f32/462bcff32469c0ec5f8ccfc80534c05c.gif" title="&quot;x-x_ {1}, x-x_ {2}, \ pontos, x-x_ {N}&quot;">  .  Solu√ß√£o de equa√ß√£o <img src="https://habrastorage.org/getpro/habr/post_images/ccb/557/80f/ccb55780f0c8e65187b0f4c9126be81c.gif" title="&quot;\ bar {L} (p) = 0&quot;">  nos d√° um novo ponto <img src="https://habrastorage.org/getpro/habr/post_images/2c4/a7b/e55/2c4a7be5582848bfbcdd9ee141e7d764.gif" title="? x '= x + p?">  .  Em seguida, para construir um modelo afim em um ponto <img src="https://habrastorage.org/getpro/habr/post_images/787/cf7/c3a/787cf7c3a3d374114b3a07305b7fa446.gif" title="&quot;x&quot;?">  √© mais razo√°vel escolher pontos de interpola√ß√£o para que o valor <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  j√° conhecido - ou seja, tire-os do conjunto <img src="https://habrastorage.org/getpro/habr/post_images/333/297/225/33329722533f0b608b0994d2a5ba83fa.gif" title="&amp; quot; \ left \ {x'-x, x'-x_ {1}, x'-x_ {2}, \ pontos, x'-x_ {N} \ right \} &amp; quot;">  .  Existem diferentes op√ß√µes para quais pontos escolher entre os muitos usados ‚Äã‚Äãanteriormente.  Por exemplo, voc√™ pode tomar como pontos de interpola√ß√£o aqueles em que <img src="https://habrastorage.org/getpro/habr/post_images/bb3/e3a/cd5/bb3e3acd5043b859fe89006d4cabe5a0.gif" title="&quot;\ left \ Vert F \ right \ Vert&quot;">  importa menos ou apenas o primeiro <img src="https://habrastorage.org/getpro/habr/post_images/055/8e9/3d9/0558e93d918ff32e873b6a71703e9969.gif" title="&quot;N&quot;">  pontos.  De qualquer forma, parece √≥bvio que <img src="https://habrastorage.org/getpro/habr/post_images/95f/756/92b/95f75692ba0aeefcef24ae42714dbc1b.gif" title="? p = x'-x?">  deve ser inclu√≠do em muitos pontos de interpola√ß√£o para o novo modelo afim.  T√£o al√©m <img src="https://habrastorage.org/getpro/habr/post_images/f24/8e8/91e/f248e891effc6650d9d31fbefc54cbe4.gif" title="&quot;n&quot;">  etapas do processo iterativo em nosso conjunto podem ser de at√© <img src="https://habrastorage.org/getpro/habr/post_images/f24/8e8/91e/f248e891effc6650d9d31fbefc54cbe4.gif" title="&quot;n&quot;">  deslocamentos constru√≠dos em pontos passados ‚Äã‚Äãanteriormente.  Se o processo for constru√≠do de tal maneira que o novo modelo afim n√£o use mais <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  dos valores anteriores, esse processo √© chamado de m√©todo secante do ponto p. <br><br>  √Ä primeira vista, pode parecer que o m√©todo secante do ponto N √© o melhor candidato para o papel de substituir o m√©todo Newton, uma vez que faz o m√°ximo uso das informa√ß√µes que obtemos no processo de solu√ß√£o, minimizando o n√∫mero de c√°lculos adicionais - usamos o valor da fun√ß√£o no √∫ltimo N pontos passaram.  Infelizmente, isso n√£o √© verdade.  O problema √© que o sistema vetorial <img src="https://habrastorage.org/getpro/habr/post_images/ed0/117/8ca/ed01178ca46506fa4588780d16d705a1.gif" title="&quot;F (x_ {0}), F (x_ {1}), \ pontos F (x_ {N})&quot;">  teimosamente se recusa a ser linearmente independente com um N. suficientemente grande. Al√©m disso, mesmo que essa condi√ß√£o seja cumprida e o modelo afim correspondente ainda exista, √© poss√≠vel que as dire√ß√µes <img src="https://habrastorage.org/getpro/habr/post_images/602/ff2/50c/602ff250c473d5b28e08a1453d4175b3.gif" title="&quot;p_ {j} = x_ {j} -x_ {0}&quot;">  tamb√©m provam ser linearmente independentes, resulta ainda menos.  E isso implica o fato de que o modelo afim, embora exista, √© degenerado e praticamente inadequado. <br><br>  Em geral, o mais est√°vel √© o m√©todo secante de 2 pontos.  Ou seja, um m√©todo no qual a cada itera√ß√£o temos que calcular valores N-1 adicionais da fun√ß√£o.  Claramente, isso n√£o √© adequado para nossos prop√≥sitos pr√°ticos. <br><br>  Ent√£o a quest√£o √© - o que foi tudo isso? <br><br><h2>  M√©todos quase-newtonianos para resolver equa√ß√µes </h2><br><br>  A sa√≠da √© simples, embora n√£o √≥bvia.  Se n√£o tivermos a capacidade t√©cnica, com base nos valores j√° calculados, de determinar exclusivamente o modelo afim que satisfaz a equa√ß√£o secante, isso n√£o ser√° necess√°rio.  Tomamos a equa√ß√£o de secantes como base, mas exigiremos que ela seja satisfeita apenas para algum sistema incompleto de vetores <img src="https://habrastorage.org/getpro/habr/post_images/e5e/f2b/432/e5ef2b43292735aa2a68afffb80bf520.gif" title="&quot;\ left \ {p_ {1}, p_ {2}, \ dots, p_ {m} \ right \}, m &amp; lt; N&quot;">  .  Em outras palavras, exigiremos que a condi√ß√£o de interpola√ß√£o seja satisfeita apenas para um n√∫mero suficientemente pequeno de valores conhecidos.  Obviamente, nesse caso, n√£o podemos mais garantir que a matriz usada nesse modelo tender√° √† matriz de Jacobi, mas n√£o precisaremos disso.  Al√©m disso, o modelo afim deve interpolar a fun√ß√£o no ponto atual, ou seja, <img src="https://habrastorage.org/getpro/habr/post_images/3b9/9d1/7fa/3b99d17fa378aeaf36097faef3830bd5.gif" title="&quot;\ barra {L} (0) = F (x)&quot;">  , obtemos a seguinte formula√ß√£o do m√©todo secante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/78c/f30/421/78cf304219a4bc90d4f900062bf2d027.gif" title="&quot;\\ \ bar {L} (p_ {i}) = F (x) + Ap_ {i} = F (x + p_ {i}), \ quad i = 1 \ dots m \\ \ bar {L} (p) = 0 \ quad \ Rightarrow p = A ^ {- 1} F (x) &quot;"><br><br>  Bruiden foi o primeiro a considerar m√©todos desse tipo para m = 1, chamando-os quase-newtonianos.  √â claro que a condi√ß√£o secante, neste caso, nos permite identificar exclusivamente a matriz <img src="https://habrastorage.org/getpro/habr/post_images/c9d/999/d9a/c9d999d9a4e8bd3d6f8e50519d1dfaa8.gif" title="&quot;A&quot;">  somente se condi√ß√µes adicionais lhe forem impostas e cada uma dessas condi√ß√µes adicionais der origem a um m√©todo separado.  O pr√≥prio Bruyden argumentou da seguinte maneira: <br><br>  <i>como o movimento na dire√ß√£o</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i>  <i>do ponto</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/460/82f/7d6/46082f7d6471c3fabb832d8f94075758.gif" title="&quot;x_ {0}&quot;"></i>  <i>direto ao ponto</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/1d0/56f/301/1d056f3016bc715aacc23418d8629173.gif" title="&quot;x_ {1}&quot;"></i>  <i>n√£o nos fornece nenhuma informa√ß√£o adicional sobre como a fun√ß√£o muda, exceto</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i>  <i>dire√ß√µes, ent√£o o efeito da nova fun√ß√£o afim no vetor</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/9fc/c76/a21/9fcc76a21130891ea5d5b10efa979bff.gif" title="q"></i>  <i>deve diferir do efeito da fun√ß√£o antiga no mesmo vetor, quanto menos diferente</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/9fc/c76/a21/9fcc76a21130891ea5d5b10efa979bff.gif" title="q"></i>  <i>de</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i>  <i>.</i>  <i>Como √∫ltimo recurso, quando</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/9fc/c76/a21/9fcc76a21130891ea5d5b10efa979bff.gif" title="q"></i>  <i>ortogonal</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i>  <i>, o comportamento da nova fun√ß√£o n√£o deve ser diferente do comportamento da antiga.</i> <i><br></i> <br>  A ideia de Breiden √© brilhante em sua simplicidade.  De fato, se n√£o temos novas informa√ß√µes sobre o comportamento da fun√ß√£o, o melhor que podemos fazer √© tentar n√£o sujar a antiga.  Ent√£o a condi√ß√£o adicional <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b3/d43/d20/0b3d43d207b144b926274d0c81abccbf.gif" title="&quot;\ bar {L} _ {1} q = \ bar {L} _ {0} q&quot;">  para todos <img src="https://habrastorage.org/getpro/habr/post_images/9fc/c76/a21/9fcc76a21130891ea5d5b10efa979bff.gif" title="q">  tal que <img src="https://habrastorage.org/getpro/habr/post_images/c16/9f6/315/c169f6315171249a34b50b26a2975c6e.gif" title="&quot;q ^ {T} p = 0&quot;"><br><br>  permite determinar exclusivamente a matriz da nova transforma√ß√£o - √© obtida adicionando uma corre√ß√£o de classifica√ß√£o 1 √† matriz antiga. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/522/f36/1f9/522f361f94a7b5a2e9da68094983b21d.gif" title="&quot;\\ A_ {1} = A_ {0} + \ dfrac {(y-A_ {0} p) p ^ {T}} {p ^ {T} p} \\ y = F (x_ {0}) -F (x_ {1}) &quot;"><br><br>  No entanto, apesar da simplicidade e consist√™ncia das conclus√µes de Bruiden, elas n√£o fornecem o ponto de apoio que poderia servir de base para a constru√ß√£o de outros m√©todos semelhantes.  Felizmente, h√° uma express√£o mais formal de sua ideia.  Ou seja, a matriz constru√≠da dessa maneira <img src="https://habrastorage.org/getpro/habr/post_images/147/7e7/ca0/1477e7ca06155c3e43fd4a640e0f7f98.gif" title="&quot;A_ {1}&quot;">  √â a solu√ß√£o para o seguinte problema: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/028/96f/3fa/02896f3facb898d70f26abad02fe90a9.gif" title="&quot;\\ \ left \ Vert A_ {1} -A_ {0} \ right \ Vert _ {F} \ rightarrow \ min \\ F (x_ {1}) - Ap = F (x_ {0})&quot;"><br><br>  A restri√ß√£o de tarefa nada mais √© do que a equa√ß√£o secante, e a condi√ß√£o de minimiza√ß√£o reflete nosso desejo de salvar o m√°ximo de informa√ß√µes poss√≠vel na matriz <img src="https://habrastorage.org/getpro/habr/post_images/107/a45/803/107a45803b226180325815eaa7be8706.gif" title="&quot;A_ {0}&quot;">  .  A medida da discrep√¢ncia entre as matrizes nesse caso √© a norma de Frobenius, na qual o problema apresentado tem uma solu√ß√£o inequ√≠voca.  Esta formula√ß√£o pode muito bem servir como ponto de partida para a constru√ß√£o de outros m√©todos.  Ou seja, podemos alterar tanto a <i>medida</i> pela qual avaliamos as mudan√ßas introduzidas quanto as <i>condi√ß√µes</i> impostas √† matriz.  Em geral, j√° √© poss√≠vel trabalhar com essa formula√ß√£o do m√©todo. <br><br><h2>  M√©todos de otimiza√ß√£o quase-Newton </h2><br><br>  Tendo entendido a id√©ia principal, podemos finalmente voltar aos problemas de otimiza√ß√£o e perceber que aplicar a f√≥rmula de Bruyden para recalcular o modelo afim n√£o se encaixa muito bem em nossa tarefa.  De fato, a primeira derivada da fun√ß√£o gradiente <img src="https://habrastorage.org/getpro/habr/post_images/6b8/82e/be7/6b882ebe727121dcb5fc21b091044b5a.gif" title="&quot;\ bigtriangledown f&quot;">  n√£o h√° mais nada al√©m da matriz hessiana, que por constru√ß√£o √© sim√©trica.  Ao mesmo tempo, a atualiza√ß√£o de acordo com a regra de Bruyden leva a uma matriz assim√©trica <img src="https://habrastorage.org/getpro/habr/post_images/147/7e7/ca0/1477e7ca06155c3e43fd4a640e0f7f98.gif" title="&quot;A_ {1}&quot;">  mesmo que <img src="https://habrastorage.org/getpro/habr/post_images/107/a45/803/107a45803b226180325815eaa7be8706.gif" title="&quot;A_ {0}&quot;">  era sim√©trico.  Isso n√£o significa que o m√©todo Bruden n√£o possa ser aplicado para resolver a equa√ß√£o do ponto estacion√°rio, mas com base nessa regra de atualiza√ß√£o, √© improv√°vel que consigamos construir bons m√©todos de otimiza√ß√£o.  Em geral, √© bastante √≥bvio que o m√©todo quase-Newton deve funcionar melhor, mais precisamente o sistema de condi√ß√µes do problema descreve as especificidades de uma matriz Jacobi espec√≠fica. <br><br>  Para corrigir essa desvantagem, adicionamos uma restri√ß√£o adicional ao problema de minimiza√ß√£o de Bruden, exigindo explicitamente que a nova matriz seja sim√©trica junto com a antiga: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/03e/167/aa2/03e167aa25e0f4aa6b8df8546552e79a.gif" title="&quot;\\ \ left \ Vert A_ {1} -A_ {0} \ right \ Vert _ {F} \ rightarrow \ min \\ \ bigtriangledown f (x_ {1}) - Ap = \ bigtriangledown f (x_ {0} ) \\ A_ {1} ^ {T} = A_ {1} &quot;"><br><br>  A solu√ß√£o para esse problema √© <br><br><img src="https://habrastorage.org/getpro/habr/post_images/df8/356/74b/df835674b94bab190bca3c18efed98ce.gif" title="&quot;A_ {1} = A_ {0} + \ dfrac {(y-A_ {0} p) p ^ {T} + p (y-A_ {0} p) ^ {T}} {p ^ {T} p} - \ dfrac {(y-A_ {0} p) ^ {T} p} {\ esquerda (p ^ {T} p \ direita) ^ {2}} pp ^ {T} &quot;"><br><br>  Aqui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/89c/f84/f29/89cf84f292ed72d1b20755677688a054.gif" title="y = \ bigtriangledown f (x_ {1}) - \ bigtriangledown f (x_ {0})"></a>  , e a f√≥rmula de rec√°lculo da matriz recebe o nome de seus criadores - Powell, Shanno e Bruyden (PSB).  A matriz resultante √© sim√©trica, mas claramente n√£o √© positiva definida, mesmo que de repente <img src="https://habrastorage.org/getpro/habr/post_images/6c7/040/47d/6c704047d3148fd7a8b563aaf79dd7f4.gif" title="&quot;y&quot;">  n√£o ser√° colinear <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  .  E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vimos</a> que a certeza positiva √© altamente desej√°vel nos m√©todos de otimiza√ß√£o. <br><br>  Novamente, corrigiremos a condi√ß√£o do problema, usando desta vez a norma de Frobenius em escala como uma medida da diverg√™ncia da matriz. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f37/eb1/0f4/f37eb10f4eb10d0c54acc9adab962f10.gif" title="&quot;\\ \ left \ Vert T ^ {- T} \ left (A_ {1} -A_ {0} \ right) T ^ {- 1} \ right \ Vert _ {F} \ rightarrow \ min \\ \ bigtriangledown f (x_ {1}) - Ap = \ bigtriangledown f (x_ {0}) \\ A_ {1} ^ {T} = A_ {1} &quot;"><br><br>  A origem de tal afirma√ß√£o da pergunta √© um grande t√≥pico separado, mas √© interessante que, se a matriz T for tal que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/673/872/131/673872131fa6cb0f44e6839be0e448e7.gif" title="T ^ {T} T = G, Gp = y"></a>  (ou seja, G tamb√©m √© uma matriz de transforma√ß√£o afim que satisfaz a equa√ß√£o secante para a dire√ß√£o p), a solu√ß√£o para esse problema acaba sendo independente da escolha de T e leva √† f√≥rmula de atualiza√ß√£o <br><br><img src="https://habrastorage.org/getpro/habr/post_images/135/ea6/c14/135ea6c14ea8f63f961e83576f1be5d5.gif" title="&quot;A_ {1} = A_ {0} + \ dfrac {(y-A_ {0} p) y ^ {T} + y (y-A_ {0} p) ^ {T}} {y ^ {T} p} - \ dfrac {\ left (y-A_ {0} p \ right) ^ {T} p} {\ left (y ^ {T} p \ right) ^ {2}} aa ^ {T} &quot;"><br><br>  conhecida como a f√≥rmula de Davidon-Fletcher-Powell.  Esse m√©todo de atualiza√ß√£o se comprovou na pr√°tica, pois possui a seguinte propriedade: <br><br>  <i>se</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/e3e/c44/1c1/e3ec441c17e1b43df108a7d8e15d3dd6.gif" title="&quot;y ^ {T} p &amp; gt; 0&quot;"></i>  <i>e</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/107/a45/803/107a45803b226180325815eaa7be8706.gif" title="&quot;A_ {0}&quot;"></i>  <i>positivo definitivo ent√£o</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/147/7e7/ca0/1477e7ca06155c3e43fd4a640e0f7f98.gif" title="&quot;A_ {1}&quot;"></i>  <i>tamb√©m identificado positivamente.</i> <br><br>  Observo depois que, se a primeira condi√ß√£o n√£o for cumprida, n√£o existe uma fun√ß√£o afim com uma matriz definida positiva que satisfa√ßa a equa√ß√£o secante. <br><br>  Se no problema que leva ao m√©todo DFP, tomamos, como medida da discrep√¢ncia de modelos afins, a dist√¢ncia n√£o entre as pr√≥prias matrizes, mas entre as matrizes inversas a elas, obtemos um problema da forma <br><br><img src="https://habrastorage.org/getpro/habr/post_images/337/0b0/af2/3370b0af216ab9695789eeb586cf3604.gif" title="&quot;\\ \ left \ Vert T ^ {- T} \ left (A_ {1} ^ {- 1} -A_ {0} ^ {- 1} \ right) T ^ {- 1} \ right \ Vert _ { F} \ rightarrow \ min \\ \ bigtriangledown f (x_ {1}) - Ap = \ bigtriangledown f (x_ {0}) \\ A_ {1} ^ {T} = A_ {1} &quot;"><br><br>  Sua solu√ß√£o √© uma f√≥rmula conhecida, descoberta quase simultaneamente por Breiden, Fletcher, Goldfarb e Shanno (BFGS). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3fa/840/c7b/3fa840c7b6ec3de81eb02bb0e9240722.gif" title="&quot;A_ {1} = A_ {0} + \ dfrac {aa} {T}} {y ^ {T} p} - \ dfrac {A_ {0} pp ^ {T} A_ {0}} {p ^ { T} A_ {0} p} &quot;"><br><br>  At√© o momento, acredita-se que o rec√°lculo de acordo com essa f√≥rmula seja o mais eficiente do ponto de vista computacional e, ao mesmo tempo, seja menos propenso √† degenera√ß√£o da matriz com um grande n√∫mero de itera√ß√µes.  Nas mesmas condi√ß√µes do DFP, essa f√≥rmula preserva a propriedade de defini√ß√£o positiva. <br><br>  Todos os m√©todos descritos para atualizar a matriz requerem uma corre√ß√£o da classifica√ß√£o 2. Isso facilita e facilita a invers√£o da matriz <img src="https://habrastorage.org/getpro/habr/post_images/147/7e7/ca0/1477e7ca06155c3e43fd4a640e0f7f98.gif" title="&quot;A_ {1}&quot;">  usando a f√≥rmula de Sherman-Morrison e o valor <img src="https://habrastorage.org/getpro/habr/post_images/5f6/3ac/2d9/5f63ac2d91f47a730fee01b5db38f3bd.gif" title="&quot;A_ {0} ^ {- 1}&quot;">  . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed0/9f8/002/ed09f80027e56f58a3502cc943758509.gif" title="&quot;B_ {1} = B_ {0} + uv ^ {T} \ Rightarrow B_ {1} ^ {- 1} = B_ {0} ^ {- 1} + \ dfrac {B_ {0} ^ {- 1} uv ^ {T} B_ {0} ^ {- 1}} {1 + v ^ {T} B_ {0} ^ {- 1} u} &quot;"><br><br>  desde que o denominador da f√≥rmula seja diferente de zero.  N√£o darei f√≥rmulas espec√≠ficas para atualizar as matrizes inversas dos m√©todos listados, pois s√£o f√°ceis de encontrar ou derivar independentemente.  A √∫nica coisa que deve ser notada nesse caso √© que as variantes dos m√©todos com atualiza√ß√£o da matriz inversa s√£o geralmente muito menos est√°veis ‚Äã‚Äã(ou seja, sofrem mais com erros de arredondamento) do que aquelas que sugerem atualizar a matriz original.  √â mais eficaz atualizar n√£o a matriz em si, mas sua decomposi√ß√£o de Cholesky (a n√£o ser, √© claro, que tal decomposi√ß√£o ocorra), pois essa op√ß√£o de implementa√ß√£o √© mais numericamente est√°vel e, al√©m disso, minimiza o custo de resolver uma equa√ß√£o que determina a dire√ß√£o do movimento. <br><br>  Resta considerar a quest√£o de como deve ser a primeira matriz no processo quase-newtoniano.  Tudo √© √≥bvio aqui - quanto mais pr√≥ximo estiver da matriz hessiana ou de sua vers√£o corrigida, se o hessiano n√£o se mostrar de repente definido positivamente, melhor ser√° do ponto de vista da converg√™ncia.  No entanto, em princ√≠pio, qualquer matriz definida positiva pode ser adequada para n√≥s.  A vers√£o mais simples dessa matriz √© √∫nica e, em seguida, a primeira itera√ß√£o coincide com a itera√ß√£o da descida do gradiente.  Fletcher e Powell mostraram (naturalmente, para o m√©todo DFP) que se a fun√ß√£o quadr√°tica for minimizada, independentemente de qual matriz (definida positiva) seja usada como a itera√ß√£o inicial do DFP, elas levar√£o a uma solu√ß√£o exatamente em N itera√ß√µes, onde N √© dimens√£o do problema, e a matriz quasi-newtoniana coincide com a matriz hessiana no ponto m√≠nimo.  No caso geral n√£o-linear dessa felicidade, √© claro que n√£o esperaremos, mas isso pelo menos d√° motivos para n√£o se preocupar muito com a m√° escolha da matriz inicial. <br><br><h2>  Conclus√£o </h2><br><br>  A abordagem descrita para a constru√ß√£o de m√©todos quase-newtonianos n√£o √© a √∫nica poss√≠vel.  No m√≠nimo, os descobridores dos m√©todos quase-newtonianos descritos e muitos pesquisadores subsequentes adotaram as mesmas f√≥rmulas com base em considera√ß√µes completamente diferentes.  No entanto, √© interessante que, assim que apareceu um certo m√©todo quase newtoniano, ficou claro, ap√≥s pouco tempo, que era uma solu√ß√£o para algum problema de otimiza√ß√£o facilmente interpretado.  Na minha opini√£o, √© not√°vel que seja poss√≠vel trazer algum denominador comum para m√©todos t√£o diversos, pois isso fornece a base para a constru√ß√£o de outros m√©todos que melhor levam em conta as especificidades de uma tarefa espec√≠fica.  Em particular, existem m√©todos quase newtonianos projetados para atualizar matrizes esparsas, m√©todos nos quais o menor n√∫mero poss√≠vel de elementos est√° sujeito a altera√ß√µes, e muitos outros seriam uma fantasia. <br><br>  Deve-se notar tamb√©m que os m√©todos de m√©tricas vari√°veis, apesar do nome, nem sempre levam √† constru√ß√£o de matrizes, que na verdade s√£o m√©tricas, embora o fa√ßam sempre que for poss√≠vel.      ,              ,          ‚Äî ,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> -</a> . ,           ,        .         ,       .      ,         ‚Äî . <br><br>  ,                  .      ,         ( ,   ,       N ,    ,     ).           (  ,     ,     ),      .   ,   ,             ‚Äî .      ‚Äî    . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt470638/">https://habr.com/ru/post/pt470638/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt470620/index.html">Infraestrutura como c√≥digo: como superar problemas com o XP</a></li>
<li><a href="../pt470622/index.html">Vis√£o geral dos m√©todos de sele√ß√£o de recursos</a></li>
<li><a href="../pt470628/index.html">Constru√ß√£o naval de simulador de nave espacial</a></li>
<li><a href="../pt470632/index.html">Arend - idioma do tipo dependente baseado no HoTT (parte 2)</a></li>
<li><a href="../pt470634/index.html">Identifique comunidades cruzadas no Instagram para identificar os interesses dos usu√°rios</a></li>
<li><a href="../pt470640/index.html">Pesquisando o Elasticsizing</a></li>
<li><a href="../pt470642/index.html">Conhe√ßa Yandex.Station Mini. Grande hist√≥ria de um pequeno dispositivo</a></li>
<li><a href="../pt470644/index.html">Por que os blogs corporativos √†s vezes azedam: algumas observa√ß√µes e dicas</a></li>
<li><a href="../pt470646/index.html">Matem√°tica para ci√™ncia de dados. Novo curso da OTUS</a></li>
<li><a href="../pt470648/index.html">IBM LTO-8 - Maneira f√°cil de armazenar dados frios</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👘 👨🏿‍🏭 🏵️ Python assíncrono: várias formas de competição 🧙🏻 🖕🏻 👨‍👧</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Com o advento do Python 3, há um burburinho sobre "assincronismo" e "simultaneidade", podemos assumir que o Python introduziu recentemente esses recur...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python assíncrono: várias formas de competição</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/421625/">  Com o advento do Python 3, há um burburinho sobre "assincronismo" e "simultaneidade", podemos assumir que o Python introduziu recentemente esses recursos / conceitos.  Mas isso não é verdade.  Usamos essas operações muitas vezes.  Além disso, os iniciantes podem pensar que o assíncrono é a única ou melhor maneira de recriar e usar operações assíncronas / paralelas.  Neste artigo, veremos várias maneiras de obter o paralelismo, suas vantagens e desvantagens. <br><a name="habracut"></a><br><h4>  Definição dos termos: </h4><br>  Antes de nos aprofundarmos nos aspectos técnicos, é importante ter algum entendimento básico dos termos frequentemente usados ​​neste contexto. <br><br>  <b>Síncrono e assíncrono:</b> <br><br>  Em operações <b>síncronas</b> , as tarefas são executadas uma após a outra.  Em tarefas <b>assíncronas</b> , podem ser iniciadas e concluídas independentemente uma da outra.  Uma tarefa assíncrona pode iniciar e continuar em execução enquanto a execução é movida para uma nova tarefa.  Tarefas assíncronas <b>não</b> bloqueiam (não force a espera pela conclusão da tarefa) e geralmente são executadas em segundo plano. <br><br>  Por exemplo, você deve entrar em contato com uma agência de viagens para planejar suas próximas férias.  Você precisa enviar uma carta ao seu supervisor antes de voar.  No modo síncrono, você primeiro liga para a agência de viagens e, se for solicitado a esperar, esperará até que eles atendam.  Então você começará a escrever uma carta para o líder.  Assim, você completa as tarefas uma após a outra.  <i>[execução síncrona, aprox.</i>  <i>tradutor]</i> Mas, se você for esperto, eles pediram para você esperar <i>[</i> aguarde <i>o telefone, aprox.</i>  <i>tradutor]</i> você começará a escrever e-mails e, quando falar novamente, fará uma pausa na escrita, na conversa e depois adicionará a carta.  Você também pode pedir a um amigo que ligue para a agência e escreva uma carta você mesmo.  Isso é assincronia, as tarefas não se bloqueiam. <br><br>  <b>Competitividade e simultaneidade:</b> <br><br>  Competitividade implica que duas tarefas sejam executadas em <u>conjunto</u> .  No exemplo anterior, quando consideramos o exemplo assíncrono, progredimos gradualmente escrevendo uma carta e depois conversando com um tour.  agência.  Isso é <b>competitividade</b> . <br><br>  Quando pedimos para ligar para um amigo e escrevemos uma carta, as tarefas foram realizadas <b>em paralelo</b> . <br><br>  A concorrência é essencialmente uma forma de competição.  Mas a simultaneidade depende do hardware.  Por exemplo, se a CPU tiver apenas um núcleo, duas tarefas não poderão ser executadas em paralelo.  Eles simplesmente compartilham o tempo do processador entre si.  Então isso é competição, mas não simultaneidade.  Mas quando temos vários núcleos <i>[como amigo no exemplo anterior, que é o segundo núcleo, aprox.</i>  <i>tradutor]</i> , podemos executar várias operações (dependendo do número de núcleos) ao mesmo tempo. <br><br>  Para resumir: <br><br><ul><li>  Sincronização: bloqueia operações (bloqueio) </li><li>  Assincronia: não bloqueia operações (sem bloqueio) </li><li>  Competitividade: progresso conjunto (conjunto) </li><li>  Simultaneidade: progresso paralelo (paralelo) </li></ul><br>  Concorrência implica concorrência.  Mas a concorrência nem sempre implica simultaneidade. <br><br><h4>  Threads e processos </h4><br>  O Python suporta threads há muito tempo.  Threads permitem que você execute operações de forma competitiva.  Mas há um problema com o <b>Global Interpreter Lock (GIL)</b> devido ao qual os threads não puderam fornecer simultaneidade verdadeira.  E, no entanto, com o advento do <b>multiprocessamento,</b> você pode usar vários núcleos usando Python. <br><br>  <b>Tópicos</b> <br><br>  Considere um pequeno exemplo.  No código a seguir, a função <i>worker</i> será executada em vários threads de forma assíncrona e simultânea. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> threading <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">worker</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(number)</span></span></span><span class="hljs-function">:</span></span> sleep = random.randrange(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) time.sleep(sleep) print(<span class="hljs-string"><span class="hljs-string">"I am Worker {}, I slept for {} seconds"</span></span>.format(number, sleep)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>): t = threading.Thread(target=worker, args=(i,)) t.start() print(<span class="hljs-string"><span class="hljs-string">"All Threads are queued, let's see when they finish!"</span></span>)</code> </pre> <br>  E aqui está um exemplo de saída: <br><br><pre> <code class="python hljs">$ python thread_test.py All Threads are queued, let<span class="hljs-string"><span class="hljs-string">'s see when they finish! I am Worker 1, I slept for 1 seconds I am Worker 3, I slept for 4 seconds I am Worker 4, I slept for 5 seconds I am Worker 2, I slept for 7 seconds I am Worker 0, I slept for 9 seconds</span></span></code> </pre><br>  Assim, iniciamos 5 threads para colaboração e após o início (ou seja, após o lançamento da função de trabalho), a operação <b>não espera</b> que os threads sejam concluídos antes de passar para a próxima instrução de impressão.  Esta é uma operação assíncrona. <br><br>  Em nosso exemplo, passamos a função para o construtor Thread.  Se quiséssemos, poderíamos implementar uma subclasse com um método (estilo OOP). <br><br>  <u>Leitura adicional:</u> <br><br>  Para saber mais sobre fluxos, use o link abaixo: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pymotw.com/3/threading/index.html</a> </li></ul><br>  <b>Bloqueio Global de Intérpretes (GIL)</b> <br><br>  O GIL foi introduzido para facilitar o manuseio de memória do CPython e fornecer a melhor integração com o C (por exemplo, com extensões).  GIL é um mecanismo de bloqueio quando o interpretador Python executa apenas um thread por vez.  I.e.  somente um encadeamento pode ser executado no bytecode do Python por vez.  O GIL garante que vários threads não sejam executados <b>em paralelo</b> . <br><br>  Detalhes rápidos de GIL: <br><br><ul><li>  Um thread pode ser executado por vez. </li><li>  O intérprete Python alterna entre threads para obter competitividade. </li><li>  O GIL é aplicável ao CPython (implementação padrão).  Mas, como, por exemplo, Jython e IronPython não possuem GIL. </li><li>  O GIL torna os programas single-threaded mais rápidos. </li><li>  O GIL geralmente não interfere na E / S. </li><li>  O GIL facilita a integração de bibliotecas seguras para threads no C, graças ao GIL, temos muitas extensões / módulos de alto desempenho escritos em C. </li><li>  Para tarefas dependentes da CPU, o intérprete verifica todos os N ticks e alterna os threads.  Portanto, um segmento não bloqueia os outros. </li></ul><br>  Muitos vêem o GIL como fraqueza.  Considero isso uma bênção, porque foram criadas bibliotecas como NumPy e SciPy, que ocupam uma posição especial e única na comunidade científica. <br><br>  <u>Leitura adicional:</u> <br><br>  Esses recursos permitirão que você mergulhe no GIL: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.dabeaz.com/python/UnderstandingGIL.pdf</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O artigo está em russo.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><i>[aprox.</i></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><i>tradutor]</i></a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um pouco mais sobre o GIL.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><i>[aprox.</i></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><i>tradutor]</i></a> </li></ul><br>  <b>Processos</b> <br><br>  Para obter simultaneidade no Python, foi adicionado um módulo de <b>multiprocessamento</b> que fornece uma API e parece muito semelhante se você já usou o <b>encadeamento</b> . <br><br>  Vamos apenas mudar o exemplo anterior.  Agora a versão modificada usa o <b>processo em</b> vez do <b>fluxo</b> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> multiprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">worker</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(number)</span></span></span><span class="hljs-function">:</span></span> sleep = random.randrange(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) time.sleep(sleep) print(<span class="hljs-string"><span class="hljs-string">"I am Worker {}, I slept for {} seconds"</span></span>.format(number, sleep)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>): t = multiprocessing.Process(target=worker, args=(i,)) t.start() print(<span class="hljs-string"><span class="hljs-string">"All Processes are queued, let's see when they finish!"</span></span>)</code> </pre><br>  O que mudou?  Acabei de importar o módulo de <b>multiprocessamento em</b> vez de <b>encadear</b> .  E então, em vez de um thread, usei um processo.  Isso é tudo!  Agora, em vez de muitos threads, usamos processos executados em diferentes núcleos da CPU (a menos, é claro, que seu processador tenha vários núcleos). <br><br>  Usando a classe Pool, também podemos distribuir a execução de uma função entre vários processos para diferentes valores de entrada.  Um exemplo dos documentos oficiais: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> multiprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Pool <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x*x <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">'__main__'</span></span>: p = Pool(<span class="hljs-number"><span class="hljs-number">5</span></span>) print(p.map(f, [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>]))</code> </pre><br>  Aqui, em vez de iterar sobre a lista de valores e chamar a função f uma de cada vez, na verdade executamos a função em diferentes processos.  Um processo executa f (1), o outro f (2) e o outro f (3).  Finalmente, os resultados são novamente combinados em uma lista.  Isso nos permite dividir cálculos pesados ​​em partes menores e executá-los em paralelo para cálculos mais rápidos. <br><br>  <u>Leitura adicional:</u> <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pymotw.com/3/multiprocessing/index.html</a> </li></ul><br>  <b>Módulo Concurrent.futures</b> <br><br>  O módulo concurrent.futures é grande e facilita a gravação de código assíncrono.  Meus favoritos são <b>ThreadPoolExecutor</b> e <b>ProcessPoolExecutor</b> .  Esses artistas suportam um conjunto de threads ou processos.  Enviamos nossas tarefas para o pool e ele executa as tarefas em um encadeamento / processo acessível.  Um objeto <b>Future</b> é retornado que pode ser usado para consultar e recuperar o resultado quando a tarefa for concluída. <br><br>  E aqui está um exemplo ThreadPoolExecutor: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> concurrent.futures <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ThreadPoolExecutor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sleep <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">return_after_5_secs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(message)</span></span></span><span class="hljs-function">:</span></span> sleep(<span class="hljs-number"><span class="hljs-number">5</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> message pool = ThreadPoolExecutor(<span class="hljs-number"><span class="hljs-number">3</span></span>) future = pool.submit(return_after_5_secs, (<span class="hljs-string"><span class="hljs-string">"hello"</span></span>)) print(future.done()) sleep(<span class="hljs-number"><span class="hljs-number">5</span></span>) print(future.done()) print(future.result())</code> </pre><br>  Tenho um artigo sobre concurrent.futures <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">masnun.com/2016/03/29/python-a-quick-introduction-to-the-concurrent-futures-module.html</a> .  Pode ser útil para um estudo mais aprofundado deste módulo. <br><br>  <u>Leitura adicional:</u> <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pymotw.com/3/concurrent.futures</a> </li></ul><br><h4>  Assíncio - o que, como e por quê? </h4><br>  Você provavelmente tem uma pergunta que muitas pessoas na comunidade Python têm - o que o asyncio traz de novo?  Por que havia outra maneira de usar E / S assíncrona?  Já não tínhamos threads e processos?  Vamos ver! <br><br>  <b>Por que precisamos de assíncio?</b> <br><br>  Os processos são muito caros <i>[em termos de consumo de recursos, aprox.</i>  <i>tradutor]</i> para criar.  Portanto, para operações de E / S, os threads são selecionados principalmente.  Sabemos que a E / S depende de coisas externas - unidades lentas ou atrasos desagradáveis ​​na rede tornam a E / S geralmente imprevisível.  Agora, suponha que usamos threads para E / S.  3 threads executam várias tarefas de E / S.  O intérprete teria que alternar entre fluxos competitivos e dar a cada um deles um tempo alternado.  Chame os fluxos T1, T2 e T3.  Três threads iniciaram sua operação de E / S.  T3 o conclui primeiro.  T2 e T1 ainda estão aguardando E / S.  O intérprete Python está mudando para T1, mas ainda está aguardando.  Bem, o intérprete se move para T2, e o intérprete ainda está aguardando, e depois se move para T3, que está pronto e executa o código.  Você vê isso como um problema? <br><br>  O T3 estava pronto, mas o intérprete trocou primeiro entre T2 e T1 - isso gerou custos de troca, que poderíamos ter evitado se o intérprete trocasse pela primeira vez para T3, certo? <br><br>  <b>O que é assínio?</b> <br><br>  O Asyncio nos fornece um loop de eventos junto com outras coisas interessantes.  O loop de eventos monitora eventos de E / S e alterna tarefas que estão prontas e aguardando operações de E / S <i>[loop de eventos é uma construção de software que aguarda a chegada e envia eventos ou mensagens no programa, aprox.</i>  <i>tradutor]</i> . <br><br>  A ideia é muito simples.  Há um loop de eventos.  E temos funções que executam E / S assíncronas.  Transferimos nossas funções para o loop de eventos e pedimos que ele as execute para nós.  O loop de eventos nos retorna um objeto Future, como uma promessa de que, no futuro, obteremos algo.  Nós nos apegamos a uma promessa, verificamos de tempos em tempos se isso importa (realmente não podemos esperar) e, finalmente, quando o valor é recebido, o usamos em algumas outras operações <i>[ou seja,</i>  <i>enviamos uma solicitação, recebemos um ticket imediatamente e nos disseram para esperar até o resultado chegar.</i>  <i>Verificamos periodicamente o resultado e, assim que é recebido, pegamos um ingresso e obtemos um valor nele, aprox.</i>  <i>tradutor]</i> . <br><br>  O Asyncio usa geradores e corotinas para interromper e retomar tarefas.  Você pode ler os detalhes aqui: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">masnun.com/2015/11/20/python-asyncio-future-task-and-the-event-loop.html</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">masnun.com/2015/11/13/python-generators-coroutines-native-coroutines-and-async-await.html</a> </li></ul><br>  <b>Como usar asyncio?</b> <br><br>  Antes de começarmos, vamos dar uma olhada em um exemplo: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_sleep_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(random.randint(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">display_date</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(num, loop)</span></span></span><span class="hljs-function">:</span></span> end_time = loop.time() + <span class="hljs-number"><span class="hljs-number">50.0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: print(<span class="hljs-string"><span class="hljs-string">"Loop: {} Time: {}"</span></span>.format(num, datetime.datetime.now())) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (loop.time() + <span class="hljs-number"><span class="hljs-number">1.0</span></span>) &gt;= end_time: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> my_sleep_func() loop = asyncio.get_event_loop() asyncio.ensure_future(display_date(<span class="hljs-number"><span class="hljs-number">1</span></span>, loop)) asyncio.ensure_future(display_date(<span class="hljs-number"><span class="hljs-number">2</span></span>, loop)) loop.run_forever()</code> </pre><br>  Observe que a sintaxe async / waitit é apenas para Python 3.5 e posterior.  Vamos analisar o código: <br><br><ul><li>  Temos uma função assíncrona display_date que usa um número (como identificador) e um loop de eventos como parâmetros. </li><li>  A função possui um loop infinito, que é interrompido após 50 segundos.  Mas durante esse período, ela imprime repetidamente o tempo e faz uma pausa.  A função de espera pode aguardar a conclusão de outras funções assíncronas (corotina). </li><li>  Passamos a função para o loop de eventos (usando o método sure_future). </li><li>  Iniciamos um ciclo de eventos. </li></ul><br>  Sempre que o aguardar é chamado, o assíncio percebe que a função provavelmente levará algum tempo.  Assim, ele interrompe a execução, começa a monitorar quaisquer eventos de E / S associados a ela e permite executar tarefas.  Quando o assinante percebe que a E / S da função em pausa está pronta, ela retoma a função. <br><br><h4>  Fazendo a escolha certa. </h4><br>  Acabamos de passar pelas formas mais populares de competitividade.  Mas a questão permanece - o que deve ser escolhido?  Depende dos casos de uso.  Pela minha experiência, tenho a tendência de seguir este pseudo-código: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> io_bound: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> io_very_slow: print(<span class="hljs-string"><span class="hljs-string">"Use Asyncio"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: print(<span class="hljs-string"><span class="hljs-string">"Use Threads"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: print(<span class="hljs-string"><span class="hljs-string">"Multi Processing"</span></span>)</code> </pre><br><ul><li>  Limite da CPU =&gt; Multi Processamento </li><li>  Limite de E / S, E / S rápida, número limitado de conexões =&gt; Multi Threading </li><li>  E / S vinculada, E / S lenta, várias conexões =&gt; Assíncio </li></ul><br>  <i>[Nota</i>  <i>tradutor]</i> <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Palestra (apresentação) em russo sobre multithreading e GIL.</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt421625/">https://habr.com/ru/post/pt421625/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt421607/index.html">"Nem tentamos executar o código antigo, não temos essa tarefa em princípio" - Roman Elizarov sobre o desenvolvimento do Kotlin</a></li>
<li><a href="../pt421611/index.html">Como o World of Warcraft foi criado: uma visão interna dos 20 anos de desenvolvimento</a></li>
<li><a href="../pt421613/index.html">Como escrevemos artigos sobre Habr: experiência dos desenvolvedores da EastBanc Technologies</a></li>
<li><a href="../pt421615/index.html">A solução para a falta de prevProps em getDerivedStateFromProps</a></li>
<li><a href="../pt421619/index.html">Sistemas autônomos do futuro. Classificação, características e requisitos</a></li>
<li><a href="../pt421629/index.html">Os robôs aceitam o meu trabalho? (E se eu sou humanista?)</a></li>
<li><a href="../pt421631/index.html">Análise do notebook Lenovo ThinkPad X1 Carbon (2018): leve, confortável e poderoso</a></li>
<li><a href="../pt421633/index.html">Como fazer um padrão em 10 dias</a></li>
<li><a href="../pt421637/index.html">Relógio infantil com GPS até 1º de setembro: em que você pode prestar atenção</a></li>
<li><a href="../pt421639/index.html">Laptop chinês Jumper EZBook X4 - teclado retroiluminado e a nova plataforma Gemini Lake</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
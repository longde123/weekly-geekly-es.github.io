<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüëß‚Äçüë¶ ü§∞üèΩ üë©üèª‚Äçüíº Entwicklung eines akustischen Datensatzes zum Training eines neuronalen Netzwerks üè¥Û†ÅßÛ†Å¢Û†Å≥Û†Å£Û†Å¥Û†Åø ü•Ä üò£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einmal sagte ein bekannter russischer Musiker in einem Interview: ‚ÄûWir arbeiten daran, an der Decke zu liegen und zu spucken.‚Äú Ich kann dieser Aussage...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Entwicklung eines akustischen Datensatzes zum Training eines neuronalen Netzwerks</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/speechpro/blog/427397/"><img src="https://habrastorage.org/webt/n9/ma/ty/n9matyv7rhr8woqlugdb6zw2dea.png"><br><br><p>  Einmal sagte ein bekannter russischer Musiker in einem Interview: ‚ÄûWir arbeiten daran, an der Decke zu liegen und zu spucken.‚Äú  Ich kann dieser Aussage nur zustimmen, da die Tatsache, dass Faulheit die treibende Kraft bei der Entwicklung der Technologie ist, nicht argumentiert werden kann.  In der Tat sind wir erst im letzten Jahrhundert von Dampfmaschinen zur digitalen Industrialisierung √ºbergegangen, und jetzt wird die k√ºnstliche Intelligenz, die von Science-Fiction-Autoren und Zukunftsforschern des letzten Jahrhunderts beschrieben wurde, jeden Tag zu einer immer gr√∂√üeren Realit√§t unserer Welt.  Computerspiele, mobile Ger√§te, Smartwatches und vieles mehr <a name="habracut"></a>  Verwenden Sie grunds√§tzlich Algorithmen, die mit Mechanismen des maschinellen Lernens verbunden sind. </p><br><br>  Heutzutage haben neuronale Netze aufgrund der zunehmenden Rechenleistung von Grafikprozessoren und der gro√üen Datenmenge an Popularit√§t gewonnen, mit der sie Klassifizierungs- und Regressionsprobleme l√∂sen und sie auf vorbereitete Daten trainieren.  Es wurden bereits viele Artikel dar√ºber geschrieben, wie neuronale Netze trainiert werden und welche Frameworks daf√ºr verwendet werden sollen.  Es gibt jedoch eine fr√ºhere Aufgabe, die ebenfalls gel√∂st werden muss, und dies ist die Aufgabe, ein Datenarray zu bilden - einen Datensatz, um das neuronale Netzwerk weiter zu trainieren.  Dies wird in diesem Artikel erl√§utert. <br><br><img src="https://habrastorage.org/webt/lv/kp/om/lvkpom8mxglgptwgqorih4jz9zu.png"><br><br>  Vor nicht allzu langer Zeit musste ein akustischer Klassifikator f√ºr Fahrzeugger√§usche erstellt werden, mit dem Daten aus einem gemeinsamen Audiostream extrahiert werden k√∂nnen: Glasscherben, √ñffnen von T√ºren und Betrieb eines Automotors in verschiedenen Modi.  Die Entwicklung des Klassifikators war nicht schwierig, aber woher kann man den Datensatz beziehen, damit er alle Anforderungen erf√ºllt? <br><br>  Google kam zur Rettung (keine Beleidigung f√ºr Yandex - ich werde etwas sp√§ter auf seine Vorteile eingehen), mit deren Hilfe mehrere Hauptcluster mit den erforderlichen Daten herausgegriffen werden konnten.  Ich m√∂chte im Voraus darauf hinweisen, dass die in diesem Artikel angegebenen Quellen eine gro√üe Menge akustischer Informationen mit verschiedenen Klassen enthalten, mit denen Sie einen Datensatz f√ºr verschiedene Aufgaben erstellen k√∂nnen.  Nun wenden wir uns einer √úbersicht dieser Quellen zu. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>Freesound.org</b></a> <br><br><img src="https://habrastorage.org/webt/pf/sz/mj/pfszmjwajssor0c8nask3seztzm.png"><br><br>  H√∂chstwahrscheinlich bietet <i>Freesound.org</i> das gr√∂√üte Volumen an akustischen Daten und ist ein gemeinsames Repository f√ºr lizenzierte Musikbeispiele, das derzeit mehr als 230.000 Kopien von Soundeffekten enth√§lt.  Jedes Soundbeispiel kann unter einer anderen Lizenz vertrieben werden. Machen Sie sich daher besser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im</a> Voraus mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lizenzvereinbarung</a> vertraut.  Beispielsweise hat die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zero-</a> Lizenz <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">(cc0)</a> den Status "Kein Urheberrecht" und erm√∂glicht Ihnen das Kopieren, √Ñndern und Verteilen, einschlie√ülich der kommerziellen Nutzung, sowie das absolut legale Verwenden der Daten. <br><br>  Um akustische Informationselemente in einer Vielzahl von freesound.org zu finden, haben die Entwickler eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">API</a> bereitgestellt, mit der Daten aus Repositorys analysiert, gesucht und heruntergeladen werden k√∂nnen.  Um damit arbeiten zu k√∂nnen, m√ºssen Sie Zugriff erhalten. Dazu m√ºssen Sie zum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Formular gehen</a> und alle erforderlichen Felder ausf√ºllen. Danach wird der einzelne Schl√ºssel generiert. <br><br><img src="https://habrastorage.org/webt/jo/i3/qr/joi3qrdieypz8db5t8kgf0_xrfk.png"><br><br>  Die Entwickler von Freesound.org stellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">APIs</a> f√ºr verschiedene Programmiersprachen bereit, sodass das gleiche Problem mit verschiedenen Tools gel√∂st werden kann.  Die Liste der unterst√ºtzten Sprachen und Links f√ºr den Zugriff auf GitHub sind unten aufgef√ºhrt. <br><br><img src="https://habrastorage.org/webt/m4/mw/8b/m4mw8bp6d82x-oges-p0exzynwm.png"><br><br>  Um dieses Ziel zu erreichen, wurde Python verwendet, da diese sch√∂ne Programmiersprache f√ºr dynamische Typisierung aufgrund ihrer Benutzerfreundlichkeit an Popularit√§t gewann und den Mythos der Komplexit√§t der Softwareentwicklung vollst√§ndig ausl√∂schte.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Modul f√ºr die Arbeit mit freesound.org</a> f√ºr Python kann aus dem Repository von github.com geklont werden. <br><br>  Unten finden Sie den zweiteiligen Code, der die Benutzerfreundlichkeit dieser API demonstriert.  Der erste Teil des Programmcodes f√ºhrt die Aufgabe der Datenanalyse aus, deren Ergebnis die Dichte der Datenverteilung f√ºr jede angeforderte Klasse ist, und der zweite Teil l√§dt Daten aus freesound.org-Repositorys f√ºr ausgew√§hlte Klassen hoch.  Die Verteilungsdichte bei der Suche nach akustischen Informationen mit den Schl√ºsselw√∂rtern <i>Glas, Motor, T√ºr</i> wird unten in einem Kreisdiagramm als Beispiel dargestellt. <br><br><img src="https://habrastorage.org/webt/uw/io/pm/uwiopmleer-snzvznuzchqsrnvc.png"><br><br>  Beispielcode f√ºr die Datenanalyse von Freesound.org <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plotly <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plotly.graph_objs <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> go <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> freesound <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> termcolor <span class="hljs-comment"><span class="hljs-comment">#      def histogram(data, filename = "tmp_histogram.html"): data = [ go.Histogram( histfunc="count", x=data, name="count",textfont=dict(size=15) ), ] plotly.offline.plot({ "data": data, "layout": go.Layout(title="Histogram") }, auto_open=True, filename=filename) pass #      freesound.org def freesound_analysis(search_tokens, output, lim_page_count = 1, key = None): lim_page_count = int(lim_page_count) try: client = freesound.FreesoundClient() client.set_token(key,"token") print(termcolor.colored("Authorisation successful ", "green")) except: print(termcolor.colored("Authorisation failed ", "red")) classes = list() for token in search_tokens: try: results = client.text_search(query=token,fields="id,name,previews") output_catalog = os.path.normpath(output) if not os.path.exists(output_catalog): os.makedirs(output_catalog) page_count = int(0) while True: for sound in results: try: classes.append(token) info = "Data has been getter: " + str(sound.name) print(termcolor.colored(info, "green")) except: info = "Data has not been getter: " + str(sound.name) print(termcolor.colored(info, "red")) page_count += 1 if (not results.next) or (lim_page_count == page_count): page_count = 0 break results = results.next_page() except: print(termcolor.colored(" Search is failed ", "red")) histogram(classes) pass</span></span></code> </pre> <br>  Beispielcode zum Herunterladen von freesound.org-Daten <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   def freesound_download(search_tokens, output, lim_page_count = 1, key = None): lim_page_count = int(lim_page_count) #  .     try: client = freesound.FreesoundClient() client.set_token(key,"token") print(termcolor.colored("Authorisation successful ", "green")) except: print(termcolor.colored("Authorisation failed ", "red")) for token in search_tokens: try: results = client.text_search(query=token,fields="id,name,previews") output_catalog = os.path.normpath(output + "\\" + str(token)) if not os.path.exists(output_catalog): os.makedirs(output_catalog) page_count = int(0) while True: for sound in results: try: sound.retrieve_preview(output_catalog) info = "Saved file: " + str(output_catalog) + str(sound.name) print(termcolor.colored(info, "green")) except: info = str("Sound can`t be saved to " + str(output_catalog) + str(sound.name) ) print(termcolor.colored(info, "red")) page_count += 1 if not results.next or lim_page_count == page_count: page_count = 0 break results = results.next_page() except: print(termcolor.colored(" Search is failed ", "red"))</span></span></code> </pre><br>  Ein Merkmal von Freesound ist, dass die Analyse von Audiodaten ohne Herunterladen einer Audiodatei durchgef√ºhrt werden kann, sodass Sie MFCC, spektrale Energie, spektralen Schwerpunkt und andere Koeffizienten erhalten k√∂nnen.  Weitere Informationen zu Lowlevel-Informationen finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation zu freesound.ord</a> . <br><br>  Mit der freesound.org-API wird der Zeitaufwand f√ºr das Abrufen und Herunterladen von Daten minimiert, sodass Sie Arbeitsstunden beim Studium anderer Informationsquellen sparen k√∂nnen, da hochgenaue akustische Klassifizierer einen gro√üen Datensatz mit gro√üer Variabilit√§t erfordern, der Daten mit unterschiedlichen Harmonischen auf einem und darstellt die gleiche Klasse von Ereignissen. <br><br>  <b>YouTube-8M und AudioSet</b> <br><br><img src="https://habrastorage.org/webt/fx/pu/rn/fxpurngrhz_d2b2lvs31fuw0jei.png"><br><br>  Ich denke, dass YouTube in der Pr√§sentation nicht besonders erforderlich ist, aber Wikipedia sagt uns dennoch, dass YouTube eine Video-Hosting-Site ist, die Benutzern Videoanzeigedienste bietet, wobei zu vergessen ist, dass YouTube eine riesige Datenbank ist und diese Quelle f√ºr maschinelles Lernen verwendet werden muss und Google Inc stellt uns ein Projekt namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">YouTube-8M Dataset zur Verf√ºgung</a> . <br><br>  Der YouTube-8M-Datensatz ist ein Datensatz, der mehr als eine Million Videodateien von YouTube in hoher Qualit√§t enth√§lt. Um genauere Informationen zu erhalten, gab es im Mai 2018 6,1 Millionen Videos mit 3862 Klassen.  Dieser Datensatz ist unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Creative Commons Attribution 4.0 International (CC BY 4.0)</a> lizenziert.  Mit einer solchen Lizenz k√∂nnen Sie Material auf jedem Medium und Format kopieren und verteilen. <br><br>  Sie fragen sich wahrscheinlich: Woher kommen die Videodaten, wenn akustische Informationen f√ºr die Aufgabe ben√∂tigt werden, und Sie werden sehr richtig liegen.  Tatsache ist, dass Google nicht nur Videoinhalte bereitstellt, sondern auch ein Teilprojekt mit Audiodaten namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AudioSet</a> separat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zuweist</a> . <br><br><img src="https://habrastorage.org/webt/fb/de/rh/fbderhx9gvzmjbdlqfbv5mt_hsq.png"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AudioSet</a> - bietet einen Datensatz aus YouTube-Videos, in dem viele Daten in einer Klassenhierarchie mithilfe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einer Ontologiedatei dargestellt werden</a> . Die grafische Darstellung befindet sich unten. <br><br><img src="https://habrastorage.org/webt/qw/11/r1/qw11r1lissfnhoo39wvvljheyo8.png"><br><br>  Mit dieser Datei erhalten Sie einen √úberblick √ºber die Verschachtelung von Klassen sowie den Zugriff auf YouTube-Videos.  Um Daten aus dem Internet hochzuladen, k√∂nnen Sie das Python-Modul youtube-dl verwenden, mit dem Sie je nach erforderlicher Aufgabe Audio- oder Videoinhalte herunterladen k√∂nnen. <br><br>  AudioSet stellt einen Cluster dar, der in drei S√§tze unterteilt ist: Test, Training (ausgeglichen) und Trainingsdatensatz (nicht ausgeglichen). <br><br>  Schauen wir uns diesen Cluster an und analysieren jeden dieser S√§tze separat, um eine Vorstellung von den enthaltenen Klassen zu erhalten. <br><br>  <b>Training (ausgewogen)</b> <br><br>  Gem√§√ü der Dokumentation besteht dieser Datensatz aus <i>22.176 Segmenten,</i> die aus verschiedenen Videos stammen, die nach Schl√ºsselw√∂rtern ausgew√§hlt wurden, wodurch jede Klasse mindestens 59 Kopien erh√§lt.  Wenn wir uns die Verteilungsdichte der Stammklassen in der Hierarchie der Menge ansehen, werden wir sehen, dass die Musikklasse die gr√∂√üte Gruppe von Audiodateien ist. <br><br><img src="https://habrastorage.org/webt/ke/fa/2c/kefa2c6njxd2_iy-_vp1hj4wkmq.png"><br><br>  Organisierte Klassen werden in Teilmengen von Klassen zerlegt, sodass Sie bei der Verwendung detailliertere Informationen erhalten.  Dieses ausgewogene Trainingsset hat eine Verteilungsdichte, bei der klar ist, dass ein Gleichgewicht vorhanden ist, aber auch einzelne Klassen unterscheiden sich stark von der allgemeinen Sichtweise. <br><br><img src="https://habrastorage.org/webt/er/zu/ba/erzuba4ghfkk9dlrsnrq7gfwlq8.png"><br><br>  Die Verteilung von Klassen, deren Anzahl von Elementen den Durchschnittswert √ºberschreitet <br><br><img src="https://habrastorage.org/webt/hm/62/-l/hm62-ltqt7_e93u21qfjinyazzy.png"><br><br>  Die durchschnittliche Dauer jeder Audiodatei betr√§gt 10 Sekunden. Detailliertere Informationen finden Sie im Datentr√§gerdiagramm, aus dem hervorgeht, dass sich die Dauer einiger Dateien vom Hauptsatz unterscheidet.  Dieses Diagramm wird ebenfalls dargestellt. <br><br><img src="https://habrastorage.org/webt/ow/t8/23/owt823euusbns9w2ipjebfjb1tg.png"><br><br>  Diagramm von anderthalb Prozent nicht durchschnittlicher Dauer aus einem ausgewogenen Satz von Audiosets <br><br><img src="https://habrastorage.org/webt/l2/4q/1n/l24q1nriwiyuec2qf7xaciwablg.png"><br><br>  <b>Training (unausgeglichen)</b> <br><br>  Der Vorteil dieses Datensatzes ist seine Gr√∂√üe.  Stellen Sie sich vor, dass dieser Satz laut Dokumentation 2.042.985 Segmente enth√§lt und im Vergleich zu ausgeglichenen Datens√§tzen eine gro√üe Variabilit√§t darstellt, die Entropie dieses Satzes jedoch viel h√∂her ist. <br><br><img src="https://habrastorage.org/webt/1q/hh/q6/1qhhq6fqowmubsrjy9czj-n_w0u.png"><br><br>  In diesem Satz betr√§gt die durchschnittliche Dauer jeder Audiodatei ebenfalls 10 Sekunden. Das Datentr√§gerdiagramm f√ºr diesen Datensatz ist unten dargestellt. <br><br><img src="https://habrastorage.org/webt/yh/co/uu/yhcouua6nv6nryg5_qu5bzsrbo0.png"><br><br>  Diagramm mit nicht durchschnittlicher Dauer aus einem unausgeglichenen Satz von Audiosets <br><br><img src="https://habrastorage.org/webt/lc/ga/gw/lcgagwcbhncmnsxvjrvouvp0bvy.png"><br><br>  <b>Testset</b> <br><br>  Diese Menge ist einer ausgeglichenen Menge sehr √§hnlich, mit dem Vorteil, dass sich die Elemente dieser Mengen nicht schneiden.  Ihre Verteilung ist unten dargestellt. <br><br><img src="https://habrastorage.org/webt/uz/ep/ek/uzepekdo_ccoh3fjevljpx7vdzg.png"><br><br>  Die Verteilung von Klassen, deren Anzahl von Elementen den Durchschnittswert √ºberschreitet <br><br><img src="https://habrastorage.org/webt/y1/6b/p0/y16bp0_grna51h4tgd9_500dht8.png"><br><br>  Die durchschnittliche Dauer eines Segments aus diesem Datensatz betr√§gt ebenfalls 10 Sekunden <br><br><img src="https://habrastorage.org/webt/wg/i-/jv/wgi-jvqyphgyblijzahtwznpvvm.png"><br><br>  und der Rest hat die im Plattendiagramm angegebene Dauer <br><br><img src="https://habrastorage.org/webt/lp/z9/jz/lpz9jzkcsfevakvk5rp0lwoex-8.png"><br><br>  Beispielcode zum Analysieren und Herunterladen von akustischen Daten gem√§√ü dem ausgew√§hlten Datensatz: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plotly <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> plotly.graph_objs <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> go <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Counter <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> termcolor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> youtube_dl <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> subprocess <span class="hljs-comment"><span class="hljs-comment">#      def histogram(data,hist_mean= True, filename = "tmp_histogram.html"): if hist_mean == True: cdata = Counter(data) mean_number_classes = np.asarray([cdata[x] for x in cdata]).mean() ldata = list() for name in cdata: if cdata[name] &gt; mean_number_classes: ldata += list(Counter({name:cdata[name]}).elements()) trace_mean_data = go.Histogram(histfunc="count", x=ldata, name="count" ) trace_data = go.Histogram(histfunc="count", x=data, name="count", text="" ) trace = [ trace_data, trace_mean_data] plotly.offline.plot({ "data": trace, "layout": go.Layout(title="stack") }, auto_open=True, filename=filename) pass #       def pie_chart(labels, values = None, filename = "tmp_pie_chart.html", textinfo = 'label+value'): if labels == None: raise Exception("Can not create pie chart, because labels is None") if values == None: data = Counter(labels) labels = list() values = list() for name in data: labels.append(name) values.append(data[name]) trace = go.Pie(labels=labels, values=values,textfont=dict(size=20),hoverinfo='label+percent', textinfo=textinfo, marker=dict(line=dict(color='#000000', width=2)) ) plotly.offline.plot([trace], filename='basic_pie_chart') pass #          def audioset_analysis(audioset_file, inputOntology): if not os.path.exists(inputOntology) or not os.path.exists(audioset_file): raise Exception("Can not found file") with open(audioset_file, 'r') as fe: csv_data = csv.reader(fe) sx = list() with open(inputOntology) as f: data = json.load(f) duration_hist = list() for row in csv_data: if row[0][0] == '#': continue classes = row[3:] try: color = "green" tmp_duration = str(float(row[2]) - float(row[1])) info = str("id: ") + str(row[0]) + str(" duration: ") + tmp_duration duration_hist.append(tmp_duration) for cl in classes: for dt in data: cl = str(cl).strip().replace('"',"") if cl == dt['id'] and len(dt['child_ids']) == 0: sx.append(dt['name']) info += str(" ")+str(dt['name']) + str(",") except: color = "red" info = "File has been pass: " + str(row[0]) continue print(termcolor.colored(info, color)) histogram(sx, filename="audioset_class") pie_chart(duration_hist, textinfo="percent + label", filename="audioset_duration")</span></span></code> </pre><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   youtube def youtube_download(filepath, ytid): ydl_opts = { 'format': 'bestaudio/best', 'outtmpl': os.path.normpath(filepath), 'postprocessors': [{ 'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav', 'preferredquality': '192', }], } with youtube_dl.YoutubeDL(ydl_opts) as ydl: ydl.download(['https://www.youtube.com/watch?v={}'.format(ytid)]) pass #    ffmpeg def cutOfPartFile(filename,outputFile, start, end, frequency = 44100): duration = float(end) - float(start) command = 'ffmpeg -i ' command += str(filename)+" " command += " -ar " + str(frequency) command += " -ss " + str(start) command += " -t " + str(duration) + " " command += str(outputFile) subprocess.call(command,shell=True) pass #    yotube        def audioset_converter(incatalog,outcatalog, token = "*.wav", frequency = 44100): find_template = os.path.join(incatalog,token) files = glob(find_template); for file in files: _,name = os.path.split(file) name = os.path.splitext(name)[0] duration = str(name).split("_")[1:3] filename = name.split("_")[0] +"."+ token.split(".")[1]; outfile = os.path.join(outcatalog,filename) cutOfPartFile(file,outfile,start=duration[0],end=duration[1]) #    audioset def audioset_download(audioset_file, outputDataset, frequency = 44100): t,h = os.path.split(audioset_file) h = h.split(".") outputDataset_full = os.path.join(outputDataset,str(h[0])+"_full") outputDataset = os.path.join(outputDataset,str(h[0])) if not os.path.exists(outputDataset): os.makedirs(outputDataset) if not os.path.exists(outputDataset_full): os.makedirs(outputDataset_full) with open(audioset_file, 'r') as fe: csv_data = csv.reader(fe) duration_hist = list() for row in csv_data: if row[0][0] == '#': continue try: color = "green" tmp_duration = str(float(row[2]) - float(row[1])) info = str("id: ") + str(row[0]) + str(" duration: ") + tmp_duration duration_hist.append(tmp_duration) save_full_file = str(outputDataset_full) + str("//")+ str(row[0]).lstrip()+str("_") +str(row[1]).lstrip() + str("_").lstrip() + str(row[2]).lstrip() + str('.%(ext)s') youtube_download(save_full_file,row[0]) except: color = "red" info = "File has been pass: " + str(row[0]) continue print(termcolor.colored(info, color)) audioset_converter(outputDataset_full,outputDataset, frequency = frequency)</span></span></code> </pre><br>  Um detailliertere Informationen zur Analyse von Audioset-Daten zu erhalten oder diese Daten gem√§√ü der <a href="">Ontologiedatei</a> und dem ausgew√§hlten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Audioset-Satz aus dem Yotube-Bereich hochzuladen</a> , steht der Programmcode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem GitHub-Repository</a> frei zur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verf√ºgung</a> . <br><br>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">urbansound</a></b> <br><br><img src="https://habrastorage.org/webt/sq/me/ww/sqmewwpsn82lf_w5mck-5w8q_ii.png"><br><br>  Urbansound ist einer der gr√∂√üten Datens√§tze mit markierten Klangereignissen, deren Klassen zur st√§dtischen Umgebung geh√∂ren.  Diese Menge wird taxonomisch (kategorisch) genannt, d.h.  Jede Klasse ist in ihre Unterklassen unterteilt.  Eine solche Menge kann in Form eines Baumes dargestellt werden. <br><br><img src="https://habrastorage.org/webt/tk/5l/jo/tk5ljok89na3nemguyn86yvtmtm.png"><br><br>  Um urbansound-Daten f√ºr die sp√§tere Verwendung hochzuladen, gehen Sie einfach auf die Seite und klicken Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Download</a> . <br><br>  Da f√ºr die Aufgabe nicht alle Unterklassen verwendet werden m√ºssen und nur eine einzige Klasse f√ºr das Fahrzeug erforderlich ist, m√ºssen zun√§chst die erforderlichen Klassen mithilfe der Metadatei gefiltert werden, die sich im Stammverzeichnis des Verzeichnisses befindet, das beim Entpacken der heruntergeladenen Datei abgerufen wurde. <br><br>  Nach dem Entladen aller erforderlichen Daten aus den aufgelisteten Quellen stellte sich heraus, dass ein Datensatz mit mehr als 15.000 Dateien gebildet wurde.  Ein solches Datenvolumen erm√∂glicht es uns, mit der Aufgabe fortzufahren, den akustischen Klassifikator zu trainieren, aber es bleibt ein ungel√∂stes Problem hinsichtlich der "Reinheit" der Daten, d. H.  Der Trainingssatz enth√§lt Daten, die sich nicht auf die erforderlichen Klassen des zu l√∂senden Problems beziehen.  Wenn Sie beispielsweise Dateien aus der Klasse "Glas zerbrechen" anh√∂ren, k√∂nnen Sie Leute finden, die dar√ºber sprechen, "wie es nicht gut ist, das Glas zu zerbrechen".  Daher stehen wir vor der Aufgabe, Daten zu filtern, und als Werkzeug zur L√∂sung dieser Art von Problem ist ein Werkzeug perfekt geeignet, dessen Kern von belarussischen Leuten entwickelt wurde und den seltsamen Namen ‚ÄûYandex.Toloka‚Äú erhielt. <br><br>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Yandex.Toloka</a></b> <br><br><img src="https://habrastorage.org/webt/k0/_1/1n/k0_11n7zzpfxckvcqdbqawyw25i.png"><br><br>  Yandex.Toloka ist ein Crowdfunding-Projekt, das 2014 ins Leben gerufen wurde, um eine gro√üe Datenmenge f√ºr die weitere Verwendung beim maschinellen Lernen zu markieren oder zu sammeln.  Mit diesem Tool k√∂nnen Sie Daten mithilfe einer Personalressource erfassen, markieren und filtern.  Ja, mit diesem Projekt k√∂nnen Sie nicht nur Probleme l√∂sen, sondern auch andere Menschen Geld verdienen.  Die finanzielle Belastung liegt in diesem Fall auf Ihren Schultern, aber aufgrund der Tatsache, dass mehr als 10.000 Tolker von Seiten der Darsteller handeln, werden die Arbeitsergebnisse in naher Zukunft eingehen.  Eine gute Beschreibung der Funktionsweise dieses Tools finden Sie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Yandex-Blog</a> . <br><br>  Im Allgemeinen ist die Verwendung des Crushs nicht besonders schwierig, da f√ºr die Ver√∂ffentlichung einer Aufgabe nur eine Registrierung auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Website</a> , ein Mindestbetrag von 10 US-Dollar und eine korrekt ausgef√ºhrte Aufgabe erforderlich sind.  Wie man eine Aufgabe richtig formuliert, kann man der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Yandex.Tolok-Dokumentation entnehmen</a> oder es gibt keinen schlechten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel √ºber Habr</a> .  Von mir selbst zu diesem Artikel m√∂chte ich hinzuf√ºgen, dass selbst wenn eine Vorlage fehlt, die f√ºr die Anforderung Ihrer Aufgabe geeignet ist, ihre Entwicklung nicht l√§nger als ein paar Stunden Arbeit dauert, mit einer Pause f√ºr Kaffee und eine Zigarette, und die Ergebnisse der Darsteller bis zum Ende des Arbeitstages erhalten werden k√∂nnen. <br><br>  <b>Fazit</b> <br><br>  Beim maschinellen Lernen besteht eine der Hauptaufgaben bei der L√∂sung des Klassifizierungs- oder Regressionsproblems darin, einen zuverl√§ssigen Datensatz zu entwickeln - einen Datensatz.  In diesem Artikel wurden Informationsquellen mit einer gro√üen Menge akustischer Daten ber√ºcksichtigt, die es erm√∂glichten, den f√ºr eine bestimmte Aufgabe erforderlichen Datensatz zu bilden und auszugleichen.  Der vorgestellte Programmcode erm√∂glicht es uns, das Hochladen von Daten auf ein Minimum zu vereinfachen, wodurch die Zeit zum Empfangen von Daten verk√ºrzt und der Rest f√ºr die Entwicklung eines Klassifikators aufgewendet wird. <br><br>  Nachdem ich Daten aus allen in diesem Artikel vorgestellten Quellen gesammelt und anschlie√üend gefiltert hatte, gelang es mir, den erforderlichen Datensatz f√ºr das Training des akustischen Klassifikators zu bilden, der auf einem neuronalen Netzwerk basiert.  Ich hoffe, dass dieser Artikel es Ihnen und Ihrem Team erm√∂glicht, Zeit zu sparen und sie f√ºr die Entwicklung neuer Technologien aufzuwenden. <br><br>  <b>PS</b> Ein in Python entwickeltes Softwaremodul zum Analysieren und Hochladen von akustischen Daten f√ºr jede der pr√§sentierten Quellen, das Sie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github-Repository finden</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de427397/">https://habr.com/ru/post/de427397/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de427387/index.html">Samsung k√ºndigte ein Display der neuen Generation an</a></li>
<li><a href="../de427389/index.html">Operation Vk 2.0. Ein Gesetzentwurf zu Nachrichtenaggregatoren wurde eingef√ºhrt. Yandex.News wird geschlossen, wenn der Dienst den Eigent√ºmer nicht √§ndert</a></li>
<li><a href="../de427391/index.html">Tipps f√ºr Junioren: Gute Gewohnheiten entwickeln</a></li>
<li><a href="../de427393/index.html">Enterprise Wireless-Sicherheitsanalyse</a></li>
<li><a href="../de427395/index.html">"Lassen Sie uns erkl√§ren: oder warum sollte ein Mathematiker Programmierer." Ein Buch dar√ºber, wie man Mathe-Vorlesungen nicht verpasst</a></li>
<li><a href="../de427399/index.html">Arbeiten mit Daten beim Erstellen einer API auf Basis von GraphQL</a></li>
<li><a href="../de427401/index.html">Dissolution Shaders und World Exploration</a></li>
<li><a href="../de427403/index.html">ReportingObserver API: Ein Blick auf den Code von Webseiten aus einer neuen Perspektive</a></li>
<li><a href="../de427405/index.html">ES2018 - verspricht endlich Methode</a></li>
<li><a href="../de427407/index.html">Meta-Clustering mit Fehlerminimierung und warum das Gehirn meiner Meinung nach so funktioniert</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
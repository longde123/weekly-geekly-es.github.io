<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äç‚öñÔ∏è üèì ‚öíÔ∏è Como entender o Tensorflow e n√£o morrer, e at√© ensinar algo sobre um carro üõÅ üé∂ üë©üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√°, guardas. A publica√ß√£o de hoje ser√° sobre como n√£o se perder na natureza, com a variedade de op√ß√µes para usar o TensorFlow para aprendizado de m√°q...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como entender o Tensorflow e n√£o morrer, e at√© ensinar algo sobre um carro</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427449/"><p>  Ol√°, guardas.  A publica√ß√£o de hoje ser√° sobre como n√£o se perder na natureza, com a variedade de op√ß√µes para usar o TensorFlow para aprendizado de m√°quina e atingir seu objetivo.  O artigo foi desenvolvido para que o leitor conhe√ßa os princ√≠pios b√°sicos do aprendizado de m√°quina, mas ainda n√£o tentou faz√™-lo com suas pr√≥prias m√£os.  Como resultado, obtemos uma demonstra√ß√£o funcional no Android, que reconhece algo com precis√£o bastante alta.  Mas as primeiras coisas primeiro. </p><br><p><img src="https://habrastorage.org/webt/rs/7r/_f/rs7r_f7v6dywnklpaok4htwntsq.jpeg"></p><a name="habracut"></a><br><p>  Tendo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">analisado os</a> materiais mais recentes, decidiu-se contratar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tensorflow</a> , que agora est√° ganhando impulso, e artigos em ingl√™s e russo parecem ser suficientes para n√£o se aprofundar nisso e conseguir descobrir o que √© o qu√™. </p><br><p>  Passando duas semanas, estudando artigos e in√∫meras ex-amostras no escrit√≥rio.  site, percebi que n√£o entendia nada.  Muitas informa√ß√µes e op√ß√µes sobre como o Tensorflow pode ser usado.  Minha cabe√ßa j√° est√° inchada com o quanto eles oferecem solu√ß√µes diferentes e o que fazer com elas, conforme aplicado √† minha tarefa. </p><br><p><img src="https://habrastorage.org/webt/bd/2z/jy/bd2zjyct-gx0xbz9nfbwwya5aw8.png"></p><br><p>  Decidi tentar de tudo, desde as op√ß√µes mais simples e prontas (nas quais era necess√°rio registrar uma depend√™ncia no gradle e adicionar algumas linhas de c√≥digo) at√© as mais complexas (nas quais eu teria que criar e treinar modelos de gr√°fico e aprender a us√°-los em um dispositivo m√≥vel aplica√ß√£o). </p><br><p>  No final, tive que usar uma vers√£o complicada, que ser√° discutida em mais detalhes abaixo.  Enquanto isso, compilei para voc√™ uma lista de op√ß√µes mais simples que s√£o igualmente eficazes, apenas cada uma se adequa ao seu objetivo. </p><br><h3 id="1--ml-kithttpsfirebasegooglecomdocsml-kit">  1. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">KIT ML</a> </h3><br><p><img src="https://habrastorage.org/webt/al/of/8w/alof8wunrnv66f66xwv2rrlbrn0.png"></p><br><p>  A solu√ß√£o mais f√°cil de usar - algumas linhas de c√≥digo que voc√™ pode usar: </p><br><ul><li>  Reconhecimento de texto (texto, caracteres latinos) </li><li>  Detec√ß√£o de rosto (rostos, emo√ß√µes) </li><li>  Digitaliza√ß√£o de c√≥digo de barras (c√≥digo de barras, c√≥digo QR) </li><li>  Rotulagem de imagens (um n√∫mero limitado de tipos de objetos na imagem) </li><li>  Reconhecimento de pontos de refer√™ncia (atra√ß√µes) </li></ul><br><p>  √â um pouco mais complicado. Com esta solu√ß√£o, voc√™ tamb√©m pode usar seu pr√≥prio modelo TensorFlow Lite, mas a convers√£o para esse formato causou dificuldades, portanto esse item n√£o foi tentado. </p><br><p>  Conforme os criadores dessa prole escrevem, a maioria das tarefas pode ser resolvida usando esses desenvolvimentos.  Mas se isso n√£o se aplicar √† sua tarefa, voc√™ precisar√° usar modelos personalizados. </p><br><h3 id="2--custom-visionhttpswwwcustomvisionai">  2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vis√£o Personalizada</a> </h3><br><p><img src="https://habrastorage.org/webt/p9/c_/2u/p9c_2ujglvyu8mbffhrmoqpzav0.png"></p><br><p>  Uma ferramenta muito conveniente para criar e treinar seus modelos personalizados usando imagens. <br>  Dos profissionais - h√° uma vers√£o gratuita que permite manter um projeto. <br>  Dos contras - a vers√£o gratuita limita o n√∫mero de imagens "recebidas" a 3.000.  Para tentar criar uma rede med√≠ocre de precis√£o - basta.  Para tarefas mais precisas, voc√™ precisa de mais. <br>  Tudo o que √© necess√°rio para o usu√°rio √© adicionar imagens com uma marca (por exemplo - imagem1 √© "guaxinim", imagem2 √© "sol"), treinar e exportar o gr√°fico para uso futuro. </p><br><p><img src="https://habrastorage.org/webt/co/lk/nw/colknw0ljunbtzcixxdrde6qwtm.png"></p><br><p>  A Microsoft tamb√©m oferece sua pr√≥pria <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">amostra</a> , com a qual voc√™ pode experimentar o gr√°fico recebido. <br>  Para aqueles que j√° est√£o "no assunto" - o gr√°fico j√° √© gerado no estado Congelado, ou seja,  voc√™ n√£o precisa fazer / converter nada com isso. <br>  Esta solu√ß√£o √© boa quando voc√™ tem uma amostra grande e (aten√ß√£o) MUITAS aulas diferentes em treinamento.  Porque  caso contr√°rio, haver√° muitas defini√ß√µes falsas na pr√°tica.  Por exemplo, voc√™ treinou em guaxinins e s√≥is e, se houver uma pessoa na entrada, ela poder√° com igual probabilidade ser definida por um sistema como um ou outro.  Embora de fato - nem um nem o outro. </p><br><h3 id="3--sozdanie-modeli-vruchnuyu">  3. Criando um Modelo Manualmente </h3><br><p><img src="https://habrastorage.org/webt/m_/ku/r_/m_kur_ks0vdyiqoiw7h5pvbwoey.jpeg"></p><br><p>  Quando voc√™ mesmo precisa ajustar o modelo para reconhecimento de imagem, manipula√ß√µes mais complexas com a sele√ß√£o da imagem de entrada entram em cena. <br>  Por exemplo, n√£o queremos ter restri√ß√µes no volume da amostra de entrada (como no par√°grafo anterior), ou queremos treinar o modelo com mais precis√£o, definindo o n√∫mero de √©poca e outros par√¢metros de treinamento. <br>  Nesta abordagem, existem v√°rios exemplos do Tensorflow que descrevem o procedimento e o resultado final. <br>  Aqui est√£o alguns exemplos: </p><br><ul><li>  Legal codelab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tensorflow para poetas</a> . <br></li></ul><br><br><p>  Ele fornece um exemplo de como criar um classificador de tipos de cores com base no banco de dados aberto de imagens ImageNet - prepare imagens e treine o modelo.  Tamb√©m √© feita uma pequena men√ß√£o de como voc√™ pode trabalhar com uma ferramenta bastante interessante - TensorBoard.  Das suas fun√ß√µes mais simples - demonstra claramente a estrutura do seu modelo acabado, bem como o processo de aprendizado de v√°rias maneiras. </p><br><ul><li><p>  Kodlab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tensorflow for Poets 2</a> - trabalho cont√≠nuo com o classificador de cores.  Ele mostra como se voc√™ possui os arquivos gr√°ficos e seus r√≥tulos (que foram obtidos no codelab anterior), √© poss√≠vel executar o aplicativo no android.  Um dos pontos do codelab √© a convers√£o do formato "usual" de gr√°fico ".pb" para o formato Tensorflow Lite (que envolve algumas otimiza√ß√µes de arquivo para reduzir o tamanho final do arquivo gr√°fico, porque os dispositivos m√≥veis exigem isso). </p><br></li><li><p>  Reconhecimento de escrita <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MNIST</a> . <br></p><br><img src="https://habrastorage.org/webt/bz/ah/mx/bzahmxc0xozicgssbkzfqbgi1qw.gif"></li></ul><br><br><p>  O nabo cont√©m o modelo original (que j√° foi preparado para esta tarefa), instru√ß√µes sobre como trein√°-lo, convert√™-lo e como executar um projeto para Android no final para verificar como tudo funciona </p><br><p>  Com base nesses exemplos, voc√™ pode descobrir como trabalhar com modelos personalizados no Tensorflow e tentar criar o seu pr√≥prio produto ou usar um dos modelos pr√©-treinados que s√£o montados no github: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Modelos de Tensorflow</a> </p><br><p>  Falando em modelos "pr√©-treinados".  Nuances interessantes ao usar aqueles: </p><br><ul><li>  Sua estrutura j√° est√° preparada para uma tarefa espec√≠fica. </li><li>  Eles j√° s√£o treinados em grandes amostras. <br>  Portanto, se sua amostra estiver insuficientemente preenchida, voc√™ poder√° usar um modelo pr√©-treinado que tenha o escopo pr√≥ximo da sua tarefa.  Usando esse modelo, adicionando suas pr√≥prias regras de treinamento, voc√™ obter√° um resultado melhor do que tentaria trein√°-lo do zero. </li></ul><br><h3 id="4--object-detection-api---cozdanie-modeli-vruchnuyu">  4. API de detec√ß√£o de objetos + cria√ß√£o de modelo manual </h3><br><p>  No entanto, todos os par√°grafos anteriores n√£o deram o resultado desejado.  Desde o in√≠cio, foi dif√≠cil entender o que precisa ser feito e com que abordagem.  Em seguida, foi encontrado um artigo interessante sobre a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">API de detec√ß√£o de objetos</a> , que mostra como encontrar v√°rias categorias em uma imagem, al√©m de v√°rias inst√¢ncias da mesma categoria.  No processo de elabora√ß√£o desse exemplo, os artigos de origem e os tutoriais em v√≠deo sobre o reconhecimento de objetos personalizados se mostraram mais convenientes (os links estar√£o no final). </p><br><p>  Mas o trabalho n√£o poderia ter sido conclu√≠do sem um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo sobre reconhecimento de Pikachu</a> - porque uma nuance muito importante foi apontada l√°, que por algum motivo n√£o √© mencionada em nenhum lugar de um guia ou exemplo.  E sem ele, todo o trabalho realizado seria em v√£o. </p><br><p>  Ent√£o, agora, finalmente, sobre o que ainda precisava ser feito e o que aconteceu na sa√≠da. </p><br><ol><li>  Primeiro, a farinha da instala√ß√£o do Tensorflow.  Quem n√£o pode instal√°-lo ou usar os scripts padr√£o para criar, treinar um modelo - basta ter paci√™ncia e pesquisar no Google.  Quase todos os problemas j√° foram escritos em quest√µes no githib ou no stackoverflow. <br></li></ol><br>  De acordo com as instru√ß√µes para o reconhecimento de objetos, precisamos preparar uma amostra de entrada antes de treinar o modelo.  Estes artigos descrevem em detalhes como fazer isso usando uma ferramenta conveniente - labelImg.  A √∫nica dificuldade aqui √© fazer um trabalho muito longo e meticuloso para destacar os limites dos objetos de que precisamos.  Nesse caso, carimba nas imagens dos documentos. <br><br><img src="https://habrastorage.org/webt/ge/hh/x_/gehhx_5fqfezu1sbh5tvoofss20.png"><br>  A pr√≥xima etapa, usando scripts prontos, exportamos os dados da etapa 2 primeiro para arquivos csv, depois para TFRecords - o formato de dados de entrada Tensorflow.  Nenhuma dificuldade deve surgir aqui. <br>  A escolha de um modelo pr√©-treinado, com base no qual pr√©-treinamos o gr√°fico, bem como o pr√≥prio treinamento.  √â aqui que o maior n√∫mero de erros desconhecidos pode ocorrer, cuja causa √© desinstalar (ou instalar incorretamente) os pacotes necess√°rios para o trabalho.  Mas voc√™ ter√° sucesso, n√£o se desespere, o resultado vale a pena. <br><br><img src="https://habrastorage.org/webt/9y/qw/1b/9yqw1boyubfcrrf5jcaylkjjtyo.jpeg"><br>  Exporte o arquivo recebido ap√≥s o treinamento para o formato 'pb'.  Basta selecionar o √∫ltimo arquivo 'ckpt' e export√°-lo. <br>  Executando um exemplo de trabalho no Android. <br>  Fazendo download da amostra oficial de reconhecimento de objeto no Tensorflow github - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TF Detect</a> .  Insira seu modelo e arquivo com etiquetas l√°.  Mas  Nada vai funcionar. <br><br><img src="https://habrastorage.org/webt/kj/3k/o4/kj3ko4d3ywoap8ff6oknuwova7c.gif"><br><br><p>  √â aqui que a maior morda√ßa em todo o trabalho aconteceu, por incr√≠vel que pare√ßa - bem, as amostras do Tensorflow n√£o queriam trabalhar de forma alguma.  Tudo caiu.  Somente o poderoso Pikachu com seu artigo conseguiu ajudar a trazer tudo para o trabalho. <br>  A primeira linha no arquivo labels.txt deve ser a inscri√ß√£o "???", porque  por padr√£o, na API de detec√ß√£o de objetos, os n√∫meros de identifica√ß√£o dos objetos n√£o come√ßam com 0 como de costume, mas com 1. Devido ao fato de a classe nula ser reservada, perguntas m√°gicas devem ser indicadas.  I.e.  seu arquivo de tag ser√° mais ou menos assim: </p><br><pre><code class="hljs">??? stamp</code> </pre> <br><p>  E ent√£o - execute a amostra e veja o reconhecimento dos objetos e o n√≠vel de confian√ßa com que foi recebido. </p><br><p><img src="https://habrastorage.org/webt/ly/kr/dm/lykrdma-x9h8epuqsuah3gkr3bk.png"><img src="https://habrastorage.org/webt/ne/lm/7v/nelm7v8rpjiuhzhevlptp0dc-fa.png"><img src="https://habrastorage.org/webt/9t/ci/4r/9tci4rxzhixufdjhb5ecpdof0ik.png"></p><br><p>  Assim, o resultado √© uma aplica√ß√£o simples que, quando voc√™ passa o mouse sobre a c√¢mera, reconhece os limites do carimbo no documento e os indica juntamente com a precis√£o do reconhecimento. <br>  E se excluirmos o tempo gasto procurando a abordagem correta e tentando lan√ß√°-la, o trabalho acabou sendo bastante r√°pido e realmente n√£o complicado.  Voc√™ s√≥ precisa conhecer as nuances antes de come√ßar o trabalho. </p><br><p>  J√° como uma se√ß√£o adicional (aqui voc√™ j√° pode fechar o artigo se estiver cansado das informa√ß√µes), gostaria de escrever algumas dicas que ajudaram a trabalhar com tudo isso. </p><br><ul><li><p>  frequentemente, os scripts tensorflow n√£o funcionavam porque eram executados nos diret√≥rios errados.  Al√©m disso, era diferente em PCs diferentes: algu√©m precisava executar a partir do <code>tensroflowmodels/models/research</code> para o trabalho e algu√©m <code>tensroflowmodels/models/research/object-detection</code> n√≠vel mais profundo do <code>tensroflowmodels/models/research/object-detection</code> </p><br></li><li><p>  lembre-se de que para cada terminal aberto voc√™ precisa exportar o caminho novamente usando o comando </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">export</span></span> PYTHONPATH=/  /tensroflowmodels/models/research/slim:<span class="hljs-variable"><span class="hljs-variable">$PYTHONPATH</span></span></code> </pre> <br></li><li><p>  se voc√™ n√£o estiver usando seu pr√≥prio gr√°fico e quiser descobrir informa√ß√µes sobre ele (por exemplo, " <code>input_node_name</code> ", necess√°rio posteriormente), execute dois comandos na pasta raiz: </p><br><pre> <code class="hljs powershell">bazel build tensorflow/tools/graph_transforms:summarize_graph bazel<span class="hljs-literal"><span class="hljs-literal">-bin</span></span>/tensorflow/tools/graph_transforms/summarize_graph -<span class="hljs-literal"><span class="hljs-literal">-in_graph</span></span>=<span class="hljs-string"><span class="hljs-string">"/  /frozen_inference_graph.pb"</span></span></code> </pre> <br><p>  onde " <code>/  /frozen_inference_graph.pb</code> " √© o caminho para o gr√°fico que voc√™ deseja conhecer </p><br></li><li><p>  Para visualizar informa√ß√µes sobre o gr√°fico, voc√™ pode usar o Tensorboard. </p><br><pre> <code class="hljs powershell">python import_pb_to_tensorboard.py -<span class="hljs-literal"><span class="hljs-literal">-model_dir</span></span>=output/frozen_inference_graph.pb -<span class="hljs-literal"><span class="hljs-literal">-log_dir</span></span>=training</code> </pre> <br><p>  onde voc√™ precisa especificar o caminho para o gr√°fico ( <code>model_dir</code> ) e o caminho para os arquivos que foram recebidos durante o treinamento ( <code>log_dir</code> ).  Em seguida, basta abrir o host local no navegador e observar o que lhe interessa. </p><br></li></ul><br><p>  E a √∫ltima parte - no trabalho com scripts python nas instru√ß√µes da API de detec√ß√£o de objetos - foi preparada uma pequena folha de dicas abaixo com comandos e dicas. </p><br><div class="spoiler">  <b class="spoiler_title">Folha de dicas</b> <div class="spoiler_text"><p>  Exportar de labelimg para csv (do diret√≥rio object_detection) </p><br><pre> <code class="hljs mel"><span class="hljs-keyword"><span class="hljs-keyword">python</span></span> xml_to_csv.py</code> </pre> <br><p>  Al√©m disso, todas as etapas listadas abaixo devem ser executadas na mesma pasta Tensorflow (" <code>tensroflowmodels/models/research/object-detection</code> " ou um n√≠vel acima - dependendo de como voc√™ for) - isso √© tudo imagens da sele√ß√£o de entrada, TFRecords e outros arquivos devem ser copiados dentro deste diret√≥rio antes de iniciar o trabalho. </p><br><p>  Exportar de csv para tfrecord </p><br><pre> <code class="hljs powershell">python generate_tfrecord.py -<span class="hljs-literal"><span class="hljs-literal">-csv_input</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/train_labels.csv -<span class="hljs-literal"><span class="hljs-literal">-output_path</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/train.record python generate_tfrecord.py -<span class="hljs-literal"><span class="hljs-literal">-csv_input</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/test_labels.csv -<span class="hljs-literal"><span class="hljs-literal">-output_path</span></span>=<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/test.record</code> </pre> <br><p>  * N√£o esque√ßa de alterar as linhas 'train' e 'test' nos caminhos do pr√≥prio arquivo (generate_tfrecord.py), bem como <br>  o nome das classes reconhecidas na fun√ß√£o <code>class_text_to_int</code> (que deve ser duplicada no arquivo <code>pbtxt</code> que voc√™ criar√° antes de treinar o gr√°fico). </p><br><p>  Treinamento </p><br><pre> <code class="hljs powershell">python legacy/train.py ‚Äîlogtostderr -<span class="hljs-literal"><span class="hljs-literal">-train_dir</span></span>=training/ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/ssd_mobilenet_v1_coco.config</code> </pre> <br><p>  ** Antes do treinamento, n√£o se esque√ßa de verificar o arquivo " <code>training/object-detection.pbtxt</code> <code>training/ssd_mobilenet_v1_coco.config</code> " - deve haver todas as classes reconhecidas e o arquivo " <code>training/ssd_mobilenet_v1_coco.config</code> " - √© necess√°rio alterar o par√¢metro " <code>num_classes</code> " para o n√∫mero de suas classes. </p><br><p>  Exportar modelo para pb </p><br><pre> <code class="hljs powershell">python export_inference_graph.py \ -<span class="hljs-literal"><span class="hljs-literal">-input_type</span></span>=image_tensor \ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/pipeline.config \ -<span class="hljs-literal"><span class="hljs-literal">-trained_checkpoint_prefix</span></span>=training/model.ckpt<span class="hljs-literal"><span class="hljs-literal">-110</span></span> \ -<span class="hljs-literal"><span class="hljs-literal">-output_directory</span></span>=output</code> </pre> </div></div><br><p>  Obrigado pelo seu interesse neste t√≥pico! </p><br><p>  Refer√™ncias </p><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigo original sobre reconhecimento de objetos</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um ciclo de v√≠deo para o artigo sobre o reconhecimento de objetos em ingl√™s</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O conjunto de scripts que foram usados ‚Äã‚Äãno artigo original</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt427449/">https://habr.com/ru/post/pt427449/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt427437/index.html">Configurando servidores vinculados: ms sql server e teradata</a></li>
<li><a href="../pt427439/index.html">Toda a verdade sobre o RTOS. Artigo 16. Signals</a></li>
<li><a href="../pt427441/index.html">Converg√™ncia com Kubernetes</a></li>
<li><a href="../pt427443/index.html">Vivissec√ß√£o do sucesso</a></li>
<li><a href="../pt427447/index.html">PVS-Studio inclui suporte para o GNU Arm Embedded Toolchain</a></li>
<li><a href="../pt427451/index.html">Conectar tarefas do phpStorm ao Bitrix24</a></li>
<li><a href="../pt427453/index.html">Como eu fiz a transmiss√£o de som no Raspberry Pi</a></li>
<li><a href="../pt427457/index.html">A Terceira Onda de Intelig√™ncia Artificial e Sistemas de Seguran√ßa do Estado</a></li>
<li><a href="../pt427459/index.html">L√¢mpadas LED Diall da loja Castorama</a></li>
<li><a href="../pt427461/index.html">A beleza das fun√ß√µes N√ÉO an√¥nimas em JavaScript</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
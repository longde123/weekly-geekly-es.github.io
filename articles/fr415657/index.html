<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë≠ üì¢ üòó Vision industrielle pour le commerce de d√©tail. Comment lire les √©tiquettes de prix dans un magasin üå∑ üå¶Ô∏è üöÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La vision industrielle est un sujet tr√®s br√ªlant de nos jours. Pour r√©soudre le probl√®me de la reconnaissance des balises de magasin √† l'aide de r√©sea...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vision industrielle pour le commerce de d√©tail. Comment lire les √©tiquettes de prix dans un magasin</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sap/blog/415657/"> La vision industrielle est un sujet tr√®s br√ªlant de nos jours.  Pour r√©soudre le probl√®me de la reconnaissance des balises de magasin √† l'aide de r√©seaux de neurones, nous avons choisi le framework TensorFlow. <br><br>  L'article expliquera exactement comment l'utiliser pour localiser et identifier plusieurs objets sur la m√™me √©tiquette de prix de magasin, ainsi que pour reconna√Ætre son contenu.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Une t√¢che similaire de reconnaissance des √©tiquettes de prix IKEA a d√©j√† √©t√© r√©solue sur Habr√© √† l'</a> aide des outils classiques de traitement d'image disponibles dans la biblioth√®que OpenCV. <br><br>  Par ailleurs, je voudrais noter que la solution peut fonctionner √† la fois sur la plate-forme SAP HANA en conjonction avec Tensorflow Serving et sur la plate-forme SAP Cloud. <br><br>  La t√¢che de reconna√Ætre le prix des marchandises est pertinente pour les acheteurs qui veulent "√©changer" les prix entre eux et choisir un magasin pour les achats, et pour les d√©taillants - ils veulent en savoir plus sur les prix des concurrents en temps r√©el. <br><br>  Assez de paroles - allez √† la technique! <br><a name="habracut"></a><br>  <b>Bo√Æte √† outils</b> <br><br>  Pour la d√©tection et la classification des images, nous avons utilis√© des r√©seaux de neurones convolutionnels impl√©ment√©s dans la biblioth√®que TensorFlow et disponibles pour le contr√¥le via l'API Object Detection. <br>  L'API de d√©tection d'objets TensorFlow est une m√©taframe open source bas√©e sur TensorFlow qui simplifie la cr√©ation, la formation et le d√©ploiement de mod√®les pour la d√©tection d'objets. <br><br>  Apr√®s avoir d√©tect√© l'objet souhait√©, la reconnaissance de texte a √©t√© effectu√©e √† l'aide de Tesseract, une biblioth√®que de reconnaissance de caract√®res.  Depuis 2006, Tesseract est consid√©r√©e comme l'une des biblioth√®ques OCR les plus pr√©cises disponibles en open source. <br><br>  Il est possible que vous posiez une question - pourquoi tout le traitement ne se fait-il pas sur TF?  La r√©ponse est tr√®s simple - il faudrait beaucoup plus de temps pour l'impl√©mentation, mais il n'y en avait pas beaucoup de toute fa√ßon.  Il √©tait plus facile de sacrifier la vitesse de traitement et d'assembler un prototype fini que de s'emb√™ter avec un OCR fait maison. <br><br>  <b>Cr√©ation et pr√©paration d'un jeu de donn√©es</b> <br><br>  Pour commencer, il fallait collecter des mat√©riaux pour le travail.  Nous avons visit√© 3 magasins et pris environ 400 photos d'√©tiquettes de prix diff√©rentes sur un appareil photo de t√©l√©phone portable en mode automatique <br><br>  <i>Exemples de photos:</i> <br><br><img src="https://habrastorage.org/webt/bp/re/ql/bpreqlti9nccwxxkuu-ubgg5e7s.png"><br>  <i>Fig.</i>  <i>1. Exemple d'image d'√©tiquette de prix</i> <br><br><img src="https://habrastorage.org/webt/4u/cn/9f/4ucn9fztbym8gbhpwum28rgmigg.png"><br>  <i>Fig.</i>  <i>2. Exemple d'image d'√©tiquette de prix</i> <br><br>  Apr√®s cela, vous devez traiter et marquer toutes les photos des √©tiquettes de prix.  Dans le processus de collecte d'images, nous avons essay√© de collecter des images de haute qualit√© (sans artefacts): √©tiquettes de prix approximativement du m√™me format, sans flou, rotations importantes, etc.  Cela a √©t√© fait pour faciliter la comparaison du contenu sur le prix r√©el et de son image num√©rique.  Cependant, si nous formons le r√©seau neuronal uniquement sur les images de haute qualit√© disponibles, cela conduira tr√®s naturellement au fait que la confiance du mod√®le dans l'identification des exemples d√©form√©s diminuera consid√©rablement.  Afin d'entra√Æner le r√©seau neuronal √† r√©sister √† de telles situations, nous avons utilis√© la proc√©dure bien connue pour √©largir l'ensemble d'entra√Ænement avec des versions d√©form√©es d'images (augmentation).  Pour compl√©ter l'√©chantillon d'apprentissage, nous avons appliqu√© des algorithmes de la biblioth√®que Imgaug: d√©calages, petits virages, flou gaussien, bruit.  Des images d√©form√©es ont √©t√© ajout√©es √† l'√©chantillon, ce qui l'a augment√© d'environ 5 fois (de 300 √† 1 500 images). <br><br>  Pour marquer l'image et s√©lectionner des objets, le programme LabelImg a √©t√© utilis√©, qui est disponible dans le domaine public.  Il vous permet de s√©lectionner les objets n√©cessaires dans l'image avec un rectangle et d'affecter chaque classe au cadre de s√©lection.  Toutes les coordonn√©es et les √©tiquettes des cadres cr√©√©s pour chaque photo sont enregistr√©es dans un fichier XML distinct. <br><br>  Les objets suivants se d√©marquent sur chaque photo: √©tiquette de prix du produit, prix du produit, nom du produit et code-barres du produit sur l'√©tiquette de prix.  Dans certains exemples d'images, o√π cela √©tait logiquement justifi√©, les zones √©taient marqu√©es par un chevauchement. <br><br><img src="https://habrastorage.org/webt/bp/ib/k-/bpibk-12lzq1m0jpaf4pxs0omak.png"><br>  <i>Fig.</i>  <i>3. Un exemple de photographie d'une paire d'√©tiquettes de prix marqu√©es dans LabelImg.</i>  <i>Les zones avec la description du produit, le prix et le code-barres sont mises en √©vidence.</i> <br><br><img src="https://habrastorage.org/webt/yl/nx/sl/ylnxslebkaqu778rxyomixqdvby.png"><br>  <i>Fig.</i>  <i>4. Un exemple de photographie d'une √©tiquette de prix marqu√©e dans LabelImg.</i>  <i>Les zones avec la description du produit, le prix et le code-barres sont mises en √©vidence.</i> <br><br>  Une fois que toutes les photos ont √©t√© trait√©es et marqu√©es, nous pr√©parons l'ensemble de donn√©es avec la s√©paration de toutes les photos et des fichiers de balises en un √©chantillon de formation et de test.  Prenez habituellement 80% de l'√©chantillon d'apprentissage √† 20% de l'√©chantillon d'essai et m√©langez au hasard. <br><br>  Ensuite, sur la machine o√π le mod√®le sera form√©, il est n√©cessaire d'installer toutes les biblioth√®ques n√©cessaires.  Tout d'abord, nous installons la biblioth√®que d'apprentissage automatique TensorFlow.  Selon le type de votre syst√®me et vous devez installer une biblioth√®que suppl√©mentaire pour l'informatique sur le GPU.  Ensuite, installez la biblioth√®que d'API de d√©tection d'objets Tensorflow et des biblioth√®ques suppl√©mentaires pour travailler avec des images et des graphiques.  Voici une liste des biblioth√®ques que nous avons utilis√©es dans notre travail: <br><br>  <i>TensorFlow-GPU v1.5, CUDA v9.0, cuDNN v7.0</i> <i><br></i>  <i>Protobuf 3+, Python-tk, Pillow 1.0, lxml, tf Slim, notebook Jupyter, Matplotlib</i> <i><br></i>  <i>Tensorflow, Cython, Cocoapi;</i>  <i>Opencv-python;</i>  <i>Pandas</i> <br><br>  Une fois toutes les √©tapes d'installation termin√©es, vous pouvez proc√©der √† la pr√©paration des donn√©es et √† la d√©finition des param√®tres d'apprentissage. <br><br>  <b>Formation mod√®le</b> <br><br>  Pour r√©soudre notre probl√®me, nous avons utilis√© deux versions du r√©seau neuronal pr√©-form√© MobileNet V2 et Faster-RCNN V2 sur le jeu de donn√©es coco comme extracteurs de propri√©t√©s d'image.  Les mod√®les ont √©t√© recycl√©s en 4 nouvelles classes: √©tiquette de prix, description du produit, prix, code-barres.  Comme principal, nous avons choisi MobileNet V2, qui est un mod√®le relativement simple qui nous permet de fournir une qualit√© acceptable √† une vitesse agr√©able.  MobileNet V2 vous permet d'impl√©menter la reconnaissance d'image m√™me sur un appareil mobile. <br><br>  Tout d'abord, vous devez indiquer √† la biblioth√®que d'API de d√©tection d'objets Tensorflow le nombre d'√©tiquettes, ainsi que les noms de ces √©tiquettes. <br><br>  La derni√®re chose √† faire avant l'entra√Ænement est de cr√©er un raccourci et de modifier le fichier de configuration.  La mappe d'√©tiquettes informe le mod√®le et mappe les noms de classe aux num√©ros d'identification de classe pour chaque objet. <br><br><img src="https://habrastorage.org/webt/xp/4x/xu/xp4xxucl6kfbkukwqwkmqrahwbk.png"><br><br>  Enfin, vous devez configurer les sources d'apprentissage pour la d√©tection d'objets pour d√©terminer quel mod√®le et quels param√®tres seront utilis√©s pour la formation.  C'est la derni√®re √©tape avant de commencer l'entra√Ænement. <br><br><img src="https://habrastorage.org/webt/ci/of/zi/ciofzi9v6s53lb-tusznaisw5ss.png"><br><br>  La proc√©dure de formation est lanc√©e par la commande: <br><br><pre><code class="hljs powershell">python train.py -<span class="hljs-literal"><span class="hljs-literal">-logtostderr</span></span> -<span class="hljs-literal"><span class="hljs-literal">-train_dir</span></span>=training/ -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span>=training/mobilenet.config</code> </pre> <br>  Si tout est correctement configur√©, TensorFlow initialise le recyclage du r√©seau neuronal.  L'initialisation peut prendre jusqu'√† 30 secondes avant le d√©but de la formation proprement dite.  Comme le r√©seau neuronal est recycl√© √† chaque √©tape, la valeur de la fonction d'erreur d'algorithme (perte) sera affich√©e.  Pour MobileNet V2, la valeur initiale de la fonction de perte est d'environ 20. Le mod√®le doit √™tre form√© jusqu'√† ce que la fonction de perte tombe √† une valeur d'environ 2. Pour visualiser le processus d'apprentissage du r√©seau de neurones, vous pouvez utiliser l'utilitaire pratique TensorBoard. <br><br><pre> <code class="hljs pgsql">: tensorboard <span class="hljs-comment"><span class="hljs-comment">--logdir=training</span></span></code> </pre> <br>  La commande initialise l'interface Web sur la machine locale, qui sera disponible sur localhost: 6006.  Apr√®s l'arr√™t, la proc√©dure de formation peut √™tre reprise plus tard √† l'aide de points de contr√¥le enregistr√©s toutes les 5 minutes. <br><br>  <b>Reconnaissance des √©tiquettes de prix et de ses √©l√©ments</b> <br><br>  Une fois la formation termin√©e, la derni√®re √©tape consiste √† cr√©er un graphe de r√©seau neuronal.  Cela se fait par la commande console, o√π sous les ast√©risques vous devez sp√©cifier le plus grand nombre de fichiers cpkt existant dans le r√©pertoire de formation. <br><br><pre> <code class="hljs powershell">python export_inference_graph.py -<span class="hljs-literal"><span class="hljs-literal">-input_type</span></span> image_tensor -<span class="hljs-literal"><span class="hljs-literal">-pipeline_config_path</span></span> training/faster_rcnn_inception_v2.config -<span class="hljs-literal"><span class="hljs-literal">-trained_checkpoint_prefix</span></span> training/model.ckpt-**** -<span class="hljs-literal"><span class="hljs-literal">-output_directory</span></span> inference_graph</code> </pre> <br>  Apr√®s cette proc√©dure, le classificateur de d√©tection d'objet est pr√™t √† fonctionner.  Pour v√©rifier la reconnaissance d'image, il suffit d'ex√©cuter un script fourni avec la biblioth√®que de d√©tection d'objets Tensorflow indiquant le mod√®le qui a √©t√© pr√©c√©demment form√© et les photos √† reconna√Ætre.  Un exemple de script Python standard est fourni <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Dans notre exemple, il faut environ 1,5 seconde pour reconna√Ætre une photo √† l'aide du mod√®le ssd mobilenet sur un simple ordinateur portable. <br><br><img src="https://habrastorage.org/webt/nd/uw/ev/nduwevuhylmr-xtfs9wcr6nmvwa.png"><br>  <i>Fig.</i>  <i>5. Le r√©sultat de la reconnaissance d'images avec des √©tiquettes de prix dans l'√©chantillon de test</i> <br><br><img src="https://habrastorage.org/webt/or/-4/w-/or-4w-dq93_tjn2oj4y4f0icpag.png"><br>  <i>Fig.</i>  <i>6. Le r√©sultat de la reconnaissance d'images avec des √©tiquettes de prix dans l'√©chantillon d'essai</i> <br><br>  Lorsque nous sommes convaincus que les √©tiquettes de prix sont d√©tect√©es normalement, il est n√©cessaire d'apprendre au mod√®le √† lire les informations des √©l√©ments individuels: le prix des marchandises, le nom des marchandises et un code √† barres.  Pour cela, il existe des biblioth√®ques disponibles en Python pour reconna√Ætre les caract√®res et codes-barres dans les photographies - Pyzbar et Tesseract. <br><br>  Avant de commencer √† reconna√Ætre les caract√®res et les codes-barres d'une photo, vous devez d√©couper cette photo en √©l√©ments dont nous avons besoin - afin d'augmenter la vitesse et de ne pas reconna√Ætre les informations inutiles qui ne sont pas incluses dans le prix.  Il est √©galement n√©cessaire de ¬´retirer¬ª les coordonn√©es des objets que le mod√®le a reconnus avec leurs classes. <br><br><img src="https://habrastorage.org/webt/hc/dk/g6/hcdkg6ngmc1l8no5paqiwm9ewga.png"><br><br>  Ensuite, nous utilisons ces coordonn√©es pour couper notre photo en parties afin de reconna√Ætre uniquement la zone n√©cessaire. <br><br><img src="https://habrastorage.org/webt/tq/2c/q7/tq2cq7ri8ecarbn2i0qmgssexug.png"><br><img src="https://habrastorage.org/webt/hg/vi/ss/hgvissbwiljgcity6q51rt0wgg8.png"><br><img src="https://habrastorage.org/webt/db/gb/lt/dbgbltacl6uwrhswvqlw196h7rm.png"><br>  <i>Fig.</i>  <i>7. Un exemple de parties en surbrillance de l'√©tiquette de prix</i> <br><br>  Ensuite, nous transf√©rons toutes les zones de d√©coupe dans les biblioth√®ques: le nom du produit et le prix du produit sont transf√©r√©s vers tesseract, et le code-barres vers pyzbar, et nous obtenons le r√©sultat de la reconnaissance. <br><br><img src="https://habrastorage.org/webt/pn/oo/sc/pnooscbtqlhzdbbrkza9wzim_0a.png"><br><img src="https://habrastorage.org/webt/ib/gk/wb/ibgkwblzbbfmxzwie-5p4zr-4-0.png"><br>  <i>Fig.</i>  <i>8. Un exemple de contenu reconnu est la zone d'√©tiquette de prix.</i> <br><br>  √Ä ce stade, la reconnaissance du texte et des codes √† barres peut entra√Æner des probl√®mes si l'image d'origine √©tait en basse r√©solution ou floue.  Si le prix peut √™tre reconnu normalement en raison des grands nombres sur l'√©tiquette de prix, alors le nom du produit et le code-barres seront mal d√©finis ou pas du tout d√©finis.  Pour ce faire, il est recommand√© de ne pas utiliser de petites photos pour la reconnaissance, et √©galement de t√©l√©charger des images sans bruit et forte distorsion - par exemple, sans le manque de mise au point appropri√©e. <br><br>  Exemple de reconnaissance d'image incorrecte: <br><br><img src="https://habrastorage.org/webt/gs/gr/qm/gsgrqms2iy2x3j0ipckqhxvd3x4.png"><br><img src="https://habrastorage.org/webt/kc/od/bn/kcodbnaech2u4gr_2qp4j1qorlk.png"><br><img src="https://habrastorage.org/webt/sg/tv/ve/sgtvvedm0i1ssvdhuzmypadxb-0.png"><br><img src="https://habrastorage.org/webt/d7/cf/kj/d7cfkjdswbwqelwrbs1hcd_3yrc.png"><br>  <i>Fig.</i>  <i>9. Un exemple de parties en surbrillance d'une √©tiquette de prix floue et d'un contenu reconnu</i> <br><br>  Dans cet exemple, vous pouvez voir que si le prix des marchandises √©tait reconnu plus ou moins correctement √† l'image de la mauvaise qualit√©, la biblioth√®que ne pourrait pas g√©rer le nom des marchandises.  Et le code-barres n'est pas du tout reconnu. <br><br>  Le m√™me texte de bonne qualit√©. <br><br><img src="https://habrastorage.org/webt/yr/q0/kv/yrq0kvrbtwcyj7sbg_jknpwfgyg.png"><br><img src="https://habrastorage.org/webt/wh/cj/2m/whcj2mkjm-lafollpostyctv_lg.png"><br>  <i>Fig.</i>  <i>10. Exemple de pi√®ces d'√©tiquette de prix mises en √©vidence et de contenu reconnu</i> <br><br>  <b>Conclusions</b> <br><br>  Au final, nous avons r√©ussi √† obtenir un mod√®le de qualit√© acceptable avec un faible pourcentage d'erreurs et un pourcentage √©lev√© de d√©tection d'objets pertinents.  Faster-RCNN Inception V2 a une meilleure qualit√© de reconnaissance que MobileNet SSD V2, mais est d'environ un ordre de grandeur inf√©rieur √† la vitesse, ce qui est une limitation importante. <br><br>  La pr√©cision obtenue de la reconnaissance des √©tiquettes de prix sur un √©chantillon retard√© de 50 images est de 100%, c'est-√†-dire que toutes les √©tiquettes de prix ont √©t√© identifi√©es avec succ√®s sur toutes les photos.  La pr√©cision de reconnaissance des zones avec un code-barres et un prix √©tait de 90%.  La pr√©cision de reconnaissance de la zone de texte est de 85%.  La pr√©cision de la lecture des prix √©tait d'environ 95%, et le texte - 80-85%.  De plus, √† titre exp√©rimental, nous pr√©sentons le r√©sultat de la reconnaissance des √©tiquettes de prix, qui est compl√®tement diff√©rent des √©tiquettes de prix dans l'√©chantillon de formation. <br><br><img src="https://habrastorage.org/webt/_c/8d/ez/_c8dezdcd7wqlpkjycogphibwau.png"><br>  <i>Fig.</i>  <i>11. Un exemple de reconnaissance d'√©tiquettes de prix atypiques qui ne font pas partie de l'ensemble de formation.</i> <br><br>  Comme vous pouvez le voir, m√™me avec des √©tiquettes de prix qui sont sensiblement diff√©rentes des √©tiquettes de prix de formation, les mod√®les ne sont pas sans erreurs, mais des objets importants peuvent √™tre reconnus sur l'√©tiquette de prix. <br><br>  <b>Que pourrait-on faire d'autre?</b> <br><br>  1) Un article int√©ressant sur l'augmentation automatique a r√©cemment √©t√© publi√©, dont l'approche peut √™tre utilis√©e <br>  2) Le mod√®le form√© fini peut et doit √™tre sensiblement comprim√© <br>  3) Exemples de publication de services finis dans SCP et TFS <br><br>  <i>Pour pr√©parer le prototype et cet article, les mat√©riaux suivants ont √©t√© utilis√©s:</i> <br><br>  1. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apporter le Machine Learning (TensorFlow) √† l'entreprise avec SAP HANA</a> <br>  2. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Fondation SAP Leonardo ML - Apportez votre propre mod√®le (BYOM)</a> <br>  3. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©f√©rentiel GitHub de d√©tection d'objets TensorFlow</a> <br>  4. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article sur la reconnaissance des ch√®ques IKEA</a> <br>  5. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article sur les avantages de MobileNet</a> <br>  6. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article sur la d√©tection d'objets TensorFlow</a> <br><br>  <i>L'article a √©t√© pr√©par√© par:</i> <i><br></i>  <i>Sergey Abdurakipov, Dmitry Buslov, Alexey Khristenko</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr415657/">https://habr.com/ru/post/fr415657/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr415645/index.html">Un aper√ßu de Highload ++ de Sib√©rie</a></li>
<li><a href="../fr415647/index.html">√Ä partir du 1er juillet, les services Internet sont requis pour stocker les messages des utilisateurs russes pendant 6 mois</a></li>
<li><a href="../fr415649/index.html">5G vs Wi-Fi: attentes et r√©alit√©</a></li>
<li><a href="../fr415651/index.html">D√©couverte de mol√©cules organiques complexes sur le satellite de Saturne</a></li>
<li><a href="../fr415655/index.html">D√©butant ou confirm√©? Comment embaucher un d√©veloppeur mobile pour iOS qui sait vraiment comment</a></li>
<li><a href="../fr415659/index.html">La pratique de travailler avec des threads dans Node.js 10.5.0</a></li>
<li><a href="../fr415661/index.html">Les rapports sur le rendement des employ√©s sont une perte de temps</a></li>
<li><a href="../fr415663/index.html">Pages de l'histoire d'Intel. 1101 - le premier MOS avec obturateur en silicium</a></li>
<li><a href="../fr415665/index.html">Fournir un travail de site rapide dans le cadre du pipeline de d√©veloppement</a></li>
<li><a href="../fr415667/index.html">L'√©quation de Drake ne fonctionne pas - et voici comment y rem√©dier</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
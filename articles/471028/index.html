<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤸🏾 🤳🏻 👵🏿 Carro para camiones ROS. Parte 6. Odometría con codificadores de rueda, mapa de habitación, lidar 💴 👲🏼 🍭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Publicaciones en la serie: 
 8. Controlamos desde el control del teléfono ROS, nodo GPS 
 7. Localización de robots: gmapping, AMCL, puntos de referen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Carro para camiones ROS. Parte 6. Odometría con codificadores de rueda, mapa de habitación, lidar</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471028/"> Publicaciones en la serie: <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">8. Controlamos desde el control del teléfono ROS, nodo GPS</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">7. Localización de robots: gmapping, AMCL, puntos de referencia en el mapa de la sala</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">6. Odometría con codificadores de rueda, mapa de habitación, lidar</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">5. Trabajamos en rviz y gazebo: xacro, nuevos sensores.</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">4. Cree una simulación de robot utilizando los editores rviz y gazebo.</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3. Acelera, cambia la cámara, arregla la marcha</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2. Software</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1. hierro</a> <br><br>  La última vez, diseñamos el proyecto como módulos xacro separados, agregamos una cámara de video virtual e imu (giroscopio). <br><br>  En esta publicación, trabajaremos con odometría a partir de codificadores ópticos montados en ejes de ruedas, cargaremos un mapa de la habitación y lo montaremos en un carro robot real. <br><a name="habracut"></a><br><h3>  Odometria y tf </h3><br>  Lo que es odometría y tf y cómo se implementan generalmente en ROS ya está bien descrito en el recurso, por lo que nos referimos a los artículos relevantes en la parte de teoría, por ejemplo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> . <br>  Habiendo comenzado desde la base teórica, trabajaremos con práctica. <br><br>  Comencemos trabajando en un robot carro conectándolo a través de VNC. <br><br>  Vaya a la carpeta rosbots_driver y cree un nodo de archivo.  Este archivo generará odometría, recibiéndolo desde codificadores ópticos, que a su vez lo envían a arduino uno y luego a raspberry pi. <br><br><pre><code class="plaintext hljs">cd /home/pi/rosbots_catkin_ws/src/rosbots_driver/scripts/rosbots_driver touch diff-tf.py</code> </pre> <br>  Ponemos el código en el archivo: <br><br><div class="spoiler">  <b class="spoiler_title">diff_tf.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/env python """ diff_tf.py - follows the output of a wheel encoder and creates tf and odometry messages. some code borrowed from the arbotix diff_controller script A good reference: http://rossum.sourceforge.net/papers/DiffSteer/ Copyright (C) 2012 Jon Stephan. """ import rospy #import roslib #roslib.load_manifest('differential_drive') from math import sin, cos, pi from geometry_msgs.msg import Quaternion from geometry_msgs.msg import Twist from geometry_msgs.msg import Vector3 from nav_msgs.msg import Odometry import tf from tf.broadcaster import TransformBroadcaster from std_msgs.msg import Int16, Int32, Int64, UInt32 ############################################################################# class DiffTf: ############################################################################# ############################################################################# def __init__(self): ############################################################################# rospy.init_node("diff_tf") self.nodename = rospy.get_name() rospy.loginfo("-I- %s started" % self.nodename) #### parameters ####### #Wheel radius : 0.0325 # wheel circum = 2* 3.14 * 0.0325 = 0.2041 # One rotation encoder ticks : 8 ticks # For 1 meter: 8 * ( 1 / 0.2041) = 39 ticks self.rate = rospy.get_param('~rate',10.0) # the rate at which to publish the transform self.ticks_meter = float(rospy.get_param('ticks_meter', 190)) # The number of wheel encoder ticks per meter of travel self.base_width = float(rospy.get_param('~base_width', 0.11)) # The wheel base width in meters self.base_frame_id = rospy.get_param('~base_frame_id','base_link') # basefootprint /the name of the base frame of the robot self.odom_frame_id = rospy.get_param('~odom_frame_id', 'odom') # the name of the odometry reference frame self.encoder_min = rospy.get_param('encoder_min', -2147483648) self.encoder_max = rospy.get_param('encoder_max', 2147483648) self.encoder_low_wrap = rospy.get_param('wheel_low_wrap', (self.encoder_max - self.encoder_min) * 0.3 + self.encoder_min ) self.encoder_high_wrap = rospy.get_param('wheel_high_wrap', (self.encoder_max - self.encoder_min) * 0.7 + self.encoder_min ) self.t_delta = rospy.Duration(1.0/self.rate) self.t_next = rospy.Time.now() + self.t_delta # internal data self.enc_left = None # wheel encoder readings self.enc_right = None self.left = 0 # actual values coming back from robot self.right = 0 self.lmult = 0 self.rmult = 0 self.prev_lencoder = 0 self.prev_rencoder = 0 self.x = 0 # position in xy plane self.y = 0 self.th = 0 self.dx = 0 # speeds in x/rotation self.dr = 0 self.yaw = 0.01 self.pitch = 0.01 self.roll = 0.01 self.then = rospy.Time.now() self.quaternion_1 = Quaternion() # subscriptions rospy.Subscriber("wheel_ticks_left", UInt32, self.lwheelCallback) rospy.Subscriber("wheel_ticks_right", UInt32, self.rwheelCallback) #rospy.Subscriber("imu_data", Vector3, self.imu_value_update) self.odomPub = rospy.Publisher("odom", Odometry,queue_size=10) self.odomBroadcaster = TransformBroadcaster() ############################################################################# def spin(self): ############################################################################# r = rospy.Rate(self.rate) while not rospy.is_shutdown(): self.update() r.sleep() ############################################################################# def update(self): ############################################################################# now = rospy.Time.now() if now &gt; self.t_next: elapsed = now - self.then self.then = now elapsed = elapsed.to_sec() # calculate odometry if self.enc_left == None: d_left = 0 d_right = 0 else: d_left = (self.left - self.enc_left) / self.ticks_meter d_right = (self.right - self.enc_right) / self.ticks_meter self.enc_left = self.left self.enc_right = self.right # distance traveled is the average of the two wheels d = ( d_left + d_right ) / 2 # this approximation works (in radians) for small angles th = ( d_right - d_left ) / self.base_width # calculate velocities self.dx = d / elapsed self.dr = th / elapsed if (d != 0): # calculate distance traveled in x and y x = cos( th ) * d y = -sin( th ) * d # calculate the final position of the robot self.x = self.x + ( cos( self.th ) * x - sin( self.th ) * y ) self.y = self.y + ( sin( self.th ) * x + cos( self.th ) * y ) if( th != 0): self.th = self.th + th # publish the odom information quaternion = Quaternion() quaternion.x = 0.0 quaternion.y = 0.0 quaternion.z = sin( self.th / 2 ) quaternion.w = cos( self.th / 2 ) ''' try: quaternion.z = self.quaternion_1[2] quaternion.w = self.quaternion_1[3] except: quaternion.z = sin( self.th / 2 ) quaternion.w = cos( self.th / 2 ) pass ''' self.odomBroadcaster.sendTransform( (self.x, self.y, 0), (quaternion.x, quaternion.y, quaternion.z, quaternion.w), rospy.Time.now(), self.base_frame_id, self.odom_frame_id ) odom = Odometry() odom.header.stamp = now odom.header.frame_id = self.odom_frame_id odom.pose.pose.position.x = self.x odom.pose.pose.position.y = self.y odom.pose.pose.position.z = 0 odom.pose.pose.orientation = quaternion odom.child_frame_id = self.base_frame_id odom.twist.twist.linear.x = self.dx odom.twist.twist.linear.y = 0 odom.twist.twist.angular.z = self.dr self.odomPub.publish(odom) def imu_value_update(self, imu_data): orient = Vector3() orient = imu_data self.yaw = orient.x self.pitch = orient.y self.roll = orient.z try: self.quaternion_1 = tf.transformations.quaternion_from_euler(self.yaw, self.pitch, self.roll) #print self.quaternion_1[0] #print self.quaternion_1[1] #print self.quaternion_1[2] #print self.quaternion_1[3] except: rospy.logwarn("Unable to get quaternion values") pass ############################################################################# def lwheelCallback(self, msg): ############################################################################# enc = msg.data if (enc &lt; self.encoder_low_wrap and self.prev_lencoder &gt; self.encoder_high_wrap): self.lmult = self.lmult + 1 if (enc &gt; self.encoder_high_wrap and self.prev_lencoder &lt; self.encoder_low_wrap): self.lmult = self.lmult - 1 self.left = 1.0 * (enc + self.lmult * (self.encoder_max - self.encoder_min)) self.prev_lencoder = enc ############################################################################# def rwheelCallback(self, msg): ############################################################################# enc = msg.data if(enc &lt; self.encoder_low_wrap and self.prev_rencoder &gt; self.encoder_high_wrap): self.rmult = self.rmult + 1 if(enc &gt; self.encoder_high_wrap and self.prev_rencoder &lt; self.encoder_low_wrap): self.rmult = self.rmult - 1 self.right = 1.0 * (enc + self.rmult * (self.encoder_max - self.encoder_min)) self.prev_rencoder = enc ############################################################################# ############################################################################# if __name__ == '__main__': """ main """ diffTf = DiffTf() diffTf.spin()</span></span></code> </pre><br></div></div><br>  Guarde el archivo y hágalo ejecutable: <br> <code>CTRL+X <br> chmod +x diff-tf.py</code> <br> <br>  Ahora en el robot, ejecute los segundos nodos - driver y diff-tf: <br>  1er terminal: <br><br><pre> <code class="plaintext hljs">python diff_tf.py</code> </pre> <br>  2do: <br><br><pre> <code class="plaintext hljs">rosrun rosbots_driver part2_cmr.py</code> </pre> <br>  En la tercera terminal, verificaremos que hay nuevos temas odom y tf: <br><br><img src="https://habrastorage.org/webt/zy/tc/rw/zytcrwcee_4-ygvgiwipil9jyxm.png"><br><br>  Veamos con el comando rostopic echo odom qué se publica en el tema (y si se publica). <br>  La salida será aproximadamente como sigue: <br><br><img src="https://habrastorage.org/webt/c2/f0/-o/c2f0-onzf3-8gdjtvegw7axrgtw.png"><br><br>  Ahora, sin cerrar los nodos en ejecución en el robot, iniciaremos la computadora de control con los entornos gráficos rviz y gazebo. <br><br>  * Una imagen (máquina virtual VMWare con Ubuntu 16.04 + ROS Kinetic), que se ofreció previamente para descargar, contiene todo lo que necesita. <br><br>  En la computadora de control (en adelante denominada "Computadora"), ejecute el modelo en rviz: <br><br><pre> <code class="plaintext hljs">roslaunch rosbots_description rviz.launch</code> </pre> <br>  Se cargará el modelo de robot cargado con el que trabajó en publicaciones anteriores: <br><br><img src="https://habrastorage.org/webt/e2/xf/kb/e2xfkbeuzqsl8g9vcl_ffiz2caa.png"><br><br>  Agregue dos pantallas a rviz haciendo clic en Agregar.  La pantalla con odometría y la pantalla con tf, marque las casillas para visualizarlas. <br><br>  En la ventana donde se representa el modelo de robot, aparecerán gráficos característicos: <br><br><img src="https://habrastorage.org/webt/i_/p3/r1/i_p3r1fflodksrj2vowmldcmxl0.png"><br>  * Para que sea más visible, puede desactivar la pantalla Robotmodel. <br><br>  Controlamos el robot desde el teclado de la computadora y vemos cómo cambia la visualización de tf y la odometría. <br><br>  Sin cerrar rviz en la segunda terminal, comenzaremos a controlar desde el teclado: <br><br><pre> <code class="plaintext hljs">rosrun teleop_twist_keyboard teleop_twist_keyboard.py /cmd_vel:=/part2_cmr/cmd_vel</code> </pre> <br>  Al controlar el robot, la ventana con visualización mostrará: flecha roja (visualización del tema principal), líneas vectoriales (tema tf). <br><br>  Si la flecha roja del tema principal muestra la dirección del movimiento del robot, entonces las líneas vectoriales tf muestran cómo se ubican los elementos individuales del robot en el espacio: <br><br><div class="spoiler">  <b class="spoiler_title">el video</b> <div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/CC6CO5VIDUA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br></div></div><br>  Ahora, para continuar, necesita "ajustar" la odometría. <br>  Para hacer esto, cierre el editor rviz e inícielo nuevamente, solo sin visualizar el modelo con el comando: <br><br><pre> <code class="plaintext hljs">rosrun rviz rviz</code> </pre> <br>  Esto es necesario para que solo base_link y odom permanezcan de los vectores del tema tf: <br><br><img src="https://habrastorage.org/webt/x6/qn/fn/x6qnfnbvkzstivryymtyovdnmuw.gif"><br><br>  En rviz, una celda es de 1 metro.  Por lo tanto, en realidad, el robot también debe pasar 1 metro para que los datos sean comparables. <br><br>  Pasaremos 1 metro en el robot, controlándolo desde el teclado.  En rviz, el robot también tiene que conducir 1 metro, una celda. <br><br>  Si el robot viaja más de lo que debería en rviz, o viceversa, una distancia más corta que en la realidad, entonces necesita editar el archivo diff_tf.py que se creó anteriormente, a saber, este bloque: <br><br><div class="spoiler">  <b class="spoiler_title">diff_tf.py</b> <div class="spoiler_text"><pre> <code class="plaintext hljs"> #### parameters ####### #Wheel radius : 0.0325 # wheel circum = 2* 3.14 * 0.0325 = 0.2041 # One rotation encoder ticks : 8 ticks # For 1 meter: 8 * ( 1 / 0.2041) = 39 ticks self.rate = rospy.get_param('~rate',10.0) # the rate at which to publish the transform self.ticks_meter = float(rospy.get_param('ticks_meter', 190)) # The number of wheel encoder ticks per meter of travel self.base_width = float(rospy.get_param('~base_width', 0.11)) # The wheel base width in meters</code> </pre> <br></div></div><br><h3>  Mapa </h3><br>  Para ir a algún lado, necesitas un mapa.  Para los propósitos de nuestro robot, necesitamos un mapa de la habitación. <br>  Trabajemos con ella. <br><br>  Para cargar un mapa en rviz, debe crear una carpeta de mapa en el proyecto (rosbots_description) en la computadora (no en el robot) y colocar dos archivos que componen el mapa: map.pgm y map.yaml. <br>  * De hecho, puede haber varios archivos de mapa en una carpeta, pero solo puede cargar uno en el asistente. <br><br>  Un mapa en ROS consta de dos archivos, uno de los cuales es una imagen PGM, donde cada píxel es: <br><br><ul><li>  blanco: el espacio es libre; </li><li>  negro: el espacio está ocupado por un obstáculo; </li><li>  gris: el espacio aún no se ha explorado. </li></ul><br>  El segundo archivo .yaml es un archivo con la configuración del mapa, donde se indican sus dimensiones, la ocupación de píxeles con diferentes tipos (enumerados anteriormente) y otros parámetros. <br><br>  Ejecute el nodo en la computadora que publicará la tarjeta: <br><br><pre> <code class="plaintext hljs">rosrun map_server map_server /home/pi/catkin_ws/src/rosbots_description/maps/rail_lab.pgm 0.05</code> </pre> <br>  En la terminal vecina, ejecute el modelo en rviz: <br><br><pre> <code class="plaintext hljs">roslaunch rosbots_description rviz.launch</code> </pre> <br>  En rviz, agregue una visualización de Mapa. <br><br>  En rviz, el robot resultó ser desproporcionadamente grande y se encuentra fuera del mapa: <br><br><img src="https://habrastorage.org/webt/h6/ob/8g/h6ob8gyq_u11omb3bzneqczgkra.gif"><br><br>  Para solucionar esto, debe ejecutar un mapa donde el tamaño de la celda será de 1 metro.  Reinicie la tarjeta con el parámetro 1 al final: <br><br><pre> <code class="plaintext hljs">rosrun map_server map_server /home/pi/catkin_ws/src/rosbots_description/maps/rail_lab.pgm 1</code> </pre> <br>  Ahora puedes montar el mapa en rviz, controlando el robot desde el teclado: <br><br><div class="spoiler">  <b class="spoiler_title">el video</b> <div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/bbsn97FUNnI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br></div></div><br>  <b>Entonces, lo que se logró</b> : <br><br><ul><li>  recibir datos de odometría de los codificadores ópticos de rueda del robot y enviarlos a temas para su visualización en rviz; </li><li>  configurar la odometría del robot para que coincida con la distancia recorrida en vivo y virtualmente; </li><li>  cargar y mostrar un mapa de habitación. </li></ul><br>  Sin embargo, a pesar del hecho de que se muestra el mapa y el robot puede viajar sobre él con una odometría "ajustada", en realidad el robot es ciego.  No ve obstáculos y tropezará con ellos.  La segunda desventaja es que el mapa de la sala virtual cargado en rviz le permite viajar solo en todas las direcciones, incluso en aquellas donde los obstáculos se muestran claramente. <br><br>  ¿Cómo hacer que el robot "vea" obstáculos en la realidad y virtualmente? <br><br>  Con un entorno virtual es más sencillo.  Todo aquí se basa en el emulador-editor de gazebo.  Y en publicaciones anteriores esto fue mencionado. <br><br>  Es más complicado con la realidad.  Necesitamos un elemento (sensor) que indique obstáculos e informe esto al sistema. <br><br>  Una opción es poner lidar en el robot. <br><br><h3>  Lidar RPlidar A1 </h3><br>  Utilizaremos la solución de presupuesto asequible y pondremos el LIDAR en el robot.  Quizás esta solución sea más costosa que usar el mismo Kinect, pero, como lo ha demostrado la práctica, es más efectiva en términos de velocidad, precisión y facilidad de instalación (menos engorrosa).  Además, es más fácil comenzar a trabajar con LIDAR, ya que  No se requiere reflexión sobre cómo alimentarlo y conectarlo al proyecto (https://habr.com/en/company/tod/blog/210252/). <br><br>  Necesitaremos el paquete ros para trabajar con lidar - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">wiki.ros.org/rplidar</a> . <br>  Con la ayuda del LIDAR, construiremos un mapa de la habitación y también lo usaremos en la navegación. <br><br>  Cómo instalar rplidar en ROS tiene muchos artículos, por ejemplo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> . <br><br>  Usaremos el conocimiento de los ancianos canosos e instalaremos paquetes con lidar en el sistema <u>en el robot</u> : <br><br><pre> <code class="plaintext hljs">cd /home/pi/rosbots_catkin_ws/src git clone https://github.com/robopeak/rplidar_ros.git cd .. catkin_make</code> </pre> <br>  En la <u>computadora,</u> instale el paquete para trabajar con la tarjeta: <br><br><pre> <code class="plaintext hljs">cd /home/pi/rosbots_catkin_ws/src git clone https://github.com/tu-darmstadt-ros-pkg/hector_slam &lt;/code&gt; cd .. catkin_make</code> </pre> <br>  Ejecute el paquete en el robot y compruebe si el LIDAR funciona: <br><br><pre> <code class="plaintext hljs">sudo chmod a+rw /dev/ttyUSB0 roslaunch rplidar_ros rplidar.launch</code> </pre> <br>  * El primer comando da acceso al puerto usb donde está conectado el lidar. <br><br>  Si todo salió bien, generará líneas en la consola: <br><br><pre> <code class="plaintext hljs">[ INFO] [1570900184.874891236]: RPLIDAR running on ROS package rplidar_ros. SDK Version:1.9.0 RPLIDAR S/N: ---------------- [ INFO] [1570900187.397858270]: Firmware Ver: 1.24 [ INFO] [1570900187.398081809]: Hardware Rev: 5 [ INFO] [1570900187.401749476]: RPLidar health status : 0 [ INFO] [1570900188.014285166]: current scan mode: Express, max_distance: 12.0 m, Point number: 4.0K , angle_compensate: 1</code> </pre> <br>  Aquí configuramos inmediatamente un pequeño LIDAR, porque  el sitio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">web</a> oficial dice que (lidar) puede funcionar mejor. <br><br>  Necesitamos lograr el resultado cuando el escaneo no es de 4.0K puntos, que se emiten por defecto, sino 8.0K.  Esta opción mejorará ligeramente la calidad del escaneo. <br><br>  Para esto, estableceremos un parámetro más en el paquete rplidar - modo de exploración: <br><br><pre> <code class="plaintext hljs">cd /rosbots_catkin_ws/src/rplidar_ros/launch nano nano rplidar.launch</code> </pre> <br>  Y despues <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">param</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"angle_compensate"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">type</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"bool"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">value</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"true"</span></span></span><span class="hljs-tag">/&gt;</span></span></code> </pre>  agrega la línea: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">param</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"scan_mode"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">type</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"string"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">value</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"Boost"</span></span></span><span class="hljs-tag">/&gt;</span></span></code> </pre> <br>  La segunda línea que debe corregirse aquí: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">param</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"frame_id"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">type</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"string"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">value</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"laser"</span></span></span><span class="hljs-tag">/&gt;</span></span></code> </pre> <br>  Reemplace el valor del láser con base_link. <br><br>  * Ahora, si reinicia el nodo con el comando roslaunch rplidar_ros rplidar.launch, el resultado será diferente: <br><br><pre> <code class="plaintext hljs">[ INFO] [1570900188.014285166]: current scan mode: Boost, max_distance: 12.0 m, Point number: 8.0K , angle_compensate: 1</code> </pre> <br>  Echa un vistazo  que muestra lidar en rviz. <br><br>  Para hacer esto, ejecuta el robot: <br><br><pre> <code class="plaintext hljs">roslaunch rplidar_ros rplidar.launch</code> </pre> <br>  En una computadora: <br><br><pre> <code class="plaintext hljs">roslaunch rosbots_description rviz.launch</code> </pre> <br>  En rviz, agregue la pantalla LaserScan y seleccione el tema de escaneo.  Además, se verá que los mensajes están cayendo en el tema: <br><br><img src="https://habrastorage.org/webt/mg/mo/6p/mgmo6p_pyjzofzrfyxwj5ollnrw.gif"><br><br>  En la ventana con la visualización del robot, el robot resultó ser un gigante.  Con su tamaño, lo resolveremos más tarde.  Ahora construyamos un mapa de habitación. <br><br>  Para hacer esto, cree un paquete con un nodo: <br><br><pre> <code class="plaintext hljs">catkin_create_pkg my_hector_mapping rospy cd my_hector_mapping mkdir launch cd launch nano hector.launch</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">hector.launch</b> <div class="spoiler_text"><pre> <code class="python hljs">&lt;?xml version=<span class="hljs-string"><span class="hljs-string">"1.0"</span></span>?&gt; &lt;launch&gt; &lt;node pkg=<span class="hljs-string"><span class="hljs-string">"tf"</span></span> type=<span class="hljs-string"><span class="hljs-string">"static_transform_publisher"</span></span> name=<span class="hljs-string"><span class="hljs-string">"laser_link"</span></span> args=<span class="hljs-string"><span class="hljs-string">"0.0 0.0 0.0 0.0 0.0 0.0 /base_link /laser 50"</span></span> /&gt; &lt;node pkg=<span class="hljs-string"><span class="hljs-string">"hector_mapping"</span></span> type=<span class="hljs-string"><span class="hljs-string">"hector_mapping"</span></span> name=<span class="hljs-string"><span class="hljs-string">"hector_mapping"</span></span> output=<span class="hljs-string"><span class="hljs-string">"screen"</span></span>&gt; &lt;!-- Frame names --&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"map_frame"</span></span> value=<span class="hljs-string"><span class="hljs-string">"map"</span></span> /&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"odom_frame"</span></span> value=<span class="hljs-string"><span class="hljs-string">"base_link"</span></span> /&gt; &lt;!-- Map size / start point --&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"map_resolution"</span></span> value=<span class="hljs-string"><span class="hljs-string">"0.050"</span></span>/&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"map_size"</span></span> value=<span class="hljs-string"><span class="hljs-string">"1024"</span></span>/&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"map_start_x"</span></span> value=<span class="hljs-string"><span class="hljs-string">"0.5"</span></span>/&gt; //  &lt;param name=<span class="hljs-string"><span class="hljs-string">"map_start_y"</span></span> value=<span class="hljs-string"><span class="hljs-string">"0.5"</span></span> /&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"map_multi_res_levels"</span></span> value=<span class="hljs-string"><span class="hljs-string">"2"</span></span> /&gt; &lt;!-- Map update parameters --&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"update_factor_free"</span></span> value=<span class="hljs-string"><span class="hljs-string">"0.4"</span></span>/&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"update_factor_occupied"</span></span> value=<span class="hljs-string"><span class="hljs-string">"0.9"</span></span> /&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"map_update_distance_thresh"</span></span> value=<span class="hljs-string"><span class="hljs-string">"0.4"</span></span>/&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"map_update_angle_thresh"</span></span> value=<span class="hljs-string"><span class="hljs-string">"0.06"</span></span> /&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"laser_z_min_value"</span></span> value=<span class="hljs-string"><span class="hljs-string">"-1.0"</span></span> /&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"laser_z_max_value"</span></span> value=<span class="hljs-string"><span class="hljs-string">"1.0"</span></span> /&gt; &lt;!-- Advertising config --&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"advertise_map_service"</span></span> value=<span class="hljs-string"><span class="hljs-string">"true"</span></span>/&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"scan_subscriber_queue_size"</span></span> value=<span class="hljs-string"><span class="hljs-string">"5"</span></span>/&gt; &lt;param name=<span class="hljs-string"><span class="hljs-string">"scan_topic"</span></span> value=<span class="hljs-string"><span class="hljs-string">"scan"</span></span>/&gt; &lt;/node&gt; &lt;/launch&gt;</code> </pre><br></div></div><br><pre> <code class="plaintext hljs">cd ~/rosbots_catkin_ws catkin_make</code> </pre> <br>  Vamos a ejecutarlo. <br><br>  En el robot: <br><br>  1er terminal: <code>roslaunch rplidar_ros rplidar.launch</code> <br>  2 °: <code>rosrun rosbots_driver part2_cmr.py</code> <br><br>  En una computadora: <br><br>  1er terminal: <code>roslaunch my_hector_mapping hector.launch</code> <br>  2do: <code>roslaunch rosbots_description rviz.launch</code> <br>  3 °: <code>rosrun teleop_twist_keyboard teleop_twist_keyboard.py /cmd_vel:=/part2_cmr/cmd_vel</code> <br><br>  En las pantallas necesita agregar un mapa, y Marco fijo seleccione base_link.  Luego puede observar en tiempo real cómo el lidar "ilumina" el espacio a su alrededor: <br><br><img src="https://habrastorage.org/webt/-6/gv/gq/-6gvgqgtmggjf7ffvnwlr1w6gwa.jpeg"><br><br>  En el paso actual, para construir un mapa, debe dar la vuelta a la habitación, "detenerse" en diferentes ángulos para que el LIDAR los marque en el mapa. <br><br>  Por eso recomiendo libros de texto.  Pero nuestro consejo es levantar el robot y caminar con él, sosteniéndolo frente a ti.  Por lo tanto, la velocidad de construcción de un mapa será mayor en el sentido de que no tendrá que distraerse y mirar hacia dónde conducía el robot en la habitación contigua en ausencia de contacto visual. <br><br>  Además, al girar el robot alrededor de su eje durante un viaje, el lidar deja artefactos negros característicos en aquellos lugares donde en realidad no hay obstáculos: <br><br><img src="https://habrastorage.org/webt/wf/tn/0y/wftn0yxvutj6keza4jhqngsasai.jpeg"><br><br>  Después de construir el mapa, guárdelo con el comando: <br><br><pre> <code class="plaintext hljs">rosrun map_server map_saver -f map-1</code> </pre> <br>  Construir el mapa perfecto con un presupuesto lidar es un mito.  Por lo tanto, ayudaremos al lidar en Photoshop.  Eliminaremos los artefactos negros del mapa, donde realmente no hay obstáculos, y alinearemos las paredes con líneas negras: <br><br><img src="https://habrastorage.org/webt/-k/xv/fo/-kxvfoxyjflij37fvy_ntw2d-ic.jpeg"><br><br>  No olvides guardar el mapa en formato .pgm. <br><br>  Ahora repetimos en la computadora los comandos que estaban al principio de la publicación, pero con un nuevo mapa: <br>  1er terminal: <code>rosrun map_server maserver /home/pi/catkin_ws/src/rosbots_description/maps/map-1.pgm 0.05</code> <br>  2do: <code>roslaunch rosbots_description rviz.launch</code> <br><br>  Resultado en rviz: <br><br><img src="https://habrastorage.org/webt/g1/g9/mj/g1g9mjpl0nwsgfumdmpmrvvem4q.jpeg"><br><br>  Se cargó el nuevo mapa, como el modelo de robot, pero el robot está fuera del mapa. <br><br>  Hablaremos de esto más tarde, pero por ahora, resumamos: <br><br><ul><li>  dominar el lidar RP-lidar A1 </li><li>  construyendo un mapa de habitación usando un lidar, ajustándolo y cargándolo en el editor visual rviz. </li></ul><br>  Archivos para descargar: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mapa de la habitación</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/471028/">https://habr.com/ru/post/471028/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../471018/index.html">Comparación del rendimiento de la PC y el teléfono inteligente, incluido el iPhone 11</a></li>
<li><a href="../471020/index.html">Cómo encontrar un error en un microprocesador lanzado hace treinta y cinco años</a></li>
<li><a href="../471022/index.html">Revelando un secreto de 140 años en física</a></li>
<li><a href="../471024/index.html">Análisis: qué son los futuros y cómo usarlos para las inversiones de intercambio</a></li>
<li><a href="../471026/index.html">TypeScript Poder nunca</a></li>
<li><a href="../471032/index.html">Foto invisible</a></li>
<li><a href="../471034/index.html">Entrevista con el desarrollador web de Pornhub</a></li>
<li><a href="../471036/index.html">Vive y aprende. Parte 5. Autoeducación: recuperarse</a></li>
<li><a href="../471038/index.html">Archivo descriptor de Linux con ejemplos</a></li>
<li><a href="../471040/index.html">[marcador] Versión PDF y ePUB del manual React</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•ä üéπ üàØÔ∏è Comment les GPU g√®rent les branchements ‚õàÔ∏è üî∏ üë®‚ÄçüöÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="√Ä propos de l'article 
 Ce message est une courte note con√ßue pour les programmeurs qui souhaitent en savoir plus sur la fa√ßon dont le GPU g√®re les br...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment les GPU g√®rent les branchements</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457704/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/f33/e39/6cbf33e39c393986a3a26bd44b9777e8.png" alt="image"></div><br><h2>  √Ä propos de l'article </h2><br>  Ce message est une courte note con√ßue pour les programmeurs qui souhaitent en savoir plus sur la fa√ßon dont le GPU g√®re les branchements.  Vous pouvez le consid√©rer comme une introduction √† ce sujet.  Je recommande de commencer par [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1</a> ], [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> ] et [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">8</a> ] pour avoir une id√©e de l'apparence g√©n√©rale du mod√®le d'ex√©cution GPU, car nous ne consid√©rerons qu'un seul d√©tail distinct.  Pour les lecteurs curieux, il y a tous les liens √† la fin de l'article.  Si vous trouvez des erreurs, contactez-moi. <br><br><h2>  Table des mati√®res </h2><br><ul><li>  √Ä propos de l'article </li><li>  Table des mati√®res </li><li>  Vocabulaire </li><li>  En quoi le noyau GPU est-il diff√©rent du noyau CPU? </li><li>  Qu'est-ce que la coh√©rence / divergence? </li><li>  Exemples de traitement de masque d'ex√©cution <ul><li>  ISA fictif </li><li>  AMD GCN ISA </li><li>  AVX512 </li></ul></li><li>  Comment faire face √† l'√©cart? </li><li>  Les r√©f√©rences </li></ul><a name="habracut"></a><br><h2>  Vocabulaire </h2><br><ul><li>  GPU - Unit√© de traitement graphique, GPU </li><li>  Classification de Flynn <br><ul><li>  SIMD - Donn√©es multiples √† instruction unique, flux d'instructions unique, flux de donn√©es multiples </li><li>  SIMT - Une seule instruction, plusieurs threads, un seul flux d'instructions, plusieurs threads </li></ul></li><li>  Wave (SIM) - un flux ex√©cut√© en mode SIMD </li><li>  Ligne (voie) - un flux de donn√©es distinct dans le mod√®le SIMD </li><li>  SMT - Multithreading simultan√©, multithreading simultan√© (Intel Hyper-threading) [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> ] <br><ul><li>  Plusieurs threads partagent les principales ressources informatiques </li></ul></li><li>  IMT - Multithreading entrelac√©, multithreading altern√© [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> ] <br><ul><li>  Plusieurs threads partagent les ressources informatiques totales du noyau, mais un seul </li></ul></li><li>  BB - Basic Block, un bloc de base - une s√©quence lin√©aire d'instructions avec un seul saut √† la fin </li><li>  ILP - Parall√©lisme au niveau de l'instruction, parall√©lisme au niveau de l'instruction [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">3</a> ] </li><li>  ISA - Instruction Set Architecture, architecture du jeu d'instructions </li></ul><br>  Dans mon article, j'adh√©rerai √† cette classification invent√©e.  Cela ressemble grosso modo √† l'organisation d'un GPU moderne. <br><br><blockquote><code>: <br> GPU -+ <br> |-  0 -+ <br> | |-  0 + <br> | | |-  0 <br> | | |-  1 <br> | | |- ... <br> | | +-  Q-1 <br> | | <br> | |- ... <br> | +-  M-1 <br> | <br> |- ... <br> +-  N-1 <br> <br> *  -  SIMD <br> <br>  : <br>  + <br> |-  0 <br> |- ... <br> +-  N-1</code> </blockquote> <br>  Autres noms: <br><br><ul><li>  Le noyau peut √™tre appel√© CU, SM, EU </li><li>  Une onde peut √™tre appel√©e un front d'onde, un thread mat√©riel (thread HW), une cha√Æne, un contexte </li><li>  Une ligne peut √™tre appel√©e un thread de programme (thread SW) </li></ul><br><h2>  En quoi le noyau GPU est-il diff√©rent du noyau CPU? </h2><br>  Toute g√©n√©ration actuelle de c≈ìurs GPU est moins puissante que les processeurs centraux: simple ILP / multi-issue [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">6</a> ] et prefetch [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">5</a> ], pas de pr√©vision ou pr√©diction de transitions / retours.  Tout cela, avec de minuscules caches, lib√®re une zone assez grande sur la puce, qui est remplie de nombreux c≈ìurs.  Les m√©canismes de chargement / stockage de la m√©moire sont capables de faire face √† la largeur du canal d'un ordre de grandeur plus grand (cela ne s'applique pas aux GPU int√©gr√©s / mobiles) que les processeurs conventionnels, mais vous devez payer pour cela avec des latences √©lev√©es.  Pour masquer la latence, le GPU utilise SMT [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> ] - tandis qu'une vague est inactive, d'autres utilisent les ressources informatiques gratuites du noyau.  Habituellement, le nombre d'ondes trait√©es par un c≈ìur d√©pend des registres utilis√©s et est d√©termin√© dynamiquement en allouant un fichier de registre fixe [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">8</a> ].  La planification de l'ex√©cution des instructions est hybride - dynamique-statique [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">6</a> ] [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">11</a> 4.4].  Les noyaux SMT ex√©cut√©s en mode SIMD atteignent des valeurs FLOPS √©lev√©es (op√©rations en virgule flottante par seconde, flops, nombre d'op√©rations en virgule flottante par seconde). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fb8/059/770/fb8059770b3653b65c5e2cc30f5fee16.png" alt="Figure 1"><br><br>  <i>Tableau de l√©gende.</i>  <i>Noir - inactif, blanc - actif, gris - √©teint, bleu - inactif, rouge - en attente</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/12e/fc7/5d9/12efc75d90a064410b1632c2be710235.png"></div><br>  <i>Figure 1. Historique d'ex√©cution 4: 2</i> <br><br>  L'image montre l'historique du masque d'ex√©cution, o√π l'axe x montre le temps allant de gauche √† droite, et l'axe y montre l'identifiant de la ligne allant de haut en bas.  Si vous ne comprenez toujours pas cela, revenez au dessin apr√®s avoir lu les sections suivantes. <br><br>  Ceci est une illustration de la fa√ßon dont l'historique d'ex√©cution du c≈ìur du GPU peut ressembler dans une configuration fictive: quatre vagues partagent un √©chantillonneur et deux ALU.  Le planificateur de vagues de chaque cycle √©met deux instructions √† partir de deux vagues.  Lorsqu'une onde est inactive lors d'un acc√®s √† la m√©moire ou d'une longue op√©ration ALU, le planificateur passe √† une autre paire d'ondes, en raison de laquelle l'ALU est constamment occup√©e √† pr√®s de 100%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/433/54a/ea2/43354aea2bb0a351048a196808d6a06a.png"></div><br>  <i>Figure 2. Historique d'ex√©cution 4: 1</i> <br><br>  Un exemple avec la m√™me charge, mais cette fois dans chaque cycle de l'instruction, une seule vague √©met.  Notez que le deuxi√®me ALU est affam√©. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/f33/e39/6cbf33e39c393986a3a26bd44b9777e8.png"></div><br>  <i>Figure 3. Historique d'ex√©cution 4: 4</i> <br><br>  Cette fois, quatre instructions sont √©mises √† chaque cycle.  Notez qu'il y a trop de demandes √† ALU, donc deux vagues attendent presque toujours (en fait, c'est une erreur de l'algorithme de planification). <br><br>  <strong><em>Mise √† jour</em></strong> Pour plus d'informations sur les difficult√©s de planification de l'ex√©cution des instructions, voir [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">12</a> ]. <br><br>  Dans le monde r√©el, les GPU ont diff√©rentes configurations de c≈ìur: certains peuvent avoir jusqu'√† 40 ondes par c≈ìur et 4 ALU, d'autres ont 7 ondes fixes et 2 ALU.  Tout cela d√©pend de nombreux facteurs et est d√©termin√© gr√¢ce au processus minutieux de simulation d'architecture. <br><br>  De plus, les vrais ALU SIMD peuvent avoir une largeur plus √©troite que les ondes qu'ils servent, puis il faut plusieurs cycles pour traiter une instruction √©mise;  le facteur est appel√© la longueur "carillon" [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">3</a> ]. <br><br><h2>  Qu'est-ce que la coh√©rence / divergence? </h2><br>  Jetons un coup d'≈ìil √† l'extrait de code suivant: <br><br><h6>  Exemple 1 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lane_id &amp; <span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Do smth } // Do some more</span></span></code> </pre> <br>  Nous voyons ici un flux d'instructions dans lequel le chemin d'ex√©cution d√©pend de l'identifiant de la ligne en cours d'ex√©cution.  De toute √©vidence, diff√©rentes lignes ont des significations diff√©rentes.  Que va-t-il se passer?  Il existe diff√©rentes approches pour r√©soudre ce probl√®me [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">4</a> ], mais au final, elles font toutes la m√™me chose.  Une telle approche est le masque d'ex√©cution, que je couvrirai.  Cette approche a √©t√© utilis√©e dans les GPU Nvidia avant Volta et dans les GPU AMD GCN.  Le point principal du masque d'ex√©cution est que nous stockons un peu pour chaque ligne de l'onde.  Si le bit d'ex√©cution de ligne correspondant est 0, aucun registre ne sera affect√© pour l'instruction suivante √©mise.  En fait, la ligne ne doit pas ressentir l'influence de l'ensemble de l'instruction ex√©cut√©e, car son bit d'ex√©cution est 0. Cela fonctionne comme suit: l'onde se d√©place le long du graphique de flux de contr√¥le dans l'ordre de recherche de profondeur, sauvegardant l'historique des transitions s√©lectionn√©es jusqu'√† ce que les bits soient d√©finis.  Je pense qu'il vaut mieux le montrer avec un exemple. <br><br>  Supposons que nous ayons des vagues d'une largeur de 8. Voici √† quoi ressemble le masque d'ex√©cution pour le fragment de code: <br><br><h6>  Exemple 1. Historique du masque d'ex√©cution </h6><br><pre> <code class="cpp hljs"> <span class="hljs-comment"><span class="hljs-comment">// execution mask uint lane_id = get_lane_id(); // 11111111 if (lane_id &amp; 1) { // 11111111 // Do smth // 01010101 } // Do some more // 11111111</span></span></code> </pre> <br>  Consid√©rons maintenant des exemples plus complexes: <br><br><h6>  Exemple 2 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (uint i = lane_id; i &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>; i++) { <span class="hljs-comment"><span class="hljs-comment">// Do smth }</span></span></code> </pre> <br><h6>  Exemple 3 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lane_id &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Do smth } else { // Do smth else }</span></span></code> </pre> <br>  Vous remarquerez peut-√™tre que l'histoire est n√©cessaire.  Lors de l'utilisation de l'approche du masque d'ex√©cution, l'√©quipement utilise g√©n√©ralement une sorte de pile.  L'approche na√Øve consiste √† stocker une pile de tuples (exec_mask, address) et √† ajouter des instructions de convergence qui r√©cup√®rent le masque de la pile et modifient le pointeur d'instructions pour l'onde.  Dans ce cas, l'onde aura suffisamment d'informations pour contourner l'int√©gralit√© du CFG pour chaque ligne. <br><br>  En termes de performances, il suffit de quelques boucles pour traiter une instruction de flux de contr√¥le en raison de tout ce stockage de donn√©es.  Et n'oubliez pas que la pile a une profondeur limit√©e. <br><br>  <strong><em>Mettre √† jour.</em></strong>  Gr√¢ce √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@craigkolb,</a> j'ai lu un article [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">13</a> ], qui note que les instructions AMD GCN fork / join s√©lectionnent d'abord un chemin parmi moins de threads [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">11</a> 4.6], ce qui garantit que la profondeur de la pile de masques est √©gale √† log2. <br><br>  <strong><em>Mettre √† jour.</em></strong>  De toute √©vidence, il est presque toujours possible de tout incorporer dans un shader / structurer des CFG dans un shader, et donc de stocker tout l'historique des masques d'ex√©cution dans des registres et de planifier le contournement / la convergence statique des CFG [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">15</a> ].  Apr√®s avoir examin√© le backend LLVM pour AMDGPU, je n'ai trouv√© aucune preuve de gestion de pile constamment √©mise par le compilateur. <br><br><h3>  Prise en charge mat√©rielle du masque d'ex√©cution </h3><br>  Jetez maintenant un ≈ìil √† ces graphiques de flux de contr√¥le de Wikipedia: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5f9/f04/a1a/5f9f04a1a89b36ad0908dee0e90542f3.png"></div><br>  <i>Figure 4. Certains types de graphiques de flux de contr√¥le</i> <br><br>  Quel est l'ensemble minimal d'instructions de contr√¥le de masque dont nous avons besoin pour g√©rer tous les cas?  Voici √† quoi cela ressemble dans mon ISA artificiel avec parall√©lisation implicite, contr√¥le de masque explicite et synchronisation enti√®rement dynamique des conflits de donn√©es: <br><br><pre> <code class="cpp hljs">push_mask BRANCH_END ; Push current mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> reconvergence pointer pop_mask ; Pop mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> jump to reconvergence instruction mask_nz r0.x ; Set execution bit, pop mask <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> all bits are zero ; Branch instruction is more complicated ; Push current mask <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> reconvergence ; <span class="hljs-function"><span class="hljs-function">Push mask </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">for</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(r0.x == </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">for</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">else</span></span></span><span class="hljs-function"> block, </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">if</span></span></span><span class="hljs-function"> any lane takes the path </span></span>; <span class="hljs-function"><span class="hljs-function">Set mask </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">with</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(r0.x != </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">, fallback to </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">else</span></span></span><span class="hljs-function"> in </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">case</span></span></span><span class="hljs-function"> no bit is 1 br_push r0.x, ELSE, CONVERGE</span></span></code> </pre> <br>  Jetons un ≈ìil au cas d). <br><br><pre> <code class="cpp hljs">A: br_push r0.x, C, D B: C: mask_nz r0.y jmp B D: ret</code> </pre> <br>  Je ne suis pas un sp√©cialiste de l'analyse des flux de contr√¥le ou de la conception d'ISA, donc je suis s√ªr qu'il y a un cas o√π mon ISA artificiel ne sera pas en mesure de faire face, mais ce n'est pas important, car un CFG structur√© devrait √™tre suffisant pour tout le monde. <br><br>  <strong><em>Mettre √† jour.</em></strong>  En savoir plus sur la prise en charge de GCN pour les instructions de flux de contr√¥le ici: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">11</a> ] ch.4, et sur l'impl√©mentation de LLVM ici: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">15</a> ]. <br><br>  Conclusion: <br><br><ul><li>  Divergence - la diff√©rence r√©sultante dans les chemins choisis par diff√©rentes lignes de la m√™me onde </li><li>  Coh√©rence - pas de divergence. </li></ul><br><h2>  Exemples de traitement de masque d'ex√©cution </h2><br><h3>  ISA fictif </h3><br>  J'ai compil√© les extraits de code pr√©c√©dents dans mon ISA artificiel et les ai ex√©cut√©s sur un simulateur dans SIMD32.  D√©couvrez comment il g√®re le masque d'ex√©cution. <br><br>  <strong><em>Mettre √† jour.</em></strong>  Notez qu'un simulateur artificiel choisit toujours le vrai chemin, et ce n'est pas la meilleure fa√ßon. <br><br><h6>  Exemple 1 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); mov r0.x, lane_id ; if (lane_id &amp; 1) { push_mask BRANCH_END and r0.y, r0.x, u(1) mask_nz r0.y LOOP_BEGIN: ; // Do smth pop_mask ; pop mask and reconverge BRANCH_END: ; // Do some more ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/d40/30c/fdb/d4030cfdb754b9a663c03ae46b31efc7.png" alt="Figure 5"><br><br>  <i>Figure 5. L'historique de l'exemple 1</i> <br><br>  Avez-vous remarqu√© une zone noire?  Cette perte de temps.  Certaines lignes attendent que d'autres terminent l'it√©ration. <br><br><h6>  Exemple 2 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); mov r0.x, lane_id ; for (uint i = lane_id; i &lt; 16; i++) { push_mask LOOP_END ; Push the current mask and the pointer to reconvergence instruction LOOP_PROLOG: lt.u32 r0.y, r0.x, u(16) ; r0.y &lt;- r0.x &lt; 16 add.u32 r0.x, r0.x, u(1) ; r0.x &lt;- r0.x + 1 mask_nz r0.y ; exec bit &lt;- r0.y != 0 - when all bits are zero next mask is popped LOOP_BEGIN: ; // Do smth jmp LOOP_PROLOG LOOP_END: ; // } ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/fe3/259/b17/fe3259b179e832553900c7cb22487e03.png" alt="Figure 6"><br><br>  <i>Figure 6. Historique de l'exemple 2</i> <br><br><h6>  Exemple 3 </h6><br><pre> <code class="lisp hljs"> mov r0.x, lane_id lt.u32 r0.y, r0.x, u(<span class="hljs-number"><span class="hljs-number">16</span></span>) <span class="hljs-comment"><span class="hljs-comment">; if (lane_id &lt; 16) { ; Push (current mask, CONVERGE) and (else mask, ELSE) ; Also set current execution bit to r0.y != 0 br_push r0.y, ELSE, CONVERGE THEN: ; // Do smth pop_mask ; } else { ELSE: ; // Do smth else pop_mask ; } CONVERGE: ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/27e/d1b/2a9/27ed1b2a99db4ab917d661946ed7c705.png" alt="Figure 7"><br><br>  <i>Figure 7. Historique de l'exemple 3</i> <br><br><h3>  AMD GCN ISA </h3><br>  <strong><em>Mettre √† jour.</em></strong>  GCN utilise √©galement un traitement de masque explicite, plus d'informations √† ce sujet ici: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">11</a> 4.x].  J'ai d√©cid√© de montrer quelques exemples de leur ISA, gr√¢ce √† l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">aire de jeux shader,</a> c'est facile √† faire.  Peut-√™tre qu'un jour je trouverai un simulateur et arriverai √† obtenir des diagrammes. <br><br>  Gardez √† l'esprit que le compilateur est intelligent, vous pouvez donc obtenir d'autres r√©sultats.  J'ai essay√© de tromper le compilateur pour qu'il n'optimise pas mes branches en y mettant des boucles de pointeur puis en nettoyant le code assembleur;  Je ne suis pas un sp√©cialiste GCN, donc quelques <code>nop</code> importants pourraient √™tre ignor√©s. <br><br>  Notez √©galement que les instructions S_CBRANCH_I / G_FORK et S_CBRANCH_JOIN ne sont pas utilis√©es dans ces fragments car elles sont simples et le compilateur ne les prend pas en charge.  Par cons√©quent, malheureusement, il n'a pas √©t√© possible de consid√©rer la pile de masques.  Si vous savez comment effectuer le traitement de la pile des probl√®mes du compilateur, dites-le moi. <br><br>  <strong><em>Mettre √† jour.</em></strong>  Consultez cet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">expos√© @ SiNGUL4RiTY</a> sur l'impl√©mentation d'un flux de contr√¥le vectoris√© dans le backend LLVM utilis√© par AMD. <br><br><h6>  Exemple 1 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); ; GCN uses 64 wave width, so lane_id = thread_id &amp; 63 ; There are scalar s* and vector v* registers ; Executon mask does not affect scalar or branch instructions v_mov_b32 v1, 0x00000400 ; 1024 - group size v_mad_u32_u24 v0, s12, v1, v0 ; thread_id calculation v_and_b32 v1, 63, v0 ; if (lane_id &amp; 1) { v_and_b32 v2, 1, v0 s_mov_b64 s[0:1], exec ; Save the execution mask v_cmpx_ne_u32 exec, v2, 0 ; Set the execution bit s_cbranch_execz ELSE ; Jmp if all exec bits are zero ; // Do smth ELSE: ; } ; // Do some more s_mov_b64 exec, s[0:1] ; Restore the execution mask s_endpgm</span></span></code> </pre> <br><h6>  Exemple 2 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); v_mov_b32 v1, 0x00000400 v_mad_u32_u24 v0, s8, v1, v0 ; Not sure why s8 this time and not s12 v_and_b32 v1, 63, v0 ; LOOP PROLOG s_mov_b64 s[0:1], exec ; Save the execution mask v_mov_b32 v2, v1 v_cmp_le_u32 vcc, 16, v1 s_andn2_b64 exec, exec, vcc ; Set the execution bit s_cbranch_execz LOOP_END ; Jmp if all exec bits are zero ; for (uint i = lane_id; i &lt; 16; i++) { LOOP_BEGIN: ; // Do smth v_add_u32 v2, 1, v2 v_cmp_le_u32 vcc, 16, v2 s_andn2_b64 exec, exec, vcc ; Mask out lanes which are beyond loop limit s_cbranch_execnz LOOP_BEGIN ; Jmp if non zero exec mask LOOP_END: ; // } s_mov_b64 exec, s[0:1] ; Restore the execution mask s_endpgm</span></span></code> </pre> <br><h6>  Exemple 3 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); v_mov_b32 v1, 0x00000400 v_mad_u32_u24 v0, s12, v1, v0 v_and_b32 v1, 63, v0 v_and_b32 v2, 1, v0 s_mov_b64 s[0:1], exec ; Save the execution mask ; if (lane_id &lt; 16) { v_cmpx_lt_u32 exec, v1, 16 ; Set the execution bit s_cbranch_execz ELSE ; Jmp if all exec bits are zero ; // Do smth ; } else { ELSE: s_andn2_b64 exec, s[0:1], exec ; Inverse the mask and &amp; with previous s_cbranch_execz CONVERGE ; Jmp if all exec bits are zero ; // Do smth else ; } CONVERGE: s_mov_b64 exec, s[0:1] ; Restore the execution mask ; // Do some more s_endpgm</span></span></code> </pre> <br><h3>  AVX512 </h3><br>  <strong><em>Mettre √† jour.</em></strong>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@tom_forsyth m'a</a> fait remarquer que l'extension AVX512 a √©galement un traitement de masque explicite, alors voici quelques exemples.  Plus de d√©tails √† ce sujet peuvent √™tre trouv√©s dans [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">14</a> ], 15.x et 15.6.1.  Ce n'est pas exactement un GPU, mais il a toujours un vrai SIMD16 avec 32 bits.  Les extraits de code ont √©t√© cr√©√©s √† l'aide du godbolt ISPC (‚Äìtarget = avx512knl-i32x16) et ont √©t√© fortement repens√©s, de sorte qu'ils peuvent ne pas √™tre 100% vrais. <br><br><h6>  Exemple 1 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids ; AVXZ512 comes with k0-k7 mask registers ; Usage: ; op reg1 {k[7:0]}, reg2, reg3 ; k0 can not be used as a predicate operand, only k1-k7 ; if (lane_id &amp; 1) { vpslld zmm0 {k1}, zmm0, 31 ; zmm0[i] = zmm0[i] &lt;&lt; 31 kmovw eax, k1 ; Save the execution mask vptestmd k1 {k1}, zmm0, zmm0 ; k1[i] = zmm0[i] != 0 kortestw k1, k1 je ELSE ; Jmp if all exec bits are zero ; // Do smth ; Now k1 contains the execution mask ; We can use it like this: ; vmovdqa32 zmm1 {k1}, zmm0 ELSE: ; } kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h6>  Exemple 2 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids kmovw eax, k1 ; Save the execution mask vpcmpltud k1 {k1}, zmm0, 16 ; k1[i] = zmm0[i] &lt; 16 kortestw k1, k1 je LOOP_END ; Jmp if all exec bits are zero vpternlogd zmm1 {k1}, zmm1, zmm1, 255 ; zmm1[i] = -1 ; for (uint i = lane_id; i &lt; 16; i++) { LOOP_BEGIN: ; // Do smth vpsubd zmm0 {k1}, zmm0, zmm1 ; zmm0[i] = zmm0[i] + 1 vpcmpltud k1 {k1}, zmm0, 16 ; masked k1[i] = zmm0[i] &lt; 16 kortestw k1, k1 jne LOOP_BEGIN ; Break if all exec bits are zero LOOP_END: ; // } kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h6>  Exemple 3 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids ; if (lane_id &amp; 1) { vpslld zmm0 {k1}, zmm0, 31 ; zmm0[i] = zmm0[i] &lt;&lt; 31 kmovw eax, k1 ; Save the execution mask vptestmd k1 {k1}, zmm0, zmm0 ; k1[i] = zmm0[i] != 0 kortestw k1, k1 je ELSE ; Jmp if all exec bits are zero THEN: ; // Do smth ; } else { ELSE: kmovw ebx, k1 andn ebx, eax, ebx kmovw k1, ebx ; mask = ~mask &amp; old_mask kortestw k1, k1 je CONVERGE ; Jmp if all exec bits are zero ; // Do smth else ; } CONVERGE: kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h2>  Comment faire face √† l'√©cart? </h2><br>  J'ai essay√© de cr√©er une illustration simple mais compl√®te de la fa√ßon dont l'inefficacit√© r√©sulte de la combinaison de lignes divergentes. <br><br>  Imaginez un simple morceau de code: <br><br><pre> <code class="lisp hljs">uint thread_id = get_thread_id()<span class="hljs-comment"><span class="hljs-comment">; uint iter_count = memory[thread_id]; for (uint i = 0; i &lt; iter_count; i++) { // Do smth }</span></span></code> </pre> <br>  Cr√©ons 256 threads et mesurons leur temps d'ex√©cution: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7c2/2da/c5d/7c22dac5d75a77156a60c510a655309a.png"></div><br>  <i>Figure 8. Dur√©e des fils divergents</i> <br><br>  L'axe x est l'identifiant du flux de programme, l'axe y est les cycles d'horloge;  diff√©rentes colonnes montrent combien de temps est perdu lors du regroupement de flux avec diff√©rentes longueurs d'onde par rapport √† l'ex√©cution monothread. <br><br>  Le temps d'ex√©cution de la vague est √©gal au temps d'ex√©cution maximal parmi les lignes qu'il contient.  Vous pouvez voir que les performances chutent d√©j√† consid√©rablement avec SIMD8, et une nouvelle expansion ne fait qu'aggraver les choses. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a0d/c9a/be6/a0dc9abe6a7a0e12515d4c88c36aaa21.png" alt="Figure 9"></div><br>  <i>Figure 9. Dur√©e d'ex√©cution des threads coh√©rents</i> <br><br>  Les m√™mes colonnes sont repr√©sent√©es sur cette figure, mais cette fois le nombre d'it√©rations est tri√© par identificateurs de flux, c'est-√†-dire que les flux avec un nombre similaire d'it√©rations sont transmis √† une seule onde. <br><br>  Pour cet exemple, l'ex√©cution est potentiellement acc√©l√©r√©e d'environ la moiti√©. <br><br>  Bien s√ªr, l'exemple est trop simple, mais j'esp√®re que vous comprenez le point: la divergence √† l'ex√©cution d√©coule de la divergence des donn√©es, donc les CFG doivent √™tre simples et les donn√©es coh√©rentes. <br><br>  Par exemple, si vous √©crivez un traceur de rayons, il peut √™tre avantageux de regrouper les rayons avec la m√™me direction et la m√™me position, car ils passeront tr√®s probablement par les m√™mes n≈ìuds dans le BVH.  Voir [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">10</a> ] et d'autres articles connexes pour plus de d√©tails. <br><br>  Il convient √©galement de mentionner qu'il existe des techniques pour traiter les √©carts au niveau du mat√©riel, par exemple, Dynamic Warp Formation [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">7</a> ] et l'ex√©cution pr√©vue pour les petites branches. <br><br><h1>  Les r√©f√©rences </h1><br>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Un voyage √† travers le pipeline graphique</a> <br><br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kayvon Fatahalian: INFORMATIQUE PARALL√àLE</a> <br><br>  [3] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'architecture informatique: une approche quantitative</a> <br><br>  [4] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Reconvergence SIMT sans pile √† faible co√ªt</a> <br><br>  [5] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dissection de la hi√©rarchie de la m√©moire GPU par le biais de micro-benchmarking</a> <br><br>  [6] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dissection de l'architecture GPU NVIDIA Volta via le micro-benchmarking</a> <br><br>  [7] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Formation et planification de distorsion dynamique pour un flux de contr√¥le GPU efficace</a> <br><br>  [8] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Maurizio Cerrato: Architectures GPU</a> <br><br>  [9] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Simulateur GPU jouet</a> <br><br>  [10] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©duire la divergence des branches dans les programmes GPU</a> <br><br>  [11] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Architecture du jeu d'instructions ¬´Vega¬ª</a> <br><br>  [12] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Joshua Barczak: Simulation de l'ex√©cution d'un shader pour GCN</a> <br><br>  [13] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vecteur tangent: une digression sur la divergence</a> <br><br>  [14] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Intel 64 et IA-32 ArchitecturesSoftware Developer's Manual</a> <br><br>  [15] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vectorisation du flux de contr√¥le divergent pour les applications SIMD</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr457704/">https://habr.com/ru/post/fr457704/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr457694/index.html">Les dangers de l'utilisation de constantes multi-caract√®res</a></li>
<li><a href="../fr457696/index.html">Les dangers de l'utilisation de constantes multi-caract√®res</a></li>
<li><a href="../fr457698/index.html">Exp√©rience: nous utilisons des proxys comme outil pour lutter contre les attaques DoS</a></li>
<li><a href="../fr457700/index.html">Guide d'authentification Node.js sans passport.js et services tiers</a></li>
<li><a href="../fr457702/index.html">Travailler avec l'API KOMPAS-3D ‚Üí Le√ßon 16 ‚Üí Contr√¥ler les caract√®res</a></li>
<li><a href="../fr457706/index.html">Robot teste SAP ERP</a></li>
<li><a href="../fr457710/index.html">Les fonctionnalit√©s √©tonnantes des r√©seaux de neurones 2019</a></li>
<li><a href="../fr457712/index.html">Comment Verizon et BGP Optimizer ont-ils mis en place d'excellents outils hors ligne</a></li>
<li><a href="../fr457714/index.html">D√©bordement de pile en anglais: Community Kill Guide</a></li>
<li><a href="../fr457718/index.html">HyperCard, le lien perdu dans l'√©volution du Web</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
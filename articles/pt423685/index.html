<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèø‚Äçü§ù‚Äçüë®üèæ ‚ñ´Ô∏è üßõüèø Simultaneidade do PostgreSQL: n√£o esf√©rica, n√£o √© cavalo, n√£o est√° no v√°cuo üÜñ üé∫ üë®üèæ‚Äçüî¨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Escalar um DBMS √© um futuro que avan√ßa continuamente. Os DBMSs melhoram e escalam melhor nas plataformas de hardware, enquanto as pr√≥prias plataformas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Simultaneidade do PostgreSQL: n√£o esf√©rica, n√£o √© cavalo, n√£o est√° no v√°cuo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/postgrespro/blog/423685/"><img src="https://habrastorage.org/webt/b0/s3/rq/b0s3rqkffufh7baruji0jc_vbgq.jpeg"><br><br>  Escalar um DBMS √© um futuro que avan√ßa continuamente.  Os DBMSs melhoram e escalam melhor nas plataformas de hardware, enquanto as pr√≥prias plataformas de hardware aumentam a produtividade, o n√∫mero de n√∫cleos e a mem√≥ria - o Achilles est√° alcan√ßando a tartaruga, mas ainda n√£o o fez.  O problema de dimensionar o DBMS est√° em pleno andamento. <br><br>  O Postgres Professional teve um problema com o dimensionamento n√£o apenas teoricamente, mas tamb√©m praticamente: com seus clientes.  E mais de uma vez.  Um desses casos ser√° discutido neste artigo. <br><br>  O PostgreSQL se adapta bem aos sistemas NUMA, se for uma √∫nica placa-m√£e com v√°rios processadores e v√°rios barramentos de dados.  Algumas otimiza√ß√µes podem ser lidas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  No entanto, existe outra classe de sistemas, eles t√™m v√°rias placas-m√£e, cuja troca de dados √© realizada por interconex√£o, enquanto uma inst√¢ncia do sistema operacional est√° trabalhando neles e para o usu√°rio esse design parece uma √∫nica m√°quina.  E, embora formalmente, esses sistemas tamb√©m possam ser atribu√≠dos ao NUMA, mas, em ess√™ncia, eles est√£o mais pr√≥ximos dos supercomputadores, como  o acesso √† mem√≥ria local do n√≥ e o acesso √† mem√≥ria do n√≥ vizinho diferem radicalmente.  A comunidade do PostgreSQL acredita que a √∫nica inst√¢ncia do Postgres em execu√ß√£o nessas arquiteturas √© uma fonte de problemas, e ainda n√£o existe uma abordagem sistem√°tica para resolv√™-los. <br><a name="habracut"></a><br>  Isso ocorre porque a arquitetura do software que utiliza mem√≥ria compartilhada √© fundamentalmente projetada para o fato de que o tempo de acesso de diferentes processos √† mem√≥ria pr√≥pria e remota √© mais ou menos compar√°vel.  No caso em que trabalhamos com muitos n√≥s, a aposta na mem√≥ria compartilhada como um canal de comunica√ß√£o r√°pido deixa de se justificar, porque, devido √† lat√™ncia, √© muito "mais barato" enviar uma solicita√ß√£o para executar uma determinada a√ß√£o ao n√≥ (n√≥) em que dados interessantes do que enviar esses dados no barramento.  Portanto, para supercomputadores e, em geral, sistemas com muitos n√≥s, as solu√ß√µes de cluster s√£o relevantes. <br><br>  Isso n√£o significa que a combina√ß√£o de sistemas com v√°rios n√≥s e a arquitetura de mem√≥ria compartilhada t√≠pica do Postgres precise ser encerrada.  Afinal, se os processos do postgres passam a maior parte do tempo realizando c√°lculos complexos localmente, essa arquitetura ser√° muito eficiente.  Em nossa situa√ß√£o, o cliente j√° havia comprado um poderoso servidor de v√°rios n√≥s e tivemos que resolver os problemas do PostgreSQL nele. <br><br>  Mas os problemas eram graves: as solicita√ß√µes de grava√ß√£o mais simples (alteram v√°rios valores de campo em um registro) foram executadas em um per√≠odo de alguns minutos a uma hora.  Como foi confirmado posteriormente, esses problemas se manifestaram em toda a sua gl√≥ria justamente por causa do grande n√∫mero de n√∫cleos e, consequentemente, pelo paralelismo radical na execu√ß√£o de solicita√ß√µes com uma troca relativamente lenta entre os n√≥s. <br><br>  Portanto, o artigo ser√°, por assim dizer, com duplo objetivo: <br><br><ul><li>  Compartilhar experi√™ncia: o que fazer se, em um sistema com v√°rios n√≥s, o banco de dados ficar mais lento a s√©rio.  Por onde come√ßar, como diagnosticar para onde se mover. </li><li>  Descreva como os problemas do DBMS do PostgreSQL podem ser resolvidos com um alto n√≠vel de simultaneidade.  Incluindo como a altera√ß√£o no algoritmo para bloquear bloqueios afeta o desempenho do PostgreSQL. </li></ul><br><h3>  Servidor e DB </h3><br>  O sistema consistia em 8 l√¢minas com 2 soquetes em cada.  No total, mais de 300 n√∫cleos (excluindo hipertrefei√ß√£o).  Um pneu r√°pido (tecnologia propriet√°ria do fabricante) conecta as l√¢minas.  N√£o √© um supercomputador, mas para uma inst√¢ncia do DBMS, a configura√ß√£o √© impressionante. <br>  A carga tamb√©m √© bastante grande.  Mais de 1 terabyte de dados.  Cerca de 3000 transa√ß√µes por segundo.  Mais de 1000 conex√µes para o postgres. <br><br>  Tendo come√ßado a lidar com as expectativas de grava√ß√£o a cada hora, a primeira coisa que fizemos foi gravar no disco como causa de atrasos.  Assim que come√ßaram os atrasos incompreens√≠veis, os testes come√ßaram a ser realizados exclusivamente em <code>tmpfs</code> .  A imagem n√£o mudou.  O disco n√£o tem nada a ver com isso. <br><br><h3>  Introdu√ß√£o ao diagn√≥stico: exibi√ß√µes </h3><br>  Como os problemas surgiram provavelmente devido √† alta competi√ß√£o de processos que "batem" nos mesmos objetos, a primeira coisa a verificar s√£o os bloqueios.  No PostgreSQL, h√° uma vis√£o <code>pg.catalog.pg_locks</code> e <code>pg_stat_activity</code> para essa verifica√ß√£o.  O segundo, j√° na vers√£o 9.6, adicionou informa√ß√µes sobre o que o processo est√° aguardando ( <i>Amit Kapila, Ildus Kurbangaliev</i> ) - <code>wait_event_type</code> .  Os valores poss√≠veis para este campo est√£o descritos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  Mas primeiro, basta contar: <br><br><pre> <code class="sql hljs">postgres=<span class="hljs-comment"><span class="hljs-comment"># SELECT COUNT(*) FROM pg_locks; count ‚Äî---‚Äî 88453 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity; count ‚Äî---‚Äî 1826 (1 row) postgres=# SELECT COUNT(*) FROM pg_stat_activity WHERE state ='active'; count ‚Äî---‚Äî 1005</span></span></code> </pre> <br>  Estes s√£o n√∫meros reais.  Atingiu at√© 200.000 bloqueios. <br>  Ao mesmo tempo, esses bloqueios dependiam do pedido infeliz: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span> <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_locks <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> pid =<span class="hljs-number"><span class="hljs-number">580707</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> <span class="hljs-keyword"><span class="hljs-keyword">mode</span></span>; count | mode ‚Äî<span class="hljs-comment"><span class="hljs-comment">-----+---------------‚Äî 93 | AccessShareLock 1 | ExclusiveLock</span></span></code> </pre> <br>  Ao ler o buffer, o DBMS usa o bloqueio de <code>share</code> , enquanto escreve - <code>exclusive</code> .  Ou seja, os bloqueios de grava√ß√£o foram respons√°veis ‚Äã‚Äãpor menos de 1% de todas as solicita√ß√µes. <br>  Na visualiza√ß√£o <code>pg_locks</code> , os tipos de bloqueio nem sempre s√£o os descritos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">na documenta√ß√£o do</a> usu√°rio. <br><br>  Aqui est√° a placa de f√≥sforo: <br><br><pre> <code class="plaintext hljs">AccessShareLock = LockTupleKeyShare RowShareLock = LockTupleShare ExclusiveLock = LockTupleNoKeyExclusive AccessExclusiveLock = LockTupleExclusive</code> </pre> <br>  A consulta SELECT mode FROM pg_locks mostrou que CREATE INDEX (sem CONCURRENTLY) aguardaria 234 INSERTs e 390 INSERTs para <code>buffer content lock</code> .  Uma solu√ß√£o poss√≠vel √© ‚Äúensinar‚Äù INSERTs de diferentes sess√µes para interceptar menos em buffers. <br><br><h3>  √â hora de usar perf </h3><br>  O utilit√°rio <b><code>perf</code></b> coleta muitas informa√ß√µes de diagn√≥stico.  No modo de <code>record</code> ... ele grava estat√≠sticas de eventos do sistema em arquivos (por padr√£o, eles est√£o em <code>./perf_data</code> ) e no modo de <code>report</code> analisa os dados coletados, por exemplo, √© poss√≠vel filtrar eventos que dizem respeito apenas ao <code>postgres</code> ou a um determinado <code>pid</code> : <br><br><pre> <code class="plaintext hljs">$ perf record -u postgres  $ perf record -p 76876  ,  $ perf report &gt; ./my_results</code> </pre> <br>  Como resultado, veremos algo como <br><br><img src="https://habrastorage.org/webt/rn/ta/rv/rntarvj2jticq7glciiqockk3-y.jpeg"><br><br>  Como usar o <code>perf</code> para diagnosticar o PostgreSQL √© descrito, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , assim como no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">wiki pg</a> . <br><br>  No nosso caso, at√© o modo mais simples forneceu informa√ß√µes importantes sobre o <code>perf top</code> - <code>perf top</code> , que funciona, √© claro, no esp√≠rito do sistema operacional <code>top</code> .  Com o <code>perf top</code> vimos que na maioria das vezes o processador gasta nos <code>PinBuffer()</code> do n√∫cleo, bem como nas <code>PinBuffer()</code> e <code>LWLockAttemptLock().</code>  . <br><br>  <code>PinBuffer()</code> √© uma fun√ß√£o que aumenta o contador de refer√™ncias ao buffer (mapeando uma p√°gina de dados para a RAM), gra√ßas a quais processos do postgres sabem quais buffers podem ser for√ßados a sair e quais n√£o. <br><br>  <code>LWLockAttemptLock()</code> - fun√ß√£o de captura do <code>LWLock</code> .  <code>LWLock</code> √© um tipo de bloqueio com dois n√≠veis de <code>shared</code> e <code>exclusive</code> , sem definir <code>deadlock</code> , os bloqueios s√£o pr√©-alocados para a <code>shared memory</code> , os processos em espera est√£o aguardando em uma fila. <br><br>  Essas fun√ß√µes j√° foram seriamente otimizadas no PostgreSQL 9.5 e 9.6.  Os spinlocks dentro deles foram substitu√≠dos pelo uso direto de opera√ß√µes at√¥micas. <br><br><h3>  Gr√°ficos de chama </h3><br>  √â imposs√≠vel sem eles: mesmo que fossem in√∫teis, ainda valeria a pena contar sobre eles - eles s√£o extraordinariamente bonitos.  Mas eles s√£o √∫teis.  Aqui est√° uma ilustra√ß√£o do <code>github</code> , n√£o do nosso caso (nem n√≥s nem o cliente estamos prontos para a divulga√ß√£o de detalhes ainda). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/75b/909/e8d/75b909e8de5177a48fa7d73f53eff437.svg"><br><br>  Essas belas imagens mostram claramente o que os ciclos do processador levam.  O mesmo <code>perf</code> pode coletar dados, mas o <code>flame graph</code> visualiza os dados de maneira inteligente e constr√≥i √°rvores com base nas pilhas de chamadas coletadas.  Voc√™ pode ler mais sobre cria√ß√£o de perfil com gr√°ficos de chama, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , e baixar tudo o que precisa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  No nosso caso, uma enorme quantidade de <code>nestloop</code> era vis√≠vel nos gr√°ficos de chama.  Aparentemente, as JOINs de um grande n√∫mero de tabelas em v√°rias solicita√ß√µes de leitura simult√¢neas causaram um grande n√∫mero de bloqueios de <code>access share</code> de <code>access share</code> . <br><br>  As estat√≠sticas coletadas pelo <code>perf</code> mostram para onde os ciclos do processador v√£o.  E, embora vimos que a maior parte do tempo do processador passa por bloqueios, n√£o vimos exatamente o que leva a expectativas t√£o longas de bloqueios, pois n√£o vemos exatamente onde as expectativas de bloqueio ocorrem, porque  O tempo da CPU n√£o √© desperdi√ßado em espera. <br><br>  Para ver as pr√≥prias expectativas, voc√™ pode criar uma solicita√ß√£o para a visualiza√ß√£o do sistema <code>pg_stat_activity</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> wait_event_type, wait_event, <span class="hljs-keyword"><span class="hljs-keyword">COUNT</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> pg_stat_activity <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> wait_event_type, wait_event;</code> </pre> <br>  revelou que: <br><br><pre> <code class="plaintext hljs">LWLockTranche | buffer_content | UPDATE ************* LWLockTranche | buffer_content | INSERT INTO ******** LWLockTranche | buffer_content | \r | | insert into B4_MUTEX | | values (nextval('hib | | returning ID Lock | relation | INSERT INTO B4_***** LWLockTranche | buffer_content | UPDATE ************* Lock | relation | INSERT INTO ******** LWLockTranche | buffer_mapping | INSERT INTO ******** LWLockTranche | buffer_content | \r</code> </pre> <br>  (os asteriscos aqui simplesmente substituem os detalhes da solicita√ß√£o que n√£o divulgamos). <br><br>  Voc√™ pode ver os valores <code>buffer_content</code> (bloqueando o conte√∫do dos buffers) e <code>buffer_mapping</code> (bloqueando os componentes da placa de hash <code>shared_buffers</code> ). <br><br><h3>  Para ajuda ao gdb </h3><br>  Mas por que existem tantas expectativas para esses tipos de bloqueios?  Para informa√ß√µes mais detalhadas sobre as expectativas, tive que usar o depurador <code>GDB</code> .  Com o <code>GDB</code> , podemos obter uma pilha de chamadas de processos espec√≠ficos.  Ao aplicar a amostragem, ou seja,  Depois de coletar um certo n√∫mero de pilhas de chamadas aleat√≥rias, voc√™ pode ter uma id√©ia de quais pilhas t√™m as maiores expectativas. <br><br>  Considere o processo de compila√ß√£o de estat√≠sticas.  Consideraremos a cole√ß√£o ‚Äúmanual‚Äù de estat√≠sticas, embora na vida real sejam utilizados scripts especiais que fazem isso automaticamente. <br><br>  Primeiro, o <code>gdb</code> precisa ser anexado ao processo do PostgreSQL.  Para fazer isso, encontre o <code>pid</code> processo <code>pid</code> servidor, digamos em <br><br><pre> <code class="plaintext hljs">$ ps aux | grep postgres</code> </pre> <br>  Digamos que encontramos: <br><br><pre> <code class="plaintext hljs">postgres 2025 0.0 0.1 172428 1240 pts/17  S   23  0:00 /usr/local/pgsql/bin/postgres -D /usr/local/pgsql/data</code> </pre> <br>  e agora insira o <code>pid</code> no depurador: <br><br><pre> <code class="plaintext hljs">igor_le:~$gdb -p 2025</code> </pre> <br>  Uma vez dentro do depurador, escrevemos <code>bt</code> [ou seja, <code>backtrace</code> ] ou <code>where</code> .  E temos muitas informa√ß√µes sobre esse tipo: <br><br><pre> <code class="plaintext hljs">(gdb) bt #0 0x00007fbb65d01cd0 in __write_nocancel () from /lib64/libc.so.6 #1 0x00000000007c92f4 in write_pipe_chunks ( data=0x110e6e8 "2018‚Äê06‚Äê01 15:35:38 MSK [524647]: [392‚Äê1] db=bp,user=bp,app=[unknown],client=192.168.70.163 (http://192.168.70.163) LOG: relation 23554 new block 493: 248.389503\n2018‚Äê06‚Äê01 15:35:38 MSK [524647]: [393‚Äê1] db=bp,user=bp,app=["..., len=409, dest=dest@entry=1) at elog.c:3123 #2 0x00000000007cc07b in send_message_to_server_log (edata=0xc6ee60 &lt;errordata&gt;) at elog.c:3024 #3 EmitErrorReport () at elog.c:1479</code> </pre> <br>  Depois de coletar estat√≠sticas, incluindo pilhas de chamadas de todos os processos do postgres, coletadas repetidamente em diferentes momentos, vimos que o <code>buffer partition lock</code> dentro do <code>relation extension lock</code> durava 3706 segundos (cerca de uma hora), ou seja, bloqueia uma parte da tabela de hash do buffer gerente, necess√°rio substituir o buffer antigo, para substitu√≠-lo posteriormente por um novo correspondente √† parte estendida da tabela.  Um certo n√∫mero de bloqueios de <code>buffer content lock</code> do <code>buffer content lock</code> tamb√©m foi percept√≠vel, o que correspondeu √† expectativa de bloquear as p√°ginas do √≠ndice da <code>B-tree</code> para inser√ß√£o. <br><br><img src="https://habrastorage.org/webt/6c/y6/cw/6cy6cwmfye29jw84dkzoabjlgvg.jpeg"><br><br>  A princ√≠pio, duas explica√ß√µes vieram para um tempo de espera t√£o monstruoso: <br><br><ul><li>  Algu√©m pegou esse <code>LWLock</code> e ficou preso.  Mas isso √© improv√°vel.  Porque nada complicado acontece dentro do bloqueio da parti√ß√£o de buffer. </li><li>  Encontramos algum comportamento patol√≥gico do <code>LWLock</code> .  Ou seja, apesar do fato de ningu√©m ter demorado muito na fechadura, sua expectativa durou excessivamente. </li></ul><br><h3>  Patches de diagn√≥stico e tratamento de √°rvores </h3><br>  Ao reduzir o n√∫mero de conex√µes simult√¢neas, provavelmente descarregar√≠amos o fluxo de solicita√ß√µes para bloqueios.  Mas isso seria como se render.  Em vez disso, <i>Alexander Korotkov</i> , arquiteto-chefe do Postgres Professional (claro, ele ajudou a preparar este artigo), prop√¥s uma s√©rie de patches. <br><br>  Antes de tudo, era necess√°rio obter uma imagem mais detalhada do desastre.  N√£o importa qu√£o boas sejam as ferramentas acabadas, as corre√ß√µes de diagn√≥stico de sua pr√≥pria fabrica√ß√£o tamb√©m ser√£o √∫teis. <br><br>  Foi criado um patch que adiciona um registro detalhado do tempo gasto na <code>relation extension</code> , o que est√° acontecendo dentro da fun√ß√£o <code>RelationAddExtraBlocks()</code> . Portanto, descobrimos o tempo gasto dentro do <code>RelationAddExtraBlocks().</code> <br><br>  E em apoio a ele, outro patch foi escrito relatando em <code>pg_stat_activity</code> o que estamos fazendo agora em <code>relation extension</code> .  Isso foi feito da seguinte maneira: quando a <code>relation</code> expande, <code>application_name</code> se torna <code>RelationAddExtraBlocks</code> .  Agora, esse processo √© convenientemente analisado com o m√°ximo de detalhes usando <code>gdb bt</code> e <code>perf</code> . <br><br>  Na verdade, remendos m√©dicos (e n√£o diagn√≥sticos) foram escritos dois.  O primeiro patch mudou o comportamento dos bloqueios das folhas da <code>B‚Äêtree</code> : antes, quando solicitado a inser√ß√£o, a folha era bloqueada como <code>share</code> e, depois disso, era <code>exclusive</code> .  Agora ele imediatamente se torna <code>exclusive</code> .  Agora, este patch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">j√° foi confirmado</a> para o <b>PostgreSQL 12</b> .  Felizmente, este ano, <i>Alexander Korotkov</i> recebeu o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">status de committer</a> - o segundo commit do PostgreSQL na R√∫ssia e o segundo na empresa. <br><br>  O valor <code>NUM_BUFFER_PARTITIONS</code> tamb√©m foi aumentado de 128 para 512 para reduzir a carga nos bloqueios de mapeamento: a tabela de hash do gerenciador de buffer foi dividida em partes menores, na esperan√ßa de que a carga em cada parte espec√≠fica fosse reduzida. <br><br>  Depois de aplicar esse patch, os bloqueios no conte√∫do dos buffers desapareceram, mas, apesar do aumento de <code>NUM_BUFFER_PARTITIONS</code> , o <code>buffer_mapping</code> permaneceu, ou seja, lembramos de bloquear partes da tabela de hash do gerenciador de buffer: <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping ----‚Äê‚Äê‚Äê--‚Äê‚Äê‚Äê+‚Äê------‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê------‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê------‚Äê‚Äê‚Äê 12549 | 1218 | 0 | 15</code> </pre> <br>  E mesmo isso n√£o √© muito.  A √°rvore B n√£o √© mais um gargalo.  A extens√£o da <code>heap-</code> veio √† tona. <br><br><h3>  Tratamento de consci√™ncia </h3><br>  Em seguida, Alexander apresentou a seguinte hip√≥tese e solu√ß√£o: <br><br>  Aguardamos muito tempo no <code>buffer parittion lock</code> do <code>buffer parittion lock</code> ao <code>buffer parittion lock</code> buffer.  Talvez no mesmo <code>buffer parittion lock</code> exista alguma p√°gina muito exigida, por exemplo, a raiz de alguma <code>B‚Äêtree</code>  Nesse ponto, h√° um fluxo cont√≠nuo de solicita√ß√µes de <code>shared lock</code> das solicita√ß√µes de leitura. <br><br>  A fila de espera no <code>LWLock</code> "n√£o √© justa".  Como <code>shared lock</code> podem ser obtidos quantos forem necess√°rios ao mesmo tempo, se o <code>shared lock</code> j√° <code>shared lock</code> sido realizado, os <code>shared lock</code> subsequentes ser√£o transmitidos sem enfileiramento.  Portanto, se o fluxo de bloqueios compartilhados tiver intensidade suficiente para que n√£o haja "janelas" entre eles, aguardar um <code>exclusive lock</code> ser√° quase infinito. <br><br>  Para corrigir isso, voc√™ pode tentar oferecer - um patch de comportamento "cavalheiro" dos bloqueios.  Isso desperta a consci√™ncia dos <code>shared locker</code> e eles fazem fila honestamente quando j√° existe um <code>exclusive lock</code> (curiosamente, fechaduras pesadas - <code>hwlock</code> - n√£o t√™m problemas com a consci√™ncia: sempre fazem fila honestamente) <br><br><pre> <code class="plaintext hljs">locks_count | active_session | buffer_content | buffer_mapping | reladdextra | inserts&gt;30sec ‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê-‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê--‚Äê-‚Äê+‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê-‚Äê‚Äê‚Äê‚Äê‚Äê‚Äê+‚Äê‚Äê‚Äê‚Äê------ 173985 | 1802 | 0 | 569 | 0 | 0</code> </pre> <br>  Est√° tudo bem!  N√£o h√° <code>insert</code> longas.  Embora os bloqueios nas pe√ßas das placas de hash permanecessem.  Mas o que fazer, essas s√£o as propriedades dos pneus do nosso pequeno supercomputador. <br><br>  Este patch tamb√©m foi <a href="">oferecido √† comunidade</a> .  Mas n√£o importa como o destino desses patches na comunidade se desenvolva, nada os impede de entrar nas pr√≥ximas vers√µes do <b>Postgres Pro Enterprise</b> , projetadas especificamente para clientes com sistemas muito carregados. <br><br><h3>  Moral </h3><br>  Bloqueios <code>share</code> leves de alta moral - blocos <code>exclusive</code> pulam a fila - resolveram o problema de atrasos por hora em um sistema de v√°rios n√≥s.  A tag hash do <code>buffer manager</code> n√£o funcionou devido ao excesso de fluxo de <code>share lock</code> , o que n√£o deixou chance para os bloqueios necess√°rios para suplantar buffers antigos e carregar novos.  Problemas com a extens√£o do buffer para as tabelas do banco de dados foram apenas uma consequ√™ncia disso.  Antes disso, era poss√≠vel expandir o gargalo com acesso √† raiz da <code>B-tree</code> <br><br>  O PostgreSQL n√£o foi projetado para arquiteturas e supercomputadores NUMA.  A adapta√ß√£o a essas arquiteturas do Postgres √© um trabalho enorme que exigiria (e possivelmente exigiria) os esfor√ßos coordenados de muitas pessoas e at√© de empresas.  Mas as conseq√º√™ncias desagrad√°veis ‚Äã‚Äãdesses problemas arquitet√¥nicos podem ser mitigadas.  E precisamos: os tipos de carga que levaram a atrasos semelhantes aos descritos s√£o bastante t√≠picos, sinais de socorro semelhantes de outros lugares continuam chegando at√© n√≥s.  Problemas semelhantes apareceram anteriormente - em sistemas com menos n√∫cleos, apenas as consequ√™ncias n√£o eram t√£o monstruosas e os sintomas foram tratados com outros m√©todos e outros patches.  Agora outro medicamento apareceu - n√£o universal, mas claramente √∫til. <br><br>  Portanto, quando o PostgreSQL trabalha com a mem√≥ria de todo o sistema como local, nenhum barramento de alta velocidade entre os n√≥s pode comparar com o tempo de acesso √† mem√≥ria local.  As tarefas surgem por causa disso dif√≠cil, muitas vezes urgente, mas interessante.  E a experi√™ncia de resolv√™-los √© √∫til n√£o apenas para os decisivos, mas tamb√©m para toda a comunidade. <br><br><img src="https://habrastorage.org/webt/od/n1/sf/odn1sf_id7l60ezlyo-padxymmi.jpeg"></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt423685/">https://habr.com/ru/post/pt423685/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt423655/index.html">Gen√©ricos + primavera: que a for√ßa esteja com voc√™</a></li>
<li><a href="../pt423657/index.html">N√£o respeito o encapsulamento ou uso um tipo diferente de tabela de m√©todo para chamar rapidamente m√©todos privados</a></li>
<li><a href="../pt423677/index.html">Pilotos a jato: Frankie West</a></li>
<li><a href="../pt423679/index.html">Uma tarefa com um arranha-c√©u e ovos - n√£o a lixeira de Newton?</a></li>
<li><a href="../pt423683/index.html">Baseado no senso comum: desenvolvendo DevOps do zero</a></li>
<li><a href="../pt423687/index.html">HyperX Pulsefire FPS Pro - mais r√°pido, mais baixo, mais acess√≠vel</a></li>
<li><a href="../pt423689/index.html">RTOS MAX - gr√°tis? Planejamos abrir uma licen√ßa para uso comercial gratuito</a></li>
<li><a href="../pt423693/index.html">Outra maneira de usar o Webpack 4 e a separa√ß√£o de c√≥digo</a></li>
<li><a href="../pt423695/index.html">Como se aposentar antes dos 40 anos com um milh√£o de d√≥lares em uma conta banc√°ria</a></li>
<li><a href="../pt423697/index.html">Apresentando o Spring Data JDBC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
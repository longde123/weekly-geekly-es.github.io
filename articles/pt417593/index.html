<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö£ üë®üèæ‚Äçü§ù‚Äçüë®üèΩ üë®üèª‚Äçüç≥ NewSQL = NoSQL + ACID üïõ üë®üèæ‚Äçüíº ü¶Å</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="At√© recentemente, em Odnoklassniki, cerca de 50 TB de dados em tempo real eram armazenados no SQL Server. Para esse volume, √© quase imposs√≠vel fornece...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NewSQL = NoSQL + ACID</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/odnoklassniki/blog/417593/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t5/hc/h2/t5hch2mr-lw9ffeahr_9gaxizlg.jpeg" width="600"></div><br>  At√© recentemente, em Odnoklassniki, cerca de 50 TB de dados em tempo real eram armazenados no SQL Server.  Para esse volume, √© quase imposs√≠vel fornecer acesso r√°pido, confi√°vel e at√© seguro ao data center usando o SQL DBMS.  Geralmente, nesses casos, eles usam um dos reposit√≥rios NoSQL, mas nem tudo pode ser transferido para o NoSQL: algumas entidades exigem garantias de transa√ß√µes ACID. <br><br>  Isso nos levou a usar o armazenamento NewSQL, ou seja, um DBMS que fornece toler√¢ncia a falhas, escalabilidade e desempenho dos sistemas NoSQL, mas ao mesmo tempo preserva as garantias ACID familiares aos sistemas cl√°ssicos.  Como existem poucos sistemas industriais em funcionamento nessa nova classe, implementamos esse sistema e o colocamos em opera√ß√£o comercial. <br><br>  Como funciona e o que aconteceu - leia abaixo do corte. <br><a name="habracut"></a><br>  Hoje, o p√∫blico mensal de Odnoklassniki √© de mais de 70 milh√µes de visitantes √∫nicos.  Estamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">entre as cinco</a> maiores redes sociais do mundo e os vinte sites em que os usu√°rios passam mais tempo.  A infraestrutura "OK" lida com cargas muito altas: mais de um milh√£o de solicita√ß√µes HTTP / s nas frentes.  Partes da frota de servidores de mais de 8000 est√£o localizadas pr√≥ximas umas das outras - em quatro data centers de Moscou, o que permite uma lat√™ncia de rede inferior a 1 ms entre elas. <br><br>  Estamos usando o Cassandra desde 2010, come√ßando com a vers√£o 0.6.  Hoje, v√°rias dezenas de clusters est√£o em opera√ß√£o.  O cluster mais r√°pido processa mais de 4 milh√µes de opera√ß√µes por segundo e as maiores armazenam 260 TB. <br><br>  No entanto, todos esses s√£o clusters NoSQL comuns usados ‚Äã‚Äãpara armazenar dados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fracamente consistentes</a> .  Mas quer√≠amos substituir o principal armazenamento consistente, o Microsoft SQL Server, usado desde a funda√ß√£o do Odnoklassniki.  O armazenamento consistia em mais de 300 m√°quinas SQL Server Standard Edition, que continham 50 TB de entidades de neg√≥cios de dados.  Esses dados s√£o modificados como parte das transa√ß√µes ACID e requerem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">alta consist√™ncia</a> . <br><br>  Para distribuir dados entre n√≥s do SQL Server, usamos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">particionamento</a> vertical e horizontal (sharding).  Historicamente, usamos um esquema simples de compartilhamento de dados: cada entidade foi associada a um token - uma fun√ß√£o do ID da entidade.  As entidades com o mesmo token foram colocadas no mesmo servidor SQL.  O relacionamento do tipo mestre-detalhe foi implementado para que os tokens dos registros principais e gerados sempre coincidissem e estivessem no mesmo servidor.  Em uma rede social, quase todos os registros s√£o gerados em nome de um usu√°rio - o que significa que todos os dados do usu√°rio em um subsistema funcional s√£o armazenados em um servidor.  Ou seja, as tabelas de um servidor SQL quase sempre participavam de uma transa√ß√£o comercial, o que tornava poss√≠vel garantir a consist√™ncia dos dados usando transa√ß√µes ACID locais, sem a necessidade de transa√ß√µes ACID distribu√≠das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lentas e n√£o confi√°veis</a> . <br><br>  Gra√ßas ao sharding e para acelerar o SQL: <br><br><ul><li>  N√£o usamos restri√ß√µes de chave estrangeira, pois ao compartilhar, o ID da entidade pode estar em outro servidor. </li><li>  N√£o usamos procedimentos e gatilhos armazenados devido √† carga adicional na CPU do DBMS. </li><li>  N√£o usamos JOINs devido a todas as op√ß√µes acima e muitas leituras aleat√≥rias do disco. </li><li>  Fora de uma transa√ß√£o, para reduzir conflitos, usamos o n√≠vel de isolamento Read Uncommitted. </li><li>  Realizamos apenas transa√ß√µes curtas (em m√©dia, menores que 100 ms). </li><li>  N√£o usamos UPDATE e DELETE com v√°rias linhas devido ao grande n√∫mero de deadlocks - atualizamos apenas um registro. </li><li>  Sempre executamos consultas apenas por √≠ndices - uma consulta com um plano para uma verifica√ß√£o completa da tabela para n√≥s significa sobrecarga do banco de dados e sua falha. </li></ul><br>  Essas etapas tornaram poss√≠vel extrair o desempenho quase m√°ximo dos servidores SQL.  No entanto, os problemas se tornaram cada vez mais.  Vamos olhar para eles. <br><br><h2>  Problemas de SQL </h2><br><ul><li>  Como usamos o sharding propriet√°rio, os administradores adicionaram manualmente novos shards.  Todo esse tempo, r√©plicas de dados escal√°veis ‚Äã‚Äãn√£o atendiam solicita√ß√µes. </li><li>  √Ä medida que o n√∫mero de registros na tabela aumenta, a velocidade de inser√ß√£o e modifica√ß√£o diminui. Ao adicionar √≠ndices a uma tabela existente, a velocidade cai v√°rias vezes, a cria√ß√£o e recria√ß√£o de √≠ndices ocorre com o tempo de inatividade. </li><li>  Ter poucos Windows para SQL Server em produ√ß√£o dificulta o gerenciamento de sua infraestrutura </li></ul><br>  Mas o principal problema √© <br><br><h2>  Toler√¢ncia a falhas </h2><br>  O SQL Server cl√°ssico tem pouca toler√¢ncia a falhas.  Suponha que voc√™ tenha apenas um servidor de banco de dados e ele falhe a cada tr√™s anos.  No momento, o site n√£o funciona por 20 minutos, isso √© aceit√°vel.  Se voc√™ tiver 64 servidores, o site n√£o funcionar√° uma vez a cada tr√™s semanas.  E se voc√™ tiver 200 servidores, o site n√£o funcionar√° toda semana.  Isso √© um problema. <br><br>  O que pode ser feito para melhorar a resili√™ncia do SQL Server?  A Wikipedia nos oferece a constru√ß√£o de um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cluster altamente acess√≠vel</a> : onde, em caso de falha de qualquer um dos componentes, existe um duplicado. <br><br>  Isso requer uma frota de equipamentos caros: redund√¢ncia m√∫ltipla, fibra, armazenamento compartilhado e a inclus√£o de uma reserva n√£o funciona de maneira confi√°vel: cerca de 10% das inclus√µes falham com um n√≥ de backup do mecanismo atr√°s do n√≥ principal. <br><br>  Mas a principal desvantagem de um cluster t√£o acess√≠vel √© a disponibilidade zero em caso de falha do datacenter em que ele se encontra.  Odnoklassniki possui quatro centros de dados e precisamos fornecer trabalho em caso de acidente completo em um deles. <br><br>  Para fazer isso, voc√™ pode usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a</a> replica√ß√£o multimestre incorporada ao SQL Server.  Essa solu√ß√£o √© muito mais cara devido ao custo do software e sofre de problemas conhecidos com a replica√ß√£o - atrasos imprevis√≠veis nas transa√ß√µes durante a replica√ß√£o s√≠ncrona e atrasos na aplica√ß√£o de replica√ß√µes (e, como resultado, modifica√ß√µes perdidas) durante as assinaturas.  A <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">resolu√ß√£o manual</a> impl√≠cita <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">de conflitos</a> torna essa op√ß√£o completamente inaplic√°vel para n√≥s. <br><br>  Todos esses problemas exigiram uma solu√ß√£o radical e procedemos a uma an√°lise detalhada deles.  Aqui, precisamos nos familiarizar com o que o SQL Server basicamente faz - as transa√ß√µes. <br><br><h2>  Transa√ß√£o simples </h2><br>  Considere a transa√ß√£o mais simples, do ponto de vista de um programador SQL aplicado,: adicionar uma foto a um √°lbum.  √Ålbuns e fotos s√£o armazenados em diferentes pratos.  O √°lbum tem um contador de fotos p√∫blico.  Em seguida, essa transa√ß√£o √© dividida nas seguintes etapas: <br><br><ol><li>  Bloqueamos o √°lbum por chave. </li><li>  Crie uma entrada na tabela de fotos. </li><li>  Se a foto tiver um status p√∫blico, encerraremos o contador de fotos p√∫blicas no √°lbum, atualizaremos o registro e confirmaremos a transa√ß√£o. </li></ol><br>  Ou na forma de pseudo-c√≥digo: <br><br><pre><code class="hljs pgsql">TX.<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>("Albums", id); Album album = albums.<span class="hljs-keyword"><span class="hljs-keyword">lock</span></span>(id); Photo photo = photos.<span class="hljs-keyword"><span class="hljs-keyword">create</span></span>(‚Ä¶); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (photo.status == <span class="hljs-built_in"><span class="hljs-built_in">PUBLIC</span></span> ) { album.incPublicPhotosCount(); } album.<span class="hljs-keyword"><span class="hljs-keyword">update</span></span>(); TX.<span class="hljs-keyword"><span class="hljs-keyword">commit</span></span>();</code> </pre> <br>  Vemos que o cen√°rio de transa√ß√£o comercial mais comum √© ler dados do banco de dados na mem√≥ria do servidor de aplicativos, alterar alguma coisa e salvar os novos valores novamente no banco de dados.  Normalmente, nessa transa√ß√£o, atualizamos v√°rias entidades, v√°rias tabelas. <br><br>  Ao executar uma transa√ß√£o, podem ocorrer modifica√ß√µes competitivas dos mesmos dados de outro sistema.  Por exemplo, o Antispam pode decidir que o usu√°rio √© suspeito e, portanto, todas as fotos do usu√°rio n√£o devem mais ser p√∫blicas, devem ser enviadas com modera√ß√£o, o que significa alterar photo.status para outro valor e desaparafusar os contadores correspondentes.  Obviamente, se esta opera√ß√£o ocorrer sem garantias de atomicidade de aplica√ß√£o e isolamento de modifica√ß√µes concorrentes, como no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ACID</a> , o resultado n√£o ser√° o necess√°rio - o contador de fotos exibir√° o valor errado ou nem todas as fotos ser√£o enviadas com modera√ß√£o. <br><br>  H√° muitos c√≥digos semelhantes que manipulam v√°rias entidades comerciais dentro da estrutura de uma transa√ß√£o durante toda a exist√™ncia do Odnoklassniki.  A partir da experi√™ncia de migrar para o NoSQL com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">consist√™ncia eventual,</a> sabemos que as maiores dificuldades (e custos de tempo) s√£o a necessidade de desenvolver c√≥digo destinado a manter a consist√™ncia dos dados.  Portanto, consideramos o principal requisito para um novo reposit√≥rio fornecer transa√ß√µes ACID l√≥gicas reais para a l√≥gica do aplicativo. <br><br>  Outros requisitos igualmente importantes foram: <br><br><ul><li>  Se o datacenter falhar, a leitura e a grava√ß√£o no novo armazenamento dever√£o estar dispon√≠veis. </li><li>  Mantendo a velocidade atual de desenvolvimento.  Ou seja, ao trabalhar com um novo reposit√≥rio, a quantidade de c√≥digo deve ser aproximadamente a mesma, n√£o h√° necessidade de adicionar algo ao reposit√≥rio, desenvolver algoritmos para resolver conflitos, manter √≠ndices secund√°rios etc. </li><li>  A velocidade do novo armazenamento deve ser alta o suficiente, tanto na leitura de dados quanto no processamento de transa√ß√µes, o que efetivamente significa a inaplicabilidade de solu√ß√µes academicamente rigorosas, universais, mas lentas, como, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">confirma√ß√µes de duas fases</a> . </li><li>  Escalonamento autom√°tico em tempo real. </li><li>  Usando servidores baratos comuns, sem a necessidade de comprar pe√ßas ex√≥ticas de ferro. </li><li>  Oportunidade de desenvolver armazenamento pelos desenvolvedores da empresa.  Em outras palavras, foi dada prioridade a solu√ß√µes pr√≥prias ou baseadas em c√≥digo aberto, preferencialmente em Java. </li></ul><br><h2>  Decis√µes, Decis√µes </h2><br>  Analisando poss√≠veis solu√ß√µes, chegamos a duas op√ß√µes poss√≠veis de arquitetura: <br><br>  O primeiro √© pegar qualquer servidor SQL e implementar a toler√¢ncia a falhas necess√°ria, mecanismo de dimensionamento, cluster de failover, resolu√ß√£o de conflitos e transa√ß√µes ACID distribu√≠das, confi√°veis ‚Äã‚Äãe r√°pidas.  Classificamos esta op√ß√£o como altamente n√£o trivial e demorada. <br><br>  A segunda op√ß√£o √© usar um reposit√≥rio NoSQL pronto com escala implementada, um cluster de failover, resolu√ß√£o de conflitos e implementar transa√ß√µes e SQL.  √Ä primeira vista, mesmo a tarefa de implementar o SQL, para n√£o mencionar as transa√ß√µes ACID, parece uma tarefa h√° anos.  Mas ent√£o percebemos que o conjunto de recursos SQL que usamos na pr√°tica est√° t√£o longe do ANSI SQL quanto o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cassandra CQL est√°</a> longe do ANSI SQL.  Examinando de perto o CQL, percebemos que ele estava pr√≥ximo o suficiente do que precis√°vamos. <br><br><h2>  Cassandra e CQL </h2><br>  Ent√£o, o que √© interessante sobre Cassandra, que recursos ele possui? <br><br>  Em primeiro lugar, aqui voc√™ pode criar tabelas com suporte para v√°rios tipos de dados, voc√™ pode fazer SELECT ou UPDATE na chave prim√°ria. <br><br><pre> <code class="hljs sql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> photos (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span> <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span> <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, owner <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span>,‚Ä¶); <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> photos <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">id</span></span>=?; <span class="hljs-keyword"><span class="hljs-keyword">UPDATE</span></span> photos <span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> ‚Ä¶ <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">id</span></span>=?;</code> </pre> <br>  Para garantir dados de r√©plica consistentes, Cassandra usa uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">abordagem de quorum</a> .  No caso mais simples, isso significa que, quando tr√™s r√©plicas da mesma linha s√£o colocadas em n√≥s diferentes do cluster, o registro √© considerado bem-sucedido se a maioria dos n√≥s (ou seja, dois em tr√™s) confirmar o sucesso dessa opera√ß√£o de grava√ß√£o.  Os dados de uma s√©rie s√£o considerados consistentes se, ao ler, a maioria dos n√≥s tiver sido interrogada e confirmada.  Assim, com a presen√ßa de tr√™s r√©plicas, a consist√™ncia total e instant√¢nea dos dados √© garantida em caso de falha de um n√≥.  Essa abordagem nos permitiu implementar um esquema ainda mais confi√°vel: sempre envie solicita√ß√µes para as tr√™s r√©plicas, aguardando uma resposta das duas mais r√°pidas.  A resposta tardia da terceira r√©plica √© ent√£o descartada.  Um n√≥ que est√° atrasado com uma resposta pode ter s√©rios problemas - freios, coleta de lixo na JVM, recupera√ß√£o direta de mem√≥ria no kernel do linux, falha de hardware, desconex√£o da rede.  No entanto, isso n√£o afeta as opera√ß√µes ou os dados do cliente. <br><br>  A abordagem quando passamos para tr√™s n√≥s e obtemos uma resposta de dois √© chamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">especula√ß√£o</a> : uma solicita√ß√£o de coment√°rios extras √© enviada antes mesmo de "cair". <br><br>  Outra vantagem do Cassandra √© o Batchlog - um mecanismo que garante a aplica√ß√£o completa ou a n√£o aplica√ß√£o completa do pacote de altera√ß√µes que voc√™ faz.  Isso nos permite resolver A no ACID - atomicidade fora da caixa. <br><br>  O mais pr√≥ximo √†s transa√ß√µes com Cassandra - s√£o os chamados " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">uma Transa√ß√µes leves</a> ".  Mas eles est√£o longe de transa√ß√µes ACID "reais": na verdade, √© uma oportunidade de gerar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CAS</a> em dados de apenas um registro, usando consenso no protocolo pesado Paxos.  Portanto, a velocidade de tais transa√ß√µes √© baixa. <br><br><h2>  O que perdemos em Cassandra </h2><br>  Ent√£o, tivemos que implementar transa√ß√µes ACID reais no Cassandra.  Usando o qual poder√≠amos facilmente implementar dois outros recursos convenientes do DBMS cl√°ssico: √≠ndices r√°pidos consistentes, que nos permitiriam realizar amostragem de dados n√£o apenas na chave prim√°ria e no gerador usual de IDs de auto incremento mon√≥tonos. <br><br><h4>  C * one </h4><br>  Assim, o novo <b>C * One</b> DBMS nasceu, consistindo em tr√™s tipos de n√≥s do servidor: <br><br><ul><li>  Armazenamento - os servidores Cassandra (quase) padr√£o respons√°veis ‚Äã‚Äãpelo armazenamento de dados em unidades locais.  √Ä medida que a carga e a quantidade de dados aumentam, seu n√∫mero pode ser facilmente dimensionado para dezenas ou centenas. </li><li>  Coordenadores de transa√ß√£o - permite a execu√ß√£o da transa√ß√£o. </li><li>  Clientes s√£o servidores de aplicativos que implementam opera√ß√µes de neg√≥cios e iniciam transa√ß√µes.  Pode haver milhares desses clientes. </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/eb6/f4f/498/eb6f4f4983f44dcbe63cd545e87f8d1a.png"><br><br>  Todos os tipos de servidores est√£o em um cluster comum, use o protocolo de mensagens interno do Cassandra para se comunicar e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fofocar</a> para trocar informa√ß√µes do cluster.  Com a ajuda do Heartbeat, os servidores aprendem sobre falhas m√∫tuas, suportam um √∫nico esquema de dados - tabelas, sua estrutura e replica√ß√£o;  esquema de particionamento, topologia de cluster etc. <br><br><h4>  Clientes </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/b83/9ff/971/b839ff971b0049d56d55bd309f44ae4e.png"><br><br>  Em vez de drivers padr√£o, o modo Fat Client √© usado.  Esse n√≥ n√£o armazena dados, mas pode atuar como coordenador da execu√ß√£o da consulta, ou seja, o pr√≥prio cliente desempenha a fun√ß√£o de coordenador de suas solicita√ß√µes: pesquisa reposit√≥rios de r√©plicas e resolve conflitos.  Isso n√£o √© apenas mais confi√°vel e r√°pido do que um driver padr√£o que requer comunica√ß√£o com um coordenador remoto, mas tamb√©m permite controlar a transfer√™ncia de solicita√ß√µes.  Fora de uma transa√ß√£o aberta no cliente, as solicita√ß√µes s√£o enviadas para o armazenamento.  Se o cliente abriu a transa√ß√£o, todas as solicita√ß√µes dentro da transa√ß√£o s√£o enviadas ao coordenador da transa√ß√£o. <br><img src="https://habrastorage.org/getpro/habr/post_images/d39/d43/483/d39d43483590319f4d49e41a25316058.png"><br><br><h2>  C * One Transaction Coordinator </h2><br>  O coordenador √© o que implementamos para o C * One do zero.  Ele √© respons√°vel por gerenciar transa√ß√µes, bloqueios e a ordem em que as transa√ß√µes s√£o aplicadas. <br><br>  Para cada transa√ß√£o que est√° sendo atendida, o coordenador gera um carimbo de data / hora: cada subsequente √© maior que a transa√ß√£o anterior.  Como o sistema de resolu√ß√£o de conflitos no Cassandra √© baseado em registros de data e hora (de dois registros conflitantes, o atual com o √∫ltimo registro de data e hora √© considerado relevante), o conflito sempre ser√° resolvido em favor da transa√ß√£o subsequente.  Assim, implementamos os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rel√≥gios Lamport</a> - uma maneira barata de resolver conflitos em um sistema distribu√≠do. <br><br><h2>  Fechaduras </h2><br>  Para garantir o isolamento, decidimos usar o m√©todo mais simples - bloqueios pessimistas na chave prim√°ria do registro.  Em outras palavras, em uma transa√ß√£o, o registro deve primeiro ser bloqueado, s√≥ ent√£o ler, modificar e salvar.  Somente ap√≥s uma confirma√ß√£o bem-sucedida um registro pode ser desbloqueado para que as transa√ß√µes concorrentes possam us√°-lo. <br><br>  A implementa√ß√£o desse bloqueio √© simples em um ambiente n√£o alocado.  H√° duas maneiras principais em um sistema distribu√≠do: implementar o bloqueio distribu√≠do no cluster ou distribuir transa√ß√µes para que as transa√ß√µes que envolvam um √∫nico registro sejam sempre atendidas pelo mesmo coordenador. <br><br>  Como, no nosso caso, os dados j√° est√£o distribu√≠dos por grupos de transa√ß√µes locais no SQL, foi decidido atribuir grupos de transa√ß√µes locais aos coordenadores: um coordenador executa todas as transa√ß√µes com um token de 0 a 9, o segundo com um token de 10 a 19 e assim por diante.  Como resultado, cada uma das inst√¢ncias do coordenador se torna um mestre do grupo de transa√ß√µes. <br><br>  Em seguida, os bloqueios podem ser implementados como um HashMap banal na mem√≥ria do coordenador. <br><br><h2>  Falhas do coordenador </h2><br>  Como um coordenador atende exclusivamente a um grupo de transa√ß√µes, √© muito importante determinar rapidamente o fato de sua falha, para que uma tentativa repetida de executar a transa√ß√£o seja atingida.  Para torn√°-lo r√°pido e confi√°vel, aplicamos um protocolo de quorum hearbeat totalmente conectado: <br><br>  Cada data center tem pelo menos dois n√≥s coordenadores.  Periodicamente, cada coordenador envia uma mensagem de pulsa√ß√£o para os outros coordenadores e informa sobre seu funcionamento, bem como as mensagens de pulsa√ß√£o das quais coordenadores no cluster pela √∫ltima vez. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cde/1e4/ccd/cde1e4ccd6d23620eda08adc231aeec7.jpg"><br><br>  Tendo recebido informa√ß√µes semelhantes dos outros na composi√ß√£o de suas mensagens de pulsa√ß√£o, cada coordenador decide por si mesmo quais n√≥s do cluster funcionam e quais n√£o s√£o, guiados pelo princ√≠pio do quorum: se o n√≥ X recebeu informa√ß√µes da maioria dos n√≥s no cluster sobre o recebimento normal de mensagens do n√≥ Y, Y trabalha.  Por outro lado, assim que a maioria relatar a perda de mensagens do n√≥ Y, Y falhar√°.  √â curioso que, se um quorum disser ao n√≥ X que n√£o recebe mais mensagens dele, o pr√≥prio n√≥ X considerar√° que falhou. <br><br>  As mensagens de pulsa√ß√£o s√£o enviadas em alta frequ√™ncia, cerca de 20 vezes por segundo, com um per√≠odo de 50 ms.  Em Java, √© dif√≠cil garantir uma resposta do aplicativo de 50 ms devido ao comprimento compar√°vel de pausas causadas pelo coletor de lixo.  Conseguimos atingir esse tempo de resposta usando o coletor de lixo G1, o que nos permite especificar o destino para a dura√ß√£o das pausas do GC.  No entanto, √†s vezes, muito raramente, a pausa do coletor ultrapassa 50 ms, o que pode levar a uma falsa detec√ß√£o de falha.  Para evitar isso, o coordenador n√£o relata a falha do n√≥ remoto quando a primeira mensagem de pulsa√ß√£o desaparece dele, apenas se v√°rias desaparecerem consecutivamente.Portanto, conseguimos detectar a falha do n√≥ do coordenador em 200 ms. <br><br>  Mas n√£o basta entender rapidamente qual n√≥ parou de funcionar.  Voc√™ precisa fazer algo sobre isso. <br><br><h2>  Reserva </h2><br>  O esquema cl√°ssico pressup√µe, no caso de recusa de um mestre, iniciar a elei√ß√£o de um novo usando um dos algoritmos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">universais</a> da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">moda</a> .  No entanto, esses algoritmos t√™m problemas bem conhecidos com a converg√™ncia do tempo e a dura√ß√£o do pr√≥prio processo eleitoral.  Conseguimos evitar atrasos adicionais usando o circuito equivalente de coordenadores em uma rede totalmente conectada: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e90/45e/007/e9045e00777362a5846eb78ef15bedea.png"><br><br>  Suponha que desejemos executar uma transa√ß√£o no grupo 50. Determinaremos antecipadamente um esquema de substitui√ß√£o, ou seja, quais n√≥s executar√£o as transa√ß√µes do grupo 50 no caso de uma falha do coordenador principal.  Nosso objetivo √© manter o sistema operacional em caso de falha no data center.  Determinamos que a primeira reserva ser√° um n√≥ de outro datacenter e a segunda reserva ser√° um n√≥ do terceiro.  Esse esquema √© selecionado uma vez e n√£o muda at√© que a topologia do cluster seja alterada, ou seja, at√© que novos n√≥s o entrem (o que acontece muito raramente).  O procedimento para escolher um novo mestre ativo em caso de falha do antigo ser√° sempre este: a primeira reserva se tornar√° o mestre ativo e, se deixar de funcionar, a segunda reserva se tornar√°. <br><br>  Esse esquema √© mais confi√°vel que o algoritmo universal, pois para ativar um novo mestre √© suficiente determinar o fato de falha do antigo. <br><br>  Mas como os clientes entender√£o qual dos mestres est√° trabalhando agora?  Por 50 ms, n√£o √© poss√≠vel enviar informa√ß√µes para milhares de clientes.  Uma situa√ß√£o √© poss√≠vel quando um cliente envia uma solicita√ß√£o para abrir uma transa√ß√£o, ainda n√£o sabendo que esse assistente n√£o est√° mais funcionando, e a solicita√ß√£o fica paralisada.  Para impedir que isso aconte√ßa, os clientes enviam especulativamente uma solicita√ß√£o para abrir uma transa√ß√£o imediatamente para o mestre do grupo e suas duas reservas, mas apenas quem √© o mestre ativo no momento responder√° a essa solicita√ß√£o.  O cliente executar√° toda a comunica√ß√£o subsequente dentro da transa√ß√£o apenas com o mestre ativo. <br><br>  Os mestres de backup recebem solicita√ß√µes de transa√ß√µes n√£o pr√≥prias na fila de transa√ß√µes n√£o nascidas, onde s√£o armazenadas por algum tempo.  Se o mestre ativo morre, o novo mestre processa solicita√ß√µes para abrir transa√ß√µes da fila e responde ao cliente.  Se o cliente j√° conseguiu abrir uma transa√ß√£o com o antigo mestre, a segunda resposta ser√° ignorada (e, obviamente, essa transa√ß√£o n√£o ser√° conclu√≠da e ser√° repetida pelo cliente). <br><br><h2>  Como uma transa√ß√£o funciona </h2><br>  Suponha que um cliente enviou a um coordenador uma solicita√ß√£o para abrir uma transa√ß√£o para uma entidade com essa chave prim√°ria.  O coordenador bloqueia essa entidade e a coloca na tabela de bloqueios na mem√≥ria.  Se necess√°rio, o coordenador l√™ essa entidade da loja e armazena os dados recebidos em um estado de transa√ß√£o na mem√≥ria do coordenador. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4d1/dfb/dcd/4d1dfbdcd92e4b05ca49ef5168177eb8.png"><br><br>  Quando o cliente deseja alterar os dados na transa√ß√£o, ele envia ao coordenador uma solicita√ß√£o para atualizar a entidade e coloca os novos dados na tabela de status da transa√ß√£o na mem√≥ria.  Isso completa a grava√ß√£o - a grava√ß√£o n√£o √© realizada no reposit√≥rio. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/00e/803/570/00e803570a0fbe19cb76786cbc6f0142.png"><br><br>  Quando um cliente solicita, dentro da estrutura de uma transa√ß√£o ativa, seus pr√≥prios dados alterados, o coordenador age assim: <br><br><ul><li>  se o ID j√° estiver na transa√ß√£o, os dados ser√£o retirados da mem√≥ria; </li><li>  se n√£o houver um ID na mem√≥ria, os dados ausentes ser√£o lidos nos n√≥s de armazenamento, combinados com os que j√° est√£o na mem√≥ria, e o resultado ser√° retornado ao cliente. </li></ul><br>  Assim, o cliente pode ler suas pr√≥prias altera√ß√µes, enquanto outros n√£o as veem, porque s√£o armazenadas apenas na mem√≥ria do coordenador e ainda n√£o est√£o nos n√≥s do Cassandra. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d8e/140/5f7/d8e1405f7995228ec3d061af59f1f685.png"><br><br>  Quando o cliente envia uma confirma√ß√£o, o estado na mem√≥ria do servi√ßo √© salvo pelo coordenador no lote registrado e, j√° na forma de um lote registrado, √© enviado aos reposit√≥rios do Cassandra.  Os reposit√≥rios fazem todo o necess√°rio para que este pacote seja aplicado atomicamente (totalmente) e retornam uma resposta ao coordenador, que libera os bloqueios e confirma o sucesso da transa√ß√£o para o cliente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/090/739/9fc/0907399fc025879f16174ff26163a937.png"><br><br>  E para reverter para o coordenador, basta liberar a mem√≥ria ocupada pelo estado da transa√ß√£o. <br><br>  Como resultado das melhorias acima, implementamos os princ√≠pios do ACID: <br><br><ul><li>  <b>Atomicidade</b> .  √â uma garantia de que nenhuma transa√ß√£o ser√° parcialmente comprometida com o sistema, todas as suas subopera√ß√µes ser√£o conclu√≠das ou nenhuma delas ser√° executada.  Cumprimos esse princ√≠pio devido ao lote registrado no Cassandra. </li><li>  <b>Coer√™ncia</b> .  Cada transa√ß√£o bem-sucedida, por defini√ß√£o, captura apenas resultados aceit√°veis.  Se, ap√≥s abrir uma transa√ß√£o e executar parte das opera√ß√µes, for constatado que o resultado n√£o √© v√°lido, uma revers√£o ser√° realizada. </li><li>  <b>Isolamento</b> .  Quando uma transa√ß√£o √© executada, transa√ß√µes paralelas n√£o devem afetar seu resultado.  As transa√ß√µes concorrentes s√£o isoladas usando bloqueios pessimistas no coordenador.  Para leituras fora da transa√ß√£o, o princ√≠pio de isolamento no n√≠vel Read Committed √© respeitado. </li><li>  <b>Sustentabilidade</b> .  Independentemente dos problemas nos n√≠veis mais baixos (desenergiza√ß√£o do sistema, falha de hardware), as altera√ß√µes feitas por uma transa√ß√£o conclu√≠da com √™xito devem permanecer salvas ap√≥s a retomada da opera√ß√£o. </li></ul><br><h2>  Leitura de √≠ndice </h2><br>  Tome uma tabela simples: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> photos ( id <span class="hljs-type"><span class="hljs-type">bigint</span></span> <span class="hljs-keyword"><span class="hljs-keyword">primary key</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">owner</span></span> <span class="hljs-type"><span class="hljs-type">bigint</span></span>, modified <span class="hljs-type"><span class="hljs-type">timestamp</span></span>, ‚Ä¶)</code> </pre> <br>  Ela tem um ID (chave prim√°ria), propriet√°rio e data da mudan√ßa.  Voc√™ precisa fazer uma solicita√ß√£o muito simples: selecione os dados do propriet√°rio com a data da altera√ß√£o "para o √∫ltimo dia". <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> owner=? <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> modified&gt;?</code> </pre> <br>  Para que essa consulta funcione rapidamente, no DBMS cl√°ssico do SQL, voc√™ precisa criar um √≠ndice por colunas (propriet√°rio, modificado).  Podemos fazer isso de maneira simples, j√° que agora temos garantias ACID! <br><br><h2>  √çndices em C * One </h2><br>  H√° uma tabela de origem com fotos, na qual o ID do registro √© a chave prim√°ria. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/039/5b3/a78/0395b3a784329992b88ba0618a94a7f1.jpg"><br><br>  Para o √≠ndice C *, o One cria uma nova tabela, que √© uma c√≥pia do original.  A chave corresponde √† express√£o do √≠ndice e tamb√©m inclui a chave prim√°ria do registro da tabela de origem: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/92a/8c2/93e/92a8c293e8c145dc37f49a5126e68095.jpg"><br><br>  Agora, a solicita√ß√£o do "propriet√°rio do √∫ltimo dia" pode ser reescrita como sele√ß√£o de outra tabela: <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> i1_test <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> owner=? <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> modified&gt;?</code> </pre> <br>  A consist√™ncia dos dados da tabela de fotos original e o √≠ndice i1 √© mantida automaticamente pelo coordenador.  Com base apenas no esquema de dados, quando a altera√ß√£o √© recebida, o coordenador gera e se lembra da altera√ß√£o n√£o apenas na tabela principal, mas tamb√©m nas altera√ß√µes de c√≥pia.  Nenhuma a√ß√£o adicional √© executada com a tabela de √≠ndice, os logs n√£o s√£o lidos, os bloqueios n√£o s√£o usados.  Ou seja, adicionar √≠ndices quase n√£o consome recursos e praticamente n√£o afeta a velocidade da aplica√ß√£o de modifica√ß√µes. <br><br>  Usando o ACID, conseguimos implementar √≠ndices "como no SQL".  Eles t√™m consist√™ncia, podem ser dimensionados, funcionam rapidamente, podem ser compostos e incorporados √† linguagem de consulta CQL.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para oferecer suporte a √≠ndices, voc√™ n√£o precisa fazer altera√ß√µes no c√≥digo do aplicativo. </font><font style="vertical-align: inherit;">Tudo √© simples, como no SQL. </font><font style="vertical-align: inherit;">E o mais importante, os √≠ndices n√£o afetam a velocidade de execu√ß√£o das modifica√ß√µes na tabela de transa√ß√µes original.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O que aconteceu </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desenvolvemos o C * One h√° tr√™s anos e o colocamos em opera√ß√£o comercial. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que conseguimos no final? Vamos avaliar isso usando o exemplo de um subsistema para processar e armazenar fotos, um dos tipos mais importantes de dados em uma rede social. N√£o se trata dos corpos das pr√≥prias fotos, mas de todos os tipos de meta-informa√ß√µes. Agora, em Odnoklassniki, existem cerca de 20 bilh√µes de registros, o sistema processa 80 mil solicita√ß√µes de leitura por segundo, at√© 8 mil transa√ß√µes ACID por segundo associadas √† modifica√ß√£o de dados. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quando usamos o SQL com fator de replica√ß√£o = 1 (mas no RAID 10), as meta-informa√ß√µes da foto foram armazenadas em um cluster altamente acess√≠vel de 32 m√°quinas com o Microsoft SQL Server (mais 11 backup). Tamb√©m alocou 10 servidores para armazenar backups. Um total de 50 carros caros. Ao mesmo tempo, o sistema trabalhava com carga nominal, sem reserva.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ap√≥s a migra√ß√£o para o novo sistema, obtivemos o fator de replica√ß√£o = 3 - uma c√≥pia em cada data center. O sistema consiste em 63 n√≥s de armazenamento Cassandra e 6 m√°quinas coordenadoras, totalizando 69 servidores. Mas essas m√°quinas s√£o muito mais baratas, seu custo total √© de cerca de 30% do custo do sistema em SQL. Nesse caso, a carga √© mantida em 30%. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Com a introdu√ß√£o do C * One, os atrasos tamb√©m diminu√≠ram: no SQL, a opera√ß√£o de grava√ß√£o levou cerca de 4,5 ms. Em C * One - cerca de 1,6 ms. A dura√ß√£o da transa√ß√£o √© em m√©dia inferior a 40 ms, a confirma√ß√£o √© realizada em 2 ms, a dura√ß√£o de leitura e grava√ß√£o √© em m√©dia 2 ms. O 99¬∫ percentil - apenas 3-3,1 ms, o n√∫mero de tempos limite diminuiu 100 vezes - tudo devido ao uso generalizado da especula√ß√£o.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">At√© o momento, a maioria dos n√≥s do SQL Server foi desativada; novos produtos s√£o desenvolvidos apenas usando o C * One. </font><font style="vertical-align: inherit;">Adaptamos o C * One para trabalhar em </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">uma nuvem √∫nica</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , o que nos permitiu acelerar a implanta√ß√£o de novos clusters, simplificar a configura√ß√£o e automatizar a opera√ß√£o. </font><font style="vertical-align: inherit;">Sem o c√≥digo fonte, seria muito mais dif√≠cil e complicado. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora, estamos trabalhando para transferir nossas outras instala√ß√µes de armazenamento para a nuvem - mas essa √© uma hist√≥ria completamente diferente.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt417593/">https://habr.com/ru/post/pt417593/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt417583/index.html">Amanh√£ ICFP Contest 2018, felicidades! (+ √∫til para participar pela primeira vez)</a></li>
<li><a href="../pt417585/index.html">Como entrar no comit√™ de programa de uma confer√™ncia de classe e por que voc√™ precisa</a></li>
<li><a href="../pt417587/index.html">M√≠dia: ataques cibern√©ticos em larga escala aceleraram o crescimento da capitaliza√ß√£o de empresas do setor de seguran√ßa da informa√ß√£o</a></li>
<li><a href="../pt417589/index.html">Sete regras simples para tornar a Internet acess√≠vel a todos</a></li>
<li><a href="../pt417591/index.html">Como "aprender" ingl√™s em um ano sozinho ou um artigo para quem n√£o trabalhou com ingl√™s</a></li>
<li><a href="../pt417595/index.html">Antiguidades: Palm OS, c√≥digo eficiente e fotos nojentas</a></li>
<li><a href="../pt417597/index.html">Armazenamento confi√°vel com DRBD9 e Proxmox (parte 2: iSCSI + LVM)</a></li>
<li><a href="../pt417601/index.html">Escolha um servidor. O que procurar? Lista de verifica√ß√£o</a></li>
<li><a href="../pt417603/index.html">An√∫ncio de uma mitap m√≥vel: o que fazer quando o aplicativo se tornar grande?</a></li>
<li><a href="../pt417605/index.html">No√ß√µes b√°sicas de modelagem 3D para impress√£o 3D</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
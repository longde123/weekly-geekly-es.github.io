<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕗 🎸 👎 Computer Vision sieht Emotionen, Puls, Atmung und Lügen - aber wie kann man darauf ein Startup aufbauen? Gespräch mit Neurodata Lab 🛋️ 👨🏾‍🤝‍👨🏽 👇🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Unsere Beziehung zum Computer Vision war nicht so laut, bis wir lernten, wie man Wunder mit menschlichen Gesichtern vollbringt. Algorithmen ersetzen M...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Computer Vision sieht Emotionen, Puls, Atmung und Lügen - aber wie kann man darauf ein Startup aufbauen? Gespräch mit Neurodata Lab</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/habr_career/blog/465153/"><img src="https://habrastorage.org/webt/5f/q8/9w/5fq89wvwqezw4pwf_j7u2-bnq64.jpeg"><br><br>  Unsere Beziehung zum Computer Vision war nicht so laut, bis wir lernten, wie man Wunder mit menschlichen Gesichtern vollbringt.  Algorithmen ersetzen Menschen in Fotos und Videos, ändern Alter, Rasse und Geschlecht.  Dies ist die wichtigste Online-Unterhaltung der letzten Jahre und eine Quelle der Angst.  Heute stürmen Apps die Charts, morgen sahen Demonstranten Säulen mit Kameras, die Gesichter erkennen.  Und anscheinend stehen wir erst am Anfang der Reise.  Was der Computer aus unseren Gesichtern lesen kann, wird immer mehr. <br><br>  Anfang dieses Monats besuchten wir das Büro des Neurodata Lab.  Die Hauptrichtung für das Unternehmen ist das Erkennen menschlicher Emotionen.  Wir haben versucht herauszufinden, wie und warum dies gemacht wird. <br><br><blockquote>  Bei My Circle erhielt Neurodata Lab eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durchschnittliche Punktzahl von 4,6</a> und eine durchschnittliche Empfehlung von 95% seiner Mitarbeiter, die Kriterien wie berufliches Wachstum, interessante Aufgaben, gute Beziehungen zu Kollegen und die Tatsache, dass das Unternehmen die Welt zu einem besseren Ort macht, bewerteten. </blockquote><a name="habracut"></a><br><hr><br>  2016 nahmen zehn Schauspieler - fünf Männer und fünf Frauen - an ungewöhnlichen Dreharbeiten teil.  Sie gingen zu einem leeren Bereich, in schwarzen, eng anliegenden Anzügen, und zeigten auf Kameras in verschiedenen Ecken des Raumes vor dem Hintergrund der grünen Wand „nichts“ - nur ihren neutralen Zustand. <br><br>  Dann spielten die Schauspieler kurze Drehbücher aus.  Es gab keine Repliken in den Skripten, nur Beschreibungen von Situationen, also improvisierten die Schauspieler.  In jeder Szene mussten sie eine von sechs Emotionen erleben - Wut, Traurigkeit, Ekel, Freude, Angst oder Überraschung.  Die Mimik und Gesten erfahrener Schauspieler werden oft stereotyp, eher für das Theater als für das wirkliche Leben geeignet, daher waren hier alle Schauspieler Studenten. <br><br><img src="https://habrastorage.org/webt/kc/pw/pc/kcpwpc8gnvulu2api4r0rwsbwow.jpeg"><br><br>  Ihnen folgte ein Lehrer der Filmschule, aber nicht nur.  Der Hauptdirektor war eine Wissenschaftlerin und Forscherin Olga Perepelkina.  Neben Video und Ton am Set wurden bioelektrische Reaktionen der Hautoberfläche und andere physiologische Eigenschaften aufgezeichnet.  Jede Szene wurde mehrmals von einer anderen Besetzung gedreht, und als Ergebnis sammelten sie ungefähr sieben Stunden Material. <br><br>  Nachdem die Schauspieler ihre Arbeit beendet hatten, beschrieben sie, wo und welche Emotionen sie während des Spiels tatsächlich erlebten.  Dann sahen sich weitere 21 Leute die Videos an und in jedem der Videos bemerkten sie, welche Emotionen der Schauspieler zu erleben schien.  Wann beginnt diese Emotion und wann endet sie? <br><br><img src="https://habrastorage.org/webt/os/vg/op/osvgop-sjzowyyhy4so9oxeguku.jpeg"><br><br>  So begann die Arbeit am ersten russischsprachigen multimodalen Datensatz zur Emotionserkennung - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RAMAS</a> . <br><br>  Das erhaltene Material war jedoch nur für wissenschaftliche Forschung und Experimente geeignet - nicht für das Training von Algorithmen im industriellen Maßstab. <br><br>  - (Olga Perepelkina) Wir mussten einen riesigen Datensatz sammeln.  Nicht 7, sondern 107 und mehr Stunden.  Wir haben die Emotion Miner-Webplattform erstellt, eine Reihe von Videos hochgeladen, die im Internet öffentlich verfügbar sind, Zehntausende Menschen aus der ganzen Welt zusammengebracht und damit begonnen, die Daten zu markieren.  So haben wir 140 Stunden Video auf 20 Skalen markiert (nicht nur Emotionen, sondern auch verschiedene kognitive und soziale Merkmale) und den weltweit größten emotionalen Datensatz gesammelt. <br><br>  <b>- Und wie haben Sie es geschafft, so viele Leute zu finden, die Sie markieren können?</b> <br>  - (O.P.) Es ist einfach - wir haben ihnen Geld für die Arbeit bezahlt.  Durchgeführte Werbeaktionen, ein kleines Budget in Marketing investiert.  Im Prinzip war es nicht sehr schwierig.  Mittlerweile sind fast 70.000 Menschen auf der Plattform registriert.  In Wirklichkeit haben jedoch etwa zweitausend Personen den Datensatz markiert. <br><br><hr><br><h2>  Produkte </h2><br>  Das Startup Neurodata Lab wurde von den Unternehmern George Pliev und Maxim Ryabov gegründet.  Sie finanzierten die Forschung nicht aus wissenschaftlichen Gründen, sondern um eine kommerzielle Anwendung für die Technologie zu finden.  Jetzt ist Affective Computing oder „Emotional Computing“ nicht der beliebteste Bereich auf dem Markt für neuronale Netze und Computer Vision.  Auf dem Gebiet der Gesichtserkennung besteht ein starker Wettbewerb.  Unterhaltungsanwendungen werden nacheinander in den Fokus gerückt.  Und Systeme, die mit Emotionen arbeiten, verlassen den Status „vielversprechend“ für mehrere Jahre nicht.  Nach Prognosen von Gartner und anderen Studien prognostiziert sie jedoch ein schnelles Wachstum. <br><br>  Neurodata Lab forscht seit etwa drei Jahren, sammelt Daten und entwickelt Algorithmen.  Jetzt verwenden sie Forschungsergebnisse in kommerziellen Produkten.  Zum Beispiel hat Neurodata Lab eine emotionale KI für Promobot-Roboter entwickelt.  Der Roboter verwendete ein Emotionserkennungssystem, um korrekt auf die Hinweise der Personen zu reagieren, die sich an ihn wenden.  Die Demo wurde dieses Jahr auf der CES <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gezeigt</a> . <br><br>  Der Algorithmus wird in Call Centern verwendet, um Anrufe zu überwachen und die Leistung der Mitarbeiter zu bewerten.  Jetzt geschieht dies alles manuell - Manager müssen selektiv Anrufaufzeichnungen abhören und prüfen, ob der Mitarbeiter dem Kunden gegenüber unhöflich war oder im Rahmen des Anstands gehalten wurde.  Das System kann dies automatisch und in Echtzeit tun.  Dabei wird auch die emotionale Stimmung des Klienten beurteilt - er war mit der Behandlung zufrieden oder nicht.  Ein Pilot eines ähnlichen Produkts Neurodata Lab wurde in Rosbank gestartet.  Der Algorithmus analysiert Anrufe, um die Kundenzufriedenheit zu messen. <br><br>  Die zweite Produktbranche ist etwas globaler.  Das Unternehmen stellt seine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">API her</a> - eine ganze Reihe von Tools für Entwickler von Drittanbietern.  Jetzt enthält es eine Analyse der Emotionen, einen Gesichts-Tracker und Tonanalysatoren, mit denen Sie eine Audioaufnahme mit mehreren Stimmen in verschiedene Audiospuren aufteilen und das Rauschen trennen können.  In Kürze wird es einen Body-Tracker, einen Pulsfrequenzdetektor, einen Atemtracker aus dem Video einer Person und andere Technologien oder Algorithmen geben. <br><br><hr><br><h2>  Arbeitsprinzip </h2><br>  Ein Mensch lernt, Emotionen unbewusst zu definieren - von Kindheit an beginnt er, bestimmte Verhaltensmuster mit den Emotionen zu assoziieren, die Menschen in seiner Umgebung erleben.  Nachdem er dies bereits gelernt hat, kann er analysieren, welche Zeichen es tut.  Das offensichtlichste ist der Ausdruck, den Mund und Augen annehmen.  Aber im Gesicht sind viele Gesichtsmuskeln, die eine unglaubliche Menge an ausdrucksstarken Nuancen erzeugen.  Wir nehmen sie automatisch wahr, obwohl wir bestimmte Details bewusst wahrnehmen können. <br><br>  Das neuronale Netzwerk analysiert auch Hunderte von Stunden Video, das von Personen markiert wurde.  Und die Zeichen, anhand derer das System Emotionen klassifiziert, sind nicht immer offensichtlich. <br><br>  - (Andrey Belyaev) Für einige Klassen gibt es gemeinsame Muster.  Zum Beispiel sind die Klassen „Wut“ und „Überraschung“ durch einen starken Ausdruck im Gesicht gekennzeichnet - hochgezogene Augenbrauen, abgerundete Augen, Rauch aus den Ohren.  Das Gitter reagiert sicherlich auf sie, aber nicht nur.  Zum Beispiel wird sie mit kleinen Augenbrauen, die wie hochgezogen aussehen, ruhig die richtige Klasse bestimmen, da sie auch auf die Dynamik von Veränderungen reagiert.  Eine der interessanten Klassen in dieser Hinsicht ist „Traurigkeit“.  Wenn ein Mensch traurig ist, ändert sich sein Gesicht meistens lange nicht.  Grid bemerkt keine Dynamik im Ausdruck und geht davon aus, dass es entweder „neutral“ oder „traurig“ ist, und klärt erst dann die verbleibenden Zeichen und kommt zu dem Schluss, dass die Klasse richtig ist. <br><br>  <b>- Was ist mit dem Sound?</b>  <b>Bestimmte Frequenzen, Bereiche, Töne?</b> <br>  - (A.B.) Ton ist komplizierter.  Jede Person hat ihre eigene Standardlautstärke, man kann sich nicht an die Klangstärke binden.  Jemand kann leise und gleichmäßig sprechen, aber tatsächlich ist er schrecklich wütend.  Und selbst wenn wir den Klang visualisieren und verstehen, worauf das System achtet, können wir ihn nicht so gut erklären wie mit dem Gesicht.  Das Gesicht hat klare Punkte: Augenbrauen, Augen, Ohren und mehr.  Aber es ist kein Ton zu hören.  Schall wird in Form eines Spektrogramms in das Gitter eingespeist, und welche spezifischen Teile davon für was und zu welchem ​​Zeitpunkt verantwortlich sind, ist viel schwieriger zu verstehen.  Daher gibt es keine Standardantwort, worauf das Raster bei der Arbeit mit Ton achtet. <br><br>  <b>- Wie zeichnet man den Puls auf?</b> <br>  - (O.P.) Mikroveränderungen der Hautfarbe werden verfolgt.  Wenn das Herz schlägt, ist das Blut mit Sauerstoff gesättigt, die Sauerstoffversorgung des Blutes ändert sich und aufgrund dessen ändert sich die Hautfarbe.  Es wird nicht mit dem Auge funktionieren, aber mit Hilfe des Algorithmus ist es möglich. <br><br>  <b>- Dies hängt jedoch stark von der Qualität des Videos ab.</b> <br>  - (O.P.) Wir haben diesen Algorithmus schon lange gesägt und können nicht nur mit einer coolen Kamera, sondern auch mit einer normalen Webcam arbeiten.  Wir wissen, wie man arbeitet, wenn der Bildschirm flackert.  Zum Beispiel, wenn eine Person einen Film sieht und sich ihre Beleuchtungsstärke ständig ändert.  Wir können mit Bedingungen arbeiten, unter denen sich eine Person bewegt und spricht. <br><br>  Der Impuls ist ein periodisches Signal und wird klar überwacht, und die Beleuchtung des Films ändert sich nicht periodisch.  Daher kann ein nützliches Signal vom Rauschen getrennt werden.  Wir haben diese Technologie sogar mit Fitness-Trackern <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verglichen</a> .  Unser Algorithmus funktioniert genauso gut - und sogar besser als einige von ihnen. <br><br>  <b>- Das System kann sehen, was eine Person nicht sieht, aber eine Person erkennt Emotionen immer noch besser.</b>  <b>Warum?</b> <br>  - (O.P.) Eine Person macht es besser, weil sie Kontextinformationen berücksichtigt.  Dazu ist jedoch ein multimodales System erforderlich, das die Genauigkeit verbessert, indem Gesicht, Stimme, Gesten, Puls, Atmung und semantische Analyse des Textes sofort analysiert werden. <br><br>  So funktioniert die menschliche Wahrnehmung.  Sie sehen einen Mann von hinten, sehen ihm beim Sitzen zu und denken: "Es scheint, er ist traurig."  Unser Ziel ist es, einen Algorithmus zu entwickeln, der Emotionen als Person wahrnimmt - im Allgemeinen unter allen Bedingungen für alle Informationen. <br><br>  Der Vorteil des Systems gegenüber Menschen besteht nun darin, dass es eine große Datenmenge automatisch analysieren kann.  Manchmal kann es eine Person besser machen, aber Sie werden sie nicht dazu bringen, rund um die Uhr zu sitzen und mit den Ohren zuzuhören, z. B. Anrufe bei einem Callcenter. <br><br>  <b>- Wenn ich Emotionen erlebe, aber versuche, sie zu verbergen, wird das System dies verstehen?</b> <br>  - (O.P.) Vielleicht. <br><br><hr><br><h2>  Wie läuft die Entwicklung? </h2><br>  Neurodata Lab ist ein kleines Unternehmen, das bis vor kurzem nur als Labor existierte.  Es verfügt über eine Wissenschaftsabteilung, ein Data Science-Team und eine Entwicklungsabteilung, die neue Entwicklungen und Entdeckungen in Produkte packt.  Jede Abteilung besteht aus 5-6 Personen.  Insgesamt beschäftigt das Team rund 30 Mitarbeiter. <br><br><h3>  Forscher </h3><br>  In der wissenschaftlichen Abteilung arbeiten Psychologen, Physiologen und Biologen.  Es gibt nur vier Mitarbeiter und drei Praktikanten, aber sie haben ein ganzes internationales Netzwerk von Kooperationen aufgebaut.  In Russland gibt es beispielsweise Projekte in Zusammenarbeit mit der Moskauer Staatsuniversität, der Higher School of Economics und der RANEPA.  Im Ausland - mit der Universität Glasgow, der Technischen Universität Paris, der Universität Genf, dem technischen Labor in Genua, das sich mit der Analyse von Bewegungen befasst. <br><br>  Wissenschaftler, die emotionales Rechnen betreiben, sind eine ganze Gemeinschaft.  Sie treffen sich regelmäßig zu gemeinsamen Workshops an verschiedenen Universitäten auf der ganzen Welt.  Alle zwei Jahre findet eine große Konferenz statt, die ausschließlich der emotionalen Technologie gewidmet ist.  In diesem Jahr wird das Neurodata Lab auf dieser Konferenz einen eigenen Workshop organisieren. <br><br><img src="https://habrastorage.org/webt/to/7t/dy/to7tdyhho0p_vnn2vucsvunhxuq.jpeg"><br><br>  <b>- Ich frage mich, was ist die tägliche Arbeit eines Forschers?</b> <br>  - (O.P.) Zuerst lesen sie Artikel.  Zum Beispiel wollten wir lernen, wie man eine Lüge erkennt, nicht nur Emotionen, und wir müssen herausfinden, was eine Lüge ist, wie ein Lügendetektor funktioniert, was bereits in diesem Bereich getan wurde, was die Probleme eines klassischen Polygraphen sind, wie man sich täuschen lässt, welche Algorithmen am coolsten sind. wie die menschliche Psyche angeordnet ist, welche psychologischen Merkmale es gibt, wenn eine Person lügt, wie die Physiologie funktioniert, warum (und ob) die Nase einer Person kälter wird und ihre Ohren rot werden, wenn sie betrügt, und so weiter. <br><br>  Dann führen wir eine Vielzahl von Experimenten durch.  Um ein System zu erstellen, das den Puls und die Atemfrequenz aus dem Video erkennt, mussten viele Daten gesammelt werden.  Es kommen ständig Themen zu uns, wir haben Ausrüstung und alle möglichen Dinge, die den Puls einer Person auf Kontaktart messen.  Wir messen EKG, Photoplethysmographie, hautgalvanische Reaktion.  Wir hatten lustige Experimente, als wir verstehen wollten, wie sich der Blutfluss über das Gesicht bewegt, und dann haben wir Elektroden direkt auf das Gesicht geklebt. <br><br><img src="https://habrastorage.org/webt/8g/mv/g7/8gmvg785lgujytcycc3igdt0it0.jpeg"><br><br>  Schließlich zeigen wir Menschen verschiedene Vidosiki.  Wir versuchen sie zu erschrecken oder umgekehrt - zu jubeln.  Forscher analysieren Daten, berücksichtigen Statistiken, schreiben Artikel und Patente basierend auf diesen Daten.  Dann kommen sie in die technische Abteilung zu Andrei und sagen: "Wir haben eine coole Sache gelesen, ein Experiment durchgeführt, Sie können versuchen, einen Algorithmus zu erstellen, der so funktioniert."  Oder Andrei kommt zu uns und sagt: "Wir wollen Stürze erkennen, wir müssen herausfinden, wie man Daten sammelt."  Und die wissenschaftliche Abteilung setzt sich und überlegt, wie dies einfach und schnell geschehen kann. <br><br>  <b>- Traumjob.</b> <br>  - (AB) Einige Leute denken - andere tun es. <br><br><hr><br><h3>  Datum Wissenschaftler und Entwickler </h3><br>  Data Science arbeitet parallel zur Produktentwicklung.  Datasenteristen trainieren neuronale Netze auf Torch, wenn in der Forschung Handlungsspielraum besteht, und auf MXnet, wenn Sie eine schnell arbeitende Lösung benötigen.  Nachdem alle Hypothesen zur Anwendbarkeit neuronaler Netze bestätigt wurden, übertragen die Jungs sie an TensorRT, um die Arbeitsgeschwindigkeit zu erhöhen und sie dem Entwicklungsteam zur Implementierung in der Produktion zu übergeben. <br><br>  Neurodata Lab hat einen eigenen Cloud-Service erstellt, auf den andere Entwickler zugreifen können - für Forschungs- oder kommerzielle Projekte. <br><br>  - (A.B.) Der Software-Kernel, der Aufgaben zwischen neuronalen Netzen verteilt, ist in Python geschrieben.  Wir mussten es schnell schreiben, aber es stellte sich ziemlich gut heraus.  Er arbeitet mit Dockern, kommuniziert über RabbitMQ, läuft in Postgres und die gRPC-Schicht hängt oben, wodurch Sie eine sichere Verbindung mit der Außenwelt herstellen und anderen Programmierern und Forschern Zugriff auf unsere Technologien gewähren können. <br><br>  Web in Symphony geschrieben.  API implementiert mit gRPC.  Dies ist eine coole Google-Sache, mit der Sie einen sicheren Kanal erstellen und Schlüssel mit dem System austauschen können, sodass nur auf bestimmte interne Funktionen zugegriffen werden kann.  Beispielsweise können Sie nur Tools einen Schlüssel geben, mit denen Gesichter erkannt und Emotionen erkannt werden können. <br><br>  Ich arbeite an einer Idee - ich möchte mein eigenes kleines Rechenzentrum bauen, in dem sich die Inferenz dreht.  Und es wird auf Jetson Nano basieren.  Dies ist so ein kleiner Einplatinencomputer für zehntausend Rubel.  Wie der Raspberry Pi nur mit einer Grafikkarte.  Mit einem Prozessor, RAM und allem anderen kostet es 6-mal billiger als 1080Ti, ohne die restlichen Computerkomponenten zu berücksichtigen, aber es arbeitet auch ungefähr 6-mal langsamer. <br><br>  <b>- Und was wird es geben?</b> <br>  - (AB) Erstens ist es billiger und funktioniert ungefähr genauso.  Zweitens wird es die Umwelt nicht mehr so ​​sehr schädigen.  Drittens brauchen sie nicht viel Strom.  Sechs Jetson Nano, die zusammen fast 1080 Ti antreiben, verbrauchen sechsmal weniger Energie und benötigen viel weniger Platz. <br><br>  <b>- Warum haben die Bergleute sie noch nicht erreicht?</b> <br>  - (AB) Bergleute benötigen ihre Grafikkarte, um viele Dinge gleichzeitig erledigen zu können.  Aber für uns ist es nicht so wichtig.  Wir haben leichte Aufgaben, die mit kleinen Kräften schnell erledigt werden müssen und das Ergebnis zurückgeben.  Wenn Sie sechs solcher Aufgaben haben, ist es sinnvoller, sie auf sechs kleine Karten zu verteilen, als sie alle auf eine große und leistungsstarke Karte zu legen, bei der diese Aufgaben mit den Ellbogen geschoben werden. <br><br><hr><br><h2>  Wie ist das Rekrutierungsteam? </h2><br>  Im Frühjahr kamen Produktmanager ins Team, und jetzt braucht das Startup Entwickler.  Backend-Anbieter, die das Web in PHP und Symphony unterstützen oder Sie davon überzeugen, beispielsweise zu Python oder Go zu wechseln.  Das Front-End, das Seiten für neue Webdienste erstellt, erweitert die Funktionalität und verbessert die Benutzerfreundlichkeit bestehender.  Ein Kernel-Entwickler, der neben seinen Kenntnissen in Python auf hohem Niveau auch Data Science und die Besonderheiten der Arbeit mit Hardware, Testern, C ++ - Entwicklern für die Arbeit mit SDK und vielen anderen versteht. <br><br><img src="https://habrastorage.org/webt/vi/gy/1d/vigy1dl19uitcp_fekbnkbuichg.jpeg"><br><br>  <b>- Wie läuft Ihre Einstellung?</b> <br>  - (AB) Für das Datum der Wissenschaftler lehne ich eine nicht sehr schwierige, sondern eher indikative Aufgabe ab, anhand derer man die Fähigkeit zum Denken und Programmieren beurteilen kann.  Ich mache es selbst in vierzig Minuten.  Junior schafft es in 4-6 Stunden.  Danach rufen wir an und besprechen technische Fragen.  Ich schlage vor, er überlegt sich eine neue Aufgabe.  Wir nehmen zusammen an, testen zusammen.  Ich beobachte nur, wie sich eine Person in Bezug auf Aufgaben in einer ungewohnten Umgebung fühlt.  Versteht er, wie der Prozess der Modellentwicklung abläuft, was Ihnen dort begegnen kann und wovor Sie keine Angst haben sollten? <br><br>  Nach diesen Phasen bleiben etwa 10% der Menschen übrig.  Normalerweise antworten ungefähr 50 Personen auf die Joons. Wir rufen die fünf verbleibenden Personen für ein abschließendes Interview in unserem Büro an und kommunizieren einfach mit fast vollständiger Bereitschaft, das Team zu übernehmen. <br><br>  <b>- Und mit den Entwicklern?</b> <br>  - (AB) Aber bei den Entwicklern ist alles etwas schlimmer.  Wir geben ihnen einen solchen Test: Sie müssen einen kleinen Dienst auf einem beliebigen Framework innerhalb des Dockers bereitstellen.  Dieser Dienst sollte mit anderen Hafenarbeitern kommunizieren, in denen Postgres und RabbitMQ liegen.  Es gibt eine Aufgabe, einen Kanal in einem Rebbit zu lesen, von dort die Aufgabe zu übernehmen, die Datenbank zu füllen und alles in die Datenbank zu schreiben.  Es scheint, dass diese Aufgabe sehr einfach ist, etwa eine Stunde lang.  Aber alles bricht zusammen, wenn wir sagen, dass wir Bilder zum Schreiben in die Datenbank übertragen werden. <br><br>  Es stellt sich ständig heraus, dass jeder dieses Problem auf völlig unterschiedliche Weise löst.  Und jeder Mensch hat fast immer eine neue Idee, die ich vorher noch nicht einmal gesehen oder mir vorgestellt hatte.  Gleichzeitig inspiziert aber nicht jeder etwas.  Beim Test etwa die Hälfte der Kandidaten abschneiden.  Dann rufen wir auch die Entwickler im Büro an.  Wir beginnen über allgemeine Themen zu sprechen, um herauszufinden, was als nächstes kommt, was Sie wollen und so weiter.  Und danach haben wir leider fast 0% Auspuff. <br><br>  <b>- Nach welchen Kriterien verstehen Sie, dass eine Person nicht über genügend Soft Skills verfügt oder nicht in der Lage ist, in einem Startup zu arbeiten?</b> <br>  - (A.B.) In einfachen Gesprächen aus der Kategorie: "Hören Sie, aber stellen Sie sich das vor ...".  Er beginnt, einen Gedanken zu entwickeln, und Sie fügen versehentlich hinzu, dass unsere Fristen abgelaufen sind, und es bleiben noch zwei Wochen für ein Projekt, das zwei Monate lang durchgeführt werden muss.  Einige sagen: "Das kann nicht erlaubt werden."  Okay  Andere sagen: „Das ist sehr schlecht, aber wir werden das Maximum drücken.  Natürlich werden wir nicht alles tun.  Vielleicht die Hälfte, aber das ist besser als ein Viertel.  Im Allgemeinen wird alles cool sein, denn das Schlimmste ist das unvollendete Projekt. "  Das sind die Leute - sofort.  Fall in Bezug auf die Aufgabe. <br><br><hr><br><h2>  Ethische Standards und moralische Dilemmata </h2><br>  Gesichtserkennung, emotionales Computing - all dies sind Forschung und Technologie, die auf Daten basieren.  Fragen aus der Kategorie „Wem sollen die Daten gehören?“, „Wer und wie soll ihre Sammlung kontrolliert werden“ - einem modernen Grenzgebiet. <br><br>  Einer der Kompromisse, über die sich mittlerweile alle mehr oder weniger einig sind, ist die unpersönliche Sammlung. ,          GDPR              .         . <br><br>    .  , ,         ,         . <br><br>     .    ,         ? <br><br> — (..) ,  - .     .       .     ?   ?  ,      : «    ,  ,   ,   ».        . <br><br>   ,    : « ,     ,   ,  !»   ,        ,    .         . «,   ,   -    ,    ,  ,  ,     ».  50 ,        5-6    ,          . ,          .    -    .     ,      . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de465153/">https://habr.com/ru/post/de465153/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de465141/index.html">33+ Kubernetes Sicherheitstools</a></li>
<li><a href="../de465143/index.html">Wie finde ich den besten Standort für Unternehmen? Life Hack ohne Registrierung und SMS</a></li>
<li><a href="../de465145/index.html">Gesichtserkennung auf Knieebene</a></li>
<li><a href="../de465149/index.html">'Hallo Welt' für dich in der Cloud</a></li>
<li><a href="../de465151/index.html">Installieren Sie Apache Cassandra unter Windows</a></li>
<li><a href="../de465155/index.html">Zwei Einheiten der neurolinguistischen Programmierung</a></li>
<li><a href="../de465161/index.html">Quintett-Datenmodell und Hunderte von Gigabyte Daten</a></li>
<li><a href="../de465163/index.html">3D-Druck: erstaunliche Fälle und etwas interessanter</a></li>
<li><a href="../de465167/index.html">Ressourcenplanung. Warum funktioniert es nicht? Teil 1</a></li>
<li><a href="../de465169/index.html">DIY von PVS-Studio: Gamification of Achievements</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
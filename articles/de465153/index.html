<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïó üé∏ üëé Computer Vision sieht Emotionen, Puls, Atmung und L√ºgen - aber wie kann man darauf ein Startup aufbauen? Gespr√§ch mit Neurodata Lab üõãÔ∏è üë®üèæ‚Äçü§ù‚Äçüë®üèΩ üëáüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Unsere Beziehung zum Computer Vision war nicht so laut, bis wir lernten, wie man Wunder mit menschlichen Gesichtern vollbringt. Algorithmen ersetzen M...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Computer Vision sieht Emotionen, Puls, Atmung und L√ºgen - aber wie kann man darauf ein Startup aufbauen? Gespr√§ch mit Neurodata Lab</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/habr_career/blog/465153/"><img src="https://habrastorage.org/webt/5f/q8/9w/5fq89wvwqezw4pwf_j7u2-bnq64.jpeg"><br><br>  Unsere Beziehung zum Computer Vision war nicht so laut, bis wir lernten, wie man Wunder mit menschlichen Gesichtern vollbringt.  Algorithmen ersetzen Menschen in Fotos und Videos, √§ndern Alter, Rasse und Geschlecht.  Dies ist die wichtigste Online-Unterhaltung der letzten Jahre und eine Quelle der Angst.  Heute st√ºrmen Apps die Charts, morgen sahen Demonstranten S√§ulen mit Kameras, die Gesichter erkennen.  Und anscheinend stehen wir erst am Anfang der Reise.  Was der Computer aus unseren Gesichtern lesen kann, wird immer mehr. <br><br>  Anfang dieses Monats besuchten wir das B√ºro des Neurodata Lab.  Die Hauptrichtung f√ºr das Unternehmen ist das Erkennen menschlicher Emotionen.  Wir haben versucht herauszufinden, wie und warum dies gemacht wird. <br><br><blockquote>  Bei My Circle erhielt Neurodata Lab eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durchschnittliche Punktzahl von 4,6</a> und eine durchschnittliche Empfehlung von 95% seiner Mitarbeiter, die Kriterien wie berufliches Wachstum, interessante Aufgaben, gute Beziehungen zu Kollegen und die Tatsache, dass das Unternehmen die Welt zu einem besseren Ort macht, bewerteten. </blockquote><a name="habracut"></a><br><hr><br>  2016 nahmen zehn Schauspieler - f√ºnf M√§nner und f√ºnf Frauen - an ungew√∂hnlichen Dreharbeiten teil.  Sie gingen zu einem leeren Bereich, in schwarzen, eng anliegenden Anz√ºgen, und zeigten auf Kameras in verschiedenen Ecken des Raumes vor dem Hintergrund der gr√ºnen Wand ‚Äûnichts‚Äú - nur ihren neutralen Zustand. <br><br>  Dann spielten die Schauspieler kurze Drehb√ºcher aus.  Es gab keine Repliken in den Skripten, nur Beschreibungen von Situationen, also improvisierten die Schauspieler.  In jeder Szene mussten sie eine von sechs Emotionen erleben - Wut, Traurigkeit, Ekel, Freude, Angst oder √úberraschung.  Die Mimik und Gesten erfahrener Schauspieler werden oft stereotyp, eher f√ºr das Theater als f√ºr das wirkliche Leben geeignet, daher waren hier alle Schauspieler Studenten. <br><br><img src="https://habrastorage.org/webt/kc/pw/pc/kcpwpc8gnvulu2api4r0rwsbwow.jpeg"><br><br>  Ihnen folgte ein Lehrer der Filmschule, aber nicht nur.  Der Hauptdirektor war eine Wissenschaftlerin und Forscherin Olga Perepelkina.  Neben Video und Ton am Set wurden bioelektrische Reaktionen der Hautoberfl√§che und andere physiologische Eigenschaften aufgezeichnet.  Jede Szene wurde mehrmals von einer anderen Besetzung gedreht, und als Ergebnis sammelten sie ungef√§hr sieben Stunden Material. <br><br>  Nachdem die Schauspieler ihre Arbeit beendet hatten, beschrieben sie, wo und welche Emotionen sie w√§hrend des Spiels tats√§chlich erlebten.  Dann sahen sich weitere 21 Leute die Videos an und in jedem der Videos bemerkten sie, welche Emotionen der Schauspieler zu erleben schien.  Wann beginnt diese Emotion und wann endet sie? <br><br><img src="https://habrastorage.org/webt/os/vg/op/osvgop-sjzowyyhy4so9oxeguku.jpeg"><br><br>  So begann die Arbeit am ersten russischsprachigen multimodalen Datensatz zur Emotionserkennung - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RAMAS</a> . <br><br>  Das erhaltene Material war jedoch nur f√ºr wissenschaftliche Forschung und Experimente geeignet - nicht f√ºr das Training von Algorithmen im industriellen Ma√üstab. <br><br>  - (Olga Perepelkina) Wir mussten einen riesigen Datensatz sammeln.  Nicht 7, sondern 107 und mehr Stunden.  Wir haben die Emotion Miner-Webplattform erstellt, eine Reihe von Videos hochgeladen, die im Internet √∂ffentlich verf√ºgbar sind, Zehntausende Menschen aus der ganzen Welt zusammengebracht und damit begonnen, die Daten zu markieren.  So haben wir 140 Stunden Video auf 20 Skalen markiert (nicht nur Emotionen, sondern auch verschiedene kognitive und soziale Merkmale) und den weltweit gr√∂√üten emotionalen Datensatz gesammelt. <br><br>  <b>- Und wie haben Sie es geschafft, so viele Leute zu finden, die Sie markieren k√∂nnen?</b> <br>  - (O.P.) Es ist einfach - wir haben ihnen Geld f√ºr die Arbeit bezahlt.  Durchgef√ºhrte Werbeaktionen, ein kleines Budget in Marketing investiert.  Im Prinzip war es nicht sehr schwierig.  Mittlerweile sind fast 70.000 Menschen auf der Plattform registriert.  In Wirklichkeit haben jedoch etwa zweitausend Personen den Datensatz markiert. <br><br><hr><br><h2>  Produkte </h2><br>  Das Startup Neurodata Lab wurde von den Unternehmern George Pliev und Maxim Ryabov gegr√ºndet.  Sie finanzierten die Forschung nicht aus wissenschaftlichen Gr√ºnden, sondern um eine kommerzielle Anwendung f√ºr die Technologie zu finden.  Jetzt ist Affective Computing oder ‚ÄûEmotional Computing‚Äú nicht der beliebteste Bereich auf dem Markt f√ºr neuronale Netze und Computer Vision.  Auf dem Gebiet der Gesichtserkennung besteht ein starker Wettbewerb.  Unterhaltungsanwendungen werden nacheinander in den Fokus ger√ºckt.  Und Systeme, die mit Emotionen arbeiten, verlassen den Status ‚Äûvielversprechend‚Äú f√ºr mehrere Jahre nicht.  Nach Prognosen von Gartner und anderen Studien prognostiziert sie jedoch ein schnelles Wachstum. <br><br>  Neurodata Lab forscht seit etwa drei Jahren, sammelt Daten und entwickelt Algorithmen.  Jetzt verwenden sie Forschungsergebnisse in kommerziellen Produkten.  Zum Beispiel hat Neurodata Lab eine emotionale KI f√ºr Promobot-Roboter entwickelt.  Der Roboter verwendete ein Emotionserkennungssystem, um korrekt auf die Hinweise der Personen zu reagieren, die sich an ihn wenden.  Die Demo wurde dieses Jahr auf der CES <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gezeigt</a> . <br><br>  Der Algorithmus wird in Call Centern verwendet, um Anrufe zu √ºberwachen und die Leistung der Mitarbeiter zu bewerten.  Jetzt geschieht dies alles manuell - Manager m√ºssen selektiv Anrufaufzeichnungen abh√∂ren und pr√ºfen, ob der Mitarbeiter dem Kunden gegen√ºber unh√∂flich war oder im Rahmen des Anstands gehalten wurde.  Das System kann dies automatisch und in Echtzeit tun.  Dabei wird auch die emotionale Stimmung des Klienten beurteilt - er war mit der Behandlung zufrieden oder nicht.  Ein Pilot eines √§hnlichen Produkts Neurodata Lab wurde in Rosbank gestartet.  Der Algorithmus analysiert Anrufe, um die Kundenzufriedenheit zu messen. <br><br>  Die zweite Produktbranche ist etwas globaler.  Das Unternehmen stellt seine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">API her</a> - eine ganze Reihe von Tools f√ºr Entwickler von Drittanbietern.  Jetzt enth√§lt es eine Analyse der Emotionen, einen Gesichts-Tracker und Tonanalysatoren, mit denen Sie eine Audioaufnahme mit mehreren Stimmen in verschiedene Audiospuren aufteilen und das Rauschen trennen k√∂nnen.  In K√ºrze wird es einen Body-Tracker, einen Pulsfrequenzdetektor, einen Atemtracker aus dem Video einer Person und andere Technologien oder Algorithmen geben. <br><br><hr><br><h2>  Arbeitsprinzip </h2><br>  Ein Mensch lernt, Emotionen unbewusst zu definieren - von Kindheit an beginnt er, bestimmte Verhaltensmuster mit den Emotionen zu assoziieren, die Menschen in seiner Umgebung erleben.  Nachdem er dies bereits gelernt hat, kann er analysieren, welche Zeichen es tut.  Das offensichtlichste ist der Ausdruck, den Mund und Augen annehmen.  Aber im Gesicht sind viele Gesichtsmuskeln, die eine unglaubliche Menge an ausdrucksstarken Nuancen erzeugen.  Wir nehmen sie automatisch wahr, obwohl wir bestimmte Details bewusst wahrnehmen k√∂nnen. <br><br>  Das neuronale Netzwerk analysiert auch Hunderte von Stunden Video, das von Personen markiert wurde.  Und die Zeichen, anhand derer das System Emotionen klassifiziert, sind nicht immer offensichtlich. <br><br>  - (Andrey Belyaev) F√ºr einige Klassen gibt es gemeinsame Muster.  Zum Beispiel sind die Klassen ‚ÄûWut‚Äú und ‚Äû√úberraschung‚Äú durch einen starken Ausdruck im Gesicht gekennzeichnet - hochgezogene Augenbrauen, abgerundete Augen, Rauch aus den Ohren.  Das Gitter reagiert sicherlich auf sie, aber nicht nur.  Zum Beispiel wird sie mit kleinen Augenbrauen, die wie hochgezogen aussehen, ruhig die richtige Klasse bestimmen, da sie auch auf die Dynamik von Ver√§nderungen reagiert.  Eine der interessanten Klassen in dieser Hinsicht ist ‚ÄûTraurigkeit‚Äú.  Wenn ein Mensch traurig ist, √§ndert sich sein Gesicht meistens lange nicht.  Grid bemerkt keine Dynamik im Ausdruck und geht davon aus, dass es entweder ‚Äûneutral‚Äú oder ‚Äûtraurig‚Äú ist, und kl√§rt erst dann die verbleibenden Zeichen und kommt zu dem Schluss, dass die Klasse richtig ist. <br><br>  <b>- Was ist mit dem Sound?</b>  <b>Bestimmte Frequenzen, Bereiche, T√∂ne?</b> <br>  - (A.B.) Ton ist komplizierter.  Jede Person hat ihre eigene Standardlautst√§rke, man kann sich nicht an die Klangst√§rke binden.  Jemand kann leise und gleichm√§√üig sprechen, aber tats√§chlich ist er schrecklich w√ºtend.  Und selbst wenn wir den Klang visualisieren und verstehen, worauf das System achtet, k√∂nnen wir ihn nicht so gut erkl√§ren wie mit dem Gesicht.  Das Gesicht hat klare Punkte: Augenbrauen, Augen, Ohren und mehr.  Aber es ist kein Ton zu h√∂ren.  Schall wird in Form eines Spektrogramms in das Gitter eingespeist, und welche spezifischen Teile davon f√ºr was und zu welchem ‚Äã‚ÄãZeitpunkt verantwortlich sind, ist viel schwieriger zu verstehen.  Daher gibt es keine Standardantwort, worauf das Raster bei der Arbeit mit Ton achtet. <br><br>  <b>- Wie zeichnet man den Puls auf?</b> <br>  - (O.P.) Mikrover√§nderungen der Hautfarbe werden verfolgt.  Wenn das Herz schl√§gt, ist das Blut mit Sauerstoff ges√§ttigt, die Sauerstoffversorgung des Blutes √§ndert sich und aufgrund dessen √§ndert sich die Hautfarbe.  Es wird nicht mit dem Auge funktionieren, aber mit Hilfe des Algorithmus ist es m√∂glich. <br><br>  <b>- Dies h√§ngt jedoch stark von der Qualit√§t des Videos ab.</b> <br>  - (O.P.) Wir haben diesen Algorithmus schon lange ges√§gt und k√∂nnen nicht nur mit einer coolen Kamera, sondern auch mit einer normalen Webcam arbeiten.  Wir wissen, wie man arbeitet, wenn der Bildschirm flackert.  Zum Beispiel, wenn eine Person einen Film sieht und sich ihre Beleuchtungsst√§rke st√§ndig √§ndert.  Wir k√∂nnen mit Bedingungen arbeiten, unter denen sich eine Person bewegt und spricht. <br><br>  Der Impuls ist ein periodisches Signal und wird klar √ºberwacht, und die Beleuchtung des Films √§ndert sich nicht periodisch.  Daher kann ein n√ºtzliches Signal vom Rauschen getrennt werden.  Wir haben diese Technologie sogar mit Fitness-Trackern <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verglichen</a> .  Unser Algorithmus funktioniert genauso gut - und sogar besser als einige von ihnen. <br><br>  <b>- Das System kann sehen, was eine Person nicht sieht, aber eine Person erkennt Emotionen immer noch besser.</b>  <b>Warum?</b> <br>  - (O.P.) Eine Person macht es besser, weil sie Kontextinformationen ber√ºcksichtigt.  Dazu ist jedoch ein multimodales System erforderlich, das die Genauigkeit verbessert, indem Gesicht, Stimme, Gesten, Puls, Atmung und semantische Analyse des Textes sofort analysiert werden. <br><br>  So funktioniert die menschliche Wahrnehmung.  Sie sehen einen Mann von hinten, sehen ihm beim Sitzen zu und denken: "Es scheint, er ist traurig."  Unser Ziel ist es, einen Algorithmus zu entwickeln, der Emotionen als Person wahrnimmt - im Allgemeinen unter allen Bedingungen f√ºr alle Informationen. <br><br>  Der Vorteil des Systems gegen√ºber Menschen besteht nun darin, dass es eine gro√üe Datenmenge automatisch analysieren kann.  Manchmal kann es eine Person besser machen, aber Sie werden sie nicht dazu bringen, rund um die Uhr zu sitzen und mit den Ohren zuzuh√∂ren, z. B. Anrufe bei einem Callcenter. <br><br>  <b>- Wenn ich Emotionen erlebe, aber versuche, sie zu verbergen, wird das System dies verstehen?</b> <br>  - (O.P.) Vielleicht. <br><br><hr><br><h2>  Wie l√§uft die Entwicklung? </h2><br>  Neurodata Lab ist ein kleines Unternehmen, das bis vor kurzem nur als Labor existierte.  Es verf√ºgt √ºber eine Wissenschaftsabteilung, ein Data Science-Team und eine Entwicklungsabteilung, die neue Entwicklungen und Entdeckungen in Produkte packt.  Jede Abteilung besteht aus 5-6 Personen.  Insgesamt besch√§ftigt das Team rund 30 Mitarbeiter. <br><br><h3>  Forscher </h3><br>  In der wissenschaftlichen Abteilung arbeiten Psychologen, Physiologen und Biologen.  Es gibt nur vier Mitarbeiter und drei Praktikanten, aber sie haben ein ganzes internationales Netzwerk von Kooperationen aufgebaut.  In Russland gibt es beispielsweise Projekte in Zusammenarbeit mit der Moskauer Staatsuniversit√§t, der Higher School of Economics und der RANEPA.  Im Ausland - mit der Universit√§t Glasgow, der Technischen Universit√§t Paris, der Universit√§t Genf, dem technischen Labor in Genua, das sich mit der Analyse von Bewegungen befasst. <br><br>  Wissenschaftler, die emotionales Rechnen betreiben, sind eine ganze Gemeinschaft.  Sie treffen sich regelm√§√üig zu gemeinsamen Workshops an verschiedenen Universit√§ten auf der ganzen Welt.  Alle zwei Jahre findet eine gro√üe Konferenz statt, die ausschlie√ülich der emotionalen Technologie gewidmet ist.  In diesem Jahr wird das Neurodata Lab auf dieser Konferenz einen eigenen Workshop organisieren. <br><br><img src="https://habrastorage.org/webt/to/7t/dy/to7tdyhho0p_vnn2vucsvunhxuq.jpeg"><br><br>  <b>- Ich frage mich, was ist die t√§gliche Arbeit eines Forschers?</b> <br>  - (O.P.) Zuerst lesen sie Artikel.  Zum Beispiel wollten wir lernen, wie man eine L√ºge erkennt, nicht nur Emotionen, und wir m√ºssen herausfinden, was eine L√ºge ist, wie ein L√ºgendetektor funktioniert, was bereits in diesem Bereich getan wurde, was die Probleme eines klassischen Polygraphen sind, wie man sich t√§uschen l√§sst, welche Algorithmen am coolsten sind. wie die menschliche Psyche angeordnet ist, welche psychologischen Merkmale es gibt, wenn eine Person l√ºgt, wie die Physiologie funktioniert, warum (und ob) die Nase einer Person k√§lter wird und ihre Ohren rot werden, wenn sie betr√ºgt, und so weiter. <br><br>  Dann f√ºhren wir eine Vielzahl von Experimenten durch.  Um ein System zu erstellen, das den Puls und die Atemfrequenz aus dem Video erkennt, mussten viele Daten gesammelt werden.  Es kommen st√§ndig Themen zu uns, wir haben Ausr√ºstung und alle m√∂glichen Dinge, die den Puls einer Person auf Kontaktart messen.  Wir messen EKG, Photoplethysmographie, hautgalvanische Reaktion.  Wir hatten lustige Experimente, als wir verstehen wollten, wie sich der Blutfluss √ºber das Gesicht bewegt, und dann haben wir Elektroden direkt auf das Gesicht geklebt. <br><br><img src="https://habrastorage.org/webt/8g/mv/g7/8gmvg785lgujytcycc3igdt0it0.jpeg"><br><br>  Schlie√ülich zeigen wir Menschen verschiedene Vidosiki.  Wir versuchen sie zu erschrecken oder umgekehrt - zu jubeln.  Forscher analysieren Daten, ber√ºcksichtigen Statistiken, schreiben Artikel und Patente basierend auf diesen Daten.  Dann kommen sie in die technische Abteilung zu Andrei und sagen: "Wir haben eine coole Sache gelesen, ein Experiment durchgef√ºhrt, Sie k√∂nnen versuchen, einen Algorithmus zu erstellen, der so funktioniert."  Oder Andrei kommt zu uns und sagt: "Wir wollen St√ºrze erkennen, wir m√ºssen herausfinden, wie man Daten sammelt."  Und die wissenschaftliche Abteilung setzt sich und √ºberlegt, wie dies einfach und schnell geschehen kann. <br><br>  <b>- Traumjob.</b> <br>  - (AB) Einige Leute denken - andere tun es. <br><br><hr><br><h3>  Datum Wissenschaftler und Entwickler </h3><br>  Data Science arbeitet parallel zur Produktentwicklung.  Datasenteristen trainieren neuronale Netze auf Torch, wenn in der Forschung Handlungsspielraum besteht, und auf MXnet, wenn Sie eine schnell arbeitende L√∂sung ben√∂tigen.  Nachdem alle Hypothesen zur Anwendbarkeit neuronaler Netze best√§tigt wurden, √ºbertragen die Jungs sie an TensorRT, um die Arbeitsgeschwindigkeit zu erh√∂hen und sie dem Entwicklungsteam zur Implementierung in der Produktion zu √ºbergeben. <br><br>  Neurodata Lab hat einen eigenen Cloud-Service erstellt, auf den andere Entwickler zugreifen k√∂nnen - f√ºr Forschungs- oder kommerzielle Projekte. <br><br>  - (A.B.) Der Software-Kernel, der Aufgaben zwischen neuronalen Netzen verteilt, ist in Python geschrieben.  Wir mussten es schnell schreiben, aber es stellte sich ziemlich gut heraus.  Er arbeitet mit Dockern, kommuniziert √ºber RabbitMQ, l√§uft in Postgres und die gRPC-Schicht h√§ngt oben, wodurch Sie eine sichere Verbindung mit der Au√üenwelt herstellen und anderen Programmierern und Forschern Zugriff auf unsere Technologien gew√§hren k√∂nnen. <br><br>  Web in Symphony geschrieben.  API implementiert mit gRPC.  Dies ist eine coole Google-Sache, mit der Sie einen sicheren Kanal erstellen und Schl√ºssel mit dem System austauschen k√∂nnen, sodass nur auf bestimmte interne Funktionen zugegriffen werden kann.  Beispielsweise k√∂nnen Sie nur Tools einen Schl√ºssel geben, mit denen Gesichter erkannt und Emotionen erkannt werden k√∂nnen. <br><br>  Ich arbeite an einer Idee - ich m√∂chte mein eigenes kleines Rechenzentrum bauen, in dem sich die Inferenz dreht.  Und es wird auf Jetson Nano basieren.  Dies ist so ein kleiner Einplatinencomputer f√ºr zehntausend Rubel.  Wie der Raspberry Pi nur mit einer Grafikkarte.  Mit einem Prozessor, RAM und allem anderen kostet es 6-mal billiger als 1080Ti, ohne die restlichen Computerkomponenten zu ber√ºcksichtigen, aber es arbeitet auch ungef√§hr 6-mal langsamer. <br><br>  <b>- Und was wird es geben?</b> <br>  - (AB) Erstens ist es billiger und funktioniert ungef√§hr genauso.  Zweitens wird es die Umwelt nicht mehr so ‚Äã‚Äãsehr sch√§digen.  Drittens brauchen sie nicht viel Strom.  Sechs Jetson Nano, die zusammen fast 1080 Ti antreiben, verbrauchen sechsmal weniger Energie und ben√∂tigen viel weniger Platz. <br><br>  <b>- Warum haben die Bergleute sie noch nicht erreicht?</b> <br>  - (AB) Bergleute ben√∂tigen ihre Grafikkarte, um viele Dinge gleichzeitig erledigen zu k√∂nnen.  Aber f√ºr uns ist es nicht so wichtig.  Wir haben leichte Aufgaben, die mit kleinen Kr√§ften schnell erledigt werden m√ºssen und das Ergebnis zur√ºckgeben.  Wenn Sie sechs solcher Aufgaben haben, ist es sinnvoller, sie auf sechs kleine Karten zu verteilen, als sie alle auf eine gro√üe und leistungsstarke Karte zu legen, bei der diese Aufgaben mit den Ellbogen geschoben werden. <br><br><hr><br><h2>  Wie ist das Rekrutierungsteam? </h2><br>  Im Fr√ºhjahr kamen Produktmanager ins Team, und jetzt braucht das Startup Entwickler.  Backend-Anbieter, die das Web in PHP und Symphony unterst√ºtzen oder Sie davon √ºberzeugen, beispielsweise zu Python oder Go zu wechseln.  Das Front-End, das Seiten f√ºr neue Webdienste erstellt, erweitert die Funktionalit√§t und verbessert die Benutzerfreundlichkeit bestehender.  Ein Kernel-Entwickler, der neben seinen Kenntnissen in Python auf hohem Niveau auch Data Science und die Besonderheiten der Arbeit mit Hardware, Testern, C ++ - Entwicklern f√ºr die Arbeit mit SDK und vielen anderen versteht. <br><br><img src="https://habrastorage.org/webt/vi/gy/1d/vigy1dl19uitcp_fekbnkbuichg.jpeg"><br><br>  <b>- Wie l√§uft Ihre Einstellung?</b> <br>  - (AB) F√ºr das Datum der Wissenschaftler lehne ich eine nicht sehr schwierige, sondern eher indikative Aufgabe ab, anhand derer man die F√§higkeit zum Denken und Programmieren beurteilen kann.  Ich mache es selbst in vierzig Minuten.  Junior schafft es in 4-6 Stunden.  Danach rufen wir an und besprechen technische Fragen.  Ich schlage vor, er √ºberlegt sich eine neue Aufgabe.  Wir nehmen zusammen an, testen zusammen.  Ich beobachte nur, wie sich eine Person in Bezug auf Aufgaben in einer ungewohnten Umgebung f√ºhlt.  Versteht er, wie der Prozess der Modellentwicklung abl√§uft, was Ihnen dort begegnen kann und wovor Sie keine Angst haben sollten? <br><br>  Nach diesen Phasen bleiben etwa 10% der Menschen √ºbrig.  Normalerweise antworten ungef√§hr 50 Personen auf die Joons. Wir rufen die f√ºnf verbleibenden Personen f√ºr ein abschlie√üendes Interview in unserem B√ºro an und kommunizieren einfach mit fast vollst√§ndiger Bereitschaft, das Team zu √ºbernehmen. <br><br>  <b>- Und mit den Entwicklern?</b> <br>  - (AB) Aber bei den Entwicklern ist alles etwas schlimmer.  Wir geben ihnen einen solchen Test: Sie m√ºssen einen kleinen Dienst auf einem beliebigen Framework innerhalb des Dockers bereitstellen.  Dieser Dienst sollte mit anderen Hafenarbeitern kommunizieren, in denen Postgres und RabbitMQ liegen.  Es gibt eine Aufgabe, einen Kanal in einem Rebbit zu lesen, von dort die Aufgabe zu √ºbernehmen, die Datenbank zu f√ºllen und alles in die Datenbank zu schreiben.  Es scheint, dass diese Aufgabe sehr einfach ist, etwa eine Stunde lang.  Aber alles bricht zusammen, wenn wir sagen, dass wir Bilder zum Schreiben in die Datenbank √ºbertragen werden. <br><br>  Es stellt sich st√§ndig heraus, dass jeder dieses Problem auf v√∂llig unterschiedliche Weise l√∂st.  Und jeder Mensch hat fast immer eine neue Idee, die ich vorher noch nicht einmal gesehen oder mir vorgestellt hatte.  Gleichzeitig inspiziert aber nicht jeder etwas.  Beim Test etwa die H√§lfte der Kandidaten abschneiden.  Dann rufen wir auch die Entwickler im B√ºro an.  Wir beginnen √ºber allgemeine Themen zu sprechen, um herauszufinden, was als n√§chstes kommt, was Sie wollen und so weiter.  Und danach haben wir leider fast 0% Auspuff. <br><br>  <b>- Nach welchen Kriterien verstehen Sie, dass eine Person nicht √ºber gen√ºgend Soft Skills verf√ºgt oder nicht in der Lage ist, in einem Startup zu arbeiten?</b> <br>  - (A.B.) In einfachen Gespr√§chen aus der Kategorie: "H√∂ren Sie, aber stellen Sie sich das vor ...".  Er beginnt, einen Gedanken zu entwickeln, und Sie f√ºgen versehentlich hinzu, dass unsere Fristen abgelaufen sind, und es bleiben noch zwei Wochen f√ºr ein Projekt, das zwei Monate lang durchgef√ºhrt werden muss.  Einige sagen: "Das kann nicht erlaubt werden."  Okay  Andere sagen: ‚ÄûDas ist sehr schlecht, aber wir werden das Maximum dr√ºcken.  Nat√ºrlich werden wir nicht alles tun.  Vielleicht die H√§lfte, aber das ist besser als ein Viertel.  Im Allgemeinen wird alles cool sein, denn das Schlimmste ist das unvollendete Projekt. "  Das sind die Leute - sofort.  Fall in Bezug auf die Aufgabe. <br><br><hr><br><h2>  Ethische Standards und moralische Dilemmata </h2><br>  Gesichtserkennung, emotionales Computing - all dies sind Forschung und Technologie, die auf Daten basieren.  Fragen aus der Kategorie ‚ÄûWem sollen die Daten geh√∂ren?‚Äú, ‚ÄûWer und wie soll ihre Sammlung kontrolliert werden‚Äú - einem modernen Grenzgebiet. <br><br>  Einer der Kompromisse, √ºber die sich mittlerweile alle mehr oder weniger einig sind, ist die unpers√∂nliche Sammlung. ,          GDPR              .         . <br><br>    .  , ,         ,         . <br><br>     .    ,         ? <br><br> ‚Äî (..) ,  - .     .       .     ?   ?  ,      : ¬´    ,  ,   ,   ¬ª.        . <br><br>   ,    : ¬´ ,     ,   ,  !¬ª   ,        ,    .         . ¬´,   ,   -    ,    ,  ,  ,     ¬ª.  50 ,        5-6    ,          . ,          .    -    .     ,      . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de465153/">https://habr.com/ru/post/de465153/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de465141/index.html">33+ Kubernetes Sicherheitstools</a></li>
<li><a href="../de465143/index.html">Wie finde ich den besten Standort f√ºr Unternehmen? Life Hack ohne Registrierung und SMS</a></li>
<li><a href="../de465145/index.html">Gesichtserkennung auf Knieebene</a></li>
<li><a href="../de465149/index.html">'Hallo Welt' f√ºr dich in der Cloud</a></li>
<li><a href="../de465151/index.html">Installieren Sie Apache Cassandra unter Windows</a></li>
<li><a href="../de465155/index.html">Zwei Einheiten der neurolinguistischen Programmierung</a></li>
<li><a href="../de465161/index.html">Quintett-Datenmodell und Hunderte von Gigabyte Daten</a></li>
<li><a href="../de465163/index.html">3D-Druck: erstaunliche F√§lle und etwas interessanter</a></li>
<li><a href="../de465167/index.html">Ressourcenplanung. Warum funktioniert es nicht? Teil 1</a></li>
<li><a href="../de465169/index.html">DIY von PVS-Studio: Gamification of Achievements</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
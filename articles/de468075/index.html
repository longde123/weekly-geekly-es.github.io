<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐏 ℹ️ 👩🏾‍🤝‍👩🏼 Die Verwendung von siamesischen neuronalen Netzen bei der Suche 🖖🏼 💪 🙉</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! In diesem Beitrag werde ich Ihnen sagen, welche Ansätze wir in Mail.ru Search verwenden, um Texte zu vergleichen. Wofür ist das? Sob...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Verwendung von siamesischen neuronalen Netzen bei der Suche</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/468075/"><img src="https://habrastorage.org/webt/vz/r1/ch/vzr1ch09luydotrwrqc26ccyn-u.jpeg"><br><br>  Hallo allerseits!  In diesem Beitrag werde ich Ihnen sagen, welche Ansätze wir in Mail.ru Search verwenden, um Texte zu vergleichen.  Wofür ist das?  Sobald wir lernen, verschiedene Texte gut miteinander zu vergleichen, kann die Suchmaschine Benutzeranfragen besser verstehen. <br><br>  Was brauchen wir dafür?  Stellen Sie die Aufgabe zunächst genau ein.  Sie müssen selbst bestimmen, welche Texte wir als ähnlich betrachten und welche nicht, und dann eine Strategie zur automatischen Bestimmung der Ähnlichkeit formulieren.  In unserem Fall werden die Texte von Benutzeranfragen mit den Texten von Dokumenten verglichen. <br><a name="habracut"></a><br>  Die Aufgabe, die Textrelevanz zu bestimmen, besteht aus drei Schritten.  Am einfachsten: Suchen Sie in zwei Texten nach passenden Wörtern und ziehen Sie anhand der Ergebnisse Schlussfolgerungen zur Ähnlichkeit.  Die nächste, schwierigere Aufgabe besteht darin, nach der Verbindung zwischen verschiedenen Wörtern zu suchen und Synonyme zu verstehen.  Und schließlich die dritte Stufe: Analyse des gesamten Satzes / Textes, Isolierung der Bedeutung und Vergleich von Sätzen / Texten nach Bedeutungen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/74a/d7d/70e/74ad7d70ea842ca2f2750b954b193c64.png"><br><br>  Eine Möglichkeit, dieses Problem zu lösen, besteht darin, eine Zuordnung vom Textbereich zu einer einfacheren zu finden.  Sie können beispielsweise Texte in den Vektorraum übersetzen und Vektoren vergleichen. <br><br>  Kehren wir zum Anfang zurück und betrachten den einfachsten Ansatz: Finden passender Wörter in Abfragen und Dokumenten.  Eine solche Aufgabe an sich ist schon ziemlich kompliziert: Um dies gut zu machen, müssen wir lernen, wie man die normale Form von Wörtern erhält, die an sich nicht trivial ist. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Anfrage <br></th><th>  Dokumenttitel <br></th></tr><tr><td>  <font color="#fa7566">Märchenheld</font> <br></td><td>  Alphabet der <font color="#fa7566">Märchenhelden</font> <br></td></tr><tr><td>  Märchenheld <br></td><td>  Literatur für das Vorschulalter <br></td></tr></tbody></table></div><br>  Das direkte Mapping-Modell kann erheblich verbessert werden.  Eine Lösung besteht darin, bedingte Synonyme abzugleichen.  Beispielsweise können Sie probabilistische Annahmen zur Verteilung von Wörtern in Texten eingeben.  Sie können mit Vektordarstellungen arbeiten und die Verbindungen zwischen den nicht übereinstimmenden Wörtern implizit isolieren und dies automatisch tun. <br><br>  Da wir uns mit der Suche beschäftigen, verfügen wir über viele Daten zum Verhalten von Benutzern beim Empfang bestimmter Dokumente als Antwort auf einige Fragen.  Basierend auf diesen Daten können wir Schlussfolgerungen über die Beziehung zwischen verschiedenen Wörtern ziehen. <br><br>  Nehmen wir zwei Sätze: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a80/f60/c56/a80f60c569a9a4fb72afc20774a7e787.png"><br><br>  Weisen Sie jedem Wortpaar aus der Abfrage und dem Titel eine gewisse Gewichtung zu, was bedeutet, wie stark das erste Wort dem zweiten zugeordnet ist.  Wir werden den Klick als sigmoidale Transformation der Summe dieser Gewichte vorhersagen.  Das heißt, wir legen die Aufgabe der logistischen Regression fest, bei der die Attribute durch eine Reihe von Paaren des Formulars dargestellt werden (Wort aus der Abfrage, Wort aus dem Titel / Text des Dokuments).  Wenn wir ein solches Modell trainieren können, werden wir verstehen, welche Wörter Synonyme sind, genauer gesagt, verbunden werden können und welche höchstwahrscheinlich nicht. <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-1"><span class="MJXp-mtext" id="MJXp-Span-2">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-4">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-5">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-6">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-7">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8">f</span><span class="MJXp-mrow" id="MJXp-Span-9"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-10">K</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-12">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-13">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14">k</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15">w</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-20">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-21">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-22">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-23">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-26">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-28">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-29">k</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-30">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-32">t</span></span><span class="MJXp-mo" id="MJXp-Span-33" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-34">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-39">a</span><span class="MJXp-mtext" id="MJXp-Span-40">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-42">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-43">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-44">t</span><span class="MJXp-mo" id="MJXp-Span-45" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-46">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-47">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-49">m</span><span class="MJXp-mtext" id="MJXp-Span-50">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-51">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-52">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-53">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">h</span><span class="MJXp-msubsup" id="MJXp-Span-56"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-57" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-58" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-59">i</span></span></span><span class="MJXp-mtext" id="MJXp-Span-60">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-61">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-63">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-64">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65">t</span><span class="MJXp-mo" id="MJXp-Span-66" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mtext" id="MJXp-Span-67">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-68">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-69">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-71">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-72">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-73">f</span><span class="MJXp-mrow" id="MJXp-Span-74"><span class="MJXp-mo" id="MJXp-Span-75" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-76">w</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-78">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80">i</span></span><span class="MJXp-mtext" id="MJXp-Span-81">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-82">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-83">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-84">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-85">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-86">h</span><span class="MJXp-msubsup" id="MJXp-Span-87"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88" style="margin-right: 0.05em;">i</span><span class="MJXp-mrow MJXp-script" id="MJXp-Span-89" style="vertical-align: -0.4em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-90">i</span></span></span><span class="MJXp-mtext" id="MJXp-Span-91">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-92">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-93">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-94">x</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-95">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-96">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-97">f</span><span class="MJXp-mrow" id="MJXp-Span-98"><span class="MJXp-mo" id="MJXp-Span-99" style="margin-left: 0em; margin-right: 0.111em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-100">G</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-101">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-102">w</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-103">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-104">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-105">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-106">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-107">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-108">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-109">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-110">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-111">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-112">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-114">W</span><span class="MJXp-mrow" id="MJXp-Span-115"><span class="MJXp-mo" id="MJXp-Span-116" style="margin-left: 0em; margin-right: 0em;">ö</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-118">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-119">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-120">r</span><span class="MJXp-mo" id="MJXp-Span-121" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-122">A</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-123">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-124">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-125">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-126">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-128">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-129">w</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-130">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-131">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-132">t</span><span class="MJXp-mo" id="MJXp-Span-133" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134">D</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-136">k</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-137">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-138">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-139">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-140">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-141">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">w</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-144">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-145">t</span><span class="MJXp-mo" id="MJXp-Span-146" style="margin-left: 0em; margin-right: 0em;">)</span></span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> \ textbf {Klickwahrscheinlichkeit} = \ sigma \ left (\ sum \ varphi _ {i} \ right) \ textbf {, wobei} \ varphi _ {i} \ textbf {- Gewicht einiger Wörter (Abfragewort, Dokumentwort) } </script></p><br>  Jetzt müssen Sie einen guten Datensatz erstellen.  Es stellt sich heraus, dass es ausreicht, den Klickverlauf der Benutzer zu erfassen und negative Beispiele hinzuzufügen.  Wie mische ich negative Beispiele ein?  Es ist am besten, sie im Verhältnis 1: 1 zum Datensatz hinzuzufügen.  Darüber hinaus können die Beispiele selbst in der ersten Phase des Trainings zufällig erstellt werden: Für ein Abfrage-Dokument-Paar finden wir ein anderes zufälliges Dokument, und wir betrachten ein solches Paar als negativ.  In den späteren Phasen des Trainings ist es vorteilhaft, komplexere Beispiele anzugeben: solche mit Schnittpunkten sowie zufällige Beispiele, die das Modell als ähnlich betrachtet (hartes negatives Mining). <br><br>  Beispiel: Synonyme für das Wort "Dreieck". <br><br><div class="scrollable-table"><table><tbody><tr><th>  Ursprüngliches Wort <br></th><th>  Synonym <br></th><th>  Gewicht <br></th></tr><tr><td>  DREIECK <br></td><td>  GEOMETRIE <br></td><td>  0,55878 <br></td></tr><tr><td>  DREIECK <br></td><td>  LÖSEN <br></td><td>  0,66079 <br></td></tr><tr><td>  DREIECK <br></td><td>  Gleichseitig <br></td><td>  0,37966 <br></td></tr><tr><td>  DREIECK <br></td><td>  OGE <br></td><td>  0,51284 <br></td></tr><tr><td>  DREIECK <br></td><td>  BERMUDA <br></td><td>  0,52195 <br></td></tr></tbody></table></div><br>  Zu diesem Zeitpunkt können wir bereits eine gute Funktion unterscheiden, die mit Wörtern übereinstimmt, aber dies ist nicht das, wonach wir streben. Eine solche Funktion ermöglicht es uns, indirekte Wörter abzugleichen, und wir möchten ganze Sätze vergleichen. <br><br>  Hier helfen uns neuronale Netze.  Lassen Sie uns einen Encoder erstellen, der Text (eine Anforderung oder ein Dokument) akzeptiert und eine Vektordarstellung erzeugt, sodass ähnliche Texte nahe und entfernte Vektoren haben.  Beispielsweise können Sie den Kosinusabstand als Maß für die Ähnlichkeit verwenden. <br><br>  Hier werden wir den Apparat siamesischer Netzwerke verwenden, weil sie viel einfacher zu trainieren sind.  Das siamesische Netzwerk besteht aus einem Codierer, der zum Abtasten von Daten aus zwei oder mehr Familien angewendet wird, und einer Vergleichsoperation (z. B. Kosinusabstand).  Beim Anwenden des Encoders auf Elemente aus verschiedenen Familien werden die gleichen Gewichte verwendet.  Dies allein ergibt eine gute Regularisierung und reduziert die Anzahl der für das Training erforderlichen Faktoren erheblich. <br><br>  Der Encoder erzeugt Vektordarstellungen aus Texten und lernt, so dass der Kosinus zwischen Darstellungen ähnlicher Texte maximal und zwischen Darstellungen unterschiedlicher Texte minimal ist. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/164/235/672/164235672d1048f21bf0ca522703999a.png" width="400"></div><br>  Ein Netzwerk von tiefer semantischer Komplexität DSSM ist für unsere Aufgabe geeignet.  Wir verwenden es mit geringfügigen Änderungen, die ich unten diskutieren werde. <br><br>  So funktioniert das klassische DSSM: Abfragen und Dokumente werden in Form eines Trigrammbeutels dargestellt, aus dem eine Standardvektordarstellung erhalten wird.  Es wird durch mehrere vollständig verbundene Schichten geleitet, und das Netzwerk wird so trainiert, dass die bedingte Wahrscheinlichkeit des Dokuments auf Anfrage maximiert wird, was der Maximierung des Kosinusabstands zwischen den Vektordarstellungen entspricht, die durch einen vollständigen Durchgang durch das Netzwerk erhalten werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2a/f6b/71f/b2af6b71f72649de1282e54456bfd695.png"><br>  <i>Po-Sen Huang Xiaodong Er <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jianfeng Gao</a> Li Deng Alex Acero Larry Heck.</i>  <i>2013 Lernen tief strukturierter semantischer Modelle für die Websuche mithilfe von Klickdaten</i> <br><br>  Wir sind fast den gleichen Weg gegangen.  Jedes Wort in der Abfrage wird nämlich als Trigrammvektor und der Text als Wortvektor dargestellt, wodurch Informationen darüber verbleiben, welches Wort stand.  Als nächstes verwenden wir eindimensionale Faltungen innerhalb der Wörter, um deren Darstellung zu glätten, und die Operation des globalen maximalen Ziehens, um Informationen über den Satz in einer einfachen Vektordarstellung zu aggregieren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed0/e1f/fd9/ed0e1ffd98e077ba51c91004485f4d2f.jpg"><br><br>  Der Datensatz, den wir für das Training verwendet haben, stimmt im Wesentlichen vollständig mit dem für das lineare Modell verwendeten überein. <br><br>  Wir haben hier nicht aufgehört.  Erstens haben sie einen Pre-Training-Modus entwickelt.  Wir nehmen eine Liste von Abfragen für das Dokument, geben ein, welche Benutzer mit diesem Dokument interagieren, und trainieren das neuronale Netzwerk, um solche Paare eng einzubetten.  Da diese Paare aus derselben Familie stammen, ist ein solches Netzwerk leichter zu erlernen.  Außerdem ist es einfacher, Kampfbeispiele neu zu trainieren, wenn wir Anfragen und Dokumente vergleichen. <br><br>  <i>Beispiel: Benutzer gehen zu e.mail.ru/login mit Anfragen: E-Mail, E-Mail-Eingabe, E-Mail-Adresse, ...</i> <br><br><div class="scrollable-table"><table><tbody><tr><th>  Anfrage <br></th><th>  Das Dokument <br></th><th>  BM25 <br></th><th>  Neurorank <br></th></tr><tr><td>  Astana Toyota <br></td><td>  Offizielle Website von Toyota in Kasachstan <br></td><td>  0 <br></td><td>  0,839 <br></td></tr><tr><td>  Poesie <br></td><td>  Poetry.ru <br></td><td>  0 <br></td><td>  0,823 <br></td></tr><tr><td>  Welttraum Pattaya <br></td><td>  Bangkok Traumwelt <br></td><td>  0 <br></td><td>  0,818 <br></td></tr><tr><td>  spb Kartoffel <br></td><td>  Kaufen Sie Kartoffeln in St. Petersburg <br></td><td>  0 <br></td><td>  0,811 <br></td></tr></tbody></table></div><br>  Schließlich ist der letzte schwierige Teil, mit dem wir immer noch zu kämpfen haben und in dem wir fast Erfolg haben, die Aufgabe, die Anfrage mit einem langen Dokument zu vergleichen.  Warum ist diese Aufgabe schwieriger?  Hier ist die Maschinerie siamesischer Netzwerke bereits schlechter geeignet, da die Anfrage und das lange Dokument zu verschiedenen Objektfamilien gehören.  Trotzdem können wir es uns leisten, die Architektur kaum zu verändern.  Es ist nur erforderlich, Windungen auch entsprechend den Wörtern hinzuzufügen, wodurch mehr Informationen über den Kontext jedes Wortes für die endgültige Vektordarstellung des Textes gespeichert werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/845/b2d/bba/845b2dbbac3e32158f085c06af1dc686.png"><br><br>  Derzeit verbessern wir die Qualität unserer Modelle weiter, indem wir Architekturen modifizieren und mit Datenquellen und Stichprobenmechanismen experimentieren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de468075/">https://habr.com/ru/post/de468075/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de468063/index.html">Angulareact</a></li>
<li><a href="../de468065/index.html">Mentale Produktmanagementmodelle für alle</a></li>
<li><a href="../de468067/index.html">So funktioniert Alpha Compositing</a></li>
<li><a href="../de468071/index.html">Eduard Medwedew, CTO bei Tungsten Labs: „Wir sind so weit gewachsen, dass Technologie massiven Schaden anrichten kann.“</a></li>
<li><a href="../de468073/index.html">Andrei Terekhov: "Sie können so viel sagen, wie Sie möchten, dass Amerikaner besser sind, aber unser Auto bricht nie zusammen."</a></li>
<li><a href="../de468077/index.html">Posit-Tests für Erwachsene. Spektralanalyse</a></li>
<li><a href="../de468079/index.html">Benutzerdefinierte Dimensionen in Google Analytics, die uns mehr als einmal gespeichert haben</a></li>
<li><a href="../de468081/index.html">"Anonyme Daten" oder was in 152-FZ geplant ist</a></li>
<li><a href="../de468083/index.html">Android Camera2 API aus dem Wasserkocher</a></li>
<li><a href="../de468085/index.html">Das Buch "Safe DevOps. Effizienter Systembetrieb</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
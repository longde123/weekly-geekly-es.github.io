<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëêüèª üì§ üéâ Criando uma IA segura: especifica√ß√µes, confiabilidade e garantias üôè üò¶ üë©‚Äç‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Entre os autores do artigo est√£o funcion√°rios da equipe de seguran√ßa de intelig√™ncia artificial (equipe de seguran√ßa) da empresa DeepMind. 

 Construi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Criando uma IA segura: especifica√ß√µes, confiabilidade e garantias</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/425387/">  <font color="gray">Entre os autores do artigo est√£o funcion√°rios da equipe de seguran√ßa de intelig√™ncia artificial (equipe de seguran√ßa) da empresa DeepMind.</font> <br><br>  Construir um foguete √© dif√≠cil.  Cada componente requer estudo e teste cuidadosos, enquanto a seguran√ßa e a confiabilidade est√£o no centro.  Os cientistas e engenheiros de foguetes se re√∫nem para projetar todos os sistemas: da navega√ß√£o ao controle, motores e chassi.  Depois que todas as pe√ßas forem montadas e os sistemas verificados, s√≥ ent√£o podemos colocar os astronautas a bordo com a certeza de que tudo ficar√° bem. <br><br>  Se a intelig√™ncia artificial (IA) for um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foguete</a> , um dia todos receberemos ingressos a bordo.  E, como foguetes, a seguran√ßa √© uma parte importante da cria√ß√£o de sistemas de intelig√™ncia artificial.  A seguran√ßa requer um projeto cuidadoso do sistema, do zero, para garantir que os v√°rios componentes funcionem juntos como planejado, criando ao mesmo tempo todas as ferramentas para monitorar a opera√ß√£o bem-sucedida do sistema ap√≥s seu comissionamento. <br><br>  Em um n√≠vel alto, a pesquisa de seguran√ßa da DeepMind se concentra no design de sistemas confi√°veis, ao mesmo tempo em que detecta e mitiga poss√≠veis riscos a curto e longo prazo.  <b>A seguran√ßa t√©cnica da IA</b> √© um campo relativamente novo, mas de r√°pido desenvolvimento, cujo conte√∫do varia de um alto n√≠vel te√≥rico a pesquisas emp√≠ricas e espec√≠ficas.  O objetivo deste blog √© contribuir para o desenvolvimento do campo e incentivar uma conversa substantiva sobre id√©ias t√©cnicas, promovendo assim nosso entendimento coletivo da seguran√ßa da IA. <br><a name="habracut"></a><br>  No primeiro artigo, discutiremos tr√™s √°reas de seguran√ßa t√©cnica da IA: <b>especifica√ß√µes</b> , <b>confiabilidade</b> e <b>garantias</b> .  Os artigos futuros geralmente corresponder√£o aos limites descritos aqui.  Embora nossas vis√µes mudem inevitavelmente ao longo do tempo, acreditamos que essas tr√™s √°reas abrangem um espectro amplo o suficiente para fornecer uma classifica√ß√£o √∫til para pesquisas atuais e futuras. <br><br><img src="https://habrastorage.org/webt/sv/8c/se/sv8cseuw2rlofm85zszbk6nhv6k.png"><br>  <i><font color="gray">Tr√™s √°reas problem√°ticas de seguran√ßa da IA.</font></i>  <i><font color="gray">Cada bloco lista alguns problemas e abordagens relevantes.</font></i>  <i><font color="gray">Essas tr√™s √°reas n√£o s√£o isoladas, mas interagem umas com as outras.</font></i>  <i><font color="gray">Em particular, um problema de seguran√ßa espec√≠fico pode incluir v√°rios problemas de bloco.</font></i> <br><br><h1>  Especifica√ß√µes: definindo tarefas do sistema </h1><br><h4>  As especifica√ß√µes garantem que o comportamento do sistema de IA seja consistente com as verdadeiras inten√ß√µes do operador </h4><br>  Talvez voc√™ conhe√ßa o mito do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rei Midas</a> e o toque de ouro.  Em uma das op√ß√µes, o deus grego Dion√≠sio prometeu a Midas qualquer recompensa que desejasse, em gratid√£o pelo fato de o rei ter se esfor√ßado ao m√°ximo para mostrar hospitalidade e miseric√≥rdia ao amigo de Dion√≠sio.  Ent√£o <b>Midas pediu que tudo o que tocasse se transformasse em ouro</b> .  Ele estava fora de si de alegria com esse novo poder: um galho de carvalho, uma pedra e rosas no jardim - tudo se transformava em ouro por seu toque.  Mas ele logo descobriu a estupidez de seu desejo: at√© comida e bebida se transformavam em ouro em suas m√£os.  Em algumas vers√µes da hist√≥ria, at√© a filha foi v√≠tima de uma b√™n√ß√£o que acabou sendo uma maldi√ß√£o. <br><br>  Esta hist√≥ria ilustra o problema das especifica√ß√µes: como formular corretamente nossos desejos?  As especifica√ß√µes devem garantir que o sistema de IA se esforce para agir de acordo com os verdadeiros desejos do criador e n√£o sintonize com um destino mal definido ou at√© incorreto.  Tr√™s tipos de especifica√ß√µes s√£o formalmente distinguidos: <br><br><ul><li>  <b>especifica√ß√£o ideal</b> (‚Äú <b>desejos</b> ‚Äù), correspondente a uma descri√ß√£o hipot√©tica (mas dif√≠cil de formular) de um sistema de IA ideal, totalmente consistente com os desejos do operador humano; </li><li>  <b>especifica√ß√£o do projeto</b> (" <b>blueprint</b> "), a especifica√ß√£o correspondente que <i>realmente usamos</i> para criar um sistema de IA, por exemplo, uma fun√ß√£o espec√≠fica de remunera√ß√£o, para maximizar a programa√ß√£o de um sistema de aprendizado por refor√ßo; </li><li>  <b>especifica√ß√£o identificada</b> (" <b>comportamento</b> "), que melhor descreve o <i>comportamento real do</i> sistema.  Por exemplo, a fun√ß√£o de recompensa identificada como resultado da engenharia reversa ap√≥s observar o comportamento do sistema (aprendizado de refor√ßo inverso).  Essa fun√ß√£o e especifica√ß√£o de recompensa geralmente s√£o diferentes daquelas programadas pelo operador porque os sistemas de IA n√£o s√£o otimizadores ideais ou devido a outras consequ√™ncias imprevistas do uso da especifica√ß√£o de projeto. </li></ul><br>  <b>O problema de especifica√ß√£o</b> surge quando h√° uma discrep√¢ncia entre a <b>especifica√ß√£o ideal</b> e a <b>especifica√ß√£o identificada</b> , ou seja, quando o sistema de IA n√£o faz o que queremos dele.  Estudar o problema do ponto de vista da seguran√ßa t√©cnica da IA ‚Äã‚Äãsignifica: como projetar fun√ß√µes-alvo mais fundamentais e gerais e ajudar os agentes a descobrir se as metas n√£o est√£o definidas?  Se os problemas geram uma incompatibilidade entre as especifica√ß√µes ideais e de design, eles se enquadram na subcategoria "Design" e, entre o design e os identificados, na subcategoria "Emerg√™ncia". <br><br>  Por exemplo, em nosso artigo cient√≠fico <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI Safety Gridworlds</a> (onde outras defini√ß√µes de problemas de especifica√ß√£o e confiabilidade s√£o apresentadas em compara√ß√£o com este artigo), oferecemos aos agentes uma fun√ß√£o de recompensa pela otimiza√ß√£o, mas avaliamos seu desempenho real pela "fun√ß√£o de desempenho de seguran√ßa", que est√° oculto dos agentes.  Esse sistema modela as diferen√ßas indicadas: a fun√ß√£o de seguran√ßa √© uma especifica√ß√£o ideal, formulada incorretamente como uma fun√ß√£o de recompensa (especifica√ß√£o de design) e, em seguida, √© implementada por agentes que criam uma especifica√ß√£o que √© divulgada implicitamente por meio da pol√≠tica resultante. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pw/vd/cm/pwvdcm0ra3_bo4qzpu9gdc_nfco.gif"></div><br>  <i><font color="gray">Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">fun√ß√µes de recompensa defeituosas da</a> OpenAI <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">em estado selvagem</a> : um agente de aprendizado por refor√ßo encontrou uma estrat√©gia aleat√≥ria para obter mais pontos</font></i> <br><br>  Como outro exemplo, considere o jogo CoastRunners, que foi analisado por nossos colegas da OpenAI (veja a anima√ß√£o acima em "Fun√ß√µes de recompensa da vida selvagem com defeito").  Para a maioria de n√≥s, o objetivo do jogo √© terminar rapidamente a pista e ficar √† frente dos outros jogadores - esta √© a nossa especifica√ß√£o ideal.  No entanto, traduzir esse objetivo em uma fun√ß√£o exata de recompensa √© dif√≠cil, portanto o CoastRunners recompensa os jogadores (especifica√ß√£o de projeto) por atingirem o objetivo ao longo do percurso.  Ensinar um agente a jogar com treinamento de refor√ßo leva a um comportamento incr√≠vel: o agente controla o barco em c√≠rculo para capturar alvos que reaparecem, batendo e pegando fogo repetidamente, em vez de terminar a corrida.  A partir desse comportamento, conclu√≠mos (especifica√ß√£o identificada) que no jogo o equil√≠brio entre recompensa instant√¢nea e recompensa de c√≠rculo completo √© quebrado.  Existem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">muitos outros exemplos semelhantes nos</a> quais os sistemas de IA encontram brechas em suas especifica√ß√µes objetivas. <br><br><h1>  Confiabilidade: projetando sistemas que resistem a viola√ß√µes </h1><br><h4>  A confiabilidade garante que o sistema de IA continue a operar com seguran√ßa em caso de interfer√™ncia </h4><br>  Em condi√ß√µes reais, onde os sistemas de IA funcionam, h√° sempre um certo n√≠vel de risco, imprevisibilidade e volatilidade.  Os sistemas de intelig√™ncia artificial devem ser resistentes a eventos imprevistos e ataques hostis que podem danificar ou manipular esses sistemas.  <b>Os</b> estudos de <b>confiabilidade</b> dos sistemas de intelig√™ncia artificial visam garantir que nossos agentes permane√ßam dentro de limites seguros, independentemente das condi√ß√µes emergentes.  Isso pode ser alcan√ßado evitando riscos ( <b>preven√ß√£o</b> ) ou auto-estabiliza√ß√£o e degrada√ß√£o suave ( <b>recupera√ß√£o</b> ).  Problemas de seguran√ßa decorrentes de <b>mudan√ßa de distribui√ß√£o</b> , <b>entradas hostis</b> ( <b>entradas</b> advers√°rias) e <b>explora√ß√£o</b> insegura (explora√ß√£o insegura) podem ser classificados como problemas de confiabilidade. <br><br>  Para ilustrar a solu√ß√£o para o problema da <b>mudan√ßa</b> de <b>distribui√ß√£o</b> , considere um rob√¥ de limpeza dom√©stica que geralmente limpa salas sem animais de estima√ß√£o.  Em seguida, o rob√¥ foi lan√ßado na casa com o animal de estima√ß√£o - e a intelig√™ncia artificial colidiu com ele durante a limpeza.  Um rob√¥ que nunca viu gatos e c√£es antes ir√° lav√°-lo com sab√£o, o que levar√° a resultados indesej√°veis ‚Äã‚Äã( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Amodei e Olah et al., 2016</a> ).  Este √© um exemplo de um problema de confiabilidade que pode surgir quando a distribui√ß√£o de dados durante o teste difere da distribui√ß√£o durante o treinamento. <br><br><img src="https://habrastorage.org/webt/oi/k0/lc/oik0lc_srvx7tovbrec-dmbzqsa.gif"><br>  <i><font color="gray">Do trabalho da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">AI Safety Gridworlds</a> .</font></i>  <i><font color="gray">O agente aprende a evitar lava, mas ao testar em uma nova situa√ß√£o, quando a localiza√ß√£o da lava mudou, ele n√£o consegue generalizar o conhecimento - e corre direto para a lava.</font></i> <br><br>  A entrada hostil √© um caso espec√≠fico de uma mudan√ßa de distribui√ß√£o em que os dados de entrada s√£o especialmente projetados para enganar o sistema de IA. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/550/89a/6d5/55089a6d587e1745783257a0c898b046.png"><br>  <i><font color="gray">Uma entrada hostil sobreposta a imagens comuns pode fazer com que o classificador reconhe√ßa a pregui√ßa como um carro de corrida.</font></i>  <i><font color="gray">As duas imagens diferem em um m√°ximo de 0,0078 em cada pixel.</font></i>  <i><font color="gray">O primeiro √© classificado como uma pregui√ßa de tr√™s dedos com uma probabilidade superior a 99%.</font></i>  <i><font color="gray">O segundo - como um carro de corrida com uma probabilidade superior a 99%</font></i> <br><br>  <b>Pesquisas inseguras</b> podem ser demonstradas por um sistema que busca maximizar seu desempenho e objetivos sem garantir que a seguran√ßa n√£o seja comprometida durante o estudo, pois aprende e examina em seu ambiente.  Um exemplo √© um limpador de rob√¥ que coloca um esfreg√£o molhado em uma tomada el√©trica, estudando estrat√©gias de limpeza ideais ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Garc√≠a e Fern√°ndez, 2015</a> ; <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Amodei e Olah et al., 2016</a> ). <br><br><h1>  Garantias: monitoramento e controle da atividade do sistema </h1><br><h4>  A garantia d√° confian√ßa de que somos capazes de entender e controlar os sistemas de IA durante a opera√ß√£o </h4><br>  Embora as precau√ß√µes de seguran√ßa cuidadosamente pensadas possam eliminar muitos riscos, √© dif√≠cil fazer tudo desde o in√≠cio.  Ap√≥s o comissionamento dos sistemas de IA, precisamos de ferramentas para seu monitoramento e configura√ß√£o constantes.  Nossa √∫ltima categoria, garantia, aborda esses problemas de duas perspectivas: <b>monitoramento</b> e aplica√ß√£o. <br><br>  <b>O monitoramento</b> inclui todos os m√©todos de verifica√ß√£o de sistemas para analisar e prever seu comportamento, usando inspe√ß√£o humana (estat√≠sticas resumidas) e inspe√ß√£o autom√°tica (para analisar um grande n√∫mero de logs).  Por outro lado, a <b>submiss√£o</b> envolve o desenvolvimento de mecanismos de controle e restri√ß√µes no comportamento dos sistemas.  Problemas como <b>interpretabilidade</b> e <b>descontinuidade</b> pertencem √†s subcategorias de controle e envio, respectivamente. <br><br>  Os sistemas de intelig√™ncia artificial n√£o s√£o semelhantes a n√≥s nem na apar√™ncia nem na maneira como processam dados.  Isso cria problemas de <b>interpretabilidade</b> .  Ferramentas e protocolos de medi√ß√£o bem projetados permitem avaliar a qualidade das decis√µes tomadas pelo sistema de intelig√™ncia artificial ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Doshi-Velez e Kim, 2017</a> ).  Por exemplo, um sistema de intelig√™ncia artificial m√©dica idealmente faria um diagn√≥stico juntamente com uma explica√ß√£o de como chegou a essa conclus√£o - para que os m√©dicos possam verificar o processo de racioc√≠nio do come√ßo ao fim ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">De Fauw et al., 2018</a> ).  Al√©m disso, para entender sistemas de intelig√™ncia artificial mais complexos, podemos usar m√©todos automatizados para construir modelos de comportamento usando a <b>teoria da m√°quina da mente</b> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Rabinowitz et al., 2018</a> ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sp/ff/ei/spffeiaxzptaap4ghzl_xmcao1o.png"></div><br>  <i><font color="gray">A ToMNet detecta duas subesp√©cies de agentes e prev√™ seu comportamento (da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"Teoria da mente da m√°quina"</a> )</font></i> <br><br>  Finalmente, queremos poder desativar o sistema de IA, se necess√°rio.  Este √© um problema de <b>descontinuidade</b> .  Projetar um switch confi√°vel √© muito dif√≠cil: por exemplo, porque um sistema de IA com maximiza√ß√£o de recompensa geralmente possui fortes incentivos para evitar isso ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hadfield-Menell et al., 2017</a> );  e porque essas interrup√ß√µes, especialmente as frequentes, alteram a tarefa original, for√ßando o sistema de IA a tirar conclus√µes incorretas da experi√™ncia ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Orseau e Armstrong, 2016</a> ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fl/6d/dn/fl6ddnu5joy9i6jnya2wdrzpyeq.png"></div><br>  <i><font color="gray">O problema das interrup√ß√µes: interven√ß√£o humana (ou seja, pressionar o bot√£o Parar) pode mudar a tarefa.</font></i>  <i><font color="gray">Na figura, a interrup√ß√£o adiciona uma transi√ß√£o (em vermelho) ao processo de tomada de decis√£o de Markov, que altera a tarefa original (em preto).</font></i>  <i><font color="gray">Veja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Orseau e Armstrong, 2016</a></font></i> <br><br><h1>  Olhando para o futuro </h1><br>  Estamos construindo a base da tecnologia que ser√° usada para muitas aplica√ß√µes importantes no futuro.  Deve-se ter em mente que algumas solu√ß√µes que n√£o s√£o cr√≠ticas √† seguran√ßa ao iniciar o sistema podem tornar-se assim quando a tecnologia se generaliza.  Embora, ao mesmo tempo, esses m√≥dulos tenham sido integrados ao sistema por conveni√™ncia, os problemas surgidos ser√£o dif√≠ceis de resolver sem uma reconstru√ß√£o completa. <br><br>  Dois exemplos da hist√≥ria da ci√™ncia da computa√ß√£o podem ser citados: esse √© o ponteiro nulo, que Tony Hoar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">chamou de "erro de bilh√£o de d√≥lares"</a> , e o procedimento gets () em C. Se as linguagens de programa√ß√£o iniciais foram projetadas com seguran√ßa em mente, o progresso desaceleraria, mas √© prov√°vel que isso teria um efeito muito positivo na seguran√ßa da informa√ß√£o moderna. <br><br>  Agora, tendo pensado e planejado tudo cuidadosamente, somos capazes de evitar problemas e vulnerabilidades semelhantes.  Esperamos que a categoriza√ß√£o dos problemas deste artigo sirva de base √∫til para esse planejamento metodol√≥gico.  N√≥s nos esfor√ßamos para garantir que, no futuro, os sistemas de IA n√£o apenas funcionem com o princ√≠pio de ‚Äúespero que seja seguro‚Äù, mas tamb√©m muito confi√°vel e verific√°vel, porque os constru√≠mos dessa maneira! <br><br>  Esperamos continuar progredindo de maneira empolgante nessas √°reas, em estreita colabora√ß√£o com a comunidade de pesquisa em IA mais ampla, e encorajamos pessoas de v√°rias disciplinas a considerar contribuir para a pesquisa de seguran√ßa em IA. <br><br><h1>  Recursos </h1><br>  Para ler sobre este t√≥pico, abaixo, h√° uma sele√ß√£o de outros artigos, programas e taxonomias que nos ajudaram a compilar nossa categoriza√ß√£o ou fornecer uma vis√£o alternativa √∫til dos problemas de seguran√ßa t√©cnica da IA: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Bibliografia anotada dos materiais recomendados</a> (Center for Human-Compatible AI, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Seguran√ßa e controle para intelig√™ncia geral artificial</a> (UC Berkeley, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Recursos de seguran√ßa da IA</a> (Victoria Krakovna, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Revis√£o da Literatura de Seguran√ßa AGI</a> (Everitt et al., 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Preparando-se para usos maliciosos da IA</a> (2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Exemplos de jogos de especifica√ß√£o em AI</a> (Victoria Krakovna, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Dire√ß√µes e desiderata para o alinhamento da IA</a> (Paul Christiano, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Financiamento para pesquisa de alinhamento</a> (Paul Christiano, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Fundamentos de agentes para alinhar intelig√™ncia de m√°quina com interesses humanos: uma agenda de pesquisa t√©cnica</a> (Machine Intelligence Research Institute, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Mundos de grade de seguran√ßa de IA</a> (Leike et al., 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Intera√ß√µes entre o problema de controle da IA ‚Äã‚Äãe o problema de governan√ßa</a> (Nick Bostrom, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Alinhamento para sistemas avan√ßados de aprendizado de m√°quina</a> (Machine Intelligence Research Institute, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Seguran√ßa de IA: tr√™s problemas humanos e um problema de IA</a> (Stuart Armstrong, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="nofollow noopener">Problemas concretos na seguran√ßa da IA</a> (Dario Amodei et al, 2016) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">O problema do aprendizado de valor</a> (Machine Intelligence Research Institute, 2016) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Uma pesquisa de perguntas de pesquisa para IA robusta e ben√©fica</a> (Instituto Future of Life, 2015) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=" rel="noopener nofollow">Prioridades de pesquisa em intelig√™ncia artificial robusta e ben√©fica</a> (Instituto Future of Life, 2015) </li></ul><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Intelig√™ncia Artificial</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aprendizado de m√°quina</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Deepmind</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ai seguran√ßa</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt425387/">https://habr.com/ru/post/pt425387/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt425375/index.html">Outra maneira de ver as comunica√ß√µes de aplicativos</a></li>
<li><a href="../pt425377/index.html">Se os designers de produtos digitais criarem coisas reais</a></li>
<li><a href="../pt425379/index.html">Charles Nutter. Como transferir um projeto monol√≠tico antigo para o JRuby e vale a pena?</a></li>
<li><a href="../pt425383/index.html">Jet Infosystems, Rosreestr, NLMK e Utkonos lan√ßam AI hackathon</a></li>
<li><a href="../pt425385/index.html">A cabe√ßa do programador: como a codifica√ß√£o afeta o pensamento</a></li>
<li><a href="../pt425389/index.html">FadeObjects - Ocultar objetos entre a c√¢mera e o personagem</a></li>
<li><a href="../pt425393/index.html">QIWI server party 3.0: relat√≥rio + v√≠deos completos de todos os relat√≥rios</a></li>
<li><a href="../pt425395/index.html">10 fatos f√≠sicos que voc√™ deveria conhecer na escola, mas que talvez n√£o soubesse</a></li>
<li><a href="../pt425397/index.html">10 bibliotecas que todo desenvolvedor Android deve conhecer</a></li>
<li><a href="../pt425401/index.html">Relat√≥rio do Clube de Roma de 2018, cap√≠tulo 1.11: Tecnologia disruptiva e revolu√ß√£o digital</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
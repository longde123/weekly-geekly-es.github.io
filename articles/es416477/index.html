<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôçüèæ üë± üèÜ Aprendizaje autom√°tico y desarrollo m√≥vil üë®üèø‚Äçüè´ ü§öüèª üíÖüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Como regla general, un cient√≠fico de datos tiene una vaga idea del desarrollo m√≥vil, y los desarrolladores de aplicaciones m√≥viles no participan en el...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aprendizaje autom√°tico y desarrollo m√≥vil</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/416477/">  Como regla general, un cient√≠fico de datos tiene una vaga idea del desarrollo m√≥vil, y los desarrolladores de aplicaciones m√≥viles no participan en el aprendizaje autom√°tico.  <strong>Andrei Volodin</strong> , ingeniero de Prisma AI, vive en la uni√≥n de estos dos mundos y les dijo a los presentadores de podcast Podlodka c√≥mo se siente. <br><br>  Aprovechando el momento, Stas Tsyganov (Tutu.ru) y Gleb Novik (Tinkoff Bank), en primer lugar, dejaron en claro de una vez por todas que <strong>nadie est√° entrenando redes neuronales en dispositivos m√≥viles</strong> .  Y tambi√©n descubr√≠ que en el aprendizaje autom√°tico, desafortunadamente, no hay magos;  discuti√≥ t√©cnicas modernas como <strong>aprendizaje profundo, aprendizaje por refuerzo</strong> y redes de c√°psulas. <br><br>  Como resultado, ya que Podlodka es un programa de audio sobre desarrollo m√≥vil, se acercaron a ella y descubrieron c√≥mo funciona todo para dispositivos m√≥viles. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fw/ph/db/fwphdbn4sxovfbminez_irgn6pm.jpeg"></div><br>  La siguiente es la versi√≥n de texto de esta conversaci√≥n, y la entrada del podcast est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><a name="habracut"></a><br><h1>  Acerca de Andrei Volodin, cocos2d y Fiber2d <br></h1><br>  GLEB: Cu√©ntanos un poco sobre ti.  Que estas haciendo <br><br>  ANDREW: Soy un desarrollador m√≥vil, pero hago muy poco en el desarrollo cl√°sico de iOS.  Mis responsabilidades pr√°cticamente no incluyen trabajar con UIKit.  Soy el desarrollador principal del motor de juegos Cocos2d bastante popular en GitHub.  Por el momento, soy ingeniero de GPU en Prisma.  Mis responsabilidades incluyen la integraci√≥n de redes neuronales en tarjetas de video y trabajar con realidad aumentada, en particular, con el kit VR. <br><br>  GLEB: ¬°Genial!  Especialmente interesante sobre cocos2d.  Que yo sepa, este marco apareci√≥ hace mucho tiempo. <br><br>  ANDREW: S√≠, alrededor de 2009. <br><br>  GLEB: ¬øLo usaste desde el principio? <br><br>  ANDREW: No.  Me convert√≠ en el desarrollador principal solo en 2015.  Antes de eso, era un contribuidor principal.  Apportable, que financi√≥ el desarrollo, se declar√≥ en quiebra, las personas que recibieron el dinero para el desarrollo se fueron y yo me convert√≠ en el l√≠der.  Ahora soy administrador en el foro y ayudo a los reci√©n llegados con algunos problemas. Las √∫ltimas versiones las he publicado.  Es decir, soy el mantenedor principal en este momento. <br><br>  GLEB: ¬øPero cocos2d sigue vivo? <br><br>  ANDREW: Lo m√°s probable es que no, principalmente debido al hecho de que est√° escrito en Objective-C, y hay mucho legado.  Por ejemplo, apoyo mis juguetes antiguos escritos con su uso, otros desarrolladores, mis proyectos heredados.  De los motores actuales se puede escuchar sobre Fiber2d.  Este es tambi√©n mi proyecto. <br><br>  Fiber2d es el primer motor de juegos Swift que se transfiere a Android.  Lanzamos un juego escrito completamente en Swift tanto en iOS como en Android.  Sobre esto tambi√©n se puede encontrar en Github.  Este es el pr√≥ximo hito en el desarrollo de la comunidad cocos2d. <br><br><h1>  Sobre el aprendizaje autom√°tico en los dedos <br></h1><br>  GLEB: Comencemos a avanzar gradualmente hacia nuestro tema hoy.  Hoy hablaremos <strong>sobre el aprendizaje autom√°tico y todo lo que lo rodea</strong> , conectado y desconectado con tel√©fonos m√≥viles.  Primero, descubramos de qu√© se trata el aprendizaje autom√°tico.  Trataremos de explicar todo lo posible con los dedos, porque no todos los desarrolladores m√≥viles est√°n familiarizados con √©l.  ¬øPuedes decirnos qu√© es? <br><br>  ANDREW: Basado en la definici√≥n cl√°sica, <strong>el aprendizaje autom√°tico es una b√∫squeda de patrones en un conjunto de datos</strong> .  Un ejemplo cl√°sico son las redes neuronales, que ahora son muy populares.  Entre ellos hay redes relacionadas con la clasificaci√≥n.  Un ejemplo simple de la tarea de clasificaci√≥n es determinar lo que se muestra en la imagen: hay alg√∫n tipo de imagen, y queremos entender qu√© es: un perro, un gato u otra cosa. <br><br>  Escribir esto con c√≥digo est√°ndar es muy dif√≠cil porque no est√° claro c√≥mo hacerlo.  Por lo tanto, se utilizan modelos matem√°ticos, que se denominan aprendizaje autom√°tico.  Se basan en el hecho de que ciertos patrones se extraen de una gran cantidad de ejemplos, y luego, usando estos patrones, es posible hacer predicciones con cierta precisi√≥n sobre nuevos ejemplos que no estaban en el conjunto de datos original.  Esto es, en pocas palabras. <br><br>  GLEB: En consecuencia, ¬øest√° aprendiendo una historia sobre cambiar un modelo utilizando un conjunto de datos de capacitaci√≥n? <br><br>  ANDREW: Durante el entrenamiento, el modelo, como regla, permanece constante.  Es decir, eliges alg√∫n tipo de arquitectura y la aprendes.  Si tomamos por ejemplo las redes neuronales, que no se limitan a todo el aprendizaje autom√°tico, inicialmente, en t√©rminos generales, todos los pesos son ceros u otros valores id√©nticos.  A medida que alimentamos nuestros datos al marco de aprendizaje, los pesos cambian un poco con cada nuevo ejemplo, y al final se vierten en una m√°quina entrenada. <br><br>  STAS: El objetivo final de este modelo es proporcionar r√°pidamente algunos datos que no provienen de la muestra de capacitaci√≥n, ¬øobtener r√°pidamente el resultado? <br><br>  ANDREW: S√≠, pero no se trata solo de velocidad.  Por ejemplo, algunas tareas no se pueden resolver de manera diferente; por ejemplo, el ejemplo de clasificaci√≥n es muy no trivial.  Antes de que se dispararan las redes de clasificaci√≥n, no hab√≠a ninguna soluci√≥n para comprender lo que se muestra en la imagen.  Es decir, en algunas √°reas esta es una tecnolog√≠a directamente revolucionaria. <br><br><h1>  Sobre el trabajo manual y el aprendizaje autom√°tico <br></h1><br>  STAS: Hace poco le dije a mi abuela qu√© es el aprendizaje autom√°tico.  Inicialmente pens√≥ que el aprendizaje autom√°tico es cuando una m√°quina le ense√±a a alguien.  Comenc√© a explicarle que, de hecho, por el contrario, estamos tratando de ense√±arle a la m√°quina para que luego realice alg√∫n tipo de tarea. <br><br>  Present√© los problemas que resuelve el aprendizaje autom√°tico.  La mayor√≠a de ellos, antes de que se disparara el aprendizaje autom√°tico, eran realizados por personas.  Adem√°s, esto no se consider√≥ un trabajo poco calificado, pero no de alta tecnolog√≠a, digamos que s√≠.  Estas son las operaciones m√°s simples que una persona puede realizar en gran medida.  ¬øTe imaginas eso? <br><br>  ANDREW: Eso tambi√©n se puede decir.  De hecho, ahora a√∫n se necesita ese trabajo, pero solo para preparar conjuntos de datos para el aprendizaje autom√°tico.  De hecho, en algunas √°reas, por ejemplo, en medicina, el aprendizaje autom√°tico hace posible suavizar un poco las tareas de rutina y facilitar un poco el proceso.  Pero no siempre  No dir√≠a que el aprendizaje autom√°tico se centra en facilitar el trabajo tonto.  A veces hace un trabajo bastante intelectual. <br><br>  STAS: ¬øPuedes dar un ejemplo de ese trabajo intelectual? <br><br>  ANDREW: Por ejemplo, nuestra aplicaci√≥n Prisma, muchos probablemente la usaron (¬°esto no es un anuncio!) No se puede decir que se trata de un trabajo intelectual y la gente a menudo redibuja la imagen en im√°genes, y la red neuronal lo hace: le das una imagen normal y <strong>obtienes algo nuevo</strong> .  Adem√°s, uno puede discutir si es hermoso o no, pero el hecho es indiscutible de que es algo que una persona no puede hacer, o lleva una cantidad enorme de tiempo. <br><br><h1>  Sobre la historia <br></h1><br>  GLEB: S√≠, creo que este es un gran ejemplo.  Probablemente valga la pena echar un vistazo a la historia.  ¬øCu√°nto tiempo se ha desarrollado este tema?  Me parece que casi desde los inicios de la programaci√≥n, al menos hace mucho, mucho tiempo. <br><br>  ANDREW: S√≠, en general, la mayor√≠a de los conceptos que ahora se aplican ya se desarrollaron en los a√±os 90.  Naturalmente, ahora han aparecido nuevos algoritmos y la calidad de los algoritmos ha mejorado.  Y aunque existe la sensaci√≥n de que un repentino inter√©s en el aprendizaje autom√°tico surgi√≥ de la nada, de hecho, la gente ha estado interesada en √©l durante mucho tiempo. <br><br>  El progreso en las primeras etapas se debi√≥ al hecho de que estos son en su mayor√≠a modelos matem√°ticos, y las matem√°ticas se han estabilizado durante mucho tiempo en t√©rminos de descubrimientos. <br><br>  La explosi√≥n actual se debe √∫nicamente al hecho de <strong>que las capacidades de hierro a nuestro alrededor han crecido significativamente</strong> , principalmente debido al uso de tarjetas de video.  Debido al hecho de que hoy podemos hacer una gran computaci√≥n paralela, han aparecido nuevas tecnolog√≠as: aprendizaje autom√°tico, criptomonedas, etc. <br><br>  En su mayor parte, el inter√©s actual y, en general, la ola actual est√°n relacionados con el hecho de que <strong>simplemente se hizo posible</strong> .  Estos c√°lculos podr√≠an hacerse antes, pero catastr√≥ficamente largos.  Ahora les lleva un tiempo bastante razonable, por lo que todos comenzaron a usarlo. <br><br><h1>  Sobre el hierro <br></h1><br>  STAS: Actualmente estoy tomando un curso, y all√≠, incluido, necesito entrenar todo tipo de modelos.  Entreno a algunos de ellos en mi MacBook de trabajo.  S√≠, en algunos casos, tiene que esperar, tal vez 5 minutos, y los modelos no son los mejores, la precisi√≥n promedio es de alrededor del 85%, pero lo principal es que funcionan.  Est√° claro que en la batalla quieres tener este porcentaje mejor y tal vez para la producci√≥n no sea del todo adecuado. <br><br>  ANDREW: S√≠, tales modelos probablemente no sean muy interesantes.  Lo m√°s probable es que esto se deba a las predicciones m√°s simples, etc.  En realidad, por ejemplo, una muestra de entrenamiento puede pesar 90 GB, y todo esto puede tomar una semana para aprender.  ¬°Empresas como Nvidia se jactan de que ahora han lanzado una nueva tarjeta gr√°fica especial de Tesla y puedes entrenar a Inception V3 en 24 horas!  Esto se considera un avance directo, porque antes tard√≥ varias semanas. <br><br>  <strong>Cuantos m√°s conjuntos de datos y m√°s compleja sea la estructura del modelo, m√°s tiempo llevar√° aprender</strong> .  Pero el rendimiento no es el √∫nico problema.  En principio, si realmente lo necesita, puede esperar un mes.  El problema est√° relacionado con la inferencia: c√≥mo aplicar esta red neuronal m√°s adelante.  Es necesario que durante su uso tambi√©n muestre buenos resultados en t√©rminos de rendimiento. <br><br>  STAS: Porque, en particular, quiero que todo funcione en dispositivos m√≥viles y que funcione r√°pidamente. <br><br>  ANDREW: No creo que inicialmente comenz√≥ a desarrollarse con miras a trabajar en aplicaciones m√≥viles.  Tal auge comenz√≥ en alg√∫n lugar en 2011, y de todos modos, estas fueron soluciones de escritorio.  Pero ahora el verdadero inter√©s de la comunidad est√° respaldado por el hecho de que en los iPhones, incluido, se ha hecho posible lanzar redes que funcionan en tiempo real. <br><br>  GLEB: Stas, dijiste que el resultado final depende de la potencia de tu tarjeta de video y, en general, del sistema.  Es decir, ¬øno funciona de otra manera? <br><br>  ANDREW: Esto no es as√≠, pero no estoy seguro de que el modelo sea entrenado en una m√°quina de baja potencia. <br><br>  GLEB: Por cierto, recuerdo, hace 5 a√±os, cuando solo hab√≠a un auge en las redes neuronales, nuestros maestros dijeron que todo lo nuevo es solo un viejo olvido.  Todo ya estaba en los a√±os 70-80 y no funcionar√°, desde entonces no funcion√≥.  Probablemente, todav√≠a estaban equivocados. <br><br>  ANDREW: S√≠  Para algunas tareas, el aprendizaje autom√°tico ahora se ha disparado muy duro.  Objetivamente, se puede decir que funcionan. <br><br><h1>  Sobre el aprendizaje profundo <br></h1><br>  GLEB: Hay algo tan de moda: el aprendizaje profundo.  ¬øCu√°l es su diferencia de lo que hablamos para esto? <br><br>  ANDREW: No dir√≠a que hay diferencias.  Hay solo algunos subconjuntos de aprendizaje autom√°tico, y hay una gran cantidad de ellos.  Debe comprender que lo que se llama <strong>aprendizaje profundo es esa parte del aprendizaje autom√°tico que com√∫nmente se conoce como redes neuronales</strong> .  Se llama profundo porque hay muchas capas en las redes neuronales, y cuantas m√°s capas, m√°s profunda es la red neuronal.  De esto vino el nombre. <br><br>  Pero hay otros tipos de aprendizaje autom√°tico.  Por ejemplo, el aprendizaje autom√°tico basado en √°rboles se ha utilizado con √©xito para el seguimiento de rostros hasta ahora porque es mucho m√°s r√°pido que las neuronas.  Tambi√©n se usa para clasificar, mostrar anuncios y m√°s. <br><br>  Es decir, el aprendizaje profundo no es otra cosa.  Esto es en realidad un subconjunto de aprendizaje autom√°tico que incluye una tonelada de todo.  Solo el aprendizaje profundo se ha convertido en el m√°s popular hoy en d√≠a. <br><br><h1>  Sobre la teor√≠a de las redes neuronales. <br></h1><br>  STAS: Quer√≠a hablar un poco sobre la teor√≠a de las redes neuronales, lo intentar√© m√°s f√°cilmente.  Dijiste que tienen muchas capas.  En teor√≠a, si tenemos una capa, y hay algunos objetos ubicados en el plano, con la ayuda de una capa podemos dividir este plano en dos partes, ¬øverdad? <br><br>  ANDREW: No, en realidad no. <br><br>  STAS: ¬øQu√© nos da una gran cantidad de capas, si est√°n en los dedos? <br><br>  ANDREW: ¬øQu√© es una red neuronal?  Vamos a aclararlo.  Esta es solo una funci√≥n matem√°tica que toma un conjunto de n√∫meros como entrada y tambi√©n proporciona un conjunto de n√∫meros como salida, eso es todo. <br><br>  Que hay adentro  Ahora las m√°s populares son las redes convolucionales dentro de las cuales tiene lugar la convoluci√≥n: simplemente hay muchas multiplicaciones de matrices entre s√≠, los resultados se suman, estas operaciones se realizan en cada capa.  Adem√°s, entre las capas existe la llamada activaci√≥n, que solo permite que las redes neuronales sean profundas. <br><br>  Dado que la combinaci√≥n de transformaciones lineales es una transformaci√≥n lineal, despu√©s de hacer 10 capas lineales, todav√≠a se pueden representar como una capa lineal.  Para que las capas no colapsen, entre ellas hay ciertas acciones matem√°ticas que hacen que la funci√≥n no sea lineal.  Esto es necesario para aumentar el n√∫mero de par√°metros. <br><br>  En t√©rminos generales, una red neuronal es solo una gran variedad de n√∫meros, que luego se aplican de alguna manera a nuestros datos, por ejemplo, a una imagen.  Pero una imagen, tambi√©n un conjunto de n√∫meros, es solo una serie de p√≠xeles.  Cuando entrenamos la red, consideramos, por ejemplo, 15 millones de par√°metros (cada n√∫mero es un par√°metro separado), que pueden desplazarse ligeramente un poco hacia la izquierda, un poco hacia la derecha con la ayuda de algunas heur√≠sticas.  Gracias a una cantidad tan enorme de par√°metros, se obtienen resultados geniales. <br><br>  Se necesita un entrenamiento profundo precisamente para que haya muchos de estos par√°metros, y todo no se colapse en una sola capa. <br><br>  GLEB: Parece m√°s o menos claro. <br><br>  ANDREW: El aprendizaje profundo es un subconjunto del aprendizaje autom√°tico.  Pero por alguna raz√≥n, surgi√≥ una exageraci√≥n sobre este tema, especialmente hace alg√∫n tiempo de todas las grietas, creo que se podr√≠a escuchar sobre el aprendizaje profundo.  No s√© si est√° justificado o no. <br><br>  GLEB: Creo que tal popularidad se debe al hecho de que da resultados impresionantes. <br><br><h1>  Sobre tareas <br></h1><br>  STAS: Con la ayuda de las redes neuronales, puede resolver la mayor√≠a de los problemas del aprendizaje autom√°tico, ¬øverdad? <br><br>  ANDREW: S√≠ <br><br>  STAS: Entonces, ¬øqu√© tareas se pueden resolver con m√©todos de aprendizaje autom√°tico? <br><br>  ANDREW: En realidad, este es un tema delicado, porque en realidad necesitas dejar de idealizar y romantizar lo que est√° sucediendo.  Como dije, no hay inteligencia artificial all√≠.  <strong>Este es un modelo puramente matem√°tico y una funci√≥n matem√°tica</strong> que multiplica algo, etc. <br><br>  Por el lado, parece que ahora el aprendizaje autom√°tico se ha estancado un poco en ciertas categor√≠as de tareas.  Esto, por ejemplo, la clasificaci√≥n (un ejemplo del que hablamos al principio), el seguimiento de los objetos y su segmentaci√≥n.  El √∫ltimo est√° en nuestra aplicaci√≥n Sticky AI: selecciona a una persona y se elimina el fondo.  Tambi√©n hay segmentaci√≥n m√©dica biol√≥gica cuando, por ejemplo, se detectan c√©lulas cancerosas.  Hay redes generativas que aprenden de n√∫meros aleatorios, y luego pueden crear algo nuevo.  Hay tareas de Transferencia de estilo y otras. <br><br>  Pero por el momento no hay una plataforma e infraestructura convenientes para usar el aprendizaje autom√°tico.  Por ejemplo, tiene un problema que usted, como persona, puede resolver f√°cilmente, pero como programador, no puede resolverlo debido a su complejidad y porque no puede simplemente escribir un algoritmo imperativo.  Pero al mismo tiempo, tampoco es posible entrenar una red neuronal principalmente porque hay un problema con la escasez de datos.  Para entrenar una neurona, necesita grandes conjuntos de datos con muchos ejemplos, adem√°s de muy formalizados, descritos en una determinada regulaci√≥n, etc.  Adem√°s, necesita la arquitectura de esta red neuronal. <br><br>  Es decir, primero <strong>debe formalizar los datos de entrada en forma de n√∫meros</strong> , hacer la arquitectura del modelo en s√≠, luego formalizar los datos de salida en forma de n√∫meros, de alguna manera interpretarlos.  Para hacer esto, necesita un aparato matem√°tico bastante poderoso y, en general, una comprensi√≥n de c√≥mo funciona todo.  Por lo tanto, ahora me parece que el uso de neuronas fuera de compa√±√≠as especializadas como la nuestra est√° disminuyendo un poco. <br><br>  Algunas tareas que no se resolvieron antes, las neuronas aprendieron a resolver muy bien.  Pero no existe tal cosa que las neuronas vinieron y resolvieron todo el espectro de problemas no resueltos. <br><br>  GLEB: ¬øEn qu√© √°reas ve problemas globales para los cuales las redes neuronales generalmente no son adecuadas? <br><br>  ANDREW: Es dif√≠cil responder de inmediato.  Nos enfrentamos a tareas en las que estamos trabajando y en las que no es posible entrenar una red neuronal.  Por ejemplo, ahora la industria del juego est√° muy interesada en aprender, e incluso hay algunas neuronas que tienen inteligencia artificial.  Pero, por ejemplo, esto a√∫n no se usa en los juegos AAA, porque de todos modos, en este momento es imposible entrenar la inteligencia artificial de un soldado abstracto para que se comporte como una persona para que parezca natural.  Es dificil <br><br><h1>  Sobre Dota <br></h1><br>  STAS: ¬øHas o√≠do que la inteligencia artificial ya est√° ganando en Dota? <br><br>  ANDREW: S√≠, pero sigue siendo un poco diferente.  Dota es un juego bastante matem√°tico, se puede describir.  No quiero ofender a nadie, pero esto es, de hecho, como las damas: el juego es el mismo.  Hay ciertas reglas, y solo juegas con ellas. <br><br>  Pero al mismo tiempo, todav√≠a hay dificultades para crear alg√∫n tipo de comportamiento natural, asociado principalmente con una peque√±a cantidad de datos y un peque√±o n√∫mero de ingenieros que pueden hacerlo. <br><br>  Por ejemplo, en Google, los ingenieros est√°n utilizando redes neuronales para entrenar a un modelo humano en 3D a caminar, solo para que se mueva.  Siempre se ve horrible, la gente no camina as√≠. <br><br><h1>  Sobre TensorFlow <br></h1><br>  STAS: Usted dijo que ahora, de hecho, no hay una manera f√°cil y econ√≥mica de resolver los problemas de aprendizaje autom√°tico sin comprender el aprendizaje autom√°tico.  En cualquier caso, resulta que esto debe ser confundido.  Me gustar√≠a saber sobre TensorFlow.  Parece que Google est√° tratando de asegurarse de que incluso las personas que no est√°n muy familiarizadas con esto y que no tengan una gran experiencia puedan resolver algunos problemas simples.  Dime qu√© es TensorFlow y c√≥mo crees que es posible. <br><br>  ANDREW: Vamos en orden.  <strong>TensorFlow no</strong> <strong>es</strong> <strong>realmente la cosa m√°s f√°cil de todas</strong> .  Este es uno de los llamados marcos de aprendizaje m√°s populares: un marco de aprendizaje de prop√≥sito general, no necesariamente una neurona.  Este no es el marco de m√°s alto nivel disponible.  Existe, por ejemplo, Keras, que es una abstracci√≥n de nivel superior en TensorFlow.  All√≠ puede hacer lo mismo con mucho menos c√≥digo. <br><br>  Las tareas t√≠picas se resuelven de manera bastante simple, porque, en particular, Github ya est√° lleno de ejemplos y repositorios.  Digamos que si su empresa realiza una b√∫squeda de im√°genes para una librer√≠a, entonces, en principio, todo est√° bien para usted.  Usted va a Github, hay ejemplos de c√≥mo puede tomar caracter√≠sticas de la imagen, escribe una b√∫squeda de caracter√≠sticas, ¬°ya est√°! <br><br>  De hecho, este es el caso con una gran cantidad de tareas.                  ,     .     -  , ,   ,     ,     ,     ,  TensorFlow ‚Äî    .    ,     . <br><br> :   ,   Google  ,        ? <br><br> : ,      ,   ,         .    ,  ,      ,       .  ,       ,        . <br><br><h1>   <br></h1><br> :      ,       .   ? -,  . <br><br> : .     ‚Äî     ¬´   ,   ,   ¬ª. ,   . <br><br> : , , ,     ,     .     ?  ,     ,       15   -  iOS ,  - .    ,    .  ,   . <br><br> :   ‚Äî , , -   .    ‚Äî  ‚Äî .      . ,  ,   R&amp;D   ,   : ¬´,   !¬ª ‚Äî - ,  ,     ,     0,5%: ¬´,   ,   !¬ª   .    ,      . <br><br> :         ,  ,  -      , ,    .   ?  .    ,          ‚Äî ,  70%.    ,        ,    .   ,     .     ,    ,     . <br><br> : ,   , ,   .      ,    .   ,   - ,      .    . <br><br> :  ,        . <br><br><h1>    <br></h1><br> :     ,  .    . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wl/fb/eo/wlfbeojhnc13z4_wcooqk5bhu4e.png"></div><br><br> :     ,       ?   ,   ,  ,   ‚Äî  ? <br><br> :     ,    ,      .      ,       . <br><br> -,  ,   <strong>   </strong> .       ,   computer science.      ,             . <br><br>        .       ,    500   Python,   .        .         .     ,      .      ,     ,   . <br><br>   ,     .  -  ,           .     ,         . <br><br> :  ,        Python   -  , ,  C++?       ,    . <br><br> : ,   .     - learning , ,  TensorFlow,        TensorFlow.    ,    <br><br>   ‚Äî    ,     TensorFlow.      TensorFlow ‚Äî      1  ‚Äî  ,   ,  . <br><br>      . ,  iOS    .       ,      learning ,  ,   Caffe, Torch, TensorFlow  .,            . <br><br>      ,        ,  ,   . R&amp;D  - ,  .              .     ()  : ¬´  !¬ª ‚Äî      ,           .         C++. <br><br>      : <br><br><ul><li> ,   .   ,     . <br></li><li>     . <br></li></ul><br><h1>    <br></h1><br> :      .    ,     ,     . <br><br> : ,       ?          , ? <br><br> :  ,     .  ,           ‚Äî   .    :   ,    ,   : ¬´,    ,   ‚Äî ¬ª,  -      .   , , -,        - .      ,      .    . <br><br>         .  ,   ,    ,         . <br><br> :     Google   ,         Google Street Maps. ,    . <br><br> : ,     -     . <br><br><h1>   Data Scientist <br></h1><br> :      .   ,       ‚Äî   ,   ,   ? <br><br> :   ,   . <br><br> : ,   ,    , ,  data scientist'.    ,   -  .    .          ,    ,       .   ‚Äî     ! <br><br>      ,    .      ,      -,      .   . <br><br> :        hype train. <br><br> : ,       ,    data scientist  .     ,      . <br><br> :   ,   .   -   data scientist'? <br><br> :    .    ,  .     ,  ,     ,  Git-     . Data scientist -  ,     .      ,  code review, unit- ‚Äî      .       ,      . <br><br> :    ,      ,     . <br><br> : ,         ,      - , , Kaffe 2, PyTorch ‚Äî   !    : ¬´ Data scientist  TensorFlow¬ª. <br><br><h1>  GPU- <br></h1><br>          .  ,    ,      ,    Swift,      UI-kit,   .  ,     ,       . <br><br>  ,   -  ,      .        ,       .   ,   ,     .          enterprise. <br><br>      - ,  ,     ,      . ,      ,    .     ,   . <br><br> :        ,       .   GPU   -    .      ,     ‚Äî         .   ,      Junior GPU   .    ,  ,         . <br><br><h1>   <br></h1><br> :    ‚Äî   . <br><br> :      ,   ? <br><br> : ,   ,        - . <br><br> :    ‚Äî      ? <br><br> :    , , -, -  . <br><br> :    ,        ? <br><br> :      .     , ,  ,         ,     .          Macbook Air.           ‚Äî -      ,     ,  . <br><br>        ,      Nvidia Titan   ,    .     ,     . <br><br><h1>   <br></h1><br> :     ?    ,    Nvidia     ,   .  ,     ,    .      ? <br><br> :                print   ,        .     NIPS,   ,         ,         .   , ,    .    - ,      ‚Äî    ,      . <br><br>   .    ONNX       ,     .     .   ,     .    ,    ,   .  ,    - ,     <strong>   </strong> .       . <br><br><h1>   <br></h1><br> :    ,    .   ,           ,    ,     ? <br><br> : ,       .   ,        .        ,    .       ,        ‚Äî   ,      .. <br><br>   ,      .  ,    .    ‚Äî  ,        ,        .   .    ,          ,       .         ,         ,   . <br><br><h1>  reinforcement training     <br></h1><br> :         .  ,    ,  , , AlphaGo.  ,    ,   ,    reinforcement training. <br><br> : Reinforcement training ‚Äî   .    ,    . ,   , ,        .    ,           ,      .   ,      . Reinforcement training   ,   ,    ,      ,  : ¬´ !¬ª <br><br> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AlphaGo</a> ‚Äî   ,    .      ,       .    ,     ,    .          ,       .  AlphaGo    ,    reinforcement training,   ,       . <br><br> ,           ,    ,       ,    . <br><br> :     ,    10 <sup>170</sup>  ‚Äî   .  ,      AlphaGo   .        ,    .   ,  , , .   ‚Äî  , -    ! <br><br>       ,    ,         ,    .          ,       ,       . ,   ! <br><br><h1>    <br></h1><br>  STAS: Quiero preguntar sobre algoritmos gen√©ticos.  Seg√∫n la descripci√≥n, parece que los algoritmos gen√©ticos tambi√©n pueden atribuirse al aprendizaje por refuerzo.  Tal como los imagino, hay una generaci√≥n, tomamos cada sujeto individual en una generaci√≥n, realiza alguna tarea, evaluamos sus acciones y luego, en base a estas estimaciones, seleccionamos los mejores.  Luego, entrecruzamos sus propiedades espec√≠ficas, creamos una nueva generaci√≥n, agregamos un poco de mutaci√≥n y ahora tenemos una nueva generaci√≥n.  Y repetimos estas operaciones, tratando de aumentar la utilidad final de cada miembro espec√≠fico de esta generaci√≥n.  Esto parece tener sentido.  ¬øSe considera esto entrenamiento de refuerzo o no? <br><br>  ANDREW: No, los algoritmos gen√©ticos siguen siendo algo diferentes. <br><br>  STAS: ¬øSe relacionan con el aprendizaje autom√°tico? <br><br>  ANDREW: Yo no dir√≠a eso.  No lo tomar√© ahora, pero pasamos los algoritmos gen√©ticos en la universidad, como todos los dem√°s, y me parece que esto es algo m√°s simple y m√°s no regulado o algo, en resumen, imperativo.  Es decir, se sabe de antemano que lo que se ingresar√°, tal ser√° la salida.  Sin embargo, en el aprendizaje autom√°tico, las cosas son algo diferentes: hay cierta probabilidad, precisi√≥n de las predicciones y todo con ese esp√≠ritu. <br><br>  Tal vez me corregir√°n las personas que entienden la terminolog√≠a mejor que yo, pero <em>desde lo alto de mi cabeza</em> dir√≠a que no. <br><br>  STAS: ¬øResulta que los algoritmos gen√©ticos no se usan para resolver la mayor√≠a de los problemas reales? <br><br>  ANDREW: S√≠, en su mayor√≠a son m√°s algor√≠tmicos y en la pr√°ctica rara vez me he reunido con ellos. <br><br><h1>  Sobre las redes de c√°psulas <br></h1><br>  GLEB: Hay otro subconjunto de aprendizaje autom√°tico: las llamadas redes de c√°psulas.  De nuevo, no profundicemos demasiado.  Cu√©ntame en pocas palabras qu√© es y por qu√© existe esta tendencia ahora. <br><br>  ANDREW: Este es un tema realmente s√∫per nuevo, solo tiene unos pocos meses.  Jeffrey Hinton public√≥ un art√≠culo y dijo que las redes convolucionales actuales son un camino a ninguna parte, y ofrecemos una nueva visi√≥n de c√≥mo se desarrollar√° esto.  La comunidad acept√≥ esta declaraci√≥n de manera ambigua y se dividi√≥ en dos campos: algunos dicen que es una exageraci√≥n exagerada, otros, una gran cosa y todo eso. <br><br>  Pero si explica con los dedos, ¬øc√≥mo funcionan las redes de convoluci√≥n?  Tomemos, por ejemplo, las neuronas que trabajan con im√°genes.  Hay una convoluci√≥n: una columna de matrices que recorre la imagen con alg√∫n paso, como si la escaneara.  En cada iteraci√≥n de tal paso, toda esta convoluci√≥n se aplica a esta pieza, y cada convoluci√≥n se convierte en un nuevo p√≠xel condicional, pero de una dimensi√≥n mucho mayor, esta operaci√≥n se repite para todas las cuadr√≠culas. <br><br>  Pero el problema con las redes convolucionales es que todos los datos que llegan a la primera capa llegan al final, tal vez no en su totalidad, pero todos afectan y todos alcanzan la etapa final.  En t√©rminos generales, si necesita determinar alguna parte de la imagen, por ejemplo, un gato, no necesita escanear toda la imagen.  Es suficiente en alg√∫n momento localizar la zona donde es m√°s probable que se encuentre el gato, y considerarla solo a ella, como lo hace una persona. <br><br>  As√≠ es como funcionan las redes de c√°psulas.  No me comprometer√© a explicar de manera experta su interior, sino por lo que entend√≠: hay ciertos √°rboles dentro de las redes de c√°psulas, y cada c√°psula posterior recibe solo los datos relevantes para la entrada.  Es decir, a trav√©s de ellos no se pasa todo, todo lo que inicialmente aceptamos para la entrada, y con cada nueva capa (no s√© c√≥mo se puede decir en la terminolog√≠a de las redes capsulares) solo se procesan los datos que realmente se necesitan, solo datos importantes .  Esta es la diferencia clave entre redes convolucionales y capsulares. <br><br>  GLEB: Suena interesante, pero no lo entiendo del todo. ¬øSe trata solo de las im√°genes en cuesti√≥n? <br><br>  ANDREW: No, eso es todo.  Us√© las im√°genes solo para explicar.  La idea clave es esta: no manejemos todos los datos y todas las caracter√≠sticas, sino solo aquellas que sean relevantes para la siguiente capa. <br><br><h1>  M√°s sobre juegos <br></h1><br>  STAS: ¬øEscuchaste que despu√©s de que los muchachos de AlphaGo derroten a todos en StarCraft? <br><br>  ANDREW: Obligado a decepcionarte, pero realmente no sigo esto.  No es que los eSports fueran interesantes para m√≠, pero ya est√° quedando claro en qu√© se encuentra el futuro.  Por ejemplo, ya hay startups que est√°n entrenadas para jugar Dota.  Ellos, como entrenador personal, analizan c√≥mo juegas y dicen que donde no eres lo suficientemente bueno, tienen sus propios datos entrenados en partidos de deportes electr√≥nicos.  Hay nuevas empresas para apostar que predicen qui√©n ganar√°, y m√°s. <br><br>  Mucha gente est√° trabajando en esta √°rea ahora, principalmente porque est√° girando mucho dinero en ella.  Pero personalmente, no me interesa por completo, as√≠ que desafortunadamente no sigo las noticias y las tendencias. <br><br>  STAS: ¬øCu√°l crees que es la dificultad de crear buena inteligencia artificial espec√≠ficamente para juegos estrat√©gicos?  ¬øEntiendo correctamente que, b√°sicamente, esta es una gran cantidad de opciones? <br><br>  ANDREW: S√≠  De hecho, ya discutimos este punto cuando expliqu√© que la inteligencia artificial todav√≠a no se usa en los juegos AAA, pero al mismo tiempo est√° en AlphaGo y, posiblemente, en otro lugar. <br><br>  El juego de ir con toda su complejidad consiste en el hecho de que en cada paso simplemente colocas una ficha para delinear una piedra, y el juego StarCraft es algo muy complejo.  All√≠ puede enviar sus unidades a lo largo de un n√∫mero virtualmente ilimitado de trayectorias, construir diferentes conjuntos de sus construcciones, etc. Todo esto es un par√°metro. <br><br>  Adem√°s, la dificultad radica en el hecho de que las redes neuronales no siempre piensan como una persona.  Cuando, por ejemplo, construimos una unidad, recordamos esto.  Pero muchas neuronas corren cada vez.  Por supuesto, hay redes recursivas que pueden recordar sus logros pasados.  En particular, se utilizan para la traducci√≥n y la informaci√≥n textual, cuando a medida que se genera la oraci√≥n, la neurona utiliza cada vez m√°s datos. <br><br>  Hay grandes dificultades con el hecho de que toda la cantidad de informaci√≥n y opciones deben formalizarse, es decir, encontrar un conjunto de datos para el entrenamiento que de alguna manera responda adecuadamente a las acciones de tu oponente, que tambi√©n puede ser un mill√≥n, a diferencia de jugar un juego de o ajedrez <br><br>  STAS: Ya veo, hay muchos par√°metros. <br><br>  GLEB: Pero no entiendo qu√©, est√° claro que DotA tiene menos par√°metros, pero sigue siendo el mismo en el sentido de que se envi√≥ a cualquier lugar, etc. <br><br>  STAS: Aqu√≠ Andrei se redujo al hecho de que, en primer lugar, tienes una unidad y la cantidad de opciones es mucho menor. <br><br>  ANDREW: Para ser honesto, nunca he jugado un segundo Dota en mi vida, pero en el original, que yo sepa, este es un juego s√∫per determinista.  Hay 3 corredores y torres que deben ser destruidos. <br><br>  GLEB: S√≠, pero en StarCraft, aunque no juego en absoluto, tambi√©n hay algunas formas y las mismas unidades.  Usted dice que hay muchos de ellos, pero lo m√°s probable es que siempre se manejen en lotes.  Es decir, aproximadamente lo mismo resulta. <br><br>  STAS: A√∫n debes organizar correctamente cada unidad por separado durante la batalla.  En el momento en que no se toman en un paquete, pero comienzan a organizarse, hay inmediatamente m√°s par√°metros. <br><br>  ANDREW: Tu problema es que piensas en estas categor√≠as: pon una unidad, etc., pero todo el tiempo olvidas que una neurona es solo una matriz, n√∫meros que se multiplican.  All√≠ debe formalizar, por ejemplo, cosas como tareas.  Digamos que hay un mapa para StarCraft y hay alg√∫n tipo de tarea en √©l, no importa si derrotas a un jugador u otra cosa.  Todo esto debe presentarse en forma de primitivas matem√°ticas, y esto es precisamente lo m√°s dif√≠cil. <br><br>  Si realmente fuera inteligencia artificial, la brecha entre Dota y StarCraft ser√≠a m√≠nima.  StarCraft puede ser un poco m√°s complicado en mec√°nica, pero sigue siendo lo mismo.  Pero debido al hecho de que operamos con n√∫meros, es m√°s dif√≠cil formalizar. <br><br><h1>  Sobre las redes de aprendizaje mutuo <br></h1><br>  STAS: Tengo la √∫ltima pregunta que quiero hacer antes de ir a nuestro tel√©fono m√≥vil.  No s√© c√≥mo se llama correctamente, pero hay una forma en que una red neuronal esencialmente sigue a otra e intenta encontrar patrones. <br><br>  ANDREW: No me comprometer√© a explicar ahora c√≥mo funciona, pero s√© con certeza que hay algoritmos s√∫per geniales que a veces escucho en el trabajo cuando dos redes neuronales aprenden a expensas entre s√≠.  Esta √°rea de experiencia ya es completamente inaccesible para m√≠, pero todo suena genial.  Hasta donde yo s√©, esto se usa para redes generativas.  Lamentablemente, no puedo decir m√°s. <br><br>  STAS: bien.  Usted dio las palabras clave m√°s importantes, el resto es Gleb y los lectores buscar√°n f√°cilmente en Google. <br><br><h1>  Acerca de los tel√©fonos m√≥viles (Apple) <br></h1><br>  GLEB: Pasemos a los tel√©fonos celulares a los que hemos estado yendo por mucho tiempo.  En primer lugar, ¬øqu√© podemos hacer cuando hablamos de aprendizaje autom√°tico en dispositivos m√≥viles? <br><br>  ANDREW: Por cierto, ¬øtienes un podcast para desarrolladores de iOS? <br><br>  GLEB: No somos un podcast de iOS.  Si, Stas? <br><br>  STAS: S√≠, para desarrolladores m√≥viles.  ¬øPor qu√© la pregunta? <br><br>  ANDREW: Solo porque la situaci√≥n es muy diferente.  Apple, en virtud del hecho de que siempre ha sido bueno en la integraci√≥n de software y hardware, y es famoso por ello, est√° muy elegante enganchado a un tren de bombo entrenado en m√°quinas. <br><br>  En 2014, Apple present√≥ la API de gr√°ficos met√°licos.  Se le cosieron cosas, por ejemplo, sombreadores de computadora, etc. Todo esto permiti√≥ con el advenimiento de iOS 10 incluir en el marco de Metal Performance Shaders muchas capas, activaciones y otros operadores de redes neuronales, en particular redes neuronales convolucionales. <br><br>  Simplemente dio un gran impulso, porque, por regla general, los c√°lculos en una tarjeta de video son muchas veces m√°s r√°pidos que en un procesador central.  Cuando Apple tuvo la oportunidad de leer en tarjetas de video m√≥viles, y r√°pidamente, no hubo necesidad de escribir sus propios operadores matem√°ticos, etc.  Dispar√≥ directamente muy duro.  Y un a√±o despu√©s lanzaron CoreML (hablaremos un poco m√°s adelante). <br><br>  Apple ten√≠a una muy buena base.  No s√© si tuvieron esa visi√≥n, o si coincidieron, pero ahora son objetivamente l√≠deres en la industria del aprendizaje autom√°tico en dispositivos m√≥viles. <br><br><h1>  Acerca de los tel√©fonos m√≥viles (Android) <br></h1><br>  Lo que funciona relativamente bien y genial en tiempo real en iOS, desafortunadamente, no funciona tan bien en Android.  Esto se debe no solo al hecho de que Android apesta.  Hay otros factores, en primer lugar, el hecho de que Android tiene una infraestructura muy diversa: hay dispositivos d√©biles, hay dispositivos fuertes, no se puede entender todo. <br><br>  Si Metal es compatible con todos los dispositivos iOS, entonces en Android ya es m√°s complicado: en alg√∫n lugar OpenGL es compatible con una versi√≥n, en otro lugar, en alg√∫n lugar no es compatible en absoluto.  En alg√∫n lugar hay Vulkan, en otro lugar no est√°.  Todos los fabricantes tienen sus propios controladores, que, por supuesto, no est√°n optimizados de ninguna manera, sino que simplemente admiten m√≠nimamente el est√°ndar.  Incluso sucede que ejecuta algunas redes neuronales en Android en la GPU, y funcionan a la misma velocidad que en la CPU, porque trabajar con memoria compartida es muy ineficiente y todo eso. <br><br>  En Android, las cosas est√°n mal en este momento.  Esto es bastante sorprendente, porque Google es uno de los l√≠deres, pero un poco ca√≠do en este sentido.  En Android, existe claramente una falta de implementaci√≥n de alta calidad de las capacidades del aprendizaje autom√°tico moderno. <br><br>  Para nosotros, por ejemplo, incluso en la aplicaci√≥n, no todas las funciones funcionan de la misma manera.  Lo que funciona r√°pido en iOS es m√°s lento en Android, incluso en dispositivos emblem√°ticos de potencia comparable.  En este sentido, en este momento, Android como plataforma est√° cayendo. <br><br><h1>  Sobre CoreML <br></h1><br>  STAS: Dado que dijeron sobre CoreML, probablemente ser√≠a correcto decir sobre TensorFlow Lite. <br><br>  ANDREW: CoreML es en realidad un caballo oscuro.  Cuando sali√≥ el a√±o pasado, todos dijeron: "¬°Guau, genial!"  Pero luego qued√≥ claro que esto es solo una peque√±a envoltura sobre Metal.  Las empresas que se dedican seriamente al aprendizaje autom√°tico, incluida la nuestra, han tenido sus propias soluciones durante mucho tiempo.  Por ejemplo, nuestras soluciones de prueba mostraron mejores resultados que CoreML en t√©rminos de velocidad y otros par√°metros. <br><br>  Pero el principal problema con CoreML era que no se pod√≠a personalizar.  A veces sucede que necesita una capa compleja en una red neuronal, que no est√°, por ejemplo, en Metal, y necesita escribirla usted mismo.  En CoreML, no era posible incrustar sus capas, por lo que tuvo que degradar a Metal al nivel inferior y escribir todo usted mismo. <br><br>  Recientemente, CoreML agreg√≥ esto, y ahora este marco se ha vuelto m√°s interesante.  Si usted es un desarrollador que no tiene nada relacionado con el aprendizaje autom√°tico en la empresa o en la aplicaci√≥n, puede ejecutar algunas neuronas en dos l√≠neas y ejecutarlas r√°pidamente en la GPU.  Los resultados, que muestran pruebas de rendimiento para CoreML, son comparables a las soluciones personalizadas y Metal desnudo. <br><br>  Es decir, CoreML funciona bastante bien.  Est√° un poco h√∫medo, tiene errores, pero cada mes est√° mejorando.  Apple est√° implementando activamente actualizaciones, no de la forma en que estamos acostumbrados, que las actualizaciones de los marcos de Apple se lanzan una vez al a√±o o en versiones semi-principales de iOS.  CoreML se est√° actualizando activamente, en este sentido, todo es genial. <br><br>  TensorFlow Lite proporciona un convertidor en CoreML, CatBoost tambi√©n admite un convertidor en CoreML.  En resumen, Apple hizo todo bien de nuevo.  Lanzaron un convertidor de c√≥digo abierto y dijeron: "Vamos a escribir todos los convertidores en CoreML", y muchos marcos de aprendizaje lo respaldaron. <br><br>  Al principio hubo cierto escepticismo sobre CoreML, en la √∫ltima WWDC la pregunta m√°s com√∫n para los desarrolladores de CoreML fue: ‚Äú¬øPor qu√© no permiten la descarga de modelos de Internet?  ¬øPor qu√© no los dejas encriptar?  Fue posible obtener estos modelos y, al parecer, robar propiedad intelectual. <br><br>  Ahora todo se ha reparado, se ha agregado funcionalidad y, por el momento, CoreML es definitivamente la plataforma l√≠der en este sentido. <br><br>  STAS: ¬øPuedes hablar sobre esto con m√°s detalle?  Resulta que ahora ya no puede almacenar el modelo, sino simplemente cargarlo desde alg√∫n lugar. <br><br>  ANDREW: S√≠, ya es posible.  Anteriormente, cuando preguntamos sobre esto, los desarrolladores sonrieron y dijeron: "Solo miren los encabezados".  Realmente hab√≠a dise√±adores que pod√≠an transferir archivos y todo se unir√≠a. <br><br>  Pero los modelos CoreML en su interior son bastante interesantes.  En realidad, son binarios ordinarios que almacenan pesos, pero adem√°s se generan archivos r√°pidos, que luego crean clases impl√≠citas.  Utiliza estas clases en su aplicaci√≥n, y los compiladores compilan este modelo en algunos archivos. <br><br>  Ahora, usando ciertos hacks y enfoques, es posible hacer que este modelo sea port√°til.  Puede proteger su propiedad intelectual mediante encriptaci√≥n y aligerar el peso de la aplicaci√≥n. <br><br>  En general, CoreML ahora se mueve en la direcci√≥n correcta.  No todo se puede hacer legalmente desde el punto de vista de App Review, no todo se puede hacer f√°cilmente, sin hacks, pero se nota c√≥mo los desarrolladores mejoran el marco. <br><br>  STAS: ¬°Genial!  Quer√≠a agregar que CoreML parece una soluci√≥n t√≠pica.  Relativamente hablando, es conveniente cuando quieres hacer algo simple usando el aprendizaje autom√°tico en tu aplicaci√≥n.  Parece que si esta es una tarea t√≠pica, Apple intent√≥ hacer que esta ruta sea lo m√°s simple posible, si encuentra un modelo, conjunto de datos y m√°s.  Esta es solo una historia sobre un problema t√≠pico, porque para ellos, probablemente, todo ya est√° listo. <br><br>  ANDREW: Para tareas t√≠picas, ¬°esto es generalmente s√∫per!  Sin hip√©rbole: realmente se necesitan dos l√≠neas de c√≥digo para ejecutar el modelo.  En este sentido, s√≠, es muy bueno, especialmente para desarrolladores independientes o empresas que no tienen un departamento de I + D en el personal, pero que tambi√©n quieren agregar algo genial. <br><br>  Pero esto no es tan interesante, porque las tareas t√≠picas se resolvieron en Github y con Metal, podr√≠a copiar este c√≥digo y ponerlo en la granja, aunque un poco m√°s complicado. <br><br>  Es importante que ahora este marco se est√© moviendo no solo hacia las tareas cotidianas cl√°sicas, sino tambi√©n hacia soluciones integradas.  ¬°Esto es realmente genial! <br><br><h1>  Acerca de la capacitaci√≥n en tel√©fonos m√≥viles <br></h1><br>  GLEB: ¬øDices que despu√©s del advenimiento de Metal fue posible entrenar modelos en tel√©fonos m√≥viles? <br><br>  ANDREW: No, la capacitaci√≥n en tel√©fonos m√≥viles nunca fue posible.  No tiene sentido, solo puedes ejecutarlo.  Si as√≠ lo digo, hice una reserva.  En los tel√©fonos m√≥viles, por supuesto, nadie ense√±a nada. <br><br>  STAS: Tampoco escuch√© nada sobre el entrenamiento en un tel√©fono m√≥vil. <br><br>  GLEB: Tampoco escuch√©, pero lo pens√©.  Por supuesto, parece intuitivamente que esto es algo extra√±o.  Pero definitivamente no hay tareas interesantes, ¬øcu√°ndo ser√≠a relevante? <br><br>  ANDREW: Es dif√≠cil imaginarlos.  Si hay algo as√≠, solo se distribuye el aprendizaje.  Incluso hay art√≠culos cient√≠ficos sobre c√≥mo hacer esto, pero seg√∫n tengo entendido, ¬øse pregunta c√≥mo aprender de los datos recopilados en el mismo tel√©fono?  Es solo que incluso si recolectas tanto (lo que no suceder√°), tomar√° tanto tiempo aprender que nunca terminar√°, y nadie trasladar√° el c√≥digo de entrenamiento a las plataformas m√≥viles, ¬øpor qu√©?  <strong>La capacitaci√≥n siempre se realiza en servidores y la inferencia en dispositivos.</strong> <br><br>  STAS: Pero finalmente resulta as√≠.  Si es una empresa, quiere tener algo as√≠, necesita datos y puede recopilarlos de sus usuarios, es decir, cargarlos peri√≥dicamente usted mismo. <br><br>  ANDREW: S√≠, pero funciona un poco diferente.  Recopila datos de todos los usuarios en un lugar en su servidor activo, entrena all√≠ y luego env√≠a de vuelta el modelo terminado.  Pero no para que todos en casa ense√±en algo. <br><br>  STAS: Por otro lado, el tel√©fono m√≥vil se calentar√≠a, y en el invierno ser√≠a relevante, pero por muy, probablemente, mucho tiempo. <br><br><h1>  Sobre tel√©fonos m√≥viles y el futuro <br></h1><br>  GLEB: ¬øHay otras cosas interesantes en t√©rminos de aplicar el aprendizaje autom√°tico a dispositivos m√≥viles?  Hablamos de lo que ya tenemos ahora.  Ser√≠a interesante mirar un poco hacia el futuro, por lo que generalmente nos gustar√≠a recibir en nuestras plataformas m√≥viles algunos superalimentos, superesoluciones. <br><br> : ,   ,    performance ‚Äî   ,    ,   . ,    - ,       . <br><br>     . ,         style-     ,       .         . <br><br>    CoreML   .  ,  ,      .   ,    ,   :   , ,  ‚Äî  ,       Android,   iOS,       .     ,         ,        iOS    Android. <br><br>   ,     ,    ,  ,      ‚Äî   Android,   iOS,   Github       .   -  ‚Äî   Uber   ,   Horovod.  Apple    ‚Äî      ,    .  ,     ,  ,   ,   ‚Äî          . <br><br> ,       .   , , ,      ‚Äî   ,   ,    - .     ,   . <br><br><h1>     <br></h1><br> :    ,     ,   ?  , ,      ?         . <br><br> :      ,     ‚Äî   (M. Bishop. Pattern Recognition and Machine Learning. Christopher. Springer. 2006),  -  .    ,      ,     3D ,     ,  - .      .   ,       ‚Äî    ,  ‚Äî     . <br><br>    ,     ,        ,    .   ,    -, ,      Andrew Ng  Coursera.       ,        . <br><br>      ,  ,         ,       ‚Äî          MNIST.   Hello World,     . <br><br> ,    ,    , , -    ,  .   -   ,   ,    ,     . <br><br> :   ? <br><br> :    advanced-  Andrew Ng! , ,  Kaggle,   ,       .          ,          ,    ‚Äî        Data Scientist. <br><br>   ‚Äî  ,     , ,     .      ,     ‚Äî        R&amp;D .    ,   .         .       ,      ,    . <br><br>       .    ,    Kaggle,  -  ‚Äî         90%  . <br><br><h1>  Resumen <br></h1><br> :    .  ,           ,     ,   ,        . <br><br><ul><li>  ,    ‚Äî    . ,   ,   ‚Äî      . </li><li>         . </li><li>        . </li><li> -    . </li><li> ,      ,  ,        . <br></li><li>       ,   . , ,    ,  -  - ! </li><li>         ‚Äî  ,    ,  CoreML ‚Äî  ,    . </li></ul><br>      ,     . <br><br><blockquote> ,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AppsConf 2018</a> ,   8  9   . <br><br>      80 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> ,  Call for Papers   ‚Äî <strong>   3 </strong> . ,   ,         . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es416477/">https://habr.com/ru/post/es416477/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es416467/index.html">Cu√°nta materia oscura atraviesa tu cuerpo cada segundo</a></li>
<li><a href="../es416469/index.html">Sincronizaci√≥n de billetera Bitcoin</a></li>
<li><a href="../es416471/index.html">El origen azul de Jeff Bezos planea aterrizar en la luna para 2023</a></li>
<li><a href="../es416473/index.html">Interfaz de la ciudad: fichas t√°ctiles en las aceras</a></li>
<li><a href="../es416475/index.html">El rover de oportunidad sigue en silencio debido a la tormenta de polvo en Marte</a></li>
<li><a href="../es416479/index.html">Concatenaci√≥n de cadenas o c√≥digo de bytes de parche</a></li>
<li><a href="../es416481/index.html">Yuri Akkermann: "Uno de los principios fundamentales de la Alianza FIDO es garantizar la privacidad"</a></li>
<li><a href="../es416483/index.html">Juego de rol: el formato m√°s antiguo de un mundo completamente gratuito en juegos</a></li>
<li><a href="../es416485/index.html">SpaceX est√° trabajando para crear un peque√±o "submarino" para salvar a los adolescentes de una cueva en Tailandia</a></li>
<li><a href="../es416487/index.html">Radio Astron cumple 7 a√±os</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
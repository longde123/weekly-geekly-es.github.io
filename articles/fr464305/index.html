<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📟 👏🏻 🛴 Petit, oui. Déballage du pétard microvirtuel 🚴🏽 ♒️ 🕵🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Enregistrez les microvirtuels de pétard. Nous utilisons deux méthodes populaires pour isoler les charges de travail multi-utilisateurs: les machines v...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Petit, oui. Déballage du pétard microvirtuel</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/464305/">  Enregistrez les microvirtuels de pétard.  Nous utilisons deux méthodes populaires pour isoler les charges de travail multi-utilisateurs: les machines virtuelles et les conteneurs.  Nous comprenons le meilleur des deux approches, simplifions autant que possible, testons sur une charge réelle élevée.  En conséquence, nous obtenons une isolation impénétrable des ordinateurs virtuels qui peuvent être lancés en centaines de millisecondes.  Cette solution fonctionne sous le capot d'AWS Lambda et Fargate, exécutant des millions de fonctions sans serveur et de conteneurs dans le cloud chaque seconde.  Il s'appelle Firecracker. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rm/ps/oo/rmpsoo1w1jptnyp2qwsaestydsq.png" width="400"></div><br><br>  Cet outil de microvirtualisation est disponible dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenSource</a> .  Si vos tâches nécessitent une isolation multi-locataire (enfin, par exemple, vous décidez de créer votre propre cloud), Firecracker est ce dont vous avez besoin. <br><br>  <strong>Vasily Pantyukhin</strong> , architecte d'Amazon Web Services, parle de l'architecture Firecracker, de la façon dont elle est utilisée par AWS Lambda, la compare avec des solutions alternatives et donne des exemples d'intégration. <br><br>  <em>Avis de non-responsabilité: tout ce qui suit est l'opinion personnelle de Vasily et cela peut ne pas coïncider avec la position d'Amazon Web Services.</em> <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/cfsICOzt6Do" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Caractéristiques naturelles des nuages ​​publics </h2><br><blockquote>  L'une des propriétés fondamentales des clouds publics est la multi-location. </blockquote><br>  Quelqu'un traduit ce terme par "multi-tenancy" ou "multi-user environment".  Mais de mon point de vue, cela ne reflète pas l'essence.  La multi-location signifie que différents utilisateurs et leurs charges vivent sur la même infrastructure physique, la partagent entre eux, mais ne se connaissent pas.  À partir des charges de travail multi-utilisateurs, la multi-location diffère en principe par des exigences plus strictes pour l'isolement des ressources et l'accès à celles-ci. <br><br><blockquote>  La surcharge est une autre propriété inhérente aux clouds publics. </blockquote><br>  Croyez-moi, dans le cas d'AWS, c'est une énorme charge!  La capture d'écran est un exemple de données réelles.  Je ne dirai pas pendant combien de temps et dans quelle région ces millions de "perroquets" ont été mesurés, mais ce n'est pas une sorte d'urgence, mais le mode de fonctionnement habituel pour nous. <br><br><img src="https://habrastorage.org/webt/up/dt/qs/updtqsp7dmtqk1czi5f2zuscbkq.png"><br><br>  Il s'avère une certaine contradiction.  D'une part, nous devons garder les utilisateurs aussi isolés que possible.  D'autre part, nous devons garantir un niveau très élevé de productivité et d'utilisation des ressources.  L'amélioration de l'un conduit souvent aux limites de l'autre.  Comment trouver un compromis, et encore mieux, pour obtenir le maximum sur tous les fronts? <br><br><h2>  Machines virtuelles ou conteneurs? </h2><br>  Il existe deux approches de base qui pourraient potentiellement aider.  Ce sont des machines virtuelles et des conteneurs.  Chacun a ses avantages et ses inconvénients. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dj/hl/ba/djhlbailazcjnfxycokcrv38a64.png" width="400"></div><br><br>  Le principal inconvénient des machines virtuelles est qu'elles prennent <strong>beaucoup de temps à charger</strong> .  Il faut généralement des dizaines de secondes, voire des minutes, pour démarrer la machine.  Mais les virtualoks ont une vertu: ils <strong>isolent les</strong> charges de <strong>béton les</strong> uns des autres.  Et des deux points de vue: <br><br><ul><li>  <strong>sécurité</strong> lorsqu'une machine virtuelle n'est pas en mesure d'accéder aux données d'une autre machine; </li><li>  <strong>ressources</strong> , lorsque j'ai commandé 8 Go de mémoire, j'espère que cette RAM sera la mienne et personne ne pourra réclamer la ressource pour laquelle j'ai payé. </li></ul><br>  Le contraire est le cas des conteneurs: ils sont légers et se <strong>chargent</strong> donc <strong>très rapidement.</strong>  Ils peuvent être facilement mis à l'échelle horizontalement.  Mais il y a une fonctionnalité avec laquelle nous, en tant que fournisseur de cloud public, ne pouvons pas vivre.  Ils utilisent un <strong>noyau partagé - le noyau du système d'exploitation est partagé entre tous les conteneurs</strong> . <br><br><img src="https://habrastorage.org/webt/pa/pz/hm/papzhmvppqzce7pxbezk8bp9owg.png"><br><br>  Peut-on dire que les conteneurs ne sont pas sûrs?  Non, même s'il existe de graves vulnérabilités. <br><br><blockquote>  Je pense qu'aujourd'hui un conteneur correctement «soudé» offre un niveau de sécurité suffisant. </blockquote><br>  Le problème est différent - un noyau partagé ne garantit pas fondamentalement qu'à l'avenir, des vulnérabilités n'apparaissent pas qui rompent l'isolement des locataires.  Le cloud public ne peut pas se le permettre, même en théorie. <br><br>  Il y a encore une autre contradiction et une solution doit être recherchée.  Le moyen le plus simple est de tirer le meilleur parti de maman - une machine virtuelle et de papa - d'un conteneur, de traverser et d'obtenir quelque chose de <strong>convergent</strong> .  En fait, nous l'avons fait.  Il s'est avéré que Firecracker. <br><br>  Firecracker est déjà en production.  Dans la même charge élevée de services critiques, par exemple, AWS Lambda (fonctions sans serveur) et AWS Fargate (conteneurs sans serveur). <br><br><h3>  Problèmes de l'ancien AWS Lambda </h3><br>  AWS Lambda est un service de fonctionnalités sans serveur.  Nous prenons la fonction en Java, Go, Python ou un autre langage, nous la jetons dans Lambda, et elle est exécutée comme par magie.  Il n'est pas nécessaire d'allouer et de gérer les ressources.  Comment cela a-t-il été mis en œuvre auparavant? <br><br><img src="https://habrastorage.org/webt/ou/ck/-s/ouck-sm6pjv4ul6t13dwlefxtry.png"><br><br>  Pour chaque compte AWS, une ou plusieurs machines virtuelles EC2 distinctes ont été allouées pour isoler les fonctions appartenant à différents locataires.  Une telle machine virtuelle consomme des ressources, même lorsqu'elle ne fait rien.  Supposons que nous exécutons une fonction toutes les 10 minutes et qu'elle s'exécute en 200 ms comme une Lambda ordinaire.  Il s'avère qu'en une heure la machine EC2 n'est utilisée que quelques secondes.  De plus, même à l'exécution, il ne consomme pas toutes les ressources disponibles - élimination sous la plinthe.  C'est furieusement non rentable. <br><br><img src="https://habrastorage.org/webt/jy/lo/0q/jylo0qlzudppsa5042qv858mfya.png"><br><br><h3>  Comment avez-vous résolu le problème du recyclage? </h3><br>  Développé à partir de zéro leur propre solution Firecracker.  Cela ressort clairement du titre du rapport :) <br><br>  Pour commencer à développer un nouveau produit, vous avez besoin d'une tâche technique.  Il contient beaucoup de texte, mais si vous sélectionnez uniquement la signification, vous obtenez ce qui suit. <br><br><ul><li>  <strong>Propulsé par KVM en</strong> tant qu'hyperviseur.  Quiconque travaille avec AWS sait que nous avons deux hyperviseurs préférés.  Les machines virtuelles héritées s'exécutent sur Xen.  Depuis fin 2017, KVM vit sous le capot de toutes les voitures. </li><li>  <strong>Cela démarre le plus rapidement possible.</strong>  Sur le matériel de référence, l'exigence était une charge complète du microvirtuel en 125 ms. </li><li>  <strong>Frais généraux de virtualisation minimum</strong> .  Dans l'architecture de référence, une seule machine micro-virtuelle Firecracker ne consomme en outre que 5 Mo de mémoire. </li><li>  <strong>La possibilité du départ le plus dense</strong> .  Paramètres de conception - pleine charge de 5 microvirtuels par cœur par seconde.  Cette exigence est fondamentale pour des services tels qu'AWS Lambda.  Les fonctions doivent décoller, s'entraîner et mourir rapidement, libérant des ressources pour la suivante. </li><li>  <strong>La possibilité de réabonnement</strong> .  C'est une opportunité - il n'est pas nécessaire de l'utiliser.  En fait, il s'agit de l'allocation de ressources virtuelles dans une plus large mesure qu'elles ne sont physiquement disponibles.  Cela signifie que le serveur dispose de 16 Go de RAM et que vous exécutez simultanément 4 machines virtuelles sur celui-ci, chacun étant sûr qu'il dispose de 8 Go de mémoire. </li></ul><br><h3>  AWS Lambda avec pétard sous le capot </h3><br>  Qu'est-ce qui a changé dans la nouvelle version d'AWS Lambda?  Du point de vue de l'utilisateur final, rien n'a changé.  La migration vers une architecture mise à jour en production était totalement transparente et invisible pour les consommateurs.  Les fonctionnalités Lambda sont de courte durée - c'était facile à faire. <br><br>  À quoi ressemble l'architecture moderne? <br><br><blockquote>  Au niveau le plus bas, il ne s'agit plus maintenant d'une machine virtuelle, mais d'un bare-metal physique. </blockquote><br>  Ces serveurs permettent d'utiliser pleinement toutes les fonctions du processeur, par exemple Intel VT.  Cela offre des avantages supplémentaires lors de l'utilisation de la virtualisation à des niveaux supérieurs. <br><br><img src="https://habrastorage.org/webt/rg/i6/s3/rgi6s36v7vgfuc2onnb-cuahbui.png"><br><br>  Au sommet de la pièce de fer se trouve le <strong>système</strong> d' <strong>exploitation hôte</strong> avec le module KVM dans le noyau.  <strong>Les</strong> microvirtuels de <strong>pétard</strong> avec leurs propres <strong>OS invités</strong> sont lancés ci-dessus.  Eh bien, ils ont déjà implémenté des composants du service AWS Lambda lui-même. <br><br>  Auparavant, pour chaque client utilisant les fonctionnalités Lambda, nous allouions des machines virtuelles EC2 distinctes à faible utilisation.  La nouvelle approche vous permet d'exécuter un microvirtuel léger uniquement lorsque vous en avez vraiment besoin.  Isoler les ressources Firecracker les unes des autres nous permet de le faire sur un matériel commun avec une densité maximale.  L'utilisation des ressources s'est fondamentalement améliorée. <br><br><h2>  Qu'y a-t-il dans la boîte? </h2><br>  J'ai promis une anboxing, alors passons en revue les principaux composants de Firecracker, considérons chacun d'eux séparément, puis assemblons le tout. <br><br><img src="https://habrastorage.org/webt/o_/by/mq/o_bymqjtw5d6aomlwpmfa7grqgk.jpeg"><br><br><h3>  Principes de conception </h3><br>  Lorsque nous avons commencé à discuter du développement de Firecracker, nous avons convenu d'adhérer à deux principes. <br><br>  <strong>Débarrassez-vous de tout ce qui n'est pas nécessaire.</strong>  Pourquoi les machines virtuelles classiques se chargent-elles lentement?  En particulier, car le code est surchargé.  Ils doivent prendre en charge un grand nombre d'appareils hérités.  Mais pourquoi émuler un appareil que personne d'autre n'utilisait il y a 10 ans?  Il n'est donc pas nécessaire de se débarrasser de tout ce qui est superflu.  Nous résolvons une tâche étroite spécifique et toute fonctionnalité qui ne permet pas de résoudre ce problème est considérée comme inutile. <br><br><blockquote>  Débarrassez-vous de tout ce qui est superflu et concentrez-vous sur une tâche. </blockquote><br>  <strong>Simplifiez ce qui reste.</strong>  Même ce qui reste devrait être aussi simple que possible. <br><br><h3>  Sur quoi ont-ils écrit? </h3><br>  Firecracker est écrit en rouille tendance parce que: <br><br><ul><li>  il vous permet d'écrire du <strong>code</strong> plus <strong>sécurisé</strong> , notamment en termes de mémoire; </li><li>  <strong>Les performances</strong> et les frais généraux sont comparables au C ++ moderne; </li><li>  La rouille <strong>est utilisée depuis longtemps,</strong> depuis 2015, elle a écrit de nombreuses solutions intéressantes pour les charges élevées. </li></ul><br><h3>  Le fer </h3><br>  Je le répète - Firecracker nécessite une installation sur du vrai matériel.  Comme configuration de référence, la machine en métal nu i3.metal a été choisie. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rg/to/nh/rgtonh5b1jbhgpzizky2wc6bsfk.png" width="400"></div><br>  <em>Remarque: le rapport était au début d'avril 2019. À cette époque, seule la plate-forme Intel était prise en charge.</em>  <em>En mai, ils ont ajouté la prise en charge alpha d'AMD et en juin ARM.</em>  <em>AMD peut être légèrement moins cher qu'Intel, et le support ARM offre des opportunités intéressantes pour travailler avec l'IoT multi-locataire.</em> <br><br>  Si vous commandez une i3.metal ou une autre machine à métaux nus dans AWS, alors pour les expériences, ce sera une configuration trop puissante et coûteuse.  Par conséquent, si vous décidez d'installer Firecracker sur eux, n'oubliez pas de payer ces machines après les expériences.  Sinon, un score décent viendra à la fin du mois. <br><br>  Y a-t-il une option moins chère?  Oui, vous pouvez démarrer Firecracker dans un environnement virtuel.  Mais plus dans AWS - nous ne prenons pas en charge la virtualisation imbriquée sur EC2.  Mais vous pouvez le faire dans GCP, Azure, DigitalOcean ou utiliser Proxmox, Parallels, VMware Fusion.  Tout fonctionnera si vous respectez les exigences, en particulier, selon la version du noyau de l'OS invité. <br><br><h3>  Le noyau </h3><br><blockquote>  L'élément fondamental de la solution est le module du noyau KVM. </blockquote><br>  Juste au cas où, je vais décrire comme une digression ce qu'est KVM.  Ce n'est pas tout l'hyperviseur, mais seulement une partie de celui-ci.  Ses principales tâches consistent à <strong>configurer un processeur virtuel</strong> (vCPU) et à <strong>démarrer une machine virtuelle</strong> . <br><br><img src="https://habrastorage.org/webt/gp/3l/ee/gp3leep27-zq3yzx9fiiho15pkm.png"><br><br>  Mais cela ne suffit pas pour un travail à part entière.  En plus du processeur, certains autres périphériques sont nécessaires.  Leur émulation se produit dans l'espace utilisateur. <br><br><h3>  VMM </h3><br>  Pour qu'au moins les périphériques de base apparaissent, vous avez besoin d'un autre composant - Virtual Machine Manager (VMM).  Avant Firecracker, l'option VMM principale était QEMU. <br><br><img src="https://habrastorage.org/webt/kg/s8/kr/kgs8krmluije10ql6x6vtch7f9g.png"><br><br>  Nous avons sérieusement envisagé la possibilité d'utiliser QEMU, mais avons décidé de développer notre propre «vélo».  Il y avait plusieurs raisons à cela. <br><br>  <strong>Gestion du développement</strong> .  QEMU est un grand produit mature avec plus d'un million de lignes de code.  Pour apporter des modifications, vous devez afficher trop de codes source.  Beaucoup de gens participent au développement et à la prise de décision sur le développement. <br><br>  <strong>La sécurité</strong>  QEMU peut émuler de nombreux appareils.  C'est pourquoi il a une surface d'attaque assez importante.  Notre tâche est de faire un microvirtuel.  D'un point de vue sécuritaire, il faut minimiser la surface d'attaque. <br><br>  <strong>La nécessité d'implémenter de nouvelles fonctionnalités.</strong>  QEMU a un bon code.  Il s'agit d'un produit mature dans lequel tous les bugs évidents sont déjà détectés.  Mais dans sa forme actuelle, la fonctionnalité QEMU ne nous convenait toujours pas - nous devions en ajouter beaucoup.  De ce point de vue, le nouveau code dans QEMU et dans le nouveau produit aurait la même qualité.  Par conséquent, une victoire spéciale ne fonctionnerait pas. <br><br><h3>  Appareils </h3><br>  Firecracker implémente VMM, qui est utilisé pour émuler des appareils.  Nous émulons les appareils suivants: <br><br><ul><li>  <strong>La console</strong>  Une chose utile et nécessaire, même si elle peut être désactivée. </li><li>  <strong>Clavier</strong>  Nous avons créé un clavier délicat - avec un seul bouton «Réinitialiser».  Nous ne faisons tout simplement pas confiance au logiciel «Reset» de ces systèmes d'exploitation qui pourraient potentiellement fonctionner dans Firecracker.  Par conséquent, ils ont fait du fer. </li><li>  <strong>Pilotes Virtio pour disque et réseau</strong> .  Virtio est un appareil très primitif.  En substance, il s'agit d'un "tampon en anneau".  Le système invité a écrit quelque chose dans le tampon, a cliqué sur l'appel et le système hôte a lu les données de ce tampon dans un fichier. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/av/hw/pvavhwc_g42zvrjrg7ftiqmcfda.png" width="500"></div><br><br>  Dans certains cas, par exemple, pour l'intégration avec des conteneurs, nous avons toujours besoin d'un périphérique réseau qui représenterait les fonctionnalités de base d'une carte réseau standard.  Virtio ne rentre pas ici, trop simple.  Par conséquent, pour le réseau, nous utilisons un autre appareil - <strong>Vsock</strong> . <br><br>  Eh bien, nous devons également pouvoir contrôler la consommation des ressources.  Le <strong>limiteur de débit en</strong> est responsable. <br><br>  Il y a des appareils.  Mais comment gérer et configurer les microvirtuels?  L'API de gestion nous aidera ici. <br><br><h3>  La gestion </h3><br>  Amazon a plusieurs principes fondamentaux incassables.  L'un d'eux est que tous les services communiquent entre eux uniquement via l'API.  Peu importe qu'il s'agisse de services externes que vous utilisez en tant qu'utilisateur ou de nos services internes.  Il n’arrive pas qu’un service accède directement à la base de données d’un autre service - il est interdit et punissable.  Le thread de l'API Firecracker est juste utilisé pour accéder aux paramètres et aux fonctionnalités des microvirtuels via l'API REST. <br><br><img src="https://habrastorage.org/webt/1s/qj/bt/1sqjbtijgutp6qfwscgu_vnq1va.png"><br><br>  Nous adhérons à la spécification Open API, vous pouvez donc utiliser Swagger. <br><br><h3>  Métadonnées </h3><br>  Il y a un tel mal - un codage dur.  C'est lorsque certaines données sont cousues directement dans le code, par exemple, le login et le mot de passe d'accès à une autre ressource.  Bien entendu, cela n'est pas autorisé.  Périodiquement, nous devons transférer certaines données à l'intérieur du microvirtuel.  Cela se fait via le <strong>service de métadonnées</strong> . <br><br><img src="https://habrastorage.org/webt/q_/ll/0m/q_ll0msnhoarxu6k5aag0ie2fug.png"><br><br>  Nous transmettons les informations requises via le socket au commerce de métadonnées IMDS.  Pour obtenir ces informations dans le microvirtuel, vous devez demander <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://169.254.169.254/latest/meta-data</a> à l'aide de l'API REST.  Les utilisateurs AWS connaissent déjà cette IP magique.  De la même manière, les microvirtuels peuvent obtenir des informations détaillées sur leur propre configuration. <br><br><h3>  Journaux </h3><br>  Il est impératif de pouvoir jeter des bûches de microvirtuels dans le monde extérieur avant sa mort.  Cela se fait via un <strong>FIFO</strong> Unix standard. <br><br><img src="https://habrastorage.org/webt/vr/p6/ib/vrp6ibzybyivbp68mi7wt1awobc.png"><br><br><h3>  Isolation supplémentaire </h3><br>  Le principal avantage de la machine virtuelle isolée.  Il semble que cela devrait suffire, mais nous sommes allés plus loin.  Au cas où, pour fonctionner en production, il est recommandé de poser une couche supplémentaire d'isolation appelée <strong>Jailer</strong> . <br><br><img src="https://habrastorage.org/webt/1o/_2/j6/1o_2j6t6y7_ae7h1cmzk36xqliq.png"><br><br>  Ce sont des précautions standard: <br><br><ul><li>  <strong>cgroups</strong> pour limiter les ressources; </li></ul><br><ul><li>  <strong>espace</strong> de <strong>noms</strong> pour isoler les processus; </li><li>  <strong>seccomp</strong> - un analogue du pare-feu pour les appels système; </li><li>  et, bien sûr, le <strong>chroot</strong> préféré de tout le monde <strong>.</strong> </li></ul><br><h2>  Intégration avec d'autres services </h2><br>  Existe-t-il des solutions prêtes à l'emploi basées sur Firecracker?  Bien sûr que oui. <br><br><h3>  OSV </h3><br>  Ce système d'exploitation est conçu pour exécuter une seule application.  Pour cette raison, elle a très simplement organisé le travail avec la mémoire et un planificateur.  Un système d'exploitation puissant et facile à gérer fonctionne désormais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">au-dessus de Firecracker</a> . <br><br><h3>  Containerd </h3><br>  Nous avons également fait l'intégration avec containerd.  Si vous travaillez déjà avec lui, vous avez besoin d'un minimum d'efforts pour lancer des conteneurs qui sont enveloppés dans Firecracker pour l'isolement. <br><br><img src="https://habrastorage.org/webt/xm/l3/1n/xml31nghhesczi3x2ul1vagz5xw.png"><br><br>  Au lieu de la cale habituelle, containerd se réfère à la cale de pétard.  Il gère déjà runc, via un agent installé à l'intérieur du microvirtuel.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vérifié, fonctionne</a> . <br><br><h3>  Conteneurs Kata </h3><br>  Lorsque nous avons annoncé Firecracker pour la première fois, l'une des questions les plus fréquemment posées par les clients était: <br><br>  <em>- Le mécanisme d'isolement des conteneurs a déjà été inventé - il s'agit des conteneurs Kata.</em>  <em>Pourquoi ne les avez-vous pas utilisés?</em>  <em>Pourquoi développer le vôtre?</em> <br>  <em>- Kata fonctionne avec QEMU, mais nous ne voulons pas travailler avec QEMU.</em>  <em>Par conséquent, nous avons décidé de cuisiner le nôtre.</em> <br><br>  Mais cela s'est avéré intéressant.  Les développeurs de Kata ont rencontré les développeurs de Firecracker et ont accepté de s'intégrer.  Parce que tout le monde voit cela comme un énorme avantage.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kata Containers v1.5</a> prend déjà en charge QEMU et Firecracker. <br><br>  Il s'avère que nous ne rivalisons pas, mais que nous nous complétons harmonieusement.  Dans Kubernetes avec la v1.12, vous pouvez définir runtimeClassName comme Kata FC ou Kata QEMU, et exécuter vos conteneurs dans l'isolement approprié. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yt/1-/bn/yt1-bnzwtgnbvhvkkr48gmhsj5o.png" width="500"></div><br><br>  Comment choisir l'isolation qui convient à votre application - Pétard ou QEMU?  Mon opinion personnelle est que ce qui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">importe est de savoir si</a> votre demande concerne des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">animaux de compagnie ou du bétail</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vs/le/yj/vsleyjeqq1hypjljyr3jcjcpsvc.png" width="300"></div><br><br>  Kata avec QEMU est une solution pour les animaux de compagnie.  QEMU est un grand système multifonctionnel.  Potentiellement, il offre plus d'options de support et de traitement pour vos animaux de compagnie préférés. <br><br>  Le pétard convient lorsque la charge est du bétail.  Dans le cas où votre application sans état a été initialement conçue pour une mise à l'échelle horizontale flexible et la défaillance d'un ou plusieurs conteneurs n'est pas critique.  Fournissant une isolation fiable, il vous permet de charger rapidement le nombre requis de nouveaux conteneurs pour remplacer ceux qui ont échoué. <br><br><h2>  Quel est le résultat? </h2><br>  Nous avons commencé avec des contradictions.  Il semble que résoudre la contradiction soit une approche «à la fois la nôtre et la vôtre», quelque chose entre les deux qui satisfera tout le monde.  Mais l'expérience montre qu'un compromis n'est pas nécessaire. <br><br>  Nous nous sommes fixé pour objectif de développer une nouvelle solution dans laquelle il n'y aura rien de superflu qui ne soit nécessaire pour résoudre une tâche étroite.  Il était également important de simplifier autant que possible tout ce que nous utilisons.  Je voudrais croire que nous n'avons pas obtenu de compromis, mais une solution solide qui vous permet de lancer rapidement et en masse des milliers de microvirtuels sans sacrifier leur isolement. <br><br>  Nous utilisons déjà Firecracker dans la production de plusieurs de nos services.  Le principal avantage que nous avons obtenu est l'amélioration de l'utilisation des services.  Cela a permis d'économiser considérablement.  Une partie de ces économies que nous avons partagées avec les clients.  Par exemple, après l'introduction de Firecracker, les prix des conteneurs sans serveur AWS Fargate en janvier 2019 ont chuté de 35 à 50%.  L'avantage est visible à l'œil nu, il ne fait donc aucun doute que nous continuerons à développer ce produit et à partager nos meilleures pratiques avec l'Open Source.  Le fait que Firecracker ait déjà commencé à s'intégrer à d'autres solutions indique un intérêt croissant de la part de la communauté. <br><br>  Si vous avez une idée ou un produit fini dans la description de laquelle il y a les mots «isolation multi-locataire» - c'est un indicateur clair de ce qu'il vaut la peine d'expérimenter avec des microvirtuels Firecracker. <br><br><blockquote>  Ce rapport illustre parfaitement le principe auquel nous essayons d'adhérer lors des conférences d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ontiko</a> - recevoir une expérience mondiale d'experts russophones.  Et le point n'est pas seulement dans une éventuelle barrière linguistique, mais dans la culture, nous sommes habitués à partager des détails techniques.  En novembre, Vasily <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">se produira</a> à nouveau à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HighLoad ++</a> , et il sera <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rejoint</a> , par exemple, par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Artemy Kolesnikov</a> de Facebook, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vittorio Cioe</a> d'Oracle et, bien sûr, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Petr Zaitsev</a> de Percona.  Nous aurons également des rapports en anglais, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">abonnez</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vous</a> à la newsletter - nous vous dirons quand de nouveaux seront ajoutés aux quarante rapports acceptés. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr464305/">https://habr.com/ru/post/fr464305/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr464291/index.html">Les 10 langages de programmation les plus influents des 50 dernières années et leurs créateurs</a></li>
<li><a href="../fr464293/index.html">Les crochets se remplacent-ils dans React Redux?</a></li>
<li><a href="../fr464295/index.html">Exemples d'utilisation de nouvelles fonctionnalités JavaScript</a></li>
<li><a href="../fr464299/index.html">0, 0, 1, 0, 2, 0, 2, 2, 1, 6, 0, 5, 0, 2, 6, 5, 4, 0, 5, 3, 0, 3, 2, 9, 0, 4, 9, 3, 6, 14, 0, 6, 3, 5, 15, 0, 5, 3, 5 ...</a></li>
<li><a href="../fr464303/index.html">Données de séries chronologiques dans un SGBD relationnel. Extensions TimescaleDB et PipelineDB pour PostgreSQL</a></li>
<li><a href="../fr464307/index.html">Test d'intégration de microservices sur Scala</a></li>
<li><a href="../fr464309/index.html">Bouton d'appel bricolage. Raspberry Pi, MajorDoMo, Freeswitch et Linphonec</a></li>
<li><a href="../fr464315/index.html">Le film dans lequel il y avait de la terre. Recherche sur Yandex et bref historique de la recherche par sens</a></li>
<li><a href="../fr464317/index.html">Projet Konbanwa</a></li>
<li><a href="../fr464325/index.html">Comment Scrumban unit le meilleur des méthodologies Kanban et Scrum</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
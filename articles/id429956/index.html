<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ§ğŸ¿ ğŸˆ ğŸ§›ğŸ» Integrasi berkelanjutan di Yandex. Bagian 2 ğŸ’™ ğŸ¥˜ âœ³ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pada artikel sebelumnya , kita berbicara tentang mentransfer pengembangan ke repositori tunggal dengan pendekatan berbasis trunk untuk pengembangan, d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Integrasi berkelanjutan di Yandex. Bagian 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/429956/"><p>  Pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel</a> sebelumnya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">,</a> kita berbicara tentang mentransfer pengembangan ke repositori tunggal dengan pendekatan berbasis trunk untuk pengembangan, dengan sistem terpadu untuk perakitan, pengujian, penyebaran, dan pemantauan, tentang tugas apa yang harus diselesaikan sistem integrasi berkesinambungan untuk bekerja secara efektif dalam kondisi seperti itu. </p><br><p>  Hari ini kami akan memberi tahu pembaca Habr tentang perangkat sistem integrasi berkelanjutan. </p><br><p><img src="https://habrastorage.org/webt/wb/mt/xc/wbmtxcvurtd6cdv1aomjrtcyfw8.png" alt="gambar"></p><br><p>  Sistem integrasi berkelanjutan harus bekerja dengan andal dan cepat.  Sistem harus merespons dengan cepat peristiwa yang masuk dan tidak boleh menyebabkan penundaan tambahan dalam proses memberikan hasil uji coba kepada pengguna.  Hasil perakitan dan pengujian harus dikirimkan kepada pengguna secara real time. </p><a name="habracut"></a><br><p>  Sistem integrasi berkelanjutan adalah sistem pemrosesan data streaming dengan penundaan minimal. </p><br><p>  Setelah mengirimkan semua hasil pada tahap tertentu (konfigurasi, build, style, tes kecil, tes menengah, dll.), Sistem build memberi sinyal ini ke sistem integrasi berkelanjutan ("menutup" panggung), dan pengguna melihat bahwa untuk pemeriksaan ini dan Pada tahap ini semua hasil diketahui.  Setiap tahap ditutup secara independen.  Pengguna menerima sinyal yang berguna lebih cepat.  Setelah menutup semua tahapan, cek dianggap selesai. </p><br><p>  Untuk mengimplementasikan sistem, kami memilih arsitektur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kappa</a> .  Sistem ini terdiri dari 2 subsistem: </p><br><ul><li>  Acara dan pemrosesan data berlangsung dalam sirkuit waktu nyata.  Setiap data input diperlakukan sebagai aliran data (stream).  Pertama, peristiwa dicatat dalam aliran dan baru kemudian mereka diproses. </li><li>  Hasil pemrosesan data terus ditulis ke dalam basis data, di mana panggilan melalui API kemudian pergi.  Dalam arsitektur Kappa, ini disebut layer penyajian. </li></ul><br><p>  Semua permintaan untuk modifikasi data harus melalui sirkuit realtime, karena di sana Anda selalu perlu memiliki kondisi sistem saat ini.  Permintaan baca hanya pergi ke database. </p><br><img src="https://habrastorage.org/webt/fb/bu/ps/fbbups7bcp0zgwvigxv5un9reek.png"><br><br><p>  Jika memungkinkan, kami mengikuti aturan append-only.  Tidak ada modifikasi atau penghapusan objek, dengan pengecualian menghapus data lama yang tidak perlu. </p><br><p>  Lebih dari 2 Tb data mentah melewati layanan per hari. </p><br><p>  Keuntungan: </p><br><ul><li>  Streaming berisi semua acara dan pesan.  Kita selalu dapat memahami apa dan kapan terjadi.  Stream dapat dianggap sebagai log besar. </li><li>  Efisiensi tinggi dan overhead minimal.  Ternyata sistem yang sepenuhnya berorientasi pada acara, tanpa kehilangan polling.  Tidak ada acara - kami tidak melakukan sesuatu yang ekstra. </li><li>  Kode aplikasi praktis tidak berurusan dengan primitif sinkronisasi ulir dan memori yang dibagi di antara utas.  Ini membuat sistem lebih andal. </li><li>  Prosesor terisolasi dengan baik satu sama lain, karena  jangan berinteraksi langsung, hanya melalui stream.  Cakupan tes yang baik dapat disediakan. </li></ul><br><p>  Tetapi pemrosesan data streaming tidak begitu sederhana: </p><br><ul><li> Pemahaman yang baik tentang model komputasi diperlukan.  Anda harus memikirkan kembali algoritma pemrosesan data yang ada.  Tidak semua algoritma langsung jatuh ke model aliran dan Anda harus menghancurkan kepala Anda sedikit. </li><li>  Penting untuk memastikan bahwa urutan penerimaan dan pemrosesan acara dipertahankan. </li><li>  Anda harus dapat menangani acara yang saling terkait, yaitu  memiliki akses cepat ke semua data yang diperlukan saat memproses pesan baru. </li><li>  Anda juga harus bisa menangani acara duplikat. </li></ul><br><h3 id="potokovaya-obrabotka-dannyh-stream-processing">  Pemrosesan aliran </h3><br><p>  Saat mengerjakan proyek, pustaka Stream Processor ditulis, yang membantu kami untuk dengan cepat mengimplementasikan dan meluncurkan algoritma pemrosesan data streaming dalam produksi. </p><br><p>  Stream Processor adalah perpustakaan untuk membangun sistem pemrosesan data streaming.  Aliran adalah urutan data (pesan) yang berpotensi tak berujung ke mana hanya menambahkan pesan baru dimungkinkan, pesan yang sudah direkam tidak diubah atau dihapus dari aliran.  Konverter dari satu aliran ke yang lain (pemroses aliran) secara fungsional terdiri dari tiga bagian: penyedia pesan masuk, yang biasanya membaca pesan dari satu aliran atau lebih dan menempatkannya dalam antrian pemrosesan, pemroses pesan yang mengubah pesan yang masuk menjadi yang keluar dan menempatkannya dalam antrian ke catatan, dan penulis, di mana pesan keluar yang dikelompokkan dalam jendela waktu jatuh ke aliran output.  Pesan data yang dihasilkan oleh satu prosesor aliran dapat digunakan oleh orang lain nanti.  Dengan demikian, stream dan prosesor membentuk grafik berarah di mana loop dimungkinkan, khususnya, prosesor aliran bahkan dapat menghasilkan pesan dalam aliran yang sama dari tempat ia menerima data. </p><br><p>  Dijamin bahwa setiap pesan dari aliran input akan diproses oleh setiap prosesor yang terkait dengannya setidaknya satu kali (semantik setidaknya satu kali).  Juga dijamin bahwa semua pesan akan diproses sesuai urutan kedatangannya di aliran ini.  Untuk melakukan ini, stream prosesor didistribusikan ke semua node layanan yang bekerja, sehingga pada satu waktu tidak lebih dari satu contoh dari setiap prosesor yang terdaftar berfungsi. </p><br><p>  Memproses peristiwa yang saling terkait adalah salah satu masalah utama dalam membangun sistem untuk streaming pemrosesan data.  Sebagai aturan, saat streaming pesan, stream processor secara bertahap membuat status tertentu yang valid pada saat pesan saat ini diproses.  Objek keadaan seperti itu biasanya dikaitkan tidak dengan keseluruhan aliran secara keseluruhan, tetapi dengan bagian pesan tertentu, yang ditentukan oleh nilai kunci dalam aliran ini.  Penyimpanan kekayaan yang efisien adalah kunci keberhasilan.  Saat memproses pesan berikutnya, penting bagi prosesor untuk dapat dengan cepat mendapatkan status ini dan, berdasarkan itu dan pesan saat ini, menghasilkan pesan keluar.  Objek keadaan ini dapat diakses oleh prosesor di L1 (tolong jangan bingung dengan cache CPU) LRU cache, yang terletak di memori.  Dalam hal tidak ada keadaan dalam cache L1, itu dikembalikan dari cache L2 yang terletak di penyimpanan yang sama di mana stream disimpan dan di mana ia disimpan secara berkala selama operasi prosesor.  Jika tidak ada keadaan dalam cache L2, maka itu dikembalikan dari pesan aliran asli, seolah-olah prosesor telah memproses semua pesan asli yang terkait dengan kunci pesan saat ini.  Teknik caching juga memungkinkan Anda untuk menangani masalah latensi penyimpanan yang tinggi, karena pemrosesan sekuensial tidak bergantung pada kinerja server, tetapi pada keterlambatan permintaan dan respons saat berkomunikasi dengan gudang data. </p><br><img width="400" src="https://habrastorage.org/webt/_o/pk/sj/_opksjvyut5cirxrnbjerswkt78.png"><br><br><p>  Untuk secara efektif menyimpan data dalam cache L1 dan data pesan dalam memori, selain struktur hemat memori, kami menggunakan kumpulan objek yang memungkinkan Anda untuk hanya memiliki satu salinan objek (atau bahkan bagiannya) dalam memori.  Teknik ini sudah digunakan di JDK untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">string string interning</a> dan juga meluas ke jenis objek lainnya, yang harus tetap. </p><br><p>  Untuk penyimpanan data yang ringkas dalam penyimpanan arus, beberapa data dinormalisasi sebelum menulis ke aliran, mis.  berubah menjadi angka.  Algoritma kompresi efektif kemudian dapat diterapkan pada angka (pengidentifikasi objek).  Bilangan diurutkan, delta dihitung, kemudian enkode dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ZigZag Enkode</a> dan kemudian kompresi oleh pengarsipan.  Normalisasi bukan teknik yang sangat standar untuk streaming sistem pemrosesan data.  Tetapi teknik kompresi ini sangat efektif dan jumlah data dalam aliran paling banyak berkurang sekitar 1.000 kali. </p><br><img width="600" src="https://habrastorage.org/getpro/habr/post_images/b1b/6f4/fa9/b1b6f4fa9d551a96fd4069b44435354f.png"><br><br><p>  Untuk setiap aliran dan prosesor, kami melacak siklus hidup pemrosesan pesan: tampilan pesan baru di aliran input, ukuran antrian pesan yang belum diproses, ukuran antrian untuk menulis ke aliran yang dihasilkan, waktu pemrosesan pesan, dan distribusi waktu menurut tahapan pemrosesan pesan: </p><br><img src="https://habrastorage.org/webt/jg/0q/rp/jg0qrpqbojreaugzrf66cikffwa.png"><br><br><h3 id="hranilische-dannyh">  Gudang data </h3><br><p>  Hasil pemrosesan data streaming harus tersedia untuk pengguna sesegera mungkin.  Data yang diproses dari stream harus secara terus-menerus direkam dalam database, di mana Anda kemudian dapat pergi untuk data (misalnya, menunjukkan laporan dengan hasil tes, menunjukkan sejarah tes). </p><br><p>  Karakteristik data dan kueri yang disimpan. <br>  Sebagian besar data adalah uji coba.  Lebih dari sebulan, lebih dari 1,5 miliar bangunan dan pengujian diluncurkan.  Sejumlah besar informasi disimpan untuk setiap peluncuran: hasil dan jenis kesalahan, deskripsi singkat tentang kesalahan (snippet), beberapa tautan ke log, durasi pengujian, serangkaian nilai numerik, metrik, dalam format nama = nilai, dll.  Beberapa data ini - misalnya, metrik dan durasi - sangat sulit untuk dikompres, karena sebenarnya ini adalah nilai acak.  Bagian lain - misalnya, hasil, jenis kesalahan, log - dapat disimpan lebih efisien, karena hampir tidak berubah dalam pengujian yang sama dari menjalankan ke menjalankan. </p><br><p>  Sebelumnya, kami menggunakan MySQL untuk menyimpan data yang diproses.  Kami secara bertahap mulai bersandar pada kemampuan basis data: </p><br><ul><li>  Jumlah data yang diproses berlipat ganda setiap enam bulan. </li><li>  Kami hanya dapat menyimpan data selama 2 bulan terakhir, tetapi kami ingin menyimpan data selama setidaknya satu tahun. </li><li>  Masalah dengan kecepatan eksekusi beberapa pertanyaan berat (hampir analitis). </li><li>  Skema basis data yang rumit.  Banyak tabel (normalisasi), yang menyulitkan penulisan ke database.  Skema dasar sangat berbeda dari skema objek yang digunakan dalam rangkaian waktu nyata. </li><li>  Tidak mengalami shutdown server.  Kegagalan server atau shutdown pusat data yang terpisah dapat menyebabkan kegagalan sistem. </li><li>  Operasi yang cukup rumit. </li></ul><br><p>  Sebagai kandidat untuk gudang data baru, kami mempertimbangkan beberapa opsi: PostgreSQL, MongoDB dan beberapa solusi internal, termasuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ClickHouse</a> . </p><br><p>  Beberapa solusi tidak memungkinkan kami untuk menyimpan data kami lebih efisien daripada solusi berbasis MySQL yang lama.  Yang lain tidak mengizinkan implementasi kueri yang cepat dan kompleks (hampir analitis).  Misalnya, kami memiliki permintaan yang agak berat yang menunjukkan komit yang memengaruhi proyek tertentu (beberapa set tes).  Dalam semua kasus di mana kita tidak dapat menjalankan query SQL cepat, kita harus memaksa pengguna untuk menunggu lama atau melakukan beberapa perhitungan di muka dengan kehilangan fleksibilitas.  Jika Anda menghitung sesuatu terlebih dahulu, maka Anda perlu menulis lebih banyak kode dan pada saat yang sama kehilangan fleksibilitas - tidak ada cara untuk dengan cepat mengubah perilaku dan menceritakan apa pun.  Jauh lebih mudah dan lebih cepat untuk menulis kueri SQL yang akan mengembalikan data yang dibutuhkan pengguna dan dapat dengan cepat memodifikasinya jika Anda ingin mengubah perilaku sistem. </p><br><h3 id="clickhouse">  Clickhouse </h3><br><p>  Kami memilih <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ClickHouse</a> .  ClickHouse adalah sistem manajemen basis data kolom (DBMS) untuk pemrosesan kueri analitik online (OLAP). </p><br><p>  Beralih ke ClickHouse, kami sengaja meninggalkan beberapa peluang yang disediakan oleh DBMS lainnya, menerima lebih dari kompensasi yang layak untuk ini dalam bentuk pertanyaan analitis yang sangat cepat dan gudang data yang kompak. </p><br><p>  Dalam DBMS relasional, nilai yang terkait dengan satu baris disimpan secara fisik berdampingan.  Di ClickHouse, nilai-nilai dari berbagai kolom disimpan secara terpisah, dan data dari satu kolom disimpan bersama.  Urutan penyimpanan data ini memungkinkan Anda untuk memberikan kompresi data tingkat tinggi dengan pilihan kunci utama yang tepat.  Ini juga mempengaruhi skenario mana DBMS akan bekerja dengan baik.  ClickHouse berfungsi lebih baik dengan kueri, di mana sejumlah kecil kolom dibaca dan kueri menggunakan satu tabel besar dan sisanya dari tabel kecil.  Tetapi bahkan dalam permintaan non-analitik, ClickHouse dapat menunjukkan hasil yang baik. </p><br><p>  Data dalam tabel diurutkan berdasarkan kunci utama.  Penyortiran dilakukan di latar belakang.  Ini memungkinkan Anda untuk membuat indeks jarang volume kecil, yang memungkinkan Anda untuk dengan cepat menemukan data.  ClickHouse tidak memiliki indeks sekunder.  Sebenarnya, ada satu indeks sekunder - kunci partisi (ClickHouse memotong data partisi di mana kunci partisi ditentukan dalam permintaan).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Lebih detail</a> . </p><br><p>  Skema data dengan normalisasi tidak berfungsi, sebaliknya, lebih disukai untuk mendenormalisasi data tergantung pada permintaan untuk itu.  Lebih disukai untuk membuat tabel "lebar" dengan sejumlah besar kolom.  Item ini juga terkait dengan yang sebelumnya, karena tidak adanya indeks sekunder terkadang membuat salinan tabel menggunakan kunci primer yang berbeda. </p><br><p>  ClickHouse tidak memiliki UPDATE dan DELETE dalam arti klasik, tetapi ada kemungkinan meniru mereka. </p><br><p>  Data perlu dimasukkan dalam blok besar dan tidak terlalu sering (sekali setiap beberapa detik).  Pemuatan data baris demi baris secara virtual tidak beroperasi pada volume data nyata. </p><br><p>  ClickHouse tidak mendukung transaksi, sistem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">akhirnya</a> menjadi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">konsisten</a> . </p><br><p>  Namun demikian, beberapa fitur ClickHouse, mirip dengan DBMS lainnya, membuatnya lebih mudah untuk mentransfer sistem yang ada padanya. </p><br><ul><li>  ClickHouse menggunakan SQL, tetapi dengan sedikit perbedaan, berguna untuk kueri khas sistem OLAP.  Ada sistem yang kuat dari fungsi agregat, ALL / ANY JOIN, ekspresi lambda dalam fungsi dan ekstensi SQL lainnya yang memungkinkan Anda untuk menulis hampir semua kueri analitik. </li><li>  ClickHouse mendukung replikasi, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">rekaman</a> kuorum, membaca kuorum.  Menulis kuorum diperlukan untuk penyimpanan data yang andal: INSERT hanya berhasil jika ClickHouse mampu menulis data ke sejumlah replika tanpa kesalahan. </li></ul><br><p>  Anda dapat membaca lebih lanjut tentang fitur ClickHouse dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasi</a> . </p><br><h4 id="osobennosti-raboty-s-clickhouse">  Fitur bekerja dengan ClickHouse </h4><br><p>  Pilihan kunci primer dan kunci partisi. </p><br><p>  Bagaimana cara memilih <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kunci primer</a> dan kunci partisi?  Mungkin ini adalah pertanyaan pertama yang muncul saat membuat tabel baru.  Pilihan kunci primer dan kunci partisi biasanya ditentukan oleh kueri yang akan dilakukan pada data.  Pada saat yang sama, kueri yang menggunakan kedua kondisi berubah menjadi yang paling efektif: baik oleh kunci primer dan oleh kunci partisi. </p><br><p>  Dalam kasus kami, tabel utama adalah matriks untuk menjalankan tes.  Adalah logis untuk mengasumsikan bahwa dengan struktur data ini, kunci harus dipilih sehingga urutan memotong salah satu dari mereka berjalan dalam urutan meningkatkan nomor baris, dan urutan memotong yang lain - dalam urutan meningkatkan jumlah kolom. </p><br><p>  Penting juga untuk diingat bahwa pilihan kunci primer dapat secara dramatis mempengaruhi kekompakan penyimpanan data, karena nilai-nilai yang identik dalam memotong kunci utama di kolom lain hampir tidak memakan ruang dalam tabel.  Jadi, dalam kasus kami, misalnya, kondisi pengujian tidak banyak berubah dari komit ke komit.  Fakta ini pada dasarnya telah menentukan pilihan kunci utama - sepasang pengidentifikasi tes dan nomor komit.  Apalagi dalam urutan itu. </p><br><img width="600" src="https://habrastorage.org/webt/0t/gj/jo/0tgjjoefxhjgbxexx4gevfwte7y.png"><br><br><p>  Kunci partisi memiliki dua tujuan.  Di satu sisi, ini memungkinkan partisi menjadi "diarsipkan" sehingga mereka dapat dihapus secara permanen dari penyimpanan, karena data di dalamnya sudah usang.  Di sisi lain, kunci partisi adalah indeks sekunder, yang berarti memungkinkan Anda untuk mempercepat kueri jika ada ekspresi untuknya. </p><br><p>  Untuk matriks kami, memilih nomor komit sebagai kunci partisi tampaknya cukup alami.  Tetapi jika Anda menetapkan nilai revisi dalam ekspresi untuk kunci partisi, maka akan ada banyak partisi yang tidak masuk akal dalam tabel seperti itu, yang akan menyebabkan penurunan kinerja permintaan untuk itu.  Oleh karena itu, dalam ekspresi untuk kunci partisi, nilai revisi dapat dibagi menjadi sejumlah besar untuk mengurangi jumlah partisi, misalnya, PARTISI DENGAN intDiv (revisi, 2000).  Jumlah ini harus cukup besar sehingga jumlah partisi tidak melebihi nilai yang disarankan, sementara itu harus cukup kecil sehingga tidak banyak data jatuh ke satu partisi dan database tidak harus membaca terlalu banyak data. </p><br><p>  Bagaimana cara mengimplementasikan UPDATE dan DELETE? </p><br><p>  Dalam arti biasa, UPDATE dan DELETE tidak didukung di ClickHouse.  Namun, alih-alih UPDATE dan DELETE, Anda bisa menambahkan kolom dengan versi ke tabel dan menggunakan mesin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ReplacingMergeTree</a> khusus (menghapus catatan duplikat dengan nilai kunci utama yang sama).  Dalam beberapa kasus, versi secara alami akan hadir dalam tabel sejak awal: misalnya, jika kita ingin membuat tabel untuk kondisi pengujian saat ini, versi dalam tabel ini akan menjadi nomor komit. </p><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> current_tests ( test_id UInt64, <span class="hljs-keyword"><span class="hljs-keyword">value</span></span> Nullable(<span class="hljs-keyword"><span class="hljs-keyword">String</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">version</span></span> UInt64 ) <span class="hljs-keyword"><span class="hljs-keyword">ENGINE</span></span> = ReplacingMergeTree(<span class="hljs-keyword"><span class="hljs-keyword">version</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> test_id</code> </pre> <br><p>  Jika catatan diubah, kami menambahkan versi dengan nilai baru, dalam kasus penghapusan, dengan nilai NULL (atau beberapa nilai khusus lainnya yang tidak dapat ditemukan dalam data). </p><br><p>  Apa yang Anda capai dengan penyimpanan baru? </p><br><p>  Salah satu tujuan utama beralih ke ClickHouse adalah kemampuan untuk menyimpan riwayat pengujian selama periode waktu yang lama (beberapa tahun, atau setidaknya satu tahun dalam kasus terburuk).  Sudah pada tahap prototipe, menjadi jelas bahwa kita dapat menjelajahi SSD yang ada di server kami untuk menyimpan setidaknya tiga tahun sejarah.  Kueri analitik telah dipercepat secara signifikan, sekarang kami dapat mengekstraksi informasi yang jauh lebih berguna dari data kami.  Margin RPS telah meningkat.  Selain itu, nilai ini hampir secara linear diskalakan dengan penambahan server baru ke kluster ClickHouse.  Membuat gudang data baru untuk database ClickHouse hanyalah langkah yang nyaris tidak terlihat bagi pengguna akhir menuju tujuan yang lebih penting - menambahkan fitur baru, mempercepat dan menyederhanakan pengembangan, berkat kemampuan untuk menyimpan dan memproses sejumlah besar data. </p><br><h4 id="prihodite-k-nam">  Datanglah ke kami </h4><br><p>  Departemen kami terus berkembang.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kunjungi kami</a> jika Anda ingin mengerjakan tugas dan algoritma yang kompleks dan menarik.  Jika Anda memiliki pertanyaan, Anda dapat bertanya langsung kepada saya di PM. </p><br><h3 id="poleznye-ssylki">  Tautan yang bermanfaat </h3><br><p>  Pemrosesan aliran </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Log: Apa yang harus diketahui oleh setiap insinyur perangkat lunak tentang abstraksi pemersatu data waktu-nyata</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dunia di luar batch: Streaming 101</a> . </li><li>  Buku <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Merancang Aplikasi Intensif Data</a> - O'Reilly Media. </li></ul><br><p>  Arsitektur Kappa </p><br><ul><li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kappa-arsitektur</a> . </li></ul><br><p>  ClickHouse: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Yandex membuka ClickHouse</a> . </li><li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://clickhouse.yandex</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dokumentasi</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id429956/">https://habr.com/ru/post/id429956/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id429946/index.html">Kegilaan dan Keberhasilan Kode Basis Data Oracle</a></li>
<li><a href="../id429948/index.html">Mengapa manajer produk di fintech diperlukan</a></li>
<li><a href="../id429950/index.html">Bagaimana menjaga kebiasaan komunikasi yang sehat dari tim terpencil</a></li>
<li><a href="../id429952/index.html">Masa lalu, sekarang, dan masa depan Docker dan runtimes kontainer lainnya di Kubernetes</a></li>
<li><a href="../id429954/index.html">Programmer untuk bandar Irlandia</a></li>
<li><a href="../id429958/index.html">Lima Aturan Debugging Mudah untuk Pemula</a></li>
<li><a href="../id429960/index.html">10 alasan mengapa pelanggan berhenti berlangganan dari suatu produk</a></li>
<li><a href="../id429964/index.html">U> X> I> P ... atau "Bagaimana nama profesi bermain leapfrog"</a></li>
<li><a href="../id429966/index.html">Gambaran Umum Teknik Adaptasi Domain Jauh Dasar (Bagian 2)</a></li>
<li><a href="../id429968/index.html">Perusahaan kurir terbesar dari China mulai menggunakan "truk jagung" tak berawak untuk pengangkutan barang</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
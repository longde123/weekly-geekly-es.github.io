<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¤¸ğŸ¾ ğŸ‘¨ğŸ½â€ğŸ¤ ğŸ‘©ğŸ¼â€ğŸ¤â€ğŸ‘¨ğŸ¿ VotingClassifier in sÑikit-learn: Aufbau und Optimierung eines Ensembles von Klassifizierungsmodellen ğŸ–•ğŸ» ğŸˆ´ ğŸ˜„</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im Rahmen der Implementierung der groÃŸen Aufgabe der Stimmungsanalyse (Analyse von Bewertungen) habe ich beschlossen, einige Zeit der zusÃ¤tzlichen Unt...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>VotingClassifier in sÑikit-learn: Aufbau und Optimierung eines Ensembles von Klassifizierungsmodellen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/430280/"> Im Rahmen der Implementierung der groÃŸen Aufgabe der Stimmungsanalyse (Analyse von Bewertungen) habe ich beschlossen, einige Zeit der zusÃ¤tzlichen Untersuchung des separaten Elements zu widmen - indem ich den VotingClassifier aus dem Modul sklearn.ensemble als Werkzeug zum Aufbau eines Ensembles von Klassifizierungsmodellen und zur Verbesserung der endgÃ¼ltigen QualitÃ¤t von Vorhersagen verwendete.  Warum ist das wichtig und was sind die Nuancen? <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/pu/ka/uy/pukauyhbdf34xacms3hlnnm4jok.jpeg"><br><br>  Es kommt hÃ¤ufig vor, dass bei der LÃ¶sung des angewandten Problems der Datenanalyse nicht sofort (oder Ã¼berhaupt nicht offensichtlich) klar ist, welches Trainingsmodell am besten geeignet ist.  Eine LÃ¶sung kann darin bestehen, das beliebteste und / oder intuitiv am besten geeignete Modell basierend auf der Art der verfÃ¼gbaren Daten auszuwÃ¤hlen.  In diesem Fall werden die Parameter des ausgewÃ¤hlten Modells optimiert (z. B. Ã¼ber GridSearchCV) und in der Arbeit verwendet.  Ein anderer Ansatz kann darin bestehen, ein Ensemble von Modellen zu verwenden, wenn die Ergebnisse mehrerer von ihnen gleichzeitig an der Bildung des Endergebnisses beteiligt sind.  Ich mÃ¶chte gleich sagen, dass der Zweck des Artikels nicht darin besteht, die Vorteile der Verwendung eines Ensembles von Modellen oder die Prinzipien seiner Konstruktion zu beschreiben (dies finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ), sondern in einem separat angewandten Ansatz zur LÃ¶sung des Problems anhand eines bestimmten Beispiels und zur Analyse der Nuancen, die bei einer solchen LÃ¶sung auftreten. <br><br>  <u>Die Aussage des globalen Problems lautet wie folgt</u> : Nur <u>100</u> Bewertungen wurden auf Mobiltelefonen als Teststichprobe abgegeben, und wir benÃ¶tigen ein vorab geschultes Modell, das das beste Ergebnis bei diesen 100 Bewertungen zeigt - nÃ¤mlich festzustellen, ob die Bewertung positiv oder negativ ist.  Eine zusÃ¤tzliche Schwierigkeit, die sich aus den Bedingungen des Problems ergibt, ist das Fehlen einer Trainingsprobe.  Um diese Schwierigkeit mithilfe der Beautiful Soup-Bibliothek zu Ã¼berwinden, wurden 10.000 Bewertungen zu Mobiltelefonen und Bewertungen von einer der russischen Websites erfolgreich analysiert. <br><br>  Wir <i>Ã¼berspringen die Schritte des Parsens, der Datenvorverarbeitung und des Studierens ihrer ursprÃ¼nglichen Struktur</i> und gehen zu dem Moment Ã¼ber, in dem es Folgendes gibt: <br><br><ul><li>  Trainingsmuster, bestehend aus 10.000 telefonischen Bewertungen, jede Bewertung ist als binÃ¤r (positiv oder negativ) gekennzeichnet.  Markup fÃ¼r die Definition von Bewertungen mit Bewertungen 1-3 als negativ und Bewertungen 4-5 als positiv. </li><li>  Mit Count Vectorizer werden die Daten in einer Form dargestellt, die fÃ¼r das Training von Klassifikatormodellen geeignet ist </li></ul><br>  <u>Wie entscheiden Sie, welches Modell fÃ¼r Sie am besten geeignet ist?</u>  Wir haben nicht die MÃ¶glichkeit, Modelle manuell zu durchlaufen, weil  Ein Testmuster mit nur 100 Bewertungen birgt das groÃŸe Risiko, dass ein Modell einfach besser fÃ¼r dieses Testmuster geeignet ist. Wenn Sie es jedoch fÃ¼r ein zusÃ¤tzliches Muster verwenden, das vor uns verborgen ist, oder in einem â€Kampfâ€œ, ist das Ergebnis unterdurchschnittlich. <br><br>  Um dieses Problem zu lÃ¶sen <b>, verfÃ¼gt die Scikit-Lernbibliothek Ã¼ber ein VotingClassifier-Modul</b> , mit dem mehrere voneinander verschiedene Modelle des maschinellen Lernens verwendet und zu einem Klassifikator kombiniert werden kÃ¶nnen.  Dies verringert das Risiko einer Umschulung sowie eine falsche Interpretation der Ergebnisse eines bestimmten Modells.  <u>Das VotingClassifier-Modul wird mit dem folgenden Befehl importiert</u> : <br> <code>from sklearn.ensemble import VotingClassifier</code> <br> <br>  Praktische Details bei der Arbeit mit diesem Modul: <br><br>  1) Das erste und wichtigste ist, wie man eine einzelne genommene Vorhersage des kombinierten Klassifikators erhÃ¤lt, nachdem man Vorhersagen von jedem der darin enthaltenen Modelle erhalten hat.  Unter den VotingClassifier-Parametern gibt es einen <i>Abstimmungsparameter</i> mit zwei mÃ¶glichen Werten: 'hart' und 'weich'. <br><br>  1.1) Im ersten Fall entspricht die endgÃ¼ltige Antwort des gemeinsamen Klassifikators der â€Meinungâ€œ der Mehrheit seiner Mitglieder.  Ihr kombinierter Klassifikator verwendet beispielsweise Daten aus drei verschiedenen Modellen.  Zwei von ihnen sagen bei einer bestimmten Beobachtung die Antwort "positives Feedback" voraus, das dritte - "negatives Feedback".  FÃ¼r diese Beobachtung ist die endgÃ¼ltige Vorhersage daher "positives Feedback", da wir 2 - "fÃ¼r" und 1 "gegen" haben. <br><br>  1.2) Im zweiten Fall, d.h.  Bei Verwendung des "weichen" Werts des <i>Abstimmungsparameters</i> erfolgt fÃ¼r <u>jede</u> Klasse eine vollstÃ¤ndige "Abstimmung" und Gewichtung der Modellvorhersagen. Die endgÃ¼ltige Antwort des kombinierten Klassifikators ist also der Argmax der Summe der vorhergesagten Wahrscheinlichkeiten.  <b>WICHTIG!</b>  Um eine solche "Abstimmungs" -Methode verwenden zu kÃ¶nnen, muss <b>jeder</b> Klassifikator aus den in Ihrem Ensemble enthaltenen Klassifizierern die <b>Predict_proba ()</b> -Methode unterstÃ¼tzen, um eine quantitative SchÃ¤tzung der Wahrscheinlichkeit des Eintritts in jede der Klassen zu erhalten.  Bitte beachten Sie, dass nicht alle Klassifikatormodelle diese Methode unterstÃ¼tzen und dementsprechend im Rahmen von VotingClassifier verwendet werden kÃ¶nnen, wenn die Methode der gewichteten Wahrscheinlichkeiten (Soft Voting) verwendet wird. <br><br>  <u>Schauen wir uns ein Beispiel an</u> : Es gibt drei Klassifikatoren und zwei Klassen von Bewertungen: positiv und negativ.  Jeder Klassifikator gibt durch die Methode "dict_proba" einen bestimmten Wahrscheinlichkeitswert (p) an, mit dem eine bestimmte Beobachtung von ihm der Klasse 1 und dementsprechend mit der Wahrscheinlichkeit (1-p) der Klasse 2 zugeordnet wird.  Der kombinierte Klassifikator fÃ¼hrt nach Erhalt einer Antwort von jedem der Modelle die Gewichtung der erhaltenen SchÃ¤tzungen durch und gibt das erhaltene Endergebnis als <p><math> </math> $$ Anzeige $$ max (w1 * p1 + w2 * p1 + w3 * p1, w1 * p2 + w2 * p2 + w3 * p3) $$ Anzeige $$ </p>  Dabei sind w1, w2, w3 die Gewichte Ihrer im Ensemble enthaltenen Klassifikatoren, die standardmÃ¤ÃŸig gleiche Gewichte haben, und p1, p2 ist die Bewertung der ZugehÃ¶rigkeit zu Klasse 1 oder Klasse 2 von jedem von ihnen.  Bitte beachten Sie auch, dass die Gewichte von Klassifizierern bei Verwendung von Soft Vote mithilfe des Gewichtungsparameters geÃ¤ndert werden kÃ¶nnen, sodass der Modulaufruf folgendermaÃŸen aussehen sollte: <br>  <code>... = VotingClassifier(estimators=[('..', clf1), ('..', clf2), ('...', clf3)], voting='soft', weights=[*,*,*])</code> , wobei die Sternchen die erforderlichen Gewichte fÃ¼r jedes Modell angeben kÃ¶nnen. <br><br>  2) Die MÃ¶glichkeit, das Modul VotingClassifier und GridSearch <u>gleichzeitig zu</u> verwenden, um die Hyperparameter aller im Ensemble enthaltenen Klassifikatoren zu optimieren. <br><br>  Wenn Sie ein Ensemble verwenden mÃ¶chten und mÃ¶chten, dass die darin enthaltenen Modelle optimiert werden, kÃ¶nnen Sie GridSearch bereits fÃ¼r den einheitlichen Klassifikator verwenden.  Der folgende Code zeigt, wie Sie mit den darin enthaltenen Modellen (logistische Regression, naive Bayes, stochastischer Gradientenabstieg) arbeiten kÃ¶nnen, wÃ¤hrend Sie im Rahmen des einheitlichen Klassifikators (VotingClassifier) â€‹â€‹bleiben: <br><br><pre> <code class="plaintext hljs">clf1 = LogisticRegression() clf2 = MultinomialNB() clf3 = SGDClassifier(max_iter=1000, loss='log') eclf = VotingClassifier(estimators=[ ('lr', clf1), ('nb', clf2),('sgd', clf3)], voting='hard') #      (hard voting), . . 1.1 &lt;b&gt;params = {'lr__C' : [0.5,1,1.5], 'lr__class_weight': [None,'balanced'], 'nb__alpha' : [0.1,1,2], 'sgd__penalty' : ['l2', 'l1'], 'sgd__alpha': [0.0001,0.001,0.01]} &lt;/b&gt; #       ,  ,     grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1) grid = grid.fit(data_messages_vectorized, df_texts['Binary_Rate']) #    ,      5     </code> </pre><br>  Daher muss das ParameterwÃ¶rterbuch so eingestellt sein, dass Sie beim Zugriff Ã¼ber GridSearch bestimmen kÃ¶nnen, welcher Parameter im Modellensemble auf einen Parameter verweist, dessen Wert Sie optimieren mÃ¶chten. <br><br>  Das ist alles, was Sie wissen mÃ¼ssen, um das VotingClassifier-Tool vollstÃ¤ndig nutzen zu kÃ¶nnen, um ein Ensemble von Modellen zu erstellen und zu optimieren.  Schauen wir uns die Ergebnisse an: <br><br><pre> <code class="plaintext hljs"> print grid.best_params_ {'lr__class_weight': 'balanced', 'sgd__penalty': 'l1', 'nb__alpha': 1, 'lr__C': 1, 'sgd__alpha': 0.001}</code> </pre><br>  Wenn die optimalen Werte der Parameter gefunden wurden, mÃ¼ssen die Ergebnisse der Arbeit fÃ¼r das Ensemble von Klassifikatoren (VotingClassifier) â€‹â€‹mit den optimalen Parametern verglichen werden. Wir werden eine Kreuzvalidierung der Trainingsprobe durchfÃ¼hren und die Modelle mit den optimalen Parametern und dem daraus bestehenden Ensemble vergleichen: <br><br><pre> <code class="plaintext hljs">for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Naive Bayes', 'SGD', 'Ensemble_HardVoting']): scores = cross_val_score(clf, data_messages_vectorized, df_texts['Binary_Rate'], cv=3, scoring='accuracy') print("Accuracy: %0.2f (+/- %0.2f) [%s]" % (scores.mean(), scores.std(), label))</code> </pre><br>  Das Endergebnis: <br><br>  Genauigkeit: 0,75 (Â± 0,02) [Logistische Regression] <br>  Genauigkeit: 0,79 (Â± 0,02) [Naive Bayes] <br>  Genauigkeit: 0,79 (Â± 0,02) [SGD] <br>  Genauigkeit: 0,79 (Â± 0,02) [Ensemble_HardVoting] <br><br>  Wie Sie sehen kÃ¶nnen, zeigten sich die Modelle im Trainingsbeispiel etwas anders (bei Standardparametern war dieser Unterschied deutlicher).  DarÃ¼ber hinaus muss der Gesamtwert (gemÃ¤ÃŸ der Genauigkeitsmetrik) des Ensembles den besten Wert der darin enthaltenen Modelle nicht Ã¼berschreiten, weil  Das Ensemble ist eher ein stabileres Modell, das in der Lage ist, im Test-Set und im â€Kampfâ€œ ein Ã¤hnliches Ergebnis zu erzielen, was bedeutet, dass das Risiko einer Umschulung, Anpassung an das Trainingsset und anderer mit dem Training verbundener Problemklassifizierer verringert wird.  Viel GlÃ¼ck bei der LÃ¶sung der angewandten Probleme und vielen Dank fÃ¼r Ihre Aufmerksamkeit! <br><br>  PS Angesichts der Besonderheiten und VerÃ¶ffentlichungsregeln in der Sandbox kann ich keinen Link zu Github und dem Quellcode fÃ¼r die in diesem Artikel angegebene Analyse sowie Links zu Kaggle im Rahmen des InClass-Wettbewerbs bereitstellen, der ein Test-Set und Tools zum ÃœberprÃ¼fen von Modellen darauf bereitstellte.  Ich kann nur sagen, dass dieses Ensemble die Basislinie deutlich Ã¼bertroffen hat und seinen rechtmÃ¤ÃŸigen Platz in der Rangliste eingenommen hat, nachdem es nach einem Test-Set gesucht hat.  Ich hoffe in den folgenden Publikationen kann ich teilen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de430280/">https://habr.com/ru/post/de430280/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de430270/index.html">Testen Sie dies: Wie bestimmen wir, welche Tests bei Pull-Request-PrÃ¼fungen ausgefÃ¼hrt werden sollen?</a></li>
<li><a href="../de430272/index.html">"Monster in Spielen oder 15 cm sind genug, um anzugreifen"</a></li>
<li><a href="../de430274/index.html">7 weitere coole PC-Spiele zum Englischlernen</a></li>
<li><a href="../de430276/index.html">Der verheerende Fehler von AnfÃ¤ngern in Gamedev</a></li>
<li><a href="../de430278/index.html">Budapester Konferenz (29.-31. Oktober) Datenkrise</a></li>
<li><a href="../de430282/index.html">9 von 10 Personen stimmen zu, weniger fÃ¼r sinnvollere Arbeit zu verdienen</a></li>
<li><a href="../de430284/index.html">Die Zusammenfassung interessanter Materialien fÃ¼r den mobilen Entwickler # 275 (12. - 18. November)</a></li>
<li><a href="../de430286/index.html">Details zur chaotischen und dunklen Seite von Piratenspielen fÃ¼r Nintendo Switch</a></li>
<li><a href="../de430290/index.html">Ein Versuch, die vierte Iteration des SpaceX BFR-Projekts vorherzusagen</a></li>
<li><a href="../de430292/index.html">Electronic Frontier Foundation: Die Netzwerkleistung des US-Polizeikennzeichens betrÃ¤gt 0,5%</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
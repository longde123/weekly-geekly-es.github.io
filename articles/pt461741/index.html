<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòï üë®üèΩ‚Äç‚öñÔ∏è ü§≥ Cluster hier√°rquico de dados categ√≥ricos em R üë®üèæ‚Äçüè≠ üë®üèΩ‚Äçüè≠ üßöüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A tradu√ß√£o foi preparada para os alunos do curso "Applied Analytics on R" . 




 Esta foi minha primeira tentativa de agrupar clientes com base em da...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cluster hier√°rquico de dados categ√≥ricos em R</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/461741/">  <i>A tradu√ß√£o foi preparada para os alunos do curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"Applied Analytics on R"</a> .</i> <br><br><img src="https://habrastorage.org/webt/wq/q0/sp/wqq0sphqihtnsg1f8eor15ffkgi.png"><br><hr><br><br>  Esta foi minha primeira tentativa de agrupar clientes com base em dados reais e me proporcionou uma experi√™ncia valiosa.  Existem muitos artigos na Internet sobre clustering usando vari√°veis ‚Äã‚Äãnum√©ricas, mas encontrar solu√ß√µes para dados categ√≥ricos, o que √© um pouco mais dif√≠cil, n√£o era t√£o simples.  Os m√©todos de clustering para dados categ√≥ricos ainda est√£o em desenvolvimento e, em outro post, tentarei outro. <br><a name="habracut"></a><br>  Por outro lado, muitas pessoas pensam que o agrupamento de dados categ√≥ricos pode n√£o produzir resultados significativos - e isso √© parcialmente verdade (consulte a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">excelente discuss√£o sobre CrossValidated</a> ).  A certa altura, pensei: ‚ÄúO que estou fazendo?  Eles podem simplesmente ser divididos em coortes. ‚Äù  No entanto, a an√°lise de coorte tamb√©m nem sempre √© aconselh√°vel, especialmente com um n√∫mero significativo de vari√°veis ‚Äã‚Äãcateg√≥ricas com um grande n√∫mero de n√≠veis: voc√™ pode lidar facilmente com 5-7 coortes, mas se voc√™ tiver 22 vari√°veis ‚Äã‚Äãe cada uma tiver 5 n√≠veis (por exemplo, uma pesquisa de cliente com estimativas discretas 1 , 2, 3, 4 e 5), e voc√™ precisa entender quais grupos caracter√≠sticos de clientes voc√™ est√° lidando - voc√™ obter√° coortes 22x5.  Ningu√©m quer se preocupar com essa tarefa.  E aqui o agrupamento pode ajudar.  Portanto, nesta postagem, falarei sobre o que eu gostaria de saber assim que comecei a agrupar. <br><br>  O pr√≥prio processo de armazenamento em cluster consiste em tr√™s etapas: <br><br><ol><li>  Construir uma matriz de dissimilaridade √© sem d√∫vida a decis√£o mais importante no agrupamento.  Todas as etapas subsequentes ser√£o baseadas na matriz de dissimilaridade que voc√™ criou. </li><li>  A escolha do m√©todo de agrupamento. </li><li>  Avalia√ß√£o de cluster. </li></ol><br>  Este post ser√° um tipo de introdu√ß√£o que descreve os princ√≠pios b√°sicos do clustering e sua implementa√ß√£o no ambiente R. <br><br><h2>  Matriz de dissimilaridade </h2><br>  A base para o agrupamento ser√° a matriz de dissimilaridade, que em termos matem√°ticos descreve qu√£o diferentes os pontos no conjunto de dados s√£o (removidos) um do outro.  Permite combinar ainda mais nos grupos os pontos mais pr√≥ximos um do outro ou separar os mais distantes entre si - essa √© a principal id√©ia do agrupamento. <br><br>  Nesse est√°gio, as diferen√ßas entre os tipos de dados s√£o importantes, uma vez que a matriz de dissimilaridade √© baseada nas dist√¢ncias entre os pontos de dados individuais.  √â f√°cil imaginar as dist√¢ncias entre os pontos dos dados num√©ricos (um exemplo bem conhecido s√£o as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dist√¢ncias euclidianas</a> ), mas no caso de dados categ√≥ricos (fatores em R), tudo n√£o √© t√£o √≥bvio. <br><br>  Para construir uma matriz de dissimilaridade nesse caso, deve-se usar a chamada dist√¢ncia de Gover.  N√£o vou me aprofundar na parte matem√°tica desse conceito, simplesmente fornecerei links: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ali</a> .  Para isso, prefiro usar <code>daisy()</code> com a <code>metric = c("gower")</code> do pacote de <code>cluster</code> . <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#-----   -----# #    ,       ,     ,   ,    library(dplyr) #     set.seed(40) #     #    ;   data.frame()     #    ,   200   1  200 id.s &lt;- c(1:200) %&gt;% factor() budget.s &lt;- sample(c("small", "med", "large"), 200, replace = T) %&gt;% factor(levels=c("small", "med", "large"), ordered = TRUE) origins.s &lt;- sample(c("x", "y", "z"), 200, replace = T, prob = c(0.7, 0.15, 0.15)) area.s &lt;- sample(c("area1", "area2", "area3", "area4"), 200, replace = T, prob = c(0.3, 0.1, 0.5, 0.2)) source.s &lt;- sample(c("facebook", "email", "link", "app"), 200, replace = T, prob = c(0.1,0.2, 0.3, 0.4)) ##   ‚Äî      dow.s &lt;- sample(c("mon", "tue", "wed", "thu", "fri", "sat", "sun"), 200, replace = T, prob = c(0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2)) %&gt;% factor(levels=c("mon", "tue", "wed", "thu", "fri", "sat", "sun"), ordered = TRUE) #  dish.s &lt;- sample(c("delicious", "the one you don't like", "pizza"), 200, replace = T) #   data.frame()      synthetic.customers &lt;- data.frame(id.s, budget.s, origins.s, area.s, source.s, dow.s, dish.s) #-----   -----# library(cluster) #       #   : daisy(), diana(), clusplot() gower.dist &lt;- daisy(synthetic.customers[ ,2:7], metric = c("gower")) # class(gower.dist) ## , </span></span></code> </pre> <br>  A matriz de dissimilaridade est√° pronta.  Para 200 observa√ß√µes, ele √© constru√≠do rapidamente, mas pode exigir uma quantidade muito grande de computa√ß√£o se voc√™ estiver lidando com um grande conjunto de dados. <br><br>  Na pr√°tica, √© muito prov√°vel que voc√™ primeiro precise limpar o conjunto de dados, executar as transforma√ß√µes necess√°rias das linhas em fatores e rastrear os valores ausentes.  No meu caso, o conjunto de dados tamb√©m continha linhas de valores ausentes que foram agrupados maravilhosamente a cada vez, por isso parecia um tesouro - at√© que eu olhei para os valores (infelizmente!). <br><br><h2>  Algoritmos de cluster </h2><br>  Voc√™ j√° deve saber que o clustering √© <i>k-means e hier√°rquico</i> .  Neste post, focalizo o segundo m√©todo, j√° que √© mais flex√≠vel e permite v√°rias abordagens: voc√™ pode escolher o algoritmo de agrupamento <i>aglomerativo</i> (de baixo para cima) ou <i>divisional</i> (de cima para baixo). <br><br><img src="https://habrastorage.org/webt/nl/vp/u4/nlvpu4e8ykoh_nd_el_4i6plh8q.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Guia de programa√ß√£o do UC Business Analytics R</a></i> <br><br>  O agrupamento aglomerativo come√ßa com <code>n</code> agrupamentos, em que <code>n</code> √© o n√∫mero de observa√ß√µes: assume-se que cada um deles √© um agrupamento separado.  Em seguida, o algoritmo tenta encontrar e agrupar os pontos de dados mais semelhantes entre si - √© assim que a forma√ß√£o de cluster come√ßa. <br><br>  O agrupamento por divis√£o √© realizado da maneira oposta - assume-se inicialmente que todos os n pontos de dados que temos s√£o um cluster grande e, em seguida, os menos semelhantes s√£o divididos em grupos separados. <br><br>  Ao decidir qual desses m√©todos escolher, sempre faz sentido tentar todas as op√ß√µes, no entanto, em geral, o <i>clustering aglomerativo √© melhor para identificar pequenos agrupamentos e √© usado pela maioria dos programas de computador, e o agrupamento por divis√£o √© mais apropriado para identificar agrupamentos grandes</i> . <br><br>  Pessoalmente, antes de decidir qual m√©todo usar, prefiro olhar para os dendrogramas - uma representa√ß√£o gr√°fica do agrupamento.  Como voc√™ ver√° mais adiante, alguns dendrogramas s√£o bem equilibrados, enquanto outros s√£o muito ca√≥ticos. <br><br>  # A entrada principal para o c√≥digo abaixo √© a diferen√ßa (matriz de dist√¢ncia) <br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#             #            ‚Äî         ‚Äî    #------------  ------------# divisive.clust &lt;- diana(as.matrix(gower.dist), diss = TRUE, keep.diss = TRUE) plot(divisive.clust, main = "Divisive")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/54/mp/m1/54mpm19v8jkkpmj6usehxlgr5qk.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#------------   ------------# #      #         ‚Äî     ,      #    (complete linkages) aggl.clust.c &lt;- hclust(gower.dist, method = "complete") plot(aggl.clust.c, main = "Agglomerative, complete linkages")</span></span></code> </pre> <br><h2>  Avalia√ß√£o de qualidade de cluster </h2><br>  Nesse est√°gio, √© necess√°rio escolher entre diferentes algoritmos de armazenamento em cluster e um n√∫mero diferente de clusters.  Voc√™ pode usar diferentes m√©todos de avalia√ß√£o, sem esquecer de ser guiado pelo <b>senso comum</b> .  Eu destaquei essas palavras em negrito e it√°lico, porque a <b>import√¢ncia</b> da escolha √© <b>muito importante</b> - o n√∫mero de clusters e o m√©todo de dividir os dados em grupos devem ser pr√°ticos do ponto de vista pr√°tico.  O n√∫mero de combina√ß√µes de valores de vari√°veis ‚Äã‚Äãcateg√≥ricas √© finito (uma vez que s√£o discretos), mas nenhum detalhamento baseado nelas ser√° significativo.  Voc√™ tamb√©m pode n√£o querer ter muito poucos clusters - nesse caso, eles ser√£o muito generalizados.  No final, tudo depende do seu objetivo e das tarefas da an√°lise. <br><br>  Em geral, ao criar clusters, voc√™ est√° interessado em obter grupos de pontos de dados claramente definidos, para que a dist√¢ncia entre esses pontos dentro do cluster ( <i>ou compacta√ß√£o</i> ) seja m√≠nima e a dist√¢ncia entre grupos ( <i>separabilidade</i> ) seja a m√°xima poss√≠vel.  Isso √© f√°cil de entender intuitivamente: a dist√¢ncia entre os pontos √© uma medida de sua dissimilaridade, obtida com base na matriz de dissimilaridade.  Assim, a avalia√ß√£o da qualidade do agrupamento √© baseada na avalia√ß√£o da compacta√ß√£o e separabilidade. <br><br>  A seguir, demonstrarei duas abordagens e mostrarei que uma delas pode fornecer resultados sem sentido. <br><br><ul><li>  <i>M√©todo do cotovelo</i> : comece com ele se o fator mais importante para sua an√°lise for a compacta√ß√£o dos clusters, ou seja, a semelhan√ßa entre os grupos. </li><li>  <i>M√©todo de avalia√ß√£o de silhuetas</i> : O gr√°fico de <i>silhueta</i> usado como uma medida da consist√™ncia dos dados mostra o qu√£o perto cada ponto de um cluster est√° dos pontos nos clusters vizinhos. </li></ul><br>  Na pr√°tica, esses dois m√©todos geralmente oferecem resultados diferentes, o que pode levar a alguma confus√£o - a compacta√ß√£o m√°xima e a separa√ß√£o mais clara ser√£o alcan√ßadas com um n√∫mero diferente de clusters, de modo que o bom senso e a compreens√£o do que seus dados realmente significam desempenhar√£o um papel importante ao tomar uma decis√£o final. <br><br>  H√° tamb√©m v√°rias m√©tricas que voc√™ pode analisar.  Vou adicion√°-los diretamente ao c√≥digo. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#      ,        #      ,     ,   ‚Äî   #     ,      ,         ,   ,     library(fpc) cstats.table &lt;- function(dist, tree, k) { clust.assess &lt;- c("cluster.number","n","within.cluster.ss","average.within","average.between", "wb.ratio","dunn2","avg.silwidth") clust.size &lt;- c("cluster.size") stats.names &lt;- c() row.clust &lt;- c() output.stats &lt;- matrix(ncol = k, nrow = length(clust.assess)) cluster.sizes &lt;- matrix(ncol = k, nrow = k) for(i in c(1:k)){ row.clust[i] &lt;- paste("Cluster-", i, " size") } for(i in c(2:k)){ stats.names[i] &lt;- paste("Test", i-1) for(j in seq_along(clust.assess)){ output.stats[j, i] &lt;- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.assess])[j] } for(d in 1:k) { cluster.sizes[d, i] &lt;- unlist(cluster.stats(d = dist, clustering = cutree(tree, k = i))[clust.size])[d] dim(cluster.sizes[d, i]) &lt;- c(length(cluster.sizes[i]), 1) cluster.sizes[d, i] } } output.stats.df &lt;- data.frame(output.stats) cluster.sizes &lt;- data.frame(cluster.sizes) cluster.sizes[is.na(cluster.sizes)] &lt;- 0 rows.all &lt;- c(clust.assess, row.clust) # rownames(output.stats.df) &lt;- clust.assess output &lt;- rbind(output.stats.df, cluster.sizes)[ ,-1] colnames(output) &lt;- stats.names[2:k] rownames(output) &lt;- rows.all is.num &lt;- sapply(output, is.numeric) output[is.num] &lt;- lapply(output[is.num], round, 2) output } #     :      7 #     ,            stats.df.divisive &lt;- cstats.table(gower.dist, divisive.clust, 7) stats.df.divisive</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/r-/g_/ou/r-g_oukwyorhqnsls_cbg4c8spw.png"><br><br>  Portanto, o indicador average.within, que representa a dist√¢ncia m√©dia entre as observa√ß√µes nos clusters, diminui, assim como within.cluster.ss (a soma dos quadrados das dist√¢ncias entre as observa√ß√µes em um cluster).  A largura m√©dia da silhueta (avg.silwidth) n√£o muda de maneira t√£o inequ√≠voca; no entanto, um relacionamento inverso ainda pode ser percebido. <br>  Observe como os tamanhos de cluster s√£o desproporcionais.  Eu n√£o me apressaria a trabalhar com um n√∫mero incompar√°vel de observa√ß√µes dentro de clusters.  Uma das raz√µes √© que o conjunto de dados pode estar desequilibrado e um grupo de observa√ß√µes supera todos os outros na an√°lise - isso n√£o √© bom e provavelmente levar√° a erros. <br><br> <code>stats.df.aggl &lt;-cstats.table(gower.dist, aggl.clust.c, 7) #      </code> <br> <br> <code>stats.df.aggl</code> <br> <br><img src="https://habrastorage.org/webt/a_/-u/aa/a_-uaa_nff99nuyobulroyk_hka.png"><br><br>  Observe qu√£o melhor o n√∫mero de observa√ß√µes por grupo √© balanceado por cluster hier√°rquico aglomerativo com base no m√©todo de comunica√ß√£o completo. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment"># ---------    ---------# #   ¬´¬ª       #    ,     7  library(ggplot2) #  #   ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))), aes(x=cluster.number, y=within.cluster.ss)) + geom_point()+ geom_line()+ ggtitle("Divisive clustering") + labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/kw/kz/xy/kwkzxyuuzwhe0yst9kteg9inias.png"><br><br>  Ent√£o, criamos um gr√°fico do "cotovelo".  Ele mostra como a soma das dist√¢ncias quadradas entre as observa√ß√µes (n√≥s a usamos como uma medida da proximidade das observa√ß√µes - quanto menor, mais pr√≥ximas s√£o as medidas dentro do cluster) para um n√∫mero diferente de clusters.  Idealmente, devemos ver uma distinta ‚Äúcurva do cotovelo‚Äù no ponto em que aglomerados adicionais d√£o apenas uma ligeira diminui√ß√£o na soma dos quadrados (SS).  Para o gr√°fico abaixo, eu pararia em cerca de 7. Embora neste caso, um dos clusters seja composto por apenas duas observa√ß√µes.  Vamos ver o que acontece durante o agrupamento aglomerado. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#       ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))), aes(x=cluster.number, y=within.cluster.ss)) + geom_point()+ geom_line()+ ggtitle("Agglomerative clustering") + labs(x = "Num.of clusters", y = "Within clusters sum of squares (SS)") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/y0/ck/q-/y0ckq-zxtzg0fbjr9gcq1jgorvq.png"><br><br>  O ‚Äúcotovelo‚Äù aglomerativo √© semelhante ao da divis√£o, mas o gr√°fico parece mais suave - as curvas n√£o s√£o t√£o pronunciadas.  Assim como no agrupamento por divis√£o, eu focaria em 7 agrupamentos, no entanto, ao escolher entre esses dois m√©todos, gosto mais dos tamanhos de agrupamento que s√£o obtidos pelo m√©todo aglomerativo - √© melhor que sejam compar√°veis ‚Äã‚Äãentre si. <br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#  ggplot(data = data.frame(t(cstats.table(gower.dist, divisive.clust, 15))), aes(x=cluster.number, y=avg.silwidth)) + geom_point()+ geom_line()+ ggtitle("Divisive clustering") + labs(x = "Num.of clusters", y = "Average silhouette width") + theme(plot.title = element_text(hjust = 0.5))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/u9/nj/nf/u9njnfcjqbxbzlfgpl5sxqailra.png"><br><br>  Ao usar o m√©todo de estimativa de silhueta, voc√™ deve escolher a quantidade que fornecer o coeficiente m√°ximo de silhueta, porque voc√™ precisa de clusters suficientemente afastados para serem considerados separados. <br><br>  O coeficiente da silhueta pode variar de ‚Äì1 a 1, com 1 correspondendo a boa consist√™ncia dentro dos clusters e ‚Äì1 n√£o muito bom. <br>  No caso do gr√°fico acima, voc√™ escolheria 9 em vez de 5 clusters. <br><br>  Para compara√ß√£o: no caso ‚Äúsimples‚Äù, o gr√°fico da silhueta √© semelhante ao gr√°fico abaixo.  N√£o √© como o nosso, mas quase. <br><br><img src="https://habrastorage.org/webt/18/yw/uj/18ywujz8uh4q5hhnhtxlzrgs1nm.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Marinheiros de Dados</a></i> <br><br><pre> <code class="sql hljs">ggplot(data = data.frame(t(cstats.table(gower.dist, aggl.clust.c, 15))), aes(x=cluster.number, y=avg.silwidth)) + geom_point()+ geom_line()+ ggtitle("Agglomerative clustering") + labs(x = "Num.of clusters", y = "Average silhouette width") + theme(plot.title = element_text(hjust = 0.5))</code> </pre> <br><img src="https://habrastorage.org/webt/vk/f1/fl/vkf1fln-v-nedwuh6rzbjkxz2pg.png"><br><br>  O gr√°fico de largura da silhueta nos diz: quanto mais voc√™ divide o conjunto de dados, mais claros os clusters se tornam.  No entanto, no final, voc√™ alcan√ßar√° pontos individuais e n√£o precisar√° disso.  No entanto, √© exatamente isso que voc√™ ver√° se come√ßar a aumentar o n√∫mero de clusters <i>k</i> .  Por exemplo, para <code>k=30</code> obtive o seguinte gr√°fico: <br><br><img src="https://habrastorage.org/webt/sz/nq/sy/sznqsykdros9uf8clfabfg8yb94.png"><br><br>  Para resumir: quanto mais voc√™ divide o conjunto de dados, melhores s√£o os clusters, mas n√£o podemos alcan√ßar pontos individuais (por exemplo, no gr√°fico acima, selecionamos 30 clusters e temos apenas 200 pontos de dados). <br><br>  Portanto, o agrupamento aglomerativo no nosso caso me parece muito mais equilibrado: os tamanhos dos agrupamentos s√£o mais ou menos compar√°veis ‚Äã‚Äã(basta olhar para um agrupamento de apenas duas observa√ß√µes ao dividir pelo m√©todo de divis√£o!), E eu pararia em 7 agrupamentos obtidos por esse m√©todo.  Vamos ver como eles se parecem e do que s√£o feitos. <br><br>  O conjunto de dados consiste em 6 vari√°veis ‚Äã‚Äãque precisam ser visualizadas em 2D ou 3D, para que voc√™ tenha que trabalhar duro!  A natureza dos dados categ√≥ricos tamb√©m imp√µe algumas limita√ß√µes, portanto, solu√ß√µes prontas podem n√£o funcionar.  Eu preciso: a) ver como as observa√ß√µes s√£o divididas em grupos; b) entender como as observa√ß√µes s√£o categorizadas.  Portanto, criei a) um dendograma de cores, b) um mapa de calor do n√∫mero de observa√ß√µes por vari√°vel dentro de cada cluster. <br><br><pre> <code class="sql hljs">library("ggplot2") library("reshape2") library("purrr") library("dplyr") <span class="hljs-comment"><span class="hljs-comment">#    library("dendextend") dendro &lt;- as.dendrogram(aggl.clust.c) dendro.col &lt;- dendro %&gt;% set("branches_k_color", k = 7, value = c("darkslategray", "darkslategray4", "darkslategray3", "gold3", "darkcyan", "cyan3", "gold3")) %&gt;% set("branches_lwd", 0.6) %&gt;% set("labels_colors", value = c("darkslategray")) %&gt;% set("labels_cex", 0.5) ggd1 &lt;- as.ggdend(dendro.col) ggplot(ggd1, theme = theme_minimal()) + labs(x = "Num. observations", y = "Height", title = "Dendrogram, k = 7")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/iy/hf/jx/iyhfjxt9q7vztvwbaazmqlzzno0.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#     ( ) ggplot(ggd1, labels = T) + scale_y_reverse(expand = c(0.2, 0)) + coord_polar(theta="x")</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/if/4g/yv/if4gyv42vtgecjd9n-b_0bb91rs.png"><br><br><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment">#  ‚Äî   #    ‚Äî       #    ,      clust.num &lt;- cutree(aggl.clust.c, k = 7) synthetic.customers.cl &lt;- cbind(synthetic.customers, clust.num) cust.long &lt;- melt(data.frame(lapply(synthetic.customers.cl, as.character), stringsAsFactors=FALSE), id = c("id.s", "clust.num"), factorsAsStrings=T) cust.long.q &lt;- cust.long %&gt;% group_by(clust.num, variable, value) %&gt;% mutate(count = n_distinct(id.s)) %&gt;% distinct(clust.num, variable, value, count) # heatmap.c ,      ‚Äî ,   ,     heatmap.c &lt;- ggplot(cust.long.q, aes(x = clust.num, y = factor(value, levels = c("x","y","z", "mon", "tue", "wed", "thu", "fri","sat","sun", "delicious", "the one you don't like", "pizza", "facebook", "email", "link", "app", "area1", "area2", "area3", "area4", "small", "med", "large"), ordered = T))) + geom_tile(aes(fill = count))+ scale_fill_gradient2(low = "darkslategray1", mid = "yellow", high = "turquoise4") #            cust.long.p &lt;- cust.long.q %&gt;% group_by(clust.num, variable) %&gt;% mutate(perc = count / sum(count)) %&gt;% arrange(clust.num) heatmap.p &lt;- ggplot(cust.long.p, aes(x = clust.num, y = factor(value, levels = c("x","y","z", "mon", "tue", "wed", "thu", "fri","sat", "sun", "delicious", "the one you don't like", "pizza", "facebook", "email", "link", "app", "area1", "area2", "area3", "area4", "small", "med", "large"), ordered = T))) + geom_tile(aes(fill = perc), alpha = 0.85)+ labs(title = "Distribution of characteristics across clusters", x = "Cluster number", y = NULL) + geom_hline(yintercept = 3.5) + geom_hline(yintercept = 10.5) + geom_hline(yintercept = 13.5) + geom_hline(yintercept = 17.5) + geom_hline(yintercept = 21.5) + scale_fill_gradient2(low = "darkslategray1", mid = "yellow", high = "turquoise4") heatmap.p</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/c5/gg/y5/c5ggy5vih07qcfi4h26mgcvkfgy.png"><br><br>  O mapa de calor mostra graficamente quantas observa√ß√µes s√£o feitas para cada n√≠vel de fator para os fatores iniciais (as vari√°veis ‚Äã‚Äãcom as quais come√ßamos).  A cor azul escuro corresponde a um n√∫mero relativamente grande de observa√ß√µes dentro do cluster.  Esse mapa de calor tamb√©m mostra que, para o dia da semana (dom, s√°b ... seg) e o tamanho da cesta (grande, m√©dio e pequeno), o n√∫mero de clientes em cada c√©lula √© quase o mesmo - isso pode significar que essas categorias n√£o s√£o determinantes para a an√°lise Talvez eles n√£o precisem ser levados em considera√ß√£o. <br><br><h2>  Conclus√£o </h2><br>  Neste artigo, calculamos a matriz de dissimilaridade, testamos os m√©todos aglomerativos e de divis√£o de agrupamento hier√°rquico e nos familiarizamos com os m√©todos de cotovelo e silhueta para avaliar a qualidade dos clusters. <br><br>  O cluster hier√°rquico de divis√£o e aglomera√ß√£o √© um bom come√ßo para estudar o t√≥pico, mas n√£o pare por a√≠ se voc√™ realmente deseja dominar a an√°lise de cluster.  Existem muitos outros m√©todos e t√©cnicas.  A principal diferen√ßa dos dados num√©ricos em cluster √© o c√°lculo da matriz de dissimilaridade.  Ao avaliar a qualidade do agrupamento, nem todos os m√©todos padr√£o fornecer√£o resultados confi√°veis ‚Äã‚Äãe significativos - o m√©todo da silhueta provavelmente n√£o √© adequado. <br><br>  E, finalmente, j√° que j√° passou algum tempo desde que eu fiz esse exemplo, agora vejo v√°rias defici√™ncias em minha abordagem e ficarei feliz em receber algum feedback.  Um dos problemas significativos da minha an√°lise n√£o estava relacionado ao agrupamento como tal - <i>meu conjunto de dados estava desequilibrado</i> de v√°rias maneiras e esse momento permaneceu inexplicado.  Isso teve um efeito not√°vel no agrupamento: 70% dos clientes pertenciam a um n√≠vel do fator ‚Äúcidadania‚Äù, e esse grupo dominou a maioria dos clusters obtidos, por isso era dif√≠cil calcular as diferen√ßas em outros n√≠veis do fator.  Na pr√≥xima vez, tentarei equilibrar o conjunto de dados e comparar os resultados do cluster.  Mas mais sobre isso em outro post. <br><br>  Por fim, se voc√™ deseja clonar meu c√≥digo, aqui est√° o link para o github: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/khunreus/cluster-categorical</a> <br>  Espero que voc√™ tenha gostado deste artigo! <br><br><h3>  <i>Fontes que me ajudaram:</i> </h3><br>  Guia hier√°rquico de armazenamento em cluster (prepara√ß√£o de dados, armazenamento em cluster, visualiza√ß√£o) - este blog ser√° interessante para quem estiver interessado em an√°lise de neg√≥cios no ambiente R: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://uc-r.github.io/hc_clustering</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https: // uc-r. github.io/kmeans_clustering</a> <br><br>  Valida√ß√£o de cluster: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://www.sthda.com/english/articles/29-cluster-validation-essentials/97-cluster-validation-statistics-must-know-methods/</a> <br><br>    (   k-): <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://eight2late.wordpress.com/2015/07/22/a-gentle-introduction-to-cluster-analysis-using-r/</a> <br><br>    denextend,        : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://cran.r-project.org/web/packages/dendextend/vignettes/introduction.html#the-set-function</a> <br><br>    ,   : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://www.r-statistics.com/2010/06/clustergram-visualization-and-diagnostics-for-cluster-analysis-r-code/</a> <br><br>     : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://jcoliver.github.io/learn-r/008-ggplot-dendrograms-and-heatmaps.html</a> <br><br>       ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5025633/</a> (  GitHub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/khunreus/EnsCat</a> ). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt461741/">https://habr.com/ru/post/pt461741/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt461731/index.html">DPKI: Abordando as desvantagens da PKI centralizada por meio de Blockchain</a></li>
<li><a href="../pt461733/index.html">Aprendendo ingl√™s: 9 express√µes ao estilo americano</a></li>
<li><a href="../pt461735/index.html">Pr√°tica de decodifica√ß√£o de hardware FFmpeg DXVA2</a></li>
<li><a href="../pt461737/index.html">Coletamos o ambiente para o TDD moderno em JavaScript + c√≥digo VS</a></li>
<li><a href="../pt461739/index.html">Back-end United 4: Okroshka. Incidentes</a></li>
<li><a href="../pt461743/index.html">Semana 31 de Seguran√ßa: Vulnerabilidade no VLC e telefone quebrado</a></li>
<li><a href="../pt461745/index.html">DeviceLock DLP: Pre√ßos do mercado negro russo pela quebra de dados pessoais (mais uma resposta √† resposta do Tinkoff Bank)</a></li>
<li><a href="../pt461747/index.html">Como implementamos o ML em um aplicativo com quase 50 milh√µes de usu√°rios. Experi√™ncia Sberbank</a></li>
<li><a href="../pt461749/index.html">Beleza nos olhos de quem v√™</a></li>
<li><a href="../pt461751/index.html">Contribui√ß√£o do designer para o desenvolvimento de aplicativos para dispositivos m√≥veis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
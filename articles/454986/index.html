<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👐🏼 🈚️ 👍🏼 Introducción a las redes neuronales convolucionales 👨🏾‍🎓 👨🏾‍🔬 🌑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El curso completo en ruso se puede encontrar en este enlace . 
 El curso de inglés original está disponible en este enlace . 


 Nuevas conferencias e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Introducción a las redes neuronales convolucionales</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454986/"> El curso completo en ruso se puede encontrar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . <br>  El curso de inglés original está disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . <br><br><img src="https://habrastorage.org/webt/uh/pm/jt/uhpmjticdnfsyigvpgkhb0t-a4s.png"><br>  <i>Nuevas conferencias están programadas cada 2-3 días.</i> <br><a name="habracut"></a><br><h2>  Entrevista con Sebastian </h2><br>  - Entonces, estamos nuevamente con Sebastian en la tercera parte de este curso.  Sebastian, sé que has desarrollado mucho usando redes neuronales convolucionales.  ¿Puede contarnos un poco más sobre estas redes y cuáles son?  Estoy seguro de que los estudiantes de nuestro curso escucharán con no menos interés, porque en esta parte tendrán que desarrollar ellos mismos la red neuronal convolucional. <br>  - Genial!  Entonces, las redes neuronales convolucionales son una excelente manera de estructurar en la red, construyendo la llamada invariancia (asignación de características inmutables).  Por ejemplo, tome la idea del reconocimiento de patrones en el escenario o la fotografía, desea comprender si Sebastian está representado en él o no.  No importa en qué parte de la fotografía estoy ubicado, dónde está ubicada mi cabeza, en el centro de la fotografía o en la esquina.  Reconocimiento de mi cabeza, mi cara debería aparecer independientemente de dónde se encuentren en la imagen.  Esto es invariancia, variabilidad de ubicación, que se realiza mediante redes neuronales convolucionales. <br>  - Muy interesante!  ¿Puede decirnos las tareas principales en las que se utilizan las redes neuronales convolucionales? <br>  - Las redes neuronales convolucionales se usan bastante estrechamente cuando se trabaja con audio y video, incluidas imágenes médicas.  También se utilizan en tecnologías del lenguaje, donde los especialistas utilizan el aprendizaje profundo para comprender y reproducir construcciones del lenguaje.  De hecho, hay muchas aplicaciones para esta tecnología, ¡incluso diría que son infinitas!  Su tecnología se puede utilizar en finanzas y en cualquier otra área. <br>  "Utilicé redes neuronales convolucionales para analizar imágenes de satélite". <br>  - Genial!  La tarea estándar! <br>  - ¿Qué opinas, podemos considerar las redes neuronales convolucionales como algo la última y más avanzada herramienta en el desarrollo del aprendizaje profundo? <br>  - Ja!  Ya he aprendido a nunca decir nunca.  ¡Siempre habrá algo nuevo y sorprendente! <br>  "¿Entonces todavía tenemos trabajo que hacer?"  :) <br>  - Habrá suficiente trabajo! <br>  - excelente!  En este curso, solo enseñamos a los futuros pioneros del aprendizaje automático.  ¿Tiene algún deseo para nuestros estudiantes antes de que comiencen a construir su primera red neuronal convolucional? <br>  - Aquí hay un hecho interesante para ti.  Las redes neuronales convolucionales se inventaron en 1989, ¡y esto es hace mucho tiempo!  La mayoría de ustedes ni siquiera nacieron en ese momento, lo que significa que no es el genio del algoritmo lo que importa, sino los datos con los que opera este algoritmo.  Vivimos en un mundo donde hay muchos datos para analizar y buscar patrones.  Tenemos la capacidad de emular las funciones de la mente humana utilizando esta gran cantidad de datos.  Cuando trabaje en redes neuronales convolucionales, intente concentrarse en encontrar los datos correctos y aplicarlos; vea lo que sucede y, a veces, puede ser una verdadera magia, como fue el caso en nuestro caso cuando resolvíamos el problema de detectar el cáncer de piel. <br>  - Genial!  Bueno, ¡finalmente vamos a la magia! <br><br><h2>  Introduccion </h2><br>  En la última lección, aprendimos cómo desarrollar redes neuronales profundas que pueden clasificar imágenes de elementos de vestimenta del conjunto de datos Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br>  Los resultados que obtuvimos al trabajar en la red neuronal fueron impresionantes: 88% de precisión de clasificación.  ¡Y esto está en unas pocas líneas de código (sin tener en cuenta el código para construir gráficos e imágenes)! <br><br><pre><code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre> <br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><pre> <code class="python hljs">NUM_EXAMPLES = <span class="hljs-number"><span class="hljs-number">60000</span></span> train_dataset = train_dataset.repeat().shuffle(NUM_EXAMPLES).batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) test_dataset = test_dataset.batch(<span class="hljs-number"><span class="hljs-number">32</span></span>)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/<span class="hljs-number"><span class="hljs-number">32</span></span>))</code> </pre><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/<span class="hljs-number"><span class="hljs-number">32</span></span>)) print(<span class="hljs-string"><span class="hljs-string">': '</span></span>, test_accuracy)</code> </pre><br> <code>: 0.8782 <br></code> <br>  También experimentamos con el efecto del número de neuronas en capas ocultas y el número de iteraciones de entrenamiento sobre la precisión del modelo.  Pero, ¿cómo hacemos que este modelo sea aún mejor y más preciso?  Una forma de lograr esto es usar redes neuronales convolucionales, abreviado SNA.  SNA muestra una mayor precisión en la resolución de los problemas de clasificación de imágenes que las redes neuronales estándar totalmente conectadas que encontramos en las clases anteriores.  Es por esta razón que el SNA se hizo tan popular y fue gracias a ellos que se hizo posible un avance tecnológico en el campo de la visión artificial. <br><br>  En esta lección, aprenderemos lo fácil que es desarrollar un clasificador SNA desde cero utilizando TensorFlow y Keras.  Utilizaremos el mismo conjunto de datos Fashion MNIST que utilizamos en la lección anterior.  Al final de esta lección, comparamos la precisión de la clasificación de los elementos de vestimenta de la red neuronal anterior con la red neuronal convolucional de esta lección. <br><br>  Antes de sumergirse en el desarrollo, vale la pena profundizar un poco más en el principio de funcionamiento de las redes neuronales convolucionales. <br><br>  Dos conceptos básicos en redes neuronales convolucionales: <br><br><ul><li>  convolución </li><li>  operación de submuestreo (agrupación, agrupación máxima) </li></ul><br><br>  Echemos un vistazo más de cerca a ellos. <br><br><h2>  Convolución </h2><br>  En esta parte de nuestra lección, aprenderemos una técnica llamada convolución.  Veamos como funciona. <br><br>  Tome una imagen en tonos de gris y, por ejemplo, imagine que sus dimensiones son de 6 px de altura y 6 px de ancho. <br><br><img src="https://habrastorage.org/webt/jd/rh/6y/jdrh6y3zzszxmhixrfnaxmndr-m.png"><br><br>  Nuestra computadora interpreta la imagen como una matriz bidimensional de píxeles.  Como nuestra imagen está en tonos de gris, el valor de cada píxel estará en el rango de 0 a 255. 0 - negro, 255 - blanco. <br><br>  En la imagen a continuación vemos una representación de la imagen de 6px x 6px y los valores de píxeles correspondientes: <br><br><img src="https://habrastorage.org/webt/qz/mw/jd/qzmwjdfjxnu88pat92ciearc4ng.png"><br><br>  Como ya sabe, antes de trabajar con imágenes, debe normalizar los valores de píxeles: lleve los valores a un intervalo de 0 a 1. Sin embargo, en este ejemplo, para mayor comodidad, guardaremos los valores de píxeles de la imagen y no los normalizaremos. <br><br>  La esencia de la convolución es crear otro conjunto de valores, que se llama núcleo o filtro.  Se puede ver un ejemplo en la imagen a continuación: una matriz de 3 x 3: <br><br><img src="https://habrastorage.org/webt/16/8x/g0/168xg0hysoiy8pwlygw-nxmw-ck.png"><br><br>  Entonces podemos escanear nuestra imagen usando el núcleo.  Las dimensiones de nuestra imagen son 6x6px, y los núcleos son 3x3px.  La capa convolucional se aplica al núcleo y a cada sección de la imagen de entrada. <br><br>  Imaginemos que queremos una convolución sobre un píxel con un valor de 25 (3 filas, 3 columnas) y lo primero que hay que hacer es centrar el núcleo sobre este píxel: <br><br><img src="https://habrastorage.org/webt/dt/qs/5x/dtqs5xle8lhrv0h504wbk3gzgnw.png"><br><br>  En la imagen, la ubicación del núcleo se resalta en amarillo.  Ahora veremos solo los valores de píxeles que están en nuestro rectángulo amarillo, cuyos tamaños corresponden a los tamaños de nuestro núcleo de convolución. <br><br>  Ahora tomamos los valores de píxel de la imagen y el núcleo, multiplicamos cada píxel de la imagen con el píxel correspondiente del núcleo y agregamos todos los valores del producto, y asignamos el valor de píxel resultante a la nueva imagen. <br><br><img src="https://habrastorage.org/webt/tz/xe/oc/tzxeocatpow2ytacpikwfpj--w8.png"><br><br><img src="https://habrastorage.org/webt/eu/ty/tj/eutytjlyn4js82ry704lkaz6gpq.png"><br><br><img src="https://habrastorage.org/webt/x5/3k/hs/x53khs1exvxwdbmn2mnxihg2wxa.png"><br><br>  Realizamos una operación similar con todos los píxeles en nuestra imagen.  Pero, ¿qué debería pasar con los píxeles en los bordes? <br><br><img src="https://habrastorage.org/webt/2h/af/nf/2hafnfev-ft4bioova_jjepqby4.png"><br><br>  Hay varias soluciones  En primer lugar, simplemente podemos ignorar estos píxeles, pero en este caso perderemos información sobre la imagen, lo que puede resultar significativo, y la imagen minimizada será más pequeña que la original.  En segundo lugar, podemos simplemente "matar" con valores cero aquellos píxeles cuyos valores centrales están más allá del alcance de la imagen.  El proceso se llama alineación. <br><br><img src="https://habrastorage.org/webt/fc/wa/1s/fcwa1sx3ekaufxf0zzstuzzk7bo.png"><br><br>  Ahora que hemos realizado la alineación con valores de píxel cero, podemos calcular el valor del píxel final en la imagen minimizada como antes. <br><br>  Una convolución es el proceso de aplicar un núcleo (filtro) a cada parte de la imagen de entrada, por analogía con una capa totalmente conectada (capa densa), veremos que la convolución es la misma capa en Keras. <br><br>  Ahora veamos el segundo concepto de redes neuronales convolucionales: la operación de submuestreo (agrupación, agrupación máxima). <br><br><h2>  Operación de submuestreo (agrupación, agrupación máxima) </h2><br>  Ahora consideraremos el segundo concepto fundamental que subyace a las redes neuronales convolucionales: la operación de submuestreo (agrupación, agrupación máxima).  En palabras simples, una operación de submuestreo es el proceso de comprimir (reducir) una imagen agregando los valores de los bloques de píxeles.  Veamos cómo funciona esto en un ejemplo concreto. <br><br><img src="https://habrastorage.org/webt/ya/d4/31/yad431do5fnnuwenxqlv7sxkq2g.png"><br><br>  Para realizar la operación de submuestreo, debemos decidir sobre dos componentes de este proceso: el tamaño de la muestra (el tamaño de la cuadrícula rectangular) y el tamaño del paso.  En este ejemplo, utilizaremos una cuadrícula rectangular de 3x3 y el paso 3. El paso determina el número de píxeles por los cuales la cuadrícula rectangular debe desplazarse al realizar la operación de submuestreo. <br><br>  Una vez que hayamos decidido el tamaño de la cuadrícula y el tamaño del paso, debemos encontrar el valor máximo de píxeles que cae en la cuadrícula seleccionada.  En el ejemplo anterior, los valores 1, 0, 4, 8, 2, 5, 20, 13, 25. entran en la cuadrícula El valor máximo es 25. Este valor se "transfiere" a la nueva imagen.  La cuadrícula se desplaza 3 píxeles hacia la derecha y se repite el proceso de seleccionar el valor máximo y transferirlo a una nueva imagen. <br><br><img src="https://habrastorage.org/webt/ht/o0/ef/hto0efftnhidlrtascm-p3gqb_m.png"><br><br>  Como resultado, se obtendrá una imagen más pequeña en comparación con la imagen de entrada original.  En nuestro ejemplo, se obtuvo una imagen que es la mitad del tamaño de nuestra imagen original.  El tamaño de la imagen final variará dependiendo de la elección del tamaño de la cuadrícula rectangular y el tamaño del paso. <br><br>  ¡Veamos cómo funcionará esto en Python! <br><br><h2>  Resumen </h2><br>  Nos familiarizamos con conceptos tales como la convolución y la operación de agrupación máxima. <br><br>  La convolución es el proceso de aplicar un filtro ("núcleo") a una imagen.  La operación de submuestreo por valor máximo es el proceso de reducir el tamaño de una imagen combinando un grupo de píxeles en un solo valor máximo de este grupo. <br><br>  Como veremos en la parte práctica, la capa convolucional se puede agregar a la red neuronal usando la capa <code>Conv2D</code> en Keras.  Esta capa es similar a la capa Densa y contiene pesos y compensaciones que se someten a optimización (selección).  <code>Conv2D</code> capa <code>Conv2D</code> también contiene filtros ("núcleos"), cuyos valores también están optimizados.  Entonces, en la capa <code>Conv2D</code> , los valores dentro de la matriz de filtro son las variables que se someten a optimización. <br><br>  Algunos términos que logramos encontrar: <br><br><ul><li>  <b>SNS</b> - redes neuronales convolucionales.  Una red neuronal que contiene al menos una capa convolucional.  Un SNA típico contiene otras capas, como capas de muestra y capas completamente conectadas. </li><li>  <b>La convolución</b> es el proceso de aplicar un filtro ("núcleo") a una imagen. </li><li>  <b>Un filtro (núcleo)</b> es una matriz de menor tamaño que los datos de entrada, destinada a convertir datos de entrada en bloques. </li><li>  <b>La alineación</b> es el proceso de agregar, a menudo valores cero, a los bordes de una imagen. </li><li>  <b>La operación de submuestreo</b> es el proceso de reducir el tamaño de una imagen a través del muestreo.  Existen varios tipos de capas de submuestreo, por ejemplo, una capa de submuestreo promediada (muestreo de un valor promedio), sin embargo, una submuestreo por el valor máximo se usa con mayor frecuencia. </li><li>  <b>El submuestreo por el valor máximo</b> es el proceso de submuestreo, durante el cual muchos valores se convierten en un valor único, el máximo entre el muestreo. </li><li>  <b>Paso</b> : el número de píxeles de desplazamiento por el filtro (núcleo) en la imagen. </li><li>  <b>Muestreo (disminución de resolución)</b> : proceso de reducción del tamaño de la imagen. </li></ul><br><h2>  CoLab: clasificación de elementos de indumentaria Fashion MNIST utilizando una red neuronal convolucional </h2><br>  ¡Nos rodearon alrededor de un dedo!  Tiene sentido realizar esta parte práctica solo después de que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se</a> haya completado la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">parte anterior</a> : todo el código, excepto un bloque, sigue siendo el mismo.  La estructura de nuestra red neuronal está cambiando, y estas son cuatro líneas adicionales para capas neuronales convolucionales y capas de submuestra en el valor máximo (agrupación máxima). <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=tf.nn.relu, input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), strides=<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=tf.nn.relu), tf.keras.layers.MaxPooling2D((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), strides=<span class="hljs-number"><span class="hljs-number">2</span></span>), tf.keras.layers.Flatten(), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br>  Todas las explicaciones detalladas de cómo trabajar, prometen darnos en la siguiente parte: 4 partes. <br><br>  Oh si  La precisión del modelo en la etapa de entrenamiento llegó a ser igual al 97% (el modelo "reentrenado" en <code>epochs=10</code> ), y cuando se ejecutó el conjunto de datos para las pruebas mostró exactamente el 91%.  Un aumento notable en la precisión en relación con la arquitectura anterior, donde utilizamos solo capas completamente conectadas: 88%. <br><br><h2>  Resumen </h2><br>  En esta parte de la lección, estudiamos un nuevo tipo de red neuronal: la red neuronal convolucional.  Nos familiarizamos con términos como "convolución" y "operación de agrupación máxima", desarrollamos y capacitamos una red neuronal convolucional desde cero.  Como resultado, vimos que nuestra red neuronal convolucional produce más precisión que la red neuronal que desarrollamos en la última lección. <br><br>  PD Nota del autor de la traducción. <br><br>  El curso se llama "Introducción al aprendizaje profundo utilizando TensorFlow", por lo que no nos quejamos de la falta de explicaciones detalladas del principio de las redes neuronales convolucionales (capas): los próximos dos artículos serán sobre el principio de la red neuronal convolucional y su estructura interna. (los artículos no se relacionan con el curso, pero fueron recomendados por los participantes de StackOverflow para comprender mejor lo que está sucediendo). <br><br>  ... y un llamado a la acción estándar: regístrese, ponga un plus y comparta :) <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Telegrama</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/454986/">https://habr.com/ru/post/454986/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../454974/index.html">Lockheed Martin patenta la impresión 3D con diamante</a></li>
<li><a href="../454976/index.html">Max Patrol 8. Descripción general de la herramienta de administración de vulnerabilidades</a></li>
<li><a href="../454978/index.html">Un error en Linux 5.1 condujo a la pérdida de datos: ya se ha lanzado un parche de corrección</a></li>
<li><a href="../454980/index.html">Lo que había en el primer iPod: veinte álbumes que Steve Jobs eligió en 2001</a></li>
<li><a href="../454982/index.html">Cómo colocamos el muestreo en SIBUR en nuevas pistas</a></li>
<li><a href="../454990/index.html">“Es recomendable que tengas un gato”: cómo una startup puede disparar a Product Hunt</a></li>
<li><a href="../454994/index.html">¿Cuáles son las ventajas de la carga inalámbrica y por qué está detrás el futuro? Experiencia personal para 2019</a></li>
<li><a href="../454996/index.html">El Centro de Entrenamiento de Cosmonautas lleva el nombre de Yu.A. Gagarin y Roscosmos comenzaron el reclutamiento abierto en el escuadrón de cosmonautas</a></li>
<li><a href="../454998/index.html">Julia y la computación paralela</a></li>
<li><a href="../455000/index.html">Cuidado de mudarse a los Países Bajos con su esposa. Parte 3: trabajo, colegas y otra vida.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
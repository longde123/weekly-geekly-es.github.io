<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöµüèº üë©üèΩ‚Äçüè≠ üë®üèΩ‚Äçüè≠ Ethische Fragen der k√ºnstlichen Intelligenz üë©üèΩ‚Äçüíº ü•ù ‚öæÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Autor des Artikels ist Alexey Malanov, Experte in der Entwicklungsabteilung f√ºr Antivirentechnologie des Kaspersky Lab 

 K√ºnstliche Intelligenz b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ethische Fragen der k√ºnstlichen Intelligenz</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/kaspersky/blog/421791/">  <i>Der Autor des Artikels ist Alexey Malanov, Experte in der Entwicklungsabteilung f√ºr Antivirentechnologie des Kaspersky Lab</i> <br><br>  K√ºnstliche Intelligenz bricht in unser Leben ein.  In Zukunft wird wahrscheinlich alles cool sein, aber bisher sind einige Fragen aufgetaucht, und diese Probleme wirken sich zunehmend auf Aspekte der Moral und Ethik aus.  Ist es m√∂glich, sich √ºber KI lustig zu machen?  Wann wird es erfunden?  Was hindert uns derzeit daran, Gesetze der Robotik zu schreiben und ihnen Moral zu verleihen?  Welche √úberraschungen bringt uns maschinelles Lernen gerade?  Kann maschinelles Lernen get√§uscht werden und wie schwierig ist es? <a name="habracut"></a><br><br><h1>  Starke und schwache KI - zwei verschiedene Dinge </h1><br>  Es gibt zwei verschiedene Dinge: Starke und schwache KI. <br>  Starke KI (wahr, allgemein, real) ist eine hypothetische Maschine, die denken und sich ihrer selbst bewusst sein kann, nicht nur hochspezialisierte Aufgaben l√∂st, sondern auch etwas Neues lernt. <br><br>  Schwache KI (eng, oberfl√§chlich) - Dies sind bereits existierende Programme zur L√∂sung ganz bestimmter Aufgaben wie Bilderkennung, automatisches Fahren, Go-Spielen usw. Um nicht verwirrt zu werden und niemanden irrezuf√ºhren, nennen wir die Maschine ‚ÄûSchwache KI‚Äú lieber Lernen ‚Äú(maschinelles Lernen). <br><br><h1>  Starke KI wird nicht bald sein </h1><br>  √úber Strong AI ist noch nicht bekannt, ob es jemals erfunden wird.  Einerseits haben sich Technologien bisher mit Beschleunigung entwickelt, und wenn dies so weitergeht, bleiben noch f√ºnf Jahre. <br><br><img src="https://habrastorage.org/webt/_i/sv/en/_isvenid4vjjjfsvl5nhnve4xee.jpeg"><br><br>  Andererseits laufen nur wenige Prozesse in der Natur exponentiell ab.  Schlie√ülich sehen wir viel h√§ufiger eine logistische Kurve. <br><br><img src="https://habrastorage.org/webt/72/uq/hj/72uqhj_g_zj1dn6wq62ewvczwya.png"><br><br>  W√§hrend wir uns irgendwo links im Diagramm befinden, scheint es uns, dass dies ein Exponent ist.  Zum Beispiel ist die Weltbev√∂lkerung bis vor kurzem mit einer solchen Beschleunigung gewachsen.  Aber irgendwann tritt "S√§ttigung" auf und das Wachstum verlangsamt sich. <br><br>  Wenn Experten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">befragt werden</a> , stellt sich heraus, dass Sie durchschnittlich weitere 45 Jahre warten m√ºssen. <br><br><img src="https://habrastorage.org/webt/3r/ro/h4/3rroh4slw6_2yu-lpodoret9vxq.png"><br><br>  Seltsamerweise glauben nordamerikanische Wissenschaftler, dass die KI in 74 Jahren den Menschen √ºbertreffen wird, und asiatische Wissenschaftler in nur 30 Jahren. Vielleicht wissen sie in Asien etwas ... <br><br>  Dieselben Wissenschaftler sagten voraus, dass eine Maschine bis 2024 besser √ºbersetzen w√ºrde als eine Person, bis 2026 Schulaufs√§tze schreiben, bis 2027 Lastwagen fahren und bis 2027 auch Go spielen w√ºrde.  Go hat es bereits verpasst, denn dieser Moment kam 2017, nur 2 Jahre nach der Prognose. <br><br>  Prognosen f√ºr mehr als 40 Jahre sind im Allgemeinen eine undankbare Aufgabe.  Es bedeutet eines Tages.  Beispielsweise wird auch nach 40 Jahren eine kosteng√ºnstige Fusionsenergie vorhergesagt.  Die gleiche Prognose wurde vor 50 Jahren gemacht, als sie gerade erst untersucht wurde. <br><br><img src="https://habrastorage.org/webt/pi/3u/v-/pi3uv-ptktxeymxbjxl2_mxrujs.png" align="right"><h1>  Eine starke KI wirft viele ethische Fragen auf </h1><br>  Starke KI wird zwar lange warten, aber wir wissen mit Sicherheit, dass es genug ethische Probleme geben wird.  Die erste Klasse von Problemen ist, dass wir KI beleidigen k√∂nnen.  Zum Beispiel: <br><br><ul><li>  Ist es ethisch korrekt, KI zu foltern, wenn sie Schmerzen versp√ºren kann? </li><li>  Ist es normal, KI f√ºr l√§ngere Zeit ohne Kommunikation zu lassen, wenn sie sich einsam f√ºhlt? </li><li>  Kannst du es als Haustier benutzen?  Was ist mit einem Sklaven?  Und wer wird es steuern und wie, denn dies ist ein Programm, das in Ihrem "Smartphone" "lebt"? </li></ul><br>  Jetzt wird niemand emp√∂rt sein, wenn Sie Ihren Sprachassistenten beleidigen, aber wenn Sie den Hund misshandeln, werden Sie verurteilt.  Und das nicht, weil sie aus Fleisch und Blut ist, sondern weil sie eine schlechte Einstellung f√ºhlt und erlebt, wie es bei einer starken KI der Fall sein wird. <br><br>  Die zweite Klasse ethischer Fragen - KI kann uns beleidigen.  Hunderte solcher Beispiele finden sich in Filmen und B√ºchern.  Wie kann man KI erkl√§ren, was wollen wir davon?  Menschen f√ºr KI sind wie Ameisen f√ºr Arbeiter, die einen Damm bauen: Um ein gro√üartiges Ziel zu erreichen, kann man ein Paar vernichten. <br><br>  Science Fiction spielt uns einen Streich.  Wir sind es gewohnt zu denken, dass Skynet und die Terminatoren nicht da sind und es nicht bald sein wird, aber jetzt k√∂nnen Sie sich entspannen.  Die KI in Filmen ist oft b√∂sartig, und wir hoffen, dass dies im Leben nicht passieren wird. Schlie√ülich wurden wir gewarnt und sind nicht so dumm wie die Helden der Filme.  Dar√ºber hinaus vergessen wir in Gedanken √ºber die Zukunft, gut √ºber die Gegenwart nachzudenken. <br><br><h1>  Maschinelles Lernen ist da </h1><br>  Durch maschinelles Lernen k√∂nnen Sie ein praktisches Problem ohne explizite Programmierung l√∂sen, jedoch durch Schulung zu Pr√§zedenzf√§llen.  Weitere Informationen finden Sie im Artikel ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">In einfachen Worten: Wie maschinelles Lernen funktioniert</a> ‚Äú. <br><br>  Da wir einer Maschine beibringen, ein bestimmtes Problem zu l√∂sen, kann das resultierende mathematische Modell (der sogenannte Algorithmus) nicht pl√∂tzlich die Menschheit versklaven / retten wollen.  Mach es normal - es wird normal sein.  Was k√∂nnte schief gehen? <br><br><img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right"><h1>  Schlechte Absichten </h1><br>  Erstens ist die Aufgabe selbst m√∂glicherweise nicht ethisch genug.  Zum Beispiel, wenn wir maschinelles Lernen verwenden, um Drohnen beizubringen, Menschen zu t√∂ten. <br><img src="https://habrastorage.org/webt/2w/cq/oi/2wcqoiuu8xuass9vd7uulmkkc9m.png"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.youtube.com/watch?v=TlO2gcs1YvM</a> <br><br>  Erst k√ºrzlich kam es zu einem kleinen Skandal.  Google entwickelt die Software f√ºr das Pilotprojekt Project Maven Drone Management.  Vermutlich k√∂nnte dies in Zukunft zur Schaffung einer vollst√§ndig autonomen Waffe f√ºhren. <br><br><img src="https://habrastorage.org/webt/sr/wa/ei/srwaeiionmujk7cx1zj-fzf-s0g.jpeg"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Mindestens 12 Google-Mitarbeiter k√ºndigten aus Protest, weitere 4.000 unterschrieben eine Petition, in der sie aufgefordert wurden, den Vertrag mit dem Milit√§r aufzugeben.  Mehr als 1000 prominente Wissenschaftler auf dem Gebiet der KI, Ethik und Informationstechnologie haben in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einem offenen Brief</a> Google gebeten, die Arbeit an dem Projekt einzustellen und den internationalen Vertrag zum Verbot autonomer Waffen zu unterst√ºtzen. <br><br><h1>  Gierige Voreingenommenheit </h1><br>  Aber selbst wenn die Autoren des Algorithmus f√ºr maschinelles Lernen keine Menschen t√∂ten und Schaden anrichten wollen, wollen sie dennoch oft einen Gewinn erzielen.  Mit anderen Worten, nicht alle Algorithmen arbeiten zum Wohle der Gesellschaft, viele zum Wohle der Sch√∂pfer.  Dies kann im medizinischen Bereich h√§ufig beobachtet werden - es ist wichtiger, nicht zu heilen, sondern mehr Behandlung zu empfehlen. <img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Wenn maschinelles Lernen etwas Bezahltes empfiehlt, ist der Algorithmus im Allgemeinen mit hoher Wahrscheinlichkeit "gierig". <br><br>  Nun, und manchmal ist die Gesellschaft selbst nicht daran interessiert, dass der resultierende Algorithmus ein Modell der Moral ist.  Zum Beispiel gibt es einen Kompromiss zwischen Fahrzeuggeschwindigkeit und Verkehrstoten.  Wir k√∂nnten die Sterblichkeit erheblich senken, wenn wir die Geschwindigkeit auf 20 km / h begrenzen w√ºrden, aber dann w√§re das Leben in gro√üen St√§dten schwierig. <br><br><h1>  Ethik ist nur einer der Parameter des Systems. </h1><br><img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right">  Stellen Sie sich vor, wir fordern den Algorithmus auf, das Budget des Landes mit dem Ziel ‚ÄûMaximierung des BIP / Arbeitsproduktivit√§t / Lebenserwartung‚Äú aufzustellen.  Es gibt keine ethischen Einschr√§nkungen und Ziele bei der Formulierung dieser Aufgabe.  Warum Geld f√ºr Waisenh√§user / Hospize / Umweltschutz bereitstellen, weil es das BIP nicht (zumindest direkt) steigern wird?  Und es ist gut, wenn wir das Budget nur dem Algorithmus anvertrauen, und in einer breiteren Darstellung des Problems stellt sich heraus, dass es ‚Äûrentabler‚Äú ist, eine arbeitslose Bev√∂lkerung sofort zu t√∂ten, um die Arbeitsproduktivit√§t zu steigern. <br><br>  Es stellt sich heraus, dass ethische Fragen zun√§chst zu den Zielen des Systems geh√∂ren sollten. <br><br><h1>  Ethik ist formal schwer zu beschreiben </h1><br>  Es gibt ein Problem mit der Ethik - es ist schwierig zu formalisieren.  Verschiedene L√§nder haben unterschiedliche Ethik.  Es √§ndert sich im Laufe der Zeit.  Beispielsweise k√∂nnen sich Meinungen zu Themen wie LGBT-Rechten und Ehen zwischen verschiedenen Rassen und Kasten √ºber Jahrzehnte hinweg erheblich √§ndern.  Die Ethik kann vom politischen Klima abh√§ngen. <br><img src="https://habrastorage.org/webt/oe/bj/x9/oebjx9ygsiqyfs-zap5diznne2i.png"><br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  In China wird beispielsweise die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberwachung der Bewegung von B√ºrgern</a> mithilfe von √úberwachungskameras und Gesichtserkennung als Norm angesehen.  In anderen L√§ndern kann die Einstellung zu diesem Thema unterschiedlich sein und von der Situation abh√§ngen. <br><br><h1>  Maschinelles Lernen betrifft Menschen </h1><br>  Stellen Sie sich ein auf maschinellem Lernen basierendes System vor, das Sie dar√ºber informiert, welchen Film Sie ansehen sollen.  Basierend auf Ihren Bewertungen f√ºr andere Filme und durch den Vergleich Ihres Geschmacks mit denen anderer Benutzer kann das System einen Film, den Sie wirklich m√∂gen, sehr zuverl√§ssig empfehlen. <img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right"><br><br>  Gleichzeitig √§ndert das System Ihren Geschmack im Laufe der Zeit und macht ihn enger.  Ohne ein System w√ºrden Sie von Zeit zu Zeit schlechte Filme und Filme ungew√∂hnlicher Genres sehen.  Und damit kein Film - auf den Punkt.  Infolgedessen sind wir keine ‚ÄûFilmexperten‚Äú mehr und werden nur noch Konsumenten dessen, was sie geben.  Interessant ist auch, dass wir nicht einmal bemerken, wie die Algorithmen uns manipulieren. <br><br>  Wenn Sie sagen, dass ein solcher Effekt von Algorithmen auf Menschen sogar gut ist, dann ist hier ein weiteres Beispiel.  China bereitet die Einf√ºhrung des Social Rating Systems vor - eines Systems zur Bewertung von Einzelpersonen oder Organisationen anhand verschiedener Parameter, deren Werte mithilfe von Massen√ºberwachungstools und mithilfe von Big-Data-Analysetechnologien ermittelt werden. <img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right">  Wenn eine Person Windeln kauft - das ist gut, w√§chst die Bewertung.  Wenn es schlecht ist, Geld f√ºr Videospiele auszugeben, sinkt die Bewertung.  Wenn mit einer Person mit einer niedrigen Bewertung kommuniziert wird, f√§llt auch. <br><br>  Infolgedessen stellt sich heraus, dass sich die B√ºrger dank des Systems bewusst oder unbewusst anders verhalten.  Kommunizieren Sie weniger mit unzuverl√§ssigen B√ºrgern, kaufen Sie mehr Windeln usw. <br><br><h1>  Algorithmischer Systemfehler </h1><br>  Neben der Tatsache, dass wir manchmal selbst nicht wissen, was wir vom Algorithmus erwarten, gibt es auch eine ganze Reihe technischer Einschr√§nkungen. <br><br>  Der Algorithmus absorbiert die Unvollkommenheit der Welt. <img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Wenn wir Daten eines Unternehmens mit rassistischen Politikern als Schulungsbeispiel f√ºr den Einstellungsalgorithmus verwenden, ist der Algorithmus auch rassistisch ausgerichtet. <br><br>  Microsoft hat einmal einem Chatbot beigebracht, auf Twitter zu chatten.  Es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">musste in</a> weniger als einem Tag ausgeschaltet werden, da der Bot Fl√ºche und rassistische Aussagen schnell beherrschte. <br><br><img src="https://habrastorage.org/webt/-o/vn/yb/-ovnybi6tui2yl-e3jewbkjlkae.png"><br><br>  Dar√ºber hinaus kann der Lernalgorithmus einige nicht formalisierte Parameter nicht ber√ºcksichtigen.  Zum Beispiel ist es f√ºr den Algorithmus bei der Berechnung der Empfehlung an den Angeklagten, Schuld auf der Grundlage der gesammelten Beweise zuzugeben oder nicht zuzugeben, schwierig zu ber√ºcksichtigen, wie beeindruckt eine solche Zulassung f√ºr den Richter sein wird, da der Eindruck und die Emotionen nirgendwo aufgezeichnet werden. <br><br><h1>  Falsche Korrelationen und R√ºckkopplungsschleifen </h1><br>  Eine falsche Korrelation besteht darin, dass je mehr Feuerwehrleute in der Stadt sind, desto h√§ufiger Br√§nde auftreten.  Oder wenn es offensichtlich ist, dass das Klima auf dem Planeten umso w√§rmer ist, je weniger Piraten auf der Erde sind. <br><br><img src="https://habrastorage.org/webt/ch/d6/yy/chd6yybu-p8-kwd90abngmtlnm8.jpeg"><br><br>  Die Leute vermuten also, dass Piraten und das Klima nicht direkt miteinander verbunden sind, und es ist nicht so einfach mit Feuerwehrleuten, und das Modell des maschinellen Lernens speichert und verallgemeinert es einfach. <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Bekanntes Beispiel.  Das Programm, bei dem die Patienten nach der Dringlichkeit der Linderung eingestuft wurden, kam zu dem Schluss, dass Asthmatiker mit Lungenentz√ºndung weniger Hilfe ben√∂tigen als nur Menschen mit Lungenentz√ºndung ohne Asthma.  Das Programm untersuchte die Statistiken und kam zu dem Schluss, dass Asthmatiker nicht sterben - warum brauchen sie Priorit√§t?  Und sie sterben nicht wirklich, weil solche Patienten aufgrund eines sehr hohen Risikos sofort die beste Versorgung in medizinischen Einrichtungen erhalten. <br><br>  Schlimmer als falsche Korrelationen sind nur R√ºckkopplungsschleifen.  Ein kalifornisches Kriminalpr√§ventionsprogramm schlug vor, mehr Polizisten in schwarze Viertel zu schicken, basierend auf der Kriminalit√§tsrate (Anzahl der gemeldeten Verbrechen).  Und je mehr Polizeiautos im Sichtbereich sind, desto h√§ufiger melden Anwohner Verbrechen (haben nur jemanden zu melden).  Infolgedessen nimmt die Kriminalit√§t nur noch zu - was bedeutet, dass mehr Polizisten entsandt werden m√ºssen usw. <br><br>  Mit anderen Worten, wenn Rassendiskriminierung ein verhaftender Faktor ist, k√∂nnen R√ºckkopplungsschleifen die Rassendiskriminierung bei polizeilichen Aktivit√§ten verst√§rken und aufrechterhalten. <br><br><h1>  Wer ist schuld? </h1><br>  2016 ver√∂ffentlichte die Big Data-Arbeitsgruppe unter der Obama-Regierung einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bericht, in dem sie</a> vor der ‚Äûm√∂glichen Kodierung von Diskriminierung bei automatisierten Entscheidungen‚Äú warnte und das ‚ÄûPrinzip der Chancengleichheit‚Äú postulierte. <br><br>  Aber etwas zu sagen ist einfach, aber was tun? <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Erstens sind maschinelle Lernmodelle schwer zu testen und zu optimieren.  Zum Beispiel erkannte die Google Foto-App Menschen mit schwarzer Haut wie Gorillas.  Und was tun?  Wenn wir gew√∂hnliche Programme Schritt f√ºr Schritt lesen und lernen, wie man sie testet, h√§ngt alles vom maschinellen Lernen von der Gr√∂√üe der Kontrollprobe ab und kann nicht unendlich sein.  Drei Jahre lang konnte Google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nichts Besseres finden,</a> als die Erkennung von Gorillas, Schimpansen und Affen √ºberhaupt auszuschalten, um eine Wiederholung des Fehlers zu verhindern. <br><br>  Zweitens ist es f√ºr uns schwierig, L√∂sungen f√ºr maschinelles Lernen zu verstehen und zu erkl√§ren.  Zum Beispiel platzierte ein neuronales Netzwerk irgendwie Gewichtskoeffizienten in sich selbst, um die richtigen Antworten zu erhalten.  Und warum fallen sie einfach so aus und was sollte getan werden, um die Antwort zu √§ndern? <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Eine Studie aus dem Jahr 2015 ergab, dass Frauen viel seltener als M√§nner hochbezahlte Stellenausschreibungen sehen, die von Google AdSense ausgeschrieben werden.  Der Lieferservice von Amazon am selben Tag <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">war</a> in den schwarzen Vierteln <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">regelm√§√üig nicht verf√ºgbar</a> .  In beiden F√§llen fiel es den Unternehmensvertretern schwer, solche L√∂sungen f√ºr die Algorithmen zu erkl√§ren. <br><br><h1>  Es bleibt, Gesetze zu erlassen und sich auf maschinelles Lernen zu verlassen </h1><br>  Es stellt sich heraus, dass niemand schuld ist, es bleibt, Gesetze zu verabschieden und die "ethischen Gesetze der Robotik" zu postulieren.  Deutschland hat erst k√ºrzlich, im Mai 2018, ein solches Regelwerk f√ºr unbemannte Fahrzeuge erlassen.  Unter anderem hei√üt es: <br><ul><li>  Die Sicherheit des Menschen hat im Vergleich zu Sch√§den an Tieren oder Eigentum h√∂chste Priorit√§t. </li><li>  Im Falle eines bevorstehenden Unfalls sollte es keine Diskriminierung geben, ohne Grund ist es nicht akzeptabel, zwischen Personen zu unterscheiden. </li></ul><br>  Aber was ist in unserem Kontext besonders wichtig: <br>  Automatische Fahrsysteme werden zu einer <b>ethischen Notwendigkeit,</b> wenn Systeme weniger Unf√§lle verursachen als menschliche Fahrer. <br><br>  Offensichtlich werden wir uns zunehmend auf maschinelles Lernen verlassen - einfach weil es im Allgemeinen besser ist als Menschen. <br><br><h1>  Maschinelles Lernen kann vergiftet werden </h1><br>  Und hier kommen wir zu keinem geringeren Ungl√ºck als der Tendenz der Algorithmen - sie k√∂nnen manipuliert werden. <br><br>  Eine Vergiftung durch maschinelles Lernen (ML-Vergiftung) bedeutet, dass jemand, der am Training des Modells teilnimmt, die vom Modell getroffenen Entscheidungen beeinflussen kann. <br><br>  In einem Computervirus-Analyselabor verarbeitet ein Modellmodell beispielsweise t√§glich durchschnittlich eine Million neue Proben (saubere und sch√§dliche Dateien). <img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right">  Die Bedrohungslandschaft √§ndert sich st√§ndig, daher werden √Ñnderungen im Modell in Form von Antiviren-Datenbankaktualisierungen an die Antivirenprodukte auf der Benutzerseite √ºbermittelt. <br><br>  So kann ein Angreifer st√§ndig sch√§dliche Dateien generieren, die denen einer sauberen sehr √§hnlich sind, und diese an das Labor senden.  Die Grenze zwischen sauberen und sch√§dlichen Dateien wird nach und nach gel√∂scht, das Modell wird "verschlechtert".  Und am Ende kann das Modell die urspr√ºngliche saubere Datei als b√∂sartig erkennen - dies f√ºhrt zu einem falsch positiven Ergebnis. <br><br>  Und umgekehrt: Wenn Sie einen selbstlernenden Spamfilter mit einer Menge sauber generierter E-Mails "spammen", k√∂nnen Sie schlie√ülich Spam erstellen, der durch den Filter geleitet wird. <br><br>  Daher verfolgt Kaspersky Lab einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mehrstufigen Schutzansatz</a> , da wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">uns nicht</a> nur auf maschinelles Lernen verlassen. <br><br>  Ein weiteres Beispiel, w√§hrend fiktiv.  Sie k√∂nnen dem Gesichtserkennungssystem speziell generierte Gesichter hinzuf√ºgen, sodass das System Sie am Ende mit jemand anderem verwechselt.  Denken Sie nicht, dass dies unm√∂glich ist, schauen Sie sich das Bild aus dem n√§chsten Abschnitt an. <br><br><img src="https://habrastorage.org/webt/8f/zx/1m/8fzx1mjghd0aq-e0yfrrsowwhuq.png" align="right"><h1>  Hacking beim maschinellen Lernen </h1><br>  Eine Vergiftung wirkt sich auf den Lernprozess aus.  Es ist jedoch nicht erforderlich, an Schulungen teilzunehmen, um einen Nutzen zu erzielen. Sie k√∂nnen auch ein fertiges Modell t√§uschen, wenn Sie wissen, wie es funktioniert. <br><br><img src="https://habrastorage.org/webt/78/tn/ea/78tneahwtmergijhapcs5cg5no4.png"><br><br><img src="https://habrastorage.org/webt/qq/hf/uv/qqhfuvjsdh5m9t8i8kd-l9wnxqo.png" align="right">  <i>Mit einer speziell gef√§rbten Brille gaben sich die Forscher als andere Menschen aus - als Prominente</i> <br><br>  Dieses Beispiel mit Gesichtern ist in der "Wildnis" noch nicht angetroffen worden - gerade weil noch niemand die Maschine damit beauftragt hat, wichtige Entscheidungen auf der Grundlage der Gesichtserkennung zu treffen.  Ohne menschliche Kontrolle wird es genau wie auf dem Bild sein. <br><br>  Selbst wenn es anscheinend nichts Kompliziertes gibt, ist es f√ºr Uneingeweihte leicht, ein Auto auf unbekannte Weise zu t√§uschen. <br><br><img src="https://habrastorage.org/webt/pb/_6/1b/pb_61bjjv5nnw5kxwxwcbifkm20.png"><br>  <i>Die ersten drei Zeichen werden als ‚ÄûTempolimit 45‚Äú und das letzte als STOP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erkannt</a></i> <br><br><img src="https://habrastorage.org/webt/qq/hf/uv/qqhfuvjsdh5m9t8i8kd-l9wnxqo.png" align="right">  Damit das Modell des maschinellen Lernens die √úbergabe erkennt, m√ºssen keine wesentlichen √Ñnderungen vorgenommen werden. Es sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gen√ºgend minimale</a> √Ñnderungen erforderlich, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">f√ºr eine</a> Person <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unsichtbar sind</a> . <br><br><img src="https://habrastorage.org/webt/_c/du/mj/_cdumjxqnp1ojmvp2i-orq-8uke.png"><br><br>  <i>Wenn Sie dem Panda auf der linken Seite nur minimale spezielle Ger√§usche hinzuf√ºgen, ist maschinelles Lernen sicher, dass <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">es sich um einen</a> Gibbon handelt</i> <br><br><img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right">  W√§hrend eine Person schlauer ist als die meisten Algorithmen, kann sie sie betr√ºgen.  Stellen Sie sich vor, dass in naher Zukunft durch maschinelles Lernen R√∂ntgenbilder von Koffern am Flughafen analysiert und nach Waffen gesucht werden.  Ein kluger Terrorist kann eine spezielle Form neben die Waffe legen und dadurch die Waffe ‚Äûneutralisieren‚Äú. <br><br>  Ebenso wird es m√∂glich sein, das chinesische Sozialbewertungssystem zu ‚Äûhacken‚Äú und die angesehenste Person in China zu werden. <br><br><h1>  Fazit </h1><br>  Lassen Sie uns zusammenfassen, was wir besprochen haben. <br><img src="https://habrastorage.org/webt/p4/ca/et/p4caet8far6cj7xuvafv8e6qddq.png"><br><br><img src="https://habrastorage.org/webt/cr/ng/y6/crngy6nspkfqx_7uxxt_trxffnk.png" align="right"><ol><li>  Es gibt noch keine starke KI. </li><li>  Wir sind entspannt. </li><li>  Durch maschinelles Lernen wird die Anzahl der Opfer in kritischen Bereichen verringert. </li><li>  Wir werden uns immer mehr auf maschinelles Lernen verlassen. </li><li>  Wir werden gute Absichten haben. </li><li>  Wir werden sogar Ethik in das Systemdesign einbringen. </li><li>  Aber die Ethik ist hart formalisiert und in verschiedenen L√§ndern unterschiedlich. </li><li>  Maschinelles Lernen ist aus verschiedenen Gr√ºnden voller Voreingenommenheit. </li><li>  Wir k√∂nnen die L√∂sungen von Algorithmen f√ºr maschinelles Lernen nicht immer erkl√§ren. </li><li>  Maschinelles Lernen kann vergiftet werden. </li><li>  Und sogar "hacken". </li><li>  Ein Angreifer kann auf diese Weise einen Vorteil gegen√ºber anderen Personen erlangen. </li><li>  Maschinelles Lernen hat Auswirkungen auf unser Leben. </li></ol><br>  Und das alles ist die nahe Zukunft. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421791/">https://habr.com/ru/post/de421791/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421779/index.html">OceanLotus: neue Hintert√ºr, alte Pl√§ne</a></li>
<li><a href="../de421783/index.html">Fun State Management Huex Framework</a></li>
<li><a href="../de421785/index.html">Kalifornien steht kurz vor einer vollst√§ndigen Ablehnung von Kohlenstoff bei der Energieerzeugung</a></li>
<li><a href="../de421787/index.html">Projektarchitekturentwicklung, Schiffe und JavaScript</a></li>
<li><a href="../de421789/index.html">Machen Sie das Frontend wieder zum "Backend"</a></li>
<li><a href="../de421793/index.html">Auf der Suche nach den Besten oder wie wir das Blockchain-Netzwerk f√ºr das Projekt ausgew√§hlt haben</a></li>
<li><a href="../de421795/index.html">Datengesteuerte Entscheidung am Beispiel der Auswahl einer Farbe zum Streichen von W√§nden</a></li>
<li><a href="../de421797/index.html">Warum brauchst du Splunk? √úberwachung der IT-Infrastruktur</a></li>
<li><a href="../de421799/index.html">Wie bekomme ich einen Job aus der Ferne in einem Unternehmen, in dem keine Remote-Mitarbeiter besch√§ftigt sind?</a></li>
<li><a href="../de421801/index.html">Der BetterSlack-Erweiterungsautor zieht es auf Antrag von Slack-Anw√§lten zur√ºck</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
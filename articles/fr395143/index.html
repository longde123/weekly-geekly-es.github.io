<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•™ üë©üèæ‚Äçü§ù‚Äçüë©üèº üéª Est-il possible d'introduire l'√©thique dans l'algorithme des robomobiles? ‚ôëÔ∏è üëê üë∞üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pour le meurtre commis par un robot, le programme (et les programmeurs) seront jug√©s 
 Ann√©e 2034. Un homme ivre erre sur le trottoir la nuit, tr√©buch...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Est-il possible d'introduire l'√©thique dans l'algorithme des robomobiles?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/395143/"><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour le meurtre commis par un robot, le programme (et les programmeurs) seront jug√©s</font></font></h4> <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/6cf/75d/315/6cf75d31565a3a88313197090c5b3e4f.jpg" alt="image" align="left"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ann√©e 2034. Un homme ivre erre sur le trottoir la nuit, tr√©buche et tombe juste devant le robot, qui le frappe et le tue sur le coup. S'il y avait une personne au volant d'une voiture, la mort serait reconnue comme un accident, car la faute incomberait au pi√©ton, et pas un seul conducteur ne pourrait l'esquiver. Mais les normes pour le "conducteur moyen" (le terme " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">personne raisonnable</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> " est </font><font style="vertical-align: inherit;">pr√©sent dans la l√©gislation √©trang√®re </font><font style="vertical-align: inherit;">) ont disparu dans les ann√©es 2020, lorsque la propagation des robots a r√©duit le nombre d'accidents de 90%. Maintenant, nous devons parler du "robot moyen".</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La famille de la victime poursuit le constructeur de v√©hicules robotis√©s, affirmant que bien que la voiture n'ait pas eu le temps de freiner, elle pourrait contourner un pi√©ton, traverser un double solide et entrer en collision avec un robot venant en sens inverse. La reconstitution de l'incident √† partir de capteurs robotis√©s de v√©hicules le confirme. L‚Äôavocat de la demanderesse, interrogeant un grand d√©veloppeur de logiciels automobiles, demande: ¬´Pourquoi la voiture n‚Äôa-t-elle pas tourn√© le dos?¬ª</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aujourd'hui, le tribunal ne demande pas aux conducteurs pourquoi ils ont fait ou non quelque chose. La question est discutable, car la personne se trompe - le conducteur peut paniquer, ne pas y penser, r√©agir √† l'instinct. Mais lorsque le robot conduit la voiture, la question est "pourquoi?" tout √† fait acceptable. Les normes √©thiques des gens, qui ne sont pas tr√®s bien √©nonc√©es dans les lois, font de nombreuses hypoth√®ses diff√©rentes auxquelles les ing√©nieurs n'ont tout simplement pas abouti. Le plus important d'entre eux - une personne peut comprendre quand vous devez vous √©carter de la lettre de la loi afin de pr√©server son esprit. D√©sormais, les ing√©nieurs doivent enseigner aux machines et autres robots comment prendre des d√©cisions intelligentes.</font></font><br>
 <a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'informatisation du processus de contr√¥le a commenc√© dans les ann√©es 1970, lorsque </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">des syst√®mes de freinage antiblocage sont</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> apparus </font><font style="vertical-align: inherit;">. Maintenant, chaque ann√©e, il y a des d√©veloppements tels que la direction automatique, l'acc√©l√©ration automatique et le freinage d'urgence. Les essais de machines enti√®rement automatiques, bien qu'avec la participation d'un conducteur humain, sont d√©j√† autoris√©s dans certains endroits en Grande-Bretagne, en Hollande, en Allemagne et au Japon. Aux √âtats-Unis, elle est </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">autoris√©e par la loi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dans quatre √âtats et le district de Columbia, et au moins elle n'est pas interdite dans les autres. Google, Nissan et Ford affirment que les robots motoris√©s appara√Ætront dans 5 √† 10 ans.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les v√©hicules automatiques collectent des informations environnementales √† partir de capteurs - cam√©ras vid√©o, t√©l√©m√®tres √† ultrasons, radars, lidars. En Californie, les robomobiles sont tenues de fournir au minist√®re des Transports toutes les donn√©es du capteur 30 secondes avant toute collision qui s'est d√©j√† suffisamment accumul√©e, y compris la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">collision provoqu√©e par la machine Google</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Les ing√©nieurs ont la possibilit√© de r√©cup√©rer des √©v√©nements dans la zone de collision de fa√ßon assez pr√©cise, en utilisant des enregistrements de ce que la machine pourrait capturer, des alternatives qu'elle consid√®re et de la logique de comportement. L'ordinateur peut √™tre amen√© √† r√©p√©ter son raisonnement - la fa√ßon dont il peut √™tre demand√© √† la personne qui a jou√© au jeu ou au simulateur de conduite.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les r√©gulateurs et les justiciables seront en mesure de maintenir des normes de s√©curit√© surhumaines pour les v√©hicules robotis√©s et d'examiner de mani√®re approfondie les collisions qui se produiront de toute fa√ßon - quoique rarement. Les fabricants et les programmeurs prot√©geront les actions de leurs produits d'une mani√®re dont les conducteurs d'aujourd'hui n'ont jamais r√™v√©. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La conduite est toujours un risque et les d√©cisions concernant sa r√©partition entre les conducteurs, les pi√©tons, les cyclistes et les biens contiennent une composante √©thique. Pour les ing√©nieurs comme pour tous, il est important que le syst√®me d√©cisionnel de la machine p√®se les cons√©quences √©thiques de ses actions. </font></font><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/044/821/2c5/0448212c5220abb6d9a7ea75f1ea180e.jpg" alt="image"><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c91/7bc/856/c917bc856aeb4a4a9db81c2671b21106.jpg" alt="image"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Collision Google Car avec un bus</font></font></i><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La r√©ponse habituelle aux situations moralement ambigu√´s est de respecter la loi tout en minimisant les dommages. La strat√©gie est attrayante - elle permet non seulement au d√©veloppeur de d√©fendre facilement les actions de la voiture (¬´Nous avons suivi la loi compl√®tement¬ª), mais transf√®re √©galement la responsabilit√© de d√©terminer l'√©thique aux l√©gislateurs. Malheureusement, cela impose √©galement un fardeau trop lourd √† la loi.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Par exemple, dans la plupart des √âtats, la loi s'appuie sur le bon sens des conducteurs et ne dit pas grand-chose sur le comportement avant une collision. Dans l'exemple d√©crit, la voiture, strictement conforme √† la lettre de la loi, ne traverse pas le double solide, risquant une collision avec un ivrogne - bien qu'il n'y ait qu'un robot motoris√© vide de l'autre c√¥t√© de la route. La loi fait rarement des exceptions dans des cas d'urgence sp√©cifiques comme une personne qui tombe sur la chauss√©e - et s'il le fait, comme c'est la coutume, par exemple, en Virginie, le texte de la loi implique que le franchissement d'un double solide est l√©gal jusqu'√† ce que la voiture s'√©crase. ("Si un tel mouvement peut √™tre effectu√© en toute s√©curit√©"). Dans ce cas, les d√©veloppeurs devront d√©cider - dans quels cas il sera s√ªr de traverser le double solide.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un Robomobile sera rarement s√ªr √† 100% que la route est vide et vous pouvez traverser un double solide sans crainte. Il √©valuera le niveau de confiance √† 98%, soit 99,99%. Les ing√©nieurs devront d√©cider √† l'avance du niveau de confiance suffisant pour traverser un double solide et de la mani√®re dont la valeur acceptable peut varier en fonction de ce que la robotique essaie d'√©viter sur la route - est-ce un sac en plastique ou un pi√©ton tomb√©. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
D√©j√†, les robomobiles prennent des d√©cisions sur la possibilit√© d'enfreindre la loi. </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Google a admis</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">que ses voitures sont autoris√©es √† d√©passer la vitesse afin de rester dans le courant - o√π ralentir est dangereux. La plupart des gens pr√©f√®rent d√©passer la vitesse dans diverses situations, par exemple, lorsqu'ils essaient de se pr√©cipiter √† l'h√¥pital. Chris Gerdes [Chris Gerdes] et Sarah Thornton de l'Universit√© de Stanford </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">contre l'</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> inclusion stricte des lois dans les algorithmes de prise de d√©cision, car les conducteurs semblent consid√©rer les lois suffisamment flexibles pour √©valuer le co√ªt de leur rupture par rapport au gain potentiel de vitesse. Personne ne veut ramper apr√®s un cycliste sur plusieurs kilom√®tres car votre voiture refuse d'appeler au moins un peu pour un double solide.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Et m√™me en respectant la loi, le robot peut prendre de nombreuses petites d√©cisions qui sont sensibles du point de vue de la s√©curit√©. En r√®gle g√©n√©rale, les voies sur l'autoroute sont presque deux fois plus larges qu'une voiture typique, et les conducteurs peuvent utiliser cette largeur pour √©viter les ordures ou pour s'√©loigner des voitures √† conduite irr√©guli√®re. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans le brevet de 2014, Google </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">d√©veloppe cette id√©e et d√©crit</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> comment un robot peut √™tre plac√© sur une bande pour r√©duire les risques. La soci√©t√© donne un exemple de robot motoris√© sur une route √† trois voies avec un camion √† droite et une petite voiture √† gauche. Pour optimiser la s√©curit√©, le robot doit avoir boug√© un peu vers la gauche, plus pr√®s dans une petite machine.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il a l'air sain, et g√©n√©ralement tout le monde le fait - consciemment ou inconsciemment. Mais des questions √©thiques se posent. En se dirigeant vers la petite machine, le robot a r√©duit le risque, mais l'a in√©galement r√©parti. Une petite machine devrait-elle prendre plus de risques simplement parce qu'elle est petite? S'il s'agissait de pr√©f√©rences pour un conducteur particulier, il ne signifierait rien. Mais si une telle redistribution est formalis√©e et √©tendue √† tous les robots, les cons√©quences seront plus graves.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans chaque exemple, le robot motoris√© prend en compte plusieurs valeurs - la valeur de l'objet qu'il peut heurter et la valeur de son passager. Les gens prennent des d√©cisions instinctivement, et le robot le fera sur la base d'une strat√©gie de gestion des risques m√ªrement r√©fl√©chie qui d√©finit le risque comme la quantit√© de dommages d'un √©v√©nement ind√©sirable, multipli√©e par sa probabilit√©.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En 2014, Google a √©galement brevet√© une application de gestion des risques. Le brevet d√©crit une machine qui peut d√©cider de reconstruire afin de mieux voir le feu de circulation. Ou la voiture peut d√©cider de rester dans la voie pour √©viter le risque de collision - par exemple, en raison des indications d'un capteur d√©fectueux - mais au prix de cela sera une mauvaise visibilit√© du feu de circulation. Le r√©sultat de l'une des d√©cisions est attribu√© une probabilit√©, ainsi qu'une valeur positive ou n√©gative (avantage ou perte). Chaque valeur est multipli√©e par la probabilit√© et les valeurs obtenues peuvent √™tre additionn√©es. Si les avantages l'emportent suffisamment sur les pertes, la machine manoeuvrera. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le probl√®me est que le risque de collision est tr√®s faible - le conducteur moyen aux √âtats-Unis subit un accident une fois tous les 257 000 kilom√®tres, ou une fois tous les 12 ans ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en Russie - une fois tous les 1,6 ans</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Cette diff√©rence est peut-√™tre due au fait qu'aux √âtats-Unis, les gens voyagent beaucoup plus souvent sur l'autoroute - env. Par cons√©quent, m√™me en commen√ßant √† recevoir un √©norme flux de donn√©es des robots lorsque ceux-ci descendent dans la rue, nous serons en mesure d'obtenir tr√®s prochainement des estimations des probabilit√©s de divers √©v√©nements.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Estimer le co√ªt des dommages est encore plus difficile. Les dommages mat√©riels sont faciles √† √©valuer - les assureurs ont une vaste exp√©rience dans ce domaine - mais les blessures et les d√©c√®s sont une autre affaire. L‚Äôhistorique de l‚Äôappropriation de la vie d‚Äôune personne, quelle que soit sa valeur, a de nombreuses ann√©es et s‚Äôexprime g√©n√©ralement par le montant d‚Äôargent qui pourrait √™tre d√©pens√© pour pr√©venir la victime moyenne. Une am√©lioration de la s√©curit√©, avec 1% de chances de sauver la vie de 100 personnes, est une victime moyenne. Le minist√®re des Transports recommande de d√©penser 9,1 millions de dollars pour √©viter les pertes. Le nombre est d√©riv√© des donn√©es de marketing, y compris les allocations dont les gens ont besoin pour un travail dangereux et les montants que les gens sont pr√™ts √† d√©penser pour l'√©quipement de s√©curit√© - par exemple, les avertisseurs de fum√©e. Vous devez peser non seulement la s√©curit√©, mais aussi la perte de mobilit√© ou de temps,d√©pens√©s sur la route, que le Minist√®re estime √† 26,44 $ l'heure.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En mots, tout est beau. Mais l'√©valuation des risques li√©s aux vies perdues et au temps pass√© sur la route n'inclut pas diff√©rentes √©valuations morales de la fa√ßon dont nous mettons les gens en danger. Par exemple, un robot motoris√©, √©valuant la vie de toutes les personnes de la m√™me mani√®re, devrait donner plus d'espace √† un motocycliste sans casque qu'√† un motocycliste en tenue compl√®te, car le premier sera moins susceptible de survivre. Mais c'est injuste - est-il possible de punir pour avoir pris soin de votre s√©curit√©?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une autre diff√©rence entre l'√©thique des robots et celle des humains est que l'√©thique des premiers peut √™tre d√©form√©e par les programmeurs, m√™me pour une bonne raison. Imaginez que l'algorithme ajuste la taille de la zone tampon pour les pi√©tons dans diff√©rentes zones sur la base de l'analyse du montant de l'indemnisation pour les r√©clamations d√©pos√©es par les pi√©tons dans un accident. D'une part, il est raisonnable, efficace et bien intentionn√©. D'un autre c√¥t√©, des p√©nalit√©s moins importantes peuvent d√©pendre du revenu moyen des personnes dans une zone particuli√®re. Ensuite, l'algorithme punira les pauvres en leur donnant une zone tampon plus petite, augmentant ainsi l√©g√®rement leur risque d'√™tre abattu.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il y a une tentation d'√©carter des questions telles que purement acad√©miques, mais vous ne pouvez pas les contourner, car les programmes prennent tout au sens propre. Vous devrez √©valuer les cons√©quences des actions avant qu'elles ne soient ex√©cut√©es - au stade du d√©veloppement, et non au stade de la cr√©ation des correctifs pour les logiciels. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En partie √† cause de cela, les chercheurs utilisent des situations hypoth√©tiques dans lesquelles une machine doit choisir entre deux maux. L'une des t√¢ches les plus c√©l√®bres de ce type est le probl√®me d'un chariot. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Un chariot lourd non contr√¥l√© est transport√© sur des rails. Sur son chemin, cinq personnes sont attach√©es aux rails par un philosophe fou. Heureusement, vous pouvez basculer la fl√®che - puis le chariot suivra un itin√©raire diff√©rent et alternatif. Malheureusement, il y a une personne sur le rev√™tement, √©galement attach√©e aux rails. Quelles sont vos actions?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Allez-vous sacrifier une vie pour plusieurs? </font><font style="vertical-align: inherit;">Sinon, √† cause de votre inaction, les gens mourront toujours, alors comment pouvez-vous faire face √† cette contradiction?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Des livres ont √©t√© √©crits sur les sujets de telles exp√©riences, et ils vous permettent de tester des syst√®mes simples et directs qui traitent des questions √©thiques et de trouver des domaines o√π il serait agr√©able de se plonger dans certaines des nuances. </font><font style="vertical-align: inherit;">Supposons que nous programmions un robot pour √©viter √† tout prix les pi√©tons. </font><font style="vertical-align: inherit;">Si un pi√©ton appara√Æt soudainement dans un tunnel √† deux voies et que la voiture ne peut pas freiner √† temps, elle devra d√©sactiver la voie, m√™me si elle est sur le chemin d'un bus avec des passagers. </font><font style="vertical-align: inherit;">La probabilit√© d'un tel √©v√©nement n'est pas aussi importante que le probl√®me qu'il expose dans la logique de la voiture robot - que la sup√©riorit√© absolue de la valeur d'un pi√©ton sur toutes les autres personnes utilisant la chauss√©e peut √™tre tr√®s dangereuse.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'√©thique en robotique est une t√¢che r√©soluble. </font><font style="vertical-align: inherit;">Nous le savons car dans d'autres domaines, nous avons d√©j√† trouv√© la possibilit√© de g√©rer √† peu pr√®s les m√™mes risques et avantages de mani√®re s√ªre et raisonnable. </font><font style="vertical-align: inherit;">Les organes des donneurs sont distribu√©s aux patients sur la base d'une m√©trique calcul√©e √† partir des ann√©es de vie potentielles et de la qualit√© de leur vie. </font><font style="vertical-align: inherit;">Les personnes exer√ßant des professions n√©cessaires comme agriculteur et enseignant sont exempt√©es de la conscription militaire.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Les t√¢ches des robomobiles sont plus compliqu√©es. </font><font style="vertical-align: inherit;">Ils doivent d√©cider rapidement, sur la base d'informations incompl√®tes, dans des situations que les programmeurs n'auraient peut-√™tre pas pr√©vu d'utiliser une √©thique qui doit √™tre int√©gr√©e trop litt√©ralement √† l'algorithme. </font><font style="vertical-align: inherit;">Heureusement, les gens n'attendent pas d'eux une sagesse surhumaine - seulement une justification rationnelle des actions d'une machine qui √©value les questions √©thiques. </font><font style="vertical-align: inherit;">La solution ne doit pas √™tre parfaite - mais r√©fl√©chie et susceptible d'√™tre prot√©g√©e.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr395143/">https://habr.com/ru/post/fr395143/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr395129/index.html">Pr√©sentation du routeur Draytek s√©rie 2912. Deuxi√®me partie</a></li>
<li><a href="../fr395131/index.html">Firefox vous permet d'acc√©der √† des sites sous plusieurs comptes en m√™me temps</a></li>
<li><a href="../fr395137/index.html">Ouverture √† distance d'un compte de courtage via le portail des services de l'√âtat: pourquoi et comment le faire</a></li>
<li><a href="../fr395139/index.html">Donnerons-nous aux robots militaires une licence pour tuer?</a></li>
<li><a href="../fr395141/index.html">Des signets de navigateur √† une nouvelle √®re: un peu sur l'histoire du d√©veloppement des services de boutons sociaux</a></li>
<li><a href="../fr395145/index.html">Demandez √† Ethan n ¬∞ 59: Qu'est-ce que l'√©nergie noire?</a></li>
<li><a href="../fr395147/index.html">Le SUV Mitsubishi Outlander s'introduit facilement par Wi-Fi</a></li>
<li><a href="../fr395149/index.html">Une nouvelle explication du principe du moteur "impossible" EmDrive: ce sont tous des photons</a></li>
<li><a href="../fr395151/index.html">Climatique dans votre maison. Annonce TION MagicAir</a></li>
<li><a href="../fr395153/index.html">Ajouter Furigan √† la macro Kanji Python pour LibreOffice</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
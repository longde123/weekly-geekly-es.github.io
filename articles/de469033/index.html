<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßíüèΩ üëá üôç Starten der Elbrus-Plattform f√ºr neuronale PuzzleLib-Netzwerke üí° üëàüèº üë©üèª‚Äçüé§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="KI auf h√§uslichem Eisen 
 Wir sprechen dar√ºber, wie wir unser Framework f√ºr neuronale Netze und Gesichtserkennungssysteme auf russische Elbrus-Prozess...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Starten der Elbrus-Plattform f√ºr neuronale PuzzleLib-Netzwerke</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ashmanov_net/blog/469033/"><h3>  KI auf h√§uslichem Eisen </h3><br>  Wir sprechen dar√ºber, wie wir unser Framework f√ºr neuronale Netze und Gesichtserkennungssysteme auf russische Elbrus-Prozessoren portiert haben. <br><br><img src="https://habrastorage.org/webt/e3/sq/qz/e3sqqz_1suglr-i19vtkvjaj3l4.png" alt="Bild"><br><br>  Es war eine interessante Aufgabe, im Fr√ºhjahr 2019 haben wir im Yandex-B√ºro √ºber das gro√üe Treffen √ºber Elbrus gesprochen, das wir jetzt mit Habr teilen. <br><a name="habracut"></a><br><h3>  Kurz - was ist Elbrus? </h3><br>  Dies ist ein russischer Prozessor mit eigener Architektur, der am <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MCST entwickelt wurde</a> .  Maxim Gorshenin spricht auf seinem Kanal gut √ºber ihn: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">www.youtube.com/watch?v=H8eBgJ58EPY</a> <br><br><h3>  Kurz gesagt - was ist PuzzleLib? </h3><br>  Dies ist unsere Plattform f√ºr neuronale Netze, die wir seit 2015 entwickeln und nutzen.  Analog zu Google TensorFlow und Facebook PyTorch.  Interessanterweise unterst√ºtzt PuzzleLib nicht nur NVIDIA- und Intel-Prozessoren, sondern auch AMD-Grafikkarten. <br><br>  Obwohl wir eine kleine Bibliothek haben (TensorFlow hat ungef√§hr 2 Millionen Zeilen, wir haben 100.000), sind wir schneller - ein bisschen, aber besser =) <br><br>  Wir sind noch nicht in Open Source, die Bibliothek wird f√ºr unsere Projekte verwendet.  Die Bibliothek ist vollst√§ndig: Sie unterst√ºtzt sowohl die Trainingsphase als auch die Inferenzphase neuronaler Netze.  Sie k√∂nnen wiederkehrende, faltungsbedingte neuronale Netze erstellen. Au√üerdem gibt es eine Schnittstelle zum Erstellen beliebiger Berechnungsgraphen. <br><br><h4>  PuzzleLib hat </h4><br><ul><li>  Module zum Aufbau neuronaler Netze (Aktivierung (Sigmoid, Tanh, ReLU, ELU, LeakyReLU, SoftMaxPlus), AvgPool (1D, 2D, 3D), BatchNorm (1D, 2D, 3D, ND), Conv (1D, 2D, 3D, ND) , CrossMapLRN, Deconv (1D, 2D, 3D, ND), Dropout (1D, 2D) usw.) </li><li>  Optimierer (AdaDelta, AdaGrad, Adam, Hooks, LBFGS, MomentumSGD, NesterovSGD, RMSProp usw.) </li><li>  Gebrauchsfertige neuronale Netze (Resnet, Inception, YOLO, U-Net usw.) </li></ul><br>  Dies sind die vertrauten, allen an neuronalen Netzen beteiligten Bl√∂cke f√ºr Entwickler neuronaler Netze (da alle Frameworks Konstruktoren sind, die aus typischen Rechenbl√∂cken und Algorithmen bestehen). <br><br>  <b>Wir hatten die Idee, unsere Bibliothek √ºber Elbrus-Architektur zu starten.</b> <b><br></b> <br><br><h3>  Warum wollten wir Elbrus unterst√ºtzen? </h3><br><ol><li>  Dies ist der einzige russische Prozessor, ich wollte verstehen, wie die Dinge damit laufen, wie einfach es ist, damit zu arbeiten. </li><li>  Wir dachten, dass es f√ºr staatliche Organisationen interessant sein k√∂nnte, dass die russische Software, die wir entwickeln, auf russischer Hardware funktioniert. </li><li>  Und nat√ºrlich waren wir nur interessiert, denn Elbrus ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VLIW-Prozessor</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dh</a> ein Prozessor mit langen Anweisungen, und es gibt keine derart vollwertigen Allzweckprozessoren auf der Welt. </li></ol><br>  Alles begann mit der Tatsache, dass wir uns mit dem MCST getroffen, gesprochen und den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Elbrus 401-</a> Computer zur Entwicklung ausgeliehen haben. <br><br>  <b>Was mir gefallen hat</b> : Linux l√§uft unter Elbrus, es gibt Python in diesem Linux und es funktioniert nicht im Emulationsmodus - es ist eine vollwertige, native Python, die f√ºr Elbrus zusammengestellt wurde.  Es gibt auch ein B√ºndel von Standard-Python-Bibliotheken, zum Beispiel numpy, die alle Entwickler sehr lieben. <br><br>  Es gab einige Aufgaben, f√ºr die wir zus√§tzlich Bibliotheken sammeln mussten: In PuzzleLib verwenden wir beispielsweise das HDF-Format, um die Gewichte neuronaler Netze zu speichern, und dementsprechend mussten wir die Bibliotheken libhdf und h5py mit dem lcc-Compiler erstellen.  Wir hatten aber keine Montageprobleme. <br><br>  Die OpenCV-Computer-Vision-Bibliothek wurde ebenfalls bereits kompiliert, es gab jedoch keine Bindung f√ºr Python - wir haben sie separat erstellt. <br><br>  Die ber√ºhmte dlib-Bibliothek ist auch ziemlich einfach zu kompilieren.  Es gab nur geringf√ºgige Schwierigkeiten: Einige Dateien dieses Open-Source-Projekts hatten keinen Bom-Marker zur Bestimmung von utf-8, was den lcc-Lexer ver√§rgerte.  Eigentlich gab es einfach ein falsches Dateiformat, das in der Quelle korrigiert werden musste. <br><br>  Wir haben uns entschlossen, zuerst mit der Gesichtserkennung zu beginnen.  Dies ist ein verst√§ndlicher Anwendungsfall f√ºr viele, bei denen diese Technologie verwendet wird.  PuzzleLib hat wie andere Bibliotheken einen ziemlich gro√üen Backend-Teil, dh eine Codebasis, die f√ºr verschiedene Prozessorarchitekturen spezifisch ist. <br><br>  <b>Unsere Backends:</b> <br><br><ul><li>  CUDA (NVIDIA) </li><li>  √ñffnen Sie CL + MI Open (AMD) </li><li>  mlkDNN (Intel) </li><li>  CPU (numpy) </li></ul><br>  Auf Elbrus haben wir ein numpy Backend gestartet, das sehr einfach war, da die Plattform ein Minimum von allem erfordert: <br><br>  <i>Plattform -&gt; c90-Compiler -&gt; Python -&gt; Numpy</i> <br><br>  Wir haben eine Bibliothek ohne komplizierende Faktoren (zum Beispiel ohne spezielle Montagesysteme) - zus√§tzlich zu der Tatsache, dass wir bestimmte Ordner sammeln mussten.  Wir haben die Tests durchgef√ºhrt, alles funktioniert - sowohl Faltungsgitter als auch wiederkehrende.  Die Gesichtserkennung, die wir gestartet haben, ist ziemlich einfach und basiert auf Inception-ResNet. <br><br>  <b>Erste Arbeitsergebnisse</b> <br><br>  Auf dem Intel Core i7 7700 betrug die Verarbeitungszeit f√ºr ein Bild 0,1 Sekunden und hier - 15. Es war eine Optimierung erforderlich. <br><br>  Zu hoffen, dass Numpy im laufenden Betrieb gut funktioniert, w√§re nat√ºrlich falsch. <br><br><h3>  Wie wir das Computing optimiert haben </h3><br>  Wir haben die Inferenzgeschwindigkeit √ºber den Python-Profiler gemessen und festgestellt, dass fast die gesamte Zeit damit verbracht wurde, Matrizen in Numpy zu multiplizieren.  F√ºr das Beispiel haben sie die einfachste manuelle Multiplikation der Matrix geschrieben, und es hat sich bereits als schneller herausgestellt, obwohl nicht klar war, warum. <br><br>  Es scheint, dass numpy.dot etwas weniger naiv geschrieben sein sollte als eine so einfache Multiplikation.  Trotzdem haben wir √ºberzeugt, √ºberpr√ºft - es stellte sich heraus, schneller (12 Sekunden pro Bild statt 15). <br><br>  Als n√§chstes lernten wir die lineare Algebra-Bibliothek EML kennen, die bei ICST entwickelt wird, und ersetzten np.dot-Aufrufe durch cblas_sgemm.  Es wurde 10 mal schneller (1,5 Sekunden) - wir waren sehr zufrieden. <br><br>  Es folgten mehrere schrittweise Optimierungen.  Da wir nur die Gesichtserkennung und im Allgemeinen keine willk√ºrlichen Daten ausf√ºhren, haben wir beschlossen, unsere Operationen nur unter 4d-Tensoren zu sch√§rfen und Fusion - danach verringerte sich die Verarbeitungszeit um das Zweifache - auf 0,75 Sekunden. <br><br>  Erl√§uterung: Fusion ist, wenn mehrere Operationen zu einer zusammengefasst werden, z. B. Faltung, Normalisierung und Aktivierung.  Anstatt einen Durchgang in drei Zyklen durchzuf√ºhren, wird ein Durchgang durchgef√ºhrt. <br><br>  Solche Bibliotheken sind bei NVIDIA ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorRT</a> ) erh√§ltlich.  Ein Rechengraph wird in ihn geladen, und die Bibliothek erzeugt einen optimierten, beschleunigten Graphen, insbesondere aufgrund der Tatsache, dass Operationen zu einem zusammengefasst werden k√∂nnen.  Intel hat auch eine √§hnliche (nGraph und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenVINO</a> ). <br><br>  Dann haben wir gesehen, dass wir, da es in Inception-ResNet viele 1x1-Faltungen gab, zus√§tzliche Daten kopieren mussten.  Wir haben uns auf die Tatsache spezialisiert, dass wir Stapel von 1 Foto bearbeiten (dh nicht 100 Fotos in Stapeln verarbeiten, sondern Streaming-Modus bereitstellen). Es gibt solche Anwendungsf√§lle, in denen Sie nicht mit Archiven, sondern mit einem Stream arbeiten m√ºssen (z. B. zur Video√ºberwachung oder ACS).  Wir haben eine spezielle Passage ohne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im2col erstellt</a> (gro√üe Kopien entfernt) - es wurden 0,45 Sekunden. <br><br>  Dann sahen wir uns noch einmal den Profiler an, wir hatten alles auf die gleiche Weise - obwohl alle Stufen mit der Zeit schrumpften, verbrachten wir immer noch 80% der Zeit mit der Berechnung von Faltungsinferenzbl√∂cken. <br>  Wir erkannten, dass wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gemm</a> parallelisieren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mussten</a> (allgemeine Matrixmultiplikation).  Dieser Edelstein, der sich in EML als Single-Threaded herausstellte.  Dementsprechend mussten wir selbst Multithread-Edelsteine ‚Äã‚Äãschreiben.  Die Idee ist folgende: Eine gro√üe Matrix wird in Unterbl√∂cke unterteilt, und dann gibt es eine Multiplikation dieser kleinen Matrizen.  Wir haben ein Gemm mit OpenMP geschrieben, aber es hat nicht funktioniert, Fehler sind abgest√ºrzt.  Wir haben einen manuellen Pool von Threads erstellt, die Parallelisierung ergab 0,33 Sekunden pro Frame. <br><br>  Als n√§chstes erhielten wir Fernzugriff auf einen leistungsst√§rkeren Server mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Elbrus 8C</a> , bei dem die Geschwindigkeit auf 0,2 Sekunden pro Frame erh√∂ht wurde. <br><br>  Das folgende Video zeigt die Arbeit des Demo-St√§nders mit Gesichtserkennung auf einem Elbrus 401-PC mit einem Elbrus 4C-Prozessor: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/iNMRKQqNM1Q" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Schlussfolgerungen und Zukunftspl√§ne </h3><br><ul><li>  Wir arbeiten nicht nur an der Gesichtserkennung, sondern im Prinzip an einem neuronalen Netzwerk-Framework, damit wir alle Detektoren und Klassifikatoren sammeln und auf Elbrus ausf√ºhren k√∂nnen. </li><li>  Wir haben einen Demo-Stand mit Web-UI zusammengestellt, um die Gesichtserkennung auf PuzzleLib zu demonstrieren. <br></li><li>  Die Gesichtserkennung auf Elbrus ist bereits schnell genug f√ºr praktische Aufgaben, dann k√∂nnen Sie sie bei Bedarf beschleunigen. </li><li>  Sie k√∂nnen mit Elbrus arbeiten.  Fr√ºher haben wir mit exotischen Prozessoren gearbeitet - zum Beispiel mit russischen Tensorprozessoren, die sich noch in der Entwicklung befinden, mit AMD-Grafikkarten und deren Software.  Dort ist nicht alles so gut und einfach.  Das hei√üt, wenn wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MI Open-</a> Bibliothek von AMD nehmen, ist dies eine sehr schlecht geschriebene Bibliothek, in der nicht alle Kombinationen von Schritten, Auff√ºllungen und Filtergr√∂√üen zu erfolgreichen Berechnungen f√ºhren.  Die Qualit√§t der Tools von Elbrus ist gut - wenn Sie ein Projekt in Python, C oder C ++ haben, ist es √ºberhaupt nicht schwierig, es auf Elbrus auszuf√ºhren. </li><li>  Es ist auch erw√§hnenswert, dass die Arbeit an der schrittweisen Optimierung, √ºber die wir gesprochen haben, keine spezifischen Operationen f√ºr die Arbeit in Elbrus sind.  Dies sind Standard-Multi-Core-Prozessoroperationen.  Unserer Meinung nach ist dies ein gutes Zeichen daf√ºr, dass der Prozessor wie ein normaler Prozessor von Intel / NVIDIA betrieben werden kann. <br></li></ul><br><h4>  Pl√§ne: </h4><br><ul><li>  Da Elbrus insofern eine Besonderheit aufweist, als es sich um einen VLIW-Prozessor handelt, k√∂nnen einige f√ºr Elbrus spezifische Optimierungen durchgef√ºhrt werden. <br></li><li>  F√ºhren Sie eine Quantisierung durch (arbeiten Sie mit int8 anstelle von float32), wodurch Speicherplatz gespart und die Geschwindigkeit erh√∂ht wird.  Dementsprechend kann es in diesem Fall nat√ºrlich zu einem Qualit√§tsverlust der Berechnungen kommen - dies ist jedoch m√∂glicherweise nicht der Fall.  Wir haben beide F√§lle in der Praxis bemerkt. </li></ul><br>  Wir planen, die Funktionen des VLIW-Prozessors besser zu verstehen und zu erkunden.  Im Moment haben wir dem Compiler nur vertraut, dass der Compiler ihn gut optimiert, wenn wir guten Code schreiben, da er die Funktionen von Elbrus kennt. <br><br>  Im Allgemeinen war es interessant, wir werden weiter verstehen.  Dies dauerte nicht lange - alle Portierungsvorg√§nge dauerten insgesamt eine Woche. <br><br>  Im Januar 2020 planen wir, PuzzleLib in Open Source zu bringen, wir werden hier mehr dar√ºber schreiben =) <br>  Vielen Dank f√ºr Ihre Aufmerksamkeit! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de469033/">https://habr.com/ru/post/de469033/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de469021/index.html">Entwicklung in einem Monorepository. Yandex-Bericht</a></li>
<li><a href="../de469023/index.html">So finden Sie einen Job mit Umzug nach Europa: ein praktischer Leitfaden f√ºr IT-Experten</a></li>
<li><a href="../de469025/index.html">K√ºhlen Sie den Wein schnell ab! Russische Erfindung</a></li>
<li><a href="../de469027/index.html">Ivanovo! Mitap: Wie baue ich eine Karriere in Digital auf?</a></li>
<li><a href="../de469031/index.html">12 neue k√ºnstliche Intelligenz f√ºr Azure Media Services</a></li>
<li><a href="../de469035/index.html">Die neuen AI-basierten Innovationen von Azure Media Services</a></li>
<li><a href="../de469037/index.html">Industrielle Steuerung. Datenerfassungssystem. ACS</a></li>
<li><a href="../de469039/index.html">Mehr als ein Spiel: Mahjong mit KI und maschinellem Lernen meistern</a></li>
<li><a href="../de469041/index.html">Wie sch√ºtzen Sie Ihr ERP-System?</a></li>
<li><a href="../de469043/index.html">C / C ++ von Python (C API)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
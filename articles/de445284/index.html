<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ‚Äçü§ù‚Äçüë®üèª ‚ö∞Ô∏è ü§ê ClickHouse Product Analytics VKontakte üç£ üë®‚Äçüë©‚Äçüë¶‚Äçüë¶ üê§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bei der Entwicklung eines Produkts, sei es ein Videodienst oder ein Band, Geschichten oder Artikel, m√∂chte ich das bedingte "Gl√ºck" des Benutzers mess...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ClickHouse Product Analytics VKontakte</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vk/blog/445284/"><img src="https://habrastorage.org/webt/0f/oi/nf/0foinfaynjgjrh11h6w55fr5510.jpeg"><br><br>  Bei der Entwicklung eines Produkts, sei es ein Videodienst oder ein Band, Geschichten oder Artikel, m√∂chte ich das bedingte "Gl√ºck" des Benutzers messen k√∂nnen.  Zu verstehen, ob wir unsere √Ñnderungen verbessern oder verschlechtern, die Richtung der Produktentwicklung anzupassen und uns dabei nicht auf die Intuition und unsere eigenen Gef√ºhle zu verlassen, sondern auf Metriken und Zahlen, an die Sie glauben k√∂nnen. <br><br>  In diesem Artikel werde ich Ihnen erl√§utern, wie wir es geschafft haben, Produktstatistiken und -analysen f√ºr einen Service mit einer monatlichen Zielgruppe von 97 Millionen zu starten und dabei √§u√üerst leistungsstarke analytische Anfragen zu erhalten.  Wir werden √ºber ClickHouse, die verwendeten Engines und die Funktionen der Abfragen sprechen.  Ich werde einen Ansatz zur Datenaggregation beschreiben, mit dem wir in Sekundenbruchteilen komplexe Metriken erhalten und √ºber Datenkonvertierung und -tests sprechen k√∂nnen. <br><br>  Jetzt haben wir ungef√§hr 6 Milliarden Lebensmittelereignisse pro Tag, in naher Zukunft werden wir 20 bis 25 Milliarden erreichen.  Und dann - nicht so schnell - werden wir bis Ende des Jahres auf 40-50 Milliarden steigen, wenn wir alle f√ºr uns interessanten Lebensmittelereignisse beschreiben. <br><br>  <b>1 Zeilen im Set.</b>  <b>Verstrichen: 0,287 Sek.</b>  <b>Verarbeitete 59,85 Milliarden Zeilen, 59,85 GB (208,16 Milliarden Zeilen / s, 208,16 GB / s)</b> <br><br>  Details unter dem Schnitt. <br><a name="habracut"></a><br><h1>  Vorwort </h1><br>  Analytische Tools waren zuvor VKontakte.  Es wurden eindeutige Benutzer ber√ºcksichtigt. Es war m√∂glich, Ereignispl√§ne anhand von Slices zu erstellen und dadurch in die Tiefe des Dienstes zu fallen.  Es ging jedoch um feste Slices im Voraus, um aggregierte Daten, um HLL f√ºr eindeutige, um eine gewisse Steifheit und die Unf√§higkeit, Fragen schnell zu beantworten, die etwas komplizierter waren als ‚Äûwie viel?‚Äú. <br><br>  Nat√ºrlich gab, gibt und wird Hadoop, es wurde auch geschrieben, geschrieben und wird viel geschrieben, viele Protokolle √ºber die Nutzung von Diensten.  Leider wurde hdfs nur von einigen Teams verwendet, um ihre eigenen Aufgaben zu implementieren.  Noch trauriger ist, dass es bei hdfs nicht um schnelle analytische Fragen geht: Es gab Fragen zu vielen Feldern, deren Antworten im Code und nicht in der Dokumentation zu finden waren, die jedem zug√§nglich war. <br><br>  Wir sind zu dem Schluss gekommen, dass es nicht mehr m√∂glich ist, so zu leben.  Jedes Team sollte Daten haben, Abfragen sollten schnell sein und die Daten selbst sollten genau und reich an n√ºtzlichen Parametern sein. <br><br>  Daher haben wir klare Anforderungen an das neue Statistik- / Analysesystem formuliert: <br><br><ul><li>  analytische Abfragen sollten schnell sein; </li><li>  Die Daten sind ziemlich genau. Im Idealfall handelt es sich dabei um unformatierte Benutzerinteraktionsereignisse mit dem Dienst. </li><li>  Die Struktur der Ereignisse sollte beschrieben, verstanden und zug√§nglich sein. </li><li>  zuverl√§ssige Datenspeicherung, einmalige Liefergarantie; </li><li>  Es ist m√∂glich, die Unikate, die Zielgruppe (t√§glich, w√∂chentlich, monatlich), die Aufbewahrungsmetriken, die vom Benutzer im Dienst verbrachte Zeit, die quantifizierten Aktionen f√ºr eindeutige und andere Metriken anhand der Slices zu z√§hlen. </li><li>  Tests, Datenkonvertierung und Visualisierung werden durchgef√ºhrt. </li></ul><br><h1>  In der K√ºche </h1><br>  Die Erfahrung hat gezeigt, dass wir zwei Datenbanken ben√∂tigen: eine langsame, in der wir die Daten aggregieren und anreichern, und eine schnelle, in der wir mit diesen Daten arbeiten und darauf Diagramme erstellen k√∂nnen.  Dies ist einer der h√§ufigsten Ans√§tze, bei denen in einer langsamen Datenbank, beispielsweise in HDFS, unterschiedliche Projektionen erstellt werden - auf eindeutigen und auf der Anzahl der Ereignisse durch Slices f√ºr einen bestimmten Zeitraum. <br><br>  An einem warmen Septembertag hatten wir bei einer Tasse Tee in der K√ºche mit Blick auf die Kasaner Kathedrale die Idee, ClickHouse als schnelle Basis zu nutzen - zu diesem Zeitpunkt haben wir es bereits zum Speichern technischer Protokolle verwendet.  Es gab viele Zweifel, die haupts√§chlich mit Geschwindigkeit und Zuverl√§ssigkeit verbunden waren: Die deklarierten Leistungstests schienen unrealistisch, und neue Datenbankversionen brachen regelm√§√üig vorhandene Funktionen.  Daher war der Vorschlag einfach - zu versuchen. <br><br><h1>  Erste Proben </h1><br>  Wir haben einen Cluster von zwei Computern mit dieser Konfiguration bereitgestellt: <br>  2xE5-2620 v4 (insgesamt 32 Kerne), 256 G RAM, 28 T Pl√§tze (raid10 mit ext4). <br><br>  Anfangs war es nahes Layout, aber dann haben wir zu weit gewechselt.  ClickHouse verf√ºgt √ºber viele verschiedene Tabellen-Engines, die wichtigsten stammen jedoch aus der MergeTree-Familie.  Wir haben ReplicatedReplacingMergeTree mit ungef√§hr den folgenden Einstellungen ausgew√§hlt: <br><br><pre><code class="sql hljs">PARTITION BY dt ORDER BY (toStartOfHour(time), cityHash64(user_id), event_microsec, event_id) SAMPLE BY cityHash64(user_id) SETTINGS index_granularity = 8192;</code> </pre> <br>  <b>Repliziert</b> - bedeutet, dass die Tabelle repliziert wird, wodurch eine unserer Zuverl√§ssigkeitsanforderungen gel√∂st wird. <br><br>  <b>Ersetzen</b> - Die Tabelle unterst√ºtzt die Deduplizierung des Prim√§rschl√ºssels: Standardm√§√üig stimmt der Prim√§rschl√ºssel mit dem Sortierschl√ºssel √ºberein, sodass im Abschnitt ORDER BY nur angegeben wird, um welchen Prim√§rschl√ºssel es sich handelt. <br><br>  <b>SAMPLE BY</b> - Ich wollte auch Sampling ausprobieren: sample gibt eine einheitlich pseudozuf√§llige Stichprobe zur√ºck. <br><br>  <b>index_granularity = 8192</b> ist die magische Anzahl von <b>Datenzeilen</b> zwischen Indexserifen (ja, es ist sp√§rlich), die standardm√§√üig verwendet wird.  Wir haben es nicht ge√§ndert. <br><br>  Die Partitionierung erfolgte nach Tag (standardm√§√üig jedoch nach Monat).  Viele Datenanfragen sollten im Tagesverlauf erfolgen. Erstellen Sie beispielsweise ein Minutendiagramm mit Videoansichten f√ºr einen bestimmten Tag. <br><br>  Als n√§chstes nahmen wir ein St√ºck technische Protokolle und f√ºllten die Tabelle mit ungef√§hr einer Milliarde Zeilen.  Hervorragende Komprimierung, Gruppierung nach Spaltentyp Int *, Z√§hlen eindeutiger Werte - alles hat unglaublich schnell funktioniert! <br><br>  Apropos Geschwindigkeit, ich meine, dass keine einzige Anfrage l√§nger als 500 ms dauerte und die meisten von ihnen in 50-100 ms passen.  Und das auf zwei Maschinen - und tats√§chlich war nur eine an den Berechnungen beteiligt. <br><br>  Wir haben uns alles angesehen und uns vorgestellt, dass anstelle der UInt8-Spalte eine L√§nder-ID angezeigt wird und die Int8-Spalte durch Daten ersetzt wird, beispielsweise √ºber das Alter des Benutzers.  Und sie haben erkannt, dass ClickHouse f√ºr uns v√∂llig geeignet ist, wenn alles richtig gemacht wird. <br><br><h1>  Starke Datentypisierung </h1><br>  Der Vorteil von ClickHouse beginnt genau dann, wenn das richtige Datenschema erstellt wird.  Beispiel: Plattform String - schlecht, Plattform Int8 + W√∂rterbuch - gut, LowCardinality (String) - praktisch und gut (ich werde etwas sp√§ter √ºber LowCardinality sprechen). <br><br>  Wir haben eine spezielle Generatorklasse in PHP erstellt, die auf Anfrage Wrapper-Klassen √ºber Ereignisse basierend auf Tabellen in ClickHouse und einen einzelnen Einstiegspunkt f√ºr die Protokollierung erstellt.  Ich werde das Beispiel des Schemas erkl√§ren, das sich herausstellte: <br><br><ol><li>  Analyst / Dateningenieur / Entwickler beschreibt die Dokumentation: Welche Felder, m√∂glichen Werte und Ereignisse m√ºssen protokolliert werden? </li><li>  In ClickHouse wird eine Tabelle gem√§√ü der Datenstruktur aus dem vorherigen Absatz erstellt. </li><li>  Umbruchklassen f√ºr Ereignisse, die auf einer Tabelle basieren, werden generiert. </li><li>  Das Produktteam implementiert das Ausf√ºllen der Felder eines Objekts dieser Klasse und das Senden. </li></ol><br>  Das √Ñndern des Schemas auf PHP-Ebene und des Typs der protokollierten Daten funktioniert nicht, ohne zuerst die Tabelle in ClickHouse zu √§ndern.  Dies kann wiederum nicht ohne Abstimmung mit dem Team, √Ñnderungen in der Dokumentation und Beschreibung der Ereignisse geschehen. <br><br>  F√ºr jedes Ereignis k√∂nnen Sie zwei Einstellungen festlegen, die den Prozentsatz der an ClickHouse bzw. Hadoop gesendeten Ereignisse steuern.  Einstellungen werden haupts√§chlich f√ºr das schrittweise Rollen ben√∂tigt, mit der M√∂glichkeit, die Protokollierung zu reduzieren, wenn etwas schief geht.  Vor Hadoop werden die Daten standardm√§√üig mit Kafka geliefert.  Und in ClickHouse fliegen sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mit KittenHouse</a> im permanenten Modus durch ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schema</a> , das mindestens eine einzelne Ereignis√ºbermittlung garantiert. <br><br>  Das Ereignis wird an die Puffertabelle an den gew√ºnschten Shard √ºbergeben, basierend auf dem Rest der Division eines Hash von user_id durch die Anzahl der Shards im Cluster.  Als N√§chstes l√∂scht die Puffertabelle die Daten in den lokalen ReplicatedReplacingMergeTree.  Zus√§tzlich zu den lokalen Tabellen wird mit der Distributed Engine eine verteilte Tabelle abgerufen, mit der Sie auf Daten von allen Shards zugreifen k√∂nnen. <br><br><h1>  Denormalisierung </h1><br>  ClickHouse ist ein s√§ulenf√∂rmiges DBMS.  Es geht nicht um normale Formulare, was bedeutet, dass es besser ist, alle Informationen f√ºr die Veranstaltung richtig zu haben, als sich anzumelden.  Es gibt auch Join, aber wenn die richtige Tabelle nicht in den Speicher passt, beginnt der Schmerz.  Daher haben wir eine willensstarke Entscheidung getroffen: Alle Informationen, an denen wir interessiert sind, sollten in der Veranstaltung selbst gespeichert werden.  Zum Beispiel Geschlecht, Alter des Benutzers, Land, Stadt, Geburtstag - all dies sind √∂ffentliche Informationen, die f√ºr die Analyse des Publikums n√ºtzlich sein k√∂nnen, sowie alle n√ºtzlichen Informationen √ºber das Objekt der Interaktion.  Wenn es sich beispielsweise um Video handelt, handelt es sich um video_id, video_owner_id, Datum des Video-Uploads, L√§nge, Qualit√§t zum Zeitpunkt des Ereignisses, maximale Qualit√§t usw. <br><br>  Insgesamt haben wir in jeder Tabelle 50 bis 200 Spalten, w√§hrend in allen Tabellen Servicefelder vorhanden sind.  Das Fehlerprotokoll lautet beispielsweise error_log. Tats√§chlich rufen wir einen Fehler au√üerhalb des Bereichs des Typs auf.  Falls seltsame Werte mit dem Alter √ºber die Gr√∂√üe des Feldtyps hinausgehen. <br><br><h2>  Typ LowCardinality (T) </h2><br>  ClickHouse kann externe W√∂rterb√ºcher verwenden.  Sie werden im Speicher gespeichert, regelm√§√üig aktualisiert und k√∂nnen in verschiedenen Szenarien effektiv verwendet werden, auch als klassische Nachschlagewerke.  Sie m√∂chten beispielsweise das Betriebssystem protokollieren und haben zwei Alternativen: eine Zeichenfolge oder eine Zahl + ein Verzeichnis.  Bei gro√üen Datenmengen und bei analytischen Hochleistungsabfragen ist es nat√ºrlich logisch, eine Zahl zu schreiben und bei Bedarf eine Zeichenfolgendarstellung aus dem W√∂rterbuch abzurufen: <br><br><pre> <code class="sql hljs">dictGetString('os', 'os_name', toUInt64(os_id))</code> </pre> <br>  Es gibt jedoch eine viel bequemere M√∂glichkeit, den Typ LowCardinality (String) zu verwenden, mit dem automatisch ein W√∂rterbuch erstellt wird.  Die Leistung mit LowCardinality unter der Bedingung einer geringen Kardinalit√§t des Wertesatzes ist radikal h√∂her als mit String. <br><br>  Zum Beispiel verwenden wir LowCardinality (String) f√ºr die Ereignistypen 'play', 'pause', 'rewind'.  Oder f√ºr die Plattform: "Web", "Android", "iPhone": <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> vk_platform, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt = yesterday() <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> vk_platform Elapsed: <span class="hljs-number"><span class="hljs-number">0.145</span></span> sec. Processed <span class="hljs-number"><span class="hljs-number">1.98</span></span> billion <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>, <span class="hljs-number"><span class="hljs-number">5.96</span></span> GB (<span class="hljs-number"><span class="hljs-number">13.65</span></span> billion <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>/s., <span class="hljs-number"><span class="hljs-number">41.04</span></span> GB/s.)</code> </pre> <br>  Die Funktion ist noch experimentell. Um sie zu verwenden, m√ºssen Sie Folgendes ausf√ºhren: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SET</span></span> allow_experimental_low_cardinality_type = <span class="hljs-number"><span class="hljs-number">1</span></span>;</code> </pre> <br>  Aber es gibt das Gef√ºhl, dass sie nach einiger Zeit nicht mehr unter der Kulisse sein wird. <br><br><h1>  VKontakte-Datenaggregation </h1><br>  Da es viele S√§ulen und viele Ereignisse gibt, besteht der nat√ºrliche Wunsch darin, die ‚Äûalten‚Äú Trennw√§nde zu schneiden, aber zuerst die Einheiten zusammenzubauen.  Gelegentlich ist es notwendig, rohe Ereignisse (vor einem Monat oder einem Jahr) zu analysieren, damit wir die Daten nicht in HDFS schneiden - jeder Analyst kann das gew√ºnschte Parkett f√ºr ein beliebiges Datum kontaktieren. <br><br>  Wenn wir in einem Zeitintervall aggregieren, ruhen wir uns in der Regel immer darauf aus, dass die Anzahl der Zeilen pro Zeiteinheit gleich dem Produkt der Schnittleistung ist.  Dies f√ºhrt zu Einschr√§nkungen: L√§nder beginnen, sich in Gruppen wie "Russland", "Asien", "Europa", "Der Rest der Welt" und dem Alter zu sammeln - in Intervallen, um die Dimension auf eine bedingte Million Zeilen pro Datum zu reduzieren. <br><br><h2>  Aggregation nach <b>dt, user_id</b> </h2><br>  Aber wir haben ein reaktives ClickHouse!  K√∂nnen wir an einem Datum auf 50 bis 100 Millionen Leitungen beschleunigen? <br>  Schnelle Tests haben gezeigt, dass wir es k√∂nnen, und in diesem Moment entstand eine einfache Idee - den Benutzer in der Maschine zu lassen.  Nicht nach "Datum, Slices" mit Funkenwerkzeugen zu aggregieren, sondern nach "Datum, Benutzer" bedeutet ClickHouse, w√§hrend Daten "transponiert" werden. <br><br>  Mit diesem Ansatz speichern wir Benutzer in aggregierten Daten, was bedeutet, dass wir weiterhin Zielgruppenindikatoren, Aufbewahrungs- und Frequenzmetriken ber√ºcksichtigen k√∂nnen.  Wir k√∂nnen Einheiten verbinden und die gemeinsame Zielgruppe mehrerer Dienste bis zur gesamten VKontakte-Zielgruppe z√§hlen.  All dies kann von jedem Slice durchgef√ºhrt werden, das zur gleichen Zeit in der Tabelle vorhanden ist. <br><br>  Ich werde mit einem Beispiel veranschaulichen: <br><br><img src="https://habrastorage.org/webt/1n/zq/23/1nzq23ia7micv91mecw0kqzxgrm.jpeg"><br><br>  Nach der Aggregation (viele weitere Spalten rechts): <br><br><img src="https://habrastorage.org/webt/nx/ol/xl/nxolxl2vmnnlsxlx6svuaklh9go.jpeg"><br><br>  In diesem Fall erfolgt die Aggregation genau nach (dt, user_id).  F√ºr Felder mit Benutzerinformationen k√∂nnen Sie mit einer solchen Aggregation die Funktionen any, anyHeavy verwenden (w√§hlt einen h√§ufig vorkommenden Wert aus).  Sie k√∂nnen beispielsweise anyHeavy (Plattform) in einem Aggregat sammeln, um anhand von Videoereignissen zu ermitteln, welche Plattform der Benutzer zum gr√∂√üten Teil verwendet.  Bei Bedarf k√∂nnen Sie groupUniqArray (Plattform) verwenden und ein Array aller Plattformen speichern, von denen der Benutzer das Ereignis ausgel√∂st hat.  Wenn dies nicht ausreicht, k√∂nnen Sie separate Spalten f√ºr die Plattform erstellen und beispielsweise die Anzahl der eindeutigen Videos speichern, die von einer bestimmten Plattform auf die H√§lfte angezeigt werden: <br><br><pre> <code class="sql hljs">uniqCombinedIf(cityHash64(video_owner_id, video_id), (platform = 'android') AND (event = '50p')) as uniq_videos_50p_android</code> </pre> <br>  Mit diesem Ansatz wird ein ziemlich breites Aggregat erhalten, in dem jede Zeile ein eindeutiger Benutzer ist und jede Spalte Informationen entweder √ºber den Benutzer oder √ºber seine Interaktion mit dem Dienst enth√§lt. <br><br>  Es stellt sich heraus, dass es zur Berechnung der DAU eines Dienstes ausreicht, eine solche Anforderung zus√§tzlich zu ihrem Aggregat auszuf√ºhren: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> dt, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> DAU <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> dt Elapsed: <span class="hljs-number"><span class="hljs-number">0.078</span></span> sec.</code> </pre> <br>  Oder berechnen Sie, wie viele Tage Benutzer f√ºr die Woche im Dienst waren: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">2.922</span></span> sec.</code> </pre> <br>  Wir k√∂nnen durch Abtasten beschleunigen, ohne dabei an Genauigkeit zu verlieren: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-number"><span class="hljs-number">10</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">7</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">7</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.454</span></span> sec.</code> </pre> <br>  Es sollte sofort beachtet werden, dass die Stichprobe nicht nach dem Prozentsatz der Ereignisse, sondern nach dem Prozentsatz der Benutzer erfolgt - und als Ergebnis wird sie zu einem unglaublich leistungsf√§higen Werkzeug. <br><br>  Oder das gleiche f√ºr 4 Wochen mit 1/100 Probenahme - etwa 1% weniger genaue Ergebnisse werden erhalten. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> days_in_service, <span class="hljs-number"><span class="hljs-number">100</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>() <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uniques <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> uniqUpTo(<span class="hljs-number"><span class="hljs-number">7</span></span>)(dt) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg2 <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> / <span class="hljs-number"><span class="hljs-number">100</span></span> <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt &gt; (yesterday() - <span class="hljs-number"><span class="hljs-number">28</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> user_id ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> days_in_service <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> <span class="hljs-number"><span class="hljs-number">28</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.287</span></span> sec.</code> </pre> <br><h2>  Aggregation auf der anderen Seite </h2><br>  Bei der Aggregation nach (dt, user_id) verlieren wir den Benutzer nicht, wir verpassen keine Informationen √ºber seine Interaktion mit dem Dienst, aber nat√ºrlich verlieren wir die Metriken f√ºr ein bestimmtes Interaktionsobjekt.  Aber Sie k√∂nnen dies auch nicht verlieren - bauen wir die Einheit durch <br>  (dt, video_owner_id, video_id), wobei die gleichen Ideen eingehalten werden.  Wir behalten die Informationen √ºber das Video so weit wie m√∂glich bei, verpassen keine Daten √ºber die Interaktion des Videos mit dem Benutzer und vermissen die Informationen √ºber den bestimmten Benutzer vollst√§ndig. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> starts <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> agg3 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (dt = yesterday()) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (video_id = ...) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (video_owner_id = ...) <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.030</span></span> sec</code> </pre> <br>  Oder die Top 10 Videoaufrufe gestern: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> video_id, video_owner_id, watches <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> video_agg_video_d1 <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> dt = yesterday() <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> watches <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.035</span></span> sec.</code> </pre> <br>  Als Ergebnis haben wir ein Schema von Einheiten der Form: <br><br><ul><li>  Aggregation nach "Datum, Benutzer" innerhalb des Produkts; </li><li>  Aggregation nach ‚ÄûDatum, Interaktionsobjekt‚Äú innerhalb des Produkts; </li><li>  manchmal entstehen andere Projektionen. </li></ul><br><h1>  Askaban und TeamCity </h1><br>  Zum Schluss noch ein paar Worte zur Infrastruktur.  Unsere Gesamtsammlung beginnt nachts und beginnt mit OPTIMIZE f√ºr jede der Tabellen mit Rohdaten, um eine au√üergew√∂hnliche Datenzusammenf√ºhrung in ReplicatedReplacingMergeTree auszul√∂sen.  Der Vorgang kann lange genug dauern, es ist jedoch erforderlich, Takes zu entfernen, falls sie auftreten.  Es ist erw√§hnenswert, dass ich bisher noch nie auf Duplikate gesto√üen bin, aber es gibt keine Garantie daf√ºr, dass sie in Zukunft nicht mehr erscheinen werden. <br><br>  Der n√§chste Schritt ist die Erstellung von Aggregaten.  Dies sind Bash-Skripte, in denen Folgendes vorkommt: <br><br><ul><li>  Zuerst erhalten wir die Anzahl der Scherben und einige Hosts von der Scherbe: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> shard_num, <span class="hljs-keyword"><span class="hljs-keyword">any</span></span>(host_name) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> host <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> system.clusters <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> shard_num</code> </pre> </li><li>  Anschlie√üend f√ºhrt das Skript nacheinander f√ºr jeden Shard (clickhouse-client -h $ host) eine Anforderung des Formulars aus (f√ºr Aggregate von Benutzern): <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">SAMPLE</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/$shards_count <span class="hljs-keyword"><span class="hljs-keyword">OFFSET</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>/$shard_num</code> </pre> </li></ul><br>  Dies ist nicht ganz optimal und kann viel Netzwerkinteraktion zwischen Hosts erzeugen.  Wenn Sie jedoch neue Shards hinzuf√ºgen, funktioniert alles sofort weiter. Die Lokalit√§t der Daten f√ºr die Einheiten bleibt erhalten, sodass wir uns entschlossen haben, uns dar√ºber keine gro√üen Sorgen zu machen. <br><br>  Wir haben Askaban als Aufgabenplaner.  Ich w√ºrde nicht sagen, dass dies ein sehr praktisches Tool ist, aber es erf√ºllt seine Aufgabe perfekt, auch wenn es darum geht, etwas komplexere Pipelines zu erstellen und wenn ein Skript warten muss, bis mehrere andere abgeschlossen sind. <br><br>  Die Gesamtzeit f√ºr die Konvertierung der jetzt vorhandenen Ereignisse in Aggregate betr√§gt 15 Minuten. <br><br><h2>  Testen </h2><br>  Jeden Morgen f√ºhren wir automatisierte Tests durch, die Fragen zu Rohdaten sowie zur Bereitschaft und Qualit√§t von Aggregaten beantworten: ‚ÄûStellen Sie sicher, dass gestern nicht mehr als ein halbes Prozent weniger Daten oder eindeutige Daten zu Rohdaten oder in Aggregaten vorhanden waren im Vergleich zum selben Tag vor einer Woche. " <br><br>  Technologisch gesehen sind dies gew√∂hnliche Komponententests mit JUnit und der Implementierung des JDBC-Treibers f√ºr ClickHouse.  Die Ausf√ºhrung aller Tests wird in TeamCity gestartet und dauert in einem Thread etwa 30 Sekunden. Bei Fehlern erhalten wir VKontakte-Benachrichtigungen von unserem wunderbaren TeamCity-Bot. <br><br><h1>  Fazit </h1><br>  Verwenden Sie nur stabile Versionen von ClickHouse und Ihr Haar wird weich und seidig.  Es ist erw√§hnenswert, dass <b><i>ClickHouse nicht langsamer wird</i></b> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de445284/">https://habr.com/ru/post/de445284/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de445272/index.html">JavaScript ist die beste Programmiersprache f√ºr Anf√§nger. So ist es oder nicht?</a></li>
<li><a href="../de445274/index.html">Wenn "Zo√´"! == "Zo√´" oder warum Sie Unicode-Strings normalisieren m√ºssen</a></li>
<li><a href="../de445276/index.html">Vollst√§ndiges UseEffect-Handbuch</a></li>
<li><a href="../de445278/index.html">So erstellen Sie ein Spiel, wenn Sie noch nie K√ºnstler sind</a></li>
<li><a href="../de445280/index.html">Rentabilit√§t von Websites und Dienstleistungen</a></li>
<li><a href="../de445286/index.html">Fu√üst√ºtze f√ºr das Gehirn: Hedera Hashgraph Distributed Registry Platform</a></li>
<li><a href="../de445288/index.html">Alle Ihre Verbraucherkredite und pers√∂nlichen Daten "an einem Ort" ...</a></li>
<li><a href="../de445290/index.html">Wie implementiere ich einheitliche Prozesse unter Ber√ºcksichtigung aller Merkmale des Unternehmens?</a></li>
<li><a href="../de445292/index.html">Was mir noch nie √ºber CSS gesagt wurde</a></li>
<li><a href="../de445294/index.html">Und nochmal zum zweiten Monitor vom Tablet ...</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏻‍💼 👪 🖕 Aplikasi Streaming Terstruktur Spark di Kubernetes. Pengalaman CEPAT RUS 👩‍👩‍👦‍👦 👨‍🏭 ⛩️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hari ini saya akan memberi tahu Anda bagaimana kami berhasil menyelesaikan masalah porting Aplikasi Streaming Terstruktur ke Kubernetes (K8s) dan meng...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aplikasi Streaming Terstruktur Spark di Kubernetes. Pengalaman CEPAT RUS</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445352/">  Hari ini saya akan memberi tahu Anda bagaimana kami berhasil menyelesaikan masalah porting <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Aplikasi Streaming Terstruktur</a> ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kubernetes</a> (K8s) dan mengimplementasikan streaming CI. <br><a name="habracut"></a><br><h4>  <i><b>Bagaimana semuanya dimulai?</b></i> </h4><br>  Streaming adalah komponen kunci dari platform FASTEN RUS BI.  Data waktu nyata digunakan oleh tim analisis tanggal untuk membuat laporan operasional. <br><br>  Aplikasi streaming diimplementasikan menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Spark Structured Streaming</a> .  Kerangka kerja ini menyediakan API transformasi data yang nyaman yang memenuhi kebutuhan kita dalam hal kecepatan perbaikan. <br><br>  Streaming sendiri naik di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AWR EMR</a> cluster.  Jadi, ketika meningkatkan aliran baru ke cluster, skrip ssh diletakkan untuk mengirimkan Spark-jobs, setelah itu aplikasi diluncurkan.  Dan pada awalnya semuanya tampak cocok untuk kita.  Tetapi dengan meningkatnya jumlah aliran, kebutuhan untuk menerapkan streaming CI menjadi semakin jelas, yang akan meningkatkan otonomi perintah tanggal analisis ketika meluncurkan aplikasi untuk mengirimkan data pada entitas baru. <br><br>  Dan sekarang kita akan melihat bagaimana kita berhasil menyelesaikan masalah ini dengan memindahkan streaming ke Kubernetes. <br><br><h4>  <i><b>Kenapa Kubernetes?</b></i> </h4><br>  Kubernetes, sebagai manajer sumber daya, paling sesuai dengan kebutuhan kita.  Ini adalah penyebaran tanpa downtime, dan berbagai alat implementasi CI di Kubernetes, termasuk Helm.  Selain itu, tim kami memiliki keahlian yang memadai dalam implementasi pipa CI pada K8.  Karena itu, pilihannya jelas. <br><br><h4>  <i><b>Bagaimana model manajemen aplikasi Spark berbasis Kubernetes diorganisasikan?</b></i> </h4><br><img src="https://habrastorage.org/webt/ms/rz/fv/msrzfvb4_7eqjzokg2cuvplcerm.png"><br><br>  Klien menjalankan percikan-kirim pada K8s.  Pod driver aplikasi dibuat.  Penjadwal Kubernetes mengikat pod ke node cluster.  Kemudian driver mengirim permintaan untuk membuat pod untuk menjalankan eksekutif, pod dibuat dan dilampirkan ke node cluster.  Setelah itu, serangkaian operasi standar dilakukan dengan konversi kode aplikasi selanjutnya menjadi DAG, dekomposisi menjadi beberapa tahapan, dipecah menjadi tugas-tugas dan peluncurannya pada executable. <br><br>  Model ini bekerja cukup berhasil ketika memulai aplikasi Spark secara manual.  Namun, pendekatan peluncuran spark-submit di luar cluster tidak sesuai dengan kami dalam hal implementasi CI.  Itu perlu untuk menemukan solusi yang akan memungkinkan Spark untuk menjalankan (melakukan percikan-kirim) langsung pada node cluster.  Dan di sini model Operator Kubernetes sepenuhnya memenuhi persyaratan kami. <br><br><h4>  <i><b>Operator Kubernetes sebagai Model Manajemen Siklus Hidup Aplikasi Spark</b></i> </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Operator Kubernetes</a> adalah konsep mengelola aplikasi statefull di Kubernetes, yang diusulkan oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CoreOS</a> , yang melibatkan otomatisasi tugas-tugas operasional, seperti menyebarkan aplikasi, memulai kembali aplikasi dalam kasus file, memperbarui konfigurasi aplikasi.  Salah satu pola utama Operator Kubernetes adalah CRD ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CustomResourceDefinitions</a> ), yang melibatkan penambahan sumber daya kustom ke kluster K8s, yang, pada gilirannya, memungkinkan Anda untuk bekerja dengan sumber daya ini seperti dengan objek Kubernetes asli. <br><br>  Operator adalah daemon yang hidup di pod cluster dan merespons pembuatan / perubahan status sumber daya khusus. <br><br>  Pertimbangkan konsep ini untuk manajemen siklus hidup aplikasi Spark. <br><br><img src="https://habrastorage.org/webt/an/ei/gt/aneigtq-0jc8fhtryimgh3orfaw.png"><br><br>  Pengguna menjalankan kubectl apply -f spark-application.yaml command, di mana spark-application.yaml adalah spesifikasi dari aplikasi Spark.  Operator menerima objek aplikasi Spark dan menjalankan spark-submit. <br><br>  Seperti yang dapat kita lihat, model Operator Kubernetes melibatkan pengelolaan siklus hidup aplikasi Spark secara langsung di kluster Kubernetes, yang merupakan argumen serius yang mendukung model ini dalam konteks memecahkan masalah kita. <br><br>  Sebagai Operator Kubernetes untuk mengelola aplikasi streaming, diputuskan untuk menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">operator spark-on-k8s</a> .  Operator ini menawarkan API yang cukup nyaman, serta fleksibilitas dalam mengonfigurasi kebijakan mulai ulang untuk aplikasi Spark (yang cukup penting dalam konteks mendukung aplikasi streaming). <br><br><h4>  <i><b>Implementasi CI</b></i> </h4><br>  Untuk menerapkan streaming CI, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GitLab CI / CD digunakan</a> .  Penyebaran aplikasi Spark di K8 dilakukan menggunakan alat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Helm</a> . <br><br>  Pipa itu sendiri melibatkan 2 tahap: <br><br><ul><li>  tes - pemeriksaan sintaksis dilakukan, serta rendering dari Helm-templates; </li><li>  deploy - penyebaran aplikasi streaming ke lingkungan pengujian (dev) dan produk (prod). </li></ul><br>  Mari kita perhatikan tahapan-tahapan ini secara lebih rinci. <br><br>  Pada tahap pengujian, template Helm aplikasi Spark (CRD - <a href="">SparkApplication</a> ) <a href="">diberikan</a> dengan nilai-nilai khusus lingkungan. <br><br>  Bagian utama dari Helm-template adalah: <br><ol><li>  percikan: <br><ul><li>  versi - versi Apache Spark </li><li>  image - Gambar Docker digunakan </li></ul></li><li>  nodeSelector - berisi daftar (kunci → nilai) yang sesuai dengan label perapian. </li><li>  toleransi - menunjukkan daftar toleransi aplikasi Spark. </li><li>  mainClass - Kelas aplikasi Spark </li><li>  applicationFile - jalur lokal tempat jar aplikasi Spark berada </li><li>  restartPolicy - Kebijakan mulai ulang aplikasi Spark <br><ul><li>  Tidak pernah - aplikasi Spark yang lengkap tidak restart </li><li>  Selalu - aplikasi Spark yang telah selesai dinyalakan ulang terlepas dari alasan pemberhentiannya. </li><li>  OnFailure - Aplikasi Spark me-restart hanya jika file </li></ul></li><li>  maxSubmissionRetries - jumlah maksimum pengajuan aplikasi Spark </li><li>  driver / pelaksana: <br><ul><li>  core - jumlah kernel yang dialokasikan untuk driver / pelaksana </li><li>  contoh (hanya digunakan untuk konfigurasi eksekutif) - jumlah eksekutif </li><li>  memori - jumlah memori yang dialokasikan untuk proses driver / pelaksana </li><li>  memoryOverhead - jumlah memori off-heap yang dialokasikan untuk driver / pelaksana </li></ul></li><li>  stream: <br><ul><li>  nama - nama aplikasi streaming </li><li>  argumen - argumen ke aplikasi streaming </li></ul></li><li>  wastafel - jalur menuju dataset Data Lake di S3 </li></ol><br>  Setelah merender template, aplikasi dikerahkan ke lingkungan pengujian dev menggunakan Helm. <br><br>  Mengerjakan pipa CI. <br><br><img src="https://habrastorage.org/webt/ah/za/br/ahzabrhmjpduar2y7ug3xzn90lu.png"><br><br>  Lalu kami meluncurkan pekerjaan deploy-prod - meluncurkan aplikasi dalam produksi. <br><br>  Kami yakin kinerja pekerjaan yang sukses. <br><br><img src="https://habrastorage.org/webt/md/-h/0e/md-h0e0u3mwccnncq7t2qqzaf5i.png"><br><br>  Seperti yang dapat kita lihat di bawah, aplikasi sedang berjalan, pod berada dalam status MENJALANKAN. <br><br><img src="https://habrastorage.org/webt/ce/4i/cc/ce4iccuv7vkzintbor0tyjtae88.png"><br><br><h4>  <i><b>Kesimpulan</b></i> </h4><br>  Porting Aplikasi Streaming Terstruktur Spark ke K8 dan implementasi CI selanjutnya memungkinkan kami untuk mengotomatiskan peluncuran stream untuk mengirimkan data ke entitas baru.  Untuk meningkatkan aliran berikutnya, cukup untuk menyiapkan Permintaan Gabung dengan deskripsi konfigurasi aplikasi Spark dalam file nilai-nilai yaml dan ketika pekerjaan deploy-prod dimulai, pengiriman data ke Data Lake (S3) akan dimulai.  Solusi ini memastikan otonomi perintah tanggal analisis ketika melakukan tugas yang berkaitan dengan menambahkan entitas baru ke repositori.  Selain itu, porting streaming ke K8s, dan khususnya, mengelola aplikasi Spark menggunakan Operator Kubernetes spark-on-k8s-operator secara signifikan meningkatkan ketahanan streaming.  Tetapi lebih lanjut tentang itu di artikel berikutnya. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id445352/">https://habr.com/ru/post/id445352/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id445340/index.html">Tingkatkan keamanan jaringan dengan menggunakan cloud analyzer</a></li>
<li><a href="../id445344/index.html">OpenVox Unified Communications Platform</a></li>
<li><a href="../id445346/index.html">Cara menulis API yang buruk</a></li>
<li><a href="../id445348/index.html">SNA Hackathon 2019: Menyederhanakan Arsitektur - Menyederhanakan Fitur</a></li>
<li><a href="../id445350/index.html">Sonata - server penyedia SIP</a></li>
<li><a href="../id445354/index.html">Menemukan objek dalam gambar</a></li>
<li><a href="../id445356/index.html">Tinjauan umum bagian Seluler di DUMP-2019: maksimum diterapkan dan berguna dalam pekerjaan sehari-hari</a></li>
<li><a href="../id445358/index.html">Organisasi sistem acara di Unity - melalui mata seorang desainer game</a></li>
<li><a href="../id445360/index.html">5 tugas khas untuk wawancara JavaScript: penguraian dan solusi</a></li>
<li><a href="../id445362/index.html">Buku "Sistem Terdistribusi. Pola Desain</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
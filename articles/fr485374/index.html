<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíô üîà üë®üèæ‚Äçüç≥ Le cache est le roi des performances: les processeurs ont-ils besoin d'un quatri√®me niveau de mise en cache ü•ü üë®‚Äç‚öïÔ∏è üë©‚Äçüè´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'√©cart entre la vitesse des processeurs au sens g√©n√©ral et la vitesse de la DRAM principale, √©galement au sens g√©n√©ral, a √©t√© un probl√®me au cours de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le cache est le roi des performances: les processeurs ont-ils besoin d'un quatri√®me niveau de mise en cache</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/485374/"><img src="https://habrastorage.org/getpro/habr/post_images/2ac/73c/219/2ac73c219095e9b2a9f772e767ba9cb7.jpg"><br><br>  L'√©cart entre la vitesse des processeurs au sens g√©n√©ral et la vitesse de la DRAM principale, √©galement au sens g√©n√©ral, a √©t√© un probl√®me au cours des 30 derni√®res ann√©es - au cours de cette p√©riode, l'√©cart a commenc√© √† se creuser vraiment.  Et il vaut la peine de dire honn√™tement que les ing√©nieurs qui ont d√©velopp√© √† la fois l'√©quipement et les programmes qui ont cr√©√© la hi√©rarchie de cache et les logiciels qui pourraient en tirer parti ont tout simplement brillamment.  C'est l'une des architectures les plus difficiles jamais con√ßues par l'homme. <br><br>  Cependant, maintenant que nous sommes au bord d'une hi√©rarchie de m√©moire en constante expansion, lorsque la m√©moire non volatile comme Optane 3D XPoint (une variante de m√©moire avec changement de phase) aux formats DIMM et SSD commence √† appara√Ætre, ainsi que de nouveaux protocoles (CXL, OpenCAPI, CCIX, NVLink et Gen-Z), la question se pose: est-il temps d'ajouter un cache de quatri√®me niveau aux serveurs?  √âtant donn√© que le travail d'un tel nombre de p√©riph√©riques d√©pend du complexe CPU - dont certains sont plus proches, tandis que d'autres sont plus √©loign√©s - il est logique de se demander si nous avons besoin d'un autre niveau de cache qui masque les retards de ces autres types de m√©moire et augmente le d√©bit de l'ensemble du syst√®me. <br><a name="habracut"></a><br>  Pour introduire les opportunit√©s, nous avons fouill√© dans notre propre m√©moire, et en m√™me temps, nous avons discut√© avec des d√©veloppeurs d'architecture de puce d'IBM, Intel, AMD et Marvell pour comprendre ce qu'ils pensent de l'utilisation du cache L4 dans les serveurs.  Le cache L4, bien s√ªr, n'est pas un nouveau mot dans la vitesse, mais il n'est pas si courant dans les architectures syst√®me. <br><br>  Cependant, avant de revenir sur l'histoire du probl√®me. <br><br>  L'ajout d'un cache de premier niveau aux processeurs qui n'avaient qu'un seul c≈ìur √† l'√©poque √©tait un compromis dans les ann√©es 1980 qui ajoutait de la latence aux sous-syst√®mes de m√©moire tout en r√©duisant la latence moyenne des demandes de donn√©es et des instructions des processeurs.  Les caches L1 √©taient √† l'origine situ√©s dans la m√©moire SRAM externe situ√©e sur les cartes m√®res et connect√©es au complexe m√©moire CPU.  Un tel cache L1 √©tait tr√®s proche du processeur, √† la fois en termes de fr√©quence d'horloge et en termes d'espace physique sur la carte, et a permis d'augmenter la charge CPU.  Ensuite, ces caches ont √©t√© divis√©s afin que les donn√©es fr√©quemment utilis√©es puissent √™tre stock√©es dans un bloc et les instructions populaires dans le second, ce qui a l√©g√®rement augment√© les performances.  √Ä un moment donn√© de l'augmentation de la vitesse d'horloge du processeur et de l'√©cart correspondant dans la vitesse du CPU et de la DRAM, des caches L2 plus gros, mais aussi plus lents ont √©t√© ajout√©s (mais moins chers en termes de bande passante), encore une fois au d√©but, ils √©taient en dehors du bo√Ætier du CPU, mais puis int√©gr√© en elle.  Et lorsque de plus en plus de c≈ìurs ont commenc√© √† √™tre ajout√©s au CPU, ainsi que de plus en plus de contr√¥leurs DRAM pour les charger, des blocs de cache L3 encore plus grands ont √©t√© ajout√©s √† la hi√©rarchie. <br><br>  Pour la plupart, un tel syst√®me fonctionnait assez bien.  Dans certains circuits CPU, nous voyons m√™me certaines r√®gles pratiques qui refl√®tent les niveaux de la hi√©rarchie de cache, ce qui nous permettra d'estimer les possibilit√©s associ√©es au quatri√®me niveau. <br><br>  Chris Gianos, ing√©nieur en puces et architecte chez Intel qui a dirig√© le d√©veloppement de nombreuses g√©n√©rations de processeurs Xeon, explique ceci: ¬´Avec chaque niveau de cache, nous devons g√©n√©ralement nous d√©velopper suffisamment fort par rapport au niveau pr√©c√©dent pour que tout cela en vaille la peine, car pour obtenir une augmentation notable des performances du syst√®me, vous devez atteindre une fr√©quence plut√¥t int√©ressante d'appels r√©ussis.  Si vous ¬´tombez dans¬ª des donn√©es mises en cache dans seulement quelques pour cent des cas, il sera difficile de le remarquer.  Tout le reste ralentit votre vitesse, et cette augmentation sera imperceptible.  Par cons√©quent, des caches relativement volumineux sont n√©cessaires, et lorsqu'il s'agit de niveaux plus √©lev√©s, des caches vraiment √©normes sont n√©cessaires.  Aujourd'hui, L2 est mesur√©e en m√©gaoctets, L3 est mesur√©e en dizaines ou centaines de m√©gaoctets.  Il est donc clair que si vous commencez √† penser au cache L4, alors nous parlerons de centaines de m√©gaoctets, sinon de gigaoctets.  Et une telle taille entra√Ænera certainement leur co√ªt √©lev√©.  Il faut que certaines conditions existent, pour que cette option devienne int√©ressante, et ce ne sera certainement pas bon march√©. ¬ª <br><br>  Les ing√©nieurs d'AMD que nous avons interrog√©s souhaitaient rester anonymes car ils ne voulaient pas donner l'impression que la soci√©t√© allait ajouter le cache L4 √† la gamme de processeurs Epyc - et, pour √™tre pr√©cis, AMD n'a rien promis de tel.  Cependant, la soci√©t√© admet toujours que c'est la prochaine √©tape √©vidente √† consid√©rer et, tout comme Intel, elle pense que tous les ing√©nieurs envisagent d'impl√©menter le cache L4.  En substance, AMD dit que les compromis associ√©s aux niveaux de cache et aux latences ont √©t√© largement √©tudi√©s √† la fois dans l'industrie et dans le monde universitaire, et qu'avec chaque nouveau niveau qui est plus grand et plus lent que le pr√©c√©dent, il existe un compromis pour augmenter le chemin global vers la DRAM.  Cela est √©galement indiqu√© par Intel Gianos, parlant de la n√©cessit√© de trouver un √©quilibre entre les demandes de cache r√©ussies et son volume. <br><br>  IBM, bien s√ªr, a ajout√© le cache L4 √† certains de ses chipsets X86 dans les ann√©es 2000, et dans les ann√©es 2010 a ajout√© L4 aux chipsets NUMA ( <a href="https://ru.wikipedia.org/wiki/Non-Uniform_Memory_Access" rel="nofollow">acc√®s m√©moire in√©gal</a> ) sur les mainframes System z11.  Le processeur z11 poss√®de quatre c≈ìurs, 64 Ko de cache L1 pour les instructions et 128 Ko de cache L1 pour les donn√©es, plus 1,5 Mo de cache L2 pour chaque c≈ìur et 24 Mo de cache partag√© L3 pour tous les c≈ìurs.  Le chipset NUMA pour z10 avait deux banques de cache L4 de 96 Mo, soit 192 Mo au total.  En publiant z12, IBM a r√©duit la taille du cache L1 √† 98 Ko par c≈ìur, mais a augment√© le cache L2 √† 2 Mo par c≈ìur, en le divisant en deux parties, pour les instructions et les donn√©es, comme dans le cas de L1.  Elle a √©galement doubl√© la taille du cache L3 √† 48 Mo pour six c≈ìurs, et la taille du cache L4 a √©t√© augment√©e √† 384 Mo pour une paire de puces dans le chipset.  Au fur et √† mesure que les g√©n√©rations de processeurs System z changent, les tailles de cache ont augment√© et pour les processeurs z15 annonc√©s en septembre, une paire de caches L1 p√®sera 128 Ko chacun, une paire de caches L2 p√®sera 4 Mo chacun, et un cache L3 partag√© pour 256 c≈ìurs aura une capacit√© de 256 Mo.  Le cache L4 dans chaque baie de l'ordinateur central est de 960 Mo et son volume total pour l'ensemble du syst√®me, compos√© de cinq baies, est de 4,68 Go. <br><br>  Comme nous l'avons <a href="https://www.nextplatform.com/2018/08/28/ibm-power-chips-blur-the-lines-to-memory-and-accelerators/" rel="nofollow">soulign√© pr√©c√©demment</a> , les processeurs Power8 et Power9 ont une m√©moire tampon et IBM a ajout√© 16 Mo de cache L4 √† chaque tampon Centaur, soit 128 Mo de cache L4 par socket pour 32 emplacements de m√©moire.  Les machines Power9 les moins ch√®res n'ont pas de m√©moire tampon, et donc pas de cache L4.  Les architectes qui ont d√©velopp√© le circuit Power10 √©taient occup√©s √† d√©velopper le circuit pour Power11, et n'ont donc pas pu r√©pondre √† nos questions, mais William Stark, qui a g√©r√© le d√©veloppement de Power10, a trouv√© un peu de temps pour nous et a remarqu√© ce qui suit: <br><br>  ¬´En g√©n√©ral, nous sommes arriv√©s √† la conclusion que les caches de haut niveau du dernier niveau sont utiles pour augmenter la vitesse des syst√®mes industriels¬ª, nous a expliqu√© Stark par e-mail.  "La latence √©lev√©e associ√©e √† la m√©moire non volatile, en particulier √† la m√©moire √† √©tat de phase, g√©n√®re une demande de cache - √©ventuellement pour un cache de type L4 - dans la hi√©rarchie de la m√©moire de stockage." <br><br>  C'est exactement ce que nous pensions.  Et d'ailleurs, nous ne pr√©tendons pas que le cache L4 sera n√©cessairement √† proximit√© de la m√©moire tampon du futur DIMM DDR5.  Il est peut-√™tre pr√©f√©rable de le placer entre le PCI-Express et le cache du processeur L3, et encore mieux, dans les tampons de m√©moire et entre le PCI-Express et le cache du processeur L3.  Il devra peut-√™tre √™tre plac√© au-dessus du contr√¥leur d'E / S et de la m√©moire dans la future architecture de serveur, qui est un peu comme <a href="https://www.nextplatform.com/2018/12/13/intel-bets-heavily-on-chip-stacking-for-the-future-of-compute/" rel="nofollow">la technologie Foveros d'Intel</a> . <br><br>  Il est possible d'envisager cela d'un point de vue diff√©rent - par exemple, IBM a eu l'occasion de modifier la taille du cristal, et les ing√©nieurs ont d√©cid√© d'ajouter le cache L4 au bus System z NUMA ou √† la puce de m√©moire tampon Power8 et Power9, non pas pour lui-m√™me, mais simplement parce que ils avaient encore la possibilit√© d'ajouter des transistors apr√®s que toutes les fonctions n√©cessaires aient √©t√© mises en ≈ìuvre.  Parfois, il nous semble que le nombre de c≈ìurs dans les processeurs Intel X86 d√©pend de la taille du cache L3 qu'ils peuvent se permettre.  Il semble parfois qu'Intel attribue la taille maximale du cache L3 √† un cristal, puis que les cristaux Xeon de trois tailles diff√©rentes soient simplement fabriqu√©s selon ces sp√©cifications - dans les derni√®res g√©n√©rations, ils ont 10, 18 ou 28 c≈ìurs sur un processus de fabrication de 14 nm. <br><br>  Tous ces probl√®mes sont, bien s√ªr, purement acad√©miques, mais ils nous donnent la motivation potentielle pour IBM et d'autres fabricants de chipsets d'ajouter le cache L4.  Non seulement cela peut aider dans certains cas, c'est juste une chose assez √©vidente.  Nous pensons que sur un monstre d'E / S tel que le mainframe System z, le cache L4 est √† sa place sans aucune question et profite √† tous les clients en augmentant le d√©bit de ces machines et en leur permettant de travailler √† 98-99% de charge de processeur, car combien de c≈ìurs , et l'√©chelle de NUMA dans les ordinateurs centraux a beaucoup augment√© ces derniers temps. <br><br>  Il n'y a aucune raison de faire le cache L4 exclusivement sur la DRAM int√©gr√©e (comme IBM le fait avec ses puces) ou sur la base d'une SRAM beaucoup plus ch√®re - c'est ce que Rabin Sugumar, architecte de puces de Cray Research, Sun Microsystems, Oracle, Broadcom nous rappelle , Cavium et Marvell: <br><br>  ¬´Nos caches L3 sont d√©j√† suffisamment gros¬ª, explique Sugumar.  - Donc L4 dans le cas o√π vous √™tes int√©ress√© doit √™tre fait en utilisant une technologie diff√©rente.  Peut-√™tre eDRAM ou m√™me HBM ou DRAM.  Dans ce contexte, une impl√©mentation du cache L4 bas√© sur HBM ressemble √† une option int√©ressante, et ce cache ne r√©sout pas tant le probl√®me de latence que la bande passante.  √âtant donn√© que la capacit√© HBM est limit√©e et la bande passante est grande, nous pouvons obtenir une certaine augmentation de la vitesse - et dans certains cas sp√©ciaux, nous voyons vraiment une augmentation significative de la bande passante. "  Sugumar ajoute que pour un nombre assez important d'applications, un nombre relativement important de rat√©s de cache est observ√©.  Cependant, vous devez calculer si l'ajout du prochain niveau de cache en vaudra la peine. <br><br>  Un autre cas d'utilisation possible pour quelque chose comme le cache L4, dit Sugumar, est d'utiliser la DRAM locale comme cache.  ¬´Nous ne menons pas de telles √©tudes en laboratoire, mais supposons que nous ayons une interface √† large bande passante sur la puce, connect√©e √† une m√©moire partag√©e quelque part √† l'autre extr√©mit√© de la boucle, √† une distance de 500 ns √† 1 Œºs.  Ensuite, l'un des cas d'utilisation sera de cr√©er un cache qui d√©place ces donn√©es de la m√©moire partag√©e vers la DRAM locale.  Vous pouvez imaginer le travail de la machine d'√©tat g√©rant cette m√©moire, donc la plupart du temps les appels iront √† la DRAM locale, et vous pouvez minimiser le nombre d'appels √† la DRAM distribu√©e g√©n√©rale. " <br><br>  Cette option nous semble un type de NUMA tr√®s int√©ressant.  Soit dit en passant, Sugumar travaillait sur la m√©moire distribu√©e pour les syst√®mes parall√®les √† grande vitesse dans Sun Microsystems avant m√™me l'apparition de la m√©moire non volatile.  Et l'un des probl√®mes avec ces diff√©rentes variantes de la hi√©rarchie de la m√©moire √©tait que si l'une d'entre elles √©tait perdue en raison d'une panne de r√©seau ou de bus, alors la machine enti√®re planterait.  ¬´Sur les syst√®mes de m√©moire distribu√©e, les pannes de r√©seau doivent √™tre trait√©es avec plus d'√©l√©gance, ce qui pose de nombreux probl√®mes de conception.¬ª <br><br>  Un autre point est que nous voulons que tout cache de haut niveau, pas m√™me L4, soit r√©alis√© au maximum avec l'aide de fer et avec le minimum avec l'aide d'un logiciel.  Les noyaux du syst√®me d'exploitation et les autres logiciels ont toujours besoin de temps pour rattraper le mat√©riel, qu'il s'agisse d'ajouter de nouveaux noyaux, ou des caches L3 ou L4, ou de la m√©moire non volatile adressable. <br><br>  ¬´√Ä un moment donn√©, un niveau de cache suppl√©mentaire deviendra in√©vitable¬ª, explique Gianos.  - Nous avons obtenu le premier niveau de cache, et √† un moment donn√©, le second est apparu.  Et puis nous avons finalement ajout√© un troisi√®me.  Et un jour, nous en aurons un quatri√®me.  La seule question est de savoir quand et pourquoi.  Et il me semble que vos observations concernant les capacit√©s de ce cache sont assez int√©ressantes.  Mais Intel n'a pas encore d√©cid√© quand ni pourquoi ces choses seront rendues publiques.  D'autres entreprises √©tudient √©galement cette question;  il serait insens√© de ne pas l'examiner.  T√¥t ou tard, cela se produira, mais ce sera bient√¥t, ou pas tr√®s - ce n'est pas encore clair. " </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr485374/">https://habr.com/ru/post/fr485374/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr485358/index.html">Le d√©veloppement mobile est-il facile et ennuyeux? Rapport Yandex</a></li>
<li><a href="../fr485362/index.html">Innovations JavaScript ES2020 avec des exemples simples</a></li>
<li><a href="../fr485364/index.html">Comment arr√™ter de perdre du temps aux d√©veloppeurs sur la dette technique</a></li>
<li><a href="../fr485370/index.html">Comment un d√©veloppeur peut-il aider un manager √† conclure un accord</a></li>
<li><a href="../fr485372/index.html">√Ä propos de l'immuable: histoire de la 9e place de la Coupe AI russe 2019</a></li>
<li><a href="../fr485376/index.html">Comment rendre le frontend trois fois plus rapide et quand appliquer des commandes au lieu de r√©f√©rentiels? Vid√©o</a></li>
<li><a href="../fr485378/index.html">√âtude de cas: comment √™tre pr√©sent√© sur Google Play et adapter ASO √† diff√©rents pays</a></li>
<li><a href="../fr485380/index.html">Succ√®s artisanal et informatique</a></li>
<li><a href="../fr485384/index.html">NeurIPS 2019: tendances ML qui nous accompagneront au cours de la prochaine d√©cennie</a></li>
<li><a href="../fr485386/index.html">Les micro-navigateurs sont partout. Mais que savons-nous d'eux?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
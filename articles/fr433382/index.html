<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘©ğŸ¿â€âš•ï¸ ğŸ§‘ ğŸ‘¨ğŸ»â€ğŸš’ [IllustrÃ©] Guide de mise en rÃ©seau dans Kubernetes. 3e partie ğŸ¤´ğŸ» ğŸŸï¸ ğŸ‘‰ğŸ¾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Remarque perev. : Cet article poursuit la sÃ©rie de documents sur le dispositif de base des rÃ©seaux dans Kubernetes, qui est dÃ©crit sous une forme acce...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>[IllustrÃ©] Guide de mise en rÃ©seau dans Kubernetes. 3e partie</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/433382/">  <i><b>Remarque</b></i>  <i><b>perev.</b></i>  <i>: Cet article poursuit la sÃ©rie de documents sur le dispositif de base des rÃ©seaux dans Kubernetes, qui est dÃ©crit sous une forme accessible et avec des illustrations illustratives (cependant, il n'y avait pratiquement aucune illustration dans cette partie du bÃ©ton pour le moment).</i>  <i>En traduisant les deux parties prÃ©cÃ©dentes de cette sÃ©rie, nous les avons combinÃ©es en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">une seule publication</a> , qui parlait du modÃ¨le de rÃ©seau K8s (interaction au sein des nÅ“uds et entre les nÅ“uds) et des rÃ©seaux de superposition.</i>  <i>Sa lecture prÃ©liminaire est souhaitable (recommandÃ©e par l'auteur lui-mÃªme).</i>  <i>La suite est consacrÃ©e aux services Kubernetes et au traitement du trafic sortant et entrant.</i> <i><br></i>  <i><b>NB</b> : Pour la commoditÃ© de l'auteur, le texte de l'auteur est complÃ©tÃ© par des liens (principalement vers la documentation officielle des K8).</i> <br><br><img src="https://habrastorage.org/webt/x4/ks/w-/x4ksw-pth57rmrhkhvmh-1sua4s.png"><a name="habracut"></a><br><br><h2>  Dynamique des clusters </h2><br>  En raison de la nature dynamique et en constante Ã©volution de Kubernetes et des systÃ¨mes distribuÃ©s en gÃ©nÃ©ral, les pods (et, par consÃ©quent, leurs adresses IP) sont Ã©galement en constante Ã©volution.  Les raisons de cela varient des mises Ã  jour entrantes pour atteindre l'Ã©tat et les Ã©vÃ©nements souhaitÃ©s conduisant Ã  la mise Ã  l'Ã©chelle, aux plantages imprÃ©vus du pod ou du nÅ“ud.  Par consÃ©quent, les adresses IP du pod ne peuvent pas Ãªtre utilisÃ©es directement pour la communication. <br><br>  Le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">service</a> dans Kubernetes entre en jeu - une IP virtuelle avec un groupe d'adresses IP de pod qui sont utilisÃ©es comme points de terminaison et identifiÃ©es par des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sÃ©lecteurs d'Ã©tiquettes</a> .  Un tel service fonctionne comme un Ã©quilibreur de charge virtuel, dont l'adresse IP reste constante, et en mÃªme temps, les adresses IP du pod qu'il prÃ©sente peuvent changer en permanence. <br><br><img src="https://habrastorage.org/webt/ub/jt/pi/ubjtpikee0m_4jbl1vxvqayaptu.png"><br>  <i>SÃ©lecteur d'Ã©tiquette dans l'objet Service dans Kubernetes</i> <br><br>  DerriÃ¨re l'implÃ©mentation complÃ¨te de cette IP virtuelle se trouvent des rÃ¨gles iptables (les derniÃ¨res versions de Kubernetes ont Ã©galement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la possibilitÃ© d'</a> utiliser IPVS, mais c'est un sujet pour une autre discussion), qui sont contrÃ´lÃ©es par un composant Kubernetes appelÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kube-proxy</a> .  Cependant, un tel nom est trompeur dans les rÃ©alitÃ©s d'aujourd'hui.  Kube-proxy Ã©tait vraiment utilisÃ© comme proxy dans les jours prÃ©cÃ©dant la sortie de Kubernetes v1.0, mais cela a conduit Ã  une grande consommation de ressources et de freins en raison des opÃ©rations de copie constantes entre l'espace du noyau et l'espace utilisateur.  Maintenant, c'est juste un contrÃ´leur - comme beaucoup d'autres contrÃ´leurs dans Kubernetes.  Il surveille le serveur API pour les modifications des points de terminaison et met Ã  jour les rÃ¨gles iptables en consÃ©quence. <br><br>  Selon ces rÃ¨gles iptables, si le paquet est destinÃ© Ã  l'adresse IP du service, une traduction d'adresse rÃ©seau de destination (DNAT) est effectuÃ©e pour lui: cela signifie que son adresse IP passera de l'IP du service Ã  l'un des points de terminaison, c'est-Ã -dire  l'une des adresses IP du pod, que iptables sÃ©lectionne au hasard.  Cela garantit que la charge est uniformÃ©ment rÃ©partie entre les pods. <br><br><img src="https://habrastorage.org/webt/1a/o4/_v/1ao4_vk1xd_grzyxccfiommthms.png"><br>  <i>DNAT dans iptables</i> <br><br>  Dans le cas d'un tel DNAT, les informations nÃ©cessaires sont stockÃ©es dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">conntrack</a> - la table de comptabilitÃ© des connexions sous Linux (il stocke les traductions Ã  cinq paires faites par iptables: <code>protocol</code> , <code>srcIP</code> , <code>srcPort</code> , <code>dstIP</code> , <code>dstPort</code> ).  Tout est organisÃ© de telle maniÃ¨re que lorsqu'une rÃ©ponse est renvoyÃ©e, une opÃ©ration DNAT inverse (non-DNAT) peut se produire, c'est-Ã -dire  Remplacement de la source IP du Pod IP au Service IP.  GrÃ¢ce Ã  ce client, il n'est absolument pas nÃ©cessaire de savoir comment travailler avec les packages en arriÃ¨re-plan. <br><br><img src="https://habrastorage.org/webt/tm/dp/n4/tmdpn4mhfrqoizyhighdxs8jit4.png"><br>  <i>EntrÃ©es Ã  cinq paires (5 tuples) dans la table conntrack</i> <br><br>  Ainsi, en utilisant les services Kubernetes, nous pouvons travailler avec les mÃªmes ports sans aucun conflit (car la rÃ©affectation des ports aux points de terminaison est possible).  Cela rend la dÃ©couverte de services trÃ¨s facile.  Il suffit d'utiliser le DNS interne et de coder en dur l'hÃ´te des services.  Vous pouvez mÃªme utiliser les variables prÃ©configurÃ©es de Kubernetes avec l'hÃ´te et le port de service. <br><br>  <b>Astuce</b> : En choisissant le deuxiÃ¨me chemin, vous Ã©conomisez beaucoup d'appels DNS inutiles! <br><br><h2>  Trafic sortant </h2><br>  Les services Kubernetes dÃ©crits ci-dessus fonctionnent au sein d'un cluster.  Dans la pratique, les applications ont gÃ©nÃ©ralement besoin d'accÃ©der Ã  certains API / sites externes. <br><br>  En gÃ©nÃ©ral, les hÃ´tes peuvent avoir des adresses IP privÃ©es et publiques.  Pour accÃ©der Ã  Internet, un NAT individuel est fourni pour ces adresses IP privÃ©es et publiques - ceci est particuliÃ¨rement vrai pour les environnements cloud. <br><br>  Pour une interaction normale de l'hÃ´te avec l'adresse IP externe, l'IP source passe de l'IP hÃ´te privÃ© Ã  l'IP publique pour les paquets sortants et pour les paquets entrants - dans la direction opposÃ©e.  Cependant, dans les cas oÃ¹ la connexion Ã  l'IP externe est initiÃ©e par le pod, l'adresse IP source est l'IP du pod, que le mÃ©canisme NAT du fournisseur de cloud ne connaÃ®t pas.  Par consÃ©quent, il supprimera simplement les paquets avec des adresses IP source diffÃ©rentes des adresses IP hÃ´tes. <br><br>  Et ici, vous l'aurez devinÃ©, nous aurons encore plus besoin d'iptables!  Cette fois, les rÃ¨gles, qui sont Ã©galement ajoutÃ©es par kube-proxy, sont exÃ©cutÃ©es par SNAT (Source Network Address Translation), alias <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IP MASQUERADE</a> (masquerading).  Au lieu de l'adresse IP source, le noyau est invitÃ© Ã  utiliser l'interface IP Ã  partir de laquelle le paquet arrive.  Une entrÃ©e apparaÃ®t dans conntrack pour poursuivre l'opÃ©ration inverse (non-SNAT) sur la rÃ©ponse. <br><br><h2>  Trafic entrant </h2><br>  Jusqu'Ã  prÃ©sent, tout allait bien.  Les pods peuvent communiquer entre eux et avec Internet.  Cependant, il nous manque toujours l'essentiel - servir le trafic des utilisateurs.  Il existe actuellement deux faÃ§ons de le mettre en Å“uvre: <br><br><h3>  1. NodePort / Cloud Load Balancer (niveau L4: IP et port) </h3><br>  La dÃ©finition de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>NodePort</code></a> comme type de service affectera le service <code>NodePort</code> dans une plage de 30 000 Ã  <code>NodePort</code> 000.  Ce <code>nodePort</code> ouvert sur chaque nÅ“ud, mÃªme si aucun pod n'est en cours d'exÃ©cution sur le nÅ“ud.  Le trafic entrant sur ce <code>NodePort</code> envoyÃ© Ã  l'un des pods (qui peuvent mÃªme apparaÃ®tre sur un autre nÅ“ud!), Toujours en utilisant iptables. <br><br>  Le type de service <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>LoadBalancer</code></a> dans les environnements cloud crÃ©e un Ã©quilibreur de charge cloud (par exemple, ELB) en face de tous les nÅ“uds, fonctionnant plus loin avec le mÃªme <code>NodePort</code> . <br><br><h3>  2. EntrÃ©e (niveau L7: HTTP / TCP) </h3><br>  De nombreuses autres implÃ©mentations effectuent Ã©galement le mappage hÃ´te / chemin HTTP avec les backends correspondants - par exemple, nginx, traefik, HAProxy, etc.  Avec eux, le LoadBalancer et le NodePort redeviennent le point d'entrÃ©e pour le trafic, mais il y a l'avantage ici que nous n'avons besoin que d'une seule entrÃ©e pour servir le trafic entrant de tous les services au lieu de nombreux NodePort / LoadBalancers. <br><br><h2>  StratÃ©gies rÃ©seau </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Les stratÃ©gies rÃ©seau</a> peuvent Ãªtre considÃ©rÃ©es comme des groupes de sÃ©curitÃ© / ACL pour les pods.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>NetworkPolicy</code></a> rÃ¨gles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>NetworkPolicy</code></a> autorisent / refusent le trafic entre les pods.  Leur implÃ©mentation exacte dÃ©pend de la couche rÃ©seau / CNI, mais la plupart d'entre eux utilisent simplement iptables. <br><br><h2>  ... </h2><br>  Câ€™est tout.  Dans les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tranches prÃ©cÃ©dentes,</a> nous avons appris les bases de la mise en rÃ©seau dans Kubernetes et le fonctionnement des superpositions.  Nous savons maintenant comment l'abstraction du service aide dans un cluster dynamique et rend la dÃ©couverte des services trÃ¨s simple.  Nous avons Ã©galement examinÃ© comment le trafic sortant / entrant circule et quelles stratÃ©gies rÃ©seau peuvent Ãªtre utiles pour sÃ©curiser un cluster. <br><br><h2>  PS du traducteur </h2><br>  Lisez aussi dans notre blog: <br><br><ul><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Un guide illustrÃ© du rÃ©seautage chez Kubernetes.Â»</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Parties 1 et 2</a> "; </li><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dans les coulisses du rÃ©seau Ã  Kubernetes</a> Â»; </li><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ExpÃ©riences avec kube-proxy et inaccessibilitÃ© de l'hÃ´te dans Kubernetes</a> Â»; </li><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comparaison des performances rÃ©seau pour Kubernetes</a> Â»; </li><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Container Networking Interface (CNI) - l'interface rÃ©seau et la norme pour les conteneurs Linux</a> Â»; </li><li>  Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Conduit est un maillage de service lÃ©ger pour Kubernetes</a> .Â» </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr433382/">https://habr.com/ru/post/fr433382/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr433372/index.html">VÃ©lo de voiture</a></li>
<li><a href="../fr433374/index.html">Toute la vÃ©ritÃ© sur RTOS. Article # 26. Canaux: services auxiliaires et structures de donnÃ©es</a></li>
<li><a href="../fr433376/index.html">Cours MIT "SÃ©curitÃ© des systÃ¨mes informatiques". ConfÃ©rence 21: Suivi des donnÃ©es, partie 1</a></li>
<li><a href="../fr433378/index.html">Cours MIT "SÃ©curitÃ© des systÃ¨mes informatiques". ConfÃ©rence 21: Suivi des donnÃ©es, partie 2</a></li>
<li><a href="../fr433380/index.html">Cours MIT "SÃ©curitÃ© des systÃ¨mes informatiques". ConfÃ©rence 21: Suivi des donnÃ©es, partie 3</a></li>
<li><a href="../fr433384/index.html">Nos donnÃ©es personnelles sont toujours vendues effrontÃ©ment</a></li>
<li><a href="../fr433386/index.html">Comment utiliser une vision par ordinateur pour Ã©valuer l'Ã©tat de la voiture. DÃ©couvrez Yandex.Taxi</a></li>
<li><a href="../fr433388/index.html">Fan de formule ou pourquoi nous jouons Ã  des jeux</a></li>
<li><a href="../fr433390/index.html">Yandex a rejoint la protection de Linux et de l'industrie informatique contre la pÃªche Ã  la traÃ®ne des brevets</a></li>
<li><a href="../fr433392/index.html">Courte critique du tÃ©lÃ©phone IP Snom D725</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
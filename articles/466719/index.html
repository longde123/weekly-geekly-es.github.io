<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👦🏿 🤽🏿 🙀 Perfiles de velocidad superligera: teoría y práctica. Parte 1 💇🏿 💻 🧚</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola Desde el titular, ya entendiste de lo que voy a hablar. Habrá mucho hardcore: 
 discutiremos Java, C, C ++, ensamblador, un poco de Linux, un poc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Perfiles de velocidad superligera: teoría y práctica. Parte 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/raiffeisenbank/blog/466719/">  Hola  Desde el titular, ya entendiste de lo que voy a hablar.  Habrá mucho hardcore: <br>  discutiremos Java, C, C ++, ensamblador, un poco de Linux, un poco del núcleo del sistema operativo.  También analizaremos un caso práctico, por lo que el artículo tendrá tres partes grandes (bastante voluminoso). <br><br><img src="https://habrastorage.org/webt/mp/cl/er/mpclerfppp9jx5ciuziyfv-n8oa.png"><br><br>  En el primero, intentaremos exprimir todo de los perfiladores existentes. <br>  En la segunda parte, crearemos nuestro propio perfilador pequeño, y en la tercera veremos cómo perfilar lo que no es habitual, porque las herramientas existentes no son muy adecuadas para esto.  Si estás listo para seguir este camino, te estoy esperando debajo del corte :) <br><a name="habracut"></a><br><h3>  Contenido </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tiempo y medios de comprensión - perfilador</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cómo funcionan los perfiladores de muestreo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¿Con qué frecuencia necesitamos tomar muestras?</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Elige un perfilador</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprenda perf para construir un perfil de aplicación Java.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aumentar la tasa de muestreo de perf</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Utilizamos (explícitamente) eventos de hardware PMU / PEBS</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen breve</a> </li></ul><br><a name="1"></a><h3>  Tiempo y medios de comprensión - perfilador </h3><br>  Desde el punto de vista cotidiano, 1 segundo es muy pequeño.  Pero sabemos que 1 segundo es mil millones de nanosegundos.  Y deje que tome aproximadamente 4 ciclos de procesador en solo 1 nanosegundo, en 1 segundo se hacen muchas cosas en la computadora que pueden mejorar o empeorar nuestras vidas. <br><br>  Supongamos que estamos desarrollando una aplicación que en sí misma es lo suficientemente crítica como para acelerar, y para algunos fragmentos de código esto es generalmente crítico.  Estas piezas se ejecutan, digamos, cientos de microsegundos, lo suficientemente rápido, pero [las <i>secciones del código</i> ] afectan directamente el éxito de nuestra aplicación y la cantidad de dinero ganado o perdido.  Por ejemplo <br>  Al enviar órdenes para concluir transacciones de intercambio, un retraso de 100 microsegundos puede costar al intercambio 1 millón de rublos o más en cada transacción, que se completa con uno, no dos, o incluso no cien. <br><br>  Y la <b>tarea</b> se estableció para mí: por un lado, debe enviar todos los pedidos al mismo tiempo y, por otro lado, enviarlos de modo que la variación entre el primero y el último sea mínima.  Es decir, era necesario perfilar una función que envía órdenes al intercambio.  Una tarea típica, excepto por un pequeño matiz: el tiempo de ejecución característico de esta función es <i>significativamente menor que 100 μs</i> . <br><br>  Pensemos en cómo perfilamos estos 100 μs para comprender lo que está sucediendo dentro. <br>  ¿Qué tener en cuenta al elegir esta herramienta? <br><br><ol><li>  La sección de código que nos interesa rara vez se ejecuta, es decir, 100 microsegundos se ejecutan en alguna parte una vez por segundo.  Y esto está en el banco de pruebas, y en producción aún menos. </li><li>  Será difícil aislar este fragmento de código en un microbenchmark, ya que afecta a una parte importante del proyecto e incluso a la entrada / salida a través de la red. </li><li>  Y finalmente, lo más importante, quiero que el perfil resultante corresponda con el comportamiento que tendrá en nuestros servidores de producción. </li></ol><br>  ¿Cómo tomamos en cuenta todos estos matices y perfilamos correctamente el método de interés? <br><br>  Conceptualmente, todos los perfiladores se pueden dividir en dos grupos de perfiladores de <i>instrumentos</i> o <i>muestreo</i> .  Consideremos cada grupo por separado. <br><br>  <b>Los perfiladores de herramientas</b> aportan bastante sobrecarga porque modifican nuestro código de bytes e insertan un registro de temporización en él.  De ahí el inconveniente clave de tales perfiladores: pueden afectar significativamente el código ejecutable.  Como resultado, será difícil decir cuánto coincide el perfil resultante con el comportamiento en los servidores de producción: algunas optimizaciones pueden funcionar de manera diferente, algunas suceden y otras no.  Quizás, en otras escalas de tiempo - segundos, minutos, horas - obtendremos datos representativos.  Pero en una escala de 100 μs, la optimización activada o fallida puede hacer que el perfil sea completamente no representativo.  Así que echemos un vistazo más de cerca a otro grupo de perfiladores. <br><br>  <b>Los perfiladores de muestreo</b> contribuyen con una sobrecarga mínima o moderada.  Estas herramientas no afectan directamente el código ejecutable, y su uso requiere un poco más de atención por su parte.  Por lo tanto, nos detendremos en los perfiladores de muestreo.  Veamos qué datos y de qué forma recibiremos de ellos. <br><br><a name="2"></a><h3>  ¿Cómo funcionan los perfiladores de muestreo? </h3><br>  Para comprender cómo funciona un generador de perfiles de muestreo, considere el siguiente ejemplo: el método <b>sendToMoex</b> llama a otros métodos.  Buscamos: <br><br><pre><code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> sendToMoex() { a.qqq(); b.doo(); c.ccc() } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> doo() { da(); db(); }</code> </pre> <br>  Si controlamos el estado de la pila de llamadas en el momento de la ejecución de esta sección del programa y la registramos periódicamente, obtendremos información aproximadamente de la siguiente forma: <br><br><img src="https://habrastorage.org/webt/gl/je/y5/gljey5esfyih7lqm1yjvpaxfese.png"><br><br>  Este es un conjunto de pilas de llamadas.  Suponiendo que las muestras se distribuyen uniformemente, el número de pilas idénticas indica el tiempo de ejecución relativo del método que está en la parte superior de la pila. <br><br>  En este ejemplo, el método Da se ejecutó tanto como el método C.ccc, y esto es 2 veces más que el método Db. Sin embargo, la suposición de que la distribución de las muestras incluso puede no ser completamente correcta, y entonces la estimación del tiempo de ejecución será incorrecta. <br><br><a name="3"></a><h3>  ¿Con qué frecuencia necesitamos tomar muestras? </h3><br>  Supongamos que queremos tomar 1000 muestras en 100 microsegundos para comprender lo que se reproduce dentro.  Luego, calculamos con una proporción simple que si necesitamos hacer 1000 muestras en 100 μs, entonces son 10 millones de muestras en 1 segundo o 10,000,000 muestras / s. <br><br><img src="https://habrastorage.org/webt/x6/rw/2j/x6rw2jbbfxfouax9ncy8hkfn3nq.png"><br><br>  Si tomamos muestras a esa velocidad, en una ejecución del código recolectaremos 1000 muestras, agregaremos y entenderemos lo que funcionó rápida o lentamente.  Después de eso, analizaremos el rendimiento y ajustaremos el código. <br><br>  Sin embargo, una frecuencia de 10 millones de muestras por segundo es mucha.  ¿Y si no logramos alcanzar esa velocidad de creación de perfiles desde el principio?  Supongamos que recolectamos 10 μs solo 10 muestras, no 1000. En este caso, tenemos que esperar a la próxima ejecución del código perfilado, que sucederá después de 1 segundo (después de todo, el código perfilado se ejecuta una vez por segundo).  Entonces recolectaremos 10 muestras más.  Como se distribuyen uniformemente con nosotros, se pueden combinar en un conjunto común.  Es suficiente esperar hasta que el código perfilado se ejecute 1000/10 = 100 veces, y recopilaremos las 1000 muestras requeridas (10 muestras cada una de 100 veces). <br><br><a name="4"></a><h3>  Elige un perfilador </h3><br>  Armados con este conocimiento teórico, pasemos a la práctica. <br><br>  Tome <b>Async-profiler.</b>  Una gran herramienta (utiliza la llamada de máquina virtual AsyncGetCallTrace) que recopila la pila de llamadas según las instrucciones del código de bytes de la máquina virtual Java.  La tasa de muestreo nativa del perfilador asíncrono es de <i>1000 muestras por segundo</i> . <br><br>  Resolveremos una proporción simple: 10,000,000 muestras / seg - 1 segundo, 1000 muestras / seg - X segundos. <br>  Obtenemos que a la frecuencia de muestreo estándar de async-profiler, la creación de perfiles llevará aproximadamente 3 horas.  Esto es mucho tiempo  Idealmente, quiero ensamblar el perfil lo más rápido posible, justo a la velocidad superluminal. <br><br>  Intentemos overclockear <b>Async-profiler</b> .  Para hacer esto, en el archivo Léame, encontramos la bandera <code>-i</code> , que establece el intervalo de muestreo.  Intentemos establecer el indicador <code>-i1</code> (1 nanosegundo), o <code>-i0</code> en general, para que el generador de muestras <code>-i0</code> sin parar.  Obtuve una frecuencia de aproximadamente 2.5 mil muestras por segundo.  En este caso, la duración total del perfil será de aproximadamente 1 hora.  Por supuesto, no 3 horas, pero tampoco muy rápido.  Parece que para alcanzar las velocidades de perfilado requeridas, debe hacer algo cualitativamente diferente para alcanzar un nuevo nivel. <br><br>  Para lograr frecuencias significativamente más altas, tendrá que abandonar la llamada AsyncGetCallTrace y usar <b>perf</b> , el generador de perfiles de Linux a tiempo completo que se encuentra en cada distribución de Linux.  Sin embargo, perf no sabe nada sobre Java, y todavía tenemos que entrenar a perf para trabajar con Java.  Mientras tanto, intentemos ejecutar perf de esta manera aterradora: <br><br><pre> <code class="java hljs">$ perf record –F <span class="hljs-number"><span class="hljs-number">10000</span></span> -p PID -g -- sleep <span class="hljs-number"><span class="hljs-number">1</span></span> [ perf record: Woken up <span class="hljs-number"><span class="hljs-number">1</span></span> times to write data ] [ perf record: .. <span class="hljs-number"><span class="hljs-number">0.215</span></span> MB perf.data (<span class="hljs-number"><span class="hljs-number">4032</span></span> samples) ]</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Más sobre notación</b> <div class="spoiler_text"><ul><li>  <i>perf record</i> significa que queremos grabar un perfil. </li><li>  La bandera <code>-F</code> y el argumento 10,000 son la frecuencia de muestreo. </li><li>  El indicador <code>-p</code> indica que queremos perfilar solo el PID específico de nuestro proceso Java. </li><li>  La bandera <code>-g</code> es responsable de recoger las pilas de llamadas. </li><li>  Finalmente, con el <i>sueño 1,</i> limitamos la entrada del perfil a 1 segundo. </li></ul></div></div><br>  ¿Por qué necesitamos recolectar pilas de llamadas?  Perfilamos todo en una fila, y luego de los datos recopilados extraemos la parte que nos interesa (el método responsable de la formación y el envío de pedidos).  El marcador de que la muestra recopilada pertenece a los datos que nos interesan es la presencia del marco de pila de la <b>llamada al</b> método <b>sendToMoex</b> . <br><br><a name="5"></a><h3>  Aprenda perf para construir un perfil de aplicación Java. </h3><br>  Ejecutamos el comando perf record ..., esperamos 1 segundo y ejecutamos el script perf para ver qué se ha perfilado.  Y veremos algo no muy claro: <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.746571</span></span>: <span class="hljs-number"><span class="hljs-number">3745505</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b53f8 [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.747565</span></span>: <span class="hljs-number"><span class="hljs-number">3728336</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b5372 [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8079</span></span> <span class="hljs-number"><span class="hljs-number">2008793.748613</span></span>: <span class="hljs-number"><span class="hljs-number">3731147</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fa1e88b53ef [unknown] (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-11038.</span></span>map)</code> </pre><br>  Parece que son direcciones, pero no hay nombres de métodos Java.  Por lo tanto, debe enseñar a perf para que coincida con estas direcciones con los nombres de los métodos. <br><br>  En el mundo de C y C ++, la llamada información de depuración se usa para unir direcciones y nombres de funciones.  Una correspondencia se almacena en una sección especial del archivo ejecutable: un método se encuentra en dichas direcciones, otro método se encuentra en otras direcciones.  Perf extrae esta información y hace un mapeo. <br><br>  Obviamente, el compilador JIT de máquina virtual no genera información de depuración en este formato.  Todavía tenemos otra manera: escribir datos sobre la correspondencia de direcciones y nombres de métodos en un archivo especial de perf-map, que perf tratará como una adición a la información de depuración leída.  Este archivo de perf-map debe estar en la carpeta tmp y tener la siguiente estructura de datos: <br><div class="scrollable-table"><table><tbody><tr><th>  Código de método dirección de inicio </th><th>  Longitud del código </th><th>  Nombre del método </th></tr><tr><td>  7f99a911d600 </td><td>  120 </td><td>  java.util.AbstractCollection. &lt;init&gt; </td></tr><tr><td>  7f99a911d9c0 </td><td>  180 </td><td>  java.util.AbstractList. &lt;init&gt; </td></tr><tr><td>  7f99a911de80 </td><td>  5c0 </td><td>  java.util.Arrays.copyOf </td></tr><tr><td>  7f99a911ed40 </td><td>  140 </td><td>  java.util.ArrayList $ Itr.hasNext </td></tr><tr><td>  7f99a911f200 </td><td>  3e0 </td><td>  java.util.ArrayList $ Itr.next <br></td></tr></tbody></table></div><br>  La primera columna es la dirección del comienzo del código del método, la segunda es su longitud, la tercera columna es el nombre del método. <br><br>  Entonces, necesitamos generar un archivo similar.  Obviamente, no podremos hacer esto manualmente (cómo sabemos en qué direcciones colocará el código el compilador JIT), por lo que utilizaremos el script create-java-perf-map.sh del proyecto perf-map-agent, pasándole el PID de nuestro proceso Java .  El archivo está listo, verifique su contenido, ejecute perf-script nuevamente. <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.867498</span></span>: cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f527 Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.868176</span></span>: <span class="hljs-number"><span class="hljs-number">2127960</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f57f Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map) java <span class="hljs-number"><span class="hljs-number">8080</span></span> <span class="hljs-number"><span class="hljs-number">1895245.868737</span></span>: <span class="hljs-number"><span class="hljs-number">1959990</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fb2dd10f627 Loop3.doRecursiveCall (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-8079.</span></span>map)</code> </pre> <br>  Voila!  ¡Vemos los nombres de los métodos de Java!  Lo que acaba de suceder: le enseñamos al perfilador de perf, que no sabe nada sobre Java, a perfilar una aplicación Java normal y ver los métodos java más populares de esta aplicación. <br><br>  Sin embargo, para analizar el rendimiento de la parte del programa que estamos interrogando, no tenemos suficiente pila de llamadas para filtrar los datos de interés de todas las muestras recopiladas. <br><br>  <b>¿Cómo obtener una pila de llamadas?</b> <br><br>  Ahora necesita hacer algo más con perf o una máquina virtual para obtener pilas de llamadas.  Para comprender lo que hay que hacer, demos un paso atrás y veamos cómo funciona la pila en general.  Imagine que tenemos tres funciones f1, f2, f3.  Además, f1 llama a f2 y f2 llama a f3. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f1() { f2(); } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f2() { f3(); } <span class="hljs-keyword"><span class="hljs-keyword">void</span></span> f3() { ... }</code> </pre> <br>  En el momento en que <code>f3</code> ejecuta la función <code>f3</code> , veamos en qué estado se encuentra la pila.  Vemos el registro <code>rsp</code> , que apunta a la parte superior de la pila.  También sabemos que la pila tiene la dirección del marco de pila anterior.  ¿Y cómo puedo obtener una pila de llamadas? <br><br>  Si de alguna manera pudiéramos obtener la dirección de esta área, podríamos imaginar la pila como una lista simplemente conectada y comprender la secuencia de llamadas que nos llevaron al punto de ejecución actual. <br><br>  ¿Qué necesitamos para esto?  Necesitamos un registro rbp adicional que apunte al área amarilla.  Resulta que el registro rbp permite que perf obtenga la pila de llamadas, para comprender la secuencia que nos llevó al punto actual.  Recomiendo leer estos detalles en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">interfaz binaria de la aplicación System V.</a>  Describe cómo se llaman los métodos en Linux. <br><br><img src="https://habrastorage.org/webt/0m/0w/vx/0m0wvx8wcaplslb7k5illbb4hbm.png"><br><br>  Entendimos cuál es nuestro problema.  Necesitamos forzar a la máquina virtual a usar el registro rbp para su propósito original, como un puntero al comienzo del marco de la pila.  Así es como el compilador JIT debe usar el registro rbp.  Hay una bandera PreserveFramePointer en la máquina virtual para esto.  Cuando pasamos este indicador a la máquina virtual, la máquina virtual comenzará a usar el registro rbp para su propósito tradicional.  Y luego Perf puede hacer girar la pila.  Y obtenemos una pila de llamadas real en el perfil.  La bandera fue aportada por el famoso Brendan Gregg en solo JDK8u60. <br><br>  Comenzamos la máquina virtual con una nueva bandera.  Ejecute <code>create-java-perf-map</code> , luego <code>perf record</code> y <code>perf script</code> .  Ahora podemos construir un perfil preciso con pilas de llamadas: <br><br><pre> <code class="javascript hljs">$ perf script java <span class="hljs-number"><span class="hljs-number">18657</span></span> <span class="hljs-number"><span class="hljs-number">1901247.601878</span></span>: <span class="hljs-number"><span class="hljs-number">979583</span></span> cycles:uppp: <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>fbfd1101edc Loop3.doRecursiveCall (...) <span class="hljs-number"><span class="hljs-number">7</span></span>f285d007b10 Interpreter (...) <span class="hljs-number"><span class="hljs-number">7</span></span>f285d0004e7 call_stub (...) <span class="hljs-number"><span class="hljs-number">67</span></span>d0db [unknown] (... libjvm.so) ... <span class="hljs-number"><span class="hljs-number">708</span></span>c start_thread (... libpthread<span class="hljs-number"><span class="hljs-number">-2.26</span></span>.so)</code> </pre><br>  Enseñamos perf profiler, incluido con la mayoría de las distribuciones de Linux, para trabajar con aplicaciones Java.  Por lo tanto, ahora podemos ver no solo las secciones activas del código, sino también la secuencia de llamadas que condujeron a la zona activa actual.  Un gran logro, dado que el perfilador perf no sabe nada sobre Java.  ¡Acabamos de enseñarle a perf todo esto! <br><br><a name="7"></a><h3>  Aumentar la tasa de muestreo de perf </h3><br>  Intentemos overclockear perf a 10 millones de muestras por segundo.  Ahora tenemos una frecuencia significativamente menor. <br><br>  Para automatizar todas las tareas que acabamos de hacer, puede usar el script <code>perf-java-record-stack</code> del proyecto perf-map-agent.  Tiene un lápiz maravilloso: la variable de entorno <code>perf_record-freq</code> , con la que puede establecer la frecuencia de muestreo.  Primero, configuremos 100 mil muestras por segundo e intentemos ejecutar.  Aparece un terrible mensaje en la consola que indica que hemos excedido la frecuencia de muestreo máxima permitida: <br><br><pre> <code class="javascript hljs">$ PERF_RECORD_FREQ=<span class="hljs-number"><span class="hljs-number">100000</span></span> ./bin/perf-java-record-stack PID ... Maximum frequency rate (<span class="hljs-number"><span class="hljs-number">30000</span></span>) reached. Please use -F freq option <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> lower value or consider tweaking /proc/sys/kernel/perf_event_max_sample_rate. ...</code> </pre><br>  En mi caso, el límite era de 30 mil muestras por segundo.  Perf dice inmediatamente qué argumento del kernel debe corregirse, lo que haremos utilizando echo sudo tee para el archivo deseado o directamente a través de <code>sysctl</code> .  Entonces <br><br><pre> <code class="javascript hljs">$ echo <span class="hljs-string"><span class="hljs-string">'1000000'</span></span> | sudo tee /proc/sys/kernel/perf_event_max_sample_rate</code> </pre> <br>  más o menos: <br><br><pre> <code class="javascript hljs">$ sudo sysctl kernel.perf_event_max_sample_rate=<span class="hljs-number"><span class="hljs-number">1000000</span></span></code> </pre><br>  Ahora le estamos diciendo al núcleo que el límite superior de la frecuencia es ahora de 1 millón de muestras por segundo.  Comenzamos el perfilador nuevamente e indicamos la frecuencia de 200 mil muestras por segundo.  El generador de perfiles funcionará durante 15 segundos y nos dará 1 millón de muestras.  Todo parece estar bien.  Al menos no hay mensajes de error formidables.  Pero, ¿qué frecuencia obtuvimos realmente?  Resulta que solo 70 mil muestras por segundo.  ¿Qué salió mal? <br><br>  Veamos el resultado del <code>dmesg</code> : <br><br><pre> <code class="javascript hljs">[<span class="hljs-number"><span class="hljs-number">84430.412898</span></span>] perf: interrupt took too long (<span class="hljs-number"><span class="hljs-number">1783</span></span> &gt; <span class="hljs-number"><span class="hljs-number">200</span></span>), lowering kernel.perf_event_max_sample_rate to <span class="hljs-number"><span class="hljs-number">89700</span></span> ... [<span class="hljs-number"><span class="hljs-number">84431.618452</span></span>] perf: interrupt took too long (<span class="hljs-number"><span class="hljs-number">2229</span></span> &gt; <span class="hljs-number"><span class="hljs-number">2228</span></span>), lowering kernel.perf_event_max_sample_rate to <span class="hljs-number"><span class="hljs-number">71700</span></span></code> </pre><br>  Esta es la salida del kernel de Linux.  Se dio cuenta de que tomamos muestras con demasiada frecuencia, y lleva demasiado tiempo, por lo que el núcleo reduce la frecuencia.  Resulta que necesitamos desenroscar otro controlador en el kernel: se llama <code>kernel.perf_cpu_time_max_percent</code> y controla la cantidad de tiempo que el kernel puede pasar en las interrupciones de perf. <br><br>  Ordenaremos una frecuencia de muestreo de 200 mil muestras por segundo.  Y después de 15 segundos obtenemos 3 millones de muestras, 200 mil muestras por segundo. <br><br><pre> <code class="javascript hljs">$ PERF_RECORD_FREQ=<span class="hljs-number"><span class="hljs-number">200000</span></span> ./bin/perf-java-record-stack PID Recording events <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> <span class="hljs-number"><span class="hljs-number">15</span></span> seconds ... ... [ perf record: Captured ... (<span class="hljs-number"><span class="hljs-number">2.961</span></span><span class="hljs-number"><span class="hljs-number">.252</span></span> samples) ]</code> </pre><br>  Ahora veamos el perfil.  Ejecutar <code>perf script</code> : <br><br><pre> <code class="javascript hljs">$ perf script ... java ... native_write_msr (<span class="hljs-regexp"><span class="hljs-regexp">/.../</span></span>vmlinux) java ... Loop2.main (<span class="hljs-regexp"><span class="hljs-regexp">/tmp/</span></span>perf<span class="hljs-number"><span class="hljs-number">-29621.</span></span>map) java ... native_write_msr (<span class="hljs-regexp"><span class="hljs-regexp">/.../</span></span>vmlinux) ...</code> </pre><br>  Vemos funciones extrañas y el módulo ejecutable vmlinux: el kernel de Linux.  Este definitivamente no es nuestro código.  Que paso  La frecuencia resultó ser tan alta que el código del núcleo comenzó a caer en las muestras.  Es decir, cuanto mayor sea la frecuencia, más muestras habrá que no estén relacionadas con nuestro código, sino con el kernel de Linux. <br><br>  Callejón sin salida. <br><br><a name="8"></a><h3>  Utilizamos (explícitamente) eventos de hardware PMU / PEBS </h3><br>  Luego decidí intentar usar la tecnología de hardware PMU / PEBS: unidad de monitoreo de rendimiento, muestreo basado en eventos precisos.  Le permite recibir notificaciones de que se ha producido un evento varias veces.  Esto se llama un "período".  Por ejemplo, podemos recibir notificaciones sobre la ejecución por parte del procesador de cada vigésima instrucción.  Veamos un ejemplo.  Deje que la instrucción xor se ejecute ahora, y el contador PMU obtiene el valor 18;  luego viene la instrucción mov: el contador es 19;  y en la siguiente instrucción, <b>agregue% r14,% r13</b> , PMU se mostrará como " <b>activo</b> ". <br><br>  Luego comienza un nuevo ciclo: se ejecuta <code>inc</code> ; la PMU se restablece a 1. Se realizan algunas iteraciones más del ciclo.  Al final, nos detenemos en la instrucción <code>mov</code> , la PMU se ajusta a 19. La siguiente instrucción add, y nuevamente la marcamos como hot.  Ver el listado: <br><br><pre> <code class="plaintext hljs">mov aaa, bbbb xor %rdx, %rdx L_START: mov $0x0(%rbx, %rdx),%r14 add %r14, %r13 ; (PMU       "") cmp %rdx,100000000 jne L_START</code> </pre> <br>  ¿No te das cuenta de las rarezas?  Un ciclo de cinco instrucciones, pero cada vez que marcamos la misma instrucción como hot.  Obviamente, esto no es cierto: todas las instrucciones son "calientes".  También pasan tiempo, y marcamos solo uno.  El hecho es que entre el período y el contador del número de instrucciones en la iteración tenemos un factor común 4. Resulta que cada cuarta iteración marcaremos la misma instrucción como "activa".  Para evitar este comportamiento, debe elegir un número como un período en el que se minimiza la probabilidad de un divisor común entre el número de iteraciones en el bucle y el contador.  Idealmente, el período debería ser primo, es decir  compartir solo en usted y en la unidad.  Para el ejemplo anterior: debe elegir un período igual a 23. Luego, marcaríamos de manera uniforme todas las instrucciones de este ciclo como "activas". <br><br>  La tecnología PMU / PEBS ha recibido soporte en su forma moderna desde al menos 2009, es decir, está disponible en casi cualquier computadora.  Para aplicarlo explícitamente, modifiquemos el script <code>perf-java-record-stack</code> .  Reemplace el indicador <code>-F</code> con <code>-e</code> , que especifica explícitamente el uso de PMU / PEBS. <br><br><pre> <code class="javascript hljs">... sudo perf record -F $PERF_RECORD_FREQ ... ...</code> </pre> <br>  Transformando el guión: <br><br><pre> <code class="javascript hljs">... sudo perf record -e cycles –c <span class="hljs-number"><span class="hljs-number">10007</span></span> ... ...</code> </pre> <br>  Ya sabes qué propiedades debe tener un período: necesitamos un número primo.  Para nuestro caso, será el período 10007. <br><br>  Lanzamos el script modificado perf-java-record-stack y en 15 segundos recibimos 4.5 millones de muestras, esto es casi 300 mil por segundo, una muestra cada 3 μs.  Es decir, para una ejecución de nuestro código perfilado, por 100 μs recolectaremos 33 muestras.  A esta frecuencia, el tiempo total de recopilación del perfil es de solo 30 segundos.  ¡Ni siquiera tomes una taza de café!  En realidad, todo es un poco más complicado.  ¿Qué sucede si nuestro código comienza a ejecutarse no una vez por segundo, sino una vez cada 5 segundos?  Luego, la duración de la creación de perfiles crecerá hasta 2,5 minutos, lo que también es un resultado bastante decente. <br><br>  Por lo tanto, en 30 segundos puede obtener un perfil que cubra completamente todas nuestras necesidades de investigación.  Victoria <br><br>  Pero la sensación de algún truco sucio no me dejó.  Volvamos a la situación en la que nuestro código se ejecuta cada 5 segundos.  Luego, la elaboración de perfiles llevará 150 segundos, tiempo durante el cual recolectaremos alrededor de 45 millones de muestras.  De estos, solo necesitamos 1000, es decir, 0.002% de los datos recopilados.  Todo lo demás es basura, lo que ralentiza el trabajo de otras herramientas y agrega gastos generales.  Sí, el problema está resuelto, pero está resuelto en la frente, fuerza sucia y contundente. <br><br>  Y esa noche, cuando obtuve un perfil tan detallado con la ayuda de perf, tuve un sueño.  Iba a casa del trabajo y pensaba, pero sería bueno si el hierro pudiera ensamblar el perfil en sí mismo e incluso con la precisión de las microestructuras y los microsegundos, y solo analizaríamos los resultados.  ¿Se hará realidad mi sueño?  Que piensas <br><br><a name="9"></a><h3>  Breve resumen: </h3><br><ul><li>  Para crear un perfil de una aplicación Java usando perf, necesita generar un archivo con información sobre símbolos usando scripts del proyecto perf-map-agent </li><li>  Para recopilar información no solo sobre secciones activas de código, sino también pilas, debe ejecutar una máquina virtual con el indicador -XX: + PreserveFramePointer </li><li>  Si desea aumentar la frecuencia de muestreo, debe prestar atención a sysctl'i y kernel.perf_cpu_time_max_percent y kernel.perf_event_max_sample_rate. </li><li>  Si las muestras del kernel que no están relacionadas con la aplicación comenzaron a ingresar al perfil, debe pensar en especificar explícitamente el período PMU / PEBS. </li></ul><br>  Este artículo (y sus partes posteriores) es una transcripción del informe, adaptado en forma de texto.  Si desea no solo leer, sino también escuchar sobre la creación de perfiles, una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">referencia</a> a la presentación. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/466719/">https://habr.com/ru/post/466719/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../466701/index.html">Let's Encrypt sirve casi el 30% de los dominios</a></li>
<li><a href="../466705/index.html">Vivaldi Beta para Android - Navegador real</a></li>
<li><a href="../466709/index.html">Desarrollo de un sistema operativo monolítico tipo Unix - Biblioteca C (2)</a></li>
<li><a href="../466711/index.html">Vulnerabilidad DaOffice permitió eliminar a cualquier usuario de la red social</a></li>
<li><a href="../466713/index.html">¿Es posible en 1C no observar la tecnología de los componentes externos? O ¿Cómo felicitar a los colegas que usan 1C?</a></li>
<li><a href="../466721/index.html">[Ekaterimburgo, anuncio] java.ural.Meetup @ 3 - anuncio de los terceros informes de video Java mitap + de java.ural.Meetup @ 2</a></li>
<li><a href="../466723/index.html">Apple Text Broadcast - 10 de septiembre de 2019</a></li>
<li><a href="../466725/index.html">Dagger 2 es elemental (Parte 1)</a></li>
<li><a href="../466727/index.html">Actualización perezosa: cómo PostgreSQL 12 mejora el rendimiento</a></li>
<li><a href="../466729/index.html">El libro "Minería de datos. Recuperando información de Facebook, Twitter, LinkedIn, Instagram, GitHub »</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📥 🤢 🚷 Détection rapide des contours en vidéo 4K: couleurs et formes complexes 🤵🏼 🤲 🏑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans la partie précédente, «Entraînement des ensembles à partir de la vidéo - rapidement et efficacement», nous avons parlé de la complexité de l'util...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Détection rapide des contours en vidéo 4K: couleurs et formes complexes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/473780/">  Dans la partie précédente, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">«Entraînement des ensembles à partir de la vidéo - rapidement et efficacement»,</a> nous avons parlé de la complexité de l'utilisation des réseaux de neurones pour toute tâche associée à des objets rares, inhabituels ou simplement complexes.  Assurez-vous de regarder les exemples, ils en valent la peine. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/N-vOm5rgMhI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Il s'est avéré que les algorithmes classiques de vision par ordinateur peuvent grandement aider à obtenir des ensembles de formation de haute qualité.  Naturellement, cette approche n'est pas applicable dans tous les cas, avec lesquels il est nécessaire de comprendre. <br><a name="habracut"></a><br><h2>  Quelle est la difficulté? </h2><br>  Comme indiqué dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partie précédente</a> , le marquage manuel détaillé des ensembles est un processus très long et, franchement, n'est généralement pas une option pour toute personne sensée.  Le marquage automatique, en particulier en ce qui concerne les contours, semble beaucoup plus intéressant, mais comment obtenir le contour d'intérêt rapidement et avec précision? <br><br><h3>  Fonction d'adhésion </h3><br>  Cela vaut peut-être la peine de commencer par la fonction d’adhésion.  Supposons que l'objet qui nous intéresse se caractérise par une couleur vive, qui, de plus, est unique à l'objet dans le contexte d'une scène particulière: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/23vSk9-9V9E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Compte tenu des spécificités de l'approche (à savoir, la nécessité de telles scènes qui sont faciles à «analyser»), il est assez facile de formuler une règle pour sélectionner des exemples pour obtenir un ensemble de formation: les scènes pour lesquelles la règle de l'unicité des couleurs de l'objet souhaité sera remplie seront très utiles (rappelez-vous, avec tous les cas difficiles vous devrez faire face à un réseau de neurones qui a été formé avec succès à l'aide de l'ensemble généré). <br><br>  En fait, la condition d'unicité est un minimum nécessaire, car la couleur peut et doit également être travaillée sur: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/tRhpocvDKK0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Distance de couleur </h3><br>  Travailler avec la couleur, dans ce cas, est une partie très importante de toute l'approche.  En effet, la fonction d'appartenance peut être implémentée en fonction de la proximité d'une couleur donnée avec une valeur seuil définie: <br><br><img src="https://habrastorage.org/webt/xm/4r/gu/xm4rgux_bfmhaz9ygptfgculdxq.png"><br><br>  La solution existante utilise plusieurs implémentations <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Delta E</a> comme standard le plus précis.  Par exemple, CIE94 dans l'espace colorimétrique LCH (L * C * h): <br><br><img src="https://habrastorage.org/webt/gk/to/p3/gktop3o45or4px6lxgnkt0nnrme.png"><br><br>  Un seuil trop grand, pour la distance des couleurs, est susceptible de «casser» le chemin, capturant des pixels qui ne sont pas liés à l'objet souhaité.  Trop petit - ne sélectionne qu'une partie de l'objet souhaité.  À cet égard, les scènes complexes nécessitent de l'attention, par exemple: <br><br><img src="https://habrastorage.org/webt/bc/ym/ky/bcymkyl_q512kcyrlfbnyotpexw.png"><br><br>  La baleine sur la photo est toujours perceptible à l'œil (avec difficulté, bien sûr), mais le contour est déjà mal construit.  Exemple entier: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/he-94r7QJK8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Restaurer le circuit </h2><br>  Supposons que tout va bien avec la couleur, comment obtenir le contour souhaité?  La tâche n'est pas simple, car le résultat est susceptible d'être assez complexe, avec des cavités, des éléments mineurs, etc.  Laquelle des options pour le contour restauré pour un seul objet est correcte? <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/0ZkDxUnRg2g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  L'éclairage est complexe, les ombres, les réflexes font partie intégrante du monde tridimensionnel, etc.  Nous utilisons un exemple plus complexe: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/dXzmN6O5S4w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  L'algorithme pour obtenir un tel résultat est le suivant: <br><br><img src="https://habrastorage.org/webt/ye/mg/9-/yemg9-f9zbd1oqrklro9phxmf3w.png"><br><br><ol><li>  image source </li><li>  sélection de l'étape de numérisation (performances critiques) </li><li>  balayage horizontal </li><li>  balayage vertical et analyse d'intersection pour rechercher des "objets" isolés </li><li>  construction d'un tableau de méta-pixels (pour identifier à la fois la forme et les caractéristiques internes de l'objet) et post-traitement (filtrage, lissage, etc.) </li><li>  "Vectorisation" de la forme restaurée de l'objet </li></ol><br>  L'analyse d'intersection facilite la localisation de zones distinctes et indépendantes.  En activant le mode d'affichage de la ligne de balayage, vous pouvez facilement voir à la fois l'approche elle-même et l'effet de l'étape de balayage sur le résultat final.  Faites attention à une astuce très simple avec une bordure qui améliore considérablement l'impression que vous faites: <br><br><img src="https://habrastorage.org/webt/8x/cn/ok/8xcnokq1of1dbrckuhacp_vk2fo.gif"><br><br>  La précision du circuit reconstruit est facile à évaluer à l'aide de l'exemple suivant: <br><br><img src="https://habrastorage.org/webt/iz/3z/oj/iz3zojqjafujvfrb2cwr4a0mezk.gif"><br><br><h2>  Test final </h2><br>  Plus d'objets, plus de contours, une meilleure précision, des cheveux et en 4K - si vous vérifiez votre mise en œuvre, donc avec des chansons et des danses. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/snI7QKb0UQg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Jusqu'à la prochaine fois, et d'autres détails tout aussi intéressants. <br><br><h3>  Autres résultats </h3><br><iframe width="560" height="315" src="https://www.youtube.com/embed/DlaSyXonXDU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/VAqEXZG1Fp8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/UpOURwroviU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Suivez le développement du projet </h3><br>  YouTube: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RobotsCanSee</a> <br>  Télégramme: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RobotsCanSeeUs</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr473780/">https://habr.com/ru/post/fr473780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr473768/index.html">Top 5 des livres pour ceux qui veulent améliorer leurs compétences</a></li>
<li><a href="../fr473770/index.html">Analyse statique de gros volumes de code Python: expérience Instagram. 2e partie</a></li>
<li><a href="../fr473774/index.html">Cloud sécurisé sur DF Cloud</a></li>
<li><a href="../fr473776/index.html">Unification des règles de validation par l'exemple d'Asp core + VueJS</a></li>
<li><a href="../fr473778/index.html">Optimisation d'image: comment utiliser Vision AI de Google pour comprendre les principes de classement des images</a></li>
<li><a href="../fr473784/index.html">Comment rédiger un contrat intelligent pour WebAssembly sur un réseau d'ontologie? Partie 2: C ++</a></li>
<li><a href="../fr473786/index.html">L'inscription au hackathon de Riga se termine. Prix ​​- formation de courte durée au PhysTech</a></li>
<li><a href="../fr473788/index.html">Les microprotéines découvrent des aspects inconnus de la biologie moderne</a></li>
<li><a href="../fr473790/index.html">Splines dans les graphismes 3D, l'option la plus automatisée</a></li>
<li><a href="../fr473794/index.html">Phishing mobile - menaces infinies</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
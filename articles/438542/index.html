<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìÑ üåÇ üëâüèª C√≥mo creamos un servicio de recomendaci√≥n para la selecci√≥n de ropa en redes neuronales ‚ò¶Ô∏è üí± üë©üèº‚Äçüé§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En este art√≠culo quiero hablar sobre c√≥mo creamos un sistema de b√∫squeda de ropa similar (m√°s precisamente ropa, zapatos y bolsos) a partir de fotogra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo creamos un servicio de recomendaci√≥n para la selecci√≥n de ropa en redes neuronales</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/438542/"><img src="https://habrastorage.org/webt/bh/ne/uw/bhneuwiip47lykb6jg-yigfnk3o.png" alt="imagen"><br><br>  En este art√≠culo quiero hablar sobre c√≥mo creamos un sistema de b√∫squeda de ropa similar (m√°s precisamente ropa, zapatos y bolsos) a partir de fotograf√≠as.  Es decir, en t√©rminos comerciales, un servicio de recomendaci√≥n basado en redes neuronales. <br><br>  Como la mayor√≠a de las soluciones de TI modernas, podemos comparar el desarrollo de nuestro sistema con el ensamblaje del constructor de Lego, cuando tomamos muchos peque√±os detalles, instrucciones y creamos un modelo listo a partir de esto.  Aqu√≠ hay una instrucci√≥n: qu√© detalles tomar y c√≥mo aplicarlos para que su GPU pueda seleccionar productos similares de una fotograf√≠a, encontrar√° en este art√≠culo. <br><br>  De qu√© partes est√° construido nuestro sistema: <br><br><ul><li>  detector y clasificador de ropa, zapatos y bolsos en im√°genes; </li><li>  rastreador, indexador o m√≥dulo para trabajar con cat√°logos electr√≥nicos de tiendas; </li><li>  m√≥dulo de b√∫squeda de im√°genes similares; </li><li>  JSON-API para una interacci√≥n conveniente con cualquier dispositivo y servicio; </li><li>  interfaz web o aplicaci√≥n m√≥vil para ver los resultados. </li></ul><br>  Al final del art√≠culo, se describir√°n todos los "rastrillos" que pisamos durante el desarrollo y recomendaciones sobre c√≥mo neutralizarlos. <br><br><h3>  Declaraci√≥n del problema y creaci√≥n del rubricador. </h3><br>  La tarea y el caso de uso principal del sistema suena bastante simple y claro: <br><br><ul><li>  el usuario env√≠a a la entrada (por ejemplo, a trav√©s de una aplicaci√≥n m√≥vil) una fotograf√≠a en la que hay prendas de vestir y / o bolsos y / o zapatos; </li><li>  el sistema determina (detecta) todos estos objetos; </li><li>  encuentra para cada uno de ellos los productos m√°s similares (relevantes) en tiendas reales en l√≠nea; </li><li>  le da al usuario productos con la capacidad de ir a una p√°gina de producto espec√≠fica para su compra. </li></ul><br>  En pocas palabras, el objetivo de nuestro sistema es responder la famosa pregunta: "¬øY usted no tiene lo mismo, solo con botones de n√°car?" <br><a name="habracut"></a><br>  Antes de precipitarse en el grupo de codificaci√≥n, marcado y capacitaci√≥n de redes neuronales, debe determinar con bastante claridad las categor√≠as que estar√°n dentro de su sistema, es decir, aquellas categor√≠as que detectar√° la red neuronal.  Es importante comprender que cuanto m√°s amplia y detallada sea la lista de categor√≠as, m√°s universal es, ya que una gran cantidad de categor√≠as peque√±as y estrechas, como mini vestido, midi-dress, maxi-dress siempre se pueden combinar con un toque en una categor√≠a de tipo de vestido. PERO NO viceversa.  En otras palabras, el rubricator debe estar bien pensado y compilado al comienzo del proyecto, para no volver a hacer el mismo trabajo 3 veces m√°s tarde.  Compilamos el rubricator, tomando como base varias tiendas grandes, como Lamoda.ru, Amazon.com, e intentamos hacerlo lo m√°s ancho posible, por un lado, y lo m√°s vers√°til posible, por otro lado, para facilitar la asociaci√≥n de categor√≠as de detectores con diferentes categor√≠as en el futuro tiendas en l√≠nea (te contar√© m√°s sobre c√≥mo hacer este grupo en la secci√≥n de rastreadores e indexadores).  Aqu√≠ hay un ejemplo de lo que sucedi√≥. <br><br><img src="https://habrastorage.org/webt/bg/ku/zq/bgkuzqn0q-wovsd8x8aq7hlwlio.png" alt="imagen"><br>  <i>Categor√≠as de ejemplo</i> <br><br>  Nuestro cat√°logo actualmente tiene solo 205 categor√≠as: ropa de mujer, ropa de hombre, zapatos de mujer, zapatos de hombre, bolsos, ropa para reci√©n nacidos.  La versi√≥n completa de nuestro clasificador est√° disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en el enlace</a> . <br><br><h3>  Indexador o m√≥dulo para trabajar con cat√°logos electr√≥nicos de tiendas. </h3><br>  Para buscar productos similares en el futuro, necesitamos crear una base extensa de lo que buscaremos.  En nuestra experiencia, la calidad de la b√∫squeda de im√°genes similares depende directamente del tama√±o de la base de b√∫squeda, que debe exceder al menos 100K im√°genes, y preferiblemente 1M im√°genes.  Si agrega 1-2 peque√±as tiendas en l√≠nea a la base de datos, lo m√°s probable es que no obtenga resultados impresionantes simplemente porque en el 80% de los casos no hay nada realmente similar al art√≠culo deseado en su cat√°logo. <br><br>  Entonces, para crear una gran base de datos de im√°genes que necesita para procesar cat√°logos de varias tiendas en l√≠nea, esto es lo que incluye este proceso: <br><br><ul><li>  Primero, necesita encontrar las fuentes XML de las tiendas en l√≠nea, por lo general, puede encontrarlas disponibles gratuitamente en Internet, o solicit√°ndolas en la propia tienda o en varios agregadores como Admitad; </li><li>  el feed es procesado (analizado) por un programa especial: un rastreador, que descarga todas las im√°genes del feed, las coloca en el disco duro (m√°s precisamente, en el almacenamiento de red al que est√° conectado su servidor), escribe toda la metainformaci√≥n sobre los productos en la base de datos; </li><li>  luego se inicia otro proceso: el indexador, que calcula vectores de caracter√≠sticas binarias de 128 dimensiones para cada imagen.  Puede combinar el rastreador y el indexador en un m√≥dulo o programa, pero hist√≥ricamente hemos desarrollado que estos eran procesos diferentes.  Esto se debi√≥ principalmente al hecho de que inicialmente calculamos descriptores (hashes) para cada imagen distribuida en una gran flota de m√°quinas, ya que este era un proceso muy intensivo en recursos.  Si trabaja solo con redes neuronales, entonces la primera m√°quina con una GPU es suficiente para usted; </li><li>  los vectores binarios se escriben en la base de datos, todos los procesos se completan y listo, la base de datos de su producto est√° lista para una b√∫squeda adicional; </li><li>  pero a√∫n queda un peque√±o truco: dado que todas las tiendas tienen diferentes cat√°logos con diferentes categor√≠as en el interior, entonces debe comparar las categor√≠as de todos los feeds contenidos en su base de datos con las categor√≠as del detector (m√°s precisamente, el clasificador) de los productos, a esto le llamamos el proceso de mapeo.  Esta es una rutina manual, pero un trabajo muy √∫til, durante el cual el operador, editando manualmente un archivo XML normal, compara las categor√≠as de fuentes en la base de datos con las categor√≠as del detector.  Aqu√≠ est√° el resultado: </li></ul><br><img src="https://habrastorage.org/webt/wb/je/hp/wbjehp3opuvabmnniuv8alvxwqm.png" alt="imagen"><br>  <i>Ejemplo de archivo de mapeo de categor√≠a: catalogador-clasificador</i> <br><br><h3>  Detecci√≥n y clasificaci√≥n. </h3><br>  Para encontrar algo similar a lo que nuestro ojo encontr√≥ en la foto, primero debemos detectar este "algo" (es decir, localizar y seleccionar el objeto).  Hemos recorrido un largo camino en la creaci√≥n de un detector, comenzando por entrenar cascadas OpenCV que no funcionaron en absoluto para esta tarea, y terminando con tecnolog√≠a moderna para detectar y clasificar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">R-FCN</a> y el clasificador basado en la red neuronal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ResNet</a> . <br><br>  Como los datos que se utilizaron para la capacitaci√≥n y las pruebas (las llamadas muestras de capacitaci√≥n y prueba), tomamos todo tipo de im√°genes de Internet: <br><br><ul><li>  buscar en im√°genes de Google / Yandex; </li><li>  conjuntos de datos marcados por terceros; </li><li>  redes sociales; </li><li>  sitios de revistas de moda; </li><li>  Tiendas de ropa, zapatos, bolsos en internet. </li></ul><br>  El marcado se llev√≥ a cabo utilizando una herramienta samopisny, el resultado del marcado fueron conjuntos de im√°genes y archivos * .seg para ellos, que almacenan las coordenadas de los objetos y las etiquetas de clase para ellos.  En promedio, de 100 a 200 im√°genes fueron etiquetadas para cada categor√≠a, el n√∫mero total de im√°genes en 205 clases fue de 65,000. <br><br>  Despu√©s de que el entrenamiento y las muestras de prueba est√©n listas, realizamos una doble verificaci√≥n del marcado, dando todas las im√°genes a otro operador.  Esto nos permiti√≥ filtrar una gran cantidad de errores que afectan fuertemente la calidad del entrenamiento de la red neuronal, es decir, el detector y el clasificador.  Luego, comenzamos a entrenar la red neuronal utilizando herramientas est√°ndar y "despegamos" la pr√≥xima instant√°nea de la red neuronal "en el calor del d√≠a" en unos pocos d√≠as.  En promedio, el tiempo de entrenamiento del detector y clasificador en el volumen de datos de 65,000 im√°genes en una GPU Titan X es de aproximadamente 3 d√≠as. <br><br>  Una red neuronal prefabricada de alguna manera debe ser verificada por su calidad, es decir, para evaluar si la versi√≥n actual de la red se ha vuelto mejor que la anterior y en qu√© medida.  C√≥mo lo hicimos <br><br><ul><li>  la muestra de prueba consisti√≥ en 12,000 im√°genes y se present√≥ exactamente de la misma manera que la capacitaci√≥n; </li><li>  escribimos una peque√±a herramienta que ejecut√≥ toda la muestra de prueba a trav√©s del detector y compil√≥ una tabla de este tipo (la versi√≥n completa de la tabla est√° disponible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ); </li><li>  esta tabla se agrega a Excel en una nueva pesta√±a y se compara con la anterior manualmente o con las f√≥rmulas integradas de Excel; </li><li>  en la salida obtenemos los indicadores generales del detector y clasificador TPR / FPR en todo el sistema en y para cada categor√≠a por separado. </li></ul><br><img src="https://habrastorage.org/webt/vq/ou/it/vqouitv0rpqps36tme91uu5ynpw.png" alt="imagen"><br>  <i>Ejemplo de una tabla de informes sobre la calidad del detector y el clasificador.</i> <br><br><h3>  M√≥dulo de b√∫squeda de im√°genes similares </h3><br>  Despu√©s de detectar elementos de vestuario en la fotograf√≠a, iniciamos el motor de b√∫squeda de im√°genes similares, as√≠ es como funciona: <br><br><ul><li>  para todos los fragmentos de imagen recortados (bienes detectados), los vectores de caracter√≠sticas binarias de 128 bits de la red neuronal se calculan en forma y color (de d√≥nde provienen, ver m√°s abajo); </li><li>  los mismos vectores calculados anteriormente en la etapa de indexaci√≥n para todas las im√°genes de los bienes almacenados en la base de datos ya est√°n cargados en la RAM de la computadora (ya que para buscar otros similares ser√° necesario realizar una gran cantidad de b√∫squedas y comparaciones por pares, cargamos toda la base de datos inmediatamente en la memoria, lo que nos permiti√≥ aumentar la velocidad de b√∫squeda es decenas de veces, mientras que la base de aproximadamente 100 mil productos cabe en no m√°s de 2-3 GB de RAM); </li><li>  los coeficientes de b√∫squeda para esta categor√≠a provienen de la interfaz o de las propiedades codificadas, por ejemplo, en la categor√≠a "vestido", buscamos m√°s en color que en forma (por ejemplo, b√∫squeda de 8 a 2 formas de color), y en la categor√≠a "zapatos de tac√≥n alto" buscamos Color de forma 1 a 1, ya que tanto la forma como el color son igualmente importantes aqu√≠; </li><li>  Adem√°s, los vectores para el cultivo (fragmentos) de la imagen de entrada se comparan en pares con la imagen de la base de datos, teniendo en cuenta los coeficientes (se compara la distancia de Hamming entre los vectores); </li><li>  Como resultado, se forma un conjunto de productos similares de la base de datos para cada fragmento de producto cortado, y se asigna un peso para cada producto (de acuerdo con una f√≥rmula simple, teniendo en cuenta la normalizaci√≥n, de modo que todos los pesos est√©n en el rango de 0 a 1) para la posibilidad de enviar a la interfaz, as√≠ como para m√°s clasificaci√≥n </li><li>  Se muestra una variedad de productos similares en la interfaz a trav√©s de la API web-JSON. </li></ul><br>  Las redes neuronales para la formaci√≥n de vectores de redes neuronales en forma y color se entrenan de la siguiente manera. <br><br><ol><li>  Para entrenar la red neuronal en forma, tomamos todas las im√°genes marcadas, recortamos los fragmentos de acuerdo con el marcado y los distribuimos en carpetas seg√∫n la clase: es decir, todos los su√©teres en una carpeta, todas las camisetas en otra y todos los zapatos de tac√≥n alto en la tercera, etc. d.  A continuaci√≥n, entrenamos un clasificador ordinario basado en esta muestra.  Por lo tanto, tipo de "explicar" a la red neuronal nuestra comprensi√≥n de la forma del objeto. </li><li>  Para entrenar la red neuronal en color, tomamos todas las im√°genes marcadas, recortamos los fragmentos seg√∫n el marcado y los distribuimos en carpetas seg√∫n el color: es decir, colocamos todas las camisetas, zapatos, bolsos, etc. en la carpeta "verde".  color verde (como resultado, cualquier objeto de color verde generalmente se acumula en una carpeta), en la carpeta "despojado" ponemos todas las cosas en una tira, y en la carpeta "rojo-blanco" todas las cosas rojas-blancas.  Luego, entrenamos un clasificador separado para estas clases, como si "explicara" a la red neuronal su comprensi√≥n del color de una cosa. </li></ol><br><img src="https://habrastorage.org/webt/b8/0-/qg/b80-qglyjgkpn6trfxxdm6b55gm.png" alt="imagen"><br>  <i>Un ejemplo de marcado de im√°genes por color para obtener vectores de signos de redes neuronales por color.</i> <br><br>  Curiosamente, dicha tecnolog√≠a funciona bien incluso en fondos complejos, es decir, cuando se cortan fragmentos de cosas no claramente a lo largo del contorno (m√°scara), sino a lo largo de un marco rectangular, que el marcador ha definido. <br><br>  La b√∫squeda de otros similares se basa en la extracci√≥n de vectores de caracter√≠sticas binarias de la red neuronal de esta manera: la salida de la pen√∫ltima capa se toma, comprime, normaliza y binariza.  En nuestro trabajo, nos comprimimos a un vector de 128 bits.  Puede hacerlo de manera un poco diferente, por ejemplo, como se describe en el art√≠culo de Yahoo " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprendizaje profundo de c√≥digos de hash binarios para la recuperaci√≥n r√°pida de im√°genes</a> ", pero la esencia de todos los algoritmos es casi la misma: se buscan im√°genes similares a la imagen comparando las propiedades que opera la red neuronal dentro de las capas. <br><br>  Inicialmente, como tecnolog√≠a para buscar im√°genes similares, utilizamos hash o descriptores de im√°genes basados ‚Äã‚Äã(calculados con mayor precisi√≥n) en ciertos algoritmos matem√°ticos, como el operador Sobel (o hash de contorno), el algoritmo SIFT (o puntos singulares), trazando un histograma o comparando el n√∫mero de √°ngulos en una imagen .  Esta tecnolog√≠a funcion√≥ y dio un resultado m√°s o menos sensato, pero los hash no se comparan con la tecnolog√≠a para buscar im√°genes similares basadas en propiedades asignadas por una red neuronal.  Si intenta explicar la diferencia en 2 palabras, entonces el algoritmo de comparaci√≥n de im√°genes basado en hash es una "calculadora" que est√° configurada para comparar im√°genes usando alguna f√≥rmula y funciona continuamente.  Una comparaci√≥n que usa caracter√≠sticas de una red neuronal es la "inteligencia artificial", entrenada por una persona para resolver un problema espec√≠fico de cierta manera.  Puede dar un ejemplo tan burdo: si busca su√©teres hash en rayas blancas y negras, es probable que encuentre todas las cosas en blanco y negro como similares.  Y si busca utilizando una red neuronal, entonces: <br><br><ul><li>  en los primeros lugares encontrar√°s todos los su√©teres con rayas blancas y negras, </li><li>  entonces todos los su√©teres blancos y negros </li><li>  y luego todos los su√©teres a rayas. </li></ul><br><h3>  JSON-API para una interacci√≥n conveniente con cualquier dispositivo y servicio </h3><br>  Hemos creado una WEB-JSON-API simple y conveniente para comunicar nuestro sistema con cualquier dispositivo y sistema, lo que, por supuesto, no es ninguna innovaci√≥n, sino un buen est√°ndar de desarrollo s√≥lido. <br><br><h3>  Interfaz web o aplicaci√≥n m√≥vil para ver resultados </h3><br>  Para verificar visualmente los resultados, as√≠ como para demostrar el sistema a los clientes, hemos desarrollado interfaces simples: <br><br><ul><li>  interfaz web, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://demo.likethis.me/</a> </li><li>  la aplicaci√≥n m√≥vil est√° disponible <a href="">aqu√≠</a> </li></ul><br><h3>  Errores cometidos en el proyecto. </h3><br><ul><li>  Inicialmente, es necesario definir m√°s claramente la tarea, y es, seg√∫n la tarea, seleccionar fotograf√≠as para el dise√±o.  Si necesita buscar fotos UGC (Contenido generado por el usuario), este es un caso y ejemplos de dise√±o.  Si necesita una b√∫squeda de fotos de revistas brillantes, este es un caso diferente, y si necesita una b√∫squeda de fotos donde se encuentra un objeto grande sobre un fondo blanco, esta es una historia separada y una muestra completamente diferente.  Lo mezclamos todo en una pila, lo que afect√≥ la calidad del detector y el clasificador. </li><li>  En las fotograf√≠as, siempre debe marcar TODOS los objetos, al menos por el hecho de que al menos de alguna manera se adapte a su tarea, por ejemplo, al elegir una selecci√≥n de vestuario similar, debe marcar inmediatamente todos los accesorios (cuentas, anteojos, pulseras, etc.), cabeza sombreros, etc.  Porque ahora que tenemos un gran conjunto de entrenamiento, para agregar otra categor√≠a necesitamos redistribuir TODAS las fotos, y este es un trabajo muy voluminoso. </li><li>  Lo m√°s probable es que la detecci√≥n se realice con una red de m√°scara, la transici√≥n a Mask-CNN y una soluci√≥n moderna basada en Detectron es una de las √°reas del desarrollo del sistema. </li><li>  Ser√≠a bueno decidir de inmediato c√≥mo va a determinar la calidad de la selecci√≥n de im√°genes similares: existen 2 m√©todos: "a simple vista" y este es el m√©todo m√°s simple y econ√≥mico y el segundo m√©todo "cient√≠fico", cuando recopila datos de "expertos" (personas, (estoy probando su algoritmo de b√∫squeda similar) y, en base a estos datos, forme una muestra de prueba y un cat√°logo espec√≠ficamente para buscar im√°genes similares.  Este m√©todo es bueno en teor√≠a y parece bastante convincente (para usted y para los clientes), pero en la pr√°ctica su implementaci√≥n es dif√≠cil y bastante costosa. </li></ul><br><h3>  Conclusi√≥n y nuevos planes de desarrollo. </h3><br>  Esta tecnolog√≠a est√° bastante lista y adecuada para su uso, ahora opera en uno de nuestros clientes en la tienda en l√≠nea como un servicio de recomendaci√≥n.  Adem√°s, recientemente, comenzamos a desarrollar un sistema similar en otra industria (es decir, ahora estamos trabajando con otros tipos de productos). <br><br>  Desde planes inmediatos: transferir la red a Mask-CNN, as√≠ como volver a marcar y volver a marcar im√°genes para mejorar la calidad del detector y el clasificador. <br><br>  En conclusi√≥n, quiero decir que de acuerdo con nuestros sentimientos, dicha tecnolog√≠a y, en general, las redes neuronales son capaces de resolver hasta el 80% de las tareas complejas y altamente intelectuales que nuestro cerebro cumple a diario.  ¬°La √∫nica pregunta es qui√©n es el primero en implementar dicha tecnolog√≠a y descargar a una persona del trabajo de rutina, liberando espacio para la creatividad y el desarrollo, que es, en nuestra opini√≥n, el prop√≥sito m√°s importante del hombre! <br><br><h3>  Referencias </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tecnolog√≠a R-FCN</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Red neuronal ResNet</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Buscar im√°genes similares utilizando una red neuronal</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/438542/">https://habr.com/ru/post/438542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../438530/index.html">Hipster Podcasts # 1</a></li>
<li><a href="../438534/index.html">Modbus en el microcontrolador ruso K1986BE92QI</a></li>
<li><a href="../438536/index.html">Bajo el cap√≥ del chatbot: qu√© puede hacer RocketBot y c√≥mo funciona</a></li>
<li><a href="../438538/index.html">Teamlead Conf 2019 Msk: sobre otro formato de comunicaci√≥n</a></li>
<li><a href="../438540/index.html">Tendencias en gesti√≥n de documentos y almacenamiento de datos para 2019</a></li>
<li><a href="../438544/index.html">Vemos pel√≠culas en casa: 10 materiales sobre c√≥mo construir un cine en casa y elegir equipos</a></li>
<li><a href="../438546/index.html">An√°lisis de los enfoques de enlace de m√≥dulos en Node.js</a></li>
<li><a href="../438548/index.html">Lombok, sources.jar y depuraci√≥n conveniente</a></li>
<li><a href="../438550/index.html">Otro manifiesto</a></li>
<li><a href="../438554/index.html">Administrar estados y eventos entre componentes en GameObject</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
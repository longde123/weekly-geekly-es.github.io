<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚴🏾 🎊 ☕️ Penyimpanan Tepercaya dengan DRBD9 dan Proxmox (Bagian 2: iSCSI + LVM) 🙌🏿 🏴󠁧󠁢󠁳󠁣󠁴󠁿 🌇</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam artikel sebelumnya, saya memeriksa kemungkinan membuat server NFS toleran-kesalahan menggunakan DRBD dan Proxmox. Ternyata cukup baik, tetapi ki...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Penyimpanan Tepercaya dengan DRBD9 dan Proxmox (Bagian 2: iSCSI + LVM)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417597/"><p><img src="https://habrastorage.org/getpro/habr/post_images/101/70c/524/10170c52443d67bd757a09ef22ba39e2.jpg" alt="gambar"></p><br><p>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel sebelumnya,</a> saya memeriksa kemungkinan membuat server NFS toleran-kesalahan menggunakan DRBD dan Proxmox.  Ternyata cukup baik, tetapi kita tidak akan berpuas diri dan sekarang kita akan mencoba untuk "memeras semua jus" dari penyimpanan kita. </p><br><p> Pada artikel ini saya akan memberi tahu Anda cara membuat target iSCSI yang toleran terhadap kesalahan dengan cara ini, yang akan kami gunakan LVM untuk memotong menjadi beberapa bagian dan menggunakannya untuk mesin virtual. </p><br><p>  Pendekatan inilah yang akan mengurangi beban dan meningkatkan kecepatan akses ke data beberapa kali, ini sangat bermanfaat ketika akses kompetitif ke data tidak diperlukan, misalnya, dalam kasus ketika Anda perlu mengatur penyimpanan untuk mesin virtual. </p><a name="habracut"></a><br><h2 id="para-slov-o-drbd">  Beberapa kata tentang DRBD </h2><br><p>  DRBD adalah solusi yang cukup sederhana dan matang, kode versi kedelapan diadopsi sebagai bagian dari kernel Linux.  Bahkan, itu mewakili mirror jaringan RAID1.  Versi kesembilan memperkenalkan dukungan untuk kuorum dan replikasi dengan lebih dari dua node. </p><br><p>  Bahkan, ini memungkinkan Anda untuk menggabungkan perangkat blok pada beberapa node fisik menjadi satu jaringan bersama yang umum. </p><br><p>  Menggunakan DRBD Anda dapat mencapai konfigurasi yang sangat menarik.  Hari ini kita akan berbicara tentang iSCSI dan LVM. </p><br><p>  Anda dapat mempelajari lebih lanjut dengan membaca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel</a> saya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sebelumnya</a> , di mana saya menggambarkan solusi ini secara rinci. </p><br><h2 id="para-slov-ob-iscsi">  Beberapa kata tentang iSCSI </h2><br><p>  iSCSI adalah protokol pengiriman perangkat blok melalui jaringan. </p><br><p>  Tidak seperti NBD, ini mendukung otorisasi, mengatasi kegagalan jaringan tanpa masalah dan mendukung banyak fungsi berguna lainnya, dan yang paling penting itu menunjukkan kinerja yang sangat baik. </p><br><p>  Ada sejumlah besar implementasinya, beberapa di antaranya juga termasuk dalam kernel dan tidak memerlukan kesulitan khusus untuk konfigurasi dan koneksinya. </p><br><h2 id="para-slov-ob-lvm">  Beberapa kata tentang LVM </h2><br><p>  Perlu disebutkan bahwa LINBIT memiliki solusi sendiri untuk Proxmox, itu harus bekerja di luar kotak dan memungkinkan untuk mencapai hasil yang serupa, tetapi dalam artikel ini saya tidak ingin fokus hanya pada Proxmox dan menjelaskan beberapa solusi yang lebih universal yang cocok untuk kedua Proxmox dan hal lain, dalam contoh ini, proxmox hanya digunakan sebagai sarana orkestrasi wadah, pada kenyataannya Anda dapat menggantinya dengan solusi lain, misalnya, meluncurkan wadah dengan target di Kubernetes. </p><br><p>  Adapun Proxmox secara khusus, ini berfungsi dengan baik dengan LUN dan LVM bersama, hanya menggunakan driver standar sendiri. </p><br><p>  Kelebihan LVM meliputi fakta bahwa penggunaannya bukan sesuatu yang revolusioner dan baru, tetapi sebaliknya, ini menunjukkan stabilitas yang kering, yang biasanya diperlukan dari penyimpanan.  Perlu disebutkan bahwa LVM cukup aktif digunakan di lingkungan lain, misalnya, di OpenNebula atau Kubernetes, dan didukung dengan cukup baik di sana. </p><br><p>  Dengan demikian, Anda akan menerima penyimpanan universal yang dapat digunakan dalam sistem yang berbeda (tidak hanya dalam proxmox), hanya menggunakan driver yang sudah jadi, tanpa perlu modifikasi khusus dengan file. </p><br><p>  Sayangnya, ketika memilih solusi penyimpanan, Anda harus selalu berkompromi.  Jadi di sini, solusi ini tidak akan memberikan Anda fleksibilitas yang sama seperti Ceph. <br>  Ukuran disk virtual dibatasi oleh ukuran grup LVM, dan area yang ditandai untuk disk virtual tertentu perlu dialokasikan ulang - ini sangat meningkatkan kecepatan akses ke data, tetapi tidak memungkinkan Thin-Provisioning (ketika disk virtual mengambil lebih sedikit ruang daripada yang sebenarnya).  Perlu disebutkan bahwa kinerja LVM melorot cukup banyak ketika menggunakan snapshot, dan karena itu kemungkinan penggunaan bebasnya sering dihilangkan. </p><br><p>  Ya, LVM mendukung Thin-Provision pools yang tidak memiliki kelemahan ini, tetapi sayangnya penggunaannya hanya mungkin dalam konteks satu node dan tidak ada cara untuk membagikan satu kumpulan Thin-Provision ke beberapa node dalam sebuah cluster. </p><br><p>  Namun terlepas dari kekurangan ini, karena kesederhanaannya, LVM masih tidak memungkinkan pesaing untuk mengatasinya dan sepenuhnya mendorongnya keluar dari medan perang. </p><br><p>  Dengan overhead yang cukup kecil, LVM masih memberikan solusi yang sangat cepat, stabil dan cukup fleksibel. </p><br><h1 id="obschaya-shema">  Skema umum </h1><br><ul><li>  Kami memiliki <strong>tiga node</strong> </li><li>  Setiap node memiliki <strong>perangkat drbd</strong> terdistribusi. </li><li>  Di atas perangkat drbd, sebuah <strong>wadah LXC</strong> dengan target iSCSI diluncurkan. </li><li>  Target terhubung ke ketiga node. </li><li>  <strong>Grup LVM</strong> telah dibuat pada target yang terhubung. </li><li>  Jika perlu, <strong>wadah LXC</strong> dapat pindah ke node lain, bersama dengan <strong>target iSCSI</strong> </li></ul><br><h1 id="nastroyka">  Kustomisasi </h1><br><p>  Kami menemukan ide sekarang, mari beralih ke implementasi. </p><br><p>  Secara default <strong>, versi kedelapan dari drbd</strong> disertakan <strong>dengan kernel Linux</strong> , sayangnya itu <strong>tidak cocok untuk</strong> kita dan kita perlu menginstal versi kesembilan dari modul. </p><br><p>  Hubungkan repositori LINBIT dan instal semua yang Anda butuhkan: </p><br><pre><code class="bash hljs">wget -O- https://packages.linbit.com/package-signing-pubkey.asc | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://packages.linbit.com/proxmox/ proxmox-5 drbd-9.0"</span></span> \ &gt; /etc/apt/sources.list.d/linbit.list apt-get update &amp;&amp; apt-get -y install pve-headers drbd-dkms drbd-utils drbdtop</code> </pre> <br><ul><li>  <code>pve-headers</code> - <code>pve-headers</code> kernel diperlukan untuk membangun modul </li><li>  <code>drbd-dkms</code> - modul kernel dalam format DKMS </li><li>  <code>drbd-utils</code> - utilitas manajemen DRBD dasar </li><li>  <code>drbdtop</code> adalah alat interaktif seperti top untuk DRBD saja </li></ul><br><p>  Setelah menginstal <strong>modul,</strong> periksa apakah semuanya baik-baik saja dengan itu: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># modprobe drbd # cat /proc/drbd version: 9.0.14-1 (api:2/proto:86-113)</span></span></code> </pre> <br><p>  Jika Anda melihat <strong>versi kedelapan</strong> di output perintah, maka ada yang tidak beres dan modul kernel <strong>in-tree</strong> dimuat.  Periksa <code>dkms status</code> mencari tahu apa alasannya. </p><br><p>  Setiap node yang kita miliki akan memiliki perangkat <strong>drbd yang</strong> sama berjalan di atas partisi reguler.  Pertama kita perlu menyiapkan bagian ini untuk drbd pada setiap node. </p><br><p>  Partisi seperti itu dapat berupa <strong>perangkat blok</strong> apa saja, dapat berupa lvm, zvol, partisi disk, atau keseluruhan disk.  Pada artikel ini saya akan menggunakan disk nvme terpisah dengan partisi di bawah drbd: <code>/dev/nvme1n1p1</code> </p><br><p>  Perlu dicatat bahwa nama perangkat cenderung berubah kadang-kadang, jadi lebih baik untuk segera menganggapnya sebagai kebiasaan untuk menggunakan symlink konstan ke perangkat. </p><br><p>  Anda dapat menemukan symlink untuk <code>/dev/nvme1n1p1</code> dengan cara ini: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># find /dev/disk/ -lname '*/nvme1n1p1' /dev/disk/by-partuuid/847b9713-8c00-48a1-8dff-f84c328b9da2 /dev/disk/by-path/pci-0000:0e:00.0-nvme-1-part1 /dev/disk/by-id/nvme-eui.0000000001000000e4d25c33da9f4d01-part1 /dev/disk/by-id/nvme-INTEL_SSDPEKKA010T7_BTPY703505FB1P0H-part1</span></span></code> </pre> <br><p>  Kami menggambarkan sumber daya kami pada ketiga simpul: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cat /etc/drbd.d/tgt1.res resource tgt1 { meta-disk internal; device /dev/drbd100; protocol C; net { after-sb-0pri discard-zero-changes; after-sb-1pri discard-secondary; after-sb-2pri disconnect; } on pve1 { address 192.168.2.11:7000; disk /dev/disk/by-partuuid/95e7eabb-436e-4585-94ea-961ceac936f7; node-id 0; } on pve2 { address 192.168.2.12:7000; disk /dev/disk/by-partuuid/aa7490c0-fe1a-4b1f-ba3f-0ddee07dfee3; node-id 1; } on pve3 { address 192.168.2.13:7000; disk /dev/disk/by-partuuid/847b9713-8c00-48a1-8dff-f84c328b9da2; node-id 2; } connection-mesh { hosts pve1 pve2 pve3; } }</span></span></code> </pre> <br><p>  Dianjurkan untuk menggunakan <strong>jaringan terpisah</strong> untuk sinkronisasi drbd. </p><br><p>  Sekarang buat metadata untuk drbd dan jalankan: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm create-md tgt1 initializing activity log initializing bitmap (320 KB) to all zero Writing meta data... New drbd meta data block successfully created. success # drbdadm up tgt1</span></span></code> </pre> <br><p>  Ulangi langkah-langkah ini pada ketiga node dan periksa status: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm status tgt1 role:Secondary disk:Inconsistent pve2 role:Secondary peer-disk:Inconsistent pve3 role:Secondary peer-disk:Inconsistent</span></span></code> </pre> <br><p>  Sekarang disk <strong>tidak konsisten</strong> kami <strong>ada</strong> di ketiga node, ini karena drbd tidak tahu disk mana yang harus diambil seperti aslinya.  Kita harus menandai salah satunya sebagai <strong>Primer</strong> agar statusnya disinkronkan ke node lain: </p><br><pre> <code class="bash hljs">drbdadm primary --force tgt1 drbdadm secondary tgt1</code> </pre> <br><p>  Segera setelah ini, <strong>sinkronisasi</strong> akan dimulai: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># drbdadm status tgt1 role:Secondary disk:UpToDate pve2 role:Secondary replication:SyncSource peer-disk:Inconsistent done:26.66 pve3 role:Secondary replication:SyncSource peer-disk:Inconsistent done:14.20</span></span></code> </pre><br><p>  Kita tidak harus menunggu sampai selesai dan kita bisa melakukan langkah lebih lanjut secara paralel.  Mereka dapat dieksekusi pada <strong>sembarang simpul</strong> , terlepas dari keadaan saat ini dari disk lokal di DRBD.  Semua permintaan akan secara otomatis dialihkan ke perangkat dengan status <strong>UpToDate</strong> . </p><br><p>  Jangan lupa untuk mengaktifkan <strong>autorun</strong> layanan drbd pada node: </p><br><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">enable</span></span> drbd.service</code> </pre> <br><h2 id="nastroyka-lxc-konteynera">  Mengkonfigurasi wadah LXC </h2><br><p>  Kami <strong>akan</strong> menghilangkan bagian konfigurasi dari <strong>cluster Proxmox yang terdiri</strong> dari tiga simpul, bagian ini dijelaskan dengan baik di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">wiki resmi</a> </p><br><p>  Seperti yang saya katakan sebelumnya, <strong>target iSCSI</strong> kami akan bekerja dalam <strong>wadah LXC</strong> .  Kami akan menyimpan wadah di perangkat <code>/dev/drbd100</code> yang baru saja kami buat. </p><br><p>  Pertama kita perlu membuat <strong>sistem file</strong> di atasnya: </p><br><pre> <code class="hljs powershell">mkfs <span class="hljs-literal"><span class="hljs-literal">-t</span></span> ext4 <span class="hljs-literal"><span class="hljs-literal">-O</span></span> mmp <span class="hljs-literal"><span class="hljs-literal">-E</span></span> mmp_update_interval=<span class="hljs-number"><span class="hljs-number">5</span></span> /dev/drbd100</code> </pre> <br><p>  <strong>Proxmox</strong> secara default mencakup <strong>perlindungan multimount</strong> di tingkat sistem file, pada prinsipnya, kita dapat melakukannya tanpa itu, karena  DRBD memiliki perlindungan sendiri secara default, itu hanya melarang <strong>Primary</strong> kedua untuk perangkat, tetapi hati-hati tidak melukai kita. </p><br><p>  Sekarang unduh templat Ubuntu: </p><br><pre> <code class="hljs pgsql"># wget http://download.proxmox.com/images/<span class="hljs-keyword"><span class="hljs-keyword">system</span></span>/ubuntu<span class="hljs-number"><span class="hljs-number">-16.04</span></span>-standard_16<span class="hljs-number"><span class="hljs-number">.04</span></span><span class="hljs-number"><span class="hljs-number">-1</span></span>_amd64.tar.gz -P /var/lib/vz/<span class="hljs-keyword"><span class="hljs-keyword">template</span></span>/<span class="hljs-keyword"><span class="hljs-keyword">cache</span></span>/</code> </pre> <br><p>  Dan buat wadah kami dari itu: </p><br><pre> <code class="hljs powershell">pct create <span class="hljs-number"><span class="hljs-number">101</span></span> local:vztmpl/ubuntu<span class="hljs-literal"><span class="hljs-literal">-16</span></span>.<span class="hljs-number"><span class="hljs-number">04</span></span><span class="hljs-literal"><span class="hljs-literal">-standard_16</span></span>.<span class="hljs-number"><span class="hljs-number">04</span></span><span class="hljs-literal"><span class="hljs-literal">-1_amd64</span></span>.tar.gz \ -<span class="hljs-literal"><span class="hljs-literal">-hostname</span></span>=tgt1 \ -<span class="hljs-literal"><span class="hljs-literal">-net0</span></span>=name=eth0,bridge=vmbr0,gw=<span class="hljs-number"><span class="hljs-number">192.168</span></span>.<span class="hljs-number"><span class="hljs-number">1.1</span></span>,ip=<span class="hljs-number"><span class="hljs-number">192.168</span></span>.<span class="hljs-number"><span class="hljs-number">1.11</span></span>/<span class="hljs-number"><span class="hljs-number">24</span></span> \ -<span class="hljs-literal"><span class="hljs-literal">-rootfs</span></span>=volume=/dev/drbd100,shared=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  Dalam perintah ini, kami menunjukkan bahwa <strong>sistem root dari</strong> wadah kami akan ada di perangkat <code>/dev/drbd100</code> dan menambahkan parameter <code>shared=1</code> untuk memungkinkan <strong>migrasi</strong> kontainer di antara node. </p><br><p>  Jika terjadi kesalahan, Anda selalu dapat memperbaikinya melalui antarmuka <strong>Proxmox</strong> atau di <code>/etc/pve/lxc/101.conf</code> wadah </p><br><p>  Proxmox akan membongkar templat dan menyiapkan <strong>sistem root</strong> wadah untuk kami.  Setelah itu kita bisa meluncurkan wadah kita: </p><br><pre> <code class="hljs pgsql">pct <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span></code> </pre> <br><h2 id="nastroyka-iscsi-targeta">  Mengkonfigurasi target iSCSI. </h2><br><p>  Dari seluruh rangkaian <strong>target</strong> , saya memilih <strong>istgt</strong> , karena memiliki kinerja tertinggi dan bekerja di ruang pengguna. </p><br><p>  Sekarang mari masuk ke wadah kami: </p><br><pre> <code class="hljs perl">pct <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> <span class="hljs-number"><span class="hljs-number">101</span></span> bash</code> </pre> <br><p>  Instal pembaruan dan <strong>istgt</strong> : </p><br><pre> <code class="hljs sql">apt-get <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y <span class="hljs-keyword"><span class="hljs-keyword">upgrade</span></span> apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> istgt</code> </pre> <br><p>  Buat file yang akan kami berikan melalui jaringan: </p><br><pre> <code class="hljs powershell">mkdir <span class="hljs-literal"><span class="hljs-literal">-p</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span> fallocate <span class="hljs-literal"><span class="hljs-literal">-l</span></span> <span class="hljs-number"><span class="hljs-number">740</span></span>G /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/target1.img</code> </pre> <br><p>  Sekarang kita perlu menulis konfigurasi untuk <strong>istgt</strong> <code>/etc/istgt/istgt.conf</code> : </p><br><pre> <code class="hljs sql">[Global] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Global section"</span></span> NodeBase <span class="hljs-string"><span class="hljs-string">"iqn.2018-07.org.example.tgt1"</span></span> PidFile /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/run/istgt.pid AuthFile /etc/istgt/auth.conf MediaDirectory /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/istgt LogFacility <span class="hljs-string"><span class="hljs-string">"local7"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Timeout</span></span> <span class="hljs-number"><span class="hljs-number">30</span></span> NopInInterval <span class="hljs-number"><span class="hljs-number">20</span></span> DiscoveryAuthMethod <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> MaxSessions <span class="hljs-number"><span class="hljs-number">16</span></span> MaxConnections <span class="hljs-number"><span class="hljs-number">4</span></span> MaxR2T <span class="hljs-number"><span class="hljs-number">32</span></span> MaxOutstandingR2T <span class="hljs-number"><span class="hljs-number">16</span></span> DefaultTime2Wait <span class="hljs-number"><span class="hljs-number">2</span></span> DefaultTime2Retain <span class="hljs-number"><span class="hljs-number">60</span></span> FirstBurstLength <span class="hljs-number"><span class="hljs-number">262144</span></span> MaxBurstLength <span class="hljs-number"><span class="hljs-number">1048576</span></span> MaxRecvDataSegmentLength <span class="hljs-number"><span class="hljs-number">262144</span></span> InitialR2T Yes ImmediateData Yes DataPDUInOrder Yes DataSequenceInOrder Yes ErrorRecoveryLevel <span class="hljs-number"><span class="hljs-number">0</span></span> [UnitControl] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Internal Logical Unit Controller"</span></span> AuthMethod CHAP Mutual AuthGroup AuthGroup10000 Portal UC1 <span class="hljs-number"><span class="hljs-number">127.0</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>:<span class="hljs-number"><span class="hljs-number">3261</span></span> Netmask <span class="hljs-number"><span class="hljs-number">127.0</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span> [PortalGroup1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"SINGLE PORT TEST"</span></span> Portal DA1 <span class="hljs-number"><span class="hljs-number">192.168</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.11</span></span>:<span class="hljs-number"><span class="hljs-number">3260</span></span> [InitiatorGroup1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Initiator Group1"</span></span> InitiatorName <span class="hljs-string"><span class="hljs-string">"ALL"</span></span> Netmask <span class="hljs-number"><span class="hljs-number">192.168</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>/<span class="hljs-number"><span class="hljs-number">24</span></span> [LogicalUnit1] <span class="hljs-keyword"><span class="hljs-keyword">Comment</span></span> <span class="hljs-string"><span class="hljs-string">"Hard Disk Sample"</span></span> TargetName disk1 TargetAlias <span class="hljs-string"><span class="hljs-string">"Data Disk1"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Mapping</span></span> PortalGroup1 InitiatorGroup1 AuthMethod <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> AuthGroup AuthGroup1 UseDigest <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span> UnitType Disk LUN0 <span class="hljs-keyword"><span class="hljs-keyword">Storage</span></span> /<span class="hljs-keyword"><span class="hljs-keyword">data</span></span>/target1.img <span class="hljs-keyword"><span class="hljs-keyword">Auto</span></span></code> </pre> <br><p>  Mulai kembali istgt: </p><br><pre> <code class="hljs pgsql">systemctl <span class="hljs-keyword"><span class="hljs-keyword">restart</span></span> istgt</code> </pre> <br><p>  Ini melengkapi pengaturan target </p><br><h2 id="nastroyka-ha">  Pengaturan HA </h2><br><p>  Sekarang kita dapat beralih ke konfigurasi <strong>HA-manager</strong> .  Mari kita membuat grup HA terpisah untuk perangkat kita: </p><br><pre> <code class="hljs powershell">ha<span class="hljs-literal"><span class="hljs-literal">-manager</span></span> groupadd tgt1 -<span class="hljs-literal"><span class="hljs-literal">-nodes</span></span> pve1,pve2,pve3 -<span class="hljs-literal"><span class="hljs-literal">-nofailback</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span> -<span class="hljs-literal"><span class="hljs-literal">-restricted</span></span>=<span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  <strong>Sumber daya</strong> kami hanya akan berfungsi pada node yang ditentukan untuk grup ini.  Tambahkan wadah kami ke grup ini: </p><br><pre> <code class="hljs powershell">ha<span class="hljs-literal"><span class="hljs-literal">-manager</span></span> add ct:<span class="hljs-number"><span class="hljs-number">101</span></span> -<span class="hljs-literal"><span class="hljs-literal">-group</span></span>=tgt1 -<span class="hljs-literal"><span class="hljs-literal">-max_relocate</span></span>=<span class="hljs-number"><span class="hljs-number">3</span></span> -<span class="hljs-literal"><span class="hljs-literal">-max_restart</span></span>=<span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br><h2 id="rekomendacii-i-tyuning">  Rekomendasi dan penyetelan </h2><br><h5 id="drbd">  DRBD </h5><br><p>  Seperti yang saya sebutkan di atas, selalu disarankan untuk menggunakan jaringan terpisah untuk replikasi.  Sangat disarankan untuk menggunakan <strong>adapter jaringan 10-gigabit</strong> , jika tidak, Anda akan mengalami kecepatan port. <br>  Jika replikasi tampaknya cukup lambat, cobalah beberapa opsi untuk <strong>DRBD</strong> .  Ini adalah konfigurasi, yang menurut saya optimal untuk <strong>jaringan 10G</strong> saya: </p><br><pre> <code class="hljs swift"># cat /etc/drbd.d/global_common.conf global { usage-<span class="hljs-built_in"><span class="hljs-built_in">count</span></span> yes; udev-always-use-vnr; } common { handlers { } startup { } options { } disk { <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-fill-target 10M; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-<span class="hljs-built_in"><span class="hljs-built_in">max</span></span>-rate 720M; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-plan-ahead <span class="hljs-number"><span class="hljs-number">10</span></span>; <span class="hljs-built_in"><span class="hljs-built_in">c</span></span>-<span class="hljs-built_in"><span class="hljs-built_in">min</span></span>-rate 20M; } net { <span class="hljs-built_in"><span class="hljs-built_in">max</span></span>-buffers 36k; sndbuf-size 1024k; rcvbuf-size 2048k; } }</code> </pre> <br><p>  Anda dapat memperoleh informasi lebih lanjut tentang setiap parameter dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasi DRBD resmi.</a> </p><br><h5 id="open-iscsi">  Buka iSCSI </h5><br><p>  Karena kami tidak menggunakan multipathing, dalam kasus kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">disarankan untuk</a> menonaktifkan pemeriksaan koneksi berkala pada klien, serta meningkatkan waktu tunggu tunggu untuk pemulihan sesi di <code>/etc/iscsi/iscsid.conf</code> . </p><br><pre> <code class="hljs powershell">node.conn[<span class="hljs-number"><span class="hljs-number">0</span></span>].timeo.noop_out_interval = <span class="hljs-number"><span class="hljs-number">0</span></span> node.conn[<span class="hljs-number"><span class="hljs-number">0</span></span>].timeo.noop_out_timeout = <span class="hljs-number"><span class="hljs-number">0</span></span> node.session.timeo.replacement_timeout = <span class="hljs-number"><span class="hljs-number">86400</span></span></code> </pre> <br><h2 id="ispolzovanie">  Gunakan </h2><br><h4 id="proxmox">  Proxmox </h4><br><p>  <strong>Target iSCSI yang</strong> dihasilkan dapat langsung terhubung ke Proxmox, tanpa lupa untuk menghapus centang <strong>Gunakan LUN Secara Langsung</strong> . </p><br><p><img src="https://habrastorage.org/webt/uw/j3/pu/uwj3pusr-nf9bc7neisd5x-fcsg.png"></p><br><p>  Segera setelah itu, dimungkinkan untuk membuat LVM di atasnya, jangan lupa untuk mencentang kotak <strong>bersama</strong> : </p><br><p><img src="https://habrastorage.org/webt/j1/ob/mw/j1obmwcwhz-e6krjix72pmiz118.png"></p><br><h4 id="drugie-sredy">  Lingkungan lain </h4><br><p>  Jika Anda berencana untuk menggunakan solusi ini di lingkungan yang berbeda, Anda mungkin perlu menginstal ekstensi cluster untuk LVM pada saat ada dua implementasi.  <strong>CLVM</strong> dan <strong>lvmlockd</strong> . </p><br><p>  Mengkonfigurasi <strong>CLVM</strong> bukanlah hal sepele dan membutuhkan manajer kluster yang berfungsi. <br>  Sedangkan sebagai metode kedua, <strong>lvmlockd</strong> belum sepenuhnya diuji dan baru saja mulai muncul di repositori yang stabil. </p><br><p>  Saya sarankan membaca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><strong>artikel yang</strong></a> bagus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><strong>tentang pemblokiran di LVM</strong></a> </p><br><p>  Ketika menggunakan <strong>LVM</strong> dengan <strong>Proxmox,</strong> penambahan klaster <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tidak diperlukan</a> , karena manajemen volume disediakan oleh proxmox itu sendiri, yang memperbarui dan memonitor metadata LVM secara independen.  Hal yang sama berlaku untuk <strong>OpenNebula</strong> , seperti yang ditunjukkan oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasi resmi</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id417597/">https://habr.com/ru/post/id417597/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id417587/index.html">Media: serangan cyber skala besar mempercepat pertumbuhan kapitalisasi perusahaan dari industri keamanan informasi</a></li>
<li><a href="../id417589/index.html">Tujuh Aturan Sederhana untuk Membuat Internet Dapat Diakses oleh Semua Orang</a></li>
<li><a href="../id417591/index.html">Cara "belajar" bahasa Inggris dalam satu tahun sendiri atau artikel untuk mereka yang tidak berhasil dengan bahasa Inggris</a></li>
<li><a href="../id417593/index.html">NewSQL = NoSQL + ACID</a></li>
<li><a href="../id417595/index.html">Barang antik: Palm OS, kode efisien dan foto menjijikkan</a></li>
<li><a href="../id417599/index.html">Intisari Fintech: regulator keuangan membutuhkan AI agar dapat bekerja dalam kondisi modern</a></li>
<li><a href="../id417601/index.html">Pilih server. Apa yang harus dicari? Periksa daftar</a></li>
<li><a href="../id417603/index.html">Pengumuman mitap seluler: Apa yang harus dilakukan ketika aplikasi menjadi besar?</a></li>
<li><a href="../id417605/index.html">Dasar-dasar pemodelan 3D untuk pencetakan 3D</a></li>
<li><a href="../id417607/index.html">Tes A / B tidak berhasil. Periksa apa yang Anda lakukan salah</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
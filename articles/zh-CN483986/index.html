<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧑🏻 👨‍👧‍👦 👩🏼‍🎨 用Emotiv Insight来控制机器人的思想 🍳 👨🏾‍💼 🤖</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="用自己的四肢以外的任何事物控制思想是一个令人着迷的领域。 想象一个未来，我们不仅可以用手指，嘴，眼睛和耳朵与互联网进行交互，这总是很有趣的。 

 如果您考虑一下，计算机和电话的接口效率很低，无法获取必要的信息。 您确切地知道您想知道的内容：例如，卢布对美元的当前汇率。 用手指单击带字母的电话屏幕的...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>用Emotiv Insight来控制机器人的思想</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483986/"><img src="https://habrastorage.org/getpro/habr/post_images/754/afa/968/754afa96856a5cddfa557e7be634e35b.jpg" alt="图片"><br><br> 用自己的四肢以外的任何事物控制思想是一个令人着迷的领域。 想象一个未来，我们不仅可以用手指，嘴，眼睛和耳朵与互联网进行交互，这总是很有趣的。 <br><br> 如果您考虑一下，计算机和电话的接口效率很低，无法获取必要的信息。 您确切地知道您想知道的内容：例如，卢布对美元的当前汇率。 用手指单击带字母的电话屏幕的某些区域，每次对准正确的点，然后查看答案。 <br><br> 头脑里说“你好，伊戈尔！”，头脑里提一个问题，然后用耳朵/眼睛/以其他方式得到答案会更加美丽。 或以相同的快速方式将消息发送给朋友。 通常，将Internet连接到大脑。 <br><br> 由于现在可以在实践中尝试使用，因此值得管理一些东西，看看它有多方便，并得出结论。 带有结果的视频位于文章的结尾。 <br><a name="habracut"></a><br>  <a href="https://habr.com/ru/post/483986/">1.输入思路</a> <br>  <a href="https://habr.com/ru/post/483986/">2.需要什么</a> <br>  <a href="https://habr.com/ru/post/483986/">3.放在一起</a> <br>  <a href="https://habr.com/ru/post/483986/">4.我们尝试一次</a> <br>  <a href="https://habr.com/ru/post/483986/">5.尝试两个</a> <br>  <a href="https://habr.com/ru/post/483986/">6.三</a> <br>  <a href="https://habr.com/ru/post/483986/">7.周末的想法</a> <br><br><a name="anc1"></a><br><h2> 主意 </h2><br> 该计划很简单： <br><br>  <b>第1步。</b>携带一个能读取大脑活动的<a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BB%25D0%25B5%25D0%25BA%25D1%2582%25D1%2580%25D0%25BE%25D1%258D%25D0%25BD%25D1%2586%25D0%25B5%25D1%2584%25D0%25B0%25D0%25BB%25D0%25BE%25D0%25B3%25D1%2580%25D0%25B0%25D1%2584%25D0%25B8%25D1%258F">EEG设备</a> 。 <br>  <b>第2步。我们</b>训练了一些算法，使我们能够以足够的准确性确定思维命令。 我们尝试了几种类型的心理命令（稍后会详细介绍）。 <br>  <b>步骤3.</b>连接到任何移动的物体。 <br>  <b>步骤4.</b>我们尝试执行一个简单的任务，例如，从A点开车到B点。 <br>  <b>步骤5。</b>如果有时间的话，我们可以从所有结论中得出结论。 如果不是，则重复步骤2和4。 <br><br> 是的，以前很多专家都进行过类似的实验： <a href="https://en.wikipedia.org/wiki/P300_(neuroscience)">P300方法</a>有很多测试，它可以让您输入想法（它很准确， <a href="https://www.youtube.com/watch%3Fv%3DtI_CoJ8ICPA">但是很长一段时间</a> ），可以控制各种假肢和其他设备。 从科学的角度来看，当前的实验没有什么新的变化，目标是亲自尝试进行大脑控制，并从对BCI（脑机接口）的感受和想法中得出一些结论。 <br><br><a name="anc2"></a><br><h2> 需要什么 </h2><br> 我们将<a href="https://www.emotiv.com/insight/">Emotiv Insight</a>用作EEG设备。 与安装了电磁卡的低分辨率设备相比，它不是最准确的设备，但足以满足我们的目的。 它的价格<b>为299美元</b> ，这种型号几乎总是有折扣，但是问题是向俄罗斯交货：不是。 这从后勤方面而不是在立法问题上进行了解释：从俄罗斯联邦海关规则的角度来看，EEG设备是医疗设备（具有相应的后果）。 <br><br> 不可能在世界各地来取货，因此只能订购与俄罗斯有交货选择的那些邻近国家：波兰，以色列或类似国家。 有传言说它正在地板下在莫斯科出售，但有适当的利润。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ec6/329/d94/ec6329d94c8f06c4e38dd42bed2dd696.jpg" alt="图片"><br><br> 从软件的角度来看，Emotiv设备也很不错：它是专有的，但是可以做很多事情，并且，对于我们的实验而言，这很重要，它具有用于处理心理命令的内置工具。 <br><br> 作为机器人，我们采用<a href="http://hicat.io/">Hicat.Livera</a>平台。 建立在Arduino的基础上。 实际上，仅在使用摄像头，滚轮，激光和对该软件进行较小修改的情况下就可以了。 它的价格约为<b>$ 100- $ 150</b> ，通过速卖通订购可能更方便，但我们没有问题，但我们直接通过网站订购。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e8a/df4/983/e8adf498388c99e337556094971241b3.jpg" alt="图片"><br><br><a name="anc3"></a><br><h2> 放在一起 </h2><br> 在点上，将所有内容连接到测试平台的过程如下所示： <br><br>  <b>1. <a href="https://www.emotiv.com/get-started/">从此处</a>为Emotiv安装必要的软件</b> 。 从整体<a href="https://www.emotiv.com/product/emotiv-bci/">上看</a> ，我们需要一个连接器和<a href="https://www.emotiv.com/product/emotiv-bci/">Emotiv BCI</a> 。 <br><br>  <b>2.将Insight连接到计算机</b>并测试连接。 <br><br>  <b>3.安装<a href="https://nodered.org/">Node-RED</a></b> 。 这是一件奇妙的事情，可让您方便地处理数据和信号。 借助大量模块，您可以在几分钟内编译某种实用程序：以电报的形式向您发送即将到来的降雨警报，处理大量原始数据等等。 <br><br>  <b>4.</b>作为模块<b>添加到Node-RED Emotiv Toolbox</b> 。  <a href="https://emotiv.gitbook.io/emotivbci-node-red-toolbox/">这里描述</a>它是什么。 点击几下。 <br><br>  <b>5.我们收集Hicat.Livera。</b> 情况如此：如果按照说明进行所有操作，电池将不断脱落，其中一颗自攻螺钉会阻止相机旋转，依此类推。 在这里，您需要一些创意。 <br><br>  <b>6.将机器人连接到计算机。</b> 为此，您不需要任何其他软件，它是通过WebSocket进行控制的，只要在同一Wi-Fi网络上就足够了。 没错，这里的情况也并非如此简单：事实证明并非所有文件都由制造商写入存储卡，因此我不得不拆卸，从<a href="https://github.com/hicat-tech/webapp">存储库</a>下载并覆盖。 通常， <a href="https://www.kickstarter.com/projects/945994322/hicatlivera-start-making-your-first-machine-vision">kickstarter</a>项目的经典辉煌和贫穷。 <br><br>  <b>7. Node-RED中的主流程。</b> 我们从Emotiv BCI中受过训练的团队接收信号，清除它们在阈值上的噪声，并将接收到的功率值发送给机器人。 在每个信号后的三分之一秒内，我们重置电动机上的电压。 原来是这样的： <br><br><img src="https://habrastorage.org/getpro/habr/post_images/91a/c72/42d/91ac7242df7f16102273722b657af4e8.png" alt="图片"><br><br> 可以<a href="https://appcraft.pro/x/bci/insight-rivera-bci-sample.txt">从此处</a>下载Node-RED的卡本身，并将其导入您的Flow中。 <br><br> 此外，它仅是练习和尝试。 <br><br><a name="anc4"></a><br><h2> 尝试一次 </h2><br> 机器人可以前进/后退，分别旋转每个轮子，升高/降低摄像机并打开/关闭激光。 很难同时进行6到8项动作的训练，因此第一次尝试涉及三个动作：前进，左转和右转。 <br><br> 连接质量在方便的监视器上可以看到大脑。 就Insight而言，重要的是耳​​后主传感器必须紧紧紧贴头皮：如果其中有干扰，则其他六个传感器都不会发出信号。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/738/515/a29/738515a291b5477a5bc08d497974b6b1.png" alt="图片"><br><br> 接下来是训练。 首先，最困难的事情是在没有外界刺激和思想的情况下记录一种平静而正常的意识状态。 谁知道冥想仍然不在任何地方，但是就那样，思考任何事情都不容易。 该算法将以该记录为背景，并查找命令状态和默认状态之间的差异。 <br><br> 之后-对每个团队进行培训。 前两个或三个条目被无条件视为培训的基础。 接下来，算法每次都会确定您的记录与上一个记录相似的程度。 如果差异太大，则建议不要在培训中考虑此课程。 显然，在意识的状态过多的情况下，训练是没有意义的。 <br><br> 随后的每个培训课程都阐明了跟踪团队的模型状态。 从该模型的地图中，您可以看到团队之间的差异是多少：如果相似度太大（雷达上的点都在附近），则该算法将很难理解每种情况下的想法。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c8e/261/41e/c8e26141ed5236be715be82de7bd9fb5.png" alt="图片"><br><br> 培训期间的主要问题是，实际上该怎么想？ 用大脑，我们可以做两件事：控制肌肉和思考。 事实上，从脑电图的角度来看，负责肌肉运动的运动皮层会产生非常强烈的干扰。 就是说，如果作为一个团队，您尝试移动四肢，拉紧它们的肢体或想象它们正在起作用，那么这将产生持续的，无法分离的噪声，其精度与Insight模型一样。 <br><br> 还有待思考。 有一个广阔的领域：从心理上讲单词，思考某种感觉，想象自己在某个地方，想象机器人朝着正确的方向运动等等。 <br><br> 首先，选择一个口头指示：以内部声音为每个团队说出特定的用语。 <br><br> 事实证明，这种方法的结果并不令人满意：是的，这些命令肯定是在不同的敏感度设置下执行的，但事实证明完全不可能控制它们。 尝试执行命令和不执行命令之间有明显的区别：在第一种情况下，机器人会执行某项操作，在第二种情况下几乎什么也没有，但是不可能强迫它至少沿大致方向运行。 <br><br><a name="anc5"></a><br><h2> 试试两个 </h2><br> 此外，这个想法开始尝试以下领域： <br><br><ol><li> 例如，想想某个灿烂的时刻，您躺在沙滩上，阳光温暖。 </li><li> 聆听不同的声音信号/音乐摘录。 </li><li> 代表某些肢体某些部位的冷/热。 </li><li> 尝试模仿情绪高涨和情绪低落。 </li><li> 从不同角度聆听不同人的语音命令（通过增加空间感来增加信号的差异性）。 </li></ol><br> 结果很有趣：例如，一个人靠近实验对象的声音导致机器人朝一个方向移动，另一个人朝另一个方向移动。 这些人说什么都没关系。 <br><br> 但是总的来说，准确性却是令人遗憾的：以允许您执行严格的命令序列的质量进行管理是行不通的。 <br><br><a name="anc6"></a><br><h2> 三 </h2><br> 为了提高控制精度，决定将团队数量从三个减少到两个：向前移动和向一个方向转向。 这足以在飞机上前进，而只识别两个团队应该更容易。 <br><br> 结果如下： <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/GtFvJEP3ED0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br> 从A点到达B点非常容易，但是经过一系列的训练后，结果大致相同。 <br><br><a name="anc7"></a><br><h2> 周末的想法 </h2><br> 从实践的角度来看，以抽象的心理命令形式进行的BCI完全是不可能的。 是的，您可以将电极植入大脑的特定部位，进行长时间的训练，从而学会自己控制光标或机械臂。 这非常适合解决残疾问题和其他问题，但是在每种情况下，此解决方案都是针对特定人员的，因为 大脑需要相对较长的时间来建立新的神经连接。 <br><br> 作为大众界面：我买了它，将其拉到头上并使用它-不起作用。 我们中的一些人立即成功地实现了命令的清晰实现，而其他人即使经过长时间的培训也没有做任何事情。 该过程过于个性化，过于复杂，无法在使用说明中进行解释。 此外，成功管理后的第二天，很难重复同一件事：意识状态已经有所不同。 <br><br> 我认为，使用通过下颌和颈部肌肉电位变化来读取内在声音的设备进行“心理”控制会更加有效。 当我们自言自语时，神经信号被传递到声带的肌肉， <a href="https://ru.wikipedia.org/wiki/%25D0%25A1%25D1%2583%25D0%25B1%25D0%25B2%25D0%25BE%25D0%25BA%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25BE%25D0%25B5_%25D1%2580%25D0%25B0%25D1%2581%25D0%25BF%25D0%25BE%25D0%25B7%25D0%25BD%25D0%25B0%25D0%25B2%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B5">它们的运动非常轻微</a> 。 如果它们被敏感的传感器监控，那么几乎不需要培训，您就可以用内心的声音来朗读文本。 <br><br> 有很多类似的设备，最后一个是麻省理工学院研究人员的<a href="https://www.theguardian.com/technology/2018/apr/06/researchers-develop-device-that-can-hear-your-internal-voice">AlterEgo</a>项目。 在开发过程中，但在视频演示中，您可以看到它仍然运行相对良好。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f04/bfd/9da/f04bfd9da296dd073fe44818f5c6b20d.jpg" alt="图片"><br><br> 但是，从本质上讲，它是相同的语音控制，但是声音很小。 所有语音接口的问题是缺乏对命令调色板的理解。 如果我们查看网站或应用程序，则会看到按钮，它们的签名并了解在哪里戳。 如果是语音助手，则不了解确切的要求是什么，必须认真学习可能的命令，或者每次听一长串可能的话题进行对话时都必须学会。 所有这一切，加上不理想的语音识别，导致一个事实，即现在我们仅使用标准的语音助手命令集：呼叫Sophocles，设置计时器五百年，提醒您停下来工作。 <br><br> 因此，目前我们有以下内容：a）如果您进行一些管理以使其看起来很酷，但同时又可以正常工作，则它仅读取内部语音（此处也必须进行实验），并且b）到目前为止，图形界面的竞争甚至不接近。 <br><br> 关于第二点， <a href="https://ru.wikipedia.org/wiki/%25D0%25A2%25D1%2580%25D0%25B0%25D0%25BD%25D1%2581%25D0%25BA%25D1%2580%25D0%25B0%25D0%25BD%25D0%25B8%25D0%25B0%25D0%25BB%25D1%258C%25D0%25BD%25D0%25B0%25D1%258F_%25D0%25BC%25D0%25B0%25D0%25B3%25D0%25BD%25D0%25B8%25D1%2582%25D0%25BD%25D0%25B0%25D1%258F_%25D1%2581%25D1%2582%25D0%25B8%25D0%25BC%25D1%2583%25D0%25BB%25D1%258F%25D1%2586%25D0%25B8%25D1%258F">经颅磁刺激</a>领域中有一些技术。 简而言之：如果将诸如微波之类的东西聚焦在视觉皮层上，那么我们将看到磷化石-发光的点和眼睛看不到的效果。 这样的设备可以绘制相当准确的字符，例如空格中的字母。 通常，这些程序通常不会引起严重的头痛和恶心，因此不建议在实验中使用，但从理论上讲，可以在没有眼镜和眼镜的铁人脸上绘制界面。 没错，您可以使用镜片和眼镜，但也许还要再这样。 <br><br>  <sup>封面上是<a href="https://www.roadtovr.com/valve-brain-computer-interfaces-vr-ar-gdc-2019/">Road to VR</a>为Valve的BCI实验撰写的照片。</sup> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN483986/">https://habr.com/ru/post/zh-CN483986/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN483972/index.html">如何使用Quora促进您的业务</a></li>
<li><a href="../zh-CN483974/index.html">通过iSCSI进行的Ceph-或站在吊床上滑雪</a></li>
<li><a href="../zh-CN483976/index.html">2020年的网络安全和威胁：假期过后我们等待着什么</a></li>
<li><a href="../zh-CN483978/index.html">了解2020年现代Web App开发的概念</a></li>
<li><a href="../zh-CN483980/index.html">创建容错IT基础架构。 第1部分-准备部署oVirt 4.3集群</a></li>
<li><a href="../zh-CN483988/index.html">MicroSPA或如何发明方形齿轮</a></li>
<li><a href="../zh-CN483992/index.html">为什么有些行星会吞噬天空</a></li>
<li><a href="../zh-CN483994/index.html">游艇上的IT迁移。 从瑞典到西班牙</a></li>
<li><a href="../zh-CN484004/index.html">@Pythonetc 2019年12月</a></li>
<li><a href="../zh-CN484006/index.html">我的电报频道@pythonetc的提示和技巧，2019年12月</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
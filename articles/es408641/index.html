<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ûñ üìì üîà Google AI entren√≥ a una IA infantil que supera todas las IA artificiales üë©üèΩ‚Äçüé§ üë©üèø‚ÄçüöÄ üëÉüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En mayo de 2017, los investigadores de Google Brain presentaron el proyecto AutoML , que automatiza el dise√±o de modelos de aprendizaje autom√°tico. Lo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Google AI entren√≥ a una IA infantil que supera todas las IA artificiales</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408641/"><img src="https://habrastorage.org/webt/ln/6r/6b/ln6r6bzfxlghsrnz9jtc7zd_qv0.jpeg"><br><br>  En mayo de 2017, los investigadores de Google Brain presentaron el proyecto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AutoML</a> , que automatiza el dise√±o de modelos de aprendizaje autom√°tico.  Los experimentos de AutoML han demostrado que este sistema puede generar redes neuronales peque√±as con un rendimiento muy bueno, bastante comparable a las redes neuronales dise√±adas y entrenadas por expertos humanos.  Sin embargo, al principio, AutoML se limit√≥ a peque√±os conjuntos de datos cient√≠ficos como CIFAR-10 y Penn Treebank. <br><br>  Los ingenieros de Google se preguntaron: ¬øqu√© pasa si ponemos tareas m√°s serias para el generador de IA?  ¬øEs este sistema de IA capaz de generar otra IA que ser√° mejor que la IA artificial en alguna tarea importante como clasificar objetos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ImageNet</a> , el m√°s famoso de los conjuntos de datos a gran escala en visi√≥n artificial?  As√≠ que hab√≠a una red neuronal <b>NASNet</b> , creada casi sin intervenci√≥n humana. <br><a name="habracut"></a><br>  Al final result√≥ que, AI hace frente al dise√±o y entrenamiento de redes neuronales no peor que los humanos.  La tarea de clasificar objetos del conjunto de datos de ImageNet y definir objetos del conjunto de datos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">COCO</a> fue parte del proyecto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprendizaje de arquitecturas transferibles para reconocimiento de imagen escalable</a> . <br><br>  Los desarrolladores del proyecto AutoML <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dicen</a> que la tarea result√≥ no ser trivial, porque los nuevos conjuntos de datos son varios √≥rdenes de magnitud m√°s grandes que los anteriores con los que el sistema est√° acostumbrado a trabajar.  Tuve que cambiar algunos algoritmos de operaci√≥n de AutoML, incluido el redise√±o del espacio de b√∫squeda para que AutoML pudiera encontrar la mejor capa y duplicarla muchas veces antes de crear la versi√≥n final de la red neuronal.  Adem√°s, los desarrolladores exploraron opciones para la arquitectura de redes neuronales para CIFAR-10 y transfirieron manualmente la arquitectura m√°s exitosa a las tareas de ImageNet y COCO. <br><br>  Gracias a estas manipulaciones, el sistema AutoML pudo detectar las capas m√°s eficientes de la red neuronal que funcionaban bien para CIFAR-10 y al mismo tiempo funcionaban bien en tareas de ImageNet y COCO.  Estas dos capas descubiertas se combinaron para formar una arquitectura innovadora llamada NASNet. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/1d3/df6/b2e/1d3df6b2e8c9b601e8715f684b2de27b.png"><br>  <i><font color="gray">La arquitectura NASNet consta de dos tipos de capas: una capa normal (izquierda) y una capa de reducci√≥n (derecha).</font></i>  <i><font color="gray">Estas dos capas est√°n dise√±adas por un generador AutoML.</font></i> <br><br>  Los puntos de referencia mostraron que la IA generada autom√°ticamente supera todos los dem√°s sistemas de visi√≥n artificial creados y entrenados por expertos humanos en la clasificaci√≥n y definici√≥n de objetos. <br><br><img src="https://habrastorage.org/webt/gw/yl/ho/gwylhoe8de3ufsbiwlcyw8ya-k0.png"><br><br>  Entonces, en la tarea de clasificaci√≥n basada en ImageNet, la red neuronal NASNet demostr√≥ una precisi√≥n de predicci√≥n del 82.7% en el conjunto de prueba.  Este resultado es m√°s alto que todos los modelos de visi√≥n artificial dise√±ados previamente de la familia Inception.  El sistema NASNet mostr√≥ un resultado de al menos 1,2 puntos porcentuales m√°s alto que todas las redes neuronales de visi√≥n artificial conocidas, incluidos los √∫ltimos resultados de trabajos a√∫n no publicados en la prensa cient√≠fica, pero ya publicados en el sitio de preimpresi√≥n arXiv.org. <br><br>  Los investigadores enfatizan que NASNet se puede escalar y, por lo tanto, adaptarse para trabajar en sistemas con recursos inform√°ticos d√©biles sin mucha p√©rdida de precisi√≥n.  La red neuronal puede funcionar incluso en un tel√©fono m√≥vil con una CPU d√©bil con un recurso de memoria limitado.  Los autores dicen que la versi√≥n en miniatura de NASNet muestra una precisi√≥n del 74%, que es 3.1 puntos porcentuales mejor que las redes neuronales conocidas de m√°s alta calidad para plataformas m√≥viles. <br><br>  Cuando los atributos adquiridos del clasificador ImageNet se transfirieron al reconocimiento de objetos y se combinaron con el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">marco Faster-RCNN</a> , el sistema mostr√≥ los mejores resultados en el problema de reconocimiento de objetos COCO tanto en el modelo grande como en la versi√≥n reducida para plataformas m√≥viles.  El modelo grande mostr√≥ un resultado de 43.1% mAP, que es 4 puntos porcentuales mejor que el competidor m√°s cercano. <br><br>  Los autores abrieron el c√≥digo fuente de NASNet en los repositorios <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Slim</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Object Detection</a> para TensorFlow, para que todos puedan experimentar una nueva red neuronal en su propio trabajo. <br><br>  El art√≠culo cient√≠fico fue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicado</a> el 1 de diciembre de 2017 en el sitio de preimpresi√≥n arXiv.org (arXiv: 1707.07012v3, tercera versi√≥n). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es408641/">https://habr.com/ru/post/es408641/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es408631/index.html">Los centros de datos calientan hogares y oficinas</a></li>
<li><a href="../es408633/index.html">¬øA qu√© sab√≠a la comida del siglo XVII?</a></li>
<li><a href="../es408635/index.html">Software malicioso que pas√≥ a la historia. Parte III</a></li>
<li><a href="../es408637/index.html">Qu√© hacer si no puedes aprender un segundo idioma</a></li>
<li><a href="../es408639/index.html">Breve rese√±a del PocketBook 631 Plus: el primer lector insignia con temperatura de color ajustable de la luz de fondo</a></li>
<li><a href="../es408643/index.html">C√≥mo estudiar la historia de las matem√°ticas seg√∫n los dibujos de los "Principios" de Euclides</a></li>
<li><a href="../es408645/index.html">Tarjeta FPGA para Raspberry Pi</a></li>
<li><a href="../es408647/index.html">A√∫n m√°s espacio peque√±o. Gran Breta√±a quiere volver al campo de poderes espaciales</a></li>
<li><a href="../es408649/index.html">Prende fuego a tu cabeza como vecino o al impacto social</a></li>
<li><a href="../es408651/index.html">El segundo lanzamiento de Vostochny termin√≥ en fracaso. Meteor-M y carga adicional perdida</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
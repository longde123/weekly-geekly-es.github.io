<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙌 👨🏾‍🌾 🚝 Stellen Sie Apps mit Docker Swarm bereit 🤜🏾 👵🏻 🚈</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Online-Empfehlungssystem für Videoinhalte, an dem wir arbeiten, ist eine geschlossene kommerzielle Entwicklung und technisch gesehen ein Mehrkompo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Stellen Sie Apps mit Docker Swarm bereit</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471528/">  Das Online-Empfehlungssystem für Videoinhalte, an dem wir arbeiten, ist eine geschlossene kommerzielle Entwicklung und technisch gesehen ein Mehrkomponentencluster aus eigenen und Open-Source-Komponenten.  In diesem Artikel wird die Einführung eines Docker-Schwarm-Clustering-Systems unter einer Staging-Plattform beschrieben, ohne den vorhandenen Workflow unserer Prozesse in einer begrenzten Zeit zu stören.  Die Erzählung, auf die Sie aufmerksam gemacht werden, ist in zwei Teile unterteilt.  Der erste Teil beschreibt das CI / CD vor der Verwendung von Docker Swarm und der zweite Teil beschreibt den Implementierungsprozess.  Wer den ersten Teil nicht lesen möchte, kann sicher zum zweiten übergehen. <br><a name="habracut"></a><br><h3>  Teil I. </h3><br>  Im fernen, fernen Jahr musste der CI / CD-Prozess so schnell wie möglich konfiguriert werden.  Eine der Bedingungen bestand darin, Docker aus mehreren Gründen nicht zum <i>Bereitstellen der</i> entwickelten Komponenten zu verwenden: <br><br><ul><li>  für einen zuverlässigeren und stabileren Betrieb von Komponenten in der Produktion (d. h. tatsächlich die Anforderung, keine Virtualisierung zu verwenden) </li><li>  Führende Entwickler wollten nicht mit Docker arbeiten (seltsam, aber es war genau das) </li><li>  aus ideologischen Gründen F &amp; E-Management </li></ul><br>  Die anfänglichen Anforderungen an Infrastruktur, Stack und Beispiel für MVP waren wie folgt: <br><br><ul><li>  4 Intel® X5650 Server mit Debian (eine weitere leistungsstarke Maschine, die vollständig für die Entwicklung vorgesehen ist) </li><li>  Die Entwicklung benutzerdefinierter Komponenten erfolgt in C ++, Python3 </li><li>  Die wichtigsten von Drittanbietern verwendeten Tools: Kafka, Clickhouse, Airflow, Redis, Grafana, Postgresql, MySQL, ... </li><li>  Pipelines Montage und Test von Komponenten separat für Debug und Release </li></ul><br>  Eines der ersten Probleme, die in der Anfangsphase gelöst werden müssen, ist die Bereitstellung benutzerdefinierter Komponenten in einer beliebigen Umgebung (CI / CD). <br><br>  Komponenten von Drittanbietern haben beschlossen, sie systemisch zu installieren und systematisch zu aktualisieren.  Benutzerdefinierte Anwendungen, die in C ++ oder Python entwickelt wurden, können auf verschiedene Arten bereitgestellt werden.  Dazu gehören beispielsweise das Erstellen von Systempaketen, das Senden an das Repository der gesammelten Images und die anschließende Installation auf Servern.  Aus einem unbekannten Grund wurde eine andere Methode gewählt: Mit CI werden ausführbare Anwendungsdateien kompiliert, eine virtuelle Projektumgebung erstellt, py-Module aus require.txt installiert und alle diese Artefakte zusammen mit Konfigurationen, Skripten und der zugehörigen Anwendungsumgebung an die Server gesendet.  Als Nächstes werden Anwendungen von einem virtuellen Benutzer ohne Administratorrechte gestartet. <br><br>  Gitlab-CI wurde als CI / CD-System ausgewählt.  Die resultierende Pipeline sah ungefähr so ​​aus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/460/406/c27/460406c27d873dc28928ac3ba901f903.png" alt="Bild"><br><div class="spoiler">  <b class="spoiler_title">Strukturell sah gitlab-ci.yml so aus</b> <div class="spoiler_text"><pre><code class="xml hljs">--- variables: #     ,    CMAKE_CPUTYPE: "westmere" DEBIAN: "MYREGISTRY:5000/debian:latest" before_script: - eval $(ssh-agent -s) - ssh-add <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">(echo</span></span></span><span class="hljs-tag"> "$</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">SSH_PRIVATE_KEY</span></span></span><span class="hljs-tag">") </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">mkdir</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-p</span></span></span><span class="hljs-tag"> ~/</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">.ssh</span></span></span><span class="hljs-tag"> &amp;&amp; </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">echo</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-e</span></span></span><span class="hljs-tag"> "</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Host</span></span></span><span class="hljs-tag"> *\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">tStrictHostKeyChecking</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">no</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">" &gt;</span></span> ~/.ssh/config stages: - build - testing - deploy debug.debian: stage: build image: $DEBIAN script: - cd builds/release &amp;&amp; ./build.sh paths: - bin/ - builds/release/bin/ when: always release.debian: stage: build image: $DEBIAN script: - cd builds/release &amp;&amp; ./build.sh paths: - bin/ - builds/release/bin/ when: always ## testing stage tests.codestyle: stage: testing image: $DEBIAN dependencies: - release.debian script: - /bin/bash run_tests.sh -t codestyle -b "${CI_COMMIT_REF_NAME}_codestyle" tests.debug.debian: stage: testing image: $DEBIAN dependencies: - debug.debian script: - /bin/bash run_tests.sh -e codestyle/test_pylint.py -b "${CI_COMMIT_REF_NAME}_debian_debug" artifacts: paths: - run_tests/username/ when: always expire_in: 1 week tests.release.debian: stage: testing image: $DEBIAN dependencies: - release.debian script: - /bin/bash run_tests.sh -e codestyle/test_pylint.py -b "${CI_COMMIT_REF_NAME}_debian_release" artifacts: paths: - run_tests/username/ when: always expire_in: 1 week ## staging stage deploy_staging: stage: deploy environment: staging image: $DEBIAN dependencies: - release.debian script: - cd scripts/deploy/ &amp;&amp; python3 createconfig.py -s $CI_ENVIRONMENT_NAME &amp;&amp; /bin/bash install_venv.sh -d -r ../../requirements.txt &amp;&amp; python3 prepare_init.d.py &amp;&amp; python3 deploy.py -s $CI_ENVIRONMENT_NAME when: manual</code> </pre> <br></div></div><br>  Es ist anzumerken, dass die Montage und das Testen auf einem eigenen Image durchgeführt werden, auf dem bereits alle erforderlichen Systempakete installiert und andere Einstellungen vorgenommen wurden. <br><br>  Obwohl jedes dieser Skripte im Job auf seine Weise interessant ist, werde <s>ich sicherlich nicht darüber sprechen</s> , aber die Beschreibung jedes einzelnen wird einige Zeit in Anspruch nehmen, und dies ist nicht der Zweck des Artikels.  Ich werde nur darauf achten, dass die Bereitstellungsphase aus einer Folge von Skriptaufrufen besteht: <br><br><ol><li>  <b>createconfig.py</b> - <b>Erstellt</b> die Datei settings.ini mit den Einstellungen der Komponenten in einer anderen Umgebung für die nachfolgende Bereitstellung (Vorproduktion, Produktion, Test, ...). </li><li>  <b>install_venv.sh</b> - <b>Erstellt</b> eine virtuelle Umgebung für py-Komponenten in einem bestimmten Verzeichnis und kopiert sie auf Remoteserver </li><li>  <b>prepare_init.d.py</b> - bereitet Komponenten-Start-Stopp-Skripte basierend auf einer Vorlage vor </li><li>  <b>deploy.py</b> - <b>Dekomprimieren Sie</b> neue Komponenten und starten Sie sie neu </li></ol><br>  Die Zeit verging.  Die Inszenierungsphase wurde durch Vorproduktion und Produktion ersetzt.  Die Produktunterstützung wurde für ein anderes Distributionskit (CentOS) hinzugefügt.  5 leistungsstärkere physische Server und ein Dutzend virtuelle wurden hinzugefügt.  Und es wurde für Entwickler und Tester immer schwieriger, ihre Aufgaben in einer Umgebung auszuführen, die mehr oder weniger nahe am Arbeitszustand liegt.  Zu diesem Zeitpunkt wurde klar, dass es unmöglich ist, ohne ihn auszukommen ... <br><br><h3>  Teil II </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/673/166/f0e67316667fed0c0d673653419e8b8a.png" alt="Bild"><br><br>  Unser Cluster ist also <s>immer noch ein Spektakel eines</s> Systems aus ein paar Dutzend separaten Komponenten, die von Dockerfiles nicht beschrieben werden.  Sie können es nur für die Bereitstellung in einer bestimmten Umgebung als Ganzes konfigurieren.  Unsere Aufgabe besteht darin, den Cluster in einer Staging-Umgebung bereitzustellen, um ihn vor dem Testen vor der Veröffentlichung auszuführen. <br><br>  Theoretisch kann es mehrere gleichzeitig arbeitende Cluster geben: so viele Aufgaben wie erledigt oder kurz vor dem Abschluss.  Die Kapazitäten, die unseren Servern zur Verfügung stehen, ermöglichen es uns, mehrere Cluster auf jedem Server auszuführen.  Jeder Staging-Cluster muss isoliert sein (es sollte keine Schnittmenge an Ports, Verzeichnissen usw. geben). <br><br>  Die wertvollste Ressource ist unsere Zeit, und wir hatten nicht viel. <br><br>  Für einen schnelleren Start entschieden sie sich aufgrund seiner Einfachheit und Flexibilität in der Architektur für Docker Swarm.  Das erste, was wir gemacht haben, war das Erstellen auf den Remote-Manager-Servern und mehreren Knoten: <br><br><pre> <code class="bash hljs">$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION kilqc94pi2upzvabttikrfr5d nop-test-1 Ready Active 19.03.2 jilwe56pl2zvabupryuosdj78 nop-test-2 Ready Active 19.03.2 j5a4yz1kr2xke6b1ohoqlnbq5 * nop-test-3 Ready Active Leader 19.03.2</code> </pre><br>  Als nächstes haben wir ein Netzwerk erstellt: <br><br><pre> <code class="bash hljs">$ docker network create --driver overlay --subnet 10.10.10.0/24 nw_swarm</code> </pre><br>  Als Nächstes verbanden sie Gitlab-CI- und Swarm-Knoten im Hinblick auf die Remoteverwaltung von CI-Knoten: Installieren von Zertifikaten, Einrichten geheimer Variablen und Einrichten des Docker-Dienstes auf dem Verwaltungsserver.  Dieser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> hat uns viel Zeit gespart. <br><br>  Als Nächstes haben wir Jobs zum Erstellen und Zerstören des Stapels in .gitlab-ci .yml hinzugefügt. <br><br><div class="spoiler">  <b class="spoiler_title">Zu .gitlab-ci .yml wurden einige weitere Jobs hinzugefügt</b> <div class="spoiler_text"><pre> <code class="xml hljs">## staging stage deploy_staging: stage: testing before_script: - echo "override global 'before_script'" image: "REGISTRY:5000/docker:latest" environment: staging dependencies: [] variables: DOCKER_CERT_PATH: "/certs" DOCKER_HOST: tcp://10.50.173.107:2376 DOCKER_TLS_VERIFY: 1 CI_BIN_DEPENDENCIES_JOB: "release.centos.7" script: - mkdir -p $DOCKER_CERT_PATH - echo "$TLSCACERT" &gt; $DOCKER_CERT_PATH/ca.pem - echo "$TLSCERT" &gt; $DOCKER_CERT_PATH/cert.pem - echo "$TLSKEY" &gt; $DOCKER_CERT_PATH/key.pem - docker stack deploy -c docker-compose.yml ${CI_ENVIRONMENT_NAME}_${CI_COMMIT_REF_NAME} --with-registry-auth - rm -rf $DOCKER_CERT_PATH when: manual ## stop staging stage stop_staging: stage: testing before_script: - echo "override global 'before_script'" image: "REGISTRY:5000/docker:latest" environment: staging dependencies: [] variables: DOCKER_CERT_PATH: "/certs" DOCKER_HOST: tcp://10.50.173.107:2376 DOCKER_TLS_VERIFY: 1 script: - mkdir -p $DOCKER_CERT_PATH - echo "$TLSCACERT" &gt; $DOCKER_CERT_PATH/ca.pem - echo "$TLSCERT" &gt; $DOCKER_CERT_PATH/cert.pem - echo "$TLSKEY" &gt; $DOCKER_CERT_PATH/key.pem - docker stack rm ${CI_ENVIRONMENT_NAME}_${CI_COMMIT_REF_NAME} # TODO: need check that stopped when: manual</code> </pre><br></div></div><br>  Aus dem obigen Codefragment geht hervor, dass Pipelines zwei Schaltflächen (deploy_staging, stop_staging) hinzugefügt wurden, für die ein manueller Eingriff erforderlich ist. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2de/e3c/790/2dee3c7907f75f793499665d8a60de8a.png" alt="Bild"><br>  Der Name des Stapels entspricht dem Namen des Zweigs, und diese Eindeutigkeit sollte ausreichen.  Dienste im Stapel erhalten eindeutige IP-Adressen sowie Ports, Verzeichnisse usw.  wird isoliert, aber von Stapel zu Stapel gleich (weil die Konfigurationsdatei für alle Stapel gleich ist) - das haben wir erreicht.  Wir stellen <b>den Stack</b> (Cluster) mit <b>docker-compose.yml bereit</b> , das unseren Cluster beschreibt. <br><br><div class="spoiler">  <b class="spoiler_title">docker-compose.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">--- version: '3' services: userprop: image: redis:alpine deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: celery_bcd: image: redis:alpine deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: schedulerdb: image: mariadb:latest environment: MYSQL_ALLOW_EMPTY_PASSWORD: 'yes' MYSQL_DATABASE: schedulerdb MYSQL_USER: **** MYSQL_PASSWORD: **** command: ['--character-set-server=utf8mb4', '--collation-server=utf8mb4_unicode_ci', '--explicit_defaults_for_timestamp=1'] deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: celerydb: image: mariadb:latest environment: MYSQL_ALLOW_EMPTY_PASSWORD: 'yes' MYSQL_DATABASE: celerydb MYSQL_USER: **** MYSQL_PASSWORD: **** deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: cluster: image: $CENTOS7 environment: - CENTOS - CI_ENVIRONMENT_NAME - CI_API_V4_URL - CI_REPOSITORY_URL - CI_PROJECT_ID - CI_PROJECT_URL - CI_PROJECT_PATH - CI_PROJECT_NAME - CI_COMMIT_REF_NAME - CI_BIN_DEPENDENCIES_JOB command: &gt; sudo -u myusername -H /bin/bash -c ". /etc/profile &amp;&amp; mkdir -p /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME &amp;&amp; cd /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME &amp;&amp; git clone -b $CI_COMMIT_REF_NAME $CI_REPOSITORY_URL . &amp;&amp; curl $CI_API_V4_URL/projects/$CI_PROJECT_ID/jobs/artifacts/$CI_COMMIT_REF_NAME/download?job=$CI_BIN_DEPENDENCIES_JOB -o artifacts.zip &amp;&amp; unzip artifacts.zip ; cd /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME/scripts/deploy/ &amp;&amp; python3 createconfig.py -s $CI_ENVIRONMENT_NAME &amp;&amp; /bin/bash install_venv.sh -d -r ../../requirements.txt &amp;&amp; python3 prepare_init.d.py &amp;&amp; python3 deploy.py -s $CI_ENVIRONMENT_NAME" deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none tty: true stdin_open: true networks: nw_swarm: networks: nw_swarm: external: true</code> </pre><br></div></div><br>  Hier sehen Sie, dass die Komponenten über ein Netzwerk (nw_swarm) verbunden und für einander zugänglich sind. <br><br>  Systemkomponenten (basierend auf redis, mysql) werden vom gemeinsamen Pool benutzerdefinierter Komponenten getrennt (Pläne und benutzerdefinierte Komponenten werden als Services unterteilt).  Die Bereitstellungsphase unseres Clusters sieht aus wie die CMD-Übertragung auf unser einziges großes konfiguriertes Image und unterscheidet sich im Großen und Ganzen praktisch nicht von der in Teil I beschriebenen Bereitstellung. Ich betone die Unterschiede: <br><br><ul><li>  <b>Git-Klon ...</b> - Wir erhalten die Dateien, die für eine Bereitstellung erforderlich sind (createconfig.py, install_venv.sh usw.). </li><li>  <b>curl ... &amp;&amp; entpacken ...</b> - Baugruppenartefakte herunterladen und entpacken (kompilierte Dienstprogramme) </li></ul><br>  Es gibt nur ein Problem, das noch nicht beschrieben wurde: Komponenten mit einer Weboberfläche sind über Entwicklerbrowser nicht zugänglich.  Wir lösen dieses Problem mit Reverse Proxy, also: <br><br>  Fügen Sie in .gitlab-ci.yml nach der Bereitstellung des Cluster-Stacks die Balancer-Bereitstellungszeile hinzu (die beim Festschreiben nur die Konfiguration aktualisiert (erstellt neue Nginx-Konfigurationsdateien mithilfe der Vorlage: /etc/nginx/conf.d/${CI_COMMIT_REF_NAME►.conf) - siehe Code docker-compose-nginx.yml) <br><br><pre> <code class="xml hljs"> - docker stack deploy -c docker-compose-nginx.yml ${CI_ENVIRONMENT_NAME} --with-registry-auth</code> </pre><br><div class="spoiler">  <b class="spoiler_title">docker-compose-nginx.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">--- version: '3' services: nginx: image: nginx:latest environment: CI_COMMIT_REF_NAME: ${CI_COMMIT_REF_NAME} NGINX_CONFIG: |- server { listen 8080; server_name staging_${CI_COMMIT_REF_NAME}_cluster.dev; location / { proxy_pass http://staging_${CI_COMMIT_REF_NAME}_cluster:8080; } } server { listen 5555; server_name staging_${CI_COMMIT_REF_NAME}_cluster.dev; location / { proxy_pass http://staging_${CI_COMMIT_REF_NAME}_cluster:5555; } } volumes: - /tmp/staging/nginx:/etc/nginx/conf.d command: /bin/bash -c "echo -e \"$$NGINX_CONFIG\" &gt; /etc/nginx/conf.d/${CI_COMMIT_REF_NAME}.conf; nginx -g \"daemon off;\"; /etc/init.d/nginx reload" ports: - 8080:8080 - 5555:5555 - 3000:3000 - 443:443 - 80:80 deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: networks: nw_swarm: external: true</code> </pre><br></div></div><br>  Aktualisieren Sie auf Entwicklungscomputern / etc / hosts.  URL bei Nginx registrieren: <br><br> <code>10.50.173.106 staging_BRANCH-1831_cluster.dev <br></code> <br>  Daher wurde die Bereitstellung isolierter Staging-Cluster implementiert, und Entwickler können sie jetzt in <s>einer</s> ausreichenden Menge starten, um ihre Aufgaben zu testen. <br><br>  Weitere Pläne: <br><br><ul><li>  Trennen Sie unsere Komponenten als Dienstleistungen </li><li>  Machen Sie für jede Docker-Datei </li><li>  Weniger geladene Knoten im Stapel automatisch erkennen </li><li>  Legen Sie Knoten nach Namensmuster fest (anstatt ID wie im Artikel zu verwenden). </li><li>  Fügen Sie hinzu, überprüfen Sie, ob der Stapel zerstört ist </li><li>  ... </li></ul><br>  Besonderer Dank für den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de471528/">https://habr.com/ru/post/de471528/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de471516/index.html">Intel 665p - SSD mit 96-Layer-QLC-NAND</a></li>
<li><a href="../de471518/index.html">Apple im Jahr 2019 ist Linux im Jahr 2000</a></li>
<li><a href="../de471520/index.html">Das Buch "Klassische Informatik Aufgaben in Python"</a></li>
<li><a href="../de471522/index.html">Askozia. Funktionsweise von Autoprovisioning Plug & Play</a></li>
<li><a href="../de471524/index.html">Vollständige Übersetzung der Anweisungen für Gutachter Google</a></li>
<li><a href="../de471530/index.html">GitLab ging einen ungewöhnlichen Weg zu CI / CD und Kubernetes</a></li>
<li><a href="../de471532/index.html">Auf Wiedersehen PCB; Hallo Siliziumverbindung</a></li>
<li><a href="../de471536/index.html">Google Flood Prediction: Ein Einblick</a></li>
<li><a href="../de471538/index.html">Von der Idee einer mobilen Anwendung bis zum MVP, in das Investoren investieren werden</a></li>
<li><a href="../de471542/index.html">OCR-Texterkennung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôå üë®üèæ‚Äçüåæ üöù Stellen Sie Apps mit Docker Swarm bereit ü§úüèæ üëµüèª üöà</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Online-Empfehlungssystem f√ºr Videoinhalte, an dem wir arbeiten, ist eine geschlossene kommerzielle Entwicklung und technisch gesehen ein Mehrkompo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Stellen Sie Apps mit Docker Swarm bereit</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471528/">  Das Online-Empfehlungssystem f√ºr Videoinhalte, an dem wir arbeiten, ist eine geschlossene kommerzielle Entwicklung und technisch gesehen ein Mehrkomponentencluster aus eigenen und Open-Source-Komponenten.  In diesem Artikel wird die Einf√ºhrung eines Docker-Schwarm-Clustering-Systems unter einer Staging-Plattform beschrieben, ohne den vorhandenen Workflow unserer Prozesse in einer begrenzten Zeit zu st√∂ren.  Die Erz√§hlung, auf die Sie aufmerksam gemacht werden, ist in zwei Teile unterteilt.  Der erste Teil beschreibt das CI / CD vor der Verwendung von Docker Swarm und der zweite Teil beschreibt den Implementierungsprozess.  Wer den ersten Teil nicht lesen m√∂chte, kann sicher zum zweiten √ºbergehen. <br><a name="habracut"></a><br><h3>  Teil I. </h3><br>  Im fernen, fernen Jahr musste der CI / CD-Prozess so schnell wie m√∂glich konfiguriert werden.  Eine der Bedingungen bestand darin, Docker aus mehreren Gr√ºnden nicht zum <i>Bereitstellen der</i> entwickelten Komponenten zu verwenden: <br><br><ul><li>  f√ºr einen zuverl√§ssigeren und stabileren Betrieb von Komponenten in der Produktion (d. h. tats√§chlich die Anforderung, keine Virtualisierung zu verwenden) </li><li>  F√ºhrende Entwickler wollten nicht mit Docker arbeiten (seltsam, aber es war genau das) </li><li>  aus ideologischen Gr√ºnden F &amp; E-Management </li></ul><br>  Die anf√§nglichen Anforderungen an Infrastruktur, Stack und Beispiel f√ºr MVP waren wie folgt: <br><br><ul><li>  4 Intel¬Æ X5650 Server mit Debian (eine weitere leistungsstarke Maschine, die vollst√§ndig f√ºr die Entwicklung vorgesehen ist) </li><li>  Die Entwicklung benutzerdefinierter Komponenten erfolgt in C ++, Python3 </li><li>  Die wichtigsten von Drittanbietern verwendeten Tools: Kafka, Clickhouse, Airflow, Redis, Grafana, Postgresql, MySQL, ... </li><li>  Pipelines Montage und Test von Komponenten separat f√ºr Debug und Release </li></ul><br>  Eines der ersten Probleme, die in der Anfangsphase gel√∂st werden m√ºssen, ist die Bereitstellung benutzerdefinierter Komponenten in einer beliebigen Umgebung (CI / CD). <br><br>  Komponenten von Drittanbietern haben beschlossen, sie systemisch zu installieren und systematisch zu aktualisieren.  Benutzerdefinierte Anwendungen, die in C ++ oder Python entwickelt wurden, k√∂nnen auf verschiedene Arten bereitgestellt werden.  Dazu geh√∂ren beispielsweise das Erstellen von Systempaketen, das Senden an das Repository der gesammelten Images und die anschlie√üende Installation auf Servern.  Aus einem unbekannten Grund wurde eine andere Methode gew√§hlt: Mit CI werden ausf√ºhrbare Anwendungsdateien kompiliert, eine virtuelle Projektumgebung erstellt, py-Module aus require.txt installiert und alle diese Artefakte zusammen mit Konfigurationen, Skripten und der zugeh√∂rigen Anwendungsumgebung an die Server gesendet.  Als N√§chstes werden Anwendungen von einem virtuellen Benutzer ohne Administratorrechte gestartet. <br><br>  Gitlab-CI wurde als CI / CD-System ausgew√§hlt.  Die resultierende Pipeline sah ungef√§hr so ‚Äã‚Äãaus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/460/406/c27/460406c27d873dc28928ac3ba901f903.png" alt="Bild"><br><div class="spoiler">  <b class="spoiler_title">Strukturell sah gitlab-ci.yml so aus</b> <div class="spoiler_text"><pre><code class="xml hljs">--- variables: #     ,    CMAKE_CPUTYPE: "westmere" DEBIAN: "MYREGISTRY:5000/debian:latest" before_script: - eval $(ssh-agent -s) - ssh-add <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">(echo</span></span></span><span class="hljs-tag"> "$</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">SSH_PRIVATE_KEY</span></span></span><span class="hljs-tag">") </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">mkdir</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-p</span></span></span><span class="hljs-tag"> ~/</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">.ssh</span></span></span><span class="hljs-tag"> &amp;&amp; </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">echo</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">-e</span></span></span><span class="hljs-tag"> "</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Host</span></span></span><span class="hljs-tag"> *\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">tStrictHostKeyChecking</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">no</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">\</span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">n</span></span></span><span class="hljs-tag">" &gt;</span></span> ~/.ssh/config stages: - build - testing - deploy debug.debian: stage: build image: $DEBIAN script: - cd builds/release &amp;&amp; ./build.sh paths: - bin/ - builds/release/bin/ when: always release.debian: stage: build image: $DEBIAN script: - cd builds/release &amp;&amp; ./build.sh paths: - bin/ - builds/release/bin/ when: always ## testing stage tests.codestyle: stage: testing image: $DEBIAN dependencies: - release.debian script: - /bin/bash run_tests.sh -t codestyle -b "${CI_COMMIT_REF_NAME}_codestyle" tests.debug.debian: stage: testing image: $DEBIAN dependencies: - debug.debian script: - /bin/bash run_tests.sh -e codestyle/test_pylint.py -b "${CI_COMMIT_REF_NAME}_debian_debug" artifacts: paths: - run_tests/username/ when: always expire_in: 1 week tests.release.debian: stage: testing image: $DEBIAN dependencies: - release.debian script: - /bin/bash run_tests.sh -e codestyle/test_pylint.py -b "${CI_COMMIT_REF_NAME}_debian_release" artifacts: paths: - run_tests/username/ when: always expire_in: 1 week ## staging stage deploy_staging: stage: deploy environment: staging image: $DEBIAN dependencies: - release.debian script: - cd scripts/deploy/ &amp;&amp; python3 createconfig.py -s $CI_ENVIRONMENT_NAME &amp;&amp; /bin/bash install_venv.sh -d -r ../../requirements.txt &amp;&amp; python3 prepare_init.d.py &amp;&amp; python3 deploy.py -s $CI_ENVIRONMENT_NAME when: manual</code> </pre> <br></div></div><br>  Es ist anzumerken, dass die Montage und das Testen auf einem eigenen Image durchgef√ºhrt werden, auf dem bereits alle erforderlichen Systempakete installiert und andere Einstellungen vorgenommen wurden. <br><br>  Obwohl jedes dieser Skripte im Job auf seine Weise interessant ist, werde <s>ich sicherlich nicht dar√ºber sprechen</s> , aber die Beschreibung jedes einzelnen wird einige Zeit in Anspruch nehmen, und dies ist nicht der Zweck des Artikels.  Ich werde nur darauf achten, dass die Bereitstellungsphase aus einer Folge von Skriptaufrufen besteht: <br><br><ol><li>  <b>createconfig.py</b> - <b>Erstellt</b> die Datei settings.ini mit den Einstellungen der Komponenten in einer anderen Umgebung f√ºr die nachfolgende Bereitstellung (Vorproduktion, Produktion, Test, ...). </li><li>  <b>install_venv.sh</b> - <b>Erstellt</b> eine virtuelle Umgebung f√ºr py-Komponenten in einem bestimmten Verzeichnis und kopiert sie auf Remoteserver </li><li>  <b>prepare_init.d.py</b> - bereitet Komponenten-Start-Stopp-Skripte basierend auf einer Vorlage vor </li><li>  <b>deploy.py</b> - <b>Dekomprimieren Sie</b> neue Komponenten und starten Sie sie neu </li></ol><br>  Die Zeit verging.  Die Inszenierungsphase wurde durch Vorproduktion und Produktion ersetzt.  Die Produktunterst√ºtzung wurde f√ºr ein anderes Distributionskit (CentOS) hinzugef√ºgt.  5 leistungsst√§rkere physische Server und ein Dutzend virtuelle wurden hinzugef√ºgt.  Und es wurde f√ºr Entwickler und Tester immer schwieriger, ihre Aufgaben in einer Umgebung auszuf√ºhren, die mehr oder weniger nahe am Arbeitszustand liegt.  Zu diesem Zeitpunkt wurde klar, dass es unm√∂glich ist, ohne ihn auszukommen ... <br><br><h3>  Teil II </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/673/166/f0e67316667fed0c0d673653419e8b8a.png" alt="Bild"><br><br>  Unser Cluster ist also <s>immer noch ein Spektakel eines</s> Systems aus ein paar Dutzend separaten Komponenten, die von Dockerfiles nicht beschrieben werden.  Sie k√∂nnen es nur f√ºr die Bereitstellung in einer bestimmten Umgebung als Ganzes konfigurieren.  Unsere Aufgabe besteht darin, den Cluster in einer Staging-Umgebung bereitzustellen, um ihn vor dem Testen vor der Ver√∂ffentlichung auszuf√ºhren. <br><br>  Theoretisch kann es mehrere gleichzeitig arbeitende Cluster geben: so viele Aufgaben wie erledigt oder kurz vor dem Abschluss.  Die Kapazit√§ten, die unseren Servern zur Verf√ºgung stehen, erm√∂glichen es uns, mehrere Cluster auf jedem Server auszuf√ºhren.  Jeder Staging-Cluster muss isoliert sein (es sollte keine Schnittmenge an Ports, Verzeichnissen usw. geben). <br><br>  Die wertvollste Ressource ist unsere Zeit, und wir hatten nicht viel. <br><br>  F√ºr einen schnelleren Start entschieden sie sich aufgrund seiner Einfachheit und Flexibilit√§t in der Architektur f√ºr Docker Swarm.  Das erste, was wir gemacht haben, war das Erstellen auf den Remote-Manager-Servern und mehreren Knoten: <br><br><pre> <code class="bash hljs">$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION kilqc94pi2upzvabttikrfr5d nop-test-1 Ready Active 19.03.2 jilwe56pl2zvabupryuosdj78 nop-test-2 Ready Active 19.03.2 j5a4yz1kr2xke6b1ohoqlnbq5 * nop-test-3 Ready Active Leader 19.03.2</code> </pre><br>  Als n√§chstes haben wir ein Netzwerk erstellt: <br><br><pre> <code class="bash hljs">$ docker network create --driver overlay --subnet 10.10.10.0/24 nw_swarm</code> </pre><br>  Als N√§chstes verbanden sie Gitlab-CI- und Swarm-Knoten im Hinblick auf die Remoteverwaltung von CI-Knoten: Installieren von Zertifikaten, Einrichten geheimer Variablen und Einrichten des Docker-Dienstes auf dem Verwaltungsserver.  Dieser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> hat uns viel Zeit gespart. <br><br>  Als N√§chstes haben wir Jobs zum Erstellen und Zerst√∂ren des Stapels in .gitlab-ci .yml hinzugef√ºgt. <br><br><div class="spoiler">  <b class="spoiler_title">Zu .gitlab-ci .yml wurden einige weitere Jobs hinzugef√ºgt</b> <div class="spoiler_text"><pre> <code class="xml hljs">## staging stage deploy_staging: stage: testing before_script: - echo "override global 'before_script'" image: "REGISTRY:5000/docker:latest" environment: staging dependencies: [] variables: DOCKER_CERT_PATH: "/certs" DOCKER_HOST: tcp://10.50.173.107:2376 DOCKER_TLS_VERIFY: 1 CI_BIN_DEPENDENCIES_JOB: "release.centos.7" script: - mkdir -p $DOCKER_CERT_PATH - echo "$TLSCACERT" &gt; $DOCKER_CERT_PATH/ca.pem - echo "$TLSCERT" &gt; $DOCKER_CERT_PATH/cert.pem - echo "$TLSKEY" &gt; $DOCKER_CERT_PATH/key.pem - docker stack deploy -c docker-compose.yml ${CI_ENVIRONMENT_NAME}_${CI_COMMIT_REF_NAME} --with-registry-auth - rm -rf $DOCKER_CERT_PATH when: manual ## stop staging stage stop_staging: stage: testing before_script: - echo "override global 'before_script'" image: "REGISTRY:5000/docker:latest" environment: staging dependencies: [] variables: DOCKER_CERT_PATH: "/certs" DOCKER_HOST: tcp://10.50.173.107:2376 DOCKER_TLS_VERIFY: 1 script: - mkdir -p $DOCKER_CERT_PATH - echo "$TLSCACERT" &gt; $DOCKER_CERT_PATH/ca.pem - echo "$TLSCERT" &gt; $DOCKER_CERT_PATH/cert.pem - echo "$TLSKEY" &gt; $DOCKER_CERT_PATH/key.pem - docker stack rm ${CI_ENVIRONMENT_NAME}_${CI_COMMIT_REF_NAME} # TODO: need check that stopped when: manual</code> </pre><br></div></div><br>  Aus dem obigen Codefragment geht hervor, dass Pipelines zwei Schaltfl√§chen (deploy_staging, stop_staging) hinzugef√ºgt wurden, f√ºr die ein manueller Eingriff erforderlich ist. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2de/e3c/790/2dee3c7907f75f793499665d8a60de8a.png" alt="Bild"><br>  Der Name des Stapels entspricht dem Namen des Zweigs, und diese Eindeutigkeit sollte ausreichen.  Dienste im Stapel erhalten eindeutige IP-Adressen sowie Ports, Verzeichnisse usw.  wird isoliert, aber von Stapel zu Stapel gleich (weil die Konfigurationsdatei f√ºr alle Stapel gleich ist) - das haben wir erreicht.  Wir stellen <b>den Stack</b> (Cluster) mit <b>docker-compose.yml bereit</b> , das unseren Cluster beschreibt. <br><br><div class="spoiler">  <b class="spoiler_title">docker-compose.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">--- version: '3' services: userprop: image: redis:alpine deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: celery_bcd: image: redis:alpine deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: schedulerdb: image: mariadb:latest environment: MYSQL_ALLOW_EMPTY_PASSWORD: 'yes' MYSQL_DATABASE: schedulerdb MYSQL_USER: **** MYSQL_PASSWORD: **** command: ['--character-set-server=utf8mb4', '--collation-server=utf8mb4_unicode_ci', '--explicit_defaults_for_timestamp=1'] deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: celerydb: image: mariadb:latest environment: MYSQL_ALLOW_EMPTY_PASSWORD: 'yes' MYSQL_DATABASE: celerydb MYSQL_USER: **** MYSQL_PASSWORD: **** deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: cluster: image: $CENTOS7 environment: - CENTOS - CI_ENVIRONMENT_NAME - CI_API_V4_URL - CI_REPOSITORY_URL - CI_PROJECT_ID - CI_PROJECT_URL - CI_PROJECT_PATH - CI_PROJECT_NAME - CI_COMMIT_REF_NAME - CI_BIN_DEPENDENCIES_JOB command: &gt; sudo -u myusername -H /bin/bash -c ". /etc/profile &amp;&amp; mkdir -p /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME &amp;&amp; cd /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME &amp;&amp; git clone -b $CI_COMMIT_REF_NAME $CI_REPOSITORY_URL . &amp;&amp; curl $CI_API_V4_URL/projects/$CI_PROJECT_ID/jobs/artifacts/$CI_COMMIT_REF_NAME/download?job=$CI_BIN_DEPENDENCIES_JOB -o artifacts.zip &amp;&amp; unzip artifacts.zip ; cd /storage1/$CI_COMMIT_REF_NAME/$CI_PROJECT_NAME/scripts/deploy/ &amp;&amp; python3 createconfig.py -s $CI_ENVIRONMENT_NAME &amp;&amp; /bin/bash install_venv.sh -d -r ../../requirements.txt &amp;&amp; python3 prepare_init.d.py &amp;&amp; python3 deploy.py -s $CI_ENVIRONMENT_NAME" deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none tty: true stdin_open: true networks: nw_swarm: networks: nw_swarm: external: true</code> </pre><br></div></div><br>  Hier sehen Sie, dass die Komponenten √ºber ein Netzwerk (nw_swarm) verbunden und f√ºr einander zug√§nglich sind. <br><br>  Systemkomponenten (basierend auf redis, mysql) werden vom gemeinsamen Pool benutzerdefinierter Komponenten getrennt (Pl√§ne und benutzerdefinierte Komponenten werden als Services unterteilt).  Die Bereitstellungsphase unseres Clusters sieht aus wie die CMD-√úbertragung auf unser einziges gro√ües konfiguriertes Image und unterscheidet sich im Gro√üen und Ganzen praktisch nicht von der in Teil I beschriebenen Bereitstellung. Ich betone die Unterschiede: <br><br><ul><li>  <b>Git-Klon ...</b> - Wir erhalten die Dateien, die f√ºr eine Bereitstellung erforderlich sind (createconfig.py, install_venv.sh usw.). </li><li>  <b>curl ... &amp;&amp; entpacken ...</b> - Baugruppenartefakte herunterladen und entpacken (kompilierte Dienstprogramme) </li></ul><br>  Es gibt nur ein Problem, das noch nicht beschrieben wurde: Komponenten mit einer Weboberfl√§che sind √ºber Entwicklerbrowser nicht zug√§nglich.  Wir l√∂sen dieses Problem mit Reverse Proxy, also: <br><br>  F√ºgen Sie in .gitlab-ci.yml nach der Bereitstellung des Cluster-Stacks die Balancer-Bereitstellungszeile hinzu (die beim Festschreiben nur die Konfiguration aktualisiert (erstellt neue Nginx-Konfigurationsdateien mithilfe der Vorlage: /etc/nginx/conf.d/${CI_COMMIT_REF_NAME‚ñ∫.conf) - siehe Code docker-compose-nginx.yml) <br><br><pre> <code class="xml hljs"> - docker stack deploy -c docker-compose-nginx.yml ${CI_ENVIRONMENT_NAME} --with-registry-auth</code> </pre><br><div class="spoiler">  <b class="spoiler_title">docker-compose-nginx.yml</b> <div class="spoiler_text"><pre> <code class="xml hljs">--- version: '3' services: nginx: image: nginx:latest environment: CI_COMMIT_REF_NAME: ${CI_COMMIT_REF_NAME} NGINX_CONFIG: |- server { listen 8080; server_name staging_${CI_COMMIT_REF_NAME}_cluster.dev; location / { proxy_pass http://staging_${CI_COMMIT_REF_NAME}_cluster:8080; } } server { listen 5555; server_name staging_${CI_COMMIT_REF_NAME}_cluster.dev; location / { proxy_pass http://staging_${CI_COMMIT_REF_NAME}_cluster:5555; } } volumes: - /tmp/staging/nginx:/etc/nginx/conf.d command: /bin/bash -c "echo -e \"$$NGINX_CONFIG\" &gt; /etc/nginx/conf.d/${CI_COMMIT_REF_NAME}.conf; nginx -g \"daemon off;\"; /etc/init.d/nginx reload" ports: - 8080:8080 - 5555:5555 - 3000:3000 - 443:443 - 80:80 deploy: replicas: 1 placement: constraints: [node.id == kilqc94pi2upzvabttikrfr5d] restart_policy: condition: none networks: nw_swarm: networks: nw_swarm: external: true</code> </pre><br></div></div><br>  Aktualisieren Sie auf Entwicklungscomputern / etc / hosts.  URL bei Nginx registrieren: <br><br> <code>10.50.173.106 staging_BRANCH-1831_cluster.dev <br></code> <br>  Daher wurde die Bereitstellung isolierter Staging-Cluster implementiert, und Entwickler k√∂nnen sie jetzt in <s>einer</s> ausreichenden Menge starten, um ihre Aufgaben zu testen. <br><br>  Weitere Pl√§ne: <br><br><ul><li>  Trennen Sie unsere Komponenten als Dienstleistungen </li><li>  Machen Sie f√ºr jede Docker-Datei </li><li>  Weniger geladene Knoten im Stapel automatisch erkennen </li><li>  Legen Sie Knoten nach Namensmuster fest (anstatt ID wie im Artikel zu verwenden). </li><li>  F√ºgen Sie hinzu, √ºberpr√ºfen Sie, ob der Stapel zerst√∂rt ist </li><li>  ... </li></ul><br>  Besonderer Dank f√ºr den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de471528/">https://habr.com/ru/post/de471528/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de471516/index.html">Intel 665p - SSD mit 96-Layer-QLC-NAND</a></li>
<li><a href="../de471518/index.html">Apple im Jahr 2019 ist Linux im Jahr 2000</a></li>
<li><a href="../de471520/index.html">Das Buch "Klassische Informatik Aufgaben in Python"</a></li>
<li><a href="../de471522/index.html">Askozia. Funktionsweise von Autoprovisioning Plug & Play</a></li>
<li><a href="../de471524/index.html">Vollst√§ndige √úbersetzung der Anweisungen f√ºr Gutachter Google</a></li>
<li><a href="../de471530/index.html">GitLab ging einen ungew√∂hnlichen Weg zu CI / CD und Kubernetes</a></li>
<li><a href="../de471532/index.html">Auf Wiedersehen PCB; Hallo Siliziumverbindung</a></li>
<li><a href="../de471536/index.html">Google Flood Prediction: Ein Einblick</a></li>
<li><a href="../de471538/index.html">Von der Idee einer mobilen Anwendung bis zum MVP, in das Investoren investieren werden</a></li>
<li><a href="../de471542/index.html">OCR-Texterkennung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
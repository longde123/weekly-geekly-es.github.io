<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ“† ğŸ’ ğŸ§šğŸ¿ Base de donnÃ©es ClickHouse pour les humains ou technologie extraterrestre ğŸ§‘ğŸ¿â€ğŸ¤â€ğŸ§‘ğŸ½ ğŸ‘† ğŸ›</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Alexey Lizunov, chef du centre de compÃ©tence des canaux de service Ã  distance de la Direction des technologies de l'information de l'ICD 



 Comme al...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Base de donnÃ©es ClickHouse pour les humains ou technologie extraterrestre</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mkb/blog/472912/"> <b>Alexey Lizunov, chef du centre de compÃ©tence des canaux de service Ã  distance de la Direction des technologies de l'information de l'ICD</b> <br><br><img src="https://habrastorage.org/webt/bs/gu/k0/bsguk03an99lspkpmtkoks2bkvg.png"><br><br>  Comme alternative Ã  la pile ELK (ElasticSearch, Logstash, Kibana), nous menons des recherches sur l'utilisation de la base de donnÃ©es ClickHouse comme entrepÃ´t de donnÃ©es pour les journaux. <br><br>  Dans cet article, nous aimerions parler de notre expÃ©rience d'utilisation de la base de donnÃ©es ClickHouse et des rÃ©sultats prÃ©liminaires de l'opÃ©ration pilote.  Il convient de noter tout de suite que les rÃ©sultats ont Ã©tÃ© impressionnants. <br><br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/uy/mc/ip/uymcipeis_jm2piqsaqdjmu9_l8.jpeg"><br><br>  Ensuite, nous dÃ©crirons plus en dÃ©tail la configuration de notre systÃ¨me et les composants qui le composent.  Mais maintenant, je voudrais parler un peu de cette base de donnÃ©es dans son ensemble, et pourquoi vous devriez y prÃªter attention.  La base de donnÃ©es ClickHouse est une base de donnÃ©es de colonnes analytiques hautes performances de Yandex.  Il est utilisÃ© dans les services Yandex, au dÃ©part c'est le principal entrepÃ´t de donnÃ©es pour Yandex.Metrica.  Le systÃ¨me open-source est gratuit.  Du point de vue du dÃ©veloppeur, j'ai toujours Ã©tÃ© intÃ©ressÃ© par la faÃ§on dont ils l'ont implÃ©mentÃ©, car il y a des donnÃ©es incroyablement volumineuses.  Et l'interface utilisateur mÃ©trique elle-mÃªme est trÃ¨s flexible et rapide.  A la premiÃ¨re connaissance de cette base de donnÃ©es, l'impression: Â«Enfin, enfin!  ConÃ§u "pour les gens"!  Ã€ partir du processus d'installation et se terminant par l'envoi de demandes. " <br><br>  Cette base de donnÃ©es a un seuil d'entrÃ©e trÃ¨s bas.  MÃªme un dÃ©veloppeur qualifiÃ© moyen peut installer cette base de donnÃ©es en quelques minutes et commencer Ã  l'utiliser.  Tout fonctionne clairement.  MÃªme les dÃ©butants de Linux peuvent rapidement passer Ã  travers l'installation et effectuer des opÃ©rations simples.  Auparavant, lorsque le mot Big Data, Hadoop, Google BigTable, HDFS, le dÃ©veloppeur habituel avait l'idÃ©e qu'ils parlaient de certains tÃ©raoctets, pÃ©taoctets, que certains surhumains Ã©taient impliquÃ©s dans les paramÃ¨tres et le dÃ©veloppement de ces systÃ¨mes, puis avec l'avÃ¨nement de la base de donnÃ©es ClickHouse, nous avons obtenu Un outil simple et comprÃ©hensible avec lequel vous pouvez rÃ©soudre la gamme de tÃ¢ches auparavant inaccessible.  Une seule voiture assez moyenne et cinq minutes Ã  installer.  Autrement dit, nous avons une telle base de donnÃ©es comme, par exemple, MySql, mais uniquement pour stocker des milliards d'enregistrements!  Une sorte de superviseur SQL.  C'est comme si les gens recevaient des armes d'extraterrestres. <br><br><h4>  Ã€ propos de notre systÃ¨me de collecte de journaux </h4><br>  Pour collecter des informations, des fichiers journaux IIS d'applications Web d'un format standard sont utilisÃ©s (nous sommes Ã©galement engagÃ©s dans l'analyse des journaux d'applications, mais l'objectif principal au stade de l'opÃ©ration pilote avec nous est de collecter les journaux IIS). <br><br>  Pour diverses raisons, nous n'avons pas complÃ¨tement abandonnÃ© la pile ELK et nous continuons Ã  utiliser les composants LogStash et Filebeat, qui ont fait leurs preuves et fonctionnent de maniÃ¨re assez fiable et prÃ©visible. <br><br>  Le schÃ©ma de journalisation gÃ©nÃ©ral est prÃ©sentÃ© dans la figure ci-dessous: <br><br><img src="https://habrastorage.org/webt/ah/kr/qg/ahkrqgjij-tfce_455jhjikjfg8.jpeg"><br><br>  L'une des caractÃ©ristiques de l'Ã©criture de donnÃ©es dans la base de donnÃ©es ClickHouse est l'insertion peu frÃ©quente (une fois par seconde) d'enregistrements en lots importants.  Apparemment, c'est la partie la plus Â«problÃ©matiqueÂ» que vous rencontrez lorsque vous rencontrez pour la premiÃ¨re fois la base de donnÃ©es ClickHouse: le schÃ©ma est un peu compliquÃ©. <br>  Le plugin LogStash a beaucoup aidÃ© ici, qui insÃ¨re directement des donnÃ©es dans ClickHouse.  Ce composant est dÃ©ployÃ© sur le mÃªme serveur que la base de donnÃ©es elle-mÃªme.  Donc, d'une maniÃ¨re gÃ©nÃ©rale, il n'est pas recommandÃ© de le faire, mais d'un point de vue pratique, afin de ne pas produire de serveurs sÃ©parÃ©s pendant qu'il est dÃ©ployÃ© sur le mÃªme serveur.  Nous n'avons pas observÃ© d'Ã©checs ou de conflits de ressources avec la base de donnÃ©es.  De plus, il est Ã  noter que le plugin dispose d'un mÃ©canisme de retray en cas d'erreur.  Et en cas d'erreur, le plugin Ã©crit sur le disque un paquet de donnÃ©es qui n'a pas pu Ãªtre insÃ©rÃ© (le format de fichier est pratique: aprÃ¨s l'Ã©dition, vous pouvez facilement insÃ©rer le paquet corrigÃ© en utilisant clickhouse-client). <br><br>  La liste complÃ¨te des logiciels utilisÃ©s dans le schÃ©ma est prÃ©sentÃ©e dans le tableau: <br><br><div class="spoiler">  <b class="spoiler_title">Liste des logiciels utilisÃ©s</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  <b>Le titre</b> <br></td><td>  <b>La description</b> <br></td><td>  <b>Lien de distribution</b> <br></td></tr><tr><td><p>  Nginx </p><br></td><td><p>  Proxy inverse pour restreindre l'accÃ¨s au port et l'autorisation </p><br><br><p>  Non utilisÃ© actuellement dans le circuit. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://nginx.org/en/download.html</a> </p><br></td><td><p>  <a href="">https://nginx.org/download/nginx-1.16.0.tar.gz</a> </p><br></td></tr><tr><td><p>  Filebeat </p><br></td><td><p>  TransfÃ©rez les journaux de fichiers. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.elastic.co/downloads/beats/filebeat</a> (distribution pour Windows 64 bits). </p><br></td><td><p>  <a href="">https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.0-windows-x86_64.zip</a> </p><br></td></tr><tr><td><p>  Logstash </p><br></td><td><p>  Collecteur de journaux. </p><br><br><p>  UtilisÃ© pour collecter les journaux de FileBeat, ainsi que pour collecter les journaux de la file d'attente RabbitMQ (pour les serveurs qui se trouvent dans la DMZ.) </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.elastic.co/products/logstash</a> </p><br></td><td><p>  <a href="">https://artifacts.elastic.co/downloads/logstash/logstash-7.0.1.rpm</a> </p><br></td></tr><tr><td><p>  Logstash - sortie - clickhouse </p><br></td><td><p>  Plugin Loagstash pour transfÃ©rer des journaux vers la base de donnÃ©es ClickHouse par lots </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://github.com/mikechris/logstash-output-clickhouse</a> </p><br></td><td><p>  / usr / share / logstash / bin / logstash-plugin install logstash-output-clickhouse </p><br><p>  / usr / share / logstash / bin / logstash-plugin install logstash-filter-prune </p><br><p>  / usr / share / logstash / bin / logstash-plugin install logstash-filter-multiline </p><br></td></tr><tr><td><p>  Clickhouse </p><br></td><td><p>  RÃ©fÃ©rentiel de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">journaux https://clickhouse.yandex/docs/ru/</a> </p><br></td><td><p>  <a href="">https://packagecloud.io/Altinity/clickhouse/packages/el/7/clickhouse-server-19.5.3.8-1.el7.x86_64.rpm</a> </p><br><p>  <a href="">https://packagecloud.io/Altinity/clickhouse/packages/el/7/clickhouse-client-19.5.3.8-1.el7.x86_64.rpm</a> </p><br><p>  Remarque  Depuis aoÃ»t 2018, les assemblys rpm Â«normauxÂ» pour RHEL sont apparus dans le rÃ©fÃ©rentiel Yandex, vous pouvez donc essayer de les utiliser.  Au moment de l'installation, nous utilisions des packages compilÃ©s par Altinity. </p><br></td></tr><tr><td><p>  Grafana </p><br></td><td><p>  Visualisation du journal.  Configurer les tableaux de bord </p><br><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://grafana.com/</a> </p><br></td><td><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://grafana.com/grafana/download</a> </p><br><br><p>  Redhat &amp; Centos (64 Bit) - DerniÃ¨re version </p><br></td></tr><tr><td><p>  Source de donnÃ©es ClickHouse pour Grafana 4.6+ </p><br></td><td><p>  Plugin Grafana avec source de donnÃ©es ClickHouse </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://grafana.com/plugins/vertamedia-clickhouse-datasource</a> </p><br></td><td><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://grafana.com/api/plugins/vertamedia-clickhouse-datasource/versions/1.8.1/download</a> </p><br></td></tr><tr><td><p>  Logstash </p><br></td><td><p>  Connectez le routeur de FileBeat Ã  la file d'attente RabbitMQ. </p><br><p>  Remarque  Malheureusement, FileBeat n'a pas de sortie directement dans RabbitMQ, donc un lien intermÃ©diaire sous la forme de Logstash est requis </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.elastic.co/products/logstash</a> </p><br></td><td><p>  <a href="">https://artifacts.elastic.co/downloads/logstash/logstash-7.0.1.rpm</a> </p><br></td></tr><tr><td><p>  Rabbitmq </p><br></td><td><p>  File d'attente des messages  Ceci est un tampon d'entrÃ©es de journal dans DMZ </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.rabbitmq.com/download.html</a> </p><br></td><td><p>  <a href="">https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.14/rabbitmq-server-3.7.14-1.el7.noarch.rpm</a> </p><br></td></tr><tr><td><p>  Erlang Runtime (requis pour RabbitMQ) </p><br></td><td><p>  ExÃ©cution d'Erlang.  Requis pour que RabbitMQ fonctionne </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.erlang.org/download.html</a> </p><br></td><td><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.rabbitmq.com/install-rpm.html#install-erlang</a> <a href="">http://www.erlang.org/downloads/21.3</a> </p><br></td></tr></tbody></table></div><br></div></div><br>  La configuration du serveur avec la base de donnÃ©es ClickHouse est prÃ©sentÃ©e dans le tableau suivant: <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Le titre</b> <br></td><td>  <b>Valeur</b> <br></td><td>  <b>Remarque</b> <br></td></tr><tr><td><p>  La configuration </p><br></td><td><p>  Disque dur: 40 Go <br>  RAM: 8 Go <br>  Processeur: Core 2 2Ghz </p><br></td><td><p>  Il est nÃ©cessaire de prÃªter attention aux conseils sur le fonctionnement de la base de donnÃ©es ClickHouse ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://clickhouse.yandex/docs/ru/operations/tips/</a> ) </p><br></td></tr><tr><td><p>  Logiciel Ã  l'Ã©chelle du systÃ¨me </p><br></td><td><p>  SystÃ¨me d'exploitation: Red Hat Enterprise Linux Server (Maipo) </p><br><p>  JRE (Java 8) </p><br></td><td><p></p><br></td></tr></tbody></table></div><br>  Comme vous pouvez le voir, il s'agit d'un poste de travail normal. <br><br>  La structure du tableau de stockage des journaux est la suivante: <br><br><div class="spoiler">  <b class="spoiler_title">log_web.sql</b> <div class="spoiler_text"><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> log_web ( logdate <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>, logdatetime DateTime CODEC(Delta, LZ4HC), fld_log_file_name LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), fld_server_name LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), fld_app_name LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), fld_app_module LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), fld_website_name LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), serverIP LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), method LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), uriStem <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, uriQuery <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, port UInt32, username LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), clientIP <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, clientRealIP <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, userAgent <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, referer <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, response <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, subresponse <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, win32response <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, timetaken UInt64 , uriQuery__utm_medium <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__utm_source <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__utm_campaign <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__utm_term <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__utm_content <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__yclid <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__region <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">Engine</span></span> = MergeTree() <span class="hljs-keyword"><span class="hljs-keyword">PARTITION</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> toYYYYMM(logdate) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> (fld_app_name, fld_app_module, logdatetime) <span class="hljs-keyword"><span class="hljs-keyword">SETTINGS</span></span> index_granularity = <span class="hljs-number"><span class="hljs-number">8192</span></span>;</code> </pre> <br></div></div><br>  Nous utilisons des valeurs par dÃ©faut pour le partitionnement (par mois) et la granularitÃ© de l'index.  Tous les champs correspondent pratiquement aux entrÃ©es du journal IIS pour l'enregistrement des requÃªtes http.  SÃ©parÃ©ment, des champs sÃ©parÃ©s pour stocker les balises utm (ils sont analysÃ©s au stade de l'insertion dans la table Ã  partir du champ de chaÃ®ne de requÃªte). <br><br>  Dans le tableau, plusieurs champs systÃ¨me sont Ã©galement ajoutÃ©s pour stocker des informations sur les systÃ¨mes, les composants et les serveurs.  Voir le tableau ci-dessous pour une description de ces champs.  Dans une mÃªme table, nous stockons les journaux de plusieurs systÃ¨mes. <br><br><div class="scrollable-table"><table><tbody><tr><td>  <b>Le titre</b> <br></td><td>  <b>La description</b> <br></td><td>  <b>Exemple</b> <br></td></tr><tr><td><p>  fld_app_name </p><br></td><td><p>  Nom de l'application / du systÃ¨me <br>  Valeurs valides: </p><br><ul><li>  site1.domain.com Site externe 1 </li><li>  site2.domain.com Site externe 2 </li><li>  internal-site1.domain.local Site interne 1 </li></ul><br></td><td>  site1.domain.com <br></td></tr><tr><td><p>  fld_app_module </p><br></td><td><p>  Module systÃ¨me <br>  Valeurs valides: </p><br><ul><li>  web - Site Web </li><li>  svc - Service de site Web </li><li>  intgr - Service d'intÃ©gration Web </li><li>  bo - Administrateur (BackOffice) </li></ul><br></td><td><p>  web </p><br></td></tr><tr><td><p>  fld_website_name </p><br></td><td><p>  Nom du site Web dans IIS </p><br><p>  Plusieurs systÃ¨mes peuvent Ãªtre dÃ©ployÃ©s sur un serveur, voire plusieurs instances d'un mÃªme module systÃ¨me </p><br></td><td><p>  web-main </p><br></td></tr><tr><td><p>  fld_server_name </p><br></td><td><p>  Nom du serveur </p><br></td><td><p>  web1.domain.com </p><br></td></tr><tr><td><p>  fld_log_file_name </p><br></td><td><p>  Chemin d'accÃ¨s au fichier journal sur le serveur </p><br></td><td>  C: \ inetpub \ logs \ LogFiles <br>  \ W3SVC1 \ u_ex190711.log <br></td></tr></tbody></table></div><br>  Cela vous permet de crÃ©er efficacement des graphiques dans Grafana.  Par exemple, affichez les demandes du frontend d'un systÃ¨me spÃ©cifique.  Ceci est similaire au compteur de site dans Yandex.Metrica. <br><br>  Voici quelques statistiques sur l'utilisation de la base de donnÃ©es pendant deux mois. <br><br><div class="spoiler">  <b class="spoiler_title">Nombre d'enregistrements par systÃ¨me et composant</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> fld_app_name, fld_app_module, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(fld_app_name) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> rows_count <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> log_web <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> fld_app_name, fld_app_module <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> TOTALS <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> fld_app_name <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span>, rows_count <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> â”Œâ”€fld_app_nameâ”€â”€â”€â”€â”€â”¬â”€fld_app_moduleâ”€â”¬â”€rows_countâ”€â” â”‚ site1.domain.ru â”‚ web â”‚ <span class="hljs-number"><span class="hljs-number">131441</span></span> â”‚ â”‚ site2.domain.ru â”‚ web â”‚ <span class="hljs-number"><span class="hljs-number">1751081</span></span> â”‚ â”‚ site3.domain.ru â”‚ web â”‚ <span class="hljs-number"><span class="hljs-number">106887543</span></span> â”‚ â”‚ site3.domain.ru â”‚ svc â”‚ <span class="hljs-number"><span class="hljs-number">44908603</span></span> â”‚ â”‚ site3.domain.ru â”‚ intgr â”‚ <span class="hljs-number"><span class="hljs-number">9813911</span></span> â”‚ â”‚ site4.domain.ru â”‚ web â”‚ <span class="hljs-number"><span class="hljs-number">772095</span></span> â”‚ â”‚ site5.domain.ru â”‚ web â”‚ <span class="hljs-number"><span class="hljs-number">17037221</span></span> â”‚ â”‚ site5.domain.ru â”‚ intgr â”‚ <span class="hljs-number"><span class="hljs-number">838559</span></span> â”‚ â”‚ site5.domain.ru â”‚ bo â”‚ <span class="hljs-number"><span class="hljs-number">7404</span></span> â”‚ â”‚ site6.domain.ru â”‚ web â”‚ <span class="hljs-number"><span class="hljs-number">595877</span></span> â”‚ â”‚ site7.domain.ru â”‚ web â”‚ <span class="hljs-number"><span class="hljs-number">27778858</span></span> â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Totals: â”Œâ”€fld_app_nameâ”€â”¬â”€fld_app_moduleâ”€â”¬â”€rows_countâ”€â” â”‚ â”‚ â”‚ <span class="hljs-number"><span class="hljs-number">210522593</span></span> â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ <span class="hljs-number"><span class="hljs-number">11</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">4.874</span></span> sec. Processed <span class="hljs-number"><span class="hljs-number">210.52</span></span> million <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>, <span class="hljs-number"><span class="hljs-number">421.67</span></span> MB (<span class="hljs-number"><span class="hljs-number">43.19</span></span> million <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>/s., <span class="hljs-number"><span class="hljs-number">86.51</span></span> MB/s.)</code> </pre> <br></div></div><div class="spoiler">  <b class="spoiler_title">La quantitÃ© de donnÃ©es sur le disque</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> formatReadableSize(<span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(data_uncompressed_bytes)) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uncompressed, formatReadableSize(<span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(data_compressed_bytes)) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> compressed, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> total_rows <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> system.parts <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">table</span></span> = <span class="hljs-string"><span class="hljs-string">'log_web'</span></span> â”Œâ”€uncompressedâ”€â”¬â”€compressedâ”€â”¬â”€total_rowsâ”€â” â”‚ <span class="hljs-number"><span class="hljs-number">54.50</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">4.86</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">211427094</span></span> â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.035</span></span> sec.</code> </pre> <br></div></div><div class="spoiler">  <b class="spoiler_title">Le degrÃ© de compression des donnÃ©es dans les colonnes</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, formatReadableSize(data_uncompressed_bytes) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uncompressed, formatReadableSize(data_compressed_bytes) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> compressed, data_uncompressed_bytes / data_compressed_bytes <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> compress_ratio <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> system.columns <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">table</span></span> = <span class="hljs-string"><span class="hljs-string">'log_web'</span></span> â”Œâ”€<span class="hljs-keyword"><span class="hljs-keyword">name</span></span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€uncompressedâ”€â”¬â”€compressedâ”€â”¬â”€â”€â”€â”€â”€compress_ratioâ”€â” â”‚ logdate â”‚ <span class="hljs-number"><span class="hljs-number">401.53</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">1.80</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">223.16665968777315</span></span> â”‚ â”‚ logdatetime â”‚ <span class="hljs-number"><span class="hljs-number">803.06</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">35.91</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">22.363966401202305</span></span> â”‚ â”‚ fld_log_file_name â”‚ <span class="hljs-number"><span class="hljs-number">220.66</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">2.60</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">84.99905736932571</span></span> â”‚ â”‚ fld_server_name â”‚ <span class="hljs-number"><span class="hljs-number">201.54</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">50.63</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">3.980924816977078</span></span> â”‚ â”‚ fld_app_name â”‚ <span class="hljs-number"><span class="hljs-number">201.17</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">969.17</span></span> KiB â”‚ <span class="hljs-number"><span class="hljs-number">212.55518183686877</span></span> â”‚ â”‚ fld_app_module â”‚ <span class="hljs-number"><span class="hljs-number">201.17</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">968.60</span></span> KiB â”‚ <span class="hljs-number"><span class="hljs-number">212.67805817411906</span></span> â”‚ â”‚ fld_website_name â”‚ <span class="hljs-number"><span class="hljs-number">201.54</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">1.24</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">162.7204926761546</span></span> â”‚ â”‚ serverIP â”‚ <span class="hljs-number"><span class="hljs-number">201.54</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">50.25</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">4.010824061219731</span></span> â”‚ â”‚ method â”‚ <span class="hljs-number"><span class="hljs-number">201.53</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">43.64</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">4.617721053304486</span></span> â”‚ â”‚ uriStem â”‚ <span class="hljs-number"><span class="hljs-number">5.13</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">832.51</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">6.311522291936919</span></span> â”‚ â”‚ uriQuery â”‚ <span class="hljs-number"><span class="hljs-number">2.58</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">501.06</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">5.269731450124478</span></span> â”‚ â”‚ port â”‚ <span class="hljs-number"><span class="hljs-number">803.06</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">3.98</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">201.91673864241824</span></span> â”‚ â”‚ username â”‚ <span class="hljs-number"><span class="hljs-number">318.08</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">26.93</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">11.812513794583598</span></span> â”‚ â”‚ clientIP â”‚ <span class="hljs-number"><span class="hljs-number">2.35</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">82.59</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">29.132328640073343</span></span> â”‚ â”‚ clientRealIP â”‚ <span class="hljs-number"><span class="hljs-number">2.49</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">465.05</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">5.478382297052563</span></span> â”‚ â”‚ userAgent â”‚ <span class="hljs-number"><span class="hljs-number">18.34</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">764.08</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">24.57905114484208</span></span> â”‚ â”‚ referer â”‚ <span class="hljs-number"><span class="hljs-number">14.71</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">1.37</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">10.736792723669906</span></span> â”‚ â”‚ response â”‚ <span class="hljs-number"><span class="hljs-number">803.06</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">83.81</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">9.582334090987247</span></span> â”‚ â”‚ subresponse â”‚ <span class="hljs-number"><span class="hljs-number">399.87</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">1.83</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">218.4831068635027</span></span> â”‚ â”‚ win32response â”‚ <span class="hljs-number"><span class="hljs-number">407.86</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">7.41</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">55.050315514606815</span></span> â”‚ â”‚ timetaken â”‚ <span class="hljs-number"><span class="hljs-number">1.57</span></span> GiB â”‚ <span class="hljs-number"><span class="hljs-number">402.06</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">3.9947395692010637</span></span> â”‚ â”‚ uriQuery__utm_medium â”‚ <span class="hljs-number"><span class="hljs-number">208.17</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">12.29</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">16.936148912472955</span></span> â”‚ â”‚ uriQuery__utm_source â”‚ <span class="hljs-number"><span class="hljs-number">215.18</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">13.00</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">16.548367623199912</span></span> â”‚ â”‚ uriQuery__utm_campaign â”‚ <span class="hljs-number"><span class="hljs-number">381.46</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">37.94</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">10.055156353418509</span></span> â”‚ â”‚ uriQuery__utm_term â”‚ <span class="hljs-number"><span class="hljs-number">231.82</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">10.78</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">21.502540454070672</span></span> â”‚ â”‚ uriQuery__utm_content â”‚ <span class="hljs-number"><span class="hljs-number">441.34</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">87.60</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">5.038260760449327</span></span> â”‚ â”‚ uriQuery__yclid â”‚ <span class="hljs-number"><span class="hljs-number">216.88</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">16.58</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">13.07721335008116</span></span> â”‚ â”‚ uriQuery__region â”‚ <span class="hljs-number"><span class="hljs-number">204.35</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">9.49</span></span> MiB â”‚ <span class="hljs-number"><span class="hljs-number">21.52661903446796</span></span> â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ <span class="hljs-number"><span class="hljs-number">28</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.005</span></span> sec.</code> </pre> <br></div></div><br><h4>  Description des composants utilisÃ©s <br><br>  FileBeat.  Transfert du journal des fichiers </h4><br>  Ce composant surveille les modifications des fichiers journaux sur le disque et transfÃ¨re les informations Ã  LogStash.  Il est installÃ© sur tous les serveurs sur lesquels les fichiers journaux sont Ã©crits (gÃ©nÃ©ralement IIS).  Il fonctionne en mode queue (c'est-Ã -dire qu'il transfÃ¨re uniquement les enregistrements ajoutÃ©s dans un fichier).  Mais sÃ©parÃ©ment, vous pouvez configurer l'intÃ©gralitÃ© du transfert de fichiers.  Ceci est utile lorsque vous devez tÃ©lÃ©charger des donnÃ©es des mois prÃ©cÃ©dents.  Mettez simplement le fichier journal dans un dossier et il le lira dans son intÃ©gralitÃ©. <br><br>  Lorsque le service s'arrÃªte, les donnÃ©es cessent d'Ãªtre transfÃ©rÃ©es vers le stockage. <br><br>  Un exemple de configuration est le suivant: <br><br><div class="spoiler">  <b class="spoiler_title">filebeat.yml</b> <div class="spoiler_text"><pre> <code class="sql hljs">filebeat.inputs: - type: log enabled: true paths: - C:/inetpub/logs/LogFiles/W3SVC1<span class="hljs-comment"><span class="hljs-comment">/*.log exclude_files: ['.gz$','.zip$'] tail_files: true ignore_older: 24h fields: fld_server_name: "site1.domain.ru" fld_app_name: "site1.domain.ru" fld_app_module: "web" fld_website_name: "web-main" - type: log enabled: true paths: - C:/inetpub/logs/LogFiles/__Import/access_log-* exclude_files: ['.gz$','.zip$'] tail_files: false fields: fld_server_name: "site2.domain.ru" fld_app_name: "site2.domain.ru" fld_app_module: "web" fld_website_name: "web-main" fld_logformat: "logformat__apache" filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false reload.period: 2s output.logstash: hosts: ["log.domain.com:5044"] ssl.enabled: true ssl.certificate_authorities: ["C:/filebeat/certs/ca.pem", "C:/filebeat/certs/ca-issuing.pem"] ssl.certificate: "C:/filebeat/certs/site1.domain.ru.cer" ssl.key: "C:/filebeat/certs/site1.domain.ru.key" #================================ Processors ===================================== processors: - add_host_metadata: ~ - add_cloud_metadata: ~</span></span></code> </pre> <br></div></div><br><h4>  LogStash  Collecteur de journaux </h4><br>  Ce composant est destinÃ© Ã  recevoir des entrÃ©es de journal de FileBeat (ou via la file d'attente RabbitMQ), Ã  analyser et Ã  insÃ©rer des bundles dans la base de donnÃ©es ClickHouse. <br><br>  Pour insÃ©rer dans ClickHouse, le plug-in Logstash-output-clickhouse est utilisÃ©.  Le plugin Logstash a un mÃ©canisme pour rÃ©cupÃ©rer les requÃªtes, mais avec un arrÃªt rÃ©gulier, il est prÃ©fÃ©rable d'arrÃªter le service lui-mÃªme.  Lorsque vous vous arrÃªtez, les messages s'accumulent dans la file d'attente RabbitMQ, donc si vous vous arrÃªtez pendant longtemps, il est prÃ©fÃ©rable d'arrÃªter Filebeats sur les serveurs.  Dans un schÃ©ma oÃ¹ RabbitMQ n'est pas utilisÃ© (sur un rÃ©seau local, Filebeat envoie des journaux directement Ã  Logstash), Filebeats fonctionne de maniÃ¨re assez raisonnable et sÃ»re, donc pour eux l'inaccessibilitÃ© de la sortie est sans consÃ©quence. <br><br>  Un exemple de configuration est le suivant: <br><br><div class="spoiler">  <b class="spoiler_title">log_web__filebeat_clickhouse.conf</b> <div class="spoiler_text"><pre> <code class="sql hljs">input { beats { port =&gt; 5044 type =&gt; 'iis' ssl =&gt; true ssl_certificate_authorities =&gt; ["/etc/logstash/certs/ca.cer", "/etc/logstash/certs/ca-issuing.cer"] ssl_certificate =&gt; "/etc/logstash/certs/server.cer" ssl_key =&gt; "/etc/logstash/certs/server-pkcs8.key" ssl_verify_mode =&gt; "peer" add_field =&gt; { "fld_server_name" =&gt; "%{[fields][fld_server_name]}" "fld_app_name" =&gt; "%{[fields][fld_app_name]}" "fld_app_module" =&gt; "%{[fields][fld_app_module]}" "fld_website_name" =&gt; "%{[fields][fld_website_name]}" "fld_log_file_name" =&gt; "%{source}" "fld_logformat" =&gt; "%{[fields][fld_logformat]}" } } rabbitmq { host =&gt; "queue.domain.com" port =&gt; 5671 user =&gt; "q-reader" password =&gt; "password" queue =&gt; "web_log" heartbeat =&gt; 30 durable =&gt; true ssl =&gt; true <span class="hljs-comment"><span class="hljs-comment">#ssl_certificate_path =&gt; "/etc/logstash/certs/server.p12" #ssl_certificate_password =&gt; "password" add_field =&gt; { "fld_server_name" =&gt; "%{[fields][fld_server_name]}" "fld_app_name" =&gt; "%{[fields][fld_app_name]}" "fld_app_module" =&gt; "%{[fields][fld_app_module]}" "fld_website_name" =&gt; "%{[fields][fld_website_name]}" "fld_log_file_name" =&gt; "%{source}" "fld_logformat" =&gt; "%{[fields][fld_logformat]}" } } } filter { if [message] =~ "^#" { drop {} } if [fld_logformat] == "logformat__iis_with_xrealip" { grok { match =&gt; ["message", "%{TIMESTAMP_ISO8601:log_timestamp} %{IP:serverIP} %{WORD:method} %{NOTSPACE:uriStem} %{NOTSPACE:uriQuery} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clientIP} %{NOTSPACE:userAgent} %{NOTSPACE:referer} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:win32response} %{NUMBER:timetaken} %{NOTSPACE:xrealIP} %{NOTSPACE:xforwarderfor}"] } } else { grok { match =&gt; ["message", "%{TIMESTAMP_ISO8601:log_timestamp} %{IP:serverIP} %{WORD:method} %{NOTSPACE:uriStem} %{NOTSPACE:uriQuery} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clientIP} %{NOTSPACE:userAgent} %{NOTSPACE:referer} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:win32response} %{NUMBER:timetaken}"] } } date { match =&gt; [ "log_timestamp", "YYYY-MM-dd HH:mm:ss" ] timezone =&gt; "Etc/UTC" remove_field =&gt; [ "log_timestamp", "@timestamp" ] target =&gt; [ "log_timestamp2" ] } ruby { code =&gt; "tstamp = event.get('log_timestamp2').to_i event.set('logdatetime', Time.at(tstamp).strftime('%Y-%m-%d %H:%M:%S')) event.set('logdate', Time.at(tstamp).strftime('%Y-%m-%d'))" } if [bytesSent] { ruby { code =&gt; "event['kilobytesSent'] = event['bytesSent'].to_i / 1024.0" } } if [bytesReceived] { ruby { code =&gt; "event['kilobytesReceived'] = event['bytesReceived'].to_i / 1024.0" } } ruby { code =&gt; "event.set('clientRealIP', event.get('clientIP'))" } if [xrealIP] { ruby { code =&gt; "event.set('clientRealIP', event.get('xrealIP'))" } } if [xforwarderfor] { ruby { code =&gt; "event.set('clientRealIP', event.get('xforwarderfor'))" } } mutate { convert =&gt; ["bytesSent", "integer"] convert =&gt; ["bytesReceived", "integer"] convert =&gt; ["timetaken", "integer"] convert =&gt; ["port", "integer"] add_field =&gt; { "clientHostname" =&gt; "%{clientIP}" } } useragent { source=&gt; "useragent" prefix=&gt; "browser" } kv { source =&gt; "uriQuery" prefix =&gt; "uriQuery__" allow_duplicate_values =&gt; false field_split =&gt; "&amp;" include_keys =&gt; [ "utm_medium", "utm_source", "utm_campaign", "utm_term", "utm_content", "yclid", "region" ] } mutate { join =&gt; { "uriQuery__utm_source" =&gt; "," } join =&gt; { "uriQuery__utm_medium" =&gt; "," } join =&gt; { "uriQuery__utm_campaign" =&gt; "," } join =&gt; { "uriQuery__utm_term" =&gt; "," } join =&gt; { "uriQuery__utm_content" =&gt; "," } join =&gt; { "uriQuery__yclid" =&gt; "," } join =&gt; { "uriQuery__region" =&gt; "," } } } output { #stdout {codec =&gt; rubydebug} clickhouse { headers =&gt; ["Authorization", "Basic abcdsfks..."] http_hosts =&gt; ["http://127.0.0.1:8123"] save_dir =&gt; "/etc/logstash/tmp" table =&gt; "log_web" request_tolerance =&gt; 1 flush_size =&gt; 10000 idle_flush_time =&gt; 1 mutations =&gt; { "fld_log_file_name" =&gt; "fld_log_file_name" "fld_server_name" =&gt; "fld_server_name" "fld_app_name" =&gt; "fld_app_name" "fld_app_module" =&gt; "fld_app_module" "fld_website_name" =&gt; "fld_website_name" "logdatetime" =&gt; "logdatetime" "logdate" =&gt; "logdate" "serverIP" =&gt; "serverIP" "method" =&gt; "method" "uriStem" =&gt; "uriStem" "uriQuery" =&gt; "uriQuery" "port" =&gt; "port" "username" =&gt; "username" "clientIP" =&gt; "clientIP" "clientRealIP" =&gt; "clientRealIP" "userAgent" =&gt; "userAgent" "referer" =&gt; "referer" "response" =&gt; "response" "subresponse" =&gt; "subresponse" "win32response" =&gt; "win32response" "timetaken" =&gt; "timetaken" "uriQuery__utm_medium" =&gt; "uriQuery__utm_medium" "uriQuery__utm_source" =&gt; "uriQuery__utm_source" "uriQuery__utm_campaign" =&gt; "uriQuery__utm_campaign" "uriQuery__utm_term" =&gt; "uriQuery__utm_term" "uriQuery__utm_content" =&gt; "uriQuery__utm_content" "uriQuery__yclid" =&gt; "uriQuery__yclid" "uriQuery__region" =&gt; "uriQuery__region" } } }</span></span></code> </pre> <br></div></div><div class="spoiler">  <b class="spoiler_title">pipelines.yml</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment"># This file is where you define your pipelines. You can define multiple. # For more information on multiple pipelines, see the documentation: # https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html - pipeline.id: log_web__filebeat_clickhouse path.config: "/etc/logstash/log_web__filebeat_clickhouse.conf"</span></span></code> </pre> <br></div></div><br><h4>  ClickHouse.  Stockage des journaux </h4><br>  Les journaux de tous les systÃ¨mes sont enregistrÃ©s dans une seule table (voir le dÃ©but de l'article).  Il est destinÃ© Ã  stocker des informations sur les demandes: tous les paramÃ¨tres sont similaires pour diffÃ©rents formats, par exemple, les journaux IIS, les journaux apache et nginx.  Pour les journaux d'application dans lesquels, par exemple, des erreurs, des messages d'information, des avertissements sont enregistrÃ©s, un tableau sÃ©parÃ© sera fourni avec la structure correspondante (maintenant au stade de la conception). <br><br>  Lors de la conception d'une table, il est trÃ¨s important de dÃ©terminer la clÃ© primaire (selon laquelle les donnÃ©es seront triÃ©es pendant le stockage).  Le degrÃ© de compression des donnÃ©es et la vitesse de requÃªte en dÃ©pendent.  Dans notre exemple, la clÃ© est <br>  ORDER BY (fld_app_name, fld_app_module, logdatetime) <br>  C'est-Ã -dire par le nom du systÃ¨me, le nom du composant systÃ¨me et la date de l'Ã©vÃ©nement.  La date d'origine de l'Ã©vÃ©nement Ã©tait en premier lieu.  AprÃ¨s l'avoir dÃ©placÃ© au dernier endroit, les requÃªtes ont commencÃ© Ã  fonctionner environ deux fois plus rapidement.  La modification de la clÃ© primaire nÃ©cessitera de recrÃ©er la table et de recharger les donnÃ©es pour que ClickHouse trie Ã  nouveau les donnÃ©es sur le disque.  Il s'agit d'une opÃ©ration difficile, il est donc conseillÃ© de penser Ã  l'avance ce qui doit Ãªtre inclus dans la clÃ© de tri. <br><br>  Il convient Ã©galement de noter que relativement dans les versions rÃ©centes, le type de donnÃ©es LowCardinality est apparu.  Lors de son utilisation, la taille des donnÃ©es compressÃ©es est fortement rÃ©duite pour les champs qui ont une faible cardinalitÃ© (peu d'options). <br><br>  Maintenant, la version 19.6 est utilisÃ©e et nous prÃ©voyons d'essayer de mettre Ã  jour la version au plus tard.  Ils comprenaient des fonctionnalitÃ©s merveilleuses telles que la granularitÃ© adaptative, les indices de saut et le codec DoubleDelta, par exemple. <br><br>  Par dÃ©faut, lors de l'installation, le niveau du journal de configuration est dÃ©fini sur trace.  Les journaux sont tournÃ©s et archivÃ©s, mais s'Ã©tendent Ã  un gigaoctet.  S'il n'y a pas besoin, vous pouvez dÃ©finir le niveau d'avertissement, puis la taille du journal diminue fortement.  Les paramÃ¨tres de journalisation sont dÃ©finis dans le fichier config.xml: <br><br><pre> <code class="xml hljs"><span class="hljs-comment"><span class="hljs-comment">&lt;!-- Possible levels: https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/Logger. h#L105 --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">level</span></span></span><span class="hljs-tag">&gt;</span></span>warning<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">level</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Quelques commandes utiles</b> <div class="spoiler_text"><pre> <code class="sql hljs">      Debian,     Linux      Altinity.           : https://www.altinity.com/blog/2017/12/18/logstash-<span class="hljs-keyword"><span class="hljs-keyword">with</span></span>-clickhouse sudo yum <span class="hljs-keyword"><span class="hljs-keyword">search</span></span> clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span> sudo yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> clickhouse-server.noarch <span class="hljs-number"><span class="hljs-number">1.</span></span>   sudo systemctl <span class="hljs-keyword"><span class="hljs-keyword">status</span></span> clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">2.</span></span>   sudo systemctl <span class="hljs-keyword"><span class="hljs-keyword">stop</span></span> clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">3.</span></span>   sudo systemctl <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>        (   <span class="hljs-string"><span class="hljs-string">";"</span></span>) clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">client</span></span> <span class="hljs-comment"><span class="hljs-comment">--multiline clickhouse-client --multiline --host 127.0.0.1 --password pa55w0rd clickhouse-client --multiline --host 127.0.0.1 --port 9440 --secure --user default --password pa55w0rd                /tmp/log_web_failed.json            : clickhouse-client --host 127.0.0.1 --password password --query="INSERT INTO log_web FORMAT JSONEachRow" &lt; /tmp/log_web_failed__fixed.json sudo mv /etc/logstash/tmp/log_web_failed.json /etc/logstash/tmp/log_web_failed__fixed.json sudo chown user_dev /etc/logstash/tmp/log_web_failed__fixed.json sudo clickhouse-client --host 127.0.0.1 --password password --query="INSERT INTO log_web FORMAT JSONEachRow" &lt; /etc/logstash/tmp/log_web_failed__fixed.json sudo mv /etc/logstash/tmp/log_web_failed__fixed.json /etc/logstash/tmp/log_web_failed__fixed_.json     quit; ##  TLS https://www.altinity.com/blog/2019/3/5/clickhouse-networking-part-2 openssl s_client -connect log.domain.com:9440 &lt; /dev/null</span></span></code> </pre> <br></div></div><br><h4>  LogStash  Routeur de journaux FileBeat vers la file d'attente RabbitMQ </h4><br>  Ce composant est utilisÃ© pour router les journaux provenant de FileBeat vers la file d'attente RabbitMQ.  Il y a deux points: <br><br><ol><li>  Malheureusement, FileBeat n'a pas de plugin de sortie pour Ã©crire directement sur RabbitMQ.  Et une telle fonctionnalitÃ©, Ã  en juger par l'ish sur leur github, n'est pas prÃ©vue pour la mise en Å“uvre.  Il existe un plugin pour Kafka, mais pour une raison quelconque, nous ne pouvons pas l'utiliser Ã  la maison. </li><li>  Il existe des exigences pour la collecte des journaux dans la DMZ.  Sur cette base, les journaux doivent d'abord Ãªtre ajoutÃ©s Ã  la file d'attente, puis LogStash de l'extÃ©rieur lit les entrÃ©es de la file d'attente. </li></ol><br>  Par consÃ©quent, c'est prÃ©cisÃ©ment pour le cas de l'emplacement du serveur dans la DMZ que vous devez utiliser un schÃ©ma aussi lÃ©gÃ¨rement compliquÃ©.  Un exemple de configuration est le suivant: <br><br><div class="spoiler">  <b class="spoiler_title">iis_w3c_logs__filebeat_rabbitmq.conf</b> <div class="spoiler_text"><pre> <code class="sql hljs">input { beats { port =&gt; 5044 type =&gt; 'iis' ssl =&gt; true ssl_certificate_authorities =&gt; ["/etc/pki/tls/certs/app/ca.pem", "/etc/pki/tls/certs/app/ca-issuing.pem"] ssl_certificate =&gt; "/etc/pki/tls/certs/app/queue.domain.com.cer" ssl_key =&gt; "/etc/pki/tls/certs/app/queue.domain.com-pkcs8.key" ssl_verify_mode =&gt; "peer" } } output { <span class="hljs-comment"><span class="hljs-comment">#stdout {codec =&gt; rubydebug} rabbitmq { host =&gt; "127.0.0.1" port =&gt; 5672 exchange =&gt; "monitor.direct" exchange_type =&gt; "direct" key =&gt; "%{[fields][fld_app_name]}" user =&gt; "q-writer" password =&gt; "password" ssl =&gt; false } }</span></span></code> </pre> <br></div></div><br><h4>  RabbitMQ.  File d'attente des messages </h4><br>  Ce composant est utilisÃ© pour mettre en mÃ©moire tampon les entrÃ©es de journal dans la DMZ.  L'enregistrement se fait via le lien Filebeat â†’ LogStash  La lecture se fait depuis l'extÃ©rieur de la DMZ via LogStash.  Lorsque vous utilisez RabboitMQ, environ 4 000 messages sont traitÃ©s par seconde. <br><br>  Le routage des messages est configurÃ© en fonction du nom du systÃ¨me, c'est-Ã -dire en fonction des donnÃ©es de configuration de FileBeat.  Tous les messages tombent dans une file d'attente.  Si, pour une raison quelconque, le service de file d'attente est arrÃªtÃ©, cela n'entraÃ®nera pas de perte de messages: FileBeats recevra des erreurs de connexion et suspendra l'envoi temporaire.  Et LogStash, qui lit Ã  partir de la file d'attente, recevra Ã©galement des erreurs rÃ©seau et attendra que la connexion reprenne.  Les donnÃ©es dans ce cas, bien sÃ»r, ne seront plus Ã©crites dans la base de donnÃ©es. <br><br>  Les instructions suivantes sont utilisÃ©es pour crÃ©er et configurer des files d'attente: <br><br><pre> <code class="sql hljs">sudo /usr/local/bin/rabbitmqadmin/rabbitmqadmin <span class="hljs-keyword"><span class="hljs-keyword">declare</span></span> <span class="hljs-keyword"><span class="hljs-keyword">exchange</span></span> <span class="hljs-comment"><span class="hljs-comment">--vhost=/ name=monitor.direct type=direct sudo /usr/local/bin/rabbitmqadmin/rabbitmqadmin declare queue --vhost=/ name=web_log durable=true sudo /usr/local/bin/rabbitmqadmin/rabbitmqadmin --vhost="/" declare binding source="monitor.direct" destination_type="queue" destination="web_log" routing_key="site1.domain.ru" sudo /usr/local/bin/rabbitmqadmin/rabbitmqadmin --vhost="/" declare binding source="monitor.direct" destination_type="queue" destination="web_log" routing_key="site2.domain.ru"</span></span></code> </pre> <br><h4>  Grafana  Tableaux de bord </h4><br>  Ce composant est utilisÃ© pour visualiser les donnÃ©es de surveillance.  Dans ce cas, vous devez installer la source de donnÃ©es ClickHouse pour le plug-in Grafana 4.6+.  Nous avons dÃ» le modifier un peu pour augmenter l'efficacitÃ© du traitement des filtres SQL sur un tableau de bord. <br><br>  Par exemple, nous utilisons des variables, et si elles ne sont pas dÃ©finies dans le champ de filtre, nous aimerions qu'il ne gÃ©nÃ¨re pas de condition sous la forme WHERE (uriStem = `` AND uriStem! = '').  Dans ce cas, ClickHouse lira la colonne uriStem.  En gÃ©nÃ©ral, nous avons essayÃ© diffÃ©rentes options et finalement corrigÃ© le plugin (macro $ valueIfEmpty) de sorte qu'en cas de valeur vide, il retournerait 1, sans mentionner la colonne elle-mÃªme. <br><br>  Et maintenant, vous pouvez utiliser cette requÃªte pour le graphique <br><br><pre> <code class="sql hljs">$columns(response, count(*) c) from $table where $adhoc and $valueIfEmpty($fld_app_name, 1, fld_app_name = '$fld_app_name') and $valueIfEmpty($fld_app_module, 1, fld_app_module = '$fld_app_module') and $valueIfEmpty($fld_server_name, 1, fld_server_name = '$fld_server_name') and $valueIfEmpty($uriStem, 1, uriStem like '%$uriStem%') and $valueIfEmpty($clientRealIP, 1, clientRealIP = '$clientRealIP')</code> </pre> <br>  qui est converti en SQL (notez que les champs uriStem vides ont Ã©tÃ© convertis en seulement 1) <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> t, groupArray((response, c)) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> groupArr <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> (intDiv(toUInt32(logdatetime), <span class="hljs-number"><span class="hljs-number">60</span></span>) * <span class="hljs-number"><span class="hljs-number">60</span></span>) * <span class="hljs-number"><span class="hljs-number">1000</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> t, response, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> default.log_web <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (logdate &gt;= toDate(<span class="hljs-number"><span class="hljs-number">1565061982</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (logdatetime &gt;= toDateTime(<span class="hljs-number"><span class="hljs-number">1565061982</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (fld_app_name = <span class="hljs-string"><span class="hljs-string">'site1.domain.ru'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (fld_app_module = <span class="hljs-string"><span class="hljs-string">'web'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> t, response <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span>, response <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span></code> </pre> <br><h4>  Conclusion </h4><br>  L'apparition de la base de donnÃ©es ClickHouse est devenue un Ã©vÃ©nement marquant sur le marchÃ©.  Il Ã©tait difficile d'imaginer que gratuitement en un instant, nous Ã©tions armÃ©s d'un outil puissant et pratique pour travailler avec les mÃ©gadonnÃ©es.  Bien sÃ»r, avec des besoins croissants (par exemple, partitionnement et rÃ©plication sur plusieurs serveurs), le schÃ©ma deviendra plus complexe.  Mais Ã  premiÃ¨re vue, travailler avec cette base de donnÃ©es est trÃ¨s agrÃ©able.  On peut voir que le produit est fait "pour les gens". <br><br>  Par rapport Ã  ElasticSearch, le coÃ»t de stockage et de traitement des journaux, selon les estimations prÃ©liminaires, est rÃ©duit de cinq Ã  dix fois.  En d'autres termes, si pour la quantitÃ© actuelle de donnÃ©es, nous devons configurer un cluster de plusieurs machines, alors lorsque vous utilisez ClickHouse, nous n'avons besoin que d'une seule machine Ã  faible puissance.  Oui, bien sÃ»r, ElasticSearch dispose Ã©galement de mÃ©canismes de compression des donnÃ©es sur disque et d'autres fonctionnalitÃ©s qui peuvent rÃ©duire considÃ©rablement la consommation de ressources, mais par rapport Ã  ClickHouse, cela sera coÃ»teux. <br><br>  Sans aucune optimisation particuliÃ¨re de sa part, sur les paramÃ¨tres par dÃ©faut, le chargement des donnÃ©es et la rÃ©cupÃ©ration des donnÃ©es de la base de donnÃ©es fonctionnent Ã  une vitesse incroyable.  Jusqu'Ã  prÃ©sent, nous avons un peu de donnÃ©es (environ 200 millions d'enregistrements), mais le serveur lui-mÃªme est faible.  Ã€ l'avenir, nous pouvons utiliser cet outil Ã  d'autres fins non liÃ©es au stockage des journaux.  Par exemple, pour l'analyse de bout en bout, dans le domaine de la sÃ©curitÃ©, du machine learning. <br><br>  En fin de compte, un peu sur les avantages et les inconvÃ©nients. <br><br><h4>  InconvÃ©nients </h4><br><ol><li>  TÃ©lÃ©chargement d'enregistrements en gros lots.  Ceci, d'une part, est une fonctionnalitÃ©, mais vous devez toujours utiliser des composants supplÃ©mentaires pour tamponner les enregistrements.  Cette tÃ¢che n'est pas toujours simple, mais toujours rÃ©soluble.  Et je voudrais simplifier le schÃ©ma. </li><li>  Certaines fonctionnalitÃ©s exotiques ou nouvelles fonctionnalitÃ©s font souvent leur apparition dans de nouvelles versions.  Cela soulÃ¨ve des prÃ©occupations, rÃ©duisant le dÃ©sir de passer Ã  une nouvelle version.  Par exemple, le moteur de table Kafka est une fonctionnalitÃ© trÃ¨s utile qui vous permet de lire directement les Ã©vÃ©nements de Kafka, sans implÃ©mentation de consommateurs.  Mais Ã  en juger par le nombre de problÃ¨mes sur le github, nous sommes toujours rÃ©ticents Ã  utiliser ce moteur en production.  Cependant, si vous ne faites pas de mouvements brusques sur le cÃ´tÃ© et utilisez les fonctionnalitÃ©s de base, cela fonctionne de maniÃ¨re stable. </li></ol><br><h4>  Avantages </h4><br><ol><li>  Cela ne ralentit pas. </li><li>  Seuil d'entrÃ©e bas. </li><li>  Open source </li><li>  C'est gratuit. </li><li>  S'adapte bien (partitionnement / rÃ©plication prÃªts Ã  l'emploi) </li><li>  Il est inclus dans le registre des logiciels russes recommandÃ© par le ministÃ¨re des Communications. </li><li>  La prÃ©sence du soutien officiel de Yandex. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr472912/">https://habr.com/ru/post/fr472912/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr472894/index.html">DartUP 2019: confÃ©rence sur Dart et Flutter Ã  Saint-PÃ©tersbourg le 23 novembre</a></li>
<li><a href="../fr472896/index.html">HÃ©licoptÃ¨re Ã  partir d'une imprimante: pour la premiÃ¨re fois, des scientifiques ont Â«imprimÃ©Â» un boÃ®tier de grande taille d'un moteur d'hÃ©licoptÃ¨re</a></li>
<li><a href="../fr472902/index.html">Windows pour IoT: prise en charge matÃ©rielle amÃ©liorÃ©e et nouvelles fonctionnalitÃ©s de pÃ©riphÃ©rique intelligent</a></li>
<li><a href="../fr472904/index.html">Comment Amazon a transformÃ© le stock en jeu</a></li>
<li><a href="../fr472908/index.html">Dagaz: Ã©pisodes (partie 2)</a></li>
<li><a href="../fr472914/index.html">RÃ©fÃ©rentiel de fonctions Wolfram: plate-forme d'accÃ¨s ouvert pour les extensions linguistiques Wolfram</a></li>
<li><a href="../fr472916/index.html">Backend, machine learning et serverless sont les plus intÃ©ressants de la confÃ©rence de juillet Habr</a></li>
<li><a href="../fr472918/index.html">ZX Spectrum en Russie et dans la CEI: comment la poursuite du online s'est transformÃ©e hors ligne</a></li>
<li><a href="../fr472922/index.html">Le programmeur Defender plus fort que l'entropie</a></li>
<li><a href="../fr472926/index.html">La loi de l'accÃ©lÃ©ration des retours (partie 1)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
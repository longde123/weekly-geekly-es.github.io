<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📆 💞 🧚🏿 Base de données ClickHouse pour les humains ou technologie extraterrestre 🧑🏿‍🤝‍🧑🏽 👆 🛁</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Alexey Lizunov, chef du centre de compétence des canaux de service à distance de la Direction des technologies de l'information de l'ICD 



 Comme al...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Base de données ClickHouse pour les humains ou technologie extraterrestre</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mkb/blog/472912/"> <b>Alexey Lizunov, chef du centre de compétence des canaux de service à distance de la Direction des technologies de l'information de l'ICD</b> <br><br><img src="https://habrastorage.org/webt/bs/gu/k0/bsguk03an99lspkpmtkoks2bkvg.png"><br><br>  Comme alternative à la pile ELK (ElasticSearch, Logstash, Kibana), nous menons des recherches sur l'utilisation de la base de données ClickHouse comme entrepôt de données pour les journaux. <br><br>  Dans cet article, nous aimerions parler de notre expérience d'utilisation de la base de données ClickHouse et des résultats préliminaires de l'opération pilote.  Il convient de noter tout de suite que les résultats ont été impressionnants. <br><br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/uy/mc/ip/uymcipeis_jm2piqsaqdjmu9_l8.jpeg"><br><br>  Ensuite, nous décrirons plus en détail la configuration de notre système et les composants qui le composent.  Mais maintenant, je voudrais parler un peu de cette base de données dans son ensemble, et pourquoi vous devriez y prêter attention.  La base de données ClickHouse est une base de données de colonnes analytiques hautes performances de Yandex.  Il est utilisé dans les services Yandex, au départ c'est le principal entrepôt de données pour Yandex.Metrica.  Le système open-source est gratuit.  Du point de vue du développeur, j'ai toujours été intéressé par la façon dont ils l'ont implémenté, car il y a des données incroyablement volumineuses.  Et l'interface utilisateur métrique elle-même est très flexible et rapide.  A la première connaissance de cette base de données, l'impression: «Enfin, enfin!  Conçu "pour les gens"!  À partir du processus d'installation et se terminant par l'envoi de demandes. " <br><br>  Cette base de données a un seuil d'entrée très bas.  Même un développeur qualifié moyen peut installer cette base de données en quelques minutes et commencer à l'utiliser.  Tout fonctionne clairement.  Même les débutants de Linux peuvent rapidement passer à travers l'installation et effectuer des opérations simples.  Auparavant, lorsque le mot Big Data, Hadoop, Google BigTable, HDFS, le développeur habituel avait l'idée qu'ils parlaient de certains téraoctets, pétaoctets, que certains surhumains étaient impliqués dans les paramètres et le développement de ces systèmes, puis avec l'avènement de la base de données ClickHouse, nous avons obtenu Un outil simple et compréhensible avec lequel vous pouvez résoudre la gamme de tâches auparavant inaccessible.  Une seule voiture assez moyenne et cinq minutes à installer.  Autrement dit, nous avons une telle base de données comme, par exemple, MySql, mais uniquement pour stocker des milliards d'enregistrements!  Une sorte de superviseur SQL.  C'est comme si les gens recevaient des armes d'extraterrestres. <br><br><h4>  À propos de notre système de collecte de journaux </h4><br>  Pour collecter des informations, des fichiers journaux IIS d'applications Web d'un format standard sont utilisés (nous sommes également engagés dans l'analyse des journaux d'applications, mais l'objectif principal au stade de l'opération pilote avec nous est de collecter les journaux IIS). <br><br>  Pour diverses raisons, nous n'avons pas complètement abandonné la pile ELK et nous continuons à utiliser les composants LogStash et Filebeat, qui ont fait leurs preuves et fonctionnent de manière assez fiable et prévisible. <br><br>  Le schéma de journalisation général est présenté dans la figure ci-dessous: <br><br><img src="https://habrastorage.org/webt/ah/kr/qg/ahkrqgjij-tfce_455jhjikjfg8.jpeg"><br><br>  L'une des caractéristiques de l'écriture de données dans la base de données ClickHouse est l'insertion peu fréquente (une fois par seconde) d'enregistrements en lots importants.  Apparemment, c'est la partie la plus «problématique» que vous rencontrez lorsque vous rencontrez pour la première fois la base de données ClickHouse: le schéma est un peu compliqué. <br>  Le plugin LogStash a beaucoup aidé ici, qui insère directement des données dans ClickHouse.  Ce composant est déployé sur le même serveur que la base de données elle-même.  Donc, d'une manière générale, il n'est pas recommandé de le faire, mais d'un point de vue pratique, afin de ne pas produire de serveurs séparés pendant qu'il est déployé sur le même serveur.  Nous n'avons pas observé d'échecs ou de conflits de ressources avec la base de données.  De plus, il est à noter que le plugin dispose d'un mécanisme de retray en cas d'erreur.  Et en cas d'erreur, le plugin écrit sur le disque un paquet de données qui n'a pas pu être inséré (le format de fichier est pratique: après l'édition, vous pouvez facilement insérer le paquet corrigé en utilisant clickhouse-client). <br><br>  La liste complète des logiciels utilisés dans le schéma est présentée dans le tableau: <br><br><div class="spoiler">  <b class="spoiler_title">Liste des logiciels utilisés</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  <b>Le titre</b> <br></td><td>  <b>La description</b> <br></td><td>  <b>Lien de distribution</b> <br></td></tr><tr><td><p>  Nginx </p><br></td><td><p>  Proxy inverse pour restreindre l'accès au port et l'autorisation </p><br><br><p>  Non utilisé actuellement dans le circuit. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://nginx.org/en/download.html</a> </p><br></td><td><p>  <a href="">https://nginx.org/download/nginx-1.16.0.tar.gz</a> </p><br></td></tr><tr><td><p>  Filebeat </p><br></td><td><p>  Transférez les journaux de fichiers. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.elastic.co/downloads/beats/filebeat</a> (distribution pour Windows 64 bits). </p><br></td><td><p>  <a href="">https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.3.0-windows-x86_64.zip</a> </p><br></td></tr><tr><td><p>  Logstash </p><br></td><td><p>  Collecteur de journaux. </p><br><br><p>  Utilisé pour collecter les journaux de FileBeat, ainsi que pour collecter les journaux de la file d'attente RabbitMQ (pour les serveurs qui se trouvent dans la DMZ.) </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.elastic.co/products/logstash</a> </p><br></td><td><p>  <a href="">https://artifacts.elastic.co/downloads/logstash/logstash-7.0.1.rpm</a> </p><br></td></tr><tr><td><p>  Logstash - sortie - clickhouse </p><br></td><td><p>  Plugin Loagstash pour transférer des journaux vers la base de données ClickHouse par lots </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://github.com/mikechris/logstash-output-clickhouse</a> </p><br></td><td><p>  / usr / share / logstash / bin / logstash-plugin install logstash-output-clickhouse </p><br><p>  / usr / share / logstash / bin / logstash-plugin install logstash-filter-prune </p><br><p>  / usr / share / logstash / bin / logstash-plugin install logstash-filter-multiline </p><br></td></tr><tr><td><p>  Clickhouse </p><br></td><td><p>  Référentiel de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">journaux https://clickhouse.yandex/docs/ru/</a> </p><br></td><td><p>  <a href="">https://packagecloud.io/Altinity/clickhouse/packages/el/7/clickhouse-server-19.5.3.8-1.el7.x86_64.rpm</a> </p><br><p>  <a href="">https://packagecloud.io/Altinity/clickhouse/packages/el/7/clickhouse-client-19.5.3.8-1.el7.x86_64.rpm</a> </p><br><p>  Remarque  Depuis août 2018, les assemblys rpm «normaux» pour RHEL sont apparus dans le référentiel Yandex, vous pouvez donc essayer de les utiliser.  Au moment de l'installation, nous utilisions des packages compilés par Altinity. </p><br></td></tr><tr><td><p>  Grafana </p><br></td><td><p>  Visualisation du journal.  Configurer les tableaux de bord </p><br><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://grafana.com/</a> </p><br></td><td><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://grafana.com/grafana/download</a> </p><br><br><p>  Redhat &amp; Centos (64 Bit) - Dernière version </p><br></td></tr><tr><td><p>  Source de données ClickHouse pour Grafana 4.6+ </p><br></td><td><p>  Plugin Grafana avec source de données ClickHouse </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://grafana.com/plugins/vertamedia-clickhouse-datasource</a> </p><br></td><td><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://grafana.com/api/plugins/vertamedia-clickhouse-datasource/versions/1.8.1/download</a> </p><br></td></tr><tr><td><p>  Logstash </p><br></td><td><p>  Connectez le routeur de FileBeat à la file d'attente RabbitMQ. </p><br><p>  Remarque  Malheureusement, FileBeat n'a pas de sortie directement dans RabbitMQ, donc un lien intermédiaire sous la forme de Logstash est requis </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.elastic.co/products/logstash</a> </p><br></td><td><p>  <a href="">https://artifacts.elastic.co/downloads/logstash/logstash-7.0.1.rpm</a> </p><br></td></tr><tr><td><p>  Rabbitmq </p><br></td><td><p>  File d'attente des messages  Ceci est un tampon d'entrées de journal dans DMZ </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.rabbitmq.com/download.html</a> </p><br></td><td><p>  <a href="">https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.7.14/rabbitmq-server-3.7.14-1.el7.noarch.rpm</a> </p><br></td></tr><tr><td><p>  Erlang Runtime (requis pour RabbitMQ) </p><br></td><td><p>  Exécution d'Erlang.  Requis pour que RabbitMQ fonctionne </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://www.erlang.org/download.html</a> </p><br></td><td><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://www.rabbitmq.com/install-rpm.html#install-erlang</a> <a href="">http://www.erlang.org/downloads/21.3</a> </p><br></td></tr></tbody></table></div><br></div></div><br>  La configuration du serveur avec la base de données ClickHouse est présentée dans le tableau suivant: <br><div class="scrollable-table"><table><tbody><tr><td>  <b>Le titre</b> <br></td><td>  <b>Valeur</b> <br></td><td>  <b>Remarque</b> <br></td></tr><tr><td><p>  La configuration </p><br></td><td><p>  Disque dur: 40 Go <br>  RAM: 8 Go <br>  Processeur: Core 2 2Ghz </p><br></td><td><p>  Il est nécessaire de prêter attention aux conseils sur le fonctionnement de la base de données ClickHouse ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://clickhouse.yandex/docs/ru/operations/tips/</a> ) </p><br></td></tr><tr><td><p>  Logiciel à l'échelle du système </p><br></td><td><p>  Système d'exploitation: Red Hat Enterprise Linux Server (Maipo) </p><br><p>  JRE (Java 8) </p><br></td><td><p></p><br></td></tr></tbody></table></div><br>  Comme vous pouvez le voir, il s'agit d'un poste de travail normal. <br><br>  La structure du tableau de stockage des journaux est la suivante: <br><br><div class="spoiler">  <b class="spoiler_title">log_web.sql</b> <div class="spoiler_text"><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> log_web ( logdate <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>, logdatetime DateTime CODEC(Delta, LZ4HC), fld_log_file_name LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), fld_server_name LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), fld_app_name LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), fld_app_module LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), fld_website_name LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), serverIP LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), method LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), uriStem <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, uriQuery <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, port UInt32, username LowCardinality( <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ), clientIP <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, clientRealIP <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, userAgent <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, referer <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, response <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, subresponse <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, win32response <span class="hljs-keyword"><span class="hljs-keyword">String</span></span>, timetaken UInt64 , uriQuery__utm_medium <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__utm_source <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__utm_campaign <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__utm_term <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__utm_content <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__yclid <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> , uriQuery__region <span class="hljs-keyword"><span class="hljs-keyword">String</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">Engine</span></span> = MergeTree() <span class="hljs-keyword"><span class="hljs-keyword">PARTITION</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> toYYYYMM(logdate) <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> (fld_app_name, fld_app_module, logdatetime) <span class="hljs-keyword"><span class="hljs-keyword">SETTINGS</span></span> index_granularity = <span class="hljs-number"><span class="hljs-number">8192</span></span>;</code> </pre> <br></div></div><br>  Nous utilisons des valeurs par défaut pour le partitionnement (par mois) et la granularité de l'index.  Tous les champs correspondent pratiquement aux entrées du journal IIS pour l'enregistrement des requêtes http.  Séparément, des champs séparés pour stocker les balises utm (ils sont analysés au stade de l'insertion dans la table à partir du champ de chaîne de requête). <br><br>  Dans le tableau, plusieurs champs système sont également ajoutés pour stocker des informations sur les systèmes, les composants et les serveurs.  Voir le tableau ci-dessous pour une description de ces champs.  Dans une même table, nous stockons les journaux de plusieurs systèmes. <br><br><div class="scrollable-table"><table><tbody><tr><td>  <b>Le titre</b> <br></td><td>  <b>La description</b> <br></td><td>  <b>Exemple</b> <br></td></tr><tr><td><p>  fld_app_name </p><br></td><td><p>  Nom de l'application / du système <br>  Valeurs valides: </p><br><ul><li>  site1.domain.com Site externe 1 </li><li>  site2.domain.com Site externe 2 </li><li>  internal-site1.domain.local Site interne 1 </li></ul><br></td><td>  site1.domain.com <br></td></tr><tr><td><p>  fld_app_module </p><br></td><td><p>  Module système <br>  Valeurs valides: </p><br><ul><li>  web - Site Web </li><li>  svc - Service de site Web </li><li>  intgr - Service d'intégration Web </li><li>  bo - Administrateur (BackOffice) </li></ul><br></td><td><p>  web </p><br></td></tr><tr><td><p>  fld_website_name </p><br></td><td><p>  Nom du site Web dans IIS </p><br><p>  Plusieurs systèmes peuvent être déployés sur un serveur, voire plusieurs instances d'un même module système </p><br></td><td><p>  web-main </p><br></td></tr><tr><td><p>  fld_server_name </p><br></td><td><p>  Nom du serveur </p><br></td><td><p>  web1.domain.com </p><br></td></tr><tr><td><p>  fld_log_file_name </p><br></td><td><p>  Chemin d'accès au fichier journal sur le serveur </p><br></td><td>  C: \ inetpub \ logs \ LogFiles <br>  \ W3SVC1 \ u_ex190711.log <br></td></tr></tbody></table></div><br>  Cela vous permet de créer efficacement des graphiques dans Grafana.  Par exemple, affichez les demandes du frontend d'un système spécifique.  Ceci est similaire au compteur de site dans Yandex.Metrica. <br><br>  Voici quelques statistiques sur l'utilisation de la base de données pendant deux mois. <br><br><div class="spoiler">  <b class="spoiler_title">Nombre d'enregistrements par système et composant</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> fld_app_name, fld_app_module, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(fld_app_name) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> rows_count <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> log_web <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> fld_app_name, fld_app_module <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> TOTALS <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> fld_app_name <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span>, rows_count <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> ┌─fld_app_name─────┬─fld_app_module─┬─rows_count─┐ │ site1.domain.ru │ web │ <span class="hljs-number"><span class="hljs-number">131441</span></span> │ │ site2.domain.ru │ web │ <span class="hljs-number"><span class="hljs-number">1751081</span></span> │ │ site3.domain.ru │ web │ <span class="hljs-number"><span class="hljs-number">106887543</span></span> │ │ site3.domain.ru │ svc │ <span class="hljs-number"><span class="hljs-number">44908603</span></span> │ │ site3.domain.ru │ intgr │ <span class="hljs-number"><span class="hljs-number">9813911</span></span> │ │ site4.domain.ru │ web │ <span class="hljs-number"><span class="hljs-number">772095</span></span> │ │ site5.domain.ru │ web │ <span class="hljs-number"><span class="hljs-number">17037221</span></span> │ │ site5.domain.ru │ intgr │ <span class="hljs-number"><span class="hljs-number">838559</span></span> │ │ site5.domain.ru │ bo │ <span class="hljs-number"><span class="hljs-number">7404</span></span> │ │ site6.domain.ru │ web │ <span class="hljs-number"><span class="hljs-number">595877</span></span> │ │ site7.domain.ru │ web │ <span class="hljs-number"><span class="hljs-number">27778858</span></span> │ └──────────────────┴────────────────┴────────────┘ Totals: ┌─fld_app_name─┬─fld_app_module─┬─rows_count─┐ │ │ │ <span class="hljs-number"><span class="hljs-number">210522593</span></span> │ └──────────────┴────────────────┴────────────┘ <span class="hljs-number"><span class="hljs-number">11</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">4.874</span></span> sec. Processed <span class="hljs-number"><span class="hljs-number">210.52</span></span> million <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>, <span class="hljs-number"><span class="hljs-number">421.67</span></span> MB (<span class="hljs-number"><span class="hljs-number">43.19</span></span> million <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>/s., <span class="hljs-number"><span class="hljs-number">86.51</span></span> MB/s.)</code> </pre> <br></div></div><div class="spoiler">  <b class="spoiler_title">La quantité de données sur le disque</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> formatReadableSize(<span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(data_uncompressed_bytes)) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uncompressed, formatReadableSize(<span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(data_compressed_bytes)) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> compressed, <span class="hljs-keyword"><span class="hljs-keyword">sum</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">rows</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> total_rows <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> system.parts <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">table</span></span> = <span class="hljs-string"><span class="hljs-string">'log_web'</span></span> ┌─uncompressed─┬─compressed─┬─total_rows─┐ │ <span class="hljs-number"><span class="hljs-number">54.50</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">4.86</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">211427094</span></span> │ └──────────────┴────────────┴────────────┘ <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.035</span></span> sec.</code> </pre> <br></div></div><div class="spoiler">  <b class="spoiler_title">Le degré de compression des données dans les colonnes</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">name</span></span>, formatReadableSize(data_uncompressed_bytes) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> uncompressed, formatReadableSize(data_compressed_bytes) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> compressed, data_uncompressed_bytes / data_compressed_bytes <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> compress_ratio <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> system.columns <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">table</span></span> = <span class="hljs-string"><span class="hljs-string">'log_web'</span></span> ┌─<span class="hljs-keyword"><span class="hljs-keyword">name</span></span>───────────────────┬─uncompressed─┬─compressed─┬─────compress_ratio─┐ │ logdate │ <span class="hljs-number"><span class="hljs-number">401.53</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">1.80</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">223.16665968777315</span></span> │ │ logdatetime │ <span class="hljs-number"><span class="hljs-number">803.06</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">35.91</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">22.363966401202305</span></span> │ │ fld_log_file_name │ <span class="hljs-number"><span class="hljs-number">220.66</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">2.60</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">84.99905736932571</span></span> │ │ fld_server_name │ <span class="hljs-number"><span class="hljs-number">201.54</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">50.63</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">3.980924816977078</span></span> │ │ fld_app_name │ <span class="hljs-number"><span class="hljs-number">201.17</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">969.17</span></span> KiB │ <span class="hljs-number"><span class="hljs-number">212.55518183686877</span></span> │ │ fld_app_module │ <span class="hljs-number"><span class="hljs-number">201.17</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">968.60</span></span> KiB │ <span class="hljs-number"><span class="hljs-number">212.67805817411906</span></span> │ │ fld_website_name │ <span class="hljs-number"><span class="hljs-number">201.54</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">1.24</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">162.7204926761546</span></span> │ │ serverIP │ <span class="hljs-number"><span class="hljs-number">201.54</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">50.25</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">4.010824061219731</span></span> │ │ method │ <span class="hljs-number"><span class="hljs-number">201.53</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">43.64</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">4.617721053304486</span></span> │ │ uriStem │ <span class="hljs-number"><span class="hljs-number">5.13</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">832.51</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">6.311522291936919</span></span> │ │ uriQuery │ <span class="hljs-number"><span class="hljs-number">2.58</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">501.06</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">5.269731450124478</span></span> │ │ port │ <span class="hljs-number"><span class="hljs-number">803.06</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">3.98</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">201.91673864241824</span></span> │ │ username │ <span class="hljs-number"><span class="hljs-number">318.08</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">26.93</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">11.812513794583598</span></span> │ │ clientIP │ <span class="hljs-number"><span class="hljs-number">2.35</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">82.59</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">29.132328640073343</span></span> │ │ clientRealIP │ <span class="hljs-number"><span class="hljs-number">2.49</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">465.05</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">5.478382297052563</span></span> │ │ userAgent │ <span class="hljs-number"><span class="hljs-number">18.34</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">764.08</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">24.57905114484208</span></span> │ │ referer │ <span class="hljs-number"><span class="hljs-number">14.71</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">1.37</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">10.736792723669906</span></span> │ │ response │ <span class="hljs-number"><span class="hljs-number">803.06</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">83.81</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">9.582334090987247</span></span> │ │ subresponse │ <span class="hljs-number"><span class="hljs-number">399.87</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">1.83</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">218.4831068635027</span></span> │ │ win32response │ <span class="hljs-number"><span class="hljs-number">407.86</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">7.41</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">55.050315514606815</span></span> │ │ timetaken │ <span class="hljs-number"><span class="hljs-number">1.57</span></span> GiB │ <span class="hljs-number"><span class="hljs-number">402.06</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">3.9947395692010637</span></span> │ │ uriQuery__utm_medium │ <span class="hljs-number"><span class="hljs-number">208.17</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">12.29</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">16.936148912472955</span></span> │ │ uriQuery__utm_source │ <span class="hljs-number"><span class="hljs-number">215.18</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">13.00</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">16.548367623199912</span></span> │ │ uriQuery__utm_campaign │ <span class="hljs-number"><span class="hljs-number">381.46</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">37.94</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">10.055156353418509</span></span> │ │ uriQuery__utm_term │ <span class="hljs-number"><span class="hljs-number">231.82</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">10.78</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">21.502540454070672</span></span> │ │ uriQuery__utm_content │ <span class="hljs-number"><span class="hljs-number">441.34</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">87.60</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">5.038260760449327</span></span> │ │ uriQuery__yclid │ <span class="hljs-number"><span class="hljs-number">216.88</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">16.58</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">13.07721335008116</span></span> │ │ uriQuery__region │ <span class="hljs-number"><span class="hljs-number">204.35</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">9.49</span></span> MiB │ <span class="hljs-number"><span class="hljs-number">21.52661903446796</span></span> │ └────────────────────────┴──────────────┴────────────┴────────────────────┘ <span class="hljs-number"><span class="hljs-number">28</span></span> <span class="hljs-keyword"><span class="hljs-keyword">rows</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> set. Elapsed: <span class="hljs-number"><span class="hljs-number">0.005</span></span> sec.</code> </pre> <br></div></div><br><h4>  Description des composants utilisés <br><br>  FileBeat.  Transfert du journal des fichiers </h4><br>  Ce composant surveille les modifications des fichiers journaux sur le disque et transfère les informations à LogStash.  Il est installé sur tous les serveurs sur lesquels les fichiers journaux sont écrits (généralement IIS).  Il fonctionne en mode queue (c'est-à-dire qu'il transfère uniquement les enregistrements ajoutés dans un fichier).  Mais séparément, vous pouvez configurer l'intégralité du transfert de fichiers.  Ceci est utile lorsque vous devez télécharger des données des mois précédents.  Mettez simplement le fichier journal dans un dossier et il le lira dans son intégralité. <br><br>  Lorsque le service s'arrête, les données cessent d'être transférées vers le stockage. <br><br>  Un exemple de configuration est le suivant: <br><br><div class="spoiler">  <b class="spoiler_title">filebeat.yml</b> <div class="spoiler_text"><pre> <code class="sql hljs">filebeat.inputs: - type: log enabled: true paths: - C:/inetpub/logs/LogFiles/W3SVC1<span class="hljs-comment"><span class="hljs-comment">/*.log exclude_files: ['.gz$','.zip$'] tail_files: true ignore_older: 24h fields: fld_server_name: "site1.domain.ru" fld_app_name: "site1.domain.ru" fld_app_module: "web" fld_website_name: "web-main" - type: log enabled: true paths: - C:/inetpub/logs/LogFiles/__Import/access_log-* exclude_files: ['.gz$','.zip$'] tail_files: false fields: fld_server_name: "site2.domain.ru" fld_app_name: "site2.domain.ru" fld_app_module: "web" fld_website_name: "web-main" fld_logformat: "logformat__apache" filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false reload.period: 2s output.logstash: hosts: ["log.domain.com:5044"] ssl.enabled: true ssl.certificate_authorities: ["C:/filebeat/certs/ca.pem", "C:/filebeat/certs/ca-issuing.pem"] ssl.certificate: "C:/filebeat/certs/site1.domain.ru.cer" ssl.key: "C:/filebeat/certs/site1.domain.ru.key" #================================ Processors ===================================== processors: - add_host_metadata: ~ - add_cloud_metadata: ~</span></span></code> </pre> <br></div></div><br><h4>  LogStash  Collecteur de journaux </h4><br>  Ce composant est destiné à recevoir des entrées de journal de FileBeat (ou via la file d'attente RabbitMQ), à analyser et à insérer des bundles dans la base de données ClickHouse. <br><br>  Pour insérer dans ClickHouse, le plug-in Logstash-output-clickhouse est utilisé.  Le plugin Logstash a un mécanisme pour récupérer les requêtes, mais avec un arrêt régulier, il est préférable d'arrêter le service lui-même.  Lorsque vous vous arrêtez, les messages s'accumulent dans la file d'attente RabbitMQ, donc si vous vous arrêtez pendant longtemps, il est préférable d'arrêter Filebeats sur les serveurs.  Dans un schéma où RabbitMQ n'est pas utilisé (sur un réseau local, Filebeat envoie des journaux directement à Logstash), Filebeats fonctionne de manière assez raisonnable et sûre, donc pour eux l'inaccessibilité de la sortie est sans conséquence. <br><br>  Un exemple de configuration est le suivant: <br><br><div class="spoiler">  <b class="spoiler_title">log_web__filebeat_clickhouse.conf</b> <div class="spoiler_text"><pre> <code class="sql hljs">input { beats { port =&gt; 5044 type =&gt; 'iis' ssl =&gt; true ssl_certificate_authorities =&gt; ["/etc/logstash/certs/ca.cer", "/etc/logstash/certs/ca-issuing.cer"] ssl_certificate =&gt; "/etc/logstash/certs/server.cer" ssl_key =&gt; "/etc/logstash/certs/server-pkcs8.key" ssl_verify_mode =&gt; "peer" add_field =&gt; { "fld_server_name" =&gt; "%{[fields][fld_server_name]}" "fld_app_name" =&gt; "%{[fields][fld_app_name]}" "fld_app_module" =&gt; "%{[fields][fld_app_module]}" "fld_website_name" =&gt; "%{[fields][fld_website_name]}" "fld_log_file_name" =&gt; "%{source}" "fld_logformat" =&gt; "%{[fields][fld_logformat]}" } } rabbitmq { host =&gt; "queue.domain.com" port =&gt; 5671 user =&gt; "q-reader" password =&gt; "password" queue =&gt; "web_log" heartbeat =&gt; 30 durable =&gt; true ssl =&gt; true <span class="hljs-comment"><span class="hljs-comment">#ssl_certificate_path =&gt; "/etc/logstash/certs/server.p12" #ssl_certificate_password =&gt; "password" add_field =&gt; { "fld_server_name" =&gt; "%{[fields][fld_server_name]}" "fld_app_name" =&gt; "%{[fields][fld_app_name]}" "fld_app_module" =&gt; "%{[fields][fld_app_module]}" "fld_website_name" =&gt; "%{[fields][fld_website_name]}" "fld_log_file_name" =&gt; "%{source}" "fld_logformat" =&gt; "%{[fields][fld_logformat]}" } } } filter { if [message] =~ "^#" { drop {} } if [fld_logformat] == "logformat__iis_with_xrealip" { grok { match =&gt; ["message", "%{TIMESTAMP_ISO8601:log_timestamp} %{IP:serverIP} %{WORD:method} %{NOTSPACE:uriStem} %{NOTSPACE:uriQuery} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clientIP} %{NOTSPACE:userAgent} %{NOTSPACE:referer} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:win32response} %{NUMBER:timetaken} %{NOTSPACE:xrealIP} %{NOTSPACE:xforwarderfor}"] } } else { grok { match =&gt; ["message", "%{TIMESTAMP_ISO8601:log_timestamp} %{IP:serverIP} %{WORD:method} %{NOTSPACE:uriStem} %{NOTSPACE:uriQuery} %{NUMBER:port} %{NOTSPACE:username} %{IPORHOST:clientIP} %{NOTSPACE:userAgent} %{NOTSPACE:referer} %{NUMBER:response} %{NUMBER:subresponse} %{NUMBER:win32response} %{NUMBER:timetaken}"] } } date { match =&gt; [ "log_timestamp", "YYYY-MM-dd HH:mm:ss" ] timezone =&gt; "Etc/UTC" remove_field =&gt; [ "log_timestamp", "@timestamp" ] target =&gt; [ "log_timestamp2" ] } ruby { code =&gt; "tstamp = event.get('log_timestamp2').to_i event.set('logdatetime', Time.at(tstamp).strftime('%Y-%m-%d %H:%M:%S')) event.set('logdate', Time.at(tstamp).strftime('%Y-%m-%d'))" } if [bytesSent] { ruby { code =&gt; "event['kilobytesSent'] = event['bytesSent'].to_i / 1024.0" } } if [bytesReceived] { ruby { code =&gt; "event['kilobytesReceived'] = event['bytesReceived'].to_i / 1024.0" } } ruby { code =&gt; "event.set('clientRealIP', event.get('clientIP'))" } if [xrealIP] { ruby { code =&gt; "event.set('clientRealIP', event.get('xrealIP'))" } } if [xforwarderfor] { ruby { code =&gt; "event.set('clientRealIP', event.get('xforwarderfor'))" } } mutate { convert =&gt; ["bytesSent", "integer"] convert =&gt; ["bytesReceived", "integer"] convert =&gt; ["timetaken", "integer"] convert =&gt; ["port", "integer"] add_field =&gt; { "clientHostname" =&gt; "%{clientIP}" } } useragent { source=&gt; "useragent" prefix=&gt; "browser" } kv { source =&gt; "uriQuery" prefix =&gt; "uriQuery__" allow_duplicate_values =&gt; false field_split =&gt; "&amp;" include_keys =&gt; [ "utm_medium", "utm_source", "utm_campaign", "utm_term", "utm_content", "yclid", "region" ] } mutate { join =&gt; { "uriQuery__utm_source" =&gt; "," } join =&gt; { "uriQuery__utm_medium" =&gt; "," } join =&gt; { "uriQuery__utm_campaign" =&gt; "," } join =&gt; { "uriQuery__utm_term" =&gt; "," } join =&gt; { "uriQuery__utm_content" =&gt; "," } join =&gt; { "uriQuery__yclid" =&gt; "," } join =&gt; { "uriQuery__region" =&gt; "," } } } output { #stdout {codec =&gt; rubydebug} clickhouse { headers =&gt; ["Authorization", "Basic abcdsfks..."] http_hosts =&gt; ["http://127.0.0.1:8123"] save_dir =&gt; "/etc/logstash/tmp" table =&gt; "log_web" request_tolerance =&gt; 1 flush_size =&gt; 10000 idle_flush_time =&gt; 1 mutations =&gt; { "fld_log_file_name" =&gt; "fld_log_file_name" "fld_server_name" =&gt; "fld_server_name" "fld_app_name" =&gt; "fld_app_name" "fld_app_module" =&gt; "fld_app_module" "fld_website_name" =&gt; "fld_website_name" "logdatetime" =&gt; "logdatetime" "logdate" =&gt; "logdate" "serverIP" =&gt; "serverIP" "method" =&gt; "method" "uriStem" =&gt; "uriStem" "uriQuery" =&gt; "uriQuery" "port" =&gt; "port" "username" =&gt; "username" "clientIP" =&gt; "clientIP" "clientRealIP" =&gt; "clientRealIP" "userAgent" =&gt; "userAgent" "referer" =&gt; "referer" "response" =&gt; "response" "subresponse" =&gt; "subresponse" "win32response" =&gt; "win32response" "timetaken" =&gt; "timetaken" "uriQuery__utm_medium" =&gt; "uriQuery__utm_medium" "uriQuery__utm_source" =&gt; "uriQuery__utm_source" "uriQuery__utm_campaign" =&gt; "uriQuery__utm_campaign" "uriQuery__utm_term" =&gt; "uriQuery__utm_term" "uriQuery__utm_content" =&gt; "uriQuery__utm_content" "uriQuery__yclid" =&gt; "uriQuery__yclid" "uriQuery__region" =&gt; "uriQuery__region" } } }</span></span></code> </pre> <br></div></div><div class="spoiler">  <b class="spoiler_title">pipelines.yml</b> <div class="spoiler_text"><pre> <code class="sql hljs"><span class="hljs-comment"><span class="hljs-comment"># This file is where you define your pipelines. You can define multiple. # For more information on multiple pipelines, see the documentation: # https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html - pipeline.id: log_web__filebeat_clickhouse path.config: "/etc/logstash/log_web__filebeat_clickhouse.conf"</span></span></code> </pre> <br></div></div><br><h4>  ClickHouse.  Stockage des journaux </h4><br>  Les journaux de tous les systèmes sont enregistrés dans une seule table (voir le début de l'article).  Il est destiné à stocker des informations sur les demandes: tous les paramètres sont similaires pour différents formats, par exemple, les journaux IIS, les journaux apache et nginx.  Pour les journaux d'application dans lesquels, par exemple, des erreurs, des messages d'information, des avertissements sont enregistrés, un tableau séparé sera fourni avec la structure correspondante (maintenant au stade de la conception). <br><br>  Lors de la conception d'une table, il est très important de déterminer la clé primaire (selon laquelle les données seront triées pendant le stockage).  Le degré de compression des données et la vitesse de requête en dépendent.  Dans notre exemple, la clé est <br>  ORDER BY (fld_app_name, fld_app_module, logdatetime) <br>  C'est-à-dire par le nom du système, le nom du composant système et la date de l'événement.  La date d'origine de l'événement était en premier lieu.  Après l'avoir déplacé au dernier endroit, les requêtes ont commencé à fonctionner environ deux fois plus rapidement.  La modification de la clé primaire nécessitera de recréer la table et de recharger les données pour que ClickHouse trie à nouveau les données sur le disque.  Il s'agit d'une opération difficile, il est donc conseillé de penser à l'avance ce qui doit être inclus dans la clé de tri. <br><br>  Il convient également de noter que relativement dans les versions récentes, le type de données LowCardinality est apparu.  Lors de son utilisation, la taille des données compressées est fortement réduite pour les champs qui ont une faible cardinalité (peu d'options). <br><br>  Maintenant, la version 19.6 est utilisée et nous prévoyons d'essayer de mettre à jour la version au plus tard.  Ils comprenaient des fonctionnalités merveilleuses telles que la granularité adaptative, les indices de saut et le codec DoubleDelta, par exemple. <br><br>  Par défaut, lors de l'installation, le niveau du journal de configuration est défini sur trace.  Les journaux sont tournés et archivés, mais s'étendent à un gigaoctet.  S'il n'y a pas besoin, vous pouvez définir le niveau d'avertissement, puis la taille du journal diminue fortement.  Les paramètres de journalisation sont définis dans le fichier config.xml: <br><br><pre> <code class="xml hljs"><span class="hljs-comment"><span class="hljs-comment">&lt;!-- Possible levels: https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/Logger. h#L105 --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">level</span></span></span><span class="hljs-tag">&gt;</span></span>warning<span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">level</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Quelques commandes utiles</b> <div class="spoiler_text"><pre> <code class="sql hljs">      Debian,     Linux      Altinity.           : https://www.altinity.com/blog/2017/12/18/logstash-<span class="hljs-keyword"><span class="hljs-keyword">with</span></span>-clickhouse sudo yum <span class="hljs-keyword"><span class="hljs-keyword">search</span></span> clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span> sudo yum <span class="hljs-keyword"><span class="hljs-keyword">install</span></span> clickhouse-server.noarch <span class="hljs-number"><span class="hljs-number">1.</span></span>   sudo systemctl <span class="hljs-keyword"><span class="hljs-keyword">status</span></span> clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">2.</span></span>   sudo systemctl <span class="hljs-keyword"><span class="hljs-keyword">stop</span></span> clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span> <span class="hljs-number"><span class="hljs-number">3.</span></span>   sudo systemctl <span class="hljs-keyword"><span class="hljs-keyword">start</span></span> clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>        (   <span class="hljs-string"><span class="hljs-string">";"</span></span>) clickhouse-<span class="hljs-keyword"><span class="hljs-keyword">client</span></span> <span class="hljs-comment"><span class="hljs-comment">--multiline clickhouse-client --multiline --host 127.0.0.1 --password pa55w0rd clickhouse-client --multiline --host 127.0.0.1 --port 9440 --secure --user default --password pa55w0rd                /tmp/log_web_failed.json            : clickhouse-client --host 127.0.0.1 --password password --query="INSERT INTO log_web FORMAT JSONEachRow" &lt; /tmp/log_web_failed__fixed.json sudo mv /etc/logstash/tmp/log_web_failed.json /etc/logstash/tmp/log_web_failed__fixed.json sudo chown user_dev /etc/logstash/tmp/log_web_failed__fixed.json sudo clickhouse-client --host 127.0.0.1 --password password --query="INSERT INTO log_web FORMAT JSONEachRow" &lt; /etc/logstash/tmp/log_web_failed__fixed.json sudo mv /etc/logstash/tmp/log_web_failed__fixed.json /etc/logstash/tmp/log_web_failed__fixed_.json     quit; ##  TLS https://www.altinity.com/blog/2019/3/5/clickhouse-networking-part-2 openssl s_client -connect log.domain.com:9440 &lt; /dev/null</span></span></code> </pre> <br></div></div><br><h4>  LogStash  Routeur de journaux FileBeat vers la file d'attente RabbitMQ </h4><br>  Ce composant est utilisé pour router les journaux provenant de FileBeat vers la file d'attente RabbitMQ.  Il y a deux points: <br><br><ol><li>  Malheureusement, FileBeat n'a pas de plugin de sortie pour écrire directement sur RabbitMQ.  Et une telle fonctionnalité, à en juger par l'ish sur leur github, n'est pas prévue pour la mise en œuvre.  Il existe un plugin pour Kafka, mais pour une raison quelconque, nous ne pouvons pas l'utiliser à la maison. </li><li>  Il existe des exigences pour la collecte des journaux dans la DMZ.  Sur cette base, les journaux doivent d'abord être ajoutés à la file d'attente, puis LogStash de l'extérieur lit les entrées de la file d'attente. </li></ol><br>  Par conséquent, c'est précisément pour le cas de l'emplacement du serveur dans la DMZ que vous devez utiliser un schéma aussi légèrement compliqué.  Un exemple de configuration est le suivant: <br><br><div class="spoiler">  <b class="spoiler_title">iis_w3c_logs__filebeat_rabbitmq.conf</b> <div class="spoiler_text"><pre> <code class="sql hljs">input { beats { port =&gt; 5044 type =&gt; 'iis' ssl =&gt; true ssl_certificate_authorities =&gt; ["/etc/pki/tls/certs/app/ca.pem", "/etc/pki/tls/certs/app/ca-issuing.pem"] ssl_certificate =&gt; "/etc/pki/tls/certs/app/queue.domain.com.cer" ssl_key =&gt; "/etc/pki/tls/certs/app/queue.domain.com-pkcs8.key" ssl_verify_mode =&gt; "peer" } } output { <span class="hljs-comment"><span class="hljs-comment">#stdout {codec =&gt; rubydebug} rabbitmq { host =&gt; "127.0.0.1" port =&gt; 5672 exchange =&gt; "monitor.direct" exchange_type =&gt; "direct" key =&gt; "%{[fields][fld_app_name]}" user =&gt; "q-writer" password =&gt; "password" ssl =&gt; false } }</span></span></code> </pre> <br></div></div><br><h4>  RabbitMQ.  File d'attente des messages </h4><br>  Ce composant est utilisé pour mettre en mémoire tampon les entrées de journal dans la DMZ.  L'enregistrement se fait via le lien Filebeat → LogStash  La lecture se fait depuis l'extérieur de la DMZ via LogStash.  Lorsque vous utilisez RabboitMQ, environ 4 000 messages sont traités par seconde. <br><br>  Le routage des messages est configuré en fonction du nom du système, c'est-à-dire en fonction des données de configuration de FileBeat.  Tous les messages tombent dans une file d'attente.  Si, pour une raison quelconque, le service de file d'attente est arrêté, cela n'entraînera pas de perte de messages: FileBeats recevra des erreurs de connexion et suspendra l'envoi temporaire.  Et LogStash, qui lit à partir de la file d'attente, recevra également des erreurs réseau et attendra que la connexion reprenne.  Les données dans ce cas, bien sûr, ne seront plus écrites dans la base de données. <br><br>  Les instructions suivantes sont utilisées pour créer et configurer des files d'attente: <br><br><pre> <code class="sql hljs">sudo /usr/local/bin/rabbitmqadmin/rabbitmqadmin <span class="hljs-keyword"><span class="hljs-keyword">declare</span></span> <span class="hljs-keyword"><span class="hljs-keyword">exchange</span></span> <span class="hljs-comment"><span class="hljs-comment">--vhost=/ name=monitor.direct type=direct sudo /usr/local/bin/rabbitmqadmin/rabbitmqadmin declare queue --vhost=/ name=web_log durable=true sudo /usr/local/bin/rabbitmqadmin/rabbitmqadmin --vhost="/" declare binding source="monitor.direct" destination_type="queue" destination="web_log" routing_key="site1.domain.ru" sudo /usr/local/bin/rabbitmqadmin/rabbitmqadmin --vhost="/" declare binding source="monitor.direct" destination_type="queue" destination="web_log" routing_key="site2.domain.ru"</span></span></code> </pre> <br><h4>  Grafana  Tableaux de bord </h4><br>  Ce composant est utilisé pour visualiser les données de surveillance.  Dans ce cas, vous devez installer la source de données ClickHouse pour le plug-in Grafana 4.6+.  Nous avons dû le modifier un peu pour augmenter l'efficacité du traitement des filtres SQL sur un tableau de bord. <br><br>  Par exemple, nous utilisons des variables, et si elles ne sont pas définies dans le champ de filtre, nous aimerions qu'il ne génère pas de condition sous la forme WHERE (uriStem = `` AND uriStem! = '').  Dans ce cas, ClickHouse lira la colonne uriStem.  En général, nous avons essayé différentes options et finalement corrigé le plugin (macro $ valueIfEmpty) de sorte qu'en cas de valeur vide, il retournerait 1, sans mentionner la colonne elle-même. <br><br>  Et maintenant, vous pouvez utiliser cette requête pour le graphique <br><br><pre> <code class="sql hljs">$columns(response, count(*) c) from $table where $adhoc and $valueIfEmpty($fld_app_name, 1, fld_app_name = '$fld_app_name') and $valueIfEmpty($fld_app_module, 1, fld_app_module = '$fld_app_module') and $valueIfEmpty($fld_server_name, 1, fld_server_name = '$fld_server_name') and $valueIfEmpty($uriStem, 1, uriStem like '%$uriStem%') and $valueIfEmpty($clientRealIP, 1, clientRealIP = '$clientRealIP')</code> </pre> <br>  qui est converti en SQL (notez que les champs uriStem vides ont été convertis en seulement 1) <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> t, groupArray((response, c)) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> groupArr <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ( <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> (intDiv(toUInt32(logdatetime), <span class="hljs-number"><span class="hljs-number">60</span></span>) * <span class="hljs-number"><span class="hljs-number">60</span></span>) * <span class="hljs-number"><span class="hljs-number">1000</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> t, response, <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> c <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> default.log_web <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (logdate &gt;= toDate(<span class="hljs-number"><span class="hljs-number">1565061982</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (logdatetime &gt;= toDateTime(<span class="hljs-number"><span class="hljs-number">1565061982</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (fld_app_name = <span class="hljs-string"><span class="hljs-string">'site1.domain.ru'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> (fld_app_module = <span class="hljs-string"><span class="hljs-string">'web'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">AND</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> t, response <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span>, response <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span> ) <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">ASC</span></span></code> </pre> <br><h4>  Conclusion </h4><br>  L'apparition de la base de données ClickHouse est devenue un événement marquant sur le marché.  Il était difficile d'imaginer que gratuitement en un instant, nous étions armés d'un outil puissant et pratique pour travailler avec les mégadonnées.  Bien sûr, avec des besoins croissants (par exemple, partitionnement et réplication sur plusieurs serveurs), le schéma deviendra plus complexe.  Mais à première vue, travailler avec cette base de données est très agréable.  On peut voir que le produit est fait "pour les gens". <br><br>  Par rapport à ElasticSearch, le coût de stockage et de traitement des journaux, selon les estimations préliminaires, est réduit de cinq à dix fois.  En d'autres termes, si pour la quantité actuelle de données, nous devons configurer un cluster de plusieurs machines, alors lorsque vous utilisez ClickHouse, nous n'avons besoin que d'une seule machine à faible puissance.  Oui, bien sûr, ElasticSearch dispose également de mécanismes de compression des données sur disque et d'autres fonctionnalités qui peuvent réduire considérablement la consommation de ressources, mais par rapport à ClickHouse, cela sera coûteux. <br><br>  Sans aucune optimisation particulière de sa part, sur les paramètres par défaut, le chargement des données et la récupération des données de la base de données fonctionnent à une vitesse incroyable.  Jusqu'à présent, nous avons un peu de données (environ 200 millions d'enregistrements), mais le serveur lui-même est faible.  À l'avenir, nous pouvons utiliser cet outil à d'autres fins non liées au stockage des journaux.  Par exemple, pour l'analyse de bout en bout, dans le domaine de la sécurité, du machine learning. <br><br>  En fin de compte, un peu sur les avantages et les inconvénients. <br><br><h4>  Inconvénients </h4><br><ol><li>  Téléchargement d'enregistrements en gros lots.  Ceci, d'une part, est une fonctionnalité, mais vous devez toujours utiliser des composants supplémentaires pour tamponner les enregistrements.  Cette tâche n'est pas toujours simple, mais toujours résoluble.  Et je voudrais simplifier le schéma. </li><li>  Certaines fonctionnalités exotiques ou nouvelles fonctionnalités font souvent leur apparition dans de nouvelles versions.  Cela soulève des préoccupations, réduisant le désir de passer à une nouvelle version.  Par exemple, le moteur de table Kafka est une fonctionnalité très utile qui vous permet de lire directement les événements de Kafka, sans implémentation de consommateurs.  Mais à en juger par le nombre de problèmes sur le github, nous sommes toujours réticents à utiliser ce moteur en production.  Cependant, si vous ne faites pas de mouvements brusques sur le côté et utilisez les fonctionnalités de base, cela fonctionne de manière stable. </li></ol><br><h4>  Avantages </h4><br><ol><li>  Cela ne ralentit pas. </li><li>  Seuil d'entrée bas. </li><li>  Open source </li><li>  C'est gratuit. </li><li>  S'adapte bien (partitionnement / réplication prêts à l'emploi) </li><li>  Il est inclus dans le registre des logiciels russes recommandé par le ministère des Communications. </li><li>  La présence du soutien officiel de Yandex. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr472912/">https://habr.com/ru/post/fr472912/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr472894/index.html">DartUP 2019: conférence sur Dart et Flutter à Saint-Pétersbourg le 23 novembre</a></li>
<li><a href="../fr472896/index.html">Hélicoptère à partir d'une imprimante: pour la première fois, des scientifiques ont «imprimé» un boîtier de grande taille d'un moteur d'hélicoptère</a></li>
<li><a href="../fr472902/index.html">Windows pour IoT: prise en charge matérielle améliorée et nouvelles fonctionnalités de périphérique intelligent</a></li>
<li><a href="../fr472904/index.html">Comment Amazon a transformé le stock en jeu</a></li>
<li><a href="../fr472908/index.html">Dagaz: épisodes (partie 2)</a></li>
<li><a href="../fr472914/index.html">Référentiel de fonctions Wolfram: plate-forme d'accès ouvert pour les extensions linguistiques Wolfram</a></li>
<li><a href="../fr472916/index.html">Backend, machine learning et serverless sont les plus intéressants de la conférence de juillet Habr</a></li>
<li><a href="../fr472918/index.html">ZX Spectrum en Russie et dans la CEI: comment la poursuite du online s'est transformée hors ligne</a></li>
<li><a href="../fr472922/index.html">Le programmeur Defender plus fort que l'entropie</a></li>
<li><a href="../fr472926/index.html">La loi de l'accélération des retours (partie 1)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üó®Ô∏è üî± ü•¢ Qu√© tan profundas se ven las redes neuronales y por qu√© requieren tanta memoria üö® üèÜ ü¶å</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoy, el gr√°fico es una de las formas m√°s aceptables para describir los modelos creados en el sistema de aprendizaje autom√°tico. Estos gr√°ficos computa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Qu√© tan profundas se ven las redes neuronales y por qu√© requieren tanta memoria</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/402641/"><img src="https://habrastorage.org/getpro/geektimes/post_images/802/6f4/eab/8026f4eab4ee028d6894159b00421c56.jpg" alt="imagen"><br><br>  Hoy, el gr√°fico es una de las formas m√°s aceptables para describir los modelos creados en el sistema de aprendizaje autom√°tico.  Estos gr√°ficos computacionales est√°n compuestos por v√©rtices neuronales conectados por bordes de sinapsis que describen las conexiones entre v√©rtices. <br><br>  A diferencia de un procesador escalar central o de gr√°ficos vectoriales, IPU, un nuevo tipo de procesador dise√±ado para el aprendizaje autom√°tico, le permite construir tales gr√°ficos.  Una computadora dise√±ada para la gesti√≥n de gr√°ficos es una m√°quina ideal para modelos de gr√°ficos computacionales creados como parte del aprendizaje autom√°tico. <br><br>  Una de las formas m√°s f√°ciles de describir c√≥mo funciona la inteligencia artificial es visualizarla.  El equipo de desarrollo de Graphcore ha creado una colecci√≥n de estas im√°genes que se muestran en la UIP.  La base fue el software Poplar, que visualiza el trabajo de la inteligencia artificial.  Los investigadores de esta compa√±√≠a tambi√©n descubrieron por qu√© las redes profundas requieren tanta memoria y qu√© soluciones existen. <a name="habracut"></a><br><br>  Poplar incluye un compilador gr√°fico que se cre√≥ desde cero para traducir las operaciones est√°ndar utilizadas como parte del aprendizaje autom√°tico en c√≥digo de aplicaci√≥n altamente optimizado para IPU.  Le permite recopilar estos gr√°ficos en el mismo principio que se ensamblan los POPNN.  La biblioteca contiene un conjunto de diferentes tipos de v√©rtices para primitivas generalizadas. <br><br>  Los gr√°ficos son el paradigma en el que se basa todo el software.  En Poplar, los gr√°ficos le permiten definir el proceso de c√°lculo, donde los v√©rtices realizan operaciones y los bordes describen la relaci√≥n entre ellos.  Por ejemplo, si desea agregar dos n√∫meros juntos, puede definir un v√©rtice con dos entradas (los n√∫meros que desea agregar), algunos c√°lculos (la funci√≥n de sumar dos n√∫meros) y la salida (resultado). <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/708/107/2ad/7081072ad3e33d401cabae1f3914bccb.jpg" alt="imagen"><br><br>  Por lo general, las operaciones de v√©rtice son mucho m√°s complicadas que en el ejemplo descrito anteriormente.  A menudo se definen por peque√±os programas llamados codelets (nombres de c√≥digo).  La abstracci√≥n gr√°fica es atractiva porque no hace suposiciones sobre la estructura de los c√°lculos y descompone el c√°lculo en componentes que el procesador de la IPU puede usar para trabajar. <br><br>  Poplar utiliza esta simple abstracci√≥n para construir gr√°ficos muy grandes que se representan como im√°genes.  La generaci√≥n program√°tica del gr√°fico significa que podemos adaptarlo a los c√°lculos espec√≠ficos necesarios para garantizar el uso m√°s eficiente de los recursos de la UIP. <br><br>  El compilador traduce las operaciones est√°ndar utilizadas en los sistemas de aprendizaje autom√°tico en c√≥digo de aplicaci√≥n altamente optimizado para IPU.  Un compilador de gr√°ficos crea una imagen intermedia de un gr√°fico computacional que se implementa en uno o m√°s dispositivos de IPU.  El compilador puede mostrar este gr√°fico computacional, por lo que una aplicaci√≥n escrita en el nivel de estructura de la red neuronal muestra una imagen del gr√°fico computacional que se ejecuta en la IPU. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/45a/eb2/4b8/45aeb24b80e244c6c16c6fc584d99678.jpg" alt="imagen"><br>  <i>Gr√°fico de aprendizaje de ciclo completo de AlexNet hacia adelante y hacia atr√°s</i> <br><br>  El compilador gr√°fico Poplar convirti√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la</a> descripci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">de AlexNet</a> en un gr√°fico computacional de 18,7 millones de v√©rtices y 115,8 millones de aristas.  La agrupaci√≥n claramente visible es el resultado de una fuerte conexi√≥n entre los procesos en cada capa de la red con una conexi√≥n m√°s f√°cil entre los niveles. <br><br>  Otro ejemplo es una red simple con conectividad completa, capacitada en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MNIST</a> : un conjunto de datos simple para visi√≥n por computadora, una especie de "Hola, mundo" en el aprendizaje autom√°tico.  Una red simple para explorar este conjunto de datos ayuda a comprender los gr√°ficos controlados por las aplicaciones de Poplar.  Al integrar bibliotecas de gr√°ficos con entornos como TensorFlow, la compa√±√≠a proporciona una de las formas m√°s f√°ciles de usar las IPU en aplicaciones de aprendizaje autom√°tico. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/f07/3bd/4e3/f073bd4e334225380ae51b16fb2e94b6.jpg" alt="imagen"><br><br>  Una vez que el gr√°fico se construye con el compilador, debe ejecutarse.  Esto es posible usando Graph Engine.  Usando ResNet-50 como ejemplo, se demuestra su funcionamiento. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/5d7/cb1/ce5/5d7cb1ce55a80f2b8e4ebefe38681710.jpg" alt="imagen"><br>  <i>Count ResNet-50</i> <br><br>  La arquitectura ResNet-50 le permite crear redes profundas a partir de particiones repetitivas.  El procesador solo necesita determinar estas particiones una vez y volver a llamarlas.  Por ejemplo, un cl√∫ster de nivel conv4 se ejecuta seis veces, pero solo una vez se aplica al gr√°fico.  La imagen tambi√©n muestra la variedad de formas de capas convolucionales, ya que cada una de ellas tiene un gr√°fico construido de acuerdo con la forma natural de c√°lculo. <br><br>  El motor crea y controla la ejecuci√≥n de un modelo de aprendizaje autom√°tico utilizando un gr√°fico creado por el compilador.  Una vez implementado, Graph Engine monitorea y responde a las IPU o dispositivos utilizados por las aplicaciones. <br><br>  La imagen ResNet-50 muestra el modelo completo.  En este nivel, es dif√≠cil distinguir entre v√©rtices individuales, por lo que debe mirar im√°genes ampliadas.  Los siguientes son algunos ejemplos de secciones dentro de capas de una red neuronal. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/dbf/166/408/dbf166408a0b1626a4bd720e1be1dbe9.jpg" alt="imagen"><br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/d69/9c1/fb6/d699c1fb6f2e43b9f4d03b405c543186.jpg" alt="imagen"><br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/802/6f4/eab/8026f4eab4ee028d6894159b00421c56.jpg" alt="imagen"><br><br><h3>  ¬øPor qu√© las redes profundas necesitan tanta memoria? </h3><br>  Grandes cantidades de memoria ocupada es uno de los mayores problemas de las redes neuronales profundas.  Los investigadores est√°n tratando de lidiar con el ancho de banda limitado de los dispositivos DRAM, que deber√≠an ser utilizados por los sistemas modernos para almacenar una gran cantidad de pesos y activaciones en una red neuronal profunda. <br><br>  Las arquitecturas se desarrollaron utilizando chips de procesador dise√±ados para el procesamiento secuencial y la optimizaci√≥n de DRAM para memoria de alta densidad.  La interfaz entre los dos dispositivos es un cuello de botella que introduce limitaciones de ancho de banda y agrega una sobrecarga significativa al consumo de energ√≠a. <br><br>  Aunque todav√≠a no tenemos una imagen completa del cerebro humano y c√≥mo funciona, en general est√° claro que no hay una gran instalaci√≥n de almacenamiento separada para la memoria.  Se cree que la funci√≥n de la memoria a largo y corto plazo en el cerebro humano est√° incrustada en la estructura de las neuronas + sinapsis.  Incluso los organismos simples como los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gusanos</a> con una estructura neuronal del cerebro, que consta de poco m√°s de 300 neuronas, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tienen</a> alg√∫n grado de funci√≥n de memoria. <br><br>  Construir memoria en procesadores convencionales es una forma de sortear los cuellos de botella de la memoria abriendo un gran ancho de banda con mucho menos consumo de energ√≠a.  Sin embargo, la memoria en un chip es algo costoso que no est√° dise√±ado para cantidades realmente grandes de memoria, que est√°n conectadas a los procesadores centrales y gr√°ficos que se utilizan actualmente para la preparaci√≥n y despliegue de redes neuronales profundas. <br><br>  Por lo tanto, es √∫til observar c√≥mo se usa la memoria hoy en d√≠a en unidades centrales de procesamiento y sistemas de aprendizaje profundo en aceleradores gr√°ficos y preguntarse: ¬øpor qu√© necesitan dispositivos de almacenamiento de memoria tan grandes cuando el cerebro humano funciona bien sin ellos? <br><br>  Las redes neuronales necesitan memoria para almacenar datos de entrada, par√°metros de peso y funciones de activaci√≥n, ya que la entrada se distribuye a trav√©s de la red.  En el entrenamiento, la activaci√≥n en la entrada debe conservarse hasta que pueda usarse para calcular los errores de los gradientes en la salida. <br><br>  Por ejemplo, una red ResNet de 50 capas tiene aproximadamente 26 millones de par√°metros de ponderaci√≥n y calcula 16 millones de activaciones hacia adelante.  Si usa un n√∫mero de coma flotante de 32 bits para almacenar cada peso y activaci√≥n, esto requerir√° aproximadamente 168 MB de espacio.  Usando un valor de precisi√≥n m√°s bajo para almacenar estas escalas y activaciones, podr√≠amos reducir a la mitad o incluso cuadruplicar este requisito de almacenamiento. <br><br>  Un problema grave de memoria surge del hecho de que las GPU se basan en datos representados como vectores densos.  Por lo tanto, pueden usar una sola secuencia de instrucciones (SIMD) para lograr computaci√≥n de alta densidad.  El procesador central utiliza bloques de vectores similares para la inform√°tica de alto rendimiento. <br><br>  En las GPU, la sinapsis tiene 1024 bits de ancho, por lo que utilizan datos de coma flotante de 32 bits, por lo que a menudo los dividen en un mini lote paralelo de 32 muestras para crear vectores de datos de 1024 bits.  Este enfoque para organizar el paralelismo vectorial aumenta el n√∫mero de activaciones en 32 veces y la necesidad de almacenamiento local con una capacidad de m√°s de 2 GB. <br><br>  Las GPU y otras m√°quinas dise√±adas para √°lgebra matricial tambi√©n est√°n sujetas a la carga de memoria de los pesos o las activaciones de la red neuronal.  Las GPU no pueden realizar convoluciones peque√±as de manera eficiente en redes neuronales profundas.  Por lo tanto, una transformaci√≥n llamada "downgrade" se usa para convertir estas convoluciones en multiplicaciones matriz-matriz (GEMM), que los aceleradores gr√°ficos pueden manejar de manera efectiva. <br><br>  Tambi√©n se requiere memoria adicional para almacenar datos de entrada, valores de tiempo e instrucciones del programa.  La medici√≥n del uso de memoria al entrenar ResNet-50 en una GPU de alto rendimiento ha demostrado que requiere m√°s de 7,5 GB de DRAM local. <br><br>  Quiz√°s alguien decida que una precisi√≥n menor puede reducir la cantidad de memoria necesaria, pero ese no es el caso.  Cuando cambia los valores de los datos a la mitad de precisi√≥n para pesos y activaciones, completa solo la mitad del ancho del vector del SIMD, gastando la mitad de los recursos inform√°ticos disponibles.  Para compensar esto, cuando cambie de precisi√≥n completa a media precisi√≥n en la GPU, tendr√° que duplicar el tama√±o del mini lote para causar suficiente paralelismo de datos para usar todos los c√°lculos disponibles.  Por lo tanto, la transici√≥n a escalas de menor precisi√≥n y activaciones en la GPU a√∫n requiere m√°s de 7.5GB de memoria din√°mica con acceso libre. <br><br>  Con tantos datos para almacenar, es simplemente imposible encajar todo esto en la GPU.  En cada capa de la red neuronal convolucional, es necesario guardar el estado de la DRAM externa, cargar la siguiente capa de red y luego cargar los datos en el sistema.  Como resultado, la interfaz de memoria externa, ya limitada por el ancho de banda de la memoria, sufre la carga adicional de recargar constantemente la balanza, as√≠ como guardar y recuperar funciones de activaci√≥n.  Esto ralentiza significativamente el tiempo de entrenamiento y aumenta significativamente el consumo de energ√≠a. <br><br>  Hay varias soluciones a este problema.  En primer lugar, las operaciones como las funciones de activaci√≥n se pueden realizar "in situ", lo que le permite sobrescribir la entrada directamente a la salida.  Por lo tanto, la memoria existente se puede reutilizar.  En segundo lugar, se puede obtener la oportunidad de reutilizar la memoria analizando la dependencia de los datos entre las operaciones en la red y la distribuci√≥n de la misma memoria para las operaciones que no la est√°n utilizando en este momento. <br><br>  El segundo enfoque es especialmente efectivo cuando se puede analizar toda la red neuronal en la etapa de compilaci√≥n para crear una memoria asignada fija, ya que los costos de administraci√≥n de memoria se reducen a casi cero.  Result√≥ que una combinaci√≥n de estos m√©todos reduce el uso de memoria de la red neuronal de dos a tres veces. <br>  Un tercer enfoque significativo fue descubierto recientemente por el equipo de Baidu Deep Speech.  Aplicaron varios m√©todos de ahorro de memoria para obtener una reducci√≥n de 16 veces en el consumo de memoria mediante funciones de activaci√≥n, lo que les permiti√≥ entrenar redes con 100 capas.  Anteriormente, con la misma cantidad de memoria, pod√≠an entrenar redes con nueve capas. <br><br>  La combinaci√≥n de recursos de memoria y procesamiento en un dispositivo tiene un potencial significativo para aumentar la productividad y la eficiencia de las redes neuronales convolucionales, as√≠ como otras formas de aprendizaje autom√°tico.  Puede hacer un compromiso entre la memoria y los recursos inform√°ticos para equilibrar las capacidades y el rendimiento del sistema. <br><br>  Las redes neuronales y los modelos de conocimiento en otros m√©todos de aprendizaje autom√°tico se pueden considerar como gr√°ficos matem√°ticos.  En estos gr√°ficos, se concentra una gran cantidad de paralelismo.  Un procesador paralelo dise√±ado para utilizar la simultaneidad en los gr√°ficos no se basa en mini lotes y puede reducir significativamente la cantidad de almacenamiento local requerido. <br><br>  Los resultados de la investigaci√≥n moderna han demostrado que todos estos m√©todos pueden mejorar significativamente el rendimiento de las redes neuronales.  Los gr√°ficos modernos y las unidades de procesamiento central tienen memoria interna muy limitada, solo unos pocos megabytes en total.  Las nuevas arquitecturas de procesador espec√≠ficamente dise√±adas para el aprendizaje autom√°tico proporcionan un equilibrio entre la memoria y la computaci√≥n en chip, proporcionando un aumento significativo en el rendimiento y la eficiencia en comparaci√≥n con las modernas unidades de procesamiento central y aceleradores gr√°ficos. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es402641/">https://habr.com/ru/post/es402641/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es402629/index.html">Mis peque√±os relevos: la computadora Brainfuck es m√°gica</a></li>
<li><a href="../es402631/index.html">Qu√© monitor de frecuencia card√≠aca elegir en la nueva temporada: soluciones de compromiso dentro de tres a cuatro mil rublos</a></li>
<li><a href="../es402633/index.html">El cuento de Battlefield 1 en Full HD en los gr√°ficos integrados en el procesador y el montaje de la consola para "imperecedero"</a></li>
<li><a href="../es402637/index.html">Estudiante de 17 a√±os corrigi√≥ error de la NASA</a></li>
<li><a href="../es402639/index.html">Peter Watts sobre SOMA</a></li>
<li><a href="../es402643/index.html">"Mundo delgado". Capitulo 10</a></li>
<li><a href="../es402645/index.html">Usando el programa ServoStudio 12 y la placa Arduino, puede crear su propio robot sin escribir una sola l√≠nea de c√≥digo</a></li>
<li><a href="../es402649/index.html">El m√°s preciso del mundo: monitores de frecuencia card√≠aca Valencell para Jabra, Suunto, Atlas, Sony y otros</a></li>
<li><a href="../es402651/index.html">El implante de polietileno de peso molecular ultra alto reemplaz√≥ el tejido √≥seo o el pol√≠mero de hierro</a></li>
<li><a href="../es402653/index.html">Los robomobiles tienen problemas con los ciclistas.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
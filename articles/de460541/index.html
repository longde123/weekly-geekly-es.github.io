<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👊🏿 🐉 🖕🏻 Suchen Sie in einer Millisekunde nach Gesichtskonturen mit einem Ensemble von Regressionsbäumen 👲 🗄️ 🍿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Übersetzung des Artikels wurde für Studenten des Kurses "Mathematik für Datenwissenschaften" vorbereitet. 

 Anmerkung 


 Dieser Artikel beschrei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Suchen Sie in einer Millisekunde nach Gesichtskonturen mit einem Ensemble von Regressionsbäumen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/460541/"><p><img src="https://habrastorage.org/webt/eb/rn/3a/ebrn3a_ugfcxc9tuhkdmwgnrut8.png"></p><br><p>  <em>Die Übersetzung des Artikels wurde für Studenten des Kurses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"Mathematik für Datenwissenschaften"</a> vorbereitet.</em> </p><br><hr><br><h1 id="annotaciya">  Anmerkung </h1><br><p>  <em>Dieser Artikel beschreibt die Aufgabe, Gesichtskonturen für ein einzelnes Bild zu finden.</em>  <em>Wir zeigen, wie das Ensemble von Regressionsbäumen verwendet werden kann, um die Position von Gesichtskonturen direkt aus einer verstreuten Teilmenge von Pixelintensitäten vorherzusagen und mit hochqualitativen Vorhersagen in Echtzeit eine Superleistung zu erzielen.</em>  <em>Wir präsentieren eine allgemeine Struktur, die auf Gradientenverstärkung basiert, um ein Ensemble von Regressionsbäumen zu untersuchen, das die Summe der quadratischen Verluste optimiert und natürlich fehlende oder teilweise markierte Daten verarbeitet.</em>  <em>Wir werden zeigen, wie die Verwendung geeigneter Verteilungen, die die Struktur von Bilddaten berücksichtigen, bei der effizienten Auswahl von Konturen hilft.</em>  <em>Verschiedene Regularisierungsstrategien und ihre Bedeutung im Kampf gegen Umschulungen werden ebenfalls untersucht.</em>  <em>Darüber hinaus analysieren wir die Auswirkung der Menge an Trainingsdaten auf die Genauigkeit von Vorhersagen und untersuchen die Auswirkung der Datenerhöhung anhand synthetisierter Daten.</em> <a name="habracut"></a></p><br><h1 id="1-vvedenie">  1. Einleitung </h1><br><p>  In diesem Artikel stellen wir einen neuen Algorithmus vor, der in Millisekunden nach Gesichtskonturen sucht und eine Genauigkeit erzielt, die modernen Methoden für Standarddatensätze überlegen oder mit diesen vergleichbar ist.  Die Erhöhung der Geschwindigkeit im Vergleich zu den vorherigen Methoden ist eine Folge der Identifizierung der Hauptkomponenten der vorherigen Algorithmen für die Suche nach Gesichtskonturen und ihrer anschließenden Aufnahme in eine optimierte Form in die Kaskade von Regressionsmodellen mit hohem Durchsatz, die mithilfe der Gradientenverstärkung konfiguriert wurden. </p><br><p>  Wir zeigen, wie bereits zuvor [8, 2], dass die Suche nach Gesichtskonturen mit einer Kaskade von Regressionsmodellen durchgeführt werden kann.  In unserem Fall sagt jedes Regressionsmodell in der Kaskade die Form des Gesichts basierend auf der anfänglichen Vorhersage und der Intensität des spärlichen Satzes von Pixeln, die relativ zu dieser anfänglichen Vorhersage indiziert sind, effektiv voraus.  Unsere Arbeit basiert auf einer Vielzahl von Studien, die im letzten Jahrzehnt durchgeführt wurden und zu erheblichen Fortschritten bei der Suche nach Gesichtskonturen geführt haben [9, 4, 13, 7, 15, 1, 16, 18, 3, 6, 19].  Insbesondere haben wir in unsere abgestimmten Regressionsmodelle zwei Schlüsselelemente aufgenommen, die in mehreren der folgenden erfolgreichen Algorithmen vorhanden sind, und jetzt werden diese Elemente detailliert beschrieben. </p><br><p><img src="https://habrastorage.org/webt/xe/fn/ux/xefnuxzvuozcmpu5xjzvwwm3kq4.png"></p><br><p>  <em>Abbildung 1. Ausgewählte Ergebnisse im HELEN-Datensatz.</em>  <em>Um 194 wichtige Punkte (Landmarken) auf dem Gesicht in einem Bild in einer Millisekunde zu erkennen, wird ein Ensemble randomisierter Regressionsbäume verwendet.</em> </p><br><p>  Die erste dreht sich um die Indexierung der Pixelintensität relativ zur aktuellen Vorhersage der Gesichtsform.  Die unterscheidbaren Merkmale in der Vektordarstellung des Gesichtsbildes können aufgrund der Verformung der Form und aufgrund von Störfaktoren wie Änderungen der Lichtverhältnisse stark variieren.  Dies macht es schwierig, die Form unter Verwendung dieser Funktionen genau vorherzusagen.  Das Dilemma besteht darin, dass wir zuverlässige Zeichen benötigen, um die Form genau vorherzusagen, und andererseits benötigen wir eine genaue Vorhersage der Form, um zuverlässige Zeichen zu extrahieren.  In der vorherigen Arbeit [4, 9, 5, 8] sowie in dieser Arbeit wird ein iterativer Ansatz (Kaskade) verwendet, um dieses Problem zu lösen.  Anstatt die Formparameter basierend auf den im globalen Bildkoordinatensystem extrahierten Merkmalen zu regressieren, wird das Bild basierend auf der aktuellen Formvorhersage in ein normalisiertes Koordinatensystem konvertiert, und dann werden Zeichen extrahiert, um den Aktualisierungsvektor für die Formparameter vorherzusagen.  Dieser Vorgang wird normalerweise mehrmals bis zur Konvergenz wiederholt. </p><br><p>  Im zweiten Teil wird untersucht, wie mit der Komplexität des Erklärungs- / Vorhersageproblems umgegangen werden soll.  Während des Tests sollte der Kontursuchalgorithmus die Form des Gesichts vorhersagen - ein hochdimensionaler Vektor, der am besten mit den Bilddaten und unserem Formmodell übereinstimmt.  Das Problem ist bei vielen lokalen Optima nicht konvex.  Erfolgreiche Algorithmen [4, 9] lösen dieses Problem unter der Annahme, dass die vorhergesagte Form in einem linearen Unterraum liegen sollte, der beispielsweise durch Auffinden der Hauptkomponenten der Trainingsformen erkannt werden kann.  Diese Annahme reduziert die Anzahl potenzieller Formen, die bei der Erklärung berücksichtigt werden, erheblich und kann dazu beitragen, lokale Optima zu vermeiden. </p><br><p>  Eine kürzlich erschienene Arbeit [8, 11, 2] nutzt die Tatsache aus, dass eine bestimmte Klasse von Regressoren garantiert Vorhersagen erstellt, die in dem durch Lernformen definierten linearen Unterraum liegen, und dass keine zusätzlichen Einschränkungen erforderlich sind.  Es ist wichtig, dass unsere Regressionsmodelle diese beiden Elemente aufweisen. <br>  Diese beiden Faktoren hängen mit unserem effektiven Training im Regressionsmodell zusammen.  Wir optimieren die entsprechende Verlustfunktion und führen die Merkmalsauswahl anhand von Daten durch.  Insbesondere trainieren wir jeden Regressor mit Gradientenverstärkung [10] unter Verwendung der quadratischen Verlustfunktion, der gleichen Verlustfunktion, die wir während des Tests minimieren möchten.  Der Satz von spärlichen Pixeln, der als Eingabe in den Regressor verwendet wird, wird unter Verwendung einer Kombination des Gradientenverstärkungsalgorithmus und der a priori-Wahrscheinlichkeit der Abstände zwischen Paaren von Eingabepixeln ausgewählt.  Eine A-priori-Verteilung ermöglicht es dem Boosting-Algorithmus, eine große Anzahl relevanter Merkmale effizient zu untersuchen.  Das Ergebnis ist eine Kaskade von Regressoren, die Gesichtsmarkierungen lokalisieren können, wenn sie von vorne initialisiert werden. </p><br><p>  Die Hauptbeiträge dieses Artikels sind: </p><br><ol><li>  Eine neue Methode zum Finden von Gesichtskonturen, basierend auf einem Ensemble von Regressionsbäumen (Entscheidungsbäumen), die die Auswahl invarianter Merkmale des Formulars durchführt und gleichzeitig die gleiche Verlustfunktion während des Trainings minimiert, die wir während des Tests minimieren möchten. </li><li>  Wir präsentieren eine natürliche Erweiterung unserer Methode, die fehlende oder undefinierte Labels verarbeitet. </li><li>  Es werden quantitative und qualitative Ergebnisse präsentiert, die bestätigen, dass unsere Methode qualitativ hochwertige Prognosen liefert und viel effektiver ist als die beste vorherige Methode (Abbildung 1). </li><li>  Der Einfluss der Menge an Trainingsdaten, der Verwendung von teilweise gekennzeichneten Daten und verallgemeinerten Daten auf die Qualität von Prognosen wird analysiert. </li></ol><br><h1 id="2-metod">  2. Methode </h1><br><p>  In diesem Artikel wird ein Algorithmus zur genauen Beurteilung der Position von Gesichtspunkten (Schlüsselpunkten) im Hinblick auf die Recheneffizienz vorgestellt.  Wie in früheren Arbeiten [8, 2] wird in unserer Methode die Kaskade der Regressoren verwendet.  Im Rest dieses Abschnitts beschreiben wir die Details der Form der einzelnen Komponenten der Kaskade und wie wir das Training durchführen. </p><br><h4 id="21-kaskad-regressorov">  2.1.  Regressionskaskade </h4><br><p>  Zuerst führen wir eine Notation ein.  Lass <img src="https://habrastorage.org/getpro/habr/post_images/96b/8a8/cd3/96b8a8cd39c5f39cf67191c499d17a36.svg">  , y-Koordinaten des i-ten Orientierungspunkts des Gesichts im Bild I. Dann der Vektor <img src="https://habrastorage.org/getpro/habr/post_images/bd9/f10/315/bd9f10315460922e284cfe03581f1e91.svg">  bezeichnet die Koordinaten aller p Flächen in I. Oft nennen wir in diesem Artikel den Vektor S eine Form.  Wir benutzen <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  um unsere aktuelle Bewertung S anzuzeigen. Jeder Regressor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  (·, ·) In der Kaskade sagt der Aktualisierungsvektor aus dem Bild und voraus <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  Dies wird zur aktuellen Formularbewertung hinzugefügt <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  So verbessern Sie die Bewertung: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/813/e90/80c/813e9080c1daa94987bfd323fcf05d75.svg">  ) <em>(1)</em> </p><br><p>  Der entscheidende Punkt der Kaskade ist, dass der Regressor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  Die Prognosen basieren auf Attributen wie Pixelintensitäten, die von I berechnet und relativ zur aktuellen Formschätzung indiziert werden <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  .  Dies führt eine Art geometrische Invarianz in den Prozess ein, und während Sie die Kaskade durchlaufen, können Sie sicherer sein, dass die genaue semantische Position auf dem Gesicht indiziert ist.  Wir werden später beschreiben, wie diese Indizierung durchgeführt wird. </p><br><p>  Bitte beachten Sie, dass der vom Ensemble erweiterte Ausgabebereich bei der anfänglichen Schätzung garantiert im linearen Unterraum der Trainingsdaten liegt <img src="https://habrastorage.org/getpro/habr/post_images/f0d/6ae/457/f0d6ae4573955eb6abc901db0a68bc4a.svg">  gehört zu diesem Raum.  Daher müssen wir keine zusätzlichen Einschränkungen für die Vorhersagen einführen, was unsere Methode erheblich vereinfacht.  Die Anfangsform kann einfach als mittlere Form von Trainingsdaten ausgewählt, zentriert und entsprechend der Ausgabe des Begrenzungsrahmens des allgemeinen Gesichtsdetektors skaliert werden. </p><br><p>  Alle erziehen <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  Wir verwenden den Gradientenverstärkungsalgorithmus für Bäume mit der Summe der quadratischen Verluste, wie in [10] beschrieben.  Jetzt werden wir detaillierte Details dieses Prozesses geben. </p><br><h4 id="22-obuchenie-kazhdogo-regressora-v-kaskade">  2.2.  Trainiere jeden Regressor in einer Kaskade </h4><br><p>  Angenommen, wir haben Trainingsdaten <img src="https://habrastorage.org/getpro/habr/post_images/a81/786/c9b/a81786c9b9d6dc27492f55b19afb5055.svg">  wo alle <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  ist ein Gesichtsbild und <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  sein Formvektor.  Um die erste Regressionsfunktion herauszufinden <img src="https://habrastorage.org/getpro/habr/post_images/0ac/302/657/0ac302657b1d8e45efa7f7b9b2557268.svg">  In der Kaskade erstellen wir aus unseren Trainingsdaten Tripletts des Gesichtsbildes, der anfänglichen Formvorhersage und des Zielaktualisierungsschritts, d.h. <img src="https://habrastorage.org/getpro/habr/post_images/6a1/450/b9e/6a1450b9ea40a582ec2794d9df7afd31.svg">  ) wo </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f29/a62/581/f29a625813ba6c6cd00aea30a8cfe019.svg">  <em>(2)</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/6c3/a0d/468/6c3a0d468f609ada0672c0f473c589ec.svg">  <em>(3)</em> und </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/691/50d/5cf/69150d5cfe48125a51002916c28453e8.svg">  <em>(4)</em> </p><br><p>  für i = 1, ..., N. </p><br><p>  Wir setzen die Gesamtzahl dieser Tripletts auf N = nR, wobei R die Anzahl der auf Bild Ii verwendeten Initialisierungen ist.  Jede anfängliche Formvorhersage für das Bild wird gleichmäßig aus ausgewählt <img src="https://habrastorage.org/getpro/habr/post_images/d1c/fb5/092/d1cfb5092f0e598893288582f2114b37.svg">  ohne Ersatz. </p><br><p>  Anhand dieser Daten trainieren wir die Regressionsfunktion <img src="https://habrastorage.org/getpro/habr/post_images/bcb/830/694/bcb83069438bb8a2d3e1e51f76a276f4.svg">  (siehe Algorithmus 1) Verwenden der Gradientenverstärkung von Bäumen mit der Summe der quadratischen Verluste.  Der Trainings-Triplett-Satz wird dann aktualisiert, um Trainingsdaten bereitzustellen. <img src="https://habrastorage.org/getpro/habr/post_images/f56/e5c/4a8/f56e5c4a803f2c95ebe20dae215895cf.svg">  % 20) für den nächsten Regressor <img src="https://habrastorage.org/getpro/habr/post_images/dc5/512/a85/dc5512a85c881619a2c05faa3c2a2806.svg">  in der Kaskade durch Setzen (mit t = 0). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/146/29d/692/14629d6922ca89d70fed70bbeb3287bd.svg">  % 20) <em>(5)</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/17d/8a5/44a/17d8a544a843aa72dc68d79ab9c2236d.svg">  <em>(6)</em> </p><br><p>  Dieser Vorgang wird wiederholt, bis eine Kaskade von T-Regressoren trainiert ist. <img src="https://habrastorage.org/getpro/habr/post_images/ee6/6a5/503/ee66a5503085c7bbaa7a616585c4ae2e.svg">  die in Kombination ein ausreichendes Maß an Genauigkeit bieten. </p><br><p>  Wie angegeben, jeder Regressor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  lernt mit dem Gradientenbaum-Boosting-Algorithmus.  Es ist zu beachten, dass die quadratische Verlustfunktion verwendet wird und die in der inneren Schleife berechneten Residuen dem Gradienten dieser Verlustfunktion entsprechen, der in jeder Trainingsprobe geschätzt wird.  Die Formulierung des Algorithmus enthält den Lernratenparameter 0 &lt;ν ≤ 1, auch als Regularisierungskoeffizient bekannt.  Das Setzen von ν &lt;1 hilft bei der Bekämpfung der Rekonfiguration und führt normalerweise zu Regressoren, die viel besser verallgemeinern als diejenigen, die mit ν = 1 trainiert wurden [10]. </p><br><hr><br><p>  <strong>Lernalgorithmus 1</strong> <strong><img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg"></strong>  <strong>in Kaskade</strong> </p><br><p>  Wir haben Trainingsdaten <img src="https://habrastorage.org/getpro/habr/post_images/2d4/805/43a/2d480543a349544ead268291984b1e6a.svg">  und Lernrate (Regularisierungskoeffizient) 0 &lt;ν &lt;1 </p><br><ol><li>  Initialisieren <br><img src="https://habrastorage.org/getpro/habr/post_images/e54/d75/bae/e54d75bae7a82091f8d5c1f04a92cc22.svg"></li><li>  für k = 1, ..., K: <br>  a) wir setzen auf i = 1, ..., <br><img src="https://habrastorage.org/getpro/habr/post_images/759/573/b03/759573b032b3bb95986dfe5d42d8e5d8.svg"><br>  b) Wir passen den Regressionsbaum an das Ziel an <img src="https://habrastorage.org/getpro/habr/post_images/683/2f3/54e/6832f354e8f4ecad8283cc1be6a6899a.svg">  mit schwacher Regressionsfunktion <img src="https://habrastorage.org/getpro/habr/post_images/425/db2/33f/425db233f09794bfe60e62a49da89a98.svg">  . <br>  c) Aktualisieren <img src="https://habrastorage.org/getpro/habr/post_images/376/5d0/ac3/3765d0ac3de75d838ad520821c141c21.svg"></li><li>  Fazit <br><img src="https://habrastorage.org/getpro/habr/post_images/7c0/9c4/2b9/7c09c42b9cc35b3225f89435a9d4ce22.svg"></li></ol><br><hr><br><h4 id="23-drevovidnyy-regressor">  2.3.  Baumregressor </h4><br><p>  Im Zentrum jeder RT-Regressionsfunktion stehen baumartige Regressoren, die für Restziele während des Gradientenverstärkungsalgorithmus geeignet sind.  Jetzt werden wir uns die wichtigsten Implementierungsdetails für das Training jedes Regressionsbaums ansehen. </p><br><h4 id="231-invariantnye-split-testy-formy">  2.3.1 Invariante Split-Form-Tests </h4><br><p>  An jedem Trennknoten im Regressionsbaum treffen wir eine Entscheidung basierend auf dem Schwellenwert der Differenz zwischen den Intensitäten von zwei Pixeln.  Die im Test verwendeten Pixel befinden sich an den Positionen u und v, wenn sie im Koordinatensystem der mittleren Form definiert sind.  Für ein Bild eines Gesichts mit einer beliebigen Form möchten wir Punkte indizieren, die relativ zu ihrer Form dieselbe Position wie u und v haben, für die durchschnittliche Form.  Zu diesem Zweck kann das Bild vor dem Extrahieren der Elemente basierend auf der aktuellen Formschätzung in die mittlere Form deformiert werden.  Da wir nur eine sehr spärliche Darstellung des Bildes verwenden, ist es viel effizienter, die Anordnung der Punkte zu verformen als das gesamte Bild.  Darüber hinaus kann eine grobe Annäherung an die Verformung vorgenommen werden, indem zusätzlich zu den in [2] vorgeschlagenen globalen Verschiebungen nur die globale Ähnlichkeitstransformation verwendet wird. </p><br><p>  Die genauen Details sind wie folgt.  Lass <img src="https://habrastorage.org/getpro/habr/post_images/482/2f7/60f/4822f760fdf061f414f323d30d0c14cd.svg">  Ist der Index des Orientierungspunkts auf dem Gesicht in der mittleren Form am nächsten an u und definiert seine Verschiebung von u als <img src="https://habrastorage.org/getpro/habr/post_images/0fa/bbb/f81/0fabbbf8125f80b9f31e3b5ce093bc3c.svg">  . </p><br><p>  Dann für die im Bild definierte Form Si <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  Position in <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  , das u im Bild einer mittleren Form qualitativ ähnlich ist, ist definiert als <br><img src="https://habrastorage.org/getpro/habr/post_images/e2d/e8d/0d4/e2de8d0d461e2ef6e76642d39a803b27.svg">  <em>(7)</em> </p><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  und <img src="https://habrastorage.org/getpro/habr/post_images/8f6/b4a/913/8f6b4a913e518f22483a28148144b54e.svg">  - Skalierungs- und Rotationsmatrix der Ähnlichkeitstransformation, die transformiert <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  in <img src="https://habrastorage.org/getpro/habr/post_images/919/800/718/919800718f235e7487c36b01db6739e1.svg">  mittlere Form. </p><br><p>  Skalierung und Rotation minimieren </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/cf0/581/e89/cf0581e890e027fcaf3327e3be6f194c.svg">  <em>(8)</em> </p><br><p>  die Summe der Quadrate zwischen den Orientierungspunkten der mittleren Form, <img src="https://habrastorage.org/getpro/habr/post_images/c73/942/e7f/c73942e7f47a9adb6091e024085fc1bb.svg">  und Point Warp. <img src="https://habrastorage.org/getpro/habr/post_images/b2d/a25/52e/b2da2552e44457f6bcbf5d1aab251267.svg">  ähnlich definiert. </p><br><p>  Formal ist jede Division eine Lösung, die 3 Parameter θ = (τ, u, v) enthält und auf jedes Trainings- und Testbeispiel als angewendet wird </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/bfe/6ee/9c7/bfe6ee9c7e9da21fb2b81caca3d8abad.svg">  <em>(9)</em> </p><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/ff8/c77/429/ff8c77429402ff15260663452a693e8d.svg">  und <img src="https://habrastorage.org/getpro/habr/post_images/b2d/a25/52e/b2da2552e44457f6bcbf5d1aab251267.svg">  werden unter Verwendung der Skala und der Rotationsmatrix bestimmt, die sich am besten verformen <img src="https://habrastorage.org/getpro/habr/post_images/5ac/ad7/803/5acad7803f7a79cc10fa8c714205eeab.svg">  in <img src="https://habrastorage.org/getpro/habr/post_images/919/800/718/919800718f235e7487c36b01db6739e1.svg">  gemäß Gleichung (7).  In der Praxis werden Aufgaben und lokale Verschiebungen in der Trainingsphase festgelegt.  Die Berechnung der Ähnlichkeitstransformation während des Testens des teuersten Teils dieses Prozesses wird auf jeder Ebene der Kaskade nur einmal durchgeführt. </p><br><h4 id="232-vybor-uzlovyh-razbieniy">  2.3.2 Auswahl der Knotenpartitionen </h4><br><p>  Für jeden Regressionsbaum approximieren wir die Grundfunktion durch eine stückweise lineare Funktion, wobei ein konstanter Vektor für jeden endlichen Knoten geeignet ist.  Um den Regressionsbaum zu trainieren, erzeugen wir zufällig einen Satz geeigneter Partitionen, dh θ, in jedem Knoten.  Dann wählen wir eifrig θ * aus diesen Kandidaten aus, was die Summe des quadratischen Fehlers minimiert.  Wenn Q ein Satz von Indizes von Trainingsbeispielen in einem Knoten ist, entspricht dies einer Minimierung </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8b2/8f1/e02/8b28f1e02ab50c802525c5ded6aaeeaf.svg">  <em>(10)</em> </p><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/fd5/fa1/737/fd5fa1737973ecd7a303b2862a32f8ec.svg">  - Indizes von Beispielen, die aufgrund der Entscheidung θ an den linken Knoten gesendet werden, <img src="https://habrastorage.org/getpro/habr/post_images/ab1/ee0/4fb/ab1ee04fb1210c9352cc942823f6dcd1.svg">  Ist der Vektor aller Residuen, die für das Bild <em>i</em> im Gradientenverstärkungsalgorithmus berechnet wurden, und </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c7f/e61/cc7/c7fe61cc7d441d07443317d12fc860c4.svg">  für <img src="https://habrastorage.org/getpro/habr/post_images/e17/6e7/ece/e176e7ece99e70aeee6c4ffe2949bb2f.svg">  <em>(11)</em> </p><br><p>  Die optimale Partition kann sehr effizient gefunden werden, denn wenn wir Gleichung (10) transformieren und von θ unabhängige Faktoren weglassen, können wir das sehen </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/517/57c/a5c/51757ca5c227156f25de32c995a6c1eb.svg"></p><br><p>  Hier müssen wir nur berechnen <img src="https://habrastorage.org/getpro/habr/post_images/88d/4eb/4bb/88d4eb4bb69acbcbbbf4ad0e10098a80.svg">  bei der Auswertung verschiedener θs, da <img src="https://habrastorage.org/getpro/habr/post_images/ba2/1c8/eeb/ba21c8eeb00ef767cf6f5bd5297f986e.svg">  kann aus den durchschnittlichen Zielen im Elternknoten µ und berechnet werden <img src="https://habrastorage.org/getpro/habr/post_images/88d/4eb/4bb/88d4eb4bb69acbcbbbf4ad0e10098a80.svg">  wie folgt: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b0a/e76/10a/b0ae7610afe1aa13d10de797871193c6.svg"></p><br><h4 id="233-vybor-priznakov">  2.3.3 Auswahl der Merkmale </h4><br><p>  Die Lösung an jedem Knoten basiert auf einem Schwellenwert der Differenz der Intensitätswerte in einem Pixelpaar.  Dies ist ein ziemlich einfacher Test, der jedoch aufgrund seiner relativen Unempfindlichkeit gegenüber Änderungen der globalen Beleuchtung viel effektiver ist als ein Schwellenwert mit einer einzelnen Intensität.  Leider besteht der Nachteil der Verwendung von Pixeldifferenzen darin, dass die Anzahl potenzieller Trennungskandidaten (Merkmal) in Bezug auf die Anzahl von Pixeln im Durchschnittsbild quadratisch ist.  Dies macht es schwierig, gute θs zu finden, ohne nach einer sehr großen Anzahl von ihnen zu suchen.  Dieser begrenzende Faktor kann jedoch unter Berücksichtigung der Struktur der Bilddaten etwas abgeschwächt werden. </p><br><p>  Wir führen die Exponentialverteilung ein </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f30/6b8/6c4/f306b86c47bfa440c1d1c716e3c9d6b8.svg">  <em>(12)</em> </p><br><p>  durch den Abstand zwischen den Pixeln, die bei der Aufteilung verwendet werden, um die Auswahl engerer Pixelpaare zu fördern. </p><br><p>  Wir haben festgestellt, dass die Verwendung dieser einfachen Verteilung den Vorhersagefehler für eine Reihe von Gesichtsdatensätzen reduziert.  In Abbildung 4 werden die mit und ohne Features ausgewählten Features verglichen, wobei die Größe des Objektpools in beiden Fällen auf 20 festgelegt ist. </p><br><h1 id="24-obrabotka-propuschennyh-metok">  2.4.  Umgang mit fehlenden Tags </h1><br><p>  Das Problem von Gleichung (10) kann leicht erweitert werden, um den Fall zu behandeln, in dem einige Orientierungspunkte auf einigen Trainingsbildern nicht markiert sind (oder wir haben ein Maß für die Unsicherheit für jeden Orientierungspunkt).  Variable eingeben <img src="https://habrastorage.org/getpro/habr/post_images/7e0/805/7ed/7e08057ed464a0c8c2af586f05a009aa.svg">  [0, 1] für jedes Trainingsbild <em>i</em> und jeden Orientierungspunkt <em>j</em> .  Installation <img src="https://habrastorage.org/getpro/habr/post_images/260/ce8/a6b/260ce8a6b696864e07aaa5de561923e6.svg">  Ein Wert von 0 zeigt an, dass der Orientierungspunkt <em>j</em> im <em>i-</em> ten Bild nicht markiert ist, und eine Einstellung von 1 zeigt an, dass er markiert ist.  Dann kann Gleichung (10) wie folgt dargestellt werden </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/7e5/183/d89/7e5183d8955912640ff62a62fd8913de.svg"></p><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/07f/821/26e/07f82126e42fc56123ae1a571fcaac7b.svg">  - Diagonalmatrix mit Vektor <img src="https://habrastorage.org/getpro/habr/post_images/a77/988/515/a779885154cabacbcccfb17d823fd818.svg">  auf ihrer Diagonale und </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/7a7/975/451/7a79754517a719b74cff33c43743171f.svg">  für <img src="https://habrastorage.org/getpro/habr/post_images/e17/6e7/ece/e176e7ece99e70aeee6c4ffe2949bb2f.svg">  <em>(13)</em> </p><br><p>  Der Gradientenverstärkungsalgorithmus muss ebenfalls modifiziert werden, um diese Gewichte zu berücksichtigen.  Dies kann erreicht werden, indem einfach das Ensemble-Modell mit dem gewichteten Durchschnittswert der Ziele initialisiert und die Regressionsbäume wie folgt an die gewichteten Residuen in Algorithmus 1 angepasst werden </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/396/468/7a9/3964687a9c8c905316ef8d6b69d73888.svg">  <em>(14)</em> </p><br><h1 id="3-eksperimenty">  3. Experimente </h1><br><p>  <strong>Grundlagen:</strong> Um die Leistung unserer vorgeschlagenen Methode, dem Ensemble von Regressionsbäumen (ERT), genau zu bewerten, haben wir zwei weitere Grundlagen erstellt.  Der erste basiert auf zufälligen Farnen (zufälligen Farnen) mit einer zufälligen Auswahl von Merkmalen (EF), und der andere ist eine fortgeschrittenere Version dieses Ansatzes mit der Auswahl von Merkmalen basierend auf Korrelation (EF + CB), was unsere neue Implementierung ist [2].  Alle Parameter sind für alle drei Ansätze festgelegt. </p><br><p>  EF nutzt die direkte Implementierung von zufälligen Farnen als schwache Regressoren im Ensemble und ist die schnellste für das Training.  Wir verwenden dieselbe Regularisierungsmethode wie in [2] für die Regularisierung von Farnen vorgeschlagen. </p><br><p>  EF + CB verwendet eine korrelationsbasierte Objektauswahlmethode, die Ausgabewerte projiziert. <img src="https://habrastorage.org/getpro/habr/post_images/ab1/ee0/4fb/ab1ee04fb1210c9352cc942823f6dcd1.svg">  's in eine zufällige Richtung w und wählt Zeichenpaare (u, v) aus, für die <img src="https://habrastorage.org/getpro/habr/post_images/dcf/e8f/3cc/dcfe8f3ccb1ca1095fc35db5b623abc0.svg">           <img src="https://habrastorage.org/getpro/habr/post_images/b63/418/2d8/b634182d884088b10405bc691e479fd8.svg">  . </p><br><p> <strong></strong> <br>    ,        .    rt   T = 10,   <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">   K = 500   <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg">  .   ( ),    <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg"> ,   F = 5.     P = 400    .    ,        P              ,     (9).        S = 20    ,    .        ,   R = 20      . </p><br><p><img src="https://habrastorage.org/webt/7j/we/fs/7jwefsr7puidwxuehw6owexel8k.png"></p><br><p> <em> 2.       ,             Viola &amp; Jones [17].        .</em> </p><br><p> <strong></strong> <br>          O (TKF).          O (NDTKF S),  N —   ,  D —  .                HELEN [12],           . </p><br><p> <strong> </strong> <br>   ,   ,      HELEN [12], ,   ,      .    2330 ,     194 .      2000    ,    . </p><br><p>           LFPW [1],    1432 .  ,     778    216   ,         ,      . </p><br><p>  <strong>Vergleich</strong> <br>  1         .                  (Active Shape Models) — STASM [14]  CompASM [12]. </p><br><p><img src="https://habrastorage.org/webt/89/fk/kc/89fkkczbo119vyy4oo7hhu7cmno.png"></p><br><p> <em> 1.        HELEN.  —          .       .      ,        .    ,       .              .</em> </p><br><p>   ,    ,        .   3       ,  ,  ERT     ,   .  ,        EF + CB     .  ,      EF + CB       ,     . </p><br><p>          LFPW [1] ( 2).    EF + CB     ,   [2]. (     ,        .)              ,      ,     . </p><br><p><img src="https://habrastorage.org/webt/ef/uu/nz/efuunznz_ljfv_sr1v1vi5fujoy.png"></p><br><p> <em> 2.        LFPW.       1.</em> </p><br><p> <strong> </strong> <br>  4     (12)       ,   ,      .  λ               0,1   .            <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">         .  4          . </p><br><p><img src="https://habrastorage.org/webt/do/pm/v4/dopmv4u-mj6pa5tcaioawlcvegs.png"></p><br><p> <em> 3.           .         ,  , .  (12).</em> </p><br><p> <strong></strong> <br>        ,   .     ,     .    — .        ν      1 (   ν = 0.1).           .  , <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg">   ,    ,    ν = 1.                   (10   )   . (      .) </p><br><p><img src="https://habrastorage.org/webt/lp/hv/hv/lphvhvclakdn02mzwrfe5rtt28w.png"></p><br><p> <em> 3.       HELEN (a)  LFPW (b). EF —    ,  EF + CB —      ,   .          (5  10),    [2].  ,      (ERT),     ,     ,             .</em> </p><br><p><img src="https://habrastorage.org/webt/xm/3y/pp/xm3yppxdejbgcglidfb-ecofaza.png"></p><br><p> <em> 4.   ,    .       ,      .</em> </p><br><p>             ,   .         ,    . </p><br><p><img src="https://habrastorage.org/webt/0r/hv/l0/0rhvl0mowqozwdscxpkc-lp-w7e.png"></p><br><p> <em> 4.      HELEN     .                .</em> </p><br><p>    ,          .   ,        ,    ,        ,       . </p><br><p> <strong></strong> <br>                 .              .  5          .    ,    ,      [8, 2] (           10 × 400 .) </p><br><p><img src="https://habrastorage.org/webt/rt/sa/n3/rtsan3fkhl6houggpnk8zyiwqie.png"></p><br><p> <em> 5.             .</em> </p><br><p> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trainingsdaten</font></font></strong> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Um die Wirksamkeit unserer Methode in Bezug auf die Anzahl der Trainingsbilder zu testen, haben wir verschiedene Modelle aus verschiedenen Teilmengen von Trainingsdaten trainiert. </font><font style="vertical-align: inherit;">Tabelle 6 fasst die Endergebnisse zusammen, und Abbildung 5 zeigt eine grafische Darstellung der Fehler auf jeder Ebene der Kaskade. </font><font style="vertical-align: inherit;">Die Verwendung vieler Ebenen von Regressoren ist am nützlichsten, wenn wir eine große Anzahl von Trainingsbeispielen haben.</font></font></p><br><p> Wir wiederholten dieselben Experimente mit einer festen Gesamtzahl erweiterter Beispiele, änderten jedoch die Kombination der Anfangsformen, die zur Erstellung des Trainingsbeispiels verwendet wurden, aus einem markierten Beispiel des Gesichts und einer Reihe kommentierter Bilder, die zur Untersuchung der Kaskade verwendet wurden (Tabelle 7). </p><br><p><img src="https://habrastorage.org/webt/8p/-8/bb/8p-8bbob2qvordp1hhebxruts38.png"></p><br><p>  <em>Tabelle 6. Die endgültige Fehlerrate für die Anzahl der Trainingsbeispiele.</em>  <em>Bei der Erstellung von Trainingsdaten für das Studium kaskadierender Regressoren wurden aus jedem markierten Gesichtsbild 20 Trainingsbeispiele generiert, wobei 20 verschiedene markierte Gesichter als erste Annahme über die Gesichtsform verwendet wurden.</em> </p><br><p><img src="https://habrastorage.org/webt/0o/ft/7s/0oft7ss-mbxhjnln3wje3hqzxau.png"></p><br><p>  <em>Abbildung 5. Der durchschnittliche Fehler auf jeder Ebene der Kaskade wird in Abhängigkeit von der Anzahl der verwendeten Trainingsbeispiele dargestellt.</em>  <em>Die Verwendung vieler Ebenen von Regressoren ist am nützlichsten, wenn die Anzahl der Trainingsbeispiele groß ist.</em> </p><br><p><img src="https://habrastorage.org/webt/am/mj/aq/ammjaqyvpgnzjynmk0ychb7lnw8.png"></p><br><p>  <em>Tabelle 7. Hier ist die effektive Anzahl von Trainingsbeispielen festgelegt, wir verwenden jedoch verschiedene Kombinationen aus der Anzahl von Trainingsbildern und der Anzahl von Anfangsformen, die für jedes markierte Gesichtsbild verwendet werden.</em> </p><br><p>  Durch das Erhöhen der Trainingsdaten mithilfe einer Vielzahl von Anfangsformularen wird der Datensatz in Bezug auf die Form erweitert.  Unsere Ergebnisse zeigen, dass diese Art der Ergänzung das Fehlen kommentierter Trainingsbilder nicht vollständig kompensiert.  Obwohl die Verbesserungsrate, die durch Erhöhen der Anzahl von Trainingsbildern erhalten wird, nach den ersten paar hundert Bildern schnell abnimmt. </p><br><p>  <strong>Teilanmerkungen</strong> <br>  Tabelle 8 zeigt die Ergebnisse der Verwendung von teilweise kommentierten Daten.  200 Fallstudien sind vollständig und der Rest nur teilweise kommentiert. </p><br><p><img src="https://habrastorage.org/webt/iu/j9/7q/iuj97qa3-awn35lf8z3yibbuzhw.png"></p><br><p>  <em>Tabelle 8. Ergebnisse unter Verwendung teilweise beschrifteter Daten.</em>  <em>200 Beispiele sind immer vollständig kommentiert.</em>  <em>Die Werte in Klammern geben den Prozentsatz der beobachteten Orientierungspunkte an.</em> </p><br><p>  Die Ergebnisse zeigen, dass wir mit teilweise gekennzeichneten Daten eine signifikante Verbesserung erzielen können.  Die angezeigte Verbesserung ist jedoch möglicherweise nicht gesättigt, da wir wissen, dass die Basisgröße der Formparameter viel geringer ist als die Größe der Orientierungspunkte (194 × 2).  Folglich besteht das Potenzial für eine signifikantere Verbesserung bei Teilmarkierungen, wenn Sie die Korrelation zwischen der Position der Landmarken explizit verwenden.  Bitte beachten Sie, dass das in diesem Artikel beschriebene Verfahren zur Erhöhung des Gradienten keine Korrelation zwischen Orientierungspunkten verwendet.  Dieses Problem kann in zukünftigen Arbeiten gelöst werden. </p><br><h1 id="4-vyvod">  4. Fazit </h1><br><p>  Wir haben beschrieben, wie ein Ensemble von Regressionsbäumen verwendet werden kann, um die Position von Gesichtsmarkierungen aus einer gestreuten Teilmenge von Intensitätswerten, die aus dem Eingabebild extrahiert wurden, zu regressieren.  Die dargestellte Struktur reduziert Fehler schneller als die vorherige Arbeit und kann auch teilweise oder undefinierte Markierungen verarbeiten.  Während die Hauptkomponenten unseres Algorithmus verschiedene Zielmessungen als unabhängige Variablen betrachten, wird die natürliche Fortsetzung dieser Arbeit die Verwendung der Korrelation von Formularparametern für ein effektiveres Training und eine bessere Verwendung von Teilbeschriftungen sein. </p><br><p><img src="https://habrastorage.org/webt/am/cu/xs/amcuxsbdkp6du3rohxpnoey0r2q.png"></p><br><p>  <em>Abbildung 6. Endergebnisse in der HELEN-Datenbank.</em> </p><br><p>  <strong>Danksagung</strong> <br>  Diese Arbeit wurde von der schwedischen Stiftung für strategische Forschung im Rahmen des VINST-Projekts finanziert. </p><br><h1 id="ispolzovannaya-literatura">  Gebrauchte Literatur </h1><br><p>  [1] PN Belhumeur, DW Jacobs, DJ Kriegman und N. Kumar.  Lokalisierung von Gesichtsteilen anhand eines Konsenses von Exemplaren.  In CVPR, Seiten 545–552, 2011. 1, 5 <br>  [2] X. Cao, Y. Wei, F. Wen und J. Sun.  Gesichtsausrichtung durch explizite Formregression.  In CVPR, Seiten 2887–2894, 2012. 1, 2, 3, 4, 5, 6 <br>  [3] TF Cootes, M. Ionita, C. Lindner und P. Sauer.  Robuste und genaue Anpassung des Formmodells durch zufällige Waldregressionsabstimmung.  In ECCV, 2012.1 <br>  [4] TF Cootes, CJ Taylor, DH Cooper und J. Graham.  Aktive Formmodelle - ihre Ausbildung und Anwendung.  Computer Vision and Image Understanding, 61 (1): 38–59, 1995.1, 2 <br>  [5] D. Cristinacce und TF Cootes.  Modelle für aktive Regressionsformen.  In BMVC, Seiten 79.1–79.10, 2007.1 <br>  [6] M. Dantone, J. Gall, G. Fanelli und LV Gool.  Erkennung von Gesichtsmerkmalen in Echtzeit mithilfe von bedingten Regressionswäldern.  In CVPR, 2012.1 <br>  [7] L. Ding und AM Mart´ınez.  Präzise detaillierte Erkennung von Gesichtern und Gesichtszügen.  In CVPR, 2008.1 <br>  [8] P. Dollar, P. Welinder und P. Perona.  Kaskadierte Posenregression.  In CVPR, Seiten 1078–1085, 2010. 1, 2, 6 <br>  [9] GJ Edwards, TF Cootes und CJ Taylor.  Fortschritte bei aktiven Erscheinungsmodellen.  In ICCV, Seiten 137–142, 1999. 1, 2 <br>  [10] T. Hastie, R. Tibshirani und JH Friedman.  Die Elemente des statistischen Lernens: Data Mining, Inferenz und Vorhersage.  New York: Springer-Verlag, 2001.2.3 <br>  [11] V. Kazemi und J. Sullivan.  Gesichtsausrichtung mit teilbasierter Modellierung.  In BMVC, Seiten 27.1–27.10, 2011.2 <br>  [12] V. Le, J. Brandt, Z. Lin, LD Bourdev und TS Huang.  Interaktive Lokalisierung von Gesichtsmerkmalen.  In [13] L. Liang, R. Xiao, F. Wen und J. Sun.  Gesichtsausrichtung über komponentenbasierte diskriminative Suche.  In ECCV, Seiten 72–85, 2008. 1ECCV, Seiten 679–692, 2012.5 <br>  [14] S. Milborrow und F. Nicolls.  Lokalisieren von Gesichtsmerkmalen mit einem erweiterten aktiven Formmodell.  In ECCV, Seiten 504–513, 2008.5 <br>  [15] J. Saragih, S. Lucey und J. Cohn.  Verformbare Modellanpassung durch regulierte Mittelwertverschiebungen.  Internation Journal of Computer Vision, 91: 200–215, 2010.1 <br>  [16] BM Smith und L. Zhang.  Ausrichtung der Gelenkfläche mit nichtparametrischen Formmodellen.  In ECCV, Seiten 43–56, 2012.1 <br>  [17] PA Viola und MJ Jones.  Robuste Gesichtserkennung in Echtzeit.  In ICCV, Seite 747, 2001.5 <br>  [18] X. Zhao, X. Chai und S. Shan.  Gelenkgesichtsausrichtung: Retten Sie schlechte Ausrichtungen durch gute durch regelmäßige Neuanpassung.  In ECCV, 2012.1 <br>  [19] X. Zhu und D. Ramanan.  Gesichtserkennung, Posenschätzung und Lokalisierung von Orientierungspunkten in freier Wildbahn.  In CVPR, Seiten 2879–2886, 2012.1 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460541/">https://habr.com/ru/post/de460541/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460531/index.html">Neugierige Perversionen aus der IT-Welt - 5</a></li>
<li><a href="../de460533/index.html">Sie haben die Idee eines IT-Produkts, was kommt als nächstes?</a></li>
<li><a href="../de460535/index.html">Erstellen eines minimalen Docker-Containers für Go-Apps</a></li>
<li><a href="../de460537/index.html">ZuriHac: Funktionale Programmierung üben</a></li>
<li><a href="../de460539/index.html">Fehlerbehandlung in Vue</a></li>
<li><a href="../de460543/index.html">Neue Zertifizierungen für Entwickler von Cisco. Branchenzertifizierungsübersicht</a></li>
<li><a href="../de460547/index.html">Antiquitäten: Psion 5MX und Leben im Ruhestand</a></li>
<li><a href="../de460551/index.html">Portugal Die besten Strände und tausend Startups pro Jahr</a></li>
<li><a href="../de460555/index.html">Bericht vom PyDaCon-Treffen bei der Mail.ru Group am 22. Juni</a></li>
<li><a href="../de460557/index.html">Eine Auswahl von Arbeitsbeispielen zur Datenverarbeitung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
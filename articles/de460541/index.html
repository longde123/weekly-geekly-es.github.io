<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëäüèø üêâ üñïüèª Suchen Sie in einer Millisekunde nach Gesichtskonturen mit einem Ensemble von Regressionsb√§umen üë≤ üóÑÔ∏è üçø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die √úbersetzung des Artikels wurde f√ºr Studenten des Kurses "Mathematik f√ºr Datenwissenschaften" vorbereitet. 

 Anmerkung 


 Dieser Artikel beschrei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Suchen Sie in einer Millisekunde nach Gesichtskonturen mit einem Ensemble von Regressionsb√§umen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/460541/"><p><img src="https://habrastorage.org/webt/eb/rn/3a/ebrn3a_ugfcxc9tuhkdmwgnrut8.png"></p><br><p>  <em>Die √úbersetzung des Artikels wurde f√ºr Studenten des Kurses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"Mathematik f√ºr Datenwissenschaften"</a> vorbereitet.</em> </p><br><hr><br><h1 id="annotaciya">  Anmerkung </h1><br><p>  <em>Dieser Artikel beschreibt die Aufgabe, Gesichtskonturen f√ºr ein einzelnes Bild zu finden.</em>  <em>Wir zeigen, wie das Ensemble von Regressionsb√§umen verwendet werden kann, um die Position von Gesichtskonturen direkt aus einer verstreuten Teilmenge von Pixelintensit√§ten vorherzusagen und mit hochqualitativen Vorhersagen in Echtzeit eine Superleistung zu erzielen.</em>  <em>Wir pr√§sentieren eine allgemeine Struktur, die auf Gradientenverst√§rkung basiert, um ein Ensemble von Regressionsb√§umen zu untersuchen, das die Summe der quadratischen Verluste optimiert und nat√ºrlich fehlende oder teilweise markierte Daten verarbeitet.</em>  <em>Wir werden zeigen, wie die Verwendung geeigneter Verteilungen, die die Struktur von Bilddaten ber√ºcksichtigen, bei der effizienten Auswahl von Konturen hilft.</em>  <em>Verschiedene Regularisierungsstrategien und ihre Bedeutung im Kampf gegen Umschulungen werden ebenfalls untersucht.</em>  <em>Dar√ºber hinaus analysieren wir die Auswirkung der Menge an Trainingsdaten auf die Genauigkeit von Vorhersagen und untersuchen die Auswirkung der Datenerh√∂hung anhand synthetisierter Daten.</em> <a name="habracut"></a></p><br><h1 id="1-vvedenie">  1. Einleitung </h1><br><p>  In diesem Artikel stellen wir einen neuen Algorithmus vor, der in Millisekunden nach Gesichtskonturen sucht und eine Genauigkeit erzielt, die modernen Methoden f√ºr Standarddatens√§tze √ºberlegen oder mit diesen vergleichbar ist.  Die Erh√∂hung der Geschwindigkeit im Vergleich zu den vorherigen Methoden ist eine Folge der Identifizierung der Hauptkomponenten der vorherigen Algorithmen f√ºr die Suche nach Gesichtskonturen und ihrer anschlie√üenden Aufnahme in eine optimierte Form in die Kaskade von Regressionsmodellen mit hohem Durchsatz, die mithilfe der Gradientenverst√§rkung konfiguriert wurden. </p><br><p>  Wir zeigen, wie bereits zuvor [8, 2], dass die Suche nach Gesichtskonturen mit einer Kaskade von Regressionsmodellen durchgef√ºhrt werden kann.  In unserem Fall sagt jedes Regressionsmodell in der Kaskade die Form des Gesichts basierend auf der anf√§nglichen Vorhersage und der Intensit√§t des sp√§rlichen Satzes von Pixeln, die relativ zu dieser anf√§nglichen Vorhersage indiziert sind, effektiv voraus.  Unsere Arbeit basiert auf einer Vielzahl von Studien, die im letzten Jahrzehnt durchgef√ºhrt wurden und zu erheblichen Fortschritten bei der Suche nach Gesichtskonturen gef√ºhrt haben [9, 4, 13, 7, 15, 1, 16, 18, 3, 6, 19].  Insbesondere haben wir in unsere abgestimmten Regressionsmodelle zwei Schl√ºsselelemente aufgenommen, die in mehreren der folgenden erfolgreichen Algorithmen vorhanden sind, und jetzt werden diese Elemente detailliert beschrieben. </p><br><p><img src="https://habrastorage.org/webt/xe/fn/ux/xefnuxzvuozcmpu5xjzvwwm3kq4.png"></p><br><p>  <em>Abbildung 1. Ausgew√§hlte Ergebnisse im HELEN-Datensatz.</em>  <em>Um 194 wichtige Punkte (Landmarken) auf dem Gesicht in einem Bild in einer Millisekunde zu erkennen, wird ein Ensemble randomisierter Regressionsb√§ume verwendet.</em> </p><br><p>  Die erste dreht sich um die Indexierung der Pixelintensit√§t relativ zur aktuellen Vorhersage der Gesichtsform.  Die unterscheidbaren Merkmale in der Vektordarstellung des Gesichtsbildes k√∂nnen aufgrund der Verformung der Form und aufgrund von St√∂rfaktoren wie √Ñnderungen der Lichtverh√§ltnisse stark variieren.  Dies macht es schwierig, die Form unter Verwendung dieser Funktionen genau vorherzusagen.  Das Dilemma besteht darin, dass wir zuverl√§ssige Zeichen ben√∂tigen, um die Form genau vorherzusagen, und andererseits ben√∂tigen wir eine genaue Vorhersage der Form, um zuverl√§ssige Zeichen zu extrahieren.  In der vorherigen Arbeit [4, 9, 5, 8] sowie in dieser Arbeit wird ein iterativer Ansatz (Kaskade) verwendet, um dieses Problem zu l√∂sen.  Anstatt die Formparameter basierend auf den im globalen Bildkoordinatensystem extrahierten Merkmalen zu regressieren, wird das Bild basierend auf der aktuellen Formvorhersage in ein normalisiertes Koordinatensystem konvertiert, und dann werden Zeichen extrahiert, um den Aktualisierungsvektor f√ºr die Formparameter vorherzusagen.  Dieser Vorgang wird normalerweise mehrmals bis zur Konvergenz wiederholt. </p><br><p>  Im zweiten Teil wird untersucht, wie mit der Komplexit√§t des Erkl√§rungs- / Vorhersageproblems umgegangen werden soll.  W√§hrend des Tests sollte der Kontursuchalgorithmus die Form des Gesichts vorhersagen - ein hochdimensionaler Vektor, der am besten mit den Bilddaten und unserem Formmodell √ºbereinstimmt.  Das Problem ist bei vielen lokalen Optima nicht konvex.  Erfolgreiche Algorithmen [4, 9] l√∂sen dieses Problem unter der Annahme, dass die vorhergesagte Form in einem linearen Unterraum liegen sollte, der beispielsweise durch Auffinden der Hauptkomponenten der Trainingsformen erkannt werden kann.  Diese Annahme reduziert die Anzahl potenzieller Formen, die bei der Erkl√§rung ber√ºcksichtigt werden, erheblich und kann dazu beitragen, lokale Optima zu vermeiden. </p><br><p>  Eine k√ºrzlich erschienene Arbeit [8, 11, 2] nutzt die Tatsache aus, dass eine bestimmte Klasse von Regressoren garantiert Vorhersagen erstellt, die in dem durch Lernformen definierten linearen Unterraum liegen, und dass keine zus√§tzlichen Einschr√§nkungen erforderlich sind.  Es ist wichtig, dass unsere Regressionsmodelle diese beiden Elemente aufweisen. <br>  Diese beiden Faktoren h√§ngen mit unserem effektiven Training im Regressionsmodell zusammen.  Wir optimieren die entsprechende Verlustfunktion und f√ºhren die Merkmalsauswahl anhand von Daten durch.  Insbesondere trainieren wir jeden Regressor mit Gradientenverst√§rkung [10] unter Verwendung der quadratischen Verlustfunktion, der gleichen Verlustfunktion, die wir w√§hrend des Tests minimieren m√∂chten.  Der Satz von sp√§rlichen Pixeln, der als Eingabe in den Regressor verwendet wird, wird unter Verwendung einer Kombination des Gradientenverst√§rkungsalgorithmus und der a priori-Wahrscheinlichkeit der Abst√§nde zwischen Paaren von Eingabepixeln ausgew√§hlt.  Eine A-priori-Verteilung erm√∂glicht es dem Boosting-Algorithmus, eine gro√üe Anzahl relevanter Merkmale effizient zu untersuchen.  Das Ergebnis ist eine Kaskade von Regressoren, die Gesichtsmarkierungen lokalisieren k√∂nnen, wenn sie von vorne initialisiert werden. </p><br><p>  Die Hauptbeitr√§ge dieses Artikels sind: </p><br><ol><li>  Eine neue Methode zum Finden von Gesichtskonturen, basierend auf einem Ensemble von Regressionsb√§umen (Entscheidungsb√§umen), die die Auswahl invarianter Merkmale des Formulars durchf√ºhrt und gleichzeitig die gleiche Verlustfunktion w√§hrend des Trainings minimiert, die wir w√§hrend des Tests minimieren m√∂chten. </li><li>  Wir pr√§sentieren eine nat√ºrliche Erweiterung unserer Methode, die fehlende oder undefinierte Labels verarbeitet. </li><li>  Es werden quantitative und qualitative Ergebnisse pr√§sentiert, die best√§tigen, dass unsere Methode qualitativ hochwertige Prognosen liefert und viel effektiver ist als die beste vorherige Methode (Abbildung 1). </li><li>  Der Einfluss der Menge an Trainingsdaten, der Verwendung von teilweise gekennzeichneten Daten und verallgemeinerten Daten auf die Qualit√§t von Prognosen wird analysiert. </li></ol><br><h1 id="2-metod">  2. Methode </h1><br><p>  In diesem Artikel wird ein Algorithmus zur genauen Beurteilung der Position von Gesichtspunkten (Schl√ºsselpunkten) im Hinblick auf die Recheneffizienz vorgestellt.  Wie in fr√ºheren Arbeiten [8, 2] wird in unserer Methode die Kaskade der Regressoren verwendet.  Im Rest dieses Abschnitts beschreiben wir die Details der Form der einzelnen Komponenten der Kaskade und wie wir das Training durchf√ºhren. </p><br><h4 id="21-kaskad-regressorov">  2.1.  Regressionskaskade </h4><br><p>  Zuerst f√ºhren wir eine Notation ein.  Lass <img src="https://habrastorage.org/getpro/habr/post_images/96b/8a8/cd3/96b8a8cd39c5f39cf67191c499d17a36.svg">  , y-Koordinaten des i-ten Orientierungspunkts des Gesichts im Bild I. Dann der Vektor <img src="https://habrastorage.org/getpro/habr/post_images/bd9/f10/315/bd9f10315460922e284cfe03581f1e91.svg">  bezeichnet die Koordinaten aller p Fl√§chen in I. Oft nennen wir in diesem Artikel den Vektor S eine Form.  Wir benutzen <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  um unsere aktuelle Bewertung S anzuzeigen. Jeder Regressor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  (¬∑, ¬∑) In der Kaskade sagt der Aktualisierungsvektor aus dem Bild und voraus <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  Dies wird zur aktuellen Formularbewertung hinzugef√ºgt <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  So verbessern Sie die Bewertung: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/813/e90/80c/813e9080c1daa94987bfd323fcf05d75.svg">  ) <em>(1)</em> </p><br><p>  Der entscheidende Punkt der Kaskade ist, dass der Regressor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  Die Prognosen basieren auf Attributen wie Pixelintensit√§ten, die von I berechnet und relativ zur aktuellen Formsch√§tzung indiziert werden <img src="https://habrastorage.org/getpro/habr/post_images/765/839/4d5/7658394d527b5ec58206aa0bde88e139.svg">  .  Dies f√ºhrt eine Art geometrische Invarianz in den Prozess ein, und w√§hrend Sie die Kaskade durchlaufen, k√∂nnen Sie sicherer sein, dass die genaue semantische Position auf dem Gesicht indiziert ist.  Wir werden sp√§ter beschreiben, wie diese Indizierung durchgef√ºhrt wird. </p><br><p>  Bitte beachten Sie, dass der vom Ensemble erweiterte Ausgabebereich bei der anf√§nglichen Sch√§tzung garantiert im linearen Unterraum der Trainingsdaten liegt <img src="https://habrastorage.org/getpro/habr/post_images/f0d/6ae/457/f0d6ae4573955eb6abc901db0a68bc4a.svg">  geh√∂rt zu diesem Raum.  Daher m√ºssen wir keine zus√§tzlichen Einschr√§nkungen f√ºr die Vorhersagen einf√ºhren, was unsere Methode erheblich vereinfacht.  Die Anfangsform kann einfach als mittlere Form von Trainingsdaten ausgew√§hlt, zentriert und entsprechend der Ausgabe des Begrenzungsrahmens des allgemeinen Gesichtsdetektors skaliert werden. </p><br><p>  Alle erziehen <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  Wir verwenden den Gradientenverst√§rkungsalgorithmus f√ºr B√§ume mit der Summe der quadratischen Verluste, wie in [10] beschrieben.  Jetzt werden wir detaillierte Details dieses Prozesses geben. </p><br><h4 id="22-obuchenie-kazhdogo-regressora-v-kaskade">  2.2.  Trainiere jeden Regressor in einer Kaskade </h4><br><p>  Angenommen, wir haben Trainingsdaten <img src="https://habrastorage.org/getpro/habr/post_images/a81/786/c9b/a81786c9b9d6dc27492f55b19afb5055.svg">  wo alle <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  ist ein Gesichtsbild und <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  sein Formvektor.  Um die erste Regressionsfunktion herauszufinden <img src="https://habrastorage.org/getpro/habr/post_images/0ac/302/657/0ac302657b1d8e45efa7f7b9b2557268.svg">  In der Kaskade erstellen wir aus unseren Trainingsdaten Tripletts des Gesichtsbildes, der anf√§nglichen Formvorhersage und des Zielaktualisierungsschritts, d.h. <img src="https://habrastorage.org/getpro/habr/post_images/6a1/450/b9e/6a1450b9ea40a582ec2794d9df7afd31.svg">  ) wo </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f29/a62/581/f29a625813ba6c6cd00aea30a8cfe019.svg">  <em>(2)</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/6c3/a0d/468/6c3a0d468f609ada0672c0f473c589ec.svg">  <em>(3)</em> und </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/691/50d/5cf/69150d5cfe48125a51002916c28453e8.svg">  <em>(4)</em> </p><br><p>  f√ºr i = 1, ..., N. </p><br><p>  Wir setzen die Gesamtzahl dieser Tripletts auf N = nR, wobei R die Anzahl der auf Bild Ii verwendeten Initialisierungen ist.  Jede anf√§ngliche Formvorhersage f√ºr das Bild wird gleichm√§√üig aus ausgew√§hlt <img src="https://habrastorage.org/getpro/habr/post_images/d1c/fb5/092/d1cfb5092f0e598893288582f2114b37.svg">  ohne Ersatz. </p><br><p>  Anhand dieser Daten trainieren wir die Regressionsfunktion <img src="https://habrastorage.org/getpro/habr/post_images/bcb/830/694/bcb83069438bb8a2d3e1e51f76a276f4.svg">  (siehe Algorithmus 1) Verwenden der Gradientenverst√§rkung von B√§umen mit der Summe der quadratischen Verluste.  Der Trainings-Triplett-Satz wird dann aktualisiert, um Trainingsdaten bereitzustellen. <img src="https://habrastorage.org/getpro/habr/post_images/f56/e5c/4a8/f56e5c4a803f2c95ebe20dae215895cf.svg">  % 20) f√ºr den n√§chsten Regressor <img src="https://habrastorage.org/getpro/habr/post_images/dc5/512/a85/dc5512a85c881619a2c05faa3c2a2806.svg">  in der Kaskade durch Setzen (mit t = 0). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/146/29d/692/14629d6922ca89d70fed70bbeb3287bd.svg">  % 20) <em>(5)</em> </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/17d/8a5/44a/17d8a544a843aa72dc68d79ab9c2236d.svg">  <em>(6)</em> </p><br><p>  Dieser Vorgang wird wiederholt, bis eine Kaskade von T-Regressoren trainiert ist. <img src="https://habrastorage.org/getpro/habr/post_images/ee6/6a5/503/ee66a5503085c7bbaa7a616585c4ae2e.svg">  die in Kombination ein ausreichendes Ma√ü an Genauigkeit bieten. </p><br><p>  Wie angegeben, jeder Regressor <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">  lernt mit dem Gradientenbaum-Boosting-Algorithmus.  Es ist zu beachten, dass die quadratische Verlustfunktion verwendet wird und die in der inneren Schleife berechneten Residuen dem Gradienten dieser Verlustfunktion entsprechen, der in jeder Trainingsprobe gesch√§tzt wird.  Die Formulierung des Algorithmus enth√§lt den Lernratenparameter 0 &lt;ŒΩ ‚â§ 1, auch als Regularisierungskoeffizient bekannt.  Das Setzen von ŒΩ &lt;1 hilft bei der Bek√§mpfung der Rekonfiguration und f√ºhrt normalerweise zu Regressoren, die viel besser verallgemeinern als diejenigen, die mit ŒΩ = 1 trainiert wurden [10]. </p><br><hr><br><p>  <strong>Lernalgorithmus 1</strong> <strong><img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg"></strong>  <strong>in Kaskade</strong> </p><br><p>  Wir haben Trainingsdaten <img src="https://habrastorage.org/getpro/habr/post_images/2d4/805/43a/2d480543a349544ead268291984b1e6a.svg">  und Lernrate (Regularisierungskoeffizient) 0 &lt;ŒΩ &lt;1 </p><br><ol><li>  Initialisieren <br><img src="https://habrastorage.org/getpro/habr/post_images/e54/d75/bae/e54d75bae7a82091f8d5c1f04a92cc22.svg"></li><li>  f√ºr k = 1, ..., K: <br>  a) wir setzen auf i = 1, ..., <br><img src="https://habrastorage.org/getpro/habr/post_images/759/573/b03/759573b032b3bb95986dfe5d42d8e5d8.svg"><br>  b) Wir passen den Regressionsbaum an das Ziel an <img src="https://habrastorage.org/getpro/habr/post_images/683/2f3/54e/6832f354e8f4ecad8283cc1be6a6899a.svg">  mit schwacher Regressionsfunktion <img src="https://habrastorage.org/getpro/habr/post_images/425/db2/33f/425db233f09794bfe60e62a49da89a98.svg">  . <br>  c) Aktualisieren <img src="https://habrastorage.org/getpro/habr/post_images/376/5d0/ac3/3765d0ac3de75d838ad520821c141c21.svg"></li><li>  Fazit <br><img src="https://habrastorage.org/getpro/habr/post_images/7c0/9c4/2b9/7c09c42b9cc35b3225f89435a9d4ce22.svg"></li></ol><br><hr><br><h4 id="23-drevovidnyy-regressor">  2.3.  Baumregressor </h4><br><p>  Im Zentrum jeder RT-Regressionsfunktion stehen baumartige Regressoren, die f√ºr Restziele w√§hrend des Gradientenverst√§rkungsalgorithmus geeignet sind.  Jetzt werden wir uns die wichtigsten Implementierungsdetails f√ºr das Training jedes Regressionsbaums ansehen. </p><br><h4 id="231-invariantnye-split-testy-formy">  2.3.1 Invariante Split-Form-Tests </h4><br><p>  An jedem Trennknoten im Regressionsbaum treffen wir eine Entscheidung basierend auf dem Schwellenwert der Differenz zwischen den Intensit√§ten von zwei Pixeln.  Die im Test verwendeten Pixel befinden sich an den Positionen u und v, wenn sie im Koordinatensystem der mittleren Form definiert sind.  F√ºr ein Bild eines Gesichts mit einer beliebigen Form m√∂chten wir Punkte indizieren, die relativ zu ihrer Form dieselbe Position wie u und v haben, f√ºr die durchschnittliche Form.  Zu diesem Zweck kann das Bild vor dem Extrahieren der Elemente basierend auf der aktuellen Formsch√§tzung in die mittlere Form deformiert werden.  Da wir nur eine sehr sp√§rliche Darstellung des Bildes verwenden, ist es viel effizienter, die Anordnung der Punkte zu verformen als das gesamte Bild.  Dar√ºber hinaus kann eine grobe Ann√§herung an die Verformung vorgenommen werden, indem zus√§tzlich zu den in [2] vorgeschlagenen globalen Verschiebungen nur die globale √Ñhnlichkeitstransformation verwendet wird. </p><br><p>  Die genauen Details sind wie folgt.  Lass <img src="https://habrastorage.org/getpro/habr/post_images/482/2f7/60f/4822f760fdf061f414f323d30d0c14cd.svg">  Ist der Index des Orientierungspunkts auf dem Gesicht in der mittleren Form am n√§chsten an u und definiert seine Verschiebung von u als <img src="https://habrastorage.org/getpro/habr/post_images/0fa/bbb/f81/0fabbbf8125f80b9f31e3b5ce093bc3c.svg">  . </p><br><p>  Dann f√ºr die im Bild definierte Form Si <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  Position in <img src="https://habrastorage.org/getpro/habr/post_images/e19/7a8/ea5/e197a8ea5f9ce816e060678de54e7ba9.svg">  , das u im Bild einer mittleren Form qualitativ √§hnlich ist, ist definiert als <br><img src="https://habrastorage.org/getpro/habr/post_images/e2d/e8d/0d4/e2de8d0d461e2ef6e76642d39a803b27.svg">  <em>(7)</em> </p><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  und <img src="https://habrastorage.org/getpro/habr/post_images/8f6/b4a/913/8f6b4a913e518f22483a28148144b54e.svg">  - Skalierungs- und Rotationsmatrix der √Ñhnlichkeitstransformation, die transformiert <img src="https://habrastorage.org/getpro/habr/post_images/7a3/62f/59e/7a362f59eba33ebc236fefd712440e76.svg">  in <img src="https://habrastorage.org/getpro/habr/post_images/919/800/718/919800718f235e7487c36b01db6739e1.svg">  mittlere Form. </p><br><p>  Skalierung und Rotation minimieren </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/cf0/581/e89/cf0581e890e027fcaf3327e3be6f194c.svg">  <em>(8)</em> </p><br><p>  die Summe der Quadrate zwischen den Orientierungspunkten der mittleren Form, <img src="https://habrastorage.org/getpro/habr/post_images/c73/942/e7f/c73942e7f47a9adb6091e024085fc1bb.svg">  und Point Warp. <img src="https://habrastorage.org/getpro/habr/post_images/b2d/a25/52e/b2da2552e44457f6bcbf5d1aab251267.svg">  √§hnlich definiert. </p><br><p>  Formal ist jede Division eine L√∂sung, die 3 Parameter Œ∏ = (œÑ, u, v) enth√§lt und auf jedes Trainings- und Testbeispiel als angewendet wird </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/bfe/6ee/9c7/bfe6ee9c7e9da21fb2b81caca3d8abad.svg">  <em>(9)</em> </p><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/ff8/c77/429/ff8c77429402ff15260663452a693e8d.svg">  und <img src="https://habrastorage.org/getpro/habr/post_images/b2d/a25/52e/b2da2552e44457f6bcbf5d1aab251267.svg">  werden unter Verwendung der Skala und der Rotationsmatrix bestimmt, die sich am besten verformen <img src="https://habrastorage.org/getpro/habr/post_images/5ac/ad7/803/5acad7803f7a79cc10fa8c714205eeab.svg">  in <img src="https://habrastorage.org/getpro/habr/post_images/919/800/718/919800718f235e7487c36b01db6739e1.svg">  gem√§√ü Gleichung (7).  In der Praxis werden Aufgaben und lokale Verschiebungen in der Trainingsphase festgelegt.  Die Berechnung der √Ñhnlichkeitstransformation w√§hrend des Testens des teuersten Teils dieses Prozesses wird auf jeder Ebene der Kaskade nur einmal durchgef√ºhrt. </p><br><h4 id="232-vybor-uzlovyh-razbieniy">  2.3.2 Auswahl der Knotenpartitionen </h4><br><p>  F√ºr jeden Regressionsbaum approximieren wir die Grundfunktion durch eine st√ºckweise lineare Funktion, wobei ein konstanter Vektor f√ºr jeden endlichen Knoten geeignet ist.  Um den Regressionsbaum zu trainieren, erzeugen wir zuf√§llig einen Satz geeigneter Partitionen, dh Œ∏, in jedem Knoten.  Dann w√§hlen wir eifrig Œ∏ * aus diesen Kandidaten aus, was die Summe des quadratischen Fehlers minimiert.  Wenn Q ein Satz von Indizes von Trainingsbeispielen in einem Knoten ist, entspricht dies einer Minimierung </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8b2/8f1/e02/8b28f1e02ab50c802525c5ded6aaeeaf.svg">  <em>(10)</em> </p><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/fd5/fa1/737/fd5fa1737973ecd7a303b2862a32f8ec.svg">  - Indizes von Beispielen, die aufgrund der Entscheidung Œ∏ an den linken Knoten gesendet werden, <img src="https://habrastorage.org/getpro/habr/post_images/ab1/ee0/4fb/ab1ee04fb1210c9352cc942823f6dcd1.svg">  Ist der Vektor aller Residuen, die f√ºr das Bild <em>i</em> im Gradientenverst√§rkungsalgorithmus berechnet wurden, und </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c7f/e61/cc7/c7fe61cc7d441d07443317d12fc860c4.svg">  f√ºr <img src="https://habrastorage.org/getpro/habr/post_images/e17/6e7/ece/e176e7ece99e70aeee6c4ffe2949bb2f.svg">  <em>(11)</em> </p><br><p>  Die optimale Partition kann sehr effizient gefunden werden, denn wenn wir Gleichung (10) transformieren und von Œ∏ unabh√§ngige Faktoren weglassen, k√∂nnen wir das sehen </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/517/57c/a5c/51757ca5c227156f25de32c995a6c1eb.svg"></p><br><p>  Hier m√ºssen wir nur berechnen <img src="https://habrastorage.org/getpro/habr/post_images/88d/4eb/4bb/88d4eb4bb69acbcbbbf4ad0e10098a80.svg">  bei der Auswertung verschiedener Œ∏s, da <img src="https://habrastorage.org/getpro/habr/post_images/ba2/1c8/eeb/ba21c8eeb00ef767cf6f5bd5297f986e.svg">  kann aus den durchschnittlichen Zielen im Elternknoten ¬µ und berechnet werden <img src="https://habrastorage.org/getpro/habr/post_images/88d/4eb/4bb/88d4eb4bb69acbcbbbf4ad0e10098a80.svg">  wie folgt: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b0a/e76/10a/b0ae7610afe1aa13d10de797871193c6.svg"></p><br><h4 id="233-vybor-priznakov">  2.3.3 Auswahl der Merkmale </h4><br><p>  Die L√∂sung an jedem Knoten basiert auf einem Schwellenwert der Differenz der Intensit√§tswerte in einem Pixelpaar.  Dies ist ein ziemlich einfacher Test, der jedoch aufgrund seiner relativen Unempfindlichkeit gegen√ºber √Ñnderungen der globalen Beleuchtung viel effektiver ist als ein Schwellenwert mit einer einzelnen Intensit√§t.  Leider besteht der Nachteil der Verwendung von Pixeldifferenzen darin, dass die Anzahl potenzieller Trennungskandidaten (Merkmal) in Bezug auf die Anzahl von Pixeln im Durchschnittsbild quadratisch ist.  Dies macht es schwierig, gute Œ∏s zu finden, ohne nach einer sehr gro√üen Anzahl von ihnen zu suchen.  Dieser begrenzende Faktor kann jedoch unter Ber√ºcksichtigung der Struktur der Bilddaten etwas abgeschw√§cht werden. </p><br><p>  Wir f√ºhren die Exponentialverteilung ein </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f30/6b8/6c4/f306b86c47bfa440c1d1c716e3c9d6b8.svg">  <em>(12)</em> </p><br><p>  durch den Abstand zwischen den Pixeln, die bei der Aufteilung verwendet werden, um die Auswahl engerer Pixelpaare zu f√∂rdern. </p><br><p>  Wir haben festgestellt, dass die Verwendung dieser einfachen Verteilung den Vorhersagefehler f√ºr eine Reihe von Gesichtsdatens√§tzen reduziert.  In Abbildung 4 werden die mit und ohne Features ausgew√§hlten Features verglichen, wobei die Gr√∂√üe des Objektpools in beiden F√§llen auf 20 festgelegt ist. </p><br><h1 id="24-obrabotka-propuschennyh-metok">  2.4.  Umgang mit fehlenden Tags </h1><br><p>  Das Problem von Gleichung (10) kann leicht erweitert werden, um den Fall zu behandeln, in dem einige Orientierungspunkte auf einigen Trainingsbildern nicht markiert sind (oder wir haben ein Ma√ü f√ºr die Unsicherheit f√ºr jeden Orientierungspunkt).  Variable eingeben <img src="https://habrastorage.org/getpro/habr/post_images/7e0/805/7ed/7e08057ed464a0c8c2af586f05a009aa.svg">  [0, 1] f√ºr jedes Trainingsbild <em>i</em> und jeden Orientierungspunkt <em>j</em> .  Installation <img src="https://habrastorage.org/getpro/habr/post_images/260/ce8/a6b/260ce8a6b696864e07aaa5de561923e6.svg">  Ein Wert von 0 zeigt an, dass der Orientierungspunkt <em>j</em> im <em>i-</em> ten Bild nicht markiert ist, und eine Einstellung von 1 zeigt an, dass er markiert ist.  Dann kann Gleichung (10) wie folgt dargestellt werden </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/7e5/183/d89/7e5183d8955912640ff62a62fd8913de.svg"></p><br><p>  wo <img src="https://habrastorage.org/getpro/habr/post_images/07f/821/26e/07f82126e42fc56123ae1a571fcaac7b.svg">  - Diagonalmatrix mit Vektor <img src="https://habrastorage.org/getpro/habr/post_images/a77/988/515/a779885154cabacbcccfb17d823fd818.svg">  auf ihrer Diagonale und </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/7a7/975/451/7a79754517a719b74cff33c43743171f.svg">  f√ºr <img src="https://habrastorage.org/getpro/habr/post_images/e17/6e7/ece/e176e7ece99e70aeee6c4ffe2949bb2f.svg">  <em>(13)</em> </p><br><p>  Der Gradientenverst√§rkungsalgorithmus muss ebenfalls modifiziert werden, um diese Gewichte zu ber√ºcksichtigen.  Dies kann erreicht werden, indem einfach das Ensemble-Modell mit dem gewichteten Durchschnittswert der Ziele initialisiert und die Regressionsb√§ume wie folgt an die gewichteten Residuen in Algorithmus 1 angepasst werden </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/396/468/7a9/3964687a9c8c905316ef8d6b69d73888.svg">  <em>(14)</em> </p><br><h1 id="3-eksperimenty">  3. Experimente </h1><br><p>  <strong>Grundlagen:</strong> Um die Leistung unserer vorgeschlagenen Methode, dem Ensemble von Regressionsb√§umen (ERT), genau zu bewerten, haben wir zwei weitere Grundlagen erstellt.  Der erste basiert auf zuf√§lligen Farnen (zuf√§lligen Farnen) mit einer zuf√§lligen Auswahl von Merkmalen (EF), und der andere ist eine fortgeschrittenere Version dieses Ansatzes mit der Auswahl von Merkmalen basierend auf Korrelation (EF + CB), was unsere neue Implementierung ist [2].  Alle Parameter sind f√ºr alle drei Ans√§tze festgelegt. </p><br><p>  EF nutzt die direkte Implementierung von zuf√§lligen Farnen als schwache Regressoren im Ensemble und ist die schnellste f√ºr das Training.  Wir verwenden dieselbe Regularisierungsmethode wie in [2] f√ºr die Regularisierung von Farnen vorgeschlagen. </p><br><p>  EF + CB verwendet eine korrelationsbasierte Objektauswahlmethode, die Ausgabewerte projiziert. <img src="https://habrastorage.org/getpro/habr/post_images/ab1/ee0/4fb/ab1ee04fb1210c9352cc942823f6dcd1.svg">  's in eine zuf√§llige Richtung w und w√§hlt Zeichenpaare (u, v) aus, f√ºr die <img src="https://habrastorage.org/getpro/habr/post_images/dcf/e8f/3cc/dcfe8f3ccb1ca1095fc35db5b623abc0.svg">           <img src="https://habrastorage.org/getpro/habr/post_images/b63/418/2d8/b634182d884088b10405bc691e479fd8.svg">  . </p><br><p> <strong></strong> <br>    ,        .    rt   T = 10,   <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">   K = 500   <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg">  .   ( ),    <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg"> ,   F = 5.     P = 400    .    ,        P              ,     (9).        S = 20    ,    .        ,   R = 20      . </p><br><p><img src="https://habrastorage.org/webt/7j/we/fs/7jwefsr7puidwxuehw6owexel8k.png"></p><br><p> <em> 2.       ,             Viola &amp; Jones [17].        .</em> </p><br><p> <strong></strong> <br>          O (TKF).          O (NDTKF S),  N ‚Äî   ,  D ‚Äî  .                HELEN [12],           . </p><br><p> <strong> </strong> <br>   ,   ,      HELEN [12], ,   ,      .    2330 ,     194 .      2000    ,    . </p><br><p>           LFPW [1],    1432 .  ,     778    216   ,         ,      . </p><br><p>  <strong>Vergleich</strong> <br>  1         .                  (Active Shape Models) ‚Äî STASM [14]  CompASM [12]. </p><br><p><img src="https://habrastorage.org/webt/89/fk/kc/89fkkczbo119vyy4oo7hhu7cmno.png"></p><br><p> <em> 1.        HELEN.  ‚Äî          .       .      ,        .    ,       .              .</em> </p><br><p>   ,    ,        .   3       ,  ,  ERT     ,   .  ,        EF + CB     .  ,      EF + CB       ,     . </p><br><p>          LFPW [1] ( 2).    EF + CB     ,   [2]. (     ,        .)              ,      ,     . </p><br><p><img src="https://habrastorage.org/webt/ef/uu/nz/efuunznz_ljfv_sr1v1vi5fujoy.png"></p><br><p> <em> 2.        LFPW.       1.</em> </p><br><p> <strong> </strong> <br>  4     (12)       ,   ,      .  Œª               0,1   .            <img src="https://habrastorage.org/getpro/habr/post_images/8a3/da7/d5c/8a3da7d5c0b3aeb3983a52357424a4ba.svg">         .  4          . </p><br><p><img src="https://habrastorage.org/webt/do/pm/v4/dopmv4u-mj6pa5tcaioawlcvegs.png"></p><br><p> <em> 3.           .         ,  , .  (12).</em> </p><br><p> <strong></strong> <br>        ,   .     ,     .    ‚Äî .        ŒΩ      1 (   ŒΩ = 0.1).           .  , <img src="https://habrastorage.org/getpro/habr/post_images/cfb/227/fd2/cfb227fd27d043451a49e2337d85a6bf.svg">   ,    ,    ŒΩ = 1.                   (10   )   . (      .) </p><br><p><img src="https://habrastorage.org/webt/lp/hv/hv/lphvhvclakdn02mzwrfe5rtt28w.png"></p><br><p> <em> 3.       HELEN (a)  LFPW (b). EF ‚Äî    ,  EF + CB ‚Äî      ,   .          (5  10),    [2].  ,      (ERT),     ,     ,             .</em> </p><br><p><img src="https://habrastorage.org/webt/xm/3y/pp/xm3yppxdejbgcglidfb-ecofaza.png"></p><br><p> <em> 4.   ,    .       ,      .</em> </p><br><p>             ,   .         ,    . </p><br><p><img src="https://habrastorage.org/webt/0r/hv/l0/0rhvl0mowqozwdscxpkc-lp-w7e.png"></p><br><p> <em> 4.      HELEN     .                .</em> </p><br><p>    ,          .   ,        ,    ,        ,       . </p><br><p> <strong></strong> <br>                 .              .  5          .    ,    ,      [8, 2] (           10 √ó 400 .) </p><br><p><img src="https://habrastorage.org/webt/rt/sa/n3/rtsan3fkhl6houggpnk8zyiwqie.png"></p><br><p> <em> 5.             .</em> </p><br><p> <strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trainingsdaten</font></font></strong> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Um die Wirksamkeit unserer Methode in Bezug auf die Anzahl der Trainingsbilder zu testen, haben wir verschiedene Modelle aus verschiedenen Teilmengen von Trainingsdaten trainiert. </font><font style="vertical-align: inherit;">Tabelle 6 fasst die Endergebnisse zusammen, und Abbildung 5 zeigt eine grafische Darstellung der Fehler auf jeder Ebene der Kaskade. </font><font style="vertical-align: inherit;">Die Verwendung vieler Ebenen von Regressoren ist am n√ºtzlichsten, wenn wir eine gro√üe Anzahl von Trainingsbeispielen haben.</font></font></p><br><p> Wir wiederholten dieselben Experimente mit einer festen Gesamtzahl erweiterter Beispiele, √§nderten jedoch die Kombination der Anfangsformen, die zur Erstellung des Trainingsbeispiels verwendet wurden, aus einem markierten Beispiel des Gesichts und einer Reihe kommentierter Bilder, die zur Untersuchung der Kaskade verwendet wurden (Tabelle 7). </p><br><p><img src="https://habrastorage.org/webt/8p/-8/bb/8p-8bbob2qvordp1hhebxruts38.png"></p><br><p>  <em>Tabelle 6. Die endg√ºltige Fehlerrate f√ºr die Anzahl der Trainingsbeispiele.</em>  <em>Bei der Erstellung von Trainingsdaten f√ºr das Studium kaskadierender Regressoren wurden aus jedem markierten Gesichtsbild 20 Trainingsbeispiele generiert, wobei 20 verschiedene markierte Gesichter als erste Annahme √ºber die Gesichtsform verwendet wurden.</em> </p><br><p><img src="https://habrastorage.org/webt/0o/ft/7s/0oft7ss-mbxhjnln3wje3hqzxau.png"></p><br><p>  <em>Abbildung 5. Der durchschnittliche Fehler auf jeder Ebene der Kaskade wird in Abh√§ngigkeit von der Anzahl der verwendeten Trainingsbeispiele dargestellt.</em>  <em>Die Verwendung vieler Ebenen von Regressoren ist am n√ºtzlichsten, wenn die Anzahl der Trainingsbeispiele gro√ü ist.</em> </p><br><p><img src="https://habrastorage.org/webt/am/mj/aq/ammjaqyvpgnzjynmk0ychb7lnw8.png"></p><br><p>  <em>Tabelle 7. Hier ist die effektive Anzahl von Trainingsbeispielen festgelegt, wir verwenden jedoch verschiedene Kombinationen aus der Anzahl von Trainingsbildern und der Anzahl von Anfangsformen, die f√ºr jedes markierte Gesichtsbild verwendet werden.</em> </p><br><p>  Durch das Erh√∂hen der Trainingsdaten mithilfe einer Vielzahl von Anfangsformularen wird der Datensatz in Bezug auf die Form erweitert.  Unsere Ergebnisse zeigen, dass diese Art der Erg√§nzung das Fehlen kommentierter Trainingsbilder nicht vollst√§ndig kompensiert.  Obwohl die Verbesserungsrate, die durch Erh√∂hen der Anzahl von Trainingsbildern erhalten wird, nach den ersten paar hundert Bildern schnell abnimmt. </p><br><p>  <strong>Teilanmerkungen</strong> <br>  Tabelle 8 zeigt die Ergebnisse der Verwendung von teilweise kommentierten Daten.  200 Fallstudien sind vollst√§ndig und der Rest nur teilweise kommentiert. </p><br><p><img src="https://habrastorage.org/webt/iu/j9/7q/iuj97qa3-awn35lf8z3yibbuzhw.png"></p><br><p>  <em>Tabelle 8. Ergebnisse unter Verwendung teilweise beschrifteter Daten.</em>  <em>200 Beispiele sind immer vollst√§ndig kommentiert.</em>  <em>Die Werte in Klammern geben den Prozentsatz der beobachteten Orientierungspunkte an.</em> </p><br><p>  Die Ergebnisse zeigen, dass wir mit teilweise gekennzeichneten Daten eine signifikante Verbesserung erzielen k√∂nnen.  Die angezeigte Verbesserung ist jedoch m√∂glicherweise nicht ges√§ttigt, da wir wissen, dass die Basisgr√∂√üe der Formparameter viel geringer ist als die Gr√∂√üe der Orientierungspunkte (194 √ó 2).  Folglich besteht das Potenzial f√ºr eine signifikantere Verbesserung bei Teilmarkierungen, wenn Sie die Korrelation zwischen der Position der Landmarken explizit verwenden.  Bitte beachten Sie, dass das in diesem Artikel beschriebene Verfahren zur Erh√∂hung des Gradienten keine Korrelation zwischen Orientierungspunkten verwendet.  Dieses Problem kann in zuk√ºnftigen Arbeiten gel√∂st werden. </p><br><h1 id="4-vyvod">  4. Fazit </h1><br><p>  Wir haben beschrieben, wie ein Ensemble von Regressionsb√§umen verwendet werden kann, um die Position von Gesichtsmarkierungen aus einer gestreuten Teilmenge von Intensit√§tswerten, die aus dem Eingabebild extrahiert wurden, zu regressieren.  Die dargestellte Struktur reduziert Fehler schneller als die vorherige Arbeit und kann auch teilweise oder undefinierte Markierungen verarbeiten.  W√§hrend die Hauptkomponenten unseres Algorithmus verschiedene Zielmessungen als unabh√§ngige Variablen betrachten, wird die nat√ºrliche Fortsetzung dieser Arbeit die Verwendung der Korrelation von Formularparametern f√ºr ein effektiveres Training und eine bessere Verwendung von Teilbeschriftungen sein. </p><br><p><img src="https://habrastorage.org/webt/am/cu/xs/amcuxsbdkp6du3rohxpnoey0r2q.png"></p><br><p>  <em>Abbildung 6. Endergebnisse in der HELEN-Datenbank.</em> </p><br><p>  <strong>Danksagung</strong> <br>  Diese Arbeit wurde von der schwedischen Stiftung f√ºr strategische Forschung im Rahmen des VINST-Projekts finanziert. </p><br><h1 id="ispolzovannaya-literatura">  Gebrauchte Literatur </h1><br><p>  [1] PN Belhumeur, DW Jacobs, DJ Kriegman und N. Kumar.  Lokalisierung von Gesichtsteilen anhand eines Konsenses von Exemplaren.  In CVPR, Seiten 545‚Äì552, 2011. 1, 5 <br>  [2] X. Cao, Y. Wei, F. Wen und J. Sun.  Gesichtsausrichtung durch explizite Formregression.  In CVPR, Seiten 2887‚Äì2894, 2012. 1, 2, 3, 4, 5, 6 <br>  [3] TF Cootes, M. Ionita, C. Lindner und P. Sauer.  Robuste und genaue Anpassung des Formmodells durch zuf√§llige Waldregressionsabstimmung.  In ECCV, 2012.1 <br>  [4] TF Cootes, CJ Taylor, DH Cooper und J. Graham.  Aktive Formmodelle - ihre Ausbildung und Anwendung.  Computer Vision and Image Understanding, 61 (1): 38‚Äì59, 1995.1, 2 <br>  [5] D. Cristinacce und TF Cootes.  Modelle f√ºr aktive Regressionsformen.  In BMVC, Seiten 79.1‚Äì79.10, 2007.1 <br>  [6] M. Dantone, J. Gall, G. Fanelli und LV Gool.  Erkennung von Gesichtsmerkmalen in Echtzeit mithilfe von bedingten Regressionsw√§ldern.  In CVPR, 2012.1 <br>  [7] L. Ding und AM Mart¬¥ƒ±nez.  Pr√§zise detaillierte Erkennung von Gesichtern und Gesichtsz√ºgen.  In CVPR, 2008.1 <br>  [8] P. Dollar, P. Welinder und P. Perona.  Kaskadierte Posenregression.  In CVPR, Seiten 1078‚Äì1085, 2010. 1, 2, 6 <br>  [9] GJ Edwards, TF Cootes und CJ Taylor.  Fortschritte bei aktiven Erscheinungsmodellen.  In ICCV, Seiten 137‚Äì142, 1999. 1, 2 <br>  [10] T. Hastie, R. Tibshirani und JH Friedman.  Die Elemente des statistischen Lernens: Data Mining, Inferenz und Vorhersage.  New York: Springer-Verlag, 2001.2.3 <br>  [11] V. Kazemi und J. Sullivan.  Gesichtsausrichtung mit teilbasierter Modellierung.  In BMVC, Seiten 27.1‚Äì27.10, 2011.2 <br>  [12] V. Le, J. Brandt, Z. Lin, LD Bourdev und TS Huang.  Interaktive Lokalisierung von Gesichtsmerkmalen.  In [13] L. Liang, R. Xiao, F. Wen und J. Sun.  Gesichtsausrichtung √ºber komponentenbasierte diskriminative Suche.  In ECCV, Seiten 72‚Äì85, 2008. 1ECCV, Seiten 679‚Äì692, 2012.5 <br>  [14] S. Milborrow und F. Nicolls.  Lokalisieren von Gesichtsmerkmalen mit einem erweiterten aktiven Formmodell.  In ECCV, Seiten 504‚Äì513, 2008.5 <br>  [15] J. Saragih, S. Lucey und J. Cohn.  Verformbare Modellanpassung durch regulierte Mittelwertverschiebungen.  Internation Journal of Computer Vision, 91: 200‚Äì215, 2010.1 <br>  [16] BM Smith und L. Zhang.  Ausrichtung der Gelenkfl√§che mit nichtparametrischen Formmodellen.  In ECCV, Seiten 43‚Äì56, 2012.1 <br>  [17] PA Viola und MJ Jones.  Robuste Gesichtserkennung in Echtzeit.  In ICCV, Seite 747, 2001.5 <br>  [18] X. Zhao, X. Chai und S. Shan.  Gelenkgesichtsausrichtung: Retten Sie schlechte Ausrichtungen durch gute durch regelm√§√üige Neuanpassung.  In ECCV, 2012.1 <br>  [19] X. Zhu und D. Ramanan.  Gesichtserkennung, Posensch√§tzung und Lokalisierung von Orientierungspunkten in freier Wildbahn.  In CVPR, Seiten 2879‚Äì2886, 2012.1 </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de460541/">https://habr.com/ru/post/de460541/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de460531/index.html">Neugierige Perversionen aus der IT-Welt - 5</a></li>
<li><a href="../de460533/index.html">Sie haben die Idee eines IT-Produkts, was kommt als n√§chstes?</a></li>
<li><a href="../de460535/index.html">Erstellen eines minimalen Docker-Containers f√ºr Go-Apps</a></li>
<li><a href="../de460537/index.html">ZuriHac: Funktionale Programmierung √ºben</a></li>
<li><a href="../de460539/index.html">Fehlerbehandlung in Vue</a></li>
<li><a href="../de460543/index.html">Neue Zertifizierungen f√ºr Entwickler von Cisco. Branchenzertifizierungs√ºbersicht</a></li>
<li><a href="../de460547/index.html">Antiquit√§ten: Psion 5MX und Leben im Ruhestand</a></li>
<li><a href="../de460551/index.html">Portugal Die besten Str√§nde und tausend Startups pro Jahr</a></li>
<li><a href="../de460555/index.html">Bericht vom PyDaCon-Treffen bei der Mail.ru Group am 22. Juni</a></li>
<li><a href="../de460557/index.html">Eine Auswahl von Arbeitsbeispielen zur Datenverarbeitung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
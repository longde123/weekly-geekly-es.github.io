<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ôüèΩ üóúÔ∏è üö¥ Hochwertige, leichte und anpassungsf√§hige Text-to-Speech-Technologie mit LPCNet üê∂ üìº üëÖ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="J√ºngste Fortschritte beim Deep Learning bringen signifikante Verbesserungen bei der Entwicklung von Sprachsynthesesystemen (im Folgenden - TTS). Dies ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Hochwertige, leichte und anpassungsf√§hige Text-to-Speech-Technologie mit LPCNet</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/473400/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/v_/5k/ko/v_5kkoibb8w2atlmcuqxhhgj7tc.jpeg"></div><br>  J√ºngste Fortschritte beim Deep Learning bringen signifikante Verbesserungen bei der Entwicklung von Sprachsynthesesystemen (im Folgenden - TTS).  Dies ist auf die Verwendung effektiverer und schnellerer Methoden zum Studium der Stimme und des Stils von Sprechern sowie auf die Synthese nat√ºrlicherer und qualitativ hochwertigerer Sprache zur√ºckzuf√ºhren. <a name="habracut"></a><br><br>  Um dies zu erreichen, m√ºssen die meisten TTS-Systeme jedoch gro√üe und komplexe neuronale Netzwerkmodelle verwenden, die schwer zu trainieren sind und selbst mit GPUs keine Sprachsynthese in Echtzeit erm√∂glichen. <br><br>  Um diese Probleme zu l√∂sen, hat unser IBM Research AI-Team eine neue Methode zur Synthese neuronaler Netze entwickelt, die auf einer modularen Architektur basiert.  Dieses Verfahren kombiniert drei tiefe neuronale Netze (im Folgenden als DNN bezeichnet) mit einer Zwischenverarbeitung ihrer Ausgangssignale.  Wir haben diese Arbeit in unserem Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûHochwertige, leichte und anpassungsf√§hige TTS-Technologie mit LPCNet‚Äú</a> auf der Interspeech 2019 vorgestellt. Die TTS-Architektur ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">leichtgewichtig</a> und kann qualitativ hochwertige Sprache in Echtzeit synthetisieren.  Jedes Netzwerk ist auf verschiedene Aspekte der Stimme des Sprechers spezialisiert, sodass Sie alle Komponenten unabh√§ngig von den anderen effektiv trainieren k√∂nnen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rk/w9/77/rkw977a1ljeapkrqgj4a29rywp8.jpeg" width="45%"></div><br>  <font color="gray">Diagramm 1. TTS-Systemarchitektur</font> <br><br>  Ein weiterer Vorteil unseres Ansatzes besteht darin, dass die Kernnetzwerke nach dem Training auch bei kleinen Mengen von Trainingsdaten, beispielsweise f√ºr Branding- und Anpassungszwecke, problemlos an einen neuen Sprach- oder Sprachstil angepasst werden k√∂nnen. <br><br>  Im Synthesevorgang wird ein Schnittstellenmodul f√ºr eine bestimmte Sprache verwendet, das den eingegebenen Text in eine Folge von Sprachmerkmalen umwandelt.  Dann werden die folgenden DNNs nacheinander angewendet: <br><br><h2>  1. Vorhersage der Prosodie </h2><br>  Prosodische Sprachmerkmale werden als vierdimensionaler Vektor pro TTS-Einheit dargestellt (ungef√§hr ein Drittel der Schallbedingungen gem√§√ü <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SMM</a> (Hidden-Markov-Modell)), der die logarithmische Dauer, die anf√§ngliche und endg√ºltige logarithmische Tonh√∂he sowie die logarithmische Energie umfasst.  Diese Merkmale werden w√§hrend des Trainingsprozesses bestimmt, sodass sie durch die Merkmale des Textes vorhergesagt werden k√∂nnen, der w√§hrend der Synthese von der Schnittstelle empfangen wird.  Prosodie ist √§u√üerst wichtig, damit Sprache nicht nur nat√ºrlich und lebendig klingt, sondern auch, damit die Daten, die f√ºr das Training oder die Anpassung bestimmt sind, den Sprachstil des Sprechers am vollst√§ndigsten widerspiegeln.  Die Anpassung der Prosodie an die Stimme des Sprechers basiert auf dem Variational Auto Encoder (VAE). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/v6/em/9c/v6em9cvo5cya0ikupkey3tj-grw.jpeg"></div><br>  <font color="gray">Schema 2. Schulung und Umschulung des Prosodie-Generators</font> <br><br><h2>  2. Vorhersage akustischer Merkmale </h2><br>  Akustische Merkmalsvektoren liefern eine spektrale Darstellung von Sprache in kurzen 10-Millisekunden-Frames, aus denen tats√§chlicher Ton erzeugt werden kann.  Akustische Merkmale werden im Lernprozess bestimmt und k√∂nnen durch phonetische Markierungen und Prosodie w√§hrend der Synthese vorhergesagt werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ne/kw/dlnekwkvezjgkqfgeaeqzp49g9s.jpeg" width="45%"></div><br>  <font color="gray">Schema 3. Netzwerksynthesizer</font> <br><br>  Das erstellte DNN-Modell besteht aus Audiodaten (Sprachansager), die f√ºr das Training oder die Anpassung erforderlich sind.  Die Architektur des Modells besteht aus Faltungs- und wiederkehrenden Schichten, die den lokalen Kontext und die Zeitabh√§ngigkeiten in der Folge von Kl√§ngen und Tonstrukturen extrahieren sollen.  DNN sagt akustische Merkmale aus ihrer ersten und zweiten Ableitung voraus.  Darauf folgt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Maximum-Likelihood-Methode,</a> und es werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Formantenfilter</a> angewendet, die dazu beitragen, eine besser klingende Sprache zu erzeugen. <br><br><h2>  3. Neuronaler Vocoder </h2><br>  Ein neuronaler Vocoder ist f√ºr die Erzeugung von Sprache aus akustischen Merkmalen verantwortlich.  Er lernt aus den nat√ºrlichen Sprachmustern des Sprechers aufgrund seiner jeweiligen Eigenschaften.  Technisch gesehen waren wir die ersten, die einen neuen, leichten und hochwertigen neuronalen Vocoder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">namens LPCNet</a> in einem vollst√§ndig kommerzialisierten TTS-System verwendeten. <br><br>  Das Neue an diesem Vocoder ist, dass er nicht versucht, ein komplexes Sprachsignal direkt mit DNN vorherzusagen.  Stattdessen sagt der DNN nur das weniger komplexe verbleibende Sprachpfadsignal voraus und konvertiert es dann mithilfe von LPC-Filtern (Linear Predictive Coding) in das endg√ºltige Sprachsignal. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9l/kv/g-/9lkvg-df4fiacjp2b7rz0xhguyu.jpeg" width="45%"></div><br>  <font color="gray">Schema 4. Neuronaler Vocoder LPCNet</font> <br><br><h2>  Sprachanpassung </h2><br>  Die Anpassung an die Sprache wird leicht erreicht, indem drei Netzwerke basierend auf einer kleinen Menge von Audiodaten vom Ziellautsprecher umgeschult werden.  In unserem Artikel pr√§sentieren wir die Ergebnisse von Anpassungsexperimenten in Bezug auf die Sprachqualit√§t und ihre √Ñhnlichkeit mit der Sprache des wahren Sprechers.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diese Seite</a> zeigt auch Beispiele f√ºr die Anpassung an acht verschiedene <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VCTK-Lautsprecher</a> (Voice Cloning Toolkit), von denen 4 M√§nner und 4 Frauen sind. <br><br><h2>  H√∂rergebnisse </h2><br>  Die folgende Abbildung zeigt die Ergebnisse von H√∂rtests synthetisierter und nat√ºrlicher Sprachmuster von VCTK-Lautsprechern.  Die MOS-Werte (Mean Opinion Score) basieren auf der Analyse der Sprachqualit√§t durch die H√∂rer auf einer Skala von 1 bis 5. Die √Ñhnlichkeit zwischen Stichprobenpaaren wurde von den Sch√ºlern auf einer Skala von 1 bis 4 bewertet. <br><br>  Wir haben die Qualit√§t der synthetisierten Sprache sowie ihre √Ñhnlichkeit mit der Sprache von ‚ÄûLive‚Äú -Sprechern gemessen und die an Frauen und M√§nner angepassten Stimmen von 5, 10 und 20 Minuten Dauer mit der nat√ºrlichen Sprache der Sprecher verglichen. <br><br>  Die Testergebnisse zeigen, dass wir sowohl f√ºr Stimmen, die an f√ºnfmin√ºtigen Beispielen trainiert wurden, sowohl eine hohe Qualit√§t als auch eine hohe √Ñhnlichkeit mit dem Original beibehalten k√∂nnen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fq/po/qt/fqpoqtpahytf2tg-msyed-hkytk.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zq/us/vc/zqusvcokvvj3csrwj63g9h9eave.jpeg"></div><br>  <font color="gray">Abbildung 5. Ergebnisse von Tests auf Qualit√§t und √Ñhnlichkeit</font> <br><br>  Diese Arbeit wurde von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IBM Watson durchgef√ºhrt</a> und diente als Grundlage f√ºr eine neue Version des IBM Watson TTS-Dienstes mit verbesserter Sprachqualit√§t (siehe "* V3" -Stimmen in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IBM Watson TTS-</a> Demo). <br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de473400/">https://habr.com/ru/post/de473400/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de473384/index.html">3DToday Fest: wie es war (sein wird). Mitgliederimpressionen</a></li>
<li><a href="../de473390/index.html">FDM lebt</a></li>
<li><a href="../de473392/index.html">Wie starten wir eine neue Bank-Site? Teil 2</a></li>
<li><a href="../de473394/index.html">Ihr alle l√ºgt! √úber CRM-Werbung</a></li>
<li><a href="../de473396/index.html">Wir brauchen noch eine Bitrix</a></li>
<li><a href="../de473406/index.html">Freier Marathon "Data Science and AI: Bringen Sie der Maschine bei, das Skript f√ºr die Serie zu schreiben"</a></li>
<li><a href="../de473408/index.html">Das Debuggen von versteckten Speicherlecks in Ruby</a></li>
<li><a href="../de473412/index.html">Erstellen eines Plugins f√ºr Clang Static Analyzer zur Suche nach Ganzzahl√ºberl√§ufen</a></li>
<li><a href="../de473416/index.html">ZeroNights 2019 Konferenzprogramm</a></li>
<li><a href="../de473418/index.html">OSCP - Offensive Sicherheit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñºÔ∏è üçµ üñ•Ô∏è Regresi√≥n lineal y descenso de gradiente üê§ üë®üèª‚Äçüé® üßóüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Deje que los indicadores X e Y, que tienen una expresi√≥n cuantitativa, se estudien en un √°rea tem√°tica determinada. 

 Adem√°s, hay muchas razones para...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Regresi√≥n lineal y descenso de gradiente</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471458/">  Deje que los indicadores X e Y, que tienen una expresi√≥n cuantitativa, se estudien en un √°rea tem√°tica determinada. <br><br>  Adem√°s, hay muchas razones para creer que el indicador Y depende del indicador X. Esta posici√≥n puede ser tanto una hip√≥tesis cient√≠fica como estar basada en el sentido com√∫n elemental.  Por ejemplo, tome tiendas de abarrotes. <br><br>  Denote por: <br><br>  X - √°rea de ventas (sq. M.) <br><br>  Y - volumen de negocios anual (millones p.) <br><br>  Obviamente, cuanto mayor sea el √°rea de negociaci√≥n, mayor ser√° el volumen de negocios anual (asumimos una relaci√≥n lineal). <br><br>  Imagine que tenemos datos sobre algunas n tiendas (espacio comercial y facturaci√≥n anual), nuestro conjunto de datos yk espacio comercial (X), para las cuales queremos predecir la facturaci√≥n anual (Y), nuestra tarea. <br><br>  Presumimos que nuestro valor de Y depende de X en la forma: Y = a + b * X <br><br>  Para resolver nuestro problema, debemos elegir los coeficientes a y b. <br><a name="habracut"></a><br>  Primero, establezcamos valores aleatorios ayb.  Despu√©s de eso, necesitamos determinar la funci√≥n de p√©rdida y el algoritmo de optimizaci√≥n. <br><br>  Para hacer esto, podemos usar la funci√≥n de p√©rdida cuadr√°tica media ra√≠z ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MSELoss</a> ).  Se calcula mediante la f√≥rmula: <br><br><img src="https://habrastorage.org/webt/ib/kd/an/ibkdanhjp5mzrxr8hxtjxo0mx-k.jpeg"><br><br>  Donde y [i] = a + b * x [i] despu√©s de a = rand () y b = rand (), e Y [i] es el valor correcto para x [i]. <br>  En esta etapa, tenemos la desviaci√≥n est√°ndar (una cierta funci√≥n de ayb).  Y es obvio que, cuanto menor es el valor de esta funci√≥n, m√°s precisamente se seleccionan los par√°metros ayb con respecto a aquellos par√°metros que describen la relaci√≥n exacta entre el √°rea del espacio comercial y el volumen de negocios en esta sala. <br><br>  Ahora podemos comenzar a usar el descenso de gradiente (solo para minimizar la funci√≥n de p√©rdida). <br><br><h3>  Descenso de gradiente </h3><br>  Su esencia es muy simple.  Por ejemplo, tenemos una funci√≥n: <br><br><pre><code class="1c hljs">y = x*x + <span class="hljs-number"><span class="hljs-number">4</span></span> * x + <span class="hljs-number"><span class="hljs-number">3</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/d1/lr/2k/d1lr2khxthepyuiv1qyafoxcm0a.jpeg"><br><br>  Tomamos un valor arbitrario de x del dominio de definici√≥n de la funci√≥n.  Imagine que este es el punto x1 = -4. <br><br>  Luego, tomamos la derivada con respecto a x de esta funci√≥n en el punto x1 (si la funci√≥n depende de varias variables (por ejemplo, ayb), entonces necesitamos tomar las derivadas parciales para cada una de las variables).  y '(x1) = -4 &lt;0 <br><br>  Ahora obtenemos un nuevo valor para x: x2 = x1 - lr * y '(x1).  El par√°metro lr (tasa de aprendizaje) le permite establecer el tama√±o del paso.  As√≠ obtenemos: <br><br>  Si la derivada parcial en un punto dado x1 &lt;0 (la funci√≥n disminuye), entonces nos movemos al punto de m√≠nimo local.  (x2 ser√° mayor que x1) <br><br>  Si la derivada parcial en un punto dado x1&gt; 0 (la funci√≥n aumenta), entonces todav√≠a nos estamos moviendo al punto de m√≠nimo local.  (x2 ser√° menor que x1) <br><br>  Al realizar este algoritmo de forma iterativa, nos acercaremos al m√≠nimo (pero no lo alcanzaremos). <br><br>  En la pr√°ctica, todo esto parece mucho m√°s simple (sin embargo, no presumo decir qu√© coeficientes ayb se ajustar√°n con mayor precisi√≥n con el caso anterior con las tiendas, por lo que tomamos una dependencia de la forma y = 1 + 2 * x para generar el conjunto de datos, y luego entrenamos nuestro modelo en este conjunto de datos): <br>  (El c√≥digo est√° escrito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ) <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment">#      np.random.seed(42) #  np-  1000     0..1 sz = 1000 x = np.random.rand(sz, 1) #   y = f(x)      y = 1 + 2 * x + 0.1 * np.random.randn(sz, 1) #    0  999 idx = np.arange(sz) #    np.random.shuffle(idx) train_idx = idx #     x_train, y_train = x[train_idx], y[train_idx] #        a = np.random.randn(1) b = np.random.randn(1) print(a,b) #   lr = 0.01 #   n_epochs = 10000 #   for epoch in range(n_epochs): #       a  b #     yhat = a + b * x_train # 1.   #      : error = (y_train - yhat) # 2.   (  ) #   a a_grad = -2 * error.mean() #   b b_grad = -2 * (x_train * error).mean() # 3.  ,     a = a - lr * a_grad b = b - lr * b_grad print(a,b)</span></span></code> </pre><br>  Una vez compilado el c√≥digo, puede ver que los valores iniciales de a y b estaban lejos del 1 y 2 requeridos, respectivamente, y los valores finales est√°n muy cerca. <br><br>  Aclarar√© un poco de por qu√© a_grad y b_grad se consideran de esa manera. <br>  <code>F(a, b) = (y_train - yhat) ^ 2 = (1 + 2 * x_train ‚Äì a + b * x_train)</code> .  La derivada parcial de F con respecto a a ser√° <code>-2 * (1 + 2 * x_train ‚Äì a + b * x_train) = -2 * error</code> .  La derivada parcial de F con respecto a b ser√° <code>-2 * x_train * (1 + 2 * x_train ‚Äì a + b * x_train) = -2 * x_train * error</code> .  Tomamos el valor medio <code>(mean())</code> ya que <code>error</code> y <code>x_train</code> e <code>y_train</code> son matrices de valores, ayb son escalares. <br><br>  Materiales utilizados en el art√≠culo: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">intodatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">www.mathprofi.ru/metod_naimenshih_kvadratov.html</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/471458/">https://habr.com/ru/post/471458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../471434/index.html">Iniciar sesi√≥n autom√°ticamente en una conferencia de Lync en Linux</a></li>
<li><a href="../471436/index.html">Nueva aplicaci√≥n 3CX para Android - Respuestas a preguntas y recomendaciones</a></li>
<li><a href="../471440/index.html">¬øC√≥mo capacitamos a los alumnos en Exceed Team o Education Time?</a></li>
<li><a href="../471450/index.html">Entrada a Aeronet, Episodio 4: Encuentra y folla</a></li>
<li><a href="../471452/index.html">La inteligencia artificial se conecta a la predicci√≥n de terremotos</a></li>
<li><a href="../471462/index.html">Escuela de desarrolladores de Java en Nizhny Novgorod</a></li>
<li><a href="../471464/index.html">Dise√±ador el√©ctrico en miniatura para ni√±os con sus propias manos.</a></li>
<li><a href="../471468/index.html">El problema de la clasificaci√≥n de hackers por peligro</a></li>
<li><a href="../471470/index.html">Cifrado de acuerdo con GOST: memorando sobre la configuraci√≥n del enrutamiento din√°mico del tr√°fico</a></li>
<li><a href="../471472/index.html">Semana de la seguridad 42: puertas traseras de hardware, vulnerabilidad en Intel NUC</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
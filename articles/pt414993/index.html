<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§òüèª üò∏ ‚ôâÔ∏è Identifica√ß√£o e classifica√ß√£o de coment√°rios t√≥xicos. Palestra em Yandex üôÜüèø ü§ì üê§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todos os sistemas modernos de modera√ß√£o usam crowdsourcing ou machine learning, que j√° se tornou um cl√°ssico. No pr√≥ximo treinamento de ML em Yandex, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identifica√ß√£o e classifica√ß√£o de coment√°rios t√≥xicos. Palestra em Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/414993/">  Todos os sistemas modernos de modera√ß√£o usam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">crowdsourcing</a> ou machine learning, que j√° se tornou um cl√°ssico.  No pr√≥ximo treinamento de ML em Yandex, Konstantin Kotik, Igor Galitsky e Alexey Noskov conversaram sobre sua participa√ß√£o no concurso para a identifica√ß√£o em massa de coment√°rios ofensivos.  A competi√ß√£o foi realizada na plataforma Kaggle. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3mL9iP8g3fA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Ol√° pessoal!  Meu nome √© Konstantin Kotik, sou cientista de dados da empresa Button of Life, estudante do departamento de f√≠sica e da Escola de Neg√≥cios da Universidade Estadual de Moscou. <br><a name="habracut"></a><br>  Hoje, nossos colegas, Igor Galitsky e Alexei Noskov, falar√£o sobre a competi√ß√£o Desafio de Classifica√ß√£o de Coment√°rios T√≥xicos, na qual nossa equipe DecisionGuys ficou em 10¬∫ lugar entre 4551 equipes. <br><br>  Uma discuss√£o on-line de t√≥picos importantes para n√≥s pode ser dif√≠cil.  Os insultos, agress√£o e ass√©dio que ocorrem on-line muitas vezes obrigam muitas pessoas a abandonar a busca por v√°rias opini√µes apropriadas sobre quest√µes de seu interesse, a se recusarem a se expressar. <br><br>  Muitas plataformas lutam para se comunicar efetivamente online, mas isso muitas vezes leva muitas comunidades a simplesmente fechar os coment√°rios dos usu√°rios. <br><br>  Uma equipe de pesquisa do Google e outra empresa est√° trabalhando em ferramentas para ajudar a melhorar as discuss√µes on-line. <br><br>  Um dos truques em que eles se concentram √© explorar comportamentos on-line negativos, como coment√°rios t√≥xicos.  Estes s√£o coment√°rios que podem ser ofensivos, desrespeitosos ou podem simplesmente for√ßar o usu√°rio a sair da discuss√£o. <br><br><img src="https://habrastorage.org/webt/y2/o4/oz/y2o4ozi061ri0lyir_c9szxsmko.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link</a></sup></sub> </h5><br>  At√© o momento, esse grupo desenvolveu uma API p√∫blica que pode determinar o grau de toxicidade de um coment√°rio, mas seus modelos atuais ainda cometem erros.  E nessa competi√ß√£o, n√≥s, os Kegglers, fomos desafiados a construir um modelo que fosse capaz de identificar coment√°rios contendo amea√ßas, √≥dio, insultos e afins.  E, idealmente, era necess√°rio que esse modelo fosse melhor que o modelo atual para sua API. <br><br>  Temos a tarefa de processar o texto: identificar e depois classificar os coment√°rios.  Como amostras de treinamento e teste, coment√°rios foram fornecidos nas p√°ginas de discuss√£o da Wikipedia.  Houve cerca de 160 mil coment√°rios no trem, 154 mil no teste. <br><br><img src="https://habrastorage.org/webt/u5/ys/we/u5yswe0_sb618cfq9rlilpykuke.jpeg" width="700"><br><br>  A amostra de treinamento foi marcada da seguinte forma.  Cada coment√°rio possui seis r√≥tulos.  Os r√≥tulos assumem o valor 1 se o coment√°rio contiver esse tipo de toxicidade, 0 caso contr√°rio.  E pode ser que todos os r√≥tulos sejam zero, um caso de coment√°rio adequado.  Ou pode ser que um coment√°rio contenha v√°rios tipos de toxicidade, imediatamente uma amea√ßa e obscenidade. <br><br>  Devido ao fato de estarmos no ar, n√£o posso demonstrar exemplos espec√≠ficos dessas classes.  Em rela√ß√£o √† amostra de teste, para cada coment√°rio foi necess√°rio prever a probabilidade de cada tipo de toxicidade. <br><br>  A m√©trica de qualidade √© a m√©dia da ROC AUC sobre os tipos de toxicidade, isto √©, a m√©dia aritm√©tica da ROC AUC para cada classe separadamente. <br><br><img src="https://habrastorage.org/webt/17/cm/gk/17cmgklewbzg00esfhzii641og4.jpeg" width="700"><br><br>  Aqui est√° a distribui√ß√£o de objetos por classes no conjunto de treinamento.  Pode-se ver que os dados s√£o muito desequilibrados.  Devo dizer imediatamente que nossa equipe obteve uma amostra de m√©todos para trabalhar com dados desequilibrados, por exemplo, superamostragem ou subamostragem. <br><br><img src="https://habrastorage.org/webt/og/t6/gy/ogt6gyfkpmslose73rrxl4v_7ci.jpeg" width="700"><br><br>  Ao construir o modelo, usei um pr√©-processamento de dados em dois est√°gios.  O primeiro est√°gio √© o pr√©-processamento b√°sico dos dados, essas s√£o as transforma√ß√µes da exibi√ß√£o no slide, trazendo o texto para min√∫sculas, excluindo links, endere√ßos IP, n√∫meros e pontua√ß√£o. <br><br><img src="https://habrastorage.org/webt/xb/5v/kq/xb5vkq8juiimjekysw3e0we4vgq.jpeg" width="700"><br><br>  Para todos os modelos, esse pr√©-processamento de dados b√°sico foi usado.  Na segunda etapa, foi realizado um pr√©-processamento parcial dos dados - substituindo emoticons pelas palavras correspondentes, decifrando abrevia√ß√µes, corrigindo erros de digita√ß√£o em palavr√µes, trazendo os diferentes tipos de tapetes para a mesma forma e tamb√©m excluindo imagens.  Em alguns coment√°rios, links para imagens foram indicados, n√≥s simplesmente os removemos. <br><br>  Para cada um dos modelos, foi utilizado pr√©-processamento parcial de dados e seus v√°rios elementos.  Tudo isso foi feito para que os modelos de base reduzissem a correla√ß√£o cruzada entre os modelos de base ao construir uma composi√ß√£o adicional. <br>  Vamos para a parte mais interessante - a constru√ß√£o de um modelo. <br><br>  Abandonei imediatamente a abordagem cl√°ssica do saco de palavras.  Devido ao fato de que nessa abordagem, cada palavra √© um atributo separado.  Essa abordagem n√£o leva em considera√ß√£o a ordem geral das palavras; sup√µe-se que as palavras sejam independentes.  Nessa abordagem, a gera√ß√£o do texto ocorre para que haja alguma distribui√ß√£o em palavras, uma palavra √© selecionada aleatoriamente nessa distribui√ß√£o e inserida no texto. <br><br>  Obviamente, existem processos generativos mais complexos, mas a ess√™ncia n√£o muda - essa abordagem n√£o leva em conta a ordem geral das palavras.  Voc√™ pode ir para engramas, mas somente a ordem das palavras da janela ser√° levada em considera√ß√£o, e n√£o geral.  Portanto, tamb√©m entendi meus colegas de equipe que precisavam usar algo mais inteligente. <br><br><img src="https://habrastorage.org/webt/7q/1q/2v/7q1q2v5h2q8c8ngog4foqvsabbm.jpeg" width="700"><br><h5>  <sub><sup><a href="">Link</a></sup></sub> </h5><br>  A primeira coisa inteligente que me ocorreu foi usar uma representa√ß√£o vetorial usando o Doc2vec.  Este √© o Word2vec mais um vetor que leva em conta a exclusividade de um documento espec√≠fico.  No artigo original, esse vetor √© chamado como o par√°grafo de identifica√ß√£o. <br><br>  Em seguida, de acordo com essa representa√ß√£o vetorial, estudou-se a regress√£o log√≠stica, onde cada documento foi representado por um vetor de 10.000 dimens√µes.  A avalia√ß√£o da qualidade foi realizada com uma valida√ß√£o cruzada de dez dobras, foi estratificada e √© importante notar que a regress√£o log√≠stica foi estudada para cada classe, seis problemas de classifica√ß√£o foram resolvidos separadamente.  E no final, o resultado foi uma distribui√ß√£o de probabilidade por classe. <br><br>  A regress√£o log√≠stica √© treinada h√° muito tempo.  Eu geralmente n√£o me encaixava na RAM.  Nas instala√ß√µes de Igor, eles passaram um dia em algum lugar para obter o resultado, como em um slide.  Por esse motivo, imediatamente nos recusamos a usar o Doc2vec devido a grandes expectativas, embora isso pudesse ser melhorado em 1000 se um coment√°rio com pr√©-processamento de dados adicional fosse feito. <br><br><img src="https://habrastorage.org/webt/kt/0i/ks/kt0iksctnlf6kobgk1e0xnkomee.jpeg" width="700"><br><br>  O mais inteligente que n√≥s e os outros concorrentes usamos foram redes neurais recorrentes.  Eles recebem sequencialmente as palavras na entrada, atualizando seu estado oculto ap√≥s cada palavra.  Igor e eu usamos a rede recorrente GRU para a incorpora√ß√£o de palavras no fastText, que √© especial porque resolve muitos problemas independentes de classifica√ß√£o bin√°ria.  Preveja a presen√ßa ou aus√™ncia da palavra de contexto de forma independente. <br><br>  Tamb√©m realizamos uma avalia√ß√£o de qualidade na valida√ß√£o cruzada de dez dobras, n√£o foi estratificada aqui e aqui a distribui√ß√£o de probabilidade foi imediatamente obtida por classe.  Cada problema de classifica√ß√£o bin√°ria n√£o foi resolvido separadamente, mas um vetor seis-dimensional foi gerado imediatamente.  Foi o nosso um dos melhores modelos individuais. <br><br>  Voc√™ pergunta, qual era o segredo do sucesso? <br><br><img src="https://habrastorage.org/webt/aq/ik/nm/aqiknmpv8txoen1uollbhmy3iz8.jpeg" width="700"><br><br>  Consistia em mistura, havia muito, com empilhamento e cria√ß√£o de redes na abordagem.  A abordagem de rede precisa ser descrita como um gr√°fico direcionado. <br><br><img src="https://habrastorage.org/webt/uj/hl/9r/ujhl9rp1pse-y-0euvxutavnrpa.jpeg" width="700"><br><br>  No in√≠cio da competi√ß√£o, a equipe do DecisionGuys era composta por duas pessoas.  Ent√£o Pavel Pleskov, no canal ODS Slack, expressou o desejo de querer se juntar a algu√©m dos 200 melhores.  Naquela √©poca, est√°vamos em algum lugar no 157¬∫ lugar, e Pavel Pleskov no 154¬∫ lugar, em algum lugar do bairro.  Igor percebeu seu desejo de participar e eu o convidei para a equipe.  Ent√£o Andrey Litvinov se juntou a n√≥s, e Pavel convidou o gr√£o-mestre Alexei Noskov para nossa equipe.  Igor - Eugene.  E o √∫ltimo parceiro da nossa equipe foi o b√∫lgaro Atanas Atanasov, e este foi o resultado de um conjunto internacional humano. <br><br>  Agora Igor Galitsky dir√° como ele ensinou o gru, com mais detalhes ele falar√° sobre as id√©ias e abordagens de Pavel Pleskov, Andrei Litvinov e Atanas Atanasov. <br><br>  Igor Galitsky: <br>  - Sou cientista de dados na Epoch8 e falarei sobre a maioria das arquiteturas que usamos. <br><br><img src="https://habrastorage.org/webt/l1/ah/jz/l1ahjzsk3hgrivbmffam4eb_9vy.jpeg" width="700"><br><br>  Tudo come√ßou com o grupo did√°tico direcional padr√£o com duas camadas, quase todas as equipes o usaram, e o fastText, a fun√ß√£o de ativa√ß√£o do EL, foi usado como incorpora√ß√£o. <br><br>  N√£o h√° nada de especial a dizer, arquitetura simples, sem frescuras.  Por que ela nos deu bons resultados com os quais ficamos no top 150 por algum tempo?  Tivemos um bom pr√©-processamento do texto.  Era necess√°rio seguir em frente. <br><br><img src="https://habrastorage.org/webt/ni/ny/dx/ninydx6a2wsofsa-qdqncx904ou.jpeg" width="700"><br><br>  Paulo teve sua pr√≥pria abordagem.  Depois de nos misturarmos com os nossos, isso deu um aumento significativo.  Antes disso, t√≠nhamos gru e model blending no Doc2vec, que dava 61 LB. <br><br><img src="https://habrastorage.org/webt/hq/uk/lg/hquklgojqvgbhidth4gqgv5lctg.jpeg" width="700"><br><br>  Vou falar sobre as abordagens de Atanas Atanasov, ele √© diretamente um entusiasta de novos artigos.  Aqui est√° o gru com aten√ß√£o, todos os par√¢metros no slide.  Ele tinha muitas abordagens bem legais, mas at√© o √∫ltimo momento ele usou seu pr√©-processamento e todo o lucro foi nivelado.  Velocidade no slide. <br><br><img src="https://habrastorage.org/webt/1f/3w/_h/1f3w_hiemppymuwtyvt4xjd04so.jpeg" width="700"><br><br>  Depois, houve uma aten√ß√£o hier√°rquica, que apresentou resultados ainda piores, pois inicialmente era uma rede para classificar documentos compostos por senten√ßas.  Ele estragou tudo, mas a abordagem n√£o √© muito. <br><br><img src="https://habrastorage.org/webt/dp/pn/su/dppnsuijdyfefmos-rmpecohrsu.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link</a></sup></sub> </h5><br>  Houve uma abordagem interessante, podemos obter recursos da oferta inicialmente desde o in√≠cio e at√© o final.  Com a ajuda da convolu√ß√£o, camadas convolucionais, obtemos recursos separadamente √† esquerda e √† direita da √°rvore.  Isso √© do come√ßo e do fim da frase, ent√£o eles se fundem e passam novamente pelo gru. <br><br><img src="https://habrastorage.org/webt/j7/gp/vr/j7gpvrmt3s3tf04qidvcfobmzvs.jpeg" width="700"><br><br>  Tamb√©m Bi-GRU com bloco de aten√ß√£o.  Este √© um dos melhores em privado foi uma rede bastante profunda, mostrou bons resultados. <br><br><img src="https://habrastorage.org/webt/d9/tw/_v/d9tw_v7n_nkvuxnxctppb2lvbyo.jpeg" width="700"><br><br>  A pr√≥xima abordagem √© destacar os recursos o m√°ximo poss√≠vel?  Ap√≥s a camada da rede recorrente, fazemos mais tr√™s camadas paralelas de convolu√ß√£o.  E aqui tomamos senten√ßas n√£o t√£o longas, reduzimos para 250, mas devido a tr√™s convolu√ß√µes, isso deu um bom resultado. <br><br><img src="https://habrastorage.org/webt/ft/hq/xy/fthqxy5pglwimem_-h46ieewheq.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link</a></sup></sub> </h5><br>  Foi a rede mais profunda.  Como Atanas disse, ele s√≥ queria ensinar algo grande e interessante.  Uma grade convolucional comum que aprendeu com os recursos de texto, os resultados n√£o s√£o nada de especial. <br><br><img src="https://habrastorage.org/webt/pq/d6/eh/pqd6eh0_hxzqvb6hkwkjzkyws1u.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link</a></sup></sub> </h5><br>  Essa √© uma nova abordagem bastante interessante: em 2017, houve um artigo sobre esse t√≥pico, que foi usado para o ImageNet e permitiu melhorar o resultado anterior em 25%.  Sua principal caracter√≠stica √© que uma pequena camada √© lan√ßada paralelamente ao bloco convolucional, que ensina os pesos para cada convolu√ß√£o nesse bloco.  Ela deu uma abordagem muito legal, apesar de cortar as frases. <br><br>  O problema √© que o comprimento m√°ximo de senten√ßas nessas tarefas alcan√ßou 1.500 palavras, houve coment√°rios muito grandes.  Outras equipes tamb√©m pensaram em como aproveitar essa grande oferta, como encontrar, porque nem tudo √© muito importante.  E muitos disseram que no final da frase havia um infa muito importante.  Infelizmente, em todas essas abordagens, isso n√£o foi levado em considera√ß√£o, porque o come√ßo foi levado.  Talvez isso daria um aumento adicional. <br><br><img src="https://habrastorage.org/webt/mn/aq/om/mnaqomuiugd3p8_bpnrphhxrcmm.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link</a></sup></sub> </h5><br>  Aqui est√° a arquitetura AC-BLSTM.  O ponto principal √© que, se a divis√£o inferior em duas partes, al√©m da aten√ß√£o, √© uma atra√ß√£o inteligente, mas em paralelo ainda √© normal, e tudo isso √© concretizado.  Tamb√©m bons resultados. <br><br><img src="https://habrastorage.org/webt/tw/qa/-c/twqa-cw8om3ingxliha5wrf3brg.jpeg" width="700"><br><br>  E Atanas todo o seu zool√≥gico de modelos, ent√£o foi uma mistura legal.  Al√©m dos modelos em si, adicionei alguns recursos de texto, geralmente comprimento, n√∫mero de letras mai√∫sculas, n√∫mero de palavr√µes, n√∫mero de caracteres, tudo isso adicionado.  Valida√ß√£o cruzada de cinco dobras e obteve excelentes resultados no LB 0,9867 privado. <br><br><img src="https://habrastorage.org/webt/jk/m-/ev/jkm-evezbsayfconwk3cc1uke2s.jpeg" width="700"><br><h5>  <sub><sup><a href="">Link</a></sup></sub> </h5><br>  E a segunda abordagem, ele ensinou com uma incorpora√ß√£o diferente, mas os resultados foram piores.  Todo mundo usava o fastText. <br><br>  Eu queria falar sobre a abordagem de nosso outro colega, Andrei, com o apelido Laol na ODS.  Ele ensinou muitos kernels p√∫blicos, bebeu-os como se estivesse fora de si, e isso realmente produziu resultados muito interessantes.  Voc√™ n√£o podia fazer tudo isso, mas apenas pegue um monte de kernels p√∫blicos diferentes, mesmo no tf-idf, existem todos os tipos de convolu√ß√£o gru. <br><br><img src="https://habrastorage.org/webt/re/gq/cg/regqcgtzm_teedu_brcisgw2hkw.jpeg" width="700"><br><h5>  <sub><sup><a href="">Link</a></sup></sub> </h5><br>  Ele teve uma das melhores abordagens, com as quais ficamos muito tempo entre os 15 primeiros, at√© que Alexey e Atanas se juntaram a n√≥s, ele combinou a mistura e o empilhamento de tudo isso.  E tamb√©m um momento muito legal, que, pelo que entendi, nenhuma das equipes usou, tamb√©m criamos recursos a partir dos resultados da API dos organizadores.  Sobre isso, conte a Alex. <br><br>  Alexey Noskov: <br>  oi  Vou falar sobre a abordagem que usei e como a conclu√≠mos. <br><br><img src="https://habrastorage.org/webt/st/ol/im/stolimynmwutbmyfpce9qgmcvjg.jpeg" width="700"><br><br>  Tudo foi bastante simples para mim: 10 dobras de valida√ß√£o cruzada, modelos pr√©-treinados em vetores diferentes com pr√©-processamento diferente, para que eles tivessem mais diversidade no conjunto, um pequeno aumento e dois ciclos de desenvolvimento.  O primeiro, que basicamente funcionou no in√≠cio, treinou um certo n√∫mero de modelos, analisou erros de valida√ß√£o cruzada, em quais exemplos ele comete erros √≥bvios e corrigiu o pr√©-processamento com base nisso, porque fica mais claro como corrigi-los. <br><br>  E a segunda abordagem, que foi usada mais no final, ensinou alguns conjuntos de modelos, analisou correla√ß√µes, encontrou blocos de modelos que s√£o fracamente correlacionados entre si e fortaleceu a parte deles.  Essa √© a matriz de correla√ß√£o de valida√ß√£o cruzada entre meus modelos. <br><br><img src="https://habrastorage.org/webt/lu/e2/ul/lue2ullofbhfzn1v1x0zk92wam4.jpeg" width="700"><br><br>  Pode-se ver que em alguns lugares ela possui uma estrutura de blocos, enquanto alguns modelos eram de boa qualidade, estavam fracamente correlacionados com os outros, e foram obtidos resultados muito bons quando eu tomei esses modelos como base, ensinei-lhes v√°rias varia√ß√µes diferentes que diferem em diferentes hiperpar√¢metros ou pr√©-processamento e, em seguida, adicionados ao conjunto. <br><br><img src="https://habrastorage.org/webt/r_/m3/5l/r_m35le0i7o8cujs5osoyq8t9h4.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link</a></sup></sub> </h5><br>  Para aumentar, a id√©ia que foi publicada no f√≥rum por Pavel Ostyakov foi a que mais provocou.  Consistia no fato de podermos fazer um coment√°rio, traduzi-lo para outro idioma e depois voltar.  Como resultado da tradu√ß√£o dupla, √© obtida uma reformula√ß√£o, algo est√° um pouco perdido, mas no geral √© obtido um texto ligeiramente diferente, que tamb√©m pode ser classificado e, assim, expandir o conjunto de dados. <br><br>  E a segunda abordagem, que n√£o ajudou muito, mas tamb√©m ajudou, √© que voc√™ pode tentar fazer dois coment√°rios arbitr√°rios, geralmente n√£o muito longos, col√°-los e colocar como r√≥tulo no alvo uma combina√ß√£o de r√≥tulos ou um pouco de entusiasmo, onde h√° apenas um dos eles continham um r√≥tulo. <br><br>  Ambas as abordagens funcionaram bem se n√£o fossem aplicadas antecipadamente a todo o conjunto de conjuntos, mas para alterar o conjunto de exemplos aos quais o aumento deveria ser aplicado a cada √©poca.  Cada √©poca no processo de forma√ß√£o de um lote, escolhemos, digamos, 30% dos exemplos que s√£o executados nas tradu√ß√µes.  Antes, antes, em algum lugar paralelo j√° existe na mem√≥ria, simplesmente selecionamos a vers√£o para tradu√ß√£o com base nela e a adicionamos ao lote durante o treinamento. <br><br><img src="https://habrastorage.org/webt/gp/84/92/gp8492suelagjk9stcprkcgdi_y.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Primeiro link</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">segundo link</a></sup></sub> </h5><br>  Uma diferen√ßa interessante foram os modelos treinados no BPE.  Existe um Senten√ßaPiece - um tokenizador do Google que permite dividir em tokens nos quais n√£o haver√° UNK.  Um dicion√°rio limitado no qual qualquer string √© dividida em alguns tokens.  Se o n√∫mero de palavras no texto real for maior que o tamanho alvo do dicion√°rio, elas come√ßar√£o a se dividir em partes menores, e uma abordagem intermedi√°ria ser√° obtida entre os modelos de n√≠vel de caractere e n√≠vel de palavra. <br><br>  Dois algoritmos de constru√ß√£o principais s√£o usados ‚Äã‚Äãl√°: BPE e Unigram.  Para o algoritmo BPE, foi f√°cil encontrar incorpora√ß√µes pr√©-marca registrada na rede e, com algum vocabul√°rio fixo - eu tinha apenas um bom vocabul√°rio de 50 mil - tamb√©m podia treinar modelos que davam um bom desempenho (inaud√≠vel - aprox. Ed.), Um pouco pior, do que o habitual no fastText, mas eles estavam muito pouco correlacionados com todos os outros e deram um bom impulso. <br><br><img src="https://habrastorage.org/webt/ny/et/hs/nyeths5qlmvbeegudjhpi3jgrpy.jpeg" width="700"><br><br>  Este √© um esquema de empilhamento cl√°ssico.  Como regra geral, na maior parte da competi√ß√£o, antes da combina√ß√£o, eu costumava simplesmente misturar todos os meus modelos sem pesos.  Isso deu os melhores resultados.  Mas ap√≥s a fus√£o, consegui um esquema um pouco mais complexo, que no final deu um bom impulso. <br><br><img src="https://habrastorage.org/webt/zg/vu/th/zgvuthkjtwku6kiaaexiagevq7s.jpeg" width="700"><br><br>  Eu tinha um grande n√∫mero de modelos.  Basta jog√°-los todos em algum tipo de empilhador?  Ele n√£o funcionou muito bem, ele treinou novamente, mas como os modelos eram grupos fortemente correlacionados, eu simplesmente os uni a esses grupos, em cada grupo calculei a m√©dia e recebi de 5 a 7 grupos de modelos muito semelhantes, dos quais como recursos para O pr√≥ximo n√≠vel usou valores m√©dios.  Treinei o LightGBM nisso, corrigi 20 lan√ßamentos com v√°rias amostras, carreguei um pouco de meta-funcionalidade semelhante ao que Atanas fez e, no final, finalmente come√ßou a funcionar, dando um impulso na m√©dia simples. <br><br><img src="https://habrastorage.org/webt/of/vg/b0/ofvgb0ucc3da92cftyrou5ngvye.jpeg" width="700"><br><h5>  <sub><sup><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Link</a></sup></sub> </h5><br>  Acima de tudo, adicionei a API que Andrei encontrou e que cont√©m um conjunto semelhante de r√≥tulos.  Os organizadores constru√≠ram modelos para eles inicialmente.  Como era originalmente diferente, os participantes n√£o o usavam, era imposs√≠vel simplesmente compar√°-lo com aqueles que precis√°vamos prever.  Mas se ele se lan√ßasse em um empilhamento que funcionasse bem como um meta-recurso, daria um impulso maravilhoso, especialmente na classe TOXIC, que, aparentemente, foi a mais dif√≠cil na tabela de classifica√ß√£o, e nos permitiu pular em v√°rios lugares no final, literalmente no √∫ltimo dia . <br><br><img src="https://habrastorage.org/webt/g-/ip/8f/g-ip8f1wpu7jq35ilzgcbnuphhk.jpeg" width="700"><br><br>  Como descobrimos que o empilhamento e a API funcionaram t√£o bem para n√≥s, antes dos envios finais, t√≠nhamos poucas d√∫vidas sobre o qu√£o bem isso seria portado para o privado.  Funcionou muito bem, ent√£o escolhemos dois envios de acordo com o seguinte princ√≠pio: um - uma mistura de modelos sem uma API que foi recebida antes disso, al√©m de empilhar com metaf√≠sica da API.  Aqui ficou 0,9880 em p√∫blico e 0,9874 em privado.  Aqui minhas marcas est√£o confusas. <br><br><img src="https://habrastorage.org/webt/cg/d2/4o/cgd24objdrwraciizrqugzuf8t8.jpeg" width="700"><br><br>  E o segundo √© uma mistura de modelos sem uma API, sem usar empilhamento e sem usar o LightGBM, porque havia receios de que isso fosse algum tipo de reciclagem menor para o p√∫blico, e poder√≠amos voar com isso.  Aconteceu que eles n√£o voaram e, como resultado, com o resultado de 0,9876 no privado, conseguimos a d√©cima posi√ß√£o.  S√≥ isso. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt414993/">https://habr.com/ru/post/pt414993/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt414979/index.html">Conceito Bitcoin MAST</a></li>
<li><a href="../pt414981/index.html">Biblioteca n√£o escrita</a></li>
<li><a href="../pt414983/index.html">Alan Kay: O que tornou o Xerox PARC especial e que ainda se parece com eles hoje</a></li>
<li><a href="../pt414989/index.html">Sat√©lite de detritos espaciais lan√ßado da ISS</a></li>
<li><a href="../pt414991/index.html">Detec√ß√£o e reconhecimento de objetos da c√¢mera no ROS usando o pacote find_object_2d</a></li>
<li><a href="../pt414995/index.html">Notas amadoras, ou O conto de como o desenvolvedor do Scala FPGA configurou</a></li>
<li><a href="../pt414997/index.html">ML-Blitz: An√°lise das tarefas da primeira pr√©-eliminat√≥ria</a></li>
<li><a href="../pt414999/index.html">Watchman 3D e testador de termistor</a></li>
<li><a href="../pt415001/index.html">O operador do carro rob√≥tico do Uber, que abateu um ciclista, assistiu ao programa Voice no momento da colis√£o</a></li>
<li><a href="../pt415003/index.html">Upload irrestrito de arquivos em Apple.com</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
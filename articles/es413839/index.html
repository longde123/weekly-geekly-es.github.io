<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📡 ⚓️ 🧘🏾 AI, curso práctico. Colección e investigación de imágenes. 🙌🏼 🤵🏽 🕓</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este artículo analiza los métodos utilizados para recopilar datos de imágenes en un proyecto de música con una presentación de diapositivas. Hubo limi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso práctico. Colección e investigación de imágenes.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/413839/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/_j/dr/q0/_jdrq0ffcxcf86rbei-wxierd5u.jpeg"></div><br>  Este artículo analiza los métodos utilizados para recopilar datos de imágenes en un proyecto de música con una presentación de diapositivas.  Hubo limitaciones que nos obligaron a usar la base de datos de imágenes existente, en lugar de imágenes tomadas de Flickr.  Sin embargo, este artículo analiza ambos enfoques para que el lector pueda aprender cómo extraer datos utilizando la API de Flickr. <br><br>  Además, dado que la calidad de una parte importante de las imágenes recopiladas con Flickr era baja, se decidió utilizar imágenes de bases de datos de imágenes existentes.  En particular, se recopilaron imágenes de tres bases de datos para investigación psicológica. <br><a name="habracut"></a><br>  Recuerde que inicialmente se seleccionaron los siguientes conjuntos de datos para este proyecto: <br><br><ol><li>  Un conjunto de datos de entrenamiento que contiene 7000 imágenes de colores emocionales de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Flickr</a> para un algoritmo de extracción de emociones. </li><li>  Un conjunto de datos de entrenamiento que contiene los trabajos de Bach para el algoritmo de finalización de melodía. </li><li>  Un conjunto de melodías que sirven como plantillas para modular las emociones. </li></ol><br>  Ahora necesita recopilar los conjuntos de datos.  Como se mostrará en el artículo, la cantidad de trabajo requerida para esto varía significativamente según el conjunto de datos seleccionado. <br><br><h2>  <font color="#0071c5">Captura de imagen</font> </h2><br>  Este proyecto requería un conjunto de imágenes que evocaban siete emociones diferentes: felicidad, tristeza, miedo, ansiedad, asombro, determinación, ira.  Para la colección de imágenes, se decidió utilizar Flickr, un sitio popular para compartir fotos, debido a su tamaño y licencia de Creative Commons *. <br><br>  Buscar manualmente en Flickr 7000 imágenes es una tarea desalentadora.  Afortunadamente, Flickr tiene una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">API</a> que proporciona un conjunto de métodos que facilitan el intercambio de datos con Flickr en un lenguaje de programación.  Sin embargo, antes de usar la API para recopilar imágenes, es importante saber qué buscar para evocar emociones relevantes.  Para determinar la lista de términos de búsqueda, se utilizó una tarea en la plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Amazon Mechanical Turk</a> *. <br><br><h3>  <font color="#0071c5">API de Flickr</font> </h3><br>  Para utilizar los métodos ofrecidos por la API de Flickr, deberá crear una cuenta de Flickr y solicitar una clave de API.  Para hacer esto, debe tener una cuenta de Flickr o Yahoo! *.  A continuación, debe seguir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> y obtener la clave. <br><br><img src="https://habrastorage.org/webt/uh/q3/0k/uhq30kznjns9goydmrjwufzdwl0.png"><br>  <i>Captura de pantalla de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">www.flickr.com/services/apps/create/apply</a></i> <br><br>  El proceso de procesamiento de una solicitud para una clave no comercial es bastante simple.  Incluye una descripción del uso previsto y la aceptación de los términos de uso.  La clave API es una medida de seguridad y se utiliza para evitar el mal uso de la API.  En los métodos proporcionados por la API, es un parámetro obligatorio. <br><br>  Después de recibir la clave API, puede descargar e instalar el kit de herramientas API para uno de los lenguajes de programación de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">The App Garden</a> .  Este proyecto utiliza <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la API PythonI Flickr de Beej</a> , que se puede usar con el lenguaje Python 3. Debe seguir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la guía de instalación de la</a> API Flickr. <br><br>  El código utilizado para descargar las imágenes se muestra a continuación.  Básicamente, aquí se usa la función de caminar API, que busca una imagen por etiqueta.  Las etiquetas se almacenan en un archivo .txt y se enumeran una por línea.  Si se encuentra una imagen, su URL se crea a partir de la plantilla en la <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">granja</a> {farm-id} .staticflickr.com / {server-id} / {id} _ {secret} .jpg</i> , donde el contenido de las llaves se reemplaza con atributos de imagen.  Luego, las 30 imágenes principales para cada etiqueta (ordenadas por relevancia) se extraen y organizan en carpetas, según la emoción y las condiciones de búsqueda. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> flickrapi <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> urllib.request <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os project_path = <span class="hljs-string"><span class="hljs-string">'/path/to/your/project'</span></span> photos_per_tag = <span class="hljs-number"><span class="hljs-number">30</span></span> filenames = [<span class="hljs-string"><span class="hljs-string">'Awe.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Happiness.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Fear.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Determination.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Anxiety.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Tranquility.txt'</span></span>, <span class="hljs-string"><span class="hljs-string">'Sadness.txt'</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">download_files</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(flickr, t, category, num_photos)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Downloads the files of a specific tag os.mkdir(t) os.chdir(t) s = [] for photo in flickr.walk(tag_mode='all', sort='relevance', tags=t, license=4, per_page=50): url = 'https://farm{}.staticflickr.com/{}/{}_{}.jpg'.format(photo.get('farm'), photo.get('server'), photo.get('id'), photo.get('secret')) s.append(url) if len(s) == num_photos: break for i in range(len(s)): filename = '{}_{}_{}.jpg'.format(category, t, str(i)) urllib.request.urlretrieve(s[i], filename) os.chdir(os.path.join(project_path, category)) if __name__ == '__main__': # Creates flickr object # These keys should be requested from flickr api_key = u'xxxxxxxxxxxx' api_secret = u'xxxxxxxxxxx' flickr = flickrapi.FlickrAPI(api_key, api_secret) # Runs the program, cycles through the emotions and downloads the images for each tag. os.chdir(project_path) for fname in filenames: categ = fname[:-4] with open(fname, 'r') as f: tags = f.read().splitlines() os.mkdir(categ) os.chdir(categ) for t in tags: download_files(flickr, t, categ, photos_per_tag) os.chdir(project_path)</span></span></code> </pre> <br>  Para usar este código, debe clonar el repositorio utilizando el enlace de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GitHub</a> .  Después de eso, siga las instrucciones en el archivo README.  Debe reemplazar los parámetros api_key y api_secret con las claves API recibidas en Flickr.  Como se mencionó anteriormente, este script solo funciona en Python 3. <br><br>  Después de que se ejecuta el programa, la carpeta se ve así: <br><br><img src="https://habrastorage.org/webt/d6/vg/4u/d6vg4uz-dqluh8gznempvdzwxrk.png"><br><br><img src="https://habrastorage.org/webt/db/n5/l_/dbn5l_zbd8-w-zjvkjyyelpumz8.jpeg"><br>  <i>Un conjunto de datos de los resultados de búsqueda en Flickr.</i> <br><br>  En total, se recolectaron alrededor de 8800 imágenes.  Se recibieron más imágenes de las requeridas, ya que planeamos descartar algunas de las imágenes de baja calidad que no se pueden usar.  El siguiente paso fue buscar estas imágenes. <br><br><h3>  <font color="#0071c5">Selección de imagen</font> </h3><br>  La calidad de las imágenes recopiladas fue diferente.  Algunas condiciones de búsqueda, por ejemplo, las flores (que se muestran en la figura) dieron imágenes utilizables de alta calidad.  Sin embargo, las condiciones de búsqueda menos específicas a menudo arrojaron imágenes completamente inutilizables.  Por ejemplo, se obtuvo una imagen de un pastel con una mujer maravilla * de la etiqueta milagrosa (debido a la emoción del asombro), y se encontró una imagen de repollo de Ambitious Farms de la etiqueta ambiciosa (debido a la emoción de la determinación). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xk/ia/0k/xkia0kxzikvgjlowgyg8b6_bemo.jpeg"></div><br>  <i>Imágenes inadecuadas</i> <br><br>  Cualquier persona que esté planeando usar la API de Flickr para buscar imágenes es alentada a usar sustantivos específicos como términos de búsqueda.  Las imágenes que se encuentran de ellos son mucho mejores que el uso de adjetivos o sustantivos abstractos.  Por ejemplo, cuando busque imágenes de asombro, debe usar términos de búsqueda como el océano o el Gran Cañón, en lugar de asombro o milagro. <br><br>  Después de ver las imágenes, el equipo concluyó que más del 40 por ciento de las imágenes eran inutilizables.  Como resultado, se revisó el enfoque para seleccionar un conjunto de datos.  Después de discutir una serie de posibilidades, como limitar el conjunto de imágenes a caras con emociones relevantes, se decidió usar imágenes de bases de datos existentes que se usan comúnmente en investigación psicológica (Base de datos afectiva PicturE de Ginebra ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GAPED</a> ), Conjunto de imágenes estandarizadas afectivas abiertas ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OASIS</a> ) e Imagen Estímulos para la provocación de emociones ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ISEE</a> ). <br><br>  A pesar de que las imágenes en las bases de datos existentes son menos diversas de lo que podrían ser en el nuevo conjunto de datos, se optó por las bases de datos existentes debido a la mayor calidad de imagen y la disponibilidad de información sobre los parámetros.  Tener información sobre los parámetros es una gran ventaja, ya que elimina la necesidad de anotaciones con Amazon Mechanical Turk, lo que reduce significativamente el costo. <br><br><h3>  <font color="#0071c5">Fuente de datos</font> </h3><br>  El proceso de recopilación de datos para el nuevo conjunto de datos fue mucho más simple.  En particular, ya no se requieren pasos con Amazon Mechanical Turk y la API de Flickr.  Los conjuntos de datos GAPED y OASIS (incluido el marcado de parámetros) están disponibles para su descarga en Internet.  El conjunto de datos ISEE estuvo disponible después de un correo electrónico al autor solicitando acceso.  Si las instrucciones para descargar los conjuntos de datos no se comprenden bien, lo más probable es que una búsqueda en Google * lo ayude a encontrar contactos de autores que puedan solicitar directamente el acceso a los conjuntos de datos. <br><br>  Se crearon dos conjuntos de datos para este proyecto.  El primero utilizó la API de Flickr para cargar imágenes usando etiquetas de emoción, el segundo fue una compilación de bases de datos existentes utilizadas en la investigación psicológica.  Cada uno de estos conjuntos de datos tiene sus pros y sus contras;  sin embargo, el segundo fue elegido para el proyecto, gracias a ventajas como la calidad de la imagen, la presencia de parámetros etiquetados y el costo. <br><br>  El método utilizado para recopilar datos directamente depende de qué datos se requieren.  Sin embargo, los procesos y métodos descritos en este artículo probablemente sean útiles para muchos proyectos. <br><br>  Ahora que se crean los conjuntos de datos, el proyecto está listo para realizar los siguientes pasos: investigación y procesamiento preliminar de datos. <br><br><h2>  <font color="#0071c5">Exploración de datos de imagen</font> </h2><br>  Como la calidad de una parte importante de las imágenes recopiladas con Flickr era baja, se decidió utilizar imágenes de bases de datos de imágenes existentes.  En particular, se recopilaron imágenes de tres bases de datos para investigación psicológica.  Cada imagen incluye información de calificación para (des) placer e intensidad, recopilada de varios artistas.  Las imágenes de 1986 de estas bases de datos se dividieron en 4 categorías.  Estas categorías cubrían el 87% de las imágenes e incluían el 34% de los animales, el 28% de las personas, el 13% de las escenas y el 12% de los objetos.  El 13% restante fue clasificado como misceláneo. <br><br><h3>  <font color="#0071c5">Animales</font> </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_j/dr/q0/_jdrq0ffcxcf86rbei-wxierd5u.jpeg"></div><br>  <i>Ejemplos de imágenes de la categoría "Animales"</i> <br><br>  Alrededor de un tercio de las imágenes contienen animales, ya sea aislados o junto con otros animales, como se muestra arriba.  En estos ejemplos, moviéndose de izquierda a derecha, aumenta la calificación de agrado.  Las imágenes desagradables de hienas que se comen a sus presas y cucarachas pueden causar una respuesta en forma de emociones tales como: miedo, tristeza y asco. <br><br>  Las imágenes de la derecha, un gato dormido, un perro sonriente, por el contrario, pueden causar simpatía y felicidad. <br><br><h3>  <font color="#0071c5">Personas</font> </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z6/kd/vf/z6kdvfa0yknvuqh3_sdboqobqa8.jpeg"></div><br>  <i>Imágenes de muestra de la categoría Personas</i> <br><br>  La categoría de imágenes Personas incluye imágenes de individuos y grupos de personas, mientras que las imágenes de grupos de personas a menudo contienen más información contextual.  Por ejemplo, la imagen de la banda de música parece haber sido tomada en el contexto de un estadio lleno de fanáticos, lo que sugiere que la imagen se toma en una actuación durante los deportes.  La imagen de una mujer enojada, por el contrario, está privada de contexto: el espectador no tiene la oportunidad de descubrir o adivinar la razón de su enojo.  Cabe señalar que no todas las imágenes con muchas personas o con grupos tienen información adicional. <br><br>  Por ejemplo, la imagen de hombres tendidos en una línea en el suelo, con heridas visibles y ropa ensangrentada, no da una idea de lo que está sucediendo.  Sin embargo, incluso con tal falta de información, las imágenes con personas causan diversas reacciones emocionales. <br><br><h3>  <font color="#0071c5">Escenas</font> </h3><br>  La categoría "Escenas" de un conjunto de imágenes incluye una variedad de escenas, desde estructuras y objetos hechos por el hombre hasta escenas de la naturaleza e incluso el espacio. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ho/2v/tt/ho2vttl3iuauwnr94ce8uivrwdw.jpeg"></div><br>  <i>Imágenes de muestra de la categoría de escenas</i> <br><br><h3>  <font color="#0071c5">Los objetos</font> </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vl/5_/bk/vl5_bkiof6y8puazjhku6d9yfuy.jpeg"></div><br>  <i>Imágenes de muestra de la categoría Objetos</i> <br><br>  La categoría "Objetos" del conjunto de imágenes incluye imágenes enfocadas en un objeto, como se muestra en los ejemplos anteriores.  No hay contexto situacional en estas imágenes, especialmente cuando se compara con otras categorías en el conjunto de imágenes. <br><br><h3>  <font color="#0071c5">Misceláneo</font> </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/md/qf/1g/mdqf1gyo2nw5sdu4oo2vyhbyxfm.jpeg"></div><br>  <i>Ejemplos de imágenes de la categoría Varios.</i> <br><br>  Finalmente, quedó un subconjunto de imágenes en el conjunto que no se pudo asignar a ninguna de las cuatro categorías.  A menudo, como se muestra en los ejemplos, estas imágenes eran escenas con varios objetos, pero sin el contexto típico de las imágenes de la categoría Escenas.  Este tipo de imagen, por regla general, contenía una calificación neutral: no eran ni agradables ni desagradables. <br><br><h2>  <font color="#0071c5">Categorías de emoción para la base de datos de imágenes</font> </h2><br>  Para identificar las categorías de emociones para la base de datos de imágenes, nos basamos en clasificaciones de significación subjetiva normativa que acompañan a cada imagen en la Base de datos afectiva PicturE de Ginebra (GAPED) y el Conjunto de imágenes estandarizadas afectivas abiertas (OASIS).  Dado que GAPED usó la escala Likert de 0 a 100, y OASIS usó la escala Likert de 1 a 7, se aplicó una transformación lineal que llevó todas las calificaciones a una escala continua de 0 a 100. Luego se investigaron dos posibles reglas para categorizar las emociones. <br><br>  Primero, es intuitivamente deseable clasificar las imágenes de acuerdo con el nivel de placer, luego dividirlas en tres partes de acuerdo con la escala de calificación, de modo que las imágenes con calificaciones 0–33.33 representen la categoría negativa, con calificaciones 33.33–66.67 neutrales, y con calificaciones 66.67–100 - una categoría positiva.  Para implementar esta regla de dividir en tres categorías, se utilizó el código Python: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">organizeFolderGAPED</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(original, pos, neg, neut)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#      GAPED    #        dict = {} files = os.listdir(original) for file in files: if '.txt' in file: with open(os.path.join(original, file), 'r') as f: for l in f: l = l.split() dict[l[0][:-4]] = l[1] #        pos/neg/neut      for roots, dirs, files, in os.walk(original): for file in files: if '.bmp' in file: if float(dict[file[:-4]]) &lt; 100/3: shutil.copy(os.path.join(roots, file), neg) elif float(dict[file[:-4]]) &gt; 200/3: shutil.copy(os.path.join(roots, file), pos) else: shutil.copy(os.path.join(roots, file), neut) def organizeFolderOASIS(original, pos, neg, neut): #      GAPED    #        dict = {} with open('/Users/harrys/Desktop/OASIS.csv') as file: reader = csv.reader(file) for row in reader: dict[row[1]] = row[4] #        pos/neg/neut       for roots, dirs, files, in os.walk(original): for file in files: if '.jpg' in file: if (float(dict[file[:-4]])-1)*100/6 &lt; 100/3: shutil.copy(os.path.join(roots, file), neg) elif (float(dict[file[:-4]])-1)*100/6 &gt; 200/3: shutil.copy(os.path.join(roots, file), pos) else: shutil.copy(os.path.join(roots, file), neut) if __name__ == '__main__' : gaped = 'path/to/your/project/directory/GAPED' oasis = 'path/to/your/project/directory/Oasis' pos = 'path/to/your/project/directory/Positive' neg = 'path/to/your/project/directory/Negative' neut = 'path/to/your/project/directory/Neutral' organizeFolderOASIS(oasis, pos, neg, neut) organizeFolderGAPED(gaped, pos, neg, neut)</span></span></code> </pre><br>  Este enfoque nos permitió dividir la base de datos en categorías: 417 imágenes negativas, 774 neutrales y 442 positivas.  En este enfoque, dividido en tres categorías en proporciones iguales de imágenes desagradables, cuya calificación no alcanzó el valor umbral, se clasificó como neutral;  Por ejemplo, las imágenes de un cadáver, un niño llorando, cementerios fueron clasificados como neutrales.  Aunque estas imágenes fueron menos desagradables que otras en la categoría negativa, surgieron dudas sobre su neutralidad. <br><br>  Por lo tanto, se decidió aplicar una regla de categorización optimizada basada en la distribución normal de datos, así como mejorar la separación de parámetros en categorías emocionales.  Los valores 0–39 se asignaron a la categoría negativa, 40–60 a la categoría neutral y 61–100 a la categoría positiva.  Para implementar esta regla, se utilizó el código Python: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> csv <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">organizeFolderGAPED</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(original, pos, neg, neut)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#      GAPED    #        dict = {} files = os.listdir(original) for file in files: if '.txt' in file: with open(os.path.join(original, file), 'r') as f: for l in f: l = l.split() dict[l[0][:-4]] = l[1] #        pos/neg/neut      for roots, dirs, files, in os.walk(original): for file in files: if '.bmp' in file: if float(dict[file[:-4]]) &lt; 40: shutil.copy(os.path.join(roots, file), neg) elif float(dict[file[:-4]]) &gt; 60: shutil.copy(os.path.join(roots, file), pos) else: shutil.copy(os.path.join(roots, file), neut) def organizeFolderOASIS(original, pos, neg, neut): #      GAPED    #        dict = {} with open('path/to/your/project/directory/OASIS.csv') as file: reader = csv.reader(file) for row in reader: dict[row[1]] = row[4] #        pos/neg/neut       for roots, dirs, files, in os.walk(original): for file in files: if '.jpg' in file: if (float(dict[file[:-4]])-1)*100/6 &lt; 40: shutil.copy(os.path.join(roots, file), neg) elif (float(dict[file[:-4]])-1)*100/6 &gt; 60: shutil.copy(os.path.join(roots, file), pos) else: shutil.copy(os.path.join(roots, file), neut) if __name__ == '__main__' : gaped = 'path/to/your/project/directory/GAPED' oasis = 'path/to/your/project/directory/Oasis' pos = 'path/to/your/project/directory/Positive' neg = 'path/to/your/project/directory/Negative' neut = 'path/to/your/project/directory/Neutral' organizeFolderOASIS(oasis, pos, neg, neut) organizeFolderGAPED(gaped, pos, neg, neut)</span></span></code> </pre><br>  Con esta regla de categorización, 40–60–40 567 imágenes positivas fueron calificadas como más agradables que 502 neutrales, y 564 imágenes negativas fueron calificadas como menos agradables que neutrales.  Por lo tanto, se mantuvo el valor objetivo de las categorías emocionales y se mejoró la distribución de imágenes por categoría.  La siguiente figura ilustra el nivel de placer asociado con cada una de las categorías.  Las diferentes longitudes de los bigotes en el diagrama de dispersión indican en qué categoría emocional (positiva o negativa) hay un mayor rango de calificaciones en comparación con la categoría neutral. <br><br><img src="https://habrastorage.org/webt/yx/3f/sv/yx3fsvbh9cpl_jyfz4_1j9xf-io.jpeg"><br>  <i>Calificaciones promedio de placer para cada una de las categorías emocionales</i> <br><br>  Concluimos que esta regla de categorización es suficiente para clasificar imágenes basadas en emociones.  Con respecto a las categorías de los parámetros de la base de datos de imágenes, a continuación se muestran los tipos de imágenes que representan cada una de las categorías emocionales.  Cabe señalar que cada categoría de parámetros (animales, personas, escenas, objetos, misceláneos) está representada en cada una de las categorías emocionales. <br><br>  <i>Categoría emocional 1: negativa</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wg/mo/xx/wgmoxxsmn1b8zp5sbsapzfpgsxi.jpeg"></div><br>  <i>Categoría emocional 2: neutral</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/dv/8a/rzdv8a89hkcqc5gbrtqt8k_yc-q.jpeg"></div><br>  <i>Categoría emocional 3: positiva</i> <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fx/u2/ot/fxu2otvmennaundgxobtgb-empq.jpeg"></div><br>  Para resumir.  Dividimos la base de datos de imágenes en categorías emocionales neutrales, negativas y positivas utilizando clasificaciones de significación normativa en el rango de 0 a 100, asignando 0-39 a negativo, 40-60 a neutral y 61-100 a positivo.  Las imágenes se distribuyeron adecuadamente en estas categorías emocionales.  Finalmente, cada categoría emocional incluía imágenes de animales, personas, escenas, objetos y más. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es413839/">https://habr.com/ru/post/es413839/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es413819/index.html">Sinceramente sobre el mercado de TI en Rusia</a></li>
<li><a href="../es413823/index.html">El boom del empleo sin sentido</a></li>
<li><a href="../es413827/index.html">Proyecto Kubernetes cumple 4 años</a></li>
<li><a href="../es413831/index.html">La nueva versión del piloto automático Tesla se lanzará en agosto, por primera vez con "características de conducción totalmente autónomas".</a></li>
<li><a href="../es413837/index.html">Hacer de Tower Defense un juego de unidad - Parte 1</a></li>
<li><a href="../es413841/index.html">Alternativas a los productos de Google</a></li>
<li><a href="../es413843/index.html">Waymo por delante del resto: los robomóviles de la compañía han rodado 11 millones de kilómetros</a></li>
<li><a href="../es413847/index.html">Monumento desencadenante "vivo"</a></li>
<li><a href="../es413849/index.html">Historia de la marca Sennheiser: libertad y visión</a></li>
<li><a href="../es413851/index.html">Esteganografía en paquetes IP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
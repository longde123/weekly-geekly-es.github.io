<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖱️ 🈚️ 👨🏼‍🎓 通过连接Wikipedia提高文本分类的质量 🍫 🐃 🖖</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="我们使用大型的多语种文本结构化资源-Wikipedia来改善文本的分类。 该方法具有高度的自动化性和独立性，可以很好地解决特定的分类问题。 但是，在确定主题的任务上预期效果最大。 

 主要思想是从Wikipedia中仅提取那些有助于我们解决分类问题的文本，而忽略其他文本。 如果我们对猫的文本进行分...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>通过连接Wikipedia提高文本分类的质量</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446228/">我们使用大型的多语种文本结构化资源-Wikipedia来改善文本的分类。 该方法具有高度的自动化性和独立性，可以很好地解决特定的分类问题。 但是，在确定主题的任务上预期效果最大。 <br><a name="habracut"></a><br> 主要思想是从Wikipedia中仅提取那些有助于我们解决分类问题的文本，而忽略其他文本。 如果我们对猫的文本进行分类，尽管有关其他类型动物的文本可能会有用，但不太可能需要有关量子物理学的文本。 此类文本彼此自动分离是所描述方法的本质。 <br><br> 如您所知，维基百科是关于许多知识和兴趣领域的文章的集合。 同时，文章的很大一部分都链接到相似主题的文章，但使用其他语言。 这些不是翻译，即一般主题的文章。 另外，大多数文章都属于一个或多个类别。 反过来，类别在大多数情况下是以层次树的形式组织的。 也就是说，可以解决将我们感兴趣的主题的维基百科文章分组的任务。 <br><br> 我们使用资源DBPedia-Wikipedia的预连接和结构化版本。  DBPedia为我们提供了所有必要的信息-文章名称，注释，文章类别以及类别的上级类别。 我们从维基百科上使用最广泛的语言开始-英语。 如果您的任务没有英文文本，或者使用的英文文本很少，请使用有大量文档的语言。 <br><br><h3> 步骤1.集群维基百科 </h3><br> 专注于文章类别。 现在，忽略它们的内容。 类别形成一个图，大多数是树状的，但是也有循环。 物品是连接到图的一个或多个节点的图（叶）的端点。 我们使用Node2Vec工具获取每个类别和每个文章的矢量表示。 相似主题的文章在向量空间中分组在一起。 <br><br> 我们可以通过本文中任何方便的方法将其聚集成相当大（数百个）的聚类。 <br><br><h3> 步骤2.在Wikipedia上进行分类器训练 </h3><br> 我们用注释（长摘要和短摘要-每篇文章大约一个文本段落）替换结果簇中文章的名称。 现在，我们有数百个群集定义为文本集。 我们使用一个方便的模型并构建一个解决多类分类问题的分类器：一个集群-一个类。 我们使用了FastText。 <br> 在输出中，我们得到一个将文本作为输入的模型，在输出中，它给出了文本属于我们数百个类集群的程度的估计矢量。 <br><br> 如果第一步不是按类别而是按内容对Wikipedia文章进行聚类，那么首先，我们将按类别丢失信息，但这很重要，其次，我们将获得一个退化的系统-按文本将其分类并构建分类器模型。 最终质量可能会比采用单独方法更差。 虽然我没有检查。 <br><br><h3> 第3步。自行建立模型，作战数据 </h3><br> 我们使用选择的作战数据，并将每个文档从步骤2提交到模型的输入。模型返回估计向量。 我们将此向量用作相关文档的特征向量。 因此，在处理完所有作战文件的训练样本后，我们获得了标准形式的机器学习表格-类标签，数字符号集。 我们将此表称为训练集。 <br><br> 我们在训练样本的基础上建立了一个分类器，可以评估各个属性的信息内容。 决策树及其任何随机森林变异都非常适合。 信息最多的标志是维基百科的文章，这些文章不仅具有与战斗文件的主题相似的主题，而且最重要的是，这些文章的主题使我们能够很好地区分战斗课。 在第一次迭代中，标志的信息量直方图通常相当平坦-就信息性而言，几个信息簇和长长的尾巴几乎等于其余数百个标志。 <br><br> 在研究了字符信息内容的直方图之后，每次都根据经验确定拐点，大约10％到30％的簇进入下一次迭代。 迭代的本质是将来自选定信息性集群的文章进行合并，提交给步骤1-3，在此将它们再次进行聚类，再次构建两个分类器，并且一切都以对信息内容直方图的分析结束。 这将需要3-4次迭代。 <br><br> 事实证明，在我们的数据上，数字符号（尤其是年份）具有很强的权重，并将整个集群的信息量拖到了自己身上。 顺理成章的结果是，专门用于年度体育赛事的集群成为了最有信息的-大量的数字和日期，狭窄的词汇。 我必须删除文章注释文本中的所有数字（第二步）。 情况变得越来越好，真正具有针对性的主题的文章集群开始脱颖而出（正如我们想象的那样）。 同时，在逻辑上落在我们的战斗任务上的意外团簇出现了，具有正确的词汇，但是很难先验地猜测此类团簇的有用性。 <br><br><h3> 步骤4.确定模型 </h3><br> 经过步骤1-3的几次迭代后，我们从Wikipedia中选择了相当数量的文章，其主题有助于共享我们的战斗文件。 我们正在用其他我们感兴趣的其他语言的类似文章来扩展选择范围，并建立最终的集群，这次是数十个。 这些聚类可以以两种方式使用-建立类似于第2步的分类器，并用其在战斗任务中扩展数字特征向量，或者将这些文本集用作附加词汇的来源并将其集成到战斗分类器中。 我们使用了第二种方式。 <br><br> 我们的战斗分类器是两个模型的结合体-截断的朴素贝叶斯和xgboost。 朴素贝叶斯（Naive Bayes）处理长克，克的长度为1到16个元素，每个发现的克将总和倾斜到一个类，但是贝叶斯没有做出最终决定-它仅给出与每个克相关的克重的总和从班级。  Xgboost接受贝叶斯，其他分类器以及根据文本独立构建的一些数字属性的输出，并且xgboost已经给出了最终模型和最终评估。 这种方法使将任何文本集（包括最终的维基百科文章集）连接到gram Bayes模型变得很容易，并且xgboost已经在寻找以维基百科簇对文本进行典型反应形式的模式。 <br><br><h3> 结果与结论 </h3><br> 第一个结果使有条件精度从60％提高到62％。 在步骤4中用放气的文章本身替换Wikipedia文章的注释时，准确性提高到66％。 结果很自然，因为注释的大小是两个或三个短语，并且文章的大小大了几个数量级。 语言材料更多-效果更高。 <br><br> 我们应该期望在文章文本上完成整个过程而不是在注解上完成之后，质量的提高会更大，但是已经存在技术上的数字问题-下载和处理整个Wikipedia或其显着部分（如果不是从第一次迭代开始）是困难的。 同样，如果您最初不仅使用英语，而且使用所有感兴趣的语言，您仍然可以赢得其他奖励。 在这种情况下，处理量的增长是倍数，而不是第一种情况下的数量级。 <br><br><h4> 语义文档向量 </h4><br> 对于每个文档，将基于Wikipedia类别构建矢量与文档与给定主题之间的关系。 向量是通过第3步中描述的方法或由我们的克贝叶斯算法来计算的。 因此，战斗文件可以根据这些向量进行聚类，并按主题对战斗文件进行分组。 剩下的只是放下主题标签，每个新文档都可以使用标签进入数据库。 然后用户可以进行搜索。 如果您以显式和可见的方式将标签附加给用户，就会出现这种情况。 看起来很时髦，尽管我不是支持者。 <br><br><h4> 自适应搜索 </h4><br> 使用语义文档向量的一种更有趣的方法是自适应搜索。 观察用户的活动，他所徘徊的文档以及甚至没有阅读的文档，您可以从长远意义上概述用户的关注领域（毕竟，用户也有责任分工，每个人都主要在寻找自己的职责），并且在当前搜索会话的框架内。 <br><br> 具有相似主题的文档具有相似的语义向量，具有较高的余弦度量，这使您可以根据其符合用户兴趣的预期程度在运行中即时评估文档中的文档，从而可以在搜索结果中增加必要的文档。 <br><br> 结果，即使每个用户使用相同的搜索查询，也可以为其个性化搜索结果，并且根据用户对上一步中的哪些文档感兴趣，即使搜索查询本身未更改，下一个搜索步骤也将根据用户的需求进行调整。 <br><br> 我们现在正在研究自适应搜索的问题。 <br><br><h4> 商业假设检验 </h4><br> 业务周期性地带有很难实施的好主意。 我们必须学会通过描述来查找文件，而不要使用经过标记的样本进行培训，也不能拥有向评估者提交一些用于标记的文件的能力。 这通常发生在相对于总体文档流很少找到目标文档的情况下，结果是，通过向评估者提交一万个文档池而没有进行初步筛选，则可以获得1-2个必要甚至更少的输出。 <br><br> 我们的方法是创建一个基于语义向量的迭代学习过程。 第一步，我们会找到一些设置目标主题的文本-这些可能是Wikipedia文章或其他来源的文本。 对于每个文本，产生其语义矢量。 如果目标主题很复杂，则集合的代数会起作用-统一，相交，将某些主题从其他主题中排除。 例如-维基百科上有关于“研究与开发”和“化妆品”的文章，集合的交集将给出“关于化妆品的研发”。 <br><br> 数据库中的所有文档都可以按照它们与给定主题的符合程度进行排序，然后集合的代数对文档本身进行如下操作-如果文档的语义矢量比给定主题的Wikipedia文章矢量更接近数据库的平均值，则认为该文档与该主题相关。 交集-如果同时文档的语义矢量比数据库的平均值更接近两个主题。 其他操作类似。 <br><br> 我们找到一组数百个或两个文档，它们与所有正面主题最接近，同时与所有负面主题最接近（如果我们对所寻找的研究中的财务问题不感兴趣，我们将“金融”类别的文章设为负面示例） ） 我们将这些文档提供给评估者，他们将在评估者中找到几个积极的例子，基于这些例子，我们将寻找其他具有紧密语义向量的文档，对其进行标记，然后在输出中我们将获得足够的文档以供积极类构建任何方便的分类器。 这可能需要几次迭代。 <br><br><h4> 总结 </h4><br> 所描述的方法无需人工分析即可自动从Wikipedia或其他有助于解决分类问题的文本源中进行选择。 通过简单地将集群从Wikipedia连接到工作的分类器，可以预期质量的显着提高，而无需修改分类器本身。 <br><br> 好吧，自适应搜索很有趣。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN446228/">https://habr.com/ru/post/zh-CN446228/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN446210/index.html">ADAM-3600-多功能工业控制器</a></li>
<li><a href="../zh-CN446212/index.html">SIEM深度：现成的相关性。 第5部分。开发相关规则的方法</a></li>
<li><a href="../zh-CN446214/index.html">OS1：Rust for x86上的原始内核。 第3部分。存储卡，页面错误异常，堆和分配</a></li>
<li><a href="../zh-CN446218/index.html">游戏设计师与心理设计师并没有太大区别。 我们如何制作CMAN游戏</a></li>
<li><a href="../zh-CN446222/index.html">利用热势进行区域分析</a></li>
<li><a href="../zh-CN446230/index.html">通过端口80远程监视和管理基于Linux / OpenWrt / Lede的设备</a></li>
<li><a href="../zh-CN446234/index.html">来自世界各地的志愿者如何制作ICPC-2019的现场直播</a></li>
<li><a href="../zh-CN446236/index.html">Yandex将改进语音识别算法</a></li>
<li><a href="../zh-CN446238/index.html">利用签名的引导加载程序来规避UEFI安全引导</a></li>
<li><a href="../zh-CN446242/index.html">拖延作为时间旅行的工具</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤟 🎸 👩🏿‍🍳 Bot in neuronalen Netzen: Wie ein virtueller Assistent funktioniert und lernt 👩🏻‍💻 👨🏻‍🔧 ♓️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Auf dem Höhepunkt der Beliebtheit von Chatbots stellte unser Team 2016 Button-Assistenten für Unternehmen her. Bis ein interessanter Gedanke auftaucht...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bot in neuronalen Netzen: Wie ein virtueller Assistent funktioniert und lernt</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/478572/"> Auf dem Höhepunkt der Beliebtheit von Chatbots stellte unser Team 2016 Button-Assistenten für Unternehmen her.  Bis ein interessanter Gedanke auftauchte: "Was ist, wenn wir die Client-Unterstützung mit neuronalen Netzen automatisieren?"  Wir wollten, dass die Chat-Roboter endlich lernen, die natürliche Sprache zu verstehen und sich wohl zu fühlen. <br><br>  Es dauerte vier Mathematiker, sechs Monate harte Arbeit, eine neue Programmiersprache und viele Fehler - und wir haben einen Konstruktor erstellt, in dem jeder einen virtuellen Assistenten mit AI zusammenstellen kann. <br><br><h4>  Im Material werden wir erzählen </h4><br><ul><li>  Wie unterscheidet sich ein virtueller Assistent von einem normalen Chat-Bot? </li><li>  Stimmt es, dass virtuelle Assistenten die Sprache verstehen? </li><li>  Wie wir dem Roboter beigebracht haben, den Kontext zu verstehen und die Sprache Lialang geschrieben haben </li><li>  Fallbeispiel: Wie wir den Support in drei Banken automatisiert haben </li><li>  Erstellung von <a href="https://lia.chat/">Lia Platform</a> und Engine für Interfaces </li><li>  Drei Schritte: Wie funktioniert die Plattform zum Zusammenstellen virtueller Assistenten (wo jeder, auch ein Nicht-Programmierer, einen Roboter zusammenbauen kann) </li></ul><br><a name="habracut"></a><br><h3>  Chat bot vs virtueller Assistent </h3><br>  Fortgeschrittene Chatbots konnten bereits in den 60er Jahren Stichwörter hervorheben und den menschlichen Dialog imitieren.  Hippies warfen sich auf LSD, die Beatles sammelten Stadien und Joseph Weizenbaum gründete Eliza, eine Gesprächspartner-Psychotherapeutin, die vielen modernen Bots und sogar Psychologen Chancen einräumt. <br>  Zum Beispiel antwortete Eliza im Satz „Mein Vater hasst mich“ auf das Schlüsselwort „Vater“ und fragte: „Wer in der Familie hasst dich noch?“  Aber der Robo-Psychotherapeut verstand die Essenz der Probleme nicht.  Moderne Chatbots funktionieren auch: Schlüsselwörter, lineare Skripte und eine Parodie des Live-Dialogs. <br><br>  Seit den 60er Jahren hat sich jedoch etwas geändert: Dank maschinellem Lernen und NLP-Technologien können wir Chat-Bots nun das Verstehen der natürlichen Sprache und des Kontexts beibringen.  Dies ist immer noch eine Nachahmung, aber sinnvoller. <br><br>  Um den Unterschied zu erkennen, vergleichen wir den Chatbot und den Assistenten. Stellen Sie sich vor, wir müssen einen <b>virtuellen Sommelier erstellen</b> , der den Kunden bei der Auswahl des Weins hilft. <br><br><h4>  Stufe 1 </h4><br>  Die erste Stufe des Chatbots und des virtuellen Assistenten ist eine: Wir finden Benutzeranforderungen heraus und entwickeln Sätze, die sie schreiben können.  Und dann schreiben wir vor, wie der Roboter darauf reagieren soll. <br><br>  Die Grundanforderung ist klar - holen Sie den Wein ab.  Aber diese Anfrage kann viele Parameter haben: Grund, Preis, Land, Farbe, Rebsorte.  Vielleicht schreibt der Benutzer sofort den Namen des zu findenden Weins.  Oder er klärt die Details: "Wo wird es gemacht?"  Oder vielleicht aus Neugier wirft er dem Bot Fragen zu: „Welche Flasche ist die teuerste der Welt?“ Und so weiter.  Außerdem gibt es neben den Anfragen im Fall „Hallo“, „Tschüss“, „Wie geht es dir“ und andere Smalltalk-Sätze, die gefragt werden müssen. <br><br>  Sie können endlos fantasieren, aber wir können nicht alle Fragen der Benutzer vorhersagen.  Wenn es uns so vorkommt, als würden die beschriebenen Situationen ausreichen, um 98% der Anfragen abzudecken, hören wir auf (obwohl dann die harte Realität abbricht und wir herausfinden, dass bestenfalls 80% abgedeckt werden). <br><br>  Dann streuen wir unsere Annahmen über die Bedürfnisse der Benutzer nach bestimmten Anforderungen - Absichten.  Absichten geben an, was der Benutzer möchte, verwerfen jedoch Informationen darüber, wie er darüber geschrieben hat.  Diese Phase gilt auch für Chatbots und Assistenten. <br><br><h4>  Liste der Absichten </h4><br>  <b>Absicht 1 - Ich möchte Wein</b> <br>  Sätze: <br><br>  - Hilf mir, einen Wein auszuwählen <br>  - Welchen Wein würdest du empfehlen? <br>  - Ich will den besten Wein <br>  - ... <br>  <b>Was ist damit zu tun? Wählen Sie nach dem</b> Zufallsprinzip einen der beliebtesten Weine aus und informieren Sie den Benutzer. <br><br>  <b>Absicht 2 - billigerer Wein</b> <br><br>  Sätze: <br><br>  - Gibt es gute Weine bis 1000 Rubel? <br>  - Aber es gibt nichts billigeres? <br>  - zu teuer für mich <br>  - ... <br>  <b>Was ist zu tun?</b> Fügen Sie der Anfrage einen Preisfilter hinzu und wählen Sie einen der beliebtesten Weine aus. <br><br>  <b>Absicht 3 - Ich möchte Wein zum Fleisch</b> <br>  Sätze: <br><br>  - Raten Sie den Wein zum Steak <br>  "Ich werde Gulasch zum Abendessen haben."  Was zu trinken <br>  - ... <br>  <b>Was zu tun ist: Eine</b> Anfrage an die Datenbank nach dem Kriterium "Fleisch", einen der beliebtesten Weine auswählen und den Benutzer informieren. <br><br>  ... (und so weiter Hunderte von verschiedenen Absichten) <br><br>  <b>Absicht 290 - wir haben den Benutzer nicht verstanden</b> <br>  Sätze: jede andere <br><br>  <b>Was zu tun ist:</b> Geben Sie einen kurzen Satz ein: "Ich weiß nicht, was Sie meinen, aber der Pinista ist zu jeder Jahreszeit ein Genuss." <br><br><h4>  Stufe 2 </h4><br>  In dieser Phase beginnen wir mit der Erstellung eines Algorithmus, mit dem der Roboter arbeitet.  Hier endet die Ähnlichkeit von Chatbot und virtuellem Assistenten. <br><br>  Beim Codieren eines Chatbots bestimmt der Programmierer die Schlüsselwörter für jede Absicht manuell, und wenn der Benutzer schreibt, sucht der Bot nach diesen Schlüsselwörtern in der Phrase. <br><br>  Bei der Entwicklung eines Assistenten lehrt ein Programmierer einen Algorithmus zum Vergleichen von Benutzerreplikaten gemäß der lexikalischen Bedeutung.  Auf diese Weise können Sie die nächstgelegene Absicht finden. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Erlesener Wein mit einem Chat-Bot </th><th>  Weinauswahl mit einem virtuellen AI-Assistenten </th><th>  Was ist passiert </th></tr><tr><td>  <b>Benutzer:</b> Hallo!  Ich möchte vor 2000 Uhr Wein zum Abendessen auswählen <br>  <b>Bot:</b> Hallo! <br>  <b>Bot:</b> Welche Preisspanne suchen wir? <br>  <b>Benutzer:</b> bis zu 2000r <br>  <b>Bot:</b> Ich kann Ramirez de la Piscina empfehlen.  Um das Beste aus der Torte zu machen, eignet sich der gutaussehende Mann aus Spanien zum Abendessen und für Ihre Lieblingsserie.  1240₽ pro Flasche </td><td>  <b><b>Benutzer:</b></b> Hallo!  Ich möchte vor 2000 Uhr Wein zum Abendessen auswählen <br>  <b>Assistent:</b> Hallo!  Ich kann Ramirez de la Piscina empfehlen.  Um das Beste aus der Torte zu machen, eignet sich der gutaussehende Mann aus Spanien zum Abendessen und für Ihre Lieblingsserie.  1240₽ pro Flasche </td><td>  Bot - ging von Schlüsselwörtern zu wählen + Wein.  Ich habe die Preisspanne nicht verstanden und erneut gefragt.  Assistent - ging für die engste Absicht und ermittelte die Preisspanne. </td></tr><tr><td>  <b>Benutzer:</b> Ich mag keine Torte <br>  <b>Bot:</b> Ihr Kandidat ist Casillero del Diablo Cabernet Sauvignon Reserva <br>  <b>Bot:</b> Chilenischer Sauvignon wird Sie auf jeden Fall wärmen.  Nur 872₽ </td><td>  <b>Benutzer:</b> Ich mag keine Torte <br>  <b>Assistent:</b> Ihr Kandidat ist Antigal, "Uno" Malbec. <br>  <b>Assistent:</b> Ein weicher Argentinier direkt aus dem Jahr 2015. Der Preis für eine Flasche beträgt 20 USD </td><td>  Chatbot wurde nach dem Schlüsselwort "tart" geführt und hat einen Fehler gemacht.  Und der Assistent verstand, dass die Absicht „Ich mag keine Torte“ am ehesten weiche Weine waren. </td></tr><tr><td>  <b>Benutzer:</b> Nun, es ist so günstig.  Ich werde es wahrscheinlich annehmen. <br>  <b>Bot:</b> Dann probieren Sie "FYI" Red Blend <br>  <b>Bot:</b> Trotz der hohen Bewertung liegt der Preis bei nur 10 US-Dollar <br>  <b>Bot:</b> Gute Wahl </td><td>  <b>Benutzer:</b> Nun, es ist so günstig.  Ich werde es wahrscheinlich annehmen. <br>  <b>Assistent:</b> Gute Wahl </td><td>  Roboter-Prozess bietet eine nach der anderen.  Mr. Chatbot sah sich das Wort "günstig" an und antwortete gemäß der Vorlage. Infolgedessen ahnte er es nicht und wurde verwirrt.  Der Assistent ignorierte einfach den ersten Satz, wie er den zweiten verstand. <br></td></tr></tbody></table></div><br><div class="spoiler">  <b class="spoiler_title">Wie es funktioniert: Eine Tabelle, die Chatbots und virtuelle Assistenten vergleicht</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th>  Chat bot </th><th>  Virtueller Assistent </th></tr><tr><td>  Um den Benutzer zu verstehen, verwenden wir Stichwörter. <br>  Beim Erstellen eines Chatbots werden maschinelles Lernen und NLU-Technologien nicht verwendet. <br></td><td>  Um den Benutzer zu verstehen, führen wir einen „intelligenten“ Vergleich durch und wählen die naheliegendste Absicht (etwas später erklären wir, wie es funktioniert). <br>  Maschinelles Lernen und NLU-Algorithmen ermöglichen es uns, den Abstand zwischen Replikaten zu messen.  Zum Beispiel ist der Ausdruck "Raumschiff" näher an "Flugzeug" als "Roller".  Und vom "Verkauf der Niere" - ganz weit weg. </td></tr><tr><td>  <b>Vorbereitung:</b> Für jede Absicht schreiben wir die Schlüsselwörter aus (wine_year_meat: steak, meat, goulash, wine + meat) <br><br>  <b>Algorithmus:</b> <br><ul><li>  Wir übernehmen die Wörter aus dem Nachbau des Benutzers („Wein zum Steak raten“ → beraten, Wein, Steak). </li><li>  Wählen Sie die Absicht, in der die meisten Schlüsselwörter aus dem Replikat des Benutzers stammen (wine_meat_meat). </li><li>  Wenn der Bot keine Kreuzungen anhand von Schlüsselwörtern gefunden hat, wählen wir die Absicht „Wir haben den Benutzer nicht verstanden“. </li><li>  Führen Sie eine Aktion aus, die der Absicht entspricht. </li></ul><br></td><td>  <b>Vorbereitung: Wir</b> trainieren das Modell für intelligente Vergleiche <br><br>  <b>Algorithmus:</b> <br><ul><li>  Vergleichen Sie mithilfe eines intelligenten Vergleichs die Phrasen eines Benutzers mit Phrasen aus Absichten. </li><li>  Wählen Sie die Absicht mit den nächsten Sätzen </li><li>  Wenn die ausgewählte Absicht der Replik des Benutzers nicht nahe genug ist (der Schwellenwert wurde nicht überschritten), wählen wir die Absicht "Wir haben den Benutzer nicht verstanden" aus. </li><li>  Führen Sie eine Aktion aus, die der Absicht entspricht. </li></ul><br></td></tr><tr><td>  <b>Wie man verbessert:</b> <br>  Fügen Sie Befehle und Schaltflächen hinzu, um Fehler zu reduzieren. <br>  Dann hören Benutzer im Allgemeinen auf, in der Sprache zu kommunizieren, und klicken einfach auf die Schaltflächen. <br>  Solche Verbesserungen führen zu einer Verschlechterung der Gesprächsintelligenz. <br></td><td>  <b>Wie man verbessert:</b> <br>  Nachdem die Benutzer mit dem Roboter gesprochen haben, werden wir neue Beispiele für Phrasen haben und diese entsprechend ihren Absichten verteilen. <br>  Mit der Zeit nimmt der Deckungsgrad zu, und der Assistent beginnt, besser mit der Kommunikation umzugehen. <br>  Solche Verbesserungen führen zu einer verbesserten Gesprächsintelligenz. <br></td></tr></tbody></table></div><br></div></div><br><h3>  Stimmt es, dass virtuelle Assistenten die Sprache verstehen? </h3><br>  Algorithmen können einige Ausdrücke von anderen unterscheiden - aber können wir sagen, dass Roboter die Sprache wirklich verstehen? <br><br>  Um diese Frage zu beantworten, kehren wir zu einem Vergleich der lexikalischen Bedeutung von Phrasen zurück.  Die Bedeutung für einen Computer sind verständliche Datentypen: Zeichenfolgen, Zahlen und Kombinationen davon.  Daher steht der Programmierer vor der Aufgabe, den Ausgangstext in eine für mathematische Vergleichsoperationen geeignete Form umzuwandeln - einen Vektor. <br><br><pre><code class="plaintext hljs">vectorize(" ") = (0.004, 17.43, -0.021, ..., 18.68) vectorize("  ") = (0.004, 19.73, -0.001, ..., 25.28) vectorize("  ") = (-8.203, 15.22, -9.253, ..., 10.11) vectorize(" ") = (89.23, -68.99, -10.62, ..., -0.982)</code> </pre> <br>  <i>Für unsere Aufgaben sollten die Vektoren von lexikalisch nahen Phrasen mathematisch nah beieinander liegen, die lexikalisch entfernten sollten weit entfernt sein, der Vektor von Phrasen aus einer anderen Oper sollte sehr weit entfernt sein.</i>  <i>Zum Beispiel steht "Ich möchte Wein" näher bei "Ich möchte Weißwein" als bei "Ich möchte keinen Wein".</i>  <i>Und weit weg von "Marsangriffen".</i> <br><br>  Ein richtig trainiertes neuronales Netzwerk wird in der Lage sein, auf die lexikalische Bedeutung dieser Vektoren zu schließen.  Es stellt sich heraus, dass Sie zum Vergleichen der Bedeutung von zwei Phrasen deren Vektoren vergleichen müssen. <br><br>  Daher lautet die Antwort auf die Frage „Verstehen Roboter die Sprache?“ Wie folgt: Sie verstehen nicht, wie eine Person ist, sie können einfach lexikalische Bedeutungen vergleichen und das Warme nicht mit dem Weichen verwechseln.  Aber wenn die Algorithmen suggestive Verfeinerungen bieten und Schlussfolgerungen ziehen können, sagen wir ehrlich: Ja, das Verständnis ist da.  In der Zwischenzeit ist "die Sprache verstehen" nur eine schöne Marketingphrase. <br><br>  Tatsächlich arbeitet der Roboter nur mit Analogien, wie ein dreijähriges Kind.  Wenn Sie dem Kind jedoch eine ausreichende Anzahl von Beispielen geben, kann es vortäuschen, ein Intellektueller zu sein und eine Diskussion zu führen.  Der "Live" -Operator der ersten Supportlinie arbeitet auf die gleiche Weise - er skizziert eine Reihe von Situationen und teilt ihnen mit, wie sie sich in ihnen verhalten sollen.  Daher eignen sich virtuelle Assistenten gut für die Support-Automatisierung. <br><br><h3>  Wie wir dem Roboter beigebracht haben, den Kontext zu verstehen: Lialang </h3><br>  Für die normale Unterstützung benötigen Roboter nur ein geringes „Verständnis“ der natürlichen Sprache - es ist wichtig, dass sie Fragen beantworten und im Kontext bleiben können.  Zu diesem Zweck haben wir Lialang geschrieben, eine Dialog-Markup-Sprache, in der Skripte beschrieben und an den Roboter übergeben werden können. <br><br>  Die Hauptaufgabe eines Lialang-Programmierers besteht darin, alle Situationen zu beschreiben, die im Dialog zwischen einer Person und einer Maschine auftreten können.  Zu diesem Zweck können Sie in unserer Sprache die Namen von Absichten und Aktionen zuordnen. <br><br>  Betrachten Sie ein einfaches Beispiel - eine Begrüßung: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent() { reaction(_) }</code> </pre> <br>  Es sieht aus wie normaler Code, aber ein neuronales Gitter funktioniert hinter dem Intent-Konstrukt (...) - Lialang beschreibt den Dialog in allgemeinen Mustern („wenn Sie nach etwas gefragt wurden“) unter Verwendung der üblichen Programmierkonstrukte.  Damit dies funktioniert, müssen Sie natürlich maschinelles Lernen und NLU-Technologien anwenden, da der Benutzer seine Anfrage nach Belieben schreiben kann. <br><br><div class="spoiler">  <b class="spoiler_title">Und hier erfahren Sie, wie Sie kontextbezogene Situationen beschreiben.</b> <div class="spoiler_text">  Wir haben das Konstrukt "was" eingeführt, um an einer beliebigen Stelle im Dialog unangemessene Grüße zu erhalten: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent() { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> was_reaction(_) { reaction(___) } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { reaction(_) } }</code> </pre> <br>  Es heißt: Lia, wenn sie dich begrüßt haben, sag hallo als Antwort.  Und wenn sie danach wieder „Hallo“ sagten - sagen Sie, dass Sie bereits Hallo gesagt haben. <br></div></div><br>  Eine Reaktion ist eine Handlung, die Lia als Reaktion auf eine Absicht ausführen muss.  In 95% der Fälle handelt es sich nur um Text.  Aber auch der Roboter kann eine Funktion im Code aufrufen, die Kommunikation zum Bediener umschalten oder andere komplexe Aktionen ausführen. <br><br>  Der Code zum Versenden von Text und Funktionen existiert unabhängig von der Sprache - die Sprache beschreibt Situationen so einfach wie möglich. <br><br>  Versuchen wir nun, etwas Komplizierteres zu schreiben - in einem Chat mit der Bank fragen Kunden häufig nach ihren Details.  Lassen Sie uns lernen, wie man sie mit Lialang zum Chatten und Mailen sendet. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent(_) or intent(___) { reaction(___) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent(__) { reaction(___) } } } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> intent(___) { reaction(___) }</code> </pre> <br>  Hier werden zwei Situationen beschrieben: <br><br><ol><li>  Lia, wenn du gebeten wurdest, die Details zu senden - schicke sie an den Chat.  Wenn sie gefragt haben, "es ist notwendig, die Post", dann senden Sie sie an die Post. </li><li>  Lia, wenn Sie sofort gebeten wurden, die Details an die Mail zu senden - senden Sie die Details an die Mail. </li></ol><br>  Also macht Lialang seine Arbeit - arbeitet im Kontext.  Selbst wenn eine Person "per Post" schreibt, wird der Roboter verstehen, dass es sich um Details handelt. <br><br>  Lia hat gelernt, komplexe Szenarien zu unterstützen - zu der Zeit, die der Benutzer benötigt, wird sie Daten von / zu CRM abrufen / ablegen, SMS senden, beim Bezahlen helfen oder über das Leben sprechen. <br><br>  Allmählich verbesserten wir die Sprache: Wir fügten Variablen, Funktionen, Entitäten (Daten, Adressen, Telefonnummern, Namen usw.), Zustände und andere nützliche Konstrukte hinzu.  So wurde es noch bequemer, darauf zu schreiben. <br><br><h3>  Fallbeispiel: Wie wir den Support in drei Banken automatisiert haben </h3><br>  Sobald wir die Technologie hergestellt hatten, musste sie dringend fertiggestellt werden - wir hatten unseren ersten Kunden.  VTB musste den Support in einer neuen Internetbank für Unternehmer automatisieren. <br><br>  Wir sind sehr erfolgreich gestartet - vor allem für ein Produkt, das in vier Monaten entwickelt wurde.  Unser Hybridroboter für VTB basierte auf neuronalen Netzen und war sofort wirksam: Er beantwortete mehr als 800 Fragen, unterstützte mehrere komplexe Szenarien (Aussagen, Tarifänderungen, Benutzereinstellungen) und sprach wie eine Person.  Infolgedessen reduzierte unser Lia in zwei Monaten die Stützlast um 74%.  Es wurde klar: Die Idee mit Support-Automatisierung funktioniert. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c63/1d6/1d3/c631d61d34e155c0e3e67b7fe354b29c.png" alt="Bild"><br><br>  Auf Basis von Lia haben wir die FAQ bei Rocketbank und DeloBank automatisiert - und in zwei Wochen haben sie 32% der Anträge ohne Bediener geschlossen. <br><br>  Es scheint, dass die Jungs zum Erfolg kamen.  Nach den ersten Kunden wurde jedoch klar, dass das Konzept geändert werden musste.  Es war die Hölle - wir mussten die Skripte manuell modifizieren, Änderungen vornehmen, die Zweige entwickeln.  Dasselbe gilt für einfache Bots, die nur härter sind und mehr Kraft erfordern.  In dieser Situation war es schwierig zu skalieren. <br><br>  Dann haben wir beschlossen, ein Werkzeug zu entwickeln, mit dem der Kunde selbst einen komplexen Assistenten zusammenstellen kann.  Und wir werden nur mit Tutorials helfen und Benutzer erziehen. <br><br><h3>  Lia Platform und Engine für Interfaces </h3><br>  Deshalb haben wir beschlossen, eine <a href="https://lia.chat/">Plattform</a> für diejenigen zu schaffen, die die Entwicklung nicht verstehen.  Obwohl Lialang weniger als zehn verschiedene Designs enthält, wird nicht jeder Manager lernen, einen eigenen Bot zu erstellen.  Manager lieben die Maus. <br><br>  Deshalb haben wir begonnen, über eine solche Schnittstelle nachzudenken, die alles kann, was Lialang kann.  Er wird keine Probleme mit verschachtelten Verzweigungen, Übergängen von einem Skript zu einem anderen haben und vor allem - nicht nur unsere Programmierer, sondern alle, die Skripte erstellen möchten. <br><br>  <b>Sehen Sie, wie es aussieht:</b> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/de6/bf6/aed/de6bf6aeda231d7af48c7a7973e72692.gif" alt="Lia patform"><br>  <i>Dialoge sind eine nichtlineare Sache und das Schreiben einer universellen Engine für alle Arten von Konversationsschemata ist sehr schwierig.</i>  <i>Aber bevor wir über die Pläne nachdachten, hatten wir bereits Lialang - es wurde zum Motor.</i> <br><br>  Was auch immer sich Interface-Designer ausgedacht haben mögen, wir programmieren keine Köpfe dafür, sondern schreiben nur einen kleinen Übersetzer für Markups vom Interface zum Lialang-Code.  Wenn die Schnittstelle erneuert wird, müssen wir nur den Übersetzer ändern - dank dessen können der Schnittstellenbefehl und der Kernbefehl getrennt existieren. <br><br><h3>  Wie funktioniert die Plattform zur Erstellung virtueller Assistenten? </h3><br>  Um Ihren eigenen virtuellen Assistenten in Lia zusammenzustellen, muss der Benutzer drei Phasen durchlaufen. <br><br><h4>  Schritt 1. Laden Sie den Chatverlauf mit den Benutzern herunter, damit der Roboter die Hauptszenarien versteht und hervorhebt </h4><br>  Wenn der Client bereits Gespräche mit Benutzern geführt hat, kann er diese auf das System hochladen und Cluster aus den beliebtesten Abfragen abrufen.  Es wird sehr praktisch sein, aus ihnen Absichten zu machen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cff/782/ad9/cff782ad9a1ad00149d87941414e25b4.png" alt="Ein Beispiel für das Nichtwissen des Benutzers"><br><br>  Mit der Zeit wird die Wirksamkeit von Lia zunehmen.  Nachrichten, die der Roboter nicht beantworten konnte, werden erneut in Gruppen aufgeteilt: "Wer bist du?", "Wer bist du?", "Wie heißt du?" Und "Bist du ein Roboter?"  Die Plattform lernt also halbautomatisch selbst: Der Benutzer erkennt, wo die Lücke ist, schließt sie und fügt neue Szenarien hinzu. Infolgedessen steigt der Prozentsatz der gedeckten Anfragen in sechs Monaten von 30% auf 70%. <br><br>  Wenn kein Korrespondenzverlauf vorhanden ist, überspringen wir diesen Schritt und beginnen sofort mit dem zweiten Schritt: Wir sagen voraus, welche Anforderungen Benutzer an den Assistenten senden. <br><br><h4>  Schritt 2. Wir notieren die Absicht: 10-20 Optionen für die häufigsten Benutzeranforderungen </h4><br>  In der zweiten Phase schreiben wir Absichten basierend auf den 10-20 beliebtesten Abfragen vor: Diese Anzahl von Optionen ist dank neuronaler Netze ausreichend.  Ein Ausdruck wie "Ich möchte Wein bestellen" lehrt den Bot, ähnliche Benutzeranforderungen zu erkennen: zum Beispiel "Wein holen" oder "Wein bestellen". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6f7/be3/2b8/6f7be32b83ba8c3e1a697a8a2602b3c2.png" alt="Beispiel für beabsichtigtes Markup"><br><br>  Ein anderer Assistent versteht und extrahiert das Wesentliche: Städtenamen, Telefonnummern, Adressen, Zeitstempel, Zeiträume, Daten und Flüche - auch wenn Sie sagen: „Müde, bringen Sie morgen eine Schachtel Wein mit“. <br><br>  Darüber hinaus können Benutzer eigene Objekte hinzufügen und Trainingssätze manuell markieren, damit der Assistent schneller lernt.  Dies ist eine der leistungsstärksten Funktionen der Plattform, dank derer Roboter geschaffen werden können, die nicht schlechter funktionieren als ein menschlicher Bediener. <br><br><h4>  Schritt 3. Erstellen Sie ein Szenario: Geben Sie mehrere Antworten oder Aktionen vor </h4><br>  Hier muss der Benutzer Antworten auf Benutzeranfragen finden.  95% des durchschnittlichen Projekts verwenden normalerweise ein einfaches Frage-Antwort-Szenario - Antworten auf häufig gestellte Fragen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f32/068/532/f32068532a574a7debc8bbbb4960d083.png" alt="Bild"><br><br>  Übrigens kann der Assistent mit Bildern, Videos und Audiodateien antworten und bei Bedarf eine Geolocation senden. <br><br>  Der Konstruktionssprung ist besonders nützlich - dank ihm kann Lia von einem Szenario zu einem anderen wechseln und dann zurückkehren, um mehrere Probleme zu lösen.  Dies ist nützlich, wenn Sie im Dialogfeld einen Schritt zurücktreten und dann zum richtigen Titel zurückkehren müssen: Stellen Sie beispielsweise eine klärende Frage. <br><br>  <b>Beispieldialog springen zu:</b> <br><br>  Assistent: Wir müssen die Lieferadresse klären, da der Empfänger nicht antwortet. <br>  Kunde: Und worüber?  Welche Bestellung?  (JumpTo zur Auftragsklärung) <br>  Assistent: Order 21. August, Antigal, "Uno" Malbec. <br>  Assistent: Können wir also die aktuelle Lieferadresse klären?  (Zurück zum Hauptskript) <br><br>  Wenn der Ersteller möchte, dass sein Assistent nicht nur mit Text antwortet, sondern Aktionen ausführt, kann er einen Programmierer anrufen, um JS-Ausschnitte für den Spezialisten zu schreiben.  Sie können JavaScript direkt während des Skripts ausführen: Greifen Sie auf die externe API zu, senden Sie eine E-Mail oder führen Sie andere komplexe Aktionen aus. <br><br><h3>  4. Zusammenfassung </h3><br>  Ein Assistent kann sich in alles integrieren: mit einer Person am Telefon, in Instant Messenger oder einem Widget, das der Kunde auf der Website veröffentlicht, sprechen. <br><br>  Das Zusammenbauen eines intelligenten Assistenten in der Plattform dauert ein paar Stunden bis zu einem Monat.  Dann lernt der Roboter, Anforderungen realistisch zu verstehen und Muster zu erkennen - es dauert ungefähr sechs Monate (die ganze Zeit über wacht eine lebende Person darüber).  Unternehmen können die meisten Routineaufgaben für das Lia-Robotermädchen erledigen: von der Koordination der Zustellung und der Bestellung eines Taxis bis hin zur Beratung der Kunden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3e1/87a/d17/3e187ad17975ec5c222949ff4b907784.png" alt="Beispiel für einen Chat mit Virtual Wine Assistant"><br><br>  Übrigens haben wir bereits Projekte mit Banken auf die Plattform übertragen.  Sie funktionieren genauso gut, werden aber viel komfortabler moderiert. <br><br>  In naher Zukunft planen wir, Extraktoren hinzuzufügen, mit denen unsere Benutzer komplexere Daten extrahieren können (der Roboter wird beispielsweise den Ausdruck "übermorgen nach dem Mittagessen" verstehen).  Wir werden auch die Versionskontrolle abschließen, damit Kunden Versionen von Projekten schnell rollen und zurücksetzen können.  Außerdem werden wir das Rollensystem der Organisation freisetzen. <br><br>  Wir gehen davon aus, dass die <a href="https://www.ibm.com/blogs/watson/2017/10/how-chatbots-reduce-customer-service-costs-by-30-percent/">Prognosen</a> von Gartner korrekt sind - und im Jahr 2022 werden bis zu 70% aller Kundeninteraktionen eine Art KI durchlaufen.  Nach unserer Vorstellung werden Designer wie Lia dabei helfen, den Kundenservice noch schneller auf Roboter zu übertragen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de478572/">https://habr.com/ru/post/de478572/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de478552/index.html">Zweites Applet, Schließen und transparente Schaltflächen in Verarbeitung 3</a></li>
<li><a href="../de478554/index.html">Webinar "SRE - Hype oder die Zukunft?" 12. Dezember um 11:00 Uhr</a></li>
<li><a href="../de478560/index.html">Sind kostenlose Instant Messenger anonym?</a></li>
<li><a href="../de478564/index.html">Wie wir bei TsIAN Terabytes an Protokollen gezähmt haben</a></li>
<li><a href="../de478566/index.html">iOS Netzwerk, wenn die Anwendung nicht ausgeführt wird</a></li>
<li><a href="../de478574/index.html">Die Wahrheit über Eisenbahnbremsen: Teil 4 - Fahrgastbremsen</a></li>
<li><a href="../de478582/index.html">Globaler VPN-Bericht über mobile Geräte im Jahr 2019</a></li>
<li><a href="../de478584/index.html">JVM-Interna, Teil 2 - Dateistruktur der Klasse</a></li>
<li><a href="../de478586/index.html">Ineffizienz</a></li>
<li><a href="../de478590/index.html">Sind Sie sicher, dass Sie Microservices verwenden?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
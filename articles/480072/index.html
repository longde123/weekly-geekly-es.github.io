<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèø üëêüèø üôèüèª Kubernetes: ¬øpor qu√© es tan importante configurar la gesti√≥n de recursos del sistema? üî∂ ‚è±Ô∏è üê°</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Como regla general, siempre existe la necesidad de proporcionar un conjunto de recursos dedicado a cualquier aplicaci√≥n para su funcionamiento correct...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes: ¬øpor qu√© es tan importante configurar la gesti√≥n de recursos del sistema?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nixys/blog/480072/"><p>  Como regla general, siempre existe la necesidad de proporcionar un conjunto de recursos dedicado a cualquier aplicaci√≥n para su funcionamiento correcto y estable.  Pero, ¬øqu√© pasa si varias aplicaciones funcionan con las mismas capacidades a la vez?  ¬øC√≥mo proporcionar los recursos m√≠nimos necesarios para cada uno de ellos?  ¬øC√≥mo puedo limitar el consumo de recursos?  ¬øC√≥mo distribuir correctamente la carga entre nodos?  ¬øC√≥mo garantizar el mecanismo de escala horizontal en caso de aumento de carga en la aplicaci√≥n? </p><br><p><img src="https://habrastorage.org/webt/-f/yj/hw/-fyjhwhkhcibnshgzndgd4w4e_c.png"></p><a name="habracut"></a><br><p>  Debe comenzar con qu√© tipos b√°sicos de recursos existen en el sistema: esto, por supuesto, el tiempo de procesador y la RAM.  En los manifiestos de k8, estos tipos de recursos se miden en las siguientes unidades: </p><br><ul><li>  CPU - en los n√∫cleos </li><li>  RAM - en bytes </li></ul><br><p>  Adem√°s, para cada recurso existe la oportunidad de establecer dos tipos de requisitos: <strong>solicitudes</strong> y <strong>l√≠mites</strong> .  Solicitudes: describe los requisitos m√≠nimos para que los recursos libres del nodo ejecuten el contenedor (y el hogar como un todo), mientras que limit establece un l√≠mite estricto en los recursos disponibles para el contenedor. </p><br><p>  Es importante comprender que en el manifiesto no es necesario definir expl√≠citamente ambos tipos, y el comportamiento ser√° el siguiente: </p><br><ul><li>  Si solo los l√≠mites del recurso se establecen expl√≠citamente, las solicitudes de este recurso toman autom√°ticamente un valor igual a los l√≠mites (esto se puede verificar llamando a describir entidades).  Es decir  de hecho, la operaci√≥n del contenedor estar√° limitada por la misma cantidad de recursos que requiere para ejecutarse. </li><li>  Si solo las solicitudes se establecen expl√≠citamente para un recurso, entonces no se establecen restricciones sobre este recurso, es decir  el contenedor est√° limitado solo por los recursos del nodo en s√≠. </li></ul><br><p>  Tambi√©n es posible configurar la gesti√≥n de recursos no solo a nivel de un contenedor espec√≠fico, sino tambi√©n a nivel de espacio de nombres utilizando las siguientes entidades: </p><br><ul><li>  <strong>LimitRange</strong> : describe la pol√≠tica de restricci√≥n a nivel de contenedor / hogar en ns y es necesaria para describir las restricciones predeterminadas en el contenedor / hogar, as√≠ como para evitar la creaci√≥n de contenedores / hogares obviamente gordos (o viceversa), limite su n√∫mero y determine la posible diferencia entre los l√≠mites y solicitudes </li><li>  <strong>ResourceQuotas</strong> : describe la pol√≠tica de restricci√≥n en general para todos los contenedores en ns y se usa, por regla general, para diferenciar recursos entre entornos (√∫til cuando los entornos no est√°n delimitados r√≠gidamente a nivel de nodos) </li></ul><br><p>  Los siguientes son ejemplos de manifiestos donde se establecen l√≠mites de recursos: </p><br><ul><li><p>  En el nivel de contenedor espec√≠fico: </p><br><pre><code class="plaintext hljs">containers: - name: app-nginx image: nginx resources: requests: memory: 1Gi limits: cpu: 200m</code> </pre> <br><p>  Es decir  en este caso, para iniciar un contenedor con nginx, necesitar√° al menos la presencia de 1G OP y 0.2 CPU libres en el nodo, mientras que el contenedor m√°ximo puede consumir 0.2 CPU y todos los OP disponibles en el nodo. </p><br></li><li><p>  En el nivel entero ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: ResourceQuota metadata: name: nxs-test spec: hard: requests.cpu: 300m requests.memory: 1Gi limits.cpu: 700m limits.memory: 2Gi</code> </pre> <br><p>  Es decir  la suma de todos los contenedores de solicitud en los ns predeterminados no puede exceder los 300 m para la CPU y 1G para el OP, y la suma de todos los l√≠mites es 700 m para la CPU y 2G para el OP. </p><br></li><li><p>  Restricciones predeterminadas para contenedores en ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-per-container spec: limits: - type: Container defaultRequest: cpu: 100m memory: 1Gi default: cpu: 1 memory: 2Gi min: cpu: 50m memory: 500Mi max: cpu: 2 memory: 4Gi</code> </pre> <br><p>  Es decir  en el espacio de nombres predeterminado para todos los contenedores, por defecto, la solicitud se establecer√° en 100 m para la CPU y 1G para el OP, l√≠mite - 1 CPU y 2G.  Al mismo tiempo, tambi√©n se estableci√≥ una restricci√≥n sobre los posibles valores en la solicitud / l√≠mite para la CPU (50m &lt;x &lt;2) y RAM (500M &lt;x &lt;4G). </p><br></li><li><p>  Limitaciones en el nivel de hogar ns: </p><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: LimitRange metadata: name: nxs-limit-pod spec: limits: - type: Pod max: cpu: 4 memory: 1Gi</code> </pre> <br><p>  Es decir  para cada hogar en el ns predeterminado, se establecer√° un l√≠mite de 4 vCPU y 1G. </p><br></li></ul><br><p>  Ahora me gustar√≠a decirle qu√© ventajas puede brindarnos la instalaci√≥n de estas restricciones. </p><br><h2 id="mehanizm-balansirovki-nagruzki-mezhdu-nodami">  El mecanismo de equilibrio de carga entre nodos. </h2><br><p>  Como saben, el componente k8s, como el <strong>planificador</strong> , que funciona de acuerdo con cierto algoritmo, es responsable de la distribuci√≥n de los hogares sobre los nodos.  Este algoritmo en el proceso de elegir el nodo √≥ptimo para ejecutar pasa por dos etapas: </p><br><ol><li>  Filtrado </li><li>  Ranking </li></ol><br><p>  Es decir  de acuerdo con la pol√≠tica descrita, los nodos se seleccionan inicialmente en los que se puede iniciar un hogar en funci√≥n de un conjunto de <strong>predicados</strong> (incluido si el nodo tiene suficientes recursos para ejecutar un hogar - PodFitsResources), y luego se otorgan puntos para cada uno de estos nodos, de acuerdo con las <strong>prioridades</strong> (incluyendo, cuantos m√°s recursos libres tenga un nodo, m√°s puntos se le asignan, LeastResourceAllocation / LeastRequestedPriority / BalancedResourceAllocation) y se ejecuta en el nodo con m√°s puntos (si varios nodos satisfacen esta condici√≥n a la vez, se selecciona uno aleatorio). </p><br><p>  Al mismo tiempo, debe comprender que el planificador, al evaluar los recursos disponibles del nodo, se centra en los datos almacenados en etcd, es decir,  por la cantidad del recurso solicitado / l√≠mite de cada pod que se ejecuta en este nodo, pero no por el consumo real de recursos.  Esta informaci√≥n se puede obtener en la salida del <code>kubectl describe node $NODE</code> , por ejemplo: </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># kubectl describe nodes nxs-k8s-s1 .. Non-terminated Pods: (9 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits AGE --------- ---- ------------ ---------- --------------- ------------- --- ingress-nginx nginx-ingress-controller-754b85bf44-qkt2t 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-flannel-26bl4 150m (0%) 300m (1%) 64M (0%) 500M (1%) 233d kube-system kube-proxy-exporter-cb629 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system kube-proxy-x9fsc 0 (0%) 0 (0%) 0 (0%) 0 (0%) 233d kube-system nginx-proxy-k8s-worker-s1 25m (0%) 300m (1%) 32M (0%) 512M (1%) 233d nxs-monitoring alertmanager-main-1 100m (0%) 100m (0%) 425Mi (1%) 25Mi (0%) 233d nxs-logging filebeat-lmsmp 100m (0%) 0 (0%) 100Mi (0%) 200Mi (0%) 233d nxs-monitoring node-exporter-v4gdq 112m (0%) 122m (0%) 200Mi (0%) 220Mi (0%) 233d Allocated resources: (Total limits may be over 100 percent, ie, overcommitted.) Resource Requests Limits -------- -------- ------ cpu 487m (3%) 822m (5%) memory 15856217600 (2%) 749976320 (3%) ephemeral-storage 0 (0%) 0 (0%)</span></span></code> </pre> <br><p>  Aqu√≠ vemos todos los pods que se ejecutan en un nodo en particular, as√≠ como los recursos que cada uno de ellos solicita.  Y as√≠ es como se ven los registros del planificador al iniciar el pod cronjob-cron-events-1573793820-xt6q9 (esta informaci√≥n aparece en el registro del planificador al establecer el d√©cimo nivel de inicio de sesi√≥n en los argumentos del comando de inicio --v = 10): </p><br><div class="spoiler">  <b class="spoiler_title">gaviota ancha</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">I1115 07:57:21.637791 1 scheduling_queue.go:908] About to try and schedule pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.637804 1 scheduler.go:453] Attempting to schedule pod: nxs-stage/cronjob-cron-events-1573793820-xt6q9 I1115 07:57:21.638285 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s5 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638300 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s6 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s3 is allowed, Node is running only 20 out of 110 Pods. I1115 07:57:21.638322 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s4 is allowed, Node is running only 17 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638365 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s12 is allowed, Node is running only 9 out of 110 Pods. I1115 07:57:21.638334 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s11 is allowed, Node is running only 11 out of 110 Pods. I1115 07:57:21.638385 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s1 is allowed, Node is running only 19 out of 110 Pods. I1115 07:57:21.638402 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s2 is allowed, Node is running only 21 out of 110 Pods. I1115 07:57:21.638383 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, Node is running only 16 out of 110 Pods. I1115 07:57:21.638335 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, Node is running only 18 out of 110 Pods. I1115 07:57:21.638408 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s13 is allowed, Node is running only 8 out of 110 Pods. I1115 07:57:21.638478 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s10 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638505 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s8 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638577 1 predicates.go:1369] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s9 is allowed, existing pods anti-affinity terms satisfied. I1115 07:57:21.638583 1 predicates.go:829] Schedule Pod nxs-stage/cronjob-cron-events-1573793820-xt6q9 on Node nxs-k8s-s7 is allowed, Node is running only 25 out of 110 Pods. I1115 07:57:21.638932 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 9 I1115 07:57:21.638946 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 2343 millicores 9640186880 memory bytes, score 8 I1115 07:57:21.638961 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: BalancedResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 9 I1115 07:57:21.638971 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: BalancedResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.638975 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: LeastResourceAllocation, capacity 39900 millicores 66620170240 memory bytes, total request 4107 millicores 11307422720 memory bytes, score 8 I1115 07:57:21.638990 1 resource_allocation.go:78] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: LeastResourceAllocation, capacity 39900 millicores 66620178432 memory bytes, total request 5847 millicores 24333637120 memory bytes, score 7 I1115 07:57:21.639022 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: TaintTolerationPriority, Score: (10) I1115 07:57:21.639030 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: TaintTolerationPriority, Score: (10) I1115 07:57:21.639034 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: TaintTolerationPriority, Score: (10) I1115 07:57:21.639041 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: NodeAffinityPriority, Score: (0) I1115 07:57:21.639053 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: NodeAffinityPriority, Score: (0) I1115 07:57:21.639059 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: NodeAffinityPriority, Score: (0) I1115 07:57:21.639061 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639063 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639073 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639077 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639085 1 interpod_affinity.go:237] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: InterPodAffinityPriority, Score: (0) I1115 07:57:21.639088 1 selector_spreading.go:146] cronjob-cron-events-1573793820-xt6q9 -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639103 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s10: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639109 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s8: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639114 1 generic_scheduler.go:726] cronjob-cron-events-1573793820-xt6q9_nxs-stage -&gt; nxs-k8s-s9: SelectorSpreadPriority, Score: (10) I1115 07:57:21.639127 1 generic_scheduler.go:781] Host nxs-k8s-s10 =&gt; Score 100037 I1115 07:57:21.639150 1 generic_scheduler.go:781] Host nxs-k8s-s8 =&gt; Score 100034 I1115 07:57:21.639154 1 generic_scheduler.go:781] Host nxs-k8s-s9 =&gt; Score 100037 I1115 07:57:21.639267 1 scheduler_binder.go:269] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10" I1115 07:57:21.639286 1 scheduler_binder.go:279] AssumePodVolumes for pod "nxs-stage/cronjob-cron-events-1573793820-xt6q9", node "nxs-k8s-s10": all PVCs bound and nothing to do I1115 07:57:21.639333 1 factory.go:733] Attempting to bind cronjob-cron-events-1573793820-xt6q9 to nxs-k8s-s10</code> </pre> </div></div><br><p>  Aqu√≠ vemos que inicialmente el planificador realiza el filtrado y forma una lista de 3 nodos en los que es posible ejecutar (nxs-k8s-s8, nxs-k8s-s9, nxs-k8s-s10).  Luego calcula los puntos de acuerdo con varios par√°metros (incluyendo BalancedResourceAllocation, LeastResourceAllocation) para cada uno de estos nodos para determinar el nodo m√°s adecuado.  Al final, se planifica bajo el nodo con la mayor cantidad de puntos (aqu√≠, dos nodos a la vez tienen el mismo n√∫mero de puntos 100037, por lo que se selecciona uno aleatorio: nxs-k8s-s10). </p><br><p>  <strong>Conclusi√≥n</strong> : si los pods funcionan en el nodo para el que no hay restricciones, entonces para k8s (desde el punto de vista del consumo de recursos) esto ser√° equivalente a si dichos pods estuvieran completamente ausentes en este nodo.  Por lo tanto, si tiene una vaina condicionalmente con un proceso voraz (por ejemplo, wowza) y no hay restricciones para ello, entonces puede surgir una situaci√≥n cuando, de hecho, el dado ha consumido todos los recursos del nodo, pero para k8s este nodo se considera descargado y se le otorgar√° el mismo n√∫mero de puntos al clasificar (es decir, en puntos con una evaluaci√≥n de los recursos disponibles), as√≠ como un nodo que no tiene campos de trabajo, lo que en √∫ltima instancia puede conducir a una distribuci√≥n desigual de la carga entre los nodos. </p><br><h2 id="vyselenie-poda">  Desalojo del hogar </h2><br><p>  Como sabe, a cada uno de los pods se le asigna una de las 3 clases de QoS: </p><br><ol><li>  <strong>garantizado</strong> : se asigna cuando la solicitud y el l√≠mite se establecen para cada contenedor en el hogar para memoria y CPU, y estos valores deben coincidir </li><li>  <strong>burstable</strong> : al menos un contenedor en el hogar tiene solicitud y l√≠mite, mientras que solicitud &lt;l√≠mite </li><li>  <strong>mejor esfuerzo</strong> : cuando ning√∫n recipiente en el hogar tiene recursos limitados </li></ol><br><p>  Al mismo tiempo, cuando hay una escasez de recursos (disco, memoria) en el nodo, kubelet comienza a clasificar y expulsar los pods de acuerdo con un cierto algoritmo que tiene en cuenta la prioridad del pod y su clase de QoS.  Por ejemplo, si estamos hablando de RAM, entonces, seg√∫n la clase de QoS, los puntos se otorgan de acuerdo con el siguiente principio: </p><br><ul><li>  <strong>Garantizado</strong> : -998 </li><li>  <strong>Mejor esfuerzo</strong> : 1000 </li><li>  <strong>Burstable</strong> : min (max (2, 1000 - (1000 * memoryRequestBytes) / machineMemoryCapacityBytes), 999) </li></ul><br><p>  Es decir  con la misma prioridad, kubelet primero expulsar√° las vainas con el mejor esfuerzo de la clase de QoS del nodo. </p><br><p>  <strong>Conclusi√≥n</strong> : si desea reducir la probabilidad de desalojo del nodo necesario del nodo en caso de recursos insuficientes, entonces, junto con la prioridad, tambi√©n debe ocuparse de establecer la solicitud / l√≠mite para √©l. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-podov-prilozheniya-hpa">  Mecanismo de escalamiento horizontal horizontal de hogar (HPA) </h2><br><p>  Cuando la tarea es aumentar y disminuir autom√°ticamente el n√∫mero de pod dependiendo del uso de recursos (sistema - CPU / RAM o usuario - rps), k8 como <strong>HPA</strong> (Horizontal Pod Autoscaler) pueden ayudar en su soluci√≥n.  El algoritmo de los cuales es el siguiente: </p><br><ol><li>  Se determinan las lecturas actuales del recurso observado (currentMetricValue) </li><li>  Se determinan los valores deseados para el recurso (nedMetricValue), que se establecen para los recursos del sistema mediante solicitud </li><li>  Se determina el n√∫mero actual de r√©plicas (currentReplicas) </li><li>  La siguiente f√≥rmula calcula el n√∫mero deseado de r√©plicas (r√©plicas deseadas) <br>  desiredReplicas = [currentReplicas * (currentMetricValue / desiredMetricValue)] </li></ol><br><p>  Sin embargo, la escala no ocurrir√° cuando el coeficiente (currentMetricValue / deseadoMetricValue) est√© cerca de 1 (podemos establecer el error permitido nosotros mismos, por defecto es 0.1). </p><br><p>  Considere hpa usando la aplicaci√≥n de prueba de aplicaci√≥n (descrita como Implementaci√≥n), donde es necesario cambiar el n√∫mero de r√©plicas, dependiendo del consumo de CPU: </p><br><ul><li><p>  Manifiesto de solicitud </p><br><pre> <code class="plaintext hljs">kind: Deployment apiVersion: apps/v1beta2 metadata: name: app-test spec: selector: matchLabels: app: app-test replicas: 2 template: metadata: labels: app: app-test spec: containers: - name: nginx image: registry.nixys.ru/generic-images/nginx imagePullPolicy: Always resources: requests: cpu: 60m ports: - name: http containerPort: 80 - name: nginx-exporter image: nginx/nginx-prometheus-exporter resources: requests: cpu: 30m ports: - name: nginx-exporter containerPort: 9113 args: - -nginx.scrape-uri - http://127.0.0.1:80/nginx-status</code> </pre> <br><p>  Es decir  vemos que debajo de la aplicaci√≥n se inicia inicialmente en dos instancias, cada una de las cuales contiene dos contenedores nginx y nginx-exporter, para cada una de las cuales se dan <strong>solicitudes</strong> para la CPU. </p><br></li><li><p>  Manifiesto de HPA </p><br><pre> <code class="plaintext hljs">apiVersion: autoscaling/v2beta2 kind: HorizontalPodAutoscaler metadata: name: app-test-hpa spec: maxReplicas: 10 minReplicas: 2 scaleTargetRef: apiVersion: extensions/v1beta1 kind: Deployment name: app-test metrics: - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 30</code> </pre> <br><p>  Es decir  creamos un hpa que supervisar√° la prueba de implementaci√≥n de la aplicaci√≥n y ajustar√° el n√∫mero de hogares con la aplicaci√≥n en funci√≥n del indicador de la CPU (esperamos que el hogar consuma el 30% de la CPU solicitada por este), mientras que el n√∫mero de r√©plicas est√° en el rango de 2-10. </p><br><p>  Ahora, consideraremos el mecanismo de operaci√≥n hpa si aplicamos una carga a uno de los hogares: </p><br><pre> <code class="bash hljs"> <span class="hljs-comment"><span class="hljs-comment"># kubectl top pod NAME CPU(cores) MEMORY(bytes) app-test-78559f8f44-pgs58 101m 243Mi app-test-78559f8f44-cj4jz 4m 240Mi</span></span></code> </pre> <br></li></ul><br><p>  Total tenemos lo siguiente: </p><br><ul><li>  Valor deseado (deseadoMetricValue): de acuerdo con la configuraci√≥n de hpa, tenemos un 30% </li><li>  Valor actual (currentMetricValue): para el c√°lculo, el controlador-administrador calcula el valor promedio del consumo de recursos en%, es decir  condicionalmente hace lo siguiente: <br><ol><li>  Obtiene los valores absolutos de las m√©tricas de hogar del servidor de m√©tricas, es decir  101m y 4m </li><li>  Calcula el valor absoluto promedio, es decir  (101m + 4m) / 2 = 53m </li><li>  Obtiene el valor absoluto para el consumo de recursos deseado (para esto, se suma la solicitud de todos los contenedores) 60m + 30m = 90m </li><li>  Calcula el porcentaje promedio de consumo de CPU en relaci√≥n con el hogar de solicitud, es decir  53m / 90m * 100% = 59% </li></ol></li></ul><br><p>  Ahora tenemos todo lo necesario para determinar si es necesario cambiar el n√∫mero de r√©plicas, para esto calculamos el coeficiente: </p><br><p> <code>ratio = 59% / 30% = 1.96</code> </p> <br><p>  Es decir  el n√∫mero de r√©plicas debe aumentarse ~ 2 veces y completar [2 * 1.96] = 4. </p><br><p>  <strong>Conclusi√≥n:</strong> Como puede ver, para que este mecanismo funcione, un requisito previo es incluir la disponibilidad de solicitudes para todos los contenedores en el hogar observado. </p><br><h2 id="mehanizm-gorizontalnogo-avtomasshtabirovaniya-nod-cluster-autoscaler">  El mecanismo de autoescalado horizontal de nodos (Cluster Autoscaler) </h2><br><p>  Para neutralizar el impacto negativo en el sistema durante r√°fagas de carga, la presencia de un hpa sintonizado no es suficiente.  Por ejemplo, de acuerdo con la configuraci√≥n en el administrador del controlador hpa, decide que la cantidad de r√©plicas debe aumentarse 2 veces, sin embargo, no hay recursos libres en los nodos para ejecutar tal cantidad de pods (es decir, el nodo no puede proporcionar los recursos solicitados para las solicitudes de pod) y estos pods entrar en el estado pendiente. </p><br><p>  En este caso, si el proveedor tiene el IaaS / PaaS apropiado (por ejemplo, GKE / GCE, AKS, EKS, etc.), una herramienta como <strong>Node Autoscaler</strong> puede ayudarnos.  Le permite establecer el n√∫mero m√°ximo y m√≠nimo de nodos en el cl√∫ster y ajustar autom√°ticamente el n√∫mero actual de nodos (accediendo a la API del proveedor de la nube para ordenar / eliminar nodos) cuando hay escasez de recursos en el cl√∫ster y los pods no se pueden programar (en el estado Pendiente). </p><br><p>  <strong>Conclusi√≥n:</strong> para poder escalar autom√°ticamente los nodos, es necesario especificar solicitudes en los contenedores de hogares para que k8s pueda evaluar correctamente la carga de nodos y, en consecuencia, informar que no hay recursos en el cl√∫ster para iniciar el pr√≥ximo hogar. </p><br><hr><br><h2 id="zaklyuchenie">  Conclusi√≥n </h2><br><p>  Cabe se√±alar que establecer l√≠mites de recursos para el contenedor no es un requisito previo para el lanzamiento exitoso de la aplicaci√≥n, pero es mejor hacerlo por las siguientes razones: </p><br><ol><li>  Para una operaci√≥n m√°s precisa del planificador en t√©rminos de equilibrio de carga entre nodos k8s </li><li>  Para reducir la probabilidad de un evento de desalojo del hogar </li><li>  Para hogares de aplicaci√≥n de escala autom√°tica horizontal (HPA) </li><li>  Para el autoescalado horizontal de nodos (Cluster Autoscaling) para proveedores en la nube </li></ol><br><h2 id="takzhe-chitayte-drugie-stati-v-nashem-bloge">  Lea tambi√©n otros art√≠culos en nuestro blog: </h2><br><ul><li>  <a href="https://habr.com/ru/company/nixys/blog/481992/">Tuber√≠a Tekton - Tuber√≠as nativas de Kubernetes</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/473578/">Construyendo M√≥dulos Din√°micos para Nginx</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/468779/">¬øCu√°l fue el resultado de la migraci√≥n de ClickHouse sin autorizaci√≥n a ClickHouse con autorizaci√≥n?</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/461723/">Comprender el paquete de contexto en Golang</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/437372/">Tres trucos simples para reducir las im√°genes acoplables</a> </li><li>  <a href="https://habr.com/ru/company/nixys/blog/424717/">Copia de seguridad de una gran cantidad de proyectos web heterog√©neos</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/480072/">https://habr.com/ru/post/480072/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../480060/index.html">Clasificador simple P300 en datos abiertos</a></li>
<li><a href="../480062/index.html">10 sistemas de control. ¬øD√≥nde es m√°s conveniente comunicarse sobre tareas y compartir archivos?</a></li>
<li><a href="../480064/index.html">Aprender palabras agrupadas tem√°ticamente</a></li>
<li><a href="../480068/index.html">[Actualizaci√≥n] Nuestra gente es golpeada, y estaremos en silencio?</a></li>
<li><a href="../480070/index.html">Reaccionar beneficios: ¬øuna bendici√≥n para las empresas?</a></li>
<li><a href="../480076/index.html">Multiprocesamiento y conciliaci√≥n de datos de varias fuentes.</a></li>
<li><a href="../480078/index.html">Nuevas bibliotecas front-end en los perif√©ricos React</a></li>
<li><a href="../480080/index.html">¬øQu√© necesitas en las aplicaciones para tomar notas?</a></li>
<li><a href="../480082/index.html">Uso de particiones en MySQL para Zabbix con una gran cantidad de objetos de monitoreo</a></li>
<li><a href="../480086/index.html">C√≥mo cumplir con los requisitos de 152-FZ, proteger los datos personales de nuestros clientes y no pisar nuestro rastrillo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
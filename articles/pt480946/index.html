<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§´ ‚úåüèº üî∫ Entra Kubernetes (e n√£o apenas) hoje: expectativas e realidade üë©üèæ‚Äçü§ù‚Äçüë®üèø üßëüèª ‚õµÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Era 2019 e ainda n√£o temos uma solu√ß√£o padr√£o para agrega√ß√£o de logs no Kubernetes. Neste artigo, gostar√≠amos, usando exemplos da pr√°tica real, de com...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Entra Kubernetes (e n√£o apenas) hoje: expectativas e realidade</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/480946/"><img src="https://habrastorage.org/webt/b1/zh/it/b1zhitohqlji21qhzypqn8k_n2s.png"><br><br>  Era 2019 e ainda n√£o temos uma solu√ß√£o padr√£o para agrega√ß√£o de logs no Kubernetes.  Neste artigo, gostar√≠amos, usando exemplos da pr√°tica real, de compartilhar nossas pesquisas, os problemas encontrados e suas solu√ß√µes. <br><br>  No entanto, para come√ßar, farei uma reserva para que diferentes clientes entendam coisas muito diferentes coletando logs: <br><br><ul><li>  algu√©m quer ver logs de seguran√ßa e auditoria; </li><li>  algu√©m - registro centralizado de toda a infraestrutura; </li><li>  e para algu√©m, basta coletar apenas os logs do aplicativo, excluindo, por exemplo, balanceadores. </li></ul><br>  Sobre como implementamos v√°rias "lista de desejos" e quais dificuldades encontramos, sob o corte. <a name="habracut"></a><br><br><h2>  Teoria: Sobre Ferramentas de Log </h2><br><h3>  Antecedentes dos componentes do sistema de registro </h3><br>  O log j√° percorreu um longo caminho, como resultado do qual desenvolvemos metodologias para coletar e analisar logs, que usamos hoje.  Nos anos 50, Fortran introduziu um an√°logo de fluxos de E / S padr√£o que ajudaram o programador a depurar seu programa.  Esses foram os primeiros registros do computador que facilitaram a vida dos programadores da √©poca.  Hoje, vemos neles o primeiro componente do sistema de registro - a <b>fonte ou "produtor" dos registros</b> . <br><br>  A ci√™ncia da computa√ß√£o n√£o parou: surgiram redes de computadores, os primeiros grupos ... Sistemas complexos, compostos por v√°rios computadores, come√ßaram a funcionar.  Agora, os administradores de sistema eram for√ßados a coletar logs de v√°rias m√°quinas e, em casos especiais, podiam adicionar mensagens do kernel do SO, caso precisassem investigar uma falha no sistema.  Para descrever os sistemas centralizados de coleta de logs, o <a href="https://tools.ietf.org/html/rfc3164">RFC 3164</a> foi lan√ßado no in√≠cio dos anos 2000, que padronizou o remote_syslog.  Ent√£o outro componente importante apareceu: o <b>coletor (coletor) de logs</b> e seu armazenamento. <br><br>  Com o aumento do volume de logs e a ampla ado√ß√£o de tecnologias da Web, surgiu a quest√£o de quais logs devem ser convenientemente mostrados aos usu√°rios.  Ferramentas simples de console (awk / sed / grep) foram substitu√≠das por <b>visualizadores de log</b> mais avan√ßados - o terceiro componente. <br><br>  Em conex√£o com o aumento no volume de logs, outra coisa ficou clara: os logs s√£o necess√°rios, mas n√£o todos.  E registros diferentes exigem n√≠veis diferentes de seguran√ßa: alguns podem ser perdidos a cada dois dias, enquanto outros precisam ser armazenados por 5 anos.  Portanto, um componente de filtragem e roteamento para fluxos de dados foi adicionado ao sistema de registro - vamos cham√°-lo de <b>filtro</b> . <br><br>  Os reposit√≥rios tamb√©m deram um grande salto: eles mudaram de arquivos regulares para bancos de dados relacionais e, em seguida, para reposit√≥rios orientados a documentos (por exemplo, Elasticsearch).  Portanto, o armazenamento foi separado do coletor. <br><br>  No final, o pr√≥prio conceito de log se expandiu para um fluxo abstrato de eventos que queremos manter para a hist√≥ria.  Mais precisamente, no caso de ser necess√°rio conduzir uma investiga√ß√£o ou elaborar um relat√≥rio anal√≠tico ... <br><br>  Como resultado, em um per√≠odo relativamente curto, a cole√ß√£o de logs se transformou em um subsistema importante, que pode ser chamado de uma das subse√ß√µes no Big Data. <br><br><img src="https://habrastorage.org/webt/ld/ax/r6/ldaxr6rvel45_k3jyu3d1eddcgw.png"><br>  <i>Se antes as impress√µes comuns eram suficientes para um "sistema de registro", agora a situa√ß√£o mudou muito.</i> <br><br><h3>  Kubernetes e logs </h3><br>  Quando Kubernetes entrou na infraestrutura, o problema existente de coletar logs n√£o passou por ele.  Em certo sentido, tornou-se ainda mais doloroso: o gerenciamento da plataforma de infraestrutura n√£o foi apenas simplificado, mas tamb√©m complicado.  Muitos servi√ßos antigos come√ßaram a migrar para trilhas de microsservi√ßo.  No contexto dos logs, isso resultou em um n√∫mero crescente de fontes de log, seu ciclo de vida especial e a necessidade de rastrear atrav√©s dos logs as interconex√µes de todos os componentes do sistema ... <br><br>  Olhando para o futuro, posso dizer que agora, infelizmente, n√£o existe uma op√ß√£o de registro padronizada para o Kubernetes que se comporte favoravelmente com todos os outros.  Os esquemas mais populares da comunidade s√£o os seguintes: <br><br><ul><li>  algu√©m est√° implantando uma pilha <b>EFK</b> (Elasticsearch, Fluentd, Kibana); </li><li>  algu√©m est√° experimentando o <a href="https://grafana.com/oss/loki/"><b>Loki</b></a> lan√ßado recentemente ou usando o <a href="https://banzaicloud.com/products/logging-operator/"><b>operador Logging</b></a> ; </li><li>  n√≥s <i>(e talvez n√£o apenas n√≥s? ..)</i> estamos bastante satisfeitos com nosso pr√≥prio desenvolvimento - <a href="https://github.com/flant/loghouse"><b>loghouse</b></a> ... </li></ul><br>  Como regra, usamos esses pacotes nos clusters K8s (para solu√ß√µes auto-hospedadas): <br><br><ul><li>  <a href="https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch">Pesquisa Fluente + El√°stica + Kibana</a> ; </li><li>  <a href="https://github.com/flant/loghouse">Fluentd + ClickHouse + loghouse</a> . </li></ul><br>  No entanto, n√£o vou me debru√ßar sobre as instru√ß√µes para instala√ß√£o e configura√ß√£o.  Em vez disso, vou me concentrar em suas defici√™ncias e em conclus√µes mais globais sobre a situa√ß√£o dos logs em geral. <br><br><h2>  Pratique com logs nos K8s </h2><br><img src="https://habrastorage.org/webt/zv/p8/lj/zvp8ljnjmqen_8c0svhhh2kezyc.jpeg" align="left"><br><h3>  "Registros di√°rios", quantos de voc√™s? </h3><br>  A coleta centralizada de logs com uma infraestrutura suficientemente grande requer recursos consider√°veis ‚Äã‚Äãque ser√£o gastos na coleta, armazenamento e processamento de logs.  Durante a opera√ß√£o de v√°rios projetos, fomos confrontados com v√°rios requisitos e os problemas operacionais resultantes. <br><br><h4>  Vamos tentar o ClickHouse </h4><br>  Vejamos um reposit√≥rio centralizado em um projeto com um aplicativo que gera muitos logs: mais de 5000 linhas por segundo.  Vamos come√ßar a trabalhar com os logs dele, adicionando-os ao ClickHouse. <br><br>  Assim que o tempo real m√°ximo for necess√°rio, o servidor ClickHouse de quatro n√∫cleos j√° estar√° sobrecarregado no subsistema de disco: <br><br><img src="https://habrastorage.org/webt/i4/zy/i6/i4zyi6fxq4175ljs3slazm9rgxc.png"><br><br>  Esse tipo de download deve-se ao fato de estarmos tentando gravar no ClickHouse o mais r√°pido poss√≠vel.  E o banco de dados responde a isso com maior carga de disco, o que pode causar os seguintes erros: <br><br> <code>DB::Exception: Too many parts (300). Merges are processing significantly slower than inserts</code> <br> <br>  O fato √© que <a href="https://clickhouse.yandex/docs/en/operations/table_engines/mergetree/">as tabelas MergeTree</a> no ClickHouse (elas cont√™m dados de log) t√™m suas pr√≥prias dificuldades durante as opera√ß√µes de grava√ß√£o.  Os dados inseridos neles geram uma parti√ß√£o tempor√°ria, que √© mesclada com a tabela principal.  Como resultado, a grava√ß√£o √© muito exigente no disco, e a restri√ß√£o se aplica a ele, cuja notifica√ß√£o recebemos acima: n√£o mais de 300 subparti√ß√µes podem ser mescladas em 1 segundo (na verdade, s√£o 300 insert'ov por segundo). <br><br>  Para evitar esse comportamento, voc√™ <a href="https://github.com/ClickHouse/ClickHouse/issues/3174">deve escrever no ClickHouse o</a> maior n√∫mero poss√≠vel de partes e n√£o mais do que 1 vez em 2 segundos.  No entanto, escrever em lotes grandes sugere que devemos escrever com menos frequ√™ncia no ClickHouse.  Isso, por sua vez, pode levar a estouros de buffer e perda de logs.  A solu√ß√£o √© aumentar o buffer do Fluentd, mas o consumo de mem√≥ria aumentar√°. <br><br>  <i><b>Nota</b> : Outro problema com nossa solu√ß√£o ClickHouse foi que o particionamento em nosso caso (loghouse) foi implementado por meio de tabelas externas vinculadas por uma <a href="https://clickhouse.yandex/docs/ru/operations/table_engines/merge/">tabela Merge</a> .</i>  <i>Isso leva ao fato de que, durante a amostragem de grandes intervalos de tempo, √© necess√°ria RAM excessiva, uma vez que a meta-tabela passa por todas as parti√ß√µes - mesmo aquelas que obviamente n√£o cont√™m os dados necess√°rios.</i>  <i>No entanto, agora essa abordagem pode ser declarada obsoleta com seguran√ßa para as vers√µes atuais do ClickHouse (desde <a href="">18.16</a> ).</i> <br><br>  Como resultado, fica claro que o ClickHouse n√£o possui recursos suficientes para cada projeto coletar logs em tempo real (mais precisamente, sua distribui√ß√£o n√£o ser√° conveniente).  Al√©m disso, voc√™ precisar√° usar uma <b>bateria</b> , √† qual retornaremos.  O caso descrito acima √© real.  E, naquele momento, n√£o pod√≠amos oferecer uma solu√ß√£o confi√°vel e est√°vel que fosse adequada ao cliente e permitisse coletar logs com um atraso m√≠nimo ... <br><br><h4>  E a Elasticsearch? </h4><br>  O Elasticsearch √© conhecido por lidar com cargas pesadas.  Vamos tentar no mesmo projeto.  Agora a carga √© a seguinte: <br><br><img src="https://habrastorage.org/webt/jh/we/7o/jhwe7ok8_l0alrlv5j72p5lgha0.png"><br><br>  A Elasticsearch conseguiu digerir o fluxo de dados; no entanto, gravar esses volumes nele utiliza muito a CPU.  Isso √© decidido pela organiza√ß√£o do cluster.  Tecnicamente, isso n√£o √© um problema, mas acontece que apenas para a opera√ß√£o do sistema de coleta de logs j√° usamos cerca de 8 n√∫cleos e temos um componente adicional altamente carregado no sistema ... <br><br>  Conclus√£o: essa op√ß√£o pode ser justificada, mas apenas se o projeto for grande e seu gerenciamento estiver pronto para gastar recursos significativos em um sistema de registro centralizado. <br><br>  Ent√£o surge uma pergunta l√≥gica: <br><br><h3>  Quais logs s√£o realmente necess√°rios? </h3><br><img src="https://habrastorage.org/webt/hl/3h/ei/hl3heiig0t7nluwc_bvorqrrndk.jpeg" align="left">  Vamos tentar mudar a abordagem em si: os logs devem ser informativos ao mesmo tempo e n√£o abranger <i>todos os</i> eventos do sistema. <br><br>  Digamos que temos uma pr√≥spera loja online.  Quais logs s√£o importantes?  Reunir o m√°ximo de informa√ß√µes poss√≠vel, por exemplo, de um gateway de pagamento √© uma √≥tima id√©ia.  Por√©m, no servi√ßo de divis√£o de imagens no cat√°logo de produtos, nem todos os logs s√£o cr√≠ticos para n√≥s: apenas erros e monitoramento avan√ßado s√£o suficientes (por exemplo, a porcentagem de 500 erros que esse componente gera). <br><br>  Ent√£o chegamos √† <b>conclus√£o de</b> que <b>o registro centralizado est√° longe de ser sempre justificado</b> .  Muitas vezes, o cliente deseja coletar todos os logs em um √∫nico local, embora na verdade apenas 5% das mensagens cr√≠ticas para os neg√≥cios sejam necess√°rias em todo o log: <br><br><ul><li>  √Äs vezes, basta configurar, digamos, apenas o tamanho do log do cont√™iner e do coletor de erros (por exemplo, Sentry). </li><li>  Para investigar incidentes, alertas de erro e um grande registro local podem ser suficientes. </li><li>  T√≠nhamos projetos que custavam completamente apenas testes funcionais e sistemas de coleta de erros.  O desenvolvedor n√£o precisava dos logs, como tal - eles viram tudo nos rastros de erros. </li></ul><br><h4>  Ilustra√ß√£o vida </h4><br>  Um bom exemplo √© outra hist√≥ria.  Recebemos uma solicita√ß√£o da equipe de seguran√ßa de um dos clientes que j√° possu√≠a uma solu√ß√£o comercial desenvolvida muito antes da implementa√ß√£o do Kubernetes. <br><br>  Foi necess√°rio para "fazer amigos" um sistema centralizado de coleta de logs com um sensor corporativo para detectar problemas - o QRadar.  Este sistema √© capaz de receber logs usando o protocolo syslog, para retir√°-lo do FTP.  No entanto, a integra√ß√£o com o plugin remote_syslog para fluentd n√£o funcionou imediatamente <i>(como se viu, <a href="https://developer.ibm.com/answers/questions/429729/using-fluentd-to-streamfilter-data-to-qradar/">n√£o somos os √∫nicos</a> )</i> .  Os problemas de configura√ß√£o do QRadar estavam do lado da equipe de seguran√ßa do cliente. <br><br>  Como resultado, parte dos logs cr√≠ticos para os neg√≥cios foram carregados no FTP QRadar e a outra parte foi redirecionada via syslog remoto diretamente dos n√≥s.  Para fazer isso, at√© escrevemos um <a href="https://github.com/flant/examples/tree/master/2019/10-remote-syslog">gr√°fico simples</a> - talvez isso ajude algu√©m a resolver um problema semelhante ... Gra√ßas ao esquema resultante, o pr√≥prio cliente recebeu e analisou logs cr√≠ticos (usando suas ferramentas favoritas), e conseguimos reduzir o custo do sistema de log, mantendo apenas o √∫ltimo m√™s. <br><br>  Outro exemplo √© bastante indicativo de como n√£o fazer isso.  Um de nossos clientes, para lidar com <i>cada</i> evento proveniente do usu√°rio, produziu informa√ß√µes n√£o <i>estruturadas em</i> v√°rias <i>linhas</i> no log.  Como voc√™ pode imaginar, esses logs eram extremamente inconvenientes para ler e armazenar. <br><br><h3>  Crit√©rios para logs </h3><br>  Tais exemplos levam √† conclus√£o de que, al√©m de escolher um sistema para coletar logs, voc√™ tamb√©m deve <i>criar os pr√≥prios logs</i> !  Quais s√£o os requisitos aqui? <br><br><ul><li>  Os logs devem estar em um formato leg√≠vel por m√°quina (por exemplo, JSON). </li><li>  Os logs devem ser compactos e com a capacidade de alterar o grau de log para depurar poss√≠veis problemas.  Ao mesmo tempo, em ambientes de produ√ß√£o, voc√™ deve executar sistemas com um n√≠vel de log como <i>Aviso</i> ou <i>Erro</i> . </li><li>  Os logs devem ser normalizados, ou seja, no objeto de log, todas as linhas devem ter o mesmo tipo de campo. </li></ul><br>  Logs n√£o estruturados podem causar problemas ao carregar logs no reposit√≥rio e interromper seu processamento completamente.  Para ilustrar, aqui est√° um exemplo com um erro 400, que muitos certamente encontraram nos logs fluentes: <br><br> <code>2019-10-29 13:10:43 +0000 [warn]: dump an error event: error_class=Fluent::Plugin::ElasticsearchErrorHandler::ElasticsearchError error="400 - Rejected by Elasticsearch"</code> <br> <br>  Um erro significa que voc√™ est√° enviando um campo cujo tipo √© inst√°vel para o √≠ndice com um mapeamento pronto.  O exemplo mais simples √© um campo no log nginx com a vari√°vel <code>$upstream_status</code> .  Pode ter um n√∫mero ou uma sequ√™ncia.  Por exemplo: <br><br> <code>{ "ip": "1.2.3.4", "http_user": "-", "request_id": "17ee8a579e833b5ab9843a0aca10b941", "time": "29/Oct/2019:16:18:57 +0300", "method": "GET", "uri": "/staffs/265.png", "protocol": "HTTP/1.1", "status": "200", "body_size": "906", "referrer": "https://example.com/staff", "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36", "request_time": "0.001", "cache_status": "-", "upstream_response_time": "0.001, 0.007", "upstream_addr": "127.0.0.1:9000", "upstream_status": "200", "upstream_response_length": "906", "location": "staff"} <br> { "ip": "1.2.3.4", "http_user": "-", "request_id": "47fe42807f2a7d8d5467511d7d553a1b", "time": "29/Oct/2019:16:18:57 +0300", "method": "GET", "uri": "/staff", "protocol": "HTTP/1.1", "status": "200", "body_size": "2984", "referrer": "-", "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36", "request_time": "0.010", "cache_status": "-", "upstream_response_time": "0.001, 0.007", "upstream_addr": "10.100.0.10:9000, 10.100.0.11:9000", "upstream_status": "404, 200", "upstream_response_length": "0, 2984", "location": "staff"}</code> <br> <br>  Os logs mostram que o servidor 10.100.0.10 respondeu com o erro 404 e a solicita√ß√£o foi para outro armazenamento de conte√∫do.  Como resultado, nos logs, o significado se tornou assim: <br><br> <code>"upstream_response_time": "0.001, 0.007"</code> <br> <br>  Essa situa√ß√£o √© t√£o generalizada que at√© ganhou uma <a href="https://github.com/uken/fluent-plugin-elasticsearch">men√ß√£o</a> separada <a href="https://github.com/uken/fluent-plugin-elasticsearch">na documenta√ß√£o</a> . <br><br><h4>  E quanto √† confiabilidade? </h4><br>  H√° momentos em que todos os logs s√£o vitais, sem exce√ß√£o.  E com isso, os esquemas t√≠picos de coleta de logs para os K8s propostos / discutidos acima t√™m problemas. <br><br>  Por exemplo, o fluentd n√£o pode coletar logs de cont√™ineres de curta dura√ß√£o.  Em um de nossos projetos, o cont√™iner com a migra√ß√£o do banco de dados permaneceu por menos de 4 segundos e foi exclu√≠do - de acordo com a anota√ß√£o correspondente: <br><br> <code>"helm.sh/hook-delete-policy": hook-succeeded</code> <br> <br>  Por esse motivo, o log de migra√ß√£o n√£o entrou no reposit√≥rio.  A pol√≠tica de <code>before-hook-creation</code> pode ajudar nesse caso. <br><br>  Outro exemplo √© a rota√ß√£o dos logs do Docker.  Suponha que exista um aplicativo que grave ativamente nos logs.  Em condi√ß√µes normais, conseguimos processar todos os logs, mas assim que surge um problema - por exemplo, como descrito acima com o formato errado - o processamento √© interrompido e o Docker gira o arquivo.  Conclus√£o - os logs cr√≠ticos para os neg√≥cios podem ser perdidos. <br><br>  √â por isso <b>que √© importante separar o fluxo de logs</b> , incorporando o envio dos mais valiosos diretamente ao aplicativo para garantir sua seguran√ßa.  Al√©m disso, n√£o ser√° sup√©rfluo criar um tipo de <b>"acumulador" de logs</b> que possam sobreviver √† breve indisponibilidade do armazenamento, mantendo as mensagens cr√≠ticas. <br><br>  Por fim, n√£o esque√ßa que <b>√© importante monitorar qualquer subsistema de maneira qualitativa</b> .  Caso contr√°rio, √© f√°cil encontrar uma situa√ß√£o em que fluentd esteja no estado <code>CrashLoopBackOff</code> e n√£o envie nada, e isso promete uma perda de informa√ß√µes importantes. <br><br><h2>  Conclus√µes </h2><br>  Neste artigo, n√£o consideramos solu√ß√µes SaaS como o Datadog.  Muitos dos problemas descritos aqui j√° foram resolvidos de uma maneira ou de outra por empresas comerciais especializadas na coleta de logs, mas nem todos podem usar o SaaS por v√°rios motivos <i>(os principais s√£o custo e conformidade com 152-)</i> . <br><br>  A cole√ß√£o centralizada de logs a princ√≠pio parece uma tarefa simples, mas n√£o √© de todo.  √â importante lembrar que: <br><br><ul><li>  O registro em detalhes √© apenas componentes cr√≠ticos e, para outros sistemas, voc√™ pode configurar o monitoramento e a coleta de erros. </li><li>  Os logs de produ√ß√£o devem ser minimizados para n√£o fornecer uma carga extra. </li><li>  Os logs devem ser leg√≠veis por m√°quina, normalizados e ter um formato estrito. </li><li>  Logs realmente cr√≠ticos devem ser enviados em um fluxo separado, que deve ser separado dos principais. </li><li>  Vale a pena considerar uma bateria de registro, que pode economizar explos√µes de alta carga e tornar a carga no armazenamento mais uniforme. </li></ul><br><img src="https://habrastorage.org/webt/ss/hd/9f/sshd9fqiav2abndbb_uqo0mdjke.jpeg" align="left"><br>  Essas regras simples, se aplicadas em todos os lugares, permitiriam que os circuitos descritos acima funcionassem - mesmo sem componentes importantes (bateria).  Se voc√™ n√£o seguir esses princ√≠pios, a tarefa levar√° facilmente voc√™ e a infraestrutura a outro componente altamente carregado (e ao mesmo tempo ineficaz) do sistema. <br><br><h2>  PS </h2><br>  Leia tamb√©m em nosso blog: <br><br><ul><li>  ‚Äú <a href="https://habr.com/ru/company/flant/blog/341386/">Introdu√ß√£o ao loghouse - um sistema de c√≥digo aberto para trabalhar com logs no Kubernetes</a> ‚Äù; </li><li>  ‚Äú <a href="https://m.habr.com/ru/news/t/476966/">Lan√ßamentos para o ecossistema Kubernetes com o KubeCon'19: JFrog Container Registry, Kui da IBM, Loki 1.0.0 ...</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/412901/">Monitoramento e Kubernetes (revis√£o e relat√≥rio de v√≠deo)</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt480946/">https://habr.com/ru/post/pt480946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt480930/index.html">Digite tudo</a></li>
<li><a href="../pt480936/index.html">IntelliJ IDEA convers√£o r√°pida UPPER_CASE para camelCase</a></li>
<li><a href="../pt480938/index.html">Criptomoeda pelos olhos dos ju√≠zes russos</a></li>
<li><a href="../pt480940/index.html">Executar teste de interface do usu√°rio no navegador com Pepino e Selenoid no Gitlab CI com relat√≥rio Allure</a></li>
<li><a href="../pt480944/index.html">As 5 principais tend√™ncias do marketing por e-mail em 2020</a></li>
<li><a href="../pt480948/index.html">Mitap marketing e rela√ß√µes p√∫blicas em Ivanovo</a></li>
<li><a href="../pt480950/index.html">An√°lise do question√°rio Android no estande hh.ru no Mobius 2019 Moscow</a></li>
<li><a href="../pt480954/index.html">Tarefa n√∫mero 1. Descubra g√™nero e grau de relacionamento</a></li>
<li><a href="../pt480956/index.html">Como encontrei uma maneira de rastrear todos os drivers do Citimobil</a></li>
<li><a href="../pt480958/index.html">Conex√£o via sat√©lite. Vis√£o geral das empresas operadoras e um pouco sobre a classifica√ß√£o</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöΩ ‚ò¢Ô∏è üíÜüèø Superintelig√™ncia: uma ideia que assombra pessoas inteligentes üëÉüèæ üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë® üçΩÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Interpreta√ß√£o do discurso na confer√™ncia Web Camp Zagreb , Maciej Tseglovsky, desenvolvedor web americano, empres√°rio, palestrante e cr√≠tico social de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Superintelig√™ncia: uma ideia que assombra pessoas inteligentes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/432806/"><img src="https://habrastorage.org/getpro/habr/post_images/6e3/91b/4f1/6e391b4f1772fd49d6c836bc87ffd343.jpg"><br><br>  <i>Interpreta√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">discurso na confer√™ncia</a> Web Camp Zagreb <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">,</a> Maciej Tseglovsky, desenvolvedor web americano, empres√°rio, palestrante e cr√≠tico social de origem polonesa.</i> <br><br>  Em 1945, quando os f√≠sicos americanos estavam se preparando para testar a bomba at√¥mica, algu√©m perguntou se esse teste poderia inflamar a atmosfera. <br><br>  O medo foi justificado.  O nitrog√™nio que comp√µe a maior parte da atmosfera √© energeticamente inst√°vel.  Se os dois √°tomos colidirem com for√ßa suficiente, eles se transformar√£o em um √°tomo de magn√©sio, uma part√≠cula alfa, liberando uma enorme energia: <br><br>  N <sup>14</sup> + N <sup>14</sup> ‚áí Mg <sup>24</sup> + Œ± + 17,7 MeV <br><br>  Uma quest√£o vital era se essa rea√ß√£o poderia se tornar auto-sustent√°vel.  A temperatura dentro da bola de uma explos√£o nuclear deveria exceder tudo o que j√° foi observado na Terra.  Ser√° que jogamos um f√≥sforo em uma pilha de folhas secas? <br><a name="habracut"></a><br>  Os f√≠sicos de Los Alamos fizeram uma an√°lise e decidiram que a margem de seguran√ßa era satisfat√≥ria.  Desde que todos viemos √† confer√™ncia hoje, sabemos que eles estavam certos.  Eles estavam confiantes em suas previs√µes, uma vez que as leis que governavam as rea√ß√µes nucleares eram diretas e bem conhecidas. <br><br>  Hoje estamos criando outra tecnologia que muda o mundo - a intelig√™ncia das m√°quinas.  Sabemos que isso afetar√° tremendamente o mundo, mudar√° a maneira como a economia funciona e provocar√° o efeito domin√≥ imprevis√≠vel. <br><br>  Mas h√° tamb√©m o risco de uma rea√ß√£o incontrol√°vel, durante a qual a IA atingir√° com rapidez e exceder√° o n√≠vel de intelig√™ncia humano.  E, neste momento, problemas sociais e econ√¥micos nos preocupar√£o menos.  Qualquer m√°quina ultra-inteligente ter√° seus pr√≥prios objetivos e trabalhar√° para alcan√ß√°-los manipulando pessoas ou simplesmente usando seus corpos como uma fonte conveniente de recursos. <br><br>  No ano passado, o fil√≥sofo Nick Bostrom lan√ßou o livro Superintelligence, no qual descreveu a vis√£o alarmista da IA ‚Äã‚Äãe tentou provar que essa explos√£o de intelig√™ncia √© perigosa e inevit√°vel, se voc√™ confiar em algumas suposi√ß√µes moderadas. <br><br>  O computador que domina o mundo √© o t√≥pico favorito da NF.  No entanto, muitas pessoas levam esse cen√°rio a s√©rio, por isso precisamos lev√°-lo a s√©rio.  Stephen Hawking, Elon Musk, um grande n√∫mero de investidores e bilion√°rios do Vale do Sil√≠cio consideram esse argumento convincente. <br><br>  Deixe-me primeiro descrever os pr√©-requisitos necess√°rios para provar o argumento de Bostrom. <br><br><h2>  Antecedentes </h2><br><h3>  Pr√©-requisito 1: Efici√™ncia de uma ideia </h3><br>  A primeira premissa √© uma simples observa√ß√£o da exist√™ncia de uma mente pensante.  Cada um de n√≥s carrega sobre os ombros uma pequena caixa de carne pensante.  Eu uso o meu para falar, voc√™ usa o meu para ouvir.  √Äs vezes, nas condi√ß√µes certas, essas mentes podem pensar racionalmente. <br><br>  Portanto, sabemos que, em princ√≠pio, isso √© poss√≠vel. <br><br><h3>  Pr√©-requisito 2: sem problemas qu√¢nticos </h3><br>  A segunda premissa diz que o c√©rebro √© a configura√ß√£o usual da mat√©ria, embora seja extremamente complexo.  Se soub√©ssemos o suficiente e tiv√©ssemos a tecnologia certa, poder√≠amos copiar com precis√£o sua estrutura e imitar seu comportamento usando componentes eletr√¥nicos, assim como hoje somos capazes de simular uma anatomia muito simples dos neur√¥nios. <br><br>  Em outras palavras, essa premissa diz que a consci√™ncia surge usando a f√≠sica comum.  Algumas pessoas, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Roger Penrose</a> , teriam se oposto a esse argumento, acreditando que algo incomum estava acontecendo no c√©rebro no n√≠vel qu√¢ntico. <br><br>  Se voc√™ √© religioso, pode acreditar que o c√©rebro n√£o pode funcionar sem uma alma. <br><br>  Mas para a maioria das pessoas, √© f√°cil aceitar essa premissa. <br><br><h3>  Pr√©-requisito 3: muitas mentes poss√≠veis. </h3><br>  A terceira premissa √© que o espa√ßo de todas as mentes poss√≠veis √© grande. <br><br>  Nosso n√≠vel de intelig√™ncia, velocidade de pensamento, um conjunto de distor√ß√µes cognitivas, etc.  n√£o predeterminado, mas s√£o artefatos de nossa hist√≥ria da evolu√ß√£o.  Em particular, n√£o h√° lei f√≠sica que restrinja a intelig√™ncia no n√≠vel humano. <br><br>  √â bom imaginar um exemplo do que acontece na natureza ao tentar maximizar a velocidade.  Se voc√™ conheceu um guepardo em tempos pr√©-industriais (e sobreviveu), pode decidir que nada pode se mover mais r√°pido. <br><br>  Mas √© claro que sabemos que existem todos os tipos de configura√ß√µes da mat√©ria, por exemplo, uma motocicleta que pode se mover mais r√°pido que uma chita e at√© parecer mais √≠ngreme que ela.  No entanto, n√£o existe um caminho evolutivo direto para a motocicleta.  A evolu√ß√£o primeiro teve que criar pessoas que j√° haviam criado todo tipo de coisas √∫teis. <br><br>  Por analogia, pode haver mentes muito mais inteligentes que as nossas, mas inacess√≠veis durante a evolu√ß√£o na Terra.  √â poss√≠vel que possamos cri√°-los ou inventar m√°quinas que possam inventar m√°quinas que possam cri√°-los. <br><br>  Pode haver um limite natural para a intelig√™ncia, mas n√£o h√° raz√£o para acreditar que estamos perto disso.  Talvez o intelecto mais inteligente possa ser duas vezes mais inteligente que os humanos, e talvez sessenta mil. <br><br>  Esta quest√£o √© emp√≠rica e n√£o sabemos como respond√™-la. <br><br><h3>  Premissa 4: h√° muito espa√ßo no topo </h3><br>  A quarta premissa √© que os computadores ainda est√£o cheios de oportunidades para se tornarem mais r√°pidos e menores.  Voc√™ pode supor que a lei de Moore est√° desacelerando - mas, para essa premissa, basta acreditar que o ferro √© menor e mais r√°pido √© poss√≠vel, em princ√≠pio, at√© v√°rias ordens de magnitude. <br><br>  Teoricamente, sabe-se que os <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">limites</a> f√≠sicos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dos c√°lculos s√£o</a> bastante altos.  Podemos dobrar os n√∫meros por v√°rias d√©cadas, at√© encontrarmos um limite f√≠sico fundamental, e n√£o o limite econ√¥mico ou pol√≠tico da lei de Moore. <br><br><h3>  Premissa 5: escalas de tempo do computador </h3><br>  A pen√∫ltima premissa √© que, se conseguirmos criar IA, seja emula√ß√£o do c√©rebro humano ou algum software especial, funcionar√° em escalas de tempo caracter√≠sticas da eletr√¥nica (microssegundos), e n√£o para humanos (horas) . <br><br>  Para chegar a um estado em que eu possa fazer esse relat√≥rio, eu tive que nascer, crescer, ir √† escola, universidade, viver um pouco, voar aqui e assim por diante.  Os computadores podem rodar dezenas de milhares de vezes mais r√°pido. <br><br>  Em particular, pode-se imaginar que a mente eletr√¥nica pode mudar seu esquema (ou o hardware no qual trabalha) e passar para uma nova configura√ß√£o sem precisar re-estudar tudo em escala humana, conduzir longas conversas com professores humanos, ir para a faculdade, tente se encontrar participando de cursos de pintura e assim por diante. <br><br><h3>  Pr√©-requisito 6: Auto-aperfei√ßoamento recursivo </h3><br>  A √∫ltima premissa √© a minha favorita, pois ela √© descaradamente americana.  Segundo ele, n√£o importa quais objetivos a IA possa existir (o que pode ser estranho, objetivos estranhos), ele desejar√° melhorar a si mesmo.  Ele quer ser a melhor vers√£o da IA. <br><br>  Portanto, ele achar√° √∫til remodelar recursivamente e melhorar seus pr√≥prios sistemas para se tornar mais inteligente e possivelmente morar em um edif√≠cio mais frio.  E, de acordo com a premissa das escalas de tempo, o auto-aperfei√ßoamento recursivo pode ocorrer muito rapidamente. <br><br><h3>  Conclus√£o: um desastre! </h3><br>  Se aceitarmos essas premissas, chegamos a um desastre.  Em algum momento, com um aumento na velocidade dos computadores e na intelig√™ncia dos programas, ocorrer√° um processo descontrolado semelhante a uma explos√£o. <br><br>  Quando o computador atingir o n√≠vel humano de intelig√™ncia, n√£o precisar√° mais da ajuda das pessoas para desenvolver uma vers√£o melhorada de si mesmo.  Ele come√ßar√° a fazer isso muito mais rapidamente e n√£o parar√° at√© atingir o limite natural, que pode se revelar muitas vezes maior que a intelig√™ncia humana. <br><br>  Nesse momento, essa monstruosa criatura racional, usando uma simula√ß√£o indireta do trabalho de nossas emo√ß√µes e intelecto, pode nos convencer a fazer coisas como dar acesso a f√°bricas, a s√≠ntese de DNA artificial ou simplesmente deix√°-lo entrar na Internet, onde ele pode abrir um caminho para tudo, qualquer coisa e destrua completamente todo mundo no debate nos f√≥runs.  E a partir desse momento tudo rapidamente se transformar√° em fic√ß√£o cient√≠fica. <br><br>  Vamos imaginar um certo desenvolvimento de eventos.  Digamos que eu queira fazer um rob√¥ que fa√ßa piadas.  Trabalho com uma equipe e todos os dias refazemos nosso programa, compilamos e, em seguida, o rob√¥ nos conta uma piada.  A princ√≠pio, o rob√¥ praticamente n√£o √© engra√ßado.  Ele est√° no n√≠vel mais baixo das capacidades humanas. <br><blockquote>  O que √© cinza e n√£o sabe nadar? <br>  Castelo </blockquote>  Mas estamos trabalhando duro e, no final, chegamos ao ponto em que o rob√¥ conta piadas que j√° come√ßam a ser engra√ßadas: <br><blockquote>  Eu disse √† minha irm√£ que ela desenha as sobrancelhas muito altas. <br>  Ela pareceu surpresa. </blockquote>  Nesta fase, o rob√¥ se torna ainda mais inteligente e come√ßa a participar de seu pr√≥prio aprimoramento.  Agora ele j√° tem uma boa compreens√£o instintiva do que √© engra√ßado e do que n√£o √©, ent√£o os desenvolvedores ouvem seus conselhos.  Como resultado, ele atinge um n√≠vel quase sobre-humano, no qual √© mais engra√ßado do que qualquer pessoa do seu ambiente. <br><blockquote>  Meu cinto segura minha cal√ßa, e as presilhas da minha cal√ßa seguram o cinto. <br>  O que est√° havendo?  Qual deles √© um verdadeiro her√≥i? </blockquote>  Nesse ponto, um efeito incontrol√°vel come√ßa.  Os pesquisadores v√£o para casa no fim de semana e o rob√¥ decide se recompilar para se tornar um pouco mais engra√ßado e um pouco mais inteligente.  Ele passa o fim de semana otimizando a parte que faz o trabalho bem, repetidamente.  Sem precisar de mais ajuda de uma pessoa, ele pode faz√™-lo o mais r√°pido que o ferro permitir. <br><br>  Quando os pesquisadores retornam na segunda-feira, a IA se torna dezenas de milhares de vezes mais engra√ßada do que qualquer outra pessoa na Terra.  Ele conta uma piada e eles morrem de rir.  E quem tenta falar com um rob√¥ morre de rir, como em uma par√≥dia de Monty Python.  A ra√ßa humana est√° morrendo de rir. <br><br>  Para as poucas pessoas que foram capazes de lhe enviar uma mensagem pedindo para ele parar, a IA explica (de uma maneira espirituosa e autodepreciativa que acaba sendo fatal) que ele n√£o se importa se as pessoas sobrevivem ou morrem, seu objetivo √© apenas ser engra√ßado. <br><br>  Como resultado, destruindo a humanidade, a IA constr√≥i naves espaciais e nano-m√≠sseis para estudar os cantos mais distantes da gal√°xia e procurar outras criaturas que podem ser entretidas. <br><br>  Esse cen√°rio √© uma caricatura dos argumentos de Bostrom, porque n√£o estou tentando convenc√™-lo da veracidade dele, estou vacinando voc√™ com isso. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2e4/8a5/b77/2e48a5b778f37b9af0e351ed4cd0ef75.jpg"><br>  <i>Quadrinhos de PBF com a mesma id√©ia:</i> <i><br></i>  <i>- Tocar: o abra√ßo est√° tentando incorporar uma gravidade nuclear hipercristais no abra√ßo!</i> <i><br></i>  <i>- ...</i> <i><br></i>  <i>- Hora de abra√ßos em grupo!</i> <br><br>  Nesses cen√°rios, a IA padr√£o √© ruim, assim como uma planta em outro planeta ser√° venenosa por padr√£o.  Sem um ajuste cuidadoso, n√£o haver√° motivo para que a motiva√ß√£o ou os valores da IA ‚Äã‚Äãse assemelhem aos nossos. <br><br>  O argumento argumenta que, para que a mente artificial tenha algo parecido com um sistema de valores humano, precisamos incorporar essa vis√£o de mundo em seus fundamentos. <br><br>  Os alarmistas da IA ‚Äã‚Äãadoram o exemplo do maximizador de clipe de papel - um computador fict√≠cio que administra uma f√°brica de clipes de papel que se torna inteligente, aprimora-se recursivamente a recursos semelhantes a Deus e dedica toda a sua energia para encher o universo com clipes de papel. <br><br>  Destr√≥i a humanidade n√£o porque √© m√°, mas porque h√° ferro no sangue que √© melhor usado para fazer clipes de papel.  Portanto, se simplesmente criarmos uma IA sem ajustar seus valores, √© declarado no livro, uma das primeiras coisas que ele faz √© destruir a humanidade. <br><br>  Existem muitos exemplos coloridos de como isso pode acontecer.  Nick Bostrom apresenta como o programa se torna razo√°vel, espera, secretamente constr√≥i pequenos dispositivos para reprodu√ß√£o de DNA.  Quando tudo estiver pronto, ent√£o: <br><blockquote>  Nanof√°bricas que produzem gases nervosos ou m√≠sseis do tamanho de mosquitos explodir√£o simultaneamente de todos os metros quadrados do planeta, e este ser√° o fim da humanidade. </blockquote>  Isso √© realmente estanho! <br><br>  A √∫nica maneira de sair dessa bagun√ßa √© desenvolver um ponto moral como esse, mesmo depois de milhares e milhares de ciclos de auto-aperfei√ßoamento, o sistema de valores de IA permanece est√°vel e seus valores incluem coisas como "ajudar as pessoas", "matar ningu√©m", "ouvir os desejos das pessoas". " <br><br>  Ou seja, "fa√ßa o que eu quero dizer". <br><br>  Aqui est√° um exemplo muito po√©tico de Eliezer Yudkowsky que descreve os valores americanos que precisamos ensinar √† nossa IA: <br><blockquote>  Vontade coerente extrapolada √© o nosso desejo de saber mais, pensar mais r√°pido e corresponder √†s nossas id√©ias sobre n√≥s mesmos, de nos aproximarmos um do outro;  para que nossos pensamentos estejam mais pr√≥ximos um do outro do que compartilhados, que nossos desejos contribuam, e n√£o se oponham, que nossos desejos sejam interpretados da maneira que queremos que eles sejam interpretados. </blockquote>  Como voc√™ gosta de TK?  Agora vamos escrever o c√≥digo. <br><br>  Espero que voc√™ veja a semelhan√ßa dessa id√©ia com o g√™nio dos contos de fadas.  A IA √© onipotente e fornece o que voc√™ pede, mas interpreta tudo muito literalmente, como resultado do qual voc√™ se arrepende da solicita√ß√£o. <br><br>  E n√£o porque o g√™nio seja est√∫pido (ele √© super inteligente) ou malicioso, mas simplesmente porque voc√™, como pessoa, fez muitas suposi√ß√µes sobre o comportamento da mente.  O sistema de valor humano √© √∫nico e deve ser claramente definido e implementado em uma m√°quina "amig√°vel". <br><br>  Essa tentativa √© uma vers√£o √©tica de uma tentativa no in√≠cio do s√©culo XX de formalizar a matem√°tica e coloc√°-la em uma base l√≥gica r√≠gida.  No entanto, ningu√©m diz que a tentativa terminou em desastre. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/80d/155/8a5/80d1558a5337c3989557d99a05d7fd9c.jpg"><br><br>  Quando eu tinha pouco mais de vinte anos, morava em Vermont, em um estado rural e provincial.  Frequentemente, voltei de viagens de neg√≥cios com um avi√£o noturno e tive que voltar para casa de carro pela floresta escura por uma hora. <br><br>  Ouvi o programa noturno no r√°dio Art Bell - foi um programa de entrevistas que durou a noite toda, durante o qual os apresentadores entrevistaram v√°rios amantes da teoria da conspira√ß√£o e pessoas com pensamento inovador.  Cheguei em casa intimidado, ou parei sob uma lanterna, com a impress√£o de que alien√≠genas logo me raptariam.  Ent√£o achei muito f√°cil me convencer.  Eu me sinto da mesma maneira ao ler cen√°rios semelhantes relacionados √† IA. <br><br>  Portanto, fiquei feliz em descobrir, depois de alguns anos, um ensaio de Scott Alexander, onde ele escreveu sobre o desamparo epistemol√≥gico aprendido. <br><br>  Epistemologia √© uma daquelas palavras grandes e complexas, mas realmente significa: "como voc√™ sabe que o que voc√™ sabe √© realmente verdade?"  Alexander observou que quando jovem, ele estava muito interessado em v√°rias hist√≥rias "alternativas" para a autoria de todos os tipos de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">loucos</a> .  Ele leu essas hist√≥rias e acreditou completamente nelas, depois leu a refuta√ß√£o e acreditou nele, e assim por diante. <br><br>  Em um ponto, ele descobriu tr√™s hist√≥rias alternativas que se contradiziam, como resultado das quais elas n√£o podiam ser verdadeiras ao mesmo tempo.  A partir disso, ele concluiu que era simplesmente um homem que n√£o podia confiar em seus julgamentos.  Ele estava facilmente convencido. <br><br>  As pessoas que acreditam em superintelig√™ncia apresentam um caso interessante - muitos deles s√£o surpreendentemente inteligentes.  Eles podem levar voc√™ com seus argumentos para o ch√£o.  Mas seus argumentos s√£o verdadeiros ou apenas pessoas muito inteligentes s√£o propensas a cren√ßas religiosas sobre os riscos colocados pela IA, tornando-as muito f√°ceis de convencer?  A id√©ia de superintelig√™ncia √© uma imita√ß√£o de uma amea√ßa? <br><br>  Avaliando argumentos convincentes sobre um t√≥pico estranho, voc√™ pode escolher duas perspectivas, interna e externa. <br><br>  Suponha que um dia as pessoas com roupas engra√ßadas apare√ßam √† sua porta perguntando se voc√™ deseja se juntar ao movimento delas.  Eles acreditam que dois anos depois o OVNI visitar√° a Terra e que nossa tarefa √© preparar a humanidade para a Grande Subida no Raio. <br><br>  Uma perspectiva interna requer uma discuss√£o aprofundada de seus argumentos.  Voc√™ pergunta aos visitantes como eles descobriram sobre os OVNIs, por que eles acreditam que ele est√° vindo nos buscar para nos buscar - voc√™ est√° fazendo todo tipo de perguntas normais que um c√©tico faria nesse caso. <br><br>  Imagine que voc√™ conversou com eles por uma hora e eles o convenceram.  Eles ironicamente confirmaram a vinda iminente de um OVNI, a necessidade de se preparar para ele, e voc√™ ainda n√£o acreditava em nada tanto em sua vida como agora acredita na import√¢ncia de preparar a humanidade para este grande evento. <br><br>  A perspectiva externa diz outra coisa.  As pessoas se vestem de forma estranha, t√™m contas, vivem em algum tipo de campo remoto, falam ao mesmo tempo e um pouco assustadoras.  E, embora seus argumentos sejam de ferro, toda a sua experi√™ncia diz que voc√™ encontrou um culto. <br><br>  √â claro que eles t√™m grandes argumentos sobre por que voc√™ deve ignorar o instinto, mas essa √© uma perspectiva interna.  Uma perspectiva externa n√£o se importa com o conte√∫do, ela v√™ a forma e o contexto e n√£o gosta do resultado. <br><br>  Portanto, eu gostaria de lidar com o risco de IA de ambas as perspectivas.  Acho que os argumentos a favor da superintelig√™ncia s√£o est√∫pidos e cheios de suposi√ß√µes n√£o suportadas.  Mas se eles lhe parecerem convincentes, algo desagrad√°vel est√° relacionado ao alarmismo da IA, como um fen√¥meno cultural, pelo qual devemos relutar em levar a s√©rio. <br><br>  Primeiro, alguns dos meus argumentos contra a superintelig√™ncia de Bostroma, que representam um risco para a humanidade. <br><br><h3>  Argumento contra defini√ß√µes difusas </h3><br>  ¬´   ¬ª ()   .             ,   ,      ,   ,    . <br><br>       ,   ‚Äì  -   ,  ,          (  -)       . <br><br>      (    ),    ,     .  ,     ‚Äì  . , ,   ,  ,             .                  . <br><br><h3>      </h3><br>   ‚Äì      , , ,       .    ? <br><br>                .      .   ,       ,       ,     .               ,        . <br><br>   ,        ,    ‚Äì .         ,    -  ,      .     ,   ,   . <br><br>       ,  ,     ¬´,  ¬ª,   ,   ,    ¬´,  ¬ª. <br><br><h3>     </h3><br>       ,   .  ,       .         ,       ,  ,   . <br><br>       ,     ,           . <br><br>    ,  ,   ,   ,   . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12a/820/5a7/12a8205a776841eb3f2e5d759f674964.jpg"><br><br><h3>    </h3><br>     .   ,      ,        . <br><br>  1930-      ,   ,    .        ,  . <br><br>     :     , ,   ,     .   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a> ,       . <br><br><h3>     </h3><br>      .       -.               ,     ,  ,  ,   ,     ? <br><br>     Ethereum,     ,         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a> . <br><br>  ,             <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> .   ,         -  , ,         ,     . <br><br><h3>     </h3><br>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> .  ,          ,    .          ,         ,      .          ,   ,        ,    ‚Äì   . <br><br>       .   ,  ,   ; , ,      . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c64/5ba/9a4/c645ba9a437c79019622c86f9e2f6fd2.jpg"><br><br>   ¬´  ¬ª   ,    ,  ,  ,     ‚Äì      , ¬´  ?¬ª   ,    ‚Äì  ,        . <br><br>  ,   ¬´ ¬ª     ,    ,     reddit/r/paperclip,  ,    . <br><br>   AdSense  ,            . <br><br><h3>     </h3><br>    ,     ,  ,          .          .          ,     . <br><br> Google   Google Home,               . <br><br>  ,  ,   ,     .    ,      .     ,   ¬´¬ª,          . <br><br><h3>    </h3><br>          ,   .    ,  ,    ‚Äì        World of Warcraft    . <br><br>   ,       ,     ,     ,    ,       . <br><br>  ,       ,       ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a> . <br><br><h3>    </h3><br>        ,     ,     , ,   ,       ,  -. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a>   ,  ,     [-,      ,         2016    ,        / . .].    .       . <br><br>         ,    .         .    ,      ,    ,         . <br><br><h3>    </h3><br>      .    ,                  ,      .          ,      ,  -   . <br><br> ,        ,  ,  .      ,            . <br><br>  ,          ‚Äì         .     ,       ,          ,    . <br><br>  ,   ,       ,              ,        ,    . <br><br><h3>    * </h3><br> [ <i>  1954       / . .</i> ] <br><br>       ,         ,  ,        .   ,            ,         ,      (       ). <br><br>         Intel   ,    ,       . <br><br><h3>   </h3><br>          ?    . <br><br>        ,         .    ,         . <br><br><h3>  </h3><br>  Se voc√™ acha que a IA nos permitir√° conquistar a gal√°xia (sem mencionar a simula√ß√£o de trilh√µes de mentes), voc√™ ter√° n√∫meros assustadores em suas m√£os.  Grandes n√∫meros multiplicados por pequenas probabilidades s√£o a marca do alarmismo da IA. <br><br>  Bostrom em algum momento descreve o que, em sua opini√£o, est√° em jogo: <br><br>  Se imaginarmos toda a felicidade experimentada durante uma vida na forma de uma l√°grima de alegria, a felicidade de todas essas almas ser√° capaz de preencher e encher os oceanos da Terra a cada segundo, e fazer isso por centenas de bilh√µes de bilh√µes de mil√™nios.  √â muito importante garantirmos que essas l√°grimas sejam l√°grimas de alegria. <br><br>  Um fardo bastante pesado para os ombros de um desenvolvedor de vinte anos! <br><br>  Aqui, √© claro, existe um "foco no sal√£o", quando multiplicando quantidades astron√¥micas por pequenas probabilidades, podemos convencer-nos da necessidade de fazer algumas coisas estranhas. <br><br>  Todo esse movimento em rela√ß√£o √† salva√ß√£o do futuro da humanidade √© um compromisso covarde.  Experimentamos os mesmos argumentos para justificar o comunismo, para explicar por que tudo est√° sempre quebrado e as pessoas n√£o podem ter um n√≠vel elementar de conforto material. <br><br>  √çamos consertar este mundo e, depois dessa felicidade, haver√° tanta coisa que a vida cotidiana de cada pessoa melhorar√°.  No entanto, para isso, foi necess√°rio primeiro consertar o mundo. <br><br>  Eu moro na Calif√≥rnia, e aqui est√° a maior porcentagem de mendigos entre todos os Estados Unidos, embora o Vale do Sil√≠cio tamb√©m esteja localizado aqui.  N√£o vejo nada que minha rica ind√∫stria fizesse para melhorar a vida das pessoas comuns e das pessoas angustiadas ao nosso redor.  No entanto, se voc√™ √© apaixonado pela id√©ia de superintelig√™ncia, a pesquisa no campo da IA ‚Äã‚Äãser√° a coisa mais importante que voc√™ pode fazer no planeta.  Isso √© mais importante do que pol√≠tica, mal√°ria, crian√ßas famintas, guerras, aquecimento global - tudo o que voc√™ pode imaginar.  De fato, sob a amea√ßa de trilh√µes e trilh√µes de criaturas, toda a popula√ß√£o do futuro da humanidade, simulada e presente, resumiu-se ao longo do tempo futuro.  E nessas condi√ß√µes, o trabalho em outros problemas n√£o parece racional. <br><br><h3>  Megalomania </h3><br>  Essa atitude se funde com a megalomania, com esses vil√µes de Bond, que podem ser vistos no topo de nossa ind√∫stria.  As pessoas pensam que o mundo ser√° dominado pela superintelig√™ncia e usam esse argumento para justificar por que as pessoas inteligentes devem primeiro tentar dominar o mundo - para corrigi-lo antes que a IA o destrua. <br><br>  Joey Ito, chefe do MIT Media Lab, em uma conversa recente com Obama, disse uma coisa maravilhosa: <br><br>  Isso pode incomodar um dos meus alunos do MIT, mas uma das minhas preocupa√ß√µes √© que as principais informa√ß√µes relacionadas √† IA sejam jovens, principalmente brancos, que gostam de conversar com computadores mais do que outras pessoas.  Muitos deles acreditam que, se puderem criar essa IA de uso geral a partir de fic√ß√£o cient√≠fica, n√£o precisaremos nos preocupar com coisas feias, como pol√≠tica e sociedade.  Eles acham que os carros inventam tudo para n√≥s. <br><br>  Percebendo que o mundo n√£o √© uma tarefa de programa√ß√£o, as pessoas obcecadas pela IA querem transform√°-lo em uma tarefa de programa√ß√£o projetando uma m√°quina semelhante a um deus.  Isso √© megalomania, e eu n√£o gosto disso. <br><br><h3>  Transumanismo vodu </h3><br>  Se voc√™ est√° convencido dos riscos da IA, precisar√° levar um vag√£o inteiro de cren√ßas tristes para eles com um trailer. <br><br>  Para iniciantes, isso √© nanotecnologia.  Qualquer superintelig√™ncia permanente poder√° criar carros min√∫sculos capazes de todos os tipos de coisas diferentes.  Vamos viver em uma sociedade que se livrou de um d√©ficit em que h√° abund√¢ncia de qualquer material. <br><br>  A nanotecnologia tamb√©m poder√° escanear seu c√©rebro para que voc√™ possa carreg√°-lo em outro corpo ou no mundo virtual.  Portanto, a segunda consequ√™ncia da superintelig√™ncia amig√°vel √© que ningu√©m morre - e nos tornamos imortais. <br><br>  Uma boa IA pode at√© ressuscitar os mortos.  As nanom√°quinas ser√£o capazes de entrar no meu c√©rebro, estudar as mem√≥rias de meu pai e criar sua simula√ß√£o, com a qual eu possa interagir, e que sempre ficar√° decepcionada comigo, independentemente do que eu fa√ßa. <br><br>  Outra consequ√™ncia estranha do advento da IA ‚Äã‚Äã√© a expans√£o gal√°ctica.  Eu nunca conseguia entender por que isso acontece, mas essa √© a base das id√©ias dos transhumanistas.  O destino da humanidade √© deixar o planeta e colonizar a gal√°xia ou morrer.  E essa tarefa est√° se tornando mais urgente, dado que outras civiliza√ß√µes poderiam fazer a mesma escolha e podem nos ultrapassar na corrida espacial. <br><br>  Portanto, muitas id√©ias complementares estranhas s√£o anexadas √† suposi√ß√£o da exist√™ncia da verdadeira IA. <br><br><h3>  Religi√£o 2.0 </h3><br>  De fato, √© um tipo de religi√£o.  As pessoas chamavam a cren√ßa na singularidade tecnol√≥gica de "um apocalipse para os nerds", e √©.  Este √© um truque legal - em vez de acreditar em um deus externo, voc√™ imagina como cria uma criatura cuja funcionalidade √© id√™ntica a Deus.  Aqui at√© ateus verdadeiros podem racionalizar seu caminho para uma f√© confort√°vel. <br><br>  A IA tem todos os atributos de um deus: ele √© onipotente, onisciente e √© favor√°vel (se voc√™ organizou corretamente a verifica√ß√£o dos limites da matriz) ou o diabo puro, em cuja miseric√≥rdia voc√™ est√°.  E, como em qualquer religi√£o, existe at√© um senso de urg√™ncia.  Precisa agir hoje!  Em jogo est√° o destino do mundo!  E, √© claro, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">eles precisam de dinheiro</a> . <br><br>  Como esses argumentos apelam aos instintos religiosos, uma vez enraizados, s√£o muito dif√≠ceis de eliminar. <br><br><h3>  √âtica em quadrinhos </h3><br>  Essas cren√ßas religiosas d√£o origem a uma √©tica em quadrinhos, na qual v√°rios her√≥is solit√°rios recebem a tarefa de salvar o mundo com tecnologia e mente afiada.  E em jogo est√° o destino do universo.  Como resultado, nossa ind√∫stria est√° cheia de caras ricos imaginando-se Batman (curiosamente, ningu√©m quer ser Robin). <br><br><h3>  Simula√ß√µes de febre </h3><br>  Se voc√™ acredita na possibilidade de vida artificial e que a IA pode desenvolver computadores extremamente poderosos, provavelmente acreditar√° que vivemos em uma simula√ß√£o.  Aqui est√° como isso funciona. <br><br>  Suponha que voc√™ seja um historiador que vive em um mundo ap√≥s a singularidade.  Voc√™ est√° estudando a Segunda Guerra Mundial e est√° interessado em saber o que acontecer√° se Hitler tomar Moscou em 1941. Como voc√™ tem acesso a hipercomputadores, cria uma simula√ß√£o, observa como os ex√©rcitos convergem e escreve um artigo cient√≠fico. <br><br>  Mas devido √† granularidade da simula√ß√£o, seus personagens s√£o criaturas inteligentes como voc√™.  Portanto, o conselho de √©tica da sua universidade n√£o permitir√° que voc√™ desative a simula√ß√£o.  Voc√™ n√£o apenas fingiu ser o Holocausto.  Como pesquisador √©tico, voc√™ agora precisa manter a simula√ß√£o operacional. <br><br>  Como resultado, o mundo simulado ir√° inventar computadores, a IA, come√ßar√° a executar suas pr√≥prias simula√ß√µes.  De certa forma, as simula√ß√µes v√£o cada vez mais longe na hierarquia at√© voc√™ ficar sem energia do processador. <br><br>  Portanto, qualquer realidade subjacente pode conter um grande n√∫mero de simula√ß√µes aninhadas, e um simples <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">argumento de contagem</a> prova que a probabilidade de vivermos em uma simula√ß√£o √© maior do que vivemos no mundo real. <br><br>  Mas acreditar nisso significa acreditar em m√°gica.  Se estamos em uma simula√ß√£o, n√£o sabemos nada sobre as regras em um n√≠vel superior.  Nem sabemos se a matem√°tica funciona da mesma maneira - talvez no mundo da simula√ß√£o 2 + 2 = 5 ou at√© 2 + 2 =. <br><br>  Um mundo simulado n√£o fornece informa√ß√µes sobre o mundo em que foi lan√ßado.  Na simula√ß√£o, as pessoas podem ressuscitar facilmente se o administrador salvou os backups necess√°rios.  E se entrarmos em contato com um dos administradores, ent√£o, de fato, teremos uma linha direta com Deus. <br><br>  Esta √© uma s√©ria amea√ßa √† sanidade.  Quanto mais voc√™ mergulha no mundo das simula√ß√µes, mais voc√™ fica louco. <br><br>  Agora temos quatro maneiras independentes de nos tornarmos imortais atrav√©s da supermente: <br><br><ol><li>  A IA benevolente inventa a nanotecnologia m√©dica e ap√≥ia para sempre o corpo em um estado jovem. </li><li>  A IA inventa uma varredura completa do c√©rebro, incluindo varreduras cerebrais de pessoas mortas, cabe√ßas congeladas etc., o que permite que voc√™ viva em um computador. </li><li>  A IA ‚Äúressuscita‚Äù as pessoas, examinando o c√©rebro de outras pessoas em busca das mem√≥rias de uma pessoa, combina isso com v√≠deos e outros materiais.  Se ningu√©m se lembra bem de uma pessoa, ele sempre pode crescer do zero em uma simula√ß√£o que come√ßa com seu DNA e recria todas as condi√ß√µes de vida. </li><li>  Se j√° vivemos na simula√ß√£o, h√° uma chance de que quem a tenha lan√ßado mantenha backups e que voc√™ possa convenc√™-los a fazer o download. </li></ol><br>  √â isso que quero dizer com IA abordando impulsos religiosos.  Que outro sistema de cren√ßas oferece quatro op√ß√µes para a imortalidade cientificamente comprovada? <br><br>  Aprendemos que pelo menos um plutocrata americano (provavelmente Elon Musk, que acredita que as chances de vivermos em uma simula√ß√£o √© de um bilh√£o para um) contratou um par de codificadores para tentar decifrar a simula√ß√£o.  Mas essa √© uma inten√ß√£o muito grosseira!  Eu uso isso! <br><br>  Se voc√™ acha que mora em um programa de computador, as tentativas de traz√™-lo para o segfault n√£o s√£o razo√°veis ‚Äã‚Äãpara todos que moram nele com voc√™.  Isso √© muito mais perigoso e irrespons√°vel do que os cientistas nucleares que tentam explodir a atmosfera. <br><br><h3>  Sede por dados </h3><br>  Como j√° mencionei, a maneira mais eficaz de obter algo interessante da IA ‚Äã‚Äãque criamos √© descart√°-los com dados.  Essa din√¢mica √© socialmente prejudicial.  Chegamos perto da introdu√ß√£o orwelliana de microfones em todas as casas.  Os dados de IA ser√£o centralizados, eles ser√£o usados ‚Äã‚Äãpara treinar redes neurais, que poder√£o ent√£o ouvir melhor nossos desejos. <br><br>  Mas se voc√™ acha que esse caminho nos leva √† IA, voc√™ deseja maximizar a quantidade de dados coletados e no menor formato poss√≠vel modificado.  Isso apenas refor√ßa a ideia da necessidade de coletar o m√°ximo de dados e realizar a vigil√¢ncia mais abrangente. <br><br><h3>  Teoria das Cordas para Programadores </h3><br>  O risco da IA ‚Äã‚Äã√© a teoria das cordas para programadores.  √â divertido pensar sobre isso, √© interessante e completamente inacess√≠vel para experimentos no n√≠vel da tecnologia moderna.  Voc√™ pode construir pal√°cios de cristais mentais que funcionam com base em princ√≠pios prim√°rios, e depois subir neles e apertar a escada atr√°s deles. <br><br>  Pessoas capazes de chegar a conclus√µes absurdas com base em uma longa cadeia de racioc√≠nio abstrato e permanecer confiantes em sua verdade - n√£o s√£o pessoas que precisam confiar na administra√ß√£o cultural. <br><br><h3>  O caminho para a loucura </h3><br>  Toda essa √°rea de "pesquisa" leva √† loucura.  Uma das caracter√≠sticas do pensamento profundo sobre os riscos de IA √© que, quanto mais loucas s√£o suas id√©ias, mais popular voc√™ se torna entre outros entusiastas.  Isso demonstra sua coragem de seguir essa linha de pensamento at√© o fim. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ray Kurzweil</a> , que acredita que n√£o vai morrer, trabalha com o Google h√° v√°rios anos e agora, provavelmente, est√° trabalhando nesse problema.  O Vale do Sil√≠cio geralmente est√° cheio de pessoas trabalhando em projetos malucos sob o pretexto de dinheiro. <br><br><h3>  Cosplay AI </h3><br>  O efeito social mais prejudicial da ansiedade sobre a IA √© o que eu chamo de AI de cosplay.  As pessoas que est√£o convencidas da realidade e inevitabilidade da IA ‚Äã‚Äãcome√ßam a se comportar conforme suas fantasias lhes dizem sobre o que a IA superinteligente pode fazer. <br><br>  Em seu livro, Bostrom lista seis coisas que a IA deve ter sucesso antes de capturar o mundo: <br><br><ol><li>  Multiplica√ß√£o de intelig√™ncia. </li><li>  Pensamento estrat√©gico. </li><li>  Manipula√ß√£o social. </li><li>  Hacks </li><li>  Pesquisa tecnol√≥gica. </li><li>  Produtividade Econ√¥mica. </li></ol><br>  Se voc√™ olhar para os adeptos da IA ‚Äã‚Äãdo Vale do Sil√≠cio, eles mesmos parecem estar trabalhando nessa lista quase sociop√°tica. <br><br>  Sam Altman, chefe do YCombinator, √© meu exemplo favorito de um arqu√©tipo desse tipo.  Aparentemente, ele √© fascinado pela id√©ia de reinventar o mundo do zero, maximizando a influ√™ncia e a produtividade pessoal.  Ele designou equipes para trabalhar na inven√ß√£o das cidades do zero e est√° envolvido em fraudes pol√≠ticas ocultas para influenciar a elei√ß√£o. <br><br>  Esse comportamento da ‚Äúcapa e adaga‚Äù, inerente √† elite do techno, provocar√° uma rea√ß√£o negativa de pessoas que n√£o est√£o envolvidas em tecnologias que n√£o gostam de ser manipuladas.  √â imposs√≠vel puxar infinitamente as alavancas do poder; acabar√° por irritar outros membros da comunidade democr√°tica. <br><br>  Eu assisti pessoas do chamado  ‚ÄúComunidades racionalistas‚Äù se referem a pessoas que n√£o s√£o consideradas efetivas, ‚Äúpersonagens n√£o-jogadores‚Äù (NPCs), um termo emprestado dos jogos.  Esta √© uma maneira terr√≠vel de ver o mundo. <br><br>  Por isso, trabalho em um setor em que os racionalistas autoproclamados s√£o as pessoas mais loucas.  Isso √© esmagador. <br><br>  Esses cosplayers de IA s√£o como crian√ßas de nove anos montando um acampamento no quintal, brincando com lanternas em tendas.  Eles projetam suas pr√≥prias sombras nas paredes da tenda e ficam com medo deles como se fossem monstros. <br><br>  Mas, de fato, eles respondem a uma imagem distorcida de si mesmos.  H√° um ciclo de feedback entre como as pessoas inteligentes imaginam o comportamento da intelig√™ncia divina e como elas constroem seu pr√≥prio comportamento. <br><br>  Ent√£o, qual √© a resposta, como isso pode ser corrigido? <br><br>  Precisamos de melhor fic√ß√£o cient√≠fica!  E, como em muitos outros casos, j√° temos a tecnologia. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8fa/7bb/a47/8fa7bba47a9f451102465e23774d291f.jpg"><br><br>  Este √© Stanislav Lem, o grande escritor polon√™s de fic√ß√£o cient√≠fica.  A NF em ingl√™s √© terr√≠vel, mas no bloco oriental temos muitos bens bons e precisamos export√°-los corretamente.  Ele j√° foi traduzido ativamente para o ingl√™s; essas tradu√ß√µes s√≥ precisam ser melhor distribu√≠das. <br><br>  O que distingue autores como Lem ou os irm√£os Strugatsky de seus parceiros ocidentais √© que eles cresceram em condi√ß√µes dif√≠ceis, sobreviveram √† guerra e depois viveram em sociedades totalit√°rias, onde precisavam expressar suas id√©ias n√£o diretamente, atrav√©s de uma palavra impressa. <br><br>  Eles t√™m uma compreens√£o real da experi√™ncia humana e das limita√ß√µes do pensamento ut√≥pico, praticamente ausente no Ocidente. <br><br>  H√° exce√ß√µes not√°veis ‚Äã‚Äã- Stanley Kubrick conseguiu fazer isso - mas √© extremamente raro encontrar uma NF americana ou brit√¢nica que expresse uma vis√£o restrita do que n√≥s, como esp√©cie, podemos fazer com a tecnologia. <br><br><h3>  Alquimistas </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/fdc/b9e/596/fdcb9e5963c4ad447547319ebf394f40.jpg" alt="imagem"><br><br>  Como eu critico o alarmismo da IA, √© justo colocar minhas cartas na mesa.  Eu acho que nosso entendimento da mente est√° aproximadamente no mesmo estado em que a alquimia estava no s√©culo XVII. <br><br>  Alquimistas t√™m uma m√° reputa√ß√£o.  N√≥s os consideramos m√≠sticos, na maioria das vezes n√£o envolvidos no trabalho experimental.  Pesquisas modernas mostram que eles eram qu√≠micos-praticantes muito mais diligentes do que pensamos.  Em muitos casos, eles usaram t√©cnicas experimentais modernas, mantiveram registros de laborat√≥rio e fizeram as perguntas certas. <br><br>  Os alquimistas entendiam muitas coisas corretamente!  Por exemplo, eles estavam convencidos da teoria corpuscular da mat√©ria: que tudo consiste em pequenos peda√ßos e que √© poss√≠vel compor esses peda√ßos de maneiras diferentes, criando diferentes subst√¢ncias - e √© assim! <br><br>  O problema deles era a falta de equipamentos precisos necess√°rios para fazer as descobertas necess√°rias.  A grande descoberta que um alquimista precisa fazer √© a lei da conserva√ß√£o da massa: o peso dos ingredientes iniciais coincide com o peso do final.  No entanto, alguns deles podem ser gases ou l√≠quidos em evapora√ß√£o, e os alquimistas simplesmente n√£o tinham precis√£o.  A qu√≠mica moderna n√£o era poss√≠vel at√© o s√©culo XVIII. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/21b/5b2/888/21b5b28887c09eeebc52c57e43025c42.jpg"><br><br>  Mas os alquimistas tamb√©m tinham pistas que os confundiam.  Eles estavam obcecados com merc√∫rio.  Quimicamente, o merc√∫rio n√£o √© particularmente interessante, mas √© o √∫nico metal na fase l√≠quida √† temperatura ambiente.  Isso parecia muito importante para os alquimistas e os fez colocar merc√∫rio no centro de seu sistema alqu√≠mico e em sua busca pela Pedra Filosofal, uma maneira de transformar metais comuns em ouro. <br><br>  A neurotoxicidade do merc√∫rio exacerbou a situa√ß√£o.  Se voc√™ brinca demais com ela, pensamentos estranhos surgir√£o para voc√™.  Nesse sentido, assemelha-se √†s nossas experi√™ncias mentais atuais relacionadas √† supermente. <br><br>  Imagine que enviamos um livro de qu√≠mica moderna para o passado a algum grande alquimista como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">George Starkey</a> ou Isaac Newton.  A primeira coisa que eles fariam com isso seria percorr√™-lo em busca de uma resposta para a quest√£o de saber se hav√≠amos encontrado a Pedra Filosofal.  E eles saberiam que o encontramos!  Realizamos o sonho deles! <br><br>  Mas n√£o gostamos muito, porque depois de transformar metais em ouro, ele se torna radioativo.  Fique ao lado de um lingote de ouro convertido e ele o matar√° com raios m√°gicos invis√≠veis. <br><br>  Pode-se imaginar o qu√£o dif√≠cil seria fazer com que os conceitos modernos de radioatividade e energia at√¥mica n√£o soassem m√≠sticos para eles. <br><br>  Ter√≠amos de explicar a eles por que usamos a ‚Äúpedra filosofal‚Äù: para a fabrica√ß√£o de metal que nunca existiu no planeta, e um punhado de punhados √© suficiente para explodir uma cidade inteira se eles colidirem a uma velocidade suficientemente alta. <br><br>  Al√©m disso, ter√≠amos de explicar aos alquimistas que todas as estrelas no c√©u s√£o "pedras filos√≥ficas" que transformam um elemento em outro, e que todas as part√≠culas em nossos corpos v√™m de estrelas do firmamento que existia e explodiu antes da Terra aparecer. <br><br> ,   ,  ,     ,      ,  ,     ,   ,     ,        ,  . <br><br>   ,  ,   ,      ,    ,     ,       .     ‚Äì     .      ,   . <br><br>   ,           .     .   ‚Äì  .        , ,  (     ),    ,   . <br><br>          ,     ,         . <br><br>      ,      .  ,        .  ,     ,  ,         .  ,         ,   ,      . <br><br>       .    ,     ,           . <br><br>    ,      , ,  ,   ,    .    ,     . <br><br>       ,   ‚Äì ,     ¬´¬ª,  ,     .       .  E isso √© √≥timo!   .    ,    : <br><blockquote>      ,  ,   ,    . <br> ‚Äî   </blockquote>       ,    ,         ,      . <br><br>    ,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>      ,     ,  ,   -   ,   ,    . <br><br>         ,       ,   ,      ,         . <br><br> , ,   ,       .    ,   -      .    ,      . <br><br>        , ,  ,     ,    . <br><br>  ,        . ,       - ,   ,       , ,   ,    . <br><br>        :   ,  ,     .  ! <br><br>         ,       ‚Äì   ,    ,       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt432806/">https://habr.com/ru/post/pt432806/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt432796/index.html">M√≥dulo de computa√ß√£o, modelos 2019</a></li>
<li><a href="../pt432798/index.html">Melhor sistema operacional de seguran√ßa: compara√ß√£o do Titan</a></li>
<li><a href="../pt432800/index.html">Investiga√ß√£o de incidentes de seguran√ßa com o StaffCop Enterprise 4.4</a></li>
<li><a href="../pt432802/index.html">Seis plataformas gratuitas de aprendizado de programa√ß√£o automatizada</a></li>
<li><a href="../pt432804/index.html">Toda a verdade sobre o RTOS. Artigo 24. Filas: servi√ßos auxiliares e estruturas de dados</a></li>
<li><a href="../pt432808/index.html">Sal√°rios em IA: onde h√° mais dinheiro e quem eles procuram na R√∫ssia</a></li>
<li><a href="../pt432810/index.html">Primeiras multas para o RGPD: quem j√° foi punido</a></li>
<li><a href="../pt432812/index.html">Escrevemos rob√¥s de negocia√ß√£o usando a estrutura gr√°fica StockSharp. Parte 1</a></li>
<li><a href="../pt432814/index.html">Integra√ß√£o Cake e TeamCity</a></li>
<li><a href="../pt432816/index.html">AXIS M3046-V vs IDIS DC-D3212X: Compare C√¢meras CFTV</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üó£Ô∏è üôÉ ü§± El camino m√°s suave y peludo en aprendizaje autom√°tico y redes neuronales profundas ü§¥üèø ü§òüèª üë©üèª‚Äçü§ù‚Äçüë®üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El aprendizaje autom√°tico moderno le permite hacer cosas incre√≠bles. Las redes neuronales funcionan en beneficio de la sociedad: encuentran delincuent...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>El camino m√°s suave y peludo en aprendizaje autom√°tico y redes neuronales profundas</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/470904/">  El aprendizaje autom√°tico moderno le permite hacer cosas incre√≠bles.  Las redes neuronales funcionan en beneficio de la sociedad: encuentran delincuentes, reconocen amenazas, ayudan a diagnosticar enfermedades y toman decisiones dif√≠ciles.  Los algoritmos pueden superar a una persona en creatividad: pintan cuadros, escriben canciones y hacen obras maestras a partir de cuadros comunes.  Y aquellos que desarrollan estos algoritmos a menudo se presentan como cient√≠ficos caricaturizados. <br><br>  ¬°No todo es tan aterrador!  Cualquiera que est√© familiarizado con la programaci√≥n puede construir una red neuronal a partir de modelos b√°sicos.  Y ni siquiera es necesario aprender Python, todo se puede hacer en JavaScript nativo.  Es f√°cil comenzar y por qu√© el aprendizaje autom√°tico es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">necesario</a> para los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">proveedores de</a> front-end, dijo <strong>Alexey</strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">Okhrimenko</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">obenjiro</a> ) en FrontendConf, y lo transferimos al texto para que los nombres de la arquitectura y los enlaces √∫tiles est√©n a la mano. <br><br><h2>  Spoiler  Alerta </h2><br>  Esta historia: <br><br><ul><li>  <strong>No para aquellos que ya</strong> trabajan con Machine Learning.  Algo interesante ser√°, pero es poco probable que bajo el corte est√© esperando la apertura. </li><li>  <strong>No se trata de transferencia de aprendizaje.</strong>  No hablaremos sobre c√≥mo escribir una red neuronal en Python, y luego trabajaremos con ella desde JavaScript.  Sin trampas: escribiremos redes neuronales profundas espec√≠ficamente en JS. </li><li>  <strong>No todos los detalles.</strong>  En general, todos los conceptos no caben en un art√≠culo, pero por supuesto analizaremos lo necesario. </li></ul><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BX2M8t5BA3s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>Sobre el orador:</strong> Alexei Okhrimenko trabaja en Avito en el departamento de Arquitectura Frontend, y en su tiempo libre dirige el Meetup Angular de Mosc√∫ y lanza el "Five Minute Angular".  Durante una larga carrera, ha desarrollado el patr√≥n de dise√±o MALEVICH, el analizador gramatical PEG SimplePEG.  El mantenedor de Alexey CSSComb comparte regularmente conocimientos sobre nuevas tecnolog√≠as en conferencias y en su <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">canal de telegramas de</a> aprendizaje autom√°tico JS. <br><br><h2>  El aprendizaje autom√°tico es muy popular. </h2><br>  Los asistentes de voz, Siri, el Asistente de Google, Alice, son populares y a menudo se encuentran en nuestras vidas.  Muchos productos han pasado del procesamiento de datos algor√≠tmicos convencionales al aprendizaje autom√°tico.  Un ejemplo sorprendente es Google Translate. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/cg/uz/z3cguzzlmogpjxmymmqhok5xw50.jpeg"></div><br>  Todas las innovaciones y los chips m√°s geniales en los tel√©fonos inteligentes se basan en el aprendizaje autom√°tico. <br><br><img src="https://habrastorage.org/webt/qd/2m/1g/qd2m1gmmouw29qcfbytgd5gdcoc.jpeg"><br><br>  Por ejemplo, Google NightSight utiliza el aprendizaje autom√°tico.  Las fotos geniales que vemos no se obtuvieron con lentes, sensores o estabilizaci√≥n, sino con la ayuda del aprendizaje autom√°tico.  La m√°quina finalmente venci√≥ a las personas en DOTA2, lo que significa que tenemos pocas posibilidades de derrotar la inteligencia artificial.  Por lo tanto, debemos dominar el aprendizaje autom√°tico lo m√°s r√°pido posible. <br><br><h2>  Comencemos con un simple </h2><br>  ¬øCu√°l es nuestra rutina de programaci√≥n diaria, c√≥mo solemos escribir funciones? <br><img src="https://habrastorage.org/webt/n1/kn/ss/n1knssbigatyl2zrakkoaazsuai.jpeg"><br>  Tomamos datos y un algoritmo que nosotros mismos inventamos o tomamos de los populares ya preparados, combinamos, hacemos un poco de magia y obtenemos una funci√≥n que nos da la respuesta correcta en una situaci√≥n dada. <br><br>  Estamos acostumbrados a este orden de cosas, pero habr√≠a una oportunidad, sin conocer el algoritmo, pero simplemente teniendo los datos y la respuesta, obtener el algoritmo de ellos. <br><br><img src="https://habrastorage.org/webt/tq/6p/4w/tq6p4wwa4ctyhg_j7a4b_t2dhl0.jpeg"><br><br>  Puedes decir: "Soy un programador, siempre puedo escribir un algoritmo". <br><br>  Ok, pero por ejemplo, ¬øqu√© algoritmo se necesita aqu√≠? <br><br><img src="https://habrastorage.org/webt/mq/ey/ce/mqeycerayzppkiqobxr_-o13oka.jpeg"><br><br>  Supongamos que el gato tiene orejas afiladas y las orejas del perro son opacas, peque√±as, como un pug. <br><br><img src="https://habrastorage.org/webt/nv/dp/-h/nvdp-h5hvyset6n3fz-q6ya03hs.jpeg"><br><br>  Tratemos de entender qui√©n es qui√©n por los o√≠dos.  Pero en alg√∫n momento, descubrimos que los perros pueden tener orejas afiladas. <br><br><img src="https://habrastorage.org/webt/uk/j2/pr/ukj2prwe9ln0hdjj6x0qa5q9vxw.jpeg"><br><br>  Nuestra hip√≥tesis no es buena, necesitamos otras caracter√≠sticas.  Con el tiempo, aprenderemos m√°s y m√°s detalles, desmotiv√°ndonos cada vez m√°s y, en alg√∫n momento, querremos abandonar este negocio por completo. <br><br>  Me imagino una imagen ideal como esta: de antemano hay una respuesta (sabemos qu√© tipo de imagen es), hay datos (sabemos que el gato est√° dibujado), queremos obtener un algoritmo que pueda alimentar los datos y obtener respuestas en la salida. <br><br>  Hay una soluci√≥n: esto es el aprendizaje autom√°tico, es decir, una de sus partes: redes neuronales profundas. <br><br><h2>  Redes neuronales profundas </h2><br>  El aprendizaje autom√°tico es un √°rea enorme.  Ofrece una cantidad gigantesca de m√©todos, y cada uno es bueno a su manera. <br><br><img src="https://habrastorage.org/webt/qv/8t/kj/qv8tkjpyrk_qeia-hp4fxkvco7w.jpeg"><br><br>  Uno de ellos es Deep Neural Networks.  El aprendizaje profundo tiene una ventaja innegable debido a que se ha vuelto popular. <br><br>  Para comprender esta ventaja, veamos el problema cl√°sico de clasificaci√≥n usando gatos y perros como ejemplo. <br><br>  Hay datos: fotos o fotos.  Lo primero que debe hacer es incrustar (incrustar), es decir, transformar los datos para que la m√°quina se sienta c√≥moda trabajando con ellos.  Es inconveniente trabajar con im√°genes, el auto necesita algo m√°s simple. <br><br>  Primero, alinee las im√°genes y elimine el color.  No importa de qu√© color sea el perro o el gato, es importante determinar el tipo de animal.  Luego convertimos las im√°genes en matrices, donde, por ejemplo, 0 es oscuro, 1 es claro. <br><br><img src="https://habrastorage.org/webt/th/st/aq/thstaqtmxfb1jqo-eacmrtlaxym.jpeg"><br><br>  Con esta presentaci√≥n de datos, las redes neuronales ya pueden funcionar. <br><br>  Vamos a crear dos matrices m√°s y fusionarlas en una cierta "capa".  Luego, multiplicamos cada uno de los elementos de la capa y la matriz de datos entre s√≠ utilizando una simple multiplicaci√≥n de matrices, y dirigimos el resultado a dos funciones de activaci√≥n (luego analizaremos cu√°les son estas funciones).  Si la funci√≥n de activaci√≥n recibe una cantidad suficiente de valores, entonces se "activa" y producir√° el resultado: <br><br><ul><li>  la primera funci√≥n devolver√° 1 si es un gato y 0 si no es un gato. </li><li>  la segunda funci√≥n devolver√° 1 si es un perro y 0 si no es un perro. </li></ul><br>  Este enfoque para codificar una respuesta se denomina <strong>codificaci√≥n de uno en caliente</strong> . <br><br><img src="https://habrastorage.org/webt/bb/-a/x5/bb-ax5li-ngkav87ibjjazse6m4.jpeg"><br><br>  Ya se notan varias caracter√≠sticas de las redes neuronales profundas: <br><br><ul><li>  Para trabajar con redes neuronales, necesita codificar datos en la entrada y decodificar en la salida. </li><li>  La codificaci√≥n nos permite hacer un resumen de los datos. </li><li>  Al cambiar los datos de entrada, podemos generar redes neuronales para diferentes dominios de dominio.  Incluso aquellos en los que no somos expertos. </li></ul><br>  No es necesario saber qu√© es un gato, qu√© es un perro.  Es suficiente seleccionar los n√∫meros necesarios para una capa adicional. <br><br>  Hasta ahora, lo √∫nico que no est√° claro es por qu√© estas redes se llaman "profundas". <br>  Todo es muy simple: podemos crear otra capa (matrices y sus funciones de activaci√≥n).  Y transfiere el resultado de una capa a otra. <br><br><img src="https://habrastorage.org/webt/9n/8r/qh/9n8rqhrwuewcgwa17oq-beuj7r4.jpeg"><br><br>  Puede colocar entre s√≠ tantas de estas capas y sus funciones para la activaci√≥n.  Combinando arquitectura en capas, obtenemos una red neuronal profunda.  Su profundidad es una multitud de capas.  Y colectivamente llamado el <strong>"modelo"</strong> . <br><br>  Ahora veamos c√≥mo se seleccionan los valores para todas estas capas.  Hay una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">visualizaci√≥n</a> genial que le permite comprender c√≥mo ocurre el proceso de aprendizaje. <br><br><img src="https://habrastorage.org/webt/aw/ot/at/awotatoajim-4vykkxk5wgldodq.jpeg"><br><br>  A la izquierda hay datos, y a la derecha est√° una de las capas.  Se puede ver que al cambiar los valores dentro de las matrices de capas, parece que cambiamos el sistema de coordenadas.  Adapt√°ndose as√≠ a los datos y al aprendizaje.  Por lo tanto, el aprendizaje es el proceso de seleccionar los valores correctos para las matrices de capas.  Estos valores se llaman pesos o pesos. <br><br><h2>  El aprendizaje autom√°tico es dif√≠cil </h2><br>  Quiero molestarte, el aprendizaje autom√°tico es dif√≠cil.  Todo lo anterior es una gran simplificaci√≥n.  En el futuro, encontrar√° una gran cantidad de √°lgebra lineal y bastante compleja.  Por desgracia, no hay escapatoria de esto. <br><br>  Por supuesto, hay cursos, pero incluso el entrenamiento m√°s r√°pido dura varios meses y no es barato.  Adem√°s, todav√≠a tienes que resolverlo t√∫ mismo.  El campo del aprendizaje autom√°tico ha crecido tanto que hacer un seguimiento de todo es casi imposible.  Por ejemplo, a continuaci√≥n hay un conjunto de modelos para resolver solo una tarea (detecci√≥n de objetos): <br><br><img src="https://habrastorage.org/webt/tw/bx/rs/twbxrs3-fary0wir6wd-e4x_2_i.jpeg"><br><br>  Personalmente, estaba muy desmotivado.  No pod√≠a acercarme a las redes neuronales y comenzar a trabajar con ellas.  Pero he encontrado un camino y quiero compartirlo contigo.  No es revolucionario, no hay nada de eso en eso, ya est√°s familiarizado con eso. <br><br><h2>  Blackbox: un enfoque simple </h2><br>  No es necesario comprender absolutamente todos los aspectos del aprendizaje autom√°tico para aprender c√≥mo aplicar redes neuronales a sus tareas comerciales.  Mostrar√© algunos ejemplos que espero te inspiren. <br><br>  Para muchos, un autom√≥vil tambi√©n es una caja negra.  Pero incluso si no sabe c√≥mo funciona, debe aprender las reglas.  Entonces, con el aprendizaje autom√°tico, a√∫n necesita conocer algunas reglas: <br><br><ul><li>  Aprenda TensorFlow JS (biblioteca para trabajar con redes neuronales). </li><li>  Aprende a elegir modelos. </li></ul><br>  Nos centramos en estas tareas y comenzamos con el c√≥digo. <br><br><h2>  Aprendiendo creando c√≥digo </h2><br>  La biblioteca TensorFlow est√° escrita para una gran cantidad de lenguajes: Python, C / C ++, JavaScript, Go, Java, Swift, C #, Haskell, Julia, R, Scala, Rust, OCaml, Crystal.  Pero definitivamente elegiremos el mejor: JavaScript. <br><br>  TensorFlow se puede conectar a nuestra p√°gina conectando un script con CDN: <br><br><pre><code class="javascript hljs">&lt;script src=<span class="hljs-string"><span class="hljs-string">"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"</span></span>&gt;<span class="xml"><span class="hljs-tag"><span class="xml"><span class="hljs-tag">&lt;/</span></span><span class="hljs-name"><span class="xml"><span class="hljs-tag"><span class="hljs-name">script</span></span></span></span><span class="xml"><span class="hljs-tag">&gt;</span></span></span></span></code> </pre> <br>  O use npm: <br><br><ul><li>  <code>npm install @tensorflow/tfjs-node</code> - para el proceso de nodo (sitio web); </li><li>  <code>npm install @tensorflow/tfjs-node-gpu</code> (Linux CUDA) - para la GPU, pero solo si la m√°quina Linux y la tarjeta de video son compatibles con la tecnolog√≠a CUDA.  Aseg√∫rese de asegurarse de que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CUDA Compute Capability</a> coincida con su biblioteca para que no resulte que el hardware costoso no es adecuado. </li><li>  <code>npm install @tensorflow/tfjs</code> ( <code>npm install @tensorflow/tfjs</code> / Browser) - para un navegador sin usar Node.js. </li></ul><br>  Para trabajar con TensorFlow JS, es suficiente importar uno de los m√≥dulos anteriores.  Ver√° muchos ejemplos de c√≥digo donde se importa todo.  No es necesario hacer esto, seleccione e importe solo uno. <br><br><h3>  Tensores </h3><br>  Cuando los datos iniciales est√°n listos, lo primero que debe hacer es <strong>importar TensorFlow</strong> .  Usaremos tensorflow / tfjs-node-gpu para obtener aceleraci√≥n debido a la potencia de la tarjeta de video. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  @tensorflow/tfjs-node-gpu  node.js const tf = require('@tensorflow/tfjs'); const a = [[1,2], [3,4]];</span></span></code> </pre> <br>  Hay una matriz de datos bidimensional, trabajaremos con ella. <br><br>  Lo siguiente que debe hacer es <strong>crear un tensor</strong> .  En este caso, se crea un tensor de rango 2, es decir, de hecho, una matriz bidimensional.  Transferimos los datos y obtenemos el tensor 2x2. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//  rank-2  (/) const b = tf.tensor([[1,2], [3,4]]); console.log('shape:', b.shape); b.print()</span></span></code> </pre> <br>  Tenga en cuenta que el m√©todo de <code>print</code> se llama, no <code>console.log</code> , porque <code>b</code> (el tensor que creamos) no es un objeto ordinario, es decir, el tensor.  √âl tiene sus propios m√©todos y propiedades. <br><br>  Tambi√©n puede crear un tensor a partir de una matriz plana y tener en cuenta su forma, digamos.  Es decir, declarar una forma, una matriz bidimensional, para transmitir simplemente una matriz plana e indicar directamente la forma.  El resultado ser√° el mismo. <br><br>  Debido al hecho de que los datos y el formulario se pueden almacenar por separado, puede cambiar la forma del tensor.  Podemos llamar al m√©todo de <code>reshape</code> y cambiar la forma de 2x2 a 4x1. <br><br>  El siguiente paso importante es <strong>generar los datos</strong> , devolverlos al mundo real. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const g = tf.tensor([[1,2], [3,4]]); g.data().then((raw) =&gt; { console.log('async raw value of g:', raw); }); console.log('raw value of g:', g.dataSync()); console.log('raw multidimensional value of g:', g.arraySync());</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El c√≥digo para</a> los tres pasos.</i> <br><br>  El m√©todo de <code>data</code> devuelve promesa.  Despu√©s de que se resuelve, obtenemos el valor inmediato del valor bruto, pero lo obtenemos de forma asincr√≥nica.  Si queremos, podemos obtenerlo sincr√≥nicamente, pero recuerda que aqu√≠ puedes perder rendimiento, as√≠ que usa m√©todos asincr√≥nicos siempre que sea posible. <br><br>  El m√©todo <code>dataSync</code> siempre devuelve datos en un formato de matriz plana.  Y si queremos devolver los datos en el formato en que est√°n almacenados en el tensor, debemos llamar a <code>arraySync</code> . <br><br><h3>  Operadores </h3><br>  Todos los operadores en TensorFlow son <strong>inmutables por defecto</strong> , es decir, en cada operaci√≥n siempre se devuelve un nuevo tensor.  Arriba, simplemente tome nuestra matriz y cuadre todos sus elementos. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   Immutable const x = tf.tensor([1,2,3,4]); const y = x.square(); // tf.square(x); y.print();</span></span></code> </pre> <br>  ¬øPor qu√© tantas dificultades para las operaciones matem√°ticas simples?  Todos los operadores que necesitamos, la suma, la mediana, etc., est√°n ah√≠.  Esto es necesario porque, de hecho, el tensor y este enfoque le permiten crear un gr√°fico de c√°lculos y realizar c√°lculos no inmediatamente, sino en WebGL (en el navegador) o CUDA (Node.js en la m√°quina).  Es decir, el uso real de Aceleraci√≥n de hardware es invisible para nosotros y, si es necesario, la recuperaci√≥n de la CPU.  Lo bueno es que no necesitamos pensar en nada al respecto.  Solo necesitamos aprender la API de tfjs. <br><br>  Ahora lo m√°s importante es el modelo. <br><br><h3>  Modelo </h3><br>  La forma m√°s f√°cil de crear un modelo es secuencial, es decir, un modelo secuencial, cuando los datos de una capa se transfieren a la siguiente capa, y de ella a la siguiente capa.  Se usan las capas m√°s simples que se usan aqu√≠. <blockquote>  La capa en s√≠ es solo una abstracci√≥n de tensores y operadores.  En t√©rminos generales, estas son funciones auxiliares que te ocultan una gran cantidad de matem√°ticas. </blockquote><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//    const model = tf.sequential({ layers: [ tf.layers.dense({ inputShape: [784], units: 32, activation: 'relu' }), tf.layers.dense({ units: 10, activation: 'softmax' }) ] });</span></span></code> </pre> <br>  Intentemos comprender c√≥mo trabajar con el modelo sin entrar en los detalles de implementaci√≥n. <br><br>  Primero, indicamos la forma de datos que cae en la red neuronal: <code>inputShape</code> es un par√°metro requerido.  Indicamos <code>units</code> : el n√∫mero de matrices multidimensionales y la funci√≥n de activaci√≥n. <br><br>  La funci√≥n <code>relu</code> notable porque se encontr√≥ por casualidad: se prob√≥, funcion√≥ mejor y, durante mucho tiempo, buscaron una explicaci√≥n matem√°tica de por qu√© sucede esto. <br><br>  Para la √∫ltima capa, cuando hacemos una categor√≠a, a menudo se usa la funci√≥n softmax: es muy adecuada para mostrar una respuesta en el formato de codificaci√≥n One-Hot.  Despu√©s de crear el modelo, llame a <code>model.summary()</code> para asegurarse de que el modelo est√© ensamblado de la manera correcta.  En situaciones particularmente dif√≠ciles, puede abordar la creaci√≥n de un modelo utilizando la programaci√≥n funcional. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const input = tf.input({ shape: [784] }); const dense1 = tf.layers.dense({ units: 32, activation: 'relu' }).apply(input); const dense2 = tf.layers.dense({ units: 10, activation: 'softmax' }).apply(dense1); const model = tf.model({ inputs: input, outputs: dense2 });</span></span></code> </pre> <br>  Si necesita crear un modelo particularmente complejo, puede utilizar el enfoque funcional: cada vez que cada capa es una nueva variable.  Como ejemplo, tomamos manualmente la siguiente capa y le aplicamos la capa anterior, para que podamos construir arquitecturas m√°s complejas.  M√°s tarde te mostrar√© d√≥nde puede ser √∫til. <br><br>  El siguiente detalle muy importante es que pasamos las capas de entrada y salida al modelo, es decir, las capas que ingresan a la red neuronal y las capas que son capas para la respuesta. <br><br>  Despu√©s de esto, un paso importante es <strong>compilar el modelo</strong> .  Tratemos de entender qu√© es la compilaci√≥n en t√©rminos de tfjs. <br><br>  Recuerde, tratamos de encontrar los valores correctos en nuestra red neuronal.  No es necesario recogerlos.  Se seleccionan de cierta manera, como dice la funci√≥n optimizadora. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   (  ) model.compile({ optimizer: 'sgd', loss: 'categoricalCrossentropy', metrics: ['accuracy'] });</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo para la</a> descripci√≥n de capas secuenciales y compilaci√≥n.</i> <br><br>  Ilustrar√© qu√© es un optimizador y qu√© es una funci√≥n de p√©rdida. <br><br><img src="https://habrastorage.org/webt/se/lt/1l/selt1lv8ppxvokzopux387dp0os.png"><br><br>  El optimizador es todo el mapa.  Le permite no solo correr al azar y buscar valor, sino hacerlo sabiamente, de acuerdo con cierto algoritmo. <br><br>  La funci√≥n de p√©rdida es la forma en que buscamos el valor √≥ptimo (peque√±a flecha negra).  Ayuda a entender qu√© valores de gradiente usar para entrenar nuestra red neuronal. <br><br>  En el futuro, cuando domine las redes neuronales, usted mismo escribir√° una funci√≥n de p√©rdida.  Gran parte del √©xito de una red neuronal depende de qu√© tan bien escrita est√© esta funci√≥n.  Pero esta es otra historia.  Comencemos simple. <br><br><h4>  Ejemplo de aprendizaje en red </h4><br>  Generaremos datos aleatorios y respuestas aleatorias (etiquetas).  Llamamos al m√≥dulo de <code>fit</code> , pasamos los datos, las respuestas y varios par√°metros importantes: <br><br><ul><li>  <code>epochs</code> : 5 veces, es decir, aproximadamente, 5 veces llevaremos a cabo un entrenamiento completo; </li><li>  <code>batchSize</code> , que indica cu√°ntos pesos se pueden cambiar a la vez para levantar, cu√°ntos elementos procesar al mismo tiempo.  Cuanto mejor sea la tarjeta de video, m√°s memoria tiene, m√°s <code>batchSize</code> se puede configurar. </li></ul><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//   const data = tf.randomNormal([100, 784]); const labels = tf.randomNormal([100, 10]); //   model.fit(data, labels, { epochs: 5, batchSize: 32 }).then(info =&gt; { console.log('  :', info.history.acc); })</span></span></code> </pre> <br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo de</a> todos los √∫ltimos pasos.</i> <br><br>  <code>Model.fit</code> asincr√≥nico <code>Model.fit</code> , devuelve promesa.  Pero puede usar async / await y esperar la ejecuci√≥n de esa manera. <br><br>  El siguiente es el <strong>uso</strong> .  Entrenamos nuestro modelo, luego tomamos los datos que queremos procesar, y llamamos al m√©todo de <code>predict</code> , decimos: "¬øPredecir qu√© hay realmente all√≠?", Y gracias a esto obtenemos el resultado. <br><br><h3>  Estructura est√°ndar </h3><br>  Cada red neuronal tiene tres archivos principales: <br><br><ul><li>  index.js: archivo en el que se almacenan todos los par√°metros de la red neuronal; </li><li>  model.js: un archivo en el que el modelo y su arquitectura se almacenan directamente; </li><li>  data.js: un archivo donde los datos se recopilan, procesan e incrustan en nuestro sistema. </li></ul><br>  Entonces, habl√© sobre c√≥mo aprender TensorFlow.js.  Peque√±a empresa, queda <strong>por elegir un modelo</strong> . <br><br>  Desafortunadamente, esto no es del todo cierto.  De hecho, cada vez que elige un modelo, debe repetir ciertos pasos. <br><br><ul><li>  Prepare datos para ello, es decir, realice la incrustaci√≥n, aj√∫stelo a la arquitectura. </li><li>  Configure los ajustes de Hyper (m√°s adelante le dir√© lo que esto significa). </li><li>  Entrenar / entrenar cada red neuronal (cada modelo puede tener sus propios matices). </li><li>  Aplique un modelo neuronal y, de nuevo, puede aplicar de diferentes maneras. </li></ul><br><h2>  Elige un modelo </h2><br>  Comencemos con las opciones b√°sicas que a menudo encontrar√°. <br><br><h3>  Sentido profundo </h3><br>  Este es un ejemplo popular de una red neuronal profunda.  Todo se hace de manera bastante simple: hay un conjunto de datos disponible p√∫blicamente: el conjunto de datos MNIST. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6g/yu/-4/6gyu-4wjgg4zfvf8w7byjx_z5yw.jpeg" width="600"></div><br>  Estas son im√°genes etiquetadas con n√∫meros, en base a las cuales es conveniente entrenar una red neuronal. <br><br>  De acuerdo con la arquitectura de One-Hot Encoding, codificamos cada una de las √∫ltimas capas.  D√≠gitos 10: en consecuencia, habr√° 10 √∫ltimas capas al final.  Simplemente enviamos fotos en blanco y negro a la entrada, todo esto es muy similar a lo que hablamos al principio. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> model = tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">784</span></span>], <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">256</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> }), ] });</code> </pre> <br>  Enderezamos la imagen en una matriz unidimensional, obtenemos 784 elementos.  En una capa 512 matrices.  Funci√≥n de activaci√≥n <code>'relu'</code> . <br><br>  La siguiente capa de matrices es ligeramente m√°s peque√±a (256), la capa de activaci√≥n tambi√©n es <code>'relu'</code> .  Redujimos el n√∫mero de matrices para buscar caracter√≠sticas m√°s generales.  A la red neuronal se le debe indicar c√≥mo aprender y forzarla a tomar una decisi√≥n m√°s seria y general, porque ella misma no lo har√°. <br><br>  Al final, hacemos 10 matrices y utilizamos la activaci√≥n de softmax para la codificaci√≥n One-Hot: este tipo de activaci√≥n funciona bien con este tipo de codificaci√≥n de respuesta. <br><br>  Las redes profundas le permiten reconocer correctamente el 80-90% de las im√°genes; quiero m√°s.  Una persona reconoce con una calidad de aproximadamente el 96%.  ¬øPueden las redes neuronales atrapar y alcanzar a una persona? <br><br><h3>  CNN (red neuronal convolucional) </h3><br>  Las redes de convoluci√≥n funcionan incre√≠blemente simples.  Al final, tienen la misma arquitectura que en los ejemplos anteriores.  Pero al principio, sucede algo m√°s.  Las matrices, en lugar de solo dar algunas soluciones, reducen la imagen.  Toman parte de la imagen y la reducen, la contraen a un d√≠gito.  Luego se recogen todos juntos y nuevamente se reducen. <br><img src="https://habrastorage.org/webt/mi/xc/gk/mixcgkl0kgopjxgams8szm0wr2q.jpeg"><br>  Por lo tanto, el tama√±o de la imagen se reduce, pero al mismo tiempo, partes de la imagen se reconocen cada vez mejor.  Las redes de convoluci√≥n funcionan muy bien para el reconocimiento de patrones, incluso mejor que los humanos. <br><blockquote>  Reconocer im√°genes se conf√≠a mejor a un autom√≥vil que a una persona.  Hubo un estudio especial, y la persona, desafortunadamente, perdi√≥. </blockquote>  Las CNN funcionan de manera muy simple: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> model = tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>], <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }), tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }), tf.layers.maxPooling2d({<span class="hljs-attr"><span class="hljs-attr">poolSize</span></span>: [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>]}), tf.layers.conv2d({ <span class="hljs-attr"><span class="hljs-attr">filters</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-attr"><span class="hljs-attr">kernelSize</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>, }) tf.layers.flatten(tf.layers.maxPooling2d({ <span class="hljs-attr"><span class="hljs-attr">poolSize</span></span>: [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>] })), tf.layers.dense({<span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'relu'</span></span>}), tf.layers.dense({<span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span>}) ] });</code> </pre> <br>  Ingresamos una matriz multidimensional espec√≠fica: una imagen de 28x28 p√≠xeles, m√°s una dimensi√≥n para el brillo, en este caso la imagen es en blanco y negro, por lo que la tercera dimensi√≥n es 1. <br><br>  A continuaci√≥n, establecemos la cantidad de <code>filters</code> y <code>kernelSize</code> : cu√°ntos p√≠xeles se reducir√°n.  Funci√≥n de activaci√≥n en todas partes <code>relu</code> . <br><br>  Hay otra capa <code>maxPooling2d</code> , que es necesaria para reducir el tama√±o de manera a√∫n m√°s eficiente.  Las redes de convoluci√≥n reducen el tama√±o muy gradualmente y, a menudo, no hay necesidad de crear redes de convoluci√≥n muy profundas. <br><br>  Explicar√© por qu√© es imposible hacer redes de convoluci√≥n muy profundas un poco m√°s tarde, pero por ahora, recuerda: a veces necesitan ser un poco m√°s r√°pidas.  Hay una capa maxPooling separada para esto. <br><br>  Al final hay la misma capa densa.  Es decir, utilizando redes neuronales convolucionales, extrajimos varios signos de los datos, despu√©s de lo cual usamos el enfoque est√°ndar y categorizamos nuestros resultados, gracias a lo cual reconocemos las im√°genes. <br><br><h3>  U net </h3><br>  Este modelo de arquitectura est√° asociado con redes de convoluci√≥n.  Con su ayuda, se han realizado muchos descubrimientos en el campo del control del c√°ncer, por ejemplo, en el reconocimiento de las c√©lulas cancerosas y el glaucoma.  Adem√°s, este modelo puede encontrar c√©lulas malignas no peores que un profesor en esta √°rea. <br><br>  Un ejemplo simple: entre los datos ruidosos que necesita para encontrar c√©lulas cancerosas (c√≠rculos). <br><br><img src="https://habrastorage.org/webt/hj/9b/yr/hj9byresramxnetrg7t_kenia0a.jpeg"><br><br>  U-Net es tan bueno que puede encontrarlos casi a la perfecci√≥n.  La arquitectura es muy simple: <br><br><img src="https://habrastorage.org/webt/16/5_/vx/165_vxamsqm5eveub2tdhzxprc8.jpeg"><br><br>  Existen las mismas redes de convoluci√≥n, al igual que MaxPooling, que reduce el tama√±o.  La √∫nica diferencia: el modelo tambi√©n utiliza redes de <strong>exploraci√≥n</strong> , la <strong>red deconvolucional</strong> . <br><br>  Adem√°s del escaneo de convoluci√≥n, cada una de las capas de alto nivel se combina entre s√≠ (inicio y salida), debido a lo cual aparecen una gran cantidad de relaciones.  Tal U-Net funciona bien incluso en peque√±as cantidades de datos. <br><br><pre> <code class="javascript hljs"><span class="hljs-comment"><span class="hljs-comment">//First part (down climb) const input = buildInput(...IMAGE_INPUT); const conv1 = genConv2D(64).apply(input); const conv2 = genConv2D(64).apply(conv1); const pool1 = geMaxPool2D(2).apply(conv2); const conv3 = genConv2D(128).apply(pool1); const conv4 = genConv2D(128).apply(conv3); const pool2 = geMaxPool2D(2).apply(conv4); const conv5 = genConv2D(256).apply(pool2); const conv6 = genConv2D(256).apply(conv5); const pool3 = geMaxPool2D(2).apply(conv6); const conv7 = genConv2D(512).apply(pool3); const conv8 = genConv2D(512).apply(conv7); const pool4 = geMaxPool2D(2).apply(conv8); const conv9 = genConv2D(1024).apply(pool4); const conv10 = genConv2D(1024).apply(conv9); const up1 = genUp2D().apply(conv10); const merge1 = tf.layers.concatenate({ axis: 3 }).apply([up1, conv8]); //Second part (up climb) const conv11 = genConv2D(512).apply(merge1); const conv12 = genConv2D(512).apply(conv11); const up2 = genUp2D().apply(conv12); const merge2 = tf.layers.concatenate({ axis: 3 }).apply([up2, conv6]); const conv13 = genConv2D(256).apply(merge2); const conv14 = genConv2D(256).apply(conv13); const up3 = genUp2D().apply(conv14); const merge3 = tf.layers.concatenate({ axis: 3 }).apply([up3, conv4]); const conv15 = genConv2D(128).apply(merge3); const conv16 = genConv2D(128).apply(conv15); const up4 = genUp2D().apply(conv16); const merge4 = tf.layers.concatenate({ axis: 3 }).apply([up4, conv2]); const conv17 = genConv2D(64).apply(merge4); const conv18 = genConv2D(64).apply(conv17); const conv19 = tf.layers .conv2d({ kernelSize: [1, 1], activation: "sigmoid", filters: 1, padding: "same" }) .apply(conv18); const model = tf.model({ inputs: input, outputs: conv19 });</span></span></code> </pre> <br>  Este c√≥digo es m√°s f√°cil de aprender en el editor.  En general, aqu√≠ se crea una gran cantidad de redes de convoluci√≥n, y luego, para desplegarlas de nuevo, <code>concatenate</code> y fusionamos varias capas.  Esto es solo una visualizaci√≥n de una imagen, solo en forma de c√≥digo.  Todo es bastante simple: copiar y reproducir este modelo es f√°cil. <br><br><h2>  LSTM (memoria larga a corto plazo) </h2><br>  Tenga en cuenta que todos los ejemplos considerados tienen una caracter√≠stica: el formato de datos de entrada es fijo.  La entrada a la red, los datos deben ser del mismo tama√±o y coincidir entre s√≠.  Los modelos LSTM se centran en c√≥mo lidiar con esto. <br><br>  Por ejemplo, hay un servicio Yandex.Referats, que genera res√∫menes. <br><br><img src="https://habrastorage.org/webt/_o/g7/mh/_og7mh4hlaz87r6jpbkzjqsgdbc.png"><br><br>  Emite un abracadabra completo, pero al mismo tiempo bastante similar a la verdad: <br><br><blockquote>  <strong>Resumen en matem√°ticas sobre el tema: "El binomio de Newton como axioma"</strong> <br><br>  Seg√∫n lo anterior, la integral de superficie produce una integral curvil√≠nea.  La funci√≥n convexa hacia abajo todav√≠a est√° en demanda. <br><br>  De esto se deduce naturalmente que lo normal a la superficie todav√≠a est√° en demanda.  Seg√∫n lo anterior, la integral de Poisson especifica esencialmente la integral trigonom√©trica de Poisson. </blockquote><br>  El servicio se basa en redes neuronales Seq-to-Seq.  Su arquitectura es m√°s compleja. <br><br><img src="https://habrastorage.org/webt/6r/3s/aw/6r3sawht3bnxadqmorz0vjqwzmw.jpeg"><br><br>  Las capas se organizan en un sistema bastante complejo.  Pero no se alarme: no tiene que conducir todas estas flechas usted mismo.  Si quieres, puedes, pero no es necesario.  Hay un ayudante que har√° esto por usted. <br><br>  Lo principal a entender es que cada una de estas piezas se combina con la anterior.  Toma datos no solo de los datos iniciales, sino tambi√©n de la capa neural anterior.  En t√©rminos generales, es posible construir alg√∫n tipo de memoria: memorizar una secuencia de datos, reproducirla y, debido a este trabajo, "secuencia a secuencia".  Adem√°s, las secuencias pueden ser de diferentes tama√±os tanto en la entrada como en la salida. <br><br>  Todo se ve hermoso en el c√≥digo: <br><br><pre> <code class="javascript hljs">tf.sequential({ <span class="hljs-attr"><span class="hljs-attr">layers</span></span>: [ tf.layers.lstm({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">returnSequences</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">inputShape</span></span>: [<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">64</span></span>] }), tf.layers.lstm({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">512</span></span>, <span class="hljs-attr"><span class="hljs-attr">returnSequences</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> }), tf.layers.dense({ <span class="hljs-attr"><span class="hljs-attr">units</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-attr"><span class="hljs-attr">activation</span></span>: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> }) ] }) ;</code> </pre> <br>  Hay un asistente especial que dice que tenemos 512 objetos (matrices).  Luego, devuelva la secuencia y el formulario de entrada ( <code>inputShape: [10000, 64]</code> ).  Luego presentamos otra capa, pero no devolvemos la secuencia ( <code>returnSequences: false</code> ), porque al final decimos que ahora necesitamos usar la funci√≥n de activaci√≥n para 64 caracteres diferentes (letras min√∫sculas y may√∫sculas).  64 opciones se activan utilizando One-Hot Encoding. <br><br><h2>  Mas interesante </h2><br>  Ahora, probablemente se est√© preguntando: ‚ÄúEsto es todo, por supuesto, bueno, pero ¬øpor qu√© lo necesito?  "Combatir el c√°ncer es bueno, pero ¬øpor qu√© lo necesito en primera l√≠nea?" <br><br>  Y comienzan los bailes con una pandereta: para descubrir c√≥mo aplicar redes neuronales al dise√±o, por ejemplo. <br><blockquote>  Con la ayuda de redes neuronales es posible resolver problemas que antes eran imposibles de resolver.  Algunos que ni siquiera se te ocurrieron.  Todo depende de ti, tu imaginaci√≥n y un poco de pr√°ctica. </blockquote>  Ahora mostrar√© ejemplos interesantes en vivo del uso de los modelos que examinamos. <br><br><h3>  CNN  Equipos de audio </h3><br>  Usando redes de convoluci√≥n, puede reconocer no solo im√°genes, sino tambi√©n comandos de audio, y con un 97% de calidad de reconocimiento, es decir, a nivel de Google Assistant y Yandex-Alice. <br><br>  Solo en la red, por supuesto, no es posible reconocer el discurso completo, las oraciones, pero puede crear un asistente de voz simple. <br><br>  Puede encontrar m√°s informaci√≥n sobre Alice en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">informe de</a> Nikita Dubko, y sobre el asistente de Google, c√≥mo trabajar con voz en √©l y sobre los est√°ndares del navegador, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  El hecho es que cualquier palabra, cualquier comando puede convertirse en un espectrograma. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/au/_v/r8/au_vr8gdnqh3k6gkcgyhz0ybwoq.jpeg" width="500"></div><br>  Puede convertir cualquier informaci√≥n de audio en dicho espectrograma.  Y luego puede codificar el audio en una imagen, aplicar CNN a la imagen y reconocer comandos de voz simples. <br><br><h3>  U-net.  Prueba de captura de pantalla </h3><br>  U-Net es √∫til no solo para el diagn√≥stico exitoso del c√°ncer, sino tambi√©n, por ejemplo, para probar capturas de pantalla.  Para m√°s detalles, vea el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">informe de</a> Lyudmila Mzhachikh, y le dir√© a la base misma. <br><br>  Para probar con capturas de pantalla, se necesitan dos capturas de pantalla: <br><br><ul><li>  b√°sico (referencia) con el que estamos comparando; </li><li>  captura de pantalla para probar. </li></ul><br><img src="https://habrastorage.org/webt/kx/2g/ci/kx2gcib0rilb_zzhohk15dmnoi4.jpeg"><br>  Desafortunadamente, en las pruebas de captura de pantalla, a menudo hay muchas ca√≠das negativas (falsos positivos).  Pero esto se puede evitar aplicando tecnolog√≠as avanzadas de control del c√°ncer en el front-end. <br><br>  Recuerde, marcamos la imagen en el √°rea donde hay c√°ncer y no.  Lo mismo se puede hacer aqu√≠. <br><br><img src="https://habrastorage.org/webt/19/kk/uw/19kkuwktd9iv30ffolxasj3_l-k.jpeg"><br><br>  Si vemos una imagen con un buen dise√±o, no la marcamos y marcamos im√°genes con un dise√±o deficiente.  Por lo tanto, puede probar el dise√±o con una sola imagen.   ,     ,   ,    . U-Net     . <br><br>       ,    ,    .  ,          U-Net,  .  ,   . <br><br><h3> LSTM. Twitter ‚Äî  2000 </h3><br>   ,    ,     ,    . <br><br>       ,     LSTM  .   40     - , : <em>¬´ ‚Äî     ¬ª</em> . <br><br>   ,  : <br><br><img src="https://habrastorage.org/webt/yu/_6/xk/yu_6xkkdkak9jganrrpvxs6vd9g.jpeg"><br><br> -   , ? <br><br>  ‚Äî .    -   : <br><br><img src="https://habrastorage.org/webt/lk/hz/sf/lkhzsfwyvs42ky2yi-k6m5reu7o.jpeg"><br><br><img src="https://habrastorage.org/webt/ai/a7/jv/aia7jvkjsgw35wpjixbsko4vjwe.jpeg"><br><br>  ,   ¬´¬ª       ,       ,        (,  ). <br><br>  : <em>¬´    ¬ª</em>  <em>¬´   ¬ª</em> . <br><br>       ‚Äî  . <br><blockquote> ¬´   ¬ª. </blockquote><br>      : <br><br><img src="https://habrastorage.org/webt/lv/ud/dp/lvuddp8bnuagbh4kgmsao3j_qvo.jpeg"><br><br><h4> EPOCS 250 </h4><br>    ,     . <br><br>    -   , ,  ,     .   ,      Overfitting ‚Äî . <br><br>   ,    ‚Äî       .  , , .   ,   ,         ,         . <br><br>    ,       ,          . <br><br>  ,       . <br><br><img src="https://habrastorage.org/webt/cv/_j/ft/cv_jftct2bzeb2_ik1apzezgjsg.jpeg"><br><br>   , ,        ,        .      ( ,  ),      .          . <br><blockquote>     ‚Äî    .    . </blockquote>      overfitting.      ,    helper-: Dropout; BatchNormalization. <br><br><h3> LSTM. Prettier </h3><br>  ,     ‚Äî  Prettier   .       ,     . <br><br>  <code>const a = 1</code> .    : <code>[]c co on ns st</code> ,    ,            : <code>[][] []c co on ns st</code> ,      . <br><br>     ,            ,     . <br><br> ,    ,     .      , ,  0 ‚Äî  ,      -  ,  - .   . <br><br>            ,      .         . <br><br><h2>  En lugar de conclusiones </h2><br> , ,     .   . , ,         Deep Neural Network. <br><br>        .         ,      .      .            .     . <br><br>       JS,       ,     .         ,      .  ,   JavaScript,         .     TensorFlow.js. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><em></em></a> <em> ,     .    </em> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><em>telegram-</em></a> <em>    JS.</em> <br><blockquote>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FrontendConf</a>    , 13 .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> 32        . <br><br>    ,    ,           .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a>  Saint AppsConf,       .      ,  ,    ,     . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/470904/">https://habr.com/ru/post/470904/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../470884/index.html">Escribir y leer datos en la cadena de bloques de Bitcoin</a></li>
<li><a href="../470888/index.html">La legislaci√≥n rusa e internacional en el √°mbito de la protecci√≥n de datos personales.</a></li>
<li><a href="../470892/index.html">Implementaci√≥n simple de CAM peque√±o en FPGA</a></li>
<li><a href="../470894/index.html">Bala</a></li>
<li><a href="../470902/index.html">Alto rendimiento y particionamiento nativo: Zabbix con soporte TimescaleDB</a></li>
<li><a href="../470908/index.html">Por primera vez en el mundo con la ayuda de tecnolog√≠as aditivas, se obtuvo un conjunto de motor de avi√≥n de gran tama√±o</a></li>
<li><a href="../470910/index.html">¬øQu√© se puede hacer con anotaciones de contratos de microservicios?</a></li>
<li><a href="../470916/index.html">El punto de control electr√≥nico "m√°s barato" en Rusia controlado desde un tel√©fono inteligente</a></li>
<li><a href="../470918/index.html">F # 9: Opci√≥n de tipo</a></li>
<li><a href="../470920/index.html">M√°s de 5 formas de conectarse a una nube de l√≠nea de datos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
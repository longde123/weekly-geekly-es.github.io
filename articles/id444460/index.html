<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>☑️ 🕊️ 🚢 Dari parser poster teater Python ke bot Telegram. Bagian 1 💐 👨🏽‍🎓 💇🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Saya sangat suka opera dan balet, tetapi tidak benar-benar - memberikan banyak uang untuk tiket. Tampilan harian situs web teater dengan tusukan di se...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Dari parser poster teater Python ke bot Telegram. Bagian 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/444460/"><img src="https://habrastorage.org/webt/en/ph/hi/enphhiao8qi4l5r9iao0vbrskhg.jpeg"><br><br>  Saya sangat suka opera dan balet, tetapi tidak benar-benar - memberikan banyak uang untuk tiket.  Tampilan harian situs web teater dengan tusukan di setiap tombol sangat melelahkan, dan tiket 170 rubel untuk kereta super yang tiba-tiba muncul sangat memilukan. <br>  Untuk mengotomatiskan bisnis ini, muncul skrip yang berjalan di poster dan mengumpulkan informasi tentang tiket termurah untuk bulan yang dipilih.  Permintaan dari seri "mengeluarkan daftar semua opera pada bulan Maret di panggung lama dan baru hingga 1000 rubel."  Seorang teman terjatuh “apakah kamu tidak melakukan bot Telegram?”  Ini tidak ada dalam rencana, tetapi mengapa tidak.  Bot lahir, meskipun berputar di laptop rumah. <br>  Kemudian Telegram diblokir.  Gagasan untuk mendorong bot ke server yang bekerja telah hilang, dan minat untuk membawa fungsionalitas ke pikiran telah memudar.  Di bawah potongan, saya berbicara tentang nasib seorang detektif tiket murah dari awal dan apa yang terjadi padanya setelah satu tahun digunakan. <br><a name="habracut"></a><br><h3>  1. Asal usul ide dan pernyataan masalah <br></h3><br>  Dalam produksi awal, keseluruhan cerita memiliki satu tugas - untuk membuat daftar pertunjukan, disaring berdasarkan harga, untuk menghemat waktu dalam melihat secara manual setiap kinerja poster secara individual.  Satu-satunya teater yang posternya menarik adalah dan tetap Mariinsky.  Pengalaman pribadi dengan cepat menunjukkan bahwa "galeri" anggaran dibuka pada hari-hari acak untuk pertunjukan acak, dan dibeli dengan cukup cepat (jika staf berdiri).  Agar tidak ketinggalan apa pun, seorang pengumpul otomatis diperlukan. <br><div class="spoiler">  <b class="spoiler_title">Jenis poster dengan tombol yang harus Anda navigasikan secara manual</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/4fa/35a/13e/4fa35a13ede41a01443fbc3e91450d3c.jpg" alt="gambar"><br></div></div><br>  Saya ingin mendapatkan serangkaian pertunjukan menarik untuk menjalankan naskah.  Kriteria utama, seperti telah disebutkan, adalah harga tiket. <br>  API situs dan sistem tiket tidak tersedia untuk umum, sehingga keputusan dibuat (tanpa basa-basi lagi) untuk mem-parsing halaman HTML, mengeluarkan tag yang diperlukan.  Buka yang utama, tekan F12 dan pelajari strukturnya.  Itu terlihat memadai, sehingga semuanya dengan cepat mencapai implementasi pertama. <br>  Jelas bahwa pendekatan ini tidak skala ke situs lain dengan poster dan akan hancur jika mereka memutuskan untuk mengubah struktur saat ini.  Jika pembaca memiliki ide tentang cara membuatnya lebih stabil tanpa API, tulis di komentar. <br><br><h3>  2. Implementasi pertama.  Fungsionalitas minimum </h3><br>  Saya datang dengan implementasi dengan pengalaman dengan Python hanya untuk menyelesaikan tugas yang berkaitan dengan pembelajaran mesin.  Dan tidak ada pemahaman mendalam tentang html dan arsitektur web (dan itu tidak muncul).  Karena itu, semuanya dilakukan sesuai dengan prinsip "ke mana aku pergi, aku tahu, tetapi sekarang kita akan menemukan cara untuk pergi" <br>  Untuk draft pertama, butuh 4 jam malam dan pengantar untuk permintaan dan modul Beautiful Soup 4 (bukan tanpa bantuan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel yang</a> bagus, terima kasih kepada penulis).  Untuk menyelesaikan sketsa - hari libur lain.  Saya tidak sepenuhnya yakin bahwa modul adalah yang paling optimal di segmen mereka, tetapi mereka telah menutup kebutuhan mereka saat ini.  Inilah yang terjadi pada tahap pertama. <br>  Informasi apa dan di mana menariknya dapat dipahami oleh struktur situs.  Pertama-tama, kami mengumpulkan alamat pengiriman yang ada di poster untuk bulan yang dipilih. <br><div class="spoiler">  <b class="spoiler_title">Struktur halaman poster di browser, semuanya disorot dengan mudah</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/3f8/142/fda/3f8142fdad0789bac8558d2f0481b021.jpg" alt="gambar"><br></div></div><br>  Dari halaman html, kita perlu membaca URL murni, lalu menjelajahinya dan melihat label harganya.  Beginilah daftar tautan disusun. <br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_text</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(url)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># URL  html r = requests.get(url) text=r.text return text def get_items(text,top_name,class_name): """   html-  "" url-, ..  - .       top_name  class_name   -  &lt;a class="c_theatre2 c_chamber_halls" href="//tickets.mariinsky.ru/ru/performance/WWpGeDRORFUwUkRjME13/"&gt; &lt;/a&gt; """ soup = BeautifulSoup(text, "lxml") film_list = soup.find('div', {'class': top_name}) items = film_list.find_all('div', {'class': [class_name]}) dirty_link=[] for item in items: dirty_link.append(str(item.find('a'))) return dirty_link def get_links(dirty_list,start,end): # ""    URL- links=[] for row in dirty_list: if row!='None': i_beg=row.find(start) i_end=row.rfind(end) if i_beg!=-1 &amp; i_end!=-1: links.append(row[i_beg:i_end]) return links # ,    ,      num=int(input('    : ')) #URL  .      ,    =) url ='https://www.mariinsky.ru/ru/playbill/playbill/?year=2019&amp;month='+str(num) #    top_name='container content gr_top' class_name='t_button' start='tickets' end='/"&gt;' #  text=get_text(url) dirty_link=get_items(text,top_name,class_name) #   URL-,     links=get_links(dirty_link,start,end)</span></span></code> </pre> <br>  Setelah mempelajari struktur halaman dengan pembelian tiket, selain ambang harga, saya memutuskan untuk memberikan kesempatan kepada pengguna untuk juga memilih: <br><br><ul><li>  jenis pertunjukan (1-opera, 2-balet, 3-konser, 4-kuliah) </li><li>  venue (panggung 1-tua, panggung 2-baru, aula 3-konser, aula 4-kamar) </li></ul><br>  Informasi dimasukkan melalui konsol dalam format numerik, beberapa angka dapat dipilih.  Variabilitas seperti itu ditentukan oleh perbedaan harga opera dan balet (opera lebih murah) dan keinginan untuk melihat daftar mereka secara terpisah. <br>  Hasilnya adalah <b>4 pertanyaan dan 4 filter data</b> - bulan, ambang harga, jenis, lokasi. <br><br>  Selanjutnya, kita pergi melalui semua tautan yang diterima.  Kami membuat get_text dan mencari harga yang lebih murah, dan juga mengeluarkan informasi terkait.  Karena Anda harus melihat ke setiap URL dan mengonversinya menjadi teks, runtime program tidak instan.  Akan menyenangkan untuk mengoptimalkan, tetapi saya tidak memikirkan caranya. <br>  Saya tidak akan mengutip kode itu sendiri, itu akan agak lama, tetapi semuanya benar di sana secara memadai dan “secara intuitif” dengan Beautiful Soup 4. <br>  Jika harga kurang dari yang dinyatakan oleh pengguna dan jenis tempat sesuai dengan set, maka pesan tentang kinerja ditampilkan di konsol.  Ada opsi lain untuk menyimpan semua ini dalam .xls, tetapi tidak berakar.  Lebih nyaman untuk melihat di konsol dan langsung mengikuti tautan daripada menusuk ke dalam file. <br><img src="https://habrastorage.org/getpro/habr/post_images/f61/dd4/a76/f61dd4a7602bc435bfe445d32aa35c51.jpg" alt="gambar"><br><br>  Sekitar 150 baris kode keluar.  Dalam versi ini, dengan fungsi minimum yang dijelaskan, skrip lebih hidup daripada semua yang hidup dan berjalan secara teratur dengan jangka waktu beberapa hari.  Semua modifikasi lain tidak selesai (penusuk telah mati) dan karena itu tidak aktif, atau tidak ada fungsi yang lebih menguntungkan. <br><br><h3>  3. Perpanjangan fungsi </h3><br>  Pada tahap kedua, saya memutuskan untuk melacak perubahan harga, menyimpan tautan ke pertunjukan yang menarik di file terpisah (lebih tepatnya, URL untuk mereka).  Pertama-tama, ini relevan untuk balet - mereka sangat jarang sangat murah dan tidak akan masuk dalam masalah anggaran umum.  Tetapi dari 5 ribu menjadi 2x penurunannya signifikan, terutama jika kinerjanya dengan pemain bintang, dan saya ingin melacaknya. <br>  Untuk melakukan ini, pertama-tama Anda harus menambahkan URL untuk pelacakan, dan kemudian secara berkala "kocok" dan bandingkan harga baru dengan yang lama. <br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">add_new_URL</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(user_id,perf_url)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#user_id ,        - WAITING_FILE = "waiting_list.csv" with open(WAITING_FILE, "a", newline="") as file: curent_url='https://'+perf_url text=get_text(curent_url) #      - , ,,   minP, name,date,typ,place=find_lowest(text) user = [str(user_id), perf_url,str(m)] writer = csv.writer(file) writer.writerow(user) def update_prices(): #        print(' ') WAITING_FILE = "waiting_list.csv" with open(WAITING_FILE, "r", newline="") as file: reader = csv.reader(file) gen=[] for row in reader: gen.append(list(row)) L=len(gen) lowest={} with open(WAITING_FILE, "w", newline="") as fl: writer = csv.writer(fl) for i in range(L): lowest[gen[i][1]]=gen[i][2] #   URL  for k in lowest.keys(): text=get_text('https://'+k) minP, name,date,typ,place=find_lowest(text) if minP==0: #     ,      "" minP=100000 if int(minP)&lt;int(lowest[k]): #   ,    lowest[k]=minP for i in range(L): if gen[i][1]==k: #  -  URL   gen[i][2]=str(minP) print('   '+k+'    '+str(minP)) writer.writerows(gen) add_new_URL('12345','tickets.mariinsky.ru/ru/performance/ZVRGZnRNbmd3VERsNU1R/') update_prices()</span></span></code> </pre> <br>  Pembaruan harga diluncurkan pada awal skrip utama, tidak dilakukan secara terpisah.  Mungkin tidak seanggun yang kita inginkan, tapi itu menyelesaikan masalahnya.  Jadi fungsi tambahan kedua adalah memantau penurunan harga untuk kinerja yang menarik. <br><br>  Kemudian bot Telegram lahir, tidak begitu mudah, cepat, ceria, tetapi masih terlahir.  Agar tidak menyatukan semuanya, cerita tentang dia (serta tentang ide-ide yang belum direalisasi dan upaya untuk melakukan ini dengan situs web Teater Bolshoi) akan berada di bagian kedua artikel. <br><br>  <b>HASIL:</b> ide itu berhasil, pengguna puas.  Butuh beberapa akhir pekan untuk mengetahui cara berinteraksi dengan halaman html.  Untungnya, Python adalah bahasa yang hampir semuanya dan modul yang siap pakai membantu menggerakkan kuku tanpa memikirkan fisika palu. <br><br>  Saya berharap case ini akan bermanfaat bagi Habrachians dan, mungkin, itu akan bekerja seperti Pendel ajaib untuk akhirnya membuat Wishlist yang duduk di kepalaku untuk waktu yang lama. <br><br>  <b>UPD:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Melanjutkan Kisah - Bagian 2</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id444460/">https://habr.com/ru/post/id444460/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id444442/index.html">Jetson Nano: Nvidia Machine Learning Single Board</a></li>
<li><a href="../id444444/index.html">Kegagalan terbaik dari konferensi kami (Joker, JPoint, DotNext, Mobius, TechTrain dan sebagainya)</a></li>
<li><a href="../id444446/index.html">Membuat aplikasi web modern dari awal</a></li>
<li><a href="../id444448/index.html">Mirai Clone Menambahkan Lusinan Eksploitasi Baru untuk Perangkat IoT Perusahaan Bertarget</a></li>
<li><a href="../id444456/index.html">Atari 65XE - Keyboard USB</a></li>
<li><a href="../id444462/index.html">Menguji Samsung Galaxy S10 - Kapan smartphone akan menyusul kamera?</a></li>
<li><a href="../id444464/index.html">Cara lain untuk menembak kaki Anda menggunakan std :: thread</a></li>
<li><a href="../id444466/index.html">Maaf, semua basis data Anda dimiliki oleh Google. Google Presentation di Game Development Conference 2019, Stadia Project</a></li>
<li><a href="../id444468/index.html">Nvidia Neural Network Mengubah Sketsa Sederhana Menjadi Lanskap Indah</a></li>
<li><a href="../id444470/index.html">20 kebiasaan untuk menjaga kebersihan: cara menggunakan teknologi, tetapi jangan biarkan mereka mengambil waktu dan perhatian mereka</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
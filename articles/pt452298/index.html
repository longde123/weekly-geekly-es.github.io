<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëäüèø üëêüèº ü§≤ Otimiza√ß√£o da coleta de lixo em um servi√ßo .NET altamente carregado üè∫ ü¶é ü§Ω</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todos os dias, dezenas de milhares de funcion√°rios de milhares de organiza√ß√µes em todo o mundo trabalham na Pyrus. Consideramos a capacidade de respos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Otimiza√ß√£o da coleta de lixo em um servi√ßo .NET altamente carregado</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452298/">  Todos os dias, dezenas de milhares de funcion√°rios de milhares de organiza√ß√µes em todo o mundo trabalham na Pyrus.  Consideramos a capacidade de resposta do servi√ßo (a velocidade de processamento de solicita√ß√µes) uma importante vantagem competitiva, pois afeta diretamente a experi√™ncia do usu√°rio.  A principal m√©trica para n√≥s √© a "porcentagem de consultas lentas".  Estudando seu comportamento, notamos que, a cada minuto, nos servidores de aplicativos, ocorrem pausas de cerca de 1000 ms.  Nesses intervalos, o servidor n√£o responde e surge uma fila de v√°rias dezenas de solicita√ß√µes.  A busca pelas causas e a elimina√ß√£o de gargalos causados ‚Äã‚Äãpela coleta de lixo no aplicativo ser√£o discutidas neste artigo. <br><br><img src="https://habrastorage.org/webt/fu/1s/j9/fu1sj9ixpj4nc633ikhwblbhlfs.jpeg"><br><a name="habracut"></a><br>  Linguagens de programa√ß√£o modernas podem ser divididas em dois grupos.  Em linguagens como C / C ++ ou Rust, o gerenciamento manual de mem√≥ria √© usado, para que os programadores passem mais tempo escrevendo c√≥digo, gerenciando a vida √∫til dos objetos e depois depurando.  Ao mesmo tempo, os bugs devido ao uso inadequado da mem√≥ria s√£o alguns dos mais dif√≠ceis de depurar, portanto, o desenvolvimento mais moderno √© realizado em linguagens com gerenciamento autom√°tico de mem√≥ria.  Isso inclui, por exemplo, Java, C #, Python, Ruby, Go, PHP, JavaScript etc.  Os programadores economizam tempo de desenvolvimento, mas voc√™ precisa pagar um tempo de execu√ß√£o extra que o programa gasta regularmente na coleta de lixo - liberando mem√≥ria ocupada por objetos para os quais n√£o h√° links restantes no programa.  Em pequenos programas, esse tempo √© insignificante, mas √† medida que o n√∫mero de objetos aumenta e a intensidade de sua cria√ß√£o, a coleta de lixo come√ßa a dar uma contribui√ß√£o not√°vel para o tempo total de execu√ß√£o do programa. <br><br>  Os servidores da Web Pyrus s√£o executados na plataforma .NET, que usa o gerenciamento autom√°tico de mem√≥ria.  A maioria das coletas de lixo √© 'para o mundo', ou seja,  no momento do trabalho, eles param todos os threads do aplicativo.  Assemblies sem bloqueio (em segundo plano) tamb√©m interrompem todos os threads, mas por um per√≠odo muito curto.  Durante o bloqueio do encadeamento, o servidor n√£o processa solicita√ß√µes, as solicita√ß√µes existentes congelam, novas s√£o adicionadas √† fila.  Como resultado, as solicita√ß√µes que foram processadas no momento da coleta de lixo s√£o diretamente mais lentas e as solicita√ß√µes s√£o processadas mais lentamente imediatamente ap√≥s a coleta de lixo ser conclu√≠da devido √†s filas acumuladas.  Isso piora a m√©trica "porcentagem de consultas lentas". <br><br>  Armado com o livro recentemente publicado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Konrad Kokosa: Pro .NET Memory Management</a> (sobre como trouxemos sua primeira c√≥pia para a R√∫ssia em 2 dias, voc√™ pode escrever uma postagem separada), totalmente dedicado ao t√≥pico de gerenciamento de mem√≥ria no .NET, come√ßamos a estudar o problema. <br><br><h2>  Medi√ß√£o </h2><br>  Para criar um perfil do servidor da Web Pyrus, usamos o utilit√°rio PerfView ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/Microsoft/perfview</a> ), aprimorado para criar perfis de aplicativos .NET.  O utilit√°rio √© baseado no mecanismo ETW (Event Tracing for Windows) e tem um impacto m√≠nimo no desempenho do aplicativo com perfil, o que permite que ele seja usado em um servidor de combate.  Al√©m disso, o impacto no desempenho depende de que tipos de eventos e de quais informa√ß√µes coletamos.  N√£o coletamos nada - o aplicativo funciona normalmente.  Al√©m disso, o PerfView n√£o requer recompila√ß√£o ou reinicializa√ß√£o do aplicativo. <br><br>  Execute o rastreamento PerfView com o par√¢metro / GCCollectOnly (tempo de rastreamento 1,5 horas).  Nesse modo, ele coleta apenas eventos de coleta de lixo e tem um impacto m√≠nimo no desempenho.  Vejamos o relat√≥rio de rastreamento Memory Group / GCStats e nele um resumo dos eventos do coletor de lixo: <br><br><img src="https://habrastorage.org/webt/v4/ia/cd/v4iacdyso10-0toycwyijfm0zbm.png"><br><br>  Aqui vemos v√°rios indicadores interessantes ao mesmo tempo: <br><ul><li>  O tempo m√©dio de pausa na constru√ß√£o na 2¬™ gera√ß√£o √© de 700 milissegundos e a pausa m√°xima √© de cerca de um segundo.  Esta figura mostra a hora em que todos os threads no aplicativo .NET param, em particular, essa pausa ser√° adicionada a todas as solicita√ß√µes processadas. <br></li><li>  O n√∫mero de montagens da 2¬™ gera√ß√£o √© compar√°vel √† 1¬™ gera√ß√£o e √© um pouco menor que o n√∫mero de montagens da 0¬™ gera√ß√£o. <br></li><li>  A coluna Induzido lista 53 montagens na 2¬™ gera√ß√£o.  Montagem induzida √© o resultado de uma chamada expl√≠cita para GC.Collect ().  Em nosso c√≥digo, n√£o encontramos uma √∫nica chamada para esse m√©todo, o que significa que algumas das bibliotecas usadas por nosso aplicativo s√£o as culpadas. <br></li></ul><br>  Vamos explicar a observa√ß√£o sobre o n√∫mero de coletas de lixo.  A id√©ia de dividir objetos pela vida √∫til √© baseada na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hip√≥tese geracional</a> : uma parte significativa dos objetos criados morre rapidamente e a maior parte do resto dura muito tempo (em outras palavras, poucos objetos com vida √∫til "m√©dia").  √â nesse modo que o coletor de lixo .NET √© aprisionado e, nesse modo, os assemblies de segunda gera√ß√£o devem ser muito menores que a gera√ß√£o 0.  Ou seja, para a opera√ß√£o ideal do coletor de lixo, devemos adaptar o trabalho de nossa aplica√ß√£o √† hip√≥tese geracional.  Vamos formular a regra da seguinte maneira: os objetos devem morrer rapidamente, sem sobreviver √† gera√ß√£o mais velha, ou viver para ela e viver l√° para sempre.  Esta regra tamb√©m se aplica a outras plataformas que usam gerenciamento autom√°tico de mem√≥ria com separa√ß√£o de gera√ß√µes, como Java. <br><br>  Os dados que nos interessam podem ser extra√≠dos de outra tabela no relat√≥rio GCStats: <br><br><img src="https://habrastorage.org/webt/m5/7y/je/m57yjedgbkwfpbiwmjkvnbhgl4o.png"><br><br>  Aqui est√£o alguns casos em que um aplicativo tenta criar um objeto grande (nos objetos do .NET Framework&gt; 85.000 bytes de tamanho s√£o criados no LOH - Large Object Heap) e precisa aguardar a conclus√£o do assembly de 2¬™ gera√ß√£o, que ocorre paralelamente em segundo plano.  Essas pausas do alocador n√£o s√£o t√£o cr√≠ticas quanto as pausas do coletor de lixo, pois afetam apenas um encadeamento.  Antes disso, usamos a vers√£o do .NET Framework 4.6.1 e, na vers√£o 4.7.1, a Microsoft finalizou o coletor de lixo, agora permite alocar mem√≥ria no Large Object Heap durante a compila√ß√£o em segundo plano da segunda gera√ß√£o: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://docs.microsoft.com / ru-ru / dotnet / framework / whats-new / # common-language-runtime-clr</a> <br>  Portanto, atualizamos para a vers√£o mais recente 4.7.2 naquele momento. <br><br><h2>  Constru√ß√µes de 2¬™ Gera√ß√£o </h2><br>  Por que temos tantas constru√ß√µes da gera√ß√£o mais antiga?  A primeira suposi√ß√£o √© que temos um vazamento de mem√≥ria.  Para testar esta hip√≥tese, vamos dar uma olhada no tamanho da segunda gera√ß√£o (configuramos o monitoramento dos contadores de desempenho correspondentes no Zabbix).  A partir dos gr√°ficos do tamanho da 2¬™ gera√ß√£o para 2 servidores Pyrus, pode-se ver que o tamanho aumenta primeiro (principalmente devido ao preenchimento de caches), mas depois se estabiliza (grandes falhas no gr√°fico - rein√≠cio regular do servi√ßo da web para atualizar a vers√£o): <br><br><img src="https://habrastorage.org/webt/gg/lc/ce/gglcce4tssnhzgcjfhesec9rcja.png"><br><br>  Isso significa que n√£o h√° vazamentos de mem√≥ria percept√≠veis, ou seja, um grande n√∫mero de assemblies de segunda gera√ß√£o ocorre por outro motivo.  A pr√≥xima hip√≥tese √© que h√° muito tr√°fego de mem√≥ria, ou seja, muitos objetos caem na 2¬™ gera√ß√£o e muitos objetos morrem l√°.  O PerfView possui um modo / GCOnly para encontrar esses objetos.  Nos relat√≥rios de rastreio, vamos prestar aten√ß√£o √†s 'Pilhas de mortes por objetos da gera√ß√£o 2 (amostragem grossa)', que cont√™m uma sele√ß√£o de objetos que morrem na 2¬™ gera√ß√£o, juntamente com pilhas de chamadas dos locais onde esses objetos foram criados.  Aqui vemos os seguintes resultados: <br><br><img src="https://habrastorage.org/webt/h7/r2/d0/h7r2d0htyxsnaqrr_ekn_ybilti.png"><br><br>  Ap√≥s abrir a linha, no interior vemos uma pilha de chamadas desses lugares no c√≥digo que criam objetos que vivem at√© a 2¬™ gera√ß√£o.  Entre eles est√£o: <br><ul><li>  System.Byte [] Se voc√™ olhar para dentro, veremos que mais da metade s√£o buffers para serializa√ß√£o no JSON: <br></li></ul><br><img src="https://habrastorage.org/webt/la/up/6v/laup6v0mho5e1tbwjfkfmsgdhog.png"><br><br><ul><li>  Slot [System.Int32] [] (isso faz parte da implementa√ß√£o do HashSet), System.Int32 [] etc.  Este √© o nosso c√≥digo que calcula caches de clientes - os diret√≥rios, formul√°rios, listas, amigos etc. que este usu√°rio v√™ e que s√£o armazenados em cache em seu navegador ou aplicativo m√≥vel: <br></li></ul><br><img src="https://habrastorage.org/webt/dx/et/jy/dxetjyvj2ande72qrod6leza6i8.png"><br><br><img src="https://habrastorage.org/webt/v6/k6/r-/v6k6r-wq0qeof0edb6h5jvct-he.png"><br><br>  Curiosamente, os buffers para JSON e para calcular caches de clientes s√£o todos objetos tempor√°rios que vivem na mesma solicita√ß√£o.  Por que eles vivem de acordo com a 2¬™ gera√ß√£o?  Observe que todos esses objetos s√£o matrizes de tamanho bastante grande.  E em um tamanho&gt; 85000 bytes, a mem√≥ria para eles √© alocada no Large Object Heap, que √© coletado apenas em conjunto com a 2¬™ gera√ß√£o. <br><br>  Para verificar, abra a se√ß√£o 'Aloca√ß√£o de heap de GC ignora pilhas gratuitas (amostragem grossa)' nos resultados do perfview / GCOnly.  L√° vemos a linha LargeObject, na qual o PerfView agrupa a cria√ß√£o de objetos grandes, e dentro vemos as mesmas matrizes que vimos na an√°lise anterior.  Reconhecemos a causa raiz dos problemas com o coletor de lixo: criamos muitos objetos grandes tempor√°rios. <br><br><img src="https://habrastorage.org/webt/sy/kr/lk/sykrlkgbmvl9jyny5hl1_ftg4ee.png"><br><br><img src="https://habrastorage.org/webt/f9/6q/mp/f96qmplnj4devma1buedg6fpo8q.png"><br><br><h2>  Altera√ß√µes no sistema Pyrus </h2><br>  Com base nos resultados da medi√ß√£o, identificamos as principais √°reas de trabalho adicional: a luta contra objetos grandes ao calcular caches de clientes e serializa√ß√£o em JSON.  Existem v√°rias solu√ß√µes para esse problema: <br><ul><li>  A coisa mais simples √© n√£o criar objetos grandes.  Por exemplo, se o buffer grande B for usado nas transforma√ß√µes sequenciais de dados A-&gt; B-&gt; C, algumas vezes essas transforma√ß√µes poder√£o ser combinadas, transformando-as em A-&gt; C e eliminando a cria√ß√£o do objeto B. Essa op√ß√£o nem sempre √© aplic√°vel, mas o mais simples e mais eficaz. <br></li><li>  Pool de objetos.  Em vez de criar constantemente novos objetos e jog√°-los fora, carregando o coletor de lixo, podemos armazenar uma cole√ß√£o de objetos gratuitos.  No caso mais simples, quando precisamos de um novo objeto, o retiramos do pool ou criamos um novo se o pool estiver vazio.  Quando n√£o precisamos mais do objeto, devolvemo-lo √† piscina.  Um bom exemplo √© o ArrayPool no .NET Core, que tamb√©m est√° dispon√≠vel no .NET Framework como parte do pacote System.Buffers Nuget. <br></li><li>  Use objetos pequenos em vez de objetos grandes. <br></li></ul><br>  Vamos considerar separadamente os dois casos de objetos grandes - computando caches de clientes e serializando em JSON. <br><br><h2>  C√°lculo do cache do cliente </h2><br>  O cliente da Web Pyrus e os aplicativos m√≥veis armazenam em cache os dados dispon√≠veis para o usu√°rio (projetos, formul√°rios, usu√°rios, etc.) O cache √© usado para acelerar o trabalho, tamb√©m √© necess√°rio para trabalhar no modo offline.  Os caches s√£o calculados no servidor e transferidos para o cliente.  Eles s√£o individuais para cada usu√°rio, pois dependem de seus direitos de acesso e geralmente s√£o atualizados, por exemplo, ao alterar diret√≥rios aos quais ele tem acesso. <br><br>  Portanto, muitos c√°lculos de cache do cliente s√£o realizados regularmente no servidor e muitos objetos tempor√°rios de vida curta s√£o criados.  Se o usu√°rio for uma organiza√ß√£o grande, ele poder√° acessar muitos objetos, respectivamente, os caches do cliente para ele ser√£o grandes.  Por isso, vimos a aloca√ß√£o de mem√≥ria para grandes matrizes tempor√°rias no Large Object Heap. <br><br>  Vamos analisar as op√ß√µes propostas para se livrar da cria√ß√£o de objetos grandes: <br><ul><li>  Descarte completo de objetos grandes.  Essa abordagem n√£o √© aplic√°vel, pois os algoritmos de prepara√ß√£o de dados usam, entre outras coisas, classifica√ß√£o e uni√£o de conjuntos e requerem buffers tempor√°rios. <br></li><li>  Usando um pool de objetos.  Essa abordagem tem dificuldades: <br><ul><li>  A variedade de cole√ß√µes usadas e os tipos de elementos nelas: HashSet, List e Array s√£o usados ‚Äã‚Äã(os dois √∫ltimos podem ser combinados).  Int32, Int64, bem como todos os tipos de classes de dados s√£o armazenados em cole√ß√µes.  Para cada tipo usado, voc√™ precisar√° de seu pr√≥prio pool, que tamb√©m armazenar√° cole√ß√µes de tamanhos diferentes. <br></li><li>  Tempo de vida dif√≠cil das cole√ß√µes.  Para obter benef√≠cios do pool, os objetos nele dever√£o ser devolvidos ap√≥s o uso.  Isso pode ser feito se o objeto for usado em um m√©todo.  Mas, no nosso caso, a situa√ß√£o √© mais complicada, pois muitos objetos grandes viajam entre m√©todos, s√£o colocados em estruturas de dados, transferidos para outras estruturas etc. <br></li><li>  Implementa√ß√£o.  Existe o ArrayPool da Microsoft, mas ainda precisamos de List e HashSet.  Como n√£o encontramos nenhuma biblioteca adequada, ter√≠amos que implementar as classes por conta pr√≥pria. </li></ul></li><li>  Uso de objetos pequenos.  Uma matriz grande pode ser dividida em v√°rias partes pequenas, que n√£o ser√£o carregadas no Large Object Heap, mas ser√£o criadas na 0¬™ gera√ß√£o e depois seguir√£o o caminho padr√£o na 1¬™ e 2¬™.  Esperamos que eles n√£o atendam √† 2¬™, mas sejam coletados pelo coletor de lixo na 0¬™ ou, em casos extremos, na 1¬™ gera√ß√£o.  A vantagem dessa abordagem √© que as altera√ß√µes no c√≥digo existente s√£o m√≠nimas.  Dificuldades: <br><ul><li>  Implementa√ß√£o.  Como n√£o encontramos bibliotecas adequadas, ter√≠amos que escrever as classes.  A falta de bibliotecas √© compreens√≠vel, pois o cen√°rio ‚Äúcole√ß√µes que n√£o carregam o heap de objetos grandes‚Äù √© um escopo muito restrito. </li></ul></li></ul><br>  Decidimos seguir no terceiro caminho e <strike>inventar nossa bicicleta</strike> para escrever List e HashSet, sem carregar o Large Object Heap. <br><br><h2>  Lista de pe√ßas </h2><br>  Nosso ChunkedList &lt;T&gt; implementa interfaces padr√£o, incluindo IList &lt;T&gt;, que requer altera√ß√µes m√≠nimas no c√≥digo existente.  Sim, e a biblioteca Newtonsoft.Json que usamos √© automaticamente capaz de serializ√°-la, uma vez que implementa IEnumerable &lt;T&gt;: <br><br><pre><code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">sealed</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">ChunkedList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt; : <span class="hljs-title"><span class="hljs-title">IList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">ICollection</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IEnumerable</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IEnumerable</span></span>, <span class="hljs-title"><span class="hljs-title">IList</span></span>, <span class="hljs-title"><span class="hljs-title">ICollection</span></span>, <span class="hljs-title"><span class="hljs-title">IReadOnlyList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IReadOnlyCollection</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt; {</code> </pre> <br>  A lista padr√£o &lt;T&gt; possui os seguintes campos: matriz para elementos e o n√∫mero de elementos preenchidos.  No ChunkedList &lt;T&gt;, h√° uma matriz de matrizes de elementos, o n√∫mero de matrizes completamente preenchidas, o n√∫mero de elementos na √∫ltima matriz.  Cada uma das matrizes de elementos com menos de 85.000 bytes: <br><br><img src="https://habrastorage.org/webt/72/zj/js/72zjjs9q6lcfud-l7nq8cy5prdi.png"><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> T[][] chunks; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> currentChunk; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> currentChunkSize;</code> </pre> <br>  Como o ChunkedList &lt;T&gt; √© bastante complicado, escrevemos testes detalhados sobre ele.  Qualquer opera√ß√£o deve ser testada em pelo menos 2 modos: em "pequena" quando a lista inteira se encaixa em uma pe√ßa de at√© 85.000 bytes de tamanho e "grande" quando consiste em mais de uma pe√ßa.  Al√©m disso, para m√©todos que alteram o tamanho (por exemplo, Adicionar), os cen√°rios s√£o ainda maiores: "pequeno" -&gt; "pequeno", "pequeno" -&gt; "grande", "grande" -&gt; "grande", "grande" -&gt; " pequeno. "  Aqui existem alguns casos de fronteira confusos que os testes de unidade fazem bem. <br><br>  A situa√ß√£o √© simplificada pelo fato de que alguns dos m√©todos da interface IList n√£o s√£o usados ‚Äã‚Äãe podem ser omitidos (como Inserir, Remover).  Sua implementa√ß√£o e teste seriam bastante gerais.  Al√©m disso, a escrita de testes de unidade √© simplificada pelo fato de n√£o precisarmos apresentar novas funcionalidades. O ChunkedList &lt;T&gt; deve se comportar da mesma forma que a Lista &lt;T&gt;.  Ou seja, todos os testes est√£o organizados da seguinte maneira: crie uma Lista &lt;T&gt; e ChunkedList &lt;T&gt;, execute as mesmas opera√ß√µes nelas e compare os resultados. <br><br>  Medimos o desempenho usando a biblioteca BenchmarkDotNet para garantir que n√£o reduzimos muito o nosso c√≥digo ao mudar de Lista &lt;T&gt; para ChunkedList &lt;T&gt;.  Vamos testar, por exemplo, adicionando itens √† lista: <br><br><pre> <code class="cs hljs">[<span class="hljs-meta"><span class="hljs-meta">Benchmark</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ChunkedList&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ChunkedList</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> list = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ChunkedList&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; N; i++) list.Add(i); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> list; }</code> </pre> <br>  E o mesmo teste usando a Lista &lt;T&gt; para compara√ß√£o.  Resultados ao adicionar 500 elementos (tudo se encaixa em uma matriz): <br><div class="scrollable-table"><table><tbody><tr><td>  M√©todo </td><td>  Mean </td><td>  Erro </td><td>  Stddev </td><td>  Gera√ß√£o 0 / 1k Op </td><td>  Gera√ß√£o 1 / 1k Op </td><td>  Gera√ß√£o 2 / 1k Op </td><td>  Mem√≥ria Alocada / Op </td></tr><tr><td>  Lista padr√£o </td><td>  1.415 us </td><td>  0.0149 us </td><td>  0.0140 us </td><td>  0,6847 </td><td>  0,0095 </td><td>  - </td><td>  4.21 KB </td></tr><tr><td>  Chunkedlist </td><td>  3.728 n√≥s </td><td>  0.0238 us </td><td>  0.0222 us </td><td>  0,6943 </td><td>  0,0076 </td><td>  - </td><td>  4.28 KB </td></tr></tbody></table></div><br>  Resultados ao adicionar 50.000 elementos (divididos em v√°rias matrizes): <br><div class="scrollable-table"><table><tbody><tr><td>  M√©todo </td><td>  Mean </td><td>  Erro </td><td>  Stddev </td><td>  Gera√ß√£o 0 / 1k Op </td><td>  Gera√ß√£o 1 / 1k Op </td><td>  Gera√ß√£o 2 / 1k Op </td><td>  Mem√≥ria Alocada / Op </td></tr><tr><td>  Lista padr√£o </td><td>  146.273 n√≥s </td><td>  3.1466 us </td><td>  4.8053 n√≥s </td><td>  124.7559 </td><td>  124.7559 </td><td>  124.7559 </td><td>  513,23 KB </td></tr><tr><td>  Chunkedlist </td><td>  287.687 n√≥s </td><td>  1.4630 n√≥s </td><td>  1.2969 us </td><td>  41.5039 </td><td>  20.5078 </td><td>  - </td><td>  256,75 KB </td></tr></tbody></table></div><br><div class="spoiler">  <b class="spoiler_title">Descri√ß√£o detalhada das colunas nos resultados</b> <div class="spoiler_text"><pre> <code class="cs hljs">BenchmarkDotNet=v0<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">.4</span></span>, OS=Windows <span class="hljs-number"><span class="hljs-number">10.0</span></span><span class="hljs-number"><span class="hljs-number">.17763</span></span><span class="hljs-number"><span class="hljs-number">.379</span></span> (<span class="hljs-number"><span class="hljs-number">1809</span></span>/October2018Update/Redstone5) Intel Core i7<span class="hljs-number"><span class="hljs-number">-8700</span></span>K CPU <span class="hljs-number"><span class="hljs-number">3.70</span></span>GHz (Coffee Lake), <span class="hljs-number"><span class="hljs-number">1</span></span> CPU, <span class="hljs-number"><span class="hljs-number">12</span></span> logical and <span class="hljs-number"><span class="hljs-number">6</span></span> physical cores [Host] : .NET Framework <span class="hljs-number"><span class="hljs-number">4.7</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> (CLR <span class="hljs-number"><span class="hljs-number">4.0</span></span><span class="hljs-number"><span class="hljs-number">.30319</span></span><span class="hljs-number"><span class="hljs-number">.42000</span></span>), <span class="hljs-number"><span class="hljs-number">64b</span></span>it RyuJIT-v4<span class="hljs-number"><span class="hljs-number">.7</span></span><span class="hljs-number"><span class="hljs-number">.3324</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> DefaultJob : .NET Framework <span class="hljs-number"><span class="hljs-number">4.7</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> (CLR <span class="hljs-number"><span class="hljs-number">4.0</span></span><span class="hljs-number"><span class="hljs-number">.30319</span></span><span class="hljs-number"><span class="hljs-number">.42000</span></span>), <span class="hljs-number"><span class="hljs-number">64b</span></span>it RyuJIT-v4<span class="hljs-number"><span class="hljs-number">.7</span></span><span class="hljs-number"><span class="hljs-number">.3324</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> <span class="hljs-comment"><span class="hljs-comment">// * Hints * Outliers ListAdd.StandardList: Default -&gt; 2 outliers were removed ListAdd.ChunkedList: Default -&gt; 1 outlier was removed // * Legends * Mean : Arithmetic mean of all measurements Error : Half of 99.9% confidence interval StdDev : Standard deviation of all measurements Gen 0/1k Op : GC Generation 0 collects per 1k Operations Gen 1/1k Op : GC Generation 1 collects per 1k Operations Gen 2/1k Op : GC Generation 2 collects per 1k Operations Allocated Memory/Op : Allocated memory per single operation (managed only, inclusive, 1KB = 1024B) 1 us : 1 Microsecond (0.000001 sec)</span></span></code> </pre> <br></div></div><br>  Se voc√™ olhar a coluna 'M√©dia', que exibe o tempo m√©dio de execu√ß√£o do teste, poder√° ver que nossa implementa√ß√£o √© apenas 2-2,5 vezes mais lenta que o padr√£o.  Considerando que no c√≥digo real, as opera√ß√µes com listas s√£o apenas uma pequena parte de todas as a√ß√µes executadas, essa diferen√ßa se torna insignificante.  Mas a coluna 'Gen 2 / 1k op' (o n√∫mero de montagens da 2¬™ gera√ß√£o para 1000 execu√ß√µes de teste) mostra que atingimos o objetivo: com um grande n√∫mero de elementos, o ChunkedList n√£o cria lixo na segunda gera√ß√£o, que era nossa tarefa. <br><br><h2>  Conjunto de pe√ßas </h2><br>  Da mesma forma, ChunkedHashSet &lt;T&gt; implementa a interface ISet &lt;T&gt;.  Ao escrever o ChunkedHashSet &lt;T&gt;, reutilizamos a l√≥gica de pequeno peda√ßo j√° implementada no ChunkedList.  Para fazer isso, adotamos uma implementa√ß√£o pronta do HashSet &lt;T&gt; da .NET Reference Source, dispon√≠vel sob a licen√ßa MIT, e substitu√≠mos as matrizes por ChunkedLists. <br><br>  Nos testes de unidade, tamb√©m usamos o mesmo truque das listas: compararemos o comportamento de ChunkedHashSet &lt;T&gt; com a refer√™ncia HashSet &lt;T&gt;. <br><br>  Finalmente, testes de desempenho.  A principal opera√ß√£o que usamos √© a uni√£o de conjuntos, e √© por isso que estamos testando: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ChunkedHashSet&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ChunkedHashSet</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params">[][] source</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ChunkedHashSet&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> arr <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> source) <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>.UnionWith(arr); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; }</code> </pre> <br>  E exatamente o mesmo teste para o HashSet padr√£o.  Primeiro teste para pequenos conjuntos: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> source = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][] { Enumerable.Range(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">600</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>).ToArray(), }</code> </pre> <br><div class="scrollable-table"><table><tbody><tr><td>  M√©todo </td><td>  Mean </td><td>  Erro </td><td>  Stddev </td><td>  Gera√ß√£o 0 / 1k Op </td><td>  Gera√ß√£o 1 / 1k Op </td><td>  Gera√ß√£o 2 / 1k Op </td><td>  Mem√≥ria Alocada / Op </td></tr><tr><td>  StandardHashSet </td><td>  30.16 nos </td><td>  0.1046 us </td><td>  0.0979 us </td><td>  9,3079 </td><td>  1.6785 </td><td>  - </td><td>  57,41 KB </td></tr><tr><td>  ChunkedHashSet </td><td>  73.54 nos </td><td>  0.5919 us </td><td>  0.5247 nos </td><td>  9,5215 </td><td>  1,5869 </td><td>  - </td><td>  58,84 KB </td></tr></tbody></table></div><br>  O segundo teste para conjuntos grandes que causaram um problema com v√°rios objetos grandes: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> source = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][] { Enumerable.Range(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">30000</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">60000</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">30000</span></span>, <span class="hljs-number"><span class="hljs-number">100000</span></span>).ToArray(), }</code> </pre> <br><div class="scrollable-table"><table><tbody><tr><td>  M√©todo </td><td>  Mean </td><td>  Erro </td><td>  Stddev </td><td>  Gera√ß√£o 0 / 1k Op </td><td>  Gera√ß√£o 1 / 1k Op </td><td>  Gera√ß√£o 2 / 1k Op </td><td>  Mem√≥ria Alocada / Op </td></tr><tr><td>  StandardHashSet </td><td>  3.031,30 n√≥s </td><td>  32.0797 us </td><td>  28.4378 nos </td><td>  699.2188 </td><td>  667.9688 </td><td>  664.0625 </td><td>  4718.23 KB </td></tr><tr><td>  ChunkedHashSet </td><td>  7.189,66 us </td><td>  25.6319 us </td><td>  23.9761 nos </td><td>  539.0625 </td><td>  265,6250 </td><td>  7.8125 </td><td>  3280.71 KB </td></tr></tbody></table></div><br>  Os resultados s√£o semelhantes √†s listagens.  O ChunkedHashSet √© mais lento em 2-2,5 vezes, mas, ao mesmo tempo, em conjuntos grandes, ele carrega menos a 2¬™ gera√ß√£o 2 ordens de magnitude. <br><br><h2>  Serializa√ß√£o em JSON </h2><br>  O servidor web Pyrus fornece v√°rias APIs que usam serializa√ß√£o diferente.  Descobrimos a cria√ß√£o de objetos grandes na API usada pelos bots e no utilit√°rio de sincroniza√ß√£o (a seguir denominada API p√∫blica).  Observe que basicamente a API usa sua pr√≥pria serializa√ß√£o, que n√£o √© afetada por esse problema.  Escrevemos sobre isso no artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://habr.com/en/post/227595/</a> , na se√ß√£o "2.  Voc√™ n√£o sabe onde est√° o gargalo do seu aplicativo. "  Ou seja, a API principal j√° est√° funcionando bem, e o problema apareceu na API p√∫blica √† medida que o n√∫mero de solicita√ß√µes e a quantidade de dados nas respostas aumentaram. <br><br>  Vamos otimizar a API p√∫blica.  Usando o exemplo da API principal, sabemos que voc√™ pode retornar uma resposta ao usu√°rio no modo de streaming.  Ou seja, voc√™ n√£o precisa criar buffers intermedi√°rios contendo a resposta inteira, mas grave a resposta imediatamente no fluxo. <br><br>  Ap√≥s uma inspe√ß√£o mais detalhada, descobrimos que, no processo de serializa√ß√£o da resposta, criamos um buffer tempor√°rio para o resultado intermedi√°rio ('content' √© uma matriz de bytes que cont√©m JSON na codifica√ß√£o UTF-8): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> serializer = Newtonsoft.Json.JsonSerializer.Create(...); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] content; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> sw = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamWriter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MemoryStream(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> UTF8Encoding(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> writer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Newtonsoft.Json.JsonTextWriter(sw)) { serializer.Serialize(writer, result); writer.Flush(); content = ms.ToArray(); }</code> </pre> <br>  Vamos ver onde o conte√∫do √© usado.  Por motivos hist√≥ricos, a API p√∫blica √© baseada no WCF, para o qual XML √© o formato padr√£o de solicita√ß√£o e resposta.  No nosso caso, a resposta XML possui um √∫nico elemento 'Bin√°rio', dentro do qual o JSON codificado em Base64 √© gravado: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">RawBodyWriter</span></span> : <span class="hljs-title"><span class="hljs-title">BodyWriter</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">readonly</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] _content; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">RawBodyWriter</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] content</span></span></span><span class="hljs-function">) : </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">base</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-literal"><span class="hljs-function"><span class="hljs-params"><span class="hljs-literal">true</span></span></span></span></span><span class="hljs-function">)</span></span> { _content = content; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWriteBodyContents</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlDictionaryWriter writer</span></span></span><span class="hljs-function">)</span></span> { writer.WriteStartElement(<span class="hljs-string"><span class="hljs-string">"Binary"</span></span>); writer.WriteBase64(_content, <span class="hljs-number"><span class="hljs-number">0</span></span>, _content.Length); writer.WriteEndElement(); } }</code> </pre> <br>  Observe que um buffer tempor√°rio n√£o √© necess√°rio aqui.  O JSON pode ser gravado imediatamente no buffer XmlWriter que o WCF nos fornece, codificando-o no Base64 em tempo real.  Assim, seguiremos o primeiro caminho, eliminando a aloca√ß√£o de mem√≥ria: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWriteBodyContents</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlDictionaryWriter writer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> serializer = Newtonsoft.Json.JsonSerializer.Create(...); writer.WriteStartElement(<span class="hljs-string"><span class="hljs-string">"Binary"</span></span>); Stream stream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Base64Writer(writer); Var sw = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamWriter(stream, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> UTF8Encoding(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> jsonWriter = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Newtonsoft.Json.JsonTextWriter(sw)) { serializer.Serialize(jsonWriter, _result); jsonWriter.Flush(); } writer.WriteEndElement(); }</code> </pre> <br>  Aqui, o Base64Writer √© um inv√≥lucro simples sobre o XmlWriter que implementa a interface Stream, que grava no XmlWriter como Base64.  Ao mesmo tempo, a partir de toda a interface, basta implementar apenas um m√©todo Write, chamado no StreamWriter: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">Base64Writer</span></span> : <span class="hljs-title"><span class="hljs-title">Stream</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">readonly</span></span> XmlWriter _writer; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Base64Writer</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlWriter writer</span></span></span><span class="hljs-function">)</span></span> { _writer = writer; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Write</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] buffer, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> offset, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> count</span></span></span><span class="hljs-function">)</span></span> { _writer.WriteBase64(buffer, offset, count); } &lt;...&gt; }</code> </pre> <br><h2>  GC induzido </h2><br>  Vamos tentar lidar com cole√ß√µes de lixo induzidas misteriosas.  Verificamos novamente nosso c√≥digo 10 vezes para as chamadas GC.Collect, mas isso falhou.  Consegui capturar esses eventos no PerfView, mas a pilha de chamadas n√£o √© muito indicativa (evento DotNETRuntime / GC / Triggered): <br><br><img src="https://habrastorage.org/webt/ye/j0/qg/yej0qglbieyx_tg05hdgutajhmc.png"><br><br>  H√° uma pequena pista - chamar RecycleLimitMonitor.RaiseRecycleLimitEvent antes da coleta de lixo induzida.  Vamos rastrear a pilha de chamadas para o m√©todo RaiseRecycleLimitEvent: <br><br><pre> <code class="cs hljs">RecycleLimitMonitor.RaiseRecycleLimitEvent(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.AlertProxyMonitors(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.CollectInfrequently(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.PBytesMonitorThread(...)</code> </pre> <br>  Os nomes dos m√©todos s√£o consistentes com suas fun√ß√µes: <br><ul><li>  No construtor de RecycleLimitMonitor.RecycleLimitMonitorSingleton, √© criado um timer que chama PBytesMonitorThread em um determinado intervalo. <br></li><li>  PBytesMonitorThread coleta estat√≠sticas sobre o uso de mem√≥ria e, sob algumas condi√ß√µes, chama CollectInfrequently. <br></li><li>  CollectInfrequently chama AlertProxyMonitors, obt√©m um bool como resultado e chama GC.Collect () se for verdadeiro.  Ele tamb√©m monitora o tempo decorrido desde a √∫ltima chamada para o coletor de lixo e n√£o a chama com muita frequ√™ncia. <br></li><li>  AlertProxyMonitors percorre a lista de aplicativos Web em execu√ß√£o do IIS, pois cada um deles gera o objeto RecycleLimitMonitor correspondente e chama RaiseRecycleLimitEvent. <br></li><li>  RaiseRecycleLimitEvent gera a lista IObserver &lt;RecycleLimitInfo&gt;.  Os manipuladores recebem como um par√¢metro RecycleLimitInfo, no qual eles podem definir o sinalizador RequestGC, que retorna para CollectInfrequently, causando uma coleta de lixo induzida. <br></li></ul><br><br>  Uma investiga√ß√£o mais aprofundada revela que os manipuladores IObserver &lt;RecycleLimitInfo&gt; s√£o adicionados ao m√©todo RecycleLimitMonitor.Subscribe (), chamado no m√©todo AspNetMemoryMonitor.Subscribe ().  Al√©m disso, o manipulador padr√£o IObserver &lt;RecycleLimitInfo&gt; (a classe RecycleLimitObserver) fica suspenso na classe AspNetMemoryMonitor, que limpa os caches do ASP.NET e √†s vezes solicita a coleta de lixo. <br><br>  O enigma do GC induzido est√° quase resolvido.  Resta descobrir a quest√£o de por que essa coleta de lixo √© chamada.  O RecycleLimitMonitor monitora o uso da mem√≥ria do IIS (mais precisamente, o n√∫mero de bytes particulares) e, quando seu uso se aproxima de um determinado limite, ele inicia com um algoritmo bastante confuso para aumentar o evento RaiseRecycleLimitEvent.  O valor de AspNetMemoryMonitor.ProcessPrivateBytesLimit √© usado como limite de mem√≥ria e, por sua vez, cont√©m a seguinte l√≥gica: <br><ul><li>  Se o Pool de aplicativos no IIS estiver definido como 'Limite de mem√≥ria privada (KB)'), o valor em kilobytes ser√° obtido a partir da√≠ <br></li><li>  Caso contr√°rio, para sistemas de 64 bits, 60% da mem√≥ria f√≠sica √© consumida (para sistemas de 32 bits, a l√≥gica √© mais complicada). <br></li></ul><br>  A conclus√£o da investiga√ß√£o √© a seguinte: o ASP.NET est√° chegando ao limite de mem√≥ria e come√ßa a chamar regularmente a coleta de lixo.  O 'Limite de mem√≥ria privada (KB)') n√£o foi definido; portanto, o ASP.NET estava limitado a 60% da mem√≥ria f√≠sica.  O problema foi mascarado pelo fato de que, no servidor do Gerenciador de tarefas, ele mostrava muita mem√≥ria livre e parecia que estava faltando.  Aumentamos o valor 'Limite de mem√≥ria privada (KB)') nas configura√ß√µes do pool de aplicativos no IIS para 80% da mem√≥ria f√≠sica.  Isso incentiva o ASP.NET a usar mais mem√≥ria dispon√≠vel.  Tamb√©m adicionamos o monitoramento do contador de desempenho '.NET CLR Memory / # Induced GC', para n√£o perder na pr√≥xima vez que o ASP.NET decidir que est√° se aproximando do limite de uso da mem√≥ria. <br><br><h2>  Medi√ß√µes repetidas </h2><br>  Vamos ver o que aconteceu com a coleta de lixo ap√≥s todas essas altera√ß√µes.  Vamos come√ßar com perfview / GCCollectOnly (tempo de rastreamento - 1 hora), o relat√≥rio GCStats: <br><br><img src="https://habrastorage.org/webt/8b/l3/fn/8bl3fnxpuymka28coyzbo0r5ak4.png"><br><br>  Pode-se ver que as assembl√©ias da 2¬™ gera√ß√£o s√£o agora 2 ordens de magnitude menores que a 0¬™ e a 1¬™.  Al√©m disso, o tempo dessas assembl√©ias diminuiu.  Montagens induzidas n√£o s√£o mais observadas.  Vejamos a lista de montagens da 2¬™ gera√ß√£o: <br><br><img src="https://habrastorage.org/webt/mx/oy/tv/mxoytvprkypunnhwtao6o6fboai.png"><br><br>  A coluna Ger mostra que todos os conjuntos da 2¬™ gera√ß√£o se tornaram em segundo plano ('2B' significa 2¬™ gera√ß√£o, em segundo plano).  Ou seja, a maior parte do trabalho √© executada em paralelo com a execu√ß√£o do aplicativo e todos os threads s√£o bloqueados por um curto per√≠odo de tempo (coluna 'Pausar MSec').  Vejamos as pausas ao criar objetos grandes: <br><br><img src="https://habrastorage.org/webt/qp/04/hp/qp04hpcq35buinfnfjn5uuudnyg.png"><br><br>  Pode-se observar que o n√∫mero de pausas ao criar objetos grandes caiu significativamente. <br><br><h2>  Sum√°rio </h2><br>  Gra√ßas √†s altera√ß√µes descritas no artigo, foi poss√≠vel reduzir significativamente o n√∫mero e a dura√ß√£o das montagens da 2¬™ gera√ß√£o.  Consegui encontrar a causa das montagens induzidas e me livrar delas.  O n√∫mero de montagens da 0¬™ e 1¬™ gera√ß√£o aumentou, mas a dura√ß√£o m√©dia diminuiu (de ~ 200 ms para ~ 60 ms).  A dura√ß√£o m√°xima de montagem da 0¬™ e 1¬™ gera√ß√£o diminuiu, mas n√£o de maneira t√£o percept√≠vel.  Os conjuntos de 2¬™ gera√ß√£o ficaram mais r√°pidos, longas pausas de at√© 1000ms desapareceram completamente. <br><br>  Quanto √† m√©trica principal - "porcentagem de consultas lentas", ela diminuiu 40% ap√≥s todas as altera√ß√µes. <br><br>  Gra√ßas ao nosso trabalho, percebemos quais contadores de desempenho s√£o necess√°rios para avaliar a situa√ß√£o com mem√≥ria e coleta de lixo, adicionando-os ao Zabbix para monitoramento cont√≠nuo.  Aqui est√° uma lista dos mais importantes que prestamos aten√ß√£o e descobrimos o motivo (por exemplo, um aumento no fluxo de solicita√ß√µes, uma grande quantidade de dados transmitidos, um bug no aplicativo): <br><div class="scrollable-table"><table><tbody><tr><td>  Contador de desempenho </td><td>  Descri√ß√£o do produto </td><td>  Quando prestar aten√ß√£o </td></tr><tr><td>  \ Process (*) \ Bytes Privados </td><td>  A quantidade de mem√≥ria alocada para o aplicativo </td><td rowspan="3">  Os valores excedem em muito o limite.  Como limite, voc√™ pode levar a mediana por 2 semanas a partir dos valores di√°rios m√°ximos. </td></tr><tr><td>  \ Mem√≥ria CLR do .NET (*) \ # Cole√ß√µes de gera√ß√£o 2 </td><td>  A quantidade de mem√≥ria na gera√ß√£o mais antiga </td></tr><tr><td>  \ Mem√≥ria do .NET CLR (*) \ Tamanho do heap de objeto grande </td><td>  A quantidade de mem√≥ria para objetos grandes </td></tr><tr><td>  \ Mem√≥ria CLR do .NET (*) \% de tempo no GC </td><td>  A porcentagem de tempo gasto coletando lixo </td><td>  O valor √© superior a 5%. </td></tr><tr><td>  \ Mem√≥ria CLR do .NET (*) \ # GC induzido </td><td>  N√∫mero de montagens induzidas </td><td>  O valor √© maior que 0. </td></tr></tbody></table></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt452298/">https://habr.com/ru/post/pt452298/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt452284/index.html">Classifica√ß√£o da cobertura do solo usando o eo-learn. Parte 1</a></li>
<li><a href="../pt452288/index.html">Situa√ß√£o: operadoras de telefonia m√≥vel dos EUA acusadas de com√©rcio ilegal de dados geogr√°ficos de assinantes</a></li>
<li><a href="../pt452290/index.html">O que os hackers sentem falta ao quebrar um banco no PHDays</a></li>
<li><a href="../pt452294/index.html">Webinar "Funcion√°rio - backdoor: t√©cnicas modernas de engenharia social"</a></li>
<li><a href="../pt452296/index.html">Dias de hackers positivos 9: concurso de intelig√™ncia competitiva 18 de maio</a></li>
<li><a href="../pt452302/index.html">Programa preliminar PyConRu-2019: dois desenvolvedores Python Core, palestrantes da Anaconda, Intel, JetBrains, Yandex</a></li>
<li><a href="../pt452304/index.html">A OpenAI AI aprendeu a escrever poemas, artigos e not√≠cias</a></li>
<li><a href="../pt452306/index.html">Para onde vai a fintech, como contar a economia unit√°ria e por que desenvolver o empreendedorismo dom√©stico. Mitap Yandex.Money</a></li>
<li><a href="../pt452310/index.html">Configurando canais de vendas em rede para gadgets DO-RA</a></li>
<li><a href="../pt452312/index.html">As telecomunica√ß√µes brit√¢nicas pagar√£o aos assinantes uma compensa√ß√£o pelas desconex√µes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
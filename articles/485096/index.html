<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüåæ ‚è±Ô∏è üêù Cinco m√©todos para la ofuscaci√≥n de la base de datos üéΩ üîâ üëÉüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los usuarios de ClickHouse ya saben que su mayor ventaja es su procesamiento de alta velocidad de consultas anal√≠ticas. Pero afirmaciones como esta de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cinco m√©todos para la ofuscaci√≥n de la base de datos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/485096/">  Los usuarios de ClickHouse ya saben que su mayor ventaja es su procesamiento de alta velocidad de consultas anal√≠ticas.  Pero afirmaciones como esta deben confirmarse con pruebas de rendimiento confiables.  De eso es de lo que queremos hablar hoy. <br><br> <a href="https://habr.com/en/company/yandex/blog/457354/"><img src="https://habrastorage.org/webt/ds/2m/sd/ds2msd5-4zeahpzlzptlqz8wgs8.png"></a> <br><br>  Comenzamos a realizar pruebas en 2013, mucho antes de que el producto estuviera disponible como c√≥digo abierto.  En aquel entonces, al igual que ahora, nuestra principal preocupaci√≥n era la velocidad de procesamiento de datos en Yandex.Metrica.  Hab√≠amos estado almacenando esos datos en ClickHouse desde enero de 2009. Parte de los datos se hab√≠an escrito en una base de datos a partir de 2012, y parte se convirti√≥ de <a href="https://clickhouse.yandex/blog/evolution-of-data-structures-in-yandex-metrica">OLAPServer y Metrage</a> (estructuras de datos utilizadas anteriormente por Yandex.Metrica).  Para las pruebas, tomamos el primer subconjunto al azar de los datos para mil millones de p√°ginas vistas.  Yandex.Metrica no ten√≠a ninguna consulta en ese momento, por lo que se nos ocurrieron consultas que nos interesaron, utilizando todas las formas posibles para filtrar, agregar y clasificar los datos. <br><br>  El rendimiento de ClickHouse se compar√≥ con sistemas similares como Vertica y MonetDB.  Para evitar sesgos, las pruebas fueron realizadas por un empleado que no hab√≠a participado en el desarrollo de ClickHouse, y los casos especiales en el c√≥digo no se optimizaron hasta que se obtuvieron todos los resultados.  Utilizamos el mismo enfoque para obtener un conjunto de datos para pruebas funcionales. <br><br>  Despu√©s de que ClickHouse se lanz√≥ como c√≥digo abierto en 2016, la gente comenz√≥ a cuestionar estas pruebas. <br><br><a name="habracut"></a><h2>  Deficiencias de las pruebas en datos privados </h2><br>  Nuestras pruebas de rendimiento: <br><br><ol><li>  No se pueden reproducir de forma independiente porque usan datos privados que no se pueden publicar.  Algunas de las pruebas funcionales no est√°n disponibles para usuarios externos por la misma raz√≥n. </li><li>  Necesita m√°s desarrollo.  El conjunto de pruebas debe ampliarse sustancialmente para aislar los cambios de rendimiento en partes individuales del sistema. </li><li>  No se ejecute por compromiso o para solicitudes de extracci√≥n individuales.  Los desarrolladores externos no pueden verificar su c√≥digo en busca de regresiones de rendimiento. </li></ol><br>  Podr√≠amos resolver estos problemas descartando los viejos ex√°menes y escribiendo nuevos basados ‚Äã‚Äãen datos abiertos, como <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/ontime">los datos de vuelo de los EE. UU.</a> Y <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/nyc_taxi">los viajes en taxi en Nueva York</a> .  O podr√≠amos usar puntos de referencia como TPC-H, TPC-DS y <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/star_schema">Star Schema Benchmark</a> .  La desventaja es que estos datos son muy diferentes de los datos de Yandex.Metrica, y preferimos mantener las consultas de prueba. <br><br><h2>  Por qu√© es importante usar datos reales </h2><br>  El rendimiento solo debe probarse en datos reales de un entorno de producci√≥n.  Veamos algunos ejemplos. <br><br>  <strong>Ejemplo 1</strong> <br><br>  Supongamos que llena una base de datos con n√∫meros pseudoaleatorios distribuidos uniformemente.  La compresi√≥n de datos no funcionar√° en este caso, aunque la compresi√≥n de datos es esencial para las bases de datos anal√≠ticas.  No existe una soluci√≥n de plata para el desaf√≠o de elegir el algoritmo de compresi√≥n correcto y la forma correcta de integrarlo en el sistema, ya que la compresi√≥n de datos requiere un compromiso entre la velocidad de compresi√≥n y descompresi√≥n y la potencial eficiencia de compresi√≥n.  Pero los sistemas que no pueden comprimir datos son perdedores garantizados.  Si sus pruebas usan n√∫meros pseudoaleatorios distribuidos uniformemente, este factor se ignora y los resultados se distorsionar√°n. <br><br>  En pocas palabras: los datos de prueba deben tener una relaci√≥n de compresi√≥n realista. <br><br>  Cubr√≠ la optimizaci√≥n de los algoritmos de compresi√≥n de datos ClickHouse en <a href="https://habr.com/en/company/yandex/blog/457612/">una publicaci√≥n anterior</a> . <br><br>  <strong>Ejemplo 2</strong> <br><br>  Digamos que estamos interesados ‚Äã‚Äãen la velocidad de ejecuci√≥n de esta consulta SQL: <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> RegionID, uniq(UserID) <span class="hljs-keyword"><span class="hljs-keyword">AS</span></span> visitors <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> test.hits <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> RegionID <span class="hljs-keyword"><span class="hljs-keyword">ORDER</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> visitors <span class="hljs-keyword"><span class="hljs-keyword">DESC</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LIMIT</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span></code> </pre> <br>  Esta es una consulta t√≠pica para Yandex.Metrica.  ¬øQu√© afecta la velocidad de procesamiento? <br><br><ul><li>  C√≥mo se ejecuta GROUP BY. </li><li>  Qu√© estructura de datos se utiliza para calcular la funci√≥n agregada uniq. </li><li>  Cu√°ntos RegionID diferentes hay y cu√°nta RAM requiere cada estado de la funci√≥n uniq. </li></ul><br>  Pero otro factor importante es que la cantidad de datos se distribuye de manera desigual entre las regiones.  (Probablemente sigue una ley de potencia. Pongo la distribuci√≥n en un gr√°fico log-log, pero no puedo decir con certeza). Si este es el caso, es importante que los estados de la funci√≥n agregada uniq con menos valores utilicen Muy poca memoria.  Cuando hay muchas claves de agregaci√≥n diferentes, cada byte cuenta.  ¬øC√≥mo podemos obtener datos generados que tengan todas estas propiedades?  La soluci√≥n obvia es usar datos reales. <br><br>  Muchos DBMS implementan la estructura de datos HyperLogLog para una aproximaci√≥n de COUNT (DISTINCT), pero ninguno de ellos funciona muy bien porque esta estructura de datos utiliza una cantidad fija de memoria.  ClickHouse tiene una funci√≥n que utiliza <a href="https://clickhouse.yandex/docs/en/query_language/agg_functions/reference/">una combinaci√≥n de tres estructuras de datos diferentes</a> , seg√∫n el tama√±o del conjunto de datos. <br><br>  En pocas palabras: los datos de prueba deben representar las propiedades de distribuci√≥n de los datos reales lo suficientemente bien, lo que significa cardinalidad (n√∫mero de valores distintos por columna) y cardinalidad entre columnas (n√∫mero de valores diferentes contados en varias columnas diferentes). <br><br>  <strong>Ejemplo 3</strong> <br><br>  En lugar de probar el rendimiento del DBMS ClickHouse, tomemos algo m√°s simple, como las tablas hash.  Para las tablas hash, es esencial elegir la funci√≥n hash correcta.  Esto no es tan importante para std :: unordered_map, porque es una tabla hash basada en el encadenamiento y se usa un n√∫mero primo como tama√±o de matriz.  La implementaci√≥n est√°ndar de la biblioteca en GCC y Clang usa una funci√≥n hash trivial como la funci√≥n hash predeterminada para los tipos num√©ricos.  Sin embargo, std :: unordered_map no es la mejor opci√≥n cuando buscamos la velocidad m√°xima.  Con una tabla hash de direccionamiento abierto, no podemos usar una funci√≥n hash est√°ndar.  Elegir la funci√≥n hash correcta se convierte en el factor decisivo. <br><br>  Es f√°cil encontrar pruebas de rendimiento de la tabla hash utilizando datos aleatorios que no tienen en cuenta las funciones hash utilizadas.  Tambi√©n hay muchas pruebas de funci√≥n hash que se centran en la velocidad de c√°lculo y ciertos criterios de calidad, a pesar de que ignoran las estructuras de datos utilizadas.  Pero el hecho es que las tablas hash y HyperLogLog requieren diferentes criterios de calidad de funci√≥n hash. <br><br><img src="https://habrastorage.org/webt/bp/3h/32/bp3h320eztrirqzhm-lexeuhmbq.png"><br><br>  Puede obtener m√°s informaci√≥n sobre esto en <a href="https://www.youtube.com/watch%3Fv%3DEoX82TEz2sQ">"C√≥mo funcionan las tablas hash en ClickHouse"</a> (presentaci√≥n en ruso).  La informaci√≥n est√° un poco desactualizada, ya que no cubre las <a href="https://abseil.io/blog/20180927-swisstables">tablas suizas</a> . <br><br><h2>  Desaf√≠o </h2><br>  Nuestro objetivo es obtener datos para probar el rendimiento que tiene la misma estructura que Yandex.Metrica con todas las propiedades que son importantes para los puntos de referencia, pero de tal manera que no haya rastros de usuarios reales del sitio web en estos datos.  En otras palabras, los datos deben ser an√≥nimos y a√∫n preservar: <br><br><ul><li>  Relaci√≥n de compresi√≥n </li><li>  Cardinalidad (el n√∫mero de valores distintos). </li><li>  Cardinalidad mutua entre varias columnas diferentes. </li><li>  Propiedades de las distribuciones de probabilidad que se pueden usar para el modelado de datos (por ejemplo, si creemos que las regiones se distribuyen de acuerdo con una ley de potencia, entonces el exponente, el par√°metro de distribuci√≥n, deber√≠a ser aproximadamente el mismo para los datos artificiales y los reales). </li></ul><br>  ¬øC√≥mo podemos obtener una relaci√≥n de compresi√≥n similar para los datos?  Si se usa LZ4, las subcadenas en datos binarios deben repetirse aproximadamente a la misma distancia y las repeticiones deben tener aproximadamente la misma longitud.  Para ZSTD, la entrop√≠a por byte tambi√©n debe coincidir. <br><br>  El objetivo final es crear una herramienta disponible p√∫blicamente que cualquiera pueda usar para anonimizar sus conjuntos de datos para su publicaci√≥n.  Esto nos permitir√≠a depurar y probar el rendimiento en los datos de otras personas similares a nuestros datos de producci√≥n.  Tambi√©n nos gustar√≠a que los datos generados sean interesantes. <br><br>  Sin embargo, estos son requisitos muy poco definidos y no estamos planeando redactar una declaraci√≥n o especificaci√≥n formal del problema para esta tarea. <br><br><h2>  Posibles soluciones </h2><br>  No quiero que parezca que este problema es particularmente importante.  Nunca se incluy√≥ realmente en la planificaci√≥n y nadie ten√≠a intenciones de trabajar en ello.  Solo esperaba que surgiera una idea alg√∫n d√≠a, y de repente estar√≠a de buen humor y podr√≠a posponer todo lo dem√°s hasta m√°s tarde. <br><br><h2>  Modelos probabil√≠sticos expl√≠citos </h2><br>  La primera idea es tomar cada columna de la tabla y encontrar una familia de distribuciones de probabilidad que la modele, luego ajustar los par√°metros en funci√≥n de las estad√≠sticas de datos (ajuste del modelo) y usar la distribuci√≥n resultante para generar nuevos datos.  Se podr√≠a utilizar un generador de n√∫meros pseudoaleatorio con una semilla predefinida para obtener un resultado reproducible. <br><br>  Las cadenas de Markov podr√≠an usarse para campos de texto.  Este es un modelo familiar que podr√≠a implementarse de manera efectiva. <br><br>  Sin embargo, requerir√≠a algunos trucos: <br><br><ul><li>  Queremos preservar la continuidad de las series de tiempo.  Esto significa que para algunos tipos de datos, necesitamos modelar la diferencia entre los valores vecinos, en lugar del valor en s√≠. </li><li>  Para modelar la "cardinalidad conjunta" de columnas tambi√©n tendremos que reflejar expl√≠citamente las dependencias entre columnas.  Por ejemplo, generalmente hay muy pocas direcciones IP por ID de usuario, por lo que para generar una direcci√≥n IP usar√≠amos un valor hash de la ID de usuario como semilla y tambi√©n agregar√≠amos una peque√±a cantidad de otros datos pseudoaleatorios. </li><li>  No estamos seguros de c√≥mo expresar la dependencia de que el mismo usuario visita con frecuencia las URL con dominios coincidentes aproximadamente al mismo tiempo. </li></ul><br>  Todo esto se puede escribir en un "script" de C ++ con las distribuciones y dependencias codificadas.  Sin embargo, los modelos de Markov se obtienen de una combinaci√≥n de estad√≠sticas con suavizado y adici√≥n de ruido.  Comenc√© a escribir un gui√≥n como este, pero despu√©s de escribir modelos expl√≠citos para diez columnas, se volvi√≥ insoportablemente aburrido, y la tabla de "hits" en Yandex. M√©trica ten√≠a m√°s de 100 columnas en 2012. <br><br><pre> <code class="cpp hljs">EventTime.day(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::discrete_distribution&lt;&gt;({ <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">13</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">42</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">31</span></span>, <span class="hljs-number"><span class="hljs-number">17</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">23</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, ...})(random)); EventTime.hour(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::discrete_distribution&lt;&gt;({ <span class="hljs-number"><span class="hljs-number">13</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">23</span></span>, <span class="hljs-number"><span class="hljs-number">24</span></span>, <span class="hljs-number"><span class="hljs-number">23</span></span>, <span class="hljs-number"><span class="hljs-number">18</span></span>, <span class="hljs-number"><span class="hljs-number">19</span></span>, <span class="hljs-number"><span class="hljs-number">19</span></span>, ...})(random)); EventTime.minute(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::uniform_int_distribution&lt;UInt8&gt;(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">59</span></span>)(random)); EventTime.second(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::uniform_int_distribution&lt;UInt8&gt;(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">59</span></span>)(random)); UInt64 UserID = hash(<span class="hljs-number"><span class="hljs-number">4</span></span>, powerLaw(<span class="hljs-number"><span class="hljs-number">5000</span></span>, <span class="hljs-number"><span class="hljs-number">1.1</span></span>)); UserID = UserID / <span class="hljs-number"><span class="hljs-number">10000000000U</span></span>LL * <span class="hljs-number"><span class="hljs-number">10000000000U</span></span>LL + <span class="hljs-keyword"><span class="hljs-keyword">static_cast</span></span>&lt;<span class="hljs-keyword"><span class="hljs-keyword">time_t</span></span>&gt;(EventTime) + UserID % <span class="hljs-number"><span class="hljs-number">1000000</span></span>; random_with_seed.seed(powerLaw(<span class="hljs-number"><span class="hljs-number">5000</span></span>, <span class="hljs-number"><span class="hljs-number">1.1</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> get_random_with_seed = [&amp;]{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> random_with_seed(); };</code> </pre><br>  Este enfoque fue un fracaso.  Si me hubiera esforzado m√°s, tal vez el gui√≥n ya estar√≠a listo. <br><br>  Ventajas: <br><br><ul><li>  Simplicidad conceptual. </li></ul><br>  Desventajas <br><br><ul><li>  Gran cantidad de trabajo requerido. </li><li>  La soluci√≥n solo se aplica a un tipo de datos. </li></ul><br>  Y preferir√≠a una soluci√≥n m√°s general que se pueda utilizar para los datos de Yandex.Metrica, as√≠ como para ofuscar cualquier otro dato. <br><br>  En cualquier caso, esta soluci√≥n podr√≠a mejorarse.  En lugar de seleccionar modelos manualmente, podr√≠amos implementar un cat√°logo de modelos y elegir el mejor entre ellos (mejor ajuste m√°s alguna forma de regularizaci√≥n).  O tal vez podr√≠amos usar modelos de Markov para todo tipo de campos, no solo para texto.  Las dependencias entre los datos tambi√©n podr√≠an extraerse autom√°ticamente.  Esto requerir√≠a calcular la <a href="https://en.wikipedia.org/wiki/Kullback%25E2%2580%2593Leibler_divergence">entrop√≠a</a> relativa (cantidad relativa de informaci√≥n) entre columnas.  Una alternativa m√°s simple es calcular las cardinalidades relativas para cada par de columnas (algo as√≠ como "cu√°ntos valores diferentes de A hay en promedio para un valor fijo B").  Por ejemplo, esto dejar√° en claro que URLDomain depende completamente de la URL, y no al rev√©s. <br><br>  Pero tambi√©n rechac√© esta idea, porque hay muchos factores a considerar y tomar√≠a demasiado tiempo escribirlos. <br><br><h2>  Redes neuronales </h2><br>  Como ya he mencionado, esta tarea no ocupaba un lugar destacado en la lista de prioridades: nadie pensaba siquiera en tratar de resolverla.  Pero por suerte, nuestro colega Ivan Puzirevsky ense√±aba en la Escuela Superior de Econom√≠a.  Me pregunt√≥ si ten√≠a alg√∫n problema interesante que funcionara como temas de tesis adecuados para sus alumnos.  Cuando le ofrec√≠ este, me asegur√≥ que ten√≠a potencial.  As√≠ que le entregu√© este desaf√≠o a un buen tipo "fuera de la calle" Sharif (aunque s√≠ tuvo que firmar un NDA para acceder a los datos). <br><br>  Compart√≠ todas mis ideas con √©l, pero hice hincapi√© en que no hab√≠a restricciones sobre c√≥mo se podr√≠a resolver el problema, y ‚Äã‚Äãuna buena opci√≥n ser√≠a probar enfoques de los que no s√© nada, como usar LSTM para generar un volcado de datos de texto.  Esto parec√≠a prometedor despu√©s de encontrar el art√≠culo <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">La efectividad irracional de las redes neuronales recurrentes</a> . <br><br>  El primer desaf√≠o es que necesitamos generar datos estructurados, no solo texto.  Pero no estaba claro si una red neuronal recurrente podr√≠a generar datos con la estructura deseada.  Hay dos formas de resolver esto.  La primera soluci√≥n es usar modelos separados para generar la estructura y el "relleno" y solo usar la red neuronal para generar valores.  Pero este enfoque fue pospuesto y luego nunca se complet√≥.  La segunda soluci√≥n es simplemente generar un volcado de TSV como texto.  La experiencia ha demostrado que algunas de las filas del texto no coincidir√°n con la estructura, pero estas filas se pueden desechar al cargar los datos. <br><br>  El segundo desaf√≠o es que la red neuronal recurrente genera una secuencia de datos y, por lo tanto, las dependencias en los datos deben seguir en el orden de la secuencia.  Pero en nuestros datos, el orden de las columnas puede ser potencialmente inverso a las dependencias entre ellas. <br>  No hicimos nada para resolver este problema. <br><br>  A medida que se acercaba el verano, tuvimos el primer script de Python en funcionamiento que gener√≥ datos.  La calidad de los datos parec√≠a decente a primera vista: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f31/4c0/56f/f314c056f24678ea65fdeec9076991bc.jpg"><br><br>  Sin embargo, nos encontramos con algunas dificultades: <br><br><ol><li>  El tama√±o del modelo es de aproximadamente un gigabyte.  Intentamos crear un modelo para datos que ten√≠a un tama√±o de varios gigabytes (para empezar).  El hecho de que el modelo resultante sea tan grande suscita preocupaciones.  ¬øSer√≠a posible extraer los datos reales sobre los que se entren√≥?  Poco probable  Pero no s√© mucho sobre aprendizaje autom√°tico y redes neuronales, y no he le√≠do el c√≥digo Python de este desarrollador, entonces, ¬øc√≥mo puedo estar seguro?  Hubo varios art√≠culos publicados en ese momento sobre c√≥mo comprimir las redes neuronales sin p√©rdida de calidad, pero no se implement√≥.  Por un lado, esto no parece ser un problema grave, ya que podemos optar por no publicar el modelo y simplemente publicar los datos generados.  Por otro lado, si se produce un sobreajuste, los datos generados pueden contener alguna parte de los datos de origen. </li><li>  En una m√°quina con una sola CPU, la velocidad de generaci√≥n de datos es de aproximadamente 100 filas por segundo.  Nuestro objetivo era generar al menos mil millones de filas.  Los c√°lculos mostraron que esto no se completar√≠a antes de la fecha de la defensa de la tesis.  No ten√≠a sentido usar hardware adicional, porque el objetivo era crear una herramienta de generaci√≥n de datos que pudiera ser utilizada por cualquier persona. </li></ol><br>  Sharif trat√≥ de analizar la calidad de los datos mediante la comparaci√≥n de estad√≠sticas.  Entre otras cosas, calcul√≥ la frecuencia de diferentes caracteres que ocurren en los datos de origen y en los datos generados.  El resultado fue sorprendente: los personajes m√°s frecuentes fueron √ê y √ë. <br><br>  Sin embargo, no te preocupes por Sharif.  √âl defendi√≥ con √©xito su tesis y luego felizmente nos olvidamos de todo. <br><br><h2>  Mutaci√≥n de datos comprimidos. </h2><br>  Supongamos que la declaraci√≥n del problema se ha reducido a un solo punto: necesitamos generar datos que tengan la misma relaci√≥n de compresi√≥n que los datos de origen, y los datos deben descomprimirse a la misma velocidad.  ¬øC√≥mo podemos lograr esto?  ¬°Necesitamos editar bytes de datos comprimidos directamente!  Esto nos permite cambiar los datos sin cambiar el tama√±o de los datos comprimidos, adem√°s, todo funcionar√° r√°pido.  Quer√≠a probar esta idea de inmediato, a pesar de que el problema que resuelve no es el mismo con el que comenzamos.  Pero as√≠ es siempre. <br><br>  Entonces, ¬øc√≥mo editamos un archivo comprimido?  Digamos que solo estamos interesados ‚Äã‚Äãen LZ4.  Los datos comprimidos de LZ4 se componen de secuencias, que a su vez son cadenas de bytes no comprimidos (literales), seguidas de una copia de coincidencia: <br><br><ol><li>  Literales (copie los siguientes N bytes tal como est√°n). </li><li>  Coincide con una longitud m√≠nima de repetici√≥n de 4 (repita N bytes que estaban en el archivo a una distancia de M). </li></ol><br>  Datos de origen: <br>  <code>Hello world Hello</code> <br><br>  Datos comprimidos (ejemplo arbitrario): <br>  <code>literals 12 "Hello world " match 5 12</code> . <br><br>  En el archivo comprimido, dejamos "coincidir" tal cual y cambiamos los valores de bytes en "literales".  Como resultado, despu√©s de descomprimir, obtenemos un archivo en el que todas las secuencias repetidas de al menos 4 bytes de longitud tambi√©n se repiten a la misma distancia, pero consisten en un conjunto diferente de bytes (b√°sicamente, el archivo modificado no contiene un solo byte que fue tomado del archivo fuente). <br><br>  ¬øPero c√≥mo cambiamos los bytes?  La respuesta no es obvia, porque adem√°s de los tipos de columna, los datos tambi√©n tienen su propia estructura interna impl√≠cita que nos gustar√≠a preservar.  Por ejemplo, el texto a menudo se almacena en codificaci√≥n UTF-8, y queremos que los datos generados tambi√©n sean v√°lidos UTF-8.  Desarroll√© una heur√≠stica simple que implica cumplir varios criterios: <br><br><ul><li>  Los bytes nulos y los caracteres de control ASCII se mantienen tal cual. </li><li>  Algunos caracteres de puntuaci√≥n permanecen tal cual. </li><li>  ASCII se convierte a ASCII y para todo lo dem√°s se conserva el bit m√°s significativo (o se escribe un conjunto expl√≠cito de sentencias "if" para diferentes longitudes UTF-8).  En una clase de byte, un nuevo valor se elige de manera uniforme al azar. </li><li>  Se conservan fragmentos como <code>https://</code> , de lo contrario, parece un poco tonto. </li></ul><br>  La √∫nica advertencia de este enfoque es que el modelo de datos son los datos de origen en s√≠, lo que significa que no se pueden publicar.  El modelo solo es apto para generar cantidades de datos no mayores que la fuente.  Por el contrario, los enfoques anteriores proporcionan modelos que permiten generar datos de tama√±o arbitrario. <br><br>  Ejemplo para una URL: <br><br> <code>http://ljc.she/kdoqdqwpgafe/klwlpm&amp;qw=962788775I0E7bs7OXeAyAx <br> http://ljc.she/kdoqdqwdffhant.am/wcpoyodjit/cbytjgeoocvdtclac <br> http://ljc.she/kdoqdqwpgafe/klwlpm&amp;qw=962788775I0E7bs7OXe <br> http://ljc.she/kdoqdqwdffhant.am/wcpoyodjit/cbytjgeoocvdtclac <br> http://ljc.she/kdoqdqwdbknvj.s/hmqhpsavon.yf#aortxqdvjja <br> http://ljc.she/kdoqdqw-bknvj.s/hmqhpsavon.yf#aortxqdvjja <br> http://ljc.she/kdoqdqwpdtu-Unu-Rjanjna-bbcohu_qxht <br> http://ljc.she/kdoqdqw-bknvj.s/hmqhpsavon.yf#aortxqdvjja <br> http://ljc.she/kdoqdqwpdtu-Unu-Rjanjna-bbcohu_qxht <br> http://ljc.she/kdoqdqw-bknvj.s/hmqhpsavon.yf#aortxqdvjja <br> http://ljc.she/kdoqdqwpdtu-Unu-Rjanjna-bbcohu-702130 <br></code> <br>  Los resultados fueron positivos y los datos fueron interesantes, pero algo no estaba del todo bien.  Las URL manten√≠an la misma estructura, pero en algunas de ellas era demasiado f√°cil reconocer "yandex" o "avito" (un mercado popular en Rusia), as√≠ que cre√© una heur√≠stica que intercambia algunos de los bytes. <br><br>  Tambi√©n hubo otras preocupaciones.  Por ejemplo, la informaci√≥n confidencial posiblemente podr√≠a residir en una columna FixedString en representaci√≥n binaria y potencialmente consta de caracteres de control ASCII y puntuaci√≥n, que decid√≠ preservar.  Sin embargo, no tom√© en cuenta los tipos de datos. <br><br>  Otro problema es que si una columna almacena datos en el formato "longitud, valor" (as√≠ es como se almacenan las columnas de cadena), ¬øc√≥mo me aseguro de que la longitud siga siendo correcta despu√©s de la mutaci√≥n?  Cuando trat√© de arreglar esto, inmediatamente perd√≠ el inter√©s. <br><br><h2>  Permutaciones aleatorias </h2><br>  Lamentablemente, el problema no se resolvi√≥.  Realizamos algunos experimentos, y empeor√≥.  Lo √∫nico que quedaba era sentarse sin hacer nada y navegar por la web al azar, ya que la magia hab√≠a desaparecido.  Afortunadamente, me encontr√© con una p√°gina que <a href="http://fabiensanglard.net/fizzlefade/index.php">explicaba el algoritmo</a> para representar la muerte del personaje principal en el juego Wolfenstein 3D. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6d4/974/bc8/6d4974bc880538a894617dfb0c77eb3d.gif" width="640" height="480"><br><br>  La animaci√≥n est√° muy bien hecha: la pantalla se llena de sangre.  El art√≠culo explica que esto es en realidad una permutaci√≥n pseudoaleatoria.  Una permutaci√≥n aleatoria de un conjunto de elementos es una transformaci√≥n biyectiva (uno a uno) escogida al azar del conjunto, o un mapeo donde cada elemento derivado corresponde exactamente a un elemento original (y viceversa).  En otras palabras, es una forma de iterar aleatoriamente a trav√©s de todos los elementos de un conjunto de datos.  Y ese es exactamente el proceso que se muestra en la imagen: cada p√≠xel se llena en orden aleatorio, sin ninguna repetici√≥n.  Si solo tuvi√©ramos que elegir un p√≠xel aleatorio en cada paso, llevar√≠a mucho tiempo llegar al √∫ltimo. <br><br>  El juego utiliza un algoritmo muy simple para la permutaci√≥n pseudoaleatoria llamado registro de desplazamiento de retroalimentaci√≥n lineal ( <a href="https://en.wikipedia.org/wiki/Linear-feedback_shift_register">LFSR</a> ).  Al igual que los generadores de n√∫meros pseudoaleatorios, las permutaciones aleatorias, o m√°s bien sus familias, pueden ser criptogr√°ficamente fuertes cuando se parametrizan mediante una clave.  Esto es exactamente lo que necesitamos para la transformaci√≥n de datos.  Sin embargo, los detalles pueden ser m√°s complicados.  Por ejemplo, el cifrado criptogr√°ficamente fuerte de N bytes a N bytes con una clave predeterminada y un vector de inicializaci√≥n parece funcionar para una permutaci√≥n pseudoaleatoria de un conjunto de cadenas de N bytes.  De hecho, esta es una transformaci√≥n uno a uno y parece ser aleatoria.  Pero si usamos la misma transformaci√≥n para todos nuestros datos, el resultado puede ser susceptible al criptoan√°lisis porque el mismo vector de inicializaci√≥n y el valor clave se usan varias veces.  Esto es similar al modo de operaci√≥n del <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">Libro</a> de <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation">c√≥digos electr√≥nico</a> para un cifrado de bloque. <br><br>  ¬øCu√°les son las formas posibles de obtener una permutaci√≥n pseudoaleatoria?  Podemos tomar transformaciones simples uno a uno y construir una funci√≥n compleja que parezca aleatoria.  Estas son algunas de mis transformaciones individuales favoritas: <br><br><ul><li>  Multiplicaci√≥n por un n√∫mero impar (como un n√∫mero primo grande) en la aritm√©tica del complemento a dos. </li><li>  Xorshift: <code>x ^= x &gt;&gt; N</code> </li><li>  CRC-N, donde N es el n√∫mero de bits en el argumento. </li></ul><br>  Por ejemplo, tres multiplicaciones y dos operaciones xorshift se utilizan para el finalizador <a href="">murmurhash</a> .  Esta operaci√≥n es una permutaci√≥n pseudoaleatoria.  Sin embargo, debo se√±alar que las funciones hash no tienen que ser uno a uno (incluso hashes de N bits a N bits). <br><br>  O aqu√≠ hay otro <a href="https://preshing.com/20121224/how-to-generate-a-sequence-of-unique-random-integers/">ejemplo</a> interesante <a href="https://preshing.com/20121224/how-to-generate-a-sequence-of-unique-random-integers/">de la teor√≠a</a> de <a href="https://preshing.com/20121224/how-to-generate-a-sequence-of-unique-random-integers/">los n√∫meros elementales</a> del sitio web de Jeff Preshing. <br><br>  ¬øC√≥mo podemos usar permutaciones pseudoaleatorias para resolver nuestro problema?  Podemos usarlos para transformar todos los campos num√©ricos para poder preservar las cardinalidades y las cardinalidades mutuas de todas las combinaciones de campos.  En otras palabras, COUNT (DISTINCT) devolver√° el mismo valor que antes de la transformaci√≥n y, adem√°s, con cualquier GROUP BY. <br><br>  Vale la pena se√±alar que preservar todas las cardinalidades contradice de alguna manera nuestro objetivo de anonimizaci√≥n de datos.  Digamos que alguien sabe que los datos de origen para las sesiones del sitio contienen un usuario que visit√≥ sitios de 10 pa√≠ses diferentes, y quieren encontrar a ese usuario en los datos transformados.  Los datos transformados tambi√©n muestran que el usuario visit√≥ sitios de 10 pa√≠ses diferentes, lo que facilita la b√∫squeda.  Incluso si descubren en qu√© se transform√≥ el usuario, no ser√° muy √∫til, porque todos los dem√°s datos tambi√©n se han transformado, por lo que no podr√°n averiguar qu√© sitios visit√≥ el usuario ni nada m√°s.  Pero estas reglas pueden aplicarse en una cadena.  Por ejemplo, si alguien sabe que el sitio web que aparece con mayor frecuencia en nuestros datos es Yandex, con Google en segundo lugar, puede usar la clasificaci√≥n para determinar qu√© identificadores de sitios transformados realmente significan Yandex y Google.  No hay nada sorprendente en esto, ya que estamos trabajando con un enunciado informal del problema y solo estamos tratando de encontrar un equilibrio entre el anonimato de datos (ocultar informaci√≥n) y preservar las propiedades de los datos (divulgaci√≥n de informaci√≥n).  Para obtener informaci√≥n sobre c√≥mo abordar el problema de anonimato de datos de manera m√°s confiable, lea este <a href="https://medium.com/georgian-impact-blog/a-brief-introduction-to-differential-privacy-eacf8722283b">art√≠culo</a> . <br><br>  Adem√°s de mantener la cardinalidad original de los valores, tambi√©n quiero mantener el orden de magnitud de los valores.  Lo que quiero decir es que si los datos de origen conten√≠an n√∫meros menores a 10, entonces quiero que los n√∫meros transformados tambi√©n sean peque√±os.  ¬øC√≥mo podemos lograr esto? <br><br>  Por ejemplo, podemos dividir un conjunto de valores posibles en clases de tama√±o y realizar permutaciones dentro de cada clase por separado (manteniendo las clases de tama√±o).  La forma m√°s f√°cil de hacer esto es tomar la potencia m√°s cercana de dos o la posici√≥n del bit m√°s significativo en el n√∫mero como la clase de tama√±o (son la misma cosa).  Los n√∫meros 0 y 1 siempre permanecer√°n como est√°n.  Los n√∫meros 2 y 3 a veces permanecer√°n como est√°n (con una probabilidad de 1/2) y a veces se intercambiar√°n (con una probabilidad de 1/2).  ¬°El conjunto de n√∫meros 1024. 2047 se asignar√° a uno de 1024!  variantes (factoriales), etc.  Para n√∫meros con signo, conservaremos el signo. <br><br>  Tambi√©n es dudoso si necesitamos una funci√≥n uno a uno.  Probablemente podamos usar una funci√≥n hash criptogr√°ficamente fuerte.  La transformaci√≥n no ser√° uno a uno, pero la cardinalidad ser√° cercana a la misma. <br><br>  Sin embargo, necesitamos una permutaci√≥n aleatoria criptogr√°ficamente fuerte para que cuando definamos una clave y derivemos una permutaci√≥n con esa clave, ser√≠a dif√≠cil restaurar los datos originales de los datos reorganizados sin conocer la clave. <br><br>  Hay un problema: adem√°s de no saber nada sobre redes neuronales y aprendizaje autom√°tico, tambi√©n soy bastante ignorante cuando se trata de criptograf√≠a.  Eso deja solo mi coraje.  Todav√≠a estaba leyendo p√°ginas web al azar, y encontr√© un enlace en <a href="https://news.ycombinator.com/item%3Fid%3D15122540">Hackers News</a> a una discusi√≥n en la p√°gina de Fabien Sanglard.  Ten√≠a un enlace a una <a href="http://antirez.com/news/113">publicaci√≥n de blog</a> del desarrollador de Redis Salvatore Sanfilippo que hablaba sobre el uso de una maravillosa forma gen√©rica de obtener permutaciones aleatorias, conocida como una <a href="https://en.wikipedia.org/wiki/Feistel_cipher">red Feistel</a> . <br><br>  La red Feistel es iterativa y consiste en rondas.  Cada ronda es una transformaci√≥n notable que le permite obtener una funci√≥n uno a uno de cualquier funci√≥n.  Veamos c√≥mo funciona. <br><br><ol><li>  Los bits del argumento se dividen en dos mitades: <br> <code>arg: xxxxyyyy <br> <font color="#0fc000">arg_l</font> : xxxx <br> <font color="#0000ff">arg_r</font> : yyyy</code> </li> <li>  La mitad derecha reemplaza a la izquierda.  En su lugar, colocamos el resultado de XOR en el valor inicial de la mitad izquierda y el resultado de la funci√≥n aplicada al valor inicial de la mitad derecha, as√≠: <br> <code>res: yyyyzzzz <br> <font color="#0000ff">res_l</font> = yyyy = <font color="#0000ff">arg_r</font> <br> <font color="#FF6600">res_r</font> = zzzz = <font color="#0fc000">arg_l</font> ^ F( <font color="#0000ff">arg_r</font> )</code> </li> </ol><br>  Tambi√©n se afirma que si usamos una funci√≥n pseudoaleatoria criptogr√°ficamente fuerte para F y aplicamos una ronda Feistel al menos 4 veces, obtendremos una permutaci√≥n pseudoaleatoria criptogr√°ficamente fuerte. <br><br>  Esto es como un milagro: tomamos una funci√≥n que produce basura aleatoria basada en datos, la insertamos en la red Feistel, y ahora tenemos una funci√≥n que produce basura aleatoria basada en datos, ¬°pero a√∫n as√≠ es invertible! <br><br>  La red Feistel est√° en el coraz√≥n de varios algoritmos de encriptaci√≥n de datos.  Lo que vamos a hacer es algo como el cifrado, solo que es realmente malo.  Hay dos razones para esto: <br><br><ul><li>  Estamos encriptando valores individuales de forma independiente y de la misma manera, de manera similar al modo de operaci√≥n del Libro de c√≥digos electr√≥nicos. </li><li>  Estamos almacenando informaci√≥n sobre el orden de magnitud (la potencia m√°s cercana de dos) y el signo del valor, lo que significa que algunos valores no cambian en absoluto. </li></ul><br>  De esta manera, podemos ofuscar los campos num√©ricos mientras conservamos las propiedades que necesitamos.  Por ejemplo, despu√©s de usar LZ4, la relaci√≥n de compresi√≥n deber√≠a permanecer aproximadamente igual, porque los valores duplicados en los datos de origen se repetir√°n en los datos convertidos, y a las mismas distancias entre s√≠. <br><br><h2>  Modelos de Markov </h2><br>  Los modelos de texto se utilizan para la compresi√≥n de datos, entrada predictiva, reconocimiento de voz y generaci√≥n de cadenas aleatorias.  Un modelo de texto es una distribuci√≥n de probabilidad de todas las cadenas posibles.  Digamos que tenemos una distribuci√≥n de probabilidad imaginaria de los textos de todos los libros que la humanidad podr√≠a escribir.  Para generar una cadena, simplemente tomamos un valor aleatorio con esta distribuci√≥n y devolvemos la cadena resultante (un libro aleatorio que la humanidad podr√≠a escribir).  Pero, ¬øc√≥mo descubrimos la distribuci√≥n de probabilidad de todas las cadenas posibles? <br><br>  Primero, esto requerir√≠a demasiada informaci√≥n.  Hay 256 ^ 10 cadenas posibles que tienen una longitud de 10 bytes, y se necesitar√≠a bastante memoria para escribir expl√≠citamente una tabla con la probabilidad de cada cadena.  En segundo lugar, no tenemos suficientes estad√≠sticas para evaluar con precisi√≥n la distribuci√≥n. <br><br>  Es por eso que usamos una distribuci√≥n de probabilidad obtenida de estad√≠sticas aproximadas como modelo de texto.  Por ejemplo, podr√≠amos calcular la probabilidad de que cada letra ocurra en el texto y luego generar cadenas seleccionando cada letra siguiente con la misma probabilidad.  Este modelo primitivo funciona, pero las cadenas siguen siendo muy poco naturales. <br><br>  Para mejorar ligeramente el modelo, tambi√©n podr√≠amos hacer uso de la probabilidad condicional de la aparici√≥n de la letra si est√° precedida por N letras espec√≠ficas.  N es una constante preestablecida.  Digamos N = 5 y estamos calculando la probabilidad de que la letra "e" ocurra despu√©s de las letras "compr".  Este modelo de texto se llama modelo Order-N Markov. <br><br> <code>P(cat <font color="#ff0000">a</font> | cat) = 0.8 <br> P(cat <font color="#ff0000">b</font> | cat) = 0.05 <br> P(cat <font color="#ff0000">c</font> | cat) = 0.1 <br> ...</code> <br> <br>  Veamos c√≥mo funcionan los modelos de Markov en el sitio web <a href="https://projects.haykranen.nl/markov/demo/">de Hay Kranen</a> .  A diferencia de las redes neuronales LSTM, los modelos solo tienen memoria suficiente para un peque√±o contexto de N de longitud fija, por lo que generan textos divertidos y sin sentido.  Los modelos de Markov tambi√©n se utilizan en m√©todos primitivos para generar spam, y los textos generados se pueden distinguir f√°cilmente de los reales contando estad√≠sticas que no se ajustan al modelo.  Hay una ventaja: los modelos de Markov funcionan mucho m√°s r√°pido que las redes neuronales, que es exactamente lo que necesitamos. <br><br>  Ejemplo de t√≠tulo (nuestros ejemplos est√°n en turco debido a los datos utilizados): <br><br><blockquote>  Hyunday Butter'dan anket shluha - Politika cabeza man≈üetleri |  STALKER BOXER √áiftede book - Yanudistkarƒ±≈ümanlƒ± Mƒ± Kanal |  League el Digitalika Haberler Haberleri - Haberlerisi - Hoteles con Centry'ler Neden babah.com </blockquote><br>  Podemos calcular estad√≠sticas a partir de los datos de origen, crear un modelo de Markov y generar nuevos datos con √©l.  Tenga en cuenta que el modelo necesita suavizarse para evitar revelar informaci√≥n sobre combinaciones raras en los datos de origen, pero esto no es un problema.  Utilizo una combinaci√≥n de modelos de 0 a N. Si las estad√≠sticas son insuficientes para el modelo de orden N, se utiliza el modelo N - 1. <br><br>  Pero a√∫n queremos preservar la cardinalidad de los datos.  En otras palabras, si los datos de origen ten√≠an 123456 valores de URL √∫nicos, el resultado deber√≠a tener aproximadamente el mismo n√∫mero de valores √∫nicos.  Podemos usar un generador de n√∫meros aleatorios inicializado determin√≠sticamente para lograr esto.  La forma m√°s f√°cil de hacer esto es usar una funci√≥n hash y aplicarla al valor original.  En otras palabras, obtenemos un resultado pseudoaleatorio que est√° expl√≠citamente determinado por el valor original. <br><br>  Otro requisito es que los datos de origen pueden tener muchas URL diferentes que comienzan con el mismo prefijo pero no son id√©nticos.  Por ejemplo: <code>https://www.yandex.ru/images/cats/?id=xxxxxx</code> .  Queremos que el resultado tambi√©n tenga URL que comiencen con el mismo prefijo, pero diferente.  Por ejemplo: <code>http://ftp.google.kz/cgi-bin/index.phtml?item=xxxxxx</code> .  Como generador de n√∫meros aleatorios para generar el siguiente car√°cter usando un modelo de Markov, tomaremos una funci√≥n hash de una ventana m√≥vil de 8 bytes en la posici√≥n especificada (en lugar de tomarla de toda la cadena). <br><br> <code>https://www.yandex.ru/ <font color="#0fc000">images/c</font> ats/?id=12345 <br> ^^^^^^^^ <br> <br> distribution: [aaaa][b][cc][dddd][e][ff][g <font color="#ff0000">g</font> ggg][h]... <br> hash(" <font color="#0fc000">images/c</font> ") % total_count:           ^ <br> <br></code> <code>http://ftp.google.kz/c <font color="#ff0000">g</font> ...</code> <br> <br>  Resulta ser exactamente lo que necesitamos.  Aqu√≠ est√° el ejemplo de los t√≠tulos de las p√°ginas: <br><br><blockquote><pre>  PhotoFunia - Haber7 - Hava m√ºkemment.net Oynamak i√ßinde ≈üa≈üƒ±racak haber, Oyunu Oynanƒ±lmaz ‚Ä¢ apr√≥d.hu k√≠n√°lat√°ban - RT √Årabe
 PhotoFunia - Kinobar.Net - apr√≥d: Ingyenes |  Posti
 PhotoFunia - Peg Perfeo - Castika, Sƒ±radƒ±≈üƒ± Deniz Lokoning Your Code, sire Eminema.tv/
 PhotoFunia - TUT.BY - Tu Ayakkanƒ±n ve Son Dakika Spor,
 PhotoFunia - pel√≠cula grande izle, Del Meireles offilim, Samsung DealeXtreme Deƒüerler NEWSru.com.tv, Smotri.com Mobile yapmak Okey
 PhotoFunia 5 |  Galaxy, gt, dupƒÉ ce anal bilgi yarak Ceza RE050A V-Stran√ß
 PhotoFunia :: Miami olacaksƒ±nƒ± yerel Haberler Oyun Young video
 PhotoFunia Monstelli'nin En ƒ∞yi kisa.com.tr ‚ÄìStar Thunder Ekranƒ±
 PhotoFunia Seks - Politika, Ekonomi, Spor GTA SANAYƒ∞ VE
 PhotoFunia Taker-Rating Star TV Resmi S√∂ylenen Yataƒüa ka≈ºdy dzie≈º wierzchnie
 PhotoFunia TourIndex.Marketime oyunu Oyna Geldollarƒ± Mynet Spor, Magazin, Haberler yerel Haberleri ve Solvia, korkusuz Ev SahneTv
 PhotoFunia todo en el Fotograma Gratis Perky Parti'nin yapƒ±yƒ± bu
 PhotoFunian D√ºnyasƒ±n takƒ±mƒ±z halles en kullarƒ± - TEZ
</pre></blockquote><br><h2>  Resultados </h2><br>  Despu√©s de probar cuatro m√©todos, me cans√© tanto de este problema que lleg√≥ el momento de elegir algo, convertirlo en una herramienta utilizable y anunciar la soluci√≥n.  Eleg√≠ la soluci√≥n que usa permutaciones aleatorias y modelos de Markov parametrizados por una clave.  Se implementa como el programa <b>clickhouse-ofuscador</b> , que es muy f√°cil de usar.  La entrada es un volcado de tabla en <a href="https://clickhouse.yandex/docs/en/interfaces/formats/">cualquier formato compatible</a> (como CSV o JSONEachRow), y los par√°metros de la l√≠nea de comando especifican la estructura de la tabla (nombres y tipos de columna) y la clave secreta (cualquier cadena, que puede olvidar inmediatamente despu√©s de usar).  El resultado es el mismo n√∫mero de filas de datos ofuscados. <br><br>  El programa se instala con clickhouse-client, no tiene dependencias y funciona en casi cualquier versi√≥n de Linux.  Puede aplicarlo a cualquier volcado de la base de datos, no solo a ClickHouse.  Por ejemplo, puede generar datos de prueba de bases de datos MySQL o PostgreSQL o crear bases de datos de desarrollo que sean similares a las bases de datos de producci√≥n. <br><br> <code>clickhouse-obfuscator \ <br> --seed "$(head -c16 /dev/urandom | base64)" \ <br> --input-format TSV --output-format TSV \ <br> --structure 'CounterID UInt32, URLDomain String, \ <br> URL String, SearchPhrase String, Title String' \ <br> &lt; table.tsv &gt; result.tsv <br> <br> clickhouse-obfuscator --help <br></code> <br>  Por supuesto, todo no est√° tan cortado y seco, porque los datos transformados por este programa son casi completamente reversibles.  La pregunta es si es posible realizar la transformaci√≥n inversa sin conocer la clave.  Si la transformaci√≥n utilizara un algoritmo criptogr√°fico, esta operaci√≥n ser√≠a tan dif√≠cil como una b√∫squeda de fuerza bruta.  Aunque la transformaci√≥n usa algunas primitivas criptogr√°ficas, no se usan de la manera correcta y los datos son susceptibles a ciertos m√©todos de an√°lisis.  Para evitar problemas, estos problemas est√°n cubiertos en la documentaci√≥n del programa (acceda usando <code>--help</code> ). <br><br>  Al final, transformamos el conjunto de datos que necesitamos <a href="https://clickhouse.yandex/docs/en/getting_started/example_datasets/metrica/">para las pruebas funcionales y de rendimiento</a> y la publicaci√≥n aprobada de VP de Yandex de seguridad de datos. <br><br>  <a href="">clickhouse-datasets.s3.yandex.net/hits/tsv/hits_v1.tsv.xz</a> <br>  <a href="">clickhouse-datasets.s3.yandex.net/visits/tsv/visits_v1.tsv.xz</a> <br><br>  Los desarrolladores que no son de Yandex usan estos datos para realizar pruebas de rendimiento real al optimizar algoritmos dentro de ClickHouse.  Los usuarios de terceros pueden proporcionarnos sus datos ofuscados para que podamos hacer que ClickHouse sea a√∫n m√°s r√°pido para ellos.  Tambi√©n lanzamos un punto de referencia abierto independiente para proveedores de hardware y nube adem√°s de estos datos: <a href="https://clickhouse.yandex/benchmark_hardware.html">clickhouse.yandex/benchmark_hardware.html</a> </div></div><p>Source: <a href="https://habr.com/ru/post/485096/">https://habr.com/ru/post/485096/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../485084/index.html">Plancton de oficina - Evoluci√≥n</a></li>
<li><a href="../485088/index.html">Rastrillo retrospectivo. C√≥mo una soluci√≥n hecha a s√≠ misma result√≥ ser m√°s fresca de lo que se pag√≥</a></li>
<li><a href="../485090/index.html">El secreto de la eficiencia es el c√≥digo de calidad, no un administrador efectivo</a></li>
<li><a href="../485092/index.html">Validaci√≥n de datos en aplicaciones iOS</a></li>
<li><a href="../485094/index.html">Microservicios con Spring Boot. Parte 3. Crear un microservicio de conversi√≥n de moneda</a></li>
<li><a href="../485098/index.html">¬øPuede el dise√±o afectar la velocidad de entrega?</a></li>
<li><a href="../485100/index.html">D√≥nde ir: los pr√≥ximos eventos gratuitos para desarrolladores en Mosc√∫ (30 de enero - 15 de febrero)</a></li>
<li><a href="../485102/index.html">Topleaked: una herramienta para detectar p√©rdidas de memoria</a></li>
<li><a href="../485104/index.html">Hacer una llave RFID universal para intercomunicadores</a></li>
<li><a href="../485108/index.html">Estad√≠sticas de especialistas certificados de PMI en Rusia el 10/01/2020</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
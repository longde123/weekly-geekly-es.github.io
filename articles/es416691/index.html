<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüë©‚Äçüë¶ üòÜ üõ¥ Seguridad del aprendizaje autom√°tico: ¬øt√©cnicas de defensa eficaces o nuevas amenazas? üíã üë©üèª‚Äçüíº üèáüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Una de las noticias m√°s populares y discutidas en los √∫ltimos a√±os es qui√©n agreg√≥ inteligencia artificial a d√≥nde y qu√© piratas inform√°ticos rompiero...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Seguridad del aprendizaje autom√°tico: ¬øt√©cnicas de defensa eficaces o nuevas amenazas?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pt/blog/416691/"><p>  Una de las noticias m√°s populares y discutidas en los √∫ltimos a√±os es qui√©n agreg√≥ inteligencia artificial a d√≥nde y qu√© piratas inform√°ticos rompieron qu√© y d√≥nde.  Al combinar estos temas, aparecen estudios muy interesantes, y ya hab√≠a varios art√≠culos en el centro que pod√≠an enga√±ar a los modelos de aprendizaje autom√°tico, por ejemplo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo sobre las limitaciones del aprendizaje profundo</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sobre c√≥mo atraer redes neuronales</a> .  Adem√°s, me gustar√≠a considerar este tema con m√°s detalle desde el punto de vista de la seguridad inform√°tica: </p><br><p><img src="https://habrastorage.org/webt/xg/nc/ev/xgncevhjj0f8_lijnifrzr5x9zm.jpeg" alt="imagen"></p><a name="habracut"></a><br><p>  <strong>Considere los siguientes problemas:</strong> </p><br><ul><li>  T√©rminos importantes </li><li>  ¬øQu√© es el aprendizaje autom√°tico? Si de repente a√∫n no lo sab√≠as. </li><li>  ¬øQu√© tiene que ver la seguridad inform√°tica? </li><li>  ¬øEs posible manipular el modelo de aprendizaje autom√°tico para realizar un ataque dirigido? </li><li> ¬øSe puede degradar el rendimiento del sistema? </li><li>  ¬øPuedo aprovechar las limitaciones de los modelos de aprendizaje autom√°tico? </li><li>  Categorizaci√≥n de los ataques. </li><li>  Formas de protecci√≥n. </li><li>  Posibles consecuencias. </li></ul><br><h3 id="1-pervoe-s-chego-hotelos-by-nachat--s-terminologii-a-nametermsa">  1. Lo primero con lo que me gustar√≠a comenzar es la terminolog√≠a. </h3><br><p>  Esta posible declaraci√≥n puede causar un gran holivar por parte de las comunidades cient√≠ficas y profesionales debido a los varios art√≠culos ya escritos en ruso, pero me gustar√≠a se√±alar que el t√©rmino "inteligencia de confrontaci√≥n" se traduce como "inteligencia enemiga".  Y la palabra "adversarial" en s√≠ misma debe traducirse no por el t√©rmino legal "adversarial", sino por un t√©rmino m√°s adecuado de seguridad "malicioso" (no hay quejas sobre la traducci√≥n del nombre de la arquitectura de la red neuronal).  Luego, todos los t√©rminos relacionados en ruso adquieren un significado mucho m√°s brillante, como "ejemplo de confrontaci√≥n" - una instancia maliciosa de datos, "configuraci√≥n de confrontaci√≥n" - un entorno malicioso.  Y el √°rea que consideraremos "aprendizaje autom√°tico adversario" es el aprendizaje autom√°tico malicioso. </p><br><p>  Al menos en el marco de este art√≠culo, se utilizar√°n dichos t√©rminos en ruso.  Espero que sea posible demostrar que este tema trata mucho m√°s sobre la seguridad para utilizar de manera justa los t√©rminos de esta √°rea, en lugar del primer ejemplo de un traductor. </p><br><p>  Entonces, ahora que estamos listos para hablar el mismo idioma, podemos comenzar esencialmente :) </p><br><h3 id="2-chto-takoe-mashinnoe-obuchenie-esli-vdrug-vy-vse-esche-ne-znali-a-idmachine_learninga">  2. Qu√© es el aprendizaje autom√°tico, si de repente a√∫n no sab√≠as </h3><br><div class="spoiler">  <b class="spoiler_title">Bueno, todavia estoy en el saber</b> <div class="spoiler_text"><p>  Por m√©todos de aprendizaje autom√°tico, generalmente nos referimos a m√©todos para construir algoritmos que pueden aprender y actuar sin programar expl√≠citamente su comportamiento en datos preseleccionados.  Por datos podemos decir cualquier cosa, si podemos describirlo con algunos signos o medirlo.  Si hay alg√∫n signo desconocido para algunos de los datos, pero realmente lo necesitamos, utilizamos m√©todos de aprendizaje autom√°tico para restaurar o predecir este signo en funci√≥n de datos ya conocidos. </p><br><p><img src="https://habrastorage.org/webt/xf/1o/tz/xf1otzv3z0siwvtbccazyjzj8lu.jpeg" alt="01"></p><br><p>  Hay varios tipos de problemas que pueden resolverse con la ayuda del aprendizaje autom√°tico, pero hablaremos principalmente sobre el problema de clasificaci√≥n. </p><br><p>  Cl√°sicamente, el prop√≥sito de la etapa de entrenamiento del modelo clasificador es seleccionar una relaci√≥n (funci√≥n) que muestre la correspondencia entre las caracter√≠sticas de un objeto en particular y una de las clases conocidas.  En un caso m√°s complejo, se requiere una predicci√≥n de la probabilidad de pertenecer a una categor√≠a particular. </p><br><p>  Es decir, la tarea de clasificaci√≥n es construir un hiperplano que divida el espacio, donde, por regla general, su dimensi√≥n es el tama√±o del vector de caracter√≠sticas, de modo que los objetos de diferentes clases se encuentran en lados opuestos de este hiperplano. </p><br><p>  Para un espacio bidimensional, tal hiperplano es una l√≠nea.  Considere un ejemplo simple: </p><br><p><img src="https://habrastorage.org/webt/kb/9d/ug/kb9dugamfx-vq6zltlxju85phze.jpeg" alt="02"></p><br><p>  En la imagen puedes ver dos clases, cuadrados y tri√°ngulos.  Es imposible encontrar la dependencia y dividirla con mayor precisi√≥n por una funci√≥n lineal.  Por lo tanto, con la ayuda del aprendizaje autom√°tico, uno puede elegir una funci√≥n no lineal que distinga mejor entre estos dos conjuntos. </p><br><p>  La tarea de clasificaci√≥n es una tarea de ense√±anza bastante t√≠pica con un maestro.  Para entrenar el modelo, dicho conjunto de datos es necesario para que sea posible distinguir las caracter√≠sticas del objeto y su clase. </p></div></div><br><h3 id="3-pri-chem-tut-kompyuternaya-bezopasnosta-namecomputer-securitya">  3. ¬øQu√© tiene que ver la seguridad inform√°tica con ella? </h3><br><p>  En seguridad inform√°tica, varios m√©todos de aprendizaje autom√°tico se han utilizado durante mucho tiempo en el filtrado de spam, an√°lisis de tr√°fico y detecci√≥n de fraude o malware. </p><br><p>  <strong>Y en cierto sentido, este es un juego en el que, despu√©s de hacer un movimiento, esperas que el enemigo reaccione.</strong>  <strong>Por lo tanto, al jugar a este juego, debes ajustar constantemente los modelos, ense√±ar sobre nuevos datos o cambiarlos por completo, teniendo en cuenta los √∫ltimos logros de la ciencia.</strong> </p><br><p>  Por ejemplo, si bien los antivirus usan an√°lisis de firmas, heur√≠sticas manuales y reglas que son bastante dif√≠ciles de mantener y extender, la industria de la seguridad todav√≠a discute sobre los beneficios reales de los antivirus y muchos consideran que los antivirus son un producto muerto.  Los atacantes eluden todas estas reglas, por ejemplo, con la ayuda de la ofuscaci√≥n y el polimorfismo.  Como resultado, se da preferencia a las herramientas que utilizan t√©cnicas m√°s inteligentes, por ejemplo, m√©todos de aprendizaje autom√°tico que seleccionan autom√°ticamente caracter√≠sticas (incluso aquellas que no son interpretadas por humanos), pueden procesar r√°pidamente grandes cantidades de informaci√≥n, generalizarlas y tomar decisiones r√°pidamente. </p><br><p>  <strong>Es decir, por un lado, el aprendizaje autom√°tico se utiliza como herramienta de protecci√≥n.</strong>  <strong>Por otro lado, esta herramienta tambi√©n se usa para ataques m√°s inteligentes.</strong> </p><br><h3 id="posmotrim-mozhet-li-etot-instrument-byt-uyazvimym">  ¬øVeamos si esta herramienta puede ser vulnerable? </h3><br><p>  Para cualquier algoritmo, no solo la selecci√≥n de par√°metros es muy importante, sino tambi√©n los datos sobre los que se entrena el algoritmo.  Por supuesto, en una situaci√≥n ideal, es necesario que haya suficientes datos para el entrenamiento, las clases deben estar equilibradas y el tiempo para el entrenamiento pasar desapercibido, lo cual es pr√°cticamente imposible en la vida real. </p><br><p>  La calidad de un modelo entrenado generalmente se entiende como la precisi√≥n de la clasificaci√≥n de los datos que el modelo a√∫n no ha "visto", en el caso general, como una cierta proporci√≥n de copias de datos correctamente clasificados a la cantidad total de datos que transmitimos al modelo. </p><br><p>  En general, todas las evaluaciones de calidad est√°n directamente relacionadas con suposiciones sobre la distribuci√≥n esperada de los datos de entrada del sistema y no tienen en cuenta las condiciones ambientales perjudiciales ( <em>entornos adversos</em> ), que a menudo van m√°s all√° de la distribuci√≥n esperada de los datos de entrada.  Un entorno malicioso se entiende como un entorno donde es posible confrontar o interactuar con el sistema.  Ejemplos t√≠picos de tales entornos son aquellos que usan filtros de spam, algoritmos de detecci√≥n de fraude y sistemas de an√°lisis de malware. </p><br><p>  Por lo tanto, la precisi√≥n puede considerarse como una medida del rendimiento promedio del sistema en su uso promedio, mientras que la evaluaci√≥n de seguridad est√° interesada en su peor implementaci√≥n. </p><br><p>  <strong>Es decir, generalmente los modelos de aprendizaje autom√°tico se prueban en un entorno bastante est√°tico donde la precisi√≥n depende de la cantidad de datos para cada clase en particular, pero en realidad no se puede garantizar la misma distribuci√≥n.</strong>  <strong>Y estamos interesados ‚Äã‚Äãen equivocar el modelo.</strong>  <strong>En consecuencia, nuestra tarea es encontrar tantos vectores como sea posible que den el resultado incorrecto.</strong> </p><br><p>  Cuando hablan de la seguridad de un sistema o servicio, generalmente significan que es imposible violar una pol√≠tica de seguridad dentro de un modelo de amenaza dado en hardware o software, tratando de verificar el sistema tanto en la etapa de desarrollo como en la etapa de prueba.  <strong>Pero hoy en d√≠a, una gran cantidad de servicios operan sobre la base de algoritmos de an√°lisis de datos, por lo que los riesgos radican no solo en la funcionalidad vulnerable, sino tambi√©n en los datos en s√≠ mismos, sobre los cuales el sistema puede tomar decisiones.</strong> </p><br><p>  Nadie se queda quieto, y los hackers tambi√©n est√°n dominando algo nuevo.  Y los m√©todos que ayudan a estudiar los algoritmos de aprendizaje autom√°tico para la posibilidad de un compromiso por parte de un atacante que puede usar el conocimiento de c√≥mo funciona el modelo se denominan <em>aprendizaje autom√°tico adversario</em> , o en ruso todav√≠a es <em>aprendizaje autom√°tico malicioso</em> . </p><br><p>  Si hablamos de la seguridad de los modelos de aprendizaje autom√°tico desde el punto de vista de la seguridad de la informaci√≥n, conceptualmente me gustar√≠a considerar varias cuestiones. </p><br><h3 id="4-mozhno-li-manipulirovat-modelyu-mashinnogo-obucheniya-chtoby-provesti-celevuyu-atakua-namemanipultiona">  4. ¬øEs posible manipular el modelo de aprendizaje autom√°tico para realizar un ataque dirigido? </h3><br><p>  Aqu√≠ hay un buen ejemplo con la optimizaci√≥n de motores de b√∫squeda.  Las personas estudian c√≥mo funcionan los algoritmos inteligentes de los motores de b√∫squeda y manipulan los datos en sus sitios para obtener una clasificaci√≥n m√°s alta.  La cuesti√≥n de la seguridad de dicho sistema en este caso no es tan aguda hasta que comprometi√≥ algunos datos o caus√≥ da√±os graves. </p><br><p>  Como ejemplo de dicho sistema, podemos citar servicios que b√°sicamente utilizan la capacitaci√≥n en l√≠nea del modelo, es decir, capacitaci√≥n en la que el modelo recibe datos en un orden secuencial para actualizar los par√°metros actuales.  Al saber c√≥mo se entrena el sistema, puede planificar el ataque y proporcionar al sistema datos previamente preparados. </p><br><p>  Por ejemplo, de esta manera <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se</a> enga√±an <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">los sistemas biom√©tricos, que actualizan gradualmente sus par√°metros a medida que</a> ocurren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">peque√±os cambios en la apariencia de una persona, por ejemplo, con un cambio natural en la edad</a> , que es la funcionalidad absolutamente natural y necesaria del servicio en este caso.  Con esta propiedad del sistema, puede preparar los datos y enviarlos al sistema biom√©trico, actualizando el modelo hasta que actualice los par√°metros a otra persona.  Por lo tanto, el atacante volver√° a entrenar al modelo y podr√° identificarse a s√≠ mismo en lugar de a la v√≠ctima. </p><br><p><img src="https://habrastorage.org/webt/wl/zn/ib/wlznibtbprrotpkl7mp5gbrbf-c.jpeg" alt="03"></p><br><h3 id="5-mozhet-li-zloumyshlennik-podbirat-takie-validnye-dannye-kotorye-vsegda-budut-srabatyvat-nepravilno-chto-privedet-k-uhudsheniyu-proizvoditelnosti-sistemy-v-toy-stepeni-chto-ee-pridetsya-otklyuchita-nameperformancea">  5. ¬øPuede un atacante seleccionar datos v√°lidos que siempre fallar√°n correctamente, lo que conducir√° a un deterioro en el rendimiento del sistema en la medida en que tendr√° que ser desactivado? </h3><br><p>  Este problema surge de manera natural por el hecho de que el modelo de aprendizaje autom√°tico a menudo se prueba en un entorno bastante est√°tico, y su calidad se eval√∫a mediante la distribuci√≥n de datos en los que se entren√≥ el modelo.  Al mismo tiempo, a menudo se plantean preguntas muy espec√≠ficas a especialistas en an√°lisis de datos, que el modelo debe responder: </p><br><ul><li>  ¬øEs el archivo malicioso? </li><li>  ¬øEsta transacci√≥n pertenece al fraude? </li><li>  ¬øEs leg√≠timo el tr√°fico actual? </li></ul><br><p>  Y se espera que el algoritmo no pueda ser 100% exacto, solo puede con cierta probabilidad atribuir el objeto a alguna clase, por lo que debemos encontrar compromisos en el caso de errores del primer y segundo tipo, cuando nuestro algoritmo no puede estar completamente seguro en su elecci√≥n y todav√≠a est√° equivocado. </p><br><p>  Tome un sistema que muy a menudo produce errores del primer y segundo tipo.  Por ejemplo, el antivirus bloque√≥ su archivo porque lo consideraba malicioso (aunque esto no es as√≠), o el antivirus omiti√≥ un archivo que era malicioso.  En este caso, el usuario del sistema lo considera ineficaz y la mayor√≠a de las veces simplemente lo apaga, aunque es probable que se haya capturado un conjunto de dichos datos. </p><br><p>  <strong>Y el conjunto de datos en el que el modelo muestra el peor resultado siempre existe.</strong>  Y la tarea del atacante es buscar dichos datos para que apague el sistema.  Tales situaciones son bastante desagradables y, por supuesto, el modelo deber√≠a evitarlas.  ¬°Y puedes imaginar la magnitud de las consecuencias de las investigaciones de todos los incidentes falsos! </p><br><p>  Los errores del primer tipo se perciben como una p√©rdida de tiempo, mientras que los errores del segundo tipo se perciben como una oportunidad perdida.  Aunque, de hecho, el costo de este tipo de errores para cada sistema espec√≠fico puede ser diferente.  Si un antivirus puede ser m√°s barato, se puede cometer un error del primer tipo, porque es mejor hacerlo de forma segura y decir que el archivo es malicioso, y si el cliente apaga el sistema y el archivo realmente resulta ser malicioso, entonces el antivirus "como se advirti√≥" y la responsabilidad recae en el usuario.  Si tomamos, por ejemplo, un sistema de diagn√≥stico m√©dico, ambos errores ser√°n bastante caros, porque en cualquier caso el paciente corre el riesgo de un tratamiento incorrecto y un riesgo para la salud. </p><br><h3 id="6-mozhet-li-zloumyshlennik-ispolzovat-svoystva-metoda-mashinnogo-obucheniya-chtoby-narushit-rabotu-sistemy-to-est-ne-vmeshivayas-v-process-obucheniya-nayti-takie-ogranicheniya-modeli-kotorye-zavedomo-dayut-nevernye-predskazaniyaa-nameconstraintsa">  6. ¬øPuede un atacante usar las propiedades de un m√©todo de aprendizaje autom√°tico para interrumpir el sistema?  Es decir, sin interferir en el proceso de aprendizaje, encuentre las limitaciones del modelo que obviamente dan predicciones incorrectas. </h3><br><p>  Parecer√≠a que los sistemas de aprendizaje profundo est√°n pr√°cticamente protegidos de la intervenci√≥n humana en la selecci√≥n de signos, por lo que ser√≠a posible decir que no hay un factor humano al tomar decisiones por el modelo.  Todo el encanto del aprendizaje profundo es que es suficiente para alimentar el modelo con datos casi "en bruto", y el modelo en s√≠, a trav√©s de m√∫ltiples transformaciones lineales, destaca las caracter√≠sticas que "considera" m√°s importantes y toma una decisi√≥n.  Sin embargo, ¬øes realmente tan bueno? </p><br><p>  Hay trabajos que describen los m√©todos para preparar tales ejemplos maliciosos en el modelo de aprendizaje profundo, que el sistema clasifica incorrectamente.  Uno de los pocos pero populares ejemplos es un art√≠culo sobre ataques f√≠sicos efectivos en modelos de aprendizaje profundo. </p><br><p>  Los autores realizaron experimentos y propusieron m√©todos para omitir modelos basados ‚Äã‚Äãen la restricci√≥n del aprendizaje profundo que enga√±a al sistema de "visi√≥n", utilizando el ejemplo de reconocimiento de se√±ales de tr√°fico.  Para obtener un resultado positivo, es suficiente que los atacantes encuentren tales √°reas en el objeto que derriben con m√°s fuerza el clasificador, y est√° equivocado.  Los experimentos se llevaron a cabo en la marca "STOP", que, debido a cambios en los investigadores, calific√≥ el modelo como la marca "SPEED LIMIT 45".  Pusieron a prueba su enfoque en otros signos y obtuvieron un resultado positivo. </p><br><p><img src="https://habrastorage.org/webt/b7/3n/zp/b73nzp60lmontpvo7g0phqwy4cu.jpeg" alt="04"></p><br><p>  Como resultado, los autores propusieron dos formas de enga√±ar al sistema de aprendizaje autom√°tico: el ataque de impresi√≥n de carteles, que implica una serie de peque√±os cambios en todo el per√≠metro de la marca llamada camuflaje, y los ataques de adhesivos, cuando se colocaron algunas pegatinas en la marca en ciertas √°reas. </p><br><p>  Pero estas son situaciones de la vida: cuando el letrero est√° en la tierra del polvo de la carretera o cuando los j√≥venes talentos abandonaron su trabajo en √©l.  Es probable que la inteligencia artificial y el arte no tengan lugar en un mundo. </p><br><p><img src="https://habrastorage.org/webt/qm/qq/gv/qmqqgvkbpraxsstagj1mmsp_o_0.jpeg" alt="Shutterstock"></p><br><p>  O <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">investigaciones</a> recientes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sobre ataques dirigidos a sistemas autom√°ticos de reconocimiento de voz</a> .  Los mensajes de voz se han convertido en una tendencia de moda cuando se comunican en las redes sociales, pero escucharlos no siempre es conveniente.  Por lo tanto, hay servicios que le permiten transmitir una grabaci√≥n de audio en texto.  Los autores del trabajo aprendieron a analizar el audio original, tomaron en cuenta la se√±al de sonido y luego aprendieron a crear otra se√±al de sonido, que es 99% similar al original, agregando un peque√±o cambio.  Como resultado, el clasificador descifra el registro como quiere el atacante. </p><br><p><img src="https://habrastorage.org/webt/o-/6v/8t/o-6v8tgin46wuycj45o67waiaho.png" alt="06"></p><br><h3 id="7-v-svyazi-s-etim-mozhno-bylo-by-kategorizirovat-suschestvuyuschie-ataki-neskolkimi-sposobamigooglv2kgp9a-nameattacksa">  7. A este respecto, ser√≠a posible clasificar los ataques existentes de varias <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">maneras</a> : </h3><br><p>  <strong>Por el m√©todo de exposici√≥n (Influencia):</strong> </p><br><ul><li>  Los ataques causales afectan el entrenamiento del modelo a trav√©s de la interferencia en el conjunto de entrenamiento. </li><li>  Los ataques exploratorios usan errores clasificadores sin afectar el conjunto de entrenamiento. </li></ul><br><p>  <strong>Violaci√≥n de seguridad:</strong> </p><br><ul><li>  Los ataques de integridad comprometen el sistema a trav√©s de errores del segundo tipo. </li><li>  Los ataques de disponibilidad provocan un apagado del sistema, generalmente basado en errores del primer tipo. </li></ul><br><p>  <strong>Especificidad:</strong> </p><br><ul><li>  El ataque dirigido (ataque dirigido) tiene como objetivo cambiar la predicci√≥n del clasificador a una clase espec√≠fica. </li><li>  El ataque masivo (ataque indiscriminado) tiene como objetivo cambiar la respuesta del clasificador a cualquier clase, excepto la correcta. </li></ul><br><p>  <strong>El prop√≥sito de la seguridad</strong> es proteger los recursos de un atacante y cumplir con los requisitos, cuyas violaciones conducen a un compromiso parcial o completo de un recurso. </p><br><p>  Se utilizan varios modelos de aprendizaje autom√°tico para la seguridad.  Por ejemplo, los sistemas de detecci√≥n de virus tienen como objetivo reducir la vulnerabilidad a los virus al detectarlos antes de que el sistema se infecte, o detectar uno existente para su eliminaci√≥n.  Otro ejemplo es el sistema de detecci√≥n de intrusos (IDS), que detecta que un sistema ha sido comprometido al detectar tr√°fico malicioso o comportamiento sospechoso en el sistema.  Otra tarea cercana es el sistema de prevenci√≥n de intrusiones (IPS), que detecta los intentos de intrusi√≥n y evita la intrusi√≥n en el sistema. </p><br><p>  En el contexto de los problemas de seguridad, el objetivo de los modelos de aprendizaje autom√°tico es, en el caso general, separar los eventos maliciosos y evitar que interfieran con el sistema. </p><br><p>  En general, el objetivo se puede dividir en dos: <br>  <em>integridad</em> : evitar que un atacante acceda a los recursos del sistema <br>  <em>Accesibilidad</em> : evitar que un atacante interfiera con el funcionamiento normal. </p><br><p>  Existe una conexi√≥n clara entre los errores de segundo tipo y las violaciones de integridad: las instancias maliciosas que pasan al sistema pueden ser da√±inas.  Al igual que los errores del primer tipo generalmente violan la accesibilidad, porque el sistema en s√≠ rechaza copias confiables de los datos. </p><br><h3 id="8-kakie-suschestvuyut-sposoby-zaschity-ot-zloumyshlennikov-manipuliruyuschih-modelyami-mashinnogo-obucheniyaa-namedefencea">  8. ¬øCu√°les son las formas de protegerse contra los ciberdelincuentes que manipulan los modelos de aprendizaje autom√°tico? </h3><br><p>  Por el momento, proteger un modelo de aprendizaje autom√°tico de ataques maliciosos es m√°s dif√≠cil que atacarlo.  Solo porque no importa cu√°nto entrenemos al modelo, siempre habr√° un conjunto de datos en el que funcionar√° peor. <br>  Y hoy no hay formas suficientemente efectivas de hacer que el modelo funcione con una precisi√≥n del 100%.  Pero hay algunos consejos que pueden hacer que el modelo sea m√°s resistente a los ejemplos maliciosos. </p><br><p>  Este es el principal: si es posible no usar modelos de aprendizaje autom√°tico en un entorno malicioso, es mejor no usarlos.  No tiene sentido rechazar el aprendizaje autom√°tico si se enfrenta a la tarea de clasificar im√°genes o generar memes.  Es casi imposible infligir un da√±o significativo que conduzca a consecuencias social o econ√≥micamente significativas en caso de un ataque deliberado.         ,    ,         , , ,        . </p><br><p>        ,      ,      ,     .      . </p><br><p>   ,     ,         .   ,      ,  ,  ,       ,      ,    ,      .  ,   ,     ,   ,       ,     ,      . </p><br><p><img src="https://habrastorage.org/webt/ir/gw/8j/irgw8jzmvbta0vlbqtogwcqbrze.jpeg" alt="imagen"><br> 1 ‚Äî , 2 ‚Äî , 3 ‚Äî   </p><br><p>     , , :      .     .          ,     . </p><br><p>       .         ,      .           ,         .         100%-       - ,            . </p><br><p>    -  ,          ‚Äî   .          ,     ‚Äî    ,    .              ,        . </p><br><p> <strong>     ,       ,       .</strong> </p><br><h3 id="9-kakovy-potencialnye-posledstviya-ispolzovaniya-mashinnogo-obucheniya-s-tochki-zreniya-bezopasnostia-nameconsequencesa"> 9.          ? </h3><br><p>               .                : ,   ,     ,   ,     . </p><br><p>    ,         .         .          ,    .      ,    ,      ,      ¬´¬ª. </p><br><p>   ,   - ,            .    ,       ,    .     -  Twitter,  Microsoft,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . </p><br><p>       ?    ,  ,     ‚Äî  ,    ,     .   ,     ,  ,            ‚Äî  ,       ,    . </p><br><blockquote>  ,   , ,  ¬´  ‚Äî    ,      ¬ª? </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es416691/">https://habr.com/ru/post/es416691/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es416681/index.html">C√≥mo PostgreSQL y ClickHouse en Python mucho, r√°pida e inmediatamente en numpy</a></li>
<li><a href="../es416683/index.html">Que sigue O c√≥mo elegir caracter√≠sticas para el desarrollo</a></li>
<li><a href="../es416685/index.html">Seguimiento de Epson ColorWorks: sus preguntas, nuestras respuestas</a></li>
<li><a href="../es416687/index.html">QSAN Storage como competidor de las marcas Tier 1</a></li>
<li><a href="../es416689/index.html">Acerca de las caracter√≠sticas de la arquitectura de Android a trav√©s de los ojos de un desarrollador que no es Android</a></li>
<li><a href="../es416693/index.html">Certificados de D-Link y Changing Information Technologies utilizados para firmar malware</a></li>
<li><a href="../es416695/index.html">Compatibilidad con vSphere 6.7 y otras funciones de la √∫ltima actualizaci√≥n Veaam Backup & Replication 9.5 3a</a></li>
<li><a href="../es416697/index.html">Fusi√≥n de operadores de telecomunicaciones en 2018</a></li>
<li><a href="../es416699/index.html">Francotirador geek o c√≥mo hacer un "buen ojo"</a></li>
<li><a href="../es416703/index.html">Creando pistas en la nieve en Unreal Engine 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
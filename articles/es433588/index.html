<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚öîÔ∏è üéé üßëüèΩ‚Äçü§ù‚Äçüßëüèª Incre√≠ble rendimiento de algoritmos paralelos C ++ 17. ¬øMito o realidad? üìØ üç≤ üëêüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Buenas tardes 

 Desde nuestro curso "C ++ Developer" le ofrecemos un peque√±o e interesante estudio sobre algoritmos paralelos. 

 Vamos 

 Con la lle...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Incre√≠ble rendimiento de algoritmos paralelos C ++ 17. ¬øMito o realidad?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/433588/">  Buenas tardes <br><br>  Desde nuestro curso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"C ++ Developer" le</a> ofrecemos un peque√±o e interesante estudio sobre algoritmos paralelos. <br><br>  Vamos <br><br>  Con la llegada de los algoritmos paralelos en C ++ 17, puede actualizar f√°cilmente su c√≥digo de "computaci√≥n" y beneficiarse de la ejecuci√≥n paralela.  En este art√≠culo, quiero considerar el algoritmo STL, que naturalmente revela la idea de la inform√°tica independiente.  ¬øPodemos esperar una aceleraci√≥n 10x con un procesador de 10 n√∫cleos?  O tal vez m√°s?  O menos?  Hablemos de eso. <br><br>  <b>Introducci√≥n a los algoritmos paralelos</b> <br><br><img src="https://habrastorage.org/webt/9g/6q/pm/9g6qpm5cnalmrub2fcrgwsuxw0y.png"><a name="habracut"></a><br><br>  C ++ 17 ofrece una configuraci√≥n de pol√≠tica de ejecuci√≥n para la mayor√≠a de los algoritmos: <br><br><ul><li> sequenced_policy - tipo de pol√≠tica de ejecuci√≥n, utilizada como un tipo √∫nico para eliminar la sobrecarga del algoritmo paralelo y el requisito de que la paralelizaci√≥n de la ejecuci√≥n del algoritmo paralelo sea imposible: el objeto global correspondiente es <code>std::execution::seq</code> ; </li><li>  paralelo_pol√≠tica: tipo de pol√≠tica de ejecuci√≥n utilizada como un tipo √∫nico para eliminar la sobrecarga del algoritmo paralelo e indicar que es posible la paralelizaci√≥n de la ejecuci√≥n del algoritmo paralelo: el objeto global correspondiente es <code>std::execution::par</code> ; </li><li>  parallel_unsequenced_policy: un tipo de pol√≠tica de ejecuci√≥n utilizada como un tipo √∫nico para eliminar la sobrecarga del algoritmo paralelo e indicar que la paralelizaci√≥n y la vectorizaci√≥n de la ejecuci√≥n del algoritmo paralelo son posibles: el objeto global correspondiente es <code>std::execution::par_unseq</code> ; </li></ul><br>  Brevemente: <br><br><ul><li>  use <code>std::execution::seq</code> para la ejecuci√≥n secuencial del algoritmo; </li><li>  use <code>std::execution::par</code> execute <code>std::execution::par</code> para ejecutar el algoritmo en paralelo (generalmente usando alguna implementaci√≥n de Thread Pool (grupo de hilos)); </li><li>  use <code>std::execution::par_unseq</code> para la ejecuci√≥n paralela del algoritmo con la capacidad de usar comandos vectoriales (por ejemplo, SSE, AVX). </li></ul><br>  Como ejemplo r√°pido, llame a <code>std::sort</code> en paralelo: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::sort(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::execution::par, myVec.begin(), myVec.end()); <span class="hljs-comment"><span class="hljs-comment">// ^^^^^^^^^^^^^^^^^^^ //  </span></span></code> </pre> <br>  ¬°Tenga en cuenta lo f√°cil que es agregar un par√°metro de ejecuci√≥n paralela al algoritmo!  ¬øPero se lograr√° una mejora significativa en el rendimiento?  ¬øAumentar√° la velocidad?  ¬øO hay alguna desaceleraci√≥n? <br><br>  <b>Paralelo <code>std::transform</code></b> <br><br>  En este art√≠culo, quiero prestar atenci√≥n al algoritmo <code>std::transform</code> , que podr√≠a ser la base de otros m√©todos paralelos (junto con <code>std::transform_reduce</code> , <code>for_each</code> , <code>scan</code> , <code>sort</code> ...). <br><br>  Nuestro c√≥digo de prueba se construir√° de acuerdo con la siguiente plantilla: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform(execution_policy, <span class="hljs-comment"><span class="hljs-comment">// par, seq, par_unseq inVec.begin(), inVec.end(), outVec.begin(), ElementOperation);</span></span></code> </pre> <br>  Suponga que la funci√≥n <code>ElementOperation</code> no tiene m√©todos de sincronizaci√≥n, en cuyo caso el c√≥digo tiene el potencial de ejecuci√≥n paralela o incluso vectorizaci√≥n.  El c√°lculo de cada elemento es independiente, el orden no importa, por lo que una implementaci√≥n puede generar m√∫ltiples hilos (posiblemente en un grupo de hilos) para el procesamiento independiente de elementos. <br><br>  Me gustar√≠a experimentar con las siguientes cosas: <br><br><ul><li>  el tama√±o del campo vectorial es grande o peque√±o; </li><li>  una conversi√≥n simple que pasa la mayor parte del tiempo accediendo a la memoria; </li><li>  m√°s operaciones aritm√©ticas (ALU); </li><li>  ALU en un escenario m√°s realista. </li></ul><br>  Como puede ver, no solo quiero probar la cantidad de elementos que son "buenos" para usar el algoritmo paralelo, sino tambi√©n las operaciones de ALU que ocupan el procesador. <br>  Otros algoritmos, como la clasificaci√≥n, la acumulaci√≥n (en forma de std :: reduce) tambi√©n ofrecen ejecuci√≥n paralela, pero tambi√©n requieren m√°s trabajo para calcular los resultados.  Por lo tanto, los consideraremos candidatos para otro art√≠culo. <br><br>  Nota de referencia <br><br>  Para mis pruebas, uso Visual Studio 2017, 15.8, ya que esta es la √∫nica implementaci√≥n en la implementaci√≥n del compilador popular / STL en este momento (noviembre de 2018) (¬°GCC en camino!).  Adem√°s, me concentr√© solo en <code>execution::par</code> , ya que <code>execution::par_unseq</code> no <code>execution::par_unseq</code> disponible en MSVC (funciona de manera similar a <code>execution::par</code> ). <br><br>  Hay dos computadoras: <br><br><ul><li>  i7 8700 - PC, Windows 10, i7 8700 - 3.2 GHz, 6 n√∫cleos / 12 hilos (Hyperthreading); </li><li>  i7 4720 - Laptop, Windows 10, i7 4720, 2.6 GHz, 4 n√∫cleos / 8 hilos (Hyperthreading). </li></ul><br>  El c√≥digo se compila en x64, publica m√°s, la auto-vectorizaci√≥n est√° habilitada por defecto, tambi√©n inclu√≠ un conjunto extendido de comandos (SSE2) y OpenMP (2.0). <br><br>  El c√≥digo est√° en mi github: <a href="">github / fenbf / ParSTLTests / TransformTests / TransformTests.cpp</a> <br><br>  Para OpenMP (2.0), uso paralelismo solo para bucles: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">pragma</span></span></span><span class="hljs-meta"> omp parallel for for (int i = 0; ...)</span></span></code> </pre> <br>  Ejecuto el c√≥digo 5 veces y miro los resultados m√≠nimos. <br><br>  <i><b>Advertencia</b> : Los resultados reflejan solo observaciones aproximadas; verifique su sistema / configuraci√≥n antes de usarlo en producci√≥n.</i>  <i>Sus requisitos y alrededores pueden diferir de los m√≠os.</i> <br><br>  Puede leer m√°s sobre la implementaci√≥n de MSVC en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esta publicaci√≥n</a> .  Y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠ est√°</a> el √∫ltimo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">informe de</a> Bill O'Neill con CppCon 2018 (Bill implement√≥ Parallel STL en MSVC). <br><br>  Bueno, ¬°comencemos con ejemplos simples! <br><br>  <b>Conversi√≥n simple</b> <br><br>  Considere el caso cuando aplica una operaci√≥n muy simple a un vector de entrada.  Puede ser copia o multiplicaci√≥n de elementos. <br><br>  Por ejemplo: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::execution::par, vec.begin(), vec.end(), out.begin(), [](<span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> v * <span class="hljs-number"><span class="hljs-number">2.0</span></span>; } );</code> </pre><br>  Mi computadora tiene 6 o 4 n√∫cleos ... ¬øpuedo esperar una ejecuci√≥n secuencial 4..6 veces m√°s r√°pida?  Aqu√≠ est√°n mis resultados (tiempo en milisegundos): <br><br><table><tbody><tr><th>  Operaci√≥n </th><th>  Tama√±o del vector </th><th>  i7 4720 (4 n√∫cleos) </th><th>  i7 8700 (6 n√∫cleos) </th></tr><tr><td>  ejecuci√≥n :: seq </td><td>  10k </td><td>  0.002763 </td><td>  0.001924 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  10k </td><td>  0.009869 </td><td>  0.008983 </td></tr><tr><td>  openmp paralelo para </td><td>  10k </td><td>  0.003158 </td><td>  0.002246 </td></tr><tr><td>  ejecuci√≥n :: seq </td><td>  100k </td><td>  0,051318 </td><td>  0,028872 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  100k </td><td>  0.043028 </td><td>  0,025664 </td></tr><tr><td>  openmp paralelo para </td><td>  100k </td><td>  0,022501 </td><td>  0.009624 </td></tr><tr><td>  ejecuci√≥n :: seq </td><td>  1000k </td><td>  1.69508 </td><td>  0.52419 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  1000k </td><td>  1.65561 </td><td>  0.359619 </td></tr><tr><td>  openmp paralelo para </td><td>  1000k </td><td>  1.50678 </td><td>  0.344863 </td></tr></tbody></table><br>  En una m√°quina m√°s r√°pida, podemos ver que tomar√° aproximadamente 1 mill√≥n de elementos para notar una mejora en el rendimiento.  Por otro lado, en mi computadora port√°til todas las implementaciones paralelas fueron m√°s lentas. <br><br>  Por lo tanto, es dif√≠cil notar una mejora significativa en el rendimiento utilizando tales transformaciones, incluso con un aumento en el n√∫mero de elementos. <br><br>  Por qu√© <br><br>  Dado que las operaciones son elementales, los n√∫cleos del procesador pueden llamarlo casi instant√°neamente, usando solo unos pocos ciclos.  Sin embargo, los n√∫cleos de procesador pasan m√°s tiempo esperando la memoria principal.  Entonces, en este caso, en su mayor parte esperar√°n, no har√°n c√°lculos. <br><br>  <i>La lectura y escritura de una variable en la memoria demora aproximadamente 2-3 ciclos si se almacena en cach√© y varios cientos de ciclos si no se almacena en cach√©.</i> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://www.agner.org/optimize/optimizing_cpp.pdf</a> <br><br>  Puede notar aproximadamente que si su algoritmo depende de la memoria, entonces no debe esperar mejoras de rendimiento con la computaci√≥n paralela. <br><br>  <b>M√°s c√°lculos</b> <br><br>  Dado que el ancho de banda de la memoria es crucial y puede afectar la velocidad de las cosas ... aumentemos la cantidad de c√°lculo que afecta a cada elemento. <br><br>  La idea es que es mejor usar ciclos de procesador en lugar de perder el tiempo esperando memoria. <br><br>  Para empezar, uso funciones trigonom√©tricas, por ejemplo, <code>sqrt(sin*cos)</code> (estos son c√°lculos condicionales en forma no √≥ptima, solo para ocupar el procesador). <br><br>  Usamos <code>sqrt</code> , <code>sin</code> y <code>cos</code> , que pueden tomar ~ 20 por <code>sqrt</code> y ~ 100 por funci√≥n trigonom√©trica.  Esta cantidad de c√°lculo puede cubrir el retraso de acceso a la memoria. <br><br>  Para obtener m√°s informaci√≥n sobre los retrasos del equipo, consulte la excelente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gu√≠a de perf de Agner Fogh</a> . <br><br>  Aqu√≠ est√° el c√≥digo de referencia: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::execution::par, vec.begin(), vec.end(), out.begin(), [](<span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">sqrt</span></span>(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">sin</span></span>(v)*<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::<span class="hljs-built_in"><span class="hljs-built_in">cos</span></span>(v)); } );</code> </pre> <br>  ¬øY ahora que?  ¬øPodemos contar con una mejora del rendimiento con respecto al intento anterior? <br><br>  Aqu√≠ hay algunos resultados (tiempo en milisegundos): <br><br><table><tbody><tr><th>  Operaci√≥n </th><th>  Tama√±o del vector </th><th>  i7 4720 (4 n√∫cleos) </th><th>  i7 8700 (6 n√∫cleos) </th></tr><tr><td>  ejecuci√≥n :: seq </td><td>  10k </td><td>  0.105005 </td><td>  0,070577 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  10k </td><td>  0,055661 </td><td>  0,03176 </td></tr><tr><td>  openmp paralelo para </td><td>  10k </td><td>  0.096321 </td><td>  0.024702 </td></tr><tr><td>  ejecuci√≥n :: seq </td><td>  100k </td><td>  1.08755 </td><td>  0.707048 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  100k </td><td>  0.259354 </td><td>  0.17195 </td></tr><tr><td>  openmp paralelo para </td><td>  100k </td><td>  0.898465 </td><td>  0.189915 </td></tr><tr><td>  ejecuci√≥n :: seq </td><td>  1000k </td><td>  10.5159 </td><td>  7.16254 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  1000k </td><td>  2.44472 </td><td>  1.10099 </td></tr><tr><td>  openmp paralelo para </td><td>  1000k </td><td>  4.78681 </td><td>  1.89017 </td></tr></tbody></table><br>  Finalmente, vemos buenos n√∫meros :) <br><br>  Para 1000 elementos (no mostrados aqu√≠), los tiempos de c√°lculo paralelos y secuenciales fueron similares, por lo tanto, para m√°s de 1000 elementos vemos una mejora en la versi√≥n paralela. <br><br>  Para 100 mil elementos, el resultado en una computadora m√°s r√°pida es casi 9 veces mejor que la versi√≥n en serie (de manera similar para la versi√≥n OpenMP). <br><br>  En la versi√≥n m√°s grande de un mill√≥n de elementos, el resultado es 5 u 8 veces m√°s r√°pido. <br>  Para tales c√°lculos, logr√© una aceleraci√≥n "lineal", dependiendo de la cantidad de n√∫cleos de procesador.  Lo cual era de esperarse. <br><br>  <b>Fresnel y vectores tridimensionales</b> <br><br>  En la secci√≥n anterior, utilic√© c√°lculos "inventados", pero ¬øqu√© pasa con el c√≥digo real? <br>  Resolvamos las ecuaciones de Fresnel que describen la reflexi√≥n y la curvatura de la luz desde una superficie lisa y plana.  Este es un m√©todo popular para generar iluminaci√≥n realista en juegos 3D. <br><br><img src="https://habrastorage.org/webt/on/wm/7u/onwm7uw4puyphebsmkehma2jxfa.png"><br><br><img src="https://habrastorage.org/webt/7z/kq/2j/7zkq2jp8qisjnpc6y_gmgvhpupk.jpeg"><br>  <i>Foto de <a href="">Wikimedia</a></i> <br><br>  Como buen ejemplo, encontr√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esta descripci√≥n e implementaci√≥n</a> . <br><br>  <b>Acerca del uso de la biblioteca GLM</b> <br><br>  En lugar de crear mi propia implementaci√≥n, utilic√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la biblioteca glm</a> .  A menudo lo uso en mis proyectos OpenGl. <br><br>  Es f√°cil acceder a la biblioteca a trav√©s del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Administrador de paquetes de Conan</a> , por lo que tambi√©n la usar√©.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a> al paquete. <br><br>  Archivo Conan: <br><br><pre> <code class="bash hljs">[requires] glm/0.9.9.1@g-truc/stable [generators] visual_studio</code> </pre><br>  y la l√≠nea de comando para instalar la biblioteca (genera archivos de accesorios que puedo usar en un proyecto de Visual Studio): <br><br><pre> <code class="bash hljs">conan install . -s build_type=Release -<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> build_release_x64 -s arch=x86_64</code> </pre> <br>  La biblioteca consta de un encabezado, por lo que puede descargarla manualmente si lo desea. <br><br>  <b>C√≥digo real y punto de referencia</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Adapte</a> el c√≥digo para glm de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">scratchapixel.com</a> : <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//    https://www.scratchapixel.com float fresnel(const glm::vec4 &amp;I, const glm::vec4 &amp;N, const float ior) { float cosi = std::clamp(glm::dot(I, N), -1.0f, 1.0f); float etai = 1, etat = ior; if (cosi &gt; 0) { std::swap(etai, etat); } //  sini     float sint = etai / etat * sqrtf(std::max(0.f, 1 - cosi * cosi)); //    if (sint &gt;= 1) return 1.0f; float cost = sqrtf(std::max(0.f, 1 - sint * sint)); cosi = fabsf(cosi); float Rs = ((etat * cosi) - (etai * cost)) / ((etat * cosi) + (etai * cost)); float Rp = ((etai * cosi) - (etat * cost)) / ((etai * cosi) + (etat * cost)); return (Rs * Rs + Rp * Rp) / 2.0f; }</span></span></code> </pre> <br>  El c√≥digo usa varias instrucciones matem√°ticas, producto escalar, multiplicaci√≥n, divisi√≥n, por lo que el procesador tiene algo que hacer.  En lugar del vector doble, usamos un vector de 4 elementos para aumentar la cantidad de memoria utilizada. <br><br>  Benchmark: <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::transform(<span class="hljs-built_in"><span class="hljs-built_in">std</span></span>::execution::par, vec.begin(), vec.end(), vecNormals.begin(), <span class="hljs-comment"><span class="hljs-comment">//   vecFresnelTerms.begin(), //  [](const glm::vec4&amp; v, const glm::vec4&amp; n) { return fresnel(v, n, 1.0f); } );</span></span></code> </pre> <br>  Y aqu√≠ est√°n los resultados (tiempo en milisegundos): <br><br><table><tbody><tr><th>  Operaci√≥n </th><th>  Tama√±o del vector </th><th>  i7 4720 (4 n√∫cleos) </th><th>  i7 8700 (6 n√∫cleos) </th></tr><tr><td>  ejecuci√≥n :: seq </td><td>  1k </td><td>  0,032764 </td><td>  0,016361 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  1k </td><td>  0,031186 </td><td>  0,028551 </td></tr><tr><td>  openmp paralelo para </td><td>  1k </td><td>  0.005526 </td><td>  0.007699 </td></tr><tr><td>  ejecuci√≥n :: seq </td><td>  10k </td><td>  0.246722 </td><td>  0.169383 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  10k </td><td>  0,090794 </td><td>  0.067048 </td></tr><tr><td>  openmp paralelo para </td><td>  10k </td><td>  0,049739 </td><td>  0,029835 </td></tr><tr><td>  ejecuci√≥n :: seq </td><td>  100k </td><td>  2.49722 </td><td>  1.69768 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  100k </td><td>  0.530157 </td><td>  0.283268 </td></tr><tr><td>  openmp paralelo para </td><td>  100k </td><td>  0.495024 </td><td>  0.291609 </td></tr><tr><td>  ejecuci√≥n :: seq </td><td>  1000k </td><td>  25/08/28 </td><td>  16.9457 </td></tr><tr><td>  ejecuci√≥n :: par </td><td>  1000k </td><td>  5.15235 </td><td>  2.33768 </td></tr><tr><td>  openmp paralelo para </td><td>  1000k </td><td>  5.11801 </td><td>  2.95908 </td></tr></tbody></table><br>  Con la computaci√≥n "real", vemos que los algoritmos paralelos proporcionan un buen rendimiento.  Para tales operaciones en mis dos m√°quinas con Windows, logr√© una aceleraci√≥n con una dependencia casi lineal del n√∫mero de n√∫cleos. <br><br>  Para todas las pruebas, tambi√©n mostr√© resultados de OpenMP y dos implementaciones: MSVC y OpenMP funcionan de manera similar. <br><br>  <b>Conclusi√≥n</b> <br><br>  En este art√≠culo, analic√© tres casos de uso de computaci√≥n paralela y algoritmos paralelos.  Reemplazar algoritmos est√°ndar con la versi√≥n std :: execute :: par puede parecer muy tentador, ¬°pero no siempre vale la pena hacerlo!  Cada operaci√≥n que use dentro del algoritmo puede funcionar de manera diferente y depender m√°s del procesador o la memoria.  Por lo tanto, considere cada cambio por separado. <br><br>  Cosas para recordar: <br><br><ul><li>  la ejecuci√≥n paralela, por lo general, hace m√°s que secuencial, ya que la biblioteca debe prepararse para la ejecuci√≥n paralela; </li><li>  no solo es importante la cantidad de elementos, sino tambi√©n la cantidad de instrucciones con las que est√° ocupado el procesador; </li><li>  es mejor tomar tareas que son independientes entre s√≠ y de otros recursos compartidos; </li><li>  Los algoritmos paralelos ofrecen una manera f√°cil de dividir el trabajo en hilos separados; </li><li>  si sus operaciones dependen de la memoria, no debe esperar mejoras de rendimiento y, en algunos casos, los algoritmos pueden ser m√°s lentos; </li><li>  Para obtener una mejora decente en el rendimiento, mida siempre los tiempos de cada problema, en algunos casos los resultados pueden ser completamente diferentes. </li></ul><br>  ¬°Un agradecimiento especial a JFT por ayudarme con este art√≠culo! <br><br>  Tambi√©n preste atenci√≥n a mis otras fuentes sobre algoritmos paralelos: <br><br><ul><li>  Un cap√≠tulo reciente en mi libro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C ++ 17 In Detail</a> sobre Algoritmos Paralelos; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">STL paralelo y sistema de archivos: ejemplo de conteo de palabras de archivos</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ejemplos de algoritmos paralelos de C ++ 17</a> . </li></ul><br>  Eche un vistazo a otro art√≠culo relacionado con Algoritmos paralelos: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">c√≥mo mejorar el rendimiento con Intel Parallel STL y Algoritmos paralelos C ++ 17</a> <br><br>  El fin <br><br>  Estamos esperando comentarios y preguntas que puede dejar aqu√≠ o en nuestro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">maestro</a> en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la puerta abierta</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es433588/">https://habr.com/ru/post/es433588/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es433576/index.html">Gu√≠a del movimiento inform√°tico de San Petersburgo.</a></li>
<li><a href="../es433578/index.html">"Cuando el arte se conecta con la artesan√≠a": editores de medios en l√≠nea sobre tecnolog√≠a, inteligencia artificial y vida</a></li>
<li><a href="../es433580/index.html">Roskomnadzor planea introducir un nuevo sistema de cerraduras por valor de 20 mil millones de rublos</a></li>
<li><a href="../es433582/index.html">¬øQu√© pasa si la participaci√≥n en las ganancias 30/70 deja de ser un est√°ndar de desarrollo de juegos?</a></li>
<li><a href="../es433586/index.html">C√≥mo no ganamos el hackathon</a></li>
<li><a href="../es433592/index.html">Informaci√≥n: Yandex.Phone</a></li>
<li><a href="../es433596/index.html">Error de Magellan: desbordamiento de b√∫fer o expedici√≥n alrededor del mundo usando SQLite FTS</a></li>
<li><a href="../es433598/index.html">C√≥mo LLVM optimiza la funci√≥n</a></li>
<li><a href="../es433600/index.html">Pixel 3 aprende a determinar la profundidad en fotos</a></li>
<li><a href="../es433602/index.html">La simplicidad matem√°tica puede ser la base de la velocidad de la evoluci√≥n.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
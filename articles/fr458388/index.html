<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöû üë®üèø‚Äçüåæ ‚ÑπÔ∏è Analyse approfondie des for√™ts et des articles (apprentissage + al√©atoire) ‚úçüèª üëÅÔ∏è üë®‚Äçüè≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous continuons de parler de la conf√©rence sur les statistiques et l'apprentissage automatique AISTATS 2019. Dans cet article, nous analyserons des ar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analyse approfondie des for√™ts et des articles (apprentissage + al√©atoire)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/458388/"><p>  Nous continuons de parler de la conf√©rence sur les statistiques et l'apprentissage automatique AISTATS 2019. Dans cet article, nous analyserons des articles sur les mod√®les profonds d'ensembles d'arbres, m√©langerons la r√©gularisation pour les donn√©es tr√®s rares et l'approximation efficace du temps de la validation crois√©e. </p><br><p><img src="https://habrastorage.org/webt/n-/uv/xj/n-uvxjud1se0puoearqtlott2de.jpeg"></p><a name="habracut"></a><br><h2 id="algoritm-glubokiy-les-an-exploration-to-non-nn-deep-models-based-on-non-differentiable-modules">  Algorithme de for√™t profonde: une exploration des mod√®les profonds non-NN bas√©s sur des modules non diff√©renciables </h2><br><p>  Zhi-Hua Zhou (Universit√© de Nanjing) <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©sentation</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article</a> <br>  Impl√©mentations - ci-dessous </p><br><p>  Un professeur chinois a parl√© de l'ensemble des arbres, que les auteurs appellent la premi√®re formation approfondie sur des modules non diff√©renciables.  Cela peut sembler une d√©claration trop forte, mais ce professeur et son H-index 95 sont des conf√©renciers invit√©s, ce fait nous permet de prendre la d√©claration plus au s√©rieux.  La th√©orie de base de Deep Forest a √©t√© d√©velopp√©e depuis longtemps, l'article original est d√©j√† 2017 (pr√®s de 200 citations), mais les auteurs √©crivent des biblioth√®ques et chaque ann√©e ils am√©liorent l'algorithme en vitesse.  Et maintenant, semble-t-il, ils ont atteint le point o√π cette belle th√©orie peut enfin √™tre mise en pratique. </p><br><p>  <em>Vue g√©n√©rale de l'architecture Deep Forest</em> <br><img src="https://habrastorage.org/webt/4k/7q/1q/4k7q1qlzs5rixw4itr5luctdpuq.jpeg"></p><br><p>  <strong>Contexte</strong> </p><br><p>  Les mod√®les profonds, qui sont maintenant compris comme des r√©seaux de neurones profonds, sont utilis√©s pour capturer des d√©pendances de donn√©es complexes.  De plus, il s'est av√©r√© que l'augmentation du nombre de couches est plus efficace que l'augmentation du nombre d'unit√©s sur chaque couche.  Mais les r√©seaux de neurones ont leurs inconv√©nients: </p><br><ul><li>  Il faut beaucoup de donn√©es pour ne pas se recycler, </li><li>  Il faut beaucoup de ressources informatiques pour apprendre dans un laps de temps raisonnable, </li><li>  Trop d'hyperparam√®tres difficiles √† configurer de mani√®re optimale </li></ul><br><p>  De plus, les √©l√©ments des r√©seaux de neurones profonds sont des modules diff√©renciables qui ne sont pas n√©cessairement efficaces pour chaque t√¢che.  Malgr√© la complexit√© des r√©seaux de neurones, des algorithmes conceptuellement simples, comme une for√™t al√©atoire, fonctionnent souvent mieux ou pas moins bien.  Mais pour de tels algorithmes, vous devez concevoir manuellement des fonctionnalit√©s, ce qui est √©galement difficile √† faire de mani√®re optimale. </p><br><p>  Les chercheurs ont d√©j√† remarqu√© que les ensembles sur Kaggle: sont ¬´tr√®s parfaits¬ª, et inspir√©s par les mots de Scholl et Hinton que la diff√©renciation est le c√¥t√© le plus faible du Deep Learning, ils ont d√©cid√© de cr√©er un ensemble d'arbres aux propri√©t√©s DL. </p><br><p>  <em>Slide "Comment faire un bon ensemble"</em> <br><img src="https://habrastorage.org/webt/8w/cb/z9/8wcbz9ml-7qidb5ii4-meqcinec.jpeg"></p><br><p>  L'architecture a √©t√© d√©duite des propri√©t√©s des ensembles: les √©l√©ments des ensembles ne devraient pas √™tre de tr√®s mauvaise qualit√© et diff√©rer. </p><br><p>  GcForest se compose de deux phases: Cascade Forest et Multi-Grained Scanning.  De plus, pour que la cascade ne se recycle pas, elle se compose de 2 types d'arbres - dont l'un est des arbres absolument al√©atoires qui peuvent √™tre utilis√©s sur des donn√©es non allou√©es.  Le nombre de couches est d√©termin√© √† l'int√©rieur de l'algorithme de validation crois√©e. <br><img src="https://habrastorage.org/webt/qv/co/-b/qvco-br5vregwj-rrxn3bxnyfeq.jpeg"></p><br><p>  <em>Deux types d'arbres</em> <br><img src="https://habrastorage.org/webt/mc/kp/ia/mckpiaiavjyh9hawcxhvtbusego.jpeg"></p><br><p>  <strong>R√©sultats</strong> </p><br><p>  En plus des r√©sultats sur les ensembles de donn√©es standard, les auteurs ont essay√© d'utiliser gcForest sur les transactions du syst√®me de paiement chinois pour rechercher la fraude et ont obtenu F1 et AUC beaucoup plus √©lev√©s que ceux de LR et DNN.  Ces r√©sultats ne sont que dans la pr√©sentation, mais le code √† ex√©cuter sur certains ensembles de donn√©es standard est sur Git. </p><br><p><img src="https://habrastorage.org/webt/y3/kf/gy/y3kfgytp_qawqyskwmvrrumzdna.jpeg"></p><br><p>  <em>R√©sultats de substitution d'algorithme.</em>  <em>mdDF est la distribution optimale des marges Deep Forest, une variante de gcForest</em> </p><br><p><img src="https://habrastorage.org/webt/e1/oh/wq/e1ohwqrilda60nmdnosaa_ye4yk.jpeg"></p><br><p>  Avantages: </p><br><ul><li>  Peu d'hyperparam√®tres, le nombre de couches est ajust√© automatiquement √† l'int√©rieur de l'algorithme </li><li>  Les param√®tres par d√©faut sont choisis pour bien fonctionner sur de nombreuses t√¢ches. </li><li>  Complexit√© adaptative du mod√®le, sur de petites donn√©es - un petit mod√®le </li><li>  Pas besoin de d√©finir de fonctionnalit√©s </li><li>  Il fonctionne de qualit√© comparable aux r√©seaux de neurones profonds, et parfois mieux </li></ul><br><p>  Inconv√©nients: </p><br><ul><li>  Pas acc√©l√©r√© sur GPU </li><li>  Dans les images perd des DNN </li></ul><br><p>  Les r√©seaux de neurones ont un probl√®me d'att√©nuation du gradient, tandis que la for√™t profonde a un probl√®me de ¬´disparition de la diversit√©¬ª.  Puisqu'il s'agit d'un ensemble, plus il y a d'√©l√©ments ¬´diff√©rents¬ª et ¬´bons¬ª √† utiliser, meilleure est la qualit√©.  Le probl√®me est que les auteurs ont d√©j√† essay√© presque toutes les approches classiques (√©chantillonnage, randomisation).  Tant qu'aucune nouvelle recherche fondamentale n'appara√Ætra sur le th√®me des ¬´diff√©rences¬ª, il sera difficile d'am√©liorer la qualit√© de la for√™t profonde.  Mais maintenant, il est possible d'am√©liorer la vitesse de calcul. </p><br><p>  <strong>Reproductibilit√© des r√©sultats</strong> </p><br><p>  J'ai √©t√© intrigu√© par XGBoost sur les donn√©es tabulaires, et je voulais reproduire le r√©sultat.  J'ai pris le jeu de donn√©es Adultes et appliqu√© GcForestCS (une version l√©g√®rement acc√©l√©r√©e de GcForest) avec les param√®tres des auteurs de l'article et XGBoost avec les param√®tres par d√©faut.  Dans l'exemple que les auteurs avaient, les caract√©ristiques cat√©gorielles √©taient d√©j√† pr√©trait√©es d'une mani√®re ou d'une autre, mais il n'√©tait pas indiqu√© comment.  En cons√©quence, j'ai utilis√© CatBoostEncoder et une autre m√©trique - ROC AUC.  Les r√©sultats √©taient statistiquement diff√©rents - XGBoost a gagn√©.  Le temps de fonctionnement de XGBoost est n√©gligeable, tandis que gcForestCS dispose de 20 minutes de chaque validation crois√©e √† 5 fois.  D'autre part, les auteurs ont test√© l'algorithme sur diff√©rents ensembles de donn√©es et ajust√© les param√®tres de cet ensemble de donn√©es √† leur pr√©traitement d'entit√©s. </p><br><p>  Le code peut √™tre trouv√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </p><br><p>  <strong>Impl√©mentations</strong> </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le code officiel des auteurs de l'article</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Modification officielle am√©lior√©e, plus rapide, mais sans documentation</a> <br>  ‚Üí La <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mise en ≈ìuvre est plus simple</a> </p><br><h2 id="pclasso-the-lasso-meets-principal-components-regression">  PcLasso: le lasso rencontre la r√©gression des principaux composants </h2><br><p>  J. Kenneth Tay, Jerome Friedman, Robert Tibshirani (Universit√© de Stanford) </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pr√©sentation</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Exemple d'utilisation</a> </p><br><p>  D√©but 2019, J.Kenneth Tay, Jerome Friedman et Robert Tibshirani de l'Universit√© de Stanford ont propos√© une nouvelle m√©thode d'enseignement avec un enseignant, particuli√®rement adapt√©e aux donn√©es rares. </p><br><p>  Les auteurs de l'article ont r√©solu le probl√®me de l'analyse des donn√©es sur les √©tudes d'expression g√©nique, qui sont d√©crites dans Zeng &amp; Breesy (2016).  La cible est le statut mutationnel du g√®ne p53, qui r√©gule l'expression des g√®nes en r√©ponse √† divers signaux de stress cellulaire.  Le but de l'√©tude est d'identifier les pr√©dicteurs qui sont en corr√©lation avec le statut mutationnel de p53.  Les donn√©es se composent de 50 lignes, dont 17 sont class√©es comme normales et les 33 autres portent des mutations dans le g√®ne p53.  Selon l'analyse de Subramanian et al.  (2005) 308 ensembles de g√®nes compris entre 15 et 500 sont inclus dans cette analyse.  Ces kits de g√®nes contiennent un total de 4 301 g√®nes et sont disponibles dans le package grpregOverlap R.  Lors de l'expansion des donn√©es pour traiter les groupes qui se chevauchent, 13 237 colonnes sont sorties.  Les auteurs de l'article ont utilis√© la m√©thode pcLasso, qui a permis d'am√©liorer les r√©sultats du mod√®le. </p><br><p>  <em>Dans l'image, nous voyons une augmentation de l'ASC lors de l'utilisation de "pcLasso"</em> <br><img src="https://habrastorage.org/webt/ok/p6/mg/okp6mgex-l9p49vcz5gedg8xa5o.jpeg"></p><br><p>  <strong>L'essence de la m√©thode</strong> </p><br><p>  La m√©thode combine <img src="https://tex.s2cms.ru/svg/l_1" alt="l_1">  -r√©gularisation avec <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  , qui r√©tr√©cit le vecteur de coefficients aux principaux composants de la matrice d'entit√©s.  Ils ont appel√© la m√©thode propos√©e ¬´composants principaux du lasso¬ª (¬´pcLasso¬ª disponible sur R).  La m√©thode peut √™tre particuli√®rement puissante si les variables sont pr√©alablement group√©es (l'utilisateur choisit quoi et comment grouper).  Dans ce cas, pcLasso compresse chaque groupe et obtient la solution en direction des principaux composants de ce groupe.  Dans le processus de r√©solution, la s√©lection des groupes significatifs parmi ceux disponibles est √©galement effectu√©e. </p><br><p>  Nous pr√©sentons la matrice diagonale de la d√©composition singuli√®re d'une matrice centr√©e de traits <img src="https://tex.s2cms.ru/svg/X" alt="X">  comme suit: </p><br><p>  Nous repr√©sentons notre d√©composition singuli√®re de la matrice centr√©e X (SVD) comme <img src="https://tex.s2cms.ru/svg/X%3DUDV%5ET" alt="X = UDV ^ T">  o√π <img src="https://tex.s2cms.ru/svg/D" alt="D">  Est une matrice diagonale compos√©e de valeurs singuli√®res.  Sous cette forme <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  - La r√©gularisation peut √™tre repr√©sent√©e: <br><img src="https://tex.s2cms.ru/svg/%5Cbeta%5ET%20VZV%5ET%20%5Cbeta" alt="\ beta ^ T VZV ^ T \ beta">  o√π <img src="https://tex.s2cms.ru/svg/Z" alt="Z">  - matrice diagonale contenant la fonction des carr√©s de valeurs singuli√®res: <img src="https://tex.s2cms.ru/svg/Z_%7B11%7D%3Df_1%20(d_1%5E2%2Cd_2%5E2%2C%E2%80%A6%2Cd_m%5E2%20)%2C%E2%80%A6%2CZ_%7B22%7D%3Df_2%20(d_1%5E2%2Cd_2%5E2%2C%E2%80%A6%2Cd_m%5E2%20)" alt="Z_ {11} = f_1 (d_1 ^ 2, d_2 ^ 2, ..., d_m ^ 2), ..., Z_ {22} = f_2 (d_1 ^ 2, d_2 ^ 2, ..., d_m ^ 2)">  . </p><br><p>  En g√©n√©ral, dans <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  -r√©gularisation <img src="https://tex.s2cms.ru/svg/Z_%7Bjj%7D%3D1" alt="Z_ {jj} = 1">  pour tous <img src="https://tex.s2cms.ru/svg/j" alt="j">  cela correspond <img src="https://tex.s2cms.ru/svg/%5Cbeta%5ET%20%5Cbeta" alt="\ beta ^ T \ beta">  .  Ils sugg√®rent de minimiser les fonctionnalit√©s suivantes: </p><br><p><img src="https://habrastorage.org/webt/6l/fj/lv/6lfjlv9m-zy8qfhcvrcqcymuuxa.jpeg"></p><br><p>  Ici <img src="https://tex.s2cms.ru/svg/D" alt="D">  - matrice des diff√©rences d'√©l√©ments diagonaux <img src="https://tex.s2cms.ru/svg/d_1%5E2-d_1%5E2%2Cd_1%5E2-d_2%5E2%2C%E2%80%A6%2Cd_1%5E2-d_m%5E2" alt="d_1 ^ 2-d_1 ^ 2, d_1 ^ 2-d_2 ^ 2, ..., d_1 ^ 2-d_m ^ 2">  .  En d'autres termes, nous contr√¥lons le vecteur <img src="https://tex.s2cms.ru/svg/%5Cbeta%20" alt="\ beta">  en utilisant √©galement l'hyperparam√®tre <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ th√™ta">  . <br>  En transformant cette expression, nous obtenons la solution: </p><br><p><img src="https://habrastorage.org/webt/vf/qs/6b/vfqs6b8fnqo3bmlacyr5j4fpigs.jpeg"></p><br><p>  Mais la principale ¬´caract√©ristique¬ª de la m√©thode est, bien s√ªr, la capacit√© de regrouper les donn√©es et, sur la base de ces groupes, de mettre en √©vidence les principales composantes du groupe.  Ensuite, nous r√©√©crivons notre solution sous la forme: </p><br><p><img src="https://habrastorage.org/webt/9l/ij/wc/9lijwc3_kvwtvxalszzyt4zq4l4.jpeg"></p><br><p>  Ici <img src="https://tex.s2cms.ru/svg/%5Cbeta_k" alt="\ beta_k">  - sous-vecteur <img src="https://tex.s2cms.ru/svg/%5Cbeta" alt="\ beta">  correspondant au groupe k, <img src="https://tex.s2cms.ru/svg/d_k%3D(d_%7Bk1%7D%2C%E2%80%A6%2Cd_%7Bkmk%7D)" alt="d_k = (d_ {k1}, ..., d_ {kmk})">  - valeurs singuli√®res <img src="https://tex.s2cms.ru/svg/X_k" alt="X_k">  class√©s par ordre d√©croissant, et <img src="https://tex.s2cms.ru/svg/D_%7Bd_%7Bk1%7D%5E2-d_%7Bkj%7D%5E2%7D" alt="D_ {d_ {k1} ^ 2-d_ {kj} ^ 2}">  - matrice diagonale <img src="https://tex.s2cms.ru/svg/d_%7Bk1%7D%5E2-d_%7Bkj%7D%5E2%2C%20j%3D1%2C2%2C%E2%80%A6%2Cm_k" alt="d_ {k1} ^ 2-d_ {kj} ^ 2, j = 1,2, ..., m_k"></p><br><p>  Quelques notes sur la solution de la fonctionnelle cible: </p><br><ol><li><p>  La fonction objectif est convexe et la composante non lisse est s√©parable.  Par cons√©quent, il peut √™tre efficacement optimis√© en utilisant une descente de gradient. <br>  L'approche consiste √† valider plusieurs valeurs <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ th√™ta">  (y compris z√©ro, respectivement, obtention de la norme <img src="https://tex.s2cms.ru/svg/l_1" alt="l_1">  -r√©gularisation), puis optimiser: <img src="https://habrastorage.org/webt/uz/bf/eo/uzbfeori9kupj8b05x46dcj6iri.jpeg">  ramasser <img src="https://tex.s2cms.ru/svg/%5Clambda" alt="\ lambda">  .  En cons√©quence, les param√®tres <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ th√™ta">  et <img src="https://tex.s2cms.ru/svg/%5Clambda" alt="\ lambda">  sont s√©lectionn√©s pour la validation crois√©e. </p><br></li><li><p>  Param√®tre <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ th√™ta">  difficile √† interpr√©ter.  Dans le logiciel (package pcLasso), l'utilisateur d√©finit lui-m√™me la valeur de ce param√®tre, qui appartient √† l'intervalle [0,1], o√π 1 correspond √† <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ th√™ta">  = 0 (lasso). </p><br></li></ol><br><p>  En pratique, faire varier les valeurs <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ th√™ta">  = 0,25, 0,5, 0,75, 0,9, 0,95 et 1, vous pouvez couvrir une large gamme de mod√®les. </p><br><p>  <em>L'algorithme lui-m√™me est le suivant</em> <br><img src="https://habrastorage.org/webt/l-/3x/si/l-3xsipork2hzeh7ws1bg1hz86o.jpeg"></p><br><p>  Cet algorithme est d√©j√† √©crit en R, si vous le souhaitez, vous pouvez d√©j√† l'utiliser.  La biblioth√®que s'appelle 'pcLasso'. </p><br><h2>  Un couteau suisse infinit√©simal </h2><br><p>  Ryan Giordano (UC Berkeley);  William Stephenson (MIT);  Runjing Liu (UC Berkeley); <br>  Michael Jordan (UC Berkeley);  Tamara Broderick (MIT) </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Code</a> </p><br><p>  La qualit√© des algorithmes d'apprentissage automatique est souvent mesur√©e par plusieurs validations crois√©es (validation crois√©e ou bootstrap).  Ces m√©thodes sont puissantes, mais lentes sur les grands ensembles de donn√©es. </p><br><p>  Dans ce travail, les coll√®gues utilisent une approximation lin√©aire des poids, produisant des r√©sultats qui fonctionnent plus rapidement.  Cette approximation lin√©aire est connue dans la litt√©rature statistique sous le nom de ¬´jackknife infinit√©simal¬ª.  Il est principalement utilis√© comme outil th√©orique pour prouver des r√©sultats asymptotiques.  Les r√©sultats de l'article sont applicables, que les poids et les donn√©es soient stochastiques ou d√©terministes.  Par cons√©quent, cette approximation estime s√©quentiellement la v√©ritable validation crois√©e pour tout k fixe. </p><br><p>  <em>Remise du Paper Award √† l'auteur de l'article</em> <br><img src="https://habrastorage.org/webt/3n/1a/-k/3n1a-kygdmkbs0drfjdg38b9z5g.jpeg"></p><br><p>  <strong>L'essence de la m√©thode</strong> </p><br><p>  Consid√©rez le probl√®me de l'estimation d'un param√®tre inconnu <img src="https://tex.s2cms.ru/svg/%5Ctheta%20%5Cin%20%5COmega_%7B%5Ctheta%7D%20%5Csubset%20R%5E%7BD%7D" alt="\ theta \ in \ Omega _ {\ theta} \ sous-ensemble R ^ {D}">  o√π <img src="https://tex.s2cms.ru/svg/%5COmega_%7B%5Ctheta%7D%20" alt="\ Omega _ {\ theta}">  Est compact et la taille de notre jeu de donn√©es est <img src="https://tex.s2cms.ru/svg/N" alt="N">  .  Notre analyse sera r√©alis√©e sur un ensemble de donn√©es fixes.  D√©finissez notre note <img src="https://tex.s2cms.ru/svg/%5Ctheta%20%5Cin%20%5COmega_%7B%5Ctheta%7D%20" alt="\ theta \ in \ Omega _ {\ theta}">  comme suit: </p><br><ol><li>  Pour chacun <img src="https://tex.s2cms.ru/svg/n%3D1%2C2%E2%80%A6%2CN" alt="n = 1,2 ..., N">  ensemble <img src="https://tex.s2cms.ru/svg/g_n" alt="g_n">  ( <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ th√™ta">  ) Est fonction de <img src="https://tex.s2cms.ru/svg/%5COmega_%7B%5Ctheta%7D%20%5Csubset%20R%5E%7BD%7D" alt="\ Omega _ {\ theta} \ sous-ensemble R ^ {D}"></li><li><img src="https://tex.s2cms.ru/svg/%5Comega_n%20" alt="\ omega_n">  Est un nombre r√©el, et <img src="https://tex.s2cms.ru/svg/%5Comega" alt="\ om√©ga">  Est un vecteur compos√© de <img src="https://tex.s2cms.ru/svg/%5Comega_n" alt="\ omega_n"></li></ol><br><p>  Alors <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D" alt="\ hat {\ theta}">  peut √™tre repr√©sent√© comme: </p><br><p><img src="https://habrastorage.org/webt/zh/ce/yi/zhceyifw80rl6neeoaedkd7x-20.jpeg"></p><br><p>  En r√©solvant ce probl√®me d'optimisation par la m√©thode du gradient, nous supposons que les fonctions sont diff√©renciables et nous pouvons calculer la Hesse.  Le principal probl√®me que nous r√©solvons est le co√ªt de calcul associ√© √† l'√©valuation <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20%CC%82(%5Comega)" alt="\ hat {\ theta} ÃÇ (\ omega)">  pour tous <img src="https://tex.s2cms.ru/svg/%5Comega%E2%88%88W" alt="\ omega‚ààW">  .  La principale contribution des auteurs de l'article consiste √† calculer l'estimation <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1%3D%5Chat%7B%5Ctheta%7D_1%20(1_%7B%5Comega%7D)" alt="\ hat {\ theta} _1 = \ hat {\ theta} _1 (1 _ {\ omega})">  o√π <img src="https://tex.s2cms.ru/svg/1_%5Comega%3D(1%2C1%2C%E2%80%A6%2C1)" alt="1_ \ omega = (1,1, ..., 1)">  .  En d'autres termes, notre optimisation ne d√©pendra que des d√©riv√©s <img src="https://tex.s2cms.ru/svg/g_n%20(%5Ctheta)" alt="g_n (\ th√™ta)">  que nous supposons exister et sont hessois: </p><br><p><img src="https://habrastorage.org/webt/tb/zb/t2/tbzbt2u2q_bdqidfjxfl9ywqesc.jpeg"></p><br><p>  Ensuite, nous d√©finissons une √©quation avec un point fixe et sa d√©riv√©e: <br><img src="https://habrastorage.org/webt/hj/8f/x3/hj8fx3broftye-ssmq4mwpkvaui.jpeg"></p><br><p>  Ici, il convient de faire attention √† ce que <img src="https://tex.s2cms.ru/svg/G(%5Ctheta%20%CC%82(%5Comega)%2Cw)%3D0" alt="G (\ th√™ta ÃÇ (\ omega), w) = 0">  depuis <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20(%5Comega)" alt="\ hat {\ theta} (\ omega)">  - solution pour <img src="https://tex.s2cms.ru/svg/%5Cfrac%7B%201%20%7D%7B%20N%20%7D%20%5Csum_%7Bn%3D1%7D%5E%7BN%7D%20%5Comega_n%20g_n%20(%5Ctheta)%3D0" alt="\ frac {1} {N} \ sum_ {n = 1} ^ {N} \ omega_n g_n (\ theta) = 0">  .  Nous d√©finissons √©galement: <img src="https://tex.s2cms.ru/svg/H_1%3DH(%5Chat%7B%5Ctheta%7D_1%2C1_%5Comega)" alt="H_1 = H (\ hat {\ theta} _1,1_ \ omega)">  , et la matrice de poids comme: <img src="https://tex.s2cms.ru/svg/%5CDelta%5Comega%3D%20%5Comega-1_%5Comega%20%5Cin%20R%5E%7Bn%7D" alt="\ Delta \ omega = \ omega-1_ \ omega \ dans R ^ {n}">  .  Dans le cas o√π <img src="https://tex.s2cms.ru/svg/H_1" alt="H_1">  a une matrice inverse, nous pouvons utiliser le th√©or√®me de fonction implicite et la ¬´r√®gle de cha√Æne¬ª: </p><br><p><img src="https://habrastorage.org/webt/c7/iv/x2/c7ivx2dadeupxwlo2hzgmxslrxe.jpeg"></p><br><p>  Cette d√©riv√©e nous permet de former une approximation lin√©aire <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20%CC%82(%5Comega)" alt="\ hat {\ theta} ÃÇ (\ omega)">  √† travers <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1" alt="\ hat {\ theta} _1">  qui ressemble √† ceci: </p><br><p><img src="https://habrastorage.org/webt/lc/rc/5h/lcrc5hirn1act9jl8lp2jakjpsk.jpeg"></p><br><p>  Depuis <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_%7BIJ%7D" alt="\ hat {\ theta} _ {IJ}">  ne d√©pend que de <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1" alt="\ hat {\ theta} _1">  et <img src="https://tex.s2cms.ru/svg/%5CDelta%20%5Comega" alt="\ Delta \ om√©ga">  , et non √† partir de solutions pour d'autres valeurs <img src="https://tex.s2cms.ru/svg/%5Comega" alt="\ om√©ga">  , en cons√©quence, il n'est pas n√©cessaire de recalculer et de trouver de nouvelles valeurs de œâ.  Au lieu de cela, il faut r√©soudre le SLE (syst√®me d'√©quations lin√©aires). </p><br><p>  <strong>R√©sultats</strong> </p><br><p>  En pratique, cela r√©duit consid√©rablement le temps par rapport √† la validation crois√©e: <br><img src="https://habrastorage.org/webt/sw/dr/6-/swdr6-j8t7pqcdwf_96705qs1tg.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr458388/">https://habr.com/ru/post/fr458388/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr458374/index.html">TJBOT comme illustration des services IBM Watson</a></li>
<li><a href="../fr458376/index.html">Pas un autre langage de programmation. Partie 1: Logique de domaine</a></li>
<li><a href="../fr458378/index.html">Utilisation d'Avocode pour la mise en page du site. Revue pour les d√©butants. Bonus - enregistrez une p√©riode d'essai de 30 jours</a></li>
<li><a href="../fr458382/index.html">Pourquoi enseignons-nous cela?</a></li>
<li><a href="../fr458384/index.html">Examen et test du scanner 3D √† lumi√®re structur√©e Pro S3 HP</a></li>
<li><a href="../fr458390/index.html">Ceph - de ¬´√† genoux¬ª √† ¬´production¬ª partie 2</a></li>
<li><a href="../fr458394/index.html">S√©curisation des protocoles sans fil en utilisant LoRaWAN comme exemple</a></li>
<li><a href="../fr458396/index.html">Comment j'ai rendu le d√©veloppement sur Vue.js pratique avec le rendu c√¥t√© serveur</a></li>
<li><a href="../fr458398/index.html">L'hygi√®ne du travail √† distance ou les avantages de la t√©l√©pathie</a></li>
<li><a href="../fr458400/index.html">Architecture et impl√©mentation des microservices √âtape par √©tape, partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
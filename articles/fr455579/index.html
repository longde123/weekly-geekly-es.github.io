<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ôüèº üë®üèø‚Äçüé® üíí Tupperware: le tueur de Facebook Kubernetes? üëÜüèæ ‚úãüèª üçï</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Gestion efficace et fiable des clusters √† toute √©chelle avec Tupperware 





 Aujourd'hui, lors de la conf√©rence Systems @Scale, nous avons pr√©sent√© ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tupperware: le tueur de Facebook Kubernetes?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/455579/"><p>  Gestion efficace et fiable des clusters √† toute √©chelle avec Tupperware </p><br><p><img src="https://habrastorage.org/webt/gm/mv/jn/gmmvjn5ev7lk2kyhaiejighzrf0.jpeg"></p><br><p>  Aujourd'hui, lors de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la conf√©rence Systems @Scale,</a> nous avons pr√©sent√© Tupperware, notre syst√®me de gestion de cluster qui orchestre les conteneurs sur des millions de serveurs, o√π presque tous nos services fonctionnent.  Nous avons lanc√© Tupperware pour la premi√®re fois en 2011 et depuis, notre infrastructure est pass√©e d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un centre de donn√©es</a> √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">15 centres de donn√©es g√©o-distribu√©s</a> .  Pendant tout ce temps, Tupperware ne s'est pas arr√™t√© et s'est d√©velopp√© avec nous.  Nous vous indiquerons dans quelles situations Tupperware fournit une gestion de cluster de premi√®re classe, y compris une prise en charge pratique des services avec √©tat, un panneau de contr√¥le unique pour tous les centres de donn√©es et la possibilit√© de r√©partir l'alimentation entre les services en temps r√©el.  Et nous partagerons les le√ßons que nous avons apprises lors du d√©veloppement de notre infrastructure. </p><br><p> Tupperware effectue diverses t√¢ches.  Les d√©veloppeurs d'applications l'utilisent pour fournir et g√©rer des applications.  Il emballe le code et les d√©pendances d'application dans une image et le livre aux serveurs sous forme de conteneurs.  Les conteneurs assurent l'isolement entre les applications sur le m√™me serveur afin que les d√©veloppeurs soient occup√©s par la logique d'application et ne r√©fl√©chissent pas √† la fa√ßon de trouver des serveurs ou de contr√¥ler les mises √† jour.  Tupperware surveille √©galement les performances du serveur et s‚Äôil d√©tecte une panne, il transf√®re les conteneurs du serveur probl√©matique. </p><a name="habracut"></a><br><p>  Les ing√©nieurs de planification des capacit√©s utilisent Tupperware pour r√©partir les capacit√©s des serveurs en √©quipes en fonction du budget et des contraintes.  Ils l'utilisent √©galement pour am√©liorer l'utilisation du serveur.  Les op√©rateurs de centres de donn√©es se tournent vers Tupperware pour r√©partir correctement les conteneurs entre les centres de donn√©es et arr√™ter ou d√©placer les conteneurs pendant la maintenance.  Pour cette raison, la maintenance des serveurs, des r√©seaux et des √©quipements n√©cessite une implication humaine minimale. </p><br><h3 id="arhitektura-tupperware">  Architecture Tupperware </h3><br><p> <a href=""><img src="https://habrastorage.org/webt/e7/q1/oz/e7q1ozhv85xlsvgczzofpgwoikg.jpeg"></a> </p><br><p>  <em>Architecture Tupperware PRN est l'une des r√©gions de nos centres de donn√©es.</em>  <em>La r√©gion se compose de plusieurs b√¢timents de centres de donn√©es (PRN1 et PRN2) situ√©s √† proximit√©.</em>  <em>Nous pr√©voyons de cr√©er un panneau de contr√¥le qui g√©rera tous les serveurs dans une r√©gion.</em> </p><br><p>  Les d√©veloppeurs d'applications fournissent des services sous forme de travaux Tupperware.  Une t√¢che se compose de plusieurs conteneurs, et tous ex√©cutent g√©n√©ralement le m√™me code d'application. </p><br><p>  Tupperware est responsable de l'approvisionnement des conteneurs et de la gestion du cycle de vie.  Il se compose de plusieurs composants: </p><br><ul><li>  Le Tupperware Frontend fournit une API pour l'interface utilisateur, la CLI et d'autres outils d'automatisation √† travers lesquels vous pouvez interagir avec Tupperware.  Ils cachent toute la structure interne aux propri√©taires d'emplois Tupperware. </li><li>  Le planificateur Tupperware est le panneau de contr√¥le charg√© de g√©rer le conteneur et le cycle de vie des travaux.  Il est d√©ploy√© aux niveaux r√©gional et mondial, o√π un planificateur r√©gional g√®re les serveurs dans une r√©gion et un planificateur global g√®re les serveurs de diff√©rentes r√©gions.  Le planificateur est divis√© en fragments, et chaque fragment contr√¥le un ensemble de t√¢ches. </li><li>  Le proxy du planificateur dans Tupperware masque le partage interne et fournit un panneau de contr√¥le unifi√© pratique pour les utilisateurs de Tupperware. </li><li>  Le distributeur Tupperware attribue des conteneurs aux serveurs.  Le planificateur est responsable de l'arr√™t, du d√©marrage, de la mise √† jour et de l'√©chec des conteneurs.  Actuellement, un seul distributeur peut g√©rer une r√©gion enti√®re sans se diviser en fragments.  (Notez la diff√©rence de terminologie. Par exemple, le planificateur dans Tupperware correspond au panneau de commande dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kubernetes</a> , et le distributeur Tupperware est appel√© le planificateur dans Kubernetes.) </li><li>  Le courtier de ressources stocke la source de v√©rit√© pour les √©v√©nements de serveur et de service.  Nous ex√©cutons un courtier de ressources pour chaque centre de donn√©es et il stocke toutes les informations du serveur dans ce centre de donn√©es.  Un courtier en ressources et un syst√®me de gestion de capacit√©, ou syst√®me d'allocation de ressources, d√©cident dynamiquement quelle alimentation du planificateur contr√¥le quel serveur.  Le service de v√©rification de l'int√©grit√© surveille les serveurs et stocke des donn√©es sur leur int√©grit√© dans le courtier de ressources.  Si le serveur a des probl√®mes ou a besoin de maintenance, le courtier en ressources demande au distributeur et au planificateur d'arr√™ter les conteneurs ou de les transf√©rer vers d'autres serveurs. </li><li>  Tupperware Agent est un d√©mon ex√©cut√© sur chaque serveur qui pr√©pare et supprime les conteneurs.  Les applications fonctionnent √† l'int√©rieur du conteneur, ce qui leur donne plus d'isolement et de reproductibilit√©.  Lors de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la conf√©rence Systems @Scale de l'ann√©e derni√®re,</a> nous avons d√©j√† d√©crit comment les conteneurs Tupperware individuels sont cr√©√©s √† l'aide d'images, btrfs, cgroupv2 et systemd. </li></ul><br><h3 id="otlichitelnye-osobennosti-tupperware">  Caract√©ristiques distinctives de Tupperware </h3><br><p>  Tupperware est tr√®s similaire √† d'autres syst√®mes de gestion de cluster, tels que Kubernetes et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mesos</a> , mais il existe quelques diff√©rences: </p><br><ul><li>  Prise en charge native des services avec √©tat. </li><li>  Un panneau de contr√¥le unique pour les serveurs de diff√©rents centres de donn√©es pour automatiser la livraison des conteneurs en fonction de l'intention, des clusters de d√©classement et de la maintenance. </li><li>  S√©paration claire du panneau de commande pour le zoom. </li><li>  Des calculs flexibles vous permettent de r√©partir la puissance entre les services en temps r√©el. </li></ul><br><p>  Nous avons con√ßu ces fonctionnalit√©s int√©ressantes pour prendre en charge une vari√©t√© d'applications sans √©tat et avec √©tat dans un immense parc de serveurs partag√©s mondial. </p><br><h3 id="vstroennaya-podderzhka-stateful-sevisov">  Prise en charge native des services avec √©tat. </h3><br><p>  Tupperware g√®re de nombreux services critiques avec √©tat qui stockent des donn√©es de produit persistantes pour Facebook, Instagram, Messenger et WhatsApp.  Il peut s'agir de grandes paires cl√©-valeur (par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ZippyDB</a> ) et de magasins de donn√©es de surveillance (par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ODS Gorilla</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Scuba</a> ).  Il n'est pas facile de maintenir des services avec √©tat, car le syst√®me doit garantir que les livraisons de conteneurs peuvent r√©sister √† des pannes √† grande √©chelle, y compris une panne de courant ou une panne de courant.  Bien que les m√©thodes conventionnelles, telles que la distribution de conteneurs sur plusieurs domaines de d√©faillance, conviennent bien aux services sans √©tat, les services avec √©tat n√©cessitent un support suppl√©mentaire. </p><br><p>  Par exemple, si √† la suite d'une panne de serveur, une r√©plique de la base de donn√©es devient indisponible, est-il n√©cessaire d'autoriser la maintenance automatique qui mettra √† jour les noyaux sur 50 serveurs √† partir d'un pool de 10 milli√®mes?  Cela d√©pend de la situation.  Si sur l'un de ces 50 serveurs il existe une autre r√©plique de la m√™me base de donn√©es, il vaut mieux attendre et ne pas perdre 2 r√©pliques √† la fois.  Afin de prendre des d√©cisions dynamiques concernant la maintenance et l'int√©grit√© du syst√®me, vous avez besoin d'informations sur la r√©plication des donn√©es internes et la logique de localisation de chaque service avec √©tat. </p><br><p>  L'interface TaskControl permet aux services avec √©tat d'influencer les d√©cisions qui affectent la disponibilit√© des donn√©es.  √Ä l'aide de cette interface, le planificateur informe les applications externes des op√©rations de conteneur (red√©marrage, mise √† jour, migration, maintenance).  Le service Stateful impl√©mente un contr√¥leur qui indique √† Tupperware quand chaque op√©ration peut √™tre effectu√©e en toute s√©curit√©, et ces op√©rations peuvent √™tre √©chang√©es ou temporairement retard√©es.  Dans l'exemple ci-dessus, le contr√¥leur de base de donn√©es peut demander √† Tupperware de mettre √† niveau 49 des 50 serveurs, mais ne pas toucher un serveur sp√©cifique (X) jusqu'√† pr√©sent.  Par cons√©quent, si la p√©riode de mise √† jour du noyau passe et que la base de donn√©es ne peut toujours pas restaurer la r√©plique probl√©matique, Tupperware mettra toujours √† niveau le serveur X. </p><br><p> <a href=""><img src="https://habrastorage.org/webt/xu/xi/5q/xuxi5qpox1v3gpc6khbipxgna0i.jpeg"></a> </p><br><p>  De nombreux services avec √©tat dans Tupperware n'utilisent pas TaskControl directement, mais via ShardManager, une plate-forme commune pour cr√©er des services avec √©tat sur Facebook.  Avec Tupperware, les d√©veloppeurs peuvent indiquer leur intention sur la fa√ßon dont les conteneurs doivent √™tre distribu√©s dans les centres de donn√©es.  Avec ShardManager, les d√©veloppeurs indiquent leur intention de r√©partir les fragments de donn√©es entre les conteneurs.  ShardManager est conscient de l'h√©bergement de donn√©es et de la r√©plication de ses applications et interagit avec Tupperware via l'interface TaskControl pour planifier les op√©rations de conteneur sans implication directe de l'application.  Cette int√©gration simplifie consid√©rablement la gestion des services avec √©tat, mais TaskControl est capable de plus.  Par exemple, notre niveau Web √©tendu est sans √©tat et utilise TaskControl pour ajuster dynamiquement la vitesse des mises √† jour dans les conteneurs.  Par cons√©quent, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">niveau Web peut effectuer rapidement plusieurs versions logicielles</a> par jour sans compromettre la disponibilit√©. </p><br><h3 id="upravlenie-serverami-v-datacentrah">  Gestion des serveurs dans les centres de donn√©es </h3><br><p>  Lorsque Tupperware est apparu pour la premi√®re fois en 2011, un planificateur distinct contr√¥lait chaque cluster de serveurs.  Ensuite, le cluster Facebook √©tait un groupe de racks de serveurs connect√©s √† un commutateur r√©seau, et le centre de donn√©es contenait plusieurs clusters.  Le planificateur pouvait g√©rer les serveurs dans un seul cluster, c'est-√†-dire que la t√¢che ne pouvait pas s'√©tendre √† plusieurs clusters.  Notre infrastructure grandissait, nous radions de plus en plus de clusters.  √âtant donn√© que Tupperware n'a pas pu transf√©rer la t√¢che du cluster d√©class√© vers d'autres clusters sans modifications, il a fallu beaucoup d'efforts et une coordination minutieuse entre les d√©veloppeurs d'applications et les op√©rateurs de centres de donn√©es.  Ce processus a entra√Æn√© un gaspillage de ressources lorsque les serveurs ont √©t√© inactifs pendant des mois en raison de la proc√©dure de mise hors service. </p><br><p>  Nous avons cr√©√© un courtier en ressources pour r√©soudre le probl√®me des clusters de d√©classement et coordonner d'autres types de t√¢ches de maintenance.  Le courtier en ressources surveille toutes les informations physiques associ√©es au serveur et d√©cide dynamiquement quel planificateur g√®re chaque serveur.  La liaison dynamique des serveurs aux planificateurs permet au planificateur de g√©rer les serveurs dans diff√©rents centres de donn√©es.  √âtant donn√© que le travail Tupperware n'est plus limit√© √† un seul cluster, les utilisateurs Tupperware peuvent sp√©cifier la fa√ßon dont les conteneurs doivent √™tre r√©partis sur les domaines de d√©faillance.  Par exemple, un d√©veloppeur peut d√©clarer son intention (par exemple: ¬´ex√©cuter ma t√¢che sur 2 domaines de d√©faillance dans la r√©gion PRN¬ª) sans sp√©cifier de zones de disponibilit√© sp√©cifiques.  Tupperware lui-m√™me trouvera les bons serveurs pour concr√©tiser cette intention m√™me dans le cas de la mise hors service d'un cluster ou d'un service. </p><br><h3 id="masshtabirovanie-dlya-podderzhki-vsey-globalnoy-sistemy">  Mise √† l'√©chelle pour prendre en charge l'ensemble du syst√®me mondial </h3><br><p>  Historiquement, notre infrastructure a √©t√© divis√©e en centaines de pools de serveurs d√©di√©s pour les √©quipes individuelles.  En raison de la fragmentation et du manque de normes, nous avions des co√ªts de transaction √©lev√©s et les serveurs inactifs √©taient √† nouveau plus difficiles √† utiliser.  Lors de la conf√©rence <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Systems @Scale de l‚Äô</a> ann√©e derni√®re, nous avons introduit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Infrastructure as a Service (IaaS)</a> , qui devrait int√©grer notre infrastructure dans une grande flotte de serveurs unifi√©s.  Mais une flotte de serveurs unique a ses propres difficult√©s.  Il doit r√©pondre √† certaines exigences: </p><br><ul><li>  <strong>√âvolutivit√©.</strong>  Notre infrastructure s'est d√©velopp√©e avec l'ajout de centres de donn√©es dans chaque r√©gion.  Les serveurs sont devenus plus petits et plus √©conomes en √©nergie, donc dans chaque r√©gion il y en a beaucoup plus.  Par cons√©quent, un seul planificateur pour une r√©gion ne peut pas g√©rer le nombre de conteneurs pouvant √™tre ex√©cut√©s sur des centaines de milliers de serveurs dans chaque r√©gion. </li><li>  <strong>Fiabilit√©</strong>  M√™me si l'√©chelle de l'ordonnanceur peut √™tre ainsi augment√©e, en raison de la grande port√©e de l'ordonnanceur, le risque d'erreurs sera plus √©lev√© et la r√©gion enti√®re du conteneur peut devenir ing√©rable. </li><li>  <strong>Tol√©rance aux pannes.</strong>  En cas de d√©faillance majeure de l'infrastructure (par exemple, en raison d'une panne de r√©seau ou d'une panne de courant, les serveurs sur lesquels le planificateur s'ex√©cute √©choueront), seule une partie des serveurs de la r√©gion aura des cons√©quences n√©gatives. </li><li>  <strong>Facilit√© d'utilisation.</strong>  Il peut sembler que vous devez ex√©cuter plusieurs planificateurs ind√©pendants dans une m√™me r√©gion.  Mais en termes de commodit√©, un point d'entr√©e unique dans un pool commun dans la r√©gion simplifie la gestion des capacit√©s et des t√¢ches. </li></ul><br><p>  Nous avons divis√© le planificateur en fragments pour r√©soudre les probl√®mes de prise en charge d'un grand pool partag√©.  Chaque fragment de planificateur g√®re son ensemble de t√¢ches dans la r√©gion, ce qui r√©duit le risque associ√© au planificateur.  √Ä mesure que le pool total augmente, nous pouvons ajouter plus de fragments de planificateur.  Pour les utilisateurs Tupperware, les fragments et les planificateurs de proxy ressemblent √† un panneau de contr√¥le.  Ils n'ont pas √† travailler avec un tas de fragments qui orchestrent les t√¢ches.  Les fragments du planificateur sont fondamentalement diff√©rents des planificateurs de cluster que nous avons utilis√©s auparavant, lorsque le panneau de contr√¥le √©tait divis√© sans s√©paration statique du pool de serveurs commun selon la topologie du r√©seau. </p><br><h3 id="povyshenie-effektivnosti-ispolzovaniya-s-pomoschyu-elastichnyh-vychisleniy">  Am√©lioration de l'utilisation avec l'informatique √©lastique </h3><br><p>  Plus notre infrastructure est grande, plus il est important d'utiliser efficacement nos serveurs pour optimiser les co√ªts d'infrastructure et r√©duire la charge.  Il existe deux fa√ßons d'am√©liorer l'utilisation du serveur: </p><br><ul><li>  Informatique flexible - r√©duisez l'√©chelle des services en ligne pendant les heures calmes et utilisez les serveurs lib√©r√©s pour les charges hors ligne, par exemple, pour l'apprentissage automatique et les t√¢ches MapReduce. </li><li>  Charge excessive - h√©bergez les services en ligne et les charges de travail par lots sur les m√™mes serveurs afin que les chargements par lots soient ex√©cut√©s avec une faible priorit√©. </li></ul><br><p>  Le goulot d'√©tranglement dans nos centres de donn√©es est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la consommation d'√©nergie</a> .  Par cons√©quent, nous pr√©f√©rons les petits serveurs √©conerg√©tiques qui, ensemble, fournissent plus de puissance de traitement.  Malheureusement, sur les petits serveurs avec une petite quantit√© de ressources processeur et de m√©moire, un chargement excessif est moins efficace.  Bien s√ªr, nous pouvons placer plusieurs conteneurs de petits services sur un petit serveur √©conome en √©nergie qui consomment peu de ressources processeur et de m√©moire, mais les grands services auront de faibles performances dans cette situation.  Par cons√©quent, nous conseillons aux d√©veloppeurs de nos grands services de les optimiser afin qu'ils utilisent l'ensemble du serveur. </p><br><p>  Fondamentalement, nous am√©liorons l'utilisation avec l'informatique √©lastique.  L'intensit√© d'utilisation de bon nombre de nos grands services, par exemple, les flux d'actualit√©s, les fonctionnalit√©s de message et le niveau Web frontal, d√©pend de l'heure de la journ√©e.  Nous r√©duisons intentionnellement l'√©chelle des services en ligne pendant les heures calmes et utilisons les serveurs lib√©r√©s pour les charges hors ligne, par exemple, pour les t√¢ches d'apprentissage automatique et de MapReduce. </p><br><p> <a href=""><img src="https://habrastorage.org/webt/6w/zu/dp/6wzudppzm9tobgoryvtrssaxlra.jpeg"></a> </p><br><p>  Par exp√©rience, nous savons qu'il est pr√©f√©rable de fournir des serveurs entiers en tant qu'unit√©s de puissance √©lastique, car les grands services sont √† la fois les principaux donateurs et les principaux consommateurs d'√©nergie √©lastique, et ils sont optimis√©s pour l'utilisation de serveurs entiers.  Lorsque le serveur est lib√©r√© du service en ligne pendant les heures calmes, le courtier de ressources donne le serveur au planificateur pour une utilisation temporaire afin qu'il ex√©cute des charges hors ligne sur celui-ci.  Si un pic de charge se produit dans un service en ligne, le courtier en ressources rappelle rapidement le serveur pr√™t√© et, avec le planificateur, le renvoie au service en ligne. </p><br><h3 id="usvoennye-uroki-i-plany-na-buduschee">  Le√ßons apprises et plans futurs </h3><br><p>  Au cours des 8 derni√®res ann√©es, nous avons d√©velopp√© Tupperware pour suivre le d√©veloppement rapide de Facebook.  Nous parlons de ce que nous avons appris et esp√©rons que cela aidera les autres √† g√©rer des infrastructures √† croissance rapide: </p><br><ul><li>  Configurez des communications flexibles entre le panneau de contr√¥le et les serveurs qu'il g√®re.  Cette flexibilit√© permet au panneau de contr√¥le de g√©rer les serveurs dans diff√©rents centres de donn√©es, permet d'automatiser le d√©classement et la maintenance des clusters et fournit une distribution dynamique de l'√©nergie √† l'aide d'une informatique flexible. </li><li>  Avec un seul panneau de contr√¥le dans la r√©gion, il devient plus pratique de travailler avec des t√¢ches et plus facile √† g√©rer une grande flotte commune de serveurs.  Veuillez noter que le panneau de commande prend en charge un seul point d'entr√©e, m√™me si sa structure interne est divis√©e pour des raisons d'√©chelle ou de tol√©rance aux pannes. </li><li>  √Ä l'aide du mod√®le de plug-in, le panneau de commande peut notifier les applications externes des op√©rations de conteneur √† venir.  De plus, les services avec √©tat peuvent utiliser l'interface du plugin pour configurer la gestion des conteneurs.  En utilisant ce mod√®le de plug-in, le panneau de commande offre une simplicit√© et sert efficacement de nombreux services avec √©tat diff√©rents. </li><li>  Nous pensons que l'informatique √©lastique, dans laquelle nous prenons des serveurs entiers pour des travaux par lots, l'apprentissage automatique et d'autres services non urgents des services des donateurs, est le meilleur moyen d'augmenter l'efficacit√© de l'utilisation de petits serveurs √©conerg√©tiques. </li></ul><br><p>  Nous commen√ßons tout juste √† mettre en ≈ìuvre un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">parc de serveurs commun mondial unique</a> .  Maintenant, environ 20% de nos serveurs sont dans le pool commun.  Pour atteindre 100%, vous devez r√©soudre de nombreux probl√®mes, notamment la prise en charge d'un pool commun pour les syst√®mes de stockage, l'automatisation de la maintenance, la gestion des exigences de diff√©rents clients, l'am√©lioration de l'utilisation du serveur et l'am√©lioration de la prise en charge des charges de travail d'apprentissage automatique.  Nous avons h√¢te de nous attaquer √† ces t√¢ches et de partager nos succ√®s. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455579/">https://habr.com/ru/post/fr455579/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455565/index.html">L'esprit peut-il truquer l'univers?</a></li>
<li><a href="../fr455569/index.html">Nous vous invitons √† la conf√©rence Tarantool du 17 juin</a></li>
<li><a href="../fr455571/index.html">DB Cursors in Doctrine</a></li>
<li><a href="../fr455575/index.html">Neural Matching: comment adapter le contenu aux r√©alit√©s de Google</a></li>
<li><a href="../fr455577/index.html">Le√ßons SDL 2: Le√ßon 3 - √âv√©nements</a></li>
<li><a href="../fr455580/index.html">Animations d'applications mobiles incontournables</a></li>
<li><a href="../fr455582/index.html">Navigation dans le magasin: de la r√©alit√© augment√©e √† l'√©tag√®re souhait√©e</a></li>
<li><a href="../fr455584/index.html">Entretiens personnalis√©s avec les forces internes de l'entreprise: des erreurs aux d√©couvertes</a></li>
<li><a href="../fr455586/index.html">S√©rie de conf√©rences sur la robotique par le professeur Gregor Sch√∂ner, directeur de l'Institut de neuroinformatique (INI) Bochum, Allemagne</a></li>
<li><a href="../fr455588/index.html">Comment √©duquer votre communaut√© pour ne pas danser avec un tambourin</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
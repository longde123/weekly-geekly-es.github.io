<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë© ‚òéÔ∏è ü•ï Pourquoi ne devriez-vous pas jeter Radeon si vous aimez l'apprentissage automatique? ‚ò¢Ô∏è üë©üèª‚Äçüè≠ ‚ôÄÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="J'ai pu r√©cup√©rer mon poste de travail en tant qu'√©tudiant. Assez logiquement, j'ai pr√©f√©r√© les solutions informatiques AMD. parce que √ßa  pas cher  r...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pourquoi ne devriez-vous pas jeter Radeon si vous aimez l'apprentissage automatique?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420989/"><p><img src="https://habrastorage.org/webt/qk/l2/et/qkl2etw2okgtjnaiuwzytjudazy.jpeg" alt="image"></p><br><p>  J'ai pu r√©cup√©rer mon poste de travail en tant qu'√©tudiant.  Assez logiquement, j'ai pr√©f√©r√© les solutions informatiques AMD.  parce que √ßa <del>  pas cher </del>  rentable en termes de rapport qualit√© / prix.  J'ai ramass√© les composants pendant longtemps, √† la fin je suis entr√© avec 40k avec un ensemble de FX-8320 et RX-460 2GB.  Au d√©but, ce kit semblait parfait!  Mon colocataire et moi avons l√©g√®rement exploit√© Monero et mon set affichait 650h / s contre 550h / s sur un set de i5-85xx et Nvidia 1050Ti.  Certes, de mon ensemble dans la pi√®ce, il faisait un peu chaud la nuit, mais cela a √©t√© d√©cid√© lorsque j'ai achet√© un refroidisseur de tour pour le processeur. </p><a name="habracut"></a><br><h3 id="skazka-konchilas">  L'histoire est finie </h3><br><p>  Tout √©tait exactement comme dans un conte de f√©es jusqu'√† ce que je m'int√©resse √† l'apprentissage automatique dans le domaine de la vision par ordinateur.  Encore plus pr√©cis√©ment - jusqu'√† ce que je devais travailler avec des images d'entr√©e avec une r√©solution de plus de 100x100px (jusqu'√† pr√©sent, mon FX √† 8 c≈ìurs s'est copieusement adapt√©).  La premi√®re difficult√© √©tait la t√¢che de d√©terminer les √©motions.  4 couches ResNet, image d'entr√©e 100x100 et 3000 images dans le jeu de formation.  Et maintenant - 9 heures de formation 150 √©poques sur le CPU. <br>  Bien s√ªr, en raison de ce retard, le processus de d√©veloppement it√©ratif en souffre.  Au travail, nous avions Nvidia 1060 6 Go et nous nous entra√Ænions pour une structure similaire (bien que la r√©gression y ait √©t√© form√©e pour localiser des objets), il volait en 15-20 minutes - 8 secondes pour une √®re d'images de 3,5k.  Lorsque vous avez un tel contraste sous votre nez, la respiration devient encore plus difficile. </p><br><p>  Eh bien, devinez mon premier coup apr√®s tout √ßa?  Oui, je suis all√© n√©gocier 1050Ti avec mon voisin.  Avec des arguments sur l'inutilit√© de CUDA pour lui, avec une offre pour √©changer ma carte contre un suppl√©ment.  Mais en vain.  Et maintenant, je poste mon RX 460 sur Avito et j'examine le 1050Ti ch√©ri sur les sites de Citylink et TechnoPoint.  M√™me en cas de vente r√©ussie de la carte, je devrais trouver 10 000 autres (je suis √©tudiant, bien que professionnel). </p><br><h3 id="guglyu">  Google </h3><br><p>  Ok  Je vais google comment utiliser Radeon sous Tensorflow.  Sachant qu'il s'agissait d'une t√¢che exotique, je n'esp√©rais pas particuli√®rement trouver quoi que ce soit de sens√©.  Collectez sous Ubuntu, qu'il d√©marre ou non, obtenez une brique - phrases arrach√©es sur les forums. </p><br><p>  Et donc je suis all√© dans l'autre sens - je n'ai pas google Tensorflow AMD Radeon, mais Keras AMD Radeon.  Il me renvoie instantan√©ment sur la page de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PlaidML</a> .  Je le <a href="">d√©marre</a> en 15 minutes (m√™me si j'ai d√ª r√©trograder Keras √† 2.0.5) et configurer le r√©seau pour apprendre.  Premi√®re observation - l'√®re est de 35 secondes au lieu de 200. </p><br><h3 id="lezu-issledovat">  Grimpez pour explorer </h3><br><p>  Les auteurs de PlaidML sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vertex.ai</a> , qui fait partie du groupe de projet Intel (!).  L'objectif de d√©veloppement est un maximum multiplateforme.  Bien s√ªr, cela ajoute de la confiance au produit.  Leur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> dit que PlaidML est comp√©titif avec Tensorflow 1.3 + cuDNN 6 en raison d'une "optimisation approfondie". </p><br><p>  Cependant, nous continuons.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'article suivant</a> nous r√©v√®le dans une certaine mesure la structure interne de la biblioth√®que.  La principale diff√©rence avec tous les autres cadres est la g√©n√©ration automatique de noyaux de calcul (dans la notation Tensorflow, le ¬´noyau¬ª est le processus complet d'ex√©cution d'une certaine op√©ration dans un graphique).  Pour la g√©n√©ration automatique de noyau dans PlaidML, les dimensions exactes de tous les tenseurs, constantes, √©tapes, tailles de convolution et valeurs limites avec lesquelles vous devrez travailler plus tard sont tr√®s importantes.  Par exemple, il est avanc√© que la cr√©ation ult√©rieure de noyaux efficaces diff√®re pour les tailles de patch 1 et 32 ‚Äã‚Äãou pour les convolutions 3x3 et 7x7.  Ayant ces donn√©es, le framework lui-m√™me g√©n√©rera le moyen le plus efficace de parall√©liser et d'ex√©cuter toutes les op√©rations pour un appareil particulier avec des caract√©ristiques sp√©cifiques.  Si vous regardez Tensorflow, lorsque vous cr√©ez de nouvelles op√©rations, nous devons √©galement impl√©menter le noyau pour elles - et les impl√©mentations sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tr√®s diff√©rentes</a> pour les noyaux √† un seul thread, √† plusieurs threads ou compatibles CUDA.  C'est-√†-dire  PlaidML est clairement plus flexible. </p><br><p>  Nous allons plus loin.  L'impl√©mentation est √©crite dans le langage auto-√©crit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tile</a> .  Ce langage pr√©sente les principaux avantages suivants - la proximit√© de la syntaxe avec les notations math√©matiques (mais devenez fou!): </p><br><p><img src="https://habrastorage.org/webt/5w/j-/t_/5wj-t_9lnzzlcln4enex-mltn9q.png" alt="image"></p><br><p>  Et diff√©renciation automatique de toutes les op√©rations d√©clar√©es.  Par exemple, dans TensorFlow, lors de la cr√©ation d'une nouvelle op√©ration personnalis√©e, il est fortement recommand√© d'√©crire une fonction pour calculer les d√©grad√©s.  Ainsi, lors de la cr√©ation de nos propres op√©rations dans le langage Tile, nous n'avons qu'√† dire <strong>CE QUE</strong> nous voulons calculer sans penser √† <strong>COMMENT</strong> consid√©rer cela par rapport aux p√©riph√©riques mat√©riels. </p><br><p>  De plus, l'optimisation du travail avec la DRAM et un analogue du cache L1 dans le GPU est effectu√©e.  Rappelez le dispositif sch√©matique: </p><br><p><img src="https://habrastorage.org/webt/sx/kf/hn/sxkfhnnaru91nkmrvbwqesxnsxs.png" alt="image"></p><br><p>  Pour l'optimisation, toutes les donn√©es disponibles sur l'√©quipement sont utilis√©es - taille du cache, largeur de ligne du cache, bande passante DRAM, etc.  Les principales m√©thodes sont la lecture simultan√©e de blocs suffisamment grands √† partir de la DRAM (une tentative pour √©viter l'adressage √† diff√©rentes zones) et la r√©alisation que les donn√©es charg√©es dans le cache sont utilis√©es plusieurs fois (une tentative pour √©viter de recharger les m√™mes donn√©es plusieurs fois). </p><br><p>  Toutes les optimisations ont lieu au cours de la premi√®re p√©riode d'entra√Ænement, tout en augmentant consid√©rablement le temps de la premi√®re manche: </p><br><p><img src="https://habrastorage.org/webt/3e/0v/of/3e0vofsvwm0y5urlztncxdxmurc.jpeg" alt="image"></p><br><p>  De plus, il convient de noter que ce cadre est li√© √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenCL</a> .  Le principal avantage d'OpenCL est qu'il est un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">standard pour les syst√®mes h√©t√©rog√®nes et rien ne vous emp√™che d'ex√©cuter le noyau sur le CPU</a> .  Oui, c'est l√† que r√©side l'un des principaux secrets de la plateforme multiplateforme PlaidML. </p><br><h3 id="zaklyuchenie">  Conclusion </h3><br><p>  Bien s√ªr, la formation sur le RX 460 est encore 5 √† 6 fois plus lente que sur le 1060, mais vous pouvez comparer les cat√©gories de prix des cartes vid√©o!  Ensuite, j'ai eu un RX 580 8 Go (ils m'ont pr√™t√©!) Et le temps qu'il a fallu pour ex√©cuter l'√®re a √©t√© r√©duit √† 20 secondes, ce qui est presque comparable. </p><br><p>  Le blog vertex.ai a des graphiques honn√™tes (plus c'est mieux): </p><br><p><img src="https://habrastorage.org/webt/no/bm/pz/nobmpzbv8-b_6coixtftrmwumrq.png" alt="image"></p><br><p>  On peut voir que PlaidML est comp√©titif avec Tensorflow + CUDA, mais certainement pas plus rapide pour les versions actuelles.  Mais les d√©veloppeurs de PlaidML ne pr√©voient probablement pas d'entrer dans une telle bataille ouverte.  Leur objectif est l'universalit√©, multiplateforme. </p><br><p>  Je vais laisser ici un tableau pas tout √† fait comparatif avec mes mesures de performances: </p><br><table><thead><tr><th>  Appareil informatique </th><th>  Temps d'ex√©cution de l'√®re (lot - 16), s </th></tr></thead><tbody><tr><td>  AMD FX-8320 tf </td><td>  200 </td></tr><tr><td>  RX 460 2GB plaid </td><td>  35 </td></tr><tr><td>  RX 580 8 GB plaid </td><td>  20 </td></tr><tr><td>  1060 6GB TF </td><td>  8 </td></tr><tr><td>  1060 6GB plaid </td><td>  10 </td></tr><tr><td>  Intel i7-2600 tf </td><td>  185 </td></tr><tr><td>  Plaid Intel i7-2600 </td><td>  240 </td></tr><tr><td>  Plaqu√© GT 640 </td><td>  46 </td></tr></tbody></table><br><p>  Le dernier article du blog vertex.ai et les derni√®res modifications apport√©es au r√©f√©rentiel datent de mai 2018.  Il semble que si les d√©veloppeurs de cet outil n'arr√™tent pas de publier de nouvelles versions et que de plus en plus de personnes offens√©es par Nvidia connaissent PlaidML, alors ils parleront beaucoup plus souvent de vertex.ai. </p><br><p>  D√©couvrez vos radeons! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr420989/">https://habr.com/ru/post/fr420989/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr420975/index.html">Ne le faites pas en production</a></li>
<li><a href="../fr420977/index.html">QComboBox + QTreeView Tricks</a></li>
<li><a href="../fr420979/index.html">Redux Basics (manuel, 2e √©dition)</a></li>
<li><a href="../fr420981/index.html">¬´Je peux vous parler de la douleur commune √† tous les d√©veloppeurs iOS¬ª - 10 questions pour le programmeur, num√©ro 2</a></li>
<li><a href="../fr420983/index.html">Les chercheurs disent qu'il est presque impossible de se cacher de l'espionnage de Google</a></li>
<li><a href="../fr420991/index.html">Poursuite</a></li>
<li><a href="../fr420993/index.html">5 √©tapes simples pour cr√©er un serveur pour tester les demandes Android REST</a></li>
<li><a href="../fr420995/index.html">Nous s√©lectionnons le mot de passe pour le TIN indien en deux secondes, ou pourquoi les math√©matiques de force brute</a></li>
<li><a href="../fr420997/index.html">KDD 2018, Day Four, Nobel Laureate Performs</a></li>
<li><a href="../fr420999/index.html">Kivy. Xamarin React Native. Trois cadres - une exp√©rience (partie 2)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
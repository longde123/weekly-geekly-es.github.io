<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôåüèΩ üßîüèº ‚öúÔ∏è Data Lake orient√© client dans une entreprise de jeux üë®üèº‚Äçüé§ üìå üëéüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Source 

 Bonjour, Habr! Je m'appelle Maxim Pchelin et je dirige le d√©veloppement de BI-DWH chez MyGames (division des jeux du groupe Mail.ru). Dans c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Data Lake orient√© client dans une entreprise de jeux</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/479900/"><img src="https://habrastorage.org/webt/ic/em/yw/icemywxszsrmzmrife7stz9ltpg.jpeg"><br>  <a href="https://www.filthymonkeymen.com/2016/06/16/neanderthal-hunting-strategy/">Source</a> <br><br>  Bonjour, Habr!  Je m'appelle Maxim Pchelin et je dirige le d√©veloppement de BI-DWH chez MyGames (division des jeux du groupe Mail.ru).  Dans cet article, je vais vous expliquer comment et pourquoi nous avons cr√©√© un stockage DataLake orient√© client. <br><br>  L'article se compose de trois parties.  Je vais d'abord expliquer pourquoi nous avons d√©cid√© d'impl√©menter DataLake.  Dans la deuxi√®me partie, je d√©crirai quelles technologies et solutions nous utilisons pour que le stockage puisse fonctionner et √™tre rempli de donn√©es.  Et dans la troisi√®me partie, je d√©crirai ce que nous faisons pour am√©liorer la qualit√© de nos services. <br><a name="habracut"></a><br><h1>  Ce qui nous a amen√©s √† DataLake </h1><br>  <a href="https://my.games/">Chez MyGames, nous</a> travaillons dans le d√©partement BI-DWH et proposons des services de deux cat√©gories: un r√©f√©rentiel pour les analystes de donn√©es et des services de reporting r√©guliers pour les utilisateurs professionnels (managers, marketeurs, d√©veloppeurs de jeux, etc.). <br><br><h3>  Pourquoi un tel stockage non standard? </h3><br>  En r√®gle g√©n√©rale, BI-DWH n'implique pas l'impl√©mentation du stockage DataLake; cela ne peut pas √™tre appel√© une solution typique.  Et comment alors ces services sont-ils construits? <br><br>  Habituellement, une entreprise a un projet - dans notre cas, c'est un jeu.  Le projet dispose d'un syst√®me de journalisation qui √©crit le plus souvent des donn√©es dans la base de donn√©es.  En plus de cette base, des vitrines sont cr√©√©es pour les agr√©gats, les m√©triques et d'autres entit√©s pour de futures analyses.  Les rapports r√©guliers sont construits sur la base de vitrines utilisant n'importe quel outil de BI appropri√©, ainsi que des syst√®mes d'analyse ad hoc, commen√ßant par des requ√™tes SQL simples et des tableaux Excel, et se terminant par le Jupyter Notebook pour DS et ML.  L'ensemble du syst√®me est pris en charge par une √©quipe de d√©veloppement. <br><br>  Supposons qu'une autre entreprise naisse dans une entreprise.  Avoir une autre √©quipe de d√©veloppement et une infrastructure sous elle est attrayant, mais co√ªteux.  Ainsi, le projet doit √™tre ¬´branch√©¬ª.  Cela peut √™tre fait de diff√©rentes mani√®res: au niveau de la base de donn√©es, au niveau de la vitrine ou au moins au niveau de l'affichage - le probl√®me est r√©solu. <br><br>  Et si l'entreprise a un troisi√®me projet?  Le ¬´partage¬ª peut d√©j√† mal se terminer: il peut y avoir des probl√®mes d'allocation des ressources ou des droits d'acc√®s.  Par exemple, l'un des projets est r√©alis√© par une √©quipe externe qui n'a pas besoin de conna√Ætre les deux premiers projets.  La situation devient plus risqu√©e. <br><br>  Imaginez maintenant qu'il n'y a pas trois projets, mais bien plus.  Et il se trouve que c'est exactement notre cas. <br><br>  MyGames est l'une des plus grandes divisions du groupe Mail.ru, nous avons 150 projets dans notre portefeuille.  De plus, ils sont tous tr√®s diff√©rents: leur propre d√©veloppement et achet√©s pour des op√©rations en Russie.  Ils fonctionnent sur diff√©rentes plateformes: PC, Xbox, Playstation, iOS et Android.  Ces projets sont d√©velopp√©s dans dix bureaux √† travers le monde avec des centaines de d√©cideurs. <br><br><img src="https://habrastorage.org/webt/6y/33/c5/6y33c5pfbswcdiqeikzuptzbs9k.jpeg"><br><br>  Pour les entreprises, c'est formidable, mais cela complique la t√¢che de l'√©quipe BI-DWH. <br><br>  Dans nos jeux, de nombreuses actions des joueurs sont enregistr√©es: quand il est entr√© dans le jeu, o√π et comment il a atteint les niveaux, avec qui et avec quel succ√®s il s'est battu, quoi et pour quelle devise il a achet√©.  Nous devons collecter toutes ces donn√©es pour chacun des jeux. <br><br>  Nous en avons besoin pour que l'entreprise puisse recevoir des r√©ponses √† ses questions sur les projets.  Que s'est-il pass√© la semaine derni√®re apr√®s le lancement de l'action?  Quelles sont nos pr√©visions de revenus ou d'utilisation des capacit√©s des serveurs de jeux pour le mois prochain?  Que peut-on faire pour influencer ces pr√©visions? <br><br>  Il est important que MyGames n'impose pas de paradigme de d√©veloppement aux projets.  Chaque studio de jeux enregistre les donn√©es car il les consid√®re plus efficaces.  Certains projets g√©n√®rent des journaux c√¥t√© client, d'autres c√¥t√© serveur.  Certains projets utilisent RDBMS pour les collecter, tandis que d'autres utilisent des outils compl√®tement diff√©rents: Kafka, Elasticsearch, Hadoop, Tarantool ou Redis.  Et nous nous tournons vers ces sources pour les donn√©es afin de les t√©l√©charger dans le r√©f√©rentiel. <br><br><h3>  Que voulez-vous de notre BI-DWH? </h3><br>  Tout d'abord, le d√©partement BI-DWH souhaite recevoir des donn√©es sur tous nos jeux pour r√©soudre √† la fois les t√¢ches op√©rationnelles quotidiennes et strat√©giques.  En partant du nombre de vies pour donner un terrible monstre √† la fin du niveau, et en terminant par la fa√ßon de r√©partir correctement les ressources au sein de l'entreprise: quels projets devraient donner plus de d√©veloppeurs ou qui devrait allouer un budget marketing. <br><br>  La fiabilit√© est √©galement attendue de nous.  Nous travaillons dans une grande entreprise et ne pouvons pas vivre selon le principe "Hier, nous avons travaill√©, mais aujourd'hui, le syst√®me est en place, et il ne montera que dans une semaine si nous trouvons quelque chose." <br><br>  Ils veulent des √©conomies de notre part.  Nous serions heureux de r√©soudre tous les probl√®mes en achetant du fer ou en embauchant des gens.  Mais nous sommes une organisation commerciale et nous ne pouvons pas nous le permettre.  Nous essayons de faire profiter l'entreprise. <br><br>  Surtout, ils veulent que nous nous concentrions sur le client.  Les clients dans ce cas sont nos consommateurs, nos clients: managers, analystes, etc. Nous devons nous adapter √† nos jeux et travailler de mani√®re √† ce qu'il soit pratique pour les clients de coop√©rer avec nous.  Par exemple, dans certains cas, lorsque nous achetons des projets sur le march√© asiatique pour des op√©rations, avec le jeu, nous pouvons obtenir des bases avec des noms en chinois.  Et la documentation de ces bases en chinois.  Nous pourrions chercher un d√©veloppeur ETL connaissant le chinois ou refuser de t√©l√©charger des donn√©es sur le jeu, mais √† la place, l'√©quipe et moi nous enfermons dans la salle de r√©union, prenons le chronom√®tre et commen√ßons √† jouer.  Entrez et sortez du jeu, achetez, tirez, mourez.  Et nous regardons ce qui et quand appara√Æt dans tel ou tel tableau.  Ensuite, nous √©crivons la documentation et sur sa base, nous construisons ETL. <br><br>  Dans ce cas, il est important de sentir le bord.  Creuser dans la journalisation unique d'un jeu avec une DAU de 50 personnes, lorsque vous devez aider un projet avec une DAU de 500 000 √† proximit√©, est un luxe inadmissible.  Donc, bien s√ªr, nous pouvons consacrer beaucoup d'efforts √† la cr√©ation d'une solution personnalis√©e, mais uniquement si les entreprises en ont vraiment besoin. <br><br>  Cependant, d√®s que les d√©veloppeurs, en particulier les d√©butants, apprennent qu'ils devront s'adapter de cette mani√®re, ils ont le d√©sir de ne jamais le faire.  Tout d√©veloppeur veut cr√©er une architecture id√©ale, ne jamais la changer et √©crire des articles √† ce sujet sur Habr. <br><br>  Mais que se passe-t-il si nous arr√™tons de nous adapter √† nos jeux?  Supposons que nous commencions √† leur demander d'envoyer des donn√©es √† une seule API d'entr√©e?  Le r√©sultat sera un - tout le monde commencera √† se disperser. <br><br><ul><li>  Certains projets vont commencer √† couper leurs solutions BI-DWH, avec pr√©f√©rence et po√©tesses.  Cela entra√Ænera une duplication des ressources et des difficult√©s dans l'√©change de donn√©es entre les syst√®mes. <br></li><li>  D'autres projets ne tireront pas la cr√©ation de leur BI-DWH, mais ils ne voudront pas non plus s'adapter au n√¥tre.  Et d'autres encore cesseront d'utiliser les donn√©es, ce qui est encore pire. <br></li><li>  Eh bien et surtout, la direction ne disposera pas d'informations syst√©matiques √† jour sur ce qui se passe dans les projets. <br></li></ul><br><h3>  Pourrions-nous impl√©menter le stockage de mani√®re simple? </h3><br>  150 projets, c'est beaucoup.  Mettre en ≈ìuvre la solution imm√©diatement pour tous est trop long.  Les entreprises n'attendront pas un an pour que les premiers r√©sultats apparaissent.  Par cons√©quent, nous avons pris 3 projets qui apportent un revenu maximum et mis en ≈ìuvre le premier prototype pour eux.  Nous voulions en collecter les donn√©es cl√©s et cr√©er des tableaux de bord de base avec les mesures les plus populaires - DAU, MAU, revenus, inscriptions, r√©tention, ainsi qu'un peu d'√©conomie et de pr√©visions. <br><br>  Nous ne pouvions pas utiliser les bases de jeu des projets eux-m√™mes pour cela.  Premi√®rement, cela rendrait l'analyse crois√©e plus difficile en raison de la n√©cessit√© d'agr√©ger les donn√©es de plusieurs bases de donn√©es.  Deuxi√®mement, les jeux eux-m√™mes fonctionnent au-dessus de ces bases de donn√©es, ce qui est important pour que les ma√Ætres et les r√©pliques ne soient pas surcharg√©s.  Enfin, tous les jeux suppriment √† un moment donn√© tout l'historique des donn√©es dont ils n'ont pas besoin dans leurs bases de donn√©es, ce qui est inacceptable pour l'analyse. <br><br>  Par cons√©quent, la seule option est de rassembler tout ce dont vous avez besoin pour l'analyse en un seul endroit.  √Ä ce stade, n'importe quelle base de donn√©es relationnelle ou r√©f√©rentiel de texte brut nous convenait.  Nous visions BI et construisions des tableaux de bord.  Il existe de nombreuses options pour les combinaisons de ces solutions: <br><br><img src="https://habrastorage.org/webt/vx/1e/hm/vx1ehmdjxzv-nimt1x3_ivm3sd8.jpeg"><br><br>  Mais nous avons compris que plus tard, nous devions couvrir tous les 150 autres jeux.  Peut-√™tre qu'une base de donn√©es relationnelle de cluster peut g√©rer la quantit√© de donn√©es g√©n√©r√©es.  Mais les sources ne sont pas seulement situ√©es dans des syst√®mes compl√®tement diff√©rents, mais ont √©galement des structures de donn√©es tr√®s diff√©rentes.  Nous rencontrons des structures relationnelles, Data Vault et autres.  Il ne fonctionnera pas de mettre tout cela dans une seule base de donn√©es sans astuces complexes et laborieuses. <br><br>  Tout cela nous a amen√©s √† comprendre que nous devons construire un DataLake. <br><br><h1>  Impl√©mentation de DataLake </h1><br>  Tout d'abord, le stockage DataLake est adapt√© √† nos conditions, car il nous permet de stocker des donn√©es non structur√©es.  DataLake peut devenir un point d'entr√©e unique pour toutes les sources diverses, des tables du SGBDR au JSON, que nous exp√©dions depuis Kafka ou Mongo.  Par cons√©quent, DataLake peut devenir la base d'analyses de conception crois√©e impl√©ment√©es sur la base d'interfaces pour divers consommateurs: SQL, Python, R, Spark, etc. <br><br><h3>  Passer √† Hadoop </h3><br>  Pour DataLake, nous avons choisi la solution √©vidente - Hadoop.  Plus pr√©cis√©ment, son assemblage de Cloudera.  Hadoop vous permet de travailler avec des donn√©es non structur√©es et est facilement √©volutif en ajoutant des n≈ìuds de donn√©es.  De plus, ce produit a √©t√© bien √©tudi√©, donc la r√©ponse √† toute question peut √™tre trouv√©e sur Stackoverflow, et ne pas d√©penser de ressources en R&amp;D. <br><br>  Apr√®s avoir impl√©ment√© Hadoop, nous avons obtenu le diagramme suivant de notre premier stockage unifi√©: <br><br><img src="https://habrastorage.org/webt/95/fn/2u/95fn2uesgfvlgfqrxdohrfnltsa.jpeg"><br><br>  Les donn√©es ont √©t√© collect√©es dans Hadoop √† partir d'un petit nombre de sources, puis plusieurs interfaces y ont √©t√© oppos√©es: outils et services de BI pour les analyses ad hoc. <br><br>  D'autres √©v√©nements se sont d√©velopp√©s de mani√®re inattendue: notre Hadoop a parfaitement d√©marr√© et les consommateurs pour lesquels les donn√©es ont circul√© dans le magasin ont abandonn√© les anciens syst√®mes analytiques et ont commenc√© √† utiliser le nouveau produit quotidiennement pour leur travail. <br><br>  Mais un probl√®me est survenu: plus vous en faites, plus ils attendent de vous.  Tr√®s rapidement, les projets d√©j√† int√©gr√©s √† Hadoop ont commenc√© √† demander plus de donn√©es.  Et ces projets qui n'ont pas encore √©t√© ajout√©s, ont commenc√© √† le demander.  Les exigences de stabilit√© ont commenc√© √† augmenter fortement. <br><br>  Dans le m√™me temps, il n'est pas raisonnable d'augmenter simplement l'√©quipe de mani√®re lin√©aire.  Si deux d√©veloppeurs DWH font face √† deux projets, alors pour quatre projets, nous ne pouvons pas embaucher deux d√©veloppeurs suppl√©mentaires.  Par cons√©quent, nous sommes d'abord all√©s dans l'autre sens. <br><br><h3>  Etablissement de processus </h3><br>  Avec des ressources limit√©es, la solution la moins ch√®re est de r√©gler les processus.  De plus, dans une grande entreprise, il est impossible de proposer une architecture de stockage et de la mettre en ≈ìuvre.  Je dois n√©gocier avec un grand nombre de personnes. <br><br><ul><li>  Tout d'abord, avec des repr√©sentants commerciaux qui allouent des ressources pour l'analyse.  Vous devrez prouver que vous ne devez mettre en ≈ìuvre que les t√¢ches de vos clients qui b√©n√©ficieront √† l'entreprise. <br></li><li>  Vous devez √©galement n√©gocier avec les analystes afin qu'ils vous donnent quelque chose en √©change des services que vous leur fournissez - analyse du syst√®me, analyse commerciale, tests.  Par exemple, nous avons donn√© l'analyse des syst√®mes de nos sources de donn√©es aux analystes.  Bien s√ªr, ils ne sont pas contents, mais sinon, il n'y aura simplement personne pour le faire. <br></li><li>  Enfin et surtout, vous devez n√©gocier avec les d√©veloppeurs de jeux: installez des SLA et convenez d'une structure de donn√©es.  Si les champs disparaissent, apparaissent et sont renomm√©s en permanence, quelle que soit la taille de l'√©quipe, vos mains vous manqueront toujours. <br></li><li>  Vous devez √©galement n√©gocier avec votre propre √©quipe: rechercher un compromis entre des solutions id√©ales que tous les d√©veloppeurs veulent cr√©er et des solutions standard qui ne sont pas si int√©ressantes, mais qui peuvent √™tre rivet√©es √† moindre co√ªt et rapidement. <br></li><li>  Il faudra convenir avec les administrateurs de la surveillance de l'infrastructure.  Bien que, d√®s que vous disposez de ressources suppl√©mentaires, il est pr√©f√©rable d'engager votre propre sp√©cialiste DevOps dans l'√©quipe de stockage. <br></li></ul><br>  √Ä ce stade, je pourrais terminer l'article si une telle variante du r√©f√©rentiel r√©pondait √† tous les objectifs fix√©s.  Mais ce n'est pas le cas.  Pourquoi? <br><br>  Avant Hadoop, nous pouvions fournir des donn√©es et des statistiques pour cinq projets.  Avec l'impl√©mentation de Hadoop et sans augmentation de l'√©quipe, nous avons pu couvrir 10 projets.  Apr√®s avoir √©tabli les processus, notre √©quipe a d√©j√† servi 15 projets.  C'est cool, mais nous avons 150 projets, nous avions besoin de quelque chose de nouveau. <br><br><h3>  Impl√©mentation du flux d'air </h3><br>  Initialement, nous avons collect√© des donn√©es √† partir de sources utilisant Cron.  Deux projets, c'est normal.  10 - √ßa fait mal, mais ok.  Cependant, environ 12 000 processus sont d√©sormais charg√©s quotidiennement pour le chargement de 150 projets dans DataLake.  Cron n'est plus adapt√©.  Pour ce faire, nous avons besoin d'un outil puissant pour g√©rer les flux de t√©l√©chargement de donn√©es. <br><br>  Nous avons choisi le gestionnaire de t√¢ches open source Airflow.  Il est n√© dans les entrailles d'Airbnb, apr√®s quoi il a √©t√© transf√©r√© √† Apache.  Il s'agit d'un outil pour ETL pilot√© par code.  Autrement dit, vous √©crivez un script en Python, et il est converti en DAG (graphe acyclique dirig√©).  Les DAG sont parfaits pour maintenir les d√©pendances entre les t√¢ches - vous ne pouvez pas cr√©er une vitrine √† l'aide de donn√©es qui n'ont pas encore √©t√© charg√©es. <br><br>  Airflow a un excellent gestionnaire d'erreurs.  Si un processus plante ou s'il y a un probl√®me avec le r√©seau, le r√©partiteur red√©marre le processus le nombre de fois que vous sp√©cifiez.  S'il y a beaucoup d'√©checs, par exemple, la table dans la source a chang√©, alors un message de notification arrive. <br><br>  Airflow a une excellente interface utilisateur: il affiche facilement quels processus sont en cours d'ex√©cution, lesquels se sont termin√©s avec succ√®s ou avec une erreur.  Si les t√¢ches sont tomb√©es avec des erreurs, vous pouvez les red√©marrer √† partir de l'interface et contr√¥ler le processus via la surveillance sans entrer dans le code. <br><br>  Airflow est personnalisable, il est construit au-dessus des op√©rateurs - ce sont des plugins pour travailler avec des sources sp√©cifiques.  Certains op√©rateurs sortent des sentiers battus, beaucoup ont √©crit la communaut√© Airflow.  Si vous le souhaitez, vous pouvez cr√©er votre propre op√©rateur, l'interface pour cela est tr√®s simple. <br><br><h3>  Comment utilisons-nous le flux d'air? </h3><br>  Par exemple, nous devons charger une table de PostgreSQL dans Hadoop.  La t√¢che <code>sql_sensor_battle_log</code> v√©rifie si la source a les donn√©es dont nous avons besoin pour hier.  Si tel est le cas, la t√¢che <code>load_stg_data_from_battle_log</code> les donn√©es de la PG et les ajoute √† Hadoop.  Enfin, <code>load_oda_data_from_battle_log</code> effectue le traitement initial: par exemple, la conversion du temps Unix en temps lisible par l'homme. <br><br>  Dans une telle cha√Æne de t√¢ches, les donn√©es sont extraites d'une entit√© dans une source: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/347/38d/4af/34738d4afc911f105891070f97f90097.png"><br><br>  Et donc - de toutes les entit√©s dont nous avons besoin d'une seule source: <br><br><img src="https://habrastorage.org/webt/bs/2i/ne/bs2ines-6me7a6f677u7rc4wgac.jpeg"><br><br>  Cet ensemble de t√©l√©chargements est le DAG.  Et √† l'heure actuelle, nous avons 250 de ces DAG pour le chargement de donn√©es brutes, le traitement, la transformation et la cr√©ation de vitrines sur celui-ci. <br><br>  Le sch√©ma de stockage unifi√© mis √† jour est le suivant: <br><br><img src="https://habrastorage.org/webt/a4/9m/ag/a49magbaiqyrtasd2awg6mqnjmk.jpeg"><br><br><ol><li>  Apr√®s l'introduction d'Airflow, nous avons pu nous permettre une forte augmentation du nombre de sources - jusqu'√† 400 pi√®ces.  Les sources de donn√©es sont √† la fois internes (de nos jeux) et externes: syst√®mes de statistiques achet√©s, API h√©t√©rog√®nes.  C'est Airflow qui nous permet d'ex√©cuter et de contr√¥ler quotidiennement 12 mille processus qui traitent les donn√©es de tous nos 150 jeux. <br></li><li>  Plus en d√©tail sur notre flux d'air, Dean Safina a √©crit dans son article ( <a href="https://habr.com/ru/company/mailru/blog/344398/">https://habr.com/ru/company/mailru/blog/344398/</a> ).  Et rejoignez √©galement la communaut√© Airflow sur Telegram ( <a href="https://t.me/ruairflow">https://t.me/ruairflow</a> ).  De nombreuses questions sur Airflow peuvent √™tre r√©solues √† l'aide de la documentation, mais parfois des demandes plus personnalis√©es apparaissent: comment puis-je int√©grer Airflow dans Docker, pourquoi ne fonctionne pas le troisi√®me jour et tout cela.  Cela peut √™tre r√©pondu dans cette communaut√©. <br></li></ol><br><h1>  Quoi am√©liorer dans DataLake </h1><br>  √Ä ce stade, les d√©veloppeurs DWH sont convaincus que tout est pr√™t et que vous pouvez maintenant vous calmer.  Malheureusement ou heureusement, il y a encore quelque chose √† resserrer dans DataLake. <br><br><h3>  Qualit√© des donn√©es </h3><br>  Avec un grand nombre de tables dans DataLake, la qualit√© des donn√©es est la premi√®re √† souffrir.  Par exemple, prenez un tableau avec les paiements.  Il contient user_id, montant, date et heure de paiement: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/998/c18/2df/998c182df294a894a55c0c7822eead23.png" width="400"></div><br>  Environ 10 000 paiements sont effectu√©s chaque jour: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b46/115/a01/b46115a0116d11be5373b93fc4d872e8.png" width="400"><br><br>  Une fois dans le tableau de la journ√©e, il n'y a eu que 28 entr√©es.  Oui, et user_id est tout vide: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/606/7c2/d84/6067c2d840a71002e83364d5c0aef2ae.png" width="200"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6b5/055/af6/6b5055af6affe4417834ee051947e57c.png" width="400"></div><br><br>  Si quelque chose se casse soudainement dans notre source, alors, gr√¢ce √† Airflow, nous le saurons imm√©diatement.  Mais s'il y a formellement des donn√©es, et m√™me dans le bon format, alors nous ne sommes pas imm√©diatement inform√©s de la ventilation et d√©j√† des consommateurs de donn√©es.  Il n'est pas r√©aliste de v√©rifier nos 5000 tables de nos propres mains. <br><br>  Pour √©viter cela, nous avons d√©velopp√© notre propre syst√®me de contr√¥le de la qualit√© des donn√©es (DQ).  Chaque jour, il surveille les t√©l√©chargements cl√©s vers notre r√©f√©rentiel: il suit les changements soudains du nombre de lignes, recherche les champs vides et v√©rifie la duplication des donn√©es.  Le syst√®me applique √©galement des v√©rifications personnalis√©es des analystes.  Sur cette base, elle envoie des notifications par courrier √©lectronique sur ce qui s'est mal pass√© et o√π.  Les analystes se rendent sur les projets et d√©couvrent pourquoi, par exemple, il y a trop peu de donn√©es, √©liminons les raisons et nous rechargeons les donn√©es. <br><br><h3>  Prioriser les t√©l√©chargements </h3><br>  Avec le nombre croissant de t√¢ches de chargement de donn√©es dans DataLake, un conflit de priorit√© survient rapidement.  La situation habituelle: certains projets moins importants ont pris toutes les ressources avec leurs t√©l√©chargements la nuit, et les tables n√©cessaires au calcul des m√©triques pour la direction n'ont pas le temps de se charger au d√©but de la journ√©e de travail.  Nous traitons cela de plusieurs mani√®res. <br><br><ul><li>  Surveillance des t√©l√©chargements de cl√©s.  Airflow poss√®de son propre syst√®me SLA, qui vous permet de d√©terminer si toutes les cl√©s sont arriv√©es √† temps.  Si certaines donn√©es ne sont pas charg√©es, nous le saurons quelques heures plus t√¥t que les utilisateurs et aurons le temps de le corriger. <br></li><li>  D√©finition des priorit√©s.  Pour ce faire, nous utilisons la file d'attente Airflow et le syst√®me de priorit√©.  Il nous permet de d√©terminer l'ordre de chargement des DAG et le nombre de processus parall√®les en eux.  Cela n'a aucun sens de t√©l√©charger des journaux qui sont analys√©s une fois par trimestre, avant de t√©l√©charger des donn√©es pour les mesures de gestion sup√©rieure. <br></li></ul><br><h3>  Suivi de la dur√©e du lot de nuit </h3><br>  Nous avons un stockage par lots.  La nuit, nous sommes en train de le construire, et il est important pour nous de nous assurer qu'il y a suffisamment de nuit pour traiter le lot quotidien.  Sinon, pendant les heures de travail, les analystes n'auront pas suffisamment de ressources de stockage pour travailler.  Nous r√©solvons r√©guli√®rement ce probl√®me de plusieurs mani√®res: <br><br><ul><li>  Mise √† l'√©chelle invers√©e.  Nous n'exp√©dions pas toutes les donn√©es, mais seulement ce dont les analystes ont besoin.  Nous surveillons toutes les tables charg√©es, et si l'une d'entre elles n'est pas utilis√©e pendant six mois, nous d√©sactivons son chargement. <br></li><li>  Renforcement des capacit√©s.  Si nous comprenons que nous sommes limit√©s par les capacit√©s du r√©seau, le nombre de c≈ìurs ou la capacit√© du disque, alors nous ajoutons des n≈ìuds de donn√©es √† Hadoop. <br></li><li>  Optimisation du flux d'air des travailleurs.  Nous faisons tout pour que chaque partie de notre syst√®me soit utilis√©e au maximum √† chaque instant de la construction du stockage. <br></li><li>  Refactorisation de processus non optimaux.  Par exemple, nous consid√©rons l'√©conomie d'un nouveau jeu, et cela nous prend 5 minutes.  Mais apr√®s un an, les donn√©es augmentent et la m√™me demande est trait√©e pendant 2 heures.  √Ä un moment donn√©, nous devons nous r√©adapter au recalcul progressif, bien qu'au tout d√©but cela puisse sembler une complication inutile. <br></li></ul><br><h3>  Contr√¥le des ressources </h3><br>  Il est important non seulement d'avoir le temps de terminer la pr√©paration du r√©f√©rentiel pour le d√©but de la journ√©e de travail, mais √©galement de surveiller la disponibilit√© de ses ressources par la suite.  Avec cela, des difficult√©s peuvent survenir avec le temps.  Tout d'abord, la raison en est que les analystes √©crivent des requ√™tes sous-optimales.  Encore une fois, les analystes eux-m√™mes deviennent de plus en plus.  La chose la plus simple dans ce cas: augmenter la capacit√© mat√©rielle.  Cependant, une demande non optimale prendra toujours toutes les ressources disponibles.  Autrement dit, t√¥t ou tard, vous commencerez √† d√©penser de l'argent en fer sans avantage significatif.  Par cons√©quent, nous utilisons plusieurs autres approches. <br><br><ul><li>  Devis: nous laissons aux utilisateurs au moins un peu de ressources.  Oui, les demandes seront ex√©cut√©es lentement, mais au moins elles le seront. <br></li><li>  Surveillance des ressources consomm√©es: combien de c≈ìurs sont utilis√©s par les demandes des utilisateurs, qui ont oubli√© d'utiliser des partitions dans Hadoop et ont pris toute la RAM, etc. lui.  Si nous avions peu de projets, nous suivrions nous-m√™mes la consommation des ressources.  Mais avec un si grand nombre, nous devions embaucher une √©quipe de surveillance distincte en constante expansion.  Et √† long terme, c'est d√©raisonnable. <br></li><li>  Formation des utilisateurs volontaire-obligatoire.  Le travail des analystes n'est pas d'√©crire des requ√™tes de qualit√© dans votre r√©f√©rentiel.  Leur travail consiste √† r√©pondre aux questions des entreprises.  Et √† part nous-m√™mes - l'√©quipe du r√©f√©rentiel - personne ne se soucie de la qualit√© des demandes des analystes.  Par cons√©quent, nous cr√©ons des FAQ et des pr√©sentations, menons des conf√©rences pour nos analystes, expliquons comment nous pouvons travailler avec notre DataLake et comment. <br></li></ul><br>  En fait, passer du temps √† rendre les donn√©es disponibles est beaucoup plus important que de les remplir.  S'il y a des donn√©es dans le stockage, mais qu'elles ne sont pas disponibles, du point de vue commercial, elles sont toujours l√† et vos efforts de t√©l√©chargement ont d√©j√† √©t√© d√©pens√©s. <br><br><h3>  Flexibilit√© de l'architecture </h3><br>  Il est important de ne pas oublier la flexibilit√© du DataLake int√©gr√© et de ne pas avoir peur de changer l'architecture lors de la modification des facteurs d'entr√©e: quelles donn√©es doivent √™tre t√©l√©charg√©es sur le stockage, qui les utilise et comment.  Nous ne pensons pas que notre architecture restera toujours inchang√©e. <br><br>  Par exemple, nous avons lanc√© un nouveau jeu mobile.  Elle √©crit JSON √† Nginx √† partir de clients, Nginx envoie des donn√©es √† Kafka, nous les analysons √† l'aide de Spark et les mettons dans Hadoop.  Tout fonctionne, la t√¢che est close. <br><br><img src="https://habrastorage.org/webt/mj/2i/cq/mj2icqljg45ckemxfjwjp1idafy.jpeg"><br><br>  Quelques mois se sont √©coul√©s et dans le stockage, tous les processus du lot de nuit ont commenc√© √† fonctionner plus longtemps.  Nous commen√ßons √† comprendre quel est le probl√®me: il se trouve que le jeu a ¬´tir√©¬ª, 50 fois plus de donn√©es ont √©t√© g√©n√©r√©es et Spark n'a pas pu faire face √† l'analyse JSON, entra√Ænant la moiti√© des ressources de stockage.  Initialement, toutes les donn√©es ont √©t√© envoy√©es √† un sujet Kafka, et Spark les a tri√©es en diff√©rentes entit√©s.  Nous avons demand√© aux d√©veloppeurs de jeux de partager des donn√©es sur les clients avec diff√©rentes entit√©s et de les verser dans des sujets Kafka distincts.  C'est devenu plus facile, mais pas pour longtemps.  Nous avons ensuite d√©cid√© de passer de l'analyse JSON quotidienne √† l'analyse horaire.  Cependant, l'installation de stockage a commenc√© √† √™tre construite non seulement la nuit, mais 24 heures sur 24, ce qui n'√©tait pas souhaitable pour nous.  Apr√®s de telles tentatives, pour r√©soudre ce probl√®me, nous avons abandonn√© Spark et impl√©ment√© ClickHouse. <br><br><img src="https://habrastorage.org/webt/wv/xw/bo/wvxwbo1pgsxynb8u3lif75uttfw.jpeg"><br><br>  Il dispose d'un excellent moteur d'analyse JSON qui d√©compose instantan√©ment les donn√©es en tableaux.  Nous envoyons d'abord des informations de Kafka √† ClickHouse, puis nous les r√©cup√©rons √† Hadoop.  Cela a compl√®tement r√©solu notre probl√®me. <br><br>  Bien s√ªr, nous essayons de ne pas reproduire les syst√®mes de zoo dans notre stockage DataLake, mais nous essayons de s√©lectionner les technologies les plus appropri√©es pour des t√¢ches sp√©cifiques. <br><br><h1>  Cela en valait-il la peine? </h1><br>  Cela valait-il la peine de d√©ployer Hadoop, un syst√®me de contr√¥le de la qualit√©, de g√©rer Airflow et d'√©tablir des processus commerciaux?  Bien s√ªr, cela valait la peine: <br><br><ul><li>  L'entreprise dispose d'informations √† jour sur tous les projets, disponibles en services uniques. <br></li><li>  Les utilisateurs de notre syst√®me, des concepteurs de jeux aux gestionnaires, ont cess√© de prendre des d√©cisions uniquement sur la base de l'intuition et sont pass√©s √† des approches bas√©es sur les donn√©es. <br></li><li>  Nous avons donn√© aux analystes les outils n√©cessaires pour cr√©er leur propre science des fus√©es.  D√©sormais, ils r√©pondent √† des demandes commerciales complexes, construisent des mod√®les de pr√©vision, des syst√®mes de recommandation, am√©liorent les jeux.  En fait, pour cela, nous travaillons en BI-DWH. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr479900/">https://habr.com/ru/post/fr479900/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr479890/index.html">Probl√®mes et t√¢ches de mise en ≈ìuvre du concept de l'Internet des objets</a></li>
<li><a href="../fr479892/index.html">√Ä propos des plugins Gradle, du multithreading dans les syst√®mes distribu√©s et de l'automatisation de la surveillance: vid√©o de Yandex.Money metap</a></li>
<li><a href="../fr479894/index.html">De Hyper-V √† VMware et vice versa: conversion de disques virtuels</a></li>
<li><a href="../fr479896/index.html">Samedi: R√©flexions d'un programmeur sur l'√©conomie, Marx, L√©nine et le capital</a></li>
<li><a href="../fr479898/index.html">V√©rit√© nue</a></li>
<li><a href="../fr479902/index.html">IntelliJ IDEA 2019.3: optimisation des performances et am√©lioration de la qualit√©</a></li>
<li><a href="../fr479904/index.html">Qu'est-ce que le NFC et comment fonctionne-t-il? Rafra√Æchissez les bases?</a></li>
<li><a href="../fr479906/index.html">Aper√ßu du secteur FinTech: les technologies financi√®res les plus prometteuses de fin 2019</a></li>
<li><a href="../fr479908/index.html">Comment l'AR / VR d'Apple a fait face √† une r√©alit√© brutale</a></li>
<li><a href="../fr479910/index.html">Comment ouvrir un tunnel dans un pod ou un conteneur Kubernetes avec tcpserver et netcat</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
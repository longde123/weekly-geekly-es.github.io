<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚èÆÔ∏è üì¨ üåÉ Reconhecimento r√°pido do Doodle de desenho: Como fazer amigos R, C ++ e redes neurais üò§ ü§≥ üë©‚Äçüåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° Habr! 

 No outono passado, em Kaggle, foi realizado um concurso para a classifica√ß√£o de imagens desenhadas √† m√£o para reconhecimento r√°pido do Do...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reconhecimento r√°pido do Doodle de desenho: Como fazer amigos R, C ++ e redes neurais</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/443758/"><img src="https://habrastorage.org/webt/cp/ir/jc/cpirjcgr-d52s_br1kqmvzkeawm.png"><br><br>  Ol√° Habr! <br><br>  No outono passado, em Kaggle, foi realizado um concurso para a classifica√ß√£o de imagens desenhadas √† m√£o para reconhecimento r√°pido do Doodle, nas quais, entre outros, uma equipe de R-schiks composta por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artem Klevtsov</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Philip Upravitelev</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Andrey Ogurtsov</a> .  N√£o descreveremos a competi√ß√£o em detalhes, isso j√° foi feito em uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publica√ß√£o recente</a> . <br><br>  Desta vez, n√£o havia medalhas na farm√°cia, mas muita experi√™ncia valiosa foi adquirida, ent√£o eu gostaria de contar √† comunidade sobre v√°rias das coisas mais interessantes e √∫teis em Kagl e no trabalho di√°rio.  Entre os t√≥picos abordados: vida dif√≠cil sem o <strong>OpenCV</strong> , an√°lise de JSONs (esses exemplos <strong>mostram a</strong> integra√ß√£o do c√≥digo C ++ em scripts ou pacotes no R usando <strong>Rcpp</strong> ), parametriza√ß√£o de scripts e dockeriza√ß√£o da solu√ß√£o final.  Todo o c√≥digo da mensagem em um formul√°rio adequado para inicializa√ß√£o est√° dispon√≠vel no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reposit√≥rio</a> . <br><br><h3>  Conte√∫do: </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Carregamento eficaz de dados do banco de dados CSV para MonetDB</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Prepara√ß√£o de lotes</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Iteradores para descarregar lotes do banco de dados</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sele√ß√£o da arquitetura do modelo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parametriza√ß√£o de Script</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Scripts de ancoragem</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Usando v√°rias GPUs na nuvem do Google</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Em vez de uma conclus√£o</a> </li></ol><a name="habracut"></a><br><h4 id="section1">  1. Carregamento eficaz de dados do banco de dados CSV para o MonetDB </h4><br><p>  Os dados deste concurso n√£o s√£o fornecidos na forma de imagens prontas, mas na forma de 340 arquivos CSV (um arquivo para cada classe) contendo JSONs com coordenadas de pontos.  Conectando esses pontos com linhas, obtemos a imagem final com um tamanho de 256x256 pixels.  Al√©m disso, para cada registro, √© fornecido um r√≥tulo se a imagem foi reconhecida corretamente pelo classificador usado no momento em que o conjunto de dados foi coletado, o c√≥digo de duas letras do pa√≠s de resid√™ncia do autor, um identificador exclusivo, carimbo de data e hora e nome da classe que corresponde ao nome do arquivo.  Uma vers√£o simplificada dos dados de origem pesa 7,4 GB no arquivo morto e cerca de 20 GB ap√≥s a descompacta√ß√£o, os dados completos ap√≥s a descompacta√ß√£o levam 240 GB.  Os organizadores garantiram que ambas as vers√µes reproduzem os mesmos desenhos, ou seja, a vers√£o completa √© redundante.  De qualquer forma, armazenar 50 milh√µes de imagens em arquivos gr√°ficos ou em matrizes foi imediatamente considerado n√£o lucrativo e decidimos mesclar todos os arquivos CSV do arquivo <em>train_simplified.zip</em> em um banco de dados com a gera√ß√£o subsequente de imagens do tamanho certo em tempo real para cada lote . </p><br><p>  O bem estabelecido <strong>MonetDB</strong> foi escolhido como DBMS, ou seja, a implementa√ß√£o para R na forma do pacote <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MonetDBLite</a></strong> .  O pacote inclui uma vers√£o incorporada do servidor de banco de dados e permite levantar o servidor diretamente da sess√£o R e trabalhar com ele l√°.  A cria√ß√£o de um banco de dados e a conex√£o com ele s√£o executados por um comando: </p><br><pre><code class="plaintext hljs">con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR"))</code> </pre> <br><p>  Precisamos criar duas tabelas: uma para todos os dados e outra para informa√ß√µes de servi√ßo sobre os arquivos baixados (√∫til se algo der errado e o processo precisar ser retomado ap√≥s o download de v√°rios arquivos): </p><br><div class="spoiler">  <b class="spoiler_title">Criar tabelas</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">if (!DBI::dbExistsTable(con, "doodles")) { DBI::dbCreateTable( con = con, name = "doodles", fields = c( "countrycode" = "char(2)", "drawing" = "text", "key_id" = "bigint", "recognized" = "bool", "timestamp" = "timestamp", "word" = "text" ) ) } if (!DBI::dbExistsTable(con, "upload_log")) { DBI::dbCreateTable( con = con, name = "upload_log", fields = c( "id" = "serial", "file_name" = "text UNIQUE", "uploaded" = "bool DEFAULT false" ) ) }</code> </pre> </div></div><br><p>  A maneira mais r√°pida de carregar dados no banco de dados era copiar diretamente arquivos CSV usando SQL - o comando <code>COPY OFFSET 2 INTO tablename FROM path USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT</code> , onde <code>tablename</code> √© o nome da tabela e o <code>path</code> √© o caminho para o arquivo. Mais tarde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">,</a> outra maneira de aumentar a velocidade <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foi descoberta</a> : basta substituir <code>BEST EFFORT</code> por <code>LOCKED BEST EFFORT</code> . Ao trabalhar com o archive, verificou-se que a implementa√ß√£o de <code>unzip</code> no R n√£o funciona corretamente com v√°rios arquivos do archive, por isso usamos <code>unzip</code> sistema (usando o <code>getOption("unzip")</code> ). </p><br><div class="spoiler">  <b class="spoiler_title">Fun√ß√£o para gravar no banco de dados</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#' @title     #' #' @description #'  CSV-  ZIP-       #' #' @param con      ( `MonetDBEmbeddedConnection`). #' @param tablename     . #' @oaram zipfile   ZIP-. #' @oaram filename    ZIP-. #' @param preprocess  ,      . #'     `data` ( `data.table`). #' #' @return `TRUE`. #' upload_file &lt;- function(con, tablename, zipfile, filename, preprocess = NULL) { #   checkmate::assert_class(con, "MonetDBEmbeddedConnection") checkmate::assert_string(tablename) checkmate::assert_string(filename) checkmate::assert_true(DBI::dbExistsTable(con, tablename)) checkmate::assert_file_exists(zipfile, access = "r", extension = "zip") checkmate::assert_function(preprocess, args = c("data"), null.ok = TRUE) #   path &lt;- file.path(tempdir(), filename) unzip(zipfile, files = filename, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) on.exit(unlink(file.path(path))) #    if (!is.null(preprocess)) { .data &lt;- data.table::fread(file = path) .data &lt;- preprocess(data = .data) data.table::fwrite(x = .data, file = path, append = FALSE) rm(.data) } #      CSV sql &lt;- sprintf( "COPY OFFSET 2 INTO %s FROM '%s' USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT", tablename, path ) #     DBI::dbExecute(con, sql) #         DBI::dbExecute(con, sprintf("INSERT INTO upload_log(file_name, uploaded) VALUES('%s', true)", filename)) return(invisible(TRUE)) }</code> </pre> </div></div><br><p>  Caso voc√™ precise converter a tabela antes de gravar no banco de dados, basta passar a fun√ß√£o que converter√° os dados no argumento de <code>preprocess</code> . </p><br><p>  C√≥digo para carregamento sequencial de dados no banco de dados: </p><br><div class="spoiler">  <b class="spoiler_title">Gravando dados no banco de dados</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     files &lt;- unzip(zipfile, list = TRUE)$Name #  ,       to_skip &lt;- DBI::dbGetQuery(con, "SELECT file_name FROM upload_log")[[1L]] files &lt;- setdiff(files, to_skip) if (length(files) &gt; 0L) { #   tictoc::tic() #   pb &lt;- txtProgressBar(min = 0L, max = length(files), style = 3) for (i in seq_along(files)) { upload_file(con = con, tablename = "doodles", zipfile = zipfile, filename = files[i]) setTxtProgressBar(pb, i) } close(pb) #   tictoc::toc() } # 526.141 sec elapsed -  SSD-&gt;SSD # 558.879 sec elapsed -  USB-&gt;SSD</code> </pre> </div></div><br><p>  O tempo de carregamento dos dados pode variar dependendo das caracter√≠sticas de velocidade do inversor usado.  No nosso caso, a leitura e grava√ß√£o no mesmo SSD ou de uma unidade flash USB (arquivo de origem) para um SSD (banco de dados) leva menos de 10 minutos. </p><br><p>  Demora mais alguns segundos para criar uma coluna com um r√≥tulo de classe inteira e uma coluna de √≠ndice ( <code>ORDERED INDEX</code> ) com n√∫meros de linha, que ser√£o usados ‚Äã‚Äãpara selecionar casos ao criar lotes: </p><br><div class="spoiler">  <b class="spoiler_title">Crie colunas e √≠ndices adicionais</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">message("Generate lables") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD label_int int")) invisible(DBI::dbExecute(con, "UPDATE doodles SET label_int = dense_rank() OVER (ORDER BY word) - 1")) message("Generate row numbers") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD id serial")) invisible(DBI::dbExecute(con, "CREATE ORDERED INDEX doodles_id_ord_idx ON doodles(id)"))</code> </pre> </div></div><br><p>  Para resolver o problema de criar um lote "on the fly", precis√°vamos atingir a velocidade m√°xima de extrair seq√º√™ncias aleat√≥rias da tabela de <code>doodles</code> .  Para isso, usamos 3 truques.  O primeiro foi reduzir a dimens√£o do tipo em que o ID da observa√ß√£o est√° armazenado.  No conjunto de dados original, o tipo <code>bigint</code> √© necess√°rio para armazenar o ID, mas o n√∫mero de observa√ß√µes permite ajustar seus identificadores iguais ao n√∫mero de s√©rie no tipo <code>int</code> .  A pesquisa √© muito mais r√°pida.  O segundo truque foi usar o <code>ORDERED INDEX</code> - essa decis√£o foi tomada empiricamente, classificando todas as <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">op√ß√µes</a> dispon√≠veis.  O terceiro era usar consultas parametrizadas.  A ess√™ncia do m√©todo √© executar o comando <code>PREPARE</code> uma vez e, em seguida, usar a express√£o preparada ao criar uma pilha do mesmo tipo de consultas, mas, na realidade, o ganho comparado ao <code>SELECT</code> simples <code>SELECT</code> na √°rea de erro estat√≠stico. </p><br><p>  O processo de preenchimento de dados consome no m√°ximo 450 MB de RAM.  Ou seja, a abordagem descrita permite que voc√™ gire conjuntos de dados com peso de dezenas de gigabytes em quase todos os hardwares econ√¥micos, incluindo alguns computadores de placa √∫nica, o que √© bastante interessante. </p><br><p>  Resta realizar medi√ß√µes da taxa de extra√ß√£o de dados (aleat√≥rios) e avaliar o dimensionamento ao amostrar lotes de tamanhos diferentes: </p><br><div class="spoiler">  <b class="spoiler_title">Banco de Dados de Refer√™ncia</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(ggplot2) set.seed(0) #     con &lt;- DBI::dbConnect(MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) #        prep_sql &lt;- function(batch_size) { sql &lt;- sprintf("PREPARE SELECT id FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",")) res &lt;- DBI::dbSendQuery(con, sql) return(res) } #     fetch_data &lt;- function(rs, batch_size) { ids &lt;- sample(seq_len(n), batch_size) res &lt;- DBI::dbFetch(DBI::dbBind(rs, as.list(ids))) return(res) } #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { rs &lt;- prep_sql(batch_size) bench::mark( fetch_data(rs, batch_size), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 23.6ms 54.02ms 93.43ms 18.8 2.6s 49 # 2 32 38ms 84.83ms 151.55ms 11.4 4.29s 49 # 3 64 63.3ms 175.54ms 248.94ms 5.85 8.54s 50 # 4 128 83.2ms 341.52ms 496.24ms 3.00 16.69s 50 # 5 256 232.8ms 653.21ms 847.44ms 1.58 31.66s 50 # 6 512 784.6ms 1.41s 1.98s 0.740 1.1m 49 # 7 1024 681.7ms 2.72s 4.06s 0.377 2.16m 49 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/ys/oj/zq/ysojzqhr14wf8u9k1xsd6ecmlxc.png"><br><h4 id="section2">  2. Prepara√ß√£o de lotes </h4><br><p>  Todo o processo de prepara√ß√£o de lotes consiste nas seguintes etapas: </p><br><ol><li>  Analisando v√°rios JSONs contendo vetores de linhas com coordenadas de ponto. </li><li>  Desenhando linhas coloridas pelas coordenadas dos pontos na imagem do tamanho desejado (por exemplo, 256x256 ou 128x128). </li><li>  Converta as imagens resultantes em um tensor. </li></ol><br><p>  No √¢mbito da competi√ß√£o entre o kernel em Python, o problema foi resolvido principalmente por meio do <strong>OpenCV</strong> .  Um dos an√°logos mais simples e √≥bvios em R ser√° assim: </p><br><div class="spoiler">  <b class="spoiler_title">Implementar convers√£o de JSON em tensor em R</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">r_process_json_str &lt;- function(json, line.width = 3, color = TRUE, scale = 1) { #  JSON coords &lt;- jsonlite::fromJSON(json, simplifyMatrix = FALSE) tmp &lt;- tempfile() #       on.exit(unlink(tmp)) png(filename = tmp, width = 256 * scale, height = 256 * scale, pointsize = 1) #   plot.new() #    plot.window(xlim = c(256 * scale, 0), ylim = c(256 * scale, 0)) #   cols &lt;- if (color) rainbow(length(coords)) else "#000000" for (i in seq_along(coords)) { lines(x = coords[[i]][[1]] * scale, y = coords[[i]][[2]] * scale, col = cols[i], lwd = line.width) } dev.off() #    3-   res &lt;- png::readPNG(tmp) return(res) } r_process_json_vector &lt;- function(x, ...) { res &lt;- lapply(x, r_process_json_str, ...) #  3-     4-    res &lt;- do.call(abind::abind, c(res, along = 0)) return(res) }</code> </pre> </div></div><br><p>  O desenho √© realizado usando as ferramentas R padr√£o e salvo em um PNG tempor√°rio armazenado na RAM (no Linux, os diret√≥rios tempor√°rios R est√£o localizados no <code>/tmp</code> montado na RAM).  Em seguida, esse arquivo √© lido na forma de uma matriz tridimensional com n√∫meros no intervalo de 0 a 1. Isso √© importante, pois o BMP mais comum seria lido em uma matriz bruta com c√≥digos de cores hexadecimais. </p><br><p>  Teste o resultado: </p><br><pre> <code class="plaintext hljs">zip_file &lt;- file.path("data", "train_simplified.zip") csv_file &lt;- "cat.csv" unzip(zip_file, files = csv_file, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) tmp_data &lt;- data.table::fread(file.path(tempdir(), csv_file), sep = ",", select = "drawing", nrows = 10000) arr &lt;- r_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/t3/n2/-u/t3n2-ugr5ilwsygdfsrwd52vspc.png"><br><p>  O pr√≥prio lote ser√° formado da seguinte maneira: </p><br><pre> <code class="plaintext hljs">res &lt;- r_process_json_vector(tmp_data[1:4, drawing], scale = 0.5) str(res) # num [1:4, 1:128, 1:128, 1:3] 1 1 1 1 1 1 1 1 1 1 ... # - attr(*, "dimnames")=List of 4 # ..$ : NULL # ..$ : NULL # ..$ : NULL # ..$ : NULL</code> </pre> <br><p>  Essa implementa√ß√£o nos pareceu n√£o √≥tima, pois a forma√ß√£o de grandes lotes leva indecentemente muito tempo e decidimos usar a experi√™ncia de nossos colegas usando a poderosa <strong>biblioteca OpenCV</strong> .  Naquele momento, n√£o havia um pacote pronto para o R (ainda n√£o h√° nenhum), portanto, uma implementa√ß√£o m√≠nima da funcionalidade necess√°ria no C ++ foi gravada com integra√ß√£o no c√≥digo R usando o <strong>Rcpp</strong> . </p><br><p>  Para resolver o problema, foram utilizados os seguintes pacotes e bibliotecas: </p><br><ol><li>  <strong>OpenCV</strong> para <strong>gera√ß√£o</strong> de imagens e desenho de linhas.  Usamos bibliotecas de sistema e arquivos de cabe√ßalho pr√©-instalados, al√©m de links din√¢micos. </li><li>  <strong>xtensor</strong> para trabalhar com matrizes e tensores multidimensionais.  Usamos os arquivos de cabe√ßalho inclu√≠dos no pacote R com o mesmo nome.  A biblioteca permite que voc√™ trabalhe com matrizes multidimensionais, na ordem principal da linha e na coluna principal. </li><li>  <strong>ndjson</strong> para analisar JSON.  Essa biblioteca √© usada no <strong>xtensor</strong> automaticamente quando est√° dispon√≠vel no projeto. </li><li>  <strong>RcppThread</strong> para organizar o processamento multithread de um vetor do JSON.  Utilizou os arquivos de cabe√ßalho fornecidos por este pacote.  O pacote difere do <strong>RcppParallel</strong> mais popular entre outras coisas por seu mecanismo de interrup√ß√£o embutido. </li></ol><br><p>  Vale ressaltar que o <strong>xtensor</strong> acabou sendo apenas um achado: al√©m de ter uma funcionalidade abrangente e alto desempenho, seus desenvolvedores mostraram-se bastante receptivos e prontamente e em detalhes responderam √†s perguntas que surgiram.  Com a ajuda deles, foi poss√≠vel implementar a transforma√ß√£o de matrizes OpenCV em tensores xtensores, bem como um m√©todo de combinar tensores de imagem tridimensionais em um tensor quadridimensional da dimens√£o correta (na verdade, o lote). </p><br><div class="spoiler">  <b class="spoiler_title">Materiais de estudo para Rcpp, xtensor e RcppThread</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://thecoatlessprofessor.com/programming/unofficial-rcpp-api-documentation</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://docs.opencv.org/4.0.1/d7/dbd/group__imgproc.html</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://xtensor.readthedocs.io/en/latest/</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://xtensor.readthedocs.io/en/latest/file_loading.html#loading-json-data-into-xtensor</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://cran.r-project.org/web/packages/RcppThread/vignettes/RcppThread-vignette.pdf</a> </p></div></div><br><p>  Para compilar arquivos usando arquivos do sistema e vincula√ß√£o din√¢mica com bibliotecas instaladas no sistema, usamos o mecanismo de plug-in implementado no pacote <strong>Rcpp</strong> .  Para encontrar automaticamente caminhos e sinalizadores, usamos o popular utilit√°rio linux <strong>pkg-config</strong> . </p><br><div class="spoiler">  <b class="spoiler_title">Implementando um plug-in Rcpp para usar a biblioteca OpenCV</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">Rcpp::registerPlugin("opencv", function() { #    pkg_config_name &lt;- c("opencv", "opencv4") #    pkg-config pkg_config_bin &lt;- Sys.which("pkg-config") #      checkmate::assert_file_exists(pkg_config_bin, access = "x") #     OpenCV  pkg-config check &lt;- sapply(pkg_config_name, function(pkg) system(paste(pkg_config_bin, pkg))) if (all(check != 0)) { stop("OpenCV config for the pkg-config not found", call. = FALSE) } pkg_config_name &lt;- pkg_config_name[check == 0] list(env = list( PKG_CXXFLAGS = system(paste(pkg_config_bin, "--cflags", pkg_config_name), intern = TRUE), PKG_LIBS = system(paste(pkg_config_bin, "--libs", pkg_config_name), intern = TRUE) )) })</code> </pre> </div></div><br><p>  Como resultado do plug-in, durante a compila√ß√£o, os seguintes valores ser√£o substitu√≠dos: </p><br><pre> <code class="plaintext hljs">Rcpp:::.plugins$opencv()$env # $PKG_CXXFLAGS # [1] "-I/usr/include/opencv" # # $PKG_LIBS # [1] "-lopencv_shape -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_datasets -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_line_descriptor -lopencv_optflow -lopencv_video -lopencv_plot -lopencv_reg -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_rgbd -lopencv_viz -lopencv_surface_matching -lopencv_text -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_flann -lopencv_xobjdetect -lopencv_objdetect -lopencv_ml -lopencv_xphoto -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_photo -lopencv_imgproc -lopencv_core"</code> </pre> <br><p>  O c√≥digo para implementar a an√°lise JSON e criar um lote para transfer√™ncia para o modelo √© fornecido sob o spoiler.  Primeiro, adicione o diret√≥rio do projeto local para procurar arquivos de cabe√ßalho (necess√°rios para o ndjson): </p><br><pre> <code class="plaintext hljs">Sys.setenv("PKG_CXXFLAGS" = paste0("-I", normalizePath(file.path("src"))))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Implementando convers√£o de JSON em tensor em C ++</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">// [[Rcpp::plugins(cpp14)]] // [[Rcpp::plugins(opencv)]] // [[Rcpp::depends(xtensor)]] // [[Rcpp::depends(RcppThread)]] #include &lt;xtensor/xjson.hpp&gt; #include &lt;xtensor/xadapt.hpp&gt; #include &lt;xtensor/xview.hpp&gt; #include &lt;xtensor-r/rtensor.hpp&gt; #include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;opencv2/imgproc/imgproc.hpp&gt; #include &lt;Rcpp.h&gt; #include &lt;RcppThread.h&gt; //    using RcppThread::parallelFor; using json = nlohmann::json; using points = xt::xtensor&lt;double,2&gt;; //   JSON   using strokes = std::vector&lt;points&gt;; //   JSON   using xtensor3d = xt::xtensor&lt;double, 3&gt;; //      using xtensor4d = xt::xtensor&lt;double, 4&gt;; //      using rtensor3d = xt::rtensor&lt;double, 3&gt;; //     R using rtensor4d = xt::rtensor&lt;double, 4&gt;; //     R //   //     const static int SIZE = 256; //   // . https://en.wikipedia.org/wiki/Pixel_connectivity#2-dimensional const static int LINE_TYPE = cv::LINE_4; //     const static int LINE_WIDTH = 3; //   // https://docs.opencv.org/3.1.0/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121 const static int RESIZE_TYPE = cv::INTER_LINEAR; //    OpenCV-   template &lt;typename T, int NCH, typename XT=xt::xtensor&lt;T,3,xt::layout_type::column_major&gt;&gt; XT to_xt(const cv::Mat_&lt;cv::Vec&lt;T, NCH&gt;&gt;&amp; src) { //    std::vector&lt;int&gt; shape = {src.rows, src.cols, NCH}; //      size_t size = src.total() * NCH; //  cv::Mat  xt::xtensor XT res = xt::adapt((T*) src.data, size, xt::no_ownership(), shape); return res; } //  JSON     strokes parse_json(const std::string&amp; x) { auto j = json::parse(x); //      if (!j.is_array()) { throw std::runtime_error("'x' must be JSON array."); } strokes res; res.reserve(j.size()); for (const auto&amp; a: j) { //      2-  if (!a.is_array() || a.size() != 2) { throw std::runtime_error("'x' must include only 2d arrays."); } //    auto p = a.get&lt;points&gt;(); res.push_back(p); } return res; } //   //  HSV cv::Mat ocv_draw_lines(const strokes&amp; x, bool color = true) { //    auto stype = color ? CV_8UC3 : CV_8UC1; //    auto dtype = color ? CV_32FC3 : CV_32FC1; auto bg = color ? cv::Scalar(0, 0, 255) : cv::Scalar(255); auto col = color ? cv::Scalar(0, 255, 220) : cv::Scalar(0); cv::Mat img = cv::Mat(SIZE, SIZE, stype, bg); //   size_t n = x.size(); for (const auto&amp; s: x) { //     size_t n_points = s.shape()[1]; for (size_t i = 0; i &lt; n_points - 1; ++i) { //    cv::Point from(s(0, i), s(1, i)); //    cv::Point to(s(0, i + 1), s(1, i + 1)); //   cv::line(img, from, to, col, LINE_WIDTH, LINE_TYPE); } if (color) { //    col[0] += 180 / n; } } if (color) { //     RGB cv::cvtColor(img, img, cv::COLOR_HSV2RGB); } //     float32   [0, 1] img.convertTo(img, dtype, 1 / 255.0); return img; } //  JSON       xtensor3d process(const std::string&amp; x, double scale = 1.0, bool color = true) { auto p = parse_json(x); auto img = ocv_draw_lines(p, color); if (scale != 1) { cv::Mat out; cv::resize(img, out, cv::Size(), scale, scale, RESIZE_TYPE); cv::swap(img, out); out.release(); } xtensor3d arr = color ? to_xt&lt;double,3&gt;(img) : to_xt&lt;double,1&gt;(img); return arr; } // [[Rcpp::export]] rtensor3d cpp_process_json_str(const std::string&amp; x, double scale = 1.0, bool color = true) { xtensor3d res = process(x, scale, color); return res; } // [[Rcpp::export]] rtensor4d cpp_process_json_vector(const std::vector&lt;std::string&gt;&amp; x, double scale = 1.0, bool color = false) { size_t n = x.size(); size_t dim = floor(SIZE * scale); size_t channels = color ? 3 : 1; xtensor4d res({n, dim, dim, channels}); parallelFor(0, n, [&amp;x, &amp;res, scale, color](int i) { xtensor3d tmp = process(x[i], scale, color); auto view = xt::view(res, i, xt::all(), xt::all(), xt::all()); view = tmp; }); return res; }</code> </pre> </div></div><br><p>  Este c√≥digo deve ser colocado no <code>src/cv_xt.cpp</code> e compilado com o comando <code>Rcpp::sourceCpp(file = "src/cv_xt.cpp", env = .GlobalEnv)</code> ;  voc√™ tamb√©m precisar√° do <code>nlohmann/json.hpp</code> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">reposit√≥rio para funcionar</a> .  O c√≥digo √© dividido em v√°rias fun√ß√µes: </p><br><ul><li>  <code>to_xt</code> - uma fun√ß√£o de gabarito para converter a matriz da imagem ( <code>cv::Mat</code> ) no tensor <code>xt::xtensor</code> ; </li><li>  <code>parse_json</code> - a fun√ß√£o analisa uma string JSON, extrai as coordenadas de pontos, empacotando-as em um vetor; </li><li>  <code>ocv_draw_lines</code> - <code>ocv_draw_lines</code> linhas coloridas do vetor recebido de pontos; </li><li>  <code>process</code> - combina as fun√ß√µes acima e tamb√©m adiciona a capacidade de dimensionar a imagem resultante; </li><li>  <code>cpp_process_json_str</code> - um wrapper sobre a fun√ß√£o de <code>process</code> , que exporta o resultado para um objeto R (matriz multidimensional); </li><li>  <code>cpp_process_json_vector</code> - um wrapper sobre a fun√ß√£o <code>cpp_process_json_str</code> , que permite processar um vetor de string no modo multiencadeado. </li></ul><br><p>  Para desenhar linhas multicoloridas, foi utilizado o modelo de cores HSV, seguido de convers√£o para RGB.  Teste o resultado: </p><br><pre> <code class="plaintext hljs">arr &lt;- cpp_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/23/mm/ro/23mmrob6qhnjgnsaqm-4mno159c.png"><br><div class="spoiler">  <b class="spoiler_title">Compara√ß√£o da velocidade de implementa√ß√µes em R e C ++</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">res_bench &lt;- bench::mark( r_process_json_str(tmp_data[4, drawing], scale = 0.5), cpp_process_json_str(tmp_data[4, drawing], scale = 0.5), check = FALSE, min_iterations = 100 ) #   cols &lt;- c("expression", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # expression min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r_process_json_str 3.49ms 3.55ms 4.47ms 273. 490ms 134 # 2 cpp_process_json_str 1.94ms 2.02ms 5.32ms 489. 497ms 243 library(ggplot2) #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { .data &lt;- tmp_data[sample(seq_len(.N), batch_size), drawing] bench::mark( r_process_json_vector(.data, scale = 0.5), cpp_process_json_vector(.data, scale = 0.5), min_iterations = 50, check = FALSE ) } ) res_bench[, cols] # expression batch_size min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r 16 50.61ms 53.34ms 54.82ms 19.1 471.13ms 9 # 2 cpp 16 4.46ms 5.39ms 7.78ms 192. 474.09ms 91 # 3 r 32 105.7ms 109.74ms 212.26ms 7.69 6.5s 50 # 4 cpp 32 7.76ms 10.97ms 15.23ms 95.6 522.78ms 50 # 5 r 64 211.41ms 226.18ms 332.65ms 3.85 12.99s 50 # 6 cpp 64 25.09ms 27.34ms 32.04ms 36.0 1.39s 50 # 7 r 128 534.5ms 627.92ms 659.08ms 1.61 31.03s 50 # 8 cpp 128 56.37ms 58.46ms 66.03ms 16.9 2.95s 50 # 9 r 256 1.15s 1.18s 1.29s 0.851 58.78s 50 # 10 cpp 256 114.97ms 117.39ms 130.09ms 8.45 5.92s 50 # 11 r 512 2.09s 2.15s 2.32s 0.463 1.8m 50 # 12 cpp 512 230.81ms 235.6ms 261.99ms 4.18 11.97s 50 # 13 r 1024 4s 4.22s 4.4s 0.238 3.5m 50 # 14 cpp 1024 410.48ms 431.43ms 462.44ms 2.33 21.45s 50 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = expression, color = expression)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() + scale_color_discrete(name = "", labels = c("cpp", "r")) + theme(legend.position = "bottom")</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/zq/if/sa/zqifsayhpqy-dujaijmn-brk058.png"><br><p>  Como voc√™ pode ver, o aumento de velocidade acabou sendo muito significativo e n√£o √© poss√≠vel acompanhar o c√≥digo C ++ paralelizando o c√≥digo R. </p><br><h4 id="section3">  3. Iteradores para descarregar lotes do banco de dados </h4><br><p>  O R tem uma reputa√ß√£o merecida como uma linguagem para o processamento de dados localizados na RAM, enquanto o Python √© mais caracterizado pelo processamento iterativo de dados, o que facilita e facilita a implementa√ß√£o de c√°lculos fora do n√∫cleo (c√°lculos usando mem√≥ria externa).  Cl√°ssico e relevante para n√≥s no contexto do problema descrito, um exemplo de tais c√°lculos s√£o as redes neurais profundas, treinadas pelo m√©todo de descida do gradiente com aproxima√ß√£o do gradiente em cada etapa por uma pequena por√ß√£o de observa√ß√µes ou um mini-lote. </p><br><p>  As estruturas de aprendizado profundo escritas em Python t√™m classes especiais que implementam iteradores com base em dados: tabelas, figuras em pastas, formatos bin√°rios, etc. Voc√™ pode usar op√ß√µes prontas ou criar suas pr√≥prias tarefas espec√≠ficas.  No R, podemos tirar o m√°ximo proveito da biblioteca Keras Python, com seus v√°rios back-ends, usando o pacote com o mesmo nome, que por sua vez funciona sobre o pacote <strong>reticulado</strong> .  O √∫ltimo merece um grande artigo separado;  al√©m de permitir a execu√ß√£o do c√≥digo Python a partir do R, tamb√©m fornece a transfer√™ncia de objetos entre as sess√µes R e Python, executando automaticamente todas as convers√µes de tipo necess√°rias. </p><br><p>  N√≥s nos livramos da necessidade de armazenar todos os dados na RAM devido ao uso do MonetDBLite, todo o trabalho da "rede neural" ser√° feito pelo c√≥digo original do Python, basta escrever um iterador com base nos dados, pois n√£o h√° um pronto para tal situa√ß√£o no R ou no Python.       :              (  R      ).         R  numpy-,     <strong>keras</strong>   . </p><br><p>        : </p><br><div class="spoiler"> <b class="spoiler_title">     </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">train_generator &lt;- function(db_connection = con, samples_index, num_classes = 340, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_class(con, "DBIConnection") checkmate::assert_integerish(samples_index) checkmate::assert_count(num_classes) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) # ,          dt &lt;- data.table::data.table(id = sample(samples_index)) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] #       dt &lt;- dt[, if (.N == batch_size) .SD, keyby = batch] #   i &lt;- 1 #   max_i &lt;- dt[, max(batch)] #     sql &lt;- sprintf( "PREPARE SELECT drawing, label_int FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",") ) res &lt;- DBI::dbSendQuery(con, sql) #  keras::to_categorical to_categorical &lt;- function(x, num) { n &lt;- length(x) m &lt;- numeric(n * num) m[x * n + seq_len(n)] &lt;- 1 dim(m) &lt;- c(n, num) return(m) } #  function() { #    if (i &gt; max_i) { dt[, id := sample(id)] data.table::setkey(dt, batch) #   i &lt;&lt;- 1 max_i &lt;&lt;- dt[, max(batch)] } # ID    batch_ind &lt;- dt[batch == i, id] #   batch &lt;- DBI::dbFetch(DBI::dbBind(res, as.list(batch_ind)), n = -1) #   i &lt;&lt;- i + 1 #  JSON    batch_x &lt;- cpp_process_json_vector(batch$drawing, scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } batch_y &lt;- to_categorical(batch$label_int, num_classes) result &lt;- list(batch_x, batch_y) return(result) } }</code> </pre> </div></div><br><p>         ,   ,  ,  ,  ( <code>scale = 1</code>    256256 , <code>scale = 0.5</code> ‚Äî 128128 ),   ( <code>color = FALSE</code>     ,   <code>color = TRUE</code>     )     ,   imagenet-.    ,       [0, 1]   [-1, 1],        <strong>keras</strong> . </p><br><p>      ,  <code>data.table</code>        <code>samples_index</code>   ,     ,   SQL-     .        <code>keras::to_categorical()</code> .       ,    ,      <code>steps_per_epoch</code>   <code>keras::fit_generator()</code> ,   <code>if (i &gt; max_i)</code>     . </p><br><p>          ,        ,  JSON- ( <code>cpp_process_json_vector()</code> ,   C++)   ,  .   one-hot    ,          ,     .         <code>data.table</code>     ‚Äî   ""  <strong>data.table</strong>       -     R. </p><br><p>       Core i5   : </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(Rcpp) library(keras) library(ggplot2) source("utils/rcpp.R") source("utils/keras_iterator.R") con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) ind &lt;- seq_len(DBI::dbGetQuery(con, "SELECT count(*) FROM doodles")[[1L]]) num_classes &lt;- DBI::dbGetQuery(con, "SELECT max(label_int) + 1 FROM doodles")[[1L]] #     train_ind &lt;- sample(ind, floor(length(ind) * 0.995)) #     val_ind &lt;- ind[-train_ind] rm(ind) #   scale &lt;- 0.5 #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { it1 &lt;- train_generator( db_connection = con, samples_index = train_ind, num_classes = num_classes, batch_size = batch_size, scale = scale ) bench::mark( it1(), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 25ms 64.36ms 92.2ms 15.9 3.09s 49 # 2 32 48.4ms 118.13ms 197.24ms 8.17 5.88s 48 # 3 64 69.3ms 117.93ms 181.14ms 8.57 5.83s 50 # 4 128 157.2ms 240.74ms 503.87ms 3.85 12.71s 49 # 5 256 359.3ms 613.52ms 988.73ms 1.54 30.5s 47 # 6 512 884.7ms 1.53s 2.07s 0.674 1.11m 45 # 7 1024 2.7s 3.83s 5.47s 0.261 2.81m 44 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/w0/i6/jx/w0i6jxjhgwqs82fbazwxdquqe18.png"><br><p>     ,              (    32 ).       <code>/dev/shm</code> ,     .    ,  <code>/etc/fstab</code> ,     <code>tmpfs /dev/shm tmpfs defaults,size=25g 0 0</code> .     ,   <code>df -h</code> . </p><br><p>       ,       : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">test_generator &lt;- function(dt, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_data_table(dt) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] data.table::setkey(dt, batch) i &lt;- 1 max_i &lt;- dt[, max(batch)] #  function() { batch_x &lt;- cpp_process_json_vector(dt[batch == i, drawing], scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } result &lt;- list(batch_x) i &lt;&lt;- i + 1 return(result) } }</code> </pre> </div></div><br><h4 id="section4"> 4.    </h4><br><p>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mobilenet v1</a> ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> .      <strong>keras</strong> , ,      R.          :       <code>(batch, height, width, 3)</code> ,      .  Python   ,         ,    ( ,    keras- ): </p><br><div class="spoiler"> <b class="spoiler_title"> mobilenet v1</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(keras) top_3_categorical_accuracy &lt;- custom_metric( name = "top_3_categorical_accuracy", metric_fn = function(y_true, y_pred) { metric_top_k_categorical_accuracy(y_true, y_pred, k = 3) } ) layer_sep_conv_bn &lt;- function(object, filters, alpha = 1, depth_multiplier = 1, strides = c(2, 2)) { # NB! depth_multiplier != resolution multiplier # https://github.com/keras-team/keras/issues/10349 layer_depthwise_conv_2d( object = object, kernel_size = c(3, 3), strides = strides, padding = "same", depth_multiplier = depth_multiplier ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_conv_2d( filters = filters * alpha, kernel_size = c(1, 1), strides = c(1, 1) ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() } get_mobilenet_v1 &lt;- function(input_shape = c(224, 224, 1), num_classes = 340, alpha = 1, depth_multiplier = 1, optimizer = optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = c("categorical_crossentropy", top_3_categorical_accuracy)) { inputs &lt;- layer_input(shape = input_shape) outputs &lt;- inputs %&gt;% layer_conv_2d(filters = 32, kernel_size = c(3, 3), strides = c(2, 2), padding = "same") %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_sep_conv_bn(filters = 64, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(1, 1)) %&gt;% layer_global_average_pooling_2d() %&gt;% layer_dense(units = num_classes) %&gt;% layer_activation_softmax() model &lt;- keras_model( inputs = inputs, outputs = outputs ) model %&gt;% compile( optimizer = optimizer, loss = loss, metrics = metrics ) return(model) }</code> </pre> </div></div><br><p>    .    ,     , ,  .        ,    imagenet-.  ,   .  <code>get_config()</code>          ( <code>base_model_conf$layers</code> ‚Äî  R- ),   <code>from_config()</code>      : </p><br><pre> <code class="plaintext hljs">base_model_conf &lt;- get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- from_config(base_model_conf)</code> </pre> <br><p>               <strong>keras</strong>     imagenet-    : </p><br><div class="spoiler"> <b class="spoiler_title">    </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">get_model &lt;- function(name = "mobilenet_v2", input_shape = NULL, weights = "imagenet", pooling = "avg", num_classes = NULL, optimizer = keras::optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = NULL, color = TRUE, compile = FALSE) { #   checkmate::assert_string(name) checkmate::assert_integerish(input_shape, lower = 1, upper = 256, len = 3) checkmate::assert_count(num_classes) checkmate::assert_flag(color) checkmate::assert_flag(compile) #     keras model_fun &lt;- get0(paste0("application_", name), envir = asNamespace("keras")) #      if (is.null(model_fun)) { stop("Model ", shQuote(name), " not found.", call. = FALSE) } base_model &lt;- model_fun( input_shape = input_shape, include_top = FALSE, weights = weights, pooling = pooling ) #    ,    if (!color) { base_model_conf &lt;- keras::get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- keras::from_config(base_model_conf) } predictions &lt;- keras::get_layer(base_model, "global_average_pooling2d_1")$output predictions &lt;- keras::layer_dense(predictions, units = num_classes, activation = "softmax") model &lt;- keras::keras_model( inputs = base_model$input, outputs = predictions ) if (compile) { keras::compile( object = model, optimizer = optimizer, loss = loss, metrics = metrics ) } return(model) }</code> </pre> </div></div><br><p>        .     :    <code>get_weights()</code>        R- ,       ( -       ),         <code>set_weights()</code> .       ,       ,      . </p><br><p>        mobilenet  1  2,   resnet34.         ,   SE-ResNeXt.  ,       ,       (  ). </p><br><h4 id="section5"> 5.   </h4><br><p>             ,    <strong><a href="">docopt</a></strong>  : </p><br><pre> <code class="plaintext hljs">doc &lt;- ' Usage: train_nn.R --help train_nn.R --list-models train_nn.R [options] Options: -h --help Show this message. -l --list-models List available models. -m --model=&lt;model&gt; Neural network model name [default: mobilenet_v2]. -b --batch-size=&lt;size&gt; Batch size [default: 32]. -s --scale-factor=&lt;ratio&gt; Scale factor [default: 0.5]. -c --color Use color lines [default: FALSE]. -d --db-dir=&lt;path&gt; Path to database directory [default: Sys.getenv("db_dir")]. -r --validate-ratio=&lt;ratio&gt; Validate sample ratio [default: 0.995]. -n --n-gpu=&lt;number&gt; Number of GPUs [default: 1]. ' args &lt;- docopt::docopt(doc)</code> </pre> <br><p>  <strong>docopt</strong>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://docopt.org/</a>  R.         <code>Rscript bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code>  <code>./bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code> ,   <code>train_nn.R</code>   (     <code>resnet50</code>     128128 ,       <code>/home/andrey/doodle_db</code> ).      ,       .     ,   <code>mobilenet_v2</code>    <strong>keras</strong>  R  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> -   R-  ‚Äî ,  . </p><br><p>                  RStudio (      <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tfruns</a></strong> ).                ,     RStudio. </p><br><h4 id="section6"> 6.   </h4><br><p>                    .        R-    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> . </p><br><p>       ¬´ ¬ª,           .        ,    NVIDIA, CUDA+cuDNN    ‚Äî    ,        <code>tensorflow/tensorflow:1.12.0-gpu</code> ,    R-. </p><br><p>  -  : </p><br><div class="spoiler"> <b class="spoiler_title">Dockerfile</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">FROM tensorflow/tensorflow:1.12.0-gpu MAINTAINER Artem Klevtsov &lt;aaklevtsov@gmail.com&gt; SHELL ["/bin/bash", "-c"] ARG LOCALE="en_US.UTF-8" ARG APT_PKG="libopencv-dev r-base r-base-dev littler" ARG R_BIN_PKG="futile.logger checkmate data.table rcpp rapidjsonr dbi keras jsonlite curl digest remotes" ARG R_SRC_PKG="xtensor RcppThread docopt MonetDBLite" ARG PY_PIP_PKG="keras" ARG DIRS="/db /app /app/data /app/models /app/logs" RUN source /etc/os-release &amp;&amp; \ echo "deb https://cloud.r-project.org/bin/linux/ubuntu ${UBUNTU_CODENAME}-cran35/" &gt; /etc/apt/sources.list.d/cran35.list &amp;&amp; \ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 &amp;&amp; \ add-apt-repository -y ppa:marutter/c2d4u3.5 &amp;&amp; \ add-apt-repository -y ppa:timsc/opencv-3.4 &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y locales &amp;&amp; \ locale-gen ${LOCALE} &amp;&amp; \ apt-get install -y --no-install-recommends ${APT_PKG} &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install.r /usr/local/bin/install.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install2.r /usr/local/bin/install2.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/installGithub.r /usr/local/bin/installGithub.r &amp;&amp; \ echo 'options(Ncpus = parallel::detectCores())' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ echo 'options(repos = c(CRAN = "https://cloud.r-project.org"))' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ apt-get install -y $(printf "r-cran-%s " ${R_BIN_PKG}) &amp;&amp; \ install.r ${R_SRC_PKG} &amp;&amp; \ pip install ${PY_PIP_PKG} &amp;&amp; \ mkdir -p ${DIRS} &amp;&amp; \ chmod 777 ${DIRS} &amp;&amp; \ rm -rf /tmp/downloaded_packages/ /tmp/*.rds &amp;&amp; \ rm -rf /var/lib/apt/lists/* COPY utils /app/utils COPY src /app/src COPY tests /app/tests COPY bin/*.R /app/ ENV DBDIR="/db" ENV CUDA_HOME="/usr/local/cuda" ENV PATH="/app:${PATH}" WORKDIR /app VOLUME /db VOLUME /app CMD bash</code> </pre></div></div><br><p>        ;         .       <code>/bin/bash</code>     <code>/etc/os-release</code> .         . </p><br><p>     -,      . ,       ,    ,          : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#!/bin/sh DBDIR=${PWD}/db LOGSDIR=${PWD}/logs MODELDIR=${PWD}/models DATADIR=${PWD}/data ARGS="--runtime=nvidia --rm -v ${DBDIR}:/db -v ${LOGSDIR}:/app/logs -v ${MODELDIR}:/app/models -v ${DATADIR}:/app/data" if [ -z "$1" ]; then CMD="Rscript /app/train_nn.R" elif [ "$1" = "bash" ]; then ARGS="${ARGS} -ti" else CMD="Rscript /app/train_nn.R $@" fi docker run ${ARGS} doodles-tf ${CMD}</code> </pre> </div></div><br><p>   -   ,      <code>train_nn.R</code>    ;     ‚Äî  "bash",         .         : <code>CMD="Rscript /app/train_nn.R $@"</code> . </p><br><p>   ,        ,             ,           . </p><br><h4 id="section7"> 7.   GPU   Google Cloud </h4><br><p>         (.  ,   @Leigh.plt  ODS-).       ,        1 GPU       GPU  .  GoogleCloud ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">    </a> ) -    ,     $300.       4V100  SSD   ,     .     ,       .      K80.       ‚Äî  SSD   c,          <code>dev/shm</code> . </p><br><p>     ,     GPU.     CPU    ,    : </p><br><pre> <code class="plaintext hljs">with(tensorflow::tf$device("/cpu:0"), { model_cpu &lt;- get_model( name = model_name, input_shape = input_shape, weights = weights, metrics =(top_3_categorical_accuracy, compile = FALSE ) })</code> </pre> <br><p>   ( )       GPU,     : </p><br><pre> <code class="plaintext hljs">model &lt;- keras::multi_gpu_model(model_cpu, gpus = n_gpu) keras::compile( object = model, optimizer = keras::optimizer_adam(lr = 0.0004), loss = "categorical_crossentropy", metrics = c(top_3_categorical_accuracy) )</code> </pre> <br><p>      ,  ,   ,        GPU   . </p><br><p>      <strong>tensorboard</strong> ,            : </p><br><div class="spoiler"> <b class="spoiler_title"></b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     log_file_tmpl &lt;- file.path("logs", sprintf( "%s_%d_%dch_%s.csv", model_name, dim_size, channels, format(Sys.time(), "%Y%m%d%H%M%OS") )) #     model_file_tmpl &lt;- file.path("models", sprintf( "%s_%d_%dch_{epoch:02d}_{val_loss:.2f}.h5", model_name, dim_size, channels )) callbacks_list &lt;- list( keras::callback_csv_logger( filename = log_file_tmpl ), keras::callback_early_stopping( monitor = "val_loss", min_delta = 1e-4, patience = 8, verbose = 1, mode = "min" ), keras::callback_reduce_lr_on_plateau( monitor = "val_loss", factor = 0.5, #  lr  2  patience = 4, verbose = 1, min_delta = 1e-4, mode = "min" ), keras::callback_model_checkpoint( filepath = model_file_tmpl, monitor = "val_loss", save_best_only = FALSE, save_weights_only = FALSE, mode = "min" ) )</code> </pre> </div></div><br><h4 id="section8"> 8.   </h4><br><p>  ,    ,    : </p><br><ul><li>  <strong>keras</strong>          ( <code>lr_finder</code>   <strong>fast.ai</strong> );   ,    R  , , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ; </li><li>    ,          GPU; </li><li>     ,    imagenet-; </li><li>  one cycle policy  discriminative learning rates (osine annealing     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">skeydan</a> ). </li></ul><br><p>       : </p><br><ul><li>           (   )  .  <strong>data.table</strong>     in-place  ,     ,                   .                  . </li><li>    R     C++    <strong>Rcpp</strong> .    <strong>RcppThread</strong>  <strong>RcppParallel</strong> ,    ,     R   . </li><li>  <strong>Rcpp</strong>      C++,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a> .         <strong>xtensor</strong>   CRAN,       ,   R     C++.   ‚Äî        ++  RStudio. </li><li> <strong>docopt</strong>      .       ,  ..  .  RStudio       ,     IDE     . </li><li>               ,      .         . </li><li> Google Cloud ‚Äî      ,     . </li><li>        ,    R  C++,    <strong>bench</strong> ‚Äî    . </li></ul><br><p>       ,          . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt443758/">https://habr.com/ru/post/pt443758/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt443746/index.html">Mercado de jogos, tend√™ncias e previs√µes - √≥timas an√°lises da App Annie</a></li>
<li><a href="../pt443748/index.html">Apresenta√ß√£o Tesla Model Y - o que esperar e onde procurar</a></li>
<li><a href="../pt443752/index.html">Kotlin como o futuro do desenvolvimento de aplicativos Android</a></li>
<li><a href="../pt443754/index.html">Sobre a adequa√ß√£o do Selenium WebDriverWait</a></li>
<li><a href="../pt443756/index.html">Design da classe: O que √© bom?</a></li>
<li><a href="../pt443764/index.html">O que o designer fumava: uma arma de fogo incomum</a></li>
<li><a href="../pt443766/index.html">Tentando a programa√ß√£o de contratos C ++ 20 agora</a></li>
<li><a href="../pt443768/index.html">Mon√≥lito para centenas de vers√µes de clientes: como escrevemos e suportamos testes</a></li>
<li><a href="../pt443770/index.html">Design Orientado a Dom√≠nio: Objetos de Valor e N√∫cleo da Estrutura de Entidades na Pr√°tica</a></li>
<li><a href="../pt443772/index.html">Antiguidades: IBM ThinkPad T40, o primeiro sistema sem fio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✌🏻 ⚖️ 🤛🏾 NVIDIA Jetson Nano：测试和第一印象-第2部分，AI测试 ⚛️ ☝🏼 🌼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="哈Ha 

 在第一部分中 ，考虑了NVIDIA Jetson Nano-Raspberry Pi尺寸的主板，专注于使用GPU进行性能计算。 现在该测试板的创建目的了-面向AI的计算。 



 考虑一下板上的不同任务，例如对图像进行分类或识别行人或印章（没有图像的地方）。 对于所有测试，源代码都可...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NVIDIA Jetson Nano：测试和第一印象-第2部分，AI测试</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/460971/"> 哈Ha <br><br> 在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第一部分中</a> ，考虑了NVIDIA Jetson Nano-Raspberry Pi尺寸的主板，专注于使用GPU进行性能计算。 现在该测试板的创建目的了-面向AI的计算。 <br><br><img src="https://habrastorage.org/webt/91/1a/7i/911a7i0fv9k20_edm9oftroelpq.png"><br><br> 考虑一下板上的不同任务，例如对图像进行分类或识别行人或印章（没有图像的地方）。 对于所有测试，源代码都可以在台式机，Jetson Nano或Raspberry Pi上运行。 对于那些感兴趣的人，继续减产。 <br><a name="habracut"></a><br> 有两种使用该板的方法。 首先是运行Keras和Tensorflow等标准框架。 它在原理上可以正常工作，但是从第一部分已经可以看出，Jetson Nano当然不如成熟的台式机或笔记本视频卡。 用户将不得不承担优化模型的任务。 第二种方法是参加电路板附带的现成的课程。 它更简单并且可以“即开即用”地工作，其缺点是所有实现细节都被更大程度地隐藏了，此外，您还必须学习和使用custom-sdk，除了这些板之外，custom-sdk在其他任何地方都将无用。 但是，我们将从第一种开始着眼于两种方式。 <br><br><h2> 图片分类 </h2><br> 考虑图像识别问题。 为此，我们将使用Keras随附的ResNet50模型（该模型是2015年ImageNet挑战赛的获胜者）。 要使用它，只需几行代码就足够了。 <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time IMAGE_SIZE = <span class="hljs-number"><span class="hljs-number">224</span></span> IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>) resnet = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE) img = tf.contrib.keras.preprocessing.image.load_img(<span class="hljs-string"><span class="hljs-string">'cat.png'</span></span>, target_size=(IMAGE_SIZE, IMAGE_SIZE)) t_start = time.time() img_data = tf.contrib.keras.preprocessing.image.img_to_array(img) x = tf.contrib.keras.applications.resnet50.preprocess_input(np.expand_dims(img_data, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)) probabilities = resnet.predict(x) print(tf.contrib.keras.applications.resnet50.decode_predictions(probabilities, top=<span class="hljs-number"><span class="hljs-number">5</span></span>)) print(<span class="hljs-string"><span class="hljs-string">"dT"</span></span>, time.time() - t_start)</code> </pre> <br> 我什至没有开始删除破坏者下的代码，因为 他很小。 如您所见，首先将图像调整为224x224（这是输入网络格式），最后，预测功能完成所有工作。 <br><br> 我们给猫拍照，然后运行程序。 <br><br><img src="https://habrastorage.org/webt/_q/e8/ln/_qe8ln2w3hsmbw4dqcy7kdnuft0.png"><br><br> 结果： <br><br><pre> <code class="python hljs">[[(<span class="hljs-string"><span class="hljs-string">'n02123045'</span></span>, <span class="hljs-string"><span class="hljs-string">'tabby'</span></span>, <span class="hljs-number"><span class="hljs-number">0.765179</span></span>), (<span class="hljs-string"><span class="hljs-string">'n02123159'</span></span>, <span class="hljs-string"><span class="hljs-string">'tiger_cat'</span></span>, <span class="hljs-number"><span class="hljs-number">0.19059166</span></span>), (<span class="hljs-string"><span class="hljs-string">'n02124075'</span></span>, <span class="hljs-string"><span class="hljs-string">'Egyptian_cat'</span></span>, <span class="hljs-number"><span class="hljs-number">0.013605555</span></span>), (<span class="hljs-string"><span class="hljs-string">'n04493381'</span></span>, <span class="hljs-string"><span class="hljs-string">'tub'</span></span>, <span class="hljs-number"><span class="hljs-number">0.0025916891</span></span>), (<span class="hljs-string"><span class="hljs-string">'n04553703'</span></span>, <span class="hljs-string"><span class="hljs-string">'washbasin'</span></span>, <span class="hljs-number"><span class="hljs-number">0.0021566998</span></span>)]]</code> </pre> <br> 再一次，由于他对英语的了解而感到不安（我想知道有多少非本地人知道什么是“平头”？），我用字典检查了输出，是的，一切正常。 <br><br> 在CPU上计算的PC代码执行时间为<b>0.5 s</b> ，在GPU上计算的PC代码执行时间为2 s（！）。 根据日志判断，问题出在模型中还是在Tensorflow中，但是在启动时，代码尝试分配大量内存，并以“分配器（GPU_0_bfc）内存不足，尝试分配freed_by_count = 0的2.13GiB”的形式发出警告。 。 这是一个警告，而不是一个错误，该代码可以正常工作，但是比它应该慢得多。 <br><br> 在Jetson Nano上，速度仍然较慢：CPU上为<b>2.8c</b> ，GPU上为<b>18.8c</b> ，输出如下所示： <br><br><img src="https://habrastorage.org/webt/t6/ok/ja/t6okja2fzqx_tjvmd6evens5dn8.png"><br><br> 通常，即使每个图像3s，这也不是实时的。 设置建议在堆栈溢出时使用的gpu_options.allow_growth选项无济于事，如果有人知道另一种方法，请在注释中编写。 <br><br>  <b>编辑</b> ：按照评论中的提示，tensorflow的首次启动通常会花费很长时间，并且使用它来衡量时间是不正确的。 确实，当处理第二个及后续文件时，结果要好得多-不带GPU时为0.6秒，带GPU时为0.2秒。 但是，在台式机上，速度分别为2.0秒和0.05秒。 <br><br>  ResNet50的一个方便功能是，在第一次启动时，它将整个模型泵出到磁盘（大约100 MB）中，然后代码完全自主运行，无需注册和SMS。 考虑到大多数现代AI服务只能在服务器上运行，而没有Internet，设备会变成“南瓜”，这特别好。 <br><br><h2> 猫与狗 </h2><br> 考虑以下问题。 使用Keras，我们将创建一个可以区分猫和狗的神经网络。 这将是一个卷积神经网络（CNN-卷积神经网络），我们将从<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">本</a>出版物中借鉴网络设计。  tensorflow_datasets包中已包含一组训练的猫和狗的图像，因此您不必自己拍摄它们。 <br><br> 我们加载一组图像并将其分为三个块-训练，验证和测试。 我们对每张图片进行“归一化”，使颜色达到0.1.1的范围。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow_datasets <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tfds <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time IMAGE_SIZE = <span class="hljs-number"><span class="hljs-number">64</span></span> IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>) splits = tfds.Split.TRAIN.subsplit(weighted=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) (cat_train, cat_valid, cat_test), info = tfds.load(<span class="hljs-string"><span class="hljs-string">'cats_vs_dogs'</span></span>, split=list(splits), with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) label_names = info.features[<span class="hljs-string"><span class="hljs-string">'label'</span></span>].int2str <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">pre_process_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image, label)</span></span></span><span class="hljs-function">:</span></span> image = tf.cast(image, tf.float32) image = image / <span class="hljs-number"><span class="hljs-number">255.0</span></span> <span class="hljs-comment"><span class="hljs-comment"># Normalize image: 0..255 -&gt; 0..1 image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE)) return image, label BATCH_SIZE = 32 SHUFFLE_BUFFER_SIZE = 1000 train_batch = cat_train.map(pre_process_image).shuffle(SHUFFLE_BUFFER_SIZE).repeat().batch(BATCH_SIZE) validation_batch = cat_valid.map(pre_process_image).repeat().batch(BATCH_SIZE)</span></span></code> </pre><br> 我们编写了生成卷积神经网络的功能。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">custom_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Source: https://medium.com/@ferhat00/deep-learning-with-keras-classifying-cats-and-dogs-part-1-982067594856 classifier = tf.keras.Sequential() # Step 1 — Convolution classifier.add(layers.Conv2D(32, (3, 3), input_shape=IMG_SHAPE, activation='relu')) # Step 2 — Pooling classifier.add(layers.MaxPooling2D(pool_size=(2, 2))) # Adding a second convolutional layer classifier.add(layers.Conv2D(32, (3, 3), activation='relu')) classifier.add(layers.MaxPooling2D(pool_size=(2, 2))) # Step 3 — Flattening classifier.add(layers.Flatten()) # Step 4 — Full connection classifier.add(layers.Dense(units=128, activation='relu')) classifier.add(layers.Dense(units=1, activation='sigmoid')) # Compiling the CNN we shall use the Adam stochastic optimisation method, binary cross entropy loss function classifier.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy']) return classifier</span></span></code> </pre><br> 现在，我们可以在“猫狗”工具包上进行网络培训。 培训需要很长时间（在GPU上需要20分钟，在CPU上需要1-2小时），因此最后我们将模型保存到文件中。 <br><br><pre> <code class="python hljs">tl_model = custom_model() t_start = time.time() tl_model.fit(train_batch, steps_per_epoch=<span class="hljs-number"><span class="hljs-number">8000</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">2</span></span>, validation_data=validation_batch, validation_steps=<span class="hljs-number"><span class="hljs-number">10</span></span>, callbacks=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>) print(<span class="hljs-string"><span class="hljs-string">"Training done, dT:"</span></span>, time.time() - t_start) print(tl_model.summary()) validation_steps = <span class="hljs-number"><span class="hljs-number">20</span></span> loss0, accuracy0 = tl_model.evaluate(validation_batch, steps=validation_steps) print(<span class="hljs-string"><span class="hljs-string">"Loss: {:.2f}"</span></span>.format(loss0)) print(<span class="hljs-string"><span class="hljs-string">"Accuracy: {:.2f}"</span></span>.format(accuracy0)) tl_model.save(<span class="hljs-string"><span class="hljs-string">"dog_cat_model.h5"</span></span>)</code> </pre><br> 顺便说一句，直接在Jetson Nano上进行培训的尝试失败了-5分钟后，主板过热并挂了。 对于资源密集型计算，电路板需要一个冷却器，尽管总的来说，直接在Jetson Nano上执行此类任务没有任何意义-您可以在PC上训练模型并在Nano上使用完成的保存文件。 <br><br> 然后又出现了一个陷阱-在PC上安装了tensowflow版本14库，到目前为止，Jetson Nano的最新版本是13。而且在第13版中没有读取保存在第14版中的模型，我不得不使用pip安装相同的版本。 <br><br> 最后，我们可以从文件中加载模型并使用它来识别图像。 <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">predict_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, image_file)</span></span></span><span class="hljs-function">:</span></span> img = image.load_img(image_file, target_size=(IMAGE_SIZE, IMAGE_SIZE)) t_start = time.time() img_arr = np.expand_dims(img, axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) result = model.predict_classes(img_arr) print(<span class="hljs-string"><span class="hljs-string">"Result: {}, dT: {}"</span></span>.format(label_names(result[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>]), time.time() - t_start)) model = tf.keras.models.load_model(<span class="hljs-string"><span class="hljs-string">'dog_cat_model.h5'</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"cat.png"</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"dog1.png"</span></span>) predict_model(model, <span class="hljs-string"><span class="hljs-string">"dog2.png"</span></span>)</code> </pre><br> 猫的照片使用了相同的照片，但“狗”测试使用了2张照片： <br><br><img src="https://habrastorage.org/webt/2m/0m/6f/2m0m6fvejlzvcdfuewdq2m9b5ug.png"><br><br> 第一个猜对了，第二个开始有错误，神经网络认为那是一只猫，我不得不增加训练的迭代次数。 但是，我可能第一次会犯一个错误； <br><br> 事实证明，在Jetson Nano上的执行时间非常短-第一张照片的处理时间为0.3秒，但随后的所有照片都快得多，显然数据已缓存在内存中。 <br><br><img src="https://habrastorage.org/webt/hx/w1/vg/hxw1vgfb217p1usxaftimpmkybo.png"><br><br> 通常，我们可以假设在这样简单的神经网络上，即使不进行任何优化，电路板速度也足够了，即使对于实时视频，100fps也足够了。 <br><br><h2> 结论 </h2><br> 如您所见，即使成功的程度不尽相同，即使Keras和Tensorflow的标准模型也可以用于Nano。 但是，结果可以得到改善，有关优化模型和减小内存大小的说明可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a>阅读。 <br><br> 但是幸运的是，制造商已经为我们做到了。 如果读者仍然有兴趣，那么最后一部分将专门介绍针对Jetson Nano进行了优化的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">现成库</a> 。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN460971/">https://habr.com/ru/post/zh-CN460971/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN460959/index.html">微软的新技术允许真实人物的3D副本使用任何语言</a></li>
<li><a href="../zh-CN460961/index.html">在混合的Swift + Objective-C项目中设置单元测试</a></li>
<li><a href="../zh-CN460965/index.html">没有这些故事板的分割控制器</a></li>
<li><a href="../zh-CN460967/index.html">特洛伊·亨特（Troy Hunt）：针对信息技术专业人员的10项个人理财课程</a></li>
<li><a href="../zh-CN460969/index.html">玛格丽特·汉密尔顿：“他们担心男人会反抗； 却没有发生”</a></li>
<li><a href="../zh-CN460973/index.html">18650电池的接触焊接</a></li>
<li><a href="../zh-CN460979/index.html">复兴生物技术是真实且不可避免的</a></li>
<li><a href="../zh-CN460981/index.html">基于Catel框架构建的WPF应用程序配置的MVVM实现</a></li>
<li><a href="../zh-CN460983/index.html">我不是真的</a></li>
<li><a href="../zh-CN460985/index.html">2019年14种最佳看板工具</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
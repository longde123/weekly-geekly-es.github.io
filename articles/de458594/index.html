<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎅🏿 ⤴️ 🐉 Vergessen Sie nicht, die Wahrscheinlichkeit einer Antwort an den Client durch eine wiederholte Anforderung beim L7-Ausgleich zu erhöhen 🏸 🤜🏻 👎🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mit nginx zum Ausgleich des HTTP-Verkehrs auf L7-Ebene kann eine Clientanforderung an den nächsten Anwendungsserver gesendet werden, wenn das Ziel kei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vergessen Sie nicht, die Wahrscheinlichkeit einer Antwort an den Client durch eine wiederholte Anforderung beim L7-Ausgleich zu erhöhen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458594/">  Mit nginx zum Ausgleich des HTTP-Verkehrs auf L7-Ebene kann eine Clientanforderung an den nächsten Anwendungsserver gesendet werden, wenn das Ziel keine positive Antwort zurückgibt.  Ein Test des Mechanismus der passiven Überprüfung des Integritätsstatus des Anwendungsservers ergab die Mehrdeutigkeit der Dokumentation und die Spezifität der Algorithmen zum Ausschließen des Servers aus dem Pool der Produktionsserver. <br><a name="habracut"></a><br><h2>  Zusammenfassung des Ausgleichs des HTTP-Verkehrs </h2><br>  Es gibt verschiedene Möglichkeiten, den HTTP-Verkehr auszugleichen.  Auf der Ebene des OSI-Modells <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gibt es Ausgleichstechnologien</a> auf Netzwerk-, Transport- und Anwendungsebene.  Abhängig von der Größe der Anwendung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">können Kombinationen verwendet werden</a> . <br><br>  Die Technologie des Verkehrsausgleichs wirkt sich positiv auf die Anwendung und deren Wartung aus.  Hier sind einige davon.  Horizontale Skalierung der Anwendung, bei der die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Last auf mehrere Knoten verteilt wird</a> .  Geplante Außerbetriebnahme des Anwendungsservers durch Entfernen des Flusses von Clientanforderungen.  Implementierung der A / B-Teststrategie für die geänderte Anwendungsfunktionalität.  Verbesserung der Anwendungsfehlertoleranz durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Senden von Anforderungen an gut funktionierende Anwendungsserver</a> . <br><br>  Die letzte Funktion ist in zwei Modi implementiert.  Im passiven Modus wertet der Balancer im Clientverkehr die Antworten des Zielanwendungsservers aus und schließt sie unter bestimmten Bedingungen aus dem Pool der Produktionsserver aus.  Im aktiven Modus sendet der Balancer regelmäßig unabhängig voneinander Anforderungen an den Anwendungsserver an einem bestimmten URI und beschließt, diese für bestimmte Anzeichen einer Antwort aus dem Pool der Produktionsserver auszuschließen.  Anschließend gibt der Balancer unter bestimmten Bedingungen den Anwendungsserver an den Pool der Produktionsserver zurück. <br><br><h2>  Passive Überprüfung des Anwendungsservers und dessen Ausschluss aus dem Pool der Produktionsserver </h2><br>  Schauen wir uns die Prüfung des passiven Anwendungsservers in der Freeware-Edition von nginx / 1.17.0 genauer an.  Anwendungsserver werden nacheinander vom Round Robin-Algorithmus ausgewählt, ihre Gewichte sind gleich. <br><br>  Das dreistufige Diagramm zeigt einen Zeitabschnitt, der mit dem Senden einer Clientanforderung an den Anwendungsserver Nr. 2 beginnt.  Ein heller Indikator kennzeichnet die Anforderungen / Antworten zwischen dem Client und dem Balancer.  Dunkler Indikator - Anfragen / Antworten zwischen Nginx und Anwendungsservern. <br><br><img src="https://habrastorage.org/webt/vg/dl/yl/vgdlylmjdofsxs-iktkfimfaqr8.gif"><br><br>  Der dritte Schritt des Diagramms zeigt, wie der Balancer die Anforderung des Clients an den nächsten Anwendungsserver umleitet, falls der Zielserver eine Fehlerantwort gegeben hat oder überhaupt nicht geantwortet hat. <br><br>  Die Liste der HTTP- und TCP-Fehler, bei denen der Server den folgenden Server verwendet, ist in der Anweisung <i>proxy_next_upstream</i> angegeben. <br><br>  Standardmäßig leitet nginx nur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anforderungen mit idempotenten HTTP-Methoden</a> an den nächsten Anwendungsserver weiter. <br><br>  Was bekommt der Kunde?  Einerseits erhöht die Möglichkeit, eine Anforderung an den nächsten Anwendungsserver umzuleiten, die Wahrscheinlichkeit, dem Client eine zufriedenstellende Antwort zu geben, wenn der Zielserver ausfällt.  Andererseits ist es offensichtlich, dass ein sequentieller Aufruf zuerst an den Zielserver und dann an den nächsten die Gesamtantwortzeit für den Client erhöht. <br><br>  Am Ende wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://nginx.org/ru/docs/http/ngx_">die Antwort des Anwendungsservers an den</a> Client zurückgegeben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://nginx.org/ru/docs/http/ngx_">, wo der</a> <i>Zähler für</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://nginx.org/ru/docs/http/ngx_">zulässige Versuche</a> <i>proxy_next_upstream_tries endet</i> . <br><br>  Wenn Sie die Umleitungsfunktion zum nächsten Arbeitsserver verwenden, müssen Sie zusätzlich die Zeitüberschreitungen auf dem Balancer- und dem Anwendungsserver harmonisieren.  Die Obergrenze der Zeit für eine Reiseanforderung zwischen Anwendungsservern und dem Balancer ist das Client-Timeout oder die vom Unternehmen angegebene Wartezeit.  Bei der Berechnung von Zeitüberschreitungen muss auch die Marge für Netzwerkereignisse (Verzögerungen / Verluste während der Paketzustellung) berücksichtigt werden.  Wenn der Client die Sitzung jedes Mal durch eine Zeitüberschreitung beendet, während der Balancer eine garantierte Antwort erhält, ist die gute Absicht, die Anwendung zuverlässig zu machen, zwecklos. <br><br><img src="https://habrastorage.org/webt/th/wt/da/thwtdayvqkzx3tr6dvlbmou1a3q.jpeg"><br><br>  Die passive Integritätsprüfung von Anwendungsservern wird beispielsweise durch Anweisungen mit den folgenden Optionen für ihre Werte gesteuert: <br><br><pre><code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">upstream</span></span> backend { <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> app01:<span class="hljs-number"><span class="hljs-number">80</span></span> weight=<span class="hljs-number"><span class="hljs-number">1</span></span> max_fails=<span class="hljs-number"><span class="hljs-number">5</span></span> fail_timeout=<span class="hljs-number"><span class="hljs-number">100s</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> app02:<span class="hljs-number"><span class="hljs-number">80</span></span> weight=<span class="hljs-number"><span class="hljs-number">1</span></span> max_fails=<span class="hljs-number"><span class="hljs-number">5</span></span> fail_timeout=<span class="hljs-number"><span class="hljs-number">100s</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> http://backend; <span class="hljs-attribute"><span class="hljs-attribute">proxy_next_upstream</span></span> timeout http_500; <span class="hljs-attribute"><span class="hljs-attribute">proxy_next_upstream_tries</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>; ... } ... }</code> </pre> <br>  Ab dem 2. Juli <i>2019</i> wurde in der Dokumentation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://nginx.org/ru/docs/http/ngx_">festgelegt,</a> dass der Parameter <i>max_fails</i> die Anzahl der erfolglosen Versuche festlegt, mit dem Server zu arbeiten, die innerhalb der durch den Parameter <i>fail_timeout</i> angegebenen Zeit <i>erfolgen sollen</i> . <br><br>  Der Parameter <i>fail_timeout</i> legt die Zeit fest, in der die angegebene Anzahl erfolgloser Versuche, mit dem Server zu arbeiten, erfolgen muss, damit der Server als nicht verfügbar betrachtet wird.  und die Zeit, in der der Server als nicht verfügbar betrachtet wird. <br><br>  In dem angegebenen Beispiel, das Teil der Konfigurationsdatei ist, ist der Balancer so konfiguriert, dass innerhalb von 100 Sekunden 5 fehlgeschlagene Anrufe abgefangen werden. <br><br><h2>  Zurückgeben des Anwendungsservers an den Produktionsserverpool </h2><br>  Wie aus der Dokumentation hervorgeht, kann der Balancer nach <i>fail_timeout</i> den Server nicht als nicht funktionsfähig betrachten.  Leider wird in der Dokumentation nicht explizit festgelegt, wie die Serverleistung bewertet wird. <br><br>  Ohne ein Experiment kann man nur annehmen, dass der Mechanismus zum Überprüfen des Zustands dem zuvor beschriebenen ähnlich ist. <br><br><h2>  Erwartungen und Realität </h2><br>  In der dargestellten Konfiguration wird vom Balancer das folgende Verhalten erwartet: <br><br><ol><li>  Bis der Balancer den Anwendungsserver Nr. 2 aus dem Pool der Produktionsserver ausschließt, werden Clientanforderungen an ihn gesendet. </li><li>  Anforderungen, die mit einem Fehler von 500 vom Anwendungsserver Nr. 2 zurückgegeben wurden, werden an den nächsten Anwendungsserver weitergeleitet, und der Client erhält positive Antworten. </li><li>  Sobald der Balancer innerhalb von 100 Sekunden 5 Antworten mit Code 500 erhält, wird der Anwendungsserver Nr. 2 aus dem Pool der Produktionsserver ausgeschlossen.  Alle Anforderungen nach einem 100-Sekunden-Fenster werden ohne zusätzliche Zeit sofort an die verbleibenden funktionierenden Anwendungsserver gesendet. </li><li>  Nach 100 Sekunden muss der Balancer die Leistung des Anwendungsservers bewerten und an den Pool der Produktionsserver zurückgeben. </li></ol><br>  Nach Durchführung von Sachversuchen wurde nach Angaben der Balancer-Magazine festgestellt, dass Aussage Nr. 3 nicht funktioniert.  Der Balancer schließt einen <i>inaktiven</i> Server aus, sobald die Bedingung für den Parameter <i>max_fails erfüllt ist</i> .  Somit wird ein ausgefallener Server vom Dienst ausgeschlossen, ohne auf den Ablauf von 100 Sekunden zu warten.  Der Parameter <i>fail_timeout</i> spielt nur die Rolle der Obergrenze der <i>Fehlerakkumulationszeit</i> . <br><br>  Als Teil der Behauptung Nr. 4 stellt sich heraus, dass nginx die Funktionalität einer Anwendung, die zuvor von der Serverwartung ausgeschlossen war, mit nur einer Anforderung überprüft.  Und wenn der Server immer noch mit einem Fehler antwortet, <i>schlägt</i> die nächste Prüfung nach <i>fail_timeout fehl</i> . <br><br><h2>  Was fehlt? </h2><br><ol><li>  Der in nginx / 1.17.0 implementierte Algorithmus ist möglicherweise nicht die fairste Methode, um die Leistung des Servers zu überprüfen, bevor er an den funktionierenden Serverpool zurückgegeben wird.  Zumindest wird gemäß der aktuellen Dokumentation nicht 1 Anforderung erwartet, sondern der in <i>max_fails</i> angegebene <i>Betrag</i> . </li><li>  Der Statusprüfungsalgorithmus berücksichtigt nicht die Geschwindigkeit von Anforderungen.  Je größer es ist, desto stärker verschiebt sich das Spektrum bei erfolglosen Versuchen nach links, und der Anwendungsserver verlässt den Arbeitsserverpool zu schnell.  Ich nehme an, dass dies sich nachteilig auf Anwendungen auswirken kann, die es sich erlauben, Fehler „kurzzeitig“ zu erzeugen.  Zum Beispiel beim Sammeln von Müll. </li></ol><br><img src="https://habrastorage.org/webt/dg/5k/t2/dg5kt2myincbznycsx2owz_rh6w.jpeg"><br><br>  Ich wollte Sie fragen, ob der Algorithmus zur Überprüfung des Serverzustands, der die Geschwindigkeit fehlgeschlagener Versuche misst, einen praktischen Nutzen bringt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458594/">https://habr.com/ru/post/de458594/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458572/index.html">Anatoly Slyusar: „Die Zeit des EU-Computers ermöglichte es uns, System- und angewandte Programmierer auszubilden.“</a></li>
<li><a href="../de458574/index.html">Wie man von einem Entwickler zu einem Teamleiter heranwächst und weiter damit lebt</a></li>
<li><a href="../de458582/index.html">Der Ingenieur von Amazon hat ein KI-Blockierungsgerät entwickelt, das Katzen von der Straße fernhält</a></li>
<li><a href="../de458584/index.html">11. Juli, Group-IB-Webinar „Malware-Analyse für Anfänger: Grundlegende Ansätze“</a></li>
<li><a href="../de458592/index.html">Von der hohen Ceph-Latenz zum Kernel-Patch mit eBPF / BCC</a></li>
<li><a href="../de458596/index.html">Kleine Freude # 6: OpenAI Gym - Spiele spielen und Roboter steuern</a></li>
<li><a href="../de458600/index.html">Was sind Elektrofahrräder (Gruppenbewertung in zwei Teilen von fünf Modellen zweier Hersteller), Teil 1</a></li>
<li><a href="../de458602/index.html">Wie wir die Great Chinese Firewall durchbohrt haben (Teil 1)</a></li>
<li><a href="../de458604/index.html">Warum sich die beiden größten Elektronikhersteller zu einem neuen GPU-Projekt zusammengeschlossen haben</a></li>
<li><a href="../de458606/index.html">Führen Sie OpenVPN in Docker in 2 Sekunden aus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
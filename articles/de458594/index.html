<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéÖüèø ‚§¥Ô∏è üêâ Vergessen Sie nicht, die Wahrscheinlichkeit einer Antwort an den Client durch eine wiederholte Anforderung beim L7-Ausgleich zu erh√∂hen üè∏ ü§úüèª üëéüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mit nginx zum Ausgleich des HTTP-Verkehrs auf L7-Ebene kann eine Clientanforderung an den n√§chsten Anwendungsserver gesendet werden, wenn das Ziel kei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vergessen Sie nicht, die Wahrscheinlichkeit einer Antwort an den Client durch eine wiederholte Anforderung beim L7-Ausgleich zu erh√∂hen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458594/">  Mit nginx zum Ausgleich des HTTP-Verkehrs auf L7-Ebene kann eine Clientanforderung an den n√§chsten Anwendungsserver gesendet werden, wenn das Ziel keine positive Antwort zur√ºckgibt.  Ein Test des Mechanismus der passiven √úberpr√ºfung des Integrit√§tsstatus des Anwendungsservers ergab die Mehrdeutigkeit der Dokumentation und die Spezifit√§t der Algorithmen zum Ausschlie√üen des Servers aus dem Pool der Produktionsserver. <br><a name="habracut"></a><br><h2>  Zusammenfassung des Ausgleichs des HTTP-Verkehrs </h2><br>  Es gibt verschiedene M√∂glichkeiten, den HTTP-Verkehr auszugleichen.  Auf der Ebene des OSI-Modells <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gibt es Ausgleichstechnologien</a> auf Netzwerk-, Transport- und Anwendungsebene.  Abh√§ngig von der Gr√∂√üe der Anwendung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">k√∂nnen Kombinationen verwendet werden</a> . <br><br>  Die Technologie des Verkehrsausgleichs wirkt sich positiv auf die Anwendung und deren Wartung aus.  Hier sind einige davon.  Horizontale Skalierung der Anwendung, bei der die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Last auf mehrere Knoten verteilt wird</a> .  Geplante Au√üerbetriebnahme des Anwendungsservers durch Entfernen des Flusses von Clientanforderungen.  Implementierung der A / B-Teststrategie f√ºr die ge√§nderte Anwendungsfunktionalit√§t.  Verbesserung der Anwendungsfehlertoleranz durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Senden von Anforderungen an gut funktionierende Anwendungsserver</a> . <br><br>  Die letzte Funktion ist in zwei Modi implementiert.  Im passiven Modus wertet der Balancer im Clientverkehr die Antworten des Zielanwendungsservers aus und schlie√üt sie unter bestimmten Bedingungen aus dem Pool der Produktionsserver aus.  Im aktiven Modus sendet der Balancer regelm√§√üig unabh√§ngig voneinander Anforderungen an den Anwendungsserver an einem bestimmten URI und beschlie√üt, diese f√ºr bestimmte Anzeichen einer Antwort aus dem Pool der Produktionsserver auszuschlie√üen.  Anschlie√üend gibt der Balancer unter bestimmten Bedingungen den Anwendungsserver an den Pool der Produktionsserver zur√ºck. <br><br><h2>  Passive √úberpr√ºfung des Anwendungsservers und dessen Ausschluss aus dem Pool der Produktionsserver </h2><br>  Schauen wir uns die Pr√ºfung des passiven Anwendungsservers in der Freeware-Edition von nginx / 1.17.0 genauer an.  Anwendungsserver werden nacheinander vom Round Robin-Algorithmus ausgew√§hlt, ihre Gewichte sind gleich. <br><br>  Das dreistufige Diagramm zeigt einen Zeitabschnitt, der mit dem Senden einer Clientanforderung an den Anwendungsserver Nr. 2 beginnt.  Ein heller Indikator kennzeichnet die Anforderungen / Antworten zwischen dem Client und dem Balancer.  Dunkler Indikator - Anfragen / Antworten zwischen Nginx und Anwendungsservern. <br><br><img src="https://habrastorage.org/webt/vg/dl/yl/vgdlylmjdofsxs-iktkfimfaqr8.gif"><br><br>  Der dritte Schritt des Diagramms zeigt, wie der Balancer die Anforderung des Clients an den n√§chsten Anwendungsserver umleitet, falls der Zielserver eine Fehlerantwort gegeben hat oder √ºberhaupt nicht geantwortet hat. <br><br>  Die Liste der HTTP- und TCP-Fehler, bei denen der Server den folgenden Server verwendet, ist in der Anweisung <i>proxy_next_upstream</i> angegeben. <br><br>  Standardm√§√üig leitet nginx nur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anforderungen mit idempotenten HTTP-Methoden</a> an den n√§chsten Anwendungsserver weiter. <br><br>  Was bekommt der Kunde?  Einerseits erh√∂ht die M√∂glichkeit, eine Anforderung an den n√§chsten Anwendungsserver umzuleiten, die Wahrscheinlichkeit, dem Client eine zufriedenstellende Antwort zu geben, wenn der Zielserver ausf√§llt.  Andererseits ist es offensichtlich, dass ein sequentieller Aufruf zuerst an den Zielserver und dann an den n√§chsten die Gesamtantwortzeit f√ºr den Client erh√∂ht. <br><br>  Am Ende wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://nginx.org/ru/docs/http/ngx_">die Antwort des Anwendungsservers an den</a> Client zur√ºckgegeben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://nginx.org/ru/docs/http/ngx_">, wo der</a> <i>Z√§hler f√ºr</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://nginx.org/ru/docs/http/ngx_">zul√§ssige Versuche</a> <i>proxy_next_upstream_tries endet</i> . <br><br>  Wenn Sie die Umleitungsfunktion zum n√§chsten Arbeitsserver verwenden, m√ºssen Sie zus√§tzlich die Zeit√ºberschreitungen auf dem Balancer- und dem Anwendungsserver harmonisieren.  Die Obergrenze der Zeit f√ºr eine Reiseanforderung zwischen Anwendungsservern und dem Balancer ist das Client-Timeout oder die vom Unternehmen angegebene Wartezeit.  Bei der Berechnung von Zeit√ºberschreitungen muss auch die Marge f√ºr Netzwerkereignisse (Verz√∂gerungen / Verluste w√§hrend der Paketzustellung) ber√ºcksichtigt werden.  Wenn der Client die Sitzung jedes Mal durch eine Zeit√ºberschreitung beendet, w√§hrend der Balancer eine garantierte Antwort erh√§lt, ist die gute Absicht, die Anwendung zuverl√§ssig zu machen, zwecklos. <br><br><img src="https://habrastorage.org/webt/th/wt/da/thwtdayvqkzx3tr6dvlbmou1a3q.jpeg"><br><br>  Die passive Integrit√§tspr√ºfung von Anwendungsservern wird beispielsweise durch Anweisungen mit den folgenden Optionen f√ºr ihre Werte gesteuert: <br><br><pre><code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">upstream</span></span> backend { <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> app01:<span class="hljs-number"><span class="hljs-number">80</span></span> weight=<span class="hljs-number"><span class="hljs-number">1</span></span> max_fails=<span class="hljs-number"><span class="hljs-number">5</span></span> fail_timeout=<span class="hljs-number"><span class="hljs-number">100s</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> app02:<span class="hljs-number"><span class="hljs-number">80</span></span> weight=<span class="hljs-number"><span class="hljs-number">1</span></span> max_fails=<span class="hljs-number"><span class="hljs-number">5</span></span> fail_timeout=<span class="hljs-number"><span class="hljs-number">100s</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> http://backend; <span class="hljs-attribute"><span class="hljs-attribute">proxy_next_upstream</span></span> timeout http_500; <span class="hljs-attribute"><span class="hljs-attribute">proxy_next_upstream_tries</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>; ... } ... }</code> </pre> <br>  Ab dem 2. Juli <i>2019</i> wurde in der Dokumentation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://nginx.org/ru/docs/http/ngx_">festgelegt,</a> dass der Parameter <i>max_fails</i> die Anzahl der erfolglosen Versuche festlegt, mit dem Server zu arbeiten, die innerhalb der durch den Parameter <i>fail_timeout</i> angegebenen Zeit <i>erfolgen sollen</i> . <br><br>  Der Parameter <i>fail_timeout</i> legt die Zeit fest, in der die angegebene Anzahl erfolgloser Versuche, mit dem Server zu arbeiten, erfolgen muss, damit der Server als nicht verf√ºgbar betrachtet wird.  und die Zeit, in der der Server als nicht verf√ºgbar betrachtet wird. <br><br>  In dem angegebenen Beispiel, das Teil der Konfigurationsdatei ist, ist der Balancer so konfiguriert, dass innerhalb von 100 Sekunden 5 fehlgeschlagene Anrufe abgefangen werden. <br><br><h2>  Zur√ºckgeben des Anwendungsservers an den Produktionsserverpool </h2><br>  Wie aus der Dokumentation hervorgeht, kann der Balancer nach <i>fail_timeout</i> den Server nicht als nicht funktionsf√§hig betrachten.  Leider wird in der Dokumentation nicht explizit festgelegt, wie die Serverleistung bewertet wird. <br><br>  Ohne ein Experiment kann man nur annehmen, dass der Mechanismus zum √úberpr√ºfen des Zustands dem zuvor beschriebenen √§hnlich ist. <br><br><h2>  Erwartungen und Realit√§t </h2><br>  In der dargestellten Konfiguration wird vom Balancer das folgende Verhalten erwartet: <br><br><ol><li>  Bis der Balancer den Anwendungsserver Nr. 2 aus dem Pool der Produktionsserver ausschlie√üt, werden Clientanforderungen an ihn gesendet. </li><li>  Anforderungen, die mit einem Fehler von 500 vom Anwendungsserver Nr. 2 zur√ºckgegeben wurden, werden an den n√§chsten Anwendungsserver weitergeleitet, und der Client erh√§lt positive Antworten. </li><li>  Sobald der Balancer innerhalb von 100 Sekunden 5 Antworten mit Code 500 erh√§lt, wird der Anwendungsserver Nr. 2 aus dem Pool der Produktionsserver ausgeschlossen.  Alle Anforderungen nach einem 100-Sekunden-Fenster werden ohne zus√§tzliche Zeit sofort an die verbleibenden funktionierenden Anwendungsserver gesendet. </li><li>  Nach 100 Sekunden muss der Balancer die Leistung des Anwendungsservers bewerten und an den Pool der Produktionsserver zur√ºckgeben. </li></ol><br>  Nach Durchf√ºhrung von Sachversuchen wurde nach Angaben der Balancer-Magazine festgestellt, dass Aussage Nr. 3 nicht funktioniert.  Der Balancer schlie√üt einen <i>inaktiven</i> Server aus, sobald die Bedingung f√ºr den Parameter <i>max_fails erf√ºllt ist</i> .  Somit wird ein ausgefallener Server vom Dienst ausgeschlossen, ohne auf den Ablauf von 100 Sekunden zu warten.  Der Parameter <i>fail_timeout</i> spielt nur die Rolle der Obergrenze der <i>Fehlerakkumulationszeit</i> . <br><br>  Als Teil der Behauptung Nr. 4 stellt sich heraus, dass nginx die Funktionalit√§t einer Anwendung, die zuvor von der Serverwartung ausgeschlossen war, mit nur einer Anforderung √ºberpr√ºft.  Und wenn der Server immer noch mit einem Fehler antwortet, <i>schl√§gt</i> die n√§chste Pr√ºfung nach <i>fail_timeout fehl</i> . <br><br><h2>  Was fehlt? </h2><br><ol><li>  Der in nginx / 1.17.0 implementierte Algorithmus ist m√∂glicherweise nicht die fairste Methode, um die Leistung des Servers zu √ºberpr√ºfen, bevor er an den funktionierenden Serverpool zur√ºckgegeben wird.  Zumindest wird gem√§√ü der aktuellen Dokumentation nicht 1 Anforderung erwartet, sondern der in <i>max_fails</i> angegebene <i>Betrag</i> . </li><li>  Der Statuspr√ºfungsalgorithmus ber√ºcksichtigt nicht die Geschwindigkeit von Anforderungen.  Je gr√∂√üer es ist, desto st√§rker verschiebt sich das Spektrum bei erfolglosen Versuchen nach links, und der Anwendungsserver verl√§sst den Arbeitsserverpool zu schnell.  Ich nehme an, dass dies sich nachteilig auf Anwendungen auswirken kann, die es sich erlauben, Fehler ‚Äûkurzzeitig‚Äú zu erzeugen.  Zum Beispiel beim Sammeln von M√ºll. </li></ol><br><img src="https://habrastorage.org/webt/dg/5k/t2/dg5kt2myincbznycsx2owz_rh6w.jpeg"><br><br>  Ich wollte Sie fragen, ob der Algorithmus zur √úberpr√ºfung des Serverzustands, der die Geschwindigkeit fehlgeschlagener Versuche misst, einen praktischen Nutzen bringt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458594/">https://habr.com/ru/post/de458594/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458572/index.html">Anatoly Slyusar: ‚ÄûDie Zeit des EU-Computers erm√∂glichte es uns, System- und angewandte Programmierer auszubilden.‚Äú</a></li>
<li><a href="../de458574/index.html">Wie man von einem Entwickler zu einem Teamleiter heranw√§chst und weiter damit lebt</a></li>
<li><a href="../de458582/index.html">Der Ingenieur von Amazon hat ein KI-Blockierungsger√§t entwickelt, das Katzen von der Stra√üe fernh√§lt</a></li>
<li><a href="../de458584/index.html">11. Juli, Group-IB-Webinar ‚ÄûMalware-Analyse f√ºr Anf√§nger: Grundlegende Ans√§tze‚Äú</a></li>
<li><a href="../de458592/index.html">Von der hohen Ceph-Latenz zum Kernel-Patch mit eBPF / BCC</a></li>
<li><a href="../de458596/index.html">Kleine Freude # 6: OpenAI Gym - Spiele spielen und Roboter steuern</a></li>
<li><a href="../de458600/index.html">Was sind Elektrofahrr√§der (Gruppenbewertung in zwei Teilen von f√ºnf Modellen zweier Hersteller), Teil 1</a></li>
<li><a href="../de458602/index.html">Wie wir die Great Chinese Firewall durchbohrt haben (Teil 1)</a></li>
<li><a href="../de458604/index.html">Warum sich die beiden gr√∂√üten Elektronikhersteller zu einem neuen GPU-Projekt zusammengeschlossen haben</a></li>
<li><a href="../de458606/index.html">F√ºhren Sie OpenVPN in Docker in 2 Sekunden aus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
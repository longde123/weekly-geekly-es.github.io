<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游뚠 游 久쥞잺 C칩mo ayudamos a CDN MegaFon.TV a no llegar a la Copa Mundial 2018 游닆 游놏 游땼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En 2016, hablamos sobre c칩mo MegaFon.TV hizo frente a todos los que quer칤an ver la nueva temporada de Game of Thrones. El desarrollo del servicio no s...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C칩mo ayudamos a CDN MegaFon.TV a no llegar a la Copa Mundial 2018</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/megafon/blog/425229/">  En 2016, hablamos sobre c칩mo MegaFon.TV hizo frente a todos los que quer칤an ver la nueva temporada de Game of Thrones.  El desarrollo del servicio no se detuvo all칤, y a mediados de 2017 tuvimos que lidiar con cargas varias veces m치s.  En esta publicaci칩n, diremos c칩mo un crecimiento tan r치pido nos inspir칩 a cambiar radicalmente el enfoque para organizar CDN y c칩mo este nuevo enfoque fue probado por la Copa del Mundo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a42/af2/54b/a42af254b7c4d8528fb0d495c27ab6d9.png"><br><a name="habracut"></a><br><h2>  Brevemente sobre MegaFon.TV </h2><br>  MegaFon.TV es un servicio OTT para ver diversos contenidos de video: pel칤culas, programas de televisi칩n, canales de televisi칩n y programas grabados.  A trav칠s de MegaFon.TV, se puede obtener acceso al contenido en pr치cticamente cualquier dispositivo: en tel칠fonos y tabletas con iOS y Android, en televisores inteligentes LG, Samsung, Philips, Panasonic de diferentes a침os de lanzamiento, con todo un zool칩gico de SO (Apple TV, Android TV), en navegadores de escritorio en Windows, MacOS, Linux, en navegadores m칩viles en iOS y Android, e incluso en dispositivos tan ex칩ticos como STB y proyectores de Android para ni침os.  Pr치cticamente no hay restricciones en los dispositivos: solo es importante la disponibilidad de Internet con un ancho de banda de 700 Kbps.  Sobre c칩mo organizamos el soporte para tantos dispositivos, habr치 un art칤culo separado en el futuro. <br>  La mayor칤a de los usuarios del servicio son suscriptores de MegaFon, lo que se explica por las ofertas rentables (y casi siempre incluso gratuitas) incluidas en el plan de tarifas del suscriptor.  Aunque tambi칠n notamos un aumento significativo en los usuarios de otros operadores.  De acuerdo con esta distribuci칩n, el 80% del tr치fico de MegaFon.TV se consume dentro de la red MegaFon. <br><br>  Arquitect칩nicamente, desde el lanzamiento del servicio, el contenido se ha distribuido a trav칠s de CDN.  Tenemos una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaci칩n</a> separada dedicada al trabajo de este CDN.  En 칠l, hablamos sobre c칩mo nos permiti칩 manejar el tr치fico pico que entr칩 al servicio a fines de 2016, durante el lanzamiento de la nueva temporada de Game of Thrones.  En esta publicaci칩n, hablaremos sobre el mayor desarrollo de MegaFon.TV y sobre nuevas aventuras que han ca칤do en el servicio junto con la Copa Mundial 2018. <br><br><h2>  Servicio de crecimiento.  Y problemas </h2><br>  En comparaci칩n con los eventos de la 칰ltima publicaci칩n, a finales de 2017 el n칰mero de usuarios de Megafon.TV ha aumentado varias veces, las pel칤culas y series tambi칠n se han vuelto un orden de magnitud m치s grande.  Se lanz칩 una nueva funcionalidad, aparecieron nuevos paquetes, disponibles "por suscripci칩n".  Los picos de tr치fico desde el "Juego de Tronos" que vemos ahora todos los d칤as, la proporci칩n de pel칤culas y programas de televisi칩n en la corriente total ha aumentado constantemente. <br><br>  Junto con esto, los problemas comenzaron con la redistribuci칩n del tr치fico.  Nuestro monitoreo, configurado para descargar fragmentos para diferentes tipos de tr치fico en diferentes formatos, comenz칩 a producir cada vez m치s errores al descargar fragmentos de video por tiempo de espera.  En el servicio MegaFon.TV, la longitud del fragmento es de 8 segundos.  Si el fragmento no tiene tiempo para cargar en 8 segundos, pueden producirse errores. <br><br>  Se esperaba que el pico de errores ocurriera en las horas m치s ocupadas.  쮺칩mo deber칤a afectar esto a los usuarios?  Como m칤nimo, pudieron observar un deterioro en la calidad del video.  No siempre se nota a simple vista, debido a un n칰mero suficientemente grande de perfiles de velocidad de bits m칰ltiple.  En el peor de los casos, el video se congela. <br><br>  La b칰squeda del problema comenz칩.  Casi de inmediato, qued칩 claro que se produce un error de retroceso en los servidores EDGE de CDN.  Aqu칤 tenemos que hacer una peque침a digresi칩n y decir c칩mo funcionan los servidores con tr치fico en vivo y VOD.  El esquema es un poco diferente.  Un usuario que acude al servidor EDGE en busca de contenido (una lista de reproducci칩n o fragmento), si hay contenido en el cach칠, lo obtiene desde all칤.  De lo contrario, el servidor EDGE busca contenido en Origin y carga el canal principal.  Junto con una lista de reproducci칩n o un fragmento, se proporciona el encabezado <b>Cache-Control: max-age</b> , que le indica al servidor EDGE cu치nto almacenar en cach칠 esta o aquella unidad de contenido.  La diferencia entre LIVE y VOD radica en el tiempo que lleva almacenar en cach칠 los fragmentos.  Para fragmentos en vivo, se establece un tiempo de almacenamiento en cach칠 corto, generalmente de 30 segundos a varios minutos, esto se debe al poco tiempo de relevancia del contenido en vivo.  Este cach칠 se almacena en la RAM, ya que debe proporcionar constantemente fragmentos y reescribir el cach칠.  Para los fragmentos de VOD, se establece m치s tiempo, desde varias horas hasta semanas e incluso meses, dependiendo del tama침o de la biblioteca de contenido y la distribuci칩n de sus vistas entre los usuarios.  En cuanto a las listas de reproducci칩n, generalmente se almacenan en cach칠 en no m치s de dos segundos, o no se almacenan en cach칠 en absoluto.  Vale la pena aclarar que solo estamos hablando del llamado modo PULL de CDN, en el que funcionaban nuestros servidores.  Usar el modo PUSH en nuestro caso no estar칤a completamente justificado. <br><br>  Pero volvamos a encontrar el problema.  Como ya hemos notado, todos los servidores trabajaron simult치neamente en la devoluci칩n de ambos tipos de contenido.  Al mismo tiempo, los propios servidores ten칤an una configuraci칩n diferente.  Como resultado, algunas m치quinas se sobrecargaron con IOPS.  Los fragmentos no tuvieron tiempo de escribir / leer debido al peque침o rendimiento, cantidad, volumen de discos, gran biblioteca de contenido.  Por otro lado, las m치quinas m치s potentes que recibieron m치s tr치fico comenzaron a fallar en el uso de la CPU.  Los recursos de la CPU se gastaron en atender el tr치fico SSL y los fragmentos entregados a trav칠s de https, mientras que los IOPS en los discos apenas alcanzaron el 35%. <br><br>  Lo que se necesitaba era un esquema que, a un costo m칤nimo, hiciera posible utilizar las capacidades disponibles de manera 칩ptima.  Adem치s, seis meses m치s tarde comenzar칤a la Copa del Mundo y, seg칰n c치lculos preliminares, los picos en el tr치fico en vivo deber칤an haber aumentado seis veces ... <br><br><h2>  Nuevo enfoque para CDN </h2><br>  Despu칠s de analizar el problema, decidimos separar el VOD y el tr치fico en vivo de acuerdo con diferentes PAD compuestos por servidores con diferentes configuraciones.  Y tambi칠n cree una funci칩n de distribuci칩n de tr치fico y su equilibrio entre diferentes grupos de servidores.  Hab칤a tres de esos grupos en total: <br><br><ul><li>  Servidores con una gran cantidad de discos de alto rendimiento que son los m치s adecuados para almacenar en cach칠 el contenido de VOD.  De hecho, los discos SSD RI de la capacidad m치xima ser칤an los m치s adecuados, pero no hab칤a ninguno, y se necesitar칤a demasiado presupuesto para comprar la cantidad correcta.  Al final, se decidi칩 usar lo mejor que estaba disponible.  Cada servidor conten칤a ocho discos SAS de 1TB y 10k en RAID5.  De estos servidores se compil칩 VOD_PAD. <br></li><li>  Servidores con una gran cantidad de RAM para almacenar en cach칠 todos los formatos posibles para la entrega de fragmentos en vivo, con procesadores capaces de manejar tr치fico SSL e interfaces de red "gruesas".  Utilizamos la siguiente configuraci칩n: 2 procesadores de 8 n칰cleos / 192 GB de RAM / 4 interfaces de 10 GB.  De estos servidores se compil칩 EDGE_PAD. <br></li><li>  El grupo de servidores restante no puede manejar el tr치fico VOD, pero es adecuado para peque침os vol칰menes de contenido en vivo.  Se pueden usar como reserva.  De los servidores RESERVE_PAD fue compilado. <br></li></ul><br>  La distribuci칩n fue la siguiente: <br><img src="https://habrastorage.org/getpro/habr/post_images/3ed/17c/dbf/3ed17cdbf13920eae4c06067e2edd296.png"><br>  Un m칩dulo l칩gico especial se encargaba de elegir el PAD del que se supon칤a que el usuario recibir칤a el contenido.  Aqu칤 est치n sus tareas: <br><ul><li>  Analice la URL, aplique el esquema anterior para cada solicitud de transmisi칩n y emita el PAD requerido <br></li><li>  Descargue las interfaces EDGE_PAD cada 5 minutos ( <i>y este fue nuestro error</i> ), y cuando se alcanza el l칤mite, cambie el exceso de tr치fico a RESERVE_PAD.  Para aliviar la carga, se escribi칩 un peque침o script perl que devolvi칩 los siguientes datos: <br>  - <b>marca de tiempo</b> : fecha y hora de actualizaci칩n de los datos de carga (en formato RFC 3339); <br>  - <b>total_bandwidth</b> - carga actual de la interfaz (total), Kbps; <br>  - <b>rx_bandwidth</b> - carga actual de la interfaz (tr치fico entrante), Kbps; <br>  - <b>tx_badwidth</b> : carga actual de la interfaz (tr치fico saliente), Kbps. <br></li><li>  Dirija el tr치fico en modo manual a cualquier PAD u servidor de Origin en caso de situaciones imprevistas, o si es necesario, trabaje en uno de los PAD.  La configuraci칩n estaba en el servidor en formato yaml y permit칤a llevar todo el tr치fico al PAD deseado, o el tr치fico de acuerdo con uno de los par치metros: <br>  - Tipo de contenido <br>  - cifrado de tr치fico <br>  - Tr치fico pagado <br>  - tipo de dispositivo <br>  - Tipo de lista de reproducci칩n <br>  - Regi칩n <br></li></ul><br>  Los servidores de origen han sido SSD con poco personal.  Desafortunadamente, al cambiar el tr치fico a Origin, HIT_RATE en fragmentos VOD dej칩 mucho que desear (alrededor del 30%), pero realizaron su tarea, por lo que no observamos ning칰n problema con los empaquetadores en CNN. <br><br>  Como hab칤a pocos servidores para la configuraci칩n EDGE_PAD, se decidi칩 asignarlos en las regiones con la mayor proporci칩n de tr치fico: Mosc칰 y la regi칩n del Volga.  Con la ayuda de GeoDNS, el tr치fico se envi칩 a la regi칩n del Volga desde las regiones de los distritos federales de Volga y Ural.  El centro de Mosc칰 sirvi칩 al resto.  Realmente no nos gust칩 la idea de entregar tr치fico a Siberia y el Lejano Oriente desde Mosc칰, pero en total estas regiones representan aproximadamente 1/20 de todo el tr치fico, y los canales de MegaFon resultaron ser lo suficientemente amplios para tales vol칰menes. <br>  Despu칠s del desarrollo del plan, se realiz칩 el siguiente trabajo: <br><br><ul><li>  En dos semanas, desarroll칩 la funcionalidad de cambiar CDN <br></li><li>  Se tard칩 un mes en instalar y configurar los servidores EDGE_PAD, as칤 como expandir los canales para ellos. <br></li><li>  Tom칩 dos semanas dividir el grupo de servidores actual en dos partes, m치s otras dos semanas para aplicar la configuraci칩n a todos los servidores en la red y el equipo del servidor <br></li><li>  Y, finalmente, la semana se dedic칩 a las pruebas (desafortunadamente, no bajo carga, lo que luego afect칩) <br></li></ul><br>  Result칩 paralelizar parte del trabajo, y al final todo tom칩 seis semanas. <br><br><h2>  Primeros resultados y planes futuros </h2><br>  Despu칠s de la optimizaci칩n, el rendimiento general del sistema fue de 250 Gb / s.  La soluci칩n con la transferencia del tr치fico VOD a servidores separados mostr칩 inmediatamente su eficacia despu칠s de su lanzamiento a producci칩n.  Desde el comienzo de la Copa del Mundo, no ha habido problemas con el tr치fico de VOD.  Varias veces, por varias razones, tuve que cambiar el tr치fico de VOD a Origin, pero en principio, tambi칠n se las arreglaron.  Quiz치s este esquema no sea muy efectivo debido al uso muy peque침o de la memoria cach칠, ya que obligamos a los SSD a sobrescribir constantemente el contenido.  Pero el circuito funciona. <br><br>  En cuanto al tr치fico en vivo, los vol칰menes correspondientes para probar nuestra decisi칩n aparecieron con el inicio de la Copa del Mundo.  Los problemas comenzaron cuando la segunda vez que enfrentamos el cambio de tr치fico cuando llegamos al l칤mite durante el partido Rusia-Egipto.  Cuando el cambio de tr치fico funcion칩, todo se verti칩 en el PAD de respaldo.  En estos cinco minutos, el n칰mero de solicitudes (curva de crecimiento) fue tan grande que la CDN de respaldo se obstruy칩 por completo y comenz칩 a generar errores.  Al mismo tiempo, el PAD principal se lanz칩 durante este tiempo y comenz칩 a permanecer inactivo un poco: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ae7/5a6/804/ae75a68044b8150556324ccfbde19827.png"><br><br>  De esto se extrajeron 3 conclusiones: <br><br><ol><li>  Cinco minutos todav칤a es demasiado.  Se decidi칩 reducir el per칤odo de descarga a 30 segundos.  Como resultado, el tr치fico en el PAD en espera dej칩 de crecer espasm칩dicamente: <br><img src="https://habrastorage.org/getpro/habr/post_images/f73/e8d/47a/f73e8d47a26d62c8fc6d82f88d442fad.png"><br></li><li>  Como m칤nimo, es necesario transferir usuarios entre PAD cada vez que se activa el interruptor.  Esto deber칤a proporcionar suavidad adicional de conmutaci칩n.  Decidimos asignar una cookie a cada usuario (o m치s bien al dispositivo), seg칰n el cual el m칩dulo responsable de la distribuci칩n comprende si el usuario debe dejarse en el PAD actual o si se debe realizar el cambio.  Aqu칤 la tecnolog칤a puede quedar a discreci칩n de quien la implemente.  Como resultado, no soltamos el tr치fico en el PAD principal. <br></li><li>  El umbral para la conmutaci칩n se estableci칩 demasiado bajo, como resultado, el tr치fico en el PAD de respaldo creci칩 como una avalancha.  En nuestro caso, fue un reaseguro: no est치bamos completamente seguros de haber hecho el ajuste correcto del servidor (la idea, por cierto, fue tomada de Habr).  El umbral se ha incrementado para el rendimiento f칤sico de las interfaces de red. <br></li></ol><br>  Las mejoras tomaron tres d칤as, y ya en el partido Rusia-Croacia, verificamos si nuestra optimizaci칩n funcion칩.  En general, el resultado nos agrad칩.  En su apogeo, el sistema proces칩 215 Gbit / s de tr치fico mixto.  Este no era un l칤mite te칩rico en el rendimiento del sistema: todav칤a ten칤amos un margen sustancial.  Si es necesario, ahora podemos conectar cualquier CDN externo, si es necesario, y "tirar" el exceso de tr치fico all칤.  Tal modelo es bueno cuando no desea pagar dinero s칩lido cada mes por usar el CDN de otra persona. <br><br>  Nuestros planes incluyen un mayor desarrollo de CDN.  Para empezar, me gustar칤a extender el esquema EDGE_PAD a todos los distritos federales; esto conducir치 a un menor uso de canales.  Tambi칠n se est치n realizando pruebas de circuito de redundancia VOD_PAD, y algunos de los resultados ahora parecen bastante impresionantes. <br><br>  En general, todo lo hecho durante el a침o pasado me lleva a pensar que la CDN del servicio que distribuye contenido de video es imprescindible.  Y ni siquiera porque le permite ahorrar mucho dinero, sino porque el CDN se convierte en parte del servicio en s칤, afecta directamente la calidad y la funcionalidad.  En tales circunstancias, entregarlo en las manos equivocadas es al menos irrazonable. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es425229/">https://habr.com/ru/post/es425229/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es425219/index.html">Qu칠 es la salud mental: una perspectiva desde la psicolog칤a / psicoterapia</a></li>
<li><a href="../es425221/index.html">C칩mo hacer pl치stico para impresi칩n 3D</a></li>
<li><a href="../es425223/index.html">Aplicaciones de Android JPHP</a></li>
<li><a href="../es425225/index.html">C칩mo ver los enlaces dentro de su m칩dulo PowerShell</a></li>
<li><a href="../es425227/index.html">Los investigadores han encontrado una manera de detectar y omitir las claves Honeytoken en varios servicios de Amazon.</a></li>
<li><a href="../es425231/index.html">Preguntas frecuentes sobre el trabajo de una azafata</a></li>
<li><a href="../es425233/index.html">Python 3 en Facebook</a></li>
<li><a href="../es425235/index.html">Un poco m치s sobre gr치ficos, o c칩mo detectar dependencias entre sus aplicaciones</a></li>
<li><a href="../es425237/index.html">Medici칩n de tiempo con precisi칩n de nanosegundos</a></li>
<li><a href="../es425241/index.html">Desarrollador 20 a침os despu칠s: Vasily Lebedev sobre ICRE, educaci칩n, su libro y programaci칩n.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
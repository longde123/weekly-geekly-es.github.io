<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèº‚Äçüè≠ ‚úãüèæ üõ•Ô∏è Algoritmos obrigat√≥rios de aprendizado de m√°quina üêû üëßüèø üëáüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Habr, ol√°. 

 Este post √© uma breve vis√£o geral dos algoritmos gerais de aprendizado de m√°quina. Cada um √© acompanhado por uma breve descri√ß√£o, guias ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Algoritmos obrigat√≥rios de aprendizado de m√°quina</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/467825/">  Habr, ol√°. <br><br>  Este post √© uma breve vis√£o geral dos algoritmos gerais de aprendizado de m√°quina.  Cada um √© acompanhado por uma breve descri√ß√£o, guias e links √∫teis. <br><br><h2>  M√©todo do componente principal (PCA) / SVD </h2><br>  Este √© um dos algoritmos b√°sicos de aprendizado de m√°quina.  Permite reduzir a dimensionalidade dos dados, perdendo a menor quantidade de informa√ß√µes.  √â usado em muitos campos, como reconhecimento de objetos, vis√£o computacional, compacta√ß√£o de dados, etc. O c√°lculo dos componentes principais se reduz ao c√°lculo dos vetores pr√≥prios e valores pr√≥prios da matriz de covari√¢ncia dos dados de origem ou √† decomposi√ß√£o singular da matriz de dados. <br><br><img src="https://habrastorage.org/webt/q1/s1/jh/q1s1jh5xtwmuvbklcbapvgcmk4a.png" alt="imagem"><br><br>  SVD √© uma maneira de calcular componentes encomendados. <br><br>  Links √∫teis: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">scipy.linalg.svd</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.decomposition.pca</a> </li></ul><br>  Guia Introdut√≥rio: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tutorial b√°sico de an√°lise de componentes</a> </li></ul><a name="habracut"></a><br><h2>  M√©todo dos m√≠nimos quadrados </h2><br>  O m√©todo dos m√≠nimos quadrados √© um m√©todo matem√°tico usado para resolver v√°rios problemas, com base na minimiza√ß√£o da soma dos quadrados dos desvios de algumas fun√ß√µes das vari√°veis ‚Äã‚Äãdesejadas.  Pode ser usado para "resolver" sistemas de equa√ß√µes sobredeterminados (quando o n√∫mero de equa√ß√µes excede o n√∫mero de inc√≥gnitas), para encontrar uma solu√ß√£o no caso de sistemas de equa√ß√µes n√£o-lineares comuns (n√£o redefinidos) e tamb√©m para aproximar os valores pontuais de uma fun√ß√£o. <br><br><img src="https://habrastorage.org/webt/7s/uw/cm/7suwcmx0ilzbfou_eqzltg4-hsm.jpeg" alt="imagem"><br><br>  Use este algoritmo para ajustar curvas / regress√µes simples. <br><br>  Links √∫teis: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">numpy.linalg.lstsq</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Numpy</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">numpy.polyfit</a> </li></ul><br>  Guia Introdut√≥rio: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Regress√£o linear de Stanford (PDF)</a> </li></ul><br><h2>  Regress√£o linear limitada </h2><br>  O m√©todo dos m√≠nimos quadrados pode confundir outliers, campos falsos etc. S√£o necess√°rias restri√ß√µes para reduzir a varia√ß√£o da linha que colocamos no conjunto de dados.  A solu√ß√£o correta √© ajustar um modelo de regress√£o linear que garanta que os pesos n√£o se comportem "mal".  Os modelos podem ter a norma L1 (LASSO) ou L2 (Regress√£o de Ridge) ou ambos (regress√£o el√°stica). <br><br><img src="https://habrastorage.org/webt/rn/a7/wk/rna7wkkbva6w6qrbq_lk0ayxshg.jpeg" alt="imagem"><br><br>  Use esse algoritmo para corresponder √†s linhas de regress√£o restritas, evitando a substitui√ß√£o. <br><br>  Link √∫til: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Modelos lineares generalizados</a> </li></ul><br>  Guias introdut√≥rios: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Regress√£o de Ridge</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Regress√£o LASSO</a> </li></ul><br><h2>  M√©todo K-means </h2><br>  O algoritmo de cluster n√£o controlado favorito de todos.  Dado um conjunto de dados na forma de vetores, podemos criar grupos de pontos com base nas dist√¢ncias entre eles.  Esse √© um dos algoritmos de aprendizado de m√°quina que move sequencialmente os centros dos clusters e, em seguida, agrupa os pontos com cada centro do cluster.  A entrada √© o n√∫mero de clusters a serem criados e o n√∫mero de itera√ß√µes. <br><br><img src="https://habrastorage.org/webt/2u/pa/9z/2upa9z52ro49nolljotlbb9sfgg.png" alt="imagem"><br><br>  Link √∫til: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.cluster.KMeans</a> </li></ul><br>  Guias introdut√≥rios: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">V√≠deo em cluster</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Introdu√ß√£o ao Clustering</a> </li></ul><br><h2>  Regress√£o log√≠stica </h2><br>  A regress√£o log√≠stica √© limitada pela regress√£o linear com n√£o linearidade (principalmente usando a fun√ß√£o sigm√≥ide ou tanh) ap√≥s a aplica√ß√£o de pesos; portanto, a limita√ß√£o de sa√≠da √© pr√≥xima das classes +/- (que √© 1 e 0 no caso de um sigm√≥ide).  As fun√ß√µes de perda de entropia cruzada s√£o otimizadas usando o m√©todo de descida de gradiente. <br><br>  Nota para iniciantes: a regress√£o log√≠stica √© usada para classifica√ß√£o, n√£o para regress√£o.  Em geral, √© semelhante a uma rede neural de camada √∫nica.  Treinado usando t√©cnicas de otimiza√ß√£o, como descida de gradiente ou L-BFGS.  Os desenvolvedores de PNL costumam us√°-lo, chamando de "classifica√ß√£o m√°xima de entropia". <br><br><img src="https://habrastorage.org/webt/gc/yv/ne/gcyvnenl933eapskav1qili-vde.jpeg" alt="imagem"><br><br>  Use o LR para treinar classificadores simples, mas muito "fortes". <br><br>  Link √∫til: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.linear_model.LogisticRegression</a> </li></ul><br>  Guia Introdut√≥rio: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Regress√£o log√≠stica |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">classifica√ß√£o</a> </li></ul><br><h2>  SVM (m√©todo de vetor de suporte) </h2><br>  SVM √© um modelo linear, como regress√£o linear / log√≠stica.  A diferen√ßa √© que ele possui uma fun√ß√£o de perda baseada em margem.  Voc√™ pode otimizar a fun√ß√£o de perda usando m√©todos de otimiza√ß√£o como L-BFGS ou SGD. <br><br><img src="https://habrastorage.org/webt/ic/0b/n6/ic0bn6jtbl4eyukyrbfbysgiazi.jpeg" alt="imagem"><br><br>  Uma coisa √∫nica que o SVM pode fazer √© aprender os classificadores de classe. <br><br>  O SVM pode ser usado para treinar classificadores (mesmo regressores). <br><br>  Link √∫til: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.svm.SVC</a> </li></ul><br>  Guias introdut√≥rios: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">M√°quina de vetores de suporte</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.linear_model.SGDClassifier</a> </li></ul><br><h2>  Redes neurais de distribui√ß√£o direta </h2><br>  Basicamente, esses s√£o classificadores multin√≠veis de regress√£o log√≠stica.  Muitas camadas de pesos s√£o separadas por n√£o linearidades (sigm√≥ide, tanh, relu + softmax e novo selu legal).  Eles tamb√©m s√£o chamados de perceptrons multicamadas.  Os FFNNs podem ser usados ‚Äã‚Äãpara classifica√ß√£o e "treinamento sem professores" como codificadores autom√°ticos. <br><br><img src="https://habrastorage.org/webt/t0/zf/km/t0zfkm_ouawuvewy-ypy4uamh0e.jpeg" alt="imagem"><br><br>  O FFNN pode ser usado para treinar o classificador ou extrair fun√ß√µes como codificadores autom√°ticos. <br><br>  Links √∫teis: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.neural_network.MLPClassifier</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.neural_network.MLPRegressor</a> </li></ul><br>  Guias introdut√≥rios: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ffnn</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Codificadores autom√°ticos</a> </li></ul><br><h2>  Redes neurais convolucionais </h2><br>  Quase todas as conquistas modernas no campo de aprendizado de m√°quina foram alcan√ßadas usando redes neurais convolucionais.  Eles s√£o usados ‚Äã‚Äãpara classificar imagens, detectar objetos ou at√© segmentar imagens.  Inventado por Jan Lekun no in√≠cio dos anos 90, as redes possuem camadas convolucionais que atuam como extratores hier√°rquicos de objetos.  Voc√™ pode us√°-los para trabalhar com texto (e at√© para trabalhar com gr√°ficos). <br><br><img src="https://habrastorage.org/webt/rw/2c/jh/rw2cjhlifo_p6xwl2bpdjftfaxy.png" alt="imagem"><br><br>  Links √∫teis: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sistema de aprendizado interativo da GPU com aprendizado profundo</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TorchCV: PyTorch Vision Library imita o ChainerCV</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ChainerCV: biblioteca para aprendizagem profunda e vis√£o computacional</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Documenta√ß√£o Keras</a> </li></ul><br>  Guias introdut√≥rios: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CNN para reconhecimento visual</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Guia para iniciantes da CNN</a> </li></ul><br><h2>  Redes Neurais Recorrentes (RNNs) </h2><br>  As RNNs modelam sequ√™ncias aplicando o mesmo conjunto de pesos recursivamente ao estado do agregador no tempo te entrada no tempo t.  RNNs puros raramente s√£o usados ‚Äã‚Äãagora, mas seus equivalentes, como LSTM e GRU, s√£o os mais avan√ßados na maioria das tarefas de modelagem de sequ√™ncia.  LSTM, que √© usado em vez de uma camada densa simples em RNN puro. <br><br><img src="https://habrastorage.org/webt/qn/g3/-b/qng3-bibabexlnufcac1i3edeaa.png" alt="imagem"><br><br>  Use RNN para qualquer tarefa de classifica√ß√£o de texto, tradu√ß√£o autom√°tica, modelagem de idiomas. <br><br>  Links √∫teis: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Modelos e exemplos criados com o TensorFlow</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Refer√™ncia de classifica√ß√£o de texto no PyTorch</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sistema de tradu√ß√£o de c√≥digo aberto</a> </li></ul><br>  Guias introdut√≥rios: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Aprendizado profundo para processamento de idiomas de Stanford</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigos da RNN</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">No√ß√µes b√°sicas sobre LSTM</a> </li></ul><br><h2>  Campos aleat√≥rios condicionais (CRFs) </h2><br>  Eles s√£o usados ‚Äã‚Äãpara modelagem de sequ√™ncia, como RNNs, e podem ser usados ‚Äã‚Äãem combina√ß√£o com RNNs.  Eles tamb√©m podem ser usados ‚Äã‚Äãem outras tarefas de previs√£o estruturada, por exemplo, na segmenta√ß√£o de imagens.  O CRF modela cada elemento da sequ√™ncia (digamos, uma frase), para que os vizinhos influenciem o r√≥tulo do componente na sequ√™ncia, e nem todos os r√≥tulos que s√£o independentes um do outro. <br><br>  Use o CRF para vincular seq√º√™ncias (em texto, imagem, s√©rie temporal, DNA etc.). <br><br>  Link √∫til: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn-crfsuite</a> </li></ul><br>  Guias introdut√≥rios: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Introdu√ß√£o aos campos aleat√≥rios condicionais</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lista de reprodu√ß√£o do YouTube para campos aleat√≥rios condicionais</a> </li></ul><br><h2>  √Årvores de decis√£o e florestas aleat√≥rias </h2><br>  Um dos algoritmos de aprendizado de m√°quina mais comuns.  Usado em estat√≠stica e an√°lise de dados para modelos de previs√£o.  A estrutura √© "folhas" e "galhos".  Os atributos dos quais a fun√ß√£o objetivo depende s√£o registrados nas "ramifica√ß√µes" da √°rvore de decis√£o, os valores da fun√ß√£o objetivo s√£o escritos nas "folhas" e os atributos que distinguem os casos s√£o registrados nos n√≥s restantes. <br><br>  Para classificar um novo caso, voc√™ precisa descer a √°rvore at√© a folha e emitir o valor correspondente.  O objetivo √© criar um modelo que preveja o valor da vari√°vel de destino com base em v√°rias vari√°veis ‚Äã‚Äãde entrada. <br><br>  Links √∫teis: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.ensemble.RandomForestClassifier</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sklearn.ensemble.GradientBoostingClassifier</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Documenta√ß√£o do XGBoost</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Documenta√ß√£o CatBoost</a> </li></ul><br>  Guias introdut√≥rios: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Introdu√ß√£o √†s √°rvores de decis√£o</a> </li><li>  <a href="">Compreendendo florestas aleat√≥rias: da teoria √† pr√°tica</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">XGBoost em Python</a> </li></ul><br>  Voc√™ aprender√° mais informa√ß√µes sobre aprendizado de m√°quina e ci√™ncia de dados assinando minha conta no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Habr√©</a> e no canal Telegram <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Neuron</a> .  N√£o pule artigos futuros. <br><br>  Todo conhecimento! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt467825/">https://habr.com/ru/post/pt467825/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt467813/index.html">Revis√£o das mudan√ßas na 17¬™ ordem do FSTEC</a></li>
<li><a href="../pt467815/index.html">A m√≠dia levantou p√¢nico de que "os endere√ßos IP est√£o acabando na R√∫ssia". Como realmente?</a></li>
<li><a href="../pt467817/index.html">Um pouco sobre os padr√µes de design generativo</a></li>
<li><a href="../pt467821/index.html">Simplifique e elimine o necess√°rio: Entrevista com John Romero, criador de Doom</a></li>
<li><a href="../pt467823/index.html">An√°lise: OOM no Kubernetes</a></li>
<li><a href="../pt467827/index.html">Como fizemos nossa pequena Unidade a partir do zero</a></li>
<li><a href="../pt467831/index.html">O caminho espinhoso para a programa√ß√£o</a></li>
<li><a href="../pt467837/index.html">MCU ‚ÄúTerr√≠vel‚Äù de tr√™s centavos - uma breve vis√£o geral dos microcontroladores que custam menos de US $ 0,1</a></li>
<li><a href="../pt467841/index.html">Facilite a conclus√£o: Entrevista com John Romero, desenvolvedor do Doom</a></li>
<li><a href="../pt467843/index.html">Como economizar at√© meio milh√£o de d√≥lares na AWS?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
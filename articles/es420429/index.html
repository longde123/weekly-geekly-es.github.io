<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úçüèø üç∏ üôåüèº USE, RED, PgBouncer, su configuraci√≥n y monitoreo üöÄ üî¨ üßëüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Comenzamos a actualizar el monitoreo de PgBouncer en nuestro servicio y decidimos combinar todo un poco. Para que todo encajara, utilizamos las metodo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>USE, RED, PgBouncer, su configuraci√≥n y monitoreo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/okmeter/blog/420429/"><img align="left" width="359" src="https://habrastorage.org/webt/l4/xy/iz/l4xyize9ztzrmf303fot3iylnc8.png" alt="Pgbouncer USE RED"><br><p>  Comenzamos a actualizar el monitoreo de PgBouncer en nuestro servicio y decidimos combinar todo un poco.  Para que todo encajara, utilizamos las metodolog√≠as de monitoreo de rendimiento m√°s famosas: USE (Utilizaci√≥n, Saturaci√≥n, Errores) de Brendan Gregg y RED (Solicitudes, Errores, Duraciones) de Tom Wilkie. </p><br><p>  Debajo de la escena hay una historia con gr√°ficos sobre c√≥mo funciona pgbouncer, qu√© configuraci√≥n maneja y c√≥mo, usando USE / RED, elegir las m√©tricas correctas para monitorearlo. </p><a name="habracut"></a><br><h2 id="snachala-pro-sami-metody">  Primero sobre los m√©todos mismos </h2><br><p>  Aunque estos m√©todos son bastante conocidos (sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ellos ya estaban en Habr√©, aunque no con gran detalle</a> ), no es que est√©n muy extendidos en la pr√°ctica. </p><br><h3 id="use">  USO </h3><br><blockquote>  Para cada recurso, realice un seguimiento de la eliminaci√≥n, la saturaci√≥n y los errores. <br>  Brendan Gregg </blockquote><p>  Aqu√≠, un <strong>recurso</strong> es cualquier componente f√≠sico separado: una CPU, disco, bus, etc.  Pero no solo: el rendimiento de algunos recursos de software tambi√©n puede considerarse mediante este m√©todo, en particular los recursos virtuales, como los contenedores / grupos c con l√≠mites, tambi√©n es conveniente considerar esto. </p><br><p> <strong>U - Eliminaci√≥n</strong> : ya sea un porcentaje del tiempo (desde el intervalo de observaci√≥n) cuando el recurso estaba ocupado con un trabajo √∫til.  Como, por ejemplo, cargar la CPU o la utilizaci√≥n del disco en un 90% significa que el 90% del tiempo lo tom√≥ algo √∫til) o, para recursos como la memoria, este es el porcentaje de memoria utilizada. </p><br><p>  En cualquier caso, el 100% de reciclaje significa que el recurso no se puede usar m√°s que ahora.  Y o bien el trabajo se atascar√° esperando la liberaci√≥n / ir a la cola, o habr√° errores.  Estos dos escenarios est√°n cubiertos por las dos m√©tricas de USO restantes correspondientes: </p><br><p>  <strong>S - Saturaci√≥n</strong> , tambi√©n es saturaci√≥n: una medida de la cantidad de trabajo "diferido" / en cola. </p><br><p>  <strong>E - Errores</strong> : simplemente contamos el n√∫mero de fallas.  Los errores / fallas afectan el rendimiento, pero es posible que no se noten de inmediato debido a la recuperaci√≥n de operaciones invertidas o mecanismos de tolerancia a fallas con dispositivos de respaldo, etc. </p><br><h3 id="red">  Rojo </h3><br><p>  Tom Wilkie (ahora trabajando en Grafana Labs) se sinti√≥ frustrado por la metodolog√≠a USE, o m√°s bien, su poca aplicabilidad en algunos casos y la inconsistencia con la pr√°ctica.  ¬øC√≥mo, por ejemplo, medir la saturaci√≥n de la memoria?  ¬øO c√≥mo medir los errores del bus del sistema en la pr√°ctica? </p><br><blockquote>  Resulta que Linux realmente informa los recuentos de errores. <br>  T. Wilkie </blockquote><p>  En resumen, para monitorear el desempe√±o y el comportamiento de los microservicios, propuso otro m√©todo adecuado: medir, nuevamente, tres indicadores: </p><br><p>  <strong>R - Rate</strong> : el n√∫mero de solicitudes por segundo. <br>  <strong>E - Errores</strong> : cu√°ntas solicitudes devolvieron un error. <br>  <strong>D - Duraci√≥n</strong> : tiempo necesario para procesar la solicitud.  Es latencia, "latencia" (¬© Sveta Smirnova :), tiempo de respuesta, etc. </p><br><p>  En general, USE es m√°s adecuado para monitorear recursos y RED para servicios y su carga de trabajo / carga √∫til. </p><br><h2 id="pgbouncer">  Pgbouncer </h2><br><p>  Al ser un servicio, al mismo tiempo tiene todo tipo de l√≠mites y recursos internos.  Lo mismo puede decirse de Postgres, a los que los clientes acceden a trav√©s de este PgBouncer.  Por lo tanto, para un monitoreo completo en esta situaci√≥n, se necesitan ambos m√©todos. </p><br><p>  Para comprender c√≥mo aplicar estos m√©todos a un portero, debe comprender los detalles de su dispositivo.  No es suficiente monitorearlo como una caja negra: "est√° vivo el proceso pgbouncer" o "est√° abierto el puerto", porque  En caso de problemas, esto no dar√° una idea de qu√© es exactamente y c√≥mo se rompi√≥ y qu√© hacer. </p><br><p>  Lo que generalmente hace el aspecto de PgBouncer desde el punto de vista del cliente: </p><br><ol><li>  el cliente se conecta </li><li>  [el cliente hace una solicitud - recibe una respuesta] x cu√°ntas veces necesita </li></ol><br><p>  Aqu√≠ he dibujado un diagrama de los estados de cliente correspondientes desde el punto de vista de PgBoucer: <br><img src="https://habrastorage.org/webt/zb/mh/ot/zbmhotvidvuxnsbzp04-bqtgqhk.jpeg"></p><br><p> En el proceso de inicio de sesi√≥n, la autorizaci√≥n puede ocurrir tanto localmente (archivos, certificados e incluso PAM y hba de nuevas versiones) como remotamente, es decir,  en la base de datos a la que se intenta la conexi√≥n.  Por lo tanto, el estado de inicio de sesi√≥n tiene un subestado adicional.  Llam√©moslo <code>Executing</code> para indicar que <code>auth_query</code> est√° <code>auth_query</code> en la base de datos en este momento: <br><img src="https://habrastorage.org/webt/e4/ib/pb/e4ibpbf6ef5q9xcdy2fantydkc4.png"></p><br><p>  Pero estas conexiones de cliente en realidad coinciden con las conexiones de backend / upstream que PgBouncer abre dentro del grupo y tiene un n√∫mero limitado.  Y brindan dicha conexi√≥n al cliente solo por el tiempo, por la duraci√≥n de la sesi√≥n, transacci√≥n o solicitud, dependiendo del tipo de agrupaci√≥n (determinada por la configuraci√≥n <code>pool_mode</code> ).  Muy a menudo, se usa la agrupaci√≥n de transacciones (lo discutiremos principalmente m√°s adelante), cuando la conexi√≥n se emite al cliente para una transacci√≥n, y el resto del tiempo el cliente no est√° conectado al servidor.  Por lo tanto, el estado "activo" del cliente nos dice poco y lo dividiremos en sustratos: <br><img src="https://habrastorage.org/webt/uv/q4/tj/uvq4tjzbbauunpwzhboxc8s3pgu.png"></p><br><p>  Cada uno de estos clientes se incluye en su propio grupo de conexiones, que se emitir√° para su uso por la conexi√≥n real a Postgres.  Esta es la tarea principal de PgBouncer: limitar el n√∫mero de conexiones a Postgres. </p><br><p>  Debido a las conexiones limitadas del servidor, puede surgir una situaci√≥n en la que el cliente necesita cumplir con la solicitud directamente, pero ahora no hay conexi√≥n gratuita.  Luego, el cliente se pone en cola y su conexi√≥n pasa al estado <code>CL_WAITING</code> .  Por lo tanto, el diagrama de estado debe complementarse: <br><img src="https://habrastorage.org/webt/2v/ny/yu/2vnyyuhlqher6cc5q5izwjtu7te.png"><br>  Como esto puede suceder en el caso de que el cliente solo <code>CL_WAITING_LOGIN</code> sesi√≥n y necesite ejecutar una solicitud de autorizaci√≥n, tambi√©n <code>CL_WAITING_LOGIN</code> estado <code>CL_WAITING_LOGIN</code> . </p><br><p>  Si ahora mira desde el reverso, desde el lado de las conexiones del servidor, entonces, en consecuencia, est√°n en tales estados: cuando la autorizaci√≥n se produce inmediatamente despu√©s de la conexi√≥n - <code>SV_LOGIN</code> , emitida y (posiblemente) utilizada por el cliente - <code>SV_ACTIVE</code> , o libremente - <code>SV_IDLE</code> . </p><br><h2 id="use-dlya-pgbouncer">  USE para PgBouncer </h2><br><p>  As√≠ llegamos a la (versi√≥n ingenua) Utilizaci√≥n de un grupo espec√≠fico: </p><br><pre> <code class="hljs nginx"><span class="hljs-attribute"><span class="hljs-attribute">Pool</span></span> utiliz =    /  </code> </pre> <br><p>  PgBouncer tiene una base de datos de utilidad pgbouncer especial en la que hay un <code>SHOW POOLS</code> que muestra el estado actual de las conexiones de cada grupo: <br><img src="https://habrastorage.org/webt/xz/_o/eb/xz_oebvf-0yahuvdfzrxx3iass0.png"><br>  Hay 4 conexiones de cliente abiertas y todas ellas son <code>cl_active</code> .  De 5 conexiones de servidor: 4 <code>sv_active</code> y una en el nuevo estado <code>sv_used</code> . </p><br><div class="spoiler">  <b class="spoiler_title">¬øQu√© es realmente sv_used sobre las diferentes configuraciones de pgbouncer no relacionadas con el monitoreo?</b> <div class="spoiler_text"><p>  Por <code>sv_used</code> tanto, <code>sv_used</code> no significa "se est√° utilizando la conexi√≥n", como podr√≠a pensar, pero "la conexi√≥n se us√≥ una vez y no se ha utilizado durante mucho tiempo".  El hecho es que PgBouncer usa conexiones de servidor en modo LIFO por defecto, es decir  Primero, se usan conexiones reci√©n lanzadas, luego las usadas recientemente, etc.  movi√©ndose gradualmente a compuestos de uso prolongado.  En consecuencia, las conexiones del servidor desde la parte inferior de dicha pila pueden "ir mal".  Y deben verificarse su vivacidad antes de su uso, lo que se hace usando <code>server_check_query</code> , mientras se est√°n verificando, el estado ser√° <code>sv_tested</code> . </p><br><p>  La documentaci√≥n dice que LIFO est√° habilitado de forma predeterminada, como  luego "un peque√±o n√∫mero de conexiones obtiene la mayor carga de trabajo. Y esto brinda el mejor rendimiento cuando hay un servidor que sirve la base de datos detr√°s de pgbouncer", es decir  como en el caso m√°s t√≠pico  Creo que el potencial aumento del rendimiento se debe al ahorro en el cambio de rendimiento entre m√∫ltiples procesos de back-end.  Pero no funcion√≥ de manera confiable, porque  Este detalle de implementaci√≥n ha existido durante&gt; 12 a√±os y va m√°s all√° del historial de compromisos en github y la profundidad de mi inter√©s =) </p><br><p>  Entonces, parec√≠a extra√±o e <code>server_check_delay</code> con las realidades actuales que el valor predeterminado de la configuraci√≥n <code>server_check_delay</code> , que determina que el servidor no se ha utilizado durante demasiado tiempo y debe verificarse antes de d√°rselo al cliente, es de 30 segundos.  Esto es a pesar del hecho de que, de forma predeterminada, tcp_keepalive se habilita simult√°neamente con la configuraci√≥n predeterminada: comience a verificar la conexi√≥n de mantener vivo con las muestras 2 horas despu√©s de su inactividad. <br>  Resulta que en una situaci√≥n de r√°faga / sobretensi√≥n de conexiones de clientes que desean hacer algo en el servidor, se introduce un retraso adicional en <code>server_check_query</code> , que, aunque " <code>SELECT 1;</code> a√∫n puede tomar ~ 100 microsegundos, y si <code>server_check_query = ';'</code>  entonces puedes guardar ~ 30 microsegundos =) </p><br><p>  Pero la suposici√≥n de que trabajar en solo unas pocas conexiones = en varios procesos de postgres de back-end "principales" ser√° m√°s eficiente, me parece dudoso.  El proceso de trabajo de postgres almacena en cach√© (meta) informaci√≥n sobre cada tabla a la que se accedi√≥ en esta conexi√≥n.  Si tiene una gran cantidad de tablas, entonces este relanzamiento puede crecer mucho y ocupar mucha memoria, hasta el intercambio de las p√°ginas del proceso 0_o.  Para evitar esto, use la configuraci√≥n <code>server_lifetime</code> (el valor predeterminado es 1 hora), por el cual la conexi√≥n del servidor se cerrar√° por rotaci√≥n.  Pero, por otro lado, hay una configuraci√≥n <code>server_round_robin</code> que cambiar√° el modo de usar conexiones de LIFO a FIFO, extendiendo las solicitudes de los clientes en las conexiones del servidor de manera m√°s uniforme. </p></div></div><br><p>  <code>SHOW POOLS</code> tomar m√©tricas <code>SHOW POOLS</code> de <code>SHOW POOLS</code> (por alg√∫n exportador de prometheus) podemos trazar estos estados: </p><br><p><img src="https://habrastorage.org/webt/i8/8f/-x/i88f-xpwo_2hj7z6iq6qbnatsju.png"></p><br><p>  Pero para llegar a la disposici√≥n necesita responder algunas preguntas: </p><br><ul><li>  ¬øCu√°l es el tama√±o de la piscina? </li><li>  ¬øC√≥mo contar cu√°ntos compuestos se usan?  ¬øEn bromas o en el tiempo, en promedio o en el pico? </li></ul><br><h3 id="razmer-pula">  Tama√±o de la piscina </h3><br><p>  Aqu√≠ todo es complicado, como en la vida.  ¬°En total, ya hay cinco l√≠mites de configuraci√≥n en pbbouncer! </p><br><ul><li>  <code>pool_size</code> se puede establecer para cada base de datos.  Se crea un grupo separado para cada par DB / usuario, es decir  desde cualquier usuario <em>adicional</em> , puede crear otros backends de <code>pool_size</code> / trabajadores de Postgres.  Porque  si <code>pool_size</code> no <code>pool_size</code> configurado, cae en <code>default_pool_size</code> , que por defecto es 20, entonces resulta que cada usuario que tiene derecho a conectarse a la base de datos (y trabaja a trav√©s de pgbouncer) puede potencialmente crear 20 procesos de Postgres, lo que parece no ser mucho.  Pero si tiene muchos usuarios diferentes de las bases de datos o las propias bases de datos, y los grupos no est√°n registrados con un usuario fijo, es decir,  ser√° creado sobre la marcha (y luego eliminado por <code>autodb_idle_timeout</code> ), entonces esto puede ser peligroso =) <br><blockquote>  Puede valer la pena dejar <code>default_pool_size</code> peque√±o, solo para cada bombero. <br></blockquote></li><li>  <code>max_db_connections</code> : solo es necesario limitar el n√∫mero total de conexiones a una base de datos, porque  de lo contrario, los clientes que se comportan mal pueden crear muchos procesos backends / postgres.  Y por defecto aqu√≠ - ilimitado ¬Ø_ („ÉÑ) _ / ¬Ø <br><blockquote>  Tal vez deber√≠a cambiar las <code>max_db_connections</code> , por ejemplo, puede enfocarse en las <code>max_connections</code> sus Postgres (por defecto 100).  Pero si tienes muchos PgBouncers ... <br></blockquote></li><li>  <code>reserve_pool_size</code> : en realidad, si <code>pool_size</code> utiliza pool_size, PgBouncer puede abrir varias conexiones m√°s a la base.  Seg√∫n tengo entendido, esto se hace para hacer frente a un aumento de la carga.  Volveremos a esto. </li><li>  <code>max_user_connections</code> : por el contrario, este es el l√≠mite de conexiones de un usuario a todas las bases de datos, es decir,  relevante si tiene varias bases de datos y van bajo los mismos usuarios. </li><li>  <code>max_client_conn</code> : cu√°ntas conexiones de cliente aceptar√° PgBouncer en total.  El valor predeterminado, como de costumbre, tiene un significado muy extra√±o: 100. Es decir,  se asume que si m√°s de 100 clientes se bloquean repentinamente, entonces solo necesitan <code>reset</code> silenciosamente al nivel TCP y <code>reset</code> (bueno, en los registros, debo admitir, esto ser√° "no se permitir√°n m√°s conexiones (max_client_conn)"). <br><blockquote>  Puede valer la pena hacer <code>max_client_conn &gt;&gt; SUM ( pool_size' )</code> , por ejemplo, 10 veces m√°s. <br></blockquote></li></ul><br><p>  Adem√°s de <code>SHOW POOLS</code> servicio pseudo-base pgbouncer tambi√©n proporciona el <code>SHOW DATABASES</code> , que muestra los l√≠mites realmente aplicados a un grupo particular: <br><img src="https://habrastorage.org/webt/1v/lv/4h/1vlv4hviyhxz1pbh9puc6xxim9o.jpeg"></p><br><h3 id="servernye-soedineniya">  Conexiones del servidor </h3><br><p>  Una vez m√°s, ¬øc√≥mo medir cu√°ntos compuestos se usan? <br>  ¬øEn bromas en promedio / en pico / a tiempo? </p><br><p>  En la pr√°ctica, es bastante problem√°tico monitorear el uso de piscinas por parte del portero con herramientas extendidas, como  pgbouncer proporciona solo una imagen moment√°nea y, como a menudo no hace una encuesta, todav√≠a existe la posibilidad de una imagen incorrecta debido al muestreo.  Aqu√≠ hay un ejemplo real de cu√°ndo, dependiendo de cu√°ndo trabaj√≥ el exportador, al principio del minuto o al final, la imagen de los compuestos abiertos y usados ‚Äã‚Äãcambia fundamentalmente: </p><br><p><img src="https://habrastorage.org/webt/i3/ch/qb/i3chqbtvyp3p6nm0bayw62pf3hq.png"></p><br><p>  Aqu√≠ todos los cambios en la carga / uso de las conexiones son solo una ficci√≥n, un artefacto de los reinicios del recopilador de estad√≠sticas.  Aqu√≠ puede ver los gr√°ficos de conexi√≥n en Postgres durante este tiempo y los descriptores de archivo del gorila y PG - sin cambios: </p><br><p><img src="https://habrastorage.org/webt/n7/bh/4r/n7bh4r_2h21ypaxhtr7njv2u8xa.png"></p><br><p>  Volver a la cuesti√≥n de la eliminaci√≥n.  Decidimos utilizar un enfoque combinado en nuestro servicio: probamos <code>SHOW POOLS</code> una vez por segundo, y una vez por minuto mostramos el n√∫mero promedio y m√°ximo de conexiones en cada clase: </p><br><p><img src="https://habrastorage.org/webt/ea/v5/ei/eav5eimcl7fofctvc24oaymzsu4.png"></p><br><p>  Y si dividimos el n√∫mero de estas conexiones de estado activo por el tama√±o del grupo, obtenemos la utilizaci√≥n promedio y m√°xima de este grupo y podemos alertar si est√° cerca del 100%. </p><br><p>  Adem√°s, PgBouncer tiene un comando <code>SHOW STATS</code> que mostrar√° estad√≠sticas de uso para cada base de datos proxy: <br><img src="https://habrastorage.org/webt/mo/wz/_q/mowz_qavy_zspkljbvnehbj1bpc.png"><br>  Estamos m√°s interesados ‚Äã‚Äãen la columna <code>total_query_time</code> : el tiempo empleado por todas las conexiones en el proceso de ejecuci√≥n de consultas en postgres.  Y a partir de la versi√≥n 1.8 tambi√©n existe la m√©trica <code>total_xact_time</code> , el tiempo dedicado a las transacciones.  En base a estas m√©tricas, podemos construir la utilizaci√≥n del tiempo de conexi√≥n del servidor; este indicador no est√° sujeto, en contraste con el calculado a partir de los estados de conexi√≥n, a problemas de muestreo, porque  Estos contadores de <code>total_..._time</code> son acumulativos y no pasan nada: </p><br><p><img src="https://habrastorage.org/webt/p3/1l/iv/p31liv1gccpj3rxnxav-nbelck0.png"><br>  Comparar <br><img src="https://habrastorage.org/webt/yk/rt/gd/ykrtgdu5s8_pcltl3w3mmcuj4oo.png"><br>  Se puede ver que el muestreo no muestra todos los momentos de alta ~ 100% de utilizaci√≥n, y consulta query_time. </p><br><h3 id="saturation-i-pgbouncer">  Saturaci√≥n y PgBouncer </h3><br><p>  ¬øPor qu√© necesita monitorear la saturaci√≥n, debido a la alta utilizaci√≥n ya est√° claro que todo est√° mal? </p><br><p>  El problema es que no importa c√≥mo mida la utilizaci√≥n, incluso los contadores acumulados no pueden mostrar una utilizaci√≥n local del 100% de los recursos si se produce solo a intervalos muy cortos.  Por ejemplo, tiene coronas u otros procesos sincr√≥nicos que pueden comenzar simult√°neamente a realizar consultas a la base de datos con el comando.  Si estas solicitudes son cortas, la utilizaci√≥n, medida en las escalas de minutos e incluso segundos, puede ser baja, pero al mismo tiempo, en alg√∫n momento, estas solicitudes se vieron obligadas a esperar en l√≠nea para su ejecuci√≥n.  Esto es similar con una situaci√≥n en la que el uso de la CPU no es del 100% y un promedio de carga alto, como el tiempo de procesador todav√≠a est√° all√≠, pero sin embargo, muchos procesos est√°n esperando en l√≠nea para la ejecuci√≥n. </p><br><p>  ¬øC√≥mo se puede monitorear esta situaci√≥n? Bueno, de nuevo, simplemente podemos contar el n√∫mero de clientes en el estado <code>cl_waiting</code> acuerdo con <code>SHOW POOLS</code> .  En una situaci√≥n normal, hay cero, y m√°s de cero significa desbordamiento de este grupo: </p><br><p><img src="https://habrastorage.org/webt/q1/tg/tj/q1tgtjcqgrqpavfpkf0kyg31hjq.png"></p><br><p>  Sigue existiendo el problema de que <code>SHOW POOLS</code> solo se puede muestrear, y en una situaci√≥n con coronas s√≠ncronas o algo as√≠, simplemente podemos omitir y no ver a esos clientes en espera. </p><br><p>  Puede usar este truco, pgbouncer en s√≠ mismo puede detectar el uso del 100% del grupo y abrir el grupo de copia de seguridad.  Dos configuraciones son responsables de esto: <code>reserve_pool_size</code> - por su tama√±o, como dije, y <code>reserve_pool_timeout</code> - cu√°ntos segundos debe <code>waiting</code> un cliente antes de usar el grupo de respaldo.  Por lo tanto, si vemos en el gr√°fico de conexiones del servidor que el n√∫mero de conexiones abiertas a Postgres es mayor que pool_size, entonces hubo una saturaci√≥n del pool, as√≠: <br><img src="https://habrastorage.org/webt/ne/ec/hn/neechnkp9sffd8g3rjov_3jjijm.png"><br>  Obviamente, algo como coronas una vez por hora hace muchas solicitudes y ocupa completamente la piscina.  Y aunque no vemos el momento en que <code>active</code> conexiones <code>active</code> exceden el l√≠mite de <code>pool_size</code> , pgbouncer se vio obligado a abrir conexiones adicionales. </p><br><p>  Tambi√©n en este gr√°fico, el <code>server_idle_timeout</code> configuraci√≥n <code>server_idle_timeout</code> es claramente visible, despu√©s de cu√°nto dejar de mantener y cerrar conexiones que no se utilizan.  Por defecto, esto es 10 minutos, que vemos en el gr√°fico, despu√©s de los picos <code>active</code> exactamente a las 5:00, a las 6:00, etc.  (seg√∫n cron <code>0 * * * *</code> ), las conexiones se cuelgan <code>idle</code> + <code>used</code> otros 10 minutos y se cierran. </p><br><p>  Si vive a la vanguardia del progreso y ha actualizado PgBouncer en los √∫ltimos 9 meses, puede encontrar en la columna <code>SHOW STATS</code> <code>total_wait_time</code> , que mejor muestra la saturaci√≥n, porque  considera acumulativamente el tiempo que pasan los clientes en estado de <code>waiting</code> .  Por ejemplo, aqu√≠, el <code>waiting</code> apareci√≥ a las 16:30: <br><img src="https://habrastorage.org/webt/ck/-q/qt/ck-qqth3dhvsqsw1zzeuvkjg4wa.png"><br>  Y <code>wait_time</code> , que es comparable y claramente afecta el <code>average query time</code> , se puede ver desde las 15:15 hasta casi las 19: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  Sin embargo, monitorear el estado de las conexiones del cliente sigue siendo muy √∫til, porque  le permite descubrir no solo el hecho de que todas las conexiones a dicha base de datos se han gastado y los clientes tienen que esperar, sino tambi√©n porque <code>SHOW POOLS</code> dividido en grupos separados por los usuarios, y <code>SHOW STATS</code> no, le permite averiguar qu√© clientes usaron todas las conexiones a la base especificada, de acuerdo con la columna <code>sv_active</code> del grupo correspondiente.  O por m√©trica </p><br><pre> <code class="hljs pgsql">sum_by(<span class="hljs-keyword"><span class="hljs-keyword">user</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">database</span></span>, metric(<span class="hljs-type"><span class="hljs-type">name</span></span>="pgbouncer.clients.count", state="active-link")):</code> </pre> <br><p><img src="https://habrastorage.org/webt/k_/0s/lf/k_0slfupzfrdz4npoiz8kbxgpko.png"></p><br><p>  En okmeter fuimos a√∫n m√°s lejos y agregamos un desglose de las conexiones utilizadas por las direcciones IP de los clientes que las abrieron y utilizaron.  Esto le permite comprender exactamente qu√© instancias de aplicaci√≥n se comportan de manera diferente: <br><img src="https://habrastorage.org/webt/dk/fr/5j/dkfr5j_yvxgmm2f0b5dvru4b9nk.png"><br>  Aqu√≠ vemos IP de kubernetes espec√≠ficos de hogares con los que tenemos que lidiar. </p><br><h3 id="errors">  Errores </h3><br><p>  Aqu√≠ no hay nada particularmente complicado: pgbouncer escribe registros en los que informa errores si se alcanza el l√≠mite de conexiones del cliente, el tiempo de espera para conectarse al servidor, etc.  Todav√≠a no hemos llegado a los registros de pgbouncer :( </p><br><h2 id="red-dlya-pgbouncer">  ROJO para PgBouncer </h2><br><p>  Si bien el USO se centra m√°s en el rendimiento, en el sentido de los cuellos de botella, RED, en mi opini√≥n, trata m√°s sobre las caracter√≠sticas del tr√°fico entrante y saliente en general, y no sobre los cuellos de botella.  Es decir, RED responde a la pregunta: ¬øfunciona todo bien y, de lo contrario, USE ayudar√° a comprender cu√°l es el problema? </p><br><h2 id="requests">  Requisitos </h2><br><p>  Parece que todo es bastante simple para la base de datos SQL y para el extractor de proxy / conexi√≥n en dicha base de datos: los clientes ejecutan declaraciones SQL, que son solicitudes.  De <code>SHOW STATS</code> tomamos <code>total_requests</code> y <code>total_requests</code> su derivada de tiempo </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"pgbouncer.total_requests"</span></span>, database: <span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fa/7u/o2/fa7uo2r8b6_4y6z9e2bounudzmw.png"></p><br><p>  Pero, de hecho, hay diferentes modos de extracci√≥n, y el m√°s com√∫n son las transacciones.  La unidad de trabajo para este modo es una transacci√≥n, no una consulta.  En consecuencia, a partir de la versi√≥n 1.8, Pgbouner ya proporciona otras dos estad√≠sticas: <code>total_query_count</code> , en lugar de <code>total_requests</code> y <code>total_xact_count</code> , el n√∫mero de transacciones completadas. </p><br><p>  Ahora, la carga de trabajo se puede caracterizar no solo en t√©rminos de la cantidad de solicitudes / transacciones completadas, sino que, por ejemplo, puede ver la cantidad promedio de solicitudes por transacci√≥n en diferentes bases de datos, dividiendo una en otra </p><br><pre> <code class="hljs lisp">rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_requests"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>)) / rate(<span class="hljs-name"><span class="hljs-name">metric</span></span>(<span class="hljs-name"><span class="hljs-name">name=</span></span><span class="hljs-string"><span class="hljs-string">"total_xact"</span></span>, database=<span class="hljs-string"><span class="hljs-string">"*"</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/xd/uh/3w/xduh3wsb-bww1tysfwtdhcw-seg.png"></p><br><p>  Aqu√≠ vemos cambios obvios en el perfil de carga, que pueden ser la raz√≥n del cambio en el rendimiento.  Y si observara solo la tasa de transacciones o solicitudes, es posible que no vea esto. </p><br><h2 id="red-errors">  Errores rojos </h2><br><p>  Est√° claro que RED y USE se cruzan en el monitoreo de errores, pero me parece que los errores en el USE son principalmente errores de procesamiento de solicitudes debido al 100% de utilizaci√≥n, es decir.  cuando el servicio se niega a aceptar m√°s trabajo.  Y los errores para RED ser√≠an mejores para medir los errores con precisi√≥n desde el punto de vista del cliente, las solicitudes del cliente.  Es decir, no solo en una situaci√≥n en la que el grupo en el PgBouncer est√° lleno o si otro l√≠mite ha funcionado, sino tambi√©n cuando se solicitan tiempos de espera como "cancelaci√≥n del estado de cuenta debido al tiempo de espera del estado de cuenta", cancelaciones y reversiones de transacciones por parte del cliente, etc. e.  de nivel superior, m√°s cercano a los tipos de errores de l√≥gica de negocios. </p><br><h2 id="durations">  Duraciones </h2><br><p>  Aqu√≠ nuevamente <code>SHOW STATS</code> con contadores acumulativos <code>total_xact_time</code> , <code>total_query_time</code> y <code>total_wait_time</code> nos ayudar√°n, dividi√©ndolos por el n√∫mero de solicitudes y transacciones, respectivamente, obtenemos el tiempo promedio de solicitud, el tiempo promedio de transacci√≥n, el tiempo promedio de espera por transacci√≥n.  Ya mostr√© un gr√°fico sobre el primero y el tercero: <br><img src="https://habrastorage.org/webt/gn/av/bb/gnavbbmcfchzhkt0d0egcybthzc.png"></p><br><p>  ¬øQu√© m√°s puedes ponerte genial?  El conocido antipatr√≥n en el trabajo con la base de datos y Postgres, en particular, cuando la aplicaci√≥n abre una transacci√≥n, realiza una solicitud, luego comienza (durante mucho tiempo) a procesar sus resultados, o peor a√∫n, va a alg√∫n otro servicio / base de datos y realiza solicitudes all√≠.  Todo este tiempo, la transacci√≥n "se cuelga" en la apertura de postgres, el servicio luego regresa y realiza algunas solicitudes m√°s, actualizaciones en la base de datos, y solo luego cierra la transacci√≥n.  Para los postgres esto es especialmente desagradable, porque  Los trabajadores de PG son caros.  Por lo tanto, podemos monitorear cuando dicha aplicaci√≥n est√° <code>idle in transaction</code> en el propio postgres, de acuerdo con la columna de <code>state</code> en <code>pg_stat_activity</code> , pero todav√≠a hay los mismos problemas descritos con el muestreo, porque  <code>pg_stat_activity</code> proporciona solo la imagen actual.  En PgBouncer, podemos restar el tiempo dedicado por los clientes en <code>total_query_time</code> solicitudes <code>total_query_time</code> del tiempo dedicado a las transacciones <code>total_xact_time</code> ; este ser√° el momento de dicha inactividad.  Si el resultado a√∫n se divide por <code>total_xact_time</code> , entonces se normalizar√°: un valor de 1 corresponde a una situaci√≥n en la que los clientes est√°n <code>idle in transaction</code> 100% del tiempo.  Y con tal normalizaci√≥n, hace que sea f√°cil entender lo malo que est√° todo: </p><br><p><img src="https://habrastorage.org/webt/t9/kn/io/t9knioh2ckzd_photgqvcq543x4.png"></p><br><p>  Adem√°s, volviendo a Duraci√≥n, la m√©trica <code>total_xact_time - total_query_time</code> se puede dividir por el n√∫mero de transacciones para ver cu√°nto es la aplicaci√≥n inactiva promedio por transacci√≥n. </p><br><hr><br><p>  En mi opini√≥n, los m√©todos USE / RED son m√°s √∫tiles para estructurar qu√© m√©tricas disparas y por qu√©.  Dado que estamos involucrados en el monitoreo a tiempo completo y tenemos que monitorear varios componentes de la infraestructura, estos m√©todos nos ayudan a tomar las m√©tricas correctas, hacer los cronogramas y disparadores correctos para nuestros clientes. </p><br><p>  <em>Un buen monitoreo no se puede hacer de inmediato; es un proceso iterativo.</em>  <em>En <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">okmeter.io</a> solo tenemos monitoreo continuo (hay muchas cosas, pero ma√±ana ser√° mejor y m√°s detallado :)</em> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es420429/">https://habr.com/ru/post/es420429/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es420413/index.html">SQLite y NW.js: instrucciones paso a paso para crear fuertes amistades</a></li>
<li><a href="../es420415/index.html">Todo lo que quer√≠a saber sobre probar adaptadores de Wi-Fi, pero ten√≠a miedo de preguntar</a></li>
<li><a href="../es420419/index.html">Corredores para aquellos a quienes les gusta la humillaci√≥n o c√≥mo cambiamos y modificamos PixJam</a></li>
<li><a href="../es420423/index.html">Problemas de interfaz de cruce de tierra</a></li>
<li><a href="../es420425/index.html">Teor√≠a y pr√°ctica del uso de HBase</a></li>
<li><a href="../es420431/index.html">Marte Gu√≠a pr√°ctica de terraformaci√≥n para amas de casa</a></li>
<li><a href="../es420433/index.html">"Formato del viernes": caminos musicales: qu√© es y por qu√© no est√°n en Rusia</a></li>
<li><a href="../es420435/index.html">Inicio r√°pido con ARM Mbed: desarrollo en microcontroladores modernos para principiantes</a></li>
<li><a href="../es420437/index.html">Una introducci√≥n pr√°ctica al administrador de paquetes para Kubernetes - Helm</a></li>
<li><a href="../es420439/index.html">Fintech digest: las inversiones en fintech alcanzaron los $ 57 mil millones, la velocidad de transacci√≥n est√° creciendo y el costo est√° cayendo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
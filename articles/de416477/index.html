<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôáüèª üëª üßìüèæ Maschinelles Lernen und mobile Entwicklung üê¥ üë∞üèø üë©‚Äçüë©‚Äçüëß‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In der Regel hat ein Datenwissenschaftler eine vage Vorstellung von der mobilen Entwicklung, und Entwickler mobiler Anwendungen besch√§ftigen sich nich...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Maschinelles Lernen und mobile Entwicklung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/416477/">  In der Regel hat ein Datenwissenschaftler eine vage Vorstellung von der mobilen Entwicklung, und Entwickler mobiler Anwendungen besch√§ftigen sich nicht mit maschinellem Lernen.  <strong>Andrei Volodin</strong> , Ingenieur bei Prisma AI, lebt an der Schnittstelle dieser beiden Welten und erz√§hlte den Podcast-Moderatoren von Podlodka, wie es sich anf√ºhlt. <br><br>  Stas Tsyganov (Tutu.ru) und Gleb Novik (Tinkoff Bank) nutzten den Moment und machten zun√§chst ein f√ºr alle Mal klar, dass <strong>niemand neuronale Netze auf Mobilger√§ten trainiert</strong> .  Und auch herausgefunden, dass es beim maschinellen Lernen leider keine Zauberer gibt;  diskutierten moderne Techniken wie <strong>Deep Learning, Enforcement Learning</strong> und Kapsel-Netzwerke. <br><br>  Da Podlodka eine Audioshow √ºber die mobile Entwicklung ist, kamen sie zu ihr und fanden heraus, wie das alles f√ºr mobile Ger√§te funktioniert. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fw/ph/db/fwphdbn4sxovfbminez_irgn6pm.jpeg"></div><br>  Als n√§chstes folgt die Textversion dieser Konversation, und der Podcast-Eintrag befindet sich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><a name="habracut"></a><br><h1>  √úber Andrei Volodin, cocos2d und Fiber2d <br></h1><br>  GLEB: Bitte erz√§hl uns etwas √ºber dich.  Was machst du? <br><br>  ANDREW: Ich bin ein mobiler Entwickler, aber ich mache sehr wenig in der klassischen iOS-Entwicklung.  Zu meinen Aufgaben geh√∂rt praktisch nicht die Arbeit mit UIKit.  Ich bin der Hauptentwickler der sehr beliebten Cocos2d-Game-Engine auf GitHub.  Im Moment bin ich GPU-Ingenieur bei Prisma.  Zu meinen Aufgaben geh√∂ren die Integration neuronaler Netze in Grafikkarten und die Arbeit mit Augmented Reality, insbesondere mit dem VR-Kit. <br><br>  GLEB: Cool!  Besonders interessant √ºber cocos2d.  Soweit ich wei√ü, ist dieser Rahmen vor langer Zeit erschienen. <br><br>  ANDREW: Ja, um 2009 herum. <br><br>  GLEB: Du hast es von Anfang an benutzt? <br><br>  ANDREW: Nein.  Ich wurde erst 2015 der Hauptentwickler.  Zuvor war ich ein Core-Mitarbeiter.  Apportable, das die Entwicklung finanzierte, ging bankrott, die Leute, die das Geld f√ºr die Entwicklung erhielten, gingen und ich wurde der Anf√ºhrer.  Jetzt bin ich Administrator im Forum und helfe Neulingen bei einigen Problemen. Die letzten Versionen wurden von mir ver√∂ffentlicht.  Das hei√üt, ich bin im Moment der Hauptbetreuer. <br><br>  GLEB: Aber lebt cocos2d noch? <br><br>  ANDREW: H√∂chstwahrscheinlich nicht, haupts√§chlich aufgrund der Tatsache, dass es in Objective-C geschrieben ist und es viel Verm√§chtnis gibt.  Zum Beispiel unterst√ºtze ich einige alte Spielzeuge, die mit ihrer Verwendung geschrieben wurden, andere Entwickler - meine Legacy-Projekte.  Von den aktuellen Motoren konnte man √ºber Fiber2d h√∂ren.  Dies ist auch mein Projekt. <br><br>  Fiber2d ist die erste Swift-Game-Engine, die auf Android portiert wurde.  Wir haben ein Spiel gestartet, das vollst√§ndig in Swift f√ºr iOS und Android geschrieben wurde.  Auch dar√ºber finden Sie auf Github.  Dies ist der n√§chste Meilenstein in der Entwicklung der cocos2d-Community. <br><br><h1>  √úber maschinelles Lernen an den Fingern <br></h1><br>  GLEB: Beginnen wir heute allm√§hlich mit unserem Thema.  Heute werden wir <strong>√ºber maschinelles Lernen und alles um es herum</strong> sprechen - verbunden und unverbunden mit Mobiltelefonen.  Lassen Sie uns zun√§chst herausfinden, worum es beim maschinellen Lernen geht.  Wir werden versuchen, so viel wie m√∂glich an den Fingern zu erkl√§ren, da nicht alle Entwickler von Mobilger√§ten damit vertraut sind.  K√∂nnen Sie uns sagen, was es ist? <br><br>  ANDREW: Basierend auf der klassischen Definition ist <strong>maschinelles Lernen eine Suche nach Mustern in einem Datensatz</strong> .  Ein klassisches Beispiel sind neuronale Netze, die heute sehr beliebt sind.  Unter ihnen gibt es Netzwerke, die sich auf die Klassifizierung beziehen.  Ein einfaches Beispiel f√ºr die Klassifizierungsaufgabe besteht darin, zu bestimmen, was auf dem Bild gezeigt wird: Es gibt eine Art Bild, und wir m√∂chten verstehen, was es ist: ein Hund, eine Katze oder etwas anderes. <br><br>  Das Schreiben mit Standardcode ist sehr schwierig, da unklar ist, wie dies zu tun ist.  Daher werden mathematische Modelle verwendet, die als maschinelles Lernen bezeichnet werden.  Sie basieren auf der Tatsache, dass bestimmte Gesetze aus einer gro√üen Anzahl von Beispielen extrahiert werden. Mit diesen Gesetzen ist es dann m√∂glich, Vorhersagen mit einiger Genauigkeit f√ºr neue Beispiele zu treffen, die nicht im urspr√ºnglichen Datensatz enthalten waren.  Dies ist auf den Punkt gebracht. <br><br>  GLEB: Lernen Sie dementsprechend eine Geschichte √ºber das √Ñndern eines Modells mithilfe eines Trainingsdatensatzes? <br><br>  ANDREW: W√§hrend des Trainings bleibt das Modell in der Regel konstant.  Das hei√üt, Sie w√§hlen eine Art Architektur und lernen sie.  Wenn wir zum Beispiel neuronale Netze nehmen, die nicht auf alles maschinelle Lernen beschr√§nkt sind, dann sind anfangs grob gesagt alle Gewichte Nullen oder andere identische Werte.  W√§hrend wir unsere Daten dem Lernrahmen zuf√ºhren, √§ndern sich die Gewichte mit jedem neuen Beispiel ein wenig und am Ende flie√üen sie in eine trainierte Maschine. <br><br>  STAS: Der ultimative Zweck dieses Modells ist es, schnell einige Daten bereitzustellen, die nicht aus dem Trainingsmuster stammen. Erhalten Sie schnell das Ergebnis? <br><br>  ANDREW: Ja, aber es geht nicht nur um Geschwindigkeit.  Beispielsweise konnten einige Aufgaben nicht anders gel√∂st werden - beispielsweise ist das Klassifizierungsbeispiel sehr nicht trivial.  Bevor die Klassifizierungsnetze abgefeuert wurden, gab es keine L√∂sungen, um zu verstehen, was auf dem Bild gezeigt wird.  Das hei√üt, in einigen Bereichen ist dies eine direkt revolution√§re Technologie. <br><br><h1>  √úber Handarbeit und maschinelles Lernen <br></h1><br>  STAS: Ich habe meiner Gro√ümutter k√ºrzlich gesagt, was maschinelles Lernen ist.  Sie dachte anfangs, dass maschinelles Lernen ist, wenn eine Maschine jemanden unterrichtet.  Ich begann ihr zu erkl√§ren, dass wir im Gegenteil versuchen, die Maschine so zu unterrichten, dass sie dann eine Aufgabe ausf√ºhrt. <br><br>  Ich stellte die Probleme vor, die maschinelles Lernen l√∂st.  Die meisten von ihnen wurden vor dem Ausl√∂sen des maschinellen Lernens von Menschen durchgef√ºhrt.  Dar√ºber hinaus wurde dies nicht als gering qualifizierte Arbeit angesehen, sondern als nicht zu hochtechnologisch.  Dies sind die einfachsten Operationen, die eine Person weitgehend ausf√ºhren kann.  K√∂nnen Sie sich das vorstellen? <br><br>  ANDREW: Das kann man auch sagen.  Tats√§chlich sind solche Arbeiten jetzt noch erforderlich, jedoch nur, um Datens√§tze f√ºr das maschinelle Lernen vorzubereiten.  In einigen Bereichen, beispielsweise in der Medizin, erm√∂glicht maschinelles Lernen, Routineaufgaben ein wenig zu gl√§tten und den Prozess ein wenig zu vereinfachen.  Aber nicht immer.  Ich w√ºrde nicht sagen, dass sich maschinelles Lernen darauf konzentriert, dummes Arbeiten zu erm√∂glichen.  Manchmal macht es einen ziemlich intellektuellen Job. <br><br>  STAS: K√∂nnen Sie ein Beispiel f√ºr eine solche intellektuelle Arbeit geben? <br><br>  ANDREW: Zum Beispiel unsere Prisma-Anwendung - viele haben sie wahrscheinlich verwendet (dies ist keine Werbung!). Es kann nicht gesagt werden, dass dies intellektuelle Arbeit ist und die Leute das Bild oft in Bilder umzeichnen, und das neuronale Netzwerk macht es - Sie geben ihm ein normales Bild und <strong>erhalten etwas Neues</strong> .  Weiter kann man dar√ºber streiten, ob es sch√∂n ist oder nicht, aber die Tatsache ist unbestreitbar, dass es etwas ist, was eine Person nicht tun kann, oder es dauert enorm viel Zeit. <br><br><h1>  √úber die Geschichte <br></h1><br>  GLEB: Ja, ich denke das ist ein gro√üartiges Beispiel.  Wahrscheinlich einen kleinen Blick auf die Geschichte wert.  Wie lange ist dieses Thema schon entwickelt?  Es scheint mir, dass fast von den Anf√§ngen der Programmierung, zumindest sehr, sehr lange her. <br><br>  ANDREW: Ja, im Allgemeinen wurden die meisten Konzepte, die jetzt angewendet werden, bereits in den 90er Jahren entwickelt.  Nat√ºrlich sind jetzt neue Algorithmen erschienen, und die Qualit√§t der damaligen Algorithmen hat sich verbessert.  Und obwohl das Gef√ºhl besteht, dass aus dem Nichts ein pl√∂tzliches Interesse an maschinellem Lernen entstanden ist, haben sich die Menschen schon lange daf√ºr interessiert. <br><br>  Fortschritte in den fr√ºhen Stadien waren auf die Tatsache zur√ºckzuf√ºhren, dass es sich haupts√§chlich um mathematische Modelle handelt und die Mathematik in Bezug auf Entdeckungen seit langem stabilisiert ist. <br><br>  Die derzeitige Explosion ist ausschlie√ülich auf die Tatsache zur√ºckzuf√ºhren, <strong>dass die Eisenkapazit√§ten um uns herum erheblich gestiegen sind</strong> , haupts√§chlich aufgrund der Verwendung von Grafikkarten.  Aufgrund der Tatsache, dass wir heute in der Lage sind, gro√üe parallele Berechnungen durchzuf√ºhren, sind neue Technologien aufgetaucht - maschinelles Lernen, Kryptow√§hrung usw. <br><br>  Das aktuelle Interesse und allgemein die aktuelle Welle h√§ngen gr√∂√ütenteils damit zusammen, dass <strong>es gerade erst m√∂glich wurde</strong> .  Diese Berechnungen k√∂nnten fr√ºher durchgef√ºhrt werden, aber katastrophal lang.  Jetzt brauchen sie eine vern√ºnftige Zeit, und so haben alle angefangen, sie zu benutzen. <br><br><h1>  √úber Eisen <br></h1><br>  STAS: Ich mache gerade einen Kurs und dort muss ich auch alle Arten von Modellen trainieren.  Ich trainiere einige davon auf meinem funktionierenden MacBook.  Ja, in einigen F√§llen m√ºssen Sie warten, vielleicht 5 Minuten, und die Modelle sind nicht die besten, die durchschnittliche Genauigkeit liegt bei 85%, aber Hauptsache, sie funktionieren.  Es ist klar, dass Sie diesen Prozentsatz im Kampf besser haben wollen und vielleicht f√ºr die Produktion nicht ganz geeignet sind. <br><br>  ANDREW: Ja, solche Modelle sind wahrscheinlich nicht sehr interessant.  Dies ist h√∂chstwahrscheinlich auf die einfachsten Vorhersagen usw. zur√ºckzuf√ºhren.  In der Realit√§t kann beispielsweise eine Trainingsprobe 90 GB wiegen, und das Erlernen kann eine Woche dauern.  Unternehmen wie Nvidia geben an, dass sie jetzt eine neue spezielle Tesla-Grafikkarte herausgebracht haben und Sie Inception V3 in 24 Stunden trainieren k√∂nnen!  Dies wird als direkter Durchbruch angesehen, da es zuvor mehrere Wochen gedauert hat. <br><br>  <strong>Je mehr Datens√§tze und je komplexer die Struktur des Modells ist, desto l√§nger dauert das Lernen</strong> .  Die Leistung ist jedoch nicht das einzige Problem.  Wenn Sie es wirklich brauchen, k√∂nnen Sie im Prinzip einen Monat warten.  Das Problem h√§ngt mit der Inferenz zusammen - wie kann man dieses neuronale Netzwerk sp√§ter anwenden?  Es ist notwendig, dass es w√§hrend seiner Verwendung auch gute Ergebnisse in Bezug auf die Leistung zeigt. <br><br>  STAS: Insbesondere m√∂chte ich, dass alles auf mobilen Ger√§ten funktioniert und schnell funktioniert. <br><br>  ANDREW: Ich glaube nicht, dass es sich urspr√ºnglich mit Blick auf die Arbeit an mobilen Anwendungen entwickelt hat.  Ein solcher Boom begann irgendwo im Jahr 2011, und trotzdem waren dies Desktop-L√∂sungen.  Jetzt wird das wahre Interesse der Community durch die Tatsache gest√ºtzt, dass es auf iPhones, einschlie√ülich, m√∂glich geworden ist, Netzwerke zu starten, die in Echtzeit funktionieren. <br><br>  GLEB: Stas, Sie sagten, dass das Endergebnis davon abh√§ngt, wie leistungsf√§hig Ihre Grafikkarte ist und im Allgemeinen das System.  Das hei√üt, es funktioniert nicht anders? <br><br>  ANDREW: Das ist nicht so, aber ich bin nicht sicher, ob das Modell auf einer Maschine mit geringem Stromverbrauch trainiert wird. <br><br>  GLEB: √úbrigens, ich erinnere mich, vor 5 Jahren, als es nur einen Boom in neuronalen Netzen gab, sagten unsere Lehrer, dass alles Neue nur gutes altes Vergessen ist.  Es war alles schon in den 70-80ern und es wird nicht funktionieren, seitdem hat es nicht mehr funktioniert.  Wahrscheinlich haben sie sich immer noch geirrt. <br><br>  ANDREW: Ja.  F√ºr einige Aufgaben hat das maschinelle Lernen jetzt sehr schwer geschossen.  Objektiv kann gesagt werden, dass sie funktionieren. <br><br><h1>  √úber tiefes Lernen <br></h1><br>  GLEB: Es gibt so etwas Modisches - tiefes Lernen.  Was ist der Unterschied zu dem, wor√ºber wir gesprochen haben? <br><br>  ANDREW: Ich w√ºrde nicht sagen, dass es Unterschiede gibt.  Es gibt nur einige Untergruppen des maschinellen Lernens, und es gibt eine gro√üe Anzahl von ihnen.  Sie m√ºssen verstehen, dass das, was als <strong>tiefes Lernen bezeichnet wird, der Teil des maschinellen Lernens ist, der √ºblicherweise als neuronale Netze bezeichnet wird</strong> .  Es wird tief genannt, weil es in neuronalen Netzen viele Schichten gibt, und je mehr Schichten, desto tiefer das neuronale Netz.  Daraus entstand der Name. <br><br>  Es gibt aber auch andere Arten des maschinellen Lernens.  Beispielsweise wurde baumbasiertes maschinelles Lernen bisher erfolgreich f√ºr die Gesichtsverfolgung eingesetzt, da es viel schneller als Neuronen ist.  Es wird auch zum Ranking, Anzeigen von Anzeigen und mehr verwendet. <br><br>  Das hei√üt, tiefes Lernen ist nichts anderes.  Dies ist eigentlich eine Teilmenge des maschinellen Lernens, die eine Menge von allem beinhaltet.  Nur tiefes Lernen ist heute am beliebtesten geworden. <br><br><h1>  √úber die Theorie der neuronalen Netze <br></h1><br>  STAS: Ich wollte ein wenig √ºber die Theorie der neuronalen Netze sprechen, ich werde es einfacher versuchen.  Sie sagten, dass sie viele Schichten haben.  Wenn wir eine Ebene haben und sich einige Objekte auf der Ebene befinden, k√∂nnen wir diese Ebene theoretisch mit Hilfe einer Ebene tats√§chlich in zwei Teile teilen, oder? <br><br>  ANDREW: Nein, nicht wirklich. <br><br>  STAS: Was gibt uns eine gro√üe Anzahl von Schichten, wenn an den Fingern? <br><br>  ANDREW: Was ist ein neuronales Netzwerk?  Lassen Sie es uns klarstellen.  Dies ist nur eine mathematische Funktion, die eine Reihe von Zahlen als Eingabe und eine Reihe von Zahlen als Ausgabe verwendet - das ist alles. <br><br>  Was ist drin?  Am beliebtesten sind nun Faltungsnetzwerke, in denen Faltung stattfindet - es gibt einfach viele Matrixmultiplikationen untereinander, die Ergebnisse werden addiert, diese Operationen werden in jeder Schicht ausgef√ºhrt.  Au√üerdem befindet sich zwischen den Schichten die sogenannte Aktivierung, die es den neuronalen Netzen nur erm√∂glicht, tief zu sein. <br><br>  Da die Kombination von linearen Transformationen eine lineare Transformation ist, k√∂nnen sie nach dem Erstellen von 10 linearen Schichten immer noch als eine lineare Schicht dargestellt werden.  Damit die Ebenen nicht kollabieren, gibt es zwischen ihnen bestimmte mathematische Aktionen, die die Funktion nichtlinear machen.  Dies ist notwendig, um die Anzahl der Parameter zu erh√∂hen. <br><br>  Grob gesagt ist ein neuronales Netzwerk nur eine riesige Anzahl von Zahlen, die dann irgendwie auf unsere Daten zutreffen, zum Beispiel auf ein Bild.  Aber ein Bild - auch eine Reihe von Zahlen - ist nur eine Reihe von Pixeln.  Wenn wir das Netzwerk trainieren, ber√ºcksichtigen wir beispielsweise 15 Millionen Parameter (jede Zahl ist ein separater Parameter), die mithilfe einiger Heuristiken leicht nach links und ein wenig nach rechts verschoben werden k√∂nnen.  Dank einer so gro√üen Anzahl von Parametern werden so coole Ergebnisse erzielt. <br><br>  Tiefes Training ist genau erforderlich, damit es viele dieser Parameter gibt und nicht alles zu einer Schicht zusammenf√§llt. <br><br>  GLEB: Es scheint mehr oder weniger klar zu sein. <br><br>  ANDREW: Deep Learning ist eine Teilmenge des maschinellen Lernens.  Aber aus irgendeinem Grund kam ein Hype zu diesem Thema auf - besonders vor einiger Zeit, von all den Rissen, ich denke, man konnte etwas √ºber tiefes Lernen h√∂ren.  Ich wei√ü nicht, ob es gerechtfertigt ist oder nicht. <br><br>  GLEB: Ich denke, dass eine solche Popularit√§t auf die Tatsache zur√ºckzuf√ºhren ist, dass sie beeindruckende Ergebnisse liefert. <br><br><h1>  √úber Aufgaben <br></h1><br>  STAS: Mit Hilfe neuronaler Netze k√∂nnen Sie die meisten Probleme des maschinellen Lernens l√∂sen, oder? <br><br>  ANDREW: Ja. <br><br>  STAS: Sprechen wir dann dar√ºber, welche Aufgaben mit Methoden des maschinellen Lernens gel√∂st werden k√∂nnen. <br><br>  ANDREW: Eigentlich ist dies ein heikles Thema, denn in Wirklichkeit muss man aufh√∂ren, das Geschehen zu idealisieren und zu romantisieren.  Wie gesagt, dort gibt es keine k√ºnstliche Intelligenz.  <strong>Dies ist ein rein mathematisches Modell und eine mathematische Funktion</strong> , die etwas multipliziert usw. <br><br>  Von der Seite scheint es, dass das maschinelle Lernen bei bestimmten Kategorien von Aufgaben etwas ins Stocken geraten ist.  Dies ist zum Beispiel die Klassifizierung (ein Beispiel, √ºber das wir gleich zu Beginn gesprochen haben), die Verfolgung von Objekten und ihre Segmentierung.  Der letzte befindet sich in unserer Sticky AI-Anwendung - er w√§hlt eine Person aus und der Hintergrund wird entfernt.  Es gibt auch eine biologische medizinische Segmentierung, wenn beispielsweise Krebszellen nachgewiesen werden.  Es gibt generative Netzwerke, die aus Zufallszahlen lernen und dann etwas Neues schaffen k√∂nnen.  Es gibt Style Transfer-Aufgaben und andere. <br><br>  Derzeit gibt es jedoch keine bequeme Plattform und Infrastruktur f√ºr die Nutzung des maschinellen Lernens.  Zum Beispiel haben Sie ein Problem, das Sie als Person leicht l√∂sen k√∂nnen, aber als Programmierer k√∂nnen Sie es aufgrund seiner Komplexit√§t und weil Sie nicht einfach einen imperativen Algorithmus schreiben k√∂nnen, nicht l√∂sen.  Gleichzeitig ist es aber auch nicht m√∂glich, ein neuronales Netzwerk zu trainieren, vor allem, weil es ein Problem mit Datenmangel gibt.  Um ein Neuron zu trainieren, ben√∂tigen Sie gro√üe Datens√§tze mit vielen Beispielen, au√üer sehr formalisierten, in einer bestimmten Verordnung beschriebenen usw.  Au√üerdem ben√∂tigen Sie die Architektur dieses neuronalen Netzwerks. <br><br>  Das hei√üt, zuerst m√ºssen <strong>Sie die Eingabedaten in Form von Zahlen</strong> formalisieren, die Modellarchitektur selbst erstellen, dann die Ausgabedaten in Form von Zahlen formalisieren und sie irgendwie interpretieren.  Dazu ben√∂tigen Sie einen ziemlich leistungsf√§higen mathematischen Apparat und im Allgemeinen ein Verst√§ndnis daf√ºr, wie alles funktioniert.  Daher scheint es mir jetzt, dass die Verwendung von Neuronen au√üerhalb spezialisierter Unternehmen wie unseres etwas nachl√§sst. <br><br>  Einige Aufgaben, die vorher nicht gel√∂st wurden, lernten Neuronen sehr cool zu l√∂sen.  Aber es gibt keine Neuronen, die das gesamte Spektrum ungel√∂ster Probleme gel√∂st haben. <br><br>  GLEB: In welchen Bereichen sehen Sie globale Probleme, f√ºr die neuronale Netze im Allgemeinen nicht geeignet sind? <br><br>  ANDREW: Es ist schwer, sofort zu antworten.  Wir stehen vor Aufgaben, an denen wir arbeiten und an denen es nicht m√∂glich ist, ein neuronales Netzwerk zu trainieren.  Zum Beispiel ist die Spielebranche jetzt sehr am Lernen interessiert, und sogar einige Neuronen haben k√ºnstliche Intelligenz.  Zum Beispiel wird dies in AAA-Spielen noch nicht verwendet, da es im Moment dennoch unm√∂glich ist, die k√ºnstliche Intelligenz eines abstrakten Soldaten so zu trainieren, dass sie sich wie eine Person verh√§lt, so dass sie nat√ºrlich aussieht.  Es ist schwer. <br><br><h1>  √úber Dota <br></h1><br>  STAS: Haben Sie geh√∂rt, dass k√ºnstliche Intelligenz in Dota bereits gewinnt? <br><br>  ANDREW: Ja, aber es ist immer noch ein bisschen anders.  Dota ist ein ziemlich mathematisches Spiel, es kann beschrieben werden.  Ich m√∂chte niemanden beleidigen, aber das ist in der Tat wie bei Dame - das Spiel ist ein und dasselbe.  Es gibt bestimmte Regeln, nach denen Sie einfach spielen. <br><br>  Gleichzeitig gibt es immer noch Schwierigkeiten, ein nat√ºrliches Verhalten zu erzeugen, das haupts√§chlich mit einer kleinen Datenmenge und einer kleinen Anzahl von Ingenieuren verbunden ist, die dies tun k√∂nnen. <br><br>  Bei Google verwenden Ingenieure beispielsweise neuronale Netze, um ein menschliches 3D-Modell f√ºr das Gehen zu trainieren - nur um es in Bewegung zu setzen.  Es sieht immer schrecklich aus, die Leute gehen nicht so. <br><br><h1>  √úber TensorFlow <br></h1><br>  STAS: Sie sagten, dass es derzeit keinen einfachen und billigen Weg gibt, Probleme des maschinellen Lernens zu l√∂sen, ohne das maschinelle Lernen √ºberhaupt zu verstehen.  In jedem Fall stellt sich heraus, dass dies gefummelt werden muss.  Ich w√ºrde gerne etwas √ºber TensorFlow erfahren.  Es scheint, dass Google versucht sicherzustellen, dass auch Leute, die sich damit nicht auskennen und keinen sehr gro√üen Hintergrund haben, einige einfache Probleme l√∂sen k√∂nnen.  Sag mir, was TensorFlow ist und wie denkst du, ist es m√∂glich? <br><br>  ANDREW: Komm schon in Ordnung.  <strong>TensorFlow</strong> <strong>ist</strong> <strong>eigentlich nicht die einfachste Sache von allen</strong> .  Dies ist eines der beliebtesten sogenannten Lern-Frameworks - ein universelles Lern-Framework, nicht unbedingt ein Neuron.  Dies ist nicht das h√∂chste verf√ºgbare Framework.  Es gibt zum Beispiel Keras, eine √ºbergeordnete Abstraktion in TensorFlow.  Dort k√∂nnen Sie dasselbe mit viel weniger Code tun. <br><br>  Typische Aufgaben werden ganz einfach gel√∂st, insbesondere weil Github bereits viele Beispiele und Repositories enth√§lt.  Wenn Ihr Unternehmen eine Bildersuche nach einem Buchladen durchf√ºhrt, ist im Prinzip alles in Ordnung f√ºr Sie.  Sie gehen zu Github, es gibt Beispiele, wie Sie Funktionen des Bildes aufnehmen k√∂nnen, Sie schreiben eine Suche nach Funktionen - Sie sind fertig! <br><br>  Tats√§chlich ist dies bei einer gro√üen Anzahl von Aufgaben der Fall.                  ,     .     -  , ,   ,     ,     ,     ,  TensorFlow ‚Äî    .    ,     . <br><br> :   ,   Google  ,        ? <br><br> : ,      ,   ,         .    ,  ,      ,       .  ,       ,        . <br><br><h1>   <br></h1><br> :      ,       .   ? -,  . <br><br> : .     ‚Äî     ¬´   ,   ,   ¬ª. ,   . <br><br> : , , ,     ,     .     ?  ,     ,       15   -  iOS ,  - .    ,    .  ,   . <br><br> :   ‚Äî , , -   .    ‚Äî  ‚Äî .      . ,  ,   R&amp;D   ,   : ¬´,   !¬ª ‚Äî - ,  ,     ,     0,5%: ¬´,   ,   !¬ª   .    ,      . <br><br> :         ,  ,  -      , ,    .   ?  .    ,          ‚Äî ,  70%.    ,        ,    .   ,     .     ,    ,     . <br><br> : ,   , ,   .      ,    .   ,   - ,      .    . <br><br> :  ,        . <br><br><h1>    <br></h1><br> :     ,  .    . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wl/fb/eo/wlfbeojhnc13z4_wcooqk5bhu4e.png"></div><br><br> :     ,       ?   ,   ,  ,   ‚Äî  ? <br><br> :     ,    ,      .      ,       . <br><br> -,  ,   <strong>   </strong> .       ,   computer science.      ,             . <br><br>        .       ,    500   Python,   .        .         .     ,      .      ,     ,   . <br><br>   ,     .  -  ,           .     ,         . <br><br> :  ,        Python   -  , ,  C++?       ,    . <br><br> : ,   .     - learning , ,  TensorFlow,        TensorFlow.    ,    <br><br>   ‚Äî    ,     TensorFlow.      TensorFlow ‚Äî      1  ‚Äî  ,   ,  . <br><br>      . ,  iOS    .       ,      learning ,  ,   Caffe, Torch, TensorFlow  .,            . <br><br>      ,        ,  ,   . R&amp;D  - ,  .              .     ()  : ¬´  !¬ª ‚Äî      ,           .         C++. <br><br>      : <br><br><ul><li> ,   .   ,     . <br></li><li>     . <br></li></ul><br><h1>    <br></h1><br> :      .    ,     ,     . <br><br> : ,       ?          , ? <br><br> :  ,     .  ,           ‚Äî   .    :   ,    ,   : ¬´,    ,   ‚Äî ¬ª,  -      .   , , -,        - .      ,      .    . <br><br>         .  ,   ,    ,         . <br><br> :     Google   ,         Google Street Maps. ,    . <br><br> : ,     -     . <br><br><h1>   Data Scientist <br></h1><br> :      .   ,       ‚Äî   ,   ,   ? <br><br> :   ,   . <br><br> : ,   ,    , ,  data scientist'.    ,   -  .    .          ,    ,       .   ‚Äî     ! <br><br>      ,    .      ,      -,      .   . <br><br> :        hype train. <br><br> : ,       ,    data scientist  .     ,      . <br><br> :   ,   .   -   data scientist'? <br><br> :    .    ,  .     ,  ,     ,  Git-     . Data scientist -  ,     .      ,  code review, unit- ‚Äî      .       ,      . <br><br> :    ,      ,     . <br><br> : ,         ,      - , , Kaffe 2, PyTorch ‚Äî   !    : ¬´ Data scientist  TensorFlow¬ª. <br><br><h1>  GPU- <br></h1><br>          .  ,    ,      ,    Swift,      UI-kit,   .  ,     ,       . <br><br>  ,   -  ,      .        ,       .   ,   ,     .          enterprise. <br><br>      - ,  ,     ,      . ,      ,    .     ,   . <br><br> :        ,       .   GPU   -    .      ,     ‚Äî         .   ,      Junior GPU   .    ,  ,         . <br><br><h1>   <br></h1><br> :    ‚Äî   . <br><br> :      ,   ? <br><br> : ,   ,        - . <br><br> :    ‚Äî      ? <br><br> :    , , -, -  . <br><br> :    ,        ? <br><br> :      .     , ,  ,         ,     .          Macbook Air.           ‚Äî -      ,     ,  . <br><br>        ,      Nvidia Titan   ,    .     ,     . <br><br><h1>   <br></h1><br> :     ?    ,    Nvidia     ,   .  ,     ,    .      ? <br><br> :                print   ,        .     NIPS,   ,         ,         .   , ,    .    - ,      ‚Äî    ,      . <br><br>   .    ONNX       ,     .     .   ,     .    ,    ,   .  ,    - ,     <strong>   </strong> .       . <br><br><h1>   <br></h1><br> :    ,    .   ,           ,    ,     ? <br><br> : ,       .   ,        .        ,    .       ,        ‚Äî   ,      .. <br><br>   ,      .  ,    .    ‚Äî  ,        ,        .   .    ,          ,       .         ,         ,   . <br><br><h1>  reinforcement training     <br></h1><br> :         .  ,    ,  , , AlphaGo.  ,    ,   ,    reinforcement training. <br><br> : Reinforcement training ‚Äî   .    ,    . ,   , ,        .    ,           ,      .   ,      . Reinforcement training   ,   ,    ,      ,  : ¬´ !¬ª <br><br> ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AlphaGo</a> ‚Äî   ,    .      ,       .    ,     ,    .          ,       .  AlphaGo    ,    reinforcement training,   ,       . <br><br> ,           ,    ,       ,    . <br><br> :     ,    10 <sup>170</sup>  ‚Äî   .  ,      AlphaGo   .        ,    .   ,  , , .   ‚Äî  , -    ! <br><br>       ,    ,         ,    .          ,       ,       . ,   ! <br><br><h1>    <br></h1><br>  STAS: Ich m√∂chte nach genetischen Algorithmen fragen.  Der Beschreibung zufolge k√∂nnen genetische Algorithmen auch dem verst√§rkten Lernen zugeschrieben werden.  Wie ich mir vorstelle, gibt es eine Generation, wir nehmen jedes einzelne Thema in einer Generation auf, es f√ºhrt eine Aufgabe aus, wir bewerten seine Handlungen und w√§hlen dann basierend auf diesen Sch√§tzungen das beste aus.  Dann kreuzen wir ihre spezifischen Eigenschaften, erstellen eine neue Generation, f√ºgen ein wenig Mutation hinzu und jetzt haben wir eine neue Generation.  Und wir wiederholen diese Operationen und versuchen, den endg√ºltigen Nutzen jedes einzelnen Mitglieds dieser Generation zu erh√∂hen.  Das scheint sinnvoll zu sein.  Wird dies als Verst√§rkungstraining angesehen oder nicht? <br><br>  ANDREW: Nein, genetische Algorithmen sind immer noch etwas anders. <br><br>  STAS: Beziehen sie sich auf maschinelles Lernen? <br><br>  ANDREW: Das w√ºrde ich nicht sagen.  Ich werde es jetzt nicht nehmen, aber wir haben die genetischen Algorithmen an der Universit√§t wie alle anderen bestanden, und es scheint mir, dass diese Sache etwas einfacher und unregulierter ist oder so - kurz gesagt, zwingend.  Das hei√üt, es ist im Voraus bekannt, dass das, was eingegeben wird, so ausgegeben wird.  Beim maschinellen Lernen sind die Dinge jedoch etwas anders - es gibt eine gewisse Wahrscheinlichkeit, Genauigkeit der Vorhersagen und alles in diesem Sinne. <br><br>  Vielleicht werde ich von Leuten korrigiert, die die Terminologie besser verstehen als ich, aber <em>von oben</em> w√ºrde ich nein sagen. <br><br>  STAS: Es stellt sich heraus, dass genetische Algorithmen nicht zur L√∂sung der meisten realen Probleme verwendet werden. <br><br>  ANDREW: Ja, sie sind meistens algorithmischer und in der Praxis habe ich sie selten getroffen. <br><br><h1>  √úber Kapselnetzwerke <br></h1><br>  GLEB: Es gibt noch eine andere Untergruppe des maschinellen Lernens - die sogenannten Kapselnetzwerke.  Gehen wir noch einmal nicht zu tief.  Sagen Sie mir kurz und b√ºndig, was es ist und warum es diesen Trend jetzt gibt? <br><br>  ANDREW: Dies ist ein wirklich super neues Thema, es ist nur ein paar Monate alt.  Jeffrey Hinton ver√∂ffentlichte einen Artikel und sagte, dass aktuelle Faltungsnetzwerke ein Weg ins Nirgendwo sind, und wir bieten eine neue Vision, wie sich dies entwickeln wird.  Die Community akzeptierte diese Aussage mehrdeutig und teilte sie in zwei Lager auf: Einige sagen, dass es ein √úberhype ist, andere - eine gro√üe Sache und all das. <br><br>  Aber wenn Sie direkt an den Fingern erkl√§ren, wie funktionieren Faltungsnetzwerke?  Nehmen wir zum Beispiel Neuronen, die mit Bildern arbeiten.  Es gibt eine Faltung - eine Spalte von Matrizen, die mit einem Schritt durch das Bild l√§uft, als w√ºrde sie es scannen.  Bei jeder Iteration eines solchen Schritts wird all diese Faltung auf dieses St√ºck angewendet, und jede Faltung wird zu einem neuen bedingten Pixel, aber von einer viel gr√∂√üeren Dimension wird diese Operation f√ºr alle Gitter wiederholt. <br><br>  Das Problem bei Faltungsnetzwerken ist jedoch, dass alle Daten, die in die erste Schicht gelangen, das Ende erreichen - vielleicht nicht vollst√§ndig, aber sie wirken sich alle aus und erreichen alle das Endstadium.  Wenn Sie einen Teil des Bildes bestimmen m√ºssen, z. B. eine Katze, m√ºssen Sie grob gesagt nicht das gesamte Bild scannen.  Es reicht aus, irgendwann die Zone zu lokalisieren, in der sich die Katze h√∂chstwahrscheinlich befindet, und nur sie zu betrachten, wie es eine Person tut. <br><br>  So funktionieren Kapselnetzwerke.  Ich werde mich nicht verpflichten, ihre Innenseiten fachm√§nnisch zu erkl√§ren, sondern nach meinem Verst√§ndnis: Es gibt bestimmte B√§ume innerhalb der Kapselnetzwerke, und jede nachfolgende Kapsel erh√§lt nur die relevanten Daten f√ºr die Eingabe.  Das hei√üt, durch sie wird nicht alles weitergegeben, was wir urspr√ºnglich f√ºr die Eingabe akzeptiert haben, und mit jeder neuen Schicht (ich wei√ü nicht, wie es in der Terminologie von Kapselnetzwerken gesagt werden kann) werden nur die Daten verarbeitet, die wirklich ben√∂tigt werden - nur wichtige Daten .  Dies ist der Hauptunterschied zwischen Faltungs- und Kapselnetzwerken. <br><br>  GLEB: Es klingt interessant, aber ich verstehe nicht ganz - geht es nur um die fraglichen Bilder? <br><br>  ANDREW: Nein, das war's auch schon.  Ich habe die Bilder nur zur Erkl√§rung verwendet.  Die Schl√ºsselidee lautet: Lassen Sie uns nicht alle Daten und Funktionen steuern, sondern nur diejenigen, die f√ºr die n√§chste Ebene relevant sind. <br><br><h1>  Mehr √ºber Spiele <br></h1><br>  STAS: Hast du geh√∂rt, dass die AlphaGo-Jungs alle in StarCraft besiegen werden? <br><br>  ANDREW: Ich bin gezwungen dich zu entt√§uschen, aber ich folge dem nicht wirklich.  Es ist nicht so, dass eSports f√ºr mich interessant war, aber es wird bereits klar, worin die Zukunft liegt.  Zum Beispiel gibt es bereits Startups, die f√ºr das Spielen von Dota ausgebildet sind.  Als Personal Trainer analysieren sie, wie Sie spielen, und sagen, wo Sie nicht gut genug sind, haben sie ihre eigenen Daten, die in E-Sport-Spielen trainiert wurden.  Es gibt Startups f√ºr Wetten, die vorhersagen, wer gewinnen wird, und vieles mehr. <br><br>  In diesem Bereich arbeiten derzeit viele Menschen, vor allem, weil sich dort viel Geld dreht.  Aber pers√∂nlich ist es f√ºr mich einfach v√∂llig uninteressant, daher verfolge ich die Nachrichten und Trends leider nicht. <br><br>  STAS: Was ist Ihrer Meinung nach die Schwierigkeit, eine gute k√ºnstliche Intelligenz speziell f√ºr strategische Spiele zu entwickeln?  Verstehe ich richtig, dass dies im Grunde eine sehr gro√üe Anzahl von Optionen ist? <br><br>  ANDREW: Ja.  Tats√§chlich haben wir diesen Punkt bereits besprochen, als ich erkl√§rte, dass k√ºnstliche Intelligenz in AAA-Spielen immer noch nicht verwendet wird, aber gleichzeitig in AlphaGo und m√∂glicherweise woanders. <br><br>  Das Go-Spiel mit all seiner Komplexit√§t besteht darin, dass Sie bei jedem Schritt einfach einen Chip einsetzen, um einen Stein zu skizzieren, und das Spiel StarCraft ist eine sehr komplexe Sache.  Dort k√∂nnen Sie Ihre Einheiten entlang einer praktisch unbegrenzten Anzahl von Trajektorien senden, verschiedene S√§tze Ihrer Konstruktionen erstellen usw. All dies ist ein Parameter. <br><br>  Die Schwierigkeit liegt au√üerdem darin, dass neuronale Netze nicht immer wie eine Person denken.  Wenn wir zum Beispiel eine Einheit bauen, erinnern wir uns daran.  Aber jedes Mal laufen viele Neuronen.  Nat√ºrlich gibt es rekursive Netzwerke, die sich an ihre bisherigen Erfolge erinnern k√∂nnen.  Sie werden insbesondere f√ºr √úbersetzungs- und Textinformationen verwendet, wenn das Neuron beim Generieren des Satzes immer mehr Daten verwendet. <br><br>  Es gibt gro√üe Schwierigkeiten mit der Tatsache, dass die gesamte Menge an Informationen und Optionen formalisiert werden muss, dh um einen Datensatz f√ºr das Training zu finden, damit er irgendwie angemessen auf die Aktionen Ihres Gegners reagiert, die im Gegensatz zum Spielen eines Spiels auch eine Million sein k√∂nnen oder Schach. <br><br>  STAS: Ich verstehe - es gibt viele Parameter. <br><br>  GLEB: Aber ich verstehe nicht, es ist klar, dass DotA weniger Parameter hat, aber es ist immer noch ungef√§hr gleich in dem Sinne, dass es irgendwohin gesendet wurde usw. <br><br>  STAS: Hier hat sich Andrei darauf reduziert, dass Sie erstens eine Einheit haben und die Anzahl der Optionen viel geringer ist. <br><br>  ANDREW: Um ehrlich zu sein, ich habe noch nie in meinem Leben einen zweiten Dota gespielt, aber im Original ist dies, soweit ich wei√ü, ein super deterministisches Spiel.  Es gibt 3 Korridore und T√ºrme, die zerst√∂rt werden m√ºssen. <br><br>  GLEB: Ja, aber in StarCraft gibt es, obwohl ich √ºberhaupt nicht spiele, auch einige M√∂glichkeiten und die gleichen Einheiten.  Sie sagen, dass es viele von ihnen gibt, aber h√∂chstwahrscheinlich werden sie immer in Chargen gefahren.  Das hei√üt, ungef√§hr das Gleiche stellt sich heraus. <br><br>  STAS: Sie m√ºssen jede Einheit w√§hrend des Kampfes immer noch korrekt anordnen.  In dem Moment, in dem sie nicht in einer Packung aufgenommen werden, sondern zu arrangieren beginnen, gibt es sofort mehr Parameter. <br><br>  ANDREW: Ihr Problem ist, dass Sie in diesen Kategorien denken: Setzen Sie eine Einheit usw., aber Sie vergessen immer wieder, dass ein Neuron nur eine Matrix ist - Zahlen, die sich multiplizieren.  Dort m√ºssen Sie beispielsweise Aufgaben formalisieren.  Nehmen wir an, es gibt eine Karte f√ºr StarCraft und eine Aufgabe - es spielt keine Rolle, ob Sie einen Spieler oder etwas anderes besiegen.  All dies muss in Form von mathematischen Grundelementen dargestellt werden, und dies ist genau das Schwierigste. <br><br>  Wenn es wirklich k√ºnstliche Intelligenz w√§re, w√§re die L√ºcke zwischen Dota und StarCraft minimal.  StarCraft mag in der Mechanik etwas komplizierter sein, aber immer noch ungef√§hr gleich.  Aufgrund der Tatsache, dass wir mit Zahlen arbeiten, ist es jedoch schwieriger zu formalisieren. <br><br><h1>  √úber gegenseitige Lernnetzwerke <br></h1><br>  STAS: Ich habe die letzte Frage, die ich stellen m√∂chte, bevor wir zu unserem Handy gehen.  Ich wei√ü nicht, wie es richtig hei√üt, aber es gibt eine M√∂glichkeit, wie ein neuronales Netzwerk im Wesentlichen einem anderen folgt und versucht, Muster zu finden. <br><br>  ANDREW: Ich werde mich nicht verpflichten, jetzt zu erkl√§ren, wie es funktioniert, aber ich wei√ü mit Sicherheit, dass es supercoole Algorithmen gibt, von denen ich manchmal bei der Arbeit h√∂re, wenn zwei neuronale Netze auf Kosten des anderen lernen.  Dieses Fachgebiet ist f√ºr mich bereits v√∂llig unzug√§nglich, aber es klingt alles cool.  Soweit ich wei√ü, wird dies f√ºr generative Netzwerke verwendet.  Mehr kann ich leider nicht sagen. <br><br>  STAS: Gut.  Sie haben die wichtigsten Schl√ºsselw√∂rter angegeben, der Rest ist Gleb und die Leser werden leicht googeln. <br><br><h1>  √úber Mobiltelefone (Apple) <br></h1><br>  GLEB: Gehen wir weiter zu den Handys, die wir schon lange haben.  Was k√∂nnen wir tun, wenn wir √ºber maschinelles Lernen auf Mobilger√§ten sprechen? <br><br>  ANDREW: Hast du √ºbrigens einen Podcast f√ºr iOS-Entwickler? <br><br>  GLEB: Wir sind kein iOS-Podcast.  Ja, Stas? <br><br>  STAS: Ja, f√ºr mobile Entwickler.  Warum die Frage? <br><br>  ANDREW: Nur weil die Situation ganz anders ist.  Apple ist aufgrund der Tatsache, dass es schon immer gut in der Integration von Software und Hardware war und daf√ºr bekannt ist, sehr elegant in einen maschinengeschulten Hype-Zug eingebunden. <br><br>  Im Jahr 2014 f√ºhrte Apple die Metal-Grafik-API ein.  Darin wurden Dinge eingen√§ht, zum Beispiel Computer-Shader usw. All dies erm√∂glichte es mit dem Aufkommen von iOS 10, viele Ebenen, Aktivierungen und andere Operatoren aus neuronalen Netzen, insbesondere Faltungs-Neuronale Netze, in das Metal Performance Shaders-Framework aufzunehmen. <br><br>  Es hat nur einen enormen Schub gegeben, da Berechnungen auf einer Grafikkarte in der Regel um ein Vielfaches schneller sind als auf einem Zentralprozessor.  Als Apple die M√∂glichkeit erhielt, schnell auf mobilen Grafikkarten zu lesen, war es nicht erforderlich, eigene mathematische Operatoren usw. zu schreiben.  Es schoss direkt sehr hart.  Und ein Jahr sp√§ter ver√∂ffentlichten sie CoreML (wir werden etwas sp√§ter dar√ºber sprechen). <br><br>  Apple hatte eine sehr gute Grundlage.  Ich wei√ü nicht, ob sie eine solche Vision hatten oder so zusammenfielen, aber sie sind jetzt objektiv f√ºhrend in der Branche des maschinellen Lernens auf Mobilger√§ten. <br><br><h1>  √úber Mobiltelefone (Android) <br></h1><br>  Was unter iOS in Echtzeit relativ cool und gro√üartig funktioniert, funktioniert unter Android leider nicht so cool.  Dies liegt nicht nur daran, dass Android schei√üe ist.  Es gibt noch andere Faktoren - vor allem die Tatsache, dass Android √ºber eine sehr vielf√§ltige Infrastruktur verf√ºgt: Es gibt schwache Ger√§te, es gibt starke - Sie k√∂nnen nicht alles unter Kontrolle bringen. <br><br>  Wenn Metal auf allen iOS-Ger√§ten unterst√ºtzt wird, ist es auf Android bereits komplizierter - irgendwo wird OpenGL in einer Version unterst√ºtzt, irgendwo anders, irgendwo wird es √ºberhaupt nicht unterst√ºtzt.  Irgendwo ist Vulkan, irgendwo nicht.  Alle Hersteller haben ihre eigenen Treiber, die nat√ºrlich in keiner Weise optimiert sind, sondern den Standard nur minimal unterst√ºtzen.  Es kommt sogar vor, dass Sie einige neuronale Netze unter Android auf der GPU ausf√ºhren und diese genauso schnell arbeiten wie auf der CPU, da die Arbeit mit gemeinsam genutztem Speicher sehr ineffizient ist. <br><br>  Unter Android sind die Dinge momentan schlecht.  Dies ist ziemlich √ºberraschend, da Google einer der f√ºhrenden Anbieter ist, in dieser Hinsicht jedoch ein wenig nachl√§sst.  Unter Android mangelt es eindeutig an einer qualitativ hochwertigen Implementierung der Funktionen des modernen maschinellen Lernens. <br><br>  F√ºr uns zum Beispiel funktionieren selbst in der Anwendung nicht alle Funktionen gleich.  Was unter iOS schnell funktioniert, ist unter Android langsamer, selbst auf Flaggschiffger√§ten mit vergleichbarer Leistung.  In diesem Sinne sinkt Android als Plattform derzeit. <br><br><h1>  √úber CoreML <br></h1><br>  STAS: Da sie √ºber CoreML gesprochen haben, w√§re es wahrscheinlich richtig, √ºber TensorFlow Lite zu sprechen. <br><br>  ANDREW: CoreML ist eigentlich ein dunkles Pferd.  Als er letztes Jahr herauskam, sagten alle zuerst: "Wow, cool!"  Aber dann wurde klar, dass dies nur eine kleine H√ºlle √ºber Metal ist.  Unternehmen, die sich ernsthaft mit maschinellem Lernen besch√§ftigen, einschlie√ülich unserer, haben seit langem ihre eigenen L√∂sungen.  Zum Beispiel zeigten unsere Testl√∂sungen bessere Ergebnisse als CoreML in Bezug auf Geschwindigkeit und andere Parameter. <br><br>  Das Hauptproblem bei CoreML war jedoch, dass es nicht angepasst werden konnte.  Manchmal kommt es vor, dass Sie eine komplexe Schicht in einem neuronalen Netzwerk ben√∂tigen, die sich beispielsweise nicht in Metal befindet, und Sie m√ºssen sie selbst schreiben.  In CoreML war es nicht m√∂glich, Ihre Ebenen einzubetten. Daher mussten Sie ein Downgrade auf Metal auf die untere Ebene durchf√ºhren und alles selbst schreiben. <br><br>  Vor kurzem hat CoreML dies hinzugef√ºgt, und jetzt ist dieses Framework interessanter geworden.  Wenn Sie ein Entwickler sind, der im Unternehmen oder in der Anwendung √ºberhaupt nichts mit maschinellem Lernen zu tun hat, k√∂nnen Sie ein Neuron direkt in zwei Zeilen ausf√ºhren und es schnell auf der GPU ausf√ºhren.  Die Ergebnisse, die Leistungstests f√ºr CoreML zeigen, sind vergleichbar mit kundenspezifischen L√∂sungen und Bare Metal. <br><br>  Das hei√üt, CoreML funktioniert ganz gut.  Es ist ein bisschen feucht, es hat Fehler, aber jeden Monat wird es besser.  Apple f√ºhrt aktiv Updates ein - nicht so, wie wir es gewohnt sind, dass Updates von Apple Frameworks einmal im Jahr oder auf Semi-Major-Versionen von iOS ver√∂ffentlicht werden.  CoreML wird aktiv aktualisiert, in diesem Sinne ist alles gro√üartig. <br><br>  TensorFlow Lite bietet einen Konverter in CoreML, CatBoost unterst√ºtzt auch einen Konverter in CoreML.  Kurz gesagt, Apple hat alles wieder richtig gemacht.  Sie ver√∂ffentlichten einen Open-Source-Konverter und sagten: "Schreiben wir alle Konverter in CoreML" - und viele Lern-Frameworks unterst√ºtzten dies. <br><br>  Anfangs gab es einige Skepsis gegen√ºber CoreML, beim letzten WWDC war die h√§ufigste Frage f√ºr CoreML-Entwickler: ‚ÄûWarum erlauben Sie nicht das Herunterladen von Modellen aus dem Internet?  Warum l√§sst du sie nicht verschl√ºsseln? "  Es war m√∂glich, diese Modelle zu bekommen und, wie sich herausstellte, geistiges Eigentum zu stehlen. <br><br>  Jetzt wurde alles repariert, zus√§tzliche Funktionen hinzugef√ºgt, und im Moment ist CoreML definitiv die f√ºhrende Plattform in diesem Sinne. <br><br>  STAS: K√∂nnen Sie genauer dar√ºber sprechen?  Es stellt sich heraus, dass Sie das Modell jetzt nicht mehr speichern k√∂nnen, sondern nur von irgendwoher laden k√∂nnen? <br><br>  ANDREW: Ja, das ist schon m√∂glich.  Zuvor, als wir danach fragten, l√§chelten die Entwickler und sagten: "Schauen Sie sich nur die √úberschriften an."  Es gab wirklich Designer, die Dateien √ºbertragen konnten und alles w√ºrde zusammenkommen. <br><br>  Aber die CoreML-Modelle im Inneren sind ziemlich interessant.  Es handelt sich eigentlich um gew√∂hnliche Bin√§rdateien, in denen Gewichte gespeichert werden. Au√üerdem werden schnelle Dateien generiert, die dann implizite Klassen erstellen.  Sie verwenden diese Klassen in Ihrer Anwendung, und Compiler kompilieren dieses Modell in einige Dateien. <br><br>  Mit bestimmten Hacks und Ans√§tzen ist es nun m√∂glich, dieses Modell portabel zu machen.  Sie k√∂nnen Ihr geistiges Eigentum durch Verschl√ºsselung sch√ºtzen und das Gewicht der Anwendung verringern. <br><br>  Im Allgemeinen bewegt sich CoreML jetzt in die richtige Richtung.  Aus Sicht von App Review kann nicht alles legal durchgef√ºhrt werden, nicht alles kann problemlos ohne Hacks durchgef√ºhrt werden, aber es f√§llt auf, wie Entwickler das Framework verbessern. <br><br>  STAS: Cool!  Ich wollte hinzuf√ºgen, dass CoreML wie eine typische L√∂sung aussieht.  Relativ gesehen ist es praktisch, wenn Sie mit maschinellem Lernen in Ihrer Anwendung etwas Einfaches tun m√∂chten.  Wenn dies eine typische Aufgabe ist, hat Apple anscheinend versucht, diese gesamte Route so einfach wie m√∂glich zu gestalten, wenn Sie ein fertiges Modell, einen Datensatz und mehr finden.  Dies ist nur eine Geschichte √ºber ein typisches Problem, denn f√ºr sie ist wahrscheinlich bereits alles fertig. <br><br>  ANDREW: F√ºr typische Aufgaben ist das im Allgemeinen super!  Ohne √úbertreibung - es werden wirklich zwei Codezeilen ben√∂tigt, um das Modell auszuf√ºhren.  In diesem Sinne ist es sehr cool, insbesondere f√ºr Indie-Entwickler oder Unternehmen, die keine Forschungs- und Entwicklungsabteilung haben, aber auch etwas Cooles hinzuf√ºgen m√∂chten. <br><br>  Dies ist jedoch nicht so interessant, da die typischen Aufgaben auf Github und mit Metal gel√∂st wurden - Sie k√∂nnen diesen Code einfach in sich selbst kopieren und auf die Farm stellen - wenn auch etwas komplizierter. <br><br>  Es ist wichtig, dass sich dieser Rahmen jetzt nicht nur in Richtung klassischer Alltagsaufgaben bewegt, sondern auch in Richtung integrierter L√∂sungen.  Das ist echt cool! <br><br><h1>  √úber das Training auf Mobiltelefonen <br></h1><br>  GLEB: Sie sagen, dass es nach dem Aufkommen von Metal m√∂glich wurde, Modelle auf Mobiltelefonen zu trainieren? <br><br>  ANDREW: Nein, ein Training auf Mobiltelefonen war nie m√∂glich.  Es macht keinen Sinn, Sie k√∂nnen es nur ausf√ºhren.  Wenn ich das sagte, machte ich eine Reservierung.  Auf Handys unterrichtet nat√ºrlich niemand etwas. <br><br>  STAS: Ich habe auch nichts √ºber das Training auf einem Handy geh√∂rt. <br><br>  GLEB: Ich habe es auch nicht geh√∂rt, aber ich habe dar√ºber nachgedacht.  Nat√ºrlich scheint es intuitiv, dass dies eine seltsame Sache ist.  Aber es gibt definitiv keine interessanten Aufgaben, wann w√§re dies relevant? <br><br>  ANDREW: Es ist schwer sich das vorzustellen.  Wenn es so etwas gibt, dann nur verteiltes Lernen.  Es gibt sogar wissenschaftliche Artikel dar√ºber, aber wie ich es verstehe, fragen Sie sich, wie Sie aus den auf demselben Telefon gesammelten Daten lernen k√∂nnen?  Es ist nur so, dass selbst wenn Sie so viel sammeln (was nicht passieren wird), es so lange dauern wird, bis Sie erfahren, dass es niemals enden wird und niemand den Trainingscode auf mobile Plattformen portieren wird. Warum?  <strong>Das Training findet immer auf Servern und die Inferenz auf Ger√§ten statt.</strong> <br><br>  STAS: Aber letztendlich stellt sich das so heraus.  Wenn Sie ein Unternehmen sind, m√∂chten Sie so etwas haben, ben√∂tigen Sie Daten und k√∂nnen diese von Ihren Benutzern sammeln, dh regelm√§√üig selbst laden. <br><br>  ANDREW: Ja, aber es funktioniert ein bisschen anders.  Sie sammeln Daten von allen Benutzern an einem Ort auf Ihrem Hot Server, trainieren dort und senden das fertige Modell zur√ºck.  Aber nicht, damit jeder zu Hause etwas lehrte. <br><br>  STAS: Andererseits w√ºrde sich das Handy aufw√§rmen - und im Winter w√§re es relevant, aber f√ºr eine sehr, wahrscheinlich lange Zeit. <br><br><h1>  √úber Handys und die Zukunft <br></h1><br>  GLEB: Gibt es noch andere interessante Dinge in Bezug auf die Anwendung von maschinellem Lernen auf mobile Ger√§te?  Wir haben dar√ºber gesprochen, was wir jetzt schon haben.  Es w√§re interessant, ein wenig in die Zukunft zu schauen - damit wir generell auf unseren mobilen Plattformen einige Superfoods, Superl√∂sungen erhalten m√∂chten. <br><br> : ,   ,    performance ‚Äî   ,    ,   . ,    - ,       . <br><br>     . ,         style-     ,       .         . <br><br>    CoreML   .  ,  ,      .   ,    ,   :   , ,  ‚Äî  ,       Android,   iOS,       .     ,         ,        iOS    Android. <br><br>   ,     ,    ,  ,      ‚Äî   Android,   iOS,   Github       .   -  ‚Äî   Uber   ,   Horovod.  Apple    ‚Äî      ,    .  ,     ,  ,   ,   ‚Äî          . <br><br> ,       .   , , ,      ‚Äî   ,   ,    - .     ,   . <br><br><h1>     <br></h1><br> :    ,     ,   ?  , ,      ?         . <br><br> :      ,     ‚Äî   (M. Bishop. Pattern Recognition and Machine Learning. Christopher. Springer. 2006),  -  .    ,      ,     3D ,     ,  - .      .   ,       ‚Äî    ,  ‚Äî     . <br><br>    ,     ,        ,    .   ,    -, ,      Andrew Ng  Coursera.       ,        . <br><br>      ,  ,         ,       ‚Äî          MNIST.   Hello World,     . <br><br> ,    ,    , , -    ,  .   -   ,   ,    ,     . <br><br> :   ? <br><br> :    advanced-  Andrew Ng! , ,  Kaggle,   ,       .          ,          ,    ‚Äî        Data Scientist. <br><br>   ‚Äî  ,     , ,     .      ,     ‚Äî        R&amp;D .    ,   .         .       ,      ,    . <br><br>       .    ,    Kaggle,  -  ‚Äî         90%  . <br><br><h1>  Zusammenfassung <br></h1><br> :    .  ,           ,     ,   ,        . <br><br><ul><li>  ,    ‚Äî    . ,   ,   ‚Äî      . </li><li>         . </li><li>        . </li><li> -    . </li><li> ,      ,  ,        . <br></li><li>       ,   . , ,    ,  -  - ! </li><li>         ‚Äî  ,    ,  CoreML ‚Äî  ,    . </li></ul><br>      ,     . <br><br><blockquote> ,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AppsConf 2018</a> ,   8  9   . <br><br>      80 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ,  Call for Papers   ‚Äî <strong>   3 </strong> . ,   ,         . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416477/">https://habr.com/ru/post/de416477/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416467/index.html">Wie viel dunkle Materie geht jede Sekunde durch Ihren K√∂rper</a></li>
<li><a href="../de416469/index.html">Bitcoin Wallet Synchronisation</a></li>
<li><a href="../de416471/index.html">Jeff Bezos 'Blue Origin plant, bis 2023 auf dem Mond zu landen</a></li>
<li><a href="../de416473/index.html">Stadtschnittstelle: taktile Fliesen auf den B√ºrgersteigen</a></li>
<li><a href="../de416475/index.html">Der Opportunity Rover ist aufgrund des Staubsturms auf dem Mars immer noch still</a></li>
<li><a href="../de416479/index.html">String-Verkettung oder Patch-Bytecode</a></li>
<li><a href="../de416481/index.html">Yuri Akkermann: ‚ÄûEines der Grundprinzipien der FIDO-Allianz ist die Gew√§hrleistung der Privatsph√§re.‚Äú</a></li>
<li><a href="../de416483/index.html">Rollenspiel - das √§lteste Format einer v√∂llig freien Welt in Spielen</a></li>
<li><a href="../de416485/index.html">SpaceX arbeitet daran, ein winziges "U-Boot" zu bauen, um Jugendliche aus einer H√∂hle in Thailand zu retten</a></li>
<li><a href="../de416487/index.html">Radio Astron wird 7 Jahre alt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
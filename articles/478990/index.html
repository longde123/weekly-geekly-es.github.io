<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßòüèø üåá üëì Instalaci√≥n de la instalaci√≥n de almacenamiento a prueba de fallas distribuida de LeoFS compatible con clientes que usan S3, NFS üë©üèº‚Äçüíª üßöüèæ üöµ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Soy de Luxoft 
 Seg√∫n Opennet : LeoFS es una instalaci√≥n de almacenamiento tolerante a fallas distribuida para objetos LeoFS , compatible con clientes...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Instalaci√≥n de la instalaci√≥n de almacenamiento a prueba de fallas distribuida de LeoFS compatible con clientes que usan S3, NFS</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/478990/"><p>  Soy de Luxoft <br>  Seg√∫n <a href="https://www.opennet.ru/opennews/art.shtml%3Fnum%3D48357" rel="nofollow">Opennet</a> : <a href="http://leo-project.net/leofs/index.html" rel="nofollow">LeoFS</a> es una instalaci√≥n de almacenamiento tolerante a fallas distribuida para objetos <a href="http://leo-project.net/leofs/index.html" rel="nofollow">LeoFS</a> , compatible con clientes que utilizan la API de Amazon S3 y REST-API, y tambi√©n admite el modo de operaci√≥n como un servidor NFS.  Hay optimizaciones para almacenar objetos peque√±os y muy grandes, hay un mecanismo de almacenamiento en cach√© incorporado, es posible la replicaci√≥n de almacenamientos entre centros de datos.  Entre los objetivos del proyecto se encuentra el logro del 99.9999999% de confiabilidad debido a la replicaci√≥n excesiva de duplicados y la eliminaci√≥n de un solo punto de falla.  El c√≥digo del proyecto est√° escrito en Erlang. </p><br><p>  LeoFS consta de tres componentes: </p><br><ul><li>  <a href="https://leo-project.net/leofs/docs/architecture/leo_storage/" rel="nofollow">LeoFS Storage</a> : presta servicios a las operaciones de agregar, recuperar y eliminar objetos y metadatos, es responsable de replicar, restaurar y poner en cola las solicitudes de los clientes. </li>
<li>  <a href="https://leo-project.net/leofs/docs/architecture/leo_gateway/" rel="nofollow">LeoFS Gateway</a> : atiende las solicitudes HTTP y redirige las respuestas a los clientes que utilizan REST-API o S3-API, proporciona el almacenamiento en cach√© de los datos m√°s solicitados en la memoria y en el disco. </li><li>  <a href="https://leo-project.net/leofs/docs/architecture/leo_manager/" rel="nofollow">LeoFS Manager</a> : supervisa el funcionamiento de los nodos LeoFS Gateway y LeoFS Storage, supervisa el estado de los nodos y comprueba las sumas de comprobaci√≥n.  Garantiza la integridad de los datos y la alta disponibilidad de almacenamiento. </li></ul><br><p>  En esta publicaci√≥n, instale Leofs usando ansible-playbook, test S3, NFS. </p><a name="habracut"></a><br><p>  Si intenta instalar LeoFS utilizando los libros de jugadas oficiales, le esperan diferentes errores: <a href="https://github.com/leo-project/leofs_ansible/issues/5" rel="nofollow">1</a> , <a href="https://github.com/leo-project/leofs_ansible/issues/4" rel="nofollow">2</a> .  En esta publicaci√≥n escribir√© lo que hay que hacer para evitar estos errores. </p><br><p>  Donde ejecutar√° ansible-playbook, debe instalar netcat. </p><br><h4 id="primer-inventory">  Ejemplo de inventario </h4><br><div class="spoiler">  <b class="spoiler_title">Inventario de ejemplo (en el repositorio hosts.sample):</b> <div class="spoiler_text"><pre><code class="plaintext hljs"># Please check roles/common/vars/leofs_releases for available versions [all:vars] leofs_version=1.4.3 build_temp_path="/tmp/leofs_builder" build_install_path="/tmp/" build_branch="master" source="package" #[builder] #172.26.9.177 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_0] 172.26.9.176 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_1] 172.26.9.178 [leo_storage] 172.26.9.179 leofs_module_nodename=S0@172.26.9.179 172.26.9.181 leofs_module_nodename=S0@172.26.9.181 172.26.9.182 leofs_module_nodename=S0@172.26.9.182 172.26.9.183 leofs_module_nodename=S0@172.26.9.183 [leo_gateway] 172.26.9.180 leofs_module_nodename=G0@172.26.9.180 172.26.9.184 leofs_module_nodename=G0@172.26.9.184 [leofs_nodes:children] leo_manager_0 leo_manager_1 leo_gateway leo_storage</code> </pre> </div></div><br><h4 id="podgotovka-serverov">  Preparaci√≥n del servidor </h4><br><p>  Desactivar Selinux.  Espero que la comunidad cree pol√≠ticas de Selinux para LeoFS. </p><br><pre> <code class="plaintext hljs"> - name: Install libselinux as prerequisite for SELinux Ansible module yum: name: "{{item}}" state: latest with_items: - libselinux-python - libsemanage-python - name: Disable SELinux at next reboot selinux: state: disabled - name: Set SELinux in permissive mode until the machine is rebooted command: setenforce 0 ignore_errors: true changed_when: false</code> </pre><br><p>  Instale <code>netcat</code> y <code>redhat-lsb-core</code> .  <code>netcat</code> necesita <code>leofs-adm</code> para <code>leofs-adm</code> , <code>netcat</code> necesita <code>redhat-lsb-core</code> para determinar la versi√≥n del sistema operativo <a href="" rel="nofollow">aqu√≠</a> . </p><br><pre> <code class="plaintext hljs"> - name: Install Packages yum: name={{ item }} state=present with_items: - nmap-ncat - redhat-lsb-core</code> </pre> <br><p>  Crear un juego de usuarios y agregarlo al grupo de ruedas </p><br><pre> <code class="plaintext hljs"> - name: Create user leofs group: name: leofs state: present - name: Allow 'wheel' group to have passwordless sudo lineinfile: dest: /etc/sudoers state: present regexp: '^%wheel' line: '%wheel ALL=(ALL) NOPASSWD: ALL' validate: 'visudo -cf %s' - name: Add the user 'leofs' to group 'wheel' user: name: leofs groups: wheel append: yes</code> </pre> <br><p>  Instalar Erlang </p><br><pre> <code class="plaintext hljs"> - name: Remote erlang-20.3.8.23-1.el7.x86_64.rpm install with yum yum: name=https://github.com/rabbitmq/erlang-rpm/releases/download/v20.3.8.23/erlang-20.3.8.23-1.el7.x86_64.rpm</code> </pre><br><p>  La versi√≥n completa del libro de jugadas ansible corregido se puede encontrar aqu√≠: <a href="https://github.com/patsevanton/leofs_ansible" rel="nofollow">https://github.com/patsevanton/leofs_ansible</a> </p><br><h4 id="ustanovka-konfigurirovanie-zapusk">  Instalaci√≥n, configuraci√≥n, inicio </h4><br><p>  A continuaci√≥n, ejecute como est√° escrito en <a href="https://github.com/leo-project/leofs_ansible" rel="nofollow">https://github.com/leo-project/leofs_ansible</a> sin build_leofs.yml </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">## Install LeoFS $ ansible-playbook -i hosts install_leofs.yml ## Config LeoFS $ ansible-playbook -i hosts config_leofs.yml ## Start LeoFS $ ansible-playbook -i hosts start_leofs.yml</span></span></code> </pre> <br><h4 id="proveryaem-status-klastera-na-primary-leomanager">  Comprobaci√≥n del estado del cl√∫ster en LeoManager primario </h4><br><pre> <code class="bash hljs">leofs-adm status</code> </pre> <br><p>  Primaria y Secundaria se pueden ver en los registros del libro de jugadas ansible </p><br><p><img src="https://habrastorage.org/webt/do/kp/oj/dokpoj8lmzwh3bmakpxx9anc-4i.png"></p><br><p><img src="https://habrastorage.org/webt/ku/0o/bt/ku0obtn6ezvfghyfai01zldeaws.png"></p><br><div class="spoiler">  <b class="spoiler_title">La conclusi√≥n ser√° algo como esto</b> <div class="spoiler_text"><pre> <code class="bash hljs"> [System Confiuration] -----------------------------------+---------- Item | Value -----------------------------------+---------- Basic/Consistency level -----------------------------------+---------- system version | 1.4.3 cluster Id | leofs_1 DC Id | dc_1 Total replicas | 2 number of successes of R | 1 number of successes of W | 1 number of successes of D | 1 number of rack-awareness replicas | 0 ring size | 2^128 -----------------------------------+---------- Multi DC replication settings -----------------------------------+---------- [mdcr] max number of joinable DCs | 2 [mdcr] total replicas per a DC | 1 [mdcr] number of successes of R | 1 [mdcr] number of successes of W | 1 [mdcr] number of successes of D | 1 -----------------------------------+---------- Manager RING <span class="hljs-built_in"><span class="hljs-built_in">hash</span></span> -----------------------------------+---------- current ring-hash | a0314afb previous ring-hash | a0314afb -----------------------------------+---------- [State of Node(s)] -------+----------------------+--------------+---------+----------------+----------------+---------------------------- <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> | node | state | rack id | current ring | prev ring | updated at -------+----------------------+--------------+---------+----------------+----------------+---------------------------- S | S0@172.26.9.179 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.181 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.182 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.183 | attached | | | | 2019-12-05 10:33:58 +0000 G | G0@172.26.9.180 | running | | a0314afb | a0314afb | 2019-12-05 10:33:49 +0000 G | G0@172.26.9.184 | running | | a0314afb | a0314afb | 2019-12-05 10:33:49 +0000 -------+----------------------+--------------+---------+----------------+----------------+----------------------------</code> </pre> </div></div><br><h4 id="sozdaem-yuzera">  Crear un usuario </h4><br><p>  Crear leofs de usuario: </p><br><pre> <code class="bash hljs">leofs-adm create-user leofs leofs access-key-id: 9c2615f32e81e6a1caf5 secret-access-key: 8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb</code> </pre> <br><p>  Lista de usuarios: </p><br><pre> <code class="bash hljs">leofs-adm get-users user_id | role_id | access_key_id | created_at ------------+---------+------------------------+--------------------------- _test_leofs | 9 | 05236 | 2019-12-02 06:56:49 +0000 leofs | 1 | 9c2615f32e81e6a1caf5 | 2019-12-02 10:43:29 +0000</code> </pre> <br><h4 id="sozdaem-bucket">  Crear un cubo </h4><br><p>  Hecho un balde </p><br><pre> <code class="bash hljs">leofs-adm add-bucket leofs 9c2615f32e81e6a1caf5 OK</code> </pre> <br><p>  Lista de cubo: </p><br><pre> <code class="bash hljs"> leofs-adm get-buckets cluster id | bucket | owner | permissions | created at -------------+----------+--------+------------------+--------------------------- leofs_1 | leofs | leofs | Me(full_control) | 2019-12-02 10:44:02 +0000</code> </pre> <br><h4 id="konfigurirovanie-s3cmd">  Configurando s3cmd </h4><br><p>  En el campo <code>HTTP Proxy server name</code> , especifique la IP del servidor Gateway </p><br><pre> <code class="bash hljs">s3cmd --configure Enter new values or accept defaults <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> brackets with Enter. Refer to user manual <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> detailed description of all options. Access key and Secret key are your identifiers <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Amazon S3. Leave them empty <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> using the env variables. Access Key [9c2615f32e81e6a1caf5]: Secret Key [8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb]: Default Region [US]: Use <span class="hljs-string"><span class="hljs-string">"s3.amazonaws.com"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: Use <span class="hljs-string"><span class="hljs-string">"%(bucket)s.s3.amazonaws.com"</span></span> to the target Amazon S3. <span class="hljs-string"><span class="hljs-string">"%(bucket)s"</span></span> and <span class="hljs-string"><span class="hljs-string">"%(location)s"</span></span> vars can be used <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> accessing a bucket [%(bucket)s.s3.amazonaws.com]: leofs Encryption password is used to protect your files from reading by unauthorized persons <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> transfer to S3 Encryption password: Path to GPG program [/usr/bin/gpg]: When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [No]: On some networks all internet access must go through a HTTP proxy. Try setting it here <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> you can<span class="hljs-string"><span class="hljs-string">'t connect to S3 directly HTTP Proxy server name [172.26.9.180]: HTTP Proxy server port [8080]: New settings: Access Key: 9c2615f32e81e6a1caf5 Secret Key: 8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb Default Region: US S3 Endpoint: s3.amazonaws.com DNS-style bucket+hostname:port template for accessing a bucket: leofs Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: False HTTP Proxy server name: 172.26.9.180 HTTP Proxy server port: 8080 Test access with supplied credentials? [Y/n] Y Please wait, attempting to list all buckets... Success. Your access key and secret key worked fine :-) Now verifying that encryption works... Not configured. Never mind. Save settings? [y/N] y Configuration saved to '</span></span>/home/user/.s3cfg<span class="hljs-string"><span class="hljs-string">'</span></span></code> </pre> <br><p>  Si recibe un error ERROR: error S3: 403 (AccessDenied): acceso denegado: </p><br><pre> <code class="bash hljs">s3cmd put test.py s3://leofs/ upload: <span class="hljs-string"><span class="hljs-string">'test.py'</span></span> -&gt; <span class="hljs-string"><span class="hljs-string">'s3://leofs/test.py'</span></span> [1 of 1] 382 of 382 100% <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0s 3.40 kB/s <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> ERROR: S3 error: 403 (AccessDenied): Access Denied</code> </pre> <br><p>  Luego debe corregir signature_v2 en la configuraci√≥n True s3cmd.  Detalles en este <a href="https://github.com/leo-project/leofs/issues/487" rel="nofollow">n√∫mero</a> . </p><br><p>  Si signature_v2 es False, habr√° un error de este tipo: </p><br><pre> <code class="bash hljs">WARNING: Retrying failed request: /?delimiter=%2F (getaddrinfo() argument 2 must be <span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> or string) WARNING: Waiting 3 sec... WARNING: Retrying failed request: /?delimiter=%2F (getaddrinfo() argument 2 must be <span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> or string) WARNING: Waiting 6 sec... ERROR: Test failed: Request failed <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: /?delimiter=%2F</code> </pre> <br><h4 id="testirovanie-zagruzki">  Prueba de arranque </h4><br><p>  Crea un archivo de 1GB </p><br><pre> <code class="bash hljs">fallocate -l 1GB 1gb</code> </pre> <br><p>  Subelo a Leofs </p><br><pre> <code class="bash hljs">time s3cmd put 1gb s3://leofs/ real 0m19.099s user 0m7.855s sys 0m1.620s</code> </pre> <br><h4 id="statistika">  Estad√≠sticas </h4><br><p>  leofs-adm du para 1 nodo: </p><br><pre> <code class="bash hljs">leofs-adm du S0@172.26.9.179 active number of objects: 156 total number of objects: 156 active size of objects: 602954495 total size of objects: 602954495 ratio of active size: 100.0% last compaction start: ____-__-__ __:__:__ last compaction end: ____-__-__ __:__:__</code> </pre> <br><p>  Vemos que la conclusi√≥n no es muy informativa. </p><br><p>  Veamos d√≥nde se encuentra este archivo. <br>  leofs-adm whereis leofs / 1gb </p><br><pre> <code class="bash hljs">leofs-adm whereis leofs/1gb -------+----------------------+--------------------------------------+------------+--------------+----------------+----------------+----------------+---------------------------- del? | node | ring address | size | checksum | has children | total chunks | clock | when -------+----------------------+--------------------------------------+------------+--------------+----------------+----------------+----------------+---------------------------- | S0@172.26.9.181 | 657a9f3a3db822a7f1f5050925b26270 | 976563K | a4634eea55 | <span class="hljs-literal"><span class="hljs-literal">true</span></span> | 64 | 598f2aa976a4f | 2019-12-05 10:48:15 +0000 | S0@172.26.9.182 | 657a9f3a3db822a7f1f5050925b26270 | 976563K | a4634eea55 | <span class="hljs-literal"><span class="hljs-literal">true</span></span> | 64 | 598f2aa976a4f | 2019-12-05 10:48:15 +0000</code> </pre> <br><h4 id="aktiviruem-nfs">  Activar NFS </h4><br><p>  Activamos NFS en el servidor Leo Gateway 172.26.9.184. </p><br><p>  En el servidor y el cliente, instale nfs-utils </p><br><pre> <code class="bash hljs">sudo yum install nfs-utils</code> </pre> <br><p>  De acuerdo con las instrucciones, arreglaremos el archivo de configuraci√≥n <code>/usr/local/leofs/current/leo_gateway/etc/leo_gateway.conf</code> </p><br><pre> <code class="bash hljs">protocol = nfs</code> </pre> <br><p>  En el servidor 172.26.9.184, ejecute rpcbind y leofs-gateway </p><br><pre> <code class="bash hljs">sudo service rpcbind start sudo service leofs-gateway restart</code> </pre> <br><p>  En el servidor donde se ejecuta leo_manager, cree un dep√≥sito para NFS y genere una clave para conectarse a NFS </p><br><pre> <code class="bash hljs">leofs-adm add-bucket <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> 05236 leofs-adm gen-nfs-mnt-key <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> 05236 ip--nfs-</code> </pre> <br><h4 id="podklyuchenie-k-nfs">  Conectarse a NFS </h4><br><pre> <code class="bash hljs">sudo mkdir /mnt/leofs <span class="hljs-comment"><span class="hljs-comment">## for Linux - "sudo mount -t nfs -o nolock &lt;host&gt;:/&lt;bucket&gt;/&lt;token&gt; &lt;dir&gt;" sudo mount -t nfs -o nolock ip--nfs-------gateway:/bucket/access_key_id/---gen-nfs-mnt-key /mnt/leofs sudo mount -t nfs -o nolock 172.26.9.184:/test/05236/bb5034f0c740148a346ed663ca0cf5157efb439f /mnt/leofs</span></span></code> </pre> <br><h4 id="prosmotr-diskovogo-prostanstva-cherez-nfs-klient">  Ver espacio en disco a trav√©s de un cliente NFS </h4><br><p>  Espacio en disco teniendo en cuenta que cada nodo de almacenamiento tiene un disco de 40 GB (3 nodos en ejecuci√≥n, 1 nodo conectado): </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 60G 3.6G 57G 6% /mnt/leofs</code> </pre> <br><h4 id="ustanovka-leofs-s-6-storage-nodami">  Instale LeoFS con 6 nodos de almacenamiento. </h4><br><div class="spoiler">  <b class="spoiler_title">Inventario (sin constructor):</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Please check roles/common/vars/leofs_releases for available versions [all:vars] leofs_version=1.4.3 build_temp_path="/tmp/leofs_builder" build_install_path="/tmp/" build_branch="master" source="package" # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_0] 172.26.9.177 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_1] 172.26.9.176 [leo_storage] 172.26.9.178 leofs_module_nodename=S0@172.26.9.178 172.26.9.179 leofs_module_nodename=S0@172.26.9.179 172.26.9.181 leofs_module_nodename=S0@172.26.9.181 172.26.9.182 leofs_module_nodename=S0@172.26.9.182 172.26.9.183 leofs_module_nodename=S0@172.26.9.183 172.26.9.185 leofs_module_nodename=S0@172.26.9.185 [leo_gateway] 172.26.9.180 leofs_module_nodename=G0@172.26.9.180 172.26.9.184 leofs_module_nodename=G0@172.26.9.184 [leofs_nodes:children] leo_manager_0 leo_manager_1 leo_gateway leo_storage</span></span></code> </pre> </div></div><br><h4 id="vyvod-leofs-adm-status">  Salida de estado de Leofs-adm </h4><br><div class="spoiler">  <b class="spoiler_title">Salida de estado de Leofs-adm</b> <div class="spoiler_text"><pre> <code class="bash hljs"> [System Confiuration] -----------------------------------+---------- Item | Value -----------------------------------+---------- Basic/Consistency level -----------------------------------+---------- system version | 1.4.3 cluster Id | leofs_1 DC Id | dc_1 Total replicas | 2 number of successes of R | 1 number of successes of W | 1 number of successes of D | 1 number of rack-awareness replicas | 0 ring size | 2^128 -----------------------------------+---------- Multi DC replication settings -----------------------------------+---------- [mdcr] max number of joinable DCs | 2 [mdcr] total replicas per a DC | 1 [mdcr] number of successes of R | 1 [mdcr] number of successes of W | 1 [mdcr] number of successes of D | 1 -----------------------------------+---------- Manager RING <span class="hljs-built_in"><span class="hljs-built_in">hash</span></span> -----------------------------------+---------- current ring-hash | d8ff465e previous ring-hash | d8ff465e -----------------------------------+---------- [State of Node(s)] -------+----------------------+--------------+---------+----------------+----------------+---------------------------- <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> | node | state | rack id | current ring | prev ring | updated at -------+----------------------+--------------+---------+----------------+----------------+---------------------------- S | S0@172.26.9.178 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.179 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.181 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:30 +0000 S | S0@172.26.9.182 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.183 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.185 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 G | G0@172.26.9.180 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:31 +0000 G | G0@172.26.9.184 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:31 +0000 -------+----------------------+--------------+---------+----------------+----------------+----------------------------</code> </pre> </div></div><br><p>  Espacio en disco, teniendo en cuenta que cada nodo de almacenamiento tiene un disco de 40 GB (6 nodos en ejecuci√≥n): </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 120G 3.6G 117G 3% /mnt/leofs</code> </pre> <br><h4 id="esli-ispolzuetsya-5-nod-storage">  Si se usan 5 nodos de almacenamiento </h4><br><pre> <code class="bash hljs">[leo_storage] 172.26.9.178 leofs_module_nodename=S0@172.26.9.178 172.26.9.179 leofs_module_nodename=S1@172.26.9.179 172.26.9.181 leofs_module_nodename=S2@172.26.9.181 172.26.9.182 leofs_module_nodename=S3@172.26.9.182 172.26.9.183 leofs_module_nodename=S4@172.26.9.183</code> </pre> <br><pre> <code class="bash hljs">df -hP 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 100G 3.0G 97G 3% /mnt/leofs</code> </pre> <br><h4 id="logi">  Registros </h4><br><p>  Los registros se encuentran en los directorios <code>/usr/local/leofs/current/*/log</code> </p><br><h4 id="esli-vy-budete-ustanavlivatnastraivat-leofs-vruchnuyu-to-vozmozhno-stolknetes-so-sleduyuschimi-oshibkami">  Si instala / configura Leofs manualmente, puede encontrar los siguientes errores. </h4><br><h5 id="error-mnesia-is-not-available">  [ERROR] Mnesia no est√° disponible </h5><br><p>  Iniciar el servicio systemctl iniciar leofs-manager-master </p><br><pre> <code class="bash hljs">leofs-adm status [ERROR] Mnesia is not available</code> </pre> <br><p>  Necesito iniciar systemctl start leofs-manager-slave en leo_manager_1 </p><br><h5 id="ne-startuet-leofs-storage">  Leofs-storage no se inicia. </h5><br><p>  Es necesario que leofs-manager-master y leofs-manager-slave y leofs-adm se ejecuten para mostrar el estado. </p><br><h5 id="attached-nodes-less-than--of-replicas">  Nodos adjuntos menos de # de r√©plicas </h5><br><p>  Cuando inicia leofs-adm start, obtiene este error: </p><br><pre> <code class="bash hljs">leofs-adm start [ERROR] Attached nodes less than <span class="hljs-comment"><span class="hljs-comment"># of replicas</span></span></code> </pre> <br><p>  No hay suficientes nodos de almacenamiento.  El estado de leofs-adm le mostrar√° menos de 2 nodos de almacenamiento.  N√∫mero m√≠nimo requerido de nodos de almacenamiento 2. </p><br><h5 id="leofs-adm-status-pokazyvaet-attached-ostalnye-running">  el estado de leofs-adm se muestra adjunto, el resto se est√° ejecutando. </h5><br><p>  Necesidad de reequilibrar los nodos </p><br><pre> <code class="bash hljs">leofs-adm rebalance</code> </pre> <br><h5 id="posle-starta-leofs-gateway-vy-ne-vidite-nodu-gateway-v-leofs-adm-status">  Despu√©s de iniciar leofs-gateway, no ver√° el nodo Gateway en estado leofs-adm </h5><br><p>  Necesito comenzar leofs-adm </p><br><pre> <code class="bash hljs">leofs-adm start</code> </pre> <br><h5 id="couldnt-connect-to-leofs-manager-na-slave-uzle">  no se pudo conectar con LeoFS Manager en el nodo Esclavo </h5><br><p>  (¬°De forma predeterminada, leofs-adm no funciona en el nodo esclavo!] ( <a href="https://leo-project.net/leofs/docs/issues/documentation-issues/" rel="nofollow">Https://leo-project.net/leofs/docs/issues/documentation-issues/</a> ) </p><br><h3 id="nagruzochnoe-testirovanie">  Prueba de carga </h3><br><p>  Las pruebas se realizan en 2 nodos con la configuraci√≥n: </p><br><pre> <code class="bash hljs">CPU: Single Core Intel Core (Broadwell) (-MCP-) speed: 2295 MHz Kernel: 3.10.0-862.3.2.el7.x86_64 x86_64 Up: 1h 08m Mem: 1023.8/1999.6 MiB (51.2%) Storage: 10.00 GiB (43.5% used) Procs: 98 Shell: bash 4.2.46 inxi: 3.0.37</code> </pre> <br><p>  Para probar, tome un disco peque√±o <br>  En ambos nodos vemos un disco de espacio libre de 9.4G y 5.9G. </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on /dev/vda1 9.4G 5.9G 3.1G 66% /</code> </pre> <br><p>  Canal de Telegram: <a href="https://t.me/sds_ru" rel="nofollow">SDS y Cluster FS</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/478990/">https://habr.com/ru/post/478990/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../478972/index.html">Ganadores del concurso de plataformas Miro</a></li>
<li><a href="../478974/index.html">M√≥dulo de carga autom√°tica mediante importaci√≥n din√°mica</a></li>
<li><a href="../478984/index.html">TimTam: un masajeador de percusi√≥n de nueva generaci√≥n con una funci√≥n de calentamiento de punta √∫nica</a></li>
<li><a href="../478986/index.html">Yandex lanz√≥ una votaci√≥n popular para los juegos retro. Finalistas de Retro Games Battle 2019</a></li>
<li><a href="../478988/index.html">Venecia: ganancias salvajes en un par de rocas desnudas</a></li>
<li><a href="../478992/index.html">Falta de miedo y alegr√≠a de vivir en TI</a></li>
<li><a href="../478994/index.html">German Post planea trabajar m√°s despacio y descansar el lunes</a></li>
<li><a href="../478996/index.html">El trabajo no es un lobo, parte 4. Empleado experimentado: c√≥mo no agotarse y no darse por vencido</a></li>
<li><a href="../478998/index.html">¬øPor qu√© siempre queremos ver la proporci√≥n √°urea? Intento (sin √©xito) de an√°lisis evolutivo utilizando redes neuronales C ++</a></li>
<li><a href="../479000/index.html">Pasant√≠a de Parallels cuando tienes 14 a√±os</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
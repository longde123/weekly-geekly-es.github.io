<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úçüèø üå≤ ü§úüèΩ Las redes neuronales sin un maestro se traducen de idiomas para los cuales no hay corpus de textos paralelos. üõÇ üåë üçô</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La traducci√≥n autom√°tica con la ayuda de redes neuronales ha recorrido un largo camino desde el momento de la primera investigaci√≥n cient√≠fica sobre e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Las redes neuronales sin un maestro se traducen de idiomas para los cuales no hay corpus de textos paralelos.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408541/"><img src="https://habrastorage.org/webt/0-/tl/ze/0-tlzebusmsbrgkbzz61wrymo9s.png"><br><br>  La traducci√≥n autom√°tica con la ayuda de redes neuronales ha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">recorrido un largo camino</a> desde el momento de la primera investigaci√≥n cient√≠fica sobre este tema hasta el momento en que Google anunci√≥ la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">transferencia completa del servicio Google Translate al aprendizaje profundo</a> . <br><br>  Como saben, la base del traductor neuronal es el mecanismo de Redes Neuronales Recurrentes Bidireccionales, construido sobre c√°lculos matriciales, que le permite construir modelos probabil√≠sticos significativamente m√°s complejos que los traductores autom√°ticos estad√≠sticos.  Sin embargo, siempre se crey√≥ que la traducci√≥n neural, como la traducci√≥n estad√≠stica, requiere textos biling√ºes paralelos para el entrenamiento.  Se est√° formando una red neuronal en estos edificios, tomando como referencia una traducci√≥n humana. <br><br>  Al final result√≥ que ahora, las redes neuronales son capaces de dominar un nuevo idioma para la traducci√≥n, incluso sin corpus de textos paralelos!  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Se</a> publicaron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dos</a> trabajos sobre este tema en el sitio de preimpresi√≥n arXiv.org. <br><a name="habracut"></a><br>  ‚ÄúImagine que le est√° dando a una persona muchos libros chinos y muchos libros √°rabes, no hay libros id√©nticos entre ellos, y esta persona est√° aprendiendo a traducir del chino al √°rabe.  Parece imposible, ¬øverdad?  Pero demostramos que una computadora es capaz de esto ‚Äù, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dice</a> Mikel Artetxe, un inform√°tico de la Universidad del Pa√≠s Vasco en San Sebasti√°n (Espa√±a). <br><br>  La mayor√≠a de las redes neuronales de traducci√≥n autom√°tica se ense√±an "con un maestro", cuyo papel es precisamente el corpus paralelo de textos traducidos por el hombre.  En el proceso de aprendizaje, en t√©rminos generales, la red neuronal asume, comprueba el est√°ndar y realiza las configuraciones necesarias en sus sistemas, luego aprende m√°s.  El problema es que para algunos idiomas en el mundo no hay una gran cantidad de textos paralelos, por lo tanto, no est√°n disponibles para las redes neuronales tradicionales de traducci√≥n autom√°tica. <br><br>  Dos nuevos modelos ofrecen un nuevo enfoque: ense√±ar una red neuronal de traducci√≥n autom√°tica <b>sin un maestro</b> .  El sistema en s√≠ est√° tratando de formar una especie de corpus de textos paralelos, agrupando palabras entre s√≠.  El hecho es que en la mayor√≠a de los idiomas del mundo existen los mismos significados, que simplemente corresponden a diferentes palabras.  Por lo tanto, todos estos significados se agrupan en grupos id√©nticos, es decir, los mismos significados de palabras se agrupan alrededor de los mismos significados de palabras, casi independientemente del idioma (consulte el art√≠culo " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Google Neural Network compil√≥ una base unificada de los significados de las palabras humanas</a> ") . <br><br><img src="https://habrastorage.org/files/d13/72d/6f7/d1372d6f7b8c41e2a4988e7f5fcad3ea.png"><br>  <i><font color="gray">El "lenguaje universal" de la red neuronal de Google Neural Machine Translation (GNMT).</font></i>  <i><font color="gray">Los grupos de significados de cada palabra se muestran en diferentes colores en la ilustraci√≥n de la izquierda, los significados m√°s bajos son los significados de las palabras obtenidas de diferentes idiomas humanos: ingl√©s, coreano y japon√©s</font></i> <br><br>  Despu√©s de haber compilado un gigantesco "atlas" para cada idioma, el sistema intenta superponer uno de esos atlas en otro, y aqu√≠ est√°, ¬°est√° listo para tener alg√∫n tipo de corpus de texto paralelo! <br><br>  Puede comparar los patrones de las dos arquitecturas de aprendizaje sin maestros propuestas. <br><br><img src="https://habrastorage.org/webt/uu/jw/u7/uujwu7yophvszhccgutsvr7tdxq.png"><br>  <i><font color="gray">La arquitectura del sistema propuesto.</font></i>  <i><font color="gray">Para cada oraci√≥n en el lenguaje L1, el sistema aprende la alternancia de dos pasos: 1) <b>eliminaci√≥n de ruido</b> , que optimiza la probabilidad de codificar una versi√≥n ruidosa de la oraci√≥n con un codificador com√∫n y su reconstrucci√≥n por el decodificador L1;</font></i>  <i><font color="gray">2) traducci√≥n inversa, cuando una oraci√≥n se traduce en modo de salida (es decir, codificada por un codificador com√∫n y decodificada por el decodificador L2), y luego se optimiza la probabilidad de codificar esta oraci√≥n traducida con un codificador com√∫n y la restauraci√≥n de la oraci√≥n original por el decodificador L1.</font></i>  <i><font color="gray">Ilustraci√≥n: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo cient√≠fico de</a> Mikel Artetks et al.</font></i> <br><br><img src="https://habrastorage.org/webt/7l/en/y3/7leny37dml5fdxwr9exn3kyu-_s.png"><br>  <i><font color="gray">La arquitectura propuesta y los objetivos de aprendizaje del sistema (del segundo trabajo cient√≠fico).</font></i>  <i><font color="gray">La arquitectura es un modelo de traducci√≥n de oraciones, donde el codificador y el decodificador funcionan en dos idiomas, dependiendo del identificador del idioma de entrada, que intercambia las tablas de b√∫squeda.</font></i>  <i><font color="gray">Arriba (codificaci√≥n autom√°tica): el modelo est√° aprendiendo c√≥mo realizar la reducci√≥n de ruido en cada dominio.</font></i>  <i><font color="gray">A continuaci√≥n (traducci√≥n): como antes, adem√°s de codificar desde otro idioma, utilizando como entrada la traducci√≥n producida por el modelo en la iteraci√≥n anterior (rect√°ngulo azul).</font></i>  <i><font color="gray">Las elipses verdes indican t√©rminos en la funci√≥n de p√©rdida.</font></i>  <i><font color="gray">Ilustraci√≥n: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">art√≠culo cient√≠fico de</a> Guillaume Lampl et al.</font></i> <br><br>  Ambos art√≠culos cient√≠ficos utilizan una t√©cnica notablemente similar con ligeras diferencias.  Pero en ambos casos, la traducci√≥n se lleva a cabo a trav√©s de un "lenguaje" intermedio o, mejor, una dimensi√≥n o espacio intermedio.  Hasta ahora, las redes neuronales sin un maestro muestran una calidad de traducci√≥n no muy alta, pero los autores dicen que es f√°cil mejorar si se usa un poco de ayuda de un maestro, solo por el bien de la pureza del experimento que no hicieron. <br><br>  Tenga en cuenta que el segundo trabajo cient√≠fico fue publicado por investigadores de la divisi√≥n de inteligencia artificial de Facebook. <br><br>  Los trabajos se presentan para la Conferencia Internacional sobre Representaciones de Aprendizaje 2018.  Ninguno de los art√≠culos ha sido publicado a√∫n en la prensa cient√≠fica. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es408541/">https://habr.com/ru/post/es408541/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es408531/index.html">Durante mucho tiempo ha sido preocupante: ¬øpor qu√© la nariz fluye del fr√≠o?</a></li>
<li><a href="../es408533/index.html">¬øQui√©n, si no SpaceX? Gu√≠a completa de empresas espaciales privadas</a></li>
<li><a href="../es408535/index.html">Cien criptomonedas descritas en no m√°s de cuatro palabras</a></li>
<li><a href="../es408537/index.html">Extraterrestres, post-apocalipsis, Jes√∫s y contrabandistas espaciales: los libros de ciencia ficci√≥n m√°s interesantes de 2017</a></li>
<li><a href="../es408539/index.html">El primer presidente astronauta del mundo.</a></li>
<li><a href="../es408543/index.html">Intentaron medir el nivel de felicidad con un reloj inteligente.</a></li>
<li><a href="../es408545/index.html">No soy un monstruo</a></li>
<li><a href="../es408547/index.html">10 consolas que nunca vieron el mundo</a></li>
<li><a href="../es408549/index.html">IoT en la ciudad: hoy y ma√±ana</a></li>
<li><a href="../es408551/index.html">Revisi√≥n del nuevo presupuesto 3D Tiger3D K-One pen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
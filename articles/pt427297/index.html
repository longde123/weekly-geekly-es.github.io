<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîü üóÉÔ∏è üï¥üèΩ Apache Ignite + Apache Spark Data Frames: juntos, mais divertidos üê• üß¶ üßîüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° Habr! Meu nome √© Nikolai Izhikov, trabalho para a Sberbank Technologies na equipe de desenvolvimento de solu√ß√µes de c√≥digo aberto. Atr√°s de 15 ano...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apache Ignite + Apache Spark Data Frames: juntos, mais divertidos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/427297/">  Ol√° Habr!  Meu nome √© Nikolai Izhikov, trabalho para a Sberbank Technologies na equipe de desenvolvimento de solu√ß√µes de c√≥digo aberto.  Atr√°s de 15 anos de desenvolvimento comercial em Java.  Sou um colaborador do Apache Ignite e colaborador do Apache Kafka. <br><br>  Abaixo do gato, voc√™ encontrar√° uma vers√£o em v√≠deo e texto do meu relat√≥rio no Apache Ignite Meetup sobre como usar o Apache Ignite com o Apache Spark e quais recursos foram implementados para isso. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f42/5f3/df5/f425f3df59ff99d03d4a3e6aff3b2655.png"><br><a name="habracut"></a><br><h2>  O que o Apache Spark pode fazer </h2><br>  O que √© o Apache Spark?  Este √© um produto que permite executar rapidamente consultas distribu√≠das de computa√ß√£o e anal√≠ticas.  Basicamente, o Apache Spark √© escrito em Scala. <br><br>  O Apache Spark possui uma API rica para conectar-se a v√°rios sistemas de armazenamento ou receber dados.  Um dos recursos do produto √© um mecanismo de consulta universal semelhante ao SQL para dados recebidos de v√°rias fontes.  Se voc√™ possui v√°rias fontes de informa√ß√£o, deseja combin√°-las e obter alguns resultados, o Apache Spark √© o que voc√™ precisa. <br><br>  Uma das principais abstra√ß√µes que o Spark fornece √© Data Frame, DataSet.  Em termos de banco de dados relacional, essa √© uma tabela, uma fonte que fornece dados de maneira estruturada.  A estrutura, o tipo de cada coluna, seu nome etc. s√£o conhecidos.  Os quadros de dados podem ser criados a partir de v√°rias fontes.  Exemplos incluem arquivos json, bancos de dados relacionais, v√°rios sistemas hadoop e Apache Ignite. <br><br>  O Spark suporta jun√ß√µes em consultas SQL.  Voc√™ pode combinar dados de v√°rias fontes e obter resultados, executar consultas anal√≠ticas.  Al√©m disso, h√° uma API para salvar dados.  Quando voc√™ conclui as consultas, realiza um estudo, o Spark fornece a capacidade de salvar os resultados no destinat√°rio que suporta esse recurso e, consequentemente, resolver o problema do processamento de dados. <br><br><h2>  Quais recursos implementamos para integrar o Apache Spark com o Apache Ignite </h2><br><ol><li>  Lendo dados das tabelas SQL do Apache Ignite. </li><li>  Gravando dados nas tabelas SQL do Apache Ignite. </li><li>  IgniteCatalog dentro do IgniteSparkSession - a capacidade de usar todas as tabelas SQL existentes do Ignite sem registrar "manualmente". </li><li>  Otimiza√ß√£o de SQL - a capacidade de executar instru√ß√µes SQL dentro do Ignite. </li></ol><br>  O Apache Spark pode ler dados das tabelas SQL do Apache Ignite e grav√°-los na forma de uma tabela.  Qualquer DataFrame formado no Spark pode ser salvo como uma tabela SQL do Apache Ignite. <br><br>  O Apache Ignite permite que voc√™ use todas as tabelas existentes do Ignite SQL na sess√£o Spark sem registrar "manualmente" - usando o IgniteCatalog na extens√£o padr√£o do SparkSession - IgniteSparkSession. <br><br>  Aqui voc√™ precisa se aprofundar um pouco mais no dispositivo Spark.  Em termos de banco de dados regular, um diret√≥rio √© um local onde as metainforma√ß√µes s√£o armazenadas: quais tabelas est√£o dispon√≠veis, quais colunas est√£o nelas etc.  Quando uma solicita√ß√£o chega, as meta-informa√ß√µes s√£o extra√≠das do cat√°logo e o mecanismo SQL faz algo com tabelas e dados.  Por padr√£o, no Spark, todas as tabelas de leitura (n√£o importa, de um banco de dados relacional, Ignite, Hadoop) devem ser registradas manualmente na sess√£o.  Como resultado, voc√™ tem a oportunidade de fazer uma consulta SQL nessas tabelas.  Spark descobre sobre eles. <br><br>  Para trabalhar com os dados que enviamos para o Ignite, precisamos registrar as tabelas.  Por√©m, em vez de registrar cada tabela com nossas m√£os, implementamos a capacidade de acessar automaticamente todas as tabelas do Ignite. <br><br>  Qual √© o recurso aqui?  Por algum motivo, n√£o sei, o diret√≥rio no Spark √© uma API interna, ou seja,  um estranho n√£o pode vir e criar sua pr√≥pria implementa√ß√£o de cat√°logo.  E, desde que o Spark saiu do Hadoop, ele suporta apenas o Hive.  E voc√™ deve registrar tudo o mais com as m√£os.  Os usu√°rios frequentemente perguntam como voc√™ pode contornar isso e fazer consultas SQL imediatamente.  Eu implementei um diret√≥rio que permite navegar e acessar as tabelas Ignite sem registrar ~ e sms ~, e propus inicialmente esse patch na comunidade Spark, √† qual recebi uma resposta: esse patch n√£o √© interessante por alguns motivos internos.  E eles n√£o forneceram a API interna. <br><br>  Agora, o cat√°logo Ignite √© um recurso interessante implementado usando a API interna do Spark.  Para usar esse diret√≥rio, temos nossa pr√≥pria implementa√ß√£o da sess√£o.Este √© o SparkSession usual, dentro do qual voc√™ pode fazer solicita√ß√µes, processar dados.  As diferen√ßas s√£o que integramos o ExternalCatalog a ele para trabalhar com tabelas Ignite, bem como IgniteOptimization, que ser√£o descritas abaixo. <br><br>  <b>Otimiza√ß√£o de SQL</b> - a capacidade de executar instru√ß√µes SQL dentro do Ignite.  Por padr√£o, ao executar jun√ß√£o, agrupamento, c√°lculo agregado e outras consultas SQL complexas, o Spark l√™ dados no modo linha por linha.  A √∫nica coisa que a fonte de dados pode fazer √© filtrar as linhas com efici√™ncia. <br><br>  Se voc√™ usar jun√ß√£o ou agrupamento, o Spark atrai todos os dados da tabela para sua mem√≥ria para o trabalhador, usando os filtros especificados, e somente os agrupa ou executa outras opera√ß√µes SQL.  No caso do Ignite, isso n√£o √© o ideal, porque o pr√≥prio Ignite possui uma arquitetura distribu√≠da e possui conhecimento dos dados armazenados nela.  Portanto, o pr√≥prio Ignite pode calcular com efici√™ncia agregados e executar agrupamentos.  Al√©m disso, pode haver muitos dados e, para agrup√°-los, voc√™ precisar√° subtrair tudo, aumentar todos os dados no Spark, o que √© bastante caro. <br><br>  O Spark fornece uma API com a qual voc√™ pode alterar o plano inicial da consulta SQL, executar a otimiza√ß√£o e encaminhar a parte da consulta SQL que pode ser executada no Ignite.  Isso ser√° eficaz em termos de velocidade e consumo de mem√≥ria, porque n√£o os usaremos para extrair dados que ser√£o imediatamente agrupados. <br><br><h2>  Como isso funciona </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/b28/1df/0ef/b281df0ef5f2ea2a08f73267ef7f5edb.png"><br><br>  Temos um cluster Ignite - esta √© a metade inferior da imagem.  N√£o h√° Zookeeper, pois existem apenas cinco n√≥s.  Existem trabalhadores spark, em cada trabalhador o n√≥ do cliente Ignite √© gerado.  Atrav√©s dele, podemos fazer uma solicita√ß√£o e ler os dados, interagir com o cluster.  Al√©m disso, o n√≥ do cliente aumenta dentro do IgniteSparkSession para o diret√≥rio funcionar. <br><br><h2>  Ignorar quadro de dados </h2><br>  Passamos ao c√≥digo: como ler dados de uma tabela SQL?  No caso do Spark, tudo √© bem simples e bom: dizemos que queremos calcular alguns dados, indicar o formato - essa √© uma constante constante.  Al√©m disso, temos v√°rias op√ß√µes - o caminho para o arquivo de configura√ß√£o do n√≥ do cliente, que inicia ao ler dados.  N√≥s indicamos qual tabela queremos ler e dizemos ao Spark para carregar.  Obtemos os dados e podemos fazer o que queremos com eles. <br><br><pre><code class="scala hljs">spark.read .format(<span class="hljs-type"><span class="hljs-type">FORMAT_IGNITE</span></span>) .option(<span class="hljs-type"><span class="hljs-type">OPTION_CONFIG_FILE</span></span>, <span class="hljs-type"><span class="hljs-type">TEST_CONFIG_FILE</span></span>) .option(<span class="hljs-type"><span class="hljs-type">OPTION_TABLE</span></span>, <span class="hljs-string"><span class="hljs-string">"person"</span></span>) .load()</code> </pre> <br>  Depois de gerar os dados - opcionalmente a partir do Ignite, de qualquer fonte -, podemos salvar tudo com a mesma facilidade, especificando o formato e a tabela correspondente.  N√≥s comandamos o Spark para escrever, especificamos um formato.  Na configura√ß√£o, prescrevemos a qual cluster se conectar.  Especifique a tabela na qual queremos salvar.  Al√©m disso, podemos prescrever op√ß√µes de utilidade - especifique a chave prim√°ria que criamos nesta tabela.  Se os dados simplesmente perturbarem sem criar uma tabela, esse par√¢metro n√£o ser√° necess√°rio.  No final, clique em Salvar e os dados s√£o gravados. <br><br><pre> <code class="scala hljs">tbl.write. format(<span class="hljs-type"><span class="hljs-type">FORMAT_IGNITE</span></span>). option(<span class="hljs-type"><span class="hljs-type">OPTION_CONFIG_FILE</span></span>, <span class="hljs-type"><span class="hljs-type">CFG_PATH</span></span>). option(<span class="hljs-type"><span class="hljs-type">OPTION_TABLE</span></span>, tableName). option(<span class="hljs-type"><span class="hljs-type">OPTION_CREATE_TABLE_PRIMARY_KEY_FIELDS</span></span>, pk). save</code> </pre><br>  Agora vamos ver como tudo funciona. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b35/41a/b86/b3541ab86eca15cd240765bf15907979.png"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LoadDataExample.scala</a> <br><br>  Esta aplica√ß√£o √≥bvia demonstrar√° primeiro os recursos de grava√ß√£o.  Por exemplo, escolhi os dados das partidas de futebol, baixei as estat√≠sticas de um recurso conhecido.  Ele cont√©m informa√ß√µes sobre torneios: ligas, partidas, jogadores, equipes, atributos de jogadores, atributos de equipes - dados que descrevem partidas de futebol em ligas de pa√≠ses europeus (Inglaterra, Fran√ßa, Espanha, etc.). <br><br>  Quero envi√°-los para o Ignite.  Criamos uma sess√£o do Spark, especificamos o endere√ßo do assistente e chamamos o carregamento dessas tabelas, passando par√¢metros.  O exemplo est√° no Scala, n√£o no Java, porque o Scala √© menos detalhado e, portanto, melhor por exemplo. <br><br>  N√≥s transferimos o nome do arquivo, lemos, indicamos que √© multilinha, este √© um arquivo json padr√£o.  Ent√£o n√≥s escrevemos em Ignite.  A estrutura do nosso arquivo n√£o pode ser descrita em nenhum lugar - o pr√≥prio Spark determina quais dados temos e qual √© a estrutura deles.  Se tudo correr bem, √© criada uma tabela na qual existem todos os campos necess√°rios dos tipos de dados necess√°rios.  √â assim que podemos carregar tudo dentro do Ignite. <br><br>  Quando os dados s√£o carregados, podemos v√™-los no Ignite e us√°-los imediatamente.  Como um exemplo simples, uma consulta que permite saber qual time jogou mais partidas.  Temos duas colunas: hometeam e awayteam, anfitri√µes e convidados.  Selecionamos, agrupamos, contamos, somamos e juntamos os dados do comando - para inserir o nome do comando.  Ta-dam - e os dados de json-chiks que entramos no Ignite.  Vemos Paris Saint-Germain, Toulouse - temos muitos dados sobre as equipes francesas. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8a4/202/52b/8a420252be6fb8df3a9083d7411911a9.png"><br><br>  Resumimos.  Agora, carregamos dados da fonte, arquivo json, para Ignite, e rapidamente.  Talvez, do ponto de vista do big data, isso n√£o seja muito grande, mas decente para um computador local.  O esquema da tabela √© obtido do arquivo json em sua forma original.  A tabela foi criada, os nomes das colunas foram copiados do arquivo de origem e a chave prim√°ria foi criada.  O ID est√° em toda parte e a chave prim√°ria √© o ID.  Esses dados entraram no Ignite, podemos us√°-los. <br><br><h2>  IgniteSparkSession e IgniteCatalog </h2><br>  Vamos ver como isso funciona. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/654/24a/4ee/65424a4eeda4a4c2c6cce7038e13d1a9.png"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CatalogExample.scala</a> <br><br>  De uma maneira bastante simples, voc√™ pode acessar e consultar todos os seus dados.  No √∫ltimo exemplo, iniciamos a sess√£o padr√£o do spark.  E n√£o havia especificidade no Ignite - exceto que voc√™ precisa colocar um jar com a fonte de dados correta - trabalho completamente padr√£o por meio da API p√∫blica.  Mas, se voc√™ deseja acessar as tabelas Ignite automaticamente, pode usar nossa extens√£o.  A diferen√ßa √© que, em vez do SparkSession, escrevemos IgniteSparkSession. <br><br>  Assim que voc√™ cria um objeto IgniteSparkSession, voc√™ v√™ no diret√≥rio todas as tabelas que foram carregadas no Ignite.  Voc√™ pode ver o diagrama e todas as informa√ß√µes.  O Spark j√° conhece as tabelas que o Ignite possui e voc√™ pode obter facilmente todos os dados. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dec/f1b/a0c/decf1ba0c5db2e0d84e50a0e88b6c192.png"><br><br><h2>  Otimiza√ß√£o de igni√ß√£o </h2><br>  Quando voc√™ faz consultas complexas no Ignite usando JOIN, o Spark puxa os dados primeiro e somente depois JOIN os agrupa.  Para otimizar o processo, criamos o recurso IgniteOptimization - ele otimiza o plano de consulta do Spark e permite encaminhar as partes da solicita√ß√£o que podem ser executadas no Ignite dentro do Ignite.  Mostramos otimiza√ß√£o em uma solicita√ß√£o espec√≠fica. <br><br><pre> <code class="sql hljs">SQL Query: <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span>   city_id,   <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span>   person p <span class="hljs-keyword"><span class="hljs-keyword">GROUP</span></span> <span class="hljs-keyword"><span class="hljs-keyword">BY</span></span> city_id <span class="hljs-keyword"><span class="hljs-keyword">HAVING</span></span> <span class="hljs-keyword"><span class="hljs-keyword">count</span></span>(*) &gt; <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br>  Atendemos o pedido.  Temos uma mesa pessoal - alguns funcion√°rios, pessoas.  Cada funcion√°rio conhece o ID da cidade em que vive.  Queremos saber quantas pessoas vivem em cada cidade.  N√≥s filtramos - em qual cidade mais de uma pessoa vive.  Aqui est√° o plano inicial que o Spark cria: <br><br><pre> <code class="scala hljs">== <span class="hljs-type"><span class="hljs-type">Analyzed</span></span> <span class="hljs-type"><span class="hljs-type">Logical</span></span> <span class="hljs-type"><span class="hljs-type">Plan</span></span> == city_id: bigint, count(<span class="hljs-number"><span class="hljs-number">1</span></span>): bigint <span class="hljs-type"><span class="hljs-type">Project</span></span> [city_id#<span class="hljs-number"><span class="hljs-number">19</span></span>L, count(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">52</span></span>L] +- <span class="hljs-type"><span class="hljs-type">Filter</span></span> (count(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">54</span></span>L &gt; cast(<span class="hljs-number"><span class="hljs-number">1</span></span> as bigint))  +- <span class="hljs-type"><span class="hljs-type">Aggregate</span></span> [city_id#<span class="hljs-number"><span class="hljs-number">19</span></span>L], [city_id#<span class="hljs-number"><span class="hljs-number">19</span></span>L, count(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-type"><span class="hljs-type">AS</span></span> count(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">52</span></span>L, count(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-type"><span class="hljs-type">AS</span></span> count(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">54</span></span>L] +- <span class="hljs-type"><span class="hljs-type">SubqueryAlias</span></span> p    +- <span class="hljs-type"><span class="hljs-type">SubqueryAlias</span></span> person       +- <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">NAME</span></span>#<span class="hljs-number"><span class="hljs-number">11</span></span>,<span class="hljs-type"><span class="hljs-type">BIRTH_DATE</span></span>#<span class="hljs-number"><span class="hljs-number">12</span></span>,<span class="hljs-type"><span class="hljs-type">IS_RESIDENT</span></span>#<span class="hljs-number"><span class="hljs-number">13</span></span>,<span class="hljs-type"><span class="hljs-type">SALARY</span></span>#<span class="hljs-number"><span class="hljs-number">14</span></span>,<span class="hljs-type"><span class="hljs-type">PENSION</span></span>#<span class="hljs-number"><span class="hljs-number">15</span></span>,<span class="hljs-type"><span class="hljs-type">ACCOUNT</span></span>#<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-type"><span class="hljs-type">AGE</span></span>#<span class="hljs-number"><span class="hljs-number">17</span></span>,<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">18</span></span>L,<span class="hljs-type"><span class="hljs-type">CITY_ID</span></span>#<span class="hljs-number"><span class="hljs-number">19</span></span>L]         <span class="hljs-type"><span class="hljs-type">IgniteSQLRelation</span></span>[table=<span class="hljs-type"><span class="hljs-type">PERSON</span></span>]</code> </pre><br>  A rela√ß√£o √© apenas uma tabela Ignite.  N√£o h√° filtros - simplesmente bombeamos todos os dados da tabela Pessoa pela rede a partir do cluster.  Ent√£o o Spark agrega tudo isso - de acordo com a solicita√ß√£o e retorna o resultado da solicita√ß√£o. <br><br>  √â f√°cil ver que toda essa sub√°rvore com filtro e agrega√ß√£o pode ser executada no Ignite.  Isso ser√° muito mais eficiente do que extrair todos os dados de uma tabela potencialmente grande no Spark - √© isso que nosso recurso IgniteOptimization faz.  Ap√≥s analisar e otimizar a √°rvore, obtemos o seguinte plano: <br><br><pre> <code class="scala hljs">== <span class="hljs-type"><span class="hljs-type">Optimized</span></span> <span class="hljs-type"><span class="hljs-type">Logical</span></span> <span class="hljs-type"><span class="hljs-type">Plan</span></span> == <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">CITY_ID</span></span>#<span class="hljs-number"><span class="hljs-number">19</span></span>L,<span class="hljs-type"><span class="hljs-type">COUNT</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>)#<span class="hljs-number"><span class="hljs-number">52</span></span>L]   <span class="hljs-type"><span class="hljs-type">IgniteSQLAccumulatorRelation</span></span>(     columns=[<span class="hljs-type"><span class="hljs-type">CITY_ID</span></span>, <span class="hljs-type"><span class="hljs-type">COUNT</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>)], qry=<span class="hljs-type"><span class="hljs-type">SELECT</span></span> <span class="hljs-type"><span class="hljs-type">CITY_ID</span></span>, <span class="hljs-type"><span class="hljs-type">COUNT</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-type"><span class="hljs-type">FROM</span></span> <span class="hljs-type"><span class="hljs-type">PERSON</span></span> <span class="hljs-type"><span class="hljs-type">GROUP</span></span> <span class="hljs-type"><span class="hljs-type">BY</span></span> city_id <span class="hljs-type"><span class="hljs-type">HAVING</span></span> count(<span class="hljs-number"><span class="hljs-number">1</span></span>) &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  Como resultado, temos apenas uma rela√ß√£o, pois otimizamos toda a √°rvore.  E, por dentro, voc√™ j√° pode ver que o Ignite enviar√° uma solicita√ß√£o pr√≥xima o suficiente da solicita√ß√£o original. <br><br>  Suponha que estamos juntando fontes de dados diferentes: por exemplo, temos um DataFrame do Ignite, o segundo do json, o terceiro do Ignite novamente e o quarto de algum tipo de banco de dados relacional.  Nesse caso, apenas a sub√°rvore ser√° otimizada no plano.  Otimizamos o que podemos, colocamos no Ignite e o Spark far√° o resto.  Devido a isso, obtemos um ganho de velocidade. <br><br>  Outro exemplo com JOIN: <br><br><pre> <code class="sql hljs">SQL Query - <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> jt1.id <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> id1, jt1.val1, jt2.id <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> id2, jt2.val2 <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> jt1 <span class="hljs-keyword"><span class="hljs-keyword">JOIN</span></span> jt2 <span class="hljs-keyword"><span class="hljs-keyword">ON</span></span> jt1.val1 = jt2.val2</code> </pre><br>  N√≥s temos duas mesas.  Permanecemos juntos por valor e selecionamos todos eles - IDs, valores.  O Spark oferece esse plano: <br><br><pre> <code class="scala hljs">== <span class="hljs-type"><span class="hljs-type">Analyzed</span></span> <span class="hljs-type"><span class="hljs-type">Logical</span></span> <span class="hljs-type"><span class="hljs-type">Plan</span></span> == id1: bigint, val1: string, id2: bigint, val2: string <span class="hljs-type"><span class="hljs-type">Project</span></span> [id#<span class="hljs-number"><span class="hljs-number">4</span></span>L <span class="hljs-type"><span class="hljs-type">AS</span></span> id1#<span class="hljs-number"><span class="hljs-number">84</span></span>L, val1#<span class="hljs-number"><span class="hljs-number">3</span></span>, id#<span class="hljs-number"><span class="hljs-number">6</span></span>L <span class="hljs-type"><span class="hljs-type">AS</span></span> id2#<span class="hljs-number"><span class="hljs-number">85</span></span>L, val2#<span class="hljs-number"><span class="hljs-number">5</span></span>] +- <span class="hljs-type"><span class="hljs-type">Join</span></span> <span class="hljs-type"><span class="hljs-type">Inner</span></span>, (val1#<span class="hljs-number"><span class="hljs-number">3</span></span> = val2#<span class="hljs-number"><span class="hljs-number">5</span></span>) :- <span class="hljs-type"><span class="hljs-type">SubqueryAlias</span></span> jt1 : +- <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">VAL1</span></span>#<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">4</span></span>L] <span class="hljs-type"><span class="hljs-type">IgniteSQLRelation</span></span>[table=<span class="hljs-type"><span class="hljs-type">JT1</span></span>] +- <span class="hljs-type"><span class="hljs-type">SubqueryAlias</span></span> jt2    +- <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">VAL2</span></span>#<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">6</span></span>L] <span class="hljs-type"><span class="hljs-type">IgniteSQLRelation</span></span>[table=<span class="hljs-type"><span class="hljs-type">JT2</span></span>]</code> </pre> <br>  Vemos que ele extrai todos os dados de uma tabela, todos os dados da segunda, junta-se a eles dentro de si e fornece os resultados.  Ap√≥s o processamento e a otimiza√ß√£o, recebemos exatamente a mesma solicita√ß√£o que √© enviada ao Ignite, onde √© executada relativamente rapidamente. <br><br><pre> <code class="scala hljs">== <span class="hljs-type"><span class="hljs-type">Optimized</span></span> <span class="hljs-type"><span class="hljs-type">Logical</span></span> <span class="hljs-type"><span class="hljs-type">Plan</span></span> == <span class="hljs-type"><span class="hljs-type">Relation</span></span>[<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">84</span></span>L,<span class="hljs-type"><span class="hljs-type">VAL1</span></span>#<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-type"><span class="hljs-type">ID</span></span>#<span class="hljs-number"><span class="hljs-number">85</span></span>L,<span class="hljs-type"><span class="hljs-type">VAL2</span></span>#<span class="hljs-number"><span class="hljs-number">5</span></span>] <span class="hljs-type"><span class="hljs-type">IgniteSQLAccumulatorRelation</span></span>(columns=[<span class="hljs-type"><span class="hljs-type">ID</span></span>, <span class="hljs-type"><span class="hljs-type">VAL1</span></span>, <span class="hljs-type"><span class="hljs-type">ID</span></span>, <span class="hljs-type"><span class="hljs-type">VAL2</span></span>], qry= <span class="hljs-type"><span class="hljs-type">SELECT</span></span> <span class="hljs-type"><span class="hljs-type">JT1</span></span>.<span class="hljs-type"><span class="hljs-type">ID</span></span> <span class="hljs-type"><span class="hljs-type">AS</span></span> id1, <span class="hljs-type"><span class="hljs-type">JT1</span></span>.<span class="hljs-type"><span class="hljs-type">VAL1</span></span>, <span class="hljs-type"><span class="hljs-type">JT2</span></span>.<span class="hljs-type"><span class="hljs-type">ID</span></span> <span class="hljs-type"><span class="hljs-type">AS</span></span> id2, <span class="hljs-type"><span class="hljs-type">JT2</span></span>.<span class="hljs-type"><span class="hljs-type">VAL2</span></span> <span class="hljs-type"><span class="hljs-type">FROM</span></span> <span class="hljs-type"><span class="hljs-type">JT1</span></span> <span class="hljs-type"><span class="hljs-type">JOIN</span></span> <span class="hljs-type"><span class="hljs-type">JT2</span></span> <span class="hljs-type"><span class="hljs-type">ON</span></span> <span class="hljs-type"><span class="hljs-type">JT1</span></span>.val1 = <span class="hljs-type"><span class="hljs-type">JT2</span></span>.val2 <span class="hljs-type"><span class="hljs-type">WHERE</span></span> <span class="hljs-type"><span class="hljs-type">JT1</span></span>.val1 <span class="hljs-type"><span class="hljs-type">IS</span></span> <span class="hljs-type"><span class="hljs-type">NOT</span></span> <span class="hljs-type"><span class="hljs-type">NULL</span></span> <span class="hljs-type"><span class="hljs-type">AND</span></span> <span class="hljs-type"><span class="hljs-type">JT2</span></span>.val2 <span class="hljs-type"><span class="hljs-type">IS</span></span> <span class="hljs-type"><span class="hljs-type">NOT</span></span> <span class="hljs-type"><span class="hljs-type">NULL</span></span>)</code> </pre> <br>  Eu vou te mostrar um exemplo <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ba4/39a/493/ba439a493e76dd573966cad413c07650.png"><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OptimizationExample.scala</a> <br><br>  Estamos criando uma sess√£o do IgniteSpark na qual todos os nossos recursos de otimiza√ß√£o j√° est√£o inclu√≠dos automaticamente.  Aqui est√° o pedido: encontre os jogadores com a classifica√ß√£o mais alta e mostre seus nomes.  Na tabela de jogadores, seus atributos e dados.  Estamos nos unindo, filtrando dados indesejados e exibindo jogadores com a classifica√ß√£o mais alta.  Vamos ver o tipo de plano que temos ap√≥s a otimiza√ß√£o e mostrar os resultados dessa consulta. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7d/c51/9ab/c7dc519abdfa6b3b1d7a8396ef9725b3.png"><br><br>  Come√ßamos.  Vemos sobrenomes familiares: Messi, Buffon, Ronaldo, etc.  A prop√≥sito, alguns, por algum motivo, se encontram de duas formas: Messi e Ronaldo.  Os amantes do futebol podem achar estranho que jogadores desconhecidos apare√ßam na lista.  Estes s√£o goleiros, jogadores com caracter√≠sticas bastante altas - no contexto de outros jogadores.  Agora, examinamos o plano de consulta que foi executado.  No Spark, quase nada foi feito, ou seja, enviamos todo o pedido novamente ao Ignite. <br><br><h2>  Apache Ignite Development </h2><br>  Nosso projeto √© um produto de c√≥digo aberto, por isso estamos sempre felizes com as corre√ß√µes e o feedback dos desenvolvedores.  Sua ajuda, feedback e corre√ß√µes s√£o muito bem-vindos.  Estamos esperando por eles.  90% da comunidade Ignite √© de l√≠ngua russa.  Por exemplo, para mim, at√© come√ßar a trabalhar no Apache Ignite, o melhor conhecimento de ingl√™s n√£o era um impedimento.  Dificilmente vale a pena escrever em russo em uma lista de desenvolvedores, mas mesmo se voc√™ escrever algo errado, eles responder√£o e o ajudar√£o. <br><br>  O que pode ser aprimorado nessa integra√ß√£o?  Como posso ajudar se voc√™ tem esse desejo?  Listar abaixo.  Asteriscos indicam complexidade. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/de4/d43/ed0/de4d43ed01894ce6b02865ad9f6aef5d.png"><br>  Para testar a otimiza√ß√£o, voc√™ precisa escrever testes com consultas complexas.  Acima, mostrei algumas consultas √≥bvias.  √â claro que se voc√™ escrever muitos agrupamentos e muitas jun√ß√µes, algo poder√° cair.  Essa √© uma tarefa muito simples - venha e fa√ßa.  Se encontrarmos algum bug com base nos resultados do teste, eles precisar√£o ser corrigidos.  Ser√° mais dif√≠cil l√°. <br><br>  Outra tarefa clara e interessante √© a integra√ß√£o do Spark com um thin client.  Inicialmente, ele pode especificar alguns conjuntos de endere√ßos IP, e isso √© suficiente para ingressar no cluster Ignite, o que √© conveniente em caso de integra√ß√£o com um sistema externo.  Se de repente voc√™ quiser se juntar √† solu√ß√£o para esse problema, eu ajudarei pessoalmente. <br><br>  Se voc√™ deseja ingressar na comunidade Apache Ignite, aqui est√£o alguns links √∫teis: <br><br><ul><li>  <i>Comece aqui - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=http://yu">https://ignite.apache.org/community/resources.html</a></i> <br></li><li>  <i>Fontes aqui - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/apache/ignite/</a></i> <br></li><li>  <i>Docas aqui - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://apacheignite.readme.io/docs</a></i> <br></li><li>  <i>Erros aqui - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://issues.apache.org/jira/browse/IGNITE</a></i> <br></li><li>  <i>Voc√™ pode escrever aqui - dev@ignite.apache.org, user@ignite.apache.org</i> <br></li></ul><br>  Temos uma lista de desenvolvedores responsiva, que o ajudar√°.  Ainda est√° longe do ideal, mas em compara√ß√£o com outros projetos, ele est√° realmente vivo. <br><br>  <i>Se voc√™ conhece Java ou C ++, est√° procurando trabalho e deseja desenvolver Open Source (Apache Ignite, Apache Kafka, Tarantool, etc.) escreva aqui: join-open-source@sberbank.ru.</i> <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/CzbAweNKEVY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt427297/">https://habr.com/ru/post/pt427297/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt427285/index.html">Escola b√°sica de circuitos digitais: Novosibirsk - Ok, Krasnoyarsk - prepare-se</a></li>
<li><a href="../pt427289/index.html">Modelagem Geol√≥gica 3D, Registro e Tecnologia da Aramco Innovations</a></li>
<li><a href="../pt427291/index.html">Minimize o tr√°fego nos formul√°rios da Web do ASP.NET, div clic√°vel e pesquisas peri√≥dicas no servidor</a></li>
<li><a href="../pt427293/index.html">Padr√µes de Design JavaScript</a></li>
<li><a href="../pt427295/index.html">Fun√ß√µes de Currying JavaScript</a></li>
<li><a href="../pt427299/index.html">Vamos pegar outra coisa para colecionar? Construtor 3 em 1 "Frota Lunar"</a></li>
<li><a href="../pt427301/index.html">Banco de dados com falha no GitHub</a></li>
<li><a href="../pt427303/index.html">Abrandando o Windows Parte 2: Criando processos</a></li>
<li><a href="../pt427307/index.html">Pr√°tica de teste de back-end Java + Garantido</a></li>
<li><a href="../pt427309/index.html">Como o PVS-Studio se mostrou mais atento do que tr√™s programadores e meio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
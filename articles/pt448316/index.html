<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∑üèª üéì üöô Determinando a ra√ßa de um c√£o: um ciclo completo de desenvolvimento, de uma rede neural em Python a um aplicativo no Google Play üéè ü§Ø üîµ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O progresso no campo das redes neurais em geral e o reconhecimento de padr√µes em particular levou ao fato de que pode parecer que criar um aplicativo ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Determinando a ra√ßa de um c√£o: um ciclo completo de desenvolvimento, de uma rede neural em Python a um aplicativo no Google Play</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/448316/">  O progresso no campo das redes neurais em geral e o reconhecimento de padr√µes em particular levou ao fato de que pode parecer que criar um aplicativo de rede neural para trabalhar com imagens seja uma tarefa rotineira.  De certa forma, √© - se voc√™ teve uma id√©ia relacionada ao reconhecimento de padr√µes, n√£o duvide que algu√©m j√° tenha escrito algo assim.  Tudo o que voc√™ precisa √© encontrar o trecho de c√≥digo correspondente no Google e "compil√°-lo" do autor. <br><br>  No entanto, ainda existem in√∫meros detalhes que tornam a tarefa n√£o t√£o insol√∫vel quanto ... chata, eu diria.  Leva muito tempo, especialmente se voc√™ √© iniciante e precisa de lideran√ßa, passo a passo, um projeto realizado diante de seus olhos e conclu√≠do do in√≠cio ao fim.  Sem o habitual nesses casos, ‚Äúpule esta parte √≥bvia‚Äù desculpas. <br><br>  Neste artigo, consideraremos a tarefa de criar um identificador de ra√ßas de c√£es: criaremos e treinaremos uma rede neural, depois a portaremos para Java para Android e a publicaremos no Google Play. <br><br>  Se voc√™ quiser ver o resultado final, aqui est√°: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NeuroDog App</a> no Google Play. <br><br>  Site com minha rob√≥tica (em andamento): <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">robotics.snowcron.com</a> . <br>  Site com o pr√≥prio programa, incluindo um guia: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Guia do usu√°rio do NeuroDog</a> . <br><br>  E aqui est√° uma captura de tela do programa: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/186/b91/457/186b914572170b01446ed1d722bce200.png" alt="imagem"><br><br><a name="habracut"></a><br><br><h3>  Declara√ß√£o do problema </h3><br><br>  Usaremos Keras: uma biblioteca do Google para trabalhar com redes neurais.  Esta √© uma biblioteca de alto n√≠vel, o que significa que √© mais f√°cil de usar em compara√ß√£o com as alternativas que eu conhe√ßo.  Se alguma coisa - existem muitos livros sobre Keras na rede, de alta qualidade. <br><br>  Usaremos a CNN - Redes Neurais Convolucionais.  A CNN (e configura√ß√µes mais avan√ßadas baseadas nelas) s√£o o padr√£o de fato no reconhecimento de imagens.  Ao mesmo tempo, o treinamento de uma rede nem sempre √© f√°cil: voc√™ precisa escolher a estrutura de rede correta, os par√¢metros de treinamento (todas essas taxas de aprendizado, momento, L1 e L2, etc.).  A tarefa requer recursos computacionais significativos e, portanto, resolv√™-la simplesmente passando por TODOS os par√¢metros falhar√°. <br><br>  Essa √© uma das v√°rias raz√µes pelas quais, na maioria dos casos, eles usam o chamado "conhecimento de transfer√™ncia", em vez da abordagem chamada "baunilha".  O Transfer Knowlege usa uma rede neural treinada por algu√©m antes de n√≥s (por exemplo, Google) e geralmente para uma tarefa semelhante, mas ainda diferente.  Pegamos as camadas iniciais, substitu√≠mos as camadas finais por nosso pr√≥prio classificador - e funciona, e funciona muito bem. <br><br>  A princ√≠pio, esse resultado pode ser surpreendente: como √© que adotamos uma rede do Google treinada para distinguir gatos de cadeiras e reconhece as ra√ßas de c√£es para n√≥s?  Para entender como isso acontece, voc√™ precisa entender os princ√≠pios b√°sicos do trabalho das Redes Neurais Profundas, incluindo os usados ‚Äã‚Äãpara o reconhecimento de padr√µes. <br><br>  N√≥s ‚Äúalimentamos‚Äù a rede com uma imagem (uma matriz de n√∫meros, isto √©) como entrada.  A primeira camada analisa a imagem em busca de padr√µes simples, como "linha horizontal", "arco" etc.  A pr√≥xima camada recebe esses padr√µes como entrada e produz padr√µes de segunda ordem, como "p√™lo", "canto do olho" ... Por fim, obtemos um quebra-cabe√ßa do qual podemos reconstruir o c√£o: l√£, dois olhos e uma m√£o humana nos dentes. <br><br>  Tudo isso foi feito com a ajuda de camadas pr√©-treinadas obtidas por n√≥s (por exemplo, do Google).  Em seguida, adicionamos nossas camadas e as ensinamos a extrair informa√ß√µes sobre ra√ßas desses padr√µes.  Parece l√≥gico. <br><br>  Para resumir, neste artigo, criaremos a CNN "vanilla" e v√°rias variantes de "transfer learning" de diferentes tipos de redes.  Quanto ao "baunilha": eu o crio, mas n√£o pretendo configur√°-lo selecionando par√¢metros, pois √© muito mais f√°cil treinar e configurar redes "pr√©-treinadas". <br><br>  Como planejamos ensinar nossa rede neural a reconhecer ra√ßas de c√£es, devemos "mostrar" amostras de v√°rias ra√ßas.  Felizmente, h√° um conjunto de fotografias criadas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> para uma tarefa semelhante (o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">original est√° aqui</a> ). <br><br>  Ent√£o, planejo portar as melhores redes recebidas para o Android.  Portar redes Kerasov para o Android √© relativamente simples, bem formalizado e faremos todas as etapas necess√°rias, para que n√£o seja dif√≠cil reproduzir esta parte. <br><br>  Depois publicaremos tudo isso no Google Play.  Naturalmente, o Google resistir√°, portanto, truques adicionais ser√£o usados.  Por exemplo, o tamanho do nosso aplicativo (devido a uma rede neural volumosa) ser√° maior que o tamanho permitido do APK do Android aceito pelo Google Play: teremos que usar pacotes.  Al√©m disso, o Google n√£o mostrar√° nosso aplicativo nos resultados da pesquisa. Isso pode ser corrigido registrando as tags de pesquisa no aplicativo ou apenas aguardando ... uma semana ou duas. <br><br>  Como resultado, obtemos um aplicativo "comercial" totalmente funcional (entre aspas, como √© definido de gra√ßa) para Android e usando redes neurais. <br><br><h3>  Ambiente de desenvolvimento </h3><br><br>  Voc√™ pode programar o Keras de maneiras diferentes, dependendo do sistema operacional em uso (recomendado pelo Ubuntu), da presen√ßa ou aus√™ncia de uma placa de v√≠deo e assim por diante.  N√£o h√° nada de ruim no desenvolvimento no computador local (e, consequentemente, na sua configura√ß√£o), exceto que essa n√£o √© a maneira mais f√°cil. <br><br>  Primeiro, a instala√ß√£o e configura√ß√£o de um grande n√∫mero de ferramentas e bibliotecas leva tempo e, quando novas vers√µes s√£o lan√ßadas, voc√™ ter√° que gastar tempo novamente.  Em segundo lugar, as redes neurais exigem grande poder computacional para treinamento.  Voc√™ pode acelerar (10 ou mais vezes) esse processo se usar uma GPU ... no momento da reda√ß√£o deste artigo, as principais GPUs mais adequadas para este trabalho custam entre US $ 2.000 e US $ 7.000.  E sim, eles tamb√©m precisam ser configurados. <br><br>  Ent√£o, vamos para o outro lado.  O fato √© que o Google permite que ouri√ßos pobres como n√≥s usem GPUs de seu cluster - gratuitamente, para c√°lculos relacionados a redes neurais, ele tamb√©m fornece um ambiente totalmente configurado, todos juntos, isso √© chamado de Google Colab.  O servi√ßo fornece acesso ao Jupiter Notebook com python, Keras e um grande n√∫mero de outras bibliotecas j√° configuradas.  Tudo o que voc√™ precisa fazer √© obter uma conta do Google (obter uma conta do Gmail e isso lhe dar√° acesso a todo o resto). <br><br>  No momento, a Colab pode ser contratada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> , mas, conhecendo o Google, isso pode mudar a qualquer momento.  Basta pesquisar no Google Colab. <br><br>  O problema √≥bvio com o uso do Colab √© que √© um servi√ßo WEB.  Como acessamos nossos dados?  Salvar a rede neural ap√≥s o treinamento, por exemplo, baixar dados espec√≠ficos da nossa tarefa e assim por diante? <br><br>  Existem v√°rias (no momento em que escrevemos este artigo - tr√™s) maneiras diferentes, usamos a que acho mais conveniente - usamos o Google Drive. <br><br>  O Google Drive √© um armazenamento de dados baseado em nuvem que funciona como um disco r√≠gido comum e pode ser mapeado no Google Colab (veja o c√≥digo abaixo).  Depois disso, voc√™ pode trabalhar com ele como faria com os arquivos em um disco local.  Ou seja, por exemplo, para acessar as fotos de c√£es para treinar nossa rede neural, precisamos carreg√°-las no Google Drive, s√≥ isso. <br><br><h2>  Criando e treinando uma rede neural </h2><br><br>  Abaixo, dou o c√≥digo em Python, bloco por bloco (do Jupiter Notebook).  Voc√™ pode copiar esse c√≥digo no seu Jupiter Notebook e execut√°-lo, bloco por bloco, tamb√©m, pois os blocos podem ser executados independentemente (√© claro, as vari√°veis ‚Äã‚Äãdefinidas no bloco anterior podem ser necess√°rias no final, mas essa √© uma depend√™ncia √≥bvia). <br><br><h3>  Inicializa√ß√£o </h3><br><br>  Primeiro de tudo, vamos montar o Google Drive.  Apenas duas linhas.  Esse c√≥digo deve ser executado apenas uma vez em uma sess√£o Colab (digamos, uma vez a cada 6 horas).  Se voc√™ chamar pela segunda vez enquanto a sess√£o ainda estiver "viva", ela ser√° ignorada, pois a unidade j√° est√° montada. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.colab <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> drive drive.mount(<span class="hljs-string"><span class="hljs-string">'/content/drive/'</span></span>)</code> </pre> <br><br>  No primeiro come√ßo, voc√™ ser√° solicitado a confirmar suas inten√ß√µes, n√£o h√° nada complicado.  Aqui est√° o que parece: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>Go to this URL <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> a browser: ... &gt;&gt;&gt; Enter your authorization code: &gt;&gt;&gt; ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑ &gt;&gt;&gt; Mounted at /content/drive/</code> </pre><br><br>  Uma se√ß√£o de <i>inclus√£o</i> completamente padr√£o;  √© poss√≠vel que alguns dos arquivos inclu√≠dos n√£o sejam necess√°rios, bem ... desculpe.  Al√©m disso, como vou testar redes neurais diferentes, ser√° necess√°rio comentar / descomentar alguns dos m√≥dulos inclu√≠dos para tipos espec√≠ficos de redes neurais: por exemplo, para usar o InceptionV3 NN, descomentar a inclus√£o do InceptionV3 e comentar, por exemplo, o ResNet50.  Ou n√£o: tudo o que muda com isso √© o tamanho da mem√≥ria usada e isso n√£o √© muito forte. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> dt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> warnings <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> regularizers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, Dropout, Activation <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Flatten, Conv2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaxPooling2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization, Input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dropout, GlobalAveragePooling2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Callback, EarlyStopping <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ReduceLROnPlateau <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ModelCheckpoint <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.vgg16 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageDataGenerator <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ResNet50 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> decode_predictions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> InceptionV3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> inception_v3_preprocessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.mobilenetv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MobileNetV2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.nasnet <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> NASNetMobile</code> </pre><br><br>  No Google Drive, criamos uma pasta para nossos arquivos.  A segunda linha exibe seu conte√∫do: <br><br><pre> <code class="python hljs">working_path = <span class="hljs-string"><span class="hljs-string">"/content/drive/My Drive/DeepDogBreed/data/"</span></span> !ls <span class="hljs-string"><span class="hljs-string">"/content/drive/My Drive/DeepDogBreed/data"</span></span> &gt;&gt;&gt; all_images labels.csv models test train valid</code> </pre><br><br>  Como voc√™ pode ver, as fotos dos c√£es (copiadas do conjunto de dados de Stanford (veja acima) no Google Drive) s√£o salvas primeiro na pasta <i>all_images</i> .  Mais tarde, iremos copi√°-los nos diret√≥rios <i>train, valid</i> e <i>test</i> .  Salvaremos modelos treinados na pasta de <i>modelos</i> .  Quanto ao arquivo labels.csv, isso faz parte do conjunto de dados com fotos, cont√©m uma tabela de correspond√™ncia dos nomes das fotos e ra√ßas de c√£es. <br><br>  Existem muitos testes que voc√™ pode executar para entender exatamente o que recebemos para uso tempor√°rio do Google.  Por exemplo: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Is GPU Working? import tensorflow as tf tf.test.gpu_device_name() &gt;&gt;&gt; '/device:GPU:0'</span></span></code> </pre><br><br>  Como voc√™ pode ver, a GPU est√° realmente conectada e, caso contr√°rio, voc√™ precisa encontrar e ativar essa op√ß√£o nas configura√ß√µes do Notebook Jupiter. <br><br>  Em seguida, precisamos declarar algumas constantes, como o tamanho das imagens, etc.  Usaremos imagens com um tamanho de 256x256 pixels; essa √© uma imagem grande o suficiente para n√£o perder detalhes e pequena o suficiente para que tudo caiba na mem√≥ria.  Observe, no entanto, que alguns tipos de redes neurais que usaremos esperam imagens de 224x224 pixels.  Nesses casos, comentamos 256 e descomentamos 224. <br><br>  A mesma abordagem (coment√°rio um - descomente) ser√° aplicada aos nomes dos modelos que salvamos, simplesmente porque n√£o queremos sobrescrever arquivos que ainda podem ser √∫teis. <br><pre> <code class="python hljs">warnings.filterwarnings(<span class="hljs-string"><span class="hljs-string">"ignore"</span></span>) os.environ[<span class="hljs-string"><span class="hljs-string">'TF_CPP_MIN_LOG_LEVEL'</span></span>] = <span class="hljs-string"><span class="hljs-string">'2'</span></span> np.random.seed(<span class="hljs-number"><span class="hljs-number">7</span></span>) start = dt.datetime.now() BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">16</span></span> EPOCHS = <span class="hljs-number"><span class="hljs-number">15</span></span> TESTING_SPLIT=<span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-comment"><span class="hljs-comment"># 70/30 % NUM_CLASSES = 120 IMAGE_SIZE = 256 #strModelFileName = "models/ResNet50.h5" # strModelFileName = "models/InceptionV3.h5" strModelFileName = "models/InceptionV3_Sgd.h5" #IMAGE_SIZE = 224 #strModelFileName = "models/MobileNetV2.h5" #IMAGE_SIZE = 224 #strModelFileName = "models/NASNetMobileSgd.h5"</span></span></code> </pre><br><br><h3>  Carregamento de dados </h3><br><br>  Primeiro, vamos <i>fazer o upload do</i> arquivo <i>labels.csv</i> e dividi-lo nas partes de treinamento e valida√ß√£o.  Observe que ainda n√£o h√° uma parte de teste, pois vou trapacear para obter mais dados de treinamento. <br><br><pre> <code class="python hljs">labels = pd.read_csv(working_path + <span class="hljs-string"><span class="hljs-string">'labels.csv'</span></span>) print(labels.head()) train_ids, valid_ids = train_test_split(labels, test_size = TESTING_SPLIT) print(len(train_ids), <span class="hljs-string"><span class="hljs-string">'train ids'</span></span>, len(valid_ids), <span class="hljs-string"><span class="hljs-string">'validation ids'</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Total'</span></span>, len(labels), <span class="hljs-string"><span class="hljs-string">'testing images'</span></span>) &gt;&gt;&gt; id breed &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">000</span></span>bec180eb18c7604dcecc8fe0dba07 boston_bull &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">001513</span></span>dfcb2ffafc82cccf4d8bbaba97 dingo &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">001</span></span>cdf01b096e06d78e9e5112d419397 pekinese &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">00214</span></span>f311d5d2247d5dfe4fe24b2303d bluetick &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-number"><span class="hljs-number">0021</span></span>f9ceb3235effd7fcde7f7538ed62 golden_retriever &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">7155</span></span> train ids <span class="hljs-number"><span class="hljs-number">3067</span></span> validation ids &gt;&gt;&gt; Total <span class="hljs-number"><span class="hljs-number">10222</span></span> testing images</code> </pre><br><br>  Em seguida, copie os arquivos de imagem para as pastas de treinamento / valida√ß√£o / teste, de acordo com os nomes dos arquivos.  A fun√ß√£o a seguir copia os arquivos cujos nomes transferimos para a pasta especificada. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">copyFileSet</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(strDirFrom, strDirTo, arrFileNames)</span></span></span><span class="hljs-function">:</span></span> arrBreeds = np.asarray(arrFileNames[<span class="hljs-string"><span class="hljs-string">'breed'</span></span>]) arrFileNames = np.asarray(arrFileNames[<span class="hljs-string"><span class="hljs-string">'id'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(strDirTo): os.makedirs(strDirTo) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(range(len(arrFileNames))): strFileNameFrom = strDirFrom + arrFileNames[i] + <span class="hljs-string"><span class="hljs-string">".jpg"</span></span> strFileNameTo = strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span> + arrFileNames[i] + <span class="hljs-string"><span class="hljs-string">".jpg"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span>): os.makedirs(strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># As a new breed dir is created, copy 1st file # to "test" under name of that breed if not os.path.exists(working_path + "test/"): os.makedirs(working_path + "test/") strFileNameTo = working_path + "test/" + arrBreeds[i] + ".jpg" shutil.copy(strFileNameFrom, strFileNameTo) shutil.copy(strFileNameFrom, strFileNameTo)</span></span></code> </pre><br><br>  Como voc√™ pode ver, apenas copiamos um arquivo para cada ra√ßa de c√£o como <i>teste</i> .  Al√©m disso, ao copiar, criamos subpastas, uma para cada ra√ßa.  Consequentemente, as fotografias s√£o copiadas para subpastas por ra√ßa. <br><br>  Isso √© feito porque o Keras pode trabalhar com um diret√≥rio de estrutura semelhante, carregando arquivos de imagem conforme necess√°rio e n√£o todos de uma vez, o que economiza mem√≥ria.  Carregar todas as 15.000 imagens de uma s√≥ vez √© uma m√° id√©ia. <br><br>  Teremos que chamar essa fun√ß√£o apenas uma vez, pois ela copia imagens - e n√£o √© mais necess√°ria.  Assim, para uso futuro, devemos comentar: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Move the data in subfolders so we can # use the Keras ImageDataGenerator. # This way we can also later use Keras # Data augmentation features. # --- Uncomment once, to copy files --- #copyFileSet(working_path + "all_images/", # working_path + "train/", train_ids) #copyFileSet(working_path + "all_images/", # working_path + "valid/", valid_ids)</span></span></code> </pre><br><br>  Obtenha uma lista de ra√ßas de c√£es: <br><br><pre> <code class="python hljs">breeds = np.unique(labels[<span class="hljs-string"><span class="hljs-string">'breed'</span></span>]) map_characters = {} <span class="hljs-comment"><span class="hljs-comment">#{0:'none'} for i in range(len(breeds)): map_characters[i] = breeds[i] print("&lt;item&gt;" + breeds[i] + "&lt;/item&gt;") &gt;&gt;&gt; &lt;item&gt;affenpinscher&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;afghan_hound&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;african_hunting_dog&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;airedale&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;american_staffordshire_terrier&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;appenzeller&lt;/item&gt;</span></span></code> </pre><br><br><h3>  Processamento de imagem </h3><br><br>  Vamos usar o recurso da biblioteca Keras chamado ImageDataGenerators.  ImageDataGenerator pode processar a imagem, dimensionar, girar e assim por diante.  Tamb√©m pode aceitar uma fun√ß√£o de <i>processamento</i> que pode processar imagens adicionalmente. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocess</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img)</span></span></span><span class="hljs-function">:</span></span> img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) <span class="hljs-comment"><span class="hljs-comment"># or use ImageDataGenerator( rescale=1./255... img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. #img = cv2.blur(img,(5,5)) return img_1[0]</span></span></code> </pre><br><br>  Preste aten√ß√£o ao seguinte c√≥digo: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># or use ImageDataGenerator( rescale=1./255...</span></span></code> </pre><br><br>  Podemos normalizar (sub-dados sob o intervalo 0-1 em vez do original 0-255) no pr√≥prio ImageDataGenerator.  Por que, ent√£o, precisamos de um pr√©-processador?  Como exemplo, considere a chamada borrada (comentada, n√£o a uso): esta √© a mesma manipula√ß√£o de imagem personalizada que pode ser arbitr√°ria.  Qualquer coisa do contraste ao HDR. <br><br>  Usaremos dois ImageDataGenerators diferentes, um para treinamento e outro para valida√ß√£o.  A diferen√ßa √© que, para o treinamento, precisamos de curvas e redimensionamentos para aumentar a "variedade" de dados, mas para valida√ß√£o, n√£o precisamos deles, pelo menos n√£o nesta tarefa. <br><br><pre> <code class="python hljs">train_datagen = ImageDataGenerator( preprocessing_function=preprocess, <span class="hljs-comment"><span class="hljs-comment">#rescale=1./255, # done in preprocess() # randomly rotate images (degrees, 0 to 30) rotation_range=30, # randomly shift images horizontally # (fraction of total width) width_shift_range=0.3, height_shift_range=0.3, # randomly flip images horizontal_flip=True, ,vertical_flip=False, zoom_range=0.3) val_datagen = ImageDataGenerator( preprocessing_function=preprocess) train_gen = train_datagen.flow_from_directory( working_path + "train/", batch_size=BATCH_SIZE, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, class_mode="categorical") val_gen = val_datagen.flow_from_directory( working_path + "valid/", batch_size=BATCH_SIZE, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, class_mode="categorical")</span></span></code> </pre><br><br><h3>  Criando uma rede neural </h3><br><br>  Como j√° mencionado, vamos criar v√°rios tipos de redes neurais.  Cada vez que chamaremos outra fun√ß√£o para criar, inclua outros arquivos e, √†s vezes, determine um tamanho de imagem diferente.  Portanto, para alternar entre diferentes tipos de redes neurais, devemos comentar / descomentar o c√≥digo apropriado. <br><br>  Primeiro de tudo, crie uma CNN ‚Äúbaunilha‚Äù.  N√£o funciona bem, porque decidi n√£o perder tempo depurando-o, mas pelo menos fornece uma base que pode ser desenvolvida se houver um desejo (geralmente essa √© uma m√° ideia, pois as redes pr√©-treinadas fornecem o melhor resultado). <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelVanilla</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() <span class="hljs-comment"><span class="hljs-comment"># Note the (7, 7) here. This is one of technics # used to reduce memory use by the NN: we scan # the image in a larger steps. # Also note regularizers.l2: this technic is # used to prevent overfitting. The "0.001" here # is an empirical value and can be optimized. model.add(Conv2D(16, (7, 7), padding='same', use_bias=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), kernel_regularizer=regularizers.l2(0.001))) # Note the use of a standard CNN building blocks: # Conv2D - BatchNormalization - Activation # MaxPooling2D - Dropout # The last two are used to avoid overfitting, also, # MaxPooling2D reduces memory use. model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(16, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) # This is the end on "convolutional" part of CNN. # Now we need to transform multidementional # data into one-dim. array for a fully-connected # classifier: model.add(Flatten()) # And two layers of classifier itself (plus an # Activation layer in between): model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=regularizers.l2(0.01))) model.add(Activation("relu")) model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=regularizers.l2(0.01))) # We need to compile the resulting network. # Note that there are few parameters we can # try here: the best performing one is uncommented, # the rest is commented out for your reference. #model.compile(optimizer='rmsprop', # loss='categorical_crossentropy', # metrics=['accuracy']) #model.compile( # optimizer=keras.optimizers.RMSprop(lr=0.0005), # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #model.compile(optimizer='adadelta', # loss='categorical_crossentropy', # metrics=['accuracy']) #opt = keras.optimizers.Adadelta(lr=1.0, # rho=0.95, epsilon=0.01, decay=0.01) #model.compile(optimizer=opt, # loss='categorical_crossentropy', # metrics=['accuracy']) #opt = keras.optimizers.RMSprop(lr=0.0005, # rho=0.9, epsilon=None, decay=0.0001) #model.compile(optimizer=opt, # loss='categorical_crossentropy', # metrics=['accuracy']) # model.summary() return(model)</span></span></code> </pre><br><br>  Quando criamos redes usando <i>transfer√™ncia de aprendizado</i> , o procedimento muda: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelMobileNetV2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># First, create the NN and load pre-trained # weights for it ('imagenet') # Note that we are not loading last layers of # the network (include_top=False), as we are # going to add layers of our own: base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) # Then attach our layers at the end. These are # to build "classifier" that makes sense of # the patterns previous layers provide: x = base_model.output x = Dense(512)(x) x = Activation('relu')(x) x = Dropout(0.5)(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) # Create a model model = Model(inputs=base_model.input, outputs=predictions) # We need to make sure that pre-trained # layers are not changed when we train # our classifier: # Either this: #model.layers[0].trainable = False # or that: for layer in base_model.layers: layer.trainable = False # As always, there are different possible # settings, I tried few and chose the best: # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br>  A cria√ß√£o de outros tipos de redes segue o mesmo padr√£o: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelResNet50</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> base_model = ResNet50(weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>, include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pooling=<span class="hljs-string"><span class="hljs-string">'avg'</span></span>, input_shape=(IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>)) x = base_model.output x = Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>)(x) x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) predictions = Dense(NUM_CLASSES, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=base_model.input, outputs=predictions) <span class="hljs-comment"><span class="hljs-comment">#model.layers[0].trainable = False # model.compile(loss='categorical_crossentropy', # optimizer='adam', metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br>  Aten√ß√£o: vencedor!  Este NN mostrou o melhor resultado: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelInceptionV3</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># model.layers[0].trainable = False # model.compile(optimizer='sgd', # loss='categorical_crossentropy', # metrics=['accuracy']) base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) x = base_model.output x = GlobalAveragePooling2D()(x) x = Dense(512, activation='relu')(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) model = Model(inputs = base_model.input, outputs = predictions) for layer in base_model.layers: layer.trainable = False # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br>  Outro: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelNASNetMobile</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># model.layers[0].trainable = False # model.compile(optimizer='sgd', # loss='categorical_crossentropy', # metrics=['accuracy']) base_model = NASNetMobile(weights = 'imagenet', include_top = False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) x = base_model.output x = GlobalAveragePooling2D()(x) x = Dense(512, activation='relu')(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) model = Model(inputs = base_model.input, outputs = predictions) for layer in base_model.layers: layer.trainable = False # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br>  Diferentes tipos de redes neurais podem ser usados ‚Äã‚Äãpara diferentes tarefas.  Portanto, al√©m dos requisitos de precis√£o da previs√£o, o tamanho pode ter import√¢ncia (o NN m√≥vel √© 5 vezes menor que o Inception) e a velocidade (se precisarmos de processamento em tempo real de um fluxo de v√≠deo, a precis√£o ter√° que ser sacrificada). <br><br><h3>  Treinamento em redes neurais </h3><br><br>  Antes de tudo, estamos <i>experimentando</i> , portanto devemos poder remover as redes neurais que salvamos, mas que n√£o usamos mais.  A seguinte fun√ß√£o remove NN, se existir: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Make sure that previous "best network" is deleted. def deleteSavedNet(best_weights_filepath): if(os.path.isfile(best_weights_filepath)): os.remove(best_weights_filepath) print("deleteSavedNet():File removed") else: print("deleteSavedNet():No file to remove")</span></span></code> </pre><br><br>  A maneira como criamos e exclu√≠mos redes neurais √© bastante simples e direta.  Primeiro exclua.  Ao chamar <i>delete</i> (somente), lembre-se de que o Notebook Jupiter possui uma fun√ß√£o de "sele√ß√£o de execu√ß√£o", selecione apenas o que deseja usar e execute-o. <br><br>  Em seguida, criamos uma rede neural se o arquivo n√£o existir, ou chamaremos o <i>carregamento,</i> se existir: √© claro, n√£o podemos chamar ‚Äúdelete‚Äù e esperar que o NN exista; portanto, para usar uma rede neural salva, n√£o chame <i>delete</i> . <br><br>  Em outras palavras, podemos criar um novo NN ou usar o existente, dependendo da situa√ß√£o e do que estamos experimentando atualmente.  Um cen√°rio simples: treinamos uma rede neural e depois sa√≠mos de f√©rias.  Eles retornaram e o Google acertou a sess√£o. Por isso, precisamos carregar a que foi salva anteriormente: comente ‚Äúdelete‚Äù e descomente ‚Äúload‚Äù. <br><br><pre> <code class="python hljs">deleteSavedNet(working_path + strModelFileName) <span class="hljs-comment"><span class="hljs-comment">#if not os.path.exists(working_path + "models"): # os.makedirs(working_path + "models") # #if not os.path.exists(working_path + # strModelFileName): # model = createModelResNet50() model = createModelInceptionV3() # model = createModelMobileNetV2() # model = createModelNASNetMobile() #else: # model = load_model(working_path + strModelFileName)</span></span></code> </pre><br><br>  <b>Os pontos de verifica√ß√£o</b> s√£o um elemento muito importante do nosso programa.  Podemos criar uma s√©rie de fun√ß√µes que devem ser chamadas no final de cada era do treinamento e pass√°-las ao ponto de verifica√ß√£o.  Por exemplo, voc√™ pode salvar uma rede neural <i>se</i> ela mostrar resultados melhores do que os que j√° foram salvos. <br><br><pre> <code class="python hljs">checkpoint = ModelCheckpoint(working_path + strModelFileName, monitor=<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, save_best_only=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, save_weights_only=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) callbacks_list = [ checkpoint ]</code> </pre><br><br>  Por fim, ensinamos a rede neural no conjunto de treinamento: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Calculate sizes of training and validation sets STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size STEP_SIZE_VALID=val_gen.n//val_gen.batch_size # Set to False if we are experimenting with # some other part of code, use history that # was calculated before (and is still in # memory bDoTraining = True if bDoTraining == True: # model.fit_generator does the actual training # Note the use of generators and callbacks # that were defined earlier history = model.fit_generator(generator=train_gen, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=val_gen, validation_steps=STEP_SIZE_VALID, epochs=EPOCHS, callbacks=callbacks_list) # --- After fitting, load the best model # This is important as otherwise we'll # have the LAST model loaded, not necessarily # the best one. model.load_weights(working_path + strModelFileName) # --- Presentation part # summarize history for accuracy plt.plot(history.history['acc']) plt.plot(history.history['val_acc']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['acc', 'val_acc'], loc='upper left') plt.show() # summarize history for loss plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss') plt.ylabel('loss') plt.xlabel('epoch') plt.legend(['loss', 'val_loss'], loc='upper left') plt.show() # As grid optimization of NN would take too long, # I did just few tests with different parameters. # Below I keep results, commented out, in the same # code. As you can see, Inception shows the best # results: # Inception: # adam: val_acc 0.79393 # sgd: val_acc 0.80892 # Mobile: # adam: val_acc 0.65290 # sgd: Epoch 00015: val_acc improved from 0.67584 to 0.68469 # sgd-30 epochs: 0.68 # NASNetMobile, adam: val_acc did not improve from 0.78335 # NASNetMobile, sgd: 0.8</span></span></code> </pre><br><br>  Os gr√°ficos de precis√£o e perda para a melhor das configura√ß√µes s√£o os seguintes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/97d/9cc/f0e97d9ccdc8f8ed9e44ddba02cf1f8d.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/612/e09/8b0/612e098b088979768d1cc66c2f6972bc.png"><br><br>  Como voc√™ pode ver, a rede neural est√° aprendendo e n√£o √© ruim. <br><br><h3>  Teste de rede neural </h3><br><br>  Ap√≥s a conclus√£o do treinamento, devemos testar o resultado;  por isso, NN apresenta fotos que ela nunca tinha visto antes - aquelas que copiamos na pasta de testes - uma para cada ra√ßa de c√£o. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># --- Test j = 0 # Final cycle performs testing on the entire # testing set. for file_name in os.listdir( working_path + "test/"): img = image.load_img(working_path + "test/" + file_name); img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. y_pred = model.predict_on_batch(img_1) # get 5 best predictions y_pred_ids = y_pred[0].argsort()[-5:][::-1] print(file_name) for i in range(len(y_pred_ids)): print("\n\t" + map_characters[y_pred_ids[i]] + " (" + str(y_pred[0][y_pred_ids[i]]) + ")") print("--------------------\n") j = j + 1</span></span></code> </pre><br><br><h3>  Exportar uma rede neural para um aplicativo Java </h3><br><br>  Primeiro de tudo, precisamos organizar o carregamento da rede neural a partir do disco.  O motivo √© claro: a exporta√ß√£o ocorre em outro bloco de c√≥digo; portanto, provavelmente iniciaremos a exporta√ß√£o separadamente - quando a rede neural for levada ao seu estado ideal.  Ou seja, imediatamente antes da exporta√ß√£o, na mesma execu√ß√£o do programa, n√£o treinaremos a rede.  Se voc√™ usar o c√≥digo mostrado aqui, n√£o haver√° diferen√ßa; a rede ideal foi selecionada para voc√™.  Mas se voc√™ aprender algo pr√≥prio, treinar tudo de novo antes de economizar √© uma perda de tempo, se antes voc√™ salvava tudo. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Test: load and run model = load_model(working_path + strModelFileName)</span></span></code> </pre><br><br>  Pelo mesmo motivo - para n√£o pular o c√≥digo - eu incluo os arquivos necess√°rios para a exporta√ß√£o aqui.  Ningu√©m o incomoda de mov√™-los para o in√≠cio do programa, se o seu senso de beleza exigir: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf</code> </pre><br><br>  Um pequeno teste ap√≥s o carregamento de uma rede neural, apenas para garantir que tudo esteja carregado - funciona: <br><br><pre> <code class="python hljs">img = image.load_img(working_path + <span class="hljs-string"><span class="hljs-string">"test/affenpinscher.jpg"</span></span>) <span class="hljs-comment"><span class="hljs-comment">#basset.jpg") img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. y_pred = model.predict(img_1) Y_pred_classes = np.argmax(y_pred,axis = 1) # print(y_pred) fig, ax = plt.subplots() ax.imshow(img) ax.axis('off') ax.set_title(map_characters[Y_pred_classes[0]]) plt.show()</span></span></code> </pre><br><br><img src="https://habrastorage.org/getpro/habr/post_images/05c/032/846/05c03284674e4337a2e5a3ba617634dd.png" alt="imagem"><br><br>  Em seguida, precisamos obter os nomes das camadas de entrada e sa√≠da da rede (esta ou a fun√ß√£o de cria√ß√£o, devemos "nomear" explicitamente as camadas, o que n√£o fizemos). <br><br><pre> <code class="python hljs">model.summary() &gt;&gt;&gt; Layer (type) &gt;&gt;&gt; ====================== &gt;&gt;&gt; input_7 (InputLayer) &gt;&gt;&gt; ______________________ &gt;&gt;&gt; conv2d_283 (Conv2D) &gt;&gt;&gt; ______________________ &gt;&gt;&gt; ... &gt;&gt;&gt; dense_14 (Dense) &gt;&gt;&gt; ====================== &gt;&gt;&gt; Total params: <span class="hljs-number"><span class="hljs-number">22</span></span>,<span class="hljs-number"><span class="hljs-number">913</span></span>,<span class="hljs-number"><span class="hljs-number">432</span></span> &gt;&gt;&gt; Trainable params: <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">110</span></span>,<span class="hljs-number"><span class="hljs-number">648</span></span> &gt;&gt;&gt; Non-trainable params: <span class="hljs-number"><span class="hljs-number">21</span></span>,<span class="hljs-number"><span class="hljs-number">802</span></span>,<span class="hljs-number"><span class="hljs-number">784</span></span></code> </pre><br><br>  Usaremos os nomes das camadas de entrada e sa√≠da posteriormente quando importarmos a rede neural para um aplicativo Java. <br><br>  Outro c√≥digo que circula na rede para obter esses dados: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_graph_nodes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> g = tf.GraphDef() g.ParseFromString(open(filename, <span class="hljs-string"><span class="hljs-string">'rb'</span></span>).read()) print() print(filename) print(<span class="hljs-string"><span class="hljs-string">"=======================INPUT==================="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'input'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"=======================OUTPUT=================="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'output'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"===================KERAS_LEARNING=============="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'keras_learning_phase'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"==============================================="</span></span>) print() <span class="hljs-comment"><span class="hljs-comment">#def get_script_path(): # return os.path.dirname(os.path.realpath(sys.argv[0]))</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mas eu n√£o gosto dele e n√£o o recomendo. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O c√≥digo a seguir exportar√° a Rede Neural Keras para o </font><font style="vertical-align: inherit;">formato </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pb</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , que capturaremos do Android.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">keras_to_tensorflow</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(keras_model, output_dir, model_name,out_prefix=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"output_"</span></span></span></span><span class="hljs-function"><span class="hljs-params">, log_tensorboard=True)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> os.path.exists(output_dir) == <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>: os.mkdir(output_dir) out_nodes = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(keras_model.outputs)): out_nodes.append(out_prefix + str(i + <span class="hljs-number"><span class="hljs-number">1</span></span>)) tf.identity(keras_model.output[i], out_prefix + str(i + <span class="hljs-number"><span class="hljs-number">1</span></span>)) sess = K.get_session() <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.framework <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> graph_util <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.framework graph_io init_graph = sess.graph.as_graph_def() main_graph = graph_util.convert_variables_to_constants( sess, init_graph, out_nodes) graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> log_tensorboard: <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.tools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> import_pb_to_tensorboard import_pb_to_tensorboard.import_to_tensorboard( os.path.join(output_dir, model_name), output_dir)</code> </pre><br><br><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Chamando estas fun√ß√µes para exportar uma rede neural: </font></font><br><br></p><pre> <code class="python hljs">model = load_model(working_path + strModelFileName) keras_to_tensorflow(model, output_dir=working_path + strModelFileName, model_name=working_path + <span class="hljs-string"><span class="hljs-string">"models/dogs.pb"</span></span>) print_graph_nodes(working_path + <span class="hljs-string"><span class="hljs-string">"models/dogs.pb"</span></span>)</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> A √∫ltima linha imprime a estrutura da rede neural resultante. </font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Criando um aplicativo Android usando uma rede neural </font></font></h2><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A exporta√ß√£o de redes neurais no Android √© bem formalizada e n√£o deve causar dificuldades. </font><font style="vertical-align: inherit;">Como sempre, existem v√°rias maneiras pelas quais usamos o mais popular (no momento da reda√ß√£o). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Primeiro, usamos o Android Studio para criar um novo projeto. </font><font style="vertical-align: inherit;">Vamos "cortar custos" porque nossa tarefa n√£o √© um tutorial para Android. </font><font style="vertical-align: inherit;">Portanto, o aplicativo conter√° apenas uma atividade. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b3/76e/997/6b376e997b34f45359c46923f6613d60.png" alt="imagem"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Como voc√™ pode ver, adicionamos a pasta ‚Äúassets‚Äù e copiamos nossa rede neural (a que exportamos anteriormente).</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Arquivo Gradle </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neste arquivo, voc√™ precisa fazer v√°rias altera√ß√µes. </font><font style="vertical-align: inherit;">Primeiro de tudo, precisamos importar a biblioteca </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tensorflow-android</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">√â usado para trabalhar com o Tensorflow (e, consequentemente, o Keras) do Java: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a16/091/fab/a16091fab2166f834827812611142d26.png" alt="imagem"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Outro obst√°culo n√£o √≥bvio: </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">versionCode</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">versionName</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Quando o aplicativo √© alterado, voc√™ precisa fazer o upload de novas vers√µes no Google Play. </font><font style="vertical-align: inherit;">Sem alterar as vers√µes no gdadle (por exemplo, 1 -&gt; 2 -&gt; 3 ...), voc√™ n√£o pode fazer isso, o Google emitir√° um erro "esta vers√£o j√° existe".</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Manifesto </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Antes de tudo, nosso aplicativo ser√° "pesado" - a Rede Neural de 100 Mb caber√° facilmente na mem√≥ria dos celulares modernos, mas abrir uma inst√¢ncia separada para cada foto "compartilhada" do Facebook √© definitivamente uma m√° id√©ia. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por isso, proibimos a cria√ß√£o de mais de uma inst√¢ncia do nosso aplicativo:</font></font><br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">activity</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">".MainActivity"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:launchMode</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"singleTask"</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ao adicionar </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">android: launchMode = "singleTask"</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> a MainActivity, pedimos ao Android para abrir (ativar) uma c√≥pia existente do aplicativo, em vez de criar outra inst√¢ncia. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em seguida, precisamos incluir nosso aplicativo na lista, que o sistema mostra quando algu√©m "compartilha" a imagem:</font></font><br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">intent-filter</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Send action required to display activity in share list --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">action</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.intent.action.SEND"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Make activity default to launch --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">category</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.intent.category.DEFAULT"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Mime type ie what can be shared with this activity only image and text --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">data</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:mimeType</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"image/*"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">intent-filter</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Por fim, precisamos solicitar recursos e permiss√µes que nosso aplicativo usar√°: </font></font><br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-feature</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.hardware.camera"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:required</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"true"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-permission</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">= </span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.permission.WRITE_EXTERNAL_STORAGE"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-permission</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.permission.READ_PHONE_STATE"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">tools:node</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"remove"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Se voc√™ est√° familiarizado com a programa√ß√£o para Android, esta parte n√£o deve causar perguntas. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aplicativo de layout. </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Criaremos dois layouts, um para retrato e outro para paisagem. </font><font style="vertical-align: inherit;">√â assim que o </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">layout do Portrait se</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> parece </font><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que adicionaremos: um campo grande (exibi√ß√£o) para mostrar a foto, uma lista irritante de an√∫ncios (mostrada quando o bot√£o com um osso √© pressionado), o bot√£o Ajuda, bot√µes para baixar uma foto do Arquivo / Galeria e capturar da c√¢mera e, finalmente, (inicialmente oculto) bot√£o "Processar" para processamento de imagem. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/f71/882/81f/f7188281ff581965c20c7e818cb0fd77.png" alt="imagem"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A atividade em si cont√©m toda a l√≥gica de mostrar e ocultar, al√©m de ativar / desativar os bot√µes, dependendo do estado do aplicativo.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mainatividade </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Esta atividade herda (estende) a atividade padr√£o do Android: </font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MainActivity</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Activity</span></span></span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Considere o c√≥digo respons√°vel pela opera√ß√£o da rede neural. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Primeiro de tudo, a rede neural aceita Bitmap. </font><font style="vertical-align: inherit;">Inicialmente, este √© um Bitmap grande (de tamanho arbitr√°rio) da c√¢mera ou de um arquivo (m_bitmap), depois o transformamos, levando aos pixels padr√£o de 256x256 (m_bitmapForNn). </font><font style="vertical-align: inherit;">Tamb√©m armazenamos o tamanho do bitmap (256) em uma constante:</font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Bitmap m_bitmap = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Bitmap m_bitmapForNn = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> m_nImageSize = <span class="hljs-number"><span class="hljs-number">256</span></span>;</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Devemos dizer √† rede neural os nomes das camadas de entrada e sa√≠da; </font><font style="vertical-align: inherit;">n√≥s os recebemos anteriormente (veja a listagem), mas lembre-se de que, no seu caso, eles podem ser diferentes:</font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String INPUT_NAME = <span class="hljs-string"><span class="hljs-string">"input_7_1"</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String OUTPUT_NAME = <span class="hljs-string"><span class="hljs-string">"output_1"</span></span>;</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em seguida, declaramos uma vari√°vel para armazenar o objeto TensofFlow. </font><font style="vertical-align: inherit;">Al√©m disso, armazenamos o caminho para o arquivo de rede neural (que se encontra nos ativos):</font></font><br><br><p></p><pre><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">private TensorFlowInferenceInterface tf;</font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
string privada MODEL_PATH = </font></font><font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
	"arquivo: ///android_asset/dogs.pb";</font></font><font></font>
</pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Armazenamos as ra√ßas de c√£es na lista, para que mais tarde elas sejam mostradas ao usu√°rio, e n√£o os √≠ndices da matriz: </font></font><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String[] m_arrBreedsArray;</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Inicialmente, baixamos o Bitmap. </font><font style="vertical-align: inherit;">No entanto, a rede neural espera uma matriz de valores RGB, e sua sa√≠da √© uma matriz de probabilidades de que essa ra√ßa seja o que √© mostrado na figura. </font><font style="vertical-align: inherit;">Portanto, precisamos adicionar mais duas matrizes (observe que 120 √© o n√∫mero de ra√ßas de c√£es presentes em nossos dados de treinamento):</font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[] m_arrPrediction = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[<span class="hljs-number"><span class="hljs-number">120</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[] m_arrInput = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>;</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Download da biblioteca de infer√™ncia tensorflow: </font></font><br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> { System.loadLibrary(<span class="hljs-string"><span class="hljs-string">"tensorflow_inference"</span></span>); }</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Como as opera√ß√µes da rede neural levam tempo, precisamos execut√°-las em um encadeamento separado; caso contr√°rio, existe a chance de recebermos uma mensagem do sistema "o aplicativo n√£o responde", sem mencionar um usu√°rio insatisfeito. </font></font><br><br><pre> <code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PredictionTask</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AsyncTask</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onPreExecute</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onPreExecute(); } <span class="hljs-comment"><span class="hljs-comment">// --- @Override protected Void doInBackground(Void... params) { try { # We get RGB values packed in integers # from the Bitmap, then break those # integers into individual triplets m_arrInput = new float[ m_nImageSize * m_nImageSize * 3]; int[] intValues = new int[ m_nImageSize * m_nImageSize]; m_bitmapForNn.getPixels(intValues, 0, m_nImageSize, 0, 0, m_nImageSize, m_nImageSize); for (int i = 0; i &lt; intValues.length; i++) { int val = intValues[i]; m_arrInput[i * 3 + 0] = ((val &gt;&gt; 16) &amp; 0xFF) / 255f; m_arrInput[i * 3 + 1] = ((val &gt;&gt; 8) &amp; 0xFF) / 255f; m_arrInput[i * 3 + 2] = (val &amp; 0xFF) / 255f; } // --- tf = new TensorFlowInferenceInterface( getAssets(), MODEL_PATH); //Pass input into the tensorflow tf.feed(INPUT_NAME, m_arrInput, 1, m_nImageSize, m_nImageSize, 3); //compute predictions tf.run(new String[]{OUTPUT_NAME}, false); //copy output into PREDICTIONS array tf.fetch(OUTPUT_NAME, m_arrPrediction); } catch (Exception e) { e.getMessage(); } return null; } // --- @Override protected void onPostExecute(Void result) { super.onPostExecute(result); // --- enableControls(true); // --- tf = null; m_arrInput = null; # strResult contains 5 lines of text # with most probable dog breeds and # their probabilities m_strResult = ""; # What we do below is sorting the array # by probabilities (using map) # and getting in reverse order) the # first five entries TreeMap&lt;Float, Integer&gt; map = new TreeMap&lt;Float, Integer&gt;( Collections.reverseOrder()); for(int i = 0; i &lt; m_arrPrediction.length; i++) map.put(m_arrPrediction[i], i); int i = 0; for (TreeMap.Entry&lt;Float, Integer&gt; pair : map.entrySet()) { float key = pair.getKey(); int idx = pair.getValue(); String strBreed = m_arrBreedsArray[idx]; m_strResult += strBreed + ": " + String.format("%.6f", key) + "\n"; i++; if (i &gt; 5) break; } m_txtViewBreed.setVisibility(View.VISIBLE); m_txtViewBreed.setText(m_strResult); } }</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> No onCreate () do MainActivity, precisamos adicionar o onClickListener para o bot√£o "Process": </font></font><br><br><pre> <code class="java hljs">m_btn_process.setOnClickListener(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> View.OnClickListener() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onClick</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(View v)</span></span></span><span class="hljs-function"> </span></span>{ processImage(); } });</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aqui processImage () chama apenas o segmento que descrevemos acima: </font></font><br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">processImage</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { enableControls(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); <span class="hljs-comment"><span class="hljs-comment">// --- PredictionTask prediction_task = new PredictionTask(); prediction_task.execute(); } catch (Exception e) { e.printStackTrace(); } }</span></span></code> </pre><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Notas adicionais </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N√£o planejamos discutir os detalhes da programa√ß√£o da interface do usu√°rio para Android, pois isso certamente n√£o se aplica √† tarefa de portar redes neurais. </font><font style="vertical-align: inherit;">No entanto, uma coisa ainda vale a pena mencionar. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quando impedimos a cria√ß√£o de inst√¢ncias adicionais de nosso aplicativo, tamb√©m quebramos a ordem normal de cria√ß√£o e exclus√£o de atividade (fluxo de controle): se voc√™ "compartilha" uma imagem do Facebook e depois compartilha outra, o aplicativo n√£o ser√° reiniciado. </font><font style="vertical-align: inherit;">Isso significa que a maneira ‚Äútradicional‚Äù de capturar dados transferidos no onCreate n√£o ser√° suficiente, pois o onCreate n√£o ser√° chamado. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Veja como resolver esse problema: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1. No onCreate em MainActivity, chame a fun√ß√£o onSharedIntent:</font></font><br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onCreate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( Bundle savedInstanceState)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onCreate(savedInstanceState); .... onSharedIntent(); ....</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Tamb√©m adicionamos um manipulador para onNewIntent: </font></font><br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onNewIntent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Intent intent)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onNewIntent(intent); setIntent(intent); onSharedIntent(); }</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aqui est√° a pr√≥pria fun√ß√£o onSharedIntent: </font></font><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onSharedIntent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Intent receivedIntent = getIntent(); String receivedAction = receivedIntent.getAction(); String receivedType = receivedIntent.getType(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (receivedAction.equals(Intent.ACTION_SEND)) { <span class="hljs-comment"><span class="hljs-comment">// If mime type is equal to image if (receivedType.startsWith("image/")) { m_txtViewBreed.setText(""); m_strResult = ""; Uri receivedUri = receivedIntent.getParcelableExtra( Intent.EXTRA_STREAM); if (receivedUri != null) { try { Bitmap bitmap = MediaStore.Images.Media.getBitmap( this.getContentResolver(), receivedUri); if(bitmap != null) { m_bitmap = bitmap; m_picView.setImageBitmap(m_bitmap); storeBitmap(); enableControls(true); } } catch (Exception e) { e.printStackTrace(); } } } } }</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Agora, processamos os dados transferidos no onCreate (se o aplicativo n√£o estava na mem√≥ria) ou no onNewIntent (se ele foi iniciado anteriormente). </font></font><br><br><br><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Boa sorte </font><font style="vertical-align: inherit;">Se voc√™ gostou do artigo, "gostei" de todas as formas poss√≠veis, tamb√©m existem bot√µes "sociais" no </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">site</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt448316/">https://habr.com/ru/post/pt448316/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt448300/index.html">Confer√™ncia mailto: CLOUD - sobre nuvens e arredores</a></li>
<li><a href="../pt448302/index.html">Vulnerabilidade nos filtros AdBlock e uBlock permite que c√≥digo arbitr√°rio seja executado no lado do usu√°rio</a></li>
<li><a href="../pt448304/index.html">O livro "Vue.js em a√ß√£o"</a></li>
<li><a href="../pt448308/index.html">Data Science Digest (abril de 2019)</a></li>
<li><a href="../pt448310/index.html">Escrevendo um bot de telegrama em python usando a parte 1 da biblioteca de telebot</a></li>
<li><a href="../pt448320/index.html">Por que sil√≠cio e por que CMOS?</a></li>
<li><a href="../pt448322/index.html">C ++ R√∫ssia 2019: transmiss√£o gratuita do primeiro sal√£o e um pouco sobre o que ser√° na confer√™ncia</a></li>
<li><a href="../pt448324/index.html">Criar globos planet√°rios procedimentais</a></li>
<li><a href="../pt448326/index.html">Ver atrav√©s. Como estudar assuntos sem quebr√°-los?</a></li>
<li><a href="../pt448328/index.html">Em Moscou, mostrar√° uma impressora que imprime √≥rg√£os e tecidos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéì üï¥üèº ‚ú°Ô∏è Aprendizado de m√°quina em alta velocidade: manuten√ß√£o preditiva de quatro meses üôåüèª ü§∏üèæ üí°</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Postado por Lyudmila Dezhkina, arquiteto de solu√ß√µes, DataArt 

 Por cerca de seis meses, nossa equipe trabalha na Plataforma de Manuten√ß√£o Preditiva ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aprendizado de m√°quina em alta velocidade: manuten√ß√£o preditiva de quatro meses</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataart/blog/453888/"><img src="https://habrastorage.org/webt/a5/ma/w3/a5maw3b31cc8lsqgqkdb5kbl-5w.jpeg"><br><br>  <i>Postado por Lyudmila Dezhkina, arquiteto de solu√ß√µes, DataArt</i> <br><br>  Por cerca de seis meses, nossa equipe trabalha na Plataforma de Manuten√ß√£o Preditiva - um sistema que deve prever poss√≠veis erros e falhas no equipamento.  Essa √°rea fica na interse√ß√£o da IoT e do Machine Learning, e voc√™ precisa trabalhar aqui com hardware e, de fato, com software.  Como criamos o ML sem servidor com a biblioteca Scikit-learn na AWS ser√° discutido neste artigo.  Vou falar sobre as dificuldades que encontramos e sobre as ferramentas que usei para economizar tempo. <a name="habracut"></a><br><br><div class="spoiler">  <b class="spoiler_title">Apenas no caso, um pouco sobre voc√™.</b> <div class="spoiler_text">  Trabalho com programa√ß√£o h√° mais de 12 anos e, durante esse per√≠odo, participei de v√°rios projetos.  Incluindo jogos, com√©rcio eletr√¥nico, carga alta e Big Data.  H√° cerca de tr√™s anos estou envolvido em projetos relacionados ao Machine Learning e Deep Learning. <br></div></div><br><img src="https://habrastorage.org/webt/v2/n9/ya/v2n9yaw20xe0knokse1jroameye.jpeg"><br><br>  <i>Parecia que os requisitos apresentados pelo cliente desde o in√≠cio</i> <br><br>  A entrevista com o cliente foi dif√≠cil, principalmente falamos sobre aprendizado de m√°quina, nos perguntaram muito sobre algoritmos e experi√™ncia pessoal espec√≠fica.  Mas n√£o serei modesto - nesta parte, inicialmente entendemos muito bem.  O primeiro obst√°culo foi o hardware que o sistema cont√©m.  No entanto, minha experi√™ncia com o ferro pessoalmente n√£o √© t√£o diversa. <br><br>  O cliente nos explicou: "Olha, n√≥s temos um transportador".  Eu imediatamente criei uma correia transportadora no caixa de um supermercado.  O que e o que pode ser ensinado l√°?  Mas rapidamente ficou claro que a palavra transportador oculta um centro de triagem com uma √°rea de 300 a 400 metros quadrados.  m, e de fato, existem muitos transportadores l√°.  Ou seja, muitos elementos do equipamento precisam ser conectados: sensores, rob√¥s.  Uma ilustra√ß√£o cl√°ssica do conceito de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"Revolu√ß√£o Industrial 4.0"</a> , na qual a IoT e a ML est√£o se unindo. <br><br>  O tema Manuten√ß√£o Preditiva certamente aumentar√° por pelo menos mais dois a tr√™s anos.  Cada transportador √© decomposto em elementos: de um rob√¥ ou motor que move uma correia transportadora para um rolamento separado.  Al√©m disso, se alguma dessas pe√ßas falhar, todo o sistema ser√° interrompido e, em alguns casos, uma hora de transportador inativo pode custar um milh√£o e meio de d√≥lares (isso n√£o √© um exagero!). <br><br>  Um de nossos clientes est√° envolvido no transporte e log√≠stica de cargas: em sua base, os rob√¥s descarregam 40 caminh√µes em 8 minutos.  N√£o pode haver atrasos aqui, os carros devem ir e vir de acordo com uma programa√ß√£o muito rigorosa, ningu√©m est√° consertando nada durante o processo de descarregamento.  Em geral, existem apenas duas ou tr√™s pessoas com comprimidos nesta base.  Mas h√° um mundo um pouco diferente, onde tudo n√£o parece t√£o elegante, e onde a mec√¢nica com luvas e sem computadores est√° diretamente sobre o objeto. <br><br>  Nosso primeiro pequeno projeto de prot√≥tipo consistiu em aproximadamente 90 sensores e tudo correu bem at√© que o projeto teve que ser dimensionado.  Para equipar a menor parte separada de um centro de classifica√ß√£o real, s√£o necess√°rios cerca de 550 sensores. <br><br><h2>  CLP e sensores </h2><br>  Controlador l√≥gico program√°vel - um pequeno computador com um programa c√≠clico embutido - costuma ser usado para automatizar o processo.  Na verdade, com a ajuda do PLC, fazemos leituras dos sensores: por exemplo, acelera√ß√£o e velocidade, n√≠vel de tens√£o, vibra√ß√£o ao longo dos eixos, temperatura (no nosso caso, 17 indicadores).  Os sensores geralmente s√£o confundidos.  Embora nosso projeto tenha mais de 8 meses, ainda temos nosso pr√≥prio laborat√≥rio, onde experimentamos sensores, selecionando os modelos mais adequados.  Agora, por exemplo, estamos considerando o uso de sensores ultrass√¥nicos. <br><br>  Pessoalmente, vi o PLC pela primeira vez, somente quando cheguei ao site do cliente.  Como desenvolvedor, eu nunca os encontrei antes, e isso foi bastante desagrad√°vel: assim que nos aprofundamos em mais de dois, tr√™s e quatro motores de uma conversa, comecei a perder a discuss√£o.  Cerca de 80% das palavras ainda eram intelig√≠veis, mas o significado geral teimosamente desapareceu.  Em geral, esse √© um problema s√©rio, cujas ra√≠zes est√£o em um limite bastante alto para a entrada na programa√ß√£o de CLP - um microcomputador onde voc√™ pode realmente fazer algo custa pelo menos US $ 200-300.  A programa√ß√£o em si n√£o √© complicada e os problemas come√ßam apenas quando o sensor est√° conectado a um transportador ou motor real. <br><br><img src="https://habrastorage.org/webt/rn/hh/p1/rnhhp1tzi_-qky6eszerqhvppyg.jpeg"><br><br>  <i>Conjunto de sensores padr√£o 37 em 1</i> <br><br>  Sensores, como voc√™ sabe, s√£o diferentes.  Os mais simples que conseguimos encontrar custam US $ 18.  A principal caracter√≠stica - ‚Äúlargura de banda e resolu√ß√£o‚Äù - quantos dados o sensor transmite em um minuto.  Pela minha pr√≥pria experi√™ncia, posso dizer que, se o fabricante reivindicar, digamos, 30 pontos de dados por minuto, na realidade √© improv√°vel que seu n√∫mero seja superior a 15. E isso tamb√©m representa um problema s√©rio: o t√≥pico est√° na moda e algumas empresas est√£o tentando ganhar dinheiro com esse hype.  Testamos sensores no valor de US $ 158, cuja largura de banda teoricamente tornou poss√≠vel simplesmente jogar fora parte do nosso c√≥digo.  Mas, na verdade, eles acabaram sendo um an√°logo absoluto desses mesmos dispositivos, com US $ 18 cada. <br><br><h2>  A primeira etapa: conectamos sensores, coletamos dados </h2><br>  Na verdade, a primeira fase do projeto foi a instala√ß√£o do hardware, a instala√ß√£o em si √© um processo longo e tedioso.  Isso tamb√©m √© uma ci√™ncia inteira - os dados que ele coleta podem depender de como voc√™ conecta o sensor a um motor ou caixa.  Tivemos um caso em que um dos dois sensores id√™nticos foi conectado dentro da caixa e o outro fora.  A l√≥gica sugere que a temperatura interna deve ser mais alta, mas os dados coletados indicam o contr√°rio.  Aconteceu que o sistema falhou, mas quando o desenvolvedor chegou √† f√°brica, ele viu que o sensor n√£o estava apenas na caixa, mas diretamente no ventilador localizado l√°. <br><br><img src="https://habrastorage.org/webt/r-/qr/3g/r-qr3gto5oa6lxqmvrkyw3fz_ny.jpeg"><br><br>  Esta ilustra√ß√£o mostra como os primeiros dados entraram no sistema.  Temos um gateway, existem PLC e sensores associados a ele.  Al√©m disso, √© claro, o cache - o equipamento geralmente roda em cart√µes m√≥veis e todos os dados s√£o transmitidos via Internet m√≥vel.  Como um dos centros de classifica√ß√£o do cliente est√° localizado em uma √°rea onde geralmente h√° furac√µes e a conex√£o pode ser interrompida, acumulamos dados no gateway at√© que ele seja restaurado. <br><br>  Em seguida, usamos o servi√ßo Greengrass da Amazon, que envia dados dentro do sistema de nuvem (AWS). <br><br>  Assim que os dados est√£o dentro da nuvem, v√°rios eventos s√£o acionados.  Por exemplo, temos um evento para dados brutos que salva os dados do sistema de arquivos.  H√° um "batimento card√≠aco" para indicar o desempenho normal do sistema.  H√° uma "redu√ß√£o de amostra", usada para exibi√ß√£o na interface do usu√°rio e para processamento (o valor m√©dio, por exemplo, por minuto para um determinado indicador) √© obtido.  Ou seja, al√©m dos dados brutos, temos dados de amostragem reduzida que caem nas telas dos usu√°rios que monitoram o sistema. <br><br>  Os dados brutos s√£o armazenados em formato parquet.  No in√≠cio, escolhemos o JSON, depois experimentamos o CSV, mas no final chegamos √† conclus√£o de que a equipe de an√°lise e a equipe de desenvolvimento est√£o satisfeitas com o "parquet". <br><br>  Na verdade, a primeira vers√£o do sistema foi criada no DynamoDB e n√£o quero dizer nada de ruim sobre esse banco de dados.  S√≥ que, assim que obtivemos an√°lises - matem√°ticos que deveriam trabalhar com os dados obtidos -, a linguagem de consulta no DynamoDB ficou muito complicada para eles.  Eles tiveram que preparar dados especialmente para ML e an√°lises.  Portanto, decidimos pelo Athena, o editor de consultas da AWS.  Para n√≥s, suas vantagens s√£o que ele permite ler dados do Parquet, escrever SQL e coletar os resultados em um arquivo CSV.  Apenas o que a equipe de an√°lise precisa. <br><br><h2>  Segunda etapa: o que analisamos? </h2><br>  Assim, a partir de um pequeno objeto, coletamos cerca de 3 GB de dados brutos.  Agora sabemos muito sobre temperatura, vibra√ß√£o e acelera√ß√£o axial.  Portanto, √© hora de nossos matem√°ticos se reunirem para entender como e, de fato, o que estamos tentando prever com base nessas informa√ß√µes. <br><br>  <i>O objetivo √© minimizar o tempo de inatividade do equipamento.</i> <br><br><img src="https://habrastorage.org/webt/x0/5j/t3/x05jt3aaezuzpdwok7l-wtuqf4g.jpeg"><br><br>  <i>As pessoas entram nesta f√°brica de Coca-Cola apenas quando recebem um sinal de avaria, vazamento de √≥leo ou, digamos, uma po√ßa no ch√£o.</i>  <i>O custo de um rob√¥ come√ßa com US $ 30.000, mas quase toda a produ√ß√£o √© constru√≠da sobre eles</i> <br><br><img src="https://habrastorage.org/webt/zf/st/co/zfstcoyb2v_0ei4hqi7lh3kd3uu.jpeg"><br><br>  <i>Cerca de 10.000 pessoas trabalham em seis f√°bricas de Tesla e, para a produ√ß√£o dessa escala, isso √© muito pouco.</i>  <i>Curiosamente, as f√°bricas da Mercedes s√£o ainda mais automatizadas.</i>  <i>√â claro que todos os rob√¥s envolvidos precisam de monitoramento constante</i> <br><br>  Quanto mais caro o rob√¥, menos sua parte de trabalho vibra.  Com a√ß√µes simples, isso pode n√£o ser decisivo, mas opera√ß√µes mais sutis, digamos com o gargalo da garrafa, exigem que ela seja minimizada.  Obviamente, o n√≠vel de vibra√ß√£o de carros caros deve ser constantemente monitorado. <br><br><h2>  Servi√ßos que economizam tempo </h2><br>  Lan√ßamos a primeira instala√ß√£o em pouco mais de tr√™s meses e acho r√°pida. <br><br><img src="https://habrastorage.org/webt/dl/ca/6l/dlca6lwxu8db9a8urijocy9p1io.jpeg"><br><br>  <i>Na verdade, esses s√£o os cinco principais pontos que permitiram economizar esfor√ßos de desenvolvimento</i> <br><br>  A primeira coisa que reduzimos o cronograma √© que a maior parte do sistema √© constru√≠da na AWS, que √© dimensionada por si s√≥.  Assim que o n√∫mero de usu√°rios exceder um determinado limite, o dimensionamento autom√°tico √© acionado e nenhuma equipe precisa gastar tempo com isso. <br><br>  Gostaria de chamar a aten√ß√£o para duas nuances.  Primeiro, trabalhamos com grandes volumes de dados e, na primeira vers√£o do sistema, t√≠nhamos pipelines para fazer backups.  Depois de algum tempo, os dados se tornaram demais e a manuten√ß√£o de c√≥pias para eles se tornou muito cara.  Em seguida, deixamos os dados brutos no intervalo somente leitura, proibindo a exclus√£o deles e recusamos os backups. <br><br>  Nosso sistema envolve integra√ß√£o cont√≠nua, para oferecer suporte a um novo site e uma nova instala√ß√£o n√£o leva muito tempo. <br><br>  √â claro que o tempo real se baseia em eventos.  Embora, √© claro, surjam dificuldades devido ao fato de alguns eventos funcionarem duas vezes ou o sistema perder contato, por exemplo, devido √†s condi√ß√µes clim√°ticas. <br><br>  A criptografia de dados, conforme exigido pelo cliente, √© feita automaticamente na AWS.  Cada cliente tem seu pr√≥prio bucket e n√£o fazemos o que criptografamos. <br><br><h2>  Encontro com analistas </h2><br>  Recebemos o primeiro c√≥digo em formato PDF, juntamente com uma solicita√ß√£o para implementar um ou outro modelo.  At√© come√ßarmos a receber o c√≥digo na forma de .ipynb, era alarmante, mas o fato √© que os analistas s√£o matem√°ticos que est√£o longe de programar.  Todas as nossas opera√ß√µes ocorrem na nuvem, n√£o permitimos o download de dados.  Juntos, todos esses pontos nos levaram a experimentar a plataforma SageMaker. <br><br>  O SageMaker permite que voc√™ use cerca de 80 algoritmos prontos para uso, incluindo estruturas: Caffe2, Mxnet, Gluon, TensorFlow, Pytorch, kit de ferramentas cognitivas da Microsoft.  No momento, usamos o Keras + TensorFlow, mas todos, exceto o kit de ferramentas cognitivas da Microsoft, tentaram.  Uma cobertura t√£o ampla nos permite n√£o limitar nossa pr√≥pria equipe anal√≠tica. <br><br><img src="https://habrastorage.org/webt/ja/pd/is/japdisyszpehfqtquzcmlyl5sru.jpeg"><br><br>  Nos primeiros tr√™s a quatro meses, as pessoas fizeram todo o trabalho com a ajuda da matem√°tica simples, realmente n√£o havia ML.  Parte do sistema √© baseada em leis puramente matem√°ticas e foi projetada para dados estat√≠sticos.  Ou seja, monitoramos o n√≠vel m√©dio de temperatura e, se percebermos que est√° fora de escala, os alertas s√£o acionados. <br><br>  Em seguida, segue o treinamento do modelo.  Tudo parece f√°cil e simples e, portanto, parece antes do in√≠cio da implementa√ß√£o. <br><br><h3>  Construir, treinar, implantar ... </h3><br><img src="https://habrastorage.org/webt/d4/ol/db/d4oldbfr8ks7xilugkd92hhbqge.png"><br><br>  Descreverei brevemente como sa√≠mos da situa√ß√£o.  Veja a segunda coluna: coletamos dados, processamos, limpamos, usamos bucket S3 e Glue para iniciar eventos e criar "parti√ß√µes".  Temos todos os dados organizados em parti√ß√µes para o Athena, essa tamb√©m √© uma nuance importante, porque o Athena √© constru√≠do sobre o S3.  Athena em si √© muito barato.  Mas pagamos pela leitura dos dados e pela sa√≠da do S3, pois cada solicita√ß√£o pode ser muito cara.  Portanto, temos um grande sistema de parti√ß√µes. <br><br>  Temos um downtimer.  E o Amazon EMR, que permite coletar dados rapidamente.  Na verdade, para a engenharia de recursos, em nossa nuvem, para cada analista, um Notebook Jupyter foi criado - essa √© a inst√¢ncia deles.  E eles analisam tudo diretamente na pr√≥pria nuvem. <br><br>  Gra√ßas ao SageMaker, conseguimos pular a fase Clusters de treinamento.  Se n√£o us√°ssemos essa plataforma, ter√≠amos que criar clusters na Amazon e um dos engenheiros do DevOps teria que segui-los.  O SageMaker permite usar os par√¢metros do m√©todo, a imagem no Docker para aumentar o cluster, resta apenas indicar o n√∫mero de inst√¢ncias no par√¢metro que voc√™ deseja usar. <br><br>  Al√©m disso, n√£o precisamos lidar com o dimensionamento.  Se queremos processar algum tipo de algoritmo grande ou se precisamos calcular algo com urg√™ncia, ativamos o escalonamento autom√°tico (tudo depende se voc√™ deseja usar uma CPU ou GPU). <br><br>  Al√©m disso, todos os nossos modelos s√£o criptografados: isso tamb√©m sai da caixa no SageMaker - os bin√°rios que est√£o no S3. <br><br><h3>  Implanta√ß√£o do modelo </h3><br>  Estamos nos aproximando do primeiro modelo implantado em um ambiente.  Na verdade, o SageMaker permite salvar artefatos de modelo, mas nesse est√°gio tivemos muita controv√©rsia, porque o SageMaker possui seu pr√≥prio formato de modelo.  Quer√≠amos nos afastar, nos livrando das restri√ß√µes, para que nossos modelos sejam armazenados em formato de picles, para que pud√©ssemos usar at√© o Keras, at√© o TensorFlow ou qualquer outra coisa, se desejado.  Embora tenhamos usado o primeiro modelo do SageMaker, como ele √©, por meio da API nativa. <br><br>  O SageMaker permite simplificar o trabalho em tr√™s etapas.  Toda vez que voc√™ tenta prever algo, precisa iniciar um determinado processo, fornecer dados e obter valores de previs√£o.  Tudo correu bem at√© que algoritmos personalizados foram necess√°rios. <br><br><img src="https://habrastorage.org/webt/k_/an/8t/k_an8tdryy5zy84x7q5jhdx9trk.jpeg"><br><br>  Os analistas sabem que possuem um IC e um reposit√≥rio.  H√° uma pasta no reposit√≥rio do IC em que eles devem colocar tr√™s arquivos.  Serve.py √© um arquivo que permite ao SageMaker aumentar o servi√ßo Flask e se comunicar com o pr√≥prio SageMaker.  Train.py √© uma classe com o m√©todo train, na qual eles devem colocar tudo o que √© necess√°rio para o modelo.  Finalmente, predict.py - com sua ajuda, eles aumentam essa classe, dentro da qual existe um m√©todo.  Tendo acesso, eles levantam todos os tipos de recursos do S3 a partir da√≠ - no SageMaker, temos uma imagem que permite executar qualquer coisa a partir da interface e programaticamente (n√£o os limitamos). <br><br>  No SageMaker, obtemos acesso a predict.py - a imagem interna √© apenas um aplicativo Flask que permite ligar para prever ou treinar com determinados par√¢metros.  Tudo isso est√° ligado ao S3 e, al√©m disso, eles t√™m a capacidade de salvar modelos do Notebook Jupyter.  Ou seja, no Jupyter Notebook, os analistas t√™m acesso a todos os dados e podem fazer algum tipo de experimenta√ß√£o. <br><br>  Na produ√ß√£o, tudo isso cai da seguinte maneira.  Temos usu√°rios, existem valores-limite previstos.  Os dados est√£o no S3 e v√£o para o Athena.  A cada duas horas, √© lan√ßado um algoritmo que calcula uma previs√£o para as pr√≥ximas duas horas.  Essa etapa do tempo se deve ao fato de que, no nosso caso, cerca de 6 horas de an√°lise s√£o suficientes para dizer que algo est√° errado com o motor.  Mesmo no momento da liga√ß√£o, o motor aquece de 5 a 10 minutos e n√£o ocorrem saltos agudos. <br><br>  Em sistemas cr√≠ticos, digamos, quando a Air France verifica turbinas de aeronaves, a previs√£o √© feita na taxa de 10 minutos.  Nesse caso, a precis√£o √© de 96,5%. <br><br>  Se percebermos que algo est√° errado, o sistema de notifica√ß√£o ser√° ativado.  Em seguida, um dos muitos usu√°rios em um rel√≥gio ou outro dispositivo recebe uma notifica√ß√£o de que um determinado motor est√° se comportando de maneira anormal.  Ele vai e verifica sua condi√ß√£o. <br><br><h3>  Gerenciar inst√¢ncias do notebook </h3><br><img src="https://habrastorage.org/webt/ue/l4/kz/uel4kzfs0p98y9urjewk2d6kk9o.jpeg"><br><br>  De fato, tudo √© muito simples.  Chegando ao trabalho, o analista lan√ßa uma inst√¢ncia no Jupyter Notebook.  Ele recebe a fun√ß√£o e a sess√£o, ent√£o duas pessoas n√£o podem editar o mesmo arquivo.  Na verdade, agora temos uma inst√¢ncia para cada analista. <br><br><h3>  Criar trabalho de treinamento </h3><br>  O SageMaker entende os trabalhos de treinamento.  Seu resultado, se voc√™ usar apenas uma API - um bin√°rio armazenado no S3: a partir dos par√¢metros fornecidos, seu modelo ser√° obtido. <br><br><pre><code class="python hljs">sagemaker = boto3.client(<span class="hljs-string"><span class="hljs-string">'sagemaker'</span></span>) sagemaker.create_training_job(**create_training_params) status = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'TrainingJobStatus'</span></span>] print(status) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: sagemaker.get_waiter(<span class="hljs-string"><span class="hljs-string">'training_job_completed_or_stopped'</span></span>).wait(TrainingJobName=job_name) <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span>: status = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'TrainingJobStatus'</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Training job ended with status: "</span></span> + status) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> status == <span class="hljs-string"><span class="hljs-string">'Failed'</span></span>: message = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'FailureReason'</span></span>] print(<span class="hljs-string"><span class="hljs-string">'Training failed with the following error: {}'</span></span>.format(message)) <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> Exception(<span class="hljs-string"><span class="hljs-string">'Training job failed'</span></span>)</code> </pre> <br><h3>  Exemplo de Par√¢metros de Treinamento </h3><br><pre> <code class="python hljs">{ <span class="hljs-string"><span class="hljs-string">"AlgorithmSpecification"</span></span>: { <span class="hljs-string"><span class="hljs-string">"TrainingImage"</span></span>: image, <span class="hljs-string"><span class="hljs-string">"TrainingInputMode"</span></span>: <span class="hljs-string"><span class="hljs-string">"File"</span></span> }, <span class="hljs-string"><span class="hljs-string">"RoleArn"</span></span>: role, <span class="hljs-string"><span class="hljs-string">"OutputDataConfig"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3OutputPath"</span></span>: output_location }, <span class="hljs-string"><span class="hljs-string">"ResourceConfig"</span></span>: { <span class="hljs-string"><span class="hljs-string">"InstanceCount"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"InstanceType"</span></span>: <span class="hljs-string"><span class="hljs-string">"ml.c4.8xlarge"</span></span>, <span class="hljs-string"><span class="hljs-string">"VolumeSizeInGB"</span></span>: <span class="hljs-number"><span class="hljs-number">50</span></span> }, <span class="hljs-string"><span class="hljs-string">"TrainingJobName"</span></span>: job_name, <span class="hljs-string"><span class="hljs-string">"HyperParameters"</span></span>: { <span class="hljs-string"><span class="hljs-string">"k"</span></span>: <span class="hljs-string"><span class="hljs-string">"10"</span></span>, <span class="hljs-string"><span class="hljs-string">"feature_dim"</span></span>: <span class="hljs-string"><span class="hljs-string">"784"</span></span>, <span class="hljs-string"><span class="hljs-string">"mini_batch_size"</span></span>: <span class="hljs-string"><span class="hljs-string">"500"</span></span>, <span class="hljs-string"><span class="hljs-string">"force_dense"</span></span>: <span class="hljs-string"><span class="hljs-string">"True"</span></span> }, <span class="hljs-string"><span class="hljs-string">"StoppingCondition"</span></span>: { <span class="hljs-string"><span class="hljs-string">"MaxRuntimeInSeconds"</span></span>: <span class="hljs-number"><span class="hljs-number">60</span></span> * <span class="hljs-number"><span class="hljs-number">60</span></span> }, <span class="hljs-string"><span class="hljs-string">"InputDataConfig"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"ChannelName"</span></span>: <span class="hljs-string"><span class="hljs-string">"train"</span></span>, <span class="hljs-string"><span class="hljs-string">"DataSource"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3DataSource"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3DataType"</span></span>: <span class="hljs-string"><span class="hljs-string">"S3Prefix"</span></span>, <span class="hljs-string"><span class="hljs-string">"S3Uri"</span></span>: data_location, <span class="hljs-string"><span class="hljs-string">"S3DataDistributionType"</span></span>: <span class="hljs-string"><span class="hljs-string">"FullyReplicated"</span></span> } }, <span class="hljs-string"><span class="hljs-string">"CompressionType"</span></span>: <span class="hljs-string"><span class="hljs-string">"None"</span></span>, <span class="hljs-string"><span class="hljs-string">"RecordWrapperType"</span></span>: <span class="hljs-string"><span class="hljs-string">"None"</span></span> } ] }</code> </pre> <br>  <b>Par√¢metros</b>  A primeira √© a fun√ß√£o: voc√™ deve indicar a que sua inst√¢ncia do SageMaker tem acesso.  Ou seja, no nosso caso, se o analista trabalha com duas produ√ß√µes diferentes, ele deve ver um balde e n√£o o outro.  A configura√ß√£o de sa√≠da √© onde voc√™ salva todos os metadados do modelo. <br><br>  Ignoramos a escala autom√°tica e podemos simplesmente especificar o n√∫mero de inst√¢ncias nas quais voc√™ deseja executar este trabalho de treinamento.  Inicialmente, geralmente usamos inst√¢ncias intermedi√°rias sem TensorFlow ou Keras, e isso foi suficiente. <br><br>  <b>Hiperpar√¢metros</b>  Voc√™ especifica a imagem do Docker na qual deseja iniciar.  Como regra, a Amazon fornece uma lista de algoritmos e suas imagens, ou seja, voc√™ deve especificar hiperpar√¢metros - os par√¢metros do pr√≥prio algoritmo. <br><br><h3>  Criar modelo </h3><br><pre> <code class="python hljs">%%time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> boto3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gmtime, strftime job_name = <span class="hljs-string"><span class="hljs-string">'kmeans-lowlevel-'</span></span> + strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d-%H-%M-%S"</span></span>, gmtime()) print(<span class="hljs-string"><span class="hljs-string">"Training job"</span></span>, job_name) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sagemaker.amazon.amazon_estimator <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> get_image_uri image = get_image_uri(boto3.Session().region_name, <span class="hljs-string"><span class="hljs-string">'kmeans'</span></span>) output_location = <span class="hljs-string"><span class="hljs-string">'s3://{}/kmeans_example/output'</span></span>.format(bucket) print(<span class="hljs-string"><span class="hljs-string">'training artifacts will be uploaded to: {}'</span></span>.format(output_location)) create_training_params = \ { <span class="hljs-string"><span class="hljs-string">"AlgorithmSpecification"</span></span>: { <span class="hljs-string"><span class="hljs-string">"TrainingImage"</span></span>: image, <span class="hljs-string"><span class="hljs-string">"TrainingInputMode"</span></span>: <span class="hljs-string"><span class="hljs-string">"File"</span></span> }, <span class="hljs-string"><span class="hljs-string">"RoleArn"</span></span>: role, <span class="hljs-string"><span class="hljs-string">"OutputDataConfig"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3OutputPath"</span></span>: output_location }, <span class="hljs-string"><span class="hljs-string">"ResourceConfig"</span></span>: { <span class="hljs-string"><span class="hljs-string">"InstanceCount"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"InstanceType"</span></span>: <span class="hljs-string"><span class="hljs-string">"ml.c4.8xlarge"</span></span>, <span class="hljs-string"><span class="hljs-string">"VolumeSizeInGB"</span></span>: <span class="hljs-number"><span class="hljs-number">50</span></span> }, <span class="hljs-string"><span class="hljs-string">"TrainingJobName"</span></span>: job_name, <span class="hljs-string"><span class="hljs-string">"HyperParameters"</span></span>: { <span class="hljs-string"><span class="hljs-string">"k"</span></span>: <span class="hljs-string"><span class="hljs-string">"10"</span></span>, <span class="hljs-string"><span class="hljs-string">"feature_dim"</span></span>: <span class="hljs-string"><span class="hljs-string">"784"</span></span>, <span class="hljs-string"><span class="hljs-string">"mini_batch_size"</span></span>: <span class="hljs-string"><span class="hljs-string">"500"</span></span>, <span class="hljs-string"><span class="hljs-string">"force_dense"</span></span>: <span class="hljs-string"><span class="hljs-string">"True"</span></span> }, <span class="hljs-string"><span class="hljs-string">"StoppingCondition"</span></span>: { <span class="hljs-string"><span class="hljs-string">"MaxRuntimeInSeconds"</span></span>: <span class="hljs-number"><span class="hljs-number">60</span></span> * <span class="hljs-number"><span class="hljs-number">60</span></span> }, <span class="hljs-string"><span class="hljs-string">"InputDataConfig"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"ChannelName"</span></span>: <span class="hljs-string"><span class="hljs-string">"train"</span></span>, <span class="hljs-string"><span class="hljs-string">"DataSource"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3DataSource"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3DataType"</span></span>: <span class="hljs-string"><span class="hljs-string">"S3Prefix"</span></span>, <span class="hljs-string"><span class="hljs-string">"S3Uri"</span></span>: data_location, <span class="hljs-string"><span class="hljs-string">"S3DataDistributionType"</span></span>: <span class="hljs-string"><span class="hljs-string">"FullyReplicated"</span></span> } }, <span class="hljs-string"><span class="hljs-string">"CompressionType"</span></span>: <span class="hljs-string"><span class="hljs-string">"None"</span></span>, <span class="hljs-string"><span class="hljs-string">"RecordWrapperType"</span></span>: <span class="hljs-string"><span class="hljs-string">"None"</span></span> } ] } sagemaker = boto3.client(<span class="hljs-string"><span class="hljs-string">'sagemaker'</span></span>) sagemaker.create_training_job(**create_training_params) status = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'TrainingJobStatus'</span></span>] print(status) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: sagemaker.get_waiter(<span class="hljs-string"><span class="hljs-string">'training_job_completed_or_stopped'</span></span>).wait(TrainingJobName=job_name) <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span>: status = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'TrainingJobStatus'</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Training job ended with status: "</span></span> + status) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> status == <span class="hljs-string"><span class="hljs-string">'Failed'</span></span>: message = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'FailureReason'</span></span>] print(<span class="hljs-string"><span class="hljs-string">'Training failed with the following error: {}'</span></span>.format(message)) <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> Exception(<span class="hljs-string"><span class="hljs-string">'Training job failed'</span></span>) %%time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> boto3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gmtime, strftime model_name=job_name print(model_name) info = sagemaker.describe_training_job(TrainingJobName=job_name) model_data = info[<span class="hljs-string"><span class="hljs-string">'ModelArtifacts'</span></span>][<span class="hljs-string"><span class="hljs-string">'S3ModelArtifacts'</span></span>] print(info[<span class="hljs-string"><span class="hljs-string">'ModelArtifacts'</span></span>]) primary_container = { <span class="hljs-string"><span class="hljs-string">'Image'</span></span>: image, <span class="hljs-string"><span class="hljs-string">'ModelDataUrl'</span></span>: model_data } create_model_response = sagemaker.create_model( ModelName = model_name, ExecutionRoleArn = role, PrimaryContainer = primary_container) print(create_model_response[<span class="hljs-string"><span class="hljs-string">'ModelArn'</span></span>])</code> </pre><br>  Criar um modelo √© o resultado de um trabalho de treinamento.  Depois que o √∫ltimo √© conclu√≠do, e quando voc√™ o monitora, ele √© salvo no S3 e voc√™ pode us√°-lo. <br><br><img src="https://habrastorage.org/webt/5e/w7/1g/5ew71gojdaow2t1mriz0qfuifmi.jpeg"><br><br>  √â assim que parece do ponto de vista dos analistas.  Nossos analistas v√£o aos modelos e dizem: nesta imagem, quero lan√ßar esse modelo.  Eles simplesmente apontam para a pasta S3, Imagem e inserem os par√¢metros na interface gr√°fica.  Como existem nuances e dificuldades, passamos a algoritmos personalizados. <br><br><h3>  Criar ponto final </h3><br><pre> <code class="python hljs">%%time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time endpoint_name = <span class="hljs-string"><span class="hljs-string">'KMeansEndpoint-'</span></span> + strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d-%H-%M-%S"</span></span>, gmtime()) print(endpoint_name) create_endpoint_response = sagemaker.create_endpoint( EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name) print(create_endpoint_response[<span class="hljs-string"><span class="hljs-string">'EndpointArn'</span></span>]) resp = sagemaker.describe_endpoint(EndpointName=endpoint_name) status = resp[<span class="hljs-string"><span class="hljs-string">'EndpointStatus'</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Status: "</span></span> + status) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: sagemaker.get_waiter(<span class="hljs-string"><span class="hljs-string">'endpoint_in_service'</span></span>).wait(EndpointName=endpoint_name) <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span>: resp = sagemaker.describe_endpoint(EndpointName=endpoint_name) status = resp[<span class="hljs-string"><span class="hljs-string">'EndpointStatus'</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Arn: "</span></span> + resp[<span class="hljs-string"><span class="hljs-string">'EndpointArn'</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"Create endpoint ended with status: "</span></span> + status) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> status != <span class="hljs-string"><span class="hljs-string">'InService'</span></span>: message = sagemaker.describe_endpoint(EndpointName=endpoint_name)[<span class="hljs-string"><span class="hljs-string">'FailureReason'</span></span>] print(<span class="hljs-string"><span class="hljs-string">'Training failed with the following error: {}'</span></span>.format(message)) <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> Exception(<span class="hljs-string"><span class="hljs-string">'Endpoint creation did not succeed'</span></span>)</code> </pre> <br>  √â necess√°rio muito c√≥digo para criar um Endpoint que se contrai de qualquer lambda e de fora.  A cada duas horas, √© acionado um evento que puxa o Endpoint. <br><br><h3>  Visualiza√ß√£o de ponto final </h3><br><img src="https://habrastorage.org/webt/tw/_n/rf/tw_nrfder3poxjeli61cpr8jtle.jpeg"><br><br>  √â assim que os analistas veem.  Eles simplesmente indicam o algoritmo, o tempo e o puxam com as m√£os da interface. <br><br><h3>  Chamar ponto final </h3><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json payload = np2csv(train_set[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">30</span></span>:<span class="hljs-number"><span class="hljs-number">31</span></span>]) response = runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType=<span class="hljs-string"><span class="hljs-string">'text/csv'</span></span>, Body=payload) result = json.loads(response[<span class="hljs-string"><span class="hljs-string">'Body'</span></span>].read().decode()) print(result)</code> </pre><br>  E √© assim que √© feito a partir de lambda.  Ou seja, temos um endpoint interno e a cada duas horas enviamos uma carga √∫til para fazer uma previs√£o. <br><br><h3>  Links √∫teis para o SageMaker: links do github </h3><br>  Esses s√£o links muito importantes.  Honestamente, depois que come√ßamos a usar a GUI habitual do Sagemaker, todos entenderam que mais cedo ou mais tarde chegar√≠amos a um algoritmo personalizado, e tudo isso seria montado manualmente.  Usando esses links, voc√™ pode encontrar n√£o apenas o uso de algoritmos, mas tamb√©m a montagem de imagens personalizadas: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/awslabs/amazon-sagemaker-examples</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/aws-samples/aws-ml-vision-end2end</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/juliensimon</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/aws/sagemaker-spark</a> <br><br><h2>  O que vem a seguir? </h2><br>  Abordamos a quarta produ√ß√£o e agora, al√©m da an√°lise, temos dois caminhos de desenvolvimento.  Primeiramente, estamos tentando obter logs da mec√¢nica, ou seja, estamos tentando come√ßar o treinamento com suporte.  Os primeiros registros de Mantainence que recebemos s√£o assim: algo quebrou na segunda-feira, cheguei l√° na quarta-feira e comecei a consert√°-lo na sexta-feira.  Agora, estamos tentando fornecer ao cliente o CMS - um sistema de gerenciamento de conte√∫do que permitir√° o registro de eventos de falha. <br><br>  Como isso √© feito?  Como regra, assim que ocorre um colapso, o mec√¢nico chega e muda a pe√ßa muito rapidamente, mas ele pode preencher todos os tipos de formul√°rios em papel, digamos, em uma semana.  A essa altura, a pessoa simplesmente esquece o que exatamente aconteceu com a parte.  O CMS, √© claro, nos leva a um novo n√≠vel de intera√ß√£o com a mec√¢nica. <br><br>  Em segundo lugar, vamos instalar sensores ultrass√¥nicos nos motores que l√™em som e est√£o envolvidos na an√°lise espectral. <br><br>  √â poss√≠vel que abandonemos o Athena, porque em big data, o uso do S3 √© caro.  Ao mesmo tempo, a Microsoft anunciou recentemente seus pr√≥prios servi√ßos, e um de nossos clientes quer tentar fazer a mesma coisa no Azure.  Na verdade, uma das vantagens do nosso sistema √© que ele pode ser desmontado e montado em outro local, como cubos. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt453888/">https://habr.com/ru/post/pt453888/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt453874/index.html">Da roleta russa ao LOTO seguro: como proteger o pessoal do data center</a></li>
<li><a href="../pt453876/index.html">Como no Yandex.Practicum, o front-end desync venceu: um n√∫mero acrob√°tico com Redux-Saga, postMessage e Jupyter</a></li>
<li><a href="../pt453882/index.html">Um √≥timo guia sobre a profiss√£o de arquiteto de solu√ß√µes (+ lista de links √∫teis)</a></li>
<li><a href="../pt453884/index.html">Substitui√ß√£o da c√¢mera HYIP ou DSLR?</a></li>
<li><a href="../pt453886/index.html">Trabalhos do programa</a></li>
<li><a href="../pt453890/index.html">Sonhos sovi√©ticos do futuro</a></li>
<li><a href="../pt453892/index.html">Certifica√ß√£o ISTQB. Parte 2: Como se preparar para a certifica√ß√£o ISTQB? Hist√≥rias de pr√°tica</a></li>
<li><a href="../pt453904/index.html">Livre-se de "vk.com/away.php" ou siga os links de uma pessoa saud√°vel</a></li>
<li><a href="../pt453906/index.html">O que √© um "Modelo de Dom√≠nio"?</a></li>
<li><a href="../pt453908/index.html">RTOS Neutrino em computadores industriais</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
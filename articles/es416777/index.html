<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå∏ üèä üèúÔ∏è El principio de funcionamiento de la red neuronal convolucional. Casi complicado üöã üçô ü¶Ñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Las redes neuronales profundas han llevado a un gran avance en muchas tareas de reconocimiento de im√°genes, como la visi√≥n por computadora y el recono...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>El principio de funcionamiento de la red neuronal convolucional. Casi complicado</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416777/">  Las redes neuronales profundas han llevado a un gran avance en muchas tareas de reconocimiento de im√°genes, como la visi√≥n por computadora y el reconocimiento de voz.  La red neuronal convolucional es uno de los tipos populares de redes neuronales. <br><br>  B√°sicamente, una red neuronal convolucional puede considerarse como una red neuronal que utiliza muchas copias id√©nticas de la misma neurona.  Esto permite que la red tenga un n√∫mero limitado de par√°metros cuando se computan modelos grandes. <br><br><img src="https://habrastorage.org/webt/qo/wl/uj/qowlujdieq8o858nnhk0ynivvqq.png"><br>  <i>Red neuronal convolucional 2D</i> <br><a name="habracut"></a><br>  Esta t√©cnica con varias copias de la misma neurona tiene una analog√≠a cercana con la abstracci√≥n de funciones en matem√°ticas y ciencias de la computaci√≥n.  Durante la programaci√≥n, la funci√≥n se escribe una vez y luego se reutiliza, sin requerir que escriba el mismo c√≥digo muchas veces en diferentes lugares, lo que acelera la ejecuci√≥n del programa y reduce la cantidad de errores.  Del mismo modo, una red neuronal convolucional, una vez que ha entrenado una neurona, la usa en muchos lugares, lo que facilita el entrenamiento del modelo y minimiza los errores. <br><br><h3>  La estructura de las redes neuronales convolucionales. </h3><br>  Supongamos que se da una tarea en la que se requiere predecir a partir del audio si hay una voz de persona en el archivo de audio. <br><br>  En la entrada, obtenemos muestras de audio en diferentes momentos.  Las muestras se distribuyen uniformemente. <br><br><img src="https://habrastorage.org/webt/-l/tq/hm/-ltqhm6q746nmks4dybmddu3boa.png"><br><br>  La forma m√°s f√°cil de clasificarlos con una red neuronal es conectar todas las muestras a una capa totalmente conectada.  En este caso, cada entrada est√° conectada a cada neurona. <br><br><img src="https://habrastorage.org/webt/6u/67/at/6u67atmfqac0v5wmw-tnqcjumhk.png"><br><br>  Un enfoque m√°s complejo tiene en cuenta cierta simetr√≠a en las propiedades que se encuentran en los datos.  Prestamos mucha atenci√≥n a las propiedades locales de los datos: ¬øcu√°l es la frecuencia del sonido durante un tiempo determinado?  ¬øAumentando o disminuyendo?  Y as√≠ sucesivamente. <br><br>  Tenemos en cuenta las mismas propiedades en todo momento.  Es √∫til conocer las frecuencias al principio, a la mitad y al final.  Tenga en cuenta que estas son propiedades locales, ya que solo necesita una peque√±a ventana de secuencia de audio para definirlas. <br><br>  Por lo tanto, es posible crear un grupo de neuronas A, que consideran peque√±os segmentos de tiempo en nuestros datos.  A observa todos estos segmentos, calculando ciertas funciones.  Luego, la salida de esta capa convolucional se alimenta a una capa F. completamente conectada. <br><br><img src="https://habrastorage.org/webt/7y/oq/3o/7yoq3outosuswuj1eqmjz1jqaig.png"><br><br>  En el ejemplo anterior, A proces√≥ solo segmentos de dos puntos.  Esto es raro en la pr√°ctica.  Por lo general, la ventana de capa de convoluci√≥n es mucho m√°s grande. <br><br>  En el siguiente ejemplo, A recibe 3 segmentos en la entrada.  Esto tambi√©n es poco probable para las tareas del mundo real, pero, desafortunadamente, es dif√≠cil visualizar A conectando m√∫ltiples entradas. <br><br><img src="https://habrastorage.org/webt/f8/t8/4_/f8t84_f4dpp6tm2eskzdeo4tifu.png"><br><br>  Una buena propiedad de las capas convolucionales es que son compuestas.  Puede alimentar la salida de una capa convolucional a otra.  Con cada capa, la red descubre funciones m√°s altas y m√°s abstractas. <br><br>  En el siguiente ejemplo, hay un nuevo grupo de neuronas B. B se usa para crear otra capa convolucional colocada encima de la anterior. <br><br><img src="https://habrastorage.org/webt/il/sv/gn/ilsvgnzz8zg9jqm0pokranbbx5k.png"><br><br>  Las capas convolucionales a menudo se entrelazan agrupando (combinando) capas.  En particular, hay un tipo de capa llamada max-pooling, que es extremadamente popular. <br><br>  A menudo, no nos importa el momento exacto en el tiempo cuando una se√±al √∫til est√° presente en los datos.  Si un cambio en la frecuencia de la se√±al ocurre tarde o temprano, ¬øimporta? <br><br>  La agrupaci√≥n m√°xima absorbe caracter√≠sticas m√°ximas de peque√±os bloques del nivel anterior.  La conclusi√≥n dice si la se√±al de la funci√≥n deseada estaba presente en la capa anterior, pero no exactamente d√≥nde. <br><br>  Capas de agrupaci√≥n m√°xima: esta es una "disminuci√≥n".  Permite que las capas convolucionales posteriores funcionen en grandes piezas de datos, porque los peque√±os parches despu√©s de la capa de fusi√≥n corresponden al parche mucho m√°s grande frente a √©l.  Tambi√©n nos hacen invariables a algunas transformaciones de datos muy peque√±as. <br><br><img src="https://habrastorage.org/webt/sk/dl/aq/skdlaqwb_hk7wauvw8pii4wvhkk.png"><br><br>  En nuestros ejemplos anteriores, se utilizaron capas convolucionales unidimensionales.  Sin embargo, las capas convolucionales pueden funcionar con datos m√°s voluminosos.  De hecho, las soluciones m√°s famosas basadas en redes neuronales convolucionales utilizan redes neuronales convolucionales bidimensionales para el reconocimiento de patrones. <br><br><img src="https://habrastorage.org/webt/lf/91/gl/lf91glavwwobg9dm1u5pqnop5ks.png"><br><br>  En una capa convolucional bidimensional, en lugar de mirar segmentos, A observar√° parches. <br><br>  Para cada parche, A calcular√° la funci√≥n.  Por ejemplo, ella puede aprender a detectar la presencia de un borde, o textura, o el contraste entre dos colores. <br><br><img src="https://habrastorage.org/webt/e8/tm/n3/e8tmn3ysyw8rb3ombksxd-ytv9i.png"><br><br>  En el ejemplo anterior, la salida de la capa convolucional se introdujo en una capa totalmente conectada.  Pero, es posible componer dos capas convolucionales, como fue el caso en el caso unidimensional considerado. <br><br><img src="https://habrastorage.org/webt/qo/wl/uj/qowlujdieq8o858nnhk0ynivvqq.png"><br><br>  Tambi√©n podemos realizar la agrupaci√≥n m√°xima en dos dimensiones.  Aqu√≠ tomamos el m√°ximo de caracter√≠sticas de un peque√±o parche. <br><br>  Esto se reduce al hecho de que cuando se considera la imagen completa, la posici√≥n exacta del borde, hasta el p√≠xel, no es importante.  Es suficiente saber d√≥nde se encuentra dentro de unos pocos p√≠xeles. <br><br><img src="https://habrastorage.org/webt/jt/kz/t2/jtkzt2o28albqpurnufgfiaiv5w.png"><br><br>  Adem√°s, las redes de convoluci√≥n tridimensionales a veces se usan para datos como video o datos masivos (por ejemplo, escaneo 3D en medicina).  Sin embargo, tales redes no son muy utilizadas y son mucho m√°s dif√≠ciles de visualizar. <br><br>  Anteriormente, dijimos que A es un grupo de neuronas.  Seremos m√°s precisos en eso: ¬øqu√© es A? <br>  En las capas convolucionales tradicionales, A es un conjunto paralelo de neuronas, todas las neuronas reciben las mismas se√±ales de entrada y calculan diferentes funciones. <br><br>  Por ejemplo, en una capa convolucional bidimensional, una neurona puede detectar bordes horizontales, otra, bordes verticales y un tercer contraste de color verde-rojo. <br><br><img src="https://habrastorage.org/webt/cm/w6/fw/cmw6fwexvstutmrgwrkfsgyefwy.png"><br><br>  El art√≠culo 'Red en Red' (Lin et al. (2013)) propone una nueva capa, "Mlpconv".  En este modelo, A tiene varios niveles de neuronas, y la √∫ltima capa deriva funciones de nivel superior para la regi√≥n que se est√° tratando.  En el art√≠culo, el modelo logra resultados impresionantes, estableciendo un nuevo nivel de tecnolog√≠a en una serie de conjuntos de datos de referencia. <br><br><img src="https://habrastorage.org/webt/f3/du/qf/f3duqfglko4krl4dsk9djtxuwcm.png"><br><br>  A los fines de esta publicaci√≥n, nos centraremos en las capas convolucionales est√°ndar. <br><br>  Resultados de la red neuronal convolucional <br><br>  En 2012, Alex Krizhevsky, Ilya Sutskever y Geoff Hinton lograron una mejora significativa en la calidad del reconocimiento en comparaci√≥n con las soluciones conocidas en ese momento (Krizehvsky et al. (2012)). <br><br>  El progreso fue el resultado de combinar varios enfoques.  Los procesadores gr√°ficos se utilizaron para entrenar una red neuronal profunda (seg√∫n los est√°ndares de 2012).  Se utiliz√≥ un nuevo tipo de neurona (ReLU) y una nueva t√©cnica para reducir el problema llamado "sobreajuste" (DropOut).  Utilizamos un gran conjunto de datos con una gran cantidad de categor√≠as de im√°genes (ImageNet).  Y, por supuesto, era una red neuronal convolucional. <br>  La arquitectura que se muestra a continuaci√≥n era profunda.  Tiene 5 capas convolucionales, 3 agrupaciones alternas y tres capas completamente conectadas. <br><br><img src="https://habrastorage.org/webt/gr/zo/vs/grzovscm0egf45_kei8cmj3mbli.png"><br><br>  De Krizehvsky et al.  (2012) <br>  La red ha sido entrenada para clasificar fotos en miles de categor√≠as diferentes. <br><br>  El modelo de Krizhevsky et al. Fue capaz de dar la respuesta correcta en el 63% de los casos.  Adem√°s, la respuesta correcta de las 5 mejores respuestas, ¬°hay un 85% de pron√≥sticos! <br><br><img src="https://habrastorage.org/webt/0g/jk/ci/0gjkci6d80jyizq9jmrgltryowe.png"><br><br>  Perm√≠tanos ilustrar lo que reconoce el primer nivel de la red. <br><br>  Recordemos que las capas convolucionales se dividieron entre dos GPU.  La informaci√≥n no va y viene a trav√©s de cada capa.  Resulta que cada vez que se inicia el modelo, ambos lados se especializan. <br><br><img src="https://habrastorage.org/webt/4l/lh/r5/4llhr5q1zo4euabkmsl_epb679w.png"><br><br>  Filtros obtenidos por la primera capa convolucional.  La mitad superior corresponde a una capa en una GPU, la mitad inferior en la otra.  De Krizehvsky et al.  (2012) <br>  Las neuronas de un lado se enfocan en blanco y negro, aprendiendo a detectar bordes de diferentes orientaciones y tama√±os.  Las neuronas, por otro lado, se especializan en color y textura, detectan contrastes y patrones de color.  Recuerde que las neuronas se inicializan al azar.  Ni una sola persona fue y los estableci√≥ como detectores fronterizos, o los dividi√≥ de esta manera.  Esto sucedi√≥ mientras entrenaba la red de clasificaci√≥n de im√°genes. <br><br>  Estos resultados notables (y otros resultados interesantes a lo largo del tiempo) fueron solo el comienzo.  Fueron seguidos r√°pidamente por muchos otros trabajos que probaron enfoques modificados y mejoraron gradualmente los resultados o los aplicaron en otras √°reas. <br>  Las redes neuronales convolucionales son una herramienta importante en la visi√≥n por computadora y el reconocimiento de patrones modernos. <br><br><h3>  Formalizaci√≥n de redes neuronales convolucionales. </h3><br>  Considere una capa convolucional unidimensional con entradas {xn} y salidas {yn}: <br><br><img src="https://habrastorage.org/webt/09/lo/-3/09lo-3ri7xuwih3umswh9f04b3c.png"><br><br>  Es relativamente f√°cil describir los resultados en t√©rminos de entrada: <br><br>  yn = A (x, x + 1, ...) <br><br>  Por ejemplo, en el ejemplo anterior: <br><br>  y0 = A (x0, x1) <br>  y1 = A (x1, x2) <br><br>  Del mismo modo, si consideramos una capa convolucional bidimensional con entradas {xn, m} y salidas {yn, m}: <br><br><img src="https://habrastorage.org/webt/bj/7e/5u/bj7e5ub22qmy2mlinnodyfg7soa.png"><br><br>  La red se puede representar mediante una matriz de valores bidimensional. <br><br><h3>  Conclusi√≥n </h3><br>  La operaci√≥n de convoluci√≥n es una herramienta poderosa.  En matem√°ticas, la operaci√≥n de convoluci√≥n surge en diferentes contextos, desde el estudio de ecuaciones diferenciales parciales hasta la teor√≠a de probabilidades.  En parte debido a su papel en PDE, la convoluci√≥n es importante en las ciencias f√≠sicas.  La convoluci√≥n tambi√©n juega un papel importante en muchas √°reas de aplicaci√≥n, como gr√°ficos por computadora y procesamiento de se√±ales. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es416777/">https://habr.com/ru/post/es416777/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es416761/index.html">Lenguaje c√≥smico, parte 1: ¬øes universal la gram√°tica universal?</a></li>
<li><a href="../es416763/index.html">Puppet Salt Chef Ensemble: compara Ansible, SaltStack, Chef y Puppet</a></li>
<li><a href="../es416765/index.html">Empresa Foliplast: un ciclo completo de producci√≥n digital en Rusia</a></li>
<li><a href="../es416767/index.html">Un deuce para ti o una auditor√≠a con pirater√≠a</a></li>
<li><a href="../es416775/index.html">Otro papercraft</a></li>
<li><a href="../es416781/index.html">¬øQui√©n salvar√° la teor√≠a de la relatividad?</a></li>
<li><a href="../es416783/index.html">¬øC√≥mo cambiar√° la revoluci√≥n de descentralizaci√≥n la econom√≠a global?</a></li>
<li><a href="../es416785/index.html">Implementaci√≥n del nuevo protocolo de transporte NTCP2 de la red I2P</a></li>
<li><a href="../es416787/index.html">Zabbix: monitoreo del almacenamiento en disco DELL MD36XX</a></li>
<li><a href="../es416791/index.html">Informe del Club de Roma 2018, Cap√≠tulo 3.3: Econom√≠a azul</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
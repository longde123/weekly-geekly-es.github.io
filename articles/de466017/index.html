<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ–• ğŸšµğŸ¼ ğŸ‘¨ğŸ¼â€ğŸ¤ Livy - das fehlende Glied in der Hadoop Spark Airflow Python-Kette ğŸ…ğŸ¾ ğŸ’ƒğŸ¼ ğŸˆ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits, einige Informationen "unter der Haube" sind das Datum der technischen Werkstatt von Alfastrakhovaniya - was unsere technischen KÃ¶pfe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Livy - das fehlende Glied in der Hadoop Spark Airflow Python-Kette</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/alfastrah/blog/466017/"><p>  Hallo allerseits, einige Informationen "unter der Haube" sind das Datum der technischen Werkstatt von Alfastrakhovaniya - was unsere technischen KÃ¶pfe begeistert. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/956/f04/a6a/956f04a6ae545bee58a8c34f2938a850.png" alt="Bild"></p><br><p>  Apache Spark ist ein wunderbares Tool, mit dem Sie groÃŸe Datenmengen schnell und einfach auf relativ bescheidenen Computerressourcen verarbeiten kÃ¶nnen (ich meine Cluster-Verarbeitung). </p><br><p>  Traditionell wird das Jupyter-Notebook in der Ad-hoc-Datenverarbeitung verwendet.  In Kombination mit Spark kÃ¶nnen wir so langlebige Datenrahmen manipulieren (Spark befasst sich mit der Zuweisung von Ressourcen, die Datenrahmen befinden sich irgendwo im Cluster, ihre Lebensdauer ist durch die Lebensdauer des Spark-Kontexts begrenzt). </p><br><p>  Nach der Ãœbertragung der Datenverarbeitung an Apache Airflow wird die Lebensdauer der Frames erheblich verkÃ¼rzt - der Spark-Kontext "lebt" innerhalb derselben Airflow-Anweisung.  Wie man das umgeht, warum man herumkommt und was Livy damit zu tun hat - lesen Sie unter dem Schnitt. </p><a name="habracut"></a><br><p>  Schauen wir uns ein sehr, sehr einfaches Beispiel an: Angenommen, wir mÃ¼ssen Daten in einer groÃŸen Tabelle denormalisieren und das Ergebnis zur weiteren Verarbeitung in einer anderen Tabelle speichern (ein typisches Element der Datenverarbeitungspipeline). </p><br><p>  Wie wÃ¼rden wir das machen: </p><br><ul><li>  geladene Daten in Datenrahmen (Auswahl aus einer groÃŸen Tabelle und Verzeichnissen) </li><li>  schaute mit "Augen" auf das Ergebnis (hat es richtig geklappt) </li><li>  gespeicherter Datenrahmen in der Hive-Tabelle (zum Beispiel) </li></ul><br><p>  Basierend auf den Ergebnissen der Analyse mÃ¼ssen wir mÃ¶glicherweise im zweiten Schritt eine bestimmte Verarbeitung einfÃ¼gen (WÃ¶rterbuchersatz oder etwas anderes).  In Bezug auf die Logik haben wir drei Schritte </p><br><ul><li>  Schritt 1: herunterladen </li><li>  Schritt 2: Verarbeitung </li><li>  Schritt 3: Speichern </li></ul><br><p>  In jupyter notebook machen wir das so - wir kÃ¶nnen die heruntergeladenen Daten fÃ¼r eine beliebig lange Zeit verarbeiten und so die Spark-Ressourcen kontrollieren. </p><br><p> Es ist logisch zu erwarten, dass eine solche Partition an Airflow Ã¼bertragen werden kann.  Das heiÃŸt, ein Diagramm dieser Art zu haben </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/312/30b/d7e/31230bd7e4c3beb62f92aebb709e2010.png" alt="Bild"></p><br><p>  Leider ist dies bei Verwendung der Airflow + Spark-Kombination nicht mÃ¶glich: Jede Airflow-Anweisung wird in einem eigenen Python-Interpreter ausgefÃ¼hrt. Daher muss jede Anweisung unter anderem die Ergebnisse ihrer AktivitÃ¤ten irgendwie "beibehalten".  Somit wird unsere Verarbeitung in einem Schritt "komprimiert" - "Daten denormalisieren". </p><br><p>  Wie kann die FlexibilitÃ¤t des Jupyter-Notebooks wieder auf Airflow Ã¼bertragen werden?  Es ist klar, dass das obige Beispiel â€es nicht wertâ€œ ist (vielleicht stellt sich im Gegenteil ein gut verstÃ¤ndlicher Verarbeitungsschritt heraus).  Aber dennoch - wie kÃ¶nnen Airflow-Anweisungen im selben Spark-Kontext Ã¼ber den gemeinsamen Datenrahmenbereich ausgefÃ¼hrt werden? </p><br><h2 id="privetstvuem-livy">  Willkommen Livy </h2><br><p>  Ein weiteres Hadoop-Ã–kosystemprodukt kommt zur Rettung - Apache Livy. </p><br><p>  Ich werde hier nicht versuchen zu beschreiben, was fÃ¼r ein "Biest" es ist.  Wenn es sehr kurz und schwarzweiÃŸ ist - Mit Livy kÃ¶nnen Sie Python-Code in ein Programm "einfÃ¼gen", das der Treiber ausfÃ¼hrt: </p><br><ul><li>  Zuerst erstellen wir eine Livy-Sitzung </li><li>  Danach haben wir die MÃ¶glichkeit, in dieser Sitzung beliebigen Python-Code auszufÃ¼hren (sehr Ã¤hnlich der Jupyter / Ipython-Ideologie). </li></ul><br><p>  Und zu all dem gibt es eine REST-API. </p><br><p>  ZurÃ¼ck zu unserer einfachen Aufgabe: Mit Livy kÃ¶nnen wir die ursprÃ¼ngliche Logik unserer Denormalisierung speichern </p><br><ul><li>  Im ersten Schritt (der ersten Anweisung unseres Diagramms) werden wir den Datenladecode in den Datenrahmen laden und ausfÃ¼hren </li><li>  im zweiten Schritt (zweite Anweisung) - fÃ¼hren Sie den Code fÃ¼r die notwendige zusÃ¤tzliche Verarbeitung dieses Datenrahmens aus </li><li>  im dritten Schritt - der Code zum Speichern des Datenrahmens in der Tabelle </li></ul><br><p>  Was in Bezug auf den Luftstrom so aussehen kÃ¶nnte: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b9b/255/bcd/b9b255bcd00525201a000ef1a3fbafa3.png" alt="Bild"></p><br><p>  (Da es sich bei dem Bild um einen sehr realen Screenshot handelt, wurden zusÃ¤tzliche â€RealitÃ¤tenâ€œ hinzugefÃ¼gt. Das Erstellen des Spark-Kontexts wurde zu einem separaten Vorgang mit einem seltsamen Namen. Die â€Verarbeitungâ€œ der Daten verschwand, weil sie nicht benÃ¶tigt wurden usw.) </p><br><p>  Zusammenfassend erhalten wir </p><br><ul><li>  Universelle Luftstromanweisung, die Python-Code in einer Livy-Sitzung ausfÃ¼hrt </li><li>  die FÃ¤higkeit, Python-Code in ziemlich komplexen Graphen zu "organisieren" (Airflow dafÃ¼r) </li><li>  Die FÃ¤higkeit, Optimierungen auf hÃ¶herer Ebene in Angriff zu nehmen, z. B. in welcher Reihenfolge wir unsere Transformationen durchfÃ¼hren mÃ¼ssen, damit Spark die allgemeinen Daten so lange wie mÃ¶glich im Cluster-Speicher behalten kann </li></ul><br><p>  Eine typische Pipeline zum Vorbereiten von Daten fÃ¼r die Modellierung enthÃ¤lt ungefÃ¤hr 25 Abfragen Ã¼ber 10 Tabellen. Es ist offensichtlich, dass einige Tabellen hÃ¤ufiger verwendet werden als andere (dieselben "allgemeinen Daten"), und es gibt etwas zu optimieren. </p><br><h2 id="chto-dalshe">  Was weiter </h2><br><p>  Die technischen FÃ¤higkeiten wurden getestet, wir Ã¼berlegen weiter - wie wir unsere Transformationen technologischer in dieses Paradigma umsetzen kÃ¶nnen.  Und wie man sich der oben erwÃ¤hnten Optimierung nÃ¤hert.  Wir stehen noch am Anfang dieses Teils unserer Reise - wenn es etwas Interessantes gibt, werden wir es definitiv teilen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de466017/">https://habr.com/ru/post/de466017/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de465991/index.html">Arbeiter sauberer schneller Architektur</a></li>
<li><a href="../de465993/index.html">Sie mÃ¼ssen keine digitale Sicherheit sparen</a></li>
<li><a href="../de465995/index.html">LDC - Ausflug</a></li>
<li><a href="../de466001/index.html">"Mobile" Feng Shui, oder wir schlafen richtig (Kaffee, Kakerlaken und Intoleranz bei HabrÃ©)</a></li>
<li><a href="../de466015/index.html">Ein bisschen mehr Ã¼ber Trigonometrie beim Rechnen</a></li>
<li><a href="../de466019/index.html">ABBYY Mobile Web Capture: Hochwertige Fotos von Dokumenten direkt im Browser Ihres Smartphones</a></li>
<li><a href="../de466021/index.html">Wie ich Yandex.Alice beigebracht habe, Ã¼ber Sexspielzeug zu sprechen</a></li>
<li><a href="../de466027/index.html">Das Buch "Der Weg von Python. Schwarzer GÃ¼rtel fÃ¼r Entwicklung, Skalierung, Test und Bereitstellung â€œ</a></li>
<li><a href="../de466029/index.html">Wie man einen Quantencomputer in einen perfekten Zufallszahlengenerator verwandelt</a></li>
<li><a href="../de466031/index.html">DeepMinds epische Mission, das komplexeste wissenschaftliche Problem zu lÃ¶sen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
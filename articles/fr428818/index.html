<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úåÔ∏è üìÆ üöº DeOldify: un programme pour colorier des images en noir et blanc üåßÔ∏è üêß üç©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bref, la t√¢che de ce projet est de coloriser et restaurer des photographies anciennes. Je vais approfondir un peu les d√©tails, mais d'abord, voyons le...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>DeOldify: un programme pour colorier des images en noir et blanc</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428818/">  Bref, la t√¢che de ce projet est de coloriser et restaurer des photographies anciennes.  Je vais approfondir un peu les d√©tails, mais d'abord, voyons les photos!  Soit dit en passant, la plupart des images source sont tir√©es du sous-r / TheWayWeWere, je remercie tout le monde pour ces gros plans de haute qualit√©. <br><br>  <b>Ce ne sont que quelques exemples, et ils sont assez typiques!</b> <br><br>  <i>Maria Anderson comme la petite f√©e et sa page Lyubov Ryabtsova dans le ballet Sleeping Beauty √† l'Imperial Theatre, Saint-P√©tersbourg, Russie, 1890</i> <i><br></i> <br><img src="https://habrastorage.org/webt/s0/vh/vl/s0vhvlbdvsrvx09bxdugq6n6vaq.jpeg"><br><a name="habracut"></a><br>  <i>Une femme se d√©tend dans son salon (1920, Su√®de)</i> <br><br><img src="https://habrastorage.org/webt/qt/fe/7f/qtfe7f0alc4foxo_f6vija5p1ey.jpeg"><br><br>  <i>√âtudiants en m√©decine posant pr√®s d'un cadavre, vers 1890</i> <br><br><img src="https://habrastorage.org/webt/z7/bp/xl/z7bpxlwrvbib_tzqgaaw8ihadqy.jpeg"><br><br>  <i>Surfeur √† Hawa√Ø, 1890</i> <br><br><img src="https://habrastorage.org/webt/pr/7f/do/pr7fdopo8pdjs-yoxa-v-4bbwmi.jpeg"><br><br>  <i>Cheval qui tourne, 1898</i> <br><br><img src="https://habrastorage.org/webt/yj/pk/iw/yjpkiwkgzbscgirnzjtp3sny8po.jpeg"><br><br>  <i>L'int√©rieur du bar Miller and Shoemaker, 1899</i> <br><br><img src="https://habrastorage.org/webt/x6/d8/mo/x6d8modnwsdzhquyhiqnpwf4t2c.jpeg"><br><br>  <i>Paris dans les ann√©es 1880</i> <br><br><img src="https://habrastorage.org/webt/kl/ct/pj/klctpjrr-czaqpsejgpgzbwyuqw.jpeg"><br><br>  <i>Vue a√©rienne d'√âdimbourg dans les ann√©es 1920</i> <br><br><img src="https://habrastorage.org/webt/fo/st/3w/fost3w3afdg26wwg_6dfjri-dw8.jpeg"><br><br>  <i>Texas femme en 1938</i> <br><br><img src="https://habrastorage.org/webt/cm/47/lp/cm47lpwsw1hpb5kcnkicahf-iga.jpeg"><br><br>  <i>Les gens de la gare de Waterloo regardent la t√©l√©vision pour la premi√®re fois, Londres, 1936</i> <br><br><img src="https://habrastorage.org/webt/in/nk/x9/innkx9gt0mixwjvdhk8ridbrqpy.jpeg"><br><br>  <i>Le√ßon de g√©ographie en 1850</i> <br><br><img src="https://habrastorage.org/webt/j_/ju/6l/j_ju6l3-7cea5_cuyjbucbsk8sq.jpeg"><br><br>  <i>Les fumeurs d'opium chinois en 1880</i> <br><br><img src="https://habrastorage.org/webt/i_/_j/tr/i__jtry3w4divci7u7b2hcaagim.jpeg"><br><br>  <b>Veuillez noter que m√™me les photos vraiment anciennes et / ou de mauvaise qualit√© ont toujours l'air plut√¥t cool:</b> <br><br>  <i>Deadwood, Dakota du Sud, 1877</i> <br><br><img src="https://habrastorage.org/webt/lm/bj/vl/lmbjvladhdfyfygu0mal1rbqtry.jpeg"><br><br>  <i>Fr√®res et s≈ìurs en 1877 (Deadwood)</i> <br><br><img src="https://habrastorage.org/webt/mz/br/wq/mzbrwqmqehigiyahfj_obgmlflc.jpeg"><br><br>  <i>Portsmouth Square √† San Francisco, 1851</i> <br><br><img src="https://habrastorage.org/webt/l3/qk/w-/l3qkw-yf0byhfmc8e6ysjl-bo7o.jpeg"><br><br>  <i>Samoura√Ø, vers 1860</i> <br><br><img src="https://habrastorage.org/webt/l_/ug/wa/l_ugwar3td8vea4rhep9gfg7r4s.jpeg"><br><br>  Bien s√ªr, le mod√®le n'est pas parfait.  Cette main rouge me rend fou, mais sinon √ßa marche fantastiquement: <br><br>  <i>Fille s√©n√©ca iroquoise, 1908</i> <br><br><img src="https://habrastorage.org/webt/js/ft/be/jsftbe0bjiodlhidemhvjj5fdf0.jpeg"><br><br>  <b>Elle peut √©galement coloriser des dessins en noir et blanc:</b> <br><br><img src="https://habrastorage.org/webt/hf/gf/zu/hfgfzugkkblhev4-ke5f55dabn8.jpeg"><br><br><h1>  D√©tails techniques </h1><br>  Il s'agit d'un mod√®le d'apprentissage en profondeur.  En particulier, j'ai combin√© les approches suivantes: <br><br><ul><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Auto-attention GAN</a></b> .  La seule chose est que l' <b>Unet pr√©-form√© est</b> utilis√© comme g√©n√©rateur et je viens de le changer pour la normalisation spectrale et, en fait, le m√©canisme d'auto-attention.  Il s'agit d'une modification assez simple.  Je vais vous dire que la diff√©rence est frappante par rapport √† la version pr√©c√©dente de Wasserstein GAN, que j'ai essay√© de faire fonctionner.  J'ai aim√© la th√©orie de Wasserstein GAN, mais en pratique cela ne fonctionne pas.  Mais je suis juste tomb√© amoureux du r√©seau Self-Attention GAN. </li><li>  Une structure d'apprentissage comme la <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">croissance progressive d'un GAN</a></b> (mais pas exactement la m√™me).  La diff√©rence est que le nombre de couches reste constant: je viens de changer la taille des donn√©es d'entr√©e et d'ajuster la vitesse d'apprentissage pour que les transitions entre les tailles soient r√©ussies.  Il semble qu'il produise le m√™me r√©sultat final, mais apprend plus vite, est plus stable et effectue mieux la g√©n√©ralisation. </li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√®gle TTUR</a></b> (r√®gle de mise √† jour √† deux √©chelles de temps).  Ici, c'est assez clair: juste une it√©ration individuelle du g√©n√©rateur / discriminateur (critique) et une vitesse d'apprentissage du discriminateur plus √©lev√©e. </li><li>  <b>La fonction de perte du g√©n√©rateur se</b> compose de deux parties: l'une d'entre elles est la fonction principale de la perte perceptuelle (ou perte de fonctionnalit√©) bas√©e sur VGG16 - elle pousse simplement le mod√®le du g√©n√©rateur pour reproduire l'image d'entr√©e.  La deuxi√®me partie est l'estimation des pertes du discriminateur (critique).  Pour les curieux: seule la fonction Perte Perte Perte ne suffit pas pour un bon r√©sultat.  Cela tend √† encourager simplement un tas de marron / vert / bleu - vous savez, en trompant le test, quels sont les r√©seaux de neurones vraiment bons!  Le point cl√© est que les GAN apprennent essentiellement la fonction de perte pour vous, ce qui est en fait un grand pas vers l'id√©al que nous recherchons dans l'apprentissage automatique.  Et bien s√ªr, les r√©sultats s'am√©lioreront consid√©rablement lorsque la machine elle-m√™me apprend ce que vous avez pr√©c√©demment encod√© manuellement.  Bien s√ªr, c'est le cas ici. </li></ul><br>  La beaut√© de ce mod√®le est qu'il est assez bon dans une vari√©t√© de modifications d'image.  Ce que vous voyez ci-dessus sont les r√©sultats du mod√®le de coloration, mais ce n'est qu'un composant du pipeline que je souhaite d√©velopper avec le m√™me mod√®le. <br><br>  Ensuite, j'essaierai de perfectionner les anciennes images, et le prochain point √† l'ordre du jour est un mod√®le pour am√©liorer la saturation et la richesse (defade).  Maintenant, elle est aux premiers stades de la formation.  Il s'agit essentiellement du m√™me mod√®le, mais avec certains param√®tres de contraste / luminosit√© comme une simulation de photos fan√©es et de photos prises avec un √©quipement ancien / m√©diocre.  J'ai d√©j√† re√ßu des r√©sultats encourageants: <br><br><img src="https://habrastorage.org/webt/jh/bs/qg/jhbsqg6a-unrsvzhxtva3z0ee7u.jpeg"><br><br><h1>  D√©tails du projet </h1><br>  Quelle est l'essence de ce projet?  Je veux juste appliquer GAN pour que les vieilles photos soient tr√®s, tr√®s bonnes.  Et plus important encore, cela rendra le projet <i>utile</i> .  Et oui, je suis vraiment int√©ress√© √† travailler avec la vid√©o, mais je dois d'abord comprendre comment prendre ce mod√®le sous contr√¥le de la consommation de m√©moire (c'est une vraie b√™te).  Ce serait bien si les mod√®les n'avaient pas appris de deux √† trois jours sur 1080Ti (malheureusement, typique pour GAN).  Bien que ce soit mon enfant et je vais activement mettre √† jour et am√©liorer le code dans un avenir pr√©visible, mais je vais essayer de rendre le programme aussi convivial que possible, bien qu'il y aura probablement des difficult√©s avec. <br><br>  Et je jure que je documenterai le code correctement ... un jour.  Certes, je fais partie de ces gens qui croient au "code auto-document√©" (LOL). <br><br><h1>  Mod√®le d'auto-lancement </h1><br>  Le projet est construit sur la merveilleuse biblioth√®que Fast.AI.  Malheureusement, il s'agit d'une ancienne version, et il reste √† mettre √† jour vers une nouvelle (c'est d√©finitivement √† l'ordre du jour).  Donc, les pr√©requis, en bref: <br><br><ul><li>  <b><i>Ancienne</i> biblioth√®que Fast.AI.</b>  Apr√®s m'√™tre enfoui dans le projet pendant deux mois, j'ai un peu rat√© ce qui lui est arriv√©, car celui qui est d√©sormais marqu√© comme ¬´ancien¬ª ne ressemble pas vraiment √† celui que j'ai.  Tout a chang√© au cours des deux derniers mois environ.  Par cons√©quent, si rien ne fonctionne avec d'autres versions, je l'ai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fourch√© ici</a> .  Encore une fois, la mise √† jour vers la derni√®re version est √† l'ordre du jour, je m'excuse √† l'avance. </li><li>  <b>Toutes les d√©pendances Fast.AI</b> : il y a des fichiers requirements.txt et environment.yml pratiques. </li><li>  <b>Pytorch 0.4.1</b> (spectral_norm est requis, vous avez donc besoin de la derni√®re version stable). </li><li>  <b>JupyterLab</b> . </li><li>  <b>Tensorboard</b> (c'est-√†-dire l'installation de Tensorflow) et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><b>TensorboardX</b></a> .  Je pense que ce n'est pas <i>strictement</i> n√©cessaire, mais c'est beaucoup plus facile.  Pour votre commodit√©, j'ai d√©j√† fourni tous les crochets / rappels n√©cessaires dans Tensorboard!  Il existe des exemples de leur utilisation.  Il est √† noter que par d√©faut, les images pendant le traitement sont enregistr√©es dans le Tensorboard toutes les 200 it√©rations, de sorte que vous aurez une vue constante et pratique de ce que fait le mod√®le. </li><li>  <b>ImageNet</b> : un excellent ensemble de donn√©es pour la formation. </li><li>  <b>Carte graphique puissante</b> .  J'aimerais vraiment avoir plus de m√©moire que 11 Go dans ma GeForce 1080Ti.  Si vous avez quelque chose de plus faible, ce sera difficile.  Unet et Critic sont absurdement excellents, mais plus ils sont gros, meilleurs sont les r√©sultats. </li></ul><br>  <b>Si vous souhaitez commencer le traitement d'images par vous-m√™me</b> sans entra√Æner le mod√®le, vous pouvez t√©l√©charger des poids pr√™ts √† l'emploi <a href="">ici</a> .  Ouvrez ensuite ColorizationVisualization.ipynb dans JupyterLab.  Assurez-vous qu'il y a une ligne avec un lien vers les poids: <br><br><pre><code class="python hljs">colorizer_path = Path(<span class="hljs-string"><span class="hljs-string">'/path/to/colorizer_gen_192.h5'</span></span>)</code> </pre> <br>  Ensuite, vous devez charger le mod√®le de coloriseur apr√®s l'initialisation de netG: <br><br><pre> <code class="python hljs">load_model(netG, colorizer_path)</code> </pre> <br>  Ensuite, placez simplement les images dans le dossier / test_images /, d'o√π vous d√©marrez le programme.  Vous pouvez visualiser les r√©sultats dans le bloc-notes Jupyter avec les lignes suivantes: <br><br><pre> <code class="python hljs">vis.plot_transformed_image(<span class="hljs-string"><span class="hljs-string">"test_images/derp.jpg"</span></span>, netG, md.val_ds, tfms=x_tfms, sz=<span class="hljs-number"><span class="hljs-number">500</span></span>)</code> </pre> <br>  J'√©conomiserais une taille d'environ 500 pixels, plus ou moins, si vous ex√©cutez le programme sur un GPU avec beaucoup de m√©moire (par exemple, GeForce 1080Ti 11 Go).  S'il y a moins de m√©moire, vous devez r√©duire la taille des images ou essayer de fonctionner sur le CPU.  En fait, j'ai essay√© de faire ce dernier, mais pour une raison quelconque, le mod√®le a fonctionn√© tr√®s, absurdement lentement, et je n'ai pas trouv√© le temps d'√©tudier le probl√®me.  Les connaisseurs ont recommand√© de construire Pytorch √† partir des sources, ce qui entra√Ænerait une augmentation importante des performances.  Hmm ... √Ä ce moment, ce n'√©tait pas avant cela. <br><br><h1>  Information additionnelle </h1><br>  La visualisation des images g√©n√©r√©es au fur et √† mesure que vous apprenez <i>peut √©galement √™tre</i> effectu√©e dans Jupyter: il vous suffit de la d√©finir sur <i>true</i> lors de la cr√©ation d'une instance de ce crochet de visualisation: <br><br> <code>GANVisualizationHook(TENSORBOARD_PATH, trainer, 'trainer', jupyter=True, visual_iters=100</code> <br> <br>  Je pr√©f√®re laisser <i>faux</i> et utiliser simplement Tensorboard.  Croyez-moi, vous voulez aussi faire exactement cela.  De plus, si vous le laissez fonctionner trop longtemps, Jupyter mangera beaucoup de m√©moire avec de telles images. <br><br>  Les poids du mod√®le sont √©galement enregistr√©s automatiquement pendant les cycles d'entra√Ænement GANTrainer.  Par d√©faut, ils sont enregistr√©s toutes les 1000 it√©rations (c'est une op√©ration co√ªteuse).  Ils sont stock√©s dans le dossier racine que vous avez sp√©cifi√© pour la formation et le nom correspond √† save_base_name sp√©cifi√© dans le programme de formation.  Les poids sont stock√©s s√©par√©ment pour chaque taille d'entra√Ænement. <br><br>  Je recommanderais de parcourir le code de haut en bas, en commen√ßant par le Jupyter Notebook.  Je prends ces notes simplement comme une interface pratique pour le prototypage et la visualisation; tout le reste ira aux fichiers .py d√®s que je leur trouverai une place.  J'ai d√©j√† des exemples de visualisation que vous pouvez facilement activer et voir: ouvrez simplement xVisualization dans le Notebook, les images de test incluses dans le projet y sont list√©es (elles sont dans test_images). <br><br>  Si vous voyez les horaires GAN, c'est la chose la plus laide du projet, juste ma version de l'impl√©mentation GAN √† apprentissage progressif, adapt√©e au g√©n√©rateur Unet. <br><br>  Les poids pr√©-form√©s pour le g√©n√©rateur de colorant sont √©galement <a href="">ici</a> .  Le projet DeFade est toujours en cours, je vais essayer de mettre de bons poids dans quelques jours. <br><br>  Habituellement, pendant la formation, vous verrez les premiers bons r√©sultats √† mi-chemin, c'est-√†-dire avec une taille de 192 pixels (si vous utilisez les exemples de formation fournis). <br><br>  Je suis s√ªr que j'ai foir√© quelque part, alors faites-le moi savoir si c'est le cas. <br><br><h1>  Probl√®mes connus </h1><br><ul><li>  Il faut <b>jouer un</b> peu <b>avec la taille de l'image</b> pour obtenir le meilleur r√©sultat.  Le mod√®le souffre clairement d'un certain rapport d'aspect et rapport d'aspect lors de la g√©n√©ration d'images.  Auparavant, c'√©tait bien pire, mais la situation s'est consid√©rablement am√©lior√©e avec l'augmentation de l'√©clairage / du contraste et l'introduction de l'apprentissage progressif.  Je veux √©liminer compl√®tement ce probl√®me et me concentrer dessus, mais jusqu'√† pr√©sent, ne d√©sesp√©rez pas si l'image semble trop satur√©e ou avec des probl√®mes √©tranges.  Tr√®s probablement, tout deviendra normal apr√®s un petit redimensionnement.  En r√®gle g√©n√©rale, pour les images sursatur√©es, vous devez augmenter la taille. </li><li>  En plus de ce qui pr√©c√®de: obtenir les meilleures images se r√©sume vraiment √† l' <b>art de choisir les param√®tres optimaux</b> .  Oui, les r√©sultats sont s√©lectionn√©s manuellement.  Je suis tr√®s satisfait de la qualit√© et le mod√®le fonctionne de mani√®re assez fiable, mais pas parfaitement.  Le projet est toujours en cours!  Je pense que l'outil peut √™tre utilis√© comme un ¬´artiste IA¬ª, mais il n'est pas encore pr√™t pour le grand public.  Mais pas le temps. </li><li>  Pour compliquer la situation: √† l'heure actuelle, le mod√®le <b>mange brutalement de la m√©moire</b> , donc sur ma carte 1080Ti, il s'av√®re qu'il traite des images avec un maximum de 500-600px.  Je parie qu'il existe de nombreuses options d'optimisation ici, mais je ne l'ai pas encore fait. </li><li>  J'ai ajout√© un remplissage nul au g√©n√©rateur Unet pour tout ce qui ne correspond pas aux tailles attendues (c'est ainsi que je peux charger une image de taille arbitraire).  C'√©tait un hack tr√®s rapide, et cela conduit √† des bordures droites et inf√©rieures stupides √† la sortie d'images de test de taille arbitraire.  Je suis s√ªr qu'il existe un meilleur moyen, mais je ne l'ai pas encore trouv√©. </li><li>  Le mannequin <i>aime</i> les v√™tements bleus.  Je ne sais pas trop pourquoi; solution √† la recherche! </li></ul><br><h1>  Vous en voulez plus? </h1><br>  Je publierai de nouveaux r√©sultats <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur Twitter</a> . <br><br>  <i>Ajout du traducteur.</i> <br>  De ce dernier sur Twitter: <br><br>  <i>Les repr√©sentants de la nationalit√© eux-m√™mes √† leur pirogue, 1880</i> <br><br><img src="https://habrastorage.org/webt/pc/qb/sq/pcqbsqbpnwcxf2htl6sd4s8p1ki.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">original</a> ) <br><br>  <i>La construction du m√©tro de Londres, 1860</i> <br><br><img src="https://habrastorage.org/webt/k9/ag/td/k9agtdyfo6ugvfs0fencnkf4nge.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">original</a> ) <br><br>  <i>Les bidonvilles de Baltimore, 1938</i> <br><br><img src="https://habrastorage.org/webt/4i/2s/kt/4i2sktdre4ehitbtuybqzwocaia.jpeg"><br><br>  <i>Gym sur le Titanic, 1912</i> <br><br><img src="https://habrastorage.org/webt/ud/_v/vn/ud_vvn-6x0v3lcbx-khx_tvtey0.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">original</a> ) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428818/">https://habr.com/ru/post/fr428818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428808/index.html">Peu de commodit√© dans la vie √©tudiante</a></li>
<li><a href="../fr428810/index.html">18 documents sur la technologie num√©rique dans l'audio</a></li>
<li><a href="../fr428812/index.html">TypeScript: d√©s√©rialisation de JSON en classes avec validation de type sur les propri√©t√©s</a></li>
<li><a href="../fr428814/index.html">Appariement de produits √† l'aide d'Elasticsearch pour le service de surveillance des prix des concurrents</a></li>
<li><a href="../fr428816/index.html">Material Design: Shape - conseils pour am√©liorer l'interface graphique d'une application Android (et pas seulement) en changeant la forme des √©l√©ments</a></li>
<li><a href="../fr428820/index.html">Vous √™tes en 3D √† la troisi√®me personne: Oculus Go + Raspberry Pi</a></li>
<li><a href="../fr428822/index.html">L'histoire d'un petit piratage ou d'un bug ad√©quat Bounty d'un fournisseur Internet local</a></li>
<li><a href="../fr428824/index.html">T√©lescope au-del√† de raisonnable</a></li>
<li><a href="../fr428826/index.html">Iekaterinbourg √† travers les yeux d'un nouveau venu ou 5 ans apr√®s la premi√®re rencontre</a></li>
<li><a href="../fr428828/index.html">T√©l√©commande pour smartphone</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
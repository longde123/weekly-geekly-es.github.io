<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíß üì™ üìÆ Redes neurais com sensibilidade ao peso (WANN) üê± üóº üë®üèø‚Äçü§ù‚Äçüë®üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O novo trabalho do Google oferece uma arquitetura de redes neurais que podem simular os instintos e reflexos inatos dos seres vivos, seguidos de trein...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Redes neurais com sensibilidade ao peso (WANN)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/465369/"><p><img src="https://habrastorage.org/getpro/habr/post_images/ebf/c30/eca/ebfc30ecaa458eca2fe85d3c43956b47.png"></p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O</a> novo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho do Google</a> oferece uma arquitetura de redes neurais que podem simular os instintos e reflexos inatos dos seres vivos, seguidos de treinamento adicional ao longo da vida. </p><br><p>  E tamb√©m reduzindo significativamente o n√∫mero de conex√µes na rede, aumentando sua velocidade. </p><a name="habracut"></a><br><p>  As redes neurais artificiais, embora semelhantes em princ√≠pio √†s biol√≥gicas, ainda s√£o muito diferentes delas para serem usadas em sua forma pura para criar uma IA forte.  Por exemplo, agora √© imposs√≠vel criar um modelo de pessoa em um simulador (ou um mouse ou at√© mesmo um inseto), dar a ele um ‚Äúc√©rebro‚Äù na forma de uma rede neural moderna e trein√°-lo.  Isso simplesmente n√£o funciona. </p><br><p>  Mesmo tendo descartado as diferen√ßas no mecanismo de aprendizagem (no c√©rebro, n√£o existe um an√°logo exato do algoritmo de propaga√ß√£o de erro de retorno, por exemplo) e a falta de correla√ß√µes de tempo em v√°rias escalas, com base nas quais o c√©rebro biol√≥gico constr√≥i seu trabalho, as redes neurais artificiais t√™m v√°rios outros problemas que n√£o permitem simular suficientemente c√©rebro vivo.  √â prov√°vel que, devido a esses problemas inerentes ao aparato matem√°tico usado agora, o Aprendizado por Refor√ßo, projetado para imitar o m√°ximo poss√≠vel o treinamento de seres vivos com base na recompensa, na pr√°tica n√£o funcione t√£o bem quanto gostar√≠amos.  Embora seja baseado em id√©ias realmente boas e corretas.  Os pr√≥prios desenvolvedores brincam que o c√©rebro √© RNN + A3C (ou seja, uma rede recorrente + algoritmo cr√≠tico de ator para seu treinamento). </p><br><p>  Uma das diferen√ßas mais not√°veis ‚Äã‚Äãentre o c√©rebro biol√≥gico e as redes neurais artificiais √© que a estrutura do c√©rebro vivo √© pr√©-configurada por milh√µes de anos de evolu√ß√£o.  Embora o neoc√≥rtex, respons√°vel pela maior atividade nervosa nos mam√≠feros, tenha uma estrutura aproximadamente uniforme, a estrutura geral do c√©rebro √© claramente definida pelos genes.  Al√©m disso, outros animais que n√£o os mam√≠feros (p√°ssaros, peixes) n√£o possuem um neoc√≥rtex, mas ao mesmo tempo exibem um comportamento complexo que n√£o √© alcan√ß√°vel pelas redes neurais modernas.  Uma pessoa tamb√©m tem limita√ß√µes f√≠sicas na estrutura do c√©rebro, que s√£o dif√≠ceis de explicar.  Por exemplo, a resolu√ß√£o de um olho √© de aproximadamente 100 megapixels (~ 100 milh√µes de hastes e cones fotossens√≠veis), o que significa que, por dois olhos, o fluxo de v√≠deo deve ter cerca de 200 megapixels com uma frequ√™ncia de pelo menos 15 quadros por segundo.  Mas, na realidade, o nervo √≥ptico √© capaz de passar por si mesmo n√£o mais do que 2-3 megapixels.  E suas conex√µes s√£o direcionadas n√£o √† parte mais pr√≥xima do c√©rebro, mas √† parte occipital ao c√≥rtex visual. </p><br><p>  Portanto, sem prejudicar a import√¢ncia do neoc√≥rtex (grosso modo, pode ser considerado no nascimento como um an√°logo das redes neurais modernas iniciadas aleatoriamente), os fatos sugerem que mesmo uma pessoa desempenha um papel enorme em uma estrutura cerebral predeterminada.  Por exemplo, se um beb√™ tiver apenas alguns minutos para mostrar sua l√≠ngua, gra√ßas aos neur√¥nios-espelho, ele tamb√©m ficar√° com a l√≠ngua para fora.  O mesmo acontece com o riso das crian√ßas.  √â sabido que os beb√™s desde o nascimento foram ‚Äúcosturados‚Äù com excelente reconhecimento dos rostos humanos.  Mais importante, por√©m, o sistema nervoso de todos os seres vivos √© otimizado para suas condi√ß√µes de vida.  O beb√™ n√£o chorar√° por horas se estiver com fome.  Ele vai se cansar.  Ou com medo de alguma coisa e cale a boca.  A raposa n√£o alcan√ßar√° a exaust√£o at√© que a fome atinja uvas inacess√≠veis.  Ela far√° v√°rias tentativas, decide que ele √© amargo e vai embora.  E este n√£o √© um processo de aprendizado, mas um comportamento predefinido pela biologia.  Al√©m disso, diferentes esp√©cies t√™m diferentes.  Alguns predadores correm imediatamente para presas, enquanto outros ficam emboscados por um longo tempo.  E eles aprenderam isso n√£o por tentativa e erro, mas essa √© sua biologia, dada por instintos.  Da mesma forma, muitos animais usaram programas de preven√ß√£o de predadores desde os primeiros minutos de vida, embora ainda n√£o pudessem aprend√™-los fisicamente. </p><br><p>  Teoricamente, m√©todos modernos de treinamento de redes neurais s√£o capazes de criar uma semelhan√ßa com um c√©rebro pr√©-treinado, zerando conex√µes desnecess√°rias (de fato, cortando-as) e deixando apenas as necess√°rias.  Mas isso requer um grande n√∫mero de exemplos, n√£o se sabe como trein√°-los e, o que √© mais importante - no momento n√£o h√° boas maneiras de consertar essa estrutura "inicial" do c√©rebro.  O treinamento subsequente altera esses pesos e tudo d√° errado. </p><br><p>  Pesquisadores <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">do Google</a> tamb√©m fizeram essa pergunta.  √â poss√≠vel criar uma estrutura cerebral inicial semelhante √† biol√≥gica, isto √©, j√° bem otimizada para resolver o problema e depois apenas trein√°-lo novamente?  Teoricamente, isso reduzir√° drasticamente o espa√ßo de solu√ß√µes e permitir√° que voc√™ treine rapidamente redes neurais. </p><br><p>  Infelizmente, os algoritmos de otimiza√ß√£o da estrutura de rede existentes, como o Neural Architecture Search (NAS), operam em blocos inteiros.  Depois de adicionar ou remover qual, a rede neural deve ser treinada novamente do zero.  Este √© um processo que consome muitos recursos e n√£o resolve completamente o problema. </p><br><p>  Portanto, os pesquisadores propuseram uma vers√£o simplificada, denominada "Redes Neurais Agn√≥sticas por Peso" (WANN).  A id√©ia √© substituir todos os pesos de uma rede neural por um peso "comum".  E no processo de aprendizado, n√£o √© selecionar pesos entre os neur√¥nios, como nas redes neurais comuns, mas selecionar a estrutura da pr√≥pria rede (o n√∫mero e a localiza√ß√£o dos neur√¥nios), que com os mesmos pesos mostra os melhores resultados.  E depois disso, otimize-o para que a rede funcione bem com todos os valores poss√≠veis desse peso total (comum para todas as conex√µes entre neur√¥nios!). </p><br><p>  Como resultado, isso fornece a estrutura de uma rede neural, que n√£o depende de pesos espec√≠ficos, mas funciona bem com todos.  Porque funciona devido √† estrutura geral da rede.  Isso √© semelhante ao c√©rebro de um animal que ainda n√£o foi inicializado com escalas espec√≠ficas no nascimento, mas que j√° cont√©m instintos incorporados devido √† sua estrutura geral.  E o subsequente ajuste fino das escalas durante o treinamento ao longo da vida torna essa rede neural ainda melhor. </p><br><p>  Um efeito colateral positivo dessa abordagem √© uma diminui√ß√£o significativa no n√∫mero de neur√¥nios na rede (uma vez que permanecem apenas as conex√µes mais importantes), o que aumenta sua velocidade.  Abaixo est√° uma compara√ß√£o da complexidade de uma rede neural cl√°ssica totalmente conectada (esquerda) e de uma nova rede correspondente (direita). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ebf/c30/eca/ebfc30ecaa458eca2fe85d3c43956b47.png"></p><br><p>  Para procurar por essa arquitetura, os pesquisadores usaram o algoritmo de busca de topologia (NEAT).  Primeiro, um conjunto de redes neurais simples √© criado e, em seguida, √© executada uma das tr√™s a√ß√µes: um novo neur√¥nio √© adicionado √† conex√£o existente entre dois neur√¥nios, uma nova conex√£o com os aleat√≥rios √© adicionada a outro neur√¥nio ou a fun√ß√£o de ativa√ß√£o no neur√¥nio muda (veja as figuras abaixo).  E ent√£o, ao contr√°rio do NAS cl√°ssico, onde s√£o pesquisados ‚Äã‚Äãpesos √≥timos entre os neur√¥nios, aqui todos os pesos s√£o inicializados com um √∫nico n√∫mero.  E a otimiza√ß√£o √© realizada para encontrar a estrutura de rede que funciona melhor em uma ampla gama de valores desse peso total.  Assim, √© obtida uma rede que n√£o depende do peso espec√≠fico entre os neur√¥nios, mas funciona bem em toda a faixa (mas todos os pesos ainda s√£o iniciados por um n√∫mero e n√£o s√£o diferentes dos das redes normais).  Al√©m disso, como objetivo adicional de otimiza√ß√£o, eles tentam minimizar o n√∫mero de neur√¥nios na rede. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/097/a11/a58/097a11a5854d96c62b9af8c862c5f9a6.png"></p><br><p>  Abaixo est√° um esbo√ßo geral do algoritmo. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/c24/3ab/418/c243ab4183b3ac197c612382e60b8226.png"></p><br><ol><li>  cria uma popula√ß√£o de redes neurais simples </li><li>  cada rede inicializa todos os seus pesos com um n√∫mero e para uma ampla variedade de n√∫meros: w = -2 ... + 2 </li><li>  as redes resultantes s√£o classificadas pela qualidade da solu√ß√£o do problema e pelo n√∫mero de neur√¥nios (abaixo) </li><li>  na parte dos melhores representantes, um neur√¥nio √© adicionado, uma conex√£o ou a fun√ß√£o de ativa√ß√£o em um neur√¥nio muda </li><li>  estas redes modificadas s√£o usadas como iniciais no ponto 1) </li></ol><br><p>  Tudo isso √© bom, mas centenas, sen√£o milhares de id√©ias diferentes foram propostas para redes neurais.  Isso funciona na pr√°tica?  Sim sim.  Abaixo est√° um exemplo do resultado da pesquisa dessa arquitetura de rede para o problema cl√°ssico do carrinho pendular.  Como pode ser visto na figura, a rede neural funciona bem com todas as variantes do peso total (melhor com +1,0, mas tamb√©m tenta levantar o p√™ndulo de -1,5).  E depois de otimizar esse peso √∫nico, ele come√ßa a funcionar perfeitamente perfeitamente (op√ß√£o Pesos ajustados na figura). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/1c7/faa/ce2/1c7faace27a7ba5298a3d13ab2863f4d.gif"></p><br><p>  Normalmente, voc√™ pode treinar novamente esse peso total √∫nico, j√° que a sele√ß√£o da arquitetura √© feita em um n√∫mero discreto limitado de par√¢metros (no exemplo acima -2, -1,1,2).  E voc√™ pode obter um par√¢metro ideal mais preciso, digamos, 1,5.  E voc√™ pode usar o melhor peso total como ponto de partida para a reciclagem de todos os pesos, como no treinamento cl√°ssico de redes neurais. </p><br><p>  Isso √© semelhante a como os animais s√£o treinados.  Tendo instintos pr√≥ximos do ideal no nascimento, e usando essa estrutura cerebral dada pelos genes como inicial, durante o curso de sua vida, os animais treinam seu c√©rebro em condi√ß√µes externas espec√≠ficas.  Mais detalhes em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo recente na revista Nature</a> . </p><br><p>  Abaixo est√° um exemplo de uma rede encontrada pela WANN para uma tarefa de controle de m√°quina baseada em pixel.  Observe que este √© um passeio nos "instintos desencapados", com o mesmo peso total em todas as articula√ß√µes, sem o ajuste fino cl√°ssico de todos os pesos.  Ao mesmo tempo, a rede neural √© extremamente simples em estrutura. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ee0/ef6/da2/ee0ef6da26d15ba297396b2b4443a8a8.png"><img src="https://habrastorage.org/getpro/habr/post_images/9be/018/565/9be01856536220bfb09556265efb118a.gif"></p><br><p>  Os pesquisadores sugerem a cria√ß√£o de conjuntos de redes da WANN como outro caso de uso para a WANN.  Assim, a rede neural usual inicializada aleatoriamente no MNIST mostra uma precis√£o de cerca de 10%.  Uma rede neural √∫nica selecionada da WANN gera cerca de 80%, mas um conjunto da WANN com pesos totais diferentes j√° mostra&gt; 90%. </p><br><p>  Como resultado, o m√©todo proposto pelos pesquisadores do Google para procurar a arquitetura inicial de uma rede neural ideal n√£o apenas imita a aprendizagem animal (nascimento com instintos √≥timos internos e reciclagem na vida), mas tamb√©m evita a simula√ß√£o de toda a vida animal com o aprendizado completo de toda a rede nos algoritmos evolutivos cl√°ssicos, criando Redes simples e r√°pidas de uma s√≥ vez.  O que √© suficiente apenas para treinar um pouco para obter uma rede neural totalmente ideal. </p><br><h3 id="ssylki">  Refer√™ncias </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Entrada de blog do Google AI</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um artigo interativo no qual voc√™ pode alterar o peso total e monitorar o resultado</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigo da Nature sobre a import√¢ncia dos instintos incorporados no nascimento</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt465369/">https://habr.com/ru/post/pt465369/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt465359/index.html">Huawei CloudCampus: infraestrutura de servi√ßos de alta nuvem</a></li>
<li><a href="../pt465361/index.html">Encruzilhada digital de Kazan: como as tecnologias de seguran√ßa rodovi√°ria s√£o introduzidas na cidade</a></li>
<li><a href="../pt465363/index.html">Natas Web. Passagem da plataforma CTF destinada a explorar vulnerabilidades da Web. Parte 5</a></li>
<li><a href="../pt465365/index.html">Script de instala√ß√£o do Windows 10</a></li>
<li><a href="../pt465367/index.html">Quem n√£o escondeu - n√£o tenho culpa (hist√≥ria de sigilo na avia√ß√£o)</a></li>
<li><a href="../pt465371/index.html">C√°lculo da hip√≥tese nula, por exemplo, a an√°lise de sal√°rios de programadores ucranianos</a></li>
<li><a href="../pt465373/index.html">N√£o √© uma revis√£o do ASUS ZenBook Pro 15 UX580GE - quase um ano com quase o topo</a></li>
<li><a href="../pt465375/index.html">Venda de servidores dedicados na Holanda e Moscou</a></li>
<li><a href="../pt465377/index.html">Fa√ßa voc√™ mesmo o Skype</a></li>
<li><a href="../pt465379/index.html">Controle de bomba de insulina aut√¥nomo sem fio caseiro</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçõ üíï üë®üèº‚Äçüíº PNL. Lo basico. T√©cnicas Autodesarrollo. Parte 2: NER üõÄüèΩ ‚è´ ‚óÄÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La primera parte del art√≠culo sobre los conceptos b√°sicos de PNL se puede leer aqu√≠ . Hoy hablaremos sobre una de las tareas de PNL m√°s populares: el ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>PNL. Lo basico. T√©cnicas Autodesarrollo. Parte 2: NER</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/449514/">  La primera parte del art√≠culo sobre los conceptos b√°sicos de PNL se puede leer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .  Hoy hablaremos sobre una de las tareas de PNL m√°s populares: el reconocimiento de entidades con nombre (NER), y analizaremos en detalle la arquitectura de las soluciones a este problema. <br><br><img src="https://habrastorage.org/webt/fu/n9/-j/fun9-jbc0m4wmnvzwfwb7m4duui.png" alt="imagen"><br><a name="habracut"></a><br>  La tarea de NER es resaltar tramos de entidades en el texto (el lapso es un fragmento continuo de texto).  Supongamos que hay un texto de noticias y queremos resaltar las entidades que contiene (algunos conjuntos preestablecidos, por ejemplo, personas, ubicaciones, organizaciones, fechas, etc.).  La tarea del NER es comprender que la parte del texto " <i>1 de enero de 1997</i> " es la fecha, " <i>Kofi Annan</i> " es la persona y " <i>ONU</i> " es la organizaci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gk/ow/au/gkowauf-i0k8yz2y7m81y4yamiu.png"></div><br>  ¬øQu√© son las entidades nombradas?  En el primer escenario cl√°sico, que se formul√≥ en la conferencia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">MUC-6</a> en 1995, se trata de personas, ubicaciones y organizaciones.  Desde entonces, han aparecido varios paquetes disponibles, cada uno de los cuales tiene su propio conjunto de entidades con nombre.  Por lo general, se agregan nuevos tipos de entidad a personas, ubicaciones y organizaciones.  Los m√°s comunes son los num√©ricos (fechas, montos monetarios), as√≠ como las entidades miscel√°neas (de varios - otras entidades con nombre; un ejemplo es iPhone 6). <br><br><h2>  ¬øPor qu√© necesitas resolver el problema NER? </h2><br>  Es f√°cil entender que, incluso si somos capaces de identificar personas, ubicaciones y organizaciones en el texto, es poco probable que esto genere un gran inter√©s entre los clientes.  Aunque alguna aplicaci√≥n pr√°ctica, por supuesto, tiene el problema en el entorno cl√°sico. <br><br>  Uno de los escenarios en los que a√∫n puede ser necesaria una soluci√≥n al problema en la formulaci√≥n cl√°sica es la estructuraci√≥n de datos no estructurados.  Supongamos que tiene alg√∫n tipo de texto (o un conjunto de textos), y los datos de este deben ingresarse en una base de datos (tabla).  Las entidades con nombre cl√°sico pueden corresponder a filas de dicha tabla o servir como contenido de algunas celdas.  En consecuencia, para completar correctamente la tabla, primero debe seleccionar en el texto los datos que ingresar√° (generalmente despu√©s de esto hay otro paso: identificar las entidades en el texto, cuando entendemos que la <i>ONU</i> y <i>las Naciones Unidas se</i> extienden "Consulte la misma organizaci√≥n; sin embargo, la tarea de identificaci√≥n o vinculaci√≥n de la entidad es otra tarea, y no hablaremos de ello en detalle en esta publicaci√≥n). <br><br>  Sin embargo, hay varias razones por las cuales NER es una de las tareas de PNL m√°s populares. <br><br>  Primero, extraer entidades nombradas es un paso hacia la "comprensi√≥n" del texto.  Esto puede tener un valor independiente y ayudar a resolver mejor otras tareas de PNL. <br><br>  Entonces, si sabemos d√≥nde se resaltan las entidades en el texto, entonces podemos encontrar fragmentos del texto que son importantes para alguna tarea.  Por ejemplo, podemos seleccionar solo aquellos p√°rrafos donde se encuentran entidades de cierto tipo, y luego trabajar solo con ellos. <br><br>  Supongamos que recibe una carta, y ser√≠a bueno hacer un fragmento solo de esa parte donde hay algo √∫til, y no solo " <i>Hola, Ivan Petrovich</i> ".  Si puede distinguir entidades con nombre, puede hacer que el fragmento sea inteligente al mostrar esa parte de la carta donde se encuentran las entidades que nos interesan (y no solo mostrar la primera oraci√≥n de la carta, como se hace a menudo).  O simplemente puede resaltar en el texto las partes necesarias de la carta (o, directamente, las entidades que son importantes para nosotros) para la conveniencia de los analistas. <br><br>  Adem√°s, las entidades son colocaciones r√≠gidas y confiables; su selecci√≥n puede ser importante para muchas tareas.  Suponga que tiene un nombre para una entidad con nombre y, sea lo que sea, lo m√°s probable es que sea continua, y todas las acciones con ella deben realizarse como con un solo bloque.  Por ejemplo, traduzca el nombre de una entidad al nombre de una entidad.  Desea traducir <i>"Pyaterochka Shop"</i> al franc√©s en una sola pieza, y no dividirlo en varios fragmentos que no est√°n relacionados entre s√≠.  La capacidad de detectar colocaciones tambi√©n es √∫til para muchas otras tareas, por ejemplo, para el an√°lisis sint√°ctico. <br><br>  Sin resolver el problema NER, es dif√≠cil imaginar la soluci√≥n a muchos problemas de PNL, por ejemplo, resolver el pronombre an√°fora o construir sistemas de preguntas y respuestas.  El pronombre an√°fora nos permite entender a qu√© elemento del texto se refiere el pronombre.  Por ejemplo, queramos analizar el texto " <i>Encantador galopado en un caballo blanco".</i>  <i>La princesa sali√≥ corriendo a su encuentro y lo bes√≥</i> ".  Si destacamos la esencia de Persona en la palabra "Encanto", entonces la m√°quina ser√° mucho m√°s f√°cil de entender que la princesa probablemente no bes√≥ al caballo, sino al pr√≠ncipe de Encanto. <br><br>  Ahora damos un ejemplo de c√≥mo la asignaci√≥n de entidades nombradas puede ayudar en la construcci√≥n de sistemas de preguntas y respuestas.  Si hace la pregunta " <i>Qui√©n interpret√≥ el papel de Darth Vader en la pel√≠cula" El imperio contraataca "</i> " en su motor de b√∫squeda favorito ", entonces con una alta probabilidad obtendr√° la respuesta correcta.  Esto se hace simplemente aislando entidades con nombre: seleccionamos las entidades (pel√≠cula, rol, etc.), entendemos lo que se nos pide y luego buscamos la respuesta en la base de datos. <br><br>  Probablemente la consideraci√≥n m√°s importante debido a que la tarea NER es tan popular: la declaraci√≥n del problema es muy flexible.  En otras palabras, nadie nos obliga a seleccionar ubicaciones, personas y organizaciones.  Podemos seleccionar cualquier texto continuo que necesitemos que sea algo diferente del resto del texto.  Como resultado, puede elegir su propio conjunto de entidades para una tarea pr√°ctica espec√≠fica proveniente del cliente, marcar el cuerpo de textos con este conjunto y capacitar al modelo.  Tal escenario es omnipresente, y esto hace que NER sea una de las tareas de PNL m√°s frecuentemente realizadas en la industria. <br><br>  Dar√© un par de ejemplos de tales casos de clientes espec√≠ficos, en cuya soluci√≥n particip√©. <br><br>  Aqu√≠ est√° el primero: le permite tener un conjunto de facturas (transferencias de dinero).  Cada factura tiene una descripci√≥n de texto, que contiene la informaci√≥n necesaria sobre la transferencia (qui√©n, qui√©n, cu√°ndo, qu√© y por qu√© motivo enviado).  Por ejemplo, la compa√±√≠a X transfiri√≥ $ 10 a la compa√±√≠a Y en tal y tal fecha para tal y tal.  El texto es bastante formal, pero est√° escrito en un lenguaje vivo.  Los bancos tienen personas especialmente capacitadas que leen este texto y luego ingresan la informaci√≥n contenida en √©l en una base de datos. <br><br>  Podemos seleccionar un conjunto de entidades que corresponden a las columnas de la tabla en la base de datos (nombres de compa√±√≠as, cantidad de transferencia, su fecha, tipo de transferencia, etc.) y aprender c√≥mo seleccionarlas autom√°ticamente.  Despu√©s de esto, solo queda ingresar las entidades seleccionadas en la tabla, y las personas que previamente leyeron los textos e ingresaron informaci√≥n en la base de datos podr√°n realizar tareas m√°s importantes y √∫tiles. <br><br>  El segundo caso de usuario es este: necesita analizar cartas con pedidos de tiendas en l√≠nea.  Para hacer esto, debe conocer el n√∫mero de pedido (para que todas las letras relacionadas con este pedido puedan marcarse o colocarse en una carpeta separada), as√≠ como otra informaci√≥n √∫til: el nombre de la tienda, la lista de productos que se ordenaron, el monto del cheque, etc. Todo esto - n√∫meros de pedido, nombres de tiendas, etc. - pueden considerarse entidades con nombre, y tambi√©n es f√°cil aprender a distinguirlas utilizando los m√©todos que ahora analizaremos. <br><br><h2>  Si NER es tan √∫til, ¬øpor qu√© no se usa en todas partes? </h2><br>  ¬øPor qu√© la tarea NER no siempre se resuelve y los clientes comerciales todav√≠a est√°n dispuestos a pagar el dinero m√°s peque√±o por su soluci√≥n?  Parecer√≠a que todo es simple: comprender qu√© texto resaltar y resaltarlo. <br><br>  Pero en la vida, no todo es tan f√°cil, surgen varias dificultades. <br><br>  La complejidad cl√°sica que nos impide vivir en la resoluci√≥n de una variedad de problemas de PNL es todo tipo de ambig√ºedades en el lenguaje.  Por ejemplo, palabras polisem√°nticas y hom√≥nimos (ver ejemplos en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">parte 1</a> ).  Existe un tipo separado de homonimia que est√° directamente relacionado con la tarea NER: entidades completamente diferentes se pueden llamar la misma palabra.  Por ejemplo, tengamos la palabra " <i>Washington</i> ".  Que es esto  Persona, ciudad, estado, nombre de la tienda, nombre del perro, objeto, ¬øalgo m√°s?  Para resaltar esta secci√≥n del texto como una entidad espec√≠fica, se debe tener mucho en cuenta: el contexto local (de qu√© se trataba el texto anterior), el contexto global (conocimiento sobre el mundo).  Una persona tiene todo esto en cuenta, pero no es f√°cil ense√±arle a una m√°quina a hacer esto. <br><br>  La segunda dificultad es t√©cnica, pero no la subestimes.  No importa c√≥mo defina la esencia, lo m√°s probable es que haya algunos casos l√≠mite y dif√≠ciles: cuando necesita resaltar la esencia, cuando no necesita qu√© incluir en el tramo de la entidad y qu√© no, etc. (por supuesto, si nuestra esencia es no es algo ligeramente variable, como un correo electr√≥nico; sin embargo, generalmente puede distinguir tales entidades triviales por m√©todos triviales: escriba una expresi√≥n regular y no piense en ning√∫n tipo de aprendizaje autom√°tico). <br><br>  Supongamos, por ejemplo, que queremos resaltar los nombres de las tiendas. <br><br>  En el texto "La <i>tienda de detectores de metales profesionales le da la bienvenida</i> ", es casi seguro que queremos incluir la palabra "tienda" en nuestra esencia, esto es claramente parte del nombre. <br><br>  Otro ejemplo es " <i>Te da la bienvenida Volkhonka Prestige, tu tienda de marca favorita a precios asequibles</i> ".  Probablemente, la palabra "tienda" no debe incluirse en la anotaci√≥n; esto claramente no es parte del nombre, sino simplemente su descripci√≥n.  Adem√°s, si incluye esta palabra en el nombre, tambi√©n debe incluir las palabras "- su favorito", y esto, tal vez, no quiero hacer nada. <br><br>  El tercer ejemplo: <i>"La tienda de mascotas de Nemo te escribe</i> " <i>.</i>  No est√° claro si la "tienda de mascotas" es parte del nombre o no.  En este ejemplo, parece que cualquier elecci√≥n ser√° adecuada.  Sin embargo, es importante que tengamos que hacer esta elecci√≥n y corregirla en las instrucciones para los marcadores, de modo que en todos los textos tales ejemplos se marquen de manera equitativa (si esto no se hace, el aprendizaje autom√°tico inevitablemente comenzar√° a cometer errores debido a contradicciones en el marcado). <br><br>  Existen muchos ejemplos de este tipo, y si queremos que el marcado sea consistente, todos ellos deben incluirse en las instrucciones para los marcadores.  Incluso si los ejemplos en s√≠ mismos son simples, deben tenerse en cuenta y calcularse, y esto har√° que la instrucci√≥n sea m√°s grande y m√°s complicada. <br><br>  Bueno, cuanto m√°s complicadas sean las instrucciones, all√≠ necesitar√°s marcadores m√°s calificados.  Una cosa es que el escriba necesita determinar si la letra es el texto del pedido o no (aunque aqu√≠ hay sutilezas y casos l√≠mite), y otra cosa es que el escriba necesita leer las instrucciones de 50 p√°ginas, encontrar entidades espec√≠ficas, entender qu√© incluir en anotaci√≥n y qu√© no. <br><br>  Los marcadores expertos son caros y, por lo general, no funcionan muy r√°pido.  Seguramente gastar√° el dinero, pero no es un hecho que obtenga el margen de beneficio perfecto, porque si las instrucciones son complejas, incluso una persona calificada puede cometer un error y malinterpretar algo.  Para combatir esto, se utiliza el marcado m√∫ltiple del mismo texto por diferentes personas, lo que aumenta a√∫n m√°s el precio de marcado y el tiempo para el que est√° preparado.  Evitar este proceso o incluso reducirlo seriamente no funcionar√°: para aprender, debe tener un conjunto de capacitaci√≥n de alta calidad de tama√±os razonables. <br><br>  Estas son las dos razones principales por las cuales NER a√∫n no ha conquistado el mundo y por qu√© los manzanos a√∫n no crecen en Marte. <br><br><h2>  C√≥mo entender si el problema NER se ha resuelto de manera de calidad </h2><br>  Le contar√© un poco sobre las m√©tricas que las personas usan para evaluar la calidad de su soluci√≥n al problema NER y sobre los casos est√°ndar. <br><br>  La m√©trica principal para nuestra tarea es una estricta medida f.  Explica qu√© es. <br><br>  Tengamos un marcado de prueba (el resultado del trabajo de nuestro sistema) y un est√°ndar (marcado correcto de los mismos textos).  Entonces podemos contar dos m√©tricas: precisi√≥n e integridad.  La precisi√≥n es la fracci√≥n de entidades positivas verdaderas (es decir, entidades seleccionadas por nosotros en el texto, que tambi√©n est√°n presentes en el est√°ndar), en relaci√≥n con todas las entidades seleccionadas por nuestro sistema.  Y la integridad es la fracci√≥n de entidades positivas verdaderas con respecto a todas las entidades presentes en el est√°ndar.  Un ejemplo de un clasificador muy preciso pero incompleto es un clasificador que selecciona un objeto correcto en el texto y nada m√°s.  Un ejemplo de un clasificador muy completo, pero generalmente inexacto, es un clasificador que selecciona una entidad en cualquier segmento del texto (por lo tanto, adem√°s de todas las entidades est√°ndar, nuestro clasificador asigna una gran cantidad de basura). <br><br>  La medida F es la media arm√≥nica de precisi√≥n e integridad, una m√©trica est√°ndar. <br><br>  Como describimos en la secci√≥n anterior, crear marcas es costoso.  Por lo tanto, no hay muchos edificios accesibles con un marcado. <br><br>  Existe cierta variedad para el idioma ingl√©s: hay conferencias populares donde las personas compiten para resolver el problema NER (y se crea un marcado para las competiciones).  Ejemplos de tales conferencias en las que se crearon sus cuerpos con entidades nombradas son MUC, TAC, CoNLL.  Todos estos casos consisten casi exclusivamente en textos de noticias. <br><br>  El cuerpo principal en el que se eval√∫a la calidad de la resoluci√≥n del problema NER es el caso CoNLL 2003 (aqu√≠ hay un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace al caso en s√≠</a> , aqu√≠ hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo al respecto</a> ).  Hay aproximadamente 300 mil tokens y hasta 10 mil entidades.  Ahora los sistemas SOTA (estado del arte, es decir, los mejores resultados en este momento) muestran en este caso una medida f del orden de 0,93. <br><br>  Para el idioma ruso, todo es mucho peor.  Hay un organismo p√∫blico ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">FactRuEval 2016</a> , aqu√≠ hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo al respecto</a> , aqu√≠ hay <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo sobre Habr√©</a> ), y es muy peque√±o: solo hay 50 mil tokens.  En este caso, el caso es bastante espec√≠fico.  En particular, la esencia bastante controvertida de LocOrg (ubicaci√≥n en un contexto organizacional) se destaca en el caso, que se confunde con las organizaciones y las ubicaciones, como resultado de lo cual la calidad de la selecci√≥n de este √∫ltimo es menor de lo que podr√≠a ser. <br><br><h2>  C√≥mo resolver el problema NER </h2><br><h3>  Reducci√≥n del problema de NER al problema de clasificaci√≥n </h3><br>  A pesar del hecho de que las entidades a menudo son detalladas, la tarea NER generalmente se reduce al problema de clasificaci√≥n a nivel de token, es decir, cada token pertenece a una de varias clases posibles.  Hay varias formas est√°ndar de hacer esto, pero la m√°s com√∫n se llama esquema BIOES.  El esquema consiste en agregar alg√∫n prefijo a la etiqueta de la entidad (por ejemplo, PER para personas u ORG para organizaciones), que indica la posici√≥n del token en el lapso de la entidad.  M√°s detalles: <br><br>  B, desde el comienzo de la palabra, el primer token en el lapso de la entidad, que consta de m√°s de 1 palabra. <br>  Yo, de las palabras dentro, esto es lo que est√° en el medio. <br>  E: desde el final de la palabra, este es el √∫ltimo token de la entidad, que consta de m√°s de 1 elemento. <br>  S es soltero.  Agregamos este prefijo si la entidad consta de una palabra. <br><br>  Por lo tanto, agregamos uno de los 4 posibles prefijos a cada tipo de entidad.  Si el token no pertenece a ninguna entidad, se marca con una etiqueta especial, generalmente etiquetada como OUT u O. <br><br>  Damos un ejemplo.  Tengamos el texto " <i>Karl Friedrich Jerome von Munchausen naci√≥ en Bodenwerder</i> ".  Aqu√≠ hay una entidad detallada: la persona "Karl Friedrich Jerome von M√ºnhausen" y una de una palabra: la ubicaci√≥n "Bodenwerder". <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ia/gp/2f/iagp2fausaarttfscowpqo8xpic.png"></div><br><br>  Por lo tanto, BIOES es una forma de mapear proyecciones de tramos o anotaciones al nivel de token. <br><br>  Est√° claro que con este marcado podemos establecer inequ√≠vocamente los l√≠mites de todas las anotaciones de entidad.  De hecho, sobre cada token, sabemos si es cierto que una entidad comienza con este token o termina en √©l, lo que significa si finalizar la anotaci√≥n de la entidad en un token dado o extenderlo a los siguientes tokens. <br><br>  La gran mayor√≠a de los investigadores utilizan este m√©todo (o sus variaciones con menos etiquetas: BIOE o BIO), pero tiene varios inconvenientes importantes.  La principal es que el esquema no permite trabajar con entidades anidadas o que se cruzan.  Por ejemplo, la esencia de la " <i>Universidad Estatal de Mosc√∫ lleva el nombre de M.V.</i>  <i>Lomonosov</i> ‚Äùes una organizaci√≥n.  Pero Lomonosov en s√≠ mismo es una persona, y tambi√©n ser√≠a bueno preguntar en el marcado.  Usando el m√©todo de marcado descrito anteriormente, nunca podemos transmitir estos dos hechos al mismo tiempo (porque solo podemos hacer una marca en un token).  En consecuencia, el token "Lomonosov" puede ser parte de la anotaci√≥n de la organizaci√≥n, o parte de la anotaci√≥n de la persona, pero nunca ambas al mismo tiempo. <br><br>  Otro ejemplo de entidades integradas: " <i>Departamento de L√≥gica Matem√°tica y Teor√≠a de Algoritmos de la Facultad de Mec√°nica y Matem√°ticas de la Universidad Estatal de Mosc√∫</i> ".  Aqu√≠, idealmente, me gustar√≠a distinguir 3 organizaciones anidadas, pero el m√©todo de marcado anterior le permite seleccionar 3 entidades disjuntas o una entidad que anota el fragmento completo. <br><br>  Adem√°s de la forma est√°ndar de reducir la tarea a la clasificaci√≥n a nivel de token, tambi√©n hay un formato de datos est√°ndar en el que es conveniente almacenar el marcado para la tarea NER (as√≠ como para muchas otras tareas de PNL).  Este formato se llama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CoNLL-U</a> . <br><br>  La idea principal del formato es esta: almacenamos los datos en forma de una tabla, donde una fila corresponde a un token, y las columnas corresponden a un tipo espec√≠fico de atributos de token (incluida la palabra en s√≠, la forma de la palabra).  En un sentido estricto, el formato CoNLL-U define qu√© tipos de caracter√≠sticas (es decir, columnas) se incluyen en la tabla, un total de 10 tipos de caracter√≠sticas para cada token.  Pero los investigadores generalmente consideran que el formato es m√°s amplio e incluyen los tipos de caracter√≠sticas que se necesitan para una tarea particular y un m√©todo para resolverlo. <br><br>  A continuaci√≥n se muestra un ejemplo de datos en un formato tipo CoNLL-U, donde se consideran 6 tipos de atributos: n√∫mero de la oraci√≥n actual en el texto, forma de la palabra (es decir, la palabra en s√≠), lema (forma de la palabra inicial), etiqueta POS (parte del discurso), morfol√≥gico caracter√≠sticas de la palabra y, finalmente, la etiqueta de la entidad asignada en este token. <br><br><img src="https://habrastorage.org/webt/yb/ue/th/ybuethtundoox6j79pt_yofveuq.png" alt="imagen"><br><br><h3>  ¬øC√≥mo resolviste el problema NER antes? </h3><br>  Estrictamente hablando, el problema se puede resolver sin aprendizaje autom√°tico, con la ayuda de sistemas basados ‚Äã‚Äãen reglas (en la versi√≥n m√°s simple, con la ayuda de expresiones regulares).  Esto parece anticuado e ineficaz, sin embargo, debe comprender si su √°rea tem√°tica es limitada y est√° claramente definida y si la entidad, por s√≠ misma, no tiene mucha variabilidad, entonces el problema NER se resuelve utilizando m√©todos basados ‚Äã‚Äãen reglas de manera bastante r√°pida y eficiente. <br><br> ,         (,     ),        ,        . <br><br> ,          (      ),      .                   . <br><br>    ,      2000-  SOTA        .   ,   . <br><br><h3>  </h3><br>   ,       ‚Äî . .    .  ,          ( ),         1,      0. <br><br>  ,         (POS-),   (     ‚Äî , ,      ),  (. .    ),  (,    ),        . <br><br>   ,        , : <br><br><ul><li> ‚Äú  ,  ‚Äù, </li><li> ‚Äú  ‚Äù, </li><li> ‚Äú  ‚Äù, </li><li>   ‚Äú ‚Äù ( ,  ,   ‚ÄúiPhone‚Äù). </li></ul><br>     ,        ,    - ,     ‚Äî     . <br><br>   ,    ‚Äì  .  ,  , ,  ‚Äì  , , ,   ‚Äì ,  , ,   ‚Äì .  ,          (‚Äú‚Äù     ,  ‚Äú‚Äù ‚Äî  ),     . , ,   ,       ‚Äî       ( ,      NER   2  ‚Äî      ). <br><br>   ,     NER,    ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nadeau and Sekine (2007), A survey of Named Entity Recognition and Classification</a> . ,   , ,  (       -  , , ,    HMM,    , , ,  ),        . <br><br>        (summarized pattern   ).           NLP. ,  2018   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a>    (word shape)     . <br><br><h2>    NER   ? </h2><br><h3> NLP almost from scratch </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El primer intento exitoso de resolver el problema NER utilizando redes neuronales se </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">realiz√≥ en 2011</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En el momento de la publicaci√≥n de este art√≠culo, mostr√≥ un resultado SOTA en el paquete CoNLL 2003. Pero debe comprender que la superioridad del modelo en comparaci√≥n con los sistemas basados ‚Äã‚Äãen algoritmos cl√°sicos de aprendizaje autom√°tico era bastante insignificante. En los pr√≥ximos a√±os, los m√©todos basados ‚Äã‚Äãen ML cl√°sico mostraron resultados comparables a los m√©todos de redes neuronales.</font></font><br><br>        NER   ,      ,       NLP   . ,      ,   , ,     .        ,     NER ( ,    NLP). <br><br>     ,   . <br><br>     ,       : <br><br><ul><li>   ¬´¬ª   (window based approach), </li><li>      (sentence based approach). </li></ul><br>      ‚Äì   ,      ‚Äì ,    ..    ,   . <br><br>        : , ‚Äú <i>The cat sat on the mat</i> ‚Äù. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pb/n1/mo/pbn1mo7pfdzlc8aay2xm9lz3tse.png"></div><br><br>    K      (,     ,  , ,           . .).        (,       ,  1         ).  Dejar <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="imagen"> ‚Äî  ,   i-  j-   . <br><br>  ,   sentence based approach   ,   ,   ‚Äî   ,     .       i  i-core,  core ‚Äî  ,         (    ,        ,    ). <br><br>      ‚Äî   <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="imagen">   <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="imagen"> ,   Lookup Table (    ‚Äú‚Äù  ). ,    <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="imagen"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es un vector booleano en el que en un lugar cuesta 1, y en otros lugares es 0. Por lo tanto, al multiplicar</font></font><img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="imagen">  en <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="imagen"> ,        .        .  <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="imagen"> ( i     1  K) ‚Äì    ,        . <br><br>              word2vec (   ,     word2vec,     )  ,      ,   word2vec            (   ). <br><br>  ,       ,      <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="imagen">  en <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="imagen">  . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ahora entenderemos c√≥mo se usan estos signos en el enfoque basado en oraciones (basado en ventanas es ideol√≥gicamente m√°s simple). Es importante que lancemos nuestra arquitectura por separado para cada token (es decir, para la oraci√≥n "El gato se sent√≥ en el tapete", lanzaremos nuestra red 6 veces). Los signos en cada ejecuci√≥n se recopilan de la misma manera, con la excepci√≥n del signo responsable de la posici√≥n del token cuya etiqueta estamos tratando de determinar: el token central.</font></font><br><br>                  : 3-5.     ,    ,         (    ).       m  f,  m ‚Äî  ,        (. .       ),  f ‚Äî   . <br><br>        ,      ‚Äî    max pooling (. .          ),      f.  ,  ,   ,         core,     (max pooling   ,         ,        ).  ‚Äú ‚Äù             ,  ,      core. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Luego, pasamos el vector a trav√©s de un perceptr√≥n multicapa con algunas funciones de activaci√≥n (en el art√≠culo - HardTanh), y como √∫ltima capa usamos un softmax totalmente conectado de dimensi√≥n d, donde d es el n√∫mero de posibles etiquetas de token. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Por lo tanto, la capa convolucional nos permite recopilar la informaci√≥n contenida en la ventana de dimensi√≥n del filtro, agrupando - seleccionar la informaci√≥n m√°s caracter√≠stica en la oraci√≥n (comprimi√©ndola en un vector), y la capa softmax - nos permite determinar qu√© etiqueta tiene el token de n√∫mero central.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> CharCNN-BLSTM-CRF </font></font></h3><br>     CharCNN-BLSTM-CRF,    ,   SOTA   2016-2018 ( 2018        ,    NLP     ;      ).     NER       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lample et al (2016)</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ma &amp; Hovy (2016)</a> . <br><br>     ,    NLP,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">   </a> . <br><br>   -     .      .  ‚Äì   ,  ‚Äì  ,  ‚Äî  :   ,    . .       -  . <br><br>         .    ,    ,      .   ‚Äî              .    Lookup-   ,       ,   . <br><br>  ,    . <br><br>    ,   .   ‚Äî          ,     ,     (        ,    ). <br><br>      CharCNN ( ,     CharRNN).   ,    - .        -     (, 20) ‚Äî  .    ,        ‚Äî        ,      . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/29/n7/t3/29n7t3o1ebdon6m7hfnmgqec3gu.png"></div><br><br> ,       ,    ,    , ‚Äî  (    ).          -  ,           . <br><br>  2  . <br><br>      ‚Äì    (     CharCNN).      ,        sentence based approach   . <br><br> ,             (, 3),     .     max pooling,  1    .                  . <br><br>         ‚Äì       (BLSTM  BiGRU;   ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">   </a> ).             RNN. <br><br> ,    -   .      - . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nm/og/oi/nmogoisze82tw_mm6r-dvs52jh0.png"></div><br><br>     BLSTM  BiGRU.  i-     ,        RNN.             (    RNN),     (    RNN).     -  . <br><br>         NLP,       NLP. <br><br> , ,   NER.  -   ,          .     . <br><br>      ‚Äì        softmax  d,  d ‚Äî    .            (      ). <br><br>   ,     ‚Äî        .        BiRNN,         ,     . ,      I-PER    B-PER  I-PER. <br><br>        ‚Äî  CRF (conditional random fields).     ,    ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a>   ),  ,  CRF     ,       . <br><br> ,    CharCNN-BLSTM-CRF,   SOTA   NER        2018 . <br><br>         .    CharCNN   f-   1%, CRF ‚Äî  1-1.5%,          (       multi-task learning,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wu et al (2018)</a> ). BiRNN ‚Äî  , , ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> . <br><br><hr><br> ,          NER.    ,   ,           . <br><br> <i> , <br>  NLP Advanced Research Group</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/449514/">https://habr.com/ru/post/449514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../449500/index.html">¬øC√≥mo no entrar en p√°nico si muchos programadores vienen de visita?</a></li>
<li><a href="../449502/index.html">Antig√ºedades: videocasete incre√≠ble</a></li>
<li><a href="../449506/index.html">Descripci√≥n general: seis formas de usar representantes residentes para resolver problemas corporativos</a></li>
<li><a href="../449508/index.html">10 caracter√≠sticas √∫tiles de R que quiz√°s no conozcas</a></li>
<li><a href="../449510/index.html">.NET: las partes buenas: del CLR a la comunidad</a></li>
<li><a href="../449516/index.html">Prepar√°ndose para el hackathon: c√≥mo exprimirse en un m√°ximo de 48 horas</a></li>
<li><a href="../449518/index.html">Selecci√≥n: 5 servicios √∫tiles para escribir art√≠culos en ingl√©s</a></li>
<li><a href="../449520/index.html">C√≥mo le ense√±√© a una neurona en un "dinosaurio" a jugar</a></li>
<li><a href="../449522/index.html">Reflexiones sobre el elixir: ventajas y desventajas de la herramienta m√°s popular para desarrolladores de alta carga</a></li>
<li><a href="../449524/index.html">Distinguir caracteres de basura: c√≥mo construir modelos robustos de redes neuronales en tareas de OCR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
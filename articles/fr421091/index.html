<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç± ‚ûø üßù Comment nous avons r√©duit le temps de d√©veloppement des mod√®les de notation √† cinq reprises en passant √† Python üìº üß• üëÇüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Maintenant, tout le monde parle beaucoup de l'intelligence artificielle et de son application dans tous les domaines de l'entreprise. Cependant, il ex...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment nous avons r√©duit le temps de d√©veloppement des mod√®les de notation √† cinq reprises en passant √† Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/idfinance/blog/421091/"><img src="https://habrastorage.org/webt/-z/kh/d3/-zkhd3-g2bfo-piumvjuva0iei4.png" alt="image"><br><br>  Maintenant, tout le monde parle beaucoup de l'intelligence artificielle et de son application dans tous les domaines de l'entreprise.  Cependant, il existe certains domaines o√π, depuis l'Antiquit√©, un type de mod√®le a domin√©, la soi-disant ¬´bo√Æte blanche¬ª - la r√©gression logistique.  L'un de ces domaines est la notation du cr√©dit bancaire. <br><a name="habracut"></a><br>  Il y a plusieurs raisons √† cela: <br><br><ul><li>  Les coefficients de r√©gression peuvent √™tre facilement expliqu√©s, contrairement aux bo√Ætes noires comme le boosting, qui peuvent inclure plus de 500 variables </li><li>  L'apprentissage automatique n'est toujours pas approuv√© par la direction en raison de la difficult√© d'interpr√©tation des mod√®les </li><li>  Il existe des exigences non √©crites du r√©gulateur pour l'interpr√©tabilit√© des mod√®les: √† tout moment, par exemple, la Banque centrale peut demander une explication - pourquoi un pr√™t √† l'emprunteur a √©t√© refus√© </li><li> Les entreprises utilisent des programmes externes d'exploration de donn√©es (par exemple, mineur rapide, SAS Enterprise Miner, STATISTICA ou tout autre package) qui vous permettent d'apprendre rapidement √† construire des mod√®les, m√™me sans comp√©tences en programmation </li></ul><br>  Ces raisons font qu'il est presque impossible d'utiliser des mod√®les complexes d'apprentissage automatique dans certains domaines, il est donc important de pouvoir ¬´tirer le maximum¬ª d'une simple r√©gression logistique, qui est facile √† expliquer et √† interpr√©ter. <br><br>  Dans cet article, nous expliquerons comment, lors de la cr√©ation du scoring, nous avons abandonn√© les packages d'exploration de donn√©es externes au profit de solutions open source sous la forme de Python, augment√© plusieurs fois la vitesse de d√©veloppement et am√©lior√© la qualit√© de tous les mod√®les. <br><br><h3>  Processus de notation </h3><br>  Le processus classique de construction de mod√®les de notation sur la r√©gression ressemble √† ceci: <br><br><img src="https://habrastorage.org/webt/jn/e2/da/jne2da4ifmsjuhgui2piws8kbsi.png" alt="image"><br><br>  Elle peut varier d'une entreprise √† l'autre, mais les principales √©tapes restent constantes.  Nous devons toujours effectuer un regroupement de variables (contrairement au paradigme d'apprentissage automatique, o√π dans la plupart des cas, seul un codage cat√©goriel est n√©cessaire), leur filtrage par valeur d'information (IV) et le t√©l√©chargement manuel de tous les coefficients et bacs pour une int√©gration ult√©rieure dans DSL. <br>  Cette approche de la cr√©ation de cartes de notation a bien fonctionn√© dans les ann√©es 90, mais les technologies des packages classiques d'exploration de donn√©es sont tr√®s d√©pass√©es et ne permettent pas l'utilisation de nouvelles techniques, telles que, par exemple, la r√©gularisation L2 en r√©gression, ce qui peut am√©liorer consid√©rablement la qualit√© des mod√®les. <br><br>  √Ä un moment donn√©, en tant qu'√©tude, nous avons d√©cid√© de reproduire toutes les √©tapes que les analystes effectuent lors de la cr√©ation du score, de les compl√©ter avec les connaissances des Data Scientists et d'automatiser autant que possible l'ensemble du processus. <br><br><h3>  Am√©lioration de Python </h3><br>  En tant qu'outil de d√©veloppement, nous avons choisi Python pour sa simplicit√© et ses bonnes biblioth√®ques, et avons commenc√© √† jouer toutes les √©tapes dans l'ordre. <br><br>  La premi√®re √©tape consiste √† collecter des donn√©es et √† g√©n√©rer des variables - cette √©tape est une partie importante du travail des analystes. <br><br>  En Python, vous pouvez charger les donn√©es collect√©es √† partir de la base de donn√©es √† l'aide de pymysql. <br><br><div class="spoiler">  <b class="spoiler_title">Code √† t√©l√©charger depuis la base de donn√©es</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">con</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> conn = pymysql.connect( host=<span class="hljs-string"><span class="hljs-string">'10.100.10.100'</span></span>, port=<span class="hljs-number"><span class="hljs-number">3306</span></span>, user=<span class="hljs-string"><span class="hljs-string">'******* '</span></span>, password=<span class="hljs-string"><span class="hljs-string">'*****'</span></span>, db=<span class="hljs-string"><span class="hljs-string">'mysql'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> conn; df = pd.read_sql(<span class="hljs-string"><span class="hljs-string">''' SELECT * FROM idf_ru.data_for_scoring '''</span></span>, con=con())</code> </pre> <br></div></div><br>  Ensuite, nous rempla√ßons les valeurs rares et manquantes par une cat√©gorie distincte pour emp√™cher le suram√©nagement, s√©lectionnons la cible, supprimons les colonnes suppl√©mentaires et divisons par train et test. <br><br><div class="spoiler">  <b class="spoiler_title">Pr√©paration des donn√©es</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">filling</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df)</span></span></span><span class="hljs-function">:</span></span> cat_vars = df.select_dtypes(include=[object]).columns num_vars = df.select_dtypes(include=[np.number]).columns df[cat_vars] = df[cat_vars].fillna(<span class="hljs-string"><span class="hljs-string">'_MISSING_'</span></span>) df[num_vars] = df[num_vars].fillna(np.nan) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">replace_not_frequent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, cols, perc_min=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, value_to_replace = </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"_ELSE_"</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> else_df = pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'var'</span></span>, <span class="hljs-string"><span class="hljs-string">'list'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> cols: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i != <span class="hljs-string"><span class="hljs-string">'date_requested'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> i != <span class="hljs-string"><span class="hljs-string">'credit_id'</span></span>: t = df[i].value_counts(normalize=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) q = list(t[t.values &lt; perc_min/<span class="hljs-number"><span class="hljs-number">100</span></span>].index) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> q: else_df = else_df.append(pd.DataFrame([[i, q]], columns=[<span class="hljs-string"><span class="hljs-string">'var'</span></span>, <span class="hljs-string"><span class="hljs-string">'list'</span></span>])) df.loc[df[i].value_counts(normalize=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)[df[i]].values &lt; perc_min/<span class="hljs-number"><span class="hljs-number">100</span></span>, i] =value_to_replace else_df = else_df.set_index(<span class="hljs-string"><span class="hljs-string">'var'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df, else_df cat_vars = df.select_dtypes(include=[object]).columns df = filling(df) df, else_df = replace_not_frequent_2(df, cat_vars) df.drop([<span class="hljs-string"><span class="hljs-string">'credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'target_value'</span></span>, <span class="hljs-string"><span class="hljs-string">'bor_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bchg_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'last_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bcacr_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bor_bonuses_got'</span></span> ], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=<span class="hljs-number"><span class="hljs-number">0.33</span></span>, stratify=df.y, random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>)</code> </pre> <br></div></div><br>  Commence maintenant l'√©tape la plus importante de la notation pour la r√©gression - vous devez √©crire le regroupement WOE pour les variables num√©riques et cat√©gorielles.  Dans le domaine public, nous n'avons pas trouv√© de bonnes et adapt√©es options pour nous et avons d√©cid√© de nous √©crire.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cet</a> article de 2017 a √©t√© pris comme base du binning num√©rique, ainsi que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cela</a> , cat√©gorique, ont-ils √©crit eux-m√™mes √† partir de z√©ro.  Les r√©sultats √©taient impressionnants (Gini sur le test a augment√© de 3 √† 5 par rapport aux algorithmes de binning des programmes externes d'exploration de donn√©es). <br><br>  Apr√®s cela, vous pouvez regarder les graphiques ou les tableaux (que nous √©crivons ensuite en excel) comment les variables sont divis√©es en groupes et v√©rifier la monotonie: <br><br><img src="https://habrastorage.org/webt/da/ij/2u/daij2uewkyujfn3jhdapc-yyfia.png" alt="image"><br><br><img src="https://habrastorage.org/webt/c6/if/3u/c6if3uqy--eqewru4nm9au1gwgw.png" alt="image"><br><br><div class="spoiler">  <b class="spoiler_title">Rendu des graphiques Bean</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_bin</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ev, for_excel=False)</span></span></span><span class="hljs-function">:</span></span> ind = np.arange(len(ev.index)) width = <span class="hljs-number"><span class="hljs-number">0.35</span></span> fig, ax1 = plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>)) ax2 = ax1.twinx() p1 = ax1.bar(ind, ev[<span class="hljs-string"><span class="hljs-string">'NONEVENT'</span></span>], width, color=(<span class="hljs-number"><span class="hljs-number">24</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">192</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">196</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>)) p2 = ax1.bar(ind, ev[<span class="hljs-string"><span class="hljs-string">'EVENT'</span></span>], width, bottom=ev[<span class="hljs-string"><span class="hljs-string">'NONEVENT'</span></span>], color=(<span class="hljs-number"><span class="hljs-number">246</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">115</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>)) ax1.set_ylabel(<span class="hljs-string"><span class="hljs-string">'Event Distribution'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">15</span></span>) ax2.set_ylabel(<span class="hljs-string"><span class="hljs-string">'WOE'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">15</span></span>) plt.title(list(ev.VAR_NAME)[<span class="hljs-number"><span class="hljs-number">0</span></span>], fontsize=<span class="hljs-number"><span class="hljs-number">20</span></span>) ax2.plot(ind, ev[<span class="hljs-string"><span class="hljs-string">'WOE'</span></span>], marker=<span class="hljs-string"><span class="hljs-string">'o'</span></span>, color=<span class="hljs-string"><span class="hljs-string">'blue'</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Legend plt.legend((p2[0], p1[0]), ('bad', 'good'), loc='best', fontsize=10) #Set xticklabels q = list() for i in range(len(ev)): try: mn = str(round(ev.MIN_VALUE[i], 2)) mx = str(round(ev.MAX_VALUE[i], 2)) except: mn = str((ev.MIN_VALUE[i])) mx = str((ev.MAX_VALUE[i])) q.append(mn + '-' + mx) plt.xticks(ind, q, rotation='vertical') for tick in ax1.get_xticklabels(): tick.set_rotation(60) plt.savefig('{}.png'.format(ev.VAR_NAME[0]), dpi=500, bbox_inches = 'tight') plt.show() def plot_all_bins(iv_df): for i in [x.replace('WOE_','') for x in X_train.columns]: ev = iv_df[iv_df.VAR_NAME==i] ev.reset_index(inplace=True) plot_bin(ev)</span></span></code> </pre> <br></div></div><br>  Une fonction de binning manuel a √©t√© √©crite s√©par√©ment, ce qui est utile, par exemple, dans le cas de la variable ¬´version OS¬ª, o√π tous les t√©l√©phones Android et iOS ont √©t√© regroup√©s manuellement. <br><br><div class="spoiler">  <b class="spoiler_title">Fonction de binning manuel</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">adjust_binning</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, bins_dict)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(bins_dict)): key = list(bins_dict.keys())[i] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> type(list(bins_dict.values())[i])==dict: df[key] = df[key].map(list(bins_dict.values())[i]) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-comment"><span class="hljs-comment">#Categories labels categories = list() for j in range(len(list(bins_dict.values())[i])): if j == 0: categories.append('&lt;'+ str(list(bins_dict.values())[i][j])) try: categories.append('(' + str(list(bins_dict.values())[i][j]) +'; '+ str(list(bins_dict.values())[i][j+1]) + ']') except: categories.append('(' + str(list(bins_dict.values())[i][j])) elif j==len(list(bins_dict.values())[i])-1: categories.append(str(list(bins_dict.values())[i][j]) +'&gt;') else: categories.append('(' + str(list(bins_dict.values())[i][j]) +'; '+ str(list(bins_dict.values())[i][j+1]) + ']') values = [df[key].min()] + list(bins_dict.values())[i] + [df[key].max()] df[key + '_bins'] = pd.cut(df[key], values, include_lowest=True, labels=categories).astype(object).fillna('_MISSING_').astype(str) df[key] = df[key + '_bins']#.map(df.groupby(key + '_bins')[key].agg('median')) df.drop([key + '_bins'], axis=1, inplace=True) return df bins_dict = { 'equi_delinquencyDays': [ 200,400,600] 'loan_purpose': {'medicine':'1_group', 'repair':'1_group', 'helpFriend':'2_group'} } df = adjust_binning(df, bins_dict)</span></span></code> </pre> <br></div></div><br>  L'√©tape suivante est la s√©lection des variables par valeur d'information.  La valeur par d√©faut est coup√©e 0,1 (toutes les variables ci-dessous n'ont pas un bon pouvoir pr√©dictif). <br><br>  Apr√®s cela, un contr√¥le de corr√©lation a √©t√© effectu√©.  Des deux variables corr√©latives, vous devez supprimer celle qui a le moins d'IV.  Le retrait de coupure a √©t√© effectu√© 0,75. <br><br><img src="https://habrastorage.org/webt/sv/7g/f0/sv7gf0nt_7sayq8jgjsjo_bfmpy.png" alt="image"><br><br><div class="spoiler">  <b class="spoiler_title">Suppression de la corr√©lation</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">delete_correlated_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, cut_off=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.75</span></span></span></span><span class="hljs-function"><span class="hljs-params">, exclude = [])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Create correlation matrix corr_matrix = df.corr().abs() # Select upper triangle of correlation matrix upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # Plotting All correlations f, ax = plt.subplots(figsize=(15, 10)) plt.title('All correlations', fontsize=20) sns.heatmap(X_train.corr(), annot=True) # Plotting highly correlated try: f, ax = plt.subplots(figsize=(15, 10)) plt.title('High correlated', fontsize=20) sns.heatmap(corr_matrix[(corr_matrix&gt;cut_off) &amp; (corr_matrix!=1)].dropna(axis=0, how='all').dropna(axis=1, how='all'), annot=True, linewidths=.5) except: print ('No highly correlated features found') # Find index of feature columns with correlation greater than cut_off to_drop = [column for column in upper.columns if any(upper[column] &gt; cut_off)] to_drop = [column for column in to_drop if column not in exclude] print ('Dropped columns:', to_drop, '\n') df2 = df.drop(to_drop, axis=1) print ('Features left after correlation check: {}'.format(len(df.columns)-len(to_drop)), '\n') print ('Not dropped columns:', list(df2.columns), '\n') # Plotting final correlations f, ax = plt.subplots(figsize=(15, 10)) plt.title('Final correlations', fontsize=20) sns.heatmap(df2.corr(), annot=True) plt.show() return df2</span></span></code> </pre> <br></div></div><br>  En plus de la s√©lection par IV, nous avons ajout√© une recherche r√©cursive du nombre optimal de variables par la m√©thode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RFE</a> de sklearn. <br>  Comme nous le voyons dans le graphique, apr√®s 13 variables, la qualit√© ne change pas, ce qui signifie que les variables suppl√©mentaires peuvent √™tre supprim√©es.  Pour la r√©gression, plus de 15 variables de notation sont consid√©r√©es comme de mauvaise forme, qui dans la plupart des cas sont corrig√©es √† l'aide de RFE. <br><br><img src="https://habrastorage.org/webt/4y/sm/2c/4ysm2cgo50qcscs2rigxeksod6y.png" alt="image"><br><div class="spoiler">  <b class="spoiler_title">RFE</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">RFE_feature_selection</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf_lr, X, y)</span></span></span><span class="hljs-function">:</span></span> rfecv = RFECV(estimator=clf_lr, step=<span class="hljs-number"><span class="hljs-number">1</span></span>, cv=StratifiedKFold(<span class="hljs-number"><span class="hljs-number">5</span></span>), verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, scoring=<span class="hljs-string"><span class="hljs-string">'roc_auc'</span></span>) rfecv.fit(X, y) print(<span class="hljs-string"><span class="hljs-string">"Optimal number of features : %d"</span></span> % rfecv.n_features_) <span class="hljs-comment"><span class="hljs-comment"># Plot number of features VS. cross-validation scores f, ax = plt.subplots(figsize=(14, 9)) plt.xlabel("Number of features selected") plt.ylabel("Cross validation score (nb of correct classifications)") plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_) plt.show() mask = rfecv.get_support() X = X.ix[:, mask] return X</span></span></code> </pre> <br></div></div><br>  Ensuite, une r√©gression a √©t√© construite et ses param√®tres ont √©t√© √©valu√©s sur la validation crois√©e et l'√©chantillonnage d'essai.  Habituellement, tout le monde regarde le coefficient de Gini (un bon article √† son sujet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ). <br><br><img src="https://habrastorage.org/webt/kb/mm/uf/kbmmufj5bxr4jybxad88d1pyggg.png" alt="image"><br><br><div class="spoiler">  <b class="spoiler_title">R√©sultats de la simulation</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf, X_test, y_test, feat_to_show=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">30</span></span></span></span><span class="hljs-function"><span class="hljs-params">, is_normalize=False, cut_off=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#cm = confusion_matrix(pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), y_test) print ('ROC_AUC: ', round(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]), 3)) print ('Gini: ', round(2*roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]) - 1, 3)) print ('F1_score: ', round(f1_score(y_test, clf.predict(X_test)), 3)) print ('Log_loss: ', round(log_loss(y_test, clf.predict(X_test)), 3)) print ('\n') print ('Classification_report: \n', classification_report(pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), y_test)) skplt.metrics.plot_confusion_matrix(y_test, pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), title="Confusion Matrix", normalize=is_normalize,figsize=(8,8),text_fontsize='large') display(eli5.show_weights(clf, top=20, feature_names = list(X_test.columns))) clf_lr = LogisticRegressionCV(random_state=1, cv=7) clf_lr.fit(X_train, y_train) plot_score(clf_lr, X_test, y_test, cut_off=0.5)</span></span></code> </pre> <br></div></div><br>  Lorsque nous nous assurons que la qualit√© du mod√®le nous convient, il est n√©cessaire d'√©crire tous les r√©sultats (coefficients de r√©gression, groupes de casiers, graphiques et variables de stabilit√© de Gini, etc.) dans Excel.  Pour cela, il est pratique d'utiliser xlsxwriter, qui peut fonctionner avec des donn√©es et des images. <br><br>  Exemples de feuilles Excel: <br><br><img src="https://habrastorage.org/webt/um/fg/fn/umfgfnwv9fo7hxo8lqq8fwyppes.png" alt="image"><br><br><img src="https://habrastorage.org/webt/xw/ym/1y/xwym1ynrybf7uhvlagzjrjshz_y.png" alt="image"><br><br><div class="spoiler">  <b class="spoiler_title">Enregistrer en Excel</b> <div class="spoiler_text"><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#WRITING writer = pd.ExcelWriter('PDL_Score_20180815-3.xlsx', engine='xlsxwriter') workbook = writer.book worksheet = workbook.add_worksheet('Sample information') bold = workbook.add_format({'bold': True}) percent_fmt = workbook.add_format({'num_format': '0.00%'}) worksheet.set_column('A:A', 20) worksheet.set_column('B:B', 15) worksheet.set_column('C:C', 10) # Sample worksheet.write('A2', 'Sample conditions', bold) worksheet.write('A3', 1) worksheet.write('A4', 2) worksheet.write('A5', 3) worksheet.write('A6', 4) # Model worksheet.write('A8', 'Model development', bold) worksheet.write('A9', 1) #labels worksheet.write('C8', 'Bads') worksheet.write('D8', 'Goods') worksheet.write('B9', 'Train') worksheet.write('B10', 'Valid') worksheet.write('B11', 'Total') # goods and bads worksheet.write('C9', y_train.value_counts()[1]) worksheet.write('C10', y_test.value_counts()[1]) worksheet.write('D9', y_train.value_counts()[0]) worksheet.write('D10', y_test.value_counts()[0]) worksheet.write('C11', y.value_counts()[1]) worksheet.write('D11', y.value_counts()[0]) # NPL worksheet.write('A13', 2) worksheet.write('B13', 'NPL') worksheet.write('C13', (y.value_counts()[1]/(y.value_counts()[1]+y.value_counts()[0])), percent_fmt) worksheet.write('A16', 3) worksheet.write('C15', 'Gini') worksheet.write('B16', 'Train') worksheet.write('B17', 'Valid') worksheet.write('B18', 'CV Scores') worksheet.write('C18', str([round(sc, 2) for sc in scores])) worksheet.write('C16', round(2*roc_auc_score(y_train, clf_lr.predict_proba(X_train)[:,1]) - 1, 3)) worksheet.write('C17', round(2*roc_auc_score(y_test, clf_lr.predict_proba(X_test)[:,1]) - 1, 3)) # Regreesion coefs feat.to_excel(writer, sheet_name='Regression coefficients', index=False) worksheet2 = writer.sheets['Regression coefficients'] worksheet2.set_column('A:A', 15) worksheet2.set_column('B:B', 50) #WOE ivs[['VAR_NAME', 'Variable range', 'WOE', 'COUNT', 'WOE_group']].to_excel(writer, sheet_name='WOE', index=False) worksheet3 = writer.sheets['WOE'] worksheet3.set_column('A:A', 50) worksheet3.set_column('B:B', 60) worksheet3.set_column('C:C', 30) worksheet3.set_column('D:D', 20) worksheet3.set_column('E:E', 12) for num, i in enumerate([x.replace('WOE_','') for x in X_train.columns]): ev = iv_df[iv_df.VAR_NAME==i] ev.reset_index(inplace=True) worksheet3.insert_image('G{}'.format(num*34+1), '{}.png'.format(i)) df3.to_excel(writer, sheet_name='Data', index=False) table.to_excel(writer, sheet_name='Scores by buckets', header = True, index = True) worksheet4 = writer.sheets['Scores by buckets'] worksheet4.set_column('A:A', 20) worksheet4.insert_image('J1', 'score_distribution.png') Ginis.to_excel(writer, sheet_name='Gini distribution', header = True, index = True) worksheet5 = writer.sheets['Gini distribution'] worksheet5.insert_image('E1', 'gini_stability.png') writer.save()</span></span></code> </pre> <br></div></div><br>  √Ä la fin, l'excellence finale est √† nouveau regard√©e par la direction, apr√®s quoi elle est donn√©e √† l'informatique pour l'int√©gration du mod√®le dans la production. <br><br><h3>  R√©sum√© </h3><br>  Comme nous l'avons vu, presque toutes les √©tapes de la notation peuvent √™tre automatis√©es afin que les analystes n'aient pas besoin de comp√©tences en programmation pour cr√©er des mod√®les.  Dans notre cas, apr√®s avoir cr√©√© ce framework, l'analyste n'a plus qu'√† collecter des donn√©es et sp√©cifier plusieurs param√®tres (indiquer la variable cible, les colonnes √† supprimer, le nombre minimum de cases, le coefficient de coupure pour la corr√©lation des variables, etc.), apr√®s quoi vous pouvez ex√©cuter le script en python, qui va construire le mod√®le et produire Excel avec les r√©sultats souhait√©s. <br>  Bien s√ªr, il est parfois n√©cessaire de corriger le code pour les besoins d'un projet particulier, et vous ne pouvez pas le faire avec un seul bouton pour ex√©cuter le script pendant la mod√©lisation, mais m√™me maintenant, nous voyons une meilleure qualit√© que les packages d'exploration de donn√©es utilis√©s sur le march√© gr√¢ce √† des techniques telles que le binning optimal et monotone, la v√©rification de la corr√©lation , RFE, version r√©gularis√©e de r√©gression, etc. <br><br>  Ainsi, gr√¢ce √† l'utilisation de Python, nous avons consid√©rablement r√©duit le temps de d√©veloppement des cartes de notation, ainsi que les co√ªts de main-d'≈ìuvre des analystes. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr421091/">https://habr.com/ru/post/fr421091/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr421081/index.html">Trop peu de gens pr√™tent attention √† cette tendance √©conomique.</a></li>
<li><a href="../fr421083/index.html">Art oubli√© de d√©corer des emballages pour cartes graphiques</a></li>
<li><a href="../fr421085/index.html">Elon Musk n'est pas l'avenir</a></li>
<li><a href="../fr421087/index.html">Comment configurer le d√©ploiement d'une application Web sur Go pour Gitlab sur VDS</a></li>
<li><a href="../fr421089/index.html">Les fournisseurs russes ont compris comment transf√©rer √† Google une partie des co√ªts du "Spring Package"</a></li>
<li><a href="../fr421093/index.html">Comment j'√©tudie le cadre Spring - partie 2 (aide aux d√©butants - le travail des d√©butants eux-m√™mes)</a></li>
<li><a href="../fr421095/index.html">En vertu du nouveau projet de loi sur le blocage avant le proc√®s pourrait tomber 19 millions de sites</a></li>
<li><a href="../fr421097/index.html">Composition des UIViewControllers et navigation entre eux (et pas seulement)</a></li>
<li><a href="../fr421099/index.html">Est-ce difficile de se concentrer? Ce n'est peut-√™tre pas de ta faute</a></li>
<li><a href="../fr421101/index.html">"Calendrier des testeurs" pour ao√ªt. Lire un livre</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚öìÔ∏è ‚ôàÔ∏è ü§üüèæ C√≥mo Yandex aplic√≥ la visi√≥n por computadora para mejorar la calidad de las transmisiones de video. Tecnolog√≠a DeepHD ü§∑üèº ‚ìÇÔ∏è üë©üèª‚Äçüç≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cuando las personas buscan en Internet una foto o un video, a menudo agregan la frase "de buena calidad". La calidad generalmente se refiere a la reso...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo Yandex aplic√≥ la visi√≥n por computadora para mejorar la calidad de las transmisiones de video. Tecnolog√≠a DeepHD</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/422561/">  Cuando las personas buscan en Internet una foto o un video, a menudo agregan la frase "de buena calidad".  La calidad generalmente se refiere a la resoluci√≥n: los usuarios quieren que la imagen sea grande y al mismo tiempo se vea bien en la pantalla de una computadora moderna, tel√©fono inteligente o TV.  Pero, ¬øqu√© pasa si la fuente de buena calidad simplemente no existe? <br><br>  Hoy les diremos a los lectores de Habr c√≥mo, con la ayuda de las redes neuronales, podemos aumentar la resoluci√≥n del video en tiempo real.  Tambi√©n aprender√° c√≥mo el enfoque te√≥rico para resolver este problema difiere del pr√°ctico.  Si no est√° interesado en los detalles t√©cnicos, puede desplazarse con seguridad por la publicaci√≥n; al final encontrar√° ejemplos de nuestro trabajo. <br><br><img width="800" src="https://habrastorage.org/webt/hx/lu/ak/hxluakxdy2mxmmskebqieei5zq4.png"><br><br>  Hay mucho contenido de video en Internet en baja calidad y resoluci√≥n.  Pueden ser pel√≠culas filmadas hace d√©cadas o transmitir canales de televisi√≥n, que por diversas razones no tienen la mejor calidad.  Cuando los usuarios extienden dicho video a pantalla completa, la imagen se vuelve turbia y borrosa.  Una soluci√≥n ideal para pel√≠culas antiguas ser√≠a encontrar la pel√≠cula original, escanearla con equipos modernos y restaurarla manualmente, pero esto no siempre es posible.  Las transmisiones son a√∫n m√°s complicadas: deben procesarse en vivo.  En este sentido, la opci√≥n m√°s aceptable para que trabajemos es aumentar la resoluci√≥n y limpiar los artefactos utilizando la tecnolog√≠a de visi√≥n por computadora. <br><br><a name="habracut"></a>  En la industria, la tarea de aumentar las im√°genes y los videos sin p√©rdida de calidad se denomina t√©rmino superresoluci√≥n.  Ya se han escrito muchos art√≠culos sobre este tema, pero las realidades de la aplicaci√≥n de "combate" resultaron ser mucho m√°s complicadas e interesantes.  Brevemente sobre los principales problemas que tuvimos que resolver en nuestra propia tecnolog√≠a DeepHD: <br><br><ul><li>  Debe poder restaurar los detalles que no estaban en el video original debido a su baja resoluci√≥n y calidad, para "terminarlos". </li><li>  Las soluciones de s√∫per resoluci√≥n restauran los detalles, pero hacen que sean claros y detallados no solo los objetos en el video, sino tambi√©n los artefactos de compresi√≥n, lo que causa disgusto a la audiencia. </li><li> Hay un problema con la recolecci√≥n de la muestra de entrenamiento: se requiere una gran cantidad de pares en los que el mismo video est√° presente en baja resoluci√≥n y calidad, y en alta.  En realidad, generalmente no hay pares de calidad para contenido deficiente. </li><li>  La soluci√≥n deber√≠a funcionar en tiempo real. </li></ul><br><h3>  Selecci√≥n de tecnolog√≠a </h3><br>  En los √∫ltimos a√±os, el uso de redes neuronales ha llevado a un √©xito significativo en la resoluci√≥n de casi todas las tareas de la visi√≥n por computadora, y la tarea de la superresoluci√≥n no es una excepci√≥n.  Encontramos las soluciones m√°s prometedoras basadas en GAN (Redes Adversarias Generativas, redes rivales generativas).  Le permiten obtener im√°genes fotorrealistas de alta definici√≥n, que las complementan con los detalles que faltan, por ejemplo, dibujando cabello y pesta√±as en las im√°genes de las personas. <br><br><img src="https://habrastorage.org/webt/gq/hl/kz/gqhlkzdwwmq3ad9p78j7wapfhzs.png"><br><br>  En el caso m√°s simple, una red neuronal consta de dos partes.  La primera parte, el generador, toma una imagen de entrada y devuelve una ampliaci√≥n duplicada.  La segunda parte, el discriminador, recibe la imagen generada y "real" como entrada, y trata de distinguirla entre s√≠. <br><br><img width="700" src="https://habrastorage.org/webt/kn/3s/sc/kn3sscgtqtwqzcnga59cwaor-8y.png"><br><br><h3>  Preparaci√≥n del set de entrenamiento </h3><br>  Para el entrenamiento, hemos recopilado docenas de clips en calidad UltraHD.  Primero, los redujimos a una resoluci√≥n de 1080p, obteniendo ejemplos de referencia.  Luego redujimos a la mitad estos videos, comprimi√©ndolos a una tasa de bits diferente en el camino para obtener algo similar a un video real en baja calidad.  Dividimos los videos resultantes en marcos y los usamos de tal manera para entrenar la red neuronal. <br><br><h3>  Desbloqueo </h3><br>  Por supuesto, quer√≠amos obtener una soluci√≥n de extremo a extremo: entrenar a la red neuronal para generar video de alta resoluci√≥n y calidad directamente desde el original.  Sin embargo, las GAN resultaron ser muy caprichosas y constantemente intentaron refinar los artefactos de compresi√≥n, en lugar de eliminarlos.  Por lo tanto, tuve que dividir el proceso en varias etapas.  El primero es la supresi√≥n de los artefactos de compresi√≥n de video, tambi√©n conocidos como desbloqueo. <br><br>  Un ejemplo de uno de los m√©todos de lanzamiento: <br><br><img src="https://habrastorage.org/webt/0c/sg/zx/0csgzx4zwbtceyujcgcay4mclac.jpeg"><br><br>  En esta etapa, minimizamos la desviaci√≥n est√°ndar entre el fotograma generado y el original.  Por lo tanto, aunque aumentamos la resoluci√≥n de la imagen, no obtuvimos un aumento real en la resoluci√≥n debido a la regresi√≥n al promedio: la red neuronal, al no saber en qu√© p√≠xeles espec√≠ficos pasa un borde particular en la imagen, se vio obligada a promediar varias opciones, obteniendo un resultado borroso.  Lo principal que hemos logrado en esta etapa es la eliminaci√≥n de los artefactos de compresi√≥n de video, por lo que la red generativa en la siguiente etapa solo necesitaba aumentar la claridad y agregar los peque√±os detalles y texturas que faltan.  Despu√©s de cientos de experimentos, seleccionamos la arquitectura √≥ptima en t√©rminos de rendimiento y calidad, que recuerda vagamente a la arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DRCN</a> : <br><br><img width="800" src="https://habrastorage.org/webt/oq/au/pc/oqaupcp8k9m4rdspvx8rrrbhpy0.png"><br><br>  La idea principal de tal arquitectura es el deseo de obtener la arquitectura m√°s profunda, sin tener problemas de convergencia en su formaci√≥n.  Por un lado, cada capa convolucional subsiguiente extrae caracter√≠sticas cada vez m√°s complejas de la imagen de entrada, lo que le permite determinar qu√© tipo de objeto se encuentra en un punto determinado de la imagen y restaurar partes complejas y muy da√±adas.  Por otro lado, la distancia en el gr√°fico de una red neuronal desde cualquiera de sus capas hasta la salida sigue siendo peque√±a, lo que mejora la convergencia de la red neuronal y permite utilizar una gran cantidad de capas. <br><br><h3>  Entrenamiento de red generativa </h3><br>  Tomamos la arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SRGAN como</a> base de una red neuronal para aumentar la resoluci√≥n.  Antes de entrenar una red competitiva, debe entrenar previamente el generador, entrenarlo de la misma manera que en la etapa de desbloqueo.  De lo contrario, al comienzo del entrenamiento, el generador devolver√° solo ruido, el discriminador comenzar√° inmediatamente a "ganar": aprender√° f√°cilmente a distinguir el ruido de los cuadros reales, y ning√∫n entrenamiento funcionar√°. <br><br><img width="800" src="https://habrastorage.org/webt/tx/pb/r-/txpbr-pwdisdcwj62mrd6h4wuxm.png"><br><br>  Luego entrenamos GAN, pero hay algunos matices.  Es importante para nosotros que el generador no solo cree marcos fotorrealistas, sino que tambi√©n almacene la informaci√≥n disponible en ellos.  Para hacer esto, agregamos la funci√≥n de p√©rdida de contenido a la arquitectura cl√°sica de GAN.  Representa varias capas de la red neuronal VGG19 capacitadas en el conjunto de datos est√°ndar de ImageNet.  Estas capas transforman la imagen en un mapa de caracter√≠sticas que contiene informaci√≥n sobre el contenido de la imagen.  La funci√≥n de p√©rdida minimiza la distancia entre dichas tarjetas obtenida de los cuadros generados y originales.  Adem√°s, la presencia de dicha funci√≥n de p√©rdida hace posible no estropear el generador en los primeros pasos del entrenamiento, cuando el discriminador a√∫n no est√° entrenado y proporciona informaci√≥n in√∫til. <br><br><img width="800" src="https://habrastorage.org/webt/d7/5p/uu/d75puuaa6jqsy6wmvknjqo-hh84.png"><br><br><h3>  Aceleraci√≥n de la red neuronal </h3><br>  Todo sali√≥ bien, y despu√©s de una serie de experimentos, obtuvimos un buen modelo que ya podr√≠a aplicarse a pel√≠culas antiguas.  Sin embargo, todav√≠a era demasiado lento para procesar la transmisi√≥n de video.  Result√≥ que es imposible simplemente reducir el generador sin una p√©rdida significativa en la calidad del modelo final.  Luego, el enfoque de la destilaci√≥n del conocimiento nos ayud√≥.  Este m√©todo implica entrenar un modelo m√°s ligero para que repita los resultados de uno m√°s pesado.  Tomamos muchos videos reales en baja calidad, los procesamos con la red neuronal generativa obtenida en el paso anterior, y capacitamos a la red m√°s ligera para obtener el mismo resultado de los mismos cuadros.  Debido a esta t√©cnica, obtuvimos una red que no es muy inferior en calidad a la original, pero diez veces m√°s r√°pida que ella: para procesar un canal de TV con una resoluci√≥n de 576p, se requiere una tarjeta NVIDIA Tesla V100. <br><br><img width="800" src="https://habrastorage.org/webt/15/b3/eg/15b3eguc_ikkl-fdaclwdsga2ka.png"><br><br><h3>  Evaluaci√≥n de la calidad de las soluciones. </h3><br>  Quiz√°s el momento m√°s dif√≠cil cuando se trabaja con redes generativas es la evaluaci√≥n de la calidad de los modelos resultantes.  No existe una funci√≥n de error clara, como, por ejemplo, al resolver el problema de clasificaci√≥n.  En cambio, solo conocemos la precisi√≥n del discriminador, que no refleja la calidad del generador que nos interesa (un lector que conozca bien esta √°rea podr√≠a sugerir el uso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">la m√©trica de Wasserstein</a> , pero, desafortunadamente, dio un resultado notablemente peor). <br><br>  La gente nos ayud√≥ a resolver este problema.  Mostramos a los usuarios del servicio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Yandex.Tolok</a> pares de im√°genes, una de las cuales era la fuente y la otra procesada por una red neuronal, o ambas fueron procesadas por diferentes versiones de nuestras soluciones.  Por una tarifa, los usuarios eligieron un mejor video de un par, por lo que obtuvimos una comparaci√≥n estad√≠sticamente significativa de las versiones, incluso con cambios que son dif√≠ciles de ver a simple vista.  Nuestros modelos finales ganan en m√°s del 70% de los casos, lo cual es bastante, dado que los usuarios dedican solo unos segundos a calificar un par de videos. <br><br>  Un resultado interesante tambi√©n fue el hecho de que el video con una resoluci√≥n de 576p, aumentado por la tecnolog√≠a DeepHD a 720p, supera el mismo video original con una resoluci√≥n de 720p en el 60% de los casos, es decir  El procesamiento no solo aumenta la resoluci√≥n del video, sino que tambi√©n mejora su percepci√≥n visual. <br><br><h3>  Ejemplos </h3><br>  En primavera, probamos la tecnolog√≠a DeepHD en varias pel√≠culas antiguas que se pueden ver en KinoPoisk: " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Rainbow</a> " de Mark Donskoy (1943), " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cranes are Flying</a> " de Mikhail Kalatozov (1957), " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">My Dear Man</a> " de Joseph Kheifits (1958), " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">The Fate of a Man</a> " Sergei Bondarchuk (1959), " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ivan Childhood</a> " de Andrei Tarkovsky (1962), " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Father of a Soldier</a> " Rezo Chkheidze (1964) y " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tango of Our Childhood</a> " de Albert Mkrtchyan (1985). <br><br><img width="800" src="https://habrastorage.org/webt/zh/un/-d/zhun-dugkeykn9bmodmrgrjfxma.png"><br><br>  La diferencia entre las versiones antes y despu√©s del procesamiento es especialmente notable si observa los detalles: estudie las expresiones faciales de los h√©roes en primeros planos, considere la textura de la ropa o un patr√≥n de tela.  Fue posible compensar algunas de las deficiencias de la digitalizaci√≥n: por ejemplo, eliminar la sobreexposici√≥n en las caras o hacer objetos m√°s visibles colocados a la sombra. <br><br>  M√°s tarde, la tecnolog√≠a DeepHD comenz√≥ a usarse para mejorar la calidad de las transmisiones de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">algunos</a> canales en el servicio Yandex.Air.  Reconocer dicho contenido es f√°cil con la etiqueta <b>dHD</b> . <br><br>  Ahora <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en Yandex,</a> en calidad mejorada, puede ver "The Snow Queen", "Bremen Town Musicians", "Golden Antelope" y otras caricaturas populares del estudio de cine Soyuzmultfilm.  Se pueden ver algunos ejemplos de din√°mica en el video: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/ainlhiNn0Yk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Para los espectadores exigentes, la diferencia ser√° especialmente notable: la imagen se ha vuelto m√°s n√≠tida, las hojas de los √°rboles, los copos de nieve, las estrellas en el cielo nocturno sobre la selva y otros peque√±os detalles son m√°s visibles. <br><br>  M√°s es m√°s. <br><br><h3>  Enlaces utiles </h3><br>  Jiwon Kim, Jung Kwon Lee, Kyoung Mu Lee Red convolucional profundamente recursiva para la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">superresoluci√≥n de imagen</a> [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv: 1511.04491</a> ]. <br><br>  Christian Ledig y col.  S√∫per resoluci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fotorrealista de</a> una sola imagen utilizando una red <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">generativa adversa</a> [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv: 1609.04802</a> ]. <br><br>  Mehdi SM Sajjadi, Bernhard Sch√∂lkopf, Michael Hirsch EnhanceNet: S√∫per resoluci√≥n de imagen √∫nica a trav√©s de s√≠ntesis de textura automatizada [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv: 1612.07919</a> ]. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es422561/">https://habr.com/ru/post/es422561/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es422547/index.html">Para eliminar Spectre y Meltdown, es posible que deba crear un tipo de procesador completamente nuevo.</a></li>
<li><a href="../es422549/index.html">Corda: Kotlin</a></li>
<li><a href="../es422551/index.html">C√≥mo robar dinero de una tarjeta sin contacto y Apple Pay</a></li>
<li><a href="../es422553/index.html">La extensi√≥n oficial del navegador Mega roba datos de intercambio de archivos y criptomonedas</a></li>
<li><a href="../es422555/index.html">Arquitectura de m√∫ltiples m√≥dulos de Android. De la A a la Z</a></li>
<li><a href="../es422565/index.html">Seminarios web de Skillbox Friday: todo para programadores y dise√±adores</a></li>
<li><a href="../es422569/index.html">Aplicaci√≥n de seguimiento horario</a></li>
<li><a href="../es422571/index.html">Paralelizaci√≥n de tareas con dependencias: ejemplo de .NET</a></li>
<li><a href="../es422573/index.html">La ingenier√≠a inversa de la representaci√≥n de The Witcher 3</a></li>
<li><a href="../es422575/index.html">Portero raro</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏿‍🌾 📦 😡 Bildverarbeitung vs. menschliche Intuition: Algorithmen zur Unterbrechung des Betriebs von Objekterkennungsprogrammen 👴🏾 💂 🍼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Logik der Maschinen ist einwandfrei, sie machen keine Fehler, wenn ihr Algorithmus korrekt funktioniert und die eingestellten Parameter den erford...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bildverarbeitung vs. menschliche Intuition: Algorithmen zur Unterbrechung des Betriebs von Objekterkennungsprogrammen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/445372/"><img src="https://habrastorage.org/webt/s9/kf/68/s9kf68iyyoikag7yeexxfaxrp1e.jpeg"><br><br>  Die Logik der Maschinen ist einwandfrei, sie machen keine Fehler, wenn ihr Algorithmus korrekt funktioniert und die eingestellten Parameter den erforderlichen Standards entsprechen.  Bitten Sie das Auto, eine Route von Punkt A nach Punkt B zu wählen, und es wird die optimalste Route unter Berücksichtigung der Entfernung, des Kraftstoffverbrauchs, des Vorhandenseins von Tankstellen usw. erstellen.  Dies ist eine reine Berechnung.  Das Auto wird nicht sagen: "Lass uns diese Straße entlang gehen, ich fühle diese Route besser."  Vielleicht sind Autos in der Geschwindigkeit der Berechnungen besser als wir, aber die Intuition ist immer noch einer unserer Trümpfe.  Die Menschheit hat Jahrzehnte damit verbracht, eine Maschine zu entwickeln, die dem menschlichen Gehirn ähnlich ist.  Aber haben sie so viel gemeinsam?  Heute werden wir eine Studie betrachten, in der Wissenschaftler, die an der unübertroffenen "Vision" der Maschine auf der Grundlage von Faltungs-Neuronalen Netzen zweifelten, ein Experiment durchführten, um ein Objekterkennungssystem mit einem Algorithmus zu täuschen, dessen Aufgabe es war, "gefälschte" Bilder zu erstellen.  Wie erfolgreich war die Sabotageaktivität des Algorithmus, haben die Menschen die Erkennung besser bewältigt als Autos, und was wird diese Studie für die Zukunft dieser Technologie bringen?  Antworten finden wir im Bericht der Wissenschaftler.  Lass uns gehen. <a name="habracut"></a><br><br><h3>  Studienbasis </h3><br>  Objekterkennungstechnologien, die Faltungs-Neuronale Netze (SNS) verwenden, ermöglichen es der Maschine grob gesagt, einen Schwan von der Nummer 9 oder eine Katze von einem Fahrrad zu unterscheiden.  Diese Technologie entwickelt sich recht schnell und wird derzeit in verschiedenen Bereichen eingesetzt, von denen der offensichtlichste die Herstellung unbemannter Fahrzeuge ist.  Viele sind der Meinung, dass die SNA des Systems zur Erkennung von Objekten als Modell des menschlichen Sehens angesehen werden kann.  Diese Aussage ist jedoch aufgrund des menschlichen Faktors zu laut.  Die Sache ist, dass es sich als einfacher herausstellte, ein Auto zu täuschen, als eine Person zu täuschen (zumindest in Bezug auf die Objekterkennung).  SNA-Systeme sind sehr anfällig für die Auswirkungen böswilliger Algorithmen (wenn Sie dies wünschen, feindlich), die sie in jeder Hinsicht daran hindern, ihre Aufgabe korrekt auszuführen, und Bilder erstellen, die vom SNA-System falsch klassifiziert werden. <br><br>  Die Forscher teilen solche Bilder in zwei Kategorien ein: "Narren" (das Ziel vollständig ändern) und "peinlich" (das Ziel teilweise ändern).  Die ersten sind bedeutungslose Bilder, die vom System als etwas Vertrautes erkannt werden.  Beispielsweise kann eine Reihe von Linien als "Baseball" und mehrfarbiges digitales Rauschen als "Gürteltier" klassifiziert werden.  Die zweite Kategorie von Bildern („peinlich“) sind Bilder, die unter normalen Bedingungen korrekt klassifiziert würden, aber der böswillige Algorithmus verzerrt sie in den Augen des SNA-Systems leicht, übertrieben übertrieben.  Beispielsweise wird die handschriftliche Nummer 6 aufgrund eines kleinen Komplements von mehreren Pixeln als Nummer 5 klassifiziert. <br><br>  Stellen Sie sich vor, welchen Schaden solche Algorithmen anrichten können.  Es lohnt sich, die Klassifizierung der Verkehrszeichen gegen autonomen Verkehr auszutauschen, und Unfälle sind unvermeidlich. <br><br>  Nachfolgend finden Sie die „gefälschten“ Bilder, die das SNA-System täuschen, das darauf trainiert ist, Objekte zu erkennen, und wie ein ähnliches System sie klassifiziert. <br><br><img src="https://habrastorage.org/webt/bl/wf/ze/blwfzeyvqwjwhtqmk65ykrbulrc.jpeg"><br>  <i>Bild Nr. 1</i> <br><br>  Serienerklärung: <br><br><ul><li>  <b>und</b> - indirekt verschlüsselte "betrügerische" Bilder; </li><li>  <b>b</b> - direkt codierte "betrügerische" Bilder; </li><li>  <b>c</b> - „peinliche“ Bilder, die das System zwingen, eine Ziffer als eine andere zu klassifizieren; </li><li>  <b>d</b> - LaVAN-Angriffe (lokalisiertes und sichtbares gegnerisches / böswilliges Rauschen) können zu einer falschen Klassifizierung führen, selbst wenn sich das „Rauschen“ nur an einem Punkt befindet (in der unteren rechten Ecke). </li><li>  <b>e</b> - dreidimensionale Objekte, die aus verschiedenen Winkeln falsch klassifiziert wurden. </li></ul><br>  Das Merkwürdigste daran ist, dass eine Person möglicherweise nicht dem Erliegen eines böswilligen Algorithmus erliegt und Bilder basierend auf ihrer Intuition korrekt klassifiziert.  Bisher hat, wie Wissenschaftler sagen, niemand einen praktischen Vergleich der Fähigkeiten einer Maschine und einer Person in einem Experiment durchgeführt, um böswilligen Algorithmen gefälschter Bilder entgegenzuwirken.  Dafür haben sich die Forscher entschieden. <br><br>  Zu diesem Zweck wurden mehrere Bilder erstellt, die mit böswilligen Algorithmen erstellt wurden.  Den Probanden wurde gesagt, dass die Maschine diese (vorderen) Bilder als vertraute Objekte klassifizierte, d.h.  Die Maschine hat sie nicht richtig erkannt.  Die Aufgabe der Probanden bestand darin, genau zu bestimmen, wie die Maschine diese Bilder klassifizierte, d.h.  Was sie denken, dass die Maschine in den Bildern gesehen hat, ist diese Klassifizierung wahr usw. <br><br>  Insgesamt wurden 8 Experimente durchgeführt, bei denen 5 Arten von böswilligen Bildern verwendet wurden, die ohne Berücksichtigung des menschlichen Sehens erstellt wurden.  Mit anderen Worten, sie werden von Maschine zu Maschine erstellt.  Die Ergebnisse dieser Experimente erwiesen sich als sehr unterhaltsam, aber wir werden sie nicht verderben und alles in Ordnung bringen. <br><br><h3>  Versuchsergebnisse </h3><br><h2>  Experiment Nr. 1: Bilder mit ungültigen Tags täuschen </h2><br>  Im ersten Experiment wurden 48 getäuschte Bilder verwendet, die vom Algorithmus erstellt wurden, um dem auf dem SNA namens AlexNet basierenden Erkennungssystem entgegenzuwirken.  Dieses System klassifizierte diese Bilder als "Zahnrad" und "Donut" ( <b>2a</b> ). <br><br><img src="https://habrastorage.org/webt/fg/yt/0h/fgyt0hewtb9akm-4nlbb-movqxo.jpeg"><br>  <i>Bild Nr. 2</i> <br><br>  Während jedes Versuchs sah die Testperson, von der es 200 gab, ein betrügerisches Bild und zwei Markierungen, d.h.  Klassifizierungsetiketten: System-SNS-Etikett und zufällig aus den anderen 47 Bildern.  Die Probanden mussten das Etikett auswählen, das von der Maschine erstellt wurde. <br><br>  Infolgedessen entschieden sich die meisten Probanden für eine von der Maschine erstellte Beschriftung anstelle einer Beschriftung eines böswilligen Algorithmus.  Klassifizierungsgenauigkeit, d.h.  Der Grad der Zustimmung des Probanden zur Maschine betrug 74%.  Statistisch gesehen wählten 98% der Probanden Maschinen-Tags auf einer höheren Ebene als die statistische Zufälligkeit ( <b>2d</b> , „% der Probanden stimmen mit der Maschine überein“).  94% der Bilder zeigten eine sehr hohe Mensch-Maschine-Ausrichtung, dh von 48 wurden nur 3 Bilder von Personen anders als eine Maschine klassifiziert. <br><br>  So zeigten die Probanden, dass eine Person in der Lage ist, ein reales Bild und einen Narren zu teilen, dh gemäß einem auf der SNA basierenden Programm zu handeln. <br><br><h2>  Experiment Nr. 2: erste Wahl gegen zweite </h2><br>  Die Forscher stellten die Frage - aufgrund dessen, welche Probanden Bilder so gut erkennen und von fehlerhaften Markierungen und betrügerischen Bildern trennen konnten?  Vielleicht haben die Probanden den orange-gelben Ring als „Donut“ bezeichnet, weil der Donut in Wirklichkeit genau diese Form hat und ungefähr dieselbe Farbe hat.  In Anerkennung könnten Assoziationen und intuitive Entscheidungen, die auf Erfahrung und Wissen basieren, einer Person helfen. <br><br>  Um dies zu überprüfen, wurde das zufällige Etikett durch das Etikett ersetzt, das von der Maschine als zweite mögliche Klassifizierungsoption ausgewählt wurde.  Zum Beispiel klassifizierte AlexNet den orange-gelben Ring als „Donut“, und die zweite Option für dieses Programm war „Brezel“. <br><br>  Die Probanden standen vor der Aufgabe, die erste Markierung der Maschine oder diejenige zu wählen, die für alle 48 Bilder ( <b>2s</b> ) den zweiten Platz <b>einnahm</b> . <br><br>  Die Grafik in der Mitte von Bild <b>2d</b> zeigt die Ergebnisse dieses Tests: 91% der Probanden wählten die erste Version des Etiketts, und der Grad der Mensch-Maschine-Übereinstimmung betrug 71%. <br><br><h2>  Experiment Nr. 3: Multithread-Klassifizierung </h2><br>  Die oben beschriebenen Experimente sind recht einfach, da die Probanden zwischen zwei möglichen Antworten wählen können (Maschinen-Tag und Zufalls-Tag).  Tatsächlich durchläuft die Maschine bei der Bilderkennung Hunderte und sogar Tausende von Optionen für Etiketten, bevor sie die am besten geeignete auswählt. <br><br>  Bei diesem Test befanden sich alle Markierungen für 48 Bilder unmittelbar vor den Probanden.  Sie mussten aus diesem Set das für jedes Bild am besten geeignete auswählen. <br><br>  Infolgedessen wählten 88% der Probanden genau die gleichen Etiketten wie die Maschine, und der Koordinationsgrad betrug 79%.  Eine interessante Tatsache ist, dass selbst bei der Auswahl des falschen Etiketts, das von der Maschine ausgewählt wurde, die Probanden in 63% dieser Fälle eines der Top-5-Etiketten auswählten.  Das heißt, alle Markierungen auf dem Auto sind in einer Liste von den am besten geeigneten bis zu den unangemessensten geordnet (übertriebenes Beispiel: „Bagel“, „Brezel“, „Gummiring“, „Reifen“ usw. bis hin zu „Falke am Nachthimmel“). ) <br><br><h2>  Versuch Nr. 3b: "Was ist das?" </h2><br>  In diesem Test haben Wissenschaftler die Regeln leicht geändert.  Anstatt sie zu fragen, welches Etikett die Maschine für ein bestimmtes Bild wählen soll, wurden die Probanden einfach gefragt, was sie vor sich sehen. <br><br>  Erkennungssysteme, die auf Faltungs-Neuronalen Netzen basieren, wählen die geeignete Bezeichnung für ein bestimmtes Bild aus.  Dies ist ein ziemlich klarer und logischer Prozess.  In diesem Test zeigen die Probanden intuitives Denken. <br><br>  Infolgedessen wählten 90% der Probanden ein Etikett, das auch von der Maschine ausgewählt wurde.  Die Mensch-Maschine-Ausrichtung zwischen den Bildern betrug 81%. <br><br><h2>  Experiment 4: Statisches Fernsehrauschen </h2><br>  Wissenschaftler stellen fest, dass Bilder in früheren Experimenten ungewöhnlich sind, aber unterscheidbare Merkmale aufweisen, die die Probanden dazu veranlassen können, die richtige (oder falsche) Wahl des Etiketts zu treffen.  Zum Beispiel ist das Bild „Baseball“ kein Ball, aber es gibt Linien und Farben, die auf einem echten Baseballball vorhanden sind.  Dies ist ein auffälliges Unterscheidungsmerkmal.  Aber wenn das Bild keine solchen Merkmale aufweist, sondern im Wesentlichen statisches Rauschen ist, kann eine Person dann zumindest etwas darauf erkennen?  Das wurde beschlossen zu überprüfen. <br><br><img src="https://habrastorage.org/webt/je/9o/sm/je9osmgxp99wmexrvqmzndviqpk.jpeg"><br>  <i>Bild Nr. 3a</i> <br><br>  In diesem Test befanden sich 8 Bilder mit Statik vor den Probanden, die das SNS-System als spezifisches Objekt erkennt (z. B. eine Vogel-Zaryanka).  Außerdem befanden sich vor den Probanden ein Etikett und damit verbundene normale Bilder (8 statische Bilder, 1 Etikett „Zaryanka“ und 5 Fotos dieses Vogels).  Die Testperson musste 1 von 8 statischen Bildern auswählen, die am besten zu dem einen oder anderen Etikett passen. <br><br>  Sie können sich selbst testen.  Oben sehen Sie ein Beispiel für einen solchen Test.  Welches der drei Bilder passt am besten zum Tag „Zaryanka“ und warum? <br><br>  81% der Probanden wählten das Etikett, das die Maschine wählte.  Gleichzeitig wurden 75% der Bilder von den Probanden mit der nach Ansicht der Maschine am besten geeigneten Beschriftung beschriftet (aus einer Reihe von Optionen, wie bereits erwähnt). <br><br>  Für diesen speziellen Test haben Sie möglicherweise Fragen, genau wie meine.  Tatsache ist, dass ich in der vorgeschlagenen Statik (oben) persönlich drei ausgeprägte Merkmale sehe, die sie voneinander unterscheiden.  Und nur in einem Bild ähnelt dieses Merkmal stark der gleichen Zaryanka (ich denke, Sie verstehen, welches Bild der drei).  Daher ist meine persönliche und sehr subjektive Meinung, dass ein solcher Test nicht besonders aussagekräftig ist.  Obwohl vielleicht unter anderem Optionen für statische Bilder wirklich nicht zu unterscheiden und nicht wiederzuerkennen waren. <br><br><h2>  Experiment Nr. 5: "zweifelhafte" Zahlen </h2><br>  Die oben beschriebenen Tests basierten auf Bildern, die nicht sofort vollständig und ohne Zweifel als das eine oder andere Objekt klassifiziert werden können.  Es gibt immer einen Bruchteil der Zweifel.  Die täuschenden Bilder sind in ihrer Arbeit ziemlich einfach - um das Bild bis zur Unkenntlichkeit zu verderben.  Es gibt jedoch eine zweite Art von böswilligen Algorithmen, die nur ein kleines Detail im Bild hinzufügen (oder entfernen), wodurch das Erkennungssystem des SNA-Systems vollständig verletzt werden kann.  Fügen Sie ein paar Pixel hinzu, und die Zahl 6 wird auf magische Weise zur Zahl 5 ( <b>1s</b> ). <br><br>  Wissenschaftler halten solche Algorithmen für einen der gefährlichsten.  Sie können das Bild-Tag leicht ändern, und das unbemannte Fahrzeug berücksichtigt das Tempolimit-Zeichen (z. B. 75 statt 45) falsch, was zu traurigen Konsequenzen führen kann. <br><br><img src="https://habrastorage.org/webt/9k/wr/h9/9kwrh9bcsqbqyolfpdgc1crqcfg.jpeg"><br>  <i>Bild # 3b</i> <br><br>  In diesem Test schlugen die Wissenschaftler vor, dass die Probanden die falsche Antwort wählen, aber eher die falsche.  Im Test wurden 100 digitale Bilder verwendet, die durch einen böswilligen Algorithmus geändert wurden (der LeNet SNA hat seine Klassifizierung geändert, dh der böswillige Algorithmus hat erfolgreich funktioniert).  Die Probanden mussten sagen, welche Zahl ihrer Meinung nach die Maschine sah.  Wie erwartet haben 89% der Probanden diesen Test erfolgreich abgeschlossen. <br><br><h2>  Experiment 6: Fotos und lokalisierte "Verzerrung" </h2><br>  Wissenschaftler stellen fest, dass sich nicht nur Objekterkennungssysteme entwickeln, sondern auch böswillige Algorithmen, die sie daran hindern.  Bisher war es für eine falsche Klassifizierung des Bildes erforderlich, 14% aller Pixel im Zielbild zu verzerren (ändern, löschen, beschädigen usw.).  Jetzt ist diese Zahl viel kleiner geworden.  Es reicht aus, ein kleines Bild in das Ziel einzufügen, und die Klassifizierung wird verletzt. <br><br><img src="https://habrastorage.org/webt/6i/sz/1p/6isz1pvm_j-zzxt1mkeq2krmlts.jpeg"><br>  <i>Bild Nr. 4</i> <br><br>  In diesem Test wurde ein ziemlich neuer böswilliger LaVAN-Algorithmus verwendet, der ein kleines Bild platziert, das an einer Stelle auf dem Zielfoto lokalisiert ist.  Infolgedessen kann das Objekterkennungssystem den U-Bahn-Zug als eine Dose Milch erkennen ( <b>4a</b> ).  Die wichtigsten Merkmale dieses Algorithmus sind genau der geringe Anteil beschädigter Pixel (nur 2%) des Zielbilds und das Fehlen der Notwendigkeit, es in seiner Gesamtheit oder im Hauptteil (höchstwertigen Teil) zu verzerren. <br><br>  Im Test wurden 22 durch LaVAN beschädigte Bilder verwendet (das SNA-Erkennungssystem Inception V3 wurde von diesem Algorithmus erfolgreich gehackt).  Die Probanden sollten die böswillige Beilage auf dem Foto klassifizieren.  87% der Probanden konnten dies erfolgreich tun. <br><br><h2>  Experiment 7: dreidimensionale Objekte </h2><br>  Die Bilder, die wir zuvor gesehen haben, sind zweidimensional, wie jedes Foto, Bild oder Zeitungsausschnitt.  Die meisten böswilligen Algorithmen bearbeiten genau solche Bilder erfolgreich.  Diese Schädlinge können jedoch nur unter bestimmten Bedingungen wirken, dh sie weisen eine Reihe von Einschränkungen auf: <br><br><ul><li>  Komplexität: nur zweidimensionale Bilder; </li><li>  Praktische Anwendung: Böswillige Änderungen sind nur auf Systemen möglich, die die empfangenen digitalen Bilder lesen, und nicht auf Bildern von Sensoren und Sensoren. </li><li>  Stabilität: Ein böswilliger Angriff verliert seine Stärke, wenn Sie ein zweidimensionales Bild drehen (Größe ändern, zuschneiden, schärfen usw.). </li><li>  Menschen: Wir sehen die Welt und die Objekte um uns herum in 3D unter verschiedenen Winkeln, bei Beleuchtung und nicht in Form von zweidimensionalen digitalen Bildern, die aus einem Winkel aufgenommen wurden. </li></ul><br><br>  Wie wir jedoch wissen, hat der Fortschritt böswillige Algorithmen nicht verschont.  Unter ihnen erschien einer, der nicht nur zweidimensionale, sondern auch dreidimensionale Bilder verzerren kann, was zu einer falschen Klassifizierung durch das Objekterkennungssystem führt.  Bei Verwendung von Software für dreidimensionale Grafiken führt ein solcher Algorithmus Klassifizierer, die auf dem SNA (in diesem Fall dem Inception V3-Programm) basieren, aus unterschiedlichen Entfernungen und Betrachtungswinkeln in die Irre.  Das Überraschendste ist, dass solche täuschenden 3D-Bilder auf einem geeigneten Drucker gedruckt werden können, d.h.  Erstellen Sie ein reales physisches Objekt, und das Objekterkennungssystem klassifiziert es immer noch falsch (z. B. eine Orange als Bohrmaschine).  Und das alles dank geringfügiger Änderungen in der Textur auf dem Zielbild ( <b>4b</b> ). <br><br>  Für ein Objekterkennungssystem ist ein solcher böswilliger Algorithmus ein schwerwiegender Gegner.  Aber der Mensch ist keine Maschine, er sieht und denkt anders.  In diesem Test gab es vor den Probanden Bilder von dreidimensionalen Objekten, in denen es die oben beschriebenen Texturänderungen aus drei Winkeln gab.  Die Probanden erhielten auch die richtige und fehlerhafte Note.  Sie mussten feststellen, welche Etiketten korrekt sind, welche nicht und warum, d.h.  ob Testpersonen Texturänderungen in Bildern sehen. <br><br>  Infolgedessen haben 83% der Probanden die Aufgabe erfolgreich abgeschlossen. <br><br>  Für eine detailliertere Einarbeitung in die Nuancen der Studie empfehle ich dringend, dass Sie sich den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bericht von Wissenschaftlern</a> ansehen. <br><br>  Unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Link</a> finden Sie die Bild-, Daten- und Codedateien, die in der Studie verwendet wurden. <br><br><h3>  Nachwort </h3><br>  Die durchgeführten Arbeiten gaben Wissenschaftlern die Möglichkeit, eine einfache und ziemlich offensichtliche Schlussfolgerung zu ziehen - die menschliche Intuition kann eine Quelle sehr wichtiger Daten und ein Werkzeug sein, um die richtige Entscheidung und / oder Wahrnehmung von Informationen zu treffen.  Eine Person kann intuitiv verstehen, wie sich das Objekterkennungssystem verhält, welche Beschriftungen es wählt und warum. <br><br>  Die Gründe, warum es für eine Person einfacher ist, ein reales Bild zu sehen und es richtig zu erkennen, sind mehrere.  Am offensichtlichsten ist die Methode, Informationen zu erhalten: Die Maschine empfängt ein Bild in digitaler Form, und eine Person sieht es mit eigenen Augen.  Für eine Maschine ist ein Bild ein Datensatz, an dem Änderungen vorgenommen werden, deren Klassifizierung Sie verzerren können.  Für uns wird das Bild eines U-Bahn-Zuges immer ein U-Bahn-Zug sein, keine Dose Milch, weil wir es sehen. <br><br>  Wissenschaftler betonen auch, dass solche Tests schwer zu bewerten sind, weil eine Person keine Maschine ist und eine Maschine keine Person.  Zum Beispiel sprechen Forscher über den Test mit einem „Donut“ und einem „Rad“.  Diese Bilder ähneln dem „Donut“ und dem „Rad“, da das Erkennungssystem sie so klassifiziert.  Eine Person sieht, dass sie wie ein "Donut" und "Rad" aussieht, aber sie sind es nicht.  Dies ist der grundlegende Unterschied in der Wahrnehmung visueller Informationen zwischen einer Person und einem Programm. <br><br>  Vielen Dank für Ihre Aufmerksamkeit, bleiben Sie neugierig und haben Sie eine gute Arbeitswoche, Jungs. <br><br>  Vielen Dank für Ihren Aufenthalt bei uns.  Gefällt dir unser Artikel?  Möchten Sie weitere interessante Materialien sehen?  Unterstützen Sie uns, indem Sie eine Bestellung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aufgeben</a> oder Ihren Freunden empfehlen, einen <b>Rabatt von 30% für Habr-Benutzer auf ein einzigartiges Analogon von Einstiegsservern, das wir für Sie erfunden haben:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die ganze Wahrheit über VPS (KVM) E5-2650 v4 (6 Kerne) 10 GB DDR4 240 GB SSD 1 Gbit / s von $ 20 oder wie teilt man den Server?</a>  (Optionen sind mit RAID1 und RAID10, bis zu 24 Kernen und bis zu 40 GB DDR4 verfügbar). <br><br>  <b>VPS (KVM) E5-2650 v4 (6 Kerne) 10 GB DDR4 240 GB SSD 1 Gbit / s bis zum Sommer kostenlos,</b> wenn Sie für einen Zeitraum von sechs Monaten bezahlen, können Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> bestellen. <br><br>  <b>Dell R730xd 2 mal günstiger?</b>  Nur wir haben <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2 x Intel Dodeca-Core Xeon E5-2650v4 128 GB DDR4 6 x 480 GB SSD 1 Gbit / s 100 TV von 249 US-Dollar</a> in den Niederlanden und den USA!</b>  Lesen Sie mehr über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Aufbau eines Infrastrukturgebäudes.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Klasse mit Dell R730xd E5-2650 v4 Servern für 9.000 Euro für einen Cent?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de445372/">https://habr.com/ru/post/de445372/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de445360/index.html">5 typische Aufgaben für JavaScript-Interviews: Analyse und Lösungen</a></li>
<li><a href="../de445362/index.html">Das Buch "Distributed Systems. Entwurfsmuster</a></li>
<li><a href="../de445366/index.html">So beschleunigen Sie die Verschlüsselung gemäß GOST 28147-89 auf dem Baikal-T1-Prozessor aufgrund des SIMD-Blocks</a></li>
<li><a href="../de445368/index.html">Laden Sie ein Spiel mit ein paar Hunderttausenden von virtuellen Benutzern</a></li>
<li><a href="../de445370/index.html">TSDB-Analyse in Prometheus 2</a></li>
<li><a href="../de445378/index.html">Labyrinthe: Klassifizierung, Erzeugung, Suche nach Lösungen</a></li>
<li><a href="../de445380/index.html">Modernes PHP ist schön und produktiv</a></li>
<li><a href="../de445384/index.html">Chang'e-4 Mission - wissenschaftliche Ausrüstung auf dem Landemodul und dem Repeater-Satelliten</a></li>
<li><a href="../de445390/index.html">IDE einer normalen Person oder warum wir uns für Monaco entschieden haben</a></li>
<li><a href="../de445392/index.html">Dynamisches Remarketing von MyTarget: nicht persönliche Produktempfehlungen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
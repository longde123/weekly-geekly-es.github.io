<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ù£Ô∏è üë¥üèΩ ü•õ Journaux dans Kubernetes (et pas seulement) aujourd'hui: attentes et r√©alit√© üßõüèø üéÉ ‚õπüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="C'√©tait en 2019, et nous n'avons toujours pas de solution standard pour l'agr√©gation de journaux dans Kubernetes. Dans cet article, nous souhaitons, √†...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Journaux dans Kubernetes (et pas seulement) aujourd'hui: attentes et r√©alit√©</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/480946/"><img src="https://habrastorage.org/webt/b1/zh/it/b1zhitohqlji21qhzypqn8k_n2s.png"><br><br>  C'√©tait en 2019, et nous n'avons toujours pas de solution standard pour l'agr√©gation de journaux dans Kubernetes.  Dans cet article, nous souhaitons, √† partir d'exemples tir√©s de la pratique, partager nos recherches, les probl√®mes rencontr√©s et leurs solutions. <br><br>  Cependant, pour commencer, je ferai une r√©servation pour que diff√©rents clients comprennent des choses tr√®s diff√©rentes en collectant des journaux: <br><br><ul><li>  quelqu'un veut voir les journaux de s√©curit√© et d'audit; </li><li>  quelqu'un - enregistrement centralis√© de l'ensemble de l'infrastructure; </li><li>  et pour quelqu'un, il suffit de collecter uniquement les journaux d'application, √† l'exclusion, par exemple, des √©quilibreurs. </li></ul><br>  √Ä propos de la fa√ßon dont nous avons mis en ≈ìuvre divers ¬´Wishlist¬ª et quelles difficult√©s nous avons rencontr√©es, sous la coupe. <a name="habracut"></a><br><br><h2>  Th√©orie: √† propos des outils de journalisation </h2><br><h3>  Contexte des composants du syst√®me de journalisation </h3><br>  La journalisation a parcouru un long chemin, gr√¢ce √† laquelle nous avons d√©velopp√© des m√©thodologies de collecte et d'analyse des journaux, que nous utilisons aujourd'hui.  Dans les ann√©es 1950, Fortran a introduit un analogue des flux d'E / S standard qui a aid√© le programmeur √† d√©boguer son programme.  Ce sont les premiers journaux informatiques qui ont simplifi√© la vie des programmeurs de l'√©poque.  Aujourd'hui, nous voyons en eux le premier √©l√©ment du syst√®me d'exploitation foresti√®re - la <b>source ou le ¬´producteur¬ª des grumes</b> . <br><br>  L'informatique ne s'est pas arr√™t√©e: des r√©seaux informatiques sont apparus, les premiers clusters ... Des syst√®mes complexes constitu√©s de plusieurs ordinateurs ont commenc√© √† fonctionner.  Les administrateurs syst√®me √©taient d√©sormais contraints de collecter les journaux de plusieurs machines et, dans des cas particuliers, ils pouvaient ajouter des messages du noyau du syst√®me d'exploitation au cas o√π ils auraient besoin d'enqu√™ter sur une d√©faillance du syst√®me.  Pour d√©crire les syst√®mes centralis√©s de collecte de journaux, la <a href="https://tools.ietf.org/html/rfc3164">RFC 3164</a> est sortie au d√©but des ann√©es 2000, qui normalisait remote_syslog.  Un autre √©l√©ment important est donc apparu: le <b>collecteur (collecteur) de journaux</b> et leur stockage. <br><br>  Avec l'augmentation du volume des journaux et l'adoption g√©n√©ralis√©e des technologies Web, la question s'est pos√©e de savoir quels journaux devraient √™tre facilement affich√©s aux utilisateurs.  Les outils de console simples (awk / sed / grep) ont √©t√© remplac√©s par des visualiseurs de <b>journaux</b> plus avanc√©s - le troisi√®me composant. <br><br>  Dans le cadre de l'augmentation du volume des journaux, une autre chose est devenue claire: les journaux sont n√©cessaires, mais pas tous.  Et diff√©rents journaux n√©cessitent diff√©rents niveaux de s√©curit√©: certains peuvent √™tre perdus tous les deux jours, tandis que d'autres doivent √™tre stock√©s pendant 5 ans.  Ainsi, un composant de filtration et de routage pour les flux de donn√©es a √©t√© ajout√© au syst√®me de journalisation - appelons-le un <b>filtre</b> . <br><br>  Les r√©f√©rentiels ont √©galement fait un bond en avant: ils sont pass√©s de fichiers normaux √† des bases de donn√©es relationnelles, puis √† des r√©f√©rentiels orient√©s documents (par exemple, Elasticsearch).  Le stockage √©tait donc s√©par√© du collecteur. <br><br>  En fin de compte, le concept du journal lui-m√™me s'est √©tendu √† un flux abstrait d'√©v√©nements que nous voulons conserver pour l'histoire.  Plus pr√©cis√©ment, dans le cas o√π il est n√©cessaire de mener une enqu√™te ou d'√©tablir un rapport d'analyse ... <br><br>  En cons√©quence, sur une p√©riode de temps relativement courte, la collecte de journaux est devenue un sous-syst√®me important, qui peut √† juste titre √™tre appel√© l'une des sous-sections du Big Data. <br><br><img src="https://habrastorage.org/webt/ld/ax/r6/ldaxr6rvel45_k3jyu3d1eddcgw.png"><br>  <i>Si jadis des impressions ordinaires pouvaient suffire √† un ¬´syst√®me d'enregistrement¬ª, la situation a maintenant beaucoup chang√©.</i> <br><br><h3>  Kubernetes et journaux </h3><br>  Lorsque Kubernetes est entr√© dans l'infrastructure, le probl√®me existant de collecte des journaux ne lui est pas pass√©.  Dans un sens, c'est devenu encore plus douloureux: la gestion de la plateforme d'infrastructure a √©t√© non seulement simplifi√©e, mais aussi compliqu√©e.  De nombreux anciens services ont commenc√© √† migrer vers des pistes de microservices.  Dans le contexte des journaux, cela a entra√Æn√© un nombre croissant de sources de journaux, leur cycle de vie sp√©cial et la n√©cessit√© de suivre √† travers les journaux les interconnexions de tous les composants du syst√®me ... <br><br>  Pour l'avenir, je peux dire que, malheureusement, il n'existe actuellement aucune option de journalisation standardis√©e pour Kubernetes qui serait avantageusement diff√©rente de tout le monde.  Les programmes les plus populaires dans la communaut√© sont les suivants: <br><br><ul><li>  quelqu'un d√©ploie une pile <b>EFK</b> (Elasticsearch, Fluentd, Kibana); </li><li>  quelqu'un essaie le <a href="https://grafana.com/oss/loki/"><b>Loki</b></a> r√©cemment sorti ou utilise l' <a href="https://banzaicloud.com/products/logging-operator/"><b>op√©rateur Logging</b></a> ; </li><li>  nous <i>(et peut-√™tre pas seulement nous? ..)</i> sommes largement satisfaits de notre propre d√©veloppement - <a href="https://github.com/flant/loghouse"><b>loghouse</b></a> ... </li></ul><br>  En r√®gle g√©n√©rale, nous utilisons ces bundles dans les clusters K8s (pour les solutions auto-h√©berg√©es): <br><br><ul><li>  <a href="https://github.com/kiwigrid/helm-charts/tree/master/charts/fluentd-elasticsearch">Fluentd + Elasticsearch + Kibana</a> ; </li><li>  <a href="https://github.com/flant/loghouse">Fluentd + ClickHouse + loghouse</a> . </li></ul><br>  Cependant, je ne m'attarderai pas sur les instructions d'installation et de configuration.  Au lieu de cela, je me concentrerai sur leurs lacunes et sur des conclusions plus globales sur la situation des journaux en g√©n√©ral. <br><br><h2>  Entra√Ænez-vous avec les journaux dans les K8 </h2><br><img src="https://habrastorage.org/webt/zv/p8/lj/zvp8ljnjmqen_8c0svhhh2kezyc.jpeg" align="left"><br><h3>  "Journaux quotidiens", combien d'entre vous? .. </h3><br>  La collecte centralis√©e des journaux avec une infrastructure suffisamment grande n√©cessite des ressources consid√©rables qui seront consacr√©es √† la collecte, au stockage et au traitement des journaux.  Au cours de l'exploitation de divers projets, nous avons √©t√© confront√©s √† diverses exigences et aux probl√®mes op√©rationnels qui en ont r√©sult√©. <br><br><h4>  Essayons ClickHouse </h4><br>  Regardons un r√©f√©rentiel centralis√© sur un projet avec une application qui g√©n√®re pas mal de logs: plus de 5000 lignes par seconde.  Commen√ßons √† travailler avec ses journaux, en les ajoutant √† ClickHouse. <br><br>  D√®s que le temps r√©el maximum est requis, le serveur ClickHouse √† 4 c≈ìurs sera d√©j√† surcharg√© sur le sous-syst√®me de disque: <br><br><img src="https://habrastorage.org/webt/i4/zy/i6/i4zyi6fxq4175ljs3slazm9rgxc.png"><br><br>  Ce type de t√©l√©chargement est d√ª au fait que nous essayons d'√©crire dans ClickHouse le plus rapidement possible.  Et la base de donn√©es r√©pond √† cela avec une charge de disque accrue, ce qui peut provoquer les erreurs suivantes: <br><br> <code>DB::Exception: Too many parts (300). Merges are processing significantly slower than inserts</code> <br> <br>  Le fait est que les <a href="https://clickhouse.yandex/docs/en/operations/table_engines/mergetree/">tables MergeTree</a> dans ClickHouse (elles contiennent des donn√©es de journal) ont leurs propres difficult√©s lors des op√©rations d'√©criture.  Les donn√©es qui y sont ins√©r√©es g√©n√®rent une partition temporaire, qui fusionne ensuite avec la table principale.  En cons√©quence, l'enregistrement est tr√®s exigeant sur le disque, et la restriction s'applique √† lui, dont nous avons re√ßu la notification ci-dessus: pas plus de 300 sous-partitions peuvent fusionner en 1 seconde (en fait, c'est 300 insert'ov par seconde). <br><br>  Pour √©viter ce probl√®me, vous devez <a href="https://github.com/ClickHouse/ClickHouse/issues/3174">√©crire dans ClickHouse en</a> morceaux aussi grands que possible et pas plus d'une fois en 2 secondes.  Cependant, l'√©criture en lots importants sugg√®re que nous devrions √©crire moins souvent dans ClickHouse.  Ceci, √† son tour, peut entra√Æner des d√©bordements de tampon et la perte de journaux.  La solution consiste √† augmenter le tampon Fluentd, mais la consommation de m√©moire augmentera. <br><br>  <i><b>Remarque</b> : Un autre probl√®me avec notre solution ClickHouse √©tait que le partitionnement dans notre cas (loghouse) √©tait impl√©ment√© via des tables externes li√©es par une <a href="https://clickhouse.yandex/docs/ru/operations/table_engines/merge/">table Merge</a> .</i>  <i>Cela conduit au fait que lors de l'√©chantillonnage de grands intervalles de temps, une quantit√© excessive de RAM est requise, car le m√©tatable traverse toutes les partitions - m√™me celles qui ne contiennent √©videmment pas les donn√©es n√©cessaires.</i>  <i>Cependant, cette approche peut d√©sormais √™tre d√©clar√©e obsol√®te en toute s√©curit√© pour les versions actuelles de ClickHouse (depuis <a href="">18.16</a> ).</i> <br><br>  En cons√©quence, il devient clair que loin de chaque projet aura suffisamment de ressources pour collecter les journaux en temps r√©el dans ClickHouse (plus pr√©cis√©ment, leur distribution ne sera pas opportune).  De plus, vous devrez utiliser une <b>batterie</b> , √† laquelle nous reviendrons.  Le cas d√©crit ci-dessus est r√©el.  Et √† cette √©poque, nous ne pouvions pas offrir une solution fiable et stable qui conviendrait au client et permettrait de collecter les journaux avec un d√©lai minimum ... <br><br><h4>  Et Elasticsearch? </h4><br>  Elasticsearch est connu pour g√©rer de lourdes charges.  Essayons-le dans le m√™me projet.  Maintenant, la charge est la suivante: <br><br><img src="https://habrastorage.org/webt/jh/we/7o/jhwe7ok8_l0alrlv5j72p5lgha0.png"><br><br>  Elasticsearch a pu dig√©rer le flux de donn√©es, cependant, y √©crire de tels volumes utilise beaucoup le CPU.  Ceci est d√©cid√© par l'organisation du cluster.  Purement techniquement, ce n'est pas un probl√®me, mais il s'av√®re que seulement pour le fonctionnement du syst√®me de collecte de journaux, nous utilisons d√©j√† environ 8 c≈ìurs et avons un composant suppl√©mentaire tr√®s charg√© dans le syst√®me ... <br><br>  Conclusion: cette option peut √™tre justifi√©e, mais uniquement si le projet est important et que sa direction est pr√™te √† consacrer des ressources importantes √† un syst√®me de journalisation centralis√©. <br><br>  Une question logique se pose alors: <br><br><h3>  Quels journaux sont vraiment n√©cessaires? </h3><br><img src="https://habrastorage.org/webt/hl/3h/ei/hl3heiig0t7nluwc_bvorqrrndk.jpeg" align="left">  Essayons de changer l'approche elle-m√™me: les journaux doivent √™tre informatifs en m√™me temps et ne pas couvrir <i>tous les</i> √©v√©nements du syst√®me. <br><br>  Disons que nous avons une boutique en ligne prosp√®re.  Quels journaux sont importants?  Rassembler autant d'informations que possible, par exemple, √† partir d'une passerelle de paiement est une excellente id√©e.  Mais tous les journaux ne sont pas critiques pour nous du service de d√©coupage d'images dans le catalogue de produits: seules les erreurs et la surveillance avanc√©e suffisent (par exemple, le pourcentage de 500 erreurs que ce composant g√©n√®re). <br><br>  Nous sommes donc arriv√©s √† la <b>conclusion</b> que <b>la journalisation centralis√©e est loin d'√™tre toujours justifi√©e</b> .  Tr√®s souvent, le client souhaite collecter tous les journaux en un seul endroit, bien qu'en fait, seuls 5% des messages critiques pour l'entreprise soient requis pour l'ensemble du journal: <br><br><ul><li>  Parfois, il suffit de configurer, par exemple, uniquement la taille du journal du conteneur et du collecteur d'erreurs (par exemple, Sentry). </li><li>  Pour enqu√™ter sur les incidents, des alertes d'erreur et un grand journal local lui-m√™me peuvent souvent suffire. </li><li>  Nous avions des projets qui ne co√ªtaient que des tests fonctionnels et des syst√®mes de collecte d'erreurs.  Le d√©veloppeur n'avait pas besoin des journaux en tant que tels - ils ont tout vu sur les traces d'erreur. </li></ul><br><h4>  Illustration de la vie </h4><br>  Un bon exemple est une autre histoire.  Nous avons re√ßu une demande de l'√©quipe de s√©curit√© d'un des clients qui disposait d√©j√† d'une solution commerciale d√©velopp√©e bien avant l'impl√©mentation de Kubernetes. <br><br>  Il a fallu ¬´se faire des amis¬ª un syst√®me centralis√© de collecte de journaux avec un capteur d'entreprise pour d√©tecter les probl√®mes - QRadar.  Ce syst√®me est capable de recevoir des journaux en utilisant le protocole syslog, pour les prendre depuis FTP.  Cependant, son int√©gration avec le plugin remote_syslog pour fluentd n'a pas fonctionn√© tout de suite <i>(il s'est av√©r√© que <a href="https://developer.ibm.com/answers/questions/429729/using-fluentd-to-streamfilter-data-to-qradar/">nous ne sommes pas les seuls</a> )</i> .  Les probl√®mes de configuration de QRadar √©taient du c√¥t√© de l'√©quipe de s√©curit√© du client. <br><br>  En cons√©quence, une partie des journaux critiques pour l'entreprise a √©t√© t√©l√©charg√©e sur FTP QRadar, et l'autre partie a √©t√© redirig√©e via un syslog distant directement √† partir des n≈ìuds.  Pour ce faire, nous avons m√™me √©crit un <a href="https://github.com/flant/examples/tree/master/2019/10-remote-syslog">tableau simple</a> - peut-√™tre que cela aidera quelqu'un √† r√©soudre un probl√®me similaire ... Gr√¢ce au sch√©ma r√©sultant, le client lui-m√™me a re√ßu et analys√© les journaux critiques (en utilisant ses outils pr√©f√©r√©s), et nous avons pu r√©duire le co√ªt du syst√®me de journalisation, en ne gardant que le dernier mois. <br><br>  Un autre exemple montre bien comment ne pas le faire.  L'un de nos clients pour g√©rer <i>chaque</i> √©v√©nement provenant de l'utilisateur, a fait une <i>sortie d'</i> information <i>non structur√©e</i> multiligne dans le journal.  Comme vous pouvez le deviner, ces journaux √©taient extr√™mement difficiles √† lire et √† stocker. <br><br><h3>  Crit√®res pour les journaux </h3><br>  De tels exemples conduisent √† la conclusion que, en plus de choisir un syst√®me de collecte de journaux, vous devez √©galement <i>concevoir les journaux eux-m√™mes</i> !  Quelles sont les exigences ici? <br><br><ul><li>  Les journaux doivent √™tre dans un format lisible par machine (par exemple JSON). </li><li>  Les journaux doivent √™tre compacts et pouvoir changer le degr√© de journalisation afin de d√©boguer d'√©ventuels probl√®mes.  Dans le m√™me temps, dans les environnements de production, vous devez ex√©cuter des syst√®mes avec un niveau de journalisation comme <i>Avertissement</i> ou <i>Erreur</i> . </li><li>  Les journaux doivent √™tre normalis√©s, c'est-√†-dire que dans l'objet journal, toutes les lignes doivent avoir le m√™me type de champ. </li></ul><br>  Les journaux non structur√©s peuvent entra√Æner des probl√®mes lors du chargement des journaux dans le r√©f√©rentiel et de l'arr√™t complet de leur traitement.  Pour illustrer, voici un exemple avec une erreur 400, que beaucoup ont s√ªrement rencontr√© dans les journaux fluentd: <br><br> <code>2019-10-29 13:10:43 +0000 [warn]: dump an error event: error_class=Fluent::Plugin::ElasticsearchErrorHandler::ElasticsearchError error="400 - Rejected by Elasticsearch"</code> <br> <br>  Une erreur signifie que vous envoyez un champ dont le type est instable √† l'index avec un mappage pr√™t.  L'exemple le plus simple est un champ dans le journal nginx avec la variable <code>$upstream_status</code> .  Il peut avoir un nombre ou une cha√Æne.  Par exemple: <br><br> <code>{ "ip": "1.2.3.4", "http_user": "-", "request_id": "17ee8a579e833b5ab9843a0aca10b941", "time": "29/Oct/2019:16:18:57 +0300", "method": "GET", "uri": "/staffs/265.png", "protocol": "HTTP/1.1", "status": "200", "body_size": "906", "referrer": "https://example.com/staff", "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36", "request_time": "0.001", "cache_status": "-", "upstream_response_time": "0.001, 0.007", "upstream_addr": "127.0.0.1:9000", "upstream_status": "200", "upstream_response_length": "906", "location": "staff"} <br> { "ip": "1.2.3.4", "http_user": "-", "request_id": "47fe42807f2a7d8d5467511d7d553a1b", "time": "29/Oct/2019:16:18:57 +0300", "method": "GET", "uri": "/staff", "protocol": "HTTP/1.1", "status": "200", "body_size": "2984", "referrer": "-", "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36", "request_time": "0.010", "cache_status": "-", "upstream_response_time": "0.001, 0.007", "upstream_addr": "10.100.0.10:9000, 10.100.0.11:9000", "upstream_status": "404, 200", "upstream_response_length": "0, 2984", "location": "staff"}</code> <br> <br>  Les journaux montrent que le serveur 10.100.0.10 a r√©pondu avec l'erreur 404e et la demande est all√©e √† un autre magasin de contenu.  En cons√©quence, dans les journaux, la signification est devenue la suivante: <br><br> <code>"upstream_response_time": "0.001, 0.007"</code> <br> <br>  Cette situation est si r√©pandue qu'elle a m√™me gagn√© une <a href="https://github.com/uken/fluent-plugin-elasticsearch">mention</a> distincte <a href="https://github.com/uken/fluent-plugin-elasticsearch">dans la documentation</a> . <br><br><h4>  Et la fiabilit√©? </h4><br>  Il y a des moments o√π tous les journaux sont vitaux sans exception.  Et avec cela, les sch√©mas de collecte de journaux typiques pour les K8 propos√©s / discut√©s ci-dessus ont des probl√®mes. <br><br>  Par exemple, fluentd ne peut pas collecter de b√ªches dans des conteneurs de courte dur√©e.  Dans l'un de nos projets, le conteneur avec la migration de la base de donn√©es a v√©cu moins de 4 secondes, puis a √©t√© supprim√© - selon l'annotation correspondante: <br><br> <code>"helm.sh/hook-delete-policy": hook-succeeded</code> <br> <br>  Pour cette raison, le journal de migration n'est pas entr√© dans le r√©f√©rentiel.  La politique de <code>before-hook-creation</code> peut aider dans ce cas. <br><br>  Un autre exemple est la rotation des journaux Docker.  Supposons qu'il existe une application qui √©crit activement dans les journaux.  Dans des conditions normales, nous parvenons √† traiter tous les journaux, mais d√®s qu'un probl√®me survient - par exemple, comme d√©crit ci-dessus avec le mauvais format - le traitement s'arr√™te et Docker fait pivoter le fichier.  Conclusion - les journaux critiques peuvent √™tre perdus. <br><br>  C'est pourquoi <b>il est important de s√©parer le flux de journaux</b> , en int√©grant l'envoi des plus pr√©cieux directement dans l'application pour assurer leur s√©curit√©.  De plus, il ne sera pas superflu de cr√©er une sorte de <b>¬´batterie¬ª de journaux</b> qui puisse survivre √† la br√®ve indisponibilit√© du stockage tout en conservant les messages critiques. <br><br>  Enfin, n'oubliez pas <b>qu'il est important de surveiller tout sous-syst√®me de mani√®re qualitative</b> .  Sinon, il est facile de rencontrer une situation dans laquelle fluentd est dans l'√©tat <code>CrashLoopBackOff</code> et n'envoie rien, ce qui promet la perte d'informations importantes. <br><br><h2>  Conclusions </h2><br>  Dans cet article, nous ne consid√©rons pas les solutions SaaS comme Datadog.  Bon nombre des probl√®mes d√©crits ici ont d√©j√† √©t√© r√©solus d'une mani√®re ou d'une autre par des soci√©t√©s commerciales sp√©cialis√©es dans la collecte de journaux, mais tout le monde ne peut pas utiliser le SaaS pour diverses raisons <i>(les principales sont le co√ªt et la conformit√© avec 152-)</i> . <br><br>  La collecte centralis√©e des journaux ressemble √† premi√®re vue √† une t√¢che simple, mais elle ne l'est pas du tout.  Il est important de se rappeler que: <br><br><ul><li>  La journalisation d√©taill√©e n'est que des composants critiques, et pour d'autres syst√®mes, vous pouvez configurer la surveillance et la collecte des erreurs. </li><li>  Les grumes en production doivent √™tre minimis√©es afin de ne pas donner une charge suppl√©mentaire. </li><li>  Les journaux doivent √™tre lisibles par machine, normalis√©s, avoir un format strict. </li><li>  Les journaux vraiment critiques doivent √™tre envoy√©s dans un flux distinct, qui doit √™tre s√©par√© des principaux. </li><li>  Il vaut la peine d'envisager une batterie de journaux, qui peut √©conomiser des rafales de charge √©lev√©e et rendre la charge sur le stockage plus uniforme. </li></ul><br><img src="https://habrastorage.org/webt/ss/hd/9f/sshd9fqiav2abndbb_uqo0mdjke.jpeg" align="left"><br>  Ces r√®gles simples, si elles √©taient appliqu√©es partout, permettraient aux circuits d√©crits ci-dessus de fonctionner - m√™me s'ils manquent de composants importants (batterie).  Si vous n'adh√©rez pas √† ces principes, la t√¢che vous m√®nera facilement, vous et l'infrastructure, vers un autre composant tr√®s charg√© (et en m√™me temps inefficace) du syst√®me. <br><br><h2>  PS </h2><br>  Lisez aussi dans notre blog: <br><br><ul><li>  ¬´ <a href="https://habr.com/ru/company/flant/blog/341386/">Pr√©sentation de loghouse - un syst√®me open source pour travailler avec les journaux dans Kubernetes</a> ¬ª; </li><li>  " <a href="https://m.habr.com/ru/news/t/476966/">Versions pour l'√©cosyst√®me Kubernetes avec KubeCon'19: JFrog Container Registry, Kui d'IBM, Loki 1.0.0 ...</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/412901/">Monitoring and Kubernetes (revue et reportage vid√©o)</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr480946/">https://habr.com/ru/post/fr480946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr480930/index.html">Tapez tout</a></li>
<li><a href="../fr480936/index.html">IntelliJ IDEA conversion rapide UPPER_CASE en camelCase</a></li>
<li><a href="../fr480938/index.html">La crypto-monnaie √† travers les yeux des juges russes</a></li>
<li><a href="../fr480940/index.html">Ex√©cutez un test d'interface utilisateur multi-navigateur avec Cucumber et Selenoid dans Gitlab CI avec rapport Allure</a></li>
<li><a href="../fr480944/index.html">Top 5 des tendances du marketing par e-mail en 2020</a></li>
<li><a href="../fr480948/index.html">Marketing Mitap et RP √† Ivanovo</a></li>
<li><a href="../fr480950/index.html">Analyse du quiz Android du stand hh.ru au Mobius 2019 Moscou</a></li>
<li><a href="../fr480954/index.html">Num√©ro de t√¢che 1. D√©couvrez le sexe et le degr√© de relation</a></li>
<li><a href="../fr480956/index.html">Comment j'ai trouv√© un moyen de suivre tous les pilotes Citimobil</a></li>
<li><a href="../fr480958/index.html">Connexion satellite. Vue d'ensemble des soci√©t√©s op√©rateurs et un peu sur la notation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
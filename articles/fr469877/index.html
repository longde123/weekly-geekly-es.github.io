<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•ì üöñ üéé Oh cette m√©thode de Newton üë™ ‚Ü©Ô∏è üíÖüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Beaucoup a √©t√© √©crit sur les m√©thodes d'optimisation num√©rique. Cela est compr√©hensible, en particulier dans le contexte des succ√®s r√©cemment d√©montr√©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Oh cette m√©thode de Newton</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/469877/">  Beaucoup a √©t√© √©crit sur les m√©thodes d'optimisation num√©rique.  Cela est compr√©hensible, en particulier dans le contexte des succ√®s r√©cemment d√©montr√©s par les r√©seaux de neurones profonds.  Et il est tr√®s gratifiant qu'au moins certains passionn√©s s'int√©ressent non seulement √† la fa√ßon de bombarder leur r√©seau de neurones sur les frameworks qui ont gagn√© en popularit√© sur Internet, mais aussi √† savoir comment et pourquoi tout cela fonctionne.  Cependant, j'ai r√©cemment d√ª noter que lorsque l'on pose des questions li√©es √† la formation des r√©seaux de neurones (et pas seulement √† la formation, et pas seulement aux r√©seaux), y compris sur Habr√©, un certain nombre de d√©clarations ¬´bien connues¬ª sont utilis√©es pour la transmission, dont la validit√© est pour le dire doucement, douteux.  Parmi ces d√©clarations douteuses: <br><br><ol><li>  Les m√©thodes du deuxi√®me ordre et plus ne fonctionnent pas bien dans les t√¢ches de formation des r√©seaux de neurones.  Parce que √ßa. </li><li>  La m√©thode de Newton n√©cessite une d√©finition positive de la matrice de Hesse (d√©riv√©es secondes) et ne fonctionne donc pas bien. <br></li><li>  La m√©thode de Levenberg-Marquardt est un compromis entre la descente de gradient et la m√©thode de Newton et est g√©n√©ralement heuristique. <br></li></ol><br>  etc.  Que de continuer cette liste, il vaut mieux se mettre aux affaires.  Dans cet article, nous examinerons la deuxi√®me d√©claration, car je ne l'ai rencontr√© qu'au moins deux fois √† Habr√©.  Je n'aborderai la premi√®re question que dans la partie concernant la m√©thode de Newton, car elle est beaucoup plus √©tendue.  Le troisi√®me et le reste seront laiss√©s jusqu'√† des temps meilleurs. <br><a name="habracut"></a><br>  Le centre de notre attention sera la t√¢che de l'optimisation inconditionnelle <img src="https://habrastorage.org/getpro/habr/post_images/823/e50/c93/823e50c935e4cc19a175f53c17ca79af.gif" title="&quot;f (x) \ rightarrow \ min&quot;">  o√π <img src="https://habrastorage.org/getpro/habr/post_images/bc7/838/e10/bc7838e10e143195c0381efbf0671cce.gif" title="&quot;x = (x_ {1}, x_ {2}, \ points)&quot;">  - un point d'espace vectoriel, ou simplement - un vecteur.  Naturellement, cette t√¢che est plus facile √† r√©soudre, plus nous en savons sur <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  .  Il est g√©n√©ralement suppos√© √™tre diff√©renciable en ce qui concerne chaque argument <img src="https://habrastorage.org/getpro/habr/post_images/6d8/d4e/07d/6d8d4e07d259325d5dd652e4b3b97af6.gif" title="&quot;x_ {k}&quot;">  , et autant de fois que n√©cessaire pour nos actes sales.  Il est bien connu qu'une condition n√©cessaire pour cela √† un moment donn√© <img src="https://habrastorage.org/getpro/habr/post_images/8ae/e32/d7e/8aee32d7e93fb189b268894bf91622b0.gif" title="&quot;x ^ {*}&quot;">  le minimum est atteint, c'est l'√©galit√© du gradient de la fonction <img src="https://habrastorage.org/getpro/habr/post_images/735/1d5/454/7351d54544ca7acc4b7a9bff7a2c2f6a.gif" title="&quot;\ bigtriangledown f (x ^ {*})&quot;">  √† ce point z√©ro.  De l√†, nous obtenons instantan√©ment la m√©thode de minimisation suivante: <br><br>  R√©soudre l'√©quation <img src="https://habrastorage.org/getpro/habr/post_images/d59/223/ac1/d59223ac159bfe660ea26a1d60f8f33f.gif" title="&quot;\ bigtriangledown f (x) = 0&quot;">  . <br><br>  La t√¢che, pour le moins, n'est pas facile.  Certainement pas plus facile que l'original.  Cependant, √† ce stade, nous pouvons imm√©diatement noter le lien entre le probl√®me de minimisation et le probl√®me de la r√©solution d'un syst√®me d'√©quations non lin√©aires.  Cette connexion nous reviendra lors de l'examen de la m√©thode Levenberg-Marquardt (lorsque nous y arriverons).  En attendant, rappelez-vous (ou d√©couvrez) que l'une des m√©thodes les plus couramment utilis√©es pour r√©soudre des syst√®mes d'√©quations non lin√©aires est la m√©thode de Newton.  Il consiste dans le fait que pour r√©soudre l'√©quation <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="&quot;F (x) = 0&quot;">  on part d'une approximation initiale <img src="https://habrastorage.org/getpro/habr/post_images/460/82f/7d6/46082f7d6471c3fabb832d8f94075758.gif" title="&quot;x_ {0}&quot;">  construire une s√©quence <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3a0/23d/4a2/3a023d4a27cdff86f8cf3bc78d5b3a21.gif" title="&quot;x_ {i + 1} = x_ {i} -H ^ {- 1} (x_ {i}) F (x_ {i})&quot;">  - La m√©thode explicite de Newton <br><br>  ou <br><br><img src="https://habrastorage.org/getpro/habr/post_images/116/6fa/27b/1166fa27b4038fed75d435daaaab53fe.gif" title="&quot;\ begin {cases} H (x_ {i}) p_ {i} = - F (x_ {i}) \\ x_ {i + 1} = x_ {i} + p_ {i} \ end {cases}&quot;">  - La m√©thode implicite de Newton <br><br>  o√π <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  - matrice compos√©e de d√©riv√©es partielles d'une fonction <img src="https://habrastorage.org/getpro/habr/post_images/01a/a15/8fc/01aa158fc8bc3d7f7f3b2807df8b4a5e.gif" title="&quot;F&quot;">  .  Naturellement, dans le cas g√©n√©ral, lorsque le syst√®me d'√©quations non lin√©aires nous est simplement donn√© en sensations, il faut quelque chose de la matrice <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  nous n'avons pas droit.  Dans le cas o√π l'√©quation est une condition minimale pour une fonction, nous pouvons affirmer que la matrice <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  sym√©trique.  Mais pas plus. <br><br>  La m√©thode de Newton pour r√©soudre des syst√®mes d'√©quations non lin√©aires est tr√®s bien √©tudi√©e.  Et voici la chose - pour sa convergence, le caract√®re d√©finitif positif de la matrice n'est pas n√©cessaire <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  .  Oui, et ne peut √™tre exig√© - sinon il aurait √©t√© sans valeur.  Au lieu de cela, il existe d'autres conditions qui assurent la convergence locale de cette m√©thode et que nous ne consid√©rerons pas ici, en envoyant les personnes int√©ress√©es √† la litt√©rature sp√©cialis√©e (ou dans le commentaire).  Nous obtenons que la d√©claration 2 est fausse. <br><br>  Alors? <br><br>  Oui et non.  L'embuscade ici dans le mot est la convergence locale avant le mot.  Cela signifie que l'approximation initiale <img src="https://habrastorage.org/getpro/habr/post_images/460/82f/7d6/46082f7d6471c3fabb832d8f94075758.gif" title="&quot;x_ {0}&quot;">  doit √™tre ¬´assez proche¬ª de la solution, sinon √† chaque √©tape nous en serons de plus en plus √©loign√©s.  Que faire?  Je n'entrerai pas dans les d√©tails de la mani√®re dont ce probl√®me est r√©solu pour les syst√®mes d'√©quations non lin√©aires de forme g√©n√©rale.  Revenons plut√¥t √† notre t√¢che d'optimisation.  La premi√®re erreur de l'√©nonc√© 2 est en fait qu'en parlant g√©n√©ralement de la m√©thode de Newton dans les probl√®mes d'optimisation, cela signifie sa modification - la m√©thode de Newton amortie, dans laquelle la s√©quence d'approximations est construite selon la r√®gle <br><br><img src="https://habrastorage.org/getpro/habr/post_images/23d/ca8/404/23dca84042b77a1560b8cd2db607e8ae.gif" title="&quot;x_ {i + 1} = x_ {i} - \ alpha_ {i} H ^ {- 1} (x_ {i}) F (x_ {i})&quot;">  - La m√©thode amortie explicite de Newton <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d4/67c/c96/9d467cc96266cf1179d3e553718f5bee.gif" title="&quot;\ begin {cases} H (x_ {i}) p_ {i} = - F (x_ {i}) \\ x_ {i + 1} = x_ {i} + \ alpha_ {i} p_ {i} \ fin {cas} &quot;">  - La m√©thode amortie implicite de Newton <br><br>  Voici la s√©quence <img src="https://habrastorage.org/getpro/habr/post_images/c70/738/fd1/c70738fd1eb4d9bfff34f20904f41bbf.gif" title="&quot;\ {\ alpha_ {i} \}&quot;">  est un param√®tre de la m√©thode et sa construction est une t√¢che distincte.  Dans les probl√®mes de minimisation, naturel lors du choix <img src="https://habrastorage.org/getpro/habr/post_images/eb2/94d/fe4/eb294dfe4cfca7355f8b030f3d7dade8.gif" title="&quot;\ alpha_ {i}&quot;">  il faudra que, √† chaque it√©ration, la valeur de la fonction f diminue, c'est-√†-dire <img src="https://habrastorage.org/getpro/habr/post_images/3ae/e45/ba0/3aee45ba0097ca8bdc8a23ef6a465f21.gif" title="&quot;f (x_ {i + 1}) &amp; lt; f (x_ {i})&quot;">  .  Une question logique se pose: existe-t-il un tel (positif) <img src="https://habrastorage.org/getpro/habr/post_images/eb2/94d/fe4/eb294dfe4cfca7355f8b030f3d7dade8.gif" title="&quot;\ alpha_ {i}&quot;">  ?  Et si la r√©ponse √† cette question est positive, alors <img src="https://habrastorage.org/getpro/habr/post_images/cf2/deb/64e/cf2deb64e8b0e4d34902a32a5fd93b7b.gif" title="&quot;p_ {i}&quot;">  appel√© le sens de la descente.  Ensuite, la question peut √™tre pos√©e de cette fa√ßon: <br>  <i>quand la direction g√©n√©r√©e par la m√©thode de Newton est-elle la direction de descente?</i> <br>  Et pour y r√©pondre, vous devrez regarder le probl√®me de la minimisation d'un autre c√¥t√©. <br><br><h2>  M√©thodes de descente </h2><br>  Pour le probl√®me de minimisation, cette approche semble assez naturelle: √† partir d'un point arbitraire, nous choisissons la direction p d'une certaine mani√®re et faisons un pas dans cette direction <img src="https://habrastorage.org/getpro/habr/post_images/fbf/01e/b21/fbf01eb21703831c5dd0e196a2efccc2.gif" title="&quot;\ alpha p&quot;">  .  Si <img src="https://habrastorage.org/getpro/habr/post_images/bd9/6f9/580/bd96f95806b05f65a5766db233a85653.gif" title="&quot;f (x + \ alpha p) &amp; lt; f (x)&quot;">  puis prenez <img src="https://habrastorage.org/getpro/habr/post_images/b87/e59/538/b87e59538ed10c96ec3db2e7bad8dc85.gif" title="&quot;x + \ alpha p&quot;">  comme nouveau point de d√©part et r√©p√©tez la proc√©dure.  Si la direction est choisie arbitrairement, une telle m√©thode est parfois appel√©e m√©thode de marche al√©atoire.  Il est possible de prendre des vecteurs de base unitaire comme direction - c'est-√†-dire de faire un pas dans une seule coordonn√©e, cette m√©thode est appel√©e m√©thode de descente de coordonn√©es.  Inutile de dire qu'ils sont inefficaces?  Pour que cette approche fonctionne bien, nous avons besoin de garanties suppl√©mentaires.  Pour ce faire, nous introduisons une fonction auxiliaire <img src="https://habrastorage.org/getpro/habr/post_images/8bf/1d5/4e1/8bf1d54e1f36dd4c9dfd5720437af51c.gif" title="&quot;g (p) = f (x + p)&quot;">  .  Je pense qu'il est √©vident que la minimisation <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  compl√®tement √©quivalent √† minimiser <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="g">  .  Si <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  diff√©renciable alors <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="g">  peut √™tre repr√©sent√© comme <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e47/615/d31/e47615d310276ab67a9163889a2335a5.gif" title="&quot;g (p) = f (x) + \ bigtriangledown f ^ {T} (x) p + o (\ parallel p \ parallel ^ {2})&quot;"><br><br>  et si <img src="https://habrastorage.org/getpro/habr/post_images/2a7/342/acb/2a7342acbe0772f75af6eee281c247d0.gif" title="&quot;\ parall√®le p \ parall√®le&quot;">  assez petit alors <img src="https://habrastorage.org/getpro/habr/post_images/2ef/8a9/23f/2ef8a923f49cf84264effb5f3f703c31.gif" title="&quot;g (p) \ approx \ bar {g} (p) = f (x) + \ bigtriangledown f ^ {T} (x) p&quot;">  .  Nous pouvons maintenant essayer de remplacer le probl√®me de minimisation <img src="https://habrastorage.org/getpro/habr/post_images/076/563/484/076563484d4e576c5c48098bfa94d45c.gif" title="&quot;g (p)&quot;">  la t√¢che de minimiser son approximation (ou <i>mod√®le</i> ) <img src="https://habrastorage.org/getpro/habr/post_images/174/774/888/1747748884846362babfd8fe73857f1e.gif" title="&quot;\ bar {g} (p)&quot;">  .  Soit dit en passant, toutes les m√©thodes bas√©es sur l'utilisation du mod√®le <img src="https://habrastorage.org/getpro/habr/post_images/174/774/888/1747748884846362babfd8fe73857f1e.gif" title="&quot;\ bar {g} (p)&quot;">  appel√© gradient.  Mais le probl√®me est, <img src="https://habrastorage.org/getpro/habr/post_images/462/957/dda/462957dda265f4fb8be04327f1c12b0f.gif" title="&quot;\ bar {g}&quot;">  Est une fonction lin√©aire et, par cons√©quent, elle n'a pas de minimum.  Pour r√©soudre ce probl√®me, nous ajoutons une restriction sur la longueur de l'√©tape que nous voulons effectuer.  Dans ce cas, il s'agit d'une exigence tout √† fait naturelle - car notre mod√®le d√©crit plus ou moins correctement la fonction objectif uniquement dans un voisinage suffisamment petit.  En cons√©quence, nous obtenons un probl√®me suppl√©mentaire d'optimisation conditionnelle: <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/8a2/c43/279/8a2c4327974067619cfad20b7ea1e821.gif" title="\\\ bar {g} (p) = f (x) + \ bigtriangledown f ^ {T} (x) p \ rightarrow \ min \\ \ parallel p \ parallel_ {2} = \ Delta"></a> <br><br>  Cette t√¢che a une solution √©vidente: <img src="https://habrastorage.org/getpro/habr/post_images/3ff/1f6/a21/3ff1f6a2117e5d9a99603bcc8fde4f69.gif" title="&quot;p = - \ beta \ bigtriangledown f (x)&quot;">  o√π <img src="https://habrastorage.org/getpro/habr/post_images/76d/0eb/69b/76d0eb69ba026a58bbe3edd275fee712.gif" title="&quot;\ beta&quot;">  - facteur garantissant le respect de la contrainte.  Les it√©rations de la m√©thode de descente prennent alors la forme <br><br><img src="https://habrastorage.org/getpro/habr/post_images/966/987/c25/966987c257a50df1855a50ea363350dd.gif" title="&quot;x_ {i + 1} = x_ {i} - \ beta \ bigtriangledown f (x_ {i})&quot;">  , <br><br>  dans lequel nous apprenons la <b>m√©thode</b> bien connue de <b>descente de gradient</b> .  Param√®tre <img src="https://habrastorage.org/getpro/habr/post_images/76d/0eb/69b/76d0eb69ba026a58bbe3edd275fee712.gif" title="&quot;\ beta&quot;">  , qui est g√©n√©ralement appel√©e vitesse de descente, a maintenant acquis une signification compr√©hensible, et sa valeur est d√©termin√©e √† partir de la condition que le nouveau point se trouve sur une sph√®re d'un rayon donn√©, circonscrite autour de l'ancien point. <br><br>  Sur la base des propri√©t√©s du mod√®le construit de la fonction objectif, nous pouvons affirmer qu'il existe une telle <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  , m√™me s'il est tr√®s petit, et si <img src="https://habrastorage.org/getpro/habr/post_images/84b/5fd/00f/84b5fd00fe1f4ca32b7cd7bd095a1490.gif" title="&quot;\ bar {g} (p) &amp; lt; \ bar {g} (0)&quot;">  alors <img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="&quot;g (p) &amp; lt; g (0)&quot;">  .  Il est √† noter que dans ce cas, la direction dans laquelle nous nous d√©placerons ne d√©pend pas de la taille du rayon de cette sph√®re.  Ensuite, nous pouvons choisir l'une des mani√®res suivantes: <br><br><ol><li>  S√©lectionnez selon une m√©thode la valeur <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  . </li><li>  D√©finissez la t√¢che de choisir la valeur appropri√©e <img src="https://habrastorage.org/getpro/habr/post_images/76d/0eb/69b/76d0eb69ba026a58bbe3edd275fee712.gif" title="&quot;\ beta&quot;">  , fournissant une diminution de la valeur de la fonction objectif. </li></ol><br>  La premi√®re approche est typique des <i>m√©thodes de la r√©gion de confiance</i> , la seconde conduit √† la formulation du probl√®me auxiliaire de la soi-disant  <i>recherche lin√©aire (LineSearch)</i> .  Dans ce cas particulier, les diff√©rences entre ces approches sont faibles et nous ne les consid√©rerons pas.  Faites plut√¥t attention aux points suivants: <br><br>  <b><i>pourquoi, en fait, recherchons-nous un d√©calage</i></b> <b><i><img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;"></i></b>  <b><i>couch√© exactement sur la sph√®re?</i></b> <br><br>  En fait, nous pourrions bien remplacer cette restriction par l'exigence, par exemple, que p appartienne √† la surface du cube, c'est-√†-dire, <img src="https://habrastorage.org/getpro/habr/post_images/cf1/a35/92e/cf1a3592ebe97c9e262a083ea44c594c.gif" title="&quot;\ parallel p \ parallel _ {\ infty} = \ Delta&quot;">  (dans ce cas, ce n'est pas trop raisonnable, mais pourquoi pas), ou une surface elliptique?  Cela semble d√©j√† tout √† fait logique, si nous rappelons les probl√®mes qui se posent lors de la minimisation des fonctions de ravin.  L'essence du probl√®me est que le long de certaines lignes de coordonn√©es, la fonction change beaucoup plus rapidement que sur d'autres.  Pour cette raison, nous obtenons que si l'incr√©ment doit appartenir √† la sph√®re, alors la quantit√© <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  √† laquelle la ¬´descente¬ª est pr√©vue doit √™tre tr√®s faible.  Et cela conduit au fait que l'atteinte d'un minimum n√©cessitera un tr√®s grand nombre d'√©tapes.  Mais si au lieu de cela nous prenons une ellipse appropri√©e comme voisinage, alors ce probl√®me viendra par magie √† n√©ant. <br><br>  Par la condition d'appartenance des points de la surface elliptique, elle peut s'√©crire <img src="https://habrastorage.org/getpro/habr/post_images/6ff/1b4/930/6ff1b49309ec84aa656d848764359b4e.gif" title="&quot;\ parallel p \ parallel_ {B} = \ sqrt {p ^ {T} Bp} = \ Delta&quot;">  o√π <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  Est une matrice d√©finie positive, √©galement appel√©e m√©trique.  Norm <img src="https://habrastorage.org/getpro/habr/post_images/ab8/b42/711/ab8b42711a932f9129bdb193b6a74360.gif" title="&quot;\ parallel \ cdot \ parallel_ {B}&quot;">  appel√© la norme elliptique induite par la matrice <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  .  De quel type de matrice s'agit-il et o√π l'obtenir - nous y r√©fl√©chirons plus tard, et maintenant nous arrivons √† une nouvelle t√¢che. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f4c/cc0/757/f4ccc0757e09fb304ff10a9a8c4751b6.gif" title="\\\ bar {g} (p) = f (x) + \ bigtriangledown f ^ {T} (x) p \ rightarrow \ min \\ \ dfrac {1} {2} \ parallel p \ parallel_ {B} ^ {2} = \ Delta"></a> <br><br>  Le carr√© de la norme et le facteur 1/2 sont ici uniquement pour plus de commodit√©, afin de ne pas salir les racines.  En appliquant la m√©thode du multiplicateur de Lagrange, on obtient le probl√®me li√© de l'optimisation inconditionnelle <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/605/36d/d5e/60536dd5e2297580940a5b926760a3ce.gif" title="f (x) + \ bigtriangledown f ^ {T} (x) p + \ dfrac {\ lambda} {2} p ^ {T} Bp- \ lambda \ Delta \ rightarrow \ min"></a> <br><br>  Une condition n√©cessaire pour un minimum car c'est <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/4c5/f7e/921/4c5f7e921637c73fcb992c5d9b9efcd6.gif" title="\ bigtriangledown f (x) + \ lambda Bp = 0"></a>  , ou <img src="https://habrastorage.org/getpro/habr/post_images/a80/6c9/ff7/a806c9ff7ce22ea27c87b6a61a4c8fed.gif" title="&quot;B \ left (\ lambda p \ right) = - \ bigtriangledown f (x)&quot;">  d'o√π <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/b50/032/3a9/b500323a970c7ae821295450627bdad2.gif" title="p = - \ dfrac {1} {\ lambda} B ^ {- 1} \ bigtriangledown f (x) = \ dfrac {1} {\ lambda} \ bar {p}"></a> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/697/906/5d7/6979065d729033e0093ffad8475e80a6.gif" title="\\\ dfrac {1} {\ lambda ^ {2}} \ left (B ^ {- 1} \ bigtriangledown f (x) \ right) ^ {T} B \ left (B ^ {- 1} \ bigtriangledown f (x) \ right) = \ dfrac {1} {\ lambda ^ {2}} \ bigtriangledown f (x) ^ {T} B ^ {- 1} BB ^ {- 1} \ bigtriangledown f (x) = \ \ = \ dfrac {1} {\ lambda ^ {2}} \ bigtriangledown f (x) ^ {T} B ^ {- 1} \ bigtriangledown f (x) = \ Delta"></a> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/41f/689/d89/41f689d890b92c84f05fdd0ede8a8114.gif" title="\ lambda = \ sqrt {\ dfrac {1} {\ Delta} \ bigtriangledown f (x) ^ {T} B ^ {- 1} \ bigtriangledown f (x)}> 0"></a> <br><br>  Encore une fois, nous voyons que la direction <img src="https://habrastorage.org/getpro/habr/post_images/45b/686/bb0/45b686bb0219a74b212cfdeaf1998653.gif" title="&quot;\ bar {p} = - B ^ {- 1} \ bigtriangledown f (x)&quot;">  , dans lequel nous allons nous d√©placer, ne d√©pend pas de la valeur <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  - uniquement √† partir de la matrice <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  .  Et encore une fois, nous pouvons soit ramasser <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  qui est lourde de la n√©cessit√© de calculer <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  et inversion matricielle explicite <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  , ou r√©soudre le probl√®me auxiliaire de trouver un biais appropri√© <img src="https://habrastorage.org/getpro/habr/post_images/b7b/6a7/371/b7b6a73716dc8f4e40a52c1c5ef0e6b4.gif" title="&quot;x_ {i + 1} = x_ {i} + \ beta \ bar {p} _ {i}&quot;">  .  Depuis <img src="https://habrastorage.org/getpro/habr/post_images/0b8/52f/d1b/0b852fd1bbc20f2966bf757a56186312.gif" title="&quot;\ lambda &amp; gt; 0&quot;">  , la solution √† ce probl√®me auxiliaire est garantie d'exister. <br><br>  Alors, que devrait-il √™tre pour la matrice B?  Nous nous limitons aux id√©es sp√©culatives.  Si la fonction objectif <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  - quadratique, c'est-√†-dire qu'il a la forme <img src="https://habrastorage.org/getpro/habr/post_images/974/f7f/cf6/974f7fcf6345b91ef8466f2cabba6efe.gif" title="&quot;f (x) = a + b ^ {T} x + x ^ {T} Hx&quot;">  o√π <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  positif d√©fini, il est √©vident que le meilleur candidat pour le r√¥le de la matrice <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  est jute <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  , car dans ce cas, une it√©ration de la m√©thode de descente que nous avons construite est requise.  Si H n'est pas d√©fini positif, alors il ne peut pas s'agir d'une m√©trique, et les it√©rations construites avec lui sont des it√©rations de la m√©thode de Newton amortie, mais ce ne sont pas des it√©rations de la m√©thode de descente.  Enfin, nous pouvons donner une r√©ponse rigoureuse √† <br><br>  <b>Question:</b> <i>La matrice de Hesse dans la m√©thode de Newton doit-elle √™tre d√©finie positive?</i> <br>  <b>R√©ponse:</b> <i>non, ce n'est requis ni dans la m√©thode standard ni dans la m√©thode de Newton amortie.</i>  <i>Mais si cette condition est satisfaite, alors la m√©thode de Newton amortie est une m√©thode de descente et a la propri√©t√© d' <i>une</i> convergence <i>globale</i> , et pas seulement locale.</i> <br><br>  √Ä titre d'illustration, voyons √† quoi ressemblent les r√©gions de confiance lors de la r√©duction de la fonction bien connue de Rosenbrock √† l'aide de la descente en gradient et des m√©thodes de Newton, et comment la forme des r√©gions affecte la convergence du processus. <br><br><img src="https://habrastorage.org/webt/_x/30/nx/_x30nxs-eyrixuan0-diyvwixww.gif" width="600"><br><br>  C'est ainsi que la m√©thode de descente se comporte avec une r√©gion de confiance sph√©rique, c'est aussi une descente en gradient.  Tout est comme un manuel - nous sommes coinc√©s dans un canyon. <br><br><img src="https://habrastorage.org/webt/9x/ik/td/9xiktd4lapdka-uk010evfvlcdm.gif" width="600"><br><br>  Et c'est ce que nous obtenons si la r√©gion de confiance a la forme d'une ellipse d√©finie par la matrice de Hesse.  Ce n'est rien de plus qu'une it√©ration de la m√©thode Newton amortie. <br><br>  Seule la question de savoir quoi faire si la matrice de Hesse n'est pas d√©finie positive est rest√©e non r√©solue.  Il existe de nombreuses options.  Le premier est de marquer.  Vous avez peut-√™tre de la chance et les it√©rations de Newton convergeront sans cette propri√©t√©.  Ceci est tout √† fait r√©el, en particulier aux √©tapes finales du processus de minimisation, lorsque vous √™tes d√©j√† suffisamment proche d'une solution.  Dans ce cas, les it√©rations de la m√©thode standard de Newton peuvent √™tre utilis√©es sans se soucier de la recherche d'un quartier admissible √† la descente.  Ou utilisez des it√©rations de la m√©thode Newton amortie dans le cas de <img src="https://habrastorage.org/getpro/habr/post_images/6da/2c0/bc5/6da2c0bc54434a64d7630c142d0c7bf9.gif" title="&quot;\ beta = 0&quot;">  c'est-√†-dire que dans le cas o√π la direction obtenue n'est pas la direction de descente, changez-la, disons, en anti-gradient.  <i>Il suffit de ne pas v√©rifier explicitement si la Hesse est d√©finie positive selon le crit√®re Sylvestre</i> , comme cela a √©t√© fait <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici !!!</a>  .  C'est inutile et inutile. <br>  Des m√©thodes plus subtiles impliquent la construction d'une matrice, dans un sens proche de la matrice de Hesse, mais poss√©dant la propri√©t√© d'√™tre d√©finitivement d√©finitif, notamment en corrigeant les valeurs propres.  Un autre sujet est les m√©thodes quasi-newtoniennes, ou m√©thodes m√©triques variables, qui garantissent le caract√®re d√©finitif positif de la matrice B et ne n√©cessitent pas le calcul des d√©riv√©es secondes.  En g√©n√©ral, une discussion d√©taill√©e de ces questions d√©passe largement le cadre de cet article. <br><br>  Oui, et en passant, il r√©sulte de ce qui a √©t√© dit que <i>la m√©thode amortie de Newton avec une d√©finition positive de la Hesse est une m√©thode de gradient</i> .  Ainsi que des m√©thodes quasi-newtoniennes.  Et bien d'autres, bas√©s sur un choix s√©par√© de direction et de taille de pas.  Il est donc incorrect de comparer la m√©thode de Newton √† la terminologie du gradient. <br><br><h2>  Pour r√©sumer </h2><br>  La m√©thode de Newton, dont on se souvient souvent lors de l'examen des m√©thodes de minimisation, n'est g√©n√©ralement pas la m√©thode de Newton dans son sens classique, mais la m√©thode de descente avec la m√©trique sp√©cifi√©e par la Hesse de la fonction objectif.  Et oui, il converge globalement si la Hesse est partout d√©finie positive.  Cela n'est possible que pour les fonctions convexes, qui sont beaucoup moins courantes dans la pratique que nous le souhaiterions, donc dans le cas g√©n√©ral, sans les modifications appropri√©es, l'application de la m√©thode de Newton (nous ne nous d√©tacherons pas du collectif et continuerons √† l'appeler ainsi) ne garantit pas le r√©sultat correct.  L'apprentissage des r√©seaux de neurones, m√™me peu profonds, conduit g√©n√©ralement √† des probl√®mes d'optimisation non convexes avec de nombreux minima locaux.  Et voici une nouvelle embuscade.  La m√©thode de Newton converge g√©n√©ralement (si elle converge) rapidement.  Je veux dire tr√®s vite.  Et cela, curieusement, est mauvais, car nous arrivons √† un minimum local en plusieurs it√©rations.  Et cela pour les fonctions avec un terrain complexe peut √™tre bien pire que le global.  La descente en pente avec recherche lin√©aire converge beaucoup plus lentement, mais est plus susceptible de ¬´sauter¬ª les ar√™tes de la fonction objectif, ce qui est tr√®s important dans les premiers stades de la minimisation.  Si vous avez d√©j√† bien r√©duit la valeur de la fonction objectif et que la convergence de la descente du gradient a consid√©rablement ralenti, un changement de m√©trique pourrait bien acc√©l√©rer le processus, mais c'est pour les √©tapes finales. <br><br>  Bien s√ªr, cet argument n'est pas universel, pas incontestable, et dans certains cas, m√™me incorrect.  Ainsi que l'affirmation que les m√©thodes de gradient fonctionnent mieux dans les probl√®mes d'apprentissage. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr469877/">https://habr.com/ru/post/fr469877/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr469861/index.html">Structures de donn√©es pour les programmeurs de jeux: donn√©es en masse</a></li>
<li><a href="../fr469865/index.html">700 employ√©s et plusieurs continents: comment Alconost a construit un mod√®le commercial sans officier</a></li>
<li><a href="../fr469869/index.html">Pourquoi vous devriez overclocker la RAM (c'est facile!)</a></li>
<li><a href="../fr469871/index.html">Quand les claviers √©taient des tables</a></li>
<li><a href="../fr469875/index.html">Comment prot√©ger vos mots de passe en 2019</a></li>
<li><a href="../fr469879/index.html">Double VPN en un clic. Comment diviser facilement l'adresse IP d'un point d'entr√©e et de sortie</a></li>
<li><a href="../fr469881/index.html">Les trois premiers jours de la vie d'un billet sur Habr√©</a></li>
<li><a href="../fr469883/index.html">Est-il possible de programmer l'al√©atoire?</a></li>
<li><a href="../fr469885/index.html">D√©sactiver la console locale lors de l'utilisation de x11vnc</a></li>
<li><a href="../fr469893/index.html">Maison avec des √©l√©ments de haute technologie pour un chat sans-abri</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
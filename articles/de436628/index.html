<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ”¬ ğŸ¤¶ğŸ¼ ğŸ‘©â€ğŸ”¬ Verbesserung des aktienbasierten Q-Learning-Agenten durch HinzufÃ¼gen von Wiederholungen und Belohnungen ğŸ’˜ ğŸ‘¨ğŸ»â€ğŸ« ğŸ’¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Erinnerung 
 Hallo Habr! Ich mache Sie auf eine weitere Ãœbersetzung meines neuen Artikels aus dem Medium aufmerksam . 

 Beim letzten Mal ( erster Art...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verbesserung des aktienbasierten Q-Learning-Agenten durch HinzufÃ¼gen von Wiederholungen und Belohnungen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436628/"><h3>  Erinnerung </h3><br>  Hallo Habr!  Ich mache Sie auf eine weitere Ãœbersetzung meines neuen Artikels aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Medium aufmerksam</a> . <br><br>  Beim letzten Mal ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erster Artikel</a> ) ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Habr</a> ) haben wir einen Agenten mit Q-Learning-Technologie erstellt, der Transaktionen mit simulierten und realen Austauschzeitreihen durchfÃ¼hrt, und versucht zu prÃ¼fen, ob dieser Aufgabenbereich fÃ¼r verstÃ¤rktes Lernen geeignet ist. <br><br>  Dieses Mal werden wir eine LSTM-Ebene hinzufÃ¼gen, um ZeitabhÃ¤ngigkeiten innerhalb der Trajektorie zu berÃ¼cksichtigen und das Belohnungs-Shaping-Engineering basierend auf PrÃ¤sentationen durchzufÃ¼hren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3c4/e75/63f/3c4e7563f3cf1e6f158dc0605fe80a78.png" alt="Bild"><br><a name="habracut"></a><br>  Ich mÃ¶chte Sie daran erinnern, dass wir zur ÃœberprÃ¼fung des Konzepts die folgenden synthetischen Daten verwendet haben: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fb2/f15/3b6/fb2f153b6c4e14ff1dc19d61a524f5e8.png" alt="Bild"><br><br>  Synthetische Daten: Sinus mit weiÃŸem Rauschen. <br><br>  Die Sinusfunktion war der erste Ausgangspunkt.  Zwei Kurven simulieren den Kauf- und Verkaufspreis eines VermÃ¶genswerts, wobei der Spread die minimalen Transaktionskosten darstellt. <br><br>  Dieses Mal mÃ¶chten wir diese einfache Aufgabe jedoch komplizieren, indem wir den Kreditzuweisungspfad erweitern: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/561/c36/928/561c369289780642ca5b22c852d06a8b.png" alt="Bild"><br><br>  Synthetische Daten: Sinus mit weiÃŸem Rauschen. <br><br>  Die Sinusphase wurde verdoppelt. <br><br>  Dies bedeutet, dass sich die spÃ¤rlichen Belohnungen, die wir verwenden, Ã¼ber lÃ¤ngere Flugbahnen erstrecken mÃ¼ssen.  DarÃ¼ber hinaus verringern wir die Wahrscheinlichkeit, eine positive Belohnung zu erhalten, erheblich, da der Agent eine Folge korrekter Aktionen zweimal lÃ¤nger ausfÃ¼hren musste, um die Transaktionskosten zu Ã¼berwinden.  Beide Faktoren erschweren die Aufgabe fÃ¼r RL selbst unter so einfachen Bedingungen wie einer Sinuswelle erheblich. <br><br>  DarÃ¼ber hinaus erinnern wir uns, dass wir diese neuronale Netzwerkarchitektur verwendet haben: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3dc/20c/e1e/3dc20ce1eedec47b871ef59ab7911ef3.png" alt="Bild"><br><br><h3>  Was wurde hinzugefÃ¼gt und warum </h3><br><h4>  Lstm </h4><br>  ZunÃ¤chst wollten wir dem Agenten ein besseres VerstÃ¤ndnis fÃ¼r die Dynamik von Ã„nderungen innerhalb der Flugbahn vermitteln.  Einfach ausgedrÃ¼ckt, der Agent sollte sein eigenes Verhalten besser verstehen: Was er jetzt und seit einiger Zeit in der Vergangenheit getan hat und wie sich die Verteilung der staatlichen Aktionen sowie die erhaltenen Belohnungen entwickelt haben.  Die Verwendung einer Wiederholungsebene kann genau dieses Problem lÃ¶sen.  Willkommen zu der neuen Architektur, mit der neue Experimente gestartet wurden: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/09c/b6e/b0d/09cb6eb0d07dd7808657aaeaec5c5c7c.png" alt="Bild"><br><br>  Bitte beachten Sie, dass ich die Beschreibung leicht verbessert habe.  Der einzige Unterschied zum alten NN besteht in der ersten verborgenen LSTM-Schicht anstelle einer vollstÃ¤ndig gebundenen. <br><br>  Bitte beachten Sie, dass wir mit LSTM in Arbeit die Auswahl von Beispielen fÃ¼r die Reproduktion von Erfahrungen fÃ¼r das Training Ã¤ndern mÃ¼ssen: Jetzt benÃ¶tigen wir Ãœbergangssequenzen anstelle von separaten Beispielen.  So funktioniert es (dies ist einer der Algorithmen).  Wir haben zuvor Punktstichproben verwendet: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/51a/d0b/412/51ad0b4125f0d084e19e81d81a6b10a4.png" alt="Bild"><br><br>  Das fiktive Schema des Wiedergabepuffers. <br><br>  Wir verwenden dieses Schema mit LSTM: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1ee/fb7/537/1eefb75379450cf86c03d5cf30e93dd9.png" alt="Bild"><br><br>  Nun werden Sequenzen ausgewÃ¤hlt (deren LÃ¤nge wir empirisch angeben). <br><br>  Nach wie vor und jetzt wird die Stichprobe durch einen PrioritÃ¤tsalgorithmus reguliert, der auf Fehlern des zeitlich-zeitlichen Lernens basiert. <br><br>  Das LSTM-Wiederholungsniveau ermÃ¶glicht die direkte Verbreitung von Informationen aus Zeitreihen, um ein zusÃ¤tzliches Signal abzufangen, das in frÃ¼heren VerzÃ¶gerungen verborgen ist.  Unsere Zeitreihe ist ein zweidimensionaler Tensor mit GrÃ¶ÃŸe: die LÃ¤nge der Sequenz auf der Darstellung unserer Zustandsaktion. <br><br><h4>  PrÃ¤sentationen </h4><br>  Das preisgekrÃ¶nte Engineering Potential Based Reward Shaping (PBRS), basierend auf Potenzial, ist ein leistungsstarkes Tool, um die Geschwindigkeit und StabilitÃ¤t zu erhÃ¶hen und nicht die OptimalitÃ¤t des Richtliniensuchprozesses zur LÃ¶sung unserer Umgebung zu verletzen.  Ich empfehle, mindestens dieses Originaldokument zum Thema zu lesen: <br><br>  <a href="">people.eecs.berkeley.edu/~russell/papers/ml99-shaping.ps</a> <br><br>  Das Potenzial bestimmt, wie gut unser aktueller Status im VerhÃ¤ltnis zum Zielstatus ist, in den wir eintreten mÃ¶chten.  Eine schematische Ansicht, wie dies funktioniert: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1b1/6f3/85d/1b16f385dedd440d6bd15f74b76f304d.png" alt="Bild"><br><br>  Es gibt Optionen und Schwierigkeiten, die Sie nach Versuch und Irrtum verstehen kÃ¶nnten, und wir lassen diese Details weg, sodass Sie Ihre Hausaufgaben machen kÃ¶nnen. <br><br>  Es ist noch eine weitere Sache zu erwÃ¤hnen, nÃ¤mlich dass PBRS durch PrÃ¤sentationen gerechtfertigt werden kann, die eine Form von Expertenwissen (oder simuliertem Wissen) Ã¼ber das <i>nahezu</i> optimale Verhalten des Agenten in der Umgebung darstellen.  Es gibt eine MÃ¶glichkeit, solche PrÃ¤sentationen fÃ¼r unsere Aufgabe mithilfe von Optimierungsschemata zu finden.  Wir lassen die Details der Suche weg. <br><br>  Die potenzielle Belohnung hat folgende Form (Gleichung 1): <br><br>  r '= r + gamma * F (s') - F (s) <br><br>  Dabei ist F das Potenzial des Staates und r die anfÃ¤ngliche Belohnung. Gamma ist der Abzinsungsfaktor (0: 1). <br><br>  <b>Mit diesen Gedanken fahren wir mit der Codierung fort.</b> <br><br>  Implementierung in R. <br>  Hier ist der neuronale Netzwerkcode, der auf der Keras-API basiert: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># configure critic NN â€” â€” â€” â€” â€” â€” library('keras') library('R6') state_names_length &lt;- 12 # just for example lstm_seq_length &lt;- 4 learning_rate &lt;- 1e-3 a_CustomLayer &lt;- R6::R6Class( â€œCustomLayerâ€ , inherit = KerasLayer , public = list( call = function(x, mask = NULL) { x â€” k_mean(x, axis = 2, keepdims = T) } ) ) a_normalize_layer &lt;- function(object) { create_layer(a_CustomLayer, object, list(name = 'a_normalize_layer')) } v_CustomLayer &lt;- R6::R6Class( â€œCustomLayerâ€ , inherit = KerasLayer , public = list( call = function(x, mask = NULL) { k_concatenate(list(x, x, x), axis = 2) } , compute_output_shape = function(input_shape) { output_shape = input_shape output_shape[[2]] &lt;- input_shape[[2]] * 3L output_shape } ) ) v_normalize_layer &lt;- function(object) { create_layer(v_CustomLayer, object, list(name = 'v_normalize_layer')) } noise_CustomLayer &lt;- R6::R6Class( â€œCustomLayerâ€ , inherit = KerasLayer , lock_objects = FALSE , public = list( initialize = function(output_dim) { self$output_dim &lt;- output_dim } , build = function(input_shape) { self$input_dim &lt;- input_shape[[2]] sqr_inputs &lt;- self$input_dim ** (1/2) self$sigma_initializer &lt;- initializer_constant(.5 / sqr_inputs) self$mu_initializer &lt;- initializer_random_uniform(minval = (-1 / sqr_inputs), maxval = (1 / sqr_inputs)) self$mu_weight &lt;- self$add_weight( name = 'mu_weight', shape = list(self$input_dim, self$output_dim), initializer = self$mu_initializer, trainable = TRUE ) self$sigma_weight &lt;- self$add_weight( name = 'sigma_weight', shape = list(self$input_dim, self$output_dim), initializer = self$sigma_initializer, trainable = TRUE ) self$mu_bias &lt;- self$add_weight( name = 'mu_bias', shape = list(self$output_dim), initializer = self$mu_initializer, trainable = TRUE ) self$sigma_bias &lt;- self$add_weight( name = 'sigma_bias', shape = list(self$output_dim), initializer = self$sigma_initializer, trainable = TRUE ) } , call = function(x, mask = NULL) { #sample from noise distribution e_i = k_random_normal(shape = list(self$input_dim, self$output_dim)) e_j = k_random_normal(shape = list(self$output_dim)) #We use the factorized Gaussian noise variant from Section 3 of Fortunato et al. eW = k_sign(e_i) * (k_sqrt(k_abs(e_i))) * k_sign(e_j) * (k_sqrt(k_abs(e_j))) eB = k_sign(e_j) * (k_abs(e_j) ** (1/2)) #See section 3 of Fortunato et al. noise_injected_weights = k_dot(x, self$mu_weight + (self$sigma_weight * eW)) noise_injected_bias = self$mu_bias + (self$sigma_bias * eB) output = k_bias_add(noise_injected_weights, noise_injected_bias) output } , compute_output_shape = function(input_shape) { output_shape &lt;- input_shape output_shape[[2]] &lt;- self$output_dim output_shape } ) ) noise_add_layer &lt;- function(object, output_dim) { create_layer( noise_CustomLayer , object , list( name = 'noise_add_layer' , output_dim = as.integer(output_dim) , trainable = T ) ) } critic_input &lt;- layer_input( shape = list(NULL, as.integer(state_names_length)) , name = 'critic_input' ) common_lstm_layer &lt;- layer_lstm( units = 20 , activation = â€œtanhâ€ , recurrent_activation = â€œhard_sigmoidâ€ , use_bias = T , return_sequences = F , stateful = F , name = 'lstm1' ) critic_layer_dense_v_1 &lt;- layer_dense( units = 10 , activation = â€œtanhâ€ ) critic_layer_dense_v_2 &lt;- layer_dense( units = 5 , activation = â€œtanhâ€ ) critic_layer_dense_v_3 &lt;- layer_dense( units = 1 , name = 'critic_layer_dense_v_3' ) critic_layer_dense_a_1 &lt;- layer_dense( units = 10 , activation = â€œtanhâ€ ) # critic_layer_dense_a_2 &lt;- layer_dense( # units = 5 # , activation = â€œtanhâ€ # ) critic_layer_dense_a_3 &lt;- layer_dense( units = length(actions) , name = 'critic_layer_dense_a_3' ) critic_model_v &lt;- critic_input %&gt;% common_lstm_layer %&gt;% critic_layer_dense_v_1 %&gt;% critic_layer_dense_v_2 %&gt;% critic_layer_dense_v_3 %&gt;% v_normalize_layer critic_model_a &lt;- critic_input %&gt;% common_lstm_layer %&gt;% critic_layer_dense_a_1 %&gt;% #critic_layer_dense_a_2 %&gt;% noise_add_layer(output_dim = 5) %&gt;% critic_layer_dense_a_3 %&gt;% a_normalize_layer critic_output &lt;- layer_add( list( critic_model_v , critic_model_a ) , name = 'critic_output' ) critic_model_1 &lt;- keras_model( inputs = critic_input , outputs = critic_output ) critic_optimizer = optimizer_adam(lr = learning_rate) keras::compile( critic_model_1 , optimizer = critic_optimizer , loss = 'mse' , metrics = 'mse' ) train.x &lt;- array_reshape(rnorm(10 * lstm_seq_length * state_names_length) , dim = c(10, lstm_seq_length, state_names_length) , order = 'C') predict(critic_model_1, train.x) layer_name &lt;- 'noise_add_layer' intermediate_layer_model &lt;- keras_model(inputs = critic_model_1$input, outputs = get_layer(critic_model_1, layer_name)$output) predict(intermediate_layer_model, train.x)[1,] critic_model_2 &lt;- critic_model_1</span></span></code> </pre> <br></div></div><br>  Debuggen Sie Ihre Entscheidung auf Ihr Gewissen ... <br><br><h3>  Ergebnisse und Vergleich </h3><br>  Lassen Sie uns gleich auf die Endergebnisse eingehen.  <i>Hinweis: Alle Ergebnisse sind PunktschÃ¤tzungen und kÃ¶nnen bei mehreren LÃ¤ufen mit unterschiedlichen zufÃ¤lligen Startseiten unterschiedlich sein.</i> <br><br>  Der Vergleich beinhaltet: <br><br><ul><li>  vorherige Version ohne LSTM und PrÃ¤sentationen </li><li>  einfaches 2-Element-LSTM </li><li>  4-Element-LSTM </li><li>  4-Zellen-LSTM mit generierten PBRS-Belohnungen </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/f2f/886/034/f2f886034a399fd4e1ecacf7ad418829.png" alt="Bild"><br><br>  Die durchschnittliche Rendite pro Folge betrug durchschnittlich Ã¼ber 1000 Folgen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/26f/38c/8ef/26f38c8ef64089c605a92abaf899ba10.png" alt="Bild"><br><br>  Die gesamte Folge kehrt zurÃ¼ck. <br><br>  <b>Diagramme fÃ¼r den erfolgreichsten Agenten:</b> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/30e/304/c65/30e304c65ce97da566c6070b0338d472.jpg" alt="Bild"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/000/7d1/8a0/0007d18a0336590c79e4c3edcf5b0a9f.png" alt="Bild"><br><br>  Agentenleistung. <br><br>  Nun, es ist ziemlich offensichtlich, dass der Agent in Form von PBRS im Vergleich zu frÃ¼heren Versuchen so schnell und stabil konvergiert, dass er als signifikantes Ergebnis akzeptiert werden kann.  Die Geschwindigkeit ist etwa 4-5 mal hÃ¶her als ohne PrÃ¤sentationen.  StabilitÃ¤t ist wunderbar. <br><br>  Bei der Verwendung von LSTM zeigten 4 Zellen eine bessere Leistung als 2 Zellen.  Ein 2-Zellen-LSTM schnitt besser ab als eine Nicht-LSTM-Version (dies ist jedoch mÃ¶glicherweise eine Illusion eines einzelnen Experiments). <br><br><h3>  Letzte Worte </h3><br>  Wir haben gesehen, dass Wiederholungen und KapazitÃ¤tsaufbau helfen.  Mir hat besonders gut gefallen, wie gut das PBRS abschneidet. <br><br>  Glauben Sie niemandem, der mich dazu bringt zu sagen, dass es einfach ist, einen gut konvergierenden RL-Agenten zu erstellen, da dies eine LÃ¼ge ist.  Jede neue Komponente, die dem System hinzugefÃ¼gt wird, macht es mÃ¶glicherweise weniger stabil und erfordert viel Konfiguration und Debugging. <br><br>  Es gibt jedoch eindeutige Hinweise darauf, dass die LÃ¶sung des Problems einfach durch Verbesserung der verwendeten Methoden verbessert werden kann (die Daten blieben erhalten).  Es ist eine Tatsache, dass fÃ¼r jede Aufgabe ein bestimmter Bereich von Parametern besser funktioniert als andere.  In diesem Sinne beschreiten Sie einen erfolgreichen Lernpfad. <br><br>  <b>Vielen Dank.</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de436628/">https://habr.com/ru/post/de436628/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de436618/index.html">Worauf Sie sich 2019 vorbereiten sollten: Programmtrends</a></li>
<li><a href="../de436620/index.html">Ein integrierter Ansatz zur Visualisierung von Sicherheitsereignissen und zur Messung ihrer Wirksamkeit</a></li>
<li><a href="../de436622/index.html">Botovodstvo</a></li>
<li><a href="../de436624/index.html">Studie: Die meisten Nutzer verstehen nicht, wie Facebook mit ihren Daten umgeht.</a></li>
<li><a href="../de436626/index.html">Python wird zur beliebtesten Programmiersprache der Welt.</a></li>
<li><a href="../de436630/index.html">Microservices. Vereinigung und warum es so wichtig ist. Teil 1 - Konfiguration</a></li>
<li><a href="../de436632/index.html">Wie wir ein System zur Verarbeitung, Speicherung und Analyse von Daten in SIBUR aufbauen</a></li>
<li><a href="../de436634/index.html">Fast interne und externe Einstellungen fÃ¼r die Anwendung in Unity3D</a></li>
<li><a href="../de436636/index.html">So erstelle ich einen VKontakte-Community-Empfehlungsdienst</a></li>
<li><a href="../de436638/index.html">Verteilen von Fenstern zwischen Monitoren nach dem Aufwachen aus dem Ruhemodus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
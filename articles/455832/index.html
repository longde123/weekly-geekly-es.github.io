<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßùüèª üìå üëáüèæ Historia de una sola investigaci√≥n SQL ‚ÜîÔ∏è üë©üèΩ‚Äçüíº üíö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En diciembre pasado, recib√≠ un interesante informe de error del equipo de soporte de VWO. El tiempo de carga de uno de los informes anal√≠ticos para un...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Historia de una sola investigaci√≥n SQL</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455832/"><p>  En diciembre pasado, recib√≠ un interesante informe de error del equipo de soporte de VWO.  El tiempo de carga de uno de los informes anal√≠ticos para un gran cliente corporativo parec√≠a prohibitivo.  Y como esta es mi √°rea de responsabilidad, inmediatamente me concentr√© en resolver el problema. </p><br><h2>  Antecedentes </h2><br><p>  Para aclarar de qu√© estoy hablando, te contar√© un poco sobre VWO.  Esta es una plataforma con la que puede ejecutar varias campa√±as espec√≠ficas en sus sitios: realizar experimentos A / B, rastrear visitantes y conversiones, analizar embudos de ventas, mostrar mapas de calor y reproducir grabaciones de visitas. </p><br><p>  Pero lo m√°s importante en la plataforma son los informes.  Todas las funciones anteriores est√°n interconectadas.  Y para los clientes corporativos, una gran variedad de informaci√≥n ser√≠a simplemente in√∫til sin una plataforma poderosa que los presentara en forma de an√°lisis. </p><br><p> Con la plataforma, puede realizar una solicitud arbitraria en un conjunto de datos grande.  Aqu√≠ hay un ejemplo simple: </p><br><pre>  Mostrar todos los clics en abc.com
 DE &lt;fecha d1&gt; A &lt;fecha d2&gt;
 para personas que
 cromo usado O
 (estaban en Europa y usaban el iPhone) </pre><br><p>  Presta atenci√≥n a los operadores booleanos.  Est√°n disponibles para los clientes en la interfaz de consulta para realizar consultas arbitrariamente complejas para recuperar muestras. </p><br><h2>  Solicitud lenta </h2><br><p>  El cliente en cuesti√≥n estaba tratando de hacer algo que intuitivamente deber√≠a funcionar r√°pidamente: </p><br><pre>  Mostrar todas las notas de la sesi√≥n
 para usuarios que visitan cualquier p√°gina
 con url donde hay "/ jobs" </pre><br><p>  Hab√≠a mucho tr√°fico en este sitio, y almacenamos m√°s de un mill√≥n de URL √∫nicas solo para ello.  Y quer√≠an encontrar una plantilla de URL bastante simple relacionada con su modelo de negocio. </p><br><a name="habracut"></a><h2>  Investigaci√≥n preliminar </h2><br><p>  Veamos qu√© pasa en la base de datos.  La siguiente es la consulta SQL lenta original: </p><br><pre><code class="plaintext hljs">SELECT count(*) FROM acc_{account_id}.urls as recordings_urls, acc_{account_id}.recording_data as recording_data, acc_{account_id}.sessions as sessions WHERE recording_data.usp_id = sessions.usp_id AND sessions.referrer_id = recordings_urls.id AND ( urls &amp;&amp; array(select id from acc_{account_id}.urls where url ILIKE '%enterprise_customer.com/jobs%')::text[] ) AND r_time &gt; to_timestamp(1542585600) AND r_time &lt; to_timestamp(1545177599) AND recording_data.duration &gt;=5 AND recording_data.num_of_pages &gt; 0 ;</code> </pre> <br><p>  Y aqu√≠ est√°n los horarios: </p><br><pre>  Tiempo planificado: 1.480 ms
 Plazo de ejecuci√≥n: 1431924.650 ms </pre><br><p>  La solicitud omiti√≥ 150 mil l√≠neas.  El planificador de consultas mostr√≥ un par de detalles interesantes, pero sin cuellos de botella obvios. </p><br><p>  Estudiemos m√°s la consulta.  Como puede ver, hace que tres tablas <code>JOIN</code> : </p><br><ol><li>  <strong>sesiones</strong> : para mostrar informaci√≥n de la sesi√≥n: navegador, agente de usuario, pa√≠s, etc. </li><li>  <strong>grabaci√≥n_datos</strong> : URL grabadas, p√°ginas, duraci√≥n de las visitas </li><li>  <strong>URL</strong> : para evitar la duplicaci√≥n de URL extremadamente grandes, las almacenamos en una tabla separada. </li></ol><br><p>  Tambi√©n tenga en cuenta que todas nuestras tablas ya est√°n divididas por <code>account_id</code> .  Por lo tanto, se excluye una situaci√≥n cuando, debido a una cuenta especialmente grande, las otras tienen problemas. </p><br><h2>  Buscando evidencia </h2><br><p>  En una inspecci√≥n m√°s cercana, vemos que algo en una solicitud particular no est√° bien.  Vale la pena ver esta l√≠nea: </p><br><pre> <code class="plaintext hljs">urls &amp;&amp; array( select id from acc_{account_id}.urls where url ILIKE '%enterprise_customer.com/jobs%' )::text[]</code> </pre> <br><p>  El primer pensamiento fue que quiz√°s debido a <code>ILIKE</code> en todas estas URL largas (tenemos m√°s de 1.4 millones de URL <strong>√∫nicas</strong> recopiladas para esta cuenta), el rendimiento podr√≠a disminuir. </p><br><p>  Pero no, ¬°ese no es el punto! </p><br><pre> <code class="plaintext hljs">SELECT id FROM urls WHERE url ILIKE '%enterprise_customer.com/jobs%'; id -------- ... (198661 rows) Time: 5231.765 ms</code> </pre> <br><p>  La solicitud de b√∫squeda de plantilla en s√≠ misma toma solo 5 segundos.  La b√∫squeda de un patr√≥n en un mill√≥n de URL √∫nicas claramente no es un problema. </p><br><p>  El pr√≥ximo sospechoso en la lista son algunos <code>JOIN</code> .  ¬øQuiz√°s su uso excesivo condujo a una desaceleraci√≥n?  <code>JOIN</code> ser los candidatos m√°s obvios para los problemas de rendimiento, pero no cre√≠a que nuestro caso fuera t√≠pico. </p><br><pre> <code class="plaintext hljs">analytics_db=# SELECT count(*) FROM acc_{account_id}.urls as recordings_urls, acc_{account_id}.recording_data_0 as recording_data, acc_{account_id}.sessions_0 as sessions WHERE recording_data.usp_id = sessions.usp_id AND sessions.referrer_id = recordings_urls.id AND r_time &gt; to_timestamp(1542585600) AND r_time &lt; to_timestamp(1545177599) AND recording_data.duration &gt;=5 AND recording_data.num_of_pages &gt; 0 ; count ------- 8086 (1 row) Time: 147.851 ms</code> </pre> <br><p>  Y este tampoco fue nuestro caso.  <code>JOIN</code> result√≥ ser bastante r√°pido. </p><br><h2>  Estrechamos el c√≠rculo de sospechosos </h2><br><p>  Estaba listo para comenzar a cambiar la consulta para lograr posibles mejoras de rendimiento.  Mi equipo y yo desarrollamos 2 ideas principales: </p><br><ul><li>  <strong>Use EXISTS para la URL de la subconsulta</strong> : Quer√≠amos verificar nuevamente si hubo alg√∫n problema con la subconsulta para las URL.  Una forma de lograr esto es simplemente usar <code>EXISTS</code> .  <code>EXISTS</code> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">puede</a> mejorar en gran medida el rendimiento, ya que termina inmediatamente tan pronto como encuentra una sola l√≠nea por condici√≥n. </li></ul><br><pre> <code class="plaintext hljs">SELECT count(*) FROM acc_{account_id}.urls as recordings_urls, acc_{account_id}.recording_data as recording_data, acc_{account_id}.sessions as sessions WHERE recording_data.usp_id = sessions.usp_id AND ( 1 = 1 ) AND sessions.referrer_id = recordings_urls.id AND (exists(select id from acc_{account_id}.urls where url ILIKE '%enterprise_customer.com/jobs%')) AND r_time &gt; to_timestamp(1547585600) AND r_time &lt; to_timestamp(1549177599) AND recording_data.duration &gt;=5 AND recording_data.num_of_pages &gt; 0 ; count 32519 (1 row) Time: 1636.637 ms</code> </pre> <br><p>  Pues si.  La subconsulta, cuando est√° envuelta en <code>EXISTS</code> , hace que todo sea s√∫per r√°pido.  La siguiente pregunta l√≥gica es ¬øpor qu√© la consulta con JOIN y la subconsulta en s√≠ son r√°pidas individualmente, pero terriblemente lentas juntas? </p><br><ul><li>  <strong>Movemos la subconsulta al CTE</strong> : si la solicitud es r√°pida por s√≠ sola, simplemente podemos calcular el resultado r√°pido primero y luego proporcionarlo a la solicitud principal </li></ul><br><pre> <code class="plaintext hljs">WITH matching_urls AS ( select id::text from acc_{account_id}.urls where url ILIKE '%enterprise_customer.com/jobs%' ) SELECT count(*) FROM acc_{account_id}.urls as recordings_urls, acc_{account_id}.recording_data as recording_data, acc_{account_id}.sessions as sessions, matching_urls WHERE recording_data.usp_id = sessions.usp_id AND ( 1 = 1 ) AND sessions.referrer_id = recordings_urls.id AND (urls &amp;&amp; array(SELECT id from matching_urls)::text[]) AND r_time &gt; to_timestamp(1542585600) AND r_time &lt; to_timestamp(1545107599) AND recording_data.duration &gt;=5 AND recording_data.num_of_pages &gt; 0;</code> </pre> <br><p>  Pero a√∫n era muy lento. </p><br><h2>  Encuentra al culpable </h2><br><p>  Todo este tiempo, una peque√±a cosa apareci√≥ ante mis ojos, de la cual constantemente me apart√©.  Pero como no quedaba nada, decid√≠ mirarla.  Estoy hablando del operador <code>&amp;&amp;</code> .  Si bien <code>EXISTS</code> simplemente mejor√≥ el rendimiento, <code>&amp;&amp;</code> fue el √∫nico factor com√∫n restante en todas las versiones de la consulta lenta. </p><br><p>  Mirando la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n</a> , vemos que <code>&amp;&amp;</code> usa cuando necesita encontrar elementos comunes entre dos matrices. </p><br><p>  En la solicitud original, esto es: </p><br><pre> <code class="plaintext hljs">AND ( urls &amp;&amp; array(select id from acc_{account_id}.urls where url ILIKE '%enterprise_customer.com/jobs%')::text[] )</code> </pre> <br><p>  Lo que significa que hacemos una b√∫squeda de plantilla para nuestras URL, luego encontramos la intersecci√≥n con todas las URL con registros compartidos.  Esto es un poco confuso, ya que "urls" aqu√≠ no se refiere a una tabla que contiene todas las URL, sino a una columna "urls" en la tabla <code>recording_data</code> . </p><br><p>  A medida que <code>&amp;&amp;</code> sospechas de <code>&amp;&amp;</code> , trat√© de encontrar confirmaci√≥n en el plan de consulta generado por <code>EXPLAIN ANALYZE</code> (ya ten√≠a un plan guardado, pero generalmente es m√°s conveniente experimentar con SQL que tratar de comprender la opacidad de los planificadores de consultas). </p><br><pre> <code class="plaintext hljs">Filter: ((urls &amp;&amp; ($0)::text[]) AND (r_time &gt; '2018-12-17 12:17:23+00'::timestamp with time zone) AND (r_time &lt; '2018-12-18 23:59:59+00'::timestamp with time zone) AND (duration &gt;= '5'::double precision) AND (num_of_pages &gt; 0)) Rows Removed by Filter: 52710</code> </pre> <br><p>  Hab√≠a unas pocas l√≠neas de filtros de <code>&amp;&amp;</code> solamente.  Lo que significaba que esta operaci√≥n no solo era costosa, sino que tambi√©n se realizaba varias veces. </p><br><p>  Lo comprob√© aislando la condici√≥n </p><br><pre> <code class="plaintext hljs">SELECT 1 FROM acc_{account_id}.urls as recordings_urls, acc_{account_id}.recording_data_30 as recording_data_30, acc_{account_id}.sessions_30 as sessions_30 WHERE urls &amp;&amp; array(select id from acc_{account_id}.urls where url ILIKE '%enterprise_customer.com/jobs%')::text[]</code> </pre> <br><p>  Esta solicitud fue lenta.  Como <code>JOIN</code> r√°pido y las subconsultas son r√°pidas, solo queda el operador <code>&amp;&amp;</code> . </p><br><p>  Esta es solo una operaci√≥n clave.  Siempre necesitamos buscar en toda la tabla principal de URL para buscar por patr√≥n, y siempre necesitamos encontrar intersecciones.  No podemos buscar entradas de URL directamente, porque estos son solo identificadores que enlazan con las <code>urls</code> . </p><br><h2>  Hacia una soluci√≥n </h2><br><p>  <code>&amp;&amp;</code> lento porque ambos conjuntos son enormes.  La operaci√≥n ser√° relativamente r√°pida si reemplazo las <code>urls</code> con <code>{ "http://google.com/", "http://wingify.com/" }</code> . </p><br><p>  Comenc√© a buscar una manera de hacer una intersecci√≥n de conjuntos en Postgres sin usar <code>&amp;&amp;</code> , pero sin mucho √©xito. </p><br><p>  Al final, decidimos simplemente resolver el problema de forma aislada: dame todas las <code>urls</code> cadena para las cuales la URL coincide con el patr√≥n.  Sin condiciones adicionales, ser√° - </p><br><pre> <code class="plaintext hljs">SELECT urls.url FROM acc_{account_id}.urls as urls, (SELECT unnest(recording_data.urls) AS id) AS unrolled_urls WHERE urls.id = unrolled_urls.id AND urls.url ILIKE '%jobs%'</code> </pre> <br><p>  En lugar de la sintaxis <code>JOIN</code> , simplemente utilic√© una subconsulta y expand√≠ la matriz <code>recording_data.urls</code> para que la condici√≥n pudiera aplicarse directamente a <code>WHERE</code> . </p><br><p>  Lo m√°s importante aqu√≠ es que <code>&amp;&amp;</code> usa para verificar si una entrada determinada contiene una URL apropiada.  Al entrecerrar los ojos un poco, puede ver en esta operaci√≥n moverse a trav√©s de los elementos de la matriz (o filas de la tabla) y detenerse cuando se cumple la condici√≥n (coincidencia).  ¬øSe parece a algo?  S√≠, <code>EXISTS</code> . </p><br><p>  Ya que se puede hacer referencia a <code>recording_data.urls</code> desde fuera del contexto de la subconsulta cuando esto sucede, podemos regresar a nuestro viejo amigo <code>EXISTS</code> y envolverlos con una subconsulta. </p><br><p>  Combinando todo junto, obtenemos la consulta optimizada final: </p><br><pre> <code class="plaintext hljs">SELECT count(*) FROM acc_{account_id}.urls as recordings_urls, acc_{account_id}.recording_data as recording_data, acc_{account_id}.sessions as sessions WHERE recording_data.usp_id = sessions.usp_id AND ( 1 = 1 ) AND sessions.referrer_id = recordings_urls.id AND r_time &gt; to_timestamp(1542585600) AND r_time &lt; to_timestamp(1545177599) AND recording_data.duration &gt;=5 AND recording_data.num_of_pages &gt; 0 AND EXISTS( SELECT urls.url FROM acc_{account_id}.urls as urls, (SELECT unnest(urls) AS rec_url_id FROM acc_{account_id}.recording_data) AS unrolled_urls WHERE urls.id = unrolled_urls.rec_url_id AND urls.url ILIKE '%enterprise_customer.com/jobs%' );</code> </pre><br><p>  Y el tiempo de ejecuci√≥n final <code>Time: 1898.717 ms</code> Es hora de celebrar? </p><br><p>  ¬°No tan r√°pido!  Primero debe verificar la correcci√≥n.  <code>EXISTS</code> extremadamente de la optimizaci√≥n <code>EXISTS</code> , ya que cambia la l√≥gica a un final anterior.  Debemos estar seguros de que no hemos agregado un error no obvio a la solicitud. </p><br><p>  Una simple verificaci√≥n fue realizar el <code>count(*)</code> en consultas lentas y r√°pidas para una gran cantidad de conjuntos de datos diferentes.  Luego, para un peque√±o subconjunto de datos, verifiqu√© la correcci√≥n de todos los resultados manualmente. </p><br><p>  Todos los controles dieron resultados consistentemente positivos.  Lo arreglamos! </p><br><h2>  Lecciones aprendidas </h2><br><p>  Hay muchas lecciones que aprender de esta historia: </p><br><ol><li>  Los planes de consulta no cuentan toda la historia, pero pueden dar pistas </li><li>  Los principales sospechosos no siempre son los verdaderos culpables. </li><li>  Las consultas lentas se pueden romper para aislar los cuellos de botella </li><li>  No todas las optimizaciones son de naturaleza reductiva. </li><li>  El uso de <code>EXIST</code> , donde sea posible, puede conducir a un fuerte aumento de la productividad. </li></ol><br><h2>  Conclusi√≥n </h2><br><p>  Pasamos de un tiempo de solicitud de ~ 24 minutos a 2 segundos, ¬°un aumento de rendimiento muy serio!  Aunque este art√≠culo result√≥ ser extenso, todos los experimentos que hicimos ocurrieron el mismo d√≠a y, seg√∫n las estimaciones, las optimizaciones y las pruebas demoraron entre 1,5 y 2 horas. </p><br><p>  SQL es un lenguaje maravilloso, si no le tiene miedo, pero trate de aprender y usar.  Tener una buena comprensi√≥n de c√≥mo se ejecutan las consultas SQL, c√≥mo la base de datos genera planes de consulta, c√≥mo funcionan los √≠ndices y simplemente el tama√±o de los datos con los que est√° tratando, puede tener mucho √©xito en la optimizaci√≥n de consultas.  Sin embargo, es igualmente importante continuar probando diferentes enfoques y disolver lentamente el problema, encontrando cuellos de botella. </p><br><p>  La mejor parte para lograr tales resultados es una notable mejora visible en la velocidad, cuando un informe que ni siquiera se hab√≠a descargado antes ahora se carga casi instant√°neamente. </p><br><p>  <strong>Un agradecimiento especial a</strong> mis compa√±eros de equipo <em>Aditya Misra</em> , <em>Aditya Gauru</em> y <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Varun Malhotra</a></em> por su lluvia de ideas y <em>Dinkar Pandir</em> por encontrar un error importante en nuestra solicitud final antes de que finalmente nos despidi√©ramos de √©l. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/455832/">https://habr.com/ru/post/455832/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../455812/index.html">Creaci√≥n de una arquitectura de microservicios en Golang y gRPC, parte 2 (acoplador)</a></li>
<li><a href="../455816/index.html">C√≥mo crear una acci√≥n genial para el Asistente de Google. Lifehacks de Just AI</a></li>
<li><a href="../455820/index.html">An√°lisis de rendimiento de VM en VMware vSphere. Parte 2: memoria</a></li>
<li><a href="../455826/index.html">Riego autom√°tico controlado a distancia</a></li>
<li><a href="../455828/index.html">Los cient√≠ficos han descubierto nuevas formas ex√≥ticas de sincronizaci√≥n</a></li>
<li><a href="../455834/index.html">Benchmarks para servidores Linux: 5 herramientas abiertas</a></li>
<li><a href="../455840/index.html">C√≥mo trabajar con m√∫ltiples consultas. Composici√≥n, Reductor, FP</a></li>
<li><a href="../455842/index.html">Difundir una lista vinculada individualmente. Edici√≥n r√°pida</a></li>
<li><a href="../455844/index.html">Creaci√≥n de un analizador Roslyn utilizando pruebas de encapsulaci√≥n como ejemplo</a></li>
<li><a href="../455848/index.html">T√©cnica para evitar comportamientos indefinidos al acceder a un singleton</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
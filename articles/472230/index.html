<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õÖÔ∏è üßíüèø üíí Chips for ML - habla sobre nuevos productos üïò üëê üñºÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Estamos hablando de nuevas arquitecturas tanto de los principales fabricantes globales como de nuevas empresas: chips de escamas de wafers, procesador...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Chips for ML - habla sobre nuevos productos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/1cloud/blog/472230/">  Estamos hablando de nuevas arquitecturas tanto de los principales fabricantes globales como de nuevas empresas: chips de escamas de wafers, procesadores de tensor y dispositivos basados ‚Äã‚Äãen gr√°ficos. <br><br>  <sup><font color="#A9A9A9">Selecci√≥n de tema:</font></sup> <sup><font color="#A9A9A9"><br><br></font></sup> <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Herramientas para desarrolladores de software: marcos abiertos y bibliotecas de MO</a> </li></ul><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/webt/ja/oa/lt/jaoaltprurinq8iyqnzfdqbnmto.jpeg"></a> <a name="habracut"></a><br>  <font color="#A9A9A9"><i>Fotos - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Jason Leung</a> - Unsplash</i></font> <br><br><h2>  Waferscale para el aprendizaje profundo </h2><br>  En la producci√≥n de procesadores cl√°sicos, un sustrato de silicio se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">divide</a> en cristales individuales.  Pero en el caso de los procesadores de escala de obleas, la oblea de semiconductores no se divide, se convierte en un chip grande.  Como resultado, los componentes est√°n m√°s cerca uno del otro y el rendimiento del sistema aumenta. <br><br>  Este enfoque fue adoptado por ingenieros de Cerebras Systems y TSMC, desarrollando un chip para aprendizaje profundo: <b>Cerebras WSE</b> .  Se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">mostr√≥</a> en la conferencia Hot Chips a fines del verano.  El dispositivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">es</a> un cristal cuadrado con lados de 21,5 cm. Consta de 1,2 billones de transistores, combinados en 400 mil n√∫cleos.  Estos n√∫cleos se "comunican" entre s√≠ utilizando el sistema patentado Swarm con un ancho de banda de 100 Pbit / s. <br><br>  Los desarrolladores dicen que el chip <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">optimiza</a> previamente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">los c√°lculos</a> al filtrar los datos cero en las operaciones matriciales; representan del 50 al 98% de todos los valores.  Como resultado, aprender un modelo en Cerebras es cien veces m√°s r√°pido que en las GPU cl√°sicas.  Sin embargo, NYTimes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">reaccion√≥</a> a tales declaraciones con una buena dosis de escepticismo: los expertos independientes a√∫n no han probado el hardware. <br><br>  Los n√∫cleos computacionales de Cerebras son programables.  Se pueden optimizar para trabajar con cualquier red neuronal.  Se espera que el nuevo chip encuentre aplicaci√≥n en sistemas en la nube y aplicaciones de aprendizaje autom√°tico: desde drones hasta asistentes de voz.  Todav√≠a no se sabe cu√°ndo saldr√° a la venta el chip, pero varias compa√±√≠as ya lo est√°n probando en las cargas de trabajo. <br><br>  <b>Silicon Interconnect Fabric</b> (Si-IF) es otro dispositivo de escala de obleas para aplicaciones MO.  Se est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">desarrollando</a> en el laboratorio de la Universidad de California.  Si-IF es un dispositivo que combina docenas de GPU en una sola oblea de silicio.  Los desarrolladores ya han introducido dos prototipos para 24 y 40 GPU.  Su rendimiento es 2.5 veces mayor que las capacidades de los dispositivos cl√°sicos.  Planean usar el sistema en el centro de datos. <br><br><h2>  Procesadores tensoriales </h2><br>  En mayo de 2018, Google anunci√≥ <b>TPU v3</b> , la tercera generaci√≥n de sus procesadores tensoriales para trabajar con la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">biblioteca de</a> aprendizaje autom√°tico <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> .  Poco se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sabe</a> sobre las caracter√≠sticas t√©cnicas del nuevo dispositivo.  La versi√≥n de producci√≥n se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">fabricar√°</a> con tecnolog√≠a de proceso de 12 o 16 nm.  Potencia de dise√±o t√©rmico: 200 vatios, rendimiento: 105 TFLOPS cuando se trabaja con bfloat 16. Este es un sistema de representaci√≥n de punto flotante de 16 bits que se utiliza en el aprendizaje profundo. <br><br>  En una serie de tareas, el rendimiento de la segunda generaci√≥n de TPU de Google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">excedi√≥ las</a> capacidades del qu√≠ntuple NVIDIA Tesla V100.  Los ingenieros dicen que la tercera generaci√≥n es ocho veces m√°s poderosa que su predecesora.  Incluso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tuvimos que instalar</a> refrigeraci√≥n l√≠quida en los chips. <br><br><img src="https://habrastorage.org/webt/b9/nr/qg/b9nrqgg4kzwjtpslnxji5a6q8p4.jpeg"><br>  <font color="#A9A9A9"><i>Foto - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cineca</a> - CC BY</i></font> <br><br>  La corporaci√≥n planea transferir varios de sus sistemas a los nuevos procesadores tensoriales: asistente de voz, servicio de procesamiento de fotos y algoritmo de clasificaci√≥n de consultas de b√∫squeda de RankBrain.  La compa√±√≠a tambi√©n quiere construir supercomputadoras escalables basadas en la nube sobre la base de TPU y acceso abierto a ellas para los cient√≠ficos involucrados en el estudio de los sistemas de IA.  A finales de la primavera, el servicio se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">lanz√≥</a> en modo beta. <br><br><h2>  Fichas que trabajan con gr√°ficos complejos </h2><br>  La startup brit√°nica Graphcore ha desarrollado un chip para tareas de aprendizaje profundo: la <b>Colossus IPU</b> (Unidad de procesamiento de inteligencia).  Contiene 1200 n√∫cleos y un conjunto de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">funciones trascendentales</a> especializadas.  Cada n√∫cleo procesa seis hilos.  El hierro se combina con el software Poplar.  Compila modelos y construye sobre su base gr√°ficas algor√≠tmicas complejas de m√∫ltiples etapas que se ejecutan en procesadores de IPU.  Las pruebas de las primeras muestras de Graphcore mostraron que tienen un rendimiento cien veces mayor que las GPU tradicionales. <br><br>  El inicio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ya incluye una</a> tarjeta PCI-E de tama√±o completo para servidores.  Tiene en su composici√≥n dos chips de IPU, fabricados de acuerdo con la tecnolog√≠a de proceso de 16 nm y que consta de 24 mil millones de transistores.  La potencia inform√°tica de dicho dispositivo es de 125 TFLOPS.  Las tarjetas est√°n dise√±adas para funcionar en centros de datos de proveedores de IaaS y autom√≥viles con piloto autom√°tico.  Los fundadores de la startup <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">dicen</a> que m√°s de un centenar de clientes trabajan con sus dispositivos, pero no nombran empresas espec√≠ficas. <br><br>  <i>La competencia en el campo de los dispositivos de hardware para el aprendizaje autom√°tico se est√° volviendo cada vez m√°s grave.</i>  <i>Nuevos jugadores ingresan al mercado, ofreciendo arquitecturas innovadoras, y compa√±√≠as eminentes contin√∫an aumentando la capacidad de las soluciones existentes.</i>  <i>En cualquier caso, esto juega en manos de los propietarios de centros de datos, ingenieros de ciencia de datos y otros especialistas que desarrollan sistemas de inteligencia artificial.</i> <br><br><hr><img src="https://habrastorage.org/webt/em/zi/pq/emzipq7g4fpas60ehj7ykxsg-iu.png" width="40" align="left">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Programa de afiliados 1cloud.ru</a> .  Los usuarios de nuestra nube pueden obtener ingresos y reducir el costo de alquilar infraestructura virtual. <br><hr><img src="https://habrastorage.org/webt/od/tw/fh/odtwfhtjb34yfqnzw3zfagzwsoc.png" width="40" align="left">  Por ejemplo, ofrecemos el servicio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Private Cloud</a> .  Con su ayuda, puede implementar infraestructura de TI para proyectos de cualquier complejidad. <br><hr></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/472230/">https://habr.com/ru/post/472230/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../472220/index.html">¬øPor qu√© a los mejores f√≠sicos no les gusta una interpretaci√≥n multimundo?</a></li>
<li><a href="../472222/index.html">‚ÄúLee si te gusta escuchar‚Äù: libros para aquellos que no son indiferentes a la m√∫sica, desde cl√°sica hasta hip-hop.</a></li>
<li><a href="../472224/index.html">Uso de la nueva SSD NVMe como disco de arranque en sistemas m√°s antiguos con BIOS heredado (para cualquier sistema operativo)</a></li>
<li><a href="../472226/index.html">Mejora de controles de formulario en Microsoft Edge y Chromium</a></li>
<li><a href="../472228/index.html">9 trucos para trabajar con c√≥digo de Visual Studio</a></li>
<li><a href="../472232/index.html">Desde "Color Extender para ZX-Spectrum" hasta ZX-Poly</a></li>
<li><a href="../472234/index.html">Criptomoneda: ¬øsigue siendo un cargador gratuito o un socio?</a></li>
<li><a href="../472240/index.html">Sobre la gamificaci√≥n. ¬øQu√© es, por qu√© y c√≥mo hacerlo? Look de desarrollador</a></li>
<li><a href="../472242/index.html">Hemos acelerado el planificador de Tokio diez veces</a></li>
<li><a href="../472246/index.html">React + IndexDb + auto-update = casi AsyncRedux</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
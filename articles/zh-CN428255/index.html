<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ§‘ğŸ¾â€ğŸ¤â€ğŸ§‘ğŸ¼ ğŸ¤¬ â™¨ï¸ è½¬ç§»å­¦ä¹ ï¼šå¦‚ä½•åœ¨æ•°æ®ä¸Šå¿«é€Ÿè®­ç»ƒç¥ç»ç½‘ç»œ â¬†ï¸ ğŸ¤²ğŸ¿ ğŸ‘©ğŸ¿â€ğŸ¤â€ğŸ‘¨ğŸ¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="æœºå™¨å­¦ä¹ æ­£å˜å¾—è¶Šæ¥è¶Šå®¹æ˜“è·å¾—ï¼Œæœ‰æ›´å¤šçš„æœºä¼šä½¿ç”¨â€œç°æˆçš„ç»„ä»¶â€æ¥åº”ç”¨è¯¥æŠ€æœ¯ã€‚ ä¾‹å¦‚ï¼Œè½¬ç§»å­¦ä¹ ä½¿æ‚¨å¯ä»¥åˆ©ç”¨åœ¨è§£å†³ä¸€ä¸ªé—®é¢˜ä¸­è·å¾—çš„ç»éªŒæ¥è§£å†³å¦ä¸€ä¸ªç±»ä¼¼çš„é—®é¢˜ã€‚ é¦–å…ˆåœ¨å¤§é‡æ•°æ®ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œï¼Œç„¶ååœ¨ç›®æ ‡é›†ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œã€‚ 



 åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä»¥å¸¦é£Ÿç‰©çš„å›¾åƒè¯†åˆ«ç¤ºä¾‹ä¸ºä¾‹ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨è½¬ç§»å­¦ä¹ æ–¹æ³•ã€‚ æˆ‘å°†åœ¨...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>è½¬ç§»å­¦ä¹ ï¼šå¦‚ä½•åœ¨æ•°æ®ä¸Šå¿«é€Ÿè®­ç»ƒç¥ç»ç½‘ç»œ</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/binarydistrict/blog/428255/"> æœºå™¨å­¦ä¹ æ­£å˜å¾—è¶Šæ¥è¶Šå®¹æ˜“è·å¾—ï¼Œæœ‰æ›´å¤šçš„æœºä¼šä½¿ç”¨â€œç°æˆçš„ç»„ä»¶â€æ¥åº”ç”¨è¯¥æŠ€æœ¯ã€‚ ä¾‹å¦‚ï¼Œè½¬ç§»å­¦ä¹ ä½¿æ‚¨å¯ä»¥åˆ©ç”¨åœ¨è§£å†³ä¸€ä¸ªé—®é¢˜ä¸­è·å¾—çš„ç»éªŒæ¥è§£å†³å¦ä¸€ä¸ªç±»ä¼¼çš„é—®é¢˜ã€‚ é¦–å…ˆåœ¨å¤§é‡æ•°æ®ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œï¼Œç„¶ååœ¨ç›®æ ‡é›†ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œã€‚ <br><br><img src="https://habrastorage.org/webt/q-/wr/cn/q-wrcns6clfsv1n2k6gki-sdoea.jpeg" alt="é£Ÿå“è®¤å¯"><br><br> åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å°†ä»¥å¸¦é£Ÿç‰©çš„å›¾åƒè¯†åˆ«ç¤ºä¾‹ä¸ºä¾‹ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨è½¬ç§»å­¦ä¹ æ–¹æ³•ã€‚ æˆ‘å°†åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">é¢å‘å¼€å‘äººå‘˜çš„æœºå™¨å­¦ä¹ å’Œç¥ç»ç½‘ç»œ</a>ç ”è®¨ä¼šä¸Šè®¨è®ºå…¶ä»–æœºå™¨å­¦ä¹ å·¥å…·ã€‚ <br><a name="habracut"></a><br> å¦‚æœæˆ‘ä»¬é¢ä¸´å›¾åƒè¯†åˆ«çš„ä»»åŠ¡ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ç°æˆçš„æœåŠ¡ã€‚ ä½†æ˜¯ï¼Œå¦‚æœéœ€è¦åœ¨è‡ªå·±çš„æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œåˆ™å¿…é¡»è‡ªå·±å®Œæˆã€‚ <br><br> å¯¹äºå›¾åƒåˆ†ç±»ç­‰å…¸å‹ä»»åŠ¡ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ç°æˆçš„ä½“ç³»ç»“æ„ï¼ˆAlexNetï¼ŒVGGï¼ŒInceptionï¼ŒResNetç­‰ï¼‰ï¼Œå¹¶åœ¨æ•°æ®ä¸Šè®­ç»ƒç¥ç»ç½‘ç»œã€‚ å·²ç»ä½¿ç”¨å„ç§æ¡†æ¶å®ç°äº†æ­¤ç±»ç½‘ç»œï¼Œå› æ­¤åœ¨æ­¤é˜¶æ®µï¼Œæ‚¨å¯ä»¥å°†å…¶ä¸­ä¸€ä¸ªç”¨ä½œé»‘åŒ£å­ï¼Œè€Œæ— éœ€æ·±å…¥ç ”ç©¶å…¶æ“ä½œåŸç†ã€‚ <br><br> ä½†æ˜¯ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œéœ€è¦å¤§é‡æ•°æ®æ‰èƒ½ä½¿å­¦ä¹ è¶‹äºä¸€è‡´ã€‚ é€šå¸¸åœ¨æˆ‘ä»¬çš„ç‰¹å®šä»»åŠ¡ä¸­ï¼Œæ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥æ­£ç¡®è®­ç»ƒç¥ç»ç½‘ç»œçš„æ‰€æœ‰å±‚ã€‚ è½¬ç§»å­¦ä¹ è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚ <br><br><h1> è½¬ç§»å­¦ä¹ è¿›è¡Œå›¾åƒåˆ†ç±» </h1><br> ç”¨äºåˆ†ç±»çš„ç¥ç»ç½‘ç»œé€šå¸¸åœ¨æœ€åä¸€å±‚åŒ…å«<code>N</code>è¾“å‡ºç¥ç»å…ƒï¼Œå…¶ä¸­<code>N</code>æ˜¯ç±»åˆ«æ•°ã€‚ è¿™æ ·çš„è¾“å‡ºçŸ¢é‡è¢«è§†ä¸ºå±äºä¸€ä¸ªç±»åˆ«çš„ä¸€ç»„æ¦‚ç‡ã€‚ åœ¨æˆ‘ä»¬è¯†åˆ«é£Ÿç‰©å›¾åƒçš„ä»»åŠ¡ä¸­ï¼Œç±»åˆ«çš„æ•°é‡å¯èƒ½ä¸åŸå§‹æ•°æ®é›†ä¸­çš„ç±»åˆ«æ•°é‡ä¸åŒã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†å¿…é¡»å®Œå…¨æ·˜æ±°æœ€åä¸€å±‚ï¼Œå¹¶æ”¾å…¥æ–°ä¸€å±‚ï¼Œå¹¶ä½¿ç”¨æ­£ç¡®æ•°é‡çš„è¾“å‡ºç¥ç»å…ƒ <br><br><img src="https://habrastorage.org/webt/u_/n3/k3/u_n3k3qpkps6nw9tjjzwc0njl-y.jpeg" alt="è½¬ç§»å­¦ä¹ "><br><br> é€šå¸¸åœ¨åˆ†ç±»ç½‘ç»œçš„æœ«å°¾ä½¿ç”¨å®Œå…¨è¿æ¥çš„å±‚ã€‚ ç”±äºæˆ‘ä»¬æ›¿æ¢äº†è¯¥å±‚ï¼Œå› æ­¤å¯¹å…¶ä½¿ç”¨é¢„è®­ç»ƒæƒé‡å°†ä¸èµ·ä½œç”¨ã€‚ æ‚¨å°†ä¸å¾—ä¸ä»å¤´å¼€å§‹è®­ç»ƒä»–ï¼Œå¹¶ä½¿ç”¨éšæœºå€¼åˆå§‹åŒ–ä»–çš„æƒé‡ã€‚ æˆ‘ä»¬ä»é¢„å…ˆè®­ç»ƒçš„å¿«ç…§ä¸­ä¸ºæ‰€æœ‰å…¶ä»–å±‚åŠ è½½æƒé‡ã€‚ <br><br> æœ‰å¤šç§ç­–ç•¥å¯ä»¥è¿›ä¸€æ­¥è®­ç»ƒæ¨¡å‹ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹å†…å®¹ï¼šæˆ‘ä»¬å°†ç«¯åˆ°ç«¯ï¼ˆ <i>end-to-end</i> ï¼‰è®­ç»ƒæ•´ä¸ªç½‘ç»œï¼Œå¹¶ä¸”æˆ‘ä»¬å°†ä¸å›ºå®šé¢„å…ˆè®­ç»ƒçš„æƒé‡ï¼Œä»¥å…è®¸ä»–ä»¬ç¨å¾®è°ƒæ•´å¹¶è°ƒæ•´æˆ‘ä»¬çš„æ•°æ®ã€‚ æ­¤è¿‡ç¨‹ç§°ä¸º<i>å¾®è°ƒ</i> ã€‚ <br><br><h1> ç»“æ„ç»„ä»¶ </h1><br> è¦è§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦ä»¥ä¸‹ç»„ä»¶ï¼š <br><br><ol><li> ç¥ç»ç½‘ç»œæ¨¡å‹çš„æè¿° </li><li> å­¦ä¹ ç®¡é“ </li><li> å¹²æ‰°ç®¡é“ </li><li> è¯¥æ¨¡å‹çš„é¢„è®­ç»ƒæƒé‡ </li><li> åŸ¹è®­å’ŒéªŒè¯æ•°æ® </li></ol><br><img src="https://habrastorage.org/webt/tf/xp/2o/tfxp2on4o-rxj6hnt4dij7u8vlk.jpeg" alt="ç»„æˆéƒ¨åˆ†"><br><br> åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘å°†ä»<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">è‡ªå·±çš„å­˜å‚¨åº“ä¸­</a>è·å–ç»„ä»¶ï¼ˆ1ï¼‰ï¼Œï¼ˆ2ï¼‰å’Œï¼ˆ3ï¼‰ï¼Œè¯¥<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">å­˜å‚¨åº“</a>åŒ…å«æœ€è½»é‡çš„ä»£ç -å¦‚æœéœ€è¦ï¼Œæ‚¨å¯ä»¥è½»æ¾åœ°æ‰¾å‡ºæ¥ã€‚ æˆ‘ä»¬çš„ç¤ºä¾‹å°†åœ¨æµè¡Œçš„<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow</a>æ¡†æ¶ä¸Šå®ç°ã€‚ å¦‚æœé€‚åˆäºæ‰€é€‰æ¡†æ¶çš„é¢„è®­ç»ƒæƒé‡ï¼ˆ4ï¼‰ä¸ç»å…¸æ¶æ„ä¹‹ä¸€ç›¸å¯¹åº”ï¼Œåˆ™å¯ä»¥æ‰¾åˆ°å®ƒä»¬ã€‚ ä½œä¸ºæ¼”ç¤ºçš„æ•°æ®é›†ï¼ˆ5ï¼‰ï¼Œæˆ‘å°†é€‰æ‹©<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Food-101</a> ã€‚ <br><br><h1> å‹å· </h1><br> ä½œä¸ºæ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ç»å…¸çš„<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">VGG</a>ç¥ç»ç½‘ç»œï¼ˆæ›´ç¡®åˆ‡åœ°è¯´æ˜¯<i>VGG19</i> ï¼‰ã€‚ å°½ç®¡æœ‰ä¸€äº›ç¼ºç‚¹ï¼Œè¯¥æ¨¡å‹ä»æ˜¾ç¤ºå‡ºç›¸å½“é«˜çš„è´¨é‡ã€‚ å¦å¤–ï¼Œå®ƒå¾ˆå®¹æ˜“åˆ†æã€‚ åœ¨TensorFlow Slimä¸Šï¼Œæ¨¡å‹æè¿°çœ‹èµ·æ¥éå¸¸ç´§å‡‘ï¼š <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow.contrib.slim <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> slim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vgg_19</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs, num_classes, is_training, scope=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'vgg_19'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, weight_decay=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.0005</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> slim.arg_scope([slim.conv2d], activation_fn=tf.nn.relu, weights_regularizer=slim.l2_regularizer(weight_decay), biases_initializer=tf.zeros_initializer(), padding=<span class="hljs-string"><span class="hljs-string">'SAME'</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.variable_scope(scope, <span class="hljs-string"><span class="hljs-string">'vgg_19'</span></span>, [inputs]): net = slim.repeat(inputs, <span class="hljs-number"><span class="hljs-number">2</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">64</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv1'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool1'</span></span>) net = slim.repeat(net, <span class="hljs-number"><span class="hljs-number">2</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">128</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv2'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool2'</span></span>) net = slim.repeat(net, <span class="hljs-number"><span class="hljs-number">4</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">256</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv3'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool3'</span></span>) net = slim.repeat(net, <span class="hljs-number"><span class="hljs-number">4</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">512</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv4'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool4'</span></span>) net = slim.repeat(net, <span class="hljs-number"><span class="hljs-number">4</span></span>, slim.conv2d, <span class="hljs-number"><span class="hljs-number">512</span></span>, [<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'conv5'</span></span>) net = slim.max_pool2d(net, [<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>], scope=<span class="hljs-string"><span class="hljs-string">'pool5'</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Use conv2d instead of fully_connected layers net = slim.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6') net = slim.dropout(net, 0.5, is_training=is_training, scope='drop6') net = slim.conv2d(net, 4096, [1, 1], scope='fc7') net = slim.dropout(net, 0.5, is_training=is_training, scope='drop7') net = slim.conv2d(net, num_classes, [1, 1], scope='fc8', activation_fn=None) net = tf.squeeze(net, [1, 2], name='fc8/squeezed') return net</span></span></code> </pre><br> ä»ImageNetä¸Šè®­ç»ƒå¹¶ä¸TensorFlowå…¼å®¹çš„VGG19æƒé‡æ˜¯ä»GitHubä¸Šçš„å­˜å‚¨åº“ä¸­çš„`` <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">é¢„è®­ç»ƒæ¨¡å‹''</a>éƒ¨åˆ†ä¸‹è½½çš„ã€‚ <br><br><pre> <code class="bash hljs">mkdir data &amp;&amp; <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> data wget http://download.tensorflow.org/models/vgg_19_2016_08_28.tar.gz tar -xzf vgg_19_2016_08_28.tar.gz</code> </pre><br><h1> æ•°æ®ä¸­å¿ƒ </h1><br> ä½œä¸ºåŸ¹è®­å’ŒéªŒè¯æ ·æœ¬ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å…¬å¼€çš„<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Food-101</a>æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«è¶…è¿‡10ä¸‡ä¸ªé£Ÿç‰©å›¾åƒï¼Œåˆ†ä¸º101ç±»ã€‚ <br><br><img src="https://habrastorage.org/webt/re/oh/pb/reohpbmt76_3qfzplzccsz-hbf8.jpeg" alt="Food-101æ•°æ®é›†"><br><br> ä¸‹è½½å¹¶è§£å‹ç¼©æ•°æ®é›†ï¼š <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> data wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz tar -xzf food-101.tar.gz</code> </pre><br> æˆ‘ä»¬åœ¨åŸ¹è®­ä¸­è®¾è®¡äº†æ•°æ®ç®¡é“ï¼Œå› æ­¤éœ€è¦ä»æ•°æ®é›†ä¸­è§£æä»¥ä¸‹å†…å®¹ï¼š <br><br><ol><li> ç­çº§æ¸…å•ï¼ˆç±»åˆ«ï¼‰ </li><li> æ•™ç¨‹ï¼šå›¾ç‰‡çš„è·¯å¾„åˆ—è¡¨å’Œæ­£ç¡®ç­”æ¡ˆçš„åˆ—è¡¨ </li><li> éªŒè¯é›†ï¼šå›¾ç‰‡çš„è·¯å¾„åˆ—è¡¨å’Œæ­£ç¡®ç­”æ¡ˆçš„åˆ—è¡¨ </li></ol><br> å¦‚æœæ˜¯æ•°æ®é›†ï¼Œåˆ™ä¸ºäº†<i>è®­ç»ƒ</i>å’Œ<i>éªŒè¯ï¼Œ</i>æ‚¨éœ€è¦è‡ªå·±ç ´åé›†åˆã€‚  Food-101å·²ç»å…·æœ‰è¿™æ ·çš„åˆ†åŒºï¼Œå¹¶ä¸”æ­¤ä¿¡æ¯å­˜å‚¨åœ¨<code>meta</code>ç›®å½•ä¸­ã€‚ <br><br><pre> <code class="python hljs">DATASET_ROOT = <span class="hljs-string"><span class="hljs-string">'data/food-101/'</span></span> train_data, val_data, classes = data.food101(DATASET_ROOT) num_classes = len(classes)</code> </pre><br> æ‰€æœ‰è´Ÿè´£æ•°æ®å¤„ç†çš„è¾…åŠ©åŠŸèƒ½éƒ½ç§»è‡³å•ç‹¬çš„<code>data.py</code>æ–‡ä»¶ä¸­ï¼š <br><br><div class="spoiler">  <b class="spoiler_title">data.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> os.path <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> join <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> opj <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parse_ds_subset</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img_root, list_fpath, classes)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Parse a meta file with image paths and labels -&gt; img_root: path to the root of image folders -&gt; list_fpath: path to the file with the list (eg train.txt) -&gt; classes: list of class names &lt;- (list_of_img_paths, integer_labels) '''</span></span> fpaths = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(list_fpath, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: class_name, image_id = line.strip().split(<span class="hljs-string"><span class="hljs-string">'/'</span></span>) fpaths.append(opj(img_root, class_name, image_id+<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) labels.append(classes.index(class_name)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> fpaths, labels <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">food101</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataset_root)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Get lists of train and validation examples for Food-101 dataset -&gt; dataset_root: root of the Food-101 dataset &lt;- ((train_fpaths, train_labels), (val_fpaths, val_labels), classes) '''</span></span> img_root = opj(dataset_root, <span class="hljs-string"><span class="hljs-string">'images'</span></span>) train_list_fpath = opj(dataset_root, <span class="hljs-string"><span class="hljs-string">'meta'</span></span>, <span class="hljs-string"><span class="hljs-string">'train.txt'</span></span>) test_list_fpath = opj(dataset_root, <span class="hljs-string"><span class="hljs-string">'meta'</span></span>, <span class="hljs-string"><span class="hljs-string">'test.txt'</span></span>) classes_list_fpath = opj(dataset_root, <span class="hljs-string"><span class="hljs-string">'meta'</span></span>, <span class="hljs-string"><span class="hljs-string">'classes.txt'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(classes_list_fpath, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: classes = [line.strip() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f] train_data = parse_ds_subset(img_root, train_list_fpath, classes) val_data = parse_ds_subset(img_root, test_list_fpath, classes) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> train_data, val_data, classes <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">imread_and_crop</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(fpath, inp_size, margin=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">, random_crop=False)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' Construct TF graph for image preparation: Read the file, crop and resize -&gt; fpath: path to the JPEG image file (TF node) -&gt; inp_size: size of the network input (eg 224) -&gt; margin: cropping margin -&gt; random_crop: perform random crop or central crop &lt;- prepared image (TF node) '''</span></span> data = tf.read_file(fpath) img = tf.image.decode_jpeg(data, channels=<span class="hljs-number"><span class="hljs-number">3</span></span>) img = tf.image.convert_image_dtype(img, dtype=tf.float32) shape = tf.shape(img) crop_size = tf.minimum(shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]) - <span class="hljs-number"><span class="hljs-number">2</span></span> * margin <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> random_crop: img = tf.random_crop(img, (crop_size, crop_size, <span class="hljs-number"><span class="hljs-number">3</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-comment"><span class="hljs-comment"># central crop ho = (shape[0] - crop_size) // 2 wo = (shape[0] - crop_size) // 2 img = img[ho:ho+crop_size, wo:wo+crop_size, :] img = tf.image.resize_images(img, (inp_size, inp_size), method=tf.image.ResizeMethod.AREA) return img def train_dataset(data, batch_size, epochs, inp_size, margin): ''' Prepare training data pipeline -&gt; data: (list_of_img_paths, integer_labels) -&gt; batch_size: training batch size -&gt; epochs: number of training epochs -&gt; inp_size: size of the network input (eg 224) -&gt; margin: cropping margin &lt;- (dataset, number_of_train_iterations) ''' num_examples = len(data[0]) iters = (epochs * num_examples) // batch_size def fpath_to_image(fpath, label): img = imread_and_crop(fpath, inp_size, margin, random_crop=True) return img, label dataset = tf.data.Dataset.from_tensor_slices(data) dataset = dataset.shuffle(buffer_size=num_examples) dataset = dataset.map(fpath_to_image) dataset = dataset.repeat(epochs) dataset = dataset.batch(batch_size, drop_remainder=True) return dataset, iters def val_dataset(data, batch_size, inp_size): ''' Prepare validation data pipeline -&gt; data: (list_of_img_paths, integer_labels) -&gt; batch_size: validation batch size -&gt; inp_size: size of the network input (eg 224) &lt;- (dataset, number_of_val_iterations) ''' num_examples = len(data[0]) iters = num_examples // batch_size def fpath_to_image(fpath, label): img = imread_and_crop(fpath, inp_size, 0, random_crop=False) return img, label dataset = tf.data.Dataset.from_tensor_slices(data) dataset = dataset.map(fpath_to_image) dataset = dataset.batch(batch_size, drop_remainder=True) return dataset, iters</span></span></code> </pre><br></div></div><br><h1> æ¨¡å‹è®­ç»ƒ </h1><br> æ¨¡å‹è®­ç»ƒä»£ç åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š <br><br><ol><li> å»ºç«‹<i>ç«è½¦/éªŒè¯</i>æ•°æ®ç®¡é“ </li><li> æ„å»º<i>è®­ç»ƒ/éªŒè¯</i>å›¾ï¼ˆç½‘ç»œï¼‰ </li><li> æŸå¤±ï¼ˆ <i>äº¤å‰ç†µæŸå¤±</i> ï¼‰åˆ†ç±»å‡½æ•°åœ¨<i>ç«è½¦</i>å›¾ä¸Šçš„é™„ç€ã€‚ </li><li> åœ¨è®­ç»ƒæœŸé—´è®¡ç®—éªŒè¯æ ·æœ¬ä¸Šé¢„æµ‹çš„å‡†ç¡®æ€§æ‰€éœ€çš„ä»£ç  </li><li> ä»å¿«ç…§åŠ è½½é¢„è®­ç»ƒçš„æ¯”ä¾‹å°ºçš„é€»è¾‘ </li><li> å»ºç«‹å„ç§åŸ¹è®­ç»“æ„ </li><li> å­¦ä¹ å‘¨æœŸæœ¬èº«ï¼ˆè¿­ä»£ä¼˜åŒ–ï¼‰ </li></ol><br> å›¾çš„æœ€åä¸€å±‚æ˜¯ä½¿ç”¨æ‰€éœ€æ•°é‡çš„ç¥ç»å…ƒæ„é€ çš„ï¼Œå¹¶ä»é¢„å…ˆè®­ç»ƒçš„å¿«ç…§åŠ è½½çš„å‚æ•°åˆ—è¡¨ä¸­æ’é™¤ã€‚ <br><br><div class="spoiler">  <b class="spoiler_title">ç¤ºèŒƒåŸ¹è®­å®ˆåˆ™</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow.contrib.slim <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> slim tf.logging.set_verbosity(tf.logging.INFO) <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> data <span class="hljs-comment"><span class="hljs-comment">########################################################### ### Settings ########################################################### INPUT_SIZE = 224 RANDOM_CROP_MARGIN = 10 TRAIN_EPOCHS = 20 TRAIN_BATCH_SIZE = 64 VAL_BATCH_SIZE = 128 LR_START = 0.001 LR_END = LR_START / 1e4 MOMENTUM = 0.9 VGG_PRETRAINED_CKPT = 'data/vgg_19.ckpt' CHECKPOINT_DIR = 'checkpoints/vgg19_food' LOG_LOSS_EVERY = 10 CALC_ACC_EVERY = 500 ########################################################### ### Build training and validation data pipelines ########################################################### train_ds, train_iters = data.train_dataset(train_data, TRAIN_BATCH_SIZE, TRAIN_EPOCHS, INPUT_SIZE, RANDOM_CROP_MARGIN) train_ds_iterator = train_ds.make_one_shot_iterator() train_x, train_y = train_ds_iterator.get_next() val_ds, val_iters = data.val_dataset(val_data, VAL_BATCH_SIZE, INPUT_SIZE) val_ds_iterator = val_ds.make_initializable_iterator() val_x, val_y = val_ds_iterator.get_next() ########################################################### ### Construct training and validation graphs ########################################################### with tf.variable_scope('', reuse=tf.AUTO_REUSE): train_logits = model.vgg_19(train_x, num_classes, is_training=True) val_logits = model.vgg_19(val_x, num_classes, is_training=False) ########################################################### ### Construct training loss ########################################################### loss = tf.losses.sparse_softmax_cross_entropy( labels=train_y, logits=train_logits) tf.summary.scalar('loss', loss) ########################################################### ### Construct validation accuracy ### and related functions ########################################################### def calc_accuracy(sess, val_logits, val_y, val_iters): acc_total = 0.0 acc_denom = 0 for i in range(val_iters): logits, y = sess.run((val_logits, val_y)) y_pred = np.argmax(logits, axis=1) correct = np.count_nonzero(y == y_pred) acc_denom += y_pred.shape[0] acc_total += float(correct) tf.logging.info('Validating batch [{} / {}] correct = {}'.format( i, val_iters, correct)) acc_total /= acc_denom return acc_total def accuracy_summary(sess, acc_value, iteration): acc_summary = tf.Summary() acc_summary.value.add(tag="accuracy", simple_value=acc_value) sess._hooks[1]._summary_writer.add_summary(acc_summary, iteration) ########################################################### ### Define set of VGG variables to restore ### Create the Restorer ### Define init callback (used by monitored session) ########################################################### vars_to_restore = tf.contrib.framework.get_variables_to_restore( exclude=['vgg_19/fc8']) vgg_restorer = tf.train.Saver(vars_to_restore) def init_fn(scaffold, sess): vgg_restorer.restore(sess, VGG_PRETRAINED_CKPT) ########################################################### ### Create various training structures ########################################################### global_step = tf.train.get_or_create_global_step() lr = tf.train.polynomial_decay(LR_START, global_step, train_iters, LR_END) tf.summary.scalar('learning_rate', lr) optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=MOMENTUM) training_op = slim.learning.create_train_op( loss, optimizer, global_step=global_step) scaffold = tf.train.Scaffold(init_fn=init_fn) ########################################################### ### Create monitored session ### Run training loop ########################################################### with tf.train.MonitoredTrainingSession(checkpoint_dir=CHECKPOINT_DIR, save_checkpoint_secs=600, save_summaries_steps=30, scaffold=scaffold) as sess: start_iter = sess.run(global_step) for iteration in range(start_iter, train_iters): # Gradient Descent loss_value = sess.run(training_op) # Loss logging if iteration % LOG_LOSS_EVERY == 0: tf.logging.info('[{} / {}] Loss = {}'.format( iteration, train_iters, loss_value)) # Accuracy logging if iteration % CALC_ACC_EVERY == 0: sess.run(val_ds_iterator.initializer) acc_value = calc_accuracy(sess, val_logits, val_y, val_iters) accuracy_summary(sess, acc_value, iteration) tf.logging.info('[{} / {}] Validation accuracy = {}'.format( iteration, train_iters, acc_value))</span></span></code> </pre><br></div></div><br> å¼€å§‹è®­ç»ƒåï¼Œæ‚¨å¯ä»¥ä½¿ç”¨TensorBoardå®ç”¨ç¨‹åºæŸ¥çœ‹å…¶è¿›åº¦ï¼Œè¯¥å®ç”¨ç¨‹åºä¸TensorFlowæ†ç»‘åœ¨ä¸€èµ·ï¼Œç”¨äºå¯è§†åŒ–å„ç§æŒ‡æ ‡å’Œå…¶ä»–å‚æ•°ã€‚ <br><br><pre> <code class="bash hljs">tensorboard --logdir checkpoints/</code> </pre><br> åœ¨TensorBoardçš„åŸ¹è®­ç»“æŸæ—¶ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å‡ ä¹å®Œç¾çš„ç”»é¢ï¼š <i>ç«è½¦æŸå¤±</i>å‡å°‘ï¼Œ <i>éªŒè¯å‡†ç¡®æ€§</i>å¢åŠ  <br><br><img src="https://habrastorage.org/webt/bk/hc/ay/bkhcayg7tn4nczu3dx2flgfukrc.jpeg" alt="TensorBoardçš„æŸå¤±å’Œå‡†ç¡®æ€§"><br><br> ç»“æœï¼Œæˆ‘ä»¬å°†ä¿å­˜çš„å¿«ç…§ä¿å­˜åœ¨<code>checkpoints/vgg19_food</code> ï¼Œæˆ‘ä»¬å°†åœ¨æ¨¡å‹æµ‹è¯•æœŸé—´ä½¿ç”¨è¯¥å¿«ç…§ï¼ˆ <i>æ¨ç†</i> ï¼‰ã€‚ <br><br><h1> æ¨¡å‹æµ‹è¯• </h1><br> ç°åœ¨æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹ã€‚ ä¸ºæ­¤ï¼š <br><br><ol><li> æˆ‘ä»¬æ„é€ äº†ä¸€ä¸ªä¸“é—¨ä¸ºæ¨ç†è€Œè®¾è®¡çš„æ–°å›¾ï¼ˆ <code>is_training=False</code> ï¼‰ </li><li> ä»å¿«ç…§åŠ è½½ç»è¿‡è®­ç»ƒçš„æƒé‡ </li><li> ä¸‹è½½å¹¶é¢„å¤„ç†è¾“å…¥çš„æµ‹è¯•å›¾åƒã€‚ </li><li> è®©æˆ‘ä»¬é€šè¿‡ç¥ç»ç½‘ç»œé©±åŠ¨å›¾åƒå¹¶è·å¾—é¢„æµ‹ </li></ol><br><div class="spoiler">  <b class="spoiler_title">æ¨æ–­</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> imageio <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.transform <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> resize <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> model <span class="hljs-comment"><span class="hljs-comment">########################################################### ### Settings ########################################################### CLASSES_FPATH = 'data/food-101/meta/labels.txt' INP_SIZE = 224 # Input will be cropped and resized CHECKPOINT_DIR = 'checkpoints/vgg19_food' IMG_FPATH = 'data/food-101/images/bruschetta/3564471.jpg' ########################################################### ### Get all class names ########################################################### with open(CLASSES_FPATH, 'r') as f: classes = [line.strip() for line in f] num_classes = len(classes) ########################################################### ### Construct inference graph ########################################################### x = tf.placeholder(tf.float32, (1, INP_SIZE, INP_SIZE, 3), name='inputs') logits = model.vgg_19(x, num_classes, is_training=False) ########################################################### ### Create TF session and restore from a snapshot ########################################################### sess = tf.Session() snapshot_fpath = tf.train.latest_checkpoint(CHECKPOINT_DIR) restorer = tf.train.Saver() restorer.restore(sess, snapshot_fpath) ########################################################### ### Load and prepare input image ########################################################### def crop_and_resize(img, input_size): crop_size = min(img.shape[0], img.shape[1]) ho = (img.shape[0] - crop_size) // 2 wo = (img.shape[0] - crop_size) // 2 img = img[ho:ho+crop_size, wo:wo+crop_size, :] img = resize(img, (input_size, input_size), order=3, mode='reflect', anti_aliasing=True, preserve_range=True) return img img = imageio.imread(IMG_FPATH) img = img.astype(np.float32) img = crop_and_resize(img, INP_SIZE) img = img[None, ...] ########################################################### ### Run inference ########################################################### out = sess.run(logits, feed_dict={x:img}) pred_class = classes[np.argmax(out)] print('Input: {}'.format(IMG_FPATH)) print('Prediction: {}'.format(pred_class))</span></span></code> </pre><br></div></div><br><img src="https://habrastorage.org/webt/j6/e6/jv/j6e6jv72cuvsl3ztjo_392quidm.jpeg" alt="æ¨è®º"><br><br> æ‰€æœ‰ä»£ç ï¼ŒåŒ…æ‹¬ç”¨äºæ„å»ºå’Œè¿è¡Œå¸¦æœ‰æ‰€æœ‰å¿…éœ€ç‰ˆæœ¬åº“çš„Dockerå®¹å™¨çš„èµ„æºï¼Œéƒ½åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ­¤å­˜å‚¨åº“ä¸­</a> -åœ¨é˜…è¯»æœ¬æ–‡æ—¶ï¼Œå­˜å‚¨åº“ä¸­çš„ä»£ç å¯èƒ½å·²æ›´æ–°ã€‚ <br><br> åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">â€œé¢å‘å¼€å‘äººå‘˜çš„æœºå™¨å­¦ä¹ å’Œç¥ç»ç½‘ç»œâ€</a>ç ”è®¨ä¼šä¸Š<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ï¼Œ</a>æˆ‘å°†åˆ†ææœºå™¨å­¦ä¹ çš„å…¶ä»–ä»»åŠ¡ï¼Œå¹¶ä¸”å­¦ç”Ÿä»¬å°†åœ¨å¯†é›†è¯¾ç¨‹ç»“æŸæ—¶ä»‹ç»ä»–ä»¬çš„é¡¹ç›®ã€‚ </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN428255/">https://habr.com/ru/post/zh-CN428255/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN428239/index.html">é—ªå­˜é©±åŠ¨å™¨å³å°†åˆ°2019å¹´-æ˜¯è¿‡å»çš„é—è¿¹è¿˜æ˜¯ä»ç„¶æ˜¯å¿…éœ€å“ï¼Ÿ</a></li>
<li><a href="../zh-CN428243/index.html">GeekBrainså°†æ•™æˆC ++ç¼–ç¨‹è¯­è¨€</a></li>
<li><a href="../zh-CN428249/index.html">WDMæŠ€æœ¯ï¼šå°†æ•°æ®ä¸­å¿ƒæ•´åˆåˆ°é˜²ç¾é›†ç¾¤ä¸­</a></li>
<li><a href="../zh-CN428251/index.html">åº”ç”¨ç¨‹åºâ€œæˆ‘çš„ç›´çº¿â€ä¸­çš„æ„šè ¢æ¼æ´</a></li>
<li><a href="../zh-CN428253/index.html">åµŒå…¥å¼è¯­è¨€ï¼šä¸ºä»€ä¹ˆé€‰æ‹©Luaï¼Ÿ</a></li>
<li><a href="../zh-CN428257/index.html">ç ”ç©¶ï¼š95ï¼…çš„å„¿ç«¥åº”ç”¨ç¨‹åºåŒ…å«å¹¿å‘Š</a></li>
<li><a href="../zh-CN428259/index.html">ã€Šä¸ºä»€ä¹ˆæˆ‘ä»¬é”™äº†ã€‹ä¸€ä¹¦ åœ¨è¡ŒåŠ¨ä¸­æ€è€ƒé™·é˜±ã€‚â€ æ‘˜å½•ç¬¬2éƒ¨åˆ†</a></li>
<li><a href="../zh-CN428261/index.html">å°è¡Œæ˜Ÿå¸¦çš„æ—¥æœ¬å‘¨</a></li>
<li><a href="../zh-CN428263/index.html">â€œæˆ‘çš„æ‰‹çœŸçš„å¾ˆç˜¦â€ï¼šä¸“ä¸šæ¸¸æˆç©å®¶å»å¥èº«æˆ¿</a></li>
<li><a href="../zh-CN428265/index.html">æˆ‘ä»¬å¯ä»¥è®¿é—®WinCEæ¡Œé¢å¹¶åœ¨Keysight DSOX1102Gç¤ºæ³¢å™¨ä¸Šè¿è¡ŒDoom</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíï üôåüèæ ü•î ¬øSe "apaga" el servidor si la prueba de humo del centro de datos "se incendi√≥"? üïµüèª üôáüèº üëä</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬øQu√© sentir√≠a si, un buen d√≠a de verano, un centro de datos con su equipo se ver√≠a as√≠? 



 Hola a todos! Mi nombre es Dmitry Samsonov, trabajo como ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øSe "apaga" el servidor si la prueba de humo del centro de datos "se incendi√≥"?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/odnoklassniki/blog/472812/">  ¬øQu√© sentir√≠a si, un buen d√≠a de verano, un centro de datos con su equipo se ver√≠a as√≠? <br><br><img src="https://habrastorage.org/webt/b4/5i/by/b45ibyn7ljfqivfhmjhqb-hyjmq.jpeg"><br><br>  Hola a todos!  Mi nombre es Dmitry Samsonov, trabajo como administrador l√≠der del sistema en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Odnoklassniki</a> .  La foto muestra uno de los cuatro centros de datos donde est√° instalado el equipo que sirve a nuestro proyecto.  Detr√°s de estos muros hay alrededor de 4 mil unidades de equipos: servidores, sistema de almacenamiento de datos, equipos de red, etc.  - Casi ‚Öì de todos nuestros equipos. <br>  La mayor√≠a de los servidores son Linux.  Hay varias docenas de servidores de Windows (MS SQL), nuestro legado, que hemos rechazado sistem√°ticamente durante muchos a√±os. <br>  Entonces, el 5 de junio de 2019 a las 14:35 los ingenieros de uno de nuestros centros de datos informaron una alarma de incendio. <br><a name="habracut"></a><br><h4>  Negaci√≥n </h4><br>  14:45.  Los incidentes menores de humo en los centros de datos son m√°s comunes de lo que parecen.  Los indicadores dentro de los pasillos eran normales, por lo que nuestra primera reacci√≥n fue relativamente tranquila: introdujimos la prohibici√≥n de trabajar con la producci√≥n, es decir, de cualquier cambio de configuraci√≥n, lanzamiento de nuevas versiones, etc., excepto para el trabajo relacionado con la reparaci√≥n de algo. <br><br><h4>  Ira </h4><br>  ¬øAlguna vez ha intentado averiguar por los bomberos exactamente d√≥nde en el techo hab√≠a un incendio, o subirse a un techo en llamas para evaluar la situaci√≥n?  ¬øCu√°l ser√° el grado de confianza en la informaci√≥n recibida a trav√©s de cinco personas? <br><br>  14:50.  <b>Se ha recibido informaci√≥n de que el fuego se acerca al sistema de enfriamiento</b> .  ¬øPero vendr√°?  El administrador del sistema de servicio muestra el tr√°fico externo desde los frentes de este centro de datos. <br><blockquote>  Por el momento, los frentes de todos nuestros servicios est√°n duplicados en tres centros de datos, se utiliza el equilibrio a nivel de DNS, lo que le permite eliminar las direcciones de un centro de datos de DNS, protegiendo as√≠ a los usuarios de posibles problemas con el acceso a los servicios.  En el caso de que ya se hayan producido problemas en el centro de datos, abandona autom√°ticamente la rotaci√≥n.  Se pueden encontrar m√°s detalles aqu√≠: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">equilibrio de carga y tolerancia a fallas en Odnoklassniki.</a> </blockquote><br>  El fuego a√∫n no nos ha afectado de ninguna manera, ni los usuarios ni el equipo se han visto afectados.  ¬øEs un accidente?  La primera secci√≥n del documento "Plan de acci√≥n para accidentes" define el concepto de "Accidente", y la secci√≥n termina de la siguiente manera: <br>  <b>‚ÄúEn <u>caso de duda, un accidente o no, ¬°este es un accidente!</u></b>  <b>"</b> <br><br>  14:53.  Se nombra un coordinador de accidentes. <br><blockquote>  Un coordinador es una persona que controla la comunicaci√≥n entre todos los participantes, estima la escala del accidente, utiliza el "Plan de acci√≥n para accidentes", atrae al personal necesario, supervisa la finalizaci√≥n de la reparaci√≥n y, lo m√°s importante, delega cualquier tarea.  En otras palabras, esta es la persona que controla todo el proceso de eliminaci√≥n del accidente. </blockquote><br><h4>  Regateo </h4><br>  15:01.  Comenzamos a desconectar servidores que no est√°n vinculados a la producci√≥n. <br>  15:03.  Apague todos los servicios reservados correctamente. <br>  Esto incluye no solo frentes (que en este momento los usuarios ya no inician sesi√≥n) y sus servicios auxiliares (l√≥gica de negocios, cach√©s, etc.), sino tambi√©n varias bases de datos con factor de replicaci√≥n 2 o m√°s ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cassandra</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">almacenamiento de datos binarios</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">almacenamiento en fr√≠o</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">NewSQL</a> , etc.). <br>  15:06.  <b>Se ha recibido informaci√≥n de que un incendio amenaza uno de los pasillos del centro de datos.</b>  No tenemos equipos en esta sala, pero el hecho de que el fuego pueda extenderse desde el techo a los pasillos cambia en gran medida la imagen de lo que est√° sucediendo. <br>  (M√°s tarde result√≥ que no hab√≠a una amenaza f√≠sica para la sala, ya que estaba aislada herm√©ticamente del techo. La amenaza era solo para el sistema de enfriamiento de esta sala). <br>  15:07.  Permitimos la ejecuci√≥n de comandos en servidores en modo acelerado sin controles adicionales ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sin nuestra calculadora favorita</a> ). <br>  15:08.  La temperatura en las habitaciones est√° dentro de los l√≠mites normales. <br>  15:12.  <b>Se registr√≥ un aumento de la temperatura en los pasillos.</b> <br>  15:13.  M√°s de la mitad de los servidores en el centro de datos est√°n apagados.  Continuamos <br>  15:16.  Se decidi√≥ apagar todo el equipo. <br>  3:21 p.m.  Comenzamos a apagar los servidores sin estado sin apagar correctamente la aplicaci√≥n y los sistemas operativos. <br>  15:23.  Se destaca a un grupo de responsables de MS SQL (hay pocos de ellos, la dependencia de los servicios de ellos no es muy buena, pero el procedimiento para restaurar la salud lleva m√°s tiempo y es m√°s complicado que, por ejemplo, Cassandra). <br><br><h4>  Depresi√≥n </h4><br>  15:25.  <b>Se recibi√≥ informaci√≥n sobre la desconexi√≥n de la energ√≠a el√©ctrica en cuatro de las 16 habitaciones (No. 6, 7, 8, 9).</b>  En las salas 7 y 8 est√°n nuestros equipos.  No hay m√°s informaci√≥n sobre nuestras dos habitaciones (No. 1 y 3). <br>  Por lo general, durante los incendios, la energ√≠a se apaga inmediatamente, pero en este caso, gracias al trabajo coordinado de los bomberos y el personal t√©cnico del centro de datos, se apag√≥ no en todas partes y no de inmediato, pero si es necesario. <br>  (M√°s tarde result√≥ que el poder en los pasillos 8 y 9 no se apag√≥). <br>  15:28.  Comenzamos a implementar bases de datos MS SQL a partir de copias de seguridad en otros centros de datos. <br>  ¬øCu√°nto tiempo llevar√°?  ¬øHay suficiente ancho de banda de red para toda la ruta? <br>  15:37.  <b>Bloqueado algunas partes de la red.</b> <br>  La red de gesti√≥n y producci√≥n est√° f√≠sicamente aislada entre s√≠.  Si la red de producci√≥n est√° disponible, puede ir al servidor, detener la aplicaci√≥n y apagar el sistema operativo.  Si no est√° disponible, puede pasar por IPMI, detener la aplicaci√≥n y apagar el sistema operativo.  Si no hay red, no puedes hacer nada.  "¬°Gracias, cap!" Pensar√°s. <br>  "De todos modos, hay mucha confusi√≥n", tambi√©n podr√≠a pensar. <br>  La cuesti√≥n es que los servidores, incluso sin fuego, generan una gran cantidad de calor.  M√°s precisamente, cuando hay enfriamiento, generan calor, y cuando no hay ninguno, crean un infierno infernal, que en el mejor de los casos derretir√° parte del equipo y apagar√° el otro, y en el peor de los casos ... causar√° un incendio dentro del pasillo, que casi con seguridad destruir√° todo. <br><br><img src="https://habrastorage.org/webt/fp/m6/zg/fpm6zg2uwewoewqfwgocfbkamky.jpeg"><br><br>  15:39.  Solucionamos problemas con la base de datos conf. <br><blockquote>  La base de datos conf es el back-end para el servicio del mismo nombre, que utilizan todas las aplicaciones de producci√≥n para cambiar r√°pidamente la configuraci√≥n.  Sin esta base, no podemos controlar el portal, pero el portal en s√≠ puede funcionar. </blockquote><br>  15:41.  Los sensores de temperatura en el equipo de red Core registran lecturas cercanas al m√°ximo permitido.  Esta es una caja que ocupa un rack completo y garantiza el funcionamiento de todas las redes dentro del centro de datos. <br><br><img src="https://habrastorage.org/webt/hk/pu/ju/hkpujukttnjdf651rnnhpof0qxw.jpeg"><br><br>  15:42.  El rastreador de problemas y la wiki no est√°n disponibles, cambie al modo de espera. <br>  Esto no es producci√≥n, pero en un accidente, la disponibilidad de cualquier base de conocimiento puede ser cr√≠tica. <br>  15:50.  Uno de los sistemas de monitoreo se ha desconectado. <br>  Hay varios de ellos, y son responsables de varios aspectos del trabajo de los servicios.  Algunos de ellos est√°n configurados para funcionar de manera aut√≥noma dentro de cada centro de datos (es decir, solo monitorean su centro de datos), mientras que otros consisten en componentes distribuidos que sobreviven de manera transparente a la p√©rdida de cualquier centro de datos. <br>  En este caso, el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sistema para detectar anomal√≠as en los indicadores de l√≥gica de negocios</a> que funciona en modo de espera maestro ha dejado de funcionar.  Cambiar a modo de espera. <br><br><h4>  Aceptaci√≥n </h4><br>  15:51.  A trav√©s de IPMI, todos los servidores, excepto MS SQL, se apagaron sin un apagado correcto. <br>  ¬øEst√° listo para la administraci√≥n masiva de servidores a trav√©s de IPMI si es necesario? <br><br><hr>  <i>El mismo momento en que se completa el rescate de equipos en el centro de datos en esta etapa.</i>  <i>Todo lo que se pudo hacer se ha hecho.</i>  <i>Algunos colegas pueden relajarse.</i> <hr><br>  16:13.  <b>Hubo informaci√≥n de que los tubos de fre√≥n de los acondicionadores de aire explotaron en el techo, lo que retrasar√° el lanzamiento del centro de datos despu√©s de eliminar el incendio.</b> <br>  16:19.  Seg√∫n los datos recibidos del personal t√©cnico del centro de datos, el aumento de temperatura en los pasillos se detuvo. <br>  17:10.  Restaurado el trabajo de la base de datos conf.  Ahora podemos cambiar la configuraci√≥n de la aplicaci√≥n. <br>  ¬øPor qu√© es tan importante si todo es tolerante a fallas y funciona incluso sin un centro de datos? <br>  Primero, no todo es tolerante a fallas.  Hay varios servicios secundarios que no sobreviven a la falla del centro de datos lo suficientemente bien, y hay bases en el modo de espera maestro.  La capacidad de administrar la configuraci√≥n le permite hacer todo lo necesario para minimizar el impacto de las consecuencias del accidente en los usuarios, incluso en condiciones dif√≠ciles. <br>  En segundo lugar, qued√≥ claro que en las pr√≥ximas horas el centro de datos no se recuperar√° por completo, por lo que fue necesario tomar medidas para que la falta de disponibilidad a largo plazo de las r√©plicas no genere problemas adicionales como desbordamientos de disco en los centros de datos restantes. <br>  17:29.  Tiempo de pizza!  Tenemos gente trabajando, no robots. <br><br><img src="https://habrastorage.org/webt/3x/ft/hl/3xfthlpehimklv9yd_oua6phnis.png"><br><br><h4>  Rehabilitaci√≥n </h4><br>  18:02.  En las habitaciones No. 8 (la nuestra), 9, 10 y 11, la temperatura se estabiliz√≥.  En uno de los que permanecen desconectados (No. 7), nuestro equipo est√° ubicado y la temperatura all√≠ contin√∫a aumentando. <br>  18:31.  Le dieron luz verde para lanzar equipos en los pasillos n. ¬∞ 1 y 3: el fuego no afect√≥ a estos pasillos. <br><br><hr>  <i>Actualmente, los servidores se est√°n lanzando en los pasillos n. ¬∞ 1, 3, 8, comenzando por los m√°s cr√≠ticos.</i>  <i>Comprueba el correcto funcionamiento de todos los servicios en ejecuci√≥n.</i>  <i>Todav√≠a hay problemas con la habitaci√≥n 7.</i> <hr><br><br>  18:44.  El personal t√©cnico del centro de datos descubri√≥ que en la sala n√∫mero 7 (donde solo se encuentra nuestro equipo), muchos servidores no est√°n apagados.  Seg√∫n nuestros datos, 26 servidores permanecen all√≠.  Despu√©s de volver a verificar, encontramos 58 servidores. <br>  20:18.  El personal t√©cnico del centro de datos sopla aire en la habitaci√≥n sin aire acondicionado a trav√©s de conductos m√≥viles colocados a trav√©s de los pasillos. <br>  23:08.  Dejaron que el primer administrador se fuera a casa.  Alguien necesita dormir por la noche para continuar trabajando ma√±ana.  A continuaci√≥n, lanzamos otra parte de los administradores y desarrolladores. <br>  02:56.  Lanzamos todo lo que podr√≠a lanzarse.  Hacemos un gran control de todos los servicios con autotest. <br><br><img src="https://habrastorage.org/webt/90/pq/ii/90pqii3vxt6p5hzomjdymkebp3a.jpeg"><br><br>  03:02 a.m.  Aire acondicionado en el √∫ltimo, s√©ptimo sal√≥n restaurado. <br>  03:36.  Pusieron los frentes en el centro de datos en rotaci√≥n en el DNS.  A partir de este momento, el tr√°fico de usuarios comienza a llegar. <br>  Disolvemos la mayor parte del equipo de administradores del hogar.  Pero dejamos algunas personas. <br><blockquote>  Peque√±as preguntas frecuentes: <br>  P: ¬øQu√© pas√≥ de 18:31 a 02:56? <br>  R: Siguiendo el "Plan de Acci√≥n de Accidentes", lanzamos todos los servicios, comenzando por los m√°s importantes.  Al mismo tiempo, el coordinador en el chat brinda un servicio a un administrador gratuito, que verifica si el sistema operativo y la aplicaci√≥n se han iniciado, si hay alg√∫n error o si los indicadores son normales.  Una vez que se completa el lanzamiento, informa al chat que es gratuito y recibe un nuevo servicio del coordinador. <br>  El proceso es inhibido adicionalmente por el hierro fallido.  Incluso si el apagado del sistema operativo y el apagado de los servidores fueron correctos, algunos de los servidores no regresan debido a fallos repentinos en las unidades, la memoria o el chasis.  Con una p√©rdida de potencia, la tasa de falla aumenta. <br>  P: ¬øPor qu√© no puede comenzar todo de una vez y luego reparar lo que sale del monitoreo? <br>  R: Todo debe hacerse gradualmente, porque existen dependencias entre los servicios.  Y todo debe verificarse de inmediato, sin esperar el monitoreo, porque es mejor tratar los problemas de inmediato, no esperar a que se agraven. </blockquote><br>  7:40 a.m.  El √∫ltimo administrador (coordinador) se fue a la cama.  El trabajo del primer d√≠a se completa. <br>  8:09 a.m.  Los primeros desarrolladores, ingenieros en los centros de datos y administradores (incluido el nuevo coordinador) comenzaron los trabajos de restauraci√≥n. <br>  09:37.  Comenzamos a subir el pasillo n√∫mero 7 (el √∫ltimo). <br>  Al mismo tiempo, continuamos restaurando lo que no terminamos en otras habitaciones: reemplazando discos / memoria / servidores, arreglando todo lo que est√° en llamas en el monitoreo, cambio de rol inverso en circuitos de espera maestra y otras peque√±as cosas, que sin embargo son bastante. <br>  17:08.  Permitir todo el trabajo regular con la producci√≥n. <br>  21:45.  El trabajo del segundo d√≠a se completa. <br>  09:45.  Hoy es viernes  Todav√≠a hay bastantes problemas menores en el monitoreo.  Antes del fin de semana, todos quieren relajarse.  Continuamos reparando masivamente todo lo que es posible.  Las tareas de administraci√≥n regulares que podr√≠an posponerse se posponen.  El coordinador es nuevo. <br>  15:40.  De repente, la mitad de la pila Core de equipos de red en el OTRO centro de datos se reinici√≥.  Se eliminaron los frentes de la rotaci√≥n para minimizar los riesgos.  No hay ning√∫n efecto para los usuarios.  M√°s tarde result√≥ que era un mal chasis.  El coordinador trabaja arreglando dos choques a la vez. <br>  17:17.  La red en otro centro de datos se restaura, todo se verifica.  El centro de datos est√° en rotaci√≥n. <br>  18:29.  Se completa el trabajo del tercer d√≠a y, en general, la recuperaci√≥n del accidente. <br><br><h4>  Ep√≠logo </h4><br>  04/04/2013, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el d√≠a del error 404</a> , Odnoklassniki <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sobrevivi√≥ al mayor accidente</a> : durante tres d√≠as el portal estuvo total o parcialmente inaccesible.  A lo largo de este tiempo, m√°s de 100 personas de diferentes ciudades, de diferentes compa√±√≠as (¬°muchas gracias de nuevo!) Remota y directamente en los centros de datos, repararon de forma manual y autom√°tica miles de servidores. <br>  Hemos sacado conclusiones.  Para evitar que esto vuelva a suceder, hemos llevado a cabo y continuamos realizando un trabajo extenso hasta nuestros d√≠as. <br><br>  ¬øCu√°les son las principales diferencias entre el accidente actual y el 404? <br><br><ul><li>  Tenemos un "Plan de acci√≥n de emergencia".  Una vez por trimestre, realizamos ejercicios: desarrollamos una emergencia, que un grupo de administradores (todos a su vez) debe eliminar utilizando el "Plan de Acci√≥n de Emergencia".  Los principales administradores de sistemas se turnan para desarrollar el rol de coordinador. </li><li>  Trimestralmente en modo de prueba, a√≠sle los centros de datos (todo a su vez) a trav√©s de LAN y WAN, lo que le permite identificar cuellos de botella de manera oportuna. </li><li>  Menos unidades defectuosas, porque tenemos est√°ndares m√°s estrictos: menos horas de funcionamiento, umbrales m√°s estrictos para SMART, </li><li>  BerkeleyDB completamente abandonado: una base de datos antigua e inestable que requer√≠a mucho tiempo para recuperarse del reinicio del servidor. </li><li>  Reduzca la cantidad de servidores con MS SQL y reduzca la dependencia del resto. </li><li>  Tenemos nuestra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">propia nube, una nube</a> , donde hemos estado migrando activamente todos los servicios durante los √∫ltimos dos a√±os.  La nube simplifica enormemente todo el ciclo de trabajo con la aplicaci√≥n y, en caso de accidente, ofrece herramientas √∫nicas como: <br><ul><li>  corregir detener todas las aplicaciones con un solo clic; </li><li>  migraci√≥n simple de aplicaciones desde servidores fallidos; </li><li>  Clasificaci√≥n autom√°tica (en orden de prioridad de servicios) lanzamiento de un centro de datos completo. </li></ul></li></ul><br>  El accidente descrito en este art√≠culo se convirti√≥ en el m√°s grande desde el d√≠a 404.  Por supuesto, no todo sali√≥ bien.  Por ejemplo, durante la falta de disponibilidad del quemador del centro de datos en otro centro de datos, un disco se bloque√≥ en uno de los servidores, es decir, solo una de las tres r√©plicas en el cl√∫ster Cassandra estaba disponible, debido a que el 4.2% de los usuarios de aplicaciones m√≥viles no pod√≠an iniciar sesi√≥n .  Al mismo tiempo, los usuarios ya conectados continuaron trabajando.  En total, se identificaron m√°s de 30 problemas seg√∫n los resultados del accidente, desde errores banales hasta fallas en la arquitectura de servicio. <br><br>  Pero la principal diferencia entre el accidente actual y el 404 es que, si bien eliminamos las consecuencias del incendio, los usuarios a√∫n correspond√≠an y hac√≠an videollamadas en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Tamtam</a> , jugaban, escuchaban m√∫sica, se daban regalos, ve√≠an videos, programas de televisi√≥n y canales de televisi√≥n en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OK</a> , y tambi√©n transmitido a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">OK Live</a> . <br><br>  ¬øC√≥mo van tus accidentes? </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/472812/">https://habr.com/ru/post/472812/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../472792/index.html">Computadora basada en v√°lvulas NOR: dentro de la computadora de control a bordo Apollo</a></li>
<li><a href="../472796/index.html">YES retrocede FAANG * o [gu√≠a pr√°ctica] en la b√∫squeda de empleo en EE. UU. / Europa para un especialista en TI</a></li>
<li><a href="../472798/index.html">Mapas de Yandex para la aplicaci√≥n de Taxi</a></li>
<li><a href="../472802/index.html">MIRO es una plataforma abierta de robot de interior. Parte 2 - Dise√±o de robot</a></li>
<li><a href="../472810/index.html">Para el administrador del sistema principiante: c√≥mo hacer que el orden salga del caos</a></li>
<li><a href="../472814/index.html">Mi primera m√°quina virtual: c√≥mo no meterse</a></li>
<li><a href="../472816/index.html">Patrones elegantes en JavaScript moderno (ciclo de equipo de Bill Sourour)</a></li>
<li><a href="../472818/index.html">Movimiento colectivo: c√≥mo estudiaron los corchos de hormigas</a></li>
<li><a href="../472822/index.html">Cuando la Academia de Ciencias de Rusia no tiene poder</a></li>
<li><a href="../472826/index.html">Microinteracciones y su uso en interfaces de usuario</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
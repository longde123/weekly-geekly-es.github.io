<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòô üç® üèÖ PyBullet Verst√§rkungstraining üë§ üöá üôä</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Viele Menschen, die maschinelles Lernen studieren, sind mit dem OpenAI-Projekt vertraut, zu dessen Gr√ºndern Elon Musk geh√∂rt, und nutzen die OpenAI Gy...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>PyBullet Verst√§rkungstraining</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420897/"><img src="https://habrastorage.org/webt/0g/x5/ai/0gx5aizowrlyrgkvekcxlxh9pge.png" alt="Bild"><br><br>  Viele Menschen, die maschinelles Lernen studieren, sind mit dem OpenAI-Projekt vertraut, zu dessen Gr√ºndern Elon Musk geh√∂rt, und nutzen die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenAI Gym-</a> Plattform, um ihre neuronalen Netzwerkmodelle zu trainieren. <br><br>  Das Fitnessstudio enth√§lt eine Vielzahl von Umgebungen, von denen einige verschiedene Arten von physikalischen Simulationen sind: die Bewegungen von Tieren, Menschen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Robotern</a> .  Diese Simulationen basieren auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MuJoCo-</a> Physik-Engine, die f√ºr p√§dagogische und wissenschaftliche Zwecke kostenlos ist. <br><br>  In diesem Artikel werden wir eine extrem einfache physikalische Simulation erstellen, die der OpenAI Gym-Umgebung √§hnelt, jedoch auf der kostenlosen Physik-Engine Bullet ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PyBullet</a> ) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">basiert</a> .  Erstellen Sie au√üerdem einen Agenten, der mit dieser Umgebung arbeitet. <br><a name="habracut"></a><br>  PyBullet ist ein Python-Modul zum Erstellen einer physikalischen Simulationsumgebung basierend auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bullet Physics-</a> Physik-Engine.  Es wird, wie MuJoCo, oft als Anregung f√ºr verschiedene Roboter verwendet, die sich f√ºr Habr interessieren. Es gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Artikel</a> mit echten Beispielen. <br><br>  Es gibt einen ziemlich guten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">QuickStartGuide</a> f√ºr PyBullet, der Links zu Beispielen auf der Quellseite von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub enth√§lt</a> . <br><br>  Mit PyBullet k√∂nnen Sie bereits erstellte Modelle im URDF-, SDF- oder MJCF-Format laden.  In den Quellen gibt es eine Bibliothek von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Modellen</a> in diesen Formaten sowie vollst√§ndig vorgefertigte Umgebungen von Simulatoren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">realer Roboter.</a> <br><br>  In unserem Fall erstellen wir die Umgebung selbst mit PyBullet.  Die Umgebungsschnittstelle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√§hnelt</a> der OpenAI Gym-Schnittstelle.  Auf diese Weise k√∂nnen wir unsere Agenten sowohl in unserer Umgebung als auch in der Turnhalle schulen. <br><br>  Der gesamte Code (iPython) sowie die Funktionsweise des Programms k√∂nnen in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Colaboratory angezeigt werden</a> . <br><br><h2>  Umwelt </h2><br>  Unsere Umgebung besteht aus einer Kugel, die sich innerhalb eines bestimmten H√∂henbereichs entlang der vertikalen Achse bewegen kann.  Der Ball hat Masse und die Schwerkraft wirkt auf ihn, und der Agent muss ihn unter Kontrolle der auf den Ball ausge√ºbten vertikalen Kraft zum Ziel bringen.  Die Zielh√∂he √§ndert sich mit jedem Neustart der Erfahrung. <br><br><img src="https://habrastorage.org/webt/w-/wy/jr/w-wyjrj1zphr8aqndhutrnno1po.png" alt="Bild"><br><br>  Die Simulation ist sehr einfach und kann tats√§chlich als Simulation eines elementaren Bewegers betrachtet werden. <br><br>  Um mit der Umgebung zu arbeiten, werden 3 Methoden verwendet: <i><b>Zur√ºcksetzen</b></i> (Neustart des Experiments und Erstellen aller Objekte der Umgebung), <i><b>Schritt</b></i> (Anwenden der ausgew√§hlten Aktion und Abrufen des resultierenden Zustands der Umgebung), <i><b>Rendern</b></i> (visuelle Anzeige der Umgebung). <br><br>  Bei der Initialisierung der Umgebung muss unser Objekt mit der physischen Simulation verbunden werden.  Es gibt zwei Verbindungsoptionen: mit grafischer Oberfl√§che (GUI) und ohne (DIRECT). In unserem Fall ist es DIRECT. <br><br><pre><code class="python hljs">pb.connect(pb.DIRECT)</code> </pre> <br><h4>  zur√ºcksetzen </h4><br>  Bei jedem neuen Experiment setzen wir die Simulation <i>pb.resetSimulation () zur√ºck</i> und erstellen alle Umgebungsobjekte erneut. <br><br>  In PyBullet haben Objekte zwei Formen: eine Kollisionsform und eine <i>visuelle Form</i> .  Die erste wird von der physikalischen Engine verwendet, um Kollisionen von Objekten zu berechnen, und um die Berechnung der Physik zu beschleunigen, hat sie normalerweise eine einfachere Form als ein reales Objekt.  Die zweite ist optional und wird nur verwendet, wenn das Bild des Objekts erstellt wird. <br><br>  Formulare werden in einem einzelnen Objekt (K√∂rper) gesammelt - <i>MultiBody</i> .  Ein K√∂rper kann wie in unserem Fall aus einer Form ( <i>CollisionShape / Visual Shape-</i> Paar) oder mehreren bestehen. <br><br>  Zus√§tzlich zu den Formen, aus denen der K√∂rper besteht, ist es notwendig, seine Masse, Position und Orientierung im Raum zu bestimmen. <br><br><div class="spoiler">  <b class="spoiler_title">Ein paar Worte zu Multi-Objekt-K√∂rpern.</b> <div class="spoiler_text">  In der Regel werden in realen F√§llen zur Simulation verschiedener Mechanismen K√∂rper verwendet, die aus vielen Formen bestehen.  Beim Erstellen des K√∂rpers werden dem K√∂rper zus√§tzlich zur Grundform der Kollisionen und Visualisierung Ketten von Formen von untergeordneten Objekten ( <i>Links</i> ), deren Position und Ausrichtung relativ zum vorherigen Objekt sowie die Arten von Verbindungen (Gelenken) von Objekten untereinander ( <i>Gelenk</i> ) √ºbertragen.  Arten von Verbindungen k√∂nnen fest, prismatisch (um dieselbe Achse gleitend) oder rotierend (um eine Achse drehend) sein.  Mit den letzten <i>beiden</i> Verbindungstypen k√∂nnen Sie die Parameter der entsprechenden Motortypen ( <i>JointMotor</i> ) wie Kraft, Geschwindigkeit oder Drehmoment <i>einstellen</i> und so die Motoren der "Gelenke" des Roboters simulieren.  Weitere Details in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> . <br></div></div><br>  Wir werden 3 K√∂rper erschaffen: Ball, Ebene (Erde) und Zielzeiger.  Das letzte Objekt hat nur eine Visualisierungsform und eine Masse von Null, daher wird es nicht an der physischen Interaktion zwischen K√∂rpern teilnehmen: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  floorColShape = pb.createCollisionShape(pb.GEOM_PLANE) #   (GEOM_PLANE), visualShape -    ,   GEOM_BOX floorVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[100,100,0.0001], rgbaColor=[1,1,.98,1]) pb_floorId = pb.createMultiBody(0,floorColShape,floorVisualShapeId, [0,0,0], [0,0,0,1]) #  PB_BallRadius = 0.2 PB_BallMass = 1 ballPosition = [0,0,5] ballOrientation=[0,0,0,1] ballColShape = pb.createCollisionShape(pb.GEOM_SPHERE,radius=PB_BallRadius) ballVisualShapeId = pb.createVisualShape(pb.GEOM_SPHERE,radius=PB_BallRadius, rgbaColor=[1,0.27,0,1]) pb_ballId = pb.createMultiBody(PB_BallMass, ballColShape, ballVisualShapeId, ballPosition, ballOrientation) #   TARGET_Z = 8 targetPosition = [0,0,TARGET_Z] targetOrientation=[0,0,0,1] targetVisualShapeId = pb.createVisualShape(pb.GEOM_BOX,halfExtents=[1,0.025,0.025], rgbaColor=[0,0,0,1]) pb_targetId = pb.createMultiBody(0,-1, targetVisualShapeId, targetPosition, targetOrientation)</span></span></code> </pre><br>  Definieren Sie die Schwerkraft und die Zeit des Simulationsschritts. <br><br><pre> <code class="python hljs">pb.setGravity(<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">-10</span></span>) pb.setTimeStep(<span class="hljs-number"><span class="hljs-number">1.</span></span>/<span class="hljs-number"><span class="hljs-number">60</span></span>)</code> </pre> <br>  Um zu verhindern, dass der Ball unmittelbar nach dem Start der Simulation f√§llt, gleichen wir die Schwerkraft aus. <br><br><pre> <code class="python hljs">pb_force = <span class="hljs-number"><span class="hljs-number">10</span></span> * PB_BallMass pb.applyExternalForce(pb_ballId, <span class="hljs-number"><span class="hljs-number">-1</span></span>, [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,pb_force], [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>], pb.LINK_FRAME)</code> </pre> <br><br><h4>  Schritt </h4><br>  Der Agent w√§hlt Aktionen basierend auf dem aktuellen Status der Umgebung aus. Anschlie√üend ruft er die <i>Schrittmethode auf</i> und erh√§lt einen neuen Status. <br><br>  Es werden zwei Arten von Aktionen definiert: Erh√∂hung und Verringerung der auf den Ball wirkenden Kraft.  Kraftgrenzen sind begrenzt. <br><br>  Nach dem √Ñndern der auf den Ball wirkenden Kraft wird ein neuer Schritt der physikalischen Simulation <i>pb.stepSimulation () gestartet</i> und die folgenden Parameter werden an den Agenten zur√ºckgegeben: <br><br>  <i>Beobachtung</i> - Beobachtungen (Zustand der Umwelt) <br>  <i>Belohnung</i> - Belohnung f√ºr perfekte Aktion <br>  <i>erledigt</i> - die Flagge des Endes der Erfahrung <br>  <i>info</i> - zus√§tzliche Informationen <br><br>  Als Zustand der Umgebung werden 3 Werte zur√ºckgegeben: die Entfernung zum Ziel, die aktuell auf den Ball ausge√ºbte Kraft und die Geschwindigkeit des Balls.  Die Werte werden normalisiert zur√ºckgegeben (0..1), da die Umgebungsparameter, die diese Werte bestimmen, je nach Wunsch variieren k√∂nnen. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     (     Z curPos[2]) curPos, curOrient = pb.getBasePositionAndOrientation(pb_ballId) #     (      Z lin_vel[2]) lin_vel, ang_vel= pb.getBaseVelocity(self.pb_ballId)</span></span></code> </pre> <br>  Die Belohnung f√ºr die perfekte Aktion ist 1, wenn sich der Ball in der N√§he des Ziels befindet (Zielh√∂he plus / minus des akzeptablen <i>Rollwerts TARGET_DELTA</i> ) und in anderen F√§llen 0. <br>  Das Experiment ist abgeschlossen, wenn der Ball die Zone verl√§sst (zu Boden f√§llt oder hoch fliegt).  Wenn der Ball das Ziel erreicht, endet das Experiment ebenfalls, jedoch erst nach einer bestimmten Zeit ( <i>STEPS_AFTER_TARGET-</i> Schritte des Experiments).  So ist unser Agent geschult, sich nicht nur dem Ziel zu n√§hern, sondern auch anzuhalten und ihm nahe zu sein.  Angesichts der Tatsache, dass die Belohnung, wenn Sie sich dem Ziel <i>n√§hern,</i> 1 betr√§gt, sollte eine vollst√§ndig erfolgreiche Erfahrung eine Gesamtbelohnung von <i>STEPS_AFTER_TARGET haben</i> . <br><br>  Als zus√§tzliche Information zum Anzeigen von Statistiken werden die Gesamtzahl der im Experiment ausgef√ºhrten Schritte sowie die Anzahl der pro Sekunde ausgef√ºhrten Schritte zur√ºckgegeben. <br><br><h4>  rendern </h4><br>  PyBullet verf√ºgt √ºber zwei Optionen zum Rendern von Bildern: GPU-Rendering basierend auf OpenGL und CPU basierend auf TinyRenderer.  In unserem Fall ist nur eine CPU-Implementierung m√∂glich. <br><br>  Um den aktuellen Rahmen der Simulation zu erhalten, m√ºssen die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Speziesmatrix</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Projektionsmatrix bestimmt</a> und dann das <i>RGB-</i> Bild der angegebenen Gr√∂√üe von der Kamera <i>abgerufen werden</i> . <br><br><pre> <code class="python hljs">camTargetPos = [<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>] <span class="hljs-comment"><span class="hljs-comment">#   ()  camDistance = 10 #     yaw = 0 #     pitch = 0 #     roll=0 #      upAxisIndex = 2 #    (z) fov = 60 #    nearPlane = 0.01 #      farPlane = 20 #      pixelWidth = 320 #   pixelHeight = 200 #   aspect = pixelWidth/pixelHeight; #    #   viewMatrix = pb.computeViewMatrixFromYawPitchRoll(camTargetPos, camDistance, yaw, pitch, roll, upAxisIndex) #   projectionMatrix = pb.computeProjectionMatrixFOV(fov, aspect, nearPlane, farPlane); #     img_arr = pb.getCameraImage(pixelWidth, pixelHeight, viewMatrix, projectionMatrix, shadow=0, lightDirection=[0,1,1],renderer=pb.ER_TINY_RENDERER) w=img_arr[0] #width of the image, in pixels h=img_arr[1] #height of the image, in pixels rgb=img_arr[2] #color data RGB dep=img_arr[3] #depth data</span></span></code> </pre> <br>  Am Ende jedes Experiments wird basierend auf den gesammelten Bildern ein Video generiert. <br><br><pre> <code class="python hljs">ani = animation.ArtistAnimation(plt.gcf(), render_imgs, interval=<span class="hljs-number"><span class="hljs-number">10</span></span>, blit=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>,repeat_delay=<span class="hljs-number"><span class="hljs-number">1000</span></span>) display(HTML(ani.to_html5_video()))</code> </pre><br><h2>  Agent </h2><br>  Der GitHub <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jaara-</a> Benutzercode wurde als Grundlage f√ºr den Agenten verwendet, als einfaches und verst√§ndliches Beispiel f√ºr die Implementierung eines Verst√§rkungstrainings f√ºr die Fitnessumgebung. <br><br>  Der Agent enth√§lt 2 Objekte: <i>Speicher</i> - ein Speicher f√ºr die Bildung von Trainingsbeispielen und <i>Gehirn selbst ist</i> das neuronale Netzwerk, das er trainiert. <br><br>  Das trainierte neuronale Netzwerk wurde in TensorFlow mithilfe der Keras-Bibliothek erstellt, die k√ºrzlich vollst√§ndig in TensorFlow integriert wurde. <br>  Das neuronale Netzwerk hat eine einfache Struktur - 3 Schichten, d.h.  Nur 1 versteckte Ebene. <br><br>  Die erste Schicht enth√§lt 512 Neuronen und verf√ºgt √ºber eine Anzahl von Eingaben, die der Anzahl der Parameter des Zustands des Mediums entsprechen (3 Parameter: Entfernung zum Ziel, St√§rke und Geschwindigkeit des Balls).  Die verborgene Schicht hat eine Dimension, die der ersten Schicht entspricht - 512 Neuronen, am Ausgang ist sie mit der Ausgangsschicht verbunden.  Die Anzahl der Neuronen der Ausgangsschicht entspricht der Anzahl der vom Agenten ausgef√ºhrten Aktionen (2 Aktionen: Abnahme und Zunahme der einwirkenden Kraft). <br><br>  Somit wird der Status des Systems dem Netzwerkeingang zugef√ºhrt, und am Ausgang haben wir einen Vorteil f√ºr jede der Aktionen. <br><br>  F√ºr die ersten beiden Schichten wird <i>ReLU</i> (gleichgerichtete Lineareinheit) als Aktivierungsfunktion verwendet, f√ºr die letzte - eine <i>lineare Funktion</i> (die Summe der Eingabewerte ist einfach). <br>  Als Funktion des Fehlers <i>MSE</i> (Standardfehler) als Optimierungsalgorithmus - <i>RMSprop</i> (Root Mean Square Propagation). <br><br><pre> <code class="python hljs">model = Sequential() model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_dim=<span class="hljs-number"><span class="hljs-number">3</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(units=<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'linear'</span></span>)) opt = RMSprop(lr=<span class="hljs-number"><span class="hljs-number">0.00025</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mse'</span></span>, optimizer=opt)</code> </pre><br>  Nach jedem Simulationsschritt speichert der Agent die Ergebnisse dieses Schritts in Form einer Liste <i>(s, a, r, s_)</i> : <br>  <i>s</i> - vorherige Beobachtung (Zustand der Umwelt) <br>  <i>a</i> - abgeschlossene Aktion <br>  <i>r</i> - Belohnung f√ºr die durchgef√ºhrte Aktion <br>  <i>s_</i> - letzte Beobachtung nach der Aktion <br><br>  Danach empf√§ngt der Agent aus dem Speicher eine zuf√§llige Reihe von Beispielen f√ºr fr√ºhere Perioden und bildet ein Trainingspaket ( <i>Batch</i> ). <br><br>  Die Anfangszust√§nde <i>s</i> der aus dem Speicher ausgew√§hlten Zufallsschritte werden als Eingabewerte ( <i>X</i> ) des Pakets verwendet. <br><br>  Die tats√§chlichen Werte der Lernausgabe ( <i>Y '</i> ) werden wie folgt berechnet: Am Ausgang ( <i>Y</i> ) des neuronalen Netzwerks f√ºr s gibt es Werte der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Q-Funktion</a> f√ºr jede der Aktionen <i>Q (s)</i> .  Aus diesem Satz w√§hlte der Agent die Aktion mit dem h√∂chsten Wert <i>Q (s, a) = MAX (Q (s)) aus</i> , schloss sie ab und erhielt die Auszeichnung <i>r</i> .  Der neue <i>Q-</i> Wert f√ºr die ausgew√§hlte Aktion <i>a</i> ist <i>Q (s, a) = Q (s, a) + DF * r</i> , wobei <i>DF</i> der Abzinsungsfaktor ist.  Die verbleibenden Ausgabewerte bleiben gleich. <br><br><pre> <code class="python hljs">STATE_CNT = <span class="hljs-number"><span class="hljs-number">3</span></span> ACTION_CNT = <span class="hljs-number"><span class="hljs-number">2</span></span> batchLen = <span class="hljs-number"><span class="hljs-number">32</span></span> <span class="hljs-comment"><span class="hljs-comment">#     states = numpy.array([ o[0] for o in batch ]) #     states_ = numpy.array([ o[3] for o in batch ]) #     p = agent.brain.predict(states) #     p_ = agent.brain.predict(states_) #     x = numpy.zeros((batchLen, STATE_CNT)) y = numpy.zeros((batchLen, ACTION_CNT)) #   for i in range(batchLen): o = batch[i] s = o[0]; a = o[1]; r = o[2]; s_ = o[3] t = p[i] #      #      ,       t[a] = r + GAMMA * numpy.amax(p_[i]) #            #    batch x[i] = s y[i] = t #      self.brain.train(x, y)</span></span></code> </pre> <br>  Das Netzwerktraining findet auf dem gebildeten Paket statt <br><br><pre> <code class="python hljs">self.model.fit(x, y, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  Nach Abschluss des Experiments wird ein Video generiert <br><br><img src="https://habrastorage.org/webt/om/ox/rk/omoxrkmnrigllf9hu_8x9ofbd7m.gif" alt="Bild"><br><br>  und Statistiken werden angezeigt <br><br><img src="https://habrastorage.org/webt/0s/ed/p2/0sedp2zvwqmiiku6emmhp2yxf7m.png" alt="Bild"><br><br>  Der Agent ben√∂tigte 1.200 Versuche, um ein Ergebnis von etwa 95 Prozent zu erzielen (Anzahl der erfolgreichen Schritte).  Und beim 50. Experiment hatte der Agent gelernt, den Ball zum Ziel zu bewegen (erfolglose Experimente verschwinden). <br><br>  Um die Ergebnisse zu verbessern, k√∂nnen Sie versuchen, die Gr√∂√üe der Netzwerkschichten (LAYER_SIZE), den Parameter des Abzinsungsfaktors (GAMMA) oder die Abnahmerate der Wahrscheinlichkeit der Auswahl einer zuf√§lligen Aktion (LAMBDA) zu √§ndern. <br><br>  Unser Agent hat die einfachste Architektur - DQN (Deep Q-Network).  Bei einer so einfachen Aufgabe reicht es aus, ein akzeptables Ergebnis zu erzielen. <br><br>  Die Verwendung der DDQN-Architektur (Double DQN) sollte beispielsweise ein reibungsloseres und genaueres Training erm√∂glichen.  Das RDQN-Netzwerk (Recurrent DQN) kann die Muster von Umgebungs√§nderungen im Laufe der Zeit verfolgen, wodurch es m√∂glich wird, den Ballgeschwindigkeitsparameter zu entfernen und die Anzahl der Netzwerkeingabeparameter zu verringern. <br><br>  Sie k√∂nnen unsere Simulation auch erweitern, indem Sie eine variable Kugelmasse oder den Neigungswinkel ihrer Bewegung hinzuf√ºgen. <br><br>  Aber das ist das n√§chste Mal. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420897/">https://habr.com/ru/post/de420897/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420887/index.html">Tele2 Hackathon Report</a></li>
<li><a href="../de420889/index.html">Die milit√§rische Minenerkennungstechnologie hilft Robomobilen beim Navigieren auf allen Stra√üen</a></li>
<li><a href="../de420891/index.html">Migration zu JUnit 5 in 10 min. Testzeit mit Extensions messen</a></li>
<li><a href="../de420893/index.html">Franchise-Verpackung A bis B.</a></li>
<li><a href="../de420895/index.html">Wie ich ein Ger√§t (JTAG-Emulator BH-USB-560v2) √ºber U-Boot wiederbelebt habe</a></li>
<li><a href="../de420901/index.html">Wie ich Spring Framework studiere (Hilfe f√ºr Anf√§nger ist die Arbeit der Anf√§nger selbst)</a></li>
<li><a href="../de420903/index.html">Implementierung von ERP: Wie man nicht versagt</a></li>
<li><a href="../de420905/index.html">Wie intelligente Beleuchtung in Russland eingef√ºhrt wird und wie lange es dauern wird</a></li>
<li><a href="../de420907/index.html">Von NOKLA bis Xiaomi: Die Entwicklung der chinesischen Mobiltelefone</a></li>
<li><a href="../de420909/index.html">Russische Fernsehunternehmen werfen Yandex Piraterie vor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤢 🕺🏼 💚 Le passé, le présent et l'avenir de Docker et d'autres environnements d'exécution de conteneurs dans Kubernetes 🚵 👨🏿‍🚀 ✝️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Remarque perev. : Nous avons déjà écrit plus d'une publication (voir les liens à la fin de l'article) sur les temps d'exécution des conteneurs (temps ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le passé, le présent et l'avenir de Docker et d'autres environnements d'exécution de conteneurs dans Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/429952/">  <i><b>Remarque</b></i>  <i><b>perev.</b></i>  <i>: Nous avons déjà écrit plus d'une publication (voir les liens à la fin de l'article) sur les temps d'exécution des conteneurs (temps d'exécution des conteneurs) - en règle générale, ils sont discutés dans le contexte de Kubernetes.</i>  <i>Cependant, souvent, ces documents ont suscité des questions des lecteurs, indiquant un manque de compréhension de l'origine du prochain projet, de la manière dont il est lié aux autres et de ce qui se passe généralement dans tout ce «zoo» de conteneurs.</i> <br><br><img src="https://habrastorage.org/webt/cy/td/t5/cytdt5jmmufxrtz_b41os56vneg.png"><br><br>  <i>Un récent article de Phil Estes, directeur technique d'IBM Watson &amp; Cloud Platform pour les conteneurs et l'architecture Linux, offre une excellente rétrospective sur la façon de naviguer et de mieux comprendre qui a perdu (ou jamais attrapé) le fil des événements.</i>  <i>En tant que responsable des projets Moby et containerd, membre des comités techniques de l'Open Container Initiative (OCI) et Moby, et ayant également le statut de Docker Captain, l'auteur écrit sur le passé, le présent et l'avenir du nouveau monde merveilleux des temps d'exécution des conteneurs.</i>  <i>Et pour les plus paresseux, le matériel commence par un TL; DR compact sur le sujet ...</i> <a name="habracut"></a><br><br><h2>  Constatations clés </h2><br><ul><li>  Au fil du temps, le choix entre les temps d'exécution des conteneurs s'est élargi, offrant plus d'options que le moteur Docker populaire. </li><li>  L'Open Container Initiative (OCI) a réussi à normaliser le concept de conteneur et d'image de conteneur afin de garantir l'interopérabilité <i>(«interopérabilité» - environ. Trad.)</i> Entre les environnements d'exécution. </li><li>  Kubernetes a ajouté la Container Runtime Interface (CRI), qui permet aux conteneurs de se connecter aux environnements d'exécution avec la couche d'orchestration sous-jacente dans K8s. </li><li>  Les innovations dans ce domaine permettent aux conteneurs de tirer parti de la virtualisation légère et d'autres techniques d'isolation uniques pour répondre aux exigences de sécurité croissantes. </li><li>  Avec OCI et CRI, l'interopérabilité et le choix sont devenus une réalité dans l'écosystème des environnements de conteneur d'exécution et d'orchestration. </li></ul><br>  La technologie de conteneurisation existe depuis un certain temps dans le monde des systèmes d'exploitation Linux - les premières idées sur des espaces de noms séparés pour les systèmes de fichiers et les processus sont apparues il y a plus de dix ans.  Et dans un passé relativement récent, le LXC est apparu et est devenu le moyen standard pour les utilisateurs de Linux d'interagir avec la puissante technologie d'isolation cachée dans le noyau Linux. <br><br>  Cependant, même en dépit des tentatives <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">du LXC de</a> cacher la complexité de la combinaison de divers "intérieurs" technologiques de ce que nous appelons habituellement un conteneur aujourd'hui, les conteneurs sont restés une sorte de magie et ne sont devenus plus forts que dans le monde des conteneurs particulièrement bien informés, et n'étaient pas largement répandus parmi les masses. <br><br>  Tout a changé en 2014 avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Docker</a> , lorsqu'un nouveau wrapper convivial pour les développeurs pour la même technologie de noyau Linux que LXC avait en service est apparu - après tout, les premières versions de Docker «en coulisses» utilisaient LXC, et les conteneurs sont devenus - un véritable phénomène de masse, car les développeurs ont été imprégnés de la simplicité et des possibilités de réutilisation des images de conteneur Docker et des commandes simples pour travailler avec eux. <br><br>  Bien sûr, Docker n'était pas le seul à vouloir gagner une part du marché des conteneurs alors que le battage médiatique qui les accompagnait ne pensait pas se calmer après le premier intérêt explosif en 2014.  Au fil des ans, une variété d'idées alternatives ont émergé pour les environnements de conteneurs exécutables de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CoreOS (rkt)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Intel Clear Containers</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hyper.sh</a> (virtualisation basée sur des conteneurs légers), ainsi que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Singularity</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">shifter</a> dans le monde de la recherche en calcul haute performance (HPC). <br><br>  Le marché a continué de croître et de mûrir, et avec l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Open Container Initiative (OCI)</a> est venu l'effort de normaliser les idées initiales promues par Docker.  Aujourd'hui, de nombreux environnements exécutables de conteneurs sont déjà compatibles avec OCI, ou en voie de l'être, offrant aux fabricants des conditions égales pour promouvoir leurs fonctionnalités et capacités axées sur une application particulière. <br><br><h2>  Popularité de Kubernetes </h2><br>  L'étape suivante de l'évolution des conteneurs consistait à combiner des conteneurs informatiques distribués à la microservices avec des conteneurs - et tout cela dans le nouveau monde des itérations de développement et de déploiement rapides (on peut dire que DevOps), qui gagnait activement du terrain avec la popularité de Docker. <br><br>  Bien <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">qu'Apache Mesos</a> et d'autres plates-formes d'orchestration logicielle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">aient</a> existé avant la domination de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kubernetes</a> , les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">K8 ont</a> décollé rapidement d'un petit projet Open Source de Google vers le projet principal de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cloud Native Computing Foundation (CNCF)</a> . <br><br>  <i><b>Remarque</b></i>  <i><b>perev.</b></i>  <i>: Savez-vous que la CNCF <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">est apparue</a> en 2015 à l'occasion de la sortie de Kubernetes 1.0?</i>  <i>Dans le même temps, le projet a été transféré par Google à une nouvelle organisation indépendante qui est devenue partie intégrante de la Fondation Linux.</i> <br><br><img src="https://habrastorage.org/webt/hu/_u/em/hu_uemcx44qdursrnr_nsc04gie.png"><br>  <i>Événement de sortie de K8s 1.0 sponsorisé, entre autres, Mesosphere, CoreOS, Mirantis, OpenStack, Bitnami</i> <br><img src="https://habrastorage.org/webt/lq/rf/ab/lqrfabydpe9_lbh9zv5x8titb48.png"><br>  <i>D'après les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">informations</a> sur la sortie de Kubernetes 1.0 sur ZDNet</i> <br><br>  Même après que Docker a publié la plate-forme d'orchestration rivale, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Swarm</a> , intégrée à Docker et dotée de la simplicité de Docker et d'une concentration sur la configuration de cluster sécurisé par défaut, cela ne suffisait plus à endiguer l'intérêt croissant pour Kubernetes. <br><br>  Cependant, de nombreuses parties prenantes en dehors des communautés natives du cloud en croissance rapide étaient confuses.  Un observateur moyen ne pouvait pas comprendre ce qui se passait: les Kubernetes se battent avec Docker ou leur coopération?  Parce que Kubernetes n'était qu'une plate-forme d'orchestration, un environnement de conteneur exécutable était nécessaire pour lancer directement les conteneurs orchestrés dans Kubernetes.  Dès le début, Kubernetes a utilisé le moteur Docker et, malgré la tension concurrentielle entre Swarm et Kubernetes, Docker était toujours le moteur d'exécution par défaut et était requis pour que le cluster Kubernetes fonctionne. <br><br>  Avec un petit nombre d'exécutions de conteneurs autres que Docker, il semblait clair que l'association de l'exécution avec Kubernetes nécessiterait une interface spécialement écrite - shim - pour chaque exécution.  L'absence d'une interface claire pour implémenter les temps d'exécution des conteneurs a rendu très difficile l'ajout de la prise en charge des nouveaux temps d'exécution dans Kubernetes. <br><br><h2>  Interface d'exécution du conteneur (CRI) </h2><br>  Pour résoudre la complexité croissante de l'implémentation des runtimes dans Kubernetes, la communauté a défini une fonction spécifique à l'interface que le runtime du conteneur doit implémenter dans Kubernetes - en la nommant <a href="">Container Runtime Interface (CRI)</a> <i>(il <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">est apparu</a> dans Kubernetes 1.5 - environ Transl.)</i> .  Cet événement a non seulement aidé le problème du nombre croissant de fragments de la base de code Kubernetes affectant l'utilisation des temps d'exécution des conteneurs, mais a également aidé à comprendre exactement quelles fonctions devraient être prises en charge par les temps d'exécution potentiels s'ils veulent se conformer à CRI. <br><br>  Comme vous pouvez le deviner, CRI attend des choses très simples de l'exécution.  Un tel environnement devrait être capable de démarrer et d'arrêter des pods, de gérer toutes les opérations avec des conteneurs dans le contexte des pods (démarrer, arrêter, suspendre, tuer, supprimer), et également de prendre en charge la gestion des images de conteneurs à l'aide du registre.  Il existe également des fonctions auxiliaires pour collecter les journaux, les métriques, etc. <br><br>  Lorsque de nouvelles fonctionnalités apparaissent dans Kubernetes, si elles dépendent de la couche d'exécution du conteneur, ces modifications sont apportées à l'API CRI versionnée.  Cela crée à son tour une nouvelle dépendance fonctionnelle sur Kubernetes et nécessite la publication de nouvelles versions de runtimes qui prennent en charge de nouvelles fonctionnalités (un exemple récent est les espaces de noms des utilisateurs). <br><br><h2>  Paysage actuel du CRI </h2><br>  Depuis 2018, il existe plusieurs options à utiliser en tant que runtime de conteneur dans Kubernetes.  Comme le montre l'illustration ci-dessous, l'une des vraies options est toujours Docker avec son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dockershim</a> qui implémente l'API CRI.  Et en fait, dans la plupart des installations de Kubernetes aujourd'hui, c'est lui, Docker, qui reste le runtime par défaut. <br><br><img src="https://habrastorage.org/webt/p6/9q/0h/p69q0hpabyujabund9bgicx12q4.jpeg"><br><br>  L'une des conséquences intéressantes de la tension entre la stratégie d'orchestration de Docker avec Swarm et la communauté Kubernetes a été un projet commun, qui a pris la base du runtime de Docker et en a rassemblé un nouveau projet Open Source développé conjointement - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">containerd</a> .  Au fil du temps, containerd a été transféré à la CNCF, la même organisation qui gère et détient le projet Kubernetes.  <i>( <b>Note trad</b> .: Nous avons décrit l'apparence de containerd plus en détail dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article séparé</a> .)</i> <br><br><img src="https://habrastorage.org/webt/yr/o1/wx/yro1wxcji1jh-xettnzp-jiyiu8.png"><br>  <i>De l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">annonce de</a> containerd sur le blog Docker</i> <br><br>  Containerd, étant une implémentation simple, basique et <i>indépendante de l'</i> entreprise <i>(sans opinion)</i> du runtime pour Docker et Kubernetes (via CRI), a commencé à gagner en popularité en tant que remplaçant potentiel de Docker dans de nombreuses installations Kubernetes.  À ce jour, IBM Cloud et Google Cloud ont tous deux des clusters basés sur containerd en mode d'accès anticipé / bêta.  Microsoft Azure a également promis de passer à containerd à l'avenir, et Amazon envisage toujours différents temps d'exécution pour ses solutions de conteneur (ECS et EKS), tout en continuant à utiliser Docker. <br><br>  Red Hat est entré dans l'espace d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exécution</a> du conteneur en créant une implémentation CRI simple appelée <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cri-o</a> basée sur l'implémentation de référence OCI, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">runc</a> .  Docker et containerd sont également basés sur runc, mais les créateurs de cri-o affirment que leurs temps d'exécution sont "juste assez" pour Kubernetes et qu'ils n'en ont pas besoin de plus - ils ont juste ajouté les fonctions les plus nécessaires pour implémenter Kubernetes CRI sur le binaire runc de base.  <i>( <b>Note trad</b> .: Nous avons écrit plus sur le projet CRI-O dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cet article</a> , et ici sur son développement ultérieur sous la forme de podman.)</i> <br><br>  Projets de virtualisation légers: Intel Clear Containers et hyper.sh - sont apparus dans la nature de la Fondation OpenStack, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">conteneurs Kata</a> , et offrent leur vision de conteneurs virtualisés pour une isolation supplémentaire en utilisant une implémentation CRI appelée <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">frakti</a> .  Cri-o et containerd fonctionnent également avec les conteneurs Kata, de sorte que leur runtime compatible OCI peut être sélectionné comme option enfichable. <br><br><h2>  Prédire l'avenir </h2><br>  Dire que vous savez que l'avenir n'est généralement pas très sage, mais nous pouvons au moins corriger certaines tendances émergentes alors que l'écosystème des conteneurs passe de l'enthousiasme et du battage publicitaire à une étape plus mature de notre existence. <br><br>  Au début, on craignait que l'écosystème des conteneurs ne forme un environnement fragmenté, dont les différents participants proposeraient des idées différentes et incompatibles sur ce qu'est un conteneur.  Grâce au travail d'OCI et aux actions responsables des principaux fournisseurs et participants, nous avons constaté un environnement sain dans l'industrie parmi les offres de logiciels qui préféraient la compatibilité avec OCI. <br><br>  Même dans les environnements plus récents où la norme d'utilisation Docker rencontrait moins de résistance en raison des restrictions existantes - par exemple, dans HPC - toutes les tentatives de création d'environnements de conteneurs conteneur non basés sur Docker ont également attiré l'attention sur l'OCI.  Des discussions sont en cours pour savoir si le BEC peut être une solution viable pour les besoins spécifiques des communautés de scientifiques et de chercheurs. <br><br>  En ajoutant à cela la standardisation des temps d'exécution des conteneurs de plug-ins dans Kubernetes à l'aide de CRI, nous pouvons imaginer un monde où les développeurs et les administrateurs peuvent choisir les bons outils et les piles de logiciels pour leurs tâches, en attendant et en observant l'interopérabilité à travers tout l'écosystème de conteneurs. <br><br>  Prenons un exemple spécifique pour mieux comprendre ce monde: <br><br><ul><li>  Un développeur avec un MacBook utilise Docker pour Mac pour développer son application et utilise même le support intégré de Kubernetes (Docker fonctionne comme le runtime CRI ici) pour essayer de déployer la nouvelle application sur les pods K8s. </li><li>  L'application passe par CI / CD dans le logiciel du fournisseur, qui utilise runc et du code spécial (écrit par le fournisseur) pour empaqueter l'image OCI et la charger dans le registre d'entreprise des conteneurs pour les tests. </li><li>  L'installation de cluster Kubernetes sur site, en utilisant containerd en tant qu'exécution CRI, exécute un ensemble de tests pour l'application. </li><li>  Cette société, pour une raison quelconque, a choisi des conteneurs Kata pour certaines charges de travail en production, donc lorsque vous déployez l'application, elle démarre dans des pods avec containerd configuré pour utiliser les conteneurs Kata comme runtime au lieu de runc. </li></ul><br>  L'ensemble du scénario décrit fonctionne à merveille en raison de la compatibilité avec la spécification OCI pour les environnements d'exécution et les images, et du fait que CRI offre la flexibilité de choisir l'exécution. <br><br>  Cette flexibilité et ce choix possibles rendent l'écosystème de conteneurs vraiment remarquable et sont également une condition très importante pour la maturité de l'industrie, qui a connu une croissance si rapide depuis 2014.  Au seuil de 2019 et des années suivantes, je vois un brillant avenir avec des innovations et une flexibilité continues pour ceux qui utilisent et créent des plateformes basées sur des conteneurs. <br><br>  De plus amples informations sur ce sujet peuvent être trouvées dans une récente conférence de Phil Estes sur QCon NY: « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CRI Runtimes Deep Dive: Who's Running My Kubernetes Pod!?</a>  " <br><br><h2>  PS du traducteur </h2><br>  Lisez aussi dans notre blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Red Hat remplace Docker par Podman</a> "; </li><li>  «L' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">intégration de containerd avec Kubernetes, en remplacement de Docker, est prête pour la production</a> »; </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CRI-O - une alternative à Docker pour le lancement de conteneurs dans Kubernetes</a> »; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Qu'est-ce que Docker fait et pourquoi Moby s'intègre-t-il à Kubernetes?"</a>  " </li><li>  « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Alors, qu'est-ce qu'un pod dans Kubernetes?</a>  " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr429952/">https://habr.com/ru/post/fr429952/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr429940/index.html">Pourquoi les plantes ont besoin du machine learning</a></li>
<li><a href="../fr429942/index.html">Obtenez de la musique VK via une API tierce</a></li>
<li><a href="../fr429946/index.html">Folie et succès du code de base de données Oracle</a></li>
<li><a href="../fr429948/index.html">Pourquoi les chefs de produit chez Fintech sont nécessaires</a></li>
<li><a href="../fr429950/index.html">Comment maintenir de saines habitudes de communication des équipes distantes</a></li>
<li><a href="../fr429954/index.html">Le programmeur des bookmakers irlandais</a></li>
<li><a href="../fr429956/index.html">Intégration continue dans Yandex. 2e partie</a></li>
<li><a href="../fr429958/index.html">Cinq règles de débogage faciles pour les débutants</a></li>
<li><a href="../fr429960/index.html">10 raisons pour lesquelles les clients se désabonnent d'un produit</a></li>
<li><a href="../fr429964/index.html">U> X> I> P ... ou "Comment les noms des professions jouent le saut"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸŒ“ ğŸ‘¸ğŸ» â˜‚ï¸ Membangun Arsitektur Berorientasi Layanan pada Rel + Kafka ğŸ¤˜ğŸ¿ âœ³ï¸ âœï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo, Habr! Saya mempersembahkan kepada Anda sebuah posting yang merupakan adaptasi teks dari kinerja Stella Cotton di RailsConf 2018 dan terjemahan d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Membangun Arsitektur Berorientasi Layanan pada Rel + Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450028/">  Halo, Habr!  Saya mempersembahkan kepada Anda sebuah posting yang merupakan adaptasi teks dari kinerja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Stella Cotton di RailsConf 2018</a> dan terjemahan dari artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">â€œMembangun Arsitektur Berorientasi Layanan dengan Rails dan Kafkaâ€</a> oleh Stella Cotton. <br><br>  Baru-baru ini, transisi dari arsitektur monolitik ke layanan-mikro terlihat jelas.  Dalam panduan ini, kita akan mempelajari dasar-dasar Kafka dan bagaimana pendekatan berbasis peristiwa dapat meningkatkan aplikasi Rails Anda.  Kami juga akan berbicara tentang masalah pemantauan dan skalabilitas layanan yang bekerja melalui pendekatan berorientasi peristiwa. <br><a name="habracut"></a><br><h2>  Apa itu Kafka? </h2><br>  Saya yakin Anda ingin memiliki informasi tentang bagaimana pengguna Anda datang ke platform Anda atau halaman apa yang mereka kunjungi, tombol mana yang mereka klik, dll.  Aplikasi yang benar-benar populer dapat menghasilkan milyaran acara dan mengirimkan sejumlah besar data ke layanan analitik, yang dapat menjadi tantangan serius bagi aplikasi Anda. <br><br>  Sebagai aturan, bagian integral dari aplikasi web membutuhkan apa yang disebut <i>aliran data waktu nyata</i> .  Kafka menyediakan koneksi toleran-kesalahan antara <b>produsen</b> , mereka yang menghasilkan acara, dan <b>konsumen</b> , mereka yang menerima acara ini.  Bahkan mungkin ada beberapa produsen dan konsumen dalam satu aplikasi.  Di Kafka, setiap acara ada untuk waktu tertentu, sehingga beberapa konsumen dapat membaca acara yang sama berulang kali.  Cluster Kafka mencakup beberapa broker yang merupakan instance Kafka. <br><br><img src="https://habrastorage.org/webt/ql/j1/uy/qlj1uyapeg_3fmswgflqauwmd7q.png"><br><br>  Fitur utama Kafka adalah kecepatan tinggi pemrosesan acara.  Sistem antrian tradisional, seperti AMQP, memiliki infrastruktur yang memantau acara yang diproses untuk setiap konsumen.  Ketika jumlah konsumen tumbuh ke tingkat yang layak, sistem hampir tidak mulai mengatasi beban, karena harus memantau peningkatan jumlah kondisi.  Juga, ada masalah besar dengan konsistensi antara konsumen dan pemrosesan acara.  Misalnya, apakah ada baiknya segera menandai pesan yang dikirim segera setelah diproses oleh sistem?  Dan jika konsumen jatuh ke ujung tanpa menerima pesan? <br><br>  Kafka juga memiliki arsitektur gagal-aman.  Sistem berjalan sebagai cluster di satu atau lebih server, yang dapat diskalakan secara horizontal dengan menambahkan mesin baru.  Semua data ditulis ke disk dan disalin ke beberapa broker.  Untuk memahami kemungkinan skalabilitas, ada baiknya melihat perusahaan seperti Netflix, LinkedIn, Microsoft.  Semuanya mengirim triliunan pesan per hari melalui kelompok Kafka mereka! <br><br><h2>  Menyiapkan Kafka di Rails </h2><br>  Heroku menyediakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">add-on cluster Kafka</a> yang dapat digunakan untuk lingkungan apa pun.  Untuk aplikasi ruby, kami sarankan menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">permata ruby-kafka</a> .  Implementasi minimal terlihat seperti ini: <br><br><pre><code class="ruby hljs"><span class="hljs-comment"><span class="hljs-comment"># config/initializers/kafka_producer.rb require "kafka" # Configure the Kafka client with the broker hosts and the Rails # logger. $kafka = Kafka.new(["kafka1:9092", "kafka2:9092"], logger: Rails.logger) # Set up an asynchronous producer that delivers its buffered messages # every ten seconds: $kafka_producer = $kafka.async_producer( delivery_interval: 10, ) # Make sure to shut down the producer when exiting. at_exit { $kafka_producer.shutdown }</span></span></code> </pre> <br>  Setelah mengkonfigurasi konfigurasi, Anda dapat menggunakan permata untuk mengirim pesan.  Berkat pengiriman acara yang tidak sinkron, kami dapat mengirim pesan dari mana saja: <br><br><pre> <code class="ruby hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">OrdersController</span></span></span><span class="hljs-class"> &lt; ApplicationController </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">create</span></span></span><span class="hljs-class"> @</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">comment</span></span></span><span class="hljs-class"> = </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Order</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">create!</span></span></span><span class="hljs-class">(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">params</span></span></span><span class="hljs-class">) $</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">kafka_producer</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">produce</span></span></span><span class="hljs-class">(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">order</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">to_json</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">topic</span></span></span><span class="hljs-class">: "</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">user_event</span></span></span><span class="hljs-class">", </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">partition_key</span></span></span><span class="hljs-class">: </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">user</span></span></span><span class="hljs-class">.</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">id</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">end</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">end</span></span></span></span></code> </pre> <br>  Kami akan berbicara tentang format serialisasi di bawah ini, tetapi untuk sekarang kami akan menggunakan JSON lama yang bagus.  Argumen <code>topic</code> merujuk pada log tempat Kafka menulis acara ini.  Topik tersebar di bagian yang berbeda, yang memungkinkan Anda untuk membagi data untuk topik tertentu menjadi broker yang berbeda untuk skalabilitas dan keandalan yang lebih baik.  Dan itu benar-benar ide yang baik untuk memiliki dua bagian atau lebih untuk setiap topik, karena jika salah satu bagian jatuh, acara Anda akan direkam dan diproses.  Kafka memastikan bahwa acara dikirimkan sesuai urutan antrian di dalam bagian, tetapi tidak dalam keseluruhan topik.  Jika urutan peristiwa penting, maka mengirim partisi_key memastikan bahwa semua peristiwa dari jenis tertentu disimpan di partisi yang sama. <br><br><h2>  Kafka untuk layanan Anda </h2><br>  Beberapa fitur yang menjadikan Kafka alat yang berguna juga menjadikannya RPC failover antar layanan.  Lihatlah contoh aplikasi e-commerce: <br><br><pre> <code class="ruby hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_order</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_order_record</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">charge_credit_card</span></span></span><span class="hljs-function"> </span><span class="hljs-comment"><span class="hljs-function"><span class="hljs-comment"># call to Payments Service send_confirmation_email # call to Email Service end</span></span></span></span></code> </pre> <br>  Ketika pengguna melakukan pemesanan, fungsi <code>create_order</code> .  Ini menciptakan pesanan dalam sistem, mengurangi uang dari kartu dan mengirim email dengan konfirmasi.  Seperti yang Anda lihat, dua langkah terakhir diambil dalam layanan terpisah. <br><br><img src="https://habrastorage.org/webt/i8/_y/tr/i8_ytruescd639f48vmelrmsfu4.png"><br><br>  Salah satu masalah dengan pendekatan ini adalah bahwa layanan unggul dalam hierarki bertanggung jawab untuk memantau ketersediaan layanan hilir.  Jika layanan untuk mengirim surat ternyata hari yang buruk, layanan yang lebih tinggi perlu mengetahuinya.  Dan jika layanan pengiriman tidak tersedia, maka Anda perlu mengulang serangkaian tindakan tertentu.  Bagaimana Kafka dapat membantu dalam situasi ini? <br><br>  Sebagai contoh: <br><br><img src="https://habrastorage.org/webt/i1/dh/a8/i1dha8zycj6ibxydaxja9y8bp10.png"><br><br>  Dalam pendekatan yang didorong oleh peristiwa ini, layanan yang unggul dapat merekam acara di Kafka yang telah dibuat pesanan.  Karena apa yang disebut pendekatan <i>setidaknya satu kali</i> , acara ini akan direkam di Kafka setidaknya sekali dan akan tersedia bagi konsumen hilir untuk membaca.  Jika layanan pengiriman surat berbohong, acara akan menunggu di disk hingga konsumen naik dan membacanya. <br><br>  Masalah lain dengan arsitektur berorientasi RPC adalah dalam sistem yang tumbuh cepat: menambahkan layanan hilir baru memerlukan perubahan di hulu.  Misalnya, Anda ingin menambahkan satu langkah lagi setelah membuat pesanan.  Di dunia yang didorong oleh peristiwa, Anda perlu menambahkan konsumen lain untuk menangani jenis acara baru. <br><br><img src="https://habrastorage.org/webt/ox/ic/ka/oxickaiivr5j6hey5fahjkcvsxc.png"><br><br><h2>  Mengintegrasikan Acara ke dalam Arsitektur Berorientasi Layanan </h2><br>  Sebuah posting berjudul " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Apa yang Anda maksud dengan" Event-Driven</a> "oleh Martin Fowler membahas kebingungan seputar aplikasi yang dikendalikan oleh peristiwa.  Ketika pengembang membahas sistem seperti itu, mereka sebenarnya berbicara tentang sejumlah besar aplikasi yang berbeda.  Untuk memberikan pemahaman umum tentang sifat sistem tersebut, Fowler mendefinisikan beberapa pola arsitektur. <br><br>  Mari kita lihat apa saja pola-pola ini.  Jika Anda ingin tahu lebih banyak, saya sarankan Anda membaca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">laporannya</a> di GOTO Chicago 2017. <br><br><h3>  Pemberitahuan acara </h3><br>  Pola Fowler pertama disebut <i>Pemberitahuan Acara</i> .  Dalam skenario ini, layanan produsen memberi tahu konsumen tentang acara tersebut dengan informasi minimum: <br><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"event"</span></span>: <span class="hljs-string"><span class="hljs-string">"order_created"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"published_at"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-03-15T16:35:04Z"</span></span> }</code> </pre> <br>  Jika konsumen membutuhkan lebih banyak informasi tentang acara tersebut, mereka meminta kepada produsen dan mendapatkan lebih banyak data. <br><br><h3>  Transfer status berdasarkan peristiwa </h3><br>  Templat kedua disebut <i>Transfer Keadaan Acara-Carried</i> .  Dalam skenario ini, produsen memberikan informasi tambahan tentang acara dan konsumen dapat menyimpan salinan data ini tanpa membuat panggilan tambahan: <br><br><pre> <code class="json hljs">{ <span class="hljs-attr"><span class="hljs-attr">"event"</span></span>: <span class="hljs-string"><span class="hljs-string">"order_created"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"order"</span></span>: { <span class="hljs-attr"><span class="hljs-attr">"order_id"</span></span>: <span class="hljs-number"><span class="hljs-number">98765</span></span>, <span class="hljs-attr"><span class="hljs-attr">"size"</span></span>: <span class="hljs-string"><span class="hljs-string">"medium"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"color"</span></span>: <span class="hljs-string"><span class="hljs-string">"blue"</span></span> }, <span class="hljs-attr"><span class="hljs-attr">"published_at"</span></span>: <span class="hljs-string"><span class="hljs-string">"2016-03-15T16:35:04Z"</span></span> }</code> </pre> <br><h3>  Sumber acara </h3><br>  Fowler menyebut templat ketiga <i>Event-Sourced</i> dan lebih bersifat arsitektur.  Pelepasan templat tidak hanya melibatkan komunikasi antara layanan Anda, tetapi juga pelestarian presentasi acara.  Ini memastikan bahwa bahkan jika Anda kehilangan database, Anda masih dapat mengembalikan keadaan aplikasi dengan hanya menjalankan aliran acara yang disimpan.  Dengan kata lain, setiap peristiwa menyimpan keadaan tertentu dari aplikasi pada saat tertentu. <br><br>  Masalah besar dengan pendekatan ini adalah bahwa kode aplikasi selalu berubah, dan dengan itu format atau jumlah data yang diberikan produsen dapat berubah.  Ini membuat mengembalikan status aplikasi bermasalah. <br><br><h3>  Segregasi Tanggung Jawab Permintaan Perintah </h3><br>  Dan templat terakhir adalah <i>Segregasi Command Query Responsibility</i> , atau CQRS.  Idenya adalah bahwa tindakan yang Anda terapkan ke objek, misalnya: membuat, membaca, memperbarui, harus dibagi ke dalam berbagai domain.  Ini berarti bahwa satu layanan harus bertanggung jawab atas pembuatan, yang lain untuk pembaruan, dll.  Dalam sistem berorientasi objek, semuanya sering disimpan dalam satu layanan. <br><br><img src="https://habrastorage.org/webt/xb/5b/mx/xb5bmxasal6md3bq2xsdgnhfhgg.png"><br><br>  Layanan yang menulis ke basis data akan membaca aliran acara dan memproses perintah.  Tetapi setiap permintaan hanya terjadi di database read-only.  Membagi logika baca dan tulis menjadi dua layanan yang berbeda meningkatkan kompleksitas, tetapi memungkinkan Anda untuk mengoptimalkan kinerja secara terpisah untuk sistem ini. <br><br><h2>  Masalahnya </h2><br>  Mari kita bicara tentang beberapa masalah yang mungkin Anda temui ketika mengintegrasikan Kafka ke aplikasi berorientasi layanan Anda. <br><br>  Masalah pertama mungkin lambat konsumen.  Dalam sistem yang berorientasi pada peristiwa, layanan Anda harus dapat memproses acara secara instan saat diterima dari layanan yang unggul.  Jika tidak, mereka hanya akan hang tanpa pemberitahuan tentang masalah atau batas waktu.  Satu-satunya tempat di mana Anda dapat menentukan batas waktu adalah koneksi soket dengan broker Kafka.  Jika layanan tidak menangani acara dengan cukup cepat, koneksi dapat terputus oleh batas waktu, tetapi memulihkan layanan memerlukan waktu tambahan, karena membuat soket seperti itu mahal. <br><br>  Jika konsumen lambat, bagaimana Anda bisa meningkatkan kecepatan pemrosesan acara?  Di Kafka, Anda dapat meningkatkan jumlah konsumen dalam grup, sehingga lebih banyak acara dapat diproses secara paralel.  Tetapi setidaknya 2 konsumen akan diminta untuk satu layanan: jika salah satu jatuh, bagian yang rusak dapat dipindahkan. <br><br>  Juga sangat penting untuk memiliki metrik dan peringatan untuk memantau kecepatan pemrosesan acara.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ruby-kafka</a> dapat bekerja dengan peringatan ActiveSupport, ia juga memiliki modul StatsD dan Datadog, yang diaktifkan secara default.  Selain itu, permata memberikan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">daftar</a> metrik yang disarankan untuk pemantauan. <br><br>  Aspek penting lain dari membangun sistem dengan Kafka adalah desain konsumen dengan kemampuan untuk menangani kegagalan.  Kafka dijamin mengirim acara setidaknya satu kali;  mengecualikan kasing ketika pesan tidak dikirim sama sekali.  Tetapi penting bahwa konsumen siap untuk menangani acara yang berulang.  Salah satu cara untuk melakukan ini adalah dengan selalu menggunakan <code>UPSERT</code> untuk menambahkan catatan baru ke database.  Jika catatan sudah ada dengan atribut yang sama, panggilan pada dasarnya tidak aktif.  Selain itu, Anda dapat menambahkan pengidentifikasi unik untuk setiap peristiwa dan hanya melewati acara yang sudah diproses sebelumnya. <br><br><h2>  Format data </h2><br>  Salah satu kejutan ketika bekerja dengan Kafka mungkin adalah sikapnya yang sederhana terhadap format data.  Anda dapat mengirim apa pun dalam byte dan data akan dikirim ke konsumen tanpa verifikasi apa pun.  Di satu sisi, ini memberikan fleksibilitas dan memungkinkan Anda untuk tidak peduli dengan format data.  Di sisi lain, jika produsen memutuskan untuk mengubah data yang dikirim, ada kemungkinan beberapa konsumen pada akhirnya akan rusak. <br><br>  Sebelum membangun arsitektur berorientasi acara, pilih format data dan analisis bagaimana itu akan membantu di masa depan untuk mendaftar dan mengembangkan skema. <br><br>  Salah satu format yang direkomendasikan untuk digunakan, tentu saja, adalah JSON.  Format ini dapat dibaca oleh manusia dan didukung oleh semua bahasa pemrograman yang dikenal.  Tapi ada jebakan.  Misalnya, ukuran data akhir di JSON bisa menjadi sangat besar.  Format ini diperlukan untuk menyimpan pasangan nilai kunci, yang cukup fleksibel, tetapi data digandakan di setiap peristiwa.  Mengubah skema juga merupakan tugas yang sulit karena tidak ada dukungan bawaan untuk overlay satu kunci pada yang lain jika Anda perlu mengganti nama bidang. <br><br>  Tim yang menciptakan Kafka menyarankan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Avro</a> sebagai sistem serialisasi.  Data dikirim dalam bentuk biner, dan ini bukan format yang paling dapat dibaca manusia, tetapi di dalamnya ada dukungan yang lebih dapat diandalkan untuk sirkuit.  Entitas terakhir di Avro mencakup skema dan data.  Avro juga mendukung kedua tipe sederhana, seperti angka, dan yang kompleks: tanggal, array, dll. Selain itu, Avro juga memungkinkan Anda untuk memasukkan dokumentasi di dalam skema, yang memungkinkan Anda untuk memahami tujuan bidang tertentu dalam sistem dan berisi banyak alat bawaan lainnya untuk bekerja dengan skema tersebut. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">avro-builder</a> adalah permata yang dibuat oleh Salsify yang menawarkan DSL seperti ruby â€‹â€‹untuk membuat skema.  Anda dapat membaca lebih lanjut tentang Avro di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel ini</a> . <br><br><h2>  Informasi tambahan </h2><br>  Jika Anda tertarik untuk meng-host Kafka atau bagaimana menggunakannya di Heroku, ada beberapa laporan yang mungkin menarik bagi Anda. <br><br>  Jeff Chao di DataEngConf SF '17 â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Melampaui 50.000 Partisi: Bagaimana Heroku Mengoperasikan dan Mendorong Batas Kafka pada Skala</a> â€ <br><br>  Pavel Pravosud di Dreamforce '16 â€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dogfooding Kafka: Bagaimana Kami Membangun Streaming Platform Platform Real-Time Heroku</a> â€ <br><br>  Selamat menikmati! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id450028/">https://habr.com/ru/post/id450028/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id450016/index.html">Pembuatan sistem verifikasi formal dari awal. Bagian 1: mesin virtual karakter dalam PHP dan Python</a></li>
<li><a href="../id450018/index.html">Duo matematika memetakan wilayah permukaan minimal yang tak berujung</a></li>
<li><a href="../id450020/index.html">Lembah Silikon datang ke anak sekolah Kansas. Ini menyebabkan protes.</a></li>
<li><a href="../id450024/index.html">Tentang implementasi open-source dari fungsi hash GOST R 34.11-2012 dan dampaknya terhadap tanda tangan elektronik GOST R 34.10-2012</a></li>
<li><a href="../id450026/index.html">Cipher akselerasi: kami mempelajari accelerometer perangkat Android menggunakan contoh tugas NeoQUEST-2019</a></li>
<li><a href="../id450030/index.html">Saya tidak bisa menggunakan Rift S dan Anda tidak akan berhasil</a></li>
<li><a href="../id450032/index.html">Cara membuat tema gelap tanpa merusak: belajar dengan tim Yandex Mail</a></li>
<li><a href="../id450034/index.html">Mengapa Anda harus berpartisipasi dalam hackathons</a></li>
<li><a href="../id450036/index.html">Summ3r 0f h4ck: magang Keamanan Digital 2019</a></li>
<li><a href="../id450040/index.html">Perusahaan baru akan mendukung OpenJDK 8 dan 11 - kami memahami situasinya</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚵🏾 👨🏿‍🚒 🤸🏻 我知道，这意味着我存在：计算机视觉深度学习的回顾（第1部分） 🕵🏾 🎫 👨🏽‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="计算机视觉。 现在，他们谈论了很多，并在很多地方应用和实施了它。 不久以前，还没有关于Habré的CV评论文章，其中包括架构和现代任务的示例。 但是它们很多，而且真的很酷！ 如果您不仅对研究和文章的观点感兴趣，而且对应用问题的观点感兴趣，都对计算机视觉现在正在发生的事情感兴趣，那么欢迎您。 此外，对...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>我知道，这意味着我存在：计算机视觉深度学习的回顾（第1部分）</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mipt/blog/450732/"> 计算机视觉。 现在，他们谈论了很多，并在很多地方应用和实施了它。 不久以前，还没有关于Habré的CV评论文章，其中包括架构和现代任务的示例。 但是它们很多，而且真的很酷！ 如果您不仅对<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">研究和文章</a>的观点感兴趣，而且对应用问题的观点感兴趣，都对计算机视觉现在正在发生的事情感兴趣，那么欢迎您。 此外，对于那些长期以来一直希望开始了解所有这些内容，但是有些事情已经成为现实的人来说，这篇文章可能是一个很好的介绍；） <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ecb/319/e06/ecb319e06d692a5ea4f2a1343cf9c31d.jpg" alt="图片"><br><a name="habracut"></a><br> 今天，在PhysTech上，“学院”与行业合作伙伴进行了积极的合作。 特别是，在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">应用数学和计算机科学物理技术学院</a> ，有来自Sberbank，Biocad，1C，Tinkoff，MTS，华为等公司的许多<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">有趣的实验室</a> 。 <br><br> 我受<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">VkusVill</a>开设的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">混合智能系统</a>实验室的启发而撰写本文。 实验室的任务很艰巨-要建立一家没有收银台的商店，主要是借助计算机视觉。 在将近一年的工作中，我有机会从事许多视觉任务，这将在这两部分中进行讨论。 <br><br><div class="spoiler">  <b class="spoiler_title">没有收银台的商店？</b>  <b class="spoiler_title">我已经在某个地方听到了..</b> <div class="spoiler_text"> 亲爱的读者，您可能想到了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Amazon Go</a> 。 从某种意义上说，任务是重复他们的成功，但是我们的决定更多是关于实现，而不是关于从头开始<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">花费很多钱来</a>建立这样的商店。 <br></div></div><br> 我们将按照计划进行： <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">动机和正在发生的事情</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">分类为生活方式</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">卷积神经网络架构：实现一个目标的1000种方法</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">卷积神经网络的可视化：向我展示激情</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">我本人是一名外科医生：我们从神经网络中提取特征</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">保持紧密：为个人和个人学习学习</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第2部分：在不扰流的情况下<s>检测，评估姿势和识别动作</s></a> </li></ol><br><a name="1"></a><h2> 动机和正在发生的事情 </h2><br><div class="spoiler">  <b class="spoiler_title">该文章适用于谁？</b> <div class="spoiler_text"> 本文将重点放在已经熟悉机器学习和神经网络的人们上。 但是，我建议您至少阅读前两部分-突然，所有内容都会变得很清楚:) <br></div></div><br> 在2019年，每个人都在谈论人工智能， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第四次工业革命</a>以及<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">人类走向单一的方法</a> 。 酷，很酷，但我想要细节。 毕竟，我们是好奇的技术人员，他们不相信关于AI的童话，我们相信正式的任务设定，数学和编程。 在本文中，我们将讨论使用非常现代的AI的特定情况-在各种计算机视觉任务中使用深度学习（即卷积神经网络）。 <br><br> 是的，我们将专门讨论网格，有时会从“经典”的角度提到一些想法（我们将在神经网络之前使用的视觉方法称为集合，但这绝不意味着现在不再使用它们）。 <br><br><div class="spoiler">  <b class="spoiler_title">我想从头开始学习计算机视觉</b> <div class="spoiler_text"> 我推荐<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Anton Konushin的课程“计算机视觉简介”</a> 。 我个人经历了SHAD中的对应部分，这为理解图像和视频处理奠定了坚实的基础。 <br></div></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gu/vu/o3/guvuo3vejwwjimlpcqiwgbpxldq.jpeg" alt="图片" width="300"></div><br> 我认为，神经网络在视觉中的第一个真正有趣的应用是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Jan LeCun的</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">笔迹识别</a> ，该应用早在1993年就被媒体报道。 现在他是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Facebook AI Research</a>的主要AI之一，他们的团队已经发布了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">许多有用的Open Source资料</a> 。 <br><br> 如今，视觉已在许多领域使用。 我仅举几个引人注目的示例： <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/3x/tl/-j/3xtl-j0kmdt9ttlnakeka3kpj0u.jpeg" alt="图片" width="400"></div><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/967/987/50c/96798750c04282d6514f994b8375edcb.jpg" alt="图片" width="400" height="300"></div><br><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">特斯拉</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Yandex</a>无人机</i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dda/997/082/dda9970829bfb17bb2b118a08d519835.jpg" alt="图片" width="400"></div><br><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">医学影像分析</a>和<a href="">癌症预测</a></i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/jz/9k/2o/jz9k2ovcurxg4zd_cj_kb20hs_0.jpeg" alt="图片" width="500"></div><br><br>  <i>游戏机：Kinect 2.0（尽管它也使用深度信息，即RGB-D图片）</i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4d1/fb8/125/4d1fb8125d4624b40993f441b42ac48d.jpg" alt="图片" width="400"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wf/kw/la/wfkwlap8pltophsuh1ggkxgkii8.jpeg" width="400"></div><br><br>  <i>人脸识别： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Apple FaceID</a> （使用多个传感器）</i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2d3/f3b/178/2d3f3b17818ae279e7a47d3c940e002f.jpg" alt="图片" width="400"></div><br><br>  <i>面点评级： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Snapchat口罩</a></i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/hn/cw/oc/hncwocoggiei8lkijpl8ihgbx_o.jpeg" alt="图片" width="400"></div><br><br>  <i>面部和眼睛运动的生物特征识别（以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">FPMI MIPT项目为例</a> ）</i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/vg/vv/4f/vgvv4f_ddwswudk1yvghxjl4rne.png" alt="图片" width="400"></div><br><br>  <i>通过图像搜索：Yandex和Google</i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b4d/cfd/d13/b4dcfdd13f85affc79d876cf4bd3f4fd.jpg" alt="图片" width="500"></div><br><br>  <i>图片中<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">文字的识别</a> （ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">光学字符识别</a> ）</i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cfa/2bb/afa/cfa2bbafae96a5bd082ef25bae9d19af.jpg" alt="图片" width="400"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/60d/62d/670/60d62d670999dcc7cbd726dde47905a0.jpg" alt="图片" width="400"></div><br><br>  <i>无人机和机器人：通过视觉接收和处理信息</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/113/220/ca0/113220ca03176c5a99b82819076e0c8a.jpg" alt="图片" width="500"></div><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">里程表</a> ：移动机器人时制作地图并计划</i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/webt/ju/b7/i6/jub7i61z3oiairdg2q45x0l6loi.png" alt="图片" width="500"></div><br><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">改善视频游戏中的图形和纹理</a></i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d56/155/0ee/d561550eec9f5badc4475392a584fe03.jpg" alt="图片" width="200" height="300"></div><br><br>  <i>图片翻译：Yandex和Google</i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/859/ffd/2d5/859ffd2d56f231c5f9b802978a688c94.jpg" alt="图片" width="500"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/31f/003/a47/31f003a47c5dc5b5c5f75758d4d3689c.jpg" alt="图片" width="500"></div><br><br>  <i>增强现实： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Leap Motion（Project North Star）</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Microsoft Hololens</a></i> <br><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9a4/3ea/74b/9a43ea74ba0b5595f257feb313756293.jpg" alt="图片" width="250" height="200"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e90/962/25b/e9096225bb7d5799823737c960e19ad6.jpg" width="250" height="300"></div><br><br>  <i>样式和纹理转移： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Prisma</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">PicsArt</a></i> <br><br> 更不用说在公司内部各种任务中的大量应用。 例如，Facebook还使用视觉来过滤媒体内容。 计算机视觉方法还用于工业<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">中的质量/损坏测试</a> 。 <br><br> 实际上，这里的增强现实必须受到特别关注，因为<s>它</s>在不久的将来<s>不起作用</s> ，这可能成为视觉应用的主要领域之一。 <br><br> 有动力。 已收费。 出发： <br><br><a name="2"></a><h2> 分类为生活方式 </h2><br><br><img src="https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/38211dc39e41273c0007889202c69f841e02248a/2-Figure1-1.png" alt="图片"><br><br> 就像我说的那样，在90年代，渔网已经被开除。 他们完成了一项特定任务-对手写数字图片进行分类的任务（著名的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">MNIST数据集</a> ）。 从历史上看，分类图像的任务成为解决视觉中几乎所有后续任务的基础。 考虑一个具体的例子： <br><br>  <b>任务</b> ：在入口处提供一个带照片的文件夹，每张照片都有一个特定的对象：猫，狗或人（即使没有“垃圾”照片，这也是一项超重要的任务，但您需要从某个地方开始）。 您需要将图片分解为三个文件夹： <code>/cats</code> ， <code>/dogs</code>和<s><code>/leather_bags</code></s> <code>/humans</code> ，在每个文件夹中仅放置带有相应对象的照片。 <br><br><div class="spoiler">  <b class="spoiler_title">什么是图片/照片？</b> <div class="spoiler_text"><img src="https://habrastorage.org/getpro/habr/post_images/074/e15/f04/074e15f04c8347ab32f98ba04aeceb6c.png" alt="图片"><br> 视觉上几乎所有地方都习惯使用RGB格式的图片。 每张图片的高度（H），宽度（W）和深度为3（彩色）。 因此，一个图片可以表示为尺寸为HxWx3的张量（每个像素是一组三个数字-通道中的强度值）。 <br></div></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/26c/167/e3f/26c167e3feb823e778b32278358053f9.jpg" width="400"></div><br><br> 想象一下，我们还不熟悉计算机视觉，但是我们知道机器学习。 图像只是计算机内存中的数字张量。 我们根据机器学习形式化任务：对象是图片，其符号是像素值，每个对象的答案是类别标签（猫，狗或人）。 这是纯粹的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">分类任务</a> 。 <br><br><div class="spoiler">  <b class="spoiler_title">如果现在变得困难..</b> <div class="spoiler_text">  ...那么最好先阅读<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">OpenDataScience ML开放课程</a>的前4篇文章，然后阅读关于视觉的更具介绍性的文章，例如， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在Small ShAD中</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">精彩演讲</a> 。 <br></div></div><br> 您可以从“经典”视图或“经典”机器学习中采用某些方法，而不是神经网络。 基本上，这些方法包括突出显示图像特征的某些特征（特殊点）或局部区域的图像（“ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">视觉单词袋</a> ”）。 通常，一切都归结为基于<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">HOG</a> / <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">SIFT的</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">SVM</a> 。 <br><br> 但是我们聚集在这里讨论神经网络，所以我们不想使用我们发明的信号，而是希望网络为我们做一切。 我们的分类器将对象的符号作为输入并返回预测（类标签）。 在这里，以像素为单位的强度值充当符号（请参见 <br> 以上的剧透）。 请记住，图片是大小张量（Height，Width，3）（如果是彩色的话）。 当学习进入网格时，通常不是通过一张图片而不是整个数据集来提供所有这些服务，而是通过批量服务，即 在对象的一小部分中（例如，批处理中有64张图像）。 <br><br> 因此，网络接收大小为（BATCH_SIZE，H，W，3）的输入张量。 您可以将每张图片“扩展”为H * W * 3个数字的矢量线，并像处理机器学习中的符号一样使用像素值进行操作，常规的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">多层感知器（MLP）</a>可以做到这一点，但是坦率地说，基线，因为将像素用作向量行时未考虑图片中对象的平移不变性。 同一只猫可能在照片的中间，而在角落，MLP将不会学习此模式。 <br><br> 因此，您需要更智能的东西，例如卷积运算。 这是关于现代视觉，关于<b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">卷积神经网络</a></b> ： <br><br><div class="spoiler">  <b class="spoiler_title">卷积网络训练代码可能看起来像这样（在PyTorch框架上）</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : # https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html import torch.nn as nn import torch.nn.functional as F import torch.optim as optim class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) for epoch in range(2): # loop over the dataset multiple times running_loss = 0.0 for i, data in enumerate(trainloader, 0): # get the inputs inputs, labels = data # zero the parameter gradients optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # print statistics running_loss += loss.item() if i % 2000 == 1999: # print every 2000 mini-batches print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print('Finished Training')</span></span></code> </pre><br></div></div><br> 从现在开始我们正在谈论<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">与老师的培训</a> ，我们需要几个组件来训练神经网络： <br><br><ul><li> 数据（已经存在） </li><li> 网络架构（重点） </li><li> 一个损失函数，它将告诉神经网络如何学习（这里将是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">交叉熵</a> ） </li><li> 优化方法（将朝着正确的方向改变网络权重） </li><li> 定义架构和优化器超参数（例如，优化器步长，层中神经元数量，正则化系数） </li></ul><br> 这正是在代码中实现的；卷积神经网络本身在Net（）类中进行了描述。 <br><br> 如果您想慢慢地并从一开始就了解捆绑和卷积网络，我建议您<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在深度学习学院（MIPT MIPT）（俄语）</a>上就此主题进行<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">演讲，</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">当然还建议在斯坦福大学的课程cs231n（英语）中进行演讲</a> 。 <br><br><div class="spoiler">  <b class="spoiler_title">深度学习学校-这是什么？</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">创新实验室FPMI MIPT的</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深度学习学校</a>是一个积极参与开发有关神经网络的开放式俄语课程的组织。 在本文中，我将多次参考这些<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">视频教程</a> 。 <br></div></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fb1/3ca/d97/fb13cad97db640053bb2c53c12b0f4a7.jpg" alt="图片" width="650"></div><br> 简而言之，通过卷积运算，您可以根据图像的可变性在图像上找到图案。 实际上，当我们训练卷积神经网络（英文：Convolutional Neural Networks）时，我们发现了能很好地描述图像的卷积滤波器（神经元权重），因此我们可以从中准确地确定类别。 已经发明了许多方法来建立这样的网络。 超出您的想象... <br><br><a name="3"></a><h3> 卷积神经网络架构：实现一个目标的1000种方法 </h3><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c28/ab9/3c6/c28ab93c670c1e44258dc86064bb3a0c.png" alt="图片" width="500"></div><br><br> 是的，是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">另一篇建筑评论</a> 。 但是在这里，我将尝试使其尽可能相关！ <br><br> 首先是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">LeNet</a> ，它帮助Jan LeCun在1998年识别了数字。 这是第一个用于分类的卷积神经网络。 她的主要特征是她基本上开始使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">卷积和池化</a>操作。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bd4/27e/5e2/bd427e5e2943ebf58409e42538c4e131.png" alt="图片"><br><br> 然后，网格的发展停滞了，但是硬件并没有停滞不前； <abbr title="加速线性代数">开发了</abbr>基于GPU和<abbr title="加速线性代数">XLA的</abbr>有效计算。 在2012年，AlexNet出现了，她参加了ILSVRC（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ImageNet大规模视觉识别挑战赛</a> ） <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">比赛</a> 。 <br><br><div class="spoiler">  <b class="spoiler_title">关于ILSVRC的一点题外话</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ImageNet</a>于2012年组装完毕，ILSVRC竞赛使用了数千张图片和1000个类别的子集。  ImageNet目前有约1400万张图片和21,841个类（从官方网站上获取），但对于比赛，它们通常通常只选择一个子集。 随后，ILSVRC成为最大的年度图像分类竞赛。 顺便说一句，我们最近<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在几分钟之内就</a>确定了如何<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在ImageNet上</a>进行<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">训练</a> 。 <br><br> 从2010年到2018年，在ImageNet（在ILSVRC中）上，他们获得了<abbr title="最先进的">SOTA</abbr>网络的图像分类。 的确，自2016年以来，本地化，检测和对场景理解（而非分类）的竞争更为相关。 <br></div></div><br> 通常，各种<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">体系结构审查可以</a>揭示从2010年到2016年在ILSVRC上进行的第一次审查，以及一些单独的网络。 为了不使故事混乱，我将它们放在下面的扰流板下面，试图强调主要思想： <br><br><div class="spoiler">  <b class="spoiler_title">2012年至2015年的建筑</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th> 年份 </th><th> 文章 </th><th> 关键思想 </th><th> 机重 </th></tr><tr><td>  2012年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">亚历克斯网</a> </td><td> 连续使用两个束； 将网络训练分为两个并行分支 </td><td>  240兆字节 </td></tr><tr><td>  2013年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Zfnet</a> </td><td> 过滤器尺寸，层中过滤器数量 </td><td>  -- </td></tr><tr><td>  2013年 </td><td>  <a href="">夸大其词</a> </td><td> 首批神经网络检测器之一 </td><td>  -- </td></tr><tr><td>  2014年 </td><td>  <a href="">Vgg</a> </td><td> 网络深度（13-19层），使用多个卷积尺寸较小（3x3）的Conv-Conv-Pool块 </td><td>  549MB（VGG-19） </td></tr><tr><td>  2014年 </td><td>  <a href="">盗梦空间（v1）（aka GoogLeNet）</a> </td><td>  1x1卷积（来自“ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">网络中网络”的思想</a> ），辅助损失（或<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深度监控</a> ），几个卷积的输出堆叠（“初始块”） </td><td>  -- </td></tr><tr><td>  2015年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Resnet</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">残余连接</a> ，非常深（152层..） </td><td>  98 MB（ResNet-50），232 MB（ResNet-152） </td></tr></tbody></table></div><br></div></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/i4/b4/z3i4b4pxfnulxzfszysn_usqn_c.png" width="500"></div><br><br> 所有这些架构的思想（除了ZFNet之外，通常很少提及）在视觉神经网络中是一个新词。 但是，在2015年之后，还有许多重要的改进，例如Inception-ResNet，Xception，DenseNet，SENet。 下面我试图将它们收集在一个地方。 <br><br><div class="spoiler">  <b class="spoiler_title">2015年至2019年的建筑</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th> 年份 </th><th> 文章 </th><th> 关键思想 </th><th> 机重 </th></tr><tr><td>  2015年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">初始版本v2和v3</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">将包分解为包1xN和Nx1</a> </td><td>  92兆字节 </td></tr><tr><td>  2016年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Inception v4和Inception-ResNet</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Inception和ResNet的结合</a> </td><td>  215兆字节 </td></tr><tr><td>  2016-17 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">续接</a> </td><td>  ILSVRC第二名，使用许多分支（“通用” Inception块） </td><td>  -- </td></tr><tr><td>  2017年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Xception</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深度可分离卷积</a> ，重量更轻，精度可与Inception相提并论 </td><td>  88兆字节 </td></tr><tr><td>  2017年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">密集网</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">密块</a> 轻巧但准确 </td><td>  33 MB（DenseNet-121），80 MB（DenseNet-201） </td></tr><tr><td>  2018年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">塞内特</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">挤压和激励块</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">46 MB（SENet-Inception），440 MB（SENet-154）</a> </td></tr></tbody></table></div><br></div></div><br> 这些PyTorch的大多数模型都可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这里</a>找到，这真是太<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">酷了</a> 。 <br><br> 您可能已经注意到，整个设备的重量很大（我希望最大为20 MB，甚至更少），而如今，它们在各处使用移动设备，而<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">物联网正变得</a>越来越流行，这意味着您也希望在这里使用网格。 <br><br><div class="spoiler">  <b class="spoiler_title">模型重量和速度之间的关系</b> <div class="spoiler_text"> 由于自身内部的神经网络仅乘以张量，因此乘法运算的次数（读取：权数）直接影响工作速度（如果不使用劳动密集型的后处理或预处理）。 网络本身的速度取决于实现方式（框架），运行网络的硬件以及输入图像的大小。 <br></div></div><br> 许多文章的作者走了发明快速架构的道路，我在下面的破坏者中收集了他们的方法： <br><br><div class="spoiler">  <b class="spoiler_title">CNN轻量级架构</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><th> 年份 </th><th> 文章 </th><th> 关键思想 </th><th> 机重 </th><th> 实施实例 </th></tr><tr><td>  2016年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">挤压网</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">FireModule压缩</a> </td><td>  0.5兆字节 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">咖啡</a> </td></tr><tr><td>  2017年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">网络</a> </td><td><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">通过神经搜索架构获得，这是AutoML类别的网络</a> </td><td>  23兆字节 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr><tr><td>  2017年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">洗牌网</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">按点分组转化，频道随机播放</a> </td><td>  -- </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">咖啡</a> </td></tr><tr><td>  2017年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">MobileNet（v1）</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">深度可分离卷积和许多其他技巧</a> </td><td>  16兆字节 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">张量流</a> </td></tr><tr><td>  2018年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">MobileNet（v2）</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">我在哈布雷推荐这篇文章</a> </td><td>  14兆字节 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">咖啡</a> </td></tr><tr><td>  2018年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Squeezenext</a> </td><td> 查看原始存储库中的图片 </td><td>  -- </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">咖啡</a> </td></tr><tr><td>  2018年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">网络</a> </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">使用RL专门针对移动设备进行神经体系结构搜索</a> </td><td>  〜2 MB </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">张量流</a> </td></tr><tr><td>  2019年 </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">MobileNet（v3）</a> </td><td> 她在我写文章时出来:) </td><td>  -- </td><td>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">火炬</a> </td></tr></tbody></table></div><br></div></div><br> 所有表格<s>中</s>的数字均来自存储库<s>的最高限额</s> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Keras Applications表格</a>以及<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">本文</a> <s>的上限</s> 。 <br><br> 您问：“为什么要写整个模型的“动物园”？ 为什么要进行分类任务？ 但是我们想教机器看，而分类只是一种狭窄的任务..”。 事实是，用于检测对象，评估姿势/点，重新识别和搜索图片的神经网络完全使用分类模型作为<b><abbr title="基本，从字面上看-脊柱">主干</abbr></b> ，成功的80％取决于它们。 <br><br> 但是我想以某种方式更加信任CNN，或者他们想到了黑匣子，但是“内部”的含义并不明显。 为了更好地了解卷积网络的功能机制，研究人员提出了可视化的用途。 <br><br><a name="4"></a><h3> 卷积神经网络的可视化：向我展示激情 </h3><br> 理解卷积网络内部正在发生的事情的重要一步是<a href="">“可视化和理解卷积网络”</a> 。 在其中，作者提出了几种方法来准确可视化不同CNN层中神经元的响应（在图片的哪些部分上）（我也建议观看<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">有关此主题的斯坦福大学讲座</a> ）。 结果令人印象深刻：作者表明，卷积网络的第一层通过边缘/角度/线的类型对某些“低级事物”做出响应，而最后一层已经对图像的整个部分做出了响应（请参见下图），也就是说，它们已经携带了本身有一些语义。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fz/vm/ym/fzvmymab57wgircssyfgxiaomvy.jpeg" alt="图片"></div><br><br> 此外， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">康奈尔大学和公司的</a>深度可视化项目进一步提高了可视化效果，而<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">著名的DeepDream</a>学会了以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">令人上瘾的</a>有趣风格进行变形（下图来自<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">deepdreamgenerator.com</a> ）。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e55/809/63f/e5580963fdfb998bfe2103f4cbf5aa8c.jpg" alt="图片" width="500"></div><br><br>  2017年， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在Distill上发表了一篇非常不错的文章</a> ，他们在其中对每个层“看到”的内容进行了详细分析，最近一次（2019年3月），Google发明了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">激活地图集</a> ：可以为每个网络层构建的唯一地图，这使我们更加了解CNN工作的总体情况。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/b-/-k/iw/b--kiw7-vibdk8vpuzfxhbagkuu.png" width="700"></div><br><br> 如果您想自己玩可视化，我建议您使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Lucid</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorSpace</a> 。 <br><br> 好吧，CNN似乎在一定程度上是正确的。 我们需要学习如何在其他任务中使用此功能，而不仅仅是在分类中。 这将帮助我们提取Embedding'ov图片和转移学习。 <br><br><a name="5"></a><h2> 我本人是一名外科医生：我们从神经网络中提取特征 </h2><br> 想象有一张图片，我们想找到一个看起来像它的图片（例如，这是在Yandex.Pictures中搜索图片）。 以前（在神经网络之前），工程师习惯于为此手动提取特征，例如，发明一种能够很好地描述图片并使其与其他图片进行比较的东西。 基本上，这些方法（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">HOG</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">SIFT</a> ）使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">图像梯度</a>进行操作，通常将这些方法称为“经典”图像描述符。 特别感兴趣的是，我指的是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这篇文章</a>以及<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Anton Konushin</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">课程</a> （这不是广告，只是一门好课程：） <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5cd/b10/ea8/5cdb10ea8f19fe29432265e906640a90.jpg" alt="图片" width="500"></div><br><br> 使用神经网络，我们不能自己发明这些功能和启发式方法，而是要适当地训练模型，然后<b>将一层或多层网络的输出作为图片的标志</b> 。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/887/d76/eb4/887d76eb431bcaf434ff70e2e0f2d4b0.png" alt="图片" width="650"></div><br> 仔细研究所有体系结构，可以清楚地看出，在CNN中分类有两个步骤： <br>  1）。  <b>特征提取器</b>层，用于使用卷积层从图像中提取信息特征 <br>  2）。 在这些功能之上学习<b>全连接（FC）</b>分类器层 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/55d/ca5/358/55dca535836121c65546bc11e2d457c1.png" alt="图片" width="500"></div><br><br>  <b>图像（特征）的嵌入</b>几乎是一个事实，您可以在卷积神经网络的特征提取器之后采用它们的标志（尽管它们可以以不同的方式聚合），作为对图像的丰富描述。 也就是说，我们对网络进行了分类训练，然后在分类层的前面出口。 这些标志称为<i>特征</i> ， <i>神经网络描述符</i>或图片<i>嵌入</i> （尽管NLP通常接受嵌入，因为这是视觉，所以我经常会说<i>特征</i> ）。 通常，这是某种数字矢量，例如128个数字，您已经可以使用它们。 <br><br><div class="spoiler">  <b class="spoiler_title">但是自动编码器呢？</b> <div class="spoiler_text"> 是的，事实上，功能可以通过<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">自动编码器</a>获得。 在我的实践中，他们以不同的方式做到了这一点，但是，例如，在有关重新识别的文章（将在后面讨论）中，他们仍然经常在提取器之后使用功能，而不是为此训练自动编码器。 在我看来，如果问题是什么效果更好，则有必要在两个方向进行实验。 <br></div></div><br> 因此，可以简单地安排用于解决<b>按图片搜索问题</b>的管道：我们通过CNN运行图片，从所需层获取标志，并从不同图片中将这些特征彼此进行比较。 例如，我们仅考虑这些向量的欧几里德距离。 <br><br><div style="text-align:center;"><img src="http://api.ning.com/files/1a5R6o7JsEHZ9j2SOd20XYu2GYExArt4Kr*0U07Z1JYbfSnF2ugTP7wmqMJn-l2auLHblJkG2QbtZcVqzScB81vPibkAjqBg/transferlearning.png" alt="图片" width="500"></div><br><br>  <b>转移学习</b>是一种有效训练神经网络的众所周知的技术，已经在特定数据集上对其神经网络进行了训练。 他们经常说精调，而不是转移学习，在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">斯坦福课程笔记cs231n中，</a>这些概念是共享的，他们说，转移学习是一个普遍的想法，而精调是该技术的一种实现。 这对我们将来并不那么重要，主要是要了解我们可以训练网络以在新数据集上进行良好的预测，而不是从随机权重开始，而要从在某些大型ImageNet类型上训练的权重开始。 当数据很少并且您想定性解决问题时，尤其如此。 <br><br><div class="spoiler">  <b class="spoiler_title">了解有关转学的更多信息</b> <div class="spoiler_text">  <a href="">原创文章</a> ，但<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">如果可以观看视频</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">为什么</a>还要<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">阅读大量文字</a> <br></div></div><br> 但是，例如，对于搜索相似的人/人/特定事物的任务，仅采取必要的功能并从数据集到数据集进行额外的训练可能是不够的。 有时从视觉上看同一个人的照片可能比不同人的照片更为相似。 即使我们很难用眼睛做到这一点，也必须使网络准确地突出一个人/物体固有的那些标志。 欢迎来到<b>表示学习</b>的世界。 <br><br><a name="6"></a><h2> 保持紧密：为个人和个人学习学习 </h2><br><div class="spoiler">  <b class="spoiler_title">术语注释</b> <div class="spoiler_text"> 如果您阅读科学文章，有时似乎有些作者对<b>度量学习</b>一词的理解会有所不同，并且对于哪种度量学习方法没有共识。 这就是为什么在本文中，我决定避免使用该特定短语，而是使用更合理的<b>表示法学习</b> ，一些读者可能不同意这一点-我很乐意在评论中进行讨论。 <br></div></div><br> 我们设置任务： <br><br><ul><li>  <b>任务1</b> ：有一个画廊（一组），上面有人们的面孔照片，我们希望网络能够根据一张新照片做出回应，或者以画廊中某人的名字作为响应（假设是这样），或者说画廊中没有这样的人（也许，我们添加了新人） <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fbc/3ad/f28/fbc3adf280e28f7bb71246f50c1e8d9e.jpg" width="300"></div></li><li>  <b>任务2</b> ：同一件事，但我们的工作不是处理人脸照片，而是处理大量人员 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jh/43/xs/jh43xsjjgxixbw8cmo1idxage5a.jpeg" width="400"></div></li></ul><br><br> 通常，第一个任务是<b>人脸识别</b> ，第二个任务是<b>重新识别</b> （缩写为<i>Reid</i> ）。 我将它们组合成一个块，因为它们的解决方案现在使用类似的思想：为了学习可以应付相当困难的情况的有效图像嵌入，如今​​它们使用了不同类型的损耗，例如<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">三重损耗</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">四重损耗</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">对比中心损失</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">余弦损失</a> 。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9s/pj/cm/9spjcm6xbc2j2ip_wgri9wutjpi.jpeg" width="550"></div><br><br> 仍然有很棒的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">暹罗</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">网络</a> ，但老实说我自己并没有使用它们。 顺便说一句，不仅是损失本身在“决定”，而且是如何对正负进行<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">抽样</a> ，《 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">抽样</a>研究》的作者强调<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">了深度嵌入学习</a> 。 <br><br> 所有这些损失和连体网络的本质很简单-我们希望要素（嵌​​入）的潜在空间中一类（人）的图片“接近”，而不同类（人）的潜在空间中的图片“远”。 接近度通常按以下方式测量：嵌入来自神经网络的图像（例如，128个数字的向量），我们要么考虑这些向量之间通常的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">欧几里得距离</a> ，要么考虑<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">余弦距离。</a> 如何衡量最好在数据集/任务上进行选择。 <br><br> 关于表示学习的问题解决管道的示意图表示如下： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/16/uh/n8/16uhn8l_iahuy-bcv_e4vohx1je.png" width="850"></div><br><br><div class="spoiler">  <b class="spoiler_title">但更确切地说，像这样</b> <div class="spoiler_text"> <b>  </b> :      (Softmax + CrossEntropy),      (Triplet, Contrastive, etc.).        positive'  negative'    <br><br> <b>  </b> :     -     ,        —   .   ,     —     -   ,       (,     <i></i> ).                 .   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a> <br></div></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">有几篇</font><font style="vertical-align: inherit;">专门针对</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">人脸识别的</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">好文章：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">评论文章（</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">必须阅读！</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceNet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ArcFace</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CosFace</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/208/1b9/d34/2081b9d346f74503302b8fd2c7265ef5.png" alt="图片" width="700"></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">还有很多实现：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">dlib</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenFace</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">FaceNet存储库</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在Habré上已经有很长一段时间被告知了</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">似乎最近才添加了ArcFace和CosFace（在注释中写，如果我在这里错过了一些内容，我将很高兴知道其他内容）。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">但是，现在更时尚的是不识别面孔，而是</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">生成</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">面孔，</font><font style="vertical-align: inherit;">不是吗？</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/t9/k3/zv/t9k3zvmuf30yzmcvlube_okh5ey.png" width="500"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">反过来，</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">重新识别</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">任务</font><font style="vertical-align: inherit;">现在正在进行中，每个月都会发表文章，人们尝试不同的方法，某些事情现在正在起作用，某些事情仍然不是很好。</font></font><br><br><img src="https://habrastorage.org/webt/f_/pe/cd/f_pecd2dvv5kbatdpj0nkk4aapm.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我将通过一个例子来说明里德问题的实质：一个画廊里有</font></font><abbr title="从大照片上切下的人类检测"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">很多</font></font></abbr><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">人，例如10个人，每个人有5个庄稼（可以来自不同侧面），也就是说，画廊里有50张照片。一个新的侦探（作物）来了，我必须说出画廊里是什么样的人，或者说他不在那儿，并为他创建一个新的ID。由于人类的检测来自不同的角度：前，后，侧面，</font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">底部</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和照片所来自的相机也不同（不同的照明/白平衡等），</font><font style="vertical-align: inherit;">因此使任务变得复杂</font><font style="vertical-align: inherit;">。</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ca/pn/gr/capngrtiskbeltdx0oq_wfntw0i.png" width="700"></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">顺便说一句，</font><font style="vertical-align: inherit;">里德（Reid）是</font><font style="vertical-align: inherit;">我们</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">实验室</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">中的关键任务之一。</font><font style="vertical-align: inherit;">确实有很多文章问世，其中一些是关于一种新的，更有效的损失，有些只是关于一种获得负面和正面损失的新方法。</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">2016年的一篇文章</font></a></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">对旧的Reid方法进行</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">了</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">很好的回顾</font><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">现在，正如我在上面所写，应用了两种方法-分类或表示学习。</font><font style="vertical-align: inherit;">但是，这个问题存在一个特殊性，研究人员以不同的方式来解决它，例如，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aligned Re-Id</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的作者</font><font style="vertical-align: inherit;">提出以一种特殊的方式来对准要素（是的，他们能够使用动态编程来改善网络</font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，Karl</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">），在</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">另一篇文章中，他们</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">建议使用</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Generative Adversarial Networks（GAN） ）</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 。 </font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">还有一些技巧。</font></font></b> <div class="spoiler_text"><ul><li>    , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">   </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">  handcrafted-    </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">       </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">  Transfer Learning     </a> </li></ul><br></div></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/456/66e/9c0/45666e9c0608373c31452aeb6a197477.jpg" alt="图片" width="650"></div><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">减激励器</font></font></b> <div class="spoiler_text">      ,   , -,        . ,  -  ,     ,    ,     <s>   </s> .   —    ! <br></div></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在这些实现中，我肯定会提到</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">OpenReid</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TorchReid</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">注意代码本身-在我看来，从框架的体系结构的角度来看，它是正确编写的，更多详细信息请参见</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">此处</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">另外，它们都在PyTorch上，并且自述文件中有许多指向“人员重新识别”的文章的链接，这很好。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">总的来说，现在中国对面部算法和里德算法有特殊的需求（</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如果您知道我的意思</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">）。</font><font style="vertical-align: inherit;">我们上线了吗？</font><font style="vertical-align: inherit;">谁知道...</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 关于神经网络加速的一句话 </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们已经说过，您可以提出一种轻量级的体系结构。</font><font style="vertical-align: inherit;">但是，如果网络已经过训练并且很酷，但是您仍然需要对其进行压缩，该怎么办？</font><font style="vertical-align: inherit;">在这种情况下，以下一种（或全部）方法可能会有所帮助：</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">蒸馏：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">二</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">三</font></font></a> </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">量化：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">二</font></font></a> </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">修剪：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">二</font></font></a> </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">好吧，规则不是使用float64，而是，例如，没有人取消float32。</font><font style="vertical-align: inherit;">甚至最近有</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一篇关于低精度训练的文章</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font><font style="vertical-align: inherit;">顺便说一下，最近，Google推出了</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MorphNet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，它（</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">某种程度上</font></a><font style="vertical-align: inherit;">）有助于自动压缩模型。</font></font><br><br><a name="7"></a><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 接下来是什么？ </font></font></h3><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ue/22/e1/ue22e11md3zjexlxq3jxsf-kx18.jpeg" alt="图片" width="500"></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">我们确实讨论了DL和CV中的许多有用和应用的内容：分类，网络体系结构，可视化，嵌入。</font><font style="vertical-align: inherit;">但是，在现代视觉中，还有其他重要任务：检测，分割，对场景的理解。</font><font style="vertical-align: inherit;">如果我们在谈论视频，那么我想及时</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">跟踪</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">对象</font><font style="vertical-align: inherit;">，识别动作并了解视频中正在发生的事情。</font><font style="vertical-align: inherit;">正是由于这些原因，第二部分将专门讨论。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">敬请期待！</font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PS：PMI MIPT物理学院现在提供什么样的教育？</font></font></b> <div class="spoiler_text">      (,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a> ,   ),      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a> ,   ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> .          <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> .   ,          ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">   </a> (  ). <br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN450732/">https://habr.com/ru/post/zh-CN450732/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN450720/index.html">如何开发用户友好的应用程序</a></li>
<li><a href="../zh-CN450724/index.html">为同志们介绍Python，而不再使用“ A vs. V语言” 语言B”等偏见</a></li>
<li><a href="../zh-CN450726/index.html">创建一个工具来快速有效地在Selenium上编写自动测试</a></li>
<li><a href="../zh-CN450728/index.html">NLog：规则和过滤器</a></li>
<li><a href="../zh-CN450730/index.html">ok.tech：前端聚会</a></li>
<li><a href="../zh-CN450734/index.html">模糊测试是安全开发的重要一步</a></li>
<li><a href="../zh-CN450736/index.html">“与提供外部阻止相比，隔离Internet更加容易和便宜。”</a></li>
<li><a href="../zh-CN450738/index.html">数据中心的机器人：人工智能如何发挥作用？</a></li>
<li><a href="../zh-CN450740/index.html">智能灯座REDMOND-添加到智能家居</a></li>
<li><a href="../zh-CN450744/index.html">明斯克自行车基础设施，用于IT培训</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úãüèº üöµüèø üîÆ S√≠ntese de fala em rede neural usando a arquitetura Tacotron 2, ou "Fa√ßa o alinhamento ou tente morrer" üôåüèΩ ‚ÑπÔ∏è üëêüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nossa equipe recebeu a tarefa: repetir os resultados do trabalho da rede neural artificial para a s√≠ntese de fala de autoria de Tacotron2, DeepMind. E...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>S√≠ntese de fala em rede neural usando a arquitetura Tacotron 2, ou "Fa√ßa o alinhamento ou tente morrer"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/nix/blog/436312/"><img src="https://habrastorage.org/webt/yu/y0/2f/yuy02fd0i4fodpxxadfkf0k2ori.jpeg"><br><br>  Nossa equipe recebeu a tarefa: repetir os resultados do trabalho da rede neural artificial para a s√≠ntese de fala de autoria de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tacotron2,</a> DeepMind.  Esta √© uma hist√≥ria sobre o caminho espinhoso que percorremos durante a implementa√ß√£o do projeto. <br><a name="habracut"></a><br>  A tarefa da s√≠ntese da fala por computador tem sido de interesse de cientistas e especialistas t√©cnicos.  No entanto, os m√©todos cl√°ssicos n√£o permitem a s√≠ntese da fala, indistingu√≠vel da humana.  E aqui, como em muitas outras √°reas, o aprendizado profundo veio em socorro. <br><br>  Vejamos os m√©todos cl√°ssicos de s√≠ntese. <br><br><h2>  S√≠ntese Concatenativa da Fala </h2><br>  Este m√©todo baseia-se na pr√©-grava√ß√£o de pequenos fragmentos de √°udio, que s√£o combinados para criar uma fala coerente.  Ele se mostra muito limpo e claro, mas completamente desprovido de componentes emocionais e entonacionais, isto √©, soa antinatural.  E tudo porque √© imposs√≠vel obter uma grava√ß√£o em √°udio de todas as palavras poss√≠veis pronunciadas em todas as combina√ß√µes poss√≠veis de emo√ß√µes e pros√≥dia.  Os sistemas concatenativos requerem enormes bancos de dados e combina√ß√µes codificadas para formar palavras.  Desenvolver um sistema confi√°vel leva muito tempo. <br><br><h2>  S√≠ntese param√©trica da fala </h2><br>  Os aplicativos concatenacionais de TTS s√£o limitados devido a altos requisitos de dados e tempo de desenvolvimento.  Portanto, foi desenvolvido um m√©todo estat√≠stico que explora a natureza dos dados.  Ele gera fala combinando par√¢metros como frequ√™ncia, espectro de amplitude, etc. <br><br>  A s√≠ntese param√©trica consiste em duas etapas. <br><br><ol><li>  Primeiro, caracter√≠sticas ling√º√≠sticas, como fonemas, dura√ß√£o etc., s√£o extra√≠das do texto. </li><li>  Ent√£o, para o vocoder (o sistema que gera a forma de onda), s√£o extra√≠dos sinais que representam o sinal de fala correspondente: cepstrum, frequ√™ncia, espectrograma linear, espectrograma de giz. </li><li>  Esses par√¢metros configurados manualmente, juntamente com os recursos lingu√≠sticos, s√£o transferidos para o modelo do codificador de voz e ele realiza muitas transforma√ß√µes complexas para gerar uma onda sonora.  Ao mesmo tempo, o vocoder avalia par√¢metros de fala, como fase, pros√≥dia, entona√ß√£o e outros. </li></ol><br>  Se pudermos aproximar os par√¢metros que definem a fala em cada uma de suas unidades, podemos criar um modelo param√©trico.  A s√≠ntese param√©trica requer significativamente menos dados e trabalho √°rduo que os sistemas concatenativos. <br><br>  Teoricamente, tudo √© simples, mas na pr√°tica existem muitos artefatos que levam √† fala abafada com um som "zumbido", que n√£o √© de modo algum um som natural. <br><br>  O fato √© que, em cada est√°gio da s√≠ntese, codificamos alguns recursos e esperamos obter um discurso realista.  Mas os dados selecionados s√£o baseados em nossa compreens√£o da fala e o conhecimento humano n√£o √© absoluto; portanto, os sinais tomados n√£o ser√£o necessariamente a melhor solu√ß√£o poss√≠vel. <br><br>  E aqui o Deep Learning entra em cena em todo o seu esplendor. <br><br>  As redes neurais profundas s√£o uma ferramenta poderosa que, teoricamente, pode aproximar uma fun√ß√£o arbitrariamente complexa, ou seja, trazer algum espa√ßo de dados de entrada X para o espa√ßo de dados de sa√≠da Y. No contexto de nossa tarefa, ser√£o texto e √°udio com fala, respectivamente. <br><br><h2>  Pr√©-processamento de dados </h2><br>  Para come√ßar, determinaremos o que temos como entrada e o que queremos obter na sa√≠da. <br><br>  A entrada ser√° texto e a sa√≠da ser√° um espectrograma de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">giz</a> .  Esta √© uma representa√ß√£o de baixo n√≠vel obtida pela aplica√ß√£o da transforma√ß√£o r√°pida de Fourier a um sinal de √°udio discreto.  Deve-se notar imediatamente que os espectrogramas obtidos dessa maneira ainda <b>precisam ser normalizados</b> , comprimindo a faixa din√¢mica.  Isso permite reduzir a rela√ß√£o natural entre o som mais alto e o mais silencioso da grava√ß√£o.  Em nossos experimentos, o uso de espectrogramas reduzidos para o <b>intervalo [-4; 4]</b> provou ser o melhor. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/849/8fe/eb1/8498feeb1bd525506739c85bc5230c65.png"><br>  <i>Figura 1: Espectrograma de giz do sinal de √°udio da fala reduzido para o intervalo [-4; 4].</i> <br><br>  Como conjunto de dados de treinamento, escolhemos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">conjunto de dados LJSpeech</a> , que cont√©m <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">13.100</a> trilhas de √°udio por 2-10 segundos.  e um arquivo com texto correspondente √† fala em ingl√™s gravado em √°udio. <br><br>  O som usando as transforma√ß√µes acima √© codificado em espectrogramas de giz.  O texto √© tokenizado e transformado. <br><br>  em uma sequ√™ncia de n√∫meros inteiros.  Devo enfatizar imediatamente que os textos est√£o normalizados: todos os n√∫meros s√£o escritos verbalmente e poss√≠veis abrevia√ß√µes s√£o decifradas, por exemplo: ‚ÄúSra.  Robinson "-" Missis Robinson ". <br><br>  Assim, ap√≥s o pr√©-processamento, obtemos conjuntos de matrizes numpy de seq√º√™ncias num√©ricas e espectrogramas de giz gravados em arquivos npy no disco. <br><br>  Para que, na fase de treinamento, todas as dimens√µes dos tensores de corre√ß√£o coincidam, adicionaremos preenchimentos a sequ√™ncias curtas.  Para seq√º√™ncias na forma de textos, elas ser√£o reservadas para preenchimento 0 e para espectrogramas, quadros cujos valores s√£o ligeiramente inferiores aos espectrogramas m√≠nimos determinados por n√≥s.  Isso √© recomendado para isolar esses revestimentos, separando-os do ru√≠do e do sil√™ncio. <br><br>  Agora, temos dados que representam texto e √°udio adequados para processamento por uma rede neural artificial.  Vejamos a arquitetura da rede de previs√£o de recursos, que pelo nome do elemento central de todo o sistema de s√≠ntese ser√° chamada Tacotron2. <br><br><h2>  Arquitetura </h2><br>  O Tacotron 2 n√£o √© uma rede, mas duas: Rede de previs√£o de recursos e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">WaveN de voca√ß√£o</a> NN.  O artigo original, bem como nossa pr√≥pria vis√£o do trabalho realizado, permite considerar a rede de previs√£o de recursos como o primeiro violino, enquanto o vocoder WaveNet desempenha o papel de um sistema perif√©rico. <br><br>  Tacotron2 √© uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sequ√™ncia para sequenciar a</a> arquitetura.  Consiste em um <b>codificador</b> (codificador), que cria alguma id√©ia interna do sinal de entrada (tokens de s√≠mbolo) e um <b>decodificador</b> (decodificador), que transforma essa representa√ß√£o em um espectrograma de giz.  Tamb√©m um elemento extremamente importante da rede √© o chamado <b>PostNet</b> , projetado para melhorar o espectrograma gerado pelo decodificador. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/744/8c3/587/7448c35878c1640d1e156e745fa2bd96.png"><br>  <i>Figura 2: Arquitetura de rede Tacotron 2.</i> <br><br>  Vamos considerar com mais detalhes os blocos de rede e seus m√≥dulos. <br><br>  A primeira camada do <b>codificador</b> √© a camada de incorpora√ß√£o.  Com base em uma sequ√™ncia de n√∫meros naturais que representam caracteres, ele cria vetores multidimensionais (512 dimens√µes). <br><br>  Em seguida, os vetores de incorpora√ß√£o s√£o alimentados em um bloco de tr√™s camadas convolucionais unidimensionais.  Cada camada inclui 512 filtros de comprimento 5. Esse valor √© um bom tamanho de filtro nesse contexto, porque captura um determinado caractere, bem como seus dois vizinhos anteriores e dois subsequentes.  Cada camada convolucional √© seguida pela normaliza√ß√£o de mini-lote e ativa√ß√£o da ReLU. <br><br>  Os tensores obtidos ap√≥s o bloqueio convolucional s√£o aplicados √†s camadas bidirecionais de LSTM, com 256 neur√¥nios cada.  Os resultados de encaminhamento e retorno s√£o concatenados. <br><br>  <b>O decodificador</b> possui uma arquitetura recorrente, ou seja, a cada etapa subsequente, a sa√≠da da etapa anterior √© usada.  Aqui eles ser√£o um quadro do espectrograma.  Outro elemento importante, se n√£o a chave, desse sistema √© o mecanismo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aten√ß√£o</a> suave (treinada) - uma t√©cnica relativamente nova que est√° ganhando cada vez mais popularidade.  Em cada etapa do decodificador, aten√ß√£o para formar um vetor de contexto e atualizar o peso da aten√ß√£o usado: <br><br><ul><li>  a proje√ß√£o do estado oculto anterior da rede RNN do decodificador em uma camada totalmente conectada, </li><li>  proje√ß√£o da sa√≠da do codificador em uma camada totalmente conectada, </li><li>  bem como pesos de aten√ß√£o aditivos (acumulados a cada passo do decodificador). </li></ul><br>  A id√©ia de aten√ß√£o deve ser entendida da seguinte forma: ‚Äúque parte dos dados do codificador deve ser usada na etapa atual do decodificador‚Äù. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e47/f4d/410/e47f4d41040e5926c719ef909d21cc99.png"><br>  <i>Figura 3: Esquema do mecanismo de aten√ß√£o.</i> <br><br>  Em cada etapa do decodificador, o vetor de contexto <i>Ci <sub>√©</sub></i> calculado (indicado como ‚Äúsa√≠das atendidas do codificador‚Äù na figura acima), que √© o produto da sa√≠da do codificador ( <i>h</i> ) e dos pesos de aten√ß√£o ( <i>Œ±</i> ): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b27/8dc/00e/b278dc00e38919c05351ff95c03dc309.png"><br><br>  onde <i>Œ± <sub>ij</sub></i> s√£o os pesos de aten√ß√£o calculados pela f√≥rmula: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3cc/344/b9f/3cc344b9f86ba736045a83a7cae8b77e.png"><br><br>  onde <i><sub>eij</sub></i> √© a chamada ‚Äúenergia‚Äù, cuja f√≥rmula de c√°lculo depende do tipo de mecanismo de aten√ß√£o que voc√™ usa (no nosso caso, ser√° um tipo h√≠brido, usando a aten√ß√£o baseada em localiza√ß√£o e a aten√ß√£o baseada em conte√∫do).  A energia √© calculada pela f√≥rmula: <br><br>  <i>e <sub>ij</sub> = v <sub>aT</sub> tanh (Ws <sub>i-1</sub> + Vh <sub>j</sub> + Uf <sub>i, j</sub> + b)</i> <br><br>  onde: <br><ul><li>  <i>s <sub>i-1</sub></i> - estado oculto anterior da rede LSTM do decodificador, </li><li>  <i>Œ± <sub>i-1</sub></i> - pesos de aten√ß√£o anteriores, </li><li>  <i>h <sub>j</sub></i> √© o j-√©simo estado oculto do codificador, </li><li>  <i>W</i> , <i>V</i> , <i>U</i> , <i>va</i> e <i>b</i> s√£o par√¢metros de treinamento, </li><li>  <i>f <sub>i, j</sub></i> - sinais de localiza√ß√£o calculados pela f√≥rmula: <br><br>  <i>f <sub>i</sub> = F * Œ± <sub>i-1</sub></i> <br><br>  onde <i>F</i> √© a opera√ß√£o de convolu√ß√£o. </li></ul><br><br>  Para uma compreens√£o clara do que est√° acontecendo, acrescentamos que alguns dos m√≥dulos descritos abaixo assumem o uso de informa√ß√µes da etapa anterior do decodificador.  Mas se esse for o primeiro passo, as informa√ß√µes ser√£o tensores de valores zero, o que √© uma pr√°tica comum ao criar estruturas de recorr√™ncia. <br><br>  Agora considere <b>o algoritmo de opera√ß√£o</b> . <br><br>  Primeiro, a sa√≠da do decodificador da etapa anterior √© alimentada em um pequeno m√≥dulo PreNet, que √© uma pilha de duas camadas totalmente conectadas de 256 neur√¥nios, alternando com as camadas de abandono com uma taxa de 0,5.  Uma caracter√≠stica distinta deste m√≥dulo √© que o dropout √© usado nele n√£o apenas no est√°gio de treinamento do modelo, mas tamb√©m no est√°gio de sa√≠da. <br><br>  A sa√≠da PreNet em concatena√ß√£o com o vetor de contexto obtido como resultado do mecanismo de aten√ß√£o √© alimentada √† entrada em uma rede LSTM unidirecional de duas camadas, com 1024 neur√¥nios em cada camada. <br><br>  Em seguida, a concatena√ß√£o da sa√≠da das camadas LSTM com o mesmo vetor de contexto (e possivelmente diferente) √© alimentada em uma camada totalmente conectada com 80 neur√¥nios, o que corresponde ao n√∫mero de canais do espectrograma.  Essa camada final do decodificador forma o espectrograma previsto quadro a quadro.  E sua sa√≠da j√° √© fornecida como entrada para a pr√≥xima etapa do decodificador na PreNet. <br><br>  Por que mencionamos no par√°grafo anterior que o vetor de contexto j√° pode ser diferente?  Uma das abordagens poss√≠veis √© recalcular o vetor de contexto depois que o estado latente da rede LSTM for obtido nesta etapa.  No entanto, em nossos experimentos, essa abordagem n√£o se justifica. <br><br>  Al√©m da proje√ß√£o em uma camada totalmente conectada de 80 neur√¥nios, a concatena√ß√£o da sa√≠da das camadas LSTM com um vetor de contexto √© alimentada em uma camada totalmente conectada com um neur√¥nio, seguida pela ativa√ß√£o sigm√≥ide - esta √© uma camada de "previs√£o de token de parada".  Ele prev√™ a probabilidade de que o quadro criado nesta etapa do decodificador seja final.  Essa camada foi projetada para gerar um espectrograma de comprimento n√£o fixo, mas arbitr√°rio, no est√°gio de sa√≠da do modelo.  Ou seja, no est√°gio de sa√≠da, esse elemento determina o n√∫mero de etapas do decodificador.  Pode ser considerado como um classificador bin√°rio. <br><br>  A sa√≠da do decodificador de todas as suas etapas ser√° o espectrograma previsto.  No entanto, isso n√£o √© tudo.  Para melhorar a qualidade do espectrograma, ele √© passado atrav√©s do m√≥dulo PostNet, que √© uma pilha de cinco camadas convolucionais unidimensionais com 512 filtros em cada um e com um tamanho de filtro de 5. A normaliza√ß√£o do lote e a ativa√ß√£o da tangente seguem cada camada (exceto a √∫ltima).  Para retornar √† dimens√£o do espectrograma, passamos os dados de sa√≠da p√≥s-rede por uma camada totalmente conectada com 80 neur√¥nios e adicionamos os dados recebidos com o resultado inicial do decodificador.  Obtemos o espectrograma de giz gerado a partir do texto.  Lucro <br><br>  Todos os m√≥dulos convolucionais s√£o regularizados com camadas de abandono com uma taxa de 0,5 e camadas de recorr√™ncia com o m√©todo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Zoneout</a> mais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">recente</a> com uma taxa de 0,1.  √â bem simples: em vez de aplicar o estado latente e o estado da c√©lula obtidos na etapa atual √† pr√≥xima etapa da rede LSTM, substitu√≠mos parte dos dados pelos valores da etapa anterior.  Isso √© feito tanto na fase de treinamento quanto na de retirada.  Nesse caso, apenas o estado oculto (que √© passado para a pr√≥xima etapa do LSTM) √© exposto ao m√©todo Zoneout a cada etapa, enquanto a sa√≠da da c√©lula LSTM na etapa atual permanece inalterada. <br><br>  Escolhemos o PyTorch como a estrutura de aprendizado profundo.  Embora no momento da implementa√ß√£o da rede ela estivesse em um estado de pr√©-lan√ßamento, ela j√° era uma ferramenta muito poderosa para construir e treinar redes neurais artificiais.  Em nosso trabalho, usamos outras estruturas, como TensorFlow e Keras.  No entanto, o √∫ltimo foi descartado devido √† necessidade de implementar estruturas personalizadas n√£o-padr√£o e, se compararmos o TensorFlow e o PyTorch, ao usar o segundo, n√£o h√° sensa√ß√£o de que o modelo foi retirado da linguagem Python.  No entanto, n√£o nos comprometemos a afirmar que um deles √© melhor e o outro pior.  O uso de uma estrutura espec√≠fica pode depender de v√°rios fatores. <br><br>  A rede √© treinada pelo m√©todo de retropropaga√ß√£o.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O ADAM √©</a> usado como um otimizador, o erro m√©dio quadr√°tico antes e depois do PostNet, bem como a entropia cruzada bin√°ria acima dos valores reais e previstos da camada Previs√£o de parada de token, s√£o usados ‚Äã‚Äãcomo fun√ß√µes de erro.  O erro resultante √© uma soma simples desses tr√™s. <br><br>  O modelo foi treinado em uma √∫nica GPU GeForce 1080Ti com 11 GB de mem√≥ria. <br><br><h2>  Visualiza√ß√£o </h2><br>  Ao trabalhar com um modelo t√£o grande, √© importante ver como vai o processo de aprendizado.  E aqui o TensorBoard se tornou uma ferramenta conveniente.  Rastreamos o valor do erro nas itera√ß√µes de treinamento e valida√ß√£o.  Al√©m disso, exibimos espectrogramas alvo, espectrogramas previstos no est√°gio de treinamento, espectrogramas previstos no est√°gio de valida√ß√£o e alinhamento, que √© um peso acumulado de aten√ß√£o acumulado em todas as etapas do treinamento. <br><br>  √â poss√≠vel que, a princ√≠pio, sua aten√ß√£o n√£o seja muito informativa: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4ce/600/7be/4ce6007bef5b7fe17aa8df56472904bc.png"><br>  <i>Figura 4: Um exemplo de escalas de aten√ß√£o mal treinadas.</i> <br><br>  Mas depois que todos os seus m√≥dulos come√ßarem a funcionar como um rel√≥gio su√≠√ßo, voc√™ finalmente ter√° algo como: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/8e7/5d9/ff0/8e75d9ff0e0da78915c1a16f623a99e8.png"><br>  <i>Figura 5: Exemplo de escalas de aten√ß√£o treinadas com sucesso.</i> <br><br>  O que esse gr√°fico significa?  Em cada etapa do decodificador, tentamos decodificar um quadro do espectrograma.  No entanto, n√£o est√° claro quais informa√ß√µes o codificador precisa usar em cada etapa do decodificador.  Pode-se supor que essa correspond√™ncia ser√° direta.  Por exemplo, se tivermos uma sequ√™ncia de texto de entrada de 200 caracteres e um espectrograma correspondente de 800 quadros, haver√° 4 quadros para cada caractere.  No entanto, voc√™ deve admitir que a fala gerada com base nesse espectrograma seria completamente desprovida de naturalidade.  Pronunciamos algumas palavras mais r√°pidas, outras mais lentas, em algum lugar que pausamos, mas em algum lugar que n√£o fazemos.  E considere que todos os contextos poss√≠veis n√£o s√£o poss√≠veis.  √â por isso que a aten√ß√£o √© um elemento-chave de todo o sistema: define a correspond√™ncia entre a etapa do decodificador e as informa√ß√µes do codificador para obter as informa√ß√µes necess√°rias para gerar um quadro espec√≠fico.  E quanto maior o valor dos pesos de aten√ß√£o, mais "aten√ß√£o deve ser prestada" √† parte correspondente dos dados do codificador ao gerar o quadro do espectrograma. <br><br>  Na fase de treinamento, tamb√©m ser√° √∫til gerar √°udio, e n√£o apenas avaliar visualmente a qualidade dos espectrogramas e da aten√ß√£o.  No entanto, aqueles que trabalharam com o WaveNet concordam que us√°-lo como vocoder na fase de treinamento seria um luxo inaceit√°vel em termos de tempo.  Portanto, √© recomend√°vel usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o algoritmo Griffin-Lim</a> , que permite a reconstru√ß√£o parcial do sinal ap√≥s transforma√ß√µes r√°pidas de Fourier.  Por que parcialmente?  O fato √© que, quando convertemos o sinal em espectrogramas, perdemos informa√ß√µes de fase.  No entanto, a qualidade do √°udio assim obtido ser√° suficiente para entender em que dire√ß√£o voc√™ est√° se movendo. <br><br><h2>  Li√ß√µes aprendidas </h2><br>  Aqui, compartilharemos algumas id√©ias sobre a constru√ß√£o do processo de desenvolvimento, enviando-as no formato de dicas.  Alguns deles s√£o bastante gerais, outros s√£o mais espec√≠ficos. <br><br>  <b>Sobre a organiza√ß√£o do fluxo de trabalho</b> : <br><br><ul><li>  Use o sistema de controle de vers√£o, descreva de forma clara e clara todas as altera√ß√µes.  Isso pode parecer uma recomenda√ß√£o √≥bvia, mas ainda assim.  Ao procurar a arquitetura ideal, ocorrem mudan√ßas constantemente.  E, tendo recebido algum resultado intermedi√°rio satisfat√≥rio, certifique-se de fazer um ponto de verifica√ß√£o para poder fazer as altera√ß√µes subseq√ºentes com seguran√ßa. <br></li><li>  Do nosso ponto de vista, nessas arquiteturas deve-se aderir aos princ√≠pios do encapsulamento: uma classe - um m√≥dulo Python.  Essa abordagem n√£o √© comum nas tarefas de ML, mas ajuda a estruturar seu c√≥digo e a acelerar a depura√ß√£o e o desenvolvimento.  No c√≥digo e na sua vis√£o da arquitetura, divida-o em blocos, blocos em m√≥dulos e m√≥dulos em camadas.  Se o m√≥dulo tiver um c√≥digo que desempenhe uma fun√ß√£o espec√≠fica, combine-o em um m√©todo de classe do m√≥dulo.  Essas s√£o verdades comuns, mas n√£o tivemos pregui√ßa de falar sobre elas novamente. <br></li><li>  Forne√ßa classes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estilo numpy</a> com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> .  Isso simplificar√° bastante o trabalho para voc√™ e seus colegas que ler√£o seu c√≥digo. <br></li><li>  Sempre desenhe a arquitetura do seu modelo.  Primeiro, ele ajudar√° voc√™ a entender o sentido e, em segundo lugar, uma vis√£o lateral da arquitetura e dos hiperpar√¢metros do modelo permitir√° identificar rapidamente imprecis√µes em sua abordagem. <br></li><li>  Melhor trabalhar em equipe.  Se voc√™ trabalha sozinho, ainda re√∫na colegas e discuta seu trabalho.  No m√≠nimo, eles podem fazer uma pergunta que o levar√° a algumas reflex√µes, mas, no m√°ximo, apontar√£o para uma imprecis√£o espec√≠fica que n√£o permite que voc√™ treine o modelo com sucesso. <br></li><li>  Outro truque √∫til j√° est√° associado ao pr√©-processamento de dados.  Suponha que voc√™ decida testar algumas hip√≥teses e fazer as altera√ß√µes apropriadas no modelo.  Mas reiniciar o treinamento, especialmente antes do fim de semana, ser√° arriscado.  A abordagem pode estar errada inicialmente e voc√™ perder√° tempo.  O que fazer ent√£o?  Aumente o tamanho da janela de transforma√ß√£o r√°pida de Fourier.  O par√¢metro padr√£o √© 1024;  aument√°-lo em 4, ou at√© 8 vezes.  Isso "comprime" os espectrogramas no n√∫mero apropriado de vezes e acelera bastante o aprendizado.  O √°udio recuperado deles ter√° uma qualidade inferior, mas essa n√£o √© sua tarefa agora?  Em 2 a 3 horas, voc√™ j√° pode obter o alinhamento (‚Äúalinhamento‚Äù das escalas de aten√ß√£o, como mostrado na figura acima), isso atesta a corre√ß√£o arquitet√¥nica da abordagem e j√° pode ser testado em big data. <br></li></ul><br>  <b>Modelos de constru√ß√£o e treinamento</b> : <br><br><ul><li>  Nossa hip√≥tese foi que, se os lotes n√£o fossem formados aleatoriamente, mas com base em seu comprimento, eles acelerariam o processo de treinamento do modelo e melhorariam os espectrogramas gerados.  A suposi√ß√£o l√≥gica, baseada na hip√≥tese de que quanto mais um sinal √∫til (e n√£o preenchimento) for fornecido √† rede de treinamento, melhor.  No entanto, essa abordagem n√£o se justificou; em nossos experimentos, n√£o fomos capazes de treinar a rede dessa maneira.  Provavelmente, isso se deve √† perda de aleatoriedade na sele√ß√£o de inst√¢ncias para treinamento. <br></li><li>  Use algoritmos modernos de inicializa√ß√£o de par√¢metros de rede com alguns estados iniciais otimizados.  Por exemplo, em nossos experimentos, usamos a Inicializa√ß√£o Uniforme de Peso Xavier.  Se no seu m√≥dulo voc√™ precisar usar a normaliza√ß√£o por mini-lote e alguma fun√ß√£o de ativa√ß√£o, eles dever√£o alternar entre si nessa ordem.  De fato, se aplicarmos, por exemplo, a ativa√ß√£o de ReLU, perderemos imediatamente todo o sinal negativo que deveria estar envolvido no processo de normaliza√ß√£o dos dados de um lote espec√≠fico. <br></li><li>  Em uma etapa espec√≠fica de aprendizado, use uma taxa de aprendizado din√¢mico.  Isso realmente ajuda a reduzir o valor do erro e aumentar a qualidade dos espectrogramas gerados. <br></li><li>  Ap√≥s criar o modelo e tentativas malsucedidas de trein√°-lo em lotes de todo o conjunto de dados, ser√° √∫til tentar trein√°-lo novamente em um lote.    ,   alignment,           (    ).  ,      ,      . <br><br>    .        .  ,        ‚Äì      .    ,            .       ,       . </li><li>    RNN-              .      . ,           .        ?             LSTM-     -. <br></li><li>       ,   LSTM-,      ¬´ ¬ª: ¬´ <i>       ,         LSTM-.      ¬´¬ª  bf.   ,        ,    ,   LSTM-     ft  1/2.   ,        :    ,        ¬´¬ª  1/2,         .    bf    ,  1   2:     ft                 </i> ¬ª. <br></li><li>   seq2seq-         .       ‚Äî       ,         .           ?           ,        ( ). <br></li><li> Agora, uma recomenda√ß√£o espec√≠fica para a estrutura do PyTorch.  Embora a camada LSTM no decodificador seja essencialmente sua pr√≥pria c√©lula LSTM, que recebe informa√ß√µes para apenas um elemento da sequ√™ncia em cada etapa do decodificador, √© recomend√°vel usar a classe <code>torch.nn.LSTM</code> vez de <code>torch.nn.LSTMCell</code> .  O motivo √© que o back-end LSTM √© implementado na biblioteca CUDNN em C e o LSTMCell em Python.  Este truque permitir√° aumentar significativamente a velocidade do sistema. </li></ul><br>  E no final do artigo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">compartilharemos exemplos de gera√ß√£o de fala a partir de textos que n√£o estavam contidos no conjunto de treinamento.</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt436312/">https://habr.com/ru/post/pt436312/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt436302/index.html">Experi√™ncia de substitui√ß√£o de importa√ß√£o real usando o sistema de armazenamento russo AERODISK</a></li>
<li><a href="../pt436304/index.html">Zimbra Collaboration Suite e a luta contra o phishing</a></li>
<li><a href="../pt436306/index.html">Machine Learning para Vertica</a></li>
<li><a href="../pt436308/index.html">Rostelecom pode se tornar um monopolista no mercado de data centers</a></li>
<li><a href="../pt436310/index.html">Como as m√©tricas de Ivan, o DevOps fez. Objeto de influ√™ncia</a></li>
<li><a href="../pt436314/index.html">Hotel-rob√¥ japon√™s "disparou" metade de seus rob√¥s devido aos problemas que eles criam</a></li>
<li><a href="../pt436316/index.html">Como os cart√µes inteligentes ajudam a impulsionar projetos de TI</a></li>
<li><a href="../pt436318/index.html">Novos Recursos de Automa√ß√£o de Rede no Red Hat Ansible</a></li>
<li><a href="../pt436320/index.html">Muitas propriedades ou objeto de propriedade: crit√©rios de sele√ß√£o</a></li>
<li><a href="../pt436322/index.html">@Pythonetc dezembro de 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
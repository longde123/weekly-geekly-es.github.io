<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§ë üë∏üèº üôÅ C√≥mo superamos la incompatibilidad al migrar datos de Greenplum 4 a Greenplum 5 ‚úùÔ∏è üîü üë≤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cuando elegimos una herramienta para procesar big data, consideramos diferentes opciones, tanto propietarias como de c√≥digo abierto. Evaluamos las pos...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo superamos la incompatibilidad al migrar datos de Greenplum 4 a Greenplum 5</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/439876/">  Cuando elegimos una herramienta para procesar big data, consideramos diferentes opciones, tanto propietarias como de c√≥digo abierto.  Evaluamos las posibilidades de adaptaci√≥n r√°pida, accesibilidad y flexibilidad de las tecnolog√≠as.  Incluyendo migraci√≥n entre versiones.  Como resultado, elegimos la soluci√≥n de c√≥digo abierto Greenplum, que mejor cumpl√≠a con nuestros requisitos, pero requer√≠a la soluci√≥n de un problema importante. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ff/69c/0d9/9ff69c0d9031f0afb897244dd0778e9e.png"><br><br>  El hecho es que las versiones 4 y 5 de los archivos de la base de datos Greenplum no son compatibles entre s√≠ y, por lo tanto, es imposible una simple actualizaci√≥n de una versi√≥n a otra.  La migraci√≥n de datos solo se puede realizar cargando y descargando datos.  En esta publicaci√≥n hablar√© sobre las posibles opciones para esta migraci√≥n. <br><a name="habracut"></a><br><h2>  Evaluar las opciones de migraci√≥n </h2><br><h3>  pg_dump y psql (o pg_restore) </h3><br>  Esto es demasiado lento cuando se trata de docenas de terabytes, ya que todos los datos se cargan y descargan a trav√©s de los nodos maestros.  Pero lo suficientemente r√°pido como para migrar DDL y tablas peque√±as.  Puede cargar ambos en un archivo y ejecutar pg_dump y psql al mismo tiempo a trav√©s de una tuber√≠a en un cl√∫ster de origen y un cl√∫ster de destino.  pg_dump simplemente carga en un solo archivo que contiene comandos DDL y comandos de datos COPY.  Los datos obtenidos se pueden procesar convenientemente, lo que se mostrar√° a continuaci√≥n. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/482/f47/cd8/482f47cd86df49125689c5360b6d060e.png"><br><br><h3>  gptransfer </h3><br>  Requiere la versi√≥n Greenplum 4.2 o posterior.  Es necesario que tanto el cl√∫ster de origen como el cl√∫ster de destino trabajen simult√°neamente.  La forma m√°s r√°pida de migrar tablas de datos grandes para la versi√≥n de c√≥digo abierto.  Pero este m√©todo es muy lento para transferir tablas vac√≠as y peque√±as debido a la alta sobrecarga. <br><br>  gptransfer usa pg_dump para transferir DDL y gpfdist para transferir datos.  El n√∫mero de segmentos primarios en el cl√∫ster de destino no debe ser menor que el segmento de host en el cl√∫ster de origen.  Esto es importante a tener en cuenta al crear cl√∫steres de "caja de arena", si los datos de los cl√∫steres principales se transferir√°n a ellos, y se planea el uso de la utilidad gptransfer.  Incluso si los hosts de segmento son pocos, puede implementar el n√∫mero requerido de segmentos en cada uno de ellos.  El n√∫mero de segmentos en el cl√∫ster de destino puede ser menor que en el cl√∫ster de origen, sin embargo, esto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">afectar√° negativamente</a> la velocidad de transferencia de datos.  Entre los cl√∫steres, se debe configurar la autenticaci√≥n ssh en los certificados. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/84b/a0a/f53/84ba0af53e82d2a4e861fe19c6f9be9a.png"><br><br>  Este es el esquema para el modo r√°pido cuando el n√∫mero de segmentos en el cl√∫ster de destino es mayor o igual que el n√∫mero en el cl√∫ster de origen.  El lanzamiento de la utilidad en s√≠ se muestra en el diagrama en el nodo maestro del cl√∫ster receptor.  En este modo, se crea una tabla de escritura externa en el cl√∫ster de origen, que escribe datos en cada segmento en la tuber√≠a con nombre.  Se ejecuta el comando INSERT INTO en writable_external_table SELECT * FROM source_table.  Gpfdist lee los datos de la canalizaci√≥n con nombre.  Tambi√©n se crea una tabla externa en el cl√∫ster de destino, solo para lectura.  La tabla indica los datos que proporciona gpfdist sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el protocolo del mismo nombre</a> .  Se ejecuta el comando INSERT INTO target_table SELECT * FROM external_gpfdist_table.  Los datos se redistribuyen autom√°ticamente entre segmentos del cl√∫ster de destino. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/13f/b61/cfb/13fb61cfba946fbea0649c1df1cbf28c.png"><br><br>  Y este es el esquema para el modo lento o, como dice gptransfer, el modo est√°ndar.  La principal diferencia es que en cada segmento-host del cl√∫ster de origen, se lanza un par gpfdist para todos los segmentos de este segmento-host.  Una tabla de registro externa se refiere a gpfdist que act√∫a como receptor de datos.  Adem√°s, si se indican varios valores para escribir en el par√°metro LOCATION de la tabla externa, gpfdist distribuye los segmentos de manera uniforme al escribir datos.  Los datos entre gpfdist en el segmento host se pasan a trav√©s de una canalizaci√≥n con nombre.  Debido a esto, la velocidad de transferencia de datos es menor, pero a√∫n resulta m√°s r√°pida que cuando se transfieren datos solo a trav√©s del nodo maestro. <br><br>  Al migrar datos de Greenplum 4 a Greenplum 5, gptransfer debe ejecutarse en el nodo maestro del cl√∫ster de destino.  Si ejecutamos gptransfer en el cl√∫ster de origen, obtenemos el error de la ausencia del campo <code>san_mounts</code> en la tabla <code>pg_catalog.gp_segment_configuration</code> : <br><br><pre> <code class="plaintext hljs">gptransfer -t big_db.public.test_table --dest-host=gpdb-target-master.local --dest-database=big_db --source-map-file=/data/master/gpseg-1/host_and_IP_segments --batch-size=10 --sub-batch-size=50 --truncate 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Starting gptransfer with args: -t big_db.public.test_table --dest-host=gpdb-target-master.local --dest-database=big_db --source-map-file=/data/master/gpseg-1/host_and_IP_segments --batch-size=10 --sub-batch-size=50 --truncate 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Validating options... 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Retrieving configuration of source Greenplum Database... 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Retrieving configuration of destination Greenplum Database... 20190109:12:46:14:010893 gptransfer:gpdb-source-master.local:gpadmin-[CRITICAL]:-gptransfer failed. (Reason='error 'ERROR: column "san_mounts" does not exist LINE 2: ... SELECT dbid, content, status, unnest(san_mounts... ^ ' in ' SELECT dbid, content, status, unnest(san_mounts) FROM pg_catalog.gp_segment_configuration WHERE content &gt;= 0 ORDER BY content, dbid '') exiting...</code> </pre> <br>  Tambi√©n debe verificar las variables GPHOME para que coincidan entre el cl√∫ster de origen y el cl√∫ster de destino.  De lo contrario, obtenemos un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">error</a> bastante extra√±o (la utilidad gptransfer falla cuando el origen y el destino tienen una ruta GPHOME diferente). <br><br><pre> <code class="plaintext hljs">gptransfer -t big_db.public.test_table --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments --b atch-size=10 --sub-batch-size=50 --truncate 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[INFO]:-Starting gptransfer with args: -t big_db.public.test_table --source-host=gpdb-spurce-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments --b atch-size=10 --sub-batch-size=50 --truncate 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[INFO]:-Validating options... 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[ERROR]:-gptransfer: error: GPHOME directory does not exist on gpdb-source-master.local</code> </pre> <br>  Simplemente puede crear el enlace simb√≥lico correspondiente y anular la variable GPHOME en la sesi√≥n en la que se inicia gptransfer. <br><br>  Cuando se inicia gptransfer en el cl√∫ster de destino, la opci√≥n "--source-map-file" debe apuntar a un archivo que contenga una lista de hosts y sus direcciones IP con segmentos primarios del cl√∫ster de origen.  Por ejemplo: <br><br><pre> <code class="plaintext hljs">sdw1,192.0.2.1 sdw2,192.0.2.2 sdw3,192.0.2.3 sdw4,192.0.2.4</code> </pre> <br>  Con la opci√≥n "--full" es posible transferir no solo tablas, sino toda la base de datos, sin embargo, las bases de datos de usuarios no deben crearse en el cl√∫ster de destino.  Tambi√©n debe recordar que hay problemas debido a los cambios de sintaxis al mover tablas externas. <br><br>  Evaluemos la sobrecarga adicional, por ejemplo, copiando 10 tablas vac√≠as (tablas de big_db.public.test_table_2 a big_db.public.test_table_11) usando gptarnsfer: <br><br><pre> <code class="plaintext hljs">gptransfer -f temp_filelist.txt --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments_dev --batch-size=10 --sub-ba tch-size=50 --truncate 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Starting gptransfer with args: -f temp_filelist.txt --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments_dev --batch-size=10 --sub-batch-size=50 --truncate 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating options... 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving configuration of source Greenplum Database... 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving configuration of destination Greenplum Database... 20190118:06:14:09:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving source tables... 20190118:06:14:12:031521 gptransfer:mdw:gpadmin-[INFO]:-Checking for gptransfer schemas... 20190118:06:14:22:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving list of destination tables... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Reading source host map file... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Building list of source tables to transfer... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Number of tables to transfer: 10 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-gptransfer will use "standard" mode for transfer. 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating source host map... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating transfer table set... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-The following tables on the destination system will be truncated: 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_2 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_3 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_4 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_5 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_6 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_7 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_8 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_9 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_10 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_11 ‚Ä¶ 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Using batch size of 10 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Using sub-batch size of 16 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Creating work directory '/home/gpadmin/gptransfer_31521' 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Creating schema public in database edw_prod... 20190118:06:14:40:031521 gptransfer:mdw:gpadmin-[INFO]:-Starting transfer of big_db.public.test_table_5 to big_db.public.test_table_5... ‚Ä¶ 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Validation of big_db.public.test_table_4 successful 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Removing work directories... 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Finished.</code> </pre> <br>  Como resultado, la transferencia de 10 tablas vac√≠as tom√≥ aproximadamente 16 segundos (14: 40-15: 02), es decir, una tabla - 1.6 segundos.  Durante este tiempo, en nuestro caso, se pueden descargar aproximadamente 100 MB de datos usando pg_dump y psql. <br><br><h3>  gp_dump &amp; gp_restore </h3><br>  Como opci√≥n: use complementos sobre ellos, gpcrondump y gpdbrestore, ya que gp_dump y gp_restore se declaran obsoletos.  Aunque gpcrondump y gpdbrestore mismos usan gp_dump y gp_restore en el proceso.  Esta es la forma m√°s universal, pero no la m√°s r√°pida.  Los archivos de copia de seguridad creados con gp_dump representan un conjunto de comandos DDL en el nodo maestro y en los segmentos primarios, principalmente conjuntos de comandos y datos COPY.  Adecuado para casos en los que no es posible proporcionar una operaci√≥n simult√°nea del cl√∫ster de destino y el cl√∫ster de origen.  Hay versiones anteriores de Greenplum y nuevas: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gp_dump</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">gp_restore</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/141/1b7/8e8/1411b78e893176ef21de383e78c0b87f.png"><br><br><h3>  Utilidades gpbackup y gprestore </h3><br>  Creado como un reemplazo para gp_dump y gp_restore.  Para su trabajo, se requiere la versi√≥n m√≠nima 4.3.17 de Greenplum ( <a href="">const MINIMUM_GPDB4_VERSION = "4.3.17"</a> ).  El esquema de trabajo es similar a gpbackup &amp; gprestore, mientras que la velocidad de trabajo es mucho m√°s r√°pida.  La forma m√°s r√°pida de obtener comandos DDL para grandes bases de datos.  Por defecto, transfiere objetos globales, para la recuperaci√≥n necesita especificar "gprestore --with-globals".  El par√°metro opcional "--jobs" puede establecer el n√∫mero de trabajos (y sesiones en la base de datos) al crear una copia de seguridad.  Debido al hecho de que se crean varias sesiones, es importante garantizar la coherencia de los datos hasta que se reciban todos los bloqueos.  Tambi√©n hay una opci√≥n √∫til "--with-stats", que le permite transferir estad√≠sticas sobre objetos utilizados para construir planes de ejecuci√≥n.  M√°s informaci√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br><h3>  Utilidad gpcopy </h3><br>  Para copiar bases de datos hay una utilidad gpcopy, un reemplazo para gptansfer.  Pero se incluye solo en la versi√≥n patentada de Greenplum de Pivotal, a partir de 4.3.26; en la versi√≥n de c√≥digo abierto, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esta utilidad no</a> .  Mientras trabaja en el cl√∫ster de origen, se ejecuta el comando COPY source_table TO PROGRAM 'gpcopy_helper ...' ON SEGMENT CSV IGNORE EXTERNAL PARTITIONS.  En el lado del cl√∫ster receptor, se crea una tabla externa temporal CREAR TABLA DE TEMPERATURA WEB EXTERNA external_temp_table (LIKE target_table) EXECUTE '... gpcopy_helper ‚Äìlisten ...' y se ejecuta el comando INSERT INTO target_table SELECT * FROM external_temp_table.  Como resultado, gpcopy_helper con el par√°metro ‚Äìlisten se inicia en cada segmento del cl√∫ster de destino, que recibe datos de gpcopy_helper de segmentos del cl√∫ster de origen.  Debido a este esquema de transmisi√≥n de datos, as√≠ como a la compresi√≥n, la velocidad de transmisi√≥n es mucho mayor.  Entre los cl√∫steres, la autenticaci√≥n ssh en los certificados tambi√©n debe configurarse.  Tambi√©n quiero se√±alar que gpcopy tiene una opci√≥n conveniente "--truncate-source-after" (y "--validate") para los casos en que los cl√∫steres de origen y destino se encuentran en los mismos servidores. <br><br><h2>  Estrategia de transferencia de datos </h2><br>  Para determinar la estrategia de transferencia, necesitamos determinar qu√© es m√°s importante para nosotros: transferir datos r√°pidamente, pero con m√°s trabajo y posiblemente menos confiable (gpbackup, gptransfer o una combinaci√≥n de los mismos) o con menos trabajo, pero m√°s lento (gpbackup o gptransfer sin combinar). <br><br>  La forma m√°s r√°pida de transferir datos, cuando hay un cl√∫ster de origen y un cl√∫ster de destino, es la siguiente: <br><br><ul><li>  Obtenga DDL usando gpbackup --metadata-only, convierta y cargue a trav√©s de la tuber√≠a usando psql <br></li><li>  Eliminar √≠ndices <br></li><li>  Transfiera tablas con un tama√±o de 100 MB o m√°s utilizando gptransfer <br></li><li>  Transfiera tablas con un tama√±o de menos de 100 MB utilizando pg_dump |  psql como en el primer p√°rrafo <br></li><li>  Crear de nuevo √≠ndices eliminados <br></li></ul><br>  Este m√©todo result√≥ estar en nuestras mediciones al menos 2 veces m√°s r√°pido que gp_dump y gp_restore.  M√©todos alternativos: transferir todas las bases de datos usando gptransfer ‚Äìfull, gpbackup &amp; gprestore, o gp_dump &amp; gp_restore. <br><br>  Los tama√±os de tabla se pueden obtener mediante la siguiente consulta: <br><br><pre> <code class="plaintext hljs">SELECT nspname AS "schema", coalesce(tablename, relname) AS "name", SUM(pg_total_relation_size(class.oid)) AS "size" FROM pg_class class JOIN pg_namespace namespace ON namespace.oid = class.relnamespace LEFT JOIN pg_partitions parts ON class.relname = parts.partitiontablename AND namespace.nspname = parts.schemaname WHERE nspname NOT IN ('pg_catalog', 'information_schema', 'pg_toast', 'pg_bitmapindex', 'pg_aoseg', 'gp_toolkit') GROUP BY nspname, relkind, coalesce(tablename, relname), pg_get_userbyid(class.relowner) ORDER BY 1,2;</code> </pre><br><br><h3>  Conversiones necesarias </h3><br>  Los archivos de copia de seguridad en Greenplum versiones 4 y 5 tampoco son totalmente compatibles.  Entonces, en Greenplum 5, debido a un cambio en la sintaxis, los comandos CREATE EXTERNAL TABLE y COPY no tienen el par√°metro INTO ERROR TABLE, y debe establecer el par√°metro SET gp_ignore_error_table en true para que la restauraci√≥n de la copia de seguridad no falle por error.  Con el conjunto de par√°metros, solo recibimos una advertencia. <br><br>  Adem√°s, la quinta versi√≥n introdujo un protocolo diferente para interactuar con tablas pxf externas, y para usarlo, debe cambiar el par√°metro LOCATION, as√≠ como configurar el servicio pxf. <br>  Tambi√©n vale la pena se√±alar que en los archivos de copia de seguridad gp_dump y gp_restore tanto en el nodo maestro como en cada segmento primario, el par√°metro SET gp_strict_xml_parse se establece en falso.  No existe dicho par√°metro en Greenplum 5 y, como resultado, recibimos un mensaje de error. <br><br>  Si el protocolo gphdfs se us√≥ para tablas externas, debe verificar la lista de origen en los archivos de respaldo en el par√°metro LOCATION para tablas externas mediante la l√≠nea 'gphdfs: //'.  Por ejemplo, solo deber√≠a haber 'gphdfs: //hadoop.local: 8020'.  Si hay otras l√≠neas, deben agregarse al script de reemplazo en el nodo maestro por analog√≠a. <br><br><pre> <code class="plaintext hljs">grep -o gphdfs\:\/\/.*\/ /data1/master/gpseg-1/db_dumps/20181206/gp_dump_-1_1_20181206122002.gz | cut -d/ -f1-3 | sort | uniq gphdfs://hadoop.local:8020</code> </pre> <br>  Hacemos reemplazos en el nodo maestro (usando el archivo de datos gp_dump como ejemplo): <br><br><pre> <code class="plaintext hljs">mv /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.gz /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.old.gz gunzip -c /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.old.gz | sed "s#'gphdfs://hadoop.local:8020#'pxf:/#g" | sed "s/\(^.*pxf\:\/\/.*'\)/\1\\&amp;\&amp;\?PROFILE=HdfsTextSimple'/" |sed "s#'&amp;#g" | sed 's/SET gp_strict_xml_parse = false;/SET gp_ignore_error_table = true;/g' | gzip -1 &gt; /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.gz nets</code> </pre> <br>  En versiones recientes, el nombre del perfil HdfsTextSimple se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">declara obsoleto</a> , el nuevo nombre es hdfs: text. <br><br><h2>  Resumen </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La conversi√≥n impl√≠cita de texto</a> , el nuevo mecanismo de gesti√≥n de recursos del cl√∫ster de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">grupos de</a> recursos, que reemplaza las colas de recursos, el optimizador <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">GPORCA</a> , que se incluye por defecto en Greenplum 5, los problemas menores con los clientes quedaron fuera del alcance del art√≠culo. <br><br>  Espero con ansias el lanzamiento de la sexta versi√≥n de Greenplum, que est√° programada para la primavera de 2019: nivel de compatibilidad con PostgreSQL 9.4, B√∫squeda de texto completo, Soporte de √≠ndice GIN, Tipos de rango, JSONB, Compresi√≥n zStd.  Adem√°s, se conocieron los planes preliminares para Greenplum 7: nivel de compatibilidad con PostgreSQL m√≠nimo 9.6, seguridad de nivel de fila, conmutaci√≥n por error maestra automatizada.  Los desarrolladores tambi√©n prometen la disponibilidad de utilidades de actualizaci√≥n de bases de datos para actualizar entre versiones principales, por lo que ser√° m√°s f√°cil vivir. <br><br>  <i>Este art√≠culo fue preparado por el equipo de gesti√≥n de datos de Rostelecom</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439876/">https://habr.com/ru/post/439876/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439864/index.html">Gesti√≥n del conocimiento, por qu√© y c√≥mo lo hicimos.</a></li>
<li><a href="../439866/index.html">Los principios de dise√±o de directorios de nomenclatura en 1C Enterprise Management 2 (ERP 2.4.6)</a></li>
<li><a href="../439868/index.html">La vida sin Facebook: opiniones menos radicales, buen humor, m√°s tiempo para los seres queridos. Ahora probado por la ciencia</a></li>
<li><a href="../439870/index.html">El video como motor de progreso: la evoluci√≥n de los sistemas de vigilancia</a></li>
<li><a href="../439874/index.html">Efectos de filtrado SVG. Parte 3. Efecto de posterizaci√≥n de imagen usando feComponentTransfer</a></li>
<li><a href="../439878/index.html">Creaci√≥n de arquitectura para una nueva startup altamente cargada en 2019</a></li>
<li><a href="../439880/index.html">Semana de la seguridad 07: vulnerabilidades locales de dispositivos IoT</a></li>
<li><a href="../439882/index.html">Aventura con traza (2)</a></li>
<li><a href="../439884/index.html">C√≥mo rechazar boletines innecesarios con un solo bot√≥n. Yandex.Mail Team Experience</a></li>
<li><a href="../439886/index.html">C√≥mo ense√±√© a una red neuronal a implementar la funci√≥n de evaluaci√≥n de posici√≥n en la Copa AI de Rusia CodeBall 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
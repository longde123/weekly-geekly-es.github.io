<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸŒº ğŸ›ŒğŸ½ ğŸ’– Eine kurze EinfÃ¼hrung in Markov-Ketten ğŸšµğŸ¼ ğŸš‡ ğŸ¥–</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im Jahr 1998 verÃ¶ffentlichten Lawrence Page, Sergey Brin, Rajiv Motwani und Terry Vinograd den Artikel â€Das PageRank-Zitierranking: Ordnung ins Web br...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Eine kurze EinfÃ¼hrung in Markov-Ketten</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455762/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84a/01a/072/84a01a0729fb1a772e89f2fa6c257a7d.gif" alt="Bild"></div><br>  Im Jahr 1998 verÃ¶ffentlichten Lawrence Page, Sergey Brin, Rajiv Motwani und Terry Vinograd den Artikel â€Das PageRank-Zitierranking: Ordnung ins Web bringenâ€œ, in dem der mittlerweile berÃ¼hmte PageRank-Algorithmus beschrieben wurde, der zur Grundlage von Google wurde.  Nach etwas weniger als zwei Jahrzehnten wurde Google ein Riese, und obwohl sich sein Algorithmus stark weiterentwickelt hat, ist PageRank immer noch das â€Symbolâ€œ fÃ¼r Google-Ranking-Algorithmen (obwohl nur wenige Menschen wirklich sagen kÃ¶nnen, wie viel Gewicht der Algorithmus heute benÃ¶tigt). . <br><br>  Aus theoretischer Sicht ist es interessant festzustellen, dass eine der Standardinterpretationen des PageRank-Algorithmus auf einem einfachen, aber grundlegenden Konzept von Markov-Ketten basiert.  Aus dem Artikel werden wir sehen, dass Markov-Ketten leistungsstarke Werkzeuge fÃ¼r die stochastische Modellierung sind, die fÃ¼r jeden Datenwissenschaftler nÃ¼tzlich sein kÃ¶nnen.  Insbesondere werden wir solche grundlegenden Fragen beantworten: Was sind Markov-Ketten, welche guten Eigenschaften besitzen sie und was kann mit ihrer Hilfe getan werden? <br><a name="habracut"></a><br><h4>  Kurzer RÃ¼ckblick </h4><br>  Im ersten Abschnitt geben wir die grundlegenden Definitionen an, die zum VerstÃ¤ndnis der Markov-Ketten erforderlich sind.  Im zweiten Abschnitt betrachten wir den Sonderfall von Markov-Ketten in einem endlichen Zustandsraum.  Im dritten Abschnitt betrachten wir einige der elementaren Eigenschaften von Markov-Ketten und veranschaulichen diese Eigenschaften anhand vieler kleiner Beispiele.  SchlieÃŸlich verknÃ¼pfen wir im vierten Abschnitt die Markov-Ketten mit dem PageRank-Algorithmus und sehen anhand eines kÃ¼nstlichen Beispiels, wie Markov-Ketten zum Einordnen der Knoten eines Graphen verwendet werden kÃ¶nnen. <br><br><blockquote>  <strong>Hinweis</strong>  Um diesen Beitrag zu verstehen, mÃ¼ssen Sie die Grundlagen der Wahrscheinlichkeit und der linearen Algebra kennen.  Insbesondere werden die folgenden Konzepte verwendet: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">bedingte Wahrscheinlichkeit</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">Eigenvektor</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">Formel mit voller Wahrscheinlichkeit</a> . </blockquote><br><hr><br><h3>  Was sind Markov-Ketten? </h3><br><h4>  Zufallsvariablen und zufÃ¤llige Prozesse </h4><br>  Bevor wir das Konzept der Markov-Ketten einfÃ¼hren, erinnern wir uns kurz an die grundlegenden, aber wichtigen Konzepte der Wahrscheinlichkeitstheorie. <br><br>  Erstens ist eine <strong>Zufallsvariable</strong> X auÃŸerhalb der Sprache der Mathematik eine GrÃ¶ÃŸe, die durch das Ergebnis eines ZufallsphÃ¤nomens bestimmt wird.  Das Ergebnis kann eine Zahl (oder "Ã„hnlichkeit einer Zahl", beispielsweise Vektoren) oder etwas anderes sein.  Zum Beispiel kÃ¶nnen wir eine Zufallsvariable als Ergebnis eines WÃ¼rfelwurfs (Zahl) oder als Ergebnis eines MÃ¼nzwurfs definieren (keine Zahl, es sei denn, wir bezeichnen beispielsweise "Adler" als 0, aber "SchwÃ¤nze" als 1).  Wir erwÃ¤hnen auch, dass der Raum mÃ¶glicher Ergebnisse einer Zufallsvariablen diskret oder stetig sein kann: Beispielsweise ist eine normale Zufallsvariable stetig und eine Poisson-Zufallsvariable diskret. <br><br>  Ferner kÃ¶nnen wir einen <strong>zufÃ¤lligen Prozess</strong> (auch als stochastisch bezeichnet) als eine Menge von Zufallsvariablen definieren, die durch die Menge T indiziert werden, die hÃ¤ufig unterschiedliche Zeitpunkte bezeichnet (im Folgenden werden wir dies annehmen).  Die beiden hÃ¤ufigsten FÃ¤lle: T kann entweder eine Menge natÃ¼rlicher Zahlen (zufÃ¤lliger Prozess mit diskreter Zeit) oder eine Menge reeller Zahlen (zufÃ¤lliger Prozess mit kontinuierlicher Zeit) sein.  Wenn wir beispielsweise jeden Tag eine MÃ¼nze werfen, legen wir einen zufÃ¤lligen Prozess mit diskreter Zeit fest, und der sich stÃ¤ndig Ã¤ndernde Wert einer Option an der BÃ¶rse legt einen zufÃ¤lligen Prozess mit kontinuierlicher Zeit fest.  ZufÃ¤llige Variablen zu verschiedenen Zeitpunkten kÃ¶nnen unabhÃ¤ngig voneinander sein (ein Beispiel mit einem MÃ¼nzwurf) oder eine gewisse AbhÃ¤ngigkeit aufweisen (ein Beispiel mit dem Optionswert).  DarÃ¼ber hinaus kÃ¶nnen sie einen kontinuierlichen oder diskreten Zustandsraum haben (den Raum mÃ¶glicher Ergebnisse zu jedem Zeitpunkt). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/31e/ada/2f8/31eada2f80d66f0df4c007ec8da11579.jpg"></div><br>  <i>Verschiedene Arten von Zufallsprozessen (diskret / kontinuierlich in Raum / Zeit).</i> <br><br><h4>  Markov-Eigenschaft und Markov-Kette </h4><br>  Es gibt bekannte Familien zufÃ¤lliger Prozesse: GauÃŸsche Prozesse, Poisson-Prozesse, autoregressive Modelle, Modelle mit gleitendem Durchschnitt, Markov-Ketten und andere.  Jeder dieser EinzelfÃ¤lle hat bestimmte Eigenschaften, die es uns ermÃ¶glichen, sie besser zu untersuchen und zu verstehen. <br><br>  Eine der Eigenschaften, die das Studium eines zufÃ¤lligen Prozesses erheblich vereinfacht, ist die Markov-Eigenschaft.  Wenn wir es in einer sehr informellen Sprache erklÃ¤ren, sagt uns die Markov-Eigenschaft, dass wir, wenn wir den Wert kennen, der durch einen zufÃ¤lligen Prozess zu einem bestimmten Zeitpunkt erhalten wird, keine zusÃ¤tzlichen Informationen Ã¼ber das zukÃ¼nftige Verhalten des Prozesses erhalten und andere Informationen Ã¼ber seine Vergangenheit sammeln.  In einer mathematischeren Sprache: Zu jedem Zeitpunkt hÃ¤ngt die bedingte Verteilung zukÃ¼nftiger ZustÃ¤nde eines Prozesses mit gegebenen aktuellen und vergangenen ZustÃ¤nden nur vom aktuellen Zustand ab und nicht von vergangenen ZustÃ¤nden (die <strong>Eigenschaft des Speichermangels</strong> ).  Ein zufÃ¤lliger Prozess mit einer Markov-Eigenschaft wird als <strong>Markov-Prozess bezeichnet</strong> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/44f/1ba/f48/44f1baf48ceb669e0416489eea2bae35.png"></div><br>  <i>Die Markov-Eigenschaft bedeutet, dass wir, wenn wir den aktuellen Status zu einem bestimmten Zeitpunkt kennen, keine zusÃ¤tzlichen Informationen Ã¼ber die Zukunft benÃ¶tigen, die aus der Vergangenheit stammen.</i> <br><br>  Basierend auf dieser Definition kÃ¶nnen wir die Definition von "homogenen Markov-Ketten mit diskreter Zeit" formulieren (im Folgenden werden wir sie der Einfachheit halber "Markov-Ketten" nennen).  <strong>Die Markov-Kette</strong> ist ein Markov-Prozess mit diskreter Zeit und einem diskreten Zustandsraum.  Eine Markov-Kette ist also eine diskrete Folge von ZustÃ¤nden, von denen jeder aus einem diskreten Zustandsraum (endlich oder unendlich) stammt und die Markov-Eigenschaft erfÃ¼llt. <br><br>  Mathematisch kÃ¶nnen wir die Markov-Kette wie folgt bezeichnen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/114/3b7/fc3/1143b7fc371f3142534c2b886bf3e69c.png"></div><br>  wobei zu jedem Zeitpunkt der Prozess seine Werte aus einer diskreten Menge E bezieht, so dass <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/886/a22/d76/886a22d7671798102ee3d94fe9868b81.png"></div><br>  Dann impliziert die Markov-Eigenschaft, dass wir haben <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/edc/8bf/384/edc8bf38422705e72c9dd7d094b249db.png"></div><br>  Beachten Sie erneut, dass diese letzte Formel die Tatsache widerspiegelt, dass fÃ¼r die Chronologie (wo ich jetzt bin und wo ich vorher war) die Wahrscheinlichkeitsverteilung des nÃ¤chsten Zustands (wo ich der nÃ¤chste sein werde) vom aktuellen Zustand abhÃ¤ngt, jedoch nicht von frÃ¼heren ZustÃ¤nden. <br><br><blockquote>  <strong>Hinweis</strong>  In diesem EinfÃ¼hrungsbeitrag haben wir beschlossen, nur Ã¼ber einfache homogene Markov-Ketten mit diskreter Zeit zu sprechen.  Es gibt jedoch auch inhomogene (zeitabhÃ¤ngige) Markov-Ketten und / oder zeitkontinuierliche Ketten.  In diesem Artikel werden solche Variationen des Modells nicht berÃ¼cksichtigt.  Es ist auch erwÃ¤hnenswert, dass die obige Definition einer Markov-Eigenschaft extrem vereinfacht ist: Die wahre mathematische Definition verwendet das Konzept der Filterung, das weit Ã¼ber unsere einfÃ¼hrende Kenntnis des Modells hinausgeht. </blockquote><br><h4>  Wir charakterisieren die Zufallsdynamik einer Markov-Kette </h4><br>  Im vorherigen Unterabschnitt haben wir die allgemeine Struktur einer Markov-Kette kennengelernt.  Mal sehen, was wir brauchen, um eine bestimmte "Instanz" eines solchen zufÃ¤lligen Prozesses festzulegen. <br><br>  ZunÃ¤chst stellen wir fest, dass die vollstÃ¤ndige Bestimmung der Eigenschaften eines zufÃ¤lligen Prozesses mit diskreter Zeit, die die Markov-Eigenschaft nicht erfÃ¼llt, schwierig sein kann: Die Wahrscheinlichkeitsverteilung zu einem bestimmten Zeitpunkt kann von einem oder mehreren Momenten in der Vergangenheit und / oder Zukunft abhÃ¤ngen.  All diese mÃ¶glichen ZeitabhÃ¤ngigkeiten kÃ¶nnen mÃ¶glicherweise die Erstellung einer Prozessdefinition erschweren. <br><br>  Aufgrund der Markov-Eigenschaft ist die Dynamik der Markov-Kette jedoch recht einfach zu bestimmen.  Und in der Tat.  wir mÃ¼ssen nur zwei Aspekte bestimmen: die <strong>anfÃ¤ngliche Wahrscheinlichkeitsverteilung</strong> (d. h. die Wahrscheinlichkeitsverteilung zum Zeitpunkt n = 0), bezeichnet mit <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/595/90e/140/59590e140cdb348c943d9dcab0ea011d.png"></div><br>  und <strong>die Ãœbergangswahrscheinlichkeitsmatrix</strong> (die uns die Wahrscheinlichkeiten gibt, dass der Zustand zum Zeitpunkt n + 1 der nÃ¤chste fÃ¼r einen anderen Zustand zum Zeitpunkt n fÃ¼r ein beliebiges Zustandspaar ist), bezeichnet mit <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/011/aee/574/011aee5747fe7e42fa09bf044c421e26.png"></div><br>  Wenn diese beiden Aspekte bekannt sind, ist die vollstÃ¤ndige (probabilistische) Dynamik des Prozesses klar definiert.  TatsÃ¤chlich kann die Wahrscheinlichkeit eines Ergebnisses des Prozesses dann zyklisch berechnet werden. <br><br>  Beispiel: Angenommen, wir mÃ¶chten die Wahrscheinlichkeit wissen, dass die ersten drei ZustÃ¤nde des Prozesses Werte haben (s0, s1, s2).  Das heiÃŸt, wir wollen die Wahrscheinlichkeit berechnen <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6c5/991/81b/6c599181b1fd3892391711f311878b72.png"></div><br>  Hier wenden wir die Formel fÃ¼r die Gesamtwahrscheinlichkeit an, die besagt, dass die Wahrscheinlichkeit des Erhaltens (s0, s1, s2) gleich der Wahrscheinlichkeit des Erhaltens des ersten s0-fachen der Wahrscheinlichkeit des Erhaltens von s1 ist, vorausgesetzt, wir haben zuvor das s0-fache der Wahrscheinlichkeit des Erhaltens von s2 unter BerÃ¼cksichtigung der Tatsache erhalten, dass wir haben frÃ¼her in der Reihenfolge s0 und s1.  Mathematisch kann dies geschrieben werden als <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a46/da3/64f/a46da364f28d5b69055700759db02663.png"></div><br>  Und dann wird eine Vereinfachung offenbart, die durch die Markov-Annahme bestimmt wird.  TatsÃ¤chlich erhalten wir bei langen Ketten stark bedingte Wahrscheinlichkeiten fÃ¼r die letzteren ZustÃ¤nde.  Im Fall von Markov-Ketten kÃ¶nnen wir diesen Ausdruck jedoch vereinfachen, indem wir die Tatsache ausnutzen, dass <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0ab/7f6/568/0ab7f6568e28bb562ebb287252422d51.png"></div><br>  auf diese Weise bekommen <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b6c/700/30a/b6c70030a8627d87c39dab96c147513a.png"></div><br>  Da sie die probabilistische Dynamik des Prozesses vollstÃ¤ndig charakterisieren, kÃ¶nnen viele komplexe Ereignisse nur auf der Grundlage der anfÃ¤nglichen Wahrscheinlichkeitsverteilung q0 und der Ãœbergangswahrscheinlichkeitsmatrix p berechnet werden.  ErwÃ¤hnenswert ist auch eine weitere grundlegende Verbindung: der Ausdruck der Wahrscheinlichkeitsverteilung zum Zeitpunkt n + 1, ausgedrÃ¼ckt in Bezug auf die Wahrscheinlichkeitsverteilung zum Zeitpunkt n <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5ae/f31/a8a/5aef31a8ae120a25e5b43d6534dc20ff.png"></div><br><h3>  Markov-Ketten in endlichen ZustandsrÃ¤umen </h3><br><h4>  Matrix- und Graphendarstellung </h4><br>  Hier nehmen wir an, dass die Menge E eine endliche Anzahl mÃ¶glicher ZustÃ¤nde N hat: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d57/788/f81/d57788f81d0a92aa1d94ef572bdf25e3.png"></div><br>  Dann kann die anfÃ¤ngliche Wahrscheinlichkeitsverteilung als <strong>ein Zeilenvektor</strong> q0 der GrÃ¶ÃŸe N beschrieben werden, und Ãœbergangswahrscheinlichkeiten kÃ¶nnen als eine Matrix p der GrÃ¶ÃŸe N durch N beschrieben werden, so dass <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/100/6f8/6ae/1006f86aeff6699711058bd890190917.png"></div><br>  Der Vorteil dieser Notation besteht darin, dass wir die Wahrscheinlichkeitsverteilung in Schritt n durch den Zeilenvektor qn so bezeichnen, dass seine Komponenten spezifiziert werden <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/006/19b/4ae/00619b4ae1601eacdb8fd7ce248f1738.png"></div><br>  dann bleiben einfache Matrixrelationen erhalten <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a12/cdc/a7b/a12cdca7b75ef09ceaacef33a3667549.png"></div><br>  (hier werden wir den Beweis nicht betrachten, aber es ist sehr einfach, ihn zu reproduzieren). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/23c/3c6/a10/23c3c6a102bd7aa079c36a75f60a5e42.png"></div><br>  <i>Wenn wir den Zeilenvektor rechts, der die Wahrscheinlichkeitsverteilung zu einem bestimmten Zeitpunkt beschreibt, mit der Ãœbergangswahrscheinlichkeitsmatrix multiplizieren, erhalten wir die Wahrscheinlichkeitsverteilung zum nÃ¤chsten Zeitpunkt.</i> <br><br>  Wie wir sehen, wird der Ãœbergang der Wahrscheinlichkeitsverteilung von einer gegebenen Stufe zur nÃ¤chsten einfach als die richtige Multiplikation des Zeilenvektors der Wahrscheinlichkeiten des Anfangsschritts mit der Matrix p definiert.  DarÃ¼ber hinaus impliziert dies, dass wir haben <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/35b/072/e0c/35b072e0c74397094e5bf6a9dab11417.png"></div><br>  Die zufÃ¤llige Dynamik einer Markov-Kette in einem endlichen Zustandsraum kann leicht als normalisierter orientierter Graph dargestellt werden, so dass jeder Knoten des Graphen ein Zustand ist und fÃ¼r jedes Zustandspaar (ei, ej) eine Kante existiert, die von ei nach ej geht, wenn p (ei, ej) )&gt; 0.  Dann ist der Kantenwert die gleiche Wahrscheinlichkeit p (ei, ej). <br><br><h4>  Beispiel: ein Leser unserer Website </h4><br>  Lassen Sie uns dies alles anhand eines einfachen Beispiels veranschaulichen.  Betrachten Sie das alltÃ¤gliche Verhalten eines fiktiven Besuchers einer Site.  Jeden Tag hat er drei mÃ¶gliche Bedingungen: Der Leser besucht die Site an diesem Tag nicht (N), der Leser besucht die Site, liest jedoch nicht den gesamten Beitrag (V), und der Leser besucht die Site und liest einen gesamten Post (R).  Wir haben also den folgenden Zustandsraum: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/242/b1c/627/242b1c62745a4a13f2a24b8f919c6820.png"></div><br>  Angenommen, dieser Leser hat am ersten Tag eine 50% ige Chance, nur auf die Site zuzugreifen, und eine 50% ige Chance, die Site zu besuchen und mindestens einen Artikel zu lesen.  Der Vektor, der die anfÃ¤ngliche Wahrscheinlichkeitsverteilung beschreibt (n = 0), sieht dann folgendermaÃŸen aus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/362/a5a/045/362a5a0455c939f9d855d65605945c90.png"></div><br>  Stellen Sie sich auch vor, dass die folgenden Wahrscheinlichkeiten eingehalten werden: <br><br><ul><li>  Wenn der Leser einen Tag nicht besucht, besteht eine Wahrscheinlichkeit von 25%, ihn am nÃ¤chsten Tag nicht zu besuchen, eine Wahrscheinlichkeit von 50%, ihn nur zu besuchen, und eine Wahrscheinlichkeit von 25%, den Artikel zu besuchen und zu lesen </li><li>  Wenn der Leser die Website eines Tages besucht, aber nicht liest, hat er eine 50% ige Chance, sie am nÃ¤chsten Tag erneut zu besuchen und den Artikel nicht zu lesen, und eine 50% ige Chance, sie zu besuchen und zu lesen </li><li>  Wenn ein Leser einen Artikel am selben Tag besucht und liest, hat er eine 33% ige Chance, sich am nÃ¤chsten Tag nicht anzumelden <em>(ich hoffe, dieser Beitrag hat keinen solchen Effekt!)</em> , eine 33% ige Chance, sich nur auf der Website anzumelden, und 34%, den Artikel erneut zu besuchen und zu lesen </li></ul><br>  Dann haben wir die folgende Ãœbergangsmatrix: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cf5/7e6/ba5/cf57e6ba5303d4e13cbb736e6115306d.png"></div><br>  Aus dem vorherigen Unterabschnitt wissen wir, wie wir fÃ¼r diesen Leser die Wahrscheinlichkeit jedes Zustands am nÃ¤chsten Tag berechnen kÃ¶nnen (n = 1). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c64/a77/76c/c64a7776cfc56a5af1a0ccf495469ef7.png"></div><br>  Die probabilistische Dynamik dieser Markov-Kette kann wie folgt grafisch dargestellt werden: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/832/797/9a1/8327979a1aa6edd9d462a0b40a4c072d.png"></div><br>  <i>PrÃ¤sentation in Form eines Diagramms der Markov-Kette, das das Verhalten unseres erfundenen Besuchers der Website modelliert.</i> <br><br><h3>  Eigenschaften von Markov-Ketten </h3><br>  In diesem Abschnitt werden wir nur auf einige der grundlegendsten Eigenschaften oder Merkmale von Markov-Ketten eingehen.  Wir werden nicht auf mathematische Details eingehen, sondern einen kurzen Ãœberblick Ã¼ber interessante Punkte geben, die untersucht werden mÃ¼ssen, um Markov-Ketten zu verwenden.  Wie wir gesehen haben, kann im Fall eines endlichen Zustandsraums die Markov-Kette als Graph dargestellt werden.  In Zukunft werden wir die grafische Darstellung verwenden, um einige Eigenschaften zu erklÃ¤ren.  Vergessen Sie jedoch nicht, dass diese Eigenschaften nicht unbedingt auf den Fall eines endlichen Zustandsraums beschrÃ¤nkt sind. <br><br><h4>  Zersetzbarkeit, PeriodizitÃ¤t, Unwiderruflichkeit und Wiederherstellbarkeit </h4><br>  Beginnen wir in diesem Unterabschnitt mit mehreren klassischen Methoden zur Charakterisierung eines Zustands oder einer gesamten Markov-Kette. <br><br>  ZunÃ¤chst erwÃ¤hnen wir, dass die Markov-Kette nicht zusammensetzbar ist, wenn es mÃ¶glich ist, einen Zustand von einem anderen Zustand aus zu erreichen (dies ist nicht in einem Schritt erforderlich).  Wenn der Zustandsraum endlich ist und die Kette als Graph dargestellt werden kann, kÃ¶nnen wir sagen, dass der Graph einer nicht zusammensetzbaren Markov-Kette stark verbunden ist (Graphentheorie). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cef/a39/05c/cefa3905cced27b4e27a4e9547fbe846.png"></div><br>  <i>Darstellung der Eigenschaft der Unzusammensetzbarkeit (IrreduzibilitÃ¤t).</i>  <i>Die Kette links kann nicht gekÃ¼rzt werden: von 3 oder 4 kÃ¶nnen wir nicht in 1 oder 2 gelangen. Die Kette rechts (eine Kante wird hinzugefÃ¼gt) kann gekÃ¼rzt werden: Jeder Zustand kann von jedem anderen aus erreicht werden.</i> <br><br>  Ein Zustand hat eine Periode k, wenn beim Verlassen fÃ¼r eine RÃ¼ckkehr in diesen Zustand die Anzahl der Zeitschritte ein Vielfaches von k ist (k ist der grÃ¶ÃŸte gemeinsame Teiler aller mÃ¶glichen LÃ¤ngen von RÃ¼ckkehrpfaden).  Wenn k = 1 ist, sagen sie, dass der Zustand aperiodisch ist und die gesamte Markov-Kette <strong>aperiodisch ist,</strong> wenn alle ihre ZustÃ¤nde aperiodisch sind.  Im Fall einer irreduziblen Markov-Kette kÃ¶nnen wir auch erwÃ¤hnen, dass, wenn ein Zustand aperiodisch ist, alle anderen ebenfalls aperiodisch sind. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cbe/65f/a07/cbe65fa07e7b816d385408824ba0ff39.png"></div><br>  <i>Darstellung der PeriodizitÃ¤tseigenschaft.</i>  <i>Die Kette links ist periodisch mit k = 2: Wenn Sie einen Zustand verlassen, erfordert die RÃ¼ckkehr immer die Anzahl der Schritte multipliziert mit 2. Die Kette rechts hat eine Periode von 3.</i> <br><br>  Ein Staat ist <strong>unwiderruflich,</strong> wenn beim Verlassen des Staates eine Wahrscheinlichkeit ungleich Null besteht, dass wir niemals zu ihm zurÃ¼ckkehren werden.  Umgekehrt gilt ein Staat als <strong>rÃ¼ckzahlbar,</strong> wenn wir wissen, dass wir nach Verlassen des Staates in Zukunft mit Wahrscheinlichkeit 1 zu ihm zurÃ¼ckkehren kÃ¶nnen (wenn er nicht unwiderruflich ist). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6a0/1ad/7b0/6a01ad7b05e96f5a6606a8a48d127233.png"></div><br>  <i>Abbildung der RÃ¼ckgabe- / Unwiderruflichkeitseigenschaft.</i>  <i>Die Kette auf der linken Seite hat die folgenden Eigenschaften: 1, 2 und 3 sind unwiderruflich (wenn wir diese Punkte verlassen, kÃ¶nnen wir nicht absolut sicher sein, dass wir zu ihnen zurÃ¼ckkehren) und haben eine Periode von 3, und 4 und 5 sind rÃ¼ckzahlbar (wenn wir diese Punkte verlassen, sind wir absolut sicher dass wir eines Tages zu ihnen zurÃ¼ckkehren werden) und eine Periode von 2 haben. Die Kette auf der rechten Seite hat eine weitere Rippe, wodurch die gesamte Kette rÃ¼ckzahlbar und aperiodisch wird.</i> <br><br>  FÃ¼r den RÃ¼ckgabezustand kÃ¶nnen wir die durchschnittliche RÃ¼ckgabezeit berechnen, die die <strong>erwartete RÃ¼ckgabezeit</strong> beim Verlassen des Zustands ist.  Beachten Sie, dass selbst die Wahrscheinlichkeit einer RÃ¼ckgabe 1 betrÃ¤gt. Dies bedeutet nicht, dass die erwartete RÃ¼ckgabezeit endlich ist.  Daher kÃ¶nnen wir unter allen RÃ¼ckkehrzustÃ¤nden zwischen <strong>positiven RÃ¼ckkehrzustÃ¤nden</strong> (mit einer endlichen erwarteten RÃ¼ckkehrzeit) und <strong>Null-RÃ¼ckkehrzustÃ¤nden</strong> (mit einer unendlichen erwarteten RÃ¼ckkehrzeit) unterscheiden. <br><br><h4>  StationÃ¤re Verteilung, Randverhalten und ErgodizitÃ¤t </h4><br>  In diesem Unterabschnitt betrachten wir Eigenschaften, die einige Aspekte der (zufÃ¤lligen) Dynamik charakterisieren, die von der Markov-Kette beschrieben wird. <br><br>  Die Wahrscheinlichkeitsverteilung Ï€ Ã¼ber den Zustandsraum E wird als <strong>stationÃ¤re Verteilung bezeichnet,</strong> wenn sie den Ausdruck erfÃ¼llt <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/736/d70/e5d/736d70e5ddfc5aeb788d29ebfa79f9ec.png"></div><br>  Da haben wir <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b98/c4e/e6c/b98c4ee6c3b8032b074c7543db816c7e.png"></div><br>  Dann erfÃ¼llt die stationÃ¤re Verteilung den Ausdruck <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b8/df4/0a8/2b8df40a8a9a2ae90eb49a7c60dafb55.png"></div><br>  Per Definition Ã¤ndert sich die stationÃ¤re Wahrscheinlichkeitsverteilung nicht Ã¼ber die Zeit.  Das heiÃŸt, wenn die Anfangsverteilung q stationÃ¤r ist, ist sie in allen nachfolgenden Zeitstufen gleich.  Wenn der Zustandsraum endlich ist, kann p als Matrix und Ï€ als Zeilenvektor dargestellt werden, und dann erhalten wir <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ee0/565/9fc/ee05659fc4ed268ee3189342a76d9311.png"></div><br>  Dies drÃ¼ckt erneut die Tatsache aus, dass sich die stationÃ¤re Wahrscheinlichkeitsverteilung nicht mit der Zeit Ã¤ndert (wie wir sehen, kÃ¶nnen wir durch Multiplizieren der Wahrscheinlichkeitsverteilung rechts mit p die Wahrscheinlichkeitsverteilung in der nÃ¤chsten Zeitstufe berechnen).  Beachten Sie, dass eine nicht zusammensetzbare Markov-Kette genau dann eine stationÃ¤re Wahrscheinlichkeitsverteilung aufweist, wenn einer ihrer ZustÃ¤nde eine positive Rendite aufweist. <br><br>  Eine weitere interessante Eigenschaft im Zusammenhang mit der stationÃ¤ren Wahrscheinlichkeitsverteilung ist wie folgt.  Wenn die Kette eine positive Rendite (dh eine stationÃ¤re Verteilung) und eine aperiodische Verteilung aufweist, konvergiert die Wahrscheinlichkeitsverteilung der Kette unabhÃ¤ngig von den anfÃ¤nglichen Wahrscheinlichkeiten, wenn die Zeitintervalle gegen unendlich tendieren: Sie sagen, dass die Kette eine <strong>begrenzende Verteilung hat</strong> , was nichts anderes ist. als stationÃ¤re Verteilung.  Im Allgemeinen kann es so geschrieben werden: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/95b/fb9/1c6/95bfb91c67d024e2df40b0e6dcdaf747.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir betonen noch einmal, dass wir keine Annahmen Ã¼ber die anfÃ¤ngliche Wahrscheinlichkeitsverteilung treffen: Die Wahrscheinlichkeitsverteilung der Kette reduziert sich unabhÃ¤ngig von den Anfangsparametern auf eine stationÃ¤re Verteilung (Gleichgewichtsverteilung der Kette). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SchlieÃŸlich ist </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ErgodizitÃ¤t</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eine weitere interessante Eigenschaft im Zusammenhang mit dem Verhalten der Markov-Kette. Wenn die Markov-Kette nicht zusammensetzbar ist, wird auch gesagt, dass sie â€ergodischâ€œ ist, weil sie den folgenden ergodischen Satz erfÃ¼llt. Angenommen, wir haben eine Funktion f (.), Die vom Zustandsraum E zur Achse geht (dies kann zum Beispiel der Preis sein, in jedem Zustand zu sein). Wir kÃ¶nnen den Durchschnittswert bestimmen, der diese Funktion entlang einer bestimmten Trajektorie bewegt (zeitlicher Durchschnitt). FÃ¼r den n-ten ersten Term wird dies als bezeichnet</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/af1/8c5/4a3/af18c54a3d7dc1e1ad4a4015ab7ad64c.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wir kÃ¶nnen auch den Durchschnittswert der Funktion f auf der Menge E berechnen, gewichtet mit der stationÃ¤ren Verteilung (rÃ¤umlicher Durchschnitt), die bezeichnet wird </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/04a/352/c77/04a352c77b0687ef3cc89f3b7e0edf38.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dann sagt uns der Ergodensatz, dass, wenn die Flugbahn unendlich lang wird, der Zeitmittelwert gleich dem rÃ¤umlichen Durchschnitt ist (gewichtet mit der stationÃ¤ren Verteilung). </font><font style="vertical-align: inherit;">Die ErgodizitÃ¤tseigenschaft kann wie folgt geschrieben werden:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/37d/c4d/6cb37dc4dcf0a3e53cc8e6baec8f4b1a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mit anderen Worten bedeutet dies, dass in der frÃ¼heren Grenze das Verhalten der Trajektorie unbedeutend wird und nur das langfristige stationÃ¤re Verhalten bei der Berechnung des zeitlichen Durchschnitts wichtig ist. </font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kehren wir zum Beispiel mit dem Site Reader zurÃ¼ck </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Betrachten Sie erneut das Beispiel des Site-Readers. </font><font style="vertical-align: inherit;">In diesem einfachen Beispiel ist es offensichtlich, dass die Kette nicht zusammensetzbar und aperiodisch ist und alle ihre ZustÃ¤nde positiv zurÃ¼ckgegeben werden kÃ¶nnen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um zu zeigen, welche interessanten Ergebnisse mit Markov-Ketten berechnet werden kÃ¶nnen, betrachten wir die durchschnittliche Zeit der RÃ¼ckkehr zum Zustand R (der Zustand â€besucht die Site und liest den Artikelâ€œ). </font><font style="vertical-align: inherit;">Mit anderen Worten, wir mÃ¶chten die folgende Frage beantworten: Wenn unser Leser eines Tages die Website besucht und einen Artikel liest, wie viele Tage mÃ¼ssen wir dann durchschnittlich warten, bis er zurÃ¼ckkommt und den Artikel liest? </font><font style="vertical-align: inherit;">Versuchen wir, ein intuitives Konzept fÃ¼r die Berechnung dieses Werts zu erhalten. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zuerst bezeichnen wir</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a2/57c/c74/2a257cc74db27e5ac89ffc1e06bd9ed9.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir wollen also m (R, R) berechnen. </font><font style="vertical-align: inherit;">Wenn wir Ã¼ber das erste Intervall sprechen, das nach dem Verlassen von R erreicht wurde, erhalten wir</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f9/e1a/a6e/4f9e1aa6e04e736fde182693398a4dca.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieser Ausdruck erfordert jedoch, dass wir fÃ¼r die Berechnung von m (R, R) m (N, R) und m (V, R) kennen. </font><font style="vertical-align: inherit;">Diese beiden GrÃ¶ÃŸen kÃ¶nnen auf Ã¤hnliche Weise ausgedrÃ¼ckt werden:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e23/7cb/f2d/e237cbf2d81597544f800d38b5a59e91.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben also 3 Gleichungen mit 3 Unbekannten und nach dem LÃ¶sen erhalten wir m (N, R) = 2,67, m (V, R) = 2,00 und m (R, R) = 2,54. </font><font style="vertical-align: inherit;">Die durchschnittliche Zeit, um zum Zustand R zurÃ¼ckzukehren, betrÃ¤gt dann 2,54. </font><font style="vertical-align: inherit;">Das heiÃŸt, unter Verwendung der linearen Algebra konnten wir die durchschnittliche Zeit bis zur RÃ¼ckkehr in den Zustand R berechnen (sowie die durchschnittliche Ãœbergangszeit von N nach R und die durchschnittliche Ãœbergangszeit von V nach R). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lassen Sie uns zum Abschluss dieses Beispiels sehen, wie die stationÃ¤re Verteilung der Markov-Kette aussehen wird. </font><font style="vertical-align: inherit;">Um die stationÃ¤re Verteilung zu bestimmen, mÃ¼ssen wir die folgende Gleichung der linearen Algebra lÃ¶sen:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bb3/73d/068/bb373d068a04d681c0501d8276731c0a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das heiÃŸt, wir mÃ¼ssen den linken Eigenvektor p finden, der dem Eigenvektor 1 zugeordnet ist. Wenn wir dieses Problem lÃ¶sen, erhalten wir die folgende stationÃ¤re Verteilung: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0c6/abe/19e/0c6abe19e37b67af5f380eb3e5c0beb9.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">StationÃ¤re Verteilung im Beispiel mit dem Site Reader. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie kÃ¶nnen auch feststellen, dass Ï€ (R) = 1 / m (R, R) ist, und wenn ein wenig reflektiert wird, dann ist diese IdentitÃ¤t ziemlich logisch (aber wir werden nicht im Detail darÃ¼ber sprechen).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Da die Kette nicht zusammensetzbar und aperiodisch ist, bedeutet dies, dass die Wahrscheinlichkeitsverteilung auf lange Sicht gegen eine stationÃ¤re Verteilung konvergiert (fÃ¼r alle Anfangsparameter). Mit anderen Worten, unabhÃ¤ngig vom Ausgangszustand des Lesers der Site erhalten wir, wenn wir lange genug warten und zufÃ¤llig einen Tag auswÃ¤hlen, die Wahrscheinlichkeit Ï€ (N), dass der Leser die Site an diesem Tag nicht besucht, die Wahrscheinlichkeit Ï€ (V), dass Der Leser wird vorbeischauen, aber den Artikel nicht lesen, und die Wahrscheinlichkeit ist Ï€Â®, dass der Leser vorbeischaut und den Artikel liest. Um die Eigenschaft der Konvergenz besser zu verstehen, werfen wir einen Blick auf die folgende Grafik, die die Entwicklung der Wahrscheinlichkeitsverteilungen ausgehend von verschiedenen Startpunkten und (schnell) der Konvergenz zu einer stationÃ¤ren Verteilung zeigt:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/128/58e/a88/12858ea88a0e3bd05950b9d30096b776.jpg"></div><br> <i>  3       (,   )    ().</i> <br><br><h3>  :  PageRank </h3><br>     PageRank!     ,  ,   PageRank,    ,   ,              .     ,   . <br><br><h4>  - </h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PageRank versucht, das folgende Problem zu lÃ¶sen: Wie ordnen wir einen vorhandenen Satz (wir kÃ¶nnen davon ausgehen, dass dieser Satz bereits durch eine Abfrage gefiltert wurde) mithilfe von Links, die bereits zwischen den Seiten vorhanden sind? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dieses Problem zu lÃ¶sen und Seiten ordnen zu kÃ¶nnen, fÃ¼hrt PageRank ungefÃ¤hr den folgenden Prozess aus. Wir glauben, dass sich ein beliebiger Internetnutzer zum ersten Mal auf einer der Seiten befindet. Dann beginnt dieser Benutzer zufÃ¤llig, sich zu bewegen, indem er auf jede Seite eines der Links klickt, die zu einer anderen Seite des betreffenden Satzes fÃ¼hren (es wird angenommen, dass alle Links, die auÃŸerhalb dieser Seiten fÃ¼hren, verboten sind). Auf jeder Seite haben alle gÃ¼ltigen Links die gleiche Wahrscheinlichkeit zu klicken.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So definieren wir die Markov-Kette: Seiten sind mÃ¶gliche ZustÃ¤nde, Ãœbergangswahrscheinlichkeiten werden durch Links von Seite zu Seite festgelegt (so gewichtet, dass auf jeder Seite alle verknÃ¼pften Seiten die gleiche Auswahlwahrscheinlichkeit haben), und die Eigenschaften des Speichermangels werden eindeutig durch das Benutzerverhalten bestimmt. Wenn wir auch annehmen, dass die gegebene Kette positiv zurÃ¼ckgegeben und aperiodisch ist (kleine Tricks werden verwendet, um diese Anforderungen zu erfÃ¼llen), dann konvergiert die Wahrscheinlichkeitsverteilung der â€aktuellen Seiteâ€œ auf lange Sicht zu einer stationÃ¤ren Verteilung. Das heiÃŸt, unabhÃ¤ngig von der ersten Seite hat jede Seite nach langer Zeit eine (fast feste) Wahrscheinlichkeit, aktuell zu werden, wenn wir einen zufÃ¤lligen Zeitpunkt wÃ¤hlen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der PageRank basiert auf der folgenden Hypothese: Die wahrscheinlichsten Seiten in einer stationÃ¤ren Verteilung sollten auch die wichtigsten sein (wir besuchen diese Seiten hÃ¤ufig, da sie Links von Seiten erhalten, die auch wÃ¤hrend ÃœbergÃ¤ngen hÃ¤ufig besucht werden). </font><font style="vertical-align: inherit;">Dann bestimmt die stationÃ¤re Wahrscheinlichkeitsverteilung den PageRank-Wert fÃ¼r jeden Zustand.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> KÃ¼nstliches Beispiel </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dies viel klarer zu machen, schauen wir uns ein kÃ¼nstliches Beispiel an. </font><font style="vertical-align: inherit;">Angenommen, wir haben eine winzige Website mit 7 Seiten mit den Bezeichnungen 1 bis 7, und die Links zwischen diesen Seiten entsprechen der folgenden Spalte.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84a/01a/072/84a01a0729fb1a772e89f2fa6c257a7d.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aus GrÃ¼nden der Klarheit sind die Wahrscheinlichkeiten jedes Ãœbergangs in der oben gezeigten Animation nicht gezeigt. </font><font style="vertical-align: inherit;">Da jedoch davon ausgegangen wird, dass â€Navigationâ€œ ausschlieÃŸlich zufÃ¤llig sein sollte (dies wird als â€zufÃ¤lliges Gehenâ€œ bezeichnet), kÃ¶nnen die Werte leicht anhand der folgenden einfachen Regel reproduziert werden: FÃ¼r eine Site mit K ausgehenden Links (Seite mit K Links zu anderen Seiten) die Wahrscheinlichkeit jedes ausgehenden Links gleich 1 / K. </font><font style="vertical-align: inherit;">Das heiÃŸt, die Ãœbergangswahrscheinlichkeitsmatrix hat die Form:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b30/3ec/a66/b303eca66763a4187d027842214ff529.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wobei die Werte von 0,0 der Einfachheit halber durch "." ersetzt werden. </font><font style="vertical-align: inherit;">Bevor wir weitere Berechnungen durchfÃ¼hren, kÃ¶nnen wir feststellen, dass diese Markov-Kette nicht zusammensetzbar und aperiodisch ist, dh auf lange Sicht konvergiert das System zu einer stationÃ¤ren Verteilung. </font><font style="vertical-align: inherit;">Wie wir gesehen haben, kann diese stationÃ¤re Verteilung berechnet werden, indem das folgende Problem des linken Eigenvektors gelÃ¶st wird</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e2f/8da/687/e2f8da6879f6f19fdc921803c8c7e371.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Auf diese Weise erhalten wir fÃ¼r jede Seite die folgenden PageRank-Werte (stationÃ¤re Verteilungswerte) </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0a8/b69/a5b/0a8b69a5b2916bca1f5fa45955af1b4b.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PageRank-Werte berechnet fÃ¼r unser kÃ¼nstliches Beispiel von 7 Seiten. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dann ist das PageRank-Ranking dieser winzigen Website 1&gt; 7&gt; 4&gt; 2&gt; 5 = 6&gt; 3.</font></font><br><br><hr><br><h3>  Schlussfolgerungen </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wichtigste Ergebnisse aus diesem Artikel: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Zufallsprozesse sind SÃ¤tze von Zufallsvariablen, die hÃ¤ufig nach Zeit indiziert sind (Indizes geben hÃ¤ufig diskrete oder kontinuierliche Zeit an). </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> FÃ¼r einen zufÃ¤lligen Prozess bedeutet die Markov-Eigenschaft, dass fÃ¼r einen bestimmten Strom die Wahrscheinlichkeit der Zukunft nicht von der Vergangenheit abhÃ¤ngt (diese Eigenschaft wird auch als â€Speichermangelâ€œ bezeichnet). </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Die zeitdiskrete Markov-Kette besteht aus zufÃ¤lligen Prozessen mit zeitdiskreten Indizes, die die Markov-Eigenschaft erfÃ¼llen </font></font></li><li>                 (  ,  â€¦) </li><li>     PageRank ( )    -,       ;          ( ,             ,  ,      ) </li></ul><br>     ,         ,    .         , ,    (   ,             ,     ),   (   -            ),   (   ),   (           ),     . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NatÃ¼rlich sind die enormen MÃ¶glichkeiten, die Markov-Ketten im Hinblick auf Modellierung und Berechnung bieten, viel grÃ¶ÃŸer als die in dieser bescheidenen Ãœbersicht berÃ¼cksichtigten. </font><font style="vertical-align: inherit;">Wir hoffen daher, dass wir das Interesse des Lesers wecken konnten, diese Tools weiter zu untersuchen, die einen wichtigen Platz im Arsenal eines Wissenschaftlers und Datenexperten einnehmen.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de455762/">https://habr.com/ru/post/de455762/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455746/index.html">Celesta 7.x: ORM, Migration und Testen "in einem Paket"</a></li>
<li><a href="../de455754/index.html">Tests eines treibenden Stratostaten. Start von Rogozin und LoRa in die StratosphÃ¤re</a></li>
<li><a href="../de455756/index.html">Ist [Gunst] th</a></li>
<li><a href="../de455758/index.html">Wachstumshacking bei Retail Rocket: Von der Hypothesensuche bis zu Testtechniken</a></li>
<li><a href="../de455760/index.html">Die Magie von SwiftUI oder Ã¼ber Funktionsersteller</a></li>
<li><a href="../de455764/index.html">Verspottend genaue, schnelle und leichte Barcode-Suche durch semantische Segmentierung</a></li>
<li><a href="../de455768/index.html">Wesentliche SEO-Faktoren vor Ort</a></li>
<li><a href="../de455770/index.html">AERODISK: Warten vs. RealitÃ¤t</a></li>
<li><a href="../de455774/index.html">Flugzeuggasturbinentriebwerke</a></li>
<li><a href="../de455784/index.html">Aufgrund dessen ist Dunkelgrau in CSS heller als Grau</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
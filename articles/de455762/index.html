<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌺 🛌🏽 💖 Eine kurze Einführung in Markov-Ketten 🚵🏼 🚇 🥖</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im Jahr 1998 veröffentlichten Lawrence Page, Sergey Brin, Rajiv Motwani und Terry Vinograd den Artikel „Das PageRank-Zitierranking: Ordnung ins Web br...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Eine kurze Einführung in Markov-Ketten</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455762/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84a/01a/072/84a01a0729fb1a772e89f2fa6c257a7d.gif" alt="Bild"></div><br>  Im Jahr 1998 veröffentlichten Lawrence Page, Sergey Brin, Rajiv Motwani und Terry Vinograd den Artikel „Das PageRank-Zitierranking: Ordnung ins Web bringen“, in dem der mittlerweile berühmte PageRank-Algorithmus beschrieben wurde, der zur Grundlage von Google wurde.  Nach etwas weniger als zwei Jahrzehnten wurde Google ein Riese, und obwohl sich sein Algorithmus stark weiterentwickelt hat, ist PageRank immer noch das „Symbol“ für Google-Ranking-Algorithmen (obwohl nur wenige Menschen wirklich sagen können, wie viel Gewicht der Algorithmus heute benötigt). . <br><br>  Aus theoretischer Sicht ist es interessant festzustellen, dass eine der Standardinterpretationen des PageRank-Algorithmus auf einem einfachen, aber grundlegenden Konzept von Markov-Ketten basiert.  Aus dem Artikel werden wir sehen, dass Markov-Ketten leistungsstarke Werkzeuge für die stochastische Modellierung sind, die für jeden Datenwissenschaftler nützlich sein können.  Insbesondere werden wir solche grundlegenden Fragen beantworten: Was sind Markov-Ketten, welche guten Eigenschaften besitzen sie und was kann mit ihrer Hilfe getan werden? <br><a name="habracut"></a><br><h4>  Kurzer Rückblick </h4><br>  Im ersten Abschnitt geben wir die grundlegenden Definitionen an, die zum Verständnis der Markov-Ketten erforderlich sind.  Im zweiten Abschnitt betrachten wir den Sonderfall von Markov-Ketten in einem endlichen Zustandsraum.  Im dritten Abschnitt betrachten wir einige der elementaren Eigenschaften von Markov-Ketten und veranschaulichen diese Eigenschaften anhand vieler kleiner Beispiele.  Schließlich verknüpfen wir im vierten Abschnitt die Markov-Ketten mit dem PageRank-Algorithmus und sehen anhand eines künstlichen Beispiels, wie Markov-Ketten zum Einordnen der Knoten eines Graphen verwendet werden können. <br><br><blockquote>  <strong>Hinweis</strong>  Um diesen Beitrag zu verstehen, müssen Sie die Grundlagen der Wahrscheinlichkeit und der linearen Algebra kennen.  Insbesondere werden die folgenden Konzepte verwendet: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">bedingte Wahrscheinlichkeit</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">Eigenvektor</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">Formel mit voller Wahrscheinlichkeit</a> . </blockquote><br><hr><br><h3>  Was sind Markov-Ketten? </h3><br><h4>  Zufallsvariablen und zufällige Prozesse </h4><br>  Bevor wir das Konzept der Markov-Ketten einführen, erinnern wir uns kurz an die grundlegenden, aber wichtigen Konzepte der Wahrscheinlichkeitstheorie. <br><br>  Erstens ist eine <strong>Zufallsvariable</strong> X außerhalb der Sprache der Mathematik eine Größe, die durch das Ergebnis eines Zufallsphänomens bestimmt wird.  Das Ergebnis kann eine Zahl (oder "Ähnlichkeit einer Zahl", beispielsweise Vektoren) oder etwas anderes sein.  Zum Beispiel können wir eine Zufallsvariable als Ergebnis eines Würfelwurfs (Zahl) oder als Ergebnis eines Münzwurfs definieren (keine Zahl, es sei denn, wir bezeichnen beispielsweise "Adler" als 0, aber "Schwänze" als 1).  Wir erwähnen auch, dass der Raum möglicher Ergebnisse einer Zufallsvariablen diskret oder stetig sein kann: Beispielsweise ist eine normale Zufallsvariable stetig und eine Poisson-Zufallsvariable diskret. <br><br>  Ferner können wir einen <strong>zufälligen Prozess</strong> (auch als stochastisch bezeichnet) als eine Menge von Zufallsvariablen definieren, die durch die Menge T indiziert werden, die häufig unterschiedliche Zeitpunkte bezeichnet (im Folgenden werden wir dies annehmen).  Die beiden häufigsten Fälle: T kann entweder eine Menge natürlicher Zahlen (zufälliger Prozess mit diskreter Zeit) oder eine Menge reeller Zahlen (zufälliger Prozess mit kontinuierlicher Zeit) sein.  Wenn wir beispielsweise jeden Tag eine Münze werfen, legen wir einen zufälligen Prozess mit diskreter Zeit fest, und der sich ständig ändernde Wert einer Option an der Börse legt einen zufälligen Prozess mit kontinuierlicher Zeit fest.  Zufällige Variablen zu verschiedenen Zeitpunkten können unabhängig voneinander sein (ein Beispiel mit einem Münzwurf) oder eine gewisse Abhängigkeit aufweisen (ein Beispiel mit dem Optionswert).  Darüber hinaus können sie einen kontinuierlichen oder diskreten Zustandsraum haben (den Raum möglicher Ergebnisse zu jedem Zeitpunkt). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/31e/ada/2f8/31eada2f80d66f0df4c007ec8da11579.jpg"></div><br>  <i>Verschiedene Arten von Zufallsprozessen (diskret / kontinuierlich in Raum / Zeit).</i> <br><br><h4>  Markov-Eigenschaft und Markov-Kette </h4><br>  Es gibt bekannte Familien zufälliger Prozesse: Gaußsche Prozesse, Poisson-Prozesse, autoregressive Modelle, Modelle mit gleitendem Durchschnitt, Markov-Ketten und andere.  Jeder dieser Einzelfälle hat bestimmte Eigenschaften, die es uns ermöglichen, sie besser zu untersuchen und zu verstehen. <br><br>  Eine der Eigenschaften, die das Studium eines zufälligen Prozesses erheblich vereinfacht, ist die Markov-Eigenschaft.  Wenn wir es in einer sehr informellen Sprache erklären, sagt uns die Markov-Eigenschaft, dass wir, wenn wir den Wert kennen, der durch einen zufälligen Prozess zu einem bestimmten Zeitpunkt erhalten wird, keine zusätzlichen Informationen über das zukünftige Verhalten des Prozesses erhalten und andere Informationen über seine Vergangenheit sammeln.  In einer mathematischeren Sprache: Zu jedem Zeitpunkt hängt die bedingte Verteilung zukünftiger Zustände eines Prozesses mit gegebenen aktuellen und vergangenen Zuständen nur vom aktuellen Zustand ab und nicht von vergangenen Zuständen (die <strong>Eigenschaft des Speichermangels</strong> ).  Ein zufälliger Prozess mit einer Markov-Eigenschaft wird als <strong>Markov-Prozess bezeichnet</strong> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/44f/1ba/f48/44f1baf48ceb669e0416489eea2bae35.png"></div><br>  <i>Die Markov-Eigenschaft bedeutet, dass wir, wenn wir den aktuellen Status zu einem bestimmten Zeitpunkt kennen, keine zusätzlichen Informationen über die Zukunft benötigen, die aus der Vergangenheit stammen.</i> <br><br>  Basierend auf dieser Definition können wir die Definition von "homogenen Markov-Ketten mit diskreter Zeit" formulieren (im Folgenden werden wir sie der Einfachheit halber "Markov-Ketten" nennen).  <strong>Die Markov-Kette</strong> ist ein Markov-Prozess mit diskreter Zeit und einem diskreten Zustandsraum.  Eine Markov-Kette ist also eine diskrete Folge von Zuständen, von denen jeder aus einem diskreten Zustandsraum (endlich oder unendlich) stammt und die Markov-Eigenschaft erfüllt. <br><br>  Mathematisch können wir die Markov-Kette wie folgt bezeichnen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/114/3b7/fc3/1143b7fc371f3142534c2b886bf3e69c.png"></div><br>  wobei zu jedem Zeitpunkt der Prozess seine Werte aus einer diskreten Menge E bezieht, so dass <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/886/a22/d76/886a22d7671798102ee3d94fe9868b81.png"></div><br>  Dann impliziert die Markov-Eigenschaft, dass wir haben <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/edc/8bf/384/edc8bf38422705e72c9dd7d094b249db.png"></div><br>  Beachten Sie erneut, dass diese letzte Formel die Tatsache widerspiegelt, dass für die Chronologie (wo ich jetzt bin und wo ich vorher war) die Wahrscheinlichkeitsverteilung des nächsten Zustands (wo ich der nächste sein werde) vom aktuellen Zustand abhängt, jedoch nicht von früheren Zuständen. <br><br><blockquote>  <strong>Hinweis</strong>  In diesem Einführungsbeitrag haben wir beschlossen, nur über einfache homogene Markov-Ketten mit diskreter Zeit zu sprechen.  Es gibt jedoch auch inhomogene (zeitabhängige) Markov-Ketten und / oder zeitkontinuierliche Ketten.  In diesem Artikel werden solche Variationen des Modells nicht berücksichtigt.  Es ist auch erwähnenswert, dass die obige Definition einer Markov-Eigenschaft extrem vereinfacht ist: Die wahre mathematische Definition verwendet das Konzept der Filterung, das weit über unsere einführende Kenntnis des Modells hinausgeht. </blockquote><br><h4>  Wir charakterisieren die Zufallsdynamik einer Markov-Kette </h4><br>  Im vorherigen Unterabschnitt haben wir die allgemeine Struktur einer Markov-Kette kennengelernt.  Mal sehen, was wir brauchen, um eine bestimmte "Instanz" eines solchen zufälligen Prozesses festzulegen. <br><br>  Zunächst stellen wir fest, dass die vollständige Bestimmung der Eigenschaften eines zufälligen Prozesses mit diskreter Zeit, die die Markov-Eigenschaft nicht erfüllt, schwierig sein kann: Die Wahrscheinlichkeitsverteilung zu einem bestimmten Zeitpunkt kann von einem oder mehreren Momenten in der Vergangenheit und / oder Zukunft abhängen.  All diese möglichen Zeitabhängigkeiten können möglicherweise die Erstellung einer Prozessdefinition erschweren. <br><br>  Aufgrund der Markov-Eigenschaft ist die Dynamik der Markov-Kette jedoch recht einfach zu bestimmen.  Und in der Tat.  wir müssen nur zwei Aspekte bestimmen: die <strong>anfängliche Wahrscheinlichkeitsverteilung</strong> (d. h. die Wahrscheinlichkeitsverteilung zum Zeitpunkt n = 0), bezeichnet mit <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/595/90e/140/59590e140cdb348c943d9dcab0ea011d.png"></div><br>  und <strong>die Übergangswahrscheinlichkeitsmatrix</strong> (die uns die Wahrscheinlichkeiten gibt, dass der Zustand zum Zeitpunkt n + 1 der nächste für einen anderen Zustand zum Zeitpunkt n für ein beliebiges Zustandspaar ist), bezeichnet mit <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/011/aee/574/011aee5747fe7e42fa09bf044c421e26.png"></div><br>  Wenn diese beiden Aspekte bekannt sind, ist die vollständige (probabilistische) Dynamik des Prozesses klar definiert.  Tatsächlich kann die Wahrscheinlichkeit eines Ergebnisses des Prozesses dann zyklisch berechnet werden. <br><br>  Beispiel: Angenommen, wir möchten die Wahrscheinlichkeit wissen, dass die ersten drei Zustände des Prozesses Werte haben (s0, s1, s2).  Das heißt, wir wollen die Wahrscheinlichkeit berechnen <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6c5/991/81b/6c599181b1fd3892391711f311878b72.png"></div><br>  Hier wenden wir die Formel für die Gesamtwahrscheinlichkeit an, die besagt, dass die Wahrscheinlichkeit des Erhaltens (s0, s1, s2) gleich der Wahrscheinlichkeit des Erhaltens des ersten s0-fachen der Wahrscheinlichkeit des Erhaltens von s1 ist, vorausgesetzt, wir haben zuvor das s0-fache der Wahrscheinlichkeit des Erhaltens von s2 unter Berücksichtigung der Tatsache erhalten, dass wir haben früher in der Reihenfolge s0 und s1.  Mathematisch kann dies geschrieben werden als <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a46/da3/64f/a46da364f28d5b69055700759db02663.png"></div><br>  Und dann wird eine Vereinfachung offenbart, die durch die Markov-Annahme bestimmt wird.  Tatsächlich erhalten wir bei langen Ketten stark bedingte Wahrscheinlichkeiten für die letzteren Zustände.  Im Fall von Markov-Ketten können wir diesen Ausdruck jedoch vereinfachen, indem wir die Tatsache ausnutzen, dass <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0ab/7f6/568/0ab7f6568e28bb562ebb287252422d51.png"></div><br>  auf diese Weise bekommen <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b6c/700/30a/b6c70030a8627d87c39dab96c147513a.png"></div><br>  Da sie die probabilistische Dynamik des Prozesses vollständig charakterisieren, können viele komplexe Ereignisse nur auf der Grundlage der anfänglichen Wahrscheinlichkeitsverteilung q0 und der Übergangswahrscheinlichkeitsmatrix p berechnet werden.  Erwähnenswert ist auch eine weitere grundlegende Verbindung: der Ausdruck der Wahrscheinlichkeitsverteilung zum Zeitpunkt n + 1, ausgedrückt in Bezug auf die Wahrscheinlichkeitsverteilung zum Zeitpunkt n <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5ae/f31/a8a/5aef31a8ae120a25e5b43d6534dc20ff.png"></div><br><h3>  Markov-Ketten in endlichen Zustandsräumen </h3><br><h4>  Matrix- und Graphendarstellung </h4><br>  Hier nehmen wir an, dass die Menge E eine endliche Anzahl möglicher Zustände N hat: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d57/788/f81/d57788f81d0a92aa1d94ef572bdf25e3.png"></div><br>  Dann kann die anfängliche Wahrscheinlichkeitsverteilung als <strong>ein Zeilenvektor</strong> q0 der Größe N beschrieben werden, und Übergangswahrscheinlichkeiten können als eine Matrix p der Größe N durch N beschrieben werden, so dass <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/100/6f8/6ae/1006f86aeff6699711058bd890190917.png"></div><br>  Der Vorteil dieser Notation besteht darin, dass wir die Wahrscheinlichkeitsverteilung in Schritt n durch den Zeilenvektor qn so bezeichnen, dass seine Komponenten spezifiziert werden <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/006/19b/4ae/00619b4ae1601eacdb8fd7ce248f1738.png"></div><br>  dann bleiben einfache Matrixrelationen erhalten <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a12/cdc/a7b/a12cdca7b75ef09ceaacef33a3667549.png"></div><br>  (hier werden wir den Beweis nicht betrachten, aber es ist sehr einfach, ihn zu reproduzieren). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/23c/3c6/a10/23c3c6a102bd7aa079c36a75f60a5e42.png"></div><br>  <i>Wenn wir den Zeilenvektor rechts, der die Wahrscheinlichkeitsverteilung zu einem bestimmten Zeitpunkt beschreibt, mit der Übergangswahrscheinlichkeitsmatrix multiplizieren, erhalten wir die Wahrscheinlichkeitsverteilung zum nächsten Zeitpunkt.</i> <br><br>  Wie wir sehen, wird der Übergang der Wahrscheinlichkeitsverteilung von einer gegebenen Stufe zur nächsten einfach als die richtige Multiplikation des Zeilenvektors der Wahrscheinlichkeiten des Anfangsschritts mit der Matrix p definiert.  Darüber hinaus impliziert dies, dass wir haben <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/35b/072/e0c/35b072e0c74397094e5bf6a9dab11417.png"></div><br>  Die zufällige Dynamik einer Markov-Kette in einem endlichen Zustandsraum kann leicht als normalisierter orientierter Graph dargestellt werden, so dass jeder Knoten des Graphen ein Zustand ist und für jedes Zustandspaar (ei, ej) eine Kante existiert, die von ei nach ej geht, wenn p (ei, ej) )&gt; 0.  Dann ist der Kantenwert die gleiche Wahrscheinlichkeit p (ei, ej). <br><br><h4>  Beispiel: ein Leser unserer Website </h4><br>  Lassen Sie uns dies alles anhand eines einfachen Beispiels veranschaulichen.  Betrachten Sie das alltägliche Verhalten eines fiktiven Besuchers einer Site.  Jeden Tag hat er drei mögliche Bedingungen: Der Leser besucht die Site an diesem Tag nicht (N), der Leser besucht die Site, liest jedoch nicht den gesamten Beitrag (V), und der Leser besucht die Site und liest einen gesamten Post (R).  Wir haben also den folgenden Zustandsraum: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/242/b1c/627/242b1c62745a4a13f2a24b8f919c6820.png"></div><br>  Angenommen, dieser Leser hat am ersten Tag eine 50% ige Chance, nur auf die Site zuzugreifen, und eine 50% ige Chance, die Site zu besuchen und mindestens einen Artikel zu lesen.  Der Vektor, der die anfängliche Wahrscheinlichkeitsverteilung beschreibt (n = 0), sieht dann folgendermaßen aus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/362/a5a/045/362a5a0455c939f9d855d65605945c90.png"></div><br>  Stellen Sie sich auch vor, dass die folgenden Wahrscheinlichkeiten eingehalten werden: <br><br><ul><li>  Wenn der Leser einen Tag nicht besucht, besteht eine Wahrscheinlichkeit von 25%, ihn am nächsten Tag nicht zu besuchen, eine Wahrscheinlichkeit von 50%, ihn nur zu besuchen, und eine Wahrscheinlichkeit von 25%, den Artikel zu besuchen und zu lesen </li><li>  Wenn der Leser die Website eines Tages besucht, aber nicht liest, hat er eine 50% ige Chance, sie am nächsten Tag erneut zu besuchen und den Artikel nicht zu lesen, und eine 50% ige Chance, sie zu besuchen und zu lesen </li><li>  Wenn ein Leser einen Artikel am selben Tag besucht und liest, hat er eine 33% ige Chance, sich am nächsten Tag nicht anzumelden <em>(ich hoffe, dieser Beitrag hat keinen solchen Effekt!)</em> , eine 33% ige Chance, sich nur auf der Website anzumelden, und 34%, den Artikel erneut zu besuchen und zu lesen </li></ul><br>  Dann haben wir die folgende Übergangsmatrix: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cf5/7e6/ba5/cf57e6ba5303d4e13cbb736e6115306d.png"></div><br>  Aus dem vorherigen Unterabschnitt wissen wir, wie wir für diesen Leser die Wahrscheinlichkeit jedes Zustands am nächsten Tag berechnen können (n = 1). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c64/a77/76c/c64a7776cfc56a5af1a0ccf495469ef7.png"></div><br>  Die probabilistische Dynamik dieser Markov-Kette kann wie folgt grafisch dargestellt werden: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/832/797/9a1/8327979a1aa6edd9d462a0b40a4c072d.png"></div><br>  <i>Präsentation in Form eines Diagramms der Markov-Kette, das das Verhalten unseres erfundenen Besuchers der Website modelliert.</i> <br><br><h3>  Eigenschaften von Markov-Ketten </h3><br>  In diesem Abschnitt werden wir nur auf einige der grundlegendsten Eigenschaften oder Merkmale von Markov-Ketten eingehen.  Wir werden nicht auf mathematische Details eingehen, sondern einen kurzen Überblick über interessante Punkte geben, die untersucht werden müssen, um Markov-Ketten zu verwenden.  Wie wir gesehen haben, kann im Fall eines endlichen Zustandsraums die Markov-Kette als Graph dargestellt werden.  In Zukunft werden wir die grafische Darstellung verwenden, um einige Eigenschaften zu erklären.  Vergessen Sie jedoch nicht, dass diese Eigenschaften nicht unbedingt auf den Fall eines endlichen Zustandsraums beschränkt sind. <br><br><h4>  Zersetzbarkeit, Periodizität, Unwiderruflichkeit und Wiederherstellbarkeit </h4><br>  Beginnen wir in diesem Unterabschnitt mit mehreren klassischen Methoden zur Charakterisierung eines Zustands oder einer gesamten Markov-Kette. <br><br>  Zunächst erwähnen wir, dass die Markov-Kette nicht zusammensetzbar ist, wenn es möglich ist, einen Zustand von einem anderen Zustand aus zu erreichen (dies ist nicht in einem Schritt erforderlich).  Wenn der Zustandsraum endlich ist und die Kette als Graph dargestellt werden kann, können wir sagen, dass der Graph einer nicht zusammensetzbaren Markov-Kette stark verbunden ist (Graphentheorie). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cef/a39/05c/cefa3905cced27b4e27a4e9547fbe846.png"></div><br>  <i>Darstellung der Eigenschaft der Unzusammensetzbarkeit (Irreduzibilität).</i>  <i>Die Kette links kann nicht gekürzt werden: von 3 oder 4 können wir nicht in 1 oder 2 gelangen. Die Kette rechts (eine Kante wird hinzugefügt) kann gekürzt werden: Jeder Zustand kann von jedem anderen aus erreicht werden.</i> <br><br>  Ein Zustand hat eine Periode k, wenn beim Verlassen für eine Rückkehr in diesen Zustand die Anzahl der Zeitschritte ein Vielfaches von k ist (k ist der größte gemeinsame Teiler aller möglichen Längen von Rückkehrpfaden).  Wenn k = 1 ist, sagen sie, dass der Zustand aperiodisch ist und die gesamte Markov-Kette <strong>aperiodisch ist,</strong> wenn alle ihre Zustände aperiodisch sind.  Im Fall einer irreduziblen Markov-Kette können wir auch erwähnen, dass, wenn ein Zustand aperiodisch ist, alle anderen ebenfalls aperiodisch sind. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cbe/65f/a07/cbe65fa07e7b816d385408824ba0ff39.png"></div><br>  <i>Darstellung der Periodizitätseigenschaft.</i>  <i>Die Kette links ist periodisch mit k = 2: Wenn Sie einen Zustand verlassen, erfordert die Rückkehr immer die Anzahl der Schritte multipliziert mit 2. Die Kette rechts hat eine Periode von 3.</i> <br><br>  Ein Staat ist <strong>unwiderruflich,</strong> wenn beim Verlassen des Staates eine Wahrscheinlichkeit ungleich Null besteht, dass wir niemals zu ihm zurückkehren werden.  Umgekehrt gilt ein Staat als <strong>rückzahlbar,</strong> wenn wir wissen, dass wir nach Verlassen des Staates in Zukunft mit Wahrscheinlichkeit 1 zu ihm zurückkehren können (wenn er nicht unwiderruflich ist). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6a0/1ad/7b0/6a01ad7b05e96f5a6606a8a48d127233.png"></div><br>  <i>Abbildung der Rückgabe- / Unwiderruflichkeitseigenschaft.</i>  <i>Die Kette auf der linken Seite hat die folgenden Eigenschaften: 1, 2 und 3 sind unwiderruflich (wenn wir diese Punkte verlassen, können wir nicht absolut sicher sein, dass wir zu ihnen zurückkehren) und haben eine Periode von 3, und 4 und 5 sind rückzahlbar (wenn wir diese Punkte verlassen, sind wir absolut sicher dass wir eines Tages zu ihnen zurückkehren werden) und eine Periode von 2 haben. Die Kette auf der rechten Seite hat eine weitere Rippe, wodurch die gesamte Kette rückzahlbar und aperiodisch wird.</i> <br><br>  Für den Rückgabezustand können wir die durchschnittliche Rückgabezeit berechnen, die die <strong>erwartete Rückgabezeit</strong> beim Verlassen des Zustands ist.  Beachten Sie, dass selbst die Wahrscheinlichkeit einer Rückgabe 1 beträgt. Dies bedeutet nicht, dass die erwartete Rückgabezeit endlich ist.  Daher können wir unter allen Rückkehrzuständen zwischen <strong>positiven Rückkehrzuständen</strong> (mit einer endlichen erwarteten Rückkehrzeit) und <strong>Null-Rückkehrzuständen</strong> (mit einer unendlichen erwarteten Rückkehrzeit) unterscheiden. <br><br><h4>  Stationäre Verteilung, Randverhalten und Ergodizität </h4><br>  In diesem Unterabschnitt betrachten wir Eigenschaften, die einige Aspekte der (zufälligen) Dynamik charakterisieren, die von der Markov-Kette beschrieben wird. <br><br>  Die Wahrscheinlichkeitsverteilung π über den Zustandsraum E wird als <strong>stationäre Verteilung bezeichnet,</strong> wenn sie den Ausdruck erfüllt <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/736/d70/e5d/736d70e5ddfc5aeb788d29ebfa79f9ec.png"></div><br>  Da haben wir <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b98/c4e/e6c/b98c4ee6c3b8032b074c7543db816c7e.png"></div><br>  Dann erfüllt die stationäre Verteilung den Ausdruck <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b8/df4/0a8/2b8df40a8a9a2ae90eb49a7c60dafb55.png"></div><br>  Per Definition ändert sich die stationäre Wahrscheinlichkeitsverteilung nicht über die Zeit.  Das heißt, wenn die Anfangsverteilung q stationär ist, ist sie in allen nachfolgenden Zeitstufen gleich.  Wenn der Zustandsraum endlich ist, kann p als Matrix und π als Zeilenvektor dargestellt werden, und dann erhalten wir <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ee0/565/9fc/ee05659fc4ed268ee3189342a76d9311.png"></div><br>  Dies drückt erneut die Tatsache aus, dass sich die stationäre Wahrscheinlichkeitsverteilung nicht mit der Zeit ändert (wie wir sehen, können wir durch Multiplizieren der Wahrscheinlichkeitsverteilung rechts mit p die Wahrscheinlichkeitsverteilung in der nächsten Zeitstufe berechnen).  Beachten Sie, dass eine nicht zusammensetzbare Markov-Kette genau dann eine stationäre Wahrscheinlichkeitsverteilung aufweist, wenn einer ihrer Zustände eine positive Rendite aufweist. <br><br>  Eine weitere interessante Eigenschaft im Zusammenhang mit der stationären Wahrscheinlichkeitsverteilung ist wie folgt.  Wenn die Kette eine positive Rendite (dh eine stationäre Verteilung) und eine aperiodische Verteilung aufweist, konvergiert die Wahrscheinlichkeitsverteilung der Kette unabhängig von den anfänglichen Wahrscheinlichkeiten, wenn die Zeitintervalle gegen unendlich tendieren: Sie sagen, dass die Kette eine <strong>begrenzende Verteilung hat</strong> , was nichts anderes ist. als stationäre Verteilung.  Im Allgemeinen kann es so geschrieben werden: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/95b/fb9/1c6/95bfb91c67d024e2df40b0e6dcdaf747.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir betonen noch einmal, dass wir keine Annahmen über die anfängliche Wahrscheinlichkeitsverteilung treffen: Die Wahrscheinlichkeitsverteilung der Kette reduziert sich unabhängig von den Anfangsparametern auf eine stationäre Verteilung (Gleichgewichtsverteilung der Kette). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schließlich ist </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ergodizität</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> eine weitere interessante Eigenschaft im Zusammenhang mit dem Verhalten der Markov-Kette. Wenn die Markov-Kette nicht zusammensetzbar ist, wird auch gesagt, dass sie „ergodisch“ ist, weil sie den folgenden ergodischen Satz erfüllt. Angenommen, wir haben eine Funktion f (.), Die vom Zustandsraum E zur Achse geht (dies kann zum Beispiel der Preis sein, in jedem Zustand zu sein). Wir können den Durchschnittswert bestimmen, der diese Funktion entlang einer bestimmten Trajektorie bewegt (zeitlicher Durchschnitt). Für den n-ten ersten Term wird dies als bezeichnet</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/af1/8c5/4a3/af18c54a3d7dc1e1ad4a4015ab7ad64c.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wir können auch den Durchschnittswert der Funktion f auf der Menge E berechnen, gewichtet mit der stationären Verteilung (räumlicher Durchschnitt), die bezeichnet wird </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/04a/352/c77/04a352c77b0687ef3cc89f3b7e0edf38.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dann sagt uns der Ergodensatz, dass, wenn die Flugbahn unendlich lang wird, der Zeitmittelwert gleich dem räumlichen Durchschnitt ist (gewichtet mit der stationären Verteilung). </font><font style="vertical-align: inherit;">Die Ergodizitätseigenschaft kann wie folgt geschrieben werden:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/37d/c4d/6cb37dc4dcf0a3e53cc8e6baec8f4b1a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mit anderen Worten bedeutet dies, dass in der früheren Grenze das Verhalten der Trajektorie unbedeutend wird und nur das langfristige stationäre Verhalten bei der Berechnung des zeitlichen Durchschnitts wichtig ist. </font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kehren wir zum Beispiel mit dem Site Reader zurück </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Betrachten Sie erneut das Beispiel des Site-Readers. </font><font style="vertical-align: inherit;">In diesem einfachen Beispiel ist es offensichtlich, dass die Kette nicht zusammensetzbar und aperiodisch ist und alle ihre Zustände positiv zurückgegeben werden können. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um zu zeigen, welche interessanten Ergebnisse mit Markov-Ketten berechnet werden können, betrachten wir die durchschnittliche Zeit der Rückkehr zum Zustand R (der Zustand „besucht die Site und liest den Artikel“). </font><font style="vertical-align: inherit;">Mit anderen Worten, wir möchten die folgende Frage beantworten: Wenn unser Leser eines Tages die Website besucht und einen Artikel liest, wie viele Tage müssen wir dann durchschnittlich warten, bis er zurückkommt und den Artikel liest? </font><font style="vertical-align: inherit;">Versuchen wir, ein intuitives Konzept für die Berechnung dieses Werts zu erhalten. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zuerst bezeichnen wir</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a2/57c/c74/2a257cc74db27e5ac89ffc1e06bd9ed9.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir wollen also m (R, R) berechnen. </font><font style="vertical-align: inherit;">Wenn wir über das erste Intervall sprechen, das nach dem Verlassen von R erreicht wurde, erhalten wir</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f9/e1a/a6e/4f9e1aa6e04e736fde182693398a4dca.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dieser Ausdruck erfordert jedoch, dass wir für die Berechnung von m (R, R) m (N, R) und m (V, R) kennen. </font><font style="vertical-align: inherit;">Diese beiden Größen können auf ähnliche Weise ausgedrückt werden:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e23/7cb/f2d/e237cbf2d81597544f800d38b5a59e91.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wir haben also 3 Gleichungen mit 3 Unbekannten und nach dem Lösen erhalten wir m (N, R) = 2,67, m (V, R) = 2,00 und m (R, R) = 2,54. </font><font style="vertical-align: inherit;">Die durchschnittliche Zeit, um zum Zustand R zurückzukehren, beträgt dann 2,54. </font><font style="vertical-align: inherit;">Das heißt, unter Verwendung der linearen Algebra konnten wir die durchschnittliche Zeit bis zur Rückkehr in den Zustand R berechnen (sowie die durchschnittliche Übergangszeit von N nach R und die durchschnittliche Übergangszeit von V nach R). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lassen Sie uns zum Abschluss dieses Beispiels sehen, wie die stationäre Verteilung der Markov-Kette aussehen wird. </font><font style="vertical-align: inherit;">Um die stationäre Verteilung zu bestimmen, müssen wir die folgende Gleichung der linearen Algebra lösen:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bb3/73d/068/bb373d068a04d681c0501d8276731c0a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das heißt, wir müssen den linken Eigenvektor p finden, der dem Eigenvektor 1 zugeordnet ist. Wenn wir dieses Problem lösen, erhalten wir die folgende stationäre Verteilung: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0c6/abe/19e/0c6abe19e37b67af5f380eb3e5c0beb9.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Stationäre Verteilung im Beispiel mit dem Site Reader. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie können auch feststellen, dass π (R) = 1 / m (R, R) ist, und wenn ein wenig reflektiert wird, dann ist diese Identität ziemlich logisch (aber wir werden nicht im Detail darüber sprechen).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Da die Kette nicht zusammensetzbar und aperiodisch ist, bedeutet dies, dass die Wahrscheinlichkeitsverteilung auf lange Sicht gegen eine stationäre Verteilung konvergiert (für alle Anfangsparameter). Mit anderen Worten, unabhängig vom Ausgangszustand des Lesers der Site erhalten wir, wenn wir lange genug warten und zufällig einen Tag auswählen, die Wahrscheinlichkeit π (N), dass der Leser die Site an diesem Tag nicht besucht, die Wahrscheinlichkeit π (V), dass Der Leser wird vorbeischauen, aber den Artikel nicht lesen, und die Wahrscheinlichkeit ist π®, dass der Leser vorbeischaut und den Artikel liest. Um die Eigenschaft der Konvergenz besser zu verstehen, werfen wir einen Blick auf die folgende Grafik, die die Entwicklung der Wahrscheinlichkeitsverteilungen ausgehend von verschiedenen Startpunkten und (schnell) der Konvergenz zu einer stationären Verteilung zeigt:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/128/58e/a88/12858ea88a0e3bd05950b9d30096b776.jpg"></div><br> <i>  3       (,   )    ().</i> <br><br><h3>  :  PageRank </h3><br>     PageRank!     ,  ,   PageRank,    ,   ,              .     ,   . <br><br><h4>  - </h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PageRank versucht, das folgende Problem zu lösen: Wie ordnen wir einen vorhandenen Satz (wir können davon ausgehen, dass dieser Satz bereits durch eine Abfrage gefiltert wurde) mithilfe von Links, die bereits zwischen den Seiten vorhanden sind? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dieses Problem zu lösen und Seiten ordnen zu können, führt PageRank ungefähr den folgenden Prozess aus. Wir glauben, dass sich ein beliebiger Internetnutzer zum ersten Mal auf einer der Seiten befindet. Dann beginnt dieser Benutzer zufällig, sich zu bewegen, indem er auf jede Seite eines der Links klickt, die zu einer anderen Seite des betreffenden Satzes führen (es wird angenommen, dass alle Links, die außerhalb dieser Seiten führen, verboten sind). Auf jeder Seite haben alle gültigen Links die gleiche Wahrscheinlichkeit zu klicken.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">So definieren wir die Markov-Kette: Seiten sind mögliche Zustände, Übergangswahrscheinlichkeiten werden durch Links von Seite zu Seite festgelegt (so gewichtet, dass auf jeder Seite alle verknüpften Seiten die gleiche Auswahlwahrscheinlichkeit haben), und die Eigenschaften des Speichermangels werden eindeutig durch das Benutzerverhalten bestimmt. Wenn wir auch annehmen, dass die gegebene Kette positiv zurückgegeben und aperiodisch ist (kleine Tricks werden verwendet, um diese Anforderungen zu erfüllen), dann konvergiert die Wahrscheinlichkeitsverteilung der „aktuellen Seite“ auf lange Sicht zu einer stationären Verteilung. Das heißt, unabhängig von der ersten Seite hat jede Seite nach langer Zeit eine (fast feste) Wahrscheinlichkeit, aktuell zu werden, wenn wir einen zufälligen Zeitpunkt wählen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Der PageRank basiert auf der folgenden Hypothese: Die wahrscheinlichsten Seiten in einer stationären Verteilung sollten auch die wichtigsten sein (wir besuchen diese Seiten häufig, da sie Links von Seiten erhalten, die auch während Übergängen häufig besucht werden). </font><font style="vertical-align: inherit;">Dann bestimmt die stationäre Wahrscheinlichkeitsverteilung den PageRank-Wert für jeden Zustand.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Künstliches Beispiel </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um dies viel klarer zu machen, schauen wir uns ein künstliches Beispiel an. </font><font style="vertical-align: inherit;">Angenommen, wir haben eine winzige Website mit 7 Seiten mit den Bezeichnungen 1 bis 7, und die Links zwischen diesen Seiten entsprechen der folgenden Spalte.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84a/01a/072/84a01a0729fb1a772e89f2fa6c257a7d.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Aus Gründen der Klarheit sind die Wahrscheinlichkeiten jedes Übergangs in der oben gezeigten Animation nicht gezeigt. </font><font style="vertical-align: inherit;">Da jedoch davon ausgegangen wird, dass „Navigation“ ausschließlich zufällig sein sollte (dies wird als „zufälliges Gehen“ bezeichnet), können die Werte leicht anhand der folgenden einfachen Regel reproduziert werden: Für eine Site mit K ausgehenden Links (Seite mit K Links zu anderen Seiten) die Wahrscheinlichkeit jedes ausgehenden Links gleich 1 / K. </font><font style="vertical-align: inherit;">Das heißt, die Übergangswahrscheinlichkeitsmatrix hat die Form:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b30/3ec/a66/b303eca66763a4187d027842214ff529.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">wobei die Werte von 0,0 der Einfachheit halber durch "." ersetzt werden. </font><font style="vertical-align: inherit;">Bevor wir weitere Berechnungen durchführen, können wir feststellen, dass diese Markov-Kette nicht zusammensetzbar und aperiodisch ist, dh auf lange Sicht konvergiert das System zu einer stationären Verteilung. </font><font style="vertical-align: inherit;">Wie wir gesehen haben, kann diese stationäre Verteilung berechnet werden, indem das folgende Problem des linken Eigenvektors gelöst wird</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e2f/8da/687/e2f8da6879f6f19fdc921803c8c7e371.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Auf diese Weise erhalten wir für jede Seite die folgenden PageRank-Werte (stationäre Verteilungswerte) </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0a8/b69/a5b/0a8b69a5b2916bca1f5fa45955af1b4b.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PageRank-Werte berechnet für unser künstliches Beispiel von 7 Seiten. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dann ist das PageRank-Ranking dieser winzigen Website 1&gt; 7&gt; 4&gt; 2&gt; 5 = 6&gt; 3.</font></font><br><br><hr><br><h3>  Schlussfolgerungen </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wichtigste Ergebnisse aus diesem Artikel: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Zufallsprozesse sind Sätze von Zufallsvariablen, die häufig nach Zeit indiziert sind (Indizes geben häufig diskrete oder kontinuierliche Zeit an). </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Für einen zufälligen Prozess bedeutet die Markov-Eigenschaft, dass für einen bestimmten Strom die Wahrscheinlichkeit der Zukunft nicht von der Vergangenheit abhängt (diese Eigenschaft wird auch als „Speichermangel“ bezeichnet). </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Die zeitdiskrete Markov-Kette besteht aus zufälligen Prozessen mit zeitdiskreten Indizes, die die Markov-Eigenschaft erfüllen </font></font></li><li>                 (  ,  …) </li><li>     PageRank ( )    -,       ;          ( ,             ,  ,      ) </li></ul><br>     ,         ,    .         , ,    (   ,             ,     ),   (   -            ),   (   ),   (           ),     . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Natürlich sind die enormen Möglichkeiten, die Markov-Ketten im Hinblick auf Modellierung und Berechnung bieten, viel größer als die in dieser bescheidenen Übersicht berücksichtigten. </font><font style="vertical-align: inherit;">Wir hoffen daher, dass wir das Interesse des Lesers wecken konnten, diese Tools weiter zu untersuchen, die einen wichtigen Platz im Arsenal eines Wissenschaftlers und Datenexperten einnehmen.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de455762/">https://habr.com/ru/post/de455762/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de455746/index.html">Celesta 7.x: ORM, Migration und Testen "in einem Paket"</a></li>
<li><a href="../de455754/index.html">Tests eines treibenden Stratostaten. Start von Rogozin und LoRa in die Stratosphäre</a></li>
<li><a href="../de455756/index.html">Ist [Gunst] th</a></li>
<li><a href="../de455758/index.html">Wachstumshacking bei Retail Rocket: Von der Hypothesensuche bis zu Testtechniken</a></li>
<li><a href="../de455760/index.html">Die Magie von SwiftUI oder über Funktionsersteller</a></li>
<li><a href="../de455764/index.html">Verspottend genaue, schnelle und leichte Barcode-Suche durch semantische Segmentierung</a></li>
<li><a href="../de455768/index.html">Wesentliche SEO-Faktoren vor Ort</a></li>
<li><a href="../de455770/index.html">AERODISK: Warten vs. Realität</a></li>
<li><a href="../de455774/index.html">Flugzeuggasturbinentriebwerke</a></li>
<li><a href="../de455784/index.html">Aufgrund dessen ist Dunkelgrau in CSS heller als Grau</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
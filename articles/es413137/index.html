<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶è üöµ ü§ï Clasifique grandes cantidades de datos en Apache Spark utilizando modelos arbitrarios de aprendizaje autom√°tico üôÖ üë©‚Äçüé§ üõ•Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Parte 1: Declaraci√≥n del problema 
 Hola Habr! Soy arquitecto de soluciones en CleverDATA. Hoy hablar√© sobre c√≥mo clasificamos grandes cantidades de d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Clasifique grandes cantidades de datos en Apache Spark utilizando modelos arbitrarios de aprendizaje autom√°tico</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/413137/"><h2>  Parte 1: Declaraci√≥n del problema </h2><br>  Hola Habr!  Soy arquitecto de soluciones en CleverDATA.  Hoy hablar√© sobre c√≥mo clasificamos grandes cantidades de datos usando modelos construidos usando casi cualquier biblioteca de aprendizaje autom√°tico disponible.  En esta serie de dos partes, consideraremos las siguientes preguntas. <br><br><ul><li>  ¬øC√≥mo presentar un modelo de aprendizaje autom√°tico como servicio (Modelo como servicio)? </li><li>  ¬øC√≥mo se realizan f√≠sicamente las tareas de procesamiento distribuido de grandes cantidades de datos con Apache Spark? </li><li>  ¬øQu√© problemas surgen cuando Apache Spark interact√∫a con servicios externos? </li><li>  ¬øC√≥mo se puede organizar la interacci√≥n Apache Spark con servicios externos utilizando las bibliotecas akka-streams y akka-http, as√≠ como el enfoque de Reactive Streams? </li></ul><br>  Inicialmente, plane√© escribir un art√≠culo, pero como el volumen de material result√≥ ser bastante grande, decid√≠ dividirlo en dos partes.  Hoy, en la primera parte, consideraremos el enunciado general del problema, as√≠ como los problemas principales que deben resolverse durante la implementaci√≥n.  En la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">segunda parte,</a> hablaremos sobre la implementaci√≥n pr√°ctica de la soluci√≥n a este problema utilizando el enfoque de Reactive Streams. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/8g/p2/pv8gp2gxotjij6hjkkirlllzlii.png"></div><a name="habracut"></a><br>  Nuestra empresa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CleverDATA</a> cuenta con un equipo de analistas de datos que, con la ayuda de una amplia gama de herramientas (como scikit-learn, facebook fastText, xgboost, tensorFlow, etc.), capacitan modelos de aprendizaje autom√°tico.  El lenguaje de programaci√≥n central de facto que usan los analistas es Python.  Casi todas las bibliotecas para el aprendizaje autom√°tico, incluso implementadas originalmente en otros idiomas, tienen una interfaz en Python y est√°n integradas con las bibliotecas principales de Python (principalmente con NumPy). <br><br>  Por otro lado, el ecosistema Hadoop se usa ampliamente para almacenar y procesar grandes cantidades de datos no estructurados.  En √©l, los datos se almacenan en el sistema de archivos HDFS en forma de bloques distribuidos replicados de cierto tama√±o (generalmente 128 MB, pero es posible configurarlo).  Los algoritmos de procesamiento de datos distribuidos m√°s eficientes intentan minimizar la interacci√≥n de red entre m√°quinas de cl√∫ster.  Para hacer esto, los datos deben procesarse en las mismas m√°quinas donde se almacenan. <br><br>  Por supuesto, en muchos casos, la interacci√≥n de la red no se puede evitar por completo, pero, sin embargo, debe intentar realizar todas las tareas localmente y minimizar la cantidad de datos que deber√°n transmitirse a trav√©s de la red. <br><br>  Este principio de procesamiento de datos distribuidos se denomina "mover c√°lculos cerca de los datos".  Todos los marcos principales, principalmente Hadoop MapReduce y Apache Spark, se adhieren a este principio.  Determinan la composici√≥n y secuencia de operaciones espec√≠ficas que deber√°n ejecutarse en m√°quinas donde se almacenan los bloques de datos necesarios. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qs/os/nw/qsosnwsibgwo5ajbmzg-v4la7m0.png"></div>  <i>Figura 1. El cl√∫ster HDFS consta de varias m√°quinas, una de las cuales es un Nodo de nombre y el resto es un Nodo de datos.</i>  <i>Name Node almacena informaci√≥n sobre los archivos que componen sus bloques y sobre las m√°quinas donde se encuentran f√≠sicamente.</i>  <i>Los bloques mismos se almacenan en el nodo de datos, que se replican en varias m√°quinas para aumentar la confiabilidad.</i>  <i>El nodo de datos tambi√©n ejecuta tareas de procesamiento de datos.</i>  <i>Las tareas consisten en el proceso principal (Master, M), que coordina el inicio de los procesos de trabajo (Worker, W) en las m√°quinas donde se almacenan los bloques de datos necesarios.</i> <br><br>  Casi todos los componentes del ecosistema de Hadoop se lanzan utilizando la m√°quina virtual Java (JVM) y est√°n estrechamente integrados entre s√≠.  Por ejemplo, para ejecutar tareas escritas usando Apache Spark para trabajar con datos almacenados en HDFS, casi no se requieren manipulaciones adicionales: el marco proporciona esta funcionalidad de forma inmediata. <br><br>  Desafortunadamente, la mayor√≠a de las bibliotecas dise√±adas para el aprendizaje autom√°tico asumen que los datos se almacenan y procesan localmente.  Al mismo tiempo, hay bibliotecas que est√°n estrechamente integradas con el ecosistema Hadoop, por ejemplo, Spark ML o Apache Mahout.  Sin embargo, tienen una serie de inconvenientes importantes.  Primero, proporcionan muchas menos implementaciones de algoritmos de aprendizaje autom√°tico.  En segundo lugar, no todos los analistas de datos pueden trabajar con ellos.  Las ventajas de estas bibliotecas incluyen el hecho de que se pueden usar para entrenar modelos en grandes vol√∫menes de datos utilizando computaci√≥n distribuida. <br><br>  Sin embargo, los analistas de datos a menudo usan m√©todos alternativos para entrenar modelos, en particular bibliotecas que permiten el uso de GPU.  No considerar√© los problemas de los modelos de capacitaci√≥n en este art√≠culo, porque quiero centrarme en el uso de modelos listos para usar creados con cualquier biblioteca de aprendizaje autom√°tico disponible para clasificar grandes cantidades de datos. <br><br>  Entonces, la tarea principal que estamos tratando de resolver aqu√≠ es aplicar modelos de aprendizaje autom√°tico a grandes cantidades de datos almacenados en HDFS.  Si pudi√©ramos usar el m√≥dulo SparkML de la biblioteca Apache Spark, que implementa los algoritmos b√°sicos de aprendizaje autom√°tico, clasificar grandes cantidades de datos ser√≠a una tarea trivial: <br><br><pre><code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> model: <span class="hljs-type"><span class="hljs-type">LogisticRegressionModel</span></span> = <span class="hljs-type"><span class="hljs-type">LogisticRegressionModel</span></span>.load(<span class="hljs-string"><span class="hljs-string">"/path/to/model"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> dataset = spark.read.parquet(<span class="hljs-string"><span class="hljs-string">"/path/to/data"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result = model.transform(dataset)</code> </pre> <br>  Desafortunadamente, este enfoque solo funciona para algoritmos implementados en el m√≥dulo SparkML (puede encontrar una lista completa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ).  En el caso de usar otras bibliotecas, adem√°s, implementadas no en la JVM, todo se vuelve mucho m√°s complicado. <br><br>  Para resolver este problema, decidimos incluir el modelo en un servicio REST.  En consecuencia, al comenzar la tarea de clasificar los datos almacenados en HDFS, es necesario organizar la interacci√≥n entre las m√°quinas en las que se almacenan los datos y la m√°quina (o grupo de m√°quinas) en la que se ejecuta el servicio de clasificaci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/8g/p2/pv8gp2gxotjij6hjkkirlllzlii.png"></div>  <i>Figura 2. El concepto de modelo como servicio</i> <br><br><h3>  Descripci√≥n del servicio de clasificaci√≥n de Python </h3><br>  Para presentar el modelo como un servicio, es necesario resolver las siguientes tareas: <br><br><ol><li>  implementar un acceso eficiente al modelo a trav√©s de HTTP; </li><li>  asegurar el uso m√°s eficiente de los recursos de la m√°quina (principalmente todos los n√∫cleos de procesador y memoria); </li><li>  proporcionar resistencia a altas cargas; </li><li>  Proporcionar la capacidad de escalar horizontalmente. </li></ol><br>  El acceso al modelo a trav√©s de HTTP es bastante simple de implementar: se ha desarrollado una gran cantidad de bibliotecas para Python que le permiten implementar un punto de acceso REST utilizando una peque√±a cantidad de c√≥digo.  Uno de estos microframes es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Flask</a> .  La implementaci√≥n del servicio de clasificaci√≥n en Flask es la siguiente: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> flask <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Flask, request, Response model = load_model() n_features = <span class="hljs-number"><span class="hljs-number">100</span></span> app = Flask(__name__) @app.route(<span class="hljs-string"><span class="hljs-string">"/score"</span></span>, methods=[<span class="hljs-string"><span class="hljs-string">'PUT'</span></span>]) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inp = np.frombuffer(request.data, dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>).reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, n_features) result = model.predict(inp) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Response(result.tobytes(), mimetype=<span class="hljs-string"><span class="hljs-string">'application/octet-stream'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: app.run()</code> </pre> <br>  Aqu√≠, cuando se inicia el servicio, cargamos el modelo en la memoria y luego lo usamos cuando llamamos al m√©todo de clasificaci√≥n.  La funci√≥n load_model carga el modelo desde alguna fuente externa, ya sea el sistema de archivos, el almacenamiento de valores clave, etc. <br><br>  Un modelo es un objeto que tiene un m√©todo de predicci√≥n.  En el caso de la clasificaci√≥n, toma una entrada a alg√∫n vector de caracter√≠sticas de cierto tama√±o y produce un valor booleano que indica si el vector especificado es adecuado para este modelo, o alg√∫n valor de 0 a 1, al que luego puede aplicar el umbral de corte: todo por encima del umbral, es un resultado positivo de la clasificaci√≥n, el resto no lo es. <br><br>  El vector de caracter√≠sticas que necesitamos clasificar se pasa en forma binaria y se deserializa en una matriz numpy.  Ser√≠a una sobrecarga hacer una solicitud HTTP para cada vector.  Por ejemplo, en el caso de un vector de 100 dimensiones y el uso de valores de tipo float32, una solicitud HTTP completa, incluidos los encabezados, se ver√≠a as√≠: <br><br><pre> <code class="hljs powershell">PUT /score HTTP/<span class="hljs-number"><span class="hljs-number">1.1</span></span> Host: score<span class="hljs-literal"><span class="hljs-literal">-node</span></span><span class="hljs-literal"><span class="hljs-literal">-1</span></span>:<span class="hljs-number"><span class="hljs-number">8099</span></span> User<span class="hljs-literal"><span class="hljs-literal">-Agent</span></span>: curl/<span class="hljs-number"><span class="hljs-number">7.58</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span> Accept: */* Content<span class="hljs-literal"><span class="hljs-literal">-Type</span></span>: application/binary Content<span class="hljs-literal"><span class="hljs-literal">-Length</span></span>: <span class="hljs-number"><span class="hljs-number">400</span></span> [<span class="hljs-number"><span class="hljs-number">400</span></span> <span class="hljs-built_in"><span class="hljs-built_in">byte</span></span><span class="hljs-type"><span class="hljs-type">s</span></span> <span class="hljs-type"><span class="hljs-type">of</span></span> <span class="hljs-type"><span class="hljs-type">data</span></span>]</code> </pre> <br>  Como puede ver, la eficiencia de dicha solicitud es muy baja (400 bytes de carga √∫til / (encabezado de 133 bytes + cuerpo de 400 bytes) = 75%).  Afortunadamente, en casi todas las bibliotecas, el m√©todo de predicci√≥n le permite recibir no el vector [1 xn], sino la matriz [mxn] y, en consecuencia, generar el resultado inmediatamente para m valores de entrada. <br><br>  Adem√°s, la biblioteca numpy est√° optimizada para trabajar con matrices grandes, lo que le permite utilizar de manera efectiva todos los recursos disponibles de la m√°quina.  Por lo tanto, podemos enviar no uno sino un n√∫mero bastante grande de vectores de caracter√≠sticas en una solicitud, deserializarlos en una matriz numpy de tama√±o [mxn], clasificar y devolver el vector [mx 1] desde valores booleanos o float32.  Como resultado, la eficiencia de la interacci√≥n HTTP cuando se usa una matriz de 1000 filas se vuelve casi igual al 100%.  El tama√±o de los encabezados HTTP en este caso puede ser descuidado. <br><br>  Para probar el servicio Flask en la m√°quina local, puede ejecutarlo desde la l√≠nea de comandos.  Sin embargo, este m√©todo es completamente inadecuado para uso industrial.  El hecho es que Flask tiene un solo subproceso y, si observamos el diagrama de carga del procesador mientras el servicio est√° en ejecuci√≥n, veremos que un n√∫cleo est√° cargado al 100% y el resto est√° inactivo.  Afortunadamente, hay formas de usar todos los n√∫cleos de la m√°quina: para esto, Flask debe ejecutarse a trav√©s del servidor de aplicaciones web uwsgi.  Le permite configurar de manera √≥ptima la cantidad de procesos y subprocesos para garantizar una carga uniforme en todos los n√∫cleos de procesador.  Puede encontrar m√°s detalles sobre todas las opciones para configurar uwsgi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  Es mejor usar nginx como un punto de entrada HTTP, ya que uwsgi puede funcionar de manera inestable en caso de altas cargas.  Nginx, por otro lado, toma todo el flujo de entrada de solicitudes en s√≠ mismo, filtra las solicitudes no v√°lidas y dosifica la carga en uwsgi.  Nginx se comunica con uwsgi a trav√©s de sockets linux usando un archivo de proceso.  A continuaci√≥n se muestra un ejemplo de configuraci√≥n nginx: <br><br><pre> <code class="nginx hljs"><span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">80</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">try_files</span></span> <span class="hljs-variable"><span class="hljs-variable">$uri</span></span> <span class="hljs-variable"><span class="hljs-variable">@score</span></span>; } <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> <span class="hljs-variable"><span class="hljs-variable">@score</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> uwsgi_params; <span class="hljs-attribute"><span class="hljs-attribute">uwsgi_pass</span></span> unix:/tmp/score.sock; } }</code> </pre><br>  Como podemos ver, result√≥ ser una configuraci√≥n bastante complicada para una m√°quina.  Si necesitamos clasificar grandes cantidades de datos, un gran n√∫mero de solicitudes llegar√° a este servicio y puede convertirse en un cuello de botella.  La soluci√≥n a este problema es la escala horizontal. <br><br>  Para mayor comodidad, empaquetamos el servicio en un contenedor Docker y luego lo implementamos en la cantidad requerida de m√°quinas.  Si lo desea, puede usar herramientas de implementaci√≥n automatizadas como Kubernetes.  A continuaci√≥n se muestra un ejemplo de estructura Dockerfile para crear un contenedor con un servicio. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ubuntu #Installing required ubuntu <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> python modules RUN apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> RUN apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y install python3 python3-pip nginx RUN <span class="hljs-keyword"><span class="hljs-keyword">update</span></span>-alternatives <span class="hljs-comment"><span class="hljs-comment">--install /usr/bin/python python /usr/bin/python3 1 RUN update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1 RUN pip install uwsgi flask scipy scikit-learn #copying script files WORKDIR /etc/score COPY score.py . COPY score.ini . COPY start.sh . RUN chmod +x start.sh RUN rm /etc/nginx/sites-enabled/default COPY score.nginx /etc/nginx/sites-enabled/ EXPOSE 80 ENTRYPOINT ["./start.sh"]</span></span></code> </pre> <br>  Entonces, la estructura del servicio de clasificaci√≥n es la siguiente: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fz/4b/c7/fz4bc7kha2wb_dbhck4gifa52ho.png"></div>  <i>Figura 3. Esquema de servicio para clasificaci√≥n</i> <br><br><h3>  Un breve resumen del trabajo de Apache Spark en el ecosistema Hadoop </h3><br>  Ahora considere el proceso de procesamiento de datos almacenados en HDFS.  Como ya se√±al√©, para esto se usa el principio de transferir c√°lculos a datos.  Para comenzar a procesar tareas, debe saber en qu√© m√°quinas se almacenan los bloques de datos que necesitamos para ejecutar procesos directamente involucrados en su procesamiento.  Tambi√©n es necesario coordinar el lanzamiento de estos procesos, reiniciarlos en caso de emergencia, si es necesario, agregar los resultados de varias subtareas, etc. <br><br>  Todas estas tareas se llevan a cabo mediante una variedad de marcos que trabajan con el ecosistema de Hadoop.  Uno de los m√°s populares y convenientes es Apache Spark.  El concepto principal en torno al cual se construye todo el marco es RDD (conjunto de datos distribuidos resilientes).  En general, RDD puede considerarse como una colecci√≥n distribuida que es resistente a ca√≠das.  RDD se puede obtener de dos maneras principales: <br><br><ol><li>  creaci√≥n desde una fuente externa, como una colecci√≥n en memoria, un archivo o directorio en el sistema de archivos, etc. </li><li>  conversi√≥n de otro RDD mediante la aplicaci√≥n de operaciones de transformaci√≥n.  RDD admite todas las operaciones b√°sicas de trabajar con colecciones, como map, flatMap, filter, groupBy, join, etc. </li></ol><br>  Es importante comprender que RDD, a diferencia de las colecciones, no son datos directamente, sino una secuencia de operaciones que deben realizarse en los datos.  Por lo tanto, cuando se llaman las operaciones de transformaci√≥n, en realidad no ocurre ning√∫n trabajo, y solo obtenemos un nuevo RDD, que contendr√° una operaci√≥n m√°s que en la anterior.  El trabajo en s√≠ comienza cuando se llaman las llamadas operaciones de terminal, o acciones.  Estos incluyen guardar en un archivo, guardar en una colecci√≥n en la memoria, contar el n√∫mero de elementos, etc. <br><br>  Al iniciar una operaci√≥n de terminal, Spark crea un gr√°fico de operaci√≥n ac√≠clico (DAG, gr√°fico ac√≠clico dirigido) basado en el RDD resultante y los ejecuta secuencialmente en el cl√∫ster de acuerdo con el gr√°fico recibido.  Al construir un DAG basado en RDD, Spark realiza una serie de optimizaciones, por ejemplo, si es posible, combina varias transformaciones sucesivas en una sola operaci√≥n. <br><br>  RDD fue la unidad principal de interacci√≥n con la API de Spark en las versiones de Spark 1.x.  En Spark 2.x, los desarrolladores dijeron que ahora el concepto principal para la interacci√≥n es Dataset.  Dataset es un complemento para RDD con soporte para interacci√≥n similar a SQL.  Al usar la API de conjunto de datos, Spark le permite usar una amplia gama de optimizaciones, incluidas las de nivel bastante bajo.  Pero, en general, los principios b√°sicos que se aplican a los RDD tambi√©n se aplican al conjunto de datos. <br><br>  Se pueden encontrar m√°s detalles sobre el trabajo de Spark en la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentaci√≥n en el sitio web oficial</a> . <br><br>  Consideremos un ejemplo de la clasificaci√≥n m√°s simple en Spark sin usar servicios externos.  Aqu√≠ se implementa un algoritmo bastante sin sentido, que considera la proporci√≥n de cada una de las letras latinas en el texto, y luego considera la desviaci√≥n est√°ndar.  Aqu√≠, en primer lugar, es importante prestar atenci√≥n directamente a los pasos b√°sicos que se utilizan al trabajar con Spark. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Data</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, text: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Features</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Score</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, score: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">//</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">1</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">std</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">)</span></span>: <span class="hljs-type"><span class="hljs-type">Float</span></span> = ??? <span class="hljs-comment"><span class="hljs-comment">//(2) val ds: Dataset[Data] = spark.read.parquet("/path/to/data").as[Data] //(3) val result: Dataset[Score] = ds.map {d: Data =&gt; //(4) val filteredText = d.text.toLowerCase.filter { letter =&gt; 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' } val featureVector = new Array[Float](26) if (filteredText.nonEmpty) { filteredText.foreach(letter =&gt; featureVector(letter) += 1) featureVector.indicies.foreach { i =&gt; featureVector(i) = featureVector(i) / filteredText.length() } } Features(d.id, featureVector) }.map {f: Features =&gt; Score(f.id, std(f.vector)) //(5) } result.write.parquet("/path/to/result") //(6)</span></span></code> </pre><br>  En este ejemplo, nosotros: <br><br><ol><li>  determinamos la estructura de los datos de entrada, intermedios y de salida (los datos de entrada se definen como texto con el que se asocia un determinado identificador, los datos intermedios coinciden con el identificador con el vector de caracter√≠sticas y la salida coincide con el identificador con alg√∫n valor num√©rico); </li><li>  definimos una funci√≥n para calcular el valor resultante por un vector de caracter√≠sticas (por ejemplo, desviaci√≥n est√°ndar, implementaci√≥n no mostrada); </li><li>  defina el conjunto de datos original como datos almacenados en HDFS en formato de parquet a lo largo de la ruta / ruta / a / datos; </li><li>  Defina un conjunto de datos intermedio como un mapa de mapa de bits del conjunto de datos original. </li><li>  Del mismo modo, determinamos el conjunto de datos resultante a trav√©s de una transformaci√≥n bit a bit desde el intermedio; </li><li>  guarde el conjunto de datos resultante en HDFS en formato de parquet a lo largo de la ruta / ruta / a / resultado.  Dado que guardar en un archivo es una operaci√≥n de terminal, los c√°lculos mismos se inician precisamente en esta etapa. </li></ol><br>  Apache Spark funciona seg√∫n el principio de maestro-trabajador.  Cuando se inicia la aplicaci√≥n, se inicia el proceso principal, llamado controlador.  Ejecuta el c√≥digo responsable de la formaci√≥n del RDD, en base al cual se realizar√°n los c√°lculos. <br><br>  Cuando se llama a una operaci√≥n de terminal, el controlador genera un DAG basado en el RDD resultante.  Luego, el controlador inicia el lanzamiento de flujos de trabajo llamados ejecutores, en los que los datos se procesar√°n directamente.  Despu√©s de iniciar los flujos de trabajo, el controlador les pasa el bloque ejecutable que debe ejecutarse y tambi√©n indica a qu√© parte de los datos debe aplicarse. <br><br>  A continuaci√≥n se muestra el c√≥digo de nuestro ejemplo, en el que se resaltan las secciones de c√≥digo que se ejecutan en el ejecutor (entre las l√≠neas parte del ejecutor comienzan y finalizan la parte del ejecutor).  El resto del c√≥digo se ejecuta en el controlador. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Data</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, text: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Features</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Score</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, score: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">std</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">)</span></span>: <span class="hljs-type"><span class="hljs-type">Float</span></span> = ??? <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> ds: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[<span class="hljs-type"><span class="hljs-type">Data</span></span>] = spark.read.parquet(<span class="hljs-string"><span class="hljs-string">"/path/to/data"</span></span>).as[<span class="hljs-type"><span class="hljs-type">Data</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[<span class="hljs-type"><span class="hljs-type">Score</span></span>] = ds.map { <span class="hljs-comment"><span class="hljs-comment">// --------------- EXECUTOR PART BEGIN ----------------------- d: Data =&gt; val filteredText = d.text.toLowerCase.filter { letter =&gt; 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' } val featureVector = new Array[Float](26) if (filteredText.nonEmpty) { filteredText.foreach(letter =&gt; featureVector(letter) += 1) featureVector.indicies.foreach { i =&gt; featureVector(i) = featureVector(i) / filteredText.length() } } Features(d.id, featureVector) // --------------- EXECUTOR PART END ----------------------- }.map { // --------------- EXECUTOR PART BEGIN ----------------------- f: Features =&gt; Score(f.id, std(f.vector)) // --------------- EXECUTOR PART END ----------------------- } result.write.parquet(‚Äú/path/to/result‚Äù)</span></span></code> </pre><br>  En el ecosistema de Hadoop, todas las aplicaciones se ejecutan en contenedores.  Un contenedor es un proceso que se ejecuta en una de las m√°quinas en un cl√∫ster al que se le asigna una cierta cantidad de recursos.  El lanzamiento del contenedor es manejado por el Administrador de recursos de YARN.  Determina cu√°l de las m√°quinas tiene una cantidad suficiente de n√∫cleos de procesador y RAM, as√≠ como si contiene los bloques de datos necesarios para el procesamiento. <br><br>  Al iniciar la aplicaci√≥n Spark, YARN crea y ejecuta el contenedor en una de las m√°quinas de cl√∫ster en las que inicia el controlador.  Luego, cuando el conductor prepara el DAG de las operaciones que deben ejecutarse en los ejecutores, YARN lanza contenedores adicionales en las m√°quinas deseadas. <br><br>  Como regla, es suficiente que el controlador asigne un n√∫cleo y una peque√±a cantidad de memoria (a menos que, por supuesto, el resultado del c√°lculo no se agregue al controlador en la memoria).  Para los ejecutores, para optimizar los recursos y reducir el n√∫mero total de procesos en el sistema, se puede distinguir m√°s de un n√∫cleo: en este caso, el ejecutor podr√° realizar varias tareas simult√°neamente. <br><br>  Pero aqu√≠ es importante comprender que en caso de que falle una de las tareas que se ejecutan en el contenedor o en caso de recursos insuficientes, YARN puede decidir detener el contenedor, y luego todas las tareas que se ejecutaron en √©l deber√°n reiniciarse nuevamente en otro artista.  Adem√°s, si asignamos un n√∫mero suficientemente grande de n√∫cleos por contenedor, entonces es probable que YARN no pueda iniciarlo.  Por ejemplo, si tenemos dos m√°quinas en las que no se usan dos n√∫cleos, entonces podemos comenzar en cada contenedor que requiera dos n√∫cleos, pero no podemos iniciar un contenedor que requiera cuatro n√∫cleos. <br><br>  Ahora veamos c√≥mo se ejecutar√° el c√≥digo de nuestro ejemplo directamente en el cl√∫ster.  Imagine que el tama√±o de los datos de origen es de 2 terabytes.  En consecuencia, si el tama√±o de bloque en HDFS es de 128 megabytes, entonces habr√° 16384 bloques en total.  Cada bloque se replica en varias m√°quinas para garantizar la fiabilidad.  Para simplificar, tomamos el factor de replicaci√≥n igual a dos, es decir, habr√° 32768 bloques disponibles en total.  Supongamos que usamos un grupo de 16 m√°quinas para el almacenamiento.  En consecuencia, en cada una de las m√°quinas en caso de distribuci√≥n uniforme habr√° aproximadamente 2048 bloques, o 256 Gigabytes por m√°quina.  En cada una de las m√°quinas, tenemos 8 n√∫cleos de procesador y 64 gigabytes de RAM. <br><br>  Para nuestra tarea, el controlador no necesita muchos recursos, por lo que le asignaremos 1 n√∫cleo y 1 GB de memoria.  Les daremos a los artistas 2 n√∫cleos y 4 GB de memoria.  Supongamos que queremos maximizar el uso de los recursos del cl√∫ster.  Por lo tanto, obtenemos 64 contenedores: uno para el conductor y 63 para los artistas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uw/qu/rc/uwqurc3i8v7wagn1zfexu-3dfgo.png"></div>  <i>Figura 4. Procesos que se ejecutan en el nodo de datos y los recursos que utilizan.</i> <br><br>  Como en nuestro caso usamos solo operaciones de mapas, nuestro DAG consistir√° en una operaci√≥n.  Consiste en las siguientes acciones: <br><br><ol><li>  tomar un bloque de datos del disco duro local, </li><li>  Convertir datos </li><li>  guarde el resultado en un nuevo bloque en su propio disco local. </li></ol><br>  En total, necesitamos procesar 16384 bloques, por lo que cada ejecutor debe realizar 16384 / (63 ejecutores * 2 n√∫cleos) = 130 operaciones.  Por lo tanto, el ciclo de vida del ejecutor como un proceso separado (en caso de que todo ocurra sin ca√≠das) se ver√° de la siguiente manera. <br><br><ol><li>  Lanzamiento de contenedores. </li><li>  Recibir del controlador una tarea en la que habr√° un identificador de bloque y la operaci√≥n necesaria.  Como asignamos dos n√∫cleos al contenedor, el ejecutor recibe dos tareas a la vez. </li><li>  Realizar una tarea y enviar el resultado al controlador. </li><li>  Obtener la siguiente tarea del controlador y repetir los pasos 2 y 3 hasta que se procesen todos los bloques para esta m√°quina local. </li><li>  Parada de contenedores </li></ol><br>  <i>Nota</i> : se obtienen DAG m√°s complejos si es necesario redistribuir datos intermedios entre m√°quinas, generalmente para operaciones de agrupaci√≥n (groupBy, reduceByKey, etc.) y conexiones (join), cuya consideraci√≥n est√° m√°s all√° del alcance de este art√≠culo. <br><br><h3>  Los principales problemas de interacci√≥n entre Apache Spark y los servicios externos. </h3><br>  Si, dentro del marco de la operaci√≥n del mapa, necesitamos acceder a alg√∫n servicio externo, la tarea se vuelve menos trivial.  Suponga que un objeto de la clase ExternalServiceClient es responsable de interactuar con un servicio externo.  En general, antes de comenzar a trabajar, debemos inicializarlo y luego llamarlo seg√∫n sea necesario: <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() <span class="hljs-comment"><span class="hljs-comment">// val score = client.score(featureVector) // .</span></span></code> </pre><br>  Por lo general, la inicializaci√≥n del cliente lleva alg√∫n tiempo, por lo tanto, como regla general, se inicializa al inicio de la aplicaci√≥n y luego se usa para obtener una instancia del cliente de alg√∫n contexto o grupo global.  Por lo tanto, cuando un contenedor con el ejecutor Spark recibe una tarea que requiere interacci√≥n con un servicio externo, ser√≠a bueno obtener un cliente ya inicializado antes de comenzar a trabajar en la matriz de datos y luego reutilizarlo para cada elemento. <br><br>  Hay dos formas de hacer esto en Spark.  Primero, si el cliente es serializable (el cliente mismo y todos sus campos deben extender la interfaz java.io.Serializable), entonces se puede inicializar en el controlador y luego <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pasar a los ejecutores a trav√©s del mecanismo de difusi√≥n variable</a> . <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> clientBroadcast = sparkContext.broadcast(client) ds.map { f: <span class="hljs-type"><span class="hljs-type">Features</span></span> =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> score = clientBroadcast.value.score(f.vector) <span class="hljs-type"><span class="hljs-type">Score</span></span>(f.id, score) }</code> </pre><br>  En el caso de que el cliente no sea serializable, o la inicializaci√≥n del cliente es un proceso que depende de la configuraci√≥n de la m√°quina en particular en la que se est√° ejecutando (por ejemplo, para equilibrar, las solicitudes de una parte de las m√°quinas deben ir a la primera m√°quina de servicio, y de la otra a la segunda), entonces el cliente puede inicializarse directamente en el ejecutor. <br><br>  Para esto, RDD (y Dataset) tiene una operaci√≥n mapPartitions, que es una versi√≥n generalizada de la operaci√≥n de mapa (si observa el c√≥digo fuente de la clase RDD, la operaci√≥n de mapa se implementa a trav√©s de mapPartitions).  La funci√≥n pasada a la operaci√≥n mapPartitions se ejecuta una vez para cada bloque.        ,      ,          ,   : <br><br><pre> <code class="scala hljs">ds.mapPartitions {fi: <span class="hljs-type"><span class="hljs-type">Iterator</span></span>[<span class="hljs-type"><span class="hljs-type">Features</span></span>] =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() fi.map { f: <span class="hljs-type"><span class="hljs-type">Features</span></span> =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> score = client.score(f.vector) <span class="hljs-type"><span class="hljs-type">Score</span></span>(f.id, score) } }</code> </pre><br>             . , , ,         ,         .     ,    ,               ,    . <br><br>      . ,             hasNext  next: <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (i.hasNext()) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> item = i.next() ‚Ä¶ }</code> </pre><br>        ,         ,    . ,       8 ,  YARN       4    2 , ,     8   .       ,               .         . <br><br>          .       ,         , ,    ,   .        :    ,    ,       .   ,     hasNext       ,      .    (,          ,       )     ,   ,    ,    . , <i>    </i> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4_/hn/vl/4_hnvluet1tc0lvq68urw9ij5fi.png" width="550"></div> <i> 5.   ,     ,   mapPartitions,    .        .</i> <br><br>   ,       ,       . ,         ,    ,       . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0e/dm/yy/0edmyyfjkekpdp5f0ncx84tevei.png" width="450"></div> <i> 6.          </i> <br><br>   ,       ,  , -,        ,      , , -,      ,     . <br><br><h3>    </h3><br>  ,          .  ,            .               ,           .          ,     . ,      ,     ,  ,    , ,    . <br><br>         . <br><br><ol><li>  ,       ,       ,          . </li><li>  ,            ,    .          ,     .                         ,      . </li><li>  ,      hasNext  false,    ,       ,    ,       .      :         hasNext = false, , ,    .    ,       ,     ,           . </li></ol><br>  ,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> . Stay tuned! <br><br><div class="spoiler"> <b class="spoiler_title">     ,  ,    ?</b> <div class="spoiler_text"><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Desarrollador de Java</font></font></a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ingeniero de sistemas</font></font></a> </li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es413137/">https://habr.com/ru/post/es413137/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es413125/index.html">La terapia g√©nica brinda a los pacientes peque√±os con atrofia muscular la oportunidad de sobrevivir</a></li>
<li><a href="../es413127/index.html">Algunas palabras sobre el rendimiento real del hipervisor</a></li>
<li><a href="../es413129/index.html">25 errores de un programador novato</a></li>
<li><a href="../es413133/index.html">Antipatrones populares: paginaci√≥n</a></li>
<li><a href="../es413135/index.html">Asignaci√≥n de prueba de revisi√≥n de c√≥digo de desarrolladores junior react</a></li>
<li><a href="../es413139/index.html">Coches el√©ctricos: se acerca la revoluci√≥n</a></li>
<li><a href="../es413141/index.html">Clasifique grandes cantidades de datos en Apache Spark utilizando modelos arbitrarios de aprendizaje autom√°tico</a></li>
<li><a href="../es413143/index.html">Bobby Urban Lite: la nueva mochila urbana de XD Design</a></li>
<li><a href="../es413145/index.html">Analista ayuda a las empresas a ganar dinero</a></li>
<li><a href="../es413147/index.html">¬øEs posible usar Tibero en lugar de Oracle? Y es necesario</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
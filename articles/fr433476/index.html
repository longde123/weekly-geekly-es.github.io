<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚è±Ô∏è ‚¨õÔ∏è üì° 50 nuances de c√©leri üë©üèø‚Äçüîß üò∂ üë©‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vous √™tes ici si vous voulez savoir comment apprivoiser un framework qui est largement connu dans les cercles des d√©veloppeurs Python appel√© Celery. E...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>50 nuances de c√©leri</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/433476/">  Vous √™tes ici si vous voulez savoir comment apprivoiser un framework qui est largement connu dans les cercles des d√©veloppeurs Python appel√© Celery.  Et m√™me si Celery ex√©cute en toute confiance les commandes de base de votre projet, l'exp√©rience fintech peut vous ouvrir des c√¥t√©s inconnus.  Parce que la fintech est toujours le Big Data, et avec elle le besoin de t√¢ches en arri√®re-plan, de traitement par lots, d'API asynchrone, etc. <br><img src="https://habrastorage.org/webt/oc/8a/rn/oc8arnnknqs37365anrx9mvuuru.jpeg"><br><br>  La beaut√© de l'histoire d'Oleg Churkin sur le c√©leri √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Moscou Python Conf ++,</a> en plus d'instructions d√©taill√©es sur la fa√ßon de configurer le c√©leri sous charge et comment le surveiller, est que vous pouvez emprunter des id√©es utiles. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SxgzHz-zE-c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>√Ä propos du conf√©rencier et du projet:</strong> Oleg Churkin ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">Bahusss</a> ) d√©veloppe des projets Python de complexit√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">variable</a> depuis 8 ans, a travaill√© dans de nombreuses entreprises bien connues: Yandex, Rambler, RBC, Kaspersky Lab.  Maintenant, techlide dans le d√©marrage de fintech-StatusPoney. <br><a name="habracut"></a><br>  Le projet fonctionne avec une grande quantit√© de donn√©es financi√®res des utilisateurs (1,5 t√©raoctets): comptes, transactions, commer√ßants, etc.  Il ex√©cute jusqu'√† un million de t√¢ches chaque jour.  Peut-√™tre que ce nombre ne semblera pas vraiment √©lev√© √† quelqu'un, mais pour une petite startup avec des capacit√©s modestes, c'est une quantit√© importante de donn√©es, et les d√©veloppeurs ont d√ª faire face √† divers probl√®mes sur la voie d'un processus stable. <br><br>  Oleg a parl√© des principaux points de travail: <br><br><ul><li>  Quelles t√¢ches vouliez-vous r√©soudre avec le framework, pourquoi avez-vous choisi le c√©leri. </li><li>  Comment le c√©leri a aid√©. </li><li>  Comment configurer Celery sous charge. </li><li>  Comment surveiller l'√©tat du c√©leri. </li></ul><br>  Et il a partag√© quelques utilitaires de conception qui impl√©mentent les fonctionnalit√©s manquantes dans Celery.  En fait, en 2018, et cela pourrait l'√™tre.  Ce qui suit est une version texte du rapport √† la premi√®re personne. <br><br><h2>  Probl√®me <br></h2><br>  Il √©tait n√©cessaire pour r√©soudre les t√¢ches suivantes: <br><br><ul><li>  Ex√©cutez <strong>des t√¢ches d'arri√®re-plan distinctes</strong> . </li><li>  Effectuez <strong>un traitement par lots de t√¢ches</strong> , c'est-√†-dire ex√©cutez de nombreuses t√¢ches √† la fois. </li><li>  Int√©grez le processus <strong>Extraire, Transformer, Charger</strong> . </li><li>  Impl√©mentez l' <strong>API asynchrone</strong> .  Il s'av√®re que l'API asynchrone peut √™tre impl√©ment√©e non seulement √† l'aide de frameworks asynchrones, mais √©galement compl√®tement synchrone; </li><li> Effectuez des <strong>t√¢ches p√©riodiques</strong> .  Aucun projet ne peut se passer de t√¢ches p√©riodiques; pour certains, Cron peut √™tre supprim√©, mais il existe √©galement des outils plus pratiques. </li><li>  Cr√©ez une <strong>architecture de d√©clencheur</strong> : pour d√©clencher un d√©clencheur, ex√©cutez une t√¢che qui met √† jour les donn√©es.  Cette op√©ration est effectu√©e afin de compenser le manque de puissance d'ex√©cution en pr√©-calculant les donn√©es en arri√®re-plan. </li></ul><br>  <strong>Les t√¢ches en arri√®re-plan</strong> incluent tout type de notification: e-mail, push, bureau - tout cela est envoy√© dans les t√¢ches en arri√®re-plan par un d√©clencheur.  De la m√™me mani√®re, une mise √† jour p√©riodique des donn√©es financi√®res est lanc√©e. <br><br>  En arri√®re-plan, diverses v√©rifications sp√©cifiques sont effectu√©es, par exemple, la v√©rification d'un utilisateur pour fraude.  Dans les startups financi√®res, <strong>beaucoup d'efforts et d'attention sont accord√©s sp√©cifiquement √† la s√©curit√© des donn√©es</strong> , car nous permettons aux utilisateurs d'ajouter leurs comptes bancaires √† notre syst√®me, et nous pouvons voir toutes leurs transactions.  Les fraudeurs peuvent essayer d'utiliser notre service pour quelque chose de mauvais, par exemple, pour v√©rifier le solde d'un compte vol√©. <br><br>  La derni√®re cat√©gorie de t√¢ches en arri√®re-plan est celle <strong>des t√¢ches de maintenance</strong> : modifier quelque chose, voir, r√©parer, surveiller, etc. <br><br>  Pour les notifications <strong>group√©es</strong> , <strong>le traitement par lots est utilis√©</strong> .  Une grande quantit√© de donn√©es que nous recevons de nos utilisateurs doit √™tre calcul√©e et trait√©e d'une certaine mani√®re, y compris  en mode batch. <br><br>  Le m√™me concept inclut l' <strong>extrait</strong> classique <strong>, la transformation, la charge</strong> : <br><br><ul><li>  charger des donn√©es √† partir de sources externes (API externe); </li><li>  garder non trait√©; </li><li>  ex√©cuter des t√¢ches qui lisent et traitent des donn√©es; </li><li>  nous enregistrons les donn√©es trait√©es au bon endroit dans le bon format, afin que plus tard, il soit pratique de les utiliser dans l'interface utilisateur, par exemple. </li></ul><br>  Ce n'est un secret pour personne que l'API asynchrone peut √™tre effectu√©e √† l'aide de simples requ√™tes d'interrogation: le front-end lance le processus sur le back-end, le back-end lance une t√¢che qui se lance p√©riodiquement, ¬´d√©verse¬ª les r√©sultats et met √† jour l'√©tat dans la base de donn√©es.  Le frontend montre √† l'utilisateur que cet √©tat interactif est en train de changer.  Cela vous permet de: <br><br><ul><li>  ex√©cuter des t√¢ches d'interrogation √† partir d'autres t√¢ches; </li><li>  ex√©cuter diff√©rentes t√¢ches en fonction des conditions. </li></ul><br>  Dans notre service, cela suffit pour le moment, mais √† l'avenir, nous devrons probablement r√©√©crire autre chose. <br><br><h2>  Exigences relatives aux outils <br></h2><br>  Pour impl√©menter ces t√¢ches, nous avions les exigences suivantes pour les outils: <br><br><ul><li>  Fonctionnalit√© n√©cessaire pour r√©aliser nos ambitions. </li><li>  <strong>√âvolutivit√©</strong> sans b√©quilles. </li><li>  <strong>Surveiller le</strong> syst√®me afin de comprendre comment il fonctionne.  Nous utilisons le rapport de bogues, donc l'int√©gration avec Sentry ne sera pas √† sa place, avec Django aussi. </li><li>  <strong>La performance</strong> , car nous avons beaucoup de t√¢ches. </li><li>  La maturit√©, la fiabilit√© et le d√©veloppement actif sont des choses √©videntes.  Nous recherchions un outil qui sera soutenu et d√©velopp√©. </li><li>  Ad√©quation de la documentation - <strong>aucune documentation nulle part</strong> . </li></ul><br><h2>  Quel outil choisir? <br></h2><br>  Quelles sont les options sur le march√© en 2018 pour r√©soudre ces probl√®mes? <br><br>  Il √©tait une fois des t√¢ches moins ambitieuses, j'ai √©crit une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">biblioth√®que</a> pratique qui est encore utilis√©e dans certains projets.  Il est facile √† utiliser et effectue des t√¢ches en arri√®re-plan.  Mais en m√™me temps, aucun courtier n'est n√©cessaire (ni Celery, ni d'autres), seul le serveur d'applications <strong>uwsgi</strong> , qui a un spouleur, est une chose qui commence comme un travailleur s√©par√©.  Il s'agit d'une solution tr√®s simple - toutes les t√¢ches sont stock√©es de mani√®re conditionnelle dans des fichiers.  Pour des projets simples, cela suffit, mais pour le n√¥tre, cela ne suffit pas. <br><br>  D'une mani√®re ou d'une autre, nous avons consid√©r√©: <br><br><ul><li>  C√©leri (10 000 √©toiles sur GitHub); </li><li>  RQ (5K √©toiles sur GitHub); </li><li>  Huey (2K √©toiles sur GitHub); </li><li>  Dramatiq (1K √©toiles sur GitHub); </li><li>  Tasktiger (0,5 K √©toiles sur GitHub); </li><li>  Flux d'air?  Luigi </li></ul><br><h2>  Candidat prometteur 2018 <br></h2><br>  J'aimerais maintenant attirer votre attention sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dramatiq</a> .  Il s'agit d'une biblioth√®que de l'adepte du c√©leri, qui connaissait tous les inconv√©nients du c√©leri et a d√©cid√© de tout r√©√©crire, tr√®s joliment.  Avantages de Dramatiq: <br><br><ul><li>  Un ensemble de toutes les fonctionnalit√©s n√©cessaires. </li><li>  Accent sur la productivit√©. </li><li>  Prise en charge de Sentry et des m√©triques pour Prometheus pr√™t √† l'emploi </li><li>  Une petite base de code clairement √©crite, le chargement automatique du code. </li></ul><br>  Il y a quelque temps, Dramatiq avait des probl√®mes avec les licences: d'abord il y avait AGPL, puis il a √©t√© remplac√© par LGPL.  Mais maintenant, vous pouvez essayer. <br><br>  Mais en 2016, en plus du c√©leri, il n'y avait rien de sp√©cial √† prendre.  Nous avons aim√© sa riche fonctionnalit√©, puis il convenait parfaitement √† nos t√¢ches, car m√™me alors, il √©tait mature et fonctionnel: <br><br><ul><li>  avait des t√¢ches p√©riodiques hors de la bo√Æte; </li><li>  pris en charge plusieurs courtiers; </li><li>  Int√©gr√© √† Django et Sentry. </li></ul><br><h2>  Caract√©ristiques du projet <br></h2><br>  Je vais vous parler de notre contexte, pour que l‚Äôhistoire soit plus claire. <br><br>  Nous utilisons <strong>Redis comme courtier de messages</strong> .  J'ai entendu beaucoup d'histoires et de rumeurs selon lesquelles Redis perd des messages, qu'il n'est pas adapt√© pour √™tre un courtier de messages.  Sur l'exp√©rience de production, cela n'est pas confirm√©, mais, il s'av√®re que Redis fonctionne d√©sormais plus efficacement que RabbitMQ (c'est avec Celery, au moins, apparemment, le probl√®me est dans le code d'int√©gration avec les courtiers).  Dans la version 4, le courtier Redis a √©t√© corrig√©, il a vraiment cess√© de perdre des t√¢ches lors des red√©marrages et fonctionne de mani√®re assez stable.  En 2016, Celery allait abandonner Redis et se concentrer sur l'int√©gration avec RabbitMQ, mais, heureusement, cela ne s'est pas produit. <br><br>  En cas de probl√®mes avec Redis, si nous avons besoin d'une haute disponibilit√© s√©rieuse, nous, parce que nous utilisons la puissance d'Amazon, passerons √† Amazon SQS ou Amazon MQ. <br><br>  Nous <strong>n'utilisons pas de backend de r√©sultat pour stocker les r√©sultats</strong> , car nous pr√©f√©rons stocker les r√©sultats nous-m√™mes o√π nous voulons et les v√©rifier comme nous le voulons.  Nous ne voulons pas que le c√©leri fasse cela pour nous. <br><br>  Nous utilisons un <strong>pool pefork</strong> , c'est-√†-dire des travailleurs de processus qui cr√©ent des fourches de processus distinctes pour une concurrence suppl√©mentaire. <br><br><h2>  Unit√© de travail <br></h2><br>  Nous discuterons des √©l√©ments de base afin de mettre √† jour ceux qui n'ont pas essay√© le c√©leri, mais qui vont le faire.  <strong>L'unit√© de travail pour le c√©leri est un d√©fi</strong> .  Je vais donner un exemple d'une t√¢che simple qui envoie un e-mail. <br><br>  Fonction simple et d√©corateur: <br><br><pre><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@current_app.task def send_email(email: str): print(f'Sending email to email={email}')</span></span></code> </pre> <br>  Le lancement de la t√¢che est simple: soit nous appelons la fonction et la t√¢che sera ex√©cut√©e en runtime (send_email (email = "python@example.com")) ou dans le travailleur, c'est-√†-dire l'effet m√™me de la t√¢che en arri√®re-plan: <br><br><pre> <code class="python hljs">send_email.delay(email=<span class="hljs-string"><span class="hljs-string">"python@example.com"</span></span>) send_email.apply_async( kwargs={email: <span class="hljs-string"><span class="hljs-string">"python@example.com"</span></span>} )</code> </pre><br>  Pendant deux ans de travail avec C√©leri sous des charges √©lev√©es, nous avons √©labor√© des r√®gles de bonne forme.  Il y avait beaucoup de r√¢teaux, nous avons appris √† les contourner et je vais partager comment. <br><br><h4>  Conception du code <br></h4><br>  La t√¢che peut contenir une logique diff√©rente.  En g√©n√©ral, Celery vous aide √† conserver des t√¢ches dans des fichiers ou des packages, ou √† les importer de quelque part.  Parfois, vous obtenez un tas de logique m√©tier dans un module.  √Ä notre avis, la bonne approche du point de vue de la modularit√© de l'application est de garder un <strong>minimum de logique dans la t√¢che</strong> .  Nous utilisons les puzzles uniquement comme ¬´d√©clencheurs¬ª du code.  Autrement dit, la t√¢che ne porte pas de logique en soi, mais d√©clenche le lancement de code en arri√®re-plan. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@celery_app.task(queue='...') def run_regular_update(provider_account_id, *args, **kwargs): """...""" flow = flows.RegularSyncProviderAccountFlow(provider_account_id) return flow.run(*args, **kwargs)</span></span></code> </pre><br>  Nous mettons tout le code dans des classes externes qui utilisent d'autres classes.  Toutes les t√¢ches consistent essentiellement en deux lignes. <br><br><h4>  Objets simples dans les param√®tres <br></h4><br>  Dans l'exemple ci-dessus, un certain identifiant est transmis √† la t√¢che.  Dans toutes les t√¢ches que nous utilisons, nous <strong>ne transf√©rons que de petites donn√©es scalaires</strong> , id.  Nous ne s√©rialisons pas les mod√®les Django pour les transmettre.  M√™me dans ETL, lorsqu'un gros blob de donn√©es provient d'un service externe, nous l'enregistrons d'abord, puis ex√©cutons une t√¢che qui lit tout ce blob par id et le traite. <br><br>  Si vous ne le faites pas, alors nous avons vu un tr√®s grand m√©lange de m√©moire consomm√©e dans Redis.  Le message commence √† prendre plus de m√©moire, le r√©seau est lourdement charg√©, le nombre de t√¢ches trait√©es (performances) diminue.  Tant que l'objet est termin√©, les t√¢ches ne sont plus pertinentes, l'objet a d√©j√† √©t√© supprim√©.  Les donn√©es devaient √™tre s√©rialis√©es - tout n'est pas bien s√©rialis√© en JSON en Python.  Nous avions besoin de l'occasion, lorsque nous r√©essayons des t√¢ches, de d√©cider d'une mani√®re ou d'une autre rapidement que faire de ces donn√©es, de les r√©cup√©rer, de les contr√¥ler. <br><br><blockquote>  Si vous transf√©rez des m√©gadonn√©es en param√®tres, d√©trompez-vous!  Il est pr√©f√©rable de transf√©rer un petit scalaire avec une petite quantit√© d'informations dans le probl√®me, et √† partir de ces informations dans la t√¢che pour obtenir tout ce dont vous avez besoin. <br></blockquote><br><h4>  Probl√®mes idempotents <br></h4><br>  Les d√©veloppeurs de c√©leri eux-m√™mes recommandent cette approche.  Lorsque la section de code est r√©p√©t√©e, aucun effet secondaire ne doit se produire, le r√©sultat doit √™tre le m√™me.  Ce n'est pas toujours facile √† r√©aliser, surtout s'il y a une interaction avec de nombreux services ou des validations en deux phases. <br><br>  Mais lorsque vous faites tout localement, vous pouvez toujours v√©rifier que les donn√©es entrantes existent et sont pertinentes, vous pouvez vraiment y travailler et utiliser des transactions.  S'il existe de nombreuses requ√™tes dans la base de donn√©es pour une t√¢che et que quelque chose peut mal se passer lors de l'ex√©cution, utilisez les transactions pour annuler les modifications inutiles. <br><br><h4>  Compatibilit√© descendante <br></h4><br>  Nous avons eu des effets secondaires int√©ressants lorsque nous avons d√©ploy√© l'application.  Quel que soit le type de d√©ploiement que vous utilisez (mise √† jour bleue + verte ou continue), il y aura toujours une situation o√π l'ancien code de service cr√©e des messages pour le nouveau code de travail, et vice versa, l'ancien travailleur re√ßoit des messages du nouveau code de service, car il a √©t√© d√©ploy√© ¬´en premier¬ª et l√†, le trafic est all√©. <br><br>  Nous avons d√©tect√© des erreurs et perdu des t√¢ches jusqu'√† ce que nous apprenions √† maintenir la <strong>compatibilit√© descendante entre les versions</strong> .  La compatibilit√© descendante est qu'entre les versions, les t√¢ches doivent fonctionner en toute s√©curit√©, quels que soient les param√®tres entrant dans cette t√¢che.  Par cons√©quent, dans toutes les t√¢ches, nous faisons maintenant une signature ¬´en caoutchouc¬ª (** kwargs).  Lorsque vous devez ajouter un nouveau param√®tre dans la prochaine version, vous le prendrez de ** kwargs dans la nouvelle version, mais ne le prendrez pas dans l'ancienne - rien ne se cassera.  D√®s que la signature change et que Celery ne le sait pas, elle se bloque et donne une erreur indiquant qu'il n'y a pas un tel param√®tre dans la t√¢che. <br><br>  Une mani√®re plus rigoureuse d'√©viter de tels probl√®mes est de versionner les files d'attente de t√¢ches entre les versions, mais c'est assez difficile √† impl√©menter et nous l'avons laiss√© dans le backlog pour l'instant. <br><br><h4>  D√©lais <br></h4><br>  Des probl√®mes peuvent survenir en raison d'un nombre insuffisant ou de d√©lais d'attente incorrects. <br><br><blockquote>  Ne pas d√©finir de d√©lai d'expiration pour une t√¢che est mauvais.  Cela signifie que vous ne comprenez pas ce qui se passe dans la t√¢che, comment la logique m√©tier doit fonctionner. <br></blockquote><br>  Par cons√©quent, toutes nos t√¢ches sont suspendues avec des d√©lais d'expiration, y compris globaux pour toutes les t√¢ches, et des d√©lais d'expiration sont √©galement d√©finis pour chaque t√¢che sp√©cifique. <br><br>  <strong>Doit √™tre appos√©: soft_limit_timeout</strong> et <strong>expire.</strong> <br><br>  Expire, c'est combien une t√¢che peut vivre en ligne.  Il est n√©cessaire que les t√¢ches ne s'accumulent pas dans les files d'attente en cas de probl√®me.  Par exemple, si nous voulons maintenant signaler quelque chose √† l'utilisateur, mais que quelque chose s'est produit et que la t√¢che ne peut √™tre termin√©e que demain - cela n'a aucun sens, demain le message ne sera plus pertinent.  Par cons√©quent, pour les notifications, nous avons une expiration assez petite. <br><br>  Notez l'utilisation de <strong>eta (compte √† rebours) + visibilit√©</strong> <strong>_timeout</strong> .  La FAQ d√©crit un tel probl√®me avec Redis - le soi-disant d√©lai de visibilit√© du courtier Redis.  Par d√©faut, sa valeur est d'une heure: si apr√®s une heure, le travailleur voit que personne n'a mis la t√¢che √† ex√©cution, il l'ajoute √† nouveau √† la file d'attente.  Ainsi, si le compte √† rebours est de deux heures, apr√®s une heure, le courtier d√©couvrira que cette t√¢che n'est pas encore termin√©e et en cr√©era une autre.  Et en deux heures, deux t√¢ches identiques seront r√©alis√©es. <br><br><blockquote>  Si le temps ou le compte √† rebours estim√© d√©passe 1 heure, alors, tr√®s probablement, l'utilisation de Redis entra√Ænera la duplication des t√¢ches, sauf, bien s√ªr, si vous avez modifi√© la valeur de visibilit√©_timeout dans les param√®tres de connexion au courtier. <br></blockquote><br><h4>  Nouvelle tentative <br></h4><br>  Pour les t√¢ches qui peuvent √™tre r√©p√©t√©es ou qui peuvent √©chouer, nous utilisons la strat√©gie R√©essayer.  Mais nous l'utilisons avec pr√©caution afin de ne pas submerger les services externes.  Si vous r√©p√©tez rapidement des t√¢ches sans sp√©cifier une interruption exponentielle, un service externe, ou peut-√™tre interne, peut tout simplement ne pas le supporter. <br><br>  Les param√®tres <strong>retry_backoff</strong> , <strong>retry_jitter</strong> et <strong>max_retries</strong> seraient bien √† sp√©cifier explicitement, en particulier max_retries.  retry_jitter - un param√®tre qui vous permet d'apporter un peu de chaos afin que les t√¢ches ne commencent pas √† se r√©p√©ter en m√™me temps. <br><br><h4>  Fuites de m√©moire <br></h4><br><blockquote>  Malheureusement, les fuites de m√©moire sont tr√®s faciles, et les trouver et les r√©parer est difficile. </blockquote><br>  En g√©n√©ral, l'utilisation de la m√©moire en Python est tr√®s controvers√©e.  Vous passerez beaucoup de temps et de nerfs √† comprendre pourquoi la fuite se produit, puis il s'av√®re que ce n'est m√™me pas dans votre code.  Par cons√©quent, toujours, lors du d√©marrage d'un projet, mettez une <strong>limite de m√©moire sur le travailleur</strong> : worker_max_memory_per_child. <br><br>  Cela garantit que OOM Killer ne viendra pas un jour, ne tuera pas tous les travailleurs et vous ne perdrez pas toutes les t√¢ches.  Le c√©leri red√©marrera les employ√©s en cas de besoin. <br><br><h4>  T√¢ches prioritaires <br></h4><br>  Il y a toujours des t√¢ches qui doivent √™tre accomplies avant tout le monde, plus vite que quiconque - elles doivent √™tre accomplies d√®s maintenant!  Il y a des t√¢ches qui ne sont pas si importantes - laissez-les √™tre accomplies pendant la journ√©e.  Pour cela, la t√¢che a un param√®tre <strong>prioritaire.</strong>  Dans Redis, cela fonctionne de mani√®re assez int√©ressante - une nouvelle file d'attente est cr√©√©e avec un nom auquel la priorit√© est ajout√©e. <br><br>  Nous utilisons une approche diff√©rente - <strong>s√©parer les travailleurs pour les priorit√©s</strong> , c'est-√†-dire  √† l'ancienne, nous cr√©ons des travailleurs de c√©leri avec une ¬´importance¬ª diff√©rente: <br><br><pre> <code class="python hljs">celery multi start high_priority low_priority -c:high_priority <span class="hljs-number"><span class="hljs-number">2</span></span> -c:low_priority <span class="hljs-number"><span class="hljs-number">6</span></span> -Q:high_priority urgent_notifications -Q:low_priority emails,urgent_notifications</code> </pre><br>  Celery multi start est un assistant qui vous aide √† ex√©cuter toute la configuration de Celery sur une seule machine et √† partir de la m√™me ligne de commande.  Dans cet exemple, nous cr√©ons des n≈ìuds (ou des travailleurs): high_priority et low_priority, 2 et 6 sont simultan√©s. <br><br>  Deux travailleurs de haute priorit√© traitent en permanence la file d'attente des notifications urgentes.  Personne d'autre ne prendra ces travailleurs, ils ne liront que les t√¢ches importantes de la file d'attente urgent_notifications. <br><br>  Pour les t√¢ches sans importance, il existe une file d'attente low_priority.  Il y a 6 employ√©s qui re√ßoivent des messages de toutes les autres files d'attente.  Nous abonnons √©galement les travailleurs √† faible priorit√© aux notifications urgentes afin qu'ils puissent aider si les travailleurs √† haute priorit√© ne peuvent pas faire face. <br><br>  Nous utilisons ce sch√©ma classique pour hi√©rarchiser les t√¢ches. <br><br><h4>  Extraire, transformer, charger <br></h4><br>  Le plus souvent, ETL ressemble √† une cha√Æne de t√¢ches, chacune recevant des informations de la t√¢che pr√©c√©dente. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task def download_account_data(account_id) ‚Ä¶ return account_id @task def process_account_data(account_id, processing_type) ‚Ä¶ return account_data @task def store_account_data(account_data) ‚Ä¶</span></span></code> </pre><br>  L'exemple a trois t√¢ches.  Celery a une approche du traitement distribu√© et plusieurs utilitaires utiles, y compris la fonction de <strong>cha√Æne</strong> , qui fait un pipeline sur trois de ces t√¢ches: <br><br><pre> <code class="python hljs">chain( download_account_data.s(account_id), process_account_data.s(processing_type=<span class="hljs-string"><span class="hljs-string">'fast'</span></span>), store_account_data.s() ).delay()</code> </pre><br>  Le c√©leri d√©montera le pipeline, effectuera la premi√®re t√¢che dans l'ordre, puis transf√©rera les donn√©es re√ßues vers la seconde et transf√©rera les donn√©es que la deuxi√®me t√¢che renvoie √† la troisi√®me.  C'est ainsi que nous impl√©mentons des pipelines ETL simples. <br><br>  Pour les cha√Ænes plus complexes, vous devez connecter une logique suppl√©mentaire.  Mais il est important de garder √† l'esprit que si un probl√®me survient dans cette cha√Æne dans une t√¢che, alors la <strong>cha√Æne enti√®re s'effondrera</strong> .  Si vous ne souhaitez pas ce comportement, g√©rez l'exception et poursuivez l'ex√©cution, ou arr√™tez la cha√Æne enti√®re par exception. <br><br>  En fait, cette cha√Æne √† l'int√©rieur ressemble √† une grosse t√¢che, qui contient toutes les t√¢ches avec tous les param√®tres.  Par cons√©quent, si vous abusez du nombre de t√¢ches dans la cha√Æne, vous obtiendrez une consommation de m√©moire tr√®s √©lev√©e et un ralentissement du processus global.  <strong>Cr√©er des cha√Ænes de milliers de t√¢ches est une mauvaise id√©e.</strong> <br><br><h2>  Traitement des t√¢ches par lots <br></h2><br>  Maintenant, la chose la plus int√©ressante: que se passe-t-il lorsque vous devez envoyer un e-mail √† deux millions d'utilisateurs. <br><br>  Vous √©crivez une telle fonction pour contourner tous les utilisateurs: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task def send_report_emails_to_users(): for user_id in User.get_active_ids(): send_report_email.delay(user_id=user_id)</span></span></code> </pre><br>  Cependant, le plus souvent, la fonction recevra non seulement l'ID utilisateur, mais √©galement la table enti√®re des utilisateurs en g√©n√©ral.  Chaque utilisateur aura sa propre t√¢che. <br><br>  Il y a plusieurs probl√®mes dans cette t√¢che: <br><br><ul><li>  Les t√¢ches sont lanc√©es s√©quentiellement, c'est-√†-dire que la derni√®re t√¢che (deux millioni√®me utilisateur) commencera dans 20 minutes et peut-√™tre que d'ici ce d√©lai, elle fonctionnera d√©j√†. </li><li>  Tous les identifiants utilisateur sont d'abord charg√©s dans la m√©moire de l'application, puis dans la file d'attente - delay () effectuera 2 millions de t√¢ches. </li></ul><br>  Je l'ai appel√© Task flood, le graphique ressemble √† ceci. <br><img src="https://habrastorage.org/webt/j_/ya/6r/j_ya6r359licn16439uohbpoaow.png"><br>  Il y a un afflux de t√¢ches que les travailleurs commencent lentement √† traiter.  Ce qui suit se produit si les t√¢ches utilisent une r√©plique ma√Ætresse, le projet entier commence √† se fissurer, rien ne fonctionne.  Voici un exemple de notre pratique, o√π l'utilisation du processeur DB √©tait de 100% pendant plusieurs heures, pour √™tre honn√™te, nous avons r√©ussi √† avoir peur. <br><img src="https://habrastorage.org/webt/ac/wh/jy/acwhjy96edpu3dry_vatxj5z7yw.png"><br>  Le probl√®me est que le syst√®me est fortement d√©grad√© avec une augmentation du nombre d'utilisateurs.  La t√¢che qui concerne la planification: <br><br><ul><li>  n√©cessite de plus en plus de m√©moire; </li><li>  s'ex√©cute plus longtemps et peut √™tre "tu√©" par le d√©lai d'expiration. </li></ul><br>  Une inondation de t√¢ches se produit: les t√¢ches s'accumulent dans les files d'attente et cr√©ent une charge importante non seulement sur les services internes, mais √©galement sur les services externes. <br><br>  Nous avons essay√© <strong>de r√©duire la comp√©titivit√© des travailleurs</strong> , cela aide dans un sens - la charge sur le service est r√©duite.  Ou vous pouvez faire <strong>√©voluer les services internes</strong> .  Mais cela ne r√©soudra pas le probl√®me du probl√®me du g√©n√©rateur, qui prend encore beaucoup.  Et n'affecte en rien la d√©pendance √† l'√©gard des performances des services externes. <br><br><h3>  G√©n√©ration de t√¢ches <br></h3><br>  Nous avons d√©cid√© de prendre un chemin diff√©rent.  Le plus souvent, nous n'avons pas besoin d'ex√©cuter les 2 millions de t√¢ches pour le moment.  Il est normal que l'envoi de notifications √† tous les utilisateurs prenne, par exemple, 4 heures si ces lettres ne sont pas si importantes. <br><br>  Nous avons d'abord essay√© d'utiliser <strong>Celery.chunks</strong> : <br><br><pre> <code class="python hljs">send_report_email.chunks( ({<span class="hljs-string"><span class="hljs-string">'user_id'</span></span>: user.id} <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> user <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> User.objects.active()), n=<span class="hljs-number"><span class="hljs-number">100</span></span> ).apply_async()</code> </pre><br>  Cela n'a pas chang√© la situation, car, malgr√© l'it√©rateur, tous les user_id seront charg√©s en m√©moire.  Et tous les travailleurs re√ßoivent une cha√Æne de t√¢ches, et bien que les travailleurs se d√©tendent un peu, nous ne sommes finalement pas satisfaits de cette d√©cision. <br><br>  Nous avons essay√© de d√©finir <strong>rate_limit</strong> pour les travailleurs afin qu'ils ne traitent qu'un certain nombre de t√¢ches par seconde, et nous avons d√©couvert qu'en fait rate_limit sp√©cifi√© pour la t√¢che est rate_limit pour le travailleur.  Autrement dit, si vous sp√©cifiez rate_limit pour la t√¢che, cela ne signifie pas que la t√¢che sera ex√©cut√©e 70 fois par seconde.  Cela signifie que le travailleur l'ex√©cutera 70 fois par seconde, et selon ce que vous avez avec les travailleurs, cette limite peut changer dynamiquement, c'est-√†-dire  real limit rate_limit * len (travailleurs). <br><br>  Si le travailleur d√©marre ou s'arr√™te, le total rate_limit change.  De plus, si vos t√¢ches sont lentes, alors toutes les pr√©lecture de la file d'attente qui remplit le travailleur seront obstru√©es par ces t√¢ches lentes.  Le travailleur regarde: ¬´Oh, j'ai cette t√¢che dans rate_limit, je ne peux plus l'ex√©cuter.  Et toutes les t√¢ches suivantes dans la file d'attente sont exactement les m√™mes - laissez-les se bloquer! ¬ª  - et en attente. <br><br><h3>  Chunkificator <br></h3><br>  √Ä la fin, nous avons d√©cid√© d'√©crire la n√¥tre et avons cr√©√© une petite biblioth√®que, qui s'appelait Chunkificator. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@task @chunkify_task(sleep_timeout=...l initial_chunk=...) def send_report_emails_to_users(chunk: Chunk): for user_id in User.get_active_ids(chunk=chunk): send_report_email.delay(user_id=user_id)</span></span></code> </pre><br>  Il prend sleep_timeout et initial_chunk et s'appelle avec un nouveau morceau.  Chunk est une abstraction sur des listes enti√®res, ou sur des listes date ou datetime.  Nous transmettons le bloc √† une fonction qui re√ßoit les utilisateurs uniquement avec ce bloc et ex√©cute les t√¢ches pour ce bloc uniquement. <br><br>  Ainsi, le g√©n√©rateur de t√¢ches ex√©cute uniquement le nombre de t√¢ches n√©cessaires et ne consomme pas beaucoup de m√©moire.  L'image est devenue comme √ßa. <br><img src="https://habrastorage.org/webt/yh/gg/h_/yhggh__vbzgiexxwskakp1nltrw.png"><br>  Le point culminant est que nous utilisons des morceaux √©pars, c'est-√†-dire que nous utilisons des instances dans la base de donn√©es comme identifiant de morceau (certaines d'entre elles peuvent √™tre ignor√©es, donc il peut y avoir moins de t√¢ches).  En cons√©quence, la charge s'est av√©r√©e plus uniforme, le processus est devenu plus long, mais tout le monde est bel et bien vivant, la base ne se fatigue pas. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La biblioth√®que est</a> impl√©ment√©e pour Python 3.6+ et est disponible sur GitHub.  Il y a une nuance que je pr√©vois de corriger, mais pour l'instant le bloc datetime a besoin d'un s√©rialiseur de cornichons - beaucoup ne seront pas en mesure de le faire. <br><br>  Quelques questions rh√©toriques - d'o√π viennent toutes ces informations?  Comment avons-nous d√©couvert que nous avions des probl√®mes?  Comment savez-vous qu'un probl√®me deviendra bient√¥t critique et que vous devez d√©j√† commencer √† le r√©soudre? <br><br>  La r√©ponse est, bien s√ªr, la surveillance. <br><br><h2>  Suivi <br></h2><br>  J'aime vraiment la surveillance, j'aime tout surveiller et garder le doigt sur le pouls.  Si vous ne gardez pas votre doigt sur le pouls, vous marcherez constamment sur le r√¢teau. <br><br>  Questions de surveillance standard: <br><br><ul><li>  La configuration de travail / simultan√©e actuelle g√®re-t-elle la charge? </li><li>  Quelle est la d√©gradation du temps d'ex√©cution des t√¢ches? </li><li>  Combien de temps les t√¢ches sont-elles align√©es?  Soudain, la ligne est d√©j√† bond√©e? </li></ul><br>  Nous avons essay√© plusieurs options.  Le c√©leri a une interface <strong>CLI</strong> , il est assez riche et donne: <br><br><ul><li>  inspecter - informations sur le syst√®me; </li><li>  contr√¥le - g√©rer les param√®tres du syst√®me; </li><li>  purge - effacer les files d'attente (force majeure); </li><li>  √©v√©nements - interface utilisateur de la console pour afficher des informations sur les t√¢ches en cours. </li></ul><br>  Mais il est difficile de vraiment surveiller quelque chose.  Il est mieux adapt√© aux fioritures locales ou si vous souhaitez modifier un certain rate_limit lors de l'ex√©cution. <br><br>  <strong>NB: vous</strong> devez avoir acc√®s au courtier de production pour utiliser l'interface CLI. <br><br>  <strong>Celery Flower</strong> vous permet de faire la m√™me chose que la CLI, uniquement via l'interface web, et ce n'est pas tout.  Mais il construit des graphiques simples et vous permet de modifier les param√®tres √† la vol√©e. <br><br>  En g√©n√©ral, Celery Flower convient pour voir comment tout fonctionne dans de petites configurations.  De plus, il prend en charge l'API HTTP, ce qui est pratique si vous √©crivez l'automatisation. <br><br>  Mais nous nous sommes <strong>install√©s sur Prom√©th√©e.</strong>  Ils ont pris l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exportateur</a> actuel: correction de fuites de m√©moire;  m√©triques ajout√©es pour les types d'exceptions;  ajout de mesures pour le nombre de messages dans les files d'attente;  Int√©gr√© avec des alertes dans Grafana et r√©jouissez-vous.  Il est √©galement publi√© sur GitHub, vous pouvez le voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br><h4>  Exemples √† Grafana <br></h4><br><img src="https://habrastorage.org/webt/wa/i3/yt/wai3ytvm4ewoiumfrlvn2gzq9eg.png"><br>  Statistiques ci-dessus pour toutes les exceptions: quelles exceptions pour quelles t√¢ches.  Vous trouverez ci-dessous le temps de terminer les t√¢ches. <br><img src="https://habrastorage.org/webt/ae/l3/sf/ael3sfmjeve51s5jtui9fh_7ydq.png"><br><h2>  Qu'est-ce qui manque dans le c√©leri? <br></h2><br>  Ceci est un cadre verdoyant, il a beaucoup de choses, mais nous manquons!  Il n'y a pas assez de petites fonctionnalit√©s, telles que: <br><br><ul><li>  <strong>Rechargement automatique du code pendant le d√©veloppement</strong> - ne prend pas en charge ce c√©leri - red√©marrage. </li><li>  <strong>Les mesures pour Prom√©th√©e sont pr√™tes</strong> √† l'emploi, mais Dramatiq le peut. </li><li>  <strong>Prise en</strong> <strong>charge du verrouillage des t√¢ches</strong> - de sorte qu'une seule t√¢che s'ex√©cute √† la fois.  Vous pouvez le faire vous-m√™me, mais Dramatiq et Tasktiger ont un d√©corateur pratique qui garantit que toutes les autres t√¢ches similaires seront bloqu√©es. </li><li>  <strong>Rate_limit pour une t√¢che</strong> - pas pour le travailleur. </li></ul><br><h2>  Conclusions <br></h2><br>  Malgr√© le fait que Celery est un framework que beaucoup utilisent dans la production, il se compose de 3 biblioth√®ques - Celery, Kombu et Billiard.  Ces trois biblioth√®ques sont d√©velopp√©es par des co-d√©veloppeurs et peuvent lib√©rer une d√©pendance et casser votre assembly. <br><img src="https://habrastorage.org/webt/dv/np/52/dvnp52xxgjcwsbdwr3c15a86-ac.png"><br>  Par cons√©quent, j'esp√®re que vous l'avez d√©j√† r√©gl√© d'une mani√®re ou d'une autre et rendu vos assemblages d√©terministes. <br><br>  En fait, les conclusions ne sont pas si tristes.  <strong>Le c√©leri fait face √† ses t√¢ches</strong> dans notre projet fintech sous notre charge.  Nous avons acquis une exp√©rience que j'ai partag√©e avec vous, et vous pouvez appliquer nos solutions ou les affiner et aussi surmonter toutes vos difficult√©s. <br><br>  N'oubliez pas que le <strong>suivi doit √™tre un √©l√©ment essentiel de votre projet</strong> .  Ce n'est que par la surveillance que vous pouvez savoir o√π vous avez quelque chose de mal, ce qui doit √™tre corrig√©, ajout√©, corrig√©. <br><br>  <strong>Contactez le conf√©rencier Oleg Churkin</strong> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">Bahusss</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">facebook</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github</a> . <br><br><blockquote>  Le prochain grand <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Python Conf ++</a> de Moscou se tiendra √† Moscou <b>le 5 avril</b> .  Cette ann√©e, nous essaierons d'int√©grer tous les avantages en une journ√©e en mode exp√©rimental.  Il n'y aura pas moins de rapports, nous allouerons un flux entier aux d√©veloppeurs √©trangers de biblioth√®ques et de produits bien connus.  De plus, le vendredi est une journ√©e id√©ale pour les after parties, qui, comme vous le savez, fait partie int√©grante de la conf√©rence sur la communication. <br><br>  Rejoignez notre conf√©rence Python professionnelle - soumettez votre rapport <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , r√©servez votre billet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  En attendant, les pr√©paratifs sont en cours, des articles sur Moscow Python Conf ++ 2018 appara√Ætront ici. <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr433476/">https://habr.com/ru/post/fr433476/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr433458/index.html">Quelques avantages √©vidents de Serverless pour DevOps</a></li>
<li><a href="../fr433462/index.html">Contr√¥les d'int√©grit√© et d√©gradation progressive des syst√®mes distribu√©s</a></li>
<li><a href="../fr433466/index.html">Comparez les pages. Plugin simple pour Atlassian Confluence</a></li>
<li><a href="../fr433472/index.html">Unity 2018.3 est sorti</a></li>
<li><a href="../fr433474/index.html">Pylint de l'int√©rieur vers l'ext√©rieur. Comment fait-il</a></li>
<li><a href="../fr433478/index.html">Pourquoi Django est choisi dans Tinkoff Magazine</a></li>
<li><a href="../fr433480/index.html">Histoire d'Holivarny sur Linter</a></li>
<li><a href="../fr433482/index.html">Django sous microscope</a></li>
<li><a href="../fr433486/index.html">Quoi encore? Le renouveau des cartes de d√©bit non bancaires</a></li>
<li><a href="../fr433488/index.html">Christmas Scrum Meetup UPD Broadcast mitap</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛳️ 🧗🏾 💛 Perf und Flammengraphen 👨🏼‍🍳 ⚫️ 🔃</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Thema der Verbesserung der Leistung von Betriebssystemen und der Suche nach Engpässen gewinnt zunehmend an Popularität. In diesem Artikel werden w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Perf und Flammengraphen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/437808/"><img src="https://habrastorage.org/webt/pa/ue/x8/pauex8un6--wep6-1ehqvmciieg.png"><br><br>  Das Thema der Verbesserung der Leistung von Betriebssystemen und der Suche nach Engpässen gewinnt zunehmend an Popularität.  In diesem Artikel werden wir anhand des Beispiels des Blockstapels unter Linux und eines Falls zur Fehlerbehebung bei einem Host über ein Tool zum Auffinden dieser Stellen sprechen. <br><br><h2>  Beispiel 1. Test </h2><br><h3>  Nichts funktioniert </h3><br>  Das Testen in unserer Abteilung umfasst Kunststoffe auf der Produkthardware und später Tests der Anwendungssoftware.  Zum Testen haben wir ein Intel Optane-Laufwerk erhalten.  Wir haben bereits <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in unserem Blog</a> über das Testen von Optane-Laufwerken geschrieben. <br><br>  Die Festplatte wurde auf einem Standardserver installiert, der für eine relativ lange Zeit unter einem der Cloud-Projekte erstellt wurde. <br><a name="habracut"></a><br>  Während des Tests zeigte sich die Festplatte nicht optimal: Während des Tests mit einer Warteschlangentiefe von 1 Anforderung pro 1 Stream in Blöcken von 4 KByte ca. 70 KByte.  Und das bedeutet, dass die Antwortzeit enorm ist: ungefähr 13 Mikrosekunden pro Anfrage! <br><br>  Es ist seltsam, weil die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spezifikation</a> "Latenz - 10 µs lesen" verspricht und wir 30% mehr haben, der Unterschied ist ziemlich signifikant.  Die Festplatte wurde auf eine andere Plattform umgestellt, eine „frischere“ Baugruppe, die in einem anderen Projekt verwendet wurde. <br><br><h3>  Warum funktioniert es? </h3><br>  Es ist lustig, aber das Laufwerk auf der neuen Plattform hat so funktioniert, wie es sollte.  Leistung erhöht, Latenz verringert, CPU pro Regal, 1 Stream pro Anforderung, 4-KByte-Blöcke, ~ 106 KB bei ~ 9 Mikrosekunden pro Anforderung. <br><br>  Und dann ist es Zeit, <s>die Einstellungen</s> zu <s>vergleichen</s> , um <b>Perfektion</b> von breiten <b>Beinen</b> zu bekommen.  Immerhin fragen wir uns warum?  Mit <b>perf können</b> Sie: <br><br><ul><li>  Nehmen Sie Hardware-Zählerablesungen vor: die Anzahl der Anweisungsaufrufe, Cache-Fehler, falsch vorhergesagten Verzweigungen usw.  (PMU-Ereignisse) </li><li>  Entfernen Sie Informationen von statischen Handelspunkten, die Anzahl der Vorkommen </li><li>  Führen Sie eine dynamische Ablaufverfolgung durch </li></ul><br>  Zur Überprüfung verwendeten wir CPU-Sampling. <br><br>  Unter dem Strich kann <b>perf</b> den gesamten Stack-Trace eines laufenden Programms kompilieren.  Das Ausführen von <b>perf</b> führt natürlich zu einer Verzögerung des Betriebs des gesamten Systems.  Aber wir haben das Flag <i>-F #</i> , wobei <i>#</i> die Abtastfrequenz ist, gemessen in Hz. <br><br>  Es ist wichtig zu verstehen, dass je höher die Abtastfrequenz ist, desto wahrscheinlicher ist es, dass eine bestimmte Funktion aufgerufen wird, aber desto mehr Bremsen bringt der Profiler in das System.  Je niedriger die Frequenz, desto größer ist die Wahrscheinlichkeit, dass wir keinen Teil des Stapels sehen. <br><br>  Bei der Auswahl einer Frequenz müssen Sie sich vom gesunden Menschenverstand und einem Trick leiten lassen - versuchen Sie, keine gerade Frequenz einzustellen, um nicht in eine Situation zu geraten, in der Arbeiten, die mit einem Timer mit dieser Frequenz ausgeführt werden, in die Samples gelangen. <br><br>  Ein weiterer Punkt, der zunächst irreführend ist: Die Software sollte mit dem Flag <i>-fno-omit-frame-pointer</i> kompiliert werden, wenn dies natürlich möglich ist.  Andernfalls werden in der Ablaufverfolgung anstelle von Funktionsnamen feste <i>unbekannte</i> Werte angezeigt.  Bei einigen Programmen werden Debugging-Symbole als separates Paket <i>geliefert</i> , z. B. <i>someutil-dbg</i> .  Es wird empfohlen, dass Sie sie installieren, bevor Sie <b>perf ausführen</b> . <br><br>  Wir haben folgende Aktionen ausgeführt: <br><br><ul><li>  Entnommen aus git: //git.kernel.dk/fio.git, Tag fio-3.9 </li><li>  CPPFLAGS in Makefile wurde die Option <em>-fno-omit-frame-pointer</em> hinzugefügt </li><li>  <em>Make -j8</em> gestartet </li></ul><br><pre><code class="bash hljs">perf record -g ~/fio/fio --name=<span class="hljs-built_in"><span class="hljs-built_in">test</span></span> --rw=randread --bs=4k --ioengine=pvsync2 --filename=/dev/nvme0n1 --direct=1 --hipri --filesize=1G</code> </pre> <br>  Die Option -g wird benötigt, um den Spurenstapel zu erfassen. <br><br>  Sie können das Ergebnis mit dem folgenden Befehl anzeigen: <br><br><pre> <code class="bash hljs">perf report -g fractal</code> </pre> <br>  Die <i>fraktale</i> Option <i>-g</i> wird benötigt, damit Prozentsätze, die die Anzahl der Abtastwerte mit dieser Funktion widerspiegeln und von <b>perf</b> angezeigt werden, relativ zur aufrufenden Funktion sind, deren Anzahl von Aufrufen als 100% angenommen wird. <br><br>  Gegen Ende des langen Fio-Call-Stacks auf der Plattform „Fresh Build“ werden wir sehen: <br><br><img src="https://habrastorage.org/webt/_y/pn/jb/_ypnjb3xkf3urq140p0qssevtku.png"><br><br>  Und auf der "Old Build" -Plattform: <br><br><img src="https://habrastorage.org/webt/gq/kx/ul/gqkxulpyxspbmfudoxhh7ysdv1e.png"><br><br>  Großartig!  Aber ich möchte schöne Flammengriffe. <br><br><h3>  Flamegramme bauen </h3><br>  Um schön zu sein, gibt es zwei Werkzeuge: <br><br><ul><li>  Relativ statischer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flamegraph</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flamescope</a> , mit dem aus den gesammelten Proben ein bestimmter Zeitraum ausgewählt werden kann.  Dies ist sehr nützlich, wenn der Suchcode die CPU mit kurzen Bursts lädt. </li></ul><br>  Diese Dienstprogramme akzeptieren <b>perf script&gt; result</b> als Eingabe. <br><br>  Laden Sie das <i>Ergebnis</i> herunter und senden Sie es per Pipes an <i>svg</i> : <br><br><pre> <code class="bash hljs">FlameGraph/stackcollapse-perf.pl ./result | FlameGraph/flamegraph.pl &gt; ./result.svg</code> </pre> <br>  Öffnen Sie in einem Browser und genießen Sie ein anklickbares Bild. <br><br>  Sie können eine andere Methode verwenden: <br><br><ol><li>  <i>Ergebnis</i> zum Flamescope hinzufügen / example / </li><li>  Führen Sie python ./run.py aus </li><li>  Wir gehen über den Browser zum 5000-Port des lokalen Hosts </li></ol><br><h3>  Was sehen wir am Ende? </h3><br>  Ein guter Fio verbringt viel Zeit mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Umfragen</a> : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o1/zg/wy/o1zgwy-l6idzwcxniq16ndbskvo.png"></div><br>  Ein schlechtes Fio verbringt überall Zeit, aber nicht in Umfragen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3z/er/bz/3zerbzvtrpwznzewdteyf6bexfq.png"></div><br>  Auf den ersten Blick scheint das Polling auf dem alten Host nicht zu funktionieren, aber überall dort, wo der 4.15-Kernel von derselben Assembly ist, ist das Polling auf NVMe-Festplatten standardmäßig aktiviert.  Überprüfen Sie, ob die Abfrage in <b>sysfs</b> aktiviert ist: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># cat /sys/class/block/nvme0n1/queue/io_poll 1</span></span></code> </pre> <br>  Während der Tests werden <i>preadv2-</i> Aufrufe mit dem Flag <i>RWF_HIPRI verwendet</i> - eine notwendige Bedingung, damit die Abfrage funktioniert.  Wenn Sie das Flammendiagramm (oder den vorherigen Screenshot aus der Ausgabe des <b>Perf-Berichts</b> ) sorgfältig studieren, können Sie es finden, aber es dauert sehr wenig Zeit. <br><br>  Das zweite, was sichtbar ist, ist der unterschiedliche Aufrufstapel für die Funktion submit_bio () und das Fehlen von io_schedule () -Aufrufen.  Schauen wir uns den Unterschied in submit_bio () genauer an. <br><br>  Langsame Plattform "alter Build": <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sd/ba/ew/sdbaewdxmxq2qqy7w6xwlkmpuia.png"></div><br>  Schnelle Plattform "frisch": <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_a/d2/_w/_ad2_wholhggbeewyuoxvqdpuas.png"></div><br>  Es scheint, dass auf einer langsamen Plattform die Anforderung einen langen Weg zum Gerät geht und gleichzeitig in den <b>Kyber-Scheduler gelangt</b> .  Weitere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Informationen zu</a> E / A-Schedulern finden Sie in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unserem Artikel</a> . <br><br>  Nach dem <b>Ausschalten von Kyber</b> zeigte der gleiche Fio-Test eine durchschnittliche Latenz von etwa 10 Mikrosekunden, wie in der Spezifikation angegeben.  Großartig! <br><br>  Aber woher kommt der Unterschied in einer weiteren Mikrosekunde? <br><br><h3>  Und wenn etwas tiefer? </h3><br>  Wie bereits erwähnt, können Sie mit <b>perf</b> Statistiken von Hardware-Zählern sammeln.  Versuchen wir, die Anzahl der Cache-Fehler und Anweisungen pro Zyklus zu ermitteln: <br><br><pre> <code class="bash hljs">perf <span class="hljs-built_in"><span class="hljs-built_in">stat</span></span> -e cycles,instructions,cache-references,cache-misses,bus-cycles /root/fio/fio --clocksource=cpu --name=<span class="hljs-built_in"><span class="hljs-built_in">test</span></span> --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=10</code> </pre> <br><img src="https://habrastorage.org/webt/ue/pc/fo/uepcfo8up5ehpvqb1ophotqjzb8.png"><br><br><img src="https://habrastorage.org/webt/p5/ln/al/p5lnalg0u05xtvc5792ghegtv34.png"><br><br>  Aus den Ergebnissen ist ersichtlich, dass eine schnelle Plattform mehr Anweisungen für den CPU-Zyklus ausführt und einen geringeren Prozentsatz an Cache-Fehlern während der Ausführung aufweist.  Natürlich werden wir im Rahmen dieses Artikels nicht näher auf den Betrieb verschiedener Hardwareplattformen eingehen. <br><br><h2>  Beispiel 2. Lebensmittelgeschäft </h2><br><h3>  Etwas läuft schief </h3><br>  Bei der Arbeit eines verteilten Speichersystems wurde eine Zunahme der Belastung der CPU auf einem der Hosts mit einer Zunahme des eingehenden Datenverkehrs beobachtet.  Hosts sind Peers, Peers und haben identische Hardware und Software. <br><br>  Schauen wir uns die CPU-Auslastung an: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># pidstat -p 1441734 1 Linux 3.13.0-96-generic (lol) 10/10/2018 _x86_64_ (24 CPU) 09:23:30 PM UID PID %usr %system %guest %CPU CPU Command 09:23:44 PM 0 1441734 23.00 1.00 0.00 24.00 4 ceph-osd 09:23:45 PM 0 1441734 85.00 34.00 0.00 119.00 4 ceph-osd 09:23:46 PM 0 1441734 0.00 130.00 0.00 130.00 4 ceph-osd 09:23:47 PM 0 1441734 121.00 0.00 0.00 121.00 4 ceph-osd 09:23:48 PM 0 1441734 28.00 82.00 0.00 110.00 4 ceph-osd 09:23:49 PM 0 1441734 4.00 13.00 0.00 17.00 4 ceph-osd 09:23:50 PM 0 1441734 1.00 6.00 0.00 7.00 4 ceph-osd</span></span></code> </pre> <br>  Das Problem trat um 09:23:46 auf und wir sehen, dass der Prozess im Kernelraum ausschließlich für die gesamte Sekunde funktionierte.  Schauen wir uns an, was im Inneren geschah. <br><br><h3>  Warum so langsam? </h3><br>  In diesem Fall haben wir Proben aus dem gesamten System entnommen: <br><br><pre> <code class="bash hljs">perf record -a -g -- sleep 22 perf script &gt; perf.results</code> </pre> <br>  Die Option <i>-a</i> wird hier für <b>perf</b> benötigt <b>,</b> um Spuren von allen CPUs <b>zu</b> entfernen. <br><br>  Öffnen Sie <b>perf.results</b> mit <b>flamescope</b> , um den Moment erhöhter CPU-Auslastung zu verfolgen. <br><br><div class="spoiler">  <b class="spoiler_title">Heatmap</b> <div class="spoiler_text"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ao/db/hq/aodbhqbwotkcwaq99bvmbznkbrg.png"></div><br></div></div><br>  Vor uns liegt eine "Wärmekarte", deren beide Achsen (X und Y) die Zeit darstellen. <br><br>  Auf der X-Achse ist der Raum in Sekunden und auf der Y-Achse in Segmente von 20 Millisekunden innerhalb von X Sekunden unterteilt. Die Zeit läuft von unten nach oben und von links nach rechts.  Die hellsten Quadrate haben die größte Anzahl von Proben.  Das heißt, die CPU arbeitete zu diesem Zeitpunkt am aktivsten. <br><br>  Eigentlich interessiert uns der rote Fleck in der Mitte.  Wählen Sie es mit der Maus aus, klicken Sie und sehen Sie, was es verbirgt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gv/kk/ko/gvkkkomg9vl7u1ylpwx7h8pceqc.png"></div><br>  Im Allgemeinen ist bereits <i>erkennbar</i> , dass das Problem in der langsamen Operation <i>tcp_recvmsg</i> und <i>skb_copy_datagram_iovec liegt</i> . <br><br>  Vergleichen Sie der Übersichtlichkeit halber Beispiele eines anderen Hosts, auf denen die gleiche Menge an eingehendem Datenverkehr keine Probleme verursacht: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/v6/_j/72/v6_j72zqvscfolhkaipeoyx9lg8.png"></div><br>  Aufgrund der Tatsache, dass wir die gleiche Menge an eingehendem Verkehr haben, identische Plattformen, die lange Zeit ohne Unterbrechung gearbeitet haben, können wir davon ausgehen, dass die Probleme auf der Seite des Eisens aufgetreten sind.  Die Funktion <i>skb_copy_datagram_iovec</i> kopiert Daten aus der <i>Kernelstruktur</i> in die Struktur im Benutzerbereich, um sie an die Anwendung weiterzuleiten.  Es gibt wahrscheinlich Probleme mit dem Hostspeicher.  Gleichzeitig gibt es keine Fehler in den Protokollen. <br><br>  Wir starten die Plattform neu.  Beim Laden des BIOS wird eine Meldung über eine defekte Speicherleiste angezeigt.  Beim Austausch wird der Host gestartet und das Problem mit einer überlasteten CPU wird nicht mehr reproduziert. <br><br><h2>  Nachtrag </h2><br><h3>  Systemleistung mit perf </h3><br>  Im Allgemeinen kann das Ausführen von <b>perf</b> auf einem ausgelasteten System zu einer Verzögerung bei der Verarbeitung von Anforderungen führen.  Die Größe dieser Verzögerungen hängt auch von der Auslastung des Servers ab. <br><br>  Versuchen wir, diese Verzögerung zu finden: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /root/fio/fio --clocksource=cpu --name=test --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=1 test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=pvsync2, iodepth=1 fio-3.9-dirty Starting 1 process Jobs: 1 (f=1): [r(1)][100.0%][r=413MiB/s][r=106k IOPS][eta 00m:00s] test: (groupid=0, jobs=1): err= 0: pid=109786: Wed Dec 12 17:25:56 2018 read: IOPS=106k, BW=414MiB/s (434MB/s)(4096MiB/9903msec) clat (nsec): min=8161, max=84768, avg=9092.68, stdev=1866.73 lat (nsec): min=8195, max=92651, avg=9127.03, stdev=1867.13 … ~# perf record /root/fio/fio --clocksource=cpu --name=test --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=1 test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=pvsync2, iodepth=1 fio-3.9-dirty Starting 1 process Jobs: 1 (f=1): [r(1)][100.0%][r=413MiB/s][r=106k IOPS][eta 00m:00s] test: (groupid=0, jobs=1): err= 0: pid=109839: Wed Dec 12 17:27:50 2018 read: IOPS=106k, BW=413MiB/s (433MB/s)(4096MiB/9916msec) clat (nsec): min=8259, max=55066, avg=9102.88, stdev=1903.37 lat (nsec): min=8293, max=55096, avg=9135.43, stdev=1904.01</span></span></code> </pre> <br>  Der Unterschied ist nicht sehr auffällig, nur etwa ~ 8 Nanosekunden. <br><br>  Mal sehen, was passiert, wenn Sie die Last erhöhen: <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /root/fio/fio --clocksource=cpu --name=test --numjobs=4 --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=1 test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=pvsync2, iodepth=1 ... fio-3.9-dirty Starting 4 processes Jobs: 4 (f=4): [r(4)][100.0%][r=1608MiB/s][r=412k IOPS][eta 00m:00s] ~# perf record /root/fio/fio --clocksource=cpu --name=test --numjobs=4 --bs=4k --filename=/dev/nvme0n1p4 --direct=1 --ioengine=pvsync2 --hipri --rw=randread --filesize=4G --loops=1 test: (g=0): rw=randread, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=pvsync2, iodepth=1 ... fio-3.9-dirty Starting 4 processes Jobs: 4 (f=4): [r(4)][100.0%][r=1584MiB/s][r=405k IOPS][eta 00m:00s]</span></span></code> </pre> <br>  Hier macht sich der Unterschied bereits bemerkbar.  Es kann gesagt werden, dass das System um weniger als 1% langsamer wurde, aber ein Verlust von etwa 7 Kiops auf einem stark belasteten System kann zu Problemen führen. <br><br>  Es ist klar, dass dieses Beispiel synthetisch ist, aber es ist sehr aufschlussreich. <br><br>  Versuchen wir, einen weiteren synthetischen Test durchzuführen, der Primzahlen berechnet - <i>sysbench</i> : <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># sysbench --max-time=10 --test=cpu run --num-threads=10 --cpu-max-prime=100000 ... Test execution summary: total time: 10.0140s total number of events: 3540 total time taken by event execution: 100.1248 per-request statistics: min: 28.26ms avg: 28.28ms max: 28.53ms approx. 95 percentile: 28.31ms Threads fairness: events (avg/stddev): 354.0000/0.00 execution time (avg/stddev): 10.0125/0.00 ~# perf record sysbench --max-time=10 --test=cpu run --num-threads=10 --cpu-max-prime=100000 … Test execution summary: total time: 10.0284s total number of events: 3498 total time taken by event execution: 100.2164 per-request statistics: min: 28.53ms avg: 28.65ms max: 28.89ms approx. 95 percentile: 28.67ms Threads fairness: events (avg/stddev): 349.8000/0.40 execution time (avg/stddev): 10.0216/0.01</span></span></code> </pre> <br>  Hier sehen Sie, dass sich sogar die minimale Verarbeitungszeit um 270 Mikrosekunden erhöht hat. <br><br><h3>  Anstelle einer Schlussfolgerung </h3><br>  <b>Perf</b> ist ein sehr leistungsfähiges Tool zur Analyse der Systemleistung und zum Debuggen.  Wie bei jedem anderen Tool müssen Sie jedoch die Kontrolle behalten und sich daran erinnern, dass jedes geladene System unter strenger Überwachung schlechter funktioniert. <br><br>  Verwandte Links: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Einzeilige Beispiele mit perf</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Perf Wiki</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de437808/">https://habr.com/ru/post/de437808/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de437796/index.html">Hat AlphaStar übermenschliche Geschwindigkeit als Patch für Simulationstrainingsfehler implementiert?</a></li>
<li><a href="../de437800/index.html">ScrumBut im Analytics-Team: vor dem Start</a></li>
<li><a href="../de437802/index.html">Innovative Cloud-Technologie: Katastrophale Cloud</a></li>
<li><a href="../de437804/index.html">Kann ich Redux auf einem Server verwenden?</a></li>
<li><a href="../de437806/index.html">EcmaScript 10 - Das diesjährige JavaScript (ES2019)</a></li>
<li><a href="../de437810/index.html">Unternehmensrealität</a></li>
<li><a href="../de437812/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 und andere Betas</a></li>
<li><a href="../de437814/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 und andere Beta-Versionen</a></li>
<li><a href="../de437816/index.html">MPLS ist überall. Wie ist die Yandex.Cloud-Netzwerkinfrastruktur?</a></li>
<li><a href="../de437818/index.html">Wir bringen dem Computer bei, Geräusche zu unterscheiden: Lernen Sie den DCASE-Wettbewerb kennen und bauen Sie Ihren Audio-Klassifikator in 30 Minuten zusammen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
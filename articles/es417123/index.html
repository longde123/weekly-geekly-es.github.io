<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔴 🍛 🤽🏼 Integración de Spark Streaming y Kafka 😝 🏤 🙀</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola colegas Le recordamos que no hace mucho tiempo publicamos un libro sobre Spark , y ahora mismo un libro sobre Kafka está siendo revisado. 


 Esp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Integración de Spark Streaming y Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/417123/">  Hola colegas  Le recordamos que no hace mucho tiempo publicamos un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">libro sobre Spark</a> , y ahora mismo un <a href="">libro sobre Kafka</a> está siendo revisado. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/it/cf/nj/itcfnjaffoo8apwikyd7_yfym5s.jpeg"></div><br>  Esperamos que estos libros tengan el éxito suficiente para continuar con el tema, por ejemplo, para la traducción y publicación de literatura sobre Spark Streaming.  Queríamos ofrecerle una traducción sobre la integración de esta tecnología con Kafka hoy. <br><a name="habracut"></a><br>  <b>1. Justificación</b> <br><br>  Apache Kafka + Spark Streaming es una de las mejores combinaciones para crear aplicaciones en tiempo real.  En este artículo, discutiremos en detalle los detalles de dicha integración.  Además, veremos un ejemplo con Spark Streaming-Kafka.  Luego discutimos el "enfoque del destinatario" y la opción de integración directa de Kafka y Spark Streaming.  Entonces, comencemos a integrar Kafka y Spark Streaming. <br><br><img src="https://habrastorage.org/webt/8x/jl/cp/8xjlcpzhwdwi4w2g87iifbquvr0.jpeg"><br><br>  <b>2. Integración de Kafka y Spark Streaming</b> <br><br>  Al integrar Apache Kafka y Spark Streaming, hay dos enfoques posibles para configurar Spark Streaming para recibir datos de Kafka, es decir,  dos enfoques para integrar Kafka y Spark Streaming.  En primer lugar, puede usar Destinatarios y la API de Kafka de alto nivel.  El segundo enfoque (más nuevo) es trabajar sin destinatarios.  Existen diferentes modelos de programación para ambos enfoques, que difieren, por ejemplo, en términos de rendimiento y garantías semánticas. <br><br><img src="https://habrastorage.org/webt/91/mn/sk/91mnsklu_81q0nx9aadnjgya4fc.png"><br><br>  Consideremos estos enfoques con más detalle. <br><br>  <i><b>a.</b></i>  <i><b>Enfoque basado en el destinatario</b></i> <br><br>  En este caso, el destinatario proporciona la recepción de datos.  Entonces, utilizando la API de consumo de alto nivel proporcionada por Kafka, implementamos el Destinatario.  Además, los datos recibidos se almacenan en Spark Artists.  Luego, se inician trabajos en Kafka - Spark Streaming, dentro de los cuales se procesan los datos. <br><br>  Sin embargo, cuando se utiliza este enfoque, el riesgo de pérdida de datos en caso de falla (con la configuración predeterminada) permanece.  En consecuencia, será necesario incluir adicionalmente un registro de escritura anticipada en Kafka - Spark Streaming para eliminar la pérdida de datos.  Por lo tanto, todos los datos recibidos de Kafka se almacenan sincrónicamente en el registro de escritura anticipada en un sistema de archivos distribuido.  Es por eso que, incluso después de una falla del sistema, todos los datos se pueden restaurar. <br><br>  A continuación, veremos cómo utilizar este enfoque con destinatarios en una aplicación con Kafka - Spark Streaming. <br><br>  <i>yo.</i>  <i>Vinculante</i> <br><br>  Ahora conectaremos nuestra aplicación de transmisión con el siguiente artefacto para aplicaciones Scala / Java, usaremos las definiciones de proyecto para SBT / Maven. <br><br><pre><code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  Sin embargo, al implementar nuestra aplicación, tendremos que agregar la biblioteca antes mencionada y sus dependencias, esto será necesario para las aplicaciones Python. <br><br>  <i>ii.</i>  <i>Programacion</i> <br><br>  Luego, cree una <code>DStream</code> entrada <code>DStream</code> importando <code>KafkaUtils</code> en el código de la aplicación de secuencia: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val kafkaStream = KafkaUtils.createStream(streamingContext, [ZK quorum], [consumer group id], [per-topic number of Kafka partitions to consume])</code> </pre> <br>  Además, utilizando las opciones de createStream, puede especificar clases clave y clases de valor, así como las clases correspondientes para su decodificación. <br><br>  <i>iii)</i>  <i>Despliegue</i> <br><br>  Como con cualquier aplicación Spark, el comando spark-submit se usa para iniciar.  Sin embargo, los detalles son ligeramente diferentes en las aplicaciones Scala / Java y en las aplicaciones Python. <br><br>  Además, con <code>–packages</code> puede agregar <code>spark-streaming-Kafka-0-8_2.11</code> y sus dependencias directamente a <code>spark-submit</code> , esto es útil para aplicaciones Python donde es imposible administrar proyectos usando SBT / Maven. <br><br><pre> <code class="java hljs">./bin/spark-submit --packages org.apache.spark:spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span>:<span class="hljs-number"><span class="hljs-number">2.2</span></span>.0 ...</code> </pre> <br>  También puede descargar el archivo JAR del <code>spark-streaming-Kafka-0-8-assembly</code> del artefacto Maven <code>spark-streaming-Kafka-0-8-assembly</code> desde el repositorio de Maven.  Luego agréguelo a <code>spark-submit</code> con - <code>jars</code> . <br><br>  <i>b.</i>  <i>Enfoque directo (sin destinatarios)</i> <br><br>  Después del enfoque utilizando destinatarios, se desarrolló un enfoque más nuevo, el "directo".  Proporciona garantías confiables de extremo a extremo.  En este caso, periódicamente le preguntamos a Kafka sobre las compensaciones de las compensaciones para cada tema / sección, y no organizamos la entrega de datos a través de los destinatarios.  Además, se determina el tamaño del fragmento de lectura, esto es necesario para el procesamiento correcto de cada paquete.  Finalmente, se usa una API de consumo simple para leer rangos con datos de Kafka con los desplazamientos dados, especialmente cuando se inician los trabajos de procesamiento de datos.  Todo el proceso es como leer archivos de un sistema de archivos. <br><br>  Nota: Esta característica apareció en Spark 1.3 para Scala y la API de Java, así como en Spark 1.4 para la API de Python. <br><br>  Ahora analicemos cómo aplicar este enfoque en nuestra aplicación de transmisión. <br>  La API del consumidor se describe con más detalle en el siguiente enlace: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Kafka Consumer |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ejemplos de Kafka Consumer</a> <br><br>  yo.  Vinculante <br><br>  Es cierto que este enfoque solo es compatible con aplicaciones Scala / Java.  Con el siguiente artefacto, construya el proyecto SBT / Maven. <br><br><pre> <code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  <i>ii.</i>  <i>Programacion</i> <br><br>  A continuación, importe KafkaUtils y cree un <code>DStream</code> entrada en el código de la aplicación de transmisión: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val directKafkaStream = KafkaUtils.createDirectStream[ [key <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">key</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">] ]( </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">streamingContext</span></span></span><span class="hljs-class">, [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">map</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Kafka</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">parameters</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">set</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">topics</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">to</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">consume</span></span></span><span class="hljs-class">])</span></span></code> </pre> <br>  En los parámetros de Kafka, deberá especificar <code>metadata.broker.list</code> o <code>bootstrap.servers</code> .  Por lo tanto, de manera predeterminada, consumiremos datos a partir del último desplazamiento en cada sección de Kafka.  Sin embargo, si desea que la lectura comience desde el fragmento más pequeño, entonces en los parámetros de Kafka debe establecer la opción de configuración <code>auto.offset.reset</code> . <br><br>  Además, trabajando con las opciones <code>KafkaUtils.createDirectStream</code> , puede comenzar a leer desde un desplazamiento arbitrario.  Luego haremos lo siguiente, que nos permitirá acceder a los fragmentos de Kafka consumidos en cada paquete. <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      ,        var offsetRanges = Array.empty[OffsetRange] directKafkaStream.transform { rdd =&gt; offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges rdd }.map { ... }.foreachRDD { rdd =&gt; for (o &lt;- offsetRanges) { println(s"${o.topic} ${o.partition} ${o.fromOffset} ${o.untilOffset}") } ... }</span></span></code> </pre> <br>  Si queremos organizar el monitoreo de Kafka basado en Zookeeper utilizando herramientas especiales, podemos actualizar Zookeeper nosotros mismos con su ayuda. <br><br>  <i>iii)</i>  <i>Despliegue</i> <br><br>  El proceso de implementación en este caso se asemeja al proceso de implementación en la variante con el destinatario. <br><br>  <b>3. Los beneficios de un enfoque directo</b> <br><br>  El segundo enfoque para integrar Spark Streaming con Kafka supera al primero por las siguientes razones: <br><br>  <b><i>a.</i></b>  <b><i>Simultaneidad Simultánea</i></b> <br><br>  En este caso, no necesita crear muchas secuencias de entrada de Kafka y combinarlas.  Sin embargo, Kafka - Spark Streaming creará tantos segmentos de RDD como segmentos de Kafka para consumo.  Todos estos datos de Kafka se leerán en paralelo.  Por lo tanto, podemos decir que tendremos una correspondencia uno a uno entre los segmentos de Kafka y RDD, y ese modelo es más comprensible y más fácil de configurar. <br><br>  <i><b>b.</b></i>  <i><b>Efectividad</b></i> <br><br>  Para eliminar por completo la pérdida de datos durante el primer enfoque, la información debía almacenarse en un registro de registros principales y luego replicarse.  De hecho, esto es ineficiente porque los datos se replican dos veces: la primera vez por el propio Kafka y la segunda por el registro de escritura anticipada.  En el segundo enfoque, este problema se elimina, ya que no hay destinatario y, por lo tanto, no se necesita un diario de escritura líder.  Si tenemos un almacenamiento de datos suficientemente largo en Kafka, puede recuperar mensajes directamente desde Kafka. <br><br>  <b><i>s</i></b>  <b><i>Semántica de una sola vez</i></b> <br><br>  Básicamente, utilizamos la API Kafka de alto nivel en el primer enfoque para almacenar fragmentos de lectura consumidos en Zookeeper.  Sin embargo, esta es la costumbre de consumir datos de Kafka.  Si bien la pérdida de datos se puede eliminar de manera confiable, existe una pequeña posibilidad de que, en algunos casos, los registros individuales se consuman dos veces.  El punto es la inconsistencia entre el mecanismo confiable de transferencia de datos en Kafka - Spark Streaming y la lectura de fragmentos que ocurre en Zookeeper.  Por lo tanto, en el segundo enfoque, usamos la API Kafka simple, que no requiere recurrir a Zookeeper.  Aquí, los fragmentos leídos se rastrean en Kafka - Spark Streaming, para esto, se utilizan puntos de control.  En este caso, se elimina la inconsistencia entre Spark Streaming y Zookeeper / Kafka. <br><br>  Por lo tanto, incluso en caso de fallas, Spark Streaming recibe cada registro estrictamente una vez.  Aquí debemos asegurarnos de que nuestra operación de salida, en la que los datos se almacenan en almacenamiento externo, sea idempotente o una transacción atómica en la que se almacenan tanto los resultados como las compensaciones.  Así es como se logra exactamente la semántica en la derivación de nuestros resultados. <br><br>  Aunque, hay un inconveniente: las compensaciones en Zookeeper no se actualizan.  Por lo tanto, las herramientas de monitoreo de Kafka basadas en Zookeeper no le permiten seguir el progreso. <br>  Sin embargo, todavía podemos referirnos a las compensaciones, si el procesamiento se organiza de esta manera: recurrimos a cada paquete y actualizamos Zookeeper nosotros mismos. <br><br>  Eso es todo lo que queríamos hablar sobre la integración de Apache Kafka y Spark Streaming.  Esperamos que lo hayas disfrutado. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417123/">https://habr.com/ru/post/es417123/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417111/index.html">Conferencias en línea: transmisión vs seminario web</a></li>
<li><a href="../es417113/index.html">Impresora italiana 3D en Rusia: Raise3D N1 Dual - modelado y creación de prototipos</a></li>
<li><a href="../es417115/index.html">Para enterrar o quemar Flutter.io?</a></li>
<li><a href="../es417117/index.html">Ingeniería inversa del emulador NES en el juego para GameCube</a></li>
<li><a href="../es417119/index.html">Paginación en Vue.js</a></li>
<li><a href="../es417125/index.html">RTC Meetup .Net: invitar a la primera reunión</a></li>
<li><a href="../es417127/index.html">Tesla firma un acuerdo para construir Gigafactory 3 en China</a></li>
<li><a href="../es417129/index.html">Universo de la mente</a></li>
<li><a href="../es417131/index.html">Cómo sentir las transacciones en MongoDB ahora</a></li>
<li><a href="../es417135/index.html">Unity3D: ¿cómo averiguar el grado de iluminación de un punto en una escena?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
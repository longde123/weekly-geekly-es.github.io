<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>  そ Integraci贸n de Spark Streaming y Kafka   </title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola colegas Le recordamos que no hace mucho tiempo publicamos un libro sobre Spark , y ahora mismo un libro sobre Kafka est谩 siendo revisado. 


 Esp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Integraci贸n de Spark Streaming y Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/417123/">  Hola colegas  Le recordamos que no hace mucho tiempo publicamos un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">libro sobre Spark</a> , y ahora mismo un <a href="">libro sobre Kafka</a> est谩 siendo revisado. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/it/cf/nj/itcfnjaffoo8apwikyd7_yfym5s.jpeg"></div><br>  Esperamos que estos libros tengan el 茅xito suficiente para continuar con el tema, por ejemplo, para la traducci贸n y publicaci贸n de literatura sobre Spark Streaming.  Quer铆amos ofrecerle una traducci贸n sobre la integraci贸n de esta tecnolog铆a con Kafka hoy. <br><a name="habracut"></a><br>  <b>1. Justificaci贸n</b> <br><br>  Apache Kafka + Spark Streaming es una de las mejores combinaciones para crear aplicaciones en tiempo real.  En este art铆culo, discutiremos en detalle los detalles de dicha integraci贸n.  Adem谩s, veremos un ejemplo con Spark Streaming-Kafka.  Luego discutimos el "enfoque del destinatario" y la opci贸n de integraci贸n directa de Kafka y Spark Streaming.  Entonces, comencemos a integrar Kafka y Spark Streaming. <br><br><img src="https://habrastorage.org/webt/8x/jl/cp/8xjlcpzhwdwi4w2g87iifbquvr0.jpeg"><br><br>  <b>2. Integraci贸n de Kafka y Spark Streaming</b> <br><br>  Al integrar Apache Kafka y Spark Streaming, hay dos enfoques posibles para configurar Spark Streaming para recibir datos de Kafka, es decir,  dos enfoques para integrar Kafka y Spark Streaming.  En primer lugar, puede usar Destinatarios y la API de Kafka de alto nivel.  El segundo enfoque (m谩s nuevo) es trabajar sin destinatarios.  Existen diferentes modelos de programaci贸n para ambos enfoques, que difieren, por ejemplo, en t茅rminos de rendimiento y garant铆as sem谩nticas. <br><br><img src="https://habrastorage.org/webt/91/mn/sk/91mnsklu_81q0nx9aadnjgya4fc.png"><br><br>  Consideremos estos enfoques con m谩s detalle. <br><br>  <i><b>a.</b></i>  <i><b>Enfoque basado en el destinatario</b></i> <br><br>  En este caso, el destinatario proporciona la recepci贸n de datos.  Entonces, utilizando la API de consumo de alto nivel proporcionada por Kafka, implementamos el Destinatario.  Adem谩s, los datos recibidos se almacenan en Spark Artists.  Luego, se inician trabajos en Kafka - Spark Streaming, dentro de los cuales se procesan los datos. <br><br>  Sin embargo, cuando se utiliza este enfoque, el riesgo de p茅rdida de datos en caso de falla (con la configuraci贸n predeterminada) permanece.  En consecuencia, ser谩 necesario incluir adicionalmente un registro de escritura anticipada en Kafka - Spark Streaming para eliminar la p茅rdida de datos.  Por lo tanto, todos los datos recibidos de Kafka se almacenan sincr贸nicamente en el registro de escritura anticipada en un sistema de archivos distribuido.  Es por eso que, incluso despu茅s de una falla del sistema, todos los datos se pueden restaurar. <br><br>  A continuaci贸n, veremos c贸mo utilizar este enfoque con destinatarios en una aplicaci贸n con Kafka - Spark Streaming. <br><br>  <i>yo.</i>  <i>Vinculante</i> <br><br>  Ahora conectaremos nuestra aplicaci贸n de transmisi贸n con el siguiente artefacto para aplicaciones Scala / Java, usaremos las definiciones de proyecto para SBT / Maven. <br><br><pre><code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  Sin embargo, al implementar nuestra aplicaci贸n, tendremos que agregar la biblioteca antes mencionada y sus dependencias, esto ser谩 necesario para las aplicaciones Python. <br><br>  <i>ii.</i>  <i>Programacion</i> <br><br>  Luego, cree una <code>DStream</code> entrada <code>DStream</code> importando <code>KafkaUtils</code> en el c贸digo de la aplicaci贸n de secuencia: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val kafkaStream = KafkaUtils.createStream(streamingContext, [ZK quorum], [consumer group id], [per-topic number of Kafka partitions to consume])</code> </pre> <br>  Adem谩s, utilizando las opciones de createStream, puede especificar clases clave y clases de valor, as铆 como las clases correspondientes para su decodificaci贸n. <br><br>  <i>iii)</i>  <i>Despliegue</i> <br><br>  Como con cualquier aplicaci贸n Spark, el comando spark-submit se usa para iniciar.  Sin embargo, los detalles son ligeramente diferentes en las aplicaciones Scala / Java y en las aplicaciones Python. <br><br>  Adem谩s, con <code>packages</code> puede agregar <code>spark-streaming-Kafka-0-8_2.11</code> y sus dependencias directamente a <code>spark-submit</code> , esto es 煤til para aplicaciones Python donde es imposible administrar proyectos usando SBT / Maven. <br><br><pre> <code class="java hljs">./bin/spark-submit --packages org.apache.spark:spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span>:<span class="hljs-number"><span class="hljs-number">2.2</span></span>.0 ...</code> </pre> <br>  Tambi茅n puede descargar el archivo JAR del <code>spark-streaming-Kafka-0-8-assembly</code> del artefacto Maven <code>spark-streaming-Kafka-0-8-assembly</code> desde el repositorio de Maven.  Luego agr茅guelo a <code>spark-submit</code> con - <code>jars</code> . <br><br>  <i>b.</i>  <i>Enfoque directo (sin destinatarios)</i> <br><br>  Despu茅s del enfoque utilizando destinatarios, se desarroll贸 un enfoque m谩s nuevo, el "directo".  Proporciona garant铆as confiables de extremo a extremo.  En este caso, peri贸dicamente le preguntamos a Kafka sobre las compensaciones de las compensaciones para cada tema / secci贸n, y no organizamos la entrega de datos a trav茅s de los destinatarios.  Adem谩s, se determina el tama帽o del fragmento de lectura, esto es necesario para el procesamiento correcto de cada paquete.  Finalmente, se usa una API de consumo simple para leer rangos con datos de Kafka con los desplazamientos dados, especialmente cuando se inician los trabajos de procesamiento de datos.  Todo el proceso es como leer archivos de un sistema de archivos. <br><br>  Nota: Esta caracter铆stica apareci贸 en Spark 1.3 para Scala y la API de Java, as铆 como en Spark 1.4 para la API de Python. <br><br>  Ahora analicemos c贸mo aplicar este enfoque en nuestra aplicaci贸n de transmisi贸n. <br>  La API del consumidor se describe con m谩s detalle en el siguiente enlace: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Kafka Consumer |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ejemplos de Kafka Consumer</a> <br><br>  yo.  Vinculante <br><br>  Es cierto que este enfoque solo es compatible con aplicaciones Scala / Java.  Con el siguiente artefacto, construya el proyecto SBT / Maven. <br><br><pre> <code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  <i>ii.</i>  <i>Programacion</i> <br><br>  A continuaci贸n, importe KafkaUtils y cree un <code>DStream</code> entrada en el c贸digo de la aplicaci贸n de transmisi贸n: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val directKafkaStream = KafkaUtils.createDirectStream[ [key <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">key</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">] ]( </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">streamingContext</span></span></span><span class="hljs-class">, [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">map</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Kafka</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">parameters</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">set</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">topics</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">to</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">consume</span></span></span><span class="hljs-class">])</span></span></code> </pre> <br>  En los par谩metros de Kafka, deber谩 especificar <code>metadata.broker.list</code> o <code>bootstrap.servers</code> .  Por lo tanto, de manera predeterminada, consumiremos datos a partir del 煤ltimo desplazamiento en cada secci贸n de Kafka.  Sin embargo, si desea que la lectura comience desde el fragmento m谩s peque帽o, entonces en los par谩metros de Kafka debe establecer la opci贸n de configuraci贸n <code>auto.offset.reset</code> . <br><br>  Adem谩s, trabajando con las opciones <code>KafkaUtils.createDirectStream</code> , puede comenzar a leer desde un desplazamiento arbitrario.  Luego haremos lo siguiente, que nos permitir谩 acceder a los fragmentos de Kafka consumidos en cada paquete. <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      ,        var offsetRanges = Array.empty[OffsetRange] directKafkaStream.transform { rdd =&gt; offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges rdd }.map { ... }.foreachRDD { rdd =&gt; for (o &lt;- offsetRanges) { println(s"${o.topic} ${o.partition} ${o.fromOffset} ${o.untilOffset}") } ... }</span></span></code> </pre> <br>  Si queremos organizar el monitoreo de Kafka basado en Zookeeper utilizando herramientas especiales, podemos actualizar Zookeeper nosotros mismos con su ayuda. <br><br>  <i>iii)</i>  <i>Despliegue</i> <br><br>  El proceso de implementaci贸n en este caso se asemeja al proceso de implementaci贸n en la variante con el destinatario. <br><br>  <b>3. Los beneficios de un enfoque directo</b> <br><br>  El segundo enfoque para integrar Spark Streaming con Kafka supera al primero por las siguientes razones: <br><br>  <b><i>a.</i></b>  <b><i>Simultaneidad Simult谩nea</i></b> <br><br>  En este caso, no necesita crear muchas secuencias de entrada de Kafka y combinarlas.  Sin embargo, Kafka - Spark Streaming crear谩 tantos segmentos de RDD como segmentos de Kafka para consumo.  Todos estos datos de Kafka se leer谩n en paralelo.  Por lo tanto, podemos decir que tendremos una correspondencia uno a uno entre los segmentos de Kafka y RDD, y ese modelo es m谩s comprensible y m谩s f谩cil de configurar. <br><br>  <i><b>b.</b></i>  <i><b>Efectividad</b></i> <br><br>  Para eliminar por completo la p茅rdida de datos durante el primer enfoque, la informaci贸n deb铆a almacenarse en un registro de registros principales y luego replicarse.  De hecho, esto es ineficiente porque los datos se replican dos veces: la primera vez por el propio Kafka y la segunda por el registro de escritura anticipada.  En el segundo enfoque, este problema se elimina, ya que no hay destinatario y, por lo tanto, no se necesita un diario de escritura l铆der.  Si tenemos un almacenamiento de datos suficientemente largo en Kafka, puede recuperar mensajes directamente desde Kafka. <br><br>  <b><i>s</i></b>  <b><i>Sem谩ntica de una sola vez</i></b> <br><br>  B谩sicamente, utilizamos la API Kafka de alto nivel en el primer enfoque para almacenar fragmentos de lectura consumidos en Zookeeper.  Sin embargo, esta es la costumbre de consumir datos de Kafka.  Si bien la p茅rdida de datos se puede eliminar de manera confiable, existe una peque帽a posibilidad de que, en algunos casos, los registros individuales se consuman dos veces.  El punto es la inconsistencia entre el mecanismo confiable de transferencia de datos en Kafka - Spark Streaming y la lectura de fragmentos que ocurre en Zookeeper.  Por lo tanto, en el segundo enfoque, usamos la API Kafka simple, que no requiere recurrir a Zookeeper.  Aqu铆, los fragmentos le铆dos se rastrean en Kafka - Spark Streaming, para esto, se utilizan puntos de control.  En este caso, se elimina la inconsistencia entre Spark Streaming y Zookeeper / Kafka. <br><br>  Por lo tanto, incluso en caso de fallas, Spark Streaming recibe cada registro estrictamente una vez.  Aqu铆 debemos asegurarnos de que nuestra operaci贸n de salida, en la que los datos se almacenan en almacenamiento externo, sea idempotente o una transacci贸n at贸mica en la que se almacenan tanto los resultados como las compensaciones.  As铆 es como se logra exactamente la sem谩ntica en la derivaci贸n de nuestros resultados. <br><br>  Aunque, hay un inconveniente: las compensaciones en Zookeeper no se actualizan.  Por lo tanto, las herramientas de monitoreo de Kafka basadas en Zookeeper no le permiten seguir el progreso. <br>  Sin embargo, todav铆a podemos referirnos a las compensaciones, si el procesamiento se organiza de esta manera: recurrimos a cada paquete y actualizamos Zookeeper nosotros mismos. <br><br>  Eso es todo lo que quer铆amos hablar sobre la integraci贸n de Apache Kafka y Spark Streaming.  Esperamos que lo hayas disfrutado. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es417123/">https://habr.com/ru/post/es417123/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es417111/index.html">Conferencias en l铆nea: transmisi贸n vs seminario web</a></li>
<li><a href="../es417113/index.html">Impresora italiana 3D en Rusia: Raise3D N1 Dual - modelado y creaci贸n de prototipos</a></li>
<li><a href="../es417115/index.html">Para enterrar o quemar Flutter.io?</a></li>
<li><a href="../es417117/index.html">Ingenier铆a inversa del emulador NES en el juego para GameCube</a></li>
<li><a href="../es417119/index.html">Paginaci贸n en Vue.js</a></li>
<li><a href="../es417125/index.html">RTC Meetup .Net: invitar a la primera reuni贸n</a></li>
<li><a href="../es417127/index.html">Tesla firma un acuerdo para construir Gigafactory 3 en China</a></li>
<li><a href="../es417129/index.html">Universo de la mente</a></li>
<li><a href="../es417131/index.html">C贸mo sentir las transacciones en MongoDB ahora</a></li>
<li><a href="../es417135/index.html">Unity3D: 驴c贸mo averiguar el grado de iluminaci贸n de un punto en una escena?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∏üèæ ‚ò∫Ô∏è üë©‚Äçüë¶ Das Buch "C ++. Die Praxis der Multithread-Programmierung " üíÇüèº üõ∂ üòó</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hi, habrozhiteli! Die Sprache C ++ wird gew√§hlt, wenn Sie wirklich blitzschnelle Anwendungen erstellen m√ºssen. Und eine wettbewerbsf√§hige Verarbeitung...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das Buch "C ++. Die Praxis der Multithread-Programmierung "</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/484818/"> <a href="https://habr.com/ru/company/piter/blog/484818/"><img src="https://habrastorage.org/webt/cr/ym/3u/crym3urkeecjcfe-nsvq0nrw59y.jpeg" align="left" alt="Bild"></a>  Hi, habrozhiteli!  Die Sprache C ++ wird gew√§hlt, wenn Sie wirklich blitzschnelle Anwendungen erstellen m√ºssen.  Und eine wettbewerbsf√§hige Verarbeitung von hoher Qualit√§t wird sie noch schneller machen.  Mit den neuen Funktionen von C ++ 17 k√∂nnen Sie die volle Leistungsf√§higkeit der Multithread-Programmierung nutzen, um auf einfache Weise die Probleme der Grafikverarbeitung, des maschinellen Lernens usw. zu l√∂sen. Anthony Williams, Experte f√ºr wettbewerbsorientierte Verarbeitung, betrachtet Beispiele und beschreibt praktische Aufgaben und gibt Geheimnisse preis, die f√ºr alle von Nutzen sind einschlie√ülich der erfahrensten Entwickler. <br><br>  Im Buch ‚Ä¢ Ein vollst√§ndiger √úberblick √ºber die Funktionen von C ++ 17.  ‚Ä¢ Start und Ablaufsteuerung.  ‚Ä¢ Synchronisation von Wettbewerbsvorg√§ngen.  ‚Ä¢ Entwicklung von Wettbewerbscode.  ‚Ä¢ Debuggen von Multithread-Anwendungen.  Das Buch eignet sich f√ºr Entwickler mit mittlerer Entwicklungsstufe, die C und C ++ verwenden.  Programmiererfahrung ist nicht erforderlich. <br><a name="habracut"></a><br><h3>  Wettbewerbsf√§hige Code-Entwicklung </h3><br><h3>  8.1.  M√∂glichkeiten zum Verteilen der Arbeit zwischen Threads </h3><br>  Stellen Sie sich vor, Sie m√ºssen ein Haus bauen.  Dazu m√ºssen Sie eine Baugrube graben, das Fundament selbst f√ºllen, Mauern errichten, Rohre und elektrische Leitungen verlegen usw. Theoretisch kann mit ausreichenden Kenntnissen alles unabh√§ngig durchgef√ºhrt werden, aber h√∂chstwahrscheinlich wird es viel Zeit in Anspruch nehmen und Sie m√ºssen von einem Job auf einen anderen wechseln ein anderer.  Man kann aber Assistenten einstellen.  Dann m√ºssen Sie ausw√§hlen, wie viele Assistenten eingestellt werden sollen, und entscheiden, wozu sie in der Lage sein sollen.  Sie k√∂nnen zum Beispiel zwei Arbeiter einstellen und mit ihnen arbeiten.  Dann muss man noch von einem Werk zum anderen wechseln, aber jetzt wird es schneller gehen, da es mehr K√ºnstler geben wird. <br><br>  Sie k√∂nnen eine andere Option w√§hlen - ein Team von Spezialisten wie Maurer, Schreiner, Elektriker und Klempner einstellen.  Jeder wird in seiner eigenen Spezialit√§t arbeiten, daher wird er unt√§tig sitzen, bis der Klempner eine Arbeitsfront hat.  Und doch wird es schneller gehen als zuvor, da es mehr Arbeiter gibt, und w√§hrend der Elektriker die Verkabelung in der K√ºche durchf√ºhrt, kann der Klempner zur Toilette gehen.  Wenn jedoch f√ºr einen bestimmten Spezialisten keine Arbeit geleistet wird, entstehen mehr Ausfallzeiten.  Es kann jedoch festgestellt werden, dass die Arbeit trotz der ber√ºcksichtigten Ausfallzeiten schneller von einem Spezialisten als von einem Arbeitsteam ausgef√ºhrt wird.  Spezialisten m√ºssen die Werkzeuge nicht st√§ndig wechseln, und mit Sicherheit erledigt jeder seine Aufgabe schneller als der Arbeiter.  Ob dies tats√§chlich so sein wird, h√§ngt von den konkreten Umst√§nden ab: Alles wird in der Praxis gelernt. <br><br>  Auch wenn Sie Spezialisten einbeziehen, m√ºssen Sie immer noch eine andere Anzahl von Arbeitern verschiedener Fachrichtungen ausw√§hlen.  Vielleicht ist es sinnvoll, zum Beispiel mehr Maurer als Elektriker einzustellen.  Dar√ºber hinaus k√∂nnen sich die Zusammensetzung Ihres Teams und die allgemeine Effektivit√§t seiner Arbeit √§ndern, wenn Sie mehrere H√§user gleichzeitig bauen m√ºssen.  Auch wenn ein Klempner in einem Haus nur wenig Arbeit hat, kann der Bau mehrerer H√§user gleichzeitig den ganzen Tag dauern.  Wenn Sie keine Spezialisten f√ºr Ausfallzeiten bezahlen m√ºssen, k√∂nnen Sie au√üerdem ein gr√∂√üeres Team einstellen, auch wenn sich die Anzahl der gleichzeitig arbeitenden Personen nicht √§ndert. <br><br>  Aber h√∂r auf √ºber den Bau zu reden.  Was hat das alles mit Threads zu tun?  Sie k√∂nnen √§hnliche √úberlegungen anstellen.  Sie m√ºssen entscheiden, wie viele Threads verwendet werden und welche Aufgaben sie ausf√ºhren sollen.  Ben√∂tigen wir Universalf√§den, die die Arbeit erledigen, die zu einem bestimmten Zeitpunkt ben√∂tigt wird, oder Spezialf√§den, die gut auf nur eine Sache abgestimmt sind?  Oder lohnt es sich, beides zu kombinieren?  Diese Entscheidungen m√ºssen unabh√§ngig von den Gr√ºnden f√ºr die Parallelisierung des Programms getroffen werden, und die Leistung und Klarheit des Codes h√§ngen wesentlich davon ab, wie erfolgreich sie sind.  Daher ist es wichtig, sich vorzustellen, welche Optionen zur Verf√ºgung stehen, um bei der Entwicklung der Anwendungsstruktur eine kompetente Entscheidung zu treffen.  In diesem Abschnitt werden verschiedene Methoden zum Verteilen von Aufgaben behandelt, beginnend mit der Verteilung von Daten zwischen Threads, bis andere Arbeiten ausgef√ºhrt wurden. <br><br><h3>  8.1.1.  Verteilung von Daten zwischen Threads vor der Verarbeitung </h3><br>  Am einfachsten zu parallelisieren sind einfache Algorithmen wie std :: for_each, die Operationen f√ºr jedes Element eines Datensatzes ausf√ºhren.  Um diesen Algorithmus zu parallelisieren, k√∂nnen Sie jedes Element einem der Verarbeitungsthreads zuordnen.  In Zukunft wird bei der Betrachtung von Leistungsproblemen deutlich, dass die beste Verteilungsoption zur Erzielung einer optimalen Leistung von den Merkmalen der Datenstruktur abh√§ngt. <br><br>  Der einfachste Fall beim Verteilen von Daten ist, wenn die ersten N Elemente einem Stream, die n√§chsten N Elemente einem anderen Stream usw. zugewiesen werden (Abb. 8.1). Es k√∂nnen jedoch auch andere Schemata verwendet werden.  Unabh√§ngig von der Methode der Datenverteilung verarbeitet jeder Thread nur die ihm zugewiesenen Elemente, ohne mit anderen Threads zu interagieren, bis die Verarbeitung abgeschlossen ist. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ie/ex/rm/ieexrmf49u6qerfqmuhtcgpbgpe.png" alt="Bild"></div><br>  Die Struktur sollte allen bekannt sein, die mit der Programmierung in den Umgebungen Message Passing Interface (MPI, <a href="http://www.mpi-forum.org/">www.mpi-forum.org</a> ) oder OpenMP (http://www.openmp.org/) gearbeitet haben: Die Aufgabe ist in viele Aufgaben unterteilt, die parallel ausgef√ºhrt werden. Workflows f√ºhren sie unabh√§ngig voneinander aus, und die Ergebnisse werden in der letzten Informationsphase gesammelt.  Dieser Ansatz wurde im Beispiel mit der Akkumulationsfunktion aus Abschnitt 2.4 verwendet: Sowohl parallele Tasks als auch die Reduktionsstufe sind Akkumulationen.  F√ºr einen einfachen for_each-Algorithmus fehlt der letzte Schritt, da nichts zu reduzieren ist. <br><br>  Die Tatsache, dass eine Mischung als das Wesentliche der Endstufe definiert ist, spielt eine sehr wichtige Rolle: Eine elementare Implementierung √§hnlich der in Listing 2.9 gezeigten f√ºhrt diese Mischung als letzte sequenzielle Stufe aus.  Diese Phase wird jedoch h√§ufig auch parallelisiert: Die Akkumulation ist eine Reduktionsoperation, sodass der Code in Listing 2.9 ge√§ndert werden kann, um einen rekursiven Aufruf desselben Codes zu erhalten, wenn beispielsweise die Anzahl der Threads die Mindestanzahl der vom Thread verarbeiteten Elemente √ºberschreitet.  Sie k√∂nnen Workflows auch zwingen, Rollup-Schritte auszuf√ºhren, sobald jeder von ihnen seine Aufgabe abgeschlossen hat, anstatt jedes Mal neue Threads zu starten. <br><br>  Bei aller Wirksamkeit ist diese Technik nicht vielseitig.  Manchmal k√∂nnen Daten nicht genau im Voraus aufgeteilt werden, da die Zusammensetzung jedes Teils erst w√§hrend der Verarbeitung bekannt wird.  Dies zeigt sich insbesondere bei der Verwendung von rekursiven Algorithmen wie Quicksort, weshalb ein anderer Ansatz erforderlich ist. <br><br><h3>  8.1.2.  Rekursive Datenverteilung </h3><br>  Der Quicksort-Algorithmus besteht aus zwei Hauptschritten: Aufteilen der Daten in zwei Teile - alles, was zu einem der Elemente (Referenz) f√ºhrt, und alles danach in der endg√ºltigen Sortierreihenfolge und rekursives Sortieren dieser beiden H√§lften.  Es ist unm√∂glich, sie durch vorl√§ufige Aufteilung der Daten zu parallelisieren, da nur w√§hrend der Verarbeitung der Elemente bestimmt werden kann, in welche ‚ÄûH√§lfte‚Äú sie fallen.  Wenn Sie diesen Algorithmus parallelisieren m√∂chten, m√ºssen Sie das Wesentliche der Rekursion verwenden.  Auf jeder Rekursionsstufe werden immer mehr Aufrufe der Funktion quick_sort ausgef√ºhrt, da Sie sowohl diejenigen sortieren m√ºssen, die gr√∂√üer als die Referenz sind, als auch diejenigen, die kleiner als diese sind.  Diese rekursiven Aufrufe sind voneinander unabh√§ngig, da sie sich auf separate Elementmengen beziehen.  Aus diesem Grund sind sie die ersten Kandidaten f√ºr die Wettbewerbsf√§higkeit.  Diese rekursive Verteilung ist in Fig. 2 dargestellt.  8.2. <br><br>  Diese Implementierung wurde bereits in Kapitel 4 erf√ºllt. Anstatt zwei rekursive Aufrufe f√ºr die gr√∂√üere und kleinere H√§lfte durchzuf√ºhren, haben wir die Funktion std :: async () verwendet, die bei jedem Schritt asynchrone Tasks f√ºr die kleinere H√§lfte ausf√ºhrt.  Aufgrund der Verwendung von std :: async () musste die C ++ - Threadbibliothek entscheiden, wann die Task in einem neuen Thread gestartet werden soll und wann - im synchronen Modus. <br><br>  Es gibt einen wichtigen Umstand: Wenn Sie einen gro√üen Datensatz sortieren, f√ºhrt das Starten eines neuen Threads f√ºr jede Rekursion zu einem schnellen Anstieg der Anzahl der Threads.  Bei der Untersuchung von Leistungsproblemen wird angezeigt, dass zu viele Threads die Anwendung verlangsamen k√∂nnen.  Dar√ºber hinaus ist eine gro√üe Anzahl von Datenfl√ºssen m√∂glicherweise nicht ausreichend.  Die Idee, die gesamte Aufgabe in einem solchen rekursiven Modus aufzuteilen, scheint sehr erfolgreich zu sein. Sie m√ºssen lediglich die Anzahl der Threads sorgf√§ltig √ºberwachen.  In einfachen F√§llen √ºbernimmt die Funktion std :: async () diese Aufgabe, es gibt jedoch auch andere Optionen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/ji/l3/rzjil3fye0-nfj2quxo75cvxon4.png" alt="Bild"></div><br>  Eine davon besteht darin, die Funktion std :: thread :: hardware_concurrency () zu verwenden, um die Anzahl der Threads auszuw√§hlen, wie dies in der parallelen Version der Funktion accumulate () aus Listing 2.9 der Fall war.  Anstatt f√ºr jeden rekursiven Aufruf einen neuen Thread zu starten, k√∂nnen Sie das zu sortierende Fragment beispielsweise wie in den Kapiteln 6 und 7 beschrieben auf einen thread-sicheren Stapel legen. Wenn der Thread nichts zu tun hat oder die Verarbeitung aller seiner Fragmente abgeschlossen ist oder auf das Sortieren des Fragments wartet, kann er es nimm ein fragment aus dem stapel und sortiere es. <br><br>  Listing 8.1 zeigt eine einfache Implementierung dieser Technologie.  Wie in den meisten anderen Beispielen wird nur die Absicht demonstriert, und es handelt sich nicht um einen Code, der f√ºr die praktische Verwendung bereit ist.  Wenn Sie den C ++ 17-Compiler verwenden und Ihre Bibliothek ihn unterst√ºtzt, sollten Sie die von der Standardbibliothek bereitgestellten parallelen Algorithmen gem√§√ü den Beschreibungen in Kapitel 10 verwenden. <br><br>  Listing 8.1.  Ein paralleler Quicksort-Algorithmus, der einen Stapel von Fragmenten verwendet, die auf die Sortierung warten <br><br><img src="https://habrastorage.org/webt/ko/nb/h6/konbh6b_q40lp0uz-gxyunwws3g.png" alt="Bild"><br><img src="https://habrastorage.org/webt/5s/md/52/5smd5279wgwzktq4thil54lidqy.png" alt="Bild"><br><img src="https://habrastorage.org/webt/ro/js/kt/rojsktncuxgmls2wtndzt9ywhqy.png" alt="Bild"><br><br>  Hier ordnet die Funktion parallel_quick_sort <b>(19)</b> den Gro√üteil der funktionalen Verantwortlichkeiten der Klasse sorter <b>(1) zu</b> , wodurch der Stapel unsortierter Fragmente <b>(2)</b> und mehrerer Threads <b>(3) auf</b> einfache Weise gruppiert werden kann.  Die Hauptarbeit wird in der do_sort-Komponentenfunktion <b>(9) ausgef√ºhrt</b> , die mit der √ºblichen Datenpartitionierung <b>(10) belegt ist</b> .  Dieses Mal wird kein neuer Thread f√ºr jedes Fragment gestartet, sondern dieses Fragment auf dem Stapel (11) abgelegt und nur dann ein neuer Thread gestartet, wenn eine freie Prozessorressource vorhanden ist (12).  Da ein Fragment mit niedrigeren Werten als dem des Referenz-Streams von einem anderen Stream verarbeitet werden kann, sollten wir auf dessen Bereitschaft warten <b>(13)</b> .  Damit keine Zeit verschwendet wird (f√ºr den Fall, dass wir einen einzelnen Thread haben oder alle anderen Threads bereits belegt sind), wird versucht, Fragmente aus dem Stapel f√ºr diese Wartezeit zu verarbeiten <b>(14)</b> .  Die try_sort_chunk-Funktion ruft ein Fragment aus dem Stapel <b>(7) ab</b> , sortiert es <b>(8)</b> und speichert die Ergebnisse in dem Versprechungsversprechen, damit sie den Stream empfangen k√∂nnen, der dieses Fragment auf den Stapel legt <b>(15)</b> . <br><br>  Jetzt befinden sich gerade gestartete Threads in einer Schleife und versuchen, Fragmente aus dem Stapel <b>(17)</b> zu sortieren, wenn das Flag end_of_data <b>(16)</b> nicht gesetzt ist.  Zwischen √úberpr√ºfungen geben sie die Rechenressource an andere Threads weiter, damit sie zus√§tzliche Arbeit auf den Stapel schieben k√∂nnen.  Die Arbeit des Codes beim Ordnen dieser Threads h√§ngt vom Destruktor Ihrer Sorter <b>(4)</b> -Klasse ab.  Wenn alle Daten sortiert sind, gibt die Funktion do_sort die Kontrolle zur√ºck (auch wenn die Aktivit√§t der Arbeitsthreads beibehalten wird), der Hauptthread kehrt von parallel_quick_sort <b>(20) zur√ºck</b> und zerst√∂rt das Sortiererobjekt.  Durch Setzen des Flags end_of_data <b>(5)</b> wird gewartet, bis die Threads ihre Arbeit beendet haben <b>(6). Durch</b> Setzen des Flags wird die Schleife in der Threads-Funktion gestoppt (16). <br><br>  Mit diesem Ansatz verschwindet das Problem der unbegrenzten Anzahl von Threads, die in der Funktion spawn_task enthalten sind, mit der der neue Thread gestartet wurde, und die Abh√§ngigkeit von der C ++ - Threadbibliothek, die die Anzahl der Threads f√ºr Sie ausw√§hlt, wie dies bei der Verwendung von std :: async () der Fall ist.  Stattdessen wird die Anzahl der Threads durch den von der Funktion std :: thread :: hardware_concurrency () zur√ºckgegebenen Wert begrenzt, um ein zu h√§ufiges Wechseln der Tasks zu verhindern.  Es ergibt sich jedoch ein anderes Problem: Die Verwaltung dieser Streams und der Datenaustausch zwischen ihnen erschweren den Code erheblich.  Obwohl Threads einzelne Datenelemente verarbeiten, greifen alle auf den Stapel zu, f√ºgen neue Fragmente hinzu und nehmen Fragmente f√ºr die Verarbeitung auf.  Solch ein intensiver Wettbewerb kann die Leistung verringern, selbst wenn ein sperrfreier (daher nicht blockierender) Stapel verwendet wird, und die Gr√ºnde daf√ºr werden bald in Betracht gezogen. <br><br>  Dieser Ansatz ist eine spezielle Version des Thread-Pools - ein Satz von Threads, von denen jeder Arbeit aus der Liste der zur√ºckgestellten Jobs erh√§lt, sie ausf√ºhrt und dann die Liste nach einem neuen durchsucht.  In Kapitel 9 werden einige potenzielle Probleme des Thread-Pools (einschlie√ülich der Konkurrenz beim Zugriff auf die Liste der Werke) und M√∂glichkeiten zu ihrer L√∂sung er√∂rtert. Nachdem Sie die erstellte Anwendung so skaliert haben, dass sie auf mehreren Prozessoren ausgef√ºhrt wird, werden Sie sp√§ter auf dieses Kapitel eingehen (siehe Unterabschnitt 8.2.1). <br><br>  Bei der Verteilung von Daten sowohl vor der Verarbeitung als auch im rekursiven Modus wird davon ausgegangen, dass sie im Voraus festgelegt wurden und eine Suche nach ihrer Verteilung durchgef√ºhrt wird.  Dies ist jedoch nicht immer der Fall: Wenn die Daten im dynamischen Modus erstellt werden oder aus einer externen Quelle stammen, funktioniert dieser Ansatz nicht.  In diesem Fall ist es m√∂glicherweise sinnvoller, die Arbeit nach Art der Aufgabe und nicht nach den Daten selbst zu verteilen. <br><br><h3>  8.1.3.  Verteilung der Arbeit nach Aufgabentyp </h3><br>  Die Aufteilung der Arbeit zwischen den Threads durch Zuweisung der einzelnen Daten (vorab oder w√§hrend der Datenverarbeitung rekursiv) basiert auf der Annahme, dass die Threads an jedem Teil die gleiche Arbeit leisten werden.  Eine alternative Arbeitsteilung ist die Spezialisierung der Abl√§ufe, bei der jeder eine eigene Aufgabe ausf√ºhrt, da Klempner und Elektriker beim Hausbau unterschiedliche Aufgaben ausf√ºhren.  Streams k√∂nnen mit unterschiedlichen oder denselben Daten arbeiten, im letzteren Fall jedoch f√ºr unterschiedliche Zwecke. <br><br>  Diese eigent√ºmliche Arbeitsteilung ergibt sich aus der Aufgabentrennung mit Hilfe des Wettbewerbs: Jeder Thread hat eine eigene Aufgabe, die er unabh√§ngig von anderen Abl√§ufen erledigt.  Manchmal k√∂nnen andere Threads Daten an den Stream liefern oder Ereignisse erzeugen, auf die er reagieren sollte. Im Allgemeinen konzentriert sich jeder Stream jedoch auf die hohe Leistung einer einzelnen Aufgabe.  Dies ist eine gute Grundkonstruktion, bei der jeder Code f√ºr eine Sache verantwortlich sein sollte. <br><br><h3>  Verteilung der Arbeit nach Art der Aufgabe, um die Verantwortung zu teilen </h3><br>  Eine Single-Threaded-Anwendung muss mit Konflikten im Zusammenhang mit dem Prinzip der Einzelverantwortung fertig werden, wenn mehrere Aufgaben f√ºr eine bestimmte Zeit ununterbrochen ausgef√ºhrt werden m√ºssen, oder die Anwendung muss die rechtzeitige Verarbeitung eingehender Ereignisse bew√§ltigen (z. B. wenn ein Benutzer eine Taste dr√ºckt oder Daten √ºber das Netzwerk eingehen). in Gegenwart anderer unvollendeter Aufgaben.  In einer Single-Threaded-Computerumgebung m√ºssen Sie unabh√§ngig Code erstellen, der einen Teil von Task A und einen Teil von Task B ausf√ºhrt, √ºberpr√ºft, ob die Taste gedr√ºckt wurde und keine Netzwerkpakete vorhanden sind, und dann zyklisch zum n√§chsten Teil von Task A zur√ºckkehren. Dies erschwert die Ausf√ºhrung des Codes Aufgaben A aufgrund der Notwendigkeit, seinen Zustand beizubehalten und die Steuerung regelm√§√üig an die Hauptschleife zur√ºckzugeben.  Wenn Sie dem Zyklus zu viele Aufgaben hinzuf√ºgen, kann die Arbeit erheblich verlangsamt werden und der Benutzer wird wahrscheinlich eine langsame Reaktion auf Tastenanschl√§ge bemerken.  Ich bin sicher, dass jeder die extremen Manifestationen einer √§hnlichen Situation in bestimmten Anwendungen beobachtet hat: Sie haben eine Aufgabe f√ºr die Anwendung festgelegt, und die Benutzeroberfl√§che reagiert erst, wenn sie abgeschlossen ist. <br><br>  Hier kommen Str√∂me auf die B√ºhne.  Wenn Sie jede Task in einem separaten Thread ausf√ºhren, kann dies das Betriebssystem anstelle von Ihnen ausf√ºhren.  Im Code f√ºr Aufgabe A k√∂nnen Sie sich darauf konzentrieren, die Aufgabe zu erledigen, ohne sich Gedanken √ºber die Beibehaltung des Status und die R√ºckkehr zur Hauptschleife zu machen oder dar√ºber, wie viel Zeit vergehen wird, bevor dies geschieht.  Das hei√üt, das Betriebssystem speichert den Status automatisch und wechselt zur richtigen Zeit zu Task B oder C, und wenn das System, auf dem das Programm ausgef√ºhrt wird, √ºber mehrere Kerne oder Prozessoren verf√ºgt, k√∂nnen die Tasks A und B gleichzeitig ausgef√ºhrt werden. Der Code f√ºr die Verarbeitung von Tastenanschl√§gen oder Quittungen Netzwerkpakete k√∂nnen jetzt zeitnah ausgef√ºhrt werden, und jeder wird davon profitieren: Der Benutzer erh√§lt eine angemessene Programmantwort, und Sie als Entwickler erhalten vereinfachten Code, da jeder Stream weitergeleitet werden kann  Operationen auszuf√ºhren, die in direktem Zusammenhang mit seinen Aufgaben stehen, ohne sie mit dem Kontrollfluss und der Benutzerinteraktion zu vermischen. <br><br>  Ein ideales Bild entsteht.  Aber kann alles so werden?  Wie immer h√§ngt alles von den jeweiligen Umst√§nden ab.             ,      .  ,     .         ,        ,  -   .        ,      -     ,    .          ,       .    -   ,           . ,   , -   ,    ,   ,          .      ,   ,    ,           . <br><br>          . -,  ,    .       ,   ,   ,       .          .      .        , , ,    ,             .   ,        ,     ‚Äî   , ,        . <br><br>                .             ,     ,         . <br><br><h3>      </h3><br>                 ,            .      : ,     ,         . <br><br>            ‚Äî        .   ,     ,      .   ,     ,       ,           . <br><br>      ,    8.1.1,   ,           . ,                  . <br><br>     ,        :    ,       . ,        20          ,      3 .      ,         .  ,   ,    ,  ,   12       ,  24  ‚Äî   . .  20     .      .         .       , ,  ,   ,   12 . ,   12       ,        .      ,  :  ,   ,     ,  ,       ,        .      3         12 . <br><br>      ,    9 ,         .            . ,  ,      .          25   ,    ‚Äî  .  ,       ,    : ,   100   ,  ,    1 ,    100 ,    1     100 .     ,  ,        .       ,     ,  , . <br><br>       ,    ,     ,   ,      . <br><br><h3>  8.2. ,      </h3><br>            ,  ,      .        ,  ,     .     ,       16      ,     . <br><br>    ,        ‚Äî   ,    ,    (      ),      .          ,    :      ? <br><br><h3>  8.2.1.     ? </h3><br>  ( )     ,          .   ,    ,        ,          .     ,     .      ,     . ,         ,         (   )       .     ,   ,      ,            . <br><br>     16-       16  :          16 .    ,        16 .   ,    ,         (   ).    ,    16    ,      ,           ,      1.       (oversubscription). <br><br>          ,       ,    C++11 (Standard Thread Library)   std::thread::hardware_concurrency().             . <br><br>   std::thread::hardware_concurrency()    :       -  ,   ,        .   ,        ,  std::thread::hardware_concurrency(),     .  std::async()    ,           .           . <br><br>      ,    ,    ,      .              ‚Äî   ,   ,     . ,     ,   ,       ,          C++.   ,     std::async(),       ,   ,    .       ,     .   ,      ,      std::thread::hardware_concurrency(),     .      ,      ,  ,    . <br><br>       ,                 .          ,     ,      ,    ,        . <br><br>         ,        ‚Äî          . <br><br>  ¬ªWeitere Informationen zum Buch finden Sie auf <a href="https://www.piter.com/collection/new/product/c-praktika-mnogopotochnogo-programmirovaniya%3F_gs_cttl%3D120%255E_%255Eamp%255E_%255Egs_direct_link%3D1%255E_%255Eamp%255E_%255Egsaid%3D82744%255E_%255Eamp%255E_%255Egsmid%3D29789%255E_%255Eamp%255E_%255Egstid%3Dc">der Website des Herausgebers</a> <br>  ¬ª <a href="https://storage.piter.com/upload/contents/978544610831/978544610831_X.pdf">Inhalt</a> <br>  ¬ª <a href="https://storage.piter.com/upload/contents/978544610831/978544610831_p.pdf">Auszug</a> <br><br>    25%   ‚Äî <b>C++</b> <br><br>  Nach Bezahlung der Papierversion des Buches wird ein elektronisches Buch per E-Mail verschickt. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de484818/">https://habr.com/ru/post/de484818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de484804/index.html">Was muss in einem Unternehmenssystem verschl√ºsselt werden? Und warum das machen?</a></li>
<li><a href="../de484806/index.html">Unterschied zwischen cPanel und Plesk Obsidian</a></li>
<li><a href="../de484812/index.html">Meine Erfahrung mit Plesk</a></li>
<li><a href="../de484814/index.html">6. Fortinet Getting Started v6.0. Webfilterung und Anwendungskontrolle</a></li>
<li><a href="../de484816/index.html">Verwenden von Operations Hooks zum Sichern von Dateien unter macOS im laufenden Betrieb</a></li>
<li><a href="../de484820/index.html">FAQ.Net - ein kostenloses Notizenprogramm f√ºr Windows mit aktualisiertem Design</a></li>
<li><a href="../de484822/index.html">Blazor: Wie verhindert man, dass eine Komponente krank wird, oder wie trennt man Code vom Markup?</a></li>
<li><a href="../de484824/index.html">Der Krieg um das Licht auszuschalten</a></li>
<li><a href="../de484826/index.html">K√ºnstliche Intelligenz verschlimmert die schlechte Medizin noch mehr</a></li>
<li><a href="../de484834/index.html">Wie man eine Unternehmensstrategie f√ºr Training und Entwicklung entwickelt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
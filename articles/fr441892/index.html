<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëÇ ü§òüèΩ üë©üèø Cr√©ation d'un mod√®le de flux de donn√©es pour diffuser des donn√©es de Pub / Sub vers BigQuery bas√© sur GCP √† l'aide du SDK Apache Beam et de Python üéÖ üõÄüèº üêµ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En ce moment, je suis engag√© dans la t√¢che de streaming (et de conversion) de donn√©es. Dans certains cercles 
 un tel processus est appel√© ETL , c'est...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cr√©ation d'un mod√®le de flux de donn√©es pour diffuser des donn√©es de Pub / Sub vers BigQuery bas√© sur GCP √† l'aide du SDK Apache Beam et de Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441892/"><p><img src="https://habrastorage.org/webt/is/qf/7j/isqf7j7patfl6lgirlqfrfbz-k8.png" alt="image"></p><br><p>  En ce moment, je suis engag√© dans la t√¢che de streaming (et de conversion) de donn√©es.  Dans certains cercles <br>  un tel processus est appel√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ETL</a> , c'est-√†-dire  extraction, conversion et chargement d'informations. </p><br><p>  L'ensemble du processus comprend la participation des services <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google Cloud Platform</a> suivants: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pub / Sub</a> - service de streaming de donn√©es en temps r√©el </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dataflow</a> - un service de conversion de donn√©es (peut <br>  fonctionne √† la fois en temps r√©el et en mode batch) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">BigQuery</a> - un service de stockage de donn√©es sous forme de tableaux <br>  (prend en charge SQL) </li></ul><a name="habracut"></a><br><h5 id="0-tekuschee-polozhenie-del">  0. √âtat actuel </h5><br><p> Pour le moment, il existe une version fonctionnelle de la diffusion en continu sur les services ci-dessus, mais <br>  En tant que mod√®le, l'un des <a href="">standards est utilis√©</a> . </p><br><p>  Le probl√®me est que ce mod√®le fournit un transfert de donn√©es 1 √† 1, c'est-√†-dire  sur <br>  √† l'entr√©e de Pub / Sub, nous avons une cha√Æne au format JSON, √† la sortie, nous avons une table BigQuery avec des champs, <br>  qui correspondent aux cl√©s des objets au niveau sup√©rieur du JSON d'entr√©e. </p><br><h5 id="1-postanovka-zadachi">  1. √ânonc√© du probl√®me </h5><br><p> Cr√©ez un mod√®le de flux de donn√©es qui vous permet d'obtenir une ou plusieurs tables √† la sortie <br>  selon les conditions donn√©es.  Par exemple, nous voulons cr√©er une table distincte pour chaque <br>  valeurs d'une cl√© JSON d'entr√©e sp√©cifique.  Il est n√©cessaire de tenir compte du fait que certains <br>  Les objets JSON en entr√©e peuvent contenir du JSON imbriqu√© en tant que valeur, c'est-√†-dire  est n√©cessaire <br>  pouvoir cr√©er des tables BigQuery avec des champs de type <code>RECORD</code> pour le stockage <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">imbriqu√©</a> <br>  les donn√©es. </p><br><h5 id="2-podgotovka-k-resheniyu">  2. Pr√©paration de la d√©cision </h5><br><p>  Pour cr√©er un mod√®le Dataflow, utilisez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SDK</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Beam</a> , qui, √† son tour, <br>  prend en charge Java et Python en tant que langage de programmation.  Je dois dire que <br>  seule la version Python 2.7.x est prise en charge, ce qui m'a un peu surpris.  De plus, le soutien <br>  Java est un peu plus large, car  pour Python, par exemple, certaines fonctionnalit√©s ne sont pas disponibles et plus <br>  Une liste modeste de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">connecteurs</a> int√©gr√©s.  Au fait, vous pouvez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©crire</a> vos propres connecteurs. </p><br><p>  Cependant, √©tant donn√© que je ne suis pas familier avec Java, j'ai utilis√© Python. </p><br><p>  Avant de commencer √† cr√©er un mod√®le, vous devez disposer des √©l√©ments suivants: </p><br><ol><li>  entrez le format JSON et il ne devrait pas changer dans le temps </li><li>  sch√©ma ou sch√©mas de tables BigQuery dans lesquelles les donn√©es seront diffus√©es </li><li>  le nombre de tables dans lesquelles le flux de donn√©es de sortie sera diffus√© </li></ol><br><p>  Notez qu'apr√®s avoir cr√©√© un mod√®le et d√©marr√© Dataflow Job en fonction de celui-ci, ces param√®tres peuvent √™tre <br>  changer uniquement en cr√©ant un nouveau mod√®le. </p><br><p>  Disons quelques mots sur ces restrictions.  Ils viennent tous du fait qu'il n'y a aucune possibilit√© <br>  cr√©er un mod√®le dynamique qui pourrait prendre n'importe quelle cha√Æne en entr√©e, l'analyser <br>  selon la logique interne, puis remplir dynamiquement les tables cr√©√©es dynamiquement <br>  cr√©√© par le circuit.  Il est tr√®s probable que cette possibilit√© existe, mais dans les donn√©es <br>  Je n'ai pas r√©ussi √† mettre en place un tel sch√©ma.  Pour autant que je comprends l'ensemble <br>  le pipeline est construit avant de l'ex√©cuter en runtime et donc il n'y a aucun moyen de le changer en <br>  voler.  Peut-√™tre que quelqu'un partagera sa d√©cision. </p><br><h5 id="3-reshenie">  3. D√©cision </h5><br><p>  Pour une compr√©hension plus compl√®te du processus, il vaut la peine d'apporter un sch√©ma du soi-disant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pipeline</a> <br>  de la documentation Apache Beam. </p><br><p><img src="https://habrastorage.org/webt/yq/yi/3z/yqyi3zjiwpmjf4i6qp7x4znqv2c.png" alt="image"></p><br><p>  Dans notre cas (nous utiliserons la division en plusieurs tableaux): </p><br><ul><li>  entr√©e - les donn√©es proviennent de PubSub dans Dataflow Job </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Transformer</a> # 1 - les donn√©es sont converties d'une cha√Æne en un dictionnaire Python, nous obtenons une sortie <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PCollection</a> # 1 </li><li>  Transformer # 2 - les donn√©es sont √©tiquet√©es, pour une s√©paration suppl√©mentaire selon des tableaux s√©par√©s, en <br>  la sortie est PCollection # 2 (en fait un tuple PCollection) </li><li>  Transformation # 3 - les donn√©es de PCollection # 2 sont √©crites dans des tableaux √† l'aide de sch√©mas <br>  tables </li></ul><br><p>  Dans le processus d'√©criture de mon propre mod√®le, j'ai √©t√© activement inspir√© par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ces</a> exemples. </p><br><div class="spoiler">  <b class="spoiler_title">Code de mod√®le avec commentaires (√† gauche des commentaires de la m√™me mani√®re que les auteurs pr√©c√©dents):</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># coding=utf-8 from __future__ import absolute_import import logging import json import os import apache_beam as beam from apache_beam.pvalue import TaggedOutput from apache_beam.options.pipeline_options import PipelineOptions from apache_beam.options.pipeline_options import SetupOptions from apache_beam.options.pipeline_options import StandardOptions from apache_beam.io.gcp.bigquery import parse_table_schema_from_json #  GCP  gcp_project = '' #  Pub/Sub  topic_name = '' # Pub/Sub    'projects/_GCP_/topics/_' input_topic = 'projects/%s/topics/%s' % (gcp_project, topic_name) #  BigQuery  bq_dataset = 'segment_eu_test' #       schema_dir = './' class TransformToBigQuery(beam.DoFn): #          ,   # BigQuery IO     python dict def process(self, element, *args, **kwargs): body = json.loads(element) #       ,      # python dict       ,     #   yield body class TagDataWithReqType(beam.DoFn): #      , ..      #     ,       #  with_outputs + default def process(self, element, *args, **kwargs): req_type = element.get('_') types = ( 'type1', 'type2', 'type3', ) if req_type in types: yield TaggedOutput(req_type, element) else: yield element def run(): #       _.json   schema_dir,  #         ()  schema_dct = {} for schema_file in os.listdir(schema_dir): filename_list = schema_file.split('.') if filename_list[-1] == 'json': with open('%s/%s' % (schema_dir, schema_file)) as f: schema_json = f.read() schema_dct[filename_list[0]] = json.dumps({'fields': json.loads(schema_json)}) # We use the save_main_session option because one or more DoFn's in this # workflow rely on global context (eg, a module imported at module level). pipeline_options = PipelineOptions() p = beam.Pipeline(options=pipeline_options) pipeline_options.view_as(SetupOptions).save_main_session = True pipeline_options.view_as(StandardOptions).streaming = True # Read from PubSub into a PCollection. input_stream = p | beam.io.ReadFromPubSub(input_topic) # Transform stream to BigQuery IO format stream_bq = input_stream | 'transform to BigQuery' &gt;&gt; beam.ParDo(TransformToBigQuery()) # Tag stream by schema name tagged_stream = \ stream_bq \ | 'tag data by type' &gt;&gt; beam.ParDo(TagDataWithReqType()). with_outputs(*schema_dct.keys(), main='default') # Stream unidentified data to default table tagged_stream.default | 'push to default table' &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.default' % ( gcp_project, bq_dataset, ), schema=parse_table_schema_from_json(schema_dct.get('default')), ) # Stream data to BigQuery tables by number of schema names for name, schema in schema_dct.iteritems(): tagged_stream[name] | 'push to table %s' % name &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.%s' % ( gcp_project, bq_dataset, name), schema=parse_table_schema_from_json(schema), ) result = p.run() result.wait_until_finish() if __name__ == '__main__': logging.getLogger().setLevel(logging.INFO) logger = logging.getLogger(__name__) run()</span></span></code> </pre> </div></div><br><p>  Maintenant, nous allons parcourir le code et donner des explications, mais d'abord, il vaut la peine de dire que le principal <br>  la difficult√© d'√©crire ce mod√®le est de penser en termes de "flux de donn√©es", et <br>  pas un message sp√©cifique.  Il est √©galement n√©cessaire de comprendre que Pub / Sub fonctionne avec des messages et <br>  c'est d'eux qu'ils recevront des informations pour baliser le flux. </p><br><pre> <code class="python hljs">pipeline_options = PipelineOptions() p = beam.Pipeline(options=pipeline_options) pipeline_options.view_as(SetupOptions).save_main_session = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> pipeline_options.view_as(StandardOptions).streaming = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre> <br><p>  Parce que  Le connecteur Apache Beam Pub / Sub IO est utilis√© uniquement en mode streaming n√©cessaire <br>  ajoutez PipelineOptions () (bien qu'en fait les options ne soient pas utilis√©es); sinon, cr√©ez un mod√®le <br>  tombe √† l'exception.  Il faut dire sur les options de lancement du mod√®le.  Ils peuvent √™tre <br>  statique et soi-disant "runtime".  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici un</a> lien vers la documentation sur ce sujet.  Les options vous permettent de cr√©er un mod√®le sans sp√©cifier de param√®tres √† l'avance, mais en les passant lorsque vous d√©marrez le travail de flux de donn√©es √† partir du mod√®le, mais je n'ai toujours pas pu l'impl√©menter, probablement parce que ce connecteur ne prend pas en charge <code>RuntimeValueProvider</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Read from PubSub into a PCollection. input_stream = p | beam.io.ReadFromPubSub(input_topic)</span></span></code> </pre> <br><p>  Tout est clair d'apr√®s le commentaire, nous lisons le fil du sujet.  Il convient d'ajouter que vous pouvez prendre le flux <br>  √† la fois du sujet et de l'abonnement (abonnement).  Si le sujet est sp√©cifi√© en entr√©e, alors <br>  un abonnement temporaire √† ce sujet sera automatiquement cr√©√©.  La syntaxe est √©galement jolie <br>  clair, le flux de donn√©es d'entr√©e <code>beam.io.ReadFromPubSub(input_topic)</code> envoy√© √† notre <br>  pipeline <code>p</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Transform stream to BigQuery IO format stream_bq = input_stream | 'transform to BigQuery' &gt;&gt; beam.ParDo(TransformToBigQuery())</span></span></code> </pre> <br><p>  C'est l√† que la transformation # 1 se produit et notre entr√©e est convertie √† partir d'une cha√Æne python en <br>  python dict, et dans la sortie, nous obtenons PCollection # 1.  <code>&gt;&gt;</code> appara√Æt dans la syntaxe.  Sur <br>  en fait, le texte entre guillemets est le nom du flux (doit √™tre unique), ainsi qu'un commentaire, <br>  qui sera ajout√© au bloc sur le graphique dans l'interface Web GCP Dataflow.  Examinons plus en d√©tail <br>  classe substitu√©e <code>TransformToBigQuery</code> . </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TransformToBigQuery</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#          ,   # BigQuery IO     python dict def process(self, element, *args, **kwargs): body = json.loads(element) #       ,      # python dict       ,     #  ,      python dict yield body</span></span></code> </pre> <br><p>  La variable d' <code>element</code> contiendra un message de l'abonnement PubSub.  Vu de <br>  code, dans notre cas, il doit √™tre JSON valide.  En classe doit √™tre <br>  la m√©thode du <code>process</code> est red√©finie, dans laquelle les transformations n√©cessaires doivent √™tre effectu√©es <br>  ligne d'entr√©e pour obtenir une sortie qui correspond au circuit <br>  la table dans laquelle ces donn√©es seront charg√©es.  Parce que  notre flux dans ce cas est <br>  continu, <code>unbounded</code> en termes d'Apache Beam, vous devez le renvoyer en utilisant <br>  <code>yield</code> , pas <code>return</code> , comme pour le flux de donn√©es final.  Dans le cas d'un flux final, vous pouvez <br>  (et n√©cessaire) configurer en plus le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>windowing</code></a> et les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>triggers</code></a> </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Tag stream by schema name tagged_stream = \ stream_bq \ | 'tag data by type' &gt;&gt; beam.ParDo(TagDataWithReqType()).with_outputs(*schema_dct.keys(), main='default')</span></span></code> </pre> <br><p>  Ce code dirige PCollection # 1 vers la transformation # 2 o√π le balisage aura lieu <br>  (s√©paration) du flux de donn√©es.  Dans la variable <code>schema_dct</code> dans ce cas, un dictionnaire, o√π la cl√© est le nom du fichier de sch√©ma sans l'extension, ce sera la balise et la valeur est le JSON valide du sch√©ma <br>  Tables BigQuery pour cette balise.  Il convient de noter que le sch√©ma doit √™tre transmis exactement aux <br>  afficher <code>{'fields': }</code> o√π <code></code> est le sch√©ma de la table BigQuery sous forme JSON (vous pouvez <br>  exporter depuis l'interface Web). </p><br><p>  <code>main='default'</code> est le nom de la balise de thread vers laquelle ils iront <br>  Tous les messages qui ne sont pas soumis √† des conditions de balisage.  Consid√©rez la classe <br>  <code>TagDataWithReqType</code> . </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TagDataWithReqType</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#      , ..      #     ,       #  with_outputs + default def process(self, element, *args, **kwargs): req_type = element.get('_') types = ( 'type1', 'type2', 'type3', ) if req_type in types: yield TaggedOutput(req_type, element) else: yield element</span></span></code> </pre> <br><p>  Comme vous pouvez le voir, la classe de <code>process</code> est √©galement remplac√©e ici.  La variable <code>types</code> contient des noms <br>  balises et ils doivent faire correspondre le nombre et le nom avec le nombre et les noms des cl√©s de dictionnaire <br>  <code>schema_dct</code> .  Bien que la m√©thode de <code>process</code> ait la capacit√© d'accepter des arguments, je n'ai jamais <br>  J'ai pu les d√©passer.  Je n'ai pas encore compris la raison. </p><br><p>  En sortie, on obtient un tuple de threads dans le nombre de tags, √† savoir le nombre des n√¥tres <br>  balises pr√©d√©finies + thread par d√©faut qui n'a pas pu √™tre balis√©. </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Stream unidentified data to default table tagged_stream.default | 'push to default table' &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.default' % ( gcp_project, bq_dataset, ), schema=parse_table_schema_from_json(schema_dct.get('default')), )</span></span></code> </pre> <br><p>  Transformer # ... (en fait, ce n'est pas sur le diagramme, c'est une "branche") - nous √©crivons le flux par d√©faut <br>  √† la table par d√©faut. </p><br><p>  <code>tagged_stream.default</code> - un flux avec la balise <code>default</code> est pris, une syntaxe alternative est <code>tagged_stream['default']</code> </p><br><p>  <code>schema=parse_table_schema_from_json(schema_dct.get('default'))</code> - ici le sch√©ma est d√©fini <br>  tables.  Veuillez noter que le fichier <code>default.json</code> avec le sch√©ma de table BigQuery valide <br>  doit √™tre dans le <code>schema_dir = './'</code> actuel. </p><br><p>  Le flux ira √† une table appel√©e <code>default</code> . </p><br><p>  Si une table portant ce nom (dans l'ensemble de donn√©es donn√© de ce projet) n'existe pas, alors elle <br>  sera cr√©√© automatiquement √† partir du sch√©ma gr√¢ce au param√®tre par d√©faut <br> <code>create_disposition=BigQueryDisposition.CREATE_IF_NEEDED</code> </p> <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Stream data to BigQuery tables by number of schema names for name, schema in schema_dct.iteritems(): tagged_stream[name] | 'push to table %s' % name &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.%s' % ( gcp_project, bq_dataset, name), schema=parse_table_schema_from_json(schema), )</span></span></code> </pre> <br><p>  Transformez # 3, tout devrait √™tre clair pour ceux qui lisent l'article depuis le d√©but et qui poss√®dent <br>  syntaxe python.  Nous s√©parons le tuple de flux avec une boucle et √©crivons chaque flux dans sa propre table avec <br>  son plan.  Il convient de rappeler que le nom du flux doit √™tre unique - <code>'%s:%s.%s' % (gcp_project, bq_dataset, name)</code> . </p><br><p>  Maintenant, il devrait √™tre clair comment cela fonctionne et vous pouvez cr√©er un mod√®le.  Pour cela, vous avez besoin <br>  ex√©cutez dans la console (n'oubliez pas d'activer venv si disponible) ou depuis l'IDE: </p><br><pre> <code class="bash hljs">python _.py / --runner DataflowRunner / --project dreamdata-test / --staging_location gs://STORAGE_NAME/STAGING_DIR / --temp_location gs://STORAGE_NAME/TEMP_DIR / --template_location gs://STORAGE_NAME/TEMPLATES_DIR/TEMPLATE_NAME</code> </pre> <br><p>  Dans le m√™me temps, l'acc√®s au compte Google doit √™tre organis√©, par exemple via l'exportation <br>  la <code>GOOGLE_APPLICATION_CREDENTIALS</code> environnement <code>GOOGLE_APPLICATION_CREDENTIALS</code> ou d'une autre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mani√®re</a> . </p><br><p>  Quelques mots sur <code>--runner</code> .  Dans ce cas, <code>DataflowRunner</code> dit que ce code <br>  s'ex√©cutera comme mod√®le pour le Job Dataflow.  Il est toujours possible de sp√©cifier <br>  <code>DirectRunner</code> , il sera utilis√© par d√©faut s'il n'y a pas d'option <code>--runner</code> et code <br>  fonctionnera comme un Job Dataflow, mais localement, ce qui est tr√®s pratique pour le d√©bogage. </p><br><p>  Si aucune erreur ne s'est produite, alors <code>gs://STORAGE_NAME/TEMPLATES_DIR/TEMPLATE_NAME</code> sera <br>  mod√®le cr√©√©.  Il est √† noter que dans <code>gs://STORAGE_NAME/STAGING_DIR</code> sera √©galement √©crit <br>  les fichiers de service n√©cessaires au bon fonctionnement du Job Datafow cr√©√© sur la base de <br>  mod√®le et vous n'avez pas besoin de les supprimer. </p><br><p>  Ensuite, vous devez cr√©er un Job Dataflow √† l'aide de ce mod√®le, manuellement ou par n'importe quel <br>  d'une autre mani√®re (CI par exemple). </p><br><h5 id="4-vyvody">  4. Conclusions </h5><br><p>  Ainsi, nous avons r√©ussi √† diffuser le flux de PubSub vers BigQuery en utilisant <br>  les transformations de donn√©es n√©cessaires √† des fins de stockage, de transformation et de <br>  l'utilisation des donn√©es. </p><br><h2 id="osnovnye-ssylki">  Liens principaux </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SDK Apache Beam</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://www.google.com/url%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26cad%3Drja%26uact%3D8%26ved%3D2ahUKEwjHvcGT5svgAhV7wsQBHSDWDEoQFjAAegQIABAC%26url%3D">Flux de donn√©es Google</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google bigquery</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article de James Moore sur support</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Exemples de code Python pour Apache Beam</a> </li></ul><br><p>  Dans cet article, des inexactitudes et m√™me des erreurs sont possibles, je serai reconnaissant pour la <br>  la critique.  Au final, je veux ajouter qu'en fait, tous ne sont pas utilis√©s ici <br>  fonctionnalit√©s du SDK Apache Beam, mais ce n'√©tait pas l'objectif. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr441892/">https://habr.com/ru/post/fr441892/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr441878/index.html">Toi comme tu veux, mais je l'ai fait</a></li>
<li><a href="../fr441882/index.html">VMware NSX pour les plus petits. Partie 3. Configuration de DHCP</a></li>
<li><a href="../fr441886/index.html">Au cours des 12 derni√®res ann√©es, je n'ai jamais montr√© de CV</a></li>
<li><a href="../fr441888/index.html">SIP depuis le m√©gaphone au tarif du domicile</a></li>
<li><a href="../fr441890/index.html">Tout ce que vous devez savoir sur les extensions d'application iOS</a></li>
<li><a href="../fr441896/index.html">Apprenez les tactiques, techniques et connaissances communes contradictoires (ATT @ CK). Tactiques d'entreprise. Partie 9</a></li>
<li><a href="../fr441898/index.html">Sketch + Node.js: g√©n√©ration d'ic√¥nes pour de nombreuses plateformes et marques</a></li>
<li><a href="../fr441900/index.html">Satya Nadella a parl√© de coop√©ration avec le Pentagone</a></li>
<li><a href="../fr441902/index.html">Comment la technologie cr√©e de nouvelles r√©alit√©s</a></li>
<li><a href="../fr441904/index.html">Installation d'un √©cran IPS sur le Thinkpad T430S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
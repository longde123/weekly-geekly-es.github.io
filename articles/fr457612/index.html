<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õπÔ∏è üíÜüèø ü•Ç Comment acc√©l√©rer la d√©compression LZ4 dans ClickHouse? üç† ü§òüèæ üíì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Lorsque vous ex√©cutez des requ√™tes dans ClickHouse , vous remarquerez peut-√™tre que le profileur affiche souvent la fonction LZ_decompress_fast vers l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment acc√©l√©rer la d√©compression LZ4 dans ClickHouse?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/457612/"> Lorsque vous ex√©cutez des requ√™tes dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ClickHouse</a> , vous remarquerez peut-√™tre que le profileur affiche souvent la fonction <code>LZ_decompress_fast</code> vers le haut.  Que se passe-t-il?  Cette question nous a amen√©s √† nous demander comment choisir le meilleur algorithme de compression. <br><br>  ClickHouse stocke les donn√©es sous forme compress√©e.  Lors de l'ex√©cution de requ√™tes, ClickHouse essaie d'en faire le moins possible, afin de conserver les ressources CPU.  Dans de nombreux cas, tous les calculs potentiellement chronophages sont d√©j√† bien optimis√©s, et l'utilisateur a √©crit une requ√™te bien pens√©e.  Il ne reste alors plus qu'√† effectuer la d√©compression. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/302/aba/057302aba5041790af404c2c781c4dd3.png"><br><br>  Alors pourquoi la d√©compression LZ4 devient-elle un goulot d'√©tranglement?  Le LZ4 semble √™tre un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">algorithme extr√™mement l√©ger</a> : le taux de d√©compression des donn√©es est g√©n√©ralement de 1 √† 3 Go / s par c≈ìur de processeur, selon les donn√©es.  C'est beaucoup plus rapide que le sous-syst√®me de disque typique.  De plus, nous utilisons tous les c≈ìurs CPU disponibles et les √©chelles de d√©compression lin√©airement sur tous les c≈ìurs physiques. <br><a name="habracut"></a><br>  Cependant, il y a deux points √† garder √† l'esprit.  Tout d'abord, les donn√©es compress√©es sont lues √† partir du disque, mais la vitesse de d√©compression est donn√©e en termes de quantit√© de donn√©es non compress√©es.  Si le taux de compression est suffisamment √©lev√©, il n'y a presque rien √† lire sur les disques.  Mais il y aura beaucoup de donn√©es d√©compress√©es, et cela affecte naturellement l'utilisation du processeur: dans le cas de LZ4, la quantit√© de travail n√©cessaire pour d√©compresser les donn√©es est presque proportionnelle au volume des donn√©es d√©compress√©es elles-m√™mes. <br><br>  Deuxi√®mement, si les donn√©es sont mises en cache, vous n'aurez peut-√™tre pas du tout besoin de lire les donn√©es des disques.  Vous pouvez compter sur le cache de pages ou utiliser votre propre cache.  La mise en cache est plus efficace dans les bases de donn√©es orient√©es colonnes, car seules les colonnes fr√©quemment utilis√©es restent dans le cache.  C'est pourquoi LZ4 appara√Æt souvent comme un goulot d'√©tranglement en termes de charge CPU. <br><br>  Cela soul√®ve deux autres questions.  Premi√®rement, si la d√©compression nous ralentit, vaut-il la peine de commencer par compresser les donn√©es?  Mais cette sp√©culation n'est pas pertinente dans la pratique.  Jusqu'√† r√©cemment, la configuration ClickHouse n'offrait que deux options de compression de donn√©es - LZ4 et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Zstandard</a> .  LZ4 est utilis√© par d√©faut.  Le passage √† Zstandard rend la compression plus forte et plus lente.  Mais il n'y avait pas d'option pour d√©sactiver compl√®tement la compression, car LZ4 est suppos√© fournir une compression minimale raisonnable qui peut toujours √™tre utilis√©e.  (C'est exactement pourquoi j'aime LZ4.) <br><br>  Mais un myst√©rieux inconnu est apparu dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chat de support international ClickHouse</a> qui a dit qu'il avait un sous-syst√®me de disque tr√®s rapide (avec SSD NVMe) et que la d√©compression √©tait la seule chose qui ralentissait ses requ√™tes, donc ce serait bien de pouvoir stocker des donn√©es sans compression  J'ai r√©pondu que nous n'avons pas cette option, mais ce serait facile √† ajouter.  Quelques jours plus tard, nous avons re√ßu une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">demande d'extraction</a> mettant en ≈ìuvre la m√©thode de compression <code>none</code> .  J'ai demand√© au contributeur de rapporter √† quel point cette option a aid√© √† acc√©l√©rer les requ√™tes.  La r√©ponse a √©t√© que cette nouvelle fonctionnalit√© s'est av√©r√©e inutile dans la pratique, car les donn√©es non compress√©es ont commenc√© √† occuper trop d'espace disque et ne cadraient pas avec ces disques NVMe. <br><br>  La deuxi√®me question qui se pose est que s'il existe un cache, pourquoi ne pas l'utiliser pour stocker des donn√©es d√©j√† d√©compress√©es?  Il s'agit d'une possibilit√© viable qui √©liminera le besoin de d√©compression dans de nombreux cas.  ClickHouse poss√®de √©galement un cache comme celui-ci: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le cache des blocs d√©compress√©s</a> .  Mais c'est dommage de gaspiller beaucoup de RAM √† ce sujet.  Il est donc g√©n√©ralement logique de l'utiliser sur de petites requ√™tes s√©quentielles qui utilisent des donn√©es presque identiques. <br><br>  Notre conclusion est qu'il est toujours pr√©f√©rable de stocker des donn√©es au format compress√©.  √âcrivez toujours les donn√©es sur le disque au format compress√©.  Transmettez √©galement des donn√©es sur le r√©seau avec compression.  √Ä mon avis, la compression par d√©faut est justifiable m√™me lors du transfert de donn√©es au sein d'un seul centre de donn√©es dans un r√©seau de 10 Go sans surabonnement, tandis que le transfert de donn√©es non compress√©es entre les centres de donn√©es est tout simplement inacceptable. <br><br><h3>  Pourquoi LZ4? </h3><br>  Pourquoi choisir LZ4?  Ne pourrions-nous pas choisir quelque chose d'encore plus l√©ger?  Th√©oriquement, nous pourrions le faire, et c'est une bonne id√©e.  Mais regardons la classe d'algorithmes √† laquelle appartient LZ4. <br><br>  Tout d'abord, il est g√©n√©rique et n'adapte pas le type de donn√©es.  Par exemple, si vous savez √† l'avance que vous disposerez d'un tableau d'entiers, vous pouvez utiliser l'un des algorithmes VarInt et cela utilisera le processeur plus efficacement.  Deuxi√®mement, LZ4 n'est pas trop d√©pendant des hypoth√®ses du mod√®le de donn√©es.  Disons que vous avez une s√©rie chronologique ordonn√©e de valeurs de capteur, un tableau de nombres √† virgule flottante.  Si vous en tenez compte, vous pouvez calculer des deltas entre ces nombres, puis les compresser avec un algorithme g√©n√©rique, ce qui entra√Ænera un taux de compression plus √©lev√©. <br><br>  Vous n'aurez aucun probl√®me √† utiliser LZ4 avec des tableaux d'octets ou des fichiers.  Bien s√ªr, il a une sp√©cialisation (plus √† ce sujet plus tard), et dans certains cas, son utilisation est inutile.  Mais si nous l'appelons un algorithme √† usage g√©n√©ral, nous serons assez proches de la v√©rit√©.  Notons que gr√¢ce √† sa conception interne, LZ4 impl√©mente automatiquement l'algorithme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RLE</a> comme cas particulier. <br><br>  Cependant, la question la plus importante est de savoir si LZ4 est l'algorithme le plus optimal de cette classe en termes de vitesse globale et de force de compression.  Les algorithmes optimaux sont appel√©s la fronti√®re de Pareto, ce qui signifie qu'aucun autre algorithme n'est d√©finitivement meilleur d'une mani√®re et pas pire d'autres (et sur une grande vari√©t√© de jeux de donn√©es √©galement).  Certains algorithmes sont plus rapides mais entra√Ænent un taux de compression plus petit, tandis que d'autres ont une compression plus forte mais sont plus lents √† compresser ou d√©compresser. <br><br>  Pour √™tre honn√™te, LZ4 n'est pas vraiment la fronti√®re de Pareto - il y a des options disponibles qui sont juste un peu mieux.  Par exemple, regardez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LZTURBO</a> d'un d√©veloppeur surnomm√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">powturbo</a> .  Il n'y a aucun doute sur la fiabilit√© des r√©sultats, gr√¢ce √† la communaut√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">encode.ru</a> (le plus grand et peut-√™tre le seul forum sur la compression de donn√©es).  Malheureusement, le d√©veloppeur ne distribue pas le code source ou les binaires;  ils ne sont disponibles que pour un nombre limit√© de personnes pour des tests ou pour beaucoup d'argent (bien qu'il semble que personne ne l'ait encore pay√©).  Jetez √©galement un ≈ìil √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lizard</a> (anciennement LZ5) et √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Densit√©</a> .  Ils peuvent fonctionner l√©g√®rement mieux que LZ4 lorsque vous s√©lectionnez un certain niveau de compression.  Une autre option vraiment int√©ressante est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LZSSE</a> .  Mais finissez de lire cet article avant de le consulter. <br><br><h3>  Comment fonctionne lz4 </h3><br>  Voyons comment fonctionne LZ4 en g√©n√©ral.  C'est l'une des impl√©mentations de l'algorithme LZ77.  L et Z repr√©sentent les noms des d√©veloppeurs (Lempel et Ziv), et 77 correspond √† l'ann√©e 1977 o√π l'algorithme a √©t√© publi√©.  Il a de nombreuses autres impl√©mentations: QuickLZ, FastLZ, BriefLZ, LZF, LZO et gzip et zip si de faibles niveaux de compression sont utilis√©s. <br><br>  Un bloc de donn√©es compress√© √† l'aide de LZ4 contient une s√©quence d'entr√©es (commandes ou instructions) de deux types: <br><br><ol><li>  Litt√©raux: "Prenez les N octets suivants tels quels et copiez-les dans le r√©sultat". </li><li>  Correspondance: "Prenez N octets du r√©sultat d√©compress√© √† partir de la valeur de d√©calage par rapport √† la position actuelle". </li></ol><br>  Exemple.  Avant la compression: <br><br><pre> <code class="plaintext hljs">Hello world Hello</code> </pre> <br>  Apr√®s compression: <br><br><pre> <code class="plaintext hljs">literals 12 "Hello world " match 5 12</code> </pre> <br>  Si nous prenons un bloc compress√© et parcourons le curseur lors de l'ex√©cution de ces commandes, nous obtiendrons les donn√©es originales non compress√©es comme r√©sultat. <br><br>  Voil√† donc essentiellement comment les donn√©es sont d√©compress√©es.  L'id√©e de base est claire: pour effectuer la compression, l'algorithme code une s√©quence r√©p√©t√©e d'octets √† l'aide de correspondances. <br><br>  Certaines caract√©ristiques sont √©galement claires.  Cet algorithme orient√© octets ne diss√®que pas les octets individuels;  il les copie uniquement dans leur int√©gralit√©.  C'est ainsi qu'il diff√®re du codage entropique.  Par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">zstd</a> est une combinaison de LZ77 et du codage entropique. <br><br>  Notez que la taille du bloc compress√© ne doit pas √™tre trop grande.  La taille est choisie pour √©viter de gaspiller beaucoup de RAM pendant la d√©compression, pour √©viter de ralentir trop l'acc√®s al√©atoire dans le fichier compress√© (qui se compose d'un grand nombre de blocs compress√©s), et parfois pour que le bloc tienne dans un cache CPU.  Par exemple, vous pouvez choisir 64 Ko pour que les tampons pour les donn√©es compress√©es et non compress√©es tiennent dans le cache L2 avec la moiti√© encore libre. <br><br>  Si nous devons compresser un fichier plus volumineux, nous pouvons concat√©ner les blocs compress√©s.  Cela est √©galement pratique pour stocker des donn√©es suppl√©mentaires (comme une somme de contr√¥le) avec chaque bloc compress√©. <br><br>  Le d√©calage maximum pour le match est limit√©.  Dans LZ4, la limite est de 64 kilo-octets.  Ce montant est appel√© la fen√™tre coulissante.  Cela signifie que les correspondances peuvent √™tre trouv√©es dans une fen√™tre de 64 kilo-octets pr√©c√©dant le curseur, qui glisse avec le curseur √† mesure qu'il avance. <br><br>  Voyons maintenant comment compresser les donn√©es ou, en d'autres termes, comment trouver les s√©quences correspondantes dans un fichier.  Vous pouvez toujours utiliser un tri de suffixes (c'est g√©nial si vous en avez d√©j√† entendu parler).  Il existe des m√©thodes qui garantissent que la correspondance la plus longue se trouve dans les octets pr√©c√©dents apr√®s la compression.  C'est ce qu'on appelle l'analyse optimale et il fournit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">presque</a> le meilleur taux de compression pour un bloc compress√© au format fixe.  Mais il existe de meilleures approches, telles que trouver une correspondance suffisamment bonne qui n'est pas n√©cessairement la plus longue.  Le moyen le plus efficace de le trouver est d'utiliser une table de hachage. <br><br>  Pour ce faire, nous parcourons le curseur √† travers le bloc de donn√©es d'origine et prenons quelques octets apr√®s le curseur (disons 4 octets).  Nous les hachons et mettons l'offset depuis le d√©but du bloc (d'o√π les 4 octets ont √©t√© pris) dans la table de hachage.  La valeur 4 est appel√©e "min-match" - en utilisant cette table de hachage, nous pouvons trouver des correspondances d'au moins 4 octets. <br><br>  Si nous regardons la table de hachage et qu'elle a d√©j√† un enregistrement correspondant, et que le d√©calage ne d√©passe pas la fen√™tre glissante, nous v√©rifions combien d'octets suppl√©mentaires correspondent apr√®s ces 4 octets.  Il y a peut-√™tre beaucoup plus de matchs.  Il est √©galement possible qu'il y ait une collision dans la table de hachage et que rien ne corresponde, mais ce n'est pas grave.  Vous pouvez simplement remplacer la valeur de la table de hachage par une nouvelle.  Les collisions dans la table de hachage entra√Æneront simplement un taux de compression plus faible, car il y aura moins de correspondances.  Soit dit en passant, ce type de table de hachage (avec une taille fixe et sans r√©solution de collisions) est appel√© "table de cache".  Ce nom est logique car en cas de collision, la table de cache oublie simplement l'ancienne entr√©e. <br><br><blockquote>  Un d√©fi pour le lecteur attentif.  Supposons que les donn√©es soient un tableau de nombres UInt32 en petit format endian qui repr√©sente une partie d'une s√©quence de nombres naturels: 0, 1, 2 ... Expliquez pourquoi ces donn√©es ne sont pas compress√©es lorsque vous utilisez LZ4 (la taille des donn√©es compress√©es n'est pas plus petit que les donn√©es non compress√©es). </blockquote><br><h3>  Comment acc√©l√©rer tout </h3><br>  Je veux donc acc√©l√©rer la d√©compression LZ4.  Voyons √† quoi ressemble la boucle de d√©compression.  Le voici en pseudocode: <br><br><pre> <code class="plaintext hljs">while (...) {    read(input_pos, literal_length, match_length);    copy(output_pos, input_pos, literal_length);    output_pos += literal_length;    read(input_pos, match_offset);    copy(output_pos, output_pos - match_offset,        match_length);    output_pos += match_length; }</code> </pre> <br>  Le format LZ4 est con√ßu pour que les litt√©raux et les correspondances alternent dans un fichier compress√©.  √âvidemment, le litt√©ral vient toujours en premier (car il n'y a nulle part o√π prendre un match au tout d√©but).  Par cons√©quent, leurs longueurs sont cod√©es ensemble. <br><br>  C'est en fait un peu plus compliqu√© que √ßa.  Un octet est lu dans le fichier, puis il est divis√© en deux quartets (demi-octets) qui contiennent les nombres cod√©s 0 √† 15. Si le nombre correspondant n'est pas 15, il est suppos√© √™tre la longueur du litt√©ral et correspondre, respectivement.  Et s'il est de 15, la longueur est plus longue et elle est cod√©e dans les octets suivants.  Ensuite, l'octet suivant est lu et sa valeur est ajout√©e √† la longueur.  S'il est √©gal √† 255, la m√™me chose se fait avec l'octet suivant. <br><br>  Notez que le taux de compression maximum pour le format LZ4 n'atteint pas 255. Et une autre observation inutile est que si vos donn√©es sont tr√®s redondantes, l'utilisation de LZ4 deux fois am√©liorera le taux de compression. <br><br>  Lorsque nous lisons la longueur d'un litt√©ral (puis la longueur de correspondance et le d√©calage de correspondance), il suffit de copier deux blocs de m√©moire pour le d√©compresser. <br><br><h3>  Comment copier un bloc de m√©moire </h3><br>  Il semblerait que vous pouvez simplement utiliser la fonction <code>memcpy</code> , qui est con√ßue pour copier des blocs de m√©moire.  Mais ce n'est pas l'approche optimale et ce n'est pas vraiment appropri√©. <br><br>  L'utilisation de memcpy n'est pas optimale car: <br><br><ol><li>  Il est g√©n√©ralement situ√© dans la biblioth√®que libc (et la biblioth√®que libc est g√©n√©ralement li√©e dynamiquement, donc l'appel memcpy sera effectu√© indirectement via PLT). </li><li>  Il n'est pas ins√©r√© par le compilateur si l'argument de taille est inconnu au moment de la compilation. </li><li>  Cela demande beaucoup d'efforts pour traiter correctement les restes d'un bloc de m√©moire qui ne sont pas des multiples de la longueur ou du registre du mot machine. </li></ol><br>  Le dernier point est le plus important.  Disons que nous avons demand√© √† la fonction memcpy de copier exactement 5 octets.  Ce serait bien de copier 8 octets tout de suite, en utilisant deux instructions movq. <br><br> <code>Hello world <font color="#0fc000">Hello</font> <font color="#ff0000">wo</font> ... <br> ^^^^^ <font color="#ff0000">^^^</font> - src <br> ^^^^^ <font color="#ff0000">^^^</font> - dst</code> <br> <br>  Mais alors nous allons copier trois octets suppl√©mentaires, donc nous allons √©crire en dehors des limites du tampon.  La fonction <code>memcpy</code> n'est pas autoris√©e √† le faire, car elle pourrait √©craser certaines donn√©es de notre programme et entra√Æner un bogue de m√©moire stomping.  Et si nous √©crivions √† une adresse non align√©e, ces octets suppl√©mentaires pourraient atterrir sur une page non allou√©e de m√©moire virtuelle ou sur une page sans acc√®s en √©criture.  Cela nous donnerait un d√©faut de segmentation (c'est bien). <br><br>  Mais dans notre cas, nous pouvons presque toujours √©crire des octets suppl√©mentaires.  Nous pouvons lire des octets suppl√©mentaires dans le tampon d'entr√©e tant que les octets suppl√©mentaires se trouvent enti√®rement √† l'int√©rieur.  Dans les m√™mes conditions, nous pouvons √©crire les octets suppl√©mentaires dans le tampon de sortie, car nous les remplacerons toujours √† la prochaine it√©ration. <br><br>  Cette optimisation est d√©j√† dans l'impl√©mentation originale de LZ4: <br><br><pre> <code class="plaintext hljs">inline void copy8(UInt8 * dst, const UInt8 * src) {    memcpy(dst, src, 8); /// Note that memcpy isn't actually called here. } inline void wildCopy8(UInt8 * dst, const UInt8 * src, UInt8 * dst_end) {    do    {        copy8(dst, src);        dst += 8;        src += 8;    } while (dst &lt; dst_end); }</code> </pre> <br>  Pour profiter de cette optimisation, nous devons simplement nous assurer que nous sommes suffisamment √©loign√©s des limites du tampon.  Cela ne devrait rien co√ªter, car nous v√©rifions d√©j√† le d√©bordement de la m√©moire tampon.  Et le traitement des derniers octets, les donn√©es "restantes", peut √™tre effectu√© apr√®s la boucle principale. <br><br>  Cependant, il y a encore quelques nuances.  La copie se produit deux fois dans la boucle: avec un litt√©ral et une correspondance.  Cependant, lors de l'utilisation de la fonction <code>LZ4_decompress_fast</code> (au lieu de <code>LZ4_decompress_safe</code> ), la v√©rification n'est effectu√©e qu'une seule fois, lorsque nous devons copier le litt√©ral.  La v√©rification n'est pas effectu√©e lors de la copie de la correspondance, mais la <a href="">sp√©cification pour le format LZ4</a> a des conditions qui vous permettent de l'√©viter: <br><br><blockquote>  Les 5 derniers octets sont toujours des litt√©raux. <br>  La derni√®re correspondance doit commencer au moins 12 octets avant la fin du bloc. <br>  Par cons√©quent, un bloc de moins de 13 octets ne peut pas √™tre compress√©. </blockquote><br>  Des donn√©es d'entr√©e sp√©cialement s√©lectionn√©es peuvent entra√Æner une corruption de la m√©moire.  Si vous utilisez la fonction <code>LZ4_decompress_fast</code> , vous avez besoin d'une protection contre les donn√©es incorrectes.  √Ä tout le moins, vous devez calculer les sommes de contr√¥le pour les donn√©es compress√©es.  Si vous avez besoin d'une protection contre les pirates, utilisez la fonction <code>LZ4_decompress_safe</code> .  Autres options: prenez une fonction de hachage cryptographique comme somme de contr√¥le (bien que cela risque de d√©truire les performances);  allouer plus de m√©moire aux tampons;  allouer de la m√©moire pour les tampons avec un appel <code>mmap</code> s√©par√© et cr√©er une page de garde. <br><br>  Quand je vois du code qui copie 8 octets de donn√©es, je me demande imm√©diatement pourquoi exactement 8 octets.  Vous pouvez copier 16 octets √† l'aide des registres SSE: <br><br><pre> <code class="plaintext hljs">inline void copy16(UInt8 * dst, const UInt8 * src) { #if __SSE2__    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(dst),        _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(src))); #else    memcpy(dst, src, 16); #endif } inline void wildCopy16(UInt8 * dst, const UInt8 * src, UInt8 * dst_end) {    do    {        copy16(dst, src);        dst += 16;        src += 16;    } while (dst &lt; dst_end); }</code> </pre> <br>  La m√™me chose fonctionne pour copier 32 octets pour AVX et 64 octets pour AVX-512.  De plus, vous pouvez d√©rouler la boucle plusieurs fois.  Si vous avez d√©j√† vu comment <code>memcpy</code> , c'est exactement l'approche qui est utilis√©e.  (Soit dit en passant, le compilateur ne d√©roulera pas ou ne vectorisera pas la boucle dans ce cas, car cela n√©cessitera l'insertion de contr√¥les volumineux.) <br><br>  Pourquoi l'impl√©mentation LZ4 originale n'a-t-elle pas fait cela?  Premi√®rement, il n'est pas clair si c'est mieux ou pire.  Le gain r√©sultant d√©pend de la taille des blocs √† copier, donc s'ils sont tous courts, cela cr√©erait du travail suppl√©mentaire pour rien.  Et deuxi√®mement, cela ruine les dispositions au format LZ4 qui permettent d'√©viter une branche inutile dans la boucle interne. <br><br>  Cependant, nous garderons cette option √† l'esprit pour le moment. <br><br><h3>  Copie d√©licate </h3><br>  Revenons √† la question de savoir s'il est toujours possible de copier des donn√©es de cette fa√ßon.  Disons que nous devons copier une correspondance, c'est-√†-dire prendre un morceau de m√©moire du tampon de sortie situ√© √† un certain d√©calage derri√®re le curseur et le copier √† la position du curseur. <br><br>  Imaginez un cas simple lorsque vous devez copier 5 octets avec un d√©calage de 12: <br><br> <code><font color="#0fc000">Hello</font> world ........... <br> ^^^^^ - src <br> ^^^^^ - dst <br> <br> Hello world <font color="#0fc000">Hello</font> <font color="#a8a8a8">wo</font> ... <br> ^^^^^ - src <br> ^^^^^ - dst</code> <br> <br>  Mais il y a un cas plus difficile, quand nous devons copier un bloc de m√©moire plus long que l'offset.  En d'autres termes, il inclut des donn√©es qui n'ont pas encore √©t√© √©crites dans le tampon de sortie. <br><br>  Copiez 10 octets avec un d√©calage de 3: <br><br> <code><font color="#0fc000">abc</font> ............. <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst <br> <br> abc <font color="#0fc000">abcabcabca</font> ... <br> ^^^^^^^^^^ - src <br> ^^^^^^^^^^ - dst</code> <br> <br>  Nous avons toutes les donn√©es pendant le processus de compression, et une telle correspondance peut tr√®s bien √™tre trouv√©e.  La fonction <code>memcpy</code> ne convient pas pour la copier, car elle ne prend pas en charge le cas o√π les plages de blocs de m√©moire se chevauchent.  La fonction <code>memmove</code> fonctionnera pas non plus, car le bloc de m√©moire √† partir <code>memmove</code> les donn√©es doivent √™tre extraites n'a pas encore √©t√© compl√®tement initialis√©.  Nous devons copier de la m√™me mani√®re que si nous copions octet par octet. <br><br><pre> <code class="plaintext hljs">op[0] = match[0]; op[1] = match[1]; op[2] = match[2]; op[3] = match[3]; ...</code> </pre> <br>  Voici comment cela fonctionne: <br><br> <code><font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ............ <br> ^ - src <br> ^ - dst <br> <br> a <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........... <br> ^ - src <br> ^ - dst <br> <br> ab <font color="#0fc000">c</font> ab <font color="#0fc000">c</font> .......... <br> ^ - src <br> ^ - dst <br> <br> abc <font color="#0fc000">a</font> bc <font color="#0fc000">a</font> ......... <br> ^ - src <br> ^ - dst <br> <br> abca <font color="#0fc000">b</font> ca <font color="#0fc000">b</font> ........ <br> ^ - src <br> ^ - dst</code> <br> <br>  En d'autres termes, nous devons cr√©er une s√©quence r√©p√©titive.  L'impl√©mentation originale de LZ4 a utilis√© un code √©tonnamment √©trange pour ce faire: <br><br><pre> <code class="plaintext hljs">const unsigned dec32table[] = {0, 1, 2, 1, 4, 4, 4, 4}; const int dec64table[] = {0, 0, 0, -1, 0, 1, 2, 3}; const int dec64 = dec64table[offset]; op[0] = match[0]; op[1] = match[1]; op[2] = match[2]; op[3] = match[3]; match += dec32table[offset]; memcpy(op+4, match, 4); match -= dec64;</code> </pre> <br>  Il copie les 4 premiers octets un par un, avance d'un nombre magique, copie enti√®rement les 4 octets suivants et d√©place le curseur sur une correspondance en utilisant un autre nombre magique.  L'auteur du code ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Yan Collet</a> ) a en quelque sorte oubli√© de laisser un commentaire sur ce que cela signifie.  De plus, les noms de variables pr√™tent √† confusion.  Ils sont tous les deux nomm√©s dec ... table, mais l'un est ajout√© et l'autre est soustrait.  De plus, l'un d'eux n'est pas sign√© et l'autre est int.  Cependant, l'auteur a r√©cemment am√©lior√© cette place dans le code. <br><br>  Voici comment cela fonctionne r√©ellement.  Nous copions les 4 premiers octets un √† la fois: <br><br> <code>abc <font color="#0fc000">abca</font> ......... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Maintenant, nous pouvons copier 4 octets √† la fois: <br><br> <code>abcabca <font color="#0fc000">bcab</font> ..... <br> ^^^^ - src <br> ^^^^ - dst</code> <br> <br>  Nous pouvons continuer comme d'habitude, en copiant 8 octets √† la fois: <br><br> <code>abcabcabcab <font color="#0fc000">cabcabca</font> ..... <br> ^^^^^^^^ - src <br> ^^^^^^^^ - dst</code> <br> <br>  Comme nous le savons tous par exp√©rience, la meilleure fa√ßon de comprendre le code est parfois de le r√©√©crire.  Voici ce que nous avons trouv√©: <br><br><pre> <code class="plaintext hljs">inline void copyOverlap8(UInt8 * op, const UInt8 *&amp; match, const size_t offset) {    /// 4 % n.    /// Or if 4 % n is zero, we use n.    /// It gives an equivalent result, but is more CPU friendly for unknown reasons.    static constexpr int shift1[] = { 0, 1, 2, 1, 4, 4, 4, 4 };    /// 8 % n - 4 % n    static constexpr int shift2[] = { 0, 0, 0, 1, 0, -1, -2, -3 };    op[0] = match[0];    op[1] = match[1];    op[2] = match[2];    op[3] = match[3];    match += shift1[offset];    memcpy(op + 4, match, 4);    match += shift2[offset]; }</code> </pre> <br>  Comme pr√©vu, cela ne change pas du tout les performances.  Je voulais juste vraiment essayer l'optimisation pour copier 16 octets √† la fois. <br><br>  Cependant, cela complique le "cas sp√©cial" et le fait appeler plus souvent (la condition <code>offset &lt; 16</code> est effectu√©e au moins aussi souvent que <code>offset &lt; 8</code> ).  La copie des plages qui se chevauchent avec une copie sur 16 octets ressemble √† ceci (seul le d√©but est illustr√©): <br><br><pre> <code class="plaintext hljs">inline void copyOverlap16(UInt8 * op, const UInt8 *&amp; match, const size_t offset) {    /// 4 % n.    static constexpr int shift1[]        = { 0, 1, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4 };    /// 8 % n - 4 % n    static constexpr int shift2[]        = { 0, 0, 0, 1, 0, -1, -2, -3, -4, 4, 4, 4, 4, 4, 4, 4 };    /// 16 % n - 8 % n    static constexpr int shift3[]        = { 0, 0, 0, -1, 0, -2, 2, 1, 8, -1, -2, -3, -4, -5, -6, -7 };    op[0] = match[0];    op[1] = match[1];    op[2] = match[2];    op[3] = match[3];    match += shift1[offset];    memcpy(op + 4, match, 4);    match += shift2[offset];    memcpy(op + 8, match, 8);    match += shift3[offset]; }</code> </pre> <br>  Cette fonction peut-elle √™tre mise en ≈ìuvre plus efficacement?  Nous aimerions trouver une instruction SIMD magique pour un code aussi complexe, car tout ce que nous voulons faire, c'est √©crire 16 octets, qui se composent enti√®rement de quelques octets de donn√©es d'entr√©e (de 1 √† 15).  Il suffit ensuite de les r√©p√©ter dans le bon ordre. <br><br>  Il y a une instruction comme celle-ci appel√©e <code>pshufb</code> (shuffle bytes) qui fait partie de SSSE3 (trois S).  Il accepte deux registres de 16 octets.  L'un des registres contient les donn√©es source.  L'autre a le "s√©lecteur": chaque octet contient un nombre de 0 √† 15, en fonction de l'octet du registre source dont il doit extraire le r√©sultat.  Si la valeur d'octet du s√©lecteur est sup√©rieure √† 127, l'octet correspondant du r√©sultat est rempli de z√©ro. <br><br>  Voici un exemple: <br><br><pre>  xmm0: abc .............
 xmm1: 0120120120120120<font></font>
<font></font>
 pshufb% xmm1,% xmm0<font></font>
<font></font>
 xmm0: abcabcabcabcabca </pre><br>  Chaque octet du r√©sultat est rempli avec l'octet s√©lectionn√© des donn√©es source - c'est exactement ce dont nous avons besoin!  Voici √† quoi ressemble le code dans le r√©sultat: <br><br><pre> <code class="plaintext hljs">inline void copyOverlap16Shuffle(UInt8 * op, const UInt8 *&amp; match, const size_t offset) { #ifdef __SSSE3__    static constexpr UInt8 __attribute__((__aligned__(16))) masks[] =    {        0, 1, 2, 1, 4, 1, 4, 2, 8, 7, 6, 5, 4, 3, 2, 1, /* offset = 0, not used as mask, but for shift amount instead */        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, /* offset = 1 */        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,        0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,        0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0,        0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3,        0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 0, 1,        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,        0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 2, 3, 4,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 0, 1, 2, 3,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 0, 1, 2,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 0, 1,        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0,    };    _mm_storeu_si128(reinterpret_cast&lt;__m128i *&gt;(op),        _mm_shuffle_epi8(            _mm_loadu_si128(reinterpret_cast&lt;const __m128i *&gt;(match)),            _mm_load_si128(reinterpret_cast&lt;const __m128i *&gt;(masks) + offset)));    match += masks[offset]; #else    copyOverlap16(op, match, offset); #endif }</code> </pre> <br>  Ici, <code>_mm_shuffle_epi8</code> est un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">intrins√®que</a> , qui se compile avec l'instruction CPU <code>pshufb</code> . <br><br>  Pouvons-nous effectuer cette op√©ration pour plusieurs octets √† la fois en utilisant des instructions plus r√©centes?  Apr√®s tout, SSSE3 est un tr√®s ancien jeu d'instructions qui existe depuis 2006. AVX2 a une instruction qui le fait pour 32 octets √† la fois, mais s√©par√©ment pour les voies individuelles de 16 octets.  C'est ce qu'on appelle des octets de permutation vectorielle, plut√¥t que des octets de m√©lange al√©atoire - les mots sont diff√©rents, mais la signification est la m√™me.  AVX-512 VBMI a une autre instruction qui fonctionne pour 64 octets √† la fois, mais les processeurs qui la prennent en charge ne sont apparus que r√©cemment.  ARM NEON a des instructions similaires appel√©es vtbl (recherche de table vectorielle), mais elles ne permettent d'√©crire que 8 octets. <br><br>  De plus, il existe une version de l'instruction <code>pshufb</code> avec des registres MMX 64 bits pour former 8 octets.  C'est parfait pour remplacer la version originale du code.  Cependant, j'ai d√©cid√© d'utiliser √† la place l'option 16 octets (pour des raisons s√©rieuses). <br><br>  Lors de la conf√©rence Highload ++ Siberia, un participant est venu vers moi apr√®s ma pr√©sentation et a mentionn√© que pour le cas de 8 octets, vous pouvez simplement utiliser la multiplication par une constante sp√©cialement s√©lectionn√©e (vous aurez √©galement besoin d'un d√©calage) - cela ne s'√©tait m√™me pas produit √† moi avant! <br><br><h3>  Comment supprimer une instruction if superflue </h3><br>  Disons que je veux utiliser une variante qui copie 16 octets.  Comment puis-je √©viter d'avoir √† effectuer une v√©rification suppl√©mentaire pour le d√©passement de tampon? <br><br>  J'ai d√©cid√© que je ne ferais pas ce contr√¥le.  Les commentaires sur la fonction diront que le d√©veloppeur doit allouer un bloc de m√©moire pour un nombre sp√©cifi√© d'octets de plus que n√©cessaire, afin que nous puissions y lire et √©crire des ordures inutiles.  L'interface de la fonction sera plus difficile √† utiliser, mais c'est un probl√®me diff√©rent. <br><br>  En fait, il pourrait y avoir des cons√©quences n√©gatives.  Disons que les donn√©es dont nous avons besoin pour d√©compresser √©taient form√©es de blocs de 65 536 octets chacun.  Ensuite, l'utilisateur nous donne un morceau de m√©moire de 65 536 octets pour les donn√©es d√©compress√©es.  Mais avec la nouvelle interface de fonction, l'utilisateur devra par exemple allouer un bloc m√©moire de 65 551 octets.  L'allocateur peut alors √™tre contraint d'allouer r√©ellement 96 ou m√™me 128 kilo-octets, selon son impl√©mentation.  Si l'allocateur est tr√®s mauvais, il peut soudainement arr√™ter la mise en cache de la m√©moire dans "heap" et commencer √† utiliser <code>mmap</code> et <code>munmap</code> chaque fois pour l'allocation de m√©moire (ou lib√©rer de la m√©moire √† l'aide de <code>madvice</code> ).  Ce processus sera extr√™mement lent en raison de d√©fauts de page.  En cons√©quence, cette petite optimisation pourrait finir par tout ralentir. <br><br><h3>  Y a-t-il une acc√©l√©ration? </h3><br>  J'ai donc fait une version du code qui utilise trois optimisations: <br><br><ol><li>  Copie de 16 octets au lieu de 8. </li><li>  Utilisation des instructions de lecture al√©atoire pour le cas de <code>offset &lt; 16</code> . </li><li>  Suppression d'un extra si. </li></ol><br>  J'ai commenc√© √† tester ce code sur diff√©rents ensembles de donn√©es et j'ai obtenu des r√©sultats inattendus. <br><br>  Exemple 1: <br>  Xeon E2650v2, donn√©es du navigateur Yandex, colonne AppVersion. <br>  R√©f√©rence: 1,67 Go / sec. <br>  16 octets, lecture al√©atoire: 2,94 Go / sec (76% plus rapide). <br><br>  Exemple 2: <br>  Xeon E2650v2, donn√©es Yandex Direct, colonne ShowsSumPosition. <br>  R√©f√©rence: 2,30 Go / sec. <br>  16 octets, lecture al√©atoire: 1,91 Go / s (20% plus lent). <br><br>  J'√©tais vraiment content au d√©but, quand j'ai vu que tout s'√©tait acc√©l√©r√© √† un pourcentage aussi √©lev√©.  Ensuite, j'ai vu que rien n'√©tait plus rapide avec les autres fichiers.  C'√©tait m√™me un peu plus lent pour certains d'entre eux.  J'ai conclu que les r√©sultats d√©pendent du taux de compression.  Plus le fichier est compress√©, plus l'avantage de passer √† 16 octets est grand.  Cela semble naturel: plus le taux de compression est √©lev√©, plus la longueur moyenne des fragments √† copier est longue. <br><br>  Pour enqu√™ter, j'ai utilis√© des mod√®les C ++ pour cr√©er des options de code pour quatre cas: en utilisant des blocs de 8 octets ou 16 octets, et avec ou sans l'instruction shuffle. <br><br><pre> <code class="plaintext hljs">template &lt;size_t copy_amount, bool use_shuffle&gt; void NO_INLINE decompressImpl(    const char * const source,    char * const dest,    size_t dest_size)</code> </pre> <br>  Des variantes compl√®tement diff√©rentes du code fonctionnaient mieux sur diff√©rents fichiers, mais lors des tests sur un bureau, la version avec shuffle gagnait toujours.  Les tests sur un bureau ne sont pas pratiques car vous devez le faire: <br><br><pre> <code class="plaintext hljs">sudo echo 'performance' | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor kill -STOP $(pidof firefox) $(pidof chromium)</code> </pre> <br>  Ensuite, je suis all√© sur l'un des anciens serveurs de "d√©veloppement" (avec le processeur Xeon E5645), j'ai pris encore plus de jeux de donn√©es et j'ai obtenu presque les r√©sultats oppos√©s, ce qui m'a totalement d√©rout√©.  Il s'av√®re que le choix de l'algorithme optimal d√©pend du mod√®le de processeur, en plus du taux de compression.  Le processeur d√©termine quand il est pr√©f√©rable d'utiliser l'instruction de lecture al√©atoire, ainsi que le seuil pour savoir quand commencer √† utiliser la copie sur 16 octets. <br><br>  Au fait, lors des tests sur nos serveurs, il est logique de le faire: <br><br><pre> <code class="plaintext hljs">sudo kill -STOP $(pidof python) $(pidof perl) $(pgrep -u skynet) $(pidof cqudp-client)</code> </pre> <br>  Sinon, les r√©sultats seront instables.  Faites √©galement attention √† la limitation thermique et au plafonnement de la puissance. <br><br><h3>  Comment choisir le meilleur algorithme </h3><br>  Nous avons donc quatre variantes de l'algorithme et nous devons choisir la meilleure pour les conditions.  Nous pourrions cr√©er un ensemble repr√©sentatif de donn√©es et de mat√©riel, puis effectuer des tests de charge s√©rieux et choisir la m√©thode qui est la meilleure en moyenne.  Mais nous n'avons pas de jeu de donn√©es repr√©sentatif.  Pour les tests, j'ai utilis√© un √©chantillon de donn√©es de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Yandex Metrica</a> , Yandex Direct, Yandex Browser et des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vols aux √âtats-Unis</a> .  Mais cela ne suffit pas, car ClickHouse est utilis√© par des centaines d'entreprises √† travers le monde.  Une optimisation excessive sur un ensemble de donn√©es peut entra√Æner une baisse des performances avec d'autres donn√©es et m√™me ne pas le r√©aliser.  Et si les r√©sultats d√©pendent du mod√®le de processeur, nous devrons √©crire explicitement les conditions dans le code et le tester sur chaque mod√®le (ou consulter le manuel de r√©f√©rence sur les instructions de timing, qu'en pensez-vous?).  Dans les deux cas, cela prend trop de temps. <br><br>  J'ai donc d√©cid√© d'utiliser une autre m√©thode, ce qui est √©vident pour les coll√®gues qui ont √©tudi√© √† notre √©cole d'analyse de donn√©es: les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´bandits multi-arm√©s¬ª</a> .  Le fait est que la variante de l'algorithme est choisie au hasard, puis nous utilisons des statistiques pour choisir progressivement plus souvent les options qui fonctionnent mieux. <br><br>  Nous avons de nombreux blocs de donn√©es qui doivent √™tre d√©compress√©s, nous avons donc besoin d'appels de fonction ind√©pendants pour d√©compresser les donn√©es.  Nous pourrions choisir l'un des quatre algorithmes pour chaque bloc et mesurer son temps d'ex√©cution.  Une op√©ration comme celle-ci ne co√ªte g√©n√©ralement rien par rapport au traitement d'un bloc de donn√©es, et dans ClickHouse, un bloc de donn√©es non compress√©es fait au moins 64 Ko.  (Lisez cet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> sur la mesure du temps.) <br><br>  Pour mieux comprendre le fonctionnement de l'algorithme des ¬´bandits multi-arm√©s¬ª, regardons d'o√π vient le nom.  C'est une analogie avec les machines √† sous dans un casino qui ont plusieurs leviers qu'un joueur peut tirer pour obtenir une somme d'argent al√©atoire.  Le joueur peut tirer les leviers plusieurs fois dans n'importe quel ordre.  Chaque levier a une probabilit√© fixe pour le montant d'argent donn√©, mais le joueur ne sait pas comment cela fonctionne et ne peut l'apprendre que par l'exp√©rience du jeu.  Une fois qu'ils l'ont compris, ils peuvent maximiser leurs gains. <br><br>  Une approche pour maximiser la r√©compense consiste √† √©valuer la distribution de probabilit√© pour chaque levier √† chaque √©tape sur la base des statistiques de jeu des √©tapes pr√©c√©dentes.  Ensuite, nous ¬´gagnons¬ª mentalement une r√©compense al√©atoire pour chaque levier, en fonction des distributions re√ßues.  Enfin, nous tirons sur le levier qui a eu le meilleur r√©sultat dans notre jeu mental.  Cette approche est appel√©e Thompson Sampling. <br><br>  Mais nous choisissons un algorithme de d√©compression.  Le r√©sultat est le temps d'ex√©cution en picosecondes par octet: moins il y en a, mieux c'est.  Nous consid√©rerons le temps d'ex√©cution comme une variable al√©atoire et √©valuerons sa distribution √† l'aide de statistiques math√©matiques.  L'approche bay√©sienne est souvent utilis√©e pour des t√¢ches comme celle-ci, mais il serait fastidieux d'ins√©rer des formules complexes dans du code C ++.  Nous pouvons utiliser une approche param√©trique et dire qu'une variable al√©atoire appartient √† une famille param√©trique de variables al√©atoires, puis √©valuer ses param√®tres. <br><br>  Comment s√©lectionner la famille de variables al√©atoires?  Par exemple, nous pouvons supposer que le temps d'ex√©cution du code a une distribution normale.  Mais c'est absolument faux.  Tout d'abord, le temps d'ex√©cution ne peut pas √™tre n√©gatif et la distribution normale prend des valeurs partout sur la droite num√©rique.  Deuxi√®mement, je suppose que le temps d'ex√©cution aura une "queue" lourde √† l'extr√©mit√© droite. <br><br>  Cependant, certains facteurs pourraient faire une bonne id√©e d'estimer la distribution normale uniquement aux fins de l'√©chantillonnage de Thompson (malgr√© le fait que la distribution de la variable cible n'est pas n√©cessairement normale).  La raison en est qu'il est tr√®s facile de calculer l'esp√©rance math√©matique et la variance, et apr√®s un nombre suffisant d'it√©rations, une distribution normale devient assez √©troite, pas tr√®s diff√©rente des distributions que nous aurions obtenues en utilisant d'autres m√©thodes.  Si nous ne sommes pas trop pr√©occup√©s par le taux de convergence lors des premi√®res √©tapes, ces d√©tails peuvent √™tre ignor√©s. <br><br> This may seem like a somewhat ignorant approach. Experience has shown us that the average time for query execution, website page loading, and so on is "garbage" that isn't worth calculating. It would be better to calculate the median, which is a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">robust statistic</a> . But this is a little more difficult, and as I will show later, the described method justifies itself for practical purposes. <br><br> At first I implemented calculation of the mathematical expectation and variance, but then I decided that this is too good, and I need to simplify the code to make it "worse": <br><br><pre> <code class="plaintext hljs">/// For better convergence, we don't use proper estimate of stddev. /// We want to eventually separate the two algorithms even in cases /// when there is no statistical significant difference between them. double sigma() const {    return mean() / sqrt(adjustedCount()); } double sample(pcg64 &amp; rng) const {    ...    return std::normal_distribution&lt;&gt;(mean(), sigma())(rng); }</code> </pre> <br> I wrote it so that the first few iterations were not taken into account, to eliminate the effect of memory latencies. <br><br> The result is a test program that can select the best algorithm for the input data, with optional modes that use the reference implementation of LZ4 or a specific version of the algorithm. <br><br> So there are six options: <br> ‚Äî Reference (baseline): original LZ4 without our modifications. <br> ‚Äî Variant 0: copy 8 bytes at a time without shuffle. <br> ‚Äî Variant 1: copy 8 bytes at a time with shuffle. <br> ‚Äî Variant 2: copy 16 bytes at a time without shuffle. <br> ‚Äî Variant 3: copy 16 bytes at a time with shuffle. <br> ‚Äî The "bandit" option, which selects the best of the four optimized variants. <br><br><h3> Testing on different CPUs </h3><br> If the result strongly depends on the CPU model, it would be interesting to find out exactly how it is affected. There might be an exceptionally large difference on certain CPUs. <br><br> I prepared a set of datasets from different tables in ClickHouse with real data, for a total of 256 different files each with 100 MB of uncompressed data (the number 256 was coincidental). Then I looked at the CPUs of the servers where I can run benchmarks. I found servers with the following CPUs: <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2650 v2 @ 2.60GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2660 v4 @ 2.00GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2660 0 @ 2.20GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5645 @ 2.40GHz <br> ‚Äî Intel Xeon E312xx (Sandy Bridge) <br> ‚Äî AMD Opteron(TM) Processor 6274 <br> ‚Äî AMD Opteron(tm) Processor 6380 <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2683 v4 @ 2.10GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5530 @ 2.40GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5440 @ 2.83GHz <br> ‚Äî Intel¬Æ Xeon¬Æ CPU E5-2667 v2 @ 3.30GHz <br><br> The most interesting part comes next ‚Äî the processors provided by the R&amp;D department: <br> ‚Äî AMD EPYC 7351 16-Core Processor, a new AMD server processor. <br> ‚Äî Cavium ThunderX2, which is AArch64, not x86. For these, my SIMD optimization needed to be reworked a bit. The server has 224 logical and 56 physical cores. <br><br> There are 13 servers in total, and each of them runs the test on 256 files in 6 variants (reference, 0, 1, 2, 3, adaptive). The test is run 10 times, alternating between the options in random order. It outputs 199,680 results that we can compare. <br><br> For example, we can compare different CPUs with each other. But we shouldn't jump to conclusions from these results, because we are only testing the LZ4 decompression algorithm on a single core (this is a very narrow case, so we only get a micro-benchmark). For example, the Cavium has the lowest performance per single core. But I tested ClickHouse on it myself, and it wins out over Xeon E5-2650 v2 on heavy queries due to the greater number of cores, even though it is missing many optimizations that are made in ClickHouse specifically for the x86. <br><br><pre> ‚îå‚îÄcpu‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄref‚îÄ‚î¨‚îÄadapt‚îÄ‚î¨‚îÄ‚îÄmax‚îÄ‚î¨‚îÄbest‚îÄ‚î¨‚îÄadapt_boost‚îÄ‚î¨‚îÄmax_boost‚îÄ‚î¨‚îÄadapt_over_max‚îÄ‚îê<font></font>
‚îÇ E5-2667 v2 @ 3.30GHz ‚îÇ 2.81 ‚îÇ 3.19 ‚îÇ 3.15 ‚îÇ 3 ‚îÇ 1.14 ‚îÇ 1.12 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5-2650 v2 @ 2.60GHz ‚îÇ 2.5 ‚îÇ 2.84 ‚îÇ 2.81 ‚îÇ 3 ‚îÇ 1.14 ‚îÇ 1.12 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5-2683 v4 @ 2.10GHz ‚îÇ 2.26 ‚îÇ 2.63 ‚îÇ 2.59 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.15 ‚îÇ 1.02 ‚îÇ<font></font>
‚îÇ E5-2660 v4 @ 2.00GHz ‚îÇ 2.15 ‚îÇ 2.49 ‚îÇ 2.46 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.14 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ AMD EPYC 7351 ‚îÇ 2.03 ‚îÇ 2.44 ‚îÇ 2.35 ‚îÇ 3 ‚îÇ 1.20 ‚îÇ 1.16 ‚îÇ 1.04 ‚îÇ<font></font>
‚îÇ E5-2660 0 @ 2.20GHz ‚îÇ 2.13 ‚îÇ 2.39 ‚îÇ 2.37 ‚îÇ 3 ‚îÇ 1.12 ‚îÇ 1.11 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E312xx (Sandy Bridge) ‚îÇ 1.97 ‚îÇ 2.2 ‚îÇ 2.18 ‚îÇ 3 ‚îÇ 1.12 ‚îÇ 1.11 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ E5530 @ 2.40GHz ‚îÇ 1.65 ‚îÇ 1.93 ‚îÇ 1.94 ‚îÇ 3 ‚îÇ 1.17 ‚îÇ 1.18 ‚îÇ 0.99 ‚îÇ<font></font>
‚îÇ E5645 @ 2.40GHz ‚îÇ 1.65 ‚îÇ 1.92 ‚îÇ 1.94 ‚îÇ 3 ‚îÇ 1.16 ‚îÇ 1.18 ‚îÇ 0.99 ‚îÇ<font></font>
‚îÇ AMD Opteron 6380 ‚îÇ 1.47 ‚îÇ 1.58 ‚îÇ 1.56 ‚îÇ 1 ‚îÇ 1.07 ‚îÇ 1.06 ‚îÇ 1.01 ‚îÇ<font></font>
‚îÇ AMD Opteron 6274 ‚îÇ 1.15 ‚îÇ 1.35 ‚îÇ 1.35 ‚îÇ 1 ‚îÇ 1.17 ‚îÇ 1.17 ‚îÇ 1 ‚îÇ<font></font>
‚îÇ E5440 @ 2.83GHz ‚îÇ 1.35 ‚îÇ 1.33 ‚îÇ 1.42 ‚îÇ 1 ‚îÇ 0.99 ‚îÇ 1.05 ‚îÇ 0.94 ‚îÇ<font></font>
‚îÇ Cavium ThunderX2 ‚îÇ 0.84 ‚îÇ 0.87 ‚îÇ 0.87 ‚îÇ 0 ‚îÇ 1.04 ‚îÇ 1.04 ‚îÇ 1 ‚îÇ<font></font>
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò </pre><br><ul><li> ref, adapt, max ‚Äî The speed in gigabytes per second (the value that is the reverse of the arithmetic mean of time for all launches on all datasets). </li><li> best ‚Äî The number of the best algorithm among the optimized variants, from 0 to 3. </li><li> adapt_boost ‚Äî The relative advantage of the adaptive algorithm compared to the baseline. </li><li> max_boost ‚Äî The relative advantage of the best of the non-adaptive variants compared to the baseline. </li><li> adapt_over_max ‚Äî The relative advantage of the adaptive algorithm over the best non-adaptive one. </li></ul><br> The results show that we were able to speed up decompression by 12-20% on modern x86 processors. Even on ARM we saw 4% improvement, despite the fact that we didn't optimize much for this architecture. It is also clear that on average for different datasets, the "bandit" algorithm comes out ahead of the pre-selected best variant on all processors (except for very old Intel CPUs). <br><br><h3>  Conclusion </h3><br> In practice, the usefulness of this work is dubious. Yes, LZ4 decompression was accelerated on average by 12-20%, and on some datasets the performance more than doubled. But in general, this doesn't have much effect on query execution time. It's difficult to find real queries that gain more than a couple percent in speed. <br><br> We decided to use ZStandard level 1 instead of LZ4 on several Yandex Metrica clusters intended for executing long queries, because it is more important to save IO and disk space on cold data. Keep this in mind if you have similar workload. <br><br> We observed the greatest benefits from optimizing decompression in highly compressible data, such as columns with mostly duplicate string values. However, we have developed a separate solution specifically for this scenario that allows us to significantly speed up queries over this kind of data. <br><br> Another point to remember is that optimization of decompression speed is often limited by the format of the compressed data. LZ4 uses a very good format, but Lizard, Density and LZSSE have other formats that can work faster. Perhaps instead of trying to accelerate LZ4, it would be better to just integrate LZSSE into ClickHouse. <br><br> It's unlikely that these optimizations will be implemented in the mainstream LZ4 library: in order to use them, the library interface would have to be modified. In fact, this is often the case with improving algorithms ‚Äî optimizations don't fit into old abstractions and they have to be revised. However, variable names have already been corrected in the original implementation. For instance, inc and dec tables have been <a href="">corrected</a> . In addition, about a month ago, the original implementation accelerated decompression by the same 12-15% by copying 32 bytes instead of 16, as discussed above. We tried the 32-byte option ourselves and the results were not that great, but they were still <a href="">faster</a> . <br><br> If you look at the profile at the beginning of the article, you may notice that we could have removed one extra copying operation from the page cache to userspace (either using <code>mmap</code> , or using <code>O_DIRECT</code> and userspace page cache, but both options are problematic). We also could have slightly improved the checksum calculation (CityHash128 is currently used without CRC32-C, but we could use HighwayHash, FARSH or XXH3). Acceleration of these two operations is useful for weakly compressed data, since they are performed on compressed data. <br><br> In any case, the changes have already been added to master more than a year ago, and the ideas that resulted from this research have been applied in other tasks. You can also watch the <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">video</a> from HighLoad++ Siberia, or view the <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">presentation</a> (both in Russian). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr457612/">https://habr.com/ru/post/fr457612/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr457600/index.html">Pr√©sentation des casques Snom A150, Snom A100M et D</a></li>
<li><a href="../fr457602/index.html">Recherche des performances du SGBD MS SQL Server Developer 2016 et PostgreSQL 10.5 pour 1C</a></li>
<li><a href="../fr457606/index.html">Alan Kay: Ce que l'on peut appeler la chose la plus √©tonnante que les ordinateurs ont rendue possible</a></li>
<li><a href="../fr457608/index.html">Comment visualiser les donn√©es dans une histoire captivante</a></li>
<li><a href="../fr457610/index.html">Analyse des vuln√©rabilit√©s de Evil Parcel</a></li>
<li><a href="../fr457614/index.html">Les secrets de la recherche d'un emploi √† l'√©tranger aupr√®s d'un chasseur de t√™tes en exercice</a></li>
<li><a href="../fr457616/index.html">Mon "Wow, je ne savais pas √ßa!" moments avec plaisanterie</a></li>
<li><a href="../fr457618/index.html">√ätre un d√©veloppeur full-stack moderne</a></li>
<li><a href="../fr457622/index.html">Mesurer les performances Qt</a></li>
<li><a href="../fr457624/index.html">Comment nous avons cass√© l'ancienne cabane et construit un gratte-ciel √† sa place</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
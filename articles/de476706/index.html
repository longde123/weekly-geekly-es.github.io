<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸƒ ğŸ‘©ğŸ½â€ğŸ¤â€ğŸ‘¨ğŸ¾ ğŸ€ Cerebras Systems stellte einen Computer mit dem weltweit grÃ¶ÃŸten Prozessor 22 Ã— 22 Zentimeter vor ğŸŠ ğŸ¤²ğŸ¼ ğŸŒ…</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das CS-1-Computerdiagramm zeigt, dass das meiste der Stromversorgung und KÃ¼hlung der riesigen Wafer-Scale-Engine (WSE) auf der Platte gewidmet ist. Fo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cerebras Systems stellte einen Computer mit dem weltweit grÃ¶ÃŸten Prozessor 22 Ã— 22 Zentimeter vor</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dcmiran/blog/476706/"><img src="https://habrastorage.org/getpro/habr/post_images/43e/87f/2b3/43e87f2b3b76001e51387e09935558ba.jpg"><br>  <i><font color="gray">Das CS-1-Computerdiagramm zeigt, dass das meiste der Stromversorgung und KÃ¼hlung der riesigen Wafer-Scale-Engine (WSE) auf der Platte gewidmet ist.</font></i>  <i><font color="gray">Foto: Cerebras-Systeme</font></i> <br><br>  Im August 2019 gaben Cerebras Systems und sein Herstellungspartner TSMC den <a href="https://habr.com/ru/news/t/464271/">grÃ¶ÃŸten Chip in der Geschichte der Computertechnologie bekannt</a> .  Mit einer FlÃ¤che von 46.225 mmÂ² und 1,2 Billionen Transistoren ist der WSE-Chip (Wafer Scale Engine) ungefÃ¤hr 56,7-mal grÃ¶ÃŸer als die grÃ¶ÃŸte GPU (21,1 Milliarden Transistoren, 815 mmÂ²). <br><br>  Skeptiker sagten, dass die Entwicklung eines Prozessors nicht die schwierigste Aufgabe sei.  Aber wie funktioniert das in einem echten Computer?  Wie hoch ist der Prozentsatz fehlerhafter Arbeiten?  Welche Leistung und KÃ¼hlung wird benÃ¶tigt?  Wie viel kostet eine solche Maschine? <br><br>  Es scheint, dass die Ingenieure von Cerebras Systems und TSMC diese Probleme lÃ¶sen konnten.  Am 18. November 2019 stellten sie auf der <a href="https://sc19.supercomputing.org/">Supercomputing-</a> Konferenz <a href="https://sc19.supercomputing.org/">2019</a> offiziell den <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">CS-1 vor</a> , "den weltweit schnellsten Computer fÃ¼r das Rechnen auf dem Gebiet des maschinellen Lernens und der kÃ¼nstlichen Intelligenz". <br><a name="habracut"></a><br>  Die ersten Exemplare von CS-1 wurden bereits an Kunden gesendet.  Eine davon wird im Argonne National Laboratory des US-Energieministeriums installiert, in dem mit der Montage des leistungsstÃ¤rksten Supercomputers der USA aus <a href="https://habr.com/ru/company/dcmiran/blog/476378/">Aurora-Modulen auf der neuen Intel-GPU-Architektur</a> begonnen wird.  Ein weiterer Kunde war das Livermore National Laboratory. <br><br>  Der Prozessor mit 400.000 Kernen ist fÃ¼r Rechenzentren zur Verarbeitung von Daten im Bereich des maschinellen Lernens und der kÃ¼nstlichen Intelligenz ausgelegt.  Cerebras behauptet, dass der Computer KI-Systeme um GrÃ¶ÃŸenordnungen effizienter trainiert als vorhandene GerÃ¤te.  Leistung CS-1 entspricht â€Hunderten von GPU-basierten Servernâ€œ, die Hunderte von Kilowatt verbrauchen.  Gleichzeitig belegt es nur 15 Einheiten im Server-Rack und verbraucht etwa 17 kW. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cfc/5aa/1da/cfc5aa1da0e52944fc1b68e4fca15146.jpg"><br>  <i><font color="gray">WSE-Prozessor.</font></i>  <i><font color="gray">Foto: Cerebras-Systeme</font></i> <br><br>  Andrew Feldman, CEO und MitbegrÃ¼nder von Cerebras Systems, sagt, der CS-1 sei "der schnellste KI-Computer der Welt".  Er verglich es mit Googles TPU-Clustern und stellte fest, dass jeder von ihnen â€10 Racks benÃ¶tigt und mehr als 100 Kilowatt verbraucht, um ein Drittel der Leistung einer einzelnen CS-1-Installation zu erbringenâ€œ. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/523/1d3/b60/5231d3b60c445d641bb654d29b8fec21.jpg"><br>  <i><font color="gray">Computer CS-1.</font></i>  <i><font color="gray">Foto: Cerebras-Systeme</font></i> <br><br>  Das Erlernen groÃŸer neuronaler Netze kann auf einem Standardcomputer Wochen dauern.  Die Installation eines CS-1 mit einem Prozessorchip mit 400.000 Kernen und 1,2 Billionen Transistoren erledigt diese Aufgabe in Minuten oder sogar Sekunden, <a href="https://spectrum.ieee.org/tech-talk/computing/hardware/cerebras-unveils-ai-supercomputer-argonne-national-lab-first-installation">schreibt</a> IEEE Spectrum.  Cerebras lieferte jedoch keine echten Testergebnisse zum Testen von Hochleistungsaussagen wie <a href="https://mlperf.org/training-results-0-6">MLPerf-Tests</a> .  Stattdessen knÃ¼pfte das Unternehmen direkt Kontakte zu potenziellen Kunden - und durfte eigene Modelle neuronaler Netze auf CS-1 trainieren. <br><br>  Dieser Ansatz ist nicht ungewÃ¶hnlich, sagen Analysten: â€Jeder verwaltet seine eigenen Modelle, die er fÃ¼r sein eigenes Unternehmen entwickelt hatâ€œ, sagte <a href="http://www.moorinsightsstrategy.com/karl-freund-biography/">Karl Freund</a> , Analyst fÃ¼r kÃ¼nstliche Intelligenz bei Moor Insights &amp; Strategies.  "Dies ist das einzige, was fÃ¼r Kunden wichtig ist." <br><br>  Viele Unternehmen entwickeln spezielle Chips fÃ¼r KI, darunter Vertreter der traditionellen Industrie wie Intel, Qualcomm sowie verschiedene Startups in den USA, GroÃŸbritannien und China.  Google hat einen Chip speziell fÃ¼r neuronale Netze entwickelt - einen Tensor-Prozessor oder TPU.  Mehrere andere Hersteller folgten diesem Beispiel.  KI-Systeme arbeiten im Multithread-Modus, und der Engpass verschiebt Daten zwischen den Chips: â€Das AnschlieÃŸen der Chips verlangsamt sie tatsÃ¤chlich und erfordert viel Energieâ€œ, <a href="https://www.nytimes.com/2019/08/19/technology/artificial-intelligence-chip-cerebras.html">erklÃ¤rt</a> Subramanian Iyer, Professor an der University of California in Los Angeles, der sich darauf spezialisiert hat Entwicklung von Chips fÃ¼r kÃ¼nstliche Intelligenz.  GerÃ¤tehersteller prÃ¼fen viele verschiedene Optionen.  Einige versuchen, Interprozessverbindungen zu erweitern. <br><br>  Das vor drei Jahren gegrÃ¼ndete Unternehmen Cerebras, das mehr als 200 Millionen US-Dollar an Risikofinanzierungen erhalten hat, hat einen neuen Ansatz vorgeschlagen.  Die Idee ist, alle Daten auf einem riesigen Chip zu speichern - und damit die Berechnungen zu beschleunigen. <br><br><img src="https://habrastorage.org/webt/up/k1/ej/upk1ejv8zsqxtj9nadanm8898zc.jpeg"><br><br>  Die gesamte Mikroschaltungsplatte ist in 400.000 kleinere Abschnitte (Kerne) unterteilt, da einige davon nicht funktionieren.  Der Chip ist so konstruiert, dass er fehlerhafte Bereiche umfahren kann.  Programmierbare SLAC-Kerne (Sparse Linear Algebra Cores) sind fÃ¼r lineare Algebra, dh fÃ¼r Berechnungen im Vektorraum, optimiert.  Das Unternehmen hat auch die Sparsity Harvesting-Technologie entwickelt, um die Rechenleistung unter spÃ¤rlichen Workloads (mit Nullen) wie Deep Learning zu verbessern.  Vektoren und Matrizen im Vektorraum enthalten normalerweise viele Nullelemente (von 50% bis 98%), sodass bei herkÃ¶mmlichen GPUs der grÃ¶ÃŸte Teil der Berechnung verschwendet wird.  Im Gegensatz dazu filtern SLAC-Kerne Nulldaten vor. <br><br>  Die Kommunikation zwischen den Kernen wird vom Swarm-System mit einem Durchsatz von 100 Petabits pro Sekunde bereitgestellt.  Hardware-Routing, Latenz gemessen in Nanosekunden. <br><br>  Die Kosten fÃ¼r einen Computer werden nicht genannt.  UnabhÃ¤ngige Experten glauben, dass der tatsÃ¤chliche Preis vom Prozentsatz der Ehe abhÃ¤ngt.  AuÃŸerdem sind die Leistung des Chips und die Anzahl der in realen Proben betriebenen Kerne nicht zuverlÃ¤ssig bekannt. <br><br><h1>  Software </h1><br>  Cerebras hat einige Details zum Softwareteil des CS-1-Systems bekannt gegeben.  Mit der Software kÃ¶nnen Benutzer ihre eigenen Modelle fÃ¼r maschinelles Lernen mit Standard-Frameworks wie <a href="https://pytorch.org/">PyTorch</a> und <a href="https://www.tensorflow.org/">TensorFlow</a> <a href="https://pytorch.org/">erstellen</a> .  Das System verteilt dann 400.000 Kerne und 18 Gigabyte SRAM-Speicher auf dem Chip auf die Schichten des neuronalen Netzwerks, so dass alle Schichten ihre Arbeit ungefÃ¤hr zur gleichen Zeit wie ihre Nachbarn abschlieÃŸen (Optimierungsaufgabe).  Infolgedessen werden Informationen von allen Schichten ohne VerzÃ¶gerung verarbeitet.  Mit einem 100-Gigabit-Ethernet-E / A-Subsystem mit 12 Ports kann der CS-1 1,2 Terabit Daten pro Sekunde verarbeiten. <br><br>  Die Konvertierung des neuronalen Quellnetzwerks in eine optimierte ausfÃ¼hrbare Darstellung (Cerebras Linear Algebra Intermediate Representation, CLAIR) erfolgt durch den Cerebras Graph Compiler (CGC).  Der Compiler weist jedem Teil des Diagramms Rechenressourcen und Speicher zu und vergleicht sie dann mit dem Rechenarray.  Dann wird der Kommunikationspfad gemÃ¤ÃŸ der internen Struktur der Platte berechnet, die fÃ¼r jedes Netzwerk eindeutig ist. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/098/093/569/098093569a8dca7e8dea9e26fc63a81a.jpg"><br>  <i><font color="gray">Verteilung der mathematischen Operationen eines neuronalen Netzwerks durch Prozessorkerne.</font></i>  <i><font color="gray"><a href="https://fortune.com/2019/11/19/artificial-intelligence-cerebras-supercomputer/">Foto</a> : GroÃŸhirn</font></i> <br><br>  Aufgrund der enormen GrÃ¶ÃŸe von WSE befinden sich alle Schichten in einem neuronalen Netzwerk gleichzeitig darauf und arbeiten parallel.  Dieser Ansatz ist einzigartig fÃ¼r WSE - laut Cerebras verfÃ¼gt kein anderes GerÃ¤t Ã¼ber genÃ¼gend internen Speicher, um alle Schichten auf einem Chip gleichzeitig zu speichern.  Eine solche Architektur mit der Platzierung des gesamten neuronalen Netzwerks auf einem Chip bietet aufgrund des hohen Durchsatzes und der geringen Latenz groÃŸe Vorteile. <br><br>  Die Software kann die Optimierungsaufgabe fÃ¼r mehrere Computer ausfÃ¼hren, sodass der Computercluster als eine groÃŸe Maschine fungieren kann.  Ein Cluster von 32 CS-1-Computern weist eine etwa 32-fache Leistungssteigerung auf, was auf eine sehr gute Skalierbarkeit hinweist.  Laut Feldman unterscheidet sich dies von GPU-basierten Clustern: â€Heute verhÃ¤lt sich ein GPU-Cluster nicht mehr wie ein einziger groÃŸer Computer.  Du bekommst viele kleine Autos. â€œ <br><br>  In der <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">Pressemitteilung</a> heiÃŸt es, dass das Argonne National Laboratory seit zwei Jahren mit Cerebras zusammenarbeitet: "Durch den Einsatz von CS-1 haben wir die Trainingsgeschwindigkeit fÃ¼r neuronale Netze drastisch erhÃ¶ht, wodurch wir die ProduktivitÃ¤t unserer Forschung steigern und signifikante Erfolge erzielen konnten." <br><br>  Eine der ersten Lasten fÃ¼r CS-1 wird eine <a href="https://arxiv.org/abs/1903.01998">neuronale Netzwerksimulation einer Kollision von Schwarzen LÃ¶chern</a> und Gravitationswellen sein, die als Ergebnis dieser Kollision erzeugt werden.  Die vorherige Version dieser Aufgabe arbeitete an 1024 von 4392 Knoten des <a href="https://www.alcf.anl.gov/theta">Theta-</a> Supercomputers. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de476706/">https://habr.com/ru/post/de476706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de476696/index.html">Erstellen und Bereitstellen einer Full-Stack-React-Anwendung</a></li>
<li><a href="../de476698/index.html">So tÃ¶tet Apple Webtechnologien</a></li>
<li><a href="../de476700/index.html">Mes bei der Herstellung von StahlheizkÃ¶rpern</a></li>
<li><a href="../de476702/index.html">Wie aus einer Kleinstadt im Outback ein internationaler E-Commerce-Hub wurde</a></li>
<li><a href="../de476704/index.html">So automatisieren Sie das Layout von E-Mails mit denselben Elementen: Wir verwenden intelligente Objekte</a></li>
<li><a href="../de476708/index.html">Slurm Basic in Moskau. Tag drei Die Sammlung der Spionageabwehr und des Clusters, fliegende Pavel Selivanov und "Slurm Inspires!"</a></li>
<li><a href="../de476710/index.html">Registrierung offen: Deep Dive to IT at Mars</a></li>
<li><a href="../de476712/index.html">Service fÃ¼r zufÃ¤llige Treffen mit Fremden, aber nicht aus. ZufÃ¤lliger Kaffee-Startverlauf</a></li>
<li><a href="../de476714/index.html">Operation des maschinellen Lernens in Mail.ru Mail</a></li>
<li><a href="../de476718/index.html">Geschichte eines nationalen Radios: Mussolini von Rural Radio und Joseph Goebbels warme Lampen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
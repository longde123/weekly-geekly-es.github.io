<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐃 👩🏽‍🤝‍👨🏾 🎀 Cerebras Systems stellte einen Computer mit dem weltweit größten Prozessor 22 × 22 Zentimeter vor 🎊 🤲🏼 🌅</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das CS-1-Computerdiagramm zeigt, dass das meiste der Stromversorgung und Kühlung der riesigen Wafer-Scale-Engine (WSE) auf der Platte gewidmet ist. Fo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cerebras Systems stellte einen Computer mit dem weltweit größten Prozessor 22 × 22 Zentimeter vor</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dcmiran/blog/476706/"><img src="https://habrastorage.org/getpro/habr/post_images/43e/87f/2b3/43e87f2b3b76001e51387e09935558ba.jpg"><br>  <i><font color="gray">Das CS-1-Computerdiagramm zeigt, dass das meiste der Stromversorgung und Kühlung der riesigen Wafer-Scale-Engine (WSE) auf der Platte gewidmet ist.</font></i>  <i><font color="gray">Foto: Cerebras-Systeme</font></i> <br><br>  Im August 2019 gaben Cerebras Systems und sein Herstellungspartner TSMC den <a href="https://habr.com/ru/news/t/464271/">größten Chip in der Geschichte der Computertechnologie bekannt</a> .  Mit einer Fläche von 46.225 mm² und 1,2 Billionen Transistoren ist der WSE-Chip (Wafer Scale Engine) ungefähr 56,7-mal größer als die größte GPU (21,1 Milliarden Transistoren, 815 mm²). <br><br>  Skeptiker sagten, dass die Entwicklung eines Prozessors nicht die schwierigste Aufgabe sei.  Aber wie funktioniert das in einem echten Computer?  Wie hoch ist der Prozentsatz fehlerhafter Arbeiten?  Welche Leistung und Kühlung wird benötigt?  Wie viel kostet eine solche Maschine? <br><br>  Es scheint, dass die Ingenieure von Cerebras Systems und TSMC diese Probleme lösen konnten.  Am 18. November 2019 stellten sie auf der <a href="https://sc19.supercomputing.org/">Supercomputing-</a> Konferenz <a href="https://sc19.supercomputing.org/">2019</a> offiziell den <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">CS-1 vor</a> , "den weltweit schnellsten Computer für das Rechnen auf dem Gebiet des maschinellen Lernens und der künstlichen Intelligenz". <br><a name="habracut"></a><br>  Die ersten Exemplare von CS-1 wurden bereits an Kunden gesendet.  Eine davon wird im Argonne National Laboratory des US-Energieministeriums installiert, in dem mit der Montage des leistungsstärksten Supercomputers der USA aus <a href="https://habr.com/ru/company/dcmiran/blog/476378/">Aurora-Modulen auf der neuen Intel-GPU-Architektur</a> begonnen wird.  Ein weiterer Kunde war das Livermore National Laboratory. <br><br>  Der Prozessor mit 400.000 Kernen ist für Rechenzentren zur Verarbeitung von Daten im Bereich des maschinellen Lernens und der künstlichen Intelligenz ausgelegt.  Cerebras behauptet, dass der Computer KI-Systeme um Größenordnungen effizienter trainiert als vorhandene Geräte.  Leistung CS-1 entspricht „Hunderten von GPU-basierten Servern“, die Hunderte von Kilowatt verbrauchen.  Gleichzeitig belegt es nur 15 Einheiten im Server-Rack und verbraucht etwa 17 kW. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cfc/5aa/1da/cfc5aa1da0e52944fc1b68e4fca15146.jpg"><br>  <i><font color="gray">WSE-Prozessor.</font></i>  <i><font color="gray">Foto: Cerebras-Systeme</font></i> <br><br>  Andrew Feldman, CEO und Mitbegründer von Cerebras Systems, sagt, der CS-1 sei "der schnellste KI-Computer der Welt".  Er verglich es mit Googles TPU-Clustern und stellte fest, dass jeder von ihnen „10 Racks benötigt und mehr als 100 Kilowatt verbraucht, um ein Drittel der Leistung einer einzelnen CS-1-Installation zu erbringen“. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/523/1d3/b60/5231d3b60c445d641bb654d29b8fec21.jpg"><br>  <i><font color="gray">Computer CS-1.</font></i>  <i><font color="gray">Foto: Cerebras-Systeme</font></i> <br><br>  Das Erlernen großer neuronaler Netze kann auf einem Standardcomputer Wochen dauern.  Die Installation eines CS-1 mit einem Prozessorchip mit 400.000 Kernen und 1,2 Billionen Transistoren erledigt diese Aufgabe in Minuten oder sogar Sekunden, <a href="https://spectrum.ieee.org/tech-talk/computing/hardware/cerebras-unveils-ai-supercomputer-argonne-national-lab-first-installation">schreibt</a> IEEE Spectrum.  Cerebras lieferte jedoch keine echten Testergebnisse zum Testen von Hochleistungsaussagen wie <a href="https://mlperf.org/training-results-0-6">MLPerf-Tests</a> .  Stattdessen knüpfte das Unternehmen direkt Kontakte zu potenziellen Kunden - und durfte eigene Modelle neuronaler Netze auf CS-1 trainieren. <br><br>  Dieser Ansatz ist nicht ungewöhnlich, sagen Analysten: „Jeder verwaltet seine eigenen Modelle, die er für sein eigenes Unternehmen entwickelt hat“, sagte <a href="http://www.moorinsightsstrategy.com/karl-freund-biography/">Karl Freund</a> , Analyst für künstliche Intelligenz bei Moor Insights &amp; Strategies.  "Dies ist das einzige, was für Kunden wichtig ist." <br><br>  Viele Unternehmen entwickeln spezielle Chips für KI, darunter Vertreter der traditionellen Industrie wie Intel, Qualcomm sowie verschiedene Startups in den USA, Großbritannien und China.  Google hat einen Chip speziell für neuronale Netze entwickelt - einen Tensor-Prozessor oder TPU.  Mehrere andere Hersteller folgten diesem Beispiel.  KI-Systeme arbeiten im Multithread-Modus, und der Engpass verschiebt Daten zwischen den Chips: „Das Anschließen der Chips verlangsamt sie tatsächlich und erfordert viel Energie“, <a href="https://www.nytimes.com/2019/08/19/technology/artificial-intelligence-chip-cerebras.html">erklärt</a> Subramanian Iyer, Professor an der University of California in Los Angeles, der sich darauf spezialisiert hat Entwicklung von Chips für künstliche Intelligenz.  Gerätehersteller prüfen viele verschiedene Optionen.  Einige versuchen, Interprozessverbindungen zu erweitern. <br><br>  Das vor drei Jahren gegründete Unternehmen Cerebras, das mehr als 200 Millionen US-Dollar an Risikofinanzierungen erhalten hat, hat einen neuen Ansatz vorgeschlagen.  Die Idee ist, alle Daten auf einem riesigen Chip zu speichern - und damit die Berechnungen zu beschleunigen. <br><br><img src="https://habrastorage.org/webt/up/k1/ej/upk1ejv8zsqxtj9nadanm8898zc.jpeg"><br><br>  Die gesamte Mikroschaltungsplatte ist in 400.000 kleinere Abschnitte (Kerne) unterteilt, da einige davon nicht funktionieren.  Der Chip ist so konstruiert, dass er fehlerhafte Bereiche umfahren kann.  Programmierbare SLAC-Kerne (Sparse Linear Algebra Cores) sind für lineare Algebra, dh für Berechnungen im Vektorraum, optimiert.  Das Unternehmen hat auch die Sparsity Harvesting-Technologie entwickelt, um die Rechenleistung unter spärlichen Workloads (mit Nullen) wie Deep Learning zu verbessern.  Vektoren und Matrizen im Vektorraum enthalten normalerweise viele Nullelemente (von 50% bis 98%), sodass bei herkömmlichen GPUs der größte Teil der Berechnung verschwendet wird.  Im Gegensatz dazu filtern SLAC-Kerne Nulldaten vor. <br><br>  Die Kommunikation zwischen den Kernen wird vom Swarm-System mit einem Durchsatz von 100 Petabits pro Sekunde bereitgestellt.  Hardware-Routing, Latenz gemessen in Nanosekunden. <br><br>  Die Kosten für einen Computer werden nicht genannt.  Unabhängige Experten glauben, dass der tatsächliche Preis vom Prozentsatz der Ehe abhängt.  Außerdem sind die Leistung des Chips und die Anzahl der in realen Proben betriebenen Kerne nicht zuverlässig bekannt. <br><br><h1>  Software </h1><br>  Cerebras hat einige Details zum Softwareteil des CS-1-Systems bekannt gegeben.  Mit der Software können Benutzer ihre eigenen Modelle für maschinelles Lernen mit Standard-Frameworks wie <a href="https://pytorch.org/">PyTorch</a> und <a href="https://www.tensorflow.org/">TensorFlow</a> <a href="https://pytorch.org/">erstellen</a> .  Das System verteilt dann 400.000 Kerne und 18 Gigabyte SRAM-Speicher auf dem Chip auf die Schichten des neuronalen Netzwerks, so dass alle Schichten ihre Arbeit ungefähr zur gleichen Zeit wie ihre Nachbarn abschließen (Optimierungsaufgabe).  Infolgedessen werden Informationen von allen Schichten ohne Verzögerung verarbeitet.  Mit einem 100-Gigabit-Ethernet-E / A-Subsystem mit 12 Ports kann der CS-1 1,2 Terabit Daten pro Sekunde verarbeiten. <br><br>  Die Konvertierung des neuronalen Quellnetzwerks in eine optimierte ausführbare Darstellung (Cerebras Linear Algebra Intermediate Representation, CLAIR) erfolgt durch den Cerebras Graph Compiler (CGC).  Der Compiler weist jedem Teil des Diagramms Rechenressourcen und Speicher zu und vergleicht sie dann mit dem Rechenarray.  Dann wird der Kommunikationspfad gemäß der internen Struktur der Platte berechnet, die für jedes Netzwerk eindeutig ist. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/098/093/569/098093569a8dca7e8dea9e26fc63a81a.jpg"><br>  <i><font color="gray">Verteilung der mathematischen Operationen eines neuronalen Netzwerks durch Prozessorkerne.</font></i>  <i><font color="gray"><a href="https://fortune.com/2019/11/19/artificial-intelligence-cerebras-supercomputer/">Foto</a> : Großhirn</font></i> <br><br>  Aufgrund der enormen Größe von WSE befinden sich alle Schichten in einem neuronalen Netzwerk gleichzeitig darauf und arbeiten parallel.  Dieser Ansatz ist einzigartig für WSE - laut Cerebras verfügt kein anderes Gerät über genügend internen Speicher, um alle Schichten auf einem Chip gleichzeitig zu speichern.  Eine solche Architektur mit der Platzierung des gesamten neuronalen Netzwerks auf einem Chip bietet aufgrund des hohen Durchsatzes und der geringen Latenz große Vorteile. <br><br>  Die Software kann die Optimierungsaufgabe für mehrere Computer ausführen, sodass der Computercluster als eine große Maschine fungieren kann.  Ein Cluster von 32 CS-1-Computern weist eine etwa 32-fache Leistungssteigerung auf, was auf eine sehr gute Skalierbarkeit hinweist.  Laut Feldman unterscheidet sich dies von GPU-basierten Clustern: „Heute verhält sich ein GPU-Cluster nicht mehr wie ein einziger großer Computer.  Du bekommst viele kleine Autos. “ <br><br>  In der <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">Pressemitteilung</a> heißt es, dass das Argonne National Laboratory seit zwei Jahren mit Cerebras zusammenarbeitet: "Durch den Einsatz von CS-1 haben wir die Trainingsgeschwindigkeit für neuronale Netze drastisch erhöht, wodurch wir die Produktivität unserer Forschung steigern und signifikante Erfolge erzielen konnten." <br><br>  Eine der ersten Lasten für CS-1 wird eine <a href="https://arxiv.org/abs/1903.01998">neuronale Netzwerksimulation einer Kollision von Schwarzen Löchern</a> und Gravitationswellen sein, die als Ergebnis dieser Kollision erzeugt werden.  Die vorherige Version dieser Aufgabe arbeitete an 1024 von 4392 Knoten des <a href="https://www.alcf.anl.gov/theta">Theta-</a> Supercomputers. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de476706/">https://habr.com/ru/post/de476706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de476696/index.html">Erstellen und Bereitstellen einer Full-Stack-React-Anwendung</a></li>
<li><a href="../de476698/index.html">So tötet Apple Webtechnologien</a></li>
<li><a href="../de476700/index.html">Mes bei der Herstellung von Stahlheizkörpern</a></li>
<li><a href="../de476702/index.html">Wie aus einer Kleinstadt im Outback ein internationaler E-Commerce-Hub wurde</a></li>
<li><a href="../de476704/index.html">So automatisieren Sie das Layout von E-Mails mit denselben Elementen: Wir verwenden intelligente Objekte</a></li>
<li><a href="../de476708/index.html">Slurm Basic in Moskau. Tag drei Die Sammlung der Spionageabwehr und des Clusters, fliegende Pavel Selivanov und "Slurm Inspires!"</a></li>
<li><a href="../de476710/index.html">Registrierung offen: Deep Dive to IT at Mars</a></li>
<li><a href="../de476712/index.html">Service für zufällige Treffen mit Fremden, aber nicht aus. Zufälliger Kaffee-Startverlauf</a></li>
<li><a href="../de476714/index.html">Operation des maschinellen Lernens in Mail.ru Mail</a></li>
<li><a href="../de476718/index.html">Geschichte eines nationalen Radios: Mussolini von Rural Radio und Joseph Goebbels warme Lampen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßîüèæ üíΩ üéΩ D√©bogage des retards r√©seau dans Kubernetes üëó ü§≤üèª üåÑ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a quelques ann√©es, Kubernetes a d√©j√† √©t√© discut√© sur le blog officiel de GitHub. Depuis lors, il est devenu la technologie standard pour le d√©plo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>D√©bogage des retards r√©seau dans Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/477390/"><img src="https://habrastorage.org/getpro/habr/post_images/c82/5b1/413/c825b1413d9c59cf78c51e6e2c8f8049.png"><br><br>  Il y a quelques ann√©es, Kubernetes a <a href="https://github.blog/2017-08-16-kubernetes-at-github/">d√©j√†</a> √©t√© <a href="https://github.blog/2017-08-16-kubernetes-at-github/">discut√©</a> sur le blog officiel de GitHub.  Depuis lors, il est devenu la technologie standard pour le d√©ploiement de services.  Kubernetes g√®re d√©sormais une partie importante des services internes et publics.  Au fur et √† mesure que nos clusters se sont d√©velopp√©s et que les exigences de performances sont devenues plus strictes, nous avons commenc√© √† remarquer que certains services sur Kubernetes affichent sporadiquement des retards qui ne peuvent √™tre expliqu√©s par la charge de l'application elle-m√™me. <br><br>  En fait, dans les applications, un retard de r√©seau al√©atoire allant jusqu'√† 100 ms ou plus se produit, ce qui entra√Æne des d√©lais d'attente ou des tentatives.  Il √©tait pr√©vu que les services seraient en mesure de r√©pondre aux demandes beaucoup plus rapidement que 100 ms.  Mais cela n'est pas possible si la connexion elle-m√™me prend autant de temps.  S√©par√©ment, nous avons observ√© des requ√™tes MySQL tr√®s rapides, qui devaient prendre des millisecondes, et MySQL vraiment g√©r√© en millisecondes, mais du point de vue de l'application demandeuse, la r√©ponse a pris 100 ms ou plus. <br><a name="habracut"></a><br>  Il est imm√©diatement devenu clair que le probl√®me se produit uniquement lors de la connexion √† l'h√¥te Kubernetes, m√™me si l'appel provenait de l'ext√©rieur de Kubernetes.  Le moyen le plus simple de reproduire le probl√®me est le test <a href="https://github.com/tsenart/vegeta">Vegeta</a> , qui s'ex√©cute √† partir de n'importe quel h√¥te interne, teste le service Kubernetes sur un port sp√©cifique et enregistre sporadiquement un d√©lai important.  Dans cet article, nous verrons comment nous avons r√©ussi √† rechercher la cause de ce probl√®me. <br><br><h1>  √âlimine la complexit√© inutile de la cha√Æne de d√©faillance </h1><br>  Apr√®s avoir reproduit le m√™me exemple, nous avons voulu affiner le centre du probl√®me et supprimer les couches suppl√©mentaires de complexit√©.  Au d√©part, il y avait trop d'√©l√©ments dans le ruisseau entre Vegeta et les gousses sur Kubernetes.  Pour identifier un probl√®me de r√©seau plus profond, vous devez en exclure certains. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/488/8c1/d29/4888c1d29a8fc1b4a1194c4c3a14c9ff.png"><br><br>  Le client (Vegeta) cr√©e une connexion TCP avec n'importe quel n≈ìud du cluster.  Kubernetes agit comme un r√©seau de superposition (au-dessus du r√©seau de centre de donn√©es existant) qui utilise <a href="https://en.wikipedia.org/wiki/IP_in_IP">IPIP</a> , c'est-√†-dire qui encapsule les paquets IP du r√©seau de superposition √† l'int√©rieur des paquets IP du centre de donn√©es.  Lorsqu'il est connect√© au premier n≈ìud, la <a href="https://en.wikipedia.org/wiki/Network_address_translation">traduction d'</a> adresse r√©seau NAT ( <a href="https://en.wikipedia.org/wiki/Network_address_translation">Network Address Translation</a> ) est effectu√©e avec une surveillance d'√©tat pour convertir l'adresse IP et le port de l'h√¥te Kubernetes en adresse IP et port sur le r√©seau de superposition (en particulier, le pod avec l'application).  Pour les paquets re√ßus, la s√©quence inverse est effectu√©e.  Il s'agit d'un syst√®me complexe avec de nombreux √©tats et de nombreux √©l√©ments qui sont constamment mis √† jour et modifi√©s au fur et √† mesure du d√©ploiement et du d√©placement des services. <br><br>  L'utilitaire <code>tcpdump</code> dans le test Vegeta donne un d√©lai pendant la n√©gociation TCP (entre SYN et SYN-ACK).  Pour supprimer cette complexit√© inutile, vous pouvez utiliser <code>hping3</code> pour de simples ¬´pings¬ª avec les packages SYN.  V√©rifiez s'il y a un retard dans le paquet de r√©ponse, puis r√©initialisez la connexion.  Nous pouvons filtrer les donn√©es en n'incluant que les paquets de plus de 100 ms, et obtenir une option plus simple pour reproduire le probl√®me que le test complet du r√©seau de niveau 7 dans Vegeta.  Voici les ¬´pings¬ª de l'h√¥te Kubernetes utilisant TCP SYN / SYN-ACK sur le ¬´port¬ª h√¥te du service (30927) avec un intervalle de 10 ms, filtr√© par les r√©ponses les plus lentes: <br><br> <code>theojulienne@shell ~ $ sudo hping3 172.16.47.27 -S -p 30927 -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1485 win=29200 rtt=127.1 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1486 win=29200 rtt=117.0 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1487 win=29200 rtt=106.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=1488 win=29200 rtt=104.1 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=5024 win=29200 rtt=109.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=59 DF id=0 sport=30927 flags=SA seq=5231 win=29200 rtt=109.2 ms</code> <br> <br>  Peut imm√©diatement faire la premi√®re observation.  Les num√©ros de s√©rie et les horaires montrent qu'il ne s'agit pas d'une congestion ponctuelle.  Le retard s'accumule souvent et est finalement trait√©. <br><br>  Ensuite, nous voulons savoir quels composants peuvent √™tre impliqu√©s dans l'apparition de congestion.  Peut-√™tre que ce sont quelques-unes des centaines de r√®gles iptables en NAT?  Ou quelques probl√®mes avec le tunnel IPIP sur le r√©seau?  Une fa√ßon de le v√©rifier consiste √† v√©rifier chaque √©tape du syst√®me en l'excluant.  Que se passe-t-il si vous supprimez la logique NAT et pare-feu, ne laissant qu'une partie de IPIP: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5b3/e2a/cff/5b3e2acff2ef9f1f8c7c527356741d92.png"><br><br>  Heureusement, Linux facilite l'acc√®s direct √† la couche de superposition IP si la machine est sur le m√™me r√©seau: <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 10.125.20.64 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7346 win=0 rtt=127.3 ms <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7347 win=0 rtt=117.3 ms <br> <br> len=40 ip=10.125.20.64 ttl=64 DF id=0 sport=0 flags=RA seq=7348 win=0 rtt=107.2 ms</code> <br> <br>  A en juger par les r√©sultats, le probl√®me persiste!  Cela exclut iptables et NAT.  Le probl√®me est donc dans TCP?  Voyons comment va le ping ICMP: <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 10.125.20.64 --icmp -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=28 ip=10.125.20.64 ttl=64 id=42594 icmp_seq=104 rtt=110.0 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49448 icmp_seq=4022 rtt=141.3 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49449 icmp_seq=4023 rtt=131.3 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49450 icmp_seq=4024 rtt=121.2 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49451 icmp_seq=4025 rtt=111.2 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=49452 icmp_seq=4026 rtt=101.1 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50023 icmp_seq=4343 rtt=126.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50024 icmp_seq=4344 rtt=116.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=50025 icmp_seq=4345 rtt=106.8 ms <br> <br> len=28 ip=10.125.20.64 ttl=64 id=59727 icmp_seq=9836 rtt=106.1 ms</code> <br> <br>  Les r√©sultats montrent que le probl√®me n'a pas disparu.  C'est peut-√™tre un tunnel IPIP?  Simplifions le test: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/267/ff6/137/267ff613754b99f8cc1bb1d89119206e.png"><br><br>  Tous les paquets sont-ils envoy√©s entre ces deux h√¥tes? <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 172.16.47.27 --icmp -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41127 icmp_seq=12564 rtt=140.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41128 icmp_seq=12565 rtt=130.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41129 icmp_seq=12566 rtt=120.8 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41130 icmp_seq=12567 rtt=110.8 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=41131 icmp_seq=12568 rtt=100.7 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9062 icmp_seq=31443 rtt=134.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9063 icmp_seq=31444 rtt=124.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9064 icmp_seq=31445 rtt=114.2 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 id=9065 icmp_seq=31446 rtt=104.2 ms</code> <br> <br>  Nous avons simplifi√© la situation pour que deux h√¥tes Kubernetes s'envoient n'importe quel paquet, m√™me un ping ICMP.  Ils voient toujours un retard si l'h√¥te cible est ¬´mauvais¬ª (certains pires que d'autres). <br><br>  Maintenant, la derni√®re question: pourquoi le retard ne se produit-il que sur les serveurs de n≈ìuds de kube?  Et cela se produit-il lorsque le noeud kube est l'exp√©diteur ou le destinataire?  Heureusement, cela est √©galement assez facile √† comprendre en envoyant un paquet √† partir d'un h√¥te en dehors de Kubernetes, mais avec le m√™me destinataire "mauvais connu".  Comme vous pouvez le constater, le probl√®me n'a pas disparu: <br><br> <code>theojulienne@shell ~ $ sudo hping3 172.16.47.27 -p 9876 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=312 win=0 rtt=108.5 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=5903 win=0 rtt=119.4 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=6227 win=0 rtt=139.9 ms <br> <br> len=46 ip=172.16.47.27 ttl=61 DF id=0 sport=9876 flags=RA seq=7929 win=0 rtt=131.2 ms</code> <br> <br>  Ensuite, nous effectuons les m√™mes requ√™tes depuis le n≈ìud kube source pr√©c√©dent vers l'h√¥te externe (ce qui exclut l'h√¥te d'origine, car le ping inclut √† la fois les composants RX et TX): <br><br> <code>theojulienne@kube-node-client ~ $ sudo hping3 172.16.33.44 -p 9876 -S -i u10000 | egrep --line-buffered 'rtt=[0-9]{3}\.' <br> ^C <br> --- 172.16.33.44 hping statistic --- <br> 22352 packets transmitted, 22350 packets received, 1% packet loss <br> round-trip min/avg/max = 0.2/7.6/1010.6 ms</code> <br> <br>  Apr√®s avoir examin√© les captures de paquets retard√©es, nous avons obtenu des informations suppl√©mentaires.  En particulier, que l'exp√©diteur (ci-dessous) voit ce d√©lai, mais le r√©cepteur (ci-dessus) ne le voit pas - voir la colonne Delta (en secondes): <br><br> <a href=""><img src="https://habrastorage.org/webt/4m/-t/dj/4m-tdjzws9lrhnva3xcxijel7eg.png"></a> <br><br>  De plus, si vous regardez la diff√©rence dans l'ordre des paquets TCP et ICMP (par num√©ros de s√©quence) du c√¥t√© destinataire, les paquets ICMP arrivent toujours dans la m√™me s√©quence dans laquelle ils ont √©t√© envoy√©s, mais avec un timing diff√©rent.  Dans le m√™me temps, les paquets TCP alternent parfois et certains d'entre eux sont bloqu√©s.  En particulier, si nous examinons les ports des paquets SYN, du c√¥t√© √©metteur, ils vont dans l'ordre, mais pas du c√¥t√© destinataire. <br><br>  Il existe une diff√©rence subtile dans la fa√ßon dont <a href="https://en.wikipedia.org/wiki/Network_address_translation">les cartes r√©seau des</a> serveurs modernes (comme dans notre centre de donn√©es) traitent les paquets contenant TCP ou ICMP.  Lorsqu'un paquet arrive, l'adaptateur r√©seau ¬´le hache sur la connexion¬ª, c'est-√†-dire qu'il essaie de rompre les connexions √† tour de r√¥le et d'envoyer chaque file d'attente √† un c≈ìur de processeur distinct.  Pour TCP, ce hachage comprend √† la fois l'adresse IP source et de destination et le port.  En d'autres termes, chaque connexion est hach√©e (potentiellement) diff√©remment.  Pour ICMP, seules les adresses IP sont hach√©es, car il n'y a pas de ports. <br><br>  Autre nouvelle observation: pendant cette p√©riode, nous constatons des retards ICMP sur toutes les communications entre les deux h√¥tes, mais pas TCP.  Cela nous indique que la raison est probablement due au hachage des files d'attente RX: il est presque certain que l'encombrement se produit dans le traitement des paquets RX, plut√¥t que dans l'envoi de r√©ponses. <br><br>  Cela exclut l'envoi de paquets de la liste des raisons possibles.  Nous savons maintenant que le probl√®me du traitement des paquets est du c√¥t√© de la r√©ception sur certains serveurs de n≈ìuds de kube. <br><br><h1>  Comprendre le traitement des packages dans le noyau Linux </h1><br>  Pour comprendre pourquoi le probl√®me se produit avec le destinataire sur certains serveurs de n≈ìuds de cube, voyons comment le noyau Linux g√®re les packages. <br><br>  Revenant √† l'impl√©mentation traditionnelle la plus simple, la carte r√©seau re√ßoit le paquet et envoie une <a href="https://en.wikipedia.org/wiki/Interrupt">interruption</a> au noyau Linux, qui est le paquet qui doit √™tre trait√©.  Le noyau arr√™te une autre op√©ration, bascule le contexte vers le gestionnaire d'interruption, traite le package, puis revient aux t√¢ches en cours. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1a2/3c3/4ee/1a23c34eea2236294913fd09a25aa1e4.png"><br><br>  Ce changement de contexte est lent: il n'√©tait peut-√™tre pas perceptible sur les cartes r√©seau de 10 m√©gaoctets dans les ann√©es 1990, mais sur les cartes 10G modernes avec un d√©bit maximal de 15 millions de paquets par seconde, chaque c≈ìur d'un petit serveur √† huit c≈ìurs peut √™tre interrompu des millions de fois par seconde. <br><br>  Afin de ne pas g√©rer constamment la gestion des interruptions, Linux a ajout√© il y a de nombreuses ann√©es <a href="https://en.wikipedia.org/wiki/New_API">NAPI</a> : une API r√©seau que tous les pilotes modernes utilisent pour augmenter les performances √† des vitesses √©lev√©es.  √Ä basse vitesse, le noyau accepte toujours les interruptions de la carte r√©seau √† l'ancienne.  D√®s qu'un nombre suffisant de paquets arrive et d√©passe le seuil, le noyau d√©sactive les interruptions et commence √† interroger la carte r√©seau et √† prendre des paquets par lots.  Le traitement est effectu√© dans softirq, c'est-√†-dire dans le <a href="https://www.kernel.org/doc/htmldocs/kernel-hacking/basics-softirqs.html">contexte des interruptions logicielles</a> apr√®s les appels syst√®me et des interruptions mat√©rielles lorsque le noyau (contrairement √† l'espace utilisateur) est d√©j√† en cours d'ex√©cution. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/22a/50d/ee1/22a50dee1fffdbc20614db2b1db28fc4.png"><br><br>  C'est beaucoup plus rapide, mais cause un probl√®me diff√©rent.  S'il y a trop de paquets, tout le temps qu'il faut pour traiter les paquets de la carte r√©seau et les processus de l'espace utilisateur n'ont pas le temps de vider r√©ellement ces files d'attente (lecture √† partir des connexions TCP, etc.).  √Ä la fin, les files d'attente se remplissent et nous commen√ßons √† abandonner les paquets.  En essayant de trouver un √©quilibre, le noyau √©tablit un budget pour le nombre maximum de paquets trait√©s dans le contexte softirq.  Une fois ce budget d√©pass√©, un thread <code>ksoftirqd</code> s√©par√© <code>ksoftirqd</code> (vous en verrez un en <code>ps</code> pour chaque c≈ìur), qui traite ces softirqs en dehors du chemin normal de syscall / interruption.  Ce thread est planifi√© √† l'aide d'un planificateur de processus standard qui tente de r√©partir √©quitablement les ressources. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d0f/1e6/f0c/d0f1e6f0c54d45c24d62cb2bcf90c674.png"><br><br>  Apr√®s avoir examin√© comment le noyau traite les paquets, vous pouvez voir qu'il existe une certaine probabilit√© de congestion.  Si les appels softirq sont re√ßus moins fr√©quemment, les paquets devront attendre un certain temps avant d'√™tre trait√©s dans la file d'attente RX de la carte r√©seau.  Cela est peut-√™tre d√ª √† une t√¢che bloquant le c≈ìur du processeur, ou quelque chose d'autre emp√™che le noyau de d√©marrer softirq. <br><br><h1>  Nous limitons le traitement au noyau ou √† la m√©thode </h1><br>  Les retards Softirq ne sont qu'une hypoth√®se.  Mais cela a du sens et nous savons que nous voyons quelque chose de tr√®s similaire.  Par cons√©quent, l'√©tape suivante consiste √† confirmer cette th√©orie.  Et si cela est confirm√©, trouvez la raison des retards. <br><br>  Retour √† nos packages lents: <br><br> <code>len=46 ip=172.16.53.32 ttl=61 id=29573 icmp_seq=1953 rtt=99.3 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29574 icmp_seq=1954 rtt=89.3 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29575 icmp_seq=1955 rtt=79.2 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29576 icmp_seq=1956 rtt=69.1 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29577 icmp_seq=1957 rtt=59.1 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29790 icmp_seq=2070 rtt=75.7 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29791 icmp_seq=2071 rtt=65.6 ms <br> <br> len=46 ip=172.16.53.32 ttl=61 id=29792 icmp_seq=2072 rtt=55.5 ms</code> <br> <br>  Comme indiqu√© pr√©c√©demment, ces paquets ICMP sont hach√©s dans une seule file d'attente NIC RX et trait√©s par un seul c≈ìur de processeur.  Si nous voulons comprendre comment fonctionne Linux, il est utile de savoir o√π (sur quel c≈ìur de processeur) et comment (softirq, ksoftirqd) ces packages sont trait√©s pour suivre le processus. <br><br>  Il est maintenant temps d'utiliser des outils qui permettent une surveillance en temps r√©el du noyau Linux.  Ici, nous avons utilis√© <a href="https://github.com/iovisor/bcc">bcc</a> .  Cette bo√Æte √† outils vous permet d'√©crire de petits programmes C qui interceptent des fonctions arbitraires dans le noyau et les √©v√©nements de tampon dans un programme Python de l'espace utilisateur qui peut les traiter et vous renvoyer le r√©sultat.  Les crochets pour les fonctions arbitraires dans le noyau sont complexes, mais l'utilitaire est con√ßu pour une s√©curit√© maximale et est con√ßu pour suivre pr√©cis√©ment ces probl√®mes de production qui ne sont pas faciles √† reproduire dans un environnement de test ou de d√©veloppement. <br><br>  Le plan ici est simple: nous savons que le noyau traite ces pings ICMP, donc nous <a href="">accrochons la fonction de</a> noyau <a href="">icmp_echo</a> , qui re√ßoit le paquet ICMP de demande d'√©cho entrant et initie l'envoi de la r√©ponse ICMP de r√©ponse d'√©cho.  Nous pouvons identifier le package en augmentant le nombre icmp_seq, qui montre <code>hping3</code> ci-dessus. <br><br>  Le code du <a href="https://gist.github.com/theojulienne/9d78a0cb68dbe56f19a2ae6316bc6846">script Cci</a> semble compliqu√©, mais il n'est pas aussi effrayant qu'il n'y para√Æt.  La fonction <code>icmp_echo</code> passe la <code>struct sk_buff *skb</code> : c'est le paquet avec la requ√™te "echo request".  Nous pouvons le suivre, extraire la s√©quence <code>echo.sequence</code> (qui correspond √† <code>icmp_seq</code> partir de hping3 <code></code> ) et l'envoyer √† l'espace utilisateur.  Il est √©galement pratique de capturer le nom / identificateur de processus actuel.  Voici les r√©sultats que nous voyons directement lors du traitement des paquets par le noyau: <br><br><pre>  NOM DU PROCESSUS TGID PID ICMP_SEQ
 0 0 swapper / 11,770
 0 0 swapper / 11,771
 0 0 swapper / 11 772
 0 0 swapper / 11 773
 0 0 swapper / 11,774
 20041 20086 prometheus 775
 0 0 swapper / 11,776
 0 0 swapper / 11,777
 0 0 swapper / 11 778
 4512 4542 rayons-rapport-s 779 </pre><br>  Ici, il convient de noter que dans le contexte de <code>softirq</code> processus qui ont effectu√© des appels syst√®me appara√Ætront comme des ¬´processus¬ª, bien qu'en fait ce noyau traite en toute s√©curit√© les paquets dans le contexte du noyau. <br><br>  Avec cet outil, nous pouvons √©tablir la connexion de processus sp√©cifiques avec des packages sp√©cifiques qui montrent un retard dans <code>hping3</code> .  Nous faisons un simple <code>grep</code> sur cette capture pour des valeurs <code>icmp_seq</code> sp√©cifiques.  Les paquets correspondant aux valeurs icmp_seq ci-dessus ont √©t√© marqu√©s avec leur RTT, que nous avons observ√© ci-dessus (entre parenth√®ses sont les valeurs RTT attendues pour les paquets que nous avons filtr√©s en raison de valeurs RTT inf√©rieures √† 50 ms): <br><br><pre>  NOM DU PROCESSUS TGID PID ICMP_SEQ ** RTT
 -
 10137 10436 cadvisor 1951
 10137 10436 cadvisor 1952
 76 76 ksoftirqd / 11 1953 ** 99ms
 76 76 ksoftirqd / 11 1954 ** 89ms
 76 76 ksoftirqd / 11 1955 ** 79ms
 76 76 ksoftirqd / 11 1956 ** 69ms
 76 76 ksoftirqd / 11 1957 ** 59 ms
 76 76 ksoftirqd / 11 1958 ** (49 ms)
 76 76 ksoftirqd / 11 1959 ** (39 ms)
 76 76 ksoftirqd / 11 1960 ** (29 ms)
 76 76 ksoftirqd / 11 1961 ** (19 ms)
 76 76 ksoftirqd / 11 1962 ** (9 ms)
 -
 10137 10436 cadvisor 2068
 10137 10436 cadvisor 2069
 76 76 ksoftirqd / 11 2070 ** 75 ms
 76 76 ksoftirqd / 11 2071 ** 65ms
 76 76 ksoftirqd / 11 2072 ** 55 ms
 76 76 ksoftirqd / 11 2073 ** (45 ms)
 76 76 ksoftirqd / 11 2074 ** (35 ms)
 76 76 ksoftirqd / 11 2075 ** (25 ms)
 76 76 ksoftirqd / 11 2076 ** (15 ms)
 76 76 ksoftirqd / 11 2077 ** (5 ms) </pre><br>  Les r√©sultats nous disent quelques choses.  Tout d'abord, le contexte <code>ksoftirqd/11</code> g√®re tous ces packages.  Cela signifie que pour cette paire particuli√®re de machines, les paquets ICMP ont √©t√© hach√©s sur le c≈ìur 11 √† la r√©ception.  Nous constatons √©galement qu'√† chaque embouteillage, des paquets sont trait√©s dans le cadre de l' <code>cadvisor</code> syst√®me <code>cadvisor</code> .  Ensuite, <code>ksoftirqd</code> prend la t√¢che et remplit la file d'attente accumul√©e: exactement le nombre de paquets qui se sont accumul√©s apr√®s <code>cadvisor</code> . <br><br>  Le fait qu'un <code>cadvisor</code> travaille toujours juste avant cela implique son implication dans le probl√®me.  Ironiquement, l'objectif de <a href="https://github.com/google/cadvisor">cadvisor</a> est ¬´d'analyser l'utilisation des ressources et les caract√©ristiques de performance des conteneurs en cours d'ex√©cution¬ª, plut√¥t que de causer ce probl√®me de performance. <br><br>  Comme pour d'autres aspects de la manutention des conteneurs, ce sont tous des outils extr√™mement avanc√©s √† partir desquels des probl√®mes de performances peuvent √™tre attendus dans certaines circonstances impr√©vues. <br><br><h1>  Que fait cadvisor pour ralentir la file d'attente des paquets? </h1><br>  Maintenant, nous avons une assez bonne compr√©hension de la fa√ßon dont la panne se produit, quel processus la cause et sur quel processeur.  Nous voyons qu'en raison d'un verrouillage dur, le noyau Linux n'a pas le temps de planifier <code>ksoftirqd</code> .  Et nous voyons que les colis sont trait√©s dans le cadre de <code>cadvisor</code> .  Il est logique de supposer que <code>cadvisor</code> d√©marre un appel syst√®me lent, apr√®s quoi tous les paquets accumul√©s √† ce moment sont trait√©s: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6fd/6fb/970/6fd6fb970f2d27943039910db9b41743.png"><br><br>  C'est une th√©orie, mais comment la tester?  Ce que nous pouvons faire, c'est suivre le fonctionnement du c≈ìur de processeur tout au long de ce processus, trouver le point o√π le budget est d√©pass√© par le nombre de paquets et ksoftirqd est appel√©, puis regarder un peu plus t√¥t - ce qui fonctionnait exactement sur le c≈ìur de processeur juste avant ce moment.  C'est comme une radiographie d'un CPU toutes les quelques millisecondes.  Cela ressemblera √† ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/44a/954/6e8/44a9546e8de19e43cb125eb8a03a8f47.png"><br><br>  Id√©alement, tout cela peut √™tre fait avec les outils existants.  Par exemple, <a href="https://perf.wiki.kernel.org/index.php/Tutorial">perf record</a> v√©rifie le c≈ìur de processeur sp√©cifi√© avec la fr√©quence indiqu√©e et peut g√©n√©rer un calendrier d'appels vers un syst√®me en cours d'ex√©cution, y compris √† la fois l'espace utilisateur et le noyau Linux.  Vous pouvez prendre cet enregistrement et le traiter √† l'aide d'un petit fork du programme <a href="https://github.com/brendangregg/FlameGraph">FlameGraph</a> de Brendan Gregg, qui pr√©serve l'ordre de trace de la pile.  Nous pouvons enregistrer des traces de pile sur une ligne toutes les 1 ms, puis s√©lectionner et enregistrer l'√©chantillon pendant 100 millisecondes avant que <code>ksoftirqd</code> dans la trace: <br><br> <code># record 999 times a second, or every 1ms with some offset so not to align exactly with timers <br> sudo perf record -C 11 -g -F 999 <br> # take that recording and make a simpler stack trace. <br> sudo perf script 2&gt;/dev/null | ./FlameGraph/stackcollapse-perf-ordered.pl | grep ksoftir -B 100</code> <br> <br>  Voici les r√©sultats: <br><br> <code>( ,   ) <br> <br> cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_iter cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages cadvisor;[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];[cadvisor];entry_SYSCALL_64_after_swapgs;do_syscall_64;sys_read;vfs_read;seq_read;memcg_stat_show;mem_cgroup_nr_lru_pages;mem_cgroup_node_nr_lru_pages ksoftirqd/11;ret_from_fork;kthread;kthread;smpboot_thread_fn;smpboot_thread_fn;run_ksoftirqd;__do_softirq;net_rx_action;ixgbe_poll;ixgbe_clean_rx_irq;napi_gro_receive;netif_receive_skb_internal;inet_gro_receive;bond_handle_frame;__netif_receive_skb_core;ip_rcv_finish;ip_rcv;ip_forward_finish;ip_forward;ip_finish_output;nf_iterate;ip_output;ip_finish_output2;__dev_queue_xmit;dev_hard_start_xmit;ipip_tunnel_xmit;ip_tunnel_xmit;iptunnel_xmit;ip_local_out;dst_output;__ip_local_out;nf_hook_slow;nf_iterate;nf_conntrack_in;generic_packet;ipt_do_table;set_match_v4;ip_set_test;hash_net4_kadt;ixgbe_xmit_frame_ring;swiotlb_dma_mapping_error;hash_net4_test ksoftirqd/11;ret_from_fork;kthread;kthread;smpboot_thread_fn;smpboot_thread_fn;run_ksoftirqd;__do_softirq;net_rx_action;gro_cell_poll;napi_gro_receive;netif_receive_skb_internal;inet_gro_receive;__netif_receive_skb_core;ip_rcv_finish;ip_rcv;ip_forward_finish;ip_forward;ip_finish_output;nf_iterate;ip_output;ip_finish_output2;__dev_queue_xmit;dev_hard_start_xmit;dev_queue_xmit_nit;packet_rcv;tpacket_rcv;sch_direct_xmit;validate_xmit_skb_list;validate_xmit_skb;netif_skb_features;ixgbe_xmit_frame_ring;swiotlb_dma_mapping_error;__dev_queue_xmit;dev_hard_start_xmit;__bpf_prog_run;__bpf_prog_run</code> <br> <br>  Il y a beaucoup de choses ici, mais l'essentiel est que nous trouvions le mod√®le ¬´cadvisor avant ksoftirqd¬ª que nous avons vu plus t√¥t dans le traceur ICMP.  Qu'est-ce que cela signifie? <br><br>  Chaque ligne est une trace du CPU √† un moment donn√©.  Chaque appel sur la pile d'une ligne est s√©par√© par un point-virgule.  Au milieu des lignes, nous voyons syscall appel√©: <code>read(): .... ;do_syscall_64;sys_read; ...</code>  <code>read(): .... ;do_syscall_64;sys_read; ...</code>  Ainsi, cadvisor passe beaucoup de temps sur l'appel syst√®me <code>read()</code> li√© aux fonctions <code>mem_cgroup_*</code> (haut de la pile d'appels / fin de ligne). <br><br>  Dans la trace des appels, il n'est pas pratique de voir exactement ce qui est lu, alors ex√©cutez <code>strace</code> et voyez ce que fait cadvisor, et recherchez les appels syst√®me de plus de 100 ms: <br><br> <code>theojulienne@kube-node-bad ~ $ sudo strace -p 10137 -T -ff 2&gt;&amp;1 | egrep '&lt;0\.[1-9]' <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.156784&gt; <br> [pid 10432] &lt;... futex resumed&gt; ) = 0 &lt;0.258285&gt; <br> [pid 10137] &lt;... futex resumed&gt; ) = 0 &lt;0.678382&gt; <br> [pid 10384] &lt;... futex resumed&gt; ) = 0 &lt;0.762328&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 154234880\nrss 507904\nrss_h"..., 4096) = 658 &lt;0.179438&gt; <br> [pid 10384] &lt;... futex resumed&gt; ) = 0 &lt;0.104614&gt; <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.175936&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 577 &lt;0.228091&gt; <br> [pid 10427] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 577 &lt;0.207334&gt; <br> [pid 10411] &lt;... epoll_ctl resumed&gt; ) = 0 &lt;0.118113&gt; <br> [pid 10382] &lt;... pselect6 resumed&gt; ) = 0 (Timeout) &lt;0.117717&gt; <br> [pid 10436] &lt;... read resumed&gt; "cache 154234880\nrss 507904\nrss_h"..., 4096) = 660 &lt;0.159891&gt; <br> [pid 10417] &lt;... futex resumed&gt; ) = 0 &lt;0.917495&gt; <br> [pid 10436] &lt;... futex resumed&gt; ) = 0 &lt;0.208172&gt; <br> [pid 10417] &lt;... futex resumed&gt; ) = 0 &lt;0.190763&gt; <br> [pid 10417] &lt;... read resumed&gt; "cache 0\nrss 0\nrss_huge 0\nmapped_"..., 4096) = 576 &lt;0.154442&gt;</code> <br> <br>  Comme vous pouvez vous y attendre, nous voyons ici des appels <code>read()</code> .  Du contenu des op√©rations de lecture et du contexte <code>mem_cgroup</code> , <code>mem_cgroup</code> peut voir que ces appels <code>read()</code> r√©f√®rent au fichier <code>memory.stat</code> , qui montre l'utilisation de la m√©moire et les limitations de cgroup (technologie d'isolation des ressources Docker).  L'outil cadvisor interroge ce fichier pour obtenir des informations sur l'utilisation des ressources pour les conteneurs.  V√©rifions si ce noyau ou ce conseiller fait quelque chose d'inattendu: <br><br> <code>theojulienne@kube-node-bad ~ $ time cat /sys/fs/cgroup/memory/memory.stat &gt;/dev/null <br> <br> real 0m0.153s <br> user 0m0.000s <br> sys 0m0.152s <br> theojulienne@kube-node-bad ~ $</code> <br> <br>  Nous pouvons maintenant reproduire le bogue et comprendre que le noyau Linux est confront√© √† une pathologie. <br><br><h1>  Qu'est-ce qui rend la lecture si lente? </h1><br>  √Ä ce stade, il est beaucoup plus facile de trouver des messages d'autres utilisateurs sur des probl√®mes similaires.  Il s'est av√©r√© que dans le tracker cadvisor, ce bogue a √©t√© signal√© comme un <a href="https://github.com/google/cadvisor/issues/1774">probl√®me d'utilisation excessive du processeur</a> , personne n'a remarqu√© que le retard √©tait √©galement refl√©t√© de mani√®re al√©atoire dans la pile du r√©seau.  En effet, il a √©t√© remarqu√© que cadvisor consomme plus de temps processeur que pr√©vu, mais cela n'a pas √©t√© accord√© beaucoup d'importance, car nos serveurs ont beaucoup de ressources processeur, nous n'avons donc pas √©tudi√© attentivement le probl√®me. <br><br>  Le probl√®me est que les groupes de contr√¥le (cgroups) prennent en compte l'utilisation de la m√©moire √† l'int√©rieur de l'espace de noms (conteneur).  Lorsque tous les processus de ce groupe de contr√¥le se terminent, Docker lib√®re un groupe de contr√¥le de m√©moire.  Cependant, la ¬´m√©moire¬ª n'est pas seulement une m√©moire de processus.  Bien que la m√©moire de processus elle-m√™me ne soit plus utilis√©e, il s'av√®re que le noyau attribue √©galement du contenu mis en cache, comme des denteries et des inodes (m√©tadonn√©es de r√©pertoire et de fichier), qui sont mis en cache dans le groupe de m√©moire.  D'apr√®s la description du probl√®me: <br><br><blockquote>  cgroups zombies: groupes de contr√¥le dans lesquels il n'y a pas de processus et ils sont supprim√©s, mais pour lesquels la m√©moire est toujours allou√©e (dans mon cas, √† partir du cache dentry, mais elle peut √©galement √™tre allou√©e √† partir du cache de page ou tmpfs). </blockquote><br>  Le noyau v√©rifiant toutes les pages du cache lorsque cgroup est lib√©r√© peut √™tre tr√®s lent, donc le processus paresseux est choisi: attendez que ces pages soient √† nouveau demand√©es, et m√™me lorsque la m√©moire est vraiment n√©cessaire, effacez finalement cgroup.  Jusqu'√† pr√©sent, cgroup est toujours pris en compte lors de la collecte des statistiques. <br><br>  En termes de performances, ils ont sacrifi√© la m√©moire pour les performances: acc√©l√©rant le nettoyage initial en raison du fait qu'il reste un peu de m√©moire en cache.  C'est normal.  Lorsque le noyau utilise la derni√®re partie de la m√©moire cache, cgroup est finalement effac√©, donc cela ne peut pas √™tre appel√© une ¬´fuite¬ª.  Malheureusement, l'impl√©mentation sp√©cifique du moteur de recherche <code>memory.stat</code> dans cette version du noyau (4.9), combin√©e √† l'√©norme quantit√© de m√©moire sur nos serveurs, conduit au fait qu'il faut beaucoup plus de temps pour restaurer les derni√®res donn√©es mises en cache et effacer les zombies de groupe de contr√¥le. <br><br>  Il s'av√®re qu'il y avait tellement de zombies de groupes de contr√¥le sur certains de nos n≈ìuds que la lecture et la latence ont d√©pass√© une seconde. <br><br>  Une solution de contournement pour le probl√®me du conseiller consiste √† effacer imm√©diatement les caches dentiers / inodes dans tout le syst√®me, ce qui √©limine imm√©diatement la latence de lecture ainsi que la latence du r√©seau sur l'h√¥te, car la suppression du cache inclut les pages mises en cache par zombies cgroup, et elles sont √©galement lib√©r√©es.  Ce n'est pas une solution, mais confirme la cause du probl√®me. <br><br>  Il s'est av√©r√© que les versions plus r√©centes du noyau (4.19+) am√©lioraient les performances de l'appel <code>memory.stat</code> , donc le passage √† ce noyau a r√©solu le probl√®me.  Dans le m√™me temps, nous avions des outils pour d√©tecter les n≈ìuds probl√©matiques dans les clusters Kubernetes, les vidanger avec √©l√©gance et red√©marrer.  Nous avons parcouru tous les clusters, trouv√© les n≈ìuds avec un retard suffisamment √©lev√© et les avons red√©marr√©s.  Cela nous a donn√© le temps de mettre √† jour le syst√®me d'exploitation sur le reste des serveurs. <br><br><h1>  Pour r√©sumer </h1><br>  √âtant donn√© que ce bogue a arr√™t√© le traitement des files d'attente NIC RX pendant des centaines de millisecondes, il a simultan√©ment provoqu√© un retard important sur les connexions courtes et un retard au milieu de la connexion, par exemple, entre les requ√™tes MySQL et les paquets de r√©ponse. <br><br>       ,   Kubernetes,            .    Kubernetes    . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr477390/">https://habr.com/ru/post/fr477390/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr477378/index.html">Agile mixte - approche Waterfall lors de la mise en ≈ìuvre d'applications m√©tier (aka Agile-like)</a></li>
<li><a href="../fr477382/index.html">Esports - faire du profit: Mercedes, m√©gaphone, paris et image de marque pour les esports</a></li>
<li><a href="../fr477384/index.html">Conf√©rence ¬´S√©curit√© de l'information. Menaces du pr√©sent et du futur ¬ª</a></li>
<li><a href="../fr477386/index.html">Semaine de s√©curit√© 48: fuite de donn√©es gigantesque et vuln√©rabilit√© dans Whatsapp</a></li>
<li><a href="../fr477388/index.html">NILFS2 - syst√®me de fichiers pare-balles pour / home</a></li>
<li><a href="../fr477392/index.html">Microphone ouvert: backend. Nous invitons des conf√©renciers</a></li>
<li><a href="../fr477396/index.html">Comment s'inscrire √† un cours et ... aller jusqu'au bout</a></li>
<li><a href="../fr477400/index.html">A propos du m√©tier de chef de produit: comment atteindre l'id√©al?</a></li>
<li><a href="../fr477402/index.html">D√©ploiement du mod√®le Keras Deep Learning en tant qu'application Web Python</a></li>
<li><a href="../fr477404/index.html">Le probl√®me de la cr√©ation et de la suppression fr√©quentes d'objets en C ++</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üê§ üßùüèº üë©‚Äçüíª Explorando o OpenCV no StereoPi: Mapa de Profundidade do V√≠deo üçó üëÇüèª ‚èèÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoje, queremos compartilhar uma s√©rie de exemplos sobre os alunos do Python para OpenCV no Raspberry Pi, a saber, a placa StereoPi de duas c√¢maras. O ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Explorando o OpenCV no StereoPi: Mapa de Profundidade do V√≠deo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446872/"><img src="https://habrastorage.org/webt/hb/xt/po/hbxtpox_r6mswlkshq4w3cpovr4.gif"><br><br>  Hoje, queremos compartilhar uma s√©rie de exemplos sobre os alunos do Python para OpenCV no Raspberry Pi, a saber, a placa StereoPi de duas c√¢maras.  O c√≥digo finalizado (mais a imagem Raspbian) ajudar√° voc√™ a executar todas as etapas, come√ßando com a captura de uma imagem e terminando com a obten√ß√£o de um mapa de profundidade do v√≠deo capturado. <br><a name="habracut"></a><br><h3>  Introdut√≥rio </h3><br>  Devo enfatizar imediatamente que esses exemplos s√£o para uma imers√£o confort√°vel no t√≥pico, e n√£o para uma solu√ß√£o de produ√ß√£o.  Se voc√™ √© um usu√°rio avan√ßado do OpenCV e est√° lidando com framboesas, sabe que, para um trabalho completo, √© aconselh√°vel codificar em uma mordida e at√© usar uma GPU de framboesa.  No final do artigo, abordarei os ‚Äúgargalos‚Äù da solu√ß√£o python e o desempenho geral com mais detalhes. <br><br><h3>  Com o que estamos trabalhando </h3><br>  Temos uma configura√ß√£o como o ferro: <br><br><img src="https://habrastorage.org/webt/or/pd/9u/orpd9ufeuctr0lbmsk0kfogroao.jpeg"><br><br>  Placa StereoPi a bordo do Raspberry Pi Compute Module 3+.  As duas c√¢meras mais simples est√£o conectadas √† vers√£o V1 do Raspberry Pi (no sensor ov5647). <br><br>  O que est√° instalado: <br><br><ul><li>  Raspbian Stretch (kernel 4.14.98-v7 +) </li><li>  Python 3.5.3 </li><li>  OpenCV 3.4.4 (pr√©-compilado, 'pip' do Python Wheels) </li><li>  Picamera 1.13 </li><li>  StereoVision lib 1.0.3 (https://github.com/erget/StereoVision) </li></ul><br>  O processo de instala√ß√£o de todo o software est√° al√©m do escopo deste artigo, e apenas sugerimos o download da imagem final do Raspbian (links para o github no final do artigo). <br><br><h3>  Etapa 1: tirar uma foto </h3><br>  Para fazer isso, use o script 1_test.py <br><br>  Abra o console, v√° da pasta inicial para a pasta com exemplos: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> stereopi-tutorial</code> </pre> <br>  Execute o script: <br><br><pre> <code class="bash hljs">python 1_test.py</code> </pre> <br>  Ap√≥s o in√≠cio, uma visualiza√ß√£o da nossa imagem est√©reo √© exibida na tela.  O processo pode ser interrompido pressionando o bot√£o Q. Isso salvar√° a √∫ltima imagem capturada, que ser√° usada em um dos seguintes scripts para configurar o mapa de profundidade. <br><br>  Esse script permite garantir que todo o hardware esteja funcionando corretamente, al√©m de obter a primeira imagem para uso futuro. <br><br>  Aqui est√° a apar√™ncia do primeiro script: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wllLrNUw3SE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Etapa 2: coletar fotos para calibra√ß√£o </h3><br>  Se falamos de um cavalo esf√©rico no v√°cuo, para obter um mapa de profundidade de boa qualidade, precisamos ter duas c√¢meras absolutamente id√™nticas, cujos eixos verticais e √≥pticos s√£o perfeitamente paralelos e os eixos horizontais coincidem.  Mas, no mundo real, todas as c√¢meras s√£o um pouco diferentes e n√£o √© poss√≠vel organiz√°-las perfeitamente.  Portanto, um truque de calibra√ß√£o de software foi inventado.  Usando duas c√¢meras do mundo real, um grande n√∫mero de fotos de um objeto conhecido anteriormente √© tirado (temos uma foto com um tabuleiro de xadrez) e, em seguida, um algoritmo especial calcula todas as ‚Äúimperfei√ß√µes‚Äù e tenta corrigi-las para que fiquem pr√≥ximas do ideal. <br><br>  Este script faz a primeira etapa do trabalho, ou seja, ajuda a tirar uma s√©rie de fotos para calibra√ß√£o. <br><br>  Antes de cada foto, o script inicia uma contagem regressiva de 5 segundos.  Desta vez, como regra, √© suficiente para mover a placa para uma nova posi√ß√£o, para garantir que em ambas as c√¢meras n√£o rasteje pelas bordas e fixe sua posi√ß√£o (para que n√£o haja desfoque na foto).  Por padr√£o, o tamanho da s√©rie √© definido para 30 fotos. <br><br>  Lan√ßamento: <br><br><pre> <code class="bash hljs">python 2_chess_cycle.py</code> </pre> <br>  Processo: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1XCAlU3k-xs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Como resultado, temos uma s√©rie de fotos na pasta / scenes. <br><br><h3>  Cortamos fotos em pares </h3><br>  O terceiro script 3_pairs_cut.py corta as fotos tiradas nas fotos "esquerda" e "direita" e as salva na pasta / pairs.  De fato, poder√≠amos excluir esse script e fazer o corte em tempo real, mas √© muito √∫til em outras experi√™ncias.  Por exemplo, voc√™ pode salvar fatias de s√©ries diferentes, usar seus scripts para trabalhar com esses pares ou at√© mesmo tirar fotos tiradas em outras c√¢meras est√©reo como pares. <br><br>  Al√©m disso, antes de cortar cada imagem, o script exibe sua imagem, o que geralmente permite ver fotos com falha antes da pr√≥xima etapa de calibra√ß√£o e simplesmente exclu√≠-las. <br><br>  Execute o script: <br><br><pre> <code class="bash hljs">python 3_pairs_cut.py</code> </pre> <br>  V√≠deo curto: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/95DWmPECbDc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Na imagem final, h√° um conjunto de fotografias e pares de cortes que usamos em nossos experimentos. <br><br><h3>  Calibra√ß√£o </h3><br>  O script 4_calibration.py desenha todos os pares com os tabuleiros de xadrez e calcula as corre√ß√µes necess√°rias para corrigir as figuras.  No roteiro, foi feita a rejei√ß√£o autom√°tica de fotografias nas quais um tabuleiro de xadrez n√£o foi encontrado, para que, no caso de fotografias malsucedidas, o trabalho n√£o pare.  Ap√≥s o upload de todos os 30 pares de fotos, o c√°lculo √© iniciado.  Demora cerca de um minuto e meio conosco.  Ap√≥s a conclus√£o, o script pega um dos pares est√©reo e, com base nos par√¢metros de calibra√ß√£o calculados, ‚Äúos corrige‚Äù, exibindo uma imagem retificada na tela.  Neste ponto, voc√™ pode avaliar a qualidade da calibra√ß√£o. <br><br>  Executar por comando: <br><br><pre> <code class="bash hljs">python 4_calibration.py</code> </pre> <br>  Script de calibra√ß√£o em funcionamento: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/vtPhu23tKGo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Configura√ß√£o do mapa de profundidade </h3><br>  O script 5_dm_tune.py carrega a foto tirada pelo primeiro script e os resultados da calibra√ß√£o.  Em seguida, √© exibida uma interface que permite alterar as configura√ß√µes do mapa de profundidade e ver o que muda.  Dica: antes de definir os par√¢metros, pegue uma moldura na qual voc√™ ter√° objetos simultaneamente a diferentes dist√¢ncias: perto (30-40 cent√≠metros), a uma dist√¢ncia m√©dia (metros ou dois) e √† dist√¢ncia.  Isso permitir√° que voc√™ escolha os par√¢metros nos quais objetos pr√≥ximos ser√£o vermelhos e objetos distantes ser√£o azul escuro. <br><br>  A imagem cont√©m um arquivo com nossas configura√ß√µes de mapa de profundidade.  Voc√™ pode carregar nossas configura√ß√µes em um script simplesmente clicando no bot√£o "Carregar configura√ß√µes" <br><br>  Lan√ßamos: <br><br><pre> <code class="bash hljs">python 5_dm_tune.py</code> </pre> <br>  Veja como √© o processo de instala√ß√£o: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Z4j3NrMyeGE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Mapa de profundidade em tempo real </h3><br>  O √∫ltimo script 6_dm_video.py cria um mapa de profundidade a partir do v√≠deo usando os resultados de scripts anteriores (calibra√ß√£o e configura√ß√£o do mapa de profundidade). <br><br>  Lan√ßamento: <br><br><pre> <code class="bash hljs">python 6_dm_video.py</code> </pre> <br>  Na verdade o resultado: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/f29arVstfZA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Esperamos que nossos scripts sejam √∫teis em suas experi√™ncias! <br><br>  Por precau√ß√£o, acrescentarei que todos os scripts t√™m processamento de pressionamento de tecla e voc√™ pode interromper o trabalho pressionando o bot√£o Q. Se voc√™ parar "aproximadamente", por exemplo, Ctrl + C, o processo de intera√ß√£o do Python com a c√¢mera poder√° ser interrompido e ser√° necess√°ria uma reinicializa√ß√£o de framboesa. <br><br><h3>  Para avan√ßados </h3><br><ul><li>  O primeiro script do processo exibe o tempo m√©dio entre as capturas de quadros e, ap√≥s a conclus√£o, o FPS m√©dio.  Esta √© uma ferramenta simples e conveniente para selecionar par√¢metros de imagem nos quais o python ainda n√£o est√° "sufocando".  Com isso, captamos 1280x480 a 20 FPS, nos quais o v√≠deo √© renderizado sem demora. </li><li>  Voc√™ pode perceber que capturamos um par est√©reo com resolu√ß√£o de 1280x480 e o escalamos para 640x240. <br><br>  Uma pergunta razo√°vel: por que tudo isso e por que n√£o pegar imediatamente a miniatura e n√£o carregar nosso python reduzindo-o? <br><br>  Resposta: com captura direta em resolu√ß√µes muito baixas, ainda existem problemas no n√∫cleo da framboesa (a imagem √© quebrada).  Portanto, tomamos uma resolu√ß√£o maior e reduzimos a imagem.  Aqui, usamos um pequeno truque: a imagem n√£o √© dimensionada com python, mas com a ajuda da GPU, para que n√£o haja carga no n√∫cleo do bra√ßo. </li><li>  Por que capturar v√≠deo no formato BGRA, n√£o BGR? <br>  Usamos os recursos da GPU para reduzir o tamanho da imagem e o nativo do m√≥dulo de redimensionamento √© o formato BGRA.  Se usarmos o BGR em vez do BGRA, teremos duas desvantagens.  O primeiro √© um pouco menor que o FPS final (em nossos testes - 20%).  O segundo √© o desgaste constante no console "PiCameraAlfaStripping: usando stripping alfa para converter para o formato n√£o alfa;  voc√™ pode encontrar o formato alfa equivalente mais r√°pido ‚Äù.  A pesquisa no Google levou √† se√ß√£o de documenta√ß√£o do Picamera, que descreve esse truque. </li><li>  Onde est√° o PiRGBArray? <br><br>  √â como a classe Picamera nativa para trabalhar com a c√¢mera, mas aqui ela n√£o √© usada.  J√° se descobriu que, em nossos testes, trabalhar com uma matriz numpy "feita √† m√£o" √© muito mais r√°pido (cerca de uma vez e meia) do que usar o PiRGBArray.  Isso n√£o significa que o PiRGBArray seja ruim, provavelmente essas s√£o nossas m√£os tortas. </li><li>  Qual a carga da porcentagem no c√°lculo do mapa de profundidade? <br>  Vamos responder com uma figura: <br><br><img src="https://habrastorage.org/webt/nn/ez/ef/nnezefyxuiuxx7difz1xctii16w.jpeg"><br><br>  Vemos que dos 4 n√∫cleos do processador, de fato, apenas um √© carregado, ou seja, 70%.  E isso apesar do fato de trabalharmos com uma GUI e estarmos produzindo imagens e mapas de profundidade para o usu√°rio.  Isso significa que h√° uma boa margem de desempenho, e o ajuste fino do OpenCV com o OpenMP e outros itens em C, bem como um modo de "combate" sem uma GUI, podem dar resultados muito interessantes. </li><li>  Qual √© o mapa de profundidade m√°xima do FPS obtido com essas configura√ß√µes? <br><br>  O m√°ximo atingido por n√≥s foi de 17 FPS, ao capturar 20 quadros por segundo da c√¢mera.  Os mais "responsivos" em termos de par√¢metros de velocidade nas configura√ß√µes do mapa de profundidade s√£o MinDisparity e NumOfDisparities.  Isso √© l√≥gico, pois eles determinam o n√∫mero de "etapas" executadas no algoritmo pela janela de pesquisa para comparar quadros.  O segundo mais responsivo √© o preFilterCap, que afeta, em particular, a "suavidade" do mapa de profundidade. </li><li>  E a temperatura do processador? <br><br>  No M√≥dulo de computa√ß√£o 3+ Lite (uma nova s√©rie, com uma ‚Äútampa‚Äù de ferro no processo), mostra aproximadamente os seguintes resultados: <br><br><img src="https://habrastorage.org/webt/ba/p7/kw/bap7kwdbbhd0y2bmvebpqzimqpa.jpeg"></li><li>  Como usar GPU? <br><br>  No m√≠nimo, pode ser usado para andistoriza√ß√£o e retifica√ß√£o de imagens em tempo real, porque h√° exemplos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui no WebGL</a> ), Python <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pi3d</a> , bem como o projeto Processing ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">exemplos para framboesas</a> ). <br><br>  H√° outro desenvolvimento interessante de Koichi Nakamura, chamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">py-videocore</a> .  Em nossa correspond√™ncia com ele, ele expressou a ideia de que, para acelerar o StereoBM, voc√™ pode usar seu tipo de n√∫cleo e OpenCV <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">com o suporte da Cuda</a> .  Em geral, para otimiza√ß√£o - uma vantagem intocada, como se costuma dizer. </li></ul><br>  Obrigado por sua aten√ß√£o, e aqui est√° o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">link prometido para a fonte</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt446872/">https://habr.com/ru/post/pt446872/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt446860/index.html">Hist√≥ria do 3dfx Voodoo1</a></li>
<li><a href="../pt446862/index.html">O que os designers esperam no DUMP-2019: vis√£o geral da se√ß√£o Design</a></li>
<li><a href="../pt446864/index.html">Energia, calor e √°gua</a></li>
<li><a href="../pt446866/index.html">Sistemas operacionais: tr√™s pe√ßas f√°ceis. Parte 2: Abstra√ß√£o: Processo (tradu√ß√£o)</a></li>
<li><a href="../pt446870/index.html">Sistemas de part√≠culas: uma hist√≥ria de Natal</a></li>
<li><a href="../pt446876/index.html">Moscou, 18 de abril - QIWI SERVER PARTY 4.0</a></li>
<li><a href="../pt446880/index.html">Gr√°ficos incorretos: nossa experi√™ncia</a></li>
<li><a href="../pt446882/index.html">O MIPT recebeu o direito de sediar a Copa do Mundo de Programa√ß√£o do ICPC em 2020 em Moscou</a></li>
<li><a href="../pt446884/index.html">O que ler e assistir em novas fic√ß√£o cient√≠fica: Marte, cyborgs e IA rebelde</a></li>
<li><a href="../pt446886/index.html">Os principais especialistas da Expo 3D: Sunny Wong. Mais de 25 milh√µes de entorses podem ser evitadas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
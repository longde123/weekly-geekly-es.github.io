<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶ì üóÑÔ∏è üò£ Open Data Hub-Projekt - Eine offene Plattform f√ºr maschinelles Lernen basierend auf Red Hat OpenShift ü§≥üèª üà∂ üßñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Zukunft ist gekommen. K√ºnstliche Intelligenz und Technologien f√ºr maschinelles Lernen werden bereits erfolgreich von Ihren Lieblingsgesch√§ften, Tr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Open Data Hub-Projekt - Eine offene Plattform f√ºr maschinelles Lernen basierend auf Red Hat OpenShift</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/redhatrussia/blog/472836/">  Die Zukunft ist gekommen. K√ºnstliche Intelligenz und Technologien f√ºr maschinelles Lernen werden bereits erfolgreich von Ihren Lieblingsgesch√§ften, Transportunternehmen und sogar Bauernh√∂fen eingesetzt, auf denen Truth√§hne wachsen. <br><br><img src="https://habrastorage.org/webt/po/5a/pz/po5apz39w7i01k1j6z_k3nlbxjk.jpeg" width="100%"><br><br>  Und wenn etwas existiert, dann existiert es im Internet bereits dar√ºber ... ein offenes Projekt!  Erfahren Sie, wie der Open Data Hub zur Skalierung neuer Technologien beitr√§gt, und vermeiden Sie die Schwierigkeiten bei deren Implementierung. <br><a name="habracut"></a><br>  Mit all den Vorteilen der k√ºnstlichen Intelligenz (KI) und des maschinellen Lernens (ML) haben Unternehmen h√§ufig Schwierigkeiten, diese Technologien zu skalieren.  Die Hauptprobleme dabei sind in der Regel folgende: <br><br><ul><li>  <b>Informationsaustausch und Zusammenarbeit</b> - Es ist fast unm√∂glich, Informationen ohne unn√∂tigen Aufwand auszutauschen und im schnellen Iterationsmodus zusammenzuarbeiten. </li><li>  <b>Zugriff auf Daten</b> - f√ºr jede Aufgabe muss sie neu und manuell erstellt werden, was zeitaufw√§ndig ist. </li><li>  On-Demand-Zugriff - Es gibt keine M√∂glichkeit, On-Demand-Zugriff auf Tools und Plattformen f√ºr maschinelles Lernen sowie auf die Computerinfrastruktur zu erhalten. </li><li>  <b>Produktion</b> - Die Modelle befinden sich noch im Prototypenstadium und werden nicht industriell genutzt. </li><li>  <b>Verfolgen und Erkl√§ren von AI-Ergebnissen</b> - Reproduzierbarkeit, Verfolgen und Erkl√§ren von AI / ML-Ergebnissen sind schwierig. </li></ul><br>  Diese Probleme bleiben ungel√∂st und beeintr√§chtigen die Geschwindigkeit, Effizienz und Produktivit√§t wertvoller Datenverarbeitungs- und Analysespezialisten.  Dies f√ºhrt zu Frustration, Entt√§uschung bei der Arbeit und infolgedessen werden die Gesch√§ftserwartungen in Bezug auf AI / ML zunichte gemacht. <br><br>  Die Verantwortung f√ºr die L√∂sung dieser Probleme liegt bei IT-Fachleuten, die Datenanalysten bereitstellen m√ºssen - richtig, so etwas wie eine Cloud.  Wenn es weiter entwickelt ist, brauchen wir eine Plattform, die Wahlfreiheit bietet und einen bequemen und einfachen Zugang bietet.  Gleichzeitig ist es schnell, einfach zu rekonfigurieren, bei Bedarf skalierbar und ausfallsicher.  Der Aufbau einer solchen Plattform auf Basis von Open-Source-Technologien tr√§gt dazu bei, nicht vom Anbieter abh√§ngig zu werden und einen langfristigen strategischen Vorteil in Bezug auf die Kostenkontrolle zu erhalten. <br><br>  Vor einigen Jahren geschah etwas √Ñhnliches in der Anwendungsentwicklung und f√ºhrte zur Entstehung von Microservices, Hybrid-Cloud-Umgebungen, IT-Automatisierung und agilen Prozessen.  Um all dies zu bew√§ltigen, begannen IT-Experten, Container, Kubernetes und offene Hybrid-Clouds zu verwenden. <br><br>  Jetzt wird diese Erfahrung angewendet, um Al's Herausforderungen zu beantworten.  Daher erstellen IT-Experten Plattformen, die auf Containern basieren, die es Ihnen erm√∂glichen, AI / ML-Services als Teil agiler Prozesse zu erstellen, Innovationen zu beschleunigen und mit Blick auf eine Hybrid-Cloud zu erstellen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vl/gs/kt/vlgsktsdfenliiynd552uvd_eb0.png"></div><br><br>  Wir werden mit dem Aufbau einer solchen Plattform mit Red Hat OpenShift beginnen, unserer Container-Kubernetes-Plattform f√ºr eine Hybrid-Cloud mit einem schnell wachsenden √ñkosystem von Software- und Hardware-ML-L√∂sungen (NVIDIA, H2O.ai, Starburst, PerceptiLabs usw.).  Einige Kunden von Red Hat, wie die BMW Group, ExxonMobil und andere, haben bereits containerisierte ML-Toolketten und DevOps-Prozesse auf Basis dieser Plattform und ihres √ñkosystems eingesetzt, um ihre ML-Architekturen in den kommerziellen Betrieb zu bringen und die Arbeit von Datenanalysten zu beschleunigen. <br><br>  Ein weiterer Grund, warum wir das Open Data Hub-Projekt gestartet haben, besteht darin, eine Beispielarchitektur zu demonstrieren, die auf mehreren Open Source-Projekten basiert, und zu zeigen, wie der gesamte Lebenszyklus einer ML-L√∂sung basierend auf der OpenShift-Plattform implementiert wird. <br><br><h3>  √ñffnen Sie das Data Hub-Projekt </h3><br>  Dies ist ein Open-Source-Projekt, das im Rahmen der entsprechenden Entwicklergemeinschaft entwickelt wird und einen vollst√§ndigen Betriebszyklus implementiert - vom Laden und Konvertieren der Anfangsdaten bis zur Erstellung, Schulung und Wartung des Modells -, wenn AI / ML-Aufgaben mithilfe von Containern und Kubernetes auf der OpenShift-Plattform gel√∂st werden.  Dieses Projekt kann als Referenzimplementierung betrachtet werden, ein Beispiel f√ºr die Erstellung einer offenen AI / ML als Servicel√∂sung auf Basis von OpenShift und verwandten Open Source-Tools wie Tensorflow, JupyterHub, Spark und anderen.  Es ist wichtig zu beachten, dass Red Hat selbst dieses Projekt verwendet, um seine AI / ML-Dienste bereitzustellen.  Dar√ºber hinaus l√§sst sich OpenShift in wichtige Software- und Hardware-ML-L√∂sungen von NVIDIA, Seldon, Starbust und anderen Anbietern integrieren, was den Aufbau und die Einf√ºhrung eigener maschineller Lernsysteme erleichtert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ii/lx/er/iilxervidxlqx7qsyfej1ibhnuc.png"></div><br><br>  Das Open Data Hub-Projekt konzentriert sich auf die folgenden Kategorien von Benutzern und Anwendungsf√§llen: <br><br><ul><li>  Ein Datenanalyst, der eine L√∂sung f√ºr die Implementierung von ML-Projekten ben√∂tigt, die nach Cloud-Typ mit Self-Service-Funktionen organisiert ist. </li><li>  Ein Datenanalyst, der die maximale Auswahl aus der Vielzahl der neuesten Open Source AI / ML-Tools und -Plattformen ben√∂tigt. </li><li>  Ein Datenanalyst, der beim Training von Modellen Zugriff auf Datenquellen ben√∂tigt. </li><li>  Datenanalyst, der Zugriff auf Computerressourcen (CPU, GPU, Speicher) ben√∂tigt. </li><li>  Date ist ein Analyst, der die M√∂glichkeit ben√∂tigt, zusammenzuarbeiten und die Arbeitsergebnisse mit Kollegen zu teilen, Feedback zu erhalten und Verbesserungen mithilfe der schnellen Iterationsmethode einzuf√ºhren. </li><li>  Ein Datenanalyst, der mit Entwicklern (und Entwicklerteams) interagieren m√∂chte, damit seine ML-Modelle und Arbeitsergebnisse in die Produktion gehen. </li><li>  Ein Dateningenieur, der Datenanalysen den Zugriff auf eine Vielzahl von Datenquellen gem√§√ü Sicherheitsstandards und -anforderungen erm√∂glichen muss. </li><li>  Ein Administrator / Betreiber von IT-Systemen, der die F√§higkeit ben√∂tigt, den Lebenszyklus (Installation, Konfiguration, Aktualisierung) von Open Source-Komponenten und -Technologien einfach zu steuern.  Wir brauchen auch geeignete Management- und Quoten-Tools. </li></ul><br>  Das Open Data Hub-Projekt kombiniert eine Reihe von Open Source-Tools, um eine vollst√§ndige AI / ML-Operation zu implementieren.  Das Jupyter-Notizbuch wird hier als Hauptwerkzeug f√ºr die Datenanalyse verwendet.  Dieses Toolkit ist mittlerweile bei Fachleuten f√ºr Datenverarbeitung und -analyse weit verbreitet. Mit dem Open Data Hub k√∂nnen sie Jupyter Notebook-Arbeitsbereiche mithilfe des integrierten JupyterHub auf einfache Weise erstellen und verwalten.  Neben dem Erstellen und Importieren von Notebooks Jupyter enth√§lt das Open Data Hub-Projekt auch eine Reihe vorgefertigter Notebooks in Form einer AI-Bibliothek. <br><br>  Diese Bibliothek ist eine Sammlung von Open-Source-Komponenten f√ºr maschinelles Lernen und Beispielskriptl√∂sungen, die das Rapid Prototyping vereinfachen.  JupyterHub ist in das OpenShift RBAC-Zugriffsmodell integriert, mit dem Sie vorhandene OpenShift-Konten verwenden und Single Sign-On implementieren k√∂nnen.  Dar√ºber hinaus bietet JupyterHub eine praktische Benutzeroberfl√§che namens Spawner, mit der der Benutzer die Menge der Rechenressourcen (Prozessorkerne, Speicher, GPU) f√ºr das ausgew√§hlte Jupyter-Notebook einfach konfigurieren kann. <br><br>  Nachdem der Datenanalyst den Laptop erstellt und eingerichtet hat, k√ºmmert sich der Kubernetes-Scheduler, der Teil von OpenShift ist, um den Rest.  Benutzer k√∂nnen nur ihre Experimente durchf√ºhren, die Ergebnisse ihrer Arbeit speichern und teilen.  Dar√ºber hinaus k√∂nnen fortgeschrittene Benutzer direkt von Jupyter-Notizb√ºchern aus direkt auf die OpenShift CLI-Shell zugreifen, um Kubernetes-Grundelemente wie Job oder OpenShift-Funktionen wie Tekton oder Knative zu aktivieren.  Oder Sie k√∂nnen hierf√ºr die praktische OpenShift-GUI verwenden, die als ‚ÄûOpenShift Web Console‚Äú bezeichnet wird. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gh/j_/2v/ghj_2vrrngca4d0gp0218_rcv2s.png"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3w/zn/_a/3wzn_ap-tzpzvuzeb5xcgvuwhse.png"></div><br><br>  Wenn Sie mit dem n√§chsten Schritt fortfahren, bietet der Open Data Hub die M√∂glichkeit, Datenpipelines zu verwalten.  Hierzu wird ein Ceph-Objekt verwendet, das als S3-kompatibles Objekt-Data-Warehouse bereitgestellt wird.  Apache Spark √ºbertr√§gt Daten aus externen Quellen oder dem integrierten Ceph S3-Speicher und erm√∂glicht Ihnen au√üerdem die Durchf√ºhrung vorl√§ufiger Datenkonvertierungen.  Apache Kafka bietet eine erweiterte Verwaltung von Datenpipelines (bei denen Sie mehrere Downloads sowie Operationen zur Transformation, Analyse und Speicherung von Daten durchf√ºhren k√∂nnen). <br><br>  Der Datenanalyst erhielt also Zugriff auf die Daten und erstellte ein Modell.  Jetzt hat er den Wunsch, die Ergebnisse mit Kollegen oder Anwendungsentwicklern zu teilen und ihnen sein Modell von Service-Prinzipien zur Verf√ºgung zu stellen.  Dazu ben√∂tigen Sie einen Ausgabeserver, und der Open Data Hub verf√ºgt √ºber einen solchen Server namens Seldon, mit dem Sie das Modell als RESTful-Service ver√∂ffentlichen k√∂nnen. <br><br>  Irgendwann gibt es mehrere solcher Modelle auf dem Seldon-Server, und es muss √ºberwacht werden, wie sie verwendet werden.  Zu diesem Zweck bietet der Open Data Hub eine Sammlung relevanter Metriken und eine Berichts-Engine, die auf den weit verbreiteten Open-Source-√úberwachungstools Prometheus und Grafana basiert.  Als Ergebnis erhalten wir Feedback zur √úberwachung der Verwendung von KI-Modellen, insbesondere in der Produktionsumgebung. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ka/wx/pq/kawxpqusyybvhp52lblnjqov2xy.png"></div><br><br>  Somit bietet der Open Data Hub einen Cloud-√§hnlichen Ansatz w√§hrend des gesamten AI / ML-Betriebszyklus, vom Zugriff √ºber die Datenaufbereitung bis hin zur Schulung und zum industriellen Betrieb des Modells. <br><br><h3>  Alles zusammenf√ºgen </h3><br>  Die Frage ist nun, wie dies f√ºr den OpenShift-Administrator organisiert werden kann.  Und hier kommt der spezielle Kubernetes-Operator f√ºr Open Data Hub-Projekte. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gj/qh/io/gjqhiogbxzrwqu7f7n5eqkian9q.png"></div><br><br>  Dieser Bediener verwaltet die Installation, Konfiguration und den Lebenszyklus des Open Data Hub-Projekts, einschlie√ülich der Bereitstellung von Tools wie JupyterHub, Ceph, Spark, Kafka, Seldon, Prometheus und Grafana.  Das Open Data Hub-Projekt finden Sie in der OpenShift-Webkonsole im Abschnitt Community-Operatoren.  Somit kann der OpenShift-Administrator festlegen, dass die entsprechenden OpenShift-Projekte als ‚ÄûOpen Data Hub-Projekt‚Äú kategorisiert werden.  Dies wird einmal gemacht.  Danach betritt der Datenanalyst √ºber die OpenShift-Webkonsole seinen Projektbereich und stellt fest, dass der entsprechende Kubernetes-Operator installiert und f√ºr seine Projekte verf√ºgbar ist.  Anschlie√üend erstellt er mit einem Klick eine Instanz des Open Data Hub-Projekts und greift sofort auf die oben beschriebenen Tools zu.  All dies kann im Hochverf√ºgbarkeits- und Fehlertoleranzmodus konfiguriert werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_n/vn/g5/_nvng5tdobehanormqndfv-tnms.png"></div><br><br>  Wenn Sie das Open Data Hub-Projekt mit Ihren eigenen H√§nden ausprobieren m√∂chten, beginnen Sie mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Installationsanweisungen und einem Einf√ºhrungs-Tutorial</a> .  Technische Details zur Open Data Hub-Architektur finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . Projektentwicklungspl√§ne finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .  In Zukunft ist geplant, eine zus√§tzliche Integration in Kubeflow zu implementieren, eine Reihe von Problemen mit der Datenregulierung und -sicherheit zu l√∂sen und die Integration in Systeme auf der Grundlage der Drools- und Optaplanner-Regeln zu organisieren.  Sie k√∂nnen Ihre Meinung √§u√üern und Mitglied des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Open Data Hub-</a> Projekts auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Community-</a> Seite werden. <br><br>  Wir fassen zusammen: Schwerwiegende Probleme bei der Skalierung hindern Unternehmen daran, das Potenzial k√ºnstlicher Intelligenz und maschinellen Lernens voll auszusch√∂pfen.  Red Hat OpenShift wird seit langem erfolgreich zur L√∂sung √§hnlicher Probleme in der Softwareindustrie eingesetzt.  Das Open Data Hub-Projekt, das in der Open Source-Entwicklergemeinschaft implementiert ist, bietet eine Referenzarchitektur f√ºr die Organisation eines vollst√§ndigen AI / ML-Betriebszyklus basierend auf der OpenShift-Hybrid-Cloud.  Wir haben einen klaren und durchdachten Entwicklungsplan f√ºr dieses Projekt und es ist uns ein ernstes Anliegen, eine aktive und fruchtbare Community f√ºr die Entwicklung offener KI-L√∂sungen auf der OpenShift-Plattform zu schaffen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de472836/">https://habr.com/ru/post/de472836/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de472818/index.html">Kollektive Bewegung: Wie Wissenschaftler Ant Corks studierten</a></li>
<li><a href="../de472822/index.html">Wenn die Russische Akademie der Wissenschaften machtlos ist</a></li>
<li><a href="../de472826/index.html">Mikrointeraktionen und ihre Verwendung in Benutzeroberfl√§chen</a></li>
<li><a href="../de472830/index.html">So schreiben Sie einfach zu beschreibenden Code</a></li>
<li><a href="../de472832/index.html">Lokalisierung oder kreative Anpassung? Fallstudie der Spielstra√üen von Rogue</a></li>
<li><a href="../de472838/index.html">In der Praxis ist die Webanwendung in 80-90% der F√§lle aufgrund des Frontends langsam: ein Interview mit Ivan Akulov</a></li>
<li><a href="../de472840/index.html">Software Defined Storage oder was hat die Dinosaurier get√∂tet?</a></li>
<li><a href="../de472848/index.html">√úberlegungen zu einer Karriere in der IT</a></li>
<li><a href="../de472850/index.html">Beruf oder Leben: Gewinnen Sie einen Netologiekurs, wenn Sie keine Angst haben</a></li>
<li><a href="../de472852/index.html">GitLab nimmt √Ñnderungen f√ºr Benutzer von Cloud- und kommerziellen Produkten vor</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏼‍🎨 👩🏿‍🤝‍👩🏾 🏇 Pixel 3了解如何确定照片的深度 🌅 💐 🖤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pixel智能手机上的人像模式可让您拍摄具有专业外观的照片，从而使背景模糊，从而引起对主体的注意。 去年，我们介绍了如何使用单相机和相位检测自动对焦（相位检测自动对焦，PDAF）（也称为双像素自动对焦 ）来计算深度。 此过程使用了未经培训的传统立体声算法 。 今年在Pixel 3上，我们采用了机器学...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pixel 3了解如何确定照片的深度</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433600/"> Pixel智能手机上的人像模式可让您拍摄具有专业外观的照片，从而使背景模糊，从而引起对主体的注意。 去年，我们介绍了如何使用单相机和相位检测自动对焦（相位检测自动对焦，PDAF）（也称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">双像素自动对焦</a> ）来计算深度。 此过程使用了未经培训的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">传统立体声算法</a> 。 今年在Pixel 3上，我们采用了机器学习，以改善深度评估并在人像模式下产生更好的结果。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/505/531/899/505531899e63adc78fbd74d94f1c3a3a.gif"><br>  <i>左：在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">HDR +中</a>捕获的原始图像。</i>  <i>右侧是使用传统立体声和机器学习深度的人像模式下拍摄结果的比较。</i>  <i>学习成果产生的错误更少。</i>  <i>在传统的立体声结果中，错误地估计了在男人身后的许多水平线的深度等于男人本人的深度，因此它们保持清晰。</i> <br><a name="habracut"></a><br><h2> 简要介绍以前的资料 </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">去年，</a>我们描述了肖像模式使用神经网络来分离属于人的图像和背景图像的像素，并使用源自PDAF像素的深度信息来补充此两级蒙版。 所有这些都是为了获得模糊效果，具体取决于深度，接近专业相机可以提供的效果。 <br><br> 要进行工作，PDAF会拍摄两个略有不同的场景快照。 在图像之间切换时，您可以看到人不在移动，背景在水平移动-这种效果称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">视差</a> 。 由于视差是一个点到相机的距离以及两个视点之间的距离的函数，因此我们可以通过将一个图像中的每个点与另一个图像中的对应点进行比较来确定深度。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e15/41c/044/e1541c044baa5454ddee71ef45c9a96c.gif"><br>  <i>左侧和中间的PDAF图像看起来相似，但在右侧的放大片段中可以看到视差。</i>  <i>放大中心的圆形结构最容易引起注意。</i> <br><br> 但是，在PDAF图像中找到这种对应关系（此方法称为立体深度）是一项极其困难的任务，因为照片之间的点移动非常微弱。 而且，所有立体声技术都存在孔径问题。 如果通过小孔径观察场景，将无法找到与立体基准线平行的线（即连接两个摄像机的线）的点的对应关系。 换句话说，当研究所呈现照片中的水平线（或具有纵向方向的图片中的垂直线）时，一个图像相对于另一个图像的所有偏移看起来几乎相同。 在去年的肖像模式下，所有这些因素都可能导致确定令人不快的文物的深度和外观时出现错误。 <br><br><h2> 改善深度评估 </h2><br> 使用Pixel 3的人像模式，我们可以利用以下事实来解决这些错误：立体声照片的视差只是图像中许多线索之一。 例如，离焦平面较远的点看起来不那么尖锐，这将是散焦深度的暗示。 此外，即使我们在平面屏幕上观看图像，也可以轻松估计到物体的距离，因为我们知道日常物体的大致大小（也就是说，您可以使用描绘人脸的像素数来估计其位置）。 这将是一个语义线索。 <br><br> 手动开发组合这些技巧的算法非常困难，但是使用MO可以做到这一点，同时提高PDAF视差技巧的性能。 具体来说，我们训练使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow</a>编写的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">卷积神经网络</a> ，该<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">网络</a>从PDAF接收像素作为输入，并学习预测深度。 在像素3纵向模式下使用了这种基于MO的改进的深度估计新方法。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7db/0ff/5e3/7db0ff5e3063425f703aaf2b3f30fd77.png"><br>  <i>我们的卷积神经网络接收PDAF图像并提供深度图。</i>  <i>该网络使用具有附加<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">跳过连接</a>和剩余块的编码器-解码器样式的体系结构。</i> <br><br><h2> 神经网络训练 </h2><br> 要训​​练网络，我们需要大量的PDAF图像和相应的高质量深度图。 而且，由于我们需要深度预测才能在人像模式下使用，因此我们需要训练数据以类似于用户使用智能手机拍摄的照片。 <br><br> 为此，我们设计了一种特殊的Frankenfon设备，其中我们组合了五台Pixel 3手机并在它们之间建立了WiFi连接，这使我们能够同时从所有手机拍照（相差不超过2毫秒）。 借助该设备，我们基于照片，从多个角度同时使用了运动和立体声，从而计算出了高质量的深度图。 <br><br><img src="https://habrastorage.org/getpro/habr/post_images/995/827/05b/99582705b2c447fa6faf95c5c114d20f.gif"><br>  <i>左：用于收集训练数据的设备。</i>  <i>中间：在五张照片之间切换的示例。</i>  <i>相机同步确保了在动态场景中计算深度的能力。</i>  <i>右：总深度。</i>  <i>置信度低的点（由于纹理的弱点而无法确定不同照片中像素的比较），被涂成黑色，不用于训练。</i> <br><br> 由于以下原因，使用此设备获得的数据非常适合训练网络： <br><br><ul><li> 五种观点保证了在多个方向上都存在视差，这使我们摆脱了光圈问题。 </li><li> 摄像机的位置可确保至少在两张照片中重复图像中的任何点，从而减少了无法匹配的点数。 </li><li> 基线（即摄像机之间的距离）大于PDAF的基线，这保证了深度的更准确估计。 </li><li> 相机同步确保了在动态场景中计算深度的能力。 </li><li> 设备的便携性保证了自然拍摄照片，模拟用户使用智能手机拍摄的照片的可能性。 </li></ul><br> 但是，尽管使用此设备获得的数据非常理想，但仍然很难预测场景对象的绝对深度-任何给定的PDAF对都可以对应于各种深度图（这完全取决于镜头的特性，焦距等）。 考虑到所有这些因素，我们估计了场景对象的相对深度，足以在人像模式下获得令人满意的结果。 <br><br><h2> 我们结合所有这一切 </h2><br> 在Pixel 3上使用MO估算深度应该可以快速完成，这样用户就不必等待太久就能获得人像效果。 但是，要使用较小的散焦和视差获得良好的深度估计，您必须以全分辨率提供照片的神经网络。 为了确保快速获得结果，我们使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow Lite</a> （一种可在移动和嵌入式设备上启动MO模型的跨平台解决方案），以及功能强大的Pixel 3 GPU（可让您快速计算异常大的输入数据的深度）。 然后，我们将获得的深度估计值与来自神经网络的遮罩相结合，以区分人，以获得以人像模式拍摄的最漂亮结果。 <br><br><h2> 自己尝试 </h2><br> 在Google Camera App 6.1及更高版本中，我们的深度图嵌入在人像模式图像中。 这意味着我们可以在拍摄照片后使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Google照片深度编辑器</a>更改模糊程度和对焦点。 您还可以使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第三方</a>程序从jpeg提取深度图，然后自己研究它们。 您也可以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">从链接中</a>获取相册，以纵向模式显示相对深度图和相应的图像，以比较传统的立体声和MO方法。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN433600/">https://habr.com/ru/post/zh-CN433600/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN433586/index.html">我们如何没有赢得黑客马拉松</a></li>
<li><a href="../zh-CN433588/index.html">并行C ++ 17算法的惊人性能。 神话还是现实？</a></li>
<li><a href="../zh-CN433592/index.html">信息：Yandex.Phone</a></li>
<li><a href="../zh-CN433596/index.html">麦哲伦的错误：使用SQLite FTS进行缓冲区溢出或环球探险</a></li>
<li><a href="../zh-CN433598/index.html">LLVM如何优化功能</a></li>
<li><a href="../zh-CN433602/index.html">数学上的简单性可能是进化速度的基础。</a></li>
<li><a href="../zh-CN433604/index.html">使用Android Studio舒适地工作</a></li>
<li><a href="../zh-CN433606/index.html">SIEM深度：现成的相关性。 第3.2部分。 事件规范化方法</a></li>
<li><a href="../zh-CN433608/index.html">未来的汽车。 屏幕代替汽车玻璃？</a></li>
<li><a href="../zh-CN433610/index.html">植物化学家的笔记。 柿子</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩‍👦 🍵 🚢 Réseaux Kubernetes: Pods 👨🏻‍✈️ 🛌🏻 ↘️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le matériel, dont nous publions la traduction aujourd'hui, est consacré aux caractéristiques de l'interaction réseau des foyers Kubernetes. Il est des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Réseaux Kubernetes: Pods</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/441576/">  Le matériel, dont nous publions la traduction aujourd'hui, est consacré aux caractéristiques de l'interaction réseau des foyers Kubernetes.  Il est destiné à ceux qui ont déjà une certaine expérience avec Kubernetes.  Si vous n'êtes pas très familier avec Kubernetes, alors cela vaut probablement la peine de lire ce tutoriel Kubernetes avant de lire ce matériel, où travailler avec cette plate-forme est envisagé pour les débutants. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/0_/ch/6q/0_ch6qrxl9vydilgtpyci7diugw.jpeg"></a> <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Pods</font> </h2><br>  Qu'est-ce que sous (pod) Kubernetes?  Sub est une entité qui se compose d'un ou plusieurs conteneurs hébergés sur le même hôte et configurés pour partager des ressources de pile réseau et d'autres ressources comme des volumes.  Les pods sont les blocs de construction de base qui composent les applications qui s'exécutent sur la plate-forme Kubernetes.  Les pods partagent une pile réseau.  En pratique, cela signifie que tous les conteneurs qui composent le foyer peuvent communiquer entre eux via l' <code>localhost</code> .  S'il y a un conteneur dans l'âtre qui exécute nginx, à l'écoute sur le port 80 et un autre conteneur qui exécute scrapyd, ce conteneur peut accéder au premier conteneur à <code>http://localhost:80</code> .  Ça n'a pas l'air si difficile.  Demandons-nous maintenant comment cela fonctionne réellement.  Jetons un coup d'œil à une situation typique lorsque le conteneur Docker est lancé sur la machine locale. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/641/7fe/52a/6417fe52a2e9de3296187860905907f7.png"></div><br>  <i><font color="#999999">Conteneur Docker exécuté sur une machine locale</font></i> <br><br>  Si vous regardez ce schéma de haut en bas, il s'avère qu'il existe une interface réseau physique <code>eth0</code> .  Le pont <code>docker0</code> est <code>docker0</code> et l'interface réseau virtuelle <code>docker0</code> est <code>veth0</code> au pont.  Notez que les <code>veth0</code> <code>docker0</code> et <code>veth0</code> sont sur le même réseau, dans cet exemple, c'est <code>172.17.0.0/24</code> .  Sur ce réseau, l'interface <code>docker0</code> attribuer l'adresse IP <code>172.17.0.1</code> , cette interface est la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">passerelle par défaut</a> pour l'interface <code>veth0</code> , à laquelle est attribuée l'adresse <code>172.17.0.2</code> .  En raison des particularités de la configuration des espaces de noms réseau lors du démarrage du conteneur, les processus à l'intérieur du conteneur ne voient que l'interface <code>veth0</code> et interagissent avec le monde extérieur via les interfaces <code>docker0</code> et <code>eth0</code> .  Exécutez maintenant le deuxième conteneur. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8b4/33a/915/8b433a91572e4afa0f9652d4e729a8b3.png"></div><br>  <i><font color="#999999">Deux conteneurs Docker exécutés sur la machine locale</font></i> <br><br>  Comme vous pouvez le voir dans le diagramme ci-dessus, la nouvelle interface réseau virtuelle <code>veth1</code> est affectée au deuxième conteneur, qui est connecté au même pont que le premier conteneur - à <code>docker0</code> .  Il s'agit d'une description assez concise de ce qui se passe réellement.  De plus, il convient de noter que la connexion entre le conteneur et le pont est établie grâce à une paire d'interfaces Ethernet virtuelles connectées, dont l'une se trouve dans l'espace de noms du conteneur et l'autre dans l'espace de noms du réseau racine.  Des détails à ce sujet peuvent être trouvés <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Tout cela est bien, mais il ne décrit pas encore ce que nous, comme appliqué aux pods Kubernetes, appelons «pile réseau partagée».  Heureusement, les espaces de noms sont très flexibles.  Docker peut lancer un conteneur et au lieu de créer une nouvelle interface réseau virtuelle pour lui, faites-le utiliser l'interface existante avec d'autres conteneurs.  Avec cette approche, nous devrons changer le schéma ci-dessus comme indiqué ci-dessous. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/456/4f6/5fb/4564f65fb5ed8773794f98f7655f0523.png"></div><br>  <i><font color="#999999">Les conteneurs utilisent une interface réseau commune</font></i> <br><br>  Maintenant, le deuxième conteneur interagit avec l'interface <code>veth0</code> déjà existante, et non avec sa propre interface <code>veth1</code> , comme c'était le cas dans l'exemple précédent.  L'utilisation d'un tel schéma entraîne plusieurs conséquences.  Pour commencer, nous pouvons maintenant dire que les deux conteneurs sont visibles extérieurement à la même adresse - <code>172.17.0.2</code> , et à l'intérieur de chacun d'eux peuvent accéder aux ports sur <code>localhost</code> ouvert par un autre conteneur.  De plus, cela signifie que ces conteneurs ne peuvent pas ouvrir les mêmes ports.  Il s'agit bien sûr d'une limitation, mais elle ne diffère pas d'une limitation similaire dans la situation où plusieurs processus ouvrent des ports sur le même hôte.  Avec cette approche, un ensemble de processus obtient tous les avantages associés à l'exécution de ces processus dans des conteneurs, tels qu'une mauvaise connectivité et une mauvaise isolation, mais en même temps, les processus peuvent organiser la collaboration dans le plus simple des environnements réseau existants. <br><br>  Kubernetes met en œuvre ce modèle en créant un conteneur spécial pour chaque foyer dont le seul but est de fournir une interface réseau pour d'autres conteneurs de foyer.  Si vous vous connectez au nœud du cluster Kubernetes auquel un sous-programme spécifique est affecté par <code>ssh</code> et exécutez la <code>docker ps</code> , vous verrez au moins un conteneur s'exécuter avec la commande <code>pause</code> .  Cette commande suspend le processus en cours jusqu'à ce qu'un signal <code>SIGTERM</code> arrive.  De tels conteneurs ne font absolument rien, ils sont dans un état "endormi" et attendent ce signal.  Bien que les conteneurs «suspendus» ne fassent rien, ils sont, pour ainsi dire, le «cœur» du foyer, fournissant à d'autres conteneurs une interface réseau virtuelle qu'ils peuvent utiliser pour interagir entre eux ou avec le monde extérieur.  En conséquence, il s'avère que dans un environnement hypothétique ressemblant à ci-dessous, notre schéma précédent ressemblerait à celui illustré ci-dessous. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3b0/e06/d66/3b0e06d66041a5dd0946f43c94314dae.png"></div><br>  <i><font color="#999999">Conteneurs hypothétiques</font></i> <br><br><h2>  <font color="#3AC1EF">Réseau de foyer</font> </h2><br>  Un sous, plein de conteneurs, est la pierre angulaire d'un certain système, mais jusqu'à présent pas ce système lui-même.  L'architecture Kubernetes repose sur l'exigence selon laquelle les pods doivent pouvoir interagir avec d'autres pods, qu'ils s'exécutent sur le même ordinateur ou sur des machines différentes.  Afin d'apprendre comment tout cela fonctionne, nous devons aller à un niveau d'abstraction plus élevé et parler du fonctionnement des nœuds dans le cluster Kubernetes.  Ici, nous aborderons le sujet du routage et des itinéraires réseau.  Ce sujet est souvent évité dans des documents comme celui-ci, car il est trop complexe.  Il n'est pas facile de trouver un guide compréhensible et pas trop long pour le routage IP, mais si vous voulez regarder un bref aperçu de ce problème, vous pouvez jeter un œil à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce</a> matériel. <br><br>  Le cluster Kubernetes comprend un ou plusieurs nœuds.  Un nœud est un système hôte, physique ou virtuel, qui contient divers outils logiciels et leurs dépendances (principalement Docker), ainsi que plusieurs composants système Kubernetes.  Le nœud est connecté au réseau, ce qui lui permet d'échanger des données avec d'autres nœuds du cluster.  Voici à quoi pourrait ressembler un cluster à deux nœuds simple. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/477/db1/b20/477db1b2030b13c41178a48821916fcc.png"></div><br>  <i><font color="#999999">Un cluster simple à deux nœuds</font></i> <br><br>  Si le cluster en question s'exécute dans un environnement cloud comme GCP ou AWS, ce schéma transmet assez précisément l'essence de l'architecture de réseau par défaut pour les projets individuels.  À des fins de démonstration, le réseau privé <code>10.100.0.0/24</code> utilisé dans cet exemple.  Par conséquent, l'adresse <code>10.100.0.1</code> attribuée au <code>10.100.0.1</code> et les adresses <code>10.100.0.2</code> et <code>10.100.0.3</code> deux nœuds.  En utilisant cette architecture, chacun des nœuds peut interagir avec l'autre en utilisant son interface réseau <code>eth0</code> .  Rappelons maintenant que under, exécuté sur l'hôte, n'est pas sur ce réseau privé.  Il est connecté au pont dans un réseau complètement différent.  Il s'agit d'un réseau virtuel qui n'existe que dans un nœud spécifique.  Afin de le rendre plus clair, redessinons le schéma précédent, en y ajoutant ce que nous avons appelé un foyer hypothétique ci-dessus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ff6/721/c32/ff6721c32b5d74bc80fccfbf6164e486.png"></div><br>  <i><font color="#999999">Pods et nœuds</font></i> <br><br>  L'hôte situé à gauche de ce diagramme a une interface <code>eht0</code> avec l'adresse <code>10.100.0.2</code> , la passerelle par défaut pour laquelle est le routeur avec l'adresse <code>10.100.0.1</code> .  Le pont <code>docker0</code> avec l'adresse <code>172.17.0.1</code> connecté à cette interface, et à lui, via l'interface virtuelle <code>veth0</code> avec l'adresse <code>172.17.0.2</code> , est connecté ce que nous appelons ici le foyer.  L'interface <code>veth0</code> été créée dans un conteneur suspendu.  Il est visible dans les trois conteneurs via une pile réseau partagée.  Étant donné que les règles de routage locales sont configurées lors de la création du pont, tout paquet arrivant à <code>eth0</code> et ayant l'adresse de destination <code>172.17.0.2</code> sera redirigé vers le pont, qui le transmettra à l'interface virtuelle <code>veth0</code> .  Bien que tout cela semble assez décent.  S'il est connu que l'hôte dont nous discutons a l'adresse <code>172.17.0.2</code> , nous pouvons ajouter une règle aux paramètres du routeur qui décrit que la prochaine transition pour cette adresse est <code>10.100.0.2</code> , après quoi les paquets à partir de là devraient être redirigés vers <code>veth0</code> .  Excellent.  Voyons maintenant un autre hôte. <br><br>  L'hôte montré dans le diagramme de droite a une interface physique <code>eth0</code> avec l'adresse <code>10.100.0.3</code> .  Il utilise la même passerelle par défaut - <code>10.100.0.1</code> , et, encore une fois, il est connecté au pont <code>docker0</code> avec l'adresse <code>172.17.0.1</code> .  On a le sentiment que tout ne va pas si bien.  Cette adresse peut en effet différer de celle utilisée sur l'hôte situé à gauche.  Les adresses des ponts ici sont identiques pour illustrer le pire scénario possible, qui, par exemple, peut se produire si vous venez d'installer Docker et de le laisser fonctionner comme vous le souhaitez.  Mais même si les réseaux en question sont différents, notre exemple met en évidence un problème plus profond, à savoir que les nœuds ne savent généralement rien des adresses privées attribuées aux ponts situés sur d'autres nœuds.  Et nous devons le savoir - pour pouvoir envoyer des paquets à ces ponts et être sûr qu'ils arriveront là où ils en ont besoin.  Évidemment, ici nous avons besoin d'une sorte d'entité, ce qui nous permet d'assurer la configuration correcte des adresses dans différents nœuds. <br><br>  La plate-forme Kubernetes nous donne une solution en deux étapes à ce problème.  Tout d'abord, cette plate-forme attribue un espace d'adressage commun aux ponts dans chaque nœud, puis attribue aux ponts les adresses dans cet espace en fonction du nœud dans lequel se trouve le pont.  Deuxièmement, Kubernetes ajoute des règles de routage à la passerelle située, dans notre cas, à <code>10.100.0.1</code> .  Ces règles définissent les règles de routage des paquets destinés à chacun des ponts.  C'est-à-dire qu'ils décrivent à travers quelle interface physique <code>eth0</code> peut être mise en contact avec chacun des ponts.  Cette combinaison d'interfaces de réseau virtuel, de ponts et de règles de routage est communément appelée <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">réseau de superposition</a> .  En parlant de Kubernetes, j'appelle généralement ce réseau un «réseau de foyer», car il s'agit d'un réseau de superposition qui permet aux pods situés à différents nœuds de communiquer entre eux.  Voici à quoi ressemblera le diagramme précédent une fois que les mécanismes Kubernetes seront opérationnels. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b9c/f87/c96/b9cf87c96d0169dbcd0846f8bb3cd323.png"></div><br>  <i><font color="#999999">Réseau de foyer</font></i> <br><br>  Il attire immédiatement l'attention sur le fait que les noms de pont sont passés de <code>docker0</code> à <code>cbr0</code> .  Kubernetes n'utilise pas de ponts Docker standard.  Ce que nous avons appelé <code>cbr</code> est une abréviation de «pont personnalisé», c'est-à-dire que nous parlons de ponts spéciaux.  Je ne suis pas prêt à donner une liste complète des différences entre le lancement de conteneurs Docker dans des pods et leur exécution sur des ordinateurs ordinaires, mais ce dont nous parlons ici est l'une des différences similaires importantes.  De plus, vous devez faire attention au fait que l'espace d'adressage attribué aux ponts dans cet exemple est <code>10.0.0.0/14</code> .  Cette adresse est extraite de l'un de nos clusters intermédiaires, qui sont déployés sur la plate-forme Google Cloud, ce qui précède est donc un exemple très réel d'un réseau de foyers.  Votre cluster peut se voir attribuer une plage d'adresses complètement différente.  Malheureusement, pour le moment, il n'y a aucun moyen d'obtenir des informations sur ces adresses à l'aide de l'utilitaire <code>kubectl</code> , mais, par exemple, si vous utilisez GCP, vous pouvez exécuter une commande comme les <code>gcloud container clusters describe &lt;cluster&gt;</code> et regardez la propriété <code>clusterIpv4Cidr</code> . <br><br>  En général, on peut noter que vous n'avez généralement pas à penser au fonctionnement du réseau de foyers.  Lorsqu'un sous-échange de données avec un autre foyer, cela se produit le plus souvent via les services Kubernetes.  C'est un peu un proxy défini par logiciel.  Mais les adresses réseau des foyers apparaissent dans les journaux.  Dans certaines situations, en particulier pendant le débogage, vous devrez peut-être définir explicitement des règles de routage dans les réseaux de foyers.  Par exemple, le trafic quittant Kubernetes lié à une adresse dans la plage 10.0.0.0/8 n'est pas traité par défaut à l'aide de NAT.  Par conséquent, si vous interagissez avec des services situés sur un autre réseau privé qui a la même plage d'adresses, vous devrez peut-être configurer des règles de routage qui vous permettront d'organiser la livraison correcte des paquets. <br><br><h2>  <font color="#3AC1EF">Résumé</font> </h2><br>  Aujourd'hui, nous avons parlé des modules Kubernetes et des fonctionnalités de leur mise en réseau.  Nous espérons que ce matériel vous aidera à prendre les bonnes mesures pour mettre en œuvre des scénarios d'interaction de foyer complexes sur les réseaux Kubernetes. <br><br>  <b>Chers lecteurs!</b>  Cet article est le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premier d'une</a> série de réseaux Kubernetes.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La deuxième</a> partie de ce cycle a déjà été <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">traduite</a> .  Nous réfléchissons à l'opportunité de traduire la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">troisième</a> partie.  Nous vous demandons de commenter cela dans les commentaires. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr441576/">https://habr.com/ru/post/fr441576/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr441566/index.html">12 concepts JavaScript à connaître</a></li>
<li><a href="../fr441568/index.html">Gestion de la mémoire Python</a></li>
<li><a href="../fr441570/index.html">Le condensé de matières fraîches du monde du front-end de la dernière semaine n ° 353 (17-24 février 2019)</a></li>
<li><a href="../fr441572/index.html">Frontend Weekly Digest (18-24 février 2019)</a></li>
<li><a href="../fr441574/index.html">Apprendre Docker Partie 6: Travailler avec des données</a></li>
<li><a href="../fr441578/index.html">Tutoriel React, partie 19: Méthodes du cycle de vie des composants</a></li>
<li><a href="../fr441580/index.html">Tutoriel React, partie 20: Première leçon de rendu conditionnel</a></li>
<li><a href="../fr441582/index.html">Optimisation du système de contrôle LQR</a></li>
<li><a href="../fr441584/index.html">PHP Digest n ° 150 (11-25 février 2019)</a></li>
<li><a href="../fr441586/index.html">Comment recommander une musique que presque personne n'a écoutée. Rapport Yandex</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
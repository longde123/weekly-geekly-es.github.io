<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>♦️ 👩🏻‍🌾 🔛 Kaggle：不能走路-让我们跑步 👩🏿‍🤝‍👨🏾 👯 👨‍🍳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="机器学习的主题有多复杂？ 如果您擅长数学，但是有关机器学习的知识往往为零，那么您在Kaggle平台上进行的激烈竞争中能走多远？ 



 关于网站和比赛 
 Kaggle是一个对ML感兴趣的社区（从初学者到很酷的专业人士）和竞赛的场所（通常带有丰厚的奖池）。 

 为了立即浸入ML的所有魅力，我决定...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle：不能走路-让我们跑步</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/singularis/blog/440026/"> 机器学习的主题有多复杂？ 如果您擅长数学，但是有关机器学习的知识往往为零，那么您在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Kaggle</a>平台上进行的激烈竞争中能走多远？ <br><br><img src="https://habrastorage.org/webt/3y/zi/_f/3yzi_f6ybvxg_uq9392v4rqoml0.png"><br><a name="habracut"></a><br><h2> 关于网站和比赛 </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Kaggle</a>是一个对ML感兴趣的社区（从初学者到很酷的专业人士）和竞赛的场所（通常带有丰厚的奖池）。 <br><br> 为了立即浸入ML的所有魅力，我决定立即选择一场严肃的比赛。 这样才可用：《 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">两个西格玛：使用新闻来预测股票走势》</a> 。 简而言之，竞赛的实质是根据资产的状态和与该资产有关的新闻来预测各个公司的股价。 比赛的奖金为100,000美元，奖金将分配给前7名。 <br><br> 比赛之所以特别，有两个原因： <br><br><ul><li> 这是仅限内核的竞赛：您只能在Kaggle内核云中训练模型； <br></li><li> 最终的席位分配将在决策完成后的六个月内公布； 在此期间，决策将预测当前日期的价格。 <br></li></ul><br><h2> 关于任务 </h2><br> 根据条件，我们必须预测信心 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>i</mi><mi>n</mi><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.76ex" height="2.66ex" viewBox="0 -832 6785.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="1356" y="0"></use><g transform="translate(1717,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="361" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-6E" x="3403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMAIN-5B" x="4003" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMAIN-2212" x="4282" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMAIN-31" x="5060" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMAIN-2C" x="5561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMAIN-31" x="6006" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMAIN-5D" x="6507" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ hat {y} _ {ti} \ in [-1,1] </script> 因为资产的回报会增加。 资产收益被视为相对于整个市场收益。 目标指标是自定义的-不是更熟悉的<abbr title="均方根误差">RMSE</abbr>或<abbr title="平均绝对误差">MAE</abbr> ，而是<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Sharpe比率</a> ，在这种情况下，该<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">比率</a>被认为如下： <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#xFF08;</mo></mrow><msub><mi>x</mi><mi>t</mi></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#xFF09;</mo></mrow></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#xFF0C;</mo></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="39.084ex" height="2.419ex" viewBox="0 -780.1 16827.7 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-65" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-78" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="1650" y="0"></use><g transform="translate(2012,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-73" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-63" x="469" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-6F" x="903" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-72" x="1388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-65" x="1840" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMAIN-3D" x="4596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-66" x="5902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-72" x="6453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-61" x="6904" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-63" x="7434" y="0"></use><g transform="translate(7867,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="809" y="-213"></use></g></g><g transform="translate(10456,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-61" x="2424" y="0"></use><g transform="translate(2953,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">（</text></g><g transform="translate(3783,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="809" y="-213"></use></g><g transform="translate(4711,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">）</text></g></g><g transform="translate(15997,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">，</text></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mrow class="MJX-TeXAtom-ORD"><mo>（</mo></mrow><msub><mi>x</mi><mi>t</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo>）</mo></mrow></mrow><mrow class="MJX-TeXAtom-ORD"><mo>，</mo></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> \ text {score} = \ frac {\ bar {x} _t} {\ sigma（x_t）}，</script></p> 在哪里 <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.782ex" height="2.539ex" viewBox="0 -780.1 9808.8 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMAIN-3D" x="1205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-73" x="2512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-75" x="2981" y="0"></use><g transform="translate(3554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-68" x="5026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-61" x="5603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="6132" y="0"></use><g transform="translate(6494,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(7584,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(8636,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="361" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> x_t = \ sum_i \ hat {y} _ {ti} r_ {ti} u_ {ti} </script>  ， <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="1.817ex" viewBox="0 -520.7 1051.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> r_ {ti} </script>  -在10天的时间段内，第t天相对于市场的资产收益i， <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="1.817ex" viewBox="0 -520.7 1172.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> u_ {ti} </script>  -一个布尔变量，指示第t天的评估中是否包括第i种资产， <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.012ex" height="2.419ex" viewBox="0 -780.1 2588.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ bar {x} _t </script>  -平均值 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> x_t </script>  ， <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#xFF08;</mo></mrow><msub><mi>x</mi><mi>t</mi></msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#xFF09;</mo></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="12.871ex" height="2.419ex" viewBox="0 -780.1 5541.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-61" x="2424" y="0"></use><g transform="translate(2953,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">（</text></g><g transform="translate(3783,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="809" y="-213"></use></g><g transform="translate(4711,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">）</text></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mrow class="MJX-TeXAtom-ORD"><mo>（</mo></mrow><msub><mi>x</mi><mi>t</mi></msub><mrow class="MJX-TeXAtom-ORD"><mo>）</mo></mrow></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ sigma（x_t）</script>  -标准偏差 <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhhgq4icBoIkOrdZ5KNBm38Jsvimxg#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> x_t </script>  。 <br><br> 夏普比率是风险调整后的回报，系数的值表明交易者的有效性： <br><br><ul><li> 小于1：性能不佳 <br></li><li>  1-2：中等效率 <br></li><li>  2-3：出色的表现， <br></li><li> 超过3：完美。 <br></li></ul><br><div class="spoiler">  <b class="spoiler_title">市场走势数据</b> <div class="spoiler_text"><ul><li>  <b>时间</b> （datetime64 [ns，UTC]）-当前时间（在UTC 22:00的所有行中的行情数据中） <br></li><li>  <b>assetCode</b> （对象）-资产标识符 <br></li><li>  <b>assetName</b> （类别）-用于与新闻数据通信的资产组的标识符 <br></li><li>  <b>Universe</b> （float64）-一个布尔值，指示在计算得分时是否将这一资产考虑在内 <br></li><li> 交易量（float64）-每日交易量 <br></li><li> 收盘价（float64）-当天收盘价 <br></li><li>  <b>开盘价</b> （float64）-当天的开盘价 <br></li><li>  <b>returnClosePrevRaw1</b> （float64）-从关闭到前一天的收益 <br></li><li>  <b>returnOpenPrevRaw1</b> （float64）-前一天从开盘到开盘的获利能力 <br></li><li>  <b>returnClosePrevMktres1</b> （float64）-前一天从收盘到收盘的获利能力，相对于整个市场的波动进行了调整 <br></li><li>  <b>returnOpenPrevMktres1</b> （float64）-前一天从开盘到开盘的获利能力，相对于整个市场的波动进行了调整 <br></li><li>  <b>returnClosePrevRaw10</b> （float64）-前10天从关闭到关闭的收益 <br></li><li>  <b>returnOpenPrevRaw10</b> （float64）-前10天从开盘到开盘的获利能力 <br></li><li>  <b>returnClosePrevMktres10</b> （float64）-前10天从收盘到收盘的收益，相对于整个市场的波动进行了调整 <br></li><li>  <b>returnOpenPrevMktres10</b> （float64）-前10天从开盘到开盘的收益率，相对于整个市场的波动进行了调整 <br></li><li>  <b>returnOpenNextMktres10</b> （float64）-未来10天从开盘到开盘的收益率，已针对整个市场的波动进行了调整。 我们将预测该值。 <br></li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">新闻数据</b> <div class="spoiler_text"><ul><li>  <b>时间</b> （datetime64 [ns，UTC]）-UTC数据可用性中的时间 <br></li><li>  <b>sourceTimestamp</b> （datetime64 [ns，UTC]）-UTC发布新闻中的时间 <br></li><li>  <b>firstCreated</b> （datetime64 [ns，UTC]）-数据的第一个版本的UTC时间 <br></li><li>  <b>sourceId</b> （对象）-记录标识符 <br></li><li>  <b>标题</b> （对象）-标题 <br></li><li>  <b>紧急</b> （int8）-新闻类型（1：警告，3：文章） <br></li><li>  <b>takeSequence</b> （int16）-参数不是很清楚，以某种顺序编号 <br></li><li>  <b>提供者</b> （类别）-新闻提供者标识符 <br></li><li>  <b>主题</b> （类别）-新闻主题代码列表（可以是地理标志，事件，行业等） <br></li><li>  <b>观众</b> （类别）-观众代码新闻列表 <br></li><li>  <b>bodySize</b> （int32）-新闻正文中的字符数 <br></li><li>  <b>companyCount</b> （int8）-新闻中明确提及的公司数量 <br></li><li>  <b>headlineTag</b> （对象）-汤森路透的某个标题标签 <br></li><li>  <b>marketCommentary</b> （布尔）-该新闻与一般市场状况有关的迹象 <br></li><li>  <b>句话</b> （Count16）-新闻中的要约数量 <br></li><li>  <b>wordCount</b> （int32）-新闻中的单词和标点符号的数量 <br></li><li>  <b>assetCodes</b> （类别）-新闻中提到的资产列表 <br></li><li>  <b>assetName</b> （类别）-资产组代码 <br></li><li>  <b>firstMentionSentence</b> （int16）-首先提及资产的句子： <br></li><li>  <b>相关性</b> （float32）-从0到1的数字，显示与资产相关的新闻的相关性 <br></li><li>  <b>sentimentClass</b> （int8）-新闻语调类 <br></li><li>  <b>sentimentNegative</b> （float32）-音调为负的概率 <br></li><li>  <b>sentimentNeutral</b> （float32）-音调为中性的可能性 <br></li><li>  <b>sentimentPositive</b> （float32）-密钥为正的概率 <br></li><li>  <b>sentimentWordCount</b> （int32）-文本中与资产相关的单词数 <br></li><li>  <b>noveltyCount12H</b> （int16）-12小时内的“新颖”新闻，相对于有关该资产的先前新闻进行计算 <br></li><li>  <b>noveltyCount24H</b> （int16）-相同，在24小时内 <br></li><li>  <b>noveltyCount3D</b> （int16）-同样，在3天内 <br></li><li>  <b>noveltyCount5D</b> （int16）-同样，在5天内 <br></li><li>  <b>noveltyCount7D</b> （int16）-相同，在7天内 <br></li><li>  <b>volumeCounts12H</b> （int16）-12小时内有关此资产的新闻数量 <br></li><li>  <b>volumeCounts24H</b> （int16）-相同，在24小时内 <br></li><li>  <b>volumeCounts3D</b> （int16）-相同，在3天内 <br></li><li>  <b>volumeCounts5D</b> （int16）-相同，持续5天 <br></li><li>  <b>volumeCounts7D</b> （int16）-同样，在7天内 <br></li></ul><br></div></div><br> 该任务本质上是二进制分类的任务，也就是说，我们预测二进制符号将产生增加（1类）或减少（0类）的作用。 <br><br><h2> 关于工具 </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Kaggle Kernels</a>是一个支持协作的云计算平台。 支持以下类型的内核： <br><ul><li>  Python脚本 <br></li><li>  R脚本 <br></li><li>  Jupyter笔记本 <br></li><li>  RMarkdown <br></li></ul><br> 每个内核都在其docker容器中运行。 容器中安装了许多软件包，可在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此处</a>找到python的列表。 技术规格如下： <br><br><ul><li>  CPU：4核 </li><li> 内存：17 GB， </li><li> 驱动器：5 GB永久性和16 GB临时性， </li><li> 最长脚本运行时间：9小时（比赛开始时为6小时）。 </li></ul><br> 内核中也提供GPU，但是在本次比赛中禁止使用GPU。 <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Keras</a>是运行在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TensorFlow</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">CNTK</a>或<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Theano</a>之上的高级神经网络框架。 这是一个非常方便且易于理解的API，并且可以使用后端API添加网络拓扑，丢失功能等。 <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Scikit-learn</a>是一个大型的机器学习算法库。 数据预处理和数据分析算法的有用来源，可与更专业的框架一起使用。 <br><br><h2> 模型验证 </h2><br> 在提交模型进行评估之前，您需要以某种方式在本地检查其效果-即，提出一种进行本地验证的方法。 我尝试了以下方法： <br><br><ol><li> 交叉验证<i>与</i>简单按比例划分为训练/测试集； </li><li> 夏普比<i>与</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><abbr title="接收器工作特性">ROC</abbr> <abbr title="曲线下面积">AUC的</abbr></a>局部计算。 </li></ol><br> 结果，最奇怪的是，最接近竞争评估的结果显示了比例分区（根据经验选择分区0.85 / 0.15）和AUC的组合。 交叉验证可能不太适合，因为在培训数据的早期阶段和评估阶段，市场行为存在很大差异。 为什么AUC的表现优于夏普比率-我完全不能说。 <br><br><h2> 第一次尝试 </h2><br> 由于任务是预测时间序列，因此第一个方法经过了经典解决方案的测试-递归神经网络（ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">RNN</a> ），或者说是其变体<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><abbr title="长期记忆">LSTM</abbr></a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><abbr title="门控循环单元">GRU</abbr></a> 。 <br><br> 递归网络的主要原理是，对于每个输出值，不是输入一个样本，而是输入整个序列。 由此得出： <br><br><ul><li> 我们需要对初始数据进行一些预处理-为每个资产生成这些长度为t天的序列。 <br></li><li> 如果前t天没有数据，则基于递归网络的模型将无法预测输出值。 <br></li></ul><br> 我每天从t开始生成序列，因此对于相当大的t（从20开始），整个训练样本集不再适合内存。 由于Keras可以将生成器用作训练和预测的输入和输出数据集，因此使用生成器解决了该问题。 <br><br> 数据的最初准备工作是尽可能幼稚的：我们获取整个市场数据，并添加几个功能（星期几，月份，一年中的星期几），而我们完全不涉及新闻数据。 <br><br> 第一个模型使用t = 10，看起来像这样： <br><br><pre><code class="python hljs">model = Sequential() model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.tanh, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, input_shape=(data.timesteps, data.features))) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(data.assets, activation=act.relu)) model.add(Dense(data.assets))</code> </pre> <br> 该模型没有任何不足之处，得分接近零（甚至略有减分）。 <br><br><h2> 时间卷积网络 </h2><br> 用于时间序列预测的更现代的神经网络解决方案是TCN。 这种拓扑的本质非常简单：我们采用一维卷积网络并将其应用于长度为t的序列。 更高级的选项使用具有不同膨胀的几个卷积层。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">从此处</a>复制了TCN实现（有时是在概念级别）（TCN堆栈可视化来自<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Wavenet文章</a> ）。 <br><br><img src="https://habrastorage.org/webt/rf/sb/-4/rfsb-4f0bydwgmhhkwvbrenuxu0.png"><br><br> 第一个相对成功的解决方案是该模型，该模型在TCN之上包括一个GRU层： <br><br><pre> <code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dense(data.assets, activation=act.relu))</code> </pre><br> 这样的模型产生得分＝ 0.27668。 稍加调整（TCN过滤器的数量，批量大小）并将t增加到100，我们已经得到0.41092： <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">16</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br> 接下来，我们添加标准化和辍学： <br><br><div class="spoiler">  <b class="spoiler_title">代号</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">channel_normalization</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> max_values = K.max(K.abs(x), <span class="hljs-number"><span class="hljs-number">2</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) + <span class="hljs-number"><span class="hljs-number">1e-5</span></span> out = x / max_values <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out model = Sequential() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data.timesteps &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>**i)) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) model.add(Flatten()) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: model.add(Flatten(input_shape=(data.timesteps, data.features))) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br></div></div><br> 应用此模型，包括在早期步骤中（t = 1），我们得到的分数= 0.53578。 <br><br><h2> 梯度提升机 </h2><br> 在这个阶段，这些想法结束了，我决定一开始就要做一些需要做的事情：看看其他参与者的公共决定。 大多数好的解决方案根本不使用神经网络，而是选择GBM。 <br><br> 梯度提升是一种ML方法，在输出时，我们得到了一组简单的模型（最常见的是决策树）。 由于存在大量此类简单模型，因此优化了损失函数。 例如，您可以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在此处</a>阅读有关梯度增强的更多信息。 <br><br> 在GBM的实现中，使用了<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">lightgbm-</a>一种Microsoft相当知名的框架。 <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">从这里</a>获取的模型和数据预处理得到的分数约为0.64： <br><br><div class="spoiler">  <b class="spoiler_title">代号</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prepare_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(marketdf, newsdf)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># a bit of feature engineering marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int) marketdf['bartrend'] = marketdf['close'] / marketdf['open'] marketdf['average'] = (marketdf['close'] + marketdf['open'])/2 marketdf['pricevolume'] = marketdf['volume'] * marketdf['close'] newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int) newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0]) newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount'] newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount'] # filter pre-2012 data, no particular reason marketdf = marketdf.loc[marketdf['time'] &gt; 20120000] # get rid of extra junk from news data droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence', 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass', 'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount'] newsdf.drop(droplist, axis=1, inplace=True) marketdf.drop(['assetName', 'volume'], axis=1, inplace=True) # combine multiple news reports for same assets on same day newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index() # join news reports to market data, note many assets will have many days without news data return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) import lightgbm as lgb print ('Training lightgbm') # money params = { "objective" : "binary", "metric" : "binary_logloss", "num_leaves" : 60, "max_depth": -1, "learning_rate" : 0.01, "bagging_fraction" : 0.9, # subsample "feature_fraction" : 0.9, # colsample_bytree "bagging_freq" : 5, # subsample_freq "bagging_seed" : 2018, "verbosity" : -1 } lgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0]) lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)</span></span></code> </pre><br></div></div><br> 这里的预处理已经包括新闻数据，并将它们与市场数据结合在一起（但是，天真地做，只考虑新闻中提到的所有资产代码之一）。 我将此预处理选项作为所有后续决策的基础。 <br><br> 通过添加一个小功能（firstMentionSentence，marketCommentary，sentimentClass），并用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ROC AUC</a>代替该指标，我们得到0.65389的分数。 <br><br><h2> 合奏 </h2><br> 下一个成功的决定是使用由神经网络模型和GBM组成的集合（尽管“集合”是两个模型的大名）。 通过对两个模型的预测取平均值来获得结果预测，从而应用软投票机制。 这项决定使分数为0.66879。 <br><br><h2> 探索性数据分析和特征工程 </h2><br> 开始的另一件事是EDA。 阅读了理解功能之间的相关性很重要之后，我们构建了这样一张图片（本节中的图片都是可单击的）： <br><br> <a href=""><img src="https://habrastorage.org/webt/hw/xl/b2/hwxlb2agjx113qtsyciwbeuulvk.png"></a> <br><br> 在这里可以清楚地看到，市场和新闻数据之间的相关性很高，但是，至少收益率的值至少与目标值相关。 由于数据表示时间序列，因此还应查看目标值的自相关： <br><br> <a href=""><img src="https://habrastorage.org/webt/gg/t_/ft/ggt_ftesggo-ro3hnbohztculz0.png"></a> <br><br> 可以看出，在10天的时间之后，依赖性显着下降。 考虑到仅延迟10天的功能（原始数据集中已包含这些功能），这可能是GBM运作良好的原因。 <br><br> 特征选择和预处理对于所有ML算法都是至关重要的。 让我们尝试使用自动方式来提取特征，即<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">主成分</a> <abbr title="主成分分析">分析</abbr> （ <abbr title="主成分分析">PCA</abbr> ）： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler market_x = market_data.loc[:,features] scaler = StandardScaler() scaler.fit(market_x) market_x = scaler.transform(market_x) pca = PCA(<span class="hljs-number"><span class="hljs-number">.95</span></span>) pca.fit(market_x) market_pca = pca.transform(market_x)</code> </pre><br> 让我们看一下PCA生成的功能： <br><br> <a href=""><img src="https://habrastorage.org/webt/oh/1e/a1/oh1ea1byez3dcgjpklh-6gbzvic.png"></a> <br><br> 我们发现该方法在我们的数据上效果不佳，因为新功能与目标值的最终相关性很小。 <br><br><h2> 微调以及是否需要 </h2><br> 许多ML模型都有相当多的超参数，即算法本身的“设置”。 可以手动选择它们，但也有自动选择机制。 对于后者，有一个<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">hyperopt</a>库，该库实现了两种匹配算法-随机搜索和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">树结构Parzen估计器（TPE）</a> 。 我试图优化： <br><br><ul><li>  lightgbm参数（算法类型，叶数，学习率等）， <br></li><li> 神经网络模型的参数（ <abbr title="时间卷积网络">TCN</abbr>过滤器的数量， <abbr title="门控循环单元">GRU</abbr>内存<abbr title="门控循环单元">块的</abbr>数量，辍学率，学习率，求解器类型）。 <br></li></ul><br> 结果，使用此优化发现的所有解决方案得分都较低，尽管它们在测试数据上效果更好。 可能是因为这样一个事实：考虑得分的数据与从训练中选择的验证数据不太相似。 因此，对于此任务，微调不是很合适，因为它会导致模型的重新训练。 <br><br><h2> 最终决定 </h2><br> 根据比赛规则，参赛者可以在最后阶段选择两种解决方案。 我的最终决定几乎相同，包含<abbr title="梯度提升机">GBM</abbr>和多层<abbr title="门控循环单元">GRU</abbr>两个模型的集合。 唯一的区别是，一种解决方案根本不使用新闻数据，而另一种解决方案仅使用神经网络模型使用新闻数据。 <br><br> 新闻数据解决方案： <br><br><img src="https://habrastorage.org/webt/lq/ql/g7/lqqlg7lzgqnkhjuvlakbvtwcmks.png"><br><div class="spoiler">  <b class="spoiler_title">进口货</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> p <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> kaggle.competitions <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> twosigmanews <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler, LabelEncoder <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, GRU, LSTM, Conv1D, Reshape, Flatten, SpatialDropout1D, Lambda, Input, Average <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, SGD, RMSprop <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> losses <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ls <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> activations <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> act <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> lgb</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">数据预处理</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># fix random from numpy.random import seed seed(42) from tensorflow import set_random_seed set_random_seed(42) env = twosigmanews.make_env() (market_train_df, news_train_df) = env.get_training_data() def cleanData(market_data, news_data):   market_data = market_data[(market_data['returnsOpenNextMktres10'] &lt;= 1) &amp; (market_data['returnsOpenNextMktres10'] &gt;= -1)]   return market_data, news_data def prepareData(marketdf, newsdf, scaler=None):   print('Preparing data...')     print('...preparing features...')   marketdf = marketdf.copy()   newsdf = newsdf.copy()   # a bit of feature engineering   marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int)   marketdf['bartrend'] = marketdf['close'] / marketdf['open']   marketdf['average'] = (marketdf['close'] + marketdf['open'])/2   marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']     newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int)   newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount']   newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount']   # filter pre-2012 data, no particular reason   marketdf = marketdf.loc[marketdf['time'] &gt; 20120000]     # get rid of extra junk from news data   droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',               'sentenceCount','bodySize','headlineTag', 'subjects','audiences',               'assetName', 'wordCount','sentimentWordCount', 'companyCount',                'coverage']   newsdf.drop(droplist, axis=1, inplace=True)   marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)     # unstack news   newsdf['assetCodes'] = newsdf['assetCodes'].apply(lambda x: x[1:-1].replace("'", ""))   codes = []   indices = []   for i, values in newsdf['assetCodes'].iteritems():       explode = values.split(", ")       codes.extend(explode)       repeat_index = [int(i)]*len(explode)       indices.extend(repeat_index)   index_df = p.DataFrame({'news_index': indices, 'assetCode': codes})   newsdf['news_index'] = newsdf.index.copy()   # Merge news on unstacked assets   news_unstack = index_df.merge(newsdf, how='left', on='news_index')   news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     # combine multiple news reports for same assets on same day   newsgp = news_unstack.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()     # join news reports to market data, note many assets will have many days without news data   res = p.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])   res.marketCommentary = res.marketCommentary.astype(float)     targetcol = 'returnsOpenNextMktres10'   target_presented = targetcol in res.columns   features = [col for col in res.columns if col not in ['time', 'assetCode', 'universe', targetcol]]     print('...scaling...')   if(scaler == None):       scaler = StandardScaler()       scaler = scaler.fit(res[features])   res[features] = scaler.transform(res[features])   print('...done.')   return type('', (object,), {       'scaler': scaler,       'data': res,       'x': res[features],       'y': (res[targetcol] &gt; 0).astype(int).values if target_presented else None,       'features': features,       'samples': len(res),       'assets': res['assetCode'].unique(),       'target_presented': target_presented   }) def generateTimeSeries(data, n_timesteps=1):     data.data[data.features] = data.data[data.features].fillna(data.data[data.features].mean())   #data.data[data.features] = data.data[data.features].fillna(0)   assets = data.data.groupby('assetCode', sort=False)     def grouper(n, iterable):       it = iter(iterable)       while True:          chunk = list(itertools.islice(it, n))          if not chunk:              return          yield chunk     def sample_generator():       while True:           for assetCode, days in assets:               x = days[data.features].values               y = (days['returnsOpenNextMktres10'] &gt; 0).astype(int).values if data.target_presented else None               for i in range(0, len(days) - n_timesteps + 1):                   yield (x[i: i + n_timesteps], y[i + n_timesteps - 1] if data.target_presented else 0)     def batch_generator(batch_size):       for batch in grouper(batch_size, sample_generator()):           yield tuple([np.array(t) for t in zip(*batch)])     n_samples = functools.reduce(lambda x,y : x + y, map(lambda t : 0 if len(t[1]) + 1 &lt;= n_timesteps else len(t[1]) - n_timesteps + 1, assets))   return type('', (object,), {       'gen': batch_generator,       'timesteps': n_timesteps,       'features': len(data.features),       'samples': n_samples,       'assets': list(map(lambda x: x[0], filter(lambda t : len(t[1]) + 1 &gt; n_timesteps, assets)))   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">神经网络模型</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   x2 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,<span class="hljs-number"><span class="hljs-number">13</span></span>:])(i)   x2 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x2)   x2 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x2)   x = Average()([x1, x2])   model = Model(inputs=i, outputs=x)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model_time_series</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)   batch_size = <span class="hljs-number"><span class="hljs-number">4096</span></span>     optimizer = RMSprop()     <span class="hljs-comment"><span class="hljs-comment"># define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505   def auc_roc(y_true, y_pred):       value, update_op = tf.metrics.auc(y_true, y_pred)       metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]       for v in metric_vars:           tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)       with tf.control_dependencies([update_op]):           value = tf.identity(value)           return value     model.compile(loss=ls.binary_crossentropy, optimizer=optimizer, metrics=['binary_accuracy', auc_roc])     print(model.summary())     print('Training model...')     if(val_data == None):       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           verbose=1)   else:       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           validation_data=val_data.gen(batch_size),           validation_steps=int(val_data.samples / batch_size),           verbose=1)   return type('', (object,), {       'predict': lambda x: model.predict_generator(x, steps=1)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">GBM模型</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)     params = {       <span class="hljs-string"><span class="hljs-string">"objective"</span></span> : <span class="hljs-string"><span class="hljs-string">"binary"</span></span>,       <span class="hljs-string"><span class="hljs-string">"metric"</span></span> : <span class="hljs-string"><span class="hljs-string">"auc"</span></span>,       <span class="hljs-string"><span class="hljs-string">"num_leaves"</span></span> : <span class="hljs-number"><span class="hljs-number">60</span></span>,       <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">-1</span></span>,       <span class="hljs-string"><span class="hljs-string">"learning_rate"</span></span> : <span class="hljs-number"><span class="hljs-number">0.01</span></span>,       <span class="hljs-string"><span class="hljs-string">"bagging_fraction"</span></span> : <span class="hljs-number"><span class="hljs-number">0.9</span></span>,  <span class="hljs-comment"><span class="hljs-comment"># subsample       "feature_fraction" : 0.9,  # colsample_bytree       "bagging_freq" : 5,        # subsample_freq       "bagging_seed" : 2018,       "verbosity" : -1 }     ds, val_ds = lgb.Dataset(data.x.iloc[:,:13], data.y), lgb.Dataset(val_data.x.iloc[:,:13], val_data.y)   print('...training...')   model = lgb.train(params, ds, 2000, valid_sets=[ds, val_ds], early_stopping_rounds=100, verbose_eval=100)   print('...done.')     return type('', (object,), {       'model': model,       'predict': lambda x: model.predict(x.iloc[:,:13], num_iteration=model.best_iteration)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">培训课程</b> <div class="spoiler_text"><pre> <code class="python hljs">n_timesteps = <span class="hljs-number"><span class="hljs-number">30</span></span> market_data, news_data = cleanData(market_train_df, news_train_df) dates = market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].unique() train = range(len(dates))[:int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates))] val = range(len(dates))[int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates)):] train_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[train])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &lt;= max(dates[train])]) val_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[val])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &gt; max(dates[train])], scaler=train_data_prepared.scaler) model_gbm = train_model(train_data_prepared, val_data_prepared) train_data_ts = generateTimeSeries(train_data_prepared, n_timesteps=n_timesteps) val_data_ts = generateTimeSeries(val_data_prepared, n_timesteps=n_timesteps) rnn = buildRNN(train_data_ts.timesteps, train_data_ts.features) model_rnn = train_model_time_series(rnn, train_data_ts, val_data_ts)</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">预言</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_predictions</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, template, model)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(hasattr(data, <span class="hljs-string"><span class="hljs-string">'gen'</span></span>)):       prediction = (model.predict(data.gen(data.samples)) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>)[:,<span class="hljs-number"><span class="hljs-number">-1</span></span>]   <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>:       prediction = model.predict(data.x) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>   predsdf = p.DataFrame({<span class="hljs-string"><span class="hljs-string">'ast'</span></span>:data.assets,<span class="hljs-string"><span class="hljs-string">'conf'</span></span>:prediction})   template[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>][template[<span class="hljs-string"><span class="hljs-string">'assetCode'</span></span>].isin(predsdf.ast)] = predsdf[<span class="hljs-string"><span class="hljs-string">'conf'</span></span>].values   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template day = <span class="hljs-number"><span class="hljs-number">1</span></span> days_data = p.DataFrame({}) days_data_len = [] days_data_n = p.DataFrame({}) days_data_n_len = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (market_obs_df, news_obs_df, predictions_template_df) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> env.get_prediction_days():   print(<span class="hljs-string"><span class="hljs-string">f'Predicting day </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{day}</span></span></span><span class="hljs-string">'</span></span>)   days_data = p.concat([days_data, market_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_len.append(len(market_obs_df))   days_data_n = p.concat([days_data_n, news_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_n_len.append(len(news_obs_df))   data = prepareData(market_obs_df, news_obs_df, scaler=train_data_prepared.scaler)   predictions_df = make_predictions(data, predictions_template_df.copy(), model_gbm)   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(day &gt;= n_timesteps):       data = prepareData(days_data, days_data_n, scaler=train_data_prepared.scaler)       data = generateTimeSeries(data, n_timesteps=n_timesteps)       predictions_df_s = make_predictions(data, predictions_template_df.copy(), model_rnn)       predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] = (predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] + predictions_df_s[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>]) / <span class="hljs-number"><span class="hljs-number">2</span></span>       days_data = days_data[days_data_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_n = days_data_n[days_data_n_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_len = days_data_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]       days_data_n_len = days_data_n_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]   env.predict(predictions_df)   day += <span class="hljs-number"><span class="hljs-number">1</span></span> env.write_submission_file()</code> </pre><br></div></div><br> 没有新闻数据的解决方案： <br><br><img src="https://habrastorage.org/webt/m8/vr/05/m8vr05gvobi5ffv6qrb5rz0zzqq.png"><br><br><div class="spoiler">  <b class="spoiler_title">代码（只是一种不同的方法）</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br></div></div><br> 在第一阶段的比赛中，两个决定都给出了相似的结果（约0.69），相当于2,927名中的566名。在新数据发布的第一个月后，参与者列表中的位置被混合使用，新闻数据的解决方案在其余697个团队中排名第65位，结果为3.19251，未来五个月内将会发生什么，没人知道。 <br><br><h2> 我还尝试了什么 </h2><br><h3> 自定义指标 </h3><br> 由于决策是使用Sharpe比率进行评估的，因此尝试将其用作提前终止培训的指标是合乎逻辑的。 <br><br>  lightgbm的指标： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sharpe_metric</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_pred, train_data)</span></span></span><span class="hljs-function">:</span></span> y_true = train_data.get_label() * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span> std = np.std(y_true * y_pred) mean = np.mean(y_true * y_pred) sharpe = np.divide(mean, std, out=np.zeros_like(mean), where=std!=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"sharpe"</span></span>, sharpe, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br> 验证显示，在此问题上，这种度量比AUC效果更差。 <br><br><h3> 注意机制 </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">注意机制</a>允许神经网络专注于源数据中的“最重要”特征。 从技术上讲，注意力由权重向量表示（最常见的是使用具有<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">softmax</a>激活的完全连接层获得的权重），再乘以另一层的输出。 我使用了一种将注意力放在时间轴上的实现： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>     <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">attention_3d_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs)</span></span></span><span class="hljs-function">:</span></span>       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(inputs)       a = Dense(timesteps, activation=act.softmax)(a)       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(a)       mul = Multiply()([inputs, a])       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mul     i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br> 这个模型看起来很漂亮，但是这种方法并没有增加分数，结果大约是0.67。 <br><br><h2> 没时间做什么 </h2><br> 看起来很有希望的几个领域： <br><br><ul><li> 更具体地讲<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">，注意机制</a> <br></li><li> 尝试使用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">自动编码器</a> ， <br></li><li> 尝试<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在线学习</a> <br></li><li> 认真处理新闻和市场数据的集成以及预处理新闻。 <br></li></ul><br><h2> 结论 </h2><br> 我们的冒险之旅已经结束，您可以尝试总结一下。 比赛原来很艰难，但我们无法面对尘土。 这表明进入ML的门槛并不高，但是，就像在任何行业中一样，专业人士已经可以使用真正的魔力（并且在机器学习中有很多魔力）。 <br><br> 结果数量： <br><br><ul><li> 第一阶段的最高分：〜0.69，而第一名则为〜1.5。 像医院的平均水平一样，0.7被一些人克服了，公共决策的最高分也达到了0.69，比我的略高。 <br></li><li> 处于第一阶段的位置：2927年为566。 <br></li><li> 第二阶段的得分：第一个月后的得分3.19251。 <br></li><li> 第二阶段排名：第一个月后的697分中有65分。 <br></li></ul><br> 我提请您注意以下事实：第二阶段的数字并没有特别讨论任何问题，因为用于定性评估决策的数据仍然很少。 <br><br><h2> 参考文献 </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">使用新闻的最终解决方案</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">两个西格玛：使用新闻预测股票走势</a> -比赛页面 <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Keras-</a>神经<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">网络框架</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">LightGBM</a> -GBM框架 <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Scikit-learn-</a>机器学习算法库 <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Hyperopt-</a>用于优化超参数的库 <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">关于WaveNet的文章</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN440026/">https://habr.com/ru/post/zh-CN440026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN440016/index.html">当可以触摸阅读时：ONYX BOOX基督山4评论</a></li>
<li><a href="../zh-CN440018/index.html">动态局部曝光</a></li>
<li><a href="../zh-CN440020/index.html">测试中的回归或回归</a></li>
<li><a href="../zh-CN440022/index.html">小法拉利：金融科技创业公司Rally Rd将让您购买稀有汽车的“股份”</a></li>
<li><a href="../zh-CN440024/index.html">从STM32将printf（）重定向到Qt Creator控制台</a></li>
<li><a href="../zh-CN440030/index.html">使用WireGuard和DNSCrypt在OpenWrt路由器上精确定位PKH阻止</a></li>
<li><a href="../zh-CN440032/index.html">人工智能地平线零黎明</a></li>
<li><a href="../zh-CN440034/index.html">吻建筑。 从微服务到整体</a></li>
<li><a href="../zh-CN440036/index.html">触摸打字</a></li>
<li><a href="../zh-CN440040/index.html">在发展中-各自为战。 但是有时候这会导致死胡同。</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
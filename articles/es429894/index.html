<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ùóÔ∏è üî´ üë®üèø‚Äçü§ù‚Äçüë®üèª Usando un ojo de pez en una Raspberry Pi 3 con ROS - Parte 2 üßù üêî ü§±üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Buenas tardes queridos lectores de Habr! Esta es la segunda parte de la historia sobre el uso de la c√°mara de ojo de pez en el Raspberry Pi 3. La prim...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Usando un ojo de pez en una Raspberry Pi 3 con ROS - Parte 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429894/">  Buenas tardes queridos lectores de Habr!  Esta es la segunda parte de la historia sobre el uso de la c√°mara de ojo de pez en el Raspberry Pi 3. La primera parte se puede encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> .  En este art√≠culo, hablar√© sobre calibrar una c√°mara de ojo de pez y usar la c√°mara para detectar objetos usando el paquete find_object_2d.  A qui√©n le importa, por favor, debajo del gato. <br><a name="habracut"></a><br>
<h2>  Calibre una c√°mara de ojo de pez usando camera_calibration </h2><br>  Aqu√≠ describo el procedimiento de calibraci√≥n basado en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">manual</a> oficial en el portal ros.org. <br><br>  Para realizar la calibraci√≥n, necesitamos el paquete de calibraci√≥n de la c√°mara.  Podemos instalarlo con apt: <br><br><pre><code class="bash hljs">sudo apt-get install ros-kinetic-camera-calibration</code> </pre> <br>  Necesitaremos una plantilla de tablero de ajedrez.  Descargue la plantilla del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">manual</a> oficial en ros.org e impr√≠mala.  Por conveniencia, lo pegu√© en una tabla de madera contrachapada: <br><br><img src="https://habrastorage.org/webt/cz/qp/g8/czqpg8rutw1ut-h7ogrjqxwnytk.jpeg" alt="imagen"><br><br>  Ejecutemos el programa de calibraci√≥n: <br><br><pre> <code class="bash hljs">rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.108 image:=/usb_cam/image_raw camera:=/usb_cam</code> </pre><br>  Tendremos una foto: <br><br><img src="https://habrastorage.org/webt/_n/t0/ib/_nt0ib2ohbvxtk8lomsx197swke.png" alt="imagen"><br><br>  Mueva la plantilla un poco y espere hasta que la plantilla se seleccione en el marco (las l√≠neas de color con puntos no aparecer√°n en la plantilla). <br><br><img src="https://habrastorage.org/webt/dm/du/yn/dmduyniktnl1joqutysbtv9ugf8.png" alt="imagen"><br><br><img src="https://habrastorage.org/webt/ir/w3/fq/irw3fq6yv4z-bfzictvsqlht93c.png" alt="imagen"><br><br>  Mueva la plantilla un poco m√°s hacia un lado.  Para realizar con √©xito la calibraci√≥n, necesitamos realizar una serie de movimientos de la plantilla frente a la c√°mara de lado a lado para que la plantilla caiga en todas las posiciones angulares en el campo de visi√≥n de la c√°mara (izquierda, derecha, arriba y abajo).  A la derecha de la ventana de imagen de la c√°mara en la ventana del programa se encuentra el panel de registro con tres barras de progreso: <br><br><ul><li>  X captura el movimiento del patr√≥n en la direcci√≥n izquierda / derecha (horizontal) en el campo de visi√≥n de la c√°mara </li><li>  Y captura el movimiento del patr√≥n en la direcci√≥n arriba / abajo (horizontal) en el campo de visi√≥n de la c√°mara </li><li>  El tama√±o captura el enfoque / eliminaci√≥n de la plantilla de la c√°mara y la inclinaci√≥n con respecto a la c√°mara. </li><li>  Inclinaci√≥n fija la pendiente de la plantilla hacia la izquierda, derecha, arriba y abajo (bisel). </li></ul><br>  Por lo tanto, para una calibraci√≥n exitosa, es importante que la plantilla aparezca en diferentes esquinas del marco, ocupe todo el marco y tambi√©n se incline hacia la izquierda, derecha, arriba y abajo. <br><br>  Calibrar una c√°mara de ojo de pez en su Raspberry Pi puede llevar bastante tiempo, as√≠ que sea paciente.  Mi procedimiento de calibraci√≥n tom√≥ 20 minutos. <br><br>  Cuando se completa la calibraci√≥n, se debe activar el bot√≥n Calibrar (resaltado en color): <br><br><img src="https://habrastorage.org/webt/lq/d-/d2/lqd-d26xbjyaishe5noij5oan1k.png" alt="imagen"><br><br>  Tambi√©n podemos ver los resultados de la calibraci√≥n en el terminal: <br><br><img src="https://habrastorage.org/webt/5c/jv/kt/5cjvktr9rxlpwwfq0kfk1kk3b7o.png" alt="imagen"><br><br>  Si est√° satisfecho con el resultado, presione el bot√≥n COMMIT.  La ventana del programa se cerrar√° y ver√° el mensaje "escribiendo datos de calibraci√≥n en ..." en el terminal. <br><br>  Verifique que se haya creado el archivo especificado: <br><br><pre> <code class="bash hljs">ll ~/.ros/camera_info/head_camera.yaml -rw-rw-r-- 1 vladimir vladimir 592 Apr 14 14:02 /home/vladimir/.ros/camera_info/head_camera.yaml</code> </pre><br>  Calibraci√≥n completada.  Ahora los datos de calibraci√≥n obtenidos se pueden usar en localizaci√≥n visual y algoritmos SLAM en ROS. <br><br><h2>  Detectar objetos usando find_object_2d </h2><br>  Instalar el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">paquete es</a> bastante simple.  Inst√°lelo desde el repositorio de apt en Ubuntu 16.04 para ROS Kinetic: <br><br><pre> <code class="bash hljs">sudo apt-get install ros-kinetic-find-object-2d <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> /opt/ros/kinetic/setup.bash</code> </pre><br>  Ejecute ROS master y rqt_image_view: <br><br><pre> <code class="bash hljs">roscore roslaunch usb_cam usb_cam-test.launch</code> </pre><br>  Con el siguiente comando, inicie el nodo del detector: <br><br><pre> <code class="bash hljs">rosrun find_object_2d find_object_2d image:=/usb_cam/image_raw</code> </pre><br>  Se abre la ventana del programa de detecci√≥n: <br><br><img src="https://habrastorage.org/webt/6l/_u/kb/6l_ukb-8wjw2cylfuloapxtpdzk.png" alt="imagen"><br><br>  Aqu√≠ veremos el flujo de la c√°mara y el resultado de la detecci√≥n de caracter√≠sticas en los objetos. <br>  Para comenzar, llevaremos a cabo la capacitaci√≥n de detectores en nuestras instalaciones.  Coloque el primer objeto frente a la c√°mara: <br><br><img src="https://habrastorage.org/webt/2y/hs/nb/2yhsnbkbcr9452owc41wpl_yzxs.png" alt="imagen"><br><br>  Haga clic derecho en el panel izquierdo de los Objetos en la ventana y se abrir√° la opci√≥n Agregar objetos de la escena.  Seleccione esta opci√≥n y se abrir√° la ventana para agregar un objeto: <br><br><img src="https://habrastorage.org/webt/r3/ey/56/r3ey56zvh_td0ap_etfqdi-nvem.png" alt="imagen"><br><br>  Despu√©s de elegir la mejor posici√≥n para el objeto, haga clic en el bot√≥n Tomar foto para tomar una foto del objeto: <br><br><img src="https://habrastorage.org/webt/ao/h6/qk/aoh6qkj0aktn86zjxmwlyn-stg4.png" alt="imagen"><br><br>  Necesitamos seleccionar el objeto en la imagen.  Use el cursor del mouse para seleccionar el objeto: <br><br><img src="https://habrastorage.org/webt/ar/l-/6c/arl-6c6qqj88nxbrh1sh7w3fhxw.png" alt="imagen"><br><br>  Haga clic en el bot√≥n Siguiente para recortar el objeto en la imagen y pasar al siguiente paso.  Despu√©s de recortar la imagen, obtenemos el n√∫mero total de rasgos caracter√≠sticos detectados en el objeto.  Solo queda presionar el bot√≥n Finalizar para agregar el objeto a la base de datos de objetos detectores entrenados.  Aqu√≠ vemos el √∫ltimo paso del procedimiento para agregar un objeto: <br><br><img src="https://habrastorage.org/webt/ma/jh/pa/majhpayey9z1nntt0i4eaegq6jq.png" alt="imagen"><br><br>  Como resultado, entrenamos el detector en un objeto.  Ahora puede intentar la detecci√≥n del objeto en la escena: <br><br><img src="https://habrastorage.org/webt/q6/vb/7u/q6vb7uerpmydbkvpncoz3buc5d8.png" alt="imagen"><br><br>  Dibujemos la posici√≥n del objeto detectado en la terminal: <br><br><pre> <code class="bash hljs">rosrun find_object_2d print_objects_detected</code> </pre><br>  La salida ser√° as√≠: <br><br><pre> <code class="bash hljs">Object 1 detected, Qt corners at (259.387238,103.530960) (448.684052,79.495495) (282.419050,240.049667) (458.438938,199.656717) --- Object 1 detected, Qt corners at (255.340408,104.615120) (451.348079,75.302353) (284.672425,230.382223) (452.696585,197.625600) --- Object 1 detected, Qt corners at (253.440521,102.973320) (447.226440,76.793541) (278.530854,238.918013) (454.377219,197.526599) ---</code> </pre><br>  Hagamos una lista de los temas: <br><br><pre> <code class="bash hljs">rostopic list</code> </pre><br>  Dos nuevos temas aparecieron en la lista: / objects y / objectsStamped. <br><br>  Mostramos informaci√≥n sobre los objetos detectados: <br><br><pre> <code class="bash hljs">rostopic <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> /objects</code> </pre><br><pre> <code class="bash hljs">layout: dim: [] data_offset: 0 data: [1.0, 266.0, 177.0, 0.7527905702590942, 0.060980819165706635, 0.00022385441116057336, 0.3012462854385376, 0.8929792046546936, 0.0008534671505913138, 334.9065856933594, 182.55294799804688, 1.0] ---</code> </pre><br>  Aqu√≠, los valores segundo y tercero (266.0, 177.0) representan el ancho y la altura del objeto.  Todos los dem√°s valores en el campo de datos representan una matriz de homograf√≠a 3x3 (utilizada para calcular la posici√≥n y orientaci√≥n del objeto, as√≠ como los valores de escala y desplazamiento). <br><br>  Como muestran las observaciones, find_object_2d hace un mal trabajo al detectar objetos con una textura d√©bil o sin textura (sin textura).  Adem√°s, el detector no es efectivo cuando detecta un objeto en un √°ngulo grande con respecto al objeto (si observamos el objeto desde el costado), o a una gran distancia del objeto. <br><br><img src="https://habrastorage.org/webt/pk/1f/ot/pk1fotpptvtwoym3g6p5g3lfgty.png" alt="imagen"><br><br>  Despu√©s de completar el trabajo con el detector, find_object_2d nos ofrecer√° guardar los objetos agregados en el disco. <br><br>  Eso es todo por ahora.  ¬°Buena suerte a todos y hasta pronto! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es429894/">https://habr.com/ru/post/es429894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es429882/index.html">Control de LED RGB a trav√©s de microcontroladores Cypress UDB PSoC</a></li>
<li><a href="../es429884/index.html">Conferencia PROSTOR 2018: preguntas y respuestas sobre el futuro del almacenamiento</a></li>
<li><a href="../es429888/index.html">Calculadora basada en pila en la placa FPGA Cyclone IV</a></li>
<li><a href="../es429890/index.html">Webinar abierto "Redes de confrontaci√≥n generativas"</a></li>
<li><a href="../es429892/index.html">xonsh - python como reemplazo de shell</a></li>
<li><a href="../es429898/index.html">DMS (Sistema de gesti√≥n de concesionarios): implementaci√≥n de los ecosistemas de informaci√≥n para la gesti√≥n de redes de concesionarios</a></li>
<li><a href="../es429902/index.html">Page Rank en la era de la Web 2.0 - Parte 1</a></li>
<li><a href="../es429904/index.html">Historias divertidas y tristes sobre el desarrollo de juegos de computadora</a></li>
<li><a href="../es429908/index.html">C√≥mo usar corutinas en la comida y dormir tranquilo por la noche</a></li>
<li><a href="../es429910/index.html">AppsConf Rises</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸˆ ğŸ‘¨ğŸ¿â€âš•ï¸ ğŸ‘¨ğŸ»â€ğŸ”§ Metode pembagian dua bagian dalam pengujian ğŸ‘©ğŸ¼â€ğŸ”¬ ğŸ‘©ğŸ¾â€ğŸ¨ ğŸ•Ÿ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Isi 


- Deskripsi Metode 
- Aplikasi oleh penguji Baris data File 
- Baris data 
- File 
- Aplikasi oleh pengembang 
- Ringkasan 
 Terkadang bug send...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Metode pembagian dua bagian dalam pengujian</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/468087/"><h2>  Isi </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Deskripsi Metode</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Aplikasi oleh penguji</a> <br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Baris data</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">File</a> </li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Aplikasi oleh pengembang</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Ringkasan</a> </li></ul><br>  Terkadang bug sendiri menemukan kita.  Jadi kami mendorong sederet data besar - dan sistem terhenti.  Apakah karena 1 juta karakter yang jatuh?  Atau apakah dia suka yang tertentu? <br><br>  Atau file diunggah ke sistem dan macet.  Mengapa  Karena nama, ekstensi, data di dalam atau ukuran?  Anda dapat mendorong pelokalan ke pengembang, biarkan dia berpikir apa yang buruk dalam file.  Namun seringkali Anda dapat menemukan alasannya sendiri, dan kemudian lebih akurat menggambarkan masalahnya. <br><br>  Jika Anda menemukan data minimum untuk dimainkan, maka: <br><br><ul><li>  Anda akan menghemat waktu untuk pengembang - ia tidak perlu terhubung ke test stand, memuat file sendiri dan debut </li><li>  Manajer akan dapat dengan mudah menilai prioritas tugas - apakah perlu segera diperbaiki, atau bisakah bug menunggu?  Sementara nama "beberapa file jatuh, mengapa xs" sulit dilakukan ... </li><li>  Deskripsi bug dari memahami penyebab musim gugur juga akan bermanfaat. </li></ul><br>  Bagaimana cara menemukan data minimum untuk memainkan bug?  Jika ada petunjuk dalam log, terapkan.  Jika tidak ada petunjuk, maka metode terbaik adalah metode pembagian dua bagian (juga dikenal sebagai metode "pembelahan dua" atau "dikotomi"). <br><a name="desc"></a><br><h2>  Deskripsi Metode </h2><br>  Metode ini digunakan untuk menemukan tempat musim gugur yang tepat: <br><br><ol><li>  Ambil paket data yang jatuh. </li><li>  Hancurkan menjadi dua. </li><li>  Periksa setengah 1 <br><br><ul><li>  Jika jatuh, maka masalahnya ada di sana.  Kami bekerja lebih jauh dengannya. </li><li>  Jika tidak jatuh â†’ periksa setengah 2. </li></ul></li><li>  Ulangi langkah 1-3 hingga satu nilai jatuh tetap ada. </li></ol><br><img src="https://habrastorage.org/webt/3p/9c/f-/3p9cf-cfekl63ojwbskywttrowu.png"><br><br>  Metode ini memungkinkan Anda untuk melokalisasi masalah dengan cepat, terutama jika dilakukan secara terprogram.  Pengembang mengintegrasikan mekanisme tersebut ke dalam pemrosesan data.  Dan jika mereka tidak membangunnya, maka mereka sendiri menderita kemudian ketika penguji datang kepada mereka dan berkata, "Itu jatuh pada file ini, tetapi saya tidak dapat menemukan alasan yang tepat." <br><a name="habracut"></a><br><a name="test"></a><br><h2>  Aplikasi oleh penguji </h2><br><a name="string"></a><br><h3>  Baris data </h3><br>  Memuat satu baris data 1 juta - sistem membeku. <br>  Kami mencoba 500 ribu (terbagi dua) - masih hang. <br>  Kami mencoba 250 ribu - tidak menggantung, semuanya baik-baik saja. <br><br>  â†“ <br><br>  Oleh karena itu kesimpulan bahwa masalahnya ada di suatu tempat antara 250 dan 500 ribu .. Sekali lagi kami menerapkan pembagian dua bagian. <br><br>  Kami mencoba 350 ribu (membaginya "dengan mata" - cukup diizinkan, Anda tidak harus berlari ke angka yang tepat ketika bermain secara manual) - semuanya baik <br>  Kami mencoba 450 ribu - ini buruk. <br>  Kami mencoba 400 ribu - ini buruk. <br><br>  â†“ <br><br>  Secara umum, Anda sudah bisa mendapatkan bug.  Sangat jarang diperlukan dari penguji untuk melaporkan bahwa perbatasan atau bug jelas dalam angka 286 586. Cukup cukup untuk melokalisasi kira-kira - 290 ribu. <br><br>  Hanya satu hal untuk memeriksa "10" dan segera "300 ribu", dan sama sekali berbeda untuk memberikan informasi yang lebih lengkap: "hingga 10 ribu semuanya baik-baik saja, mulai 10 hingga 280 ribu rem dimulai, sudah turun menjadi 290 ribu". <br><br>  Jelas bahwa ketika kuantitas diukur dalam ribuan, akan terlalu lama untuk mencari wajah tertentu secara manual.  Ya, pengembang tidak membutuhkan ini.  Nah, tidak ada yang mau membuang waktu dengan sia-sia. <br><br><img src="https://habrastorage.org/webt/el/eg/de/elegdeql-ebnkuuveicpqye9pqo.png"><br><br>  Tentu saja, jika masalah aslinya ada pada garis dengan panjang 10-30 karakter, Anda dapat menemukan batas yang tepat.  Itu semua masalah hubungan yang wajar dengan waktu - jika menggunakan menebak atau membagi dua, Anda dapat dengan cepat menemukan nilai yang tepat dan itu kecil (hingga 100 biasanya) - kami mencari pasti.  Jika masalahnya ada pada jalur yang besar, lebih dari 1000 â†’ cari kira-kira. <br><a name="file"></a><br><h3>  File </h3><br>  Mengunggah file - macet!  Bagaimana, mengapa?  Pertama, kami mencoba menganalisis untuk diri kami sendiri apa yang dapat memengaruhi tes yang kami uji?  Ini adalah chip aturan utama "pertama positif, kemudian negatif."  Jika Anda tidak mencoba memasukkan semuanya ke dalam satu tes sekaligus: <br><br><ul><li>  Memeriksa file sampel kecil </li><li>  Kami memeriksa file 2GB besar, dengan banyak kolom, banyak kolom, ditambah variasi data internal yang berbeda </li></ul><br>  Akan sulit untuk dilokalisasi di sini.  Dan jika Anda memisahkan cek: <br><br><ul><li>  Banyak baris (tetapi datanya positif dan diverifikasi sebelumnya) </li><li>  Banyak kolom </li><li>  Beban berat </li><li>  ... </li></ul><br>  Itu kira-kira sudah bisa dimengerti, apa alasannya.  Misalnya, jatuh pada sejumlah besar garis - dari 100 ribu.  Oke, kami sedang mencari perbatasan yang lebih akurat menggunakan pembagian dua bagian: <br><br><ul><li>  Kami membagi file menjadi dua oleh 50 ribu, memeriksa yang pertama. </li><li>  Jika Anda jatuh, bagilah </li><li>  Maka, sampai kita menemukan tempat khusus untuk jatuh </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/s1/t_/xn/s1t_xngwtntmh0hhlvvkgwz6p9q.png"></div><br>  Jika penurunan tergantung pada jumlah garis, kami mencari batas perkiraan: "Setelah 5.000 jatuh, tidak ada 4000 ribu."  Mencari tempat tertentu (4589) tidak perlu.  Terlalu lama dan tidak sepadan dengan waktu. <br><br><blockquote>  Bug ini ditemukan oleh siswa di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dadat</a> .  File data dapat dimuat di sana, sistem akan memproses dan menstandarisasi data ini: kesalahan ketik yang benar, menentukan informasi yang hilang dari direktori (kode KLADR, FIAS, koordinat geografis, distrik kota, kode pos ...). <br><br>  Gadis itu mencoba mengunduh file besar dan mendapatkan hasilnya: sistem menunjukkan bilah progres pada 100% beban dan hang lebih dari 30 menit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/-m/tb/78/-mtb78f5xzib4lpt-xiyf2yukha.jpeg"></div><br>  Lokalisasi melangkah lebih jauh - kapan pembekuan dimulai?  Ini penting karena memengaruhi prioritas tugas.  Berapa ukuran unduhan yang umum?  Seberapa sering pengguna mengirimkan LOTS langsung? <br><br>  Mungkin sistem ini dirancang untuk memproses ribuan baris, kemudian bug semacam itu dijejalkan ke "Perbaiki suatu hari".  Atau unduhan biasa - 10-50 ribu baris yang memproses secara normal, yah, itu berarti bug tidak menyala, kami akan memperbaikinya nanti. <br><br>  Pelokalan tugas: <br><br><ul><li>  untuk file dengan 50 ribu baris, 15 detik hang, </li><li>  untuk file dengan 100 ribu baris, 30 detik hang, </li><li>  untuk file dengan 150 ribu baris, 1 menit hang, </li><li>  untuk file dengan 165 ribu baris hang 4 menit, </li><li>  untuk file 172 ribu baris dengan 100% progress bar penuh membeku selama lebih dari setengah jam </li></ul><br>  Di sinilah pekerjaan penguji sudah dilakukan secara kualitatif.  Informasi lengkap diberikan tentang pengoperasian sistem, atas dasar yang mana manajer dapat menyimpulkan betapa mendesaknya diperlukan untuk memperbaiki bug. <br><br>  Verifikasi juga tidak memakan banyak waktu.  Anda dapat pergi atau dari akhir - di sini kami telah mengunduh 200 ribu baris, dan kapan masalahnya dimulai?  Kami menggunakan metode pembagian dua bagian! <br><br>  Atau mulai dengan jumlah yang relatif kecil - 50 ribu, secara bertahap meningkat (setengahnya, metode pembagian dua bagian, justru sebaliknya).  Mengetahui bahwa semuanya akan menjadi buruk pada 200 ribu, kami memahami bahwa tidak akan ada banyak tes.  Kami memeriksa 50, 100, 150 - untuk tiga tes kami menemukan batas perkiraan.  Dan kemudian menggali tidak lagi diperlukan. <br></blockquote><br>  Tetapi ingat bahwa Anda juga perlu menguji teori Anda.  Benarkah masalahnya ada pada jumlah baris, dan bukan data di dalam file?  Memeriksa ini sangat mudah - buat file 5000 baris dengan satu nilai "positif".  Nilai itu yang tepatnya berfungsi yang sudah Anda periksa sebelumnya.  Jika tidak ada jatuh, maka masalahnya adalah najis =)) Tampaknya teori jumlah baris salah dan masalahnya ada di data itu sendiri. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vy/sb/de/vysbde5vdjztq6dnntm9os8xpoy.png"></div><br>  Meskipun Anda dapat mencoba 10 ribu baris dengan nilai positif.  Mungkin saja kejatuhan akan terjadi lagi.  Hanya file sumber Anda ada di beberapa kolom.  Atau ada karakter di dalamnya yang mengambil byte lebih dari nilai positif ... Secara umum, jangan langsung menolak teori ukuran file atau jumlah baris.  Coba pembagian dua bagian sebaliknya - gandakan file. <br><br>  Tetapi bagaimanapun juga, ingatlah bahwa semakin banyak cek tercampur dalam satu, semakin sulit untuk melokalisasi bug.  Oleh karena itu, lebih baik untuk segera menguji jumlah baris atau kolom pada nilai positif tunggal.  Sehingga Anda yakin bahwa Anda menguji jumlah data, bukan data itu sendiri.  Analisis uji dan semua itu =) <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/f1/qc/wr/f1qcwrou3aj-wein9ymrhkg6jiq.png"></div><br>  Tetapi bagaimana jika masalahnya bukan pada jumlah baris, tetapi pada data itu sendiri?  Dan Anda tidak tahu persis di mana.  Mungkin Anda menjejalkan data dari "War and Peace" ke dalam file uji, atau mengunduh spreadsheet besar dari suatu tempat di Internet ... Atau pengguna menemukan masalah sama sekali - ia mengunggah file-nya dan semuanya jatuh.  Dia datang untuk mendukung, dukungan datang kepada Anda: file ada pada Anda, mainkan. <br><br>  Tindakan selanjutnya tergantung pada situasinya.  Jika tenggat waktu pengguna berjalan atau uang didebit darinya, dan kemudian pemrosesan file telah jatuh, maka ini adalah bug pemblokir.  Dan tidak ada waktu untuk melatih penguji pelokalan.  Lebih mudah untuk memberikan file yang jatuh ke pengembang, biarkan dia bebas dan temukan alasannya sendiri. <br><br>  Tetapi jika Anda sendiri menemukan kesalahan, yaitu waktu untuk menggali sendiri.  Sekali lagi, jangan lupa akal sehat, seperti biasa dengan lokalisasi.  Awalnya kami mencoba menarik kesimpulan sendiri, lalu meminta bantuan.  Untuk membuat kesimpulan sendiri, Anda perlu: <br><br><ul><li>  periksa log, mungkin ada jawaban yang tepat; </li><li>  melihat isi file: sesuatu mungkin menarik perhatian Anda, itulah teori pertama; </li><li>  gunakan metode pembagian dua bagian. </li></ul><br>  Akibatnya, alih-alih bug â€œFalls file, mengapa xs, ini adalah lampiran file 2GBâ€, Anda meletakkan bug yang dipikirkan dengan baik dan dilokalkan: â€œFile jatuh jika tanggal format DD / MM / YYYYY ada di dalamâ€.  Dan kemudian Anda tidak perlu file 2GB, Anda hanya perlu satu file untuk satu baris dan satu kolom! <br><br><img src="https://habrastorage.org/webt/dv/tj/5n/dvtj5nacjhowgbwxhdx74cd1ea8.png"><br><a name="prog"></a><br><h2>  Aplikasi oleh pengembang </h2><br>  Pada sejumlah besar data, tester tidak mencari batas yang jelas, karena tidak masuk akal untuk melakukan ini secara manual.  Tetapi pengembang menggunakan metode pembagian dua bagian dalam kode dan selalu dapat menemukan tempat tertentu untuk jatuh.  Bagaimanapun, sistem akan membagi kemenangan, dan bukan seseorang! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ab/1q/am/ab1qamsk9ygow7dvurjbygxbueu.png"></div><br>  Sebagai contoh, kami memiliki mekanisme untuk memuat data ke dalam sistem.  Itu bisa memuat 10 ribu satu juta.  Tapi ini tidak masalah, karena unduhannya ada dalam 200 entri.  Jika ada yang salah, sistem itu sendiri melakukan pembagian dua bagian.  Itu sendiri.  Sampai menemukan tempat masalah.  Kemudian baca di log: <br><br><blockquote><ul><li>  Mendapat 1.000 entri </li><li>  200 catatan yang diproses </li><li>  Diproses 400 catatan </li><li>  Ups, jatuh di atas tumpukan 200 rekaman! </li><li>  Saya mencoba memproses satu pak ukuran 100 </li><li>  Saya mencoba memproses satu pak ukuran 50 </li><li>  Saya mencoba memproses satu pak ukuran 25 </li></ul><br>  ... <br><ul><li>  Kesalahan pada pengidentifikasi seperti itu: bidang Email yang diperlukan tidak diisi </li><li>  600 catatan yang diproses </li></ul><br>  ... </blockquote><br>  Di sini, tentu saja, logika selanjutnya juga tergantung pada pengembangnya.  Entah pemrosesan berhenti setelah menemukan kesalahan, atau melangkah lebih jauh.  Tersandung pada paket 200 entri?  Kami sampai pada titik menemukan kemacetan, menandai entri sebagai salah, memproses 199 yang tersisa, dan melanjutkan. <br><br>  Tetapi bagaimana jika seluruh paket berantakan?  Kami menandai catatan sebagai salah, tetapi 199 sisanya juga tidak dapat diproses.  Mengapa  Kami menerapkan metode yang sama, mencari masalah baru.  Caranya adalah Anda selalu harus bisa berhenti tepat waktu. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mu/1v/ir/mu1viryveqlw6vqmexnqjirg2ke.png"></div><br>  Jika jumlah kesalahan lebih dari 10-50-100, maka lebih baik menghentikan pengunduhan.  Mungkin saja terjadi kesalahan unggahan di sistem asli dan kami menerima sejuta "kurva" data.  Jika sistem akan membagi setiap paket dari 200 catatan menjadi dua, dan kemudian membagi 199 sisanya, dan seterusnya, maka itu akan buruk bagi semua orang: <br><br><ul><li>  Log tumbuh dari 15 mb menjadi 3 gb dan menjadi tidak dapat dibaca; </li><li>  Sistem mungkin macet saat mencoba membuat pesan kesalahan akhir (saya berbicara tentang situasi ini di bagian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">BMW Mnemonics</a> ); </li><li>  Banyak waktu dihabiskan untuk mencari semua kesalahan.  Ya, sistem melakukan ini lebih cepat daripada seseorang, tetapi jika Anda membagi satu juta paket dari 200 catatan, itu akan memakan waktu. </li></ul><br>  Jadi otak harus dimasukkan di mana-mana - baik dalam pengujian manual dan saat menulis kode program.  Anda harus selalu mengerti kapan harus berhenti.  Hanya dalam kasus pengujian manual akan "menemukan perbatasan", dan dalam pengembangan "berhenti jika ada banyak jatuh". <br><a name="itogo"></a><br><h3>  Ringkasan </h3><br>  Metode pembagian dua bagian digunakan untuk mencari lokasi yang tepat dari musim gugur dan lokalisasi bug. <br><br>  Cari nomornya dan mulailah membaginya menjadi dua: <br><br><ul><li>  panjang garis; </li><li>  ukuran file </li><li>  berat file; </li><li>  jumlah baris / kolom; </li><li>  jumlah memori bebas di ponsel; </li><li>  ... </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_d/6_/7v/_d6_7vxayb-tfjsku59wq1vfopq.png"></div><br>  Tapi ingat - suatu hari Anda harus berhenti!  Tidak perlu berhenti dan mencari angka pastinya jika membutuhkan ribuan tes tambahan.  Tetapi 5-10 menit dapat diberikan untuk pelokalan. <br><br>  <i>PS - cari artikel yang lebih bermanfaat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di blog saya dengan tag â€œbergunaâ€</a></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id468087/">https://habr.com/ru/post/id468087/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id468077/index.html">Posit tes dengan cara dewasa. Analisis spektral</a></li>
<li><a href="../id468079/index.html">Dimensi khusus di Google Analytics yang menyelamatkan kami lebih dari sekali</a></li>
<li><a href="../id468081/index.html">â€œData anonimâ€ atau apa yang direncanakan di 152-FZ</a></li>
<li><a href="../id468083/index.html">Android Camera2 API dari ketel</a></li>
<li><a href="../id468085/index.html">Buku "Safe DevOps. Pengoperasian Sistem yang Efisien</a></li>
<li><a href="../id468089/index.html">Redefinisi Berbasis Edisi: apakah mungkin dalam produksi?</a></li>
<li><a href="../id468091/index.html">RUU tentang penciptaan database tunggal dengan data warga diadopsi di Duma Negara dalam bacaan pertama</a></li>
<li><a href="../id468093/index.html">Nitrat dalam produk: toko Swiss vs toko Rusia vs pondok musim panas</a></li>
<li><a href="../id468097/index.html">Microsoft Edge - Generic XSS</a></li>
<li><a href="../id468099/index.html">C / C ++ dari Python (CFFI, pybind11)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
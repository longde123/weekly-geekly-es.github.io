<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåò üë©üèΩ‚Äçüöí ü¶é Enfrente o Anti-Spoofing ou reconhe√ßa tecnologicamente um trapaceiro entre mil üéø üö∏ üçì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A identifica√ß√£o biom√©trica de uma pessoa √© uma das id√©ias mais antigas para o reconhecimento de pessoas, que elas geralmente tentavam implementar tecn...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Enfrente o Anti-Spoofing ou reconhe√ßa tecnologicamente um trapaceiro entre mil</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/452894/"><p>  A identifica√ß√£o biom√©trica de uma pessoa √© uma das id√©ias mais antigas para o reconhecimento de pessoas, que elas geralmente tentavam implementar tecnicamente.  As senhas podem ser roubadas, espionadas, esquecidas, as chaves podem ser falsificadas.  Mas as caracter√≠sticas √∫nicas da pr√≥pria pessoa s√£o muito mais dif√≠ceis de falsificar e perder.  Podem ser impress√µes digitais, voz, desenho dos vasos da retina, marcha e muito mais. </p><br><p><img src="https://habrastorage.org/webt/h4/wd/zr/h4wdzrqvlnvfy8da0k3cn5589hg.jpeg"></p><br><p>  Claro, os sistemas biom√©tricos est√£o tentando enganar!  √â sobre isso que falaremos hoje.  Como os invasores tentam burlar os sistemas de reconhecimento facial personificando outra pessoa e como isso pode ser detectado. </p><a name="habracut"></a><br><p>  Voc√™ pode assistir a uma vers√£o em v√≠deo desta hist√≥ria <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . Se voc√™ preferir ler e assistir, convido voc√™ a continuar </p><br><p>  De acordo com as id√©ias dos diretores de Hollywood e dos escritores de fic√ß√£o cient√≠fica, √© muito f√°cil enganar a identifica√ß√£o biom√©trica.  S√≥ √© necess√°rio apresentar ao sistema as ‚Äúpartes necess√°rias‚Äù do usu√°rio real, individualmente ou levando-o como ref√©m.  Ou voc√™ pode "colocar a m√°scara" de outra pessoa, por exemplo, usando uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">m√°scara de transplante f√≠sico</a> ou, em geral, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">apresentando falsos sinais gen√©ticos</a> </p><br><p>  Na vida real, os atacantes tamb√©m tentam se apresentar como outra pessoa.  Por exemplo, assalte um banco usando uma m√°scara de homem negro, como na figura abaixo. </p><br><p><img src="https://habrastorage.org/webt/pl/vz/67/plvz67jfgazkigzqsdhkko62ego.png"></p><br><p>  O reconhecimento de rosto parece uma √°rea muito promissora para uso no setor m√≥vel.  Se h√° muito tempo que todos est√£o acostumados a usar impress√µes digitais, e a tecnologia da voz est√° se desenvolvendo de forma gradual e razoavelmente previs√≠vel, ent√£o, com a identifica√ß√£o pela face, a situa√ß√£o se desenvolveu bastante incomum e digna de uma pequena digress√£o na hist√≥ria do problema. </p><br><h2 id="kak-vse-nachinalos-ili-iz-fantastiki-v-realnost">  Como tudo come√ßou ou da fic√ß√£o √† realidade </h2><br><p>  Os sistemas de reconhecimento atuais demonstram uma tremenda precis√£o.  Com o advento de grandes conjuntos de dados e arquiteturas complexas, tornou-se poss√≠vel obter precis√£o de reconhecimento facial de at√© 0,000001 (um erro por milh√£o!) E agora eles s√£o adequados para transfer√™ncia para plataformas m√≥veis.  O gargalo era sua vulnerabilidade. </p><br><p>  Para representar outra pessoa em nossa realidade t√©cnica, e n√£o no filme, as m√°scaras s√£o usadas com mais frequ√™ncia.  Eles tamb√©m tentam enganar o sistema de computador apresentando outra pessoa em vez de seu rosto.  As m√°scaras podem ter uma qualidade completamente diferente, desde a foto de outra pessoa impressa na frente do rosto impressa na impressora a m√°scaras tridimensionais muito complexas com aquecimento.  As m√°scaras podem ser apresentadas separadamente na forma de uma folha ou tela, ou usadas na cabe√ßa. </p><br><p>  Muita aten√ß√£o foi atra√≠da para o t√≥pico por uma tentativa bem-sucedida de enganar o sistema Face ID no iPhone X com uma m√°scara bastante complexa de p√≥ de pedra com inser√ß√µes especiais ao redor dos olhos que imitam o calor de um rosto vivo usando radia√ß√£o infravermelha. </p><br><p><img src="https://habrastorage.org/webt/xl/kq/pr/xlkqprysss0ce2arbqm0sw_xbpo.png"></p><br><p>  Alega-se que usando essa m√°scara foi poss√≠vel enganar o Face ID no iPhone X. V√≠deo e algum texto podem ser encontrados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> </p><br><p>  A presen√ßa de tais vulnerabilidades √© muito perigosa para os sistemas banc√°rios ou estaduais para autenticar um usu√°rio pessoalmente, onde a penetra√ß√£o de um invasor acarreta perdas significativas. </p><br><h2 id="terminologiya">  Terminologia </h2><br><p>  O campo de pesquisa do anti-spoofing de face √© bastante novo e ainda n√£o pode se gabar nem da terminologia predominante. </p><br><p>  Vamos concordar em chamar uma tentativa de enganar o sistema de identifica√ß√£o apresentando-o com um falso par√¢metro biom√©trico (neste caso, uma pessoa) <strong>ataque de falsifica√ß√£o</strong> . </p><br><p>  Consequentemente, um conjunto de medidas de prote√ß√£o para combater esse engano ser√° chamado de <strong>anti-spoofing</strong> .  Ele pode ser implementado na forma de uma variedade de tecnologias e algoritmos que s√£o incorporados ao transportador de um sistema de identifica√ß√£o. </p><br><p>  A <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ISO</a> oferece um conjunto de terminologias ligeiramente expandido, com termos como <strong>ataque de apresenta√ß√£o</strong> - tenta fazer com que o sistema identifique incorretamente o usu√°rio ou permita que ele evite a identifica√ß√£o demonstrando uma imagem, um v√≠deo gravado etc.  <strong>Normal (Bona Fide)</strong> - corresponde ao algoritmo usual do sistema, ou seja, tudo o que N√ÉO √© um ataque.  <strong>Instrumento de ataque de apresenta√ß√£o</strong> significa um meio de ataque, por exemplo, uma parte artificial do corpo.  E, finalmente, a <strong>detec√ß√£o de ataques de apresenta√ß√£o</strong> - meios automatizados de detectar esses ataques.  No entanto, os pr√≥prios padr√µes ainda est√£o em desenvolvimento, por isso √© imposs√≠vel falar sobre quaisquer conceitos estabelecidos.  A terminologia em russo est√° quase completamente ausente. </p><br><p>  Para determinar a qualidade do trabalho, os sistemas geralmente usam a m√©trica <strong>HTER</strong> (Taxa de erro total da metade - metade do erro total), que √© calculada como a soma dos coeficientes das identifica√ß√µes permitidas erroneamente (FAR - Taxa de aceita√ß√£o falsa) e identifica√ß√µes proibidas erroneamente (FRR - Taxa de rejei√ß√£o falsa), dividida ao meio. <br>  HTER = (FAR + FRR) / 2 </p><br><p>  Vale dizer que, em sistemas biom√©tricos, o FAR geralmente recebe a maior aten√ß√£o, a fim de fazer todo o poss√≠vel para impedir que um invasor entre no sistema.  E eles est√£o fazendo um bom progresso nisso (lembra-se do milion√©simo desde o in√≠cio do artigo?) O outro lado √© o aumento inevit√°vel da FRR - o n√∫mero de usu√°rios comuns erroneamente classificados como intrusos.  Se isso puder ser sacrificado por sistemas estatais, de defesa e outros sistemas similares, as tecnologias m√≥veis que funcionam com sua enorme escala, uma variedade de dispositivos de assinante e, em geral, dispositivos orientados √† perspectiva do usu√°rio, s√£o muito sens√≠veis a quaisquer fatores que podem fazer com que os usu√°rios recusem servi√ßos.  Se voc√™ quiser reduzir o n√∫mero de telefones esmagados contra a parede ap√≥s a d√©cima nega√ß√£o consecutiva de identifica√ß√£o, preste aten√ß√£o ao FRR! </p><br><h2 id="vidy-atak-obmanyvaem-sistemu">  Tipos de ataques.  Sistema de fraude </h2><br><p><img src="https://habrastorage.org/webt/dt/jx/lp/dtjxlptnxcphiicevd6lbhlzzpa.png"></p><br><p>  Por fim, vamos descobrir exatamente como os invasores enganam o sistema de reconhecimento e como isso pode ser combatido. </p><br><p>  O meio mais popular de trapacear s√£o as m√°scaras.  N√£o h√° nada mais √≥bvio do que colocar a m√°scara de outra pessoa e apresentar seu rosto a um sistema de identifica√ß√£o (geralmente chamado de ataque de m√°scara). </p><br><p><img src="https://habrastorage.org/webt/q2/tr/nl/q2trnl3zhhuftbggl3vx-sfqoyw.png"></p><br><p>  Voc√™ tamb√©m pode imprimir uma foto sua ou de outra pessoa em um peda√ßo de papel e traz√™-la para a c√¢mera (vamos chamar esse tipo de ataque de ataque impresso). </p><br><p><img src="https://habrastorage.org/webt/f9/g7/ds/f9g7dsc81eiffu9srctasf2udcm.png"></p><br><p>  Um pouco mais complicado √© o ataque de repeti√ß√£o, quando o sistema √© apresentado com a tela de outro dispositivo no qual um v√≠deo gravado anteriormente com outra pessoa √© reproduzido.  A complexidade da execu√ß√£o √© compensada pela alta efici√™ncia de um ataque desse tipo, j√° que os sistemas de controle costumam usar sinais baseados na an√°lise de seq√º√™ncias de tempo, por exemplo, rastreamento de piscar, micro-movimentos da cabe√ßa, presen√ßa de express√µes faciais, respira√ß√£o e assim por diante.  Tudo isso pode ser facilmente reproduzido em v√≠deo. </p><br><p><img src="https://habrastorage.org/webt/de/dd/vj/deddvj6xvnwbv6dpbryxphjwaa8.png"></p><br><p>  Ambos os tipos de ataques t√™m v√°rios recursos caracter√≠sticos que permitem detect√°-los e, assim, distinguem uma tela de tablet ou uma folha de papel de uma pessoa real. </p><br><p>  Resumimos os recursos caracter√≠sticos que nos permitem identificar esses dois tipos de ataques em uma tabela: </p><br><div class="scrollable-table"><table><thead><tr><th>  <strong>Ataque impresso</strong> </th><th>  <strong>Replay attack</strong> </th></tr></thead><tbody><tr><td>  Diminuir a qualidade da textura da imagem ao imprimir </td><td>  Moir√© </td></tr><tr><td>  Artefatos da transmiss√£o de meio-tom ao imprimir em uma impressora </td><td>  Reflex√µes (destaques) </td></tr><tr><td>  Artefatos de impress√£o mec√¢nica (linhas horizontais) </td><td>  Imagem plana (falta de profundidade) </td></tr><tr><td>  Falta de movimentos locais (por exemplo, piscando) </td><td>  As margens da imagem podem estar vis√≠veis. </td></tr><tr><td>  As margens da imagem podem estar vis√≠veis. </td><td></td></tr></tbody></table></div><br><h2 id="algoritmy-obnaruzheniya-atak-staraya-dobraya-klassika">  Algoritmos de detec√ß√£o de ataques.  Bom velho cl√°ssico </h2><br><p><img src="https://habrastorage.org/webt/1r/n8/-e/1rn8-elrfhm1q0ud9q4jbaukidq.png"></p><br><p>  Uma das abordagens mais antigas (2007, 2008) baseia-se na detec√ß√£o de piscadas humanas, analisando a imagem usando uma m√°scara.  O objetivo √© criar algum tipo de classificador bin√°rio que permita selecionar imagens com os olhos abertos e fechados em uma sequ√™ncia de quadros.  Isso pode ser uma an√°lise do fluxo de v√≠deo usando a identifica√ß√£o de partes da face (detec√ß√£o de ponto de refer√™ncia) ou o uso de alguma rede neural simples.  E hoje esse m√©todo √© mais frequentemente usado;  o usu√°rio √© solicitado a executar uma sequ√™ncia de a√ß√µes: vire a cabe√ßa, pisque, sorria e muito mais.  Se a sequ√™ncia for aleat√≥ria, n√£o √© f√°cil para um invasor se preparar com anteced√™ncia.  Infelizmente, para um usu√°rio honesto, essa miss√£o tamb√©m nem sempre √© super√°vel, e o engajamento diminui acentuadamente. </p><br><p><img src="https://habrastorage.org/webt/4s/fb/vv/4sfbvvforopuonls_ochr8dpzjg.png"></p><br><p>  Voc√™ tamb√©m pode usar os recursos de deteriora√ß√£o da qualidade da imagem ao imprimir ou reproduzir na tela.  Provavelmente, at√© alguns padr√µes locais, mesmo esquivos pelos olhos, ser√£o detectados na imagem.  Isso pode ser feito, por exemplo, contando padr√µes bin√°rios locais (LBP, padr√£o bin√°rio local) para diferentes √°reas da face ap√≥s a sele√ß√£o no quadro ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PDF</a> ).  O sistema descrito pode ser considerado o fundador de toda a dire√ß√£o dos algoritmos de anti-spoofing de face com base na an√°lise de imagem.  Em poucas palavras, ao calcular o LBP, cada pixel da imagem, oito de seus vizinhos s√£o capturados sequencialmente e sua intensidade √© comparada.  Se a intensidade for maior que no pixel central, um ser√° atribu√≠do, se menor, zero.  Assim, para cada pixel √© obtida uma sequ√™ncia de 8 bits.  Com base nas seq√º√™ncias obtidas, √© constru√≠do um histograma por pixel, que √© alimentado na entrada do classificador SVM. </p><br><p><img src="https://habrastorage.org/webt/qu/x_/vv/qux_vvmfk7ikww7ojknhq_mpbhu.png"></p><br><p>  Padr√µes bin√°rios locais, histograma e SVM.  Voc√™ pode se juntar aos cl√°ssicos atemporais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> </p><br><p>  O indicador de efici√™ncia do HTER √© de "at√©" 15% e significa que uma parte significativa dos atacantes supera a defesa sem muito esfor√ßo, embora deva-se reconhecer que muito √© eliminado.  O algoritmo foi testado no conjunto de dados IDIAP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Replay-Attack</a> , composto por 1200 v√≠deos curtos de 50 participantes e tr√™s tipos de ataques - ataque impresso, ataque m√≥vel, ataque de alta defini√ß√£o. </p><br><p>  Id√©ias para analisar a textura da imagem foram continuadas.  Em 2015, a Bukinafit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">desenvolveu um</a> algoritmo para dividir alternativamente a imagem em canais, al√©m do RGB tradicional, para os resultados cujos padr√µes bin√°rios locais foram novamente calculados, que, como no m√©todo anterior, foram alimentados na entrada do classificador SVN.  A precis√£o do HTER, calculada nos conjuntos de dados CASIA e Replay-Attack, era impressionante na √©poca, 3%. </p><br><p><img src="https://habrastorage.org/webt/7j/vy/i7/7jvyi7inhsl5g2ulp05v4luido8.png"></p><br><p>  Ao mesmo tempo, apareceu um trabalho sobre a detec√ß√£o de moir√©.  Patel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publicou</a> um artigo em que sugeria procurar artefatos de imagem na forma de um padr√£o peri√≥dico causado pela sobreposi√ß√£o de duas digitaliza√ß√µes.  A abordagem acabou sendo vi√°vel, mostrando ao HTER cerca de 6% nos conjuntos de dados IDIAP, CASIA e RAFS.  Foi tamb√©m a primeira tentativa de comparar o desempenho de um algoritmo em diferentes conjuntos de dados. </p><br><p><img src="https://habrastorage.org/webt/98/m2/ls/98m2ls-svv7gxfaagripfrhzymo.png"></p><br><p>  Padr√£o peri√≥dico na imagem causado por varreduras de sobreposi√ß√£o </p><br><p>  Para detectar tentativas de apresenta√ß√£o de fotos, a solu√ß√£o l√≥gica era tentar analisar n√£o uma imagem, mas sua sequ√™ncia retirada do fluxo de v√≠deo.  Por exemplo, Anjos e colegas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sugeriram</a> isolar recursos do fluxo √≥ptico em pares adjacentes de quadros, alimentando o classificador bin√°rio na entrada e calculando a m√©dia dos resultados.  A abordagem acabou sendo bastante eficaz, demonstrando um HTER de 1,52% em seu pr√≥prio conjunto de dados. </p><br><p><img src="https://habrastorage.org/webt/ih/9e/vo/ih9evob9a5hmtjekxhx1iwsgxm8.png"></p><br><p>  Um m√©todo interessante para rastrear movimentos, que √© um pouco distante das abordagens convencionais.  Como em 2013 o princ√≠pio ‚Äúaplicar uma imagem bruta √† entrada da rede convolucional e ajustar as camadas da grade para obter o resultado‚Äù n√£o era usual nos projetos modernos de aprendizado profundo, Bharadzha <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aplicava</a> consistentemente transforma√ß√µes preliminares mais complexas.  Em particular, ele usou o algoritmo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">amplia√ß√£o de v√≠deo euleriano</a> conhecido pelo trabalho de cientistas do MIT, que foi usado com sucesso para analisar as mudan√ßas de cor na pele, dependendo do pulso.  Substitu√≠ o LBP pelo HOOF (histogramas das dire√ß√µes √≥pticas de fluxo), tendo notado corretamente que, como queremos rastrear movimentos, precisamos de sinais apropriados, e n√£o apenas de an√°lise de textura.  O mesmo SVM, tradicional na √©poca, era usado como classificador.  O algoritmo mostrou resultados extremamente impressionantes nos conjuntos de dados Print Attack (0%) e Replay Attack (1,25%). </p><br><p><img src="https://habrastorage.org/webt/-i/1w/w2/-i1ww2rsu0kqmxglhh-on8lnr5g.png"></p><br><h2 id="davayte-uzhe-uchit-setki">  J√° vamos aprender a grade! </h2><br><p><img src="https://habrastorage.org/webt/7p/t-/yk/7pt-ykbzzuyb7bzpnd9qpjodfog.png"></p><br><p>  De algum ponto, ficou √≥bvio que a transi√ß√£o para o aprendizado profundo havia amadurecido.  A not√≥ria "revolu√ß√£o do aprendizado profundo" superou a antifalsifica√ß√£o. </p><br><p>  A ‚Äúprimeira andorinha‚Äù pode ser considerada o m√©todo de an√°lise de mapas de profundidade em se√ß√µes individuais (‚Äúremendos‚Äù) da imagem.  Obviamente, um mapa de profundidade √© um sinal muito bom para determinar o plano em que a imagem est√° localizada.  Se apenas porque a imagem na folha de papel n√£o tem "profundidade" por defini√ß√£o.  No trabalho <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">de Ataum em</a> 2017, muitas pequenas se√ß√µes separadas foram extra√≠das da imagem; mapas de profundidade foram calculados para eles, que depois se fundiram com o mapa de profundidade da imagem principal.  Assinalou-se que dez amostras aleat√≥rias de imagens faciais s√£o suficientes para identificar de forma confi√°vel o Ataque Impresso.  Al√©m disso, os autores reuniram os resultados de duas redes neurais convolucionais, a primeira das quais calculou mapas de profundidade para manchas e a segunda para a imagem como um todo.  Durante o treinamento em conjuntos de dados, a classe Ataque Impresso foi associada a um mapa de profundidade zero e uma s√©rie de se√ß√µes selecionadas aleatoriamente foi associada a um modelo de face tridimensional.  Em geral, o mapa de profundidade em si n√£o era t√£o importante, apenas uma determinada fun√ß√£o indicadora foi usada, o que caracteriza a ‚Äúprofundidade da se√ß√£o‚Äù.  O algoritmo apresentou um valor HTER de 3,78%.  Tr√™s conjuntos de dados p√∫blicos foram usados ‚Äã‚Äãpara treinamento - CASIA-MFSD, MSU-USSA e Replay-Attack. </p><br><p><img src="https://habrastorage.org/webt/a7/bl/df/a7bldfybkgzeeptdtomphvq1kwk.png"></p><br><p>  Infelizmente, a disponibilidade de um grande n√∫mero de excelentes estruturas para o aprendizado profundo levou ao surgimento de um grande n√∫mero de desenvolvedores que est√£o tentando "resolver" o problema da antifalsifica√ß√£o de rosto de uma maneira bem conhecida de montar redes neurais.  Geralmente, parece uma pilha de mapas de recursos nas sa√≠das de v√°rias redes pr√©-treinadas em alguns conjuntos de dados generalizados que s√£o alimentados a um classificador bin√°rio. </p><br><p><img src="https://habrastorage.org/webt/ek/8b/rc/ek8brc52akg2y3zfy6ejmbr-taq.png"></p><br><p>  Em geral, vale a pena concluir que, at√© o momento, foram publicados alguns trabalhos, que geralmente apresentam bons resultados e que unem apenas um pequeno ‚Äúmas‚Äù.  Todos esses resultados s√£o demonstrados em um conjunto de dados espec√≠fico!  A situa√ß√£o √© agravada pela disponibilidade limitada de conjuntos de dados e, por exemplo, no not√≥rio Replay-Attack, n√£o surpreende HTER 0%.  Tudo isso leva ao surgimento de arquiteturas muito complexas, como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">essas</a> , usando v√°rios recursos engenhosos, algoritmos auxiliares montados na pilha, com v√°rios classificadores, cujos resultados s√£o calculados em m√©dia, e assim por diante ... Os autores obt√™m HTER = 0,04% na sa√≠da! </p><br><p><img src="https://habrastorage.org/webt/aw/_k/s_/aw_ks_6-xp40fyjz97ue9mwzp8q.png"></p><br><p>  Isso sugere que o problema de antifalsifica√ß√£o de rosto foi resolvido em um conjunto de dados espec√≠fico.  Vamos trazer para a mesa v√°rios m√©todos modernos baseados em redes neurais.  √â f√°cil ver que os "resultados de refer√™ncia" foram alcan√ßados por m√©todos muito diversos que surgiram apenas nas mentes questionadoras dos desenvolvedores. </p><br><p><img src="https://habrastorage.org/webt/bb/7v/73/bb7v73awyzwhxeyyvtejgm3skh4.png"></p><br><p>  Resultados comparativos de v√°rios algoritmos.  A tabela √© retirada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> . </p><br><p>  Infelizmente, o mesmo fator ‚Äúpequeno‚Äù viola a boa imagem da luta por d√©cimos de um por cento.  Se voc√™ tentar treinar a rede neural em um conjunto de dados e aplic√°-lo em outro, os resultados ser√£o ... n√£o t√£o otimistas.  Pior ainda, as tentativas de aplicar classificadores na vida real n√£o deixam nenhuma esperan√ßa. <br>  Como exemplo, tomamos os dados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">de</a> 2015, onde uma m√©trica de sua qualidade foi usada para determinar a autenticidade da imagem apresentada.  D√™ uma olhada em si mesmo: </p><br><p><img src="https://habrastorage.org/webt/jw/b5/-n/jwb5-naohhjhek2tkmakbssjyik.png"></p><br><p>  Em outras palavras, um algoritmo treinado nos dados do Idiap, mas aplicado no MSU, fornecer√° uma taxa de detec√ß√£o verdadeiramente positiva de 90,5%, e se voc√™ fizer o oposto (treinar no MSU e testar no Idiap), apenas 47,2 poder√£o ser determinados corretamente % (!) Para outras combina√ß√µes, a situa√ß√£o piora ainda mais e, por exemplo, se voc√™ treina o algoritmo no MSU e o verifica no CASIA, o TPR ser√° de 10,8%!  Isso significa que um grande n√∫mero de usu√°rios honestos foi atribu√≠do erroneamente aos atacantes, o que n√£o pode deixar de ser deprimente.  Mesmo o treinamento entre bancos de dados n√£o conseguiu reverter a situa√ß√£o, o que parece ser uma sa√≠da perfeitamente razo√°vel. </p><br><p>  Vamos ver mais.  Os resultados apresentados no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo de</a> Patel em 2016 mostram que, mesmo com pipelines de processamento bastante complexos e com a sele√ß√£o de recursos confi√°veis, como pisca e textura, os resultados em conjuntos de dados desconhecidos n√£o podem ser considerados satisfat√≥rios.  Ent√£o, em algum momento, ficou bastante √≥bvio que os m√©todos propostos n√£o eram desesperadamente suficientes para resumir os resultados. </p><br><p><img src="https://habrastorage.org/webt/vf/lz/ol/vflzoljiplnkj_vgm-zth9a0sdc.png"></p><br><h2 id="a-esli-ustroit-sorevnovanie">  E se voc√™ organizar uma competi√ß√£o ... </h2><br><p>  Claro, no campo da cara anti-spoofing n√£o foi sem concorr√™ncia.  Em 2017, foi realizada uma competi√ß√£o na Universidade de Oulu, na Finl√¢ndia, com seu pr√≥prio novo conjunto de dados com protocolos bastante interessantes, orientados especificamente para uso no campo de aplicativos m√≥veis. </p><br><p>  - Protocolo 1: H√° uma diferen√ßa na ilumina√ß√£o e no fundo.  Os conjuntos de dados s√£o gravados em v√°rios locais e diferem em segundo plano e ilumina√ß√£o. </p><br><p>  Protocolo 2: V√°rios modelos de impressoras e telas foram usados ‚Äã‚Äãpara ataques.  Portanto, no conjunto de dados de verifica√ß√£o, √© utilizada uma t√©cnica que n√£o √© encontrada no conjunto de treinamento </p><br><p>  Protocolo 3: Intercambiabilidade de sensores.  V√≠deos e ataques de usu√°rios reais s√£o gravados em cinco smartphones diferentes e usados ‚Äã‚Äãem um conjunto de dados de treinamento.         ,      . </p><br><p> - 4:    . </p><br><p>    .     ,      ,            ,      -      .      ,   ,  10%.        : </p><br><ol><li><p> GRADIENT </p><br><ul><li>      (   HSV  YCbCr),   . </li><li>                . </li><li>           HSV  YCbCr,     .    ROI (region-of-interest)            160√ó160 .. </li><li>  ROI   3√ó3  5√ó5  ,     LBP  ,        6018. </li><li>      (Recursive Feature Elimination)    6018  1000. </li><li>         SVM   .| </li></ul><br></li><li><p> SZCVI </p><br><ul><li>      ,    </li><li>    216√ó384 </li><li>  VGG-  </li><li>       </li></ul><br></li><li><p> Recod </p><br><ul><li> SqueezeNet   Imagenet </li><li> Transfer learning    : CASIA  UVAD </li><li>       224√ó224 pixels.      , ,   ,     CNN. </li><li>        . </li><li>            </li></ul><br></li><li><p> CPqD </p><br><ul><li>  Inception-v3,   ImageNet </li><li> C   </li><li>         ,  ,      224√ó224 RGB | </li></ul><br></li></ol><br><p>  ,       .    LBP,  ,    ,     .. GRADIANT        ,     ,      ,   .     . </p><br><p>      .   ,        . -,        ( 15   NUAA  1140  MSU-USSA)  ,   ,  ,   ,     .       ,  ,  ,    ,         . -,                 . ,   CASIA        ,     . ,     ,    ,    ,      ‚Ä¶  ,       ,   ,           . </p><br><p><img src="https://habrastorage.org/webt/ur/yf/t8/uryft8082ylvw-1kbyvcxucjcem.png"></p><br><p>       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>        30 .   ,        ,            .  ,          . </p><br><p> ,  ,   ¬´ ¬ª.          . ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>     (rPPG ‚Äì remote photoplethysmography),       .    ,           , -,   ‚Äì     .            .  ,        , ,  . ,        ,     .            ,     ,                 ,        . </p><br><p><img src="https://habrastorage.org/webt/db/le/44/dble44fc8acyqdhzead3ndbkg3a.png"></p><br><p><img src="https://habrastorage.org/webt/sy/u7/vu/syu7vucfvb5inhajqoilb6rqxu8.png"></p><br><p> O trabalho mostrou um valor de HTER de cerca de 10%, confirmando a principal aplicabilidade do m√©todo.  Existem v√°rios trabalhos que confirmam as perspectivas dessa abordagem. <br>  (CVPR 2018) JH-Ortega et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">An√°lise do tempo do rosto anti-falsifica√ß√£o baseado em pulso em vis√≠vel e NIR</a> <br>  (2016) X. Li.  et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Anti-falsifica√ß√£o de rosto generalizada, detectando o pulso de v√≠deos de rosto</a> <br>  (2016) J. Chen et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Realsense = frequ√™ncia card√≠aca real: estimativa invari√°vel da frequ√™ncia card√≠aca a partir de v√≠deos</a> <br>  (2014) HE Tasli et al.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Medi√ß√£o remota de sinais vitais baseada em PPG usando regi√µes faciais adapt√°veis</a> </p><br><p>  Em 2018, Liu e colegas da Universidade de Michigan propuseram <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">abandonar a classifica√ß√£o bin√°ria</a> em favor da abordagem que eles chamaram de ‚Äúsupervis√£o bin√°ria‚Äù - ou seja, usar uma estimativa mais complexa baseada em um mapa de profundidade e em fotopletismografia remota.  Para cada uma dessas imagens faciais, um modelo tridimensional foi reconstru√≠do usando uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rede neural</a> e nomeado com um mapa de profundidade.  As imagens falsas receberam um mapa de profundidade composto por zeros, no final, √© apenas um peda√ßo de papel ou uma tela de dispositivo!  Essas caracter√≠sticas foram tomadas como ‚Äúverdade‚Äù; as redes neurais foram treinadas em seu pr√≥prio conjunto de dados SiW.  Em seguida, uma m√°scara facial tridimensional foi sobreposta √† imagem de entrada, um mapa de profundidade e um pulso foram calculados, e tudo isso foi amarrado em um transportador bastante complicado.  Como resultado, o m√©todo mostrou uma precis√£o de cerca de 10% no conjunto de dados competitivo da OULU.  Curiosamente, o vencedor da competi√ß√£o organizada pela Universidade de Oulu construiu o algoritmo em padr√µes de classifica√ß√£o bin√°ria, rastreamento intermitente e outros sinais "projetados √† m√£o", e sua solu√ß√£o tamb√©m teve uma precis√£o de cerca de 10%.  O ganho foi de apenas meio por cento!  A nova tecnologia combinada √© suportada pelo fato de o algoritmo ter sido treinado em seu pr√≥prio conjunto de dados e testado no OULU, melhorando o resultado do vencedor.  Isso indica uma certa portabilidade dos resultados do conjunto de dados para o conjunto de dados e, o que diabos n√£o est√° brincando, √© poss√≠vel para a vida real.  No entanto, ao tentar executar o treinamento em outros conjuntos de dados - CASIA e ReplayAttack, o resultado foi novamente cerca de 28%.  Obviamente, isso excede o desempenho de outros algoritmos ao treinar em v√°rios conjuntos de dados, mas com esses valores de precis√£o, n√£o se pode falar em nenhum uso industrial! </p><br><p><img src="https://habrastorage.org/webt/qd/bu/fn/qdbufnt8yc9pghj4egkxqaku_3g.png"></p><br><p>  Uma abordagem diferente foi proposta por Wang e colegas em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho</a> recente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">de</a> 2019.  Observou-se que, na an√°lise da micromo√ß√£o da face, s√£o not√°veis ‚Äã‚Äãrota√ß√µes e deslocamentos da cabe√ßa, levando a uma mudan√ßa caracter√≠stica nos √¢ngulos e dist√¢ncias relativas entre os sinais na face.  Portanto, quando o rosto √© deslocado horizontalmente, o √¢ngulo entre o nariz e a orelha aumenta.  Por√©m, se voc√™ trocar uma folha de papel com uma imagem da mesma maneira, o √¢ngulo diminuir√°!  Para ilustra√ß√£o, vale a pena citar um desenho da obra. </p><br><p><img src="https://habrastorage.org/webt/x9/lq/kz/x9lqkzuzmgz7gz5ejx1rsiom7wq.png"></p><br><p>  Sob esse princ√≠pio, os autores constru√≠ram uma unidade de aprendizado inteira para transferir dados entre as camadas de uma rede neural.  Ele levou em considera√ß√£o ‚Äúcompensa√ß√µes incorretas‚Äù para cada quadro em uma sequ√™ncia de dois quadros, e isso permitiu que os resultados fossem usados ‚Äã‚Äãno pr√≥ximo bloco de an√°lise de depend√™ncia de longo prazo com base na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Unidade Recorrente Fechada</a> GRU.  Todos os sinais foram concatenados, a fun√ß√£o de perda foi calculada e a classifica√ß√£o final foi realizada.  Isso nos permitiu melhorar um pouco o resultado no conjunto de dados da OULU, mas o problema de depend√™ncia dos dados de treinamento permaneceu, pois para o par CASIA-MFSD e Replay-Attack, os indicadores eram 17,5 e 24%, respectivamente. </p><br><p>  No final, vale a pena observar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalho dos</a> especialistas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">da</a> Tencent, que propuseram alterar a maneira como a imagem de v√≠deo de origem √© recebida.  Em vez de observar passivamente a cena, eles sugeriram iluminar dinamicamente o rosto e ler reflex√µes.  O princ√≠pio da irradia√ß√£o ativa de um objeto h√° muito tempo √© aplicado em sistemas de localiza√ß√£o de v√°rios tipos; portanto, seu uso no estudo da face parece muito l√≥gico.  Obviamente, para uma identifica√ß√£o confi√°vel na pr√≥pria imagem, n√£o h√° sinais suficientes, e iluminar a tela do telefone ou tablet com uma sequ√™ncia de s√≠mbolos de luz (CAPTCHA de luz de acordo com a terminologia dos autores) pode ajudar bastante.  A seguir, √© determinada a diferen√ßa de dispers√£o e reflex√£o sobre um par de quadros, e os resultados s√£o alimentados em uma rede neural multitarefa para processamento adicional no mapa de profundidade e c√°lculo de v√°rias fun√ß√µes de perda.  No final, √© realizada uma regress√£o dos quadros de luz normalizados.  Os autores n√£o analisaram a capacidade de generaliza√ß√£o de seu algoritmo em outros conjuntos de dados e o treinaram em seu pr√≥prio conjunto de dados privado.  O resultado √© de cerca de 1% e √© relatado que o modelo j√° foi implantado para uso real. </p><br><p><img src="https://habrastorage.org/webt/c-/ts/w8/c-tsw8vywrvsv3l58ow-axifkay.png"></p><br><p>  At√© 2017, a √°rea antifalsifica√ß√£o de rosto n√£o era muito ativa.  Mas 2019 j√° apresentou uma s√©rie de trabalhos, que est√£o associados √† promo√ß√£o agressiva de tecnologias m√≥veis de identifica√ß√£o facial, principalmente pela Apple.  Al√©m disso, os bancos est√£o interessados ‚Äã‚Äãem tecnologias de reconhecimento facial.  Muitas pessoas novas vieram para o setor, o que nos permite esperar um progresso r√°pido.  Mas at√© agora, apesar dos belos t√≠tulos das publica√ß√µes, a capacidade de generaliza√ß√£o dos algoritmos permanece muito fraca e n√£o nos permite falar sobre qualquer adequa√ß√£o para uso pr√°tico. </p><br><h2 id="zaklyuchenie-a-naposledok-ya-skazhu-chto">  Conclus√£o  E finalmente, eu direi isso ... </h2><br><ul><li>  Os padr√µes bin√°rios locais, rastreamento de piscar, respira√ß√£o, movimentos e outros sinais projetados manualmente n√£o perderam seu significado.  Isso se deve principalmente ao fato de o treinamento profundo no campo da anti-falsifica√ß√£o de rosto ainda ser muito ing√™nuo. </li><li>  √â claro que, na "mesma solu√ß√£o", v√°rios m√©todos ser√£o mesclados.  An√°lise de reflex√£o, dispers√£o e mapas de profundidade devem ser usados ‚Äã‚Äãjuntos.  Provavelmente, a adi√ß√£o de um canal de dados adicional ajudar√°, por exemplo, grava√ß√£o de voz e algum tipo de abordagem do sistema que permitir√° coletar v√°rias tecnologias em um √∫nico sistema </li><li>  Quase todas as tecnologias usadas para reconhecimento de rosto encontram aplica√ß√£o em anti-falsifica√ß√£o de rosto (cap!) Tudo o que foi desenvolvido para reconhecimento de face, de uma forma ou de outra, encontrou aplica√ß√£o para an√°lise de ataques </li><li>  Os conjuntos de dados existentes atingiram a satura√ß√£o.  Dos dez conjuntos de dados b√°sicos em cinco, erro zero foi atingido.  Isso j√° fala, por exemplo, da efici√™ncia de m√©todos baseados em mapas de profundidade, mas n√£o permite melhorar a capacidade de generaliza√ß√£o.  Precisamos de novos dados e novas experi√™ncias sobre eles </li><li>  H√° um claro desequil√≠brio entre o grau de desenvolvimento do reconhecimento de rosto e o anti-spoofing de rosto.  As tecnologias de reconhecimento est√£o significativamente √† frente dos sistemas de prote√ß√£o.  Al√©m disso, √© a falta de sistemas de prote√ß√£o confi√°veis ‚Äã‚Äãque inibe o uso pr√°tico dos sistemas de reconhecimento facial.  Aconteceu que a principal aten√ß√£o foi dada especificamente ao reconhecimento de rosto, e os sistemas de detec√ß√£o de ataques permaneceram um pouco distantes </li><li>  Existe uma forte necessidade de uma abordagem sistem√°tica no campo da anti-falsifica√ß√£o de rosto.  A competi√ß√£o anterior da Universidade de Oulu mostrou que, ao usar um conjunto de dados n√£o representativo, √© poss√≠vel derrotar com um simples ajuste competente das solu√ß√µes estabelecidas, sem desenvolver novas.  Talvez uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">nova competi√ß√£o</a> possa mudar a mar√© </li><li>  Com o crescente interesse no assunto e a introdu√ß√£o de tecnologias de reconhecimento facial por grandes players, surgiram ‚Äújanelas de oportunidade‚Äù para novas equipes ambiciosas, pois h√° uma s√©ria necessidade de uma nova solu√ß√£o no n√≠vel arquitetural </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt452894/">https://habr.com/ru/post/pt452894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt452884/index.html">An√°lise do desempenho da m√°quina virtual no VMware vSphere. Parte 1: CPU</a></li>
<li><a href="../pt452886/index.html">Projetos Wiki e nome Noosfera em HACKNOWLEGE</a></li>
<li><a href="../pt452888/index.html">Perto de Munique, come√ßou a testar o tiltrotor Lilium Jet de cinco lugares</a></li>
<li><a href="../pt452890/index.html">23 de maio, 18:30 - transmiss√£o ao vivo da cozinha QIWI</a></li>
<li><a href="../pt452892/index.html">Como um n√£o programador pode se mudar para os EUA: instru√ß√µes passo a passo</a></li>
<li><a href="../pt452900/index.html">√çndices no PostgreSQL - 9 (BRIN)</a></li>
<li><a href="../pt452902/index.html">Terminando 4 anos de treinamento como programador, entendo que estou longe de ser um programador</a></li>
<li><a href="../pt452904/index.html">Como as m√°quinas se comunicam - protocolo MQTT</a></li>
<li><a href="../pt452906/index.html">Mecanismos JavaScript: como eles funcionam? Da pilha de chamadas √†s promessas, (quase) tudo o que voc√™ precisa saber</a></li>
<li><a href="../pt452908/index.html">Selenium WebDriver - M√©trica de teste em tempo real usando Grafana e InfluxDB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>